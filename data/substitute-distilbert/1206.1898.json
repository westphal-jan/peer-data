{"id": "1206.1898", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jun-2012", "title": "A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function", "abstract": "we propose a broader bayesian approach to solve stochastic optimization problems that involve finding extrema of noisy, nonlinear functions. previous work has dominated on representing possible functions explicitly, which continues to a half - step procedure of first, doing inference over binary function space and second, finding the extrema of these functions. here we skip functional representation step and directly model the distribution over extrema. onto this end, we devise a non - parametric conjugate prior where the estimated parameter belongs to a robust kernel function and the sufficient statistic is composed of various observed function values. the resulting posterior exponential directly captures the uncertainty over the maximum of the unknown function.", "histories": [["v1", "Sat, 9 Jun 2012 01:57:02 GMT  (391kb)", "https://arxiv.org/abs/1206.1898v1", "8 pages, 4 figures"], ["v2", "Sat, 10 Nov 2012 18:09:17 GMT  (977kb)", "http://arxiv.org/abs/1206.1898v2", "9 pages, 5 figures"]], "COMMENTS": "8 pages, 4 figures", "reviews": [], "SUBJECTS": "stat.ML cs.AI math.ST stat.TH", "authors": ["pedro a ortega", "jordi grau-moya", "tim genewein", "david balduzzi", "daniel a braun"], "accepted": true, "id": "1206.1898"}, "pdf": {"name": "1206.1898.pdf", "metadata": {"source": "CRF", "title": "A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function", "authors": ["Pedro A. Ortega", "Tim Genewein", "Daniel A. Braun"], "emails": ["pedro.ortega@tuebingen.mpg.de", "jordi.grau@tuebingen.mpg.de", "tim.genewein@tuebingen.mpg.de", "david.balduzzi@tuebingen.mpg.de", "daniel.braun@tuebingen.mpg.de"], "sections": [{"heading": null, "text": "ar X\niv :1\n20 6.\n18 98\nv2 ["}, {"heading": "1 Introduction", "text": "Historically, the fields of statistical inference and stochastic optimization have often developed their own specific methods and approaches. Recently, however, there has been a growing interest in applying inference-based methods to optimization problems and vice versa [1\u20134]. Here we consider stochastic optimization problems where we observe noise-contaminated values from an unknown nonlinear function and we want to find the input that maximizes the expected value of this function.\nThe problem statement is as follows. Let X be a metric space. Consider a stochastic function f : X R mapping a test point x \u2208 X to real values y \u2208 R characterized by the conditional pdf P (y|x). Consider the mean function\nf\u0304(x) := E[y|x] =\n\u222b\nyP (y|x) dy. (1)\nThe goal consists in modeling the optimal test point\nx\u2217 := argmax x {f\u0304(x)}. (2)\nClassic approaches to solve this problem are often based on stochastic approximation methods [5]. Within the context of statistical inference, Bayesian optimization methods have been developed where a prior distribution over the space of functions is assumed and uncertainty is tracked during the entire optimization process [6, 7]. In particular, non-parametric Bayesian approaches such as Gaussian Processes have been applied for derivative-free optimization [8, 9], also within the context of the continuum-armed bandit problem [10]. Typically, these Bayesian approaches aim to explicitly represent the unknown objective function of (1) by entertaining a posterior distribution over the space of objective functions. In contrast, we aim to model directly the distribution of the maximum of (2) conditioned on observations.\nThe paper is structured as follows. Section 2 gives a brief description of the model suitable for direct implementation. The model is then derived in Section 3. Section 4 presents experimental results. Section 4 concludes."}, {"heading": "2 Description of the Model", "text": "Our model is intuitively straightforward and easy to implement1. Let h(x) : X \u2192 R be an estimate of the mean f\u0304(x) constructed from data Dt := {(xi, yi)}ti=1 (Figure 1a, left). This estimate can easily be converted into a posterior pdf over the location of the maximum by first multiplying it with a precision parameter \u03b1 > 0 and then taking the normalized exponential (Figure 1a, right)\nP (x\u2217|Dt) \u221d exp{\u03b1 \u00b7 h(x \u2217)}.\nIn this transformation, the precision parameter \u03b1 controls the certainty we have over our estimate of the maximizing argument: \u03b1 \u2248 0 expresses almost no certainty, while \u03b1 \u2192 \u221e expresses certainty. The rationale for the precision is: the more distinct inputs we test, the higher the precision\u2014testing the same (or similar) inputs only provides local information and therefore should not increase our knowledge about the global maximum. A simple and effective way of implementing this idea is given by\nP (x\u2217|Dt) \u221d exp\n{\n\u03c1 \u00b7\n(\n\u03be + t \u00b7\n\u2211\niK(xi, xi)\u2211 i \u2211 j K(xi, xj)\n)\n\ufe38 \ufe37\ufe37 \ufe38\neffective # of locations\n\u00b7\n\u2211\ni K(xi, x \u2217)yi +K0(x \u2217)y0(x \u2217)\n\u2211\niK(xi, x \u2217) +K0(x\u2217)\n\ufe38 \ufe37\ufe37 \ufe38\nestimate of f\u0304(x\u2217)\n}\n, (3)\nwhere \u03c1, \u03be, K , K0 and y0 are parameters of the estimator: \u03c1 > 0 is the precision we gain for each new distinct observation; \u03be > 0 is the number of prior points; K : X \u00d7 X \u2192 R+ is a finite, symmetric kernel function; K0 : X \u2192 R+ is a prior precision function; and y0 : X \u2192 R is a prior estimate of f\u0304 .\nIn (3), the mean function f\u0304 is estimated with a kernel regressor [11], and the total effective number of locations is calculated as the sum of the prior locations \u03be and the number of distinct locations in the data Dt. The latter is estimated by multiplying the number of data points t with the coefficient\n\u2211\ni K(xi, xi)\u2211 i \u2211 j K(xi, xj) \u2208 (0, 1],\n1Implementations can be downloaded from http://www.adaptiveagents.org/argmaxprior\ni.e. the ratio between the trace of the Gramian matrix (K(xi, xj))i,j and the sum of its entries. Inputs that are very close to each other will have overlapping kernels, resulting in large off-diagonal entries of the Gramian matrix\u2014hence decreasing the number of distinct locations (Figure 1b).\nThe expression for the posterior can be calculated, up to a constant factor, in quadratic time in the number of observations. It can therefore be easily combined with Markov chain Monte Carlo methods (MCMC) to implement stochastic optimizers as illustrated in Section 4."}, {"heading": "3 Derivation of the Model", "text": ""}, {"heading": "3.1 Function-Based, Indirect Model", "text": "Our first task is to derive an indirect Bayesian model for the optimal test point that builds its estimate via the underlying function space. Let G be the set of hypotheses, and assume that each hypothesis g \u2208 G corresponds to a stochastic mapping g : X R. Let P (g) be the prior2 over G and let the likelihood be P ({yt}|g, {xt}) = \u220f t P (yt|g, xt). Then, the posterior of g is given by\nP (g|{yt}, {xt}) = P (g)P ({yt}|g, {xt})\nP ({yt}|{xt}) =\nP (g) \u220f\nt P (yt|g, xt)\nP ({yt}|{xt}) . (4)\nFor each x\u2217 \u2208 X , let G(x\u2217) \u2282 G be the subset of functions such that for all g \u2208 G(x\u2217), x\u2217 = argmaxx{g\u0304(x)} 3. Then, the posterior over the optimal test point x\u2217 is given by\nP (x\u2217|{yt}, {xt}) =\n\u222b\nG(x\u2217)\nP (g|{yt}, {xt}) dg, (5)\nThis model has two important drawbacks: (a) it relies on modeling the entire function space G, which is potentially much more complex than necessary; (b) it requires calculating the integral (5), which is intractable for virtually all real-world problems."}, {"heading": "3.2 Domain-Based, Direct Model", "text": "We want to arrive at a Bayesian model that bypasses the integration step suggested by (5) and directly models the location of optimal test point x\u2217. The following theorem explains how this direct model relates to the previous model.\nTheorem 1. The Bayesian model for the optimal test point x\u2217 is given by\nP (x\u2217) =\n\u222b\nG(x\u2217)\nP (g) dg (prior)\nP (yt|x \u2217, xt,Dt\u22121) =\n\u222b\nG(x\u2217) P (yt|g, xt)P (g) \u220ft\u22121 k=1 P (yk|g, xk) dg\n\u222b G(x\u2217) P (g) \u220ft\u22121 k=1 P (yk|g, xk) dg , (likelihood)\nwhere Dt := {(xk, yk)}tk=1 is the set of past tests.\nProof. Using Bayes\u2019 rule, the posterior distribution P (x\u2217|{yt}, {xt}) can be rewritten as\nP (x\u2217) \u220f\nt P (yt|x \u2217, xt,Dt\u22121)\nP ({yt}|{xt}) . (6)\nSince this posterior is equal to (5), one concludes (using (4)) that\nP (x\u2217) \u220f\nt\nP (yt|x \u2217, xt,Dt\u22121) =\n\u222b\nG(x\u2217)\nP (g) \u220f\nt\nP (yt|g, xt) dg.\nNote that this expression corresponds to the joint P (x\u2217, {yt}|{xt}). The prior P (x\u2217) is obtained by setting t = 0. The likelihood is obtained as the fraction\nP (yt|x \u2217, xt,Dt\u22121) =\nP (x\u2217, {yk} t k=1|{xk} t k=1) P (x\u2217, {yk} t\u22121 k=1|{xk} t\u22121 k=1) ,\n2For the sake of simplicity, we neglect issues of measurability of G. 3Note that we assume that the mean function g\u0304 is bounded and that it has a unique maximizing test point.\nwhere it shall be noted that the denominator P (x\u2217, {yk} t\u22121 k=1|{xk} t\u22121 k=1) doesn\u2019t change if we add the condition xt.\nFrom Theorem 1 it is seen that although the likelihood model P (yt|g, xt) for the indirect model is i.i.d. at each test point, the likelihood model P (yt|x\u2217, xt,Dt\u22121) for the direct model depends on the past tests Dt\u22121, that is, it is adaptive. More critically though, the likelihood function\u2019s internal structure of the direct model corresponds to an integration over function space as well\u2014 thus inheriting all the difficulties of the indirect model."}, {"heading": "3.3 Abstract Properties of the Likelihood Function", "text": "There is a way to bypass modeling the function space explicitly if we make a few additional assumptions. We assume that for any g \u2208 G(x\u2217), the mean function g\u0304 is continuous and has a unique maximum. Then, the crucial insight consists in realizing that the value of the mean function g\u0304 inside a sufficiently small neighborhood of x\u2217 is larger than the value outside of it (see Figure 2a).\nWe assume that, for any \u03b4 > 0 and any z \u2208 X , let B\u03b4(z) denote the open \u03b4-ball centered on z. The functions in G fulfill the following properties:\na. Continuous: Every function g \u2208 G is such that its mean g\u0304 is continuous and bounded.\nb. Maximum: For any x\u2217 \u2208 X , the functions g \u2208 G(x\u2217) are such that for all \u03b4 > 0 and all z /\u2208 B\u03b4(x \u2217), g\u0304(x\u2217) > g\u0304(z).\nFurthermore, we impose a symmetry condition on the likelihood function. Let x\u22171 and x \u2217 2 be in X , and consider their associated equivalence classes G(x\u22171) and G(x \u2217 2). There is no reason for them to be very different: in fact, they should virtually be indistinguishable outside of the neighborhoods of x\u22171 and x \u2217 2. It is only inside of the neighborhood of x \u2217 1 when G(x \u2217 1) becomes distinguishable from the other equivalence classes because the functions in G(x\u22171) systematically predict higher values than the rest. This assumption is illustrated in Figure 2b. In fact, taking the log-likelihood ratio of two competing hypotheses\nlog P (yt|x \u2217 1, xt,Dt\u22121)\nP (yt|x\u22172, xt,Dt\u22121)\nfor a given test location xt should give a value equal to zero unless xt is inside of the vicinity of x\u22171 or x\u22172 (see Figure 2c). In other words, the amount of evidence a hypothesis gets when the test point is outside of its neighborhood is essentially zero (i.e. it is the same as the amount of evidence that most of the other hypotheses get)."}, {"heading": "3.4 Likelihood and Conjugate Prior", "text": "Following our previous discussion, we propose the following likelihood model. Given the previous data Dt\u22121 and a test point xt \u2208 X , the likelihood of the observation yt is\nP (yt|x \u2217, xt,Dt\u22121) =\n1\nZ(xt,Dt\u22121) \u03bb(yt|xt,Dt\u22121) exp\n{ \u03b1t \u00b7 ht(x \u2217)\u2212 \u03b1t\u22121 \u00b7 ht\u22121(x \u2217) } , (7)\nwhere: Z(xt,Dt\u22121) is a normalizing constant; \u03bb(yt|xt,Dt\u22121) is a posterior probability over yt given xt and the data Dt\u22121; \u03b1t is a precision measuring the knowledge we have about the whole function given by\n\u03b10 := \u03c1 \u00b7 \u03be and \u03b1t := \u03c1 \u00b7 ( \u03be +\n\u2211\niK(xi, xi)\u2211 i \u2211 j K(xi, xj)\n)\nwhere \u03c1 > 0 is a precision scaling parameter; \u03be > 0 is a parameter representing the number prior locations tested; and ht is an estimate of the mean function f\u0304 given by\nh0(x \u2217) := y0(x \u2217) and ht(x\u2217) :=\n\u2211t i=1 K(xi, x \u2217)yi +K0(x \u2217)y0(x\n\u2217) \u2211t\ni=1 K(xi, x \u2217) +K0(x\u2217)\n.\nIn the last expression, y0 corresponds to a prior estimate of f\u0304 with prior precision K0. Inspecting (7), we see that the likelihood model favours positive changes to the estimated mean function from new, unseen test locations. The pdf \u03bb(yt|xt,Dt\u22121) does not need to be explicitly defined, as it will later drop out when computing the posterior. The only formal requirement is that it should be independent of the hypothesis x\u2217.\nWe propose the conjugate prior\nP (x\u2217) = 1\nZ0 exp{\u03b10 \u00b7 g0(x\n\u2217)} = 1\nZ0 exp{\u03be \u00b7 y0(x\n\u2217)}. (8)\nThe conjugate prior just encodes a prior estimate of the mean function. In a practical optimization application, it serves the purpose of guiding the exploration of the domain, as locations x\u2217 with high prior value y0(x\u2217) are more likely to contain the maximizing argument.\nGiven a set of data points Dt, the prior (8) and the likelihood (7) lead to a posterior given by\nP (x\u2217|Dt) = P (x\u2217)\n\u220ft k=1 P (yk|x\n\u2217, xk,Dk\u22121) \u222b\nX P (x\u2032) \u220ft k=1 P (yk|x \u2032, xk,Dk\u22121) dx\u2032\n= exp\n{\u2211t k=1 \u03b1k \u00b7 hk(x \u2217)\u2212 \u03b1k\u22121 \u00b7 hk\u22121(x \u2217) } Z\u221210 \u220ft k=1 Z(xk,Dk\u22121) \u22121\n\u222b\nX exp {\u2211t k=1 \u03b1k \u00b7 hk(x \u2032)\u2212 \u03b1k\u22121 \u00b7 hk\u22121(x\u2032) } Z\u221210 \u220ft k=1 Z(xk,Dk\u22121) \u22121 dx\u2032\n= exp\n{ \u03b1t \u00b7 ht(x \u2217) }\n\u222b\nX exp\n{ \u03b1t \u00b7 ht(x\u2032) } dx\u2032\n. (9)\nThus, the particular choice of the likelihood function guarantees an analytically compact posterior expression. In general, the normalizing constant in (9) is intractable, which is why the expression is only practical for relative comparisons of test locations. Substituting the precision \u03b1t and the mean function estimate ht yields\nP (x\u2217|Dt) \u221d exp\n{\n\u03c1 \u00b7\n(\n\u03be + t \u00b7\n\u2211\ni K(xi, xi)\u2211 i \u2211 j K(xi, xj)\n)\n\u00b7\n\u2211\niK(xi, x \u2217)yi +K0(x \u2217)y0(x \u2217)\n\u2211\niK(xi, x \u2217) +K0(x\u2217)\n}\n."}, {"heading": "4 Experimental Results", "text": ""}, {"heading": "4.1 Parameters.", "text": "We have investigated the influence of the parameters on the resulting posterior probability distribution. Figure 3 shows how the choice of the precision \u03c1 and the kernel width \u03c3 affect the shape of the posterior probability density. We have used the Gaussian kernel\nK(x, x\u2217) = exp { \u2212 1\n2\u03c32 (x \u2212 x\u2217)2\n}\n. (10)\nIn this figure, 7 data points are shown, which were drawn as y \u223c N(f(x), 0.3), where the mean function is\nf(x) = cos(2x+ 32\u03c0) + sin(6x+ 3 2\u03c0). (11)\nThe functions K0 and y0 were chosen as\nK0(x) = 1 and y0(x) = \u2212 1\n2\u03c320 (x\u2212 \u00b50)\n2, (12)\nwhere the latter corresponds to the logarithm of a Gaussian with mean \u00b50 = 1.5 and variance \u03c320 = 5. Choosing a higher value for \u03c1 leads to sharper updates, while higher values for the kernel width \u03c3 produce smoother posterior densities."}, {"heading": "4.2 Application to Optimization.", "text": "Comparison to Gaussian Process UCB. We have used the model to optimize the same function (11) as in our preliminary tests but with higher additive noise equal to one. This is done by sampling the next test point xt directly from the posterior density over the optimum location P (x\u2217|Dt), and then using the resulting pair (xt, yt) to recursively update the model. Essentially, this procedure corresponds to Bayesian control rule/Thompson sampling [12, 13].\nWe compared our method against a Gaussian Process optimization method using an upper confidence bound (UCB) criterion [10]. The parameters for the GP-UCB were set to the following values: observation noise \u03c3n = 0.3 and length scale \u2113 = 0.3. For the constant that trades off exploration and exploitation we followed Theorem 1 in [10] which states \u03b2t = 2 log(|D|t2\u03c02/6\u03b4) with \u03b4 = 0.5. We have implemented our proposed method with a Gaussian kernel as in (10) with width \u03c32 = 0.05. The prior sufficient statistics are exactly as in (12). The precision parameter was set to \u03c1 = 0.3.\nSimulation results over ten independent runs are summarized in Figure 4. We show the timeaveraged observation values y of the noisy function evaluated at test locations sampled from the posterior. Qualitatively, both methods show very similar convergence (on average), however our method converges faster and with a slightly higher variance.\nHigh-Dimensional Problem. To test our proposed method on a challenging problem, we have designed a non-convex, high-dimensional noisy function with multiple local optima. This Noisy Ripples function is defined as\nf(x) = \u2212 11000\u2016x\u2212 \u00b5\u2016 2 + cos(23\u03c0\u2016x\u2212 \u00b5\u2016)\nwhere \u00b5 \u2208 X is the location of the global maximum, and where observations have additive Gaussian noise with zero mean and variance 0.1. The advantage of this function is that it generalizes well to any number of dimensions of the domain. Figure 5a illustrates the function for the 2-dimensional input domain. This function is difficult to optimize because it requires averaging the noisy observations and smoothing the ridged landscape in order to detect the underlying quadratic form.\nWe optimized the 50-dimensional version of this function using a Metropolis-Hastings scheme to sample the next test locations from the posterior over the maximizing argument. The Markov chain\nwas started at [20, 20, \u00b7 \u00b7 \u00b7 , 20]T , executing 120 isotropic Gaussian steps of variance 0.07 before the point was used as an actual test location. For the arg-max prior, we used a Gaussian kernel with lengthscale l = 2, precision factor \u03c1 = 1.5, prior precision K0(x\u2217) = 1 and prior mean estimate y0(x\u2217) = \u2212 21000\u2016x+ 5\u2016 2. The goal \u00b5 was located at the origin.\nThe result of one run is presented in Figure 5b. It can be seen that the optimizer manages to quickly (\u2248 100 samples) reach near-optimal performance, overcoming the difficulties associated with the high-dimensionality of the input space and the numerous local optima. Crucial for this success was the choice of a kernel that is wide enough to accurately estimate the mean function. The authors are not aware of any method capable of solving a problem is similar characteristics."}, {"heading": "5 Discussion & Conclusions", "text": "We have proposed a novel Bayesian approach to model the location of the maximizing test point of a noisy, nonlinear function. This has been achieved by directly constructing a probabilistic model over the input space, thereby bypassing having to model the underlying function space\u2014a much harder problem. In particular, we derived a likelihood function that belongs to the exponential family by assuming a form of symmetry in function space. This in turn, enabled us to state a conjugate prior distribution over the optimal test point.\nOur proposed model is computationally very efficient when compared to Gaussian process-based (cubic) or UCB-based models (expensive computation of argmax). The evaluation time of the posterior density scales quadratically in the size of the data. This is due to the calculation of the effective number of previously seen test locations\u2014the kernel regressor requires linear compuation time. However, during MCMC steps, the effective number of test locations does not need to be updated as long as no new observations arrive.\nIn practice, one of the main difficulties associated with our proposed method is the choice of the parameters. As in any kernel-based estimation method, choosing the appropriate kernel bandwidth can significantly change the estimate and affect the performance of optimizers that rely on the model. There is no clear rule on how to choose a good bandwidth.\nIn a future research, it will be interesting to investigate the theoretical properties of the proposed nonparametric model, such as the convergence speed of the estimator and its relation to the extensive literature on active learning and bandits."}], "references": [{"title": "A tutorial on bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning", "author": ["E. Brochu", "V. Cora", "N. de Freitas"], "venue": "Technical Report TR-2009-023,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Approximate inference and stochastic optimal control", "author": ["K. Rawlik", "M. Toussaint", "S. Vijayakumar"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Probabilistic Constrained Optimization: Methodology and Applications, chapter Statistical Inference of Stochastic Optimization Problems, pages 282\u2013304", "author": ["A. Shapiro"], "venue": "Kluwer Academic Publishers,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2000}, {"title": "Optimal control as a graphical model inference problem", "author": ["H.J. Kappen", "V. G\u00f3mez", "M. Opper"], "venue": "Machine Learning,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Stochastic Approximation Algorithms and Applications", "author": ["H.J. Kushner", "G.G. Yin"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1997}, {"title": "Application of bayesian approach to numerical methods of global and stochastic optimization", "author": ["J. Mockus"], "venue": "Journal of Global Optimization,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1994}, {"title": "Practical Bayesian Optimization", "author": ["D. Lizotte"], "venue": "Phd thesis, University of Alberta,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2008}, {"title": "Efficient global optimization of expensive blackbox functions", "author": ["D.R. Jones", "M. Schonlau", "W.J. Welch"], "venue": "Journal of Global Optimization,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1998}, {"title": "Gaussian processes for global optimization", "author": ["M.A. Osborne", "R. Garnett", "S.J. Roberts"], "venue": "In 3rd International Conference on Learning and Intelligent Optimization", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Gaussian process optimization in the bandit setting: No regret and experimental design", "author": ["N. Srinivas", "A. Krause", "S. Kakade", "M. Seeger"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "The Elements of Statistical Learning", "author": ["T. Hastie", "R. Tbshirani", "J. Friedman"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "Simulation studies in optimistic Bayesian sampling in contextualbandit problems", "author": ["B.C. May", "D.S. Leslie"], "venue": "Technical Report 11:02,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "A minimum relative entropy principle for learning and acting", "author": ["P.A. Ortega", "D.A. Braun"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "Recently, however, there has been a growing interest in applying inference-based methods to optimization problems and vice versa [1\u20134].", "startOffset": 129, "endOffset": 134}, {"referenceID": 1, "context": "Recently, however, there has been a growing interest in applying inference-based methods to optimization problems and vice versa [1\u20134].", "startOffset": 129, "endOffset": 134}, {"referenceID": 2, "context": "Recently, however, there has been a growing interest in applying inference-based methods to optimization problems and vice versa [1\u20134].", "startOffset": 129, "endOffset": 134}, {"referenceID": 3, "context": "Recently, however, there has been a growing interest in applying inference-based methods to optimization problems and vice versa [1\u20134].", "startOffset": 129, "endOffset": 134}, {"referenceID": 4, "context": "Classic approaches to solve this problem are often based on stochastic approximation methods [5].", "startOffset": 93, "endOffset": 96}, {"referenceID": 5, "context": "Within the context of statistical inference, Bayesian optimization methods have been developed where a prior distribution over the space of functions is assumed and uncertainty is tracked during the entire optimization process [6, 7].", "startOffset": 227, "endOffset": 233}, {"referenceID": 6, "context": "Within the context of statistical inference, Bayesian optimization methods have been developed where a prior distribution over the space of functions is assumed and uncertainty is tracked during the entire optimization process [6, 7].", "startOffset": 227, "endOffset": 233}, {"referenceID": 7, "context": "In particular, non-parametric Bayesian approaches such as Gaussian Processes have been applied for derivative-free optimization [8, 9], also within the context of the continuum-armed bandit problem [10].", "startOffset": 128, "endOffset": 134}, {"referenceID": 8, "context": "In particular, non-parametric Bayesian approaches such as Gaussian Processes have been applied for derivative-free optimization [8, 9], also within the context of the continuum-armed bandit problem [10].", "startOffset": 128, "endOffset": 134}, {"referenceID": 9, "context": "In particular, non-parametric Bayesian approaches such as Gaussian Processes have been applied for derivative-free optimization [8, 9], also within the context of the continuum-armed bandit problem [10].", "startOffset": 198, "endOffset": 202}, {"referenceID": 10, "context": "In (3), the mean function f\u0304 is estimated with a kernel regressor [11], and the total effective number of locations is calculated as the sum of the prior locations \u03be and the number of distinct locations in the data Dt.", "startOffset": 66, "endOffset": 70}, {"referenceID": 11, "context": "Essentially, this procedure corresponds to Bayesian control rule/Thompson sampling [12, 13].", "startOffset": 83, "endOffset": 91}, {"referenceID": 12, "context": "Essentially, this procedure corresponds to Bayesian control rule/Thompson sampling [12, 13].", "startOffset": 83, "endOffset": 91}, {"referenceID": 9, "context": "We compared our method against a Gaussian Process optimization method using an upper confidence bound (UCB) criterion [10].", "startOffset": 118, "endOffset": 122}, {"referenceID": 9, "context": "For the constant that trades off exploration and exploitation we followed Theorem 1 in [10] which states \u03b2t = 2 log(|D|t\u03c0/6\u03b4) with \u03b4 = 0.", "startOffset": 87, "endOffset": 91}], "year": 2012, "abstractText": "We propose a novel Bayesian approach to solve stochastic optimization problems that involve fnding extrema of noisy, nonlinear functions. Previous work has focused on representing possible functions explicitly, which leads to a two-step procedure of first, doing inference over the function space and second, finding the extrema of these functions. Here we skip the representation step and directly model the distribution over extrema. To this end, we devise a non-parametric conjugate prior based on a kernel regressor. The resulting posterior distribution directly captures the uncertainty over the maximum of the unknown function. We illustrate the effectiveness of our model by optimizing a noisy, high-dimensional, non-convex objective function.", "creator": "LaTeX with hyperref package"}}}