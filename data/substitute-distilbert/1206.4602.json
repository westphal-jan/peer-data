{"id": "1206.4602", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2012", "title": "Quasi-Newton Methods: A New Direction", "abstract": "four decades after their invention, quasi - newton methods are still state of the art in unconstrained arithmetic optimization. although not usually interpreted thus, these are learning artifacts that fit a local quadratic approximation satisfying the objective function. we show that many, including the most known, quasi - newton methods can be scaled than approximations generating bayesian linear regression under varying prior considerations. this new notion elucidates some shortcomings of classical algorithms, and lights the way to a novel nonparametric quasi - newton method, which is able to make more efficient use of simpler information at computational cost similar though its requirements.", "histories": [["v1", "Mon, 18 Jun 2012 14:41:11 GMT  (475kb)", "http://arxiv.org/abs/1206.4602v1", "ICML2012"]], "COMMENTS": "ICML2012", "reviews": [], "SUBJECTS": "cs.NA cs.LG stat.ML", "authors": ["philipp hennig", "martin kiefel"], "accepted": true, "id": "1206.4602"}, "pdf": {"name": "1206.4602.pdf", "metadata": {"source": "META", "title": "Quasi-Newton Methods: A New Direction", "authors": ["Philipp Hennig", "Martin Kiefel"], "emails": ["philipp.hennig@tuebingen.mpg.de", "martin.kiefel@tuebingen.mpg.de"], "sections": [{"heading": "1. Introduction", "text": "Quasi-Newton algorithms are arguably the most popular class of nonlinear numerical optimization methods, used widely in numerical applications not just in machine learning. Their defining property is that they iteratively build estimators Bi for the Hessian B(x) = \u2207\u2207\u22baf(x) of the objective function f(x), from observations of f \u2019s gradient \u2207f(x), at each iteration searching for a local minimum along a line search direction \u2212B\u22121i \u2207f(x), an estimate of the eponymous Newton-Raphson search direction. Some of the most widely known members of this family include Broyden\u2019s (1965) method, the SR1 formula (Davidon, 1959; Broyden, 1967), the DFP method (Davidon, 1959; Fletcher & Powell, 1963) and the BFGS method (Broyden, 1969; Fletcher, 1970; Goldfarb, 1970; Shanno, 1970). Decades of continued research effort in this area make it impossible to give even a superficial overview over the available literature. The textbooks by No-\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\ncedal & Wright (1999) and Boyd & Vandenberghe (2004) are good modern starting points for readers interested in background. An insightful and extensive contemporary review was compiled by Dennis & More\u0301e (1977). The ubiquity of optimization problems in machine learning has made these algorithms tools of the trade. But, perhaps because they predate machine learning itself, they have rarely been studied as learning algorithms in their own right. This paper offers a probabilistic analysis. Throughout, let f \u2236 RN _ R be a sufficiently regular, not necessarily convex, function; \u2207f \u2236 RN _ RN its gradient; B \u2236 RN _ RN\u00d7N its Hessian. We consider iterative algorithms moving from location x`\u22121 \u2208 RD to location x`. The algorithm performs consecutive line searches along one-dimensional subspaces xi(\u03b1) = \u03b1ei +x0i , with \u03b1 \u2208 R+ and a unit length vector ei \u2208 RN spanning the line search space starting at x0i . Evaluations at xi evince the gradient \u2207f(xi) (and usually also f(xi), though this will not feature in this paper). The goal is to find a candidate x\u2217 for a local minimum: a root \u2207f(x\u2217) = 0 of the gradient. The derivations of classical quasi-Newton algorithms proceed along the following line of argument: We require an update rule incorporating an observation\u2207f(xi+1) into a current estimate B\u0302i to get a new estimate B\u0302i+1, subject to the following desiderata: Low Rank/Cost Updates Optimization problems\nregularly have dimensionality above N \u223c 103, even beyond N \u223c 106. So the update should be of low rank M (usually M = 1 or 2), because, by Schur\u2019s lemma, it has (worst-case) costO(N2+NM+M3).\nConsistency with Quadratic Model If f is locally described well to second order, then\nyi \u2261 \u2207f(xi) \u2212\u2207f(xi\u22121) \u2248 B(xi)si, (1) with si \u2261 xi \u2212 xi\u22121. Because this is the fundamental idea behind this family of algorithms, it is also known as the quasi-Newton equation (Dennis & More\u0301e, 1977).\nSymmetry The Hessian of twice differentiable functions is symmetric; so its estimator should be, too.\nPositive Definiteness Convex functions have positive definite Hessians everywhere. Over time, it has become common conviction that, even for non-convex problems, positive definiteness of the estimator is desirable.\nThis paper\u2019s contributions are twofold: Section 2 offers a probabilistic viewpoint on classical quasi-Newton methods, in the process showing that symmetry is only achieved in a partial, definiteness in only a weak way by the classical algorithms. In Section 3 we use these insights to construct a novel nonparametric Bayesian quasi-Newton algorithm; this addresses several shortcomings of classic algorithms, and increases performance at only mildly higher cost. We will write \u00d0\u21c0 X to indicate an n\u00d7m matrix X stacked row-wise into a vector of length nm. Its elements can be enumerated by an index set (ij) \u2208 [1, n] \u00d7 [1,m]. The symbol \u2297 denotes the Kronecker product: (a \u2297 b)(ij)(k`) = aikbj`. It allows a compact notation for vectorised matrices: \u00d0\u00d0\u00d0\u21c0 XY Z = (X \u2297 Z\u22ba)\u00d0\u21c0Y . If A and B have size I \u00d7J and K \u00d7L, respectively, then A\u2297B has size IK \u00d7 JL, and lim\u03b3_0(Y \u2297 \u03b3Z) =\u00d0\u21c00 for any fixed, finite Y and Z."}, {"heading": "2. Quasi-Newton Methods as approximate Bayesian Regressors", "text": "From a probabilistic perspective, Equation (1) is a likelihood for B. Using si = xi\u2212xi\u22121, we can write it using Dirac\u2019s distribution\np(yi \u2223B,si) = \u03b4(yi \u2212Bsi) = lim \u03b2_0 N [yi;S\u22bai \u00d0\u21c0B,Vi\u22121 \u2297 \u03b2] (2) with any arbitrary N \u00d7N matrix Vi\u22121, a scalar \u03b2, and the linear operator Si = (I \u2297 si). Of course, the N real numbers in yi are not sufficient to identify the N2 numbers in B. Classical derivations (Dennis & More\u0301e, 1977; Nocedal & Wright, 1999) thus introduce a regularizer based on the weighted Frobenius norm around the current best estimate Bi\u22121 from previous iterations. The weight in the Frobenius norm is encoded using a positive definite matrix, which we will suggestively call V \u22121i\u22121 and, without loss of generality, identify with the Vi\u22121 of Eq. (2)\n\u2225B\u2212Bi\u22121\u2225F,V \u22121i\u22121 \u2261 tr(V \u22121i\u22121(B\u2212Bi\u22121)\u22baV \u22121i\u22121(B\u2212Bi\u22121))= (\u00d0\u21c0B \u2212\u00d0\u21c0B i\u22121)\u22ba(V \u22121i\u22121 \u2297 V \u22121i\u22121)(\u00d0\u21c0B \u2212\u00d0\u21c0B i\u22121). (3) The new estimate is the unique matrix Bi minimizing the regularizer subject to Eq. (2). Inspecting Eq. (3)\nwe see that, up to isomorphisms, the Frobenius regularizer is the negative logarithm of a Gaussian prior p(B) = N [\u00d0\u21c0B ;\u00d0\u21c0B i\u22121,\u03a3i\u22121 \u2261 (Vi\u22121 \u2297 Vi\u22121)] . (4) Gaussian likelihoods are conjugate to Gaussian priors. So the posterior is Gaussian, too, even for the limit case of a Dirac likelihood. A few lines of algebra1 show that the posterior has mean and covariance\nBi = Bi\u22121 + (yi \u2212Bi\u22121si)s\u22bai Vi\u22121 s\u22bai Vi\u22121si and (5) \u03a3i = Vi\u22121 \u2297 (Vi\u22121 \u2212 Vi\u22121sis\u22bai Vi\u22121 s\u22bai Vi\u22121si ) \u2261 Vi\u22121 \u2297 Vi, (6)\nrespectively. The new mean is a rank-1 update of the old mean, and the rank of the new covariance \u03a3i is one less than that of \u03a3i\u22121. The posterior mean has maximum posterior probability (minimal regularized loss), and is thus our new point estimate. Choosing a unit variance prior \u03a3i\u22121 = I \u2297 I recovers one of the oldest quasi-Newton algorithms: Broyden\u2019s method (1965):\nBi = Bi\u22121 + (yi \u2212Bi\u22121si)s\u22bai s\u22bai si (7)\nBroyden\u2019s method does not satisfy the third requirement of Section 1: the updated estimate is, in general, not a symmetric matrix. A supposed remedy for this problem, and in fact the only rank-1 update rule that obeys Eq. (2) (Dennis & More\u0301e, 1977) is the symmetric rank 1 (SR1) method (Davidon, 1959; Broyden, 1967):\nBi = Bi\u22121 + (yi \u2212Bi\u22121si)(yi \u2212Bi\u22121si)\u22ba s\u22bai (yi \u2212Bi\u22121si) . (8)\nThe SR1 update rule has acquired a controversial reputation (e.g. Nocedal & Wright, 1999, \u00a76.2): While some authors report good successes with this method, others note that it is unstable and overly limited. Our Bayesian interpretation adds to the doubts about the SR1 formula, since it identifies it as Gaussian regression with a prior variance involving Vi\u22121 with Vi\u22121si = (yi \u2212Bi\u22121si), (9) a data-dependent prior covariance. Given the prior (4), there is no rank 1 update rule that gives a symmetric posterior. This blemish of rank-1 updates is also reflected in Eq. (6): Uncertainty drops only in the \u201crow\u201d, or \u201cprimal\u201d subspace of the belief (the right hand side of the Kronecker product in the covariance). While this still means uncertainty goes toward 0 over time, it does so in an asymmetric way.\n1Here and later, detailed derivations are left out due to space constraints. They can be found in an upcoming journal version of this paper, currently under review."}, {"heading": "2.1. Symmetric Estimates, but no Symmetric Beliefs", "text": "The proper probabilistic way to encode Hessians\u2019 symmetry is to include an additional likelihood term\n\u03b4(\u2206\u00d0\u21c0B \u2212\u00d0\u21c00 ) = lim \u03c4_0 N (\u00d0\u21c00 ,\u2206\u00d0\u21c0B, \u03c4I) (10)\nusing \u2206, the antisymmetry operator \u2013 the linear map defined through\n\u2206 \u00d0\u21c0 X = 1\n2 \u00d0\u00d0\u00d0\u00d0\u00d0\u00d0\u21c0(X \u2212X\u22ba). (11) Since this is a linear map, the resulting posterior is analytic, and Gaussian. But the rank of \u2206 is 1/2 \u22c5 N(N \u2212 1) (e.g. Lu\u0308tkepohl, 1996, \u00a74.3.1, Eqs. 12 & 20), so the corresponding update rule does not obey the first requirement of Section 1. However, the structure of Eq. (6) hints at another idea, which in fact turns out to give rise to the most popular quasiNewton methods. We introduce a second, dual observation (dual, as in \u201cdual vector space\u201d, not as in \u201cprimal-dual optimization\u201d).\np(y\u22bai \u2223B,s\u22bai ) = \u03b4(y\u22bai \u2212 s\u22baiB) = lim \u03b3_0 N [y\u22bai ;s\u22bai\u00d0\u21c0B,\u03b3 \u2297 Vi] . (12)\nThe posterior after both primal and dual observation is a Gaussian with mean and covariance Bi = Bi\u22121 + (yi \u2212Bi\u22121si)s\u22bai V \u22bai\u22121 s\u22bai Vi\u22121si + Vi\u22121si(yi \u2212Bi\u22121si)\u22ba s\u22bai Vi\u22121si \u2212 Vi\u22121si(s\u22bai (yi \u2212Bi\u22121si))s\u22bai Vi\u22121(s\u22bai Vi\u22121si)2 (13) \u03a3i = (Vi\u22121 \u2212 Vi\u22121sis\u22bai Vi\u22121\ns\u22bai Vi\u22121si )\u2297 Vi = Vi \u2297 Vi. (14) The posterior mean is clearly symmetric if Bi\u22121 is symmetric (as Vi\u22121 is symmetric by definition). Choosing the unit prior \u03a3i\u22121 = I \u2297 I once more, Eq. (13) gives what is known as Powell\u2019s (1970) symmetric Broyden (PSB) update. Eq. (13) has previously been known to be the most general form of a symmetric rank 2 update obeying the quasi-Newton equation and minimizing a Frobenius regularizer (Dennis & More\u0301e, 1977). This old result is a corollary of our derivations. But note that symmetry only extends to the mean, not the entire belief: In contrast to the posterior generated by Eq. (10), samples from this posterior are, with probability 1, not symmetric. Of course, they can be projected into the space of symmetric matrices by applying the symmetrization operator \u0393 defined by\n\u0393 \u00d0\u21c0 X = 1\n2 \u00d0\u00d0\u00d0\u00d0\u00d0\u00d0\u21c0(X +X\u22ba) (note that I = \u0393 +\u2206; \u0393\u2206 = 0). (15)\nSince \u0393 is a symmetric linear operator, the projection of any Gaussian belief N (X;X0,\u03a3) onto the space of symmetric matrices is itself a GaussianN (\u0393X; \u0393X0,\u0393\u03a3\u0393). But symmetrized samples from the posterior of Eqs. (13) & (14) do not necessarily obey the quasi-Newton Equation (2). While Eq. (12) does convey useful information, it is not equivalent to encoding symmetry. It is cheaper, but also weaker, than using the correct likelihood (10)."}, {"heading": "2.2. Positive Definiteness: Meaning or Decoration?", "text": "Consider choosing Vi\u22121 = B. The prior is then p(B)\u221d \u2223B\u2223\u2212N2/2 \u22c5exp [\u22121 2 (N \u2212 2 tr(Bi\u22121B\u22121) + tr(Bi\u22121B\u22121Bi\u22121B\u22121))] . (16)\nThis is an intriguing prior. Although there is some semblance to the Wishart distribution, the second term in the exponential means this prior is broader than the Wishart. It is not well-defined for degenerate matrices, and it is not clear whether it is proper. It is thus surprising to discover that it engenders the two most popular quasi-Newton methods: If we use the quasi-Newton equation (2) a second time to replace Vi\u22121s = y, Eq. (16) gives the DFP method (Davidon, 1959; Fletcher & Powell, 1963)\nBi = Bi\u22121 + (yi \u2212Bi\u22121si)y\u22bai s\u22bai yi + yi(yi \u2212Bi\u22121si)\u22ba y\u22bai si\n\u2212 yi(s\u22bai (yi \u2212Bi\u22121si))y\u22bai(y\u22bai si)2 . (17) And, if we exchange in the entire preceding derivation s ] y, B ] B\u22121, Bi\u22121 ] B\u22121i\u22121, then we arrive at the BFGS method (Broyden, 1969; Fletcher, 1970; Goldfarb, 1970; Shanno, 1970), which ranks among the most widely used algorithms in machine learning overall. DFP and BFGS owe much of their popularity to the fact that the updated Bi,DFP and B \u22121 i,BFGS are guaranteed to be positive definite whenever Bi\u22121,DFP and B\u22121i\u22121,BFGS are positive definite, respectively, and additionally y\u22bai si > 0. How helpful is this property? It is relatively straightforward to extend a theorem by Dennis & More\u0301e (1977) to find that, assuming Bi\u22121 is positive definite, the posterior mean of Eq. (13) is positive definite if, and only if,\n0 < (y\u22baiB\u22121i\u22121Vi\u22121si)2+ (yi \u2212Bi\u22121si)\u22baB\u22121i\u22121yi \u22c5 s\u22bai Vi\u22121B\u22121i\u22121Vi\u22121si= s\u22bai Vi\u22121[B\u22121i\u22121yiy\u22baiB\u22121i\u22121 \u2212 y\u22baB\u22121i\u22121yi + s\u22bai yi]Vi\u22121si. (18)\nIf the prior covariance is not to depend on the data, it is thus impossible to guarantee positive definiteness in this framework \u2013 BFGS and DFP circumvent this conceptual issue by choosing Vi\u22121 = B, then applying Eq. (2) a second time. But, even casting aside such philosophical reservations, our analysis also casts doubt upon the efficacy of the way in which DFP and BFGS achieve positive definiteness: Eq. (16) does not exclude indefinite matrices; in fact it assigns positive measure to every invertible matrix. For example, under a mean Bi\u22121 = I, the indefinite matrix B = diag(1,\u22121) is assigned p(B) \u221d exp(\u22122). DFP and BFGS achieve positive definiteness, not by including additional information, but by manipulating the prior such that, as if by accident, the MAP estimator (not the belief) happens to be positive definite. These observations do not rule out any utility of guaranteeing positive definiteness in this way. But there is less value in the positive definiteness guarantee of DFP and BFGS than previously thought. The algorithm should aim to find the \u201cbest\u201d positive definite explanation for the data, not \u201cany\u201d such explanation."}, {"heading": "2.3. Rank M Updates", "text": "The classical quasi-Newton algorithms update the mean of the belief at every step in a rank 2 operation, then, implicitly, reset their uncertainty in the next step, thereby discarding information acquired earlier. Albeit inelegant from a Bayesian point of view, this scheme is still a good idea given other aspects of the framework: Since the quasi-Newton likelihood models the objective function as a quadratic, model mismatch would lead to strong overfitting under exact Bayesian inference. But it is instructive to consider the effect of encoding more than just the most recent observation. It is straightforward to extend Eq. (2) to observations(Y,S) from several line searches:\nYnm = \u2207nf(xim) \u2212\u2207nf(xim\u22121) Snm = xim,n \u2212 xim\u22121,n (19)\nGiven a prior p(B) = N (B;B0, V0), the Gaussian posterior then has mean and covariance\nBi = B0 + (Y \u2212B0S)(S\u22baV0S)\u22121S\u22baV0 (20)+ V0S(S\u22baV0S)\u22121(Y \u2212B0S)\u22ba\u2212 V S(S\u22baV0S)\u22121(S\u22ba(Y \u2212B0S))(S\u22baV S)\u22121S\u22baV0 \u03a3i = (V0 \u2212 V0S(S\u22baV0S)\u22121S\u22baV0) (21)\u2297 (V0 \u2212 V0S(S\u22baV0S)\u22121S\u22baV0) .\nHere, the absence of information about the symmetry of the Hessian becomes even more obvious: No matter the prior covariance V0, because of the term S \u22baY in\nthe third line of Eq. (20), the posterior mean is not in general symmetric, unless Y = BS, (e.g. if the objective function is in fact a quadratic)."}, {"heading": "2.4. Summary", "text": "The preceding section showed that quasi-Newton algorithms, including the state-of-the-art BFGS and DFP algorithms, can be interpreted as approximate Bayesian regression from the primal and dual likelihood of Eqs. (2) and (12) under varying priors, in the following sense: At each quasi-Newton step, fix a Gaussian prior ad hoc, update the mean, then \u201cforget\u201d the covariance update. Two particularly interesting observations concern the way in which the desiderata of symmetry and positive definiteness of the MAP estimator are achieved in these algorithms. Symmetry is encoded via dual observations, which is a useful but imperfect shortcut. Positive definiteness is achieved not by encoding relevant information, but by shifting the prior post hoc. It is thus doubtable whether the proven good performance of BFGS and DFP is actually down to positive definiteness, instead of a simpler effect of moving from the clearly pathological formulation of Broyden\u2019s method to dual observations and a less restrictive (though nontrivial) prior."}, {"heading": "3. A Nonparametric Bayesian Quasi-Newton Method", "text": "Section 2 used the probabilistic perspective to gain novel insight into classical methods. In this second part of the paper we depart from the traditional framework to construct a nonparametric, Bayesian quasiNewton method, de novo. To motivate this effort, notice some further deficiencies of DFP/BFGS regarding use of available information: Eq. (2) assumes that the function is (locally) a quadratic. Old observations collected \u201cfar\u201d from the current location (in the sense that a second order expansion is a poor approximation) may thus be useless or even harmful. The fact that the function is not quadratic should be part of the model. On an only slightly related point, individual line searches typically involve several evaluations of the objective function f and its gradient; but the algorithms only make use of one of those (the last one). This is clearly wasteful, but even the exact Bayesian parametric algorithm of Section 2.3 has this problem: Because a matrix S of several observations along one line search has rank 1, the inverse of S\u22baV0S is not defined. The following section will address all these issues. Several aspects of the resulting algorithm are involved. Derivations can be found in the journal version. A matlab implementation can be\nfound at www.probabilistic-optimization.org."}, {"heading": "3.1. A Nonparametric Prior", "text": "Defining a prior for the function B \u2236 RN _ RN\u00d7N , we choose a set of N2 correlated Gaussian processes. The mean function is assumed to be an arbitrary integrable function B0(x) (in our implementation we use a constant function, but the analytic derivations do not need to be so restrictive). The core idea is to assume that the covariance between the element Bij at location x\u00be and the entry Bk` at location x\u00bc is\ncov (Bij(x\u00be),Bk`(x\u00bc)) = kik(x\u22ba\u00be, x\u22ba\u00bc)kj`(x\u00be, x\u00bc)= (k \u2297 k)(ij)(k`)(x\u00be, x\u00bc) (22) with an N \u00d7N matrix of kernels, k. To give a more concrete intuition: In our implementation we use one joint squared exponential kernel for all elements. I.e.\nkij(x\u00be, x\u00bc) = Vij exp(\u22121 2 (x\u00be \u2212 x\u00bc)\u22ba\u039b\u22121(x\u00be, x\u00bc))\n(23) with a positive definite matrix V and length scales \u039b. Other kernels can of course be chosen; but it will become clear that an important practical requirement is the ability to efficiently integrate the kernel. This is feasible, though nontrivial, with the squared exponential kernel. Another option, not yet explored by us, may be offered by spline kernels (Minka, 2000)."}, {"heading": "3.2. Line Integral Observations", "text": "For the Hessian B(x) of a general function f , the quasi-Newton equation (2) is only a zeroth order approximation (a second-order approximation to f itself), assuming a constant Hessian everywhere. In our treatment, we will replace it with the exact statement: We observe the value of the line integral along the path ri \u2236 [0,1] _ RN , ri(t) = xi\u22121 + t(xi \u2212 xi\u22121). Yni =\u2211\nm \u222b rim Bnm(x) dxm =\u2211 m Smi \u222b 1 0 Bnm(ri(t)) dt.\n(24) This uses the classic result that line integrals over scalar fields, such as B(x), are fully defined by the path\u2019s start and end point, irrespective of the path itself. Hence, the nonparametric version of the quasiNewton equation is the likelihood\np(Y \u2223B(x),S) = lim \u03b2_0 N [Y ;S\u22ba\u00d0\u21c0B,k \u2297 \u03b2IM] (25) with a linear operator (\u2299 denotes the Hadamard, or element-wise product (a\u2299 b)k` = ak`bk`)\nS = I \u2297 (\u222b 1 0 dt\u2299 S) . (26)"}, {"heading": "3.3. Gaussian Process Inference from Integral Observations", "text": "Because the Gaussian exponential family is closed under linear transformations, Gaussian process inference is analytic under any linear operator. Since integration is a linear operation, Gaussian process inference is possible, in closed form, from integral observations. Nevertheless, this idea has only rarely been used in the literature (e.g. by Minka, 2000). Figure 1 gives a 1D toy example for intuition.\nThe posterior distribution under our nonparametric prior, the likelihood of Eq. (25) and its dual equivalent is a Gaussian process with mean and covariance functions\nB\u25c7(x\u00be) = B0(x\u00be) + (Y \u2212B0)K\u22121k\u22ba(x\u00be)+ k(x\u00be)K\u22121(Y \u2212B0)\u22ba (27)\u2212 k(x\u00be)K\u22121S\u22ba(Y \u2212B0)K\u22121k\u22ba(x\u00be) \u03a3\u25c7(x\u00be, x\u00bc) = [k(x\u22ba\u00be, x\u22ba\u00bc) \u2212 k(x\u22ba\u00be)K\u22121k\u22ba(x\u00bc)] (28)\u2297 [k(x\u00be, x\u00bc) \u2212 k(x\u00be)K\u22121k\u22ba(x\u00bc)] .\nThis uses B0 \u2208 RN\u00d7M , the function k \u2236 R _ RN\u00d7M and\nthe Gram matrix K \u2208 RM\u00d7M , defined by B0,nm = \u2211\u0300S`m \u222b 1\n0 B0,n`(r`(t)) dt\nknm(x\u00be) = \u2211\u0300S`m \u222b 1 0 k(x\u00be, r`(t)) dt\nKpq = \u2211\u0300 ,j S`pSjq\u222c 1 0 k(r`(t), rj(t\u2032)) dt dt\u2032.\n(29)\nThese objects are homologous to concepts in canonical Gaussian process inference: B0,nm is the n-th mean prediction along the m-th line integral observation. knm(x\u00be) is the covariance between the n-th column of the Hessian at location x\u00be and the m-th line-integral observation. Kpq is the covariance between the p-th and q-th line integral observations. An important aspect is that, because k is a positive definite kernel, unless two observations are exactly identical, K has full rank M (the number of function evaluations), even if several observations take place within one shared 1- dimensional subspace. So it is possible to make full use of all function evaluations made during line searches, not just the first and last one, as in the classical setting. A downside is that evaluating the mean function involves finding the inverse of K, at cost O(M3). Two aspects of numerical optimization make this issue less problematic than one might think. First, solving an optimization problem takes finite time, often just a few hundred evaluations; so the cubic cost in M is often manageable. Where it is not, note that, because optimization proceeds along a trajectory through the parameter space, old observations tend to have low covariance with the Hessian at the current location, and thus a small effect on the local mean estimate (the effect of this influence is measured by kK\u22121). So they can often simply be ignored."}, {"heading": "3.4. Numerical Implementation", "text": "As mentioned above, for a concrete implementation, we chose to use the squared exponential kernel (23), and a constant mean function assigning B0(x\u00be) = I everywhere. It is another advantage of the Bayesian formulation that prior assumptions are easy to analyze and understand: The squared exponential prior amounts to the assumption that the elements of the Hessian vary independently over the parameter space, on one unique set of length-scales \u039b. Multiple length scales could be modeled using sums of kernels, but our implementation does not currently offer this option.\nChanging the length scales \u039b amounts to automatic pre-conditioning, another benefit of a Bayesian formulation that we cannot dwell on for space reasons. Hyperparameters could be fitted by type-II maximum\nlikelihood, as in canonical Gaussian process regression. Unfortunately, this is an optimization problem itself. Another option is to instead fix the hyperparameters ad hoc by tracking the signal variance to fix V in Eq. (23) and the relative change along line searches to fix \u039b.\nImplementing the integrals of Eq. (29) for the squaredexponential kernel, particularly those in K, is nontrivial, because definite integrals over Gaussians are not analytic. k involves the error function, for which good double-precision approximations are widely available. The integrals in K are of two distinct types: The covariance between observations made as part of the same line search involve 1D integrals of the error function, which can be analytically reduced to the error and exponential functions2. The covariance between observations made during different line searches are bivariate Gaussian integrals. Fortunately, good, lightweight numerical approximations are available for this problem (Genz, 2004).\nFrom Sec. 1, recall that updating the search direction requires the inverse of B. Explicit inversion costsO(N3), but the inverse can be constructed analytically, from the matrix inversion lemma, in O(N2 + NM + M3). Using a diagonal prior mean B0 and an argument largely analogous to the derivation of the L-BFGS algorithm (Nocedal, 1980) lowers cost to O(NM +M3), linear in N . The nonparametric method is thus applicable to problems of even very high dimensionality.\n2Jaakko Peltonen, 2011, personal communication"}, {"heading": "4. Experiments", "text": "Figure 2 shows averages of experiments on a 200- dimensional domain. The objective functions were the logarithms of products of Gamma distributions with different parameters for each dimension (a simplified version of hyperparameter learning for Gaussian process regression). In this experiment, the nonparametric algorithm outperforms its predecessors strongly. The performance advantage is not always so drastic (the journal version contains additional empirical results, including less pronounced cases). Despite the relatively precise numerical treatment of the integrals involved, the nonparametric Bayesian quasi-Newton algorithm poses more numerical challenges than its predecessors. This issue becomes clear when minimizing quadratic functions, whose constant Hessian voids the modelling advantage of the nonparametric method: The Bayesian algorithm behaves more regularly initially, but towards the end of the optimization process the numerical conditioning of the Bayesian algorithms begins to play a role, offering an advantage to the better conditioned older methods. At this small scale, however, the Hessian is essentially constant, and\nthe function is well described by a local model. In our practical implementation, we check for convergence, then pass the learned inverse Hessian to the better conditioned BFGS for the final few steps.\nAn additional benefit of the nonparametric formulation is the availability of a global estimate of the Hessian function. Figure 3 illustrates this point with results from a popular two-dimensional test problem \u2013 Rosenbrock\u2019s polynomial (details in caption). This figure is mostly for intuition: Rosenbrock\u2019s valley is challenging even for the exact Newton method since it breaks the line search paradigm, so the similarity between the methods on this problem is not particularly indicative of general performance.\nCost As pointed out above, the computational complexity of this algorithm, given a diagonal prior mean, is O(NM +M3) per update of the search direction, where M is the number of function evaluations used to build the model (which can be controlled ad hoc within the algorithm by excluding redundant or irrelevant evaluations). This compares to O(NM) for the corresponding cases of DFP and BFGS. Although the\noverhead created by the squared-exponential integrals is nontrivial, we found the computational demands of our implementation manageable: In our experiments, the cost of constructing and inverting the matrix K was negligible, and could, in very time-sensitive settings, be further reduced by a more efficient implementation."}, {"heading": "5. Outlook", "text": "Owing to the limitations of a conference publication, we have only outlined many of our core results. To give an intuition for the potential of probabilistic formulations of numerical optimization, consider some of the most immediate future work: Perhaps the most obvious insight is that Gaussian process integration is trivial to extend to noisy evaluations. In combination with a robust replacement for the traditional line searches, our work may thus lead to robust numerical optimizers. Repeated integration, and non-Gaussian likelihoods in combination with approximate inference, may allow optimization without gradients, and from only gradient sign observations, respectively. Structured and hierarchical priors are a third direction, offering new avenues for optimization of very high-dimensional functions."}, {"heading": "6. Conclusion", "text": "We have shown that the most popular quasi-Newton algorithms can be interpreted as approximations to Bayesian regression under Gaussian and other priors. This deepens our understanding of these algorithms. In particular, it emerged that symmetry in the estimators of SR1, PSB, DFP and BFGS, and positive definiteness in those of DFP and BFGS, are encoded in only approximate, incomplete ways.\nAs a parallel result, our analysis also gives rise to a new class of Bayesian nonparametric quasi-Newton algorithms. These use a kernel model to utilize all observations in each line-search, explicitly track uncertainty, and thus achieve faster convergence towards the true Hessian. While the new methods are not trivial to understand and implement, their computational cost lies within a constant of that of their predecessors. A demonstrative implementation can be found at www.probabilistic-optimization.org."}, {"heading": "Acknowledgments", "text": "The authors thank Christian Schuler, Tom Minka and Carl Rasmussen for helpful discussions, as well as Carl Rasmussen for his release of minimize.m, which simplified development. MK is supported by a grant from\nMicrosoft Research Ltd."}], "references": [{"title": "Convex Optimization", "author": ["S.P. Boyd", "L. Vandenberghe"], "venue": null, "citeRegEx": "Boyd and Vandenberghe,? \\Q2004\\E", "shortCiteRegEx": "Boyd and Vandenberghe", "year": 2004}, {"title": "A class of methods for solving nonlinear simultaneous equations", "author": ["C.G. Broyden"], "venue": "Math. Comp.,", "citeRegEx": "Broyden,? \\Q1965\\E", "shortCiteRegEx": "Broyden", "year": 1965}, {"title": "Quasi-Newton methods and their application to function minimization", "author": ["C.G. Broyden"], "venue": "Math. Comp.,", "citeRegEx": "Broyden,? \\Q1967\\E", "shortCiteRegEx": "Broyden", "year": 1967}, {"title": "A new double-rank minimization algorithm", "author": ["C.G. Broyden"], "venue": "Notices American Math. Soc,", "citeRegEx": "Broyden,? \\Q1969\\E", "shortCiteRegEx": "Broyden", "year": 1969}, {"title": "Variable metric method for minimization", "author": ["W.C. Davidon"], "venue": "Technical report, Argonne National Laboratories, Ill.,", "citeRegEx": "Davidon,? \\Q1959\\E", "shortCiteRegEx": "Davidon", "year": 1959}, {"title": "Quasi-Newton methods, motivation and theory", "author": ["Dennis", "J.E. Jr.", "J.J. Mor\u00e9e"], "venue": "SIAM Review, pp", "citeRegEx": "Dennis et al\\.,? \\Q1977\\E", "shortCiteRegEx": "Dennis et al\\.", "year": 1977}, {"title": "A new approach to variable metric algorithms", "author": ["R. Fletcher"], "venue": "The Computer Journal,", "citeRegEx": "Fletcher,? \\Q1970\\E", "shortCiteRegEx": "Fletcher", "year": 1970}, {"title": "A rapidly convergent descent method for minimization", "author": ["R. Fletcher", "M.J.D. Powell"], "venue": "The Computer Journal,", "citeRegEx": "Fletcher and Powell,? \\Q1963\\E", "shortCiteRegEx": "Fletcher and Powell", "year": 1963}, {"title": "Numerical computation of rectangular bivariate and trivariate normal and t probabilities", "author": ["A. Genz"], "venue": "Statistics and Computing,", "citeRegEx": "Genz,? \\Q2004\\E", "shortCiteRegEx": "Genz", "year": 2004}, {"title": "A family of variable metric updates derived by variational means", "author": ["D. Goldfarb"], "venue": "Math. Comp.,", "citeRegEx": "Goldfarb,? \\Q1970\\E", "shortCiteRegEx": "Goldfarb", "year": 1970}, {"title": "Deriving quadrature rules from Gaussian processes", "author": ["T.P. Minka"], "venue": "Technical report,", "citeRegEx": "Minka,? \\Q2000\\E", "shortCiteRegEx": "Minka", "year": 2000}, {"title": "Updating quasi-Newton matrices with limited", "author": ["J. Nocedal"], "venue": "storage. Math. Comp.,", "citeRegEx": "Nocedal,? \\Q1980\\E", "shortCiteRegEx": "Nocedal", "year": 1980}, {"title": "A new algorithm for unconstrained optimization", "author": ["M.J.D. Powell"], "venue": "Nonlinear Programming. AP,", "citeRegEx": "Powell,? \\Q1970\\E", "shortCiteRegEx": "Powell", "year": 1970}, {"title": "Conditioning of quasi-Newton methods for function minimization", "author": ["D.F. Shanno"], "venue": "Math. Comp.,", "citeRegEx": "Shanno,? \\Q1970\\E", "shortCiteRegEx": "Shanno", "year": 1970}], "referenceMentions": [{"referenceID": 4, "context": "Some of the most widely known members of this family include Broyden\u2019s (1965) method, the SR1 formula (Davidon, 1959; Broyden, 1967), the DFP method (Davidon, 1959; Fletcher & Powell, 1963) and the BFGS method (Broyden, 1969; Fletcher, 1970; Goldfarb, 1970; Shanno, 1970).", "startOffset": 102, "endOffset": 132}, {"referenceID": 2, "context": "Some of the most widely known members of this family include Broyden\u2019s (1965) method, the SR1 formula (Davidon, 1959; Broyden, 1967), the DFP method (Davidon, 1959; Fletcher & Powell, 1963) and the BFGS method (Broyden, 1969; Fletcher, 1970; Goldfarb, 1970; Shanno, 1970).", "startOffset": 102, "endOffset": 132}, {"referenceID": 4, "context": "Some of the most widely known members of this family include Broyden\u2019s (1965) method, the SR1 formula (Davidon, 1959; Broyden, 1967), the DFP method (Davidon, 1959; Fletcher & Powell, 1963) and the BFGS method (Broyden, 1969; Fletcher, 1970; Goldfarb, 1970; Shanno, 1970).", "startOffset": 149, "endOffset": 189}, {"referenceID": 3, "context": "Some of the most widely known members of this family include Broyden\u2019s (1965) method, the SR1 formula (Davidon, 1959; Broyden, 1967), the DFP method (Davidon, 1959; Fletcher & Powell, 1963) and the BFGS method (Broyden, 1969; Fletcher, 1970; Goldfarb, 1970; Shanno, 1970).", "startOffset": 210, "endOffset": 271}, {"referenceID": 6, "context": "Some of the most widely known members of this family include Broyden\u2019s (1965) method, the SR1 formula (Davidon, 1959; Broyden, 1967), the DFP method (Davidon, 1959; Fletcher & Powell, 1963) and the BFGS method (Broyden, 1969; Fletcher, 1970; Goldfarb, 1970; Shanno, 1970).", "startOffset": 210, "endOffset": 271}, {"referenceID": 9, "context": "Some of the most widely known members of this family include Broyden\u2019s (1965) method, the SR1 formula (Davidon, 1959; Broyden, 1967), the DFP method (Davidon, 1959; Fletcher & Powell, 1963) and the BFGS method (Broyden, 1969; Fletcher, 1970; Goldfarb, 1970; Shanno, 1970).", "startOffset": 210, "endOffset": 271}, {"referenceID": 13, "context": "Some of the most widely known members of this family include Broyden\u2019s (1965) method, the SR1 formula (Davidon, 1959; Broyden, 1967), the DFP method (Davidon, 1959; Fletcher & Powell, 1963) and the BFGS method (Broyden, 1969; Fletcher, 1970; Goldfarb, 1970; Shanno, 1970).", "startOffset": 210, "endOffset": 271}, {"referenceID": 1, "context": "Some of the most widely known members of this family include Broyden\u2019s (1965) method, the SR1 formula (Davidon, 1959; Broyden, 1967), the DFP method (Davidon, 1959; Fletcher & Powell, 1963) and the BFGS method (Broyden, 1969; Fletcher, 1970; Goldfarb, 1970; Shanno, 1970).", "startOffset": 61, "endOffset": 78}, {"referenceID": 1, "context": "Choosing a unit variance prior \u03a3i\u22121 = I \u2297 I recovers one of the oldest quasi-Newton algorithms: Broyden\u2019s method (1965): Bi = Bi\u22121 + (yi \u2212Bi\u22121si)s\u22bai s\u22bai si (7)", "startOffset": 96, "endOffset": 120}, {"referenceID": 4, "context": "(2) (Dennis & Mor\u00e9e, 1977) is the symmetric rank 1 (SR1) method (Davidon, 1959; Broyden, 1967): Bi = Bi\u22121 + (yi \u2212Bi\u22121si)(yi \u2212Bi\u22121si)\u22ba s\u22bai (yi \u2212Bi\u22121si) .", "startOffset": 64, "endOffset": 94}, {"referenceID": 2, "context": "(2) (Dennis & Mor\u00e9e, 1977) is the symmetric rank 1 (SR1) method (Davidon, 1959; Broyden, 1967): Bi = Bi\u22121 + (yi \u2212Bi\u22121si)(yi \u2212Bi\u22121si)\u22ba s\u22bai (yi \u2212Bi\u22121si) .", "startOffset": 64, "endOffset": 94}, {"referenceID": 9, "context": "(13) gives what is known as Powell\u2019s (1970) symmetric Broyden (PSB) update.", "startOffset": 28, "endOffset": 44}, {"referenceID": 4, "context": "(16) gives the DFP method (Davidon, 1959; Fletcher & Powell, 1963)", "startOffset": 26, "endOffset": 66}, {"referenceID": 3, "context": "And, if we exchange in the entire preceding derivation s ] y, B ] B\u22121, Bi\u22121 ] B\u22121 i\u22121, then we arrive at the BFGS method (Broyden, 1969; Fletcher, 1970; Goldfarb, 1970; Shanno, 1970), which ranks among the most widely used algorithms in machine learning overall.", "startOffset": 121, "endOffset": 182}, {"referenceID": 6, "context": "And, if we exchange in the entire preceding derivation s ] y, B ] B\u22121, Bi\u22121 ] B\u22121 i\u22121, then we arrive at the BFGS method (Broyden, 1969; Fletcher, 1970; Goldfarb, 1970; Shanno, 1970), which ranks among the most widely used algorithms in machine learning overall.", "startOffset": 121, "endOffset": 182}, {"referenceID": 9, "context": "And, if we exchange in the entire preceding derivation s ] y, B ] B\u22121, Bi\u22121 ] B\u22121 i\u22121, then we arrive at the BFGS method (Broyden, 1969; Fletcher, 1970; Goldfarb, 1970; Shanno, 1970), which ranks among the most widely used algorithms in machine learning overall.", "startOffset": 121, "endOffset": 182}, {"referenceID": 13, "context": "And, if we exchange in the entire preceding derivation s ] y, B ] B\u22121, Bi\u22121 ] B\u22121 i\u22121, then we arrive at the BFGS method (Broyden, 1969; Fletcher, 1970; Goldfarb, 1970; Shanno, 1970), which ranks among the most widely used algorithms in machine learning overall.", "startOffset": 121, "endOffset": 182}, {"referenceID": 1, "context": "And, if we exchange in the entire preceding derivation s ] y, B ] B\u22121, Bi\u22121 ] B\u22121 i\u22121, then we arrive at the BFGS method (Broyden, 1969; Fletcher, 1970; Goldfarb, 1970; Shanno, 1970), which ranks among the most widely used algorithms in machine learning overall. DFP and BFGS owe much of their popularity to the fact that the updated Bi,DFP and B \u22121 i,BFGS are guaranteed to be positive definite whenever Bi\u22121,DFP and B\u22121 i\u22121,BFGS are positive definite, respectively, and additionally y\u22bai si > 0. How helpful is this property? It is relatively straightforward to extend a theorem by Dennis & Mor\u00e9e (1977) to find that, assuming Bi\u22121 is positive definite, the posterior mean of Eq.", "startOffset": 122, "endOffset": 605}, {"referenceID": 10, "context": "Another option, not yet explored by us, may be offered by spline kernels (Minka, 2000).", "startOffset": 73, "endOffset": 86}, {"referenceID": 8, "context": "Fortunately, good, lightweight numerical approximations are available for this problem (Genz, 2004).", "startOffset": 87, "endOffset": 99}, {"referenceID": 11, "context": "Using a diagonal prior mean B0 and an argument largely analogous to the derivation of the L-BFGS algorithm (Nocedal, 1980) lowers cost to O(NM +M3), linear in N .", "startOffset": 107, "endOffset": 122}], "year": 2012, "abstractText": "Four decades after their invention, quasiNewton methods are still state of the art in unconstrained numerical optimization. Although not usually interpreted thus, these are learning algorithms that fit a local quadratic approximation to the objective function. We show that many, including the most popular, quasi-Newton methods can be interpreted as approximations of Bayesian linear regression under varying prior assumptions. This new notion elucidates some shortcomings of classical algorithms, and lights the way to a novel nonparametric quasi-Newton method, which is able to make more efficient use of available information at computational cost similar to its predecessors.", "creator": "LaTeX with hyperref package"}}}