{"id": "1206.6432", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "Sparse Support Vector Infinite Push", "abstract": "in this paper, we address the problem of embedded feature selection for ranking on top of the worst problems. \\ pose this problem as a regularized empirical risk minimization with $ p $ - norm push gap function ( $ p = \\ infty $ ) and sparsity cost regularizers. we leverage the issues apply to every challenging iteration problem by considering an alternating direction method or numerical algorithm which is justified upon proximal operators of the loss function and the regularizer. our main technical contribution is thus to provide a numerical scheme for computing the deep slice loss function proximal operator. experimental results on toy, infinite microarray and bci problems show how our novel algorithm stands favorably to competitors for ranking on top while using fewer characters in the scoring function.", "histories": [["v1", "Wed, 27 Jun 2012 19:59:59 GMT  (195kb)", "http://arxiv.org/abs/1206.6432v1", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)"]], "COMMENTS": "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)", "reviews": [], "SUBJECTS": "cs.LG cs.CE stat.ML", "authors": ["alain rakotomamonjy"], "accepted": true, "id": "1206.6432"}, "pdf": {"name": "1206.6432.pdf", "metadata": {"source": "META", "title": "Sparse Support Vector Infinite Push", "authors": ["Alain Rakotomamonjy"], "emails": ["alain.rakoto@insa-rouen.fr"], "sections": [{"heading": "1. Introduction", "text": "Learning to rank is a supervised learning problem which objective is to estimate a scoring function from training examples. That function is expected to define a partial order on the examples by scoring relevant instances higher than the non-relevant ones. Examples of applications in which ranking is central are information retrieval (Chapelle & Keerthi, 2010), drug discovery (Agarwal et al., 2010).\nMany machine learning algorithms have been proposed for learning ranking functions. Some of them aim at optimizing a pairwise ranking criterion using exponential loss, like the RankBoost of Freund et al. (2003) or using Hinge loss (Joachims, 2002). Methods based on decision trees have also been investigated (Cle\u0301mencon & Vayatis, 2009). While these methods\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\nhave shown their interests, they may not be optimally targeted at a specific goal which is getting an accurate ranking at the top of the list. Indeed, for instance, in information retrieval, one usually wants to have the most relevant documents as possible at the top of the list, while getting an accurate pairwise ordering in other part of the list is not of great importance. For this reason, several recently proposed algorithms focus on correctly ranking the best instances (Rudin, 2009; Agarwal, 2011).\nFor most of the works we described above, the scoring function is a linear function of the form f(x) = w\u22a4x, where w is the weight vector that has to be learned. The resulting weight vector w is usually a non-sparse vector, which means that all features will be considered in the scoring function even though they are non-informative. Hence, similarly to other supervised learning paradigms, ranking methods may also benefit from feature selection as keeping only few features in the scoring function may improve performances as well as reducing prediction time. To the best of our knowledge, very few works have addressed the problem of feature selection in ranking (Geng et al., 2007) and in ranking on top of the list problems. Naturally, algorithms like the SVM-RFE or methods based on sparsity-inducing norms like the \u21131 norm can be easily extended to ranking algorithms. But developing algorithms for embedded feature selection becomes more challenging when loss functions related to ranking on top have to be considered. This is the challenge we want to address in this paper and as far as we know, this is the first paper proposing embedded feature selection using sparsity inducing norms for ranking on top of the list.\nWe focus on the recent p-norm push loss function introduced by Rudin (2009) and more specifically, on the case where p = \u221e, denoted as an infinite push framework by Agarwal (2011). In this latter work, Agarwal (2011) has also proposed a support vector like algorithm, named as support vector Infinite Push, which has been proved to perform better than competitors when the goal is to maximize the number of\nrelevant instances on top of the list. Here, we provide a novel algorithm for solving the regularized empirical risk minimization related to the support vector Infinite Push loss function that can also handle sparsity inducing regularizers. While typical methods dealing with sparsity suppose that the loss function is smooth (Bach et al., 2011), our optimization problem is challenging since both the loss function and the regularizer can be non-differentiable. We propose to overcome this issue by proposing an alternating direction method of multipliers (ADMM), which is wrapped around the computation of the infinite push loss function proximal operator in addition to the one of the regularizer.\nGlobally, the paper provides contributions to the state of the art in several points: (a) it proposes a numerical scheme for computing the proximal operator of the support vector infinite push loss function, (b) it shows that the optimization framework we consider offers some theoretical guarantees on the uniqueness of the problem minimizer, property that is not always insured by Agarwal\u2019s algorithm, (c) it is the first paper showing that p-norm push ranking algorithms can also embed feature selection through the use of sparsity inducing norms. It demonstrates that ranking on top applications can also benefit from feature selection either by improved performances or reduced prediction time.\nThe paper is organized as follows. Section 2 introduces the global framework for ranking on top of the list as well as the optimization related to sparse support vector infinite push. In Section 3, the ADMM-based algorithm proposed for solving the problem and the numerical scheme for computing the proximal operator of the infinite push loss are presented. Experimental results are described in Section 4 while conclusion is in Section 5."}, {"heading": "2. Infinite Push framework", "text": "In this section, we introduce the Infinite Push loss function and the support vector Infinite Push optimization problem we are interested in. Existence and uniqueness of solutions to the problem are also discussed."}, {"heading": "2.1. Infinite Push loss function", "text": "We limited ourselves to the case of bipartite ranking problem which goal is to learn a function that, given a training set {xi} \u2113 i=1, xi \u2208 R\nd, with m positive and n negative examples, gives higher scores to positive examples than to negatives ones. Learning such a function can be cast into an empirical regularized risk min-\nimization framework, where the loss function related to the risk is designed so as to favor higher scores for positive examples. Typically, in such a context, the loss function focuses on the average pairwise scoring losses and it can be written as :\nL(f(\u00b7), S) = 1\nmn\n\u2211\ni,j\nIf(x+ i )\u2264f(x\u2212 j )\nwhere I\u00b7 is the indicator function, S is a set of examples with known labels and f(\u00b7) is the scoring function that we want to evaluate. Several extensions of this loss function have been recently considered in order to provide more importance to errors made on top of the lists, for instance by weighting the pairwise loss (Usunier et al., 2009) or by replacing the mean with some more appropriate functions. For this purpose, Rudin (2009) has introduced the Infinite Push loss function\nL(f(\u00b7), S)\u221e = max j\n\u2211\ni\nIf(x+ i )\u2264f(x\u2212 j ) (1)\nwhich gets smaller as the negative example with highest score is assigned a small score. This loss function is the one on which we have focused our interest."}, {"heading": "2.2. Support Vector Infinite Push", "text": "We can now define the empirical risk minimization (ERM) framework used for learning the scoring function f(\u00b7) that we have chosen to be linear so that f(x) = w\u22a4x. the loss function given in Equation (1) is non-convex and different convexifications proposed in the literature have led to different ERM frameworks and algorithms. We can mention for instance the relaxation by means of exponential loss that yield to boosting-like algorithm (Rudin, 2009). If Hinge loss is used as a convex relaxation then we get the following Support Vector like optimization problem :\nmin w \u03bb\u2126(w) + max 1\u2264j\u2264n\n(\n1\nm\nm \u2211\ni=1\n( 1\u2212w\u22a4(x+i \u2212 x \u2212 j ) )\n+\n)\n(2) where \u2126(w) is some regularization term and the function (u)+ = u if u > 0 and 0 otherwise.\nFor \u2126(w) = \u03bb2 \u2016w\u2016 2, Agarwal has proposed an algorithm for solving the dual of this problem, which is :\nmin \u03b1i,j\n1\n2\n\u2211\ni,j\n\u2211\nk,l\n\u03b1i,j\u03b1k,l(x + i \u2212 x \u2212 j ) \u22a4(x+k \u2212 x \u2212 l )\u2212\n\u2211\ni,j\n\u03b1i,j\nst \u2211 j maxi(\u03b1i,j) \u2264 1 \u03bbm\n\u03b1i,j \u2265 0 (3)\nwhich has smooth quadratic objective function under some mixed-norm constraints over the dual variables \u03b1i,j . The algorithm is based on a nice and clever gradient projection algorithm (Agarwal, 2011).\nIn this paper, we focus our effort on this support vector infinite push problem and propose a novel optimization algorithm for solving it when \u2126(w) is some non-differentiable sparsity-inducing regularizer so as to perform feature selection in a top-ranking learning problem. For this purpose, we investigate an algorithm that directly solves the primal problem in Equation (2).\nHowever, before delving into the details of the algorithm, we discuss, in what follows the existence and uniqueness of the solution of the primal problem (2) based on some classical results on convex analysis:\nProposition 1. (a) For any convex regularization term \u2126(w) that is lower semi-continuous and and coercive, problem (2) admits at least one solution. (b) For any strictly convex, lower semi continuous and coercive regularization term, problem (2) admits an unique solution.\nWe omit the proof of these two propositions since they are rather direct consequences of some well known results on the minimization of composite non-smooth functions (Combettes & Pesquet, 2007). Instead, we prefer to bring to light some properties of the primal problem compared to the dual one that are consequences of these propositions :\nAn interesting point is that for \u2126(w) = \u03bb2 \u2016w\u2016 2, point 2 of the proposition guarantees uniqueness of solution since \u2126 satisfies all required properties. Conversely, when considering the dual problem (3) as in Agarwal (2011), this property may be lost. Indeed, it can be easily shown that when the dimensionality of the problem d is smaller than m \u00b7n, the Hessian of the dual objective function is only positive semi-definite. We remark that even for small-scale high-dimensional learning problem, the condition d < m \u00b7 n can be rapidly reached making optimization in the primal theoretically more sound.\nUniqueness of the solution for \u21131 norms or mixednorms are more involved and we have left these analyses for future works."}, {"heading": "3. Algorithm for sparse Support Vector Infinite Push", "text": "In this section, we show how we leverage the issues raised by the non-smooth objective function in problem (2) and we describe in details the ADMM algo-\nrithm we propose for solving the sparse support vector infinite push problem."}, {"heading": "3.1. Deriving ADMM formulation", "text": "Before delving into the derivations, we want to mention that Douglas-Rachford splitting algorithm is tailored for minimizing the sum of two non-smooth objective functions. However, the presence of the design matrix will add some linear constraint on the problem, making it easier to address through an ADMM framework. For this purpose, we rewrite the optimization problem (2) as the following linearly-constrained problem :\nmin w,a\n\u2126(w) + max 1\u2264j\u2264n\n(\n1\nm\n\u2211\ni\n(ai,j)+\n)\nai,j = 1\u2212w T (x+i \u2212 x \u2212 j )\n(4)\nwhere \u2126(w) can be any sparsity inducing norm like the \u21131 norm, any mixed-norm (Bach et al., 2011) or the classical \u21132 regularization term. Then, by properly defining the matrix X (which rows are of the form (x+i \u2212 x \u2212 j ) T ), the vector a and the function g(a) = maxj ( 1 m \u2211 i max(ai,j , 0) )\nwe yield the following reformulation :\nmin w,a \u2126(w) + g(a)\nXw + a\u2212 1 = 0 (5)\nThe augmented Lagrangian related to this problem is\nL(w,a, \u03b4, \u00b5) = \u2126(w) + g(a) + \u03b4\u22a4(Xw + a\u2212 1) +\u00b52 \u2016Xw + a\u2212 1\u2016 2\nwhere \u03b4 is a vector of Lagrangian multipliers related to the equality constraint and \u00b5 is a parameter weighting the quadratic penalty. After rearranging the terms, one can show that the augmented Lagrangian is\nL(w,a, \u03b3) = \u2126(w) + g(a) + \u00b52 \u2016Xw + a\u2212 1+ \u03b3\u2016 2\nwhere \u03b3 = \u03b4 \u00b5 . The alternating direction method of multipliers that solves our original problem (4) looks for a saddle point of the augmented Lagrangian by solving alternatively at iteration k the following problems :\nwk+1 = argmin w L(w,ak, \u03b3k) (6)\nak+1 = argmin a L(wk+1,a, \u03b3k) (7) \u03b3k+1 = \u03b3k +Xwk+1 + ak+1 \u2212 1 (8)\nAll the challenges of the algorithm now resides essentially in the resolution of these problems."}, {"heading": "3.2. Solving problem (6)", "text": "The optimization problem related tow can be restated as\nmin w\n1 2 \u2016Xw \u2212 s\u201622 + 1 \u00b5 \u2126(w)\nwith s being 1 \u2212 ak \u2212 \u03b3k. Depending on the form of \u2126(w), this problem becomes a ridge regression problem for \u2126(w) = \u03bb2 \u2016w\u20162, a Lasso when \u2126(w) = \u03bb\u2016w\u20161, or another (probably known) problem if a different regularization term is considered.\nFor sparsity-inducing regularizers (e.g \u21131 norm), the problem has to be solved numerically and thus, each iteration of the ADMM approach involves the resolution of a Lasso. Depending on the Lasso algorithm used, one can highly benefit from warm-starting the solution since between two consecutive ADMM iteration, the second member s is not expected to vary a lot.\nFor the \u21132 norm regularizer, the solution has a closedform solution\nwk+1 = (X\u22a4X+ \u03bb\n\u00b5 I)\u22121(X\u22a4s)\nIn some situations, when the dimensionality of the problem is large, it may be more efficient to numerically solve this linear system by means of a conjugate gradient descent approach."}, {"heading": "3.3. Solving problem (7)", "text": "Now supposing that w and the Lagrangian multipliers \u03b3 are fixed in the Lagrangian, the optimization problem related to (7) boils down to be :\nak+1 = argmin a\ng(a) + \u00b5\n2 \u2016a\u2212 s\u201622 (9)\nwith s being 1 \u2212 \u03b3k \u2212 Xwk+1. We note that by definition, ak+1 is the result of 1\n\u00b5 g(\u00b7) proximal operator\napplied to the vector s (Combettes & Pesquet, 2010). Now, let us look into more details at this problem. The most challenging part of it comes from the two nested max functions defining g(\u00b7). In order to overcome part of the issues, we propose to use the doubling trick and rewrites the minimization problem as :\nmin a +,a\u2212\n1 2\u2016a + \u2212 a\u2212 \u2212 s\u201622 +maxj\n(\n1 m\u00b5\n\u2211 i a + )\nst a+ \u2265 0,a\u2212 \u2265 0 (10) with a = a+ \u2212 a\u2212. Now, since the regularization term and the constraints are decoupled in a+ and a\u2212, we suggest to solve problem (10) by means a of blockcoordinate descent (BCD) algorithm that starts from\nsome positive random vectors and alternatively optimize over a+ then a\u2212 keeping the other vector fixed. Before providing algorithmic details, we state here a proposition based on the work of Tseng (2001) that guarantees the soundness of the BCD algorithm.\nProposition 2. Let us define f0(a +,a\u2212) = 12\u2016a + \u2212 a\u2212 \u2212 s\u201622, f1(a +) = maxj ( 1 m\u00b5 \u2211 i a + ) + I a +\u22650, f2(a \u2212) = I a \u2212\u22650, the sequence generates by the BCD method by alternatively optimizing over a+ and a\u2212 converges towards the minimum of Problem 10.\nProof. It is easy to see that the objective function f(a+,a\u2212) of Problem 10 is f(a+,a\u2212) = f0(a\n+,a\u2212) + f1(a +,a\u2212) + f2(a +,a\u2212). Besides, f0 is continuous on its domain and coercive, f(\u00b7, \u00b7) is convex with respect to any of its parameter with the other fixed and the functions fi(\u00b7),i = {0, 1, 2} are lower semi-continuous. Owing to all these properties, applying Theorem 5.1 of Tseng (2001) concludes the proof.\nNow, we are interested in solving each coordinate descent of Equation (10). When considering minimizing over a\u2212 with a+ fixed, the problem is rather simple since it boils down to be a projection of \u2212s + a+ on the positive quadrant. Hence, we have the following closed-form solution for each component of a\u2212 :\na\u2212k =\n{\n\u2212sk + a + k if \u2212 sk + a + k \u2265 0 0 otherwise\nWe can now focus on the other alternate problem\nmin a +\n1 2\u2016a + \u2212 b\u201622 +maxj\n(\n1 m\u00b5\n\u2211\ni\u2208Gi a+i\n)\nst a+ \u2265 0\nwith b = a\u2212 + s and Gi being the indices of elements of a coupling the negative example xj with positive examples. Interestingly, owing to the positiveness of a+ and by replacing the constraint in the objective value this problem is equivalent to\nmin a +\n1 2\u2016a + \u2212 b\u201622 +maxj\n(\n1 m\u00b5\n\u2211\ni\u2208Gi |a+i |\n)\n+ I a +\u22650\n(11)\nWe can note here that the solution of this problem occurs at\na+\u22c6 = proxI\u00b7\u22650+\u2126\u2020(b)\nwith I\u00b7\u22650 being the indicator on the positive quadrant and \u2126\u2020(u) = maxj ( 1 m\u00b5 \u2211 i\u2208Gi |u+i | ) which is a mixed \u2113\u221e \u2212 \u21131 norm on u. The proximal operator proxI\u00b7\u22650+\u2126(b) is non-trivial and needs to be computed numerically. For this purpose, we have applied a Douglas-Rachford algorithm which can handle the\nminimization of the sum of two non-smooth convex functions f1 and f2. The following proposition makes this explicit :\nProposition 3. (Combettes & Pesquet, 2010) Let f1 and f2 be two convex lower semi-continuous functions of Rd such that the intersection of their domain relative interiors is not empty and such that f1(\u00b7) + f2(\u00b7) is coercive. Set v0 \u2208 R d and build un for n \u2265 0 as\nun = prox\u03b3f2(vn) vn+1 = vn + \u03b7 ( prox\u03b3f1(2un \u2212 vn)\u2212 un) ) (12)\nwith \u03b3 > 0 and \u03b7 \u2208]0, 2[, then every sequence {un} generated by this algorithm converges towards a minimizer of f1 + f2.\nHence, a direct application of this algorithm to our problem given in Equation (11) with f2(v) = 1 2\u2016v \u2212 b\u201622 + Iv\u22650 and f1(v) = maxj ( 1 m\u00b5 \u2211 i\u2208Gi |vi| ) leads to the minimizer of Equation (11). Now the remaining question is : what are the proximal operators of \u03b3f1 and \u03b3f2?\nFor \u03b3f2, we have to solve the problem\nprox\u03b3f2(vn) = argmin z\n1 2 \u2016z\u2212vn\u2016 2 2+ \u03b3 2 \u2016z\u2212b\u201622+ Iz\u22650\nwhich solution can be easily proven to be\nprox\u03b3f2(vn) = PC\n(\nvn + \u03b3b\n1 + \u03b3\n)\nwith PC being the projection on the positive quadrant. Now, regarding \u03b3f1, we look for\nprox\u03b3f1(v) = argmin z\n1 2 \u2016z\u2212v\u201622+ \u03b3 m\u00b5 max j\n(\n\u2211\ni\u2208Gi\n|zi|\n)\n(13) which is the proximal operator of a \u2113\u221e \u2212 \u21131 mixed norm. For solving this problem, we use classical result from convex analysis and proximal operator (Combettes & Wajs, 2005; Sra, 2011), which states that the proximal operator of a norm \u2016 \u00b7 \u2016 is\nprox\u03c4\u2016\u00b7\u2016(u) = u\u2212\u03a0\u2016\u00b7\u2016\u2217\u2264\u03c4 (u)\nwith \u03a0\u2016\u00b7\u2016\u2217\u2264\u03c4 (u) being the projection of u on the \u03c4 - radius ball of the dual norm \u2016 \u00b7 \u2016\u2217. Then, since the dual norm of \u2113\u221e \u2212 \u21131 norm is the \u21131 \u2212 \u2113\u221e norm, we have\nprox\u03b3f1(v) = v \u2212\u03a0\u2016\u00b7\u20161,\u221e\u2264 \u03b3m\u00b5 (v) (14)\nThis problem is easily tractable since projection of vector on a \u21131 \u2212 \u221e ball has been recently studied and several efficient algorithms proposed (Quattoni et al., 2009; Sra, 2011).\nAlgorithm 1 ADMM approach for primal infinite push.\n1: Input : X : matrix of pairwise difference of examples, \u03bb regularization term 2: set \u00b5 > 0, k = 0 3: initialize ak and \u03b3k to vectors of 0. 4: repeat 5: s = 1\u2212 ak \u2212 \u03b3k 6: wk+1 = argminw 1 2\u2016Xw \u2212 s\u2016 2 2 + \u03bb\u2126(w) 7: s = 1\u2212 \u03b3k \u2212Xwk+1 8: set a+ = 0 and a\u2212 = 0 9: repeat\n10: a\u2212 = max(\u2212s+ a+, 0) 11: set b = a\u2212 + s and v0 = 0 12: repeat 13: un = 1 1+\u03b3 max(vn + \u03b3b, 0) 14: vn+1 = vn+\u03b7(un\u2212vn\u2212\u03a0\u2016\u00b7\u20161,\u221e(2un\u2212vn)) 15: until convergence is met 16: a+ = un 17: until convergence is met 18: ak+1 = a+ \u2212 a\u2212 19: \u03b3k+1 = \u03b3t +Xwk+1 + ak+1 \u2212 1 20: k \u2190 k + 1 21: until condition"}, {"heading": "3.4. Convergence analysis", "text": "Convergence of Algorithm 1, for solving the primal infinite push problem builds upon classical convergence results of ADMM or Douglas-Rachford splitting algorithm (Eckstein & Bertsekas, 1992). Indeed, a direct application of Theorem 8 in that paper tells us that our algorithm converges for any \u00b5 > 0, as long as the matrix X has full column rank (condition that is satisfied by most non-degenerate problems for which d < m \u00b7 n) and that the computation errors of problem (6) and problem (7) are summable. Practically, this latter condition means that the convergence criterion on these two problems should become tighter and tighter as the iterations go. However, in our implementation, these stopping criteria have been kept fixed but still no empirical problem of convergence has been noticed."}, {"heading": "3.5. Computational complexity", "text": "The two most computationally demanding part of our algorithm for sparse infinite push is the Lasso problem that has to be solved at each iteration and the projection on the \u21131 \u2212 \u2113\u221e ball. For the Lasso, there exists efficient algorithms that scale linearly with the number of training examples. We can, for instance, mention the SpaRSa algorithm of Figueiredo et al. (Figueiredo et al., 2007). Similarly, the projection on\n100 150 200 250 300 350 400 0.2\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\n0.55\n0.6\n0.65\n0.7\n# Training examples\nra te\no f p\nos iti\nve s\nat to\np\n# useful variables : 10, # noisy variables:20\n0.03\n0.06\n0.00\n0.00 0.00 0.00\n0.00\n0.13\nL1 InfPush RFE InfPush SVM Rank\n100 150 200 250 300 350 400 0.2\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\n0.55\n0.6\n0.65\n0.7\n# Training examples\nra te\no f p\nos iti\nve s\nat to\np\n# useful variables : 10, # noisy variables:100\n0.220.06 0.00 0.00 0.00\n0.04\n0.00\n0.03\nL1 InfPush RFE InfPush SVM Rank\nFigure 1. Rate of positives at top of the list of when the number of discriminative features is 10 and the number of noisy variables is : left) 20. right) 100.\nthe \u21131 \u2212 \u2113\u221e ball of Quattoni et al. (2009) has a complexity of O(n log n) in the size of the vector to project. Hence, in our case, since the number of examples in the Lasso and the size of the vector to project are both m \u00b7 n, we end up with an algorithm which complexity is O(m \u00b7 n logm \u00b7 n).\nAs a comparison, a plain implementation of RankSVM would also lead to a complexity that is linear with respects to the number of pairwise examples (Chapelle & Keerthi, 2010). However, since RankSVM is easier to deal with as the loss function can be made differentiable we expect RankSVM to have a better constant."}, {"heading": "4. Experiments", "text": "Our objective here is to provide empirical evidences that our method can be beneficial in problems with noisy or redundant features compared to an infinite push approach that considers all the features. We also show that when compared to other feature selection methods like recursive feature elimination (RFE) in an infinite push context, our embedded approach based on sparsity-inducing norm provides better accuracy on top of the list.\nNote that we have not compared our methods to other ranking algorithms, except SVMRank (Chapelle & Keerthi, 2010), since Agarwal (2011) has already shown the superiority of the infinite push model on other methods for ranking positive instances on top of the list and because these methods such as SVMMAP does not have their sparse counterpart in the literature."}, {"heading": "4.1. Toy problem", "text": "On this problem, we compare the efficiency of using an \u21131 sparsity-inducing norm to recursive-feature elimination for reducing the influence of noisy variables\nin an infinite push framework. Our RFE implementation follows exactly the same procedure as the one used for SVM RFE (Guyon et al., 2002), but replacing the SVM with the infinite push algorithm as proposed by Agarwal (2011). This infinite push RFE bears strong resemblance with the backward elimination of Geng et al. (2007). For a baseline comparison, we have also included an \u21131 SVM Rank.\nThe toy problem is a binary classification problem in R\nd with evenly distributed classes. Among these d variables, only r of them define a subspace of Rd in which classes can be discriminated. For these r relevant variables, the two classes follow a Gaussian pdf with mean respectively \u00b5 and \u2212\u00b5 and covariance matrices randomly drawn from a Wishart distribution. \u00b5 has been randomly drawn from {\u22121,+1}r. The other d \u2212 r non-relevant variables follow an i.i.d Gaussian probability distribution with zero mean and unit variance for both classes. We have respectively sampled n and nt number of examples for training and testing. For some experiments, n is varying, but we have always set nt = 1000. Before learning, the training set has been normalized to zero mean and unit variance and the test sets have been rescaled accordingly. Hyperparameters of all methods have been chosen as those maximizing performance on a validation set obtained by random 70%\u2212 30% split of the training set examples.\nAveraged results over 20 trials are depicted on Figure 1 which plots the rate of positive on top of the list defined as #pos. on top\nm , with respects to varying\nnumber of training examples for fixed number of features. We note that our \u21131 support vector infinite push significantly outperforms other competitors, in most cases with a p-value of a Wilcoxon signed rank test lower than 0.05 (the numbers besides the markers). We can also remark that unlike the infinite push approach, SVM Rank does not necessarily improve its performances on the top as the number of examples increases. This is unsurprising as SVM Rank aims at optimizing average ranking.\nFigure 2 depicts the precision and the F-measure of the different algorithms for retrieving the true variables. We remark that the RFE infinite push performs very good with respects to the F-measure. However, the use of the \u21131 norm yields to a better precision : more relevant variables are selected at the expense of selecting some irrelevant ones. This is a well known issue of the \u21131 norm that can be overcome using an adaptive approach (Zou, 2006).\nAn empirical illustration of the computational complexity of our algorithm as well as the one of a sparse\nSVM Rank is reported in Figure 3. We can highlight that both algorithms have an empirical exponent complexity of about 1 with respects to the number of pairwise training examples."}, {"heading": "4.2. Real-world problems", "text": "We also also carried out experiments on some realworld datasets. These datasets are essentially related to DNA microarray analysis (colon,yeast), or comes from the UCI dataset repository (ionosphere, sonar, spectf, wpbc), as well as P300 based BCI speller. The same pre-processing as for the toy dataset has been applied to these real ones.\nWe have compared a plain infinite push method that does not perform embedded variable selection and a \u21131 SVM Rank to our sparse \u21131 infinite push. Comparison criteria are the rate of positive examples ranked on top and the number of variables used by the scoring functions. Averaged results over 10 iterations have been reported in Table 1. Results clearly shows that our \u21131 infinite push model is the model that achieves the best compromise between accuracy on top of the list and variable selection. Indeed, for all datasets, performances on top are statistically equivalent whereas\nsparse infinite push uses significantly fewer variables in most of the cases. A reduction of a factor 20 or 8 can respectively be achieved with respects to the original number of variables or the number of variables selected by SVM Rank."}, {"heading": "5. Conclusions", "text": "We have shown in this paper that embedded feature selection based on sparsity-inducing norms can be extended to loss functions that are themselves nondifferentiable and intrinsically complex. For sparse SVM infinite push, we have proposed an algorithm based on alternate direction method of multipliers that alternatively solves a Lasso (or related) problem and applies the proximal operator of the infinite push loss. For computing this proximal operator, we have devised a novel algorithm based on the projection on \u21131 \u2212 \u2113\u221e ball. Our experimental results show that our sparse\nSVM infinite push compares favorably to other approaches in terms of number of variables used in the model as well as in term of accuracy of ranking on top of the list. Future works will focus on algorithms that scale linearly or sublinearly with m \u00b7 n and on theoretical analysis of the methods."}, {"heading": "Acknowledgments", "text": "This work is partially supported by the PASCAL2 Network of Excellence, ICT-216886, ANR Project ASAP ANR-09-EMER-001."}], "references": [{"title": "The infinite push: A new support vector ranking algorithm that directly optimizes accuracy at the absolute top of the list", "author": ["S. Agarwal"], "venue": "In Proceedings of the SIAM International Conference on Data Mining (SDM),", "citeRegEx": "Agarwal,? \\Q2011\\E", "shortCiteRegEx": "Agarwal", "year": 2011}, {"title": "Ranking chemical structures for drug discovery: A new machine learning approach", "author": ["S. Agarwal", "D. Dugar", "S. Sengupta"], "venue": "Journal of Chemical Information and Modeling,", "citeRegEx": "Agarwal et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Agarwal et al\\.", "year": 2010}, {"title": "Convex optimization with sparsity-inducing norms. In Optimization for Machine Learning", "author": ["F. Bach", "R. Jenatton", "J. Mairal", "G. Obozinski"], "venue": null, "citeRegEx": "Bach et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Bach et al\\.", "year": 2011}, {"title": "Efficient algorithms for ranking with svms", "author": ["O. Chapelle", "S.S. Keerthi"], "venue": "Information Retrieval Journal,", "citeRegEx": "Chapelle and Keerthi,? \\Q2010\\E", "shortCiteRegEx": "Chapelle and Keerthi", "year": 2010}, {"title": "Tree-based ranking methods", "author": ["S. Cl\u00e9mencon", "N. Vayatis"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Cl\u00e9mencon and Vayatis,? \\Q2009\\E", "shortCiteRegEx": "Cl\u00e9mencon and Vayatis", "year": 2009}, {"title": "A douglas- rachford splitting approach to nonsmooth convex variational signal recovery", "author": ["P. Combettes", "Pesquet", "J.-C"], "venue": "IEEE Journal Selected Topics Signal Processing,", "citeRegEx": "Combettes et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Combettes et al\\.", "year": 2007}, {"title": "Signal recovery by proximal forward-backward splitting", "author": ["P. Combettes", "V. Wajs"], "venue": "Multiscale Modeling and Simulation,", "citeRegEx": "Combettes and Wajs,? \\Q2005\\E", "shortCiteRegEx": "Combettes and Wajs", "year": 2005}, {"title": "An efficient boosting algorithm for combining preferences", "author": ["Y. Freund", "R. Iyer", "R. Schapire", "Y. Singer"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Freund et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Freund et al\\.", "year": 2003}, {"title": "Feature selection for ranking", "author": ["X. Geng", "Liu", "T.-Y", "T. Qin", "H. Lin"], "venue": "In Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "Geng et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Geng et al\\.", "year": 2007}, {"title": "Gene selection for cancer classification using support vector machines", "author": ["I. Guyon", "J. Weston", "S. Barnhill", "V. Vapnik"], "venue": "Machine Learning,", "citeRegEx": "Guyon et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Guyon et al\\.", "year": 2002}, {"title": "Optimizing search engines using clickthrough data", "author": ["T. Joachims"], "venue": "In Proceedings of the ACM Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Joachims,? \\Q2002\\E", "shortCiteRegEx": "Joachims", "year": 2002}, {"title": "An efficient projection for l1,\u221e regularization", "author": ["A. Quattoni", "X. Carreras", "M. Collins", "T. Darrell"], "venue": "In Proceedings of the 26th International Conference on Machine Learning,", "citeRegEx": "Quattoni et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Quattoni et al\\.", "year": 2009}, {"title": "The p-norm push: A simple convex ranking algorithm that concentrates at the top of the list", "author": ["C. Rudin"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Rudin,? \\Q2009\\E", "shortCiteRegEx": "Rudin", "year": 2009}, {"title": "Fast projections onto l1,q-norm balls for grouped feature selection", "author": ["S. Sra"], "venue": "In Proceedings of the European Conference on Machine Learning,", "citeRegEx": "Sra,? \\Q2011\\E", "shortCiteRegEx": "Sra", "year": 2011}, {"title": "Convergence of block coordinate descent method for nondifferentiable minimization", "author": ["P. Tseng"], "venue": "Journal of Optimization Theory and Application,", "citeRegEx": "Tseng,? \\Q2001\\E", "shortCiteRegEx": "Tseng", "year": 2001}, {"title": "Ranking with ordered weigthed pairwise classification", "author": ["N. Usunier", "D. Buffoni", "P. Gallinari"], "venue": "In Proceeding of the 26 International Conference on Machine Learning,", "citeRegEx": "Usunier et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Usunier et al\\.", "year": 2009}, {"title": "The adaptive lasso and its oracle properties", "author": ["H. Zou"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Zou,? \\Q2006\\E", "shortCiteRegEx": "Zou", "year": 2006}], "referenceMentions": [{"referenceID": 1, "context": "Examples of applications in which ranking is central are information retrieval (Chapelle & Keerthi, 2010), drug discovery (Agarwal et al., 2010).", "startOffset": 122, "endOffset": 144}, {"referenceID": 10, "context": "(2003) or using Hinge loss (Joachims, 2002).", "startOffset": 27, "endOffset": 43}, {"referenceID": 7, "context": "Some of them aim at optimizing a pairwise ranking criterion using exponential loss, like the RankBoost of Freund et al. (2003) or using Hinge loss (Joachims, 2002).", "startOffset": 106, "endOffset": 127}, {"referenceID": 12, "context": "For this reason, several recently proposed algorithms focus on correctly ranking the best instances (Rudin, 2009; Agarwal, 2011).", "startOffset": 100, "endOffset": 128}, {"referenceID": 0, "context": "For this reason, several recently proposed algorithms focus on correctly ranking the best instances (Rudin, 2009; Agarwal, 2011).", "startOffset": 100, "endOffset": 128}, {"referenceID": 8, "context": "To the best of our knowledge, very few works have addressed the problem of feature selection in ranking (Geng et al., 2007) and in ranking on top of the list problems.", "startOffset": 104, "endOffset": 123}, {"referenceID": 11, "context": "We focus on the recent p-norm push loss function introduced by Rudin (2009) and more specifically, on the case where p = \u221e, denoted as an infinite push framework by Agarwal (2011).", "startOffset": 63, "endOffset": 76}, {"referenceID": 0, "context": "We focus on the recent p-norm push loss function introduced by Rudin (2009) and more specifically, on the case where p = \u221e, denoted as an infinite push framework by Agarwal (2011). In this latter work, Agarwal (2011) has also proposed a support vector like algorithm, named as support vector Infinite Push, which has been proved to perform better than competitors when the goal is to maximize the number of", "startOffset": 165, "endOffset": 180}, {"referenceID": 0, "context": "We focus on the recent p-norm push loss function introduced by Rudin (2009) and more specifically, on the case where p = \u221e, denoted as an infinite push framework by Agarwal (2011). In this latter work, Agarwal (2011) has also proposed a support vector like algorithm, named as support vector Infinite Push, which has been proved to perform better than competitors when the goal is to maximize the number of", "startOffset": 165, "endOffset": 217}, {"referenceID": 2, "context": "While typical methods dealing with sparsity suppose that the loss function is smooth (Bach et al., 2011), our optimization problem is challenging since both the loss function and the regularizer can be non-differentiable.", "startOffset": 85, "endOffset": 104}, {"referenceID": 15, "context": "Several extensions of this loss function have been recently considered in order to provide more importance to errors made on top of the lists, for instance by weighting the pairwise loss (Usunier et al., 2009) or by replacing the mean with some more appropriate functions.", "startOffset": 187, "endOffset": 209}, {"referenceID": 12, "context": "For this purpose, Rudin (2009) has introduced the Infinite Push loss function", "startOffset": 18, "endOffset": 31}, {"referenceID": 12, "context": "We can mention for instance the relaxation by means of exponential loss that yield to boosting-like algorithm (Rudin, 2009).", "startOffset": 110, "endOffset": 123}, {"referenceID": 0, "context": "The algorithm is based on a nice and clever gradient projection algorithm (Agarwal, 2011).", "startOffset": 74, "endOffset": 89}, {"referenceID": 0, "context": "Conversely, when considering the dual problem (3) as in Agarwal (2011), this property may be lost.", "startOffset": 56, "endOffset": 71}, {"referenceID": 2, "context": "where \u03a9(w) can be any sparsity inducing norm like the l1 norm, any mixed-norm (Bach et al., 2011) or the classical l2 regularization term.", "startOffset": 78, "endOffset": 97}, {"referenceID": 14, "context": "Before providing algorithmic details, we state here a proposition based on the work of Tseng (2001) that guarantees the soundness of the BCD algorithm.", "startOffset": 87, "endOffset": 100}, {"referenceID": 14, "context": "1 of Tseng (2001) concludes the proof.", "startOffset": 5, "endOffset": 18}, {"referenceID": 13, "context": "For solving this problem, we use classical result from convex analysis and proximal operator (Combettes & Wajs, 2005; Sra, 2011), which states that the proximal operator of a norm \u2016 \u00b7 \u2016 is", "startOffset": 93, "endOffset": 128}, {"referenceID": 11, "context": "This problem is easily tractable since projection of vector on a l1 \u2212 \u221e ball has been recently studied and several efficient algorithms proposed (Quattoni et al., 2009; Sra, 2011).", "startOffset": 145, "endOffset": 179}, {"referenceID": 13, "context": "This problem is easily tractable since projection of vector on a l1 \u2212 \u221e ball has been recently studied and several efficient algorithms proposed (Quattoni et al., 2009; Sra, 2011).", "startOffset": 145, "endOffset": 179}, {"referenceID": 11, "context": "the l1 \u2212 l\u221e ball of Quattoni et al. (2009) has a complexity of O(n log n) in the size of the vector to project.", "startOffset": 20, "endOffset": 43}, {"referenceID": 0, "context": "Note that we have not compared our methods to other ranking algorithms, except SVMRank (Chapelle & Keerthi, 2010), since Agarwal (2011) has already shown the superiority of the infinite push model on other methods for ranking positive instances on top of the list and because these methods such as SVMMAP does not have their sparse counterpart in the literature.", "startOffset": 121, "endOffset": 136}, {"referenceID": 9, "context": "Our RFE implementation follows exactly the same procedure as the one used for SVM RFE (Guyon et al., 2002), but replacing the SVM with the infinite push algorithm as proposed by Agarwal (2011).", "startOffset": 86, "endOffset": 106}, {"referenceID": 0, "context": ", 2002), but replacing the SVM with the infinite push algorithm as proposed by Agarwal (2011). This infinite push RFE bears strong resemblance with the backward elimination of Geng et al.", "startOffset": 79, "endOffset": 94}, {"referenceID": 0, "context": ", 2002), but replacing the SVM with the infinite push algorithm as proposed by Agarwal (2011). This infinite push RFE bears strong resemblance with the backward elimination of Geng et al. (2007). For a baseline comparison, we have also included an l1 SVM Rank.", "startOffset": 79, "endOffset": 195}, {"referenceID": 16, "context": "This is a well known issue of the l1 norm that can be overcome using an adaptive approach (Zou, 2006).", "startOffset": 90, "endOffset": 101}], "year": 2012, "abstractText": "In this paper, we address the problem of embedded feature selection for ranking on top of the list problems. We pose this problem as a regularized empirical risk minimization with p-norm push loss function (p = \u221e) and sparsity inducing regularizers. We leverage the issues related to this challenging optimization problem by considering an alternating direction method of multipliers algorithm which is built upon proximal operators of the loss function and the regularizer. Our main technical contribution is thus to provide a numerical scheme for computing the infinite push loss function proximal operator. Experimental results on toy, DNA microarray and BCI problems show how our novel algorithm compares favorably to competitors for ranking on top while using fewer variables in the scoring function.", "creator": "LaTeX with hyperref package"}}}