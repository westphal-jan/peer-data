{"id": "1211.2399", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Nov-2012", "title": "Mining Determinism in Human Strategic Behavior", "abstract": "this work runs amongst other fusion field experimental planning and data mining. it superseded author's previous work on military behaviour independent of human subjects from experimental data, where game - theoretic studies partially fail to work. game - theoretic predictions aka equilibria only tend to success with experienced subjects on binary games, what is rarely given. apart inside game theory, contemporary experimental economics offers a number of alternative models. over relevant literature, these models are always biased by psychological and near - psychological theories and are claimed to be proven by the data. this work introduces a data mining approach to the problem without using vast psychological background. apart from determinism, no other biases prove addressed. two datasets from different human subject experiments separately taken for evaluation. the first one is a repeated mixed strategy zero sum game and the second - repeated ultimatum game. as result, the way of mining deterministic regularities in human strategic behaviour is reported and recorded. as future work, the behavior from a new representation table is discussed.", "histories": [["v1", "Sun, 11 Nov 2012 11:27:01 GMT  (10kb)", "http://arxiv.org/abs/1211.2399v1", "8 pages, no figures, EEML 2012"]], "COMMENTS": "8 pages, no figures, EEML 2012", "reviews": [], "SUBJECTS": "cs.GT cs.AI", "authors": ["rustam tagiew"], "accepted": false, "id": "1211.2399"}, "pdf": {"name": "1211.2399.pdf", "metadata": {"source": "CRF", "title": "Mining Determinism in Human Strategic Behavior", "authors": ["Rustam Tagiew"], "emails": ["tagiew@informatik.tu-freiberg.de"], "sections": [{"heading": null, "text": "ar X\niv :1\n21 1.\n23 99\nv1 [\ncs .G\nT ]\n1 1\nN ov\n2 01\nKeywords: Game Theory, Psychology, Data Mining, Artificial Intelligence, DomainSpecific Languages"}, {"heading": "1 Introduction", "text": "Game theory is one of many scientific disciplines predicting outcomes of social, economical and competitive interactions among humans on the granularity level of individual decisions [1, p.4]. People are assumed to be autonomous and intelligent, and to decide according to their preferences. People can be regarded as rational, if they always make decisions, whose execution has according to their subjective estimation the most preferred consequences [2,3]. The correctness of subjective estimation depends on the level of intelligence. Rationality can justify own decisions and predictions of other people\u2019s decisions. If interacting people satisfy the concept of rationality and apply mutually and even recursively this concept, then the interaction is called strategic interaction (SI). Further, game is a notion for the formal structure of a concrete SI [4]. A definition of a game consists of a number of players, their legal actions and players\u2019 preferences. The preferences can be replaced by a payoff function under assumed payoff maximization. The payoff function defines each player\u2019s outcome depending on his actions, other players\u2019 actions and random events in the environment. The game-theoretic solution of a game is a prediction about the behavior of the players aka an equilibrium. The assumption of rationality is the basis for an equilibrium. Deviating from an equilibrium is beyond rationality, because it does not maximize the payoff. Not every game has an\nequilibrium. However, there is at least one mixed strategies equilibrium (MSE) in finite games [5].\nThe notion of game is commonly used for pleasant time spending activities like board games, but can also be extended to all social, economical and competitive interactions among humans. A board game can have the same game structure as a war. Some board games are even developed to train people, like Prussian army war game \u201dKriegspiel Chess\u201d [6] for officers. We like it to train ourselves in order to perform better in games [7]. In most cases, common human behavior in games deviates from game-theoretic predictions [8,9]. One can say without any doubt that if a human player is trained in a concrete game, he will perform close to equilibrium. But, a chess master does not also play poker perfectly and vice versa. On the other side, a game-theorist can find a way to compute an equilibrium for a game, but it does not make a successful player out of him. There are many games we can play; for most of them, we are not trained. That is why it is more important to investigate our behavior while playing general games than playing a concrete game on expert level. Conducting experiments for gathering data of human game playing is called experimental economics.\nAlthough general human preferences are a subject of philosophical discussions [10], game theory assumes that they can be captured as required for modeling rationality. Regarding people as rational agents is disputed at least in psychology, where even a scientifically accessible argumentation exposes the existence of stable and consistent human preferences as a myth [11]. The problems of human rationality can not be explained by bounded cognitive abilities only. \u201dBritish people argue that it is worth spending billions of pounds to improve the safety of the rail system. However, the same people habitually travel by car rather than by train, even though traveling by car is approximately 30 times more dangerous than by train!\u201d[12, p.527\u2013530] Since the last six decades nevertheless, the common scientific standards for econometric experiments are that subjects\u2019 preferences over outcomes can be insured by paying differing amounts of money [13]. However, insuring preferences by money is criticized by the term \u201dHomo Economicus\u201d as well.\nThe ability of modeling other people\u2019s rationality and reasoning as well corresponds with the psychological term \u201dTheory of Mind\u201d (ToM) [14], which lacks almost only in the cases of autism. For experimental economics, subjects as well as researchers, who both are supposed to be non-autistic people, may fail in modeling of others\u2019 minds anyway. In Wason task at least, subjects\u2019 reasoning does not match the researchers\u2019 one [15]. Human rationality is not restricted to capability for science-grade logical reasoning \u2013 rational people may use no logic at all [16]. However, people also mistake seriously in the calculus of probabilities [17]. In mixed strategy games, the required sequence of random decisions can not be properly generated by people [18]. Due to bounded cognitive abilities, every \u201drandom\u201d decision depends on previous ones and is predictable in this way. In ultimatum games [9, S. 43ff], the economists\u2019 misconception of human preferences is revealed \u2013 people\u2019s minds value fairness additionally to personal enrichment. Our minds originated from the time, when private property had not been invented and social values like fairness were essential for survival.\nThis work concentrates on human playing of general games and continues author\u2019s previous work [19]. It is about the common human deviations from predicted equilibria\nin games, for which they are not trained or experienced. The two examples introduced in this work are a repeated mixed strategy zero sum game and a repeated ultimatum game from responders\u2019 perspective. The only assumption is the existence of deterministic rules in human behavior. Under this assumption, diverse data mining algorithms are evaluated. Apart from mining deterministic regularities, modeling human behavior in general games needs a representation formalism which is not specific to a concrete game. Representing human behavior models in such a formalism would increase their comparability. Therefore, this paper includes a general formalism discussion, where results from the evaluation are involved.\nThe next section summarizes related work on a formalism for human behavior in games. Then, the data mining approach on datasets is presented afterwards. Summary and discussion conclude this paper."}, {"heading": "2 Related Work", "text": "A very comprehensive gathering of works in experimental psychology and economics on human behavior in general games can be found in [9]. This work inspired research in artificial intelligence [20], which led to the creation of network of influence diagrams (NID) as a representation formalism. NID is a formalism similar to the possible worlds semantics of Kripke models [21] and is a super-set of Bayesian games. The main idea of NID is modeling human reasoning patterns in diverse SIs. Every node of a NID is a multi-agent influence diagram (MAID) representing a model of SI of an agent. MAID is an influence diagram (ID), where every decision node is associated with an agent. ID is a Bayesian network (BN), where one has ordinary nodes, decision nodes and utility nodes. In summary, this approach assumes that human decision making can be modeled using BN \u2013 human reasoning is assumed to have a non-deterministic structure. This formalism is already applied for modeling reciprocity in a repeated ultimatum game called \u201dColored Trails\u201d (CT) [22]. The result of this work is that models of adaptation to human behavior based on BNs perform better than standard game theoretical algorithms.\nAnother independent work is an application of a cognitive architecture from psychology to games [23]. A cognitive architecture is a formalism concerned to represent general human reasoning [24] in order to compare different models. Today\u2019s most popular cognitive architecture is ACT-R (Adaptive Control of Thought Rational) [25]. In comparison to NID, ACT-R is used for a number of psychological studies. ACT-R consists of two tiers \u2013 symbolic and sub-symbolic. On the symbolic tier, there are chunks \u2013 facts and \u201dIf-Then\u201d-rules. On the sub-symbolic tier, there are exponential functions, which determine activation levels of chunks, delays in reasoning and priorities between rules. Based on ACT-R, an almost deterministic model for a mixed strategy zero sum game \u201dRock Paper Scissors\u201d (RPS) is designed. The only case, in which the designed model predicts random behavior is the beginning of a game sequence. The model was successfully evaluated as a base for an artificial player, which won against human subjects.\nWhether deterministic or not, both works follow the same approach. First, they construct a model, which is based on theoretical considerations. Second, they adjust the\nparameters of this model to the experimental data. This makes the human behavior explainable using the concepts from the model, but needs a priori knowledge to construct the model."}, {"heading": "3 Used Datasets", "text": "The first dataset chosen for our data mining approach has already been mentioned in our previous work [19]. It is the game RPS played over a computer network. This game is easy to explain and most people do not train to play it on expert level; it is symmetric, zero sum and two player. The study was conducted on threads of 30 one-shot games. A player had a delay for consideration of 6 sec for every shot. If he did not react, the last or default gesture was chosen. A thread lasted 30 \u2217 6 sec = 3 min. This game has one mixed strategy equilibrium (MSE), which is an equal probability distribution between the three gestures. At least, one can not lose playing this MSE.\nTen computer science undergraduates were recruited. They were in average 22,7 years old and 7 of them were male. They had to play the thread twice against another test person. Between the two threads, they played other games. In this way, 300 oneshot games or 600 single human decisions are gathered. Every person got e 0.02 for a won one-shot game and e 0.01 for a draw. The persons, who played against each other, sat in two separate rooms. One of the players used a cyber-glove and the other one a mouse as input for gestures. The graphical user interface showed the following information - own last and actual choice, opponents last choice, a timer and already gained money. According to statements of the persons, they had no problems to understand the game rules and to choose a gesture timely. All winners and 80% of losers attested that they had fun to play the game.\nThe second dataset is the recorded responder behavior from the CT experiment [22]. This dataset contains 371 single human decisions of 25 participating subjects. A positive decision of the responder updates the monetary payoff of both players, while a negative one does not change anything. The payoff update varied between $1.45 and $-1.35 for the responder. In 160 cases, responders update was zero. The equilibrium for the responder is to accept only proposals, which increase his payoff regardless of the proposer\u2019s payoff."}, {"heading": "4 Methods", "text": "Statistical analysis of the datasets from the previous chapter exposed that the human behavior observed in the experiments can not be explained using only game theory [1]. The shape of equilibrium deviations confirms the one reported in relevant literature [9]. The goal is to find a model beyond game theory for the prediction of average deviations. In related work, the creation of a sophisticated model preceded the evaluation on the data. In this work, the evaluation on the data precedes the creation of a model. Of course, some people would not match into such a model like trained or somehow experienced individuals. Prediction of specific individuals is not addressed in this paper.\nMachine done prediction without participation in game playing with human subjects should not be confused with prediction algorithms of artificial players. Quite the contrary, artificial players can manipulate the predictability of human subjects by own behavior. For instance, an artificial player, which always throws \u201dPaper\u201d in RPS, would success at predicting a human opponent always throwing \u201dScissors\u201d in reaction. Otherwise, if an artificial player maximizes its payoff based on opponent modeling, it would face a change in human behavior and have to handle that. This case is more complex than a spectator prediction model for an \u201donly-humans\u201d interaction. This paper restricts on a prediction model without participating.\nHuman behavior can be modeled as either deterministic or non-deterministic. Although human subjects fail at generating truly random sequences as demanded by MSE, non-deterministic models are especially used in case of artificial players in order to handle uncertainties. \u201dSpecifically, people are poor at being random and poor at learning optimal move probabilities because they are instead trying to detect and exploit sequential dependencies. ... After all, even if people do not process game information in the manner suggested by the game theory player model, it may still be the case that across time and across individuals, human game playing can legitimately be viewed as (pseudo) randomly emitting moves according to certain probabilities.\u201d [23] In the addressed case of spectator prediction models, non-deterministic view can be regarded as too shallow, because deterministic models allow much more exact predictions. Nondeterministic models are only useful in cases, where a proper clarification of uncertainties is either impossible or costly. To remind, deterministic models should not be considered to obligatory have a formal logic shape.\nThe deterministic function HD(Game,History)\u2192 Decision denotes a human decision. History denotes the previous turns in the game. Game and History are the input and Decision \u2013 the output. Finding a hypothesis, which matches the regularity between input and output without a priori knowledge, is a typical problem called supervised learning [26]. There is already a big amount of algorithms for supervised learning. Each algorithm has its own hypothesis space (HS). For a Bayesian learner, e.g., the hypothesis space is the set of all possible Bayesian networks. There are many different types of hypothesis spaces - rules, decision trees, Bayesian models, functions and so on. Concrete hypothesis HDI is a relationship between input and output described by using the formal means of the corresponding hypothesis space.\nWhich hypothesis space is most appropriate to contain valid hypotheses about human behavior? This is a machine learning version of the question about a formalism for human behavior. The most appropriate hypothesis space contains the most correct hypothesis for every concrete example of human behavior. A correct hypothesis does not only perform well on the given data (training set), but it performs also well on new data (test set). Further, it can be assumed that the algorithms which choose a hypothesis perform alike well for all hypothesis spaces. For instance, a decision tree algorithm creates a tree, a neuronal algorithm creates a neuronal network and the distance between the created tree to the best possible tree is the same as the distance between the created neuronal network and the best possible neuronal network. This assumption is a useful simplification of the problem for a preliminary demonstration. Using it, one can consider the algorithm with the best performance on the given data as the algorithm with\nthe most appropriate hypothesis space. The standard method for measurement of performance of a machine learning algorithm or also a classifier is cross validation.\nAs it is already mentioned, a machine learning algorithm has to find hypothesis HDI which matches best the real human behavior function HD. Human decision making depends mostly on a small part of the history due to bounded resources. This means that one needs a simplification function S(History) \u2192 Pattern. Using function S the function HD(X ,Y ) is to be approximated through HDII(X ,S(Y)). The problem for finding the most appropriate hypothesis can be formulated in equation 1. The function match in equation 1 is considered to be implemented through a cross validation run.\nargmax HS ( max HDII\u2208HS\n(match(HD(X ,Y ),HDII(X ,S(Y ))))) (1)"}, {"heading": "5 Empirical Results", "text": "The first dataset is transformed to a sets of tuples, each one consists of three own previous gestures, three opponent previous gestures and own next gesture. Therefore, every tuple has the length 3+ 3+ 1 = 7. The simplification function is a window over three last turns. There are 2187 possible tuples for RPS. The decisions in the first three turns of game are not considered. Therefore, the size of the set results to 540 tuples. The second dataset is also transformed to a sets of 371 tuples, where every tuple includes the proposers payoff update, the responders payoff update and the responders boolean reply.\nImplementations of classifiers provided by WEKA [27] are used for the cross validation on the both sets of tuples. For the first dataset, there are currently 45 classifiers available in the WEKA library, which can handle multi-valued nominal classes. Gestures in RPS are nominal, because there is no order between them. These classifiers belong to different groups - rule-based, decision trees, function approximators, baysian learners, instance-based and miscellaneous. A cross validation of all 45 classifiers on RPS dataset is performed. For the CT dataset, a cross-validation of 35 appropriate classifiers is performed. The number of subsets for cross-validation is 10. Both cross-validation runs are conducted with preserving order of the tuples.\nSequential minimal optimization (SMO) [28] showed 46.48% prediction correctness, which is about 1% higher than the sophisticated non-deterministic model for RPS of Warglen [29]. Unfortunately, decreasing and increasing the window size in the function S for the RPS dataset diminishes the performance. Using the single rule classifier (OneR), one can find out that 43.15% of the RPS dataset matches the rule: \u201dChoose paper after rock, scissors after paper and rock after scissors\u201d. A number of classifiers including SMO achieve 95.42% correctness on the CT dataset in cross-validation. One of this algorithms is based on decission tables [30]. This algorithm finds out that 95.15% of the CT dataset conforms the rule: \u201dIf an acceptance does neither change your payoff nor improve the proposers payoff, then refuse!\u201d This result overperforms clearly the 72% reported from the non-deterministic approach of Pfeffer [22]."}, {"heading": "6 Conclusion", "text": "The strategic behavior consists out of the observable actions, whose origins are tried to be understood as generally as possible. Summarizing the results of this work, it can be said that SMO can find the most general deterministic hypothesis about regularities of human behavior in the investigated scenarios. The correctness of such a hypothesis overperforms the numbers reported in related work. The hypothesis space of SMO is one of complex functions and can be used for the design of a game behavior description formalism."}], "references": [{"title": "Strategische Interaktion realer Agenten: Ganzheitliche Konzeptualisierung und Softwarekomponenten einer interdisziplinren Forschungsinfrastruktur", "author": ["R. Tagiew"], "venue": "PhD thesis, TU Bergakademie Freiberg", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Artificial Intelligence", "author": ["S. Russel", "P. Norvig"], "venue": "Pearson Education", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2003}, {"title": "A course in game theory", "author": ["M.J. Osborne", "A. Rubinstein"], "venue": "MIT Press", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1994}, {"title": "Theory of Games and Economic Behavior", "author": ["O. Morgenstern", "J. von Neumann"], "venue": "Princeton University Press", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1944}, {"title": "Non-cooperative games", "author": ["J. Nash"], "venue": "Annals of Mathematics (54)", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1951}, {"title": "Kriegspiel: Chess Under Uncertainty", "author": ["D.H. Li"], "venue": "Premier", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1994}, {"title": "General game playing: Overview of the aaai competition", "author": ["M.R. Genesereth", "N. Love", "B. Pell"], "venue": "AI Magazine 26(2)", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2005}, {"title": "Putting game theory to the test", "author": ["R. Pool"], "venue": "Science 267", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1995}, {"title": "Behavioral Game Theory", "author": ["C.F. Camerer"], "venue": "Princeton University Press", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2003}, {"title": "Ten Theories of Human Nature", "author": ["L. Stevenson", "D.L. Haberman"], "venue": "OUP USA", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2004}, {"title": "Economics wins, psychology loses, and society pays", "author": ["M.H. Bazerman", "D. Malhotra"], "venue": "In De Cremer, D., Zeelenberg, M., Murnighan, J.K., eds.: Social Psychology and Economics. Lawrence Erlbaum Associates", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2006}, {"title": "Cognitive Psychology: A Student\u2019s Handbook", "author": ["M.W. Eysenck", "M.T. Keane"], "venue": "Psychology Press", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2005}, {"title": "An experimental imperfect market", "author": ["E.H. Chamberlin"], "venue": "Journal of Political Economy 56", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1948}, {"title": "Learning to apply theory of mind", "author": ["R. Verbrugge", "L. Mol"], "venue": "Journal of Logic, Language and Information 17", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2008}, {"title": "Reasoning", "author": ["P.C. Wason"], "venue": "In Foss, B.M., ed.: New horizons in psychology. Penguin Books", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1966}, {"title": "The probabilistic approach to human reasoning", "author": ["M. Oaksford", "N. Chater"], "venue": "Trends in Cognitive Sciences 5", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2001}, {"title": "Judgment Under Uncertainty: Heuristics and Biases", "author": ["D. Kahneman", "P. Slovic", "A. Tversky"], "venue": "Cambridge University Press", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1982}, {"title": "Not that bad after all: Generation of random sequences", "author": ["Y. Kareev"], "venue": "Journal of Experimental Psychology: Human Percetion and Performance 18", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1992}, {"title": "Hypotheses about typical general human strategic behavior in a concrete case", "author": ["R. Tagiew"], "venue": "AI*IA, Springer", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "A language for modeling agents\u2019 decision making processes in games", "author": ["Y. Gal", "A. Pfeffer"], "venue": "AAMAS, ACM Press", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2003}, {"title": "Semantical considerations on modal logic", "author": ["S. Kripke"], "venue": "Acta Philosophica Fennica 16", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1963}, {"title": "Modeling reciprocal behavior in human bilateral negotiation", "author": ["Y. Gal", "A. Pfeffer"], "venue": "AAAI, AAAI Press", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2007}, {"title": "Cognitive modeling versus game theory: Why cognition matters", "author": ["M.F. Rutledge-Taylor", "R.L. West"], "venue": "ICCM.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2004}, {"title": "Background, structure, and preview of the model comparison", "author": ["K.A. Gluck", "R.W. Pew", "M.J. Young"], "venue": "In Gluck, K.A., Pew, R.W., eds.: Modeling Human Behavior with Integrated Cognitive Architectures. Lawrence Erlbaum Associates", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2005}, {"title": "Machine Learning", "author": ["T.M. Mitchell"], "venue": "McGraw-Hill Higher Education", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1997}, {"title": "Data Mining", "author": ["I.H. Witten", "E. Frank"], "venue": "Morgan Kaufmann", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2005}, {"title": "Fast training of support vector machines using sequential minimal optimization", "author": ["J.C. Platt"], "venue": "Advances in Kernel Methods - Support Vector Learning, MIT Press", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1999}, {"title": "Predicting human interactive learning by regret-driven neural networks", "author": ["D. Marchiori", "M. Warglien"], "venue": "Science 319", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2008}, {"title": "The power of decision tables", "author": ["R. Kohavi"], "venue": "ECML, Springer", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1995}], "referenceMentions": [{"referenceID": 1, "context": "People can be regarded as rational, if they always make decisions, whose execution has according to their subjective estimation the most preferred consequences [2,3].", "startOffset": 160, "endOffset": 165}, {"referenceID": 2, "context": "People can be regarded as rational, if they always make decisions, whose execution has according to their subjective estimation the most preferred consequences [2,3].", "startOffset": 160, "endOffset": 165}, {"referenceID": 3, "context": "Further, game is a notion for the formal structure of a concrete SI [4].", "startOffset": 68, "endOffset": 71}, {"referenceID": 4, "context": "However, there is at least one mixed strategies equilibrium (MSE) in finite games [5].", "startOffset": 82, "endOffset": 85}, {"referenceID": 5, "context": "Some board games are even developed to train people, like Prussian army war game \u201dKriegspiel Chess\u201d [6] for officers.", "startOffset": 100, "endOffset": 103}, {"referenceID": 6, "context": "We like it to train ourselves in order to perform better in games [7].", "startOffset": 66, "endOffset": 69}, {"referenceID": 7, "context": "In most cases, common human behavior in games deviates from game-theoretic predictions [8,9].", "startOffset": 87, "endOffset": 92}, {"referenceID": 8, "context": "In most cases, common human behavior in games deviates from game-theoretic predictions [8,9].", "startOffset": 87, "endOffset": 92}, {"referenceID": 9, "context": "Although general human preferences are a subject of philosophical discussions [10], game theory assumes that they can be captured as required for modeling rationality.", "startOffset": 78, "endOffset": 82}, {"referenceID": 10, "context": "Regarding people as rational agents is disputed at least in psychology, where even a scientifically accessible argumentation exposes the existence of stable and consistent human preferences as a myth [11].", "startOffset": 200, "endOffset": 204}, {"referenceID": 12, "context": "527\u2013530] Since the last six decades nevertheless, the common scientific standards for econometric experiments are that subjects\u2019 preferences over outcomes can be insured by paying differing amounts of money [13].", "startOffset": 207, "endOffset": 211}, {"referenceID": 13, "context": "The ability of modeling other people\u2019s rationality and reasoning as well corresponds with the psychological term \u201dTheory of Mind\u201d (ToM) [14], which lacks almost only in the cases of autism.", "startOffset": 136, "endOffset": 140}, {"referenceID": 14, "context": "In Wason task at least, subjects\u2019 reasoning does not match the researchers\u2019 one [15].", "startOffset": 80, "endOffset": 84}, {"referenceID": 15, "context": "Human rationality is not restricted to capability for science-grade logical reasoning \u2013 rational people may use no logic at all [16].", "startOffset": 128, "endOffset": 132}, {"referenceID": 16, "context": "However, people also mistake seriously in the calculus of probabilities [17].", "startOffset": 72, "endOffset": 76}, {"referenceID": 17, "context": "In mixed strategy games, the required sequence of random decisions can not be properly generated by people [18].", "startOffset": 107, "endOffset": 111}, {"referenceID": 18, "context": "This work concentrates on human playing of general games and continues author\u2019s previous work [19].", "startOffset": 94, "endOffset": 98}, {"referenceID": 8, "context": "A very comprehensive gathering of works in experimental psychology and economics on human behavior in general games can be found in [9].", "startOffset": 132, "endOffset": 135}, {"referenceID": 19, "context": "This work inspired research in artificial intelligence [20], which led to the creation of network of influence diagrams (NID) as a representation formalism.", "startOffset": 55, "endOffset": 59}, {"referenceID": 20, "context": "NID is a formalism similar to the possible worlds semantics of Kripke models [21] and is a super-set of Bayesian games.", "startOffset": 77, "endOffset": 81}, {"referenceID": 21, "context": "This formalism is already applied for modeling reciprocity in a repeated ultimatum game called \u201dColored Trails\u201d (CT) [22].", "startOffset": 117, "endOffset": 121}, {"referenceID": 22, "context": "Another independent work is an application of a cognitive architecture from psychology to games [23].", "startOffset": 96, "endOffset": 100}, {"referenceID": 23, "context": "A cognitive architecture is a formalism concerned to represent general human reasoning [24] in order to compare different models.", "startOffset": 87, "endOffset": 91}, {"referenceID": 18, "context": "The first dataset chosen for our data mining approach has already been mentioned in our previous work [19].", "startOffset": 102, "endOffset": 106}, {"referenceID": 21, "context": "The second dataset is the recorded responder behavior from the CT experiment [22].", "startOffset": 77, "endOffset": 81}, {"referenceID": 0, "context": "Statistical analysis of the datasets from the previous chapter exposed that the human behavior observed in the experiments can not be explained using only game theory [1].", "startOffset": 167, "endOffset": 170}, {"referenceID": 8, "context": "The shape of equilibrium deviations confirms the one reported in relevant literature [9].", "startOffset": 85, "endOffset": 88}, {"referenceID": 22, "context": "\u201d [23] In the addressed case of spectator prediction models, non-deterministic view can be regarded as too shallow, because deterministic models allow much more exact predictions.", "startOffset": 2, "endOffset": 6}, {"referenceID": 24, "context": "Finding a hypothesis, which matches the regularity between input and output without a priori knowledge, is a typical problem called supervised learning [26].", "startOffset": 152, "endOffset": 156}, {"referenceID": 25, "context": "Implementations of classifiers provided by WEKA [27] are used for the cross validation on the both sets of tuples.", "startOffset": 48, "endOffset": 52}, {"referenceID": 26, "context": "Sequential minimal optimization (SMO) [28] showed 46.", "startOffset": 38, "endOffset": 42}, {"referenceID": 27, "context": "48% prediction correctness, which is about 1% higher than the sophisticated non-deterministic model for RPS of Warglen [29].", "startOffset": 119, "endOffset": 123}, {"referenceID": 28, "context": "One of this algorithms is based on decission tables [30].", "startOffset": 52, "endOffset": 56}, {"referenceID": 21, "context": "15% of the CT dataset conforms the rule: \u201dIf an acceptance does neither change your payoff nor improve the proposers payoff, then refuse!\u201d This result overperforms clearly the 72% reported from the non-deterministic approach of Pfeffer [22].", "startOffset": 236, "endOffset": 240}], "year": 2012, "abstractText": "This work lies in the fusion of experimental economics and data mining. It continues author\u2019s previous work on mining behavior rules of human subjects from experimental data, where game-theoretic predictions partially fail to work. Game-theoretic predictions aka equilibria only tend to success with experienced subjects on specific games, what is rarely given. Apart from game theory, contemporary experimental economics offers a number of alternative models. In relevant literature, these models are always biased by psychological and nearpsychological theories and are claimed to be proven by the data. This work introduces a data mining approach to the problem without using vast psychological background. Apart from determinism, no other biases are regarded. Two datasets from different human subject experiments are taken for evaluation. The first one is a repeated mixed strategy zero sum game and the second \u2013 repeated ultimatum game. As result, the way of mining deterministic regularities in human strategic behavior is described and evaluated. As future work, the design of a new representation formalism is discussed.", "creator": "LaTeX with hyperref package"}}}