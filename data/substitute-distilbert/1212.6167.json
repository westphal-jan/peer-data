{"id": "1212.6167", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Dec-2012", "title": "Transfer Learning Using Logistic Regression in Credit Scoring", "abstract": "the credit requests risk optimization is a fast growing idea due to consumer'overwhelming acceptance requests. credit requests, of new and existing customers, are often evaluated by detailed discrimination rules based on customers information. however, these kinds of strategies have serious limits and strength't take into account the technological difference between current customers and the future ones. the aim of this paper is to assess credit worthiness over non customers borrowers and to model potential risk given a heterogeneous population formed by particular customers of the bank and businesses who are not. adherents agree on previous works done in generalized gaussian discrimination and transpose them into the logistic model to bring out efficient discrimination rules for non customers'subpopulation.", "histories": [["v1", "Wed, 26 Dec 2012 12:03:26 GMT  (105kb,D)", "http://arxiv.org/abs/1212.6167v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CE", "authors": ["farid beninel", "waad bouaguel", "ghazi belmufti"], "accepted": false, "id": "1212.6167"}, "pdf": {"name": "1212.6167.pdf", "metadata": {"source": "CRF", "title": "Transfer Learning Using Logistic Regression in Credit Scoring", "authors": ["Farid Beninel", "Waad Bouaguel", "Ghazi Belmufti"], "emails": ["farid.beninel@ensai.fr", "bouaguelwaad@mailpost.tn,", "belmufti@yahoo.com"], "sections": [{"heading": "1 Introduction", "text": "The credit risk is one of the major risks that a loans institution has to manage. This risk arises when a borrower doesn\u0160t pay his debt in the fixed due. To face up this kind of risk, banks\u2019 managers have to look for efficient solutions to well distinguish good from bad risk applicant. Credit scoring is one of the most successful financial risk management solutions developed for lending institutions, this solution has been fundamental in consumer credit management since Durand (1941). Authors like Feldman (1997), Thomas et al. (2002) and Saporta (2006) defined the Credit scoring as the process of determining how likely a particular applicant is default with reimbursement. Credit scoring methods are applied in order to classify possible creditors in two classes of risk: good and bad (Giudici, 2003). These methods use explanatory variables obtained from applicant information to estimate his intended performance to pay back loan. A large number ar X iv :1\n21 2.\n61 67\nv1 [\ncs .L\nG ]\n2 6\nof Transfer Learning Using Logistic Regression in Credit Scoring classification methods can be used in the process of identifying borrowers\u0160 behavior as decision trees (Breiman et al., 1984), neural networks (Mcculloch and Pitts, 1943), discriminant analysis (Fisher, 1936; Mahalanobis, 1936), logistic regression (Cox, 1970; Cox and Snell, 1989) . . .\nBoth these techniques can provide good discrimination but the most common used methods for building scorecard (i.e. credit models) are discriminant analysis and logistic regression. Logistic regression is a more appropriate technique for Credit scoring cases (Henley and Hand, 1996). Fan and Wang (1998) and Sautory et al. (1992) recommend the use of the binary logistic regression in Credit scoring cases, when discriminant analysis application conditions are not obtainable. This choice becomes imperative if qualitative variables get involved in the model (Bardos, 2001).\nAvailable information about credit candidate supplies a fundamental element in his credit request acceptation, information lack in credit risk valorization is suspected to lead to wrong decision making. In this paper, we will focus in Credit scoring evaluation, using logistic regression technique when the population of interest is characterized by a small size.\nBorrower\u2019s behavior is described by a binary target variable denoted Y , value taken by this last one supplies a basic element in credits\u2019 granting decision, Y = 0 when the borrower presents problem and Y = 1 otherwise. Beside this variable, every borrower is also described by a set of description variables (X1, X2, . . . , Xd) informing about the borrower and about his accounts\u2019 functioning.\nThe sample of loans\u2019 applicants results from a heterogeneous population formed by borrowers customers and others who are not. Here we deal with the problem of discrimination in the case of a subpopulations\u2019 mixture, where the two subpopulations are respectively: borrowers\u2019 customers and borrowers\u2019 non customers. More precisely, we will focus in non customers subpopulation credit worthiness evaluation, assuming that sample size of this subpopulation is considered weak.\nBeginning with the hypothesis that population size is one of the most important factors affecting the classification power of the logistic regression technique, we evaluate future customers (i.e non customer) behavior to pay back loan, by looking for efficient solution to the problem of non customers small sample size.\nWe proceed to investigate how using the information on hand of borrowers customers and non customers can be efficient. The first approach, which is generally used by banks, consists in using the borrowers customers predictive model, to predict borrowers non customers behavior. However, it does not take into account, difference between the two subpopulations. Another approach consists in using a learning sample resulting from non customers\u0160 subpopulation to build their predictive model. However, this second approach needs a learning sample of a suitable size, which is not our case.\nChanging the second approach can bring an efficient solution to the problem of learning from small size sample. This change consists in using a design sample, drown from another population considered slightly different (e.g. customers\u0160 subpopulation), this sample will be used in models building in place of non customers design sample. The idea of using two slightly populations for estimating one population parameters, has been first proposed by Biernacki et al. (2002). In a multinomial context, Biernacki et al. (2002) proved that two slightly different populations are linked through linear relations. Estimation of nonlabeled sample\nallocation rules was obtained via estimating the linear relationship parameters, using five constraints models on the linear relationships. This approach proved to be efficient in biological context and many extension of this paper was proposed, including Biernacki and Jacques (2007), Bouveyron and Jacques (2009) as well as Beninel and Biernacki (2005, 2007, 2009). Beninel and Biernacki (2009) extended this approach to the multinomial logistic discrimination and proposed an additional links\u2019 model in the case where the two studied subpopulation are two Gaussian ones. The main idea of this previous works is that information related to one of the two subpopulations contains some information related to the other one. The earlier works, have been the exit of the main thoughts of this paper, given previous results in the case of Gaussian mixture model and the six presented models by Beninel and Biernacki (2009), our task is then, to go in deep in the previous results with more testes and simulations, and to add to the former links\u2019 models a seventh one."}, {"heading": "2 Logistic Regression Model", "text": ""}, {"heading": "2.1 Classical Logistic Regression", "text": "Logistic regression is a variant of linear regression, which is used when the dependent variable is a binary variable and the independent variables are continuous, categorical, or both. Logistic regression model supplies a linear function of descriptors as discrimination tool, this technique is widely used in Credit scoring applications due to its simplicity and explainability. Model form is given by\nlog( pi\n1\u2212 pi ) = \u03b20 + \u03b2\nTxi, (1)\nwhere \u2013 pi is the posteriori probability, defined as the probability that an individual i have the\nmodality 1 for given values taken by descriptors (i.e. P (Yi = 1|xi)). \u2013 xi = (x1i ,x 2 i , . . . ,x d i ) is the vector of observed value taking by description variables. \u2013 \u03b2T = (\u03b21, \u03b22, . . . , \u03b2d) is the vector of variables effect. \u2013 \u03b20 is the intercept.\nThis technique serves to estimate the posteriori probability pi, which the value allows to assign every borrower to his group membership i.e., {Yi = 1} if pi is greater than a fixed threshold value and {Yi = 0} otherwise."}, {"heading": "2.2 Mixture Logistic Regression", "text": "Let us remind that we deal with the problem of discrimination in case of subpopulations\u2019 mixture, where the two subpopulations of interests are the subpopulation of borrowers customers and the subpopulation of borrowers non customers, denoted respectively \u2126 and \u2126\u2217, for which we associate the two following posteriori probability p and p\u2217. Our purpose is the prediction of the solvency of borrowers\u2019 non customers using the information on hand of the two subpopulations.\nGiven two learning samples SA = {(xi, Yi) : i = 1, ..., n} and S\u2217A = {(x\u2217i , Y \u2217i ) : i = 1, ..., n\u2217}, where the pairs (xi, Yi) and (x\u2217i , Y \u2217i ) are independent and identically distributed (i.i.d.) realizations of the random couples (x, Y ) and (x\u2217, Y \u2217), we consider the logistic model over \u2126, as given by\npi = P (Yi = 1|xi, \u03b8) = exp\u03b20+\u03b2\nTxi\n1 + exp\u03b20+\u03b2Txi , (2)\nand over \u2126\u2217\np\u2217i = P (Y \u2217 i = 1|x\u2217i , \u03b8\u2217) =\nexp\u03b2 \u2217 0+\u03b2 \u2217Tx\u2217i\n1 + exp\u03b2 \u2217 0+\u03b2 \u2217Tx\u2217i , (3)\nwhere \u2013 \u03b8 = {(\u03b20||\u03b2T ) \u2208 Rd+1} and \u03b8\u2217 = {(\u03b2\u22170 ||\u03b2\u2217T ) \u2208 Rd+1} are the sets of all parameters\nto be estimated respectively over \u2126 and \u2126\u2217. \u2013 (\u03b20||\u03b2T ) and (\u03b2\u22170 ||\u03b2\u2217T ) are the concatenations of the intercept and the vector of vari-\nables effect over \u2126 and \u2126\u2217. The mixture model allows the resolution of various discrimination problems, in our case we assume that an experienced rule, to predict on the first subpopulation \u2126 is known and we have a small learning sample from the second subpopulations \u2126\u2217. From available data we want to get a new allocation rule over \u2126\u2217. According to Beninel and Biernacki (2009) links between subpopulations could exist and consequently, information on \u2126 could provide some information on \u2126\u2217. Existence of a link between variables vector implies a link between the two scores functions given in (2.2) and (2.2). Using acceptable links between the scores functions of the two subpopulations allows to use hidden information of samples S\u2217L and SL to get the allocations rules over \u2126\n\u2217. We look in what follows for these links basing on results found in Gaussian case."}, {"heading": "3 Gaussian Case and Links Models", "text": "In order to estimate the score function parameters over \u2126\u2217, we use the data on hand of the two subpopulations. The use of customer subpopulation \u2126 data aims to moderate the small size of the subpopulation \u2126\u2217 of non customers, by supposing the existence of hidden links between the distribution of variables over \u2126 and that over \u2126\u2217. It\u2019s known from Beninel and Biernacki (2007) as well as Bouveyron and Jacques (2009) that existence of particular connections between the variables distributions lead to relations between the parameters of their respective logistic regression models, consequently our task consists in finding these links. In this context a preliminary case study was successfully done in Gaussian multivariate case Beninel and Biernacki (2005). It is a question here of extending the found results in Gaussian case to logistic case, which leads to simple and parsimonious linking models between the parameters of logistic classification rules associated respectively to the two subpopulations \u2126 and \u2126\u2217."}, {"heading": "3.1 Gaussian Case: Subpopulations Links", "text": "In Gaussian discrimination, it is crucial to define handled data in terms of two samples: a learning sample L and a prediction sample P , resulting respectively from the following subpopulations: \u2126 and \u2126\u2217. In our case these two subpopulations are different.\nThe learning sample L is composed of n pairs (xi, Yi), i = 1, . . . , n where, xi is a vector of Rd representing the numeric characteristics describing the individual i and Yi is his group\u2019s label. The n pairs (xi, Yi) are supposed to be i.i.d realizations of the random couple (x, Y ) defined over \u2126 by the following joint distribution:\nx|Y=k \u223cNd(\u00b5k,\u03a3k) k = {1, ...,K} and\nY \u223cMK(1, \u03c01, ..., \u03c0K), (4)\nwhere Nd(\u00b5k,\u03a3k) is the Gaussians distributions of dimension d, with an average \u00b5k and a variance-covariance matrix \u03a3k. MK(1, \u03c01, ..., \u03c0K) is the multinomial distribution of parameters \u03c01, ..., \u03c0K , where \u03c0k is the proportion of the group k in the subpopulation and the parameter K represents modality of the target variable Y .\nThe prediction sample P consists of n\u2217 individuals, which we know their numeric characteristics x\u2217i , i = 1, ..., n \u2217, assumed the same over L. The n\u2217 labels Y \u22171 , . . . , Y \u2217 n\u2217 are to be estimated. The n\u2217 pairs (x\u2217i , Y \u2217 i ) are supposed to be i.i.d realizations of the random couple (x, Y ) defined over \u2126\u2217 by the following joint distribution:\nx\u2217|Y \u2217=k \u223cNd(\u00b5 \u2217 k,\u03a3 \u2217 k), k = {1, ...,K} and Y \u2217 \u223cMK(1, \u03c0\u22171 , ..., \u03c0\u2217K).\n(5)\nThen, we try to estimate the n\u2217 unknown labels by using resulting information from the samples L and P . Our task is then, to identify acceptable relations linking the two subpopulations. In order to bring to light the existing links between the two subpopulations, we are going to adopt the approach proposed by Beninel and Biernacki Beninel and Biernacki (2009), which supposes the existence of an application \u03c6k : Rd \u2192 Rd linking in law the random variables vectors of \u2126 and \u2126\u2217. Then\nx\u2217|Y \u2217=k \u223c \u03c6k(x|Y=k) = [\u03c6k1(x|Y=k), ..., \u03c6kd(x|Y=k)] T . (6)\nThe outcomes resulting from Beninel and Biernacki (2009) verify that the function \u03c6k is affine, we drive from equation (6) the following relations between the variables distributions:\nx\u2217|Y \u2217=k \u223c \u039bkx|Y=k + \u03b1k, (7)\nwhere \u039bk is a diagonal matrix defined over Rd\u00d7d and \u03b1k is a vector of Rd. From the previous expression we deduct this following links between the parameters of two subpopulations\n\u00b5\u2217k = \u039bk\u00b5k + \u03b1k, (8) \u03a3\u2217k = \u039bk\u03a3k\u039bk. (9)"}, {"heading": "3.2 Gaussian Case Extended to Logistic Case", "text": "Anderson (1982) proved the existence of a link between the parameters of the mixture Gaussian model and those of corresponding logistic model. Links between the two subpopulations can be obtained in a stochastic case where, the variables vector x and x\u2217 defined over \u2126 and \u2126\u2217 are Gaussian, homoscedastic conditionally in the groups and the matrices of common variance-covariance are noted in the following way:\n\u03a3 = \u03a31 = \u03a32and\u03a3 \u2217 = \u03a3\u22171 = \u03a3 \u2217 2, (10)\nwe obtain the following links between the logistic parameters and the Gaussian one for the two subpopulations: over \u2126,\n\u03b20 = 1\n2 (\u00b5T2 \u03a3 \u22121\u00b52 \u2212 \u00b5T1 \u03a3\u22121\u00b51)and\u03b2 = \u03a3\u22121(\u00b51 \u2212 \u00b52) (11)\nand over \u2126\u2217,\n\u03b2\u22170 = 1 2 (\u00b5 \u2217T 2 \u03a3 \u2217\u22121\u00b5\u22172 \u2212 \u00b5\u2217T1 \u03a3\u2217\u22121\u00b5\u22171) and \u03b2\u2217 = \u03a3\u2217\u22121(\u00b5\u22171 \u2212 \u00b5\u22172) (12)\nreplacing the \u00b5\u2217k, k = 1, 2 and the \u03a3 \u2217 by their expression given by equations (8), (9) and limiting to linear relations which, can exist between the two subpopulations parameters, we obtain the following expressions for \u03b2\u22170 and \u03b2 \u2217:\n\u03b2\u22170 = c+ \u03b20 and \u03b2 \u2217 = \u039b\u03b2, (13)\nconsequently, the scoring function obtained by replacing the parameters \u03b2\u22170 and \u03b2 \u2217 in equation (2.2) is given by:\nP (Y \u2217i = 1|x\u2217i , \u03b8, %) = exp\u03b20+c+(\u039b\u03b2)\nTx\u2217i\n1 + exp\u03b20+c+(\u039b\u03b2) Tx\u2217i\n, (14)\nhere % = {(c,\u039b) \u2208 Rd+1} is the set of transition parameters to be estimated."}, {"heading": "3.3 Links Models", "text": "Estimation of links between \u2126 and \u2126\u2217 subpopulations is done through several logistic intermediary sample models of connections, inspired by the Gaussian case previously evoked in subsection 3.1. Our purpose in this paper is the estimation and comparison of this models listed in the following table\nModels Parameters Descreptions M1 c = 0 \u039b = Id The score functions are invariable.\nM2 c = 0 \u039b = \u03bbId The score functions of the two subpopulations differ only through the scalar parameter \u03bb. M3 c \u2208 R \u039b = Id The score functions of the two subpopulations differ only through the scalar parameter \u03b2\u22170 . M4 c \u2208 R \u039b = \u03bbId The score function of the two subpopulations differ through the couple (\u03b2\u22170 , \u03bb). M5 c = 0 \u039b \u2208 Rd\u00d7d The score functions of the two subpopulations differ only through the vectoriel parameter \u03b2\u2217. M6 c \u2208 R \u039b \u2208 Rd\u00d7d There is no more stochastic link between the logistic discriminations of the two subpopulations. All parameters are free.\nTAB. 1 \u2013 Links models\nFor each one of the above models, estimation of transition parameters is conditionally done to the subpopulation \u2126 parameters. We add a seventh model noted M7, which consist in introducing as observations, all the borrowers (customer and non customers) and to apply a simple logistic regression. This consists in the joined estimation of \u2126 parameters and the transition parameters."}, {"heading": "4 Empirical Analysis", "text": ""}, {"heading": "4.1 Credit Data Set and Subpopulations Definition", "text": "The adopted herein data set is a real word data set: German credit data, illustrated in Figure 1, available from the UCI Machine Learning Repository (http://archive.ics.uci.edu/ml/datasets.html) or see also (Fahrmeir and Tutz, 1994) for more description. The German Credit scoring data set is often used by credit specialists. It cover a sample of 1000 credit consumers where 700 instances are creditworthy applicants and 300 are not. Each applicant is described by a binary target variable Kredit, Kredit = 1 for creditworthy and Kredit = 0 otherwise, 20 other input variables are assumed to influence this target variable, duration of credits in months (Laufzeit), behaviour repayment of other loans (Moral), value of savings or stocks (Sparkont), stability in the employment (Beszeit), further running credits (Weitkred) . . .\nIn this case study we are interested in the evaluation of the borrowers non customers behavior to pay back loans, we use the variable Laufkont (balance of current account) to separate\nthe available data set in two subpopulations: Laufkont > 1 the customers subpopulation composed from 726, Laufkont = 1 the non customers subpopulation composed from 274. Afterward, we devine the subpopulation of borrowers non customers into two samples: a learning sample S\u2217L and a test sample S \u2217 T . The first sample allows to represent the diverse models and to bring out affectation rules, the second one allows to verify the reliability of the established models in learning step."}, {"heading": "4.2 Experiments Description", "text": "To obtain a robust estimate of our seven models performance, our simulations involves taking 50 random design (of size n \u2208 {50, 100, 150, 200}) and test sample splits from the non customers subpopulation. For each design the following algorithm is applied to estimate the parameters of each model from our seven logistic models.\nAlgorithm 1 ESTIM(x,x\u2217, S\u2217L)\u2192 \u03b8\u2217 Require: x: Customer design matrix defined over \u2126. x\u2217: non customer design matrix defined over \u2126\u2217. S\u2217L: Non customer learning sample, S \u2217 L \u2208 \u2126\u2217. Ensure: \u03b8\u2217: Set of all parameters to be estimated over \u2126\u2217, \u03b8\u2217 = {(\u03b2\u22170 ||\u03b2\u2217T ) \u2208 Rd+1}. 1: Estimate the set of parameters \u03b8, \u03b8 = {(\u03b20||\u03b2T ) \u2208 Rd+1}, using a simple logistic regres-\nMost application of assignment procedures works with the misclassification error rates as evaluation criterion, in this case study our choice was a unusual one, so we decided to work\nwith the test error rate, Type II error rate and Type I error rate. The aim was to focus in minimizing the number of default accepted applicant by minimizing the Type I error.\nModels Learning sample transition parameters Estimated parameters M1 \u2126 \u03b2\u0302\u22170 = \u03b20 and \u03b2\u0302\u2217 = \u03b2 M2 \u03bb \u03b2\u0302\u22170 = \u03b20 and \u03b2\u0302\u2217 = \u03bb\u03b2 M3 c \u03b2\u0302\u22170 = c+ \u03b20 and \u03b2\u0302\u2217 = \u03b2 M4 S\u2217L c and \u03bb \u03b2\u0302 \u2217 0 = c+ \u03b20 and \u03b2\u0302\u2217 = \u03bb\u03b2 M5 \u039b \u03b2\u0302\u22170 = \u03b20 and \u03b2\u0302\u2217 = \u039b\u03b2 M6 c and \u039b \u03b2\u0302\u22170 = c+ \u03b20 and \u03b2\u0302\u2217 = \u039b\u03b2 M7 S\u2217L \u222a \u2126 \u03b2\u0302\u22170 and \u03b2\u0302\u2217\nTAB. 2 \u2013 Summary of parameters to be estimated"}, {"heading": "4.3 Experimental Results", "text": "The results for the German credit data set were obtained by using the seven models are summarized in Tables 3, 4 and 5 respectively.\nModels M1 M2 M3 M4 M5 M6 M7 n = 50 0.348 0.370 0.348 0.347 0.358 0.361 0.343 n = 100 0.385 0.362 0.344 0.345 0.347 0.344 0.385 n = 150 0.356 0.354 0.330 0.332 0.338 0.342 0.354 n = 200 0.367 0.337 0.308 0.308 0.321 0.315 0.334\nTAB. 3 \u2013 Results summary for predictive credit test error rate with respect to the learning sample size\nModels M1 M2 M3 M4 M5 M6 M7 n = 50 0.282 0.312 0.338 0.332 0.385 0.341 0.283 n = 100 0.226 0.304 0.339 0.311 0.364 0.356 0.284 n = 150 0.209 0.286 0.296 0.321 0.344 0.338 0.279 n = 200 0.185 0.283 0.294 0.296 0.305 0.245 0.203\nTAB. 4 \u2013 Results summary for predictive credit Type II error with respect to the learning sample size\nWe found no significant differences among models M3 and M4 that means that these two models achieved almost the same test error rate in Table 3 and almost the same Type II and Type I error in Tables 4 and 5, for different training size. It is obvious from Table 3, that test error rate decreases proportionally to the learning sample size, this improvement can be\nModels M1 M2 M3 M4 M5 M6 M7 n = 50 0.394 0.321 0.284 0.285 0.291 0.301 0.376 n = 100 0.384 0.301 0.279 0.275 0.281 0.297 0.362 n = 150 0.384 0.281 0.230 0.233 0.253 0.275 0.316 n = 200 0.336 0.271 0.220 0.218 0.250 0.273 0.278\nTAB. 5 \u2013 Results summary for predictive credit Type I error with respect to the learning sample size\nsuitable to the estimate of models\u2019 parameters which become more precise with the increase of the training data size. Tables 4 and 5, shows that Type II error and Type I proportionally decrease to the design sample size, these results prove the importance of the population size in classification.\nAs shown in Table 3, the test error rate of the two previous models achieved 0.308 which is the lowest rate of misclassified instances, according to this first criterion these models are the two best classification models. For the remaining models, we remark that models M5 and M6 also achieved good results, followed by model M2, the left behind two models generate the most raised test error rate, specially model M1 which appears the worst one.\nTest error rate, however measured, is only one aspect of performance, this criterion may not be the most precise one, further misclassification rate can be another aspect of performance, so each model is evaluated by assessing Type I and II error rate. We remind that the cut-off threshold used in this case study is 0.5 for this threshold, all the applicants whose estimated probability of non-reliability P (Y = 0) is less than 0.5 are assessed as non-reliable applicants, otherwise they are classified as reliable. In Table 4 model M1 and M7 achieved 0.185 and 0.203 error rate, which are the lowest Type II error rate, in other hand models M5 and M6, followed by M2 have the most raised rate, this kind of error arise when a reliable applicant is predicted as non-reliable. Models M5 and M6 are less efficient in the reliable applicants prediction.\nTable 5 summarize Type I error for the seven models. A Type I error means taking a nonreliable client and predicting him as reliable, this kind of error is more dangerous and more costly than the previous one, the model with the lowest rate of Type I error is considered as the best model. From Table 5 we remark that models M3 and M4 have the lowest rate of Type I error, followed by models M5, M6 and M2, in other hand models M1 and M7 have the most raised Type I error rate, It seems that these two previous models have greater difficulty in predicting non-reliable clients than reliable ones.\nThe previous misclassification rates are obtained when the cut-off is 0.5, however changing this threshold might modify the previous results and can allow decider to catch a greater number of good or bad applicants. Hand Hand (2001) in his work proposed the use of graphical tools as evaluation criterion, in place of scalar criterion. We use in this paper the ROC (i.e. receiver operating characteristic) curve to evaluate our seven models, the ROC curve shows how the errors change when the threshold varies, this kind of curve situate positives instances against the negatives instances which allow finding the middle ground between specificity and sensitivity. Figure 2 shows the ROC curve of our models. The X axis of the curve represents models\u2019\n1 \u2212 specificity (i.e. Type II error rate) and the Y axis represents models\u2019 sensitivity (i.e. 1\u2212Type I error rate). According to Liu and Schumann Liu and Schumann (2002) a model with a ROC curve, which follows the 45\u25e6 line would be useless. It would classify the same proportion of not worthy applicants and worthy cases into the not worthy class at each value of the threshold. Figure 2 shows that the seven models are convexes and situated over the first bisector, which lead us to affirm that our models are statistically approved and not useless. In Figure 2 we remark that models M3 and M4 curves appears considerably higher to the other models\u2019 curves which confirms our intuition about their performance, models M1, M7 and M2 has the lowest AUC (i.e. air under curve), from the balance between false positive and false negative point of view these models are bad.\nThe evoked performance measures in this section, served to evaluate the validity and the discriminant power of the studied models. From the previous results, we remark that the most banks\u2019 practiced model M1 seem the least successful model once applied to non customers borrowers\u2019 data, this confirms the difference between the two studied subpopulations. We also remark that models M5 and M6 might be a good classifier. However, models M3 and M4 seems to be the more suitable models for the prediction of non customers behavior to pay back loan. These last one are the best predictive models because their constant is calculated from the non customers learning sample independently of customers sample, what supposes their importance in the reliability prediction of the target variable kredit and confirm the existence of a certain link between the two subpopulation \u2126 and \u2126\u2217. Model M5 possesses the most raised rate of Type II error, this model is considered as careful but its use can lead to a loss of reliable borrowers.\nTo be sure of our models performance, we compare in what follows the performance of the models M3 and M4 with two successful classification techniques:\n\u2013 SVM (Vapnik, 1995) is one of the most outstanding machine learning techniques. The use of SVM in financial application has been previously discussed by several works (Schebesch and Stecking, 2005; Min and Lee, 2005; Huang et al., 2007; Wang, 2008; Bellotti and Crook, 2009). There many raisons for choosing SVM (Burges, 1998), it requires less prior assumptions about the input data and can perform on small or huge data set by doing a nonlinear mapping from an original input space into a high dimensional"}, {"heading": "5 Conclusion", "text": "In this paper we have considered the problem of credit worthiness evaluation, for a population of insufficient size. We proposed seven simple logistic submodels combining the classification rule on customers subpopulation and the labeled sample from the non customers subpopulation. A comparison of the seven models performance was done and the models M3 andM4 was selected as the best classification model for the non customers subpopulation, this two models beat the performance of traditional classification model M1. This research would have been able to generate more interesting results if we were able to have a non customers\u2019 sample of bigger size. We envisage as perspective, to apply logistic regression using non-linear links between the two subpopulations. We also can apply a nonparametric approach which can seem efficient once the linear models find their limits."}], "references": [{"title": "Logistic discrimination", "author": ["J. Anderson"], "venue": "Handbook of Statistics 2, 169\u2013191. Bardos, M. (2001). Analyse discriminante: Application au risque et scoring financier. Dunod.", "citeRegEx": "Anderson,? 1982", "shortCiteRegEx": "Anderson", "year": 1982}, {"title": "Support vector machines for credit scoring and discovery of significant features", "author": ["T. Bellotti", "J. Crook"], "venue": "Expert Syst. Appl. 36(2), 3302\u20133308.", "citeRegEx": "Bellotti and Crook,? 2009", "shortCiteRegEx": "Bellotti and Crook", "year": 2009}, {"title": "Analyse discriminante g\u00e9n\u00e9ralis\u00e9e: Extension au mod\u00e8le logistique", "author": ["F. Beninel", "C. Biernacki"], "venue": "Cloque Data Mining et Apprentissage Statistique Applications en Assurance, Niort, France.", "citeRegEx": "Beninel and Biernacki,? 2005", "shortCiteRegEx": "Beninel and Biernacki", "year": 2005}, {"title": "Mod\u00e8les d\u2019extension de la r\u00e9gression logistique", "author": ["F. Beninel", "C. Biernacki"], "venue": "Revue des Nouvelles Technologies de l\u2019Information, Data Mining et apprentissage statistique : application en assurance, banque et marketing, France, pp. 207\u2013218.", "citeRegEx": "Beninel and Biernacki,? 2007", "shortCiteRegEx": "Beninel and Biernacki", "year": 2007}, {"title": "Updating a logistic discriminant rule: Comparing some logistic submodels in credit-scoring", "author": ["F. Beninel", "C. Biernacki"], "venue": "International Conference on Agents and Artificial Intelligence, France, pp. 267\u2013274.", "citeRegEx": "Beninel and Biernacki,? 2009", "shortCiteRegEx": "Beninel and Biernacki", "year": 2009}, {"title": "A generalized discriminant rule when training population and test population differ on their descriptive parameters", "author": ["C. Biernacki", "F. Beninel", "V. Bretagnolle"], "venue": "Biometrics 58, 387\u0170\u2013397.", "citeRegEx": "Biernacki et al\\.,? 2002", "shortCiteRegEx": "Biernacki et al\\.", "year": 2002}, {"title": "Analyse discriminante sur donn\u00e9es binaires lorsque les populations d\u2019apprentissage et de test sont diff\u00e9rentes", "author": ["C. Biernacki", "J. Jacques"], "venue": "Revue des Nouvelles Technologies de l\u2019Information, Data Mining et apprentissage statistique : application en assurance, banque et marketing, France, pp. 109\u2013125.", "citeRegEx": "Biernacki and Jacques,? 2007", "shortCiteRegEx": "Biernacki and Jacques", "year": 2007}, {"title": "Mod\u00e8les adaptatifs pour les m\u00e9langes de r\u00e9gressions", "author": ["C. Bouveyron", "J. Jacques"], "venue": "41\u00e8mes Journ\u00e9es de Statistique, SFdS, Bordeaux, France. inria-00386638, version 1-22.", "citeRegEx": "Bouveyron and Jacques,? 2009", "shortCiteRegEx": "Bouveyron and Jacques", "year": 2009}, {"title": "Classification and Regression Trees", "author": ["L. Breiman", "J. Friedman", "R. Olshen", "C. Stone"], "venue": "Monterey, CA: Wadsworth and Brooks.", "citeRegEx": "Breiman et al\\.,? 1984", "shortCiteRegEx": "Breiman et al\\.", "year": 1984}, {"title": "A tutorial on support vector machines for pattern recognition", "author": ["J. Burges"], "venue": "Data Min. Knowl. Discov. 2(2), 121\u2013167. English", "citeRegEx": "Burges,? 1998", "shortCiteRegEx": "Burges", "year": 1998}, {"title": "The analysis of binary data [by] D", "author": ["D. Cox"], "venue": "R. Cox. Methuen London,. English", "citeRegEx": "Cox,? 1970", "shortCiteRegEx": "Cox", "year": 1970}, {"title": "Analysis of binary data", "author": ["D. Cox", "E. Snell"], "venue": "Chapman and Hall, London,. English", "citeRegEx": "Cox and Snell,? 1989", "shortCiteRegEx": "Cox and Snell", "year": 1989}, {"title": "Risk elements in consumer instalment financing", "author": ["D. Durand"], "venue": "(Technical edition) By David Durand. National bureau of economic research [New York].", "citeRegEx": "Durand,? 1941", "shortCiteRegEx": "Durand", "year": 1941}, {"title": "Multivariate Statistical Modelling Based on Generalized Linear Models (Springer Series in Statistics", "author": ["L. Fahrmeir", "G. Tutz"], "venue": null, "citeRegEx": "Fahrmeir and Tutz,? \\Q1994\\E", "shortCiteRegEx": "Fahrmeir and Tutz", "year": 1994}, {"title": "Comparing linear discriminant function with logistic regression for the two-group classification problem", "author": ["X. Fan", "L. Wang"], "venue": "Annual Meeting of American Educational Research association, pp. 265\u2013286.", "citeRegEx": "Fan and Wang,? 1998", "shortCiteRegEx": "Fan and Wang", "year": 1998}, {"title": "Small business loans, small banks and big change in technology called credit scoring", "author": ["R. Feldman"], "venue": "The Region (Sep), 19\u201325.", "citeRegEx": "Feldman,? 1997", "shortCiteRegEx": "Feldman", "year": 1997}, {"title": "The use of multiple measurements in taxonomic problems", "author": ["R. Fisher"], "venue": "Annals of Eugenics 7, 179\u2013188.", "citeRegEx": "Fisher,? 1936", "shortCiteRegEx": "Fisher", "year": 1936}, {"title": "Applied Data Mining: Statistical Methods for Business and Industry", "author": ["P. Giudici"], "venue": "West", "citeRegEx": "Giudici,? 2003", "shortCiteRegEx": "Giudici", "year": 2003}, {"title": "Measuring diagnostic accuracy of statistical prediction rules", "author": ["D. Hand"], "venue": "Statistica Neerlandica 55(1), 3\u201316.", "citeRegEx": "Hand,? 2001", "shortCiteRegEx": "Hand", "year": 2001}, {"title": "A k-nearest-neighbour classfier for assessing consumer credit risk", "author": ["W. Henley", "D. Hand"], "venue": "The Statistician 45, 77\u201395.", "citeRegEx": "Henley and Hand,? 1996", "shortCiteRegEx": "Henley and Hand", "year": 1996}, {"title": "Credit scoring with a data mining approach based on support vector machines", "author": ["C.L. Huang", "M.C. Chen", "C.J. Wang"], "venue": "Expert Syst. Appl. 33(4), 847\u2013856.", "citeRegEx": "Huang et al\\.,? 2007", "shortCiteRegEx": "Huang et al\\.", "year": 2007}, {"title": "The evaluation of classification models for credit scoring", "author": ["Y. Liu", "M. Schumann"], "venue": "institute fur wirtschaftsinformatik, working paper.", "citeRegEx": "Liu and Schumann,? 2002", "shortCiteRegEx": "Liu and Schumann", "year": 2002}, {"title": "On the generalized distance in statistics", "author": ["P. Mahalanobis"], "venue": "Natl. Inst. Science 12, 49\u201355.", "citeRegEx": "Mahalanobis,? 1936", "shortCiteRegEx": "Mahalanobis", "year": 1936}, {"title": "A logical calculus of the ideas immanent in nervous activity", "author": ["W. Mcculloch", "W. Pitts"], "venue": "Bulletin of Mathematical Biology 5(4), 115\u2013133.", "citeRegEx": "Mcculloch and Pitts,? 1943", "shortCiteRegEx": "Mcculloch and Pitts", "year": 1943}, {"title": "Bankruptcy prediction using support vector machine with optimal choice of kernel function parameters", "author": ["J.H. Min", "Y.C. Lee"], "venue": "Expert Syst. Appl. 28, 603\u2013614.", "citeRegEx": "Min and Lee,? 2005", "shortCiteRegEx": "Min and Lee", "year": 2005}, {"title": "Credit scoring, statistique et apprentissage", "author": ["G. Saporta"], "venue": "EGC, pp. 3\u20134.", "citeRegEx": "Saporta,? 2006", "shortCiteRegEx": "Saporta", "year": 2006}, {"title": "Une \u00e9tude comparative des m\u00e9thodes de discrimination et de r\u00e9gression logistique", "author": ["O. Sautory", "W. Chang", "V. S\u00e9bastien"], "venue": "Journ\u00e9es de M\u00e9todologie Statistique 1992. INSEE M\u00e9thodes N 46-47-48.", "citeRegEx": "Sautory et al\\.,? 1992", "shortCiteRegEx": "Sautory et al\\.", "year": 1992}, {"title": "Support vector machines for classifying and describing credit applicants: detecting typical and critical regions", "author": ["K.B. Schebesch", "R. Stecking"], "venue": "Journal of the Operational Research Society 56(9), 1082\u20131088.", "citeRegEx": "Schebesch and Stecking,? 2005", "shortCiteRegEx": "Schebesch and Stecking", "year": 2005}, {"title": "Credit Scoring and Its Applications", "author": ["L. Thomas", "J. Crook", "D. Edelman"], "venue": "Philadelphia, PA, USA: Society for Industrial and Applied Mathematics.", "citeRegEx": "Thomas et al\\.,? 2002", "shortCiteRegEx": "Thomas et al\\.", "year": 2002}, {"title": "The nature of statistical learning theory", "author": ["V. Vapnik"], "venue": "New York, NY, USA: SpringerVerlag New York, Inc.", "citeRegEx": "Vapnik,? 1995", "shortCiteRegEx": "Vapnik", "year": 1995}, {"title": "Building credit scoring systems based on support-based support vector machine ensemble", "author": ["Y. Wang"], "venue": "Proceedings of the 2008 Fourth International Conference on Natural Computation - Volume 05, Washington, DC, USA, pp. 323\u2013327. IEEE Computer Society.", "citeRegEx": "Wang,? 2008", "shortCiteRegEx": "Wang", "year": 2008}], "referenceMentions": [{"referenceID": 17, "context": "Credit scoring methods are applied in order to classify possible creditors in two classes of risk: good and bad (Giudici, 2003).", "startOffset": 112, "endOffset": 127}, {"referenceID": 12, "context": "Credit scoring is one of the most successful financial risk management solutions developed for lending institutions, this solution has been fundamental in consumer credit management since Durand (1941). Authors like Feldman (1997), Thomas et al.", "startOffset": 188, "endOffset": 202}, {"referenceID": 12, "context": "Credit scoring is one of the most successful financial risk management solutions developed for lending institutions, this solution has been fundamental in consumer credit management since Durand (1941). Authors like Feldman (1997), Thomas et al.", "startOffset": 188, "endOffset": 231}, {"referenceID": 12, "context": "Credit scoring is one of the most successful financial risk management solutions developed for lending institutions, this solution has been fundamental in consumer credit management since Durand (1941). Authors like Feldman (1997), Thomas et al. (2002) and Saporta (2006) defined the Credit scoring as the process of determining how likely a particular applicant is default with reimbursement.", "startOffset": 188, "endOffset": 253}, {"referenceID": 12, "context": "Credit scoring is one of the most successful financial risk management solutions developed for lending institutions, this solution has been fundamental in consumer credit management since Durand (1941). Authors like Feldman (1997), Thomas et al. (2002) and Saporta (2006) defined the Credit scoring as the process of determining how likely a particular applicant is default with reimbursement.", "startOffset": 188, "endOffset": 272}, {"referenceID": 8, "context": "of Transfer Learning Using Logistic Regression in Credit Scoring classification methods can be used in the process of identifying borrowers\u0160 behavior as decision trees (Breiman et al., 1984), neural networks (Mcculloch and Pitts, 1943), discriminant analysis (Fisher, 1936; Mahalanobis, 1936), logistic regression (Cox, 1970; Cox and Snell, 1989) .", "startOffset": 168, "endOffset": 190}, {"referenceID": 23, "context": ", 1984), neural networks (Mcculloch and Pitts, 1943), discriminant analysis (Fisher, 1936; Mahalanobis, 1936), logistic regression (Cox, 1970; Cox and Snell, 1989) .", "startOffset": 25, "endOffset": 52}, {"referenceID": 16, "context": ", 1984), neural networks (Mcculloch and Pitts, 1943), discriminant analysis (Fisher, 1936; Mahalanobis, 1936), logistic regression (Cox, 1970; Cox and Snell, 1989) .", "startOffset": 76, "endOffset": 109}, {"referenceID": 22, "context": ", 1984), neural networks (Mcculloch and Pitts, 1943), discriminant analysis (Fisher, 1936; Mahalanobis, 1936), logistic regression (Cox, 1970; Cox and Snell, 1989) .", "startOffset": 76, "endOffset": 109}, {"referenceID": 10, "context": ", 1984), neural networks (Mcculloch and Pitts, 1943), discriminant analysis (Fisher, 1936; Mahalanobis, 1936), logistic regression (Cox, 1970; Cox and Snell, 1989) .", "startOffset": 131, "endOffset": 163}, {"referenceID": 11, "context": ", 1984), neural networks (Mcculloch and Pitts, 1943), discriminant analysis (Fisher, 1936; Mahalanobis, 1936), logistic regression (Cox, 1970; Cox and Snell, 1989) .", "startOffset": 131, "endOffset": 163}, {"referenceID": 19, "context": "Logistic regression is a more appropriate technique for Credit scoring cases (Henley and Hand, 1996).", "startOffset": 77, "endOffset": 100}, {"referenceID": 14, "context": "Fan and Wang (1998) and Sautory et al.", "startOffset": 0, "endOffset": 20}, {"referenceID": 14, "context": "Fan and Wang (1998) and Sautory et al. (1992) recommend the use of the binary logistic regression in Credit scoring cases, when discriminant analysis application conditions are not obtainable.", "startOffset": 0, "endOffset": 46}, {"referenceID": 5, "context": "The idea of using two slightly populations for estimating one population parameters, has been first proposed by Biernacki et al. (2002). In a multinomial context, Biernacki et al.", "startOffset": 112, "endOffset": 136}, {"referenceID": 5, "context": "The idea of using two slightly populations for estimating one population parameters, has been first proposed by Biernacki et al. (2002). In a multinomial context, Biernacki et al. (2002) proved that two slightly different populations are linked through linear relations.", "startOffset": 112, "endOffset": 187}, {"referenceID": 3, "context": "This approach proved to be efficient in biological context and many extension of this paper was proposed, including Biernacki and Jacques (2007), Bouveyron and Jacques (2009) as well as Beninel and Biernacki (2005, 2007, 2009).", "startOffset": 116, "endOffset": 145}, {"referenceID": 3, "context": "This approach proved to be efficient in biological context and many extension of this paper was proposed, including Biernacki and Jacques (2007), Bouveyron and Jacques (2009) as well as Beninel and Biernacki (2005, 2007, 2009).", "startOffset": 116, "endOffset": 175}, {"referenceID": 2, "context": "This approach proved to be efficient in biological context and many extension of this paper was proposed, including Biernacki and Jacques (2007), Bouveyron and Jacques (2009) as well as Beninel and Biernacki (2005, 2007, 2009). Beninel and Biernacki (2009) extended this approach to the multinomial logistic discrimination and proposed an additional links\u2019 model in the case where the two studied subpopulation are two Gaussian ones.", "startOffset": 186, "endOffset": 257}, {"referenceID": 2, "context": "This approach proved to be efficient in biological context and many extension of this paper was proposed, including Biernacki and Jacques (2007), Bouveyron and Jacques (2009) as well as Beninel and Biernacki (2005, 2007, 2009). Beninel and Biernacki (2009) extended this approach to the multinomial logistic discrimination and proposed an additional links\u2019 model in the case where the two studied subpopulation are two Gaussian ones. The main idea of this previous works is that information related to one of the two subpopulations contains some information related to the other one. The earlier works, have been the exit of the main thoughts of this paper, given previous results in the case of Gaussian mixture model and the six presented models by Beninel and Biernacki (2009), our task is then, to go in deep in the previous results with more testes and simulations, and to add to the former links\u2019 models a seventh one.", "startOffset": 186, "endOffset": 780}, {"referenceID": 2, "context": "According to Beninel and Biernacki (2009) links between subpopulations could exist and consequently, information on \u03a9 could provide some information on \u03a9\u2217.", "startOffset": 13, "endOffset": 42}, {"referenceID": 2, "context": "It\u2019s known from Beninel and Biernacki (2007) as well as Bouveyron and Jacques (2009) that existence of particular connections between the variables distributions lead to relations between the parameters of their respective logistic regression models, consequently our task consists in finding these links.", "startOffset": 16, "endOffset": 45}, {"referenceID": 2, "context": "It\u2019s known from Beninel and Biernacki (2007) as well as Bouveyron and Jacques (2009) that existence of particular connections between the variables distributions lead to relations between the parameters of their respective logistic regression models, consequently our task consists in finding these links.", "startOffset": 16, "endOffset": 85}, {"referenceID": 2, "context": "It\u2019s known from Beninel and Biernacki (2007) as well as Bouveyron and Jacques (2009) that existence of particular connections between the variables distributions lead to relations between the parameters of their respective logistic regression models, consequently our task consists in finding these links. In this context a preliminary case study was successfully done in Gaussian multivariate case Beninel and Biernacki (2005). It is a question here of extending the found results in Gaussian case to logistic case, which leads to simple and parsimonious linking models between the parameters of logistic classification rules associated respectively to the two subpopulations \u03a9 and \u03a9\u2217.", "startOffset": 16, "endOffset": 428}, {"referenceID": 2, "context": "In order to bring to light the existing links between the two subpopulations, we are going to adopt the approach proposed by Beninel and Biernacki Beninel and Biernacki (2009), which supposes the existence of an application \u03c6k : R \u2192 R linking in law the random variables vectors of \u03a9 and \u03a9\u2217.", "startOffset": 125, "endOffset": 176}, {"referenceID": 2, "context": "The outcomes resulting from Beninel and Biernacki (2009) verify that the function \u03c6k is affine, we drive from equation (6) the following relations between the variables distributions:", "startOffset": 28, "endOffset": 57}, {"referenceID": 13, "context": "html) or see also (Fahrmeir and Tutz, 1994) for more description.", "startOffset": 18, "endOffset": 43}, {"referenceID": 18, "context": "203 error rate, which are the lowest Type II error rate, in other hand models M5 and M6, followed by M2 have the most raised rate, this kind of error arise when a reliable applicant is predicted as non-reliable. Models M5 and M6 are less efficient in the reliable applicants prediction. Table 5 summarize Type I error for the seven models. A Type I error means taking a nonreliable client and predicting him as reliable, this kind of error is more dangerous and more costly than the previous one, the model with the lowest rate of Type I error is considered as the best model. From Table 5 we remark that models M3 and M4 have the lowest rate of Type I error, followed by models M5, M6 and M2, in other hand models M1 and M7 have the most raised Type I error rate, It seems that these two previous models have greater difficulty in predicting non-reliable clients than reliable ones. The previous misclassification rates are obtained when the cut-off is 0.5, however changing this threshold might modify the previous results and can allow decider to catch a greater number of good or bad applicants. Hand Hand (2001) in his work proposed the use of graphical tools as evaluation criterion, in place of scalar criterion.", "startOffset": 66, "endOffset": 1117}, {"referenceID": 29, "context": "To be sure of our models performance, we compare in what follows the performance of the models M3 and M4 with two successful classification techniques: \u2013 SVM (Vapnik, 1995) is one of the most outstanding machine learning techniques.", "startOffset": 158, "endOffset": 172}, {"referenceID": 27, "context": "The use of SVM in financial application has been previously discussed by several works (Schebesch and Stecking, 2005; Min and Lee, 2005; Huang et al., 2007; Wang, 2008; Bellotti and Crook, 2009).", "startOffset": 87, "endOffset": 194}, {"referenceID": 24, "context": "The use of SVM in financial application has been previously discussed by several works (Schebesch and Stecking, 2005; Min and Lee, 2005; Huang et al., 2007; Wang, 2008; Bellotti and Crook, 2009).", "startOffset": 87, "endOffset": 194}, {"referenceID": 20, "context": "The use of SVM in financial application has been previously discussed by several works (Schebesch and Stecking, 2005; Min and Lee, 2005; Huang et al., 2007; Wang, 2008; Bellotti and Crook, 2009).", "startOffset": 87, "endOffset": 194}, {"referenceID": 30, "context": "The use of SVM in financial application has been previously discussed by several works (Schebesch and Stecking, 2005; Min and Lee, 2005; Huang et al., 2007; Wang, 2008; Bellotti and Crook, 2009).", "startOffset": 87, "endOffset": 194}, {"referenceID": 1, "context": "The use of SVM in financial application has been previously discussed by several works (Schebesch and Stecking, 2005; Min and Lee, 2005; Huang et al., 2007; Wang, 2008; Bellotti and Crook, 2009).", "startOffset": 87, "endOffset": 194}, {"referenceID": 9, "context": "There many raisons for choosing SVM (Burges, 1998), it requires less prior assumptions about the input data and can perform on small or huge data set by doing a nonlinear mapping from an original input space into a high dimensional", "startOffset": 36, "endOffset": 50}, {"referenceID": 18, "context": "According to Liu and Schumann Liu and Schumann (2002) a model with a ROC curve, which follows the 45\u25e6 line would be useless.", "startOffset": 13, "endOffset": 54}, {"referenceID": 8, "context": "\u2013 Decision trees (Breiman et al., 1984) was used in credit scoring for the first time by ?.", "startOffset": 17, "endOffset": 39}], "year": 2012, "abstractText": "The credit scoring risk management is a fast growing field due to consumer\u2019s credit requests. Credit requests, of new and existing customers, are often evaluated by classical discrimination rules based on customers information. However, these kinds of strategies have serious limits and don\u2019t take into account the characteristics difference between current customers and the future ones. The aim of this paper is to measure credit worthiness for non customers borrowers and to model potential risk given a heterogeneous population formed by borrowers customers of the bank and others who are not. We hold on previous works done in generalized gaussian discrimination and transpose them into the logistic model to bring out efficient discrimination rules for non customers\u2019 subpopulation. Therefore we obtain several simple models of connection between parameters of both logistic models associated respectively to the two subpopulations. The German credit data set is selected to experiment and to compare these models. Experimental results show that the use of links between the two subpopulations improve the classification accuracy for the new loan applicants.", "creator": "LaTeX with hyperref package"}}}