{"id": "1302.4979", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Feb-2013", "title": "Abstraction in Belief Networks: The Role of Intermediate States in Diagnostic Reasoning", "abstract": "healthy belief networks are bing agents used as a knowledge representation for diagnostic reasoning. one simple method accurately conducting diagnostic reasoning is cannot represent system faults and observations only. in this paper, we investigate how having intermediate nodes - nodes other than fault and origin points affects the diagnostic performance given a bayesian social network. we conducted comparative framework of experiments on a set of real belief networks for medical diagnosis in liver and bile disease. we compared the effects on diagnostic performance of particular two - level network consisting just of disease agents finding nodes with that of a network which models intermediate possible disease states as well. we provide some theoretical evidence for differences observed between the abstracted low - level network and the full network.", "histories": [["v1", "Wed, 20 Feb 2013 15:23:19 GMT  (369kb)", "http://arxiv.org/abs/1302.4979v1", "Appears in Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence (UAI1995)"]], "COMMENTS": "Appears in Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence (UAI1995)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["gregory m provan"], "accepted": false, "id": "1302.4979"}, "pdf": {"name": "1302.4979.pdf", "metadata": {"source": "CRF", "title": "Abstraction in Belief Networks: The Role of Intermediate States in Diagnostic Reasoning", "authors": ["Gregory Provan"], "emails": [], "sections": [{"heading": null, "text": "1 THE TRADEOFF BETWEEN\nACCURACY AND COST\nIn recent years, there has been substantial growth in interest in Bayesian belief networks (BNs) as a knowl edge representation [Pearl, 1988]. There has been work in the development of effective knowledge engineering techniques, efficient inference algorithms, and increas ing numbers of real-world applications of BNs [Henri on et al., 1991h\nThe primary goal of the work described here is to in vestigate how the precision of representation of BNs affects the quality of diagnosis based on the network. We view this research as a contribution towards devel oping an empirical and theoretical basis for knowledge engineering guidelines. These guidelines would help knowledge engineers choose the level and complexity\n*This work was supported by NSF grants #IRI91-20330 and #IRI92-10030.\nof representation that provides the most appropriate tradeoff between accuracy and the cost of computa tional resources for inference, storage and of knowledge engineering.\nThe problem domain that we use in this study is medical diagnosis for hepatobiliary disorders (liver and bile diseases), using a network called CPCS-BN. In the CPCS-BN, the variables can be divided into three classes: diseases, Intermediate Pathophysiolog ical States (IPSs) and findings. In addition, these variables are causally ordered, with diseases \"caus ing\" IPSs and IPSs \"causing\" findings. This causal ordering is reflected by a directed, hierarchical order ing in CPCS-BN: disease nodes precede IPS nodes, which precede finding nodes.\nIn this paper we abstract CPCS-BN into a two-level network containing only disease and finding nodes, and experimentally compare the performance of the three level and the two-level networks to determine the effect on diagnostic accuracy of our mapping. The two-level simplification is structurally isomorphic to the QMR DT network [Shwe et al., 1991; Middleton et al., 1991], and our experiments aim to test whether having more than two levels in a network-representing intermedi ate disease states explicitly-leads to better diagnos tic performance than just having two levels. Figure 1 shows a simple case of reducing a three-level network into a two-level version of that network that does not contain IPS nodes. This two-level mapping may be viewed as extreme, but it does provide a point of ref erence between the QMR-DT representation and the three-level CPCS representation.\nThere are some important tradeoffs involved in model ing intermediate nodes, involving (a) the number and cost of probability assessments, and (b) the indepen dence assumptions that are necessary. For the first case, the cost of knowledge engineering is roughly pro portional to the number of probabilities which need to be assessed, multiplied by the average cost of each assessment. On the one hand introducing intermedi ate nodes can reduce the total number of probabili ties which need to be specified, as we shall show in the paper. However, on the other hand, the average\ncost of each assesment is higher: greater knowledge engineering effort is required to specify probabilities which are typically unobservable, such as probabili ties of diseases causing IPSs.l Given the (effective) two-level QMR KB, an additional two 111an-years of knowledge engineering was spent in constructing the CPCS KB [Parker and Miller, 1987], an indication of the difficulty of modeling intermediate nodes for such domains. In the construction of CPCS-BN, disease priors were obtained from data, and other probabil ities were elicited from knowledge engineers; of this latter set of probabilities, disease-finding relationships (as modeled in the two-level network) are better un derstood than disease-IPS or IPS-finding relationships of the three-level network, and hence are simpler to assess. This is because practical experience and data on which to base probability assessments could be ob tained for disease-finding tuples more easily than for disease-IPS or IPS-finding tuples.\nFor the second case, modeling intermediate nodes, i.e., IPSs, introduces explicit independence models into CPCS-BN, thereby reducing computational expense. Taken together, it is clear that evaluating the trade offs fully is a multi-attribute task: the total k\ufffdowledge engineering costs are a function of the number of prob abilities to be assessed, the difficulty of assessing cer tain types of probabilities, and the use of appropriate independence assumptions. Our study aims to explore the relationships between such knowledge engineering tradeoffs and diagnostic accuracy, and hence shed light on where abstractions in BNs are appropriate.\n2 EXPERIMENTAL DOMAIN\nln this section we briefly describe the BN we have selected for our experimental analysis, CPCS-BN. CPCS-BN supports medical diagnosis for liver and bile (hepatobiliary) diseases. We derived the network from\n11PSs are hidden or conceptual classes for which there typically is no di1\u00b7ect evidence, as there is for findings.\nAbstraction in Belief Networks 465\na rich knowledge base, the CPCS system, developed by R. Parker and R. Miller [Parker and Miller, 1987] in the mid-1980s as an experimental extension of the Internist-I knowledge base [Miller et al., 1982]. The CPCS KB was developed as an experimental ex tension of the Internist-1 KB to support patient sim ulation and computer aided instruction. The develop ers felt that these tasks required a KB with a much richer representation than that of Internist-1. CPCS is restricted to the hepatobiliary medical domain be cause the developers regarded the knowledge engineer ing task too great to convert all of Internist-! to a richer representation based on their experience with the CPCS system.\nInternist-1, and more recently QMR, contain only dis eases and findings-a two-level representation. The CPCS KB has a multilevel representation that in cludes diseases and findings as well as predisposing factors to diseases (PFDs) that influence disease preva lence rates, and intermediate pathophysiological states (IPSs) that mediate between diseases and findings. For example, consider a disease acute gastritis which in volves blood loss and two findings suggestive of blood loss: pale skin and low red blood cell count. lnternist-1 has direct links between this disease and the two find ings. In contrast, the CPCS KB includes anemia (an IPS) between the disease and the two findings.\nThe full CPCS-BN has 448 nodes and over 900 arcs. Because inference in the complete CPCS-BN is ex tremely time consuming, for our experiments we used subsets of the full network comprising 42 nodes (2 dis eases) , 146 nodes ( 3 diseases) and 245 nodes ( 4 dis eases). These subsets are described in more detail in Section 5.\n3 BAYESI AN NETWORK\nREPRESENTATION\nThis section describes the theoretical underpinnings for our representation of causal influences. In CPCS BN, all causal influence are leaky noisy OR, and so we describe the noisy OR representation for causal influ ences, followed by the leak representation for causes that are not explicitly modeled. Noisy OR and leaky noisy OR are simplified representations for probabilis tic influence that require far fewer parameters than the full conditional-probability matrix. In fact, the pa rameters they require are link probabilities, the type of causal relationships represented in the CPCS KB.\nIn the following discussion, we denote variables using upper-case letters (e.g., X) and instantiations of vari ables using lower-case letters (e.g., x) . We consider all variables to be binary, where x means that X is absent, and x means X is present.\nThe noisy OR is model of probabilistic causal influ ence between a binary effect variable and a set of bi nary variables that represent its causes. This repre-\n466 Provan\nsentation was originally proposed by Pearl [1986] and independently by Peng and Reggia [1986]. For the noisy-OR network in Figure 2, let V be the set of predecessor variables {D1, ... Dm}. Let Vx\ufffdV be t\ufffdsubset of predecessors of X that are present and Vx\ufffdV be the subset of predecessors of X that are absent. We assume that all predecessors are in stantiated (thus, Vx U Vx = V). We define d; as the instantiation of V in which D; is present and all other Dj(j =Pi) are absent, or d; = {d; 1\\ Uu;dj}. We use P(d) as shorthand for P(dl,d2, ... ,dm)\u00b7\nFigure 2: A noisy-OR network.\nLet TJ;, on the arc from D; to X, represent the ac tivation probability, the probability that X is present given that D; is present and all other predecessors are absent, i.e., TJ; = P(xl\ufffd\u00b7 \u00b7\nSince the D; E Vx are assumed to be causally inde pendent, X is absent only when all D; fail to cause X to be present:\nP(xiV) II P(xl\ufffd, i:D;EVx\nII (1- ,;). (1) i:D;EVx\nIf X is binary, then we obtain from Eq. 1\nP(xiV) = 1- II (1- TJ;). (2) i:D,EVx\nLike any model, a BN is an incomplete representation of reality. We can use leak events to represent the miss ing variables that influence a finding. Each finding, or other variable with predecessors, has a correspond ing leak event that represents all the possible events that could cause that finding to be present, other than those predecessor variables of the finding that are rep resented explicitly in the model. The leak probability for X, px, is equal to the probability that X is present when all its explicitly modeled predecessors II (X) are absent:\npx = P(l x) = P(xid; 't:/D; E II(X)). (3) Thus, we can model the leak event like any other ex plicit cause D; of X. By incorporating a leak event into Eq. 3, we arrive at a formula for the leaky-noisy OR:\np (X IV) = 1 - ( 1 - p X) II ( 1 - \"li) . ( 4) i:D;EVx\n4 LEVEL REDUCTION\nOPERATION\nThis section outlines how we abstract the three-level CPCS-BN into a two-level network using an approx imate and computationally efficient mapping. The mapping could be done exactly using arc reversal and barren node removal operations [Shachter, 1988], but that process is exponential in the size of the network. Our mapping will avoid these costly operations and provides bounds on the degree of entailed information loss that can be used to identify if more accurate map pings are necessary.\nThe level reduction process we describe can be applied to leaky noisy OR networks in which the nodes can be classified into a hierarchy of node types, such that the intermediate node classes can be abstracted away.\nReducing a network from three to two levels results in probabilities as shown in the right-hand-side network of Figure 3. The basic operation is to assign all paths between disease and finding nodes in the three-level network as edges in the resulting two-level network. Each edge in the two-level network takes on an activa tion probability given by the product of the activation probabilities on the path from which the edge was cre ated.\nFigure 3: Network reduction using an approximate method\nThe following subsections outline our reduction map pings for activation probabilities and leak probabili ties, followed by the algorithm for the reduction pro cess.\n4.1 LINK ACTIVATION PROBABILITY MAPPING\nWe define the initial three-level network to be com prised of a set N of nodes. Levels of the network are indicated as node classes called A-, 8- and C-nodes, starting from the top level. In other words, A repre sents disease nodes, B IPS nodes, and C finding nodes. Consider a path connecting nodes A E A, B E B and C E C. In particular, we define the A-B edge to have activation probability denoted by p;, and the B-C edge to have probability denoted by q;. 2 Using a\n2There may be multiple IPS nodes in between a disease\nsimple approximation, we convert each two-edge path into a single-edge path. For a path with activation probabilities Pi and qi, the reduced activation proba bility, as shown in Figure 3 is defined as Piqi.\nThis reduction is not exact, and we ignore all correla tions. Thus, for example, the fork example in Figure 4 has a high level of correlation, which we are ignor ing. In this figure, a correlation is induced when the three-level network edge with activation probability q1 is \"converted into\" three edges in the two-level net work, with activation probabilties Pl q1, p2q1 and p3q1. These three resulting edges are correlated, since they \"share\" the activation probability q1.\nFigure 4: Subnetwork with a fork. We make an ap proximation by ignoring the correlation resulting from creating multiple links in the two-level network using a single edge in the three-level network. For example, the three-level network edge with activation probabilty q1 is \"converted into\" three edges in the two-level net work, with activation probabilities Pl q1, p2q1 and p3q1.\nWe can reduce an n-level network, n > 3 to a 2- level network by recursively applying the operations described below.\nFor diamond subnetworks, such as that shown in Fig ure 5, we perform a mapping that \"combines\" the mul tiple paths between nodes A and C into a single edge. For example, the middle diagram in Figure 5 shows two edges between nodes A and C that are combined into a single edge. For a set of such edges with activation probabilities p1 q1, . . . , Pkqk, the activation probability for the single \"new\" edge connecting nodes A and C is given by\nTJ = 1 - 11 [1- pjqj]\u00b7 j\n4.2 LEAK ACTIVATION PROBABILITY MAPPING\n(5)\nConsider the leftmost portion of network shown in Fig ure 6. To reduce this to a two-level network, we need to create an updated leak variable for C, eliminating node B and its leak node LB in the process. We use the leak updating process described in [del Favero et al., 1995].\nand finding node, so a path may have multiple edges.\nThe new leak activation probability is computed in two steps:\n1. Update the leak probability for the path from LB to B to C, as shown in Figure 6. The leak can acti vate B when A is absent, with a probability given by the leak probability PB. We can reduce the path from L B to B to C to a single edge connect ing the leak node for B and node C. As shown in the center network of Figure 6, we will now have a new leak node LB with leak probability given by PB1 = PBq. 2. Use leak updating to absorb LB and Lc into a single new leak node, L'c:\nPC' 1- (1- PB')(1- pc) 1- (1- PBq)(1- pc).\n4.3 LEVEL REDUCTION A LGORITHM\nThe level reduction algorithm applies the subnetwork reductions successively until a full reduction is com plete. We define the reduction from 3 to 2 levels as follows:\nInput: a 3-level network with node subsets A, B, C and edges\u00a3.\nOutput: a 2-level network with node subsets A, C and edges\u00a3'.\n468 Provan\nLevel-reduction (A, B, C)\n1. For each disease A; E A, IPS Bj E B, and find ing Ck E C, if there is a link from A; to Bj with activation probability Pm, and there is a link from Bj to Ck with activation probability qm, create a new link lm from A; to Cj with activa tion probability Pm = p;qk , and leak probability Pm = 1- (1- PHk)(1- Pk)\u00b7 2. For all sets of arcs lm that link A; to Ck, replace them all by a single link ln from A; to Ck with link probability Pn = 1 - Tim (1 - Pm) and with leak probability Pn = 1- Tim (I- Pm)\u00b7\nNote that in CPCS-BN there are arcs joining pairs of IPS nodes such as joining B; to Bj, and these are first reduced by calling the algorithm on the path from disease A to IPS B; to IPS Bj, obtaining an arc from A to Bi.\n4.4 EFFECTS OF LEVEL REDUCTION\nWe now describe one of the factors critical to under standing the effects of the level reduction operation: the fan-in and fan-out of an intermediate node. The fan-in of a node is the number of arcs terminating at the node and the fan-out is the number of arcs leaving the node. For example, the intermediate node in the subnetwork of Figure 4 has a fan-in of 3 and a fan-out of 2.\nConsider a three-level network for our analysis. The first point to note is that for a node with fan-in of m and fan-out of n, m+n activation probabilities need to be specified, as opposed to m x n activation probabili ties in the two-level representation of this subnetwork. Hence fewer probabilities need to be specified in the three-level version.\nThe second point is that the two-level version of the subnetwork will approximate the posterior probabili ties assigned to diseases proportional to the values of fan-in and fan-out parameters. A fan-in and fan-out of 1 gives an exact reduction; when either parameter is greater than 1, the reduction becomes less accurate. Consider a subnetwork with fan-in of m and fan-out of 1, where the IPS I can take on value i, finding F can take on value f, and diseases can take on values d = d1, d2, .. , dm. As before, a disease-IPS activation probability is given by p;, an IPS-finding activation probability by q, and a leak probability for node X by px. The three-level network will have a probability of diseases given positive finding denoted by\nP(dif) P(fld)P(d)\nP(f) P(fli)P(ild)P(d) P(!IZ)P(zid)P(d)\nP(f) + P(f)\nm\n{q(1- pr)[1- IT(l- pi)] i=1\nm P(d) + PF }](1-p;)} P(f).\nThe two-level network will have a probability of dis eases given finding given by\nP(dif) P(fld)P(d)\nP(f) m\nP(d) (1-}] (1- p;q)](1- PF) P(f). The ratio n1 of three-level probability to two-level probability is equal to\n{q(1- Pr)[1- n\ufffd1 (1- p;)] + PF n\ufffd1 (1- p;)}AA (1- TI\ufffd1 (1- p;q)](1- PF) \ufffdt\ufffdl (6) We can simplify this expression using the fact that 1 - n\ufffd1 (1-p;) > n\ufffd1 (1-p;) to obtain an approximate value for n1 of\n(1 - PI) L; Pi - ni;o!j PiPj + ... + P1P2 ... Pm (1- PF) L; Pi- q ni;o!j PiPj + . . . + qm-1 (PlP2 ... Pm).\n(7) Assuming a value of q < 1, the two-level probability specified in the denominator of equation 7 is larger than that of the three-level probability when there is more than one disease. The relative difference be tween the numerator and denominator increases as q decreases. In addition, the larger the values of the p;, the less effect the value of q has on the relative difference between numerator and denominator. This can be seen more clearly by looking at the case of two diseases, where we have:\n(1- pr)(P1 + P2- P1P2) (1 - PF )(p1 + P2 - qp1p2). (8)\nAs an example, equation 7 predicts that for subnet works of this type the two-level network will assign over-optimistically high posterior probabilities to mul tiple diseases (that are present) given positive evidence on the findings and activation probabilities of approx imately the same size.\nIn an analogous fashion, we can derive a corresponding ratio for a network with fan-in of 1 and fan-out of n:\n=\n=\nP(d)P(ild)P(fli) + P(d)P(ildr(fli') P(f) P(f P(d)P(fld) P(f) P(d)p ni P(f;li)+P(d) n, PF; (1 -p)\nP(f) P(d) n. P(f;ld)\nP(f) p ni q; + (1- p) ni PF,\nTI; piq; 1\npn-1' (9)\nassuming that leak probabilities are small relative to activation probabilities. In this case, the two-level net work underestimates the posterior probability assigned to D given positive evidence for findings, and the de gree of underestimation increases as p gets smaller.\nA network with fan-in and fan-out parameters greater than 1 will thus be a combination of these effects. Note that the situation with both positive and negative evi dence is significantly more complicated to analyze. We are currently examining these more general situations.\n5 EXPERIMENTAL DESIGN\nThis section summarizes how we conducted our experi ments. Key aspects of our design are the subnetworks and test cases used, and the measures of diagnostic performance employed. Our approach can be summa rized as follows:\n1. Select canonical full network (n-disease, binary) 2. Generate reduced (two-level) network 3. Generate test cases from full network 4. Perform inference on canonical network and re\nduced network to compute the probability as signed to the true diagnosis 5. Analyse results, using paired t-tests over the prob ability assigned to the true diagnosis for all the test cases.\n5.1 S UBNETWORKS USED IN EXPERIMENTS\nBecause CPCS-BN is large and multiply-connected, it is impractical to perform inference using the entire network. If we wish only to compute the posterior probabilities of a small set of diseases, we would like to perform inference using only the subnetwork of the CPCS network that is relevant.\nWe can select subnetworks from the full CPCS-BN us ing the BN graphical tool Netview [Pradhan et al., 1994], and then can export them for inference to an inference system such as IDEAL [Srinivas and Breese, 1990]. We can select subsets of the larger CPCS-BN, and can maintain correct probabilities in the subnet work by appropriately updating leak probabilities, as described in [del Favero et al., 1995].\nascending-cholangitis\nFigure 7: Predecessors of the node hepatomegaly.\nWhen a subnetwork is saved, Net view updates the leak probabilities to take into account the missing diseases. In CPCS-BN, the node hepatomegaly has four disease predecessors shown in Figure 7. In subnetworks with fewer than four diseases, the updated leak probability\nAbstraction in Belief Networks 469\nfor hepatomegaly is calculated based on this set of predecessors.\nTable 1 summarizes the number of nodes of each type in the three subnetworks.\nWe needed far more test cases to estimate reliably the effects of the experimental manipulations on the di agnostic performance than the small number of cases available from real patient data. Accordingly, we gen erated sample test cases directly from the BNs them selves, generating findings according to the probabil ities specified by the network, as described in [del Favero et al., 1995].\nSince we wanted to investigate how the amount of ev idence affects sensitivity to the experimental manip ulations, we generated cases with varying numbers of findings. The test cases, as initially generated, include values for all findings. To create harder cases with fewer findings, and also for greater medical realism, we created five cases from each initial case, by revealing the findings in five Phases, approximating the order in which findings would be revealed in a real medical consultation. Phases 1 and 2 are medical history and simple examination findings respectively, and phases 3 through 5 are tests of increasing expense and invasive ness.\n5.3 MEASURES OF DIAGNOS TIC PERFORMANCE\nWe quantify diagnostic performance as the probabil ity assigned by each network to each true diagnosis, averaged over the set of test cases. We analyze sepa rately the probabilities assigned to each disease when present - that is, the true positive rate. Initially, we aggregate the results by phase so that we can see how performance varies by phase.\nFor statistical analysis of the results we used the paired t test to compare pairs of results, since we ran the same set of test cases under each condition. The posterior probabilities (true positive and false positive rates) of ten have very skewed distributions since they are con strained to be less than one. Accordingly, for statisti cal testing, we transformed them to the log-odds met ric, which provides a distributions that appear more nearly normal.\n470 Provan\n6 RESULTS\nWe ran experiments on the three networks described in the previous section, and compared the average ex pected posterior probability across all diseases. Table 2 shows a sample of these results. This table shows that for every phase value, the 2-level network assigned a probability value to the true diagnosis almost identi cal to that assigned by the three-level network. These differences were statistically insignificant at the 97.5% confidence level.\nA second point to notice is that the probability values increase with phase number, due to there being more evidence for the higher phase values.\nTable 3 compares the posterior probabilities for the three-disease network for two of the three diseases. Note that for ascending chalangitis, there are statisti cally insignificant differences between the probabilities for the two networks (at the 95% confidence level). In contrast, there is a statistically-significant difference (at the 95% confidence level) for the disease hepatitis acute-viral. This is because the node for hepatitis acute-viral has more IPS nodes in the path between it and its successor finding nodes than does the node for ascending chalangitis.\n7 RELATED WORK\nSeveral other approaches have been proposed to ana lyze the sensitivity of representation richness to KB\nconstruction and inference costs, especially focus ing on conditional independence assumptions. Fry back [1978], in a Bayesian model for medical diagnosis, showed empirically that large models with many in appropriate independence assumptions can have lower diagnostic accuracy than smaller models that do not include such inappropriate independence assumptions.\nProvan [1994; 1993] studied the sensitivity of diagnos tic accuracy to the richness and size of temporal BN models, using domain-dependent network reformula tion methods. Network size provided a measure of the knowledge engineering and inference costs associated with the network. Provan found that diagnostic ac curacy improved as a function of network complexity; however, if the model was penalized for its size, then the definition of best model was sensitive to both di agnostic accuracy and model size.\nWellman and Liu [1994 ] compared the results of vari ous domain size abstractions for Bayesian networks for commuter-traffic routing. They used an anytime algo rithm, and were primarily interested in the quality of the results given bounded time for inference. In this set of experiments we ignore the inference time, and focus solely on diagnostic performance.\n8 CONCLUSIONS\nIn this paper, we have investigated how having inter mediate nodes affects the diagnostic performance of a Bayesian belief network. In a series of experiments on a set of real belief subnetworks extracted from a large BN for medical diagnosis in liver and bile disease, we compared the effects on diagnostic performance of a two-level network consisting just of disease and find ing nodes with that of the full network which models intermediate pathophysiological disease states as well.\nWe found that the two-level network assigned poste rior probabilities to the the diseases that were virtually identical to those assigned by the three-level network: any differences are probably not of practical impor tance. Paired-t tests verified that these differences were, for the most part, statistically insignificant at the 95% level.\nThese results indicate that the intermediate nodes, for the network studied, do not make a statistically signif icant difference to the posterior probabilities assigned to diseases. Without such nodes, the network slightly overestimates the true-positive and false-positive prob abilities for the larger networks. By studying the net work topology of intermediate nodes, we have shown one factor that can be used to predict this degree of overestimation: the larger the number of parents and children that intermediate nodes have, the greater the overestimation. Since the larger networks have more densely-connected intermediate nodes, they will dis play larger differences of posteriors that smaller net works. Note that, given that the results for original and abstracted networks are virtually identical, it is not worthwhile studying more accurate network ab straction methods for this domain.\nOur empirical results to date show that the additional effort required to build the CPCS KB from the two level QMR KB does not lead to increased diagnostic accuracy. This is in accord with other experiments [del Favero et al., 1995] on CPCS-BN in which we showed that abstracting the CPCS-BN's quaternary-valued variables to binary-valued variables (as are present in QMR-DT) does not degrade diagnostic accuracy sig nificantly.\nOne cannot apply these results to all domains, how ever. For example, in other domains constructing net works with intermediate nodes may be simpler and provide more accurate diagnoses than two-level net works. We plan to study similar abstractions in other domains, examine the role of intermediate nodes in in ference speed, as well as analyze the theoretical prop erties of network abstractions in more detail.\nAcknowledgements: Malcolm Pradhan provided as sistance with running the experiments, and Max Hen rion provided valuable commentary.\nReferences\n[del Favero et al., 1995] B. del Favero, K. Huang, M. Henrion, M. Pradhan, and G. Provan. The sen sitivity of belief networks to imprecise probabilities: an experimental investigation. submitted, 1995.\n[Fryback, 1978] D. G. Fryback. Bayes' Theorem and Conditional Nonindependence of Data in Medical Diagnosis. \u2022 Computers and Biomedical Research, 11:423-434, 1978.\n[Henrion et al., 1991] M. Henrion, J .S. Breese, and E.J. Horvitz. Decision analysis and expert systems.\nAbstraction in Belief Networks 471\nAI Magazine, 12(4):64-91, 1991. [Middleton et al., 1991] B. Middleton, M. Shwe, D.E.\nHeckerman, M. Henrion, E. J. Horvitz, H. Lehmann, and G.F. Cooper. Probabilistic Diagnosis using a Reformulation of the INTERNIST-1/QMR Knowl edge Base II: Evaluation of Diagnostic Performance. Meth. Information in Medicine, 30:256-267, 1991.\n[Miller et al., 1982] R. A. Miller, H. E. J. Pople, and J. D. Myers. INTERNIST-I: An experimental computer-based diagnostic consultant for general in ternal medicine. N Engl J Med, 307:468-476, 1982.\n[Parker and Miller, 1987] R.C. Parker and R.A. Miller. Using causal knowledge to create simulated patient cases: the CPCS project as an extension of Internist-1. Proc. SCAMC, pages 473-480, 1987.\n[Pearl, 1986] J. Pearl. Fusion, Propagation, and Structuring in Belief Networks. Artificial Intelli gence, 29:241-288, 1986.\n[Pearl, 1988] J. Pearl. Probabilistic Reasoning in In telligent Systems. Morgan Kaufmann, 1988.\n[Peng and Reggia, 1986] Y. Peng and J. Reggia. Plau sibility of Diagnostic Hypotheses. In Pmc. AAAI, pages 140-145, 1986.\n[Pradhan et al., 1994] M. - Pradhan, G.M. Provan, B. Middleton, and M. Henrion. Knowledge engi neering for large belief networks. In Uncertainty in Artificial Intelligence, Seattle, 1994. Morgan Kauf mann.\n[Provan, 1993] G. Provan. Tradeoffs in Constructing and Evaluating Temporal Influence Diagrams. In Proc. Conf. Uncertainty in Artificial Intelligence, pages 40-47, 1993.\n[Provan, 1994] G.M. Provan. Tradeoffs in Knowledge Based Construction of Probabilistic Models. IEEE Trans. on Syst. Man and Cyb., 24(11), 1994.\n[Shachter, 1988] R. Shachter. Probabilistic Inference and Influence Diagrams. Operations Research, 36:589-604, 1988.\n[Shwe et al., 1991] M. Shwe, B. Middleton, D.E. Heckerman, M. Henrion, E. J. Horvitz, H. Lehmann, and G.F. Cooper. Probabilistic Diagnosis using a Reformulation of the INTERNIST-1/QMR Knowl edge Base I: Probabilistic Model and Inference Al gorithms. Methods of Information in Medicine, 30:241-255, 1991.\n[Srinivas and Breese, 1990] S. Srinivas and J. Breese. IDEAL: A Software Package for Analysis of Influ ence Diagrams. In Pmc. Conf. Uncertainty in Arti ficial Intelligence, pages 212-219, 1990.\n[Wellman and Liu, 1994] M. Wellman and C. Liu. State-space Abstraction for Anytime Evaluation of Probabilistic Networks. In Pmc. Conf. Uncertainty in Artificial Intelligence, pages 567-574, 1994.\n472\nAccounting for Context in Plan Recognition, with Application to Traffic Monitoring\nDavid V. Pynadath and Michael P. Wellman Artificial Intelligence Laboratory\nUniversity of Michigan 1101 Beal Avenue\nAnn Arbor, MI 48109-2110 USA {pynadath, wellman} @engin.urnich.edu\nAbstract\nTypical approaches to plan recognition start from a representation of an agent's possible plans, and reason evidentially from observations of the agent's actions to assess the plausibility of the various candidates. A more expansive view of the task (consistent with some prior work) ac counts for the context in which the plan was gen erated, the mental state and planning process of the agent, and consequences of the agent's ac tions in the world. We present a general Bayesian framework encompassing this view, and focus on how context can be exploited in plan recogni tion. We demonstrate the approach on a prob lem in traffic monitoring, where the objective is to induce the plan of the driver from observation of vehicle movements. Starting from a model of how the driver generates plans, we show how the highway context can appropriately influence the recognizer's interpretation of observed driver be havior.\n1 INTRODUCTION\nThe problem of plan recognition is to induce the plan of ac tion driving an agent's behavior, based on partial observa tion of its behavior up to the current time. Deriving the un derlying plan can be useful for many purposes-predicting the agent's future behavior, interpreting its past behavior, or generating actions designed to influence the plan itself. Researchers in AI have studied plan recognition for several kinds of tasks, including discourse analysis (Grosz & Sid ner, 1990), collaborative planning (Huber & Durfee, 1993 ), and adversarial planning (Azarewicz et at., 1989). These works have employed a great variety of reasoning tech niques, operating on similarly various plan representations and adopting varied assumptions about observability.\nThe common theme underlying these diverse motivations and approaches is that the object to be induced is a plan, and\nthat this plan is the cause of observed behavior. If there is anything special about the task of plan recognition as op posed to recognition in general, it must be due to special properties of plans: how they are constituted, and how they cause the behavior we observe and wish to predict, inter pret, and influence.\nIn this paper, we focus on one of these special properties the context in which the plan is generated-and how it can be exploited in the recognition process. Whereas most previous approaches have emphasized the relationship be tween plans and their observable effects,1 we argue that it is equally necessary to consider evidence that would bear on which plan would have been appropriate for the agent to generate. We demonstrate this point through an example application in traffic monitoring, where the interpretation of an individual vehicle's action depends on the surround ing highway context. Our techniques for reasoning about plan-generation context are based on Bayesian networks, as part of a general Bayesian framework for plan recognition. This contribution can be considered a variant extension of the model of Charniak and Goldman (1993), and of the ap proach advocated by Huber et al. (1994).\n2 PLAN RECOGNITION\n2.1 TOWARDS A GENERAL BAYESIAN FRAMEWORK\nOne of the aims of our work is to elucidate the fundamen tal elements of plan recognition, and to develop a general Bayesian framework for approaches to this task. Achiev ing generality is complicated by the diversity of represen tations for plans and techniques for plan generation; there fore, we present the framework at multiple levels of speci ficity. The most abstract specification is designed to accom modate most conceivable versions of plan recognition, and by introducing further distinctions we taxonornize the ap-\n1 Although, as we point out in the discussion below, several of these approaches can also accommodate the sort of context infor mation we are concerned with.\nproaches.\nThe framework for plan recognition is distinguished from uncertain reasoning in general by two special features of plans. First, plans are structured linguistic objects. Plan languages considered in AI research range from simple se quences of action tokens to general-purpose programming languages. In either case, the recognizer can and should ex ploit the structure of plans in inducing them from partial ob\nservations ofthe actions comprising the plan. Another way to say this is that plans are descriptions of action patterns, and therefore any general pattern-recognition technique is automatically a plan recognition technique for the class of plans corresponding to the class of patterns associated with the given technique.\nThe second special feature of plans is that they are ratio nal constructions. They are synthesized by a rational agent with some beliefs, preferences, and capabilities, that is, a mental state. Knowing the agent's mental state and its ra tionality properties strongly constrains the possible plans it\nwill construct. (The degree of constraint depends on the power of the rationality theory we adopt.) The rational ori gin of plans is what distinguishes plan recognition from pat tern recognition. If the observations available include evi dence bearing on the beliefs, preferences, and capabilities of the agent, then the recognizer should combine this with evidence from the observed actions in reasoning about the entire plan.\nOur framework is Bayesian in that we start from a causal theory of how the agent's mental state causes its plan and\nexecuting its plan causes activity, and reason from observed effects to underlying causes. Our recognizer has uncertain a priori knowledge about the agent's mental state, the world state, and the world's dynamics, which can be summarized\n(at least in principle) by a probability distribution. It then makes partial observations about the world, and uses this evidence to induce properties of the agent and its plan.\nThe remainder of this section describes our framework in more detail. We demonstrate the utility of the framework by showing how extensions to the underlying conception of plans and planning generate corresponding extensions to plan recognition. Examples from our explorations of plan recognition in a highway traffic domain illustrate our appli cation of the framework to a concrete problem.\n2.2 PLANNING MODEL\nWe begin with a model of the planning agent operating in the world. As it begins planning, the agent has a certain mental state, consisting of its preferences (e.g., goals), be liefs (e.g., about the state of its environment), and capabil ities (e.g., available actions). We assume the actual plan ning process to be some rational procedure for generating the plan that will best satisfy the agent's preferences based\nContext in Plan Recognition 473\non its beliefs, subject to its capabilities. This plan then de termines (perhaps with some uncertainty) the actions taken by the agent in the world.\nMost plan-recognition work concentrates only on this last\nstep, the relationship between a plan and the actions taken in the world. Typical approaches start from a representa\ntion of the possible plans, and prune the set of possibilities based on the actions observed. For example, Kautz (1986)\nconnects plans and actions through event hierarchies, which place the plan at the top of a taxonomy of subplans and ac tions. Vilain (1990) presents a context-free grammar repre sentation of these event hierarchies as an alternative model. Lin and Goebel ( 1991) restrict the constraint language, per mitting use of a faster, specialized message-passing recog\nnition algorithm.\nGiven the reduced set of possible plans that could explain the observations, the plan recognizer must apply some pref erence criterion for choosing among them. For instance, Kautz's approach prefers explanations that involve fewer\nplans. The algorithm of Lin and Goebel prefers plan scenar ios that are more general. However, given two explanations containing the same number of plans, at the same levels of generality, neither algorithm has a basis for a choice either way. To borrow an example from Chamiak and Goldman, suppose we hear that Jack packed a bag and went to the air port. Depending on the exact event hierarchy, neither algo\nrithm may be able to decide whether Jack is in the process\nof taking a trip or conducting a terrorist bombing.\nThe average reader would probably not consider the latter\npossibility, since people are much more likely to take a trip\nthan bomb an airplane. Charniak and Goldman account for this behavior in their recognition procedure by including\nprior probabilities on plans. This allows them to distinguish among equally possible, but unequally plausible explana\ntions for observed activity. The recognition model of Car berry (1990), based on the Dempster-Shafer theory of ev\nidential reasoning instead of Bayesian techniques, takes a similar approach by using threshold plausibility and differ ence levels of belief to distinguish among competing hy\npotheses. Similar distinctions could be supported in lin\nguistic approaches as well, perhaps based on probabilistic grammars (Wetherell, 1980).\n2.3 MENTAL STATE\nIn a particular case, we typically have information avail able to us that would augment these prior probabilities. For instance, we may know that Jack belongs to a terrorist or ganization, which would make the bombing explanation of his actions more plausible. To account for this sort of knowledge, the plan-recognition framework should accom modate all possible information about the agent's plan se lection process, beginning with its mental state. We can break down an agent's mental state into three distinct com-"}], "references": [{"title": "The sen\u00ad sitivity of belief networks to imprecise probabilities: an experimental investigation", "author": ["B. del Favero", "K. Huang", "M. Henrion", "M. Pradhan", "G. Provan"], "venue": "submitted,", "citeRegEx": "del Favero et al.. 1995", "shortCiteRegEx": null, "year": 1995}, {"title": "Bayes' Theorem and Conditional Nonindependence of Data in Medical Diagnosis", "author": ["D.G. Fryback"], "venue": "\u2022 Computers and Biomedical Research, 11:423-434", "citeRegEx": "Fryback. 1978", "shortCiteRegEx": null, "year": 1978}, {"title": "Probabilistic Diagnosis using a Reformulation of the INTERNIST-1/QMR Knowl\u00ad edge Base II: Evaluation of Diagnostic Performance", "author": ["Middleton et al", "1991] B. Middleton", "M. Shwe", "D.E. Heckerman", "M. Henrion", "E.J. Horvitz", "H. Lehmann", "G.F. Cooper"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q1991\\E", "shortCiteRegEx": "al. et al\\.", "year": 1991}, {"title": "INTERNIST-I: An experimental computer-based diagnostic consultant for general in\u00ad ternal medicine", "author": ["R.A. Miller", "H.E.J. Pople", "J.D. Myers"], "venue": "N Engl J Med, 307:468-476", "citeRegEx": "Miller et al.. 1982", "shortCiteRegEx": null, "year": 1982}, {"title": "Using causal knowledge to create simulated patient cases: the CPCS project as an extension of Internist-1", "author": ["R.C. Parker", "R.A. Miller"], "venue": "Proc. SCAMC, pages 473-480", "citeRegEx": "Parker and Miller. 1987", "shortCiteRegEx": null, "year": 1987}, {"title": "Fusion", "author": ["J. Pearl"], "venue": "Propagation, and Structuring in Belief Networks. Artificial Intelli\u00ad gence, 29:241-288", "citeRegEx": "Pearl. 1986", "shortCiteRegEx": null, "year": 1986}, {"title": "Probabilistic Reasoning in In\u00ad telligent Systems", "author": ["J. Pearl"], "venue": "Morgan Kaufmann", "citeRegEx": "Pearl. 1988", "shortCiteRegEx": null, "year": 1988}, {"title": "Plau\u00ad sibility of Diagnostic Hypotheses", "author": ["Y. Peng", "J. Reggia"], "venue": "Pmc. AAAI, pages 140-145", "citeRegEx": "Peng and Reggia. 1986", "shortCiteRegEx": null, "year": 1986}, {"title": "Knowledge engi\u00ad neering for large belief networks", "author": ["M. - Pradhan", "G.M. Provan", "B. Middleton", "M. Henrion"], "venue": "Uncertainty in Artificial Intelligence, Seattle,", "citeRegEx": "Pradhan et al.. 1994", "shortCiteRegEx": null, "year": 1994}, {"title": "Tradeoffs in Constructing and Evaluating Temporal Influence Diagrams", "author": ["G. Provan"], "venue": "Proc. Conf. Uncertainty in Artificial Intelligence, pages 40-47", "citeRegEx": "Provan. 1993", "shortCiteRegEx": null, "year": 1993}, {"title": "Tradeoffs in Knowledge\u00ad Based Construction of Probabilistic Models", "author": ["G.M. Provan"], "venue": "IEEE Trans. on Syst. Man and Cyb., 24(11)", "citeRegEx": "Provan. 1994", "shortCiteRegEx": null, "year": 1994}, {"title": "Probabilistic Inference and Influence Diagrams", "author": ["R. Shachter"], "venue": "Operations Research, 36:589-604", "citeRegEx": "Shachter. 1988", "shortCiteRegEx": null, "year": 1988}, {"title": "Probabilistic Diagnosis using a Reformulation of the INTERNIST-1/QMR Knowl\u00ad edge Base I: Probabilistic Model and Inference Al\u00ad", "author": ["Shwe et al", "1991] M. Shwe", "B. Middleton", "D.E. Heckerman", "M. Henrion", "E.J. Horvitz", "H. Lehmann", "G.F. Cooper"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q1991\\E", "shortCiteRegEx": "al. et al\\.", "year": 1991}, {"title": "IDEAL: A Software Package for Analysis of Influ\u00ad ence Diagrams", "author": ["S. Srinivas", "J. Breese"], "venue": "Pmc. Conf. Uncertainty in Arti\u00ad ficial Intelligence, pages 212-219", "citeRegEx": "Srinivas and Breese. 1990", "shortCiteRegEx": null, "year": 1990}, {"title": "State-space Abstraction for Anytime Evaluation of Probabilistic Networks", "author": ["M. Wellman", "C. Liu"], "venue": "Pmc. Conf. Uncertainty in Artificial Intelligence, pages 567-574", "citeRegEx": "Wellman and Liu. 1994", "shortCiteRegEx": null, "year": 1994}], "referenceMentions": [{"referenceID": 6, "context": "In recent years, there has been substantial growth in interest in Bayesian belief networks (BNs) as a knowl\u00ad edge representation [Pearl, 1988].", "startOffset": 129, "endOffset": 142}, {"referenceID": 4, "context": "l Given the (effective) two-level QMR KB, an additional two 111an-years of knowledge engineering was spent in constructing the CPCS KB [Parker and Miller, 1987], an indication of the difficulty of modeling intermediate nodes for such domains.", "startOffset": 135, "endOffset": 160}, {"referenceID": 4, "context": "Miller [Parker and Miller, 1987] in the mid-1980s as an experimental extension of the Internist-I knowledge base [Miller et al.", "startOffset": 7, "endOffset": 32}, {"referenceID": 3, "context": "Miller [Parker and Miller, 1987] in the mid-1980s as an experimental extension of the Internist-I knowledge base [Miller et al., 1982].", "startOffset": 113, "endOffset": 134}, {"referenceID": 11, "context": "The mapping could be done exactly using arc reversal and barren node removal operations [Shachter, 1988], but that process is exponential in the size of the network.", "startOffset": 88, "endOffset": 104}, {"referenceID": 0, "context": "We use the leak updating process described in [del Favero et al., 1995].", "startOffset": 46, "endOffset": 71}, {"referenceID": 8, "context": "We can select subnetworks from the full CPCS-BN us\u00ad ing the BN graphical tool Netview [Pradhan et al., 1994], and then can export them for inference to an inference system such as IDEAL [Srinivas and Breese, 1990].", "startOffset": 86, "endOffset": 108}, {"referenceID": 13, "context": ", 1994], and then can export them for inference to an inference system such as IDEAL [Srinivas and Breese, 1990].", "startOffset": 85, "endOffset": 112}, {"referenceID": 0, "context": "We can select subsets of the larger CPCS-BN, and can maintain correct probabilities in the subnet\u00ad work by appropriately updating leak probabilities, as described in [del Favero et al., 1995].", "startOffset": 166, "endOffset": 191}, {"referenceID": 0, "context": "Accordingly, we gen\u00ad erated sample test cases directly from the BNs them\u00ad selves, generating findings according to the probabil\u00ad ities specified by the network, as described in [del Favero et al., 1995].", "startOffset": 177, "endOffset": 202}, {"referenceID": 0, "context": "This is in accord with other experiments [del Favero et al., 1995] on CPCS-BN in which we showed that abstracting the CPCS-BN's quaternary-valued variables to binary-valued variables (as are present in QMR-DT) does not degrade diagnostic accuracy sig\u00ad nificantly.", "startOffset": 41, "endOffset": 66}], "year": 2011, "abstractText": "ion in Belief Networks: The Role of Intermediate States in Diagnostic Reasoning Gregory Provan* Institute for Decision Systems Research 4984 El Camino Real, Suite 110 Los Altos, CA 94022", "creator": "pdftk 1.41 - www.pdftk.com"}}}