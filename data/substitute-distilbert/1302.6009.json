{"id": "1302.6009", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Feb-2013", "title": "On learning parametric-output HMMs", "abstract": "we present a novel approach approaching learning an hmm whose outputs are distributed according \\ infinite parametric family. this is done by { \\ em decoupling } the learning task into two steps : first estimating the mixture parameters, and then estimating the hidden states transition probabilities. their first step is accomplished for fitting a simplified model incorporating the output stationary distribution. given the parameters of this mixture transformation, the second step is formulated yields the solution of an easily solvable convex quadratic program. we provide an error analysis for satisfying estimated transition probabilities where show they are robust to increasing perturbations in the estimates of the reaction parameters. finally, we support our analysis with some encouraging empirical results.", "histories": [["v1", "Mon, 25 Feb 2013 07:20:19 GMT  (649kb)", "http://arxiv.org/abs/1302.6009v1", null]], "reviews": [], "SUBJECTS": "cs.LG math.ST stat.ML stat.TH", "authors": ["aryeh kontorovich", "boaz nadler", "roi weiss"], "accepted": true, "id": "1302.6009"}, "pdf": {"name": "1302.6009.pdf", "metadata": {"source": "CRF", "title": "On learning parametric-output HMMs", "authors": ["Aryeh Kontorovich"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n30 2.\n60 09"}, {"heading": "1 Introduction", "text": "Hidden Markov Models (HMM) are a standard tool in the modeling and analysis of time series with a wide variety of applications. When the number of hidden states is known, the standard method for estimating the HMM parameters from given observed data is the Baum-Welch algorithm [Baum et al., 1970]. The latter is known to suffer from two serious drawbacks: it\ntends to converge (i) very slowly and (ii) only to a local maximum. Indeed, the problem of recovering the parameters of a general HMM is provably hard, in several distinct senses [Abe and Warmuth, 1992, Lyngs\u00f8 and Pedersen, 2001, Terwijn, 2002].\nIn this paper we consider learning parametric-output HMMs with a finite and known number of hidden states, where the output from each hidden state follows a parametric distribution from a given family. A notable example is a Gaussian HMM, where from each state x, the output is a (possibly multivariate) Gaussian, N (\u00b5x,\u03a3x), typically with unknown \u00b5x,\u03a3x.\nMain results. We propose a novel approach to learning parametric output HMMs, based on the following two insights: (i) in an ergodic HMM, the stationary distribution is a mixture of distributions from the parametric family, and (ii) given the output parameters, or their approximate values, one can efficiently recover the corresponding transition probabilities up to small additive error.\nCombining these two insights leads to our decoupling approach to learning parametric HMMs. Rather than attempting, as in the Baum-Welch algorithm, to jointly estimate both the transition probabilities and the output density parameters, we instead learn each of them separately. First, given one or several long observed sequences, the HMM output parameters are estimated by a general purpose parametric mixture learner, such as the Expectation-Maximization (EM) algorithm. Next, once these parameters are approximately known, we learn the hidden state transition probabilities by solving a computationally efficient convex quadratic program (QP).\nThe key idea behind our approach is to treat the underlying hidden process as if it were sampled independently from the Markov chain\u2019s stationary distribution, and operate only on the empirical distribution of singletons and consecutive pairs. Thus we avoid computing the exact likelihood, which depends on the full sequence, and obtain considerable gains in computational efficiency. Under mild assumptions on the Markov chain and on its output probabilities, we prove in Theorem 1 that given the exact output probabilities, our estimator for the hidden state transition matrix is asymptotically consistent. Additionally, this estimator is robust to small perturbations in the output probabilities (Theorems 2-6).\nBeyond its practical prospects, our proposed approach also sheds light on the theoretical difficulty of the full HMM learning problem: It shows that for parametric-output HMMs the key difficulty is fitting a mixture model, since once its parameters have been accurately estimated, learning the transition\nmatrix can be cast as a convex program. While learning a general mixture is considered a hard problem, we note that recently much progress has been made under various separation conditions on the mixture components, see e.g. Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein.\nRelated work. The problem of estimating HMM parameters from observations has been actively studied since the 1970\u2019s, see Cappe\u0301 et al. [2005], Rabiner [1990], Roweis and Ghahramani [1999]. While computing the maximumlikelihood estimator for an HMM is in general computationally intractable, under mild conditions, such an estimator is asymptotically consistent and normally distributed, see Bickel et al. [1998], Chang [1996], Douc and Matias [2001].\nIn recent years, there has been a renewed interest in learning HMMs, in particular under various assumptions that render the learning problem tractable [Farago\u0301 and Lugosi, 1989, Hsu et al., 2009, Mossel and Roch, 2006, Siddiqi et al., 2010, Anandkumar et al., 2012]. Also, Cybenko and Crespi [2011], Lakshminarayanan and Raich [2010] recently suggested Non-negative Matrix Factorization (NNMF) approaches for learning HMMs. These methods are related to our approach, since with known output probabilities, NNMF reduces to a convex program similar to the one considered here. Hence, our stability and consistency analysis may be relevant to NNMFbased approaches as well.\nPaper outline. In Section 2 we present our problem setup. The algorithm for learning the HMM appears in Section 3, and its statistical analysis in Section 4. Section 5 contains some simulation results. The technical details are deferred to the Appendices."}, {"heading": "2 Problem Setup", "text": "Notation. When X \u2208 X and Y \u2208 Y take values in a discrete set we abbreviate P (x) for Pr(X = x) and P (y |x) for Pr(Y = y |X = x). When Y \u2208 Y is continuous-valued, we denote by P (y |x) the probability density function of Y given X.\nFor x,w \u2208 Rn, diag(x) denotes the n\u00d7n diagonal matrix with entries xi on its diagonal, x/w is the vector with entries xi/wi, and \u2016x\u20162w = \u2211 iwix 2 i is a w-weighted \u21132 norm (for wi > 0). The shorthand x . y means x \u2264\n(1 + o(1))y. Similarly we write x .P y for x \u2264 (1 + oP (1))y. Finally, for a positive integer n \u2208 N, we write [n] = {1, 2, . . . , n}.\nHidden Markov Model. We consider a discrete-time, discrete-space HMMs with n hidden states. The HMM output alphabet, denoted Y, may be either discrete or continuous. A parametric-output HMM is characterized by a tuple (A,F\u03b8n, P0) where A is an n\u00d7 n column stochastic matrix, P0 is the distribution of the initial state and F\u03b8n = (f\u03b81 , . . . , f\u03b8n) is an ordered tuple of parametrized probability density functions. In the sequel we sometimes write fi instead of f\u03b8i .\nTo generate the output sequence of the HMM, first an unobserved Markov sequence of hidden states x = {xt}T\u22121t=0 is generated with the following distribution.\nP (x) = P0(x0)\nT\u22121 \u220f\nt=1\nAxt,xt\u22121 ,\nwhere Aij = P (Xt = i |Xt\u22121 = j) are the transition probabilities. Then, each hidden stateXt independently emits an observation Yt \u2208 Y according to the distribution P (yt |xt) \u2261 fxt(yt). Hence the output sequence y = (yt)T\u22121t=0 has the conditional probability\nP (y |x) = T\u22121 \u220f\nt=0\nP (yt |xt) = T\u22121 \u220f\nt=0\nfxt(yt).\nThe HMM Learning Problem. Given one or several HMM output sequences (Yt) T\u22121 t=0 , the HMM learning problem is to estimate both the transition matrix A and the parameters of the output distributions F\u03b8n."}, {"heading": "3 Learning Parametric-Output HMMs", "text": "The standard approach to learning the parameters of an HMM is to maximize the likelihood\n\u2211\nx\u2208[n]T P0(x0)P (y0 |x0)\nT\u22121 \u220f\nt=1\nAxt,xt\u22121P (yt |xt).\nAs discussed in the Introduction, this problem is in general computationally hard. In practice, neglecting the small effect of the initial distribution P0(x0)\non the likelihood, A and F\u03b8n are usually estimated via the Baum-Welch algorithm, which is computationally slow and only guaranteed to converge to a local maximum."}, {"heading": "3.1 A Decoupling Approach", "text": "In what follows we show that when the output distributions are parametric, we can decouple the HMM learning task into two steps: learning the output parameters \u03b81, . . . , \u03b8n followed by learning the transition probabilities of the HMM. Under some mild structural assumptions on the HMM, this decoupling implies that the difficulty of learning a parametric-output HMM can be reduced to that of learning a parametric mixture model. Indeed, given (an approximation to) F\u03b8n\u2019s parameters, we propose an efficient, single-pass, statistically-consistent algorithm for estimating the transition matrix A.\nAs an example, consider learning a Gaussian HMM with univariate outputs. While the Baum-Welch approach jointly estimates n2+2n parameters (the matrix A and the parameters \u00b5i, \u03c3 2 i ), our decoupling approach first fits a mixture model with only 3n parameters (\u03c0i, \u00b5i, \u03c3 2 i ), and then solves a convex problem for the matrix A. While both problems are in general computationally hard, ours has a significantly lower dimensionality for large n.\nAssumptions. To recover the matrix A and the output parameters \u03b8j we make the following assumptions:\n(1a) The Markov chain has a unique stationary distribution \u03c0 over the n hidden states. Moreover, each hidden state is recurrent with a frequency bounded away from zero: mink \u03c0k \u2265 a0 for some constant a0 > 0.\n(1b) The n\u00d7n transition matrix A is geometrically ergodic1: there exists parameters G < \u221e and \u03c8 \u2208 [0, 1) such that from any initial distribution P0\n\u2225 \u2225AtP0 \u2212 \u03c0 \u2225 \u2225 1 \u2264 2G\u03c8t, \u2200t \u2208 N. (1)\n(1c) The output parameters of the n states are all distinct: \u03b8i 6= \u03b8j for i 6= j. In addition, the parametric family is identifiable.\nRemarks: Assumption (1a) rules out transient states, whose presence makes it generally impossible to estimate all entries in A from one or a few long observed sequences. Assumption (1b) implies mixing and is used later on to bound the error and the number of samples needed to learn the\n1Any finite-state ergodic Markov chain is geometrically ergodic.\nmatrix A. Assumption (1c) is crucial to our approach, which uses the distribution of only single and pairs of consecutive observations. If two states i, j had same output parameters, it would be impossible to distinguish between them based on single outputs."}, {"heading": "3.2 Learning the output parameters.", "text": "Assumptions (1a,1b) imply that the Markov chain over the hidden states is mixing, and so after only a few time steps, the distribution of Xt is very close to stationary. Assuming for simplicity that already X0 is sampled from the stationary distribution, or alternatively neglecting the first few outputs, this implies that each observable Yt is a random realization from the following parametric mixture model,\nY \u223c n \u2211\ni=1\n\u03c0if\u03b8i(y). (2)\nHence, given the output sequence (Yt) T\u22121 t=0 one may estimate the output parameters \u03b8i and the stationary distribution \u03c0i by fitting a mixture model of the form (2) to the observations. This is commonly done via the EM algorithm.\nLike its more sophisticated cousin Baum-Welch, the mixture-learning EM algorithm also suffers from local maxima. Indeed, from a theoretical viewpoint, learning such a mixture model (i.e. the parameters of F\u03b8n) is a non-trivial task considered in general to be computationally hard. Nonetheless, under various separation assumptions, efficient algorithms with rigorous guarantees have been recently proposed (see e.g. Belkin and Sinha [2010]).2 Note that while these algorithms have polynomial complexity in sample size and output dimension, they are still exponential in the number of mixture components (i.e., in the number of hidden states of the HMM). Hence, these methods do not imply polynomial learnability of parametric-output HMMs.\nIn what follows we assume that using some mixture-learning procedure, the output parameters \u03b8j have been estimated with a relatively small error\n(say |\u03b8\u0302j \u2212 \u03b8j| = O(1/ \u221a T )). Furthermore, to allow for cases where \u03b8j were estimated from separate observed sequences of perhaps other HMMs with same output parameters but potentially different stationary distributions, we do not assume that \u03c0i have been estimated.\n2Note that the techniques for learning mixtures assume iid data. However, if these are algorithmically stable \u2014 as such methods typically are \u2014 the iid assumption can be replaced by strong mixing [Mohri and Rostamizadeh, 2010]."}, {"heading": "3.3 Learning the transition matrix A", "text": "Next, we describe how to recover the matrix A given either exact or approximate knowledge of the HMM output probabilities. For clarity and completeness, we first give an estimation procedure for the stationary distribution \u03c0.\nDiscrete observations. As a warm-up to the case of continuous outputs, we start with HMMs with a discrete observation space of size |Y| = m. In this case we can replace F\u03b8n by an m \u00d7 n column-stochastic matrix B such that Bki \u2261 P (k | i) is the probability of observing an output k given that the Markov chain is in hidden state i. In what follows, we assume that the number of output states is larger or equal to the number of hidden states, m \u2265 n, and that the m \u00d7 n matrix B has full rank n. The latter is the discrete analogue of assumption (1c) mentioned above.\nFirst note that since the matrix A has a stationary distribution \u03c0, the process Yt also has a stationary distribution \u03c1, which by analogy to Eq. (2), is\n\u03c1 = B\u03c0. (3)\nSimilarly, the pair (Yt, Yt+1) has a unique stationary distribution \u03c3, given by\n\u03c3k,k\u2032 = \u2211\n\u2113,\u2113\u2032\u2208[n] \u03c0\u2113A\u2113\u2032,\u2113Bk,\u2113Bk\u2032,\u2113\u2032 . (4)\nAs we shall see below, knowledge of \u03c1 and \u03c3 suffices to estimate \u03c0 and A. Although \u03c1 and \u03c3 are themselves unknown, they are easily estimated from a single pass on the data (Yt) T\u22121 t=0 :\n\u03c1\u0302k = 1\nT\nT\u22121 \u2211\nt=0\n1{yt=k},\n\u03c3\u0302k,k\u2032 = 1 T \u2212 1 T\u22121 \u2211\nt=1\n1{yt\u22121=k}1{yt=k\u2032}. (5)\nEstimating the stationary distribution \u03c0. The key idea in our approach is to replace the exact, but complicated and non-convex likelihood function by a \u201cpseudo-likelihood\u201d, which treats the hidden state sequence (Xt) as if they were iid draws from the unknown stationary distribution\n\u03c0. The pseudo-likelihood has the advantage of having an easily computed global maximum, which, as we show in in Section 4, yields an asymptotically consistent estimator. Approximating the (Xt) as iid draws from \u03c0 means that the (Yt) are treated as iid draws from \u03c1 = B\u03c0. Thus, given a sequence (Yt) T\u22121 t=0 the pseudo-likelihood for a vector \u03c0 is\nL(y0, . . . , yT\u22121 |\u03c0) = T\u22121 \u220f\ni=0\n(B\u03c0)yi = m \u220f\nk=1\n(B\u03c0)nkk\nwhere nk = \u2211T\u22121 i=0 1{yt=k} = T \u03c1\u0302k. Its maximizer is\n\u03c0\u0302ML = argmin xi\u22650, \u2016x\u20161=1\n\u2212 m \u2211\nk=1\n\u03c1\u0302k log(Bx)k. (6)\nSince \u2212 log(x) is convex, (Bx)k is a linear combination of the unknown variables xj , and the constraints are all linear, the above is nothing but a convex program, easily solved via standard optimization methods [Nesterov and Nemirovskii, 1994].\nHowever, to facilitate the analysis and to increase the computational efficiency, we consider the asymptotic behavior of the pseudo-likelihood in (6), for T sufficiently large so that \u03c1\u0302 is close to \u03c1. First, we write\n(Bx)k = \u03c1\u0302k\n( 1 + (Bx)k \u2212 \u03c1\u0302k\n\u03c1\u0302k\n)\n.\nNext, assuming that T \u226b 1 is sufficiently large to ensure |(Bx)k \u2212 \u03c1\u0302k| \u226a \u03c1\u0302k, we take a second order Taylor expansion of log(Bx)k in (6). This gives\n\u2212 n \u2211\nk=1\n\u03c1\u0302k log \u03c1\u0302k \u2212 n \u2211\nk=1\n((Bx)k \u2212 \u03c1\u0302k) +\n+\nn \u2211\nk=1\n\u03c1\u0302k\n( (Bx)k \u2212 \u03c1\u0302k \u03c1\u0302k\n)2\n+O\n(\n\u2016Bx\u2212 \u03c1\u0302\u20163\u221e minj \u03c12j\n)\n.\nThe first term is independent of x, whereas the second term vanishes. Thus, we may approximate (6) by the quadratic program\nargmin xi\u22650, \u2016x\u20161=1\n\u2016\u03c1\u0302 \u2212Bx\u20162(1/\u03c1\u0302) (7)\nwhere \u2016x\u20162w = \u2211 k wkx 2 k is a weighted \u21132 norm w.r.t. the weight vector w. Eq. (7) is also a convex problem, easily solved via standard optimization techniques. However, let us temporarily ignore the non-negativity constraints xi \u2265 0 and add a Lagrange multiplier for the equality constraint\n\u2211 xi = 1:\nmin 1\n2\nm \u2211\nk=1\n1\n\u03c1\u0302k\n( \u03c1\u0302k \u2212 n \u2211\nj=1\nBkjxj\n)2 \u2212 \u03bb ( \u2211\nj\nxj \u2212 1 ) . (8)\nDifferentiating with respect to xi yields\nWx = (1 + \u03bb)1, (9)\nwhere W = B\u22badiag(1/\u03c1\u0302)B. Enforcing the normalization constraint is equivalent to solving for x\u2217 = W\u221211 and normalizing \u03c0\u0302 = x\u2217/ \u2016x\u2217\u20161. Note that if all entries of x\u2217 are positive, \u03c0\u0302 is the solution of the optimization problem in (7), and we need not invoke a QP solver. Assumptions (1a,1b) that \u03c0k is bounded away from zero and that the chain is mixing imply that for sufficiently large T , all entries of \u03c0\u0302 will be positive with high probability, see Section 4.\nEstimating the transition matrix A. To estimate A, we consider pairs (Yt, Yt+1) of consecutive observations. By definition we have that for a single pair,\nP (Yt = k, Yt+1 = k \u2032) =\n\u2211\ni,j\nBk\u2032iBkjAijP (Xt = j).\nAs above, we treat the T \u2212 1 consecutive pairs (Yt, Yt+1) as independent of each other, with the hidden state Xt sampled from the stationary distribution \u03c0. When the output probability matrix B and the stationary distribution \u03c0 are both known, the pseudo-likelihood is given by\nL(y |A) = \u220f\n(k,k\u2032)\n(\n\u2211\nij\nBk\u2032iBkjAij\u03c0j\n)nkk\u2032 ,\nwhere nkk\u2032= \u2211T\u22121 t=1 1{yt\u22121=k}1{yt=k\u2032}=(T \u2212 1)\u03c3\u0302kk\u2032 . The resulting estimator is\nargmin Aij\u22650, \u2211 iAij=1,A\u03c0=\u03c0\n\u2212 \u2211 \u03c3\u0302kk\u2032 log ( \u2211\nij\nCkk \u2032\nij Aij\n)\n(10)\nwhere Ckk \u2032 ij = \u03c0jBkjBk\u2032i. In practice, since \u03c0 is not known, we use C\u0302 kk\u2032 ij = \u03c0\u0302jBkjBk\u2032i, with \u03c0\u0302 instead of \u03c0. Again, (10) is a convex program in A and may be solved by standard constrained convex optimization methods. To obtain a more computationally efficient formulation, let us assume that mink,k\u2032 \u03c3k,k\u2032 \u2265 a2 > 0, and that mink,k\u2032 T \u03c3\u0302kk\u2032 \u226b 1, so that\n|(C\u0302A)kk\u2032 \u2212 \u03c3\u0302kk\u2032| \u226a \u03c3\u0302kk\u2032, where (C\u0302A)kk\u2032 = \u2211 ij C\u0302 kk\u2032 ij Aij . Then, as above, the approximate minimization problem is\nargmin Aij\u22650, \u2211 iAij=1,A\u03c0\u0302=\u03c0\u0302\n\u2225 \u2225 \u2225 \u03c3\u0302 \u2212 C\u0302A \u2225 \u2225 \u2225 2\n1/\u03c3\u0302 . (11)\nIn contrast to the estimation of \u03c0, where we could ignore the non-negativity constraints, here the constraints Aij \u2265 0 are essential, since for realistic HMMs, some entries in A might be strictly zero. Finally, note that if \u03c0\u0302 = \u03c0 and \u03c3\u0302 = \u03c3, the true matrix A satisfies \u03c3 = CA and is the minimizer of (10).\nIn summary, given one or more output sequences (yt) T\u22121 t=0 and an estimate of B, we first make a single pass over the data and construct the estimators \u03c1\u0302 and \u03c3\u0302, with complexity O(T ). Then, the stationary distribution \u03c0 is estimated via (9), and its transition matrix A via (11). To estimate A, we first compute the matrix product C\u0302\u22baC\u0302, with O(n4m2) operations. The resulting QP has size n2, and is thus solvable [den Hertog, 1994] in time O(n6) \u2014 which is dominated by O(n4m2) since m \u2265 n by assumption. Hence, the overall time complexity of estimating A is O(T + n4m2).\nExtension to continuous observations. We now extend the above results to the case of continuous outputs distributed according to a known parametric family. Recall that in this case, each hidden state i \u2208 [n] has an associated output probability density f\u03b8i(y). As with discrete observations, we assume that an approximation (\u03b8\u03021, . . . , \u03b8\u0302n) to fi\u2019s parameters is given and use it to construct estimates of \u03c0 and A.\nTo this end, we seek analogues of (3) and (4), which relate the observable quantities to the latent ones. This will enable us to construct the appropriate empirical estimates and the corresponding quadratic programs, whose solutions will be our estimators \u03c0\u0302 and A\u0302. To handle infinite output alphabets, we map each observation y to an n-dimensional vector \u03d5(y) = (f\u03b81(y), . . . , f\u03b8n(y)), whose entries are the likelihood of y from each of the underlying hidden states. As shown below, this allows us to reduce the problem to a discrete \u201cobservation\u201d space which can be solved by the methods introduced in the previous subsection.\nEstimating the stationary distribution \u03c0. To obtain an analogue of (3), we define the vector \u03be \u2208 Rn, and matrix K \u2208 Rn\u00d7n, which will play the role of \u03c1 and B for discrete output alphabets. The vector \u03be is defined as\n\u03be = E[\u03d5(Y )], or more explicitly,\n\u03bek \u2261 E[fk(Y )] = n \u2211\nj=1\n\u03c0j\n\u222b\nY fk(y)P (y | j)dy.\nSimilarly, the (i, j) entry of K is given by\nKij \u2261 E[fi(Y ) |X = j] = \u222b\nY fi(y)P (y | j)dy. (12)\nWith these definitions we have, as in Eq. (3),\n\u03be = K\u03c0. (13)\nThus, given an observed sequence (yt) T\u22121 t=0 we construct the empirical estimate\n\u03be\u0302k = 1\nT\nT\u22121 \u2211\nt=0\nfk(yt), (14)\nand consequently solve the QP\n\u03c0\u0302 = argmin \u2016x\u2016\n1 =1,x\u22650\n\u2225 \u2225 \u2225 \u03be\u0302 \u2212Kx \u2225 \u2225 \u2225 2\n1/\u03be\u0302 . (15)\nIn analogy to the discrete case, we assume rank(K) = n so (15) has a unique solution. Its asymptotic consistency and accuracy are discussed in Section 4.\nEstimating the transition matrix A. Next, following the same paradigm we obtain an analogue of (4). Bayes rule implies that for stationary chains,\nP (k |Y ) = fk(Y )\u03c0k\u2211n l=1 fl(Y )\u03c0l . (16)\nWe define the matrices \u03b7 \u2208 Rn\u00d7n and F \u2208 Rn\u00d7n (analogues of \u03c3 and B) as follows. Let Y and Y \u2032 be two consecutive observations of the HMM, then\n\u03b7kk\u2032 \u2261 E [ P (k |Y )P (k\u2032 |Y \u2032) ] Fkj \u2261 E[P (k |Y ) | j]= \u222b\nY P (k | y)P (y | j)dy. (17)\nA simple calculation shows that, as in (4),\n\u03b7kk\u2032 =\nn \u2211\ni,j=1\nFk\u2032iFkjAij\u03c0j . (18)\nSince here F plays the role of B, we may call it an effective observation matrix. This suggests estimating A with the same tools used in the discrete case. Thus, given an observed sequence (yt) T\u22121 t=0 we construct an empirical estimate \u03b7\u0302 by\n\u03b7\u0302kk\u2032 = 1 T \u2212 1 T\u22121 \u2211\nt=1\nP\u0302 (k | yt\u22121)P\u0302 (k\u2032 | yt), (19)\nwhere P\u0302 is given by (16) but with \u03c0 replaced by \u03c0\u0302. Consequently we solve the following QP\nA\u0302 = argmin Aij\u22650, \u2211 iAij=1,A\u03c0\u0302=\u03c0\u0302\n\u2225 \u2225 \u2225\u03b7\u0302 \u2212 (C\u0302A) \u2225 \u2225 \u2225 2\n1/\u03b7\u0302 , (20)\nwhere C\u0302kk \u2032 ij = \u03c0\u0302jFkjFk\u2032i and (C\u0302A)kk\u2032 = \u2211 ij C\u0302 kk\u2032 ij Aij . As for the matrix B in the discrete case, to ensure a unique solution to Eq. (20) we assume rank(F ) = n.\nRemark 1. Instead of (18), we could estimate \u03b7\u2032k,k\u2032 \u2261 E[fk(Y )fk\u2032(Y \u2032)], from which A can also be recovered, since\n\u03b7\u2032k,k\u2032 = n \u2211\ni,j=1\nKk\u2032iKkjAij\u03c0j.\nThis has the advantage that for many distributions the matrix K can be cast in a closed analytic form. For example in the Gaussian case, while F needs to be calculated numerically, we have\nKij = 1\u221a 2\u03c0 1 \u221a\n\u03c32i + \u03c3 2 j\nexp\n(\n\u22121 2 (\u00b5i \u2212 \u00b5j)2 \u03c32i + \u03c3 2 j\n)\n.\nAdditionally, K does not depend on the stationary distribution. The drawback is that in principle, and as simulations suggest, accurately estimating \u03b7\u2032 may require many more samples, see Appendix for details.\nIn summary, given approximate output parameters (\u03b8\u03021, . . . , \u03b8\u0302n), we first calculate the n \u00d7 n matrix K. Next, we construct the vector \u03be\u0302 by a single pass over the data (Yt) T\u22121 t=0 . Then the stationary distribution \u03c0 is estimated via (15). Given \u03c0\u0302, we calculate the n\u00d7n matrix F , construct the empirical estimate \u03b7\u0302, and estimate A via (20). As in the discrete observation case, the time complexity of this scheme is O(T + n6) with additional terms for calculating K and F ."}, {"heading": "4 Error analysis", "text": "First, we study the statistical properties of our estimators under the assumption that the output parameters, (\u03b81, . . . , \u03b8n) in the continuous case, or the matrix B in the discrete case, are known exactly. Later on we show that our estimators are stable to perturbations in these parameters. For simplicity, throughout this section we assume that the initial hidden state X0 is sampled from the stationary distribution \u03c0. This assumption is not essential and omitting it would not qualitatively change our results. All proofs are deferred to the Appendices.\nTo provide bounds on the error and required sample size we make the following additional assumptions:\n(2a) In the discrete case, there exists an a1 > 0 such that minj \u03c1j \u2265 a1. (2b) In the continuous case, all f\u03b8i are bounded:\nmax i\u2208[n] sup y\u2208R\nf\u03b8i(y) \u2264 L < \u221e.\nFinally, for ease of notation we define\ng\u03c8 \u2261 2G\n1\u2212 \u03c8 .\nAsymptotic Strong Consistency. Our first result shows that with perfectly known output probabilities, as T \u2192 \u221e, our estimates \u03c0\u0302, A\u0302 are strongly consistent. Theorem 1. Let (Yt) T\u22121 t=0 be an observed sequence of an HMM, whose Markov chain satisfies Assumptions (1a,1b). Assume rank(B) = n in the discrete case, or rank(F ) = rank(K) = n in the continuous case. Then, both estimators, \u03c0\u0302 of (9) and A\u0302 of (11) in the discrete case, or (15) and (20) in the continuous case, are asymptotically strongly consistent. Namely, as T \u2192 \u221e, with probability one,\n\u03c0\u0302 \u2192 \u03c0 and A\u0302 \u2192 A.\nError analysis for the stationary distribution \u03c0. Recall that to estimate \u03c0 in the discrete case, we argued that for sufficiently large sample size T , the positivity constraints can be ignored, which amounts to solving an n \u00d7 n system of linear equations, Eq. (9). The following theorem provides both a lower bound on the required sample size T for this condition to hold with high probability, as well as error bounds on the difference \u03c0\u0302 \u2212 \u03c0. Theorem 2. Discrete case: Let \u03c1\u0302 be given by (5), and \u03c0\u0302 be the solution of (9). Let B\u0303 = diag(1/ \u221a \u03c1)B, and \u03c31(B\u0303) be its smallest singular value. Under Assumption (2a), a sequence of length\nT & g\u03c8\n\u221a log n\na0a1\u03c31(B\u0303) , (21)\nis sufficient to ensure that with high probability, all entries in \u03c0\u0302 are strictly positive. Furthermore, as T \u2192 \u221e,\n\u2016\u03c0\u0302 \u2212 \u03c0\u20162 .P\n\u221a\ng2\u03c8\nTa21\u03c3 2 1(B\u0303)\n. (22)\nNext we consider the errors in the estimate \u03c0\u0302 for the continuous observations case. For simplicity, instead of analyzing the quadratic program (15) with a weighted \u21132 norm, we consider the following quadratic program, whose solution is also asymptotically consistent:\nmin x\u22650,\n\u2211 i xi=1\n\u2016\u03be\u0302 \u2212Kx\u201622. (23)\nThis allows for a cleaner analysis, without changing the qualitative flavor of the results.\nTheorem 3. Continuous case: Let \u03be\u0302 be given by (14), \u03c0\u0302 be the solution of (15), and K\u0303 = diag(1/ \u221a \u03be)K. Under Assumption (2b), as T \u2192 \u221e,\n\u2016\u03c0\u0302 \u2212 \u03c0\u20162 .P\n\u221a\n(n3 lnn)g2\u03c8L 4\nT\u03c341(K\u0303) , (24)\nError Analysis for the Matrix A. Again, for simplicity, instead of analyzing the quadratic programs (11) and (20) with a weighted \u21132 norm, we consider the following quadratic programs, whose solutions are also asymptotically consistent for \u03bd\u0302 \u2208 {\u03c3\u0302, \u03b7\u0302}:\nmin Aij\u22650, \u2211 iAij=1\n\u2016\u03bd\u0302 \u2212 C\u0302A\u201622. (25)\nNote that this QP is applicable even if \u03bdkk\u2032 = 0 for some k, k \u2032, which implies that \u03bd\u0302kk\u2032 = 0 as well.\nTheorem 4. Discrete case. Let A\u0302 be the solution of (25) with \u03bd\u0302 = \u03c3\u0302 given in (5). Then, as T \u2192 \u221e,\n\u2225 \u2225 \u2225 A\u0302\u2212A \u2225 \u2225 \u2225\nF .P\n\u221a\nn3g2\u03c8 Ta40a 2 1\u03c3 10 1 (B)\n(26)\nand thus an observed sequence length\nT & n3g2\u03c8\na40a 2 1\u03c3 10 1 (B)\n(27)\nsuffices for accurate estimation.\nTheorem 5. Continuous case. Let A\u0302 be the solution of (25) with \u03bd\u0302 = \u03b7\u0302 given in (19). Then, as T \u2192 \u221e,\n\u2225 \u2225 \u2225 A\u0302\u2212A \u2225 \u2225 \u2225\nF .P\n\u221a\n(n7 lnn)g2\u03c8L 4\nTa60\u03c3 8 1(F )\u03c3 4 1(K)\n(28)\nand thus an observed sequence length\nT & (n7 lnn)g2\u03c8L 4\na40\u03c3 8 1(F )\u03c3 4 1(K)\n(29)\nsuffices for accurate estimation.\nRemarks. Note the key role of the smallest singular value \u03c31, in the error bounds in the theorems above: Two hidden states with very similar output probabilities drive \u03c31 to zero, thus requiring many more observations to resolve the properties of the underlying hidden sequence.\nInaccuracies in the output parameters. In practice we only have approximate output parameters, found for example, via an EM algorithm. For simplicity, we study the effect of such inaccuracies only in the continuous case. Similar results hold in the discrete case. To this end, assume the errors in the matrices K and F of Eqs. (12) and (17) are of the form\nK\u0303 = K + \u01ebLQ, F\u0303 = F + \u01ebP, (30)\nwith \u2016Q\u2016F , \u2016P\u2016F \u2264 1. The following theorem shows our estimators are stable w.r.t. errors in the estimated output parameters. Note that if K,F are estimated by a sequence of length T , then typically \u01eb = O(T\u22121/2).\nTheorem 6. Given an error of \u01eb in the output parameters as in Eq. (30), the estimators given in Theorems 3 and 5, incur an additional error of at most\nO\n(\nnr\u01eb\na20\u03c3 4 1\n)\n, (31)\nwith r = 1 for estimating \u03c0, and r = 32 for estimating A, and where \u03c31 is the smallest singular value of K/L2 when estimating \u03c0, and of F when estimating A."}, {"heading": "5 Simulation Results", "text": "We illustrate our algorithm by some simulation results, executed in MATLAB with the help of the HMM and EM toolboxes3. We consider a toy example with n = 4 hidden states, whose outputs are univariate Gaussians, N (\u00b5i, \u03c32i ), with A, F\u03b8n and \u03c0 given by\nA =\n\n   0.7 0.0 0.2 0.5 0.2 0.6 0.2 0.0 0.1 0.2 0.6 0.0 0.0 0.2 0.0 0.5\n\n   ,\nf1 = N (\u22124, 4) f2 = N (0, 1) f3 = N (2, 36) f4 = N (4, 1)\n\u03c0\u22ba = (0.3529, 0.2941, 0.2353, 0.1176).\nFig. 1 shows the mixture and its four components.\n3Available at http://www.cs.ubc.ca/~murphyk and http://www.mathworks.com/ (under EM GM Fast).\nTo estimate A we considered the following methods:\nmethod initial \u03b8 initial A\n1 BW random random 2 none exactly known QP 3 none EM QP 4 BW exactly known QP 5 BW EM QP 6 BW exactly known random 7 BW EM random\nFig. 2 (left) shows on a logarithmic scale E\u2016A\u0302\u2212A\u20162F vs. sample size T , averaged over 100 independent realizations. Fig. 2 (right) shows the running time as a function of T . In these two figures, the number of iterations of the BW step was set to 20.\nFig. 3 (left) shows the convergence of E\u2016A\u0302\u2212A\u20162F as a function of the number of BW iterations, with known output parameters, but either with or without the QP results. Fig. 3 (right) gives E\u2016A\u0302\u2212A\u20162F as a function of the number of BW iterations for both known and EM-estimated output parameters with 105 samples.\nThe simulation results highlight the following points: (i) BW with a random guess of both A and the parameters \u03b8j = (\u00b5j , \u03c3 2 j ) is useless if run for only 20 iterations. It often requires hundreds of iterations to converge, in some cases to a poor inaccurate solution (results not shows due to lack of space); (ii) For a small number of samples the accuracy of QP+EM (method 3) is comparable to BW+EM (method 5) but requires only a fraction of\nthe computation time. (iii) When the number of samples becomes large, the QP+EM is not only faster, but (surprisingly) also more accurate than BW+EM. As Fig. 3 suggests, this is due to the slow convergence of the BW algorithm, which requires more than 20 iterations for convergence. (iv) Starting the BW iterations with (\u00b5i, \u03c3 2 i ) estimated by EM and A estimated by QP as its initial values significantly accelerated the convergence giving a superior accuracy after only 20 iterations. These results show the (well known) importance of initializing the BW algorithm with sufficiently accurate starting values. Our QP approach provides such an initial value for A by a computationally fast algorithm."}, {"heading": "6 Appendix", "text": "We now give a detailed account for the theorems stated in section 4."}, {"heading": "6.1 Preliminaries I", "text": "In what follows we use the following notation: For an n \u00d7 n matrix A, vec(A) \u2208 Rn2 is the result of stacking its columns vertically into a single long vector. Thus, its Frobenius matrix norm is \u2016A\u2016F = \u2016vec(A)\u20162.\nRecall the definition of g\u03c8:\ng\u03c8 \u2261 2G\n1\u2212 \u03c8 .\nOne can easily verify that for 2G \u2265 1, we have 1 + \u03c8g\u03c8 \u2264 g2\u03c8. Also recall that assumption (2b) states that the distributions in F\u03b8n are bounded by L, which is defined by:\nmax i\u2208[n] sup y\u2208R\nf\u03b8i(y) \u2264 L < \u221e.\nThe following concentration result from Kontorovich and Weiss [2012, Theorem 1] is our main tool in proving the error bounds given here.\nLemma 1. Let Y = Y0, . . . , YT\u22121 \u2208 YT be the output of a Hidden Markov chain with transition matrix A and output distributions F\u03b8n. Assume that A is geometrically ergodic with constants G,\u03c8 as in (1). Let F : (Y0, . . . , YT\u22121) 7\u2192 R be any function that is l-Lipschitz with respect to the Hamming metric on YT . Then, for all \u01eb > 0,\nP (|F (Y )\u2212EF | > \u01ebT ) \u2264 2 exp ( \u2212T (1\u2212 \u03c8) 2\u01eb2\n2l2G2\n)\n. (32)\nWe will also need the following Lemma (proved in [Kontorovich and Weiss, 2012] for the discrete output case but easily generalize to continuous outputs) for bounding the variance of our estimators.\nLemma 2. Let f(y) : R \u2192 R+ be a function of the observables of an n states geometrically ergodic HMM with constants (G,\u03c8) and\n\u222b\nY f(y)dy \u2264 1.\nAssume the HMM is started with the stationary distribution \u03c0. Then\nVar\n[\n1\nT\nT\u22121 \u2211\nt=0\nf(Yt)\n]\n\u2264 Var[f(Y )] T + \u03c8g\u03c8E[f(Y )] T .\nSimilarly, let g(y, y\u2032) : R \u00d7 R \u2192 R+ be a function of consecutive observations (y, y\u2032) such that\n\u222b\u222b\nY g(y, y\u2032)dydy\u2032 \u2264 1.\nThen\nVar\n[\n1\nT\nT\u22121 \u2211\nt=1\ng(Yt, Yt+1)\n]\n\u2264 Var[g(Y, Y \u2032)]\nT \u2212 1 +\n(1 + \u03c8g\u03c8)E[g(Y, Y \u2032)]\nT \u2212 1 ."}, {"heading": "6.2 Accuracy of \u03c1\u0302, \u03c3\u0302, \u03be\u0302 and \u03b7\u0302", "text": "Since our estimators \u03c0\u0302 and A\u0302 are constructed in terms of \u03c1\u0302 and \u03c3\u0302 in the discrete case, and \u03be\u0302 and \u03b7\u0302 in the continuous case, let us first examine the accuracy of the later. The following results shows that geometric ergodicity is sufficient to ensure their rapid convergence to the true values.\nLemma 3. Discrete case. Let (yt) T t=1 be an observed sequence from a discrete output HMM whose initial state X0 follows the stationary distribution \u03c0. Let \u03c1 be given by (3) and \u03c3 by (4) with their empirical estimates given in (5). Then\nE[\u2016\u03c1\u0302\u2212 \u03c1\u20162] \u2264 \u221a\n1 + \u03c8g\u03c8 T\n(33)\nE[\u2016\u03c3\u0302 \u2212 \u03c3\u20162] \u2264 \u221a\n2 + \u03c8g\u03c8 T \u2212 1 (34)\nFurthermore, for any \u01eb > 0 ,\nP (\u2016\u03c1\u0302\u2212 \u03c1\u20162 > \u221a 1+\u03c8g\u03c8 T + \u01eb) \u2264 2 exp\n(\n\u22122T\u01eb2 g2 \u03c8\n)\n(35)\nand\nP\n(\n\u2016\u03c3\u0302 \u2212 \u03c3\u20162 > \u221a\n2 + \u03c8g\u03c8 T \u2212 1 + \u01eb\n)\n\u2264 (36)\n2 exp\n(\n\u22122(T \u2212 1)\u01eb2 g2\u03c8\n)\n.\nFinally, we have for any fixed v \u2208 Rm with \u2016v\u20162 = 1,\nP (|\u3008\u03c1\u0302,v\u3009 \u2212 \u3008\u03c1,v\u3009| > \u01eb) \u2264 2 exp ( \u22122T\u01eb 2\ng2\u03c8\n)\n. (37)\nProof. First note that w.r.t the Hamming metric, T ||\u03c1\u0302\u2212\u03c1||2 and |\u3008\u03c1\u0302,v\u3009 \u2212 \u3008\u03c1,v\u3009| are 1-Lipschitz and T ||\u03c3\u0302 \u2212 \u03c3||2 is 2-Lipschitz. Thus the claims in (35, 36, 37) all follows directly from Lemma 1 where for (35, 36) we also take into account (33) and (34) respectively. In order to prove (33) note that\nE[\u2016\u03c1\u0302\u2212 \u03c1\u201622] = \u2211 k\u2208[n] E(\u03c1\u0302k \u2212 \u03c1k)2 = \u2211 k\u2208[n] V ar(\u03c1\u0302k).\nSo by taking in Lemma 2, f(y) = 1y=k, we have E[1y=k] = \u03c1k and V ar(1y=k) = \u03c1k(1\u2212 \u03c1k) \u2264 \u03c1k. Since \u2211m k=1 \u03c1k = 1 we get the desired bound.\nThe bound in (34) is obtained similarly by taking g(y, y\u2032) = 1y=k1y\u2032=k\u2032 in Lemma 2 with the fact that \u2211\nkk\u2032 \u03c3kk\u2032 = 1.\nLemma 4. Continuous case. Let (Yt) T t=1 be an observed sequence from a continuous observations HMM whose initial state X0 follows the stationary distribution \u03c0. Let \u03be be given by (13) , \u03b7 by (18) and \u03be\u0302 and \u03b7\u0302 be their empirical estimates, given by (14) and (19) respectively. Then for any \u01eb > 0 ,\nP (\u2225 \u2225 \u2225 \u03be\u0302 \u2212 \u03be \u2225 \u2225 \u2225\n2 > \u01eb\n) \u2264 2n exp ( \u2212 2T\u01eb 2\ng2\u03c8nL 2\n)\n, (38)\nand\nP (\u2016\u03b7\u0302 \u2212 \u03b7\u20162 > \u01eb) \u2264 (39)\n2n2 exp\n(\n\u22122(T \u2212 1)\u01eb 2\ng2\u03c8n 2\n)\n.\nProof. Note that E\u03be\u0302k = \u03bek and T \u03be\u0302k is L-Lipschitz for all k \u2208 [n]. Thus by Lemma 1 and the union bound we have\nP (\u2225 \u2225 \u2225\u03be\u0302 \u2212 \u03be \u2225 \u2225 \u2225 \u221e > \u01eb\u2032 )\n\u2264 2n exp ( \u22122T\u01eb \u20322\ng2\u03c8L 2\n)\n. (40)\nSince \u2225\n\u2225 \u2225 \u03be\u0302 \u2212 \u03be\n\u2225 \u2225 \u2225 2\n2 =\n\u2211\nk\u2208[n] (\u03be\u0302k \u2212 \u03bek)2 \u2264 n\n\u2225 \u2225 \u2225 \u03be\u0302 \u2212 \u03be \u2225 \u2225 \u2225 2\n\u221e ,\nwe have\nP (\u2225 \u2225 \u2225 \u03be\u0302 \u2212 \u03be \u2225 \u2225 \u2225\n2 > \u01eb\n) \u2264 P (\u221a n \u2225 \u2225 \u2225 \u03be\u0302 \u2212 \u03be \u2225 \u2225 \u2225\n\u221e > \u01eb\n)\n.\nputting \u01eb\u2032 = \u01eb/ \u221a n in (40), the claim in (38) follows.\nThe proof of (39) follows the same paradigm as the proof for (40). Indeed E[\u03b7\u0302kk\u2032 ] = \u03b7kk\u2032 and T \u02c6\u03b7kk\u2032 is 1-Lipschitz so by Lemma 1 and the union bound we have\nP ( \u2016\u03b7\u0302 \u2212 \u03b7\u2016\u221e > \u01eb\u2032 )\n\u2264 2n2 exp ( \u22122T\u01eb \u20322\ng2\u03c8L 2\n)\n. (41)\nSince\n\u2016\u03b7\u0302 \u2212 \u03b7\u201622 = \u2211 k,k\u2032\u2208[n]\u00d7[n] (\u03b7\u0302kk\u2032 \u2212 \u03b7kk\u2032)2 \u2264 n2 \u2016\u03b7\u0302 \u2212 \u03b7\u20162\u221e ,\nwe have\nP (\u2016\u03b7\u0302 \u2212 \u03b7\u20162 > \u01eb) \u2264 P (n \u2016\u03b7\u0302 \u2212 \u03b7\u2016\u221e > \u01eb) .\nputting \u01eb\u2032 = \u01eb/n in (41), the claim in (39) follows."}, {"heading": "6.3 Proof of theorem 1 - Strong consistency", "text": "We now prove the strong consistency of our estimators stated in Theorem 1.\nProof. For the discrete case, by Lemma 3, the expectation E[\u2016\u03c1\u0302\u2212 \u03c1\u20162] goes to zero as T \u2192 \u221e. Furthermore, using the Borel-Cantelli lemma, \u2016\u03c1\u0302\u2212 \u03c1\u20162 converge to its expectation a.s. concluding that \u03c1\u0302 converges a.s. to \u03c1. The same argument goes for \u03c3\u0302, \u03be\u0302, \u03b7\u0302 and \u03c3, \u03be, \u03b7 respectively.\nNow, the function f : Rm \u2192 Rn given by f(x) = (B\u22ba diag(1/x)B)\u221211 is continuous on Rm+ . Moreover, f(\u03c1) = \u03c0 since the optimization problem (7) has a unique minimizer x\u2217 for all \u03c1\u0302, which in particular is given by x\u2217 = \u03c0 when \u03c1\u0302 = \u03c1. Since \u03c1 \u2208 Rm+ by assumption, the argument above shows that almost surely, \u03c1\u0302 \u2208 Rm+ for all sufficiently large T . Therefore, limT\u2192\u221e f(\u03c1\u0302) = f(\u03c1) = \u03c0 almost surely, and the asymptotic strong consistency of \u03c0\u0302 is established.\nTo prove the asymptotic strong consistency of A\u0302 in the discrete case, recall that the minimizer of the quadratic program x\u22baKx \u2212 h\u22bax subject to Gx \u2264 g, Dx = d, is continuous under small perturbations of K,h,G,D, d\n[Dantzig et al., 1967]. In particular, if \u03c0\u0302 is sufficiently close to \u03c0 then A\u0302 is close to A. Since \u03c0\u0302 \u2192 \u03c0 and \u03c3\u0302 \u2192 \u03c3 almost surely, we also have A\u0302 a.s.\u2212\u2192A.\nFor the continuous observations case, note that \u03c0\u0302 and A\u0302 are also solutions of quadratic programs. Also note that \u03be\u0302 \u2192 \u03be and \u03b7\u0302 \u2192 \u03b7 almost surely. Thus we have that A\u0302 a.s.\u2212\u2192A and \u03c0\u0302 a.s.\u2212\u2192\u03c0 as above."}, {"heading": "6.4 Proof of Theorem 2: Bounding the error for \u03c0\u0302 in the discrete observations case", "text": "Proof. Lemma 3 and the fact that \u2016\u03c1\u0302\u2212 \u03c1\u2016\u221e \u2264 \u2016\u03c1\u0302 \u2212 \u03c1\u20162 implies that \u2016\u03c1\u0302\u2212 \u03c1\u2016\u221e = OP (1/ \u221a T ). Hence we make a change of variables,\n\u03c1\u0302 = \u03c1+ 1\u221a T \u03b6. (42)\nTo establish the (eventual) positivity of the entries of \u03c0\u0302, we consider the solution x\u2217 of (8) with \u03bb = 0, e.g. without the normalization \u2211\nxi = 1, and write it as x\u2217 = \u03c0+ \u03b4. Our goal is to understand the relation between \u03b4 and \u03b6.\nObserve that \u03b4 satisfies the system of linear equations\n\u2211\nj\n(\n\u2211\nk\nBkjBki\n\u03c1k\n(\n1 + 1\u221a T \u03b6k \u03c1k\n)\n)\n(\u03c0j + \u03b4j) = 1.\nWe need T sufficiently large so that, with high probability, maxk 1\u221a T \u03b6k \u03c1k \u226a 1, or equivalently, |\u03c1\u0302k \u2212 \u03c1k| \u226a \u03c1k.\nBy taking T & 4g\u03c8/a 2 1 we have\nE[\u2016\u03c1\u0302\u2212 \u03c1\u2016\u221e] \u2264 a1/2.\nSo choosing \u01eb = min \u03c1k/2 \u2265 a1/2 in (35), this condition is satisfied for T & g2\u03c8/a 2 1. Then, approximating 1/(1 + \u01eb) = 1\u2212 \u01eb+O(\u01eb2) gives\n\u2211\nj\n[\n\u2211\nk\nBkjBki \u03c1k\n(\n1\u2212 1\u221a T \u03b6k \u03c1k\n)\n]\n(\u03c0j + \u03b4j)\n= 1 +OP\n(\n1\nT\n)\n.\nNote that since B\u03c0 = \u03c1, the leading order correction for \u03b4 is simply\n\u03b4 = 1\u221a T (B\u0303\u22baB\u0303)\u22121B\u0303\u22ba\n(\n\u03b6\n\u03c1\n)\n+OP\n(\n1\nT\n)\n,\nwhere the matrix B\u0303 = diag(1/ \u221a \u03c1)B.\nLet {ui} and {vi} be the right and left singular vectors of B\u0303 with nonzero singular values \u03c3i(B\u0303), where \u03c31 \u2264 \u03c32 . . . \u2264 \u03c3n; thus, B\u0303ui = \u03c3ivi. The fact that B\u0303 also has n non-zero singular values follows from its definition combined with our Assumption 2d that B has rank n. Then\nB\u0303 \u22ba B\u0303 = \u2211\ni\n\u03c32i uiu \u22ba i (43)\nand hence,\n\u03b4 = 1\u221a T \u2211\ni\n1 \u03c3i \u3008 \u03b6 \u03c1 ,vi\u3009ui +OP\n(\n1\nT\n)\n(44)\nFor the solution x to have strictly positive coordinates we need that |\u03b4j | < \u03c0j for each of j = 1, . . . , n. Without loss of generality, assume that \u03c01 = minj \u03c0j and analyze the worst-case setting. This occurs when the singular vector u1 with smallest singular value coincides with the standard basis vector e1. Then,\n|\u03b41| \u2264 1\u221a T\n1\n\u03c31(B\u0303)minj \u03c1j |\u3008\u03b6,v1\u3009|+OP\n(\n1\nT\n)\n. (45)\nIt follows from (37) that |\u03b41| will be dominated by min\u03c0j \u2265 a0 provided that\nT & g\u03c8\na0a1\u03c31(B\u0303) . (46)\nIn the unlikely event that (i) the vector \u03c0 is uniform (\u03c0j = 1/n for all j), (ii) the matrix B\u0303 has n identical singular values, we need the equation analogous to (45) to hold for all n coordinates. By a union bound argument, an additional factor of log n in the number of samples suffices to ensure, with high probability, the non-negativity of the solution x.\nNext we proceed to bound \u2016\u03c0\u0302 \u2212 \u03c0\u201622. To this end, we write\nx\u2217 \u2212 \u03c0 = \u03b4 = \u2211\ni\n1 \u03c3i(B\u0303) \u3008 \u03c1\u0302\u2212 \u03c1 \u03c1 ,vi\u3009ui +OP\n(\n1\nT\n)\n.\nSince both the {ui} and the {vi} are orthonormal,\n\u2016\u03b4\u201622 = \u2211\ni\n1 \u03c32i (B\u0303) \u3008 \u03c1\u0302 \u2212 \u03c1 \u03c1 ,vi\u30092\n\u2264 1 \u03c321(B\u0303)(min \u03c1k) 2 \u2211\ni\n\u3008\u03c1\u0302\u2212 \u03c1,vi\u30092\n\u2264 \u2016\u03c1\u0302\u2212 \u03c1\u2016 2 2\n\u03c321(B\u0303)a 2 1\n.\nBounding \u2016\u03c1\u0302\u2212 \u03c1\u201622 via Lemma 3 and noting that\n\u2016\u03c0\u0302 \u2212 \u03c0\u20162 = \u2225 \u2225 \u2225 x\u2217\n\u2016x\u2217\u2016 1\n\u2212 \u03c0 \u2225 \u2225\n\u2225 2 \u2264 2 \u2016x\u2217 \u2212 \u03c0\u20162 = 2 \u2016\u03b4\u20162 ,\nthe result in (22) follows."}, {"heading": "6.5 Preliminaries II", "text": "The remaining estimators (\u03c0\u0302 for the continuous observations case, and A\u0302 for both the discrete and continuous observations cases) are obtained as solutions for quadratic programs. Let us take for example the QP for calculating \u03c0\u0302 with continuous observations HMM, given in (23). For this case, the QP is equivalent to\n\u03c0\u0302 = argmin x\n1 2 x \u22ba K \u22ba Kx\u2212 x\u22baK\u22ba \u03be\u0302\nsubject to x \u2265 0 and \u2211i xi = 1. Note that if \u03be\u0302 was equal to its true values \u03be, the solution of the above QP would simply be the true \u03c0. In reality, we only have the estimate \u03be\u0302. In order to analyze the error \u2016\u03c0\u0302 \u2212 \u03c0\u20162, we will need to consider how the solutions of such a quadratic program are affected by errors in \u03be.\nMore generally, we are concerned with two QPs\nminQ(x) = min 1\n2 x\n\u22ba Mx\u2212 x\u22bah, (47)\nmin Q\u0302(x) = min 1\n2 x\n\u22ba M\u0302x\u2212 x\u22bah\u0302, (48)\nboth subject to Gx \u2264 g, Dx = d. We assume that the solution to the first QP is the \u201ctrue\u201d value while the solution to the second is our estimate. So bounding the estimate error is equivalent to bounding the error between the solutions obtained by the above two QPs, where M\u0302 and h\u0302 are perturbed versions of M and h.\nGiven that, note that only the objective function has been perturbed, while the linear constraints remained unaffected. We may thus apply the following classical result on the solution stability of definite quadratic programs.\nTheorem 7. [Daniel, 1973] Let \u03bb = \u03bbmin(M) be the smallest eigenvalue of M , and let \u01eb = max{\u2016M\u0302 \u2212M\u20162, \u2016h\u0302 \u2212 h\u20162}. Let x and x\u0302 be the minimizers of Eqs.(47) and (48), respectively. Then, for \u01eb < \u03bb,\n\u2016x\u2212 x\u0302\u20162 \u2264 \u01eb\n\u03bb\u2212 \u01eb(1 + \u2016x\u20162).\nIn the following we will obtain bounds on \u01eb and \u03bb for the different estimators and invoke the above theorem."}, {"heading": "6.6 Proof of Theorem 3: Bounding the error for \u03c0\u0302 in the continuous observations case", "text": "Proof. Note that in the notation given in Theorem 7, we have h = \u03be \u22ba K and h\u0302 = \u03be\u0302 \u22ba\nK. Since we assumed that the output density parameters are known exactly we have no error in M = K \u22ba\nK. It is immediate that\n\u03bbmin(K \u22ba K) = \u03c321(K),\nand \u01eb \u2264 \u2225 \u2225 \u2225\u03be\u0302 \u2212 \u03be \u2225 \u2225 \u2225\n2 \u2016K\u20162 \u2264 nL\n\u2225 \u2225 \u2225\u03be\u0302 \u2212 \u03be \u2225 \u2225 \u2225\n2 .\nFrom Lemma 4 we have\n\u2225 \u2225 \u2225 \u03be\u0302 \u2212 \u03be \u2225 \u2225 \u2225\n2 .P\n\u221a\n(n lnn)g2\u03c8L 2\nT ,\nwhile by Theorem 7 we have\n\u2016\u03c0\u0302 \u2212 \u03c0\u20162 . \u01eb\n\u03bbmin(K \u22ba K) (1 + \u2016\u03c0\u20162).\nSince \u2016\u03c0\u20162 \u2264 1, the claim follows.\nAs a side remark we note that the form of (24) is somewhat counterintuitive, as it suggests a worse behavior for larger L. Intuitively, however, larger L corresponds to a more peaked \u2014 and hence lower-variance \u2014 density, which ought to imply sharper estimates. Note however that as numerical simulations suggest we typically have\n\u03c321(F\u0303 )L 2\n\u03c321(K\u0303) = O(1).\nThus, whenever \u03c321(F\u0303 ) is well behaved so is the estimate in (24) and the bound is reasonable after all. Finally note that F is stochastic so it behaves very much like the matrix B in the discrete outputs case."}, {"heading": "6.7 Proof of Theorem 4: Bounding the error of A\u0302 in the discrete observations case", "text": "Let A\u0302 be the solution of\nmin Aij\u22650, \u2211 iAij=1\n\u2016\u03c3\u0302 \u2212 C\u0302A\u201622, (25)\nwhere \u03c3\u0302 is given in (5). Recall that Ckk \u2032 ij = \u03c0jBkjBk\u2032i and C\u0302 kk\u2032 ij = \u03c0\u0302jBkjBk\u2032i. First note that if \u03c0 and \u03c3 were known exactly, the above QP could be written as\nminQ(A) = min 1\n2 vec(A)\n\u22ba M vec(A)\u2212 vec(A)\u22bah (49)\nwhere M = C \u22ba C and h = C \u22ba\nvec(\u03c3). Its solution is precisely the transition probability matrix A. In reality, as we only have estimates \u03c0\u0302 and \u03c3\u0302, the optimization problem is perturbed to\nmin Q\u0302(A) = min 1\n2 vec(A)\u22baM\u0302 vec(A) \u2212 vec(A)\u22ba h\u0302 (50)\nwhere M\u0302 = C\u0302 \u22ba C\u0302, and h\u0302 = C\u0302 \u22ba\nvec(\u03c3\u0302). To analyze how errors in \u03c3\u0302 and C\u0302 affect the optimization problem we follow the same route as above. Thus we need to bound \u2016h\u0302 \u2212 h\u20162, \u2016M\u0302 \u2212 M\u20162, and the smallest eigenvalue of M . Regarding the latter, by definition, \u03bbmin(M) = \u03c3 2 1(C), where \u03c31(C) is the smallest singular value of C. A simple exercise in linear algebra yields\n\u03c31(C) \u2265 a0\u03c321(B). (51) The following lemma provides bounds on \u2016M\u0302 \u2212M\u20162 and on \u2016h\u0302\u2212 h\u20162. Lemma 5. Asymptotically, as T \u2192 \u221e,\n\u2016h\u0302\u2212 h\u20162 .P \u221a n (\u2016\u03c0\u0302 \u2212 \u03c0\u20162 + \u2016\u03c3\u0302 \u2212 \u03c3\u20162) (52)\nand\n\u2016M\u0302 \u2212M\u20162 .P 2n\u2016\u03c0\u0302 \u2212 \u03c0\u20162. (53) Proof. By definition, hij = \u2211 k,k\u2032 C kk\u2032 ij \u03c3kk\u2032, and h\u0302ij = \u2211 k,k\u2032 C\u0302 kk\u2032 ij \u03c3\u0302kk\u2032 . Using the definitions of C and C\u0302, up to mixed terms O(\u2016\u03c0\u0302 \u2212 \u03c0\u2016\u221e\u2016\u03c3\u0302 \u2212 \u03c3\u2016\u221e), we obtain\nh\u0302ij \u2212 hij = (\u03c0\u0302j \u2212 \u03c0j) \u2211\nkk\u2032\nBkjBk\u2032i\u03c3kk\u2032\n+\u03c0j \u2211\nkk\u2032\nBkjBk\u2032i(\u03c3\u0302kk\u2032 \u2212 \u03c3kk\u2032)\nSince each of \u2016\u03c0\u0302 \u2212 \u03c0\u2016\u221e and \u2016\u03c3\u0302 \u2212 \u03c3\u2016\u221e are OP (1/ \u221a T ), the neglected mixed terms are asymptotically negligible as compared to each of the first two ones. Next, we use the fact that \u03c3kk\u2032 \u2264 1, \u03c0j \u2264 1 and \u2211\nkk\u2032 BkjBk\u2032i \u2264 1 to obtain that\n\u2225 \u2225 \u2225h\u0302\u2212 h \u2225 \u2225 \u2225\n2 .P\n\u221a n \u2016\u03c0\u0302 \u2212 \u03c0\u20162 + \u221a n \u2016vec(\u03c3\u0302)\u2212 vec(\u03c3)\u20162\nSimilarly, we have that for the n2 \u00d7 n2 matrix M , and not including higher order mixed terms (\u03c0\u0302j \u2212 \u03c0j)(\u03c0\u0302\u03b2 \u2212 \u03c0\u03b2), which are asymptotically negligible,\n(M\u0302 \u2212M)ij,\u03b1\u03b2 = (\u03c0\u0302j \u2212 \u03c0j)\u03c0\u03b2 \u2211\nkk\u2032\nBkjBk\u03b2Bk\u2032iBk\u2032\u03b1\n+(\u03c0\u0302\u03b2 \u2212 \u03c0\u03b2)\u03c0j \u2211\nkk\u2032\nBkjBk\u03b2Bk\u2032iBk\u2032\u03b1\nNote that \u2211 kk\u2032 BkjBk\u03b2Bk\u2032iBk\u2032\u03b1 = ( \u2211 k BkjBk\u03b2)( \u2211 k\u2032 Bk\u2032iBk\u2032\u03b1) \u2264 1. Hence, by similar arguments as for h, (53) follows.\nWe can now prove Theorem 4:\nProof. (of Theorem 4) Lemma 3, together with (22), implies that with high probability,\n\u2016\u03c3\u0302 \u2212 \u03c3\u2016F .P\n\u221a\ng2\u03c8 T \u2212 1 ,\nand\n\u2016\u03c0\u0302 \u2212 \u03c0\u20162 .P\n\u221a\ng2\u03c8\nTa21\u03c3 2 1(B\u0303)\n.\nInserting these into (52) and (53) yields, w.h.p.,\n\u01eb = max {\u2225 \u2225 \u2225h\u0302\u2212 h \u2225 \u2225 \u2225 2 , \u2225 \u2225 \u2225M\u0302 \u2212M \u2225 \u2225 \u2225 2 }\n.\n\u221a\nn2g2\u03c8\nTa21\u03c3 2 1(B\u0303)\n. (54)\nBy Theorem 7, we have that \u2225\n\u2225 \u2225A\u0302\u2212A \u2225 \u2225 \u2225\nF .\n\u01eb\n\u03bb1(M) (1 + \u2016A\u2016F ), (55)\nwhere \u2016A\u2016F \u2264 \u221a n since A is column-stochastic. The claim follows by substituting the bounds on \u01eb in (54) and on \u03bb1(M) = \u03c3 2 1(C) \u2265 a20\u03c341(B) in (51) into (55) and noting that \u03c321(B\u0303) \u2265 \u03c321(B)."}, {"heading": "6.8 Proof of Theorem 5: Bounding the error of A\u0302 in the continuous observations case", "text": "Let A\u0302 be the solution of\nmin Aij\u22650, \u2211 iAij=1\n\u2016\u03b7\u0302 \u2212 C\u0302A\u201622, (25)\nwhere \u03b7\u0302 is given in (19) and Ckk \u2032 ij = \u03c0jFkjFk\u2032i and C\u0302 kk\u2032 ij = \u03c0\u0302jFkjFk\u2032i. The above QP can be written as\nmin Q\u0302(A) = min 1\n2 vec(A)\u22baM\u0302 vec(A) \u2212 vec(A)\u22ba h\u0302 (56)\nwhere M\u0302 = C\u0302 \u22ba C\u0302, and h\u0302 = C\u0302 \u22ba\nvec(\u03c3\u0302). Exactly as in the previous subsection, we want to bound the difference\nbetween the solutions for the above QP and the unperturbed one. First note that\n\u03c31(C) \u2265 a0\u03c321(F ). (57)\nNext we give the analogue of lemma 5.\nLemma 6. Asymptotically, as T \u2192 \u221e,\n\u2016h\u0302\u2212 h\u20162 .P \u221a n ( 1\na0 \u2016\u03c0\u0302 \u2212 \u03c0\u20162 + \u2016\u03b7\u0302 \u2212 \u03b7\u20162\n)\n(58)\nand\n\u2016M\u0302 \u2212M\u20162 .P 2n \u2016\u03c0\u0302 \u2212 \u03c0\u20162\na0 . (59)\nProof. In contrast to Lemma 5, here F is also perturbed due to errors in \u03c0\u0302 with\nF\u0302ij =\n\u222b\nY\n\u03c0\u0302ifi(y)fj(y) \u2211\nk \u03c0\u0302kfk(y) dy.\nExpending the difference \u2206Fij \u2261 \u2223 \u2223 \u2223F\u0302ij \u2212 Fij \u2223 \u2223\n\u2223 up to first order in \u03c0\u0302 \u2212 \u03c0 we find that\n\u2016\u2206F\u2016F \u2264 \u2016\u03c0\u0302 \u2212 \u03c0\u2016\u221e\na0 \u2016F\u2016F \u2264\n\u221a n \u2016\u03c0\u0302 \u2212 \u03c0\u2016\u221e\na0 ,\nwhere in the last inequality we used the fact that F is stochastic. Repeating the arguments in the proof for Lemma 5 and noting that a0 \u226a 1 we get (58) and (59).\nWe now come to the proof of Theorem 5.\nProof. (of Theorem 5) Lemma 4, together with (24), implies that with high probability,\n\u2016\u03b7\u0302 \u2212 \u03b7\u2016F .P\n\u221a\n(n2 lnn)g2\u03c8 T \u2212 1 ,\nand\n\u2016\u03c0\u0302 \u2212 \u03c0\u20162 .P\n\u221a\n(n3 lnn)g2\u03c8L 4\nT\u03c341(K\u0303)\nInserting these into (58) and (59) yields, w.h.p.,\n\u01eb = max {\u2225 \u2225 \u2225 h\u0302\u2212 h \u2225 \u2225 \u2225 2 , \u2225 \u2225 \u2225 M\u0302 \u2212M \u2225 \u2225 \u2225 2 }\n.\n\u221a\n(n5 lnn)g2\u03c8L 4\nT\u03c341(K\u0303) . (60)\nBy Theorem 7, we have that\n\u2225 \u2225 \u2225A\u0302\u2212A \u2225 \u2225 \u2225\nF .\n\u01eb\n\u03bb1(M) (1 + \u2016A\u2016F ), (61)\nwhere \u2016A\u2016F \u2264 \u221a n since A is column-stochastic. The claim follows by substituting the bounds on \u01eb in (60) and on \u03bb1(M) = \u03c3 2 1(C) \u2265 a20\u03c341(F ) in (51) into (61) and noting that \u03c321(F\u0303 ) \u2265 \u03c321(F ).\nAs for remark 1, we point out that estimating \u03b7\u2032 with the help of the matrix K (instead of \u03b7 with F ) results in an estimator that is not O(1/T )- Lipschitz any more but O(L2/T )-Lipschitz with L = maxi\u2208[n] supy\u2208R f\u03b8i(y). This means that in principle we will need many more samples to accurately estimate \u03b7\u2032 compared to \u03b7, see Lemma 4. Thus, since in high dimensions calculating F via numerical integration may be computational intensive, choosing between the two estimators is in some sense choosing between working with limited number of samples and computational efficiency."}, {"heading": "6.9 Proof of Theorem 6: Perturbations in the output parameters", "text": "We give here the proof for the perturbation in the matrix F . The proof for perturbations in the matrix K is similar.\nProof. By definition, bij = \u2211 k,k\u2032 C kk\u2032 ij \u03c3kk\u2032 , and b\u0302ij = \u2211 k,k\u2032 C\u0302 kk\u2032 ij \u03c3\u0302kk\u2032 . Using the definitions of C and C\u0302, up to first order in {\u2016\u03c0\u0302 \u2212 \u03c0\u2016\u221e , \u2016\u03c3\u0302 \u2212 \u03c3\u2016\u221e , \u01ebF } we obtain\nb\u0302ij \u2212 bij = (\u03c0\u0302j \u2212 \u03c0j) \u2211\nkk\u2032\nBkjBk\u2032i\u03c3kk\u2032\n+\u03c0j \u2211\nkk\u2032\nBkjBk\u2032i(\u03c3\u0302kk\u2032 \u2212 \u03c3kk\u2032)\n+\u01ebF\u03c0j \u2211\nkk\u2032\n(PkjBk\u2032i +BkjPk\u2032i)\u03c3kk\u2032 .\nAs the two first terms already considered we focus on the last term. It can be shown that:\n\u2211\nij\n(\n\u03c0j \u2211\nkk\u2032\nPkjBk\u2032i\u03c3kk\u2032\n)2\n\u2264 n \u2016P\u20162F .\nThus \u2225\n\u2225 \u2225 b\u0302\u2212 b\n\u2225 \u2225 \u2225 2 \u2264 \u221an (\u2016\u03c0\u0302 \u2212 \u03c0\u20162 + \u2016vec(\u03c3\u0302)\u2212 vec(\u03c3)\u20162+ (62)\n+2\u01ebF \u2016P\u2016F ) (1 + o(1)).\nSimilarly, for the matrix K up to first order in {\u2016\u03c0\u0302 \u2212 \u03c0\u2016\u221e , \u01ebF} we have\n(K\u0302 \u2212K)ij,\u03b1\u03b2 = (\u03c0\u0302j \u2212 \u03c0j)\u03c0\u03b2 \u2211\nkk\u2032\nBkjBk\u03b2Bk\u2032iBk\u2032\u03b1\n+ (\u03c0\u0302\u03b2 \u2212 \u03c0\u03b2)\u03c0j \u2211\nkk\u2032\nBkjBk\u03b2Bk\u2032iBk\u2032\u03b1\n+ \u01ebF\u03c0j\u03c0\u03b2 \u2211\nkk\u2032\nPkjBk\u03b2Bk\u2032iBk\u2032\u03b1 + . . .\n+ \u01ebF\u03c0\u03b2\u03c0j \u2211\nkk\u2032\nBkjBk\u03b2Bk\u2032iPk\u2032\u03b1.\nAgain considering only the terms including P and using the facts that \u2211\nk BkjBk\u03b2 \u2264 1 and \u2211 kk\u2032(PkjBk\u2032i) 2 \u2264 \u2211k P 2kj we similarly find that\n\u2225 \u2225 \u2225 K\u0302 \u2212K \u2225 \u2225 \u2225\n2 \u2264 (1 + op(1))2n (\u2016\u03c0\u0302 \u2212 \u03c0\u20162 + 4\u01ebF \u2016P\u2016F ) .\nRepeating the analysis in the proofs for Theorems 3, 4 and 5 give the desired result."}], "references": [{"title": "On the computational complexity of approximating distributions by probabilistic automata", "author": ["N. Abe", "M.K. Warmuth"], "venue": "Machine Learning,", "citeRegEx": "Abe and Warmuth.,? \\Q1992\\E", "shortCiteRegEx": "Abe and Warmuth.", "year": 1992}, {"title": "A method of moments for mixture models and hidden markov models", "author": ["A. Anandkumar", "D. Hsu", "S.M. Kakade"], "venue": "In COLT,", "citeRegEx": "Anandkumar et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Anandkumar et al\\.", "year": 2012}, {"title": "A maximization technique occurring in the statistical analysis of probabilistic functions of Markov chains", "author": ["L.E. Baum", "T. Petrie", "G. Soules", "N. Weiss"], "venue": "Ann. Math. Stat.,", "citeRegEx": "Baum et al\\.,? \\Q1970\\E", "shortCiteRegEx": "Baum et al\\.", "year": 1970}, {"title": "Polynomial learning of distribution families", "author": ["M. Belkin", "K. Sinha"], "venue": "In Foundations of Computer Science (FOCS),", "citeRegEx": "Belkin and Sinha.,? \\Q2010\\E", "shortCiteRegEx": "Belkin and Sinha.", "year": 2010}, {"title": "Inference in hidden Markov models", "author": ["O. Capp\u00e9", "E. Moulines", "T. Ryd\u00e9n"], "venue": null, "citeRegEx": "Capp\u00e9 et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Capp\u00e9 et al\\.", "year": 2005}, {"title": "Full reconstruction of Markov models on evolutionary trees: identifiability and consistency", "author": ["J.T. Chang"], "venue": "Math. Biosci.,", "citeRegEx": "Chang.,? \\Q1996\\E", "shortCiteRegEx": "Chang.", "year": 1996}, {"title": "Learning hidden Markov models using nonnegative matrix factorization", "author": ["G. Cybenko", "V. Crespi"], "venue": "IEEE Trans. Information Theory,", "citeRegEx": "Cybenko and Crespi.,? \\Q2011\\E", "shortCiteRegEx": "Cybenko and Crespi.", "year": 2011}, {"title": "Stability of the solution of definite quadratic programs", "author": ["J.W. Daniel"], "venue": "Mathematical Programming,", "citeRegEx": "Daniel.,? \\Q1973\\E", "shortCiteRegEx": "Daniel.", "year": 1973}, {"title": "On the continuity of the minimum sets of a continuous function", "author": ["G.B. Dantzig", "J. Folkman", "N. Shapiro"], "venue": "J. Math. Anal. Appl.,", "citeRegEx": "Dantzig et al\\.,? \\Q1967\\E", "shortCiteRegEx": "Dantzig et al\\.", "year": 1967}, {"title": "Interior point approach to linear, quadratic and convex programming, volume 277 of Mathematics and its Applications", "author": ["D. den Hertog"], "venue": null, "citeRegEx": "Hertog.,? \\Q1994\\E", "shortCiteRegEx": "Hertog.", "year": 1994}, {"title": "Asymptotics of the maximum likelihood estimator for general hidden Markov models", "author": ["R. Douc", "C. Matias"], "venue": "Bernoulli, 7(3):pp", "citeRegEx": "Douc and Matias.,? \\Q2001\\E", "shortCiteRegEx": "Douc and Matias.", "year": 2001}, {"title": "An algorithm to find the global optimum of left-to-right hidden Markov model parameters", "author": ["A. Farag\u00f3", "G. Lugosi"], "venue": "Problems Control Inform. Theory/Problemy Upravlen. Teor. Inform.,", "citeRegEx": "Farag\u00f3 and Lugosi.,? \\Q1989\\E", "shortCiteRegEx": "Farag\u00f3 and Lugosi.", "year": 1989}, {"title": "A spectral algorithm for learning hidden markov models", "author": ["D. Hsu", "S.M. Kakade", "T. Zhang"], "venue": "In COLT,", "citeRegEx": "Hsu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hsu et al\\.", "year": 2009}, {"title": "Uniform Chernoff and Dvoretzky-KieferWolfowitz-type inequalities for Markov chains and related processes, arxiv:1207.4678", "author": ["A. Kontorovich", "R. Weiss"], "venue": null, "citeRegEx": "Kontorovich and Weiss.,? \\Q2012\\E", "shortCiteRegEx": "Kontorovich and Weiss.", "year": 2012}, {"title": "Non-negative matrix factorization for parameter estimation in hidden markov models", "author": ["B. Lakshminarayanan", "R. Raich"], "venue": "In Machine Learning for Signal Processing (MLSP), pages", "citeRegEx": "Lakshminarayanan and Raich.,? \\Q2010\\E", "shortCiteRegEx": "Lakshminarayanan and Raich.", "year": 2010}, {"title": "Complexity of comparing hidden markov models", "author": ["R.B. Lyngs\u00f8", "C.N. Pedersen"], "venue": "In Proceedings of the 12th International Symposium on Algorithms and Computation,", "citeRegEx": "Lyngs\u00f8 and Pedersen.,? \\Q2001\\E", "shortCiteRegEx": "Lyngs\u00f8 and Pedersen.", "year": 2001}, {"title": "Stability bounds for stationary \u03c6-mixing and \u03b2-mixing processes", "author": ["M. Mohri", "A. Rostamizadeh"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Mohri and Rostamizadeh.,? \\Q2010\\E", "shortCiteRegEx": "Mohri and Rostamizadeh.", "year": 2010}, {"title": "Settling the polynomial learnability of mixtures of gaussians", "author": ["Ankur Moitra", "Gregory Valiant"], "venue": "IEEE 51st Annual Symposium on Foundations of Computer Science,", "citeRegEx": "Moitra and Valiant.,? \\Q2010\\E", "shortCiteRegEx": "Moitra and Valiant.", "year": 2010}, {"title": "Learning nonsingular phylogenies and hidden Markov models", "author": ["E. Mossel", "S. Roch"], "venue": "Ann. Appl. Probab.,", "citeRegEx": "Mossel and Roch.,? \\Q2006\\E", "shortCiteRegEx": "Mossel and Roch.", "year": 2006}, {"title": "Interior-point polynomial algorithms in convex programming", "author": ["Y. Nesterov", "A. Nemirovskii"], "venue": null, "citeRegEx": "Nesterov and Nemirovskii.,? \\Q1994\\E", "shortCiteRegEx": "Nesterov and Nemirovskii.", "year": 1994}, {"title": "Readings in speech recognition. chapter A tutorial on hidden Markov models and selected applications in speech recognition, pages", "author": ["L.R. Rabiner"], "venue": null, "citeRegEx": "Rabiner.,? \\Q1990\\E", "shortCiteRegEx": "Rabiner.", "year": 1990}, {"title": "A unifying review of linear gaussian models", "author": ["S. Roweis", "Z. Ghahramani"], "venue": "Neural Comput.,", "citeRegEx": "Roweis and Ghahramani.,? \\Q1999\\E", "shortCiteRegEx": "Roweis and Ghahramani.", "year": 1999}, {"title": "Reduced-rank Hidden Markov Models", "author": ["S.M. Siddiqi", "B. Boots", "G.J. Gordon"], "venue": "In AISTAT,", "citeRegEx": "Siddiqi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Siddiqi et al\\.", "year": 2010}, {"title": "On the learnability of Hidden Markov Models", "author": ["S. Terwijn"], "venue": "In Proceedings of the 6th International Colloquium on Grammatical Inference: Algorithms and Applications,", "citeRegEx": "Terwijn.,? \\Q2002\\E", "shortCiteRegEx": "Terwijn.", "year": 2002}, {"title": "The following concentration result from Kontorovich and Weiss [2012, Theorem 1] is our main tool in proving the error bounds given here", "author": ["\u2264 L"], "venue": "Let Y = Y0,", "citeRegEx": "\u221e.,? \\Q2012\\E", "shortCiteRegEx": "\u221e.", "year": 2012}], "referenceMentions": [{"referenceID": 2, "context": "When the number of hidden states is known, the standard method for estimating the HMM parameters from given observed data is the Baum-Welch algorithm [Baum et al., 1970].", "startOffset": 150, "endOffset": 169}, {"referenceID": 8, "context": "Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein.", "startOffset": 0, "endOffset": 26}, {"referenceID": 2, "context": "Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein.", "startOffset": 27, "endOffset": 51}, {"referenceID": 2, "context": "Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein. Related work. The problem of estimating HMM parameters from observations has been actively studied since the 1970\u2019s, see Capp\u00e9 et al. [2005], Rabiner [1990], Roweis and Ghahramani [1999].", "startOffset": 27, "endOffset": 216}, {"referenceID": 2, "context": "Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein. Related work. The problem of estimating HMM parameters from observations has been actively studied since the 1970\u2019s, see Capp\u00e9 et al. [2005], Rabiner [1990], Roweis and Ghahramani [1999].", "startOffset": 27, "endOffset": 232}, {"referenceID": 2, "context": "Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein. Related work. The problem of estimating HMM parameters from observations has been actively studied since the 1970\u2019s, see Capp\u00e9 et al. [2005], Rabiner [1990], Roweis and Ghahramani [1999]. While computing the maximumlikelihood estimator for an HMM is in general computationally intractable, under mild conditions, such an estimator is asymptotically consistent and normally distributed, see Bickel et al.", "startOffset": 27, "endOffset": 262}, {"referenceID": 2, "context": "Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein. Related work. The problem of estimating HMM parameters from observations has been actively studied since the 1970\u2019s, see Capp\u00e9 et al. [2005], Rabiner [1990], Roweis and Ghahramani [1999]. While computing the maximumlikelihood estimator for an HMM is in general computationally intractable, under mild conditions, such an estimator is asymptotically consistent and normally distributed, see Bickel et al. [1998], Chang [1996], Douc and Matias [2001].", "startOffset": 27, "endOffset": 486}, {"referenceID": 2, "context": "Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein. Related work. The problem of estimating HMM parameters from observations has been actively studied since the 1970\u2019s, see Capp\u00e9 et al. [2005], Rabiner [1990], Roweis and Ghahramani [1999]. While computing the maximumlikelihood estimator for an HMM is in general computationally intractable, under mild conditions, such an estimator is asymptotically consistent and normally distributed, see Bickel et al. [1998], Chang [1996], Douc and Matias [2001].", "startOffset": 27, "endOffset": 500}, {"referenceID": 2, "context": "Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein. Related work. The problem of estimating HMM parameters from observations has been actively studied since the 1970\u2019s, see Capp\u00e9 et al. [2005], Rabiner [1990], Roweis and Ghahramani [1999]. While computing the maximumlikelihood estimator for an HMM is in general computationally intractable, under mild conditions, such an estimator is asymptotically consistent and normally distributed, see Bickel et al. [1998], Chang [1996], Douc and Matias [2001]. In recent years, there has been a renewed interest in learning HMMs, in particular under various assumptions that render the learning problem tractable [Farag\u00f3 and Lugosi, 1989, Hsu et al.", "startOffset": 27, "endOffset": 524}, {"referenceID": 1, "context": ", 2010, Anandkumar et al., 2012]. Also, Cybenko and Crespi [2011], Lakshminarayanan and Raich [2010] recently suggested Non-negative Matrix Factorization (NNMF) approaches for learning HMMs.", "startOffset": 8, "endOffset": 66}, {"referenceID": 1, "context": ", 2010, Anandkumar et al., 2012]. Also, Cybenko and Crespi [2011], Lakshminarayanan and Raich [2010] recently suggested Non-negative Matrix Factorization (NNMF) approaches for learning HMMs.", "startOffset": 8, "endOffset": 101}, {"referenceID": 16, "context": "However, if these are algorithmically stable \u2014 as such methods typically are \u2014 the iid assumption can be replaced by strong mixing [Mohri and Rostamizadeh, 2010].", "startOffset": 131, "endOffset": 161}, {"referenceID": 3, "context": "Belkin and Sinha [2010]).", "startOffset": 0, "endOffset": 24}, {"referenceID": 19, "context": "(6) Since \u2212 log(x) is convex, (Bx)k is a linear combination of the unknown variables xj , and the constraints are all linear, the above is nothing but a convex program, easily solved via standard optimization methods [Nesterov and Nemirovskii, 1994].", "startOffset": 217, "endOffset": 249}], "year": 2013, "abstractText": "We present a novel approach to learning an HMM whose outputs are distributed according to a parametric family. This is done by decoupling the learning task into two steps: first estimating the output parameters, and then estimating the hidden states transition probabilities. The first step is accomplished by fitting a mixture model to the output stationary distribution. Given the parameters of this mixture model, the second step is formulated as the solution of an easily solvable convex quadratic program. We provide an error analysis for the estimated transition probabilities and show they are robust to small perturbations in the estimates of the mixture parameters. Finally, we support our analysis with some encouraging empirical results.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}