{"id": "1302.6937", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Feb-2013", "title": "Online Convex Optimization Against Adversaries with Memory and Application to Statistical Arbitrage", "abstract": "in many online learning scenarios optimal loss functions are not linear, but rather linear on demand. our first contribution is a complete characterization of sufficient and necessary conditions for learning with memory, accompanied with a novel algorithm for this region that attains the optimal o ( \\ sqrt { t } ) - regret. this improves previous online learning paradigm that guaranteed o ( t ^ { 2 / 10 } ) regret and required more stringent conditions. as canonical application of the new implementation, we address the classical problem in finance of constructing efficient reverting algorithms. we design an initial online learning algorithm for this problem, and provide guarantees for its performance. we complement certain theoretical findings with an empirical guide that verifies our theoretical results on financial data.", "histories": [["v1", "Wed, 27 Feb 2013 17:46:43 GMT  (43kb)", "http://arxiv.org/abs/1302.6937v1", "16 pages, 3 figures"], ["v2", "Tue, 10 Jun 2014 07:41:36 GMT  (48kb)", "http://arxiv.org/abs/1302.6937v2", "22 pages, 2 figures"]], "COMMENTS": "16 pages, 3 figures", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["oren anava", "elad hazan", "shie mannor"], "accepted": false, "id": "1302.6937"}, "pdf": {"name": "1302.6937.pdf", "metadata": {"source": "CRF", "title": "Online Learning for Loss Functions with Memory and Applications to Statistical Arbitrage", "authors": ["Oren Anava", "Elad Hazan", "Shie Mannor"], "emails": ["soanava@tx.technion.ac.il", "ehazan@ie.technion.ac.il", "shie@ee.technion.ac.il"], "sections": [{"heading": null, "text": "ar X\niv :1\n30 2.\n69 37\nv1 [\ncs .L\nG ]\n2 7\n\u221a T )-regret. This improves previous online learning algorithms that guaranteed O(T 2/3) regret and required more stringent conditions. As an application of the new technique, we address the classical problem in finance of constructing mean reverting portfolios. We design an efficient online learning algorithm for this problem, and provide guarantees for its performance. We complement our theoretical findings with an empirical study that verifies our theoretical results on financial data."}, {"heading": "1 Introduction", "text": "In numerous online learning scenarios the environment is not completely oblivious to the decision maker, and the decision maker\u2019s historical actions affect her current state and future rewards. We are particularly concerned in scenarios in which this historic effect is relatively short-term and simple, in contrast to stateaction models in which better tailored reinforcement learning models have been devised [YMS09].\nThus, our focus is on online learning in which actions have short-term effects on future losses. This model was initially considered in the information theory community [MOSW06], with an eye on applications in compression, coding and portfolio selection. In this work, after describing our contributions to this framework, we apply this model to finding statistical arbitrage opportunities in financial market data.\nWe start by studying the framework of online learning with memory. Our first result is a novel algorithm for this framework that attains optimal regret bounds on the order of O( \u221a T ), where T is the number of prediction iterations. The algorithm is also computationally efficient, and we show that its assumptions are not only sufficient, but in fact necessary for any efficient algorithm for learning with memory. These bounds improve [MOSW06], who attains a regret bound of O(T 2/3). Thus, our results show that in fact the optimal regret bounds for this framework are of the same order as standard memoryless learning, and the overhead for the more complicated model is in the memory effect only.\nNext, we proceed to study our motivating problem \u2014 constructing mean revering portfolios. In the literature, \u201cstatistical arbitrage\u201d refers to statistical mispricing of one or more assets based on the expected\nvalue of these assets. One of the most common trading strategies, known as \u201cpairs trading\u201d, seeks to create a mean reverting portfolio by combining two different assets (typically using both short and long sales). Then, by buying the combined portfolio below its mean and selling it above, one can have an expected positive profit with low risk.\nThis strategy consists of three main steps: choosing the two underlying assets, then finding appropriate distribution of weights over them, and finally applying trading algorithms (which determine the buying and selling points) to maximize profit. In this work we focus on the first two steps with the following extensions: we allow portfolios that consist of more than two assets, and we consider an online scheme in which the distribution of weights can be updated (up to some extent). I.e., given a set of n different assets we wish to isolate a subset of k assets that has a large amount of mean reversion, and then determine a certain weight distribution over this subset.\nThe problem of modifying the weights of a portfolio in order to maximize mean reversion is a learning problem with memory: the weights of previous iterations determine the price of the mixed asset, and thus the overall performance in terms of mean reversion. We cast this problem formally as a learning with memory problem, and utilize our new technique to solve it online. This yields the first sub-linear regret algorithm for this problem. Besides the theoretical sublinear regret bound, we test the resulting algorithm and demonstrate its effectiveness on financial data."}, {"heading": "1.1 Related work", "text": "Statistical arbitrage and in particular pairs trading strategies initially took place in the mid 80\u2019s [EG87]. Since then, a great deal of work has been done on the problem of assembling mean reverting portfolios, mostly using cointegration techniques (see [Vid11] for more comprehensive information). In order to quantify the amount of mean reversion in various portfolios, different proxies are often suggested such as zero-crossing and predictability [Sch11, D\u2019A11]. In this work, we consider a new proxy for mean reversion which is aimed at maximizing fluctuation, as well as keeping the mean close to zero. Furthermore, whereas classical cointegration techniques require training period before applying a trading strategy (see for instance [AL10, AM12]), the online approach does not require that, in addition to providing a performance guarantee against the best mean reverting portfolio in hindsight."}, {"heading": "2 Online learning with memory", "text": "Online learning is a game-theoretic optimization framework, where iteratively an online player chooses a decision xt, and suffers loss ft(xt). The loss function ft is chosen by an all-powerful adversary with full knowledge of our learning algorithm (see for instance [CBL06]).\nHere we consider the following extension. At iteration t, an online player chooses a decision xt \u2208 K, where K is called the decision set. Then, an adversary chooses a loss function ft : Km \u2192 R, and the online player suffers loss of ft(xt\u2212m+1, . . . , xt). Notice that the loss at iteration t depends on the previous m\u2212 1 decisions of the player, as well as on his current decision.\nOur goal in this framework is to minimize the sum of losses over predefined number of iterations T . A reasonable benchmark is to try to be not much worse than the total loss suffered by the best decision in hindsight. More precisely, we define the regret as\nRT =\nT \u2211\nt=m\nft(xt\u2212m+1, . . . , xt)\u2212min x\nT \u2211\nt=m\nft(x, . . . , x), (1)\nand wish to obtain efficient algorithms, whose regret grows sub-linearly in T , corresponding to an average per-round regret going to zero as T increases. 1\nWe henceforth make the following assumptions. The first two assumptions are standard and necessary for any regret minimization algorithm to apply, even without memory. Assumption three is the only new assumption we make, and as we explain - it is a necessary assumption if one considers efficient algorithms.\n1. The diameter of K is bounded, i.e., there exists D > 0, such that supx,y\u2208K \u2016x\u2212 y\u2016 \u2264 D , where \u2016 \u00b7 \u2016 refers to the \u21132 norm.\n2. There exists G > 0, such that\nsup (xt\u2212m+1,...,xt),t\n\u2016\u2207ft(xt\u2212m+1, . . . , xt)\u2016 \u2264 G.\nIt follows that ft is Lipchitz continuous with a Lipchitz constant G.\n3. Define gt(x) = ft(x, . . . , x). Then, we assume that gt(x) is convex in x, for all t. This assumption is essentially necessary for an efficient algorithm, since achieving sublinear regret bound for {ft}Tt=1 implies also that\n\u2211T t=1 gt(x) can be minimized efficiently."}, {"heading": "2.1 Algorithm and analysis", "text": "By assumption 3 the functions {gt}Tt=1 are convex, and hence we can apply the Online Gradient Descent (OGD) algorithm of [Zin03] with some modifications.\nAlgorithm 1 OGD with Memory 1: Input: Learning rate \u03b7. 2: Choose x1 \u2208 K arbitrarily. 3: for t = 1 to T do 4: Play xt and suffer loss ft(xt\u2212m+1, . . . , xt).\n5: Set xt+1 \u2190 \u03a0K ( xt \u2212 \u03b7\u2207gt(xt) ) 6: end for\nHere, \u03a0K is the Euclidean projection onto K, i.e.\n\u03a0K(y) = argmin x\u2208K\n\u2016y \u2212 x\u2016.\n1The iterations in which t < m are ignored since we assume that the loss per iteration is bounded by a constant, this adds at most a constant to the final regret bound.\nFor Algorithm 1 we can prove the following bound.\nTheorem 2.1. Let G and D be as defined in Section 2, and set \u03b7 = D G \u221a mT . Then, Algorithm 1 achieves the following regret bound for {ft}Tt=1:\nRT =\nT \u2211\nt=m\nft(xt\u2212m+1, . . . , xt)\u2212min x\nT \u2211\nt=m\nft(x, . . . , x) \u2264 2 \u00b7GD \u221a mT. (2)\nProof. By applying algorithm 1 for the loss functions {gt}Tt=1 we have that\nT \u2211\nt=m\ngt(xt)\u2212min x\nT \u2211\nt=m\ngt(x) \u2264 D2\n2\u03b7 +\n\u03b7G2T\n2 ,\nusing the analysis of [Zin03], and from the definitions of ft and gt it follows that\nT \u2211\nt=m\nft(xt, . . . , xt)\u2212min x\nT \u2211\nt=m\nft(x, . . . , x) \u2264 D2\n2\u03b7 +\n\u03b7G2T\n2 . (3)\nOn the other hand, since ft is Lipshitz continuous for the Lipshitz constant G we have:\n|ft(xt, . . . , xt)\u2212 ft(xt\u2212m+1, . . . , xt)|2\n\u2264 (G \u00b7 \u2016(xt, . . . , xt)\u2212 (xt\u2212m+1, . . . , xt)\u2016)2 = G2 \u00b7 m\u22121 \u2211\nj=1\n\u2016xt \u2212 xt\u2212j\u20162\n\u2264 G2 \u00b7 m\u22121 \u2211\nj=1\nj \u2211\nl=1\n\u2016xt\u2212l+1 \u2212 xt\u2212l\u20162 \u2264 G2 \u00b7 m\u22121 \u2211\nj=1\nj \u2211\nl=1\n\u2016\u03b7\u2207gt\u2212l(xt\u2212l)\u20162\n\u2264 G2 \u00b7 m\u22121 \u2211\nj=1\nj \u2211\nl=1\n\u03b72G2 = G4 \u00b7 m\u22121 \u2211\nj=1\nj \u2211\nl=1\n\u03b72 \u2264 m2\u03b72G4,\nwhich implies that |ft(xt, . . . , xt)\u2212 ft(xt\u2212m+1, . . . , xt)| \u2264 m\u03b7G2.\nSumming the above for t = m, . . . , T we get:\n\u2223 \u2223 \u2223 \u2223 \u2223 T \u2211\nt=m\nft(xt, . . . , xt)\u2212 T \u2211\nt=m\nft(xt\u2212m+1, . . . , xt)\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2264 T \u2211\nt=m\nm\u03b7G2 = m\u03b7G2T. (4)\nNow, by combining Equations (3) and (4) we get the following inequality:\nT \u2211\nt=m\nft(xt\u2212m+1, . . . , xt)\u2212min x\nT \u2211\nt=m\nft(x, . . . , x) \u2264 D2\n2\u03b7 +\n\u03b7G2T\n2 +m\u03b7G2T.\nFinally, substituting \u03b7 = D G \u221a mT yields\nRT = T \u2211\nt=m\nft(xt\u2212m+1, . . . , xt)\u2212min x\nT \u2211\nt=m\nft(x, . . . , x) \u2264 2 \u00b7GD \u221a mT,\nwhich completes the proof."}, {"heading": "3 Application to finance", "text": "In this section we use the technique just developed to find and exploit statistical arbitrage opportunities. Roughly speaking, the goal is to synthetically create a mean reverting portfolio, exploiting correlation between similar assets. That is, we are seeking a strategy that maintains weights upon predefined set of assets, such that the combined portfolio is mean reverting.\nAs a first step we define a criterion for measuring mean reversion, that is empirically well behaving. Unfortunately, this criterion is not convex (as are most of other previously considered criteria), and we define a semi-definite relaxation to cope with the problem. Another difficulty comes from the very nature of the problem: weights of one iteration affect future performance, thus memory comes unavoidably into the picture.\nWe proceed to formally define the new mean reversion criterion, its semi-definite relaxation, and the use of our new memory-learning algorithm in this model."}, {"heading": "3.1 Problem definition", "text": "Tendency to return to the mean is not a quantifiable criterion for mean reversion, and the literature addresses several proxies to capture the notion of mean reversion, e.g., in [Sch11, D\u2019A11]. In this work, we present a new criterion for mean reversion effectiveness: low squared mean and high variance. More precisely, we denote by yt \u2208 Rn the prices of n assets at time t, and by xt \u2208 Rn a distribution of weights over these assets (we allow short selling, thus xt can contain negative entries).\nSince short selling is allowed, the norm of xt can sum up to an arbitrary number, determined by the loan flexibility of the back. Thus we assume without loss of generality that \u2016xt\u20162 = 1, and define the following loss function:\nft(xt\u2212m\u22121, . . . , xt) =\n( m\u22121 \u2211\ni=0\nxTt\u2212iyt\u2212i\n)2\n\u2212 \u03bb \u00b7 m\u22121 \u2211\ni=0\n( xTt\u2212iyt\u2212i )2\nfor some \u03bb > 0. Notice that minimizing this loss function iteratively yields a process {xTt yt}Tt=1 such that its mean is close to 0, while its variance is maximized. Variance maximization is crucial here, since high variance processes tend to create larger amount of statistical arbitrage opportunities.\nWe use the regret criterion to measure our performance against the best distribution of weights in hindsight, and wish to obtain online algorithm that generates a series {xt}Tt=1 such that\nT \u2211\nt=m\nft(xt\u2212m\u22121, . . . , xt)\u2212min x\nT \u2211\nt=m\nft(x, . . . , x) = o(T ).\nThe previous distributions of our weights affect the mean reversion amount of our portfolio, and hence ft is a loss function with memory. As in Section 2, we define gt(x) = ft(x, . . . , x), and show that by obtaining regret bound for {gt}Tt=1 we also guarantee a regret bound for {ft}Tt=1. Notice that gt is of the form\ngt(x) = x TAtx\u2212 xTBtx (5)\nfor\nAt =\nm\u22121 \u2211\ni=0\nm\u22121 \u2211\nj=0\nyt\u2212iyt\u2212j ,\nand\nBt = \u03bb \u00b7 ( m\u22121 \u2211\ni=0\nyt\u2212iy T t\u2212i\n)\n,\nThe function gt is not convex in general, and hence we cannot apply the technique detailed in Section 2 straightforwardly. Instead, we define\nht(X) = X \u25e6 At \u2212X \u25e6Bt, (6) where\nX \u25e6 A = n \u2211\ni=1\nn \u2211\nj=1\nX(i, j) \u00b7 A(i, j),\nand X is a PSD matrix with Tr(X) = 1.\nNow, the problem of minimizing \u2211T t=m ht(X) is a PSD relaxation to the problem of minimizing \u2211T\nt=m gt(x), and for the optimal solution\nx\u22c6 = argmin x\nT \u2211\nt=m\ngt(x),\nit holds in particular that\nmin X\nT \u2211\nt=m\nht(X) \u2264 T \u2211\nt=m\nht(x \u22c6x\u22c6\u22a4) =\nT \u2211\nt=m\ngt(x \u22c6).\nNotice that ht is linear in X for all t, and hence we can apply regret minimization techniques on the loss functions {ht}Tt=1."}, {"heading": "3.2 Parameter setting", "text": "Throughout this section we use the following parameters and notations:\n1. The decision set K is defined as:\nK = {X|X is PSD and Tr (X) = 1}.\nFrom this definition we can bound the diameter of K by supX,Y \u2208K \u2016X \u2212 Y \u2016F \u2264 D = \u221a 2 , when \u2016 \u00b7 \u2016F refers to the Frobenius norm.\n2. There exists G > 0, such that\nsup (xt\u2212m+1,...,xt),t\n\u2016\u2207ft(xt\u2212m+1, . . . , xt)\u2016 \u2264 G.\nIt follows that ft is Lipshitz continuous for the Lipshitz constant G, and also that\nsup Xt,t\n\u2016\u2207ht(Xt)\u2016F \u2264 G.\nClearly, the value of G depends on the prices of assets we are considering, and its computation is done accordingly."}, {"heading": "3.3 Algorithm and analysis", "text": "We turn now to present our online algorithm.\nAlgorithm 2 Online Statistical Arbitrage (OSA)\n1: Input: Learning rate \u03b7, X0 = 1nIn\u00d7n. 2: Randomize x0 \u223c X0. 3: for t = 1 to (T \u2212 1) do 4: Set Xt \u2190 \u03a0K (Xt\u22121 \u2212 \u03b7\u2207ht(Xt)) 5: Set xt = xt\u22121 w.p. (\n1\u2212 1 m \u221a T\n)\n,\n6: Otherwise, randomize xt \u223c Xt. 7: Play xt and suffer loss ft(xt\u2212m+1, . . . , xt). 8: end for\nHere, \u03a0K refers to the following projection onto K:\n\u03a0K(X) = arg min Y \u2208K\n\u2016X \u2212 Y \u2016F .\nAlso, xt \u223c Xt refers to the eigenvector decomposition of the matrix Xt. I.e, we represent Xt = \u2211n i=1 \u03bbiviv \u22a4 i , where each vi is a unit vector and \u2211n\ni=1 \u03bbi = 1, when \u03bbi \u2265 0. Then, we randomize the eigenvector xt = vi with probability \u03bbi. Technically, this decomposition is possible due to the fact that Xt is positive semidefinite with Tr(Xt) = 1 for all t.\nFor Algorithm 2 we can prove the following bound.\nTheorem 3.1. Set \u03b7 = D\u221a mGT 3/4 . Then, Algorithm 2 achieves the following regret bound for {ft}Tt=1:\nRT = T \u2211\nt=m\nE [ft(xt\u2212m+1, . . . , xt)]\u2212min x\nT \u2211\nt=m\nft(x, . . . , x) \u2264 3 \u00b7 \u221a mGDT 3/4.\nProof. By applying Algorithm 2 for the loss functions {ht}Tt=1 we get a series of matrices {Xt}Tt=1, such that\nT \u2211\nt=m\nht(Xt)\u2212min X\nT \u2211\nt=m\nht(X) \u2264 D2\n2\u03b7 +\nG2\n2\nT \u2211\nt=m\n\u03b7,\nusing the analysis of [Zin03]. From the definitions of gt and ht it exists that\nmin X\nT \u2211\nt=m\nht(X) \u2264 min x\nT \u2211\nt=m\ngt(x),\nand hence T \u2211\nt=m\nht(Xt)\u2212min x\nT \u2211\nt=m\ngt(x) \u2264 D2\n2\u03b7 +\nG2\n2\nT \u2211\nt=m\n\u03b7.\nNow, from Lemma 3.2 we know that \u2223\n\u2223 \u2223 \u2223 \u2223\nT \u2211\nt=m\nht(Xt)\u2212 E [gt(xt)] \u2223 \u2223 \u2223 \u2223\n\u2223\n\u2264 \u221a mGDT 3/4,\nwhich yields T \u2211\nt=m\nE [gt(xt)]\u2212min x\nT \u2211\nt=m\ngt(x) \u2264 D2\n2\u03b7 +\nG2\n2\nT \u2211\nt=m\n\u03b7 + \u221a mGDT 3/4.\nFrom the definition of gt it follows that\nT \u2211\nt=m\nE [ft(xt, . . . , xt)]\u2212min x\nT \u2211\nt=m\nft(x, . . . , x) \u2264 D2\n2\u03b7 +\nG2\n2\nT \u2211\nt=1\n\u03b7 + \u221a mGDT 3/4. (7)\nNext, we bound the distance between xt and xt\u22121 in expectation for all t. Unlike presented in Section 2, we cannot rely on the closeness of xt and xt\u22121 that follows from the step size of the online update. However, we can use the fact that xt 6= xt\u22121 with probability 1m\u221aT , and therefore\nE [ \u2016xt \u2212 xt\u22121\u20162 ] \u2264 0 \u00b7 ( 1\u2212 1 m \u221a T ) +D2 \u00b7 1 m \u221a T = D2 m \u221a T .\nNow, similarly to Section 2 we rely on the fact that ft is Lipchitz continuous with a Lipchitz constant G, and thus\n|E [ft(xt, . . . , xt)]\u2212 E [ft(xt\u2212m+1, . . . , xt)]|2\n\u2264 E [|ft(xt, . . . , xt)\u2212 ft(xt\u2212m+1, . . . , xt)|]2 \u2264 (G \u00b7 E [\u2016(xt, . . . , xt)\u2212 (xt\u2212m+1, . . . , xt)\u2016])2 \u2264 G2 \u00b7 m\u22121 \u2211\nj=1\nE [ \u2016xt \u2212 xt\u2212j\u20162 ] \u2264 G2 \u00b7 m\u22121 \u2211\nj=1\nj \u2211\nl=1\nE [ \u2016xt\u2212l+1 \u2212 xt\u2212l\u20162 ] \u2264 G2 \u00b7 m\u22121 \u2211\nj=1\nj \u2211\nl=1\nD2\nm \u221a T\n\u2264 mG 2D2\u221a T ,\nand it follows that\n|E [ft(xt, . . . , xt)]\u2212 E [ft(xt\u2212m+1, . . . , xt)] | \u2264 \u221a mGD\nT 1/4 .\nSumming the above for all t yields\n\u2223 \u2223 \u2223 \u2223 \u2223 T \u2211\nt=m\nE [ft(xt, . . . , xt)]\u2212 T \u2211\nt=m\nE [ft(xt\u2212m+1, . . . , xt)]\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2264 \u221a mGDT 3/4, (8)\nand by combining (7) and (8) we get that\nT \u2211\nt=m\nE [ft(xt, . . . , xt)]\u2212min x\nT \u2211\nt=m\nft(x, . . . , x) \u2264 D2\n2\u03b7 +\nG2\n2\nT \u2211\nt=1\n\u03b7 + 2 \u00b7 \u221a mGDT 3/4.\nFinally, substituting \u03b7 = D\u221a mGT 3/4 yields\nRT =\nT \u2211\nt=m\nE [ft(xt\u2212m+1, . . . , xt)]\u2212min x\nT \u2211\nt=m\nft(x, . . . , x) \u2264 3 \u00b7 \u221a mGDT 3/4,\nwhich completes the proof.\nWe now turn to prove Lemma 3.2.\nLemma 3.2. Let gt and ht be as denoted in Equations and (5) and (6). Then, Algorithm 2 generates online sequences {Xt}Tt=1 and {xt}Tt=1 such that\n\u2223 \u2223 \u2223 \u2223 \u2223 T \u2211\nt=m\nht(Xt)\u2212 E [gt(xt)] \u2223 \u2223 \u2223 \u2223\n\u2223\n\u2264 \u221a mGDT 3/4.\nProof. Notice that gt(xt) = ht ( xtx \u22a4 t ) from the definitions of gt and ht. We show by induction that\n\u2225 \u2225 \u2225 Xt \u2212 E [ xtx \u22a4 t ]\u2225 \u2225 \u2225\nF \u2264\n\u221a mD\nT 1/4 ,\nand from the Lipchitz property of {ht}Tt=1 this also implies that \u2223\n\u2223 \u2223 ht(Xt)\u2212 E\n[\nht\n(\nxtx \u22a4 t\n)] \u2223\n\u2223 \u2223 \u2264\n\u221a mGD\nT 1/4 .\nThus, for t = 0 we have that \u2225\n\u2225 \u2225 X0 \u2212 E\n[\nx0x \u22a4 0\n]\u2225\n\u2225 \u2225 F = 0 \u2264\n\u221a mD\nT 1/4 ,\nsince x0 \u223c X0. For t = 1 we have that \u2225\n\u2225 \u2225 X1 \u2212 E\n[\nx1x \u22a4 1\n] \u2225\n\u2225 \u2225\nF\n= 0 \u00b7 1 m \u221a T + \u2225 \u2225 \u2225 X1 \u2212 E [ x0x \u22a4 0 ] \u2225 \u2225 \u2225 F \u00b7 ( 1\u2212 1 m \u221a T )\n= \u2225 \u2225 \u2225 X1 \u2212X0 +X0 \u2212 E [ x0x \u22a4 0 ]\u2225 \u2225 \u2225 F \u00b7 ( 1\u2212 1 m \u221a T ) \u2264 \u2016X1 \u2212X0\u2016F \u00b7 (\n1\u2212 1 m \u221a T\n)\n+ \u2225 \u2225 \u2225 X0 \u2212 E [ x0x \u22a4 0 ] \u2225 \u2225 \u2225 F \u00b7 ( 1\u2212 1 m \u221a T )\n\u2264 (\u03b7G) \u00b7 ( 1\u2212 1 m \u221a T ) = D\u221a mT 3/4 \u2212 D m3/2T 5/4 \u2264\n\u221a mD\nT 1/4 .\nNext, we assume that \u2225\n\u2225 \u2225 Xt \u2212 E\n[\nxtx \u22a4 t\n]\u2225\n\u2225 \u2225 F \u2264\n\u221a mD\nT 1/4\nand prove that \u2225\n\u2225 \u2225 Xt+1 \u2212 E\n[\nxt+1x \u22a4 t+1\n] \u2225\n\u2225 \u2225 F \u2264\n\u221a mD\nT 1/4 .\nThus, \u2225\n\u2225 \u2225 Xt+1 \u2212 E\n[\nxt+1x \u22a4 t+1\n]\u2225\n\u2225 \u2225\nF\n= 0 \u00b7 1 m \u221a T + \u2225 \u2225 \u2225 Xt+1 \u2212 E [ xtx \u22a4 t ]\u2225 \u2225 \u2225 F \u00b7 ( 1\u2212 1 m \u221a T )\n= \u2225 \u2225 \u2225 Xt+1 \u2212Xt +Xt \u2212 E [ xtx \u22a4 t ] \u2225 \u2225 \u2225 F \u00b7 ( 1\u2212 1 m \u221a T ) \u2264 \u2016Xt+1 \u2212Xt\u2016F \u00b7 (\n1\u2212 1 m \u221a T\n)\n+ \u2225 \u2225 \u2225 Xt \u2212 E [ xtx \u22a4 t ]\u2225 \u2225 \u2225 F \u00b7 ( 1\u2212 1 m \u221a T )\n\u2264 ( \u03b7G+\n\u221a mD\nT 1/4\n) \u00b7 ( 1\u2212 1 m \u221a T ) = ( D\u221a mT 3/4 +\n\u221a mD\nT 1/4\n) \u00b7 ( 1\u2212 1 m \u221a T )\n=\n\u221a mD\nT 1/4 \u2212 D m3/2T 5/4 \u2264\n\u221a mD\nT 1/4 ,\nwhich completes the induction. Now, from the Lipchitz property of {ht}Tt=1 this implies that \u2223\n\u2223 \u2223 ht(Xt)\u2212 E\n[\nht\n(\nxtx \u22a4 t\n)] \u2223\n\u2223 \u2223 \u2264\n\u221a mGD\nT 1/4 ,\nand summing the above for all t yields\n\u2223 \u2223 \u2223 \u2223 \u2223 T \u2211\nt=m\nht(Xt)\u2212 E [ ht(xtx \u22a4 t ) ]\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2264 \u221a mGDT 3/4."}, {"heading": "4 Experiments", "text": "The following experiments demonstrate the effectiveness of the proposed algorithms, under two different settings. In the first setting, we consider the Dow Jones Index (30 stocks) and apply our criterion to isolate subsets of stocks that have a maximal amount of mean reversion. In the second setting, we consider pairs of sector related stocks, and apply the proposed algorithm to construct mean reverting portfolios (\u201cpairs trading\u201d)."}, {"heading": "4.1 Comparison method", "text": "We compare the amount of mean reversion of the different portfolios using the Portmanteau test from [LB78]. This test is aimed at determining whether a process is close to be pure noise process, and hence can be effectively applied in our case as a measure for mean reversion. More accurately, we define \u2206t = xTt yt \u2212 xTt\u22121yt\u22121 to be the daily change of our portfolio, and consequently\nQm ( {\u2206t}Tt=1 ) = T (T + 2)\nL \u2211\nk=1\n(\n\u03c1 (k)2 T \u2212 k\n)\n,\nto be the Portmanteau statistic, where\n\u03c1 (k) = \u2211T t=k+1\u2206t\u2206t\u2212k \u2211T\nt=1 \u2206 2 t\nis the sample autocorrelation at lag k, and L is the number of autocorrelation lags (chosen to be 20 by default). Under the null hypothesis, the asymptotic distribution of Qm is chi-square with L degrees of freedom, and therefore we can use the p-value as our measure for mean reversion.\nAdditionally, we compare the revenue obtained by applying the following trading strategy to each of the portfolios: buy whenever it reaches a certain lower threshold, and sell whenever it reaches an upper threshold (we assume no transaction cost). We arbitrarily use (\u22121) and (+1) as lower and upper thresholds in our experiments, but similar results can be shown for any other choice. It is highly likely that dynamic trading strategies such as those presented in [GGR99, JY06] would yield higher revenue. However, the design of a trading strategy is completely orthogonal to our work, and our goal here is simply to compare various portfolios with unified trading strategy."}, {"heading": "4.2 Data set", "text": "For the first setting, we consider time series of daily closing rates of all 30 stocks in the Dow Jones. For the second setting, we consider time series of daily closing rates of 8 pairs of stocks. The selection of the pairs relies on their sectoral belonging (Financials, Energy, Telecommunication services, etc.). In both settings, we use data between the dates 01/01/2008 and 01/02/2013, which is taken from Yahoo! Finance."}, {"heading": "4.3 Isolating mean reverting portfolio", "text": "In this setting, we test our criterion on the Dow Jones Index (30 stocks) and isolate subsets of stocks that have large amount of mean reversion. This can be done by setting a certain threshold, and including only those stocks with corresponding weights above this threshold in our portfolio. We compare the performance of our criterion for various values of \u03bb (recall that higher value of \u03bb corresponds to more fluctuating portfolios).\nThis setting is aimed at testing the effect of the \u03bb parameter in the proposed criterion. In Figure 1 one can clearly see that the proposed algorithm generates distributions that create mean reverting portfolios, regardless of the value of \u03bb. The significance of the Portmanteau test can be clearly seen in Table 1 for all three values. The supplementary material contains detailed information regarding the proposed portfolios for each of the values of \u03bb."}, {"heading": "4.4 Pairs trading", "text": "In this setting, we compare the performance of the proposed algorithm (OSA) to the trading strategy of distributing the weight proportionally to the price of the stocks (this strategy is referred to as \u201cBenchmark\u201d). I.e., assume that the average prices (over certain period of time) of stocks A and B are $10 and $20. Then, we would sell two shares of A against each share of B we buy, or vise versa. We also compare the performance to the offline optimal distribution of weights (this strategy is referred to as \u201cOff-opt\u201d), which follows from our criterion:\nx\u22c6 = argmin x\n\n\n\nT \u2211\nt=m\n( m\u22121 \u2211\ni=0\nxT yt\u2212i\n)2\n\u2212 \u03bb \u00b7 m\u22121 \u2211\ni=0\n( xT yt\u2212i )2\n\n\n\n.\nIn all runs, we use the parameters \u03bb = 2 and m = 5, which were chosen arbitrarily.\nIn Tables 2 and 3 one can clearly see the advantage of the proposed algorithm (OSA) over the offline benchmarks, in the compared parameters \u2014 revenue and closeness to pure noise. In Figure 2(b) we demonstrate the performance of the proposed algorithm visually, by applying it on the pair AT&T and Verizon (Telecommunication services)."}, {"heading": "5 Conclusion", "text": "Motivated by financial applications, we have considered the setting of online learning with memory, and gave efficient and asymptotically-optimal regret algorithms for this general setting. Application to constructing mean-reverting instruments is explored theoretically and empirically.\nThe following research directions remain: First, whereas the proposed algorithm for the online learning with memory framework is optimal in the number of iterations T , the optimal dependence on the memory parameter m remains unknown. We conjecture that the regret bound of \u0398( \u221a mT ) is tight. Second, it would be interesting to explore the optimal trading strategy in conjunction to a mean reverting portfolio."}], "references": [{"title": "Statistical arbitrage in the US equities market", "author": ["Marco Avellaneda", "Jeong-Hyun Lee"], "venue": "Quantitative Finance,", "citeRegEx": "Avellaneda and Lee.,? \\Q2010\\E", "shortCiteRegEx": "Avellaneda and Lee.", "year": 2010}, {"title": "Optimal portfolio selection in nonlinear arbitrage spreads", "author": ["Hamad Alsayed", "Frank McGroarty"], "venue": "European Journal of Finance,", "citeRegEx": "Alsayed and McGroarty.,? \\Q2012\\E", "shortCiteRegEx": "Alsayed and McGroarty.", "year": 2012}, {"title": "Prediction, learning, and games", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": null, "citeRegEx": "Cesa.Bianchi and Lugosi.,? \\Q2006\\E", "shortCiteRegEx": "Cesa.Bianchi and Lugosi.", "year": 2006}, {"title": "Identifying small mean-reverting portfolios", "author": ["Alexandre D\u2019Aspremont"], "venue": "Quant. Finance,", "citeRegEx": "D.Aspremont.,? \\Q2011\\E", "shortCiteRegEx": "D.Aspremont.", "year": 2011}, {"title": "Co-Integration and Error Correction: Representation, Estimation, and Testing", "author": ["Robert F. Engle", "C.W.J. Granger"], "venue": null, "citeRegEx": "Engle and Granger.,? \\Q1987\\E", "shortCiteRegEx": "Engle and Granger.", "year": 1987}, {"title": "Pairs trading: performance of a relative-value arbitrage", "author": ["Evan Gatev", "William N. Goetzmann", "K. Geert Rouwenhorst"], "venue": "Review of Financial Studies,", "citeRegEx": "Gatev et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Gatev et al\\.", "year": 1999}, {"title": "Dynamic portfolio selection in arbitrage", "author": ["J. Jurek", "H. Yang"], "venue": "SSRN eLibrary,", "citeRegEx": "Jurek and Yang.,? \\Q2006\\E", "shortCiteRegEx": "Jurek and Yang.", "year": 2006}, {"title": "On a measure of lack of fit in time series models", "author": ["G.M. Ljung", "G.E.P. Box"], "venue": null, "citeRegEx": "Ljung and Box.,? \\Q1978\\E", "shortCiteRegEx": "Ljung and Box.", "year": 1978}, {"title": "On sequential strategies for loss functions with memory", "author": ["N. Merhav", "E. Ordentlich", "G. Seroussi", "M.J. Weinberger"], "venue": "IEEE Trans. Inf. Theor.,", "citeRegEx": "Merhav et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Merhav et al\\.", "year": 2006}, {"title": "Financial Markets and Trading: An Introduction to Market Microstructure and Trading Strategies (Wiley Finance). Wiley, 1 edition", "author": ["Anatoly B. Schmidt"], "venue": null, "citeRegEx": "Schmidt.,? \\Q2011\\E", "shortCiteRegEx": "Schmidt.", "year": 2011}, {"title": "Pairs Trading: Quantitative Methods and Analysis", "author": ["G. Vidyamurthy"], "venue": "Wiley Finance. Wiley,", "citeRegEx": "Vidyamurthy.,? \\Q2011\\E", "shortCiteRegEx": "Vidyamurthy.", "year": 2011}, {"title": "Markov decision processes with arbitrary reward processes", "author": ["Jia Yuan Yu", "Shie Mannor", "Nahum Shimkin"], "venue": "Math. Oper. Res.,", "citeRegEx": "Yu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2009}, {"title": "Online convex programming and generalized infinitesimal gradient ascent", "author": ["M. Zinkevich"], "venue": "In ICML,", "citeRegEx": "Zinkevich.,? \\Q2003\\E", "shortCiteRegEx": "Zinkevich.", "year": 2003}], "referenceMentions": [], "year": 2017, "abstractText": "In many online learning scenarios the loss functions are not memoryless, but rather depend on history. Our first contribution is a complete characterization of sufficient and necessary conditions for learning with memory, accompanied with a novel algorithm for this framework that attains the optimal O( \u221a T )-regret. This improves previous online learning algorithms that guaranteed O(T ) regret and required more stringent conditions. As an application of the new technique, we address the classical problem in finance of constructing mean reverting portfolios. We design an efficient online learning algorithm for this problem, and provide guarantees for its performance. We complement our theoretical findings with an empirical study that verifies our theoretical results on financial data.", "creator": "LaTeX with hyperref package"}}}