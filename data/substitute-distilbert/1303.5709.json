{"id": "1303.5709", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Mar-2013", "title": "Theory Refinement on Bayesian Networks", "abstract": "theory refinement is the art of updating a domain theory in the light of new cases, to be done automatically or with some expert assistance. the problem of theory refinement under uncertainty is reviewed here in broad context of bayesian statistics, a theory of belief revision. the problem is reduced to an incremental learning task which followed : the learning system is initially primed with a partial theory supplied by a lab assistant, and thereafter maintains its linear internal representation of alternative theories which is permitted not be interrogated by the domain expert and able to be entirely refined from nothing. algorithms for refinement of bayesian networks are presented to illustrate. is meant by \" partial theory \", \" alternative finite representation \", etc. the algorithms are an incremental variant of cognitive learning algorithms. the literature so authors work well while batch and incremental mode.", "histories": [["v1", "Wed, 20 Mar 2013 15:29:57 GMT  (476kb)", "http://arxiv.org/abs/1303.5709v1", "Appears in Proceedings of the Seventh Conference on Uncertainty in Artificial Intelligence (UAI1991)"]], "COMMENTS": "Appears in Proceedings of the Seventh Conference on Uncertainty in Artificial Intelligence (UAI1991)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["wray l buntine"], "accepted": false, "id": "1303.5709"}, "pdf": {"name": "1303.5709.pdf", "metadata": {"source": "CRF", "title": "Theory Refinement on Bayesian Networks", "authors": ["Wray Buntine"], "emails": ["wray@ptolemy.arc.nasa.gov"], "sections": [{"heading": null, "text": "1 Introduction\nTheory refinement is the task of updating a domain theory in the light of new cases. The key idea is to usc the expert's prior domain knowledge to prime a learn ing system during the knowledge acquisition process. Subsequent refinement of theory proceeds by having the learning system accept examples or ask key ques tions of the expert. Shapiro (Shapiro, 1983), for in stance, developed a comprehensive theory and suite of algorithms for the task of refining Horn clause theo ries (logic programs). Ginsberg ct al. applied a more heuristic approach to the refinement of a rule base in the context of medical diagnosis (Ginsberg ct at., 1988). Recent research in this area (Ourston and Mooney, 1990; Towell ct at., 1990) grew out the need to make the many iuductive leamiug algorithms avail able more knowledge intensive, so they can mimic some\nof the perceived benefits of analytic learning methods such as explanation based learning. But this research faces the problems of \"imperfect and uncertain domain theories\" and \"noisy training cases\" not well handled by analytic methods.\nA recent example of this hybrid learning approach is as follows (Towell et at., 1990): a rule-base of knowl edge about the domain is transcribed into a neural net work to initialize the network; the new training cases are then run in a back-propagation algorithm to refine the network. This approach addresses the following research question: how can we build a learning algo rithm that covers the full spectrum from theory re finement, to standard batch learning (starting with a non-informative theory, and assuming learning occurs from just one batch of cases), to incremental learning (assuming new cases come in smaller batches and the theory is gradually refined)?\nA second recent example of theory refinement is of Bayesian networks sometimes used in medical expert systems (Lauritzen and Spiegclhalter, 1988). While experts can set up an appropriate graphical structure and estimate the needed probabilities, new examples may arrive on a daily basis so the expert system needs to be refined. Spiegelhalter et al. argue that the ex pert's experience and confidence in setting up the ini tial model needs to be quantified (Spiegelhalter and Lauritzen, 1989) (for instance, how many examples was it based on) in order to do refinement carefully. It could be that the expert's initial model is based on many cases and is very reliable, and the 10 new noisy cases obtained happen to be unusual so they wrongly suggest the expert's initial model requires major re finement. Spiegclhaltcr et a.l.'s approach addresses a second research question: given some new and possi bly anomalous cases, when do we start refining, how drastically do we refine, and when do we disregard the anomalous cases as noise? Spiegelhalter, however, did not address the issue of refining the structure of a Bayesian network, only the continuous parameters of the probability distributions.\nThis paper considers these two broad research ques tions together. The approach to theory refinement suggested is as follows: the learning system is primed with a partial theory supplied by a domain expert, and thereafter maintains its own alternative theory repre sentation which is able to be interrogated by the do main expert and able to be incrementally refined from data. Furthermore, the partial theory is such that it can initially be null, and that it incorporates a quan tification of the expert's experience so that the \"right\" amount of refinement is done given new cases. An other approach to learning networks that incorporates a partial theory is given by by (Srinivas et a!., 1990).\nThe general approach developed here is based on Bayesian principles for belief updating that form the basis of several learning algorithms (Buntine, 1990b; Cooper and Herskovits, 1991). The principles spec ify precisely a \"nonnative\" approach to theory refine ment, and the approach suggested here approximates this. The normative property is a claim that the prin ciples set a standard which other theory refinement or learning algorithms must approximate; if they fail to do so they will return poorer refined/learned the ories on average. Another popular learning frame work in the computing area is uniform convergence, of which the PAC model is an instance (Haussler, 1991). This is an approach that approximates the normative Bayesian approach when sample sizes arc large. Sev eral researchers have reported ( unsurprisingly) that the Bayesian approach is superior with smaller size training samples (Buntine, 1990b; Opper and Haus sler, 1991) in a range of batch learning problems.\nSome previous methods for learning Bayesian networks (Geiger et a!., 1990; Spirtes and Glymom, 1990; Verma and Pearl, 1990; Srinivas et a!., 1990) arc closer to the large sample uniform convergence framework be cause they assume independence information can be unambiguously determined. Some of these algorithms also make the assumption (Geiger et a!., 1990; Spirtes and Glymour, 1990; Verma and Pearl, 1990) that the unknown probability distribution is a DAG-isomorph (Pearl, 1988). This means all independencies in the problem must be perfectly captured by some Bayesian network, which may not be the case in a particular problem (for instance, all non-chordal Markov net works arc not DAG-isomorphic). These algorithms can scc1ningly \"discover causality fron1 data\" 1 but ex istence of son1c \";causality\" is inlnHxliatc fron1 the as sumption of DAG-isomorphism. How restrictive will this asstunption be in practice and how sensitive arc the algorithms to its failmc? The approach here in contrast requires that son1c ordering (possibly causal) of the variables is supplied to the system. This as sumes nothing abont the underlyiug probability dis tribution because a Bayesian network can always be found for some ordering. The algori tlnns presented do, however, assun1c that every cxa1nplc in the traiu iug sample has variahle values fully specified. (While\nTheory Refinement on Bayesian Networks 53\nthis assumption can be relaxed, it can involve consid erable computational cost if done properly.)\nIn the approach presented here, the initial partial the ory obtained from the domain expert is interpreted as a prior information about the space of possible theo ries, and the alternative theory representation is inter preted as a subspace of alternative theories that are rea.sonable a posterior, represented in a compact form. Simple learning approaches approximate this space of alternative theories by taking a single high poste rior structure (Cooper and Herskovits, 1991; Buntine, 1990a) however experiments show that averaging over a larger sized space yields considerable improvement (Buntine, 1990a)1. This improved performance corre sponds to the improved accuracy gained in the TOP N system when the system approximates posteriors using a thousand alternative disease sets instead of a single disease set (Henrion, 1990).\nA space of alternative theories is difficult to present to a domain expert but can be readily summarized in several ways for expert interrogation during theory refinement: two approaches are described here. The theory refinement algorithm of course applies Bayes theorem to this space of alternatives. To generate a space of rea.sonable alternatives, it docs a search of the space of high posteriors in a similar style and with the same motivation as the TOP N system and the Bayesian averaging method for trees (Bun tine, 1990a).\nTlw theory refinement. approach is dcvclopccl here for Bayesian networks. These networks arc first intro duced and then the representation of partial theories and their transformation to a prior is described. Tl1e representation for alternative theories is described, and then the theory refinement and interrogation algo rithms arc presented. These major sections describe the approach but assume that conditional probabil ity distributions for each node in a Bayesian uetwork are represented with a full conditional joint distribu tion, and that all values of variables arc supplied with each training case. Of course, in larger practical sys tems, these two assumptions rarely apply. The final section describes how noisy-or gates and other lower dimensional conditional distributions can have their parameters learnt within the same theory refinement framework.\n2 Bayesian Networks\nBayesian networks specify dependence properties be tween variables by using a directed acyclic graph. They describe probabilistic models useful for non directed classification. That is, oue can predict ( aud cmnpntc likelihoods for) one snhset of variables from any other. In contra,;t, class probability trees (Qnin-\n1Simila.r rcsnlts arc reported ill (Spirtcs ct al., 1990), although tltcir justification i::: different.\n54 Buntine\nJan, 1986; Duntine, 1990a) only allow directed classi fication because they only yield predictions about a special target variable usually referred to as the class.\nof variables that have outgoing arcs to a variable x are called the parents of the variable x. Each vari able also has an associated conditional probability ta ble which gives probabilities for different values of the variable conditioned on values of its parent variables. For instance for the graph in the figure, we need val ues for Pr\u00b7(ela), Pr(Jia, b), Pr\u00b7(gle,d), etc., because a is the only parent of e, etc. Given the parent struc ture specifying the network and the conditional prob ability tables, methods exist for computing arbitrary conditional and marginal likelihoods between variables (Lauritzen and Spiegelhalter, 1988).\nThe following notation is used here. A Bayesian net work consists of a set of discrete variables X where each variable x E X has a set of parent variables IIx. The full parent structure is denoted II. For instance, for the graph in the figure, IIe = {a}, IId = {a, b}, etc. The set of possible values for the variable x is v (x) and for the cartesian product of variables in IIx is v(IIx ). For instance, if a, b and d arc boolean, then v(a) = {t\u00b7rue, false}, and v(II<I) = {(tr\u00b7ue, tnw), (tr\u00b7ue, false), (false, tr1le), (fal se, false)}. Also, mx denotes the cardinality of v(x).\nGiven an assignment I to the variables in X, X = I, denote corresponding assignments to x E X by Ilx, and to IIx C X by I1n,. For instance, if X = {u, v, w} and II, = { v, w} for u, v and w boolean, then if I= (true,false,true), then !1, =true and l1n\" = (.false, true). Also, (I denotes the matrix of condi tional probabilities for x given that the parent vari ables are II.,. and conditioned on their values. So P\u00b7r( x = i I IIx = j, II,, II) = II,.=;IJ. With these, we arc able to determine the probability of the full set of variables X using the standard expansion\nPr(X =I I II, II) = ITIIx=I1,v1n, xE.t'\nThis gives the likelihood for a single example given II and (1, and a product of these forms gives the likeli hood for an independently and identically distributed training san1plc, used in calculating various posteriors.\n3 Partial Bayesian networks\nAn initial partial theory given by the expert is to be transformed to a prior probability over the space of theories. Since a Bayesian network is fully specified by a parent structure II together with conditional proba bilities II, an initial partial theory then somehow spec ifies a prior distribution Pr(II, IJ). This section de scribes the information obtained from the expert and how it is converted into a prior on Bayesian networks.\nExperience shows that experts are often able to sug gest roughly which variables influence which. This is because experts are usually better at expressing quali tative knowledge than quantitative, and because weak domain theories often indicate influence but not its ex act equational form. If variables are ordered accord ing to time of occurrence, for instance family history of heart disease pre-dates heart disease, then many of the potential influences (those following in time) are made impossible. The partial theory obtained from the expert is an ordering of variables and a Bayesian network specified pictorially in shades of grey. Dlack arcs indicate definite parents (with a prior of 1). Miss ing arcs indicate definite non-parents (with a prior of 0). Grey arcs indicate parents whose status we arc uncertain about, with prior belief proportional to the grey level (or to allow greater range, with log prior mapped to the grey level). This tells the theory re finement algorithm how eager it should be to modify a potential parent's status in the light of new evidence.\nWe ask the expert to provide a total ordering, \"--<\", on variables such that a variable's parents must be a subset of those variables less than it (i.e. y E IIx only if y --< x ). We then ask the expert to indicate how strongly s/he believes each potential parent is a par ent, measured in units of subjective probability. De note this information by E. So for variables x, y E X such that y --< x, this is the prior probability that y is a parent of x, denoted PT(y -+ x 1--<, E). Assuming independence, a full prior on any given parent struc ture conditioned on the total ordering of variables is now\nPr(II 1--<, E) = IT Pr(IIr 1--<, E) , .rE.l'\nasstuning II is consistent with -<, where\nPr (II, 1--<, E) = ( IT Pr(y -+ :r 1--<, E)) yE IT\ufffd-\n( IT (1- Pr(y-+ X 1--<, E))) y\ufffdn,\nTo extend this simple model of a partial theory we could also introduce correlations between potential parents.\nSo a partial Bayesian network is specified by a total ordering of variables -< together with a prior proba bility for each potential parent E, which allows us to evaluate Pr(y -> x 1-<, E). To complete the prior, we need to specify Pr(B liT,-<, E).\nWe assume e is independent of -< and E given l1 so develop a prior for Pr(B I IT). We choose a prior that is a conjugate prior (it yields a posterior in the same functional form, so makes the mathematics sim ple (Berger, 1985)) and assumes the least amount of information is known about the conditional probability tables. This is a product of standard non-informative priors on multinomial distributions (each conditional probability distribution is a multinomial), the sym metric Dirichlet prior (Buntine, 1990b; Berger, 1985), and assumes prior independence between cells in the conditional probability table:\nPr(e liT) = I1 IJ\"\u00b7-1\nII II iEv(,) ilj\n, . Detam3;(o:x, ... ,o:x) xE.l JEv(!I,) where Bctam, ts the mx dimensional Beta function given by\nBc tac (n1, . \u2022 . ,nc) = fli-l.C r(n;)\nr(l:i=t...c n;) '\nr is the Gamma function, e.g. r(n+l) = n!, and ax is a parameter to the prior for each variable x. A particular Bayesian network is often equivalent to a set of other Bayesian networks with some arc directions changed (Verma and Pearl, 1990). With\n( 1)\nthis prior gives equivalent networks equivalent priors, and means marginal priors for individual variables are non-informative. (The proof of this is more involved than we have space for.)\n4 Representing alternative Bayesian networks\nGiven a total ordering on variables, the theory re finement algorithm given in the next section consid ers re<esonable altemative parent sets for each variable determined according to some criteria of reasonable ness. For the variable x alternative pareut sets IT,, will be a collection of subsets of { y : y -< x } . Com bin ing these gives a space of alternative parent structures that can then be represented by taking the cartesian product across X of the sets of reasonable parent sets. For each possible parent structure IT, we also have to know its posterior probability and sufficient informa tion to update this given new examples. This space of parent structures and the additional information can be thought of as similar to a version space (Mitchell, 1982). However, because of the inherent uncertainty\nTheory Refinement on Bayesian Networks 55\nof the theories considered here, the \"version space\" cannot be updated by considering consistency with the training sample, most specific generalizations, etc. Instead Bayes theorem indicates the normative way of updating the \"version space\" of alternative parent structures and our posterior belief in them.\nUnfortunately, the full space of parent structures is super exponential, so we cannot store and update de tails about each one. To overcome this we can store those whose posterior is quite high in relative terms since these arc the only structures that are significant. This section outlines how we can calculate the poste rior for a given parent structure, and how a reasonable set of alternative parent structures can be stored. We refer to this representation of the set of reasonable par ent structures, their conditional probability tables and associated statistics as a combined Da.ye sian network. \"Reasonable\" in this context is given a more precise meaning in the next section where it is shown how to maintain and update combined Bayesian networks.\nLet Px denote a set containing sets of reasonable par ent variables for the variable x, so we have fair belief that the \"true\" I1x E Px. Then the space of rea\ufffdonablc parent structures l1 given the total ordering -< is given by the c\ufffdtrtesian product @,,EX Px. Let the number of different reasonable parents l:.rE.l\" IPxl be denoted by P (we note this now because it is useful in dctennining the operation couut for later algorithms).\nEach reasonable parent structure II has an associ ated subjective posterior probability indicating how strongly we currently believe it is the \"true\" struc ture. Having seen the sample Sample, and obtained the information -< and E from the expert, this is Pr(IT I Sample,-<, E). According to standard rules of probability, this can be calculated a.s\nPr(IT I Sample,-<, E)\nex Pr\u00b7(II 1-<, E). fe Pr(e IIT)Pr(Sample liT, e)\nwhere\nII Pr(I1x I Sample,-<, E) (2) -':E.l'\nPr(IT., I Smnplc, -<,E)\nex Pr(IT.r 1-<, E)\nII jEv(!I,.)\nand nx=ilj is the number of examples in the training sample Sample with x = i and IT., = j, assuming every example in Sample has variable values fully specified. The solution to the integral follows by using standard properties of the Dirichlet integral (Buntine, 1990b). The counts nx=ili arc the only parameters in the pos terior affected by the training sample and they are referred to as sufficient statistics (Berger, 1985); these need to be maintained during incremental learning.\n56 Buntine\nFinally, each reasonable parent structure also has esti mates for the parameters e specifying the conditional probability tables. The estimated table for the vari able x is given by EofSample,li (8 x=ifj). According to standard rules of probability, these can be calculated as\nEofSample,li (ex=ifj) JR ex=ifjPr-(Sample I II, 8)Pr-(8 I II)\nJ\ufffd Pr-(Sample I II, 8)Pr(8 I II) nx=ifi +a,.\nnx=.lj + 11txG'x ' (3)\nwhere n,=.fi = i:i=l. . . m, nx=ifj\u00b7 The integrations arc done using standard properties of the Dirichlet integral and simplified using recursive properties of the Gamma function (r(x + 1) = xr(x)). With this basic information, we are now ready to de scribe the representation for a combined Bayesian net work. In order to reconstruct the necessary conditional probability tables, compute the posteriors, etc. for each set of parent variables IIx E Px, it is sufficient that the corresponding counts nx=ifj are kept. To save computation the posterior Pr(IIx I Sample, -<, E) and the totals nx=.fi are also kept. To access all alterna tive parent sets IIx E Px efficiently they are stored in a lattice structure where subset and superset parent sets are linked together in a web, denoted the parent lattice for x. The full set of lattices is of size P which is 2 lXI. Because this is potentially exponential in JXJ, only those parent sets with significant posterior prob abilities are stored and linked. For instance, we might only store those parent sets with posterior within a factor of 1/ 1000 of the maximum posterior parent set found so far to, for instance, restrain P to be O(JXI). The structure updating algorithm does this. By in creasing this factor close to 1, we are always guaran teed to make the full set of lattices manageable in size but at the expense of losing accuracy in theory refine ment. Tint because posterior probabilities usually vary exponentially in learning, the set of reasonable parent sets should be manageable.\nThe root node of the parent lattice for x is the empty set and the lea\u00b7ves are the sets II,. which have no superscts contained in P,. We refer to this entire representation as a combined Dayesian net work. Notice that we can easily fill in a lattice P., == { {a},{a, b}, {a,c},{a,rl} } by adding {a, b,c} awl {a,c,rl} or {a,b,c,rl} to reduce the number of leaves, although some of these new leaves may have insignificant posterior probabilities.\nTo assist in the search and update of the lattice during theory refinement, nodes (i.e. parent sets and associ ated statistics) arc labeled as alive, dead or asleep. Alive uodes represent the set of \"reasonable\" alterna tives having high posteriors, and correspond to those parent sets in P_.,. Dead nodes exist in the lattice as\ndead-end markers in the search space, they have been explored, have been forever determined as \"unreason able\" alternatives and are not to be further expanded. Asleep nodes are similar bnt are only considered unrea sonable for now and may be made alive later on. Fur thermore, nodes can be either open or closed, depend ing on whether they require further expansion during search.\n5 Theory Refinement\nThis section proposes several algorithms for the modi fication and interrogation of a combined Bayesian net work. Most algorithms are linear-time in lv(IIx)l, lXI, P, which itself may be O(IX 1), and other relevant vari ables. The structure update algorithm is an adjustable search algorithm so its time can vary from anything to fast greedy search to a slower beam search.\n5.1 Parameter Updates\nWhen the training sample Sample is extended, and we require a rapid incremental update of the combined Bayesian network, then a simple parameter update can be done without altering the structure of the parent lattices. This means, for each variable x E X and for each reasonable parent set IIx E P,., we have to increment the corresponding cell counts, and update the posteriors. Normally, this process should effect only the alive nodes in the parent h\u2022ttice. For instance, suppose Sample is extended to Sample' with the new example having x = \u00b7i and IIx = j, then we should increment nx=ifj and\nPr(IIx I Sample',-<, E) Pr(IIx I Sample, -<, E)\n(nx=ifj + ax)(n,=.fj- 1 + mxax) (n.,.=.fj + m,et, )(nx=ifj - 1 + Ct.r )\nThis follows from recursive propcttics of the Gamrna function. The full update process will therefore take O(P) operations. If we increase Sample by adding N extra examples in a batch then we can repeat tlris process N times. This process can be further sped llp by initially updating only the leaf nodes in the parent lattices because the change in example counts carr tlH;n be filtered upwards without rcfCrcnce to the examples.\n5.2 Structure Updates\nGiven additional time, an any-time search can be be gun to extend and modify the reasonable parent struc tures Px and the corresponding parent lattices to en sure high posterior parent sets arc represented. This algorithm is first presented here as a one-time batch algorithm (starting from an empty lattice), awl then differentiated to produce the incrernental version. Tl1e algori thn1 presented is a sin1plc hc\ufffdun search algori tln11\nwith three parameters such that 1 > C > D > E. These are used to vary the search, as explained below. Alternatively, a branch and bound algorithm could be developed using upper bounds on posterior probabili ties, or a corresponding decision theoretic search algo rithm.\nThe batch beam search algorithm finds many parent sets with posteriors within a given factor C of the best found. The beams searched are those parents sets within a factor D of the best found. The algorithm is presented in pseudo-code in Figure 2. This search\nis nutde easier by the fact the posterior probabilities on alteruativc structures tend to vary exponentially as structmes change, and high posterior structmes tend to clump together. This makes the beam search more efficient. Also, parent sets are marked dead if at any time they have a posterior less than a factor E of the best and have fairly stable probability estimates. Many parent sets will be marked dead as posteriors for poor parent structmes decrease exponentially with increasing san1plc si:;,c. Since dead nodes cannot be ex panded, this further reduces the search. Finally, notice that if C and D arc set close to 1, then the algorithm becomes a greedy search for a high posterior parent set.\nTheory Refinement on Bayesian Networks 57\nA process reproducing the result of this algorithm can be run incrementally. This would be needed when an additional batch of examples is received. If asleep nodes have not been updated with previous addi tional samples because the parameter update process of the previous section was used, then these asleep nodes should first have their parameters updated and Best-Posterior recalculated. Processing after this is interruptible to achieve the any-time feature of the search. Adjust Alive-list and Open-list to reflect the new Best-Posterior. Finally expand nodes from Open-list and continue with the search. Some nodes may oscillate on and off Alive-list and Open-list be cause the posterior ordering of parent sets will oscillate as the training samples increases and the posteriors are modified. This is the problem of repeated restruc turing reported by Crawford to occur in incremental learning algorithms (Crawford, 1989). This can be pre vented by making a differential on C and D between placing a node on and taking a node off.\n5.3 Structure posteriors\nOne useful form of feedback to the expert is to re turn information in exactly the same format initially obtained from the expert, a partial Bayesian network. This means calculating the posterior probability (con ditioned on the training sample) that variable y will be a parent of x\nP1'(y---+ x I Sample,-<, E) L Pr(Ilx I Sample,-<, E)\nTI\"\"EP.:c A yETI.:c\nThe full calculation for all variables will take O(IXI\u00b7P) operations. This information could be pictorially rep resented as a graph with arcs done in shades of grey to indicate strength of belief. Standard asymptotic prop erties of Bayesian methods assure us that as the sample size gets arbitrarily large, these posterior probabilities will converge to either 0 or 1.\n5.4 Alternative Bayesian networks\nAnother useful form of feedback for the expert is to return some \"good\" Bayesian networks stored in the combined Bayesian network. We can do this by select ing for each x E X, a set of parents Ilx and an asso ciated conditional probability distribution. To ensure these arc truly representative networks, we can return a collection of networks together in a compressed for mat corresponding to a single Bayesian network, de noted a smoothed Bayesian network. A similar op eration has been presented for class probability trees (Buntine, 1990a). For each variable x, we choose a leaf L, E P., from the parent lattice for x using a probabilistic method described later. This provides one potential parent set for x. However, there may be more high posterior\n58 Buntine\nparents sets in Px that are subsets of Lx. We shall average each of their corresponding conditional proba bility tables together to obtain a single representative conditional probability table.\nDenote by Sx the set of parent sets that are subsets of L.--c,\nSx = { II x : Ilx E Px 1\\ II x \ufffd Lx } \ufffd Px \u00b7\nThen we can merge all these parent sets and average their conditional probability tables together to obtain a single representation of them all. This is done with the following formulae: the posterior probability that the \"true\" set of parents for x is in Sx,\nPr(Sx I Sample,-<:, E) = I.: Pr\u00b7(II x I Sample,-<:, E) , n\ufffdes.r\nthe posterior expected conditional probability table for x conditioned on Lx assuming that the \"true\" set of parents for x is in Sx,\nEn.,BIS\"'Sample,-<,E (Pr(x = i I Lx = j, II x, 11))\nI.: P.r(x = i I IIx = iln,,IIx,Sample) TI.rES.r\nPr\u00b7(II x I Sample,-<:, E) PT(Sx I Sample,-<:, E) '\n(note the 1st probability on the right-hand side of the equation is calculated using Equation (3)) and the pos terior expected probability that y is a parent of x as suming that the \"true\" set of parents for x is in Sx,\nPr(y--+ x I Sx, Sample,-<:, E)\nl:n.ES. \" yETI. Pr(IIx I Sample,-<:, E) PT(Sx I Sample,-<:, E)\nW c usc these formulae as follows: for each x we choose a leaf Lx in Px randomly in proportion with Pr(Sx I Sample,-<:, E). For the full set of variables this takes O(P) operations. Because this process relics on selec tion of leaves from the parent lattice, it may be advan tageous to reduce the number of leaves, as discussed with the structure update algorithm. For a variable x, we can display its set of parents pictorially using grey scales as discussed previously, but using Pr\u00b7(y --+ x I S., Sample,-<:, E) as the probability y is a parent of x. For the full set of variables this takes 0( IX I \u00b7 P) operations. Finally, we can generate the conditional probability tables for x given the value of Lx by com puting En.,BIS-.Sample,-<,E (Pr(x = i I Lx = j, II x, 11)). This represents the average of the various conditional probability tables corresponding to parent sets in Sx. Empirically, this has the effect of smoothing the condi tional probability tables for x given Lx computed us ing Equation (3). This takes O(l:xE.t' mx lv( Lx) IISx I) operations.\nGiven only a small training sample, this technique is likely to produce many different smoothed Bayesian\nnetworks corresponding to the many different alive leaves in the parent lattices. Perusal of these will give the expert some idea of the current variability in choice of a \"good\" Bayesian network. As the training sam ple size increases, asymptotic properties of Bayesian methods assure us the sets of high posterior parents and their conditional probability tables will become roughly equivalent so the different smoothed Bayesian networks produced will differ much less and eventually converge.\n6 Extensions\nThis section briefly considers relaxing one of the as sumptions made in the previous section: full condi tional joint distributions exist at each node. Further extensions would be the handling of \"missing values\", where some examples have variable values missing, and the handling of expert designated \"hidden variables\" in the structure. Both problems can be handled the EM algorithm (Dempster et al., 1977).\nWhile full conditional joint distributions are more gen eral than any other model, their specification requires an exponential number of parameters. When estimat ing parameter values from data, this can be a severe problem as it is when trying to elicit the same prob abilities from an expert. One way around this is to introduce approximate distributions of lower dimen sion. We have two issues to consider here: (1) How do you learn parameters for a specific conditional distri bution? (2) How do you then patch the distribution learnt into the broad framework given previously?\nThere are many ways of representing restricted con ditional probability distributions: trees (Buntinc, la90a), logistic regression and other qualitative mod els popular in economic statistics (Amcmiya, 1985), and the noisy-or gate popular in AI (Pearl, 1988).\nThe noisy-or gate is described as follows. Suppose boolean variable x is conditioned on boolean variables x1, . . . , Xn. The noisy-or has para1nctcrs qo, . . . , qn,\nPT(x I x1, ... x,., q)\n'Jo rr when x is false, and i=l, ... n\n1 - fJo rr when x is true, i=l, . . . n\nwhere the indicator function lx, is 1 when x; is true and zero otherwise. A similar conditional probabil ity distribution is the multivariate logistic regression function, which in a slightly modified form applies to boolean variable x conditioned on to boolean variables x1, . . . , Xn and is\nPr(x I x1, . . . x,., r\u00b7)\nIl 1,.\n1'0 i=l, . . . n 1'; l when x is false, and\n1\n1 rr 1 \u2022. + ro i=l, . .. n ri ' when x is true.\n(It is usually given with parameters r; = er:.) The two forms approximate each other when the product is small. More generally, the logistic function is a sym metrized version of the noisy-or. Versions of the func tion exist when the variables are many-valued discrete variables, and to introduce higher-order correlations between variables. The logistic function has the same functional form as a simple (or \"idiot\") Bayes clas sifier, and can be obtained by taking the conditional distribution from a quadratic exponential distribution on discrete variables :z:, :z:1, ... Xn.\nTo incorporate these methods into the framework just given, we need to be able to calculate the posterior ex pected parameter values, and the (relative) posterior probability that the noisy-or function or the logistic regression function is \"true\", independently of the pa rameter values. Since each conditional distribution is associated with a particular set of parent variables, the parameter values and the posterior can then be placed in a parent lattice of the combined Bayesian network. The posterior can be used, for instance, to search the space of logistic regressions over different parent sets using the algorithm of Figure 2, and also used when determining structure posteriors.\nPosterior expected parameter values, and the (rela tive) posterior probability for both noisy-or and logis tic regression models are readily estimated using stan dard maximum likelihood and Bayesian methods. It is simple to show that the sample likelihood functions for both the noisy-or and the logistic regression func tion is convex. So with a dominant likelihood term, the posterior on the parameters is unimodal and the maxinmm posterior parameters can be found using search methods such as scoring, N ewton-Raphson, or conjugate gradient (Amemiya, 1985). A multivariate normal approximation for the posterior at this point (Berger, 1985, p224) can then be used to marginal ize out the parameters and approximate the posterior probability that the noisy-or function of the logistic regression function is \"true\". Notice that because the numeric search algorithms are iterative, they are read ily placed in an incremental framework. Given a few new training cases, start the iterative search at the pre vious maximum posterior point and convergence will be rapid to the new point (because the posterior is uuimo dal, there will be no catastrophic changes of the lll<tXinmm posterior point).\n7 Conclusion\nThis paper has presented a representation and some theory refinement algorithms for learning Bayesian networks. These have the following important prop crtic.s:\nTheory Refinement on Bayesian Networks 59\n\u2022 The representation can be initiated with a par tial Bayesian network that quantifies the expert's experience and confidence. A similar approach was suggested in (Srinivas et a!., 1990). There after the representation maintains several reason able hypotheses in a form of version space.\n\u2022 The algorithm\ufffd approximate the normative Bayesian solution to the corresponding batch learning problem. An analogous approximation for class probability trees significantly outper formed standard statistical and AI methods (Bun tine, 1990a) on a large range of problems. A weaker approximation for batch learning (which finds a single high posterior network) has been re ported to work well empirically (Cooper and Her skovits, 1991), and the parameter updating com ponent of the algorithm corresponds to previous work (Spiegelhalter and Lauritzen, 1989).\n\u2022 There is an incremental algorithm that allows any-time return for varied processing times be tween receipt of new examples. The development of the algorithm illustrates how a batch learn ing algorithm can be converted to an incremental learning algorithm.\n\u2022 There are several algorithms that allow a user to interrogate the current hypotheses about Bayesian networks and to get some idea of their variability.\n\u2022 The algorithms have parameters that allow fuller approximation of the normative solution. These parameters allow one to trade-off space/time com plexity with (average-case) quality of learned the ories (compare with (Buntine, 1990a; Henrion, 1990)).\n\u2022 Extensions have been suggested to show how to handle different conditional probability models such as noisy-or gates and logistic functions.\nExperience with a similar approach for learning trees suggests the algorithms, with some additional hacking, should work well.\nAcknowledgements\nSeveral of these ideas have been suggested indepen dently by Bob Fung, and I have also benefited from discussion with him. The writing of this paper was motivated by some comments made by Pat Langley.\nReferences\nAmemiya, T. (1985). Advanced Econometrics. Har vard University Press, Cambridge, MA.\nBerger, J. 0. (1985). Sta.ti.st-ica.l Decision Theory and Bayes\u00b7ian Analysis. Springer-Verlag, New York.\n60 Buntine\nBuntine, W. ( 1990a). Learning classification trees. Technical Report FIA-90-12-19-01, RIACS and NASA Ames Research Center, Moffett Field, CA. Paper presented at Third International Workshop on Artificial Intelligence and Statistics.\nBuntine, W. ( 1990b). A Theory of Learning Classifi cation Rules. PhD thesis, University of Technology, Sydney. Forthcoming.\nCooper, G. and Herskovits, E. (1991). A Bayesian method for the induction of probabilistic networks from data. Technical Report KSL-91-02, Knowl edge Systems Laboratory, Medical Computer Sci ence, Stanford University.\nCrawford, S. (1989). Extensions to the CART algo rithm. International Journal of Man-Machine Stud ies, 3 1(2):197-217.\nDempster, A., Laird, N., and Rubin, D. (1977). Max imum likelihood from incomplete data via the EM algorithm. J. Roy. Statist. Soc. B, 39: 1-38.\nGeiger, D., Paz, A., and Pearl, J. (1990). Learning causal trees from dependence information. In Eighth Nat-ional Conference on Artificial Intelligence, pages 770-77 1, Boston, Massachusetts.\nGinsberg, A., Weiss, S., and Politakis, P. (1988). Au tomatic knowledge base refinement for classification systems. Artificial Intelligence, 35 (2): 197-226.\nHaussler, D. ( 199 1). A decision theoretic generaliza tion of the PAC learning model and its application to some feed-forward neural networks. Information and Control. To appear.\nHenrion, M. ( 1990). Towards efficient inference in mul tiply connected belief networks. In Oliver, R. and Smith, J ., editors, Infl\u00b7uence Diagrams, Belief Nets and Decision Analysis, pages 385-407. Wiley.\nLauritzen, S. and Spiegelhalter, D. (1988). Local com putations with probabilities on graphical structures and their application to expert systems. J. Roy. Statist. Soc. B, 50(2) :240-265.\nMitchell, T. (1982). Generalization as search. Artificial Intelligence, 18(2):203-226.\nOpper, M. and Haussler, D. ( 1991). Generalised per formance of Bayes optimal classification algorithm for learning a pcrceptron. In COLT'91: 1991 Work shop on Compu.tational Learn\u00b7ing Theory. Morgan Kaufmann. Manuscript.\nOurston, D. and Mooney, R. (1990). Changing the rules: A comprchcusive approach to theory rcfinc mcut. In Eiyhth Na.t\u00b7ional Conference on Ari'ificia.l Intelligence, pages 815-820, Boston, Massachusetts.\nPearl, .J. ( 1988). Probabilistic Reasoning in Intelligent Systems. Morgan and Kauffman.\nQuinlan, .J. ( 1986). Induction of decision trees. Ma chine Learning, 1( 1):81-106.\nShapiro, E. ( 1983). Algorithmic Program Debugging. MIT Press.\nSpiegelhalter, D. and Lauritzen, S. (1989). Sequen tial updating of conditional probabilities on directed graphical structures. Research Report R-89-10, In stitute of Electronic Systems, Aalborg University, Aalborg, Denmark.\nSpirtes, P. and Glymour, C. ( 1990). An algorithm for fast recovery of sparse causal graphs. Report CMU LCL-90-4, Laboratory for Computational Linguis tics, Carnegie Mellon University.\nSpirtes, P., Scheines, R., and Glymour, C. (1990). Sim ulation studies of the reliability of computer-aided model specification using TETRAD II. EQS and LISREL programs. Socialogical Methods and Re search, 19( 1):3-66.\nSrinivas, S., Russell, S., and Agogino, A. (1990). Auto mated construction of sparse Bayesian networks. In Hem\u00b7ion, M., Schachter, R., Kana!, L., and Lemmer, J ., editors, Uncertainty in Artificial Intell-igence 5, pages 295-308. Elsevier Science Publishers, Amster dam.\nTowell, G., Shavlik, J., and Nom\u00b7dewier, M. ( 1990). Refinement of approximate domain theories by knowledge-based neural networks. In E\u00b7ighth Na tional Conference on Artificial Intelligence, pages 86 1-866, Boston, Massachusetts.\nVerma, T. and Pearl, .J. ( 1990). Equivalence and syn thesis of causal modek In Sixth WoTkshop on Un certainty \u00b7in A T'iificial IntcUigcncc, Cambridge, MA."}], "references": [{"title": "Advanced Econometrics. Har\u00ad vard", "author": ["T. Amemiya"], "venue": null, "citeRegEx": "Amemiya,? \\Q1985\\E", "shortCiteRegEx": "Amemiya", "year": 1985}, {"title": "Sta.ti.st-ica.l Decision Theory and Bayes\u00b7ian Analysis", "author": ["J. Berger"], "venue": null, "citeRegEx": "Berger,? \\Q1985\\E", "shortCiteRegEx": "Berger", "year": 1985}, {"title": "Learning classification trees", "author": ["W. Buntine"], "venue": "Technical Report FIA-90-12-19-01, RIACS and NASA Ames Research Center, Moffett Field, CA. Paper presented at Third International Workshop on Artificial Intelligence and Statistics", "citeRegEx": "Buntine,? \\Q1990\\E", "shortCiteRegEx": "Buntine", "year": 1990}, {"title": "A Theory of Learning Classifi\u00ad cation Rules", "author": ["W. Buntine"], "venue": "PhD thesis,", "citeRegEx": "Buntine,? \\Q1990\\E", "shortCiteRegEx": "Buntine", "year": 1990}, {"title": "A Bayesian method for the induction of probabilistic networks from data", "author": ["G. Cooper", "E. Herskovits"], "venue": "Technical Report KSL-91-02,", "citeRegEx": "Cooper and Herskovits,? \\Q1991\\E", "shortCiteRegEx": "Cooper and Herskovits", "year": 1991}, {"title": "Extensions to the CART algo\u00ad rithm", "author": ["S. Crawford"], "venue": "International Journal of Man-Machine Stud\u00ad ies,", "citeRegEx": "Crawford,? \\Q1989\\E", "shortCiteRegEx": "Crawford", "year": 1989}, {"title": "Max\u00ad imum likelihood from incomplete data via the EM algorithm", "author": ["A. Dempster", "N. Laird", "D. Rubin"], "venue": "J. Roy. Statist. Soc. B,", "citeRegEx": "Dempster et al\\.,? \\Q1977\\E", "shortCiteRegEx": "Dempster et al\\.", "year": 1977}, {"title": "Au\u00ad tomatic knowledge base refinement for classification systems", "author": ["A. Ginsberg", "S. Weiss", "P. Politakis"], "venue": "Artificial Intelligence,", "citeRegEx": "Ginsberg et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Ginsberg et al\\.", "year": 1988}, {"title": "Towards efficient inference in mul\u00ad tiply connected belief networks", "author": ["M. Henrion"], "venue": null, "citeRegEx": "Henrion,? \\Q1990\\E", "shortCiteRegEx": "Henrion", "year": 1990}, {"title": "Local com\u00ad putations with probabilities on graphical structures and their application to expert systems", "author": ["S. Lauritzen", "D. Spiegelhalter"], "venue": "J. Roy. Statist. Soc. B,", "citeRegEx": "Lauritzen and Spiegelhalter,? \\Q1988\\E", "shortCiteRegEx": "Lauritzen and Spiegelhalter", "year": 1988}, {"title": "Generalization as search", "author": ["T. Mitchell"], "venue": "Artificial Intelligence,", "citeRegEx": "Mitchell,? \\Q1982\\E", "shortCiteRegEx": "Mitchell", "year": 1982}, {"title": "Generalised per\u00ad formance of Bayes optimal classification algorithm for learning a pcrceptron", "author": ["M. Opper", "D. Haussler"], "venue": "Work\u00ad shop on Compu.tational Learn\u00b7ing Theory. Morgan Kaufmann. Manuscript", "citeRegEx": "Opper and Haussler,? \\Q1991\\E", "shortCiteRegEx": "Opper and Haussler", "year": 1991}, {"title": "Changing the rules: A comprchcusive approach to theory rcfinc\u00ad mcut", "author": ["D. Ourston", "R. Mooney"], "venue": "In Eiyhth Na.t\u00b7ional Conference on Ari'ificia.l Intelligence,", "citeRegEx": "Ourston and Mooney,? \\Q1990\\E", "shortCiteRegEx": "Ourston and Mooney", "year": 1990}, {"title": "Probabilistic Reasoning in Intelligent Systems", "author": ["Pearl", ".J"], "venue": null, "citeRegEx": "Pearl and .J.,? \\Q1988\\E", "shortCiteRegEx": "Pearl and .J.", "year": 1988}, {"title": "Induction of decision trees", "author": ["Quinlan", ".J"], "venue": "Ma\u00ad chine Learning,", "citeRegEx": "Quinlan and .J.,? \\Q1986\\E", "shortCiteRegEx": "Quinlan and .J.", "year": 1986}, {"title": "Algorithmic Program Debugging", "author": ["E. Shapiro"], "venue": null, "citeRegEx": "Shapiro,? \\Q1983\\E", "shortCiteRegEx": "Shapiro", "year": 1983}, {"title": "Sequen\u00ad tial updating of conditional probabilities on directed graphical structures", "author": ["D. Spiegelhalter", "S. Lauritzen"], "venue": "Research Report R-89-10,", "citeRegEx": "Spiegelhalter and Lauritzen,? \\Q1989\\E", "shortCiteRegEx": "Spiegelhalter and Lauritzen", "year": 1989}, {"title": "An algorithm for fast recovery of sparse causal graphs. Report CMU\u00ad LCL-90-4, Laboratory for Computational Linguis\u00ad", "author": ["P. Spirtes", "C. Glymour"], "venue": null, "citeRegEx": "Spirtes and Glymour,? \\Q1990\\E", "shortCiteRegEx": "Spirtes and Glymour", "year": 1990}, {"title": "Sim\u00ad ulation studies of the reliability of computer-aided model specification using TETRAD II. EQS and LISREL programs", "author": ["P. Spirtes", "R. Scheines", "C. Glymour"], "venue": "Socialogical Methods and Re\u00ad search,", "citeRegEx": "Spirtes et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Spirtes et al\\.", "year": 1990}, {"title": "Auto\u00ad mated construction of sparse Bayesian networks", "author": ["S. Srinivas", "S. Russell", "A. Agogino"], "venue": null, "citeRegEx": "Srinivas et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Srinivas et al\\.", "year": 1990}, {"title": "Refinement of approximate domain theories by knowledge-based neural networks", "author": ["G. Towell", "J. Shavlik", "M. Nom\u00b7dewier"], "venue": "In E\u00b7ighth Na\u00ad tional Conference on Artificial Intelligence,", "citeRegEx": "Towell et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Towell et al\\.", "year": 1990}, {"title": "Equivalence and syn\u00ad thesis of causal modek In Sixth WoTkshop on Un\u00ad certainty \u00b7in A", "author": ["T. Verma", "Pearl", ".J"], "venue": null, "citeRegEx": "Verma et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Verma et al\\.", "year": 1990}], "referenceMentions": [{"referenceID": 15, "context": "Shapiro (Shapiro, 1983), for in\u00ad stance, developed a comprehensive theory and suite of algorithms for the task of refining Horn clause theo\u00ad ries (logic programs).", "startOffset": 8, "endOffset": 23}, {"referenceID": 12, "context": "Recent research in this area (Ourston and Mooney, 1990; Towell ct at., 1990) grew out the need to make the many iuductive leamiug algorithms avail\u00ad", "startOffset": 29, "endOffset": 76}, {"referenceID": 16, "context": "tial model needs to be quantified (Spiegelhalter and Lauritzen, 1989) (for instance, how many examples was it based on) in order to do refinement carefully.", "startOffset": 34, "endOffset": 69}, {"referenceID": 4, "context": "The general approach developed here is based on Bayesian principles for belief updating that form the basis of several learning algorithms (Buntine, 1990b; Cooper and Herskovits, 1991).", "startOffset": 139, "endOffset": 184}, {"referenceID": 17, "context": "Some of these algorithms also make the assumption (Geiger et a!., 1990; Spirtes and Glymour, 1990; Verma and Pearl, 1990) that the unknown probability distribution is a DAG-isomorph (Pearl, 1988).", "startOffset": 50, "endOffset": 121}, {"referenceID": 4, "context": "Simple learning approaches approximate this space of alternative theories by taking a single high poste\u00ad rior structure (Cooper and Herskovits, 1991; Buntine, 1990a) however experiments show that averaging over a larger sized space yields considerable improvement (Buntine, 1990a)1.", "startOffset": 120, "endOffset": 165}, {"referenceID": 8, "context": "This improved performance corre\u00ad sponds to the improved accuracy gained in the TOP N system when the system approximates posteriors using a thousand alternative disease sets instead of a single disease set (Henrion, 1990).", "startOffset": 206, "endOffset": 221}, {"referenceID": 9, "context": "conditional and marginal likelihoods between variables (Lauritzen and Spiegelhalter, 1988).", "startOffset": 55, "endOffset": 90}, {"referenceID": 1, "context": "We choose a prior that is a conjugate prior (it yields a posterior in the same functional form, so makes the mathematics sim\u00ad ple (Berger, 1985)) and assumes the least amount of information is known about the conditional probability tables.", "startOffset": 130, "endOffset": 144}, {"referenceID": 1, "context": "This is a product of standard non-informative priors on multinomial distributions (each conditional probability distribution is a multinomial), the sym\u00ad metric Dirichlet prior (Buntine, 1990b; Berger, 1985), and assumes prior independence between cells in the conditional probability table:", "startOffset": 176, "endOffset": 206}, {"referenceID": 10, "context": "This space of parent structures and the additional information can be thought of as similar to a version space (Mitchell, 1982).", "startOffset": 111, "endOffset": 127}, {"referenceID": 1, "context": "The counts nx=ili arc the only parameters in the pos\u00ad terior affected by the training sample and they are referred to as sufficient statistics (Berger, 1985); these need to be maintained during incremental learning.", "startOffset": 143, "endOffset": 157}, {"referenceID": 5, "context": "This is the problem of repeated restruc\u00ad turing reported by Crawford to occur in incremental learning algorithms (Crawford, 1989).", "startOffset": 113, "endOffset": 129}, {"referenceID": 6, "context": "Both problems can be handled the EM algorithm (Dempster et al., 1977).", "startOffset": 46, "endOffset": 69}, {"referenceID": 0, "context": "So with a dominant likelihood term, the posterior on the parameters is unimodal and the maxinmm posterior parameters can be found using search methods such as scoring, N ewton-Raphson, or conjugate gradient (Amemiya, 1985).", "startOffset": 207, "endOffset": 222}, {"referenceID": 16, "context": "A weaker approximation for batch learning (which finds a single high posterior network) has been re\u00ad ported to work well empirically (Cooper and Her\u00ad skovits, 1991), and the parameter updating com\u00ad ponent of the algorithm corresponds to previous work (Spiegelhalter and Lauritzen, 1989).", "startOffset": 251, "endOffset": 286}, {"referenceID": 8, "context": "These parameters allow one to trade-off space/time com\u00ad plexity with (average-case) quality of learned the\u00ad ories (compare with (Buntine, 1990a; Henrion, 1990)).", "startOffset": 128, "endOffset": 159}], "year": 2011, "abstractText": "Theory refinement is the task of updating a domain theory in the light of new cases, to be done automatically or with some expert as\u00ad sistance. The problem of theory refinement under uncertainty is reviewed here in the con\u00ad text of Bayesian statistics, a theory of belief revision. The problem is reduced to an incre\u00ad mental learning task as follows: the learning system is initially primed with a partial the\u00ad ory supplied by a domain expert, and there\u00ad after maintains its own internal representa\u00ad tion of alternative theories which is able to be interrogated by the domain expert and able to be incrementally refined from data. Algo\u00ad rithms for refinement of Bayesian networks are presented to illustrate what is meant by \"partial theory\", \"alternative theory repre\u00ad sentation\", etc. The algorithms are an incre\u00ad mental variant of batch learning algorithms from the literature so can work well in batch and incremental mode.", "creator": "pdftk 1.41 - www.pdftk.com"}}}