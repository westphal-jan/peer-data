{"id": "1306.1083", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Jun-2013", "title": "Discriminative Parameter Estimation for Random Walks Segmentation: Technical Report", "abstract": "the random walks ( rw ) algorithm concerns one of the most e - cient and easy - fair - use probabilistic segmentation methods. by comparing contrast terms with prior methods, it avoids minimal segmentations of medical images in a weakly correlated manner. however, one of the main drawbacks of using the rw algorithm is that its parameters have to re hand - tuned. we propose a novel discriminative learning framework that estimates the parameters utilizing a training dataset. the main complaint we face is realizing the individual samples are not software supervised. speci cally, they provide a hard segmentation of the images, instead of a proba - bilistic segmentation. we overcome this concerns by treating the optimal probabilistic segmentation that is compatible than some given sensory segmentation as a latent variable. this lead us to employ the latent support vector machine formulation for parameter estimation. we show that our approach signi cantly outperforms the baseline methods on a challenging test consisting of real clinical reference mri volumes of skeletal muscles.", "histories": [["v1", "Wed, 5 Jun 2013 12:48:02 GMT  (57kb)", "http://arxiv.org/abs/1306.1083v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["pierre-yves baudin", "danny goodman", "puneet kumar", "noura azzabou", "pierre g carlier", "nikos paragios", "m pawan kumar"], "accepted": false, "id": "1306.1083"}, "pdf": {"name": "1306.1083.pdf", "metadata": {"source": "CRF", "title": "Discriminative Parameter Estimation for Random Walks Segmentation: Technical Report", "authors": ["Pierre-Yves Baudin", "Danny Goodman", "Puneet Kumar", "Noura Azzabou", "Pierre G. Carlier", "Nikos Paragios", "Pawan Kumar"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n30 6.\n10 83\nv1 [\ncs .C\nV ]\n5 J\nun 2\n01 3\nDiscriminative Parameter Estimation\nfor Random Walks Segmentation:\nTechnical Report\nPierre-Yves Baudin1\u22126, Danny Goodman1\u22123, Puneet Kumar1\u22123, Noura Azzabou4\u22126, Pierre G. Carlier4\u22126, Nikos Paragios1\u22123, and\nM. Pawan Kumar1\u22123\n1 Center for Visual Computing, E\u0301cole Centrale Paris, FR 2 Universite\u0301 Paris-Est, LIGM (UMR CNRS), E\u0301cole des Ponts ParisTech, FR\n3 E\u0301quipe Galen, INRIA Saclay, FR 4 Institute of Myology, Paris, FR\n5 CEA, I2 BM, MIRCen, IdM NMR Laboratory, Paris, FR 6 UPMC University Paris 06, Paris, FR"}, {"heading": "1 Literature Survey on the State of the Art Algorithms in Muscle Segmentation", "text": "In the following, we present the principal methods addressing the segmentation of skeletal muscles.\nMuscle Segmentation using Simplex meshes with medial representations A skeletal muscle segmentation method was presented in [8] based on simplex meshes [6]. Considering a 3D surface model, simplex meshes are discrete meshes where each vertex has exactly 3 neighbors. Having a constant connectivity allows to simply parametrize the location of one vertex with respect to its neighbors, and thus parametrize deformation of the shape \u2013 translation, rotation, scaling \u2013 in a local manner. Indeed, the location of a pixel, denoted as x can be expressed as a linear combination of the locations of the three neighbors plus a local elevation term parallel to the local normal: x = \u03b51x1 + \u03b52x2 + (1\u2212 \u03b51 \u2212 \u03b52)x3 + hn. As a result, many local measurements \u2013 including curvature and cell surface \u2013 can be computed efficiently and global energy terms enforcing local constraints come up naturally.\nHere, the authors impose local smoothing via curvature averaging, which does not tend to reduce the surface like 1-order operators typically do. Prior knowledge is imposed by constraining the local scale changes on the elevation parameter with respect to a reference shape. Denoting the surface of the triangle formed by the three neighbors of a pixel as S, given the reference shape parameters ( \u03b5\u03031, \u03b5\u03032, h\u0303, S\u0303 )\n, the new location of the considered pixel is expressed as:\nx = \u03b5\u03031x1 + \u03b5\u03032x2 + (1\u2212 \u03b5\u03031 \u2212 \u03b5\u03032)x3 + h\u0303 ( S/S\u0303 )1/\u03b2 n, (1)\nwhere \u03b2 \u2208 [2,+\u221e[ is a parameter which sets the amount of allowed local deformation: with \u03b2 = 2 this definition is similitude invariant; with \u03b2 = +\u221e this"}, {"heading": "2 Pierre-Yves Baudin et al.", "text": "definition is invariant through rigid transformations only. The model is attached to the target image through either gradient norm maximization in the direction of the gradient at the location of the vertices, or maximization of similarities between the reference and the target images at the vertices location.\nA medial representation \u2013 similar to the M-reps [13] \u2013 is combined with the simplex parametrization to exploit the specific tubular shapes of the skeletal muscles. Medial vertices are added to the model, constrained to remain on the medial axis of the tubular objects. This is achieved by connecting the new vertices to the surface vertices through spring-like forces. This constrains the global structure to resemble its initial reference shape, thus acting as a global shape prior. This medial axis representation also allows efficient collision handling. The model is fit to the image through an iterative process of successive local evolutions. Such model appear to always yield a valid solution, sometimes at the price of an excessive regularization or lack of adaptability to the specifics of the target image. paragraphMuscle Segmentation using Deformable Models and Shape Matching\nMuscle Segmentation using Deformable Models and Shape Matching A shape prior for muscle segmentation in 3D images was presented in [9], deriving from a computer animation technique, called shape matching, used to efficiently approximate large soft-tissue elastic deformations. This method was applied to muscle segmentation with some success. In this approach, discrete meshes are used to parametrize the moving surface. Let x0 be the vector containing the initial position of the control points of the parametric surface. Clustering is performed on x0 such that each cluster \u03b6i contains at least a certain number of vertices (set by the user). During segmentation, the evolution of the active surface is performed according to the following iterative procedure:\n1. Shift vertices according to the external force: x\u0303t = fext + x t. The external\n\u201cforce\u201d fext is computed as the maximal gradient search in the gradient direction.\n2. Regularize vertex positions:\n(a) Compute rigid registration for each clusters:\nTi = argmin \u2211\nj\u2208\u03b6i\n\u2225 \u2225Tix 0 j \u2212 x\u0303 t j \u2225 \u2225 2 , (2)\n(b) Average target position for each vertex:\nxt+1i = 1\n|\u03b6i|\n\u2211\nj\u2208\u03b6i\nTjx 0 j . (3)\nSingle reference prior models are convenient in that they require only one annotated example of the objects of interest. However, when segmenting a class of objects whose shape varies a lot, such approach becomes too constraining and does not allow the model to adopt valid shapes which are too different from the single reference.\nParameter Estimation for RW Segmentation: Technical Report 3\nMuscle segmentation using a hierarchical statistical shape model A hierarchical prior model using Diffusion Wavelets was proposed to segment organs in [7] \u2013 including one calf muscle \u2013 in MRI. This model builds on the formulation of the ASM [4], using a different basis for the subspace of valid solutions. One of the main drawbacks of ASMs, is that they often require a large number of training data in order to obtain relevant decomposition modes. Indeed, some non-correlated shape features \u2013 such as global and local shape configurations \u2013 are often modeled by the same deformation modes. Thus, desired shape behaviors are often mixed with unwanted shape behaviors when optimizing the shape parameters for segmenting a new image. The hierarchical approach allows to uncorrelate small and large scale shape behaviors. Moreover, the presented method also uncorrelates long-range shape behaviors, thus ensuring that deformation mode are spatially localized.\nWe give a brief summary of this method. First, a graph G (V , E) is built on the set of landmarks: V is the set of nodes and each landmark corresponds to a node in V ; E is the set of edges, whose weights are determined through a statistical analysis of the mutual relations between the landmarks in the training set {xk}k=1...K (cf. Shape Maps [12]). As a result, landmarks with independent behaviors will be connected by edges with a small weight, whereas nodes with strongly related behaviors \u2013 such as neighboring points \u2013 will be connected by large weight edges.\nSecond, a Diffusion Wavelet decomposition of G is performed. This process involves computing the diffusion operator T of graph G, which is the symmetric normalized Laplace-Beltrami operator, and computing and compressing the dyadic powers of T. The output of this decomposition is a hierarchical orthogonal basis {\u0393i} for the graph, whose vectors correspond to different graph scales; considering the vector of landmark positions when decomposed on the new basis:\nx = x\u0304+ \u0393p, (4)\nglobal deformations \u2013 i.e. global relations between all the nodes \u2013 are controlled by some of the coefficients in p, while local interactions \u2013 i.e. local interactions between close-by nodes \u2013 are controlled by some other coefficients in p. Projecting all the training examples onto this new basis, a PCA is performed at each scale of the decomposition. Finally, during the segmentation process, the landmarks are positioned on the target image in an iterative manner: 1) the position of the landmarks is updated according to a local appearance model; 2) they are projected into the hierarchical subspace defined previously.\nMuscle segmentation using a continuous region model A region-based segmentation method, proposed in [5], was extended to multi-label segmentation in [2], and applied to skeletal muscle segmentation [1]. Before performing the PCA on the training samples, an Isometric Log-Ratio (ILR) transform is applied to the assignment vectors. The reason for using this transform is that multi-label segmentation requires to have probabilities at all times, which the previous method does not achieve. Here, the PCA is performed in the ILR space and its output"}, {"heading": "4 Pierre-Yves Baudin et al.", "text": "is projected back into the initial probability space. Denoting \u03b7\u03b3 = \u00b5 + \u0393\u03b3 a segmentation in the subspace of valid solution spanned by the PCA in the ILR space, the following functional is proposed:\nE (\u03b7\u03b3) = d (\u03b7BG,\u03b7\u03b3) 2 +\n\u222b\n(1\u2212 h (x)) |\u2207\u03b7\u03b3 | 2 + \u03b3T\u03a3\u22121\u03b3, (5)\nwhere d (\u03b7BG, \u00b7) is an intensity prior functional for separating muscle voxels from background voxels, and h (x) is and edge-map of the target image such that the energy is minimal when the boundaries of the model match the edges in the image."}, {"heading": "2 The Random Walks Algorithm", "text": "The Random Walks algorithm is graph-based: consider a graph G = (V , E), where V is a set of nodes \u2013 corresponding to each voxel in the 3d image \u2013 and E is a set of edges \u2013 one per pair of adjacent voxels. Let us also denote a set of labels \u2013 one per object to segment \u2013 as S.\nThe aim of the Random Walks Algorithm [10] is to compute an assignment probability of all voxels to all labels. These probabilities depend on: i) contrast between adjacent voxels, ii) manual \u2013 thus deterministic \u2013 assignments of some voxels, called seeds, and iii) prior assignment probabilities.\nThe probabilities, contained in vector y, can be obtained by minimizing the following functional:\nERWprior(x,y) = y \u22a4Ly + w\u2016y \u2212 y0\u2016 2 \u2126(x)\n= y\u22a4\n[\n\u2211\n\u03b1\nw\u03b1L\u03b1\n]\ny + \u2211\n\u03b2\nw\u03b2\u2016y \u2212 y\u03b2\u2016 2 \u2126\u03b2 ,\nwhich is a linear combination of Laplacians and prior terms. The Laplacian matrices L\u03b1 contain the contrast terms. Its entries are of the form:\nLi,j =\n\n \n \n\u2211\nk \u03c9kj if i = j,\n\u2212\u03c9ij if (i, j) \u2208 E ,\n0 otherwise.\n(6)\nHere, \u03c9ij designates the weight of edge (i, j). It is usually computed as follows:\n\u03c9ij = exp ( \u2212\u03b2 (Ii \u2212 Ij) 2 ) , (7)\nwhere Ii is the intensity of voxel i. In our experiments, we used three different Laplacians using this formnulation, with three values of \u03b2: 50, 100 and 150 (with the image voxel values normalized with their empirical standard deviation).\nParameter Estimation for RW Segmentation: Technical Report 5\nWe also implemented the lesser used alternate formulation:\nwij = 1\n\u03b2 |Ii \u2212 Ij |+ \u03b5 , (8)\nwhich we employed in one additional Laplacian term with \u03b2 = 100 and \u03b5 = 1 for comparison purposes, since the selected values do give good results on their own.\nSince the objective function is quadratic in y, its minimum can be computed by minimizing a linear system. The quadratic term, composed of a sum of Laplacians and diagonal matrices due to the prior term, is very sparse and has a specific structure due to the fact that only adjacent voxels are connected with an edge.\nGiven the size of the problem (several millions of variables), this system has to be solved with iterative methods, such as Conjugate Gradient. The specific structure of the problem and the existence of parallelized algorithms (such as multigrid Conjugate Gradient) allow for an efficient optimization. For instance, our own implementation takes less than 20s for volumes of size 200\u00d7 200\u00d7 100 on a regular desktop machine."}, {"heading": "3 Derivation of the Latent SVM Upper Bound", "text": "Given a dataset D = {(xk, zk) , k = 1, . . . , N}, which consists of inputs xk and their hard segmentation zk, we would like to estimate parameters w such that the resulting inferred segmentations are accurate. Here, the accuracy is measured using the loss function \u2206 (\u00b7, \u00b7). Formally, let y\u0303k (w) denote the soft segmentation obtained by minimizing the energy functional E (\u00b7,xk; w) for the k-th training sample, that is,\ny\u0303k (w) = argmin y\nw\u22a4\u03c8 (xk,y) . (9)\nWe would like to learn the parameters w such that the empirical risk is minimized over all samples in the dataset. In other words, we would like to estimate the parameters w\u22c6 such that\nw\u22c6 = argmin w\n1\nN\n\u2211\nk\n\u2206 (zk, y\u0303k (w)) . (10)\nThe above objective function is highly non-convex in w, which makes it prone to bad local minimum solutions. To alleviate this deficiency, the latent SVM"}, {"heading": "6 Pierre-Yves Baudin et al.", "text": "formulation upper bounds the risk for a sample (x, z) as follows:\n\u2206 (zk, y\u0303k (w)) = \u2206 (zk, y\u0303k (w)) +w \u22a4 [\u03c8 (xk, y\u0303k (w))\u2212 \u03c8 (xk, y\u0303k (w))] , (11)\n\u2264 min \u2206(zk,y\u0302)=0\nw\u22a4\u03c8 (xk, y\u0302) (12)\n\u2212 [ w\u22a4\u03c8 (xk, y\u0303k (w))\u2212\u2206 (zk, y\u0303k (w)) ] ,\n\u2264 min \u2206(zk,y\u0302)=0\nw\u22a4\u03c8 (xk, y\u0302) (13)\n\u2212min y\n[ w\u22a4\u03c8 (xk,y)\u2212\u2206 (zk,y) ] .\nThe first inequality follows from the fact that the prediction y\u0303k (w) has the minimum possible energy (see equation 9). Thus, its energy has to be less than or equal to the energy of any compatible segmentation y\u0302 with \u2206 (zk, y\u0302) = 0. The second inequality is true since it replaces the loss augmented energy of the prediction y\u0303k (w) with the minimum loss augmented energy.\nThis inequality leads to the following minimization problem:\nmin w, \u03bek\u22650\n\u03bb \u2016w\u20162 + 1\nN\n\u2211\nk\n\u03bek, (14)\ns.t. min \u2206(xk,y\u0302)=0\nw\u22a4\u03c8 (xk, y\u0302) \u2264 w \u22a4\u03c8 (xk, y\u0304)\u2212\u2206 (zk, y\u0304) + \u03bek, \u2200y\u0304, \u2200k,\nwhere \u03bb \u2016w\u20162 is a regularization term, preventing overfitting the parameters to the training data."}, {"heading": "4 Dual-Decomposition Algorithm for the ACI", "text": "Briefly, dual decomposition allows us to iteratively solve a convex optimization problem of the form\ny\u2217 = argmin y\u2208F\nM \u2211\nm=1\ngm(y). (15)\nAt each iteration t it solves a set of slaves problems\ny\u2217m = argmin ym\u2208F\n(\ngm(ym) + \u03c1 t mym\n)\n, (16)\nwhere \u03c1tm are the dual variables satisfying \u2211 m \u03c1 t m = 0. The dual variables are initialized as \u03c10m = 0, \u2200m, and updated at iteration t as follows:\n\u03c1t+1m \u2190 \u03c1 t m + \u03b7 t(y\u2217m \u2212 \u2211\nn\ny\u2217n/M), (17)\nwhere \u03b7t is the learning rate at iteration t. Under fairly general conditions, this iterative strategy converges to the globally optimal solution of the original problem, that is, y\u2217 = y\u2217m, \u2200m. We refer the reader to [3,11] for details.\nIn order to specify our slave problems, we divide the set of voxels V into subsets Vm,m = 1, \u00b7 \u00b7 \u00b7 ,M , such that each pair of neighboring voxels (i, j) \u2208 N\nParameter Estimation for RW Segmentation: Technical Report 7\nappear together in exactly one subset Vm. Given such a division of voxels, our slave problems correspond to the following:\nmin ym\u2208C(Vm)\ny\u22a4mLm(x;w)ym + E prior m (ym,x;w) + \u03c1 t mym, (18)\nwhere Lm(x;w) is the Laplacian corresponding to the voxels Vm. The prior energy functions Epriorm modify the original prior E\nprior by weighing each voxel i \u2208 Vm by the reciprocal of the number of subsets Vn that contain i. In other words, the prior term for each voxel i \u2208 Vm is multiplied by 1/|{Vn, i \u2208 Vn}|.\nThe slave problems defined above can be shown to provide a valid reparameterization of the original problem:\nmin y\u2208C(V)\ny\u22a4L(x;w)y + Eprior(y,x;w). (19)\nBy using small subsets Vm we can optimize each slave problem in every iteration using a standard quadratic programming solver. In our experiments, we used the Mosek solver. To the best of our knowledge, this is the first application of dual decomposition to solve a probabilistic segmentation problem under linear constraints."}, {"heading": "8 Pierre-Yves Baudin et al.", "text": "9. Gilles, B., Pai, D.K.: Fast musculoskeletal registration based on shape matching. In: MICCAI, Lecture Notes in Computer Science, vol. 5242, pp. 822\u2013829 (Jan 2008), http://www.ncbi.nlm.nih.gov/pubmed/18982681 10. Grady, L.: Random walks for image segmentation. PAMI (2006) 11. Komodakis, N., Paragios, N., Tziritas, G.: MRF optimization via dual decompo-\nsition: Message-passing revisited. In: ICCV (2007) 12. Langs, G., Paragios, N., Mas, L., Paris, E.C.D., Galen, E., Saclay, I.: Modeling the\nstructure of multivariate manifolds: Shape Maps (2008) 13. Pizer, S.M., Fletcher, P.T., Joshi, S., Thall, A., Chen, J.Z., Fridman, Y., Fritsch,\nD.S., Gash, A.G., Glotzer, J.M., Jiroutek, M.R., et al.: Deformable m-reps for 3d medical image segmentation. International Journal of Computer Vision 55(2-3), 85\u2013106 (2003)\nar X\niv :1\n30 6.\n10 83\nv1 [\ncs .C\nV ]\n5 J\nun 2\n01 3\nPreface\nThis textbook is intended for use by students of physics, physical chemistry, and theoretical chemistry. The reader is presumed to have a basic knowledge of atomic and quantum physics at the level provided, for example, by the first few chapters in our book The Physics of Atoms and Quanta. The student of physics will find here material which should be included in the basic education of every physicist. This book should furthermore allow students to acquire an appreciation of the breadth and variety within the field of molecular physics and its future as a fascinating area of research.\nFor the student of chemistry, the concepts introduced in this book will provide a theoretical framework for that entire field of study. With the help of these concepts, it is at least in principle possible to reduce the enormous body of empirical chemical knowledge to a few basic principles: those of quantum mechanics. In addition, modern physical methods whose fundamentals are introduced here are becoming increasingly important in chemistry and now represent indispensable tools for the chemist. As examples, we might mention the structural analysis of complex organic compounds, spectroscopic investigation of very rapid reaction processes or, as a practical application, the remote detection of pollutants in the air.\nApril 1995 Walter Olthoff Program Chair\nECOOP\u201995\nOrganization\nECOOP\u201995 is organized by the department of Computer Science, Univeristy of A\u030arhus and AITO (association Internationa pour les Technologie Object) in cooperation with ACM/SIGPLAN.\nExecutive Commitee\nConference Chair: Ole Lehrmann Madsen (A\u030arhus University, DK) Program Chair: Walter Olthoff (DFKI GmbH, Germany) Organizing Chair: J\u00f8rgen Lindskov Knudsen (A\u030arhus University, DK) Tutorials: Birger M\u00f8ller-Pedersen (Norwegian Computing Center, Norway) Workshops: Eric Jul (University of Kopenhagen, Denmark) Panels: Boris Magnusson (Lund University, Sweden) Exhibition: Elmer Sandvad (A\u030arhus University, DK) Demonstrations: Kurt N\u00f8rdmark (A\u030arhus University, DK)\nProgram Commitee\nConference Chair: Ole Lehrmann Madsen (A\u030arhus University, DK) Program Chair: Walter Olthoff (DFKI GmbH, Germany) Organizing Chair: J\u00f8rgen Lindskov Knudsen (A\u030arhus University, DK) Tutorials: Birger M\u00f8ller-Pedersen (Norwegian Computing Center, Norway) Workshops: Eric Jul (University of Kopenhagen, Denmark) Panels: Boris Magnusson (Lund University, Sweden) Exhibition: Elmer Sandvad (A\u030arhus University, DK) Demonstrations: Kurt N\u00f8rdmark (A\u030arhus University, DK)\nReferees\nV. Andreev Ba\u0308rwolff E. Barrelet H.P. Beck G. Bernardi E. Binder P.C. Bosetti\nBraunschweig F.W. Bu\u0308sser T. Carli A.B. Clegg G. Cozzika S. Dagoret Del Buono\nP. Dingus H. Duhm J. Ebert S. Eichenberger R.J. Ellison Feltesse W. Flauger\nIII\nA. Fomenko G. Franke J. Garvey M. Gennis L. Goerlich P. Goritchev H. Greif E.M. Hanlon R. Haydar R.C.W. Henderso P. Hill H. Hufnagel A. Jacholkowska Johannsen S. Kasarian I.R. Kenyon C. Kleinwort T. Ko\u0308hler S.D. Kolya P. Kostka\nU. Kru\u0308ger J. Kurzho\u0308fer M.P.J. Landon A. Lebedev Ch. Ley F. Linsel H. Lohmand Martin S. Masson K. Meier C.A. Meyer S. Mikocki J.V. Morris B. Naroska Nguyen U. Obrock G.D. Patel Ch. Pichler S. Prell F. Raupach\nV. Riech P. Robmann N. Sahlmann P. Schleper Scho\u0308ning B. Schwab A. Semenov G. Siegmon J.R. Smith M. Steenbock U. Straumann C. Thiebaux P. Van Esch from Yerevan Ph L.R. West G.-G. Winter T.P. Yiou M. Zimmer\nSponsoring Institutions\nBernauer-Budiman Inc., Reading, Mass. The Hofmann-International Company, San Louis Obispo, Cal. Kramer Industries, Heidelberg, Germany\nTable of Contents\nHamiltonian Mechanics\nHamiltonian Mechanics unter besonderer Beru\u0308cksichtigung der ho\u0308hreren Lehranstalten . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\nIvar Ekeland, Roger Temam, Jeffrey Dean, David Grove, Craig Chambers, Kim B. Bruce, and Elisa Bertino\nHamiltonian Mechanics2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 Ivar Ekeland and Roger Temam\nAuthor Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\nSubject Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\nHamiltonian Mechanics unter besonderer\nBeru\u0308cksichtigung der ho\u0308hreren Lehranstalten\nIvar Ekeland1, Roger Temam2 Jeffrey Dean, David Grove, Craig Chambers, Kim B. Bruce, and Elsa Bertino\n1 Princeton University, Princeton NJ 08544, USA, I.Ekeland@princeton.edu,\nWWW home page: http://users/~iekeland/web/welcome.html 2 Universite\u0301 de Paris-Sud, Laboratoire d\u2019Analyse Nume\u0301rique, Ba\u0302timent 425,\nF-91405 Orsay Cedex, France\nAbstract. The abstract should summarize the contents of the paper using at least 70 and at most 150 words. It will be set in 9-point font size and be inset 1.0 cm from the right and left margins. There will be two blank lines before and after the Abstract. . . .\nKeywords: computational geometry, graph theory, Hamilton cycles"}, {"heading": "1 Fixed-Period Problems: The Sublinear Case", "text": "With this chapter, the preliminaries are over, and we begin the search for periodic solutions to Hamiltonian systems. All this will be done in the convex case; that is, we shall study the boundary-value problem\nx\u0307 = JH \u2032(t, x)\nx(0) = x(T )\nwith H(t, \u00b7) a convex function of x, going to +\u221e when \u2016x\u2016 \u2192 \u221e."}, {"heading": "1.1 Autonomous Systems", "text": "In this section, we will consider the case when the Hamiltonian H(x) is autonomous. For the sake of simplicity, we shall also assume that it is C1.\nWe shall first consider the question of nontriviality, within the general framework of (A\u221e, B\u221e)-subquadratic Hamiltonians. In the second subsection, we shall look into the special case when H is (0, b\u221e)-subquadratic, and we shall try to derive additional information.\nThe General Case: Nontriviality. We assume that H is (A\u221e, B\u221e)-subquadratic at infinity, for some constant symmetric matrices A\u221e and B\u221e, with B\u221e \u2212A\u221e positive definite. Set:\n\u03b3 : = smallest eigenvalue of B\u221e \u2212A\u221e (1) \u03bb : = largest negative eigenvalue of J d\ndt +A\u221e . (2)\n2 Theorem 1 tells us that if \u03bb+ \u03b3 < 0, the boundary-value problem:\nx\u0307 = JH \u2032(x) x(0) = x(T )\n(3)\nhas at least one solution x, which is found by minimizing the dual action functional:\n\u03c8(u) =\n\u222b T\no\n[ 1\n2\n( \u039b\u22121o u, u ) +N\u2217(\u2212u) ] dt (4)\non the range of \u039b, which is a subspace R(\u039b)2L with finite codimension. Here\nN(x) := H(x)\u2212 1\n2 (A\u221ex, x) (5)\nis a convex function, and\nN(x) \u2264 1\n2 ((B\u221e \u2212A\u221e)x, x) + c \u2200x . (6)\nProposition 1. Assume H \u2032(0) = 0 and H(0) = 0. Set:\n\u03b4 := lim inf x\u21920\n2N(x) \u2016x\u2016\u22122 . (7)\nIf \u03b3 < \u2212\u03bb < \u03b4, the solution u is non-zero:\nx(t) 6= 0 \u2200t . (8)\nProof. Condition (7) means that, for every \u03b4\u2032 > \u03b4, there is some \u03b5 > 0 such that\n\u2016x\u2016 \u2264 \u03b5\u21d2 N(x) \u2264 \u03b4\u2032\n2 \u2016x\u20162 . (9)\nIt is an exercise in convex analysis, into which we shall not go, to show that this implies that there is an \u03b7 > 0 such that\n3 Since u1 is a smooth function, we will have \u2016hu1\u2016\u221e \u2264 \u03b7 for h small enough, and inequality (10) will hold, yielding thereby:\n\u03c8(hu1) \u2264 h2\n2\n1 \u03bb \u2016u1\u2016 2 2 + h2 2 1 \u03b4\u2032 \u2016u1\u2016 2 . (11)\nIf we choose \u03b4\u2032 close enough to \u03b4, the quantity ( 1\n\u03bb + 1 \u03b4\u2032\n) will be negative, and\nwe end up with \u03c8(hu1) < 0 for h 6= 0 small . (12)\nOn the other hand, we check directly that \u03c8(0) = 0. This shows that 0 cannot be a minimizer of \u03c8, not even a local one. So u 6= 0 and u 6= \u039b\u22121o (0) = 0. \u2293\u2294\nCorollary 1. Assume H is C2 and (a\u221e, b\u221e)-subquadratic at infinity. Let \u03be1, . . . , \u03beN be the equilibria, that is, the solutions of H\n\u2032(\u03be) = 0. Denote by \u03c9k the smallest eigenvalue of H \u2032\u2032 (\u03bek), and set:\n\u03c9 := Min {\u03c91, . . . , \u03c9k} . (13)\nIf: T\n2\u03c0 b\u221e < \u2212E\n[ \u2212 T\n2\u03c0 a\u221e\n] < T\n2\u03c0 \u03c9 (14)\nthen minimization of \u03c8 yields a non-constant T -periodic solution x.\nWe recall once more that by the integer part E[\u03b1] of \u03b1 \u2208 IR, we mean the a \u2208 ZZ such that a < \u03b1 \u2264 a + 1. For instance, if we take a\u221e = 0, Corollary 2 tells us that x exists and is non-constant provided that:\nT 2\u03c0 b\u221e < 1 < T 2\u03c0 (15)\nor\nT \u2208\n( 2\u03c0\n\u03c9 , 2\u03c0\nb\u221e\n) . (16)\nProof. The spectrum of \u039b is 2\u03c0T ZZ + a\u221e. The largest negative eigenvalue \u03bb is given by 2\u03c0T ko + a\u221e, where\n2\u03c0 T ko + a\u221e < 0 \u2264 2\u03c0 T (ko + 1) + a\u221e . (17)\nHence:\nko = E\n[ \u2212 T\n2\u03c0 a\u221e\n] . (18)\nThe condition \u03b3 < \u2212\u03bb < \u03b4 now becomes:\nb\u221e \u2212 a\u221e < \u2212 2\u03c0\nT ko \u2212 a\u221e < \u03c9 \u2212 a\u221e (19)\nwhich is precisely condition (14). \u2293\u2294\n4 Lemma 1. Assume that H is C2 on IR2n\\{0} and that H \u2032\u2032(x) is non-degenerate for any x 6= 0. Then any local minimizer x\u0303 of \u03c8 has minimal period T .\nProof. We know that x\u0303, or x\u0303 + \u03be for some constant \u03be \u2208 IR2n, is a T -periodic solution of the Hamiltonian system:\nx\u0307 = JH \u2032(x) . (20)\nThere is no loss of generality in taking \u03be = 0. So \u03c8(x) \u2265 \u03c8(x\u0303) for all x\u0303 in some neighbourhood of x in W 1,2 ( IR/TZZ; IR2n ) .\nBut this index is precisely the index iT (x\u0303) of the T -periodic solution x\u0303 over the interval (0, T ), as defined in Sect. 2.6. So\niT (x\u0303) = 0 . (21)\nNow if x\u0303 has a lower period, T/k say, we would have, by Corollary 31:\niT (x\u0303) = ikT/k(x\u0303) \u2265 kiT/k(x\u0303) + k \u2212 1 \u2265 k \u2212 1 \u2265 1 . (22)\nThis would contradict (21), and thus cannot happen. \u2293\u2294\nNotes and Comments. The results in this section are a refined version of [1]; the minimality result of Proposition 14 was the first of its kind.\nTo understand the nontriviality conditions, such as the one in formula (16), one may think of a one-parameter family xT , T \u2208 ( 2\u03c0\u03c9\u22121, 2\u03c0b\u22121\n\u221e\n) of periodic\nsolutions, xT (0) = xT (T ), with xT going away to infinity when T \u2192 2\u03c0\u03c9\u22121, which is the period of the linearized system at 0.\nTheorem 1 (Ghoussoub-Preiss). Assume H(t, x) is (0, \u03b5)-subquadratic at infinity for all \u03b5 > 0, and T -periodic in t\nH(t, \u00b7) is convex \u2200t (23)\nH(\u00b7, x) is T\u2212periodic \u2200x (24)\nH(t, x) \u2265 n (\u2016x\u2016) with n(s)s\u22121 \u2192 \u221e as s\u2192 \u221e (25)\n5 \u2200\u03b5 > 0 , \u2203c : H(t, x) \u2264 \u03b5\n2 \u2016x\u20162 + c . (26)\nAssume also that H is C2, and H \u2032\u2032(t, x) is positive definite everywhere. Then there is a sequence xk, k \u2208 IN, of kT -periodic solutions of the system\nx\u0307 = JH \u2032(t, x) (27)\nsuch that, for every k \u2208 IN, there is some po \u2208 IN with:\np \u2265 po \u21d2 xpk 6= xk . (28)\n\u2293\u2294\nExample 1 (External forcing). Consider the system:\nx\u0307 = JH \u2032(x) + f(t) (29)\nwhere the Hamiltonian H is (0, b\u221e)-subquadratic, and the forcing term is a distribution on the circle:\nf = d\ndt F + fo with F \u2208 L\n2 ( IR/TZZ; IR2n ) , (30)\nwhere fo := T \u22121 \u222b T o f(t)dt. For instance,\nf(t) = \u2211\nk\u2208IN\n\u03b4k\u03be , (31)\nwhere \u03b4k is the Dirac mass at t = k and \u03be \u2208 IR 2n is a constant, fits the prescription. This means that the system x\u0307 = JH \u2032(x) is being excited by a series of identical shocks at interval T .\nDefinition 1. Let A\u221e(t) and B\u221e(t) be symmetric operators in IR 2n, depending continuously on t \u2208 [0, T ], such that A\u221e(t) \u2264 B\u221e(t) for all t. A Borelian function H : [0, T ]\u00d7 IR2n \u2192 IR is called (A\u221e, B\u221e)-subquadratic at infinity if there exists a function N(t, x) such that:\nH(t, x) = 1\n2 (A\u221e(t)x, x) +N(t, x) (32)\n\u2200t , N(t, x) is convex with respect to x (33)\nN(t, x) \u2265 n (\u2016x\u2016) with n(s)s\u22121 \u2192 +\u221e as s\u2192 +\u221e (34)\n\u2203c \u2208 IR : H(t, x) \u2264 1\n2 (B\u221e(t)x, x) + c \u2200x . (35)\nIf A\u221e(t) = a\u221eI and B\u221e(t) = b\u221eI, with a\u221e \u2264 b\u221e \u2208 IR, we shall say that H is (a\u221e, b\u221e)-subquadratic at infinity. As an example, the function \u2016x\u2016 \u03b1 , with 1 \u2264 \u03b1 < 2, is (0, \u03b5)-subquadratic at infinity for every \u03b5 > 0. Similarly, the Hamiltonian\nH(t, x) = 1\n2 k \u2016k\u20162 + \u2016x\u2016\u03b1 (36)\nis (k, k + \u03b5)-subquadratic for every \u03b5 > 0. Note that, if k < 0, it is not convex.\n6 Notes and Comments. The first results on subharmonics were obtained by Rabinowitz in [5], who showed the existence of infinitely many subharmonics both in the subquadratic and superquadratic case, with suitable growth conditions on H \u2032. Again the duality approach enabled Clarke and Ekeland in [2] to treat the same problem in the convex-subquadratic case, with growth conditions on H only.\nRecently, Michalek and Tarantello (see [3] and [4]) have obtained lower bound on the number of subharmonics of period kT , based on symmetry considerations and on pinching estimates, as in Sect. 5.2 of this article."}, {"heading": "1 Fixed-Period Problems: The Sublinear Case", "text": "With this chapter, the preliminaries are over, and we begin the search for periodic solutions to Hamiltonian systems. All this will be done in the convex case; that is, we shall study the boundary-value problem\nx\u0307 = JH \u2032(t, x)\nx(0) = x(T )\nwith H(t, \u00b7) a convex function of x, going to +\u221e when \u2016x\u2016 \u2192 \u221e."}, {"heading": "1.1 Autonomous Systems", "text": "In this section, we will consider the case when the Hamiltonian H(x) is autonomous. For the sake of simplicity, we shall also assume that it is C1.\nWe shall first consider the question of nontriviality, within the general framework of (A\u221e, B\u221e)-subquadratic Hamiltonians. In the second subsection, we shall look into the special case when H is (0, b\u221e)-subquadratic, and we shall try to derive additional information.\nThe General Case: Nontriviality. We assume that H is (A\u221e, B\u221e)-subquadratic at infinity, for some constant symmetric matrices A\u221e and B\u221e, with B\u221e \u2212A\u221e positive definite. Set:\n\u03b3 : = smallest eigenvalue of B\u221e \u2212A\u221e (1) \u03bb : = largest negative eigenvalue of J d\ndt +A\u221e . (2)\n8 Theorem 21 tells us that if \u03bb+ \u03b3 < 0, the boundary-value problem:\nx\u0307 = JH \u2032(x) x(0) = x(T )\n(3)\nhas at least one solution x, which is found by minimizing the dual action functional:\n\u03c8(u) =\n\u222b T\no\n[ 1\n2\n( \u039b\u22121o u, u ) +N\u2217(\u2212u) ] dt (4)\non the range of \u039b, which is a subspace R(\u039b)2L with finite codimension. Here\nN(x) := H(x)\u2212 1\n2 (A\u221ex, x) (5)\nis a convex function, and\nN(x) \u2264 1\n2 ((B\u221e \u2212A\u221e)x, x) + c \u2200x . (6)\nProposition 1. Assume H \u2032(0) = 0 and H(0) = 0. Set:\n\u03b4 := lim inf x\u21920\n2N(x) \u2016x\u2016\u22122 . (7)\nIf \u03b3 < \u2212\u03bb < \u03b4, the solution u is non-zero:\nx(t) 6= 0 \u2200t . (8)\nProof. Condition (7) means that, for every \u03b4\u2032 > \u03b4, there is some \u03b5 > 0 such that\n\u2016x\u2016 \u2264 \u03b5\u21d2 N(x) \u2264 \u03b4\u2032\n2 \u2016x\u20162 . (9)\nIt is an exercise in convex analysis, into which we shall not go, to show that this implies that there is an \u03b7 > 0 such that\n9 Since u1 is a smooth function, we will have \u2016hu1\u2016\u221e \u2264 \u03b7 for h small enough, and inequality (10) will hold, yielding thereby:\n\u03c8(hu1) \u2264 h2\n2\n1 \u03bb \u2016u1\u2016 2 2 + h2 2 1 \u03b4\u2032 \u2016u1\u2016 2 . (11)\nIf we choose \u03b4\u2032 close enough to \u03b4, the quantity ( 1\n\u03bb + 1 \u03b4\u2032\n) will be negative, and\nwe end up with \u03c8(hu1) < 0 for h 6= 0 small . (12)\nOn the other hand, we check directly that \u03c8(0) = 0. This shows that 0 cannot be a minimizer of \u03c8, not even a local one. So u 6= 0 and u 6= \u039b\u22121o (0) = 0. \u2293\u2294\nCorollary 1. Assume H is C2 and (a\u221e, b\u221e)-subquadratic at infinity. Let \u03be1, . . . , \u03beN be the equilibria, that is, the solutions of H\n\u2032(\u03be) = 0. Denote by \u03c9k the smallest eigenvalue of H \u2032\u2032 (\u03bek), and set:\n\u03c9 := Min {\u03c91, . . . , \u03c9k} . (13)\nIf: T\n2\u03c0 b\u221e < \u2212E\n[ \u2212 T\n2\u03c0 a\u221e\n] < T\n2\u03c0 \u03c9 (14)\nthen minimization of \u03c8 yields a non-constant T -periodic solution x.\nWe recall once more that by the integer part E[\u03b1] of \u03b1 \u2208 IR, we mean the a \u2208 ZZ such that a < \u03b1 \u2264 a + 1. For instance, if we take a\u221e = 0, Corollary 2 tells us that x exists and is non-constant provided that:\nT 2\u03c0 b\u221e < 1 < T 2\u03c0 (15)\nor\nT \u2208\n( 2\u03c0\n\u03c9 , 2\u03c0\nb\u221e\n) . (16)\nProof. The spectrum of \u039b is 2\u03c0T ZZ + a\u221e. The largest negative eigenvalue \u03bb is given by 2\u03c0T ko + a\u221e, where\n2\u03c0 T ko + a\u221e < 0 \u2264 2\u03c0 T (ko + 1) + a\u221e . (17)\nHence:\nko = E\n[ \u2212 T\n2\u03c0 a\u221e\n] . (18)\nThe condition \u03b3 < \u2212\u03bb < \u03b4 now becomes:\nb\u221e \u2212 a\u221e < \u2212 2\u03c0\nT ko \u2212 a\u221e < \u03c9 \u2212 a\u221e (19)\nwhich is precisely condition (14). \u2293\u2294\n10\nLemma 1. Assume that H is C2 on IR2n\\{0} and that H \u2032\u2032(x) is non-degenerate for any x 6= 0. Then any local minimizer x\u0303 of \u03c8 has minimal period T .\nProof. We know that x\u0303, or x\u0303 + \u03be for some constant \u03be \u2208 IR2n, is a T -periodic solution of the Hamiltonian system:\nx\u0307 = JH \u2032(x) . (20)\nThere is no loss of generality in taking \u03be = 0. So \u03c8(x) \u2265 \u03c8(x\u0303) for all x\u0303 in some neighbourhood of x in W 1,2 ( IR/TZZ; IR2n ) .\nBut this index is precisely the index iT (x\u0303) of the T -periodic solution x\u0303 over the interval (0, T ), as defined in Sect. 2.6. So\niT (x\u0303) = 0 . (21)\nNow if x\u0303 has a lower period, T/k say, we would have, by Corollary 31:\niT (x\u0303) = ikT/k(x\u0303) \u2265 kiT/k(x\u0303) + k \u2212 1 \u2265 k \u2212 1 \u2265 1 . (22)\nThis would contradict (21), and thus cannot happen. \u2293\u2294\nNotes and Comments. The results in this section are a refined version of 1980; the minimality result of Proposition 14 was the first of its kind.\nTo understand the nontriviality conditions, such as the one in formula (16), one may think of a one-parameter family xT , T \u2208 ( 2\u03c0\u03c9\u22121, 2\u03c0b\u22121\n\u221e\n) of periodic\nsolutions, xT (0) = xT (T ), with xT going away to infinity when T \u2192 2\u03c0\u03c9\u22121, which is the period of the linearized system at 0.\nTheorem 1 (Ghoussoub-Preiss). Assume H(t, x) is (0, \u03b5)-subquadratic at infinity for all \u03b5 > 0, and T -periodic in t\nH(t, \u00b7) is convex \u2200t (23)\nH(\u00b7, x) is T\u2212periodic \u2200x (24)\nH(t, x) \u2265 n (\u2016x\u2016) with n(s)s\u22121 \u2192 \u221e as s\u2192 \u221e (25)\n11\n\u2200\u03b5 > 0 , \u2203c : H(t, x) \u2264 \u03b5\n2 \u2016x\u20162 + c . (26)\nAssume also that H is C2, and H \u2032\u2032(t, x) is positive definite everywhere. Then there is a sequence xk, k \u2208 IN, of kT -periodic solutions of the system\nx\u0307 = JH \u2032(t, x) (27)\nsuch that, for every k \u2208 IN, there is some po \u2208 IN with:\np \u2265 po \u21d2 xpk 6= xk . (28)\n\u2293\u2294\nExample 1 (External forcing). Consider the system:\nx\u0307 = JH \u2032(x) + f(t) (29)\nwhere the Hamiltonian H is (0, b\u221e)-subquadratic, and the forcing term is a distribution on the circle:\nf = d\ndt F + fo with F \u2208 L\n2 ( IR/TZZ; IR2n ) , (30)\nwhere fo := T \u22121 \u222b T o f(t)dt. For instance,\nf(t) = \u2211\nk\u2208IN\n\u03b4k\u03be , (31)\nwhere \u03b4k is the Dirac mass at t = k and \u03be \u2208 IR 2n is a constant, fits the prescription. This means that the system x\u0307 = JH \u2032(x) is being excited by a series of identical shocks at interval T .\nDefinition 1. Let A\u221e(t) and B\u221e(t) be symmetric operators in IR 2n, depending continuously on t \u2208 [0, T ], such that A\u221e(t) \u2264 B\u221e(t) for all t. A Borelian function H : [0, T ]\u00d7 IR2n \u2192 IR is called (A\u221e, B\u221e)-subquadratic at infinity if there exists a function N(t, x) such that:\nH(t, x) = 1\n2 (A\u221e(t)x, x) +N(t, x) (32)\n\u2200t , N(t, x) is convex with respect to x (33)\nN(t, x) \u2265 n (\u2016x\u2016) with n(s)s\u22121 \u2192 +\u221e as s\u2192 +\u221e (34)\n\u2203c \u2208 IR : H(t, x) \u2264 1\n2 (B\u221e(t)x, x) + c \u2200x . (35)\nIf A\u221e(t) = a\u221eI and B\u221e(t) = b\u221eI, with a\u221e \u2264 b\u221e \u2208 IR, we shall say that H is (a\u221e, b\u221e)-subquadratic at infinity. As an example, the function \u2016x\u2016 \u03b1 , with 1 \u2264 \u03b1 < 2, is (0, \u03b5)-subquadratic at infinity for every \u03b5 > 0. Similarly, the Hamiltonian\nH(t, x) = 1\n2 k \u2016k\u20162 + \u2016x\u2016\u03b1 (36)\nis (k, k + \u03b5)-subquadratic for every \u03b5 > 0. Note that, if k < 0, it is not convex.\n12\nNotes and Comments. The first results on subharmonics were obtained by Rabinowitz in 1985, who showed the existence of infinitely many subharmonics both in the subquadratic and superquadratic case, with suitable growth conditions on H \u2032. Again the duality approach enabled Clarke and Ekeland in 1981 to treat the same problem in the convex-subquadratic case, with growth conditions on H only.\nRecently, Michalek and Tarantello (see Michalek, R., Tarantello, G. 1982 and Tarantello, G. 1983) have obtained lower bound on the number of subharmonics of period kT , based on symmetry considerations and on pinching estimates, as in Sect. 5.2 of this article."}], "references": [{"title": "Nonlinear oscillations and boundary-value problems for Hamiltonian systems", "author": ["F. Clarke", "I. Ekeland"], "venue": "Arch. Rat. Mech. Anal. 78, 315\u2013333", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1982}, {"title": "Solutions p\u00e9riodiques, du p\u00e9riode donn\u00e9e, des \u00e9quations hamiltoniennes", "author": ["F. Clarke", "I. Ekeland"], "venue": "Note CRAS Paris 287, 1013\u20131015", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1978}, {"title": "Subharmonic solutions with prescribed minimal period for nonautonomous Hamiltonian systems", "author": ["R. Michalek", "G. Tarantello"], "venue": "J. Diff. Eq. 72, 28\u201355", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1988}], "referenceMentions": [{"referenceID": 1, "context": "Muscle segmentation using a continuous region model A region-based segmentation method, proposed in [5], was extended to multi-label segmentation in [2], and applied to skeletal muscle segmentation [1].", "startOffset": 149, "endOffset": 152}, {"referenceID": 0, "context": "Muscle segmentation using a continuous region model A region-based segmentation method, proposed in [5], was extended to multi-label segmentation in [2], and applied to skeletal muscle segmentation [1].", "startOffset": 198, "endOffset": 201}, {"referenceID": 2, "context": "We refer the reader to [3,11] for details.", "startOffset": 23, "endOffset": 29}, {"referenceID": 0, "context": "The results in this section are a refined version of [1]; the minimality result of Proposition 14 was the first of its kind.", "startOffset": 53, "endOffset": 56}, {"referenceID": 1, "context": "Again the duality approach enabled Clarke and Ekeland in [2] to treat the same problem in the convex-subquadratic case, with growth conditions on H only.", "startOffset": 57, "endOffset": 60}, {"referenceID": 2, "context": "Recently, Michalek and Tarantello (see [3] and [4]) have obtained lower bound on the number of subharmonics of period kT , based on symmetry considerations and on pinching estimates, as in Sect.", "startOffset": 39, "endOffset": 42}], "year": 2013, "abstractText": "The abstract should summarize the contents of the paper using at least 70 and at most 150 words. It will be set in 9-point font size and be inset 1.0 cm from the right and left margins. There will be two blank lines before and after the Abstract. . . .", "creator": "LaTeX with hyperref package"}}}