{"id": "1306.1343", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Jun-2013", "title": "The User Feedback on SentiWordNet", "abstract": "with the release product sentiwordnet 3. 0 the related web interface has been restyled and improved in order to allow users to submit feedback on the sentiwordnet entries, in their form of the descriptions accompanying alternative triplets of values for an xml. this feeds reports describing the release of the user feedback collected so far and on the plans for the future.", "histories": [["v1", "Thu, 6 Jun 2013 08:56:32 GMT  (529kb,D)", "http://arxiv.org/abs/1306.1343v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["andrea esuli"], "accepted": false, "id": "1306.1343"}, "pdf": {"name": "1306.1343.pdf", "metadata": {"source": "CRF", "title": "The User Feedback on SentiWordNet", "authors": ["Andrea Esuli"], "emails": ["andrea.esuli@isti.cnr.it"], "sections": [{"heading": "1 Introduction", "text": "SentiWordNet [1] is an automatically generated lexical resource that assigns to each sysnset of WordNet [2] a triplet of positivity, negativity and objectivity scores.\nSentiWordNet is a general (or global) lexicon, i.e., its scores are deemed to be of general application regardless of the specific domain of the text which contains the terms to which the scores are associated. The hypothesis on global applicability of scores to terms may not hold on all the possible uses of terms in any domain but, from a practical perspective, it should hold for a large part of the cases. In SentiWordNet this hypothesis holds stronger because the application of scores to each distinct sense of a term allows to discriminate a good number of otherwise sentiment-ambiguous cases, e.g., blue in the sense of the color or in the sense of the mood1.\nIn its practical use SentiWordNet can be considered a resource that provides a basic, wide-coverage, sentiment knowledge into the application in which it is used. Domain-specific applications will then likely pair it with a domainspecific resource in order to improve the precision on domain-specific terms.\nSentiWordNet is an automatically generated resource and, as for any other automatic labeling process based on machine learning, it contains errors, i.e., incorrect triplets of values associated to some synsets. With the release of SentiWordNet 3.0 the related Web interface2 has been restyled and improved in order to allow users to submit feedback on the SentiWordNet entries, in the form of the suggestion of alternative triplets of values for an entry, as shown in Figures 1 and 2.\n1This also requires sense level disambiguation of text. 2http://swn.isti.cnr.it/\nar X\niv :1\n30 6.\n13 43\nv1 [\ncs .C\nL ]\n6 J\nun 2\n01 3\nIn the following we report on the collected feedback information and also on the future evolution of the feedback collection process."}, {"heading": "2 Collecting the feedback", "text": "Feedback from users has been collected in two ways: (i) from the Web interface, and (ii) from the download interface.\nThe Web interface allows the user to search for any term in WordNet and shows all the synsets to which the term belong with the relative SentiWordNet values. Each synsets has a \u201cFeedback!\u201d link that opens a feedback dialog\n(see Figure 2) that allows the user to submit its suggested triplet of values (which can differ or be the same of the SentiWordNet triplet).\nWhen a user clicks on the link to the download page of SentiWordNet the actual download link is presented along with a feedback dialog (see Figure 3) that presents the triplet for a synset and asks to the user to check them, confirm it or submit a triplet of corrected values. After the submission of the feedback the interface loads automatically the values for another synset, so that the user can submit feedback on other SentiWordNet triplets. Synsets are selected in random order among the set of synsets with the minimum number of feedbacks. This means, for example, that whenever a synset gets its first feedback, independently of the feedback source (web search, or download link), it will be never presented for feedback from the download link until all synsets will have at least one feedback too.\nWhen users submit their feedback the information that is stored is:\n\u2022 Original SentiWordNet values (positivity and negativity, the objectivity value can be determined as 1 \u2212 (posivitity + negativity)).\n\u2022 The values submitted by the user (positivity and negativity).\n\u2022 IP of the browser submitting the data.\n\u2022 Time and date."}, {"heading": "3 Releasing the feedback", "text": "Before releasing the feedback we faced with the requirement of preserving the privacy of the users that have contributed their feedback. At the same time we liked to save some information about the event that generated the feedback, which could be useful for the analysis of data.\nWe thus converted each IP to a unique identifier, so that it is still possible to group feedbacks generated by the same IP but not to determine its exact\nsource. We also added the country in which the IP is located, by using the WHOIS protocol. Though the information obtained in this way is only a rough approximation of the location of the feedback source, and it does not provide any information about the fluency in English of the submitter, it can be useful for future analyses involving grouping or filtering based on geographic areas.\nThe exact time information has been removed, leaving only the date of submission.\nThe feedback entries are released in a text file, with a feedback entry per line, and each line composed of the following tab-separated field:\n\u2022 Incremental counter: can be used as unique identifier of feedback entries.\n\u2022 SynsetId: the offset in the WordNet data file. Along with the part of speech it uniquely identifies the synset.\n\u2022 Part of speech of the synset.\n\u2022 SentiWordNet-positivity: the positivity value assigned to the synset in SentiWordNet at the time of feedback submission.\n\u2022 SentiWordNet-negativity: same as above, for negativity.\n\u2022 Feedback-positivity: the positivity value submitted by the user.\n\u2022 Feedback-negativity: same as above, for negativity.\n\u2022 Date of submission.\n\u2022 Anonymized IP.\n\u2022 Country in which the IP is locate: two letter country code, \u201cxx\u201d if not available.\n\u2022 List of word#senseNumber pairs belonging to the synsets: attached to allow quick human inspection without need to search for the synset on WordNet.\nThe feedback data can be downloaded from the SentiWordNet website. The feedback data is released under the Creative Commons AttributionShareAlike 3.0 Unported (CC BY-SA 3.0) license3."}, {"heading": "4 User feedback statistics", "text": "A total of 3510 feedback entries have been collected (about 3.5 a day on average). The feedback entries have been submitted from 1209 distinct IP addresses. The average is thus 2.9 entries per IP address, and the distribution follows a power law, as shown in Table 1.\nWith respect to the geographic origin of the feedback, 350 of the 1209 distinct IP addresses cannot be mapped to any country (\u201cxx\u201d, in Table 2). The remaining IP addresses come from 72 countries, 35 of which have contributed at least 15 feedback submissions from at least 5 distinct IP addresses.\n3http://creativecommons.org/licenses/by-sa/3.0/\nThe distribution in time of the feedback submissions (see Table 3) shows a first period, in 2010, with a relatively low number of submissions, a second period in 2011-2012 with a higher steady flow of submissions (85 per month on average) and a high peak in the first months of 2013.\nAmong all the feedback entries 2236 (63.7%) have the same exact values of the original SentiWordNet triplet. This in principle means that that feedback states the correctness of the relative SentiWordNet values, but there is also the possibility that part of that feedback has been generated by careless clicks on the feedback submission interface. The evaluation of feedback quality is beyond the scope of this report, though we are working on a number of improvements on the feedback collection process aimed at improving the quality of the collected feedback, as described in the next section."}, {"heading": "5 Improving user feedback collection", "text": "While preparing feedback data we have noticed some weak points in the feedback collection process and we have designed some modification to the interface and the collected information in order to improve them.\nThe feedback submission interface presented from the download link is vulnerable to repeated submission of feedback that confirms the original SentiWordNet values. This is due to the fact that that kind of submission has almost no \u201ccost\u201d, i.e., it requires only to click the \u201cSubmit feedback\u201d button, and that repeated click of that button does not even require to move the mouse. In order to limit the false confirmatory submissions we have added a confirmation dialog that asks to the user to actively confirm the submission of the feedback.\nWe noted also that there is a difference in the users\u2019 role between the two possible sources of feedback, i.e., the download link and the search interface. The feedback interface on the download link pushes requests of feedback to the users, with the synsets been evaluated selected by the interface, not by the users. Users may be thus not motivated to give their evaluation or also may not be prepared to evaluate a specific synset (e.g., being non-native speakers of the language). When users instead submit their feedback from the search interface,\nthey do it on entries they have searched for. Moreover, the main purpose of the interface is not feedback submission and thus it is likely that when the user decides to submit feedback the submitted values are carefully thought.\nIn the original implementation of the feedback collection process we did not differentiate the sources of feedback. It is not possible, on the feedback data from this first release, to tell if the feedback comes from the download or the search interface. We have added this information to any feedback collected from now on.\nWe have also redesigned the original feedback area in the search interface, substituting the single \u201cFeedback!\u201d button (see Figure 1) with two buttons: one that explicitly confirms the correctness of the presented values and one that opens the dialog for the submission of an alternative triplet of values (see Figure 4)."}], "references": [{"title": "Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining", "author": ["S. Baccianella", "A. Esuli", "F. Sebastiani"], "venue": "In Proceedings of the 7th conference on International Language Resources and Evaluation (LREC\u201910),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "Wordnet: A lexical database for english", "author": ["G.A. Miller"], "venue": "Communications of the ACM,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1995}], "referenceMentions": [{"referenceID": 0, "context": "SentiWordNet [1] is an automatically generated lexical resource that assigns to each sysnset of WordNet [2] a triplet of positivity, negativity and objectivity scores.", "startOffset": 13, "endOffset": 16}, {"referenceID": 1, "context": "SentiWordNet [1] is an automatically generated lexical resource that assigns to each sysnset of WordNet [2] a triplet of positivity, negativity and objectivity scores.", "startOffset": 104, "endOffset": 107}], "year": 2013, "abstractText": "With the release of SentiWordNet 3.0 the related Web interface has been restyled and improved in order to allow users to submit feedback on the SentiWordNet entries, in the form of the suggestion of alternative triplets of values for an entry. This paper reports on the release of the user feedback collected so far and on the plans for the future.", "creator": "LaTeX with hyperref package"}}}