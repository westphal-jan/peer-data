{"id": "1307.8057", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jul-2013", "title": "Extracting Connected Concepts from Biomedical Texts using Fog Index", "abstract": "in this paper, now establish fog index ( db ) as a text filter to recall the sentences in texts that treat connected biomedical concepts of interest. to do so, we have used 24 random papers each containing four pairs of connected concepts. for each pair, we categorize sentences based on whether they contain both, any or none of the concepts. we then use fi random measure samples of the solutions of each category and find three sentences containing more of the concepts have low readability. we rank sentences down a subject according to their authenticity and select 30 percent of the most difficult sentences. we use an association matrix to track nearly most frequent pairs - concepts in them. this matrix mean that the first filter produces some pairs that hold almost no connections. to remove these unwanted pairs, all use the equally weighted harmonic mean of their positive correlation value ( ppv ) and sensitivity as a second filter. experimental results demonstrate demonstrating effectiveness of our method.", "histories": [["v1", "Tue, 30 Jul 2013 17:27:29 GMT  (290kb)", "http://arxiv.org/abs/1307.8057v1", "12th Conference of the Pacific Association for Computational Linguistics (PACLING 2011), Kuala Lumpur, Malaysia, July 19-21, 2011"]], "COMMENTS": "12th Conference of the Pacific Association for Computational Linguistics (PACLING 2011), Kuala Lumpur, Malaysia, July 19-21, 2011", "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["rushdi shams", "robert e mercer"], "accepted": false, "id": "1307.8057"}, "pdf": {"name": "1307.8057.pdf", "metadata": {"source": "CRF", "title": "Extracting Connected Concepts from Biomedical Texts using Fog Index", "authors": ["Rushdi Shams", "Robert E. Mercer"], "emails": ["rshams@uwo.ca,", "mercer@csd.uwo.ca"], "sections": [{"heading": null, "text": "to locate the sentences in texts that contain connected biomedical concepts of interest. To do so, we have used 24 random papers each containing four pairs of connected concepts. For each pair, we categorize sentences based on whether they contain both, any or none of the concepts. We then use FI to measure difficulty of the sentences of each category and find that sentences containing both of the concepts have low readability. We rank sentences of a text according to their FI and select 30 percent of the most difficult sentences. We use an association matrix to track the most frequent pairs of concepts in them. This matrix reports that the first filter produces some pairs that hold almost no connections. To remove these unwanted pairs, we use the Equally Weighted Harmonic Mean of their Positive Predictive Value (PPV) and Sensitivity as a second filter. Experimental results demonstrate the effectiveness of our method.\nKey Words- Computational Linguistics, Text mining, Connected Concepts, Fog Index, Text Readability."}, {"heading": "1. Introduction", "text": "In recent years, extraction of connected biomedical concepts (i.e., disease, treatment, genes) from texts has drawn the attention of scientists interested in finding functional similarity (i.e., identification of genes involved in human diseases) [1]. Although benchmark research has reported successful methods to extract biomedical concepts [2] [3], they have rarely followed simple procedures. For example, Perez-Iratxeta et al. [4] could not relate diseases with gene functions from biomedical texts forthwith- they needed to apply a twofold intermediary process of connecting disease with chemical components and chemical components with gene functions. The key reason for this limitation of applying simple methods of extracting connected concepts from biomedical texts is manifold. While some researchers concentrated on number of occurrences of connected concepts in abstract of a paper [4] [5], others preferred to comb through either the full text [6] or pre-specified segments (i.e., Introduction, Methods, Results, and Discussion) [7]. Next to this, the connections can be very\ngeneral (i.e., biochemical connections) or very specific (i.e., regulatory connections). Therefore, the demand of simple identification and extraction of biomedical or any other concepts from a scientific literature that maintain general or specific connections with one another is not met till to date. This situation suggests using improved yet simple computational method to identify and extract important, explicit and implicit connections from biomedical texts.\nAs text is highly structured by syntax and semantics of natural language, it is believed that such methods should involve these two features but several reports assert their complexity [8] [9]. Apart from this, Sherman [10] proposed that scientific literature is subject to statistical analysis and zeroed in on the importance of average sentence length. Gunning [11] practically demonstrated this important measure along with the number of complex words (i.e., words with three or more syllables) to assess the readability of text known as the Fog Index (FI), shorthand for the Gunning Fog Readability Index. It is now considered as a yardstick for readability assessment of books, novels, scientific literature and newspapers and even to detect online chatting bots [12].\nIn this paper, we report a simple novel statistical method to extract connected biomedical concepts from biomedical texts using FI. We statistically established FI as a text filter, experimenting on 24 random papers that describe four pairs of concepts: Ischemia-Glutamate, Ataxia-Dehydrogenase, Hypogonadism-Gonadotropin, and Epilepsy-GABA. Besides FI, our method also uses the equally weighted harmonic mean of the connections\u2019 Positive Predictive Value (PPV) and sensitivity as a second filter. While the prior concentrates on the important part of the text where the connections are stated, the latter assesses their representativeness. We selected sentences of a paper that are difficult to read and measured most frequent connected concepts present in them. With careful observations, we noticed that the first filter produces some noisy pairs of concepts that have a rather weak connection. To omit them, we calculated the PPV and sensitivity of each pair. Then, we filtered these pairs based on the equally weighted harmonic mean of their PPV and sensitivity.\nIn the remainder of this paper, we describe related work, illustrate the complete method, report and discuss experimental results, and draw conclusions."}, {"heading": "2. Related work", "text": "New research trends in the biomedical field include the discovery of hidden connections in texts to form new hypotheses that can be explored further by conventional experimentation [6]. A series of investigations by Swanson [13] [14] showed that these hidden connections can lead us to new discoveries. He reported that fish oil leads to change in blood viscosity and red blood cell rigidity that helps prevent Raynaud\u2019s syndrome [13]. Later, investigative reports started to discover suggestions for clinical therapies and basic physiological linkages from bibliographically isolated texts. However, the working principles of Swanson\u2019s empirical research include the computational burden of full-text syntactic analysis and involve large literature databases like MEDLINE. Our work, though it does not generate hypotheses, can be a good means of finding implicit connections in texts using fewer computations (as it filters out texts according to their readability and does not operate syntactically) without involving literature repositories.\nA handful of research work in semantic relation classification or extraction from bioscience texts depends on the proper identification of connections. Rosario and Hearst [15] concentrated on discovering connections between \u201ctreatment\u201d and \u201cdisease\u201d. They reported 79.6 percent accuracy in blindly identifying concepts that fall into either of the categories and are somehow connected with one another. They used a MEDLINE-based neural network that addresses it to be intriguing yet complicated. A similar machine learning technique was applied by Frunza and Inkpen [8] to extract disease-treatment connections from texts. Their reported accuracy surpassed the results of Rosario and Hearst although their interest was limited to MEDLINE 2001 titles and abstracts. Their paper, like many other prominent work [16] [17], has a significant use of PPV and sensitivity to evaluate the mining technique. Contrary, we used these measures to evaluate the representativeness of the connected concepts.\nPerez-Iratxeta et al. [4] proposed a massive framework to prioritize disease associated genes. Instead of looking into literature, they combined several isolated pieces of biomedical repositories like Medical Subject Heading (MeSH), Gene Ontology (GO), RefSeq database, and MEDLINE. They used both databases and ontology that have lack in communication with one another and thus experienced tedious and complex scoring methods and formidable number of intermediate stages. In our work, we decided to stick with texts only to remain simple yet capable of producing improved results.\nRobert Gunning [11] first introduced Fog Index (FI) to measure semantic difficulties using average sentence length and polysyllabic words in his 1952 book The Technique of Clear Writing. We were motivated to apply FI as our text filter when we came across the experimental\noutput carried by Duffy and Kabance [18]. They converted a passage with no more than two phrases into primer prose and applied FI to test its readability. They found the score well below the readability index (i.e., it was excessively easy to read). Their investigation on this phenomenon suggested that easy articles (in this case the primer prose) obscure the relationships and ideas as they emphasize each of them equally. In other words, difficult articles possess relationships and ideas and emphasize them in particular that yields low readability. We believe that if biomedical texts display similar attribute, then FI can be an appropriate measure to filter texts that bear associations of scientific interest."}, {"heading": "3. Methodology", "text": "The work of Perez-Iratxeta et al. [4] lists pairs of connected concepts like disease-chemical components, chemical component-genes, and disease-genes. Among them, we considered four disease-chemical component pairs, namely Ischemia-Glutamate, AtaxiaDehydrogenase, Hypogonadism-Gonadotropin., and Epilepsy-GABA. We collected 24 scientific papers (six for each pair of concepts) at random from several biomedical literature repositories. To work with the text only, we removed the title, affiliations, keywords, footnotes, figures, tables, acknowledgements, and references from the paper.\nWe considered each pair of concepts and a paper related to them. We classified its sentences into three sets: sentences containing both of the concepts, none of the concepts and any of the concepts. For example, the sentence \u201cGlutamate, which is potentially excito-toxic to brain neurons, is released excessively during ischemia\u201d, will be put into the set of sentences containing both of the concepts Ischemia and Glutamate, as Ischemia and Glutamate are both present. Then, we applied Gunning\u2019s formula for FI (Eq. 1) to score the sentences of every set. It is noted that according to this formula, the lower the score of a sentence, the easier it is to read.\n(1)\nIt can be noted that according to Gunning, words that are polysyllabic (i.e., contain three or more syllables) are called . Also, as we applied FI on every sentence, the value of is always 1.\nWe normalized this score by the paper\u2019s average number of syllables per word because readability score of long and short sentences varies due to the total number of syllables [11]. Eq. 2 provides the normalized FI ( ) of the sentences in every set.\n(2)\nTable 1 shows the calculated for the three sets of sentences for the 24 papers in groups related to the four pairs of connected concepts.\nTable 1 shows that, for every pair of connected concepts, while the set of sentences containing any or both of the concepts displays either High or Medium , the set of sentences containing none of them consistently possesses Low scores. This observation leads us to a decision that the sentences that are easier to read contain no connected concepts and therefore, we should look into low-readable sentences for hidden connections.\nNow that we have FI as a functioning text filter, we need to define a way to determine the number of lowreadable sentences to be considered for concept extraction. We ranked all sentences in a paper based on their FI score and sorted them in descending order (i.e., the most difficult sentences are at the top of the list). Then, in five chunks of 10 percent interval, we selected top 50 percent, 40 percent, 30 percent, 20 percent, and 10 percent of the sentences from this sorted list. For every chunk, we tagged these selected sentences with Genia Biomedical POS tagger [19], identified nouns in them and used an association matrix to record the frequency of connected concepts (i.e., number of occurrences of one noun with the other). For the sentence \u201cGlutamate, which\nis potentially excito-toxic to brain neurons, is released excessively during ischemia\u201d, the connected concepts are glutamate-brain, glutamate-neurons, glutamate-ischemia, brain-neurons, brain-ischemia, and neurons-ischemia. From the output of the association matrix, we kept 20 most frequent for our experiment. We observed that some chunk contains new connections that are absent in chunk and vice versa. To find a threshold, we tracked number of connections revealed and connections missed by every chunk with respect to its previous chunk . From Figure 1, we see that for the first chunk (50 percent of the sentences), all of the 20 most frequent connections are new. The number of new connections becomes steady in the third chunk (30 percent of the sentences) but reaches the extremes in the fourth and fifth. The results in Figure 1 are showed for six papers related to Ischemia and Glutamate. Similar experiments were conducted with other connected concepts and all of them showed that if we take less than 30 percent of the ranked sentences, the number of new concepts reach the extremes.\nWe recorded identical behavior for the number of connections dropped by every chunk. Figure 2 shows that as we start, the first chunk (10 percent of the sentences) does not miss any connection. The number of dropped connections becomes steady in the third chunk (30 percent of the sentences) but starts to reach the extremes in the fourth and fifth. Again, the results in Figure 2 are produced by six papers on Ischemia and Glutamate. We\nconducted similar experiments with other connected concepts. All of them showed that if we take less than 30 percent of the ranked sentences, the number of dropped connections reach the extremes.\nThese two observations indicate that the degree of concepts connected with each other is conserved if we take 30 percent of the low-readable sentences. Similar results are obtained for the three other pairs of concepts.\nProvided the threshold, Table 2 shows the 20 most frequent connected concepts found in a paper on Ischemia-Glutamate where the connections are ranked according to their frequency. For each pair shown in Table 2, we extracted sentences from the paper that contain both of the concepts. These sentences are fed to Unified Medical Language System (UMLS) semantic\nrelation network [20] to find out the semantic relations between the concepts. Surprisingly, we found that among the 20 connected concepts, only nine have textual semantic connections (Levels-Glutamate, IschemiaGlutamate, Levels-Increase, Increase-Glutamate, 10minIschemia, Glutamate-Experiment, Glutamate-Neurons, Glutamate-CA4, and Ischemia-5min).\nSo, FI, as a text filter, brings in some text that contains most frequent connected concepts but some of the concepts lack representativeness (i.e., they do not hold any connection). It urged us to provide a means by which we can filter out these noisy pairs of concepts. We observed as we collected texts at random, there is the possibility that the pairs we considered for experimentation may never co-occur in a sentence which indicates that our data set is imbalanced. So, we used the equally weighted harmonic mean of the PPV and sensitivity of the pairs of concepts provided by FI to evaluate their representativeness as it is a great evaluation metric for imbalanced dataset [8].\nPPV is the percentage of correctly predicted connections and sensitivity represents the percentage of connections identified as relevant by our system. To measure the PPV and sensitivity of every pair of concepts,\nwe first considered the set of sentences filtered by FI and counted the number. This is the total number of results returned by our system that comprises the number of True Positives and False Positives . Then, we take a pair depicted in Table 2, searched the paper, and developed a second set of sentences that contain both of its concepts. The number of sentences in this set is the number of results that should have been returned by our system and comprises the number of True Positives and False Negatives . Finally, we counted the number of sentences that are present in both sets- which is the number of s returned by our system. Afterwards, is obtained by subtracting from and is obtained by subtracting from . So, the PPV of every\npair of connected concepts is\nand the sensitivity of\nevery pair of connected concepts is\n. We then\napplied the formula in Eq. 3 to determine the equally weighted harmonic mean for the given pair of concepts. In this way, we measured this mean for every pair of concepts in Table 2.\n(3)\nWhen we finished measuring this mean for all of the pairs, we re-ranked them and considered the first 10 pairs of concepts. These 10 pairs of connected concepts are said to be the representative connected concepts of the paper.\nWe followed the similar procedure to evaluate the representativeness of pairs of concepts for the rest of the three connected concepts.\nWe measured the accuracy of every connected pair by\nusing Eq. 4 as well-\n(4)\nWhere is the number of True Negatives and can be found by subtracting from total number of sentences in a text. But we found that in the case of accuracy, the connections are not distinguishable according to their ranks."}, {"heading": "4. Results and Discussions", "text": "Table 3 lists the 10 connected concepts for a paper on Ischemia and Glutamate among which seven pairs of concepts are reported as semantically connected by UMLS.\nTable 4 shows the 10 connected concepts for a paper on Ataxia and Dehydrogenase, eight of which are semantically connected in the UMLS semantic relation network. Our observation of this domain reveals that PDHC (Pyruvate Dehydrogenase Complex) is manifested in Ataxia patients, especially those suffering from Friedreich\u2019s Ataxia. So, the relations among Friedreich, Ataxia and PDHC are vividly represented in the list.\nTable 5 lists the 10 connected concepts for a paper on Hypogonadism and Gonadotropin. According to the UMLS semantic relation network, eight of these pairs are semantically related.\nSteroids have significant effects on diseases like Hypogonadism, where release of testosterone plays an important role. Therefore, the connection between AAS (Anabolic Androgenic Steroid) that induces Hypogonadism and Testosterone is present in the list.\nTable 6 displays the connected concepts present in a\npaper on Epilepsy and GABA.\nEpilepsy is a neuronal disease that causes inhibition and significantly affects neuronal structure like the Hippocampus. In the list, we find eight concepts that are semantically related according to UMLS."}, {"heading": "5. Conclusions", "text": "In this paper, we report on the extraction of connected concepts from biomedical texts by assessing text readability. The readability of text is determined by a metric called Fog Index (FI). We curated 24 random papers by using four pairs of connected concepts as keywords and applied FI on them. Experimental results showed that sentences display low readability if they contain connected concepts. We selected 30 percent of the most difficult-to-read sentences, and used an association matrix to track the most frequent pairs of concepts in them. To remove those pairs of concepts that have a rather weak connection, we used the equally weighted harmonic mean of their positive predictive value and sensitivity as a second ranking filter. The results are supported by finding almost all of the extracted concepts semantically connected by the UMLS semantic relation network."}, {"heading": "6. References", "text": "[1] F. Yuan, R. Wang, M. Guan, and G. He, \u201cA Novel Computational Method for Predicting Disease Genes Based on Functional Similarity\u201d, Lecture Notes in Computer Science, Vol. 6216/2010, 2010, pp. 42-51. [2] S. Zhao, \u201cNamed Entity Recognition in Biomedical Texts using an HMM Model\u201d, International Joint Workshop on Natural Language Processing in Biomedicine and Its Applications, Geneva, Switzerland, 2004, pp. 84-87. [3] J. Kazama, T. Makino, Y. Ohta, and J. Tsujii, \u201cTuning Support Vector Machines for Biomedical Named Entity Recognition\u201d, ACL-02 Workshop on Natural Language Processing in the Biomedical Domain, Vol. 3, Philadelphia, USA, 2002, pp. 1-8. [4] C. Perez-Iratxeta, P. Bork, and M. Andrade, \u201cLiterature and Genome Data Mining for Prioritizing Disease-Associated Genes\u201d, Discovering Bimolecular Mechanisms with Computational Biology (Molecular Biology Intelligence Unit II), 2006, pp. 74-81. [5] H. Dai, Y. Chang, R. T. Tsai, and W. Hsu, \u201cNew Challenges for Biological Text-Mining in the Next Decade\u201d, Journal of Computer Science and Technology, Vol. 25, No. 1, 2010, pp. 169-179. [6] R. Lindsay and M. Gordon, \u201c Literature-Based Discovery by Lexical Statistics\u201d, Journal of the American\nSociety for Information Science, Vol. 50, No. 7, 1999, pp. 574-587. [7] S. Agarwal and H. Yu, \u201cAutomatically Classifying Sentences in Full-text Biomedical Articles into Introduction, Methods, Results and Discussion\u201d, Bioinformatics, Vol. 25, No. 23, 2009, pp. 3174-3180. [8] O. Frunza and D. Inkpen, \u201cExtraction of DiseaseTreatment Semantic Relations from Biomedical Sentences\u201d, 2010 Workshop on Biomedical Natural Language Processing, ACL 2010, Uppsala, Sweden, 2010, pp. 91-98. [9] G. Leroy, H. Chen, and J. D. Martinez, \u201cA Shallow Parser based on Closed-class Words to Capture Relations in Biomedical Text\u201d, Journal of Biomedical Informatics, Vol. 36, 2003, pp. 145-158. [10] A. L. Sherman, \u201cAnalytics of literature: A Manual for the Objective Study of English Prose and Poetry\u201d, Boston: Ginn & Co, 1893. [11] R. Gunning, \u201cFog Index after Twenty Years\u201d, Journal of Business Communication, Vol. 6, No. 3, 1969, pp. 3-13. [12] O. S. Goh, C. C. Fung, A. Depickere, and K.W. Wong, \u201cUsing Gunning-Fog Index to Assess Instant Message Readability from ECAs\u201d, 3 rd International Conference on Natural Computation (ICNC 2007), Hainan, China, 2007, pp. 480-486. [13] D. R. Swanson, \u201cFish Oil, Raynaud\u2019s Syndrome, and Undiscovered Public Knowledge\u201d, Perspectives in Biology and Medicine, Vol. 30, 1986, pp. 7-18. [14] D. R. Swanson, \u201cA Second Example of Mutually Isolated Medical Literatures related by Implicit, Unnoticed Connections\u201d, Journal of the American Society for Information Science, Vol. 40, 1989, pp. 432-435. [15] B. Rosario and M. A. Hearst, \u201cClassifying Semantic Relations in Bioscience Texts\u201d, 42 nd Annual Meeting of Association for Computational Linguistics, Barcelona, Spain, 2004. [16] L. Smith et al., \u201cOverview of BioCreative II Gene Mention Recognition, Genome Biology, Vol. 9 (Suppl.2): S2, 2008. [17] M. Krallinger et al., \u201cOverview of the ProteinProtein Interaction Annotation Extraction Task of BioCreative II\u201d, Genome Biology, Vol. 9 (Suppl.2): S4, 2008. [18] T. M. Duffy and P. Kabance, \u201cTesting a Readable Writing Approach to Text Revision\u201d, Journal of Educational Psychology, Vol. 74, 1982, pp. 733-48. [19] Y. Tsuruoka et al., \u201cDeveloping a Robust Part-ofSpeech Tagger for Biomedical Text\u201d, Lecture Notes on Computer Science, Vol. 3746/2005, 2005, pp. 382-392. [20] Unified Medical Language System (UMLS), \u201cUMLS Terminology Services (UTS)\u201d, URL: https://uts.nlm.nih.gov/home.html [March 10, 2011]"}], "references": [{"title": "A Novel Computational Method for Predicting Disease Genes Based on Functional Similarity", "author": ["F. Yuan", "R. Wang", "M. Guan", "G. He"], "venue": "Lecture Notes in Computer Science, Vol. 6216/2010", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2010}, {"title": "Named Entity Recognition in Biomedical Texts using an HMM Model", "author": ["S. Zhao"], "venue": "International Joint Workshop on Natural Language Processing in Biomedicine and Its Applications, Geneva, Switzerland", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2004}, {"title": "Tuning Support Vector Machines for Biomedical Named Entity Recognition", "author": ["J. Kazama", "T. Makino", "Y. Ohta", "J. Tsujii"], "venue": "ACL-02 Workshop on Natural Language Processing in the Biomedical Domain, Vol. 3, Philadelphia, USA", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2002}, {"title": "Literature and Genome Data Mining for Prioritizing Disease-Associated Genes", "author": ["C. Perez-Iratxeta", "P. Bork", "M. Andrade"], "venue": "Discovering Bimolecular Mechanisms with Computational Biology (Molecular Biology Intelligence Unit II)", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2006}, {"title": "New Challenges for Biological Text-Mining in the Next Decade", "author": ["H. Dai", "Y. Chang", "R.T. Tsai", "W. Hsu"], "venue": "Journal of Computer Science and Technology, Vol. 25, No. 1", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": " Literature-Based Discovery by Lexical Statistics", "author": ["R. Lindsay", "M. Gordon"], "venue": "Journal of the American  Society for Information Science, Vol. 50, No. 7", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1999}, {"title": "Automatically Classifying Sentences in Full-text Biomedical Articles into Introduction", "author": ["S. Agarwal", "H. Yu"], "venue": "Methods, Results and Discussion\u201d, Bioinformatics, Vol. 25, No. 23", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "Extraction of Disease- Treatment Semantic Relations from Biomedical Sentences", "author": ["O. Frunza", "D. Inkpen"], "venue": "2010 Workshop on Biomedical Natural Language Processing, ACL 2010, Uppsala, Sweden", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "A Shallow Parser based on Closed-class Words to Capture Relations in Biomedical Text", "author": ["G. Leroy", "H. Chen", "J.D. Martinez"], "venue": "Journal of Biomedical Informatics, Vol. 36", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2003}, {"title": "Fog Index after Twenty Years", "author": ["R. Gunning"], "venue": "Journal of Business Communication, Vol. 6, No. 3", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1969}, {"title": "Using Gunning-Fog Index to Assess Instant Message Readability from ECAs", "author": ["O.S. Goh", "C.C. Fung", "A. Depickere", "K.W. Wong"], "venue": "3  rd International Conference on Natural Computation ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2007}, {"title": "Fish Oil", "author": ["D.R. Swanson"], "venue": "Raynaud\u2019s Syndrome, and Undiscovered Public Knowledge\u201d, Perspectives in Biology and Medicine, Vol. 30", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1986}, {"title": "A Second Example of Mutually Isolated Medical Literatures related by Implicit", "author": ["D.R. Swanson"], "venue": "Unnoticed Connections\u201d, Journal of the American Society for Information Science, Vol. 40", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1989}, {"title": "Classifying Semantic Relations in Bioscience Texts", "author": ["B. Rosario", "M.A. Hearst"], "venue": "42  nd Annual Meeting of Association for Computational Linguistics, Barcelona, Spain", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2004}, {"title": "Overview of BioCreative II Gene Mention Recognition", "author": ["L. Smith"], "venue": "Genome Biology,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2008}, {"title": "Overview of the Protein- Protein Interaction Annotation Extraction Task of BioCreative II", "author": ["M. Krallinger"], "venue": "Genome Biology,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}, {"title": "Testing a Readable Writing Approach to Text Revision", "author": ["T.M. Duffy", "P. Kabance"], "venue": "Journal of Educational Psychology, Vol. 74", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1982}, {"title": "Developing a Robust Part-of- Speech Tagger for Biomedical Text", "author": ["Y. Tsuruoka"], "venue": "Lecture Notes on Computer Science,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": ", identification of genes involved in human diseases) [1].", "startOffset": 54, "endOffset": 57}, {"referenceID": 1, "context": "Although benchmark research has reported successful methods to extract biomedical concepts [2] [3], they have rarely followed simple procedures.", "startOffset": 91, "endOffset": 94}, {"referenceID": 2, "context": "Although benchmark research has reported successful methods to extract biomedical concepts [2] [3], they have rarely followed simple procedures.", "startOffset": 95, "endOffset": 98}, {"referenceID": 3, "context": "[4] could not relate diseases with gene functions from biomedical texts forthwith- they needed to apply a twofold intermediary process of connecting disease with chemical components and chemical components with gene functions.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "While some researchers concentrated on number of occurrences of connected concepts in abstract of a paper [4] [5], others preferred to comb through either the full text [6] or pre-specified segments (i.", "startOffset": 106, "endOffset": 109}, {"referenceID": 4, "context": "While some researchers concentrated on number of occurrences of connected concepts in abstract of a paper [4] [5], others preferred to comb through either the full text [6] or pre-specified segments (i.", "startOffset": 110, "endOffset": 113}, {"referenceID": 5, "context": "While some researchers concentrated on number of occurrences of connected concepts in abstract of a paper [4] [5], others preferred to comb through either the full text [6] or pre-specified segments (i.", "startOffset": 169, "endOffset": 172}, {"referenceID": 6, "context": ", Introduction, Methods, Results, and Discussion) [7].", "startOffset": 50, "endOffset": 53}, {"referenceID": 7, "context": "As text is highly structured by syntax and semantics of natural language, it is believed that such methods should involve these two features but several reports assert their complexity [8] [9].", "startOffset": 185, "endOffset": 188}, {"referenceID": 8, "context": "As text is highly structured by syntax and semantics of natural language, it is believed that such methods should involve these two features but several reports assert their complexity [8] [9].", "startOffset": 189, "endOffset": 192}, {"referenceID": 9, "context": "Gunning [11] practically demonstrated this important measure along with the number of complex words (i.", "startOffset": 8, "endOffset": 12}, {"referenceID": 10, "context": "It is now considered as a yardstick for readability assessment of books, novels, scientific literature and newspapers and even to detect online chatting bots [12].", "startOffset": 158, "endOffset": 162}, {"referenceID": 5, "context": "New research trends in the biomedical field include the discovery of hidden connections in texts to form new hypotheses that can be explored further by conventional experimentation [6].", "startOffset": 181, "endOffset": 184}, {"referenceID": 11, "context": "A series of investigations by Swanson [13] [14] showed that these hidden connections can lead us to new discoveries.", "startOffset": 38, "endOffset": 42}, {"referenceID": 12, "context": "A series of investigations by Swanson [13] [14] showed that these hidden connections can lead us to new discoveries.", "startOffset": 43, "endOffset": 47}, {"referenceID": 11, "context": "He reported that fish oil leads to change in blood viscosity and red blood cell rigidity that helps prevent Raynaud\u2019s syndrome [13].", "startOffset": 127, "endOffset": 131}, {"referenceID": 13, "context": "Rosario and Hearst [15] concentrated on discovering connections between \u201ctreatment\u201d and \u201cdisease\u201d.", "startOffset": 19, "endOffset": 23}, {"referenceID": 7, "context": "A similar machine learning technique was applied by Frunza and Inkpen [8] to extract disease-treatment connections from texts.", "startOffset": 70, "endOffset": 73}, {"referenceID": 14, "context": "Their paper, like many other prominent work [16] [17], has a significant use of PPV and sensitivity to evaluate the mining technique.", "startOffset": 44, "endOffset": 48}, {"referenceID": 15, "context": "Their paper, like many other prominent work [16] [17], has a significant use of PPV and sensitivity to evaluate the mining technique.", "startOffset": 49, "endOffset": 53}, {"referenceID": 3, "context": "[4] proposed a massive framework to prioritize disease associated genes.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "Robert Gunning [11] first introduced Fog Index (FI) to measure semantic difficulties using average sentence length and polysyllabic words in his 1952 book The Technique of Clear Writing.", "startOffset": 15, "endOffset": 19}, {"referenceID": 16, "context": "We were motivated to apply FI as our text filter when we came across the experimental output carried by Duffy and Kabance [18].", "startOffset": 122, "endOffset": 126}, {"referenceID": 3, "context": "[4] lists pairs of connected concepts like disease-chemical components, chemical component-genes, and disease-genes.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "We normalized this score by the paper\u2019s average number of syllables per word because readability score of long and short sentences varies due to the total number of syllables [11].", "startOffset": 175, "endOffset": 179}, {"referenceID": 17, "context": "For every chunk, we tagged these selected sentences with Genia Biomedical POS tagger [19], identified nouns in them and used an association matrix to record the frequency of connected concepts (i.", "startOffset": 85, "endOffset": 89}, {"referenceID": 7, "context": "So, we used the equally weighted harmonic mean of the PPV and sensitivity of the pairs of concepts provided by FI to evaluate their representativeness as it is a great evaluation metric for imbalanced dataset [8].", "startOffset": 209, "endOffset": 212}], "year": 2011, "abstractText": "In this paper, we establish Fog Index (FI) as a text filter to locate the sentences in texts that contain connected biomedical concepts of interest. To do so, we have used 24 random papers each containing four pairs of connected concepts. For each pair, we categorize sentences based on whether they contain both, any or none of the concepts. We then use FI to measure difficulty of the sentences of each category and find that sentences containing both of the concepts have low readability. We rank sentences of a text according to their FI and select 30 percent of the most difficult sentences. We use an association matrix to track the most frequent pairs of concepts in them. This matrix reports that the first filter produces some pairs that hold almost no connections. To remove these unwanted pairs, we use the Equally Weighted Harmonic Mean of their Positive Predictive Value (PPV) and Sensitivity as a second filter. Experimental results demonstrate the effectiveness of our method. Key WordsComputational Linguistics, Text mining, Connected Concepts, Fog Index, Text Readability.", "creator": "Microsoft\u00ae Office Word 2007"}}}