{"id": "1308.0689", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Aug-2013", "title": "Measure Transformer Semantics for Bayesian Machine Learning", "abstract": "the bayesian approach to machine learning amounts to computing posterior sampling of random variables from a probabilistic model of how the variables are related ( if is, a prior distribution ) and a set of observations of variables. there is a trend in machine memory computing expressing bayesian models as probabilistic programs. utilizing a foundation for one kind of programming, we propose a core functional calculus with primitives for sampling prior distributions and observing variables. we define measure - transformer combinators inspired by fluctuations in measure composition, and use these to give a useful semantics to our dependency product. the original features of our semantics include its support for discrete, hybrid, and hybrid measures, arising, in particular, for observations of zero - probability events. we compile our core language to a small imperative language that requires processed outside an existing inference engine for factor graphs, which are data structures that enable many efficient inference algorithms. fusion allows efficient approximate verification of posterior marginal distributions, taking thousands of observations per second for large databases on realistic models.", "histories": [["v1", "Sat, 3 Aug 2013 12:28:23 GMT  (69kb)", "https://arxiv.org/abs/1308.0689v1", "An abridged version of this paper appears in the proceedings of the 20th European Symposium on Programming (ESOP'11), part of ETAPS 2011"], ["v2", "Fri, 6 Sep 2013 11:45:21 GMT  (72kb)", "http://arxiv.org/abs/1308.0689v2", "An abridged version of this paper appears in the proceedings of the 20th European Symposium on Programming (ESOP'11), part of ETAPS 2011"], ["v3", "Fri, 20 Sep 2013 18:48:34 GMT  (71kb)", "http://arxiv.org/abs/1308.0689v3", "An abridged version of this paper appears in the proceedings of the 20th European Symposium on Programming (ESOP'11), part of ETAPS 2011"], ["v4", "Mon, 23 Sep 2013 08:01:06 GMT  (71kb)", "http://arxiv.org/abs/1308.0689v4", "An abridged version of this paper appears in the proceedings of the 20th European Symposium on Programming (ESOP'11), part of ETAPS 2011"]], "COMMENTS": "An abridged version of this paper appears in the proceedings of the 20th European Symposium on Programming (ESOP'11), part of ETAPS 2011", "reviews": [], "SUBJECTS": "cs.LO cs.AI cs.PL", "authors": ["johannes borgstr\\\"om", "rew d gordon", "michael greenberg", "james margetson", "jurgen van gael"], "accepted": false, "id": "1308.0689"}, "pdf": {"name": "1308.0689.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["JOHANNES BORGSTR\u00d6Ma", "ANDREW D. GORDONb", "MICHAEL GREENBERG", "JAMES MARGETSONd", "JURGEN VAN GAEL", "J. VAN GAEL", "Csoft", "FACTORIE", "Figaro", "HANSEI", "HBC", "IBAL"], "emails": ["borgstrom@acm.org", "adg@microsoft.com,", "jfdm1@roundwood.org", "mgree@seas.upenn.edu", "jurgen.vangael@gmail.com"], "sections": [{"heading": "1. INTRODUCTION", "text": "In the past 15 years, statistical machine learning has unified many seemingly unrelated methods through the Bayesian paradigm. With a solid understanding of the theoretical foundations, advances in algorithms for inference, and numerous applications, the Bayesian paradigm is now the state of the art for learning from data. The theme of this paper is the idea of expressing Bayesian models as probabilistic programs, which was pioneered by BUGS [14] and is recently gaining in popularity,\n2012 ACM CCS: [Theory of computation]: Semantics and reasoning\u2014Program constructs; [Computing methodologies]: Machine learning\u2014Machine learning approaches.\nKey words and phrases: Probabilistic Programming, Model-based Machine Learning, Programming Languages, Denotational Semantics. \u2217 An abridged version of this paper appears in the proceedings of the 20th European Symposium on Programming (ESOP\u201911), part of ETAPS 2011, held in Saarbru\u0308cken, Germany, March 26\u2013April 3, 2011.\nLOGICAL METHODS lIN COMPUTER SCIENCE DOI:10.2168/LMCS-9(3:11)2013\nc\u00a9 J. Borgstr\u00f6m, A. D. Gordon, M. Greenberg, J. Margetson, and J. Van Gael CC\u00a9 Creative Commons\nwitness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], \u03bb\u25e6 [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].\nIn particular, we draw inspiration from Csoft [52], an imperative language where programs denote factor graphs [28], data structures that support efficient inference algorithms [25]. Csoft is the native language of Infer.NET [37], a software library for Bayesian reasoning. This paper gives an alternative probabilistic semantics to languages with features similar to those of Csoft.\nBayesian Models as Probabilistic Expressions. Consider a simplified form of TrueSkill [19], a large-scale online system for ranking computer gamers. There is a population of players, each assumed to have a skill, which is a real number that cannot be directly observed. We observe skills only indirectly via a series of matches. The problem is to infer the skills of players given the outcomes of the matches. Here is a concrete example: Alice, Bob, and Cyd are new players."}, {"heading": "In a tournament of three games, Alice beats Bob, Bob beats Cyd, and Alice beats Cyd. What are", "text": "their skills? In a Bayesian setting, we represent our uncertain knowledge of the skills as continuous probability distributions. The following probabilistic expression models the situation by generating probability distributions for the players\u2019 skills, given three played games (observations).\n// prior distributions, the hypothesis let skill() = random (Gaussian(10.0,20.0)) let Alice,Bob,Cyd = skill(),skill(),skill() // observe the evidence let performance player = random (Gaussian(player,1.0)) observe (performance Alice > performance Bob) //Alice beats Bob observe (performance Bob > performance Cyd) //Bob beats Cyd observe (performance Alice > performance Cyd) //Alice beats Cyd // return the skills Alice,Bob,Cyd\nA run of this expression goes as follows. We sample the skills of the three players from the prior distribution Gaussian(10.0,20.0). Such a distribution can be pictured as a bell curve centred on the mean 10.0, and gradually tailing off at a rate given by the variance, here 20.0. Sampling from such a distribution is a randomized operation that returns a real number, most likely close to the mean. For each match, the run continues by sampling an individual performance for each of the two players. Each performance is centred on the skill of a player, with low variance, making the performance closely correlated with but not identical to the skill. We then observe that the winner\u2019s performance is greater than the loser\u2019s. An observation observe M always returns (), but represents a constraint that M must be true. A whole run is valid if all encountered observations are true. The run terminates by returning the three skills.\nA classic computational method to compute an approximate posterior distribution of each of the skills is Monte Carlo sampling [31]. We run the expression many times, but keep just the valid runs\u2014the ones where the sampled skills and performances are consistent with the observed outcomes. We then compute the means of the resulting skills by applying standard statistical formulas. In the example above, the posterior distribution of the returned skills moves so that the mean of Alice\u2019s skill is greater than Bob\u2019s, which is greater than Cyd\u2019s. To the best of our knowledge, all prior inference techniques for probabilistic languages with continuous distributions, apart from Csoft and\nrecent versions of IBAL [43], are based on nondeterministic inference using some form of Monte Carlo sampling.\nInference algorithms based on factor graphs [28, 25] are an efficient alternative to Monte Carlo sampling. Factor graphs, used in Csoft, allow deterministic but approximate inference algorithms, which are known to be significantly more efficient than sampling methods, where applicable.\nObservations with zero probability arise naturally in Bayesian models. For example, in the model above, a drawn game would be modelled as the performance of two players being observed to be equal. Since the performances are randomly drawn from a continuous distribution, the probability of them actually being equal is zero, so we would not expect to see any valid runs in a Monte Carlo simulation. (To use Monte Carlo methods, one must instead write that the absolute difference between two drawn performances is less than some small \u03b5 .) However, our semantics based on measure theory makes sense of such observations. Our semantics is the first for languages with continuous or hybrid distributions, such as Fun or Imp, that are implemented by deterministic inference via factor graphs.\nPlan of the Paper. We propose Fun: \u2022 Fun is a functional language for Bayesian models with primitives for probabilistic sampling and observations (Section 2). \u2022 Fun programs have a rigorous probabilistic semantics as measure transformers (Section 3). \u2022 Fun has an efficient implementation: our system compiles Fun to Imp (Section 4), a subset of\nCsoft, and then relies on Infer.NET (Section 6). \u2022 Fun supports array types and array comprehensions in order to express Bayesian models over\nlarge datasets (Section 5).\nOur main contribution is a framework for finite measure transformer semantics, which supports discrete measures, continuous measures, and mixtures of the two, and also supports observations of zero probability events.\nAs a substantial application, we supply measure transformer semantics for Fun and Imp, and use the semantics to verify the translations in our compiler. Theorem 3.3 establishes agreement with the discrete semantics of Section 2 for Bernoulli Fun. Theorem 4.4 establishes the correctness of the compilation from Fun to Imp.\nWe designed Fun to be a subset of the F# dialect of ML [51], for implementation convenience: F# reflection allows easy access to the abstract syntax of a program. All the examples in the paper have been executed with our system, described in Section 6. We end the paper with a description of related work (Section 7) and some concluding remarks (Section 8).\nAppendix A contains proofs omitted from the main body of the paper. The technical report version of our paper [8] includes additional details, including the code of an F# implementation of measure transformers in the discrete case."}, {"heading": "2. BAYESIAN MODELS AS PROBABILISTIC EXPRESSIONS", "text": "We introduce the idea of expressing a probabilistic model as code in a functional language, Fun, with primitives for generating and observing random variables. As an illustration, we first consider a subset, Bernoulli Fun, limited to weighted Boolean choices. We describe in elementary terms an operational semantics for Bernoulli Fun that allows us to compute the conditional probability that the expression yields a given value given that the run was valid.\n2.1. Syntax, Informal Semantics, and Bayesian Reading. Expressions are strongly typed, with types t,u built up from base scalar types b and pair types. We let c range over constant data of scalar type, n over integers, and r over real numbers. We write ty(c) = t to mean that constant c has type t. For each base type b, we define a zero element 0b with 0bool = true, and let 0t\u2217u = (0t ,0u). We have arithmetic and Boolean operations \u2295 on base types."}, {"heading": "Types, Constant Data, and Zero Elements:", "text": "b ::= bool | int | real base type t,u ::= unit | b | (t \u2217u) compound type ty(()) = unit ty(true) = ty(false) = bool ty(n) = int ty(r) = real 0bool = true 0int = 0 0real = 0.0\nSignatures of Arithmetic and Logical Operators: \u2297 : b1,b2 \u2192 b3 &&, ||,= : bool,bool \u2192 bool >,= : int, int \u2192 bool +,\u2212,\u2217,% : int, int \u2192 int > : real,real \u2192 bool +,\u2212,\u2217 : real,real \u2192 real\nWe have several standard probability distributions as primitive: D : t \u2192 u takes parameters in t and yields a random value in u. The names xi below only document the meaning of the parameters. Signatures of Distributions: D : (x1 : b1 \u2217 \u00b7 \u00b7 \u00b7 \u2217 xn : bn)\u2192 b Bernoulli : (success : real)\u2192 bool Binomial : (trials : int\u2217 success : real)\u2192 int Poisson : (rate : real)\u2192 int DiscreteUniform : (max : int)\u2192 int Gaussian : (mean : real \u2217 variance : real)\u2192 real Beta : (a : real \u2217b : real)\u2192 real Gamma : (shape : real \u2217 scale : real)\u2192 real\nThe expressions and values of Fun are below. Expressions are in a limited syntax akin to A-normal form, with let-expressions for sequential composition. Fun: Values and Expressions\nV ::= x | c | (V,V ) value M,N ::= expression\nV value V1 \u2297V2 arithmetic or logical operator V.1 left projection from pair V.2 right projection from pair if V then M1 else M2 conditional let x = M in N let (scope of x is N) random (D(V )) primitive distribution observe V observation\nIn the discrete case, Fun has a standard sampling semantics (cf. [41]); the formal semantics for the general case comes later. A run of a closed expression M is the process of evaluating M to a value. The evaluation of most expressions is standard, apart from sampling and observation.\nTo run random (D(V )), where V = (c1, . . . ,cn), choose a value c at random from the distribution D(c1, . . . ,cn) (independently from earlier random choices) and return c.\nTo run observe V , always return (). We say the observation is valid if and only if the value V is some zero element 0b.\nDue to the presence of sampling, different runs of the same expression may yield more than one value, with differing probabilities. Let a run be valid so long as every encountered observation is valid. The sampling semantics of an expression is the conditional probability of returning a particular value, given a valid run. Intuitively, Boolean observations are akin to assume statements in assertion-based program specifications, where runs of a program are ignored if an assumed formula is false."}, {"heading": "Example: Two Coins, Not Both Tails", "text": "let heads1 = random (Bernoulli(0.5)) in let heads2 = random (Bernoulli(0.5)) in let u = observe (heads1 || heads2) in (heads1,heads2)\nThe subexpression random (Bernoulli(0.5)) generates true or false with equal likelihood. The whole expression has four distinct runs, each with probability 1/4, corresponding to the possible combinations of Booleans heads1 and heads2. All these runs are valid, apart from the one where heads1 = false and heads2 = false (representing two tails), since observe(false||false) is not a valid observation. The sampling semantics of this expression is a probability distribution assigning probability 1/3 to the values (true, false), (false, true), and (true, true), but probability 0 to the value (false, false).\nThe sampling semantics allows us to interpret an expression as a Bayesian model. We interpret the distribution of possible return values as the prior probability of the model. The constraints on valid runs induced by observations represent new evidence or training data. The conditional probability of a value given a valid run is the posterior probability: an adjustment of the prior probability given the evidence or training data.\nThus, the expression above can be read as a Bayesian model of the problem: I toss two coins. I observe that not both are tails. What is the probability of each outcome? The uniform distribution of two Booleans represents our prior knowledge about two coins, the observe expression represents the evidence that not both are tails, and the overall sampling semantics is the posterior probability of two coins given this evidence.\nNext, we define syntactic conventions and a type system for Fun, define a formal semantics for the discrete subset of Fun, and describe further examples. Our discrete semantics is a warm up before Section 3. There we deploy measure theory to give a semantics to our full language, which allows both discrete and continuous prior distributions.\n2.2. Syntactic Conventions and Monomorphic Typing Rules. We recite our standard syntactic conventions and typing rules.\nWe identify phrases of syntax \u03c6 (such as values and expressions) up to consistent renaming of bound variables (such as x in a let-expression). Let fv(\u03c6) be the set of variables occurring free in phrase \u03c6 . Let \u03c6 {\u03c8/x} be the outcome of substituting phrase \u03c8 for each free occurrence of variable x in phrase \u03c6 . To keep our core calculus small, we treat function definitions as macros with call-by-value semantics. In particular, in examples, we write first-order non-recursive function definitions in the form let f x1 . . . xn = M, and we allow function applications f M1 . . . Mn as expressions. We consider such a function application as being a shorthand for the expression let x1 = M1 in . . . let xn = Mn in M, where the bound variables x1, . . . , xn do not occur free in M1, . . . ,\nMn. We allow expressions to be used in place of values, via insertion of suitable let-expressions. For example, (M1,M2) stands for let x1 = M1 in let x2 = M2 in (x1,x2), and M1 \u2297M2 stands for let x1 = M1 in let x2 = M2 in x1 \u2297 x2, when either M1 or M2 or both is not a value. Let M1;M2 stand for let x = M1 in M2 where x /\u2208 fv(M2). The notation t = t1 \u2217 \u00b7 \u00b7 \u00b7 \u2217 tn for tuple types means the following: when n = 0, t = unit; when n = 1, t = t1; and when n > 1, t = t1 \u2217 (t2 \u2217 \u00b7 \u00b7 \u00b7 \u2217 tn). In listings, we rely on syntactic abbreviations available in F#, such as layout conventions (to suppress in keywords) and writing tuples as M1, . . . ,Mn without enclosing parentheses.\nLet a typing environment, \u0393, be a list of the form \u03b5 ,x1 : t1, . . . ,xn : tn; we say \u0393 is well-formed and write \u0393 \u22a2 \u22c4 to mean that the variables xi are pairwise distinct. Let dom (\u0393) = {x1, . . . ,xn} if \u0393 = \u03b5 ,x1 : t1, . . . ,xn : tn. We sometimes use the notation x : t for \u0393 = \u03b5 ,x1 : t1, . . . ,xn : tn where x = x1, . . . ,xn and t = t1, . . . , tn.\nTyping Rules for Fun Expressions: \u0393 \u22a2 M : t\n(FUN VAR) \u0393 \u22a2 \u22c4 (x : t) \u2208 \u0393\n\u0393 \u22a2 x : t\n(FUN CONST) \u0393 \u22a2 \u22c4\n\u0393 \u22a2 c : ty(c)\n(FUN PAIR) \u0393 \u22a2V1 : t1 \u0393 \u22a2V2 : t2 \u0393 \u22a2 (V1,V2) : t1 \u2217 t2 (FUN OPERATOR) \u2297 : b1,b2 \u2192 b3 \u0393 \u22a2V1 : b1 \u0393 \u22a2V2 : b2\n\u0393 \u22a2V1 \u2297V2 : b3 (FUN PROJ1) \u0393 \u22a2V : t1 \u2217 t2 \u0393 \u22a2V.1 : t1 (FUN PROJ2) \u0393 \u22a2V : t1 \u2217 t2 \u0393 \u22a2V.2 : t2 (FUN IF) \u0393 \u22a2V : bool \u0393 \u22a2 M1 : t \u0393 \u22a2 M2 : t\n\u0393 \u22a2 if V then M1 else M2 : t (FUN LET)\n\u0393 \u22a2 M1 : t1 \u0393,x : t1 \u22a2 M2 : t2\n\u0393 \u22a2 let x = M1 in M2 : t2\n(FUN RANDOM) D : (x1 : b1 \u2217 \u00b7 \u00b7 \u00b7 \u2217 xn : bn)\u2192 b\n\u0393 \u22a2V : (b1 \u2217 \u00b7 \u00b7 \u00b7 \u2217bn) \u0393 \u22a2 random (D(V )) : b\n(FUN OBSERVE) \u0393 \u22a2V : b\n\u0393 \u22a2 observe V : unit\nLemma 2.1. If \u0393,x : t,\u0393\u2032 \u22a2 M : t \u2032 and \u0393 \u22a2V : t then \u0393,\u0393\u2032 \u22a2 M{V/x} : t \u2032. Proof. By induction on the derivation of \u0393,x : t,\u0393\u2032 \u22a2 M : t \u2032. Lemma 2.2. If \u0393 \u22a2 M : t then \u0393 \u22a2 \u22c4. Proof. By induction on the derivation of \u0393 \u22a2 M : T . Lemma 2.3 (Unique Types). If \u0393 \u22a2 M : t and \u0393 \u22a2 M : t \u2032 then t = t \u2032. Proof. By induction on the structure of M. The proof needs that the result types of the signatures of overloaded binary operators and of distributions are determined by the argument types.\n2.3. Formal Semantics for Bernoulli Fun. Let Bernoulli Fun be the fragment of our calculus where every random expression takes the form random (Bernoulli(c)) for some real c \u2208 (0,1), that is, a weighted Boolean choice returning true with probability c, and false with probability 1\u2212c. We show that a closed well-typed expression M induces conditional probabilities PM [value =V | valid], the probability that the value of a valid run of M is V .\nFor this calculus, we inductively define an operational semantics, M \u2192p M\u2032, meaning that expression M takes a step to M\u2032 with probability p. Reduction Relation: M \u2192p M\u2032 where p \u2208 (0,1] V1 \u2297V2 \u21921 \u2297(c1,c2) (V1,V2).1 \u21921 V1 (V1,V2).2 \u21921 V2 if true then M1 else M2 \u21921 M1 if false then M1 else M2 \u21921 M2 let x =V in M \u21921 M{V/x} R[M]\u2192p R[M\u2032] if M \u2192p M\u2032 for reduction context R given by R ::= [] | let x =R in M random (Bernoulli(c))\u2192c true random (Bernoulli(c))\u21921\u2212c false observe V \u21921 ()\nSince there is no recursion or unbounded iteration in Bernoulli Fun, there are no non-terminating reduction sequences M1 \u2192p1 . . .Mn \u2192pn . . . .\nMoreover, we can prove standard preservation and progress lemmas.\nLemma 2.4 (Preservation). If \u0393 \u22a2 M : t and M \u2192p M\u2032 then \u0393 \u22a2 M\u2032 : t. Proof. By induction on the derivation of M \u2192p M\u2032. Lemma 2.5 (Progress). If \u03b5 \u22a2M : t and M is not a value then there are p and M\u2032 such that M \u2192p M\u2032. Proof. By induction on the structure of M.\nLemma 2.6 (Determinism). If M \u2192p M\u2032 and M \u2192p\u2032 M\u2032 then p = p\u2032. Proof. By induction on the structure of M.\nLemma 2.7 (Probability). If \u03b5 \u22a2 M : t then \u03a3{(p,N)|M\u2192pN}p = 1. Proof. By induction on the structure of M.\nWe consider a fixed expression M such that \u03b5 \u22a2 M : t. Let the space \u2126 be the set of all runs of M, where a run is a sequence \u03c9 = (M1, . . . ,Mn+1) for n \u2265 0 and p1, . . . , pn such that M = M1 \u2192p1 \u00b7 \u00b7 \u00b7 \u2192pn Mn+1 =V ; we define the functions value(\u03c9) = V and prob(\u03c9) = 1p1 . . . pn, and we define the predicate valid(\u03c9) to hold if and only if whenever M j = R[observe V ] then V = 0b for some zero element 0b. Since M is well-typed, is normalizing, and samples only from Bernoulli distributions, \u2126 is finite. Let \u03b1 ,\u03b2 \u2286 \u2126 range over events, and let probability PM [\u03b1 ] = \u2211\u03c9\u2208\u03b1 prob(\u03c9). Below, we write P [\u00b7] for PM [\u00b7] when M is clear from the context. Proposition 2.8. The function P [\u03b1 ] forms a probability distribution, that is, (1) we have P [\u03b1 ] \u2265 0 for all \u03b1 , (2) P [\u2126] = 1, and (3) P [\u03b1 \u222a\u03b2 ] = P [\u03b1 ]+P [\u03b2 ] if \u03b1 \u2229\u03b2 =\u2205. Proof. Item (1) follows from the fact that p\u2265 0 whenever M \u2192p N. Item (2) follows from Lemma 2.7, Lemma 2.4, and termination. Item (3) is immediate from the definition.\nTo give the semantics of our expression M we first define the following probabilities and events. Given a value V , value =V is the event value\u22121(V ) = {\u03c9 | value(\u03c9) =V}. Hence, P [value =V ] is the prior probability that a run of M terminates with V . We let the event valid = {\u03c9 \u2208 \u2126 | valid(\u03c9)}; hence, P [valid] is the probability that a run is valid.\nIf P [\u03b2 ] 6= 0, the conditional probability of \u03b1 given \u03b2 is\nP [\u03b1 | \u03b2 ], P [\u03b1 \u2229\u03b2 ] P [\u03b2 ]\nThe semantics of a program M is given by the conditional probability distribution\nPM [value =V | valid] = PM\n[ (value\u22121(V ))\u2229 valid ]\nPM [valid] ,\nthe conditional probability that a run of M returns V given a valid run, also known as the posterior probability.\nThe conditional probability PM [value =V | valid] is only defined when PM [valid] is not zero. For pathological choices of M such as observe false or let x = 3 in observe x there are no valid runs, so P [valid] = 0, and P [value =V | valid] is undefined. (This is an occasional problem in practice; Bayesian inference engines such as Infer.NET fail in this situation with a zero-probability exception.)\n2.4. An Example in Bernoulli Fun. The expression below encodes the question: 1% of a population have a disease. 80% of subjects with the disease test positive, and 9.6% without the disease also test positive. If a subject is positive, what are the odds they have the disease? [54]"}, {"heading": "Epidemiology: Odds of Disease Given Positive Test", "text": "let has disease = random (Bernoulli(0.01)) let positive result = if has disease\nthen random (Bernoulli(0.8)) else random (Bernoulli(0.096))\nobserve positive result has disease\nFor this expression, we have \u2126= {\u03c9tt ,\u03c9t f ,\u03c9 f t ,\u03c9 f f } where each run \u03c9c1c2 corresponds to the choice has disease = c1 and positive result = c2. The probability of each run is: \u2022 prob(\u03c9tt) = 0.01\u00d70.8 = 0.008 (true positive) \u2022 prob(\u03c9t f ) = 0.01\u00d70.2 = 0.002 (false negative) \u2022 prob(\u03c9 f t) = 0.99\u00d70.096 = 0.09504 (false positive) \u2022 prob(\u03c9 f f ) = 0.99\u00d70.904 = 0.89496 (true negative) The semantics P [value = true | valid] here is the conditional probability of having the disease, given that the test is positive.\nHere P [valid] = prob(\u03c9 f t) + prob(\u03c9tt) and P [value = true\u2229 valid] = prob(\u03c9tt), so we have P [value = true | valid] = 0.008/(0.008+0.09504) = 0.07764. So the likelihood of disease given a positive test is just 7.8%, less than one might think.\nThis example illustrates inference on an explicit enumeration of the runs in \u2126. The size of \u2126 is exponential in the number of random expressions, so although illustrative, this style of inference does not scale up. As we explain in Section 4, our implementation strategy is to translate Fun\nexpressions to the input language of an existing inference engine based on factor graphs, permitting efficient approximate inference."}, {"heading": "3. SEMANTICS AS MEASURE TRANSFORMERS", "text": "We cannot generalize the operational semantics of the previous section to continuous distributions, such as random (Gaussian(1,1)), since the probability of any particular sample is zero. A further difficulty is the need to observe events with probability zero, a common situation in machine learning. For example, consider the naive Bayesian classifier, a common, simple probabilistic model. In the training phase, it is given objects together with their classes and the values of their pertinent features. Below, we show the training for a single feature: the weight of the object. The zero probability events are weight measurements, assumed to be normally distributed around the class mean. The outcome of the training is the posterior weight distributions for the different classes."}, {"heading": "Naive Bayesian Classifier, Single Feature Training:", "text": "let wPrior() = random (Gaussian(0.5,1.0)) let Glass,Watch,Plate = wPrior(),wPrior(),wPrior() let weight objClass objWeight = observe (objWeight\u2212(random (Gaussian(objClass,1.0)))) weight Glass .18; weight Glass .21 weight Watch .11; weight Watch .073 weight Plate .23; weight Plate .45 Watch,Glass,Plate\nAbove, the call to weight Glass .18 modifies the distribution of the variable Glass. The example uses observe (x\u2212y) to denote that the difference between the weights x and y is 0. The reason for not instead writing x=y is that conditioning on events of zero probability without specifying the random variable they are drawn from is not in general well-defined, cf. Borel\u2019s paradox [21]. To avoid this issue, we instead observe the random variable x\u2212y of type real, at the value 0. (Our compiler does permit the expression observe (x=y), as sugar for observe (x\u2212y)).\nTo give a formal semantics to such observations, as well as to mixtures of continuous and discrete distributions, we turn to measure theory, following standard sources [6, 48]. Two basic concepts are measurable spaces and measures. A measurable space is a set of values equipped with a collection of measurable subsets; these measurable sets generalize the events of discrete probability. A measure is a function that assigns a positive size to each measurable set; finite measures, which assign a finite size to each measurable set, generalize probability distributions.\nWe work in the usual mathematical metalanguage of sets and total functions. To machine-check our theory, one might build on a recent formalization of measure theory and Lebesgue integration in higher-order logic [35].\n3.1. Types as Measurable Spaces. In the remainder of the paper, we let \u2126 range over sets of possible outcomes; in our semantics \u2126 will range over B= {true, false}, Z, R, and finite Cartesian products of these sets. A \u03c3 -algebra over \u2126 is a set M \u2286 P(\u2126) which (1) contains \u2205 and \u2126, and (2) is closed under complement and countable union and intersection. A measurable space is a pair (\u2126,M) where M is a \u03c3 -algebra over \u2126; the elements of M are called measurable sets. We use the notation \u03c3\u2126(S), when S \u2286 P(\u2126), for the smallest \u03c3 -algebra over \u2126 that is a superset of S; we may omit \u2126 when it is clear from context. Given two measurable spaces (\u21261,M1) and (\u21262,M2), we\ncan compute their product as (\u21261,M1)\u00d7 (\u21262,M2), (\u21261 \u00d7\u21262,\u03c3\u21261\u00d7\u21262{A\u00d7B | A \u2208M1,B \u2208M2}) If (\u2126,M) and (\u2126\u2032,M\u2032) are measurable spaces, then the function f : \u2126 \u2192 \u2126\u2032 is measurable if and only if for all A \u2208 M\u2032, f\u22121(A) \u2208 M, where the inverse image f\u22121 : P(\u2126\u2032) \u2192 P(\u2126) is given by f\u22121(A), {\u03c9 \u2208 \u2126 | f (\u03c9) \u2208 A}. We write f\u22121(x) for f\u22121({x}) when x \u2208 \u2126\u2032.\nWe give each first-order type t an interpretation as a measurable space T[[t]] , (Vt ,Mt) below. We identify closed values of type t with elements of Vt , and write () for \u2205, the unit value."}, {"heading": "Semantics of Types as Measurable Spaces:", "text": "T[[unit]] = ({()},{{()},\u2205}) T[[bool]] = (B,P(B)) T[[int]] = (Z,P(Z)) T[[real]] = (R,\u03c3R({[a,b] | a,b \u2208 R})) T[[t \u2217u]] = T[[t]]\u00d7T[[u]]\nThe set \u03c3R({[a,b] | a,b \u2208 R}) in the definition of T[[real]] is the Borel \u03c3 -algebra on the real line, which is the smallest \u03c3 -algebra containing all closed (and open) intervals. Below, we write f : t \u2192 u to denote that f : Vt \u2192 Vu is measurable, that is, that f\u22121(B) \u2208Mt for all B \u2208Mu.\n3.2. Finite Measures. A measure \u00b5 on a measurable space (\u2126,M) is a function M\u2192 R+\u222a{\u221e} that is countably additive, that is, \u00b5(\u2205) = 0 and if the sets A0,A1, . . . \u2208M are pairwise disjoint, then \u00b5(\u222aiAi) = \u2211i \u00b5(Ai). We write |\u00b5 |, \u00b5(\u2126). A finite measure \u00b5 is a measure \u00b5 satisfying |\u00b5 | 6= \u221e; a \u03c3 -finite measure \u00b5 is a measure such that \u2126 = A0 \u222aA1 \u222a . . . with \u00b5(Ai) 6= \u221e. All the measures we consider in this paper are \u03c3 -finite.\nLet M t be the set of finite measures on the measurable space T[[t]]. Additionally, a finite measure \u00b5 on (\u2126,M) is a probability measure when |\u00b5 | = 1. We do not restrict M t to just probability measures, although one can obtain a probability measure from a non-zero finite measure by normalizing with 1/|\u00b5 |. We make use of the following constructions on measures. \u2022 Given a function f : t \u2192 u and a measure \u00b5 \u2208 M t, there is a measure \u00b5 f\u22121 \u2208 M u given by (\u00b5 f\u22121)(B), \u00b5( f\u22121(B)). \u2022 Given a finite measure \u00b5 and a measurable set B, we let \u00b5 |B(A) , \u00b5(A\u2229B) be the restriction of \u00b5 to B. \u2022 We can add two measures on the same set as (\u00b51 +\u00b52)(A), \u00b51(A)+\u00b52(A). \u2022 We can multiply a measure by a positive constant as (r \u00b7\u00b5)(A), r \u00b7\u00b5(A). \u2022 The (independent) product (\u00b51 \u00d7\u00b52) of two (\u03c3 -finite) measures is also definable [6, Sec. 18], and\nsatisfies (\u00b51 \u00d7\u00b52)(A\u00d7B) = \u00b51(A) \u00b7\u00b52(B). \u2022 If \u00b5i is a measure on ti for i \u2208 {1,2}, we let the disjoint sum \u00b51 \u2295 \u00b52 be the measure on t1 + t2\ndefined as A1 \u228eA2 7\u2192 \u00b51(A1)+\u00b52(A2). \u2022 Given a measure \u00b5 on the measurable space T[[t]], a measurable set A \u2208Mt and a function f : t \u2192\nreal, we write \u222b A f d\u00b5 or equivalently \u222b A f (x)d\u00b5(x) for standard (Lebesgue) integration. This integration is always well-defined if \u00b5 is finite and f is non-negative and bounded from above. \u2022 Given t, we let \u03bbt be the \u201cstandard\u201d measure on T[[t]] built from independent products and disjoint sums of the Lebesgue measure on real and the counting measure on discrete b. We often omit t when it is clear from the context. (We also use \u03bb -notation for functions, but we trust any ambiguity is easily resolved.) \u2022 Given a measure \u00b5 on a measurable space T[[t]] we call a function \u00b5\u0307 : t \u2192 real a density for \u00b5 iff \u00b5(A) = \u222b\nA \u00b5\u0307 d\u03bb for all A \u2208M.\nStandard Distributions. Given a closed well-typed Fun expression random (D(V )) of base type b, we define a corresponding finite measure \u00b5D(V ) on measurable space T[[b]], via its density D(V ) = \u00b5\u0307D(V ). In the discrete case, we first define the probability mass function, written D(V ) c, and then define the measure \u00b5D(V ) as a summation. Masses D(V ) c and Measures \u00b5D(V ) for Discrete Probability Distributions:\nBernoulli(p) true , p if 0 \u2264 p \u2264 1, 0 otherwise Bernoulli(p) false , 1\u2212 p if 0 \u2264 p \u2264 1, 0 otherwise Binomial(n, p) i ,\n( i n ) pi/n! if 0 \u2264 p \u2264 1, 0 otherwise DiscreteUniform(m) i , 1/m if 0 \u2264 i < m, 0 otherwise Poisson(l) n , e\u2212lln/n! if l,n \u2265 0, 0 otherwise \u00b5D(V )(A), \u2211i D(V ) ci if A = \u22c3 i{ci} for pairwise disjoint ci\nIn the continuous case, we first define the probability density function D(V ) r and then define the measure \u00b5D(V ) as an integral. Below, we write G for the standard Gamma function, which on naturals n satisfies G(n) = (n\u22121)!. Densities D(V ) r and Measures \u00b5D(V ) for Continuous Probability Distributions:\nGaussian(m,v) r , e\u2212(r\u2212m) 2/2v/ \u221a 2\u03c0v if v > 0, 0 otherwise Gamma(s, p) r , rs\u22121e\u2212pr ps/G(s) if r,s, p > 0, 0 otherwise Beta(a,b) r , ra\u22121(1\u2212 r)b\u22121G(a+b)/(G(a)G(b)) if a,b > 0 and 0 \u2264 r \u2264 1, 0 otherwise \u00b5D(V )(A), \u222b A D(V )d\u03bb where \u03bb is the Lebesgue measure on R\nThe Dirac \u03b4 measure is defined on the measurable space T[[b]] for each base type b, and is given by \u03b4c(A), 1 if c \u2208 A, 0 otherwise.\nConditional density. The notion of density can be generalized as follows, yielding an unnormalized counterpart to conditional probability. Given a measurable function p : t \u2192 u, we consider two families of events on t. Firstly, events Ec , {x \u2208 Vt | p(x) = c} where c ranges over Vu. Secondly, rectangles Rd , {x \u2208 Vt | x \u2264 d} where d ranges over Vt and \u2264 is the coordinate-wise partial order (that on pair types satisfies (a,b) \u2264 (c,d) iff a \u2264 c and b \u2264 d, that on int and real is the standard ordering, and that only relates equal booleans).\nGiven a finite measure \u00b5 on T[[t]] and c \u2208 Vu, we let Fc : t \u2192 R be defined by the limit below (following [13])\nFc(d), lim i\u2192\u221e \u00b5(Rd \u2229 p\u22121(Bi))/\u03bbu(Bi) (3.1) if the limit exists and is the same for all sequences {Bi} of closed sets converging regularly to c. On points d where no unique limit exists, we let\nFc(d), inf{Fc(d\u2032) | d \u2264 d\u2032\u2227d 6= d\u2032\u2227Fc(d\u2032) defined} where we let inf \u2205 , \u221e. If Fc is bounded, we define D\u00b5 [\u00b7||p = c] \u2208 R (the \u00b5-density at Ec) as the finite measure on T[[t]] with (unnormalized) cumulative distribution function Fc, that is, D\u00b5 [Rd ||p = c] = Fc(d). (If Fc is not bounded, it is not the distribution function of a finite measure.)\nAs examples of this definition, when u is discrete we have that D\u00b5 [A||p = c] = \u00b5(A \u2229 {x | p(x) = c}), so discrete density amounts to filtering. In the continuous case, if Vt = R\u00d7Rk, p =\n\u03bb (x,y).(x\u2212 c) and \u00b5 has a continuous density \u00b5\u0307 then\nFc(a,b) = lim i\u2192\u221e \u00b5(R(a,b)\u2229 p\u22121(Bi)) \u03bbR(Bi)\n= lim i\u2192\u221e\n\u222b\n(R(a,b)\u2229p\u22121(Bi))\u00b5\u0307(x,y)d\u03bbt(x,y)\n\u03bbR(Bi)\n= \u222b\n{y|(c,y)\u2208R(a,b)} \u00b5\u0307(c,y)d\u03bb Rk (y) when a 6= c by continuity.\nWhen a = c the limit may not be unique, in which case we have\nFc(c,b) = inf{Fc(d\u2032) | (c,b) \u2264 d\u2032}\n= \u222b\n{y|(a,y)\u2208R(a,b)} \u00b5\u0307(a,y)d\u03bbRk (y) by monotonicity of Fc and continuity.\nWe then get\nD\u00b5 [A||p = c] = \u222b\n{y|(c,y)\u2208A} \u00b5\u0307(c,y)d\u03bbRk (y). (3.2)\nOne case when conditional density may not be defined is when the conditioning event is at a discontinuity of the density function: let t = real \u2217 real, p(x,y) = x, and \u00b5\u0307(x,y) = 1 if 0 \u2264 x,y \u2264 1, otherwise 0. Then F1(x,y) = 0 if x < 1 or y \u2264 0, and otherwise the limit (3.1) is not unique. Thus F1(1,0) = \u221e, so F1 is not bounded and D\u00b5 [\u00b7||p = 1] is undefined. For more examples, see Section 3.5.\nThere exists a more declarative approach to D\u00b5 . For A \u2208Mt , we let \u03bdA(B) = \u00b5(A\u2229 p\u22121(B)); this measure is said to be absolutely continuous (wrt. \u03bbu) if \u03bdA(B) = 0 whenever \u03bbu(B) = 0. If \u00b5 is outer regular, i.e. \u00b5(A) = inf{\u00b5(G) | A \u2282 G,G open} for all A, and \u03bdA is absolutely continuous, the defining limit (3.1) exists almost everywhere [13], that is, there is a set C with \u00b5(C) = 0 such that c \u2208 C if Fc(d) is undefined. Then, D\u00b5 [A||p = c] is a version of the Radon-Nikodym derivative of \u03bdA(B) (wrt. \u03bbu). For all B \u2208Mu, conditional density thus satisfies the equation\n\u00b5(A\u2229 p\u22121(B)) = \u222b\nB D\u00b5 [A||p = x] d\u03bbu(x). (3.3)\nThe existence of a family of finite measures D\u00b5 [ \u00b7 ||p = c] on T[[t]] satisfying equation (3.3) above is guaranteed in certain situations, e.g., when \u00b5 p\u22121 has density d at c we may take D\u00b5 as a version of the regular conditional probability \u00b5 [\u00b7 | p = c] (see for instance [6, Theorem 33.3]) scaled by d. However, if \u00b5(p\u22121(c)) = 0 the value of D\u00b5 [A||p = c] may not be uniquely defined, since two versions of D\u00b5 [ \u00b7 ||p = \u00b7 ] may differ on a null set. In order to avoid this ambiguity we have given an explicit construction that works for many useful cases.\n3.3. Measure Transformers. We will now recast some standard theorems of measure theory as a library of combinators, that we will later use to give semantics to probabilistic languages. A measure transformer is a partial function from finite measures to finite measures. We let t \u2740 u be the set of partial functions M t \u2192 M u. We use the combinators on measure transformers listed below in the formal semantics of our languages. The definitions of these combinators occupy the remainder of this section. We recall that \u00b5 denotes a measure and A a measurable set, of appropriate types."}, {"heading": "Measure Transformer Combinators:", "text": "pure \u2208 (t \u2192 u)\u2192 (t \u2740 u) >>> \u2208 (t1 \u2740 t2)\u2192 (t2 \u2740 t3)\u2192 (t1 \u2740 t3) choose \u2208 (t \u2192 bool)\u2192 (t \u2740 u)\u2192 (t \u2740 u)\u2192 (t \u2740 u) extend \u2208 (t \u2192 M u)\u2192 (t \u2740 (t \u2217u)) observe \u2208 (t \u2192 b)\u2192 (t \u2740 t)\nLifting a Function to a Measure Transformer. To lift a pure measurable function to a measure transformer, we use the combinator pure \u2208 (t \u2192 u) \u2192 (t \u2740 u). Given f : t \u2192 u, we let pure f \u00b5 A , \u00b5 f\u22121(A), where \u00b5 is a measure on T[[t]] and A is a measurable set from T[[u]] (cf. [6, Eqn 13.7]).\nSequential Composition of Measure Transformers. To sequentially compose two measure transformers we use standard function composition, defining >>>\u2208 (t1 \u2740 t2)\u2192 (t2 \u2740 t3)\u2192 (t1 \u2740 t3) as T >>>U ,U \u25e6T .\nConditional Choice between two Measure Transformers. The combinator choose \u2208 (t \u2192 bool)\u2192 (t \u2740 u) \u2192 (t \u2740 u) \u2192 (t \u2740 u) makes a choice between two measure transformers, parametric on a predicate p. Intuitively, choose p TT TF \u00b5 first splits Vt into two sets depending on whether or not p is true. For each equivalence class, we then run the corresponding measure transformer on \u00b5 restricted to the class. Finally, the resulting finite measures are added together, yielding a finite measure. If p\u22121(true) = B we let choose p TT TF \u00b5 A = TT(\u00b5 |B)(A)+TF(\u00b5 |Vt\\B)(A).\nExtending Domain of a Measure. The combinator extend \u2208 (t \u2192 M u)\u2192 (t \u2740 (t \u2217u)) extends the domain of a measure using a function yielding measures. It is reminiscent of creating a dependent pair, since the distribution of the second component depends on the value of the first. For extend m to be defined, we require that for every A \u2208Mu, the function fA , \u03bbx.m(x)(A) is measurable, nonnegative and bounded from above. In particular, this holds for all A if m is measurable and m(x) always is a (sub-)probability distribution, which is always the case in our semantics for Fun. We let extend m \u00b5 AB , \u222b\nVt m(x)({y | (x,y) \u2208 AB})d\u00b5(x), where we integrate over the first component (call it x) with respect to the measure \u00b5 , and the integrand is the measure under m(x) of the set {y | (x,y) \u2208 AB} for each x (cf. [6, Ex. 18.20]).\nObservation as a Measure Transformer. The combinator observe \u2208 (t \u2192 b)\u2192 (t \u2740 t) conditions a measure over T[[t]] on the event that an indicator function of type t \u2192 b is zero. Here observation is unnormalized conditioning of a measure on an event. If defined, we let observe p \u00b5 A , D\u00b5 [A||p = 0b]. As an example, if p : t \u2192 bool is a (measurable) predicate on values of type t, we have observe p \u00b5 A = \u00b5(A\u2229{x | p(x) = true}). Notice that observe p \u00b5 A can be greater than \u00b5(A) when p : t \u2192 real (cf. the naive Bayesian classifier on page 9), for which reason we cannot restrict ourselves to (sub-)probability measures. For examples, see Equation (3.2) and Section 3.5.\n3.4. Measure Transformer Semantics of Fun. In order to give a compositional denotational semantics of Fun programs, we give a semantics to open programs, later to be placed in some closing context. Since observations change the distributions of program variables, we may draw a parallel to while programs. There, a program can be given a denotation as a function from variable valuations to a return value and a variable valuation. Similarly, we give semantics to an open Fun term by mapping a measure over assignments to the term\u2019s free variables to a joint measure of the term\u2019s return value and assignments to its free variables. This choice is a generalization of the (discrete) semantics of pWHILE [4]. This contrasts with Ramsey and Pfeffer [46], where the semantics of an open program takes a variable valuation and returns a (monadic computation yielding a) distribution of return values.\nFirst, we define a data structure for an evaluation environment assigning values to variable names, and corresponding operations. Given an environment \u0393 = x1:t1, . . . ,xn:tn, we let S\u3008\u0393\u3009 be the set of states, or finite maps s = {x1 7\u2192 c1, . . . ,xn 7\u2192 cn} such that for all i = 1, . . . ,n, ty(ci) = ti. We let T[[S\u3008\u0393\u3009]] , T[[unit\u2217 t1 \u2217 \u00b7 \u00b7 \u00b7 \u2217 tn]] be the measurable space of states in S\u3008\u0393\u3009. We define dom(s) , {x1, . . . ,xn}. We define the following operators."}, {"heading": "Auxiliary Operations on States and Pairs:", "text": "add x (s,c), s\u222a{x 7\u2192 c} if ty(c) = t and x /\u2208 dom(s), s otherwise. lookup x s , s(x) if x \u2208 dom(s), () otherwise. drop X s , {(x 7\u2192 c) \u2208 s | x /\u2208 X} fst((x,y)) , x snd((x,y)) , y\nWe write s|X for drop (dom(s) \\X) s. We apply these combinators to give a semantics to Fun programs as measure transformers. We assume that all bound variables in a program are different from the free variables and each other. Below, V[[V ]] s gives the valuation of V in state s, and A[[M]] gives the measure transformer denoted by M."}, {"heading": "Measure Transformer Semantics of Fun:", "text": "V[[x]] s , lookup x s V[[c]] s , c V[[(V1,V2)]] s , (V[[V1]] s,V[[V2]] s)\nA[[V ]], pure \u03bb s.(s,V[[V ]] s) A[[V1 \u2297V2]], pure \u03bb s.(s,\u2297(V[[V1]] s,V[[V2]] s)) A[[V.1]] , pure \u03bb s.(s,fst(V[[V ]] s)) A[[V.2]] , pure \u03bb s.(s,snd(V[[V ]] s))\nA[[if V then M else N]], choose (\u03bb s.V[[V ]] s) A[[M]] A[[N]] A[[random (D(V ))]], extend \u03bb s.\u00b5D(V[[V ]] s) A[[observe V ]], (observe \u03bb s.V[[V ]] s)>>> pure \u03bb s.(s,()) A[[let x = M in N]],A[[M]]>>> pure (add x) >>>A[[N]]>>> pure \u03bb (s,y).((drop {x} s),y)\nA value expression V returns the valuation of V in the current state, which is left unchanged. Similarly, binary operations and projections have a deterministic meaning given the current state. An if V expression runs the measure transformer given by the then branch on the states where V evaluates true, and the transformer given by the else branch on all other states, using the combinator choose. A primitive distribution random (D(V )) extends the state measure with a value drawn from the distribution D, with parameters V depending on the current state. An observation observe V modifies the current measure by restricting it to states where V is zero. It is implemented with the observe\ncombinator, and it always returns the unit value. The expression let x = M in N intuitively first runs M and binds its return value to x using add. After running N, the binding is discarded using drop.\nLemma 3.1. If s : S\u3008\u0393\u3009 and \u0393 \u22a2V : t then V[[V ]] s \u2208 Vt . Lemma 3.2. If \u0393 \u22a2 M : t then A[[M]] \u2208 S\u3008\u0393\u3009\u2740 (S\u3008\u0393\u3009 \u2217 t).\nThe measure transformer semantics of Fun is hard to use directly, except in the case of Bernoulli Fun where they can be directly implemented: a naive implementation of M\u3008S\u3008\u0393\u3009\u3009 is as a map assigning a probability to each possible variable valuation. If there are N variables, each sampled from a Bernoulli distribution, in the worst case there are 2N paths to be explored in the computation, each of which corresponds to a variable valuation. Our direct implementation of the measure transformer semantics, described in the technical report version of our paper [8], explicitly constructs the valuation. It works fine for small examples but would blow up on large datasets. In this simple case, the measure transformer semantics of closed programs also coincides with the sampling semantics.\nTheorem 3.3. Suppose \u03b5 \u22a2 M : t for some M in Bernoulli Fun. If \u00b5 =A[[M]] \u03b4() and \u03b5 \u22a2V : t then PM [value =V | valid] = \u00b5({((),V )})/|\u00b5 |. Proof. We add a construct to give a semantics to open Bernoulli Fun expressions. Let init(M,\u00b5) stand for M starting in an initial probability measure \u00b5 on S\u3008\u0393\u3009. Let init(M,\u00b5)\u2192ps M{V1/x1 \u00b7 \u00b7 \u00b7Vn/xn} when s= {xi 7\u2192Vi | i= 1..n} \u2208 S\u3008\u0393\u3009 and ps = \u00b5({s\u2032 | s\u2032|fv(M) = s|fv(M)}). In particular, if M is closed, then init(M,\u03b4())\u21921 M, so init(M,\u03b4()) has the same traces as M but for an additional (valid) initial step.\nBy induction on the derivation of \u0393 \u22a2 M : t, we prove that if \u0393 \u22a2 M : t and \u03b5 \u22a2 V : t and \u00b5 \u2208 M\u3008S\u3008\u0393\u3009\u3009, then \u03bd(S\u3008\u0393\u3009\u00d7 {V}) = PN [valid\u2229 value =V ] and \u03bd(S\u3008\u0393\u3009 \u00d7Vt) = PN [valid], where \u03bd = A[[M]] \u00b5 and N = init(M,\u00b5).\nThen, for closed M we get PM [value =V | valid] = PM [valid\u2229 value =V ]/PM [valid] = \u03bd({((),V )})/\u03bd({()}\u00d7Vt).\n3.5. Discussion of the Semantics. In this section we discuss some small examples that are illustrative of the semantics of the observe primitive. The first example highlights the difference between discrete observations and observations on continuous types.\nThe subsequent examples contrast our definition of observe with some alternative definitions. The second example deals with the definition of discrete observations, that is shown to coincide with the filtering semantics of Bernoulli Fun, unlike two alternative semantics. In the third example, we treat continuous observations, showing that distributing an observation into both branches of an if statement yields the same result, in contrast to an alternative semantics of observations as computing (normalized) conditional probability distributions.\nIn the fourth example, we show an example of model comparison that depends on the unnormalized nature of observations. In the fifth example, we show a well-typed Fun program with an observation (of a derived random variable) that failed to be well-defined in the original semantics of observation.\nDiscrete versus continuous observations. As an example to highlight the difference between continuous and discrete observations, we first consider the following program, which observes that a normally distributed random variable is zero. The resulting distribution of the return value x is a point mass at 0.0, as expected. The measure of {0.0} in this distribution is Gaussian(0.0,1.0) 0.0 \u2248 0.4."}, {"heading": "Continuous Observation:", "text": "let x = random (Gaussian(0.0, 1.0)) in let = observe x in x\nThe second program instead observes that a Boolean variable is true. This has zero probability of occurring, and since the Boolean type is discrete, the resulting measure is the zero measure. Discrete Observation:\nlet x = random (Gaussian(0.0, 1.0)) in let b = (x==0.0) in let = observe b in x\nThese examples show the need for observations at real type, as well as at type bool. (This also clearly distinguishes observe from assume in assertional programming.)\nDiscrete Observations amount to filtering. A consequence of Theorem 3.3 is that our measure transformer semantics is a generalization of the sampling semantics for discrete probabilities. For this theorem to hold, it is critical that observe denotes unnormalized conditioning (filtering). Otherwise programs that perform observations inside the branches of conditional expressions would have undesired semantics. As the following example shows, the two program fragments observe (x=y ) and if x then observe (y=true) else observe (y=false) would have different measure transformer semantics although they have the same sampling semantics.\nSimple Conditional Expression: Mif let x = random (Bernoulli(0.5)) let y = random (Bernoulli(0.1)) if x then observe (y=true) else observe (y=false) y\nIn the sampling semantics, the two valid runs are when x and y are both true (with probability 0.05), and both false (with probability 0.45), so we have P [true | valid] = 0.1 and P [false | valid] = 0.9.\nIf, instead of the unnormalized definition observe p \u00b5 A = \u00b5(A\u2229{x | p(x)}), we had either of the normalizing definitions\nobserve p \u00b5 A = \u00b5(A\u2229{x | p(x)}) \u00b5({x | p(x)}) or |\u00b5 | \u00b5(A\u2229{x | p(x)})\n\u00b5({x | p(x)}) then A[[Mif]] \u03b4() {true}=A[[Mif]] \u03b4() {false}, which would invalidate the theorem.\nLet M\u2032 = Mif with observe (x = y) substituted for the conditional expression. With the actual or either of the flawed definitions of observe we have A[[M\u2032]] \u03b4() {true}= (A[[M\u2032]] \u03b4() {false})/9.\nContinuous Observations are not normalizing. As in the discrete case, continuous observations do not renormalize the resulting measure. In the program below, the variables x and y are independent: observing x at a given value amounts to scaling the measure of y by some fixed amount. Simple Continuous Observation: Mobs let x = random (Gaussian(0.0, 1.0)) let y = random (Gaussian(0.0, 1.0)) observe (x\u22121.0) y\nThe resulting distribution \u00b5y of y is the normal distribution, scaled by a factor Gaussian(0.0,1.0) 1.0\u2248 0.24. In particular, \u00b5y({y \u2208R : y >\u22121})/|\u00b5y| \u2248 0.16. Below, we let \u03bd be the joint distribution of x and y before the observation.\nIf we replace the observation by an if statement that performs the same observation in each branch, the resulting distribution is unchanged. Let M\u2032 = Mobs with the conditional expression N :=if x+y>0 then observe (x\u22121.0) else observe (x\u22121.0) substituted for observe (x\u22121.0). Let A= {(x,y) \u2208R2 : x+y> 0} and B=R2\\A. We have A[[N]]\u03bd = choose p T T \u03bd = T (\u03bd |A)+T (\u03bd |B) where p= \u03bbx,y.(x+y> 0) and T = observe \u03bbx, .(x\u22121). Since the definition of observe \u03bbx, .(x\u2212 1)\u00b5 =D\u00b5 [\u00b7||x = 1] is linear in \u00b5 (where defined) and \u03bd = \u03bd |A +\u03bd |B, we have A[[Mobs]] =A[[M\u2032]].\nHowever, if observations always yielded probability distributions, and if statements reweighted the result of each branch by the probability that that branch was taken, the above equality would not hold. In M\u2032, the branch condition x+y>0 is true with probability 0.5 a priori. This reweighting semantics would after the observation of x=1 give the same probability to 1+y>0 (the left branch being taken) and 1+y<0 (the right branch being taken). In contrast, the original program Mobs yields P [1+y<0]\u2248 0.16.\nMedical trial. As another example, let us consider a simple Bayesian evaluation of a medical trial [37]. We assume a trial group of nTrial persons, of which cTrial were healthy at the end of the trial, and a control group of nControl persons, of which cControl were healthy at the end of the trial. Below, Beta(1.0,1.0) is the uniform distribution on the interval [0.0,1.0]. We return the posterior distributions of the likelihood that a member of the trial group (pTrial) and a member of the control group (pControl) is healthy at the end of the trial."}, {"heading": "Medical Trial:", "text": "let medicalTrial nTrial nControl cTrial cControl = let pTrial = random(Beta(1.0,1.0)) observe (cTrial == random (Binomial(nTrial,pTrial))); let pControl = random(Beta(1.0,1.0)) observe (cControl == random (Binomial(nControl,pControl))); pTrial, pControl\nWe can then compare this model to one where the treatment is ineffective, that is, where the members of the trial group and the control group have the same probability of becoming healthy. Also here we give a uniform prior to the probability that the treatment is effective; the posterior distribution of this variable will depend on the Bayesian evidence for the different models, that is, the ratio between the probabilities of the observed outcome in the two models. This way of performing model comparison critically depends on the unnormalized nature of discrete observations as filtering."}, {"heading": "Model Selection:", "text": "let modelSelection nTrial nControl cTrial cControl = let pEffective = random(Beta(1.0,1.0)) if random(Bernoulli(pEffective)) then\nmedicalTrial nTrial nControl cTrial cControl ()\nelse let pAll = random(Beta(1.0,1.0)) observe (cTrial == random (Binomial(nTrial,pAll))) observe (cControl == random (Binomial(nControl,pAll)))\npEffective\nObservation of Derived Variable. The following example, due to Chung-Chieh Shan, highlighted regularity problems with our original definition of observation [8]. Observation of Derived Variable:\nlet x = random (Beta(1.0, 1.0)) in let y = x \u2212 0.5 in observe y; x.\nIntuitively, this program should yield a point mass at x=0.5, y=0. In our semantics, if \u00b5 is the measure before the observation (when starting from \u03b4()) we have\nF0(x,y) = 1 if x > 0.5 and y > 0\nF0(x,y) = 0 if x < 0.5 or y < 0\nOtherwise, we have F0(x,y) = inf{F0(x\u2032,y\u2032) | x\u2032 \u2265 x\u2227y\u2032 \u2265 y}= 1 so D\u00b5 [A||y = 0] = 1 iff (0.5,0) \u2208A and otherwise 0; in particular we have D\u00b5 [x = 0.5||y = 0] = 1.\nThe original definition of observation simply applied the limit of Equation (3.1) to any A (not only to rectangles Rd). Then the density of any null set would be 0, and in particular we would have D\u00b5 [x = 0.5||y = 0] = 0. This would contradict countable additivity, since |D\u00b5 [\u00b7||y = 0]| = 1 but D\u00b5 [x1 < |x\u22120.5| \u2264 x2||y = 0] = 0 when 0 < x1 < x2."}, {"heading": "4. SEMANTICS BY COMPILATION TO CSOFT", "text": "A naive implementation of the measure transformer semantics of the previous section would work directly with measures of states, whose size even in the discrete case could be exponential in the number of variables in scope. For large models, this becomes intractable. In this section, we instead give a semantics to Fun programs by translation to the simple imperative language Imp. We consider Imp to be a sublanguage of Csoft; the Csoft program is then evaluated by Infer.NET by constructing a suitable factor graph [28], whose size will be linear in the size of the program. The implementation advantage of translating F# to Csoft, over simply generating factor graphs directly [32], is that the translation preserves the structure of the input model (including array processing in our full language), which can be exploited by the various inference algorithms supported by Infer.NET.\n4.1. Imp: An Imperative Core Calculus. Imp is an imperative language, based on the static single assignment (SSA) intermediate form. It is a sublanguage of Csoft, the input language of Infer.NET [37]. A composite statement C is a sequence of statements, each of which either stores the result of a primitive operation in a location, observes the contents of a location to be zero, or branches on the value of a location. Imp shares the base types b with Fun, but has no tuples."}, {"heading": "Syntax of Imp:", "text": "l, l\u2032, . . . location (variable) in global store E,F ::= c | l | (l \u2297 l) expression I ::= statement\nl \u2190 E assignment l s\u2190\u2212 D(l1, . . . , ln) random assignment observeb l observation if l then C1 else C2 conditional local l : b in C local declaration (scope of l is C)\nC ::= nil | I | (C;C) composite statement\nWhen making an observation observeb, we make explicit the type b of the observed location. In a local declaration, local l : b in C, the location l is bound, with scope C. Next, we derive an extended form of local, which introduces a sequence of local variables."}, {"heading": "Extended Form of local:", "text": "local \u03a3 in C , local l1 : b1 in . . . local ln : bn in C where \u03a3 = \u03b5 , l1 : b1, . . . , ln : bn\nThe typing rules for Imp are standard. We consider Imp typing environments \u03a3 to be a special case of Fun environments \u0393, where variables (locations) always map to base types. If \u03a3 = \u03b5 , l1 : b1, . . . , ln : bn, we say \u03a3 is well-formed and write \u03a3 \u22a2 \u22c4 to mean that the locations li are pairwise distinct. The judgment \u03a3 \u22a2 E : b means that the expression E has type b in the environment \u03a3. The judgment \u03a3 \u22a2C : \u03a3\u2032 means that the composite statement C is well-typed in the initial environment \u03a3, yielding additional bindings \u03a3\u2032."}, {"heading": "Judgments of the Imp Type System:", "text": "\u03a3 \u22a2 \u22c4 environment \u03a3 is well-formed \u03a3 \u22a2 E : b in \u03a3, expression E has type b \u03a3 \u22a2C : \u03a3\u2032 given \u03a3, statement C assigns to \u03a3\u2032"}, {"heading": "Typing Rules for Imp Expressions and Commands:", "text": "(IMP CONST) \u03a3 \u22a2 \u22c4\n\u03a3 \u22a2 c : ty(c)\n(IMP LOC) \u03a3 \u22a2 \u22c4 (l:b) \u2208 \u03a3\n\u03a3 \u22a2 l : b\n(IMP OP) \u03a3 \u22a2 l1 : b1 \u03a3 \u22a2 l2 : b2 \u2297 : b1,b2 \u2192 b3\n\u03a3 \u22a2 l1 \u2297 l2 : b3\n(IMP ASSIGN) \u03a3 \u22a2 E : b l /\u2208 dom(\u03a3)\n\u03a3 \u22a2 l \u2190 E : (\u03b5 , l:b)\n(IMP RANDOM) D : (x1 : b1, . . . ,xn : bn)\u2192 b l /\u2208 dom(\u03a3)\n\u03a3 \u22a2 l1 : b1 \u00b7 \u00b7 \u00b7 \u03a3 \u22a2 ln : bn \u03a3 \u22a2 l s\u2190\u2212 D(l1, . . . , ln) : (\u03b5 , l:b)\n(IMP OBSERVE) \u03a3 \u22a2 l : b\n\u03a3 \u22a2 observeb l : \u03b5\n(IMP SEQ) \u03a3 \u22a2C1 : \u03a3\u2032 \u03a3,\u03a3\u2032 \u22a2C2 : \u03a3\u2032\u2032\n\u03a3 \u22a2C1;C2 : \u03a3\u2032,\u03a3\u2032\u2032\n(IMP NIL) \u03a3 \u22a2 \u22c4\n\u03a3 \u22a2 nil : \u03b5 (IMP IF) \u03a3 \u22a2 l : bool \u03a3 \u22a2C1 : \u03a3\u2032 \u03a3 \u22a2C2 : \u03a3\u2032\n\u03a3 \u22a2 if l then C1 else C2 : \u03a3\u2032\n(IMP LOCAL) \u03a3 \u22a2C : \u03a3\u2032 (l : b) \u2208 \u03a3\u2032 \u03a3 \u22a2 local l : b in C : (\u03a3\u2032 \\{l : b})\nTo treat sequences of local variables, we use the shuffle product \u03a31 +\u03a32 of two environments, defined below."}, {"heading": "Typing Rule for Extended Form of local:", "text": "(SH EMP)\n\u03b5 \u2208 \u03b5 + \u03b5\n(SH LEFT) \u03a3 \u2208 \u03a31 +\u03a32 \u03a3,x : b \u22a2 \u22c4 (\u03a3,x : b) \u2208 (\u03a31,x : b)+\u03a32\n(SH RIGHT) \u03a3 \u2208 \u03a31 +\u03a32 \u03a3,x : b \u22a2 \u22c4 (\u03a3,x : b) \u2208 \u03a31 +(\u03a32,x : b)\n(IMP LOCALS) \u03a3 \u22a2C : \u03a3\u20321 \u03a3\u20321 \u2208 \u03a31 +\u03a3\u2032 \u03a3 \u22a2 local \u03a31 in C : \u03a3\u2032\nLemma 4.1. (1) If \u03a3,\u03a3\u2032 \u22a2 \u22c4 then dom(\u03a3)\u2229dom(\u03a3\u2032) =\u2205. (2) If \u03a3 \u22a2 E : b then \u03a3 \u22a2 \u22c4 and fv(E)\u2286 dom(\u03a3). (3) If \u03a3 \u22a2C : \u03a3\u2032 then \u03a3,\u03a3\u2032 \u22a2 \u22c4.\n4.2. Measure Transformer Semantics of Imp. A compound statement C in Imp has a semantics as a measure transformer I[[C]] generated from the set of combinators defined in Section 3. An Imp program does not return a value, but is solely a measure transformer on states S\u3008\u03a3\u3009\u2740 S\u3008\u03a3,\u03a3\u2032\u3009 (where \u03a3 is a special case of \u0393). Interpretation of Statements: I[[C]],I[[I]] : S\u3008\u03a3\u3009\u2740 S\u3008\u03a3,\u03a3\u2032\u3009 I[[nil]], pure id I[[C1;C2]], I[[C1]]>>> I[[C2]]\nI[[l \u2190 c]], pure \u03bb s.add l (s,c) I[[l \u2190 l\u2032]], pure \u03bb s.add l (s,lookup l\u2032 s) I[[l \u2190 l1 \u2297 l2]], pure \u03bb s.add l (s,\u2297(lookup l1 s,lookup l2 s))) I[[l s\u2190\u2212 D(l1, . . . , ln)]], extend (\u03bb s.\u00b5D(lookup l1 s,...,lookup ln s))>>> pure (add l) I[[observeb l]], observe \u03bb s.lookup l s I[[if l then C1 else C2]], choose (\u03bb s.lookup l s) I[[C1]] I[[C2]] I[[local l : b in C]], I[[C]]>>> pure (drop {l})\nLemma 4.2. If \u03a3 \u22a2C : \u03a3\u2032 then A[[M]] \u2208 S\u3008\u03a3\u3009\u2740 S\u3008\u03a3,\u03a3\u2032\u3009."}, {"heading": "Semantics of Extended Form of local:", "text": "I[[local \u03a3 in C]], I[[C]]>>> pure (drop (dom(\u03a3)))\n4.3. Translating from Fun to Imp. The translation from Fun to Imp is a mostly routine compilation of functional code to imperative code. The main point of interest is that Imp locations only hold values of base type, while Fun variables may hold tuples. We rely on patterns p and layouts \u03c1 to track the Imp locations corresponding to Fun environments."}, {"heading": "Notations for the Translation from Fun to Imp:", "text": "p ::= l | () | (p, p) pattern: group of Imp locations to represent Fun value \u03c1 ::= (xi 7\u2192 pi)i\u22081..n layout: finite map from Fun variables to patterns \u03a3 \u22a2 p : t in environment \u03a3, pattern p represents Fun value of type t \u03a3 \u22a2 \u03c1 : \u0393 in environment \u03a3, layout \u03c1 represents environment \u0393\n\u03c1 \u22a2 M \u21d2C, p given \u03c1 , expression M translates to C and pattern p"}, {"heading": "Typing Rules for Patterns \u03a3 \u22a2 p : t and Layouts \u03a3 \u22a2 \u03c1 : \u0393:", "text": "(PAT LOC) \u03a3 \u22a2 \u22c4 (l : t) \u2208 \u03a3 \u03a3 \u22a2 l : t (PAT UNIT) \u03a3 \u22a2 \u22c4 \u03a3 \u22a2 () : unit (PAT PAIR) \u03a3 \u22a2 p1 : t1 \u03a3 \u22a2 p2 : t2 \u03a3 \u22a2 (p1, p2) : t1 \u2217 t2 (LAYOUT) locs(\u03c1) = dom(\u03a3) \u03a3 \u22a2 \u22c4 dom(\u03c1) = dom(\u0393) \u03a3 \u22a2 \u03c1(x) : t \u2200(x : t) \u2208 \u0393\n\u03a3 \u22a2 \u03c1 : \u0393\nThe rule (PAT LOC) represents values of base type by a single location. The rules (PAT UNIT) and (PAT PAIR) represent products by a pattern for their corresponding components. The rule (LAYOUT) asks that each entry in \u0393 is assigned a pattern of suitable type by layout \u03c1 .\nThe translation rules below depend on some additional notations. We say p\u2208\u03a3 if every location in p is in \u03a3. Let locs(\u03c1) =\n\u22c3{fv(\u03c1(x)) | x \u2208 dom(\u03c1)}, and let locs(C) be the environment listing the set of locations assigned by a command C. Rules for Translation: p \u223c p\u2032 and p \u2190 p\u2032 and p \u22a2 M \u21d2C, p () \u223c () l \u223c l\u2032 p1 \u223c p\u20321 \u2227 p2 \u223c p\u20322 \u21d2 (p1, p2)\u223c (p\u20321, p\u20322) () \u2190 () , nil (p1, p2)\u2190 (p\u20321, p\u20322), p1 \u2190 p\u20321; p2 \u2190 p\u20322 (TRANS VAR)\n\u03c1 \u22a2 x \u21d2 nil,\u03c1(x) (TRANS CONST) c 6= () l /\u2208 locs(\u03c1) \u03c1 \u22a2 c \u21d2 (l \u2190 c), l (TRANS UNIT)\n\u03c1 \u22a2 () \u21d2 nil, () (TRANS OPERATOR) \u03c1 \u22a2V1 \u21d2C1, l1 \u03c1 \u22a2V2 \u21d2C2, l2 l /\u2208 locs(\u03c1)\u222a locs(C1)\u222a locs(C2) locs(C1)\u2229 locs(C2) =\u2205 \u03c1 \u22a2V1 \u2297V2 \u21d2 (C1;C2; l \u2190 l1 \u2297 l2), l (TRANS PAIR) \u03c1 \u22a2V1 \u21d2C1, p1 \u03c1 \u22a2V2 \u21d2C2, p2 locs(C1)\u2229 locs(C2) =\u2205 \u03c1 \u22a2 (V1,V2)\u21d2 (C1;C2),(p1, p2) (TRANS PROJ1) \u03c1 \u22a2V \u21d2C,(p1, p2)\n\u03c1 \u22a2V.1 \u21d2C, p1\n(TRANS PROJ2) \u03c1 \u22a2V \u21d2C,(p1, p2)\n\u03c1 \u22a2V.2 \u21d2C, p2 (TRANS IF) \u03c1 \u22a2V1 \u21d2C1, l (locs(\u03c1)\u222a locs(C1)\u222a locs(C2)\u222a locs(C3))\u2229 fv(p) =\u2205 \u03c1 \u22a2 M2 \u21d2C2, p2 C\u20322 = local locs(C2) in (C2; p \u2190 p2) p2 \u223c p \u03c1 \u22a2 M3 \u21d2C3, p3 C\u20323 = local locs(C3) in (C3; p \u2190 p3) p3 \u223c p \u03c1 \u22a2 (if V1 then M2 else M3)\u21d2 (C1; if l then C\u20322 else C\u20323), p (TRANS OBSERVE)\n\u03c1 \u22a2V \u21d2C, l b is the type of V \u03c1 \u22a2 observe V \u21d2 (C;observeb l), ()\n(TRANS RANDOM) \u03c1 \u22a2V \u21d2C, p l /\u2208 locs(\u03c1)\u222a locs(C)\n\u03c1 \u22a2 random (D(V ))\u21d2 (C; l s\u2190\u2212 D(p)), l\n(TRANS LET) \u03c1 \u22a2 M1 \u21d2C1, p1 x /\u2208 dom(\u03c1) \u03c1{x 7\u2192 p1} \u22a2 M2 \u21d2C2, p2 \u03c1 \u22a2 let x = M1 in M2 \u21d2 (local (locs(C1)\\ fv(p1)) in C1);C2, p2\nIn general, a Fun term M translates under a layout \u03c1 to a series of commands C and a pattern p. The commands C mutate the global store so that the locations in p correspond to the value that M returns. The simplest example of this is in (TRANS CONST): the constant expression c translates to an Imp program that writes c into a fresh location l. The pattern that represents this return value is l itself. The (TRANS VAR) and (TRANS UNIT) rules are similar. In both rules, no commands are run. For variables, we look up the pattern in the layout \u03c1 ; for unit, we return the unit location. Translation of pairs (TRANS PAIR) builds each of the constituent values and constructs a pair pattern.\nMore interesting are the projection operators. Consider (TRANS PROJ1); the second projection is translated similarly by (TRANS PROJ2). To find V.1, we run the commands to generate V , which we know must return a pair pattern (p1, p2). To extract the first element of this pair, we simply need to return p1. Not only would it not be easy to isolate and run only the commands to generate the values that go in p1, it would be incorrect to do so. For example, the Fun expressions constructing the second element of V may observe values, and hence have non-local effects.\nThe translation for conditionals (TRANS IF) is somewhat subtle. First, we run the translated branch condition. The return value of the translated branches is reassigned to a pattern p of fresh locations: using a shared output pattern allows us to avoid the \u03c6 nodes common in SSA compilers. We use the Imp derived form where the local variables of the then and else branches of the conditional are restricted. Instead, both branches write to a fresh shared target p, in order to preserve well-typedness (Proposition 4.3).\nThe rule (TRANS OBSERVE) translates observe by running the commands to generate the value for V and then observing the pattern. (This pattern l can only be a location, and not of the form () or (p1, p2), as observations are only possible on values of base type.)\nThe rule (TRANS RANDOM) translates random sampling in much the same way. By D(p), we mean the flattening of p into a list of locations and passing it to the distribution constructor D.\nFinally, the rule (TRANS LET) translates let statements by running both expressions in sequence. We translate M2, the body of the let, with an extended layout, so that C2 knows where to find the values written by C1, in the pattern p1. Here the local variables of the let-bound expression are restricted using local.\nProposition 4.3. Suppose \u0393 \u22a2 M : t and \u03a3 \u22a2 \u03c1 : \u0393. (1) There are C and p such that \u03c1 \u22a2 M \u21d2C, p. (2) Whenever \u03c1 \u22a2 M \u21d2C, p, there is \u03a3\u2032 such that \u03a3 \u22a2C : \u03a3\u2032 and \u03a3,\u03a3\u2032 \u22a2 p : t.\nProof. By induction on the typing of M (Appendix A.1).\nWe define operations lift and restrict to translate between Fun variables (S\u3008\u0393\u3009) and Imp locations (S\u3008\u03a3\u3009).\nlift \u03c1 , \u03bb s.flatten{\u03c1(x) 7\u2192 V[[x]] s | x \u2208 dom(\u03c1)} restrict \u03c1 , \u03bb s.{x 7\u2192 V[[\u03c1(x)]] s | x \u2208 dom(\u03c1)}\nWe let flatten take a mapping from patterns to values to a mapping from locations to base values. Given these notations, we state that the compilation of Fun to Imp preserves the measure transformer semantics, modulo a pattern p that indicates the locations of the various parts of the return value in the typing environment; an environment mapping \u03c1 , which does the same translation for the initial typing environment; and superfluous variables, removed by restrict.\nTheorem 4.4. If \u0393 \u22a2 M : t and \u03a3 \u22a2 \u03c1 : \u0393 and \u03c1 \u22a2 M \u21d2C, p then: A[[M]] = pure (lift \u03c1)>>> I[[C]]>>> pure (\u03bb s. (restrict \u03c1 s,V[[p]] s)).\nProof. By induction on the typing of M (Appendix A.2)."}, {"heading": "5. ADDING ARRAYS AND COMPREHENSIONS", "text": "To be useful for machine learning, our language must support large datasets. To this end, we extend Fun and Imp with arrays and comprehensions. We offer three examples, after which we present the formal semantics, which is based on unrolling.\n5.1. Comprehension Examples in Fun. Earlier, we tried to estimate the skill levels of three competitors in head-to-head games. Using comprehensions, we can model skill levels for an arbitrary number of players and games:"}, {"heading": "TrueSkill:", "text": "let trueskill (players:int[]) (results:(bool\u2217int\u2217int)[]) = let skills = [for p in players \u2192random (Gaussian(10.0,20.0))] for (w,p1,p2) in results do\nlet perf1 = random (Gaussian(skills.[p1], 1.0)) let perf2 = random (Gaussian(skills.[p2], 1.0)) if w // win? then observe (perf1 > perf2) // first player won else observe (perf1 = perf2) // draw\nskills\nFirst, we create a prior distribution for each player: we assume that skills are normally distributed around 10.0, with variance 20.0. Then we look at each of the results\u2014this is the comprehension. The result of the head-to-head matches is an array of triples: a Boolean and two indexes. If the Boolean is true, then the first index represents the winner and the second represents the loser. If the Boolean is false, then the match was a draw between the two players. The probabilistic program walks over the results, and observes that either the first player\u2019s performance\u2014normally distributed around their skill level\u2014was greater than the second\u2019s performance, or that the two players\u2019 performances were equal. Returning skills after these observations allows us to inspect the posterior distributions. Our original example can be modelled with players = [0;1;2] (IDs for Alice, Bob, and Cyd, respectively) and results = [(true,0,1);(true,1,2);(true,0,2)].\nAs another example, we can generalize the simple Bayesian classifier of Section 3 to arrays of categories and measurements, as follows:\nBayesian Inference Over Arrays:\nlet trainF (catIds:int[]) (trainData:(int\u2217real)[]) fMean fVariance = let priors = [for cid in catIds \u2192random (Gaussian(fMean,fVariance))] for (cid,m) in trainData do observe (m \u2212 random (Gaussian(priors.[cid],1.0))) priors let catIds:int[] = (\u2217 ... \u2217) let trainingData:(int\u2217real)[] = (\u2217 ... \u2217)\nThe function trainF is a probabilistic program for training a naive Bayesian classifier on a single feature. Each category of objects\u2014modelled by the array catIds\u2014is given a normally distributed prior on the weight of objects in that category; we store these in the priors array. Then, for each measurement m of some object of category cid in the trainingData array, we observe that m is normally distributed according to the prior for that category of object. We then return the posterior distributions, which have been appropriately modified by the observed weights. We can train using this model by issuing a command such as trainF catIds trainingData 20.0 5.0, which runs inference to compute for each category its posterior distribution for this feature.\nAs a third example, consider the adPredictor component of the Bing search engine, which estimates the click-through rates for particular users on advertisements [17]. We describe a probabilistic program that models (a small part of) adPredictor. Without loss of generality, we use only two features to make our prediction: the advertiser\u2019s listing and the phrase used for searching. In the real system, many more (undisclosed) features are used for prediction.\nadPredictor in F#:\nlet read lines filename count line = (\u2217 ... \u2217) [<RegisterArray>] let imps = (\u2217 ... \u2217) [<ReflectedDefinition>] let probit b x =\nlet y = random (Gaussian(x,1.0)) observe (b == (y > 0.0))\n[<ReflectedDefinition>] let ad predictor (listings:int[]) (phrases:int[]) impressions =\nlet lws = [for l in listings \u2192random (Gaussian(0.0,0.33))] let pws = [for p in phrases \u2192random (Gaussian(0.0,0.33))] for (clicked,lid,pid) in Array.toList impressions do\nprobit clicked (lws.[lid] + pws.[pid]) lws,pws\nThe read lines function loads data from a file on disk. The data are formatted as newline-separated records of comma-separated values. There are three important values in each record: a field that is 1 if the given impression lead to a click, and a 0 otherwise; a field that is the database ID of the listing shown; a field that is the part of the search phrase that led to the selection of the listing. We preprocess the data in three ways, which are elided in the code above. First, we convert the 1/0-valued Boolean to a true/false-valued Boolean. Second, we normalize the listing IDs so that they begin at 0, that is, so that we can use them as array indexes. Third, we collect unique phrases and assign them fresh, 0-based IDs. We define imps\u2014a list of advertising impressions (a listing ID and a phrase ID) and whether or not the ad was clicked\u2014in terms of this processed data. The [<RegisterArray>] attribute on the definition of imps instructs the compiler to simply evaluate this F# expression, yielding a deterministic constant. Finally, ad predictor defines the model. We use the [<ReflectedDefinition>] attribute on ad predictor to mark it as a probabilistic program, which should be compiled and sent to Infer.NET. Suppose we have stored the collated listing and phrase IDs in ls and ps, respectively; we can train on the impressions by calling ad predictor ls ps imps.\n5.2. Formalizing Arrays and Comprehensions in Fun. We introduce syntax for arrays in Fun, and give interpretations of this extended syntax in terms of the core languages, essentially by treating arrays as tuples and by unfolding iterations. We work with non-empty zero-indexed arrays of statically known size (representing, for example, statically known experimental data).\nThere are three array operations: array literals, indexing, and array comprehension. First, let R be a set of ranges r. Ranges allow us to differentiate arrays of different sizes. Moreover, limitations in the implementation of Infer.NET disallow nested iterations on the same range. Here we disallow nested iterations altogether\u2014they are not needed for our examples and they would significantly complicate the formalization. We assign sizes to ranges using the function |\u00b7| : R \u2192 Z+. In the metalanguage, arrays over range r correspond to tuples of length |r|."}, {"heading": "Extended Syntax of Fun:", "text": "t ::= \u00b7 \u00b7 \u00b7 | t[r] type M,N ::= \u00b7 \u00b7 \u00b7 | expression\n[V1; . . . ;Vn] array literal V1.[V2]r indexing [for x inr V \u2192 M] comprehension\nFirst, we add arrays as a type: t[r] is an array of elements of type t over the range r. In the array type t[r], we require that the type t contains no array type t \u2032[r\u2032], that is, we do not consider nested arrays. Indexing, V1.[V2]r, extracts elements out of an array, where the index V2 is computed modulo the size |r| of the array V1. A comprehension [for x inr V \u2192 M] maps over an array V , producing a new array where each element is determined by evaluating M with the corresponding element of array V bound to x. To simplify the formalization, we here require that the body M of the comprehension contains neither array literals nor comprehensions. We attach the range to indexing and comprehensions so that the measure transformer semantics can be given simply; the range can be inferred easily, and need not be written by the programmer. We elide the range in our code examples. We here do not distinguish comprehensions that produce values\u2014like the one that produces skills\u2014and those that do not\u2014like the one that observes player performances according to results. For the sake of efficiency, our implementation does distinguish these two uses. In some of the code examples, we write for x in V do M to mean [for x inr V \u2192 M]. We do so only when M has type unit and we intend to ignore the result of the expression. We encode arrays as tuples. For all n > 0, we define \u03c0n(M,N) with M : tn and N : int and if N%n = i we expect \u03c0n((V0, . . . ,Vn\u22121),N) =Vi. Derived Types and Expressions for Arrays in Fun:\n\u03c01(M,N) := M \u03c0n(M,N) := if N%n== 0 then M.1 else \u03c0n\u22121(M.2,N \u22121) for n > 1 t[r] := t |r| where t1 := t and tn+1 := t \u2217 tn\n[V0; ...;Vn\u22121] := (V0, . . . ,Vn\u22121) V1[V2]r := \u03c0|r|(V1,V2) for x inr V \u2192 M :=\nlet y0 = (let x = \u03c0|r|(V,0) in M) in \u00b7 \u00b7 \u00b7 let y|r|\u22121 = (let x = \u03c0|r|(V, |r|\u22121) in M) in (y0; . . . ;y|r|\u22121) where y1, . . . ,y|r| are fresh for M and V .\nOur derived forms for arrays yield programs whose size grows linearly with the data over which they compute\u2014we implement V [i]r with O(|r|) projections. To avoid this problem, our implementation takes advantage of support for arrays in the Infer.NET factor graph library (see Section 5.3).\nThe static semantics of these new constructs is straightforward; we give the derived rules for (FUN ARRAY), (FUN INDEX), and (FUN FOR). By adding these as derived forms in Fun, we do not need to extend Imp at all. On the other hand, our formalization does not reflect that our implementation preserves the structure of array comprehensions when going to Infer.NET."}, {"heading": "Extended Typing Rules for Fun Expressions: \u0393 \u22a2 M : t", "text": "(FUN ARRAY) \u0393 \u22a2Vi : t \u2200i \u2208 0..n\u22121 \u0393 \u22a2 [V0; . . . ;Vn\u22121] : t[rn] (FUN INDEX) \u0393 \u22a2V1 : t[r] \u0393 \u22a2V2 : int \u0393 \u22a2V1[V2]r : t (FUN FOR) \u0393 \u22a2V : t[r] \u0393,x : t \u22a2 M : t \u2032 \u0393 \u22a2 [for x inr V \u2192 M] : t \u2032[r]\nThe rule (FUN ARRAY) uses the notation rn for the concrete range of size n; we assume there is a unique such range for each n > 0. This rule can be derived using repeated applications of (FUN PAIR). The rule (FUN INDEX) checks that the array V1 is non-empty array and the index V2 is an integer; the actual index is the value of V2 modulo the size of the array, as in the meta-language. We can derive this rule for a given n by induction on n, using repeated applications of (FUN IF); we use (FUN PROJ1) in the then case and (FUN PROJ2) in the else case. The rule (FUN FOR) requires that the source expression V is an array, and that the body M is well-typed assuming a suitable type for x. We can derive (FUN FOR) using repeated applications of (FUN LET), with (FUN PAIR) to type the final result.\n5.3. Arrays in Imp. We now sketch our structure-preserving implementation strategy. We work in a version of Imp with arrays and iteration over ranges, and we extend both the assignment form and expressions to permit array indexing. Inside the body of an iteration over a range, the name of the range can be used as an index."}, {"heading": "Extended Syntax of Imp:", "text": "E ::= . . . | l[l\u2032] | l[r] expression I ::= \u00b7 \u00b7 \u00b7 | statement\nl[r]\u2190 E assignment to array item for r do C iteration over ranges\nWe require that every occurrence of an index r is inside an iteration for r do C. Inside such an iteration, every assignment to an array variable must be at index r. We also extend patterns to include range indexed locations, and write (p1, p2)[r] for (p1[r], p2[r]).\nOur compiler translates comprehensions over variables of array type as an iteration over the translation of the body of the comprehension. We add to \u03c1 the fact that the comprehension variable corresponds to the array variable indexed by the range. We invent a fresh array result pattern p\u2032, and assign the result of the translated body to p\u2032[r]. Finally, we hide the local variables of the translation of the body of the comprehension, in order to avoid clashes in the unrolling semantics of the loop. This compilation corresponds to the rule (TRANS FOR) below. In particular, the sizes of ranges are never needed in our compiler, so compilation is not data dependent.\nCompilation of comprehensions:\n(TRANS FOR) \u03c1{x 7\u2192 \u03c1(z)[r]} \u22a2 M \u21d2C, p p[r] \u223c p\u2032 (locs(\u03c1)\u222a locs(C))\u2229 fv(p\u2032) =\u2205\n\u03c1 \u22a2 [for x inr z \u2192 M]\u21d2 for r do local locs(C) in (C; p\u2032[r]\u2190 p), p\u2032"}, {"heading": "6. IMPLEMENTATION EXPERIENCE", "text": "We implemented a compiler from Fun to Imp in F#. We wrote two backends for Imp: an exact inference algorithm based on a direct implementation of measure transformers for discrete measures, and an approximating inference algorithm for continuous measures, using Infer.NET [37]. The translation of Section 4 formalizes our translation of Fun to Imp. Translating Imp to Infer.NET is relatively straightforward, and amounts to a syntax-directed series of calls to Infer.NET\u2019s object-oriented API.\nThe frontend of our compiler takes (a subset of) actual F# code as its input. To do so, we make use of F#\u2019s reflected definitions, which allow programmatic access to ASTs. This implementation strategy is advantageous in several ways. First, there is no need to design new syntax, or even write a parser. Second, all inputs to our compiler are typed ASTs of well typed F# programs. Third, a single file can contain both ordinary F# code as well as reflected definitions. This allows a single module to both read and process data, and to specify a probabilistic model for inference from the data.\nFunctions computing array values containing deterministic data are tagged with an attribute RegisterArray, to signal to the compiler that they do not need to be interpreted as Fun programs. Reflected definitions later in the same file are typed with respect to these registered definitions and then run in Infer.NET with the pre-processed data; we further discuss this idea below.\nBelow follows some statistics on a few of the examples we have implemented. The number of lines of code includes F# code that loads and processes data from disk before loading it into Infer.NET. The times are based on an average of three runs. All of the runs are on a four-core machine with 4GB of RAM. The Naive Bayes program is the naive Bayesian classifier of the earlier examples. The Mixture model is another clustering/classification model. TrueSkill and adPredictor were described earlier. TrueSkill spends the majority of its time (64%) in Infer.NET, performing inference. AdPredictor spends most of the time in pre-processing (58%), and only 40% in inference. The time spent in our compiler is negligible, never more than a few hundred milliseconds."}, {"heading": "Summary of our Basic Test Suite:", "text": "LOC Observations Variables Time Naive Bayes 28 9 3 <1s\nMixture 33 3 3 <1s TrueSkill 68 15,664 84 6s\nadPredictor 78 300,752 299,594 3m30s\nIn summary, our implementation strategy allowed us to build an effective prototype quickly and easily: the entire compiler is only 2079 lines of F#; the Infer.NET backend is 600 lines; the discrete backend is 252 lines. Our implementation, however, is only a prototype, and has limitations. Our discrete backend is limited to small models using only finite measures. Infer.NET supports only a limited set of operations on specific combinations of probabilistic and deterministic arguments. It would be useful in the future to have an enhanced type system able to detect errors arising from illegal combinations of operators in Infer.NET. The reflected definition facility is somewhat limited in F#. In the adPredictor example on page 24, a call to Array.toList is required because F# does not\nreflect definitions that contain comprehensions over arrays\u2014only lists. (The F# to Fun compiler discards this extra call as a no-op, so there is no runtime overhead.)"}, {"heading": "7. RELATED WORK", "text": "Formal Semantics of Probabilistic Languages. There is a long history of formal semantics for probabilistic languages with sampling primitives, often combined with recursive computation. One of the first semantics is for Probabilistic LCF [49], which augments the core functional language LCF with weighted binary choice, for discrete distributions. (Apart from its inclusion of observations, Bernoulli Fun is a first-order terminating form of Probabilistic LCF.) Kozen [27] develops a probabilistic semantics for while-programs augmented with random assignment. He develops two provably equivalent semantics; one more operational, and the other a denotational semantics using partially ordered Banach spaces. Imp is simpler than Kozen\u2019s language, as Imp has no unbounded while-statements, so the semantics of Imp need not deal with non-termination. On the other hand, observations are not present in Kozen\u2019s language, although discrete observations can be encoded using possibly non-terminating while loops.\nJones and Plotkin [22] investigate the probability monad, and apply it to languages with discrete probabilistic choice. Ramsey and Pfeffer [46] give a stochastic \u03bb -calculus with a measure-theoretic semantics in the probability monad, and provide an embedding within Haskell; they do not consider observations. We can generalize the semantics of observe to the stochastic \u03bb -calculus as filtering in the probability monad (yielding what we may call a sub-probability monad), as long as the events that are being observed are discrete. In their notation, we can augment their language with a failure construct defined by P[[fail]]\u03c1 = \u00b50 where we define \u00b50(A) = 0 for all measurable sets A. Then, we can define observe v = (if v = true then () else fail). However, as discussed in Section 3.5, zeroprobability observations of real variables do not translate easily to the probability monad, as the following example shows. Let N be an expression denoting a continuous distribution, for example, random (Gaussian(0.0,1.0)), and let f x = observe x. Suppose there is a semantics for [[f x]]{x 7\u2192 r} for real r in the probability monad. The probability monad semantics of the program let x = N in f x of the stochastic \u03bb -calculus is [[N]] \u226b= \u03bby.[[f x]]{x 7\u2192 y}, which yields the measure \u00b5(A) = \u222b\nR (M[[[[f x]]{x 7\u2192 y}]])(A) dM[N](y). Here the probability (M[[[[f x]]{x 7\u2192 y}]])(A) is zero except when y = 0, where it is some real number. Since the N-measure of y = 0 is zero, the whole integral is zero for all A (in particular \u00b5(R) = 0), whereas the intended semantics is that x is constrained to be zero with probability 1 (so in particular \u00b5(R) = 1).\nThe probabilistic concurrent constraint programming language Probabilistic cc of Gupta, Jagadeesan, and Panangaden [18] is also intended for describing probability distributions using independent sampling and constraints. Our use of observations loosely corresponds to constraints on random variables in Probabilistic cc. In the finite case, Probabilistic cc also relies on a sampling semantics with observation (constraints) denoting filtering. To admit continuous distributions, Probabilistic cc adds general fixpoints and defines the semantics of a program as the limit of finite unrollings of its fixpoints, if defined. This can lead to surprising results, such as that the distribution resulting from observing that two apparently uniform distributions are equal may not itself be uniform. In contrast, we work directly with standard distributions and have a less syntactic semantics of observation that appears to be easier to anticipate.\nMcIver and Morgan [33] develop a theory of abstraction and refinement for probabilistic while programs, based on weakest preconditions. They reject a subdistribution transformer semantics in order to admit demonic nondeterminism in the language.\nWe conjecture that Fun and Imp could in principle be conferred semantics within a probabilistic language supporting general recursion, by encoding discrete observations by placing the whole program within a conditional sampling loop, and by encoding Gaussian and other continuous distributions as repeated sampling using recursive functions. Still, dealing with recursion would be a non-trivial development, and would raise issues of computability. Ackerman, Freer, and Roy [2] show the uncomputability of conditional distributions in general, establishing limitations on constructive foundations of probabilistic programming. We chose when formulating the semantics of Fun and Imp to include some distributions as primitive, and to exclude recursion; compared to encodings within probabilistic languages with recursion, this choice has the advantage of compositionality (rather than relying on a global sampling loop) and of admitting a direct (if sometimes approximate) implementation (via message-passing algorithms on factor graphs, with efficient implementations of primitive distributions).\nRecent work on semantics of probabilistic programs within interactive theorem provers includes the mechanization of measure theory [20] and Lebesgue integration [35] in HOL, and a framework for proofs of randomized algorithms in Coq [3] which also allows for discrete observations.\nProbabilistic Languages for Machine Learning. Koller et al. [26] proposed representing a probability distribution using first-order functional programs with discrete random choice, and proposed an inference algorithm for Bayesian networks and stochastic context-free grammars. Observations happen outside their language, by returning the distributions P [A\u2227B] ,P [A\u2227\u00acB],P [\u00acA] which can be used to compute P [B | A]. Their work was subsequently developed by Pfeffer into the language IBAL [43], which has observations and uses a factor graph semantics, but only works with discrete datatypes.\nPark et al. [41] propose \u03bb\u25e6, the first probabilistic language with formal semantics applied to actual machine learning problems involving continuous distributions. The formal basis is sampling functions, which uniformly supports both discrete and continuous probability distributions, and inference is by Monte Carlo importance sampling methods. The calculus \u03bb\u25e6 enables conditional sampling via fixpoints and rejection, and its implementation allows discrete observations only.\nHANSEI [24, 23] is an embedding of a probabilistic language as a programming library in OCaml, based on explicit manipulation of discrete probability distributions as lists, and sampling algorithms based on coroutines. HANSEI uses an explicit fail statement, which is equivalent to observe false and so cannot be used for conditioning on zero probability events. Infer.NET [37] is a software library that implements the approximate deterministic algorithms expectation propagation [38] and variational message passing [53], as well as Gibbs sampling, a nondeterministic algorithm. Infer.NET models are written in a probabilistic subset of C#, known as Csoft [52]. Csoft allows observe on zero probability events, but does not have a continuous semantics other than as factor graphs and is currently only implemented as an internal language of Infer.NET. This paper gives a higher-level semantics of Csoft (or Imp) programs as distribution transformers.\nAlthough there are many Bayesian modelling languages, Csoft and IBAL are the only previous languages implemented by a compilation to factor graphs. Probabilistic Scheme [45] is a probabilistic form of the untyped functional language Scheme, limited to discrete distributions, and with a construct for reifying the distribution induced by a thunk as a value. Church [15] is another probabilistic form of Scheme, equipped with conditional sampling and a mechanism of stochastic memoization. In MIT-Church, queries are implemented using Markov chain Monte Carlo methods. WinBUGS [39] is a popular implementation of the BUGS language [14] for explicitly describing distributions suitable for MCMC analysis.\nFACTORIE [32] is a Scala library for explicitly constructing factor graphs. Blaise [7] is a software library for building MCMC samplers in Java, that supports compositional construction of sophisticated probabilistic models, and decouples the choice of inference algorithm from the specification of the distribution.\nA recent paper [16] based on Fun describes a model-learner pattern which captures common probabilistic programming patterns in machine learning, including various sorts of mixture models.\nOther Uses of Probabilistic Languages. Probabilistic languages with formal semantics find application in many areas apart from machine learning, including databases [9], model checking [29], differential privacy [34, 47], information flow [30], and cryptography [1]. A recent monograph on semantics for labelled Markov processes [40] focuses on bisimulation-based equational reasoning. The syntax and semantics of Imp is modelled on the probabilistic language pWhile [4] without observations.\nErwig and Kollmansberger [12] describe a library for probabilistic functional programming in Haskell. The library is based on the probability monad, and uses a finite representation suitable for small discrete distributions; the library would not suffice to provide a semantics for Fun or Imp with their continuous and hybrid distributions. Their library has similar functionality to that provided by our combinators for discrete distributions listed in the technical report."}, {"heading": "8. CONCLUSION", "text": "We advocate probabilistic functional programming with observations and comprehensions as a modelling language for Bayesian reasoning. We developed a system based on the idea, invented new formal semantics to establish correctness, and evaluated the system on a series of typical inference problems.\nOur direct contribution is a rigorous semantics for a probabilistic programming language with zero-probability observations on continuous variables. We have shown that probabilistic functional programs with iteration over arrays, but without the complexities of general recursion, are a concise representation for complex probability distributions arising in machine learning. An implication of our work for the machine learning community is that probabilistic programs can be written directly within an existing declarative language (Fun\u2014a subset of F#), linked by comprehensions to large datasets, and compiled down to lower level Bayesian inference engines.\nFor the programming language community, our new semantics suggests some novel directions for research. What other primitives are possible\u2014non-generative models, inspection of distributions, on-line inference on data streams? Can we verify the transformations performed by machine learning compilers such as Infer.NET compiler for Csoft? What is the role of type systems for such probabilistic languages? Avoiding (discrete) zero probability exceptions, and ensuring that we only generate Csoft programs suitable for our back-end, are two possibilities, but we expect there are more.\nAcknowledgements. We gratefully acknowledge discussions with and comments from Ralf Herbrich, Oleg Kiselyov, Tom Minka, Aditya Nori, Robert Simmons, Nikhil Swamy, Dimitrios Vytiniotis and John Winn. Chung-Chieh Shan highlighted an issue with our original definition of observation. The comments by the anonymous reviewers were most helpful, in particular regarding the definition of conditional density."}, {"heading": "APPENDIX A. DETAILED PROOFS", "text": "Our proofs are structured as follows. \u2022 Appendix A.1 gives a proof of Proposition 4.3. \u2022 Appendix A.2 gives a proof of Theorem 4.4.\nA.1. Proof of Proposition 4.3. We begin with a series of lemmas.\nLemma A.1 (Pattern agreement weakening). If \u03a3 \u22a2 p : t and \u03a3,\u03a3\u2032 \u22a2 \u22c4, then \u03a3,\u03a3\u2032 \u22a2 p : t. Proof. By induction on t.\nLemma A.2 (Expression and statement heap weakening). (1) If \u03a3 \u22a2 E : b and \u03a3,\u03a3\u2032 \u22a2 \u22c4, then \u03a3,\u03a3\u2032 \u22a2 E : b (2) If \u03a3 \u22a2 I : \u03a3\u2032 and \u03a3,\u03a3\u2032,\u03a3\u2032\u2032 \u22a2 \u22c4, then \u03a3,\u03a3\u2032\u2032 \u22a2 I : \u03a3\u2032 (3) If \u03a3 \u22a2C : \u03a3\u2032 and \u03a3,\u03a3\u2032,\u03a3\u2032\u2032 \u22a2 \u22c4, then \u03a3,\u03a3\u2032\u2032 \u22a2C : \u03a3\u2032. Proof. By induction on E , I, and C, respectively.\nLemma A.3 (Pattern agreement uniqueness). If \u03a3 \u22a2 p : t and \u03a3\u2032 \u22a2 p\u2032 : t then p \u223c p\u2032. Proof. By induction on t.\nLemma A.4 (Pattern creation). If \u03a3 \u22a2 p : t then there exists \u03a3\u2032 such that \u03a3,\u03a3\u2032 \u22a2 \u22c4 and \u03a3\u2032 \u22a2 p\u2032 : t and dom(\u03a3\u2032) = fv(p\u2032).\nProof. By induction on t, and the assumption that there always exist new, globally fresh locations.\nLemma A.5 (Pattern assignment). If \u03a3 \u22a2 p : t and \u03a3\u2032 \u22a2 p\u2032 : t and \u03a3,\u03a3\u2032 \u22a2 \u22c4, then \u03a3 \u22a2 p\u2032 \u2190 p : \u03a3\u2032\u2032, where \u03a3\u2032\u2032 \u2286 \u03a3\u2032. Proof. By induction on t. \u2022 (t = unit) Trivial: p\u2032 \u2190 p = nil, so \u03a3\u2032\u2032 = \u03b5 \u2286 \u03a3\u2032. \u2022 (t = bool) \u03a3 \u22a2 l : bool and \u03a3\u2032 \u22a2 l\u2032 : bool, so l : bool \u2208 \u03a3 and l\u2032 : bool \u2208 \u03a3\u2032. So l : bool \u22a2 l\u2032 \u2190 l : (l\u2032 : bool)\u2286 \u03a3\u2032. \u2022 (t = int) Similar. \u2022 (t = real) Similar. \u2022 (t = t1 \u2217 t2) \u03a3 \u22a2 p1, p2 : t1 \u2217 t2 and \u03a3\u2032 \u22a2 p\u20321, p\u20322 : t1 \u2217 t2. Both \u03a3 and \u03a3\u2032 factor into contexts that type\np1 and p2 (resp. p\u20321 and p \u2032 2) individually; call them \u03a31 and \u03a32 (resp. \u03a3\u20321 and \u03a3\u20322). By the IHs, we have \u03a31 \u22a2 p\u20321 \u2190 p1 : \u03a3\u2032\u20321 \u2286 \u03a3\u20321 and \u03a32 \u22a2 p\u20322 \u2190 p2 : \u03a3\u2032\u20322 \u2286 \u03a3\u20322. We can then see \u03a3 \u22a2 p\u20321 \u2190 p1; p\u20322 \u2190 p2 : \u03a3\u2032\u20321 ,\u03a3\u2032\u20322 \u2286 \u03a3\u20321,\u03a3\u20322.\nThe purpose of this subsection is to prove the following. Restatement of Proposition 4.3 Suppose \u0393 \u22a2 M : t and \u03a3 \u22a2 \u03c1 : \u0393. (1) There are C and p such that \u03c1 \u22a2 M \u21d2C, p. (2) Whenever \u03c1 \u22a2 M \u21d2C, p, there is \u03a3\u2032 such that \u03a3 \u22a2C : \u03a3\u2032 and \u03a3,\u03a3\u2032 \u22a2 p : t. Proof. By induction on the typing of M, leaving \u03a3 and \u03c1 general. (FUN VAR) \u0393 \u22a2 x : t. For (1), we have C = nil and p = \u03c1(x). For (2), let \u03a3\u2032 = \u03b5 . By assumption,\n\u03a3,\u03a3\u2032 \u22a2 \u03c1(x) : t and \u03a3 \u22a2 nil : \u03a3\u2032 immediately.\n(FUN CONST) \u0393 \u22a2 c : ty(c). For (1), we have: l 6\u2208 locs(\u03c1) ty(c) = b for some base type b \u03c1 \u22a2 c \u21d2 l \u2190 c, l\nFor (2), let \u03a3\u2032 = l : ty(c). We have \u03a3,\u03a3\u2032 \u22a2 l : ty(c) and \u03a3 \u22a2 l \u2190 c : \u03a3\u2032. (FUN OPERATOR) \u0393 \u22a2V1 \u2297V2 : b3, where \u2297 has type b1 \u2217b2 \u2192 b3. By inversion and the IH:\n\u0393 \u22a2V1 : b1 \u03c1 \u22a2V1 \u21d2C1, l1 (IH1) \u2203\u03a31 (IH2)\n\u03a3,\u03a31 \u22a2 l1 : b1 \u03a3 \u22a2C1 : \u03a31\n\u0393 \u22a2V2 : b2 \u03c1 \u22a2V2 \u21d2C2, l2 (IH2) \u2203\u03a32 (IH2)\n\u03a3,\u03a32 \u22a2 l2 : b2 \u03a3 \u22a2C2 : \u03a32\nWe have for (1), by (TRANS OPERATOR): \u03c1 \u22a2V1 \u2297V2 \u21d2C1;C2; l \u2190 l1 \u2297 l2, l. Let \u03a3\u2032 = \u03a31,\u03a32, l : b3 \u22a2 \u22c4. By weakening we find for (2): \u03a3,\u03a3\u2032 \u22a2 l : b3 and \u03a3 \u22a2C1;C2; l \u2190 l1 \u2297 l2 : \u03a3\u2032.\n(FUN PAIR) \u0393 \u22a2 (M1,M2) : t1 \u2217 t2. By inversion and the IH: \u0393 \u22a2 M1 : t1 \u03c1 \u22a2 M1 \u21d2CM1 , p1 (IH1) \u2203\u03a31 (IH2)\n\u03a3,\u03a31 \u22a2 p1 : t1 \u03a3 \u22a2CM1 : \u03a31\n\u0393 \u22a2 M2 : t2 \u03c1 \u22a2 M2 \u21d2CM2 , p2 (IH1) \u2203\u03a32 (IH2)\n\u03a3,\u03a32 \u22a2 p2 : t2 \u03a3 \u22a2CM2 : \u03a32\nWe have for (1): \u03c1 \u22a2 (M1,M2)\u21d2CM1 ;CM2 ,(p1, p2). Let \u03a3\u2032 = \u03a31,\u03a32 \u22a2 \u22c4. By weakening we find for (2): \u03a3,\u03a3\u2032 \u22a2 (p1, p2) : t1 \u2217 t2 and \u03a3 \u22a2CM1 ;CM2 : \u03a3\u2032.\n(FUN PROJ1) \u0393 \u22a2 M.1 : t1. By inversion and the IH: \u0393 \u22a2 M : t1 \u2217 t2 \u03c1 \u22a2 M \u21d2CM, p (IH1) \u2203\u03a3\u2032 (IH2)\n\u03a3,\u03a3\u2032 \u22a2 p : t1 \u2217 t2 \u03a3 \u22a2 M : S\u2032\nBy inversion, p = (p1, p2), such that \u03a3,\u03a3\u2032 \u22a2 p1 : t1 and \u03a3,\u03a3\u2032 \u22a2 p2 : t2. We now have \u03c1 \u22a2 M.1 \u21d2 CM, p1 for (1). We use \u03a3\u2032 to show \u03a3,\u03a3\u2032 \u22a2 p1 : t1 and \u03a3 \u22a2CM : \u03a3\u2032 for (2).\n(FUN PROJ2) \u0393 \u22a2 M.2 : t2. Analogous to the previous case.\n(FUN IF) \u0393 \u22a2 if M1 then M2 else M3 : t. We have: \u0393 \u22a2 M1 : bool \u03c1 \u22a2 M1 \u21d2CM1 , p1 (IH1) \u2203\u03a31 (IH2)\n\u03a3,\u03a31 \u22a2 p1 : bool \u03a3 \u22a2CM1 : \u03a31\n\u0393 \u22a2 M2 : t \u03c1{x 7\u2192 pl} \u22a2 M2 \u21d2CM2 , p2 (IH1) \u2203\u03a32 (IH2)\n\u03a3,\u03a32 \u22a2 p2 : t \u03a3 \u22a2CM2 : \u03a32\n\u0393 \u22a2 M3 : t \u03c1{x 7\u2192 pr} \u22a2 M3 \u21d2CM3 , p3 (IH1) \u2203\u03a33 (IH2)\n\u03a3,\u03a33 \u22a2 p3 : t \u03a3 \u22a2CM3 : \u03a33\nBy inversion, p1 = l and \u03a3,\u03a31 \u22a2 l : bool. By pattern agreement uniqueness (Lemma A.3), p2 \u223c p3. Let \u03a3p\u2032 \u22a2 p\u2032 : t, for dom(\u03a3p\u2032) = f v(p) (by Lemma A.4). We have (locs(\u03c1)\u222a locs(C1)\u222a locs(C2)\u222a locs(C3))\u2229 f v(p) =\u2205. We also have p\u2032 \u223c p2 and p\u2032 \u223c p3. We now have for (1):\n\u03c1 \u22a2 if M1 then M2 else M3 \u21d2 CM1 ; if l then local locs(C2) in CM2 ; [[p \u2032 \u2190 p2]] else local locs(C3) in CM3 ; [[p\u2032 \u2190 p3]], p\u2032\nFinally, let \u03a3 f = \u03a32 \u2229 \u03a33 \u2229 \u03a3p\u2032 \u22a2 \u22c4 and \u03a3\u2032 = \u03a31,\u03a3 f \u22a2 \u22c4. By pattern assignment, we can see \u03a3 f \u22a2 [[p\u2032 \u2190 p2]] and \u03a3 f \u22a2 [[p\u2032 \u2190 p3]]. By weakening (Lemmas A.1, and A.2) we have what we need for (2):\n\u03a3,\u03a3\u2032 \u22a2 p\u2032 : t \u03a3 \u22a2CM1 ; if l then ... else ... : \u03a3\u2032\n(FUN LET) \u0393 \u22a2 let x = M1 in M2 : t2. We have: \u0393 \u22a2 M1 : t1 \u03c1 \u22a2 M1 \u21d2CM1 , p1 (IH1) \u2203\u03a31 (IH2)\n\u03a3,\u03a31 \u22a2 p1 : t1 \u03a3 \u22a2CM1 : \u03a31\n\u0393,x : T1 \u22a2 M2 : t2 Next, note that \u03a3,\u03a31 \u22a2 \u03c1{x 7\u2192 p1} : \u0393,x : T1. We can now apply the IH to M2\u2019s typing derivation to see:\n\u03c1{x 7\u2192 p1} \u22a2 M2 \u21d2CM2 , p2 (IH1) \u2203\u03a32 (IH2)\n\u03a3,\u03a32 \u22a2 p2 : t2 \u03a3 \u22a2CM2 : \u03a32\nFirst, we have: \u03c1 \u22a2 let x = M1 in M2 \u21d2 (local (locs(CM1) \\ fv(p1)) in CM1);CM2 , p2 for (1). For (2), let \u03a3\u20321 = \u03a31|fv(p1) and \u03a3\u2032 = \u03a3\u20321,\u03a32 \u22a2 \u22c4. By weakening, we find \u03a3,\u03a3\u2032 \u22a2 p2 : t2 and \u03a3 \u22a2 (local (locs(CM1)\\ fv(p1)) in CM1);CM2 : \u03a3\u2032.\n(FUN OBSERVE) \u0393 \u22a2 observeb E : unit. By the IH, with \u03a3\u2032 = \u03b5 from IH2.\n(FUN RANDOM) \u0393 \u22a2 random(D(V )) : bn+1. We have: D : (x1 : b1 \u2217 ...\u2217 xn : bn)\u2192 bn+1 \u0393 \u22a2V : (b1 \u2217 ...\u2217bn)\nWe have, by the IH: \u03c1 \u22a2V \u21d2C, p (IH1) \u2203\u03a3\u2032 (IH2)\n\u03a3,\u03a3\u2032 \u22a2 p : t (\u2217) \u03a3 \u22a2C : \u03a3\u2032\nSo \u03c1 \u22a2 random(D(V )) \u21d2 C; l s\u2190\u2212 D(p), l, for (1). We find (2) by (*) and by (Imp Seq), (Imp Random), and the IH \u03a3 \u22a2C; l : \u03a3\u2032, l, where \u03a3\u2032, l \u22a2 l : bn+1.\nA.2. Proof of Theorem 4.4. We use the following lemma.\nLemma A.6 (Value equivalence). If \u0393 \u22a2V : t and \u03a3 \u22a2 \u03c1 : \u0393 and \u03c1 \u22a2V \u21d2C, p then I[[C]] = pure f , where f is either id or a series of (independent) calls to add :\nf = \u03bb s. add l1(add l2(...(add ln(s,cn))...,c2),c1) where each of the li are distinct, and\nA[[V ]] = pure (lift \u03c1)>>> I[[C]] >>> pure (\u03bb s. restrict \u03c1 s,V[[p]] s)\nProof. By induction on the derivation of \u0393 \u22a2V : t. (FUN VAR) \u0393 \u22a2 x : t, so x : t \u2208 \u0393 and \u03a3 \u22a2 \u03c1(x) : t. We have \u03c1 \u22a2 x \u21d2 nil,\u03c1(x), so f = id.\nA[[x]] = pure (\u03bb s. (s,V[[x]] s)) = pure (\u03bb s. (s,lookup x s)) = pure (\u03bb s. (restrict \u03c1(lift \u03c1),V[[p]] (lift \u03c1 s))) = lift \u03c1 >>> (\u03bb s. (restrict \u03c1 s,V[[p]] s)) = lift \u03c1 >>> pure id >>> (\u03bb s. (restrict \u03c1 s,V[[p]] s)) = lift \u03c1 >>>A[[x]] >>> (\u03bb s. (restrict \u03c1 s,V[[p]] s))\n(FUN CONST) \u0393 \u22a2 c : ty(c). We have \u03c1 \u22a2 c \u21d2 l \u2190 c, l, so f = \u03bb s. add l (s,c). A[[c]]\n= pure (\u03bb s. s,c) = pure (\u03bb s. restrict \u03c1(lift \u03c1 s),V[[l]] (add l (lift \u03c1 s,c))) = pure (lift \u03c1)>>> pure (\u03bb s. restrict \u03c1 s,V[[l]] (add l (s,c))) = pure (lift \u03c1)>>> pure (\u03bb s. add l (s,c)) >>> pure (\u03bb s. restrict \u03c1 s,V[[l]] s) = pure (lift \u03c1)>>> I[[l \u2190 c]]>>> pure (\u03bb s. restrict \u03c1 s,V[[l]] s)\n(FUN PAIR) \u0393 \u22a2 (V1,V2) : t1 \u2217 t2. We have \u03c1 \u22a2V1,V2 \u21d2C1;C2,(p1, p2). By the IH, I[[C1]] = pure f1 and I[[C2]] = pure f2, where f1 and f2 are either id or add s. We also have:\nA[[Vi]] = pure (\u03bb s. s,V[[Vi]] s) = pure (lift \u03c1)>>> I[[Ci]]>>> pure (\u03bb s. restrict \u03c1 s,V[[pi]] s) = pure (lift \u03c1)>>> pure fi >>> pure (\u03bb s. restrict \u03c1 s,V[[pi]] s) = pure (\u03bb s. restrict \u03c1( fi(lift \u03c1 s)),V[[pi]] ( fi (lift \u03c1 s))) = pure (\u03bb s. s,V[[pi]] ( fi (lift \u03c1 s)))\nSo V[[Vi]] s = V[[pi]] ( fi(lift \u03c1 s)). Let f = f1; f2. We derive: A[[V1,V2]]\n= pure (\u03bb s. s,(V[[V1]] s,V[[V2]] s)) = pure (\u03bb s. s,(V[[p1]] ( f1 (lift \u03c1 s)),V[[p2]] ( f2 (lift \u03c1 s))) by weakening/independence = pure (\u03bb s. s,(V[[p1]] (( f1; f2)(lift \u03c1 s)),V[[p2]] (( f1; f2)(lift \u03c1 s))) = pure (\u03bb s. restrict \u03c1 ( f1; f2(lift \u03c1 s)), (V[[p1]] (( f1; f2)(lift \u03c1 s)),V[[p2]] (( f1; f2)(lift \u03c1 s))) = pure (lift \u03c1)>>> pure ( f1; f2)>>> pure (\u03bb s. restrict \u03c1 s,(V[[p1]] s,V[[p2]] s)) = pure (lift \u03c1)>>> I[[C1]]>>> I[[C2]]>>> pure (\u03bb s. restrict \u03c1 s,V[[(p1, p2)]] s) = pure (lift \u03c1)>>> I[[C1;C2]]>>> pure (\u03bb s. restrict \u03c1 s,V[[(p1, p2)]] s)\nRestatement of Theorem 4.4 \u0393 \u22a2 M : t and \u03a3 \u22a2 \u03c1 : \u0393 and \u03c1 \u22a2 M \u21d2C, p then: A[[M]] = pure (lift \u03c1)>>> I[[C]]>>> pure (\u03bb s. (restrict \u03c1 s,V[[p]] s))\nProof. By induction on \u0393 \u22a2 M : t. (FUN VAR) By the value lemma. (FUN CONST) By the value lemma. (FUN PAIR) By the value lemma. (FUN OPERATOR) \u0393 \u22a2V1\u2297V2 : b3 and \u03c1 \u22a2V1\u2297V2 \u21d2 (C1;C2; l \u2190 l1 \u2297 l2), l. We have A[[V1\u2297V2]] =\npure (\u03bb s. s,\u2297(V[[V1]] s,V[[V2]] s)). By the value lemma (Lemma A.6): A[[Vi]]\n= pure (\u03bb s. s,V[[Vi]] s) = pure (lift \u03c1)>>> I[[Ci]]>>> pure (\u03bb s. restrict \u03c1 s,V[[li]] s) = pure (lift \u03c1)>>> pure fi >>> pure (\u03bb s. restrict \u03c1 s,V[[li]] s) = pure (\u03bb s. restrict \u03c1 ( fi (lift \u03c1 s)),V[[li]] ( fi (lift \u03c1 s))) = pure (\u03bb s. s,V[[li]] ( fi(lift \u03c1 s))) = pure (\u03bb s. s,V[[li]] (( f1; f2)(lift \u03c1 s)) by weakening/independence\nSo V[[Vi]] s = V[[li]] (( f1; f2)(lift \u03c1 s)). We derive: A[[V1 \u2297V2]]\n= pure (\u03bb s. s,V[[V1]] s\u2297V[[V2]] s) = pure (\u03bb s. s,\u2297(V[[l1]] (( f1; f2)(lift \u03c1 s)),V[[l2]] (( f1; f2)(lift \u03c1 s)))) = pure (lift \u03c1)>>> pure ( f1; f2)>>> pure (\u03bb s. restrict \u03c1 s,\u2297(V[[l1]] s,V[[l2]] s)))) = pure (lift \u03c1)>>> I[[C1]]>>> I[[C2]]>>> pure (\u03bb s. restrict \u03c1 s,\u2297(V[[l1]] s,V[[l2]] s)))) = pure (lift \u03c1)>>> I[[C1]]>>> I[[C2]]>>> I[[l \u2190 l1 \u2297 l2]]>>> pure (\u03bb s. restrict \u03c1 s,V[[l]] s))) = pure (lift \u03c1)>>> I[[C1;C2; l \u2190 l1 \u2297 l2]]>>> pure (\u03bb s. restrict \u03c1 s,V[[l]] s)))\n(FUN PROJ1) \u0393 \u22a2V.1 : t1 and \u0393 \u22a2V : t1 \u2217 t2. We have \u03c1 \u22a2V \u21d2C,(p1, p2) and \u03c1 \u22a2V.1 \u21d2C, p1. By the value lemma as before, we can conclude V[[V ]] s = V[[(p1, p2)]] ( f (lift \u03c1 s)). Therefore:\nA[[V.1]] = pure (\u03bb s. s,fst V[[V ]] s) = pure (\u03bb s. s,fst (V[[(p1, p2)]] ( f (lift \u03c1 s))) = pure (\u03bb s. s,V[[p1]] ( f (lift \u03c1 s)) = pure (lift \u03c1)>>> pure f >>> pure (\u03bb s. restrict \u03c1 s,V[[p1]] s) = pure (lift \u03c1)>>> I[[C]]>>> pure (\u03bb s. restrict \u03c1 s,V[[p1]] s)\n(FUN PROJ2) Symmetric to Proj1.\n(FUN IF) \u0393 \u22a2 if V1 then M2 else M3 : t. We have: \u03c1 \u22a2 ...\u21d2C1; if l1 then local locs(C2) in C2; p \u2190 2 else local locs(C3) in C3; p \u2190 p3, p\nOur IHs are: A[[Mi]] = pure (lift \u03c1)>>> I[[Ci]]>>> pure (\u03bb s. restrict \u03c1 s,V[[pi]] s). By the value lemma we have I[[V1]] = pure f1 for some f1 such that V[[V1]] s = V[[l1]] ( f1(lift \u03c1 s)). We now calculate (at length):\nA[[if V1 then M2 else M3]] = choose (\u03bb s. V[[V1]] s) A[[M2]] A[[M3]]\n= choose (\u03bb s. V[[l1]] ( f1 (lift \u03c1 s))) (pure (lift \u03c1)>>> I[[C2]]>>> pure (\u03bb s. restrict \u03c1 s,V[[p2]] s)) (pure (lift \u03c1)>>> I[[C3]]>>> pure (\u03bb s. restrict \u03c1 s,V[[p3]] s))\n= pure (lift \u03c1)>>> choose (\u03bb s.V[[l1]] ( f1 s)) (I[[C2]]>>> pure (\u03bb s. restrict \u03c1 s,V[[p2]] s)) (I[[C3]]>>> pure (\u03bb s. restrict \u03c1 s,V[[p3]] s))\n= pure (lift \u03c1)>>> choose (\u03bb s.V[[l1]] ( f1 s)) (I[[C2]]>>> I[[p \u2190 p2]]>>> pure (\u03bb s. restrict \u03c1 s,V[[p]] s)) (I[[C3]]>>> I[[p \u2190 p3]]>>> pure (\u03bb s. restrict \u03c1 s,V[[p]] s))\n= pure (lift \u03c1)>>> choose (\u03bb s.V[[l1]] ( f1 s)) (I[[C2]]>>> I[[p \u2190 p2]]>>> pure (drop locs(C2))>>> pure (\u03bb s. restrict \u03c1 s,V[[p]] s)) (A[[C3]]>>>A[[p \u2190 p3]]>>> pure (drop locs(C3))>>> pure (\u03bb s. restrict \u03c1 s,V[[p]] s))\n= pure (lift \u03c1)>>> (choose (\u03bb s.V[[l1]] ( f1 s)) (A[[C2]]>>>A[[p \u2190 p2]]>>> pure (drop locs(C2))) (A[[C3]]>>>A[[p \u2190 p3]]>>> pure (drop locs(C3))))>>>\npure (\u03bb s. restrict \u03c1 s,V[[p]] s)\n= pure (lift \u03c1)>>>A[[C1]]>>> (choose (\u03bb s.V[[l1]] s) (A[[C2; p \u2190 p2]]>>> pure (drop locs(C2))) (A[[C3; p \u2190 p3]]>>> pure (drop locs(C3))))>>>\npure (\u03bb s. restrict \u03c1 s,V[[p]] s) = pure (lift \u03c1)>>>A[[C1]]>>> (choose (\u03bb s.V[[l1]] s)\n(A[[local locs(C2) in C2; p \u2190 p2]]) (A[[local locs(C3) in C3; p \u2190 p3]]))>>>\npure (\u03bb s. restrict \u03c1 s,V[[p]] s) (FUN LET) \u0393 \u22a2 let x = M1 in M2 : t2; by inversion, \u0393 \u22a2 M1 : t1 and \u0393,x : t1 \u22a2 M2 : t2.\nLet \u03c1 \u2032 = \u03c1{x 7\u2192 p1} and \u03a31 = (locs(C1)\\ fv(p1)). We have: \u03c1 \u22a2 M1 \u21d2C1, p1 \u03c1 \u2032 \u22a2 M2 \u21d2C2, p2 \u03c1 \u22a2 let x = M1 in M2 \u21d2 (local \u03a31 in C1);C2, p2\nAs our IHs:\nA[[M1]] = pure (lift \u03c1)>>>A[[C1]]>>> pure (\u03bb s. restrict \u03c1 s,V[[p1]] s) A[[M2]] = pure (lift \u03c1 \u2032)>>>A[[C2]]>>> pure (\u03bb s. restrict \u03c1 \u2032s,V[[p2]] s)\nWe derive: A[[let x = M1 in M2]]\n= A[[M1]]>>> pure (add x) >>>A[[M2]]>>> pure (\u03bb s,y. drop x s,y) = pure (lift \u03c1)>>>A[[C1]]>>> pure (\u03bb s. restrict \u03c1 s,V[[p1]] s)>>> pure (add x)>>>\nA[[M2]]>>> pure (\u03bb s,y. drop x s,y) = pure (lift \u03c1)>>>A[[C1]]>>> pure (\u03bb s. restrict \u03c1 s,V[[p1]] s)>>>\npure (add x)>>> pure (lift \u03c1 \u2032)>>> A[[C2]]>>> pure (\u03bb s. restrict \u03c1 \u2032s,V[[p2]] s)>>> pure (\u03bb s,y. drop x s,y) = pure (lift \u03c1)>>>A[[C1]]>>> pure (drop (dom(\u03a31)))>>> A[[C2]]>>> pure (\u03bb s. restrict \u03c1 \u2032s,V[[p2]] s)>>> pure (\u03bb s,y. drop x s,y) = pure (lift \u03c1)>>>A[[C1]]>>> pure (drop (dom(\u03a31)))>>> A[[C2]]>>> pure (\u03bb s. restrict \u03c1 s,V[[p2]] s)\n= pure (lift \u03c1)>>>A[[(local \u03a31 in C1);C2]]>>> pure (\u03bb s. restrict \u03c1 s,V[[p2]] s) (FUN RANDOM) \u0393 \u22a2 random(D(V )) : b, where D : (b1, ...,bn) \u2192 bn+1,\u0393 \u22a2 V : (b1, ...,bn). We\nhave \u03c1 \u22a2 V \u21d2 C, p and \u03c1 \u22a2 D(V )\u21d2 C; l \u2190 D(p), l. By the value lemma, A[[C]] = pure f and V[[V ]] s = V[[p]] ( f (lift \u03c1 s)). We derive:\nA[[random(D(V ))]] = extend (\u03bb s. \u00b5D(V[[V ]] s)) = extend (\u03bb s. \u00b5D(p( f (lift \u03c1 s)))) = pure (lift \u03c1)>>> extend (\u03bb s. \u00b5D(p( f s)))>>> pure (\u03bb s,v. restrict \u03c1 s,v) = pure (lift \u03c1)>>> pure f >>> extend (\u03bb s. \u00b5D(V[[p]] s))>>> pure (\u03bb s,v. restrict \u03c1 s,v) = pure (lift \u03c1)>>>A[[C]]>>> extend (\u03bb s. \u00b5D(V[[p]] s))>>> pure (\u03bb s,v. restrict \u03c1 s,v) = pure (lift \u03c1)>>>A[[C]]>>> extend (\u03bb s. \u00b5D(V[[p]] s))>>>\npure (add l)>>> pure (\u03bb s. restrict \u03c1 s,V[[l]] s) = pure (lift \u03c1)>>>A[[C; l \u2190 D(p)]]>>> pure (\u03bb s. restrict \u03c1 s,V[[l]] s)\n(FUN OBSERVE) \u0393 \u22a2 observe V : unit and \u0393 \u22a2V : b for some base type b. We have \u03c1 \u22a2V \u21d2C, l. By the value lemma: A[[C]] = pure f and V[[V ]] s = V[[l]] ( f (lift \u03c1 s)).\nA[[observe V ]] = observe (\u03bb s. V[[V ]] s)>>> pure (\u03bb s. (s,()) = observe (\u03bb s. l( f (lift \u03c1 s)))>>> pure (\u03bb s. s,()) = pure (lift \u03c1)>>> observe (\u03bb s. V[[l]] ( f s))>>> pure (\u03bb s. restrict \u03c1 s,() s) = pure (lift \u03c1)>>> pure f >>> observe (\u03bb s. V[[l]] s)>>> pure (\u03bb s. restrict \u03c1 s,() s) = pure (lift \u03c1)>>>A[[C]]>>> observe (\u03bb s. V[[l]] s)>>> pure (\u03bb s. restrict \u03c1 s,() s) = pure (lift \u03c1)>>>A[[C;observe l]]>>> pure (\u03bb s. restrict \u03c1 s,() s)"}], "references": [{"title": "Reconciling two views of cryptography (the computational soundness of formal encryption)", "author": ["M. Abadi", "P. Rogaway"], "venue": "J. Cryptology, 15(2):103\u2013127,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2002}, {"title": "Noncomputable conditional distributions", "author": ["N.L. Ackerman", "C.E. Freer", "D.M. Roy"], "venue": "LICS, pages 107\u2013116,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "Proofs of randomized algorithms in Coq", "author": ["P. Audebaud", "C. Paulin-Mohring"], "venue": "Science of Computer Programming, 74(8):568\u2013589,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Formal certification of code-based cryptographic proofs", "author": ["G. Barthe", "B. Gr\u00e9goire", "S.Z. B\u00e9guelin"], "venue": "POPL, pages 90\u2013101. ACM,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "A type theory for probability density functions", "author": ["S. Bhat", "A. Agarwal", "R.W. Vuduc", "A.G. Gray"], "venue": "J. Field and M. Hicks, editors, POPL, pages 545\u2013556. ACM,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "Probability and Measure", "author": ["P. Billingsley"], "venue": "Wiley, 3rd edition,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1995}, {"title": "Composable Probabilistic Inference with Blaise", "author": ["K.A. Bonawitz"], "venue": "PhD thesis, MIT,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Measure transformer semantics for Bayesian machine learning", "author": ["J. Borgstr\u00f6m", "A.D. Gordon", "M. Greenberg", "J. Margetson", "J. Van Gael"], "venue": "European Symposium on Programming (ESOP\u201911), volume 6602 of LNCS, pages 77\u201396. Springer,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Probabilistic databases: diamonds in the dirt", "author": ["N.N. Dalvi", "C. R\u00e9", "D. Suciu"], "venue": "Commun. ACM, 52(7):86\u201394,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "Markov logic", "author": ["P. Domingos", "S. Kok", "D. Lowd", "H. Poon", "M. Richardson", "P. Singla"], "venue": "L. De Raedt, P. Frasconi, K. Kersting, and S. Muggleton, editors, Probabilistic inductive logic programming, pages 92\u2013117. Springer-Verlag, Berlin, Heidelberg,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2008}, {"title": "Functional pearls: Probabilistic functional programming in Haskell", "author": ["M. Erwig", "S. Kollmansberger"], "venue": "J. Funct. Program., 16(1):21\u201334,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2006}, {"title": "On the definition of probability densities and sufficiency of the likelihood map", "author": ["D.A.S. Fraser", "P. McDunnough", "A. Naderi", "A. Plante"], "venue": "J. Probability and Mathematical Statistics, 15:301\u2013310,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1995}, {"title": "A language and program for complex Bayesian modelling", "author": ["W.R. Gilks", "A. Thomas", "D.J. Spiegelhalter"], "venue": "The Statistician, 43:169\u2013178,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1994}, {"title": "Church: a language for generative models", "author": ["N. Goodman", "V.K. Mansinghka", "D.M. Roy", "K. Bonawitz", "J.B. Tenenbaum"], "venue": "Uncertainty in Artificial Intelligence (UAI\u201908), pages 220\u2013229. AUAI Press,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2008}, {"title": "A modellearner pattern for Bayesian reasoning", "author": ["A.D. Gordon", "M. Aizatulin", "J. Borgstr\u00f6m", "G. Claret", "T. Graepel", "A. Nori", "S. Rajamani", "C. Russo"], "venue": "POPL, pages 403\u2013416,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Web-scale Bayesian click-through rate prediction for sponsored search advertising in Microsoft\u2019s Bing search engine", "author": ["T. Graepel", "J.Q. Candela", "T. Borchert", "R. Herbrich"], "venue": "International Conference on Machine Learning, pages 13\u201320,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}, {"title": "Stochastic processes as concurrent constraint programs", "author": ["V. Gupta", "R. Jagadeesan", "P. Panangaden"], "venue": "POPL, pages 189\u2013202,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1999}, {"title": "TrueSkilltm: A Bayesian skill rating system", "author": ["R. Herbrich", "T. Minka", "T. Graepel"], "venue": "Advances in Neural Information Processing Systems (NIPS\u201906), pages 569\u2013576,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2006}, {"title": "Formal verification of probabilistic algorithms", "author": ["J. Hurd"], "venue": "PhD thesis, University of Cambridge, 2001. Available as University of Cambridge Computer Laboratory Technical Report UCAM\u2013CL\u2013TR\u2013566, May", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2003}, {"title": "Probability Theory: The Logic of Science, chapter 15.7 The Borel-Kolmogorov paradox, pages", "author": ["E.T. Jaynes"], "venue": "CUP,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2003}, {"title": "A probabilistic powerdomain of evaluations", "author": ["C. Jones", "G.D. Plotkin"], "venue": "Logic in Computer Science (LICS\u201989), pages 186\u2013195. IEEE Computer Society,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1989}, {"title": "Embedded probabilistic programming", "author": ["O. Kiselyov", "C. Shan"], "venue": "Domain-Specific Languages, pages 360\u2013384,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2009}, {"title": "Monolingual probabilistic programming using generalized coroutines", "author": ["O. Kiselyov", "C. Shan"], "venue": "Uncertainty in Artificial Intelligence (UAI\u201909),", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2009}, {"title": "Probabilistic Graphical Models", "author": ["D. Koller", "N. Friedman"], "venue": "The MIT Press,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2009}, {"title": "Effective Bayesian inference for stochastic programs", "author": ["D. Koller", "D.A. McAllester", "A. Pfeffer"], "venue": "AAAI/IAAI, pages 740\u2013747,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1997}, {"title": "Semantics of probabilistic programs", "author": ["D. Kozen"], "venue": "Journal of Computer and System Sciences, 22(3):328\u2013350,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1981}, {"title": "Factor graphs and the sum-product algorithm", "author": ["F.R. Kschischang", "B.J. Frey", "H.-A. Loeliger"], "venue": "IEEE Transactions on Information Theory, 47(2):498\u2013519,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2001}, {"title": "Quantitative analysis with the probabilistic model checker PRISM", "author": ["M.Z. Kwiatkowska", "G. Norman", "D. Parker"], "venue": "Quantitative Aspects of Programming Languages (QAPL 2005), volume 153(2) of ENTCS, pages 5\u201331,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2006}, {"title": "Quantifying information flow", "author": ["G. Lowe"], "venue": "CSFW, pages 18\u201331. IEEE Computer Society,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2002}, {"title": "Information Theory, Inference, and Learning Algorithms", "author": ["D.J.C. MacKay"], "venue": "CUP,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2003}, {"title": "Factorie: Probabilistic programming via imperatively defined factor graphs", "author": ["A. McCallum", "K. Schultz", "S. Singh"], "venue": "Advances in Neural Information Processing Systems (NIPS\u201909), pages 1249\u20131257,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2009}, {"title": "Abstraction, refinement and proof for probabilistic systems", "author": ["A. McIver", "C. Morgan"], "venue": "Monographs in computer science. Springer,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2005}, {"title": "Privacy integrated queries: an extensible platform for privacy-preserving data analysis", "author": ["F. McSherry"], "venue": "SIGMOD Conference, pages 19\u201330. ACM,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2009}, {"title": "On the formalization of the Lebesgue integration theory in HOL", "author": ["T. Mhamdi", "O. Hasan", "S. Tahar"], "venue": "Interactive Theorem Proving (ITP 2010),", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2010}, {"title": "Blog: Probabilistic models with unknown objects", "author": ["B. Milch", "B. Marthi", "S.J. Russell", "D. Sontag", "D.L. Ong", "A. Kolobov"], "venue": "L. P. Kaelbling and A. Saffiotti, editors, IJCAI, pages 1352\u20131359. Professional Book Center,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2005}, {"title": "Software available from http://research.microsoft.com/infernet", "author": ["T. Minka", "J. Winn", "J. Guiver", "A. Kannan"], "venue": "Infer.NET 2.3,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2009}, {"title": "Expectation Propagation for approximate Bayesian inference", "author": ["T.P. Minka"], "venue": "Uncertainty in Artificial Intelligence (UAI\u201901), pages 362\u2013369. Morgan Kaufmann,", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2001}, {"title": "Bayesian Modeling Using WinBUGS", "author": ["I. Ntzoufras"], "venue": "Wiley,", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2009}, {"title": "Labelled Markov processes", "author": ["P. Panangaden"], "venue": "Imperial College Press,", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2009}, {"title": "A probabilistic language based upon sampling functions", "author": ["S. Park", "F. Pfenning", "S. Thrun"], "venue": "POPL, pages 171\u2013 182. ACM,", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2005}, {"title": "IBAL: A probabilistic rational programming language", "author": ["A. Pfeffer"], "venue": "B. Nebel, editor, International Joint Conference on Artificial Intelligence (IJCAI\u201901), pages 733\u2013740. Morgan Kaufmann,", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2001}, {"title": "The design and implementation of IBAL: A general-purpose probabilistic language", "author": ["A. Pfeffer"], "venue": "L. Getoor and B. Taskar, editors, Introduction to Statistical Relational Learning. MIT Press,", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2007}, {"title": "Practical probabilistic programming", "author": ["A. Pfeffer"], "venue": "P. Frasconi and F. A. Lisi, editors, Inductive Logic Programming (ILP 2010), volume 6489 of Lecture Notes in Computer Science, pages 2\u20133. Springer,", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2010}, {"title": "Report on the probabilistic language scheme", "author": ["A. Radul"], "venue": "Proceedings of the 2007 symposium on Dynamic languages (DLS\u201907), pages 2\u201310. ACM,", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2007}, {"title": "Stochastic lambda calculus and monads of probability distributions", "author": ["N. Ramsey", "A. Pfeffer"], "venue": "POPL, pages 154\u2013165,", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2002}, {"title": "Distance makes the types grow stronger: A calculus for differential privacy", "author": ["J. Reed", "B.C. Pierce"], "venue": "ICFP, pages 157\u2013168,", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2010}, {"title": "A First Look at Rigorous Probability Theory", "author": ["J.S. Rosenthal"], "venue": "World Scientific, 2nd edition,", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2006}, {"title": "Probabilistic LCF", "author": ["N. Saheb-Djahromi"], "venue": "Mathematical Foundations of Computer Science (MFCS), volume 64 of LNCS, pages 442\u2013451. Springer,", "citeRegEx": "49", "shortCiteRegEx": null, "year": 1978}, {"title": "AutoBayes program synthesis system users manual", "author": ["J. Schumann", "T. Pressburger", "E. Denney", "W. Buntine", "B. Fischer"], "venue": "Technical Report NASA/TM\u20132008\u2013215366, NASA Ames Research Center,", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2008}, {"title": "Expert F", "author": ["D. Syme", "A. Granicz", "A. Cisternino"], "venue": "Apress,", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2007}, {"title": "Probabilistic programming with Infer.NET", "author": ["J. Winn", "T. Minka"], "venue": "Machine Learning Summer School lecture notes, available at http://research.microsoft.com/~minka/papers/mlss2009/,", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2009}, {"title": "Variational message passing", "author": ["J.M. Winn", "C.M. Bishop"], "venue": "Journal of Machine Learning Research, 6:661\u2013694,", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2005}, {"title": "An intuitive explanation", "author": ["E.S. Yudkowsky"], "venue": "Bayesian reasoning,", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2003}], "referenceMentions": [{"referenceID": 12, "context": "The theme of this paper is the idea of expressing Bayesian models as probabilistic programs, which was pioneered by BUGS [14] and is recently gaining in popularity,", "startOffset": 121, "endOffset": 125}, {"referenceID": 48, "context": "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], \u03bb\u25e6 [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].", "startOffset": 77, "endOffset": 81}, {"referenceID": 9, "context": "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], \u03bb\u25e6 [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].", "startOffset": 91, "endOffset": 95}, {"referenceID": 6, "context": "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], \u03bb\u25e6 [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].", "startOffset": 104, "endOffset": 107}, {"referenceID": 34, "context": "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], \u03bb\u25e6 [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].", "startOffset": 114, "endOffset": 118}, {"referenceID": 13, "context": "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], \u03bb\u25e6 [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].", "startOffset": 127, "endOffset": 131}, {"referenceID": 50, "context": "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], \u03bb\u25e6 [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].", "startOffset": 139, "endOffset": 143}, {"referenceID": 30, "context": "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], \u03bb\u25e6 [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].", "startOffset": 154, "endOffset": 158}, {"referenceID": 42, "context": "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], \u03bb\u25e6 [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].", "startOffset": 167, "endOffset": 171}, {"referenceID": 22, "context": "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], \u03bb\u25e6 [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].", "startOffset": 180, "endOffset": 184}, {"referenceID": 40, "context": "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], \u03bb\u25e6 [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].", "startOffset": 201, "endOffset": 205}, {"referenceID": 39, "context": "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], \u03bb\u25e6 [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].", "startOffset": 210, "endOffset": 214}, {"referenceID": 16, "context": "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], \u03bb\u25e6 [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].", "startOffset": 233, "endOffset": 237}, {"referenceID": 10, "context": "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], \u03bb\u25e6 [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].", "startOffset": 243, "endOffset": 247}, {"referenceID": 43, "context": "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], \u03bb\u25e6 [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].", "startOffset": 274, "endOffset": 278}, {"referenceID": 50, "context": "In particular, we draw inspiration from Csoft [52], an imperative language where programs denote factor graphs [28], data structures that support efficient inference algorithms [25].", "startOffset": 46, "endOffset": 50}, {"referenceID": 26, "context": "In particular, we draw inspiration from Csoft [52], an imperative language where programs denote factor graphs [28], data structures that support efficient inference algorithms [25].", "startOffset": 111, "endOffset": 115}, {"referenceID": 23, "context": "In particular, we draw inspiration from Csoft [52], an imperative language where programs denote factor graphs [28], data structures that support efficient inference algorithms [25].", "startOffset": 177, "endOffset": 181}, {"referenceID": 35, "context": "NET [37], a software library for Bayesian reasoning.", "startOffset": 4, "endOffset": 8}, {"referenceID": 17, "context": "Consider a simplified form of TrueSkill [19], a large-scale online system for ranking computer gamers.", "startOffset": 40, "endOffset": 44}, {"referenceID": 29, "context": "A classic computational method to compute an approximate posterior distribution of each of the skills is Monte Carlo sampling [31].", "startOffset": 126, "endOffset": 130}, {"referenceID": 41, "context": "recent versions of IBAL [43], are based on nondeterministic inference using some form of Monte Carlo sampling.", "startOffset": 24, "endOffset": 28}, {"referenceID": 26, "context": "Inference algorithms based on factor graphs [28, 25] are an efficient alternative to Monte Carlo sampling.", "startOffset": 44, "endOffset": 52}, {"referenceID": 23, "context": "Inference algorithms based on factor graphs [28, 25] are an efficient alternative to Monte Carlo sampling.", "startOffset": 44, "endOffset": 52}, {"referenceID": 49, "context": "We designed Fun to be a subset of the F# dialect of ML [51], for implementation convenience: F# reflection allows easy access to the abstract syntax of a program.", "startOffset": 55, "endOffset": 59}, {"referenceID": 7, "context": "The technical report version of our paper [8] includes additional details, including the code of an F# implementation of measure transformers in the discrete case.", "startOffset": 42, "endOffset": 45}, {"referenceID": 39, "context": "[41]); the formal semantics for the general case comes later.", "startOffset": 0, "endOffset": 4}, {"referenceID": 52, "context": "If a subject is positive, what are the odds they have the disease? [54]", "startOffset": 67, "endOffset": 71}, {"referenceID": 19, "context": "Borel\u2019s paradox [21].", "startOffset": 16, "endOffset": 20}, {"referenceID": 5, "context": "To give a formal semantics to such observations, as well as to mixtures of continuous and discrete distributions, we turn to measure theory, following standard sources [6, 48].", "startOffset": 168, "endOffset": 175}, {"referenceID": 46, "context": "To give a formal semantics to such observations, as well as to mixtures of continuous and discrete distributions, we turn to measure theory, following standard sources [6, 48].", "startOffset": 168, "endOffset": 175}, {"referenceID": 33, "context": "To machine-check our theory, one might build on a recent formalization of measure theory and Lebesgue integration in higher-order logic [35].", "startOffset": 136, "endOffset": 140}, {"referenceID": 11, "context": "Given a finite measure \u03bc on T[[t]] and c \u2208 Vu, we let Fc : t \u2192 R be defined by the limit below (following [13]) Fc(d), lim i\u2192\u221e \u03bc(Rd \u2229 p(Bi))/\u03bbu(Bi) (3.", "startOffset": 106, "endOffset": 110}, {"referenceID": 11, "context": "1) exists almost everywhere [13], that is, there is a set C with \u03bc(C) = 0 such that c \u2208 C if Fc(d) is undefined.", "startOffset": 28, "endOffset": 32}, {"referenceID": 3, "context": "This choice is a generalization of the (discrete) semantics of pWHILE [4].", "startOffset": 70, "endOffset": 73}, {"referenceID": 44, "context": "This contrasts with Ramsey and Pfeffer [46], where the semantics of an open program takes a variable valuation and returns a (monadic computation yielding a) distribution of return values.", "startOffset": 39, "endOffset": 43}, {"referenceID": 7, "context": "Our direct implementation of the measure transformer semantics, described in the technical report version of our paper [8], explicitly constructs the valuation.", "startOffset": 119, "endOffset": 122}, {"referenceID": 35, "context": "As another example, let us consider a simple Bayesian evaluation of a medical trial [37].", "startOffset": 84, "endOffset": 88}, {"referenceID": 7, "context": "The following example, due to Chung-Chieh Shan, highlighted regularity problems with our original definition of observation [8].", "startOffset": 124, "endOffset": 127}, {"referenceID": 26, "context": "NET by constructing a suitable factor graph [28], whose size will be linear in the size of the program.", "startOffset": 44, "endOffset": 48}, {"referenceID": 30, "context": "The implementation advantage of translating F# to Csoft, over simply generating factor graphs directly [32], is that the translation preserves the structure of the input model (including array processing in our full language), which can be exploited by the various inference algorithms supported by Infer.", "startOffset": 103, "endOffset": 107}, {"referenceID": 35, "context": "NET [37].", "startOffset": 4, "endOffset": 8}, {"referenceID": 15, "context": "As a third example, consider the adPredictor component of the Bing search engine, which estimates the click-through rates for particular users on advertisements [17].", "startOffset": 161, "endOffset": 165}, {"referenceID": 35, "context": "NET [37].", "startOffset": 4, "endOffset": 8}, {"referenceID": 47, "context": "One of the first semantics is for Probabilistic LCF [49], which augments the core functional language LCF with weighted binary choice, for discrete distributions.", "startOffset": 52, "endOffset": 56}, {"referenceID": 25, "context": ") Kozen [27] develops a probabilistic semantics for while-programs augmented with random assignment.", "startOffset": 8, "endOffset": 12}, {"referenceID": 20, "context": "Jones and Plotkin [22] investigate the probability monad, and apply it to languages with discrete probabilistic choice.", "startOffset": 18, "endOffset": 22}, {"referenceID": 44, "context": "Ramsey and Pfeffer [46] give a stochastic \u03bb -calculus with a measure-theoretic semantics in the probability monad, and provide an embedding within Haskell; they do not consider observations.", "startOffset": 19, "endOffset": 23}, {"referenceID": 16, "context": "The probabilistic concurrent constraint programming language Probabilistic cc of Gupta, Jagadeesan, and Panangaden [18] is also intended for describing probability distributions using independent sampling and constraints.", "startOffset": 115, "endOffset": 119}, {"referenceID": 31, "context": "McIver and Morgan [33] develop a theory of abstraction and refinement for probabilistic while programs, based on weakest preconditions.", "startOffset": 18, "endOffset": 22}, {"referenceID": 1, "context": "Ackerman, Freer, and Roy [2] show the uncomputability of conditional distributions in general, establishing limitations on constructive foundations of probabilistic programming.", "startOffset": 25, "endOffset": 28}, {"referenceID": 18, "context": "Recent work on semantics of probabilistic programs within interactive theorem provers includes the mechanization of measure theory [20] and Lebesgue integration [35] in HOL, and a framework for proofs of randomized algorithms in Coq [3] which also allows for discrete observations.", "startOffset": 131, "endOffset": 135}, {"referenceID": 33, "context": "Recent work on semantics of probabilistic programs within interactive theorem provers includes the mechanization of measure theory [20] and Lebesgue integration [35] in HOL, and a framework for proofs of randomized algorithms in Coq [3] which also allows for discrete observations.", "startOffset": 161, "endOffset": 165}, {"referenceID": 2, "context": "Recent work on semantics of probabilistic programs within interactive theorem provers includes the mechanization of measure theory [20] and Lebesgue integration [35] in HOL, and a framework for proofs of randomized algorithms in Coq [3] which also allows for discrete observations.", "startOffset": 233, "endOffset": 236}, {"referenceID": 24, "context": "[26] proposed representing a probability distribution using first-order functional programs with discrete random choice, and proposed an inference algorithm for Bayesian networks and stochastic context-free grammars.", "startOffset": 0, "endOffset": 4}, {"referenceID": 41, "context": "Their work was subsequently developed by Pfeffer into the language IBAL [43], which has observations and uses a factor graph semantics, but only works with discrete datatypes.", "startOffset": 72, "endOffset": 76}, {"referenceID": 39, "context": "[41] propose \u03bb\u25e6, the first probabilistic language with formal semantics applied to actual machine learning problems involving continuous distributions.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "HANSEI [24, 23] is an embedding of a probabilistic language as a programming library in OCaml, based on explicit manipulation of discrete probability distributions as lists, and sampling algorithms based on coroutines.", "startOffset": 7, "endOffset": 15}, {"referenceID": 21, "context": "HANSEI [24, 23] is an embedding of a probabilistic language as a programming library in OCaml, based on explicit manipulation of discrete probability distributions as lists, and sampling algorithms based on coroutines.", "startOffset": 7, "endOffset": 15}, {"referenceID": 35, "context": "NET [37] is a software library that implements the approximate deterministic algorithms expectation propagation [38] and variational message passing [53], as well as Gibbs sampling, a nondeterministic algorithm.", "startOffset": 4, "endOffset": 8}, {"referenceID": 36, "context": "NET [37] is a software library that implements the approximate deterministic algorithms expectation propagation [38] and variational message passing [53], as well as Gibbs sampling, a nondeterministic algorithm.", "startOffset": 112, "endOffset": 116}, {"referenceID": 51, "context": "NET [37] is a software library that implements the approximate deterministic algorithms expectation propagation [38] and variational message passing [53], as well as Gibbs sampling, a nondeterministic algorithm.", "startOffset": 149, "endOffset": 153}, {"referenceID": 50, "context": "NET models are written in a probabilistic subset of C#, known as Csoft [52].", "startOffset": 71, "endOffset": 75}, {"referenceID": 43, "context": "Probabilistic Scheme [45] is a probabilistic form of the untyped functional language Scheme, limited to discrete distributions, and with a construct for reifying the distribution induced by a thunk as a value.", "startOffset": 21, "endOffset": 25}, {"referenceID": 13, "context": "Church [15] is another probabilistic form of Scheme, equipped with conditional sampling and a mechanism of stochastic memoization.", "startOffset": 7, "endOffset": 11}, {"referenceID": 37, "context": "WinBUGS [39] is a popular implementation of the BUGS language [14] for explicitly describing distributions suitable for MCMC analysis.", "startOffset": 8, "endOffset": 12}, {"referenceID": 12, "context": "WinBUGS [39] is a popular implementation of the BUGS language [14] for explicitly describing distributions suitable for MCMC analysis.", "startOffset": 62, "endOffset": 66}, {"referenceID": 30, "context": "FACTORIE [32] is a Scala library for explicitly constructing factor graphs.", "startOffset": 9, "endOffset": 13}, {"referenceID": 6, "context": "Blaise [7] is a software library for building MCMC samplers in Java, that supports compositional construction of sophisticated probabilistic models, and decouples the choice of inference algorithm from the specification of the distribution.", "startOffset": 7, "endOffset": 10}, {"referenceID": 14, "context": "A recent paper [16] based on Fun describes a model-learner pattern which captures common probabilistic programming patterns in machine learning, including various sorts of mixture models.", "startOffset": 15, "endOffset": 19}, {"referenceID": 8, "context": "Probabilistic languages with formal semantics find application in many areas apart from machine learning, including databases [9], model checking [29], differential privacy [34, 47], information flow [30], and cryptography [1].", "startOffset": 126, "endOffset": 129}, {"referenceID": 27, "context": "Probabilistic languages with formal semantics find application in many areas apart from machine learning, including databases [9], model checking [29], differential privacy [34, 47], information flow [30], and cryptography [1].", "startOffset": 146, "endOffset": 150}, {"referenceID": 32, "context": "Probabilistic languages with formal semantics find application in many areas apart from machine learning, including databases [9], model checking [29], differential privacy [34, 47], information flow [30], and cryptography [1].", "startOffset": 173, "endOffset": 181}, {"referenceID": 45, "context": "Probabilistic languages with formal semantics find application in many areas apart from machine learning, including databases [9], model checking [29], differential privacy [34, 47], information flow [30], and cryptography [1].", "startOffset": 173, "endOffset": 181}, {"referenceID": 28, "context": "Probabilistic languages with formal semantics find application in many areas apart from machine learning, including databases [9], model checking [29], differential privacy [34, 47], information flow [30], and cryptography [1].", "startOffset": 200, "endOffset": 204}, {"referenceID": 0, "context": "Probabilistic languages with formal semantics find application in many areas apart from machine learning, including databases [9], model checking [29], differential privacy [34, 47], information flow [30], and cryptography [1].", "startOffset": 223, "endOffset": 226}, {"referenceID": 38, "context": "A recent monograph on semantics for labelled Markov processes [40] focuses on bisimulation-based equational reasoning.", "startOffset": 62, "endOffset": 66}, {"referenceID": 3, "context": "The syntax and semantics of Imp is modelled on the probabilistic language pWhile [4] without observations.", "startOffset": 81, "endOffset": 84}, {"referenceID": 10, "context": "Erwig and Kollmansberger [12] describe a library for probabilistic functional programming in Haskell.", "startOffset": 25, "endOffset": 29}], "year": 2013, "abstractText": "The Bayesian approach to machine learning amounts to computing posterior distributions of random variables from a probabilistic model of how the variables are related (that is, a prior distribution) and a set of observations of variables. There is a trend in machine learning towards expressing Bayesian models as probabilistic programs. As a foundation for this kind of programming, we propose a core functional calculus with primitives for sampling prior distributions and observing variables. We define measure-transformer combinators inspired by theorems in measure theory, and use these to give a rigorous semantics to our core calculus. The original features of our semantics include its support for discrete, continuous, and hybrid measures, and, in particular, for observations of zero-probability events. We compile our core language to a small imperative language that is processed by an existing inference engine for factor graphs, which are data structures that enable many efficient inference algorithms. This allows efficient approximate inference of posterior marginal distributions, treating thousands of observations per second for large instances of realistic models.", "creator": "LaTeX with hyperref package"}}}