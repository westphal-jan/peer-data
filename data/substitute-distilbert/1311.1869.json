{"id": "1311.1869", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Nov-2013", "title": "Optimization, Learning, and Games with Predictable Sequences", "abstract": "we provide several applications of optimistic mirror descent, an online random algorithm based on its idea of predictable sequences. first, one recover the mirror prox algorithm for offline optimization, prove finite extension to holder - smooth functions, to apply the results to saddle - point type problems. next, we prove perform a version of optimistic mirror descent ( which has a close variant to the stationary weights algorithm ) ( be used by two strongly - uncoupled players in a finite zero - sum optimal game to converge to the minimax equilibrium at the rate of o ( ( \u2026 t ) / t ). this addresses a question of daskalakis colleagues in 2011. further, we consider a partial information version of the problem. we then apply the result to convex programming and exhibit a simple algorithm for calculating approximate max gradient problem.", "histories": [["v1", "Fri, 8 Nov 2013 02:47:40 GMT  (22kb)", "http://arxiv.org/abs/1311.1869v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.GT", "authors": ["alexander rakhlin", "karthik sridharan"], "accepted": true, "id": "1311.1869"}, "pdf": {"name": "1311.1869.pdf", "metadata": {"source": "CRF", "title": "Optimization, Learning, and Games with Predictable Sequences", "authors": ["Alexander Rakhlin", "Karthik Sridharan"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n31 1.\n18 69\nv1 [\ncs .L\nG ]\n8 N\nov 2\n01 3\nWe provide several applications of Optimistic Mirror Descent, an online learning algorithm based on the idea of predictable sequences. First, we recover theMirror Prox algorithm for offline optimization, prove an extension to H\u00f6lder-smooth functions, and apply the results to saddle-point type problems. Next, we prove that a version of Optimistic Mirror Descent (which has a close relation to the Exponential Weights algorithm) can be used by two strongly-uncoupled players in a finite zero-summatrix game to converge to the minimax equilibrium at the rate ofO((logT )/T ). This addresses a question of Daskalakis et al [6]. Further, we consider a partial information version of the problem. We then apply the results to convex programming and exhibit a simple algorithm for the approximateMax Flow problem.\n1 Introduction\nRecently, no-regret algorithms have received increasing attention in a variety of communities, including theoretical computer science, optimization, and game theory [3, 1]. The wide applicability of these algorithms is arguably due to the black-box regret guarantees that hold for arbitrary sequences. However, such regret guarantees can be loose if the sequence being encountered is not \u201cworst-case\u201d. The reduction in \u201carbitrariness\u201d of the sequence can arise from the particular structure of the problem at hand, and should be exploited. For instance, in some applications of online methods, the sequence comes from an additional computation done by the learner, thus being far from arbitrary.\nOne way to formally capture the partially benign nature of data is through a notion of predictable sequences [11]. We exhibit applications of this idea in several domains. First, we show that the Mirror Prox method [9], designed for optimizing non-smooth structured saddle-point problems, can be viewed as an instance of the predictable sequence approach. Predictability in this case is due precisely to smoothness of the inner optimization part and the saddle-point structure of the problem. We extend the results to H\u00f6lder-smooth functions, interpolating between the case of well-predictable gradients and \u201cunpredictable\u201d gradients.\nSecond, we address the question raised in [6] about existence of \u201csimple\u201d algorithms that converge at the rate of O\u0303(T\u22121)when employed in an uncoupled manner by players in a zero-sum finite matrix game, yet maintain the usualO(T\u22121/2) rate against arbitrary sequences. We give a positive answer and exhibit a fully adaptive algorithm that does not require the prior knowledge of whether the other player is collaborating. Here, the additional predictability comes from the fact that both players attempt to converge to theminimax value. We also tackle a partial information version of the problemwhere the player has only access to the real-valued payoff of themixed actions played by the two players on each round rather than the entire vector.\nOur third application is to convex programming: optimization of a linear function subject to convex constraints. This problem often arises in theoretical computer science, and we show that the idea of predictable sequences can be used here too. We provide a simple algorithm for \u01eb-approximateMax Flow for a graphwith d edges with time complexity O\u0303(d3/2/\u01eb), a performance previously obtained through a relatively involved procedure [8].\n2 Online Learning with Predictable Gradient Sequences\nLet us describe the online convex optimization (OCO) problem and the basic algorithm studied in [4, 11]. Let F be a convex set of moves of the learner. On round t = 1, . . . ,T , the learner makes a prediction ft \u2208F and observes a convex function Gt onF . The objective is to keep regret\n1\nT T\u2211 t=1 Gt ( ft)\u2212Gt ( f \u2217) small for any f \u2217 \u2208F . LetRbe a 1-strongly convex functionw.r.t. somenorm \u2225\u22c5\u2225onF , and let g0 = argming\u2208F R(g). Suppose that at the beginning of every round t , the learner has access to Mt , a vector computable based on the past observations or side information. In this paper we study the Optimistic Mirror Descent algorithm, defined by the interleaved sequence\nft = argmin f \u2208F \u03b7t \u27e8 f ,Mt \u27e9+DR( f ,gt\u22121) , gt = argmin g\u2208F \u03b7t \u27e8g ,\u2207Gt( ft )\u27e9+DR(g ,gt\u22121) (1) where DR is the Bregman Divergence with respect to R and {\u03b7t} is a sequence of step sizes that can be chosen adaptively based on the sequence observed so far. The method adheres to the OCO protocol since Mt is available at the beginning of round t , and \u2207Gt ( ft ) becomes available after the prediction ft is made. The sequence { ft} will be called primary, while {gt} \u2013 secondary. This method was proposed in [4] for Mt = \u2207Gt\u22121( ft\u22121), and the following lemma is a straightforward extension of the result in [11] for general Mt : Lemma 1. Let F be a convex set in a Banach space B. Let R \u2236 B \u2192 R be a 1-strongly convex function on F with respect to some norm \u2225 \u22c5\u2225, and let \u2225 \u22c5\u2225\u2217 denote the dual norm. For any fixed step-size \u03b7, the Optimistic Mirror Descent Algorithm yields, for any f \u2217 \u2208 F ,\nT\u2211 t=1 Gt( ft )\u2212Gt( f \u2217) \u2264 T\u2211 t=1 \u27e8 ft \u2212 f \u2217,\u2207t \u27e9 \u2264 \u03b7\u22121R2 + T\u2211 t=1 \u2225\u2207t \u2212Mt \u2225\u2217 \u2225gt \u2212 ft \u2225\u2212 12\u03b7 T\u2211 t=1 (\u2225gt \u2212 ft \u22252+\u2225gt\u22121 \u2212 ft \u22252) (2) where R \u2265 0 is such thatDR( f \u2217,g0) \u2264R2 and\u2207t =\u2207Gt ( ft ).\nWhen applying the lemma, we will often use the simple fact that\n\u2225\u2207t \u2212Mt \u2225\u2217 \u2225gt \u2212 ft \u2225 = inf \u03c1>0 {\u03c1 2 \u2225\u2207t \u2212Mt \u22252\u2217+ 12\u03c1 \u2225gt \u2212 ft \u22252} . (3)\nIn particular, by setting \u03c1 = \u03b7, we obtain the (unnormalized) regret bound of \u03b7\u22121R2+(\u03b7/2)\u2211Tt=1 \u2225\u2207t \u2212Mt \u22252\u2217, which is R \u221a 2\u2211Tt=1 \u2225\u2207t \u2212Mt \u22252\u2217 by choosing \u03b7 optimally. Since this choice is not known ahead of time, one may either employ the doubling trick, or choose the step size adaptively:\nCorollary 2. Consider step size\n\u03b7t =Rmaxmin \u23a7\u23aa\u23aa\u23aa\u23a8\u23aa\u23aa\u23aa\u23a9 \u239b \u239d \u00bf\u00c1\u00c1\u00c0t\u22121\u2211 i=1 \u2225\u2207i \u2212Mi \u22252\u2217+ \u00bf\u00c1\u00c1\u00c0t\u22122\u2211 i=1 \u2225\u2207i \u2212Mi \u22252\u2217\u239e\u23a0 \u22121 ,1 \u23ab\u23aa\u23aa\u23aa\u23ac\u23aa\u23aa\u23aa\u23ad with R2max = sup f ,g\u2208F DR( f ,g). Then regret of the Optimistic Mirror Descent algorithm is upper bounded by\n3.5Rmax \u221a\u2211Tt=1 \u2225\u2207t \u2212Mt \u22252\u2217+1 T .\nThese results indicate that tighter regret bounds are possible if one can guess thenext gradient\u2207t by computing Mt . One such case arises in offline optimization of a smooth function, whereby the previous gradient turns out to be a good proxy for the next one. More precisely, suppose we aim to optimize a function G( f ) whose gradients are Lipschitz continuous: \u2225\u2207G( f )\u2212\u2207G(g)\u2225\u2217 \u2264H\u2225 f \u2212 g\u2225 for some H > 0. In this optimization setting, no guessing of Mt is needed: we may simply query the oracle for the gradient and set Mt =\u2207G(gt\u22121). The Optimistic Mirror Descent then becomes\nft = argmin f \u2208F \u03b7t \u27e8 f ,\u2207G(gt\u22121)\u27e9+DR( f ,gt\u22121) , gt = argmin g\u2208F \u03b7t \u27e8g ,\u2207G( ft )\u27e9+DR(g ,gt\u22121) which can be recognized as the Mirror Prox method, due to Nemirovski [9]. By smoothness, \u2225\u2207G( ft )\u2212Mt \u2225\u2217 =\u2225\u2207G( ft )\u2212\u2207G(gt\u22121)\u2225\u2217 \u2264H\u2225 ft \u2212 gt\u22121\u2225. Lemma 1 with Eq. (3) and \u03c1 = \u03b7 = 1/H immediately yields a bound\nT\u2211 t=1 G( ft)\u2212G( f \u2217) \u2264HR2 , which implies that the average f\u0304T = 1T \u2211Tt=1 ft satisfies G( f\u0304T )\u2212G( f \u2217) \u2264 HR2/T , a known bound for Mirror Prox. We now extend this result to arbitrary \u03b1-H\u00f6lder smooth functions, that is convex functions G such that \u2225\u2207G( f )\u2212 \u2207G(g)\u2225\u2217 \u2264H\u2225 f \u2212 g\u2225\u03b1 for all f ,g \u2208F . Lemma 3. Let F be a convex set in a Banach space B and let R \u2236 B\u2192 R be a 1-strongly convex function on F with respect to some norm \u2225 \u22c5\u2225. Let G be a convex \u03b1-H\u00f6lder smooth function with constant H > 0 and \u03b1 \u2208 [0,1]. Then the average f\u0304T = 1T \u2211Tt=1 ft of the trajectory given by Optimistic Mirror Descent Algorithm enjoys\nG( f\u0304T )\u2212 inf f \u2208F G( f ) \u2264 8HR1+\u03b1 T 1+\u03b1 2\nwhere R \u2265 0 is such that sup f \u2208F DR( f ,g0) \u2264R. This result provides a smooth interpolation between the T\u22121/2 rate at \u03b1 = 0 (that is, no predictability of the gradient is possible) and the T\u22121 rate when the smoothness structure allows for a dramatic speed up with a very simple modification of the original Mirror Descent.\n3 Structured Optimization\nIn this section we consider the structured optimization problem\nargmin f \u2208F G( f ) whereG( f ) is of the formG( f ) = supx\u2208X \u03c6( f ,x) with \u03c6(\u22c5,x) convex for every x \u2208 X and \u03c6( f , \u22c5) concave for every f \u2208F . BothF andX are assumed to be convex sets. WhileG itself need not be smooth, it has been recognized that the structure can be exploited to improve rates of optimization if the function \u03c6 is smooth [10]. From the point of view of online learning, wewill see that the optimization problem of the saddle point type can be solved by playing two online convex optimization algorithms against each other (henceforth called Players I and II).\nSpecifically, assume that Player I produces a sequence f1, . . . , fT by using a regret-minimization algorithm, such\nthat\n1\nT T\u2211 t=1 \u03c6( ft ,xt )\u2212 inf f \u2208F 1 T T\u2211 t=1 \u03c6( f ,xt ) \u2264Rate1(x1, . . . ,xT ) (4) and Player II produces x1, . . . ,xT with\n1\nT T\u2211 t=1 (\u2212\u03c6( ft ,xt ))\u2212 inf x\u2208X 1 T T\u2211 t=1 (\u2212\u03c6( ft ,x)) \u2264Rate2( f1, . . . , fT ) . (5)\nBy a standard argument (see e.g. [7]),\ninf f\n1\nT T\u2211 t=1 \u03c6( f ,xt ) \u2264 inf f \u03c6( f , x\u0304T ) \u2264 sup x inf f \u03c6( f ,x) \u2264 inf f sup x \u03c6( f ,x) \u2264 sup x \u03c6( f\u0304T ,x) \u2264 sup x 1 T T\u2211 t=1 \u03c6( ft ,x) where f\u0304T = 1T \u2211Tt=1 ft and x\u0304T = 1T \u2211Tt=1 xt . By adding (4) and (5), we have\nsup x\u2208X\n1\nT T\u2211 t=1 \u03c6( ft ,x)\u2212 inf f \u2208F 1 T T\u2211 t=1 \u03c6( f ,xt ) \u2264Rate1(x1, . . . ,xT )+Rate2( f1, . . . , fT ) (6) which sandwiches the previous sequence of inequalities up to the sum of regret rates and implies near-optimality of f\u0304T and x\u0304T .\nLemma 4. Suppose both players employ the Optimistic Mirror Descent algorithm with, respectively, predictable sequences M1t and M 2 t , 1-strongly convex functions R1 on F (w.r.t. \u2225 \u22c5 \u2225F ) and R2 on X (w.r.t. \u2225 \u22c5 \u2225X ), and fixed\nlearning rates \u03b7 and \u03b7\u2032. Let { ft} and {xt} denote the primary sequences of the players while let {gt},{yt} denote the secondary. Then for any \u03b1,\u03b2 > 0,\nsup x\u2208X \u03c6( f\u0304T ,x)\u2212 inf f \u2208F sup x\u2208X \u03c6( f ,x) (7) \u2264 R21 \u03b7 + \u03b1 2 T\u2211 t=1 \u2225\u2207 f \u03c6( ft ,xt )\u2212M1t \u22252F\u2217 + 12\u03b1 T\u2211 t=1 \u2225gt \u2212 ft \u22252F \u2212 12\u03b7 T\u2211 t=1\n(\u2225gt \u2212 ft \u22252F +\u2225gt\u22121 \u2212 ft \u22252F) + R22 \u03b7\u2032 + \u03b2 2 T\u2211 t=1 \u2225\u2207x\u03c6( ft ,xt )\u2212M2t \u22252X\u2217 + 12\u03b2 T\u2211 t=1 \u2225yt \u2212 xt \u22252X \u2212 12\u03b7\u2032 T\u2211 t=1\n(\u2225yt \u2212 xt \u22252X +\u2225yt\u22121 \u2212 xt \u22252X ) where R1 and R2 are such thatDR1( f \u2217,g0) \u2264R21 andDR2(x\u2217, y0) \u2264R22 , and f\u0304T = 1T \u2211Tt=1 ft .\nThe proof of Lemma 4 is immediate from Lemma 1. We obtain the following corollary:\nCorollary 5. Suppose \u03c6 \u2236F \u00d7X \u21a6R is H\u00f6lder smooth in the following sense: \u2225\u2207 f \u03c6( f ,x)\u2212\u2207f \u03c6(g ,x)\u2225F\u2217 \u2264H1\u2225 f \u2212 g\u2225\u03b1F , \u2225\u2207 f \u03c6( f ,x)\u2212\u2207 f \u03c6( f , y)\u2225F\u2217 \u2264H2\u2225x\u2212 y\u2225\u03b1\u2032X and \u2225\u2207x\u03c6( f ,x)\u2212\u2207x\u03c6(g ,x)\u2225X\u2217 \u2264H4\u2225 f \u2212 g\u2225\u03b2F , \u2225\u2207x\u03c6( f ,x)\u2212\u2207x\u03c6( f , y)\u2225X\u2217 \u2264H3\u2225x\u2212 y\u2225\u03b2\u2032X . Let \u03b3 = min{\u03b1,\u03b1\u2032,\u03b2,\u03b2\u2032}, H = max{H1,H2,H3,H4}. Suppose both players employ Optimistic Mirror Descent with M1t =\u2207 f \u03c6(gt\u22121, yt\u22121) and M2t =\u2207x\u03c6(gt\u22121, yt\u22121), where {gt} and {yt} are the secondary sequences updated by the two algorithms, and with step sizes \u03b7 = \u03b7\u2032 = (R21 +R22) 1\u2212\u03b32 (2H)\u22121 (T2 ) \u03b3\u221212 . Then\nsup x\u2208X \u03c6( f\u0304T ,x)\u2212 inf f \u2208F sup x\u2208X \u03c6( f ,x) \u2264 4H(R21 +R22) 1+\u03b32 T 1+\u03b3 2\n(8)\nAs revealed in the proof of this corollary, the negative terms in (7), that come from an upper bound on regret of Player I, in fact contribute to cancellations with positive terms in regret of Player II, and vice versa. Such a coupling of the upper bounds on regret of the two players can be seen as leading to faster rates under the appropriate assumptions, and this idea will be exploited to a great extent in the proofs of the next section.\n4 Zero-sum Game and Uncoupled Dynamics\nThe notions of a zero-sum matrix game and a minimax equilibrium are arguably the most basic and important notions of game theory. The tight connectionbetween linear programming andminimax equilibrium suggests that theremight be simple dynamics that can lead the two players of the game to eventually converge to the equilibrium\nvalue. Existence of such simple or natural dynamics is of interest in behavioral economics, where one asks whether agents can discover static solution concepts of the game iteratively and without extensive communication.\nMore formally, let A \u2208 [\u22121,1]n\u00d7m be a matrix with bounded entries. The two players aim to find a pair of nearoptimal mixed strategies ( f\u0304 , x\u0304) \u2208 \u2206n \u00d7\u2206m such that f\u0304 TAx\u0304 is close to the minimax value min f \u2208\u2206n maxx\u2208\u2206m f TAx, where \u2206n is the probability simplex over n actions. Of course, this is a particular form of the saddle point problem\nconsidered in the previous section, with \u03c6( f ,x) = f TAx. It is well-known (and follows immediately from (6)) that the players can compute near-optimal strategies by simply playing no-regret algorithms [7]. More precisely, on round t , the players I and II \u201cpredict\u201d the mixed strategies ft and xt and observe Axt and f T t A, respectively. While\nblack-box regretminimization algorithms, such as Exponential Weights, immediately yieldO(T\u22121/2) convergence rates, Daskalakis et al [6] asked whether faster methods exist. To make the problem well-posed, it is required that the two players are strongly uncoupled: neither A nor the number of available actions of the opponent is known to either player, no \u201cfunny bit arithmetic\u201d is allowed, and memory storage of each player allows only for constant number of payoff vectors. The authors of [6] exhibited a near-optimal algorithm that, if used by both players, yields a pair of mixed strategies that constitutes anO( log(m+n)(logT+(log(m+n))3/2) T\n)-approximate minimax equilibrium. Furthermore, the method has a regret bound of the same order as Exponential Weights when faced with an arbitrary sequence. The algorithm in [6] is an application of the excessive gap technique of Nesterov, and requires careful choreography and interleaving of rounds between the two non-communicating players. The authors, therefore, asked whether a simple algorithm (e.g. a modification of Exponential Weights) can in fact achieve the same result. We answer this in the affirmative. While a direct application of Mirror Prox does not yield the result (and also does not provide strong decoupling), belowwe show that amodification of Optimistic Mirror Descent achieves the goal. Furthermore, by choosing the step size adaptively, the same method guarantees the typicalO(T\u22121/2) regret if not faced with a compliant player, thus ensuring robustness.\nIn Section 4.1, we analyze the \u201cfirst-order information\u201d version of the problem, as described above: upon play-\ning the respective mixed strategies ft and xt on round t , Player I observes Axt and Player II observes f T t A. Then, in Section 4.2, we consider an interesting extension to partial information, whereby the players submit their moves ft ,xt but only observe the real value f T t Axt . Recall that in both cases the matrix A is not known to the players.\n4.1 First-Order Information Consider the following simple algorithm. Initialize f0 = g \u20320 \u2208 \u2206n and x0 = y \u20320 \u2208 \u2206m to be uniform distributions, set \u03b2 = 1/T 2 and proceed as follows:\nOn round t, Player I performs\nPlay ft and observe Axt Update gt(i)\u221d g \u2032t\u22121(i)exp{\u2212\u03b7t [Axt ]i}, g \u2032t = (1\u2212\u03b2)gt +(\u03b2/n)1n ft+1(i)\u221d g \u2032t(i)exp{\u2212\u03b7t+1[Axt ]i}\nwhile simultaneously Player II performs\nPlay xt and observe f \u22ba t A Update yt(i)\u221d y \u2032t\u22121(i)exp{\u2212\u03b7\u2032t [ f Tt A]i}, y \u2032t = (1\u2212\u03b2) yt +(\u03b2/m)1m xt+1(i)\u221d y \u2032t (i)exp{\u2212\u03b7\u2032t+1[ f Tt A]i}\nHere, 1n \u2208 Rn is a vector of all ones and both [b]i and b(i) refer to the i -th coordinate of a vector b. Other than the \u201cmixing in\u201d of the uniform distribution, the algorithm for both players is simply the Optimistic Mirror Descent with the (negative) entropy function. In fact, the step of mixing in the uniform distribution is only needed when some coordinate of gt (resp., yt ) is smaller than 1/(nT 2). Furthermore, this step is also not needed if none of the players deviate from the prescribed method. In such a case, the resulting algorithm is simply the constant step-\nsize Exponential Weights ft (i)\u221d exp{\u2212\u03b7\u2211t\u22122s=1[Axs\u22121]i +2\u03b7[Axt\u22121]i}, but with a factor 2 in front of the latest loss vector! Proposition 6. Let A \u2208 [\u22121,1]n\u00d7m , F = \u2206n , X = \u2206m . If both players use above algorithm with, respectively, M1t = Axt\u22121 and M2t = f Tt\u22121A, and the adaptive step sizes \u03b7t =min{log(nT )(\u221a\u2211t\u22121i=1 \u2225Axi \u2212 Axi\u22121\u22252\u2217+\u221a\u2211t\u22122i=1 \u2225Axi \u2212 Axi\u22121\u22252\u2217)\u22121 , 111} and\n\u03b7\u2032t =min{log(mT )(\u221a\u2211t\u22121i=1 \u2225 f Ti A\u2212 f Ti\u22121A\u22252\u2217+ \u221a\u2211t\u22122i=1 \u2225 f Ti A\u2212 f Ti\u22121A\u22252\u2217)\u22121 , 111}\nrespectively, then the pair ( f\u0304T , x\u0304T ) is an O ( logm+logn+logTT )-approximate minimax equilibrium. Furthermore, if only one player (say, Player I) follows the above algorithm, her regret against any sequence x1, . . . ,xT of plays is\nO\u239b\u239d log(nT )T \u239b\u239d \u00bf\u00c1\u00c1\u00c0 T\u2211 t=1 \u2225Axt \u2212 Axt\u22121\u22252\u2217+1\u239e\u23a0\u239e\u23a0 . (9)\nIn particular, this implies the worst-case regret ofO( log(nT)\u221a T ) in the general setting of online linear optimization. We remark that (9) can give intermediate rates for regret in the case that the second player deviates from the prescribed strategy but produces \u201cstable\u201d moves. For instance, if the second player employs a mirror descent algorithm (or Follow the Regularized Leader / Exponential Weights method) with step size \u03b7, one can typically show stability \u2225xt \u2212 xt\u22121\u2225 =O(\u03b7). In this case, (9) yields the rateO(\u03b7 logT\u221a T\n) for the first player. A typical setting of \u03b7\u221d T\u22121/2 for the second player still ensures theO(logT /T ) regret for the first player.\nLet us finish with a technical remark. The reason for the extra step of \u201cmixing in\u201d the uniform distribution stems from the goal of having an adaptive and robust method that still attainsO(T\u22121/2) regret if the other player deviates from using the algorithm. If one is only interested in the dynamics when both players cooperate, this step is not necessary, and in this case the extraneous logT factor disappears from the above bound, leading to the O ( logn+logm T\n) convergence. On the technical side, the need for the extra step is the following. The adaptive step size result of Corollary 2 involves the term R2max \u2265 supg DR1( f \u2217,g) which is potentially infinite for the negative entropy function R1. It is possible that the doubling trick or the analysis of Auer et al [2] (who encountered the same problem for the Exponential Weights algorithm) can remove the extra logT factor while still preserving the regret minimization property. We also remark that Rmax is small when R1 is instead the p-norm; hence, the use of this regularizer avoids the extraneous logarithmic in T factor while still preserving the logarithmic dependence on n andm. However, projection onto the simplex under the p-norm is not as elegant as the Exponential Weights update.\n4.2 Partial Information\nWe now turn to the partial (or, zero-th order) information model. Recall that the matrix A is not known to the players, yet we are interested in finding \u01eb-optimal minimax strategies. On each round, the two players choose mixed strategies ft \u2208\u2206n and xt \u2208\u2206m , respectively, and observe f Tt Axt . Now the question is, howmany such observations do we need to get to an \u01eb-optimal minimax strategy? Can this be done while still ensuring the usual no-regret rate?\nThe specific setting we consider below requires that on each round t , the two players play four times, and that these four plays are \u03b4-close to each other (that is, \u2225 f it \u2212 f jt \u22251 \u2264 \u03b4 for i , j \u2208 {1, . . . ,4}). Interestingly, up to logarithmic factors, the fast rate of the previous section is possible even in this scenario, but we do require the knowledge of the number of actions of the opposing player (or, an upper bound on this number). We leave it as an open problem the question of whether one can attain the 1/T -type rate with only one play per round.\nPlayer I u1, . . . ,un\u22121 : orthonormal basis of \u2206n Initialize g1 , f1 = 1 n 1n ; Draw i0 \u223cUnif([n\u22121]) At time t = 1 to T Play ft Draw it \u223cUnif([n\u22121]) Observe :\nr+t = ( ft +\u03b4uit\u22121 ) \u22baAxt r\u2212t = ( ft \u2212\u03b4uit\u22121 ) \u22baAxt r\u0304 + t = ( ft +\u03b4uit ) \u22ba Axt r\u0304\u2212t = ( ft \u2212\u03b4uit ) \u22baAxt\nBuild estimates :\na\u0302t = n 2\u03b4 (r+t \u2212 r\u2212t )uit\u22121 a\u0304t =\nn 2\u03b4 (r\u0304+t \u2212 r\u0304\u2212t )uit Update :\ngt (i)\u221d g \u2032t\u22121(i)exp{\u2212\u03b7t a\u0302t (i)} g \u2032t = (1\u2212\u03b2) gt +(\u03b2/n)1 ft+1(i)\u221d g \u2032t (i)exp{\u2212\u03b7t+1 a\u0304t (i)}\nEnd\nPlayer II v1, . . . ,vm\u22121 : orthonormal basis of \u2206m Initialize y1,x1 = 1 m 1m ; Draw j0 \u223cUnif([m\u22121]) At time t = 1 to T Play xt Draw jt \u223cUnif([m\u22121]) Observe :\ns+t = \u2212 f \u22bat A(xt +\u03b4v jt\u22121) s\u2212t = \u2212 f \u22bat A(xt \u2212\u03b4v jt\u22121) s\u0304+t = \u2212 f \u22bat A(xt +\u03b4v jt ) s\u0304\u2212t = \u2212 f \u22bat A(xt \u2212\u03b4v jt )\nBuild estimates :\nb\u0302t = m 2\u03b4 (s+t \u2212 s\u2212t )v jt\u22121 b\u0304t =\nm 2\u03b4 (s\u0304+t \u2212 s\u0304\u2212t )v jt Update :\nyt (i)\u221d y\u2032t\u22121(i)exp{\u2212\u03b7\u2032t b\u0302t (i)} y \u2032 t = (1\u2212\u03b2) yt +(\u03b2/m)1\nxt+1(i)\u221d y\u2032t (i)exp{\u2212\u03b7\u2032t+1b\u0304t (i)} End\nLemma 7. Let A \u2208 [\u22121,1]n\u00d7m , F = \u2206n , X = \u2206m , let \u03b4 be small enough (e.g. exponentially small in m,n,T ), and let \u03b2 = 1/T 2. If both players use above algorithms with the adaptive step sizes\n\u03b7t =min{\u221alog(nT ) \u221a \u2211t\u22121i=1\u2225a\u0302i\u2212a\u0304i\u22121\u22252\u2217\u2212 \u221a\n\u2211t\u22122i=1\u2225a\u0302i\u2212a\u0304i\u22121\u22252\u2217 \u2225a\u0302t\u22121\u2212a\u0304t\u22122\u22252\u2217 , 1 28m \u221a log(mT)}\nand\n\u03b7\u2032t =min \u23a7\u23aa\u23aa\u23a8\u23aa\u23aa\u23a9 \u221a log(mT ) \u221a \u2211t\u22121i=1\u2225b\u0302i\u2212b\u0304i\u22121\u2225 2 \u2217 \u2212 \u221a \u2211t\u22122i=1\u2225b\u0302i\u2212b\u0304i\u22121\u2225 2 \u2217 \u2225b\u0302t\u22121\u2212b\u0304t\u22122\u22252\u2217 , 1 28n \u221a log(nT) \u23ab\u23aa\u23aa\u23ac\u23aa\u23aa\u23ad respectively, then the pair ( f\u0304T , x\u0304T ) is an\nO\u239b\u239d (m log(nT )\u221alog(mT )+n log(mT )\u221alog(nT )) T\n\u239e\u23a0 -approximate minimax equilibrium. Furthermore, if only one player (say, Player I) follows the above algorithm, her regret against any sequence x1, . . . ,xT of plays is bounded by\nO\u239b\u239c\u239d m \u221a log(mT ) log(nT )+n\u221alog(nT )\u2211Tt=1 \u2225xt \u2212 xt\u22121\u22252 T\n\u239e\u239f\u23a0 We leave it as an open problem to find an algorithm that attains the 1/T -type rate when both players only observe the value eTi Ae j = Ai , j upon drawing pure actions i , j from their respective mixed strategies ft ,xt . We hypothesize a rate better than T\u22121/2 is not possible in this scenario.\n5 Approximate Smooth Convex Programming\nIn this section we show how one can use the structured optimization results from Section 3 for approximately solving convex programming problems. Specifically consider the optimization problem\nargmax f \u2208G\nc\u22ba f (10)\ns.t. \u2200i \u2208 [d], Gi( f ) \u2264 1\nwhere G is a convex set and eachGi is anH-smooth convex function. Let the optimal value of the above optimization problem be given by F\u2217 > 0, and without loss of generality assume F\u2217 is known (one typically performs binary search if it is not known). Define the sets F = { f \u2236 f \u2208 G,c\u22ba f = F\u2217} and X =\u2206d . The convex programming problem in (10) can now be reformulated as\nargmin f \u2208F max i\u2208[d] Gi( f ) = argmin f \u2208F sup x\u2208X d\u2211 i=1 x(i)Gi( f ) . (11) This problem is in the saddle-point form, as studied earlier in the paper. Wemay think of the first player as aiming to minimize the above expression over F , while the second player maximizes over a mixture of constraints with the aim of violating at least one of them. Lemma 8. Fix \u03b3,\u01eb > 0. Assume there exists f0 \u2208 G such that c\u22ba f0 \u2265 0 and for every i \u2208 [d], Gi ( f0) \u2264 1\u2212\u03b3. Suppose each Gi is 1-Lipschitz overF . Consider the solution f\u0302T = (1\u2212\u03b1) f\u0304T +\u03b1 f0 where\u03b1 = \u01eb\n\u01eb+\u03b3 and f\u0304T = 1T \u2211Tt=1 ft \u2208F is the average of the trajectory of the procedure in Lemma4 for the optimization problem (11). Let R1(\u22c5) = 12 \u2225\u22c5\u222522 and R2 be the entropy function. Further let B be a known constant such that B \u2265\u2225 f \u2217\u2212 g0\u22252 where g0 \u2208 F is some initialization and f \u2217 \u2208F is the (unknown) solution to the optimization problem. Set \u03b7 = argmin\n\u03b7\u2264H\u22121 {B2 \u03b7 + \u03b7 logd 1\u2212\u03b7H }, \u03b7\u2032 = 1\u03b7 \u2212H, M1t =\u2211di=1 yt\u22121(i)\u2207Gi(gt\u22121) and M2t = (G1(gt\u22121), . . . ,Gd(gt\u22121)). Let number\nof iterations T be such that\nT > 1 \u01eb inf \u03b7\u2264H\u22121 {B2 \u03b7 + \u03b7 logd 1\u2212\u03b7H }\nWe then have that f\u0302T \u2208 G satisfies all d constraints and is \u01eb\u03b3 -approximate, that is c\u22ba f\u0302T \u2265 (1\u2212 \u01eb\n\u03b3 )F\u2217 .\nLemma 8 tells us that using the predictable sequences approach for the two players, one can obtain an \u01eb \u03b3 -\napproximate solution to the smooth convex programming problem in number of iterations at most order 1/\u01eb. If T1 (reps. T2) is the time complexity for single update of the predictable sequence algorithm of Player I (resp. Player\n2), then time complexity of the overall procedure isO(T1+T2 \u01eb ) 5.1 Application to Max-Flow\nWe now apply the above result to the problem of finding Max Flow between a source and a sink in a network, such that the capacity constraint on each edge is satisfied. For simplicity, consider a network where each edge has capacity 1 (the method can be easily extended to the case of varying capacity). Suppose the number of edges d in the network is the same order as number of vertices in the network. The Max Flow problem can be seen as an instance of a convex (linear) programming problem, and we apply the proposed algorithm for structured optimization to obtain an approximate solution.\nFor the Max Flow problem, the sets G and F are given by sets of linear equalities. Further, if we use Euclidean norm squared as regularizer for the flow player, then projection step can be performed in O(d) time using conjugate gradient method. This is because we are simply minimizing Euclidean norm squared subject to equality constraints which is well conditioned. Hence T1 =O(d). Similarly, the Exponential Weights update has time complexityO(d) as there are order d constraints, and so overall time complexity to produce \u01eb approximate solution is given byO(nd), where n is the number of iterations of the proposed procedure.\nOnce again, we shall assume that we know the value of themaximum flow F\u2217 (for, otherwise, we can use binary search to obtain it).\nCorollary 9. Applying the procedure for smooth convex programming from Lemma 8 to the Max Flow problemwith f0 = 0 \u2208 G the 0 flow, the time complexity to compute an \u01eb-approximate Max Flow is bounded by O(d3/2 \u221a logd\n\u01eb ) .\nThis time complexity matches the known result from [8], but with amuch simpler procedure (gradient descent for the flow player and Exponential Weights for the constraints). It would be interesting to see whether the techniques presented here can be used to improve the dependence on d to d4/3 or better while maintaining the 1/\u01eb dependence. While the result of [5] has the improved d4/3 dependence, the complexity in terms of \u01eb ismuchworse.\n6 Discussion\nWe close this paper with a discussion. As we showed, the notion of using extra information about the sequence is a powerful tool with applications in optimization, convex programming, game theory, to name a few. All the applications considered in this paper, however, used some notion of smoothness for constructing the predictable processMt . An interesting direction of further research is to isolate more general conditions under which the next gradient is predictable, perhaps even when the functions are not smooth in any sense. For instance one could use techniques from bundle methods to further restrict the set of possible gradients the function being optimized can have at various points in the feasible set. This could then be used to solve for the right predictable sequence to use so as to optimize the bounds. Using this notion of selecting predictable sequences one can hope to derive adaptive optimization procedures that in practice can provide rapid convergence.\nAcknowledgements: We thank Vianney Perchet for insightful discussions. We gratefully acknowledge the sup-\nport of NSF under grants CAREER DMS-0954737 and CCF-1116928, as well as Dean\u2019s Research Fund.\nReferences\n[1] S. Arora, E. Hazan, and S. Kale. The multiplicative weights update method: A meta-algorithm and applica-\ntions. Theory of Computing, 8(1):121\u2013164, 2012.\n[2] P. Auer, N. Cesa-Bianchi, and C. Gentile. Adaptive and self-confident on-line learning algorithms. Journal of\nComputer and System Sciences, 64(1):48\u201375, 2002.\n[3] N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University Press, 2006.\n[4] C.-K. Chiang, T. Yang, C.-J. Lee, M. Mahdavi, C.-J. Lu, R. Jin, and S. Zhu. Online optimization with gradual\nvariations. In COLT, 2012.\n[5] P. Christiano, J. A Kelner, A. Madry, D. A. Spielman, and S.-H. Teng. Electrical flows, laplacian systems, and\nfaster approximation of maximum flow in undirected graphs. In Proceedings of the 43rd annual ACM symposium on Theory of computing, pages 273\u2013282. ACM, 2011.\n[6] C. Daskalakis, A. Deckelbaum, and A. Kim. Near-optimal no-regret algorithms for zero-sum games. In Pro-\nceedings of the Twenty-Second Annual ACM-SIAM Symposium on Discrete Algorithms, pages 235\u2013254. SIAM, 2011.\n[7] Y. Freund and R. Schapire. Adaptive game playing using multiplicative weights. Games and Economic Behav-\nior, 29(1):79\u2013103, 1999.\n[8] A. Goldberg and S. Rao. Beyond the flow decomposition barrier. Journal of the ACM (JACM), 45(5):783\u2013797,\n1998.\n[9] A. Nemirovski. Prox-method with rate of convergence O(1/t) for variational inequalities with lipschitz contin-\nuous monotone operators and smooth convex-concave saddle point problems. SIAM Journal on Optimization, 15(1):229\u2013251, 2004.\n[10] Y. Nesterov. Smooth minimization of non-smooth functions. Mathematical Programming, 103(1):127\u2013152,\n2005.\n[11] A. Rakhlin and K. Sridharan. Online learning with predictable sequences. In Proceedings of the 26th Annual\nConference on Learning Theory (COLT), 2013.\nProofs\nProof of Lemma 1. For any f \u2217 \u2208F , \u27e8 ft \u2212 f \u2217,\u2207t \u27e9 = \u27e8 ft \u2212 gt ,\u2207t \u2212Mt \u27e9+ \u27e8 ft \u2212 gt ,Mt \u27e9+ \u27e8gt \u2212 f \u2217,\u2207t \u27e9 (12)\nFirst observe that \u27e8 ft \u2212 gt ,\u2207t \u2212Mt \u27e9 \u2264 \u2225 ft \u2212 gt \u2225\u2225\u2207t \u2212Mt\u2225\u2217 . (13) Any update of the form a\u2217 = argmina\u2208A \u27e8a,x\u27e9+DR(a,c) satisfies for any d \u2208 A \u27e8a\u2217\u2212d ,x\u27e9 \u2264DR(d ,c)\u2212DR(d ,a\u2217)\u2212DR(a\u2217,c) . (14) This yields\n\u27e8 ft \u2212 gt ,Mt \u27e9 \u2264 1 \u03b7 (DR(gt ,gt\u22121)\u2212DR(gt , ft )\u2212DR( ft ,gt\u22121)) (15)\nand\n\u27e8gt \u2212 f \u2217,\u2207t \u27e9 \u2264 1 \u03b7 (DR( f \u2217,gt\u22121)\u2212DR( f \u2217,gt )\u2212DR(gt ,gt\u22121)) . (16)\nCombining, \u27e8 ft \u2212 f \u2217,\u2207t \u27e9 is upper bounded by \u2225\u2207t \u2212Mt \u2225\u2217 \u2225ft \u2212 gt\u2225+ 1\u03b7 (DR(gt ,gt\u22121)\u2212DR(gt , ft )\u2212DR( ft ,gt\u22121)) + 1\n\u03b7 (DR( f \u2217,gt\u22121)\u2212DR( f \u2217,gt )\u2212DR(gt ,gt\u22121)))\n= \u2225\u2207t \u2212Mt \u2225\u2217 \u2225 ft \u2212 gt \u2225+ 1\u03b7 (DR( f \u2217,gt\u22121)\u2212DR( f \u2217,gt )\u2212DR(gt , ft )\u2212DR( ft ,gt\u22121)) \u2264 \u2225\u2207t \u2212Mt \u2225\u2217 \u2225 ft \u2212 gt \u2225+ 1\u03b7 (DR( f \u2217,gt\u22121)\u2212DR( f \u2217,gt)\u2212 12 \u2225gt \u2212 ft \u22252 \u2212 12 \u2225gt\u22121 \u2212 ft \u22252) (17)\nwhere in the last step we used strong convexity: for any f , f \u2032, DR( f , f \u2032) \u2265 12 \u2225 f \u2212 f \u2032\u22252. Summing over t = 1, . . . ,T yields, for any f \u2217 \u2208F ,\nT\u2211 t=1 \u27e8 ft \u2212 f \u2217,\u2207t \u27e9\u2264 \u03b7\u22121DR( f \u2217,g0)+ T\u2211 t=1 \u2225\u2207t \u2212Mt \u2225\u2217 \u2225gt \u2212 ft \u2225\u2212 12\u03b7 T\u2211 t=1 (\u2225gt \u2212 ft \u22252+\u2225gt\u22121 \u2212 ft \u22252) . Appealing to convexity ofGt \u2019s completes the proof.\nProof of Corollary 2. Let us re-work the proof of Lemma 1 for the case of a changing \u03b7t . Eq. (15) and (16) are now replaced by\n\u27e8 ft \u2212 gt ,Mt \u27e9 \u2264 1 \u03b7t (DR(gt ,gt\u22121)\u2212DR(gt , ft )\u2212DR( ft ,gt\u22121)) (18) and\n\u27e8gt \u2212 f \u2217,\u2207t \u27e9 \u2264 1 \u03b7t (DR( f \u2217,gt\u22121)\u2212DR( f \u2217,gt )\u2212DR(gt ,gt\u22121)) . (19) The upper bound of Eq. (17) becomes\n\u2225\u2207t \u2212Mt \u2225\u2217 \u2225 ft \u2212 gt\u2225+ 1\u03b7t (DR( f \u2217,gt\u22121)\u2212DR( f \u2217,gt )\u2212 12 \u2225gt \u2212 ft \u22252\u2212 12 \u2225gt\u22121\u2212 ft \u22252) . Summing over t = 1, . . . ,T yields, for any f \u2217 \u2208F ,\nT\u2211 t=1 \u27e8 ft \u2212 f \u2217,\u2207t \u27e9 \u2264 \u03b7\u221211 DR( f \u2217,g0)+ T\u2211 t=2 DR( f \u2217,gt\u22121)( 1 \u03b7t \u2212 1 \u03b7t\u22121 )+ T\u2211 t=1 \u2225\u2207t \u2212Mt \u2225\u2217 \u2225gt \u2212 ft \u2225\n\u2212 T\u2211 t=1 1 2\u03b7t (\u2225gt \u2212 ft \u22252+\u2225gt\u22121\u2212 ft \u22252)\n\u2264 (\u03b7\u221211 +\u03b7\u22121T )R2max+ T\u2211 t=1 \u2225\u2207t \u2212Mt \u2225\u2217 \u2225gt \u2212 ft \u2225\u2212 12 T\u2211 t=1 \u03b7\u22121t (\u2225gt \u2212 ft \u22252+\u2225gt\u22121 \u2212 ft \u22252) (20) Observe that\n\u03b7t =Rmaxmin \u23a7\u23aa\u23aa\u23aa\u23a8\u23aa\u23aa\u23aa\u23a9 1\u221a\u2211t\u22121i=1 \u2225\u2207i \u2212Mi \u22252\u2217 +\u221a\u2211t\u22122i=1 \u2225\u2207i \u2212Mi \u22252\u2217 ,1 \u23ab\u23aa\u23aa\u23aa\u23ac\u23aa\u23aa\u23aa\u23ad (21)\n=Rmaxmin \u23a7\u23aa\u23aa\u23aa\u23a8\u23aa\u23aa\u23aa\u23a9 \u221a\u2211t\u22121i=1 \u2225\u2207i \u2212Mi \u22252\u2217 \u2212\u221a\u2211t\u22122i=1 \u2225\u2207i \u2212Mi \u22252\u2217\u2225\u2207t\u22121 \u2212Mt\u22121\u22252\u2217 ,1 \u23ab\u23aa\u23aa\u23aa\u23ac\u23aa\u23aa\u23aa\u23ad (22) From (21),\n\u03b7\u22121t \u2264R \u22121 maxmax \u23a7\u23aa\u23aa\u23a8\u23aa\u23aa\u23a92 \u00bf\u00c1\u00c1\u00c0t\u22121\u2211 i=1 \u2225\u2207i \u2212Mi \u22252\u2217,1 \u23ab\u23aa\u23aa\u23ac\u23aa\u23aa\u23ad . Using this step size in Equation (20) and defining \u03b71 = 1,\u2211Tt=1 \u27e8 ft \u2212 f \u2217,\u2207t \u27e9 is upper bounded by\nRmax \u239b\u239d2 \u00bf\u00c1\u00c1\u00c0T\u22121\u2211 t=1 \u2225\u2207t \u2212Mt \u22252\u2217+2\u239e\u23a0+ T\u2211 t=1 \u2225\u2207t \u2212Mt \u2225\u2217 \u2225gt \u2212 ft \u2225\u2212 12 T\u2211 t=1\n\u03b7\u22121t (\u2225gt \u2212 ft \u22252+\u2225gt\u22121 \u2212 ft \u22252) \u2264Rmax \u239b\u239d2 \u00bf\u00c1\u00c1\u00c0T\u22121\u2211 t=1 \u2225\u2207t \u2212Mt \u22252\u2217+2\u239e\u23a0+ 12 T\u2211 t=1 \u03b7t+1 \u2225\u2207t \u2212Mt \u22252\u2217+ 12 T\u2211 t=1 \u03b7\u22121t+1 \u2225ft \u2212 gt\u22252\u2212 1 2 T\u2211 t=1\n\u03b7\u22121t \u2225gt \u2212 ft \u22252 where we used (3) with \u03c1 = \u03b7t+1 and dropped one of the positive terms. The last two terms can be upper bounded as\n1\n2 T\u2211 t=1 \u03b7\u22121t+1 \u2225 ft \u2212 gt\u22252\u2212 1 2 T\u2211 t=1 \u03b7\u22121t \u2225gt \u2212 ft \u22252 \u2264 R2max 2 T\u2211 t=1 (\u03b7\u22121t+1 \u2212\u03b7\u22121t ) \u2264 R2max 2 \u03b7\u22121T+1 ,\nyielding an upper bound\nRmax \u239b\u239d2 \u00bf\u00c1\u00c1\u00c0 T\u2211 t=1 \u2225\u2207t \u2212Mt \u22252\u2217+2\u239e\u23a0+ 12 T\u2211 t=1\n\u03b7t+1 \u2225\u2207t \u2212Mt \u22252\u2217 + R2max2 \u03b7\u22121T+1 \u2264 3Rmax \u239b\u239d \u00bf\u00c1\u00c1\u00c0 T\u2211 t=1 \u2225\u2207t \u2212Mt \u22252\u2217+1\u239e\u23a0+ 12 T\u2211 t=1\n\u03b7t+1 \u2225\u2207t \u2212Mt \u22252\u2217 . In view of (21), we arrive at\n3Rmax \u239b\u239d \u00bf\u00c1\u00c1\u00c0 T\u2211 t=1 \u2225\u2207t \u2212Mt \u22252\u2217 +1\u239e\u23a0+ Rmax2 T\u2211 t=1 \u239b\u239d \u00bf\u00c1\u00c1\u00c0 t\u2211 i=1 \u2225\u2207i \u2212Mi \u22252\u2217 \u2212 \u00bf\u00c1\u00c1\u00c0t\u22121\u2211 i=1\n\u2225\u2207i \u2212Mi \u22252\u2217\u239e\u23a0 \u2264 3Rmax \u239b\u239d \u00bf\u00c1\u00c1\u00c0 T\u2211 t=1 \u2225\u2207t \u2212Mt \u22252\u2217 +1\u239e\u23a0+ Rmax2 \u00bf\u00c1\u00c1\u00c0 T\u2211 i=1\n\u2225\u2207i \u2212Mi \u22252\u2217 \u2264 3.5 Rmax \u239b\u239d \u00bf\u00c1\u00c1\u00c0 T\u2211 t=1 \u2225\u2207t \u2212Mt\u22252\u2217 +1\u239e\u23a0\nProof of Lemma 3. Let\u2207t =\u2207G( ft ) and Mt =\u2207G(gt\u22121). Then by Lemma 1 and by H\u00f6lder smoothness, T\u2211 t=1 \u27e8 ft \u2212 f \u2217,\u2207t \u27e9 \u2264 R2 \u03b7 +H T\u2211 t=1 \u2225gt \u2212 ft \u22251+\u03b1\u2212 1 2\u03b7 T\u2211 t=1\n\u2225gt \u2212 ft \u22252 . (23) We can re-write the middle term in the upper bound as\nH T\u2211 t=1 \u2225gt \u2212 ft \u22251+\u03b1 = T\u2211 t=1 H ((1+\u03b1)\u03b7) 1+\u03b12 ( \u2225gt \u2212 ft \u2225\u221a(1+\u03b1)\u03b7) 1+\u03b1\n\u2264 ( T\u2211 t=1 H 2\n1\u2212\u03b1 ((1+\u03b1)\u03b7) 1+\u03b11\u2212\u03b1 ) 1\u2212\u03b1 2 ( T\u2211 t=1 \u2225gt \u2212 ft \u22252(1+\u03b1)\u03b7 ) 1+\u03b1 2\nby H\u00f6lder\u2019s inequality with conjugate powers 1/p = (1\u2212\u03b1)/2 and 1/q = (1+\u03b1)/2. We further upper bound the last term using AM-GM inequality as\n1\u2212\u03b1 2 (TH 21\u2212\u03b1 (1+\u03b1) 1+\u03b11\u2212\u03b1 \u03b7 1+\u03b11\u2212\u03b1 )+ 1 2\u03b7 T\u2211 t=1 \u2225gt \u2212 ft \u22252 . Plugging into (23),\nT\u2211 t=1 \u27e8 ft \u2212 f \u2217,\u2207t \u27e9 \u2264 R2 \u03b7 + 1\u2212\u03b1 2 (TH 21\u2212\u03b1 (1+\u03b1) 1+\u03b11\u2212\u03b1 \u03b7 1+\u03b11\u2212\u03b1 ) .\nSetting \u03b7 =R1\u2212\u03b1H\u22121(1+\u03b1)\u2212 1+\u03b12 (1\u2212\u03b1)\u2212 1\u2212\u03b12 T\u2212 1\u2212\u03b12 yields an upper bound of T\u2211 t=1 \u27e8 ft \u2212 f \u2217,\u2207t \u27e9 \u2264HR1+\u03b1(1+\u03b1) 1+\u03b12 (1\u2212\u03b1) 1\u2212\u03b12 T 1\u2212\u03b12 \u2264 8HR1+\u03b1T 1\u2212\u03b12 .\nProof of Corollary 5. Using Lemma 4,\nsup x\u2208X \u03c6( 1 T T\u2211 t=1 ft ,x)\u2212 inf f \u2208F sup x\u2208X \u03c6( f ,x) \u2264 R21\n\u03b7 + \u03b7 2 T\u2211 t=1 \u2225\u2207 f \u03c6( ft ,xt )\u2212\u2207 f \u03c6(gt\u22121, yt\u22121)\u22252F\u2217 \u2212 12\u03b7 T\u2211 t=1 \u2225gt\u22121\u2212 ft \u22252F + R22\n\u03b7\u2032 + \u03b7\u2032 2 T\u2211 t=1 \u2225\u2207x\u03c6( ft ,xt )\u2212\u2207x\u03c6(gt\u22121, yt\u22121)\u22252X\u2217 \u2212 12\u03b7\u2032 T\u2211 t=1 \u2225yt\u22121 \u2212 xt \u22252X Using \u2225a+b\u22252 \u2264 2\u2225a\u22252+2\u2225b\u22252 and the smoothness assumption yields\n\u03b7\n2 T\u2211 t=1 \u2225\u2207 f \u03c6( ft ,xt )\u2212\u2207 f \u03c6(gt\u22121, yt\u22121)\u22252F\u2217 \u2264 \u03b7\nT\u2211 t=1 \u2225\u2207 f \u03c6( ft ,xt )\u2212\u2207 f \u03c6(gt\u22121,xt )\u22252F\u2217 +\u03b7 T\u2211 t=1 \u2225\u2207 f \u03c6(gt\u22121,xt )\u2212\u2207 f \u03c6(gt\u22121, yt\u22121)\u22252F\u2217 \u2264 \u03b7H21\nT\u2211 t=1 \u2225 ft \u2212 gt\u22121\u22252\u03b1F +\u03b7H22 T\u2211 t=1 \u2225xt \u2212 yt\u22121\u22252\u03b1\u2032X and similarly\n\u03b7\u2032\n2 T\u2211 t=1 \u2225\u2207x\u03c6( ft ,xt )\u2212\u2207x\u03c6(gt\u22121, yt\u22121)\u22252X\u2217 \u2264 \u03b7\u2032\nT\u2211 t=1 \u2225\u2207x\u03c6( ft ,xt )\u2212\u2207x\u03c6( ft , yt\u22121)\u22252X\u2217 +\u03b7\u2032 T\u2211 t=1 \u2225\u2207x\u03c6( ft , yt\u22121)\u2212\u2207x\u03c6(gt\u22121, yt\u22121)\u22252X\u2217 \u2264 \u03b7\u2032H23\nT\u2211 t=1 \u2225xt \u2212 yt\u22121\u22252\u03b2\u2032X +\u03b7\u2032H24 T\u2211 t=1 \u2225 ft \u2212 gt\u22121\u22252\u03b2F . Combining, we get the upper bound of\nR21 \u03b7 + T\u2211 t=1 (4\u03b1\u03b7)\u03b1\u03b7H21 (\u2225 ft \u2212 gt\u22121\u2225F\u221a 4\u03b1\u03b7 )2\u03b1+ T\u2211 t=1 (4\u03b1\u2032\u03b7\u2032)\u03b1\u2032\u03b7H22 (\u2225xt \u2212 yt\u22121\u2225X\u221a 4\u03b1\u2032\u03b7\u2032 )2\u03b1 \u2032 \u2212 1 2\u03b7 T\u2211 t=1\n\u2225gt\u22121 \u2212 ft \u22252F + R22 \u03b7\u2032 + T\u2211 t=1 (4\u03b2\u2032\u03b7\u2032)\u03b2\u2032\u03b7\u2032H23 (\u2225xt \u2212 yt\u22121\u2225X\u221a 4\u03b2\u2032\u03b7\u2032 )2\u03b2 \u2032 + T\u2211 t=1 (4\u03b2\u03b7)\u03b2\u03b7\u2032H24 (\u2225 ft \u2212 gt\u22121\u2225F\u221a 4\u03b2\u03b7 )2\u03b2\u2212 1 2\u03b7\u2032 T\u2211 t=1\n\u2225yt\u22121 \u2212 xt \u22252X As in the proof of Lemma 3, we use H\u00f6lder inequality to further upper bound by\nR21 \u03b7 + R22 \u03b7\u2032 \u2212 1 2\u03b7 T\u2211 t=1 \u2225gt\u22121\u2212 ft \u22252F \u2212 12\u03b7\u2032 T\u2211 t=1 \u2225yt\u22121 \u2212 xt \u22252X (24) +(T (4\u03b1\u03b7) \u03b11\u2212\u03b1 \u03b7 11\u2212\u03b1 H 21\u2212\u03b11 )1\u2212\u03b1( T\u2211\nt=1\n\u2225 ft \u2212 gt\u22121\u22252F 4\u03b1\u03b7 )\u03b1+(T (4\u03b1\u2032\u03b7\u2032) \u03b1\u20321\u2212\u03b1\u2032 \u03b7 11\u2212\u03b1\u2032 H 21\u2212\u03b1\u20322 )1\u2212\u03b1 \u2032 ( T\u2211\nt=1\n\u2225xt \u2212 yt\u22121\u22252X 4\u03b1\u2032\u03b7\u2032 )\u03b1 \u2032\n+(T (4\u03b2\u2032\u03b7\u2032) \u03b2\u20321\u2212\u03b2\u2032 \u03b7\u2032 11\u2212\u03b2\u2032 H 21\u2212\u03b2\u20323 ) 1\u2212\u03b2\u2032 ( T\u2211\nt=1\n\u2225xt \u2212 yt\u22121\u22252X 4\u03b2\u2032\u03b7\u2032 )\u03b2 \u2032 +(T (4\u03b2\u03b7) \u03b21\u2212\u03b2 \u03b7\u2032 11\u2212\u03b2 H 21\u2212\u03b24 )1\u2212\u03b2( T\u2211 t=1 \u2225 ft \u2212 gt\u22121\u22252F 4\u03b2\u03b7 )\u03b2\n\u2264 R21 \u03b7 + R22 \u03b7\u2032 +((1\u2212\u03b1)(4\u03b1\u03b7) \u03b11\u2212\u03b1 \u03b7 11\u2212\u03b1 H 21\u2212\u03b11 )T +((1\u2212\u03b1\u2032)(4\u03b1\u2032\u03b7\u2032) \u03b1\u20321\u2212\u03b1\u2032 \u03b7 11\u2212\u03b1\u2032 H 21\u2212\u03b1\u20322 )T +((1\u2212\u03b2\u2032)(4\u03b2\u2032\u03b7\u2032) \u03b2\u20321\u2212\u03b2\u2032 \u03b7\u2032 11\u2212\u03b2\u2032 H 21\u2212\u03b2\u20323 )T +((1\u2212\u03b2)(4\u03b2\u03b7) \u03b21\u2212\u03b2 \u03b7\u2032 11\u2212\u03b2 H 21\u2212\u03b24 )T\nSetting \u03b7 = \u03b7\u2032 we get an upper bound of R21 +R 2 2\n\u03b7 +((1\u2212\u03b1)(4\u03b1) \u03b11\u2212\u03b1 \u03b7 1+\u03b11\u2212\u03b1 H 21\u2212\u03b11 )T +((1\u2212\u03b1\u2032)(4\u03b1\u2032) \u03b1\u20321\u2212\u03b1\u2032 \u03b7 1+\u03b1\u20321\u2212\u03b1\u2032 H 21\u2212\u03b1\u20322 )T\n+((1\u2212\u03b2\u2032)(4\u03b2\u2032) \u03b2\u20321\u2212\u03b2\u2032 \u03b7 1+\u03b2\u20321\u2212\u03b2\u2032 H 21\u2212\u03b2\u20323 )T +((1\u2212\u03b2)(4\u03b2) \u03b21\u2212\u03b2 \u03b7 1+\u03b21\u2212\u03b2 H 21\u2212\u03b24 )T \u2264 R21 +R 2 2\n\u03b7 +((1\u2212\u03b1)(\u03b1) \u03b11\u2212\u03b1 \u03b7 1+\u03b11\u2212\u03b1 (2H1) 21\u2212\u03b1 )T +((1\u2212\u03b1\u2032)(\u03b1\u2032) \u03b1\u20321\u2212\u03b1\u2032 \u03b7 1+\u03b1\u20321\u2212\u03b1\u2032 (2H2) 21\u2212\u03b1\u2032 )T\n+((1\u2212\u03b2\u2032)(\u03b2\u2032) \u03b2\u20321\u2212\u03b2\u2032 \u03b7 1+\u03b2\u20321\u2212\u03b2\u2032 (2H3) 21\u2212\u03b2\u2032 )T +((1\u2212\u03b2)(\u03b2) \u03b21\u2212\u03b2 \u03b7 1+\u03b21\u2212\u03b2 (2H4) 21\u2212\u03b2 )T \u2264 R21 +R 2 2\n\u03b7 +(\u03b7 1+\u03b11\u2212\u03b1 (2H1) 21\u2212\u03b1 )T +(\u03b7 1+\u03b1\u20321\u2212\u03b1\u2032 (2H2) 21\u2212\u03b1\u2032 )T\n+(\u03b7 1+\u03b2\u20321\u2212\u03b2\u2032 (2H3) 21\u2212\u03b2\u2032 )T +(\u03b7 1+\u03b21\u2212\u03b2 (2H4) 21\u2212\u03b2 )T \u2264 R21 +R 2 2\n\u03b7 +(2H\u03b7) 1+\u03b31\u2212\u03b3 HT\nFinally picking step size as \u03b7 = (R21 +R22) 1\u2212\u03b32 (2H)\u22121 (T2 ) \u03b3\u221212 we conclude that sup x\u2208X \u03c6( 1 T T\u2211 t=1 ft ,x)\u2212 inf f \u2208F sup x\u2208X \u03c6( f ,x) \u2264 4H(R21 +R22) 1+\u03b32 T 1+\u03b3 2\n(25)\nProof of Proposition 6. Let R1( f ) = \u2211ni=1 f (i) ln f (i) and, respectively, R2(x) = \u2211mi=1 x(i) lnx(i). These functions are strongly convex with respect to \u2225 \u22c5 \u22251 norm on the respective flat simplex. We first upper bound regret of Player I, writing \u2207t as a generic observation vector, later to be chosen as Axt , and Mt as a generic predictable\nsequence, later chosen to be Axt\u22121. Observe that \u2225g \u2032t \u2212 gt\u22251 \u2264 1/T 2. Let f \u2217 = ei\u2217 be a vertex of the simplex. Then \u27e8 ft \u2212 f \u2217,\u2207t \u27e9 = \u27e8 ft \u2212 gt ,\u2207t \u2212Mt \u27e9+ \u27e8 ft \u2212 gt ,Mt \u27e9+ \u27e8gt \u2212 f \u2217,\u2207t \u27e9\nBy the update rule,\n\u27e8 ft \u2212 gt ,Mt \u27e9 \u2264 1 \u03b7t (DR1(gt ,g \u2032t\u22121)\u2212DR1(gt , ft )\u2212DR1( ft ,g \u2032t\u22121)) and\n\u27e8gt \u2212 f \u2217,\u2207t \u27e9\u2264 1 \u03b7t (DR1( f \u2217,g \u2032t\u22121)\u2212DR1( f \u2217,gt)\u2212DR1(gt ,g \u2032t\u22121)) . We conclude that \u27e8 ft \u2212 f \u2217,\u2207t \u27e9 is upper bounded by\n\u2225\u2207t \u2212Mt \u2225\u2217 \u2225 ft \u2212 gt\u2225+ 1\u03b7t (DR1(gt ,g \u2032t\u22121)\u2212DR1(gt , ft )\u2212DR1( ft ,g \u2032t\u22121)) + 1\n\u03b7t (DR1( f \u2217,g \u2032t\u22121)\u2212DR1( f \u2217,gt )\u2212DR1(gt ,g \u2032t\u22121)))\n= \u2225\u2207t \u2212Mt \u2225\u2217 \u2225 ft \u2212 gt\u2225+ 1\u03b7t (DR1( f \u2217,g \u2032t\u22121)\u2212DR1( f \u2217,gt )\u2212DR1(gt , ft )\u2212DR1( ft ,g \u2032t\u22121))\nUsing strong convexity, the term involving the four divergences can be further upper bounded by\n1 \u03b7t (DR1( f \u2217,g \u2032t\u22121)\u2212DR1( f \u2217,gt)\u2212 12 \u2225gt \u2212 ft \u22252 \u2212 12 \u2225g \u2032t\u22121 \u2212 ft \u22252) = 1 \u03b7t\n(DR1( f \u2217,g \u2032t\u22121)\u2212DR1( f \u2217,g \u2032t)\u2212 12 \u2225gt \u2212 ft \u22252 \u2212 12 \u2225g \u2032t\u22121 \u2212 ft \u22252) + 1\n\u03b7t (DR1( f \u2217,g \u2032t )\u2212DR1( f \u2217,gt))\n= 1 \u03b7t (DR1( f \u2217,g \u2032t\u22121)\u2212DR1( f \u2217,g \u2032t)\u2212 12 \u2225gt \u2212 ft \u22252 \u2212 12 \u2225g \u2032t\u22121 \u2212 ft \u22252)+ 1\u03b7t ln gt(i \u2217)\ng \u2032t(i\u2217) where f \u2217 is 1 on coordinate i\u2217 and 0 everywhere else, and the norm is the \u21131 norm. Now let us bound the last term. First, whenever g \u2032t(i\u2217) \u2265 gt(i\u2217) the term is negative. Since g \u2032t(i\u2217) = (1\u22121/T 2)gt(i\u2217)+1/(nT 2) this happens whenever gt(i\u2217) \u2264 1/n. On the other hand, for gt(i\u2217) > 1/n we can bound\nln gt(i\u2217) g \u2032t(i\u2217) = ln gt(i\u2217)(1\u22121/T 2)gt(i\u2217)+1/(nT 2) \u2264 2T 2 . Using the above in the bound on \u27e8 ft \u2212 f \u2217,\u2207t \u27e9 and summing over t = 1, . . . ,T , and using the fact that the step size are non-increasing, we conclude that\nT\u2211 t=1 \u27e8 ft \u2212 f \u2217,\u2207t \u27e9\u2264 \u03b7\u221211 DR1( f \u2217,g0)+ T\u2211 t=2 DR1( f \u2217,g \u2032t\u22121)( 1\u03b7t \u2212 1\u03b7t\u22121 )+ T\u2211 t=1 \u2225\u2207t \u2212Mt \u2225\u2217 \u2225gt \u2212 ft \u2225 \u2212\nT\u2211 t=1 1 2\u03b7t (\u2225gt \u2212 ft \u22252+\u2225g \u2032t\u22121\u2212 ft \u22252)+ 2 T 2 T\u2211 t=1 1 \u03b7t\n\u2264 (\u03b7\u221211 +\u03b7\u22121T )R21,max+ T\u2211 t=1 \u2225\u2207t \u2212Mt \u2225\u2217 \u2225gt \u2212 ft \u2225\u2212 12 T\u2211 t=1 \u03b7\u22121t (\u2225gt \u2212 ft \u22252+\u2225g \u2032t\u22121 \u2212 ft \u22252) + 2\nT 2 T\u2211 t=1 1 \u03b7t . (26)\nwhere R21,max is an upper bound on the largest KL divergence between f \u2217 and any g \u2032 that has all coordinates at least 1/(nT 2). Since f \u2217 is a vertex of the flat simplex, we may take R21,max \u225c log(nT 2). Also note that 1/\u03b7t \u2264 c\u221aT and so 2\nT 2 \u2211Tt=1 1\u03b7t \u2264 cT 1/2 \u2264 1 for T large enough. Hence we conclude that a bound on regret of Player I is given by T\u2211 t=1 \u27e8 ft \u2212 f \u2217,\u2207t \u27e9 \u2264 (\u03b7\u221211 +\u03b7\u22121T )R21,max+ T\u2211 t=1 \u2225Axt \u2212 Axt\u22121\u2225\u2217 \u2225gt \u2212 ft \u2225\u2212 12 T\u2211 t=1\n\u03b7\u22121t (\u2225g \u2032t \u2212 ft \u22252+\u2225g \u2032t\u22121\u2212 ft \u22252)+1 (27) Observe that\n\u03b7t =min \u23a7\u23aa\u23aa\u23aa\u23a8\u23aa\u23aa\u23aa\u23a9R 2 1,max \u221a\u2211t\u22121i=1 \u2225Axi \u2212 Axi\u22121\u22252\u2217\u2212\u221a\u2211t\u22122i=1 \u2225Axi \u2212 Axi\u22121\u22252\u2217\u2225Axt\u22121 \u2212 Axt\u22122\u22252\u2217 , 1 11 \u23ab\u23aa\u23aa\u23aa\u23ac\u23aa\u23aa\u23aa\u23ad and\n11 \u2264 \u03b7\u22121t \u2264max{2R\u221221,max\u221a\u2211t\u22121i=1 \u2225Axi \u2212 Axi\u22121\u22252\u2217,11} With this, the upper bound on Player I\u2019s unnormalized regret is\n1+22R21,max +2 \u00bf\u00c1\u00c1\u00c0T\u22121\u2211 t=1 \u2225Axt \u2212 Axt\u22121\u22252\u2217+ T\u2211 t=1 \u2225Axt \u2212 Axt\u22121\u2225\u2217 \u2225gt \u2212 ft \u2225\u2212 112 T\u2211 t=1 (\u2225gt \u2212 ft \u22252+\u2225g \u2032t\u22121\u2212 ft \u22252)\nAdding the regret of the second player who uses step size \u03b7\u2032t , the overall bound on the suboptimality, as in Eq. (6), is\n2+22R21,max +2 \u00bf\u00c1\u00c1\u00c0T\u22121\u2211 t=1 \u2225Axt \u2212 Axt\u22121\u22252\u2217+ T\u2211 t=1\n\u2225Axt \u2212 Axt\u22121\u2225\u2217 \u2225gt \u2212 ft \u2225 +22R22,max +2 \u00bf\u00c1\u00c1\u00c0T\u22121\u2211 t=1 \u2225 f Tt A\u2212 f Tt\u22121A\u22252\u2217+ T\u2211 t=1\n\u2225 f Tt A\u2212 f Tt\u22121A\u2225\u2217 \u2225yt \u2212 xt \u2225 \u2212 11\n2 T\u2211 t=1 (\u2225gt \u2212 ft \u22252+\u2225g \u2032t\u22121 \u2212 ft \u22252)\u2212 11 2 T\u2211 t=1 (\u2225yt \u2212 xt \u22252+\u2225y \u2032t\u22121 \u2212 xt \u22252) By over-bounding with \u221a c \u2264 c +1 for c \u2265 0, we obtain an upper bound\nT\u2211 t=1 \u27e8 ft \u2212 f \u2217,\u2207t \u27e9 \u2264 6+22R21,max +2T\u22121\u2211 t=1 \u2225Axt \u2212 Axt\u22121\u22252\u2217+ T\u2211 t=1 \u2225Axt \u2212 Axt\u22121\u2225\u2217 \u2225g \u2032t \u2212 ft \u2225 +22R22,max +2\nT\u22121\u2211 t=1 \u2225 f Tt A\u2212 f Tt\u22121A\u22252\u2217+ T\u2211 t=1 \u2225 f Tt A\u2212 f Tt\u22121A\u2225\u2217 \u2225y \u2032t \u2212 xt \u2225 \u2212 11\n2 T\u2211 t=1 (\u2225g \u2032t \u2212 ft \u22252 +\u2225g \u2032t\u22121\u2212 ft \u22252)\u2212 11 2 T\u2211 t=1 (\u2225y \u2032t \u2212 xt \u22252+\u2225y \u2032t\u22121 \u2212 xt \u22252) \u2264 6+22R21,max + 5\n2 T\u2211 t=1 \u2225Axt \u2212 Axt\u22121\u22252\u2217+ 12 T\u2211 t=1 \u2225gt \u2212 ft \u22252 +22R22,max + 5\n2 T\u2211 t=1 \u2225 f Tt A\u2212 f Tt\u22121A\u22252\u2217 + 12 T\u2211 t=1 \u2225yt \u2212 xt \u22252 \u2212 11\n2 T\u2211 t=1 (\u2225gt \u2212 ft \u22252 +\u2225g \u2032t\u22121\u2212 ft \u22252)\u2212 11 2 T\u2211 t=1 (\u2225yt \u2212 xt \u22252+\u2225y \u2032t\u22121 \u2212 xt \u22252) Since each entry of the matrix is bounded by 1, \u2225Axt \u2212 Axt\u22121\u22252\u2217 \u2264 \u2225xt \u2212 xt\u22121\u22252 \u2264 2\u2225xt \u2212 y \u2032t\u22121\u22252 +2\u2225xt\u22121 \u2212 y \u2032t\u22121\u22252 and similar inequality holds for the other player too. This leads to an upper bound of\n6+22R21,max +22R 2 2,max +\n1\n2 T\u2211 t=1 \u2225yt \u2212 xt \u22252+ 1 2 T\u2211 t=1 \u2225gt \u2212 ft \u22252 +5\nT\u2211 t=1 (\u2225g \u2032t \u2212 ft \u22252+\u2225g \u2032t\u22121 \u2212 ft \u22252)+5 T\u2211 t=1 (\u2225y \u2032t \u2212 xt \u22252+\u2225y \u2032t\u22121 \u2212 xt \u22252) \u2212 11\n2 T\u2211 t=1 (\u2225gt \u2212 ft \u22252+\u2225g \u2032t\u22121\u2212 ft \u22252)\u2212 11 2 T\u2211 t=1 (\u2225yt \u2212 xt \u22252+\u2225y \u2032t\u22121 \u2212 xt \u22252) \u2264 6+22R21,max +22R 2 2,max\n+5 T\u2211 t=1 (\u2225g \u2032t \u2212 ft \u22252\u2212\u2225gt \u2212 ft \u22252)+5 T\u2211 t=1 (\u2225y \u2032t \u2212 xt \u22252\u2212\u2225yt \u2212 xt \u22252) . (28) Now note that\n\u2225g \u2032t \u2212 ft \u22252\u2212\u2225gt \u2212 ft \u22252 = (\u2225g \u2032t \u2212 ft \u2225+\u2225gt \u2212 ft \u2225)(\u2225g \u2032t \u2212 ft \u2225\u2212\u2225gt \u2212 ft \u2225) \u2264 (\u2225g \u2032t \u2212 ft \u2225+\u2225gt \u2212 ft \u2225)(\u2225g \u2032t \u2212 g \u2032t\u2225) \u2264 4\nT 2 (29)\nSimilarly we also have that \u2225y \u2032t \u2212 xt \u22252 \u2212\u2225yt \u2212 xt \u22252 \u2264 4T 2 . Using these in Eq. (28) we conclude that the overall bound on the suboptimality is\n6+22R21,max +22R 2 2,max +\n40 T = 6+22log(nT 2)+22log(mT 2)+ 40 T\n= 6+22log(nmT 4)+ 40 T .\nThis proves the result for the case when both players adhere to the prescribed algorithm. Now, consider the case when Player I adheres, but we do not make any assumption about Player II. Then, from Eq. (27) and Eq. (3) with \u03c1 = \u03b7t , the upper bound on,\u2211Tt=1 \u27e8 ft \u2212 f \u2217,\u2207t \u27e9, the unnormalized regret of Player I\u2019s is (\u03b7\u221211 +\u03b7\u22121T )R21,max+1+ T\u2211\nt=1 \u2225Axt \u2212 Axt\u22121\u2225\u2217 \u2225gt \u2212 ft \u2225\u2212 12 T\u2211 t=1 \u03b7\u22121t (\u2225gt \u2212 ft \u22252+\u2225g \u2032t\u22121 \u2212 ft \u22252) \u2264 22R21,max +1+2 \u00bf\u00c1\u00c1\u00c0T\u22121\u2211 t=1 \u2225Axt \u2212 Axt\u22121\u22252\u2217+ T\u2211 t=1 \u2225Axt \u2212 Axt\u22121\u2225\u2217 \u2225gt \u2212 ft \u2225\u2212 12 T\u2211 t=1 \u03b7\u22121t \u2225gt \u2212 ft \u22252\n\u2264 22R21,max +1+2 \u00bf\u00c1\u00c1\u00c0T\u22121\u2211 t=1 \u2225Axt \u2212 Axt\u22121\u22252\u2217+ 12 T\u2211 t=1 \u03b7t+1 \u2225Axt \u2212 Axt\u22121\u22252\u2217+ 12 T\u2211 t=1\n(\u03b7\u22121t+1 \u2212\u03b7\u22121t )\u2225gt \u2212 ft \u22252 . Now, using the definition of the stepsize,\n1\n2 T\u2211 t=1 \u03b7t+1 \u2225Axt \u2212 Axt\u22121\u22252\u2217 \u2264 R21,max2 T\u2211 t=1 \u239b\u239d \u00bf\u00c1\u00c1\u00c0 t\u2211 i=1 \u2225Axi \u2212 Axi\u22121\u22252\u2217\u2212 \u00bf\u00c1\u00c1\u00c0t\u22121\u2211 i=1\n\u2225Axi \u2212 Axi\u22121\u22252\u2217\u239e\u23a0 \u2264 R21,max\n2 \u00bf\u00c1\u00c1\u00c0 T\u2211 i=1\n\u2225Axi \u2212 Axi\u22121\u22252\u2217 while\n1\n2 T\u2211 t=1 (\u03b7\u22121t+1 \u2212\u03b7\u22121t )\u2225gt \u2212 ft \u22252 \u2264 2 T\u2211 t=1 (\u03b7\u22121t+1 \u2212\u03b7\u22121t ) \u2264 4\u03b7\u22121T+1 Combining, we get an upper bound of\n22R21,max +1+2 \u00bf\u00c1\u00c1\u00c0T\u22121\u2211 t=1 \u2225Axt \u2212 Axt\u22121\u22252\u2217+ R21,max2 \u00bf\u00c1\u00c1\u00c0 T\u2211 i=1 \u2225Axi \u2212 Axi\u22121\u22252\u2217\n+4max \u23a7\u23aa\u23aa\u23a8\u23aa\u23aa\u23a92R \u22122 1,max \u00bf\u00c1\u00c1\u00c0 T\u2211 i=1 \u2225Axi \u2212 Axi\u22121\u22252\u2217,11 \u23ab\u23aa\u23aa\u23ac\u23aa\u23aa\u23ad\n\u2264 22R21,max +45+10 \u00bf\u00c1\u00c1\u00c0 T\u2211 t=1 \u2225Axt \u2212 Axt\u22121\u22252\u2217+ R21,max2 \u00bf\u00c1\u00c1\u00c0 T\u2211 i=1 \u2225Axi \u2212 Axi\u22121\u22252\u2217\n\u2264 22R21,max +45+ 20+R21,max\n2\n\u00bf\u00c1\u00c1\u00c0 T\u2211 t=1\n\u2225Axt \u2212 Axt\u22121\u22252\u2217 concluding the proof.\nProof of Lemma 7. We start with the observation that a\u0302t and a\u0304t\u22121 are unbiased estimates of Axt and Axt\u22121 respectively. Thats is Eit\u22121 [a\u0302t ]= Axt and Eit\u22121 [a\u0304t\u22121] = Axt\u22121. Hence we have\nE[ T\u2211 t=1 f \u22bat Axt \u2212 inf f \u2208\u2206n T\u2211 t=1 f \u22baAxt] \u2264 E[ T\u2211 t=1 \u27e8 ft , a\u0302t \u27e9\u2212 inf f \u2208\u2206n T\u2211 t=1 \u27e8 f , a\u0302t \u27e9]\nUsing the same line of proof as the one used to arrive at Eq. (27) in Proposition 6, we get that the unnormalized regret for Player I can be upper bounded as,\nE[ T\u2211 t=1 f \u22bat Axt \u2212 inf f \u2208\u2206n T\u2211 t=1 f \u22baAxt] \u2264 E[(\u03b7\u221211 +\u03b7\u22121T )R21,max+1+ T\u2211\nt=1 \u2225a\u0302t \u2212 a\u0304t\u22121\u2225\u2217 \u2225gt \u2212 ft \u2225\u2212 12 T\u2211 t=1 \u03b7\u22121t (\u2225gt \u2212 ft \u22252+\u2225g \u2032t\u22121\u2212 ft \u22252)] \u2264 E[(\u03b7\u221211 +\u03b7\u22121T )R21,max+1+ T\u2211\nt=1 \u03b7t+1 \u2225a\u0302t \u2212 a\u0304t\u22121\u22252\u2217+ 14 T\u2211 t=1 \u03b7\u22121t+1 \u2225gt \u2212 ft \u22252\n\u2212 1\n2 T\u2211 t=1 \u03b7\u22121t (\u2225gt \u2212 ft \u22252+\u2225g \u2032t\u22121\u2212 ft \u22252)] Since \u2225gt \u2212 ft \u22252 \u2264 4, we upper bound the above by\nE[(\u03b7\u221211 +\u03b7\u22121T )R21,max+1+ T\u2211 t=1 \u03b7t+1 \u2225a\u0302t \u2212 a\u0304t\u22121\u22252\u2217+ T\u2211 t=1 (\u03b7\u22121t+1 \u2212\u03b7\u22121t )\u2212 1 4 T\u2211 t=1 \u03b7\u22121t (\u2225gt \u2212 ft \u22252+\u2225g \u2032t\u22121 \u2212 ft \u22252)] \u2264 E[2R21,max(\u03b7\u221211 +\u03b7\u22121T )+1+ T\u2211\nt=1 \u03b7t+1 \u2225a\u0302t \u2212 a\u0304t\u22121\u22252\u2217\u2212 14 T\u2211 t=1 \u03b7\u22121t (\u2225gt \u2212 ft \u22252+\u2225g \u2032t\u22121\u2212 ft \u22252)] Since\n\u03b7t =min \u23a7\u23aa\u23aa\u23aa\u23a8\u23aa\u23aa\u23aa\u23a9R1,max \u221a\u2211t\u22121i=1 \u2225a\u0302i \u2212 a\u0304i\u22121\u22252\u2217\u2212\u221a\u2211t\u22122i=1 \u2225a\u0302i \u2212 a\u0304i\u22121\u22252\u2217\u2225a\u0302t\u22121\u2212 a\u0304t\u22122\u22252\u2217 , 1 28m R2,max \u23ab\u23aa\u23aa\u23aa\u23ac\u23aa\u23aa\u23aa\u23ad and\n28mR2,max \u2264 \u03b7 \u22121 t \u2264max{2R\u221211,max\u221a\u2211t\u22121i=1 \u2225a\u0302i \u2212 a\u0304i\u22121\u22252\u2217,28m R2,max}\nthe upper bound on Player I\u2019s unnormalized regret is\nE[ T\u2211 t=1 f \u22bat Axt \u2212 inf f \u2208\u2206n T\u2211 t=1 f \u22baAxt] \u2264 56mR2,maxR21,max+1+ 7 2 R1,max \u00bf\u00c1\u00c1\u00c0 T\u2211 t=1\n\u2225a\u0302t \u2212 a\u0304t\u22121\u22252\u2217 (30) \u22127mR2,max\nT\u2211 t=1 (\u2225gt \u2212 ft \u22252+\u2225g \u2032t\u22121\u2212 ft \u22252) Both players are honest : We first consider the case when both players play the prescribed algorithm. In this case, a similar regret bound holds for Player II. Adding the regret of the second player who uses step size \u03b7\u2032t , the overall bound on the suboptimality, as in Eq. (6), is\n2+56R1,maxR2,max (mR1,max+nR2,max)+ 7 2 R1,max \u00bf\u00c1\u00c1\u00c0 T\u2211 t=1 \u2225a\u0302t \u2212 a\u0304t\u22121\u22252\u2217+ 72R2,max \u00bf\u00c1\u00c1\u00c0 T\u2211 t=1 \u2225b\u0302t \u2212 b\u0304t\u22121\u22252\u2217\n\u22127mR2,max T\u2211 t=1 (\u2225gt \u2212 ft \u22252+\u2225g \u2032t\u22121\u2212 ft \u22252)\u22127nR1,max T\u2211 t=1 (\u2225yt \u2212 xt \u22252+\u2225y \u2032t\u22121 \u2212 xt \u22252) Now note that\n\u2225a\u0302t \u2212 a\u0304t\u22121\u2225\u2217 \u2264 n2\u03b4 \u2225uit\u22121\u2225\u2217 \u2223r+t \u2212 r\u2212t + r\u0304\u2212t \u2212 r\u0304+t \u2223 = n2\u03b4 \u2225uit\u22121\u2225\u2217 \u22232\u03b4u\u22bait\u22121 A(xt \u2212 xt\u22121)\u2223 \u2264 n \u2223A(xt \u2212 xt\u22121)\u2223 \u2264 n \u2225xt \u2212 xt\u22121\u2225\nSimilarly we have \u2225b\u0302t \u2212 b\u0304t\u22121\u2225\u2217 \u2264m \u2225 ft \u2212 ft\u22121\u2225. Hence using this, we can bound the sub-optimality as 2+56R1,maxR2,max (mR1,max+nR2,max)+ 7\n2 nR1,max \u00bf\u00c1\u00c1\u00c0 T\u2211 t=1 \u2225xt \u2212 xt\u22121\u22252 + 7 2 mR2,max \u00bf\u00c1\u00c1\u00c0 T\u2211 t=1\n\u2225 ft \u2212 ft\u22121\u22252 \u22127mR2,max\nT\u2211 t=1 (\u2225gt \u2212 ft \u22252+\u2225g \u2032t\u22121 \u2212 ft \u22252)\u22127nR1,max T\u2211 t=1 (\u2225yt \u2212 xt \u22252 +\u2225y \u2032t\u22121 \u2212 xt \u22252) Using the fact that \u221a c2 \u2264 c2+1 we further bound sub-optimality by\n2+56R1,maxR2,max (mR1,max+nR2,max)+ 7 2 mR2,max+ 7 2 nR1,max + 7 2 nR1,max T\u2211 t=1 \u2225xt \u2212 xt\u22121\u22252 + 7\n2 mR2,max T\u2211 t=1 \u2225 ft \u2212 ft\u22121\u22252\u22127mR2,max T\u2211 t=1 (\u2225gt \u2212 ft \u22252+\u2225g \u2032t\u22121\u2212 ft \u22252) \u22127nR1,max\nT\u2211 t=1 (\u2225yt \u2212 xt \u22252 +\u2225y \u2032t\u22121 \u2212 xt \u22252) Nownote that \u2225xt \u2212 xt\u22121\u22252 \u2264 2\u2225xt \u2212 y \u2032t\u22121\u22252 +2\u2225xt\u22121 \u2212 y \u2032t\u22121\u22252\nand similarly \u2225 ft \u2212 ft\u22121\u22252 \u2264 2\u2225 ft \u2212 g \u2032t\u22121\u22252 +2\u2225 ft\u22121 \u2212 g \u2032t\u22121\u22252 Hence we can conclude that sub-optimality is bounded by\n2+56R1,maxR2,max (mR1,max+nR2,max)+ 7 2 mR2,max+ 7 2 nR1,max\n+7mR2,max T\u2211 t=1 (\u2225g \u2032t \u2212 ft \u22252 \u2212\u2225gt \u2212 ft \u22252)+7nR1,max T\u2211 t=1 (\u2225y \u2032t \u2212 xt \u22252\u2212\u2225yt \u2212 xt \u22252) \u2264 2+56R1,maxR2,max (mR1,max+nR2,max)+ 7\n2 mR2,max+\n7 2 nR1,max\n+28mR2,max T\u2211 t=1 \u2225g \u2032t \u2212 gt\u2225+28nR1,max T\u2211 t=1 \u2225y \u2032t \u2212 yt \u2225 \u2264 2+56R1,maxR2,max (mR1,max+nR2,max)+ 7\n2 mR2,max+\n7 2 nR1,max\n+ 28(mR2,max +nR1,max)\nT Just as in the proof of Proposition 6 we have R1,max \u2264 \u221a log(nT 2) and R2,max \u2264\u221alog(mT 2) and so overall we get the bound on sub-optimality :\n2+56 \u221a log(mT 2) log(nT 2)(m\u221alog(nT 2)+n\u221alog(mT 2))+ 7 2 m \u221a log(mT 2)+ 7 2 n \u221a log(nT 2)\n+ 28(m\u221alog(mT 2)+n\u221alog(nT 2))\nT\nPlayer II deviates from algorithm : Now let us consider the case when the Player 2 deviates from the prescribed algorithm. In this case, note that starting from Eq. (30) and simply dropping the negative termwe get,\nE[ T\u2211 t=1 f \u22bat Axt \u2212 inf f \u2208\u2206n T\u2211 t=1 f \u22baAxt]\u2264 56mR2,maxR21,max+1+ 7 2 R1,max \u00bf\u00c1\u00c1\u00c0 T\u2211 t=1 \u2225a\u0302t \u2212 a\u0304t\u22121\u22252\u2217\nAs we noted earlier, \u2225a\u0302t \u2212 a\u0304t\u22121\u2225\u2217 \u2264 n \u2225xt \u2212 xt\u22121\u2225 and so, E[ T\u2211\nt=1 f \u22bat Axt \u2212 inf f \u2208\u2206n T\u2211 t=1 f \u22baAxt] \u2264 56mR2,maxR21,max +1+ 7 2 nR1,max \u00bf\u00c1\u00c1\u00c0 T\u2211 t=1\n\u2225xt \u2212 xt\u22121\u22252 Further noting that R1,max \u2264 \u221a log(nT ) and R2,max \u2264\u221alog(mT )we conclude that\nE[ T\u2211 t=1 f \u22bat Axt \u2212 inf f \u2208\u2206n T\u2211 t=1 f \u22baAxt] \u2264 56m\u221alog(mT ) log(nT )+1+ 7 2 n \u00bf\u00c1\u00c1\u00c0log(nT ) T\u2211 t=1\n\u2225xt \u2212 xt\u22121\u22252 This concludes the proof.\nProof of Lemma 8. Noting that the constraints are all H-strongly smooth and that the objective is linear for the maximizing player, we can apply Lemma 4 to the optimization problem with R1(\u22c5) = 12 \u2225\u22c5\u222522 and R2 the entropy function to obtain that\nT (max i\u2208[d] Gi ( f\u0304T )\u2212 inf f \u2208F max i\u2208[d] Gi ( f )) \u2264 \u2225 f \u2217\u2212 g0\u222522\n\u03b7 + T\u2211 t=1 \u27e8 d\u2211 i=1 xt (i)\u2207Gi( ft)\u2212 d\u2211 i=1 yt\u22121(i)\u2207Gi(gt\u22121),gt \u2212 ft\u27e9\u2212 1 2\u03b7 T\u2211 t=1 (\u2225gt \u2212 ft \u222522+\u2225gt\u22121 \u2212 ft \u222522) + logd\n\u03b7\u2032 + \u03b2 2 T\u2211 t=1 \u2225G( ft )\u2212G(gt\u22121)\u22252\u221e+ 12\u03b2 T\u2211 t=1 \u2225yt \u2212 xt \u222521\u2212 12\u03b7\u2032 T\u2211 t=1 (\u2225yt \u2212 xt \u222521+\u2225yt\u22121 \u2212 xt \u222521) (Strictly speaking we have used a version of Lemma 4 where the first term coming from (12) in Lemma 1 is kept as a linear term.) Here, G( f ) is the vector of the values of the constraints for f . We then write T\u2211 t=1 \u27e8 d\u2211 i=1 xt (i)\u2207Gi( ft)\u2212 d\u2211 i=1\nyt\u22121(i)\u2207Gi(gt\u22121),gt \u2212 ft\u27e9 = T\u2211\nt=1 \u27e8 d\u2211 i=1 xt (i)\u2207Gi( ft )\u2212 d\u2211 i=1 yt\u22121(i)\u2207Gi( ft),gt \u2212 ft\u27e9+ T\u2211 t=1 \u27e8 d\u2211 i=1 yt\u22121(i)\u2207Gi( ft )\u2212 d\u2211 i=1 yt\u22121(i)\u2207Gi(gt\u22121),gt \u2212 ft\u27e9 = T\u2211\nt=1 d\u2211 i=1 (xt (i)\u2212 yt\u22121(i))\u27e8\u2207Gi( ft ),gt \u2212 ft \u27e9+ T\u2211 t=1 d\u2211 i=1 yt\u22121(i)\u27e8\u2207Gi ( ft )\u2212\u2207Gi (gt\u22121),gt \u2212 ft \u27e9 \u2264\nT\u2211 t=1 \u2225xt \u2212 yt\u22121\u22251max i\u2208[d] \u2223\u27e8\u2207Gi( ft ),gt \u2212 ft \u27e9\u2223+ T\u2211 t=1 d\u2211 i=1 yt\u22121(i)\u2225\u2207Gi ( ft )\u2212\u2207Gi(gt\u22121)\u22252 \u2225gt \u2212 ft \u22252 \u2264\nT\u2211 t=1 \u2225xt \u2212 yt\u22121\u22251 \u2225gt \u2212 ft \u22252+H T\u2211 t=1 \u2225ft \u2212 gt\u22121\u22252 \u2225gt \u2212 ft \u22252 where we used the fact that each \u2225\u2207Gi ( f )\u2225 \u2264 1. Combining, we get an upper bound of\n\u2225 f \u2217 \u2212 g0\u222522 \u03b7 + T\u2211 t=1 \u2225xt \u2212 yt\u22121\u22251 \u2225gt \u2212 ft \u22252\u2212 12\u03b7 T\u2211 t=1 (\u2225gt \u2212 ft \u222522+\u2225gt\u22121 \u2212 ft \u222522)+H T\u2211 t=1\n\u2225 ft \u2212 gt\u22121\u22252 \u2225gt \u2212 ft \u22252 + logd\n\u03b7\u2032 + \u03b2 2 T\u2211 t=1 \u2225G( ft )\u2212G(gt\u22121)\u22252\u221e+ 12\u03b2 T\u2211 t=1 \u2225yt \u2212 xt \u222521\u2212 12\u03b7\u2032 T\u2211 t=1 (\u2225yt \u2212 xt \u222521 +\u2225yt\u22121 \u2212 xt \u222521)\n\u2264 \u2225 f \u2217\u2212 g0\u222522\n\u03b7 +\n1\n2\u03b2 T\u2211 t=1 \u2225xt \u2212 yt\u22121\u222521+ \u03b22 T\u2211 t=1 \u2225gt \u2212 ft \u222522\u2212 12\u03b7 T\u2211 t=1 (\u2225gt \u2212 ft \u222522+\u2225gt\u22121\u2212 ft \u222522) + logd\n\u03b7\u2032 + \u03b2 2 T\u2211 t=1 \u2225 ft \u2212 gt\u22121\u222522+ 12\u03b2 T\u2211 t=1 \u2225yt \u2212 xt \u222521 \u2212 12\u03b7\u2032 T\u2211 t=1 (\u2225yt \u2212 xt \u222521+\u2225yt\u22121 \u2212 xt \u222521) + H\n2 T\u2211 t=1 \u2225 ft \u2212 gt\u22121\u222522+ H2 T\u2211 t=1 \u2225gt \u2212 ft \u222522 = \u2225 f \u2217\u2212 g0\u222522\n\u03b7 + 1 2 (\u03b2+H \u2212 1 \u03b7 ) T\u2211 t=1 (\u2225gt \u2212 ft \u222522 +\u2225gt\u22121\u2212 ft \u222522) + logd\n\u03b7\u2032 + 1 2 ( 1 \u03b2 \u2212 1 \u03b7\u2032 ) T\u2211 t=1 (\u2225yt \u2212 xt \u222521+\u2225yt\u22121 \u2212 xt \u222521) Picking \u03b2 \u2265 0 such that 1\n\u03b7 \u2212H \u2265\u03b2 \u2265 \u03b7\u2032 we get an upper bound of\n\u2225 f \u2217\u2212 g0\u222522 \u03b7 + logd \u03b7\u2032 \u2264 B2 \u03b7 + logd \u03b7\u2032\nOf course, for this choice to be possible we need to pick \u03b7 and \u03b7\u2032 such that 1 \u03b7 \u2212H \u2265 \u03b7\u2032. Therefore, picking \u03b7\u2032 = 1 \u03b7 \u2212H\nand \u03b7 \u2264 1/H we obtain max i\u2208[d] Gi ( f\u0304T )\u2212 inf f \u2208F max i\u2208[d] Gi ( f ) \u2264 1 T inf \u03b7\u2264H\u22121 {B2 \u03b7 + \u03b7 logd 1\u2212\u03b7H }\nNow since T is such that T \u2265 1 \u01eb inf\u03b7\u2264H\u22121 {B2\u03b7 + \u03b7 logd1\u2212\u03b7H }we can conclude that\nmax i\u2208[d] Gi( f\u0304T )\u2212argmin f \u2208F max i\u2208[d] Gi( f ) \u2264 \u01eb Observe that for an optimal solution f \u2217 \u2208 G to the original optimization problem (10) we have that f \u2217 \u2208F and\n\u2200i ,Gi( f \u2217) \u2264 1. Thus, max i\u2208[d]\nGi ( f\u0304T ) \u2264 1+\u01eb We conclude that f\u0304T \u2208F is a solution that attains the optimum value F\u2217 and almost satisfies the constraints. Now we have from the lemma statement that f0 \u2208 G is such that c\u22ba f0 \u2265 0 and for every i \u2208 [d], Gi ( f0) \u2264 1\u2212\u03b3. Hence by convexity ofGi , we have that for every i \u2208 [d], Gi (\u03b1 f0 +(1\u2212\u03b1) f\u0304T )\u2264\u03b1Gi ( f0)+(1\u2212\u03b1)Gi ( f\u0304T ) \u2264\u03b1(1\u2212\u03b3)+(1\u2212\u03b1)(1+\u01eb) \u2264 1 Thus for \u03b1 = \u01eb\n\u01eb+\u03b3 and f\u0302T = (1\u2212\u03b1) f\u0304T +\u03b1 f0 we can conclude that f\u0302T \u2208 G and that all the constraints are satisfied. That is for every i \u2208 [d],Gi( f\u0302T ) \u2264 1. Also note that\nc\u22ba f\u0302T = (1\u2212\u03b1)c\u22ba f\u0304T +\u03b1c\u22ba f0 = (1\u2212\u03b1)F\u2217 = \u03b3F\u2217 \u01eb+\u03b3\nand, hence, f\u0302T is an approximate maximizer, that is\nc\u22ba( f \u2217\u2212 f\u0302T ) \u2264 F\u2217\u2212 \u03b3F\u2217 \u01eb+\u03b3 = F\u2217\u01eb+F\u2217\u03b3\u2212\u03b3F\u2217 \u01eb+\u03b3 = \u01eb( F\u2217 \u01eb+\u03b3) \u2264 \u01eb\u03b3F\u2217\nThus we obtain a (1+ \u01eb \u03b3 )-optimal solution in the multiplicative sense which concludes the proof.\nProof of Corollary 9. As mentioned, for both players, the time to perform each step of the optimistic mirror descent in the Max Flow problem isO(d). Now further note that Max Flow is a linear programming problem and so we are ready to apply Lemma 8. Specifically for f0 we use the 0 flow which is in G (though not inF ) and note that for f0 we have that \u03b3 = 1. Applying Lemma 8 we get that number of iterations T we need to reach an \u01eb approximate solution is given by\nT \u2264 1\n\u01eb inf \u03b7\u2264H\u22121 {B2 \u03b7 + \u03b7 logd 1\u2212\u03b7H }\nNowwe can use g0 = argmin g\u2208F \u2225g\u22252 which can be computed inO(d) time. Observe that \u2225 f \u2217\u2212 g0\u22252 \u2264 \u2225 f \u2217\u22252+\u2225g0\u22252 \u2264 2 \u221a d =\u2236 B . Also note that for linear constraints we have H = 0. Hence, the number of iterations is at most\nT \u2264 1 \u01eb inf \u03b7 {B2 \u03b7 +\u03b7 logd} =\n\u221a d logd\n\u01eb\nSince each iteration has time complexityO(d), the overall complexity of the algorithm is given by O(d3/2 \u221a logd\n\u01eb )\nthis concludes the proof."}], "references": [], "referenceMentions": [], "year": 2013, "abstractText": "We provide several applications of Optimistic Mirror Descent, an online learning algorithm based on the idea<lb>of predictable sequences. First, we recover theMirror Prox algorithm for offline optimization, prove an extension<lb>to H\u00f6lder-smooth functions, and apply the results to saddle-point type problems. Next, we prove that a version<lb>of Optimistic Mirror Descent (which has a close relation to the Exponential Weights algorithm) can be used by<lb>two strongly-uncoupled players in a finite zero-summatrix game to converge to the minimax equilibrium at the<lb>rate ofO((logT )/T ). This addresses a question of Daskalakis et al [6]. Further, we consider a partial information<lb>version of the problem. We then apply the results to convex programming and exhibit a simple algorithm for the<lb>approximateMax Flow problem.", "creator": "LaTeX with hyperref package"}}}