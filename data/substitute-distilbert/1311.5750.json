{"id": "1311.5750", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Nov-2013", "title": "Gradient Hard Thresholding Pursuit for Sparsity-Constrained Optimization", "abstract": "hard thresholding gradient ( htp ) is an iterative problem selection procedure for finding sparse solutions of underdetermined linear difficulties. this method has been shown to have rich quantitative guarantee and sufficient numerical performance. in fact paper, to generalize htp from compressive sensing to a generic problem function of sparsity - constrained convex optimization. the proposed algorithm iterates between a standard gradient descent step and a hard thresholding step with or without debiasing. we prove that our method enjoys the strong guarantees granted to htp in terms of rate of convergence and parameter estimation accuracy. numerical evidences show that our method rates superior while the state - just - the - art greedy selection methods in sparse logistic regression - sparse precision equation estimation tasks.", "histories": [["v1", "Fri, 22 Nov 2013 13:52:07 GMT  (296kb)", "http://arxiv.org/abs/1311.5750v1", "arXiv admin note: text overlap witharXiv:1102.2233by other authors"], ["v2", "Mon, 25 Nov 2013 04:19:39 GMT  (296kb)", "http://arxiv.org/abs/1311.5750v2", null]], "COMMENTS": "arXiv admin note: text overlap witharXiv:1102.2233by other authors", "reviews": [], "SUBJECTS": "cs.LG cs.NA stat.ML", "authors": ["xiaotong yuan", "ping li 0001", "tong zhang 0001"], "accepted": true, "id": "1311.5750"}, "pdf": {"name": "1311.5750.pdf", "metadata": {"source": "CRF", "title": "Gradient Hard Thresholding Pursuit for Sparsity-Constrained Optimization", "authors": ["Xiao-Tong Yuan", "Ping Li", "Tong Zhang"], "emails": ["{xtyuan1980@gmail.com,", "pingli@stat.rutgers.edu,", "tzhang@stat.rutgers.edu}"], "sections": [{"heading": null, "text": "ar X\niv :1\n31 1.\n57 50\nv1 [\nKey words. Sparsity, Greedy Selection, Hard Thresholding Pursuit, Gradient Descent."}, {"heading": "1 Introduction", "text": "In the past decade, high-dimensional data analysis has received broad research interests in data mining and scientific discovery, with many significant results obtained in theory, algorithm and applications. The major driven force is the rapid development of data collection technologies in many applications domains such as social networks, natural language processing, bioinformatics and computer vision. In these applications it is not unusual that data samples are represented with millions or even billions of features using which an underlying statistical learning model must be fit. In many circumstances, however, the number of collected samples is substantially smaller than the dimensionality of the feature, implying that consistent estimators cannot be hoped for unless additional assumptions are imposed on the model. One of the widely acknowledged prior assumptions is that the data exhibit low-dimensional structure, which can often be captured by imposing sparsity constraint on the model parameter space. It is thus crucial to develop robust and efficient computational procedures for solving, even just approximately, these optimization problems with sparsity constraint.\nIn this paper, we focus on the following generic sparsity-constrained optimization problem\nmin x\u2208Rp\nf(x), s.t. \u2016x\u20160 \u2264 k, (1.1)\nwhere f : Rp 7\u2192 R is a smooth convex cost function. Among others, several examples falling into this model include: (i) Sparsity-constrained linear regression model (Tropp & Gilbert, 2007) where the residual error is used to measure data reconstruction error; (ii) Sparsity-constrained logistic regression model (Bahmani et al., 2013) where the sigmoid loss is used to measure prediction error; (iii) Sparsity-constrained graphical model learning (Jalali et al., 2011) where the likelihood of samples drawn from an underlying probabilistic model is used to measure data fidelity.\nUnfortunately, due to the non-convex cardinality constraint, the problem (1.1) is generally NP-hard even for the quadratic cost function (Natarajan, 1995). Thus, one must instead seek approximate solutions. In particular, the special case of (1.1) in least square regression models has gained significant attention in the area of compressed sensing (Donoho, 2006). A vast body of greedy selection algorithms for compressing sensing have been proposed including matching pursuit (Mallat & Zhang, 1993), orthogonal matching pursuit (Tropp & Gilbert, 2007), compressive sampling matching pursuit (Needell & Tropp, 2009), hard thresholding pursuit (Foucart, 2011), iterative hard thresholding (Blumensath & Davies, 2009) and subspace pursuit (Dai & Milenkovic, 2009) to name a few. These algorithms successively select the position of nonzero entries and estimate their values via exploring the residual error from the previous iteration. Comparing to those first-order convex optimization methods developed for \u21131-regularized sparse learning (Beck & Teboulle, 2009; Agarwal et al., 2010), these greedy selection algorithms often exhibit similar accuracy guarantees but more attractive computational efficiency.\nThe least square error used in compressive sensing, however, is not an appropriate measure of discrepancy in a variety of applications beyond signal processing. For example, in statistical machine learning the log-likelihood function is commonly used in logistic regression problems (Bishop, 2006) and graphical models learning (Jalali et al., 2011; Ravikumar et al., 2011). Thus, it is desirable to investigate theory and algorithms applicable to a broader class of sparsityconstrained learning problems as given in (1.1). To this end, several forward selection algorithms have been proposed to select the nonzero entries in a sequential fashion (Kim & Kim, 2004; Shalev-Shwartz et al., 2010; Yuan & Yan, 2013; Jaggi, 2011). This category of methods date\nback to the Frank-Wolfe method (Frank & Wolfe, 1956). The forward greedy selection method has also been generalized to minimize a convex objective over the linear hull of a collection of atoms (Tewari et al., 2011; Yuan & Yan, 2012). To make the greedy selection procedure more adaptive, Zhang (2008) proposed a forward-backward algorithm which takes backward steps adaptively whenever beneficial. Jalali et al. (2011) have applied this forward-backward selection method to learn the structure of a sparse graphical model. More recently, Bahmani et al. (2013) proposed a gradient hard-thresholding method which generalizes the compressive sampling matching pursuit method (Needell & Tropp, 2009) from compressive sensing to the general sparsity-constrained optimization problem. The hard-threshholding-type methods have also been shown to be statistically and computationally efficient for sparse principal component analysis (Yuan & Zhang, 2013; Ma, 2013)."}, {"heading": "1.1 Our Contribution", "text": "In this paper, inspired by the success of Hard Thresholding Pursuit (HTP) (Foucart, 2011, 2012) in compressive sensing, we propose the Gradient Hard Thresholding Pursuit (GraHTP) method to encompass the sparse estimation problems arising from applications with general nonlinear models. At each iteration, GraHTP performs standard gradient descent followed by a hard thresholding operation which first selects the top k (in magnitude) entries of the resultant vector and then (optionally) conducts debiasing on the selected entries. We prove that under mild conditions GraHTP (with or without debiasing) has strong theoretical guarantees analogous to HTP in terms of convergence rate and parameter estimation accuracy. We have applied GraHTP to the sparse logistic regression model and the sparse precision matrix estimation model, verifying that the guarantees of HTP are valid for these two models. Empirically we demonstrate that GraHTP is comparable or superior to the state-of-the-art greedy selection methods in these two sparse learning models. To our knowledge, GraHTP is the first gradient-descent-truncation-type method for sparsity constrained nonlinear problems."}, {"heading": "1.2 Notation", "text": "In the following, x \u2208 Rp is a vector, F is an index set and A is a matrix. The following notations will be used in the text.\n\u2022 [x]i: the ith entry of vector x.\n\u2022 xF : the restriction of x to index set F , i.e., [xF ]i = [x]i if i \u2208 F , and [xF ]i = 0 otherwise.\n\u2022 xk: the restriction of x to the top k (in modulus) entries. We will simplify xFk to xk without ambiguity in the context. \u2022 \u2016x\u2016 = \u221a x\u22a4x: the Euclidean norm of x.\n\u2022 \u2016x\u20161 = \u2211d i=1 |xi|: the \u21131-norm of x.\n\u2022 \u2016x\u20160: the number of nonzero entries of x.\n\u2022 supp(x): the index set of nonzero entries of x.\n\u2022 supp(x, k): the index set of the top k (in modulus) entries of x.\n\u2022 [A]ij : the element on the ith row and jth column of matrix A.\n\u2022 \u2016A\u2016 = sup\u2016x\u2016\u22641 \u2016Ax\u2016: the spectral norm of matrix A.\n\u2022 AF\u2022 (A\u2022F ): the rows (columns) of matrix A indexed in F .\n\u2022 |A|1 = \u2211 1\u2264i\u2264p,1\u2264j\u2264q |[A]ij |: the element-wise \u21131-norm of A.\n\u2022 Tr(A): the trace (sum of diagonal elements) of a square matrix A.\n\u2022 A\u2212: the restriction of a square matrix A on its off-diagonal entries\n\u2022 vect(A): (column wise) vectorization of a matrix A."}, {"heading": "1.3 Paper Organization", "text": "This paper proceeds as follows: We present in \u00a72 the GraHTP algorithm. The convergence guarantees of GraHTP are provided in \u00a73. The specializations of GraHTP in logistic regression and Gaussian graphical models learning are investigated in \u00a74. Monte-Carlo simulations and experimental results on real data are presented in \u00a75. We conclude this paper in \u00a76."}, {"heading": "2 Gradient Hard Thresholding Pursuit", "text": "GraHTP is an iterative greedy selection procedure for approximately optimizing the non-convex problem (1.1). A high level summary of GraHTP is described in the top panel of Algorithm 1. The procedure generates a sequence of intermediate k-sparse vectors x(0), x(1), . . . from an initial sparse approximation x(0) (typically x(0) = 0). At the t-th iteration, the first step S1, x\u0303(t) = x(t\u22121) \u2212 \u03b7\u2207f(x(t\u22121)), computes the gradient descent at the point x(t\u22121) with step-size \u03b7. Then in the second step, S2, the k coordinates of the vector x\u0303(t) that have the largest magnitude are chosen as the support in which pursuing the minimization will be most effective. In the third step, S3, we find a vector with this support which minimizes the objective function, which becomes x(t). This last step, often referred to as debiasing, has been shown to improve the performance in other algorithms too. The iterations continue until the algorithm reaches a terminating condition, e.g., on the change of the cost function or the change of the estimated minimum from the previous iteration. A natural criterion here is F (t) = F (t\u22121) (see S2 for the definition of F (t)), since then x(\u03c4) = x(t) for all \u03c4 \u2265 t, although there is no guarantee that this should occur. It will be assumed throughout the paper that the cardinality k is known. In practice this quantity may be regarded as a tuning parameter of the algorithm via, for example, cross-validations.\nIn the standard form of GraHTP, the debiasing step S3 requires to minimize f(x) over the support F (t). If this step is judged too costly, we may consider instead a fast variant of GraHTP, where the debiasing is replaced by a simple truncation operation x(t) = x\u0303 (t) k . This leads to the Fast GraHTP (FGraHTP) described in the bottom panel of Algorithm 1. It is interesting to note that FGraHTP can be regarded as a projected gradient descent procedure for optimizing the non-convex problem (1.1). Its per-iteration computational overload is almost identical to that of the standard gradient descent procedure. While in this paper we only study the FGraHTP outlined in Algorithm 1, we should mention that other fast variants of GraHTP can also be considered. For instance, to reduce the computational cost of S3, we can take a restricted Newton step or a restricted gradient descent step to calculate x(t).\nWe close this section by pointing out that, in the special case where the squared error f(x) = 1 2\u2016y\u2212Ax\u20162 is the cost function, GraHTP reduces to HTP (Foucart, 2011). Specifically, the gradient descent step S1 reduces to x\u0303(t) = x(t\u22121) + \u03b7A\u22a4(y \u2212 Ax(t\u22121)) and the debiasing step S3 reduces to the orthogonal projection x(t) = argmin{\u2016y \u2212Ax\u2016, supp(x) \u2286 F (t)}. In the meanwhile, FGraHTP reduces to IHT (Blumensath & Davies, 2009) in which the iteration is defined by x(t) = (x(t\u22121) + \u03b7A\u22a4(y \u2212Ax(t\u22121)))k.\nAlgorithm 1: Gradient Hard Thresholding Pursuit (GraHTP).\nInitialization: x(0) with \u2016x(0)\u20160 \u2264 k (typically x(0) = 0), t = 1. Output: x(t). repeat\n(S1) Compute x\u0303(t) = x(t\u22121) \u2212 \u03b7\u2207f(x(t\u22121)); (S2) Let F (t) = supp(x\u0303(t), k) be the indices of x\u0303(t) with the largest k absolute values; (S3) Compute x(t) = argmin{f(x), supp(x) \u2286 F (t)}; t = t+ 1;\nuntil halting condition holds; \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2013\u22c6 Fast GraHTP \u22c6\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 repeat\nCompute x\u0303(t) = x(t\u22121) \u2212 \u03b7\u2207f(x(t\u22121)); Compute x(t) = x\u0303\n(t) k as the truncation of x\u0303 (t) with top k entries preserved; t = t+ 1;\nuntil halting condition holds;"}, {"heading": "3 Theoretical Analysis", "text": "In this section, we analyze the theoretical properties of GraHTP and FGraHTP. We first study the convergence of these two algorithms. Next, we investigate their performances for the task of sparse recovery in terms of convergence rate and parameter estimation accuracy. We require the following key technical condition under which the convergence and parameter estimation accuracy of GraHTP/FGraHTP can be guaranteed. To simplify the notation in the following analysis, we abbreviate \u2207F f = (\u2207f)F and \u2207sf = (\u2207f)s.\nDefinition 1 (Condition C(s, \u03b6, \u03c1s)). For any integer s > 0, we say f satisfies condition C(s, \u03b6, \u03c1s) if for any index set F with cardinality |F | \u2264 s and any x, y with supp(x)\u222asupp(y) \u2286 F , the following inequality holds for some \u03b6 > 0 and 0 < \u03c1s < 1:\n\u2016x\u2212 y \u2212 \u03b6\u2207F f(x) + \u03b6\u2207Ff(y)\u2016 \u2264 \u03c1s\u2016x\u2212 y\u2016.\nRemark 1. In the special case where f(x) is least square loss function and \u03b6 = 1, Condition C(s, \u03b6, \u03c1s) reduces to the well known Restricted Isometry Property (RIP) condition in compressive sensing.\nWe may establish the connections between condition C(s, \u03b6, \u03c1s) and the conditions of restricted strong convexity/smoothness which are key to the analysis of several previous greedy selection methods (Zhang, 2008; Shalev-Shwartz et al., 2010; Yuan & Yan, 2013; Bahmani et al., 2013).\nDefinition 2 (Restricted Strong Convexity/Smoothness). For any integer s > 0, we say f(x) is restricted ms-strongly convex and Ms-strongly smooth if there exist \u2203ms,Ms > 0 such that\nms 2 \u2016x\u2212 y\u20162 \u2264 f(x)\u2212 f(y)\u2212 \u3008\u2207f(y), x\u2212 y\u3009 \u2264 Ms 2 \u2016x\u2212 y\u20162, \u2200\u2016x\u2212 y\u20160 \u2264 s. (3.1)\nThe following lemma connects condition C(s, \u03b6, \u03c1s) to the restricted strong convexity/smoothness conditions.\nLemma 1. Assume that f is a differentiable function.\n(a) If f satisfies condition C(s, \u03b6, \u03c1s), then for all \u2016x\u2212y\u20160 \u2264 s the following two inequalities hold:\n1\u2212 \u03c1s \u03b6 \u2016x\u2212 y\u2016 \u2264 \u2016\u2207F f(x)\u2212\u2207F f(y)\u2016 \u2264 1 + \u03c1s \u03b6 \u2016x\u2212 y\u2016\nf(x) \u2264 f(y) + \u3008\u2207f(y), x\u2212 y\u3009+ 1 + \u03c1s 2\u03b6 \u2016x\u2212 y\u20162.\n(b) If f is ms-strongly convex and Ms-strongly smooth, then f satisfies condition C(s, \u03b6, \u03c1s) with any\n\u03b6 < 2ms/M 2 s , \u03c1s =\n\u221a\n1\u2212 2\u03b6ms + \u03b62M2s .\nA proof of this lemma is provided in Appendix A.1.\nRemark 2. The Part(a) of Lemma 1 indicates that if condition C(s, \u03b6, \u03c1s) holds, then f is strongly smooth. The Part(b) of Lemma 1 shows that the strong smoothness/convexity conditions imply condition C(s, \u03b6, \u03c1s). Therefore, condition C(s, \u03b6, \u03c1s) is no stronger than the strong smoothness/conveixy conditions."}, {"heading": "3.1 Convergence", "text": "We now analyze the convergence properties of GraHTP and FGraHTP. First and foremost, we make a simple observation about GraHTP: since there is only a finite number of subsets of {1, ..., p} of size k, the sequence defined by GraHTP is eventually periodic. The importance of this observation lies in the fact that, as soon as the convergence of GraHTP is established, then we can certify that the limit is exactly achieved after a finite number of iterations. We establish in Theorem 1 the convergence of GraHTP and FGraHTP under proper conditions. A proof of this theorem is provided in Appendix A.2.\nTheorem 1. Assume that f satisfies condition C(2k, \u03b6, \u03c12k) and the step-size \u03b7 < \u03b6/(1 + \u03c12k). Then the sequence {x(t)} defined by GraHTP converges in a finite number of iterations. Moreover, the sequence {f(x(t))} defined by FGraHTP converges.\nRemark 3. Since \u03c12k \u2208 (0, 1), we have that the convergence results in Theorem 1 hold whenever the step-size \u03b7 < \u03b6/2. If f is ms-strongly convex and Ms-strongly smooth, then from Part(b) of Lemma 1 we know that Theorem 1 holds whenever the step-size \u03b7 < ms/M 2 s ."}, {"heading": "3.2 Sparse Recovery Performance", "text": "The following theorem is our main result on the parameter estimation accuracy of GraHTP and FGraHTP when the target solution is sparse.\nTheorem 2. Let x\u0304 be an arbitrary k\u0304-sparse vector and k \u2265 k\u0304. Let s = 2k + k\u0304. If f satisfies condition C(s, \u03b6, \u03c1s) and \u03b7 < \u03b6,\n(a) if \u00b51 = \u221a 2(1 \u2212 \u03b7/\u03b6 + (2 \u2212 \u03b7/\u03b6)\u03c1s)/(1 \u2212 \u03c1s) < 1, then at iteration t, GraHTP will recover an\napproximation x(t) satisfying\n\u2016x(t) \u2212 x\u0304\u2016 \u2264 \u00b5t1\u2016x(0) \u2212 x\u0304\u2016+ 2\u03b7 + \u03b6\n(1\u2212 \u00b51)(1 \u2212 \u03c1s) \u2016\u2207kf(x\u0304)\u2016.\n(b) if \u00b52 = 2(1 \u2212 \u03b7/\u03b6 + (2 \u2212 \u03b7/\u03b6)\u03c1s) < 1, then at iteration t, FGraHTP will recover an approximation x(t) satisfying\n\u2016x(t) \u2212 x\u0304\u2016 \u2264 \u00b5t2\u2016x(0) \u2212 x\u0304\u2016+ 2\u03b7\n1\u2212 \u00b52 \u2016\u2207sf(x\u0304)\u2016.\nA proof of this theorem is provided in Appendix A.3. Note that we did not make any attempt to optimize the constants in Theorem 2, which are relatively loose. In the discussion, we ignore the constants and focus on the main message Theorem 2 conveys. The part (a) of Theorem 2 indicates that under proper conditions, the estimation error of GraHTP is determined by the multiple of \u2016\u2207kf(x\u0304)\u2016, and the rate of convergence before reaching this error level is geometric. Particularly, if the sparse vector x\u0304 is sufficiently close to an unconstrained minimum of f then the estimation error floor is negligible because \u2207kf(x\u0304) has small magnitude. In the ideal case where \u2207f(x\u0304) = 0 (i.e., the sparse vector x\u0304 is an unconstrained minimum of f), this result guarantees that we can recover x\u0304 to arbitrary precision. In this case, if we further assume that \u03b7 satisfies the conditions in Theorem 1, then exact recovery can be achieved in a finite number of iterations. The part (b) of Theorem 2 shows that FGraHTP enjoys a similar geometric rate of convergence and the estimation error is determined by the multiple of \u2016\u2207sf(x\u0304)\u2016 with s = 2k + k\u0304.\nThe shrinkage rates \u00b51 < 1 (see Part (a)) and \u00b52 < 1 (see Part (b)) respectively control the convergence rate of GraHTP and FGraHTP. For GraHTP, the condition \u00b51 < 1 implies\n\u03b7 > ((2\n\u221a 2 + 1)\u03c1s + \u221a 2\u2212 1)\u03b6\u221a\n2 + \u221a 2\u03c1s\n. (3.2)\nBy combining this condition with \u03b7 < \u03b6, we can see that \u03c1s < 1/( \u221a 2 + 1) is a necessary condition\nto guarantee \u00b51 < 1. On the other side, if \u03c1s < 1/( \u221a 2 + 1), then we can always find a step-size \u03b7 < \u03b6 satisfying (3.2) such that \u00b51 < 1. This condition of \u03c1s is analogous to the RIP condition for estimation from noisy measurements in compressive sensing (Cande\u0300s et al., 2006; Needell & Tropp, 2009; Foucart, 2011). Indeed, in this setup our GraHTP algorithm reduces to HTP which requires weaker RIP condition than prior compressive sensing algorithms. The guarantees of GraHTP and HTP are almost identical, although we did not make any attempt to optimize the RIP sufficient constants, which are 1/( \u221a 2+1) (for GraHTP) versus 1/ \u221a 3 (for HTP). We would like to emphasize that the condition \u03c1s < 1/( \u221a 2 + 1) derived for GraHTP also holds in fairly general setups beyond compressive sensing. For FGraHTP we have similar discussions.\nFor the general sparsity-constrained optimization problem, we note that a similar estimation error bound has been established for the GraSP (Gradient Support Pursuit) method (Bahmani et al., 2013) which is another hard-thresholding-type method. At time stamp t, GraSP first conducts debiasing over the union of the top k entries of x(t\u22121) and the top 2k entries of \u2207f(x(t\u22121)), then it selects the top k entries of the resultant vector and updates their values via debiasing, which becomes x(t). Our GraHTP is connected to GraSP in the sense that the k largest absolute elements after the gradient descent step (see S1 and S2 of Algorithm 1) will come from some combination of the largest elements in x(t\u22121) and the largest elements in the gradient \u2207f(x(t\u22121)). Although the convergence rate are of the same order, the per-iteration cost of GraHTP is cheaper than GraSP. Indeed, at each iteration, GraSP needs to minimize the objective over a support of size 3k while that size for GraHTP is k. FGraHTP is even cheaper for iteration as it does not need any debiasing operation. We will compare the actual numerical performances of these methods in our empirical study."}, {"heading": "4 Applications", "text": "In this section, we will specialize GraHTP/FGraHTP to two popular statistical learning models: the sparse logistic regression (in \u00a74.1) and the sparse precision matrix estimation (in \u00a74.2)."}, {"heading": "4.1 Sparsity-Constrained \u21132-Regularized Logistic Regression", "text": "Logistic regression is one of the most popular models in statistics and machine learning (Bishop, 2006). In this model the relation between the random feature vector u \u2208 Rp and its associated random binary label v \u2208 {\u22121,+1} is determined by the conditional probability\nP(v|u; w\u0304) = exp(2vw\u0304 \u22a4u)\n1 + exp(2vw\u0304\u22a4u) , (4.1)\nwhere w\u0304 \u2208 Rp denotes a parameter vector. Given a set of n independently drawn data samples {(u(i), v(i))}ni=1, logistic regression learns the parameters w so as to minimize the logistic log-likelihood given by\nl(w) := \u2212 1 n log \u220f\ni\nP(u(i) | v(i);w) = 1 n\nn \u2211\ni=1\nlog(1 + exp(\u22122v(i)w\u22a4u(i))).\nIt is well-known that l(w) is convex. Unfortunately, in high-dimensional setting, i.e., n < p, the problem can be underdetermined and thus its minimum is not unique. A conventional way to handle this issue is to impose \u21132-regularization to the logistic loss to avoid singularity. The \u21132penalty, however, does not promote sparse solutions which are often desirable in high-dimensional learning tasks. The sparsity-constrained \u21132-regularized logistic regression is then given by:\nmin w\nf(w) = l(w) + \u03bb\n2 \u2016w\u20162, subject to \u2016w\u20160 \u2264 k, (4.2)\nwhere \u03bb > 0 is the regularization strength parameter. Obviously f(w) is \u03bb-strongly convex and hence it has a unique minimum. The cardinality constraint enforces the solution to be sparse.\n4.1.1 Verifying Condition C(s, \u03b6, \u03c1s)\nLet U = [u(1), ..., u(n)] \u2208 Rp\u00d7n be the design matrix and \u03c3(z) = 1/(1 + exp(\u2212z)) be the sigmoid function. In the case of \u21132-regularized logistic loss considered in this section we have\n\u2207f(w) = Ua(w)/n + \u03bbw,\nwhere the vector a(w) \u2208 Rn is given by [a(w)]i = \u22122v(i)(1 \u2212 \u03c3(2v(i)w\u22a4u(i))). The following result verifies that f(w) satisfies Condition C(s, \u03b6, \u03c1s) under mild conditions.\nProposition 1. Assume that for any index set F with |F | \u2264 s we have \u2200i, \u2016(u(i))F \u2016 \u2264 Rs. Then the \u21132-regularized logistic loss satisfies Condition C(s, \u03b6, \u03c1s) with any\n\u03b6 < 2\u03bb\n(4 \u221a sR2s + \u03bb) 2 , \u03c1s =\n\u221a 1\u2212 2\u03b6\u03bb+ \u03b62(4\u221asR2s + \u03bb)2.\nA proof of this result is given in Appendix A.4."}, {"heading": "4.1.2 Bounding the Estimation Error", "text": "We are going to bound \u2016\u2207sf(w\u0304)\u2016 which we obtain from Theorem 2 that controls the estimation error bounds of GraHTP (with s = k) and FGraHTP (with s = 2k+ k\u0304). In the following deviation, we assume that the joint density of the random vector (u, v) \u2208 Rp+1 is given by the following exponential family distribution:\nP(u, v; w\u0304) = exp ( vw\u0304\u22a4u+B(u)\u2212A(w\u0304) ) , (4.3)\nwhere\nA(w\u0304) := log \u2211\nv={\u22121,1}\n\u222b\nRp\nexp ( vw\u0304\u22a4u+B(u) ) du\nis the log-partition function. The term B(u) characterizes the marginal behavior of u. Obviously, the conditional distribution of v given u, P(v | u; w\u0304), is given by the logistical model (4.1). By trivial algebra we can obtain the following standard result which shows that the first derivative of the logistic log-likelihood l(w) yields the cumulants of the random variables v[u]j (see, e.g., Wainwright & Jordan, 2008):\n\u2202l\n\u2202[w]j =\n1\nn\nn \u2211\ni=1\n{ \u2212v(i)[u(i)]j + Ev[v[u(i)]j | u(i)] } . (4.4)\nHere the expectation Ev[\u00b7 | u] is taken over the conditional distribution (4.1). We introduce the following sub-Gaussian condition on the random variate v[u]j .\nAssumption 1. For all j, we assume that there exists constant \u03c3 > 0 such that for all \u03b7,\nE[exp(\u03b7v[u]j)] \u2264 exp ( \u03c32\u03b72/2 ) .\nThis assumption holds when [u]j are sub-Gaussian (e.g., Gaussian or bounded) random variables. The following result establishes the bound of \u2016\u2207sf(w\u0304)\u2016.\nProposition 2. If Assumption 1 holds, then with probability at least 1\u2212 4p\u22121,\n\u2016\u2207sf(w\u0304)\u2016 \u2264 4\u03c3 \u221a s ln p/n+ \u03bb\u2016w\u0304s\u2016.\nA proof of this result can be found in Appendix A.5.\nRemark 4. If we choose \u03bb = O( \u221a ln p/n), then with overwhelming probability \u2016\u2207sf(w\u0304)\u2016 vanishes at the rate of O( \u221a\ns ln p/n). This bound is superior to the bound provided by Bahmani et al. (2013, Section 4.2) which is non-vanishing."}, {"heading": "4.2 Sparsity-Constrained Precision Matrix Estimation", "text": "An important class of sparse learning problems involves estimating the precision (inverse covariance) matrix of high dimensional random vectors under the assumption that the true precision matrix is sparse. This problem arises in a variety of applications, among them computational biology, natural language processing and document analysis, where the model dimension may be comparable or substantially larger than the sample size. Specifically, for multivariate Gaussian distribution, precision matrix estimation is equivalent to learning the structure of Gaussian Markov random field (GMRF) (Edwards, 2000).\nLet x be a p-variate random vector with zero-mean Gaussian distribution N (0, \u03a3\u0304). Its density is parameterized by the precision matrix \u2126\u0304 = \u03a3\u0304\u22121 \u227b 0 as follows:\n\u03c6(x; \u2126\u0304) = 1 \u221a\n(2\u03c0)p(det \u2126\u0304)\u22121 exp\n(\n\u22121 2 x\u22a4\u2126\u0304x\n)\n.\nLet G = (V,E) be a graph representing conditional independence relations between components of x. The vertex set V has p elements corresponding to [x]1, ..., [x]p, and the edge set E consists of ordered pairs (i, j), where (i, j) \u2208 E if there is an edge between [x]i and [x]j . The edge between [x]i and [x]j is excluded from E if and only if [x]i and [x]j are independent given {[x]k, k 6= i, j}. It is well known that when x \u223c N (0, \u03a3\u0304), the conditional independence between [x]i and [x]j given other variables is equivalent to [\u2126\u0304]ij = 0. Thus for Gaussian distributions, learning the structure of G is equivalent to estimating the support of the precision matrix \u2126\u0304.\nGiven i.i.d. samples Xn = {x(i)}ni=1 drawn from N (0, \u03a3\u0304), the negative log-likelihood, up to a constant, can be written in terms of the precision matrix as\nL(Xn; \u2126\u0304) := \u2212 log det \u2126\u0304 + \u3008\u03a3n, \u2126\u0304\u3009,\nwhere \u03a3n is the sample covariance matrix. We are interested in the problem of estimating a sparse precision \u2126\u0304 with no more than a pre-specified number of off-diagonal non-zero entries. For this purpose, we consider the following cardinality constrained log-determinant program:\nmin \u2126\u227b0\nL(\u2126) := \u2212 log det \u2126 + \u3008\u03a3n,\u2126\u3009, s.t. \u2016\u2126\u2212\u20160 \u2264 2k, (4.5)\nwhere \u2126\u2212 is the restriction of \u2126 on the off-diagonal entries, \u2016\u2126\u2212\u20160 = |supp(\u2126\u2212)| is the cardinality of the support set of \u2126\u2212 and integer k > 0 bounds the number of edges |E| in GMRF.\n4.2.1 Verifying Condition C(s, \u03b6, \u03c1s)\nIt is easy to show that the Hessian \u22072L(\u2126) = \u2126\u22121 \u2297 \u2126\u22121, where \u2297 is the Kronecker product operator. The following result shows that L satisfies Condition C(s, \u03b6, \u03c1s) if the eigenvalues of \u2126 are lower bounded from zero and upper bounded.\nProposition 3. Suppose that \u2016\u2126\u2212\u20160 \u2264 s and \u03b1sI \u2126 \u03b2sI for some 0 < \u03b1s \u2264 \u03b2s. Then L(\u2126) satisfies Condition C(s, \u03b6, \u03c1s) with any\n\u03b6 < 2\u03b14s \u03b22s , \u03c1s = \u221a 1\u2212 2\u03b6\u03b2\u22122s + \u03b62\u03b1\u22124s .\nProof. Due to the fact that the eigenvalues of Kronecker products of symmetric matrices are the products of the eigenvalues of their factors, it holds that\n\u03b2\u22122s I \u2126\u22121 \u2297 \u2126\u22121 \u03b1\u22122s I.\nTherefore we have \u03b2\u22122s \u2264 \u2016\u22072L(\u2126)\u20162 \u2264 \u03b1\u22122s which implies that L(\u2126) is \u03b2\u22122s -strongly convex and \u03b1\u22122s -strongly smooth. The desired result follows directly from the Part(b) of Lemma 1.\nMotivated by Proposition 3, we consider applying GraHTP to the following modified version of problem (4.5):\nmin \u03b1I \u2126 \u03b2I\nL(\u2126), s.t. \u2016\u2126\u2212\u20160 \u2264 2k, (4.6)\nwhere 0 < \u03b1 \u2264 \u03b2 are two constants which respectively lower and upper bound the eigenvalues of the desired solution. To roughly estimate \u03b1 and \u03b2, we employ a rule proposed by Lu (2009, Proposition 3.1) for the \u21131 log-determinant program. Specifically, we set\n\u03b1 = (\u2016\u03a3n\u20162 + n\u03be)\u22121, \u03b2 = \u03be\u22121(n\u2212 \u03b1Tr(\u03a3n)),\nwhere \u03be is a small enough positive number (e.g., \u03be = 10\u22122 as utilized in our experiments)."}, {"heading": "4.2.2 Bounding the Estimation Error.", "text": "Let h := vect(\u2207L(\u2126\u0304)). It is known from Theorem 2 that the estimation error is controlled by \u2016hs\u20162. Since \u2207L(\u2126\u0304) = \u2212\u2126\u0304\u22121 + \u03a3n = \u03a3n \u2212 \u03a3\u0304, we have \u2016hs\u20162 \u2264 \u221a s|\u03a3n \u2212 \u03a3\u0304|\u221e. It is known that |\u03a3n \u2212 \u03a3\u0304|\u221e \u2264 \u221a\nlog p/n with probability at least 1 \u2212 c0p\u2212c1 for some positive constants c0 and c1 and sufficiently large n (see, e.g., Ravikumar et al., 2011, Lemma 1). Therefore with overwhelming probability we have \u2016hs\u20162 = O( \u221a s log p/n) when n is sufficiently large."}, {"heading": "4.2.3 A Modified GraHTP", "text": "Unfortunately, GraHTP is not directly applicable to the problem (4.6) due to the presence of the constraint \u03b1I \u2126 \u03b2I in addition to the sparsity constraint. To address this issue, we need to modify the debiasing step (S3) of GraHTP to minimize L(\u2126) over the constraint of \u03b1I \u2126 \u03b2I as well as the support set F (t):\nmin \u03b1I \u2126 \u03b2I\nL(\u2126), s.t. supp(\u2126) \u2286 F (t). (4.7)\nSince this problem is convex, any off-the-shelf convex solver can be applied for optimization. In our implementation, we resort to alternating direction method (ADM) for solving this subproblem because of its reported efficiency (Boyd et al., 2010; Yuan, 2012). The implementation details of ADM for solving (4.7) are deferred to Appendix B. The modified GraHTP for the precision matrix estimation problem is formally described in Algorithm 2.\nGenerally speaking, the guarantees in Theorem 1 and Theorem 2 are not valid for the modified GraHTP. However, if \u2126\u0304\u2212 \u03b1I and \u03b2I \u2212 \u2126\u0304 are diagonally dominant, then with a slight modification of proof, we can prove that the Part (a) of Theorem 2 is still valid for the modified GraHTP. We sketchily describe the proof idea as follows: Let Z := [\u2126\u0304]F (t) . Since \u2126\u0304\u2212\u03b1I and \u03b2I\u2212\u2126\u0304 are diagonally dominant, we have Z \u2212 \u03b1I and \u03b2I \u2212Z are also diagonally dominant and thus \u03b1I Z \u03b2I. Since \u2126(t) is the minimum of L(\u2126) restricted over the union of the cone \u03b1I \u2126 \u03b2I and the supporting set F (t), we have \u3008\u2207L(\u2126(t)), Z \u2212 \u2126(t)\u3009 \u2265 0. The remaining of the arguments follows that of the Part(a) of Theorem 2.\nAlgorithm 2: A Modified GraHTP for Sparse Precision Matrix Estimation.\nInitialization: \u2126(0) with \u2126(0) \u227b 0 and \u2016(\u2126(0))\u2212\u20160 \u2264 2k and \u03b1I \u2126(0) \u03b2I (typically \u2126(0) = \u03b1I), t = 1. Output: \u2126(t). repeat\n(S1) Compute \u2126\u0303(t) = \u2126(t\u22121) \u2212 \u03b7\u2207L(\u2126(t\u22121)); (S2) Let F\u0303 (t) = supp((\u2126\u0303(t))\u2212, 2k) be the indices of (\u2126\u0303(t))\u2212 with the largest 2k absolute values and F (t) = F\u0303 (t) \u222a {(1, 1), ..., (p, p)}; (S3) Compute \u2126(t) = argmin { L(\u2126), \u03b1I \u2126 \u03b2I, supp(\u2126) \u2286 F (t) }\n; t = t+ 1;\nuntil halting condition holds;"}, {"heading": "5 Experimental Results", "text": "This section is devoted to show the empirical performances of GraHTP and FGraHTP when applied to sparse logistic regression and sparse precision matrix estimation problems. Here we do not report the results of our algorithms in compressive sensing tasks because in these tasks GraHTP and FGraHTP reduce to the well studied HTP (Foucart, 2011) and IHT (Blumensath & Davies, 2009), respectively. Our algorithms are implemented in Matlab 7.12 running on a desktop with Intel Core i7 3.2G CPU and 16G RAM."}, {"heading": "5.1 Sparsity-Constrained \u21132-Regularized Logistic Regression.", "text": ""}, {"heading": "5.1.1 Monte-Carlo Simulation", "text": "We consider a synthetic data model identical to the one used in (Bahmani et al., 2013). The sparse parameter w\u0304 is a p = 1000 dimensional vector that has k\u0304 = 100 nonzero entries drawn independently from the standard Gaussian distribution. Each data sample is an independent instance of the random vector u generated by an autoregressive process [u]i+1 = \u03c1[u]i + \u221a\n1\u2212 \u03c12[a]i with [u]1 \u223c N (0, 1), [a]i \u223c N (0, 1), and \u03c1 = 0.5 being the correlation. The data labels, v \u2208 {\u22121, 1}, are then\ngenerated randomly according to the Bernoulli distribution\nP(v = 1|u; w\u0304) = exp(2w\u0304 \u22a4u)\n1 + exp(2w\u0304\u22a4u) .\nWe fix the regularization parameter \u03bb = 10\u22124 in the objective of (4.2). We are interested in the following two cases:\n1. Case 1: Cardinality k is fixed and sample size n is varying: we test with k = 100 and n \u2208 {100, 200, ..., 2000}.\n2. Case 2: Sample size n is fixed and cardinality k is varying: we test with n = 500 and k \u2208 {100, 150, ..., 500}.\nFor each case, we compare GraHTP and FGraHTP with two state-of-the-art greedy selection methods: GraSP (Bahmani et al., 2013) and FBS (Forward Basis Selection) (Yuan & Yan, 2013). As aforementioned, GraSP is also a hard-thresholding-type method. This method simultaneously selects at each iteration k nonzero entries and update their values via exploring the top k entries in the previous iterate as well as the top 2k entries in the previous gradient. FBS is a forwardselection-type method. This method iteratively selects an atom from the dictionary and minimizes the objective function over the linear combinations of all the selected atoms. Note that all the considered algorithms have geometric rate of convergence. We will compare the computational efficiency of these methods in our empirical study. We initialize w(0) = 0. Throughout our experiment, we set the stopping criterion as \u2016w(t) \u2212 w(t\u22121)\u2016/\u2016w(t\u22121)\u2016 \u2264 10\u22124.\nResults. Figure 5.1(a) presents the estimation errors of the considered algorithms. From the left panel of Figure 5.1(a) (i.e., Case 1) we observe that: (i) when cardinality k is fixed, the estimation errors of all the considered algorithms tend to decrease as sample size n increases; and (ii) in this case GraHTP and FGraHTP are comparable and both are superior to GraSP and FBS. From the right panel of Figure 5.1(a) (i.e., Case 2) we observe that: (i) when n is fixed, the estimation errors of all the considered algorithms but FBS tend to increase as k increases (FBS is relatively insensitive to k because it is a forward selection method); and (ii) in this case GraHTP and FGraHTP are comparable and both are superior to GraSP and FBS at relatively small k < 200. Figure 5.1(b) shows the CPU times of the considered algorithms. From this group of results we observe that in most cases, FBS is the fastest one while GraHTP and FGraHTP are superior or comparable to GraSP in computational time. We also observe that when k is relatively small, GraHTP is even faster than FGraHTP although FGraHTP is cheaper in per-iteration overhead. This is partially because when k is small, GraHTP tends to need fewer iterations than FGraHTP to converge."}, {"heading": "5.1.2 Real Data", "text": "The algorithms are also compared on the rcv1.binary dataset (p = 47,236) which is a popular dataset for binary classification on sparse data. A training subset of size n = 20,242 and a testing subset of size 20,000 are used. We test with sparsity parameters k \u2208 {100, 200, ..., 1000} and fix the regularization parameter \u03bb = 10\u22125. The initial vector is w(0) = 0 for all the considered algorithms. We set the stopping criterion as \u2016w(t) \u2212 w(t\u22121)\u2016/\u2016w(t\u22121)\u2016 \u2264 10\u22124 or the iteration stamp t > 50.\nFigure 5.2 shows the evolving curves of empirical logistic loss for k = 200, 400, 800, 1000. It can be observed from this figure that GraHTP and GraSP are comparable in terms of convergence rate and they are superior to FGraHTP and FBS. The testing classification errors and CPU running time of the considered algorithms are provided in Figure 5.3: (i) in terms of accuracy, all the considered methods are comparable; and (ii) in terms of running time, FGraHTP is the most efficient one; GraHTP is significantly faster than GraSP and FBS. The reason that FGraHTP runs fastest is because it has very low per-iteration cost although its convergence curve is slightly less sharper than GraHTP and GraSP (see Figure 5.2). To summarize, GraHTP and FGraHTP achieve better trade-offs between accuracy and efficiency than GraHTP and FBS on rcv1.binary dataset."}, {"heading": "5.2 Sparsity-Constrained Precision Matrix Estimation", "text": ""}, {"heading": "5.2.1 Monte-Carlo Simulation", "text": "Our simulation study employs the sparse precision matrix model \u2126\u0304 = B+\u03c3I where each off-diagonal entry in B is generated independently and equals 1 with probability P = 0.1 or 0 with probability 1 \u2212 P = 0.9. B has zeros on the diagonal, and \u03c3 is chosen so that the condition number of \u2126\u0304 is p. We generate a training sample of size n = 100 from N (0, \u03a3\u0304), and an independent sample of size 100 from the same distribution for tuning the parameter k. We compare performance for different values of p \u2208 {30, 60, 120, 200}, replicated 100 times each.\nWe compare the modified GraHTP (see Algorithm 2) with GraSP and FBS. To adopt GraSP to sparse precision matrix estimation, we modify the algorithm with a similar two-stage strategy as used in the modified GraHTP such that it can handle the eigenvalue bounding constraint in addition to the sparsity constraint. In the work of Yuan & Yan (2013), FBS has already been applied to sparse precision matrix estimation. Also, we compare GraHTP with GLasso (Graphical Lasso) which is a representative convex method for \u21131-penalized log-determinant program (Friedman et al., 2008). The quality of precision matrix estimation is measured by its distance to the truth in Frobenius norm and the support recovery F-score. The larger the F-score, the better the support recovery performance. The numerical values over 10\u22123 in magnitude are considered to be nonzero.\nFigure 5.4 compares the matrix error in Frobenius norm, sparse recovery F-score and CPU running time achieved by each of the considered algorithms for different p. The results show that GraHTP performs favorably in terms of estimation error and support recovery accuracy. We note that the standard errors of GraHTP is relatively larger than Glasso. This is as expected since GraHTP approximately solves a non-convex problem via greedy selection at each iteration; the procedure is less stable than convex methods such as GLasso. Similar phenomenon of instability is observed for GraSP and FBS. Figure 5.2.1 shows the computational time of the considered algorithms. We observed that GLasso, as a convex solver, is computationally superior to the three considered greedy selection methods. Although inferior to GLasso, GraHTP is computationally much more efficient than GraSP and FBS.\nTo visually inspect the support recovery performance of the considered algorithms, we show in Figure 5.5 the heatmaps corresponding to the percentage of each matrix entry being identified as a nonzero element with p = 60. Visual inspection on these heatmaps shows that the three greedy selection methods, GraHTP, GraSP, FBS, are sparser than GLasso. Similar phenomenon is observed in our experiments with other values of p."}, {"heading": "5.2.2 Real Data", "text": "We consider the task of LDA (linear discriminant analysis) classification of tumors using the breast cancer dataset (Hess et al., 2006), available at http://bioinformatics.mdanderson.org/. This dataset consists of 133 subjects, each of which is associated with 22,283 gene expression levels. Among these subjects, 34 are with pathological complete response (pCR) and 99 are with residual disease (RD). The pCR subjects are considered to have a high chance of cancer free survival in the long term. Based on the estimated precision matrix of the gene expression levels, we apply LDA to predict whether a subject can achieve the pCR state or the RD state.\nIn our experiment, we follow the same protocol used by (Cai et al., 2011) as well as references therein. The data are randomly divided into the training and test sets. In each random division, 5 pCR subjects and 16 RD subjects are randomly selected to constitute the test data, and the\nremaining subjects form the training set with n = 112. A two-sample t test is performed between the two groups for each gene, and the p = 113 most significant genes are selected as the covariants for prediction. The gene data are then normalized. Following the LDA framework, we assume that the normalized gene expression data are normally distributed as N (\u00b5l, \u03a3\u0304), where the two groups are assumed to have the same covariance matrix, \u03a3\u0304, but different means, \u00b5l, l = 1 for pCR state and l = 2 for RD state. The precision matrix \u2126\u0302 estimated by the considered methods is used in the LDA scores, \u03b4l(x) = x \u22a4\u2126\u0302\u00b5\u0302l \u2212 12 \u00b5\u0302\u22a4l \u2126\u0302\u00b5\u0302l + log \u03c0\u0302l, where \u00b5\u0302l = (1/nl) \u2211 i\u2208groupl xi is the within-class mean in the training set and \u03c0\u0302l = nl/n is the proportion of class l subjects in the training set. The classification rule is set as l\u0302(x) = argmaxl=1,2 \u03b4l(x).\nClearly, the classification performance is directly affected by the estimation accuracy of \u2126\u0302. We use the test data to assess the estimation performance and compare (modified) GraHTP with GraSP and FBS. We also compare GraHTP with GLasso (Graphical Lasso) (Friedman et al., 2008). We use a 6-fold cross-validation on the training data for tuning k. We repeat the experiment 100 times.\nResults. To compare the classification performance, we use specificity, sensitivity (or recall), and\nMathews correlation coefficient (MCC) criteria as in (Cai et al., 2011):\nSpecificity = TN\nTN+ FP , Sensitivity =\nTP\nTP + FN ,\nMCC = TP\u00d7 TN\u2212 FP\u00d7 FN \u221a\n(TP + FP)(TP + FN)(TN + FP)(TN + FN) ,\nwhere TP and TN stand for true positives (pCR) and true negatives (RD), respectively, and FP and FN stand for false positives/ negatives, respectively. The larger the criterion value, the better the classification performance. Since one can adjust decision threshold in any specific algorithm to trade-off specificity and sensitivity (increase one while reduce the other), the MCC is more meaningful as a single performance metric.\nTable 5.1 reports the averages standard deviations in the parentheses over the 100 replications of the experiment. It can be observed that GraHTP is quite competitive to the leading methods in terms of the three metrics. The mean of CPU running times (in seconds) of the three methods are listed in the last column of Table 5.1. Figure 5.6 shows the evolving curves of log-determinant loss verses number of iterations. We observed that on this data, GraHTP converges much faster than GraSP and FBS. Note that we did not draw the curve of GLasso in Figure 5.6 because its objective function is different from that of the problem (4.6)."}, {"heading": "6 Conclusion", "text": "In this paper, we propose GraHTP as a generalization of HTP from compressive sensing to the generic problem of sparsity-constrained optimization. The main idea is to force the gradient descent iteration to be sparse via hard threshloding. Theoretically, we prove that under mild conditions, GraHTP converges geometrically in finite steps of iteration and its estimation error is controlled by the restricted norm of gradient at the target sparse solution. We also propose and analyze the FGraHTP algorithm as a fast variant of GraHTP without the debiasing step. Empirically, we compare GraHTP and FGraHTP with several representative greedy selection methods when applied to sparse logistic regression and sparse precision matrix estimation tasks. Our theoretical results and empirical evidences show that simply combing gradient descent with hard threshloding, with or without debiasing, leads to efficient and accurate computational procedures for sparsity-constrained optimization problems."}, {"heading": "Acknowledgment", "text": "Xiao-Tong Yuan was a postdoctoral research associate supported by nsf-dms 0808864 and nsf-eager 1249316. Ping Li is supported by ONR-N00014-13-1-0764, AFOSR-FA9550-13-1-0137, and NSF-BigData 1250914. Tong Zhang is supported by nsf-iis 1016061, nsf-dms 1007527, and nsf-iis 1250985."}, {"heading": "A Technical Proofs", "text": "A.1 Proof of Lemma 1\nProof. Part (a): The first inequality follows from the triangle inequality. The second inequality can be derived by combining the first one and the integration f(x) \u2212 f(y) \u2212 \u3008\u2207f(y), x \u2212 y\u3009 = \u222b 1 0 \u3008\u2207f(y + \u03c4(x\u2212 y))\u2212\u2207f(y), x\u2212 y\u3009d\u03c4 .\nPart (b): By adding two copies of the inequality (3.1) with x and y interchanged and using the Theorem 2.1.5 in (Nesterov, 2004), we know that\n(x\u2212 y)\u22a4(\u2207f(x)\u2212\u2207f(y)) \u2265 ms\u2016x\u2212 y\u20162, \u2016\u2207F f(x)\u2212\u2207F f(y)\u2016 \u2264 Ms\u2016x\u2212 y\u2016.\nFor any \u03b6 > 0 we have\n\u2016x\u2212 y \u2212 \u03b6\u2207F f(x) + \u03b6\u2207F f(y)\u20162 \u2264 (1\u2212 2\u03b6ms + \u03b62M2s )\u2016x\u2212 y\u20162.\nIf \u03b6 < 2ms/M 2 s , then \u03c1s =\n\u221a\n1\u2212 2\u03b6ms + \u03b62M2s < 1. This proves the desired result.\nA.2 Proof of Theorem 1\nProof. We first prove the finite iteration guarantee of GraHTP. Let us consider the vector x\u0303 (t) k which is the restriction of x\u0303(t) on F (t). According to the definition of x(t) we have f(x(t)) \u2264 f(x\u0303(t)k ). It follows that\nf(x(t))\u2212 f(x(t\u22121)) \u2264 f(x\u0303(t)k )\u2212 f(x(t\u22121))\n\u2264 \u3008\u2207f(x(t\u22121)), x\u0303(t)k \u2212 x(t\u22121)\u3009+ 1 + \u03c12k 2\u03b6 \u2016x\u0303(t)k \u2212 x(t\u22121)\u20162 \u2264 \u2212 1 2\u03b7 \u2016x\u0303(t)k \u2212 x(t\u22121)\u20162 + 1 + \u03c12k 2\u03b6 \u2016x\u0303(t)k \u2212 x(t\u22121)\u20162 = \u2212\u03b6 \u2212 \u03b7(1 + \u03c12k) 2\u03b6\u03b7 \u2016x\u0303(t)k \u2212 x(t\u22121)\u20162, (A.1)\nwhere the second inequality follows from Lemma 1 and the third inequality follows from the fact that x\u0303 (t) k is a better k-sparse approximation to x\u0303 (t) than x(t\u22121) so that \u2016x\u0303(t)k \u2212 x\u0303(t)\u2016 = \u2016x\u0303 (t) k \u2212x(t\u22121)+ \u03b7\u2207f(x(t\u22121))\u20162 \u2264 \u2016x(t\u22121)\u2212x(t\u22121)+\u03b7\u2207f(x(t\u22121))\u20162 = \u2016\u03b7\u2207f(x(t\u22121))\u20162, which implies 2\u03b7\u3008\u2207f(x(t\u22121)), x\u0303(t)k \u2212 x(t\u22121)\u3009 \u2264 \u2212\u2016x\u0303(t)k \u2212 x(t\u22121)\u20162. Since \u03b7(1 + \u03c12k) < \u03b6, it follows that the sequence {f(x(t))} is nonincreasing, hence it is convergent. Since it is also eventually periodic, it must be eventually constant. In view of (A.1), we deduce that x\u0303 (t) k = x\n(t\u22121), and in particular that F (t) = F (t\u22121), for t large enough. This implies that x(t) = x(t\u22121) for t large enough, which implies the desired result.\nBy noting that x(t) = x\u0303 (t) k and from the inequality (A.1), we immediately establish the conver-\ngence of the sequence {f(x(t))} defined by FGraHTP.\nA.3 Proof of Theorem 2\nProof. Part (a): The first step of the proof is a consequence of the debiasing step S3. Since x(t) is the minimum of f(x) restricted over the supporting set F (t), we have \u3008\u2207f(x(t)), z\u3009 = 0 whenever\nsupp(z) \u2286 F (t). Let F\u0304 = supp(x\u0304) and F = F\u0304 \u222a F (t) \u222a F (t\u22121). It follows that\n\u2016(x(t) \u2212 x\u0304)F (t)\u20162 = \u3008x(t) \u2212 x\u0304, (x(t) \u2212 x\u0304)F (t)\u3009 = \u3008x(t) \u2212 x\u0304\u2212 \u03b6\u2207F (t)f(x(t)) + \u03b6\u2207F (t)f(x\u0304), (x(t) \u2212 x\u0304)F (t)\u3009 \u2212 \u03b6\u3008\u2207F (t)f(x\u0304), (x(t) \u2212 x\u0304)F (t)\u3009 \u2264 \u03c1s\u2016x(t) \u2212 x\u0304\u2016\u2016(x(t) \u2212 x\u0304)F (t)\u2016+ \u03b6\u2016\u2207kf(x\u0304)\u2016\u2016(x(t) \u2212 x\u0304)F (t)\u2016,\nwhere the last inequality is from Condition C(s, \u03b6, \u03c1s), \u03c1k+k\u0304 \u2264 \u03c1s and \u2016\u2207F (t)f(x\u0304)\u2016 \u2264 \u2016\u2207kf(x\u0304)\u2016. After simplification, we have \u2016(x(t) \u2212 x\u0304)F (t)\u2016 \u2264 \u03c1s\u2016x(t) \u2212 x\u0304\u2016+ \u03b6\u2016\u2207kf(x\u0304)\u2016. It follows that\n\u2016x(t) \u2212 x\u0304\u2016 \u2264 \u2016(x(t) \u2212 x\u0304)F (t)\u2016+ \u2016(x(t) \u2212 x\u0304)F (t)\u2016 \u2264 \u03c1s\u2016x (t) \u2212 x\u0304\u2016+ \u03b6\u2016\u2207kf(x\u0304)\u2016+ \u2016(x(t) \u2212 x\u0304)F (t)\u2016.\nAfter rearrangement we obtain\n\u2016x(t) \u2212 x\u0304\u2016 \u2264 \u2016(x(t) \u2212 x\u0304) F (t) \u2016\n1\u2212 \u03c1s + \u03b6\u2016\u2207kf(x\u0304)\u2016 1\u2212 \u03c1s . (A.2)\nThe second step of the proof is a consequence of steps S1 and S2. We notice that\n\u2016(x(t\u22121) \u2212 \u03b7\u2207f(x(t\u22121)))F\u0304 \u2016 \u2264 \u2016(x(t\u22121) \u2212 \u03b7\u2207f(x(t\u22121)))F (t)\u2016.\nBy eliminating the contribution on F\u0304 \u2229 F (t), we derive\n\u2016(x(t\u22121) \u2212 \u03b7\u2207f(x(t\u22121)))F\u0304 \\F (t)\u2016 \u2264 \u2016(x(t\u22121) \u2212 \u03b7\u2207f(x(t\u22121)))F (t)\\F\u0304 \u2016.\nFor the right-hand side, we have\n\u2016(x(t\u22121) \u2212 \u03b7\u2207f(x(t\u22121)))F (t)\\F\u0304 \u2016 \u2264 \u2016(x(t\u22121) \u2212 x\u0304\u2212 \u03b7\u2207f(x(t\u22121)) + \u03b7\u2207f(x\u0304))F (t)\\F\u0304 \u2016+ \u03b7\u2016\u2207kf(x\u0304)\u2016.\nAs for the left-hand side, we have\n\u2016(x(t\u22121) \u2212 \u03b7\u2207f(x(t\u22121)))F\u0304\\F (t)\u2016 \u2265 \u2016(x(t\u22121) \u2212 x\u0304\u2212 \u03b7\u2207f(x(t\u22121)) + \u03b7\u2207f(x\u0304))F\u0304\\F (t) + (x(t) \u2212 x\u0304)F (t)\u2016 \u2212 \u03b7\u2016\u2207kf(x\u0304)\u2016 \u2265 \u2016(x(t) \u2212 x\u0304)\nF (t) \u2016 \u2212 \u2016(x(t\u22121) \u2212 x\u0304\u2212 \u03b7\u2207f(x(t\u22121)) + \u03b7\u2207f(x\u0304))F\u0304 \\F (t)\u2016 \u2212 \u03b7\u2016\u2207kf(x\u0304)\u2016.\nWith F\u0304\u2206F (t) denoting the symmetric difference of the set F\u0304 and F (t), it follows that\n\u2016(x(t) \u2212 x\u0304) F (t) \u2016 \u2264 \u221a 2\u2016(x(t\u22121) \u2212 x\u0304\u2212 \u03b7\u2207f(x(t\u22121)) + \u03b7\u2207f(x\u0304))F\u0304\u2206F (t)\u2016+ 2\u03b7\u2016\u2207kf(x\u0304)\u2016 \u2264 \u221a 2\u2016x(t\u22121) \u2212 x\u0304\u2212 \u03b7\u2207F f(x(t\u22121)) + \u03b7\u2207F f(x\u0304)\u2016+ 2\u03b7\u2016\u2207kf(x\u0304)\u2016 \u2264 \u221a 2\u2016x(t\u22121) \u2212 x\u0304\u2212 \u03b6\u2207Ff(x(t\u22121)) + \u03b6\u2207F f(x\u0304)\u2016+ \u221a 2(\u03b6 \u2212 \u03b7)\u2016\u2207F f(x(t\u22121))\u2212\u2207F f(x\u0304)\u2016+ 2\u03b7\u2016\u2207kf(x\u0304)\u2016 \u2264 \u221a 2(1\u2212 \u03b7/\u03b6 + (2\u2212 \u03b7/\u03b6)\u03c1s)\u2016x(t\u22121) \u2212 x\u0304\u2016+ 2\u03b7\u2016\u2207kf(x\u0304)\u2016, (A.3)\nwhere the last inequality follows from Condition C(s, \u03b6, \u03c1s), \u03b7 < \u03b6 and Lemma 1. As a final step, we put (A.2) and (A.3) together to obtain\n\u2016x(t) \u2212 x\u0304\u2016 \u2264 \u221a 2(1\u2212 \u03b7/\u03b6 + (2\u2212 \u03b7/\u03b6)\u03c1s)\n1\u2212 \u03c1s \u2016x(t\u22121) \u2212 x\u0304\u2016+ (2\u03b7 + \u03b6)\u2016\u2207kf(x\u0304)\u2016 1\u2212 \u03c1s\nSince \u00b51 = \u221a 2(1 \u2212 \u03b7/\u03b6 + (2 \u2212 \u03b7/\u03b6)\u03c1s)/(1 \u2212 \u03c1s) < 1, by recursively applying the above inequality we obtain the desired inequality in part (a).\nPart (b): Recall that F (t) = supp(x(t), k) and F = F (t\u22121) \u222a F (t) \u222a supp(x\u0304). Consider the following vector y = x(t\u22121) \u2212 \u03b7\u2207F f(x(t\u22121)). By using triangular inequality we have\n\u2016y \u2212 x\u0304\u2016 = \u2016x(t\u22121) \u2212 \u03b7\u2207F f(x(t\u22121))\u2212 x\u0304\u2016 \u2264 \u2016x(t\u22121) \u2212 x\u0304\u2212 \u03b7\u2207F f(x(t\u22121)) + \u03b7\u2207F f(x\u0304)\u2016+ \u03b7\u2016\u2207F f(x\u0304)\u2016 \u2264 (1\u2212 \u03b7/\u03b6 + (2\u2212 \u03b7/\u03b6)\u03c1s)\u2016x(t\u22121) \u2212 x\u0304\u2016+ \u03b7\u2016\u2207sf(x\u0304)\u2016,\nwhere the last inequality follows from Condition C(s, \u03b6, \u03c1s), \u03b7 < \u03b6 and \u2016\u2207F f(x\u0304)\u2016 \u2264 \u2016\u2207sf(x\u0304)\u2016. For FGraHTP, we note that x(t) = x\u0303\n(t) k = yk, and thus \u2016x(t) \u2212 x\u0304\u2016 \u2264 \u2016x(t) \u2212 y\u2016+ \u2016y \u2212 x\u0304\u2016 \u2264 2\u2016y \u2212 x\u0304\u2016. It\nfollows that\n\u2016x(t) \u2212 x\u0304\u2016 \u2264 2(1 \u2212 \u03b7/\u03b6 + (2\u2212 \u03b7/\u03b6)\u03c1s)\u2016x(t\u22121) \u2212 x\u0304\u2016+ 2\u03b7\u2016\u2207sf(x\u0304)\u2016.\nSince \u00b52 = 2(1 \u2212 \u03b7/\u03b6 + (2 \u2212 \u03b7/\u03b6)\u03c1s) < 1, by recursively applying the above inequality we obtain the desired inequality in part (b).\nA.4 Proof of Proposition 1\nProof. Obviously, f(w) is \u03bb-strongly convex. Consider an index set F with cardinality |F | \u2264 s and all w,w\u2032 with supp(w)\u222a supp(w\u2032) \u2286 F . Since \u03c3(z) is Lipschitz continuous with constant 1, we have\n|[a(w)]i \u2212 [a(w\u2032)]i)| = 2|\u03c3(2v(i)w\u22a4u(i))\u2212 \u03c3(2v(i)w\u2032\u22a4u(i))| \u2264 4|(w \u2212 w\u2032)\u22a4v(i)u(i)| \u2264 4\u2016(u(i))F \u2016\u2016w \u2212 w\u2032\u2016 \u2264 4Rs\u2016w \u2212w\u2032\u2016,\nwhich implies \u2016a(w) \u2212 a(w\u2032)\u2016\u221e \u2264 4Rs\u2016w \u2212 w\u2032\u2016.\nTherefore we have\n\u2016\u2207F f(w)\u2212\u2207F f(w\u2032)\u2016 \u2264 1\nn \u2016UF\u2022(a(w) \u2212 a(w\u2032))\u2016 + \u03bb\u2016w \u2212 w\u2032\u2016\n\u2264 1 n \u2016UF\u2022(a(w) \u2212 a(w\u2032))\u20161 + \u03bb\u2016w \u2212 w\u2032\u2016 \u2264 1 n |UF\u2022|1\u2016a(w) \u2212 a(w\u2032)\u2016\u221e + \u03bb\u2016w \u2212 w\u2032\u2016 \u2264 (4\u221asR2s + \u03bb)\u2016w \u2212 w\u2032\u2016,\nwhere the second \u201c\u2264\u201d follows \u2016x\u2016 \u2264 \u2016x\u20161, the third \u201c\u2264\u201d follows from \u2016Ax\u20161 \u2264 |A|1\u2016x\u2016\u221e, and last \u201c\u2264\u201d follows from |UF\u2022|1 \u2264 n \u221a smaxi \u2016[u(i)]F\u2016 \u2264 n \u221a sRs. Therefore f is (4 \u221a sR2s + \u03bb)-strongly smooth. The desired result follows directly from Part(b) of Lemma 1.\nA.5 Proof of Proposition 2\nProof. For any index set F with |F | \u2264 s, we can deduce\n\u2016\u2207F f(w\u0304)\u2016 \u2264 \u2016[\u2207l(w\u0304)]F \u2016+ \u03bb\u2016w\u0304F \u2016 \u2264 \u221a s\u2016\u2207l(w\u0304)\u2016\u221e + \u03bb\u2016w\u0304s\u2016. (A.4)\nWe next bound the term \u2016\u2207l(w\u0304)\u2016\u221e. From (4.4) we have \u2223\n\u2223 \u2223 \u2223\n\u2202l\n\u2202[w\u0304]j\n\u2223 \u2223 \u2223 \u2223 =\n\u2223 \u2223 \u2223 \u2223 \u2223 1 n n \u2211\ni=1\n\u2212v(i)[u(i)]j + Ev[v[u(i)]j | u(i)] \u2223 \u2223 \u2223 \u2223\n\u2223\n\u2264 \u2223 \u2223 \u2223\n\u2223 \u2223\n1\nn\nn \u2211\ni=1\nv(i)[u(i)]j \u2212 E[v[u]j ] \u2223 \u2223 \u2223 \u2223\n\u2223\n+\n\u2223 \u2223 \u2223 \u2223 \u2223 1 n n \u2211\ni=1\nEv[v[u (i)]j | u(i)]\u2212 E[v[u]j ]\n\u2223 \u2223 \u2223 \u2223 \u2223 ,\nwhere E[] is taken over the distribution (4.3). Therefore, for any \u03b5 > 0,\nP\n( \u2223\n\u2223 \u2223 \u2223\n\u2202l\n\u2202[w\u0304]j\n\u2223 \u2223 \u2223 \u2223 > \u03b5 ) \u2264 P ( \u2223 \u2223 \u2223 \u2223\n\u2223\n1\nn\nn \u2211\ni=1\nv(i)[u(i)]j \u2212 E[v[u]j ] \u2223 \u2223 \u2223 \u2223\n\u2223\n> \u03b5\n2\n)\n+P\n(\u2223\n\u2223 \u2223 \u2223 \u2223 1 n\nn \u2211\ni=1\nEv[v[u (i)]j | u(i)]\u2212 E[v[u]j ]\n\u2223 \u2223 \u2223 \u2223 \u2223 > \u03b5 2 )\n\u2264 4 exp { \u2212n\u03b5 2\n8\u03c32\n}\n,\nwhere the last \u201c\u2264\u201d follows from the large deviation inequality of sub-Gaussian random variables which is standard (see, e.g., Vershynin, 2011). By the union bound we have\nP(\u2016\u2207l(w\u0304)\u2016\u221e > \u03b5) \u2264 4p exp { \u2212n\u03b5 2\n8\u03c32\n}\n.\nBy letting \u03b5 = 4\u03c3 \u221a ln p/n, we know that with probability at least 1\u2212 4p\u22121,\n\u2016\u2207l(w\u0304)\u2016\u221e \u2264 4\u03c3 \u221a ln p/n.\nCombing the above inequality with (A.4) yields the desired result.\nB Solving Subproblem (4.7) via ADM\nIn this appendix section, we provide our implementation details of ADM for solving the subproblem (4.7). By introducing an auxiliary variable \u0398 \u2208 Rp\u00d7p, the problem (4.7) is obviously equivalent to the following problem:\nmin \u03b1I \u2126 \u03b2I\nL(\u2126), s.t. \u2126 = \u0398, supp(\u0398) \u2286 F. (B.1)\nThen, the Augmented Lagrangian function of (B.1) is\nJ(\u2126,\u0398,\u0393) := L(\u2126)\u2212 \u3008\u0393,\u2126\u2212\u0398\u3009+ \u03c1 2 \u2016\u2126 \u2212\u0398\u20162Frob,\nwhere \u0393 \u2208 Rp\u00d7p is the multiplier of the linear constraint \u2126 = \u0398 and \u03c1 > 0 is the penalty parameter for the violation of the linear constraint. The ADM solves the following problems to generate the new iterate:\n\u2126(\u03c4+1) = argmin \u03b1I \u2126 \u03b2I J(\u2126,\u0398(\u03c4),\u0393(\u03c4)), (B.2)\n\u0398(\u03c4+1) = argmin supp(\u0398)\u2286F J(\u2126(\u03c4+1),\u0398,\u0393(\u03c4)), (B.3)\n\u0393(\u03c4+1) = \u0393(\u03c4) \u2212 \u03c1(\u2126(\u03c4+1) \u2212\u0398(\u03c4+1)).\nLet us first consider the minimization problem (B.2). It is easy to verify that it is equivalent to the following minimization problem:\n\u2126(\u03c4+1) = argmin \u03b1I \u2126 \u03b2I\n1 2 \u2016\u2126\u2212M\u20162Frob \u2212 1 \u03c1 log det\u2126,\nwhere\nM = \u0398(\u03c4) \u2212 1 \u03c1 (\u03a3n \u2212 \u0393(\u03c4)).\nLet the singular value decomposition of M be\nM = V \u039bV \u22a4, with \u039b = diag(\u03bb1, ..., \u03bbn).\nIt is easy to verify that the solution of problem (B.2) is given by\n\u2126(\u03c4+1) = V \u039b\u0303V \u22a4, with \u039b\u0303 = diag(\u03bb\u03031, ..., \u03bb\u0303n),\nwhere\n\u03bb\u0303j = min\n\n\n\n\u03b2,max\n\n\n\n\u03b1, \u03bbj +\n\u221a\n\u03bb2j + 4/\u03c1\n2\n\n\n\n\n\n\n.\nNext, we consider the minimization problem (B.3). It is straightforward to see that the solution of problem (B.3) is given by\n\u0398(\u03c4+1) = [ \u2126(\u03c4+1) \u2212 1/\u03c1\u0393(\u03c4) ]\nF ."}], "references": [{"title": "Fast global convergence rates of gradient methods for high-dimensional statistical recovery", "author": ["A. Agarwal", "S. Negahban", "M. Wainwright"], "venue": "In Proceedings of the 24th Annual Conference on Neural Information Processing Systems", "citeRegEx": "Agarwal et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Agarwal et al\\.", "year": 2010}, {"title": "Greedy sparsity-constrained optimization", "author": ["S. Bahmani", "B. Raj", "P. Boufounos"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bahmani et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bahmani et al\\.", "year": 2013}, {"title": "A fast iterative shrinkage-thresholding algorithm for linear inverse problems", "author": ["A. Beck", "Teboulle", "Marc"], "venue": "SIAM Journal on Imaging Sciences,", "citeRegEx": "Beck et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Beck et al\\.", "year": 2009}, {"title": "Pattern Recognition and Machine Learning", "author": ["C.M. Bishop"], "venue": "ISBN 978-0-387-31073-2", "citeRegEx": "Bishop,? \\Q2006\\E", "shortCiteRegEx": "Bishop", "year": 2006}, {"title": "Iterative hard thresholding for compressed sensing", "author": ["T. Blumensath", "M.E. Davies"], "venue": "Applied and Computational Harmonic Analysis,", "citeRegEx": "Blumensath and Davies,? \\Q2009\\E", "shortCiteRegEx": "Blumensath and Davies", "year": 2009}, {"title": "Distributed optimization and statistical learning via the alternating direction method of multipliers", "author": ["S. Boyd", "N. Parikh", "E. Chu", "B. Peleato", "J. Eckstein"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Boyd et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Boyd et al\\.", "year": 2010}, {"title": "A constrained l1 minimization approach to sparse precision matrix estimation", "author": ["T. Cai", "W. liu", "X. Luo"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Cai et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Cai et al\\.", "year": 2011}, {"title": "Stable signal recovery from incomplete and inaccurate measurements", "author": ["E.J. Cand\u00e8s", "J.K. Romberg", "T. Tao"], "venue": "Communications on Pure and Applied Mathematics,", "citeRegEx": "Cand\u00e8s et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Cand\u00e8s et al\\.", "year": 2006}, {"title": "Subspace pursuit for compressive sensing signal reconstruction", "author": ["W. Dai", "O. Milenkovic"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Dai and Milenkovic,? \\Q2009\\E", "shortCiteRegEx": "Dai and Milenkovic", "year": 2009}, {"title": "Introduction to Graphical Modelling", "author": ["D.M. Edwards"], "venue": null, "citeRegEx": "Edwards,? \\Q2000\\E", "shortCiteRegEx": "Edwards", "year": 2000}, {"title": "Hard thresholding pursuit: An algorithm for compressive sensing", "author": ["S. Foucart"], "venue": "SIAM Journal on Numerical Analysis,", "citeRegEx": "Foucart,? \\Q2011\\E", "shortCiteRegEx": "Foucart", "year": 2011}, {"title": "Sparse recovery algorithms: sufficient conditions in terms of restricted isometry constants", "author": ["S. Foucart"], "venue": "In Approximation Theory XIII: San Antonio 2010,", "citeRegEx": "Foucart,? \\Q2012\\E", "shortCiteRegEx": "Foucart", "year": 2012}, {"title": "An algorithm for quadratic programming", "author": ["M. Frank", "P. Wolfe"], "venue": "Naval Res. Logist. Quart.,", "citeRegEx": "Frank and Wolfe,? \\Q1956\\E", "shortCiteRegEx": "Frank and Wolfe", "year": 1956}, {"title": "Sparse inverse covariance estimation with the graphical lasso", "author": ["J. Friedman", "T. Hastie", "R. Tibshirani"], "venue": null, "citeRegEx": "Friedman et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Friedman et al\\.", "year": 2008}, {"title": "Pharmacogenomic predictor of snesitivity to preoperative chemotherapy with paclitaxel and fluorouracil, doxorubicin, and cyclophosphamide in breast cancer", "author": ["K.R. Hess", "K. Anderson", "W.F. Symmans"], "venue": "Journal of Clinical Oncology,", "citeRegEx": "Hess et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hess et al\\.", "year": 2006}, {"title": "Sparse convex optimization methods for machine learning", "author": ["M. Jaggi"], "venue": "Technical report, PhD thesis in Theoretical Computer Science, ETH Zurich,", "citeRegEx": "Jaggi,? \\Q2011\\E", "shortCiteRegEx": "Jaggi", "year": 2011}, {"title": "On learning discrete graphical models using greedy methods", "author": ["A. Jalali", "C.C. Johnson", "P.K. Ravikumar"], "venue": "In Proceedings of the 25th Annual Conference on Neural Information Processing Systems", "citeRegEx": "Jalali et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Jalali et al\\.", "year": 2011}, {"title": "Gradient lasso for feature selection", "author": ["Kim", "Yongdai", "Jinseog"], "venue": "In Proceedings of the Twentyfirst International Conference on Machine Learning", "citeRegEx": "Kim et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2004}, {"title": "Smooth optimization approach for sparse covariance selection", "author": ["Z. Lu"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Lu,? \\Q2009\\E", "shortCiteRegEx": "Lu", "year": 2009}, {"title": "Sparse principal component analysis and iterative thresholding", "author": ["Z. Ma"], "venue": "Annals of Statistics,", "citeRegEx": "Ma,? \\Q2013\\E", "shortCiteRegEx": "Ma", "year": 2013}, {"title": "Matching pursuits with time-frequency dictionaries", "author": ["S. Mallat", "Zhang", "Zhifeng"], "venue": "IEEE Transactions on Signal Processing,", "citeRegEx": "Mallat et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Mallat et al\\.", "year": 1993}, {"title": "Sparse approximate solutions to linear systems", "author": ["B.K. Natarajan"], "venue": "SIAM Journal on Computing,", "citeRegEx": "Natarajan,? \\Q1995\\E", "shortCiteRegEx": "Natarajan", "year": 1995}, {"title": "Cosamp: iterative signal recovery from incomplete and inaccurate samples", "author": ["D. Needell", "J.A. Tropp"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Needell and Tropp,? \\Q2009\\E", "shortCiteRegEx": "Needell and Tropp", "year": 2009}, {"title": "Introductory Lectures on Convex Optimization: A", "author": ["Y. Nesterov"], "venue": "Basic Course. Kluwer,", "citeRegEx": "Nesterov,? \\Q2004\\E", "shortCiteRegEx": "Nesterov", "year": 2004}, {"title": "High-dimensional covariance estimation by minimizing l1-penalized log-determinant divergence", "author": ["P. Ravikumar", "M.J. Wainwright", "G. Raskutti", "B. Yu"], "venue": "Electronic Journal of Statistics,", "citeRegEx": "Ravikumar et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ravikumar et al\\.", "year": 2011}, {"title": "Trading accuracy for sparsity in optimization problems with sparsity constraints", "author": ["Shalev-Shwartz", "Shai", "Srebro", "Nathan", "Zhang", "Tong"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2010}, {"title": "Greedy algorithms for structurally constrained high dimensional problems", "author": ["A. Tewari", "P. Ravikumar", "I.S. Dhillon"], "venue": "In Proceedings of the 25th Annual Conference on Neural Information Processing Systems", "citeRegEx": "Tewari et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Tewari et al\\.", "year": 2011}, {"title": "Signal recovery from random measurements via orthogonal matching pursuit", "author": ["J. Tropp", "A. Gilbert"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Tropp and Gilbert,? \\Q2007\\E", "shortCiteRegEx": "Tropp and Gilbert", "year": 2007}, {"title": "Introduction to the non-asymptotic analysis of random matrices", "author": ["Vershynin", "Roman"], "venue": null, "citeRegEx": "Vershynin and Roman.,? \\Q2011\\E", "shortCiteRegEx": "Vershynin and Roman.", "year": 2011}, {"title": "Graphical models, exponential families, and variational inference", "author": ["M.J. Wainwright", "M.I. Jordan"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Wainwright and Jordan,? \\Q2008\\E", "shortCiteRegEx": "Wainwright and Jordan", "year": 2008}, {"title": "Alternating direction method of multipliers for covariance selection models", "author": ["X.M. Yuan"], "venue": "Journal of Scientific Computing,", "citeRegEx": "Yuan,? \\Q2012\\E", "shortCiteRegEx": "Yuan", "year": 2012}, {"title": "Forward basis selection for sparse approximation over dictionary", "author": ["Yuan", "X.-T", "S. Yan"], "venue": "In Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics (AISTATS\u201912),", "citeRegEx": "Yuan et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Yuan et al\\.", "year": 2012}, {"title": "Forward basis selection for pursuing sparse representations over a dictionary", "author": ["Yuan", "X.-T", "S. Yan"], "venue": "IEEE Transactions on Pattern Analysis And Machine Intelligence,", "citeRegEx": "Yuan et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Yuan et al\\.", "year": 2013}, {"title": "Truncated power method for sparse eigenvalue problems", "author": ["Yuan", "X.-T", "T. Zhang"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Yuan et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Yuan et al\\.", "year": 2013}, {"title": "Adative forward-backward greedy algorithm for sparse learning with linear models", "author": ["T. Zhang"], "venue": "In Proceedings of the 22nd Annual Conference on Neural Information Processing Systems", "citeRegEx": "Zhang,? \\Q2008\\E", "shortCiteRegEx": "Zhang", "year": 2008}], "referenceMentions": [{"referenceID": 1, "context": "Among others, several examples falling into this model include: (i) Sparsity-constrained linear regression model (Tropp & Gilbert, 2007) where the residual error is used to measure data reconstruction error; (ii) Sparsity-constrained logistic regression model (Bahmani et al., 2013) where the sigmoid loss is used to measure prediction error; (iii) Sparsity-constrained graphical model learning (Jalali et al.", "startOffset": 260, "endOffset": 282}, {"referenceID": 16, "context": ", 2013) where the sigmoid loss is used to measure prediction error; (iii) Sparsity-constrained graphical model learning (Jalali et al., 2011) where the likelihood of samples drawn from an underlying probabilistic model is used to measure data fidelity.", "startOffset": 120, "endOffset": 141}, {"referenceID": 21, "context": "1) is generally NP-hard even for the quadratic cost function (Natarajan, 1995).", "startOffset": 61, "endOffset": 78}, {"referenceID": 10, "context": "A vast body of greedy selection algorithms for compressing sensing have been proposed including matching pursuit (Mallat & Zhang, 1993), orthogonal matching pursuit (Tropp & Gilbert, 2007), compressive sampling matching pursuit (Needell & Tropp, 2009), hard thresholding pursuit (Foucart, 2011), iterative hard thresholding (Blumensath & Davies, 2009) and subspace pursuit (Dai & Milenkovic, 2009) to name a few.", "startOffset": 279, "endOffset": 294}, {"referenceID": 0, "context": "Comparing to those first-order convex optimization methods developed for l1-regularized sparse learning (Beck & Teboulle, 2009; Agarwal et al., 2010), these greedy selection algorithms often exhibit similar accuracy guarantees but more attractive computational efficiency.", "startOffset": 104, "endOffset": 149}, {"referenceID": 3, "context": "For example, in statistical machine learning the log-likelihood function is commonly used in logistic regression problems (Bishop, 2006) and graphical models learning (Jalali et al.", "startOffset": 122, "endOffset": 136}, {"referenceID": 16, "context": "For example, in statistical machine learning the log-likelihood function is commonly used in logistic regression problems (Bishop, 2006) and graphical models learning (Jalali et al., 2011; Ravikumar et al., 2011).", "startOffset": 167, "endOffset": 212}, {"referenceID": 24, "context": "For example, in statistical machine learning the log-likelihood function is commonly used in logistic regression problems (Bishop, 2006) and graphical models learning (Jalali et al., 2011; Ravikumar et al., 2011).", "startOffset": 167, "endOffset": 212}, {"referenceID": 25, "context": "To this end, several forward selection algorithms have been proposed to select the nonzero entries in a sequential fashion (Kim & Kim, 2004; Shalev-Shwartz et al., 2010; Yuan & Yan, 2013; Jaggi, 2011).", "startOffset": 123, "endOffset": 200}, {"referenceID": 15, "context": "To this end, several forward selection algorithms have been proposed to select the nonzero entries in a sequential fashion (Kim & Kim, 2004; Shalev-Shwartz et al., 2010; Yuan & Yan, 2013; Jaggi, 2011).", "startOffset": 123, "endOffset": 200}, {"referenceID": 26, "context": "The forward greedy selection method has also been generalized to minimize a convex objective over the linear hull of a collection of atoms (Tewari et al., 2011; Yuan & Yan, 2012).", "startOffset": 139, "endOffset": 178}, {"referenceID": 19, "context": "The hard-threshholding-type methods have also been shown to be statistically and computationally efficient for sparse principal component analysis (Yuan & Zhang, 2013; Ma, 2013).", "startOffset": 147, "endOffset": 177}, {"referenceID": 23, "context": "The forward greedy selection method has also been generalized to minimize a convex objective over the linear hull of a collection of atoms (Tewari et al., 2011; Yuan & Yan, 2012). To make the greedy selection procedure more adaptive, Zhang (2008) proposed a forward-backward algorithm which takes backward steps adaptively whenever beneficial.", "startOffset": 140, "endOffset": 247}, {"referenceID": 15, "context": "Jalali et al. (2011) have applied this forward-backward selection method to learn the structure of a sparse graphical model.", "startOffset": 0, "endOffset": 21}, {"referenceID": 1, "context": "More recently, Bahmani et al. (2013) proposed a gradient hard-thresholding method which generalizes the compressive sampling matching pursuit method (Needell & Tropp, 2009) from compressive sensing to the general sparsity-constrained optimization problem.", "startOffset": 15, "endOffset": 37}, {"referenceID": 10, "context": "We close this section by pointing out that, in the special case where the squared error f(x) = 1 2\u2016y\u2212Ax\u2016 is the cost function, GraHTP reduces to HTP (Foucart, 2011).", "startOffset": 149, "endOffset": 164}, {"referenceID": 34, "context": "We may establish the connections between condition C(s, \u03b6, \u03c1s) and the conditions of restricted strong convexity/smoothness which are key to the analysis of several previous greedy selection methods (Zhang, 2008; Shalev-Shwartz et al., 2010; Yuan & Yan, 2013; Bahmani et al., 2013).", "startOffset": 199, "endOffset": 281}, {"referenceID": 25, "context": "We may establish the connections between condition C(s, \u03b6, \u03c1s) and the conditions of restricted strong convexity/smoothness which are key to the analysis of several previous greedy selection methods (Zhang, 2008; Shalev-Shwartz et al., 2010; Yuan & Yan, 2013; Bahmani et al., 2013).", "startOffset": 199, "endOffset": 281}, {"referenceID": 1, "context": "We may establish the connections between condition C(s, \u03b6, \u03c1s) and the conditions of restricted strong convexity/smoothness which are key to the analysis of several previous greedy selection methods (Zhang, 2008; Shalev-Shwartz et al., 2010; Yuan & Yan, 2013; Bahmani et al., 2013).", "startOffset": 199, "endOffset": 281}, {"referenceID": 7, "context": "This condition of \u03c1s is analogous to the RIP condition for estimation from noisy measurements in compressive sensing (Cand\u00e8s et al., 2006; Needell & Tropp, 2009; Foucart, 2011).", "startOffset": 117, "endOffset": 176}, {"referenceID": 10, "context": "This condition of \u03c1s is analogous to the RIP condition for estimation from noisy measurements in compressive sensing (Cand\u00e8s et al., 2006; Needell & Tropp, 2009; Foucart, 2011).", "startOffset": 117, "endOffset": 176}, {"referenceID": 1, "context": "For the general sparsity-constrained optimization problem, we note that a similar estimation error bound has been established for the GraSP (Gradient Support Pursuit) method (Bahmani et al., 2013) which is another hard-thresholding-type method.", "startOffset": 174, "endOffset": 196}, {"referenceID": 3, "context": "1 Sparsity-Constrained l2-Regularized Logistic Regression Logistic regression is one of the most popular models in statistics and machine learning (Bishop, 2006).", "startOffset": 147, "endOffset": 161}, {"referenceID": 9, "context": "Specifically, for multivariate Gaussian distribution, precision matrix estimation is equivalent to learning the structure of Gaussian Markov random field (GMRF) (Edwards, 2000).", "startOffset": 161, "endOffset": 176}, {"referenceID": 5, "context": "In our implementation, we resort to alternating direction method (ADM) for solving this subproblem because of its reported efficiency (Boyd et al., 2010; Yuan, 2012).", "startOffset": 134, "endOffset": 165}, {"referenceID": 30, "context": "In our implementation, we resort to alternating direction method (ADM) for solving this subproblem because of its reported efficiency (Boyd et al., 2010; Yuan, 2012).", "startOffset": 134, "endOffset": 165}, {"referenceID": 10, "context": "Here we do not report the results of our algorithms in compressive sensing tasks because in these tasks GraHTP and FGraHTP reduce to the well studied HTP (Foucart, 2011) and IHT (Blumensath & Davies, 2009), respectively.", "startOffset": 154, "endOffset": 169}, {"referenceID": 1, "context": "1 Monte-Carlo Simulation We consider a synthetic data model identical to the one used in (Bahmani et al., 2013).", "startOffset": 89, "endOffset": 111}, {"referenceID": 1, "context": "For each case, we compare GraHTP and FGraHTP with two state-of-the-art greedy selection methods: GraSP (Bahmani et al., 2013) and FBS (Forward Basis Selection) (Yuan & Yan, 2013).", "startOffset": 103, "endOffset": 125}, {"referenceID": 13, "context": "Also, we compare GraHTP with GLasso (Graphical Lasso) which is a representative convex method for l1-penalized log-determinant program (Friedman et al., 2008).", "startOffset": 135, "endOffset": 158}, {"referenceID": 18, "context": "2 Sparsity-Constrained Precision Matrix Estimation 5.2.1 Monte-Carlo Simulation Our simulation study employs the sparse precision matrix model \u03a9\u0304 = B+\u03c3I where each off-diagonal entry in B is generated independently and equals 1 with probability P = 0.1 or 0 with probability 1 \u2212 P = 0.9. B has zeros on the diagonal, and \u03c3 is chosen so that the condition number of \u03a9\u0304 is p. We generate a training sample of size n = 100 from N (0, \u03a3\u0304), and an independent sample of size 100 from the same distribution for tuning the parameter k. We compare performance for different values of p \u2208 {30, 60, 120, 200}, replicated 100 times each. We compare the modified GraHTP (see Algorithm 2) with GraSP and FBS. To adopt GraSP to sparse precision matrix estimation, we modify the algorithm with a similar two-stage strategy as used in the modified GraHTP such that it can handle the eigenvalue bounding constraint in addition to the sparsity constraint. In the work of Yuan & Yan (2013), FBS has already been applied to sparse precision matrix estimation.", "startOffset": 33, "endOffset": 971}, {"referenceID": 14, "context": "2 Real Data We consider the task of LDA (linear discriminant analysis) classification of tumors using the breast cancer dataset (Hess et al., 2006), available at http://bioinformatics.", "startOffset": 128, "endOffset": 147}, {"referenceID": 6, "context": "In our experiment, we follow the same protocol used by (Cai et al., 2011) as well as references therein.", "startOffset": 55, "endOffset": 73}, {"referenceID": 13, "context": "We also compare GraHTP with GLasso (Graphical Lasso) (Friedman et al., 2008).", "startOffset": 53, "endOffset": 76}, {"referenceID": 6, "context": "Mathews correlation coefficient (MCC) criteria as in (Cai et al., 2011):", "startOffset": 53, "endOffset": 71}, {"referenceID": 23, "context": "5 in (Nesterov, 2004), we know that (x\u2212 y)(\u2207f(x)\u2212\u2207f(y)) \u2265 ms\u2016x\u2212 y\u2016, \u2016\u2207F f(x)\u2212\u2207F f(y)\u2016 \u2264 Ms\u2016x\u2212 y\u2016.", "startOffset": 5, "endOffset": 21}], "year": 2017, "abstractText": "Hard Thresholding Pursuit (HTP) is an iterative greedy selection procedure for finding sparse solutions of underdetermined linear systems. This method has been shown to have strong theoretical guarantee and impressive numerical performance. In this paper, we generalize HTP from compressive sensing to a generic problem setup of sparsity-constrained convex optimization. The proposed algorithm iterates between a standard gradient descent step and a hard thresholding step with or without debiasing. We prove that our method enjoys the strong guarantees analogous to HTP in terms of rate of convergence and parameter estimation accuracy. Numerical evidences show that our method is superior to the state-of-the-art greedy selection methods in sparse logistic regression and sparse precision matrix estimation tasks.", "creator": "LaTeX with hyperref package"}}}