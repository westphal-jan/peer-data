{"id": "1312.4287", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Dec-2013", "title": "Strategic Argumentation is NP-Complete", "abstract": "in this paper we note the complexity of strategic argumentation for dialogue games. a dialogue game is a 2 - player option where conflict parties play arguments. we show how to model dialogue games in a skeptical, non - objective formalism, and we show that the power of deciding what move ( set of rules ) to play requires each turn is an inquiry - complete problem.", "histories": [["v1", "Mon, 16 Dec 2013 10:09:06 GMT  (40kb)", "http://arxiv.org/abs/1312.4287v1", null]], "reviews": [], "SUBJECTS": "cs.LO cs.AI cs.CC", "authors": ["guido governatori", "francesco olivieri", "simone scannapieco", "antonino rotolo", "matteo cristani"], "accepted": false, "id": "1312.4287"}, "pdf": {"name": "1312.4287.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Guido Governatori", "Francesco Olivieri", "Simone Scannapieco", "Antonino Rotolo", "Matteo Cristani"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n31 2.\n42 87\nv1 [\ncs .L\nO ]\n1 6\nD ec\n2 01"}, {"heading": "1 Introduction and Motivation", "text": "Over the years many dialogue games for argumentation have been proposed to study questions such as which conclusions are justified, or how procedures for debate and conflict resolution should be structured to arrive at a fair and just outcome. We observed that the outcome of a debate does not solely depend on the premises of a case, but also on the strategies that parties in a dispute actually adopt. According to our knowledge, this aspect has not received the proper attention in the literature of the field.\nAlmost all the AI literature on the strategic aspects of argumentation (see Section 3 for a brief overview) assumes to work with argument games with complete information, i.e., dialogues where the structure of the game is common knowledge among the players. Consider, however, the following example due to (Satoh and Takahashi 2011) (which in turn modifies an example taken from (Okuno and Takahashi 2009)):\np0 : \u201cYou killed the victim.\u201d c1 : \u201cI did not commit murder! There is no evidence!\u201d p1 : \u201cThere is evidence. We found your ID card near the scene.\u201d c2 : \u201cIt\u2019s not evidence! I had my ID card stolen!\u201d p2 : \u201cIt is you who killed the victim. Only you were near the scene at the time of the murder.\u201d c3 : \u201cI didn\u2019t go there. I was at facility A at that time.\u201d p3 : \u201cAt facility A? Then, it\u2019s impossible to have had\nyour ID card stolen since facility A does not allow a person to enter without an ID card.\u201d\nThis dialogue exemplifies an argument game occurring in witness examinations in legal courts. The peculiarity of this game is the fact that the exchange of arguments reflects an\nCopyright c\u00a9 2013, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\nasymmetry of information between the players: each player does not know the other player\u2019s knowledge, thus she cannot predict which arguments are attacked and which counterarguments are employed for attacking the arguments. Indeed, (Satoh and Takahashi 2011) points out, for instance, that p3 attacks c2, but only when c3 is given: hence, the attack p3 of the proponent is made possible only when the opponent discloses some private information with the move c3.\nDespite the encouraging results offered by (Satoh and Takahashi 2011), we argue that relaxing the complete-information assumption leads in general to non-tractable frameworks. In this paper, in particular, we explore the computational cost of argument games of incomplete information where the (internal) logical structure of arguments is considered.\nIn this case relaxing complete information, such as when players do not share the same beliefs and set of arguments, simply amounts to the fact they have different logical theories, i.e., different sets of rules from which arguments supporting logical conclusions can be built. Hence, if the proponent, having a theory T , has the objective to prove that some l is true, there is no obvious way for preferring an argument for l obtained from the minimal subset of T (which could at first sight minimise the chances of successful attacks from the opponent) over the maximal set of arguments obtained from the whole T (which could at a first sight maximise the chances to defeat any counterarguments of the opponent).\nThe layout of the paper is as follows. Section 2 offers a gentle introduction and motivation for our research problem. Section 3 reviews relevant related work, thus presenting further motivations behind our contribution. Section 4 presents the logic used for building arguments in dialogues (Argumentation Logic): it is a variant of Defeasible Logic (Antoniou et al. 2001) having linear complexity; another logic (Agent Logic has linear complexity as well) is subsequently recalled from (Governatori and Rotolo 2008). In this second logic, it is possible to formulate the NPcomplete \u201cRestoring Sociality Problem\u201d; the objective is to prove that this problem can be mapped into the problem of interest here, the so-called \u201cStrategic Argumentation Problem\u201d, which rather consists in successfully deciding for each player what move to play at each argument turn (thus showing that the Strategic Argumentation Problem is NPcomplete as well). Section 5 defines dialogue protocols for\ngames of incomplete information based on Argumentation Logic and formulates the Strategic Argumentation Problem. Section 6 shows how to transform a theory in Agent Logic into an equivalent one in Argumentation Logic, and presents the main theorem of computational complexity for argument games."}, {"heading": "2 A Gentle Introduction to the Problem", "text": "In the most typical forms of strategic argumentation, two players exchange arguments in a dialogue game: in the simplest case, a proponent (hereafter Pr) has the objective to prove a conclusion l (a literal of the language) and an opponent (hereafter Op) presents counterarguments to the moves of Pr. If we frame this intuition in proof-theoretic settings, such as in those developed in (Governatori et al. 2004; Prakken 2010; Toni 2013) where arguments are defined as inference trees formed by applying rules, exchanging arguments means exchanging logical theories (consisting of rules) proving conclusions. Assume, for instance, that the argument game is based on a finite set F of indisputable facts and a finite set R of rules: facts initially fire rules and this leads to building proofs for literals.\nIf R and F are common knowledge of Pr and Op, successful strategies in argument games are trivially identified: each player can compute if the entire theory (consisting of F and R) logically entails l. In this situation the game consists of a single move.\nSuppose now that F is known by both players, but R is partitioned into three subsets: a set RCom known by both players and two subsets RPr and ROp corresponding, respectively, to Pr\u2019s and Op\u2019s private knowledge (what Pr and Op privately know to be true). This scenario exemplifies an argument game of incomplete information. In this context, each player can use all rules belonging to her private knowledge (RPr or ROp) as well as all the public rules. These rules are not just the rules in RCom but also rules that, though initially belonging to the private information of other player, have been used in previous turns.\nLet us suppose to work with a skeptical non-monotonic framework, i.e., a logical machinery where, whenever two conflicting conclusions are obtainable from different rules, the system refrains to take a decision. Assuming a game where players has private and public knowledge, the problem of deciding what move (set of rules) to play at each turn amounts to establish whether there is any subset of her rules that can be successful. Is there any safe criterion to select successful strategies?\nConsider the following three examples.\nPr and Op are debating about the truthfulness of a statement, we say l; Pr is arguing that l is the case, whilst Op answers back the truthfulness of the opposite claim (henceforth \u00acl). Each player has her own (private) arguments, not known by the opponent, but they both share the factual knowledge as well as some inference rules. Suppose Pr has the following private arguments:\nP1 : a \u21d2 b \u21d2 c \u21d2 l P2 : \u00acb \u21d2 \u00ace \u21d2 f P3 : \u00acb \u21d2 \u00ace \u21d2 g P4 : d \u21d2 c,\nwhile Op has\nO1 : a \u21d2 e \u21d2 \u00acl O2 : d \u21d2 \u00acb O3 : f \u21d2 \u00acl,\nwhere F = {a,d} and RCom = {g \u21d2\u00acl}. The notation used is to exemplify arguments as chains of rules. For instance, argument P1 implies that RPr contains three rules r1 : a\u21d2 b, r2 : b \u21d2 c, and r3 : c \u21d2 l.\nThe point of the example being that if Pr decides to announce all his private arguments, then she is not able to prove her thesis l. Indeed, she would not have counterarguments defeating O3 and RCom. If instead she argues with P1 and the subpart \u00acb \u21d2 \u00ace of P2, keeping hidden from Op the way to prove the premises d of O2, then she proves l\nConsider now this new setting:\nF = {a,d, f}\nRCom = /0\nRPr = {a \u21d2 b, d \u21d2 c, c \u21d2 b}\nROp = {c \u21d2 e, e, f \u21d2\u00acb}\nIf Pr\u2019s intent is to prove b and she plays {a \u21d2 b}, then Pr wins the game. However, if Pr plays {d \u21d2 c, c \u21d2 b} (or even RPr), this allows Op to succeed. Here, a minimal subset of RPr is successful. However, the situation (for similar reasons) can be reversed for Pr:\nF = {a,d, f}\nRCom = /0\nRPr = {a \u21d2 b, d \u21d2\u00acc}\nROp = {d,c \u21d2\u00acb, f \u21d2 c}\nIn this second case, the move {a \u21d2 b} is not successful for Pr, while playing with the whole RPr ensures victory.\nIn the remainder of this paper, we will study this research question in the context of Defeasible Logic. We will show that the problem of deciding what set of rules to play (Strategic Argumentation Problem) at a given move is NP-complete even when the problem of deciding whether a given theory (defeasibly) entails a literal can be computed in polynomial time. We will map the NP-complete Restoring Sociality Problem proposed in (Governatori and Rotolo 2008) into the Strategic Argumentation Problem. To this end, we first propose a standard Defeasible Logic to formalise the argumentation framework (Subsection 4.1) and then we present the BIO agent defeasible logic (Subsection 4.2). Finally, in Section 6 we show how to transform an agent defeasible logic into an equivalent argumentation one and we present the main theorem of computational complexity."}, {"heading": "3 Related Work", "text": "Despite the game-like character of arguments and debates, game-theoretic investigations of argumentation are still rare in the AI argumentation literature and in the game theory one as well (an exception in this second perspective is (Glazer and Rubinstein 2001)).\nMost existing game-theoretic investigations of argumentation in AI, such as (Procaccia and Rosenschein 2005; Matt and Toni 2008; Riveret et al. 2008; Rahwan and Larson 2009; Grossi and van der Hoek 2013) proceed within Dung\u2019s abstract argumentation paradigm, while (Roth et al. 2007), though working on argumentation semantics related with Dung\u2019s approach, develop a framework where also the logical internal structure of arguments is made explicit.\n(Matt and Toni 2008) presents a notion of argument strength within the class of games of strategy. The measure of the strength of an argument emerges from confronting proponent and opponent via a repeated game of argumentation strategy such that the payoffs reflect the long term interaction between proponent and opponent strategies.\nOther types of game analyses have been used for argumentation. In particular, argumentation games have been reconstructed as two-player extensive-form games of perfect information (Procaccia and Rosenschein 2005; Riveret et al. 2008; Grossi and van der Hoek 2013). (For a discussion on using extensive-form games, see also (Rahwan and Larson 2009).) While (Grossi and van der Hoek 2013) works on zero-sum games, (Riveret et al. 2008) does not adopt this view because preferences over outcomes are specified in terms of expected utility combining the probability of success of arguments (with respect to a third party, an adjudicator such as a judge) with the costs and benefits associated to arguments, thus making possible that argument withdrawn be the most preferred option. Besides this difference, in both approaches uncertainty is introduced due to different probabilities of success depending on a third party, such as external audience or a judge, whose attitude towards the arguments exchanged by proponent and opponent is uncertain.\nAll these works assume that argument games have complete information, which, we noticed, is an oversimplification is many real-life contexts (such as in legal disputes). How to go beyond complete information? In game-theoretic terms, one of the simplest ways of analyzing argument games of incomplete information is to frame them as Bayesian extensive games with observable actions (Osborne and Rubinstein 1999, chap. 12): this is possible because every player observes the argumentative move of the other player and uncertainty only derives from an initial move of chance that distributes (payoff-relevant) private information among the players corresponding to logical theories: hence, chance selects types for the players by assigning to them possibly different theories from the set of all possible theories constructible from a given language. If this hypothesis is correct, notice that (i) Bayesian extensive games with observable actions allow to simply extend the argumentation models proposed, e.g., in (Riveret et al. 2008;\nGrossi and van der Hoek 2013), and (ii) the probability distributions over players\u2019 types can lead to directly measuring the probability of justification for arguments and conclusions, even when arguments are internally analyzed (Riveret, Rotolo, and Sartor 2012). Despite this fact, however, complexity results for Bayesian games are far from encouraging (see (Gottlob, Greco, and Mancini 2007) for games of strategy). If we move to Bayesian extensive games with observable actions things not encouraging, too. Indeed, we guess that considerations similar to those presented by (Chalkiadakis and Boutilier 2007) can be applied to argument games: the calculation of the perfect Bayesian equilibrium solution can be tremendously complex due to both the size of the strategy space (as a function of the size of the game tree, and it can be computationally hard to compute it (Dimopoulos, Nebel, and Toni 2002)), and the dependence between variables representing strategies and players\u2019 beliefs. A study of these game-theoretical issues cannot be developed here and is left to future work: this paper, instead, considers a more basic question: the computational problem of exploring solutions in the logical space of strategies when arguments have an internal structure.\nIn this sense, this contribution does not directly develop any game-theoretic analysis of argumentation games of incomplete information, but it offers results about the computation cost for logically characterizing the problems that any argumentation game with incomplete information potentially rises. Relevant recent papers that studied argumentation of incomplete information without any direct game-theoretic analysis are (Okuno and Takahashi 2009) and (Satoh and Takahashi 2011), which worked within the paradigm of abstract argumentation. The general idea in these works is to devise a system for dynamic argumentation games where agents\u2019 knowledge bases can change and where such changes are precisely caused by exchanging arguments. (Okuno and Takahashi 2009) presents a first version of the framework and an algorithm, for which the authors prove a termination result. (Satoh and Takahashi 2011) generalizes this framework (by relaxing some constraints) and devises a computational method to decide which arguments are accepted by translating argumentation framework into logic programming; this further result, however, is possible only when players are eager to give all the arguments, i.e., when proponent and opponent eventually give all possible arguments in the game."}, {"heading": "4 Logic", "text": "In this section we shall introduce the two logics used in this paper. The first is the logic used in a dialogue game. This is the logic to represent the knowledge of the players, the structure of the arguments, and perform reasoning. We call this logic \u201cArgumentation logic\u201d and we use the Defeasible Logic of (Antoniou et al. 2001). (Governatori et al. 2004) provides the relationships between this logic (and some of its variants) and abstract argumentation, and (Thakur et al. 2007) shows how to use this logic for dialogue games. The second logic, called Agent Logic, is the logic in which the \u201crestoring sociality problem\u201d (a known NP-completed problem)\n(Governatori and Rotolo 2008) was formulated. It is included in this paper to show how to reduce the restoring sociality problem into the strategic argumentation problem, proving thus that the later is also an NP-complete problem. The Agent Logic is an extension of Defeasible Logic with modal operators for Beliefs, Intentions and Obligations (Governatori and Rotolo 2008).\nAdmittedly, this section takes a large part of this paper, but is required to let the reader comprehend the mechanisms behind our demonstration of NP-completeness."}, {"heading": "4.1 Argumentation Logic", "text": "A defeasible argumentation theory is a standard defeasible theory consisting of a set of facts or indisputable statements, a set of rules, and a superiority relation > among rules saying when a single rule may override the conclusion of another rule. We have that \u03c61, . . . ,\u03c6n \u2192 \u03c8 is a strict rule such that whenever the premises \u03c61, . . . ,\u03c6n are indisputable so is the conclusion \u03c8 . A defeasible rule \u03c61, . . . ,\u03c6n \u21d2 \u03c8 is a rule that can be defeated by contrary evidence. Finally, \u03c61, . . . ,\u03c6n \u2740 \u03c8 is a defeater that is used to prevent some conclusion but cannot be used to draw any conclusion.\nDefinition 1 (Language). Let PROP be a set of propositional atoms and Lblarg be a set of labels. Define:\nLiterals Lit = PROP\u222a{\u00acp|p \u2208 PROP}\nIf q is a literal, \u223cq denotes the complementary literal (if q is a positive literal p then \u223cq is \u00acp; and if q is \u00acp, then \u223cq is p);\nRules r : \u03c61, . . . ,\u03c6n \u2192\u0592 \u03c8 ,\nwhere r \u2208 Lblarg is a unique label, A(r) = {\u03c61, . . . ,\u03c6n} \u2286 Litarg is the antecedent of r, C(r) = \u03c8 \u2208 Litarg is the consequent of r, and \u2192\u0592\u2208 {\u2192,\u21d2,\u2740} is the type of r.\nWe use R[q] to indicate all rules with consequent q. We denote the sets of strict, rules, strict and defeasible rules, and defeaters with Rs, Rd, Rsd, and Rdft, respectively.\nDefinition 2 (Defeasible Argumentation Theory). A defeasible argumentation theory is a structure\nDarg = (F,R,>)\nwhere\n\u2022 F \u2286 Lit is a finite set of facts; \u2022 R is the finite set of rules; \u2022 The superiority relation > is acyclic, irreflexive, and\nasymmetric.\nDefinition 3 (Proofs). Given an agent theory D, a proof P of length n in D is a finite sequence P(1), . . . ,P(n) of labelled formulas of the type +\u2206q, \u2212\u2206q, +\u2202q and\u2212\u2202q, where the proof conditions defined in the rest of this section hold. P(1..n) denotes the initial part of the derivation of length n.\nWe start with some terminology.\nDefinition 4. Given # \u2208 {\u2206,\u2202} and a proof P in D, a literal q is #-provable in D if there is a line P(m) of P such that P(m) = +#q. A literal q is #-rejected in D if there is a line P(m) of P such that P(m) =\u2212#q.\nThe definition of \u2206 describes just forward chaining of strict rules:\n+\u2206: If P(n+ 1) = +\u2206q then (1) q \u2208 F or (2) \u2203r \u2208 Rs[q] s.t. \u2200a \u2208 A(r). a is \u2206-provable. \u2212\u2206: If P(n+ 1) =\u2212\u2206q then (1) q /\u2208 F and (2) \u2200r \u2208 Rs[q]. \u2203a \u2208 A(r) s.t. a is \u2206-rejected.\nFor a literal q to be definitely provable either is a fact, or there is a strict rule with head q, whose antecedents have all been definitely proved previously. And to establish that q cannot be definitely proven we must establish that every strict rule with head q has at least one antecedent is definitely rejected.\nThe following definition is needed to introduce the defeasible provability.\nDefinition 5. A rule r \u2208 Rsd is applicable in the proof condition for \u00b1\u2202 iff \u2200a \u2208 A(r), +\u2202a \u2208 P(1..n). A rule r is discarded in the condition for \u00b1\u2202 iff \u2203a \u2208 A(r) such that \u2212\u2202a \u2208 P(1..n). +\u2202 : If P(n+ 1) = +\u2202q then (1)+\u2206q \u2208 P(1..n) or (2) (2.1) \u2212\u2206\u223cq \u2208 P(1..n) and\n(2.2) \u2203r \u2208 Rsd[q] s.t. r is applicable, and (2.3) \u2200s \u2208 R[\u223cq]. either s is discarded, or\n(2.3.1) \u2203t \u2208 R[q] s.t. t is applicable and t > s. \u2212\u2202 : If P(n+ 1) =\u2212\u2202q then\n(1) \u2212\u2206X q \u2208 P(1..n) and either (2.1) +\u2206\u223cq \u2208 P(1..n) or (2.2) \u2200r \u2208 Rsd[q]. either r is discarded, or (2.3) \u2203s \u2208 R[\u223cq] s.t. s is applicable, and\n(2.3.1) \u2200t \u2208 R[q]. either t is discarded, or t 6> s.\nTo show that q is defeasibly provable we have two choices: (1) We show that q is already definitely provable; or (2) we need to argue using the defeasible part of a theory D. For this second case, \u223cq is not definitely provable (2.1), and there exists an applicable strict or defeasible rule for q (2.2). Every attack s is either discarded (2.3), or defeated by a stronger rule t (2.3.1). \u2212\u2202X q is defined in an analogous manner and follows the principle of strong negation which is closely related to the function that simplifies a formula by moving all negations to an inner most position in the resulting formula, and replaces the positive tags with the respective negative tags, and the other way around (Antoniou et al. 2000)."}, {"heading": "4.2 Agent Logic", "text": "A defeasible agent theory is a standard defeasible theory enriched with 1) modes for rules, 2) modalities (belief, intention, obligation) for literals, and 3) relations for conversions and conflict resolution. We report below only the distinctive features. For a detailed exposition see (Governatori and Rotolo 2008).\nDefinition 6 (Language). Let PROP and Lit be a set of propositional atoms and literals as in Definition 1, MOD = {BEL, INT,OBL} be the set of modal operators, and Lblsoc be a set of labels. Define:\nModal literals\nModLit = {Xl|l \u2208 Lit,X \u2208 {OBL, INT}};\nRules r : \u03c61, . . . ,\u03c6n \u2192\u0592X \u03c8 ,\nwhere r \u2208 Lblsoc is a unique label, A(r) = {\u03c61, . . . ,\u03c6n} \u2286 Lit\u222aModLit is the antecedent of r, C(r) = \u03c8 \u2208 Lit is the consequent of r, \u2192\u0592\u2208 {\u2192,\u21d2,\u2740} is the type of r, and X \u2208 MOD is the mode of r.\nRX (RX [q]) denotes all rules of mode X (with consequent q), and R[q] = \u22c3\nX\u2208{BEL,OBL,INT} R X [q].\nObservation 1. Rules for intention and obligation are meant to introduce modalities: for example, if we have the intention rule r : a \u21d2INT b and we derive a, then we obtain INTb. On the contrary, belief rules produce literals and not modal literals.\nRule conversion It is sometimes meaningful to use rules for a modality Y as they were for another modality X , i.e., to convert one mode of conclusions into a different one. Formally, we define the asymmetric binary convert relation Cv \u2286 MOD \u00d7 MOD such that Cv(Y,X) means \u2018a rule of mode Y can be used also to produce conclusions of mode X\u2019. This corresponds to the following rewriting rule:\nXa1, . . . ,Xan A(r) = a1, . . . ,an \u21d2Y b Xb Cv(Y,X)\nwhere A(r) 6= /0 and A(r)\u2286 Lit.\nConflict-detection/resolution We define an asymmetric binary conflict relation Cf \u2286 MOD \u00d7 MOD such that Cf(Y,X) means \u2018modes Y and X are in conflict and mode Y prevails over X\u2019.\nDefinition 7 (Defeasible Agent Theory). A defeasible agent theory is a structure\nDsoc = (Fsoc,R BEL,RINT,ROBL,>soc,V ,F )\nwhere\n\u2022 Fsoc \u2286 Lit\u222aModLit is a finite set of facts; \u2022 RBEL, ROBL, RINT are three finite sets of rules for beliefs,\nobligations, and intentions; \u2022 The superiority (acyclic) relation >soc=>smsoc \u222a> Cf soc such\nthat: i. >smsoc\u2286 R X \u00d7RX such that if r >soc s then r \u2208 RX [p] and s \u2208 RX [\u223cp]; and ii. >Cfsoc is such that \u2200r \u2208 R Y [p],\u2200s \u2208\nRX [\u223cp] if Cf(Y,X) then r >Cfsoc s. \u2022 V = {Cv(BEL,OBL),Cv(BEL, INT)} is a set of convert\nrelations; \u2022 F = {Cf(BEL,OBL),Cf(BEL, INT),Cf(OBL, INT)} is a\nset of conflict relations.\nA proof is now a finite sequence of labelled formulas of the type +\u2206X q, \u2212\u2206X q, +\u2202X q and \u2212\u2202X q.\nThe following definition states the special status of belief rules, and that the introduction of a modal operator corresponds to being able to derive the associated literal using the rules for the modal operator.\nDefinition 8. Given # \u2208 {\u2206,\u2202} and a proof P in D, q is #- provable in D if there is a line P(m) of P such that either\n1. q is a literal and P(m) = +#BELq, or 2. q is a modal literal X p and P(m) = +#X p, or 3. q is a modal literal \u00acX p and P(m) =\u2212#X p. Instead, q is #-rejected in D if\n4. q is a literal and P(m) =\u2212#BELq or 5. q is a modal literal X p and P(m) =\u2212#X p, or 6. q is a modal literal \u00acX p and P(m) = +#X p.\nWe are now ready to report the definition of \u2206X . +\u2206X : If P(n+ 1) = +\u2206X q then\n(1) q \u2208 F if X = BEL or Xq \u2208 F or (2) \u2203r \u2208 RXs [q] s.t. \u2200a \u2208 A(r). a is \u2206-provable or (3) \u2203r \u2208 RYs [q] s.t. Cv(Y,X) \u2208 C and\n\u2200a \u2208 A(r). Xa is \u2206-provable. \u2212\u2206X : If P(n+ 1) =\u2212\u2206X q then\n(1) q /\u2208 F if X = BEL and Xq /\u2208 F and (2) \u2200r \u2208 RXs [q]. \u2203a \u2208 A(r) s.t. a is \u2206-rejected and (3) \u2200r \u2208 RYs [q]. if Cv(Y,X) \u2208 C then\n\u2203a \u2208 A(r) s.t. Xa is \u2206-rejected. The sole difference with respect to +\u2206 is that now we may use rule of a different mode, namely Y , to derive conclusions of mode X through the conversion mechanism. In this framework, only belief rules may convert to other modes. That is the case, every antecedent of the belief rule r \u2208 RY in clause (3) must be (definitely) proven with modality X .\nWe reformulate definition of being applicable/discarded, taking now into account also Cv and Cf relations. Definition 9. Given a proof P and X ,Y,Z \u2208 MOD \u2022 A rule r is applicable in the proof condition for \u00b1\u2202X iff\n1. r \u2208 RX and \u2200a \u2208 A(r), a is \u2202 -provable, or 2. r \u2208RY , Cv(Y,X)\u2208C , and \u2200a\u2208A(r), Xa is \u2202 -provable.\n\u2022 A rule r is discarded in the condition for \u00b1\u2202X iff 3. r \u2208 RX and \u2203a \u2208 A(r) such that a is \u2202 -rejected; or 4. r \u2208 RY and, if Cv(Y,X), then \u2203a \u2208 A(r) such that Xa is\n\u2202 -rejected, or 5. r \u2208 RZ and either \u00acCv(Z,X) or \u00acCf(Z,X).\nWe are now ready to provide proof conditions for \u00b1\u2202X :\n+\u2202X : If P(n+ 1) = +\u2202X q then (1)+\u2206Xq \u2208 P(1..n) or (2) (2.1) \u2212\u2206X\u223cq \u2208 P(1..n) and\n(2.2) \u2203r \u2208 Rsd [q] s.t. r is applicable, and (2.3) \u2200s \u2208 R[\u223cq] either s is discarded, or\n(2.3.1) \u2203t \u2208 R[q] s.t. t is applicable and t > s, and either t,s \u2208 RZ , or Cv(Y,X) and t \u2208 RY\n\u2212\u2202X : If P(n+ 1) =\u2212\u2202X q then (1) \u2212\u2206Xq \u2208 P(1..n) and either\n(2.1) +\u2206X\u223cq \u2208 P(1..n) or (2.2) \u2200r \u2208 Rsd [q], either r is discarded, or (2.3) \u2203s \u2208 R[\u223cq], s.t. s is applicable, and\n(2.3.1) \u2200t \u2208 R[q] either t is discarded, or t 6> s, or t \u2208 RZ,s \u2208 RZ \u2032 , Z 6= Z\u2032 and,\nif t \u2208 RY then \u00acCv(Y,X).\nAgain, the only difference with respect to +\u2202 is that we have rules for different modes, and thus we have to ensure the appropriate relationships among the rules. Hence, clause (2.3.1) prescribes that either attack rule s and counterattack rule t have the same mode (i.e., s, t \u2208 RZ), or that t can be used to produce a conclusion of the mode X (i.e., t \u2208 RY and Cv(Y,X)). Notice that this last case is reported for the sake of completeness but it is useless in our framework since it plays a role only within theories with more than three modes.\nBeing the strong negation of the positive counterpart, \u2212\u2202X q is defined in an analogous manner.\nWe define the extension of a defeasible theory as the set of all positive and negative conclusions. In (Maher 2001; Governatori and Rotolo 2008), authors proved that the extension calculus of a theory in both argumentation and agent logic is linear in the size of the theory.\nLet us introduce some preliminary notions, which are needed for formulating the \u201crestoring sociality problem\u201d (Governatori and Rotolo 2008) (and recalled below).\n\u2022 Given an agent defeasible theory D, a literal l is supported in D iff there exists a rule r \u2208 R[l] such that r is applicable, otherwise l is not supported. For X \u2208 MOD we use +\u03a3X l and \u2212\u03a3X l to indicate that l is supported / not supported by rules for X .\n\u2022 Primitive intentions of an agent are those intentions given as facts in a theory.\n\u2022 Primary intentions and obligations are those derived using only rules for intentions and obligations (without any rule conversion).\n\u2022 A social agent is an agent for which obligation rules are stronger than any conflicting intention rules but weaker than any conflicting belief rules."}, {"heading": "4.3 Restoring Sociality Problem", "text": "INSTANCE: Let I be a finite set of primitive intentions, OBLp a primary obligation, and D a theory such that I \u2286 F , D \u22a2 \u2212\u2202OBLp, D \u22a2 \u2212\u03a3OBL\u223cp, D \u22a2 +\u2202INT\u223cp, D \u22a2 +\u03a3OBLp and D \u22a2 \u2212\u03a3BEL\u223cp. QUESTION: Is there a theory D\u2032 equal to D apart from containing only a proper subset I\u2032 of I instead of I, such that \u2200q if D \u22a2+\u2202OBLq then D\u2032 \u22a2 \u2202OBLq and D\u2032 \u22a2+\u2202OBLp? Let us the consider the theory consisting of\nF = {INTp, INTs}\nR = {r1 : p,s \u21d2BEL q r2 : \u21d2OBL \u223cq r3 : \u21d2BEL s}\n>= {r1 > r2}\nr1 is a belief rule and so the rule is stronger than the obligation rule r2. In addition we have that the belief rule is not applicable (i.e., \u2212\u03a3BELq) since there is no way to prove +\u2202BELp. There are no obligation rules for q, so \u2212\u2202OBLq. However, rule r1 behaves as an intention rule since all its antecedent can be proved as intentions, i.e., +\u2202INTp and +\u2202INTs. Hence, since r1 is stronger than r2, the derivation of +\u2202OBL\u223cq is prevented against the sociality of the agent.\nThe related decision problem is whether it is possible to avoid the \u201cdeviant\u201d behaviour by giving up some primitive intentions, retaining all the (primary) obligations, and maintaining a set of primitive intentions as close as possible to the original set of intentions.\nTheorem 10 ((Governatori and Rotolo 2008)). The Restoring Sociality Problem is NP-complete."}, {"heading": "5 Dialogue Games", "text": "The form of a dialogue game involves a sequence of interactions between two players, the Proponent Pr and the Opponent Op. The content of the dispute being that Pr attempts to assess the validity of a particular thesis (called critical literal within our framework), whereas Op attacks Pr\u2019s claims in order to refute such thesis. We shift such position in our setting by stating that the Opponent has the burden of proof on the opposite thesis, and not just the duty to refute the Proponent\u2019s thesis.\nThe challenge between the parties is formalised by means of argument exchange. In the majority of concrete instances of argumentation frameworks, arguments are defined as chains of reasoning based on facts and rules captured in some formal language (in our case, a defeasible derivation P). Each party adheres to a particular set of game rules as defined below.\nThe players partially shares knowledge of a defeasible theory. Each participant has a private knowledge regarding some rules of the theory. Other rules are known by both parties, but this set may be empty. These rules along with all the facts of the theory and the superiority relation represent the common knowledge of both participants.\nBy putting forward a private argument during a step of the game, the agent increases the common knowledge by the rules used within the argument just played.\nDefine the argument theory to be Darg = (F,R,>) such that i. R = RPr \u222aROp \u222a RCom, ii. RPr (ROp) is the private knowledge of the Proponent (Opponent), and iii. RCom is the (possibly empty) set of rules known by both participants. We use the superscript notation Diarg, R i Pr, R i Op, and R i Com to denote such sets at turn i. We assume that Darg is coherent and consistent, i.e., there is no literal p such that: i. Darg \u22a2 \u00b1\u2202 p, and ii. Darg \u22a2+\u2202 p and Darg \u22a2+\u2202\u223cp.\nWe now formalise the game rules, that is how the common theory Diarg is modified based on the move played at turn i.\nThe parties start the game by choosing the critical literal l to discuss about: the Proponent has the burden to prove +\u2202 l by using the current common knowledge along with a subset of RPr, whereas the Opponent\u2019s final goal is to prove +\u2202\u223cl using ROp instead of RPr.\nThe players may not present arguments in parallel: they take turn in making their move.\nThe repertoire of moves at each turn just includes 1) putting forward an argument, and 2) passing.\nWhen putting forward an argument at turn i, the Proponent (Opponent) may bring a demonstration P whose terminal literal differs from l (\u223cl). When a player passes, she declares her defeat and the game ends. This happens when\nthere is no combination of the remaining private rules which proves her thesis.\nHence, the initial state of the game is T 0arg = (F,R 0 Com,>)\nwith R0Com = RCom, and R 0 Pr = RPr, R 0 Op = ROp.\nIf T 0arg \u22a2 +\u2202 l, the Opponent starts the game. Otherwise, the Proponent does so.\nAt turn i, if Proponent plays Riarg, then\n\u2022 T i\u22121arg \u22a2+\u2202\u223cl (T i\u22121arg \u22a2 \u2212\u2202 l if i = 1);\n\u2022 Riarg \u2286 R i\u22121 Pr ;\n\u2022 T iarg = (F,R i Com,>);\n\u2022 RiPr = R i\u22121 Pr \\R i arg, R i Op = R i\u22121 Op , and R i Com = R i\u22121 Com\u222aR i arg;\n\u2022 T iarg \u22a2+\u2202 l.\nAt turn i, if Opponent plays Riarg, then\n\u2022 T i\u22121arg \u22a2+\u2202 l;\n\u2022 Riarg \u2286 R i\u22121 Op ;\n\u2022 T iarg = (F,R i Com,>);\n\u2022 RiPr = R i\u22121 Pr , R i Op = R i\u22121 Op \\R i arg, and R i Com = R i\u22121 Com\u222aR i arg;\n\u2022 T iarg \u22a2+\u2202\u223cl."}, {"heading": "5.1 Strategic Argumentation Problem", "text": "PROPONENT\u2019S INSTANCE FOR TURN i: Let l be the critical literal, Ri\u22121Pr be the set of the private rules of the Proponent, and T i\u22121arg be such that either T i\u22121 arg \u22a2 \u2212\u2202 l if i = 1, or Di\u22121arg \u22a2 +\u2202\u223cl otherwise. QUESTION: Is there a subset Riarg of R i\u22121 Pr such that D i arg \u22a2 +\u2202 l? OPPONENT\u2019S INSTANCE FOR TURN i: Let l be the critical literal, Ri\u22121Op be the set of the private rules of the Opponent, and Di\u22121arg be such that D i\u22121 arg \u22a2+\u2202 l. QUESTION: Is there a subset Riarg of R i\u22121 Op such that D i arg \u22a2 +\u2202\u223cl?"}, {"heading": "6 Reduction", "text": "We now show how to transform Agent Logic (Section 4.2) into Argumentation Logic (Section 4.1). Basically, we need to act by transforming both literals and rules: whereas the agent theory deals with three different modes of rules and modal literals, the argumentation theory has rules without modes and literals.\nThe two main ideas of transformations proposed in Definitions 11 and 12 are\n\u2022 Flatten all modal literals with respect to internal negations modalities. For instance, \u223cp is flattened into the literal not p, while OBLq is obl q.\n\u2022 Remove modes from rules for BEL, OBL and INT. Thus, a rule with mode X and consequent p is transformed into a standard, non-modal rule with conclusion X p. An exception is when we deal with belief rules, given that they do not produce modal literals. Therefore, rule \u21d2OBL p is translated in \u21d2 obl p, while rule \u21d2BEL q becomes \u21d2 q.\nFunction pflat flattens the propositional part of a literal and syntactically represents negations; function flat flattens modalities.\nDefinition 11. Let Dsoc be a defeasible agent theory. Define two syntactic transformations pflat : Litsoc \u2192 PROParg and flat : ModLitsoc\u222aLitsoc \u2192 Litarg as\npflat(p) =\n{\np \u2208 PROParg if p \u2208 PROPsoc not q \u2208 PROParg if p = \u00acq, q \u2208 PROPsoc\nflat(p) =\n\n     \n      pflat(q) if p = q, obl pflat(q) if p = OBLq \u00acobl pflat(q) if p = \u00acOBLq int pflat(q) if p = INTq \u00acint pflat(q) if p = \u00acINTq.\nGiven that in BIO a belief modal literal is not BELp but simply p, we have that flat(p) = pflat(p) whenever the considered mode is BEL, while flat(X p) = x pflat(p) if X = {OBL, INT}.\nWe need to redefine the concept of complement to map BIO modal literals into an argumentation logic with literals obtained through flat. Thus, if q \u2208 PROParg is a literal p then \u223cq is not p; and if q is not p, then \u223cq is p. Moreover, if q \u2208 Litarg is x pflat(p) then \u223cq = x pflat(\u223cp); and q is \u00acx pflat(p) then \u223cq = x pflat(p).\nWe now propose a detailed description of facts and rules introduced by Definition 12.\nIn the \u201crestoring sociality problem\u201d we have to select a subset of factual intentions, while in the \u201cstrategic argumentation problem\u201d we choose a subset of rules to play to defeat the opponent\u2019s argument. Therefore, factual intentions are modelled as strict rules with empty antecedent (rp), while factual beliefs and obligations are facts of Darg.\nWe recall that, while proving\u00b1#X q, a rule in BIO may fire if either is of mode X , through Cv, or through Cf. Hence, a rule r in Dsoc has many counterparts in Darg.\nSpecifically, r f l is built from r by: removing the mode, and flattening each antecedent of r as well as the consequent p which in turn embeds the mode introduced by r.\nMoreover, if r \u2208 RBEL[p] then it may be used through conversion to derive X p. To capture this feature we introduce a rule rCvx with conclusion x pflat(p) and where for each antecedent a \u2208 A(r) the corresponding in A(rCvx) is x pflat(a) according either to clause (3) of +\u2206X or to condition 2. of Definition 9.\nIn Dsoc, it is easy to determine which rule may fire against one another, being that consequents of rules are non-modal literals. Even when the rules have different modes and the conflict mechanism is used, their conclusions are two complementary literals. Given the definition of complementary literals obtained through flat we have introduced after Definition 11, this is not the case for the literals in Darg. The situation is depicted in the following theory.\nr : a \u21d2OBL p r f l : a \u21d2 obl p s : b \u21d2INT \u00acp s f l : b \u21d2 int not p t : c \u21d2BEL p t f l : c \u21d2 p.\nHere, r may fire against s through Cf(OBL, INT) while r f l cannot, given that obl p is not the complement of int not p. In the same fashion, if we derive +\u2202BELc then t may fire against s because of Cf(BEL, INT), while if we have either +\u2202OBLc or +\u2202INTc then the conflict between beliefs and intentions is activated by the use of r through either Cv(BEL,OBL) or Cv(BEL, INT), respectively. Nonetheless, in both cases there is no counterpart of t in Darg able to fire against int not p.\nTo obviate this issue, we introduce a defeater rC f OI where we flatten the antecedents of r and the conclusion is the intention of the conclusion of r, namely int pflat(C(r)). This means that when r fires, so does rC f OI attacking s f l . Notice that being rC f OI a defeater, such a rule cannot derive directly +\u2202 int pflat(p) but just prevents the opposite conclusion. The same idea is adopted for rules rC f belx and rCvyC f x: defeaters rC f belx are needed to model conflict between beliefs and intentions (as rule t in the previous example), whereas defeaters rCvyC f x take care of situations where r \u2208 RZ may be used to convert Z into Y and Z prevails over X by Cf.\nThus in the previous example, we would have: rC f OI : a \u2740 int p, tC f belint : c \u2740 int p, tC f belint : c \u2740 int p, tCvxC f int : x c \u2740 int p, with x \u2208 {obl, int}.\nAntecedents in BIO may be negation of modal literals; in that framework, a theory proves \u00acX p if such theory rejects X p (as stated by condition 3. of Definition 8). In Darg we have to prove \u00acx pflat(p) This is mapped in Darg through conditions 8\u201310 of Definition 12 and the last condition of >.\nDefinition 12. Let Dsoc = (Fsoc,RBEL,ROBL,RINT,>soc,V ,F ) be a defeasible agent theory. Define Darg = (F,R,>) an argumentation defeasible theory such that\nF = {flat(p)|p \u2208 Fsoc, p \u2208 Lit or p = OBLq} (1)\nR = {rp : \u2192 int pflat(p)|INTp \u2208 Fsoc} (2)\n\u222a{r f l : \u22c3\na\u2208A(r)\nflat(a) \u2192\u0592 flat(p)|r \u2208 RX [q],\nX = BEL and p = q, or p = Xq \u2208 ModLit} (3)\n\u222a{rCvx : \u22c3\na\u2208A(r)\nx pflat(a) \u2192\u0592 x pflat(p)|r \u2208 RBELsd [p],\nA(r) 6= /0,A(r)\u2286 Lit,x \u2208 {obl, int}} (4)\n\u222a{rCvyC f x : \u22c3\ny pflat(a)\u2208A(rCvy)\ny pflat(a)\u2740 x pflat(p)|\nrCvy \u2208 R[y pflat(p)],x,y \u2208 {obl, int},x 6= y} (5)\n\u222a{rC f belx : \u22c3\na\u2208A(r)\nflat(a)\u2740 x pflat(p)|r \u2208 RBEL[p],\nx \u2208 {obl, int}} (6)\n\u222a{rC f OI : \u22c3\na\u2208A(r)\nflat(a)\u2740 int pflat(p)|r \u2208 ROBL[p]} (7)\n\u222a{rdum\u2212xp : x pflat(p)\u21d2 xp|r \u2208 R Y .\u00acX p \u2208 A(r)} (8)\n\u222a{rdum\u2212negxp : \u21d2\u223cxp|rdum\u2212xp \u2208 R} (9)\n\u222a{rneg\u2212xp : \u223cxp \u21d2\u00acx pflat(p)|rdum\u2212negxp \u2208 R} (10)\n>= {(r\u03b1 ,s\u03b2 )|(r,s) \u2208>soc,\u03b1,\u03b2 \u2208 { f l,Cvx,CvxC f y, C f belx,C f OI}}\n\u222a{(r f l ,sneg\u2212xp)|r f l \u2208 R[x pflat(p)]}\n\u222a{(rdum\u2212xp,sdum\u2212negxp)|rdum\u2212xp,sdum\u2212negxp \u2208 R}. (11)\nWe name Darg the argumentation counterpart of Dsoc.\nThe following result is meant to prove the correctness of the transformation given in Definition 12. This is the case when the transformation preserves the positive and negative provability for any given literal.\nTheorem 13. Let Dsoc = (Fsoc,RBEL,ROBL,RINT,>soc ,V ,F ) be a defeasible agent theory and Darg = (F,R,>) the argumentation counterpart of Dsoc. Given p \u2208 Lit \u222a ModLit and # = {\u2206,\u2202}:\n1. Dsoc \u22a2 \u00b1#BELp iff Darg \u22a2 \u00b1#flat(p); 2. Dsoc \u22a2 \u00b1#X p iff Darg \u22a2 \u00b1#flat(X p), X \u2208 {OBL, INT}.\nProof. The proof is by induction on the length of a derivation P. For the inductive base, we consider all possible derivations of length 1 for a given literal q. Given the proof tags\u2019 specifications as in Definitions 11 and 12, the inductive base only takes into consideration derivations for \u00b1\u2206, since to prove \u00b1\u2202q requires at least 2 steps.\nP(1) = +\u2206Xq. This is possible either when clause (1), or (2) of +\u2206X in Dsoc holds.\nFor (1), we have either i. q \u2208 Fsoc and X = BEL or OBLq \u2208 Fsoc then flat(q) \u2208 F or flat(OBLq) \u2208 F by condition (1) of Definition 12; or ii. INTq \u2208 Fsoc then there exists rq \u2208 Rs[int pflat(q)], A(rq) = /0, by condition (2) of Definition 12. Cases i. and ii. as seen together state that either if\nX = BEL then Darg \u22a2+\u2206flat(q), or Darg \u22a2 +\u2206flat(Xq) otherwise, by clause (1), or (2) of +\u2206 in Darg.\nConcerning (2) of +\u2206X , there exists r \u2208 RXs [q] such that A(r) = /0. Hence, if X = BEL then we have r f l \u2208 Rs[flat(q)], otherwise we have r f l \u2208 Rs[x pflat(q)] with x = {obl, int}, where both situations follow by condition (3) of Definition 12 and A(r f l) = /0. Thus, Darg \u22a2 +\u2206flat(q) or Darg \u22a2 +\u2206flat(Xq), respectively, by clause (2) of +\u2206 in Darg.\nP(1) = +\u2206flat(q). This is possible either when clause (1), or (2) of +\u2206 in Darg holds.\nFor (1), we have either pflat(q)\u2208F with q= p and p\u2208Lit, or obl pflat(p) \u2208 F with q = OBLp; hence, by Definition 11 and condition (1) of Definition 12, we conclude that p\u2208 Fsoc or OBLp \u2208 Fsoc, respectively. Thus, either Dsoc \u22a2 +\u2206BELp or Dsoc \u22a2+\u2206OBLp by clause (1) of +\u2206X in Dsoc.\nConcerning (2) of +\u2206X , we consider if either i. q = p and p \u2208 Lit or q = OBLp, or ii. q = INTp.\nCase i., there exists r f l \u2208 Rs[flat(p)], A(r f l) = /0. Therefore, there exists r \u2208 RXs [p], with A(r) = /0 and X = {BEL,OBL}, by condition (3) of Definition 12. Thus, Dsoc \u22a2 +\u2206X p by clause (2) of +\u2206X in Dsoc.\nCase ii., two possible situations arise: a) There exists r f l \u2208 Rs[int pflat(p)], A(r f l) = /0, then there exists r \u2208 RINTs [p], A(r) = /0, by condition (3) of Definition 12; or b) there exists rp \u2208 Rs[int pflat(p)], then INTp \u2208 Fsoc by condition (2) of Definition 12. For a) as well as for b), Dsoc \u22a2 +\u2206INTp by clause (2) or (1), respectively, of +\u2206X in Dsoc.\nP(1) =\u2212\u2206X q, P(1) =\u2212\u2206flat(q). Both demonstrations are the same as and use the same ideas of cases P(1) = +\u2206X q or P(1) = +\u2206flat(q), respectively.\n(P(1) = \u2212\u2206X q) Clause (1) and (2) of \u2212\u2206X in Dsoc are satisfied. Thus, q 6\u2208 Fsoc (q \u2208 Lit) or Xq 6\u2208 Fsoc and, consequently, neither flat(q) \u2208 F nor obl pflat(q) \u2208 F, and there is no rule rq that proves INTq. Moreover, for all r \u2208 RXs [q] then A(r) 6= /0 and, accordingly, the same situation holds for all the corresponding rules of type r f l in Darg.\nThe same reasoning applies for the other direction.\nP(n+ 1) = +\u2206Xq. If q \u2208 Fsoc and X = BEL, or Xq \u2208 Fsoc and X = {OBL, INT}, then the case is the same as the corresponding inductive base.\nIf there exists r \u2208 RXs [q] such that a is \u2206-provable at P(n), for all a \u2208 A(r), meaning that: a) There exists r f l : \u22c3\na\u2208A(r) flat(a)\u2192 flat(q) with X = BEL, or there exists r f l : \u22c3\na\u2208A(r) flat(a) \u2192 x pflat(q) with x \u2208 {obl, int} by condition (3) of Definition 12; and b) flat(a) is \u2206-provable for all flat(a) \u2208 A(r f l), by inductive hypothesis. Hence, Darg \u22a2 +\u2206flat(q) or Darg \u22a2 +\u2206flat(Xq), respectively, by clause (2) of +\u2206 in Darg.\nFinally, if clause (3) of +\u2206X in Dsoc is the case, then there exists r \u2208 RYs [q] such that Cv(Y,X) \u2208 V and Xa is \u2206-provable at P(n), for all a \u2208 A(r). Thus, there exists rCvx \u2208 Rs[x pflat(q)] by condition (4) of Definition 12, and\nx pflat(a) is \u2206-provable for all x pflat(a) \u2208 A(rCvx), by inductive hypothesis. Again, Darg \u22a2+\u2206flat(Xq) by clause (2) of +\u2206 in Darg.\nP(n+ 1) = +\u2206flat(q). This is possible either when clause (1), or (2) of +\u2206 in Darg holds.\nIf flat(q)\u2208 F, then the proof is the same as the corresponding inductive base.\nOtherwise, we consider if either i. q = p and p \u2208 Lit, or ii. q = X p with X = {OBL, INT}.\nCase i., there exists r f l \u2208 Rs[flat(p)], such that flat(a) is \u2206- provable at P(n), for all flat(a)\u2208A(r f l). Therefore: a) There exists r \u2208 RBELs [p] by condition (3) of Definition 12; and b) a is \u2206-provable for all a \u2208 A(r) by inductive hypothesis. Thus, Dsoc \u22a2+\u2206BELp by clause (2) of +\u2206X in Dsoc.\nCase ii. is divided in two sub-cases. First sub-case, there exists r f l \u2208 Rs[x pflat(p)] such that flat(a) is \u2206-provable at P(n), for all flat(a) \u2208 A(r f l). This case is analogous to the previous case. Second sub-case, there exists rCvx \u2208 Rs[x pflat(p)], with x = {obl, int}, such that x pflat(a) is \u2206- provable for all x pflat(a) \u2208 A(rCvx). Therefore, the following two conditions are satisfied: a) There exists r \u2208 RBELs [p] by condition (4) of Definition 12, and b) Xa is \u2206-provable for all a \u2208 A(r) by inductive hypothesis. Thus, Dsoc \u22a2+\u2206X p by clause (3) of +\u2206X in Dsoc.\nP(n+ 1) =\u2212\u2206Xq. Clauses (1)\u2013(3) of \u2212\u2206X in Dsoc hold. For (1), q 6\u2208 Fsoc (q \u2208 Lit) or Xq 6\u2208 Fsoc. Consequently, neither flat(q) \u2208 F nor obl pflat(q) \u2208 F, and there is no rule rq to support int pflat(q).\nFor (2), for all r \u2208 RXs [q] there exists a \u2208 A(r) such that a is \u2206-rejected at P(n). Accordingly, for all the corresponding rules of type r f l in Darg, there exists flat(a) \u2208 A(r f l) which is \u2206-rejected by inductive hypothesis. Hence, we conclude that Darg \u22a2 \u2212\u2206flat(q) if X = BEL.\nFinally, the same reasoning applies for all rules r \u2208 RYs [q], with Cv(Y,X) \u2208 V , where there exists a \u2208 A(r) such that Xa is \u2206-rejected at P(n). Thus, we conclude that Darg \u22a2 \u2212\u2206flat(Xq), with X = {OBL, INT}.\nP(n+1)=\u2212\u2206flat(q). The proof follows the inductive base and the case P(n) =\u2212\u2206X q.\nP(n+ 1) = +\u2202X q. Clauses (1) and (2.1) of +\u2202X have already been proved for the inductive step of \u00b1\u2206X .\nIf clause (2.2) of +\u2202X is the case, then there exists r \u2208 Rsd[q] such that r is applicable at P(n + 1) (i.e., a is \u2202 - provable at P(n) in Dsoc, for all a \u2208 A(r)) and either clause (2.3) or (2.3.1) is satisfied.\nWe have two cases. If r \u2208 RX then there exists either r f l \u2208Rsd[flat(q)] when X =BEL, or r f l \u2208Rsd[x pflat(q)] otherwise by condition (3) of Definition 12. Thus, flat(a) is \u2202 -provable at P(n) in Darg, for all flat(a) \u2208 A(r f l) by inductive hypothesis. If r \u2208 RY and X = {OBL, INT}, then there exists either rCvx \u2208 Rsd[x flat(q)] by condition (4) of Definition 12. Hence, x pflat(a) is \u2202 -provable at P(n) in Darg, for all flat(a) \u2208 A(rCvx) by inductive hypothesis. We conclude\nthat clause (2.2) of +\u2202 holds in Darg by inductive hypothesis.\nFor, clause (2.3) if s \u2208 R[\u223cq] is discarded, then we have the following cases.\na. s \u2208 RX , then there exists a \u2208 A(s) which is \u2202 -rejected at P(n). Thus, flat(a) is \u2202 -rejected at P(n) in Darg by inductive hypothesis, and therefore s f l is discarded in Darg.\nb. s \u2208 RBEL and X \u2208 {OBL, INT}, then there exists a \u2208 A(s) such that Xa is \u2202 -rejected at P(n). Hence, x pflat(a) is \u2202 - rejected at P(n) in Darg by inductive hypothesis and we conclude that sCvx is discarded in Darg. c. X = BEL and s \u2208 RZ with Z \u2208 {OBL, INT}, or X = OBL and s \u2208 RINT. We conclude that s f l is discarded because either X = BEL and s f l 6\u2208 R[\u223cflat(q)], or s f l 6\u2208 R[\u223cx pflat(q)] otherwise.\nFinally, we consider clause (2.3.1) of +\u2202X . Following the above reasoning, if t is applicable in Dsoc, then t f l or tCvx is applicable in Darg as well.\nIf t,s \u2208 RZ and t >smsoc s, then t\u03b1 > s\u03b1 with \u03b1 \u2208 { f l,Cvz} by condition (11) of Definition 12. If X = BEL, there is no need for further analysis given that the transformation does not produce additional rules for pflat(q), for any literal q.\nOtherwise, we have either\ni. t \u2208 RBEL[q] and s \u2208 RX [\u223cq]: thus tCvx > s f l;\nii. t \u2208 RBEL[q] and s \u2208 RX [\u223cq]: thus tC f belx > s f l , with tC f belx : \u22c3 flat(a)\u2740 x pflat(q);\niii. s, t \u2208 RBEL: thus either a) tC f belx > sCvx, or b) tCvyC f x > sCvx, with tCvyC f x : \u22c3 y pflat(a)\u2740 x pflat(q);\nby condition (11) and Cf(BEL,X) for i. and ii., t >smsoc s for the last case. It only remains to prove that tC f belx and tCvyC f x are applicable in Darg. If t is applicable in Dsoc at P(n+ 1), then any a \u2208 A(t) is \u2202 -provable in Dsoc at P(n) and so is flat(a) in Darg by inductive hypothesis. We conclude that tC f belx is applicable in Darg at P(n+ 1). Instead, if t is applicable in Dsoc at P(n+ 1) through Cv(BEL,Y ), then Ya is \u2202 -provable in Dsoc at P(n) for every a \u2208 A(t). By inductive hypothesis, any y pflat(a) \u2208 A(tCvyC f x) is \u2202 -provable as well. Hence, tCvyC f x is applicable in Darg as well.\nThis completes the analysis when s\u03b1 with \u03b1 \u2208 { f l,Cvx}; we now analyse other possible attacks in Darg and first proceed for X = OBL, then for X = INT.\nSuppose there is a rule w \u2208 RBEL[\u223cq]; w produces rules wC f belx and wCvyC f x. In the first case w would fire against Xq due to Cf(BEL,X). If w is discarded in Dsoc at P(n+1), then there exists a \u2208 A(w) such that a is \u2202 -rejected in Dsoc at P(n). By inductive hypothesis, we conclude that flat(a) \u2208 A(wC f belx) is \u2202 -rejected in Darg at P(n). Otherwise, w is defeated by an applicable t in Dsoc. Assume there is no t \u2208 RBEL[q] stronger than w. Thus, Dsoc \u22a2 \u2212\u2202X q, against the hypothesis. Therefore, t >soc w and the corresponding of t in D is stronger than wC f belx by construction of > in Definition 12.\nAn analogous reasoning applies for wCvyC f x. Here, w would be applicable through Cv(BEL,Y ) and then fire against Xq by Cf(BEL,X). If w is discarded, then there\nexists a \u2208 A(w) such that Ya is \u2202 -rejected in Dsoc at P(n). By inductive hypothesis, y pflat(a) is \u2202 -rejected in Darg and wCvyC f x is discarded at P(n+1). Otherwise, w is defeated in Dsoc by an applicable t \u2208 RBEL[q] either directly, or through conversion. In both cases, the corresponding rule of t in Darg is stronger than wCvyC f x by construction of > in Definition 12. Notice that if w is applicable in Dsoc at P(n+ 1) then Ya is \u2202 -provable at P(n) for any a \u2208 A(w) and, consequently, so is y pflat(a) by inductive hypothesis, making wCvyC f x applicable in Darg.\nA final analysis is in order when X = INT and we consider wC f OI : \u22c3\nflat(a) \u2740 int pflat(\u223cq). The counterpart in Dsoc is w \u2208 ROBL[\u223cq], which is either discarded, or defeated by a stronger rule t. Again, if w is discarded in Dsoc, then there exists a \u2208 A(w) such that a is \u2202 -rejected in Dsoc at P(n). By inductive hypothesis, flat(a) is \u2202 -rejected in Darg and wC f OI is discarded at P(n+ 1). Otherwise w is defeated either by an applicable t \u2208 ROBL[q], or t \u2208 RBEL[q] (in this last case directly, or through Cf(BEL,OBL), or through Cf(BEL, INT)). This relation is preserved in > between wC f OI and the corresponding rule of t in Darg by condition (11) of Definition 12. If the t is in ROBL, then tC f OI \u2208 R[int pflat(q)]. Stating that t is applicable in Dsoc at P(n+ 1) means that every antecedent a is \u2202 -provable. By inductive hypothesis, so is the corresponding flat(a) in Darg, making tC f OI applicable at P(n+ 1).\nP(n+ 1) = +\u2202flat(q). Clauses (1) and (2.1) of +\u2202 have already been proved for the inductive base of \u00b1\u2206.\nIf q = p and p \u2208 Lit, then the only rules to consider as support/attack flat(p) are obtained through condition (3) of Definition 12. Therefore, by inductive hypothesis, for any applicable rule r f l the corresponding rule r in Dsoc is applicable as well, and the same reasoning holds for discarded rules. Moreover, the superiority relation is isomorphic for such rules. Hence, Dsoc \u22a2+\u2202BELp.\nProofs that if a rule is applicable/discarded in Darg at P(n+1) then so is the corresponding rule in Dsoc at P(n+1), are analogous to the various cases studied for the inductive step of +\u2202X . Specifically, we use s\u03b1 for rules captured by the quantifier in clause (2.3) of +\u2202 and t\u03b2 for those in the scope of the quantifier of clause (2.3.1).\nIt remains to argue that every applicable attack rule is defeated. By the construction of the superiority relation, this statement is straightforward for the rules which have a natural counterpart in Darg, i.e., t f l > s f l , tCvx > sCvx, tCvy > sCvx when Cf(Y,X) \u2208 F , tCvy > sCvx.\nSuppose s\u03b1 \u2208 R[x pflat(\u223cp)], with \u03b1 \u2208 {CvyC f x,C f belx}. Such a rule is defeated by tCvx \u2208 R[x pflat(p)], tCvyC f x \u2208 R[x pflat(p)], or tC f belx \u2208 R[x pflat(p)]. All these rule have the same counterpart rule, namely t \u2208 RBEL[p], what changes is how t is made applicable to challenge s \u2208 RBEL[\u223cp]. Again, due to construction of > in Definition 12 t\u03b2 > s\u03b1 , \u03b2 \u2208 {Cvx,CvyC f x,C f belx}, are so because t >soc s.\nThe case when sC f OI \u2208 R[x pflat(\u223cp)] differs from the previous one in that it can be defeated also by tC f OI . Once more we have that t >smsoc s by construction of >.\nAt last, we analyse the case when Darg \u22a2+\u2202\u00acx pflat(p). The only rule that may fire to prove \u00acx pflat(p) is rneg\u2212xp, which is applicable whenever any rule rdum\u2212xp is discarded at in Darg at P(n+ 1), due to conditions 8\u201310 and construction of > in Definition 12. That is the case if x pflat(p) is \u2202 -rejected in Darg at P(n). By inductive hypothesis, Dsoc \u22a2 \u2212\u2202X p at P(n), thus, by Definition 8 clause 3, \u00acX p is \u2202 -provable in Dsoc at P(n+ 1).\nP(n+ 1) = \u2212\u2202X q, \u2212\u2202flat(q). The main reasoning follows straightforwardly from the case given that the proof conditions for \u2212\u2202X and \u2212\u2202 are the strong negation of +\u2202X and +\u2202 , respectively. Clauses (1) and (2.1) of \u2212\u2202X (\u2212\u2202 ) have already been proved in the inductive step of \u00b1\u2206X (\u00b1\u2206), as well as clauses (2.2)-(2.3) in the inductive step of +\u2202X (+\u2202 ).\nBy construction of the superiority relation given in Definition 12, if t 6>soc s, then no superiority relation may exist between any transformations of t and s in Darg.\nFinally, concerning P(n+ 1) = \u2212\u2202X , we must consider the case when \u00acXq is \u2202 -provable in Dsoc at P(n+ 1). This is the case when clause 3. of Definition 8 is satisfied, i.e., when Dsoc \u22a2 \u2212\u2202X q at P(n). By inductive hypothesis, Darg \u22a2\u2212\u2202x pflat(q) at P(n), making rules rdum\u2212xp discarded in Darg at P(n+1). Accordingly, Darg \u22a2+\u2202\u223cxp at P(n+2) and we conclude that rules rneg\u2212xp prove \u00acx pflat(q) at P(n+ 3).\nIn order to show the final result that the Strategic Argumentation Problem is NP-Complete, we first prove that the proposed transformation is polynomial.\nTheorem 14. There is a linear transformation from any defeasible agent theory Tsoc to its argumentation counterpart Targ.\nProof. The transformation rules of Definition 12 are applied once to each rule and each tuple of the superiority relation. Transformation rule (1) maps one fact in Tsoc into one fact in Targ. Transformation rule (2) maps one primitive intention Tsoc into one strict rule in Targ. Rule (3) and (7) again copy one rule into one rule. Rules (4)\u2013(6) generate two rules in Targ for every belief rule in Tsoc. Rules (8)\u2013(10) generate a total of three rules in Targ for each negative modal literal in Tsoc. Rule (11) generates thirty-two tuples in Targ for each tuple in >soc and two tuples for each negative modal literal in in Tsoc.\nThe above reasoning shows that the transformation performs a number of steps that is, in the worst case, smaller than thirty-two times the size of the defeasible agent theory, and this proves the claim.\nTheorem 15. The Strategic Argumentation Problem is NPComplete.\nProof. First, the Strategic Argumentation Problem is polynomially solvable on non-deterministic machines since, given a defeasible argumentation theory Darg, we guess a set of rules Riarg and we can check the extension in polynomial time (Maher 2001).\nSecond, the Strategic Argumentation Problem is NPhard. In fact, we map the Restoring Sociality Problem\n(Governatori and Rotolo 2008) into the Strategic Argumentation Problem. Given a (deviant) defeasible agent theory Dsoc, Dsoc is mapped into its argumentation counterpart Darg (Definition 12). The transformation is polynomial (Theorem 14) and correct (Theorem 13)."}, {"heading": "6.1 Discussion", "text": "In this paper we concentrated in a game with a symmetry on what the two parties have to prove: Pr has to prove l (i.e., +\u2202 l) while Op has to prove \u223cl (i.e., +\u2202\u223cl); however, it is possible to have games where the two parties have different burden on proof, namely, the proponent Pr has to prove l and the opponent Op has to disprove it. In Defeasible Logic this can be achieve either by proving that the opposite holds, namely +\u2202\u223cl or simply by showing that l is not provable, i.e., \u2212\u2202 l. In this case we have two different types of strategic argumentation problems: one for the proponent (which is the same as the current one), and one for the opponent. For the opponent, the related decision problem is if there exists a subset of her private rules such that adding it to current public rule make that the resulting theory proves \u2212\u2202 l. The proof conditions for +\u2202 and \u2212\u2202 are the strong negation of each other (Antoniou et al. 2000); hence this version of the strategic argumentation problem is coNP-complete.\nThe NP-completeness result of the paper is proved for the ambiguity blocking, team defeat variant of Defeasible Logic. However, the proof of the result does not depend on the specific features of this particular variant of the logic, and the result extends to the other variants of the logic (see (Billington et al. 2010) for the definition of the various variants). The version of the argumentation logic presented in this paper does not correspond to the grounded semantics for Dung\u2019s style abstract argumentation framework (though it is possible to give such a semantics for it, see (Governatori et al. 2004)). However, the ambiguity blocking variant corresponds to Dung\u2019s grounded semantics (Governatori et al. 2004). Accordingly, strategic argumentation seems to be a computationally infeasible problem in general.\nFinally, in our game we chose that the superiority relation is known a priori by both players. If not so, the problem reduces to revising the corresponding Agent Logic by changing a combination of rules and superiority relation. The problem of revising a defeasible theory by only modifying the superiority relation has proven to be NP-complete in (Governatori et al. 2012)."}, {"heading": "7 Summary", "text": "Almost all research in AI on argumentation assumes that strategic dialogues are games of complete information, i.e., dialogues where the structure of the game is common knowledge among the players. Following (Okuno and Takahashi 2009; Satoh and Takahashi 2011) we argue that argument games work under incomplete information: each player does not know the other player\u2019s knowledge, thus she cannot predict which arguments are attacked and which counterarguments are employed for attacking the arguments; hence, argument moves can disclose such private information, thus allowing the other player to attack.\nWhile it is outside the scope of this paper how to analyse strategic dialogues in game-theoretic terms, our research effort is preliminary to this analysis, since it studies the computation cost for logically characterising the problem that any argumentation game with incomplete information potentially rises. We have shown that the problem of deciding what set of rules to play (\u201cStrategic Argumentation Problem\u201d) at a given move is NP-complete even when the problem of deciding whether a given theory (defeasibly) entails a literal can be computed in polynomial time. To this end, we mapped the NP-complete \u201cRestoring Sociality Problem\u201d proposed in (Governatori and Rotolo 2008) into the strategic argumentation problem."}], "references": [{"title": "A family of defeasible reasoning logics and its implementation", "author": ["Antoniou"], "venue": "ECAI", "citeRegEx": "Antoniou,? \\Q2000\\E", "shortCiteRegEx": "Antoniou", "year": 2000}, {"title": "Representation results for defeasible logic", "author": ["Antoniou"], "venue": "ACM Transactions on Computational Logic 2(2):255\u2013287", "citeRegEx": "Antoniou,? \\Q2001\\E", "shortCiteRegEx": "Antoniou", "year": 2001}, {"title": "An inclusion theorem for defeasible logics", "author": ["Billington"], "venue": "ACM Trans. Comput", "citeRegEx": "Billington,? \\Q2010\\E", "shortCiteRegEx": "Billington", "year": 2010}, {"title": "Coalitional bargaining with agent type uncertainty", "author": ["Chalkiadakis", "G. Boutilier 2007] Chalkiadakis", "C. Boutilier"], "venue": null, "citeRegEx": "Chalkiadakis et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Chalkiadakis et al\\.", "year": 2007}, {"title": "On the computational complexity of assumption-based argumentation for default reasoning", "author": ["Nebel Dimopoulos", "Y. Toni 2002] Dimopoulos", "B. Nebel", "F. Toni"], "venue": null, "citeRegEx": "Dimopoulos et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Dimopoulos et al\\.", "year": 2002}, {"title": "Debates and decisions: On a rationale of argumentation rules. Games and Economic Behavior 36(2):158\u2013173", "author": ["Glazer", "J. Rubinstein 2001] Glazer", "A. Rubinstein"], "venue": null, "citeRegEx": "Glazer et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Glazer et al\\.", "year": 2001}, {"title": "Complexity of pure equilibria in bayesian games", "author": ["Greco Gottlob", "G. Mancini 2007] Gottlob", "G. Greco", "T. Mancini"], "venue": null, "citeRegEx": "Gottlob et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Gottlob et al\\.", "year": 2007}, {"title": "BIO logical agents: Norms, beliefs, intentions in defeasible logic", "author": ["Governatori", "G. Rotolo 2008] Governatori", "A. Rotolo"], "venue": "Journal of Autonomous Agents and Multi Agent Systems", "citeRegEx": "Governatori et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Governatori et al\\.", "year": 2008}, {"title": "Argumentation semantics for defeasible logic", "author": ["Governatori"], "venue": "J. Log", "citeRegEx": "Governatori,? \\Q2004\\E", "shortCiteRegEx": "Governatori", "year": 2004}, {"title": "Revision of defeasible logic preferences", "author": ["Governatori"], "venue": "CoRR abs/1206.5833", "citeRegEx": "Governatori,? \\Q2012\\E", "shortCiteRegEx": "Governatori", "year": 2012}, {"title": "Audience-based uncertainty in abstract argument games", "author": ["Grossi", "D. van der Hoek 2013] Grossi", "W. van der Hoek"], "venue": "In Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence,", "citeRegEx": "Grossi et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Grossi et al\\.", "year": 2013}, {"title": "A gametheoretic measure of argument strength for abstract argumentation", "author": ["Matt", "P. Toni 2008] Matt", "F. Toni"], "venue": null, "citeRegEx": "Matt et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Matt et al\\.", "year": 2008}, {"title": "Argumentation system with changes of an agent\u2019s knowledge base", "author": ["Okuno", "K. Takahashi 2009] Okuno", "K. Takahashi"], "venue": null, "citeRegEx": "Okuno et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Okuno et al\\.", "year": 2009}, {"title": "A Course in Game Theory", "author": ["Osborne", "M.J. Rubinstein 1999] Osborne", "A. Rubinstein"], "venue": null, "citeRegEx": "Osborne et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Osborne et al\\.", "year": 1999}, {"title": "An abstract framework for argumentation with structured arguments", "author": ["H. Prakken"], "venue": "Argument & Computation", "citeRegEx": "Prakken,? \\Q2010\\E", "shortCiteRegEx": "Prakken", "year": 2010}, {"title": "Extensive-form argumentation games", "author": ["Procaccia", "A. Rosenschein 2005] Procaccia", "J. Rosenschein"], "venue": "EUMAS 2005,", "citeRegEx": "Procaccia et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Procaccia et al\\.", "year": 2005}, {"title": "Argumentation and game theory", "author": ["Rahwan", "I. Larson 2009] Rahwan", "K. Larson"], "venue": "In Argumentation in Artificial Intelligence. Springer", "citeRegEx": "Rahwan et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Rahwan et al\\.", "year": 2009}, {"title": "Heuristics in argumentation: A game theory investigation", "author": ["Riveret"], "venue": "COMMA, volume 172 of Frontiers in Artificial Intelligence and Applications,", "citeRegEx": "Riveret,? \\Q2008\\E", "shortCiteRegEx": "Riveret", "year": 2008}, {"title": "Probabilistic rule-based argumentation for norm-governed learning agents", "author": ["Rotolo Riveret", "R. Sartor 2012] Riveret", "A. Rotolo", "G. Sartor"], "venue": null, "citeRegEx": "Riveret et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Riveret et al\\.", "year": 2012}, {"title": "Strategic argumentation: a game theoretical investigation", "author": ["Roth"], "venue": "In ICAIL \u201907: Proceedings of the 11th International Conference on Artificial Intelligence and Law,", "citeRegEx": "Roth,? \\Q2007\\E", "shortCiteRegEx": "Roth", "year": 2007}, {"title": "A semantics of argumentation under incomplete information", "author": ["Satoh", "K. Takahashi 2011] Satoh", "K. Takahashi"], "venue": "In Proceedings of Jurisn", "citeRegEx": "Satoh et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Satoh et al\\.", "year": 2011}, {"title": "Dialogue games in defeasible logic", "author": ["Thakur"], "venue": "Australian Conference on Artificial Intelligence,", "citeRegEx": "Thakur,? \\Q2007\\E", "shortCiteRegEx": "Thakur", "year": 2007}], "referenceMentions": [{"referenceID": 14, "context": "If we frame this intuition in proof-theoretic settings, such as in those developed in (Governatori et al. 2004; Prakken 2010; Toni 2013) where arguments are defined as inference trees formed by applying rules, exchanging arguments means exchanging logical theories (consisting of rules) proving conclusions.", "startOffset": 86, "endOffset": 136}], "year": 2013, "abstractText": "In this paper we study the complexity of strategic argumentation for dialogue games. A dialogue game is a 2-player game where the parties play arguments. We show how to model dialogue games in a skeptical, non-monotonic formalism, and we show that the problem of deciding what move (set of rules) to play at each turn is an NP-complete problem.", "creator": "LaTeX with hyperref package"}}}