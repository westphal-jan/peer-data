{"id": "1401.3470", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2014", "title": "Message-Based Web Service Composition, Integrity Constraints, and Planning under Uncertainty: A New Connection", "abstract": "thanks to recent advances, ai planning has become the underlying technique for several applications. figuring well among these is automated web background encryption ( sts ) at minimal \" capability \" level, where services are described exploring terms of preconditions and effects over ontological concepts. a key issue nowadays addressing wsc as planning is that ontologies are generally only formal vocabularies ; they also axiomatize the possible relationships between concepts. such axioms correspond to what has been termed \" integrity constraints \" in the actions and usage literature, and applying a scripted service is essentially a belief update operation. logical reasoning required for system update is assumed to be harder than reasoning through the ontology itself. the support for belief update being severely limited in current planning tools.", "histories": [["v1", "Wed, 15 Jan 2014 05:27:56 GMT  (657kb)", "http://arxiv.org/abs/1401.3470v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["j\\\"org hoffmann", "piergiorgio bertoli", "malte helmert", "marco pistore"], "accepted": false, "id": "1401.3470"}, "pdf": {"name": "1401.3470.pdf", "metadata": {"source": "CRF", "title": "Message-Based Web Service Composition, Integrity Constraints, and Planning under Uncertainty: A New Connection", "authors": ["J\u00f6rg Hoffmann", "Piergiorgio Bertoli", "Malte Helmert", "Marco Pistore"], "emails": ["JOE.HOFFMANN@SAP.COM", "BERTOLI@FBK.EU", "HELMERT@INFORMATIK.UNI-FREIBURG.DE", "PISTORE@FBK.EU"], "sections": [{"heading": null, "text": "Thanks to recent advances, AI Planning has become the underlying technique for several applications. Figuring prominently among these is automated Web Service Composition (WSC) at the \u201ccapability\u201d level, where services are described in terms of preconditions and effects over ontological concepts. A key issue in addressing WSC as planning is that ontologies are not only formal vocabularies; they also axiomatize the possible relationships between concepts. Such axioms correspond to what has been termed \u201cintegrity constraints\u201d in the actions and change literature, and applying a web service is essentially a belief update operation. The reasoning required for belief update is known to be harder than reasoning in the ontology itself. The support for belief update is severely limited in current planning tools.\nOur first contribution consists in identifying an interesting special case of WSC which is both significant and more tractable. The special case, which we term forward effects, is characterized by the fact that every ramification of a web service application involves at least one new constant generated as output by the web service. We show that, in this setting, the reasoning required for belief update simplifies to standard reasoning in the ontology itself. This relates to, and extends, current notions of \u201cmessage-based\u201d WSC, where the need for belief update is removed by a strong (often implicit or informal) assumption of \u201clocality\u201d of the individual messages. We clarify the computational properties of the forward effects case, and point out a strong relation to standard notions of planning under uncertainty, suggesting that effective tools for the latter can be successfully adapted to address the former.\nFurthermore, we identify a significant sub-case, named strictly forward effects, where an actual compilation into planning under uncertainty exists. This enables us to exploit off-the-shelf planning tools to solve message-based WSC in a general form that involves powerful ontologies, and requires reasoning about partial matches between concepts. We provide empirical evidence that this approach may be quite effective, using Conformant-FF as the underlying planner.\nc\u00a92009 AI Access Foundation. All rights reserved."}, {"heading": "1. Introduction", "text": "Since the mid-nineties, AI Planning tools have become several orders of magnitude more scalable, through the invention of automatically generated heuristic functions and other search techniques (see McDermott, 1999; Bonet & Geffner, 2001; Hoffmann & Nebel, 2001; Gerevini, Saetti, & Serina, 2003; Helmert, 2006; Chen, Wah, & Hsu, 2006). This has paved the way to the adoption of planning as the underlying technology for several applications. One such application area is web service composition (WSC), by which in this paper we mean the automated composition of semantic web services (SWS). SWS are pieces of software advertised with a formal description of what they do. Composing SWS means to link them together so that their aggregate behavior satisfies a complex user requirement. The ability to automatically compose web services is the key to reducing human effort and time-to-market when constructing integrated enterprise applications. As a result, there is a widely recognized economic potential for WSC.\nIn the wide-spread SWS frameworks OWL-S1 and WSMO2, SWS are described at two distinct \u201clevels\u201d. One of these addresses the overall functionality of the SWS, and the other details precisely how to interact with the SWS. At the former level, called \u201cservice profile\u201d in OWL-S and \u201cservice capability\u201d in WSMO, SWS are described akin to planning operators, with preconditions and effects. Therefore, planning is a prime candidate for realizing WSC at this level. This is the approach we follow in our paper.\nIn such a setting, a key aspect is that SWS preconditions and effects are described relative to an ontology which defines the formal (logical) vocabulary. Indeed, ontologies are much more than just formal vocabularies introducing a set of logical concepts. They also define axioms which constrain the behavior of the domain. For instance, an ontology may define a subsumption relationship between two concepts A and B, stating that all members of A are necessarily members of B. The natural interpretation of such an axiom, in the context of WSC, is that every state that can be encountered \u2013 every possible configuration of domain entities \u2013 must satisfy the axiom. In that sense, ontology axioms correspond to integrity constraints as discussed in the actions and change literature (Ginsberg & Smith, 1988; Eiter & Gottlob, 1992; Brewka & Hertzberg, 1993; Lin & Reiter, 1994; McCain & Turner, 1995; Herzig & Rifi, 1999).3 Hence WSC as considered here is like planning in the presence of integrity constraints. Since the constraints affect the outcome of action executions, we are facing the frame and ramification problems, and execution of actions corresponds closely to complex notions such as belief update (Lutz & Sattler, 2002; Herzig, Lang, Marquis, & Polacsek, 2001). Unsurprisingly, providing such support for integrity constraints in the modern scalable planning tools mentioned above poses serious challenges. To the best of our knowledge, it has yet to be attempted at all.\nRegarding the existing WSC tools, or planning tools employed for solving WSC problems, the situation isn\u2019t much better. Most tools ignore the ontology, i.e., they act as if no constraints on the domain behavior were given (Ponnekanti & Fox, 2002; Srivastava, 2002; Narayanan & McIlraith, 2002; Sheshagiri, desJardins, & Finin, 2003; Pistore, Traverso, & Bertoli, 2005b; Pistore, Marconi, Bertoli, & Traverso, 2005a; Agarwal, Chafle, Dasgupta, Karnik, Kumar, Mittal, & Srivastava, 2005a). Other approaches tackle the full generality of belief update by using general reasoners, and\n1. For example, see the work of Ankolekar et al. (2002) and Burstein et al. (2004). 2. For example, see the work of Roman et al. (2005) and Fensel et al. (2006). 3. Integrity constraints are sometimes also called state constraints or domain constraints.\nsuffer from the inevitable performance deficiencies (Eiter, Faber, Leone, Pfeifer, & Polleres, 2003; Giunchiglia, Lee, Lifschitz, McCain, & Turner, 2004).\nOur work addresses the middle ground between these two extremes, i.e., the trade-off between expressivity and scalability in WSC. We do so via the identification of special cases that can be tackled more efficiently. Figure 1 gives an overview of the WSC and planning frameworks involved.\nIn brief, the forward effects case requires that every effect and ramification of a web service affects at least one new constant that was generated as the web service\u2019s output. In this situation, the frame problem trivializes, making the planning problem more similar to common notions of conformant planning (Smith & Weld, 1998; Bonet & Geffner, 2000; Cimatti, Roveri, & Bertoli, 2004; Hoffmann & Brafman, 2006). We will discuss how existing tools for the latter, in particular Conformant-FF (Hoffmann & Brafman, 2006), can be extended to deal with WSC under forward effects. With strictly forward effects, where action effects are required to affect only outputs, we devise an actual compilation into conformant planning. We thus obtain a scalable tool for interesting WSC problems with integrity constraints. In particular we are able to exploit (some of) the heuristic techniques mentioned above (Hoffmann & Nebel, 2001; Hoffmann & Brafman, 2006).\nIn what follows, we will explain the various parts of Figure 1 in a little more detail. Our starting point is a WSC formalism, addressing WSC in terms of planning in the presence of integrity constraints, as discussed above. The formalism is essentially an enriched form of conformant planning. Its distinguishing aspects are:\n\u2022 The initial state description is a conjunction of literals (possibly not mentioning some of the logical facts in the task, and hence introducing uncertainty).\n\u2022 Actions have a conditional effects semantics, meaning they can be executed in any state, but have an effect only if they are applicable.\n\u2022 Actions may have output variables, i.e., they may create new constants.\n\u2022 There is a set of integrity constraints, each of which is a universally quantified clause.\n\u2022 The semantics of action execution is defined in terms of a belief update operation.\nSection 2 below provides more details on these choices, and motivates them with an example and results from the literature. As we will show, planning in the formalism is very hard. Particularly,\neven just testing whether a given action sequence is a plan is \u03a0p2-complete. This is in contrast to the more common notions of conformant planning, where plan testing is \u201conly\u201d coNP-complete.\nAs we will see, forward effects remove the additional complexity. Intuitively, the forward effects case covers the situation where a web service outputs some new constants, sets their characteristic properties relative to the inputs, and relies on the ontology axioms to describe any ramifications concerning the new constants. This case is syntactically characterized as follows:\n(1) Every effect literal contains at least one output variable.\n(2) Within each integrity constraint, every literal has the same set of variables in its arguments.\nThis definition is best understood with an example. Consider the following variant of the widespread \u201cvirtual travel agency\u201d (VTA). Web services that book travel and accommodation must be linked. These web services generate new constants corresponding to tickets and reservations. For example, there are integrity constraints stating subsumption, such as \u2200z : trainTicket(z) \u21d2 ticket(z). A web service bookTicket may have the input variable x, the precondition train(x ), the output variable y, and the effect trainTicket(y) \u2227 ticketFor(y, x). This is a forward effects task: every effect literal contains the output variable y, and the integrity constraint has the single variable z which provides the arguments of all literals in the constraint. Say one instantiates the input of bookTicket with a constant c and its output with a new constant d. When applying the resulting ground action to a state where train(c) holds true, the constant d gets created, and its characteristic properties relative to the inputs \u2013 trainTicket(d) \u2227 ticketFor(d, c) \u2013 are set directly by the action. The integrity constraint takes care of the ramification, establishing that ticket(d) holds. Note that the status of c \u2013 apart from its relation to d \u2013 is not affected in any way. 4\nThe forward effects case is closely related to a wide-spread notion of WSC problems, which we refer to as \u201cmessage-based WSC\u201d. In such approaches, the composition semantics is based on chaining over input and output messages of web services, in one or the other sense. Inferences from ontology axioms can be made in many of these approaches, but only in a restricted way limited by an assumption of \u201clocality\u201d of the individual messages, where the interferences affect only a particular message transfer, and any implications for other transfers are ignored. This locality assumption is usually made in an informal way, and often not stated explicitly at all. One contribution of our work is to shed some light on this issue, via the identification of the forward effects case which lies \u201cin between\u201d message-based WSC and a full planning framework with belief update semantics.\nBoth message-based WSC and the forward effects case share the focus on output constants. There are two important differences. First, the forward effects case is more restricted than messagebased WSC in terms of the ontology axioms allowed. Essentially, forward effects correspond to a special case of WSC where the locality assumption of message-based WSC is actually justified, within a full planning framework. Second, that full framework comes with the benefit of increased flexibility in the combination of services, because locality is not enforced (e.g. the output of one service may be reused at several points in a plan).\nFrom a computational point of view, the key property of the forward effects case is that it removes the need for belief update. In a nutshell, the reason is that actions affect only \u201cnew\u201d propositions, i.e., propositions involving at least one output constant. (Recall here the point made about\n4. The latter would not be the case if the effect of bookTicket included a literal affecting only x (example:\n\u00actrain(x)), or if there was an integrity constraint capable of mixing \u201cold\u201d and \u201cnew\u201d constants (example: \u2200x, y : trainTicket(y) \u21d2 \u00actrain(x)).\nthe unchanged status of c, in the VTA example above.) The output constant (d, in the example) does not exist prior to the application of the action, and hence the previous belief carries no knowledge about it and need not be revised. Consider the characterization of forward effects, as given above. Condition (1) ensures that the immediate effect of the action affects only new propositions. Condition (2) ensures that any changes on new propositions only propagate to new propositions. Since all literals in a constraint share the same variables, the output constant in question is copied to all of them. As we will see, by virtue of these properties the complexity of plan testing is coNP-complete, rather than \u03a0p2-complete, in the forward effects case. This complexity reduction is critical because the reduced complexity is the same as in the more common notions of conformant planning under initial state uncertainty. Therefore it should be feasible to adapt conformant planning tools to address WSC with forward effects. Scalable planning tools for conformant planning have already been developed (Cimatti et al., 2004; Bryce, Kambhampati, & Smith, 2006; Hoffmann & Brafman, 2006; Palacios & Geffner, 2007). Hence this is a promising line of research. As an example, we will focus on the Conformant-FF tool (Hoffmann & Brafman, 2006) (short CFF) and outline the main steps that need to be taken in adapting CFF to handle WSC with forward effects.\nWe then identify a case where an actual compilation into conformant planning under initial state uncertainty exists. For that, one must fix a set of constants a priori. In a manner that is fairly standard (see, e.g., the Settlers domain of Long & Fox, 2003), we simply include in that set a subset of \u201cpotential constants\u201d that can be used to instantiate outputs. The more subtle idea we put forward is to identify a condition on the actions under which we can \u201cpredict\u201d which properties will be assigned to which potential constants, in case they are created. This enables us to design a compilation that moves all action effects into the initial state formula, and uses actions only to modify the set of constants that already exist. In this way, reasoning about the initial state formula in the compiled task is the same as reasoning about output constants in the original task, and the reasoning mechanisms included in tools such as CFF can be naturally used to implement the latter.\nOur trick for predicting output properties is to require that all actions are compatible in the sense that they either produce different outputs, or have the same effects. It turns out that this condition is naturally given in a restriction of forward effects, which we call strictly forward effects, where the web service effects concern only new constants.\nClearly, not being able to reference the inputs is a limitation. For example, we can no longer say, in the above VTA example, that the output y is a ticket for the input x. Still, the strictly forward effects case describes an interesting class of WSC problems. That class corresponds to web services modeled as in the early versions of OWL-S, for example, where there was no logical connection between inputs and outputs. Further, this class of WSC problems allows powerful ontologies \u2013 universally quantified clauses \u2013 and makes it possible to combine services very flexibly. Using our compilation, this class of problems can be solved by off-the-shelf tools for planning under uncertainty.\nWe validate the compilation approach empirically by running a number of tests using CFF as the underlying planner. We use two test scenarios, both of which are scalable in a variety of parameters, covering a range of different problem structures. We examine how CFF reacts to the various parameters. Viewed in isolation, these results demonstrate that large and complex WSC instances can be comfortably solved using modern planning heuristics.\nA comparison to alternative WSC tools is problematic due to the widely disparate nature of what kinds of problems these tools can solve, what kinds of input languages they understand, and\nwhat purpose the respective developers had in mind. To nevertheless provide some assessment of the comparative benefits of our approach we run tests with the DLVK tool by Eiter et al. (2003) and Eiter, Faber, Leone, Pfeifer, and Polleres (2004). DLVK is one of the few planning tools that deals with ontology axioms \u2013 called \u201cstatic causal rules\u201d \u2013 directly, without the need to restrict to forward effects and without the need for a compilation. Since, in the context of our work, the main characteristic of WSC is the presence of ontology axioms, this means that DLVK is one of the few existing \u201cnative WSC tools\u201d. By comparison, our forward effects compilation approach solves a similar problem, but sacrifices some expressivity. The question is, can we in principle gain anything from this sacrifice? Absolutely, the answer is \u201cyes\u201d. DLVK is much slower than compilation+CFF, solving only a small fraction of our test instances even when always provided with the correct plan length bound. We emphasize that we do not wish to over-state these results, due to the above-mentioned differences between the tools. The only conclusion we draw is that the trade-off between expressivity and scalability in WSC is important, and that the forward effects case seems to constitute an interesting point in that trade-off.\nThe paper is organized as follows. First, Section 2 provides some further background necessary to understand the context and contribution of our work. Section 3 introduces our WSC planning formalism. Section 4 defines and discusses forward effects. Section 5 introduces our compilation to planning under uncertainty, and Section 6 presents empirical results. We discuss the most closely related work at the relevant points during the text, and Section 7 provides a more complete overview. Finally, Section 8 concludes and discusses future work. To improve readability, most proofs are moved into Appendix A and replaced in the text by proof sketches."}, {"heading": "2. Background", "text": "The context of our work is rather intricate. WSC as such is a very new topic posing many different challenges to existing techniques, with the effect that the field is populated by disparate works differing considerably in their underlying purpose and scope. In other words, the \u201ccommon ground\u201d is fairly thin in this area. Further, our work actually involves three fields of research \u2013 WSC, planning, and reasoning about actions and change \u2013 which are all relevant to understanding our contribution. For these reasons, we now explain this background in some detail. We first discuss WSC in general, and WSC as Planning in particular. We then state the relevant facts about belief update. We finally consider \u201cmessage-based\u201d WSC."}, {"heading": "2.1 WSC, and WSC as Planning", "text": "Composition of semantic web services has received considerable attention in the last few years. A general formulation of the problem, shared by a large variety of works, focuses on the \u201ccapability\u201d level, where each web service is conceived as an atomic operator that transforms concepts. More specifically, a service is defined via an \u201cIOPE\u201d description: the service receives as input a set I of typed objects, and, provided some precondition P on I holds, produces as output a set O of typed objects for which some effect E is guaranteed to hold. The typing of the objects exchanged by the services is given in terms of their membership in concepts. Concepts are classes defined within ontologies, which exploit Description Logics (DL), or some other form of logic, to formally define the universe of concepts admitted in the discourse. An ontology can express complex relationships among concepts, like a subsumption hierarchy, or the way objects belonging to a concept are structured into parts referring to other concepts.\nThis general setting can be instantiated in various ways depending on the kind of conditions admitted as preconditions/effects of services, and on the kind of logics underlying the ontology definitions. Independent of this, the problem of semantic web service composition can be stated as one of \u201clinking appropriately a set of existing services so that their aggregate behavior is that of a desired service (the goal)\u201d. To illustrate this problem, consider the following example, which is inspired by the work of Thakkar, Ambite, and Knoblock (2005) on e-services for bioinformatics (and relies on the actual structure of proteins, see for example Petsko & Ringe, 2004; Branden & Tooze, 1998; Chasman, 2003; Fersht, 1998):\nExample 1 Say we want to compose a web service that provides information about different classes of proteins. The ontology states which classes of proteins exist, and which structural characteristics may occur. We have available an information service for every structural characteristic, and a presentation service that combines a range of information. Given a particular protein class, the composed web service should run the relevant information services, and present their output.\nConcretely, classes of proteins are distinguished by their location (cell, membrane, intermembrane, . . . ). This is modeled by predicates protein(x), cellProtein(x), membraneProtein(x), intermembraneProtein(x), along with sub-concept relations such as \u2200x : cellProtein(x) \u21d2 protein(x). An individual protein is characterized by the following four kinds of structures:\n1. The \u201cprimary structure\u201d states the protein\u2019s sequence of amino-acids, e.g., 1kw3(x) (a protein called \u201cGlyoxalase\u201d) and 1n55(x) (a protein called \u201cTriosephosphate Isomerase\u201d).\n2. The \u201csecondary structure\u201d states the protein\u2019s external shape in terms of a DSSP (\u201cDictio-\nnary of Secondary Structure for Proteins\u201d) code, admitting a limited set of possible values. For example, G indicates a 3-turn helix, B a \u03b2-sheet, and so on. The total set of values is G,H,I,T,E,B,S.\n3. The \u201ctertiary structure\u201d categorizes the protein\u2019s 3-D shape.\n4. For a subset of the proteins, a \u201cquaternary structure\u201d categorizes the protein\u2019s shape when\ncombined in complexes of proteins (amounting to about 3000 different shapes, see for example 3DComplex.org, 2008).\nThere are various axioms that constrain this domain, apart from the mentioned subconcept relations. First, some obvious axioms specify that each protein has a \u201cvalue\u201d in each of the four kinds of structures (i.e., the protein has a sequence of amino-acids, an external shape, etc). However, there are also more complex axioms. Particular kinds of proteins come only with particular structure values. This is modeled by axioms such as:\n\u2200x : \u00accellProtein(x) \u2228 G(x) \u2228 \u00ac1n55(x)\n\u2200x : \u00accellProtein(x) \u2228 \u00acB(x) \u2228 1kw3(x) \u2228 complexBarrel(x)\nFor each DSSP code Z there is an information service, named getInfoDSSPZ , whose precondition is Z(x) and whose effect is InfoDSSP(y) where y is an output of the service. Similarly, we have information services for amino-acids, 3-D shapes, and shapes in complexes. The presentation service, named combineInfo, requires that information on all four kinds of structures has been created, and has the effect combinedPresentation(y) (where y is an output of combineInfo).\nThe input to the composed web service is a protein c (a logical constant) and its class. The goal is \u2203x : combinedPresentation(x). A solution is to reason about which characteristics may occur, to apply the respective information services, and then to run combineInfo. In a variant of the problem, an additional requestInfo service is used to initiate the information request, i.e., the output of requestInfo is the protein c and its class.\nThis example shows how ontology axioms play a crucial role in our form of WSC, formulating complex dependencies between different concepts. Note that applying a web service may have indirect consequences implied by the ontology axioms. In the example, the output of the requestInfo service has implications for which kinds of information services are required.\nAnother interesting aspect of Example 1 is that it requires what the SWS community calls \u201cpartial matches\u201d, as opposed to \u201cplug-in matches\u201d (Paolucci, Kawamura, Payne, & Sycara, 2002; Li & Horrocks, 2003; Kumar, Neogi, Pragallapati, & Ram, 2007).5 Consider the situation where one wants to \u201cconnect\u201d a web service w to another web service w\u2032. That is, w will be executed prior to w\u2032, and the output of w will be used to instantiate the input of w\u2032. Then w and w\u2032 are said to have a partial match if, given the ontology axioms, the output of w sometimes suffices to provide the necessary input for w\u2032. By contrast, w and w\u2032 are said to have a plug-in match if, given the ontology axioms, the output of w always suffices to provide the necessary input for w\u2032.\nPlug-in matches are tackled by many approaches to WSC, whereas partial matches are tackled only by few. Part of the reason probably is that plug-in matches are easier to handle, in many types of WSC algorithms. Indeed most existing WSC tools support plug-in matches only (see a detailed discussion of WSC tools in Section 7). Example 1 cannot be solved with plug-in matches because each of the information services provides the necessary input for the combineInfo service only in some particular cases.\nWe base our work on a planning formalism that allows to specify web services (i.e., actions) with outputs, and that allows to specify ontology axioms. The axioms are interpreted as integrity constraints, and the resulting semantics corresponds closely to the common intuitions behind WSC, as well as to the existing formal definitions related to WSC (Lutz & Sattler, 2002; Baader, Lutz, Milicic, Sattler, & Wolter, 2005; Liu, Lutz, Milicic, & Wolter, 2006b, 2006a; de Giacomo, Lenzerini, Poggi, & Rosati, 2006). Since one of our main aims is to be able to exploit existing planning techniques, we consider a particular form of ontology axioms, in correspondence with the representations that are used by most of the existing tools for planning under uncertainty. Namely, the axioms are universally quantified clauses. An example is the subsumption relation \u2200x : trainTicket(x) \u21d2 ticket(x) mentioned above, where as usual A \u21d2 B is an abbreviation for \u00acA\u2228B. A planning task specifies a set of such clauses, interpreted as the conjunction of the clauses. Note that this provides significant modeling power. The meaning of the universal quantification in the clauses is that the clauses hold for all planning \u201cobjects\u201d \u2013 logical constants \u2013 that are known to exist. In that sense, the interpretation of formulas is closed-world as is customary in planning tools. However, in contrast to most standard planning formalisms including PDDL, we do not assume a fixed set of constants. Rather, the specification of actions with outputs enables the dynamic creation of new constants. The quantifiers in the ontology axioms range over all constants that exist in the respective world. In a similar fashion, the planning goal may contain variables, which are existentially quantified. The constants used to instantiate the goal may have pre-existed, or they may have been generated as\n5. The terminology in these works is slightly different from what we use here, and they also describe additional kinds\nof matches. Some details are given in Section 7.\nthe outputs of some of the web services that were applied on the path to the world. Consider for illustration the goal \u2203x : combinedPresentation(x) in Example 1, where the goal variable x will have to be instantiated with an output created by the combineInfo service.\nAnother important aspect of our planning formalism is that we allow incomplete initial state descriptions. The initial state corresponds to the input that the user provides to the composed web service. Certainly we cannot assume that this contains complete information about every aspect of the world. (In Example 1, the initial state tells us which class of proteins we are interested in, but leaves open what the consequences are regarding the possible structural characteristics.) We consider the case where there is no observability, i.e., conformant planning. The outcome of WSC is a sequence of web services that satisfies the user goal in all possible situations.6 As is customary in conformant planning, the actions have a conditional effects semantics, i.e., they fire if their precondition holds true, and otherwise they do nothing. Note that, this way, we obtain a notion of partial matches: the solution employs different actions depending on the situation.\nThe main difference between our planning formalism and the formalisms underlying most current planning tools is the presence of integrity constraints, and its effect on the semantics of executing actions. That semantics is defined as a belief update operation."}, {"heading": "2.2 Belief Update", "text": "The correspondence of web service applications to belief update was first observed by Lutz and Sattler (2002), and followed by Baader et al. (2005), Liu et al. (2006b, 2006a) and de Giacomo et al. (2006). In the original statement of the belief update problem, we are given a \u201cbelief\u201d \u03a6, i.e., a logical formula defining the worlds considered possible. We are further given a formula \u03c6, the \u201cupdate\u201d. Intuitively, \u03c6 corresponds to some observation telling us that the world has changed in a way so that, now, \u03c6 is true. We want to obtain a formula \u03a6\u2032 defining the worlds which are possible given this update. Certainly, we need to have that \u03a6\u2032 |= \u03c6. Ensuring this corresponds to the well-known ramification problem. At the same time, however, the world should not change unnecessarily. That is, we want \u03a6\u2032 to be \u201cas close as possible to \u03a6\u201d, among the formulas which satisfy \u03c6. This corresponds to the frame problem.\nSay we want to apply an action a in the presence of integrity constraints. \u03a6 describes the worlds that are possible prior to the application of a. \u03a6\u2032 is the resulting set of possible worlds. The integrity constraints correspond to a formula \u03a6IC which holds in \u03a6, and which we require to hold in \u03a6\u2032. The update formula \u03c6 is given as the conjunction of the action effect with \u03a6IC , i.e., we have \u03c6 = effa \u2227 \u03a6IC . This means that we update our previous belief with the information that, after a, effa is a new formula required to hold, and \u03a6IC is still true. For example, we may have an action effect A(c) and a subsumption relation between concepts A and B, formulated as a clause \u2200x : \u00acA(x) \u2228B(x). Then the update formula A(c) \u2227 \u2200x : \u00acA(x) \u2228B(x) ensures that B(c) is true in \u03a6\u2032.\nBelief update has been widely considered in the literature on AI and databases (see for example Fagin, Kuper, Ullman, & Vardi, 1988; Ginsberg & Smith, 1988; Winslett, 1988, 1990; Katzuno & Mendelzon, 1991; Herzig, 1996; Herzig & Rifi, 1999; Liu et al., 2006b; de Giacomo et al., 2006). The various approaches differ in exactly how \u03a6\u2032 should be defined. The best consensus is that there is no one approach that is most adequate in every application context. All approaches\n6. Of course, more generally, observability is partial and web service effects are also uncertain. We do not consider\nthese generalizations here. Extending our notions accordingly should be straightforward, and is future work.\nagree that \u03c6 should hold in the updated state of affairs, \u03a6\u2032 |= \u03c6. Major differences lie in what exactly it should be taken to mean that \u03a6\u2032 should be \u201cas close as possible to \u03a6\u201d. Various authors, for example Brewka and Hertzberg (1993), McCain and Turner (1995), Herzig (1996), and Giunchiglia and Lifschitz (1998), argue that a notion of causality is needed, in addition to (or even instead of) a notion of integrity constraints, to model domain behavior in a natural way. We do not counter these arguments, but neither do we follow a causal approach in our work. The reason is that ontologies in the context of WSC, for example ontologies formulated in the web ontology language OWL (McGuinness & van Harmelen, 2004), do not incorporate a notion of causality. All we are given is a set of axioms, made with the intention to describe the behavior of the domain itself, rather than the behavior it exhibits when changed by some particular web services. Our idea in this work is to try to leverage on what we have (or what we are reasonably close to having). Consideration of causal approaches in WSC is left for future work.\nBelief update is a computationally very hard problem. Eiter and Gottlob (1992) and Liberatore (2000) show that, for the non-causal approaches to defining \u03a6\u2032, reasoning about \u03a6\u2032 is typically harder than reasoning in the class of formulas used for formulating \u03a6 and \u03c6. Specifically, deciding whether or not a particular literal is true in \u03a6\u2032 is \u03a02p-hard even if \u03a6 is a complete conjunction of literals (corresponding to a single world state) and \u03c6 is a propositional CNF formula. The same problem is coNP-hard even if \u03a6 is a single world state and \u03c6 is a propositional Horn formula. We use these results to show that, in our planning formalism, checking a plan \u2013 testing whether or not a given action sequence is a plan \u2013 is \u03a02p-complete, and deciding polynomially bounded plan existence is \u03a33p-complete.\nGiven this complexity, it is perhaps unsurprising that the support for integrity constraints in current planning tools is severely limited. The only existing planning tools that do support integrity constraints, namely those by Eiter et al. (2003) and Giunchiglia et al. (2004), are based on generic deduction, like satisfiability testing or answer set programming. They hence lack the planningspecific heuristic and search techniques that are the key to scalability in the modern planning tools developed since the mid-nineties. It has not even been investigated yet if and how integrity constraints could be handled in the latter tools. The only existing approach that ventures in this direction implements so-called derived predicates in some of the modern planning tools (Thie\u0301baux, Hoffmann, & Nebel, 2005; Gerevini, Saetti, Serina, & Toninelli, 2005; Chen et al., 2006). This approach postulates a strict distinction between \u201cbasic\u201d predicates that may be affected by actions, and \u201cderived\u201d predicates that may be affected by integrity constraints taking the form of logic programming rules. If a predicate appears in an action effect, then it is not allowed to appear in the head of a rule. This is not a desirable restriction in the context of WSC, where web services are bound to affect properties that are constrained by ontology axioms.\nThe existing work connecting WSC with belief update (Lutz & Sattler, 2002; Baader et al., 2005; Liu et al., 2006b, 2006a; de Giacomo et al., 2006) is of a theoretical nature. The actual implemented WSC tools make severe simplifying assumptions. Most often, that assumption is to ignore the ontology axioms (Ponnekanti & Fox, 2002; Srivastava, 2002; McIlraith & Son, 2002; Sheshagiri et al., 2003; Sirin, Parsia, Wu, Hendler, & Nau, 2004; Pistore et al., 2005b, 2005a). Sometimes, the ontology constraints are restricted to subsumption hierarchies, which makes the update problem easy (Constantinescu & Faltings, 2003; Constantinescu, Faltings, & Binder, 2004b, 2004a). Sirin and Parsia (2004) and Sirin, Parsia, and Hendler (2006) discuss the problem of dealing with ontology axioms in WSC, but do not make a connection to belief update, and describe no alternative solution. Finally, some authors, for example Meyer and Weske (2006), do deal with ontology ax-\nioms during composition, but do not provide a formal semantics and do not specify exactly how action applications are handled. It seems that these not fully formalized WSC approaches implicitly assume a message-based framework. Those frameworks are closely related to the forward effects special case identified herein."}, {"heading": "2.3 Message-Based WSC", "text": "In message-based approaches to WSC, the composition semantics is based on chaining over input and output messages of web services. The word \u201cmessage\u201d is not a standard term in this context. Most authors use their own individual vocabulary. As far as we are aware, the first appearance of the word \u201cmessage\u201d in a WSC paper title is in the work by Liu, Ranganathan, and Riabov (2007). This work describes message-based WSC as follows. A solution is a directed acyclic graph (DAG) of web services, where the input needed for web service (DAG graph node) w must be provided by the outputs of the predecessors ofw in the graph. That is, the plan determines fixed connections between the actions. Reasoning, then, only takes place \u201cwithin these connections\u201d. Any two connections between different output and input messages, i.e., any two graph edges ending in a different node, are assumed to be mutually independent. Consider the following example for illustration. Say a web service w has the effect hasAttributeA(c, d) where d is an output constant and c is an input (i.e., c existed already prior to application of w). Say there is an axiom \u2200x, y : hasAttributeA(x, y) \u21d2 conceptB(x) expressing an \u201cattribute domain restriction\u201d. If x has y as a value of attribute A, then x must be of concept B. Given this, w\u2019s effect implies conceptB(c). Now, suppose that our belief prior to applying w did not constrain c to be of concept B. Then applying w leads to new knowledge about c. Hence we need a non-trivial belief update taking into account the changed status of c, and any implications that may have. Message-based WSC simply acts as if the latter is not the case. It only checks whether w correctly supplies the inputs of the web services w\u2032 that w is connected to. That is, the new fact hasAttributeA(c, d) may be taken as part of a proof that the effect of w implies the precondition of a connected web service w\u2032. But it is not considered at all what implications hasAttributeA(c, d) may have with respect to the previous state of affairs. In that sense, message-based WSC \u201cignores\u201d the need for belief update.\nThe intuitions underlying message-based WSC are fairly wide-spread. Many papers use them in a more or less direct way. There are many approaches that explicitly define WSC solutions to be DAGs with local input/output connections as above (Zhan, Arpinar, & Aleman-Meza, 2003; Lecue & Leger, 2006; Lecue & Delteil, 2007; Kona, Bansal, Gupta, & Hite, 2007; Liu et al., 2007; Ambite & Kapoor, 2007). In various other works (Constantinescu & Faltings, 2003; Constantinescu et al., 2004b, 2004a; Meyer & Weske, 2006), the message-based assumptions are more implicit. They manifest themselves mainly in the sense that ontology axioms are only used to infer the properties of output messages, and often only for checking whether the inferences imply that a desired input message is definitely given.\nPrevious work on message-based WSC does not address at all how message-based WSC relates to the various notions, like belief update, considered in the literature. One contribution of our work is to shed some light on this issue, via the identification of the forward effects case which lies \u201cin between\u201d message-based WSC and a full planning framework with belief update semantics.\nBoth message-based WSC and the forward effects case share the focus on outputs. Indeed, the output constants generated by our actions can be viewed as \u201cmessages\u201d. An output constant represents an information object which is created by one web service, and which will form the\ninput of some other web service. In the forward effects case, due to the restriction on axioms, the individual messages do not interact. This is much like message-based WSC. The main difference is this: while message-based WSC ignores any possible interactions, in forward effects there actually aren\u2019t any interactions, according to a formal planning-based execution semantics. In that sense, forward effects correspond to a special case of WSC where the assumptions of message-based WSC are justified.\nReconsider our example from above, featuring a web service w with an effect implying that conceptB(c) where c is a pre-existing constant. As explained above, message-based WSC will simply ignore the need for updating the knowledge about c. In contrast, the forward effects case disallows the axiom \u2200x, y : hasAttributeA(x, y) \u21d2 conceptB(x) because it may lead to new conclusions about the old belief (note that the literals in the axiom refer to different sets of variables).\nThe forward effects case also differs significantly from most approaches to message-basedWSC in terms of the flexibility with which it allows to combine actions into plans. In the messagebased approach using DAGs, a solution DAG ensures that the inputs of each service w can always be provided by w\u2019s predecessors. That is, we have a plug-in match between the set W of w\u2019s predecessors in the DAG, and w itself. Note that this is slightly more general than the usual notion of plug-in matches, in that |W |may be greater than 1, and hence each single service inW may have only a partial match with w. This is the notion used, amongst others, by Liu et al. (2007). Other authors, for example Lecue and Leger (2006) and Lecue and Delteil (2007), are more restrictive in that they consider every individual input x ofw in turn and require that there exists aw\u2032 \u2208 W so that w\u2032 has a plug-in match with x (i.e., w\u2032 guarantees to always provide x). Even in the more generous of these two definitions, partial matches are restricted to appear locally, on DAG links. Every action/web service is required to be always executable at the point where it is applied. In other words, the services are used in a fixed manner, not considering the dynamics of actual execution. In Example 1, this would mean using the same information services regardless of the class of the protein, hence completely ignoring what is relevant and what is not.\nThe forward effects case incorporates a much more general notion of partial matches. This happens in a straightforward way, exploiting the existing notions from planning, in the form of a conditional effects semantics. The standard notion of a conformant solution defines how partial matches must work together on a global level, to accomplish the goal. To the best of our knowledge, there is only one other line of work on WSC, by Constantinescu et al. (Constantinescu & Faltings, 2003; Constantinescu et al., 2004b, 2004a), that incorporates a comparable notion of partial matches. In that work, web services are characterized in terms of input and output \u201ctypes\u201d. To handle partial matches, so-called \u201cswitches\u201d combine several web services in a way that ascertains all relevant cases can be covered. The switches are designed relative to a subsumption hierarchy over the types. Note that subsumption hierarchies are a special case of the much more general integrity constraints \u2013 universally quantified clauses \u2013 that we consider in our work."}, {"heading": "3. Formalizing WSC", "text": "As a solid basis for addressing WSC, we define a planning formalism featuring integrity constraints, on-the-fly creation of output constants, incomplete initial state descriptions, and actions with a conditional effects semantics. The application of actions is defined as a belief update operation, following the possible models approach by Winslett (1988). That definition of belief update is somewhat canonical in that it is very widely used and discussed. In particular it underlies all the recent work\nrelating to formalizations of WSC (Lutz & Sattler, 2002; Baader et al., 2005; Liu et al., 2006b, 2006a; de Giacomo et al., 2006; de Giacomo, Lenzerini, Poggi, & Rosati, 2007). As we will show further below (Section 4.3), most belief update operations are equivalent anyway as soon as we are in the forward effects case. Recall here that the forward effects case is the central object of investigation in this paper.\nWe first give the syntax of our formalism, which we denote withWSC, then we give its semantics. We conclude with an analysis of its main computational properties."}, {"heading": "3.1 Syntax", "text": "We denote predicates withG,H, I , variables with x, y, z, and constants with c, d, e. Literals are possibly negated predicates whose arguments are variables or constants. If all arguments are constants, the literal is ground. We refer to positive ground literals as propositions. Given a set P of predicates and a set C of constants, we denote by PC the set of all propositions that can be formed from P and C. Given a setX of variables, we denote by LX the set of all literals l which use only variables from X . Note here that l may use arbitrary predicates and constants.7 If l is a literal, we write l[X] to indicate that l has the variable arguments X . If X = {x1, . . . , xk} and C = (c1, . . . , ck), then by l[c1, . . . , ck/x1, . . . , xk] we denote the respective substitution, abbreviated as l[C]. In the same way, we use the substitution notation for any construct involving variables. Slightly abusing notation, we use a vector of constants also to denote the set of constants appearing in it. Further, if a function a assigns constants to the variables X , then by l[a/X] we denote the substitution where each argument x \u2208 X was replaced with a(x). We are only concerned with first-order logic, that is, whenever we write formula we mean a first-order formula. We denote true as 1 and false as 0.\nA clause, or integrity constraint, is a disjunction of literals with universal quantification on the outside. The variables quantified over are exactly those that appear in at least one of the literals. For example, \u2200x, y : \u00acG(x, y)\u2228H(x) is an integrity constraint but \u2200x, y, z : \u00acG(x, y)\u2228H(x) and \u2200x : \u00acG(x, y)\u2228H(x) are not. An operator o is a tuple (Xo, preo, Yo, effo), whereXo, Yo are sets of variables, preo is a conjunction of literals from L Xo , and effo is a conjunction of literals from L Xo\u222aYo .8 The intended meaning is thatXo are the inputs and Yo the outputs, i.e., the new constants created by the operator. For an operator o, an action a is given by (prea, effa) \u2261 (preo, effo)[Ca/Xo, Ea/Yo] where Ca and Ea are vectors of constants. For Ea we require that the constants are pairwise different \u2013 it makes no sense to \u201coutput the same new constant twice\u201d. Given an action a, we will refer to a\u2019s inputs and outputs by Ca and Ea, respectively. We will also use the notations prea, effa with the obvious meaning.\nAWSC task, or planning task, is a tuple (P,\u03a6IC ,O, C0, \u03c60, \u03c6G). Here, P is a set of predicates. \u03a6IC is a set of integrity constraints. O is a set of operators and C0 is a set of constants, the initial constants supply. \u03c60 is a conjunction of ground literals, describing the possible initial states. \u03c6G is a conjunction of literals with existential quantification on the outside, describing the goal states, e.g., \u2203x, y : G(x) \u2227 H(y). All predicates are taken from P , and all constants are taken from C0. All constructs (e.g., sets and conjunctions) are finite. We will sometimes identify \u03a6IC with the conjunction of the clauses it contains. Note that the existential quantification of the goal variables\n7. One could of course introduce more general notations for logical constructs using some set of predicates or constants.\nHowever, herein the two notations just given will suffice.\n8. As stated, we do not address disjunctive or non-deterministic effects. This is a topic for future work.\nprovides the option to instantiate the goal with constants created during planning \u2013 obtaining objects as requested by the goal may be possible only through the use of outputs.\nThe various formulas occurring in (P,\u03a6IC ,O, C0, \u03c60, \u03c6G)may make use of constants fromC0. Specifically, this is the case for clauses in \u03a6IC and for the goal formula \u03c6G. Allowing such use of constants does not have any effect on our complexity or algorithmic results. It is conceivable that the feature may be useful. As a simple example, in the VTA domain the user may wish to select a particular train. Say the train company provides a table of trains with their itineraries. That table can be represented in \u03c60, possibly with help from \u03a6IC stating constraints that hold for particular trains. The user can then select a train, say ICE107, and pose as a goal that \u2203y : ticketFor(y, ICE107). Constraining the produced ticket in this way would not be possible without the use of pre-existing constants (or would at least require a rather dirty hack, e.g., encoding the desired train in terms of a special predicate).\nOperator descriptions, that is, preconditions and effects, may also use constants from C0. The value of this is more benign than for \u03a6IC and \u03c6G because one can always replace a constant c in the precondition/effect with a new input/output variable x, and instantiate x (during planning) with c. Note, however, that this would give the planner the option to (uselessly) instantiate x with some other constant, and may hence affect planning performance. In our above example, there might be a special operator booking a ticket for ICE107 (e.g., if that train has particular ticketing regulations). The correspondence of a WSC task to a web service composition task is fairly obvious. The set P of predicates is the formal vocabulary used in the underlying ontology. The set \u03a6IC of integrity constraints is the set of axioms specified by the ontology, i.e., domain constraints such as subsumption relations. The setO of operators is the set of web services. Note that our formalization corresponds very closely to the notion of IOPE descriptions: inputs, outputs, preconditions, and effects (Ankolekar et al., 2002; Burstein et al., 2004). An action corresponds to a web service call, where the web service\u2019s parameters are instantiated with the call arguments.\nThe constructs C0, \u03c60, and \u03c6G are extracted from the user requirement on the composition. We assume that such requirements also take the form of IOPE descriptions. Then, C0 are the user requirement inputs, and \u03c60 is the user requirement precondition. In other words, C0 and \u03c60 describe the input given to the composition by the user. Similarly, \u03c6G is the user requirement effect \u2013 the condition that the user wants to be accomplished \u2013 and the user requirement outputs are the (existentially quantified) variables in \u03c6G."}, {"heading": "3.2 Semantics", "text": "In what follows, assume we are given a WSC task (P,\u03a6IC ,O, C0, \u03c60, \u03c6G). To be able to model the creation of constants, states (also called world states) in our formalism are enriched with the set of constants that exist in them. A state s is a pair (Cs, Is) where Cs is a set of constants, and Is is a Cs-interpretation, i.e., a truth value assignment Is : P\nCs 7\u2192 {0, 1}. Quantifiers are taken to range over the constants that exist in a state. That is, if I is a C-interpretation and \u03c6 is a formula, then by writing I |= \u03c6 we mean that I |= \u03c6C where \u03c6C is the same as \u03c6 except that all quantifiers were restricted to range over C. To avoid clumsy notation, we will sometimes write s |= \u03c6 to abbreviate Is |= \u03c6.\nThe core definition specifies how the application of an action affects a state. This is defined through a form of belief update. Let us first define the latter. Assume a state s, a set of constants C \u2032 \u2287 Cs, and a formula \u03c6. We define update(s, C \u2032, \u03c6) to be the set of interpretations that result\nfrom creating the constants C \u2032 \\ Cs, and updating s with \u03c6 according to the semantics proposed by Winslett (1988).\nSay I1 and I2 are C \u2032-interpretations. We define a partial order over such interpretations, by\nsetting I1 <s I2 if and only if\n{p \u2208 PCs | I1(p) 6= Is(p)} \u2282 {p \u2208 P Cs | I2(p) 6= Is(p)}. (1)\nIn words, I1 is ordered before I2 iff it differs from s in a proper subset of values. Given this, we can now formally define update(s, C \u2032, \u03c6). Let I be an arbitrary C \u2032-interpretation. We define\nI \u2208 update(s, C \u2032, \u03c6) :\u21d4 I |= \u03c6 and {I \u2032 | I \u2032 |= \u03c6, I \u2032 <s I} = \u2205. (2)\nHence, update(s, C \u2032, \u03c6) is defined to be the set of all C \u2032-interpretations which satisfy \u03c6, and which are minimal with respect to the partial order <s. Put in different terms, update(s, C\n\u2032, \u03c6) contains all interpretations that differ from s in a set-inclusion minimal set of values.\nNow, assume an action a. We say that a is applicable in s, short appl(s, a), if s |= prea, Ca \u2286 Cs, and Ea \u2229 Cs = \u2205. That is, on top of the usual precondition satisfaction we require that a\u2019s inputs exist and that a\u2019s outputs do not yet exist. The result of executing a in s is:\nres(s, a) :=\n{\n{(C \u2032, I \u2032) | C \u2032 = Cs \u222a Ea, I \u2032 \u2208 update(s, C \u2032,\u03a6IC \u2227 effa)} appl(s, a) {s} otherwise (3)\nNote that a can be executed in s even if it is not applicable. In that case, the outcome is the singleton set containing s itself, i.e., the action does not affect the state. This is an important aspect of our formalism, which we get back to below. If \u03a6IC \u2227 effa is unsatisfiable, then obviously we get res(s, a) = \u2205. We say in this case that a is inconsistent.9\nThe overall semantics ofWSC tasks is now easily defined via a standard notion of beliefs. These model our uncertainty about the true state of the world. A belief b is the set of world states that are possible at a given point in time. The initial belief is\nb0 := {s | Cs = C0, s |= \u03a6IC \u2227 \u03c60}. (4)\nAn action a is inconsistent with a belief b if it is inconsistent with at least one s \u2208 b. In the latter case, res(b, a) is undefined. Otherwise, it is defined by\nres(b, a) := \u22c3\ns\u2208b\nres(s, a). (5)\nThis is extended to action sequences in the obvious way. A plan is a sequence \u3008a1, . . . , an\u3009 so that\n\u2200s \u2208 res(b0, \u3008a1, . . . , an\u3009) : s |= \u03c6G. (6)\nFor illustration, consider the formalization of our example from Section 2.\nExample 2 Reconsider Example 1. For the sake of conciseness, we formalize only a part of the example, with simplified axioms. TheWSC task is defined as follows:\n9. Unless \u03a6IC mentions any constants, if a is based on operator o and a is inconsistent, then any action based on o is inconsistent. Such operators can, in principle, be filtered out in a pre-process to planning.\n\u2022 P = {protein, cellProtein, G, H, I, 1n55, 1kw3, InfoDSSP, Info3D, combinedPresentation}, where all the predicates are unary.\n\u2022 \u03a6IC consists of the clauses:\n\u2013 \u2200x : \u00accellProtein(x) \u2228 protein(x) \u2013 [subsumption]\n\u2013 \u2200x : \u00acprotein(x) \u2228 G(x) \u2228 H(x) \u2228 I(x) \u2013 [at least one DSSP value]\n\u2013 \u2200x : \u00acprotein(x) \u2228 1n55(x) \u2228 1kw3(x) \u2013 [at least one 3-D shape]\n\u2013 \u2200x : \u00accellProtein(x) \u2228 G(x) \u2228 1n55(x) \u2013 [dependency]\n\u2013 \u2200x : \u00accellProtein(x) \u2228 H(x) \u2228 \u00ac1n55(x) \u2013 [dependency]\n\u2022 O consists of the operators:\n\u2013 getInfoDSSPG: ({x},G(x), {y}, InfoDSSP(y))\n\u2013 getInfoDSSPH : ({x},H(x), {y}, InfoDSSP(y))\n\u2013 getInfoDSSPI : ({x}, I(x), {y}, InfoDSSP(y))\n\u2013 getInfo3D1n55: ({x}, 1n55(x), {y}, Info3D(y))\n\u2013 getInfo3D1kw3: ({x}, 1kw3(x), {y}, Info3D(y))\n\u2013 combineInfo: ({x1, x2}, InfoDSSP(x1) \u2227 Info3D(x2), {y}, combinedPresentation(y))\n\u2022 C0 = {c}, \u03c60 = cellProtein(c)\n\u2022 \u03c6G = \u2203x : combinedPresentation(x)\nTo illustrate the formalism, we now consider a plan for this example task.\nThe initial belief b0 consists of all states s where Cs = {c} and s |= \u03a6IC \u2227 cellProtein(c). Say we apply the following sequence of actions:\n1. Apply getInfoDSSPG(c, d) to b0. Then we get to the belief b1 which is the same as b0 except that, from all s \u2208 b0 where s |= G(c), new states are generated that have the constant d and InfoDSSP(d).\n2. Apply getInfoDSSPH(c, d) to b1. We get the belief b2 where new states with d and InfoDSSP(d) are generated from all s \u2208 b1 where s |= H(c).\n3. Apply getInfo3D1n55(c, e) to b2, yielding b3.\n4. Apply getInfo3D1kw3(c, e) to b3. This yields b4, where we get e and Info3D(e) from all s \u2208 b2 where s |= 1n55(c) or s |= 1kw3(c).\n5. Apply combineInfo(d, e, f) to b4. This brings us to b5 which is like b4 except that from all s \u2208 b4 where d, e \u2208 Cs new states are generated that have f and combinedPresentation(f).\nFrom the dependencies in \u03a6IC (the last two clauses), we get that any s \u2208 b0 satisfies either G(c) or H(c). From the subsumption clause and the clause regarding 3-D shapes (first and third clauses) we get that any s \u2208 b0 satisfies either 1n55(c) or 1kw3(c). Hence, as is easy to verify, b5 |= \u03c6G and so \u3008getInfoDSSPG(c, d), getInfoDSSPH(c, d), getInfo3D1n55(c, e), getInfo3D1kw3(c, e), combineInfo(d, e, f)\u3009 is a plan.\nNote that this plan does not make use of getInfoDSSPI(c, d). To obtain a plan, in this domain one can always just apply all information services. However, this plan is trivial and does not take into account what is relevant and what is not. Reasoning over \u03a6IC enables us to find better plans.\nOur semantics for executing non-applicable actions is vital for the workings of Example 2. As pointed out above, below the definition of res(s, a) (Equation (3)), a can be executed in s even if it is not applicable. This realizes partial matches: a web service can be called as soon as it might match one of the possible situations. In planning terms, our actions have a conditional effects semantics.10 The contrasting notion would be to enforce preconditions, i.e., to say that res(s, a) is undefined if a is not applicable to s. This would correspond to plug-in matches.\nIn Example 2, the partial match semantics is necessary in order to be able to apply actions that cover only particular cases. For example, consider the action getInfoDSSPG(c, d), which is applied to the initial belief in the example plan. The precondition of that action is G(c). However, there are states in the initial belief which do not satisfy that precondition. The initial belief allows any interpretation satisfying \u03a6IC \u2227 \u03c60 (cf. Equation (4)), and some of these interpretations satisfy H(c) rather than G(c). Due to the partial match semantics, getInfoDSSPG(c, d) does not affect such states \u2013 its match with the initial belief is partial.\nClarification is also in order regarding our understanding of constants. First, like every PDDLlike planning formalism (we are aware of), we make a unique name assumption, i.e., different constants refer to different objects. Second, our understanding of web services is that any output they create is a separate individual, i.e., a separate information object.\nThe latter directly raises the question why we allow actions to share output constants. The answer is that we allow the planner to treat two objects as if they were the same. This makes sense if the two objects play the same role in the plan. Consider again Example 2. The actions getInfoDSSPG(c, d) and getInfoDSSPH(c, d) share the same output constant, d. This means that d is one name for two separate information objects. These two objects have the same properties, derived from InfoDSSP(d). The only difference between them is that they are created in different cases, namely from states that satisfy G(c) and H(c) respectively. Having a single name for the two objects is useful because we can take that name as a parameter of actions that do not need to distinguish between the different cases. In the example, combineInfo(d, e, f) is such an action. As hinted, the \u201ccases\u201d in the above correspond to different classes of concrete execution traces. Importantly, on any particular execution trace, each output constant is created at most once. To see this, consider an execution trace s0, a0, s1, a1, . . . , ak, sk+1, i.e., an alternating sequence of states and actions where s0 \u2208 b0, and si+1 \u2208 res(si, ai) for all 0 \u2264 i \u2264 k. Say that ai and aj share an output constant, d. Say further that ai is applicable in si, and hence d \u2208 Csi+1 . Then, quite obviously, we have d \u2208 Csl for all i + 1 \u2264 l \u2264 k + 1. In particular, aj is not applicable in sj : the intersection of its output constants with Csj is non-empty (cf. the definition of appl(s, a)). So, due to our definition of action applicability, it can never happen that the same constant is created twice. In other words, there can never be a reachable state where a single constant name refers to more than one individual information object. In that sense, the use of one name for several objects occurs only at planning time, when the actual execution trace \u2013 the actual case which will occur \u2013 is not known. For illustration, consider getInfoDSSPG(c, d) and getInfoDSSPH(c, d), and their shared\n10. An obvious generalization is to allow several conditional effects per action, in the style of the ADL language (Ped-\nnault, 1989). We omit this here for the sake of simplifying the discussion. An extension in this direction is straightforward.\noutput d, in Example 2. Even if the concrete state s0 \u2208 b0 in which the execution starts satisfies both G(c) and H(c), only one of the actions will fire \u2013 namely the one that comes first.\nWe remark that we initially experimented with a definition where actions instantiate only their inputs, and when they are applied to a state s their outputs are, by virtue of the execution semantics, instantiated to constants outside of Cs. In such a framework, one can never choose to \u201cshare output constants\u201d, i.e., to use the same name for two different outputs. The notion we have settled for is strictly richer: the planner can always choose to instantiate the outputs with constants outside of Cs. The question is, when does it make sense to share outputs? Answering this question in a domainindependent planner may turn out to be quite non-trivial. We get back to this when we discuss a possible adaptation of CFF in Section 4.5. In the experiments reported herein (Section 6), we use a simple heuristic. Outputs are shared iff the operator effects are identical (giving an indication that the respective outputs may indeed \u201cplay the same role\u201d in the plan).\nWe conclude this sub-section with a final interesting observation regarding modeling in our framework. Negative effects are not an essential part of theWSC formalism: they can be compiled away. We simply replace any negative effect \u00acG(x1, . . . , xk) with notG(x1, . . . , xk) (introducing a new predicate) and state in the integrity constraints that the two are equivalent. That is, we introduce the two new clauses \u2200x1, . . . , xk : G(x1, . . . , xk) \u2228 notG(x1, . . . , xk) and \u2200x1, . . . , xk : \u00acG(x1, . . . , xk) \u2228 \u00acnotG(x1, . . . , xk). While this is a simple compilation technique, the formal details are a little intricate, and are moved to Appendix A. If a is an action in the original task, then a+ denotes the corresponding action in the compiled task, and vice versa. Similarly, if s is an action in the original task, then s+ denotes the corresponding state in the compiled task. We get:\nProposition 1 (Compilation of Negative Effects in WSC) Assume a WSC task (P, \u03a6IC , O, C0, \u03c60, \u03c6G). Let (P +,\u03a6\u2032+IC ,O +, C0, \u03c60, \u03c6G) be the same task but with negative effects compiled away. Assume an action sequence \u3008a1, . . . , an\u3009. Let b be the result of executing \u3008a1, . . . , an\u3009 in (P, \u03a6IC , O, C0, \u03c60, \u03c6G), and let b + be the result of executing \u3008a+1 , . . . , a + n \u3009 in (P +,\u03a6+IC ,O +, C0, \u03c60, \u03c6G). Then, for any state s, we have that s \u2208 b iff s+ \u2208 b+.\nThis can be proved by straightforward application of the relevant definitions. The most important aspect of the result is that the new clauses introduced are allowed in the forward effects and strictly forward effects special cases identified later. Hence, any hardness results transfer directly to tasks without negative effects and dropping negative effects cannot make the algorithms any easier."}, {"heading": "3.3 Computational Properties", "text": "We now perform a brief complexity analysis of the WSC formalism in its most general form as introduced above. In line with many related works of this kind (Eiter & Gottlob, 1992; Bylander, 1994; Liberatore, 2000; Eiter et al., 2004), we consider the propositional case. In our context, this means that we assume a fixed upper bound on the arity of predicates, on the number of input/output parameters of each operator, on the number of variables appearing in the goal, and on the number of variables in any clause. We will refer to WSC tasks restricted in this way as WSC tasks with fixed arity.\nWe consider the problems of checking plans \u2013 testing whether or not a given action sequence is a plan \u2013 and of deciding plan existence. For the latter, we distinguish between polynomially bounded plan existence, and unbounded plan existence. We deem these to be particularly relevant decision problems in the context of plan generation. Certainly, plan checks are an integral part of plan gen-\neration. Indeed, if a planning tool is based on state space search, then the tool either performs such checks explicitly for (potentially many) plan candidates generated during search, or this complexity is inherent in the effort that underlies the computation of state transitions. Polynomially bounded plan existence is relevant because, in most commonly used planning benchmark domains, plans are of polynomial length (it is also a very wide-spread intuition in the SWS community that composed web services will not contain exceedingly large numbers of web services). Finally, unbounded plan existence is the most general decision problem involved, and thus is of generic interest.\nAll the problems turn out to be very hard. To prove this, we reuse and adapt various results from the literature. We start with the complexity of plan checking, for which hardness follows from a long established result (Eiter & Gottlob, 1992) regarding the complexity of belief update. For all the results, detailed proofs are available in Appendix A.\nTheorem 1 (Plan Checking inWSC) Assume a WSC task with fixed arity, and a sequence \u3008a1, . . . , an\u3009 of actions. It is \u03a0 p 2-complete to decide whether \u3008a1, . . . , an\u3009 is a plan.\nProof Sketch: Membership can be shown by a guess-and-check argument. Guess the proposition values along \u3008a1, . . . , an\u3009. Then check whether these values comply with res, and lead to an inconsistent action, or to a final state that does not satisfy the goal. \u3008a1, . . . , an\u3009 is a plan iff this is not the case for any guess of proposition values. Checking goal satisfaction is polynomial, checking compliance with res is in coNP, checking consistency is in NP. Hardness follows by a simple adaptation of the proof of Lemma 6.2 from Eiter and Gottlob (1992). That proof uses a reduction from checking validity of a QBF formula \u2200X.\u2203Y.\u03c8[X,Y ]. The lemma considers the case where a propositional belief \u03a6 is updated with an arbitrary (propositional) formula \u03c6, and the decision problem is to ask whether some other formula \u03a6\u2032 is implied by the updated belief. In the proof, \u03a6 is a complete conjunction of literals, i.e., \u03a6 corresponds to a single world state. \u03a6\u2032 is a single propositional fact r which is true in \u03a6. The semantics of \u2200X.\u2203Y.\u03c8[X,Y ] are encoded in a complicated construction defining the update \u03c6. In a nutshell, \u03c6 is a CNF telling us that for every assignment toX (which will yield a world state s\u2032 in the updated belief), we either have to find an assignment to Y so that \u03c8[X,Y ] holds (\u201ccompleting\u201d s\u2032), or we have to falsify r.\nThe difference in our setting lies in our very restricted \u201cupdate formulas\u201d \u2013 action effects \u2013 and in the fact that the integrity constraints are supposed to hold in every belief. We adapt the above proof by, first, taking the integrity constraints to be the clauses in Eiter and Gottlob\u2019s CNF formula \u03c6. We then modify the constraints so that they need only be true if a new fact t holds \u2013 i.e., we insert \u00act into every clause. The initial belief has t false, and otherwise corresponds exactly to \u03a6 as above. The only action of the plan makes t true. The goal is Eiter and Gottlob\u2019s fact r. 2\nWe remark that membership in Theorem 1 remains valid when allowing actions with multiple conditional effects, when allowing parallel actions, and even when allowing their combination. On the other hand, by virtue of the proof argument as outlined, hardness holds even if the initial state literals \u03c60 are complete (describe a single world state), the plan consists of a single action with a single positive effect literal, and the goal is a single propositional fact that is initially true.\nWe next consider polynomially bounded plan existence. For this, membership follows directly from Theorem 1. To prove hardness, we construct a planning task that extends Eiter and Gottlob\u2019s construction from above with actions that allow to choose a valuation for a third, existentially quantified, set of variables, and hence reduces validity checking of a QBF formula \u2203X.\u2200Y.\u2203Z.\u03c8[X,Y, Z].\nTheorem 2 (Polynomially Bounded Plan Existence in WSC) Assume aWSC task with fixed arity, and a natural number b in unary representation. It is \u03a3p3-complete to decide whether there exists a plan of length at most b.\nProof: For membership, guess a sequence of at most b actions. By Theorem 1, we can check with a \u03a0p2 oracle whether the sequence is a plan.\nFor hardness, validity of a QBF formula \u2203X.\u2200Y.\u2203Z.\u03c8[X,Y, Z], where \u03c8 is in CNF, is reduced to testing plan existence. SayX = {x1, . . . , xn}. In the planning task, there are n actions (operators with empty input/output parameters) oxi and o\u00acxi of which the former sets xi to true and the latter sets xi to false. Further, there is an action o t which corresponds to the action used in the hardness proof of Theorem 1. The actions are equipped with preconditions and effects ensuring that any plan must first apply, for all 1 \u2264 i \u2264 n, either oxi or o\u00acxi , and thereafter must apply ot (of course enforcing the latter also requires a new goal fact that can be achieved only by ot). Hence, choosing a plan candidate in this task is the same as choosing a value assignment aX for the variables X .\nIn our construction, after all the oxi and o\u00acxi actions have been executed, one ends up in a belief that contains a single world state, where the value assignment aX for the variables X corresponds to the chosen actions. This world state basically corresponds to the belief \u03a6 as in the hardness proof of Theorem 1. The only difference is that the construction has been extended to cater for the third set of variables. This is straightforward. Then, the belief that results from executing ot satisfies the goal iff Eiter and Gottlob\u2019s fact r holds in all its world states. By virtue of similar arguments to those of Eiter and Gottlob, the latter is the case iff \u2200Y.\u2203Z.\u03c8[aX/X, Y, Z], i.e., the substitution of \u2203X.\u2200Y.\u2203Z.\u03c8[X,Y, Z] with aX , is valid. From this, the claim follows. 2\nOur final result regards unbounded plan existence in WSC. The result is relatively easy to obtain from the generic reduction described by Bylander (1994) to prove PSPACE-hardness of plan existence in STRIPS. Somewhat shockingly, it turns out that plan existence inWSC is undecidable even without any integrity constraints, and with a complete initial state description. The source of undecidability is, of course, the ability to generate new constants on-the-fly.\nTheorem 3 (Unbounded Plan Existence in WSC) Assume a WSC task. The decision problem asking whether a plan exists is undecidable.\nProof Sketch: By a modification of the proof by Bylander (1994) that plan existence in propositional STRIPS planning is PSPACE-hard. The original proof proceeds by a generic reduction, constructing a STRIPS task for a Turing Machine with polynomially bounded space. The latter restriction is necessary to model the machine\u2019s tape: tape cells are pre-created for all positions within the bound. Exploiting the ability to create constants on-the-fly, we can instead introduce simple operators that allow to extend the tape, at both ends. 2\nNot being able to decide plan existence is, of course, a significant limitation in principle. However, this limitation is probably of marginal importance in practice, because most planning tools just assume that there is a plan, and they try to find it \u2013 rather than trying to prove that there is no plan. In that sense, most planning tools are, by their nature, semi-decision procedures anyway. What matters more than decidability in such a setting is the question whether one can find a plan\nquickly enough, i.e., before exhausting time or memory.11 This is also the most relevant question in web service composition."}, {"heading": "4. Forward Effects", "text": "The high complexity of planning in WSC motivates the search for interesting special cases. We define a special case, called forward effects, where every change an action makes to the state involves a newly generated constant.\nWe start the section by defining the forward effects case and making a core observation about its semantics. We then discuss the modeling power of this special case. Next, we discuss forward effects from a more general perspective of belief update. We analyze the main computational properties of forward effects, and we conclude the section with an assessment of how an existing planning tool could be adapted to handle forward effects.\n4.1 WSC|fwd and its Semantics\nThe forward effects special case of WSC is defined as follows.\nDefinition 1 Assume aWSC task (P,\u03a6IC ,O, C0, \u03c60, \u03c6G). The task has forward effects iff:\n1. For all o \u2208 O, and for all l[X] \u2208 effo, we have X \u2229 Yo 6= \u2205.\n2. For all clauses \u03c6 \u2208 \u03a6IC , where \u03c6 = \u2200x1, . . . , xk : l1[X1] \u2228 \u00b7 \u00b7 \u00b7 \u2228 ln[Xn], we have X1 = \u00b7 \u00b7 \u00b7 = Xn.\nThe set of all WSC tasks with forward effects is denoted with WSC|fwd.\nThe first condition says that the variables of every effect literal contain at least one output variable. This implies that every ground effect literal of an action contains at least one new constant. The second condition says that, within every integrity constraint, all literals share the same arguments. This implies that effects involving new constants can only affect literals involving new constants. Note that, since x1, . . . , xk are by definition exactly the variables occurring in any of the literals, for each Xi we have Xi = x1, . . . , xk. Note further that we may have k = 0, i.e., the literals in the clause may be ground. This is intentional. The constants mentioned in the clause must be taken from C0, cf. the discussion in Section 3.1. Therefore, such clauses have no interaction with statements about the new constants generated by aWSC|fwd action.\nWe will discuss the modeling power of WSC|fwd below (Section 4.2). First, we observe that the semantics of WSC|fwd is much simpler than that of general WSC. One no longer needs the notion of minimal change with respect to the previous state. To state this more precisely, assume a WSC task with predicates P . Say I \u2032 is an interpretation over PC \u2032\n, where C \u2032 is a set of constants. Say that C \u2286 C \u2032. We denote by I \u2032|C the restriction of I\n\u2032 to PC , i.e., the interpretation of PC that coincides with I \u2032 on all these propositions. Given a state s and an action a, we define:\nres|fwd(s, a) :=\n{\n{(C \u2032, I \u2032) | C \u2032 = Cs \u222a Ea, I \u2032|Cs = Is, I \u2032 |= \u03a6IC \u2227 effa} appl(s, a) {s} otherwise\n(7)\n11. Indeed the planning community is generally rather unconcerned by undecidability, cf. the numeric track of the inter-\nnational planning competitions, and Helmert\u2019s (2002) results on the decidability of numerical planning problems.\nCompare this to Equation (3), where I \u2032 is defined to be a member of update(s, C \u2032,\u03a6IC \u2227 effa), which returns all interpretations that satisfy \u03a6IC \u2227 effa and that differ minimally from Is. In Equation (7), I \u2032 is simply set to be identical to Is, on the constants (on the propositions over the constants) that existed beforehand. In other words, the set of new states we get is the cross-product of the old state with all satisfying assignments to \u03a6IC \u2227 effa.\nLemma 1 (Semantics of WSC|fwd) Assume a WSC|fwd task, a reachable state s, and an action a. Then res(s, a) = res|fwd(s, a).\nProof Sketch: InWSC|fwd, if s \u2032 differs minimally from s, then it follows that s\u2032 agrees totally with s, on the set of propositions PCs interpreted by s. To see this, denote as before with PCs+Ea the set of all propositions with arguments in Cs \u222aEa, and with at least one argument in Ea, and denote with \u03a6IC [Cs + Ea] the instantiation of \u03a6IC with all constants from Cs \u222a Ea, where in each clause at least one variable is instantiated from Ea. The key argument is that s\n\u2032 |= \u03a6IC \u2227 effa is equivalent to s\u2032 |= \u03a6IC [Cs \u222a Ea] \u2227 effa, which in turn is equivalent to s\n\u2032 |= \u03a6IC [Cs] \u2227 \u03a6IC [Cs + Ea] \u2227 effa. In the last formula, \u03a6IC [Cs] only uses the propositions P\nCs , whereas \u03a6IC [Cs + Ea] \u2227 effa only uses the propositions PCs+Ea . Since s is reachable, we have s |= \u03a6IC [Cs]. Therefore, to satisfy \u03a6IC \u2227 effa, there is no need to change any of the values assigned by s. 2"}, {"heading": "4.2 Modeling Power", "text": "Intuitively, WSC|fwd covers the situation where a web service outputs some new constants, sets their characteristic properties relative to the inputs, and relies on the ontology axioms to describe any ramifications concerning the new constants. As was detailed in Section 2, this closely corresponds to the various notions of message-based WSC explored in the literature. In that sense, the modeling power of WSC|fwd is comparable to that of message-based WSC, one of the most-widespread approaches in the area.\nA simple concrete way of assessing the modeling power ofWSC|fwd is to consider the allowed and disallowed axioms. Examples of axioms that are not allowed byWSC|fwd are: attribute domain restrictions, taking the form \u2200x, y : \u00acG(x, y) \u2228H(x); attribute range restrictions, taking the form \u2200x, y : \u00acG(x, y)\u2228H(y); and relation transitivity, taking the form \u2200x, y, z : \u00acG(x, y)\u2228\u00acG(y, z)\u2228 G(x, z). Note that, for all these axioms, it is easy to construct a case where an action effect, even though it involves a new constant, affects the \u201cold belief\u201d. For example, if constants c and e existed beforehand, and an action outputs d and sets G(c, d) \u2227G(d, e), then the axiom \u2200x, y : \u00acG(x, y) \u2228 \u00acG(y, z) \u2228G(x, z) infers that G(c, e) \u2013 a statement that does not involve the new constant d.\nTypical ontology axioms that are allowed by WSC|fwd are: subsumption relations, taking the form \u2200x : \u00acG(x) \u2228 H(y); mutual exclusion, taking the form \u2200x : \u00acG(x) \u2228 \u00acH(y); relation reflexivity, taking the form \u2200x : \u00acG(x, x); and relation symmetry, taking the form \u2200x, y : \u00acG(x, y) \u2228 G(y, x). We can also express that a concept G is contained in the union of concepts H1, . . . , Hn, and more generally we can express any complex dependencies between concepts, taking the form of clausal constraints on the allowed combinations of concept memberships.\nOne example where complex dependencies are important is the domain of proteins as illustrated in Example 1. Capturing the dependencies is important here in order to be able to select the correct web services. Similar situations arise in many domains that involve complex interdependencies and/or complex regulations. An example for the latter is the Virtual Travel Agency which we discussed before. For example, in the German rail system there are all kinds of regulations regarding\nwhich train may be booked with which kind of discount under which conditions. Modeling these regulations would enable a WSC algorithm to select the appropriate booking services. Another interesting case is the hospital domain described by de Jonge, van der Linden, and Willems (2007). There, the problem of hospital asset tracking is handled by means of a set of tracking, logging and filter services, which transform logs to extract various kinds of information. In this setting, it would make sense to model complex dependencies so that the web service composer may determine which hospital assets need to be tracked and retrieved. Namely, the latter depends on the type of operation in question, and on the kind of examinations which that operation requires. Accordingly, what we need to model is a categorization of operations, their mapping to sets of required examinations, and how those examinations are associated with hospital assets. Further complications arise since the required examinations/assets may depend on particular circumstances. Clearly, we can express the categorization and dependencies in terms of clauses. While this of course captures only a fraction of what is relevant in a hospital, it is considerably more informed than a composer which always just tracks all the assets.\nThe main weakness of WSC|fwd is that it does not allow us to express changes regarding preexisting objects. This is best illustrated when considering the case of negative effects.12 In the planning community, these are commonly used to model how previous properties of objects are invalidated by an action. For illustration, reconsider Example 1. Say there is an additional operator dropCoffeeIn3Dmachine, with effect \u00acInfo3D(y). One would normally expect that, when this operator is applied, the fact Info3D(y) is deleted and must be re-established. This is not so in WSC|fwd. According to the restrictions this special case imposes, the variable y in \u00acInfo3D(y) must be an output of dropCoffeeIn3Dmachine. That is, dropping coffee into the machine creates a new object, whose characteristic property happens to be \u00acInfo3D(y) rather than Info3D(y). Clearly, this is not the intended semantics of the operator.\nTo model the intended semantics, we would need to instantiate y with a pre-existing constant. Say that, as in belief b3 in Example 1, a constant e with Info3D(e) was previously created by getInfo3D1n55(c, e). Then WSC|fwd does allow us to instantiate dropCoffeeIn3Dmachine with e, so that we have the effect \u00acInfo3D(e). However, by virtue of the definition of action applicability, that action will be applicable only in states where e does not yet exist \u2013 corresponding to execution paths where getInfo3D1n55(c, e) was not executed. Hence the property Info3D(e) does not get deleted from any state, and e as used by dropCoffeeIn3Dmachine is still regarded as a newly created object whose characteristic property is \u00acInfo3D(y). The only difference the new action makes is that, now, the plan uses the same name (e) to refer to two different information objects (output of getInfo3D1n55(c, e) vs. output of dropCoffeeIn3Dmachine) that do not play the same role in the plan, cf. the discussion in Section 3.2.\nAn interesting workaround is to let the operators output \u201ctime steps\u201d, in a spirit reminiscent of the situation calculus (McCarthy & Hayes, 1969; Reiter, 1991). Every operator obtains an extra output variable t, which is included into every effect literal. The new time step t is stated to stand in some relation to the previous time steps, e.g., next(tprev, t) where tprev is an input variable instantiated to the previous time step. In such a setting, we can state how the world changes over time. In particular we can state that some object property is different in t than in tprev. For example, if an action moves a file f from \u201cRAEDME\u201d to \u201cREADME\u201d then we could state that name(f,\u201cRAEDME\u201d, tprev) and name(f,\u201cREADME\u201d, t). The problem with such a construction\n12. Or, inWSC, positive effects triggering negative effects via \u03a6IC , cf. Proposition 1.\nis that the time steps have no special interpretation, they are just ordinary objects.13 This causes at least two difficulties. (1) If we want to refer to an object property, we have to know the time step in the first place \u2013 that is, we have to know whether the actual time step is t or tprev. Note here that we cannot maintain a predicate actualTime(x) because this would require us to invalidate a property of tprev. (2) There is no solution to the frame problem. The operators must explicitly state every relevant property of the previous time step, and how each property is changed in the new time step.14\nTo conclude this sub-section, let us consider how WSC|fwd can be generalized without losing Lemma 1. Most importantly, instead of requiring that every effect literal involves a new constant, one can postulate this only for literals that may actually be affected by the integrity constraints. In particular, if a predicate does not appear in any of the clauses, then certainly an effect literal on that predicate is not harmful even if it does not involve an output constant. One obtains a potentially stronger notion by considering ground literals, rather than predicates. Note that this kind of generalization solves difficulty (1) of the time-step construction, presuming that time steps are not constrained by the clauses. (The frame problem, however, persists.)\nAnother possibility, deviating somewhat from the way WSC and WSC|fwd are currently defined, is to define the integrity constraints in terms of logic programming style rules, along the lines of Eiter et al. (2003, 2004). The requirement on WSC|fwd can then be relaxed to postulate that the effect literals without new constants do not appear in the rule heads.\nWe remark that the latter observation suggests a certain strategic similarity with the aforementioned derived predicates (Thie\u0301baux et al., 2005) previously used in AI Planning to manage the complexity of integrity constraints. There, the integrity constraints take the form of stratified logic programming style derivation rules, and the predicates appearing in rule heads are not allowed to appear in operator effects. This is an overly restricted solution, in the WSC context. The effects of web services are indeed very likely to affect concepts and relations appearing in the ontology axioms. They may do so inWSC|fwd, as long as output constants are involved."}, {"heading": "4.3 Belief Update", "text": "Lemma 1 is specific to the possible models approach (Winslett, 1988) that underlies our semantics of action applications. It is interesting to consider the semantics of WSC|fwd from a more general perspective of belief update. Recall that such an update involves a formula characterizing the current belief, and a formula describing the update. We seek a formula that characterizes the updated belief.\nA wide variety of definitions has been proposed as to how the updated belief should be defined. However, some common ground exists. Katzuno and Mendelzon (1991) suggest eight postulates, named (U1) . . . (U8), which every sensible belief update operation should satisfy. Herzig and Rifi (1999) discuss in detail to what degree the postulates are satisfied by a wide range of alternative belief update operators. In particular they call a postulate \u201cuncontroversial\u201d if all update operators under investigation satisfy them. We will take up these results in the following. We examine to what extent we can draw conclusions about the updated belief, \u03a6\u2032, in the setting of the forward effects case, when relying only on Herzig and Rifi\u2019s \u201cuncontroversial postulates\u201d.\n13. Note that here the similarity to the situation calculus ends. Whereas time steps are assigned a specific role in the\nformulas used in the situation calculus, here they are just ordinary objects handled by actions, as if they were packages or blocks. 14. Despite these difficulties, Theorem 6 below shows that a time step construction can be used to simulate an Abacus\nmachine, and hence to prove undecidability of plan existence in WSC|fwd.\nWe assume that a planning task with predicates P is given. We need the following notations:\n\u2022 If \u03a6 and \u03c6 are formulas, then \u03a6 \u25e6 \u03c6 denotes the formula that results from updating the belief \u03a6 with the update \u03c6, under some semantics for the belief update operator \u25e6.\n\u2022 Given disjoint sets of constants C and E, PC+E denotes the set of all propositions formed from predicates in P , where all arguments are contained in C \u222aE and there exists at least one argument contained in E. (Recall that PC denotes the set of all propositions formed from predicates in P and arguments from C.)\n\u2022 Given a set of constants C, \u03a6IC [C] denotes the instantiation of \u03a6IC with C. That is, \u03a6IC [C] is the conjunction of all clauses that result from replacing the variables of a clause \u03c6 \u2208 \u03a6IC , \u03c6 = \u2200x1, . . . , xk : l1[X1] \u2228 \u00b7 \u00b7 \u00b7 \u2228 ln[Xn], with a tuple (c1, . . . , ck) of constants in C.\n\u2022 Given disjoint sets of constants C and E, \u03a6IC [C + E] is the conjunction of all clauses that result from replacing the variables of a clause \u03c6 \u2208 \u03a6IC , \u03c6 = \u2200x1, . . . , xk : l1[X1] \u2228 \u00b7 \u00b7 \u00b7 \u2228 ln[Xn], with a tuple (c1, . . . , ck) of constants in C \u222a E, where at least one constant is taken from E.15\n\u2022 If \u03c8 is a ground formula then by P (\u03c8) we denote the set of propositions occurring in \u03c8.\nWe will denote the current belief by \u03a6 and the update by \u03c6. As another convention, given a set of constants C, by writing \u03c8C we indicate that P (\u03c8) \u2286 PC . Similarly, given disjoint sets of constants C and E, by writing \u03c8C+E we indicate that P (\u03c8) \u2286 PC+E . If s is a state, then by \u03c8s we denote the conjunction of literals satisfied by s.\nWe first consider the case where, similar to the claim of Lemma 1, \u03a6 corresponds to a single concrete world state s. We want to apply an action a. We wish to characterize the set of states res(s, a), i.e., we wish to construct the formula \u03a6 \u25e6 \u03c6. For simplicity of notation, denote C := Cs and E := Ea. If a is not applicable to s, there is nothing to do. Otherwise, we have that:\n(I) \u03a6 \u2261 \u03a6IC [C] \u2227 \u03c8 C where P (\u03c8C) \u2286 PC .\nFor example, we can set \u03c8C := \u03c8s. Since s |= \u03a6IC , we get the desired equivalence. Further, we have that:\n(IIa) \u03c6 \u2261 \u03a6IC [C] \u2227 \u03a6IC [C + E] \u2227 effa;\n(IIb) P (\u03a6IC [C + E]) \u2286 P C+E and P (effa) \u2286 P C+E .\n(IIa) holds trivially: \u03c6 is defined as \u03a6IC \u2227 effa, which is equivalent to \u03a6IC [C \u222a E] \u2227 effa which is equivalent to \u03a6IC [C]\u2227\u03a6IC [C+E]\u2227 effa. As for (IIb), this is a consequence of the forward effects case. Every effect literal contains at least one output constant, hence effa contains only propositions from PC+E . For \u03a6IC [C + E], we have that at least one variable in each clause is instantiated with a constant e \u2208 E. Since, by definition, all literals in the clause share the same variables, e appears in every literal and therefore \u03a6IC [C + E] contains only propositions from P C+E .\nAs an illustration, consider our simple VTA example. There are four predicates, train(x), ticket(x), trainTicket(x), and ticketFor(x, y). The set of integrity constraints \u03a6IC consists of\n15. If no clause in \u03a6IC contains any variable, then \u03a6IC [C + E] is empty. As is customary, an empty conjunction is taken to be true, i.e., 1.\nthe single axiom \u2200x : trainTicket(x) \u21d2 ticket(x). In our current state s, we have Cs = {c}, and Is sets all propositions to 0 except for train(c). We consider the application of the action a = bookTicket(c, d), whose precondition is train(c), whose set E of output constants is {d}, and whose effect effa is trainTicket(d) \u2227 ticketFor(d, c). In this setting, we have: \u03a6IC [C] = (trainTicket(c) \u21d2 ticket(c)); \u03c8C = (train(c)\u2227\u00acticket(c)\u2227\u00actrainTicket(c)\u2227\u00acticketFor(c, c)); and \u03a6IC [C + E] = (trainTicket(d) \u21d2 ticket(d)).\nWe will derive in the following that:\n(III) \u03a6 \u25e6 \u03c6 \u2261 (\u03a6IC [C] \u2227 \u03c8 C) \u2227 (\u03a6IC [C + E] \u2227 effa).\nThat is, we can characterize the updated belief simply by the conjunction of the previous belief with the action effect and the extended instantiation of the ontology axioms. This corresponds exactly to Lemma 1. To illustrate, we will continue the VTA example. The left hand side of (III) refers to the four propositions based only on c, and sets them according to s. The right hand side refers to propositions based only on d \u2013 trainTicket(d) and ticket(d) \u2013 as well as the proposition ticketFor(d, c) which links c and d.\nAs one prerequisite of our derivation of (III), we have to make an assumption which, to the best\nof our knowledge, is not discussed anywhere in the belief update literature:\n(IV) Let \u03c81, \u03c8 \u2032 1, \u03c82, \u03c8 \u2032 2 be formulas where P (\u03c81) \u2229 P (\u03c8 \u2032 1) = \u2205, P (\u03c81) \u2229 P (\u03c8 \u2032 2) = \u2205, P (\u03c82) \u2229\nP (\u03c8\u20321) = \u2205, and P (\u03c82) \u2229 P (\u03c8 \u2032 2) = \u2205. Then (\u03c81 \u2227 \u03c8 \u2032 1) \u25e6 (\u03c82 \u2227 \u03c8 \u2032 2) \u2261 (\u03c81 \u25e6 \u03c82) \u2227 (\u03c8 \u2032 1 \u25e6 \u03c8 \u2032 2).\nThis assumption postulates that formulas talking about disjoint sets of variables can be updated separately. Since formulas with disjoint variables essentially speak about different aspects of the world, this seems a reasonable assumption.\nNow, we start from the formula \u03a6\u25e6\u03c6. We make replacements according to (I) and (IIa), leading to the equivalent formula (\u03a6IC [C] \u2227 \u03c8\nC) \u25e6 (\u03a6IC [C] \u2227 \u03a6IC [C + E] \u2227 effa). We can map this formula onto (IV) by taking \u03c81 to be \u03a6IC [C] \u2227 \u03c8 C , \u03c8\u20321 to be 1, \u03c82 to be \u03a6IC [C], and \u03c8 \u2032 2 to be \u03a6IC [C + E] \u2227 effa. Hence, we can separate our update into two parts as follows:\n(A) (\u03a6 \u25e6 \u03c6)C := (\u03a6IC [C] \u2227 \u03c8 C) \u25e6 \u03a6IC [C]\n(B) (\u03a6 \u25e6 \u03c6)C+E := 1 \u25e6 (\u03a6IC [C + E] \u2227 effa)\nAccording to (IV), we then obtain our desired formula \u03a6 \u25e6 \u03c6 by \u03a6 \u25e6 \u03c6 \u2261 (\u03a6 \u25e6 \u03c6)C \u2227 (\u03a6 \u25e6 \u03c6)C+E . Illustrating this with the VTA example, we simply separate the parts of the update that talk only about c from those that talk only about d or the combination of both constants. The (A) part of the update is trainTicket(c) \u21d2 ticket(c) conjoined with \u03c8s, updated with trainTicket(c) \u21d2 ticket(c). The (B) part of the update is 1 \u2013 representing the (empty) statement that the previous state smakes about d \u2013 updated with (trainTicket(d) \u21d2 ticket(d))\u2227 trainTicket(d)\u2227 ticketFor(d, c).\nIt remains to examine (\u03a6 \u25e6 \u03c6)C and (\u03a6 \u25e6 \u03c6)C+E . We need to prove that:\n(C) (\u03a6 \u25e6 \u03c6)C \u2261 \u03a6IC [C] \u2227 \u03c8 C , and\n(D) (\u03a6 \u25e6 \u03c6)C+E \u2261 \u03a6IC [C + E] \u2227 effa.\nEssentially, this means to prove that: (C) updating a formula with something it already implies does not incur any changes; (D) updating 1 with some formula yields a belief equivalent to that formula. To see this, compare (A) with (C) and (B) with (D).\nWhile these two statements may sound quite trivial, it is in fact far from trivial to prove them for the wide variety of, partly rather complex, belief update operations in the literature. Here we build on the works by Katzuno and Mendelzon (1991) and Herzig and Rifi (1999). We need two of the postulates made by Katzuno and Mendelzon (1991), namely:\n(U1) For any \u03c81 and \u03c82: (\u03c81 \u25e6 \u03c82) \u21d2 \u03c82.\n(U2) For any \u03c81 and \u03c82: if \u03c81 \u21d2 \u03c82 then (\u03c81 \u25e6 \u03c82) \u2261 \u03c81.\nHerzig and Rifi (1999) prove that (U1) is \u201cuncontroversial\u201d, meaning it is satisfied by all belief update operators they investigated (cf. above). They also prove that (U2) is equivalent to the conjunction of two weaker statements, of which only one is uncontroversial, namely:\n(U2a) For any \u03c81 and \u03c82: (\u03c81 \u2227 \u03c82) \u21d2 (\u03c81 \u25e6 \u03c82).\nThe other statement is not uncontroversial. However, it is proved to be satisfied by all non-causal update operators under investigation, except the so-called Winslett\u2019s standard semantics (Winslett, 1990). The latter semantics is not useful in our context anyway. The only restriction it makes on the states in res(s, a) is that they differ from s only on the propositions mentioned in the update formula. In our case, these include all propositions appearing in \u03a6IC [C \u222aE], which is bound to be quite a lot. So, if we were to use Winslett\u2019s standard semantics, then res(s, a) would be likely to retain hardly any information from s.\nConsider now the formula (\u03a6 \u25e6 \u03c6)C as specified in (A), (\u03a6 \u25e6 \u03c6)C = (\u03a6IC [C] \u2227 \u03c8 C) \u25e6 \u03a6IC [C]. We will now prove (C). This is indeed quite simple. We have that (\u03a6IC [C] \u2227 \u03c8 C) \u21d2 \u03a6IC [C], so we can instantiate \u03c81 in (U2) with \u03a6IC [C] \u2227 \u03c8 C , and \u03c82 in (U2) with \u03a6IC [C]. We obtain (\u03a6IC [C] \u2227 \u03c8 C) \u25e6 \u03a6IC \u2261 \u03a6IC [C] \u2227 \u03c8 C , and hence (\u03a6 \u25e6 \u03c6)C \u2261 \u03a6IC [C] \u2227 \u03c8 C as desired. With what was said above, this result is not uncontroversial, but holds for all non-causal update operators (except Winslett\u2019s standard semantics) investigated by Herzig and Rifi (1999). In terms of the VTA example, (U2) allowed us to conclude that the update trainTicket(c) \u21d2 ticket(c) does not make any change to the previous belief, which already contains that property.\nNext, consider the formula (\u03a6\u25e6\u03c6)C+E as specified in (B), (\u03a6\u25e6\u03c6)C+E = 1\u25e6(\u03a6IC [C+E]\u2227effa). We now prove (D). By postulate (U1), we get that (\u03a6 \u25e6 \u03c6)C+E \u21d2 \u03a6IC [C + E] \u2227 effa, because \u03a6IC [C+E]\u2227effa is the update formula \u03c82. For the other direction, we exploit (U2a). We instantiate \u03c81 in (U2a) with 1, and get that 1\u2227 (\u03a6IC [C +E]\u2227 effa) \u21d2 1 \u25e6 (\u03a6IC [C +E]\u2227 effa), which is the same as 1 \u2227 (\u03a6IC [C + E] \u2227 effa) \u21d2 (\u03a6 \u25e6 \u03c6)\nC+E , which is equivalent to \u03a6IC [C + E] \u2227 effa \u21d2 (\u03a6 \u25e6\u03c6)C+E . This proves the claim. Note that we have used only postulates that are uncontroversial according to Herzig and Rifi (1999). Reconsidering the VTA example, we have\u03a6IC [C+E]\u2227effa = (trainTicket(d) \u21d2 ticket(d))\u2227 trainTicket(d)\u2227 ticketFor(d, c). The previous state does not say anything about these propositions, and is thus represented as 1. The postulates allow us to conclude that (for all belief update operators investigated by Herzig & Rifi, 1999) the resulting belief will be equivalent to (trainTicket(d) \u21d2 ticket(d)) \u2227 trainTicket(d) \u2227 ticketFor(d, c). So far, we were restricted to the case where \u03a6, the belief to be updated, corresponds to a single world state s. Consider now the more general case where \u03a6 characterizes a belief b, and we want to characterize the set of states res(b, a). At first glance, it seems that not much changes, because Katzuno and Mendelzon (1991) also make this following postulate:\n(U8) For any \u03c81, \u03c82, and \u03c8: (\u03c81 \u2228 \u03c82) \u25e6 \u03c8 \u2261 (\u03c81 \u25e6 \u03c8) \u2228 (\u03c82 \u25e6 \u03c8).\nThis means that, if \u03a6 consists of two alternate parts, then updating \u03a6 is the same as taking the union of the updated parts. In other words, we can compute the update on a state-by-state basis. The statement (I) from above is still true, it\u2019s just that now \u03c8C is the disjunction over \u03c8s for all states s \u2208 b, rather than only the single \u03c8s. The rest of the argumentation stays exactly the same. Herzig and Rifi (1999) prove that (U8) is uncontroversial and leave it at that.\nHowever, matters are not that simple. The source of complications is our use of a partial matches/conditional effects semantics. The update formula \u03c6 is different for the individual states s \u2208 b. Hence we cannot directly apply (U8). Obviously, states s1 \u2208 b where a is applicable are updated differently from states s2 \u2208 b where a is not applicable \u2013 the latter are not updated at all. 16 A somewhat more subtle distinction between states in b is which constants exist in them: for different sets of constants, the integrity constraints in the update are different. Hence, to obtain a \u201cgeneric\u201d update of \u03a6, we have to split \u03a6 into equivalence classes \u03a61, . . . ,\u03a6n where the states within each \u03a6i cannot be distinguished based on prea and based on the existing constants. Then, (U8) and the argumentation from above can be used to show the equivalent of (III) for each \u03a6\u2032i. The last step, defining the final \u03a6 \u25e6 \u03c6 to be the disjunction of the individual \u03a6i \u25e6 \u03c6i, appears sensible. But it does not follow immediately from Katzuno and Mendelzon (1991).\nFor illustration, consider a variant of the VTA example where we have two preceding states, one state s where we have train(c) as before, and a new state s\u2032 where we have ticket(c) instead. In s\u2032, bookTicket(c, d) is not applicable, and hence the update is different for s and s\u2032. The s part is as above, yielding the result \u03c8s \u2227 (trainTicket(d) \u21d2 ticket(d)) \u2227 trainTicket(d) \u2227 ticketFor(d, c). The update to s\u2032 is trivial, and yields \u03c8s\u2032 as its result. The final outcome is the disjunction of these two beliefs.\nWe point out that the situation is much easier if we consider plug-in matches (i.e., forced preconditions) instead of partial matches. There, a is applicable to all states, and it is also easy to see that every state in b has the same constants. Therefore, for plug-in matches, (III) follows immediately with (U8). In the above VTA example, an update would not be computed at all since bookTicket(c, d) would not be considered to be applicable to the preceding belief. If s\u2032 satisfies train(c) but disagrees in some other aspect, e.g. (quite nonsensically) that also ticket(c) holds, then the updated belief is equivalent to (\u03c8s \u2228 \u03c8s\u2032) \u2227 (trainTicket(d) \u21d2 ticket(d)) \u2227 trainTicket(d) \u2227 ticketFor(d, c)."}, {"heading": "4.4 Computational Properties", "text": "Paralleling our analysis for general WSC from Section 3.3, we now perform a brief complexity analysis of the WSC|fwd special case. As before, we consider the \u201cpropositional\u201d case which assumes a fixed upper bound on the arity of predicates, on the number of input/output parameters of each operator, on the number of variables appearing in the goal, and on the number of variables in any clause. Also as before, we consider the decision problems of checking plans, of deciding polynomially bounded plan existence, and of deciding unbounded plan existence, in that order.\nIn contrast to before, we cannot reuse results from the literature as much because, of course, the particular circumstances ofWSC|fwd have not been investigated before. We include proof sketches here, and refer to Appendix A for the detailed proofs.\n16. One might speculate that the common update would be prea \u21d2 \u03c6, but that is not the case. For example, under the possible models approach that we adopt in WSC, updating s where s |= prea with prea \u21d2 \u03c6 gives rise to result states that change s to violate prea instead of changing it to satisfy \u03c6.\nThanks to the simpler semantics as per Lemma 1, plan checking is much easier in WSC|fwd than inWSC.\nTheorem 4 (Plan Checking inWSC|fwd) Assume a WSC|fwd task with fixed arity, and a sequence \u3008a1, . . . , an\u3009 of actions. It is coNP-complete to decide whether \u3008a1, . . . , an\u3009 is a plan.\nProof Sketch: Hardness is obvious, considering an empty sequence. Membership can be shown by a guess-and-check argument. Say C is the union of C0 and all output constants appearing in \u3008a1, . . . , an\u3009. We guess an interpretation I of all propositions over P and C. Further, for each 1 \u2264 t \u2264 n, we guess a set Ct of constants. I needs not be time-stamped because, once an action has generated its outputs, the properties of the respective propositions remain fixed forever. Thanks to Lemma 1, we can check in polynomial time whether (a) I and the Ct correspond to an execution of \u3008a1, . . . , an\u3009. Also, we can check in polynomial time whether (b) I and Cn satisfy \u03c6G. \u3008a1, . . . , an\u3009 is a plan iff there is no guess where the answer to (a) is \u201cyes\u201d and the answer to (b) is \u201cno\u201d. 2\nMembership in Theorem 4 remains valid when allowing parallel actions and multiple conditional effects \u2013 provided one imposes restrictions ensuring that the effects/actions applied simultaneously (in one step) can never be self-contradictory. Otherwise, checking plans also involves a consistency test for each plan step, which is an NP-complete problem. Note that it is quite reasonable to demand that simultaneous actions/effects do not contradict each other. Widely used restrictions imposed to ensure this are mutually exclusive effect conditions, and/or non-conflicting sets of effect literals.\nWe next consider polynomially bounded plan existence. Membership follows directly from Theorem 4. To prove hardness, we reduce from validity checking of a QBF formula \u2203X.\u2200Y.\u03c6[X,Y ]. The constructed planning task allows to choose values for X , and thereafter to apply actions evaluating \u03c6 for arbitrary values of Y . The goal is accomplished iff a setting for X exists that works for all Y .\nTheorem 5 (Polynomially Bounded Plan Existence in WSC|fwd) Assume aWSC|fwd task with fixed arity, and a natural number b in unary representation. It is \u03a3p2-complete to decide whether there exists a plan of length at most b.\nProof Sketch: For membership, guess a sequence of at most b actions. By Theorem 4, we can check with an NP oracle whether the sequence is a plan.\nHardness can be proved by reduction from validity checking of a QBF formula \u2203X.\u2200Y.\u03c6[X,Y ] where \u03c6 is in DNF normal form, i.e., \u03c6 =\n\u2228k j=1 \u03c6j . The key idea is to use outputs for the creation\nof \u201ctime steps\u201d, and hence ensure that the operators adhere to the restrictions of WSC|fwd. Setting xi is allowed only at time step i. That is, for each xi we have operators o\nxi1 and oxi0. These take as input a set of time steps {t0, . . . , ti\u22121} which are required to be successive, by the precondition start(t0)\u2227 next(t0, t1) \u2227 \u00b7 \u00b7 \u00b7 \u2227 next(ti\u22122, ti\u22121). They output a new time step ti which they attach as a successor of ti\u22121, and they set xi to 1 and 0, respectively, at time step i. That is, they have an effect literal of the form xi(ti) and \u00acxi(ti), respectively. The rest of the planning task consists of: operators ot that allow extending a sequence of time steps until step B, for a suitable value B (see below); and of operators o\u03c6j which allow achieving the goal, given \u03c6j is true at the end of a time step sequence of length B. There are no integrity constraints (\u03a6IC is empty). The values of the yi are not specified, i.e., those variables can take on any value in the initial belief.\nIf \u2203X.\u2200Y.\u03c6[X,Y ] is valid then obviously one can construct a plan for the task simply by setting the xi accordingly, using the o\nt for stepping on to timeB, and applying all the o\u03c6j . What necessitates our complicated construction is the other direction of the proof: namely, the plan may cheat by setting a xi to both 1 and 0. The construction ensures that this is costly, because such a plan is forced to maintain two parallel sequences of time steps, starting from the faulty xi. We can choose a sufficiently large value forB, together with a sufficiently small plan length bound b, so that cheating is not possible. 2\nOur final result regards unbounded plan existence. Somewhat surprisingly, it turns out that this is still undecidable in WSC|fwd. Similar to the above, the key idea again is to let actions output a new \u201ctime step\u201d, thereby ensuring membership of the constructed task in WSC|fwd.\nTheorem 6 (Unbounded Plan Existence in WSC|fwd) Assume a WSC|fwd task. The decision problem asking whether a plan exists is undecidable.\nProof Sketch: By reduction from the halting problem for Abacus machines, which is undecidable. An Abacus machine consists of a tuple of integer variables v1, . . . , vk (ranging over all positive integers including 0), and a tuple of instructions I1, . . . , In. A state is given by the content of v1, . . . , vk plus the index pc of the active instruction. The machine stops iff it reaches a state where pc = n. All vi are initially 0, and pc is initially 0. The instructions either increment a variable and jump to another instruction, or they decrement a variable and jump to different instructions depending on whether or not the variable was already 0. It is not difficult to encode an Abacus machine as a WSC|fwd task. The two key ideas are: (1) design an operator that \u201coutputs\u201d the next successor to an integer; (2) design operators simulating the instructions, by stepping to successors or predecessors of integer values. In the latter kind of operators, membership in WSC|fwd is ensured by letting the operators output a new \u201ctime step\u201d to which the new variable values are associated. The goal asks for the existence of a time step where the active instruction is In. 2\nAs argued at the end of Section 3.3 already, we don\u2019t deem undecidability of unbounded plan existence a critical issue in practice. Most planning tools are by nature semi-decision procedures, anyway. In particular, web service composition is typically expected to occur in a real-time setting, where severe time-outs apply."}, {"heading": "4.5 Issues in Adapting CFF", "text": "In our view, the most crucial observation about WSC|fwd is that we can now test plans in coNP, rather than in\u03a0p2 as for generalWSC. Standard notions of planning under uncertainty have the same complexity of plan testing, and research has already resulted in a sizable number of approaches and (comparatively) scalable tools (Cimatti et al., 2004; Bryce et al., 2006; Hoffmann & Brafman, 2006; Palacios & Geffner, 2007). We will show in the next section that, under certain additional restrictions onWSC|fwd, these tools can be applied off-the-shelf. Regarding generalWSC|fwd, the match in the complexity of plan testing suggests that the underlying techniques can be successfully adapted. In the following, we consider in some detail the CFF tool (Hoffmann & Brafman, 2006). Other promising options would be to extend MBP (Cimatti et al., 2004) or POND (Bryce et al., 2006), or to look into the compilation techniques investigated by Palacios and Geffner (2007).\nCFF can be characterized as follows:\n(1) Search is performed forward in the space of action sequences.\n(2) For each sequence a\u0304, a CNF formula \u03c6(a\u0304) is generated that encodes the semantics of a\u0304, and SAT reasoning over \u03c6(a\u0304) checks whether a\u0304 is a plan.\n(3) Some reasoning results \u2013 namely the literals that are always true after executing a\u0304 \u2013 are cached to speed up future tests.\n(4) Search is guided by an adaptation of FF\u2019s (Hoffmann & Nebel, 2001) relaxed plan heuristic.\n(5) Relaxed planning makes use of a strengthened variant of the CNF formulas \u03c6(a\u0304) used for reasoning about action sequences, where most of the clauses are projected onto only 2 of\ntheir literals (i.e., all but 2 of the literals are removed from each respective clause).\nAll of these techniques should be self-explanatory, except possibly the last one. Projecting the CNF formulas ensures that the relaxed planning remains an over-approximation of the \u201creal\u201d planning, because the projected formulas allow us to draw more conclusions. At the same time, the projected formulas can be handled sufficiently runtime-efficiently.17 The method for 2-projecting \u201cmost\u201d of the clauses is, in a nutshell, to ignore all but one of the condition literals of each conditional effect in the relaxed planning graph.\nIt is fairly obvious that the basic answers given by CFF, i.e., the techniques (1) \u2013 (5), also apply in WSC|fwd. Note that, indeed, the main enabling factor here is that we can check plans in coNP, rather than in \u03a0p2 as for general WSC. This enables us to design the desired CNF formulas \u03c6(a\u0304) in a straightforward fashion. If plan checking is \u03a0p2-hard, then we either need to replace the CNF formulas with QBF formulas, or we have to create worst-case exponentially large CNF formulas. Both are, at the least, technically quite challenging.\nThe adaptation of CFF toWSC|fwd is of more immediate promise, but is not trivial. It involves technical challenges regarding the on-the-fly creation of constants as well as the computation of the heuristic function. The latter also brings significant new opportunities in the WSC context, pertaining to the exploitation of typical forms of ontology axioms. Let us consider these issues in a little detail.\nFirst, like most of today\u2019s planning tools, CFF pre-instantiates PDDL into a purely propositional representation, based on which the core planning algorithms are implemented. If one allows on-thefly creation of constants, then pre-instantiation is no longer possible, and hence the adaptation to WSC|fwd involves re-implementing the entire tool. While this is a challenge in itself, there are more difficult obstacles to overcome. A sloppy formulation of the key question is: How many constants should we create? One can, of course, create a new tuple of constants for (the outputs of) each and every new action application. However, it seems likely that such an approach would blow up the representation size very quickly, and would hence be infeasible. So one should instead share output constants where reasonable. But how does one recognize the \u201creasonable\u201d points? This issue is especially urgent inside the heuristic function. Namely, it is easy to see that, in the worst case, the relaxed planning graph grows exponentially in the number of layers. Just imagine an example where web service w1 takes an input of type A and generates an output of type B, whereas w2 takes an input of type B and generates an output of type A. Starting with one constant of type A and one of type B, we get 2 constants of each type in the next graph layer. Then, each of w1 and w2\n17. Inside the heuristic function, the formulas come from relaxed planning graphs which can be quite big. So handling\nthem without further approximations seems hopeless. This is discussed in detail by Hoffmann and Brafman (2006).\ncan be applied two times, and we get 4 constants of each type in the next graph layer, and so forth. This dilemma probably cannot be handled without making further approximations in the relaxed planning graph.\nOne a more positive note, it seems possible to exploit the most typical structures of ontologies in practice. In particular, most practical ontologies make extensive use of subsumption relations, structuring the domain of interest into a concept hierarchy. Additional ontology axioms often come in the form of constraints on relations (reflexivity, symmetry, transitivity) or on the typing or number of relation arguments. It may make sense to exploit some of these structures for optimizing the formulas \u03c6(a\u0304) and the associated SAT reasoning. Certainly, it makes sense to exploit these structures inside the heuristic function. One can include specialized analysis and sub-solver techniques that recognize these structures and solve them separately in order to obtain more precise relaxed plans. One can even try to take into account only these structures inside the relaxed planning, and hence (potentially) obtain a very fast heuristic function."}, {"heading": "5. Compilation to Initial State Uncertainty", "text": "We now show that, under certain additional restrictions, off-the-shelf scalable tools for planning under uncertainty can be exploited to solve WSC|fwd. The main limiting factors are: (1) These tools do not allow the generation of new constants. (2) These tools allow the specification of a clausal formula only for the initial state, not for all states. Our approach to deal with (1) considers a set of constants fixed a priori, namely the initially available constants plus additional \u201cpotential\u201d constants that can be used to instantiate outputs. Our more subtle observation is that, within a special case ofWSC|fwd, where the dynamics of states become predictable a priori, one can also deal with (2) in a natural way.\nIn what follows, we first introduce our core observation of a case where the state space becomes \u201cpredictable\u201d, in a certain sense. We then observe that predictability is naturally given in a special case of forward effects, which we term strictly forward effects. We discuss the strengths and limitations of this new special case. We finally provide a compilation of strictly forward effects into planning under initial state uncertainty."}, {"heading": "5.1 Predictable State Spaces", "text": "Our core observation is based on a notion of compatible actions. Assume aWSC|fwd task (P,\u03a6IC , O, C0, \u03c60, \u03c6G). Two actions a, a\n\u2032 are compatible if either Ea \u2229 Ea\u2032 = \u2205, or effa = effa\u2032 . That is, a and a\u2032 either have disjunct outputs \u2013 and hence affect disjunct sets of literals since we are in WSC|fwd \u2013 or their effects agree completely. A set A of actions is compatible if Ea \u2229 C0 = \u2205 for all a \u2208 A, and every pair of actions in A is compatible.\nLemma 2 states that, given the used actions are compatible, every state that can ever be reached\nsatisfies all action effects, modulo the existing constants.\nLemma 2 (Predictable State Spaces in WSC|fwd) Assume a WSC|fwd task, a compatible set of actions A, and a state s that can be reached with actions from A. Then s |= \u03c60 and, for all a \u2208 A, if Ea \u2286 Cs then s |= effa.\nProof: The proof is by induction. In the base case, for s \u2208 b0, the claim holds by definition since Cs \u2229 Ea = \u2205 for all a \u2208 A. Say s \u2032 is reached from s by an action a \u2208 A. If a is not applicable\nto s, with induction assumption there is nothing to prove. Otherwise, because we are in WSC|fwd, by Lemma 1 we have that res(s, a) = {(C \u2032, I \u2032) | C \u2032 = Cs \u222a Ea, I\n\u2032|Cs = Is, s |= \u03a6IC \u2227 effa}. With induction assumption applied to s, we have res(s, a) = {(C \u2032, I \u2032) | C \u2032 = Cs \u222a Ea, s |= \u03c60 \u2227 \u2227\na\u2032\u2208A,Ea\u2032\u2286Cs effa\u2032 \u2227\u03a6IC \u2227 effa}. Now, if any a\n\u2032 \u2208 A has Ea\u2032 \u2286 Cs \u222aEa but Ea\u2032 6\u2286 Cs, then\nwe have Ea\u2032 \u2229 Ea 6= \u2205 and hence effa\u2032 = effa by prerequisite. This concludes the argument. 2\nBy virtue of this lemma, the possible configurations of all constants that can be generated by\nactions from A are characterized by the formula \u03a6IC \u2227 \u03c60 \u2227 \u2227 a\u2208A effa. Since all parts of this formula are known prior to planning, the set of possible configurations is \u201cpredictable\u201d. Before we even begin to plan, we already know how the constants will behave if they are generated. So we can list the possible behaviors of all potential constants in our initial belief, and let the actions affect only those constants which actually exist. In other words, we can compile into initial state uncertainty. We will detail this further below. First, we need to identify a setting in which Lemma 2 can actually be applied."}, {"heading": "5.2 Strictly Forward Effects", "text": "Given a WSC|fwd task, we must settle for a finite set A of compatible actions that the planner should try to compose the plan from. One option is to simply require every action to have its own unique output constants. This appears undesirable since planning tasks often contain many actions, and so the set of potential constants would be huge. Further, to enable chaining over several actions, the potential constants should be allowed to instantiate the input parameters of every operator, hence necessitating the creation of a new action and, with that, more new potential constants. It is unclear where to break this recursion, in a sensible way.\nHerein, we focus instead on a restriction of WSC|fwd where it suffices to assign unique output constants to individual operators, rather than to individual actions.\nDefinition 2 Assume a WSC task (P,\u03a6IC ,O, C0, \u03c60, \u03c6G). The task has strictly forward effects iff:\n1. For all o \u2208 O, and for all l[X] \u2208 effo, we have |X| > 0 and X \u2286 Yo.\n2. For all clauses \u03c6 \u2208 \u03a6IC , where \u03c6 = \u2200x1, . . . , xk : l1[X1] \u2228 \u00b7 \u00b7 \u00b7 \u2228 ln[Xn], we have X1 = \u00b7 \u00b7 \u00b7 = Xn.\nThe set of all WSC tasks with strictly forward effects is denoted with WSC|sfwd.\nThe second condition is identical to the corresponding condition for WSC|fwd. The first condition is strictly stronger. While WSC|fwd requires that at least one effect literal variable is taken from the outputs,WSC|sfwd requires that all these variables are taken from the outputs. Therefore, obviously,WSC|sfwd \u2282 WSC|fwd. Note that theWSC task formulated in Example 2 is a member of WSC|sfwd.\nThe key property of WSC|sfwd is that, without input variables in the effect, all actions based on the operator will have the same effect. So, for the action set to be compatible, all we need is to choose a set of unique output constants for every operator. Indeed, we can do so for every set of operators whose effects are pairwise identical. We can also choose several sets of output constants for each such group of operators."}, {"heading": "5.3 Modeling Power", "text": "The limitations ofWSC|fwd, discussed in Section 4.2, are naturally inherited byWSC|sfwd. Moreover, unlike WSC|fwd, we cannot state any properties in the effect that connect the inputs to the outputs. This is a serious limitation. For illustration, consider the small VTA example we have been using. The operator bookTicket has an effect ticketFor(y, x), relating the produced ticket y to the train x given as input. Clearly, the notion of a \u201cticket\u201d is rather weak if we cannot state what the ticket is actually valid for. Another interesting case is the one where we extend Example 2 by considering two proteins rather than just one. That is, we set C0 = {c, c \u2032}, \u03c60 = cellProtein(c)\u2227cellProtein(c\u2032). We wish to encode that we need the combined presentation for both of those, i.e., \u03c6G = \u2203y : combinedPresentation(y, c) \u2227 combinedPresentation(y, c\n\u2032). In WSC|fwd, we can solve this by including, for every information providing operator, the input variable x into the effect literal. For example, we set getInfo3D1n55 := ({x}, 1n55(x), {y}, Info3D(y, x)). This is not possible inWSC|sfwd.\nTo some extent, these difficulties can be overcome by encoding the relevant inputs into predicate names. To handle composition for the two proteins c and c\u2032, this would essentially mean making a copy of the entire model and renaming the part for c\u2032. The goal would be \u03c6G = \u2203y, y\n\u2032 : combinedPresentation(y)\u2227 combinedPresentation\u2032(y\u2032), and the operator preconditions would make sure that combinedPresentation(y) is generated as before, while combinedPresentation\u2032(y\u2032) is generated using the new operators. Note that this a rather dirty hack, and that it depends on knowing the number of copies needed, prior to planning. The equivalent solution for the VTA would introduce a separate \u201cticketFor-x\u201d predicate for every entity x for which a ticket may be bought. At the very least, this would result in a rather oversized and unreadable model. A yet more troublesome case is the time-step construction outlined in Section 4.2, where we added a new output variable t into each effect and related that via an effect literal next(prevt, t) to a previous time step prevt provided as input. In WSC|sfwd, we can no longer relate t to prevt so there is no way of stating which time step happens after which other one. Trying to encode this information into predicate names, we would have to include one predicate per possible time step. This necessitates assuming a bound on the number of time steps, a clear limitation with respect to the more natural encoding.\nDespite the above,WSC|sfwd is far from a pathological and irrelevant special case. An example where it applies is the domain of proteins as shown in Example 1. Similarly, the hospital domain discussed in Section 4.2 can be naturally modeled in WSC|sfwd. More generally, there is in fact a wealth of WSC formalisms which do not encode any connections between inputs and outputs. For example, that category contains all formalisms which rely exclusively on specifying the \u201ctypes\u201d of input and output parameters. The information modeled with such types is only what kind of input a service requires, and what kind of output it produces \u2013 for example, \u201cinput is a train\u201d and \u201coutput is a ticket\u201d. Examples of such formalisms are various notions of message-based composition (Zhan et al., 2003; Constantinescu et al., 2004a; Lecue & Leger, 2006; Lecue & Delteil, 2007; Kona et al., 2007; Liu et al., 2007). In fact, the early versions of OWL-S regarded inputs and outputs as independent semantic entities, using a Description Logic formalization of their types.\nThus, the existence of a compilation from WSC|sfwd into planning under uncertainty is quite interesting. It shows how a composition model similar to the early versions of OWL-S, in a general form with partial matches and powerful background ontologies, can be attacked by off-the-shelf planning techniques. This opens up a new connection between WSC and planning."}, {"heading": "5.4 Compilation", "text": "We compile a WSC|sfwd task into a task of conformant planning under initial state uncertainty, which takes the form (P,A, \u03c60, \u03c6G). P is the finite set of propositions used. A is a finite set of actions, where each a \u2208 A takes the form (pre(a), eff(a)) of a pair of sets of literals over P . \u03c60 is a CNF formula over P , \u03c6G is a conjunction of literals over P . These notions are given a standard belief state semantics. A state is a truth value assignment to P . The initial belief is the set of states satisfying \u03c60. The result of executing an action a in a state s is res(s, a) := s if s 6|= pre(a), 18 and otherwise res(s, a) := (s\u222aadd(a))\\del(a). Here we use the standard notation that gives s in terms of the set of propositions that it makes true, uses add(a) to denote the positive literals in eff(a), and del(a) to denote the negative literals in eff(a). Extension of res to beliefs and the definition of a plan remain unchanged.\nAssume a WSC|sfwd task (P,\u03a6IC ,O, C0, \u03c60, \u03c6G). The compiled task (P \u2032,A, \u03c6\u20320, \u03c6 \u2032 G) makes use of a new unary predicate Ex that expresses which constants have yet been brought into existence. The compilation is obtained as follows. For each operator o \u2208 O, with outputs Yo = {y1, . . . , yk}, we create a set of new constants Eo = {e1, . . . , ek}. Then, C := C0 \u222a \u22c3\no\u2208O Eo will be the set of constants fixed a priori. Initialize A := \u2205. For each operator o \u2208 O, include into A the set of actions resulting from using C to instantiate the precondition preo \u2227 ( \u2227 x\u2208Xo Ex(x)) \u2227 ( \u2227\ne\u2208Eo \u00acEx(e)). Give each of these actions the same effect,\n\u2227\ne\u2208Eo Ex(e). In words, we instan-\ntiate o\u2019s outputs with Eo, we enrich o\u2019s precondition by saying that all inputs exist and that all outputs do not yet exist, and we replace o\u2019s effect with a statement simply bringing the outputs into existence.\nReplacing the effects in this way, where do the original effects go? They are included into the initial state formula. That is, we initialize \u03c6\u20320 as the conjunction of effo[Eo/Yo] for all operators o \u2208 O. Then, we instantiate all clauses in \u03a6IC with C and conjoin this with \u03c6 \u2032 0. We obtain our final \u03c6\u20320 by further conjoining this with \u03c60 \u2227 ( \u2227 c\u2208C0 Ex(c)) \u2227 \u2227 c\u2208C\\C0 \u00acEx(c)) \u2227 \u00acGoal. Here, Goal is a new proposition. It serves to model the goal. Namely, we have to introduce a set of artificial goal achievement actions. The goal has the form \u03c6G = \u2203x1, . . . , xk.\u03c6[x1, . . . , xk]. The new actions are obtained by instantiating the operator ({x1, . . . , xk}, \u03c6 \u2227 \u2227k i=1 Ex(xi), \u2205, Goal) with C. That is, the goal achievement actions instantiate the existentially quantified variables in the goal with all possible constants. Those actions are added to the set A. The overall compiled task now takes the form (P \u2032,A, \u03c6\u20320, Goal), where P \u2032 is simply the set of mentioned propositions.\nIn summary, we compile aWSC|sfwd task (P,\u03a6IC ,O, C0, \u03c60, \u03c6G) into a conformant planning task (P \u2032,A, \u03c6\u20320, \u03c6 \u2032 G) as follows:\n\u2022 For each operator o \u2208 O, create a unique set of new constants Eo = {e1, . . . , ek} where Yo = {y1, . . . , yk}. We denote C := C0 \u222a \u22c3 o\u2208O Eo.\n\u2022 P \u2032 contains all instantiations, with C, of P plus two new predicates, Ex and Goal. Ex has arity 1 and expresses which constants have yet been brought into existence. Goal has arity 0 and forms the new goal, i.e., \u03c6\u2032G = Goal.\n\u2022 The actionsA are the instantiations of all o \u2208 O, whereXo is instantiated withC, and Yo is instantiated with Eo. The preconditions are enriched with ( \u2227\nx\u2208Xo Ex(x))\u2227 (\n\u2227\ne\u2208Eo \u00acEx(e)),\nthe effects are replaced by \u2227\ne\u2208Eo Ex(e).\n18. As before, we give the actions a conditional effects semantics, rather than the more usual distinction between forced\npreconditions, and non-forced effect conditions.\n\u2022 Further, A contains goal achievement actions, achieving Goal under preconditions instantiating \u03c6G with C.\n\u2022 The original action effects, i.e., the conjunction of effo[Eo/Yo] for all operators o \u2208 O, is moved into \u03c6\u20320. Further, \u03c6 \u2032 0 contains \u03c60, \u03a6IC instantiated with C, and ( \u2227 c\u2208C0 Ex(c)) \u2227\n\u2227\nc\u2208C\\C0 \u00acEx(c)) \u2227 \u00acGoal.\nIn the terminology of Section 5.1, this means that we choose the set A of actions as all actions that can be obtained from an operator o \u2208 O by instantiating the inputs with constants from C, and the outputs with Eo. As suggested by Lemma 2, the initial state formula \u03c6 \u2032 0 of the compiled task describes the possible configurations of the constants C, and the only effect of applying an action is to bring the respective output constants into existence. Note that, although the effects of the compiled actions are all positive, planning is still hard (coNP-complete, to be precise) due to the uncertainty. (If we allow WSC operators to also delete constants, then we have negative effects \u2013 deleting constants \u2013 in the compiled task.)\nAccording to the above strategy, we create only one set of output constants per operator, and we do not take into account sets of operators that have identical effects. This is only to simplify the presentation. Our results carry over immediately to more complicated strategies that create more than one set of output constants per operator, as well as to strategies that share sets of output constants between operators with identical effects. It should be noted, however, that operators whose effects are not identical can not, in general, share their outputs. In particular, if the two effects are in conflict, e.g., InfoDSSP(d) and \u00acInfoDSSP(d), then the initial state formula \u03c6\u20320 as above is unsatisfiable. The compiled planning task is then trivially solved by the empty plan, and, of course, does not encode solutions in the original problem.\nExample 3 Re-consider the planning task defined in Example 2. We specify a compiled task. We set C = {c, d, e, f} where c is the only initially available constant, and d, e, f are potential constants for operator outputs. The compiled planning task (P \u2032,A, \u03c6\u20320, \u03c6 \u2032 G) is the following:\n\u2022 P \u2032 = {protein, cellProtein, G, H, I, 1n55, 1kw3, combinedPresentation, InfoDSSP, Info3D, Ex,Goal}, where all the predicates except Goal are unary (have one argument).\n\u2022 A consists of all instantiations of:\n\u2013 getInfoDSSPG[d/y]: ({x},G(x) \u2227 Ex(x) \u2227 \u00acEx(d), Ex(d))\n\u2013 getInfoDSSPH [d/y]: ({x},H(x) \u2227 Ex(x) \u2227 \u00acEx(d), Ex(d))\n\u2013 getInfoDSSPI [d/y]: ({x}, I(x) \u2227 Ex(x) \u2227 \u00acEx(d), Ex(d))\n\u2013 getInfo3D1n55[e/y]: ({x}, 1n55(x) \u2227 Ex(x) \u2227 \u00acEx(e), Ex(e))\n\u2013 getInfo3D1kw3[e/y]: ({x}, 1kw3(x) \u2227 Ex(x) \u2227 \u00acEx(e), Ex(e))\n\u2013 combineInfo[f/y]: ({x1, x2}, InfoDSSP(x1) \u2227 Info3D(x2) \u2227 Ex(x1) \u2227 Ex(x2) \u2227 \u00acEx(f), Ex(f))\n\u2013 GoalOp: ({x}, combinedPresentation(x) \u2227 Ex(x), Goal)\n\u2022 \u03c6\u20320 is the conjunction of:\n\u2013 all instantiations of \u03a6IC \u2013 [consisting of the five axioms given in Example 2]\n\u2013 cellProtein(c) \u2013 [\u03c60]\n\u2013 InfoDSSP(d)\u2227 Info3D(e)\u2227 combinedPresentation(f) \u2013 [original action effects]\n\u2013 Ex(c)\u2227 \u00acEx(d)\u2227 \u00acEx(e)\u2227 \u00acEx(f) \u2013 [constants existence]\n\u2013 \u00acGoal \u2013 [goal not yet achieved]\n\u2022 \u03c6\u2032G = Goal\nNow consider again the plan for the original task (see Example 2): \u3008getInfoDSSPG(c, d), getInfoDSSPH(c, d), getInfo3D1n55(c, e), getInfo3D1kw3(c, e), combineInfo(d, e, f)\u3009.\nTo illustrate, we now verify that this plan yields a plan for the compiled task. In that task, the initial belief b0 consists of all states s where c is the only existing constant, d, e, f satisfy the respective effects, and s |= \u03a6IC \u2227 cellProtein(c). Now we apply the action sequence:\n1. Apply getInfoDSSPG(c, d) to b0. We get to the belief b1 which is the same as b0 except that, in all s \u2208 b0 where s |= G(c), d now also exists.\n2. Apply getInfoDSSPH(c, d) to b1. We get to the belief b2 which is the same as b1 except that, in all s \u2208 b1 where s |= H(c), d exists.\n3. Apply getInfo3D1n55(c, e) to b2, yielding b3.\n4. Apply getInfo3D1kw3(c, e) to b3. This brings us to b4 where we have Ex(e) for all s \u2208 b2 with s |= 1n55(c) or s |= 1kw3(c).\n5. Apply combineInfo(d, e, f) to b4. This brings us to b5 which is like b4 except that all s \u2208 b4 where both d and e exist now also have Ex(f).\n6. Apply GoalOp(f) to b5, yielding b6.\nThe same reasoning over \u03a6IC used in Example 2 to show that b5 satisfies the original goal, can now be used to show that GoalOp(f) is applicable in all s \u2208 b5 and hence the resulting belief b6 satisfies the goal. So we obtain a plan for the compiled task simply by attaching a goal achievement action to the original plan.\nTo prove soundness and completeness of the compilation, we need to rule out inconsistent operators, i.e., operators whose effects are in conflict with the background theory (meaning that \u03a6IC \u2227 \u2203Xo, Yo : effo is unsatisfiable). For example, this is the case if \u2200x : \u00acA(x) \u2228 \u00acB(x) is contained in \u03a6IC , and effo = A(y) \u2227 B(y). In the presence of such an operator, the initial belief of the compiled task is empty, making the task meaningless. Note that inconsistent operators can never be part of a plan, and hence can be filtered out as a pre-process. Note also that, inWSC|sfwd, an operator is inconsistent iff all actions based on it are inconsistent.\nNon-goal achievement actions in A correspond to actions in the original task, in the obvious way. With this connection, we can transform plans for the compiled task directly into plans for the original task, and vice versa.\nTheorem 7 (Soundness of Compilation) Consider the WSC|sfwd task (P,\u03a6IC ,O, C0, \u03c60, \u03c6G) without inconsistent operators and a plan \u3008a1, . . . , an\u3009 for the compiled task (P \u2032,A, \u03c6\u20320, \u03c6 \u2032 G). Then the sub-sequence of non-goal achievement actions in \u3008a1, . . . , an\u3009 is a plan for the task (P,\u03a6IC ,O, C0, \u03c60, \u03c6G).\nProof Sketch: For an arbitrary sequence of non-goal achievement actions, denote by b the belief after execution in the original task, and by b the belief after execution in the compiled task. For a state s in the original task, denote by [s] the class of all compiled-task states s over the constants C0 \u222a \u22c3 o\u2208O Eo so that {c | s(Ex(c)) = 1} = Cs, s|Cs = Is, and s |= \u03a6IC \u2227 \u03c60 \u2227 \u2227\no\u2208O effo[Eo]. One can prove that b = \u22c3\ns\u2208b[s]. The claim follows directly from that. 2\nTheorem 8 (Completeness of Compilation) Consider the WSC|sfwd task (P,\u03a6IC ,O, C0, \u03c60, \u03c6G) without inconsistent operators and a plan \u3008a1, . . . , an\u3009 where every operator o appears with at most one instantiation Eo of the outputs. Then \u3008a1, . . . , an\u3009 can be extended with goal achievement actions to form a plan for the compiled task (P \u2032,A, \u03c6\u20320, \u03c6 \u2032 G) obtained using the outputs Eo.\nProof Sketch: Follows immediately from b = \u22c3\ns\u2208b[s] as shown for the proof of Theorem 7. Say one executes \u3008a1, . . . , an\u3009 in the compiled task, ending in a belief b. From there, a plan for the compiled task can be obtained simply by attaching one goal achievement action for every tuple of constants satisfying \u03c6G in a world state from b. 2\nThe reader may have noticed that the number of instantiations of the goal achievement operator is exponential in the arity of the goal. In the worst case, all these instantiations must be included in the plan for the compiled task. In particular, this may happen in the plan constructed as per the proof of Theorem 8. However, for practical purposes it appears reasonable to assume a fixed upper bound on the number of goal variables.\nAs indicated, the proofs of Theorems 7 and 8 remain valid when allowing more than one Eo per operator, and/or when operators with identical effects share output constants. Note that operators have identical effects if several web services provide alternative ways of achieving something. Example 3 illustrates such a situation (cf. our earlier discussion in Section 3.2). In our experiments as described in the next section, all groups of operators with identical effects are assigned the same output constants."}, {"heading": "6. Empirical Results", "text": "To show that the compilation approach has merits, we now report on a number of empirical experiments using CFF as the underlying planner. We start with a discussion of the general experimental setup and then discuss the results for two different test scenarios."}, {"heading": "6.1 Experiments Setup", "text": "We implemented the compilation from WSC|sfwd into planning under uncertainty as described above, and connected it to the CFF tool. It should be noted here that, although the compiled planning tasks do not have delete effects, they are not solved by CFF\u2019s relaxed-plan-based heuristic function. That function makes a further relaxation ignoring all but one of the conditions of each effect (see the earlier discussion of CFF in Section 4.5). Ignoring all but one condition significantly affects the compiled tasks because their effects typically involve many conditions, particularly those conditions stating that all inputs exist and all outputs do not yet exist.\nOne problematic point in evaluating planning-based WSC is the choice of test cases. The field is still rather immature, and due to the widely disparate nature of existing WSC tools, there is\nno common set of benchmarks.19 In fact, because web service composition is such a new topic posing so many challenges to existing techniques, the different works differ widely in terms of both their underlying purpose, and the specific aspect of WSC they address. A detailed discussion of existing WSC tools is given below in Section 7. The method we choose for evaluation is to design two test scenarios that reflect what are intuitively relevant kinds of problem structures in potential applications of planning-based WSC, and that are scalable in a number of interesting parameters. We test the reaction of our approach to these parameters.\nWhile our test scenarios are artificial benchmarks, and cannot lead to broad conclusions of significance for practice, they do allow us to draw conclusions about planning behavior in differently structured test problems. Our solution method scales quite well in most of the tested cases, efficiently finding solutions that involve many web service calls, and that successfully employ only those services that are really necessary. Viewing these results in isolation, one can conclude that representation techniques and heuristic functions from planning under uncertainty may be useful to attack large and complex planning-like WSC instances.\nA comparison to alternative WSC tools is, again, problematic, due to the broad range of problems the tools can solve, the different kinds of solutions they find, and the different kinds of input syntax/language they read. To obtain at least some notion of empirical comparison to these tools, in the following we consider only expressivity (\u201cHow general is the input language of a tool?\u201d) and scalability (\u201cHow quickly can the tool compose?\u201d). Each of the existing WSC tools constitutes a separate point in the trade-off between these two. The question then is whether our compilation approach, restricting toWSC|sfwd and using CFF to solve the compiled tasks, is a sensible point in that trade-off.\nIn terms of expressivity, our approach is located in between very general planning methods (like Eiter et al., 2003, 2004; Giunchiglia et al., 2004), inspired by the actions and change literature, and the more restricted methods that have been applied to WSC so far. The question is whether we gain scalability in comparison to the more expressive methods.\nWe confirm in our experiments that the answer is, as expected, \u201cyes\u201d. We run the DLVK tool (Eiter et al., 2003, 2004), which handles a powerful planning language based on logic programming. That language in particular features \u201cstatic causal rules\u201d which are similar to the integrity constraints in fully general WSC.20 In that sense, from our perspective DLVK is a \u201cnative WSC tool\u201d that handles ontology axioms directly rather than via restricting their expressivity and compiling them away. In particular, we encoded ourWSC test problems directly in DLVK\u2019s input language, without the compilation that we use for CFF.\nDLVK relies on answer set programming, instead of relaxed plan heuristics, to find plans. Further, in the style of many reasoning-based planners, DLVK requires as input a length bound on the plan, and can hence be used to find optimal plans by running it several times with different bounds. In all cases, we ran DLVK only once, with the bound corresponding to the optimal plan length. Even so, DLVK is much slower than CFF, solving only a small fraction of our test instances. We do not wish to over-interpret these results. All we conclude is thatWSC|sfwd constitutes an interesting point in the trade-off between expressivity and scalability in WSC.\n19. While the VTA example could be considered one such benchmark, essentially every individual approach defines its\nown particular version of that example.\n20. The similarity lies in that both static causal rules and fully general integrity constraints can, as a side effect of applying\nan action, yield ramifications affecting the properties inherited from the previous state.\nWhen running some first tests with the compilation approach, we noticed that the encoding as per Section 5.4 is unnecessarily generous about the set of initial states. Observe that our compiled tasks are always easier to solve if more propositions are true in the initial state. This is, simply, because all literals in operator preconditions, effects, and the goal are positive. Hence, if a proposition p does not appear positively in any initial state clause, then one can set p to 0 initially, and thereby reduce the number of initial states, without introducing any new plans.21 Setting a proposition to 0 may cause unit propagations, setting other propositions to 1 or 0. We iterate these steps until a fixpoint occurs. The resulting initial state description is stricter than before, and yields better performance both for CFF and for DLVK. We use this optimized encoding in all the experiments reported below.\nWe also experimented with another optimization. That optimization makes the assumption that the constants requested by the goal will be generated in a step-wise fashion, where each intermediate constant is generated with certainty before generating the next constant. Recall that in the encoding as per Section 5.4, the existence of the inputs of operators, i.e., the condition \u2227\nx\u2208Xo exists(x), is\npart of the operator precondition and is thus interpreted under a conditional effects semantics. However, both CFF and DLVK offer a distinction between effect conditions and forced preconditions that must hold in the entire belief for the action to be applicable. We can exploit that distinction to postulate that the condition \u2227\nx\u2208Xo exists(x) is forced. This reduces the state space, but may cut\nout solutions. The reduction is quite beneficial both for CFF and for DLVK. Since the optimization affects the set of plans, we switch it on only in part of the test cases, to point out the possible speedup. The tests where the optimization is switched on are discussed in the text, and indicated by the keyword forced in the name of the test case.\nWe use two versions of CFF. One is CFF\u2019s default configuration which makes use of FF\u2019s \u201cenforced Hill-climbing\u201d search algorithm as well as its \u201chelpful actions pruning\u201d technique (Hoffmann & Nebel, 2001). In the other configuration, CFF helpful actions pruning is turned off, and the search proceeds in standard \u201cgreedy best-first\u201d fashion, with an open queue ordered by increasing heuristic values. We henceforth denote the former configuration with CFF-def and the latter configuration with CFF-std.\nAll results were obtained on a 2.8GHz Pentium IV PC running Linux. All tests were run with a\ntime-out of 600 seconds CPU, and limiting memory usage to 1 GB."}, {"heading": "6.2 Subsumption Hierarchies", "text": "We first investigate how well our approach can deal with scaling subsumption hierarchies, and with building chains of successively created entities (outputs). For that purpose, we design a test scenario called SH, which demands the composition of web services realizing a chain of generation steps, where every generation step has to deal with a subsumption hierarchy.\nThe scenario is depicted in Figure 2. There are n \u201ctop-level\u201d concepts TL1, . . . , TLn, depicted with \u201cTL\u201d in Figure 2. The goal input is TL1, the goal output is TLn. Beneath each TLi, there is a tree-shaped hierarchy of sub-concepts. More precisely, the tree is perfectly balanced with branching factor b, and has depth d. The inner nodes of the tree are called \u201cintermediate-level\u201d (or simply \u201cintermediate\u201d) concepts, depicted with \u201cIL\u201d in Figure 2. The leaf nodes of the tree are called \u201cbasic-level\u201d (or simply \u201cbasic\u201d) concepts, depicted with \u201cBL\u201d in Figure 2. For every non-leaf concept C in the tree, with children C1, . . . , Cb, we have the axioms \u2200x : Ci(x) \u21d2 C(x)\n21. Of course, reducing the set of initial states does not invalidate any old plans, either.\nWEB SERVICE COMPOSITION AND PLANNING UNDER UNCERTAINTY: A NEW CONNECTION\nTL\nIL IL\nBL BLBLBLBLBL\nTL\nILIL\nBL BL BL BL BL BL\nSWS SWS SWS SWS SWS SWS\nFigure 2: Schematic illustration of the SH scenario.\nexpressing subsumption, as well as an axiom \u2200x : C(x) \u21d2 C1(x)\u2228 \u00b7 \u00b7 \u00b7 \u2228Cb(x) expressing that the parent is covered by its children.\nThe available web services are defined as follows. For each top level concept TLi, and for each leaf BLi,j of the corresponding tree structure, there is a web service available that takes BLi,j as input and that outputs TLi+1. The corresponding WSC operator takes the form oi,j = ({x}, BLi,j(x), {y}, TLi+1(y)). Then, by applying, for each 1 \u2264 i < n in order, all services oi,j , it is possible to make sure that a constant of concept TLi+1 is created in all possible cases. Hence, sequencing all these steps is a plan, of length (n \u2212 1) \u2217 bd. Note here that, as we already stated in Section 5.4, in our experiments groups of operators with identical effects are assigned the same output constants. For the SH scenario, this means that for each 1 \u2264 i < n, all the oi,j share the same output constant. Hence the total number of output constants generated, i.e., the number of \u201cpotential constants\u201d in the initial state, is equal to the number of top-level concepts, n. Although the SH scenario is of an abstract nature, it is representative for a variety of relevant situations. Specifically, the scenario can model situations where sets of different services must be used to address a request which none of them can handle alone. The role of each single service is then to handle some particular possible case. In our example, the \u201cset of different services\u201d is the set of services oi,j assembled for each TLi. Given a constant c which is a member of TLi, i.e., TLi(c) holds, the \u201cparticular possible case\u201d handled by service oi,j is the case where c happens to be a member of leaf BLi,j \u2013 one of those cases must hold due to the coverage clauses in the tree.\nSimilar situations arise, e.g., for geographically located (regional) services when the composition request is not location-specific or addresses locations at a higher (inter-regional) level. A similar pattern can also be found in e-government scenarios where a clear-cut classification of activities leads to establishing several \u201cparallel\u201d services that serve different departmental areas.\nOrthogonal to this \u201chorizontal\u201d composition, the scenario can model \u201cvertical\u201d composition, where one function has to be pursued by concatenating existing functions. This is the case for most complex procedures in such diverse areas as e-government or e-commerce.\nThe scenario can be instantiated to study different aspects of the scalability of our approach. Our empirical tests measure scalability in both the horizontal and the vertical direction. Further, we consider two extreme cases of the possible shapes of the individual concept trees in the chain, giving us instances with identical numbers of leaves. We set up the test scenario SH-broad, where d = 1 and b scales over 2, 4, 8, 16, 32. We set up the test scenario SH-deep, where b = 2 and d scales over 1, 2, 3, 4, 5. In both scenarios, n scales from 2 to 20.\nFurther, we designed a SH-trap variant where a second chain of n concepts can be linked, but is completely irrelevant for the goal service. This variant is suitable for testing to what extent the composition techniques are affected by irrelevant information. Finally, recall that the encoding method comes in two versions as explained above, where the default method treats input existence \u2013 \u2227\nx\u2208Xo exists(x) \u2013 by a conditional effects semantics, whereas the non-default method, forced,\ncompromises completeness for efficiency by treating input existence as a forced precondition.\nAll in all, we have the following choices: 3 different planners (CFF-def, CFF-std, DLVK); 2 different encoding methods; SH with or without the trap; SH-broad or SH-deep. The crossproduct of these choices yields 24 experiments, within each of which there are 19 possible values for n and 5 possible values for b or d, i.e., 95 test instances. For CFF, we measured 3 performance parameters: total runtime, number of search states inserted into the open queue, and number of actions in the plan. For DLVK, we measured total runtime and number of actions in the plan. Of course, not all of this large amount of data is interesting. In what follows, we summarize the most important observations. Figure 3 shows the data we selected for this purpose. Part (a) of the figure shows CFF-std on SH-broad; (b) shows CFF-std on SH-deep; (c) shows CFF-def on SH-forcedbroad; (d) shows DLVK on SH-broad and SH-deep; (e) shows DLVK on SH-forced-broad and SH-forced-deep; (f) shows DLVK and CFF-std on SH-trap. The vertical axes all show log-scaled runtime (sec). The horizontal axes show n in (a), (b) and (c). In (d), (e) and (f), n is fixed to n = 2 and the horizontal axes show the number of leaves in the concept hierarchy.\nConsider first Figure 3 (a) and (b). These plots point out how efficiently CFF can handle this kind of WSC problem, even with no forced optimization. Comparing the two plots points out the difference between handling broad and deep concept hierarchies. In both plots, CFF-std runtime is shown over n, the length of the chain to be built. In (a), we show 5 curves for the 5 different values of b (the number of leaves in a hierarchy of depth 1), and in (b) we show 5 curves for the 5 different values of d (the depth of a hierarchy with branching factor 2). In both cases, the scaling behavior is fairly good. With small concept hierarchies (b = 2 or d = 1), chains of almost arbitrary length can be built easily. As the hierarchies grow, runtime becomes exponentially worse. Note, however, that from one curve to the next the size of the hierarchies doubles, so that growth is itself exponential. With concept hierarchies of 16 leaves, i.e., 16 alternative cases to be handled in each step, we can still easily build chains of 6 steps, where the solution involves 96 web services. The most interesting aspect of comparing the two plots, (a) and (b), is that the underlying search spaces are actually identical: the open queues are the same. The only difference in performance stems\nfrom an overhead in CFF\u2019s reasoning techniques, which consume more runtime in the case of deep concept hierarchies. Hence the slightly worse behavior in (b).\nIf we run CFF-def on the test suites of Figure 3 (a) and (b), then we obtain much worse behavior. For example, with b = 8 we only get up to n = 3. The reason seems to be that FF\u2019s helpful actions pruning and enforced hill-climbing are too greedy in this domain. A simple way to overcome this is to use a standard heuristic search algorithm instead, as done by CFF-std shown in Figure 3 (a) and (b). On the other hand, if the forced optimization is switched on, then helpful actions pruning and enforced hill-climbing work much better, and we obtain a significant performance boost when using CFF-def. The latter is pointed out by Figure 3 (c), showing data for CFF-def on SH-forced-broad. Like Figure 3 (a) for CFF-std on SH-broad, this plot shows 5 curves, one for each of the 5 values of b (legend omitted from the plot because it would overlap the curves). We see that, in this case, we can easily build arbitrarily long chains even for b = 16, giving us a solution involving 320 web services for n = 20. Even for b = 32, we still get up to n = 9.\nFigure 3 (d) and (e) show what one gets when trying to solve the same examples, encoding them directly for DLVK instead of using the compilation and solving them with CFF. As expected, the performance is much worse. Since hardly any test instance is solved for n > 2, we fixed n to its minimum value 2 in these plots, unlike (a), (b) and (c). Each of (d) and (e) shows data for both the broad and deep variants, showing the number of leaves on the horizontal axis. In order to obtain a more fine-grained view, for the broad variant we increase that number by steps of 1 rather than by a multiplicative factor of 2 as before. We see that, without the forced optimization \u2013 Figure 3 (d) \u2013 performance is poor, and the largest case we can solve is n = 2, b = 6 where the solution involves 6 web services. As we switch forced on \u2013 Figure 3 (e) \u2013 performance is dramatically improved but is still on a different level than what we obtain by compilation+CFF.\nFigure 3 (f), finally, exemplifies the results we get in the trap scenario. We show data for the broad version, on the default encoding with CFF-std, and on both the default and the forced encoding with DLVK. DLVK is quite affected by the irrelevant chain of concepts, now solving only the single instance n = 2, b = 2 for the default encoding, and getting up to n = 2, b = 16 for the forced encoding, instead of n = 2, b = 20 without the trap. This behavior is expected since DLVK does not make use of heuristic techniques that would be able to detect the irrelevance of the second chain of concepts. The question then is whether CFF\u2019s techniques are better at that. Figure 3 (f) shows that CFF-std is largely unaffected for n = 2 \u2013 one can see this by comparing that curve with the points on the vertical axis in Figure 3 (a). However, for n > 2 the performance of CFF-std drastically degrades: the only instances solved are n = 3, b = 2 and n = 4, b = 2. The reason seems to be that the additional actions yield a huge blow-up in the open queue used by the global heuristic search algorithm in CFF-std. Indeed, the picture is very different when using CFF-def and the forced encoding instead: the search spaces are then identical to those explored with no trap, and the behavior we get is identical to that shown in Figure 3 (c).\nAll plans found in the SH scenario are optimal, i.e., the plans returned contain only those web services that are needed. The single exception is DLVK in trap, where the solutions include some useless web services from the trap chain.22\n22. Note here that DLVK\u2019s plans are parallel. Their parallel length is optimal (because we provided the correct plan\nlength bound, cf. Section 6.1. However, each parallel step may contain unnecessary actions, on top of the necessary ones. That\u2019s what happens in trap."}, {"heading": "6.3 Complex Concept Dependencies", "text": "The two variants of the SH scenario feature tightly structured relationships between the involved concepts, and allow the investigation of scalability issues by varying the size of the structure. We now consider a more advanced scenario, where the way top-level concepts are covered by lowerlevel concepts is subject to complex concept dependencies, similar to the axioms constraining protein classes and their characteristics in Example 1. Therefore we investigate how performance is impacted by more complex concept structures than just subsumption hierarchies.\nOur new scenario is called CD, for concept dependencies. Figure 4 illustrates this scenario, and contrasts it with the SH scenario. Similarly to what we had in SH, we have top-level concepts, of which each one is associated to a set of basic sub-concepts. There are b basic concepts for every top-level concept. There are n top-level concepts TL1, . . . , TLn, and the goal is to achieve TLn starting from TL1. As before, this is done through combining web services that cover all possibilities. Namely, for every top-level concept TLi and for every basic concept BLi,j associated with it, we have the operator oi,j = (({x}, BLi,j(x), {y}, TLi+1(y)). 23\nThe difference lies in the connection between the basic concepts and the top-level concepts. In SH, this was rigidly given in terms of a tree structure of subsumption and coverage axioms over intermediate concepts. Every basic concept \u2013 i.e., every operator oi,j corresponding to such a concept \u2013 had to be included in the plan in order to cover all possible cases. In CD, we use instead a complex set of axioms to connect the basic concepts to the top-level. Each top-level concept has m intermediate concepts ILi,1, . . . , ILi,m, for which as before we have axioms stating that each ILi,j\n23. Note here again that, for the same i, all these operators are assigned the same output constant by our compilation\ntechnique.\nis a sub-concept of TLi, as well as the axiom \u2200x : TLi(x) \u21d2 ILi,1(x) \u2228 \u00b7 \u00b7 \u00b7 \u2228 ILi,m(x) stating that TLi is covered by ILi,1, . . . , ILi,m. For the connection between the intermediate concepts and the basic concepts, complex dependencies are used. Each intermediate subconcept is constrained to be covered by some non-empty set of combinations of the basic subconcepts. Precisely, we create a random DNF, of only positive literals, using the basic concepts as the predicates. We then take that DNF to imply ILi,j . Note here that, in the implication, the DNF is negated and hence becomes a CNF, which we can directly encode into our formalism. We do this for every ILi,j .\nIn such a setting, it is interesting to control how many combinations are required to cover the top-level concept TLi. This directly corresponds to the total number of random combinations (random DNF disjuncts) that are generated, for all of the intermediate concepts ILi,j taken together. We control this via what we call the coverage factor, c, ranging in (0, 1]. From the 2b \u2212 1 possible combinations of basic concepts, we pick a random subset of size \u2308c \u00d7 (2b \u2212 1)\u2309. Each such combination is associated to the DNF of a randomly chosen intermediate concept. Note that the CNF formulas generated this way may be enormous. To minimize the size of the encoding, we use the formula minimization software Espresso (Brayton, Hachtel, McMullen, & Sangiovanni-Vincentelli, 1984; McGeer, Sanghavi, Brayton, & Sangiovanni-Vincentelli, 1993).\nIf \u2013 hypothetically \u2013 c is set to 0 then the task is unsolvable. In the experiments reported below, whenever we write c = 0% this means that exactly one combination was selected, and associated with every intermediate concept.\nBy escaping from the rigid schema of relationships presented by SH, the CD scenario is suitable to test whether the performance of our approach is tied to the specific structure of the SH problem. Moreover, the way CD is designed allows us to determine to what degree the planners react intelligently to different concept structures. In particular, the scenario allows the analysis of:\n1. The ability of our approach, and in particular of the selected underlying planner CFF, to iden-\ntify plans that contain only relevant actions. Especially when the \u201ccoverage factor\u201d c is low, some basic subconcepts may never appear in any partition of intermediate concepts, and thus, the plan does not need to include the respective operators. Still, due to the conditional effects/partial matches semantics, plans that include those operators are valid plans. Evaluating plan length performance over varying c is therefore interesting.\n2. The ability of our approach to deal with complex axiomatizations. This can be measured in\nterms of the impact of the coverage factor on runtime performance. The randomization of the choice of combinations of basic factors, in different settings of c, may induce significant differences in the CNF axiomatizations, and as a result, subject the underlying reasoning engine to very different situations.\nIn summary, the CD scenario is representative for situations where complex dependencies must be taken into account in order to select the correct services. Examples of such domains were discussed in Sections 4.2 and 5.3. In particular, the CD scenario corresponds closely to (a scalable version of) our protein domain example. The different values for the DSSP code correspond to different basic concepts, and the respective getInfoDSSP services are the operators taking them to an intermediate concept, InfoDSSP(y). This is similar for amino-acids, 3-D shapes, and shapes in complexes. The top level concept combinedPresentation(y) can be achieved once constants for every intermediate concept have been created. So, the only difference to CD lies in that, rather than having just a single top-level concept generated from its intermediates, CD has a sequence of top-level concepts that need to be generated in turn.\nAs with the SH scenario, the total data of our experiments is extensive, even more so since we now have 4 scenario parameters rather than 2 as before, and since individual instances now contain a random element. In Figure 5, we report selected results pointing out the main observations. Part (a)/(b) of the figure show CFF-std runtime/plan length over n for m = 4, b = 5; (c)/(d) show CFFstd runtime/search nodes over c for n = 5, m = 3, b = 7; (e) shows DLVK and CFF-std runtime over b in CD for n = 2, c = 100%; (f) show the latter data for CFF-def and CD-forced.\nFigure 5 (a) and (b) consider the scalability and solution lengths of the test varying the size of the scenario, and representing different coverage factors as different lines. We report data for CFFstd. Results are very similar for CD-forced and CFF-def, i.e., contrary to SH, in CD this setting of options does not bring a significant performance gain. We see in Figure 5 (a) that CFF scales up pretty well, though not as well as in SH, being easily able to solve tasks with 7 top level concepts of which each has 4 intermediate concepts and 5 basic concepts. Tasks with minimum coverage factor, c = 0%, are solved particularly effortlessly. For higher c values, one can observe somewhat of an easy-hard-easy pattern, where, for example, the curve for c = 100% lies significantly below the curves for c = 40% and c = 60%. We examine this easy-hard-easy pattern in more detail below.\nIn Figure 5 (b), an obvious and expected observation is that plan length grows linearly with n, i.e., with the number of top level concepts. A likewise obvious, but much more important, observation is that plan length grows monotonically with the coverage factor c. As reported above, a lower coverage factor opens up the opportunity to employ less basic services, namely only the relevant ones. Figure 5 (b) clearly shows that CFF-std is effective at determining which of the services are relevant and which are not.\nLet us get back to the intriguing observation from Figure 5 (a), the easy-hard-easy pattern over growing c. Figure 5 (c) and (d) examine this phenomenon in more detail. Both plots scale c on the horizontal axis, for a fixed setting of n, m and b. Runtime is shown in (c), while (d) shows the number of search states inserted into the open queue. For each value of c, the plots give the average and standard deviation of the results for 30 randomized instances. We clearly see the easyhard-easy pattern in (c) for runtime, with high variance particularly for c = 80%. In (d), we see that there is no such pattern for the number of search states, and that the variance is much less pronounced. This shows that the easy-hard-easy pattern is not due to differences in the actual search performed by CFF, but due to the effort spent in the search nodes. We traced the behavior of CFF in detail, and found that the reason for the easy-hard-easy pattern lies in the runtime CFF spends in its SAT reasoning for \u201cstate transitions\u201d, i.e., in the reasoning it uses to determine which facts are definitely true/false in each belief. For high but non-100 values of c, the CNF encodings of the concept dependency structures take on a rather complex form. In the cases where CFF takes a lot of runtime, almost all of the runtime is spent within a single call to the SAT solver. That is, it seems that CFF\u2019s SAT solver exhibits a kind of heavy-tailed behavior on these formulas, a phenomenon well known in the SAT and CP community, see for example the work of Gomes, Selman, Crato, and Kautz (2000). It should be noted here that, in typical planning benchmarks, the CNFs have a much simpler structure, which motivates the use of a fairly naive SAT solver in CFF, using neither clause learning nor restarts, in order to save overhead on formulas that are simple anyway. It seems likely that the addition of advanced SAT techniques to the solver could ameliorate the observed problem.\nFinally, Figure 5 (e) and (f) compare the performances of compilation+CFF and DLVK (with no compilation). Both plots fix n = 2, i.e., data is shown for only 2 top level concepts. The only instances that DLVK solves for n > 2 are the ones where the forced optimization is used and n = 3, m = 2, b = 2. Further, in both plots c is fixed to c = 100%. The reason for this is that we did\nnot find a significant difference in the performance of DLVK for different values of c. DLVK was unable to exploit lower c for lower runtime, and neither did it show an easy-hard-easy pattern. We speculate that DLVK\u2019s answer set programming solver tends to perform exhaustive search anyway and is accordingly not as affected by different structures as the heuristic techniques employed by CFF. However, like CFF, DLVK was able to exploit lower coverage factors c for shorter plans.\nFigure 5 (e) shows the default setting without the forced optimization. We see that the performance of DLVK explodes quickly while CFF does not experience as much trouble. CFF fails at the upper ends of its curves, both in Figure 5 (e) and (f), only because the problem files, i.e., the CNFs describing the complex concept dependencies, become too large to parse (> 4 MB). That notwithstanding, CFF\u2019s runtime behavior is clearly exponential. Note, however, that the actual encodings, i.e., the problem instances to be solved, also grow exponentially over c. We can further observe that DLVK exhibits quite some variance, particularly across different settings ofm: the curves cross in Figure 5 (e). This is even more pronounced in Figure 5 (f), where we can also observe, as before for SH, that the forced optimization brings a huge advantage for DLVK. For m = 2 and m = 6 in Figure 5 (f), DLVK fails on the first unsolved problem instance due to running out of memory shortly after parsing the problem.\nConcluding this section, we observe that the empirical behavior of CFF in the SH and CD scenarios is promising. These results should not be over-interpreted, though. While the test scenarios do capture problem structure typical of a variety of potential applications of WSC technology, our approach has yet to be put to the test of actual practice. The same, however, can be said of essentially all current planning-based WSC technology, since the field as a whole is still rather immature."}, {"heading": "7. Related Work", "text": "The relation of our work to the belief update literature has been covered in detail already in Sections 2.2 and 4.3. As for the relation to planning, our formalism basically follows all the commonly used frameworks. Our notions of operators, actions, and conditional effects are exactly as used in the PDDL framework (McDermott et al., 1998; Bacchus, 2000; Fox & Long, 2003), except for the extension with outputs. Regarding the latter, it has been recognized for some time in the planning community, for example by Golden (2002, 2003) and Edelkamp (2003), that on-the-fly creation of constants is a relevant feature for certain kinds of planning problems. However, attempts to actually address this feature in planning tools are scarce. In fact the only attempt we are aware of is the work by Golden (2002, 2003) and Golden, Pand, Nemani, and Votava (2003). Part of the reason for this situation is probably that almost all current state of the art tools employ pre-processing procedures that compile the PDDL task into a fully grounded description. The core algorithms are then implemented based on a propositional representation. Lifting such algorithms to a representation that involves variables and on-the-fly instantiations requires a major (implementation) effort. In the work herein, we circumvent that effort by using \u201cpotential\u201d constants and feeding the resulting problem to CFF, which like most planners employs the said pre-processing. Extending CFF for WSC|fwd will involve dealing with non-propositional representations as a sub-problem.\nOur notion of initial state uncertainty and conformant plans closely follows the related literature from planning under uncertainty (Smith & Weld, 1998; Cimatti et al., 2004; Hoffmann & Brafman, 2006). The formalization in terms of beliefs is adapted from the work by Bonet and Geffner (2000). There are some related works in planning which allow a domain axiomatization, i.e., some form of axioms constraining the possible world states (Eiter et al., 2003; Giunchiglia et al., 2004). To the best of our knowledge, no work in planning exists, apart from the work presented herein, which considers the combination of domain axioms and outputs.\nA few words are in order regarding our notions of \u201cpartial\u201d and \u201cplug-in\u201d matches. This terminology originates from work on service discovery in the SWS community (see for example Paolucci et al., 2002; Li & Horrocks, 2003; Kumar et al., 2007). In service discovery, one is concerned with\nmatching service advertisements against service requests. The discovery result is the set of services whose advertisement matches the request. The descriptions of services and requests are similar to the functional-level service descriptions, i.e., the planning operators that we use here. However, the terminology in these works is slightly different from ours, and they also describe additional kinds of matches. The notions given by Li and Horrocks (2003) have the closest relation to ours. Service descriptions are defined in terms of constructed Description Logic concepts. Say A is the concept describing the advertisement, and R is the concept describing the request. Then Li and Horrocks say that A and R have: an \u201cexact match\u201d ifA \u2261 R; a \u201cplug-in match\u201d ifA \u2292 R; a \u201csubsume match\u201d if A \u2291 R; and an \u201cintersection match\u201d if A \u2293 R 6\u2291 \u22a5. To compare this to our setting, consider the situation where A is the effect of action a, and R is the precondition of action r. Exact matches are a special case of plug-in matches which we do not distinguish herein. Intersection matches correspond to what we call partial matches. Concerning plug-in and subsume matches, matters are more subtle. The intuitive meaning of \u201cplug-in match\u201d is that \u201cthe advertisement fully suffices to fulfill the request\u201d. In planning terms, this means that the effect of a implies the precondition of r. However, in service discovery this is traditionally taken to mean that every requested entity is being provided, i.e., A \u2292 R. The latter notion \u2013 where the precondition of r implies the effect of a \u2013 is not meaningful in planning. Hence we use only one of the two notions, in correspondence to Li and Horrocks\u2019s \u201csubsume matches\u201d.\nIn contrast to the work of Li and Horrocks (2003), and to our work, Paolucci et al. (2002) and Kumar et al. (2007) define matches for individual input/output parameters in service descriptions, rather than for service descriptions on a more global level (precondition/effect for us, constructed concept for Li & Horrocks, 2003). On the level of individual parameters, Paolucci et al. (2002) suggest the same notions as Li and Horrocks (2003) except that they do it in a less formal notation, and they do not define intersection matches. The same is true of Kumar et al. (2007). The latter authors also define notions of \u201ccontains\u201d and \u201cpart-of\u201d matches, relating to the building blocks of constructed concepts. Obviously, such notions do not make sense in our framework, where there aren\u2019t any constructed concepts. Finally, Kumar et al. define some ways of aggregating matches for individual parameters to matches for entire service descriptions. Again, this is not applicable in our case since we work on a more global level in the first place.\nA brief survey of the existing works on WSC is as follows. There is a variety of works that compile composition into more or less standard deterministic planning formalisms (Ponnekanti & Fox, 2002; Srivastava, 2002; Sheshagiri et al., 2003). Some other works (Agarwal, Dasgupta, Karnik, Kumar, Kundu, Mittal, & Srivastava, 2005b; Agarwal et al., 2005a) additionally focus on end-to-end integration of SWS composition in the larger context. Akkiraju, Srivastava, Anca-Andreea, Goodwin, and Syeda-Mahmood (2006) investigate techniques to disambiguate concept names. McIlraith and Fadel (2002) achieve composition with particular forms of non-atomic services, by modeling the latter as atomic actions that take the meaning of a kind of macro-actions. Narayanan and McIlraith (2002) obtain a composition ability as a side-effect of verifying SWS properties using Petri Nets. Kuter, Sirin, Nau, Parsia, and Hendler (2005), Au, Kuter, and Nau (2005), and Au and Nau (2006) focus on information gathering at composition time, rather than at plan execution time. McDermott (2002) treats the actual interaction (communication) with a web service as a planning problem.\nMediratta and Srivastava (2006) design an approach to WSC based on conditional planning, i.e., a form of planning under uncertainty. While this suggests a close relation to our work, the focus of Mediratta and Srivastava\u2019s work is actually quite different from ours. Mediratta and Srivastava do not consider output variables, and neither do they consider any domain axiomatizations. The\nonly overlap with our formalism lies in that they allow incomplete initial state descriptions, i.e., initial states that assign a value to only a subset of the propositions. They handle observation actions which allow observing the value of any unspecified proposition. To ameliorate the need for complete modeling, they consider a definition of \u201cuser acceptable\u201d plans, where only a subset of the plan branches, as specified by the user, are guaranteed to lead to the goal. The latter may be an interesting option to look into when extending our framework to handle partial observability.\nTwo approaches explore how to adapt formalisms from so-called \u201chand-tailored planning\u201d for SWS composition. The approaches are based on Golog (McIlraith & Son, 2002) and HTN planning (Sirin et al., 2004), respectively. These frameworks enable the human user to provide control information. However, non-deterministic action choice is allowed. If no control information is given, then planning is fully automatic. Hence, in this sense, these frameworks are strictly more powerful than planning without such control information. Further, both approaches are capable of handling advanced plan constructs such as loops and branches. In Golog, the possible plans \u2013 the possible composition solutions \u2013 are described in a kind of logic where high-level instructions are given by the programmer, and the planner will bind these instructions to concrete actions as part of the execution. In HTN, the programmer supplies the planning algorithm with a set of so-called \u201cdecomposition methods\u201d, specifying how a certain task can be accomplished in terms of a combination of sub-tasks. Recursively, there are decomposition methods for those sub-tasks. Thus the overall task can be decomposed in a step-wise fashion, until atomic actions are reached. Neither McIlraith and Son (2002) nor Sirin et al. (2004) are concerned with handling ontology axioms, as we do in this paper. Hence, combining the insights of both directions has synergetic potential, and is an interesting topic for future work.\nAnother approach capable of handling advanced plan constructs (loops, branches) is described by Pistore et al. (2005b), Pistore, Traverso, Bertoli, and Marconi (2005c), Pistore et al. (2005a), and Bertoli, Pistore, and Traverso (2006). In this work, \u201cprocess level\u201d composition is implemented, as opposed to the profile/capability level composition as addressed in this paper. At the process level, the semantic descriptions detail precisely how to interact with the SWS, rather than characterizing them only in terms of preconditions and effects. Pistore et al. (2005b, 2005c, 2005a) and Bertoli et al. (2006) exploit BDD (Binary Decision Diagram) based search techniques to obtain complex solutions fully automatically. However, ontology axioms are not handled and input/output types are matched based on type names.\nThere are only a few approaches where ontology axioms are used and the requirements on the matches are relaxed. One of those is described by Sirin, Hendler, and Parsia (2003), Sirin, Parsia, and Hendler (2004), Sirin and Parsia (2004), and Sirin et al. (2006). In the first two papers of this series (Sirin et al., 2003, 2004), a SWS composition support tool for human programmers is proposed: at any stage during the composition process, the tool provides the user with a list of matching services. The matches are found by examining the subconcept relation. An output A is considered a match of input B if A \u2286 B. This corresponds to plug-in matches. In later work (Sirin & Parsia, 2004; Sirin et al., 2006), the HTN approach (Sirin et al., 2004) mentioned above is adapted to not work on the standard planning semantics, but on the description logics semantics of OWL-S. The difficulties inherent in updating a belief are observed, but the connection to belief update as studied in the literature is not made, and it remains unclear which solution is adopted.\nAs far as we are aware, all other methods with more relaxed matches follow what we have here termed a message-based approach to WSC. These approaches were already discussed in some depth in Section 2.3. Next, we give a few more details on the ones most closely related to our work. The\napproach by Liu et al. (2007) was discussed in sufficient detail already in Section 2.3, so we do not reconsider this here.\nMeyer and Weske (2006) handle ontology axioms in their WSC tool, but do not provide a semantics for action applications. Reasoning is only used to determine whether a particular output can be used to establish a particular input, so the approach can be classified as \u201cmessage-based\u201d, in our terms. The kind of matches handled is said to be plug-in. To the best of our knowledge, this tool is the only existing WSC tool that employs a relaxed plan based heuristic function, like CFF. However, through various design decisions, the authors sacrifice scalability. They explicitly enumerate all world states in every belief, and hence suffer from exponentially large beliefs. They search forward with parallel actions and consequently suffer from a huge branching factor. They take their heuristic to be relaxed planning graph length (rather than relaxed plan length) and thus suffer from the fact that, most of the time, hmax is a much less informative heuristic than h+ (Bonet & Geffner, 2001; Hoffmann, 2005).\nAn approach rather closely related to ours, in that it can handle partial matches, is described by Constantinescu and Faltings (2003) and Constantinescu et al. (2004a, 2004b). In this work the ontology is assumed to take the form of a tree of concepts, where edges indicate the subconcept relation. Such a tree is compiled into intervals, where each interval represents a concept and the contents are arranged to correspond to the tree. The intervals are used for efficient implementation of indexing in service lookup (discovery), as well as for matching during composition. The latter searches forward in a space of \u201cswitches\u201d. Starting at the initial input, if the current input is of type A, then a service with input Ai matches if A \u2229 Ai 6= \u2205. Such services are collected until the set of the collected Ai covers A (that is, until the union of the intervals for the various Ai contains the interval forA). The collected services form a switch, and in the next step of the search, each of their outputs becomes a new input that must be treated (i.e., the switch is an AND node). Composition is interleaved with discovery, i.e., in every search state discovery is called to find the services that match this state. The search proceeds in a depth-first fashion. Major differences to our work are the following. First, the formalization is very different, using intervals vs. using standard notions from planning based on logics. Second, the approach interleaves discovery and composition, which are separate steps in our framework (web service discovery is needed to determine the \u201coperators\u201d of a WSC task). Third, the approach considers concept trees vs. clausal integrity constraints. Last, the approach uses depth-first search, whereas one of the main points we are making is that one can exploit the heuristic techniques implemented in standard planning tools for scalable WSC.\nFinally, an interesting approach related to planning is described by Ambite and Kapoor (2007). To capture the dependencies between different input variables of a web service, the input is described in terms of a relation between those variables. The same is done for the outputs. The relations are formulated in terms of logical formulas relative to an ontology. The underlying formalism is first-order logic, so the modeling language is quite expressive.24 Reasoning is performed in order to establish links (\u201cmessages\u201d, in our terms) between inputs and outputs. The algorithmic framework in which that happens is inspired by partial-order planning (Penberthy & Weld, 1992), starting from the goal relation and maintaining a set of open links. The solution is a DAG of web services where links correspond to different kinds of data exchanges (selection, projection, join, union). Automatic insertion of mediator services, e.g., for converting a set of standard formats, is also supported.\n24. At the cost of undecidable reasoning, which according to the authors is not a major issue in practice.\nTo some extent, our preconditions/effects and clausal integrity constraints can be used to model \u201crelations\u201d in the sense of Ambite and Kapoor (2007). Say r is a k-ary relation with definition \u03c6, describing the input of a web service. We set the corresponding operator\u2019s precondition to r(x1, . . . , xk), and we transform \u03c6 into a set of universally quantified clauses. As long as the latter can be done, and as long as the ontology axioms can be likewise transformed, we obtain a model equivalent to that of Ambite and Kapoor. In that sense, the main modeling advantage of the approach of Ambite and Kapoor over WSC|fwd is existential quantification. It is an open question whether such quantification can be accommodated in our framework. Insertion of mediator services can be supported in WSC|fwd, but only in the limited sense of recognizing, via particular preconditions, that a particular kind of mediator is required. Modeling the actual data flow is bound to be awkward. In summary, the work of Ambite and Kapoor is more advanced than ours from a data description and transformation point of view. On the other hand, Ambite and Kapoor neither consider belief update, nor do they place their work in the context of a fully-fledged planning formalism, and they are less concerned with exploiting the heuristic technologies of recent planners. Combining the virtues of both approaches \u2013 within either framework \u2013 is an interesting direction for further research."}, {"heading": "8. Discussion", "text": "We have suggested a natural planning formalism for a significant notion of web service composition at the profile / capability level, incorporating on-the-fly creation of constants to model outputs, incomplete initial states to model incomplete user input, conditional effects semantics to model partial matches, and, most importantly, clausal integrity constraints to model ontology axioms. We have identified an interesting special case, forward effects, where the semantics of action applications is simpler than in the general case. We have demonstrated how this relates to the belief update literature, and we have shown how it results in reduced computational complexity. Forward effects relate closely to message-based WSC, and our results serve both to put this form of WSC into context, and to extend it towards a more general notion of partial matches. Further, we have identified a compilation into planning under (initial state) uncertainty, opening up an interesting new connection between the planning and WSC areas.\nOur empirical results are encouraging, but should not be over-interpreted. While our test scenarios serve to capture some structural properties that are likely to appear in applications of WSC technology, our approach has yet to be put to the test of actual practice. The same, however, can be said of essentially all current planning-based WSC technology, since that field is still rather immature. In that sense, a more thorough evaluation of our approach, and of planning-based WSC as a whole, is a challenge for the future.\nApart from such evaluation, there are several directions for research improving and extending the technology introduced herein. A line of research that we find particularly interesting is to adapt modern planning tools for WSC, starting from our special cases, where the complications incurred by integrity constraints are more manageable. We have already outlined a few ideas for adapting CFF, and pointed out that new challenges arise. It appears particularly promising to tailor generic heuristic functions, originating in planning, to exploit the typical forms of ontology axioms as occur in practice. Considering the wealth of heuristic functions available by now, this topic alone provides material for a whole family of subsequent work."}, {"heading": "Acknowledgments", "text": "We thank the anonymous reviewers, as well as the managing editor Derek Long, for their comments, which were of significant help for improving the paper.\nJo\u0308rg Hoffmann performed part of this work while being employed at the University of Innsbruck, Austria. His work was partly funded through the European Union\u2019s 6th Framework Programme under the SUPER project (IST FP6-026850, http://www.ip-super.org).\nPiergiorgio Bertoli\u2019s and Marco Pistore\u2019s work was partly supported by the project \u201cSoftware\nMethodology and Technology for Peer-to-Peer Systems\u201d (STAMPS).\nMalte Helmert\u2019s work was partly supported by the German Research Council (DFG) as part of the Transregional Collaborative Research Center \u201cAutomatic Verification and Analysis of Complex Systems\u201d (SFB/TR 14 AVACS). See www.avacs.org for more information."}, {"heading": "Appendix A. Proofs", "text": "We first formally prove Proposition 1, stating that negative effects can be compiled away in WSC. Before we do so, we first need to introduce the compilation formally. Assume a WSC task (P, \u03a6IC ,O, C0, \u03c60, \u03c6G). We construct a secondWSC task (P +,\u03a6+IC ,O +, C0, \u03c60, \u03c6G), where initially P+,\u03a6+IC and O + are the same as P,\u03a6IC and O, respectively. We proceed as follows. Let G \u2208 P be a predicate with arity k, so that there exists o \u2208 O, o = (Xo, preo, Yo, effo) where effo contains a negative literal \u00acG(x1, . . . , xk). We introduce a new predicate notG into P +, and we introduce the two new clauses \u2200x1, . . . , xk : G(x1, . . . , xk) \u2228 notG(x1, . . . , xk) and \u2200x1, . . . , xk : \u00acG(x1, . . . , xk) \u2228 \u00acnotG(x1, . . . , xk). For every operator o whose effect contains a negation of G, we replace, in effo, \u00acG(a1, . . . , ak) with notG(a1, . . . , ak). 25 We continue doing so until no negative effect literals remain in O+. If a is an action in (P,\u03a6IC ,O, C0, \u03c60, \u03c6G) then we denote by a + the corresponding action in (P+,\u03a6+IC ,O +, C0, \u03c60, \u03c6G). We also use this notation vice versa, i.e., if a + is an action in (P+,\u03a6+IC ,O +, C0, \u03c60, \u03c6G) then a denotes the corresponding action in (P,\u03a6IC ,O, C0, \u03c60, \u03c6G). If s = (Cs, Is) is a state using the predicates P , then we denote by s + a state using the predicates P+, with the following properties: Cs+ = Cs; for all p \u2208 P Cs we have Is+(p) = Is(p); for all notp where p \u2208 PCs we have Is+(notp) = 1 iff Is(p) = 0. Since there is, obviously, exactly one such s+, we will also use this correspondence vice versa.\nProposition 1 Assume a WSC task (P, \u03a6IC , O, C0, \u03c60, \u03c6G). Let (P +,\u03a6\u2032+IC ,O +, C0, \u03c60, \u03c6G) be the same task but with negative effects compiled away. Assume an action sequence \u3008a1, . . . , an\u3009. Let b be the result of executing \u3008a1, . . . , an\u3009 in (P, \u03a6IC , O, C0, \u03c60, \u03c6G), and b + is the result of executing \u3008a+1 , . . . , a + n \u3009 in (P +,\u03a6+IC ,O +, C0, \u03c60, \u03c6G). Then, for any state s, we have that s \u2208 b iff s+ \u2208 b+.\nProof: By induction over the length of the action sequence in question. If the sequence is empty, then we have to consider the initial beliefs of the two tasks, for which the claim follows directly by definition. For the inductive step, say that the claim holds for b and b+, and a is an action. We need to show that, for any state s, we have that s \u2208 res(b, a) iff s+ \u2208 res(b+, a+).\nFor the direction from right to left, say s+ \u2208 res(b+, a+). By definition we have s+ \u2208 res(s+0 , a +) for a state s+0 \u2208 b +. By induction hypothesis, s0 \u2208 b. It therefore suffices to show that\n25. The arguments ai here may be either variables or constants.\ns \u2208 res(s0, a). We need to show that (1) s |= \u03a6IC \u2227 effa and (2) s differs from s0 in a set-inclusion minimal set of values. (1) is obvious from the definitions. Assume to the contrary of (2) that there exists s1 so that s1 |= \u03a6IC \u2227 effa and s1 is identical to s except that there exists at least one proposition p where s1(p) = s0(p) but s(p) 6= s0(p). By definition, we get that s + 1 |= \u03a6 + IC \u2227 effa+ . Further, we get that s+1 (p) = s + 0 (p) but s +(p) 6= s+0 (p), and altogether that s + 1 <s+\n0\ns+. This is a\ncontradiction to s+ \u2208 res(s+, a+), and hence proves that s \u2208 res(s0, a) as desired. The direction from left to right proceeds in the same fashion. Say s \u2208 res(b, a). By definition we have s \u2208 res(s0, a) for a state s0 \u2208 b. By induction hypothesis, s + 0 \u2208 b +. It then suffices to show that s+ \u2208 res(s+0 , a +). We need to show that (1) s+ |= \u03a6+IC \u2227 effa and (2) s\n+ differs from s+0 in a set-inclusion minimal set of values. (1) is obvious from the definitions. Assume to the contrary of (2) that there exists s+1 so that s + 1 |= \u03a6 + IC \u2227 effa+ and s + 1 is identical to s + except that there exists at least one proposition p where s+1 (p) = s + 0 (p) but s\n+(p) 6= s+0 (p). By definition, we get that s1 |= \u03a6IC \u2227 effa. Further, if p \u2208 P\nCs0 then we get that s1(p) = s0(p) but s(p) 6= s0(p). If p = notq 6\u2208 PCs0 then we get the same property for q. Altogether, we get that s1 <s0 s. This is a contradiction to s \u2208 res(s, a), and hence proves that s+ \u2208 res(s+0 , a +) as desired. 2\nTheorem 1 Assume a WSC task with fixed arity, and a sequence \u3008a1, . . . , an\u3009 of actions. It is \u03a0p2-complete to decide whether \u3008a1, . . . , an\u3009 is a plan. Proof: Membership is proved by a guess-and-check argument. First, observe that, for arbitrary s, s\u2032, and A, we can decide within coNP whether s\u2032 \u2208 res(s,A). Guess a state s\u2032\u2032 where Cs\u2032\u2032 = Cs \u222aEa. Check whether s\u2032\u2032 |= \u03a6IC \u2227 effa. Check whether Is\u2032 6\u2264s Is\u2032\u2032 . Then s\n\u2032 \u2208 res(s, a) iff no guess succeeds. Further, for an action a, deciding whether a is inconsistent is, obviously, equivalent to a satisfiability test, so this is contained in NP. With these instruments at hand, we can design a guess-and-check procedure to decide whether \u3008a1, . . . , an\u3009 is a plan. We guess the proposition values along \u3008a1, . . . , an\u3009. We then check whether these values comply with res, and lead to an inconsistent action, or to a final state that does not satisfy the goal. In detail, the checking proceeds as follows. First, check whether the initial proposition values satisfy \u03a6IC \u2227 \u03c60. If not, stop without success. Otherwise, iteratively consider each action ai, with pre-state s and post-state s \u2032. Check with an NP oracle whether a is inconsistent. If yes, stop with success. If not, test with an NP oracle whether s\u2032 \u2208 res(s, a). If not, stop without success. Otherwise, if i < n, then go on to ai+1. If i = n, then test whether s\u2032 |= \u03c6G. Stop with success if s \u2032 6|= \u03c6G, stop without success if s \u2032 |= \u03c6G. \u3008a1, . . . , an\u3009 is a plan iff no guess of proposition values is successful. Hardness follows by the following adaptation of the proof of Lemma 6.2 from Eiter and Gottlob (1992). Validity of a QBF formula \u2200X.\u2203Y.\u03c6[X,Y ], where \u03c6 is in CNF, is reduced to plan testing for a single action a. We use the 0-ary predicates X = {x1, . . . , xm}, Y = {y1, . . . , yn}, and new 0-ary predicates {z1, . . . , zm, r, t}. The set of operators contains the single operator o with empty in/out parameters, empty precondition, and effect t. The initial constants are empty; \u03c60 is the conjunction of all xi, all yi, all zi, r, and \u00act; \u03c6G is r. The theory is:\n( m \u2227\ni=1\n(\u00act \u2228 xi \u2228 zi)) \u2227 ( m \u2227\ni=1\n(\u00act \u2228 \u00acxi \u2228 \u00aczi)) \u2227 ( \u2227\nC\u2208\u03c6\n(\u00act \u2228 \u00acr \u2228 C)) \u2227 ( n \u2227\ni=1\n(\u00act \u2228 \u00acyi \u2228 r))\nwhere \u03c6 is viewed as a set of clauses C. More readably, the theory is equivalent to:\nt \u21d2 [( m \u2227\ni=1\nxi \u2261 \u00aczi) \u2227 (r \u21d2 \u03c6) \u2227 (( n \u2228\ni=1\nyi) \u21d2 r)]\nWe refer to the initial belief as b. The plan to test contains the single action a based on (equal to, in fact) o. We refer to the resulting belief as b\u2032. Obviously, b contains a single state s where everything except t is true. Also, a is consistent: any interpretation that sets r and all yi to 0 satisfies\u03a6IC\u2227effa.\nThe theory conjuncts xi \u2261 \u00aczi make sure that each w \u2208 b \u2032 makes exactly one of xi, zi true. In particular, the different assignments to X are incomparable with respect to set inclusion. Hence, we have that for every assignment aX of truth values to X , there exists a state s\n\u2032 \u2208 b\u2032 that complies with aX : aX is satisfiable together with \u03a6IC \u2227 effa, and any other assignment a \u2032 X is more distant from s in at least one variable (e.g., if a\u2032X(xi) = 1 and aX(xi) = 0 then aX is closer to s than a \u2032 X regarding the interpretation of zi). We now prove that, if a is a plan, then \u2200X.\u2203Y.\u03c6[X,Y ] is valid. Let aX be a truth value assignment to X . With the above, we have a state s\u2032 \u2208 b\u2032 that complies with aX . Since a is a plan, we have s\u2032 |= r. Therefore, due to the theory conjunct r \u21d2 \u03c6, we have s\u2032 |= \u03c6. Obviously, the values assigned to Y by s\u2032 satisfy \u03c6 for aX .\nFor the other direction, say \u2200X.\u2203Y.\u03c6[X,Y ] is valid. Assume that, contrary to the claim, a is not a plan. Then we have s\u2032 \u2208 b\u2032 so that s\u2032 6|= r. But then, due to the theory conjunct (\n\u2228n i=1 yi) \u21d2 r,\nwe have that s sets all yi to false. Now, because \u2200X.\u2203Y.\u03c6[X,Y ] is valid, there exists a truth value assignment aY to Y that complies with the setting of all xi and zi in s. Obtain s \u2032\u2032 by modifying s\u2032 to comply with aY , and setting r to 1. We have that s \u2032\u2032 |= \u03a6IC \u2227 effa. But then, s\n\u2032\u2032 is closer to s than s\u2032, and hence s\u2032 6\u2208 b\u2032 in contradiction. This concludes the argument. 2\nTheorem 2. Assume aWSC task with fixed arity, and a natural number b in unary representation. It is \u03a3p3-complete to decide whether there exists a plan of length at most b.\nProof: For membership, guess a sequences of actions containing at most b actions (note that the size of such a sequence is polynomial in the size of the input representation). By Theorem 1, we can check with a \u03a0p2 oracle whether the sequence is a plan. Hardness follows by an extension of the proof of Lemma 6.2 of Eiter and Gottlob (1992). Validity of a QBF formula \u2203X.\u2200Y.\u2203Z.\u03c6[X,Y, Z], where \u03c6 is in CNF, is reduced to testing plan existence. We use the 0-ary predicates X = {x1, . . . , xn}, Y = {y1, . . . , ym}, Z = {z1, . . . , zk}, and new 0-ary predicates {q1, . . . , qm, r, t, f1, . . . fn, h, g}. The set of operators is composed of:\n\u2022 ot := (\u2205, f1 \u2227 \u00b7 \u00b7 \u00b7 \u2227 fn \u2227 h, \u2205, t \u2227 g \u2227 \u00ach)\n\u2022 For 1 \u2264 i \u2264 n: oxi := (\u2205, h, \u2205, xi \u2227 fi)\n\u2022 For 1 \u2264 i \u2264 n: o\u00acxi := (\u2205, h, \u2205,\u00acxi \u2227 fi)\nThe initial constants are empty. The initial literal conjunction \u03c60 is composed of all yi, all zi, all qi, r, \u00act, all \u00acfi, h, and \u00acg. That is, the yi, zi, and qi as well as r and h are true, while the fi as well as t and g are false. No value is specified (only) for the xi. The goal \u03c6G is r \u2227 g. The theory is:\n( m \u2227\ni=1\n(\u00act \u2228 yi \u2228 qi)) \u2227 ( m \u2227\ni=1\n(\u00act \u2228 \u00acyi \u2228 \u00acqi)) \u2227 ( \u2227\nC\u2208\u03c6\n(\u00act \u2228 \u00acr \u2228 C)) \u2227 ( n \u2227\ni=1\n(\u00act \u2228 \u00aczi \u2228 r))\nwhere \u03c6 is viewed as a set of clauses C. More readably, the theory is equivalent to:\nt \u21d2 [( m \u2227\ni=1\nyi \u2261 \u00acqi) \u2227 (r \u21d2 \u03c6) \u2227 (( n \u2228\ni=1\nzi) \u21d2 r)]\nFirst, note a few obvious things about this construction:\n\u2022 ot must be included in any plan.\n\u2022 Once ot is applied, no action can be applied anymore.\n\u2022 Before ot is applied, either oxi or o\u00acxi must be applied, for every 1 \u2264 i \u2264 n.\n\u2022 The theory is \u201cswitched off\u201d, i.e., made irrelevant because t is false, up to the point where ot\nis applied.\nThat is, any plan for this task must first apply oxi or o\u00acxi , for every 1 \u2264 i \u2264 n, thereby choosing a value for every xi. Then, o\nt must be applied and the plan must stop. Before applying ot, no changes are made to the states except that the values of xi are set and that the fi are made true one after the other. Hence, the belief b in which ot is applied contains a single state s which corresponds to an extension of \u03c60 with a value assignment for X , where the values of the fi have been flipped. We denote the value assignment for X in s with aX . We further denote b\n\u2032 := res(b, ot). Note that ot is consistent: any interpretation that sets r and all zi to 0, besides setting the immediate effects t\u2227 g \u2227\u00ach, satisfies \u03a6IC \u2227 effot . Obviously, all of the applications of o\nxi and o\u00acxi are consistent as well.\nThe theory conjuncts yi \u2261 \u00acqi make sure that each w \u2208 b \u2032 makes exactly one of yi, qi true. In particular, the different assignments to Y are incomparable with respect to set inclusion. Hence, we have that for every assignment aY of truth values to Y , there exists a state s\n\u2032 \u2208 b\u2032 that complies with aY : aY is satisfiable together with \u03a6IC \u2227 effot , and any other assignment a \u2032 Y is more distant from s in at least one variable (e.g., if a\u2032Y (yi) = 1 and aY (yi) = 0 then aY is closer to s than a \u2032 Y regarding the interpretation of qi). We now prove that, if there exists a plan ~a yielding assignment aX , then \u2203X.\u2200Y.\u2203Z.\u03c6[X,Y, Z] is valid. Let aY be an arbitrary truth value assignment to Y . Then we have a state s \u2032 \u2208 b\u2032 that complies with aX and aY . aX and aY are satisfiable together with \u03a6IC \u2227 effot . With the above, any other assignment a\u2032Y is more distant from s in at least one variable. And, of course, if one deviates from aX then one is more distant from s in the respective variable. Since~a is a plan, we have s\n\u2032 |= r. Therefore, due to the theory conjunct r \u21d2 \u03c6, we have s\u2032 |= \u03c6. Obviously, the values assigned to Z by s\u2032 satisfy \u03c6 for aX and aY . This proves the claim because aY can be chosen arbitrarily.\nFor the other direction, say \u2203X.\u2200Y.\u2203Z.\u03c6[X,Y, Z] is valid. Let aX be an assignment toX so that \u2200Y.\u2203Z.\u03c6[aX/X, Y, Z] is valid. Let ~a be the corresponding plan, i.e., ~a first applies, for 1 \u2264 i \u2264 n, either oxi or o\u00acxi according to aX . Thereafter, ~a applies o\nt. Assume that ~a is not a plan. Then we have s\u2032 \u2208 b\u2032 so that s\u2032 6|= r. But then, due to the theory conjunct (\n\u2228n i=1 zi) \u21d2 r, we have that s sets\nall zi to false. Now, because \u2200Y.\u2203Z.\u03c6[aX/X, Y, Z] is valid, there exists a truth value assignment aZ to Z that complies with the setting of all xi, yi, and qi in s. Obtain s\n\u2032\u2032 by modifying s\u2032 to comply with aZ , and setting r to 1. We have that s \u2032\u2032 |= \u03a6IC \u2227 effot . But then, s \u2032\u2032 is closer to s than s\u2032, and hence s\u2032 6\u2208 b\u2032 in contradiction. This concludes the argument. 2\nTheorem 3. Assume a WSC task. The decision problem asking whether there exists a plan is undecidable.\nProof: This result holds even with an empty background theory, a complete specification of the initial state, predicates of arity at most 2, operators of arity at most 2, a goal with no variables at all (arity 0), and only positive literals in preconditions and the goal. The result follows with a minor modification of Tom Bylander\u2019s proof (Bylander, 1994) that plan existence in propositional STRIPS planning is PSPACE-complete.26 The original proof proceeds by a generic reduction, constructing a STRIPS task for a Turing Machine (TM) with polynomially bounded space. The latter restriction is necessary to model the machine\u2019s tape: tape cells are pre-created for all positions within the bound. What makes the difference between PSPACE-membership and undecidability is the ability to create constants. We can introduce simple operators that allow us to extend the tape, at both ends.\nIn detail, say the TM has (a finite number of) states q and tape alphabet symbols a (where b is the blank); \u03b4 is the transition function, q0 is the initial state, and F is the set of accepting states; \u03c9 is the input word. Our planning encoding contains the following predicates. State(q) indicates that the current TM state is q. In(a, c) indicates that the current content of tape cell c is a. Neighbors(c, c\u2032) is true iff c\u2032 is the (immediate) right neighbor of c. At(c) indicates that the current position of the TM head is c. Rightmost(c) (Leftmost(c)) is true iff c currently has no right (left) neighbor. The set of initial constants contains all states q, all alphabet symbols a, and tape cells c corresponding to \u03c9. By the initial literals, all the propositions over these constants are assigned truth values as obvious. For every transition (q, a, q\u2032, a\u2032, R) \u2208 \u03b4 we include an operator:\n({x, x\u2032}, State(q) \u2227 In(x, a) \u2227Neighbors(x, x\u2032) \u2227At(x),\n\u2205, State(q\u2032) \u2227 \u00acState(q) \u2227 In(x, a\u2032) \u2227 \u00acIn(x, a) \u2227At(x\u2032) \u2227 \u00acAt(x)).\nObviously, this encodes exactly that transition. We do likewise for transitions (q, a, q\u2032, a\u2032, L) \u2208 \u03b4. To model the final states, we introduce a 0-ary predicateG, and include for each q \u2208 F an operator:\n(\u2205, State(q), \u2205, G)\nWe finally include the operators:\n({x}, Rightmost(x), {x\u2032}, Neighbors(x, x\u2032) \u2227 In(b, x\u2032) \u2227Rightmost(x\u2032) \u2227 \u00acRightmost(x))\nand\n({x\u2032}, Leftmost(x\u2032), {x}, Neighbors(x, x\u2032) \u2227 In(b, x) \u2227 Leftmost(x) \u2227 \u00acLeftmost(x\u2032))\nWith these definitions, it is easy to verify that there exists a plan iff the TM can reach an accepting state on \u03c9. 2\nLemma 1. Assume a WSC|fwd task, a reachable state s, and an action a. Then res(s, a) = res|fwd(s, a).\n26. Propositional STRIPS is like our framework, but with an empty background theory, a complete specification of\nthe initial state, a goal with no variables, only positive literals in preconditions and the goal, and with no output parameters in the operators.\nProof: If a is not applicable to s, then the claim holds trivially. Consider the other case. By Equation 3, res(s, a) is defined as\nres(s, a) :=\n{\n{(C \u2032, I \u2032) | C \u2032 = Cs \u222a Ea, I \u2032 \u2208 min(s, C \u2032,\u03a6IC \u2227 effa)} appl(s, a) {s} otherwise\nwheremin(s, C \u2032,\u03a6IC \u2227 effa) is the set of all C \u2032-interpretations that satisfy \u03a6IC \u2227 effa and that are minimal with respect to the partial order defined by I1 \u2264s I2 :iff for all propositions p over Cs, if I2(p) = Is(p) then I1(p) = Is(p).\nIt is obvious that res|fwd(s, a) \u2286 res(s, a) \u2013 if Is\u2032 satisfies \u03a6IC \u2227 effa and Is\u2032 is identical to Is on the propositions over Cs, then in particular Is\u2032 is minimal according to \u2264s.\nFor the other direction, let s\u2032 \u2208 res(s, a). Assume that Is\u2032(p) 6= Is(p) for some proposition p over Cs. Define s\n\u2032\u2032 to be equal to s\u2032 except that Is\u2032\u2032(p) := Is(p). Obviously, Is\u2032 6\u2264s\u2032\u2032 I2. It now suffices to show that s\u2032\u2032 |= \u03a6IC \u2227 effa: then, we get Is\u2032 6\u2208 min(s, C\n\u2032,\u03a6IC \u2227 effa) in contradiction, hence Is\u2032 agrees with Is on all propositions p over Cs, hence s\n\u2032 \u2208 res|fwd(s, a). As before, denote with PCs+Ea the set of all propositions with arguments in Cs \u222a Ea, and with at least one argument in E, and denote with \u03a6IC [Cs + Ea] the instantiation of \u03a6IC with all constants from Cs \u222a Ea, where in each clause at least one variable is instantiated from Ea. To see that s\u2032\u2032 |= \u03a6IC \u2227 effa, consider first that this is equivalent to s\n\u2032\u2032 |= \u03a6IC [Cs \u222a Ea] \u2227 effa, which in turn is equivalent to s\u2032\u2032 |= \u03a6IC [Cs]\u2227\u03a6IC [Cs+Ea]\u2227effa. In the last formula, because the task is in WSC|fwd,\u03a6IC [Cs] speaks only over the propositionsP\nCs , whereas\u03a6IC [Cs+Ea]\u2227effa speaks only over the propositions PCs+Ea . So we can treat these two parts separately. We have s\u2032\u2032 |= \u03a6IC [Cs] because s |= \u03a6IC [Cs] by prerequisite since s is reachable. We have s\n\u2032\u2032 |= \u03a6IC [Cs + Ea] \u2227 effa by definition. This concludes the argument. 2\nTheorem 4. Assume a WSC|fwd task with fixed arity, and a sequence \u3008a1, . . . , an\u3009 of actions. It is coNP-complete to decide whether \u3008a1, . . . , an\u3009 is a plan.\nProof: Hardness is obvious, considering an empty sequence. Membership can be shown by the following guess-and-check argument. Say C is the union of C0 and all output constants appearing in \u3008A1, . . . , An\u3009. We guess an interpretation I of all propositions over P and C. Further, for each 1 \u2264 t \u2264 n, we guess a set Ct of constants. We can then check in polynomial time whether I and the Ct correspond to an execution of \u3008A1, . . . , An\u3009. For 1 \u2264 t \u2264 n and a \u2208 At, say that a is applicable if I |= prea, Ca \u2286 Ct, and Ea \u2229 Ct = \u2205. First, we assert I |= \u03a6IC . Second, for all t and for all a \u2208 At, assert that, if a is applicable, then I |= effa. Third, assert that Ct+1 = Ct \u222a {Ea | a \u2208 At, a is applicable}. Using Lemma 1, it is easy to see that I and the Ct correspond to an execution iff all three assertions hold. Note that I needs not be time-stamped because once an action has generated its outputs then the properties of the respective propositions remain fixed forever. The claim follows because, with fixed arity, we can also test in polynomial time whether I and Cn satisfy \u03c6G. A guess of I and Ct is successful if it corresponds to an execution and does not satisfy \u03c6G. Obviously, \u3008A1, . . . , An\u3009 is a plan iff there is no such guess of I and Ct. 2\nTheorem 5. Assume a WSC|fwd task with fixed arity, and a natural number b in unary representation. It is \u03a3p2-complete to decide whether there exists a plan of length at most b.\nProof: For membership, guess a sequence of at most b actions. By Theorem 1, we can check with a \u03a0p2 oracle whether the sequence is a plan.\nTo prove hardness, assume a QBF formula \u2203X.\u2200Y.\u03c6[X,Y ] where \u03c6 is in DNF normal form. (This formula class is complete for \u03a3p2.) SayX = x1, . . . , xn, Y = y1, . . . , ym, and \u03c6 = \u03c61 \u2228 \u00b7 \u00b7 \u00b7 \u2228 \u03c6k. We design a WSC|fwd task which has a plan iff \u2203X.\u2200Y.\u03c6[X,Y ] is true. The key construction is to use outputs for the creation of \u201ctime steps\u201d, and to allow setting xi only at time step i. The yi can take on arbitrary values. Once all xi are set, one operator per \u03c6k allows to achieve the goal given \u03c6k is true. The main property we need to ensure in the construction is that each xi can be set at most once, i.e., either to 1 or to 0. Then there is a plan for the task iff one can set X so that, for all Y , at least one \u03c6i is true \u2013 which is the case iff \u2203X.\u2200Y.\u03c6[X,Y ] is true.\nThe predicates for our task are P = {x1(.), . . . , xn(.), y1(), . . . , ym(), time(.), start(.), next(..), goal(.)}. We indicate predicate arity here by the number of points in the parentheses. For example, the predicate next(..) has arity 2. The theory \u03a6IC is empty. The initial constants are C0 = {t0}. The initial literals are \u03c60 = time(t0). The goal is \u2203y.goal(y). The operators are as follows:\n\u2022 For all 1 \u2264 i \u2264 n, we have: oxi1 = ({t0, . . . , ti\u22121}, start(t0)\u2227 next(t0, t1) \u2227 \u00b7 \u00b7 \u00b7 \u2227 next(ti\u22122, ti\u22121), {ti}, time(ti)\u2227next(ti\u22121, ti)\u2227xi(ti)). Such an operator allows generating time step i, and setting xi to 1 at that step.\n\u2022 For all 1 \u2264 i \u2264 n, we have: oxi0 = ({t0, . . . , ti\u22121}, start(t0)\u2227 next(t0, t1) \u2227 \u00b7 \u00b7 \u00b7 \u2227 next(ti\u22122, ti\u22121), {ti}, time(ti) \u2227 next(ti\u22121, ti) \u2227 \u00acxi(ti)). Such an operator allows generating time step i, and setting xi to 0 at that step.\n\u2022 We will define a value B below. For all n \u2264 j < n + B, we have: otj = ({t0, . . . , tj\u22121}, start(t0)\u2227 next(t0, t1) \u2227 \u00b7 \u00b7 \u00b7 \u2227 next(tj\u22122, tj\u22121), {tj}, time(tj) \u2227 next(tj\u22121, tj)). These operators allow increasing the time step from n to n+B.\n\u2022 For 1 \u2264 i \u2264 k, say \u03c6i = xlxj1 \u2227 \u00b7 \u00b7 \u00b7 \u2227 xlxjxn\u2227 ylyj1 \u2227 \u00b7 \u00b7 \u00b7 \u2227 ylyjyn where xlj \u2208 {xj ,\u00acxj} and ylj \u2208 {yj ,\u00acyj}. We have: o\n\u03c6i = ({t0, . . . , tn+B}, start(t0)\u2227 next(t0, t1) \u2227 \u00b7 \u00b7 \u00b7 \u2227 next(tn+B\u22121, tn+B)\u2227 xlxj1(txj1) \u2227 \u00b7 \u00b7 \u00b7 \u2227 xlxjxn(txjxn)\u2227 ylyj1() \u2227 \u00b7 \u00b7 \u00b7 \u2227 ylyjyn(), {c}, goal(c)). Such an operator allows to achieve the goal after time step n + B, provided the respective \u03c6i is true. Note here that the xj precondition literals refer to time step tj , i.e., the value set for xj at an earlier time step, while the yj precondition literals have no arguments and refer to the initial values of yj , which are arbitrary.\nAssume we choose any value for B (polynomial in the input size). If \u2203X.\u2200Y.\u03c6[X,Y ] is true, then, obviously, we can find a plan of size n+B+k. We apply an oxi1 or oxi0 operator for each xi, depending on whether xi must be set to 1 or 0. We apply B operators o tj . We apply all operators o\u03c6i . The respective input parameter instantiations are all obvious. The opposite direction \u2013 proving truth of \u2203X.\u2200Y.\u03c6[X,Y ] based on a plan \u2013 is more problematic. The plan might \u201ccheat\u201d by setting some xi to both 1 and 0. The reason why our construction is so complicated is to be able to avoid precisely this case, based on specifying a strict enough plan length bound b. The key property is that, in order to cheat for xi, the plan has to generate two sequences of time steps ti, . . . , tn+B . Therefore, a lower bound on the length for a cheating plan is n + 2B. As we have already seen, an upper bound on the length of a non-cheating plan is n + B + k. To determine our plan length bound b, we now simply choose aB so that any cheating plan will have to use too many steps: n+2B > n+B+k is the case iffB > k. So we can setB := k+1, and obtain b := n+ 2k + 1. With this bound b, any plan will proceed by setting each xi to a value (n actions),\nincreasing the time step to n+B = n+k+1 (k+1 actions), and applying a sufficient subset of the o\u03c6i (at most k actions). If the plan cheats, then it needs to apply at least n+2B = n+2k+2 actions before being able to apply o\u03c6i actions exploiting different value settings for a xi. This concludes the argument. 2\nTheorem 6. Assume a WSC|fwd task. The decision problem asking whether there exists a plan is undecidable.\nProof: We reduce from the halting problem for Abacus machines, which is undecidable. An Abacus machine consists of a tuple of integer variables v1, . . . , vk (ranging over all positive integers including 0), and a tuple of instructions I1, . . . , In. A state is given by the content of v1, . . . , vk plus the index pc of the active instruction. The machine stops iff it reaches a state where pc = n. All vi are initially 0, and pc is initially 0. There are two kinds of instructions. Ii : INC j;GOTO Ii\u2032 increments the value of vj and jumps to pc = i\n\u2032. Ii : DEC j;BRANCH Ii+/Ii0 asks whether vj = 0. If so, it jumps to pc = i0. Otherwise, it decrements the value of vj and jumps to pc = i +.\nWe map an arbitrary abacus program to aWSC|fwd instance as follows: \u2022 Predicates: number(v), zero(v), succ(v\u2032, v), value1(v, t), . . . , valuek(v, t), instruction1(t), . . . , instructionn(t)\n\u2022 Background theory: none (i.e., the trivial theory)\n\u2022 Operators:\n\u2013 An operator \u3008{v}, {number(v)}, {v\u2032}, {number(v\u2032), succ(v\u2032, v)}\u3009\n\u2013 For instructions of the form Ii : INC j;GOTO Ii\u2032 , the operator\n\u3008{v1, . . . , vk, t},\n{instructioni(t), value1(v1, t), . . . , valuek(vk, t), succ(v \u2032, vj)}, {t\u2032}, {instructioni\u2032(t \u2032), value1(v1, t \u2032), . . . , valuej\u22121(vj\u22121, t \u2032), valuej(v \u2032, t\u2032),\nvaluej+1(vj+1, t \u2032), . . . , valuek(vk, t \u2032)}\u3009.\n\u2013 For instructions of the form Ii : DEC j;BRANCH Ii+/Ii0 , the operators\n\u3008{v1, . . . , vk, t},\n{instructioni(t), value1(v1, t), . . . , valuek(vk, t), succ(vj , v \u2032)}, {t\u2032}, {instructioni+(t \u2032), value1(v1, t \u2032), . . . , valuej\u22121(vj\u22121, t \u2032), valuej(v \u2032, t\u2032),\nvaluej+1(vj+1, t \u2032), . . . , valuek(vk, t \u2032)}\u3009.\nand\n\u3008{v1, . . . , vk, t},\n{instructioni(t), value1(v1, t), . . . , valuek(vk, t), zero(vj)}, {t\u2032}, {instructioni0(t \u2032), value1(v1, t \u2032), . . . , valuej\u22121(vj\u22121, t \u2032), valuej(vj , t \u2032),\nvaluej+1(vj+1, t \u2032), . . . , valuek(vk, t \u2032)}\u3009.\n\u2022 Initial constants: v0, t0\n\u2022 Initial literals: number(v0)\u2227zero(v0)\u2227value1(v0, t0)\u2227\u00b7 \u00b7 \u00b7\u2227valuek(v0, t0)\u2227instruction1(t0)\n\u2022 Goal condition: \u2203t.instructionn(t)\nWe now describe the intuitive meaning of the constants and predicates. There are two kinds of constants: numbers, which represent natural numbers (including 0), and time points, which represent computation steps of the Abacus machine. Variables that refer to time points are denoted as t or t\u2032 above. All other variables represent numbers.\nThree predicates refer to numbers exclusively: number(v) is true iff v encodes a natural number (and not a time point); zero(v) is true iff v encodes the number 0; and succ(v\u2032, v) is true iff v\u2032 encodes the number that is one larger than the number encoded by v. The reduction does not enforce that every number is uniquely represented (e.g., there may be several representations of the number 3), but such a unique representation is not necessary. It is guaranteed that the number 0 is uniquely represented, though.\nThe remaining predicates encode configurations of the Abacus machine: valuei(v, t) is true iff, at time point t, the i-th Abacus variable holds the number represented by v, and instructionj(t) is true iff the current instruction at time point t is Ij .\nObviously, from an accepting run of the Abacus machine we can extract a plan for the task, and vice versa. This proves the claim. 2\nTo prove Theorems 7 and 8, we first establish a core lemma from which both theorems follow relatively easily. We need a few notations. We denote beliefs (states) in (P,\u03a6IC ,O, C0, \u03c60, \u03c6G) with b (s), and we denote beliefs (states) in (P \u2032,A, \u03c6\u20320, \u03c6 \u2032 G) with b (s). Assume a sequence \u3008a1, . . . , ai\u3009 of non-goal achievement actions. Then we denote b := res(b0, \u3008a1, . . . , ai\u3009) and b := res(b0, \u3008a1, . . . , ai\u3009). Note here that we overload the res function to also denote state transitions in the compiled task formalism. Further, for a state s, by C(s) := {c | s(Ex(c)) = 1} we denote the constants that exist in s. We denote by \u2261C the relation over states s and s \u2032 that is true iff C(s) = C(s\u2032) and s|C(s) = s \u2032|C(s). \u2261C is an equivalence relation, where equivalent states agree on which constants exist and how they are interpreted. Note that every state s reachable in the compiled task satisfies s |= \u03a6IC \u2227\u03c60\u2227 \u2227 o\u2208O effo[Eo]. Note further that \u03a6IC \u2227\u03c60\u2227 \u2227\no\u2208O effo[Eo] is actually satisfiable be prerequisite, unless \u03a6IC \u2227\u03c60 is unsatisfiable, because the outputs are instantiated with unique constants and the operators are consistent. For a state s, we define [s] :=\n{s | s defined over C0 \u222a \u22c3\no\u2208O\nEo, C(s) = Cs, s|Cs = Is, s |= \u03a6IC \u2227 \u03c60 \u2227 \u2227\no\u2208O\neffo[Eo]}\nThat is, [s] is the equivalence class of states s reachable in the compiled task that agree with s on which constants exist and how they are interpreted.\nLemma 3 Assume a WSC|sfwd task without inconsistent operators. Let \u3008a1, . . . , ai\u3009 consist of non-goal achievement actions, and let b := res(b0, \u3008a1, . . . , ai\u3009) and b := res(b0, \u3008a1, . . . , ai\u3009). Then b = \u22c3\ns\u2208b[s].\nProof: The proof is by induction over i. In the base case, we have i = 0, i.e., b = b0 and b = b0. We have b0 =\n{s | Cs = C0, Is |= \u03a6IC \u2227 \u03c60}\nOn the other hand, we have b0 =\n{s | C(s) = C0, s |= \u03a6IC \u2227 \u03c60 \u2227 \u2227\no\u2208O\neffo[Eo]}\nObviously, the latter is comprised of one equivalence class for each possibility to assign the propositions over C0 in a way compliant with \u03a6IC \u2227 \u03c60. This is exactly the claim. In the inductive case, say we add another action a to \u3008a1, . . . , ai\u3009. By induction assumption, we have b = \u22c3\ns\u2208b[s]. We need to prove that res(b, a) = \u22c3 s\u2032\u2208res(b,a)[s \u2032]. Obviously, it suffices to prove\nthat, for every s \u2208 b, we have res([s], a) = \u22c3 s\u2032\u2208res(s,a)[s \u2032]. First, say a is not applicable to s. Then s is neither applicable in any s \u2208 [s], and we have res([s], a) = [s] = \u22c3\ns\u2032\u2208res(s,a)[s \u2032]. Second, say\na is applicable to s. Then by Lemma 1 we have res(s, a) =\n{(Cs \u222a Ea, I \u2032) | I \u2032|Cs = Is, I \u2032 |= \u03a6IC \u2227 effa}\nOn the other hand, we have res([s], a) =\n{s\u2032 | ex. s \u2208 [s], C(s\u2032) = C(s) \u222a Ea, s \u2032|C(s) = s, s \u2032 |= \u03a6IC \u2227 \u03c60 \u2227 \u2227\no\u2208O\neffo[Eo]}\nWe can re-write the latter into\n{s\u2032 | C(s\u2032) = Cs \u222a Ea, s \u2032|Cs = Is, s \u2032 |= \u03a6IC \u2227 \u03c60 \u2227 \u2227\no\u2208O\neffo[Eo]}\nObviously, as desired, the latter set is comprised of one equivalence class for each possibility to assign the propositions over Cs \u222aEa in a way compliant with s and \u03a6IC \u2227 effa. This concludes the argument. 2\nTheorem 7. Assume a WSC|sfwd task (P,\u03a6IC ,O, C0, \u03c60, \u03c6G) without inconsistent operators, and a plan \u3008a1, . . . , an\u3009 for the compiled task (P \u2032,A, \u03c6\u20320, \u03c6 \u2032 G). Then the sub-sequence of non-goal achievement actions in \u3008a1, . . . , an\u3009 is a plan for (P,\u03a6IC ,O, C0, \u03c60, \u03c6G).\nProof: If \u03a6IC \u2227 \u03c60 is unsatisfiable, there is nothing to prove, because the start belief of the original task is empty. For the non-trivial case, first note that, in any plan for the compiled task, the goal achievement actions can be moved to the back of the plan. Hence, without loss of generality, we can assume that \u3008a1, . . . , ai\u3009 consist entirely of non-goal achievement actions, and \u3008ai+1, . . . , ai\u3009 consist entirely of goal achievement actions. Denote b := res(b0, \u3008a1, . . . , ai\u3009) and b := res(b0, \u3008a1, . . . , ai\u3009). By Lemma 3, we have b = \u22c3\ns\u2208b[s]. Since \u3008a1, . . . , an\u3009 is a plan for the compiled task, every s \u2208 b has a tuple of constants satisfying \u03c6G. With b = \u22c3\ns\u2208b[s], it follows that every s \u2208 b satisfies \u03c6G. 2\nTheorem 8. Assume a WSC|sfwd task (P,\u03a6IC ,O, C0, \u03c60, \u03c6G) without inconsistent operators, and a plan \u3008a1, . . . , an\u3009 where every operator o appears with at most one instantiation Eo of the outputs. Then \u3008a1, . . . , an\u3009 can be extended with goal achievement actions to form a plan for the compiled task (P \u2032,A, \u03c6\u20320, \u03c6 \u2032 G) obtained using the outputs Eo.\nProof: Denote b := res(b0, \u3008a1, . . . , an\u3009) and b := res(b0, \u3008a1, . . . , an\u3009). By Lemma 3, we have b = \u22c3\ns\u2208b[s]. Since \u3008a1, . . . , an\u3009 is a plan, every s \u2208 b satisfies \u03c6G. With b = \u22c3\ns\u2208b[s], it follows that every s \u2208 b has a tuple of constants satisfying \u03c6G. Attaching all the respective goal achievement actions yields a plan for the compiled task. 2"}], "references": [], "referenceMentions": [], "year": 2009, "abstractText": "Thanks to recent advances, AI Planning has become the underlying technique for several applications. Figuring prominently among these is automated Web Service Composition (WSC) at the \u201ccapability\u201d level, where services are described in terms of preconditions and effects over ontological concepts. A key issue in addressing WSC as planning is that ontologies are not only formal vocabularies; they also axiomatize the possible relationships between concepts. Such axioms correspond to what has been termed \u201cintegrity constraints\u201d in the actions and change literature, and applying a web service is essentially a belief update operation. The reasoning required for belief update is known to be harder than reasoning in the ontology itself. The support for belief update is severely limited in current planning tools. Our first contribution consists in identifying an interesting special case of WSC which is both significant and more tractable. The special case, which we term forward effects, is characterized by the fact that every ramification of a web service application involves at least one new constant generated as output by the web service. We show that, in this setting, the reasoning required for belief update simplifies to standard reasoning in the ontology itself. This relates to, and extends, current notions of \u201cmessage-based\u201d WSC, where the need for belief update is removed by a strong (often implicit or informal) assumption of \u201clocality\u201d of the individual messages. We clarify the computational properties of the forward effects case, and point out a strong relation to standard notions of planning under uncertainty, suggesting that effective tools for the latter can be successfully adapted to address the former. Furthermore, we identify a significant sub-case, named strictly forward effects, where an actual compilation into planning under uncertainty exists. This enables us to exploit off-the-shelf planning tools to solve message-based WSC in a general form that involves powerful ontologies, and requires reasoning about partial matches between concepts. We provide empirical evidence that this approach may be quite effective, using Conformant-FF as the underlying planner. c \u00a92009 AI Access Foundation. All rights reserved. HOFFMANN, BERTOLI, HELMERT & PISTORE", "creator": null}}}