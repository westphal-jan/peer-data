{"id": "1401.5860", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jan-2014", "title": "A New Look at BDDs for Pseudo-Boolean Constraints", "abstract": "pseudo - boolean constraints are omnipresent fuzzy database applications, whereby thus a commercial effort has been devoted to the advantages of good sat encoding techniques for them. some of these encodings first construct a binary decision diagram ( bdd ) for the constraint, and then encode linear bdd performing a propositional formula. these bdd - based approaches have gained important advantages, so as avoids being dependent on the size of the coefficients, or being able to share the same bdd for representing many constraints.", "histories": [["v1", "Thu, 23 Jan 2014 02:48:33 GMT  (634kb)", "http://arxiv.org/abs/1401.5860v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["ignasi ab\\'io", "robert nieuwenhuis", "albert oliveras", "enric rodriguez-carbonell", "valentin mayer-eichberger"], "accepted": false, "id": "1401.5860"}, "pdf": {"name": "1401.5860.pdf", "metadata": {"source": "CRF", "title": "A New Look at BDDs for Pseudo-Boolean Constraints", "authors": ["Ignasi Ab\u0301\u0131o", "Robert Nieuwenhuis", "Albert Oliveras", "Enric Rod\u0155\u0131guez-Carbonell", "Valentin Mayer-Eichberger"], "emails": ["iabio@lsi.upc.edu", "roberto@lsi.upc.edu", "oliveras@lsi.upc.edu", "erodri@lsi.upc.edu", "mayereichberger@gmail.com"], "sections": [{"heading": "1. Introduction", "text": "In this paperwe study Pseudo-Boolean constraints (PB constraints for short), that is, constraints of the form a1x1 + \u00b7 \u00b7 \u00b7 + anxn # K, where the ai and K are integer coefficients, the xi are Boolean (0/1) variables, and the relation operator # belongs to {<,>,\u2264,\u2265,=}. We will assume that # is \u2264 and the ai and K are positive since other cases can be easily reduced to this one (see Ee\u0301n & So\u0308rensson, 2006).\nSuch a constraint (\u2264 with positive coefficients) is a Boolean function C : {0, 1}n \u2192 {0, 1} that is monotonic decreasing in the sense that any solution for C remains a solution after flipping inputs from 1 to 0. Therefore these constraints can be expressed by a set of clauses with only negative literals. For example, each clause could simply define a (minimal) subset of variables that cannot be simultaneously true. Note however that not every such a monotonic function is a PB constraint. For example, the function expressed by the two clauses x1 \u2228 x2 and x3 \u2228 x4 has no (single) equivalent PB constraint a1x1 + \u00b7 \u00b7 \u00b7+ a4x4 \u2264 K (since without loss of generality a1 \u2265 a2 and a3 \u2265 a4, and then also x1 \u2228 x3 is needed). Hence, even among the monotonic Boolean functions, PB constraints are a rather restricted class (see also Smaus, 2007).\nc\u00a92012 AI Access Foundation. All rights reserved.\nPB constraints are omnipresent in practical SAT applications, not just in typical 0-1 linear integer problems, but also as an ingredient in new SAT approaches to, e.g., cumulative scheduling (Schutt, Feydy, Stuckey, & Wallace, 2009), logic synthesis (Aloul, Ramani, Markov, & Sakallah, 2002) or verification (Bryant, Lahiri, & Seshia, 2002), so it is not surprising that a significant number of SAT encodings for these constraints have been proposed in the literature. Here we are interested in encoding a PB constraint C by a clause set S (possibly with auxiliary variables) that is not only equisatisfiable, but also generalized arc-consistent (GAC): given a partial assignment A, if xi is false in every extension of A satisfying C, then unit propagating A on S sets xi to false.\nTo our knowledge, the only polynomial GAC encoding so far was given by Bailleux, Boufkhad, and Roussel (2009). Some other existing encodings are based on building (forms of) Binary Decision Diagrams (BDDs) and translating these into CNF. Although the approach of Bailleux et al. is not BDD-based, our main motivation to revisit BDD-based encodings is the following:\nExample 1. Let us consider two Pseudo-Boolean constraints: 3x1 + 2x2 + 4x3 \u2264 5 and 30001x1 + 19999x2 + 39998x3 \u2264 50007. Both are clearly equivalent: the Boolean function they represent can be expressed, e.g., by the clauses x1\u2228x3 and x2\u2228x3. However, encodings like the one of Bailleux et al. (2009) heavily depend on the concrete coefficients of each constraint, and generate a significantly larger SAT encoding for the second one. Since, given a variable ordering, ROBDDs are a canonical representation for Boolean functions (Bryant, 1986), i.e., each Boolean function has a unique ROBDD, a ROBDD-based encoding will treat both constraints equivalently.\nAnother reason for revisiting BDDs is that in practical problems numerous PB constraints exist that share variables among each other. Representing them all as a single ROBDD has the potential of generating a much more compact SAT encoding that is moreover likely to have better propagation properties.\nAs we have mentioned, BDD-based approaches have already been studied in the literature. A good example is the work of Ee\u0301n and So\u0308rensson (2006), where a GAC encoding using six three-literals clauses per BDD node is given. However, when it comes to study the BDD size, on page 9 they cite the work of Bailleux, Boufkhad, and Roussel (2006) to say \u201cIt is proven that in general a PB-constraint can generate an exponentially sized BDD\u201d. In Section 7 we explain why the approach of Bailleux et al does not use ROBDDs, and prove that the example they use to show the exponentiality of their method turns out to have polynomial ROBDDs. Somewhat surprisingly, probably due to the different names that PB constraints receive (0-1 integer linear constraints, linear threshold functions, weight constraints, knapsack constraints), the work of Hosaka, Takenaga, and Yajima (1994) has remained unknown to our research community. In that paper, it is proved that there are PB constraints for which no polynomial-sized ROBDDs exist. For self-containedness of this article, and to bring this interesting result to the knowledge of our research community, we include this family of PB constraints and prove that, regardless of the variable ordering, the corresponding ROBDD will always have exponential size.\nMain contributions and organization of this paper:\n\u2022 Subsection 3.2: We reproduce the family of PB constraints proposed by Hosaka et al. (1994), for which no polynomial-size ROBDD exist. For self-containedness, we give a clearer alternative proof than in the original paper.\n\u2022 Subsection 3.3: A very simple proof that, unless NP=co-NP, there are PB constraints that admit no polynomial-size ROBDD, independently of the variable order.\n\u2022 Subsection 4.1: A proof that PB constraints whose coefficients are powers of two do admit polynomial-size ROBDDs.\n\u2022 Subsections 4.2 and 4.3: A GAC and polynomial (size O(n3 log amax)) ROBDD-based encoding for PB constraints.\n\u2022 Section 5: An algorithm to construct ROBDDs for Pseudo-Boolean constraints in polynomial time w.r.t. the size of the final ROBDD.\n\u2022 Section 6: A GAC SAT encoding of BDDs for monotonic functions, a more general class of Boolean functions than PB constraints. This encoding uses only one binary and one ternary clause per node (the standard if-then-else encoding for BDDs used in, e.g., Ee\u0301n & So\u0308rensson, 2006, requires six ternary clauses per node). Moreover, this translation works for any BDD variable ordering.\n\u2022 Section 7: A related work section, summarizing the most important ingredients of the existing encodings of Pseudo-Boolean constraints into SAT.\n\u2022 Section 8: An experimental evaluation comparing our approach with other encodings and tools.\nThis article extends the shorter preliminary paper \u201cBDDs for Pseudo-Boolean Constraints \u2013 Revisited\u201d (Ab\u0301\u0131o, Nieuwenhuis, Oliveras, & Rodr\u0301\u0131guez-Carbonell, 2011), which was presented at the SAT 2011 conference. Extensions include: (i) proofs of all technical results, (ii) multiple examples illustrating the various concepts and algorithms presented, (iii) the PB constraint family by Hosaka et al. (1994) for which no polynomial ROBDD exists, (iv) an algorithm to efficiently construct ROBDDs for Pseudo-Boolean constraints, (v) a detailed related work section, (vi) extensive experimental results comparing our encoding to other approaches and (vii) a brief report of our experience trying to take advantage of the sharing potential of BDDs."}, {"heading": "2. Preliminaries", "text": "Let X = {x1, x2, . . .} be a fixed set of propositional variables. If x \u2208 X then x and x are positive and negative literals, respectively. The negation of a literal l, written l, denotes x if l is x, and x if l is x. A clause is a disjunction of literals x1 \u2228 . . . \u2228 xp \u2228 xp+1 \u2228 . . . \u2228 xn, sometimes written as x1\u2227 . . . xp \u2192 xp+1\u2228 . . . xn. A CNF formula is a conjunction of clauses.\nA (partial) assignment A is a set of literals such that {x, x} \u2286 A for no x, i.e., no contradictory literals appear. A literal l is true in A if l \u2208 A, is false in A if l \u2208 A, and is undefined in A otherwise. Sometimes we will write A as a set of pairs x = v, where v\nis 1 if x is true in A and 0 if x is false in A. A clause C is true in A if at least one of its literals is true in A. A formula F is true in A if all its clauses are true in A. In that case, A is a model of F . Systems that decide whether a formula F has any model are called SAT-solvers, and the main inference rule they implement is unit propagation: given a CNF F and an assignment A, find a clause in F such that all its literals are false in A except one, say l, which is undefined, add l to A and repeat the process until reaching a fixpoint.\nPseudo-Boolean constraints (PB constraints for short) are constraints of the form a1x1+ \u00b7 \u00b7 \u00b7 + anxn # K, where the ai and K are integer coefficients, the xi are Boolean (0/1) variables, and the relation operator # belongs to {<,>,\u2264,\u2265,=}. We will assume that # is \u2264 and the ai and K are positive, since other cases can be easily reduced to this one 1: (i) changing into \u2264 is straightforward if coefficients can be negative; (ii) replacing \u2212ax by a(1\u2212x)\u2212a; (iii) replacing (1\u2212x) by x. Negated variables like x can be handled as positive ones or, alternatively, replaced by a fresh x\u2032 and adding the clauses x \u2228 x\u2032 and x \u2228 x\u2032. A particular case of Pseudo-Boolean constraints is the one of cardinality constraints, in which all coefficients ai are equal to 1.\nOur main goal is to find CNF encodings for PB constraints. That is, given a PBconstraint C, construct an equisatisfiable clause set (a CNF) S such that any model for S restricted to the variables of C is a model of C and viceversa. Two extra properties are sought: (i) consistency checking by unit propagation or simply consistency : whenever a partial assignment A cannot be extended to a model for C, unit propagation on S and A produces a contradiction (a literal l and its negation l); and (ii) generalized arc-consistency or GAC (again by unit propagation): given an assignment A that can be extended to a model of C, but such that A\u222a {x} cannot, unit propagation on S and A produces x. More concretely, we will use ROBDDs for finding such encodings. ROBDDs are introduced by means of the following example.\nExample 2. Figure 1 explains (one method for) the construction of a ROBDD for the PB constraint 2x1 + 3x2 + 5x3 \u2264 6 and the ordering [x1, x2, x3]. The root node has as selector variable x1. Its false child represents the PB constraint assuming x1 = 0 (i.e., 3x2+5x3 \u2264 6) and its true child represents 2+3x2 +5x3 \u2264 6, that is, 3x2 +5x3 \u2264 4. The two children have the next variable in the ordering (x2) as selector, and the process is repeated until we reach\n1. An =-constraint can be split into a \u2264-constraint and a \u2265-constraint. Here we consider (generalized arc-)consistency for the latter two isolatedly, not for the original =-constraint.\nthe last variable in the sequence. Then, a constraint of the form 0 \u2264 K is the True node (1 in the figure) if K \u2265 0 is positive, and the False node (0) if K < 0. This construction (leftmost in the figure), is known as an Ordered BDD. For obtaining a Reduced Ordered BDD (ROBDD for short in the rest of the paper), two reductions are applied until fixpoint: removing nodes with identical children (as done with the leftmost x3 node in the second BDD of the figure), and merging isomorphic subtrees, as done for x3 in the third BDD. The fourth final BDD is a fixpoint. For a given ordering, ROBDDs are a canonical representation of Boolean functions: each Boolean function has a unique ROBDD. BDDs can be encoded into CNF by introducing an auxiliary variable a for every node. If the selector variable of the node is x and the auxiliary variables for the false and true child are f and t, respectively, add the if-then-else clauses:\nx \u2227 f \u2192 a x \u2227 t \u2192 a f \u2227 t \u2192 a x \u2227 f \u2192 a x \u2227 t \u2192 a f \u2227 t \u2192 a\nIn what follows, the size of a BDD is its number of nodes. We will say that a BDD represents a PB constraint if they represent the same Boolean function. Given an assignment A over the variables of a BDD, we define the path induced by A as the path that starts at the root of the BDD and at each step, moves to the false (true) child of a node if and only if its selector variable is false (true) in A."}, {"heading": "3. Exponential ROBDDs for PB Constraints", "text": "In this section we study the size of ROBDDs for PB constraints. We start by defining the notion of the interval of a PB constraint. Then, in Section 3.2 we consider two families of PB constraints and study their ROBDD size: we first prove that the example given by Bailleux et al. (2006) has polynomial ROBDDs, and then we reproduce the example of Hosaka et al. (1994) that has exponential ROBDDs regardless of the variable ordering. Finally, we relate the ROBDD size of a PB constraint with the well-known subset sum problem."}, {"heading": "3.1 Intervals", "text": "Before formally defining the notion of interval of a PB constraint, let us first give some intuitive explanation.\nExample 3. Consider the constraint 2x1 + 3x2 + 5x3 \u2264 6. Since no combination of its coefficients adds to 6, the constraint is equivalent to 2x1 + 3x2 + 5x3 < 6, and hence to 2x1+ 3x2 + 5x3\u22645. This process cannot be repeated again since 5 can be obtained with the existing coefficients.\nSimilarly, we could try to increase the right-hand side of the constraint. However, there is a combination of the coefficients that adds to 7, which implies that the constraint is not equivalent to 2x1 + 3x2 + 5x3 \u2264 7. All in all, we can state that the constraint is equivalent to 2x1 + 3x2 + 5x3 \u2264 K for any K \u2208 [5, 6]. It is trivial to see that the set of valid K\u2019s is always an interval.\nDefinition 4. Let C be a constraint of the form a1x1 + \u00b7 \u00b7 \u00b7+ anxn \u2264 K. The interval of C consists of all integers M such that a1x1 + \u00b7 \u00b7 \u00b7+ anxn \u2264M , seen as a Boolean function, is equivalent to C.\nSimilarly, given a ROBDD representing a PB constraint and a node \u03bd with selector variable xi,we will refer to the interval of \u03bd as all the integers M such that the constraint aixi + \u00b7 \u00b7 \u00b7 anxn \u2264M is represented (as a Boolean function) by the ROBDD rooted at \u03bd.\nIn the following, unless stated otherwise, the ordering used in the ROBDD will be [x1, x2, . . . , xn].\nProposition 5. If [\u03b2, \u03b3] is the interval of a node \u03bd with selector variable xi then:\n1. There is an assignment {xj = vj}nj=i such that aivi + \u00b7 \u00b7 \u00b7+ anvn = \u03b2.\n2. There is an assignment {xj = vj}nj=i such that aivi + \u00b7 \u00b7 \u00b7+ anvn = \u03b3 + 1.\n3. There is an assignment {xj = vj}i\u22121j=1 such that K\u2212a1v1\u2212a2v2\u2212\u00b7 \u00b7 \u00b7\u2212ai\u22121vi\u22121 \u2208 [\u03b2, \u03b3]\n4. Take h < \u03b2. There exists an assignment {xj = vj}nj=i such that aivi + \u00b7 \u00b7 \u00b7+ anvn > h and its path goes from \u03bd to True.\n5. Take h > \u03b3. There exists an assignment {xj = vj}nj=i such that aivi + \u00b7 \u00b7 \u00b7+ anvn \u2264 h and its path goes from \u03bd to False.\n6. The interval of the True node is [0,\u221e).\n7. The interval of the False node is (\u2212\u221e,\u22121]. Moreover, it is the only interval with negative values.\nProof. 1. Since \u03b2 \u2212 1 does not belong to the interval of \u03bd, the constraints aixi + ai+1xi+1 + \u00b7 \u00b7 \u00b7+ anxn \u2264 \u03b2 \u2212 1 aixi + ai+1xi+1 + \u00b7 \u00b7 \u00b7+ anxn \u2264 \u03b2\nare different. This means that there is a partial assignment satisfying the second one but not the first one.\n2. The proof is analogous to the previous one.\n3. Take a partial assignment {x1 = v1, . . . , xi\u22121 = vi\u22121} whose path goes from the root to \u03bd. Therefore, by definition of the ROBDD, \u03bd is the ROBDD of the constraint\naixi + ai+1xi+1 + \u00b7 \u00b7 \u00b7+ anxn \u2264 K \u2212 a1v1 \u2212 \u00b7 \u00b7 \u00b7 \u2212 ai\u22121vi\u22121.\nTherefore, by definition of the interval of \u03bd,\nK \u2212 a1v1 \u2212 a2v2 \u2212 \u00b7 \u00b7 \u00b7 \u2212 ai\u22121vi\u22121 \u2208 [\u03b2, \u03b3].\n4. Intuitively, this property states that, if h is not in the interval of \u03bd, there is an assignment that satisfies the ROBDD rooted at \u03bd but not the constraint aixi + \u00b7 \u00b7 \u00b7+ anxn \u2264 h. Since h does not belong to the interval of \u03bd, the ROBDD of\nC \u2032 : aixi + \u00b7 \u00b7 \u00b7+ anxn \u2264 h\nis not \u03bd. Therefore, there exists an assignment that either\nx1\nx2\nx3\n01\n1\n1\n1\n0\n0\n0\n[5, 6]\n[5, 7]\n[0, 4]\n[0,\u221e) (\u2212\u221e,\u22121]\nx1\nx2x2\nx3x3\n01\n1 1\n11\n1\n0\n0\n0 0\n0\n[5, 6]\n[5, 7] [3, 4]\n[5,\u221e) [0, 4]\n[0,\u221e) (\u2212\u221e,\u22121]\nWe now prove that, given a ROBDD for a PB constraint, one can easily compute the intervals for every node bottom-up. We first start with a motivating example.\nExample 6. Let us consider again the constraint 2x1 + 3x2 + 5x3 \u2264 6. Assume that all variables appear in every path from the root to the leaves (otherwise, add extra nodes as in the rightmost BDD of Figure 2). Assume now that we have computed the intervals for the two children of the root (rightmost BDD in Figure 2). This means that the false child of the root is the BDD for 3x2+5x3 \u2264 [5, 7] and the true child the BDD for 3x2+5x3 \u2264 [3, 4]. Assuming x1 to be false, the false child would also represent the constraint 2x1 +3x2 +5x3 \u2264 [5, 7], and assuming x1 to be true, the true child would represent the constraint 2x1 +3x2 +5x3 \u2264 [5, 6]. Taking the intersection of the two intervals, we can infer that the root node represents 2x1 + 3x2 + 5x3 \u2264 [5, 6].\nMore formally, the interval of every node can be computed as follows:\nProposition 7. Let a1x1 +a2x2 + \u00b7 \u00b7 \u00b7+anxn \u2264 K be a constraint, and let B be its ROBDD with the order [x1, . . . , xn]. Consider a node \u03bd with selector variable xi, false child \u03bdf (with selector variable xf and interval [\u03b2f , \u03b3f ]) and true child \u03bdt (with selector variable xt and interval [\u03b2t, \u03b3t]), as shown in Figure 3. The interval of \u03bd is [\u03b2, \u03b3], with:\nBefore moving to the proof, we want to note that if in every path from the root to the leaves of the ROBDD all variables were present, the definition of \u03b2 would be much simpler (\u03b2 = max{\u03b2f , \u03b2t + ai}). The other coefficients are necessary to account for the variables that have been removed due to the ROBDD reduction process.\nProof. Let us assume that [\u03b2, \u03b3] is not the interval of \u03bd. One of the following statements should hold:\n1. There exists h \u2208 [\u03b2, \u03b3] that does not belong to the interval of \u03bd.\n2. There exists h < \u03b2 belonging to the interval of \u03bd.\n3. There exists h > \u03b3 belonging to the interval of \u03bd.\nWe will now prove that none of these cases can hold.\n1. Let us define\nC \u2032 : aixi + \u00b7 \u00b7 \u00b7+ anxn \u2264 h.\nIf h does not belong to the interval, there exists an assignment {xj = vj}nj=i that either satisfies C \u2032 and its path goes from \u03bd to False or it does not satisfy C \u2032 and its path goes to True. Assume that the assignment satisfies C \u2032 and its path goes from \u03bd to False (the other case is similar). There are two possibilities:\n\u2022 The assignment satisfies vi = 0. Since h \u2265 \u03b2, it holds\nh\u2212 ai+1vi+1 \u2212 \u00b7 \u00b7 \u00b7 \u2212 af\u22121vf\u22121 \u2265 \u03b2 \u2212 ai+1vi+1 \u2212 \u00b7 \u00b7 \u00b7 \u2212 af\u22121vf\u22121 \u2265 \u03b2 \u2212 ai+1 \u2212 \u00b7 \u00b7 \u00b7 \u2212 af\u22121 \u2265 \u03b2f .\nOn the other hand, since h \u2264 \u03b3,\nh\u2212 ai+1vi+1 \u2212 \u00b7 \u00b7 \u00b7 \u2212 af\u22121vf\u22121 \u2264 h \u2264 \u03b3 \u2264 \u03b3f .\nTherefore, h\u2212 ai+1vi+1 \u2212 \u00b7 \u00b7 \u00b7 \u2212 af\u22121vf\u22121 belongs to the interval of \u03bdf . Since the assignment {xf = vf , . . . , xn = vn} goes from \u03bdf to False, we have:\nafvf + \u00b7 \u00b7 \u00b7+ anvn > h\u2212 ai+1vi+1 \u2212 \u00b7 \u00b7 \u00b7 \u2212 af\u22121vf\u22121\nai+1vi+1 + \u00b7 \u00b7 \u00b7+ afvf + \u00b7 \u00b7 \u00b7 anvn > h\nHence, adding aivi to the sum one can see that the assignment does not satisfy C \u2032, which is a contradiction.\n\u2022 The case vi = 1 gives a similar contradiction.\n2. By definition of \u03b2, either h < \u03b2f + ai+1 + \u00b7 \u00b7 \u00b7 + af\u22121 or h < \u03b2t + ai + ai+1 + \u00b7 \u00b7 \u00b7 + at\u22121. We will only consider the first case, since the other one is similar. Therefore, h\u2212ai+1\u2212\u00b7 \u00b7 \u00b7\u2212af\u22121 < \u03b2f . Due to point 4 of Proposition 5, there exists an assignment {xf = vf , . . . xn = vn} such that\nafvf + \u00b7 \u00b7 \u00b7 anvn > h\u2212 ai+1 \u2212 \u00b7 \u00b7 \u00b7 \u2212 af\u22121\nand its path goes from \u03bdf to True. Hence, the assignment\n{xi = 0, xi+1 = 1, . . . , xf\u22121 = 1, xf = vf , . . . , xn = vn}\ndoes not satisfy the constraint aixi + \u00b7 \u00b7 \u00b7+anxn \u2264 h and its path goes from \u03bd to True. By definition of interval, h cannot belong to the interval of \u03bd.\n3. This case is very similar to the previous one.\nThis proposition gives a natural way of computing all intervals of a ROBDD in a bottomup fashion. The procedure is initialized by computing the intervals of the terminal nodes as detailed in Proposition 5, points 6 and 7.\nExample 8. Let us consider again the constraint 2x1 + 3x2 + 5x3 \u2264 6. Its ROBDD is shown in the left-hand side of Figure 2, together with its intervals. For their computation, we first compute the intervals of the True and False nodes, which are [0,\u221e) and (\u2212\u221e,\u22121] in virtue of Proposition 5. Then, we can compute the interval of the node having x3 as selector variable with the previous proposition\u2019s formula: \u03b23 = max{0,\u2212\u221e + 5} = 0, \u03b33 = min{\u221e,\u22121 + 5} = 4. Therefore, its interval is [0, 4].\nIn the next step, we compute the interval for the node with selector variable x2: \u03b22 = max{0 + 5, 0 + 3} = 5, \u03b32 = min{\u221e, 4 + 3} = 7. Thus, it its interval is [5, 7]. Finally, we can compute the root\u2019s interval: \u03b21 = max{5, 0 + 2 + 3} = 5, \u03b31 = min{7, 4 + 2} = 6, that is, [5, 6]."}, {"heading": "3.2 Some Families of PB Constraints and their ROBDD Size", "text": "We start by revisiting the family of PB constraints given by Bailleux et al. (2006), where it is proved that, for their concrete variable ordering, their non-reduced BDDs grow exponentially for this family. Here we prove that ROBDDs are polynomial for this family, and that this is even independent of the variable ordering. The family is defined by considering a, b and n positive integers such that \u2211n i=1 b\ni < a. The coefficients are \u03c9i = a + b\ni and the right-hand side of the constraint is K = a \u00b7 n/2. We will first prove that the constraint C : \u03c91x1 + \u00b7 \u00b7 \u00b7 + \u03c9nxn \u2264 K is equivalent to the cardinality constraint C \u2032 : x1 + \u00b7 \u00b7 \u00b7+ xn \u2264 n/2\u2212 1. For simplicity, we assume that n is even.\n\u2022 Take an assignment satisfying C \u2032. In this case, there are at most n/2\u2212 1 variables xi assigned to true, and the assignment also satisfies C since:\n\u03c91x1 + \u00b7 \u00b7 \u00b7+ \u03c9nxn \u2264 n\u2211\ni=n/2+2\n\u03c9i = (n/2\u2212 1)a+ n\u2211\ni=n/2+2\nbi < K \u2212 a+ n\u2211\ni=1\nbi < K.\n\u2022 Consider now an assignment not satisfying C \u2032. In this case, there are at least n/2 true variables in the assignment and it does not satisfy C either:\n\u03c91x1 + \u00b7 \u00b7 \u00b7+ \u03c9nxn \u2265 n/2\u2211 i=1 \u03c9i = (n/2) \u00b7 a+ n/2\u2211 i=1 bi > (n/2) \u00b7 a = K.\nSince the two constraints are equivalent and ROBDDs are canonical, the ROBDD representation of C and C \u2032 are the same. But the ROBDD of C \u2032 is known to be of quadratic size because it is a cardinality constraint (see, for instance, Bailleux et al., 2006).\nIn the following, we present a family of PB constraints that only admit exponential ROBDDs. This example was first given by Hosaka et al. (1994), but a clearer alternative proof is given next. First of all, we prove a lemma that, under certain technical conditions, gives a lower bound on the number of nodes of the ROBDD for a PB constraint.\nLemma 9. Let a1x1 + \u00b7 \u00b7 \u00b7 + anxn \u2264 K be a PB constraint, and let i be an integer with 1 \u2264 i \u2264 n. Assume that every assignment {x1 = v1, x2 = v2, . . . , xi = vi} admits an extension {x1 = v1, . . . , xn = vn} such that a1v1 + \u00b7 \u00b7 \u00b7 + anvn = K. Let M be the number of different results we can obtain adding some subset of the coefficients a1, a2, . . . , ai, i.e.,\nM = |{ i\u2211\nj=1\najbj : bj \u2208 {0, 1}}|. Then, the ROBDD size with ordering [x1, x2, . . . , xn] is at\nleast M .\nProof. Let us consider a PB constraint that satisfies the conditions of the lemma. We will prove that its ROBDD has at least M distinct nodes by showing that any two assignments of the form {x1 = v1, . . . , xi = vi} and {x1 = v\u20321, . . . , xi = v\u2032i} with a1v1 + \u00b7 \u00b7 \u00b7 + aivi 6= a1v \u2032 1 + \u00b7 \u00b7 \u00b7+ aiv\u2032i lead to different nodes in the ROBDD. Assume that it is not true: there are two assignments {x1 = v1, . . . , xi = vi} and {x1 = v\u20321, . . . , xi = v\u2032i} with a1v1 + \u00b7 \u00b7 \u00b7 + aivi < a1v\u20321 + \u00b7 \u00b7 \u00b7 + aiv\u2032i such that their paths end at the same node. Take the extended assignment A = {x1 = v1, . . . , xn = vn} such that a1v1 + \u00b7 \u00b7 \u00b7 anvn = K. Since A satisfies the PB constraint, the path it defines ends at the\ntrue node. However, the assignment A\u2032 = {x1 = v\u20321, . . . , xi = v\u2032i, xi+1 = vi+1, . . . , xn = vn} does not satisfy the constraint, since\na1v \u2032 1 + \u00b7 \u00b7 \u00b7 aiv\u2032i + ai+1vi+1 + \u00b7 \u00b7 \u00b7 anvn > a1v1 + \u00b7 \u00b7 \u00b7+ anvn = K.\nHowever, the nodes defined by {x1 = v1, . . . , xi = vi} and {x1 = v\u20321, . . . , xi = v\u2032i} were the same, so the path defined by A\u2032 must also end at the true node, which is a contradiction.\nWe can now show a family of PB constraints that only admits exponential ROBDDs.\nTheorem 10. Let n be a positive integer, and let us define ai,j = 2 j\u22121 + 22n+i\u22121 for all 1 \u2264 i, j \u2264 2n; and K = (24n \u2212 1)n. Then, the PB constraint 2n\u2211 i=1 2n\u2211 j=1 ai,jxi,j \u2264 K\nhas at least 2n nodes in any variable ordering.\nProof. It is convenient to describe the coefficients in binary notation: 2n\ufe37 \ufe38\ufe38 \ufe37 2n\ufe37 \ufe38\ufe38 \ufe37\na1,1 = 0 0 \u00b7 \u00b7 \u00b7 0 1 0 0 \u00b7 \u00b7 \u00b7 0 1 a1,2 = 0 0 \u00b7 \u00b7 \u00b7 0 1 0 0 \u00b7 \u00b7 \u00b7 1 0 \u00b7 \u00b7 \u00b7 . .. a1,2n\u22121 = 0 0 \u00b7 \u00b7 \u00b7 0 1 0 1 \u00b7 \u00b7 \u00b7 0 0 a1,2n = 0 0 \u00b7 \u00b7 \u00b7 0 1 1 0 \u00b7 \u00b7 \u00b7 0 0\na2,1 = 0 0 \u00b7 \u00b7 \u00b7 1 0 0 0 \u00b7 \u00b7 \u00b7 0 1 a2,2 = 0 0 \u00b7 \u00b7 \u00b7 1 0 0 0 \u00b7 \u00b7 \u00b7 1 0 \u00b7 \u00b7 \u00b7 . .. a2,2n\u22121 = 0 0 \u00b7 \u00b7 \u00b7 1 0 0 1 \u00b7 \u00b7 \u00b7 0 0 a2,2n = 0 0 \u00b7 \u00b7 \u00b7 1 0 1 0 \u00b7 \u00b7 \u00b7 0 0 \u00b7 \u00b7 \u00b7 . ..\na2n,2n = 1 0 \u00b7 \u00b7 \u00b7 0 0 1 0 \u00b7 \u00b7 \u00b7 0 0\nK/n = 1 1 \u00b7 \u00b7 \u00b7 1 1 1 1 \u00b7 \u00b7 \u00b7 1 1 First of all, one can see that the sum of all the a\u2019s is 2K. Let us take an arbitrary bijection\nF = (F1, F2) : {1, 2, . . . , 4n2} \u2192 {1, 2, . . . , 2n} \u00d7 {1, 2, . . . , 2n},\nand consider the ordering defined by it: [xF (1), xF (2), . . . , xF (4n2)], where xF (k) = xF1(k),F2(k) for every k. We want to prove that the ROBDD of the PB constraint with this ordering has at least 2n nodes.\nThe proof will consist in showing that the hypotheses of Lemma 9 hold. That is, first we show that for any variable ordering, we can find an integer s such that any assignment\nto the first s variables can be extended to a full assignment that adds K. Then, we prove that there are at least 2n different values we can add with the first s coefficients, as required by Lemma 9.\nLet us define bk with 1 \u2264 k \u2264 2n as the position of the k-th different value of the tuple (F1(1), F1(2), . . . , F1(4n 2)). More formally,\nbk = 1 if k = 1,min{r : F1(r) 6\u2208 {F1(b1), F1(b2), . . . , F1(bk\u22121)}} if k > 1. Analogously, let us define c1, . . . , c2n as\nck = 1 if k = 1,min{s : F2(s) 6\u2208 {F2(c1), F2(c2), . . . , F2(ck\u22121)}} if k > 1. Let us denote by ir = F1(br) and js = F2(cs) for all 1 \u2264 r, s \u2264 2n. Notice that {i1, i2, . . . , i2n} and {j1, j2, . . . , j2n} are permutations of {1, 2, . . . , 2n}. Assume that bn \u2265 cn (the other case is analogous), and take an arbitrary assignment {xF (1) = vF (1), xF (2) = vF (2), . . . , xF (cn) = vF (cn)}. We want to extend it to a complete assignment such that\n4n2\u2211 k=1 aF (k)vF (k) = K.\nFigure 4 represents the initial assignment. All the values are in the top-left square since the assignment is undefined for all xir,js with r > n or s > n. Extending the assignment so that the sum is K amounts to completing the table in such a way that there are exactly n ones in every column and row.\nThe assignment can be completed in the following way: first, complete the top left square in any way, for instance, adding zeros to every non-defined cell. Then, copy that square to the bottom-right square and, finally, add the complementary square to the other two squares (i.e., write 0 instead of 1 and 1 instead of 0). Figure 5 shows the extended assignment for that example.\nMore formally, the assignment is completed as follows:\nvir,js =  0 if r, s \u2264 n and vir,js was undefined, \u00acvir\u2212n,js if r > n and s \u2264 n, \u00acvir,js\u2212n if s > n and r \u2264 n, vir\u2212n,js\u2212n if r, s > n,\nwhere \u00ac0 = 1 and \u00ac1 = 0. Now, let us prove that it satisfies the requirements, i.e., the coefficients corresponding to true variables in the assignment add exactly K. Let us fix r, s \u2264 n. Denote by i = ir, j = js, i \u2032 = ir+n and j \u2032 = js+n.\n\u2022 If vi,j = 0, by definition vi\u2032,j = vi,j\u2032 = 1 and vi\u2032,j\u2032 = 0. Therefore, ai,jvi,j + ai\u2032,jvi\u2032,j + ai,j\u2032vi,j\u2032 + ai\u2032,j\u2032vi\u2032,j\u2032 = ai\u2032,j + ai,j\u2032\n= 22n+i \u2032\u22121 + 2j\u22121 + 22n+i\u22121 + 2j \u2032\u22121 = ai,j + ai\u2032,j + ai,j\u2032 + ai\u2032,j\u2032\n2 .\n\u2022 Analogously, if vi,j = 1,\nai,jvi,j + ai\u2032,jvi\u2032,j + ai,j\u2032vi,j\u2032 + ai\u2032,j\u2032vi\u2032,j\u2032 = ai,j + ai\u2032,j + ai,j\u2032 + ai\u2032,j\u2032\n2 .\nTherefore, 4n2\u2211 k=1 aF (k)vF (k) = 1 2 4n2\u2211 k=1 aF (k) = K.\nBy Lemma 9, the number of nodes of the ROBDD is at least the number of different results we can obtain by adding some subset of the coefficients aF (1), aF (2), . . . , aF (cn). Consider the set aF (c1), aF (c2), . . . , aF (cn). We will now see that all its different subsets add different values, and hence the ROBDD size is at least 2n.\nThe sum of a subset of {aF (c1), aF (c2), . . . , aF (cn)} is\nS = aF (c1)v1 + aF (c2)v2 + \u00b7 \u00b7 \u00b7+ aF (cn)vn, vr \u2208 {0, 1}.\nLet us look at the 2n last bits of S in binary notation: all the digits are 0 except for the positions F2(c1), F2(c2), . . . , F2(cn), which are v1, v2, . . . , vn. Therefore, if two subsets add the same, the 2n last digits of the sum are the same. This means that the values of (v1, . . . , vn) are the same, and thus they are the same subset."}, {"heading": "3.3 Relation between the Subset Sum Problem and the ROBDD Size", "text": "In this section, we study the relationship between the ROBDD size for a PB constraint and the subset sum problem. This allows us to, assuming that NP and co-NP are different, give a much simpler proof that there exist PB constraints that do not admit polynomial ROBDDs.\nLemma 9 and the exponential ROBDD example of Theorem 10 suggest that there is a relationship between the size of ROBDDs and the number of ways we can obtain K by adding some of the coefficients of the PB. It seems that if K can be obtained in a lot of different ways, the ROBDD will be large.\nIn this section we explore another relationship between the problem of adding K with a subset of the coefficients and the size of the ROBDDs. In a sense, we give a proof that the converse of the last paragraph is not true: if NP and co-NP are different, there are exponentially-sized ROBDDs of PB constraints with no subsets of their coefficients adding K. Let us start by defining one version of the well-known subset sum problem.\nDefinition 11. Given a set of positive integers S = {a1, . . . , an} and an integer K, the subset sum problem of (K,S) consists in determining whether there exists a subset of {a1, . . . , an} that sums to exactly K.\nIt is well-known that the subset sum problem is NP-complete when K \u223c 2n, but there are polynomial algorithms in n when K is also a polynomial in n. For a given subset sum problem (K,S) with S = {a1, . . . , an}, we can construct its associated PB constraint a1x1 + \u00b7 \u00b7 \u00b7+anxn \u2264 K. In the previous section we have seen one PB constraint family whose coefficients can add K in an exponential number of ways, thus generating an exponential ROBDD. Now, assuming that NP and co-NP are different, we will see that there exists a PB constraint family with exponential ROBDDs in any ordering such that their coefficients cannot add K. First, we show how ROBDDs can act as unsatisfiability certificates for the subset sum problem.\nTheorem 12. Let (K,S) be an UNSAT subset sum problem. Then, if a ROBDD for its associated PB constraint has polynomial size, it can act as a polynomial unsatisfiability certificate for (K,S).\nProof. We only need to show how, in polynomial time, we can check whether the ROBDD is an unsatisfiability certificate for (K,S). For that, we note that the subset sum problem is UNSAT if and only if the PB constraints\na1x1 + \u00b7 \u00b7 \u00b7+ anxn \u2264 K, a1x1 + \u00b7 \u00b7 \u00b7+ anxn \u2264 K \u2212 1\nare equivalent, and this happens if and only if their ROBDDs are the same. Therefore, we have to show, in polynomial time, that the given ROBDD represents both constraints. It can be done, for instance, by building the ROBDD (using Algorithm 1 of Section 5) and comparing the ROBDDs.\nThe key point now is that, if we assume NP to be different from co-NP, there exists a family of UNSAT subset sum problems with no polynomial-sized unsatisfiability certificate. Hence, the family consisting of the associated PB constraints does not admit polynomial ROBDDs.\nHence, PB constraints associated with difficult-to-certify UNSAT subset sum problems will produce exponential ROBDDs. However, subset sum is NP-complete if K \u223c 2n. In PB constraints from industrial problems usually K \u223c nr for some r, so we could expect non-exponential ROBDDs for these constraints."}, {"heading": "4. Avoiding Exponential ROBDDs", "text": "In this section we introduce our positive results. We restrict ourselves to a particular class of PB constraints, where all coefficients are powers of two. As we will show below, these constraints admit polynomial ROBDDs. Moreover, any PB constraint can be reduced to this class by means of coefficient decomposition.\nExample 13. Let us take the PB constraint 9x1 + 8x2 + 3x3 \u2264 10. Considering the binary representation of the coefficients, this constraint can be rewritten into (23x3,1 + 2\n0x0,1) + (23x3,2) + (2 1x1,3 + 2 0x0,3) \u2264 10 if we add the binary clauses expressing that xi,r = xr for appropriate i and r."}, {"heading": "4.1 Power-of-two PB Constraints Do Have Polynomial-size ROBDDs", "text": "Let us consider a PB constraint of the form:\nC : 20 \u00b7 \u03b40,1 \u00b7 x0,1 + 20 \u00b7 \u03b40,2 \u00b7 x0,2 + \u00b7 \u00b7 \u00b7 + 20 \u00b7 \u03b40,n \u00b7 x0,n + 21 \u00b7 \u03b41,1 \u00b7 x1,1 + 21 \u00b7 \u03b41,2 \u00b7 x1,2 + \u00b7 \u00b7 \u00b7 + 21 \u00b7 \u03b41,n \u00b7 x1,n +\n. . . + 2m \u00b7 \u03b4m,1 \u00b7 xm,1 + 2m \u00b7 \u03b4m,2 \u00b7 xm,2 + \u00b7 \u00b7 \u00b7 + 2m \u00b7 \u03b4m,n \u00b7 xm,n \u2264 K,\nwhere \u03b4i,r \u2208 {0, 1} for all i and r. Notice that every PB constraint whose coefficients are powers of 2 can be expressed in this way. Let us consider its ROBDD representation with the ordering [x0,1, x0,2, . . . , x0,n, x1,1, . . . , xm,n].\nLemma 14. Let [\u03b2, \u03b3] be the interval of a node with selector variable xi,r. Then 2 i divides \u03b2 and 0 \u2264 \u03b2 < (n+ r \u2212 1) \u00b7 2i.\nProof. By Proposition 5.1, \u03b2 can be expressed as a sum of coefficients all of which are multiples of 2i, and hence \u03b2 itself is a multiple of 2i. By Proposition 5.7, the only node whose interval contains negative values is the False node, and hence \u03b2 \u2265 0. Now, using Proposition 5.3, there must be an assignment to the variables {x0,1, . . . , xi,r\u22121} such that 20\u03b40,1x0,1 + \u00b7 \u00b7 \u00b7+ 2i\u03b4i,r\u22121xi,r\u22121 belongs to the interval. Therefore:\n\u03b2 \u2264 20\u03b40,1x0,1 + \u00b7 \u00b7 \u00b7+ 2i\u03b4i,r\u22121xi,r\u22121 \u2264 20 + 20 + \u00b7 \u00b7 \u00b7+ 2i\n= n20 + n21 + \u00b7 \u00b7 \u00b7+ n2i\u22121 + (r \u2212 1) \u00b7 2i = n(2i \u2212 1) + 2i(r \u2212 1) < 2i(n+ r \u2212 1)\nCorollary 15. The number of nodes with selector variable xi,r is bounded by n+ r\u2212 1. In particular, the size of the ROBDD belongs to O(n2m).\nProof. Let \u03bd1, \u03bd2, . . . , \u03bdt be all the nodes with selector variable xi,r. Let [\u03b2j , \u03b3j ] the interval of \u03bdj . Note that such intervals are pair-wise disjoint since a non-empty intersection would imply that there exists a constraint represented by two different ROBDDs. Hence we can assume, without loss of generality, that \u03b21 < \u03b22 < \u00b7 \u00b7 \u00b7 < \u03b2t. Due to Lemma 14, we know that \u03b2j \u2212 \u03b2j\u22121 \u2265 2i. Hence 2i(n+ r\u2212 1) > \u03b2t \u2265 \u03b2t\u22121 + 2i \u2265 \u00b7 \u00b7 \u00b7 \u2265 \u03b21 + 2i(t\u2212 1) \u2265 2i(t\u2212 1) and we can conclude that t < n+ r."}, {"heading": "4.2 A Consistent Encoding for PB Constraints", "text": "Let us now take an arbitrary PB constraint C : a1x1 + \u00b7 \u00b7 \u00b7 anxn \u2264 K and assume that aM is the largest coefficient. For m = log aM , we can rewrite C splitting the coefficients into powers of two as shown in Example 13:\nC\u0303 : 20 \u00b7 \u03b40,1 \u00b7 x0,1 + 20 \u00b7 \u03b40,2 \u00b7 x0,2 + \u00b7 \u00b7 \u00b7 + 20 \u00b7 \u03b40,n \u00b7 x0,n + 21 \u00b7 \u03b41,1 \u00b7 x1,1 + 21 \u00b7 \u03b41,2 \u00b7 x1,2 + \u00b7 \u00b7 \u00b7 + 21 \u00b7 \u03b41,n \u00b7 x1,n +\n. . . + 2m \u00b7 \u03b4m,1 \u00b7 xm,1 + 2m \u00b7 \u03b4m,2 \u00b7 xm,2 + \u00b7 \u00b7 \u00b7 + 2m \u00b7 \u03b4m,n \u00b7 xm,n \u2264 K,\nwhere \u03b4m,r \u03b4m\u22121,r \u00b7 \u00b7 \u00b7 \u03b40,r is the binary representation of ar. Notice that C and C\u0303 represent the same constraint if we add clauses expressing that xi,r = xr for appropriate i and r. This process is called coefficient decomposition of the PB constraint. A similar idea was given by Bartzis and Bultan (2003).\nThe important remark is that, using a consistent SAT encoding of the ROBDD for C\u0303 (e.g. the one given in Ee\u0301n & So\u0308rensson, 2006, or the one presented in Section 6) and adding clauses expressing that xi,r = xr for appropriate i and r, we obtain a consistent encoding for the original constraint C using O(n2 log aM ) auxiliary variables and clauses.\nThis is not difficult to see. Take an assignment A over the variables of C which cannot be extended to a model of C. This is because the coefficients corresponding to the variables true in A add more than K. Using the clauses for xi,r = xr, unit propagation will produce an assignment to the xi,r\u2019s that cannot be extended to a model of C\u0303. Since the encoding for C\u0303 is consistent, a false clause will be found. Conversely, if we consider an assignment A over the variables of C that can be extended to a model of C, this assignment can clearly be extended to a model for C\u0303 and the clauses expressing xi,r = xr. Hence, unit propagation on those clauses and the encoding of C\u0303 will not detect a false clause.\nExample 16. Consider the PB constraint C : 2x1 + 3x2 + 5x3 \u2264 6. For obtaining the consistent encoding we have presented, we first rewrite C by splitting the coefficients into powers of two: C \u2032 : 1x0,2 + 1x0,3 + 2x1,1 + 2x1,2 + 4x2,3 \u2264 6. Next, we encode C \u2032 into a ROBDD and finally encode the ROBDD into SAT and add clauses for enforcing the relations xi,j = xj. Or, instead of that, we can replace xi,j by xj into the ROBDD, and encode the result into SAT. Figure 6 shows the decision diagram after the replacement."}, {"heading": "4.3 A Generalized Arc-consistent Encoding for PB Constraints", "text": "Unfortunately, the previous approach does not result in a GAC encoding. The intuitive idea can be seen in the following example:\nExample 17. Let us consider the constraint 3x1 + 4x2 \u2264 6. After splitting the coefficients into powers of two, we obtain C \u2032 : x0,1 + 2x1,1 + 4x2,2 \u2264 6. If we set x2,2 to true, C \u2032 implies that either x0,1 or x1,1 have to be false, but the encoding cannot exploit the fact that both variables will receive the same truth value and hence both should be propagated. Adding clauses stating that x0,1 = x1,1 does not help in this sense.\nIn order to overcome this limitation, we follow the method presented by Bessiere, Katsirelos, Narodytska, and Walsh (2009) and Bailleux et al. (2009). Let C : a1x1+\u00b7 \u00b7 \u00b7+anxn \u2264 K be an arbitrary PB constraint. We denote as Ci the constraint a1x1 + \u00b7 \u00b7 \u00b7+ ai \u00b7 1 + \u00b7 \u00b7 \u00b7+ anxn \u2264 K, i.e., the constraint assuming xi to be true. For every i with 1 \u2264 i \u2264 n, we encode Ci as in Section 4.2 and, in addition, we add the binary clause ri \u2228 xi, where ri is the root of the ROBDD for Ci. This clause helps us to preserve GAC: given an assignment A such that A \u222a {xi} cannot be extended to a model of C, literal ri will be propagated using A (because the encoding for Ci is consistent). Hence the added clause will allow us to propagate xi.\nExample 18. Consider again the PB constraint C : 2x1 + 3x2 + 5x3 \u2264 6. Let us define the constraints C1 : 3x2 + 5x3 \u2264 4, C2 : 2x1 + 5x3 \u2264 3 and C3 : 2x1 + 3x2 \u2264 1. Now, we encode these constraints into ROBDDs as in the previous section, with coefficient decomposition. Figure 7 shows the resulting ROBDDs. Finally, we need to encode them into SAT consistently, and then add the clauses ri \u2228 xi, assuming that the variable associated with the root of the ROBDD for Ci is ri.\nThis encoding is GAC: take for instance the assignment A = {x1 = 1}. Constraint C3 is not satisfied. Hence, by consistency, r3 is propagated. Therefore, clause r3 \u2228 x3 propagates x3, as wanted. The propagation with other assignments is similar.\nAll in all, the suggested encoding is GAC and uses O(n3 log(aM )) clauses and auxiliary variables, where aM is the largest coefficient."}, {"heading": "5. An Algorithm for Constructing ROBDDs for Pseudo-Boolean", "text": "Constraints\nLet us fix a Pseudo-Boolean constraint a1x1 + \u00b7 \u00b7 \u00b7 + anxn \u2264 K and a variable ordering [x1, x2, . . . , xn]. The goal of this section is to prove that one can construct the ROBDD of this constraint using this ordering in polynomial time with respect to the ROBDD size and n.\nThis algorithm builds standard ROBDDs, but it can be used to build ROBDDs with coefficient decomposition: we just need to first split the coefficients and, secondly, apply the algorithm. Forthcoming Example 21 shows in detail the overall process. A very similar version of this algorithm was described by Mayer-Eichberger (2008).\nThe key point of the algorithm will be to label each node of the ROBDD with its interval. In the following, for every i \u2208 {1, 2, . . . , n + 1}, we will use a set Li consisting of pairs ([\u03b2, \u03b3],B), where B is the ROBDD of the constraint aixi + \u00b7 \u00b7 \u00b7 + anxn \u2264 K \u2032 for every K \u2032 \u2208 [\u03b2, \u03b3] (i.e., [\u03b2, \u03b3] is the interval of B). All these sets will be kept in a tuple L = (L1, L2, . . . , Ln+1).\nNote that by definition of the ROBDD\u2019s intervals, if ([\u03b21, \u03b31],B1) and ([\u03b22, \u03b32],B2) belong to Li then either [\u03b21, \u03b31] = [\u03b22, \u03b32] or [\u03b21, \u03b31]\u2229 [\u03b22, \u03b32] = \u2205. Moreover, the first case holds if and only if B1 = B2. Therefore, Li can be represented with a binary search tree-like data structure, where insertions and searches can be done in logarithmic time. The function search(K,Li) searches whether there exists a pair ([\u03b2, \u03b3],B) \u2208 Li with K \u2208 [\u03b2, \u03b3]. Such a tuple is returned if it exists, otherwise an empty interval is returned in the first component of the pair. Similarly, we will also use function insert(([\u03b2, \u03b3],B), Li) for insertions. The overall algorithm is detailed in Algorithm 1 and Algorithm 2:\nTheorem 19. Algorithm 1 runs in O(nm logm) time (where m is the size of the ROBDD) and is correct in the following sense:\n2. Actually, the diagram after replacing the variables xi,j by xj is not a ROBDD. However, we will denote them as ROBDDs for simplicity.\nAlgorithm 1 Construction of ROBDD algorithm Require: Constraint C : a1x1 + . . .+ anxn \u2264 K \u2032 Ensure: returns B the ROBDD of C. 1: for all i such that 1 \u2264 i \u2264 n+ 1 do 2: Li \u2190 { \u00c4 (\u2212\u221e,\u22121], False \u00e4 , \u00c4 [ai + ai+1 + \u00b7 \u00b7 \u00b7+ an,\u221e), T rue\n\u00e4 } 3: end for 4: L \u2190 (L1, . . . , Ln+1). 5: ([\u03b2, \u03b3],B)\u2190 BDDConstruction(1, a1x1 + . . .+ anxn \u2264 K \u2032,L). 6: return B.\nAlgorithm 2 Procedure BDDConstruction Require: integer i \u2208 {1, 2, . . . , n+ 1}, constraint C : aixi + . . .+ anxn \u2264 K \u2032 and set L Ensure: returns [\u03b2, \u03b3] interval of C and B its ROBDD 1: ([\u03b2, \u03b3],B)\u2190 search(K \u2032, Li). 2: if [\u03b2, \u03b3] 6= \u2205 then 3: return ([\u03b2, \u03b3],B) 4: else 5: ([\u03b2F , \u03b3F ],BF ) := BDDConstruction(i+ 1, ai+1xi+1 + . . .+ anxn \u2264 K \u2032,L). 6: ([\u03b2T , \u03b3T ],BT ) := BDDConstruction(i+ 1, ai+1xi+1 + . . .+ anxn \u2264 K \u2032 \u2212 ai,L). 7: if [\u03b2T , \u03b3T ] = [\u03b2F , \u03b3F ] then 8: B \u2190 BT 9: [\u03b2, \u03b3]\u2190 [\u03b2T + ai, \u03b3T ] 10: else 11: B \u2190 ite(xi,BT ,BF ) // root xi, true branch BT and false branch BF . 12: [\u03b2, \u03b3]\u2190 [\u03b2F , \u03b3F ] \u2229 [\u03b2T + ai, \u03b3T + ai] 13: end if 14: insert(([\u03b2, \u03b3],B), Li) 15: return ([\u03b2, \u03b3],B) 16: end if\n1. K \u2032 belongs to the interval returned by BDDConstruction(aixi+ \u00b7 \u00b7 \u00b7+anxn \u2264 K \u2032,L).\n2. The tuple ([\u03b2, \u03b3],B) returned by BDDConstruction consist of a BDD B and its interval [\u03b2, \u03b3].\n3. If BDDConstruction returns ([\u03b2, \u03b3],B), then the BDD B is reduced.\nProof. Let us first start with the three correctness statements:\n1. If K \u2032 is found in Li at line 1 of Algorithm 2 the statement is obviously true. Otherwise let us reason by induction on i. The base case is when i = n + 1, and since Ln+1 contains the intervals (\u2212\u221e,\u22121] and [0,\u221e], the search call at line 1 will succeed and hence the result holds. For i < n + 1 we can assume, by induction hypothesis, that K \u2032 \u2208 [\u03b2F , \u03b3F ] and K \u2032\u2212ai \u2208 [\u03b2T , \u03b3T ]. If the two intervals coincide the result is obvious, otherwise it is also easy to see that K \u2032 \u2208 [\u03b2F , \u03b3F ] \u2229 [\u03b2T + ai, \u03b3T + ai].\n2. Let us prove that in every moment all the tuples of L are correct, i.e., they contain BDDs with their correct interval. Since the returned value is always an element of some Li, this proves the statement.\nBy Proposition 5.6 and 5.7, initial tuples of L are correct. We have to prove that if all the previously inserted intervals are correct, the current interval is also correct. It follows in virtue of Proposition 7.\n3. Let us prove that all the tuples of L contain only reduced BDDs. As before, all the initial BDDs in L are reduced. Let B be a BDD computed by the algorithm, with children BT and BF . By induction hypothesis, they are reduced, so B is reduced if and only if its two children are not equal. The algorithm creates a node only if its children\u2019s intervals are different. Therefore, BT and BF do not represent the same Boolean constraint, so they are different BDDs.\nRegarding runtime, since the cost of search and insertion in Li is logarithmic in its size, the cost of the algorithm is O(logm) times the number of calls to BDDConstruction. Hence, it only remains to show that there are at most O(nm) calls.\nEvery call (but the first one) to BDDConstruction is done when we are exploring an edge of the ROBDD. Notice that no edge is explored twice, since the edges are only explored from the parent node and whenever we reach an explored node there are no recursive calls to BDDConstruction. On the other hand, for every edge of the ROBDD we make 2k\u2212 1 calls, where k is the length of the edge (if the nodes joined by the edge have variables xi and xj we say that its length is |i\u2212 j|). Since the ROBDD has O(m) edges and their length is O(n), the number of calls is O(nm).\nLet us illustrate the algorithm with an example:\nExample 20. Take the constraint C : 2x1 + 3x2 + 5x3 \u2264 6, and let us apply the algorithm to obtain the ROBDD in the ordering [x1, x2, x3]. Figure 8 represents the recursive calls to BDDConstruction and the returned parameters (the ROBDD and the interval).\n\u2022 In calls number 3, 5, 6, 8 and 9, the search function returns true and the interval and the ROBDD are returned without any other computation.\n\u2022 In call number 7, the two recursive calls return the same interval (and, therefore, the same ROBDD). Hence, that ROBDD is returned.\n\u2022 In call number 1 the two recursive calls return two different ROBDDs, so it adds a node to join the two ROBDDs into another one, which is returned. The same happens in calls number 2 and 4.\nThe overall process with coefficient decomposition would work as in the following example:\nExample 21. Let us take the constraint C : 2x1 + 3x2 + 5x3 \u2264 6. If we want to build the ROBDD with coefficient decomposition using Algorithm 1, we proceed as follows:\n1. Split the coefficients and obtain C \u2032 : 1y1 + 1y2 + 2y3 + 2y4 + 4y5 \u2264 6, where x1 = y3, x2 = y1 = y4 and x3 = y2 = y5.\n2. Apply the algorithm to C \u2032 and obtain a ROBDD B\u2032.\n3. Replace y1 for x2, y2 for x3, etc. in the nodes of B\u2032."}, {"heading": "6. SAT Encodings of BDDs for Monotonic Functions", "text": "In this section we consider a BDD representing a monotonic function F and we want to encode it into SAT. As expected, we want the encoding to be as small as possible and GAC.\nThe encoding explained here is valid with any type of BDDs, so, in particular, it is valid with ROBDDs. The main differences with the Minisat+ encoding (Ee\u0301n & So\u0308rensson, 2006) is the number of clauses generated (6 ternary clauses per node versus one binary and one ternary clauses per node) and that our encoding is GAC with any variable ordering.\nAs usual, the encoding introduces an auxiliary variable for every node. Let \u03bd be a node with selector variable x and auxiliary variable n. Let f be the variable of its false child and t be the variable of its true child. Only two clauses per node are needed:\nf \u2192 n t \u2227 x\u2192 n.\nFurthermore, we add a unit clause with the variable of the True node and another one with the negation of the variable of the False node.\nTheorem 22. The encoding is consistent in the following sense: a partial assignment A cannot be extended to a model of F if and only if r is propagated by unit propagation, where r is the root of the BDD.\nProof. We prove the theorem by induction on the number of variables of the BDD. If the BDD has no variables, then the BDD is either the True node or the False node and the result is trivial.\nAssume that the result is true for BDDs with less than k variables, and let F be a function whose BDD has k variables. Let r be the root node, x1 its selector variable and\nf, t respectively its false and true children (note that we abuse the notation and identify nodes with their auxiliary variable). We denote by F1 the function F|x1=1 (i.e., F after setting x1 to true) and by F0 the function F|x1=0.\n\u2022 Let A be a partial assignment that cannot be extended to a model of F .\n\u2013 Assume x1 \u2208 A. Since A cannot be extended, the assignment A \\ {x1} cannot be extended to a model of F1. By definition of the BDD, the function F1 has t as a BDD. By induction hypothesis, t is propagated, and since x1 \u2208 A, r is also propagated. \u2013 Assume x1 6\u2208 A. Then, the assignment A \\ {x1} cannot be extended to a model of F0. Since F0 has f as a BDD, by induction hypothesis f is propagated, and hence r also is.\n\u2022 Let A be a partial assignment, and assume r has been propagated. Then, either f has also been propagated or t has been propagated and x1 \u2208 A (note that x1 has not been propagated because it only appears in one clause which is already true).\n\u2013 Assume that f has been propagated. Since f is the BDD of F0, by induction hypothesis the assignment A \\ {x1, x1} cannot be extended to a model of F0. Since the function is monotonic, neither can A \\ {x1, x1} be extended to a model of F . Therefore, A cannot be extended to a model of F . \u2013 Assume that t has been propagated and x1 \u2208 A. Since t is the BDD of F1, by induction hypothesis A \\ {x1} cannot be extended to a model of F1, so neither can A be extended to a model of F .\nFor obtaining a GAC encoding, we only have to add a unit clause.\nTheorem 23. If we add a unit clause forcing the variable of the root node to be true, the previous encoding becomes generalized arc-consistent.\nProof. We will prove it by induction on the variables of the BDD. The case with zero variables is trivial, so let us prove the induction case.\nAs before, let r be the root node, with x1 its selector variable and n its auxiliary variable, and f, t its false and true children. We denote by F0 and F1 the functions F|x1=0 and F|x1=1.\nLet A be a partial assignment that can be extended to a model of F . Assume that A \u222a {xi} cannot be extended. We want to prove that xi will be propagated.\n\u2022 Let us assume that x1 \u2208 A. In this case, t is propagated due to the clause t\u2227 x1 \u2192 n and the unit clause n. Since x1 \u2208 A and A\u222a{xi} cannot be extended to a model of F , A \\ {x1}\u222a {xi} neither can be extended to an assignment satisfying F1. By induction hypothesis, since t is the BDD of the function F1, xi is propagated.\n\u2022 Let us assume that x1 6\u2208 A and xi 6= x1. Since F is monotonic, A \u222a {xi} cannot be extended to a model of F if and only if it cannot be extended to a model of F0. Notice that f is propagated thanks to the clause f \u2192 n and the unit clause n. By induction hypothesis, the method is GAC for F0, so xi is propagated.\n\u2022 Finally, assume that x1 6\u2208 A and xi = x1. Since A \u222a {x1} cannot be extended to a model of F , A cannot be extended to a model of F1. By Theorem 22, t is propagated and, due to t \u2227 x1 \u2192 n and n, also is x1.\nWe finish this section with an example illustrating how the suggested encoding of BDDs into SAT can be used in the different PB encoding methods we have presented in this paper.\nExample 24. Consider the constraint C : 2x1 + 3x2 + 5x3 \u2264 6. We will encode this constraint into SAT with three methods: with the usual ROBDD encoding; with the consistent approach of ROBDDs and splitting of the coefficients, explained in Section 4.2; and with the GAC approach of ROBDDs and splitting of the coefficients explained in Section 4.3.\n1. BDD-1: this method builds the ROBDD for C and then encodes it into SAT. Hence we start by building the ROBDD of C, which can be seen in the last picture of Figure 1. Now, we need to encode it into SAT. Let y1, y2 and y3 be fresh variables corresponding to the nodes of the ROBDD of C having respectively x1, x2 and x3 as selector variable.\nFor node y1, we have to add the clauses y2 \u2192 y1 and x1 \u2227 y3 \u2192 y1. For y2, we have to add the clauses > \u2192 y2 and x2\u2227 y3 \u2192 y2, where > is the tautology symbol.\nFor y3, we have to add the clauses > \u2192 y3 and x3 \u2227 \u22a5 \u2192 y3, where \u22a5 is the contradiction symbol.\nMoreover, we have to add the unit clauses >, \u22a5 and y1. All in all, after removing the units and tautologies, the clauses obtained are y1, y2, x1 \u2228 y3, x2 \u2228 y3 and x3 \u2228 y3.\n2. BDD-2: we build the ROBDD of C with coefficient decomposition as in Example 21. Figure 6 shows the resulting ROBDD. We introduce variables y1, y2, . . . , y6 for every node of the ROBDD. More precisely, the first x2 node (starting top-down) receives variable y1, the next x2 node gets y5. The first x3 receives y2 and the other one y6. Finally the leftmost x1 node gets variable y3 and the other one y4. We have to add the following clauses: y2 \u2192 y1, y4\u2227x2 \u2192 y1, y3 \u2192 y2, y4\u2227x3 \u2192 y2, > \u2192 y3, y5\u2227x1 \u2192 y3, y5 \u2192 y4, y6 \u2227 x1 \u2192 y4, > \u2192 y5, y6 \u2227 x2 \u2192 y5, > \u2192 y6, \u22a5 \u2227 x3 \u2192 y6, and the unit clauses >, \u22a5 and y1. After removing the units from the clauses and tautologies, we obtain y1, y2, y3, y4\u2228x2, y4 \u2228 x3, y5 \u2228 x1, y5 \u2228 y4, y6 \u2228 x1 \u2228 y4, y6 \u2228 x2 \u2228 y5 and x3 \u2228 y6. Notice that this encoding is consistent: if we have the assignment A = {x2, x3}, then y4 is propagated by the clause y4\u2228x2, which in turn propagates y5 due to clause y5\u2228y4 and finally y6 is propagated by the clause y6 \u2228 x2 \u2228 y5. A contradiction is found with clause x3 \u2228 y6. However, the encoding is not GAC: the partial assignment A = {x1} can only propagate y5. However, x3 should also be propagated.\n3. BDD-3: let C1, C2 and C3 be the constraints setting respectively x1, x2 and x3 to true. Figure 7 shows the ROBDDs of these constraints. We have to encode these ROBDDs\nas usual, as in BDD-2, but replacing the unit clause r of the root by r \u2192 xi. In this case the variables associated with the roots of C1, C2 and C3 will be y1, z1 and w1 respectively.\nAfter removing the units and tautologies, clauses from C1 are y1\u2228x1, y2\u2228y1, y4\u2228x2\u2228y1, y3 \u2228 y2, y4 \u2228 x3 \u2228 y2, y4 \u2228 x2 \u2228 y3 and x3 \u2228 y4. Clauses from C2 are z1 \u2228 x2 and x3 \u2228 z1. Finally, clauses from C3 are w1 \u2228 x3, w2 \u2228 w1, x1 \u2228 w1 and x2 \u2228 w2. This encoding is GAC. Take, for instance, the assignment A = {x1}. In this case, w1 is propagated in virtue of x1 \u2228 w1 and x3 is propagated by clause w1 \u2228 x3."}, {"heading": "7. Related Work", "text": "Due to the ubiquity of Pseudo-Boolean constraints and the success of SAT solvers, the problem of encoding those constraints into SAT has been thoroughly studied in the literature. In the following we review the most important contributions, paying special attention to the basic idea on which they are based, the encoding size, and the propagation properties the encodings fulfill. To ease the presentation, in the remaining of this section we will always assume that the constraint we want to encode is a1x1 + . . . + anxn \u2264 k, with maximum coefficient amax.\nThe first encoding to mention is the one proposed by Warners (1998). In a nutshell, the encoding uses several adders for numbers in binary representation. First of all, the left hand side of the constraint is split into two halves, each of which is recursively treated to compute the corresponding partial sum. After that, the two partial sums are added and the final result is compared with k . The encoding uses O(n log(amax)) clauses and variables and is neither consistent nor GAC. This is not surprising, since adders for numbers in binary make extensive use of xors, which do not have good propagation properties.\nBailleux et al. (2006) introduced an encoding \u201cvery close to those using a BDD and translating it into clauses\u201d. In order to understand the differences between their construction and BDDs let us introduce it in detail. First of all, the coefficients are ordered from small to large. Then, the root is labeled with variable Dn,k, expressing that the sum of the first n terms is no more than k. Its two children are Dn\u22121,k and Dn\u22121,k\u2212an , which correspond to setting xn to false and true, respectively. The process is repeated until nodes corresponding to trivial constraints are reached, which are encoded as true or false. For each node Di,b with children Di\u22121,b and Di\u22121,b\u2212ai , the following four clauses are added:\nDi\u22121,b\u2212ai \u2192 Di,b Di\u22121,b \u2192 Di,b Di\u22121,b\u2212ai \u2227 xi \u2192 Di,b Di\u22121,b \u2227 xi \u2192 Di,b\nExample 25. The encoding proposed by Bailleux et al. (2006) on 2x1 + \u00b7 \u00b7 \u00b7+ 2x10 + 5x11 + 6x12 \u2264 10 is illustrated in Figure 9. Node D10,5 represents 2x1 + 2x2 + \u00b7 \u00b7 \u00b7 + 2x10 \u2264 5, whereas node D10,4 represents 2x1 + 2x2 + \u00b7 \u00b7 \u00b7 2x10 \u2264 4. The method fails to identify that these two PB constraints are equivalent and hence subtrees B and C will not be merged, yielding a much larger representation than with ROBDDs.\nThe resulting encoding is GAC, but an example of a PB constraint family is given for which their kind of non-reduced BDDs, with their concrete variable ordering is exponentially large. However, as we have shown in Section 3.2, ROBDDs for this family are polynomial.\nSeveral important new contributions were presented in the paper by the MiniSAT team (Ee\u0301n & So\u0308rensson, 2006). The paper describes three encodings, all of which are implemented in the MiniSAT+ tool. The first one is a standard ROBDD construction for Pseudo-Boolean constraints. This is done in two steps: first, they suggest a simple dynamic programming algorithm for constructing a non-reduced BDD, which is later reduced. The result is a ROBDD, but the first step may take exponential time even if the final ROBDD is polynomial. Once the ROBDD is constructed, they suggest to encode it into SAT using 6 ternary clauses per node. The paper showed that, given a concrete variable ordering, the encoding is GAC. Regarding the ROBDD size, the authors cite the work of Bailleux et al. (2006) to state the BDDs are exponential in the worst case. As we have seen before, the citation is not correct because Bailleux et al do not construct ROBDDs.\nThe second method is similar to the one of Warners (1998) in the sense that the construction relies on a network of adders. First of all coefficients are decomposed into binary representation. For each bit i, a bucket is created with all variables whose coefficient has bit i set to one. The i-th bit of the left-hand side of the constraint is computed using a series of full adders and half adders. Finally, the resulting sum is lexicographically compared to k. The resulting encoding is neither consistent nor GAC and uses a number of adders linear in the sum of the number of digits of the coefficients.\nThe last method they suggest is the use of sorting networks. Numbers are expressed in unary representation and coefficients are decomposed using a mixed radix representation. The smaller the number in this representation, the smaller the encoding. In this setting, sorting networks are used to play the same role of adders, but with better propagation properties. If N is smaller than the sum of the digits of all coefficients in base 2, the size of the encoding is O(N log2N). Whereas this encoding is not GAC for arbitrary PseudoBoolean constraints, generalized arc-consistency is obtained for cardinality constraints.\nThe first polynomial and GAC encoding for Pseudo-Boolean constraints, called WatchDog, was introduced by Bailleux et al. (2009). It uses O(n2 log n log amax) variables and O(n3 log n log amax) clauses. Again, numbers are expressed in unary representation and totalizers are used to play the role of sorting networks. In order to make the comparison with the right hand side trivial, the left-hand side and k are incremented until k becomes a power of two. Then, all coefficients are decomposed in binary representation and each bit is added independently, taking into account the corresponding carry. In the same paper, another encoding which is only consistent and uses O(n log n log amax) variables and O(n2 log n log amax) clauses is also presented.\nFinally, it is worth mentioning the work of Bartzis and Bultan (2003). The authors deal with the more general case in which the variables xi are not Boolean, but bounded integers 0 \u2264 xi < 2b. They suggest a BDD-based approach very similar in flavor to our method of Section 4, but instead of decomposing the coefficients as we do, they decompose the variables xi in binary representation. The BDD ordering starts with the first bit of x1, then the first bit of the x2, etc... After that, the second bit is treated in a similar fashion, and so on. The resulting BDD has O(n \u00b7 b \u00b7\u2211 ai) nodes and nothing is mentioned about propagation properties. For the case of Pseudo-Boolean constraints, i.e. b = 1, their approach amounts to standard BDDs.\nTable 1 summarizes the different encodings of PB constraints into SAT."}, {"heading": "8. Experimental Results", "text": "The goal of this section is to assess the practical interest of the encodings we have presented in the paper. Our aim is to evaluate to which extent BDD-based encodings are interesting from the practical point of view. For us, this means to study whether they are competitive with existing techniques, whether they show good behavior in general or are only interesting for very specific types of problems, or whether they produce smaller encodings.\nFor that purpose, first of all, we compare our encodings with other SAT encodings in terms of encoding time, number of clauses and number of variables. After that, we also consider total runtime (that is, encoding time plus solving time) of these encodings and we compare it with the runtime of state-of-the-art Pseudo-Boolean solvers. Finally, we briefly report on some experiments with sharing, that is, trying to encode several Pseudo-Boolean constraints in a single ROBDD.\nAll experiments were performed on a 2Ghz Linux Quad-Core AMD with a time limit of 1800 seconds per benchmark. The benchmarks used for these experiments were obtained from the Pseudo-Boolean Competition 2011 (http://www.cril.univ-artois.fr/PB11/), category no optimization, small integers, linear constraints (DEC-SMALLINT-LIN). For compactness and clarity, we have grouped benchmarks that come from the same source into families. However, individual results can be found at http://www.lsi.upc.edu/~iabio/ BDDs/results.ods."}, {"heading": "8.1 The Bergmann-Hommel Test", "text": "In order to summarize the experiments and make it easier to extract conclusions, every experiment is accompanied with a Bergmann-Hommel non-parametric hypothesis test (Bergmann & Hommel, 1988) of the results with a confidence level of 0.1.\nThe Bergmann-Hommel test is a way of comparing the results of n different methods over multiple independent data sets. It gives us two interesting pieces of information. First of all, it sorts the methods by giving them a real number between 1 and n, such that the lower the number the better the method. Moreover, it indicates, for each pair of methods, whether one method significantly improves upon the other. As an example, Figure 10 is the output of a Bergmann-Hommel test. BDD-1 is the best method but there is not significant difference between this method and BDD-2 (this is illustrated by a thick line connecting the methods). On the other hand, the Bergmann-Hommel test indicates that BDD-1 is significantly better than Adder, since there is no thick line connecting BDD-1 and Adder. The same can be said for BDD-1 and WD-1, BDD-1 and BDD-3, BDD-1 and WD-2, BDD-2 and Adder, etc.\nWe will now give a quick overview of how a Bergmann-Hommel test is computed. The remaining of this section can be skipped if the reader is not interested in the details of the test. On the other hand, for more detailed information, we refer the reader to the work of Bergmann and Hommel (1988).\nLet us assume we have n methods and m data sets, and let Ci,j be the result (time, number of variables or any other value) of the i-th method in the j-th benchmark. For every data set, we assign a number to every method: the best method in that data set has a 1, the second has a 2, and so on. Then, for every method, we compute the average of these values in the different data sets. The obtained value is denoted by Ri and is called the average rank of the i-th method. A method with smaller average rank is better than a method with a bigger one.\nThese average ranks make it possible to rank the different methods. However, we are also interested in detecting whether the differences between the methods are significant or not: this is computed in the second part of the test. Before that, we need some previous definitions.\nGiven i, j \u2208 N = {1, 2, . . . , n}, we denote by pi,j the p-value3 of zi,j = Ri\u2212Rj\u221a n(n\u22121)/(6m) with respect a normal distribution N(0, 1). A partition of N = {1, 2, . . . , n} is a collection of sets P = {P1, P2, . . . , Pr} such that (i) the Pi\u2019s are subsets of N , (ii) P1 \u222aP2 \u222a \u00b7 \u00b7 \u00b7 \u222aPr = N and\n3. The p-value of z with respect to a normal distribution N(0, 1) is the probability p[ |Z| > |z| ], where the random variable Z \u223c N(0, 1).\n(iii) Pi \u2229 Pj = \u2205 for every i 6= j. Given P a partition of N , we define\nL(P ) = r\u2211\ni=1\n|Pi|(|Pi| \u2212 1) 2\nand p(P ) as the minimum pi,j such that i and j belong to the same subset Pk \u2208 P . The Bergmann-Hommel test ensures (with a significance level of \u03b1) that the methods i and j are not significantly different if and only if there is a partition P with p(P ) > \u03b1L(P ) such that i and j belong to the same subset Pk \u2208 P . Hence, it is a time-consuming test since the number of partitions can be very large.\nIn our case, the data sets are the families of benchmarks. We have to use the families instead of the benchmarks because the data sets must be independent."}, {"heading": "8.2 Encodings into SAT", "text": "We start by comparing different methods for encoding Pseudo-Boolean constraints into SAT. We have focused on the time spent by the encoding, the number of auxiliary variables used and the number of clauses. Moreover, for each benchmark family, we also report the number of PB-constraints that were encoded into SAT.\nThe encodings we have included in the experimental evaluation are: the adder encoding as presented by Ee\u0301n and So\u0308rensson (2006) (Adder), the consistent WatchDog encoding of Bailleux et al. (2009) (WD-1), its GAC version (WD-2), the encoding into ROBDDs without coefficient decomposition, using Algorithm 1 and the encoding from Section 6 (BDD1); the encoding into ROBDDs after coefficient decomposition as explained in Section 4.2 (BDD-2), with Algorithm 1 and the encoding from Section 6; and the GAC approach from Section 4.3 (BDD-3 ), also with Algorithm 1 and the encoding from Section 6. Notice that BDD-1 method is very similar to the ROBDDs presented by Ee\u0301n and So\u0308rensson (2006). However, since Algorithm 1 produces every node only once, BDD-1 should be faster. Also, the encoding of Section 6 only creates two clauses per BDD node, as opposed to six clauses as suggested by Ee\u0301n and So\u0308rensson.\nTable 2 shows the number of problems that the different methods could encode without timing out. The first column corresponds to the family of problems. The second column shows the number of problems in this family. The third and fourth columns contain the average number of SAT and Pseudo-Boolean constraints in the problem. For the experiments, we considered a constraint to be SAT if it is a clause or has at most 3 variables. Small PB constraints do not benefit from the above encodings and hence for these constraints a naive encoding into SAT was always used. The remaining columns correspond to the number of encoded problems without timing out. Time limit was set to 1800 seconds per benchmark.\nTable 3 shows the time spent to encode the benchmarks by the different methods. As before, the first columns correspond to the family of problems, the number of problems in this family and the average number of SAT and Pseudo-Boolean constraints in the problems. The remaining columns correspond to the average encoding time (in seconds) per benchmarks of each method. Timeouts are counted as 1800 seconds in the average computation.\nTable 4 shows the average number of auxiliary variables required for encoding the PB constraints (SAT constraints are not counted). The meaning of the first 4 columns is\nthe same as before, and the others contain the average number of auxiliary variables (in thousands) of the benchmarks that did not time out.\nFinally, Table 5 contains the average number (in thousands) of clauses needed to encode the problem. As before, we have only considered the benchmarks that have not timed out, and clauses due to the encoding of SAT constraints are not counted.\nFigures 10, 11 and 12 represent the Bergmann-Hommel tests of these tables. They show that BDD-1, BDD-2 and Adders are the best methods in terms of time, variables and clauses. It is worth mentioning that BDD-1 and BDD-2 are faster and use significantly less clauses than Adder. However, Adders uses significantly less auxiliary variables than BDD-2. Notice that BDD-1 is GAC, BDD-2 is only consistent and Adder is not consistent, so at least theoretically BDD-1 clauses have more unit propagation power than BDD-2 clauses, and BDD-2 clauses are better than Adder clauses. Hence, BDD-1 is the best method using these criteria and BDD-2 is better than Adder. Regarding the other methods, it seems clear\nthat encoding n different constraints in order to obtain GAC, as it is done in WD-2 and BDD-3, is not a good idea in terms of variables and clauses."}, {"heading": "8.3 SAT vs. PB", "text": "In this section we compare the state-of-the-art solvers for Pseudo-Boolean problems and some encodings into SAT. For the SAT approach, once the encoding has been done, the SAT formula is given to the SAT Solver Lingeling (Biere, 2010) version 276. We have considered the same SAT encodings as in the previous section. Regarding Pseudo-Boolean solvers, we have considered MiniSAT+ (Ee\u0301n & So\u0308rensson, 2006) and the best non-parallel solvers in the No optimization, small integers, linear constraints category of the PseudoBoolean Competition: borg (Silverthorn & Miikkulainen, 2010) version pb-dec-11.04.03, bsolo (Manquinho & Silva, 2006) version 3.2, wbo (Manquinho, Martins, & Lynce, 2010) version 1.4 and SAT4J (Berre & Parrain, 2010) version 2.2.1. We have also included the SMT Solver Barcelogic (Bofill, Nieuwenhuis, Oliveras, Rodr\u0301\u0131guez-Carbonell, & Rubio, 2008) for PB constraints, which couples a SAT solver with a theory solver for PB constraints.\nTable 6 shows the number of instances solved by each method. Table 7 shows the average time spent by all these methods. For the SAT encodings, times include both the encoding and SAT solving time. As before, a time limit of 1800 seconds per benchmark was set, and for the average computation, a timeout is counted as 1800 seconds. Both tables include a column VBS (Virtual Best Solver), which represents the best solver in every instance. This gives an idea of which speedup we could obtain with a portfolio approach.\nFigure 13 shows the result of the Bergmann-Hommel test: SMT is the best method, whereas Adder, BDD-3 and WD-2 are the worst ones. There are no significant difference between the other methods. The main conclusion we can infer is that BDD encodings are definitely a competitive method. Also, there is no technique that outperforms the others in all benchmark families, and hence portfolio strategies would make a lot of sense in this\narea, as witnessed by the performance of Borg, which implements such an approach. Finally, we also want to mention that the possible exponential explosion of BDDs rarely occurs in practice and hence, coefficient decomposition does not seem to pay off in practical situations.\nRegarding the Best Virtual Solver, SMT contributes to 52% of the problems. In 25% of the cases the best solution was given by a specific PB solver. Among them, Wbo contributes with 10% of the problems and bsolo with 8%. Finally, encoding methods give the best solution in the 23% of the cases: 14% of the times due to Watchdog methods and 8% of the times due to BDD-based methods."}, {"heading": "8.4 Sharing", "text": "One of the possible advantages of using ROBDDs to encode Pseudo-Boolean constraints is that ROBDDs allow one to encode a set of constraints, and not just one. It would seem natural to think that if two constraints are similar enough, the two individual ROBDDs would be similar in structure, and merging them into a single one would result in a ROBDD whose size is smaller than the sum of the two individual ROBDDs. However, the main difficulty is to decide which constraints should be encoded together, since a bad choice could result in a ROBDD whose size is larger than the sum of the ROBDDs for the individual constraints.\nWe performed initial experiments where the criteria of similarity between constraints only took into account which variables appeared in the constraints. We first fixed an integer k and chose the constraint with the largest set of variables. After that, we looked for a constraint such that all but k variables appeared in the first constraint. The next step was to look for another constraint such that all but k variables appeared in any of the two previous constraints and so on, until reaching a fixpoint. Finally, all selected constraints were encoded together.\nWe tried this experiment on all benchmarks with different values of k and it rarely gave any advantage. However, we still believe that there could be a way of encoding different constraints into a single ROBDD, but different criteria for selecting the constraints should be studied. We see this as a possible line of future research."}, {"heading": "9. Conclusions and Future Work", "text": "Both theoretical and practical contributions have been made. Regarding the theoretical part, we have negatively answered the question of whether all PB constraints admit polynomial BDDs by citing the work of Hosaka et al. (1994) which, to the best of our knowledge, is largely unknown in our research community. Moreover, we have given a simpler proof assuming that NP is different from co-NP, which relates the subset sum problem and the ROBDDs\u2019 size of PB constraints.\nAt the practical level, we have introduced a ROBDD-based polynomial and generalized arc-consistent encoding of PB constraints and developed a BDD-based generalized arcconsistent encoding of monotonic functions that only uses two clauses per BDD node. We have also presented an algorithm to efficiently construct all these ROBDDs and proved that the overall method is competitive in practice with state-of-the-art encodings and tools. As future work at the practical level, we plan to study which type of Pseudo-Boolean\nconstraints are likely to produce smaller ROBDDs if encoded together rather than being encoded individually."}, {"heading": "Acknowledgments", "text": "All UPC authors are partially supported by Spanish Min. of Educ. and Science through the LogicTools-2 project (TIN2007-68093-C02-01). Ab\u0301\u0131o is also partially supported by FPU grant."}], "references": [{"title": "BDDs for pseudoboolean constraints: revisited", "author": ["I. Ab\u0301\u0131o", "R. Nieuwenhuis", "A. Oliveras", "E. Rod\u0155\u0131guez-Carbonell"], "venue": "In Proceedings of the 14th international conference on Theory and application of satisfiability testing,", "citeRegEx": "Ab\u0301\u0131o et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ab\u0301\u0131o et al\\.", "year": 2011}, {"title": "Generic ILP versus specialized 0-1 ILP: an update", "author": ["F.A. Aloul", "A. Ramani", "I.L. Markov", "K.A. Sakallah"], "venue": "In Proceedings of the 2002 IEEE/ACM international conference on Computer-aided design,", "citeRegEx": "Aloul et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Aloul et al\\.", "year": 2002}, {"title": "A Translation of Pseudo Boolean Constraints to SAT", "author": ["O. Bailleux", "Y. Boufkhad", "O. Roussel"], "venue": "Journal on Satisfiability, Boolean Modeling and Computation, JSAT,", "citeRegEx": "Bailleux et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Bailleux et al\\.", "year": 2006}, {"title": "New Encodings of Pseudo-Boolean Constraints into CNF", "author": ["O. Bailleux", "Y. Boufkhad", "O. Roussel"], "venue": "12th International Conference on Theory and Applications of Satisfiability Testing, SAT \u201909,", "citeRegEx": "Bailleux et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bailleux et al\\.", "year": 2009}, {"title": "Construction of efficient bdds for bounded arithmetic constraints. In Proceedings of the 9th international conference on Tools and algorithms for the construction and analysis", "author": ["C. Bartzis", "T. Bultan"], "venue": "of systems,", "citeRegEx": "Bartzis and Bultan,? \\Q2003\\E", "shortCiteRegEx": "Bartzis and Bultan", "year": 2003}, {"title": "Improvements of general multiple test procedures for redundant systems of hypotheses", "author": ["B. Bergmann", "G. Hommel"], "venue": "Multiple Hypothesenprfung - Multiple Hypotheses Testing,", "citeRegEx": "Bergmann and Hommel,? \\Q1988\\E", "shortCiteRegEx": "Bergmann and Hommel", "year": 1988}, {"title": "The Sat4j library, release", "author": ["D.L. Berre", "A. Parrain"], "venue": "Journal on Satisfiability, Boolean Modeling and Computation, JSAT,", "citeRegEx": "Berre and Parrain,? \\Q2010\\E", "shortCiteRegEx": "Berre and Parrain", "year": 2010}, {"title": "Circuit complexity and decompositions of global constraints", "author": ["C. Bessiere", "G. Katsirelos", "N. Narodytska", "T. Walsh"], "venue": "In Proceedings of the 21st international jont conference on Artifical intelligence,", "citeRegEx": "Bessiere et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bessiere et al\\.", "year": 2009}, {"title": "Lingeling, Plingeling, PicoSAT and PrecoSAT at SAT Race 2010. Tech. rep., Institute for Formal Models and Verification", "author": ["A. Biere"], "venue": null, "citeRegEx": "Biere,? \\Q2010\\E", "shortCiteRegEx": "Biere", "year": 2010}, {"title": "The Barcelogic SMT Solver", "author": ["M. Bofill", "R. Nieuwenhuis", "A. Oliveras", "E. Rod\u0155\u0131guez-Carbonell", "A. Rubio"], "venue": "In Computer-aided Verification (CAV),", "citeRegEx": "Bofill et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bofill et al\\.", "year": 2008}, {"title": "Graph-Based Algorithms for Boolean Function Manipulation", "author": ["R.E. Bryant"], "venue": "IEEE Transactions on Computers,", "citeRegEx": "Bryant,? \\Q1986\\E", "shortCiteRegEx": "Bryant", "year": 1986}, {"title": "Deciding CLU Logic Formulas via Boolean and Pseudo-Boolean Encodings", "author": ["R.E. Bryant", "S.K. Lahiri", "S.A. Seshia"], "venue": "In Proceedings of the International Workshop on Constraints in Formal Verification, CFV 02. Associated with International Conference on Principles and Practice of Constraint Programming", "citeRegEx": "Bryant et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Bryant et al\\.", "year": 2002}, {"title": "Translating Pseudo-Boolean Constraints into SAT", "author": ["N. E\u00e9n", "N. S\u00f6rensson"], "venue": "Journal on Satisfiability, Boolean Modeling and Computation,", "citeRegEx": "E\u00e9n and S\u00f6rensson,? \\Q2006\\E", "shortCiteRegEx": "E\u00e9n and S\u00f6rensson", "year": 2006}, {"title": "On the Size of Ordered Binary Decision Diagrams Representing Threshold Functions", "author": ["K. Hosaka", "Y. Takenaga", "S. Yajima"], "venue": "In Algorithms and Computation, 5th International Symposium,", "citeRegEx": "Hosaka et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Hosaka et al\\.", "year": 1994}, {"title": "Improving Unsatisfiability-Based Algorithms for Boolean Optimization", "author": ["V.M. Manquinho", "R. Martins", "I. Lynce"], "venue": "13th International Conference on Theory and Applications of Satisfiability Testing,", "citeRegEx": "Manquinho et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Manquinho et al\\.", "year": 2010}, {"title": "On Using Cutting Planes in Pseudo-Boolean Optimization", "author": ["V.M. Manquinho", "J.P.M. Silva"], "venue": "Journal on Satisfiability, Boolean Modeling and Computation, JSAT,", "citeRegEx": "Manquinho and Silva,? \\Q2006\\E", "shortCiteRegEx": "Manquinho and Silva", "year": 2006}, {"title": "Towards Solving a System of Pseudo Boolean Constraints with Binary Decision Diagrams. Master\u2019s thesis, New University of Lisbon", "author": ["V. Mayer-Eichberger"], "venue": null, "citeRegEx": "Mayer.Eichberger,? \\Q2008\\E", "shortCiteRegEx": "Mayer.Eichberger", "year": 2008}, {"title": "Why cumulative decomposition is not as bad as it sounds", "author": ["A. Schutt", "T. Feydy", "P.J. Stuckey", "M.G. Wallace"], "venue": "In Proceedings of the 15th international conference on Principles and practice of constraint programming,", "citeRegEx": "Schutt et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Schutt et al\\.", "year": 2009}, {"title": "Latent class models for algorithm portfolio methods", "author": ["B. Silverthorn", "R. Miikkulainen"], "venue": "In Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence", "citeRegEx": "Silverthorn and Miikkulainen,? \\Q2010\\E", "shortCiteRegEx": "Silverthorn and Miikkulainen", "year": 2010}, {"title": "On Boolean Functions Encodable as a Single Linear Pseudo-Boolean Constraint", "author": ["J. Smaus"], "venue": "4th International Conference on the Integration of AI and OR Techniques in Constraint Programming, CPAIOR \u201907,", "citeRegEx": "Smaus,? \\Q2007\\E", "shortCiteRegEx": "Smaus", "year": 2007}, {"title": "A Linear-Time Transformation of Linear Inequalities into Conjunctive Normal Form", "author": ["J.P. Warners"], "venue": "Information Processing Letters,", "citeRegEx": "Warners,? \\Q1998\\E", "shortCiteRegEx": "Warners", "year": 1998}], "referenceMentions": [{"referenceID": 10, "context": "Since, given a variable ordering, ROBDDs are a canonical representation for Boolean functions (Bryant, 1986), i.", "startOffset": 94, "endOffset": 108}, {"referenceID": 8, "context": ", cumulative scheduling (Schutt, Feydy, Stuckey, & Wallace, 2009), logic synthesis (Aloul, Ramani, Markov, & Sakallah, 2002) or verification (Bryant, Lahiri, & Seshia, 2002), so it is not surprising that a significant number of SAT encodings for these constraints have been proposed in the literature. Here we are interested in encoding a PB constraint C by a clause set S (possibly with auxiliary variables) that is not only equisatisfiable, but also generalized arc-consistent (GAC): given a partial assignment A, if xi is false in every extension of A satisfying C, then unit propagating A on S sets xi to false. To our knowledge, the only polynomial GAC encoding so far was given by Bailleux, Boufkhad, and Roussel (2009). Some other existing encodings are based on building (forms of) Binary Decision Diagrams (BDDs) and translating these into CNF.", "startOffset": 142, "endOffset": 726}, {"referenceID": 2, "context": "Although the approach of Bailleux et al. is not BDD-based, our main motivation to revisit BDD-based encodings is the following: Example 1. Let us consider two Pseudo-Boolean constraints: 3x1 + 2x2 + 4x3 \u2264 5 and 30001x1 + 19999x2 + 39998x3 \u2264 50007. Both are clearly equivalent: the Boolean function they represent can be expressed, e.g., by the clauses x1\u2228x3 and x2\u2228x3. However, encodings like the one of Bailleux et al. (2009) heavily depend on the concrete coefficients of each constraint, and generate a significantly larger SAT encoding for the second one.", "startOffset": 25, "endOffset": 427}, {"referenceID": 12, "context": "A good example is the work of E\u00e9n and S\u00f6rensson (2006), where a GAC encoding using six three-literals clauses per BDD node is given.", "startOffset": 30, "endOffset": 55}, {"referenceID": 12, "context": "A good example is the work of E\u00e9n and S\u00f6rensson (2006), where a GAC encoding using six three-literals clauses per BDD node is given. However, when it comes to study the BDD size, on page 9 they cite the work of Bailleux, Boufkhad, and Roussel (2006) to say \u201cIt is proven that in general a PB-constraint can generate an exponentially sized BDD\u201d.", "startOffset": 30, "endOffset": 250}, {"referenceID": 12, "context": "A good example is the work of E\u00e9n and S\u00f6rensson (2006), where a GAC encoding using six three-literals clauses per BDD node is given. However, when it comes to study the BDD size, on page 9 they cite the work of Bailleux, Boufkhad, and Roussel (2006) to say \u201cIt is proven that in general a PB-constraint can generate an exponentially sized BDD\u201d. In Section 7 we explain why the approach of Bailleux et al does not use ROBDDs, and prove that the example they use to show the exponentiality of their method turns out to have polynomial ROBDDs. Somewhat surprisingly, probably due to the different names that PB constraints receive (0-1 integer linear constraints, linear threshold functions, weight constraints, knapsack constraints), the work of Hosaka, Takenaga, and Yajima (1994) has remained unknown to our research community.", "startOffset": 30, "endOffset": 780}, {"referenceID": 13, "context": "2: We reproduce the family of PB constraints proposed by Hosaka et al. (1994), for which no polynomial-size ROBDD exist.", "startOffset": 57, "endOffset": 78}, {"referenceID": 13, "context": "Extensions include: (i) proofs of all technical results, (ii) multiple examples illustrating the various concepts and algorithms presented, (iii) the PB constraint family by Hosaka et al. (1994) for which no polynomial ROBDD exists, (iv) an algorithm to efficiently construct ROBDDs for Pseudo-Boolean constraints, (v) a detailed related work section, (vi) extensive experimental results comparing our encoding to other approaches and (vii) a brief report of our experience trying to take advantage of the sharing potential of BDDs.", "startOffset": 174, "endOffset": 195}, {"referenceID": 2, "context": "2 we consider two families of PB constraints and study their ROBDD size: we first prove that the example given by Bailleux et al. (2006) has polynomial ROBDDs, and then we reproduce the example of Hosaka et al.", "startOffset": 114, "endOffset": 137}, {"referenceID": 2, "context": "2 we consider two families of PB constraints and study their ROBDD size: we first prove that the example given by Bailleux et al. (2006) has polynomial ROBDDs, and then we reproduce the example of Hosaka et al. (1994) that has exponential ROBDDs regardless of the variable ordering.", "startOffset": 114, "endOffset": 218}, {"referenceID": 2, "context": "2 Some Families of PB Constraints and their ROBDD Size We start by revisiting the family of PB constraints given by Bailleux et al. (2006), where it is proved that, for their concrete variable ordering, their non-reduced BDDs grow exponentially for this family.", "startOffset": 116, "endOffset": 139}, {"referenceID": 2, "context": "But the ROBDD of C \u2032 is known to be of quadratic size because it is a cardinality constraint (see, for instance, Bailleux et al., 2006). In the following, we present a family of PB constraints that only admit exponential ROBDDs. This example was first given by Hosaka et al. (1994), but a clearer alternative proof is given next.", "startOffset": 113, "endOffset": 282}, {"referenceID": 4, "context": "A similar idea was given by Bartzis and Bultan (2003). The important remark is that, using a consistent SAT encoding of the ROBDD for C\u0303 (e.", "startOffset": 28, "endOffset": 54}, {"referenceID": 2, "context": "In order to overcome this limitation, we follow the method presented by Bessiere, Katsirelos, Narodytska, and Walsh (2009) and Bailleux et al. (2009). Let C : a1x1+\u00b7 \u00b7 \u00b7+anxn \u2264 K be an arbitrary PB constraint.", "startOffset": 127, "endOffset": 150}, {"referenceID": 16, "context": "A very similar version of this algorithm was described by Mayer-Eichberger (2008). The key point of the algorithm will be to label each node of the ROBDD with its interval.", "startOffset": 58, "endOffset": 82}, {"referenceID": 18, "context": "The first encoding to mention is the one proposed by Warners (1998). In a nutshell, the encoding uses several adders for numbers in binary representation.", "startOffset": 53, "endOffset": 68}, {"referenceID": 2, "context": "Bailleux et al. (2006) introduced an encoding \u201cvery close to those using a BDD and translating it into clauses\u201d.", "startOffset": 0, "endOffset": 23}, {"referenceID": 2, "context": "Bailleux et al. (2006) introduced an encoding \u201cvery close to those using a BDD and translating it into clauses\u201d. In order to understand the differences between their construction and BDDs let us introduce it in detail. First of all, the coefficients are ordered from small to large. Then, the root is labeled with variable Dn,k, expressing that the sum of the first n terms is no more than k. Its two children are Dn\u22121,k and Dn\u22121,k\u2212an , which correspond to setting xn to false and true, respectively. The process is repeated until nodes corresponding to trivial constraints are reached, which are encoded as true or false. For each node Di,b with children Di\u22121,b and Di\u22121,b\u2212ai , the following four clauses are added: Di\u22121,b\u2212ai \u2192 Di,b Di\u22121,b \u2192 Di,b Di\u22121,b\u2212ai \u2227 xi \u2192 Di,b Di\u22121,b \u2227 xi \u2192 Di,b Example 25. The encoding proposed by Bailleux et al. (2006) on 2x1 + \u00b7 \u00b7 \u00b7+ 2x10 + 5x11 + 6x12 \u2264 10 is illustrated in Figure 9.", "startOffset": 0, "endOffset": 849}, {"referenceID": 2, "context": "Figure 9: Tree-like construction of Bailleux et al. (2006) for 2x1+\u00b7 \u00b7 \u00b7+2x10+5x11+6x12\u226410", "startOffset": 36, "endOffset": 59}, {"referenceID": 2, "context": "Regarding the ROBDD size, the authors cite the work of Bailleux et al. (2006) to state the BDDs are exponential in the worst case.", "startOffset": 55, "endOffset": 78}, {"referenceID": 2, "context": "Regarding the ROBDD size, the authors cite the work of Bailleux et al. (2006) to state the BDDs are exponential in the worst case. As we have seen before, the citation is not correct because Bailleux et al do not construct ROBDDs. The second method is similar to the one of Warners (1998) in the sense that the construction relies on a network of adders.", "startOffset": 55, "endOffset": 289}, {"referenceID": 20, "context": "GAC Warners (Warners, 1998) O(n log amax) NO NO Non-reduced BDD (Bailleux et al.", "startOffset": 12, "endOffset": 27}, {"referenceID": 2, "context": "GAC Warners (Warners, 1998) O(n log amax) NO NO Non-reduced BDD (Bailleux et al., 2006) Exponential YES YES ROBDD (E\u00e9n & S\u00f6rensson, 2006) Exponential (6 per node) YES YES Adders (E\u00e9n & S\u00f6rensson, 2006) O(\u2211 log ai) NO NO Sorting Networks (E\u00e9n & S\u00f6rensson, 2006) O((\u2211 log ai) log2(\u2211 log ai) YES NO Watch Dog (WD) (Bailleux et al.", "startOffset": 64, "endOffset": 87}, {"referenceID": 3, "context": ", 2006) Exponential YES YES ROBDD (E\u00e9n & S\u00f6rensson, 2006) Exponential (6 per node) YES YES Adders (E\u00e9n & S\u00f6rensson, 2006) O(\u2211 log ai) NO NO Sorting Networks (E\u00e9n & S\u00f6rensson, 2006) O((\u2211 log ai) log2(\u2211 log ai) YES NO Watch Dog (WD) (Bailleux et al., 2009) O(n2 log n log amax) YES NO Gen.", "startOffset": 231, "endOffset": 254}, {"referenceID": 3, "context": "WD (Bailleux et al., 2009) O(n3 log n log amax) YES YES", "startOffset": 3, "endOffset": 26}, {"referenceID": 2, "context": "The first polynomial and GAC encoding for Pseudo-Boolean constraints, called WatchDog, was introduced by Bailleux et al. (2009). It uses O(n2 log n log amax) variables and O(n3 log n log amax) clauses.", "startOffset": 105, "endOffset": 128}, {"referenceID": 2, "context": "The first polynomial and GAC encoding for Pseudo-Boolean constraints, called WatchDog, was introduced by Bailleux et al. (2009). It uses O(n2 log n log amax) variables and O(n3 log n log amax) clauses. Again, numbers are expressed in unary representation and totalizers are used to play the role of sorting networks. In order to make the comparison with the right hand side trivial, the left-hand side and k are incremented until k becomes a power of two. Then, all coefficients are decomposed in binary representation and each bit is added independently, taking into account the corresponding carry. In the same paper, another encoding which is only consistent and uses O(n log n log amax) variables and O(n2 log n log amax) clauses is also presented. Finally, it is worth mentioning the work of Bartzis and Bultan (2003). The authors deal with the more general case in which the variables xi are not Boolean, but bounded integers 0 \u2264 xi < 2b.", "startOffset": 105, "endOffset": 823}, {"referenceID": 5, "context": "On the other hand, for more detailed information, we refer the reader to the work of Bergmann and Hommel (1988). Let us assume we have n methods and m data sets, and let Ci,j be the result (time, number of variables or any other value) of the i-th method in the j-th benchmark.", "startOffset": 85, "endOffset": 112}, {"referenceID": 10, "context": "The encodings we have included in the experimental evaluation are: the adder encoding as presented by E\u00e9n and S\u00f6rensson (2006) (Adder), the consistent WatchDog encoding of Bailleux et al.", "startOffset": 102, "endOffset": 127}, {"referenceID": 2, "context": "The encodings we have included in the experimental evaluation are: the adder encoding as presented by E\u00e9n and S\u00f6rensson (2006) (Adder), the consistent WatchDog encoding of Bailleux et al. (2009) (WD-1), its GAC version (WD-2), the encoding into ROBDDs without coefficient decomposition, using Algorithm 1 and the encoding from Section 6 (BDD1); the encoding into ROBDDs after coefficient decomposition as explained in Section 4.", "startOffset": 172, "endOffset": 195}, {"referenceID": 2, "context": "The encodings we have included in the experimental evaluation are: the adder encoding as presented by E\u00e9n and S\u00f6rensson (2006) (Adder), the consistent WatchDog encoding of Bailleux et al. (2009) (WD-1), its GAC version (WD-2), the encoding into ROBDDs without coefficient decomposition, using Algorithm 1 and the encoding from Section 6 (BDD1); the encoding into ROBDDs after coefficient decomposition as explained in Section 4.2 (BDD-2), with Algorithm 1 and the encoding from Section 6; and the GAC approach from Section 4.3 (BDD-3 ), also with Algorithm 1 and the encoding from Section 6. Notice that BDD-1 method is very similar to the ROBDDs presented by E\u00e9n and S\u00f6rensson (2006). However, since Algorithm 1 produces every node only once, BDD-1 should be faster.", "startOffset": 172, "endOffset": 685}, {"referenceID": 8, "context": "For the SAT approach, once the encoding has been done, the SAT formula is given to the SAT Solver Lingeling (Biere, 2010) version 276.", "startOffset": 108, "endOffset": 121}, {"referenceID": 13, "context": "Regarding the theoretical part, we have negatively answered the question of whether all PB constraints admit polynomial BDDs by citing the work of Hosaka et al. (1994) which, to the best of our knowledge, is largely unknown in our research community.", "startOffset": 147, "endOffset": 168}], "year": 2012, "abstractText": "Pseudo-Boolean constraints are omnipresent in practical applications, and thus a significant effort has been devoted to the development of good SAT encoding techniques for them. Some of these encodings first construct a Binary Decision Diagram (BDD) for the constraint, and then encode the BDD into a propositional formula. These BDD-based approaches have some important advantages, such as not being dependent on the size of the coefficients, or being able to share the same BDD for representing many constraints. We first focus on the size of the resulting BDDs, which was considered to be an open problem in our research community. We report on previous work where it was proved that there are Pseudo-Boolean constraints for which no polynomial BDD exists. We also give an alternative and simpler proof assuming that NP is different from Co-NP. More interestingly, here we also show how to overcome the possible exponential blowup of BDDs by coefficient decomposition. This allows us to give the first polynomial generalized arc-consistent ROBDD-based encoding for Pseudo-Boolean constraints. Finally, we focus on practical issues: we show how to efficiently construct such ROBDDs, how to encode them into SAT with only 2 clauses per node, and present experimental results that confirm that our approach is competitive with other encodings and state-of-the-art Pseudo-Boolean solvers.", "creator": "TeX"}}}