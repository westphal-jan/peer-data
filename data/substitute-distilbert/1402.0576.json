{"id": "1402.0576", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Feb-2014", "title": "Optimizing SPARQL Query Answering over OWL Ontologies", "abstract": "the sparql query terminology is currently being extended by the world educational web consortium ( w3c ) with so - called indirect regimes. an implementation regime defines how queries are evaluated under more expressive semantics since sparqls standard simple entailment, which is based outside subgraph matching. the queries are very expressive wherein variables can place within complex concepts and can also corresponded to concept or role names. in same paper, we obtain a sound and complete algorithm for the unique direct semantics entailment regime. we further propose several novel categories such as strategies for determining at good query execution order, semantic rewriting techniques, and show how specialized owl reasoning tasks and the concept and role hierarchy can, used to reduce the query execution time. for determining extremely good execution order, we propose a cost - based model, where the costs scales based on information about the instances of concepts and roles that could extracted from a model abstraction built by an owl reasoner. gibson present two ordering strategies : a static and a dynamic one. targeting the dynamic case, he improve the accessibility by exploiting an individual clustering approach that allows consistently computing the cost functions based on one individual sample from a cluster. we provide a prototypical implementation and evaluate the efficiency of the specific optimizations. our experimental study results that the static ordering architecture outperforms the dynamic rules when accurate statistics easily stored. this changes, however, when the statistics are normally accurate, e. g., due to nondeterministic reasoning decisions. for queries that go beyond conjunctive instance queries we welcome an improvement of up | three orders of magnitude due to the proposed optimizations.", "histories": [["v1", "Tue, 4 Feb 2014 01:39:51 GMT  (408kb)", "http://arxiv.org/abs/1402.0576v1", null]], "reviews": [], "SUBJECTS": "cs.DB cs.AI", "authors": ["ilianna kollia", "birte glimm"], "accepted": false, "id": "1402.0576"}, "pdf": {"name": "1402.0576.pdf", "metadata": {"source": "CRF", "title": "Optimizing SPARQL Query Answering over OWL Ontologies", "authors": ["Ilianna Kollia", "Birte Glimm"], "emails": ["ilianna2@mail.ntua.gr", "birte.glimm@uni-ulm.de"], "sections": [{"heading": null, "text": "In this paper, we describe a sound and complete algorithm for the OWL Direct Semantics entailment regime. We further propose several novel optimizations such as strategies for determining a good query execution order, query rewriting techniques, and show how specialized OWL reasoning tasks and the concept and role hierarchy can be used to reduce the query execution time. For determining a good execution order, we propose a cost-based model, where the costs are based on information about the instances of concepts and roles that are extracted from a model abstraction built by an OWL reasoner. We present two ordering strategies: a static and a dynamic one. For the dynamic case, we improve the performance by exploiting an individual clustering approach that allows for computing the cost functions based on one individual sample from a cluster.\nWe provide a prototypical implementation and evaluate the efficiency of the proposed optimizations. Our experimental study shows that the static ordering usually outperforms the dynamic one when accurate statistics are available. This changes, however, when the statistics are less accurate, e.g., due to nondeterministic reasoning decisions. For queries that go beyond conjunctive instance queries we observe an improvement of up to three orders of magnitude due to the proposed optimizations."}, {"heading": "1. Introduction", "text": "Query answering is important in the context of the Semantic Web since it provides a mechanism via which users and applications can interact with ontologies and data. Several query languages have been designed for this purpose, including RDQL (Seaborne, 2004), SeRQL (Broekstra & Kampman, 2006) and, most recently, SPARQL. In this paper, we consider the SPARQL query language (Prud\u2019hommeaux & Seaborne, 2008), which was standardized in 2008 by the World Wide Web Consortium (W3C) and which is currently being extended to SPARQL 1.1 (Harris & Seaborne, 2013). Since 2008, SPARQL has developed into the main query language for the Semantic Web and is now supported by most RDF triple stores. The query evaluation mechanism defined in the SPARQL Query specification is based on subgraph matching. This form of query evaluation is also called simple entailment since it can equally be defined in terms of the simple entailment relation between RDF graphs (Hayes, 2004). SPARQL 1.1 includes several entailment regimes (Glimm & Ogbuji, 2013)\nc\u00a92013 AI Access Foundation. All rights reserved.\nin order to use more elaborate entailment relations, such as those induced by RDF Schema (RDFS) (Brickley & Guha, 2004) or OWL (Motik, Patel-Schneider, & Cuenca Grau, 2012b; Schneider, 2012). Query answering under such entailment regimes is more complex as it may involve retrieving answers that only follow implicitly from the queried graph, which is seen as an OWL ontology when using OWL entailment. While several implementations for SPARQL\u2019s RDFS entailment regime are available (e.g., Oracle 11g (Oracle, 2013), Apache Jena (The Apache Software Foundation, 2013), or Stardog (Clark & Parsia, 2013b)), the development of tools that provide full SPARQL support under OWL semantics is still an ongoing effort.\nSince we consider the OWL Direct Semantics entailment regime of SPARQL 1.1 in this paper, when we talk about SPARQL queries or the evaluation of SPARQL queries, we always assume that the OWL Direct Semantics entailment regime is used. In this setting, the WHERE clause of a query can be seen as a set of extended OWL axioms (an extended OWL ontology), which can have variables in place of concept, role or individual names. The query answers contain each instantiation of the variables that leads to OWL axioms that are entailed by the queried ontology. Thus, a naive query evaluation procedure can be realized through OWL\u2019s standard reasoning task of entailment checking.\nPlease note that there are two types of individual variables in SPARQL; standard (distinguished) variables and anonymous individuals (aka blank nodes). The anonymous individuals are treated like distinguished variables with the difference that they cannot be selected and, hence, their bindings cannot appear in the query answer. This is in contrast to conjunctive queries, where anonymous individuals are treated as existential variables. On the other hand, anonymous individuals can occur in the query answer as bindings to distinguished variables, i.e., SPARQL treats anonymous individuals from the queried ontology as constants. This treatment of anonymous individuals has been chosen for compatibility with SPARQL\u2019s standard subgraph matching semantics. For example, in order to implement the RDF(S) entailment regime, systems can simply extend the queried graph with inferred information (materialization) and can then use SPARQL\u2019s standard evaluation mechanism over the materialized graph in order to compute the query results. Similarly, when users move on to systems that support the OWL RL profile (Motik, Cuenca Grau, Horrocks, Wu, Fokoue, & Lutz, 2012a), the OWL RL rule set from the OWL 2 specification can be used to compute the query answers (again via materialization). If one were to change the semantics of blank nodes for SPARQL\u2019s entailment regimes to reflect conjunctive query semantics, one could no longer use materialization plus a standard SPARQL query processor to implement the entailment regime. If one were to change the semantics of blank nodes only for the OWL Direct Semantics entailment regime, where materialization cannot be used to implement the regime, users would not simply get more answers by moving from systems that support RDF(S) to systems that support OWL\u2019s Direct Semantics, but it could also happen that they get less answers by using a more expressive logic, which is counter-intuitive.\nOver the last decade, much effort has been spent on optimizing standard reasoning tasks such as entailment checking, classification, or realization (i.e., the computation of instances of all concepts and roles) (Sirin, Cuenca Grau, & Parsia, 2006; Tsarkov, Horrocks, & PatelSchneider, 2007; Glimm, Horrocks, Motik, Shearer, & Stoilos, 2012). The optimization of query answering algorithms has, however, mostly been addressed for conjunctive queries in OWL profiles, most notably the OWL 2 QL profile (Calvanese, Giacomo, Lembo, Lenzerini,\n& Rosati, 2007; Kontchakov, Lutz, Toman, Wolter, & Zakharyaschev, 2010; Pe\u0301rez-Urbina, Motik, & Horrocks, 2010; Rodriguez-Muro & Calvanese, 2012). An exception to this are the works on nRQL and SPARQL-DL. The query language nRQL is supported by Racer Pro (Haarslev, Mo\u0308ller, & Wessel, 2004) and SPARQL-DL is implemented in the Pellet reasoner (Sirin, Parsia, Grau, Kalyanpur, & Katz, 2007). We discuss this in greater detail in Section 8.\nIn this paper, we address the problem of efficient SPARQL query evaluation for OWL 2 DL ontologies by proposing a range of novel optimizations that deal in particular with the expressive features of SPARQL such as variables in place of concepts or roles. We further adapt common techniques from databases such as cost-based query planning. The costs for our cost model are based on information about the instances of concepts and roles that are extracted from a model abstraction built by an OWL reasoner. We present a static and a dynamic algorithm for finding an optimal or near optimal execution order and for the dynamic case, we improve the performance by exploiting an individual clustering approach that allows for computing the cost functions based on one individual sample from a cluster. We further propose query rewriting techniques and show how specialized OWL reasoning tasks and the concept and role hierarchy can be used to reduce the query execution time. We provide a prototypical implementation and evaluate the efficiency of the proposed optimizations. Our experimental study shows that the static ordering usually outperforms the dynamic one when accurate statistics are available. This changes, however, when the statistics are less accurate, e.g., due to non-deterministic reasoning decisions. For queries that go beyond conjunctive SPARQL instance queries, we observe an improvement of up to three orders of magnitude due to the proposed optimizations.\nNote that this paper combines and extends two conference papers: I. Kollia and B. Glimm: Cost based Query Ordering over OWL Ontologies. Proceedings of the 11th International Semantic Web Conference, 2012 and I. Kollia, B. Glimm and I. Horrocks: SPARQL Query Answering over OWL Ontologies. Proceedings of the 8th Extended Semantic Web Conference, 2011. In the current paper we have, additionally to the first above mentioned paper, defined cost functions for general SPARQL queries (i.e., not only for conjunctive instance queries) and added experimental results for these expressive queries. In comparison to the second of the above mentioned papers, we have defined the notion of concept and role polarity and presented theorems that let us prune the search space of possible mappings for axiom templates based on the polarity together with an algorithm that shows the way we use the optimization. Moreover, more experimental results have been added for complex queries that make use of this optimization.\nThe remainder of the paper is organized as follows: we next present some preliminaries, we then present a general query evaluation algorithm in Section 3 that serves as the basis for further optimization. In Section 4, we present the foundations for our cost model, which we then specify in Section 5. In Section 6, we present optimizations for complex queries that cannot directly be mapped to specialized reasoner tasks. Finally, we evaluate our approach in Section 7 and discuss related work in Section 8 before we conclude in Section 9."}, {"heading": "2. Preliminaries", "text": "In this section, we first give a brief introduction into Description Logics since the OWL Direct Semantics is based on the Description Logic SROIQ (Horrocks, Kutz, & Sattler, 2006). The optimizations we present do not need all features of SROIQ. Hence, we only present SHOIQ, which allows for a shorter and easier to follow presentation.\nAfter introducing SHOIQ, we clarify the relationship between RDF, SPARQL and OWL, we present SPARQL\u2019s OWL Direct Semantics entailment regime and we give an overview of the model building tableau and hypertableau calculi.\n2.1 The Description Logic SHOIQ\nWe first define the syntax and semantics of roles, and then go on to SHOIQ-concepts, individuals, and ontologies/knowledge bases.\nDefinition 1 (Syntax of SHOIQ ). Let NC , NR, and NI be countable, infinite, and pairwise disjoint sets of concept names, role names, and individual names, respectively. We call S = (NC ,NR,NI ) a signature. The set rol(S) of SHOIQ-roles over S (or roles for short) is NR \u222a {r \u2212 | r \u2208 NR} \u222a {\u22a4r,\u22a5r}, where roles of the form r \u2212 are called inverse roles, \u22a4r is the top role (analogous to owl:topObjectProperty), and \u22a5r is the bottom role (analogous to owl:bottomObjectProperty). A role inclusion axiom is of the form r \u2291 s with r, s roles. A transitivity axiom is of the form trans(r) for r a role. A role hierarchy H is a finite set of role inclusion and transitivity axioms.\nFor a role hierarchy H, we define the function inv over roles as inv(r) := r\u2212 if r \u2208 NR and inv(r) := s if r = s\u2212 for a role name s \u2208 NR. Further, we define \u2291H as the smallest transitive reflexive relation on roles such that r \u2291 s \u2208 H implies r \u2291H s and inv(r) \u2291H inv(s). We write r \u2261H s if r \u2291H s and s \u2291H r. A role r is transitive w.r.t. H (notation r+ \u2291H r) if a role s exists such that r \u2291H s, s \u2291H r, and trans(s) \u2208 H or trans(inv(s)) \u2208 H. A role s is called simple w.r.t. H if there is no role r such that r is transitive w.r.t. H and r \u2291H s.\nGiven a signature S = (NC , NR, NI ) and a role hierarchy H, the set of SHOIQconcepts (or concepts for short) over S is the smallest set built inductively over symbols from S using the following grammar, where o \u2208 NI , A \u2208 NC , n \u2208 IN0, s is a simple role w.r.t. H, and r is a role w.r.t. H:\nC ::= \u22a4 | \u22a5 | {o} | A | \u00acC | C \u2293 C | C \u2294 C | \u2200r.C | \u2203r.C | 6n s.C | >n s.C.\nWe now define the semantics of SHOIQ concepts:\nDefinition 2 (Semantics of SHOIQ-concepts). An interpretation I = (\u2206I , \u00b7I) consists of a non-empty set \u2206I, the domain of I, and a function \u00b7I , which maps every concept name A \u2208 NC to a subset A I \u2286 \u2206I , every role name r \u2208 NR to a binary relation r I \u2286 \u2206I \u00d7\u2206I, and every individual name a \u2208 NI to an element a I \u2208 \u2206I. The top role \u22a4r is interpreted as {\u3008\u03b4, \u03b4\u2032\u3009 | \u03b4, \u03b4\u2032 \u2208 \u2206I} and the bottom role \u22a5r as \u2205. For each role name r \u2208 NR, the interpretation of its inverse role (r\u2212) I consists of all pairs \u3008\u03b4, \u03b4\u2032\u3009 \u2208 \u2206I \u00d7 \u2206I for which \u3008\u03b4\u2032, \u03b4\u3009 \u2208 rI.\nThe semantics of SHOIQ-concepts over a signature S is defined as follows:\n\u22a4I = \u2206I \u22a5I = \u2205 ({o})I = {oI} (\u00acC)I = \u2206I \\ CI (C \u2293D)I = CI \u2229DI (C \u2294D)I = CI \u222aDI\n(\u2200r.C)I = {\u03b4 \u2208 \u2206I | if \u3008\u03b4, \u03b4\u2032\u3009 \u2208 rI , then \u03b4\u2032 \u2208 CI} (\u2203r.C)I = {\u03b4 \u2208 \u2206I | there is a \u3008\u03b4, \u03b4\u2032\u3009 \u2208 rI with \u03b4\u2032 \u2208 CI}\n(6n s.C)I = {\u03b4 \u2208 \u2206I | \u266f(sI(\u03b4, C)) \u2264 n} (>n s.C)I = {\u03b4 \u2208 \u2206I | \u266f(sI(\u03b4, C)) \u2265 n}\nwhere \u266f(M) denotes the cardinality of the set M and sI(\u03b4, C) is defined as\n{\u03b4\u2032 \u2208 \u2206I | \u3008\u03b4, \u03b4\u2032\u3009 \u2208 sI and \u03b4\u2032 \u2208 CI}.\nDefinition 3 (Syntax and Semantics of Axioms and Ontologies, Entailment). For C,D concepts, a (general) concept inclusion axiom (GCI) is an expression C \u2291 D. We introduce C \u2261 D as an abbreviation for C \u2291 D and D \u2291 C. A finite set of GCIs is called a TBox. An (ABox) (concept or role) assertion axiom is an expression of the form C(a), r(a, b), \u00acr(a, b), a \u2248 b, or a 6\u2248 b, where C \u2208 NC is a concept, r \u2208 NR is a role, and a, b \u2208 NI are individual names. An ABox is a finite set of assertion axioms. An ontology O is a triple (T , H, A) with T a TBox, H a role hierarchy, and A an ABox. We use NO\nC , NO R ,\nand NO I\nto denote, respectively, the set of concept, role, and individual names occurring in O.\nLet I = (\u2206I , \u00b7I) be an interpretation. Then I satisfies a role inclusion axiom r \u2291 s if rI \u2286 sI, I satisfies a transitivity axiom trans(r) if rI is a transitive binary relation, and a role hierarchy H if it satisfies all role inclusion and transitivity axioms in H. The interpretation I satisfies a GCI C \u2291 D if CI \u2286 DI; and I satisfies a TBox T if it satisfies each GCI in T . The interpretation I satisfies an assertion axiom C(a) if aI \u2208 CI, r(a, b) if \u3008aI , bI\u3009 \u2208 rI , \u00acr(a, b) if \u3008aI , bI\u3009 /\u2208 rI , a \u2248 b if aI = bI , and a 6\u2248 b if aI 6= bI ; I satisfies an ABox if it satisfies each assertion in A. We say that I satisfies O if I satisfies T , H, and A. In this case, we say that I is a model of O and write I |= O. We say that O is consistent if O has a model.\nGiven an axiom \u03b1, we say that O entails \u03b1 (written O |= \u03b1) if every model I of O satisfies \u03b1.\nDescription Logics can further be extended with concrete domains, which correspond to OWL\u2019s datatypes. In such a case, one distinguishes between abstract roles that relate two individuals and concrete roles that relate an individual with a data value. The Description Logic SROIQ further allows for a number of features such as role chains of the form hasFather \u25e6 hasBrother \u2291 hasUncle, support for the special concept Self, which can be used in axioms of the form Narcissist \u2291 \u2203loves.Self, or for defining roles that are reflexive, irreflexive, symmetric, or asymmetric.\nDescription Logic ontologies can equally be expressed in terms of OWL ontologies, which in turn can be mapped into RDF graphs (Patel-Schneider & Motik, 2012). The other direction is, however, not always possible, i.e., a mapping from RDF graphs to OWL ontologies is only defined for certain well-formed RDF graphs that correspond to an OWL 2 DL ontology."}, {"heading": "2.2 The Relationship between RDF, SPARQL, and OWL", "text": "SPARQL queries are evaluated over RDF graphs which remain the basic data structure even when adopting a more elaborate semantic interpretation.\nDefinition 4 (RDF Graphs). RDF is based on the set I of International Resource Identifiers (IRIs), the set L of RDF literals, and the set B of blank nodes. The set T of RDF terms is I \u222a L \u222a B. An RDF graph is a set of RDF triples of the form (subject, predicate, object) \u2208 (I \u222aB)\u00d7 I \u00d7 T .\nWe generally abbreviate IRIs using prefixes rdf, rdfs, owl, and xsd to refer to the RDF, RDFS, OWL, and XML Schema Datatypes namespaces, respectively. The empty prefix is used for an imaginary example namespace, which we completely omit in Description Logic syntax.\nAn example of a SPARQL query is\nSELECT ?x FROM <ontologyIRI> WHERE { ?x rdf:type :C . ?x :r ?y }\nThe WHERE clause of the SPARQL query consists of a basic graph pattern (BGP): an RDF graph written in Turtle syntax (Beckett, Berners-Lee, Prud\u2019hommeaux, & Carothers, 2013), where some nodes or edges are replaced by variables. A basic graph pattern is more precisely defined as follows:\nDefinition 5 (Basic Graph Pattern). Let V be a countably infinite set of query variables disjoint from T . A triple pattern is a member of the set (T \u222a V )\u00d7 (I \u222a V )\u00d7 (T \u222a V ), and a basic graph pattern (BGP) is a set of triple patterns.\nWe do not recall the complete surface syntax of SPARQL here since the only part that is specific to the evaluation of SPARQL queries under OWL\u2019s Direct Semantics is the evaluation of BGPs. More complex WHERE clauses, which use operators such as UNION for alternative selection criteria or OPTIONAL to query for optional bindings (Prud\u2019hommeaux & Seaborne, 2008), can be evaluated simply by combining the results obtained by the BGP evaluation. Similarly, operations such as the projection of variables from the SELECT clause is a straightforward operation over the results of the evaluation of the WHERE clause. Therefore, we focus here on BGP evaluation only. For a more detailed introduction to SPARQL queries and their algebra we refer interested readers to the work of Hitzler, Kro\u0308tzsch, and Rudolph (2009) or Glimm and Kro\u0308tzsch (2010).\nSince the Direct Semantics of OWL is defined in terms of OWL structural objects, i.e., OWL axioms, we map the BGPs of SPARQL queries into structural objects, which can have variables in place of class (concept), object or data property (abstract or concrete role), or individual names or literals. Since there is a direct mapping between OWL axioms and Description Logic axioms, BGPs can be expressed as Description Logic axioms in which variables can occur in place of concept, role and individual names. For example, the BGP of the previous example is mapped to ClassAssertion(C ?x) and ObjectPropertyAssertion(r ?x ?y) in functional-style syntax or to C(?x) and r(?x, ?y) in Description Logic syntax.\nFor further details, we refer interested readers to the W3C specification that defines the mapping between OWL structural objects and RDF graphs (Patel-Schneider & Motik, 2012) and to the specification of the OWL Direct Semantics entailment regime of SPARQL\n(Glimm & Ogbuji, 2013) that defines the extension of this mapping between BGPs and OWL objects with variables."}, {"heading": "2.3 SPARQL Queries", "text": "In the following, we directly write BGPs in Description Logic notation extended to allow for variables in place of concept, role and individual names in axioms. It is worth reminding that SPARQL does not support existentially quantified variables, which is in contrast to database-style conjunctive queries, where one typically also has existential/nondistinguished variables.\nFor brevity and without loss of generality, we assume here that neither the query nor the queried ontology contains anonymous individuals. We further do not consider data properties and literals, but the presented optimizations can easily be transferred to this case.\nDefinition 6 (Query). Let S = (NC ,NR,NI ) be a signature. A query signature Sq w.r.t. S is a six-tuple (NC ,NR,NI ,VC ,VR,VI ), where VC , VR, and VI are countable, infinite, and pairwise disjoint sets of concept variables, role variables, and individual variables disjoint from NC , NR, and NI . A concept term is an element from NC \u222a VC . A role term is an element from NR \u222a VR. An individual term is an element from NI \u222a VI . An axiom template over Sq is a SROIQ axiom over S, where one can also use concept variables from VC in place of concept names, role variables from VR in place of role names, and individual variables from VI in place of individual names. A query q w.r.t. a query signature Sq is a non-empty set of axiom templates over Sq. We use Vars(q) (Vars(at) for an axiom template at) to denote the set of all variables in q (at) and |q| to denote the number of axiom templates in q. Let t, t\u2032 be individual terms; we call axiom templates of the form A(t) with A \u2208 NC , r(t, t\u2032) with r \u2208 NR, or t \u2248 t\n\u2032 query atoms. A conjunctive instance query q w.r.t. a query signature Sq is a non-empty set of query atoms.\nFor a function \u00b5, we use dom(\u00b5) to denote the domain of \u00b5. Let O be an ontology over S and q = {at1, . . . , atn} a query over Sq consisting of n axiom templates. A mapping \u00b5 for q over O is a total function \u00b5 : Vars(q) \u2192 NO\nC \u222a NO R \u222a NO I such that\n1. \u00b5(v) \u2208 NO C for each v \u2208 VC \u2229 dom(\u00b5),\n2. \u00b5(v) \u2208 NO R for each v \u2208 VR \u2229 dom(\u00b5),\n3. \u00b5(v) \u2208 NO I for each v \u2208 VI \u2229 dom(\u00b5), and\n4. O \u222a \u00b5(q) is a SROIQ ontology.\nWe write \u00b5(q) (\u00b5(at)) to denote the result of replacing each variable v in q (at) with \u00b5(v). The set \u0393Oq of the compatible mappings for q over O is defined as \u0393 O q := {\u00b5 | \u00b5 is a mapping for q over O}. A mapping \u00b5 is a solution mapping or a certain answer for q over O if O |= \u00b5(q). We denote the set containing all solution mappings for q over O with \u2126Oq . The result size or the number of answers of a query q over O is given by the cardinality of the set \u2126Oq .\nNote that the last condition in the definition of mappings is required to ensure decidability of query entailment. For example, without the condition, a reasoner might have to\ntest instantiated axiom templates where a role variable has been replaced by a non-simple role in a number restriction, which is not allowed in Description Logic axioms. Note also that we do not indicate which variables are to be selected since we do not consider the straightforward task of projection here. Examples of queries according to the above definition are the following (where ?x is a concept variable, ?y a role variable, and ?z an individual variable):\nC \u2291 \u2203?y.?x\n(\u2203r.?x)(?z)\nIn the remainder, we use S for a signature (NC ,NR,NI ), O to denote a SROIQ ontology over S, A,B \u2208 NC for concept names from O, r, s \u2208 NR for role names from O, a, b \u2208 NI for individual names from O, ?x, ?y for variables, c1, c2 for concept terms, r1, r2 for role terms, t, t\u2032 for individual terms, q = {at1, . . . , atn} for a query with n axiom templates over the query signature Sq = (NC ,NR,NI ,VC ,VR,VI ), \u0393 O q for the compatible mappings and \u2126Oq for the solution mappings of q over O."}, {"heading": "2.4 Model-building (Hyper)Tableau Calculi", "text": "In this section, we give a brief overview over the main reasoning techniques for OWL DL ontologies since our cost-based query planning relies on these techniques.\nIn order to check whether an ontology O entails an axiom \u03b1, one typically checks whether O \u222a {\u00ac\u03b1} has a model. If that is not the case, then every model of O satisfies \u03b1 and O |= \u03b1. For example, to check whether an individual a0 is an instance of a concept C w.r.t. an ontology O, we check whether adding the concept assertion \u00acC(a0) to O leads to an inconsistency. To check this, most OWL reasoners use a model construction calculus such as tableau or hypertableau. In the remainder, we focus on the hypertableau calculus (Motik, Shearer, & Horrocks, 2009), but a tableau calculus could equally be used and we state how our results can be transferred to tableau calculi.\nThe hypertableau calculus starts from the initial set of ABox assertions and, by applying derivation rules, it tries to construct (an abstraction of) a model of O. Derivation rules usually add new concept or role assertion axioms, they may introduce new individuals, they can be nondeterministic, leading to the need to choose between several alternative assertion axioms to add or they can lead to a clash when a contradiction is detected. To show that an ontology O is (in)consistent, the hypertableau calculus constructs a derivation, i.e., a sequence of sets of assertions A0, . . . ,An, such that A0 contains all ABox assertions in O, Ai+1 is the result of applying a derivation rule to Ai and An is the final set of assertions where no more rules are applicable. If a derivation exists such that An does not contain a clash, then O is consistent and An is called a pre-model of O. Otherwise O is inconsistent. Each assertion in a set of assertions Ai is derived either deterministically or nondeterministically. An assertion is derived deterministically if it is derived by the application of a deterministic derivation rule from assertions that were all derived deterministically. Any other derived assertion is derived nondeterministically. It is easy to know whether an assertion was derived deterministically or not because of the dependency directed backtracking that most (hyper)tableau reasoners employ. In the pre-model, each individual s0 is assigned a label L(s0) representing the concepts it is (non)deterministically an instance of and each\npair of individuals \u3008s0, s1\u3009 is assigned a label L(\u3008s0, s1\u3009) representing the roles through which individual s0 is (non)deterministically related to individual s1."}, {"heading": "3. Motivation", "text": "A straightforward algorithm to compute the answers for a query q is to test, for each mapping \u00b5, whether O |= \u00b5(q). Since only terms that are used in O can occur in the range of a mapping \u00b5 for q over O, there are finitely many mappings to test. In the worst case, however, the number of mappings that have to be tested is still exponential in the number of variables in the query. Such an algorithm is sound and complete if the reasoner used to decide entailment is sound and complete since we check all mappings for variables that can constitute actual solution mappings.\nOptimizations cannot easily be integrated into the above sketched algorithm since it uses the reasoner to check for the entailment of the instantiated query as a whole and, hence, does not take advantage of relations or dependencies that may exist between the individual axiom templates in q. For a more optimized evaluation, one can evaluate the query axiom template by axiom template. Initially, the solution set contains only the identity mapping, which does not map any variable to a value. One then picks the first axiom template, extends the identity mapping to cover the variables of the chosen axiom template and then uses a reasoner to check which of the mappings instantiate the axiom template into an entailed axiom. One then picks the next axiom template and again extends the mappings from the previous round to cover all variables and checks which of those mappings lead to an entailed axiom. Thus, axiom templates which are very selective and are only satisfied by very few solutions reduce the number of intermediate solutions. Choosing a good execution order, therefore, can significantly affect the performance.\nFor example, let q = {A(?x), r(?x, ?y)} with ?x, ?y \u2208 VI . The query belongs to the class of conjunctive instance queries. We assume that the queried ontology contains 100 individuals, only 1 of which belongs to the concept A. This A instance has 1 r-successor, while we have overall 200 pairs of individuals related with the role r. If we first evaluate A(?x), we test 100 mappings (since ?x is an individual variable), of which only 1 mapping satisfies the axiom template. We then evaluate r(?x, ?y) by extending the mapping with all 100 possible mappings for ?y. Again only 1 mapping yields a solution. For the reverse axiom template order, the first axiom template requires the test of 100 \u00b7100 mappings. Out of those, 200 remain to be checked for the second axiom template and we perform 10, 200 tests instead of just 200. Note also that the number of intermediate results when the query is evaluated in the order A(?x), r(?x, ?y) is smaller than when it is evaluated in the reverse order (2 versus 201).\nIn the context of databases or triple stores, cost-based ordering techniques for finding an optimal or near optimal join ordering have been widely applied (Steinbrunn, Moerkotte, & Kemper, 1997; Stocker, Seaborne, Bernstein, Kiefer, & Reynolds, 2008). These techniques involve the maintenance of a set of statistics about relations and indexes, e.g., number of pages in a relation, number of pages in an index, number of distinct values in a column, together with formulas for the estimation of the selectivity of predicates and the estimation of the CPU and I/O costs of query execution that depends amongst others, on the number of pages that have to be read from or written to secondary memory. The formulas for the\nestimation of selectivities of predicates (result output size of axiom templates) estimate the data distributions using histograms (Ioannidis & Christodoulakis, 1993), parametric or sampling methods or combinations of them. Ordering strategies as implemented in databases or triple stores are, however, not directly applicable in our setting. In the presence of expressive schema level axioms, we cannot rely on counting the number of occurrences of triples. We also cannot, in general, precompute all relevant inferences to base our statistics on materialized inferences. Furthermore, we should not only aim at decreasing the number of intermediate results, but also take into account the cost of checking or computing the solutions. This cost can be very significant with OWL reasoning and its precise estimation before query evaluation is difficult as this cost takes values from a wide range, e.g., due to nondeterminism and the high worst-case complexity of the standard reasoning tasks.1\nFor several kinds of axiom templates we can, however, directly retrieve the solutions from the reasoner instead of checking entailment. For example, for C(?x), reasoners typically have a method to retrieve concept instances. Although this might internally trigger several tests, most methods of reasoners are highly optimized and avoid as many tests as possible. Furthermore, reasoners typically cache several results such as the computed concept hierarchy and retrieving sub-concepts can then be realized with a cache lookup. Thus, the actual execution cost might vary significantly. Notably, we do not have a straight correlation between the number of results for an axiom template and the actual cost of retrieving the solutions as is typically the case in triple stores or databases. This requires cost models that take into account the cost of the specific reasoning operations (depending on the state of the reasoner) as well as the number of results.\nAs motivated above, we distinguish between simple and complex axiom templates. Simple axiom templates are those that correspond to dedicated reasoning tasks. Let c1 be a concept term, C,C \u2032 (complex) concepts or concept variables, r1, r2 role terms or role inverses and t, t\u2032 individual terms. The set of simple axiom templates contains templates of the form: C \u2291 C \u2032, \u2203r1.\u22a4 \u2291 c1 (domain restriction template), \u22a4 \u2291 \u2200r1.c1 (range restriction template), r1 \u2291 r2, C(t), r1(t, t\n\u2032), t \u2248 t\u2032, t 6\u2248 t\u2032. Complex axiom templates can, in contrast, not be evaluated by dedicated reasoning tasks and might require iterating over the compatible mappings and by checking entailment for each instantiated axiom template. An example of a complex axiom template is (\u2203r.?x)(?y)."}, {"heading": "4. Preprocessing for Extracting Information for Queries", "text": "In this section, we describe a way of preprocessing the queried ontology to extract information that is useful for ordering the axiom templates in a query. This preprocessing is useful for axiom templates of the form c1(t), r1(t, t\n\u2032), or t \u2248 t\u2032, where c1 is a concept term, r1 is a role term and t, t\u2032 are individual terms."}, {"heading": "4.1 Extracting Individual Information from Reasoner Models", "text": "The first step in the ordering of query atoms is the extraction of statistics by exploiting information generated by reasoners. We use the labels of an initial pre-model to pro-\n1. For example, the description logic SROIQ, which underpins the OWL 2 DL standard, has a worst case complexity of 2-NExpTime (Kazakov, 2008) and typical implementations are not worst case optimal.\nAlgorithm 1 initializeKnownAndPossibleConceptInstances(O)\nInput: a consistent SROIQ ontology O 1: An := buildModelFor(O) 2: for all a \u2208 NO\nI do\n3: for all C \u2208 LAn(a) do 4: if C was derived deterministically then 5: K[C] := K[C] \u222a {a} 6: else 7: P [C] := P [C] \u222a {a} 8: end if 9: end for\n10: end for\nvide information about the concepts the individuals belong to or the roles with which one individual is connected to another one. We exploit this information similarly as was suggested for determining known or possible (non-)subsumers for concepts during classification (Glimm et al., 2012). In the hypertableau calculus, the following two properties hold for each ontology O and each constructed pre-model An for O:\n(P1) for each concept name C (role name r), each individual s0 (pair of individuals \u3008s1, s2\u3009) in An, if C \u2208 LAn(s0) (r \u2208 LAn(\u3008s1, s2\u3009)) and the assertion C(s0) (r(s1, s2)) was derived deterministically, then it holds O |= C(s0) (O |= r(s1, s2)).\n(P2) for an arbitrary individual s0 in An (pair of individuals \u3008s1, s2\u3009 in An) and an arbitrary concept name C (simple role name r), if C 6\u2208 LAn(s0) (r 6\u2208 LAn(\u3008s1, s2\u3009)), then O 6|= C(s0) (O 6|= r(s1, s2)).\nFor simplicity, we assume here that equality (\u2248) is axiomatized and \u2248 is treated as a reflexive, symmetric, and transitive role. We use these properties to extract information from the pre-model of a satisfiable ontology O.\nDefinition 7 (Known and Possible Instances). Let An be a pre-model for an ontology O. An individual a is a known (possible) instance of a concept name C in An, denoted a \u2208 KAn [C] (a \u2208 PAn [C]), if C \u2208 LAn(a) and C(a) is derived deterministically (nondeterministically) in An. A pair of individuals \u3008a1, a2\u3009 is a known (possible) instance of a simple role name r in An, denoted \u3008a1, a2\u3009 \u2208 KAn(r), if r \u2208 LAn(\u3008a1, a2\u3009) and r(a1, a2) is derived deterministically (nondeterministically) in An. The individual a1 is (possibly) equal to the individual a2, written a1 \u2208 K\u2248[a2] and a2 \u2208 K\u2248[a1] (a1 \u2208 P\u2248[a2] and a2 \u2208 P\u2248[a1]) if a1 \u2248 a2 has been deterministically (nondeterministically) derived in O.\nIn the remainder, we assume that the known and possible instances are defined w.r.t. some arbitrary pre-model An for O and we simply write K[C], K[r], K\u2248[a], P [C], P [r], and P\u2248[a]. Intuitively, K[C] contains individuals that can safely be considered instances of the concept name C. On the other hand, the possible instances require costly consistency checks in order to decide whether they are real instances of the concept, while individuals that neither belong to K[C] nor P [C] can safely be assumed to be non-instances of C.\nAlgorithm 1 outlines a procedure to initialize the relations for known and possible concept instances. The information we extract involves the maintenance of the sets of known and possible instances for all concepts of O. One can define a similar algorithm for initializing the known and possible instances of simple roles and for (possibly) equal individuals. In our implementation, we use a more involved procedure to only store the direct types of each individual, where a concept name C is a direct type of an individual a in an ontology O if O |= C(a) and there is no concept name D such that O |= D \u2291 C, O |= D(a) and O 6|= D \u2261 C.\nHypertableau and tableau reasoners typically do not deal with transitivity directly. In order to deal with non-simple roles, O is expanded with additional axioms that capture the semantics of the transitive relations before a pre-model is built. In particular, for each individual a and non-simple role r, new concepts Ca and C r a are introduced and the axioms Ca(a) and Ca \u2291 \u2200r.C r a are added to O. The consequent application of the transitivity encoding (Motik et al., 2009) produces axioms that propagate Cra to each individual b that is reachable from a via an r-chain. The known and possible r-successors for a can then be determined from the Cra instances.\nThe technique presented in this paper can be used with any (hyper)tableau calculus for which properties (P1) and (P2) hold. All (hyper)tableau calculi used in practice that we are aware of satisfy property (P1). Pre-models produced by tableau algorithms as presented in the literature also satisfy property (P2); however, commonly used optimizations, such as lazy unfolding, can compromise property (P2), which we illustrate with the following example. Let us assume we have an ontology O containing the axioms\nA \u2291 \u2203r.(C \u2293D) (1)\nB \u2261 \u2203r.C (2)\nA(a) (3)\nIt is obvious that in this ontology A is a subconcept of B (hence, O |= B(a)) since every individual that is r-related to an individual that is an instance of the intersection of C and D is also r-related to an individual that is an instance of the concept C. However, even though the assertion A(a) occurs in the ABox, the assertion B(a) is not added in the pre-model when we use lazy unfolding. With lazy unfolding, instead of treating (2) as two disjunctions \u00acB \u2294 \u2203r.C and B \u2294 \u2200r.(\u00acC) as is typically done for general concept inclusion axioms, B is only lazily unfolded into its definition \u2203r.C once B occurs in the label of an individual. Thus, although (\u2203r.(C \u2293 D))(a) would be derived, this does not lead to the addition of B(a).\nNevertheless, most (if not all) implemented calculi produce pre-models that satisfy at least the following weaker property:\n(P3) for an arbitrary individual s0 in An and an arbitrary concept name C where C is primitive in O,2 if C 6\u2208 LAn(s0), then O 6|= C(s0).\nHence, properties (P2) and (P3) can be used to extract (non-)instance information from pre-models. For tableau calculi that only satisfy (P3), for each non-primitive concept name\n2. A concept C is considered primitive in O if O is unfoldable (Tsarkov et al., 2007) and it contains no axiom of the form C \u2261 E\nC in O we need to add to P [C] the individuals in O that do not include the concept C in their label.\nThe proposed technique for determining known and possible instances of concept and role names can be used in the same way with both tableau and hypertableau reasoners. Since tableau algorithms often introduce more nondeterminism than hypertableau, one might, however, find less deterministic derivations, which results in less accurate statistics."}, {"heading": "4.1.1 Individual Clustering", "text": "In this section, we describe the procedure for creating clusters of individuals within an ontology O using a constructed pre-model An of O. Two types of clusters are created: concept clusters and role clusters. Concept clusters contain individuals having the same concepts in their label and role clusters contain individuals with the same concept and role labels. Role clusters are divided into three categories, those that are based on the first individual of role instances, those based on the second individual and those based on both individuals.\nDefinition 8 (Concept and Role Clusters). Let O be an ontology and An a pre-model for O. We define the following two relations P1 and P2 that map an individual a from O to the roles for which a has at least one successor or predecessor, respectively:\nP1(a) = {r | r \u2208 LAn(\u3008a, b\u3009) for some b \u2208 N O I } P2(a) = {r | r \u2208 LAn(\u3008b, a\u3009) for some b \u2208 N O I }\nBased on these relations, we build three different partitions over NO I : concept clusters CC, role successor clusters PC1, and role predecessor clusters PC2 such that the clusters satisfy:\nfor each C \u2208 CC.(for each a1, a2 \u2208 C.(LAn(a1) = LAn(a2)))\nfor each C \u2208 PC1.(for each a1, a2 \u2208 C.(LAn(a1) = LAn(a2) and P1(a1) = P1(a2))) for each C \u2208 PC2.(for each a1, a2 \u2208 C.(LAn(a1) = LAn(a2) and P2(a1) = P2(a2))).\nWe further partition NO I \u00d7 NO I into role clusters PC12 such that the clusters satisfy:\nfor each C \u2208 PC12.(for each \u3008a1, a2\u3009, \u3008a3, a4\u3009 \u2208 C.(LAn(a1) = LAn(a3),LAn(a2) = LAn(a4)\nand LAn(\u3008a1, a2\u3009) = LAn(\u3008a3, a4\u3009))).\nWe use these clusters in the next section to optimize the dynamic query ordering strategy."}, {"heading": "5. Query Answering and Axiom Template Ordering", "text": "In this section, we describe two different algorithms (a static and a dynamic one) for ordering the axiom templates of a query based on some costs and then we deal with the formulation of these costs. We first introduce the abstract graph representation of a query q by means of a labeled graph Gq on which we define the computed statistical costs.\nDefinition 9 (Query Join Graph). A query join graph Gq for a query q is a tuple (V,E,EL), where\n\u2022 V = q is a set of vertices (one for each axiom template);\n\u2022 E \u2286 V \u00d7V is a set of edges; such that \u3008at1, at2\u3009 \u2208 E if Vars(at1)\u2229Vars(at2) 6= \u2205 and at1 6= at2;\n\u2022 EL is a function that assigns a set of variables to each \u3008at1, at2\u3009 \u2208 E such that EL(at1, at2) = Vars(at1) \u2229 Vars(at2).\nIn the remainder, we use Gq for the query join graph of q. Our goal is to find a query execution plan, which determines the evaluation order for axiom templates in q. Since the number of possible execution plans is of order |q|!, the ordering task quickly becomes impractical. In the following, we focus on greedy algorithms for determining an execution order, which prune the search space considerably. Roughly speaking, we proceed as follows: We define a cost function, which consists of two components (i) an estimate for the costs of the reasoning tasks needed for the evaluation of an axiom template and (ii) an estimate for the intermediate result size, i.e., the number of results that the evaluation of an axiom template will incur. Both components are combined to induce an order among axiom templates. In this paper, we simply build the sum of the two cost components, but different combinations such as a weighted sum of the two values could also be used. For the query plan construction we distinguish static from dynamic planning. For the former, we start constructing the plan by adding a minimal template according to the order. Variables from this template are then considered bound, which changes the cost function and might induce a different order among the remaining axiom templates. Considering the updated order, we again select the minimal axiom template that is not yet in the plan and update the costs. This process continues until the plan contains all templates. Once a complete plan has been determined the templates are evaluated. The dynamic case differs in that after selecting a template for the plan, we immediately determine the solutions for the chosen template, which are then used to update the cost function. While this yields accurate cost estimates, it can be very costly when all solutions are considered for updating the cost function. Sampling techniques can be used to only test a subset of the solutions, but we show in Section 7 that random sampling, i.e., randomly choosing a percentage of the individuals from the so far computed solutions, is not adequate. For this reason, we propose an alternative sampling approach that is based on the use of the previously described individual clusters. We first present an example to make the difference between static and dynamic planning clearer and justify why dynamic ordering can be beneficial in our setting.\nExample 1. Let O be an ontology and q = {C(?x), r(?x, ?y),D(?y)} a conjunctive instance query over O. Suppose that for the known and possible instances of the query concepts and roles we have\nK[C] = {a} K[r] = \u2205 K[D] = {b}\nP [C] = {c, e} P [r] = {\u3008c, d\u3009, \u3008e, f\u3009} P [D] = {f, g, h}\nAnd let us assume that the possible instances of C, D and r are, in fact, real instances (note that we do not have this information from the beginning). Please have in mind that the possible instances of concepts or roles are more costly to evaluate than the known instances\nsince they require expensive consistency checks in order to decide whether they are real instances.\nAccording to static planning, an ordering for query atoms is first determined. In particular, the atom r(?x, ?y) is chosen first since it has the least number of known and possible instances (0 known and 2 possible versus 1 known and 2 possible for C(?x) and 1 known and 3 possible for D(?y)). Then the atom C(?x) is chosen since it has less known and possible instances than D(?y), i.e., 1 known and 2 possible versus 1 known and 3 possible for D(?y). Hence the chosen execution plan in static planning is P = (r(?x, ?y), C(?x),D(?y)). Afterwards, the query is evaluated according to the chosen execution plan, i.e., the atom r(?x, ?y) is evaluated first, which gives the solution mappings \u21261 = {{?x 7\u2192 c, ?y 7\u2192 d}, {?x 7\u2192 e, ?y 7\u2192 f}}. This requires 2 consistency checks for the 2 possible instances of r. Afterwards, we check which of the ?x mappings, c and e, are known or possible instances of C. Since both c and e are possible instances, we check whether they are real instances of C (this requires 2 consistency checks). Hence, the solution mappings are \u21262 = \u21261 = {{?x 7\u2192 c, ?y 7\u2192 d}, {?x 7\u2192 e, ?y 7\u2192 f}}. In the end, we check which of the ?y mappings, d and f , are known or possible instances of D. For the only possible instance, f , we find after one consistency check that f is indeed an instance of D. Hence, the solution mappings for q are \u2126Oq = {{?x 7\u2192 e, ?y 7\u2192 f}} and finding the solution required 5 consistency checks.\nAccording to dynamic planning, an ordering is determined while we evaluate the query. For the same reasons as before, the atom r(?x, ?y) is chosen to be evaluated first and the solution mappings are, as before, \u21261 = {{?x 7\u2192 c, ?y 7\u2192 d}, {?x 7\u2192 e, ?y 7\u2192 f}} (this requires 2 consistency checks). We afterwards check which of the ?y mappings, d and f , are known or possible instances of D. Note that this only requires a look-up since if we find d or f to be among the possible instances, we do not check whether the individual is indeed an instance or not. Here only f is a possible instance. We also check which of the ?x mappings, c and e, are known or possible instances of C. Here, both c and e are possible instances, i.e., we have 2 relevant possible instances for C(?x) and 1 for D(?y). Hence, the atom D(?y) is chosen to be evaluated next, resulting in the solution sequence \u21262 = {{?x 7\u2192 e, ?y 7\u2192 f}} for the (partial) execution plan (r(?x, ?y),D(?y)), requiring 1 consistency check. In the end, we check whether the ?x mapping, e, is a known or possible instance of C. Since e is a possible instance, we check whether it is a real instance (this requires 1 consistency check). Hence, the solution mappings for q are \u2126Oq = {{?x 7\u2192 e, ?y 7\u2192 f}}, which have been found by performing 4 consistency checks, one less than in the static case.\nNote that in dynamic ordering we perform less checks than in static ordering, since in this case we can exploit the results of joins of query atoms and more information regarding the possible instances of atoms (i.e., which of them are real instances), which is determined as a result of evaluating the atoms while ordering them.\nWe now make the process of query plan construction more precise, but we leave the exact details of defining the cost function and the ordering it induces to later.\nDefinition 10 (Static and Dynamic Ordering). A static (dynamic) cost function w.r.t. q over O is a function s : q \u00d7 2V ars(q) \u2192 R \u00d7 R (d : q \u00d7 2\u0393 O q \u2192 R \u00d7 R), where with \u0393Oq we denote the set of compatible mappings for q over O. The two costs \u3008Ecsat,Rs s at\u3009 (\u3008Ec d at,Rs d at\u3009) for an axiom template at \u2208 q are combined to yield a static ordering s (dynamic ordering\nd), which is a total order over the axiom templates of q such that, for at, at \u2032 \u2208 q, we say\nthat at s at \u2032 (at d at \u2032) iff Ecsat + Rs s at \u2264 Ec s at\u2032 + Rs s at\u2032 (Ec d at + Rs d at \u2264 Ec d at\u2032 + Rs d at\u2032).\nAn execution plan for q is a duplicate-free sequence of axiom templates from q. The initial execution plan is the empty sequence and a complete execution plan is a sequence containing all templates of q. Let Pi = (at1, . . . , ati) with i < |q| be an execution plan for q with query join graph Gq = (V,E,EL). The set of bound variables of ati within Pi is Vb(ati) = Vars(ati) \u2229 Vars({at1, . . . , ati\u22121}). Let Cq be the set of complex axiom templates in q. We next define which axiom templates can be used to extend an incomplete execution plan. Let at be an axiom template in Pi, the set suci(at) contains the axiom templates that are connected to at and not yet in Pi, i.e., suci(at) = {at\n\u2032 \u2208 q | \u3008at, at\u2032\u3009 \u2208 E, at\u2032 /\u2208 {at1, . . . ati}}. Based on this, we define the set of connected successor axiom templates for Pi as Si = {at | at \u2032 \u2208 {at1, . . . , ati} and at \u2208 suci(at \u2032)}. We further allow for including axiom templates that are only connected to a complex axiom template from Si and define the potential next templates qi for Pi w.r.t. Gq as qi = q if Pi is the initial execution plan and otherwise\nqi = Si \u222a \u22c3\nat \u2208 Cq \u2229 Si\nsuci(at).\nGiven Pi, the static (dynamic) ordering induces an execution plan Pi+1 = (at1, . . . , ati, ati+1) with ati+1 \u2208 qi and ati+1 s at (ati+1 d at) for each at \u2208 qi such that at 6= ati+1.\nNote that according to the above definition, for Pi an execution plan, it can be the case that qi contains templates that are assigned the same minimal cost by the cost function. In such case, one can choose any of these atoms to add to Pi. Moreover, according to the above definition for the case of queries containing only simple axiom templates we have that, for i > 0, the set of potential next templates only contains templates that are connected to a template that is already in the plan since unconnected templates cause an unnecessary blowup of the number of intermediate results. For queries with complex templates the set of potential next axiom templates can additionally contain templates that do not share common variables with any template that is already in the plan. This different handling of queries with complex templates is reasonable since, before evaluating a complex axiom template that requires many consistency checks, we want to reduce the number of candidate bindings, by first evaluating other simple (cheaper) templates that bind variables which appear in the complex one.\nExample 2. Let O be an ontology and q = {?x \u2291 A, ?y \u2291 r,B \u2291 \u2203?y.?x} a query over O. Assuming that systems usually precompute the concept and role hierarchies before they accept queries, the evaluation of the first two templates, i.e., ?x \u2291 A and ?y \u2291 r, require cheap cache lookups, whereas the axiom template B \u2291 \u2203?y.?x, requires costly consistency checks. Hence, it is reasonable to first evaluate the first two (cheap) templates to reduce the mappings for ?x and ?y and then evaluate the third (expensive) template, by checking which of the reduced mappings yield an entailed axiom.\nAn example that shows the actual gain we get from handling the ordering of complex axiom templates in this way is presented in Section 7.\nLet n = |q| and Pn = (at1, . . . , atn) be a complete execution plan for q over O determined by static ordering. The procedure to find the solution mappings \u2126Oq for Pn is recursively\ndefined as follows: Initially, our solution set contains only the identity mapping \u21260 = {\u00b50}, which does not map any variable to any value. Assuming that we have evaluated the sequence Pi = (at1, . . . , ati), i < n and we have found the set of solution mappings \u2126i, in order to find the solution mappings \u2126i+1 of Pi+1, we use specific reasoning tasks to extend the mappings in \u2126i to cover the new variables of ati+1 if ati+1 is a simple axiom template or the entailment check service of reasoners if ati+1 does not contain new variables or if ati+1 is a complex axiom template. In dynamic planning the difference is that the execution plan construction is interleaved with query evaluation. In particular, let n = |q| and Pi = (at1 . . . ati) with i < n be a (partial) execution plan for q determined by dynamic ordering and let \u2126i be the solution mappings of Pi. In order to find Pi+1 we extend Pi with a new template, ati+1, from q, i.e., Pi+1 = (at1, . . . ati+1), which, according to the dynamic cost function, has the minimal cost among the remaining templates q \\ {at1, . . . ati}. The dynamic cost function assigns costs to templates at iteration i+ 1 taking into account the solution mappings \u2126i. We afterwards evaluate the atom ati+1, i.e., we find the solution mappings \u2126i+1 of Pi+1 by extending the solution mappings \u2126i of Pi in the same way as in the static case. In Section 6.3 in Algorithm 3, we show the complete procedure we follow to answer a query.\nWe now define the cost functions s and d more precisely, which estimate the cost of the required reasoner operations (first component) and the estimated result output size (second component) of evaluating an axiom template. The intuition behind the estimated value of the reasoner operation costs is that the evaluation of possible instances is much more costly than the evaluation of known instances since possible instances require expensive consistency checks whereas known instances require cheap cache lookups. The estimated result size takes into account the number of known and possible instances and the probability that possible instances are actual instances.\nThe time needed for an entailment check can change considerably between ontologies and even within an ontology (depending on the involved concepts, roles and individuals). In order to more accurately determine the entailment cost we use different entailment cost values depending on whether the template under consideration is a template of the form i) c1(t), ii) r1(t, t \u2032), iii) t \u2248 t\u2032, where c1 is a concept term, r1 is a role term and t, t \u2032 are individual terms, iv) one of the rest simple axiom templates (that require consistency checks to be evaluated) or a complex axiom template. In the following we write CL to denote the cost of a cache lookup in the internal structures of the reasoner, CE as a placeholder for the relevant entailment cost value and PIS for the possible instance success, i.e, the estimated percentage of possible instances that are actual instances. The costs CL and CE are determined by recording the average time of previously performed lookups and entailment checks for the queried ontology, e.g., during the initial consistency check, classification, or for previous queries. The possible instance success, PIS , was determined by testing several ontologies and checking how many of the initial possible instances were real ones, which was around 50% in nearly all ontologies.\nApart from the relations for the known and possible instances from Section 4.1, we use the following auxiliary relations:\nDefinition 11 (Successor and Predecessor Relations). Let r be a role and a an individual. We define sucK[r] and preK[r] as the set of individuals with known r-successors and\nr-predecessors, respectively:\nsucK[r] := {a | \u2203b.\u3008a, b\u3009 \u2208 K[r]} and preK[r] := {a | \u2203b.\u3008b, a\u3009 \u2208 K[r]}.\nSimilarly, we define sucK[r, a] and preK[r, a] as the known r-successors of a and the known r-predecessors of a, respectively:\nsucK[r, a] := {b | \u3008a, b\u3009 \u2208 K[r]} and preK[r, a] := {b | \u3008b, a\u3009 \u2208 K[r]}.\nWe analogously define the functions sucP[r], preP[r], sucP[r, a], and preP[r, a] by replacing K[r] with P [r].\nNext, we define the cost functions for the case of conjunctive instance queries, i.e., queries containing only query atoms. In Section 5.2 we extend the cost functions to deal with general queries."}, {"heading": "5.1 The Static and Dynamic Cost Functions for Conjunctive Instance Queries", "text": "The static cost function s takes two components as input: a query atom and a set containing the variables of the query atom that are considered bound. The function returns a pair of real numbers for the reasoning cost and the result size for the query atom.\nInitially, all variables are unbound and we use the number of known and possible instances or successors/predecessors to estimate the number of required lookups and consistency checks for evaluating the query atom and for the resulting number of mappings. For an input of the form \u3008C(?x), \u2205\u3009 or \u3008r(?x, ?y), \u2205\u3009 the resulting pair of real numbers for the computational cost and the estimated result size is computed as\n\u3008|K[at]| \u00b7 d \u00b7 CL + |P [at]| \u00b7 d \u00b7 CE , |K[at]|+ PIS \u00b7 |P [at]|\u3009,\nwhere at denotes the predicate of the query atom (C or r). For at a concept (role) atom, the factor d represents the depth of the concept (role) in the concept (role) hierarchy. We use this factor since we only store the direct types of each individual (roles of which individuals are instances) and, in order to find the instances of a concept (role), we may need to check all its subconcepts (subroles) for known or possible instances. If the query atom is a role atom with a constant in the first place, i.e., the input to the cost function is of the form \u3008r(a, ?x), \u2205\u3009, we use the relations for known and possible successors to estimate the computational cost and result size:\n\u3008|sucK[r, a]| \u00b7 d \u00b7 CL + |sucP[r, a]| \u00b7 d \u00b7 CE , |sucK[r, a]| + PIS \u00b7 |sucP[r, a]|\u3009.\nAnalogously, we use preK and preP instead of sucK and sucP for an input of the form \u3008r(?x, a), \u2205\u3009. Finally, if the atom contains only constants, i.e., the input to the cost function is of the form \u3008C(a), \u2205\u3009, \u3008r(a, b), \u2205\u3009, the function returns \u3008d \u00b7 CL, 1\u3009 if the individual is a known instance of the concept or role, \u3008d \u00b7 CE, PIS\u3009 if the individual is a possible instance and \u3008d \u00b7 CL, 0\u3009 otherwise, i.e., if the individual is a known non-instance.\nFor equality atoms of the form ?x \u2248?y, a \u2248?x, ?x \u2248 a or a \u2248 b, we again exploit information from the initial pre-model as described in Section 4.1. Based on the cardinality of K\u2248[a] and P\u2248[a], we can define cost functions for the different cases of query atoms and\nbound variables. For inputs of the form \u3008?x \u2248 a, \u2205\u3009 and \u3008a \u2248 ?x, \u2205\u3009, the cost function is defined as:\n\u3008|K\u2248[a]| \u00b7 CL + |P\u2248[a]| \u00b7 CE , |K\u2248[a]|+ PIS \u00b7 |P\u2248[a]|\u3009.\nFor inputs of the form \u3008?x \u2248 ?y, \u2205\u3009, the cost function is computed as:\n\u2329\n\u2211\na\u2208NO I\n(|K\u2248[a]| \u00b7 CL + |P\u2248[a]| \u00b7 CE)/2, \u2211\na\u2208NO I\n(|K\u2248[a]|+ PIS \u00b7 |P\u2248[a]|)/2\n\u232a\n.\nFor inputs of the form \u3008a \u2248 b, \u2205\u3009, the function returns \u3008CL, 1\u3009 if b \u2208 K\u2248[a], \u3008CE , PIS\u3009 if b \u2208 P\u2248[a], and \u3008CL, 0\u3009 otherwise (i.e., b is not equivalent to a).\nAfter determining the cost of an initial query atom, at least one variable of a consequently considered atom is bound, since during the query plan construction we move over atoms sharing a common variable and we assume that the query is connected. We now define the cost functions for atoms with at least one variable bound. We make the assumption that atoms with unbound variables are more costly to evaluate than atoms with all their variables bound. For a query atom r(?x, ?y) with only ?x bound, i.e., function inputs of the form \u3008r(?x, ?y), {?x}\u3009, we use the average number of known and possible successors of the role to estimate the computational cost and result size:\n\u2329\n|K[r]|\n|sucK[r]| \u00b7 d \u00b7 CL +\n|P [r]|\n|sucP[r]| \u00b7 d \u00b7 CE,\n|K[r]|\n|sucK[r]| +\n|P [r]|\n|sucP[r]| \u00b7 PIS\n\u232a\n.\nIn case only ?y in r(?x, ?y) is bound, we use the predecessor functions preK and preP instead of sucK and sucP. Note that we now work with an estimated average number of successors (predecessors) for one individual.\nFor atoms with all their variables bound, we use formulas that are comparable to the ones above for an initial plan, but normalized to estimate the values for one individual. For an input query atom of the form C(?x) with ?x a bound variable we use\n\u2329\n|K[C]| \u00b7 d \u00b7 CL + |P [C]| \u00b7 d \u00b7 CE |NO\nI |\n, |K[C]|+ PIS \u00b7 |P [C]|\n|NO I |\n\u232a\n.\nSuch a simple normalization is not always accurate, but leads to good results in most cases as we show in Section 7. Similarly, we normalize the formulas for role atoms of the form r(?x, ?y) such that {?x, ?y} is the set of bound variables of the atom. The two cost components for these atoms are computed as\n\u2329\n|K[r]| \u00b7 d \u00b7 CL + |P [r]| \u00b7 d \u00b7 CE |NO\nI | \u00b7 |NO I |\n, |K[r]|+ PIS \u00b7 |P [r]|\n|NO I | \u00b7 |NO I |\n\u232a\n.\nFor role atoms with a constant and a bound variable, i.e., atoms of the form r(a, ?x) (r(?x, a)) with ?x a bound variable, we use sucK[r, a] and sucP[r, a] (preK[r, a] and preP[r, a]) instead of K[r] and P [r] in the above formulas and we normalize by |NO\nI |.\nSimilarly, we normalize the cost functions for inputs with equality atoms and bound variables, depending on whether the atoms contain one or two bound variables. For inputs of the form \u3008?x \u2248 a, {?x}\u3009, \u3008a \u2248?x, {?x}\u3009, we divide the cost function components for inputs\nof the form \u3008?x \u2248 a, \u2205\u3009 and \u3008a \u2248?x, \u2205\u3009 by |NO I |. For an input of the form \u3008?x \u2248 y, {?x, ?y}\u3009, we divide the cost function components for input of the form \u3008?x \u2248?y, \u2205\u3009 by |NO I | \u00b7 |NO I |. For inputs of the form \u3008?x \u2248?y, {?x}\u3009, and \u3008?x \u2248?y, {?y}\u3009, we divide the cost function components for input of the form \u3008?x \u2248?y, \u2205\u3009 by |NO\nI |.\nThe dynamic cost function d is based on the static function s, but only uses the first equations, where the atom contains only unbound variables or constants. The function takes a pair \u3008at,\u2126\u3009 as input, where at is a query atom and \u2126 is the set of solution mappings for the atoms that have already been evaluated, and returns a pair of real numbers using matrix addition as follows:\nd(at,\u2126) = \u2211\n\u00b5\u2208\u2126\ns(\u00b5(at), \u2205)\nWhen sampling techniques are used, we compute the costs for each of the potential next atoms for an execution plan by only considering one individual of each relevant cluster. Which cluster is relevant depends on the query atom for which we compute the cost function and the previously computed bindings. For instance, if we compute the cost of a role atom r(?x, ?y) and we have already determined bindings for ?x, we use the role successor cluster PC1. Among the ?x bindings, we then just check the cost for one binding per cluster and assign the same cost to all other ?x bindings of the same cluster.\nExample 3. Let us assume that we have a conjunctive instance query q and that we have to find the cost (using the dynamic function) of the atom C(?x) within an execution plan for q. We further assume that from the evaluation of previous query atoms in the plan we have already determined a set of intermediate solutions \u2126 with the mappings a, b, or c for ?x. Let us assume that a, b, and c belong to the same concept cluster. According to dynamic ordering we need to find the cost of each instantiated atom using the static cost function, i.e., d(C(?x),\u2126) = s(C(a), \u2205) + s(C(b), \u2205) + s(C(c), \u2205). If we additionally use cluster based sampling, we find the cost for only one individual of each cluster, let us say a, and then assign the same cost to all other individuals from the cluster which are mappings for ?x in \u2126. Hence, the cost of the atom C(?x) when sampling is used, is computed as d(C(?x),\u2126) = 3 \u00b7 s(C(a), \u2205) avoiding the computation of s(C(b), \u2205) and s(C(c), \u2205).\nAn example that is similar to Example 1 (but with a greater number of instances) and shows how ordering is achieved by the use of the defined static and dynamic functions is shown below. We assume that q is a query consisting of the three query atoms: C(?x),\nr(?x, ?y), D(?y). Table 1 gives information about the known and possible instances of these atoms within a sequence. The second column shows already executed sequences Pi\u22121 = (at1, . . . , ati\u22121) for the atoms of q. Column 3 gives the current atom ati and column 4 (5) gives the number of mappings to known (possible) instances of at that satisfy at the same time the atoms (at1, . . . , ati\u22121) from column 2. Column 6 gives the number of real instances from the possible instances for the current atom. For example, row 4 says that we have evaluated the atom r(?x, ?y) and, in order to evaluate C(?x), we only consider those 100 known and 150 possible instances of C that are also mappings for ?x. We further assume that we have 10,000 individuals in our ontology O. We now explain, using the example, how the above described formulas work. We assume that CL \u2264 CE, which is always the case since a cache lookup is less expensive than a consistency check and that the CE values are the same for all query concepts and roles. For ease of presentation, we further do not consider the factor for the depth of the concept (role) within the concept (role) hierarchy. In both techniques (static and dynamic) the atom r(?x, ?y) is chosen first since it has the least number of possible instances (200) while it has the same (or smaller) number of known instances (200) as the other atoms (\u00b50 is the initial solution mapping that does not map any variable):\ns(r(?x, ?y), \u2205) = d(r(?x, ?y), {\u00b50}) = \u3008200 \u00b7 CL + 200 \u00b7 CE , 200 + PIS \u00b7 200\u3009,\ns(C(?x), \u2205) = d(C(?x), {\u00b50}) = \u3008200 \u00b7 CL + 350 \u00b7 CE , 200 + PIS \u00b7 350\u3009,\ns(D(?y), \u2205) = d(D(?y), {\u00b50}) = \u3008700 \u00b7 CL + 600 \u00b7 CE , 700 + PIS \u00b7 600\u3009.\nIn the case of static ordering, the atom C(?x) is chosen after r(?x, ?y) since C has less possible (and known) instances than D (350 versus 600):\ns(C(?x), {?x}) =\n\u2329\n200\n10, 000 \u00b7 CL +\n350\n10, 000 \u00b7 CE, 200 + 350 \u00b7 PIS 10, 000\n\u232a\n,\ns(D(?y), {?y}) =\n\u2329\n700\n10, 000 \u00b7 CL +\n600\n10, 000 \u00b7 CE, 700 + 600 \u00b7 PIS 10, 000\n\u232a\n.\nHence, the order of evaluation in this case is P = (r(?x, ?y), C(?x),D(?y)) leading to 200 (row 2) + 150 (row 4) + 40 (row 7) entailment checks. In the dynamic case, after the evaluation of r(?x, ?y), which gives a set of solutions \u21261, the atom D(?y) has fewer known and possible instances (50 known and 50 possible) than the atom C(?x) (100 known and 150 possible) and, hence, a lower cost:\nd(D(?y),\u21261) = \u300850 \u00b7 CL + 150 \u00b7 CL + 50 \u00b7 CE, 50 + 0 + 50 \u00b7 PIS\u3009,\nd(C(?x),\u21261) = \u3008100 \u00b7 CL + 0 \u00b7 CL + 150 \u00b7 CE, 100 + 0 + 150 \u00b7 PIS\u3009.\nNote that applying a solution \u00b5 \u2208 \u21261 to D(?y) (C(?x)) results in a query atom with a constant in place of ?y (?x). For D(?y), it is the case that out of the 250 r-instances, 200 can be handled with a look-up (50 turn out to be known instances and 150 turn out not to be instances of D), while 50 require an entailment check. Similarly, when considering C(?x), we need 100 lookups and 150 entailment checks. Note that we assume the worst case in this example, i.e., that all values that ?x and ?y take are different. Therefore, the atom D(?y) is chosen next, leading to the execution of the query atoms in the order P = (r(?x, ?y),D(?y), C(?x)) and the execution of 200 (row 2) + 50 (row 5) + 35 (row 6) entailment checks."}, {"heading": "5.2 Cost Functions for General Queries", "text": "We now explain how we order the remaining simple and complex axiom templates. We again use statistics from the reasoner, whenever these are available. In case the reasoner cannot give estimates, one can still work with statistics computed from explicitly stated information or use upper bounds to estimate the reasoner costs and the result size of axiom templates.\nWe first consider a general concept assertion axiom template. Let KC [a] be the concepts of which a is a known instance, PC [a] the concepts of which a is a possible instance. These sets are computed from the sets of known and possible instances of concepts. For an input of the form \u3008?x(a), \u2205\u3009 the cost function is defined as\n\u3008|KC [a]| \u00b7 d \u00b7 CL + |PC [a]| \u00b7 d \u00b7 CE , |KC [a]|+ PIS \u00b7 |PC [a]|\u3009.\nFor an input of the form \u3008?x(?y), \u2205\u3009, the cost function is defined as\n\u2329\n\u2211\nC\u2208NO C\n(|K[C]| \u00b7 d \u00b7 CL + |P [C]| \u00b7 d \u00b7 CE), \u2211\nC\u2208NO C\n(|K[C]|+ PIS \u00b7 |P [C]|)\n\u232a\n.\nFor inputs of the form \u3008?x(a), {?x}\u3009 and \u3008?x(?y), {?x, ?y}\u3009, we normalize the above functions by |NO\nC | and |NO I |\u00b7|NO C | respectively. For inputs of the form \u3008?x(?y), {?x}\u3009 and \u3008?x(?y), {?y}\u3009\nwe normalize the function for inputs of the form \u3008?x(?y), \u2205\u3009 by |NO C | and |NO I | respectively.\nFor general role assertion axiom templates, there are several cases of cost functions depending on the bound variables. We next define the cost functions for some cases. The cost functions for the other cases can similarly be defined. For an input of the form \u3008?z(?x, ?y), \u2205\u3009, the cost function is defined as :\n\u2329\n\u2211\nr\u2208NO R\n(|K[r]| \u00b7 d \u00b7 CL + |P [r]| \u00b7 d \u00b7 CE), \u2211\nr\u2208NO R\n(|K[r]|+ PIS \u00b7 |P [r]|)\n\u232a\n.\nFor inputs of the form \u3008?z(a, ?y), \u2205\u3009, the cost function is defined as:\n\u2329\n\u2211\nr\u2208NO R\n(|sucK[r, a]| \u00b7 d \u00b7 CL + |sucP[r, a]| \u00b7 d \u00b7 CE), \u2211\nr\u2208NO R\n(|sucK[r, a]| + PIS \u00b7 |sucP[r, a]|)\n\u232a\n.\nFor an input of the form \u3008?z(?x, ?y), {?z}\u3009, the cost function is defined as:\n\u2329\n\u2211\nr\u2208NO R\n|K[r]| \u00b7 d \u00b7 CL + |P [r]| \u00b7 d \u00b7 CE |NO\nR |\n, \u2211\nr\u2208NO R\n|K[r]|+ PIS \u00b7 |P [r]|\n|NO R |\n\u232a\n.\nLast, for inputs of the form \u3008?z(?x, ?y), {?x}\u3009, the two cost components are computed as:\n\u2329\n\u2211\nr\u2208NO R\n( |K[r]|\n|sucK[r]| \u00b7 d \u00b7 CL +\n|P [r]|\n|sucP[r]| \u00b7 d \u00b7 CE),\n\u2211\nr\u2208NO R\n( |K[r]|\n|sucK[r]| +\n|P [r]|\n|sucP[r]| \u00b7PIS)\n\u232a\n.\nFor concept (role) inclusion axiom templates of the form c1 \u2291 c2 (r1 \u2291 r2), where c1, c2 concept terms (r1, r2 role terms), that contain only concept (role) names and variables we need lookups in the computed concept (role) hierarchy in order to compute the answers (assuming that the concept (role) hierarchy is precomputed).\nOne can define similar cost functions for other types of axiom templates by either using the available statistics or by relying on told information from the ontology. For this paper, however, we just define a cost function based on the assumption that we iterate over all possible values of the respective variables and do one consistency check for each value. Hence, we define the following general cost function for these cases:\n\u3008|N | \u00b7 CE, |N |\u3009,\nwhere N \u2208 {NO C ,NO R ,NO I } as appropriate for the variable that is tested. As discussed in Section 5.1, the dynamic function is based on the static one and is applied only to the above described cases for an empty set of bound variables.\nProposition 1. Let q be a query over an ontology O, s and d the static and dynamic cost functions defined in Sections 5.1 and 5.2. The ordering induced by s and d is a total order over the axiom templates of q.\nProof. The cost functions s and d are defined for all kinds of axiom templates and return two real numbers to each possible input. Since, according to Definition 10, the orders s and d are based on the addition of the two real numbers, addition of reals yields again a real number, and since \u2264 is a total order over the reals, we immediately get that s and d are total orders.\nIt is obvious that the ordering of axiom templates does not affect soundness and completeness of a query evaluation algorithm."}, {"heading": "6. Complex Axiom Template Optimizations", "text": "In this section, we first describe some optimizations that we have developed for complex axiom templates (Sections 6.1, 6.2) and then we present the procedure for evaluating queries (Section 6.3)."}, {"heading": "6.1 Axiom Template Rewriting", "text": "Some costly to evaluate axiom templates can be rewritten into axiom templates that can be evaluated more efficiently and yield an equivalent result. Before we go on to describe the axiom template rewriting technique, we define what a concept template is, which is useful throughout the section.\nDefinition 12 (Concept Template). Let Sq = (NC ,NR,NR,VC ,VR,VI ) be a query signature w.r.t. a signature S = (NC ,NR,NI ). A concept template over Sq is a SROIQ concept over S, where one can also use concept variables from VC in place of concept names, role variables from VR in place of role names and individual variables from VI in place of individual names.\nDefinition 13 (Rewriting). Let O be an ontology, at \u2208 q an axiom template over Sq, t, t1, . . . tn individuals or individual variables from Sq, and C,C1, . . . , Cn concept templates over Sq. The function rewrite takes an axiom template and returns a set of axiom templates as follows:\n\u2022 if at = (C1 \u2293 . . . \u2293Cn)(t), then rewrite(at) = {C1(t), . . . , Cn(t)};\n\u2022 if at = C \u2291 C1 \u2293 . . . \u2293 Cn, then rewrite(at) = {C \u2291 C1, . . . , C \u2291 Cn};\n\u2022 if at = C1 \u2294 . . . \u2294 Cn \u2291 C, then rewrite(at) = {C1 \u2291 C, . . . , Cn \u2291 C};\n\u2022 if at = t1 \u2248 . . . \u2248 tn, then rewrite(at) = {t1 \u2248 t2, t2 \u2248 t3, . . . , tn\u22121 \u2248 tn}.\nTo understand the intuition behind such transformation, we consider a query with only the axiom template: ?x \u2291 \u2203r.?y \u2293 A. Its evaluation requires a quadratic number of consistency checks in the number of concepts (since ?x and ?y are concept variables). The rewriting yields: ?x \u2291 A and ?x \u2291 \u2203r.?y. The first axiom template is now evaluated with a cheap cache lookup (assuming that the concept hierarchy has been precomputed). For the second one, we only have to check the usually few resulting bindings for ?x combined with all other concept names for ?y.\nNote that Description Logics typically do not support n-ary equality axioms t1 \u2248 . . . \u2248 tn, but only binary ones, whereas in OWL, one can typically also write n-ary equality axioms. Since our cost functions are only defined for binary equality axioms, we equivalently rewrite an n-ary one into several binary ones. One could even further optimize the evaluation of such atoms by just evaluating one binary equality axiom template and by then propagating the binding for the found equivalent individuals to the other equality axioms. This is valid since equality is a congruence relation."}, {"heading": "6.2 Concept and Role Hierarchy Exploitation", "text": "The number of consistency checks required to evaluate a query can be further reduced by taking the concept and role hierarchies into account. Once the concepts and roles are classified (this can ideally be done before a system accepts queries), the hierarchies are stored in the reasoner\u2019s internal structures. We further use the hierarchies to prune the search space of solutions in the evaluation of certain axiom templates. We illustrate the intuition with the example Infection \u2291 \u2203hasCausalLinkTo.?x. If A is not a solution and B \u2291 A holds, then B is also not a solution. Thus, when searching for solutions for ?x, we choose the next binding to test by traversing the concept hierarchy top-down. When we find a non-solution A, the subtree rooted in A of the concept hierarchy can safely be pruned. Queries over ontologies with a large number of concepts and a deep concept hierarchy can, therefore, gain the maximum advantage from this optimization. We employ similar optimizations using the role hierarchies.\nIn the example above, we can prune the subconcepts of A because ?x has positive polarity in the axiom template Infection \u2291 \u2203hasCausalLinkTo.?x., i.e., ?x occurs positively on the right hand side of the axiom template. In case a variable ?x has negative polarity in an axiom template of the form C1 \u2291 C2, i.e., ?x occurs directly or indirectly under a negation on the right hand side of the axiom template or positively on the left-hand side of an axiom template, one can, instead, prune the superconcepts.\nWe next specify more precisely the polarity of a concept variable in a concept or axiom template.\nDefinition 14 (Concept Polarity). Let ?x \u2208 VC be a concept variable and C,C1, C2,D concept templates, r a role, and n \u2208 IN0. We define the polarity of ?x in C as follows: ?x occurs positively in ?x. Furthermore, ?x occurs positively (negatively)\n\u2022 in \u00acD if ?x occurs negatively (positively) in D,\n\u2022 in C1 \u2293 C2 or C1 \u2294 C2 if ?x occurs positively (negatively) in C1 or C2,\n\u2022 in \u2203r.D, \u2200r.D, or > n r.D if ?x occurs positively (negatively) in D,\n\u2022 in 6 n r.D if ?x occurs negatively (positively) in D\n\u2022 in = n r.D if ?x occurs in D.\nWe further say that ?x occurs positively (negatively) in C1 \u2291 C2 if ?x occurs negatively (positively) in C1 or positively (negatively) in C2. Note that ?x can occur both positively and negatively in a concept template. We further define a partial function polc that maps a concept variable ?x and a concept template C (axiom template of the form C1 \u2291 C2) to pos if ?x occurs only positively in C (C1 \u2291 C2) and to neg if ?x occurs only negatively in C (C1 \u2291 C2).\nNote that no matter whether ?x occurs positively or negatively in a concept template D, in any concept template C of the form = n r.D, ?x occurs positively as well as negatively. This is due to the fact that C is equivalent to the concept template 6 n r.D \u2293 > n r.D in which ?x occurs positively as well as negatively. Since the function polc is not defined for variables that appear both positively and negatively, the concept hierarchy cannot be exploited in this case. For example, consider the concept template \u00ac?x \u2294 \u2203r.?x, (axiom template ?x \u2291 \u2203r.?x), where ?x appears negatively in \u00ac?x and positively in \u2203r.?x. Now, let \u03b4 \u2208 \u2206I be an arbitrary element from a model I = (\u2206I , \u00b7I) of the ontology. It is obvious that if \u03b4 is an instance of \u00acA \u2294 \u2203r.A and either A \u2291 B or B \u2291 A holds, we cannot deduce that \u03b4 is an instance of \u00acB \u2294 \u2203r.B.\nBefore proving the correctness of the proposed optimization, we first show the relationship between entailment and concept membership, which is used in the subsequent proofs.\nLemma 1. Let q be a query over O w.r.t. the query signature Sq = (NC ,NR,NI ,VC ,VR,VI ), at \u2208 q be an axiom template of the form C1 \u2291 C2 where C1 and C2 are concept templates and let \u00b5 be a mapping for at over O. It holds that O 6|= \u00b5(C1 \u2291 C2) iff there exists an interpretation I = (\u2206I , \u00b7I) and an element \u03b4 \u2208 \u2206I such that I |= O and \u03b4 6\u2208 \u00b5(\u00acC1 \u2294C2) I .\nProof. O 6|= \u00b5(C1 \u2291 C2) holds iff there exists an interpretation I = (\u2206 I , \u00b7I) and an element \u03b4 \u2208 \u2206I such that I |= O and \u03b4 \u2208 \u00b5(C1) I and \u03b4 6\u2208 \u00b5(C2) I , which holds iff \u03b4 \u2208 \u00b5(C1) I and \u03b4 \u2208 \u00b5(\u00acC2) I , which is equivalent to \u03b4 \u2208 \u00b5(C1 \u2293 \u00acC2)\nI , which is equivalent to \u03b4 \u2208 \u00b5(\u00ac(\u00acC1 \u2294 C2)) I , which holds iff \u03b4 6\u2208 \u00b5(\u00acC1 \u2294 C2) I .\nThe following theorem holds for every axiom template of the form C1 \u2291 C2. Note that we assume here that concept assertion templates of the form C(a) are expressed as the equivalent axiom templates {a} \u2291 C. We use C\u00b5(?x)=A, where A is a concept name, to denote the concept obtained by applying the extension of \u00b5 that also maps ?x to A.\nTheorem 1. Let O be an ontology, A,B concept names such that O |= A \u2291 B, C1, C2 concept templates, C1 \u2291 C2 an axiom template, C = \u00acC1 \u2294C2, ?x \u2208 VC a concept variable occurring in C and \u00b5 a mapping that covers all variables of C apart from ?x.\n1. For polc(?x,C) = pos it holds that if O 6|= (C1 \u2291 C2)\u00b5(?x)=B , then O 6|= (C1 \u2291 C2)\u00b5(?x)=A.\n2. For polc(?x,C) = neg it holds that if O 6|= (C1 \u2291 C2)\u00b5(?x)=A, then O 6|= (C1 \u2291 C2)\u00b5(?x)=B .\nProof. Due to Lemma 1, it suffices to show for some model I = (\u2206I , \u00b7I) of O and some element \u03b4 \u2208 \u2206I the following (which is formalized in contrapositive form):\n1. For polc(?x,C) = pos it holds that if \u03b4 \u2208 (C\u00b5(?x)=A) I , then \u03b4 \u2208 (C\u00b5(?x)=B) I .\n2. For polc(?x,C) = neg it holds that if \u03b4 \u2208 (C\u00b5(?x)=B) I , then \u03b4 \u2208 (C\u00b5(?x)=A) I .\nWe prove the claim by induction on the structure of the concept template C:\n\u2022 For C =?x, ?x occurs positively in C. Now, if \u03b4 \u2208 (?x\u00b5(?x)=A) I , that is \u03b4 \u2208 AI , it is\neasy to see that \u03b4 \u2208 BI since O |= A \u2291 B by assumption. Hence, \u03b4 \u2208 (?x\u00b5(?x)=B) I .\n\u2022 For C = \u00acD and polc(?x,C) = pos, if \u03b4 \u2208 (\u00acD\u00b5(?x)=A) I , we have to show that\n\u03b4 \u2208 (\u00acD\u00b5(?x)=B) I . Note that polc(?x,D) = neg. In contrary to what is to be shown, assume that \u03b4 \u2208 (D\u00b5(?x)=B) I . Since O |= A \u2291 B and by induction hypothesis \u03b4 \u2208 (D\u00b5(?x)=A) I and \u03b4 \u2208 (\u00acD\u00b5(?x)=A)\nI which is a contradiction. The proof is analogous for polc(?x,C) = neg.\n\u2022 For C = C1 \u2293 C2 and polc(?x,C) = pos, if \u03b4 \u2208 ((C1 \u2293 C2)\u00b5(?x)=A) I , then \u03b4 \u2208\n(C1\u00b5(?x)=A) I and \u03b4 \u2208 (C2\u00b5(?x)=A) I . Since O |= A \u2291 B and by induction hypothesis, \u03b4 \u2208 (C1\u00b5(?x)=B) I and \u03b4 \u2208 (C2\u00b5(?x)=B) I . Thus, \u03b4 \u2208 ((C1 \u2293 C2)\u00b5(?x)=B) I . The proof is analogous for polc(?x,C) = neg.\n\u2022 The proof for C1 \u2294C2 is analogous to the one for C1 \u2293 C2.\n\u2022 For C = \u2203r.D and polc(?x,C) = pos, if \u03b4 \u2208 ((\u2203r.D)\u00b5(?x)=A) I , then \u03b4 has at least one r-\nsuccessor, say \u03b4\u2032, that is an instance of D\u00b5(?x)=A. Since O |= A \u2291 B and by induction hypothesis, \u03b4\u2032 \u2208 D\u00b5(?x)=B . Hence, \u03b4 \u2208 (\u2203r.(D\u00b5(?x)=B)) I = ((\u2203r.D)\u00b5(?x)=B)\nI . The proof is analogous for polc(?x,C) = neg.\n\u2022 For C = \u2200r.D and polc(?x,C) = pos, if \u03b4 \u2208 ((\u2200r.D)\u00b5(?x)=A) I , then \u03b4 \u2208 (\u2200r.(D)\u00b5(?x)=A) I\nand each r-successors of \u03b4 is an instance of D\u00b5(?x)=A. Since O |= A \u2291 B and by induction hypothesis, these r-successors are also instances of D\u00b5(?x)=B . Hence, \u03b4 \u2208 (\u2200r.(D\u00b5(?x)=B)) I = ((\u2200r.D)\u00b5(?x)=B) I . The proof is analogous for polc(?x,C) = neg.\n\u2022 For C = > n r.D and polc(?x,C) = pos, if \u03b4 \u2208 ((> n r.D)\u00b5(?x)=A) I , then \u03b4 has at\nleast n distinct r-successors which are instances of D\u00b5(?x)=A. Since O |= A \u2291 B and by induction hypothesis, these successors are instances of D\u00b5(?x)=B . Hence, \u03b4 has at least n distinct r-successors that are instances of D\u00b5(?x)=B and, therefore, \u03b4 \u2208 (> n r.(D)\u00b5(?x)=B) I = ((> n r.D)\u00b5(?x)=B) I . The proof is analogous for polc(?x,C) = neg.\n\u2022 For C = 6 n r.D and polc(?x,C) = pos, if \u03b4 \u2208 ((6 n r.D)\u00b5(?x)=A) I , we have to show\nthat \u03b4 \u2208 ((6 n r.D)\u00b5(?x)=B) I . Note that polc(?x,D) = neg. In contrary to what is to be shown, assume that \u03b4 \u2208 (\u00ac(6 n r.D)\u00b5(?x)=B) I , i.e., \u03b4 \u2208 ((> n + 1 r.D)\u00b5(?x)=B)\nI . Hence, \u03b4 has at least n + 1 distinct r-successors which are instances of D\u00b5(?x)=B . Since polc(?x,D) = neg and by induction hypothesis, these D\u00b5(?x)=B instances are also D\u00b5(?x)=A instances and \u03b4 \u2208 (> n + 1 r.(D)\u00b5(?x)=A) I = ((> n + 1 r.D)\u00b5(?x)=A)\nI , which is a contradiction. The proof is analogous for polc(?x,C) = neg.\n\u2022 For C = (= n r.D), the polarity of ?x in C is always positive and negative, so polc(?x,C) is undefined and the case cannot occur.\nWe now extend this optimization to the case of role variables and we first define the polarity of a role variable in a concept or axiom template.\nDefinition 15 (Role Polarity). Let ?x \u2208 VR be a role variable, C,C1, C2,D concept templates, r a role, and n \u2208 IN0. We define the polarity of ?x in C as follows: ?x occurs positively in \u2203?x.D, \u2203?x\u2212.D, > n ?x.D, > n ?x\u2212.D, = n ?x.D, and = n ?x\u2212.D; ?x occurs negatively in \u2200?x.D, \u2200?x\u2212.D, 6 n ?x.D, 6 n ?x\u2212.D, = n ?x.D, and = n ?x\u2212.D. Furthermore, ?x occurs positively (negatively)\n\u2022 in \u00acD if ?x occurs negatively (positively) in D,\n\u2022 in C1 \u2293 C2 or C1 \u2294 C2 if ?x occurs positively (negatively) in C1 or C2,\n\u2022 in \u2203r.D, \u2203?x.D, \u2203?x\u2212.D, > n r.D, > n ?x.D, > n ?x\u2212.D, \u2200r.D, \u2200?x.D, or \u2200?x\u2212.D if ?x occurs positively (negatively) in D,\n\u2022 in 6 n r.D, 6 n ?x.D, or 6 n ?x\u2212.D if ?x occurs negatively (positively) in D,\n\u2022 in = n r.D if ?x occurs in D.\nWe further say that ?x occurs positively (negatively) in C1 \u2291 C2 if ?x occurs negatively (positively) in C1 or positively (negatively) in C2. We define a partial function polr that maps a role variable ?x and a concept template C (axiom template of the form C1 \u2291 C2) to pos if ?x occurs only positively in C (C1 \u2291 C2) and to neg if ?x occurs only negatively in C (C1 \u2291 C2).\nNote also that we do not make any assumption about occurrences of ?x in D in the first part of the definition.\nWe now show, that the hierarchy optimization is also applicable to role variables, provided they occur only positively or only negatively.\nTheorem 2. Let O be an ontology, r, s role names such that O |= r \u2291 s, C1, C2 concept templates, C1 \u2291 C2 an axiom template, C = \u00acC1 \u2294 C2, ?x \u2208 VR a role variable occurring in C and \u00b5 a mapping that covers all variables of C apart from ?x.\n1. For polr(?x,C) = pos it holds that if O 6|= (C1 \u2291 C2)\u00b5(?x)=s, then O 6|= (C1 \u2291 C2)\u00b5(?x)=r.\n2. For polr(?x,C) = neg it holds that if O 6|= (C1 \u2291 C2)\u00b5(?x)=r, then O 6|= (C1 \u2291 C2)\u00b5(?x)=s.\nProof. Due to Lemma 1, it suffices to show for some model I = (\u2206I , \u00b7I) of O and some element \u03b4 \u2208 \u2206I the following (which is formalized in contrapositive form):\n1. For polr(?x,C) = pos it holds that if \u03b4 \u2208 (C\u00b5(?x)=r) I , then \u03b4 \u2208 (C\u00b5(?x)=s) I .\n2. For polr(?x,C) = neg it holds that if \u03b4 \u2208 (C\u00b5(?x)=s) I , then \u03b4 \u2208 (C\u00b5(?x)=r) I .\nWe prove the claim by induction on the structure of the concept template C:\n\u2022 For C = \u2203?x.D, where D is a concept template that does not contain ?x. We have polr(?x,C) = pos. Assume, \u03b4 \u2208 ((\u2203?x.D)\u00b5(?x)=r) I , that is, \u03b4 \u2208 (\u2203r.\u00b5(D))I . Then\nthere is some \u03b4\u2032 \u2208 \u2206I such that \u3008\u03b4, \u03b4\u2032\u3009 \u2208 rI and \u03b4\u2032 \u2208 \u00b5(D)I . Since O |= r \u2291 s, we also have \u3008\u03b4, \u03b4\u2032\u3009 \u2208 sI and, therefore, \u03b4 \u2208 (\u2203s.\u00b5(D))I = ((\u2203?x.D)\u00b5(?x)=s) I .\n\u2022 For C = \u2200?x.D, where D is a concept template that does not contain ?x. We have polr(?x,C) = neg. If \u03b4 \u2208 ((\u2200?x.D)\u00b5(?x)=s) I , we have to show that \u03b4 \u2208 ((\u2200?x.D)\u00b5(?x)=r) I .\nIn contrary to what is to be shown, assume that \u03b4 \u2208 (\u00ac(\u2200?x.D)\u00b5(?x)=r) I , i.e., \u03b4 \u2208 (\u2203r.\u00b5(\u00acD))I . Hence, there is some \u03b4\u2032 \u2208 \u2206I such that \u3008\u03b4, \u03b4\u2032\u3009 \u2208 rI and \u03b4\u2032 \u2208 \u00b5(\u00acD)I . Since O |= r \u2291 s, we also have \u3008\u03b4, \u03b4\u2032\u3009 \u2208 sI and, therefore, \u03b4 /\u2208 (\u2200s.\u00b5(D))I = ((\u2200?x.D)\u00b5(?x)=s) I , which is a contradiction.\n\u2022 For C = > n ?x.D where D is a concept template that does not contain ?x. We have polr(?x,C) = pos. Assume, \u03b4 \u2208 ((> n ?x.D)\u00b5(?x)=r)\nI , that is \u03b4 \u2208 (> n r.\u00b5(D))I and \u03b4 has at least n distinct r-successors which are instances of \u00b5(D). Since O |= r \u2291 s these r-successors are also s-successors of \u03b4 and, therefore, \u03b4 \u2208 (> n s.\u00b5(D))I = ((> n ?x.D)\u00b5(?x)=s) I .\n\u2022 For C = 6 n ?x.D where C is a concept template that does not contain ?x. We have polr(?x,C) = neg. If \u03b4 \u2208 ((6 n ?x.D)\u00b5(?x)=s) I , we have to show that \u03b4 \u2208\n((6 n ?x.D)\u00b5(?x)=r) I . In contrary to what is to be shown, assume that \u03b4 \u2208 (\u00ac(6 n ?x.D)\u00b5(?x)=r) I , i.e., \u03b4 \u2208 (> n + 1 r.\u00b5(D))I . Hence, \u03b4 has at least n + 1 distinct r-successors, which are instances of \u00b5(D). Since O |= r \u2291 s, these r-successors are also s-successors and \u03b4 \u2208 ((> n+ 1 s.\u00b5(D)))I = ((> n+ 1 ?x.D)\u00b5(?x)=s)\nI , which is a contradiction.\n\u2022 For C = C1\u2293C2 and polr(?x,C) = pos, if \u03b4 \u2208 ((C1\u2293C2)\u00b5(?x)=r) I , then \u03b4 \u2208 (C1\u00b5(?x)=r) I\nand \u03b4 \u2208 (C2\u00b5(?x)=r) I . Since O |= r \u2291 s and by the induction hypothesis, \u03b4 \u2208 (C1\u00b5(?x)=s) I and \u03b4 \u2208 (C2\u00b5(?x)=s) I . Thus, \u03b4 \u2208 ((C1 \u2293 C2)\u00b5(?x)=s) I . The proof is analogous for polr(?x,C) = neg.\n\u2022 The proof for C1 \u2294C2 is analogous to the one for C1 \u2293 C2.\n\u2022 For C = \u00acD and polr(?x,C) = pos, if \u03b4 \u2208 (\u00acD\u00b5(?x)=r) I , we have to show that\n\u03b4 \u2208 (\u00acD\u00b5(?x)=s) I . Note that polr(?x,D) = neg. In contrary to what is to be shown, assume that \u03b4 \u2208 (D\u00b5(?x)=s) I . Since O |= r \u2291 s and by induction hypothesis \u03b4 \u2208 (D\u00b5(?x)=r) I and \u03b4 \u2208 (\u00acD\u00b5(?x)=r)\nI which is a contradiction. The proof is analogous for polr(?x,C) = neg.\n\u2022 For C = \u2203p.D and polr(?x,C) = pos, we also have polr(?x,D) = pos. Now, if \u03b4 \u2208 ((\u2203p.D)\u00b5(?x)=r)\nI , then \u03b4 has at least one p-successor that is an instance ofD\u00b5(?x)=r . Since O |= r \u2291 s and by induction hypothesis, this p-successor is an instance of D\u00b5(?x)=s. Hence, \u03b4 \u2208 ((\u2203p.D)\u00b5(?x)=s) I . The proof is analogous for polr(?x,C) = neg.\n\u2022 For C = \u2203?x.D and polr(?x,C) = pos, we also have polr(?x,D) = pos. Note that ?x occurs in D since otherwise the case is handled already above. Now, if \u03b4 \u2208 ((\u2203?x.D)\u00b5(?x)=r)\nI , then \u03b4 has at least one r-successor which is an instance of D\u00b5(?x)=r . Since O |= r \u2291 s and by induction hypothesis, \u03b4 has at least one s-successor that is an instance of D\u00b5(?x)=s. Hence, \u03b4 \u2208 ((\u2203?x.D)\u00b5(?x)=s) I .\n\u2022 For C = \u2200p.D and polr(?x,C) = pos, we also have polr(?x,D) = pos. Now, if \u03b4 \u2208 ((\u2200p.D)\u00b5(?x)=r) I , then \u03b4 \u2208 (\u2200p.(D)\u00b5(?x)=r) I and each p-successor of \u03b4 is an instance\nof D\u00b5(?x)=r . Since O |= r \u2291 s and by induction hypothesis, these p-successors are also instances of D\u00b5(?x)=s. Hence, \u03b4 \u2208 (\u2200p.(D\u00b5(?x)=s)) I = ((\u2200p.D)\u00b5(?x)=s)\nI . The proof is analogous for polr(?x,C) = neg.\n\u2022 For C = \u2200?x.D and polr(?x,C) = neg, we also have polr(?x,D) = neg. Note that ?x occurs in D since otherwise the case is handled already above. Now, if \u03b4 \u2208 ((\u2200?x.D)\u00b5(?x)=s) I , we have to show that \u03b4 \u2208 ((\u2200?x.D)\u00b5(?x)=r) I . In contrary to\nwhat is to be shown, assume that \u03b4 /\u2208 ((\u2200?x.D)\u00b5(?x)=r) I , i.e., \u03b4 \u2208 (\u2203r.(\u00acD)\u00b5(?x)=r) I . Hence, there is some \u03b4\u2032 \u2208 \u2206I such that \u3008\u03b4, \u03b4\u2032\u3009 \u2208 rI and \u03b4\u2032 \u2208 ((\u00acD)\u00b5(?x)=r) I . Since O |= r \u2291 s, \u03b4\u2032 is also an s-successor of \u03b4 and, by induction hypothesis, we have \u03b4\u2032 \u2208 ((\u00acD)\u00b5(?x)=s) I which is a contradiction.\n\u2022 For C = > n p.D and polr(?x,C) = pos, if \u03b4 \u2208 (( > n p.D)\u00b5(?x)=r) I , then \u03b4 has at\nleast n distinct p-successors that are instances of D\u00b5(?x)=r . Since O |= r \u2291 s and by induction hypothesis, these p-successors are also instances of D\u00b5(?x)=s. Hence, \u03b4 \u2208 (( > n p.D)\u00b5(?x)=s) I . The proof is analogous for polr(?x,C) = neg\n\u2022 For C = > n ?x.D and polr(?x,C) = pos, we also have polr(?x,D) = pos. Note that ?x occurs in D since otherwise the case is handled already above. Now, if \u03b4 \u2208 (( > n ?x.D)\u00b5(?x)=r)\nI , then \u03b4 has at least n distinct r-successors which are instances of D\u00b5(?x)=r. Since O |= r \u2291 s and by induction hypothesis, \u03b4 has at least n distinct s-successors that are instances of D\u00b5(?x)=s. Hence, \u03b4 \u2208 (( > n ?x.D)\u00b5(?x)=s) I .\n\u2022 For C = 6 n p.D and polr(?x,C) = pos, if \u03b4 \u2208 ((6 n p.D)\u00b5(?x)=r) I , we have to show\nthat \u03b4 \u2208 ((6 n p.D)\u00b5(?x)=s) I . Note that polr(?x,D) = neg. In contrary to what is to be shown, assume that \u03b4 \u2208 (\u00ac(6 n p.D)\u00b5(?x)=s) I , i.e., \u03b4 \u2208 ((> n + 1 p.D)\u00b5(?x)=s)\nI . Hence, \u03b4 has at least n + 1 distinct p-successors which are instances of D\u00b5(?x)=s. Since polr(?x,D) = neg and by induction hypothesis, these D\u00b5(?x)=s instances are also D\u00b5(?x)=r instances and \u03b4 \u2208 (> n + 1 p.(D)\u00b5(?x)=r) I = ((> n + 1 p.D)\u00b5(?x)=r)\nI , which is a contradiction. The proof is analogous for polr(?x,C) = neg.\n\u2022 For C = 6 n ?x.D and polr(?x,C) = neg, we have polr(?x,D) = pos. Note that ?x occurs in D since otherwise the case is handled already above. If \u03b4 \u2208 ((6 n ?x.D)\u00b5(?x)=s) I we have to show that \u03b4 \u2208 ((6 n ?x.D)\u00b5(?x)=r) I . In contrary\nAlgorithm 2 getPossibleMappings(O, ?x, at, \u00b5)\nInput: O: the queried SROIQ ontology ?x: a concept or role variable at: an axiom template in which ?x occurs \u00b5: a mapping with ?x \u2208 dom(\u00b5) Output: a set of mappings 1: S := \u2205 2: if ?x \u2208 VC then 3: if polc(?x, at) = pos then 4: S := {\u00b5\u2032 | \u00b5\u2032(?x) = A,A is a direct subconcept of \u00b5(?x) in O,\n\u00b5\u2032(?y) = \u00b5(?y) for ?y \u2208 dom(\u00b5) \\ {?x}} 5: else 6: S := {\u00b5\u2032 | \u00b5\u2032(?x) = A,A is a direct superconcept of \u00b5(?x) in O, \u00b5\u2032(?y) = \u00b5(?y) for ?y \u2208 dom(\u00b5) \\ {?x}} 7: end if 8: else 9: if polr(?x, at) = pos then\n10: S := {\u00b5\u2032 | \u00b5\u2032(?x) = r, r is a direct subrole of \u00b5(?x) in O, \u00b5\u2032(?y) = \u00b5(?y) for ?y \u2208 dom(\u00b5) \\ {?x}} 11: else 12: S := {\u00b5\u2032 | \u00b5\u2032(?x) = r, r is a direct superrole of \u00b5(?x) in O, \u00b5\u2032(?y) = \u00b5(?y) for ?y \u2208 dom(\u00b5) \\ {?x}} 13: end if 14: end if 15: return S\nto what is to be shown, assume that \u03b4 \u2208 (\u00ac(6 n ?x.D)\u00b5(?x)=r) I , i.e., \u03b4 \u2208 ((> n + 1 ?x.D)\u00b5(?x)=r) I . Hence, \u03b4 has at least n + 1 distinct r-successors which are instances of D\u00b5(?x)=r . Since O |= r \u2291 s, and by induction hypothesis, these r-successors are also s-successors and instances of D\u00b5(?x)=s. Hence, \u03b4 \u2208 ((> n + 1 ?x.D)\u00b5(?x)=s) I and \u03b4 \u2208 ((6 n ?x.D)\u00b5(?x)=s) I , which is a contradiction.\n\u2022 For C = (= n ?x.D) or C = (= n r.D), the polarity of ?x in C is always positive and negative, so polr(?x,C) is undefined and the case cannot occur.\n\u2022 The cases for ?x occurring in the form of an inverse (?x\u2212) are analogous, given that O |= r \u2291 s iff O |= r\u2212 \u2291 s\u2212.\nAlgorithm 2, which we explain in detail in Section 6.3, shows how we use the above theorems to create possible concept and role mappings for a concept or role variable ?x that appears only positively or only negatively in an axiom template C1 \u2291 C2."}, {"heading": "6.3 Query Answering Algorithm", "text": "Algorithm 3 shows an optimized way of evaluating queries using static ordering. First, axiom templates are simplified where possible (method rewrite in line 1). Next, the method\nAlgorithm 3 evaluate(O, q)\nInput: O: the queried SROIQ ontology q: a query over O Output: a set of solutions for evaluating q over O 1: At := rewrite(q) 2: At1, . . . , Atm:=connectedComponents(At) 3: for j=1, . . . , m do 4: Rj := {\u00b50 | dom(\u00b50) = \u2205} 5: at1, . . . , atn := order(At\nj) 6: for i = 1, . . . , n do 7: R := \u2205 8: for each \u00b5 \u2208 Rj do 9: if isSimple(ati) and Vars(ati) \\ dom(\u00b5) 6= \u2205 then\n10: R := R \u222a {\u00b5\u2032 \u222a \u00b5 | \u00b5\u2032 \u2208 callSpecificReasonerTask(\u00b5(ati))} 11: else if Vars(ati) \\ dom(\u00b5) = \u2205 then 12: if O |= \u00b5(ati) then 13: R := R \u222a {\u00b5} 14: end if 15: else 16: Vopt := {?x |?x 6\u2208 dom(\u00b5), Theorem 1 or 2 applies to ?x and ati} 17: B := initializeVariableMappings(O, ati, \u00b5, Vopt) 18: while B 6= \u2205 do 19: \u00b5\u2032 := removeMapping(B) 20: if O |= \u00b5\u2032(ati) then 21: R := R \u222a {\u00b5\u2032\u2032 | \u00b5\u2032\u2032(?x) = \u00b5\u2032(?x) if ?x /\u2208 Vopt and\n\u00b5\u2032\u2032(?x) = C if ?x \u2208 Vopt \u2229 VC ,O |= C \u2261 \u00b5 \u2032(?x) and \u00b5\u2032\u2032(?x) = r if ?x \u2208 Vopt \u2229 VR,O |= r \u2261 \u00b5 \u2032(?x)}\n22: for each ?x \u2208 Vopt do 23: B := B \u222a getPossibleMappings(O, ?x, ati, \u00b5\n\u2032) 24: end for 25: end if 26: end while 27: end if 28: end for 29: Rj := R 30: end for 31: end for 32: Rans := {\u00b51 \u222a . . . \u222a \u00b5m | \u00b5j \u2208 Rj, 1 \u2264 j \u2264 m} 33: return Rans\nconnectedComponents (line 2) partitions the axiom templates into sets of connected components, i.e., within a component the templates share common variables, whereas between components there are no shared variables. Unconnected components unnecessarily increase the amount of intermediate results and, instead, one can simply combine the results for the\nAlgorithm 4 initializeVariableMappings(O, at, \u00b5, Vopt) Input: O: the queried SROIQ ontology at: an axiom template \u00b5: a partial mapping Vopt: the variables of at to which Theorem 1 or 2 applies Output: a set of mappings 1: S := {\u00b5} 2: for each ?x \u2208 Vars(at) \\ dom(\u00b5) do 3: R := \u2205 4: if ?x \u2208 VC and ?x \u2208 Vopt then 5: for each \u00b5\u2032 \u2208 S do 6: if polc(?x, at) = pos then 7: \u00b5\u2032(?x) := \u22a4 8: else 9: \u00b5\u2032(?x) := \u22a5 10: end if 11: R := R \u222a {\u00b5\u2032} 12: end for 13: else if ?x \u2208 VR and ?x \u2208 Vopt then 14: for each \u00b5\u2032 \u2208 S do 15: if polr(?x, at) = pos then 16: \u00b5\u2032(?x) := \u22a4r 17: else 18: \u00b5\u2032(?x) := \u22a5r 19: end if 20: R := R \u222a {\u00b5\u2032} 21: end for 22: else 23: R := {\u00b5\u2032 | \u00b5\u2032(?x) = a, a \u2208 NO\nC or a \u2208 NO R or a \u2208 NO I and \u00b5\u2032(?y) = \u00b51(?y)\nfor \u00b51 \u2208 S and ?y \u2208 dom(\u00b51)} 24: end if 25: S := R 26: end for 27: return S\ncomponents in the end (line 32). For each component, we proceed as described below: we first determine an order (method order in line 5) as described in Section 5. For a simple axiom template, which contains so far unbound variables, we call a specialized reasoner method to retrieve entailed results, i.e., mappings for unbound variables (callSpecificReasonerTask in line 10). Note that the mappings \u00b5\u2032 do not assign values to any of the variables covered by the already computed (partial) solution \u00b5 since we instantiate the atom ati by \u00b5. This allows for defining the union of \u00b5 and \u00b5\u2032 by setting (\u00b5 \u222a \u00b5\u2032)(v) = \u00b5(v) if v \u2208 dom(\u00b5), and (\u00b5 \u222a \u00b5\u2032)(v) = \u00b5\u2032(v) otherwise. For templates with all their variables bound, we check whether the mappings lead to entailed axioms (lines 11 to 14). For all other cases, i.e.,\nfor complex axiom templates with unbound variables, we check which compatible mappings yield an entailed axiom (lines 15 to 27). In particular, we first initialize a set B of candidate mappings for the unbound variables of the axiom template (line 17, which refers to Algorithm 4). Algorithm 4 initializes the unbound variables of axiom templates on which Theorem 1 or 2 applies to \u22a4 (\u22a4r) or \u22a5 (\u22a5r) depending on whether the respective polarity function returns pos or neg. For template variables on which the optimization is not applicable, all compatible mappings are returned. The method removeMapping (line 19) returns a mapping from B and deletes this mapping from B. We then instantiate the axiom template and check entailment. In case the entailment holds, we first extend the set R with the current mapping \u00b5\u2032 and with mappings that map the optimization variables to equivalent concepts or roles of the respective variable mappings in \u00b5\u2032 (line 21) and we afterwards extend the set B of possible mappings for the variables to which the hierarchy optimization is applicable (getPossibleMappings in line 23). For example, if we just checked a mapping \u00b5 that maps a concept variable ?x to the concept A and ?x only occurs positively in the axiom template, then we add to the set B all mappings that map ?x to a direct subconcept3 of A (see Algorithm 2 line 4). In the implementation we use a more involved procedure, i.e., in order to avoid checking entailment of an instantiated axiom template more than once with the same mapping, which can be the case with the concept (role) hierarchy traversal that we perform, we keep track of already processed mappings and check only those that have not been checked in a previous iteration of the while loop (lines 18 to 26). For ease of presentation, this is not shown in Algorithm 3. We then repeat the procedure until B is empty (lines 18 to 26).\nFor the dynamic ordering, Algorithm 3 has to be changed as follows: We first compute the number of axiom templates in Atj; n := |Atj |. We then swap line 5 and line 6, i.e., instead of ordering all axiom templates before the loop that evaluates the axiom templates, we order within the for loop. The function order gets as additional input parameter the set of currently computed solutions and returns only the next cheapest axiom template according to the dynamic ordering function. Hence, we have ati := order(At\nj , Rj) instead of at1, . . . , atn := order(At\nj). We further insert a line after calling order to remove the cheapest axiom template from the current component: Atj := Atj \\ {ati}. As a result, the next iteration of the for loop will compute the cheapest axiom template amongst the not yet evaluated templates until, in the last iteration, we only have one axiom template left.\nAlgorithm 3 is sound and complete. The soundness and completeness of the algorithm is based on the following facts:\n\u2022 The method rewrite (see Definition 13) does not affect the answers to a query q, since it rewrites axiom templates to templates with the same set of answers.\n\u2022 The method connectedComponents does not affect the answers of q; it just splits the query into several components that are evaluated separately and we then take the cartesian product of the answers.\n\u2022 The method order does not change the query in any way; it just reorders the axiom templates.\n3. We say that a concept name A is a direct subconcept of a concept name B w.r.t. O, if O |= A \u2291 B and there is no other concept name A\u2032 such that O |= A\u2032 \u2291 B, O |= A \u2291 A\u2032 and O 6|= A \u2261 A\u2032. In a similar way we can define the direct superconcept, the direct subrole and direct superrole.\n\u2022 For the actual axiom template evaluation, we iterate over all the templates of the query by taking into account the mappings that have already been computed from the evaluation of previous templates and we distinguish between three cases:\n1. The axiom template is a simple one and contains unbound variables. We use specialized reasoner tasks to compute entailed mappings and since we use a sound and complete reasoner the result is indeed sound and complete.\n2. The axiom template does not contain unbound variables. In this case, we simply check entailment using a sound and complete reasoner.\n3. The axiom template is a complex template that has at least one variable unbound. For variables for which the optimization of Section 6.2 is applicable, we initialize the variables to \u22a4/\u22a4r (\u22a5/\u22a5r) and we traverse the concept/role hierarchy topdown (bottom-up). We prune mappings according to Theorems 1 and 2 in case a checked mapping does not constitute a solution mapping. In this case, we do not extend the set of possible mappings B. For variables of axiom templates to which the hierarchy optimization is not applicable, we check all compatible mappings. Thus, due to Theorem 1 and 2 the procedure is sound and complete.\nAlthough the above algorithm was implemented in the HermiT reasoner, one can compute the answers of a query using any (hyper)tableau reasoner."}, {"heading": "7. Evaluation", "text": "We tested the developed optimizations with standard benchmarks and a range of custom queries that test complex axiom template evaluation over more expressive ontologies. All experiments were performed on a Mac OS X Lion machine with a 2.53 GHz Intel Core i7 processor and Java 1.6 allowing 1GB of Java heap space. We measure the time for one-off tasks such as classification separately since such tasks are usually performed before the system accepts queries. The ontologies and all code required to perform the experiments are available online (Kollia & Glimm, 2013). The developed system (Glimm & Kollia, 2013), called OWL-BGP, is implemented as a SPARQL Wrapper that can be used with any reasoner that implements the OWLReasoner interface of the OWL API (Horridge & Bechhofer, 2009). In Section 7.1 we compare the different ordering strategies that have been developed on two benchmarks (LUBM and UOBM) that contain queries with variables only in place of individuals (query atoms). We also show the effect of ordering on LUBM using some custom queries with simple axiom templates created for SPARQL-DL (Kremen & Sirin, 2008). In Section 7.2 we show the effect of the proposed optimizations for queries with complex axiom templates. For the evaluation we have used the HermiT hypertableau reasoner (Motik, Shearer, Glimm, Stoilos, & Horrocks, 2013). Other reasoners such as Pellet (Clark & Parsia, 2013a) or Racer Pro (Racer Systems GmbH & Co. KG, 2013) could equally well be used with our implementation as long as they provide an interface with the required statistics, i.e., the number of known and possible instances of concepts and roles for the computation of the cost functions used for query ordering. Without any optimizations, providing this interface with statistics can easily be realized as described in the current paper. The presented query ordering techniques can also be used when optimizations such\nas caching, pseudo model merging techniques, binary instance retrieval, or absorption are employed. The cost functions might, however, require some adaptation to take the reduction in the required number of consistency checks into account. For example, Pellet uses binary instance retrieval, where testing possible instances of a concept A is realized by splitting the candidate instances into two partitions. For each partition, a single consistency check is performed. If the consistency check is successful, it is safe to consider all individuals belonging to the partition as non-instances of the tested concept A. Otherwise, we further split the partition and process the resulting partitions in the same way. In this case, one performs one consistency check to potentially determine several (non-)instances of A, which should be reflected in the cost functions.\nIt is also worth noting that the TrOWL reasoning framework (Thomas, Pan, & Ren, 2013) started to use our SPARQL wrapper to provide SPARQL support. An adaptation to also provide statistics is, to the best of our knowledge, still outstanding, although this should be straightforward. TrOWL is based on two approximate reasoners: one that underapproximates (computation of concept and role instances is sound, but incomplete) (Ren, Pan, & Zhao, 2010) and one that overapproximates (computation of concept and role instances is complete, but unsound) (Pan, Thomas, & Zhao, 2009). In such a setting, the underapproximation can straightforwardly be seen as the known instances and the overapproximation minus the underapproximation as the possible instances."}, {"heading": "7.1 Query Ordering", "text": "We tested our ordering techniques with the Lehigh University Benchmark (LUBM) (Guo, Pan, & Heflin, 2005) as a case where no disjunctive information is present and with the more expressive University Ontology Benchmark (UOBM) (Ma, Yang, Qiu, Xie, Pan, & Liu, 2006).\nWe first used the 14 conjunctive ABox queries provided in LUBM. From these, queries 2, 7, 8, 9 are the most interesting ones in our setting since they contain many atoms and ordering them can have an effect in running time. We tested the queries on LUBM(1,0) and LUBM(2,0) which contain data for one or two universities respectively, starting from index 0. LUBM(1,0) contains 17,174 individuals and LUBM(2,0) contains 38,334 individuals. LUBM(1,0) took 19 s to load and 0.092 s for classification and initialization of known and possible instances of concepts and roles. The clustering approach for concepts took 1 s and resulted in 16 clusters. The clustering approach for roles lasted 4.9 s and resulted in 17 role successor clusters, 29 role predecessor clusters and 87 role clusters. LUBM(2,0) took 48.5 s to load and 0.136 s for classification and initialization of known and possible instances. The clustering approach for concepts took 3.4 s and resulted in 16 clusters. The clustering approach for roles lasted 16.3 s and resulted in 17 role successor clusters, 31 role predecessor clusters and 102 role clusters. Table 2 shows the execution time for each of the four queries for LUBM(1,0) and LUBM(2,0) for four cases: i) when we use the static algorithm (columns 2 and 6), ii) when we use the dynamic algorithm (columns 3 and 7), iii) when we use random sampling, i.e., taking half of the individuals that are returned (from the evaluation of previous query atoms) in each run, to decide about the next cheapest atom to be evaluated in the dynamic case and iv) using the proposed sampling approach that is based on clusters constructed from individuals in the queried ontology (columns 4 and\n8). The queries marked with (*) are the queries where the static and dynamic algorithms result in a different ordering. In Queries 7 and 8 we observe an increase in running time when the dynamic technique is used (in comparison to the static) which is especially evident on Query 8 of LUBM(2,0), where the number of individuals in the ontology and the intermediate result sizes are larger. Dynamic ordering also behaves worse than static in Queries 2 and 9. This happens because, although the dynamic algorithm chooses a better ordering than the static algorithm, the intermediate results (that need to be checked in each iteration to determine the next query atom to be executed) are quite large and hence the cost of iterating over all possible mappings in the dynamic case far outweighs the better ordering that is obtained. We also observe that a random sampling for collecting the ordering statistics in the dynamic case (checking only 50% of individuals in \u2126i\u22121 randomly for detecting the next query atom to be executed) leads to much worse results in most queries than plain static or dynamic ordering. This happens since random sampling often leads to the choice of a worse execution order. The use of the cluster based sampling method performs better than the plain dynamic algorithm in all queries. In Queries 2 and 9, the gain we have from the better ordering of the dynamic algorithm when sampling is used is much more evident. This is the case since we use at most one individual from every cluster for the cost functions computation and the number of clusters is much smaller than the number of the otherwise tested individuals in each run.\nIn order to show the effectiveness of our proposed cost functions we compared the running times of all the valid plans (plans that comply to the connectedness condition of Definition 10, i.e., plans on which consecutive atoms share at least one common variable)\nwith the running time of the plan chosen by our method. In the following we show the results for LUBM(1, 0), but the results for LUBM(2,0) are comparable. In Table 3 we show, for each query, the number of valid plans that were constructed according to Definition 10 (column 2), the order of the plan chosen by the static, dynamic, and cluster based sampling methods if we order the valid plans by their execution time (columns 3,4,5; e.g., a value of 2 indicates that the ordering method chose the second best plan), the running time of HermiT for the plan that was created by Pellet (column 6) as well as the running time of the worst constructed plan (column 7).\nThe comparison of our ordering approach with the approach followed by other reasoners that support conjunctive query answering such as Pellet or Racer Pro is not very straightforward. This is the case because Pellet and Racer have many optimizations for instance retrieval (Sirin et al., 2007; Haarslev & Mo\u0308ller, 2008), which HermiT does not have. Thus, a comparison between the execution times of these reasoners and HermiT would not convey much information about the effectiveness of the proposed query ordering techniques. The idea of comparing only the orderings computed by other reasoners with those computed by our methods is also not very informative since the orderings chosen by different reasoners depend much on the way that queries are evaluated and on the costs of specific tasks in these reasoners and, hence, are reasoner dependent, i.e., an ordering that is good for one reasoner and which leads to an efficient evaluation may not be good for another reasoner. We should note that when we were searching for orderings according to Pellet, we switched off the simplification optimization that Pellet implements regarding the exploitation of domain and range axioms of the queried ontology for reducing the number of query atoms to be evaluated (Sirin & Parsia, 2006). This has been done in order to better evaluate the difference of the plain ordering obtained by Pellet and HermiT since our cost functions take into account all the query atoms.\nWe observe that for all queries apart from Query 9 the orderings chosen by our algorithms are the (near)optimal ones. For Queries 2 and 7, Pellet chooses the same ordering as our algorithms. For Query 8, Pellet chooses an ordering which, when evaluated with HermiT, results in higher execution time. For Query 9, our algorithms choose plans from about the middle of the order over all the valid plans w.r.t. the query execution time, which means that our algorithms do not perform well in this query. This is because of the greedy techniques we have used to find the execution plan which take into account only local information to choose the next query atom to be executed. Interestingly, the use of cluster based sampling has led to the finding of a better ordering, as we can see from the running time in Table 2 and the better ordering of the plan found with cluster based sampling techniques compared to static or plain dynamic ordering (Table 3). The ordering chosen by Pellet for Query 9 does also not perform well. We see that, in all queries, the worst running times are many orders of magnitude greater than the running times achieved by our ordering algorithms. In general, we observe that in LUBM static techniques are adequate and the use of dynamic ordering does not improve the execution time much compared to static ordering.\nIn order to show the scalability of the system, we next run the LUBM queries with different numbers of universities, i.e., LUBM(i,0) where i ranges from 3 to 9. Table 4 shows the number of individuals appearing in each ABox of different university size. The running times of Queries 2, 7, 8, 9 as well as the running time of all the 14 LUBM queries are shown in Table 5. The results for LUBM(1,0) and LUBM(2,0) are shown in Table 2. Note that the results shown are for the case that static ordering is performed. From this table we see that for all queries, the running time increases when the number of individuals of the ABox increases, which is reasonable. We observe that query answering over ontologies is still not as scalable as query answering over databases and this is so, because of the more expressive schema that has to be taken into account and the fact that we have incomplete information in contrast to databases where we have complete information.\nUnlike LUBM, the UOBM ontology contains disjunctions and the reasoner makes also nondeterministic derivations. In order to reduce the reasoning time, we removed the nominals and only used the first three departments containing 6,409 individuals. The resulting ontology took 16 s to load and 0.1 s to classify and initialize the known and possible instances. The clustering approach for concepts took 1.6 s and resulted in 356 clusters. The clustering approach for roles lasted 6.3 s and resulted in 451 role successor clusters, 390 role predecessor clusters and 4,270 role clusters. We present results for the static and dynamic algorithms on Queries 4, 9, 11, 12 and 14 provided in UOBM, which are the most interesting ones because they consist of many atoms. Most of these queries contain one atom with possible instances. As we see from Table 6, static and dynamic ordering show\nsimilar performance in Queries 4, 9, 11 and 12. Since the available statistics in this case are quite accurate, both methods find the optimal plans and the intermediate result set sizes are small. For both ordering methods, atoms with possible instances for these queries are executed last. In Query 14, the dynamic algorithm finds a better ordering which results in comparable performance. The effect that the cluster based sampling technique has on the running time is not as obvious as in the case of LUBM. This happens because in the current experiment the intermediate result sizes are not very large and, most importantly, because the gain obtained due to sampling is in the order of milliseconds whereas the total query answering times are in the order of seconds obscuring the small improvement in running time due to sampling. In all queries the orderings that are created by Pellet result in the same or worse running times than the orderings created by our algorithms.\nIn order to illustrate when dynamic ordering performs better than static, we also created the two custom queries:\nq1 = { isAdvisedBy(?x,?y), GraduateStudent(?x), Woman(?y) } q2 = { SportsFan(?x), GraduateStudent(?x), Woman(?x) }\nIn both queries, P [GraduateStudent], P [Woman] and P [isAdvisedBy] are non-empty, i.e., the query concepts and roles have possible instances. The running times for dynamic ordering are smaller since the more accurate statistics result in a smaller number of possible instances that have to be checked during query execution. In particular, for the static ordering, 151 and 41 possible instances have to be checked in query q1 and q2, respectively, compared to only 77 and 23 for the dynamic ordering. Moreover, the intermediate results are generally smaller in dynamic ordering than in static leading to a significant reduction in the running time of the queries. Interestingly, query q2 could not be answered within the time limit of 30 minutes when we transformed the three query concepts into a conjunction, i.e., when we asked for instances of the intersection of the three concepts. This is because for complex concepts the reasoner can no longer use the information about known and possible instances and falls back to a more naive way of computing the concept instances. Again, for the same reasons as before, the sampling techniques have no apparent effect on the running time of these queries.\nFor each query of the SPARQL-DL tests issued over LUBM(1,0) (Kremen & Sirin, 2008) (cf. Table 7), Table 8 shows the running time of the plan chosen by our method (column 2), the number of valid plans, i.e., plans that comply to the connectedness condition of Definition 10 (column 3), the order of the chosen plan if we order the valid plans by their execution times (column 4), the running time of HermiT for the plan that was created by Pellet (column 5) as well as the running time of the worst constructed plan (column 6). The queries as shown in Table 7 are ordered according to our static ordering algorithm. Since reasoning for LUBM is deterministic, we use static planning to order the axiom templates. Dynamic planning does not improve the execution times (actually it makes them worse) since, as it has been explained before, with only deterministic reasoning we have most of the important information for ordering from the beginning and the overhead caused by dynamic ordering results in worse query execution time.\nFrom the results of Table 8 one can observe that for Queries 1, 2, 3, 4 and 8 the proposed ordering chooses the optimal plan among all valid plans. For Queries 5, 6, 7, 9 and 10 the optimal plan is not chosen according to the proposed cost estimation algorithm. For Queries 5, 7, 9 and 10 this is due to the greedy techniques we have used for finding in\neach iteration of our ordering algorithm the next cheapest axiom template to be evaluated. For example, the optimal plan for Query 10 starts with the template GraduateStudent(?x), which is not the cheapest one according to our cost based technique and then, while moving\nover connected templates, a different order is chosen than the order chosen by our algorithm. It turns out that all valid plans beginning with the atom GraduateStudent(?x) lead to better execution times than the plan chosen by our algorithm resulting in the existence of several better plans than the chosen one.\nFor Query 6 we do not find the optimal plan because we have overestimated the cost of the disjoint axiom template and hence have missed the optimal ordering. Nevertheless, the chosen plans lead to execution times for all queries that are up to three orders of magnitude lower than those when the worst plans are chosen. For queries in which the proposed ordering does not lead to the optimal plan, one has to additionally take into account the time we saved from not computing the costs for the |q!| possible orderings, which can be very high. Apart from Queries 4, 6 and 8, we observe that the plans produced by Pellet are not optimal when evaluated with HermiT. As we have discussed before, this happens because the statistics created for ordering are reasoner specific and hence a good ordering for one reasoner may not be good for another reasoner."}, {"heading": "7.2 Complex Axiom Template Optimizations", "text": "In the absence of suitable standard benchmarks for arbitrary SPARQL queries, we created a custom set of queries as shown in Tables 10 and 12 for the GALEN and the FBbt XP ontology, respectively. Systems that fully support the SPARQL Direct Semantics entailment regime are still under development, which makes it hard to compare our results for these kinds of queries with other systems.\nGALEN is a biomedical ontology. It\u2019s expressivity is (Horn-)SHIF and it consists of 2,748 concepts and 413 abstract roles. FBbt XP is an ontology taken from the Open Biological Ontologies (OBO) Foundry (OBO Foundry, 2013). It falls into the SHI fragment of SROIQ and consists of 7,221 concepts and 21 abstract roles. We only consider the TBox part of FBbt XP since the ABox is not relevant for showing the different effects of the proposed optimizations on the execution times of the considered queries. GALEN took 3.7 s to load and 11.1 s to classify (concepts and roles), while FBbt XP took 1.5 s to load and 7.4 s to classify.\nThe execution times for the queries of Tables 10 and 12 are shown on the right-hand side of Tables 9 and 11, respectively. We have set a time limit of 30 minutes for each query. For each query, we tested the execution once without optimizations and once for each combination of applicable optimizations from Sections 5 and 6. In Tables 9 and 11, one can also see the number of consistency checks that were performed for the evaluation of each query and each combination of the applicable optimizations as well as the number of results of each query. In these tables we have taken the time of the worst ordering of query atoms for the cases in which the ordering optimization is applicable but not enabled. Note that only the complex axiom templates require consistency checks to be evaluated; the simple ones (subsumption axiom templates in this case) need only cache lookups in the reasoner\u2019s internal structures since the concepts and roles are already classified.\nGALEN Queries: As expected, an increase in the number of variables within an axiom template leads to a significant increase in the query execution time because the number of mappings that have to be checked grows exponentially in the number of variables. This can, in particular, be observed from the difference in execution time between Query 1 and 2.\nFrom these two queries, it is evident that the use of the hierarchy exploitation optimization leads to a decrease in execution time of up to two orders of magnitude. Query 3 can only be completed in the time limit if at least the query rewriting optimization is enabled. We can get an improvement of up to three orders of magnitude in this query, by using rewriting in combination with the hierarchy exploitation. Query 4 can only be completed in the given time limit if at least reordering and rewriting is enabled. Rewriting splits the first axiom template into the following two simple axiom templates, which are evaluated much more efficiently:\nNAMEDLigament \u2291 NAMEDInternalBodyPart and NAMEDLigament \u2291?x\nAfter the rewriting, the ordering optimization has an even more pronounced effect since both rewritten axiom templates can be evaluated with a simple cache lookup. Without ordering, the complex axiom template could be executed before the simple ones, which leads to the inability of answering the query within the time limit of 30 min. Without a good ordering, Query 5 can also not be answered within the time limit. The ordering chosen by our algorithm is shown below. Note that the query consists of two connected components: one for the axioms containing ?z and ?w and another one for the axioms containing ?x and ?y.\n?z \u2291 ModifierAttribute\n?w \u2291 AbstractStatus\nBacterium \u2291 \u2203?z.?w\n?y \u2291 StatusAttribute\n?x \u2291 NonNormalCondition\n?x \u2291 \u2203?y.Status\nIn this query, the hierarchy exploitation optimization does not improve the execution time since, due to the chosen ordering, the variables on which the hierarchy optimization can be applied, are already bound when it comes to the evaluation of the complex templates. Hence, the running times with and without the hierarchy exploitation are similar. The number of consistency checks is significantly lower than the number of answers because the overall results are computed by taking the cartesian products of the results for the two connected components. Interestingly, for queries with complex axiom templates, it does not make sense to require that the next axiom template to evaluate shares a variable with the previously evaluated axiom templates, as in the case of simple axiom templates. For example, if we would require that, the first connected component of the query would be executed in the following order:\n?z \u2291 ModifierAttribute\nBacterium \u2291 \u2203?z.?w\n?w \u2291 AbstractStatus\nthis results in 294,250 instead of 1,498 consistency checks since we no longer use a cheap cache look-up check to determine the bindings for ?w, but first iterate over all possible ?w bindings and check entailment of the complex axiom template and then reduce the computed candidates when processing the last axiom template.\nAlthough our optimizations can significantly improve the query execution time, the required time can still be quite high. In practice, it is, therefore, advisable to add as many restrictive axiom templates (axiom templates which require only cache lookups) for query variables as possible. For example, the addition of ?y \u2291 Shape to Query 4 reduces the runtime from 1.12 s to 0.65 s. We observe, as expected, that the execution time for each query and applicable optimization is analogous to the number of consistency checks that are performed for the evaluation of the query.\nFBbt XP Queries: For Queries 1, 2, 3, 5 and 6, on which the ordering optimization is applicable, we observe a decrease in execution time up to two orders of magnitude when\nthe ordering optimization is used. The ordering optimization is important for answering Queries 1, 2 and 3 within the time limit. For all queries, the additional use of the hierarchy exploitation optimization leads to an improvement of up to three orders of magnitude. We observe that in some queries the effect of the hierarchy exploitation is more profound than in others. More precisely, the smaller the ratio of the result size to the number of consistency checks without the hierarchy optimization, the more pronounced is the effect when enabling this optimization. In other words, when more tested mappings are indeed solutions, one can prune fewer parts of the hierarchy since pruning can only be performed when we find a non-solution. In Query 2, we even observe a slight increase in running\ntime when the hierarchy optimization is used. This is because the optimization can only prune few candidate mappings, which does not outweigh the overhead caused by maintaining information about which hierarchy parts have already been tested. In Query 6, the rewriting optimization is important to answer the query within the time limit. When all optimizations are enabled, the number of consistency checks is less than the result size (32,490 versus 43,338) since only the complex axiom template requires consistency checks."}, {"heading": "8. Related Work", "text": "There is not yet a standardized and commonly implemented query language for OWL ontologies. Several of the widely deployed systems support, however, some query language. Pellet supports SPARQL-DL (Sirin & Parsia, 2007), which is a subset of SPARQL, adapted to work with OWL\u2019s Direct Semantics. The kinds of SPARQL queries that are supported in SPARQL-DL are those that can directly be mapped to reasoner tasks. Therefore, SPARQLDL can be understood as queries that only use simple axiom templates in our terminology. Similarly, KAON2 (Hustadt, Motik, & Sattler, 2004) supports SPARQL queries, but restricted to ABox queries/conjunctive instance queries. To the best of our knowledge, there are no publications that describe any ordering strategies for KAON2. Racer Pro (Haarslev & Mo\u0308ller, 2001) has a proprietary query language, called nRQL (Haarslev et al., 2004), which allows for queries that go beyond ABox queries, e.g., one can retrieve sub- or superconcepts of a given concept. TrOWL (Thomas et al., 2013) is another system that supports SPARQL queries, but the reasoning in TrOWL is approximate, i.e., an OWL DL ontology is rewritten into an ontology that uses a less expressive language before reasoning is applied (Thomas, Pan, & Ren, 2010). TrOWL is based on the SPARQL framework presented here, but instead of using HermiT as background reasoner, it uses its approximate reasoners for the OWL 2 EL and OWL 2 QL profiles. Furthermore, there are systems such as QuOnto (Acciarri, Calvanese, De Giacomo, Lembo, Lenzerini, Palmieri, & Rosati, 2013) or Requiem (Pe\u0301rez-Urbina, Motik, & Horrocks, 2013), which support profiles of OWL 2, and which support conjunctive queries, e.g., written in SPARQL syntax, but with proper nondistinguished variables. Of the systems that support all of OWL 2 DL, only Pellet supports non-distinguished variables as long as they are not used in cycles, since decidability of cyclic conjunctive queries is to the best of our knowledge still an open problem.\nThe problem of finding good orderings for the templates of a query issued over an ontology has already been preliminarily studied (Sirin & Parsia, 2006; Kremen & Sirin, 2008; Haarslev & Mo\u0308ller, 2008). Similarly to our work, Sirin and Parsia as well as Kremen and Sirin exploit reasoning techniques and information provided by reasoner models to create statistics about the cost and the result size of axiom template evaluations within execution plans. A difference is that they use cached models for cheaply finding obvious concept and role (non-)instances, whereas in our case we do not cache any model or model parts. Instead we process the pre-model constructed for the initial ontology consistency check and extract the known and possible instances of concepts and roles from it. We subsequently use this information to create and update the query atom statistics. Moreover, Sirin and Parsia and Kremen and Sirin compare the costs of complete execution plans \u2014after heuristically reducing the huge number of possible complete plans \u2014 and choose the one that is most promising before the beginning of query execution. This is different from our cheap\ngreedy algorithm that finds, at each iteration, the next most promising axiom template. Our experimental study shows that this is equally effective as the investigation of all possible execution orders. Moreover, in our work we have additionally used dynamic ordering combined with clustering techniques, apart from static ones, and have shown that these techniques lead to better performance particularly in ontologies that contain disjunctions and do now allow for purely deterministic reasoning.\nHaarslev and Mo\u0308ller discuss by means of an example the ordering criteria they use to find efficient query execution plans in Racer Pro. In particular, they use traditional database cost based optimization techniques, which means that they take into account only the cardinality of concept and role atoms to decide about the most promising ordering. As previously discussed, this can be inadequate especially for ontologies with disjunctive information.\nA significant amount of work on the estimation of cost metrics and the search for optimal orders for evaluating joins has been performed in the context of databases. As discussed in Section 3, in databases, cost formulas are defined that estimate the CPU and I/O costs (similar to our reasoning costs) and the number of returned tuples (similar to our result sizes). These estimates are used to find good join orders. The System R query optimizer, for example, is among the first works to use extended statistics and a novel dynamic programming algorithm to find effective (minimal) join orders of query atoms (Selinger, Astrahan, Chamberlin, Lorie, & Price, 1979). A heuristic similar to ours (for the case of conjunctive instance queries) is used in this work, according to which the join order permutations are reduced by avoiding Cartesian products of result sets of query atoms. Regarding join order selection, apart from dynamic programming, also other algorithmic paradigms based on branch-and-bound or simulated annealing have, since then, been presented in the literature. Dynamic ordering has also been explored in the literature in the context of adaptive query processing techniques (Gounaris, Paton, Fernandes, & Sakellariou, 2002), which have been proposed to overcome the problems caused by the lack of necessary statistics, good selectivity estimates, knowledge for the runtime mappings of a query at compile time. These techniques take into account changes that happen to the evaluation environment at runtime and modify the execution plan at runtime (i.e., they change the used operators for joins or the order in which the (remaining) query atoms are evaluated)."}, {"heading": "9. Conclusions", "text": "In the current paper, we presented a sound and complete query answering algorithm and novel optimizations for the OWL Direct Semantics entailment regime of SPARQL 1.1. Our prototypical query answering system combines existing tools such as ARQ, the OWL API, and the HermiT OWL reasoner. Apart from the query ordering optimization\u2014which uses (reasoner dependent) statistics provided by HermiT\u2014the system is independent of the reasoner used, and could employ any reasoner that supports the OWL API.\nWe propose two cost-based ordering strategies for finding (near-)optimal execution orders for conjunctive instance queries. The cost formulas are based on information extracted from models of a reasoner (in our case HermiT). We show through an experimental study that static techniques are quite adequate for ontologies in which reasoning is deterministic. When reasoning is nondeterministic, however, dynamic techniques often perform better.\nThe use of cluster based sampling techniques can improve the performance of the dynamic algorithm when the intermediate result sizes of queries are sufficiently large, whereas random sampling is not beneficial and often leads to suboptimal query execution plans.\nThe presented approach can be used to find answers to queries issued over SROIQ ontologies. Since it is based on entailment checking for finding answers to conjunctive instance queries it is not as scalable as other techniques, such as query rewriting, which are applied to ontologies of lower expressivity, such as DL-Lite. In other words, there is a trade-off between scalability and ontology expressivity and one needs to consider if it is more important for one\u2019s application to use a more scalable query answering system with a less expressive ontology or a less scalable system with a more expressive ontology.\nThe module for ordering is based on the extraction of statistics from a reasoner model, which is computed off-line. Any update of the ontology ABox would then cause the construction of a new model from scratch and the consequent recompilation of known and possible instances of concepts and roles unless an incremental reasoner is used. An incremental reasoner could, for example, find modules of the pre-model that are affected by the update and recompute only model parts. One could then also incrementally update the statistics that are used for ordering. To the best of our knowledge, OWL DL reasoners only partially support incremental reasoning and we have not considered this case in the current paper.\nFor queries that go beyond conjunctive instance queries we further provide optimizations such as rewriting into equivalent, but simpler queries. Another highly effective and frequently applicable optimization prunes the number of candidate solutions that have to be checked by exploiting the concept and role hierarchies. One can, usually, assume that these hierarchies are computed before a system accepts queries. Our empirical evaluation shows that this optimization can reduce the query evaluation times up to three orders of magnitude."}, {"heading": "Acknowledgments", "text": "This work was done within the Transregional Collaborative Research Centre SFB/TRR 62 \u201cA Companion-Technology for Cognitive Technical Systems\u201d funded by the German Research Foundation (DFG)."}], "references": [{"title": "QuOnto. Available at http://www.dis.uniroma1.it/\u223cquonto", "author": ["A. Acciarri", "D. Calvanese", "G. De Giacomo", "D. Lembo", "M. Lenzerini", "M. Palmieri", "R. Rosati"], "venue": null, "citeRegEx": "Acciarri et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Acciarri et al\\.", "year": 2013}, {"title": "RDF Vocabulary Description Language 1.0: RDF Schema", "author": ["D. Brickley", "R.V. Guha"], "venue": "W3C Recommendation. Available at http://www.w3. org/TR/rdf-schema/", "citeRegEx": "Brickley and Guha,? \\Q2004\\E", "shortCiteRegEx": "Brickley and Guha", "year": 2004}, {"title": "An RDF query and transformation language", "author": ["J. Broekstra", "A. Kampman"], "venue": "Semantic Web and Peer-to-Peer,", "citeRegEx": "Broekstra and Kampman,? \\Q2006\\E", "shortCiteRegEx": "Broekstra and Kampman", "year": 2006}, {"title": "Tractable reasoning and efficient query answering in description logics: The DL-Lite family", "author": ["D. Calvanese", "G.D. Giacomo", "D. Lembo", "M. Lenzerini", "R. Rosati"], "venue": "Journal of Automated Reasoning,", "citeRegEx": "Calvanese et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Calvanese et al\\.", "year": 2007}, {"title": "A novel approach to ontology classification", "author": ["B. Glimm", "I. Horrocks", "B. Motik", "R. Shearer", "G. Stoilos"], "venue": "Journal of Web Semantics: Science, Services and Agents on the World Wide Web,", "citeRegEx": "Glimm et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Glimm et al\\.", "year": 2012}, {"title": "OWL-BGP. Available at http://code.google.com/p/owl-bgp", "author": ["B. Glimm", "I. Kollia"], "venue": null, "citeRegEx": "Glimm and Kollia,? \\Q2013\\E", "shortCiteRegEx": "Glimm and Kollia", "year": 2013}, {"title": "SPARQL beyond subgraph matching", "author": ["B. Glimm", "M. Kr\u00f6tzsch"], "venue": "In Proceedings of the 9th International Semantic Web Conference (ISWC\u201910),", "citeRegEx": "Glimm and Kr\u00f6tzsch,? \\Q2010\\E", "shortCiteRegEx": "Glimm and Kr\u00f6tzsch", "year": 2010}, {"title": "SPARQL 1.1 entailment regimes", "author": ["B. Glimm", "C. Ogbuji"], "venue": null, "citeRegEx": "Glimm and Ogbuji,? \\Q2013\\E", "shortCiteRegEx": "Glimm and Ogbuji", "year": 2013}, {"title": "Adaptive query processing: A survey", "author": ["A. Gounaris", "N.W. Paton", "A.A. Fernandes", "R. Sakellariou"], "venue": "In In 19th BNCOD,", "citeRegEx": "Gounaris et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Gounaris et al\\.", "year": 2002}, {"title": "LUBM: A benchmark for OWL knowledge base systems", "author": ["Y. Guo", "Z. Pan", "J. Heflin"], "venue": "Journal of Web Semantics,", "citeRegEx": "Guo et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Guo et al\\.", "year": 2005}, {"title": "Racer system description", "author": ["V. Haarslev", "R. M\u00f6ller"], "venue": "Proceedings of the 1st International Joint Conference on Automated Reasoning (IJCAR\u201901),", "citeRegEx": "Haarslev and M\u00f6ller,? \\Q2001\\E", "shortCiteRegEx": "Haarslev and M\u00f6ller", "year": 2001}, {"title": "On the scalability of description logic instance retrieval", "author": ["V. Haarslev", "R. M\u00f6ller"], "venue": "Journal of Automated Reasoning,", "citeRegEx": "Haarslev and M\u00f6ller,? \\Q2008\\E", "shortCiteRegEx": "Haarslev and M\u00f6ller", "year": 2008}, {"title": "Querying the semantic web with Racer + nRQL", "author": ["V. Haarslev", "R. M\u00f6ller", "M. Wessel"], "venue": "In Proceedings of the KI-2004 International Workshop on Applications of Description Logics", "citeRegEx": "Haarslev et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Haarslev et al\\.", "year": 2004}, {"title": "Foundations of Semantic Web Technologies", "author": ["P. Hitzler", "M. Kr\u00f6tzsch", "S. Rudolph"], "venue": null, "citeRegEx": "Hitzler et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hitzler et al\\.", "year": 2009}, {"title": "The OWL API: A Java API for working with OWL 2 ontologies", "author": ["M. Horridge", "S. Bechhofer"], "venue": "Proceedings of the OWLED 2009 Workshop on OWL: Experiences and Directions,", "citeRegEx": "Horridge and Bechhofer,? \\Q2009\\E", "shortCiteRegEx": "Horridge and Bechhofer", "year": 2009}, {"title": "The even more irresistible SROIQ", "author": ["I. Horrocks", "O. Kutz", "U. Sattler"], "venue": "Proceedings of the 10th International Conference on Principles of Knowledge Representation and Reasoning (KR\u201906),", "citeRegEx": "Horrocks et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Horrocks et al\\.", "year": 2006}, {"title": "Optimal histograms for limiting worst-case error propagation in the size of join results", "author": ["Y.E. Ioannidis", "S. Christodoulakis"], "venue": "ACM Transactions on Database Systems,", "citeRegEx": "Ioannidis and Christodoulakis,? \\Q1993\\E", "shortCiteRegEx": "Ioannidis and Christodoulakis", "year": 1993}, {"title": "RIQ and SROIQ are harder than SHOIQ", "author": ["Y. Kazakov"], "venue": "Brewka, G., & Lang, J. (Eds.), Proceedings of the 11th International Conference on Principles of Knowledge Representation and Reasoning (KR\u201908), pp. 274\u2013284. AAAI Press.", "citeRegEx": "Kazakov,? 2008", "shortCiteRegEx": "Kazakov", "year": 2008}, {"title": "Evaluation sources. Available at http://code.google.com/ p/query-ordering", "author": ["I. Kollia", "B. Glimm"], "venue": null, "citeRegEx": "Kollia and Glimm,? \\Q2013\\E", "shortCiteRegEx": "Kollia and Glimm", "year": 2013}, {"title": "The combined approach to query answering in DL-Lite", "author": ["R. Kontchakov", "C. Lutz", "D. Toman", "F. Wolter", "M. Zakharyaschev"], "venue": "Proceedings of the 12th International Conference on Principles of Knowledge Representation and Reasoning", "citeRegEx": "Kontchakov et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kontchakov et al\\.", "year": 2010}, {"title": "SPARQL-DL implementation experience", "author": ["P. Kremen", "E. Sirin"], "venue": "Proceedings of the 4th OWLED Workshop on OWL: Experiences and Directions Washington,", "citeRegEx": "Kremen and Sirin,? \\Q2008\\E", "shortCiteRegEx": "Kremen and Sirin", "year": 2008}, {"title": "Towards a complete OWL ontology benchmark", "author": ["L. Ma", "Y. Yang", "Z. Qiu", "G. Xie", "Y. Pan", "S. Liu"], "venue": "In The Semantic Web: Research and Applications, Lecture Notes in Computer Science,", "citeRegEx": "Ma et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Ma et al\\.", "year": 2006}, {"title": "OWL 2 Web Ontology Language: Profiles", "author": ["B. Motik", "B. Cuenca Grau", "I. Horrocks", "Z. Wu", "A. Fokoue", "C. Lutz"], "venue": null, "citeRegEx": "Motik et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Motik et al\\.", "year": 2012}, {"title": "OWL 2 Web Ontology Language: Direct Semantics", "author": ["B. Motik", "P.F. Patel-Schneider", "B. Cuenca Grau"], "venue": null, "citeRegEx": "Motik et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Motik et al\\.", "year": 2012}, {"title": "HermiT. Available at http://www.hermit-reasoner.com", "author": ["B. Motik", "R. Shearer", "B. Glimm", "G. Stoilos", "I. Horrocks"], "venue": null, "citeRegEx": "Motik et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Motik et al\\.", "year": 2013}, {"title": "Hypertableau reasoning for description logics", "author": ["B. Motik", "R. Shearer", "I. Horrocks"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Motik et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Motik et al\\.", "year": 2009}, {"title": "The open biological and biomedical ontologies", "author": ["OBO Foundry"], "venue": "Available at http: //www.obofoundry.org/.", "citeRegEx": "Foundry,? 2013", "shortCiteRegEx": "Foundry", "year": 2013}, {"title": "Oracle database documentation library 11g release 2", "author": ["Oracle"], "venue": "Available at http: //www.oracle.com/pls/db112/homepage.", "citeRegEx": "Oracle,? 2013", "shortCiteRegEx": "Oracle", "year": 2013}, {"title": "Completeness guaranteed approximation for owl dl query answering", "author": ["J.Z. Pan", "E. Thomas", "Y. Zhao"], "venue": "In Proceedings of the 2009 International Workshop on Description Logics (DL\u201909)", "citeRegEx": "Pan et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Pan et al\\.", "year": 2009}, {"title": "OWL 2 Web Ontology Language: Mapping to RDF Graphs", "author": ["P.F. Patel-Schneider", "B. Motik"], "venue": null, "citeRegEx": "Patel.Schneider and Motik,? \\Q2012\\E", "shortCiteRegEx": "Patel.Schneider and Motik", "year": 2012}, {"title": "Tractable query answering and rewriting under description logic constraints", "author": ["H. P\u00e9rez-Urbina", "B. Motik", "I. Horrocks"], "venue": "Journal of Applied Logic,", "citeRegEx": "P\u00e9rez.Urbina et al\\.,? \\Q2010\\E", "shortCiteRegEx": "P\u00e9rez.Urbina et al\\.", "year": 2010}, {"title": "SPARQL Query Language for RDF. W3C Recommendation. Available at http://www.w3.org/TR/ rdf-sparql-query", "author": ["E. Prud\u2019hommeaux", "A. Seaborne"], "venue": null, "citeRegEx": "Prud.hommeaux and Seaborne,? \\Q2008\\E", "shortCiteRegEx": "Prud.hommeaux and Seaborne", "year": 2008}, {"title": "Soundness preserving approximation for tbox reasoning", "author": ["Y. Ren", "J.Z. Pan", "Y. Zhao"], "venue": "In Proceedings of the 25th National Conference on Artificial Intelligence", "citeRegEx": "Ren et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ren et al\\.", "year": 2010}, {"title": "High performance query answering over dl-lite ontologies", "author": ["M. Rodriguez-Muro", "D. Calvanese"], "venue": "In Proc. of the 13th Int. Conf. on the Principles of Knowledge Representation and Reasoning (KR", "citeRegEx": "Rodriguez.Muro and Calvanese,? \\Q2012\\E", "shortCiteRegEx": "Rodriguez.Muro and Calvanese", "year": 2012}, {"title": "OWL 2 Web Ontology Language: RDFBased Semantics. W3C Recommendation. Available at http://www.w3.org/TR/ owl2-rdf-based-semantics", "author": ["M. Schneider"], "venue": null, "citeRegEx": "Schneider,? \\Q2012\\E", "shortCiteRegEx": "Schneider", "year": 2012}, {"title": "RDQL \u2013 A Query Language for RDF. W3C Member Submission", "author": ["A. Seaborne"], "venue": "Available at http://www.w3.org/Submission/RDQL/", "citeRegEx": "Seaborne,? \\Q2004\\E", "shortCiteRegEx": "Seaborne", "year": 2004}, {"title": "Access path selection in a relational database management system", "author": ["P.G. Selinger", "M.M. Astrahan", "D.D. Chamberlin", "R.A. Lorie", "T.G. Price"], "venue": "Proceedings of the 1979 ACM SIGMOD International Conference on Management of Data,", "citeRegEx": "Selinger et al\\.,? \\Q1979\\E", "shortCiteRegEx": "Selinger et al\\.", "year": 1979}, {"title": "From wine to water: Optimizing description logic reasoning for nominals", "author": ["E. Sirin", "B. Cuenca Grau", "B. Parsia"], "venue": "Proceedings of the 10th International Conference on Principles of Knowledge Representation and Reasoning", "citeRegEx": "Sirin et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Sirin et al\\.", "year": 2006}, {"title": "Optimizations for answering conjunctive ABox queries: First results", "author": ["E. Sirin", "B. Parsia"], "venue": "In Proceedings of the 2006 International Workshop on Description Logics (DL\u201906),", "citeRegEx": "Sirin and Parsia,? \\Q2006\\E", "shortCiteRegEx": "Sirin and Parsia", "year": 2006}, {"title": "SPARQL-DL: SPARQL query for OWL-DL", "author": ["E. Sirin", "B. Parsia"], "venue": "Proceedings of the OWLED 2007 Workshop on OWL: Experiences and Directions,", "citeRegEx": "Sirin and Parsia,? \\Q2007\\E", "shortCiteRegEx": "Sirin and Parsia", "year": 2007}, {"title": "Pellet: A practical OWL-DL reasoner", "author": ["E. Sirin", "B. Parsia", "B.C. Grau", "A. Kalyanpur", "Y. Katz"], "venue": "Journal of Web Semantics,", "citeRegEx": "Sirin et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Sirin et al\\.", "year": 2007}, {"title": "Heuristic and randomized optimization for the join ordering problem", "author": ["M. Steinbrunn", "G. Moerkotte", "A. Kemper"], "venue": "VLDB Journal,", "citeRegEx": "Steinbrunn et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Steinbrunn et al\\.", "year": 1997}, {"title": "SPARQL basic graph pattern optimization using selectivity estimation", "author": ["M. Stocker", "A. Seaborne", "A. Bernstein", "C. Kiefer", "D. Reynolds"], "venue": "In Proceedings of the 17th International Conference on World Wide Web (WWW\u201908),", "citeRegEx": "Stocker et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Stocker et al\\.", "year": 2008}, {"title": "Apache jena", "author": ["The Apache Software Foundation"], "venue": "Available at http://jena.apache.org.", "citeRegEx": "Foundation,? 2013", "shortCiteRegEx": "Foundation", "year": 2013}, {"title": "TrOWL: Tractable OWL 2 reasoning infrastructure", "author": ["E. Thomas", "J.Z. Pan", "Y. Ren"], "venue": "In Proceedings of the Extended Semantic Web Conference (ESWC\u201910)", "citeRegEx": "Thomas et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Thomas et al\\.", "year": 2010}, {"title": "TrOWL. Available at http://trowl.eu", "author": ["E. Thomas", "J.Z. Pan", "Y. Ren"], "venue": null, "citeRegEx": "Thomas et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Thomas et al\\.", "year": 2013}, {"title": "Optimizing terminological reasoning for expressive description logics", "author": ["D. Tsarkov", "I. Horrocks", "P.F. Patel-Schneider"], "venue": "Journal of Automated Reasoning,", "citeRegEx": "Tsarkov et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Tsarkov et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 35, "context": "Several query languages have been designed for this purpose, including RDQL (Seaborne, 2004), SeRQL (Broekstra & Kampman, 2006) and, most recently, SPARQL.", "startOffset": 76, "endOffset": 92}, {"referenceID": 34, "context": "in order to use more elaborate entailment relations, such as those induced by RDF Schema (RDFS) (Brickley & Guha, 2004) or OWL (Motik, Patel-Schneider, & Cuenca Grau, 2012b; Schneider, 2012).", "startOffset": 127, "endOffset": 190}, {"referenceID": 27, "context": ", Oracle 11g (Oracle, 2013), Apache Jena (The Apache Software Foundation, 2013), or Stardog (Clark & Parsia, 2013b)), the development of tools that provide full SPARQL support under OWL semantics is still an ongoing effort.", "startOffset": 13, "endOffset": 27}, {"referenceID": 33, "context": "More complex WHERE clauses, which use operators such as UNION for alternative selection criteria or OPTIONAL to query for optional bindings (Prud\u2019hommeaux & Seaborne, 2008), can be evaluated simply by combining the results obtained by the BGP evaluation. Similarly, operations such as the projection of variables from the SELECT clause is a straightforward operation over the results of the evaluation of the WHERE clause. Therefore, we focus here on BGP evaluation only. For a more detailed introduction to SPARQL queries and their algebra we refer interested readers to the work of Hitzler, Kr\u00f6tzsch, and Rudolph (2009) or Glimm and Kr\u00f6tzsch (2010).", "startOffset": 157, "endOffset": 622}, {"referenceID": 6, "context": "For a more detailed introduction to SPARQL queries and their algebra we refer interested readers to the work of Hitzler, Kr\u00f6tzsch, and Rudolph (2009) or Glimm and Kr\u00f6tzsch (2010). Since the Direct Semantics of OWL is defined in terms of OWL structural objects, i.", "startOffset": 153, "endOffset": 179}, {"referenceID": 17, "context": "For example, the description logic SROIQ, which underpins the OWL 2 DL standard, has a worst case complexity of 2-NExpTime (Kazakov, 2008) and typical implementations are not worst case optimal.", "startOffset": 123, "endOffset": 138}, {"referenceID": 4, "context": "We exploit this information similarly as was suggested for determining known or possible (non-)subsumers for concepts during classification (Glimm et al., 2012).", "startOffset": 140, "endOffset": 160}, {"referenceID": 25, "context": "The consequent application of the transitivity encoding (Motik et al., 2009) produces axioms that propagate C a to each individual b that is reachable from a via an r-chain.", "startOffset": 56, "endOffset": 76}, {"referenceID": 46, "context": "A concept C is considered primitive in O if O is unfoldable (Tsarkov et al., 2007) and it contains no axiom of the form C \u2261 E", "startOffset": 60, "endOffset": 82}, {"referenceID": 40, "context": "This is the case because Pellet and Racer have many optimizations for instance retrieval (Sirin et al., 2007; Haarslev & M\u00f6ller, 2008), which HermiT does not have.", "startOffset": 89, "endOffset": 134}, {"referenceID": 12, "context": "Racer Pro (Haarslev & M\u00f6ller, 2001) has a proprietary query language, called nRQL (Haarslev et al., 2004), which allows for queries that go beyond ABox queries, e.", "startOffset": 82, "endOffset": 105}, {"referenceID": 45, "context": "TrOWL (Thomas et al., 2013) is another system that supports SPARQL queries, but the reasoning in TrOWL is approximate, i.", "startOffset": 6, "endOffset": 27}], "year": 2013, "abstractText": "The SPARQL query language is currently being extended by the World Wide Web Consortium (W3C) with so-called entailment regimes. An entailment regime defines how queries are evaluated under more expressive semantics than SPARQL\u2019s standard simple entailment, which is based on subgraph matching. The queries are very expressive since variables can occur within complex concepts and can also bind to concept or role names. In this paper, we describe a sound and complete algorithm for the OWL Direct Semantics entailment regime. We further propose several novel optimizations such as strategies for determining a good query execution order, query rewriting techniques, and show how specialized OWL reasoning tasks and the concept and role hierarchy can be used to reduce the query execution time. For determining a good execution order, we propose a cost-based model, where the costs are based on information about the instances of concepts and roles that are extracted from a model abstraction built by an OWL reasoner. We present two ordering strategies: a static and a dynamic one. For the dynamic case, we improve the performance by exploiting an individual clustering approach that allows for computing the cost functions based on one individual sample from a cluster. We provide a prototypical implementation and evaluate the efficiency of the proposed optimizations. Our experimental study shows that the static ordering usually outperforms the dynamic one when accurate statistics are available. This changes, however, when the statistics are less accurate, e.g., due to nondeterministic reasoning decisions. For queries that go beyond conjunctive instance queries we observe an improvement of up to three orders of magnitude due to the proposed optimizations.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}