{"id": "1402.2561", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jan-2014", "title": "The CQC Algorithm: Cycling in Graphs to Semantically Enrich and Enhance a Bilingual Dictionary", "abstract": "phonetic paper - readable technologies are knowledge resources useful in many automatic tasks. however, compared to monolingual computational lexicons like wordnet, bilingual dictionaries typically provide the lower amount of structured information, such as lexical and semantic relations, and often don't cover the entire range of semantic translations for a word of interest. in this paper models present cycles for quasi - cycles ( cqc ), a novel algorithm for the automated disambiguation of ambiguous translations in the lexical entries of a bilingual machine - readable dictionary. the structure elements represented as a graph, and cyclic patterns easily repeated in the graph to assign an appropriate sense tag to each translation specific said lexical entry. further, we use the processing output to improve the output of the design itself, by suggesting accurate solutions to structural problems termed as misalignments, partial alignments and missing entries. finally, we successfully apply cqc to the task of synonym extraction.", "histories": [["v1", "Sat, 18 Jan 2014 21:08:40 GMT  (774kb)", "http://arxiv.org/abs/1402.2561v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["tiziano flati", "roberto navigli"], "accepted": false, "id": "1402.2561"}, "pdf": {"name": "1402.2561.pdf", "metadata": {"source": "CRF", "title": "The CQC Algorithm: Cycling in Graphs to Semantically Enrich and Enhance a Bilingual Dictionary", "authors": ["Tiziano Flati", "Roberto Navigli"], "emails": ["flati@di.uniroma1.it", "navigli@di.uniroma1.it"], "sections": [{"heading": null, "text": "matic tasks. However, compared to monolingual computational lexicons like WordNet, bilingual dictionaries typically provide a lower amount of structured information such as lexical and semantic relations, and often do not cover the entire range of possible translations for a word of interest. In this paper we present Cycles and Quasi-Cycles (CQC), a novel algorithm for the automated disambiguation of ambiguous translations in the lexical entries of a bilingual machine-readable dictionary. The dictionary is represented as a graph, and cyclic patterns are sought in this graph to assign an appropriate sense tag to each translation in a lexical entry. Further, we use the algorithm\u2019s output to improve the quality of the dictionary itself, by suggesting accurate solutions to structural problems such as misalignments, partial alignments and missing entries. Finally, we successfully apply CQC to the task of synonym extraction."}, {"heading": "1. Introduction", "text": "Lexical knowledge resources, such as thesauri, machine-readable dictionaries, computational lexicons and encyclopedias, have been enjoying increasing popularity over the last few years. Among such resources we cite Roget\u2019s Thesaurus (Roget, 1911), the Macquarie Thesaurus (Bernard, 1986), the Longman Dictionary of Contemporary English (Proctor, 1978, LDOCE), WordNet (Fellbaum, 1998) and Wikipedia. These knowledge resources have been utilized in many applications, including Word Sense Disambiguation (Yarowsky, 1992; Nastase & Szpakowicz, 2001; Mart\u00ednez, de Lacalle, & Agirre, 2008, cf. Navigli, 2009b, 2012 for a survey), semantic interpretation of text (Gabrilovich & Markovitch, 2009), Semantic Information Retrieval (Krovetz & Croft, 1992; Mandala, Tokunaga, & Tanaka, 1998; Sanderson, 2000), Question Answering (Lita, Hunt, & Nyberg, 2004; Moldovan & Novischi, 2002), Information Extraction (Jacquemin, Brun, & Roux, 2002), knowledge acquisition (Navigli & Ponzetto, 2010), text summarization (Silber & McCoy, 2003; Nastase, 2008), classification (Rosso, Molina, Pla, Jim\u00e9nez, & Vidal, 2004; Wang & Domeniconi, 2008; Navigli, Faralli, Soroa, de Lacalle, & Agirre, 2011) and even simplification (Woodsend & Lapata, 2011).\nMost of these applications exploit the structure provided by the adopted lexical resources in a number of different ways. For instance, lexical and semantic relations encoded in computational lexicons such as WordNet have been shown to be very useful in graph-based Word Sense Disambiguation (Mihalcea, 2005; Agirre & Soroa, 2009; Navigli & Lapata, 2010; Ponzetto & Navigli, 2010) and semantic similarity (Pedersen, Banerjee, & Patwardhan, 2005; Agirre, Alfonseca, Hall, Kravalova, Pasca, & Soroa, 2009). Interestingly, it has been\nc\u00a92012 AI Access Foundation. All rights reserved.\nreported that the higher the amount of structured knowledge, the higher the disambiguation performance (Navigli & Lapata, 2010; Cuadros & Rigau, 2006). Unfortunately, not all the semantics are made explicit within lexical resources. Even WordNet (Fellbaum, 1998), the most widely-used computational lexicon of English, provides explanatory information in the unstructured form of textual definitions, i.e., strings of text which explain the meaning of concepts using possibly ambiguous words (e.g., \u201cmotor vehicle with four wheels\u201d is provided as a definition of the most common sense of car). Still worse, while computational lexicons like WordNet contain semantically explicit information such as is-a and part-of relations, machine-readable dictionaries (MRDs) are often just electronic transcriptions of their paper counterparts. Thus, for each entry they mostly provide implicit information in the form of free text, which cannot be immediately utilized in Natural Language Processing applications.\nOver recent years various approaches to the disambiguation of monolingual dictionary definitions have been investigated (Harabagiu, Miller, & Moldovan, 1999; Litkowski, 2004; Castillo, Real, Asterias, & Rigau, 2004; Navigli & Velardi, 2005; Navigli, 2009a), and results have shown that they can, indeed, boost the performance of difficult tasks such as Word Sense Disambiguation (Cuadros & Rigau, 2008; Agirre & Soroa, 2009). However, little attention has been paid to the disambiguation of bilingual dictionaries, which would be capable of improving popular applications such as Machine Translation.\nIn this article we present a graph-based algorithm which aims at disambiguating translations in bilingual machine-readable dictionaries. Our method takes as input a bilingual MRD and transforms it into a graph whose nodes are word senses1 (e.g., car1n) and whose edges (s, s\u2032) mainly represent the potential relations between the source sense s of a word w (e.g., car1n) and the various senses s\u2032 of its translations (e.g., macchina3n). Next, we introduce a novel notion of cyclic and quasi-cyclic graph paths that we use to select the most appropriate sense for a translation w\u2032 of a source word w.\nThe contributions of this paper are threefold: first, we present a novel graph-based algorithm for the disambiguation of bilingual dictionaries; second, we exploit the disambiguation results in a way which should help lexicographers make considerable improvements to the dictionary and address issues or mistakes of various kinds; third, we use our algorithm to automatically identify synonyms aligned across languages.\nThe paper is organized as follows: in Section 2 we introduce the reader to the main ideas behind our algorithm, also with the help of a walk-through example. In Section 3 we provide preliminary definitions needed to introduce our disambiguation algorithm. In Section 4 we present the Cycles and Quasi-Cycles (CQC) algorithm for the disambiguation of bilingual dictionaries. In Section 5 we assess its disambiguation performance on dictionary translations. In Section 6, we show how to enhance the dictionary semi-automatically by means of CQC, and provide experimental evidence in Section 7. In Section 8 we describe an application to monolingual and bilingual synonym extraction and then in Section 9 describe experiments. Related work is presented in Section 10. We give our conclusions in Section 11.\n1. We denote with wip the i-th sense of a word w with part of speech p in a reference sense inventory (we use n for nouns, v for verbs, a for adjectives and r for adverbs), where senses can simply be denoted by integers (like 1, 2, 3, etc.), but also by letters and numbers (such as A.1, B.4, D.3) indicating different levels of granularity (homonymy, polysemy, etc.)."}, {"heading": "2. A Brief Overview", "text": "In this section we provide a brief overview of our approach to the disambiguation of bilingual dictionary entries."}, {"heading": "2.1 Goal", "text": "The general form of a bilingual dictionary entry is:\nwip \u2192 v1, v2, . . . , vk\nwhere:\n\u2022 wip is the i-th sense of the word w with part of speech p in the source language (e.g., play2v is the second sense of the verb play);\n\u2022 each vj is a translation in the target language for sense wip (e.g., suonarev is a translation for play2v). Note that each vj is implicitly assumed to have the same part of speech p as wp. Importantly, no sense is explicitly associated with vj .\nOur objective is to associate each target word vj with one of its senses so that the concepts expressed by wp and vj match. We aim to do this in a systematic and automatic way. First of all, starting from a bilingual dictionary (see Section 3.1), we build a \u201cnoisy\u201d graph associated with the dictionary (see Section 3.2), whose nodes are word senses and edges are (mainly) translation relations between word senses. These translation relations are obtained by linking a source word sense (wip above) to all the senses of a target word vj . Next, we define a novel notion of graph patterns, which we have called Cycles and Quasi-Cycles (CQC), that we use as a support for predicting the most suitable sense for each translation vj of a source word sense wip (see Section 3.3)."}, {"heading": "2.2 A Walk-Through Example", "text": "We now present a walk-through example to give further insights into the main goal of the present work. Consider the following Italian-English dictionary entries:\ngiocareA.1v \u2192 play, toy recitareA.2v \u2192 act, play suonareA.1v \u2192 sound, ring, play suonareB.4v \u2192 ring, echo\ninterpretare4v \u2192 play, act\nand the following English-Italian entries:\nplay1v \u2192 giocare play2v \u2192 suonare, riprodurre play3v \u2192 interpretare, recitare\nOur aim is to sense tag the target terms on the right-hand side, i.e., we would like to obtain the following output:\ngiocareA.1v \u2192 play1v, toy1v recitareA.2v \u2192 actA.1v , play3v suonareA.1v \u2192 sound1.A.1v , ring2.A.2v , play2v suonareB.4v \u2192 ring2.A.4v , echoA.1v\ninterpretare4v \u2192 play3v, actA.1v\nplay1v \u2192 giocareA.1v play2v \u2192 suonareA.2v , riprodurre1v play3v \u2192 interpretare3v, recitareA.2v\nwhere the numbers beside each right-hand translation correspond to the most suitable senses in the dictionary for that translation (e.g., the first sense of playv corresponds to the sense of playing a game). For instance, in order to disambiguate the first entry above (i.e., giocareA.1v \u2192 play, toy), we have to determine the best sense of the English verb play given the Italian verb sense giocareA.1v . We humans know that since the source sense is about \u201cplaying a game\u201d, the right sense for playv is the first one. In fact, among the 3 senses of the verb playv shown above, we can see that the first sense is the only one which translates back into giocare. In other words, the first sense of playv is the only one which is contained in a path starting from, and ending in, giocareA.1v , namely:\ngiocareA.1v \u2192 play1v \u2192 giocareA.1v\nwhile there are no similar paths involving the other senses of playv. Our hunch is that by exploiting cyclic paths we are able to predict the most suitable sense of an ambiguous translation. We provide a scoring function which weights paths according to their length (with shorter paths providing better clues, and thus receiving higher weights) and, at the same time, favours senses which participate in most paths. We will also study the effect of edge reversal as a further support for disambiguating translations. Our hunch here is that by allowing the reversal of subsequent edges we enable previously-missed meaningful paths, which we call quasi-cycles (e.g., recitareA.2v \u2192 play3v \u2192 interpretare3v \u2192 actA.1v \u2190 recitareA.2v ). We anticipate that including quasi-cycles significantly boosts the overall disambiguation performance."}, {"heading": "3. Preliminaries", "text": "We now provide some fundamental definitions which will be used throughout the rest of the paper."}, {"heading": "3.1 Bilingual Dictionary", "text": "We define a bilingual machine-readable dictionary (BiMRD) as a quadruple D = (L, Senses, T ,M), where L is the bilingual lexicon (i.e., L includes all the lexical items for both languages), Senses is a mapping such that, given a lexical item w \u2208 L, returns the set\nof senses for w in D, T is a translation function which, given a word sense s \u2208 Senses(w), provides a set of (possibly ambiguous) translations for s. Typically, T (s) \u2282 L, that is, the translations are in the lexicon. However, it might well be that some translations in T (s) are not in the lexicon. Finally, M is a function which, given a word sense s \u2208 Senses(w), provides the set of all words representing meta-information for sense s (e.g.,M(phoneme1n) = {linguistics}).\nFor instance, consider the Ragazzini-Biagi English-Italian BiMRD (Ragazzini & Biagi, 2006). The dictionary provides Italian translations for each English word sense, and vice versa. For a given source lemma (e.g., languagen in English), the dictionary lists its translations in the target language for each sense expressed by the lemma. Figure 1 shows the dictionary entry of languagen. The dictionary provides:\n\u2022 a lexicon for the two languages, i.e., the set L of lemmas for which dictionary entries exist (such as languagen in Figure 1, but also linguan, linguaggion, etc.);\n\u2022 the set of senses of a given lemma, e.g., Senses(languagen) = {language1n, language2n} (the communication sense vs. the speaking ability), Senses(linguan) = {lingua1n, lingua2n} (the muscular organ and a set of words used for communication, respectively); Senses(linguaggion) = {linguaggio1n, linguaggio2n, linguaggio3n} (the faculty of speaking, the means of communication and machine language, respectively);\n\u2022 the translations for a given sense, e.g., T (language1n) = {linguan, linguaggion};\n\u2022 optionally, some meta-information about a given sense, such asM(phoneme1n) = {linguistics}.\nThe dictionary also provides usage examples and compound translations (see Figure 1), lexical variants (e.g., acknowledgement vs. acknowledgment) and references to other entries (e.g., from motorcar to car)."}, {"heading": "3.2 Noisy Graph", "text": "Given a BiMRD D, we define a noisy dictionary graph G = (V,E) as a directed graph where:\n1. V is the set of senses in the dictionary D (i.e., V = \u22c3 w\u2208L Senses(w));\n2. For each word w \u2208 L and a sense s \u2208 Senses(w), an edge (s, s\u2032) is in E if and only if s\u2032 is a sense of a translation of s in the dictionary (i.e., s\u2032 \u2208 Senses(w\u2032) and w\u2032 \u2208 T (s)), or s\u2032 is a sense of a meta-word m in the definition of s (i.e., if s\u2032 \u2208 Senses(m) for some m \u2208M(s)).\nAccording to the above definition, given an ambiguous word w\u2032 in the definition of s, we add an edge from s to each sense of w\u2032 in the dictionary. In other words, the noisy graph G associated with dictionary D encodes all the potential meanings for word translations in terms of edge connections. In Figure 2 we show an excerpt of the noisy graph associated with the Ragazzini-Biagi dictionary. In this sub-graph three kinds of nodes can be found:\n\u2022 the source sense (rectangular box), namely language1n.\n\u2022 the senses of its translations (thick ellipse-shaped nodes), e.g., the three senses of linguaggion and the two senses of linguan.\n\u2022 other senses (ellipse-shaped nodes), which are either translations or meta-information for other senses (e.g., speech1n is a translation sense of eloquio1n)."}, {"heading": "3.3 Graph Cycles and Quasi-Cycles", "text": "We now recall the definition of graph cycle. A cycle for a graph G is a sequence of edges of G that form a path v1 \u2192 v2 \u2192 \u00b7 \u00b7 \u00b7 \u2192 vn (vi \u2208 V \u2200i \u2208 {1, . . . , n}) such that the first node\nof the path corresponds to the last, i.e., v1 = vn (Cormen, Leiserson, & Rivest, 1990, p. 88). The length of a cycle is given by the number of its edges. For example, a cycle of length 3 in Figure 2 is given by the path:\nlanguage1n \u2192 linguaggio2n \u2192 lingua2n \u2192 language1n.\nWe further provide the definition of quasi-cycle as a sequence of edges in which the reversal of the orientation of one or more consecutive edges creates a cycle (Bohman & Thoma, 2000). For instance, a quasi-cycle of length 4 in Figure 2 is given by the path:\nlanguage1n \u2192 linguaggio1n \u2192 speech1n \u2190 eloquio1n \u2192 language1n.\nIt can be seen that the reversal of the edge (eloquio1n, speech1n) creates a cycle. Since the direction of this edge is opposite to that of the cycle, we call it a reversed edge. Finally, we say that a path is (quasi-)cyclic if it forms a (quasi-)cycle. Note that we do not consider paths going across senses of the same word; so language1n \u2192 lingua1n \u2192 tongue1n \u2190 lingua2n \u2192 language1n is not considered a legal quasi-cycle.\nIn order to provide a graphical representation of (quasi-)cycles, in Figure 3 we show different kinds of (quasi-)cycles starting from a given node s, namely: a cycle (a), a quasicycle with 1 terminal (b) and non-terminal (c) reversed edge (a reversed edge is terminal if it is incident from s), with more reversed edges ((d) and (e)), and an illegal quasi-cycle whose reversed edges are not consecutive (f)."}, {"heading": "4. The CQC Algorithm", "text": "We are now ready to introduce the Cycles & Quasi-Cycles (CQC) algorithm, whose pseudocode is given in Table 1. The algorithm takes as input a BiMRD D = (L, Senses, T ,M),\nand a sense s of a word w in its lexicon (i.e., w \u2208 L and s \u2208 Senses(w)). The algorithm aims at disambiguating each of the word\u2019s ambiguous translations w\u2032 \u2208 T (s), i.e., to assign it the right sense among those listed in Senses(w\u2032).\nThe algorithm outputs a mapping \u00b5 between each ambiguous word w\u2032 \u2208 T (s) and the sense s\u2032 of w\u2032 chosen as a result of the disambiguation procedure that we illustrate hereafter.\nFirst, for each sense s\u2032 of our target translation w\u2032 \u2208 T (s), the algorithm performs a search of the noisy graph associated with D and collects the following kinds of paths:\ni) Cycles:\ns\u2192 s\u2032 \u2192 s1 \u2192 \u00b7 \u00b7 \u00b7 \u2192 sn\u22122 \u2192 sn\u22121 = s\nii) Quasi-cycles:\ns\u2192 s\u2032 \u2192 s1 \u2192 ...\u2192 sj \u2190 ...\u2190 sk \u2192 ...\u2192 sn\u22122 \u2192 sn\u22121 = s 1 \u2264 j \u2264 n\u22122, j < k \u2264 n\u22121 (1)\nwhere s is our source sense, s\u2032 is our candidate sense for w\u2032 \u2208 T (s), si is a sense listed in D (i \u2208 {1, . . . , n \u2212 2}), sn\u22121 = s, and n is the length of the path. Note that both kinds of path start and end with the same node s, and that the algorithm searches for quasi-cycles whose reversed edges connecting sk to sj are consecutive. To avoid redundancy we require (quasi-)cycles to be simple, that is, no node is repeated in the path except the start/end node (i.e., si 6= s, si 6= s\u2032, si 6= si\u2032 \u2200i, i\u2032 s. t. i 6= i\u2032).\nDuring the first step of the algorithm (see Table 1, lines 2-3), (quasi-)cyclic paths are sought for each sense of w\u2032. This step is performed with a depth-first search (DFS, cf. Cormen et al., 1990, pp. 477\u2013479) up to a depth \u03b4.2 The DFS \u2013 whose pseudocode is\n2. We note that a depth-first search is equivalent to a breadth-first search (BFS) for the purpose of collecting paths.\nshown in Table 2 \u2013 starts from a sense s\u2032 \u2208 Senses(w\u2032), and recursively explores the graph; outgoing edges are explored in order to collect cycles (lines 7-9 of Rec-DFS, see Table 2) while incoming edges are considered in order to collect quasi-cycles (lines 11-14); before extending the current path p with a reversed edge, however, it is necessary to check whether the latter is consecutive to all previously reversed edges (if any) present in p and to skip it otherwise (cf. Formula (1)). The stack visited contains the nodes visited so far, in order to avoid the repetition of a node in a path (cf. lines 1, 5 and 15 of Rec-DFS). Finally the search ends when the maximum path length is reached, or a previously visited node is encountered (line 1 of Rec-DFS); otherwise, if the initial sense s is found, a (quasi-)cycle is collected (lines 2-4 of Rec-DFS). For each sense s\u2032 of w\u2032 the DFS returns the full set paths(s\u2032) of paths collected. Finally, in line 4 of Table 1, all_paths is set to store the paths for all the senses of w\u2032.\nThe second phase of the CQC algorithm (lines 5-10 of Table 1) computes a score for each sense s\u2032 of w\u2032 based on the paths collected for s\u2032 during the first phase. Let p be such a path, and let l be its length, i.e., the number of edges in the path. Then the contribution of p to the score of s\u2032 is given by:\nscore(p) := \u03c9(l)\nNumPaths(all_paths, l) (2)\nwhere:\n\u2022 \u03c9(l) is a monotonically non-increasing function of its length l; in our experiments, we tested three different weight functions \u03c9(l), namely a constant, a linear and an inversely exponential function (see Section 5).\n\u2022 the normalization factor NumPaths(all_paths, l) calculates the overall number of collected paths of length l among all the target senses.\nIn this way the score of a sense s\u2032 amounts to:\nscore(s\u2032) := \u2211\np\u2208paths(s\u2032)\nscore(p) = \u03b4\u2211 l=2 \u03c9(l) NumPaths(paths(s\u2032), l) NumPaths(all_paths, l) (3)\nThe rationale behind our scoring formula is two-fold: first \u2013 thanks to function \u03c9 \u2013 it favours shorter paths, which are intuitively less likely to be noisy; second, for each path length, it accounts for the ratio of paths of that length in which s\u2032 participates (second factor of the right-hand side of the formula above).\nAfter the scores for each sense s\u2032 of the target translation w\u2032 have been calculated, a mapping is established between w\u2032 and the highest-scoring sense (line 11). Finally, after all the translations have been disambiguated, the mapping is returned (line 12).\nAs a result of the systematic application of the algorithm to each sense in our BiMRD D, a new graph G\u2032 = (V,E\u2032) is output, where V is again the sense inventory of D, and E\u2032 is a subset of the noisy edge set E such that each edge (s, s\u2032) \u2208 E\u2032 is the result of our disambiguation algorithm run with input D and s. Figure 4 shows the \u201cclean\u201d, unambiguous dictionary graph after executing CQC, as compared to the initial noisy graph from Figure 2. In this pruned graph, each sense links to only one sense of each of its translations."}, {"heading": "4.1 An Example", "text": "As an example, consider the following dictionary entry in the Ragazzini-Biagi dictionary:\nlanguage n. 1 lingua; linguaggio.\nIn order to disambiguate the Italian translations we call the CQC algorithm as follows: CQC(D, language1n). Let us first concentrate on the disambiguation of linguan, an ambiguous word with two senses in the Ragazzini-Biagi. First, two calls are made, namely DFS(lingua1n, language 1 n) and DFS(lingua2n, language1n). Each function call performs a DFS starting from the respective sense of our target word to collect all relevant cycles and quasi-cycles according to the algorithm in Table 2. The set of cycles and quasi-cycles collected for the two senses from the noisy graph of Figure 2 are shown in Figure 5.\nDuring the second phase of the CQC algorithm, and for each sense of linguan, the contribution of each path is calculated (lines 8-10 of the algorithm in Table 1). Specifically, the following scores are calculated for the two senses of linguan (we assume our weight function \u03c9(l) = 1/el):\nscore(lingua1n) = 2 \u00b7 1e4 \u00b7 1 NumPaths(all_paths,4) ' 2 \u00b7 0.018 \u00b7 1 4 = 0.009\nscore(lingua2n) = 1 \u00b7 1e2 \u00b7 1 NumPaths(all_paths,2) + + 3 \u00b7 1\ne3 \u00b7 1NumPaths(all_paths,3) +\n+ 2 \u00b7 1 e4 \u00b7 1NumPaths(all_paths,4) ' ' 1 \u00b7 0.135 \u00b7 11 + 3 \u00b7 0.050 \u00b7 1 3 + 2 \u00b7 0.018 \u00b7 1 4 = 0.194\nwhere NumPaths(all_paths, l) is the total number of paths of length l collected over all the senses of linguan. Finally, the sense with the highest score (i.e., lingua2n in our example) is returned.\nSimilarly, we determine the scores of the various senses of linguaggion as follows:\nscore(linguaggio1n) = 2 \u00b7 1e4 \u00b7 1 NumPaths(all_paths,4) ' 2 \u00b7 0.018 \u00b7 1 4 = 0.009.\nscore(linguaggio2n) = 1 \u00b7 1e2 \u00b7 1 NumPaths(all_paths,2) + + 2 \u00b7 1\ne3 \u00b7 1NumPaths(all_paths,3) +\n+ 2 \u00b7 1 e4 \u00b7 1NumPaths(all_paths,4) ' ' 1 \u00b7 0.135 \u00b7 12 + 2 \u00b7 0.050 \u00b7 1 2 + 2 \u00b7 0.018 \u00b7 1 4 = 0.1265.\nscore(linguaggio3n) = 1 \u00b7 1e2 \u00b7 1 NumPaths(all_paths,2) ' 1 \u00b7 0.135 \u00b7 1 2 = 0.0675.\nAs a result, sense 2 is correctly selected."}, {"heading": "5. Evaluation: Dictionary Disambiguation", "text": "In our first set of experiments we aim to assess the disambiguation quality of the CQC algorithm and compare it with existing disambiguation approaches. We first describe our experimental setup in Section 5.1, by introducing the bilingual dictionary used throughout this article, and providing information on the dictionary graph, our tuning and test datasets, and the algorithms, parameters and baselines used in our experiments. We describe our experimental results in Section 5.2."}, {"heading": "5.1 Experimental Setup", "text": "In this section we discuss the experimental setup for our dictionary disambiguation experiment."}, {"heading": "5.1.1 Dictionary", "text": "We performed our dictionary disambiguation experiments on the Ragazzini-Biagi (Ragazzini & Biagi, 2006), a popular bilingual English-Italian dictionary, which contains over 90,000 lemmas and 150,000 word senses."}, {"heading": "5.1.2 Dictionary Graph", "text": "In order to get an idea of the difficulty of our dictionary disambiguation task we determined the ratio of wrong edges in the graph. To do this we first calculated the ratio of correct edges, i.e., those edges which link source senses to their right translation senses. This quantity can be estimated as the overall number of translations in the dictionary (i.e., assuming each translation has an appropriate sense in the dictionary) divided by the total number of edges:\nCorrectnessRatio(G) =\n\u2211 s\u2208V |T (s)|\n|E| (4)\nThe ratio of wrong edges is then calculated as 1 \u2212 CorrectnessRatio(G), obtaining an estimate of 66.4% of incorrect edges in the noisy graph of the Ragazzini-Biagi dictionary."}, {"heading": "5.1.3 Dataset", "text": "Our datasets for tuning and test consist of dictionary entries, each containing translations of a source sense into a target language. Each translation item was manually disambiguated according to its sense inventory in the bilingual dictionary. For example, given the Italian entry brillanteA.2a , translated as \u201csparklinga, vivaciousa\u201d, we associated the appropriate English sense from the English-Italian section to sparklinga and vivaciousa (senses 3 and 1, respectively).\nFor tuning purposes, we created a dataset of 50 entries, totaling 80 translations. We also prepared a test dataset of 500 entries, randomly sampled from the Ragazzini-Biagi dictionary (250 from the English-Italian section, 250 from the Italian-English section). Overall, the test dataset included 1,069 translations to be disambiguated. We report statistics for the two datasets in Table 3, including the number of polysemous translations and the average polysemy of each translation. We note that for 44 of the translations in the test set (i.e., 4.1% of the total) none of the senses listed in the dictionary is appropriate (including monosemous translations). A successful disambiguation system, therefore, should not disambiguate these items. The last column in the table shows the number of translations for which a sense exists that translates back to the source lemma (e.g., car1n translates to macchina and macchina3n translates to car)."}, {"heading": "5.1.4 Algorithms", "text": "We compared the following algorithms in our experimental framework3, since (with the exception of CQC and variants thereof) they represent the most widespread graph-based approaches and are used in many NLP tasks with state-of-the-art performance:\n\u2022 CQC: we applied the CQC algorithm as described in Section 4;\n\u2022 Cycles, a variant of the CQC algorithm which searches for cycles only (i.e., quasicycles are not collected);\n\u2022 DFS, which applies an ordinary DFS algorithm and collects all paths between s and s\u2032 (i.e., paths are not \u201cclosed\u201d by completing them with edge sequences connecting s\u2032\nto s). In this setting the path s\u2192 s\u2032 is discarded, as by construction it can be found in G for each sense s\u2032 \u2208 Senses(w\u2032);\n\u2022 Random walks, which performs a large number of random walks starting from s\u2032 and collecting those paths that lead to s. This approach has been successfully used to approximate an exhaustive search of translation circuits (Mausam, Soderland, Etzioni,\n3. In order to ensure a level playing field, we provided in-house implementations for all the algorithms within our graph-based framework, except for Personalized PageRank, for which we used a standard implementation (http://jung.sourceforge.net).\nWeld, Skinner, & Bilmes, 2009; Mausam, Soderland, Etzioni, Weld, Reiter, Skinner, Sammer, & Bilmes, 2010). We note that, by virtue of its simulation nature, this method merely serves as a way of collecting paths at random. In fact, given a path ending in a node v, the next edge is chosen equiprobably among all edges outgoing from v.\n\u2022 Markov chains, which calculates the probability of arriving at a certain source sense s starting from the initial translation sense s\u2032 averaged over n consecutive steps, that is, ps\u2032,s = 1 n \u2211n m=1 p (m) s\u2032,s , where p (m) s\u2032,s is the probability of arriving at node s using exactly\nm steps starting from node s\u2032. The initial Markov chain is initialized from the noisy dictionary graph as follows: for each v, v\u2032 \u2208 V , if (v, v\u2032) \u2208 E, then p(0)v,v\u2032 = 1/out(v), where out(v) is the outdegree of v in the noisy graph, otherwise p(0)v,v\u2032 = 0.\n\u2022 Personalized PageRank (PPR): a popular variant of the PageRank algorithm (Brin & Page, 1998) where the original Markov chain approach to node ranking is modified by perturbating the initial probability distribution on nodes (Haveliwala, 2002, 2003). PPR has been successfully applied to Word Sense Disambiguation (Agirre & Soroa, 2009) and thus represents a very competitive system to compare with. In order to disambiguate a target translation w\u2032 of a source word w, for each translation sense s\u2032, we concentrate all the probability mass on s\u2032, and apply PPR. We select the best translation sense as the one which maximizes the PPR value of the source word (or, equivalently, that of the translation sense itself).\n\u2022 Lesk algorithm (Lesk, 1986): we apply an adaptation of the Lesk algorithm in which, given a source sense s of word w and a word w\u2032 occurring as a translation of s, we determine the right sense of w\u2032 on the basis of the (normalized) maximum overlap between the entries of each sense s\u2032 of w\u2032 and that of s:\nargmax s\u2032\u2208Senses(w\u2032) |next\u2217(s) \u2229 next\u2217(s\u2032)| max{|next\u2217(s)|, |next\u2217(s\u2032)|} ,\nwhere we define next\u2217(s) = synonyms(s)\u222anext(s), synonyms(s) is the set of lexicalizations of sense s (i.e., the synonyms of sense s, e.g., acknowledgement vs acknowledgment) and next(s) is the set of nodes s\u2032 connected through an edge (s, s\u2032).\nFor all the algorithms that explicitly collect paths (CQC, Cycles, DFS and Random walks), we tried three different functions for weighting paths, namely:\n\u2022 A constant function \u03c9(l) = 1 that weights all paths equally, independently of their length l;\n\u2022 A linear function \u03c9(l) = 1/l that assigns each path a score inversely proportional to its length l;\n\u2022 An exponential function \u03c9(l) = 1/el that assigns a score that decreases exponentially with the path length."}, {"heading": "5.1.5 Parameters", "text": "We used the tuning dataset to fix the parameters of each algorithm that maximized the performance. We tuned the maximum path length for each of the path-based algorithms (CQC, Cycles, DFS, Random walks and Markov chains), by trying all lengths in {1, . . . , 6}. Additionally, for CQC, we tuned the minimum and maximum values for the parameters j and k used for quasi-cyclic patterns (cf. Formula 1 in Section 4). These parameters determine the position and the number of reversed edges in a quasi-cyclic graph pattern. The best results were obtained when n\u22121 \u2264 k \u2264 n\u22121, i.e. k = n\u22121, and n\u22123 \u2264 j < n\u22121, that is, CQC yielded the best performance when up to 2 terminal reversed edges were sought (cf. Section 3.3 and Figure 3). For Random walks, we tuned the number of walks needed to disambiguate each item (ranging between 50 and 2,000). The best parameters resulting from tuning are reported in Table 4. Finally, for PPR we used standard parameters: we performed 30 iterations and set the damping factor to 0.85."}, {"heading": "5.1.6 Measures", "text": "To assess the performance of our algorithms, we calculated precision (the number of correct answers over the number of items disambiguated by the system), recall (the number of correct answers over the number of items in the dataset), and F1 (a harmonic mean of precision and recall, given by 2PRP+R). Note that precision and recall do not consider those items in the test set for which no appropriate sense is available in the dictionary. In order to account for these items, we also calculated accuracy as the number of correct answers divided by the total number of items in the test set."}, {"heading": "5.1.7 Baselines", "text": "We compared the performance of our algorithms with three baselines:\n\u2022 the First Sense (FS) Baseline, that associates the first sense listed by the dictionary with each translation to be disambiguated (e.g., car1n is chosen for car independently of the disambiguation context). The rationale behind this baseline derives from the tendency of lexicographers to sort senses according to the importance they perceive or estimate from a (possibly sense-tagged) corpus;\n\u2022 the Random Baseline, which selects a random sense for each target translation;\n\u2022 the Degree Baseline, that chooses the translation sense with the highest out-degree, i.e., the highest number of outgoing edges."}, {"heading": "5.2 Results", "text": "We are now ready to present the results of our dictionary disambiguation experiment."}, {"heading": "5.2.1 Results without Backoff Strategy", "text": "In Table 5 we report the results of our algorithms on the test set. CQC, PPR and Cycles are the best performing algorithms, achieving around 83%, 81% and 75% accuracy respectively. CQC outperforms all other systems in terms of F1 by a large margin. The results show that the mere use of cyclic patterns does not lead to state-of-the-art performance, which is, instead, obtained when quasi-cycles are also considered. Including quasi-cycles leads to a considerable increase in recall, while at the same time maintaining a high level of precision. The DFS is even more penalizing because it does not get backward support as happens for cycling patterns. Markov chains consistently outperform Random walks. We hypothesize that this is due to the higher coverage of Markov chains compared to the number of random walks collected by a simulated approach. PPR considerably outperforms the two other probabilistic approaches (especially in terms of recall and accuracy), but lags behind CQC by 3 points in F1 and 2 in accuracy. This result confirms previous findings in the literature concerning the high performance of PPR, but also corroborates our hunch about quasi-cycles being the determining factor in the detection of hard-to-find semantic connections within dictionaries. Finally, Lesk achieves high precision, but low recall and accuracy, due to the lack of a lookahead mechanism.\nThe choice of the weighting function impacts the performance of all path-based algorithms, with 1/el performing best and the constant function 1 resulting in the worst results (this is not the case for the DFS, though).\nThe random baseline represents our lowerbound and is much lower than all other results. Compared to the first sense baseline, CQC, PPR and Cycles obtain better performance. This result is consistent with previous findings for tasks such as the Senseval-3 Gloss Word Sense Disambiguation (Litkowski, 2004). However, at the same time, it is in contrast with results on all-words Word Sense Disambiguation (Navigli, 2009b), where the first or most frequent sense baseline generally outperforms most disambiguation systems. Nevertheless, the nature of these two tasks is very different, because \u2013 in dictionary entries \u2013 senses tend to be equally distributed, whereas in open text they have a single predominant meaning that is determined by context. As for the Degree Baseline, it yields results below expectations, and far worse than the FS baseline. The reason behind this lies in the fact that the amount of translations and translation senses does not necessarily correlate with mainstream meanings.\nWhile attaining the highest precision, CQC also outperforms the other algorithms in terms of accuracy. However, accuracy is lower than F1: this is due to F1 being a harmonic mean of precision and recall, while in calculating accuracy each and every item in the dataset is taken into account, even those items for which no appropriate sense tag can be given.\nIn order to verify the reliability of our tuning phase (see Section 5.1), we studied the F1 performance of CQC by varying the depth \u03b4 of the DFS (cf. Section 4). The best results \u2013 shown in Table 6 \u2013 are obtained on the test set when \u03b4 = 4, which confirms this as the\noptimal parameter choice for CQC (cf. Table 4). In fact, F1 increases with higher values of \u03b4, up to a performance peak of 85.19% obtained when \u03b4 = 4. With higher values of \u03b4 we observed a performance decay due to the noise introduced. The optimal value of \u03b4 is in line with previous experimental results on the impact of the DFS depth in Word Sense Disambiguation (Navigli & Lapata, 2010)."}, {"heading": "5.2.2 Results with Backoff Strategy", "text": "As mentioned above, the experimented path-based approaches are allowed not to return any result; this is the case when no paths can be found for any sense of the target word. In a second set of experiments we thus let the algorithms use the first sense baseline as a backoff strategy whenever they were not able to give any result for a target word. This is especially useful when the disambiguation system cannot make any decision because of lack of knowledge in the dictionary graph. As can be seen in Table 7, the scenario changes\nradically in this setting. The adoption of the first sense backoff strategy results in generally higher performance; notwithstanding this CQC keeps showing the best results, achieving almost 87% F1 and accuracy when \u03c9 = 1/el."}, {"heading": "5.2.3 Directed vs. Undirected Setting", "text": "Our algorithm crucially takes advantage of the quasi-cyclic pattern and therefore relies heavily on the directionality of edges. Thus, in order to further verify the beneficial impact of quasi-cycles, we also compared our approach in an undirected setting, i.e., using a noisy graph whose edges are unordered pairs. This setting is similar to that of de Melo and Weikum (2010), who aim at detecting imprecise or wrong interlanguage links in Wikipedia. However, in their task only few edges are wrong (in fact, they remove less than 2% of the cross-lingual interlanguage links), whereas our dictionary graph contains much more noise, which we estimated to involve around 66% of the edges (see Section 5.1.2).\nTo test whether directionality really matters, we compared CQC with its natural undirected counterpart, namely Undirected Cycles: this algorithm collects all (undirected) cycles linking each target sense back to the source sense in the underlying undirected noisy graph. We did not implement the DFS in the undirected setting because it is equivalent to the Undirected Cycles; neither did we implement the undirected versions of Random Walks,\nMarkov Chains and PPR, because they are broadly equivalent to Degree in an undirected setting (Upstill, Craswell, & Hawking, 2003). As shown in Table 8, Undirected Cycles yields a 66% F1 performance and 71% accuracy (almost regardless of the \u03c9 function). Consistently with our previous experiments, allowing the algorithm to resort to the FS Baseline as backoff strategy boosts performance up to 77-78% (with \u03c9 = 1/el producing the best results, see Table 9). Nonetheless, Undirected Cycles performs significantly worse than Cycles and CQC.\nThe reason for this behaviour lies in the strong disambiguation evidence provided by the directed flow of information. In fact, not accounting for directionality leads to a considerable loss of information, since we would be treating two different scenarios in the same way: one in which s\u2192 t and another one in which s t.\nFor example, in the directed setting two senses s and t which reciprocally link to one another (s t) create a cycle of length 2 (s \u2192 t \u2192 s); in an undirected setting, instead, the two edges are merged (s \u2212 t) and no supporting cycles of length 2 can be found. As a result we are not considering the fact that t translates back to s, which is a precious piece of information! Furthermore an undirected cycle is likely to correspond to a noisy, illegal quasi-cycle (cf. Figure 3(f)), i.e., one which could contain any sequence whatsoever of plain and reversed edges. Consequently, in the undirected setting meaningful and nonsensical paths are lumped together."}, {"heading": "6. Dictionary Enhancement", "text": "We now present an application of the CQC algorithm to the problem of enhancing the quality of a bilingual dictionary."}, {"heading": "6.1 Ranking Translation Senses", "text": "As explained in Section 4, the application of the CQC algorithm to a sense entry determines, together with a sense choice, a ranking for the senses chosen for its translations. For instance, the most appropriate senses for the translations of language (cf. Section 4.1) are chosen on the basis of the following scores: 0.009 (lingua1n), 0.194 (lingua2n), 0.009 (linguaggio1n), 0.1265 (linguaggio2n), 0.0675 (linguaggio3n). The higher the score for the target translation, the higher the confidence in selecting the corresponding sense. In fact, a high score is a clear hint of a high amount of connectivity conveyed from the target translation back to the source sense. As a result, the following senses are chosen in our example: lingua2n, linguaggio2n. Our hunch is that this confidence information can prove to be useful not only in disambiguating dictionary translations, but also in identifying recurring problems dictionaries tend to suffer from.\nFor instance, assume an English word w translates to an Italian word w\u2032 but no sense entry of w\u2032 in the bilingual dictionary translates back to w. An example where such a shortcoming could be fixed is the following: wood2n \u2192 bosco but no sense of bosco translates back into wood (here wood2n and bosco refer to the forest sense). However, this phenomenon does not always need to be solved. This might be the case if w is a relevant (e.g., popular) translation for w\u2032, but w\u2032 is not a frequent term. For instance, idioma1n (idiomn in english) translates to language and no sense of language has idioma as its translation. This is correct because we do not expect language to translate into such an uncommon word as idioma.\nBut how can we decide whether a problem of this kind needs to be fixed (like bosco) or not (like idioma)? To answer this question we will exploit the confidence scores output by the CQC algorithm. In fact, applying the CQC algorithm to the pair wood2n, bosco1n we obtain a score of 0.2 (indicating that bosco1n should point back to wood)4, while on the pair idioma1n, language1n we get a score of 0.07 (pointing out that idioma1n is not at easy reach from language1n)."}, {"heading": "6.2 Patterns for Enhancing a Bilingual Dictionary", "text": "In this section, we propose a methodology to enhance the bilingual dictionary using the sense rankings provided by the CQC algorithm. In order to solve relevant problems raised by the Zanichelli lexicographers on the basis of their professional experience, we identified the following 6 issues, each characterized by a specific graph pattern:\n\u2022 Misalignment. The first pattern is of the kind sw \u2192 sw\u2032 6\u2192 sw, where sw is a sense of w in the source language, sw\u2032 is a sense of w\u2032 in the target language, and\u2192 denotes a translation in the dictionary. For instance, buy1n is translated as compera1n, but compera1n is not translated as buy1n. A high-ranking sense such as compera1n implies that this issue should be solved.\n\u2022 Partial alignment. This pattern is of the kind sw \u2192 sw\u2032 \u2192 sw\u2032\u2032w or sw\u2032\u2032w \u2192 sw\u2032 \u2192 sw where sw and sw\u2032\u2032w are senses in the source language, w\u2032\u2032w is a compound that ends with w, and sw\u2032 is a sense in the target language. For instance, repellent1n is translated as insettifugo1n, which in turn translates to insect repellent1n.\n4. Note that in practice values greater than 0.3 are very unlikely.\n\u2022 Missing lemma. This pattern is of the kind sw \u2192 sw\u2032 where sw\u2032 does not exist in the dictionary. For example, persistente1a is translated as persistenta, however the latter lemma does not exist in the dictionary lexicon.\n\u2022 Use of reference. This pattern is of the kind sw \u2192 sw\u2032 \u2192 sw\u2032\u2032 \u2192 sw where sw\u2032 is a reference to sw\u2032\u2032 . For example, pass3n is translated as tesserino1n, while the latter refers to tessera1n, which in turn is translated as passn. However, for clarity\u2019s sake, double referencing should be avoided within dictionaries.\n\u2022 Use of variant. This pattern is of the kind sw \u2192 sw\u2032 and sw\u2032\u2032 \u2192 sw, where w\u2032\u2032 is a variant of w\u2032 . For example, riscontro6n is translated as acknowledgment1n. However, this is a just variant of the main form acknowledgement1n. In the interests of consistency the main form should always be preferred.\n\u2022 Inconsistent spelling. This pattern is of the kind sw \u2192 sw\u2032 and sw\u2032\u2032 \u2192 sw where w and w\u2032 differ only by minimal spelling conventions. For example, asciugacapelli1n is translated as hair-dryer1n, while hair dryer1n is translated as asciugacapelli1n. The inconsistency between hair-dryer and hair dryer must be solved in favour of the latter, which is a lemma defined within the dictionary.\nTable 10 presents the above patterns in the form of graphs together with examples. Next, we collected all the pattern occurrences in the Ragazzini-Biagi bilingual dictionary and ranked them by the CQC scores assigned to the corresponding translation in the source\nentry. An excerpt of the top- and bottom-ranking issues for the misalignment pattern is reported in Table 11."}, {"heading": "7. Evaluation: Dictionary Enhancement", "text": "In the following two subsections we describe the experimental setup and give the results of our dictionary enhancement experiment."}, {"heading": "7.1 Experimental Setup", "text": "The aim of our evaluation is to show that the higher the confidence score the higher the importance of the issue for an expert lexicographer. Given such an issue (e.g., misalignment), we foresee two possible actions to be taken by a lexicographer: \u201capply some change to the dictionary entry\u201d or \u201cignore the issue\u201d. In order to assess the quality of the issues, we prepared a dataset of 200 randomly-sampled instances for each kind of dictionary issue (i.e., 200 misalignments, 200 uses of variants, etc.). Overall the dataset included 1,200 issue instances (i.e., 200 \u00b7 6 issue types). The dataset was manually annotated by expert lexicographers, who decided for each issue whether a change in the dictionary was needed (positive response) or not (negative response). Random sampling guarantees that the dataset has a distribution comparable to that of the entire set of instances for an issue of interest."}, {"heading": "7.2 Results", "text": "We report the results for each issue type in Table 12. We observed an acceptance percentage ranging between 80.0 and 84.5% for three of the issues, namely: misalignment, use of reference and use of variant, thus indicating a high level of reliability for the degree of importance calculated for these issues. We note however that semantics cannot be of much help in the case of missing lemmas, partial alignment and inconsistent spelling. In fact these issues inevitably cause the graphs to be disconnected and thus the disambiguation scores equal 0.\nTo determine whether our score-based ranking impacts the degree of reliability of our enhancement suggestions we graphed the percentage of accepted suggestions by score for the misalignment issue (Figure 6). As expected, the higher the disambiguation score, the higher the percentage of suggestions accepted by lexicographers, up to 99% when the score > 0.27. We observed similar trends for the other issues."}, {"heading": "8. Synonym Extraction", "text": "In the previous sections, we have shown how to use cycles and quasi-cycles to extend bilingual dictionary entries with sense information and tackle important dictionary issues. We now propose a third application of the CQC algorithm to enrich the bilingual dictionary with synonyms, a task referred to as synonym extraction. The task consists of automatically identifying appropriate synonyms for a given lemma. Many efforts have been made to develop automated methods that collect synonyms. Current approaches typically rely either on statistical methods based on large corpora or on fully-fledged semantic networks such as WordNet (a survey of the literature in the field is given in Section 10). Our approach is closer to the latter direction, but relies on a bilingual machine readable dictionary (i.e., a resource with no explicit semantic relations), rather than a full computational lexicon. We exploit cross-language connections to identify the most appropriate synonyms for a given word using cycles and quasi-cycles.\nThe idea behind our synonym extraction approach is as follows: starting from some node(s) in the graph associated with a given word, we perform a cycle and quasi-cycle search (cf. Section 4). The words encountered in the cycles or quasi-cycles are likely to be closely related to the word sense we started from and they tend to represent good synonym candidates in the two languages. We adopted two synonym extraction strategies:\n\u2022 sense-level synonym extraction: the aim of this task is to find synonyms of a given sense s of a word w.\n\u2022 word-level synonym extraction: given a word w, we collect the union of the synonyms for all senses of w.\nIn both cases we apply CQC to obtain a set of paths P (respectively starting from a given sense s of w or from any sense of w). Next, we rank each candidate synonym according to the following formula:\nscore(w\u2032) = \u2211\np\u2208P (w\u2032)\n1\nelength(p) (5)\nwhich provides a score for a synonym candidate w\u2032, where P (w\u2032) is the set of (quasi-)cycles passing through a sense of w\u2032. In the sense-level strategy P (w\u2032) contains all the paths starting from sense s of our source word w, whereas in the word-level strategy P (w\u2032) contains paths starting from any sense of w. In contrast to other approaches in the literature, our synonym extraction approach actually produces not only synonyms, but also their senses according to the dictionary sense inventory. Further, thanks to the above formula, we are able to rank synonym senses from most to less likely. For example, given the English sense capable1a, the system outputs the following ordered list of senses:\nLang. Word sense Score it abile1a 13.34 it capace2a 8.50 en able1a 4.42 en skilful1a 3.21 it espertoA.1a 3.03 en clever1a 2.61 en deft1a 1.00 ... ... ...\nen crafty1a 0.18 it destroA.1a 0.17\nIn the word-level strategy, instead, synonyms are found by performing a CQC search starting from each sense of the word w, and thus collecting the union of all the paths obtained in each individual visit. As a result we can output the list of all the words which are likely to be synonym candidates. For example, given the English word capable, the system outputs the following ordered list of words:\nLang. Word Score it abile 12.00 it capace 10.65 en clever 3.45 en able 2.90 it esperto 2.41 en skilful 2.30 en deft 0.54 ... ... ...\nit sapiente 0.18 en expert 0.16"}, {"heading": "9. Evaluation: Synonym Extraction", "text": "We now describe the experimental setup and discuss the results of our synonym extraction experiment."}, {"heading": "9.1 Experimental Setup", "text": ""}, {"heading": "9.1.1 Dataset", "text": "To compare the performance of CQC on synonym extraction with existing approaches, we used the Test of English as a Foreign Language (TOEFL) dataset provided by ETS via Thomas Landauer and coming originally from the Educational Testing Service (Landauer & Dumais, 1997). This dataset is part of the well-known TOEFL test used to evaluate the ability of an individual to use and understand English. The dataset includes 80 question items, each presenting:\n1. a sentence where a target word w is emphasized;\n2. 4 words listed as possible synonyms for w.\nThe examinee is asked to indicate which one, among the four presented choices, is more likely to be the right synonym for the given word w. The examinee\u2019s language ability is then estimated to be the fraction of correct answers. The performance of automated systems can be assessed in the very same way."}, {"heading": "9.1.2 Algorithms", "text": "We performed our experiments with the same algorithms used in Section 5.1.4 and compared their results against the best ones known in the literature. All of our methods are based on some sort of graph path or cycle collection. In order to select the best synonym for a target word, we used the approach described in Section 8 for all methods but Markov chains and PPR. For the latter we replaced equation 5 with the corresponding scoring function of the method (cf. Section 5.1.4). We also compared with the best approaches for synonym extraction in the literature, including:\n\u2022 Product Rule (PR) (Turney, Littman, Bigham, & Shnayder, 2003): this method \u2013 which achieves the highest performance \u2013 combines various different modules. Each\nmodule produces a probability distribution based on a word closeness coefficient calculated on the possible answers the system can output and a merge rule is then applied to integrate all four distributions into a single one.\n\u2022 Singular Value Decomposition (LSA) (Rapp, 2003), an automatic Word Sense Induction method which aims at finding sense descriptors for the different senses of ambiguous words. Given a word, the twenty most similar words are considered good candidate descriptors. Then pairs are formed and classified according to two criteria: i) two words in a couple should be as dissimilar as possible; ii) their cooccurrence vectors should sum to the ambiguous word cooccurrence vector (scaled by 2). Finally, words with the highest score are selected.\n\u2022 Generalized Latent Semantic Analysis (GLSA) (Matveeva, Levow, Farahat, & Royer, 2005), a corpus-based method which builds term-vectors and represents the document space in terms of vectors. By means of Singular Value Decomposition and Latent Semantic Analysis they obtain the similarity matrix between the words of a prefixed vocabulary and extract the related document matrix. Next, synonyms of a word are selected on the basis of the highest cosine-similarity between the candidate synonym and the fixed word.\n\u2022 Positive PMI Cosine (PPMIC) (Bullinaria & Levy, 2007) systematically explores several possibilities of representation for the word meanings in the space of cooccurrence vectors, studying and comparing different information metrics and implementation details (such as the cooccurrence window or the corpus size).\n\u2022 Context-window overlapping (CWO) (Ruiz-Casado, M., E., & Castells, 2005) is an approach based on the key idea that synonymous words can be replaced in most contexts. Given two words, their similarity is measured as the number of contexts that can be found by replacing each word with the other, where the context is restricted to an L-window of open-class words in a Google snippet.\n\u2022 Document Retrieval PMI (PMI-IR) (Terra & Clarke, 2003) integrates many different word similarity measures and cooccurrence estimates. Using a large corpus of Web data they analyze how the corpus size influences the measure performance and compare a window- with a document-oriented approach.\n\u2022 Roget\u2019s Thesaurus system (JS) (Jarmasz & Szpakowicz, 2003), exploits Roget\u2019s thesaurus taxonomy and WordNet to measure semantic similarity. Given two words their closeness is defined as the minimum distance between the nodes associated with the words. This work is closest to our own in that the structure of knowledge resources is exploited to extract synonyms."}, {"heading": "9.2 Results", "text": "In Table 13 and 14 we report the performance (precision and recall, respectively) of our algorithms on the TOEFL with maximum path length \u03b4 varying from 2 to 6. The best results are obtained for all algorithms (except for Markov chains) when \u03b4 = 6, as this value makes it easier to find near synonyms that cannot be immediately obtained as translations\nof the target word in the dictionary. We attribute the higher recall (but lower precision) of Markov chains to the amount of noise accumulated after only few steps. Interestingly, PPR (which is independent of parameter \u03b4, and therefore is not shown in Tables 13 and 14) obtained comparable performance, i.e., 94.55% precision and 65% recall. Thus, CQC is the best graph-based approach achieving 93% precision and 85% recall. This result corroborates our previous findings (cf. Section 5).\nTable 15 shows the results of the best systems in the literature and compares them with CQC.5 We note that the systems performing better than CQC exploit a large amount of information: for example Rapp (2003) uses a corpus of more than 100 million words of everyday written and spoken language, while Matveeva et al. (2005) draw on more than 1 million New York Times articles with a \u2018history\u2019 label. Even if they do not rely on a manually-created lexicon, they do have to cope with the extremely high term-space dimension and need to adopt some method to reduce dimensionality (i.e., either using Latent Semantic Indexing on the term space or reducing the vocabulary size according to some general strategy such as selecting the top frequent words).\nIt is easy to see how our work stands above all lexicon-based ones, raising performance from 78.75% up to 85% recall. In Table 15 we also report the performance of other lexiconbased approaches in the literature (Hirst & St-Onge, 1998; Leacock & Chodorow, 1998; Jarmasz & Szpakowicz, 2003). We note that our system exploits the concise edition of the Ragazzini bilingual dictionary which omits lots of translations (i.e., edges) and senses which are to be found in the complete edition of the dictionary. Our graph algorithm could\n5. Further information about the state of the art for the TOEFL test can be found at the following web site: http://aclweb.org/aclwiki/index.php?title=TOEFL_Synonym_Questions_(State_of_the_art)\nreadily take advantage of the richer structure of the complete edition to achieve even better performance.\nAnother interesting aspect is the ability of CQC to rank synonym candidates. To better understand this phenomenon, we performed a second experiment. We selected 100 senses (50 for each language). We applied the CQC algorithm to each of them and also to their lemmas. In the former case a sense-tagged list was returned; in the latter the list contained just words. Then we determined the precision of CQC in retrieving the top ranking K synonyms (precision@K) according to the algorithm\u2019s score. We performed our evaluation at both the sense- and the word-level, as explained in Section 8. In Table 16 we report the precision@K calculated at both levels when K = 1, . . . , 10. Note that, when K is sufficiently small (K \u2264 4), the sense-level extraction achieves performance similar to the word-level one, while being semantically precise. However, we observe that with larger values of K the performance difference increases considerably."}, {"heading": "10. Related Work", "text": "We now review the literature in the three main fields we have dealt with in this paper, namely: gloss disambiguation (Section 10.1), dictionary enhancement (Section 10.2) and synonym extraction (Section 10.3)."}, {"heading": "10.1 Gloss Disambiguation", "text": "Since the late 1970s much work on the analysis and disambiguation of dictionary glosses has been done. This includes methods for the automatic extraction of taxonomies from lexical resources (Litkowski, 1978; Amsler, 1980), the identification of genus terms (Chodorow, Byrd, & Heidorn, 1985) and, more in general, the extraction of explicit information from machine-\nreadable dictionaries (see, e.g., Nakamura & Nagao, 1988; Ide & V\u00e9ronis, 1993), as well as the construction of ambiguous semantic networks from glosses (Kozima & Furugori, 1993). A relevant project in this direction is MindNet (Vanderwende, 1996; Richardson, Dolan, & Vanderwende, 1998), a lexical knowledge base obtained from the automated extraction of lexico-semantic information from two machine-readable dictionaries.\nMore recently, a set of heuristics has been proposed to semantically annotate WordNet glosses, leading to the release of the eXtended WordNet (Harabagiu et al., 1999; Moldovan & Novischi, 2004). Among the heuristics, the cross reference heuristic is the closest technique to our notion of (quasi-)cyclic patterns. Given a pair of words w and w\u2032, this heuristic is based on the occurrence of w in the gloss of a sense s\u2032 of w\u2032 and, vice versa, of w\u2032 in the gloss of a sense s of w. In other words, a cycle s\u2192 s\u2032 \u2192 s of length 2 is sought. Recently, a similar consideration has been put forward proposing that probabilistic translation circuits can be used as evidence to automatically acquire a multilingual dictionary (Mausam et al., 2009).\nBased on the eXtended WordNet, a gloss disambiguation task was organized at Senseval3 (Litkowski, 2004). Most notably, the best performing systems, namely the TALP system (Castillo et al., 2004), and SSI (Navigli & Velardi, 2005), are knowledge-based and rely on rich knowledge resources: respectively, the Multilingual Central Repository (Atserias, Vil-\nlarejo, Rigau, Agirre, Carroll, Magnini, & Vossen, 2004), and a proprietary lexical knowledge base (cf. Navigli & Lapata, 2010).\nHowever, the literature in the field of gloss disambiguation is focused only on monolingual dictionaries, such as WordNet and LDOCE. To our knowledge, CQC is the first algorithm aimed at disambiguating the entries of a bilingual dictionary: our key idea is to harvest (quasi-)cyclic paths from the dictionary \u2013 viewed as a noisy graph \u2013 and use them to associate meanings with the target translations. Moreover, in contrast to many disambiguation methods in the literature (Navigli, 2009b), our approach works on bilingual machine-readable dictionaries and does not exploit lexical and semantic relations, such as those available in computational lexicons like WordNet."}, {"heading": "10.2 Dictionary Enhancement", "text": "The issue of improving the quality of machine-readable dictionaries with computational methods has been poorly investigated so far. Ide and V\u00e9ronis (1993, 1994), among others, have been working on the identification of relevant issues when transforming a machinereadable dictionary into a computational lexicon. These include overgenerality (e.g., a newspaper defined as an artifact, rather than a publication), inconsistent definitions (e.g., two concepts defined in terms of each other), meta-information labels and sense divisions (e.g., fine-grained vs. coarse-grained distinctions). Only little work has been done on the automatic improvement of monolingual dictionaries (Navigli, 2008), as well as bilingual resources, for which a gloss rewriting algorithm has been proposed (Bond, Nichols, & Breen, 2007). However, to our knowledge, the structure of bilingual dictionaries has never previously been exploited for the purpose of suggesting dictionary enhancements. Moreover, we rank our suggestions on the basis of semantic-driven confidence scores, thus submitting to the lexicographer more pressing issues first."}, {"heading": "10.3 Synonym Extraction", "text": "Another task aimed at improving machine-readable dictionaries is that of synonym extraction. Many efforts have been made to automatically collect a set of synonyms for a word of interest. We introduced various methods aimed at this task in Section 8. Here we distinguish in greater detail between corpus-based (i.e., statistical) and lexicon-based (or knowledge-based) approaches.\nCorpus-based approaches typically harvest statistical information about word occurrences from large corpora, inferring probabilistic clauses such as \u201cword w is likely to appear (i.e., cooccur) together with word y with probability p\u201d. Thus, word similarity is approximated with word distance functions. One common goal is to build a cooccurrence matrix; this can be done directly via corpus analysis or indirectly by obtaining its vector space representation.\nThe most widespread statistical method (Turney et al., 2003; Bullinaria & Levy, 2007; Ruiz-Casado et al., 2005; Terra & Clarke, 2003) is to estimate the word distance by counting the number of times that two words appear together in a corpus within a fixed k-sized window, followed by a convenient normalization. This approach suffers from the well-known data sparseness problem; furthermore it introduces the additional window-size parameter k whose value has to be tuned.\nA similar statistical approach consists of building a vocabulary of terms V from a corpus C and then representing a document by means of the elements of V contained therein. In this framework a document is represented as a vector, a corpus as a term-document matrix L as well as a document-term matrix L\u2032. The matrix product LL\u2032 represents the cooccurrence matrix which gives a measure of word closeness.\nFor computational reasons, however, it is often desirable to shrink the vocabulary size. Classical algebraic methods, such as Singular Value Decomposition (SVD), can be applied to synonym extraction (Rapp, 2003; Matveeva et al., 2005), because they are able to produce a smaller vocabulary V \u2032 representing the concept space. These methods do not take into account the relative word position, but only cooccurrences within the same document, so less information is usually considered. On the other hand, by virtue of SVD, a more significant concept space is built and documents can be more suitably represented.\nLexicon-based approaches (Jarmasz & Szpakowicz, 2003; Blondel & Senellart, 2002) are an alternative to purely statistical ones. Graph models are employed in which words are represented by nodes and relations between words by edges between nodes. In this setting, no corpus is required. Instead two words are deemed to be synonyms if the linking path, if any, satisfies some structural criterion, based on length, structure or connectivity degree. Our application of CQC to the synonym extraction problem follows this direction. However, in contrast to existing work in the literature, we do not exploit any lexical or semantic relation between concepts, such as those in WordNet, nor any lexical pattern as done by Wang and Hirst (2012). Further, we view synonym extraction as a dictionary enrichment task that we can perform at a bilingual level."}, {"heading": "11. Conclusions", "text": "In this paper we presented a novel algorithm, called Cycles and Quasi-Cycles (CQC), for the disambiguation of bilingual machine-readable dictionaries. The algorithm is based on the identification of (quasi-)cycles in the noisy dictionary graph, i.e., circular edge sequences (possibly with some consecutive edges reversed) relating a source word sense to a target one.\nThe contribution of the paper is threefold:\n1. We show that our notion of (quasi-)cyclic patterns enables state-of-the-art performance to be attained in the disambiguation of dictionary entries, surpassing all other disambiguation approaches (including the popular PPR), as well as a competitive baseline such as the first sense heuristic. Crucially, the introduction of reversed edges allows us to find more semantic connections, thus substantially increasing recall while keeping precision very high.\n2. We explore the novel task of dictionary enhancement by introducing graph patterns for a variety of dictionary issues, which we tackle effectively by means of the CQC algorithm. We use CQC to rank the issues based on the disambiguation score and present enhancement suggestions automatically. Our experiments show that the higher the score the more relevant the suggestion. As a result, important idiosyncrasies such as missing or redundant translations can be submitted to expert lexicographers, who can review them in order to improve the bilingual dictionary.\n3. We successfully apply CQC to the task of synonym extraction. While data-intensive approaches achieve better performance, CQC obtains the best result among lexiconbased systems. As an interesting side effect, our algorithm produces sense-tagged synonyms for the two languages of interest, whereas state-of-the-art approaches all focus on a single language and do not produce sense annotations for synonyms.\nThe strength of our approach lies in its weakly supervised nature: the CQC algorithm relies exclusively on the structure of the input bilingual dictionary. Unlike other research directions, no further resource (such as labeled corpora or knowledge bases) is required.\nThe paths output by our algorithm for the dataset presented in Section 5.1 are available from http://lcl.uniroma1.it/cqc. We are scheduling the release of a software package which allows for the application of the CQC algorithm to any resource for which a standard interface can be implemented.\nAs regards future work, we foresee several developments of the CQC algorithm and its applications: starting from the work of Budanitsky and Hirst (2006), we plan to experiment with cycles and quasi-cycles when used as a semantic similarity measure, and compare them with the most successful existing approaches. Moreover, although in this paper we focused on the disambiguation of dictionary glosses, exactly the same approach can be applied to the disambiguation of collocations using any dictionary of choice (along the lines of Navigli, 2005), thus providing a way of further enriching lexical knowledge resources with external knowledge."}, {"heading": "Acknowledgments", "text": "The authors gratefully acknowledge the support of the ERC Starting Grant MultiJEDI No. 259234. The authors wish to thank Jim McManus, Simon Bartels and the three anonymous reviewers for their useful comments on the paper, and Zanichelli for making the RagazziniBiagi dictionary available for research purposes."}], "references": [{"title": "Automatic extraction of synonyms in a dictionary", "author": ["V.D. Blondel", "P.P. Senellart"], "venue": "In Proceedings of the SIAM Text Mining Workshop,", "citeRegEx": "Blondel and Senellart,? \\Q2002\\E", "shortCiteRegEx": "Blondel and Senellart", "year": 2002}, {"title": "A note on sparse random graphs and cover graphs", "author": ["T. Bohman", "L. Thoma"], "venue": "The Electronic Journal of Combinatorics,", "citeRegEx": "Bohman and Thoma,? \\Q2000\\E", "shortCiteRegEx": "Bohman and Thoma", "year": 2000}, {"title": "Enhancing a dictionary for transfer rule acquisition", "author": ["F.C. Bond", "E. Nichols", "J.W. Breen"], "venue": "Linguistic Research,", "citeRegEx": "Bond et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bond et al\\.", "year": 2007}, {"title": "Anatomy of a large-scale hypertextual web search engine", "author": ["S. Brin", "M. Page"], "venue": "In Proceedings of the 7th Conference on World Wide Web (WWW),", "citeRegEx": "Brin and Page,? \\Q1998\\E", "shortCiteRegEx": "Brin and Page", "year": 1998}, {"title": "Evaluating WordNet-based measures of semantic distance", "author": ["A. Budanitsky", "G. Hirst"], "venue": "Computational Linguistics,", "citeRegEx": "Budanitsky and Hirst,? \\Q2006\\E", "shortCiteRegEx": "Budanitsky and Hirst", "year": 2006}, {"title": "Extracting semantic representations from word co-occurrence statistics: A computational study", "author": ["J.A. Bullinaria", "J.P. Levy"], "venue": "Behavior Research Methods,", "citeRegEx": "Bullinaria and Levy,? \\Q2007\\E", "shortCiteRegEx": "Bullinaria and Levy", "year": 2007}, {"title": "The TALP systems for disambiguating WordNet glosses", "author": ["M. Castillo", "F. Real", "J. Asterias", "G. Rigau"], "venue": "In Proceedings of ACL 2004 SENSEVAL-3 Workshop,", "citeRegEx": "Castillo et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Castillo et al\\.", "year": 2004}, {"title": "Extracting semantic hierarchies from a large on-line dictionary", "author": ["M. Chodorow", "R. Byrd", "G. Heidorn"], "venue": "In Proceedings of Association for Computational Linguistics (ACL", "citeRegEx": "Chodorow et al\\.,? \\Q1985\\E", "shortCiteRegEx": "Chodorow et al\\.", "year": 1985}, {"title": "Introduction to algorithms", "author": ["T.H. Cormen", "C.E. Leiserson", "R.L. Rivest"], "venue": null, "citeRegEx": "Cormen et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Cormen et al\\.", "year": 1990}, {"title": "Quality assessment of large scale knowledge resources", "author": ["M. Cuadros", "G. Rigau"], "venue": "In Proceedings of Empirical Methods on Natural Language Processing (EMNLP", "citeRegEx": "Cuadros and Rigau,? \\Q2006\\E", "shortCiteRegEx": "Cuadros and Rigau", "year": 2006}, {"title": "KnowNet: Building a large net of knowledge from the web", "author": ["M. Cuadros", "G. Rigau"], "venue": "In Proceedings of the 22nd International Conference on Computational Linguistics (COLING),", "citeRegEx": "Cuadros and Rigau,? \\Q2008\\E", "shortCiteRegEx": "Cuadros and Rigau", "year": 2008}, {"title": "Untangling the cross-lingual link structure of Wikipedia", "author": ["G. de Melo", "G. Weikum"], "venue": "In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL", "citeRegEx": "Melo and Weikum,? \\Q2010\\E", "shortCiteRegEx": "Melo and Weikum", "year": 2010}, {"title": "WordNet: An Electronic Database", "author": ["C. Fellbaum"], "venue": null, "citeRegEx": "Fellbaum,? \\Q1998\\E", "shortCiteRegEx": "Fellbaum", "year": 1998}, {"title": "Wikipedia-based semantic interpretation for natural language processing", "author": ["E. Gabrilovich", "S. Markovitch"], "venue": "Journal of Artificial Intelligence Research (JAIR),", "citeRegEx": "Gabrilovich and Markovitch,? \\Q2009\\E", "shortCiteRegEx": "Gabrilovich and Markovitch", "year": 2009}, {"title": "WordNet 2 - a morphologically and semantically enhanced resource", "author": ["S. Harabagiu", "G. Miller", "D. Moldovan"], "venue": "In Proceedings of Special Interest Group on the Lexicon of the Association for Computational Linguistics (SIGLEX", "citeRegEx": "Harabagiu et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Harabagiu et al\\.", "year": 1999}, {"title": "Topic-sensitive PageRank", "author": ["T.H. Haveliwala"], "venue": "In Proceedings of 11th International Conference on World Wide Web (WWW", "citeRegEx": "Haveliwala,? \\Q2002\\E", "shortCiteRegEx": "Haveliwala", "year": 2002}, {"title": "Topic-sensitive pagerank: A context-sensitive ranking algorithm for web search", "author": ["T.H. Haveliwala"], "venue": "IEEE Transactions on Knowledge and Data Engineering,", "citeRegEx": "Haveliwala,? \\Q2003\\E", "shortCiteRegEx": "Haveliwala", "year": 2003}, {"title": "Lexical chains as representations of context for the detection and correction of malapropisms", "author": ["G. Hirst", "D. St-Onge"], "venue": "WordNet: An electronic lexical database,", "citeRegEx": "Hirst and St.Onge,? \\Q1998\\E", "shortCiteRegEx": "Hirst and St.Onge", "year": 1998}, {"title": "Extracting knowledge bases from machine-readable dictionaries: Have we wasted our time", "author": ["N. Ide", "J. V\u00e9ronis"], "venue": "In Proceedings of Workshop on Knowledge Bases and Knowledge Structures,", "citeRegEx": "Ide and V\u00e9ronis,? \\Q1993\\E", "shortCiteRegEx": "Ide and V\u00e9ronis", "year": 1993}, {"title": "Machine readable dictionaries: What have we learned, where do we go", "author": ["N. Ide", "J. V\u00e9ronis"], "venue": "In Proceedings of the COLING \u201994 International Workshop on Directions of Lexical Research,", "citeRegEx": "Ide and V\u00e9ronis,? \\Q1994\\E", "shortCiteRegEx": "Ide and V\u00e9ronis", "year": 1994}, {"title": "Enriching a text by semantic disambiguation for Information Extraction", "author": ["B. Jacquemin", "C. Brun", "C. Roux"], "venue": "In Proceedings of the Workshop on Using Semantics for Information Retrieval and Filtering in the 3rd International Conference on Language Resources and Evaluations (LREC", "citeRegEx": "Jacquemin et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Jacquemin et al\\.", "year": 2002}, {"title": "Roget\u2019s thesaurus and semantic similarity", "author": ["M. Jarmasz", "S. Szpakowicz"], "venue": "In Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP", "citeRegEx": "Jarmasz and Szpakowicz,? \\Q2003\\E", "shortCiteRegEx": "Jarmasz and Szpakowicz", "year": 2003}, {"title": "Similarity between words computed by spreading activation on an english dictionary", "author": ["H. Kozima", "T. Furugori"], "venue": "In Proceedings of The Association for Computational Linguistics (ACL", "citeRegEx": "Kozima and Furugori,? \\Q1993\\E", "shortCiteRegEx": "Kozima and Furugori", "year": 1993}, {"title": "Lexical ambiguity and Information Retrieval", "author": ["R. Krovetz", "W.B. Croft"], "venue": "ACM Transactions on Information Systems,", "citeRegEx": "Krovetz and Croft,? \\Q1992\\E", "shortCiteRegEx": "Krovetz and Croft", "year": 1992}, {"title": "Solution to Plato\u2019s Problem: The Latent Semantic Analysis Theory of Acquisition, Induction and Representation of Knowledge", "author": ["T.K. Landauer", "S.T. Dumais"], "venue": "Psychological Review,", "citeRegEx": "Landauer and Dumais,? \\Q1997\\E", "shortCiteRegEx": "Landauer and Dumais", "year": 1997}, {"title": "Combining local context and WordNet similarity for word sense identification", "author": ["C. Leacock", "M. Chodorow"], "venue": "WordNet: An electronic lexical database,", "citeRegEx": "Leacock and Chodorow,? \\Q1998\\E", "shortCiteRegEx": "Leacock and Chodorow", "year": 1998}, {"title": "Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone", "author": ["M. Lesk"], "venue": "In Proceedings of the 5th Special Interest Group on Design of Communication (SIGDOC),", "citeRegEx": "Lesk,? \\Q1986\\E", "shortCiteRegEx": "Lesk", "year": 1986}, {"title": "Resource analysis for Question Answering", "author": ["L.V. Lita", "W.A. Hunt", "E. Nyberg"], "venue": "In Proceedings of the 42th Annual Meeting of the Association for Computational Linguistics (ACL", "citeRegEx": "Lita et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Lita et al\\.", "year": 2004}, {"title": "Models of the semantic structure of dictionaries", "author": ["K.C. Litkowski"], "venue": "American Journal of Computational Linguistics,", "citeRegEx": "Litkowski,? \\Q1978\\E", "shortCiteRegEx": "Litkowski", "year": 1978}, {"title": "SENSEVAL-3 task: Word-Sense disambiguation of WordNet glosses", "author": ["K.C. Litkowski"], "venue": "In Proceedings of ACL 2004 SENSEVAL-3 Workshop,", "citeRegEx": "Litkowski,? \\Q2004\\E", "shortCiteRegEx": "Litkowski", "year": 2004}, {"title": "The use of WordNet in Information Retrieval", "author": ["R. Mandala", "T. Tokunaga", "H. Tanaka"], "venue": "In Proceedings of COLING/ACL Workshop on Usage of WordNet in Natural Language Processing Systems,", "citeRegEx": "Mandala et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Mandala et al\\.", "year": 1998}, {"title": "On the use of automatically acquired examples for all-nouns Word Sense Disambiguation", "author": ["D. Mart\u00ednez", "O.L. de Lacalle", "E. Agirre"], "venue": "Journal of Artificial Intelligence Research (JAIR),", "citeRegEx": "Mart\u00ednez et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Mart\u00ednez et al\\.", "year": 2008}, {"title": "Generalized latent semantic analysis for term representation", "author": ["I. Matveeva", "G. Levow", "A. Farahat", "C. Royer"], "venue": "In Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP", "citeRegEx": "Matveeva et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Matveeva et al\\.", "year": 2005}, {"title": "Compiling a massive, multilingual dictionary via probabilistic inference", "author": ["Mausam", "S. Soderland", "O. Etzioni", "D. Weld", "M. Skinner", "J. Bilmes"], "venue": "In Proceedings of Association for Computational Linguistics and International Joint Conference on Natural Language Processing (ACL-IJCNLP", "citeRegEx": "Mausam et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Mausam et al\\.", "year": 2009}, {"title": "Panlingual lexical translation via probabilistic inference", "author": ["Mausam", "S. Soderland", "O. Etzioni", "D.S. Weld", "K. Reiter", "M. Skinner", "M. Sammer", "J. Bilmes"], "venue": "Artificial Intelligence,", "citeRegEx": "Mausam et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Mausam et al\\.", "year": 2010}, {"title": "Unsupervised large-vocabulary word sense disambiguation with graphbased algorithms for sequence data labeling", "author": ["R. Mihalcea"], "venue": "In Proceedings of the Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP),", "citeRegEx": "Mihalcea,? \\Q2005\\E", "shortCiteRegEx": "Mihalcea", "year": 2005}, {"title": "Lexical chains for Question Answering", "author": ["D. Moldovan", "A. Novischi"], "venue": "In Proceedings of International Conference on Computational Linguistics (COLING),", "citeRegEx": "Moldovan and Novischi,? \\Q2002\\E", "shortCiteRegEx": "Moldovan and Novischi", "year": 2002}, {"title": "Word Sense Disambiguation of WordNet glosses", "author": ["D. Moldovan", "A. Novischi"], "venue": "Computer Speech & Language,", "citeRegEx": "Moldovan and Novischi,? \\Q2004\\E", "shortCiteRegEx": "Moldovan and Novischi", "year": 2004}, {"title": "Extraction of semantic information from an ordinary English dictionary and its evaluation", "author": ["Nakamura", "J.-I", "M. Nagao"], "venue": "In Proceedings of the 12th International Conference on Computational Linguistics (COLING),", "citeRegEx": "Nakamura et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Nakamura et al\\.", "year": 1988}, {"title": "Topic-driven multi-document summarization with encyclopedic knowledge and spreading activation", "author": ["V. Nastase"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP", "citeRegEx": "Nastase,? \\Q2008\\E", "shortCiteRegEx": "Nastase", "year": 2008}, {"title": "Word Sense Disambiguation in Roget\u2019s Thesaurus Using WordNet", "author": ["V. Nastase", "S. Szpakowicz"], "venue": "In Proceedings of the NAACL WordNet and Other Lexical Resources workshop,", "citeRegEx": "Nastase and Szpakowicz,? \\Q2001\\E", "shortCiteRegEx": "Nastase and Szpakowicz", "year": 2001}, {"title": "Semi-automatic extension of large-scale linguistic knowledge bases", "author": ["R. Navigli"], "venue": "In Proceedings of the Eighteenth International Florida Artificial Intelligence Research Society Conference (FLAIRS),", "citeRegEx": "Navigli,? \\Q2005\\E", "shortCiteRegEx": "Navigli", "year": 2005}, {"title": "A structural approach to the automatic adjudication of word sense disagreements", "author": ["R. Navigli"], "venue": "Journal of Natural Language Engineering,", "citeRegEx": "Navigli,? \\Q2008\\E", "shortCiteRegEx": "Navigli", "year": 2008}, {"title": "Using Cycles and Quasi-Cycles to disambiguate dictionary glosses", "author": ["R. Navigli"], "venue": "In Proceedings of the 12th conference of the European chapter of the Association for Computational Linguistics (EACL", "citeRegEx": "Navigli,? \\Q2009\\E", "shortCiteRegEx": "Navigli", "year": 2009}, {"title": "Word Sense Disambiguation: a Survey", "author": ["R. Navigli"], "venue": "ACM Computing Surveys,", "citeRegEx": "Navigli,? \\Q2009\\E", "shortCiteRegEx": "Navigli", "year": 2009}, {"title": "A Quick Tour of Word Sense Disambiguation, Induction and Related Approaches", "author": ["R. Navigli"], "venue": "In Proceedings of the 38th International Conference on Current Trends in Theory and Practice of Computer Science (SOFSEM", "citeRegEx": "Navigli,? \\Q2012\\E", "shortCiteRegEx": "Navigli", "year": 2012}, {"title": "Two birds with one stone: learning semantic models for Text Categorization and Word Sense Disambiguation", "author": ["R. Navigli", "S. Faralli", "A. Soroa", "O.L. de Lacalle", "E. Agirre"], "venue": "In Proceedings of the 20th ACM Conference on Information and Knowledge Management (CIKM", "citeRegEx": "Navigli et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Navigli et al\\.", "year": 2011}, {"title": "An experimental study on graph connectivity for unsupervised Word Sense Disambiguation", "author": ["R. Navigli", "M. Lapata"], "venue": "IEEE Transactions on Pattern Anaylsis and Machine Intelligence (TPAMI),", "citeRegEx": "Navigli and Lapata,? \\Q2010\\E", "shortCiteRegEx": "Navigli and Lapata", "year": 2010}, {"title": "BabelNet: Building a very large multilingual semantic network", "author": ["R. Navigli", "S.P. Ponzetto"], "venue": "In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL", "citeRegEx": "Navigli and Ponzetto,? \\Q2010\\E", "shortCiteRegEx": "Navigli and Ponzetto", "year": 2010}, {"title": "Structural semantic interconnections: a knowledge-based approach to Word Sense Disambiguation", "author": ["R. Navigli", "P. Velardi"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI),", "citeRegEx": "Navigli and Velardi,? \\Q2005\\E", "shortCiteRegEx": "Navigli and Velardi", "year": 2005}, {"title": "Dependency-based construction of semantic space models", "author": ["S. Pado", "M. Lapata"], "venue": "Computational Linguistics,", "citeRegEx": "Pado and Lapata,? \\Q2007\\E", "shortCiteRegEx": "Pado and Lapata", "year": 2007}, {"title": "Maximizing semantic relatedness to perform Word Sense Disambiguation", "author": ["T. Pedersen", "S. Banerjee", "S. Patwardhan"], "venue": "In University of Minnesota Supercomputing Institute Research Report UMSI 2005/25,", "citeRegEx": "Pedersen et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Pedersen et al\\.", "year": 2005}, {"title": "Knowledge-rich Word Sense Disambiguation rivaling supervised system", "author": ["S.P. Ponzetto", "R. Navigli"], "venue": "In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL", "citeRegEx": "Ponzetto and Navigli,? \\Q2010\\E", "shortCiteRegEx": "Ponzetto and Navigli", "year": 2010}, {"title": "Word sense discovery based on sense descriptor dissimilarity", "author": ["R. Rapp"], "venue": "In Proceedings of the Ninth Machine Translation Summit,", "citeRegEx": "Rapp,? \\Q2003\\E", "shortCiteRegEx": "Rapp", "year": 2003}, {"title": "MindNet: acquiring and structuring semantic information from text", "author": ["S.D. Richardson", "W.B. Dolan", "L. Vanderwende"], "venue": "In Proceedings of International Conference on Computational Linguistics (COLING", "citeRegEx": "Richardson et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Richardson et al\\.", "year": 1998}, {"title": "Information retrieval and text categorization with semantic indexing", "author": ["P. Rosso", "A. Molina", "F. Pla", "D. Jim\u00e9nez", "V. Vidal"], "venue": "In Proceedings of the Intelligent Text Processing and Computational Linguistics Conference (CICLing),", "citeRegEx": "Rosso et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Rosso et al\\.", "year": 2004}, {"title": "Using context-window overlapping in synonym discovery and ontology extension", "author": ["M. Ruiz-Casado", "E. A", "P. Castells"], "venue": "In Proceedings of the International Conference Recent Advances in Natural Language Processing (RANLP", "citeRegEx": "Ruiz.Casado et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Ruiz.Casado et al\\.", "year": 2005}, {"title": "Retrieving with good sense", "author": ["M. Sanderson"], "venue": "Information Retrieval,", "citeRegEx": "Sanderson,? \\Q2000\\E", "shortCiteRegEx": "Sanderson", "year": 2000}, {"title": "Efficient text summarization using lexical chains", "author": ["H.G. Silber", "K.F. McCoy"], "venue": "In Proceedings of 5th Conference on Intelligent User Interfaces (IUI),", "citeRegEx": "Silber and McCoy,? \\Q2003\\E", "shortCiteRegEx": "Silber and McCoy", "year": 2003}, {"title": "Frequency estimates for statistical word similarity measures", "author": ["E. Terra", "C. Clarke"], "venue": "In Proceedings of the 2003 Human Language Technology and North American Chapter of Association of Computational Linguistics Conference (HLT/NAACL", "citeRegEx": "Terra and Clarke,? \\Q2003\\E", "shortCiteRegEx": "Terra and Clarke", "year": 2003}, {"title": "A uniform approach to analogies, synonyms, antonyms, and associations", "author": ["P.D. Turney"], "venue": "In Proceedings of the 22nd International Conference on Computational Linguistics (COLING),", "citeRegEx": "Turney,? \\Q2008\\E", "shortCiteRegEx": "Turney", "year": 2008}, {"title": "Combining independent modules to solve multiple-choice synonym and analogy problems", "author": ["P.D. Turney", "M.L. Littman", "J. Bigham", "V. Shnayder"], "venue": "In Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP", "citeRegEx": "Turney et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Turney et al\\.", "year": 2003}, {"title": "Predicting fame and fortune: PageRank or Indegree", "author": ["T. Upstill", "N. Craswell", "D. Hawking"], "venue": "In Proceedings of the Australasian Document Computing Symposium,", "citeRegEx": "Upstill et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Upstill et al\\.", "year": 2003}, {"title": "The analysis of noun sequences using semantic information extracted from on-line dictionaries, Ph.D", "author": ["L. Vanderwende"], "venue": null, "citeRegEx": "Vanderwende,? \\Q1996\\E", "shortCiteRegEx": "Vanderwende", "year": 1996}, {"title": "Building semantic kernels for text classification using Wikipedia", "author": ["P. Wang", "C. Domeniconi"], "venue": "In Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD),", "citeRegEx": "Wang and Domeniconi,? \\Q2008\\E", "shortCiteRegEx": "Wang and Domeniconi", "year": 2008}, {"title": "Exploring patterns in dictionary definitions for synonym extraction", "author": ["T. Wang", "G. Hirst"], "venue": "Journal of Natural Language Engineering,", "citeRegEx": "Wang and Hirst,? \\Q2012\\E", "shortCiteRegEx": "Wang and Hirst", "year": 2012}, {"title": "WikiSimple: Automatic simplification of wikipedia articles", "author": ["K. Woodsend", "M. Lapata"], "venue": "In Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Woodsend and Lapata,? \\Q2011\\E", "shortCiteRegEx": "Woodsend and Lapata", "year": 2011}, {"title": "Word-sense disambiguation using statistical models of the Roget\u2019s categories trained on large corpora", "author": ["D. Yarowsky"], "venue": "In Proceedings of 14th International Conference on Computational Linguistics (COLING", "citeRegEx": "Yarowsky,? \\Q1992\\E", "shortCiteRegEx": "Yarowsky", "year": 1992}], "referenceMentions": [{"referenceID": 12, "context": "Among such resources we cite Roget\u2019s Thesaurus (Roget, 1911), the Macquarie Thesaurus (Bernard, 1986), the Longman Dictionary of Contemporary English (Proctor, 1978, LDOCE), WordNet (Fellbaum, 1998) and Wikipedia.", "startOffset": 182, "endOffset": 198}, {"referenceID": 57, "context": "Navigli, 2009b, 2012 for a survey), semantic interpretation of text (Gabrilovich & Markovitch, 2009), Semantic Information Retrieval (Krovetz & Croft, 1992; Mandala, Tokunaga, & Tanaka, 1998; Sanderson, 2000), Question Answering (Lita, Hunt, & Nyberg, 2004; Moldovan & Novischi, 2002), Information Extraction (Jacquemin, Brun, & Roux, 2002), knowledge acquisition (Navigli & Ponzetto, 2010), text summarization (Silber & McCoy, 2003; Nastase, 2008), classification (Rosso, Molina, Pla, Jim\u00e9nez, & Vidal, 2004; Wang & Domeniconi, 2008; Navigli, Faralli, Soroa, de Lacalle, & Agirre, 2011) and even simplification (Woodsend & Lapata, 2011).", "startOffset": 133, "endOffset": 208}, {"referenceID": 39, "context": "Navigli, 2009b, 2012 for a survey), semantic interpretation of text (Gabrilovich & Markovitch, 2009), Semantic Information Retrieval (Krovetz & Croft, 1992; Mandala, Tokunaga, & Tanaka, 1998; Sanderson, 2000), Question Answering (Lita, Hunt, & Nyberg, 2004; Moldovan & Novischi, 2002), Information Extraction (Jacquemin, Brun, & Roux, 2002), knowledge acquisition (Navigli & Ponzetto, 2010), text summarization (Silber & McCoy, 2003; Nastase, 2008), classification (Rosso, Molina, Pla, Jim\u00e9nez, & Vidal, 2004; Wang & Domeniconi, 2008; Navigli, Faralli, Soroa, de Lacalle, & Agirre, 2011) and even simplification (Woodsend & Lapata, 2011).", "startOffset": 411, "endOffset": 448}, {"referenceID": 35, "context": "For instance, lexical and semantic relations encoded in computational lexicons such as WordNet have been shown to be very useful in graph-based Word Sense Disambiguation (Mihalcea, 2005; Agirre & Soroa, 2009; Navigli & Lapata, 2010; Ponzetto & Navigli, 2010) and semantic similarity (Pedersen, Banerjee, & Patwardhan, 2005; Agirre, Alfonseca, Hall, Kravalova, Pasca, & Soroa, 2009).", "startOffset": 170, "endOffset": 258}, {"referenceID": 12, "context": "Even WordNet (Fellbaum, 1998), the most widely-used computational lexicon of English, provides explanatory information in the unstructured form of textual definitions, i.", "startOffset": 13, "endOffset": 29}, {"referenceID": 29, "context": "Over recent years various approaches to the disambiguation of monolingual dictionary definitions have been investigated (Harabagiu, Miller, & Moldovan, 1999; Litkowski, 2004; Castillo, Real, Asterias, & Rigau, 2004; Navigli & Velardi, 2005; Navigli, 2009a), and results have shown that they can, indeed, boost the performance of difficult tasks such as Word Sense Disambiguation (Cuadros & Rigau, 2008; Agirre & Soroa, 2009).", "startOffset": 120, "endOffset": 256}, {"referenceID": 26, "context": "\u2022 Lesk algorithm (Lesk, 1986): we apply an adaptation of the Lesk algorithm in which, given a source sense s of word w and a word w\u2032 occurring as a translation of s, we determine the right sense of w\u2032 on the basis of the (normalized) maximum overlap between the entries of each sense s\u2032 of w\u2032 and that of s:", "startOffset": 17, "endOffset": 29}, {"referenceID": 29, "context": "This result is consistent with previous findings for tasks such as the Senseval-3 Gloss Word Sense Disambiguation (Litkowski, 2004).", "startOffset": 114, "endOffset": 131}, {"referenceID": 11, "context": "This setting is similar to that of de Melo and Weikum (2010), who aim at detecting imprecise or wrong interlanguage links in Wikipedia.", "startOffset": 38, "endOffset": 61}, {"referenceID": 53, "context": "\u2022 Singular Value Decomposition (LSA) (Rapp, 2003), an automatic Word Sense Induction method which aims at finding sense descriptors for the different senses of ambiguous words.", "startOffset": 37, "endOffset": 49}, {"referenceID": 52, "context": "5 We note that the systems performing better than CQC exploit a large amount of information: for example Rapp (2003) uses a corpus of more than 100 million words of everyday written and spoken language, while Matveeva et al.", "startOffset": 105, "endOffset": 117}, {"referenceID": 32, "context": "5 We note that the systems performing better than CQC exploit a large amount of information: for example Rapp (2003) uses a corpus of more than 100 million words of everyday written and spoken language, while Matveeva et al. (2005) draw on more than 1 million New York Times articles with a \u2018history\u2019 label.", "startOffset": 209, "endOffset": 232}, {"referenceID": 46, "context": "Algorithm Author(s) / Method Resource type Recall (%) PR Turney et al. (2003) Hybrid 97.", "startOffset": 57, "endOffset": 78}, {"referenceID": 42, "context": "50 LSA Rapp (2003) Corpus-based 92.", "startOffset": 7, "endOffset": 19}, {"referenceID": 28, "context": "50 GLSA Matveeva et al. (2005) Corpus-based 86.", "startOffset": 8, "endOffset": 31}, {"referenceID": 28, "context": "50 GLSA Matveeva et al. (2005) Corpus-based 86.25 CQC Flati and Navigli (2012) Lexicon-based 85.", "startOffset": 8, "endOffset": 79}, {"referenceID": 5, "context": "00 PPMIC Bullinaria and Levy (2007) Corpus-based 85.", "startOffset": 9, "endOffset": 36}, {"referenceID": 5, "context": "00 PPMIC Bullinaria and Levy (2007) Corpus-based 85.00 CWO Ruiz-Casado et al. (2005) Web-based 82.", "startOffset": 9, "endOffset": 85}, {"referenceID": 5, "context": "00 PPMIC Bullinaria and Levy (2007) Corpus-based 85.00 CWO Ruiz-Casado et al. (2005) Web-based 82.55 PMI-IR Terra and Clarke (2003) Corpus-based 81.", "startOffset": 9, "endOffset": 132}, {"referenceID": 5, "context": "00 PPMIC Bullinaria and Levy (2007) Corpus-based 85.00 CWO Ruiz-Casado et al. (2005) Web-based 82.55 PMI-IR Terra and Clarke (2003) Corpus-based 81.25 JS Jarmasz and Szpakowicz (2003) Lexicon-based 78.", "startOffset": 9, "endOffset": 184}, {"referenceID": 5, "context": "00 PPMIC Bullinaria and Levy (2007) Corpus-based 85.00 CWO Ruiz-Casado et al. (2005) Web-based 82.55 PMI-IR Terra and Clarke (2003) Corpus-based 81.25 JS Jarmasz and Szpakowicz (2003) Lexicon-based 78.75 HSO Hirst and St-Onge (1998) Lexicon-based 77.", "startOffset": 9, "endOffset": 233}, {"referenceID": 5, "context": "00 PPMIC Bullinaria and Levy (2007) Corpus-based 85.00 CWO Ruiz-Casado et al. (2005) Web-based 82.55 PMI-IR Terra and Clarke (2003) Corpus-based 81.25 JS Jarmasz and Szpakowicz (2003) Lexicon-based 78.75 HSO Hirst and St-Onge (1998) Lexicon-based 77.91 PairClass Turney (2008) Corpus-based 76.", "startOffset": 9, "endOffset": 277}, {"referenceID": 5, "context": "00 PPMIC Bullinaria and Levy (2007) Corpus-based 85.00 CWO Ruiz-Casado et al. (2005) Web-based 82.55 PMI-IR Terra and Clarke (2003) Corpus-based 81.25 JS Jarmasz and Szpakowicz (2003) Lexicon-based 78.75 HSO Hirst and St-Onge (1998) Lexicon-based 77.91 PairClass Turney (2008) Corpus-based 76.25 DS Pado and Lapata (2007) Corpus-based 73.", "startOffset": 9, "endOffset": 322}, {"referenceID": 5, "context": "00 PPMIC Bullinaria and Levy (2007) Corpus-based 85.00 CWO Ruiz-Casado et al. (2005) Web-based 82.55 PMI-IR Terra and Clarke (2003) Corpus-based 81.25 JS Jarmasz and Szpakowicz (2003) Lexicon-based 78.75 HSO Hirst and St-Onge (1998) Lexicon-based 77.91 PairClass Turney (2008) Corpus-based 76.25 DS Pado and Lapata (2007) Corpus-based 73.00 Human Average non-English US college applicant Human 64.50 Random Random guessing Random 25.00 LC Leacock and Chodorow (1998) Lexicon-based 21.", "startOffset": 9, "endOffset": 467}, {"referenceID": 28, "context": "This includes methods for the automatic extraction of taxonomies from lexical resources (Litkowski, 1978; Amsler, 1980), the identification of genus terms (Chodorow, Byrd, & Heidorn, 1985) and, more in general, the extraction of explicit information from machine-", "startOffset": 88, "endOffset": 119}, {"referenceID": 63, "context": "A relevant project in this direction is MindNet (Vanderwende, 1996; Richardson, Dolan, & Vanderwende, 1998), a lexical knowledge base obtained from the automated extraction of lexico-semantic information from two machine-readable dictionaries.", "startOffset": 48, "endOffset": 107}, {"referenceID": 14, "context": "More recently, a set of heuristics has been proposed to semantically annotate WordNet glosses, leading to the release of the eXtended WordNet (Harabagiu et al., 1999; Moldovan & Novischi, 2004).", "startOffset": 142, "endOffset": 193}, {"referenceID": 33, "context": "Recently, a similar consideration has been put forward proposing that probabilistic translation circuits can be used as evidence to automatically acquire a multilingual dictionary (Mausam et al., 2009).", "startOffset": 180, "endOffset": 201}, {"referenceID": 29, "context": "Based on the eXtended WordNet, a gloss disambiguation task was organized at Senseval3 (Litkowski, 2004).", "startOffset": 86, "endOffset": 103}, {"referenceID": 6, "context": "Most notably, the best performing systems, namely the TALP system (Castillo et al., 2004), and SSI (Navigli & Velardi, 2005), are knowledge-based and rely on rich knowledge resources: respectively, the Multilingual Central Repository (Atserias, Vil-", "startOffset": 66, "endOffset": 89}, {"referenceID": 42, "context": "Only little work has been done on the automatic improvement of monolingual dictionaries (Navigli, 2008), as well as bilingual resources, for which a gloss rewriting algorithm has been proposed (Bond, Nichols, & Breen, 2007).", "startOffset": 88, "endOffset": 103}, {"referenceID": 61, "context": "The most widespread statistical method (Turney et al., 2003; Bullinaria & Levy, 2007; Ruiz-Casado et al., 2005; Terra & Clarke, 2003) is to estimate the word distance by counting the number of times that two words appear together in a corpus within a fixed k-sized window, followed by a convenient normalization.", "startOffset": 39, "endOffset": 133}, {"referenceID": 56, "context": "The most widespread statistical method (Turney et al., 2003; Bullinaria & Levy, 2007; Ruiz-Casado et al., 2005; Terra & Clarke, 2003) is to estimate the word distance by counting the number of times that two words appear together in a corpus within a fixed k-sized window, followed by a convenient normalization.", "startOffset": 39, "endOffset": 133}, {"referenceID": 53, "context": "Classical algebraic methods, such as Singular Value Decomposition (SVD), can be applied to synonym extraction (Rapp, 2003; Matveeva et al., 2005), because they are able to produce a smaller vocabulary V \u2032 representing the concept space.", "startOffset": 110, "endOffset": 145}, {"referenceID": 32, "context": "Classical algebraic methods, such as Singular Value Decomposition (SVD), can be applied to synonym extraction (Rapp, 2003; Matveeva et al., 2005), because they are able to produce a smaller vocabulary V \u2032 representing the concept space.", "startOffset": 110, "endOffset": 145}, {"referenceID": 32, "context": "Classical algebraic methods, such as Singular Value Decomposition (SVD), can be applied to synonym extraction (Rapp, 2003; Matveeva et al., 2005), because they are able to produce a smaller vocabulary V \u2032 representing the concept space. These methods do not take into account the relative word position, but only cooccurrences within the same document, so less information is usually considered. On the other hand, by virtue of SVD, a more significant concept space is built and documents can be more suitably represented. Lexicon-based approaches (Jarmasz & Szpakowicz, 2003; Blondel & Senellart, 2002) are an alternative to purely statistical ones. Graph models are employed in which words are represented by nodes and relations between words by edges between nodes. In this setting, no corpus is required. Instead two words are deemed to be synonyms if the linking path, if any, satisfies some structural criterion, based on length, structure or connectivity degree. Our application of CQC to the synonym extraction problem follows this direction. However, in contrast to existing work in the literature, we do not exploit any lexical or semantic relation between concepts, such as those in WordNet, nor any lexical pattern as done by Wang and Hirst (2012). Further, we view synonym extraction as a dictionary enrichment task that we can perform at a bilingual level.", "startOffset": 123, "endOffset": 1260}, {"referenceID": 4, "context": "As regards future work, we foresee several developments of the CQC algorithm and its applications: starting from the work of Budanitsky and Hirst (2006), we plan to experiment with cycles and quasi-cycles when used as a semantic similarity measure, and compare them with the most successful existing approaches.", "startOffset": 125, "endOffset": 153}], "year": 2012, "abstractText": "Bilingual machine-readable dictionaries are knowledge resources useful in many automatic tasks. However, compared to monolingual computational lexicons like WordNet, bilingual dictionaries typically provide a lower amount of structured information such as lexical and semantic relations, and often do not cover the entire range of possible translations for a word of interest. In this paper we present Cycles and Quasi-Cycles (CQC), a novel algorithm for the automated disambiguation of ambiguous translations in the lexical entries of a bilingual machine-readable dictionary. The dictionary is represented as a graph, and cyclic patterns are sought in this graph to assign an appropriate sense tag to each translation in a lexical entry. Further, we use the algorithm\u2019s output to improve the quality of the dictionary itself, by suggesting accurate solutions to structural problems such as misalignments, partial alignments and missing entries. Finally, we successfully apply CQC to the task of synonym extraction.", "creator": "TeX"}}}