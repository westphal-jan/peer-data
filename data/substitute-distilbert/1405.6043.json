{"id": "1405.6043", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-May-2014", "title": "Understanding model counting for $\\beta$-acyclic CNF-formulas", "abstract": "we extend specialized knowledge about so - called structural restrictions of $ \\ mathrm { \\ # ate } $ by calculating a polynomial time algorithm for $ \\ beta $ - acyclic $ \\ mathrm { \\ # abd } $. in contrast to previous algorithms in the area, our algorithm does not proceed by dynamic programming but works towards an elimination order, solving a partial version of optimization satisfaction. moreover, we give evidence that this expression from more standard algorithm is generally a violation, but that there is locally no dynamic programming instead of the usual style above $ \\ beta $ - acyclic $ \\ mathrm { \\ # sat } $.", "histories": [["v1", "Fri, 23 May 2014 12:38:18 GMT  (29kb)", "http://arxiv.org/abs/1405.6043v1", null]], "reviews": [], "SUBJECTS": "cs.CC cs.AI", "authors": ["johann brault-baron", "florent capelli", "stefan mengel"], "accepted": false, "id": "1405.6043"}, "pdf": {"name": "1405.6043.pdf", "metadata": {"source": "CRF", "title": "Understanding model counting for \u03b2-acyclic CNF-formulas", "authors": ["Johann Brault-Baron", "Florent Capelli", "Stefan Mengel"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n40 5.\n60 43\nv1 [\ncs .C\nC ]\n2 3\nM ay\n2 01\n4\nUnderstanding model counting for \u03b2-acyclic\nCNF-formulas\nJohann Brault-Baron\u2217 Florent Capelli\u2020 Stefan Mengel\u2021\nMay 26, 2014\nWe extend the knowledge about so-called structural restrictions of #SAT by giving a polynomial time algorithm for \u03b2-acyclic #SAT. In contrast to previous algorithms in the area, our algorithm does not proceed by dynamic programming but works along an elimination order, solving a weighted version of constraint satisfaction. Moreover, we give evidence that this deviation from more standard algorithm is not a coincidence, but that there is likely no dynamic programming algorithm of the usual style for \u03b2-acyclic #SAT."}, {"heading": "1. Introduction", "text": "The propositional model counting problem #SAT is, given a CNF-formula F , to count the satisfying assignments of F . #SAT is the canonical #P-complete problem and is thus central to the area of counting complexity. Moreover, many important problems in artificial intelligence research reduce to #SAT (see e.g. [Rot96]), so there is also great interest in the problem from a practical point of view.\nUnfortunately, #SAT is computationally very hard: even for very restricted CNF-formulas, e.g. monotone 2-CNF-formulas, the problem is #P-hard and in fact even #P-hard to approximate [Rot96]. Thus the focus of research in finding tractable classes of #SAT-instances has turned to so-called structural classes, which one gets by assigning a graph or hypergraph to a CNF-formula and then restricting the class of (hyper)graphs considered. The general idea is that if the (hyper)graph associated to an instance has a treelike decomposition that is \u201cnice\u201d enough, e.g. a tree decomposition of small width, then there is a dynamic programming algorithm that solves #SAT for the instance. In the recent years, there has been a push for constructing such dynamic programming algorithms for ever more general classes of graphs and hypergraphs, see e.g. [FMR08, SS10, PSS13, SS13, CDM14].\nVery recently, S\u00e6ther, Telle and Vatshelle, in a striking contribution [STV14], have introduced a new width measure for CNF-formulas, that they call PS-width. Essentially, it is a measure for how much information has to be propagated from one step to the next in a natural formalization of the known dynamic programming algorithms. In our opinion, PS-width thus gives an upper bound on how far the dynamic programming techniques from the literature can\n\u2217LSV UMR 8643, ENS Cachan and Inria, France \u2020IMJ UMR 7586 - Logique, Universite\u0301 Paris Diderot, France \u2021LIX UMR 7161, Ecole Polytechnique, France\nbe extended. Moreover, S\u00e6ther, Telle and Vatshelle have shown that if one is given a formula F and a decomposition of small PS-width, one can efficiently count the number of satisfying assignments of F . Thus they have essentially turned the construction of dynamic programming algorithms into a question of graph theory: If, for a class of formulas, one can efficiently compute decompositions that have small PS-width for all formulas having these graphs, the dynamic programming of [STV14] solves these instances. In fact, PS-width gives a uniform explanation for all structural tractability results for #SAT from the literature that we are aware of. On the other hand, since, in our opinion, the framework of [STV14] is a very good formalization of dynamic programming, there is likely no efficient dynamic programming algorithm for a class of CNF-formulas, if it does not have decompositions of small PS-width, or if these decompositions cannot be constructed efficiently.\nIn this article, we focus on \u03b2-acyclic CNF-formulas, i.e., formulas whose associated hypergraph is \u03b2-acyclic. There are several different reasonable ways of defining acyclicity of hypergraphs that have been proposed [Fag83, Dur12], and \u03b2-acyclicity is the most general acyclicity notion discussed in the literature for which #SAT could be tractable (see the discussions in [OPS13, CDM14]). The complexity of #SAT for \u03b2-acyclic formulas is interesting for several reasons: First, up to this paper, it was the only structural class of formulas for which we know that SAT is tractable [OPS13] without this directly generalizing to a tractability result for #SAT. This is because the algorithm of [OPS13] does not proceed by dynamic programming but uses resolution, a technique that is known to generally not generalize to counting. Moreover, \u03b2-acyclicity can be generalized to a width-measure [GP04], so there is hope that a good algorithm for \u03b2-acyclic formulas might generalize to wider classes for which even the status for SAT is left as an open problem in [OPS13]. Since decomposition techniques based on hypergraph acyclicity tend to be more general than graph-based techniques [GLS00], this might lead to large, new classes of tractable #SAT-instances.\nThe contribution of this paper is twofold: First, we show that #SAT on \u03b2-acyclic hypergraphs is tractable. In fact, we show that a more general counting problem which we call weighted counting for constraint satisfaction with default values, short #CSPd, is tractable on \u03b2-acyclic hypergraphs. We remark that there is another line of research on #CSP, the counting problem related to constraint satisfaction, where dichotomy theorems for weighted #CSP depending on fixed constraint languages are proven, see e.g. [BDG+12, CC12]. We do not assume that the relations of our instances are fixed but we consider them as part of the input. Thus our results and those on fixed constraint languages are completely unrelated. Instead, the structural restrictions we consider are similar to those considered e.g. in [DJ04], but since we allow clauses, resp. relations, of unbounded arity, our results and those of [DJ04] are incomparable.\nWe note that our algorithm is in style very different from the algorithms for structural #SAT in the literature. Instead of doing dynamic programming along a decomposition, we proceed along a vertex elimination order which is more similar to the approach to SAT in [OPS13]. But in contrast to using well-understood resolution techniques, we develop from scratch a procedure to update the weights of our #CSPd instance along the elimination order. Our algorithm is non-obvious and novel, but it is relatively easy to write down and its correctness is easy to prove. Indeed most of the work in this paper is spent on showing the polynomial runtime bound which requires a thorough understanding of how the weights of instances evolve during the algorithm.\nOur second contribution is that we show that our tractability result is not covered by the framework of S\u00e6ther, Telle and Vatshelle [STV14], short STV-framework, which\u2014as we show\u2014 covers all other known structural tractability results for #SAT. We do this by showing that \u03b2-acyclic #SAT-instances may have a PS-width so high that from [STV14] we cannot even get subexponential runtime bounds. This can be seen as an explanation for why the algorithm for\n\u03b2-acyclic #SAT is so substantially different from the algorithms from the literature. If one accepts the framework of [STV14] as a good formalization of dynamic programming\u2014which we do\u2014then the deviation from the usual dynamic programming paradigm is not a coincidence but instead due to the fact that there is no efficient dynamic programming algorithm in the usual style. Thus, our algorithm indeed introduces a new algorithmic technique for #SAT that allows the solution of instances that could not be solved with techniques known before."}, {"heading": "2. Preliminaries and notation", "text": ""}, {"heading": "2.1. Weighted counting for constraint satisfaction with default values", "text": "Let D and X be two sets. DX denotes the set of functions from X to D. We think of X as a set of variables and of D as a domain, and thus we call a \u2208 DX an assignment to the variables X. A partial assignment to the variables X is a mapping in DY where Y \u2286 X. If a \u2208 DX and Y \u2286 X, we denote by a|Y the restriction of a onto Y . For a \u2208 D\nX and b \u2208 DY , we write a \u223c b if a|X\u2229Y = b|X\u2229Y and if a \u223c b, we denote by a \u222a b the mapping in D\nX\u222aY with (a \u222a b)(x) = a(x) if x \u2208 X and (a \u222a b)(x) = b(x) otherwise. Let a \u2208 DX , y /\u2208 X and d \u2208 D. We write a\u2295y d := a \u222a {y 7\u2192 d}.\nDefinition 1. A weighted constraint with default value c = (f, \u00b5) on variables X and domain D is a function f : S \u2192 Q+ with S \u2286 D\nX and \u00b5 \u2208 Q+. S = supp(c) is called the support of c, \u00b5(c) = \u00b5 its default value and we denote by var(c) = X the variables of c. We define the size |c| of the constraint c to be |c| := |S| \u00b7 |var(c)|. The constraint c naturally induces a total function on DX , also denoted by c, defined by c(a) = f(a) if a \u2208 S and c(a) = \u00b5 otherwise.\nObserve that we do not assume var(c) to be non-empty. A constraint whose set of variables is empty has only one possible value in its support: the value associated to the empty assignment (the assignment that assigns no variable).\nSince we only consider weighted constraints with default value in this paper, we will only say weighted constraint where the default value is always implicitly understood. Note that we have to restrict ourselves to non-negative weights, because non-negativity will be crucial in the proofs. This is not a problem in our context, non-negative numbers are sufficient to encode #SAT as we will see in Section 2.3.\nDefinition 2. The problem #CSPd is the problem of computing, given a finite set I of weighted constraints on domain D, the partition function\nw(I) = \u2211\na\u2208Dvar(I)\n\u220f\nc\u2208I\nc(a| var(c)),\nwhere var(I) := \u22c3\nc\u2208I var(c). The size \u2016I\u2016 of a #CSPd-instance I is defined to be \u2016I\u2016 := \u2211 c\u2208I |c|. Its structural size s(I)\nof I is defined to be s(I) := \u2211\nc\u2208I |var(c)|.\nNote that the size of an instance as defined above roughly corresponds to that of an encoding in which the non-default values, i.e., the values on the support, are given by listing the support and the associated values in one table for each relation. We consider this convention as very natural and indeed it is near to the conventions in database theory and artificial intelligence.\nGiven an instance I, it will be useful to refer to subinstances of I, that is a set J \u2286 I. We will also refer to partition function of subinstances under some partial assignment, that is, the\npartition function of J where some of its variables are forced to a certain value. To this end, for a \u2208 DW , with W \u2286 var(I), and J \u2286 I with V \u2032 = var(J) we define\nw(J, a) := \u2211\nb\u2208DV \u2032\na\u223cb\n\u220f\nc\u2208J\nc(b| var(c)).\nWe use the following straightforward observation throughout this paper\nw(J, a) = \u2211\nb\u2208DV \u2032\\W\n\u220f\nc\u2208J\nc((a \u222a b)| var(c))."}, {"heading": "2.2. Graphs and hypergraphs associated to CNF-formulas", "text": "We use standard notation for graphs which can e.g. be found in [Die05]. A hypergraph H = (V,E) consists of a finite set V and a set E of non-empty subsets of V . The elements of V are called vertices while the elements of E are called edges. As usual for graphs, we sometimes denote the vertex set of a hypergraph H by V (H) and the edge set of H by E(H). The size of a hypergraph is defined to be \u2016H\u2016 = \u2211 e\u2208E(H) |e|.\nA subhypergraph H\u2032 of a hypergraphH is a hypergraph such that V (H\u2032) \u2286 V (H) and E(H\u2032) \u2286 {e \u2229 V (H\u2032) | e \u2208 E(H), e \u2229 V (H\u2032) 6= \u2205}. For S \u2286 V (H), the induced subhypergraph of H by S is the hypergraph H[S] = (S, {e \u2229 S | e \u2208 E(H)} \\ {\u2205}). We denote by H \\ S the hypergraph H[V (H) \\ S]. If S contains only one vertex v, we also write H \\ v for H \\ {v}.\nWe are interested in structural restrictions of the problem #CSPd. What we mean by structural restriction is that we restrict the way the variables interact in the different constraints. To formalize this notion, we introduce the hypergraph associated to an instance of #CSPd: The hypergraph H(I) associated to #CSPd-instance I is the hypergraph H(I) := (var(I), EI) where EI := {var(c) | c \u2208 I}. The hypergraph of a CNF-formula is defined as H(F ) := (var(F ), EF ) where EF := {var(C) | C \u2208 cla(F )} where var(F ) denotes the set of variables of F and cla(F ) denotes the set of clauses of F .\nThe incidence graph I(H) of a hypergraph H = (V,E) is the bipartite graph with the vertex set V \u222aE and an edge between v \u2208 V, e \u2208 E if and only if v \u2208 e. Similarly, the incidence graph I(F ) of a CNF-formula F has the vertex set var(F )\u222a cla(F ) and x \u2208 var(F ) and C \u2208 cla(F ) are connected by an edge if and only if x appears in C.\n2.3. Relation to #SAT\nWe show in this section how we can encode #SAT into #CSPd-instances with the same hypergraphs.\nThe problem SAT differs from the classical CSP framework in the way the constraints are represented. Classically, in CSP, all the solutions to a constraint are explicitly listed. For a CNF-formula however, each clause with n variables has 2n \u2212 1 solutions, which would lead to a CSP-representation exponentially bigger than the CNF-formula. One way of dealing with this is encoding CNF-formulas into CSP-instances by listing all assignments that are not solution of a constraint, see e.g. [CGH09]. In this encoding, each clause has only one counter-example and the corresponding CSP-instance is roughly of the same size as the CNF-formula.\nThe strength of the CSP with default values is that it can easily embed both representations. This leads to a polynomial reduction of #SAT to #CSPd.\nLemma 3. Given a CNF-formula F one can construct in polynomial time a #CSPd-instance I on variables var(F ) and domain {0, 1} such that\n\u2022 H(F ) = H(I),\n\u2022 for all a \u2208 {0, 1}var(F ), a is a solution of F if and only if w(I, a) = 1, and otherwise w(I, a) = 0, and\n\u2022 s(I) = \u2016I\u2016 = |F |.\nProof. For each clause C of F , we define a constraint c with default value 1 whose variables are the variables of C and such that supp(c) = {a} and c(a) = 0, where a is the only assignment of var(C) that is not a solution of C. It is easy to check that this construction has the above properties."}, {"heading": "2.4. \u03b2-acyclicity of hypergraphs", "text": "In this section we introduce the characterizations of \u03b2-acyclicity of hypergraphs we will use in this paper. We remark that there are many more characterizations, see e.g. [BLS99, Bra14].\nDefinition 4. Let H be a hypergraph. A vertex x \u2208 V (H) is defined to be a nest point if {e \u2208 E(H) | x \u2208 e} forms a sequence of sets increasing for inclusion, that is {e \u2208 E(H) | x \u2208 e} = {e1, . . . , ek} with ei \u2286 ei+1 for i \u2208 {1, . . . , k \u2212 1}.\nA \u03b2-elimination order for H is defined inductively as follows:\n\u2022 If H = \u2205, then only the empty tuple is a \u03b2-elimination order for H.\n\u2022 Otherwise, (x1, . . . , xn) is a \u03b2-elimination for H if x1 is a nest point of H and (x2, . . . , xn) is a \u03b2-elimination order for H \\ x1. A hypergraph H called \u03b2-acyclic if and only if there exists a \u03b2-elimination order for H.\nIt is easy to see that one can test \u03b2-acyclicity of a graph in polynomial time and that one can compute a \u03b2-elimination order efficiently if it exists.\nWe will also make use of another equivalent characterization of \u03b2-acyclic hypergraphs. A graph G is defined to be chordal bipartite if it is bipartite and every cycle of length at least 6 in G has a chord.\nTheorem 5 ([ADM86]). A hypergraph is \u03b2-acyclic if and only if its incidence graph is chordal bipartite.\nWe say that a #CSPd-instance I is \u03b2-acyclic if H(I) is \u03b2-acyclic and we use an analogous convention for #SAT. Note that the incidence graph of an instance I and that of its hypergraph in general do not coincide, because I might contain several constraints with the same sets of variables. But with Theorem 5, it is not hard to see that the incidence graph of an instance I is chordal bipartite if and only if the incidence graph of the hypergraph of I is chordal bipartite, so we can interchangeably use both notions of incidence graphs in this paper without changing the class of instances.\nCorollary 6. #SAT is polynomial time reducible to #CSPd. Moreover, #SAT restricted to \u03b2-acyclic formulas is polynomial time reducible to #CSPd restricted to \u03b2-acyclic instances.\nProof. Taking the construction of Lemma 3, it is clear that the number of solution of F is equal to w(I). The rest follows from the fact that the hypergraph remains unchanged during the reduction."}, {"heading": "2.5. Width measures of graphs and CNF-Formulas", "text": "In this section we introduce several width measures on graphs and CNF-formulas that are used when relating our algorithm for \u03b2-acyclic #CSPd to the framework of S\u00e6ther, Telle and Vatshelle [STV14]. Readers only interested in the algorithmic part of this paper may safely skip to Section 3.\nWe consider several width notions that are mainly defined by branch decompositions. For an introduction into this area and many more details see [Vat12]. For a tree T we denote by L(T ) the set of the leaves of T . A branch decomposition (T, \u03b4) of a graph G = (V,E) consists of a subcubic tree T , i.e., a tree in which every vertex has at most degree 3, and a bijection \u03b4 between L(T ) and V . For convenience we often identify L(T ) and V . Moreover, it is often convenient to see a branch decomposition as rooted tree, and as this does not change any of the notions we define (see [Vat12]), we generally follow this convention. For every x \u2208 V (T ) we define Tx be the subtree of T rooted in x. From x we get a partition or cut of V into two sets defined by (L(Tx), V \\ L(Tx)). For a set X \u2286 V we often write X\u0304 for V \\X.\nGiven a symmetric function f : 2V \u00d72V \u2192 R we define the f -width of a branch decomposition (T, \u03b4) to be maxx\u2208V (T ) f(L(Tx), V \\L(Tx)), i.e., the f -width is the maximum value of f over all cuts of the vertices of T . The f -branch width of a graph G is defined as the minimum f -width of all branch decompositions of G.\nGiven a graph G = (V,E) and a cut (X, X\u0304) of V , we define G[X, X\u0304 ] to be the graph with vertex set V and edge set {uv | u \u2208 X, v \u2208 X\u0304, uv \u2208 E}.\nWe will use at several places the well-known notion of treewidth of a graph G, denoted by tw(G). Instead of working with the usual definition of treewidth (see e.g. [Bod93]), it is more convenient for us to work with the strongly related notion of Maximum-Matching-width (short MM-width) introduced by Vatshelle [Vat12]. The MM-width of a graph G, denoted by mmw(G), is defined as the f -branch width of G for the function f that, given a cut (X, X\u0304) of G, computes the size of the maximum matching of G[X, X\u0304 ]. MM-width and treewidth are linearly related [Vat12, p. 28].\nLemma 7. Let G be a graph, then 13 (tw(G) + 1) \u2264 mmw(G) \u2264 tw(G) + 1.\nAnother width measure of graphs that we will use extensively is Maximum-Induced-Matchingwidth (short MIM-width): The MIM-width of a graph G, denoted by mimw(G), is defined as the f -branch width of G for the function f that, given a cut (X, X\u0304) of G, computes the size of the maximum induced matching of G[X, X\u0304 ].\nGiven a CNF-formula F , we say that a set of clauses C \u2286 cla(F ) is precisely satisfiable if there is an assignment to F that satisfies all clauses in C and no clause in cla(F ) \\ C. The PS-value of F is defined to be the number of precisely satisfiable subsets of cla(F ). Let F be a CNF-formula, X \u2286 var(F ) and C \u2286 cla(F ). Then we denote by FX,C the formula we get from F by deleting first every clause not in C and then every variable not in X.\nLet I(F ) be the incidence graph of F and let (A, A\u0304) be a cut of I(F ). Let X := var(F ) \u2229 A, X\u0304 := var(F ) \u2229 A\u0304, C := cla(F ) \u2229 A and C\u0304 := cla(F ) \u2229 A\u0304. Let ps(A, A\u0304) be the maximum of the PS-values of FX,C\u0304 and FX\u0304,C . Then the PS-width of a branch decomposition (T, \u03b4) of G is defined as the ps-branch width of (T, \u03b4). Moreover, the PS-width of F , denoted psw(F ), is defined to be the ps-branch width of I(F ).\nLet us try to give an intuition why we believe that PS-width is a good notion to model the limits of tractable dynamic programming for #SAT: The dynamic programming algorithms in the literature typically proceed by cutting instances into subinstances and then iteratively solving the instance along these cuts. During this process, some information has to be propagated\nbetween the subinstances. Intuitively, a minimum amount of such information is which sets of clauses are already satisfied by certain assignments and which clauses still have to be satisfied later in the process. In doing this, the individual clauses can be \u201cbundled together\u201d if they are satisfied by an assignment simultaneously. The number such bundles is exactly the PS-width of a cut, so we feel that PS-width is a good formalization of the minimum amount of information that has to be propagated during dynamic programming in the style of the algorithms from the literature.\nNot only is PS-width in our opinion a good measure for the limits of dynamic programming, but S\u00e6ther, Telle and Vatshelle also showed that it allows tractable solving of #SAT.\nTheorem 8 ([STV14]). Given a CNF-formula F of n variables and m clauses and of size s, and a branch decomposition (T, \u03b4) of the incidence graph I(F ) of F with PS-width k, one can count the number of satisfying assignments of F in time O(k3s(m+ n)).\nWe admit that the intuition explained above is rather vague and informal, so the reader might or might not share it, but we stress that it is supported more rigorously by the fact that all known tractability results from the literature that were shown by dynamic programming can be explained by a combination of PS-width and Theorem 8.\nS\u00e6ther, Telle and Vatshelle showed the following connection between the PS-width of a CNFformula F and the MIM-width of the incidence graph G of F .\nTheorem 9 ([STV14]). For any CNF-formula F over m clauses, any branch decomposition of the incidence graph I(F ) of F with MIM-width k has PS-width at most mk.\nTheorem 9 and Theorem 8 essentially turn finding structural classes of tractable #SATinstances into a problem of graph theory: it suffices to show that certain classes of formulas have sufficiently small MIM-width or PS-width to show that they are tractable. We will see that all tractability results from the literature can be explained this way. Unfortunately, deciding if a class of formulas has small MIM-width or PS-width seems to be tricky. In fact, even the complexity of deciding if a given graph has MIM-width 1 in polynomial time is left as an open problem in [Vat12]."}, {"heading": "3. The algorithm and its correctness", "text": "In this section we describe an algorithm that, given an instance I of #CSPd on domain D and a nest point x of H(I), constructs in a polynomial number of arithmetic operations an instance I \u2032 such that H(I \u2032) = H(I) \\ x, \u2016I \u2032\u2016 \u2264 \u2016I\u2016 and w(I) = |D|w(I \u2032). We then explain that if I is \u03b2-acyclic, we can iterate the procedure to compute w(I) in a polynomial number of arithmetic operations.\nIn the following, for x \u2208 var(I), we denote by I(x) = {c \u2208 I | x \u2208 var(c)}.\nTheorem 10. Let I be a set of weighted constraints on domain D and x a nest point of H(I). Let I(x) = {c1, . . . , cp} with var(c1) \u2286 . . . \u2286 var(cp). Let I \u2032 = {c\u2032 | c \u2208 I} where\n\u2022 if c /\u2208 I(x) then c\u2032 := c\n\u2022 if c = ci, then c \u2032 i := (f \u2032 i , \u00b5) is the weighted constraint on variables var(c \u2032 i) = var(c) \\ {x},\nwith default value \u00b5(ci) and supp(c \u2032 i) := {a \u2208 D var(c\u2032i) | \u2203d \u2208 D, (a \u2295x d) \u2208 supp(ci)}. Moreover, for all a \u2208 supp(c\u2032i), let Pi(a, d) := \u220fi j=1 cj((a \u2295x d)|var(cj)) and P0(a, d) = 1. We define:\nf \u2032i(a) :=\n\u2211 d\u2208D Pi(a, d)\u2211\nd\u2208D Pi\u22121(a, d)\nif \u2211\nd\u2208D Pi\u22121(a, d) 6= 0 and f \u2032 i(a) := 0 otherwise.\nThen H(I \u2032) = H(I) \\ x, \u2016I \u2032\u2016 \u2264 \u2016I\u2016 and w(I) = |D|w(I \u2032). Moreover, one can compute I \u2032 with a O(p\u2016I(x)\u2016) arithmetic operations.\nProof. First, we explain why I \u2032 is well-defined. As x is a nest point, we can write I(x) = {c1, . . . , cm} with var(c1) \u2286 . . . \u2286 var(cm). If two constraints have the same variables, we choose an arbitrary order for them. Note that in Section 4 we will choose a specific order that ensures that the algorithm runs in polynomial time on a RAM, but in this proof any order will do. Finally, remark that Pi(a, d) is well defined since for a \u2208 supp(c \u2032 i), d \u2208 D and j \u2264 i, (a \u2295x d) assigns all variables of cj since var(cj) \u2286 var(ci). Thus writing cj((a\u2295x d)|var(cj)) is correct. We insist on the fact that it is only because x is a nest point that this definition works.\nH(I \u2032) = H(I) \\ x is obvious because for a constraint in I with variable set V , there exists a constraint in I \u2032 with variable set V \\ {x}.\n\u2016I \u2032\u2016 \u2264 \u2016I\u2016 because for all c \u2208 I, |c\u2032| \u2264 |c| since |{a \u2208 Dvar(c \u2032) | \u2203d \u2208 D, (a\u2295x d) \u2208 supp(c)}| \u2264\n|supp(c)|. We now show by induction on i that for all a \u2208 Dvar(c \u2032 i),\n|D| i\u220f\nj=1\nc\u2032j(a) = \u2211\nd\u2208D\nPi(a, d).\nFor i = 1, let a \u2208 Dvar(c \u2032 1). If a \u2208 supp(c\u20321), then by definition:\nc\u20321(a) = \u2211 d\u2208D P1(a, d)\u2211 d\u2208D P0(a, d) .\nSince P0(a, d) = 1 for all d, we have the expected result. If a /\u2208 supp(c\u20321), then for all d, a\u2295x d /\u2208 supp(c1). Thus P1(a, d) = \u00b51 for all d and finally\n\u2211\nd\u2208D\nP1(a, d) = |D|\u00b51 = |D|c \u2032 1(a).\nNow suppose that the result holds for i. Let a \u2208 Dvar(c \u2032 i). Then we get by induction\n|D| i+1\u220f\nj=1\nc\u2032j(a) = ( \u2211\nd\u2208D\nPi(a, d))c \u2032 i+1(a).\nFirst, assume that \u2211\nd\u2208D Pi(a, d) = 0. Since this sum is a sum of positive rationals, we have that for all d, Pi(a, d) = 0. Thus, Pi+1(a, d) = 0 for all d, that is \u2211 d\u2208D Pi+1(a, d) = 0 which confirm the induction hypothesis. Now assume that \u2211 d\u2208D Pi(a, d) 6= 0. If a \u2208 supp(c \u2032 i+1), by definition of c \u2032 i+1, the induction hypothesis trivially holds. If a /\u2208 supp(ci+1), we have Pi+1(a, d) = \u00b5i+1Pi(a, d) for all d. Thus \u2211 d\u2208D Pi+1(a, d) =\n\u00b5i \u2211 d\u2208D Pi(a, d) = c \u2032 i+1(a) \u2211 d\u2208D Pi(a, d) which establish the induction hypothesis for i+ 1.\nApplying the result for i = p, we find:\n|D| \u220f\nc\u2208I(x)\nc\u2032(a) = \u2211\nd\u2208D\n\u220f\nc\u2208I(x)\nc((a \u2295x d)|var(c))\nNow, it is sufficient to remark that for c /\u2208 I(x), for all d \u2208 D, c((a\u2295x d)|var(c)) = c(a|var(c)) = c\u2032(a|\nvar(c)) since x /\u2208 var(c) and c = c \u2032. Thus:\n|D|w(I \u2032) = \u2211\na\u2208Dvar(I)\\{x}\n\u2211\nd\u2208D\n\u220f\nc\u2208I\u2032\nc((a\u2295x d)|var(c)) = w(I).\nWe now analyze the number of arithmetic operations we make in the construction of I \u2032. Clearly, if we have computed the \u2211 d\u2208D Pi(a, d) for all i \u2264 p and a \u2208 supp(c \u2032 i) then we can compute c\u2032i(a) with one division. Thus we need to do p divisions. Now remark that if we have computed Pi(a, d), then we only need one more multiplication to compute Pi+1(a, d).\nNow, we prove by induction on i that Pi(a, d) could take at least 1+ \u2211i\nj=1 |cj | different values. It is trivial for i = 0. Now remark that if a \u2295x d /\u2208 supp(ci), then Pi(a, d) = \u00b5iPi\u22121(a, d), thus by induction, it gives 1+ \u2211i\u22121 j=1 |cj | different values for Pi. And there is at most |supp(ci)| \u2264 |ci| other values for a\u2295x d \u2208 supp(ci), which prove the induction. In the end, we have to compute at most O(p \u00d7 \u2016I(x)\u2016) different values for the Pi which can be done with a O(p \u00d7 \u2016I(x)\u2016) multiplications. Now if i is fixed, for all a, \u2211\nd\u2208D Pi(a, d)\nhave at most 1 + \u2211i\nj=1 |cj | different terms that are already computed. Thus we only need O(\u2016I(x)\u2016) operations to compute each of them. As there is p different sums to compute, we can do everything with a O(p\u2016I(x)\u2016) arithmetic operations.\nTheorem 11. If I is a \u03b2-acyclic instance of #CSPd, we can compute w(I) with a O(s(I) 2\u2016I\u2016) arithmetic operations.\nProof. We iterate the algorithm of Theorem 10 on a \u03b2-elimination order of the variables of I to transform it into an instance I\u2217. After all variables are eliminated, every constraint of I\u2217 has an empty set of variables, thus w(I\u2217) = \u220f\nc\u2208I\u2217 c(\u01eb), where \u01eb denotes the empty assignment.\nMoreover, by Theorem 10, w(I) = |D||var(I)|w(I\u2217). Thus w(I) can be computed with O(s(I)) additionnal multiplications.\nIf we denote by px = |{c \u2208 I | x \u2208 var(c)}|, we have a total complexity of \u2211\nx\u2208var(I)O(px\u2016I(x)\u2016), that is O(( \u2211 x\u2208var(I) px)|var(I)|\u2016I\u2016). It is easy to see that \u2211 x\u2208var(I) px = s(I) and since |var(I)| \u2264 s(I), we have a total number of arithmetic operations that is a O(s(I)2\u2016I\u2016)."}, {"heading": "4. Runtime analysis of the algorithm", "text": "The analysis of Theorem 11 shows that our algorithm uses only a polynomial number of arithmetic operations. Unfortunately, this does not guarantee that the algorithm runs in polynomial time on a RAM. The problem is that, due to the many multiplications and divisions, the bitsize of the new (rational) weights computed by the algorithm at each step could grow exponentially, leading to an overall superpolynomial runtime. In this section we will prove that this is in fact not the case. We will show that at each step of the algorithm, numerous cancellations occur, leading to weights of polynomial bitsize. Combining this with Theorem 11, it will follow that the algorithm runs in polynomial time."}, {"heading": "4.1. Some technical lemmas", "text": "In this section, we will show some rather technical lemmas we will use later on. Throughout this paper, we follow the convention that for all assignment a, we have w(\u2205, a) = 1. This is motivated by the following lemma.\nLemma 12. Let I be a set of weighted constraints, J \u2286 I and a a partial assignment of var(I). If w(J, a) = 0 then w(I, a) = 0.\nProof. We have w(J, a) = 0 = \u2211\nb\u2243a \u220f c\u2208J c(b|var(c)). Since every term of the sum is non-negative,\nwe have that for all b \u2243 a it holds \u220f\nc\u2208J c(b|var(c)) = 0. Thus,\nw(I, a) = \u2211\nb\u2243a\n\u220f\nc\u2208J\nc(b| var(c))\n\u220f\nc\u2208I\\J\nc(b| var(c)) = 0.\nOne key ingredient in our analysis will be understanding how two subinstances interact under a partial assignment.\nLemma 13. Let I be a set of weighted constraints on domain D, J1 \u2286 I, J2 \u2286 I and a \u2208 D W for W \u2286 var(I). Let V1 = var(J1), V2 = var(J2). If V1 \u2229 V2 \u2286 W and J1 \u2229 J2 = \u2205, then\nw(J1 \u222a J2, a) = w(J1, a)w(J2, a)\nProof. Let V = V1 \u222a V2. Since V \\ W = (V1 \\ W ) \u222a (V2 \\ W ) and this union is disjoint by definition, there is a natural bijection between DV1\\W \u00d7DV2\\W and DV \\W that associates to (b1, b2) the assignment b1\u222ab2. Moreover, if c \u2208 J1, then (b1\u222ab2)|var(c) = b1|var(c) since var(c) \u2286 V1. Similarly, for c \u2208 J2, (b1 \u222a b2)|var(c) = b2|var(c). Consequently,\nw(J1 \u222a J2, a) = \u2211\nb1\u2208DV1\\W\n\u2211\nb2\u2208DV2\\W\n\u220f\nc\u2208J1\nc((a \u222a b1)|var(c)) \u220f\nc\u2208J2\nc((a \u222a b2)|var(c))\n= w(J1, a)w(J2, a)\nCorollary 14. Let I be a set of weighted constraints on domain D, J1 \u2286 I, J2 \u2286 I and a \u2208 D W for W \u2286 var(I). Let V1 = var(J1 \\ J2), V2 = var(J2 \\ J1) and V0 = var(J1 \u2229 J2). If V0 \u2229 V1 \u2286 W and V0 \u2229 V2 \u2286 W . If w(J2, a) 6= 0, we have:\nw(J1, a) w(J2, a) = w(J1 \\ J2, a) w(J2 \\ J1, a)\nProof. First, remark that w(J2 \\ J1, a) 6= 0 by Lemma 12 since J2 \\ J1 \u2286 J2 and w(J2, a) 6= 0. Apply Lemma 13 on J1 \\ J2 and J1 \u2229 J2 for the numerator and on J2 \\ J1 and J2 \u2229 J1 for the denominator and observe that w(J1 \u2229 J2, a) cancels.\nWe will use the following corollary heavily in Section 4.\nCorollary 15. Let I be a set of weighted constraints on domain D, J1, J2, J3, J4 \u2286 I and a \u2208 DW for W \u2286 var(I). Assume that w(J3, a) 6= 0 and w(J4, a) 6= 0 and\n(i) J1 \u2229 J2 \u2286 J3 and J3 \u2229 J4 \u2286 J1,\n(ii) var(J1 \\ J3) \u2229 var(J1 \u2229 J3) \u2286 W ,\n(iii) var(J3 \\ J1) \u2229 var(J1 \u2229 J3) \u2286 W ,\n(iv) var(J1 \\ J3) \u2229 var(J2) \u2286 W , and\n(v) var(J3 \\ J1) \u2229 var(J4) \u2286 W .\nThen w(J1, a)w(J2, a)\nw(J3, a)w(J4, a) =\nw((J1 \\ J3) \u222a J2, a) w((J3 \\ J1) \u222a J4, a) .\nProof. Apply Corollary 14 on J1 and J3 and Lemma 13 on J1 \\J3 and J2 for the numerator and on J3 \\J1 and J4 for the denominator. Remark that Condition (i) ensures that (J1 \\J3)\u2229J2 = \u2205 and (J3 \\ J1) \u2229 J4 = \u2205 and that the denominator is not null because w((J3 \\ J1) \u222a J4, a) = w(J3 \\ J1, a)w(J4, a) and w(J4, a) 6= 0 by assumption and w(J3 \\ J1, a) 6= 0 by Lemma 12 and w(J3, a) 6= 0."}, {"heading": "4.2. Defining partial orders", "text": "The algorithm of Theorem 10 transforms an instance into a new one with the same number of constraints but with one variable less. In this section we will give an explicit description of the weight of a constraint c \u2208 I after k such elimination steps. In the following, I is a \u03b2-acyclic CSP-instance and {x1, . . . , xn} = var(I) is a \u03b2-elimination order of H(I). We assume that we will perform the elimination along this order. Let Xk = {x1, . . . , xk} and for c \u2208 I, we denote by c(k) the constraint c after the elimination of xk. By convention, c\n(0) = c. Remark that var(c(k)) = var(c) \\Xk.\nIn the following, we will introduce for each k, a partial order \u227ak on I. The intuition for this partial order is that for c, d \u2208 I, c \u227ak d means that d\n(k) \u201cdepends on\u201d c(0). For example, assume that x1 \u2208 var(c) \u2286 var(d). When we eliminate x1, we see\u2014in the formula of Theorem 10\u2014that the weight of c appears in the definition of d(1). Hence, we would like to have c \u227a1 d.\nTo simplify the proofs, we make one more assumption on I: If c, d \u2208 I and c 6= d, then var(c) 6= var(d). We may assume this w.l.o.g. since it is easy to merge two constraints with the same variables without increasing \u2016I\u2016. Observe that we make this assumption only on the initial instance I. During the elimination process, constraints with the same set of variables might appear, but we can easily handle them.\nDefinition 16. For two constraints c, d \u2208 I, we write c \u227a d if there exists k such that var(c) \\ Xk ( var(d) \\Xk. We write c d if c \u227a d or c = d.\nLemma 17. is a total order on I.\nProof. We first show that is antisymmetric. So let c, d be constraints such that c d and d c. By way of contradiction, assume that c 6= d, so c \u227a d and d \u227a c. By definition there are k, k\u2032 such that var(c) \\Xk ( var(d) \\Xk and var(d) \\Xk\u2032 ( var(c) \\Xk\u2032 . W.l.o.g. assume that k < k\u2032. Then var(c) \\X\u2113 \u2286 var(d) \\X\u2113 for all \u2113 \u2265 k which is a contradiction to d \u227a c. It follows that is antisymmetric.\nWe now show transitivity of . So let c, d, e \u2208 I with c d and d e. If we have c = d or d = e, then we get immediately c d. Thus we may assume that c \u227a d and d \u227a e. By definition, there exist k, \u2113 such that var(c) \\Xk ( var(d) \\Xk and var(d) \\X\u2113 ( var(e) \\X\u2113. For m := max(k, \u2113) we get var(c) \\Xm \u2286 var(d) \\Xm \u2286 var(e) \\Xm and one of these inclusions is strict. Thus var(c) \\Xm ( var(e) \\Xm, that is c \u227a e and it follows that is transitive.\nWe now show that is total. So let c, d \u2208 I. If c = d, then by definition c d. So we assume that c 6= d. Let k = max{j | xj(\u2208 var(c) \\ var(d)) \u222a (var(d) \\ var(c))}. Observe that k is well-defined, since var(d) 6= var(c) by assumption on I. Assume first that xk \u2208 var(d) \\ var(c). Then var(c) \\ var(d) \u2286 Xk\u22121 by maximality of k. It follows that var(c) \\Xk\u22121 \u2286 var(d) \\Xk\u22121 and since xk \u2208 var(d) \\Xk\u22121, we have var(c) \\Xk\u22121 ( var(d) \\Xk\u22121. Thus c \u227a d. Analogously, we get for xk \u2208 var(c) \\ var(d) that d \u227a c. Hence \u227a is total.\nDefinition 18. For k \u2208 {0, . . . , n}, we define the relation \u227ak\u2286 I \u00d7 I inductively on k as\n\u2022 \u227a0= \u2205\n\u2022 for all c, d \u2208 I, c \u227ak+1 d if and only if c \u227ak d or there exists e \u2208 I such that c k e \u227a d and xk+1 \u2208 var(d) \u2229 var(e),\nwhere we denote by c k d if c = d or c \u227ak d.\nObserve that the definition of \u227ak is compatible with the informal discussion of c \u227ak d at the beginning of this section: If d(k) depends on c(k). For k = 0, no constraint depends on another, thus \u227a0= \u2205. Then, when eliminating xk+1, if xk+1 /\u2208 var(d), then the dependencies of d do not change since d remains the same. But if xk+1 \u2208 var(d), then the weight of each constraint e whose variables are included in var(d) and xk+1 \u2208 var(e) will appear in d\n(k+1). And if e depends on c at step k, that is c \u227ak e, then d will also depend on c after the elimination of xk+1.\nWe now show some properties of \u227ak that are crucial for the understanding of how the weights of constraints interact with each other.\nLemma 19. a) (\u227ak) \u2286 (\u227ak+1).\nb) For all c, d \u2208 I, c \u227ak+1 d implies c \u227a d and var(c) \\Xk \u2286 var(d) \\Xk.\nc) ( k) is a partial order.\nProof. a) follows directly from the definition of \u227ak+1. We prove b) by induction on k. For k = 0, let c, d \u2208 I such that c \u227a1 d. Since \u227a0= \u2205, c 6\u227a0 d. Thus, by definition, there exists e such that: c 0 e \u227a d and x1 \u2208 var(c) \u2229 var(d). Again, since \u227a0= \u2205, we have c = e. Thus c \u227a d and since x1 is a nest point, var(c) \u2286 var(d), which is the induction hypothesis for k = 0 since X0 = \u2205.\nNow assume that k \u2265 0 and that the statement is true for k. Let c, d \u2208 I such that c \u227ak+1 d. If c \u227ak d, then we get from the induction hypothesis that c \u227a d and var(c)\\Xk\u22121 \u2286 var(d)\\Xk\u22121. This directly yields var(c) \\ Xk \u2286 var(d) \\ Xk. Now, if c 6\u227ak d, then there exists e such that c k e, e \u227a d and xk+1 \u2208 var(e)\u2229var(d). By induction c e and thus c \u227a d since \u227a is transitive by Lemma 17. As xk+1 is a nest point after eliminating Xk, we have var(e) \\Xk \u2286 var(d) \\Xk. By induction we get var(c) \\Xk \u2286 var(e) \\Xk and thus var(c) \\Xk \u2286 var(d) \\Xk as desired.\nFor c), observe that k reflexive by definition. Furthermore, k is antisymmetric since it is a subrelation of the order \u227a by b). It remains to show that \u227ak is transitive. We do this by induction on k. The case k = 0 is trivial since (\u227a0) = \u2205. Now suppose that (\u227ak) is transitive for k \u2265 0. Let c, d, e \u2208 I such that c \u227ak+1 d and d \u227ak+1 e. If c \u227ak d \u227ak e, then by induction c \u227ak e and then c \u227ak+1 e since (\u227ak) \u2286 (\u227ak+1).\nNow assume that c 6\u227ak d. Then by definition, there exists c \u2032 such that c k c \u2032 \u227a d and xk+1 \u2208 var(c \u2032)\u2229 var(d). Since d \u227ak+1 e, we also have c \u2032 \u227a e and xk+1 \u2208 var(d)\\Xk \u2286 var(e)\\Xk. Thus xk+1 \u2208 var(c \u2032) \u2229 var(e) and c k c\n\u2032 \u227a e, that is c \u227ak+1 e. Finally assume that c \u227ak d and d 6\u227ak e. Since d \u227ak+1 e, there exists d \u2032 such that d k d \u2032 \u227a e\nand xk+1 \u2208 var(d \u2032) \u2229 var(e). By induction, (\u227ak) is transitive. Thus c \u227ak d \u2032 \u227a e and xk+1 \u2208 var(d\u2032) \u2229 var(e). That is c \u227ak+1 e.\nAgain, from our intuitive understanding of \u227ak, the transitivity is obvious: if d (k) depends on c(k) and e(k) depends on d(k), then e(k) should depend on c(k). An other informal observation is that if c and d have no common dependencies at step k, then they should not share a variable in Xk since sharing a nest point automatically induces a dependency:\nLemma 20. For all c, d \u2208 I, if c \u227a d but c 6\u227ak d, then var(c) \u2229 var(d) \u2229Xk = \u2205.\nProof. By way of contradiction. If for j \u2264 k, xj \u2208 var(c) \u2229 var(d) \u2229 Xk then c j c \u227a d and xj \u2208 var(c) \u2229 var(d). That is c \u227aj d and by Lemma 19 we get c \u227ak d.\nWe need one final property: if d \u227a e both depend on c at step k, then these dependencies were induced by the elimination of at most two nest points. During the elimination of the second nest point, e will get both the dependencies of c but also the dependencies of d. Thus e should depend on d. This is formalized by the following lemma:\nLemma 21. Let c, d, e \u2208 I. If c \u227ak d, c \u227ak e and d \u227a e then d \u227ak e.\nProof. The proof is by induction on k. The case k = 0 is trivial since the precondition cannot hold. Assume the result holds for k \u2265 0 and let c, d, e \u2208 I be constraints such that c \u227ak+1 d, c \u227ak+1 e and d \u227a e. If both c \u227ak d and c \u227ak e, then the induction gives d \u227ak e thus d \u227ak+1 e.\nOtherwise, assume that c 6\u227ak d and c 6\u227ak e. Then by definition xk+1 \u2208 var(d) \u2229 var(e). Since d \u227a e, it gives d \u227ak+1 e.\nNow assume c 6\u227ak d but c \u227ak e. By definition, there exists c \u2032 such that c k c \u2032 \u227a d and xk+1 \u2208 var(c \u2032) \u2229 var(d). Since c\u2032 \u227a d \u227a e, we have c\u2032 \u227a e and by induction c \u227ak c \u2032 and c \u227ak e gives c\u2032 \u227ak e. Thus xk+1 \u2208 var(e) and d \u227ak+1 e. Finally assume that c \u227ak d but c 6\u227ak e. By definition, there exists c \u2032 such that c k c \u2032 \u227a e and xk+1 \u2208 var(c \u2032) \u2229 var(e). As in the previous case, by induction, we can deduce that d k c \u2032 or c\u2032 \u227ak d. Both cases lead to d \u227ak+1 e.\nWe now define for every k and every constraint c a subinstance Ik(c) of I that intuitively contains the relations of I that have an influence on the weights of c after the first k variables have been eliminated.\nDefinition 22. For every k \u2208 {0, . . . , n} and c \u2208 I we define Ik(c) := {d \u2208 I | d k c}.\nWe will now prove a lemma that helps us understand how Ik(c) is evolving during the algorithm. Again, the behaviour is intuitively very natural: If xk+1 /\u2208 var(c), then c will have no new dependencies, thus Ik+1(c) = Ik(c). If xk+1 \u2208 var(c) however, c will take all the dependencies of the constraints d such that xk+1 \u2208 var(d) and d \u227a c.\nLemma 23. For k \u2264 0, if xk+1 /\u2208 var(c) then Ik+1(c) = Ik(c). Otherwise, let I(xk+1) := {c1, . . . , cm} with c1 \u227a . . . \u227a cm. Then we have\nIk+1(c1) = Ik(c1)\nand for i < m Ik+1(ci+1) = Ik(ci+1) \u222a Ik+1(ci).\nProof. First, assume that xk+1 /\u2208 var(c). Since (\u227ak) \u2286 (\u227ak+1) by Lemma 19, it follows that Ik(c) \u2286 Ik+1(c). Now, if d \u2208 Ik+1(c) and d 6= c, then either d \u227ak c or there exists e such that d k e \u227a c and xk+1 \u2208 var(c) \u2229 var(e). Since xk+1 /\u2208 var(c), we necessarily have d \u227ak c, that is d \u2208 Ik(c). This implies Ik(c) = Ik+1(c).\nFor the second equality, Ik(c1) \u2286 Ik+1(c1) still follows from Lemma 19. For the other direction, consider d \u2208 Ik+1(c1), that is d k+1 c1. By way of contradiction, assume that d 6 k c. By definition of \u227ak+1, there exists e \u2208 I such that d k e \u227a c1 and xk+1 \u2208 var(e). However, by definition, c1 is the minimal constraint with respect to whose variables contain xk+1. Thus such an e \u2208 I cannot exist. Consequently, d \u2208 Ik(c1) and it follows Ik+1(c1) = Ik(c1).\nNow fix i < m. By definition of ci+1, we have xk+1 \u2208 var(ci+1). We first prove that Ik(ci+1)\u222a Ik+1(ci) \u2286 Ik+1(ci+1). By Lemma 19 again, Ik(ci+1) \u2286 Ik+1(ci+1). Now let d \u2208 Ik+1(ci). We have ci k ci \u227a ci+1 and xk+1 \u2208 var(ci) \u2229 var(ci+1) and thus, by definition of \u227ak+1 this implies ci \u227ak+1 ci+1. This yields d k+1 ci \u227ak+1 ci+1 and thus d \u2208 Ik+1(ci+1).\nFinally, we prove that Ik+1(ci+1) \u2286 Ik(ci+1) \u222a Ik+1(ci). So let d \u2208 Ik+1(ci+1). If d k ci+1, then, by definition, we have d \u2208 Ik(ci+1). So assume now that d 6 k ci+1. By definition of \u227ak+1, there exists e such that d k e \u227a ci+1 and xk+1 \u2208 var(e) \u2229 var(ci+1). Since xk+1 \u2208 var(e) and e \u227a ci+1, it follows that e = cj for a j < i+1. If j = i, then d k e = ci and thus d k+1 ci which implies d \u2208 Ik+1(ci). Otherwise, j < i and we have d k cj \u227a ci and xk+1 \u2208 var(cj) \u2229 var(ci), which gives d \u227ak+1 ci. Thus d \u2208 Ik+1(ci) as well."}, {"heading": "4.3. Proof of the runtime bound", "text": "In this section, we will prove that for each c \u2208 I and a an assignment of var(c(k)), c(k)(a) is proportional to\nw(Ik(c), a)\nw(Ik(c) \\ {c}, a) .\nSince Ik(c) is a subinstance of I, the bitsize of the computed rational number is polynomial in the size of the input. Thus, it will follow that the weight of c(k) is a rational number of polynomial bitsize and thus all arithmetic operations of the algorithm can be done in polynomial time.\nRemember that by convention w(\u2205, a) = 1 and that for x \u2208 var(I), I(x) = {c \u2208 I | x \u2208 var(c)}.\nLemma 24. Let k \u2265 0 and I(xk+1) = {c1, . . . , cm} with c1 \u227a . . . \u227a cm. For all j \u2264 m and a : var(cj) \\Xk \u2192 D we have\nj\u220f\ni=1\nw(Ik(ci), a)\nw(Ik(ci) \\ {ci}, a) =\nw(Ik+1(cj), a)\nw(Ik+1(cj) \\ {c1, . . . , cj}, a) .\nProof. The proof is by induction on j. For j = 1, it is a consequence of Lemma 23 since Ik+1(c1) = Ik(c1). Assume the result holds for j \u2265 1. Fix a : var(cj+1) \\ Xk \u2192 D. Observe first that by Lemma 19 we have var(ci) \\Xk \u2286 var(cj+1) \\Xk for i \u2264 j (this could alternatively be seen from the fact that xk+1 is a nest point after removing x1, . . . , xk). Thus we can use induction for a and get\nj+1\u220f\ni=1\nw(Ik(ci), a)\nw(Ik(ci) \\ {ci}, a) =\nw(Ik+1(cj), a)\nw(Ik+1(cj) \\ {c1, . . . , cj}, a)\nw(Ik(cj+1), a)\nw(Ik(cj+1) \\ {cj+1}, a) .\nWe will apply Corollary 15 with J1 := Ik+1(cj), J2 := Ik(cj+1), J3 := Ik(cj+1) \\ {cj+1} and J4 := Ik+1(cj) \\ {c1, . . . , cj} and W := var(cj+1) \\Xk.\nObserve that by Lemma 23 and by the fact that J3 \u2286 J2, (J1 \\J3)\u222aJ2 = J1\u222aJ2 = Ik+1(cj+1). Moreover, (J3 \\ J1)\u222a J4 = (J3 \\ J1)\u222a (J1 \\ {c1, . . . , cj}) = (J1 \u222a J3) \\ {c1, . . . , cj} = Ik+1(cj+1) \\ {c1, . . . , cj+1} since cj+1 /\u2208 J1. Hence, if the conditions of Corollary 15 are met, the lemma will follow.\nWe now verify each conditions of Corollary 15:\n(i) if c \u2208 J1 \u2229 J2, then c k+1 cj+1 (it is in J2) and c 6= cj+1 since c cj \u227a cj+1. Thus c \u2208 J3. Moreover J4 \u2286 J1, thus J3 \u2229 J4 \u2286 J1.\n(ii) since J3 \u2286 J2, this condition is implied by condition (iv).\n(iii) Let c \u2208 J3 \\ J1 and d \u2208 J1. Since both c \u2208 J3 and d \u2208 J1, we have c \u227ak cj+1 and d \u227ak+1 cj \u227ak+1 cj+1. By Lemma 19, var(c) \\Xk \u2286 W and var(d) \\Xk \u2286 W .\nWe claim that c and d are incomparable with respect to \u227ak.\nFirst, if c \u227ak d, then c \u227ak+1 d \u227ak+1 cj that is c \u2208 J1 which is a contradiction. Consequently, c \u2280k d.\nNow, if d \u227ak c, then d \u227ak+1 c and d \u227ak+1 cj. Thus, since c 6 k+1 cj , we have cj \u227ak+1 c \u227ak+1 cj+1 thus cj \u227a c \u227a cj+1. We have that xk+1 \u2208 var(cj), and by Lemma 19 b) we get xk+1 \u2208 var(c). But this contradicts the definition of cj as the maximal constraint with respect to that is less than cj+1 and holds xk+1. Hence this is a contradiction and we get d \u2280 c.\nThus, c and d are indeed incomparable with respect to \u227ak. Since \u227a is a total order we have either d \u227a c or c \u227a d and thus by Lemma 20 we have var(c) \u2229 var(d) \u2229 Xk = \u2205. Since by Lemma 19 b) we have that var(c) \\Xk \u2286 var(cj+1) and var(d) \\Xk \u2286 var(cj+1), it follows that var(c) \u2229 var(d) \u2286 W . Since this is true for all combinations of c and d, it follows that var(J3 \\ J1) \u2229 var(J1 \u2229 J3) \u2286 W as desired.\n(iv) let c \u2208 J1 \\J3 and d \u2208 J2. We have c \u227ak+1 cj and d k cj+1. By Lemma 19, var(c) \\Xk \u2286 var(cj) \\Xk \u2286 W and var(d) \\Xk \u2286 W .\nWe again show that c and d are incomparable with respect to \u227ak.\nIf c \u227ak d, we get with d k cj+1 and transitivity c \u227ak cj+1. Thus c \u2208 J3 which is a contradiction. Consequently, c \u2280k d.\nNow assume that d \u227ak c. We have c \u227a cj \u227a cj+1 and d k cj+1 and thus with Lemma 21 we get c \u227ak cj+1. But then c \u2208 J3 which is a contradiction again.\nThus c and d are indeed incomparable with respect to \u227ak. Now the claim follows as in (iii).\n(v) since J4 \u2286 J1, this is implied by our proof of condition (iii) (we have not assumed d \u2208 J3 there).\nWe can now state the main theorem of this section. Remember that c(k) is the weighted constraint we get from c after k steps of our elimination procedure.\nTheorem 25. For all c \u2208 I and k \u2265 0, there exists \u03b1k(c) \u2208 N \\ {0} such that for all a : var(c) \\Xk \u2192 D, either\nc(k)(a) = 0\nor\nc(k)(a) = 1\n\u03b1k(c) \u00b7\nw(Ik(c), a)\nw(Ik(c) \\ {c}, a)\nand \u03b1k(c) \u2264 |D| k.\nProof. The proof is by induction on k. Note that \u227a0= \u2205 by definition and by convention w(\u2205, a) = 1. So taking \u03b10(c) = 1, proves the result for k = 0.\nNow assume that the result holds for k \u2265 0. To lighten the notations, we will denote xk+1 by x.\nIf x /\u2208 var(c), then c(k) = c(k+1). By Lemma 23, we also know that Ik+1(c) = Ik(c). Thus, if by choosing \u03b1k+1(c) = \u03b1k(c), the result follows.\nSo consider now I(x), i.e. the constraints that contain x as a variable. Let I(x) = {c1, . . . , cm} with c1 \u227a . . . \u227a cm. We will prove the result for all of the ci by induction on i. For i = 1, we have by definition, for all a : var(c1) \\Xk+1 \u2192 D, either c (k+1) 1 (a) = 0 and there is nothing to prove, or\nc (k+1) 1 (a) =\n\u2211 d\u2208D c (k) 1 (a\u2295x d)\n|D| .\nBy induction on k, we get\nc (k+1) 1 (a) =\n1\n|D|\u03b1k(c1)\n\u2211\nd\u2208D\u2032\nw(Ik(c1), a\u2295x d)\nw(Ik(c1) \\ {c1}, a\u2295x d)\nwhere D\u2032 = {d \u2208 D | c1(a \u2295x d) 6= 0}. As there is no constraint in Ik(c1) \\ {c1} having the variable x, the denominator in the sum does not depends on d. Moreover, Ik+1(c1) = Ik(c1) by Lemma 23. If d /\u2208 D\u2032 then c1(a \u2295x d) = 0 and hence w(Ik(c1), a \u2295x d) = 0. Thus, if we set \u03b1k+1(c1) = |D|\u03b1k(c1), we have\nc (k+1) 1 (a) =\n\u03b1k+1(c1) \u22121\nw(Ik+1(c1) \\ {c1}, a)\n\u2211\nd\u2208D\nw(Ik+1(c1), a\u2295x d)\n= 1\n\u03b1k+1(c1) \u00b7\nw(Ik+1(c1), a)\nw(Ik+1(c1) \\ {c1}, a) .\nFor i > 1, for all a : var(ci+1) \\Xk+1 \u2192 D, either c (k+1) i+1 (a) = 0 and there is nothing to prove,\nor by definition\nc (k+1) i+1 (a) =\n\u2211 d\u2208D \u220f j\u2264i+1 c\n(k) j ((a\u2295x d)|var(c(k)j ) )\n\u2211 d\u2208D \u220f j\u2264i c\n(k) j ((a\u2295x d)|var(c(k)j )\n) .\nApplying the induction hypothesis and Lemma 24 on both the numerator and the denominator, by also remarking that Ik(ci) \\ {c1, . . . , ci} does not contain any constraint with the variable x\nc (k+1) i+1 (a) =\n1 \u03b1k(ci+1) \u00b7 w(Ik+1(ci+1), a) w(Ik+1(ci), a) w(Ik+1(ci) \\ {c1, . . . , ci}, a) w(Ik+1(ci+1) \\ {c1, . . . , ci+1}, a) .\nWe now apply Corollary 15 with W := var(ci+1) \\Xk+1, J1 := Ik+1(ci) \\ {c1, . . . , ci}, J2 := Ik+1(ci+1), J3 := Ik+1(ci+1) \\ {c1, . . . , ci+1} and J4 := Ik+1(ci). Note that this will yields the desired result: We have (J1 \\ J3) \u222a J2 = J2 = Ik+1(ci+1) since J1 \u2286 J3 and (J3 \\ J1) \u222a J4 = Ik+1(ci+1)\\{ci+1}, from combining Lemma 23 and the fact that {c1, . . . , ci} \u2286 J4 and ci+1 /\u2208 J4.\nWe now check the conditions of Corollary 15.\n(i) Since J1 \u2286 J3, we have J1 \u2229 J2 \u2286 J3. Moreover, J3 \u2229 J4 \u2286 J1 since J1 = J4 \\ {c1, . . . , ci} and J3 does not contain any of the c1, . . . , ci.\n(ii) This condition holds since J1 \\ J3 = \u2205.\n(iii) This condition is a consequence of condition (v) since J1 \u2229 J3 \u2286 J4.\n(iv) This condition holds since J1 \\ J3 = \u2205.\n(v) Let c \u2208 J3 \\ J1 and d \u2208 J4. We have that c \u227ak+1 ci+1. Moreover, ci k ci \u227a ci+1 and x \u2208 var(ci) \u2229 var(ci+1) and consequently, by definition of \u227ak+1, we have ci \u227ak+1 ci+1. By definition of J4 we have d \u227ak+1 ci thus by transitivity of \u227ak+1 we get d \u227ak+1 ci+1. Using Lemma 19 b), it follows that var(c) \\Xk+1 \u2286 W and var(d) \\Xk+1 \u2286 W .\nNote that c 6 k+1 ci, because c /\u2208 J1 and c /\u2208 {c1, . . . , ci+1}.\nWe now show that c and d are incomparable with respect to \u227ak+1.\nBy way of contradiction, assume first that c \u227ak+1 d. Then as d \u227ak+1 ci, we get c \u227ak+1 ci which is a contradiction.\nNow assume that d \u227ak+1 c. With d \u227ak+1 ci and the fact that \u227a is a total order we get from Lemma 21 that c \u227ak+1 ci or ci \u227ak+1 c. But we know that c 6\u227ak+1 ci, so it follows that ci \u227ak+1 c \u227ak+1 ci+1 and thus ci \u227a c \u227a ci+1. By definition of ci, we have x \u2208 var(ci) and by Lemma 19 it follows that x \u2208 var(c). But this contradicts the choice of ci as the maximal element in I(x) with respect to \u227a that is less than ci+1.\nConsequently, c and d are in fact incomparable with respect to \u227ak+1. Now (v) follows as in as in (iii) in the proof of Lemma 24.\nHaving checked all conditions, we may apply Corollary 15 which concludes the proof.\nCombining the results of Section 3 and Section 4, we now state the main tractability result of this paper.\nTheorem 26. There exists an algorithm that, given a \u03b2-acyclic instance I of #CSPd on domain D, computes w(I) in polynomial time.\nProof. In a first step, one computes a \u03b2-elimination order for H(I), which can be done naively in polynomial time, iteratively searching by brute force for a nest point. When it is found, we remove the nest point and iterate.\nThen we can iterate the elimination procedure of Theorem 10, respecting the order \u227a of Section 4 induced by the elimination order. We make O(s(I)2\u2016I\u2016) arithmetic operations to perform all the elimination steps. The other operations needed are the computation of the new supports of the constraints at each step, which can be done in polynomial time.\nFinally, Section 4 provides a good upper bound on the size of the rationals on which we need to perform arithmetic operations. They are always of polynomial bitsize (of size O(|var(I)| log |D|)), thus each operation can be perform in polynomial time.\nCombining Theorem 26 and Corollary 6 we get the main tractability result for #SAT.\nCorollary 27. #SAT on \u03b2-acyclic CNF-formulas can be solved in polynomial time."}, {"heading": "5. Relation to the STV-framework", "text": "In this section we compare our algorithmic result for #SAT on \u03b2-acyclic hypergraphs to the framework proposed by S\u00e6ther, Telle and Vatshelle in [STV14] which we call short the STVframework. We first show that the STV-framework gives a uniform explanation of all tractability results for #SAT in the literature, extending the results of [STV14]. We see this as strong evidence that the STV-framework is indeed a good formalization of the intuitive notion of \u201cdynamic programming for #SAT\u201d.\nNext we show that the STV-framework cannot give any subexponential time algorithms for \u03b2-acyclic #SAT. To this end, we prove an exponential lower bound on the PS-width of \u03b2-acyclic CNF-formulas."}, {"heading": "5.1. Explaining old results by PS-width", "text": "In this section we show that the STV-framework is indeed strong enough to explain all known results on structural #SAT. Figure 1 shows the hierarchy for inclusion formed by the acyclicity notions and classes defined by bounding the width measures from the literature. Most proofs of inclusion can be found in [Fag83, Dur12, GP04, PSS13, CDM14] and the references therein. The relation between disjoint branches and MIM-width and that between \u03b2-acyclicity and MIMwidth are shown in this paper.\nKnown complexity results for the restrictions of #SAT can be found in Table 1; for definitions of the appearing complexity classes see e.g. [FG06].\nIn [Vat12] it is shown that MIM-width is bounded by cliquewidth, so nearly all tractability results of Table 1 follow from [STV14]. To show that the missing results can also be explained in the STV-framework, we only have to recover the tractability results for formulas with disjoint branches decompositions and the fixed-parameter result for formulas of bounded signed incidence cliquewidth. We reprove these results in the following sections by giving upper bounds on the MIM-width and the PS-width, respectively."}, {"heading": "5.1.1. Hypergraphs with disjoint branches", "text": "In this section we show how the tractability of #SAT on hypergraphs with a disjoint branches decomposition proved in [CDM14] can be explained by the STV-framework.\nA join tree (T, \u03bb) of a hypergraph H = (V,E) consists of a rooted tree T and a mapping \u03bb : V (T ) \u2192 E such that the following connectivity condition is satisfied: Let t1, t2 \u2208 V (T ) and v \u2208 \u03bb(t1) \u2229 \u03bb(t2), then v \u2208 \u03bb(t) for every t \u2208 V (T ) that lies on the path in T connecting t1 and t2. A join tree is a disjoint branches decomposition if whenever t1 and t2 lie on different branches of T , we have \u03bb(t1) \u2229 \u03bb(t2) = \u2205. Hypergraphs with disjoint branches decompositions are a strict subclass of \u03b2-acyclic hypergraphs [Dur12].\nTheorem 28. [CDM14] There is an algorithm that, given a hypergraph H, in time polynomial in \u2016H\u2016 compute a disjoint branches decomposition of H if one exists and rejects otherwise.\nLemma 29. Given a hypergraph H and a disjoint branches decomposition of H, we can in polynomial time compute a branch decomposition of I(G) of MIM-width at most 2.\nProof. Let (T , \u03bb) be a disjoint branches decomposition of H = (V,E). We construct a branch decomposition (T, \u03b4) of H as follows: The vertices of T form the internal vertices of T . For every v \u2208 V we introduce a new leaf u labeled by \u03b4(u) = v connecting it to the vertex of T that corresponds to the edge containing v that is farthest from the root of T . Observe that this choice is unique because T has disjoint branches and thus vertices v \u2208 V only appear along a path from the root to a leaf. Furthermore, we add a new leaf u for each e \u2208 E labeled by \u03b4(u) = e, connecting it to the vertex x of T with \u03bb(x) = e.\nWe now make T subcubic: For any internal vertex x, we introduce a binary tree Tx having as leaves the leaf children of x and connect it to x. After that, for every vertex x having more than two children, we introduce again a binary tree T \u2032x having the children of x as its leaves and connect it to x. The result is a branch decomposition (T, \u03b4) of the incidence graph of H.\nWe claim that (T, \u03b4) has MIM-width at most 2. So let v be a cut vertex with cut (X, X\u0304). First assume that v lies in one of the Tx. Let e = \u03bb(x) be the single e \u2208 E that appears as label of a leaf of Tx. Observe that all u \u2208 V \u2229X lie in e. Also, all u \u2208 V \u2229X that lie in an edge different from e must lie in a common edge e\u2032 \u2208 E that corresponds to the parent of e in T . Since e\u2032 /\u2208 X only one vertex in X \u2229 V can contribute to an independent matching in I(H)[X, X\u0304 ]. Furthermore, e is the only edge in E \u2229X, and it follows that the MIM-width of the cut (X, X\u0304) is at most 2.\nIf v does not lie in any Tx\u2014that is v lies in a T \u2032 y or is a vertex y \u2208 V (T )\u2014then the cut (X, X\u0304) corresponds to cutting subtrees T1, . . . ,Ts from a vertex x in T . Every vertex u \u2208 X \u2229V lies in an edge e \u2208 X \u2229E which is the label \u03bb(x\u2032) for some vertex x\u2032 in a Ti. Now if u is also in an edge e\u2032 \u2208 X\u0304 \u2229 E, then u \u2208 \u03bb(x) \u2208 X\u0304 \u2229 E. Consequently, only one vertex u \u2208 X \u2229 V can be an end vertex of an induced matching in I(H)[X, X\u0304 ]. Furthermore, no vertex u in X\u0304 \u2229 V is in an edge e \u2208 X \u2229 E, because we connected u to the vertex y farthest from the root in the construction of T and thus cutting outside Tx we cannot be in a situation where u /\u2208 X. Consequently, the MIM-width of the cut (X, X\u0304) is at most 1.\nCorollary 30 ([CDM14]). #SAT on hypergraphs with disjoint branches decompositions can be solved in polynomial time.\nProof. Given a CNF-Formula F , compute a disjoint branches decomposition with Theorem 28. Then apply the construction of Lemma 29 to get a branch decomposition of MIM-width at most 2. Now combining Theorem 9 and Theorem 8 yields the results."}, {"heading": "5.1.2. Signed incidence cliquewidth", "text": "In this section we use the STV-framework to reprove a result from [FMR08] stating that #SAT is fixed-parameter tractable parameterized by signed cliquewidth. We first state the relevant definitions from [FMR08].\nThe signed incidence graph SI(F ) of a CNF-formula is the incidence graph of F where each edge xC is signed positively or negatively depending on if the variable x appears positively or negatively in the clause C. The set of CNF-formulas of signed cliquewidth at most k is defined as the set of formulas whose signed incidence graph can be obtained by the following operations over graphs whose vertices are coloured by {1, . . . , k}, starting from singleton graphs.\n1. Disjoint union.\n2. Recolouring: For a vertex-coloured signed bipartite graph G, we defined \u03c1i,j(G) to be the graph that results from recolouring with j all vertices that were previously coloured with i.\n3. Positive edge creation: For a vertex-coloured signed bipartite graph G, we define \u03b7+i,j(G) to be the graph that results from connecting all clause-vertices coloured i to all variablevertices coloured j, with edges signed positively. We do not add edges between variable vertices coloured i and clause-vertices coloured j, or any other vertices.\n4. Negative edge creation: Similarly to above, we define \u03b7\u2212i,j(G) to be the graph resulting from connecting all clause-vertices coloured with i to all variable-vertices coloured with j, with edges signed negatively.\nThe signed cliquewidth of a CNF-formula is the minimum k such that it has signed cliquewidth at most k.\nA parse tree for the signed cliquewidth of a formula F is the rooted tree whose leaves hold singleton graphs, whose internal vertices are coloured with the operations of the definitions above (so a vertex corresponding to a disjoint union has two children, and vertices corresponding to other operations have one child), and whose root holds the graph SI(F ) (with any vertex colouring).\nGiven a signed parse tree of a formula F , we construct iteratively a branch decomposition. We assume w.l.o.g. that whenever we make a union, the graphs whose union we take have only disjoint colors in their vertex coloring. This can be easily achieved by at most doubling the number of colors used. Furthermore, we assume that in the end all vertices have the same color.\nWe construct the branch decomposition along the parse tree iteratively. To this end, we assign a tree T\u03c4 to each sub-parse tree \u03c4 . To a singleton v representing a variable of F , we assign a singleton vertex labeled with v. For \u03c4 = \u03b7+i,j(\u03c4 \u2032) and \u03c4 = \u03b7\u2212i,j(\u03c4 \u2032) we set T\u03c4 := T\u03c4 \u2032 . For \u03c4 = \u03c1i,j(\u03c4 \u2032) we again let T\u03c4 := T\u03c4 \u2032 . Finally, for \u03c4 = \u03c41 \u222a \u03c42 we introduce a new root and connect it to T\u03c41 and T\u03c42 . Observe that T\u03c4 is essentially the tree we get from \u03c4 by forgetting internal labels and contracting all paths to edges. Observe that the result (T, \u03b4) is obviously a branch decomposition.\nLemma 31. (T, \u03b4) has PS-width at most 22k.\nProof. Let v be a cut vertex with the cut (A, A\u0304). Let X := A \u2229 var(F ), X\u0304 := A\u0304 \u2229 var(F ), C := A\u2229 cla(F ) and C\u0304 := A\u0304\u2229 cla(F ). Let \u03c4 be the sub-parse tree which is rooted by the union that led to the introduction of v.\nWe first show that |PS(FX,C\u0304)| \u2264 2 2k. Observe that when two variables x, x\u2032 \u2208 X have the\nsame color in \u03c4 , then they must always appear together in every clause in C\u0304 and their sign must be the same. Call Xi the set of variables in X that are colored by i. Then for every assignment of FX,C\u0304 the set of satisfied clauses depends only on if there is a variable in Xi that is set to true if Xi appears positively or if there is a variable in Xi set to false if Xi appears negatively. So to get the same precise satisfiability set, we can delete all but two variables from Xi from FX,C\u0304 . It follows that FX,C\u0304 has the same precise satisfiability set as a formula with 2k variables. But there are only 22k assignments to 2k variables, so it follows that |PS(FX,C\u0304)| \u2264 2 2k.\nWe now show that |PS(FX\u0304,C)| \u2264 2 2k. To this end observe that if two clauses C,C \u2032 in \u03c4 have\nthe same color i, then they will contain the same variables in X\u0304 and moreover C|X\u0304 = C \u2032|X\u0304 . Thus FX\u0304,C only has k different clauses, so trivially |PS(FX\u0304,C)| \u2264 2 2k.\nCorollary 32 ([FMR08]). #SAT on formulas of signed incidence cliquewidth k can be solved in time 2O(k)|F |2 assuming that we are provided a parse tree of width k.\nNote that the runtime bound in [FMR08] cannot be easily compared, because the runtime in [FMR08] depends on the size of the parse tree directly and not on the formula. But both results are fixed-parameter results that singly exponentially depend on k, so they are at least very close."}, {"heading": "5.2. Lower bounds on MIM-width and PS-width", "text": "In this section we will prove the promised lower bound on the PS-width of \u03b2-acyclic CNFformulas. We start off with a simple Lemma that can be seen as a partial reverse of Lemma 9. We remind the reader that a CNF-formula F is called monotone if all variables appear only positively in F .\nLemma 33. For every bipartite graph G there is a monotone CNF-formula F such that F has the incidence graph G and psw(F ) \u2265 2mimw(G)/2.\nProof. We construct F by choosing arbitrarily one color class of G to represent clauses and the other one to represent variables. This choice then uniquely yields a monotone formula where a clause C contains a variable x if and only if x is connected to C by an edge in G.\nLet (T, \u03b4) be a branch decomposition of G and F . Let t be a vertex of T with cut (A, A\u0304). Set X := var(F ) \u2229A, X\u0304 := var(F ) \u2229 A\u0304, C := cla(F ) \u2229A and C\u0304 := cla(F ) \u2229 A\u0304. Moreover, let M be a maximum independent matching of G[A, A\u0304] and let VM be the end vertices of M .\nFirst assume that |C \u2229 VM | \u2265 |C\u0304 \u2229 VM |. Let C1, . . . , Ck be the clauses in C \u2229 VM and let x1, . . . , xk be variables in X\u0304 \u2229 VM . Note that k \u2265 |M |/2. Since M is an independent matching, every clause Ci contains exactly one of the variables xj, and we assume w.l.o.g. that Ci contains xi. Let a be an assignment to the xi and let a\n\u2032 be the extended assignment of X\u0304 that we get by assigning 0 to all other variables. Then a\u2032 satisfies in FX\u0304,C exactly the clauses Ci for which a(xi) = 1 since the formula is monotone. Since there are 2 k assignments to the xi, we have |PS(FX\u0304,C)| \u2265 2 k \u2265 2|M |/2.\nFor |C \u2229 VM | \u2264 |C\u0304 \u2229 VM | it follow symmetrically that |PS(FX,C\u0304)| \u2265 2 |M |/2.\nConsequently, we have in either case that the PS-width of F is at least 2|M |/2 and the claim follows.\nTo a graph G = (V,E) we define a graph G\u2032 = (V \u2032, E\u2032) as follows:\n\u2022 for every v \u2208 V there are two vertices xv, yv \u2208 V \u2032,\n\u2022 for every edge e = uv \u2208 E there are four vertices pe,u, qe,u, pe,v, qe,v \u2208 V \u2032,\n\u2022 every u, v \u2208 V we add the edge xvyu to E \u2032, and\n\u2022 for every edge e = uv \u2208 E we add the edges pe,uqe,u, pe,vqe,v, xupe,u, yvqe,u, xvpe,v, yuqe,v.\nThese are all vertices and edges of G\u2032.\nLemma 34. G\u2032 is chordal bipartite.\nProof. We have to show that every cycle C in G\u2032 of length at least 6 has a chord. We consider two cases: Assume first that C contains no vertex pe,v and consequently no qe,v either. Then all vertices of C are xv or yv and so C is a cycle in the complete bipartite graph induced by the xv and yv. Clearly, C has a chord then.\nNow assume that C contains a vertex pe,v and consequently also qe,v. Let e = uv. Then C must also contain xv and yu, so xvyu \u2208 E \u2032 is a chord.\nLemma 35. Let G be bipartite. Then tw(G) \u2264 6mimw(G\u2032).\nProof. Let (T \u2032, \u03b4\u2032) be a branch decomposition of G\u2032. Let A,B \u2286 V (G) be the two colour classes of G. We construct a branch decomposition (T, \u03b4) of G by deleting the leaves labeled with pe,u, qe,u, pe,v, qe,v, and those labeled xv for v \u2208 A or with yv for v \u2208 B. Then we delete all internal vertices of of T \u2032 that have become leaves by these deletions until we get a branch decomposition T with the leaves xv for v \u2208 B and yv for v \u2208 A. For the leaves of T we define \u03b4(t) := v where v \u2208 V is such that \u03b4\u2032(t) = xv or \u03b4\n\u2032(t) = yv. The result (T, \u03b4) is a branch decomposition of G.\nLet t be a vertex of T with the corresponding cut (X, X\u0304). Let M \u2286 E be a matching in G[X, X\u0304 ]. Let (X \u2032, X\u0304 \u2032) be the cut of t in (T \u2032, \u03b4\u2032). Let e = uv \u2208 M , then xu and yv are on different sides of the cut X \u2032 and they are connected by the path xupe,uqe,uyv. Consequently, there is at least one edge along this path in G\u2032[X \u2032, X\u0304 \u2032]. Choose one such edge arbitrarily.\nLet M \u2032 be the set of edges we have chosen for the different edges in M . Let M \u2032x be the set of edges in M \u2032 that do not have an end vertex yv and let M \u2032 y be the set of edges in M\n\u2032 that do not have an end vertex xv. Let M\n\u2032\u2032 be the bigger of these two sets. Since e\u2032 \u2208 M \u2032 can only have an end vertex xv or yu but not both, we have |M \u2032 x|+ |M \u2032 y| \u2265 |M\n\u2032| and thus |M \u2032\u2032| \u2265 |M \u2032|/2. We claim that M \u2032\u2032 is an independent matching in G\u2032. Clearly, M \u2032 is a matching because M\nis one. Consequently, M \u2032\u2032 \u2286 M \u2032 is also a matching. We now show that M \u2032\u2032 is also independent. By way of contradiction, assume this were not true. Then there must be two adjacent vertices u, v \u2208 V \u2032 that are end vertices of edges in M \u2032\u2032 but not in the same edge in M \u2032\u2032. If u = pe\u2032,w for some e\u2032 \u2208 E and w \u2208 V , then v must be xw. But then by construction of M\n\u2032, the vertex w must be incident to two edges in M which contradicts M being a matching. Similarly, we can rule out that v is qe,w. Thus, u must be xw or yw and v must be xw\u2032 or yw\u2032. Since xw and xw\u2032 are in the same colour class of G\u2032, they are not adjacent. Similarly yw and yw\u2032 are not adjacent. Consequently, we may assume that u = xw and v = yw\u2032. But then they cannot both be an endpoint of an edge in M \u2032\u2032 by construction of M \u2032\u2032. Thus M \u2032\u2032 is independent.\nBy Lemma 7 we know that there is a t \u2208 T with cut (X, X\u0304) such that we can find a matching M of size at least tw(G)3 in G[X, X\u0304 ]. By the construction above the corresponding cut (X \u2032, X\u0304 \u2032) yields an independent matching of size tw(G)6 in G \u2032[X \u2032, X\u0304 \u2032]. This completes the proof.\nUsing the connection between vertex expansion and treewidth (see [GM09]) the following lemma is easy to show.\nLemma 36. There is a family G of graphs and constants c > 0 and d \u2208 N such that for every G \u2208 G the graph G has maximum degree d and we have tw(G) \u2265 c|E(G)|.\nCorollary 37. There is a family G\u2032 of chordal bipartite graphs and a constant c such that for every graph G \u2208 G we have mimw(G) \u2265 c|V (G)|.\nProof. Let G be the class of Lemma 36. We first transform every graph G \u2208 G into a bipartite one G1 by subdividing every edge, i.e. by introducing for each edge e = uv a new vertex we and by replacing e by uwe and wev. It is well-known that subdividing edges does not decrease the treewidth of a graph (see e.g. [Die05]), and thus tw(G) \u2264 tw(G1). Moreover, |E(G1)| = 2|E(G)|, and thus tw(G1) \u2265 1 2c|E(G1)|. Now let G \u2032 = {G\u20321 | G \u2208 G}. Then the graphs in G \u2032 are chordal bipartite by Lemma 34 and the bound on the MIM-width follows by combining Lemma 36 and Lemma 35.\nWe can now easily prove the main result of this section.\nCorollary 38. There is a family of monotone \u03b2-acyclic CNF-formulas of PS-width 2\u2126(n) where n is the number of variables in the formulas.\nProof. Let F be the class of monotone CNF-formulas having the class G\u2032 of Corollary 37 as its incidence graphs. By Theorem 5 the formulas in F are \u03b2-acyclic. Combining the bound on the MIM-width of G\u2032 with Lemma 33 then directly yields the result.\nIt follows that the STV-framework cannot prove subexponential runtime bounds for #SAT on \u03b2-acyclic formulas."}, {"heading": "6. Conclusion", "text": "We have shown that \u03b2-acyclic #SAT can be solved in polynomial time, a question left open in [CDM14]. Our algorithm does not follow the dynamic programming approach that was used in all other structural tractability results that were known before, and as we have seen this is no coincidence. Instead, \u03b2-acyclic #SAT lies outside the STV-framework of [STV14] that explains all old results in a uniform way.\nWe close this paper with several open problems that we feel should be explored in the future. First, our algorithm for #SAT is specifically designed for the case of \u03b2-acyclic formulas, but we feel that the techniques developed, in particular those of Section 4, might possibly be extended to other classes of hypergraphs that one can characterize by elimination orders. In this direction, it would be interesting to see if hypergraphs of bounded \u03b2-hypertree width, a width measure generalizing \u03b2-acyclicity proposed in [GP04], can be characterized by elimination orders and if such a characterization can be used to solve #SAT on the respective instances. Note that this case lies outside of the STV-framework, therefore dynamic programming without new ingredients is unlikely to work. Also, even the complexity of deciding SAT on instances of bounded \u03b2-hypertree width is an open problem [OPS13].\nIt might also be interesting to generalize our algorithm to solve cases for which we already have polynomial time algorithms. For example, is there any uniform explanation for tractability of bounded cliquewidth #SAT and \u03b2-acyclic #SAT, similarly to the way in which the framework of [STV14] explains tractability for all previously known results?\nFinally, we feel that, although we have shown that the STV-framework does not explain all tractability results for #SAT, it is still a framework that should be studied in the future. We believe that there are still many classes to be captured by it in the future and thus we see a\nbetter understanding of the framework as an important goal for future research. One question is the complexity of computing branch decompositions of (approximately) minimal MIM-width or PS-width. Alternatively, one could try to find more classes of bipartite graphs for which one can efficiently compute branch decompositions of small MIM-width. This would then directly extend the knowledge on structural classes of CNF-formulas for which dynamic programming can efficiently solve #SAT."}], "references": [{"title": "A", "author": ["G. Ausiello"], "venue": "D\u2019Atri, and M. Moscarini. Chordality properties on graphs and minimal conceptual connections in semantic data models. J. Comput. Syst. Sci., 33(2):179\u2013202", "citeRegEx": "ADM86", "shortCiteRegEx": null, "year": 1986}, {"title": "The complexity of weighted and unweighted #csp", "author": ["A. Bulatov", "M. Dyer", "L.A. Goldberg", "M. Jalsenius", "M. Jerrum", "D. Richerby"], "venue": "Journal of Computer and System Sciences, 78(2):681\u2013688, March", "citeRegEx": "BDG+12", "shortCiteRegEx": null, "year": 2012}, {"title": "Graph Classes: A Survey", "author": ["A. Brandst\u00e4dt", "V.B. Le", "J.P. Spinrad"], "venue": "Society for Industrial and Applied Mathematics, Philadelphia, PA, USA", "citeRegEx": "BLS99", "shortCiteRegEx": null, "year": 1999}, {"title": "A tourist guide through treewidth", "author": ["H.L. Bodlaender"], "venue": "Acta Cybern., 11(1-2):1\u201321", "citeRegEx": "Bod93", "shortCiteRegEx": null, "year": 1993}, {"title": "ArXiv e-prints", "author": ["J. Brault-Baron. Hypergraph Acyclicity Revisited"], "venue": "March", "citeRegEx": "Bra14", "shortCiteRegEx": null, "year": 2014}, {"title": "STOC \u201912", "author": ["J.-Y. Cai", "X. Chen. Complexity of counting CSP with complex weights. In Proceedings of the Forty-fourth Annual ACM Symposium on Theory of Computing"], "venue": "page 909\u2013920, New York, NY, USA,", "citeRegEx": "CC12", "shortCiteRegEx": null, "year": 2012}, {"title": "Hypergraph acyclicity and propositional model counting", "author": ["F. Capelli", "A. Durand", "S. Mengel"], "venue": "CoRR, abs/1401.6307", "citeRegEx": "CDM14", "shortCiteRegEx": null, "year": 2014}, {"title": "Constraint representations and structural tractability", "author": ["D.A. Cohen", "M.J. Green", "C. Houghton"], "venue": "Principles and Practice of Constraint Programming - CP 2009, pages 289\u2013303", "citeRegEx": "CGH09", "shortCiteRegEx": null, "year": 2009}, {"title": "Graph Theory (Graduate Texts in Mathematics)", "author": ["R. Diestel"], "venue": "Springer, August", "citeRegEx": "Die05", "shortCiteRegEx": null, "year": 2005}, {"title": "The complexity of counting homomorphisms seen from the other side", "author": ["V. Dalmau", "P. Jonsson"], "venue": "Theor. Comput. Sci., 329(1-3):315\u2013323", "citeRegEx": "DJ04", "shortCiteRegEx": null, "year": 2004}, {"title": "Some characterizations of \u03b3 and \u03b2-acyclicity of hypergraphs", "author": ["D. Duris"], "venue": "Inf. Process. Lett., 112(16):617\u2013620", "citeRegEx": "Dur12", "shortCiteRegEx": null, "year": 2012}, {"title": "Degrees of acyclicity for hypergraphs and relational database schemes", "author": ["R. Fagin"], "venue": "Journal of the ACM, 30(3):514\u2013550", "citeRegEx": "Fag83", "shortCiteRegEx": null, "year": 1983}, {"title": "Parameterized Complexity Theory", "author": ["J. Flum", "M. Grohe"], "venue": "Springer-Verlag New York Inc", "citeRegEx": "FG06", "shortCiteRegEx": null, "year": 2006}, {"title": "Counting truth assignments of formulas of bounded tree-width or clique-width", "author": ["E. Fischer", "J.A. Makowsky", "E.V. Ravve"], "venue": "Discrete Applied Mathematics, 156(4):511\u2013 529", "citeRegEx": "FMR08", "shortCiteRegEx": null, "year": 2008}, {"title": "A comparison of structural csp decomposition methods", "author": ["G. Gottlob", "N. Leone", "F. Scarcello"], "venue": "Artif. Intell., 124(2):243\u2013282", "citeRegEx": "GLS00", "shortCiteRegEx": null, "year": 2000}, {"title": "On tree width", "author": ["M. Grohe", "D. Marx"], "venue": "bramble size, and expansion. J. Comb. Theory, Ser. B, 99(1):218\u2013228", "citeRegEx": "GM09", "shortCiteRegEx": null, "year": 2009}, {"title": "Hypergraphs in Model Checking: Acyclicity and Hypertree-Width versus Clique-Width", "author": ["G. Gottlob", "R. Pichler"], "venue": "SIAM Journal on Computing, 33(2)", "citeRegEx": "GP04", "shortCiteRegEx": null, "year": 2004}, {"title": "Satisfiability of acyclic and almost acyclic CNF formulas", "author": ["S. Ordyniak", "D. Paulusma", "S. Szeider"], "venue": "Theoretical Computer Science, 481:85\u201399", "citeRegEx": "OPS13", "shortCiteRegEx": null, "year": 2013}, {"title": "Model Counting for CNF Formulas of Bounded Modular Treewidth", "author": ["D. Paulusma", "F. Slivovsky", "S. Szeider"], "venue": "30th International Symposium on Theoretical Aspects of Computer Science, STACS 2013, pages 55\u201366", "citeRegEx": "PSS13", "shortCiteRegEx": null, "year": 2013}, {"title": "On the hardness of approximate reasoning", "author": ["D. Roth"], "venue": "Artificial Intelligence, 82(1\u20132):273 \u2013 302", "citeRegEx": "Rot96", "shortCiteRegEx": null, "year": 1996}, {"title": "Algorithms for propositional model counting", "author": ["M. Samer", "S. Szeider"], "venue": "Journal of Discrete Algorithms, 8(1):50\u201364", "citeRegEx": "SS10", "shortCiteRegEx": null, "year": 2010}, {"title": "Model Counting for Formulas of Bounded CliqueWidth", "author": ["F. Slivovsky", "S. Szeider"], "venue": "Algorithms and Computation - 24th International Symposium, ISAAC 2013, pages 677\u2013687", "citeRegEx": "SS13", "shortCiteRegEx": null, "year": 2013}, {"title": "Solving MaxSAT and #SAT on structured CNF formulas", "author": ["S. Hortemo S\u00e6ther", "J.A. Telle", "M. Vatshelle"], "venue": "CoRR, abs/1402.6485", "citeRegEx": "STV14", "shortCiteRegEx": null, "year": 2014}, {"title": "New Width Parameters of Graphs", "author": ["M. Vatshelle"], "venue": "PhD thesis, University of Bergen", "citeRegEx": "Vat12", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 19, "context": "[Rot96]), so there is also great interest in the problem from a practical point of view.", "startOffset": 0, "endOffset": 7}, {"referenceID": 19, "context": "monotone 2-CNF-formulas, the problem is #P-hard and in fact even #P-hard to approximate [Rot96].", "startOffset": 88, "endOffset": 95}, {"referenceID": 22, "context": "Very recently, S\u00e6ther, Telle and Vatshelle, in a striking contribution [STV14], have introduced a new width measure for CNF-formulas, that they call PS-width.", "startOffset": 71, "endOffset": 78}, {"referenceID": 22, "context": "Thus they have essentially turned the construction of dynamic programming algorithms into a question of graph theory: If, for a class of formulas, one can efficiently compute decompositions that have small PS-width for all formulas having these graphs, the dynamic programming of [STV14] solves these instances.", "startOffset": 280, "endOffset": 287}, {"referenceID": 22, "context": "On the other hand, since, in our opinion, the framework of [STV14] is a very good formalization of dynamic programming, there is likely no efficient dynamic programming algorithm for a class of CNF-formulas, if it does not have decompositions of small PS-width, or if these decompositions cannot be constructed efficiently.", "startOffset": 59, "endOffset": 66}, {"referenceID": 17, "context": "The complexity of #SAT for \u03b2-acyclic formulas is interesting for several reasons: First, up to this paper, it was the only structural class of formulas for which we know that SAT is tractable [OPS13] without this directly generalizing to a tractability result for #SAT.", "startOffset": 192, "endOffset": 199}, {"referenceID": 17, "context": "This is because the algorithm of [OPS13] does not proceed by dynamic programming but uses resolution, a technique that is known to generally not generalize to counting.", "startOffset": 33, "endOffset": 40}, {"referenceID": 16, "context": "Moreover, \u03b2-acyclicity can be generalized to a width-measure [GP04], so there is hope that a good algorithm for \u03b2-acyclic formulas might generalize to wider classes for which even the status for SAT is left as an open problem in [OPS13].", "startOffset": 61, "endOffset": 67}, {"referenceID": 17, "context": "Moreover, \u03b2-acyclicity can be generalized to a width-measure [GP04], so there is hope that a good algorithm for \u03b2-acyclic formulas might generalize to wider classes for which even the status for SAT is left as an open problem in [OPS13].", "startOffset": 229, "endOffset": 236}, {"referenceID": 14, "context": "Since decomposition techniques based on hypergraph acyclicity tend to be more general than graph-based techniques [GLS00], this might lead to large, new classes of tractable #SAT-instances.", "startOffset": 114, "endOffset": 121}, {"referenceID": 9, "context": "in [DJ04], but since we allow clauses, resp.", "startOffset": 3, "endOffset": 9}, {"referenceID": 9, "context": "relations, of unbounded arity, our results and those of [DJ04] are incomparable.", "startOffset": 56, "endOffset": 62}, {"referenceID": 17, "context": "Instead of doing dynamic programming along a decomposition, we proceed along a vertex elimination order which is more similar to the approach to SAT in [OPS13].", "startOffset": 152, "endOffset": 159}, {"referenceID": 22, "context": "Our second contribution is that we show that our tractability result is not covered by the framework of S\u00e6ther, Telle and Vatshelle [STV14], short STV-framework, which\u2014as we show\u2014 covers all other known structural tractability results for #SAT.", "startOffset": 132, "endOffset": 139}, {"referenceID": 22, "context": "We do this by showing that \u03b2-acyclic #SAT-instances may have a PS-width so high that from [STV14] we cannot even get subexponential runtime bounds.", "startOffset": 90, "endOffset": 97}, {"referenceID": 22, "context": "If one accepts the framework of [STV14] as a good formalization of dynamic programming\u2014which we do\u2014then the deviation from the usual dynamic programming paradigm is not a coincidence but instead due to the fact that there is no efficient dynamic programming algorithm in the usual style.", "startOffset": 32, "endOffset": 39}, {"referenceID": 8, "context": "be found in [Die05].", "startOffset": 12, "endOffset": 19}, {"referenceID": 7, "context": "[CGH09].", "startOffset": 0, "endOffset": 7}, {"referenceID": 0, "context": "Theorem 5 ([ADM86]).", "startOffset": 11, "endOffset": 18}, {"referenceID": 22, "context": "In this section we introduce several width measures on graphs and CNF-formulas that are used when relating our algorithm for \u03b2-acyclic #CSPd to the framework of S\u00e6ther, Telle and Vatshelle [STV14].", "startOffset": 189, "endOffset": 196}, {"referenceID": 23, "context": "For an introduction into this area and many more details see [Vat12].", "startOffset": 61, "endOffset": 68}, {"referenceID": 23, "context": "Moreover, it is often convenient to see a branch decomposition as rooted tree, and as this does not change any of the notions we define (see [Vat12]), we generally follow this convention.", "startOffset": 141, "endOffset": 148}, {"referenceID": 3, "context": "[Bod93]), it is more convenient for us to work with the strongly related notion of Maximum-Matching-width (short MM-width) introduced by Vatshelle [Vat12].", "startOffset": 0, "endOffset": 7}, {"referenceID": 23, "context": "[Bod93]), it is more convenient for us to work with the strongly related notion of Maximum-Matching-width (short MM-width) introduced by Vatshelle [Vat12].", "startOffset": 147, "endOffset": 154}, {"referenceID": 22, "context": "Theorem 8 ([STV14]).", "startOffset": 11, "endOffset": 18}, {"referenceID": 22, "context": "Theorem 9 ([STV14]).", "startOffset": 11, "endOffset": 18}, {"referenceID": 23, "context": "In fact, even the complexity of deciding if a given graph has MIM-width 1 in polynomial time is left as an open problem in [Vat12].", "startOffset": 123, "endOffset": 130}, {"referenceID": 22, "context": "In this section we compare our algorithmic result for #SAT on \u03b2-acyclic hypergraphs to the framework proposed by S\u00e6ther, Telle and Vatshelle in [STV14] which we call short the STVframework.", "startOffset": 144, "endOffset": 151}, {"referenceID": 22, "context": "We first show that the STV-framework gives a uniform explanation of all tractability results for #SAT in the literature, extending the results of [STV14].", "startOffset": 146, "endOffset": 153}, {"referenceID": 20, "context": "class lower bound upper bound primal treewidth FPT [SS10] incidence treewidth FPT [SS10] modular incidence treewidth W1-hard [PSS13] XP [PSS13] signed incidence cliquewidth FPT [FMR08] incidence cliquewidth W1-hard [OPS13] XP [SS13] MIM-width XP [STV14] \u03b3-acyclic FP [GP04, SS13] disjoint branches FP [CDM14] \u03b2-acyclic FP (this paper)", "startOffset": 51, "endOffset": 57}, {"referenceID": 20, "context": "class lower bound upper bound primal treewidth FPT [SS10] incidence treewidth FPT [SS10] modular incidence treewidth W1-hard [PSS13] XP [PSS13] signed incidence cliquewidth FPT [FMR08] incidence cliquewidth W1-hard [OPS13] XP [SS13] MIM-width XP [STV14] \u03b3-acyclic FP [GP04, SS13] disjoint branches FP [CDM14] \u03b2-acyclic FP (this paper)", "startOffset": 82, "endOffset": 88}, {"referenceID": 18, "context": "class lower bound upper bound primal treewidth FPT [SS10] incidence treewidth FPT [SS10] modular incidence treewidth W1-hard [PSS13] XP [PSS13] signed incidence cliquewidth FPT [FMR08] incidence cliquewidth W1-hard [OPS13] XP [SS13] MIM-width XP [STV14] \u03b3-acyclic FP [GP04, SS13] disjoint branches FP [CDM14] \u03b2-acyclic FP (this paper)", "startOffset": 125, "endOffset": 132}, {"referenceID": 18, "context": "class lower bound upper bound primal treewidth FPT [SS10] incidence treewidth FPT [SS10] modular incidence treewidth W1-hard [PSS13] XP [PSS13] signed incidence cliquewidth FPT [FMR08] incidence cliquewidth W1-hard [OPS13] XP [SS13] MIM-width XP [STV14] \u03b3-acyclic FP [GP04, SS13] disjoint branches FP [CDM14] \u03b2-acyclic FP (this paper)", "startOffset": 136, "endOffset": 143}, {"referenceID": 13, "context": "class lower bound upper bound primal treewidth FPT [SS10] incidence treewidth FPT [SS10] modular incidence treewidth W1-hard [PSS13] XP [PSS13] signed incidence cliquewidth FPT [FMR08] incidence cliquewidth W1-hard [OPS13] XP [SS13] MIM-width XP [STV14] \u03b3-acyclic FP [GP04, SS13] disjoint branches FP [CDM14] \u03b2-acyclic FP (this paper)", "startOffset": 177, "endOffset": 184}, {"referenceID": 17, "context": "class lower bound upper bound primal treewidth FPT [SS10] incidence treewidth FPT [SS10] modular incidence treewidth W1-hard [PSS13] XP [PSS13] signed incidence cliquewidth FPT [FMR08] incidence cliquewidth W1-hard [OPS13] XP [SS13] MIM-width XP [STV14] \u03b3-acyclic FP [GP04, SS13] disjoint branches FP [CDM14] \u03b2-acyclic FP (this paper)", "startOffset": 215, "endOffset": 222}, {"referenceID": 21, "context": "class lower bound upper bound primal treewidth FPT [SS10] incidence treewidth FPT [SS10] modular incidence treewidth W1-hard [PSS13] XP [PSS13] signed incidence cliquewidth FPT [FMR08] incidence cliquewidth W1-hard [OPS13] XP [SS13] MIM-width XP [STV14] \u03b3-acyclic FP [GP04, SS13] disjoint branches FP [CDM14] \u03b2-acyclic FP (this paper)", "startOffset": 226, "endOffset": 232}, {"referenceID": 22, "context": "class lower bound upper bound primal treewidth FPT [SS10] incidence treewidth FPT [SS10] modular incidence treewidth W1-hard [PSS13] XP [PSS13] signed incidence cliquewidth FPT [FMR08] incidence cliquewidth W1-hard [OPS13] XP [SS13] MIM-width XP [STV14] \u03b3-acyclic FP [GP04, SS13] disjoint branches FP [CDM14] \u03b2-acyclic FP (this paper)", "startOffset": 246, "endOffset": 253}, {"referenceID": 6, "context": "class lower bound upper bound primal treewidth FPT [SS10] incidence treewidth FPT [SS10] modular incidence treewidth W1-hard [PSS13] XP [PSS13] signed incidence cliquewidth FPT [FMR08] incidence cliquewidth W1-hard [OPS13] XP [SS13] MIM-width XP [STV14] \u03b3-acyclic FP [GP04, SS13] disjoint branches FP [CDM14] \u03b2-acyclic FP (this paper)", "startOffset": 301, "endOffset": 308}, {"referenceID": 12, "context": "[FG06].", "startOffset": 0, "endOffset": 6}, {"referenceID": 23, "context": "In [Vat12] it is shown that MIM-width is bounded by cliquewidth, so nearly all tractability results of Table 1 follow from [STV14].", "startOffset": 3, "endOffset": 10}, {"referenceID": 22, "context": "In [Vat12] it is shown that MIM-width is bounded by cliquewidth, so nearly all tractability results of Table 1 follow from [STV14].", "startOffset": 123, "endOffset": 130}, {"referenceID": 6, "context": "In this section we show how the tractability of #SAT on hypergraphs with a disjoint branches decomposition proved in [CDM14] can be explained by the STV-framework.", "startOffset": 117, "endOffset": 124}, {"referenceID": 10, "context": "Hypergraphs with disjoint branches decompositions are a strict subclass of \u03b2-acyclic hypergraphs [Dur12].", "startOffset": 97, "endOffset": 104}, {"referenceID": 6, "context": "[CDM14] There is an algorithm that, given a hypergraph H, in time polynomial in \u2016H\u2016 compute a disjoint branches decomposition of H if one exists and rejects otherwise.", "startOffset": 0, "endOffset": 7}, {"referenceID": 6, "context": "Corollary 30 ([CDM14]).", "startOffset": 14, "endOffset": 21}, {"referenceID": 13, "context": "In this section we use the STV-framework to reprove a result from [FMR08] stating that #SAT is fixed-parameter tractable parameterized by signed cliquewidth.", "startOffset": 66, "endOffset": 73}, {"referenceID": 13, "context": "We first state the relevant definitions from [FMR08].", "startOffset": 45, "endOffset": 52}, {"referenceID": 13, "context": "Corollary 32 ([FMR08]).", "startOffset": 14, "endOffset": 21}, {"referenceID": 13, "context": "Note that the runtime bound in [FMR08] cannot be easily compared, because the runtime in [FMR08] depends on the size of the parse tree directly and not on the formula.", "startOffset": 31, "endOffset": 38}, {"referenceID": 13, "context": "Note that the runtime bound in [FMR08] cannot be easily compared, because the runtime in [FMR08] depends on the size of the parse tree directly and not on the formula.", "startOffset": 89, "endOffset": 96}, {"referenceID": 15, "context": "Using the connection between vertex expansion and treewidth (see [GM09]) the following lemma is easy to show.", "startOffset": 65, "endOffset": 71}, {"referenceID": 8, "context": "[Die05]), and thus tw(G) \u2264 tw(G1).", "startOffset": 0, "endOffset": 7}, {"referenceID": 6, "context": "We have shown that \u03b2-acyclic #SAT can be solved in polynomial time, a question left open in [CDM14].", "startOffset": 92, "endOffset": 99}, {"referenceID": 22, "context": "Instead, \u03b2-acyclic #SAT lies outside the STV-framework of [STV14] that explains all old results in a uniform way.", "startOffset": 58, "endOffset": 65}, {"referenceID": 16, "context": "In this direction, it would be interesting to see if hypergraphs of bounded \u03b2-hypertree width, a width measure generalizing \u03b2-acyclicity proposed in [GP04], can be characterized by elimination orders and if such a characterization can be used to solve #SAT on the respective instances.", "startOffset": 149, "endOffset": 155}, {"referenceID": 17, "context": "Also, even the complexity of deciding SAT on instances of bounded \u03b2-hypertree width is an open problem [OPS13].", "startOffset": 103, "endOffset": 110}, {"referenceID": 22, "context": "For example, is there any uniform explanation for tractability of bounded cliquewidth #SAT and \u03b2-acyclic #SAT, similarly to the way in which the framework of [STV14] explains tractability for all previously known results? Finally, we feel that, although we have shown that the STV-framework does not explain all tractability results for #SAT, it is still a framework that should be studied in the future.", "startOffset": 158, "endOffset": 165}], "year": 2014, "abstractText": "We extend the knowledge about so-called structural restrictions of #SAT by giving a polynomial time algorithm for \u03b2-acyclic #SAT. In contrast to previous algorithms in the area, our algorithm does not proceed by dynamic programming but works along an elimination order, solving a weighted version of constraint satisfaction. Moreover, we give evidence that this deviation from more standard algorithm is not a coincidence, but that there is likely no dynamic programming algorithm of the usual style for \u03b2-acyclic #SAT.", "creator": "LaTeX with hyperref package"}}}