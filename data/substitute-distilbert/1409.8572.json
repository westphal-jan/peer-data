{"id": "1409.8572", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Sep-2014", "title": "Freshness-Aware Thompson Sampling", "abstract": "to follow the dynamicity of the user's content, groups have recently started to model interactions between users and the context - aware recommender systems ( cars ) as a bandit problem where the system needs to compete with exploration and exploitation dilemma. in this sense, we propose researchers study the freshness of the user's content in cars environmental context filtering problem. we introduce in this paper an algorithm named freshness - aware thompson sampling ( fa - av ) that manages the recommendation deemed fresh document according to reasonable user's risk of the situation. the intensive evaluation and the detailed detailing of the experimental results reveals several important discoveries in its exploration / exploit ( cc / exp ) behaviour.", "histories": [["v1", "Mon, 29 Sep 2014 17:17:52 GMT  (51kb,D)", "http://arxiv.org/abs/1409.8572v1", "21st International Conference on Neural Information Processing. arXiv admin note: text overlap witharXiv:1409.7729"]], "COMMENTS": "21st International Conference on Neural Information Processing. arXiv admin note: text overlap witharXiv:1409.7729", "reviews": [], "SUBJECTS": "cs.IR cs.LG", "authors": ["djallel bouneffouf"], "accepted": false, "id": "1409.8572"}, "pdf": {"name": "1409.8572.pdf", "metadata": {"source": "CRF", "title": "Freshness-Aware Thompson Sampling", "authors": ["Djallel Bouneffouf"], "emails": ["Djallel.Bouneffouf}@Orange.com"], "sections": [{"heading": null, "text": "Keywords: CARS, Thompson Sampling, Contextual bandits"}, {"heading": "1 Introduction", "text": "Mobile technologies have made access to a huge collection of information, anywhere and any-time. In this sense, recommender systems must promptly identify the importance of documents to recommend in the great location and moment. Recently, CARS tackle this problem by relating the user\u2019s interest to the user\u2019s situation (time, location, friends). However, they cannot avoid to recommend the same document under the same situations. As a result, a small set of documents are recommended again and again and then are seen as favourite documents, however recommend the same set of documents many times in a short period makes the users feel bored. Works found in literature [9, 8, 1] tackle this problem by addressing the recommendation as a need for balancing exr/exp studied in the \u201dbandit algorithm\u201d. Actually the greatest result in exr/exp is performed by the Thompson Sampling (TS), but its drawback is in the none consideration of the freshness of document in the recommendation. The Freshness can be considered as the strength of strangeness or the amount of forgotten experience [6], and it leads the system to recommend some documents that have not been clicked for a long time because these documents are fresh to users even though they do not click to them multiple times. To this effect, we introduce in this paper an algorithm named Freshness-Aware Thompson Sampling (FATS) that achieves this goal by balancing adaptively the exr/exp trade-off according to the user\u2019s\n?\nar X\niv :1\n40 9.\n85 72\nv1 [\ncs .I\nR ]\n2 9\nSe p\n20 14\nsituation and the document\u2019s freshness. This algorithm extends the TS strategy by exploring fresh documents in suitable user\u2019s situations.\nThe remaining of the paper is organized as follows. Section 2 reviews related works. Section 3 gives key notion used in the paper. Section 4 describes the algorithms involved in the proposed approach. The experimental evaluation is illustrated in Section 5. The last section concludes the paper and points out possible directions for future work."}, {"heading": "2 Related Work", "text": "We refer, in the following, techniques that study the different dimensions of our problem. Multi-Armed Bandit Problem in RS. Recently, research works are dedicated to study the multi-armed bandit problem in RS, considering the user\u2019s behaviour as the context. In [3], authors model CARS as a contextual bandit problem. The authors propose an algorithm called Contextual- -greedy which a perform recommendation sequentially recommends documents based on contextual information about the users\u2019 documents. In [1], authors analyse the TS in contextual bandit problem. The study demonstrate that it has better empirical performance compared to the state-of-art methods. The authors in [3, 1] describe a smart way to balance exr/exp, but do not consider the user\u2019s context and document freshness during the recommendation.\nUser\u2019s Content Dynamicity in RS. To follow the dinamicity of the user\u2019s content, the authors in [5] formulate and study a new variant of the k-armed bandit problem, motivated by e-commerce applications. In their model, arms have (stochastic) lifetime after which they expire. In this setting an algorithm needs to continuously explore new arms, contrarily to the standard k-armed bandit model in which arms are available indefinitely and exploration is reduced once an optimal arm is identified. In this work the dynamicity of the content is considered but the authors do not address the notion of freshness. A notion of freshness of document is used in [7], where the authors propose an RS that considers the freshness of music in recommendation. However they neither consider the freshness in CARS nor in multi-armed bandit problem.\nThe Risk-Aware Decision. The risk-aware decision has been studied for a long time in reinforcement learning, where the risk is defined as the reward criteria that not only takes into account the expected reward, but also some additional statistics of the total reward, such as its variance or standard deviation [10]. In RS the risk is recently studied. The authors in [4] consider the risk of the situations in the recommendation process, and the study yields to the conclusion that considering the risk level of the situation on the exr/exp strategy significantly increases the performance of the recommender system.\nContribution. From this state of the art we observe that none of the existing works have studied the correlation between the user\u2019s situation risk and the freshness document recommendation. This is precisely what we intend to do with Freshness-Aware Thompson Sampling (FATS), the proposing algorithm exploits the following new features: (1) The algorithm takes into consideration\nthe document\u2019s freshness in its exr/exp trade-off by considering the \u201dForgetting Curve\u201d to assess freshness and evaluate favouredness. (2) The algorithm manages the recommendation of fresh documents according to the user\u2019s situation, where the fresh documents are more explored in non-risky situation (the user is at home the user may be interested by a freshness documents) rather than risky or critical situation (the user is at the office, in a meeting or with a client) the system has to do less exploration to avoid disturbing the user."}, {"heading": "3 Key Notion", "text": "This section focuses on introducing the key notions used in this paper. Situation: A situation is an external semantic interpretation of low-level context data, enabling a higher-level specification of human behaviour. More formally, a situation S is a n-dimensional vector, S = (O\u03b41 .c1, O\u03b42 .c2, ..., O\u03b4n .cn) where each ci is a concept of an ontology O\u03b4i representing a context data dimension. According to our need, we consider a situation as a 3-dimensional vector S = (OLocation.ci, OTime.cj , OSocial.ck) where ci, cj , ck are concepts of Location, Time and Social ontologies.\nUser preferences: User preferences UP are deduced during the user navigation activities. UP \u2286 D \u00d7A\u00d7 V where D is a set of documents, A is a set of preference attributes and V a set of values. We focus on the following preference attributes: click, fail , time and recom which respectively correspond to the number of clicks for a document, number of failure (recommended and not clicked), the time spent on a document and the number of times it was recommended.\nThe user model: The user model is structured as a case base composed of a set of situations with their corresponding UP , denoted UM = {(Si;UP i)}, where Si \u2208 S is the user situation and UP i \u2208 UP its user preferences.\nDefinition of risk: \u201dThe risk in recommender systems is the possibility to disturb or to upset the user (which leads to a bad answer of the user)\u201d.\nFrom the precedent definition of the risk, we have proposed to consider in our system Critical Situations (CS) which is a set of situations where the user needs the best information that can be recommended by the system, because he can not be disturbed. This is the case, for instance, of a professional meeting. In such a situation, the system must exclusively perform exploitation rather than exploration-oriented learning. In other cases where the risk of the situation is less important (like for example when the user is using his information system at home, or he is on holiday with friends), the system can make some exploration by recommending information without taking into account his interest.\nTo consider the risk level of the situation in RS, we go further in the definition of situation by adding it a risk level R, as well as one to each concept: S[R]=(O\u03b41 .c1[cv1], O\u03b42 .c2[cv2], ..., O\u03b4n .cn[cvn]) where CV={cv1, cv2, ..., cvn} is the set of risk levels assigned to concepts, cvi \u2208 [0, 1]. R \u2208 [0, 1] is the risk level of situation S, and the set of situations with R = 1 are considered as CS.\nDefinition (Situation Bandit Problem). In a situation bandits problem, there is a distribution P over (Si, r(d1), ..., r(dk)), where S is the situation,\ndi \u2208 D is one of the k document to be recommended, and r(d) \u2208 [0, 1] is the reward for document d. The problem is a repeated game: on each round, a sample (Si, r(d1), ..., r(dk)) is drawn from P , the situation S is announced, and then for one document chosen by the system, its reward r(d) is revealed.\nDefinition (Thompson Sampling). The Thompson Sampling (TS) is a randomized algorithm based on Bayesian ideas. Using Beta prior and considering the Bernoulli bandit problem (the rewards are either 0 or 1), TS initially assumes document d to have prior Beta(1, 1) on \u00b5d (the probability of success). At time t, having observed SUd(t) successes (reward = 1) and FUd(t) failures (reward = 0) in \u03b8d(t) = SUd(t) + FUd(t) selects of document d, the algorithm updates the distribution on \u00b5d as Beta(SUd(t)+1, FUd(t)+1). The algorithm then generates independent samples from these posterior distributions of the \u00b5d, and selects the document with the largest sample value."}, {"heading": "4 FA-TS", "text": "To adapt the FA-TS algorithm to consider freshness document in context aware environment, we propose to compute the similarity between the present situation and each one in the situation base; if there is a situation that can be reused; the algorithm retrieves it, and then applies the TS algorithm. The proposed FA-TS algorithm is described in Algorithm 1 and involves for each trial t = 1...T the following tasks. Task 1: Let St be the current user\u2019s situation, and PS the set of past situations. The system compares St with the situations in PS in order to choose the most similar Sp using the RetrieveCase() method. Task 2: Let D be the document collection and Dp \u2208 D the set of documents recommended in situation Sp. After retrieving Sp, the system observes the user\u2019s behaviour when reading each document di \u2208 Dp. Based on observed rewards, the algorithm chooses the document dp with the greater expected reward rt using the RecommendDocuments() method. To have the appropriate exploration at each situation, the RecommendDocuments() method include a module R(St) that computes the risk of the situation. Task 3: The algorithm improves its document-selection strategy with the new observation (St, dt, rt). The updating of the case base is done using the Auto improvement() method.\nAlgorithm 1 The FA-TS algorithm\n1: Require: d \u2208 D set UP, PS,N 2: Foreach t = 1, 2, ..., T do 3: (Sp, UP p) = RetrieveCase(St, PS, UP,D) // Retrieve the most similar case 4: SelectDocuments(UP p, St, Sp, D,N) // Recommend N documents 5: Receive a feedback UP t from the user 6: Autoimprovement(UP p, UP t, St, Sp, N) // Update user\u2019s profile\nRetrieveCase(): The system compares St with the situations in PS in order to choose the most similar one, Sp = argmaxSi\u2208PSsim(S t, Si). The semantic\nsimilarity metric is computed by: sim(St, Si) = \u2211 \u03b4\u2208\u2206 \u03b1\u03b4sim\u03b4(c t \u03b4, c i \u03b4) (1)\nIn Eq. 1, sim\u03b4 is the similarity metric related to dimension \u03b4 between two concepts ct\u03b4 and c i \u03b4, and \u2206 is the set of dimensions (in our case Location, Time and Social); \u03b1\u03b4 is the weight associated to dimension \u03b4 and it is set out by using an arithmetic mean as follows: \u03b1\u03b4 = 1 t\u22121 ( \u2211t\u22121 k=1 y k \u03b4 ) ,where y k \u03b4 = sim\u03b4(c K \u03b4 , c p \u03b4) at trial k \u2208 {1, ..., t \u2212 1} from the t \u2212 1 previous recommendations, and cp\u03b4 \u2208 Sp. The idea here is to augment the importance of a dimension with the previously corresponding computed similarity values, reflecting the impact of the dimension when computing the most similar situation in Eq.1. The similarity between two concepts of a dimension \u03b4 depends on how closely ct\u03b4 and c i \u03b4 are related in the corresponding ontology. To compute sim\u03b4, we use the same similarity measure as [11]:\nsim\u03b4(c t \u03b4, c i \u03b4) = 2 \u2217\ndepth(LCS)\ndepth(ct\u03b4) + depth(c i \u03b4)\n(2)\nIn Eq. 2, LCS is the Least Common Subsumer of ct\u03b4 and c i \u03b4, and depth is the number of nodes in the path from the current node to the ontology root. SelectDocuments(): The algorithm chooses the document dp with the greatest index P computed as follows:\nP (d) = (1\u2212 ) \u2217 \u03b8(d, Sp)\u2212 \u2217Mr(d) (3)\nIn Eq. 3, \u03b8(d, Sp) = SUd(S p, t) + FUd(S p, t). The idea here is to consider the sampling for each user\u2019s situation rather than all over the situations.\nMr(d) is the strength of strangeness or the amount of experience forgotten. We apply Forgetting Curve [6] to evaluate the freshness of a document to a user. The Forgetting Curve is shown as follows:\nMr(d) = e\u2212 t(d) rsm(d) (4)\nIn Eq. 4, Mr is memory retention, rsm is the relative strength of memory and t is time. The least the amount of memory retention of a document is in a user\u2019s mind, the freshest is the document to the user. In our work, rsm is defined as the number of times the document has been clicked and t is the distance from present time to the last time the document has been clicked.\nTo adapt the impact of the user\u2019s memory retention to context-aware environment, we consider an that manage the weight of the Mr in computing the pertinence of documents. With the assumption that more the situation is risky more the user does not forget the document related to this situation, we propose to reduce recommending fresh document according the risk of the situation. More the situation is risky less fresh document is explored. Concretely, the algorithm computes the weight of , by using the situation risk level R(St), as indicated in Eq. 5.\n= max \u2212R(St) \u2217 ( max \u2212 min) (5)\nA strict exploitation ( =0) leads to a non optimal documents selection strategy, this is why R is multiplied by (1\u2212 min), where min is the minimum exploration allowed in CS and max is the maximum exploration allowed in all situations (these metrics are fixed to max = 0.5\u2227 min = 0.05 using an off-line simulation).\nAutoimprovement(): Depending on the similarity between the current situation St and its most similar situation Sp, two scenarios are possible: (1) If sim(St, Sp) 6= 1 then PS = PS \u222a St \u2227 UP = UP \u222a UP t : the current situation does not exist in the case base; the system adds this new case composed of the current situation St and the current user preferences UP t; (2) If sim(St, Sp) = 1 then Sp = Sp \u222a St \u2227 UP p = UP p \u222a UP t: the situation exists in the case base; the system updates the case having premise the situation Sp with the current user preferences UP t.\nComputing the Risk Level of the Situation: The risk complete level R(St) of the current situation is computed by aggregating three approaches Rc, Rv and Rm as follows:\nR(St) = \u2211 j\u2208J \u03bbjRj(S t) (6)\nIn Eq. 6, Rj is the risk metric related to dimension j \u2208 J , where J = {m, c, v}; \u03bbj is the weight associated to dimension j and it is set out using an off-line evaluation. Rc compute the risk using concepts, Rm compute the risk using the semantic similarity between the current situation and situations stocked in the system and Rv compute the risk using the variance of the reward. The three approaches and their aggregation are described in [2]."}, {"heading": "5 Evaluation of FA-TS", "text": "In order to empirically evaluate the performance of our approach in on-line environment, we conduct our experiment with 3500 users of mobile application. We have randomly split users on five groups, and we assign to each group the mobile application with different recommendation algorithms (the algorithms are described below). Each time the user opens his software he gets 10 documents recommended by the system. To evaluate the impact of the risk we compare FA-TS to a variant with a fixed exploration of freshness like: FA-TS-1: In FA-TS, the risk is fixed to 1 ( = 0), which means that the algorithm does not consider the freshness in its recommendation. FA-TS-0.5: In FA-TS, the risk is fixed to 0.5 ( = 0.5), which means that the algorithm considers the freshness of the documents and the probability computed by the TS to recommend document. FA-TS-0: In FA-TS, the risk is fixed to 0 ( = 1), which means that the algorithm considers just the freshness to recommend document (no consideration of the risk of the situation) and TS: The TS uses the algorithm described in [1] to recommend document without consideration of freshness documents.\nAverage precision on top 10 documents. We compare the algorithms regarding the precision which is the number of user\u2019s clicks on the 10 recommended documents during a navigation session. The average precision (AP) is the mean of the system\u2019s precision for all session during one day, a navigation session is\nthe interval between the time when the user opens the mobile application and the time when he closes it. Note that we do not compute the recall because we can not know a priori all pertinent documents. In Fig. 5, the horizontal axis represents the day of the month and the vertical axis is the performance metric.\nWe have displayed in the Table. 5 the average number of clicks per recommendation and the average time spent on documents (ATSD) for all the 28 days. We have several observations regarding the different algorithms. From the Fig. 5 we can observe that the FA-TS algorithm has effectively the best average precision during this month. We have also observed that FA \u2212 TS \u2212 1 gives better results than TS in term of average clicks, which shows that considering the user\u2019s situation awareness in the TS approach improves its result. FA\u2212TS\u22120.5 gives better result than FA\u2212 TS \u2212 1, which is explained by the consideration of the documents freshness in the TS. FA \u2212 TS outperforms FA \u2212 TS \u2212 0.5, which shows that managing the freshness of the document according to the situation\u2019s risk gives better result than a fixed approaches. An other interesting observation is in the fact that FA\u2212 TS \u2212 0 outperform TS, which shows the impotence of considering the freshness which is not done by the TS. From the Table. 5 we can say that the ATSD does not significantly change from an algorithm to an other, which means that the exr/exp trade-off does not impact the user\u2019s time spent on documents and let us say that FA-TS gives better result on precision without reducing the quality of the recommended documents."}, {"heading": "6 Conclusion", "text": "In this paper, we have studied the problem of document freshness in CARS and have proposed a new approach that considers the freshness of the document in recommendation regarding the user\u2019s situation. The experimental results demonstrate that considering the freshness on CARS significantly increases their performance. Moreover, this study yields to the conclusion that managing the recommendation of fresh document according to the risk of the situation gives a real add-value in recommendation performance."}], "references": [{"title": "Thompson sampling for contextual bandits with linear payoffs", "author": ["S. Agrawal", "N. Goyal"], "venue": "CoRR, abs/1209.3352", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "DRARS", "author": ["D. Bouneffouf"], "venue": "A Dynamic Risk-Aware Recommender System. PhD thesis, Institut National des T\u00e9l\u00e9communications", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "A contextual-bandit algorithm for mobile context-aware recommender system", "author": ["D. Bouneffouf", "A. Bouzeghoub", "A.L. Gan\u00e7arski"], "venue": "ICONIP (3), pages 324\u2013331", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Risk-aware recommender systems", "author": ["D. Bouneffouf", "A. Bouzeghoub", "A.L. Gan\u00e7arski"], "venue": "ICONIP (1), pages 57\u201365", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Mortal Multi-Armed Bandits", "author": ["D. Chakrabarti", "R. Kumar", "F. Radlinski", "E. Upfal"], "venue": "D. Koller, D. Schuurmans, Y. Bengio, L. Bottou, D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou, editors, NIPS, pages 273\u2013280. MIT Press", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2008}, {"title": "Memory: A contribution to experimental psychology", "author": ["H. Ebbinghaus"], "venue": "Teachers college, Columbia university", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1913}, {"title": "Nextone player: A music recommendation system based on user behavior", "author": ["Y. Hu", "M. Ogihara"], "venue": "In Proceedings of the 12th International Society for Music Information Retrieval Conference,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "A contextual-bandit approach to personalized news article recommendation", "author": ["L. Li", "W. Chu", "J. Langford", "R.E. Schapire"], "venue": "Proceedings of the 19th international conference on World wide web, WWW \u201910, pages 661\u2013 670, USA", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Exploitation and exploration in a performance based contextual advertising system", "author": ["W. Li", "X. Wang", "R. Zhang", "Y. Cui"], "venue": "Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD \u201910, pages 27\u201336, USA", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Investment Science", "author": ["D. Luenberger"], "venue": "Oxford University Press", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1998}, {"title": "Text-learning and related intelligent agents: A survey", "author": ["D. Mladenic"], "venue": "IEEE Intelligent Systems, 14(4):44\u201354", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1999}], "referenceMentions": [{"referenceID": 8, "context": "Works found in literature [9, 8, 1] tackle this problem by addressing the recommendation as a need for balancing exr/exp studied in the \u201dbandit algorithm\u201d.", "startOffset": 26, "endOffset": 35}, {"referenceID": 7, "context": "Works found in literature [9, 8, 1] tackle this problem by addressing the recommendation as a need for balancing exr/exp studied in the \u201dbandit algorithm\u201d.", "startOffset": 26, "endOffset": 35}, {"referenceID": 0, "context": "Works found in literature [9, 8, 1] tackle this problem by addressing the recommendation as a need for balancing exr/exp studied in the \u201dbandit algorithm\u201d.", "startOffset": 26, "endOffset": 35}, {"referenceID": 5, "context": "The Freshness can be considered as the strength of strangeness or the amount of forgotten experience [6], and it leads the system to recommend some documents that have not been clicked for a long time because these documents are fresh to users even though they do not click to them multiple times.", "startOffset": 101, "endOffset": 104}, {"referenceID": 2, "context": "In [3], authors model CARS as a contextual bandit problem.", "startOffset": 3, "endOffset": 6}, {"referenceID": 0, "context": "In [1], authors analyse the TS in contextual bandit problem.", "startOffset": 3, "endOffset": 6}, {"referenceID": 2, "context": "The authors in [3, 1] describe a smart way to balance exr/exp, but do not consider the user\u2019s context and document freshness during the recommendation.", "startOffset": 15, "endOffset": 21}, {"referenceID": 0, "context": "The authors in [3, 1] describe a smart way to balance exr/exp, but do not consider the user\u2019s context and document freshness during the recommendation.", "startOffset": 15, "endOffset": 21}, {"referenceID": 4, "context": "To follow the dinamicity of the user\u2019s content, the authors in [5] formulate and study a new variant of the k-armed bandit problem, motivated by e-commerce applications.", "startOffset": 63, "endOffset": 66}, {"referenceID": 6, "context": "A notion of freshness of document is used in [7], where the authors propose an RS that considers the freshness of music in recommendation.", "startOffset": 45, "endOffset": 48}, {"referenceID": 9, "context": "The risk-aware decision has been studied for a long time in reinforcement learning, where the risk is defined as the reward criteria that not only takes into account the expected reward, but also some additional statistics of the total reward, such as its variance or standard deviation [10].", "startOffset": 287, "endOffset": 291}, {"referenceID": 3, "context": "The authors in [4] consider the risk of the situations in the recommendation process, and the study yields to the conclusion that considering the risk level of the situation on the exr/exp strategy significantly increases the performance of the recommender system.", "startOffset": 15, "endOffset": 18}, {"referenceID": 0, "context": ", cvn} is the set of risk levels assigned to concepts, cvi \u2208 [0, 1].", "startOffset": 61, "endOffset": 67}, {"referenceID": 0, "context": "R \u2208 [0, 1] is the risk level of situation S, and the set of situations with R = 1 are considered as CS.", "startOffset": 4, "endOffset": 10}, {"referenceID": 0, "context": "di \u2208 D is one of the k document to be recommended, and r(d) \u2208 [0, 1] is the reward for document d.", "startOffset": 62, "endOffset": 68}, {"referenceID": 10, "context": "To compute sim\u03b4, we use the same similarity measure as [11]:", "startOffset": 55, "endOffset": 59}, {"referenceID": 5, "context": "We apply Forgetting Curve [6] to evaluate the freshness of a document to a user.", "startOffset": 26, "endOffset": 29}, {"referenceID": 1, "context": "The three approaches and their aggregation are described in [2].", "startOffset": 60, "endOffset": 63}, {"referenceID": 0, "context": "FA-TS-0: In FA-TS, the risk is fixed to 0 ( = 1), which means that the algorithm considers just the freshness to recommend document (no consideration of the risk of the situation) and TS: The TS uses the algorithm described in [1] to recommend document without consideration of freshness documents.", "startOffset": 227, "endOffset": 230}], "year": 2014, "abstractText": "To follow the dynamicity of the user\u2019s content, researchers have recently started to model interactions between users and the ContextAware Recommender Systems (CARS) as a bandit problem where the system needs to deal with exploration and exploitation dilemma. In this sense, we propose to study the freshness of the user\u2019s content in CARS through the bandit problem. We introduce in this paper an algorithm named Freshness-Aware Thompson Sampling (FA-TS) that manages the recommendation of fresh document according to the user\u2019s risk of the situation. The intensive evaluation and the detailed analysis of the experimental results reveals several important discoveries in the exploration/exploitation (exr/exp) behaviour.", "creator": "LaTeX with hyperref package"}}}