{"id": "1410.0736", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Oct-2014", "title": "HD-CNN: Hierarchical Deep Convolutional Neural Network for Large Scale Visual Recognition", "abstract": "existing deep convolutional neural network ( cnn ) architectures are trained as n - way classifiers primarily distinguish between n output classes. this work builds on the intuition that not all classes are equally difficult to distinguish from this true class label. towards this end, threads introduce hierarchical branching cnns, named as progressive deep cnn ( hd - cnn ), wherein classes that can be perfectly distinguished are classified in the higher layer coarse category cnn, while the shorter difficult classifications are done amid lower layer fine length cnn. we propose utilizing a multinomial logistic loss after a severe temporal sparsity penalty for hd - cnn training. wherein they ensure each branching component deals with a minimum more categories confusing to each other. this new web architecture adopts mean - to - fine classification language and module design principle. the proposed model selects nonlinear behavior over standard models. we demonstrate state - of - the - art results on cifar100 benchmark.", "histories": [["v1", "Fri, 3 Oct 2014 01:17:20 GMT  (1483kb,D)", "http://arxiv.org/abs/1410.0736v1", null], ["v2", "Fri, 19 Dec 2014 07:51:51 GMT  (4582kb,D)", "http://arxiv.org/abs/1410.0736v2", "Submission to ICLR 2015"], ["v3", "Sat, 28 Feb 2015 03:11:49 GMT  (4638kb,D)", "http://arxiv.org/abs/1410.0736v3", "Revised based on ICLR 2015 reviews"], ["v4", "Sat, 16 May 2015 03:36:32 GMT  (1000kb,D)", "http://arxiv.org/abs/1410.0736v4", "Add new results on ImageNet using VGG-16-layer building block net"]], "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["zhicheng yan", "hao zhang", "robinson piramuthu", "vignesh jagadeesh", "dennis decoste", "wei di", "yizhou yu"], "accepted": false, "id": "1410.0736"}, "pdf": {"name": "1410.0736.pdf", "metadata": {"source": "CRF", "title": "HD-CNN: Hierarchical Deep Convolutional Neural Network for Image Classification", "authors": ["Zhicheng Yan", "Vignesh Jagadeesh", "Dennis Decoste", "Wei Di", "Robinson Piramuthu"], "emails": ["zyan3@illinois.edu,[vjagadeesh,", "rpiramuthu]@ebay.com"], "sections": [{"heading": "1. Introduction", "text": "Convolutional Neural Networks (CNN) have seen a strong resurgence over the past few years in several areas of computer vision. The primary reasons for this comeback are attributed to increased availability of large-scale datasets and advances in parallel computing resources. For instance, convolutional networks now hold state of the art results in image classification [17, 21, 28, 3], object detection [21, 10, 6], pose estimation [25], face recognition [24] and a variety of other tasks. This work builds on the rich literature of CNNs by exploring a very specific problem in classification. The question we address is: Given a base neural network, is it possible to induce new architectures by arranging the base neural network in a certain sequence to achieve considerable gains in classification accuracy? The base neural network could be a vanilla CNN [14] or a more sophisticated variant like the Network\nin Network [17], and the novel architecture we propose for approaching this problem is named as HD-CNN.\nIntuition behind HD-CNN Conventionally, deep neural networks are trained as N -way classifers, wherein they are trained to tell one category apart from the remaining N \u2212 1 categories. However, it is fairly obvious that some difficult classes are confused more often with a given true class label than others. In other words, for any given class label, it is possible to define a set of easy classes and a set of confusing classes. The intuition behind the HD-CNN framework is to use an initial coarse classifier CNN to separate the easily separable classes from one another. Subsequently, the challenging classes are routed to downstream fine CNNs that just focus on confusing classes. Let us take an example shown in Fig 1. In the CIFAR100 [13] dataset, it is relatively easy to tell an Apple from Bus while telling an Apple from Orange is harder. Images from Apple and Orange can have similar shape, texture and color and correctly telling one from the other is harder. In contrast, images from Bus often have distinctive visual appearance from those in Apple and classification can be expected to be easier. In fact, both categories Apple and Orange belong to the same coarse category fruit and vegetables and category Bus belongs to another coarse category vehicles 1, as defined within CIFAR100. On the one hand, presumably it is easier to train a deep CNN to classify images into coarse categories. On the other hand, it is intuitively satisfying that we can train ar X iv :1 41 0. 07 36\nv1 [\ncs .C\nV ]\n3 O\nct 2\n01 4\na separate deep CNN focusing only on the fine/confusing categories within the same coarse category to achieve better classification performance.\nSalient Features of HD-CNN Architecture: Inspired by the observations above, we propose a generic architecture of convolutional neural network, named as Hierarchical Deep Convolutional Neural Network (HD-CNN), which follows the coarse-to-fine classification strategy and module design principle. It provenly improves classification performance over standard deep CNN models. See Figure 2 for a schematic illustration of the architecture.\n\u2022 A standard deep CNN is chosen to be used as the building block of HD-CNN.\n\u2022 A coarse category component is added to the architecture for predicting the probabilities over coarse categories.\n\u2022 Multiple branching components are independently added. Although each branching component receives the input image and gives a probability distribution over the full set of fine categories, each of them is good at classifying only a subset of categories.\n\u2022 The multiple full predictions from branching components are linearly combined to form the final fine category prediction, weighted by the corresponding coarse category probabilities.\nThis module design gives us the flexibility to choose the most fitting end-to-end deep CNN as the HD-CNN building block for the task under consideration.\nContribution Statement: Our primary contributions in this work are summarized below.\n\u2022 We introduce a novel coarse to fine HD-CNN architecture for hierarchical image classification\n\u2022 We develop strategies for training HD-CNN, including the addition of a temporal sparsity term to the traditional multinomial logistic loss and the usage of HDCNN components pretraining\n\u2022 We empirically illustrate boosting performance of vanilla CNN and NIN building blocks using HD-CNN\nHD-CNN is different from the simple model averaging technique [14]. In model averaging, all the models are capable of classifying the full set of the categories and each one is trained independently. The main sources of their prediction differences include different initializations, different subsets of training set and so on. In HD-CNN, each branching component only excels at classifying a subset of the categories and all the branching components are finetuned jointly. We evaluate HD-CNN on CIFAR100 dataset and report state-of-the-art performance.\nThe paper is organized as follows. We review related work in section 2. The architecture of HD-CNN is elaborated in section 3. The details of HD-CNN training are discussed in section 4. We show experimental results in section 5 and conclude this paper in section 6."}, {"heading": "2. Related Work", "text": ""}, {"heading": "2.1. Convolutional Neural Network", "text": "Convolutional neural networks hold state-of-the-art performance in a variety of computer vision tasks, including image classifcation [14], object detection [6, 10], image parsing[4], face recognition [24], pose estimation [25, 19] and image annotation [8] and so on.\nThere has recently been considerable interest in enhancing specific components in CNN architecture, including pooling layers [27], activation units [9, 22], nonlinear layers [17]. These changes either facilitate fast and stable network training [27], or expand the network\u2019s capacity of learning more complicated and highly nonlinear functions [9, 22, 17].\nIn this work, we do not redesign a specific part within any existing CNN model. Instead, we design a novel generic CNN architecture that is capable of wrapping around an existing CNN model as a building block. We assemble multiple building blocks into a larger Hierarchical Deep CNN model. In HD-CNN, each building block tackles an easier problem and is promising to give better performance. When each building block in HD-CNN excels at solving its assigned task and together they are well coordinated, the entire HD-CNN is able to deliver better performance, as shown in section 5."}, {"heading": "2.2. Image Classification", "text": "The architecture proposed through this work is fairly generic, and can be applied to computer vision tasks where the CNN is applicable. In order to keep the discussion focussed, and illustrate a proof of concept of our ideas, we adopt the problem of image classification.\nClassical image classification systems in vision use handcrafted features like SIFT [18] and SURF [1] to cap-\nture spatially consistent bag of words [15] model for image classification. More recently, the breakthrough paper of Krizhevsky et al. [14] showed massive improvement gains on the imagenet challenge while using a CNN. Subsequently, there have been multiple efforts to enhance this basic model for the image classification task.\nImpressive performance on the CIFAR dataset has been achieved using recently proposed Network in Network [17], Maxout networks and variants [9, 22], and exploiting tree based priors [23] while training CNNs. Further, several authors have investigated the use of CNNs as feature extractors [20] on which discriminative classifiers are trained for predicting class labels. The recent work by [26] proposes to optimize a multi-label loss function that exploits the structure in output label space.\nThe strength of HD-CNN comes from explicit use of hierarchy, designed based on classification performance. Use of hierarchy for multi-class problems has been studied before. In [7], the authors used a fast initial na\u0131\u0308ve bayes training sweep to find the hardest classes from the confusion matrix and then trained SVMs to separate each of the hardest class pairs. However, to our knowledge, we are the first to incorporate hierarchy in the context of Deep CNNs, by solving coarse classification followed by fine classification. This also enables us to exploit deeper networks without increasing the complexity of training.\n3. Overview of HD-CNN Our HD-CNN training approach is summarized in Algorithm 1."}, {"heading": "3.1. Notations", "text": "The following notations are used for the discussion below. A dataset consists of Nt training samples {xti, yti} Nt i=1 and Ns testing samples {xsi , ysi } Ns i=1. xi and yi denote the image data and label, respectively. There are C fine categories in the dataset {Sk}Ck=1. We will identify C \u2032 coarse categories as elaborated in section 4.1.1.\n3.2. HD-CNN Architecture\nSimilar to the standard deep CNN model, Hierarchical Deep Convolutional Neural Network (HD-CNN) achieves end-to-end classification as can be seen in Figure 2. It mainly comprises three parts, namely a single coarse category component B, multiple branching fine category components {F j}C\u2032j=1 and a single probabilistic averaging layer. On the left side of Fig 2 is the single coarse category component. It receives raw image pixel as input and outputs a probability distribution over coarse categories. We use coarse category probabilities to assign weights to the full predictions made by branching fine category components.\nIn the middle of Fig 2 are a set of branching components, each of which makes a prediction over the full set of\nAlgorithm 1 HD-CNN training algorithm 1: procedure HD-CNN TRAINING 2: Step 1: Pretrain HD-CNN 3: Step 1.1: Identify coarse categories using train-\ning set only (Section 4.1.1) 4: Step 1.2: Pretrain coarse category component\n(Section 4.1.2) 5: Step 1.3: Pretrain fine category components\n(Section 4.1.3) 6: Step 2: Fine-tune HD-CNN (Section 4.2)\nfine categories. Branching components share parameters in shallow layers but have independent deep layers. The reason for sharing parameters in shallow layers is three-fold. First, in shallow layers CNN usually extracts primitive lowlevel features (e.g. blobs, corners) [28] which are useful for classifying all fine categories. Second, it greatly reduces the total number of parameters in HD-CNN which is critical to the success of training a good HD-CNN model. If we build up each branching fine category component completely independent to each other, the number of free parameters in HD-CNN will be linearly proportional to the number of coarse categories. An overly large number of parameters in the model will make the training extremely difficult. Third, both the computational cost and memory consumption of HD-CNN are also reduced, which is of practical significance to deploy HD-CNN in real applications.\nOn the right side of Figure 2 is the probabilistic averaging layer which receives branching component predictions as well as the coarse component prediction and produces a weighted average as the final prediction (Equation 1).\np(xi) = C\u2032\u2211 j=1 Bijpj(xi) (1)\nwhere Bij is the probability of coarse category j for image i predicted by the coarse category componentB. pj(xi) is the fine category prediction made by the j-th branching component F j for image i.\nWe stress that both coarse category component and fine category components can be implemented as any end-toend deep CNN model which takes a raw image as input and returns probabilistic prediction over categories as output. This flexible module design allows us to choose the best module CNN as the building block depending on the task we are tackling.\n4. Training HD-CNN with Temporal Sparsity Penalty\nThe purpose of adding multiple branching CNN components into HD-CNN is to make each one excel in classifying\na subset of fine categories. To ensure each branch consistently focuses on a subset of fine categories, we add a Temporal Sparsity Penalty term to the multinomial logistic loss function for training. The revised loss function we use to train HD-CNN is shown in Equation 2.\nE = \u2212 1 n n\u2211 i=1 pyi log(pyi) + \u03bb 2 C\u2032\u2211 j=1 (tj \u2212 1 n n\u2211 i=1 Bij) 2 (2)\nwhere n is the size of training mini-batch. yi is the ground truth label for image i. \u03bb is a regularization constant and is set to \u03bb = 5. Bij is the probability of coarse category j for image i predicted by the coarse category component B. tj is the target temporal sparsity of branch j.\nWe\u2019re not the first one using temporal sparsity penalty for regularization. In [16], a similar temporal sparsity term is adopted to regularize the learning of sparse restricted Boltzmann machines in an unsupervised setting. The difference is we use temporal sparsity penalty to regularize the supervised HD-CNN training. In section 5, we show that with a proper initialization, the temporal sparsity term can ensure each branching component focuses on classifying a different subset of fine categories and prevent a small number of branches receiving the majority of coarse category probability mass.\nThe complete workflow of HD-CNN network training is summarized in Algorithm 1. It mainly consists of a pretraining stage and a fine-tuning stage, both of which are elaborated below.\n4.1. Pretraining HD-CNN\nCompared with training a HD-CNN from scratch, finetuning the entire HD-CNN with pretrained components has several benefits.\n\u2022 First, assume that both the coarse category component and branching components choose a similar implementation of a standard deep CNN. Compared with the standard deep CNN model, we have additional free parameters from shared branching shallow layers as well as C \u2032 independent branching deep layers. This will greatly increase the number of free parameters within HD-CNN. With the same amount of training data, overfitting problem is more likely to hurt the training process if the HD-CNN is trained from scratch. Pretraining is proven to be effective for overcoming the difficulty of insufficient training data [6].\n\u2022 Second, a good initialization for the coarse category component will be beneficial for branching components to focus on a consistent subset of fine categories that are much harder to classify. For example, the branching component 1 excels in telling Apple from\nOrange while the branching component 2 is more capable of telling Bus from Train. To achieve this goal, we have developed an effective procedure to identify a set of coarse categories which coarse category component is pretrained to classify (Section 4.1.1 and 4.1.2).\n\u2022 Third, a proper pretraining for the branching fine category components can increase the chance that we can learn a better branching component over the standard deep CNN for classifying a subset of fine categories this branch focuses on (Section 4.1.3)."}, {"heading": "4.1.1 Identifying Coarse Categories", "text": "For most classification datasets, the given labels {yi}Ni=1 represent fine-level labels and we have no prior about the number of coarse categories as well as the membership of each fine category. Therefore, we develop a simple but effective strategy to identify them.\n\u2022 First, we divide the training samples {xti, yti} Nt i=1 into\ntwo parts train train and train val. We train a standard deep CNN model using the train train part and evaluate it on the train val part.\n\u2022 Second, we plot the confusion matrix F of size C \u00d7C from train val part. A distance matrix D is derived as D = 1 \u2212 F. We make D\u2019s diagonal elements to zero. To make D symmetric, we transform it by computing D = 0.5 \u2217 (D + DT ). The entry Dij measures how easy it is to tell category i from category j.\n\u2022 Third, Laplacian eigenmap [2] is used to obtain lowdimensional feature representations {fi}Ci=1 for the fine categories. Such representations preserve local neighborhood information on a low-dimensional manifold and are used to cluster fine categories into coarse categories. We choose to use knn nearest neighbors to construct the adjacency graph with knn = 3. The weights of the adjacency graph are set by using a heat kernel with width parameter t = 0.95. The dimensionality of {fi}Ci=1 is chosen to be 3.\n\u2022 Last, Affinity Propagation [5] is employed to cluster C fine categories into C \u2032 coarse categories. We choose to use Affinity Propagation because it can automatically induce the number of coarse categories and empirically lead to more balanced clusters in size than other clustering methods, such as k-means clustering. Balanced clusters are helpful to ensure each branching component handles a similar number of fine categories and thus has a similar amount of workload. The damping factor \u03bb in Affinity Propagation algorithm can affect the number of resulting clusters and it is set to 0.98 throughout the paper. The result here is a mapping\nP : y 7\u2192 y\u2032 from the fine categories to the coarse categories.\nTarget temporal sparsity. The coarse-to-fine category mapping P also provides a natural way to specify the target temporal sparsity {tj}j=1,...,C\u2032 . Specifically, tj is set to be the fraction of all the training images within the coarse category j (Equation 3) under the assumption that the distribution over coarse categories across the entire training dataset is identical to that within a training mini-batch.\ntj = \u2211 k|P (k)=j |Sk|\u2211C\nk=1 |Sk| (3)\nwhere Sk is the set of images from fine category k."}, {"heading": "4.1.2 Pretraining the Coarse Category Component", "text": "To pretrain the coarse category component, we first replace fine category labels {yti} with coarse category labels using the mapping P : y 7\u2192 y\u2032. The full set of training samples {xti, y\u2032 t i} Nt i=1 are used to train a standard deep CNN model which outputs a probability distribution over the coarse categories. After that, we copy the learned parameters from the standard deep CNN to the coarse category component of HD-CNN."}, {"heading": "4.1.3 Pretraining the Fine Category Components", "text": "Branching fine category components {F j}C\u2032j=1 are also independently pretrained. First, before pretraining each branching component we train a standard deep CNN model F p from scratch using all the training samples {xti, yti} Nt i=1. Second, we initialize each branching component F j by copying the learnt parameters from F p into F j and finetune F j by only using training images with fine labels yti such that P (yti) = j. By using the images within the same coarse category j for fine-tuning, each branching component F i is adapted to achieve better performance for the fine categories within the coarse category j and is allowed to be not discriminative for other fine categories.\n4.2. Fine-tuning HD-CNN\nAfter both coarse category component and branching fine category components are properly pretrained, we finetune the entire HD-CNN using the multinomial logistic loss function with the temporal sparsity penalty. We prefer to use larger training mini-batch as it gives better estimations of the temporal sparsity."}, {"heading": "5. Experiments", "text": ""}, {"heading": "5.1. Overview", "text": "We evaluate HD-CNN on the benchmark dataset CIFAR100 [12]. To demonstrate that HD-CNN is a generic architecture, We experiment with two different building block\nnetworks on CIFAR100 dataset. In both cases, HD-CNN can achieve superior performance over the building block network alone.\nWe implement HD-CNN on the widely deployed Caffe [11] project and plan to release our code. We follow [9] to preprocess the datasets (e.g. global contrast normalization and ZCA whitening). For CIFAR100, we use randomly cropped image patch of size 26 \u00d7 26 and their horizontal reflections for training, For testing, we use multiview testing [14]. Specifically, we extract five 26 \u00d7 26 patches (the 4 corner patches and the center patch) as well as their horizontal reflections and average their predictions.\nWe follow [14] to update the network parameter by back propagation. We use small mini-batches of size 100 for pretraining components and large mini-batches of size 250 for fine-tuning the entire HD-CNN. We start the training with a fixed learning rate and decrease it by a factor of 10 after the training error stops improving. We decrease the learning rate up to a factor of 2."}, {"heading": "5.2. CIFAR100", "text": "The CIFAR100 dataset consists of 100 classes of natural images. There are 50, 000 training images and 10, 000 testing images. For identifying coarse categories, we randomly choose 10, 000 images from the training set as the train val part and the rest are used as the train train part."}, {"heading": "5.2.1 CNN Building Block", "text": "We use a standard CNN network CIFAR100-CNN as the building block. The CIFAR100-CNN network consists of 3 convolutional layers, 1 fully-connected layer and 1 SOFTMAX layer. There are 64 filters in each convolutional layer. Rectified linear units (ReLU) are used as the activation units. Pooling layers and response normalization layers are also used between convolutional layers. The complete CIFAR100-CNN architecture is defined in Table 1.\nWe identify four coarse categories and the fine categories within each coarse category are listed in Table 3. Accordingly, we build up a HD-CNN with four branching components using CIFAR100-CNN building block. Branching components share layers from conv1 to norm1 but have independent layers from conv2 to prob.\nWe compare the test accuracies of a standard CIFAR100CNN network and a HD-CNN with CIFAR100-CNN building block in Table 4. The HD-CNN achieves testing accuracy 58.72% which improves the performance of the baseline CIFAR100-CNN of 55.51% by more than 3%.\nWe dissect the HD-CNN by computing the finecategory-wise testing accuracy for each branching component. This can be done by using the single full prediction from a branching component. For a branching component j, we sort the fine categories {k}Ck=1 in descending order based on the mean coarse probability {Mkj}Ck=1 where Mkj = 1 |ysi=k| \u2211 ysi=k Bij . The fine-category-wise testing accuracies for the four branching components are shown in Figure 3. Clearly, each branching component only excels classifying the top ranked categories while can not distinguish categories of low rank. Furthermore, if we treat the single prediction from a branching component as the final prediction, the four branching components will have testing accuracies 15.82%, 21.23%, 9.24% and 19.57% on the entire testing set, respectively. But when the branching predictions are linearly combined using the coarse category prediction as the weights, the accuracy increases to 58.72%."}, {"heading": "5.2.2 NIN Building Block", "text": "In [17], a NIN network with three stacked mlpconv layers achieves state-of-the-art testing accuracy 64.32%. The network definition files are publicly available1. The complete architecture, named as CIFAR100-NIN, is shown in Table 2. We use CIFAR100-NIN as the building block and build up a HD-CNN with five branching components. Branching components share layers from conv1 to conv2 but have independent layers from cccp3 to prob.\nWe achieve testing accuracy 65.33% which improves the current best method NIN [17] by 0.61% and sets new state-\n1https://github.com/mavenlin/cuda-convnet/blob/ master/NIN/cifar-100_def\nof-the-art results of a single network on CIFAR100.\nWe also compare HD-CNN performance with simple model averaging results. We independently train five CIFAR100-NIN networks with random parameter initialization and take their averaged prediction as the final prediction. We obtain testing accuracy 66.53% which is about 1.2% higher than that of HD-CNN (Table 5). To our best knowledge, this is also the best results ever reported in the literature using multiple networks. However, model averaging requires training and evaluation of five independent standard models. Furthermore, HD-CNN is orthogonal to the model averaging technique and an ensemble of HDCNN networks can further improve the performance.\nEffectiveness of the temporal sparsity penalty. To verify the effectiveness of temporal sparsity penalty in our loss function (2), we fine-tune a HD-CNN using the traditional multinomial logistic loss function. The testing accuracy is 64.12%, which is more than 1% worse than that of a HDCNN trained with temporal sparsity penalty. We find that without the temporal sparsity penalty regularization, the coarse category probability concentration issue arises. In\nother words, the trained coarse category component consistently assigns nearly 100% probability mass to one of branching fine category components. In this case, the final averaged prediction is dominated by the single prediction of a certain branching component. This downgrades the HDCNN back to the standard building block model and thus has a similar performance as the standard model.\n5.2.3 Computational Complexity of HD-CNN\nDue to the use of shared layers in the branching components, the increase of computational complexity of HD-\nCNN is sublinearly proportional to the number of branching components when compared with building block models. We compare the computational complexity at testing time between HD-CNN models and standard building block models in terms of GPU memory consumption and time cost for the entire test set (Table 6). The mini-batch size is 100."}, {"heading": "6. Conclusions", "text": "HD-CNN is a flexible deep CNN architecture to improve over existing deep CNN models. It adopts coarse-to-fine classification strategy and network module design principle. It can achieve state-of-the-art performance on CIFAR100."}], "references": [{"title": "Surf: Speeded up robust features", "author": ["H. Bay", "T. Tuytelaars", "L. Van Gool"], "venue": "ECCV 2006, pages 404\u2013417. Springer", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Laplacian eigenmaps for dimensionality reduction and data representation", "author": ["M. Belkin", "P. Niyogi"], "venue": "Neural computation, 15(6):1373\u20131396", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2003}, {"title": "Multi-column deep neural networks for image classification", "author": ["D. Ciresan", "U. Meier", "J. Schmidhuber"], "venue": "Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pages 3642\u20133649. IEEE", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning hierarchical features for scene labeling", "author": ["C. Farabet", "C. Couprie", "L. Najman", "Y. LeCun"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on, 35(8):1915\u2013 1929", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Clustering by passing messages between data points", "author": ["B.J. Frey", "D. Dueck"], "venue": "Science, 315:972\u2013976", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["R. Girshick", "J. Donahue", "T. Darrell", "J. Malik"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Scaling multiclass support vector machines using inter-class confusion", "author": ["S. Godbole", "S. Sarawagi", "S. Chakrabarti"], "venue": "Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201902, pages 513\u2013518, New York, NY, USA", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2002}, {"title": "Deep convolutional ranking for multilabel image annotation", "author": ["Y. Gong", "Y. Jia", "T. Leung", "A. Toshev", "S. Ioffe"], "venue": "CoRR, abs/1312.4894", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "Maxout networks", "author": ["I.J. Goodfellow", "D. Warde-Farley", "M. Mirza", "A. Courville", "Y. Bengio"], "venue": "ICML", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Spatial pyramid pooling in deep convolutional networks for visual recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "Computer Vision\u2013ECCV 2014, pages 346\u2013361. Springer", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Caffe: An open source convolutional architecture for fast feature embedding", "author": ["Y. Jia"], "venue": "http://caffe. berkeleyvision.org/", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky", "G. Hinton"], "venue": "Computer Science Department, University of Toronto, Tech. Rep", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky", "G.E. Hinton"], "venue": "Masters thesis, Department of Computer Science, University of Toronto", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in neural information processing systems, pages 1097\u20131105", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories", "author": ["S. Lazebnik", "C. Schmid", "J. Ponce"], "venue": "Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on, volume 2, pages 2169\u20132178. IEEE", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "Sparse deep belief net model for visual area v2", "author": ["H. Lee", "C. Ekanadham", "A.Y. Ng"], "venue": "Advances in neural information processing systems, pages 873\u2013880", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2008}, {"title": "Network in network", "author": ["M. Lin", "Q. Chen", "S. Yan"], "venue": "CoRR, abs/1312.4400", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Object recognition from local scale-invariant features", "author": ["D.G. Lowe"], "venue": "Computer Vision, 1999. Proceedings. Seventh IEEE International Conference on, volume 2, pages 1150\u2013 1157. IEEE", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1999}, {"title": "Multi-source deep learning for human pose estimation", "author": ["W. Ouyang", "X. Chu", "X. Wang"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2329\u20132336", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "Cnn features off-the-shelf: an astounding baseline for recognition", "author": ["A.S. Razavian", "H. Azizpour", "J. Sullivan", "S. Carlsson"], "venue": "arXiv preprint arXiv:1403.6382", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Overfeat: Integrated recognition", "author": ["P. Sermanet", "D. Eigen", "X. Zhang", "M. Mathieu", "R. Fergus", "Y. LeCun"], "venue": "localization and detection using convolutional networks. In International Conference on Learning Representations ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Improving deep neural networks with probabilistic maxout units", "author": ["J.T. Springenberg", "M. Riedmiller"], "venue": "arXiv preprint arXiv:1312.6116", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "Discriminative transfer learning with tree-based priors", "author": ["N. Srivastava", "R. Salakhutdinov"], "venue": "Advances in Neural Information Processing Systems, pages 2094\u20132102", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "Deepface: Closing the gap to human-level performance in face verification", "author": ["Y. Taigman", "M. Yang", "M. Ranzato", "L. Wolf"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1701\u20131708", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}, {"title": "Deeppose: Human pose estimation via deep neural networks", "author": ["A. Toshev", "C. Szegedy"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2014}, {"title": "Cnn: Single-label to multi-label", "author": ["Y. Wei", "W. Xia", "J. Huang", "B. Ni", "J. Dong", "Y. Zhao", "S. Yan"], "venue": "arXiv preprint arXiv:1406.5726", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "Stochastic pooling for regularization of deep convolutional neural networks", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "International Conference on Learning Representations (ICLR)", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "Visualizing and understanding convolutional networks", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "Computer Vision\u2013ECCV 2014, pages 818\u2013833. Springer", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 16, "context": "For instance, convolutional networks now hold state of the art results in image classification [17, 21, 28, 3], object detection [21, 10, 6], pose estimation [25], face recognition [24] and a variety of other tasks.", "startOffset": 95, "endOffset": 110}, {"referenceID": 20, "context": "For instance, convolutional networks now hold state of the art results in image classification [17, 21, 28, 3], object detection [21, 10, 6], pose estimation [25], face recognition [24] and a variety of other tasks.", "startOffset": 95, "endOffset": 110}, {"referenceID": 27, "context": "For instance, convolutional networks now hold state of the art results in image classification [17, 21, 28, 3], object detection [21, 10, 6], pose estimation [25], face recognition [24] and a variety of other tasks.", "startOffset": 95, "endOffset": 110}, {"referenceID": 2, "context": "For instance, convolutional networks now hold state of the art results in image classification [17, 21, 28, 3], object detection [21, 10, 6], pose estimation [25], face recognition [24] and a variety of other tasks.", "startOffset": 95, "endOffset": 110}, {"referenceID": 20, "context": "For instance, convolutional networks now hold state of the art results in image classification [17, 21, 28, 3], object detection [21, 10, 6], pose estimation [25], face recognition [24] and a variety of other tasks.", "startOffset": 129, "endOffset": 140}, {"referenceID": 9, "context": "For instance, convolutional networks now hold state of the art results in image classification [17, 21, 28, 3], object detection [21, 10, 6], pose estimation [25], face recognition [24] and a variety of other tasks.", "startOffset": 129, "endOffset": 140}, {"referenceID": 5, "context": "For instance, convolutional networks now hold state of the art results in image classification [17, 21, 28, 3], object detection [21, 10, 6], pose estimation [25], face recognition [24] and a variety of other tasks.", "startOffset": 129, "endOffset": 140}, {"referenceID": 24, "context": "For instance, convolutional networks now hold state of the art results in image classification [17, 21, 28, 3], object detection [21, 10, 6], pose estimation [25], face recognition [24] and a variety of other tasks.", "startOffset": 158, "endOffset": 162}, {"referenceID": 23, "context": "For instance, convolutional networks now hold state of the art results in image classification [17, 21, 28, 3], object detection [21, 10, 6], pose estimation [25], face recognition [24] and a variety of other tasks.", "startOffset": 181, "endOffset": 185}, {"referenceID": 13, "context": "The question we address is: Given a base neural network, is it possible to induce new architectures by arranging the base neural network in a certain sequence to achieve considerable gains in classification accuracy? The base neural network could be a vanilla CNN [14] or a more sophisticated variant like the Network Apple Orange Bus", "startOffset": 264, "endOffset": 268}, {"referenceID": 16, "context": "in Network [17], and the novel architecture we propose for approaching this problem is named as HD-CNN.", "startOffset": 11, "endOffset": 15}, {"referenceID": 12, "context": "In the CIFAR100 [13] dataset, it is relatively easy to tell an Apple from Bus while telling an Apple from Orange is harder.", "startOffset": 16, "endOffset": 20}, {"referenceID": 13, "context": "HD-CNN is different from the simple model averaging technique [14].", "startOffset": 62, "endOffset": 66}, {"referenceID": 13, "context": "Convolutional neural networks hold state-of-the-art performance in a variety of computer vision tasks, including image classifcation [14], object detection [6, 10], image parsing[4], face recognition [24], pose estimation [25, 19] and image annotation [8] and so on.", "startOffset": 133, "endOffset": 137}, {"referenceID": 5, "context": "Convolutional neural networks hold state-of-the-art performance in a variety of computer vision tasks, including image classifcation [14], object detection [6, 10], image parsing[4], face recognition [24], pose estimation [25, 19] and image annotation [8] and so on.", "startOffset": 156, "endOffset": 163}, {"referenceID": 9, "context": "Convolutional neural networks hold state-of-the-art performance in a variety of computer vision tasks, including image classifcation [14], object detection [6, 10], image parsing[4], face recognition [24], pose estimation [25, 19] and image annotation [8] and so on.", "startOffset": 156, "endOffset": 163}, {"referenceID": 3, "context": "Convolutional neural networks hold state-of-the-art performance in a variety of computer vision tasks, including image classifcation [14], object detection [6, 10], image parsing[4], face recognition [24], pose estimation [25, 19] and image annotation [8] and so on.", "startOffset": 178, "endOffset": 181}, {"referenceID": 23, "context": "Convolutional neural networks hold state-of-the-art performance in a variety of computer vision tasks, including image classifcation [14], object detection [6, 10], image parsing[4], face recognition [24], pose estimation [25, 19] and image annotation [8] and so on.", "startOffset": 200, "endOffset": 204}, {"referenceID": 24, "context": "Convolutional neural networks hold state-of-the-art performance in a variety of computer vision tasks, including image classifcation [14], object detection [6, 10], image parsing[4], face recognition [24], pose estimation [25, 19] and image annotation [8] and so on.", "startOffset": 222, "endOffset": 230}, {"referenceID": 18, "context": "Convolutional neural networks hold state-of-the-art performance in a variety of computer vision tasks, including image classifcation [14], object detection [6, 10], image parsing[4], face recognition [24], pose estimation [25, 19] and image annotation [8] and so on.", "startOffset": 222, "endOffset": 230}, {"referenceID": 7, "context": "Convolutional neural networks hold state-of-the-art performance in a variety of computer vision tasks, including image classifcation [14], object detection [6, 10], image parsing[4], face recognition [24], pose estimation [25, 19] and image annotation [8] and so on.", "startOffset": 252, "endOffset": 255}, {"referenceID": 26, "context": "There has recently been considerable interest in enhancing specific components in CNN architecture, including pooling layers [27], activation units [9, 22], nonlinear layers [17].", "startOffset": 125, "endOffset": 129}, {"referenceID": 8, "context": "There has recently been considerable interest in enhancing specific components in CNN architecture, including pooling layers [27], activation units [9, 22], nonlinear layers [17].", "startOffset": 148, "endOffset": 155}, {"referenceID": 21, "context": "There has recently been considerable interest in enhancing specific components in CNN architecture, including pooling layers [27], activation units [9, 22], nonlinear layers [17].", "startOffset": 148, "endOffset": 155}, {"referenceID": 16, "context": "There has recently been considerable interest in enhancing specific components in CNN architecture, including pooling layers [27], activation units [9, 22], nonlinear layers [17].", "startOffset": 174, "endOffset": 178}, {"referenceID": 26, "context": "These changes either facilitate fast and stable network training [27], or expand the network\u2019s capacity of learning more complicated and highly nonlinear functions [9, 22, 17].", "startOffset": 65, "endOffset": 69}, {"referenceID": 8, "context": "These changes either facilitate fast and stable network training [27], or expand the network\u2019s capacity of learning more complicated and highly nonlinear functions [9, 22, 17].", "startOffset": 164, "endOffset": 175}, {"referenceID": 21, "context": "These changes either facilitate fast and stable network training [27], or expand the network\u2019s capacity of learning more complicated and highly nonlinear functions [9, 22, 17].", "startOffset": 164, "endOffset": 175}, {"referenceID": 16, "context": "These changes either facilitate fast and stable network training [27], or expand the network\u2019s capacity of learning more complicated and highly nonlinear functions [9, 22, 17].", "startOffset": 164, "endOffset": 175}, {"referenceID": 17, "context": "Classical image classification systems in vision use handcrafted features like SIFT [18] and SURF [1] to cap-", "startOffset": 84, "endOffset": 88}, {"referenceID": 0, "context": "Classical image classification systems in vision use handcrafted features like SIFT [18] and SURF [1] to cap-", "startOffset": 98, "endOffset": 101}, {"referenceID": 14, "context": "ture spatially consistent bag of words [15] model for image classification.", "startOffset": 39, "endOffset": 43}, {"referenceID": 13, "context": "[14] showed massive improvement gains on the imagenet challenge while using a CNN.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "Impressive performance on the CIFAR dataset has been achieved using recently proposed Network in Network [17], Maxout networks and variants [9, 22], and exploiting tree based priors [23] while training CNNs.", "startOffset": 105, "endOffset": 109}, {"referenceID": 8, "context": "Impressive performance on the CIFAR dataset has been achieved using recently proposed Network in Network [17], Maxout networks and variants [9, 22], and exploiting tree based priors [23] while training CNNs.", "startOffset": 140, "endOffset": 147}, {"referenceID": 21, "context": "Impressive performance on the CIFAR dataset has been achieved using recently proposed Network in Network [17], Maxout networks and variants [9, 22], and exploiting tree based priors [23] while training CNNs.", "startOffset": 140, "endOffset": 147}, {"referenceID": 22, "context": "Impressive performance on the CIFAR dataset has been achieved using recently proposed Network in Network [17], Maxout networks and variants [9, 22], and exploiting tree based priors [23] while training CNNs.", "startOffset": 182, "endOffset": 186}, {"referenceID": 19, "context": "Further, several authors have investigated the use of CNNs as feature extractors [20] on which discriminative classifiers are trained for predicting class labels.", "startOffset": 81, "endOffset": 85}, {"referenceID": 25, "context": "The recent work by [26] proposes to optimize a multi-label loss function that exploits the structure in output label space.", "startOffset": 19, "endOffset": 23}, {"referenceID": 6, "context": "In [7], the authors used a fast initial na\u0131\u0308ve bayes training sweep to find the hardest classes from the confusion matrix and then trained SVMs to separate each of the hardest class pairs.", "startOffset": 3, "endOffset": 6}, {"referenceID": 27, "context": "blobs, corners) [28] which are useful for classifying all fine categories.", "startOffset": 16, "endOffset": 20}, {"referenceID": 15, "context": "In [16], a similar temporal sparsity term is adopted to regularize the learning of sparse restricted Boltzmann machines in an unsupervised setting.", "startOffset": 3, "endOffset": 7}, {"referenceID": 5, "context": "Pretraining is proven to be effective for overcoming the difficulty of insufficient training data [6].", "startOffset": 98, "endOffset": 101}, {"referenceID": 1, "context": "\u2022 Third, Laplacian eigenmap [2] is used to obtain lowdimensional feature representations {fi}i=1 for the fine categories.", "startOffset": 28, "endOffset": 31}, {"referenceID": 4, "context": "\u2022 Last, Affinity Propagation [5] is employed to cluster C fine categories into C \u2032 coarse categories.", "startOffset": 29, "endOffset": 32}, {"referenceID": 11, "context": "We evaluate HD-CNN on the benchmark dataset CIFAR100 [12].", "startOffset": 53, "endOffset": 57}, {"referenceID": 10, "context": "We implement HD-CNN on the widely deployed Caffe [11] project and plan to release our code.", "startOffset": 49, "endOffset": 53}, {"referenceID": 8, "context": "We follow [9] to preprocess the datasets (e.", "startOffset": 10, "endOffset": 13}, {"referenceID": 13, "context": "For CIFAR100, we use randomly cropped image patch of size 26 \u00d7 26 and their horizontal reflections for training, For testing, we use multiview testing [14].", "startOffset": 151, "endOffset": 155}, {"referenceID": 13, "context": "We follow [14] to update the network parameter by back propagation.", "startOffset": 10, "endOffset": 14}, {"referenceID": 22, "context": "ConvNet + Tree based priors [23] 63.", "startOffset": 28, "endOffset": 32}, {"referenceID": 16, "context": "Network in nework [17] 64.", "startOffset": 18, "endOffset": 22}, {"referenceID": 16, "context": "In [17], a NIN network with three stacked mlpconv layers achieves state-of-the-art testing accuracy 64.", "startOffset": 3, "endOffset": 7}, {"referenceID": 16, "context": "33% which improves the current best method NIN [17] by 0.", "startOffset": 47, "endOffset": 51}], "year": 2014, "abstractText": "Existing deep convolutional neural network (CNN) architectures are trained as N-way classifiers to distinguish between N output classes. This work builds on the intuition that not all classes are equally difficult to distinguish from a true class label. Towards this end, we introduce hierarchical branching CNNs, named as Hierarchical Deep CNN (HD-CNN), wherein classes that can be easily distinguished are classified in the higher layer coarse category CNN, while the most difficult classifications are done on lower layer fine category CNN. We propose utilizing a multinomial logistic loss and a novel temporal sparsity penalty for HD-CNN training. Together they ensure each branching component deals with a subset of categories confusing to each other. This new network architecture adopts coarseto-fine classification strategy and module design principle. The proposed model achieves superior performance over standard models. We demonstrate state-of-the-art results on CIFAR100 benchmark.", "creator": "LaTeX with hyperref package"}}}