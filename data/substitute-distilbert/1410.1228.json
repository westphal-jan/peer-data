{"id": "1410.1228", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Oct-2014", "title": "Interactive Fingerprinting Codes and the Hardness of Preventing False Discovery", "abstract": "we show a tight bound on the number of adaptively chosen statistical queries whereupon a computationally efficient algorithm can answer specifically given $ for $ samples concerning an unknown collection. a statistical query asks for the expectation of a predicate over any underlying distribution, and an answer means a statistical query is accurate if \u03b5 is \" close \" to the null expectation over the distribution. this calculation was recently considered by dwork. dem., who showed that $ \\ void { \\ omega } ( n ^ 2 ) $ queries can be answer efficiently, and explored by hardt and ullman, who showed after answering $ \\ tilde { o } ( n ^ 3 ) $ queries is computationally hard. we close the gap between the two bounds by proving a new, nearly - optimal random result. specifically, some show that, absent a standard hardness assumption, there happens no computationally efficient algorithm that given $ n $ samples from an unknown distribution can give valid answers to $ o ( n ^ 2 ) $ adaptively chosen statistical queries. an implication of our results is that computationally improving algorithms for using arbitrary, adaptively chosen the queries may as well be differentially private. we obtain our results via their explicit construction of a new combinatorial object that we call an interactive fingerprinting process, & may be showing independent interest.", "histories": [["v1", "Sun, 5 Oct 2014 23:55:22 GMT  (38kb,D)", "http://arxiv.org/abs/1410.1228v1", null], ["v2", "Fri, 20 Feb 2015 19:29:47 GMT  (41kb,D)", "http://arxiv.org/abs/1410.1228v2", null]], "reviews": [], "SUBJECTS": "cs.CR cs.DS cs.LG", "authors": ["thomas steinke", "jonathan ullman"], "accepted": false, "id": "1410.1228"}, "pdf": {"name": "1410.1228.pdf", "metadata": {"source": "CRF", "title": "Interactive Fingerprinting Codes and the Hardness of Preventing False Discovery", "authors": ["Thomas Steinke", "Jonathan Ullman"], "emails": ["tsteinke@seas.harvard.edu.", "jullman@cs.columbia.edu."], "sections": [{"heading": null, "text": "\u2217Harvard University School of Engineering and Applied Sciences. Supported by NSF grant CCF-1116616. Email: tsteinke@seas.harvard.edu. \u2020Harvard University Center for Research on Computation and Society and Columbia University. Supported by NSF Grant CNS-1237235 and a Simons Society of Fellows Junior Fellowship. Email: jullman@cs.columbia.edu.\nar X\niv :1\n41 0.\n12 28\nv1 [\ncs .C\nR ]\n5 O\nct 2\nContents"}, {"heading": "1 Introduction 1", "text": "1.1 Discussion of Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n1.1.1 Techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.2 Applications to Data Privacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.3 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4"}, {"heading": "2 Interactive Fingerprinting Codes 5", "text": "2.1 Definition and Existence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 2.2 The Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 2.3 Analysis Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.3.1 Soundness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 2.3.2 Completeness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 2.3.3 Establishing Correlation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n2.4 Proof of Soundness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 2.5 Proof of Completeness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n2.5.1 Biased Fourier Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 2.5.2 Robustness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 2.5.3 Concentration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 2.5.4 Bounding the Score . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19"}, {"heading": "3 Hardness of False Discovery 22", "text": "3.1 The Statistical Query Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 3.2 Encryption Schemes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 3.3 Description of the Attack . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 3.4 Analysis of the Attack . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 3.5 An Information-Theoretic Lower Bound . . . . . . . . . . . . . . . . . . . . . . . 27"}, {"heading": "4 Hardness of Avoiding Blatant Non Privacy 28", "text": "4.1 Blatant Non Privacy and Sample Accuracy . . . . . . . . . . . . . . . . . . . . . . 28 4.2 Lower Bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 4.3 An Information-Theoretic Lower Bound . . . . . . . . . . . . . . . . . . . . . . . 33\nReferences 33\nA Security Reductions from Sections 3 and 4 34"}, {"heading": "1 Introduction", "text": "Empirical research is commonly done by asking multiple \u201cqueries\u201d (e.g., summary statistics, hypothesis tests, or learning algorithms) on a finite sample drawn from some population. \u201cFalse discovery\u201d occurs if the outcome of the queries on the sample does not reflect the population. For example, if a certain irrelevant gene is believed to be predictive for cancer based on the sample. For decades statisticians have been devising methods for preventing false discovery, such as the \u201cBonferroni correction\u201d [Bon36, Dun61] and the widely used and highly influential method of Benjamini and Hochberg [BH95] for controlling the \u201cfalse discovery rate.\u201d\nNevertheless, false discovery persists across all empirical sciences, and both popular and scientific articles report on an increasing number of invalid research findings. Typically false discovery is attributed to misuse of statistics. However, another possible explanation\u2014recently proposed by Dwork et al. [DFH+14] and Hardt and Ullman [HU14]\u2014is that methods for preventing false discovery do not address the fact that modern data analysis is inherently adaptive. The queries made, the experimental setup, and the selection and tuning of the algorithms all depend on previous interactions with the data. [DFH+14] gave methods for preventing false discovery in some cases, while [HU14] showed contrasting hardness results suggesting that there may be an inherent computational barrier to preventing false discovery. In this work we give a new, nearly optimal hardness result, showing that the algorithms of Dwork et al. [DFH+14] are nearly optimal in the worst case.\nThese results are formalized in Kearns\u2019 statistical-query (SQ) model [Kea93]. In the SQ model, there is an algorithm called the oracle that gets access to n samples from an unknown distribution D over some finite universe {0,1}d , where the parameter d is the dimensionality of the distribution. The oracle must answer statistical queries about D. A statistical query q is specified by a predicate p : X \u2192 {0,1} and the answer to a statistical query is q(D) = E\nx\u223cD [p(x)] .\nThe oracle\u2019s answer a to a query q is accurate if |a \u2212 q(D)| \u2264 \u03b1 with high probability. Importantly, the goal of the oracle is to provide answers that \u201cgeneralize\u201d to the underlying distribution rather than answers that are specific to the sample. The latter is easy to achieve by outputting the empirical average of the query predicate on the sample.\nThe analyst makes a sequence of queries q1,q2, . . . , qk to the oracle, which responds with answers a1, a2, . . . , ak . In the adaptive setting, the analyst receives each answer ai to qi before the next query is asked, so qi+1 may depend on q1, a1,q2, a2, . . . , qi , ai . We say the oracle is accurate given n samples for k adaptively chosen queries, if when given n samples from an arbitrary distribution D, the oracle accurately responds to any adaptive analyst that makes at most k queries. A computationally efficient oracle answers each query in time polynomial in n and d.1\nWhen the queries q1,q2, . . . , qk are specified non adaptively (i.e. independent of a1, a2, . . . , ak), then the empirical average of each query on the sample is accurate with high probability as long as k \u2264 2o(n). However, this guarantee no longer holds in the interactive setting and a more sophisticated oracle is required.\nThe results of Dwork et al. [DFH+14] gave a surprising way to construct an accurate oracle, by showing that any oracle that satisfies differential privacy [DMNS06] and provides accurate answers with respect to the sample, also provides accurate answers with respect to the underlying distribution. Using known constructions of differentially private algorithms, they obtain a computationally efficient algorithm that is accurate for \u2126\u0303(n2) queries, and a computationally inefficient algorithm that is accurate for nearly 2n queries.\n1We assume that the analyst asks queries that can be evaluated on the sample in polynomial time.\nIt was already known that computationally efficient differentially private algorithms could not answer more than O\u0303(n2) queries [Ull13], but differentially privacy may not be necessary at all. Unfortunately, [HU14] showed that no computationally efficient algorithm could answer too many more queries. Specifically, assuming the existence of one-way functions, there is no computationally efficient oracle that answers more than O\u0303(n3) queries.\nIn this work we resolve this gap almost completely, and show that, assuming the existence of one-way functions, there is no efficient oracle that answers O(n2) queries. Conceptually, our result gives further evidence that there may be an inherent computational barrier to preventing false discovery in interactive data analysis. It also shows that when answering arbitrary adaptively chosen statistical queries, one cannot do better than to use a differentially private algorithm in the worst case. We believe it is an intriguing open question to see whether this sort of equivalence holds in more restricted settings. Finally, as a consequence of our results, we obtain a dichotomy for privacy preserving data analysis in the adaptive setting. There is a computationally efficient differentially private algorithm that answers \u2126\u0303(n2) arbitrary adaptive queries, but, assuming the existence of one-way functions, every computationally efficient algorithm that answers O(n2) arbitrary adaptive queries is blatantly non private.\nTo prove our result, we modify the adversary used in [HU14]. First, we abstract the combinatorial properties required by their adversary into a new combinatorial object that we call an interactive fingerprinting code. Then, we give a nearly optimal construction of interactive fingerprinting codes, which is the main technical contribution of our work."}, {"heading": "1.1 Discussion of Results", "text": "Our main result is the following nearly optimal hardness result for preventing false discovery in interactive data analysis.\nTheorem 1.1 (Informal). Assuming the existence of one-way functions, there is no computationally efficient oracle that given n samples is accurate on O(n2) adaptively chosen queries.\nAs in [HU14], our hardness result applies whenever the dimensionality of the data grows with the sample size faster than logarithmically so that 2d is no longer polynomial in n.2 This requirement is rather mild, and is also necessary. If n 2d then the empirical distribution of the n samples will be close to the underlying distribution in statistical distance, so every statistical query can be answered accurately given the sample. Thus, the dimensionality of the data has a major effect on the hardness of the problem. [HU14] also showed that if the dimensionality is much larger than n, then we cannot even hope for a computationally unbounded oracle that provides accuracy on adaptive queries. We obtain a nearly optimal version of that result.\nTheorem 1.2 (Informal). There is no oracle (even a computationally unbounded one) that given n samples in dimension d =O(n2) is accurate on O(n2) adaptively chosen queries.\nThis result should be contrasted with the aforementioned result of Dwork et al. [DFH+14] showing that if d n2 then there is an oracle that runs in time polynomial in n and 2d and accurately answers nearly 2n adaptive queries.\n2This is under the stronger, but still standard, assumption that exponentially hard one-way functions exist."}, {"heading": "1.1.1 Techniques", "text": "The structure of our proof is rather simple, and closely follows the framework in [HU14]. We will design a challenge distribution D and a computationally efficient adaptive analyst A who knows D. If any computationally efficient oracle O is given n samples S = {x1, . . . ,xn} drawn from D, then our analyst A can use the answers of O to reconstruct the set S. Using this information, the adversary can construct a query on which S is not representative of D.\nOur adversary A and the distribution D, like that of [HU14], is built from a combinatorial object with a computational \u201cwrapper.\u201d The computational wrapper is cryptographic queries which \u201chide\u201d information from the oracle O. The combinatorial object is what we call an interactive fingerprinting code, which we introduce.\nInteractive fingerprinting codes (IFPCs) are an abstraction of the technique in [HU14]. They generalize fingerprinting codes, which were introduced by Boneh and Shaw [BS98] for the problem of watermarking digital content. Our main contribution is to define and construct IFPCs.\nAn interactive fingerprinting code F is an efficient interactive algorithm that defeats any adversary P (called the pirate) with high probability in the following game. The adversary P picks S \u2282 [N ] unknown to F . The goal of F is to identify S by making ` interactive queries to P . F specifies each query by a vector c \u2208 {\u00b11}N . In response, the adversary P must simply output a \u2208 {\u00b11} such that a = ci for some i \u2208 [N ]. However, the adversary is restricted to only see ci for i \u2208 S. At any time, F may accuse some i \u2208 [N ]. If i \u2208 S is accused, then i is removed from S (i.e. S \u2190 S\\{i}), thereby further restricting P . If i < S is accused, then this is referred to as a false accusation. To win, the interactive fingerprinting code F must identify all of S, without making \u201ctoo many\u201d false accusations.\nThe difference between interactive and non interactive fingerprinting codes is that a non interactive fingerprinting code must give all ` queries to P at once, but is (necessarily) only required to identify one i \u2208 S.\n[HU14] implicitly construct an interactive fingerprinting code with ` = O\u0303(N3) by concatenatingN independent copies of a non interactive fingerprinting code. We give a construction of an interactive fingerprinting codes using the optimal O(N2) queries based on the construction of non interactive fingerprinting codes by [Tar08].\nTheorem 1.3 (Informal). For everyN , there exists an interactive fingerprinting code with ` =O(N2) that, except with negligible probability, makes at most N/1000 false accusations.\nThis result suffices for our applications, but our construction is somewhat more general and has several additional parameters, which we detail in Section 2."}, {"heading": "1.2 Applications to Data Privacy", "text": "The adversary used to show hardness of preventing false discovery is effectively carrying out a reconstruction attack against the database of samples. Roughly, if there is an adversary who can reconstruct the set of samples S from the oracle\u2019s answers, then the oracle is said to be \u201cblatantly non-private\u201d\u2014it reveals essentially all of the data it holds, and so cannot guarantee any reasonable notion of privacy to the owners of the data. Since the seminal work of Dinur and Nissim [DN03], such reconstruction attacks have been used to establish strong limitations on the accuracy of privacy-preserving oracles.\nUsing interactive fingerprinting codes, combined with the framework of [HU14], we obtain the following results. In both cases, [HU14] show similar results, in which our O(n2) bounds are replaced with O\u0303(n3).\nTheorem 1.4 (Informal). Assuming the existence of one-way functions, every computationally efficient oracle that, given n samples, is accurate on O(n2) adaptively chosen queries is blatantly non private.\nTheorem 1.4 should be compared with the result in [Ull13], which showed that any computationally efficient oracle that, given n samples, is accurate for O\u0303(n2) non-adaptively chosen queries cannot satisfy the strong guarantee of \u201cdifferential privacy\u201d [DN03, DMNS06]. Theorem 1.4 shows that, in the adaptive setting, we can obtain a stronger privacy violation using fewer queries than [Ull13].\nTheorem 1.5 (Informal). Every (possibly computationally unbounded) oracle that, given n samples in dimension d =O(n2), is accurate on O(n2) adaptively chosen queries is blatantly non private.\nTheorem 1.5 should be compared with the result in [BUV14] that showed any (possibly computationally unbounded) oracle that answers a fixed family of O\u0303(n2) simple queries in dimension d = O\u0303(n2) cannot satisfy differential privacy.\nIn contrast with Theorems 1.4 and 1.5, the well-known result of [DMNS06] shows that there is an efficient differentially private algorithm that answers \u2126\u0303(n2) adaptively chosen queries. Our results show that, in the adaptive setting, there is a sharp threshold for the number of queries where, below this threshold, the strong notation of differential privacy can be achieved and, above this threshold, even minimal notions of privacy are unachievable."}, {"heading": "1.3 Related Work", "text": "Our work and [HU14] build on techniques for attacking allegedly privacy preserving algorithms. These works showed a surprising tension between methods for secure content-distribution and privacy-preserving algorithms. This connection first appeared in the work of Dwork, Naor, Reingold, Rothblum, and Vadhan [DNR+09], who showed that the existence of traitor-tracing schemes [CFN94] implies hardness results for differential privacy. This connection was expanded and strengthened in [Ull13], which introduced the use of fingerprinting codes in the context of differential privacy, and used them to prove nearly optimal hardness results for certain problems in differential privacy. Bun et al. [BUV14] showed that fingerprinting codes can be used to prove nearly-optimal information-theoretic lower bounds for differential privacy, which established fingerprinting codes as the key information-theoretic object underlying lower bounds in differential privacy.\nInteractive fingerprinting codes are similar in spirit to the work of Fiat and Tassa [FT01] on dynamic traitor-tracing. They too used the power of adaptivity to reconstruct the entire set of samples, as opposed to only one sample. Technically their results are incomparable to ours, and their techniques do not suffice in our setting. Specifically, they allowed codewords over a large alphabet, c \u2208 [N ]N , and achieve a length of O\u0303(N ). This large alphabet generalization is fundamentally different, and does not lead to hardness results for answering adaptive queries. This is inherent, since, by [DFH+14], there is no hardness result for answering O\u0303(N ) queries.3\nThe algorithms of Dwork et al. [DFH+14] rely on known differentially private mechanisms for answering adaptive statistical queries. Recently, [Ull14] showed how to design differentially private mechanisms for answering exponentially many adaptively chosen queries\n3This problem is not merely an artifact of restricting the data to distributions over {\u00b11}. Even if we were to consider more general distributions over [N ], the methods of Fiat and Tassa [FT01] inherently do not suffice. Queries over [N ] are equivalent to queries over {\u00b11}logN , whereas the large alphabet is fundamental to the analysis in Fiat and Tassa and cannot be straightforwardly replaced by the binary alphabet.\nfrom the richer class of convex empirical risk minimization queries. By the results of Dwork et al. [DFH+14], this algorithm is also a (computationally inefficient) oracle that is accurate for exponentially many adaptively chosen convex empirical risk minimization queries.\nOrganization In Section 2 we define and construct interactive fingerprinting codes, the main new technical ingredient we use to establish our results. In Sections 3 and 4 we show how interactive fingerprinting codes can be used to obtain hardness results for preventing false discovery and blatant non privacy, respectively. The definition of interactive fingerprinting codes is contained in Section 2.1 and is necessary for Sections 3 and 4, but the remainder of Section 2 and Sections 3 and 4 can be read in either order."}, {"heading": "2 Interactive Fingerprinting Codes", "text": "In order to motivate the definition of interactive fingerprinting codes, it will be helpful to review the motivation for standard, non-interactive fingerprinting codes.\nFingerprinting codes were introduced by Boneh and Shaw [BS98] for the problem of watermarking digital content (such as a movie or a piece of software). Consider a company that distributes some content to N users. Some of the users may illegally distribute copies of the content. To combat this, the company gives each user a unique version of the content by adding distinctive \u201cwatermarks\u201d to it. Thus, if the company finds an illegal copy, it can be traced back to the user who originally purchased it. Unfortunately, users may be able to remove the watermarks. In particular, a coalition of users may combine their copies in a way that mixes or obfuscates the watermarks. A fingerprinting code ensures that, even if up to n users collude to combine their codewords, an illegal copy can be still be traced to at least one of the users.\nFormally, every user i \u2208 [N ] is given a codeword (c1i , c 2 i , . . . , c ` i ) \u2208 {\u00b11} ` by the fingerprinting code, which represents the combination of watermarks in that user\u2019s copy. A subset S \u2282 [N ] of at most n users can arbitrarily combine their codewords to create a \u201cpirate codeword\u201d a = (a1, a2, . . . , a`) \u2208 {\u00b11}`. The only constraint is so-called consistency\u2014for every j \u2208 [`], if, for every colluding user i \u2208 S, we have cji = b, then a\nj = b. That is to say, if each of the colluding users receives the same watermark, then their combined codeword must also have that watermark. Given a, the fingerprinting code must be able to trace at least one user i \u2208 S. Tardos [Tar08] constructed optimal fingerprinting codes with ` =O(n2 logN ).\nA key drawback of fingerprinting codes is that we can only guarantee that a single user i \u2208 S is traced. This is inherent, as setting the pirate codeword a to be the codeword of a single user prevents any other user from being identified. We will see that this can be circumvented by moving to an interactive setting.\nSuppose the company is instead distributing a stream of content (such as a TV series) to N users\u2014that is, the content is not distributed all at once and the illegal copies are obtained whilst the content is being distributed (e.g. the episodes of the TV series appear on the internet before the next episode is shown). Again, the content is watermarked so that each user receives a unique stream and a subset S \u2282 [N ] of at most n users combine their streams and distribute an illegal stream. The company obtains the illegal stream and uses this to trace the colluding users S. As soon as the company can identify a colluding user i \u2208 S, that user\u2019s stream is terminated (e.g. their subscription is cancelled). This process continues until every i \u2208 S has been traced and the distribution of illegal copies ceases.\nAnother twist on fingerprinting codes is robustness [BUV14]. Suppose that the consistency constraint only holds for (1 \u2212 \u03b2)` choices of j \u2208 [`]. That is to say, the colluding users can somehow remove a \u03b2 fraction of the watermarks. [BUV14] showed how to modify the Tardos fingerprinting code to be robust to a small constant fraction of inconsistencies. In this work, we show that robustness to any \u03b2 < 1/2 fraction of inconsistencies can be achieved."}, {"heading": "2.1 Definition and Existence", "text": "We are now ready to formally define interactive fingerprinting codes. To do so we make use of the following game between an adversary P and the fingerprinting code F . Both P and F may be stateful. For a given execution of F , we let C \u2208 {\u00b11}N\u00d7` be the matrix with columns c1, . . . , c`\nand let a \u2208 {\u00b11}` be the vector with entries a1, . . . , a`. We want to construct the fingerprinting code so that, if a is consistent, then the tracer succeeds in recovering every user in S. For convenience, we will define the notation \u03b8j to be the number of rounds 1, . . . , j in which aj is not consistent with cj . Formally, for a given execution of F ,\n\u03b8j = \u2223\u2223\u2223\u2223{1 \u2264 k \u2264 j \u2223\u2223\u2223 @ i \u2208 [N ], ak = cki }\u2223\u2223\u2223\u2223 .\nUsing this notation, a is \u03b2-consistent if \u03b8` \u2264 \u03b2`. We also define the notation \u03c8j to be the number of users in I1, . . . , I j who are falsely accused (i.e. not in the coalition S1). Formally,\n\u03c8j = \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223  \u22c3 1\u2264k\u2264j Ik  \\ S1 \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 .\nUsing this notation, we require \u03c8` \u2264 \u03b4N - that is, the tracing algorithm does not make too many false accusations.\nDefinition 2.1 (Interactive Fingerprinting Codes). We say that an algorithm F is an n-collusionresilient interactive fingerprinting code of length ` for N users robust to a \u03b2 fraction of errors with failure probability \u03b5 and false accusation probability \u03b4 if for every adversary P , it holds that\nP IFPCN,n,`[P ,F ]\n[( \u03b8` \u2264 \u03b2` ) \u2228 ( \u03c8` > \u03b4N )] \u2264 \u03b5\nThe length ` may depend on N,n,\u03b2,\u03b5,\u03b4.\nThe constraint \u03c8` \u2264 \u03b4N is called soundness\u2014the interactive fingerprinting code should not make (many) false accusations. The constraint \u03b8` > \u03b2` is called completeness\u2014the interactive fingerprinting code should force the adversary P to be inconsistent. Although it may seem strange that we make no reference to recovering the coalition S1, notice that if Sj , \u2205, then P can easily be consistent. Therefore, if the pirate cannot be consistent, it must be the case that Sj = \u2205 for some j, meaning all of S1 has been accused.\nIn the remainder of this section, we give a construction of interactive fingerprinting codes, and establish the following theorem.\nTheorem 2.2 (Existence of Interactive Fingerprinting Codes). For every 1 \u2264 n \u2264 N , 0 \u2264 \u03b2 < 1/2, and 0 < \u03b4 \u2264 1, there is a n-collusion-resilient interactive fingerprinting code of length ` for N users robust to a \u03b2 fraction of errors with failure probability \u03b5 \u2264min{\u03b4N,2\u2212\u2126(\u03b4N )}+ \u03b4\u2126(( 1 2\u2212\u03b2)n) and false accusation probability \u03b4 for\n` =O n2 log(1/\u03b4)(1 2 \u2212 \u03b2 )4  .\nThe expression for the failure probability \u03b5 is a bit mysterious. To interpret it, we fix \u03b2 = 1/2 \u2212\u2126(1) and consider two parameter regimes: \u03b4N 1 and \u03b4N 1. In the traditional parameter regime for fingerprinting codes \u03b4N = \u03b5\u2032 1, and so no users are falsely accused. Then our fingerprinting code has length O(n2 log(N/\u03b5\u2032)) and a failure probability of \u03b5\u2032. However, if we are willing to tolerate falsely accusing a small constant fraction of users, then we can set, for example, \u03b4N = .01N , and our fingerprinting code will have lengthO(n2) and failure probability 2\u2212\u2126(n)."}, {"heading": "2.2 The Construction", "text": "Our construction and analysis is based on the optimal (non interactive) fingerprinting codes of Tardos [Tar08], and the robust variant by Bun et al. [BUV14]. The code is essentially the same, but columns are generated and shown to the adversary one at a time, and tracing is modified to identify users interactively.\nWe begin with some definitions and notation. For 0 \u2264 a < b \u2264 1, let Da,b be the distribution with support (a,b) and probability density function \u00b5(p) = Ca,b/ \u221a p(1\u2212 p), where Ca,b is a normalising constant.4 For \u03b1,\u03b6 \u2208 (0,1/2), let D\u03b1,\u03b6 be the distribution on [0,1] that returns a sample from D\u03b1,1\u2212\u03b1 with probability 1\u2212 2\u03b6 and 0 or 1 each with probability \u03b6.\nFor p \u2208 [0,1], let c \u223c p denote that c \u2208 {\u00b11} is drawn from the distribution with P [c = 1] = p and P [c = \u22121] = 1\u2212 p. Let c1\u00b7\u00b7\u00b7n \u223c p denote that c \u2208 {\u00b11}n is drawn from a product distribution in which ci \u223c p independently for all i \u2208 [n].\nDefine \u03c6p : {\u00b11} \u2192R by \u03c60(c) = \u03c61(c) = 0 and, for p \u2208 (0,1), \u03c6p(1) = \u221a\n(1\u2212 p)/p and \u03c6p(\u22121) = \u2212 \u221a p/(1\u2212 p). The function \u03c6p is chosen so that \u03c6p(c) has mean 0 and variance 1 when c \u223c p. The fingerprinting code F is defined in Figure 2. In addition to the precise setting of parameters, we have given asymptotic bounds to help follow the analysis. We now analyze F and establish Theorem 2.2. The proof of Theorem 2.2 is split into Theorems 2.7 and 2.17. For convenience, define I = \u22c3 j\u2208[`] I j .\n4To sample from Da,b, first sample \u03d5 \u2208 (sin\u22121( \u221a a),sin\u22121( \u221a b)) uniformly, then output sin2(\u03d5) as the sample."}, {"heading": "2.3 Analysis Overview", "text": "Intuitively, the quantity sji , which we call the score of user i, measures the \u201ccorrelation\u201d between the answers (a1, \u00b7 \u00b7 \u00b7 , aj ) of P and the i-th codeword (c1i , \u00b7 \u00b7 \u00b7 , c j i ), using a particular measure of correlation that takes into account the choices p1, . . . ,pj . If sji ever exceeds the threshold \u03c3 , meaning that the answers are significantly correlated with the i-th codeword, then we accuse user i. Thus, our goal is to show two things: Soundness, that the score of an innocent user (i.e. i < S1) never exceeds the threshold, as the answers cannot be correlated with the unknown i-th codeword. And completeness, that the score of every guilty user (i.e. i \u2208 S1) will at some point exceed the threshold, meaning that the answers must correlate with the i-th codeword for every i \u2208 S1."}, {"heading": "2.3.1 Soundness", "text": "The proof of soundness closely mirrors Tardos\u2019 analysis [Tar08] of the non-interactive case. If i is innocent, then, since P doesn\u2019t see the codeword (c1i , \u00b7 \u00b7 \u00b7 , c j i ) of the i th user, there cannot be too much correlation. In this case, one can show that sji is the sum of j independent random variables, each with mean 0 and variance 1, where we take the answers a1, . . . , aj as fixed and the randomness is over the choice of the unknown codeword. By analogy to Gaussian random\nvariables, one would expect that sji \u2264 \u03c3 = \u0398( \u221a ` log(1/\u03b4)) with probability at least 1\u2212\u03b4. Formally, the fact that the score in each round is not bounded prevents the use of a Chernoff bound. But nonetheless, in Section 2.4, we prove soundness using a Chernoff-like tail bound for sji ."}, {"heading": "2.3.2 Completeness", "text": "To prove completeness, we must show that, for guilty users i \u2208 S1, we have sji > \u03c3 for some j \u2208 [`] with high probability. In Sections 2.5.1 and 2.5.3, we prove that if P gives consistent answers in a 1\u2212 \u03b2 fraction of rounds, then the sum of the scores for each of the guilty users is large. Specifically, in Theorem 2.15, we prove that with high probability\u2211\ni\u2208S1 s`i \u2265\u0398 (`) (1)\nThe constants hidden by the asymptotic notation are set to imply that, for at least one i \u2208 S1, the score s`i is above the threshold \u03c3 = \u0398 (`/n). This step is not too different from the analysis of Tardos and Bun et al. [Tar08, BUV14] for the non-interactive case. To show that, for every i \u2208 S1, we will have sji > \u03c3 at some point, we must depart from the analysis of non-interactive fingerprinting codes. If sji > \u03c3 , and user i is accused in round j, then the adversary will not see the suffix of codeword (cj+1i , \u00b7 \u00b7 \u00b7 , c ` i ). By the same argument that was used to prove soundness, the answers will not be correlated with this suffix, so with high probability the score s`i does not increase much beyond \u03c3 . Thus,\u2211\ni\u2208S1 s`i \u2264 n \u00b7O(\u03c3 ) = \u0398 (`) . (2)\nThe hidden constants are set to ensure that Equation (2) conflicts with Equation (1). Thus, we can conclude that P cannot give consistent answers for a 1 \u2212 \u03b2 fraction of rounds. That is to say, P is forced to be inconsistent because all of S1 is accused and eventually P sees none of the codewords and is reduced to guessing an answer aj ."}, {"heading": "2.3.3 Establishing Correlation", "text": "Proving Equation (1) is key to the analysis. Our proof thereof combines and simplifies the analyses of [Tar08] and [BUV14]. For this high level overview, we ignore the issue of robustness and fix \u03b2 = 0.\nFirst we prove that the correlation bound holds in expectation and then we show that it holds with high probability using an Azuma-like concentration bound. (Again, as the random variables being summed are not bounded, we are forced to use a more tailored analysis to prove concentration.) We show that it holds in expectation for each round. In Proposition 2.12, we show that the concentration grows in expectation in each round. For every j \u2208 [`],\nE \u2211 i\u2208S1 s j i \u2212 s j\u22121 i  = E \u2211 i\u2208S1 aj \u00b7\u03c6p j (cji )  \u2265\u2126(1), (3) where the expectations are taken over the randomness of pj , cj , and aj . Equation (3), combined with a concentration result, implies Equation (1).\nThe intuition behind Equation (3) and the choice of pj is as follows. Consistency guarantees that, if cji = b for all i \u2208 S\n1, then aj = b. This is a weak correlation guarantee, but it suffices to ensure correlation between aj and \u2211 i\u2208S1 c j i . The affine scaling \u03c6 pj ensures that \u03c6p j (cji ) has mean zero (i.e. is uncorrelated with a constant) and and unit variance (i.e. has unit correlation with itself). The expectation of aj \u00b7\u03c6pj (cji ) can be interpreted as the i-th first-order Fourier coefficient of aj as a function of cj . To understand first-order Fourier coefficients, consider the \u201cdictator\u201d function: Suppose aj = cji\u2217 for some i \u2217 \u2208 S1 - that is, P always outputs the i\u2217-th bit. Then\nE aj ,cj ,pj aj \u2211 i\u2208S1 \u03c6p j (cji )  = Ecj ,pj [ c j i\u2217 \u00b7\u03c6 pj (cji\u2217) ] = E pj [ 2 \u221a pj(1\u2212 pj ) ] = \u0398(1).\nThis example can be generalised to aj being an arbitrary function of cjS1 using Fourier analysis. This calculation also indicates why we choose the probability density function of pj \u223c D\u03b1,1\u2212\u03b1 to be proportional to 1/ \u221a p(1\u2212 p).\nTo handle robustness (\u03b2 > 0) we use the ideas of [BUV14]. With probability 2\u03b6 each round is a \u201cspecial\u201d constant round\u2014i.e. cj = (1)N or cj = (\u22121)N . Otherwise it is a \u201cnormal\u201d round where cj is sampled as before. Intuitively, the adversary P cannot distinguish the special rounds from the normal rounds in which c happens to be constant. If the adversary gives inconsistent answers on normal rounds, then it must also give inconsistent answers on special rounds. Since there are many more special rounds than normal rounds, this means that a small number of inconsistencies in normal rounds implies a large number of inconsistencies on special rounds. Conversely, inconsistencies are absorbed by the special rounds, so we can assume there are very few inconsistencies in normal rounds. Thus P is forced to behave consistently on the normal rounds and the analysis on these rounds proceeds as before."}, {"heading": "2.4 Proof of Soundness", "text": "We first show that no user is falsely accused except with probability \u03b4/2. This boils down to proving a concentration bound. Then another concentration bound shows that with high probability at most a \u03b4 fraction of users are falsely accused.\nThese concentrations bounds are essentially standard. However, we are showing concentration of sums of variables of the form \u03c6p(c), which may be quite large if p \u2248 0 or p \u2248 1. This technical problem prevents us from directly applying standard concentration bounds. Instead we open up the standard proofs and verify the desired concentration. We take the usual approach of bounding the moment generating function and using that to give a tail bound. Lemma 2.3. For p \u2208 [\u03b1,1\u2212\u03b1]\u222a {0,1} and t \u2208 [\u2212 \u221a \u03b1/2, \u221a \u03b1/2], we have\nE c\u223cp\n[ et\u03c6 p(c) ] \u2264 et 2 .\nProof. If p \u2208 {0,1}, \u03c6p = 0 and the result is trivial. We have E c\u223cp [\u03c6p(c)] = 0, E c\u223cp\n[ \u03c6p(c)2 ] = 1,\nand, for c \u2208 {\u00b11}, |\u03c6p(c)| \u2264 1/ \u221a \u03b1. In particular, |\u03c6p(c) \u00b7 t| \u2264 1/2. For u \u2208 [\u22121/2,1/2], we have eu \u2264 1 +u +u2. Thus\nE c\u223cp\n[ et\u03c6 p(c) ] \u2264 1 + t E\nc\u223cp [\u03c6p(c)] + t2 E c\u223cp\n[ \u03c6p(c)2 ] = 1 + t2 \u2264 et 2 .\nLemma 2.4. Let p1 \u00b7 \u00b7 \u00b7pm \u2208 [\u03b1,1 \u2212 \u03b1] \u222a {0,1} and c1 \u00b7 \u00b7 \u00b7cm drawn independently with ci \u223c pi . Let a1 \u00b7 \u00b7 \u00b7am \u2208 [\u22121,1] be fixed. For all \u03bb \u2265 0, we have\nP \u2211 i\u2208[m] ai\u03c6 pi (ci) \u2265 \u03bb  \u2264 e\u2212\u03bb2/4m + e\u2212\u221a\u03b1\u03bb/4. Proof. By Lemma 2.3, for all t \u2208 [\u2212 \u221a \u03b1/2, \u221a \u03b1/2],\nE c\n[ et \u2211 i\u2208[m] ai\u03c6 pi (ci ) ] \u2264 \u220f i\u2208[m] E ci [ etai\u03c6 pi (ci ) ] \u2264 et 2m.\nBy Markov\u2019s inequality,\nP \u2211 i\u2208[m] ai\u03c6 pi (ci) \u2265 \u03bb  \u2264 E [ et \u2211 i\u2208[m] ai\u03c6 pi (ci ) ] et\u03bb \u2264 et 2m\u2212t\u03bb.\nSet t = min{ \u221a \u03b1/2,\u03bb/2m}. If \u03bb \u2208 [0,m \u221a \u03b1], then\nP \u2211 i\u2208[m] ai\u03c6 pi (ci) \u2265 \u03bb  \u2264 e\u2212\u03bb2/4m. On the other hand, if \u03bb \u2265m \u221a \u03b1, then\nP \u2211 i\u2208[m] ai\u03c6 pi (ci) \u2265 \u03bb  \u2264 e\u03b1m/4\u2212\u221a\u03b1\u03bb/2 \u2264 e\u2212\u221a\u03b1\u03bb/4. The result is obtained by adding these expressions.\nThe following theorem shows how we can beat the union bound for tail bounds on partial sums.\nTheorem 2.5 (Etemadi\u2019s Inequality [Ete85]). Let X1 \u00b7 \u00b7 \u00b7Xn \u2208 R be independent random variables. For k \u2208 [n], define Sk = \u2211 i\u2208[k]Xi to be the k th partial sum. Then, for all \u03bb > 0,\nP [ max k\u2208[n] |Sk | > 4\u03bb ] \u2264 4 \u00b7max k\u2208[n] P [|Sk | > \u03bb] .\nProposition 2.6 (Individual Soundness). For all i \u2208 [N ], we have P [ i \u2208 I \\ S1 ] \u2264 8(e\u2212\u03c3 2/64` + e\u2212\u03c3 \u221a \u03b1/16) \u2264 \u03b4/2,\nwhere the probability is taken over IFPCN,N,`[P ,FN,n,\u03b4,\u03b2] for an arbitrary P .\nProof. Let i \u2208 [N ] \\ S1. Since the adversary does not see cji for any j \u2208 [`], we may treat the answers of the adversary as fixed and analyse sji as if c j i was drawn after the actions of the adversary are fixed. Thus, by Lemma 2.4, for every j \u2208 [`],\nP [ s j i > \u03c3 4 ] = P \u2211 k\u2208[j] ak\u03c6p k (cki ) > \u03c3 4  \u2264 e\u2212\u03c32/64` + e\u2212\u03c3\u221a\u03b1/16.\nLikewise P [ s j i < \u2212 \u03c3 4 ] \u2264 e\u2212\u03c32/64` + e\u2212\u03c3 \u221a \u03b1/16. Thus, by Theorem 2.5,\nP [i \u2208 I] \u2264 P [ max j\u2208[`] |sji | > \u03c3 ] \u2264 4max j\u2208[`] P [ |sji | > \u03c3 4 ] \u2264 8(e\u2212\u03c3 2/64` + e\u2212\u03c3 \u221a \u03b1/16) \u2264 \u03b4 2 .\nTheorem 2.7 (Soundness). We have P [ |I \\ S1| > \u03b4N ] \u2264min { \u03b4N,e\u2212\u03b4N/8 } ,\nwhere the probability is taken over IFPCN,N,`[P ,FN,n,\u03b4,\u03b2] for an arbiratry P .\nInterestingly, this theorem does not require |S1| \u2264 n \u2013 that is, it holds with respect to IFPCN,N,`[P ,FN,n,\u03b4,\u03b2], rather than IFPCN,n,`[P ,FN,n,\u03b4,\u03b2]. It only requires that F does not see the codewords of users not in S1.\nProof. Let Ei \u2208 {0,1} be the indicator of the event i \u2208 I\\S1. The Eis for i \u2208 [N ] are independent (conditioned on the choice of S1 and pj for j \u2208 [`]). Moreover, by Proposition 2.6, E [Ei] \u2264 \u03b4/2 for all i \u2208 [N ]\\S1. Thus, by a Chernoff bound,\nP [ |I\\S1| > \u03b4N ] = P  \u2211 i\u2208[N ] Ei > \u03b4N  \u2264 e\u2212\u03b4N/8. If \u03b4 < 1/N , then this is a very poor bound. Instead we use the fact that the Eis are discrete\nand Markov\u2019s inequality, which amounts to a union bound. For \u03b4N < 1, we have\nP [ |I\\S1| > \u03b4N ] = P [ |I\\S1| \u2265 1 ] \u2264 E  \u2211 i\u2208[N ] Ei  \u2264 \u03b4N2 \u2264 \u03b4N.\nThe following lemma will be useful later.\nLemma 2.8. For i \u2208 [N ], let ji \u2208 [` + 1] be the first j such that i < Sj , where we define S`+1 = \u2205. For any S \u2282 [N ],\nP \u2211 i\u2208S s`i \u2212 s ji\u22121 i > \u03bb  \u2264 e\u2212\u03bb2/4|S |` + e\u2212\u221a\u03b1\u03bb/4, where the probability is taken over IFPCN,N,`[P ,FN,n,\u03b4,\u03b2] for an arbitrary P . Proof. We have \u2211 i\u2208S s`i \u2212 s ji\u22121 i = \u2211 i\u2208S \u2211 j\u2208[`] I(j \u2265 ji)aj\u03c6p j (cji ).\nAgain, since the adversary doesn\u2019t see cji for j \u2265 ji , the random variables I(j \u2265 ji)a j and \u03c6p j (cji ) are independent, so we can view I(j \u2265 ji)aj \u2208 [\u22121,1] as fixed. Now the result follows from Lemma 2.4."}, {"heading": "2.5 Proof of Completeness", "text": "To show that the fingerprinting code identifies guilty users we must lower bound the scores\u2211 i\u2208S1 s ` i . First we bound their expectation and then their tails."}, {"heading": "2.5.1 Biased Fourier Analysis", "text": "For this section, assume that the adversary P is always consistent - that is, we have no robustness and \u03b2 = 0. Robustness will be added in Section 2.5.2. Here we establish that the scores have good expectation, namely\nE \u2211 i\u2208S1 s j i \u2212 s j\u22121 i  \u2265\u2126(1) for all j \u2208 [`]. The score s`i computes the \u2018correlation\u2019 between the bits given to user i and the output of the adversary. We must show that that the adversary\u2019s consistency constraint implies that there exists some correlation on average.\nIn this section we deviate from the proof in [Tar08]. We use biased Fourier analysis to give a more intuitive proof of the correlation bound.\nWe have the following lemma and proposition, which relate the correlation aj \u00b7 \u2211 i\u2208S1\u03c6\npj (cji ) to the properties of aj as a function of pj . To interpret these imagine that f represents the adversary P with one round viewed in isolation \u2013 the fingerprinting code gives the adversary cj and the adversary responds with f (cj\nSj ).\nFirstly, the following lemma gives an interpretation of the correlation value for a fixed pj .\nLemma 2.9. Let f : {\u00b11}n\u2192R. Define g : [0,1]\u2192R by g(p) = E c1\u00b7\u00b7\u00b7n\u223cp [f (c)]. For any p \u2208 (0,1),\nE c1\u00b7\u00b7\u00b7n\u223cp f (c) \u00b7\u2211 i\u2208[n] \u03c6p(ci)  = g \u2032(p)\u221ap(1\u2212 p). Proof. For p \u2208 (0,1) and s \u2282 [n], define \u03c6ps : {\u00b11}n\u2192 R by \u03c6 p s (c) = \u220f i\u2208s\u03c6 p(ci). The functions \u03c6 p s form an orthonormal basis with respect to the product distribution with bias p \u2013 that is,\n\u2200s, t \u2282 [n] E c1\u00b7\u00b7\u00b7n\u223cp\n[ \u03c6 p s (c) \u00b7\u03c6 p t (c) ] = { 1 s = t 0 s , t } .\nThus, for any p \u2208 (0,1), we can write f in terms of these basis functions: \u2200c \u2208 {\u00b11}n f (c) = \u2211 s\u2282[n] f\u0303 p(s)\u03c6ps (c),\nwhere \u2200s \u2282 [n] f\u0303 p(s) = E\nc1\u00b7\u00b7\u00b7n\u223cp\n[ f (c)\u03c6ps (c) ] .\nThis decomposition is a generalisation of Fourier analysis to biased distributions [O\u2019D14, \u00a78.4].\nFor p,q \u2208 (0,1), the expansion of f gives the following expressions for g(q), g \u2032(q) and g \u2032(p).\ng(q) = E c1\u00b7\u00b7\u00b7n\u223cq [f (c)] = \u2211 s\u2282[n] f\u0303 p(s) E c1\u00b7\u00b7\u00b7n\u223cq [ \u03c6 p s (c) ] =\n\u2211 s\u2282[n] f\u0303 p(s) \u220f i\u2208s E c\u223cq [\u03c6p(c)]\n= \u2211 s\u2282[n] f\u0303 p(s) ( q \u221a 1\u2212 p p \u2212 (1\u2212 q) \u221a p 1\u2212 p )|s| .\ng \u2032(q) = \u2211\ns\u2282[n]:s,\u2205 f\u0303 p(s) \u00b7 |s| \u00b7\n( q \u221a 1\u2212 p p \u2212 (1\u2212 q) \u221a p 1\u2212 p )|s|\u22121 \u00b7 (\u221a 1\u2212 p p + \u221a p 1\u2212 p ) .\ng \u2032(p) = \u2211\ns\u2282[n]:s,\u2205 f\u0303 p(s) \u00b7 |s| \u00b7 0|s|\u22121 \u00b7\n(\u221a 1\u2212 p p + \u221a p 1\u2212 p )\n= \u2211 i\u2208[n] f\u0303 p({i}) \u00b7 (\u221a 1\u2212 p p + \u221a p 1\u2212 p ) .\nNote that f\u0303 p({i}) = E c1\u00b7\u00b7\u00b7n\u223cp [f (c)\u03c6p(ci)] and, hence,\nE c1\u00b7\u00b7\u00b7n\u223cp f (c) \u00b7\u2211 i\u2208[n] \u03c6p(ci)  = \u2211 i\u2208[n] f\u0303 p({i}) = g \u2032(p)\u221a\n1\u2212p p +\n\u221a p\n1\u2212p\n= g \u2032(p) \u221a p(1\u2212 p).\nNow we can interpret the correlation for a random pj \u223cDa,b. Proposition 2.10. Let f : {\u00b11}n\u2192 R. Define g : [0,1]\u2192 R by g(p) = E\nc1\u00b7\u00b7\u00b7n\u223cp [f (c)]. For any 0 \u2264 a <\nb \u2264 1,\nE p\u223cDa,b  Ec1\u00b7\u00b7\u00b7n\u223cp f (c) \u00b7\u2211\ni\u2208[n] \u03c6p(ci)   = g(b)\u2212 g(a)2sin\u22121(\u221ab)\u2212 2sin\u22121(\u221aa) \u2265 g(b)\u2212 g(a)\u03c0 .\nThis effectively follows by integrating Lemma 2.9. Proof. Let \u00b5(p) = Ca,b/ \u221a p(1\u2212 p) be the probability density function for the distribution Da,b on the interval (a,b). By Lemma 2.9 and the fundamental theorem of calculus, we have\nE p\u223cDa,b  Ec1\u00b7\u00b7\u00b7n\u223cp f (c) \u00b7\u2211\ni\u2208[n] \u03c6p(ci)\n  = Ep\u223cDa,b [g \u2032(p)\u221ap(1\u2212 p)]\n= \u222b b a g \u2032(p) \u221a p(1\u2212 p)\u00b5(p)dp\n=Ca,b \u222b b a g \u2032(p)dp =Ca,b \u00b7 (g(b)\u2212 g(a)).\nIt remains to show that Ca,b = ( 2sin\u22121( \u221a b)\u2212 2sin\u22121( \u221a a) )\u22121 \u2265 1/\u03c0. This follows from observing that\nC\u22121a,b = \u222b b a 1\u221a p(1\u2212 p) dp = \u222b b a ( d dp 2sin\u22121( \u221a p) ) dp = 2sin\u22121( \u221a b)\u2212 2sin\u22121( \u221a a)\nand C\u22121a,b \u2264 C \u22121 0,1 = 2sin \u22121(1)\u2212 2sin\u22121(0) = \u03c0.\nNow we have a lemma to bring consistency into the picture. If f is consistent, b \u2248 1, and a \u2248 0, then g(b)\u2212 g(a) \u2248 g(1)\u2212 g(0) = f ((1)n)\u2212 f ((\u22121)n) = 1\u2212 (\u22121) = 2. This gives a lower bound on the correlation for consistent f .\nLemma 2.11. Let f : {\u00b11}n \u2192 {\u00b11}. Define g : [0,1] \u2192 [\u22121,1] by g(p) = E c1\u00b7\u00b7\u00b7n\u223cp [f (c)]. Suppose \u03b1 \u2208 [0,1]. Then |g(1\u2212\u03b1)\u2212 g(1)| \u2264 2n\u03b1 and |g(\u03b1)\u2212 g(0)| \u2264 2n\u03b1.\nProof. We have P c1\u00b7\u00b7\u00b7n\u223c1\u2212\u03b1\n[X = (1)n] = (1\u2212\u03b1)n and\ng(1\u2212\u03b1)\u2212 g(1) =f ((1)n) \u00b7 P c1\u00b7\u00b7\u00b7n\u223c1\u2212\u03b1 [c = (1)n] + E c1\u00b7\u00b7\u00b7n\u223cp [f (c)|c , (1)n] \u00b7 P c1\u00b7\u00b7\u00b7n\u223c1\u2212\u03b1 [c , (1)n]\u2212 g(1)\n=g(1) \u00b7 (1\u2212\u03b1)n + E c1\u00b7\u00b7\u00b7n\u223cp [f (c)|c , (1)n] \u00b7 (1\u2212 (1\u2212\u03b1)n)\u2212 g(1) = ( g(1)\u2212 E\nc1\u00b7\u00b7\u00b7n\u223cp [f (c)|c , (1)n]\n) \u00b7 ((1\u2212\u03b1)n \u2212 1) .\nNow \u2223\u2223\u2223\u2223\u2223g(1)\u2212 Ec1\u00b7\u00b7\u00b7n\u223cp [f (c)|c , (1)n] \u2223\u2223\u2223\u2223\u2223 \u2264 2 and |(1\u2212\u03b1)n \u2212 1| \u2264 n\u03b1, whence |g(1\u2212\u03b1)\u2212 g(1)| \u2264 2n\u03b1. The other half of the lemma is symmetric."}, {"heading": "2.5.2 Robustness", "text": "We require the fingerprinting code to be robust to inconsistent answers. We show that the correlation is still good in the presence of inconsistencies.\nFor f : {\u00b11}n\u2192 {\u00b11}, define a random variable \u03be\u03b1,\u03b6(f ) by \u03be\u03b1,\u03b6(f ) = f (c) \u00b7 \u2211 i\u2208[n] \u03c6p(ci) +\u03b3I (p \u2208 {0,1} \u2227 f (c) , 2p \u2212 1) , p \u223cD\u03b1,\u03b6 , c1\u00b7\u00b7\u00b7n \u223c p,\nwhere I is the indicator function and \u03b3 \u2208 (0,1/2) satisfies \u03b6\u03b3/2 = (1\u2212 2\u03b6)/\u03c0 - that is,\n\u03b3 := 2 \u03c0 1\u2212 2\u03b6 \u03b6 .\nThe first term f (c) \u00b7 \u2211 i\u2208[n]\u03c6\np(ci) measures the correlation as before. The second term \u03b3I (p \u2208 {0,1} \u2227 f (c) , 2p \u2212 1) measures inconsistencies. We will lower bound the expectation of \u03be\u03b1,\u03b6(f ), which amounts to saying \u201ceither there is good correlation or there is an inconsistency with good probability.\u201d Thus either the fingerprinting code is able to accuse users or the adversary is forced to be inconsistent.\nThe following bounds the expected increase in scores from one round of interaction.\nProposition 2.12. Let f : {\u00b11}n\u2192 {\u00b11} and \u03b1,\u03b6 \u2208 (0,1/2). Then\nE [ \u03be\u03b1,\u03b6(f ) ] \u2265 2 \u03c0 (1\u2212 2\u03b6)(1\u2212 2n\u03b1).\nProof. Define g : [0,1]\u2192 [\u22121,1] by g(p) = E c1\u00b7\u00b7\u00b7n\u223cp [f (c)]. Now\nE [ \u03be\u03b1,\u03b6(f ) ] = P p\u223cD\u03b1,\u03b6 [p = 0] \u00b7\u03b3I(f ((\u22121)n) = 1) + P p\u223cD\u03b1,\u03b6 [p = 1] \u00b7\u03b3I(f ((1)n) = \u22121)\n+ P p\u223cD\u03b1,\u03b6 [p \u2208 [\u03b1,1\u2212\u03b1]] \u00b7 E p\u223cD\u03b1,1\u2212\u03b1  Ec1\u00b7\u00b7\u00b7n\u223cp f (c) \u00b7\u2211 i\u2208[n] \u03c6p(ci)  \n=\u03b6 \u00b7\u03b3 (I(g(0) = 1) + I(g(1) = \u22121))\n(by Proposition 2.10) + (1\u2212 2\u03b6) \u00b7 g(1\u2212\u03b1)\u2212 g(\u03b1)\n2sin\u22121( \u221a 1\u2212\u03b1)\u2212 2sin\u22121( \u221a \u03b1) \u2265\u03b6 \u00b7\u03b3 (\n1 + g(0) 2 + 1\u2212 g(1) 2\n) + (1\u2212 2\u03b6) \u00b7\ng(1\u2212\u03b1)\u2212 g(\u03b1) \u03c0\n= 1\u2212 2\u03b6 \u03c0 (1 + g(0) + 1\u2212 g(1) + g(1\u2212\u03b1)\u2212 g(\u03b1)) \u22651\u2212 2\u03b6 \u03c0 (2\u2212 |g(\u03b1)\u2212 g(0)| \u2212 |g(1\u2212\u03b1)\u2212 g(1)|)\n(by Lemma 2.11) \u22651\u2212 2\u03b6 \u03c0 (2\u2212 4n\u03b1)."}, {"heading": "2.5.3 Concentration", "text": "So far we have shown that the fingerprinting code achieves good correlation or the adversary is not consistent in expectation. However, we need this to hold with high probability. Thus we now show that sums of \u03be\u03b1,\u03b6(f ) variables concentrate around their expectation.\nAgain, the proofs in this section are standard. However, the \u03be\u03b1,\u03b6(f ) variables can be quite unwieldy and we are thus unable to apply standard results directly. So instead we must open the proofs and verify that the concentration bounds hold. We proceed by bounding the moment generating function of \u03be\u03b1,\u03b6(f ) and then proving an Azuma-like concentration inequality. These calculations are not novel or insightful. Proposition 2.13. Let f : {\u00b11}n\u2192 {\u00b11}, \u03b1 \u2208 (0,1/2), \u03b6 \u2208 [1/4,1/2), and t \u2208 [\u2212 \u221a \u03b1/8, \u221a \u03b1/8]. Then\nE [ e t(\u03be\u03b1,\u03b6(f )\u2212E[\u03be\u03b1,\u03b6(f )]) ] \u2264 eCt 2 ,\nwhere C = 64e n\u03b1/4\n\u03b1 .\nProof. We have \u03be\u03b1,\u03b6(f ) = f (c) \u00b7 \u2211 i\u2208[n] \u03c6p(ci) +\u03b3I (p \u2208 {0,1} \u2227 f (c) , 2p \u2212 1) , p \u223cD\u03b1,\u03b6 , c1\u00b7\u00b7\u00b7n \u223c p.\nLet Y = \u2211 i\u2208[n]\u03c6 p(ci). By Lemma 2.3 and independence,\nE [ etY ] = E c1\u00b7\u00b7\u00b7n\u223cp [ et \u2211 i\u2208[n]\u03c6 p(ci ) ] = ( E c\u223cp [ et\u03c6 p(c) ])n \u2264 et 2n\nfor t \u2208 [\u2212 \u221a \u03b1/2, \u221a \u03b1/2]. Pick t \u2208 {\u00b1 \u221a \u03b1/2} such that\n\u221e\u2211 k=0 t2k+1 (2k + 1)! E [ Y 2k+1 ] \u2265 0.\nThen by dropping positive terms, for all j \u2265 1,\n0 \u2264 E [ Y 2j ] \u2264\n(2j)! t2j \u221e\u2211 k=0 tk k! E [ Y k ] = (2j)! t2j E [ etY ] \u2264 (2j)! t2j ent 2 = 4j(2j)! \u03b1j en\u03b1/4.\nThus we have bounded the even moments of Y . By Cauchy-Schwartz, for k = 2j + 1 \u2265 3,\nE [ |Y |k ] \u2264 \u221a E [ Y 2j ] \u00b7E [ Y 2j+2 ] \u2264 \u221a 4j(2j)! \u03b1j en\u03b1/4 \u00b7 4j+1(2j + 2)! \u03b1j+1 en\u03b1/4 = 2kk! \u03b1k/2 en\u03b1/4 \u221a k + 1 k .\nSince |f (c)| \u2264 1, we have E [ |f (c) \u00b7Y |k ] \u2264 E [ |Y |k ] \u2264 2k+1k!en\u03b1/4/\u03b1k/2 for all k \u2265 2. Since \u03b6 \u2208\n[1/4,1/2), we have \u03b3 = (2/\u03c0)(1 \u2212 2\u03b6)/\u03b6 \u2208 (0,1). Hence E [ |\u03b3I (p \u2208 {0,1} \u2227 f (c) , 2p \u2212 1) |k ] \u2264 1 for\nall k. The map u 7\u2192 |u|k is convex for all k \u2265 2, thus |(x + y)/2|k \u2264 (|x|k + |y|k)/2 for all k \u2265 2 and x,y \u2208R. Combining these three facts, we have\nE [ |\u03be\u03b1,\u03b6(f )|k ] \u2264 2k\u22121E [ |f (c) \u00b7Y |k + |\u03b3I(f (c) , f \u2217(c))|k ] \u2264 2 2kk!en\u03b1/4\n\u03b1k/2 + 2k\u22121 \u2264 2\n2k+1k!en\u03b1/4\n\u03b1k/2 .\nFor t \u2208 [\u2212 \u221a \u03b1/8, \u221a \u03b1/8], we have\nE [ et\u03be\u03b1,\u03b6(f ) ] \u22641 + tE [ \u03be\u03b1,\u03b6(f ) ] + \u221e\u2211 k=2 |t|k k! E [ |\u03be\u03b1,\u03b6(f )|k ] \u22641 + tE [ \u03be\u03b1,\u03b6(f )\n] + \u221e\u2211 k=2 |t|k k! 22k+1k!en\u03b1/4 \u03b1k/2\n=1 + tE [ \u03be\u03b1,\u03b6(f ) ] + 2en\u03b1/4 \u221e\u2211 k=2 ( 4|t| \u221a \u03b1 )k \u22641 + tE [ \u03be\u03b1,\u03b6(f ) ] + 2en\u03b1/4\n\u221e\u2211 k=2 ( 4|t| \u221a \u03b1 )2 2\u2212(k\u22122)\n=1 + tE [ \u03be\u03b1,\u03b6(f ) ] + 64en\u03b1/4\n\u03b1 t2\n\u2264etE[\u03be\u03b1,\u03b6(f )]+Ct 2\nTheorem 2.14 (Azuma-Doob Inequality). Let X1 \u00b7 \u00b7 \u00b7Xm \u2208 R, \u00b51 \u00b7 \u00b7 \u00b7\u00b5mR and U0 \u00b7 \u00b7 \u00b7Um \u2208\u2126 be random variables such that, for all i \u2208 [m],\n\u2022 Xi is determined by Ui ,\n\u2022 \u00b5i is determined by Ui\u22121, and\n\u2022 Ui\u22121 is determined by Ui .\nSuppose that, for all i \u2208 [m], u \u2208\u2126, and t \u2208 [\u2212c,c],\nE [ et(Xi\u2212\u00b5i ) | Ui\u22121 = u ] \u2264 eCt 2 .\nIf \u03bb \u2208 [0,2Cmc], then\nP  \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 \u2211 i\u2208[m] (Xi \u2212\u00b5i) \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 \u2265 \u03bb  \u2264 2e\u2212\u03bb2/4Cm.\nIf \u03bb \u2265 2Cmc, then\nP  \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 \u2211 i\u2208[m] (Xi \u2212\u00b5i) \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 \u2265 \u03bb  \u2264 2emCc2\u2212c\u03bb \u2264 2e\u2212c\u03bb/2.\nProof. First we show by induction on k \u2208 [m] that, for all u \u2208\u2126 and t \u2208 [\u2212c,c],\nE [ et \u2211m i=m\u2212k+1(Xi\u2212\u00b5i ) | Um\u2212k = u ] \u2264 ek\u00b7Ct 2 .\nThis clearly holds for k = 1, as this is our supposition for i = m. Now suppose this holds for some k \u2208 [m\u2212 1]. For u \u2208\u2126 and t \u2208 [\u2212c,c], we have\nE [ et \u2211m i=m\u2212k(Xi\u2212\u00b5i ) | Um\u2212(k+1) = u ] = \u2211 v\u2208\u2126 P [Um\u2212k = v | Um\u2212k\u22121 = u]E [ et \u2211m i=m\u2212k(Xi\u2212\u00b5i ) | Um\u2212k = v ] = \u2211 v\u2208\u2126 P [v | u]E [ et(Xm\u2212k\u2212\u00b5m\u2212k)et \u2211m i=m\u2212k+1(Xi\u2212\u00b5i ) | v\n] (using shorthand v \u2261 Um\u2212k = v and u \u2261 Um\u2212k\u22121 = u)\n= \u2211 v\u2208\u2126 P [v | u]E [ et(Xm\u2212k\u2212\u00b5m\u2212k) | v ] E [ et \u2211m i=m\u2212k+1(Xi\u2212\u00b5i ) | v ] (since Um\u2212k = v determines Xm\u2212k and \u00b5m\u2212k)\n\u2264 \u2211 v\u2208\u2126 P [v | u]E [ et(Xm\u2212k\u2212\u00b5m\u2212k) | v ] ek\u00b7Ct 2\n(by the induction hypothesis) =E [ et(Xm\u2212k\u2212\u00b5m\u2212k) | u ] ek\u00b7Ct 2\n\u2264eCt 2 ek\u00b7Ct 2\n(by our supposition for i =m\u2212 k)\n=e(k+1)\u00b7Ct 2 .\nThus, for all t \u2208 [\u2212c,c], we have E [ et \u2211m i=1(Xi\u2212\u00b5i ) ] \u2264 em\u00b7Ct 2 .\nBy Markov\u2019s inequality we have\nP \u2211 i\u2208[m] (Xi \u2212\u00b5i) \u2265 \u03bb  \u2264 E [ et \u2211 i\u2208[m](Xi\u2212\u00b5i ) ] et\u03bb \u2264 emCt 2\u2212t\u03bb\nand\nP \u2211 i\u2208[m] (Xi \u2212\u00b5i) \u2264 \u2212\u03bb  \u2264 E [ e\u2212t \u2211 i\u2208[m](Xi\u2212\u00b5i ) ] e(\u2212t)(\u2212\u03bb) \u2264 emCt 2\u2212t\u03bb\nfor all t \u2208 [0, c] and \u03bb > 0. Set t = min{c,\u03bb/2mC} to obtain the result."}, {"heading": "2.5.4 Bounding the Score", "text": "Now we can finally show that the scores are large with high probability.\nTheorem 2.15 (Correlation Lower Bound). At the end of IFPCN,n,`[P ,FN,n,\u03b4,\u03b2] for arbitrary P , we have, for any \u03bb \u2208 [0,17.5`/ \u221a \u03b1],\n\u03b3\u03b8` + \u2211 i\u2208S1 s`i \u2265 2 \u03c0 (1\u2212 2\u03b6)(1\u2212 2n\u03b1)` \u2212\u03bb\nwith probability at least 1\u2212 2e\u2212 \u03bb2\u03b1 280` .\nProof. Since the adversary P is computationally unbounded and arbitrary, we may assume it is deterministic. We may also assume n = |S1| and that the adversary is able to see cjS1 at each round. (This only gives the adversary more power.)\nThis means that for each j \u2208 [`] we can define a function f j : {\u00b11}n\u2192 {\u00b11} that only depends on the interaction up to round j \u2212 1 (i.e. is a function of the state of P before it receives cj ) and satisfies f j(cj\nSj ) = aj . For j \u2208 [`], define\nXj := \u03b3 \u00b7 I ( pj \u2208 {0,1} \u2227 f j(cjS1) , 2p j \u2212 1 ) + f j(cjS1) \u00b7 \u2211 i\u2208S1 \u03c6p j (cji ) \u223c \u03be\u03b1,\u03b6(f j ),\nwhere \u223c denotes having the same distribution. We have \u03b3 \u00b7 (\u03b8j \u2212\u03b8j\u22121) + \u2211 i\u2208S1 (sji \u2212 s j\u22121 i ) \u2264 Xj\nand \u03b3\u03b8` + \u2211 i\u2208S1 s`i \u2264 \u2211 j\u2208[`] Xj \u223c \u2211 j\u2208[`] \u03be\u03b1,\u03b6(f j ).\nNow we can apply the above lemmas to bound the expectation and tail of this random variable. Firstly, Proposition 2.12 shows that\n\u00b5j := E [ Xj ] = E [ \u03be\u03b1,\u03b6(f j ) ] \u2265 2 \u03c0 (1\u2212 2\u03b6)(1\u2212 2n\u03b1)\nfor all f j . Moreover, by Proposition 2.13,\nE [ et(X j\u2212\u00b5j ) ] = E [ e t(\u03be\u03b1,\u03b6(f j )\u2212E[\u03be\u03b1,\u03b6(f j )]) ] \u2264 eCt 2\nfor all t \u2208 [\u2212 \u221a \u03b1/8, \u221a \u03b1/8], where C = 70/\u03b1 \u2265 64en\u03b1/4/\u03b1, as \u03b1 \u2264 1/4n.\nDefine Uj = (f 1,p1, c1, \u00b7 \u00b7 \u00b7 , f j ,pj , cj , f j+1) for j \u2208 [`]\u222a{0}. Now X1 \u00b7 \u00b7 \u00b7X`, \u00b51 \u00b7 \u00b7 \u00b7\u00b5`, and U0, \u00b7 \u00b7 \u00b7 ,U` satisfy the hypotheses of Theorem 2.14 with C = 70/\u03b1, c = \u221a \u03b1/8, and m = `.\nFor \u03bb \u2208 [0,2Cmc] = [0,17.5`/ \u221a \u03b1], we have\nP \u2211 j\u2208[`] Xj \u2264 2 \u03c0 (1\u2212 2\u03b6)(1\u2212 2n\u03b1)` \u2212\u03bb  \u2264 P  \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 \u2211 i\u2208[m] (Xi \u2212\u00b5i) \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 \u2265 \u03bb  \u2264 2e\u2212\u03bb2/4Cm \u2264 2e\u2212 \u03bb2\u03b1280` ,\nas required.\nHowever, we can also prove that the scores are small with high probability. This follows from the fact that users with large scores are accused and therefore no user\u2019s score can be too large:\nLemma 2.16. For all \u03bb > 0,\nP \u2211 i\u2208S1 s`i > \u03bb+n\u03c3 + n \u221a \u03b1  \u2264 e\u2212\u03bb2/4n` + e\u2212\u221a\u03b1\u03bb/4, where the probability is taken over IFPCN,n,`[P ,FN,n,\u03b4,\u03b2] for an arbitrary P .\nWe will set \u03bb = \u03c3 and, since 1/ \u221a \u03b1 \u2264 \u03c3 , we get that \u2211 i\u2208S1 s ` i \u2264 3\u03c3n with high probability.\nProof. Let ji \u2208 [`+ 1] be as in Lemma 2.8 \u2013 that is, i < Sji and i \u2208 Sji\u22121, where we define S`+1 = \u2205 and S0 = [N ]. By the definition of ji , sj , and Sj , we have s ji\u22122 i \u2264 \u03c3 for all i \u2208 S 1, as otherwise i \u2208 I ji\u22122 and therefore i < Sji\u22121 = Sji\u22122\\I ji\u22122. If i \u2208 S1, then ji = 1 and s ji\u22121 i = 0. Thus\u2211\ni\u2208S1 s ji\u22121 i = \u2211 i\u2208S1 s ji\u22122 i + a ji\u22121\u03c6p ji\u22121(cji\u22121i ) \u2264 \u2211 i\u2208S1 \u03c3 + 1 \u221a \u03b1 \u2264 n\u03c3 + n\u221a \u03b1 .\nBy Lemma 2.8,\nP \u2211 i\u2208S1 s`i \u2212 s ji\u22121 i > \u03bb  \u2264 e\u2212\u03bb2/4n` + e\u2212\u221a\u03b1\u03bb/4. The lemma follows.\nNow we show that the conflicting bounds of Theorem 2.15 and Lemma 2.16 imply completeness - that is, the adversary P cannot be consistent.\nTheorem 2.17 (Completeness). At the end of IFPCN,n,`[P ,FN,n,\u03b4,\u03b2] for an arbitrary P , we have \u03b8` > \u03b2` with probability at least 1\u2212 \u03b4 1 2 ( 12\u2212\u03b2)n, assuming ( 1 2 \u2212 \u03b2 ) n \u2265 1.\nProof. Suppose for the sake of contradiction that \u03b8` \u2264 \u03b2`. By Lemma 2.16, \u2211 i\u2208S1 s ` i \u2264 \u03bb+n\u03c3+ n\u221a \u03b1 with probability at least 1\u2212 e\u2212\u03bb2/4n` \u2212 e\u2212 \u221a \u03b1\u03bb/4. Set \u03bb = n\u03c3 \u2265 n\u221a\n\u03b1 . Now we assume\u2211 i\u2208S1 s`i \u2264 3n\u03c3,\nwhich holds with probability at least 1\u2212 e\u2212n\u03c32/4` \u2212 e\u2212 \u221a \u03b1n\u03c3/4. Then\n\u03b3\u03b8` + \u2211 i\u2208S1 s`i \u2264 \u03b3\u03b2` + 3n\u03c3. (4)\nBy Theorem 2.15, with probabilty at least 1\u2212 2e\u2212 \u03bb2\u03b1 280` ,\n\u03b3\u03b8` + \u2211 i\u2208S1 s`i \u2265 2 \u03c0 (1\u2212 2\u03b6)(1\u2212 2n\u03b1)` \u2212\u03bb (5)\nfor all \u03bb \u2208 [0,17.5`/ \u221a \u03b1]. Set \u03bb = ( 1 2 \u2212 \u03b2 )2 `/2\u03c0 and assme Equation (5) also holds.\nCombining Equations (4) and (5) gives\n2 \u03c0 (1\u2212 2\u03b6)(1\u2212 2n\u03b1)` \u2212\n( 1 2 \u2212 \u03b2 )2 2\u03c0 ` \u2264 \u03b3\u03b2` + 3n\u03c3. (6)\nWe claim this is a contradiction, which then holds with high probability, thus proving the theorem.\nRearranging Equation (6) gives\n2 \u03c0 (1\u2212 2\u03b6)(1\u2212 2n\u03b1) \u2264\n( 1 2 \u2212 \u03b2 )2 2\u03c0 +\u03b3\u03b2 + 3n\u03c3 ` . (7)\nOur setting of parameters gives\n2n\u03b1 \u2264\n( 1 2 \u2212 \u03b2 ) 2\nand 3n\u03c3 ` \u2264\n( 1 2 \u2212 \u03b2 )2 2\u03c0 .\nSubstituting these into Equation (7) gives\n2 \u03c0\n(1\u2212 2\u03b6) ( 1\u2212 1\n2 (1 2 \u2212 \u03b2 )) \u2264\n( 1 2 \u2212 \u03b2 )2 \u03c0 +\u03b3\u03b2. (8)\nNow we use 1 \u2212 2\u03b6 = 12 ( 1 2 \u2212 \u03b2 ) and \u03b3 = 2\u03c0 1\u22122\u03b6 \u03b6 = ( 12\u2212\u03b2) \u03c0\u03b6 to derive a contradiction from Equation (8): ( 1 2 \u2212 \u03b2\n) \u03c0 ( 1\u2212 1 2 (1 2 \u2212 \u03b2 )) \u2264 ( 1 2 \u2212 \u03b2 )2 \u03c0 + ( 1 2 \u2212 \u03b2 ) \u03c0\u03b6 \u03b2,\n1\u2212 1 2 (1 2 \u2212 \u03b2 ) \u2264 (1 2 \u2212 \u03b2 ) + \u03b2 \u03b6 ,\n\u03b6 ( 1\u2212 3\n2 (1 2 \u2212 \u03b2 )) \u2264\u03b2.\nSince \u03b6 = 12 \u2212 1 4 ( 1 2 \u2212 \u03b2 ) , we have\n\u03b6 ( 1\u2212 3\n2 (1 2 \u2212 \u03b2 )) = 1 2 ( 1\u2212 1 2 (1 2 \u2212 \u03b2 ))( 1\u2212 3 2 (1 2 \u2212 \u03b2 )) > 1 2 ( 1\u2212 2 (1 2 \u2212 \u03b2 )) .\nAnd \u03b2 =\n1 2\n( 1\u2212 2 (1 2 \u2212 \u03b2 )) .\nThis gives a contradiction. The total failure probability is bounded by\ne\u2212n\u03c3 2/4` + e\u2212 \u221a \u03b1n\u03c3/4 + 2e\u2212\u03bb 2\u03b1/280` \u2264 ( \u03b4\n32\n)16n + ( \u03b4\n32\n)4n + 2 ( \u03b4 32 ) 1 2 ( 12\u2212\u03b2)n \u2264 \u03b4 1 2 ( 12\u2212\u03b2)n,\nassuming (\n1 2 \u2212 \u03b2\n) n \u2265 1."}, {"heading": "3 Hardness of False Discovery", "text": ""}, {"heading": "3.1 The Statistical Query Model", "text": "Given a distribution D over {0,1}d , we would like to answer statistical queries about D. A statistical query on {0,1}d is specified by a function q : {0,1}d \u2192 [\u22121,1] and (abusing notation) is defined to be\nq(D) = E x\u2190RD [q(x)] .\nOur goal is to design an oracle O that answers statistical queries onD using only iid samples x1, . . . ,xn\u2190R D. Our focus is the case where the queries are chosen adaptively and adversarially.\nSpecifically, O is a stateful algorithm that holds a collection of samples x1, . . . ,xn \u2208 {0,1}d , takes a statistical query q as input, and returns a real-valued answer a \u2208 [\u22121,1]. We require that when x1, . . . ,xn are iid samples from D, the answer a is close to q(D), and moreover that this condition holds for every query in an adaptively chosen sequence q1, . . . , q`. Formally, we define the following game between an O and a stateful adversary A.\nDefinition 3.1 (Accuracy). An oracle O is (\u03b1,\u03b2,\u03b3)-accurate for ` adaptively chosen queries given n samples in {0,1}d if for every adversary A,\nP Accn,d,`[O,A]\n[ For (1\u2212 \u03b2)` choices of j, \u2223\u2223\u2223O(x,qj )\u2212 qj(D)\u2223\u2223\u2223 \u2264 \u03b1] \u2265 1\u2212\u03b3 . As a shorthand, we will say that O is (\u03b1,\u03b2)-accurate for ` queries if for every n,d \u2208 N, O is (\u03b1,\u03b2,on(1))-accurate for ` queries given n samples in {0,1}d . Here, ` may depend on n and d and on(1) is a function of n that tends to 0.\nWe are interested in oracles that are both accurate and computationally efficient. We say that an oracle O is computationally efficient if when given samples x1, . . . ,xn \u2208 {0,1}d and a query q : {0,1}d \u2192 [\u22121,1] it runs in time poly(n,d, |q|). Here q will be represented as a circuit that evaluates q(x) and |q| denotes the size of this circuit."}, {"heading": "3.2 Encryption Schemes", "text": "Our attack relies on the existence of a semantically secure private-key encryption scheme. An encryption scheme is a triple of efficient algorithms (Gen,Enc,Dec) with the following syntax:\n\u2022 Gen is a randomized algorithm that takes as input a security parameter \u03bb and outputs a \u03bb-bit secret key. Formally, sk\u2190R Gen(1\u03bb).\n\u2022 Enc is a randomized algorithm that takes as input a secret key and a messagem \u2208 {\u22121,0,1} and outputs a ciphertext ct. Formally, ct\u2190R Enc(sk,m).\n\u2022 Dec is a deterministic algorithm that takes as input a secret key and a ciphertext ct and outputs a decrypted message m\u2032. If the ciphertext ct was an encryption of m under the key sk, then m\u2032 =m. Formally, if ct\u2190R Enc(sk,m), then Dec(sk,ct) =m with probability 1.\nRoughly, security of the encryption scheme asserts that no polynomial time adversary who does not know the secret key can distinguish encryptions of m = 0 from encryptions of m = 1, even if the adversary has access to an oracle that returns the encryption of an arbitrary message under the unknown key. For convenience, we will require that this security property holds simultaneously for an arbitrary polynomial number of secret keys. The existence of an encryption scheme with this property follows immediately from the existence an ordinary semantically secure encryption scheme. We start with the stronger definition only to simplify our proofs. A secure encryption scheme exists under the minimal cryptographic assumption that one-way functions exist. The formal definition of security is not needed until Section A."}, {"heading": "3.3 Description of the Attack", "text": "The adversary is specified in Figure 4. In Figure 4, (Gen,Enc,Dec) is an encryption scheme and F is an n-collusion resilient interactive fingerprinting code for N users of length ` = `(N ) robust to a \u03b2 fraction of errors with false accusation probability \u03b4 = 1/8. Observe that Attackn,d is only well defined for pairs n,d \u2208 N for which 1 + dlog2(2000n)e \u2264 d, so that there exists a suitable choice of \u03bb \u2208 N. Through this section we will assume that n = n(d) is a polynomial in d and that d is a sufficiently large unspecified constant, which ensures that Attackn,d is well defined."}, {"heading": "3.4 Analysis of the Attack", "text": "We will start by establishing that the number of falsely accused users is small. That is, letting \u03c8` denote the number of users in T ` who are not in the set S, we have \u03c8` \u2264 N/8 with high probability. This condition will follow from the security of the interactive fingerprinting code F . However, security alone is not enough to guarantee that the number of falsely accused users is small, because security of F applies to adversaries that only have access to cji for users i \u2208 S \\ T j , whereas the queries to the oracle depend on cji for users i < S \\ T j . To remedy this\nproblem we rely on the fact entries cji for i outside of S \\ T j are encrypted under keys ski that are not known to the oracle. Thus, a computationally efficient oracle \u201cdoes not know\u201d those rows. We can formalize this argument by comparing Attack to an IdealAttack (Figure 5) where these entries are replaced with zeros, and argue that the adversary cannot distinguish between these two attacks without breaking the security of the encryption scheme.\nClaim 3.2. For every oracle O, every polynomial n = n(d), and every sufficiently large d \u2208N,\nP IdealAttackn,d [O]\n[ \u03c8` > N/8 ] \u2264 negl(n)\nProof. This follow straightforwardly from a reduction to the security of the fingerprinting code. Notice that since the query qj does not depend on any entry cji for i < S \\ T j\u22121. Thus, an adversary for the fingerprinting code who has access to cj S\\T j\u22121 can simulate the view of the oracle. Since we have for any adversary P\nP IFPCN,n,`[P ,F ]\n[ \u03c8` > N/8 ] \u2264 negl(n),\nwe also have P\nIdealAttackn,d [O]\n[ \u03c8` > N/8 ] \u2264 negl(n),\nas desired.\nNow we can argue that an efficient oracle cannot distinguish between the real attack and the ideal attack. Thus the conclusion that \u03c8` \u2264N/8 with high probability must also hold in the real game.\nThe distribution D: Given parameters d,n, let N = 2000n, and \u03bb = d \u2212 dlog2(2000n)e. For i \u2208 [N ], let ski \u2190R Gen(1\u03bb) and let yi = (i, ski) \u2208 {0,1}d . Let D be the uniform distribution over {y1, . . . , yN } \u2286 {0,1}d .\nChoose samples x1, . . . ,xn\u2190R D, let x = (x1, . . . ,xn). Let S \u2286 [N ] be the set of unique indices i such that (i, ski) appears in x.\nRecovery phase: Let T 1 = \u2205. For j = 1, . . . , ` = `(N ):\nLet cj \u2208 {\u00b11}N be the column given by F . For i \u2208 S, let ctji = Enc(ski , c j i ), for i \u2208 [N ] \\ S, let ct j i = Enc(ski ,0). Define the query qj(i\u2032 , sk\u2032) to be Dec(sk\u2032 , ctji\u2032 ) if i \u2032 < T j and 0 otherwise. Let aj = O(x;qj ) and round aj to {\u00b11} to obtain aj . Give aj to F and let I j \u2286 [N ] be the set of accused users and T j = T j\u22121 \u222a I j .\nFigure 5: IdealAttackn,d[O]\nClaim 3.3. Let Z1 be the event {\n\u03c8` > N/8\n}\n. Assume (Gen,Enc,Dec) is a computationally secure encryption scheme and let n = n(d) be any polynomial. Then if O is computationally efficient, for every d \u2208N \u2223\u2223\u2223\u2223\u2223\u2223 PIdealAttackn,d [O] [Z1]\u2212 PAttackn,d [O] [Z1]\n\u2223\u2223\u2223\u2223\u2223\u2223 \u2264 negl(n) The proof is straightforward from the definition of security, and is deferred to Section A.\nCombining Claims 3.2 and 3.3 we easily obtain the following.\nClaim 3.4. For every computionally efficient oracle O, every polynomial n = n(d), and every sufficiently large d \u2208N,\nP Attackn,d [O]\n[ \u03c8` > N/8 ] \u2264 negl(n)\nClaim 3.4 will be useful because it will allow us to establish that an accurate oracle must give answers that are consistent with the fingerprinting code. That is, using \u03b8` to denote the number of inconsistent answers a1, . . . , a`, we will have \u03b8` `/2 with high probability.\nClaim 3.5. If O is (1/3,\u03b2)-accurate for ` = `(2000n) adaptively chosen queries then for every polynomial n = n(d) and every sufficiently large d \u2208N,\nP Attackn,d [O]\n[ \u03b8` \u2264 \u03b2` ] \u2265 1\u2212 on(1)\nProof. In the attack, the oracle\u2019s input consists of n samples from D, and the total number of queries issued is `. Therefore, by the assumption that O is (1/3,\u03b2)-accurate for ` queries, we have\nP  For (1\u2212 \u03b2)` choices of j \u2208 [`],\u2223\u2223\u2223\u2223\u2223\u2223O(x,qj )\u2212 E(i,ski )\u2190RD [qj(i, ski)] \u2223\u2223\u2223\u2223\u2223\u2223 \u2264 1/3  \u2265 1\u2212 on(1). (9)\nObserve that, by construction, for every j \u2208 [`],\u2223\u2223\u2223\u2223\u2223\u2223 E(i,ski )\u2190RD [qj(i, ski)]\u2212 Ei\u2208[N ] [ c j i ]\u2223\u2223\u2223\u2223\u2223\u2223 =\n\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223  1N \u2211 i\u2208[N ]\\T j\u22121 Dec(ski , ct j i ) + 1 N \u2211 i\u2208T j\u22121 0 \u2212 Ei\u2208[n] [ c j i ]\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 =\n\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223  1N \u2211 i\u2208[N ]\\T j\u22121 c j i \u2212 Ei\u2208[n] [ c j i ]\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 \u2264 2 \u2223\u2223\u2223T j\u22121\u2223\u2223\u2223 N\n\u2264 2(\u03c8j\u22121 +n)\nN (10)\nwhere the second equality is because by construction ctji \u2190R Enc(ski , c j i ) and the inequality is because we have cji \u2208 {\u00b11}. By Claim 3.4, and the fact that \u03c8j\u22121 \u2264 \u03c8`, we have\nP [ \u03c8j\u22121 > N/8 +n ] \u2264 P [ \u03c8` > N/8 +n ] \u2264 negl(n).\nNoting that N/8 +n \u2264N/6 and combining with (10), we have\nP [ \u2200 j \u2208 [`], \u2223\u2223\u2223\u2223\u2223\u2223 E(i,ski )\u2190RD [qj(i, ski)]\u2212 Ei\u2208[n] [ c j i ]\u2223\u2223\u2223\u2223\u2223\u2223 \u2264 1/3 ] \u2265 1\u2212negl(n)\nApplying the triangle inequality to (9) and (10), we obtain\nP  For (1\u2212 \u03b2)` choices of j \u2208 [`],\u2223\u2223\u2223\u2223\u2223\u2223O(x,qj )\u2212 Ei\u2208[N ] [ c j i ]\u2223\u2223\u2223\u2223\u2223\u2223 \u2264 2/3  \u2265 1\u2212 on(1). (11)\nFix a j \u2208 [`] such that aj is accurate for query qj . If cji = 1 for every i \u2208 S \\T j\u22121, then by (10), aj = O(x,qj ) \u2265 1/3, so the rounded answer aj = 1. Similarly if cji = \u22121 for every i \u2208 S \\ T j\u22121, aj = \u22121. Therefore there must exist i \u2208 S \\T j\u22121 so that aj = cji . Thus there are (1\u2212\u03b2)` choices of j \u2208 [`] for which this condition holds, so the number of errors \u03b8` is at most \u03b2`. This completes the proof of the claim.\nAs before, we can argue that the real attack and the ideal attack are computationally indistinguishable, and thus the oracle must also give consistent answers in the ideal attack.\nClaim 3.6. Let Z2 be the event { \u03b8` \u2264 \u03b2` } . Assume (Gen,Enc,Dec) is a computationally secure encryption scheme and let n = n(d) be any polynomial. Then if O is computationally efficient, for every d \u2208N \u2223\u2223\u2223\u2223\u2223\u2223 PIdealAttackn,d [O] [Z2]\u2212 PAttackn,d [O] [Z2] \u2223\u2223\u2223\u2223\u2223\u2223 \u2264 negl(n)\nThe proof is straightforward from the definition of security, and is deferred to Section A. Combining Claims 3.5 and 3.6 we easily obtain the following.\nClaim 3.7. If O computationally efficient and (1/3,\u03b2)-accurate for ` = `(2000n) adaptively chosen queries then for every polynomial n = n(d) and every sufficiently large d \u2208N,\nP IdealAttackn,d [O]\n[ \u03b8` \u2264 \u03b2` ] \u2265 1\u2212 on(1)\nHowever, the conclusion of 3.7 can easily be seen to lead to a contradiction, because the security of the fingerprinting code assures that no attacker who only has access to cj\nS\\T j\u22121 in\neach round j = 1, . . . , ` can give answers that are consistent for (1\u2212 \u03b2)` of the columns cj . Thus, we have\nClaim 3.8. For every oracle O, every polynomial n = n(d), and every sufficiently large d \u2208N,\nP IdealAttackn,d [O]\n[ \u03b8` \u2264 \u03b2` ] \u2264 negl(n)\nPutting it together, we obtain the following theorem. Theorem 3.9. There is a function `(2000n,\u03b2) = O(n2/ (\n1 2 \u2212 \u03b2\n)4 ) such that there is no computa-\ntionally efficient oracle O that is (1/3,\u03b2)-accurate for `(2000n,\u03b2) adaptively chosen queries given n samples in {0,1}d .\nProof. Assume for the sake of contradiction that there were such an oracle. Then by Claim 3.7 we would have\nP IdealAttackn,d [O]\n[ \u03b8` \u2264 \u03b2` ] \u2265 1\u2212 on(1).\nBut, by Claim 3.8 we have P\nIdealAttackn,d [O]\n[ \u03b8` \u2264 \u03b2` ] \u2264 negl(n),\nwhich is a contradiction."}, {"heading": "3.5 An Information-Theoretic Lower Bound", "text": "As in [HU14], we observe that the techniques underlying our computational hardness result can also be used to prove an information-theoretic lower bound when the dimension of the data is large. At a high level, the argument uses the fact that the encryption scheme we rely on only needs to satisfy relatively weak security properties, specifically security for at most O(n2) messages. This security property can actually be achieved against computationally unbounded adversaries provided that the length of the secret keys is O(n2). As a result, our lower bound can be made to hold against computationally unbounded oracles, but since the secret keys have length O(n2), we will require d =O(n2). We refer the reader to [HU14] for a slightly more detailed discussion, and simply state the following result.\nTheorem 3.10. There is a function `(2000n,\u03b2) =O(n2/ (\n1 2 \u2212 \u03b2\n)4 ) such that there is no oracleO (even\none that is computationally unbounded) that is (1/3,\u03b2)-accurate for `(2000n,\u03b2) adaptively chosen queries given n samples in {0,1}d when d \u2265 `(2000n,\u03b2)."}, {"heading": "4 Hardness of Avoiding Blatant Non Privacy", "text": "In this section we show how our arguments also imply that computationally efficient oracles that guarantee accuracy for adaptively chosen statistical queries must be blatantly non-private."}, {"heading": "4.1 Blatant Non Privacy and Sample Accuracy", "text": "Before we can define blatant non-privacy, we need to define a notion of accuracy that is more appropriate for the application to privacy. In contrast to Definition 3.1 where accuracy is defined with respect to the distribution, here we define accurate with respect to the sample itself. With this change in mind, we model blatant non-privacy via the following game.\nDefinition 4.1. An oracle O is (\u03b1,\u03b2,\u03b3)-sample-accurate for ` adaptively chosen queries given n samples in {0,1}d if for every adversary Apriv,\nP NonPrivacyn,d,`[O,Apriv]\n[ For (1\u2212 \u03b2)` choices of j \u2208 [`], \u2223\u2223\u2223O(x,qj )\u2212 qj(x)\u2223\u2223\u2223 \u2264 \u03b1] \u2265 1\u2212\u03b3 where q(x) = 1n \u2211 i\u2208[n] q(xi) is the average over the sample.\nAs a shorthand, we will say that O is (\u03b1,\u03b2)-sample-accurate for ` queries if for every n,d \u2208N, O is (\u03b1,\u03b2,on(1))-accurate for ` queries given n samples in {0,1}d . Here, ` may depend on n and d and on(1) is a function of n that tends to 0.\nDefinition 4.2. Giving (\u03b1,\u03b2)-accurate answers to ` adaptively chosen queries is blatantly nonprivate for efficient oracles if there exists an adversary Apriv such that for every oracle O that is computationally efficient and (\u03b1,\u03b2)-sample-accurate for ` adaptively chosen queries,\nP NonPrivacyn,d,`[O,Apriv]\n[ |x4x\u2032 | > n/100 ] \u2264 on(1)\nIf the conclusion holds even for computationally inefficient oracles then we replace \u201cfor efficient oracles\u201d with \u201cfor unbounded oracles\u201d in the definition."}, {"heading": "4.2 Lower Bounds", "text": "In this section we show the following theorem\nTheorem 4.3. Giving accurate answers to O(n2) adaptively chosen queries is blatantly non-private for computationally efficient oracles.\nThe attack is defined in Figure 7. Therein F is a n-collusion-resilient interactive fingerprinting code of length ` for N = 2n users robust to a \u03b2 fraction of errors with false accusation probability \u03b4 = 1/2000.\nWe will start by establishing that the number of falsely accused users is small. That is, letting \u03c8j denote the number of users in T j who are not in the set x, we have \u03c8L \u2264 n/1000 with high probability. As in Section 3, this condition will follow from the security of the interactive fingerprinting code F combined with the security of the encryption scheme, via the introduction of an \u201cideal attack\u201d (Figure 8).\nClaim 4.4. For every oracle O, every polynomial n = n(d), and every sufficiently large d \u2208N,\nP IdealAttackn,d [O]\n[ \u03c8L > n/1000 ] \u2264 negl(n)\nProof. This follow straightforwardly from a reduction to the security of the fingerprinting code. Notice that since the query qj does not depend on any entry cji for i < x\\T j\u22121. Thus, an adversary for the fingerprinting code who has access to cj x\\T j\u22121 can simulate the view of the oracle. Since we have for any adversary P\nP IFPCN,n,`[P ,F ]\n[ \u03c8` > N/2000 ] \u2264 negl(n),\nwe also have P\nIdealPrivacyAttackn,d [O]\n[ \u03c8L > n/1000 ] \u2264 negl(n),\nwhere we have used the fact that for every j \u2032 \u2264 j, \u03c8j \u2032 \u2264 \u03c8j . This completes the proof.\nNow we can argue that an efficient oracle cannot distinguish between the real attack and the ideal attack. Thus the conclusion that \u03c8L \u2264 n/1000 with high probability must also hold in the real game.\nClaim 4.5. Let Z1 be the event { \u03c8L > n/1000 } Assume (Gen,Enc,Dec) is a computationally secure encryption scheme and let n = n(d) be any polynomial. Then if O is computationally efficient, for every d \u2208N \u2223\u2223\u2223\u2223\u2223\u2223 PIdealPrivacyAttackn,d [O] [Z1]\u2212 PPrivacyAttackn,d [O] [Z1]\n\u2223\u2223\u2223\u2223\u2223\u2223 \u2264 negl(n) The proof is straightforward from the definition of security, and is deferred to Section A.\nCombining Claims 4.4 and 4.5 we easily obtain the following.\nClaim 4.6. For every computionally efficient oracle O, every polynomial n = n(d), and every sufficiently large d \u2208N,\nP PrivacyAttackn,d [O]\n[ \u03c8L > n/1000 ] \u2264 negl(n)\nBy Claim 4.6 we have |x\u2032 \\ x| \u2264 n/1000. Now, in order to show |x\u20324x| \u2264 n/100, it suffices to show that |x\\x\u2032 | \u2264 n/200. In order to do so we begin with the following claim, which establishes that if the oracle O is sufficiently accurate, and |x \\ T j\u22121| \u2264 n/200, then the oracle returns a consistent answer to the query qj . Recalling that we use \u03b8j to denote the number of rounded answers ak for 1 \u2264 k \u2264 j that are inconsistent with cj , we can state the following claim.\nClaim 4.7. If O is (1/1000,0)-sample-accurate for ` = `(2n) adaptively chosen queries then for every polynomial n = n(d), every sufficiently large d \u2208N, and every j \u2208 [L],\nP PrivacyAttackn,d [O]\n[ \u03b8L = 0 ] \u2265 1\u2212 on(1)\nProof. Observe that, by construction, for every j \u2208 [`],\nE i\u2208x\n[ qj(xi) ] =\n1 n  \u2211 i\u2208(x\\T j\u22121) c j i + \u2211 i\u2208(x\u2229T j\u22121) 0  = E i\u2208(x\\T j\u22121) [ c j i ] \u00b7 ( |x \\ T j\u22121| n\n) After renormalizing by (n/n\u2212 |T j\u22121|) we have(\nn\nn\u2212 |T j\u22121| ) \u00b7 E i\u2208x [ qj(xi) ] = E i\u2208(x\\T j\u22121) [ c j i ] \u00b7 ( n n\u2212 |T j\u22121| ) \u00b7 ( |x \\ T j\u22121| n\n) = E i\u2208(x\\T j\u22121) [ c j i ] \u00b7 ( n\u2212 T j\u22121 +\u03c8j\u22121 n\u2212 |T j\u22121|\n) = E i\u2208(x\\T j\u22121) [ c j i ] \u00b7 ( 1 + \u03c8j\u22121 n\u2212 |T j\u22121|\n) Since 0 \u2264 \u03c8j\u22121 \u2264 n/10000 (by Claim 4.6), and since the algorithm terminates unless |T j\u22121| \u2264 499n/500, we obtain\nE i\u2208(x\\T j\u22121)\n[ c j i ] \u2264 ( n\nn\u2212 |T j\u22121| ) \u00b7 E i\u2208x [ qj(xi) ] \u2264 11 10 \u00b7 E i\u2208(x\\T j\u22121) [ c j i ] =\u21d2 \u2223\u2223\u2223\u2223\u2223\u2223 ( n n\u2212 |T j\u22121| ) \u00b7 E i\u2208x [ qj(xi) ] \u2212 E i\u2208(x\\T j\u22121) [ c j i\n]\u2223\u2223\u2223\u2223\u2223\u2223 \u2264 110 (12) By the assumption that O is (1/1000,0)-sample-accurate, we have that, with probability 1 \u2212 on(1), for every j \u2208 [L], \u2223\u2223\u2223\u2223\u2223aj \u2212 Ei\u2208x [qj(xi)]\n\u2223\u2223\u2223\u2223\u2223 \u2264 1/1000. (13) Now, combining (12) and (13), we have\u2223\u2223\u2223\u2223\u2223\u2223 ( n n\u2212 |T j\u22121| ) \u00b7 aj \u2212 E i\u2208(x\\T j\u22121) [ c j i\n]\u2223\u2223\u2223\u2223\u2223\u2223 \u2264 \u2223\u2223\u2223\u2223\u2223\u2223 (( n n\u2212 |T j\u22121| ) \u00b7 E i\u2208x [ qj(xi) ] \u2212 E i\u2208(x\\T j\u22121) [ c j i ]) + (\nn\nn\u2212 |T j\u22121|\n) \u00b7 1\n1000 \u2223\u2223\u2223\u2223\u2223\u2223 \u2264 12 + 110 \u2264 23 (14) Finally, observe that if cji = 1 for every i \u2208 [2n], then we have\nE i\u2208(x\\T j\u22121)\n[ c j i ] = 1,\nand by (14) we have (n/(n\u2212 |T j |))aj \u2265 1\u2212 2/3 = 1/3. Thus, the rounded answer aj = 1. Similarly, if cji = \u22121 for every i \u2208 [2n], then we have a j = \u22121. This completes the proof of the claim.\nAs before, we can argue that the real attack and the ideal attack are computationally indistinguishable, and thus the oracle must also give consistent answers in the ideal attack.\nClaim 4.8. Let Z2 be the event { \u03b8L = 0 } Assume (Gen,Enc,Dec) is a computationally secure encryption scheme and let n = n(d) be any polynomial. Then if O is computationally efficient, for every d \u2208N \u2223\u2223\u2223\u2223\u2223\u2223 PIdealPrivacyAttackn,d [O] [Z2]\u2212 PPrivacyAttackn,d [O] [Z2]\n\u2223\u2223\u2223\u2223\u2223\u2223 \u2264 negl(n) The proof is straightforward from the definition of security, and is deferred to Section A.\nCombining Claims 4.7 and 4.8 we easily obtain the following.\nClaim 4.9. If O computationally efficient and (1/1000,0)-accurate for ` = `(2n) adaptively chosen queries then for every polynomial n = n(d) and every sufficiently large d \u2208N,\nP IdealPrivacyAttackn,d [O]\n[ \u03b8L = 0 ] \u2265 1\u2212 on(1)\nWe can use Claim 4.9 to derive a contradiction. To do so we use the fact that the security of the fingerprinting code assures that no attacker who only has access to cj\nx\\T j\u22121 in each round\nj = 1, . . . , ` can give answers that are consistent for all ` of the columns cj . Thus, we have\nClaim 4.10. For every oracle O, every polynomial n = n(d), and every sufficiently large d \u2208 N, if L = `\nP IdealPrivacyAttackn,d [O]\n[ \u03b8` = 0 ] \u2264 negl(n)\nPutting it together, we obtain the following theorem.\nTheorem 4.11. There is a function `(2n) = O(n2) such that there is no computationally efficient oracle O that is (1/1000,0)-accurate for `(2n) adaptively chosen queries given n samples in {0,1}d .\nProof. Assume for the sake of contradiction that there were such an oracle. Now consider two cases. First consider the case that L < `, which means the algorithm has terminated early due to the condition |T L| \u2265 499n/500 being reached. In this case we have |x\u2032 | = |T L| \u2265 499n/500. However, by Claim 4.4, we have that |x\u2032 \\ x| \u2264 n/10000. Therefore we have |x4x\u2032 | \u2264 (499/500\u2212 1/5000)n \u2264 n/100, as desired.\nNow consider the case where L = `, meaning the algorithm does not terminate early. In this case, by Claim 4.9 we have\nP IdealPrivacyAttackn,d [O]\n[ \u03b8` = 0 ] \u2265 1\u2212 on(1)\nbut by Claim 4.10 we have\nP IdealPrivacyAttackn,d [O]\n[ \u03b8` = 0 ] \u2264 negl(n),\nwhich is a contradiction. This completes the proof of the theorem."}, {"heading": "4.3 An Information-Theoretic Lower Bound", "text": "As we did in Section 3.5, we can prove an information-theoretic analogue of our hardness result for avoiding blatant non-privacy.\nTheorem 4.12. There is a function `(2n) = O(n2) such that there is no oracle O (even a computationally unbounded one) that is (1/1000,0)-accurate for `(2n) adaptively chosen queries given n samples in {0,1}d where d \u2265 `(2n).\nThe proof is essentially identical to what is sketched in Section 3.5."}, {"heading": "Acknowledgements", "text": "We thank Moritz Hardt and Salil Vadhan for insightful discussions during the early stages of this work."}, {"heading": "A Security Reductions from Sections 3 and 4", "text": "In Section 3 we made several claims comparing the probability of events in Attack to the probability of events in IdealAttack. Each of these claims follow from the assumed security of the encryption scheme. In this section we restate and prove these claims. Since the claims are all of a similar nature, the proof will be somewhat modular. The claims in Section 4 relating PrivacyAttack to IdealPrivacyAttack can be proven in an essentially identical fashion, and we omit these proofs for brevity.\nBefore we begin recall the formal definition of security of an encryption scheme. Security is defined via a pair of oracles E0 and E1. E1(sk1, . . . , skN , \u00b7) takes as input the index of a key i \u2208 [N ] and a message m and returns Enc(ski ,m), whereas E0(sk1, . . . , skN , \u00b7) takes the same input but returns Enc(ski ,0). The security of the encryption scheme asserts that for randomly chosen secret keys, no computationally efficient adversary can tell whether or not it is interacting with E0 or E1.\nDefinition A.1. An encryption scheme (Gen,Enc,Dec) is secure if for every polynomial N = N (\u03bb), and every poly(\u03bb)-time adversary B, if sk1, . . . , skN \u2190R Gen(1\u03bb)\u2223\u2223\u2223\u2223P [BE0(sk1,...,skN ,\u00b7) = 1]\u2212P [BE1(sk1,...,skN ,\u00b7) = 1]\u2223\u2223\u2223\u2223 = negl(\u03bb)\nWe now restate the relevant claims from Section 3. Claim A.2 (Claim 3.3 Restated). Let Z1 be the event { \u03c8` > N/8 } . Assume (Gen,Enc,Dec) is a computationally secure encryption scheme and let n = n(d) be any polynomial. Then if O is computationally efficient, for every d \u2208N\u2223\u2223\u2223\u2223\u2223\u2223 PIdealAttackn,d [O] [Z1]\u2212 PAttackn,d [O] [Z1] \u2223\u2223\u2223\u2223\u2223\u2223 \u2264 negl(n)\nClaim A.3 (Claim 3.6 Restated). Let Z2 be the event { \u03b8` \u2264 \u03b2` } . Assume (Gen,Enc,Dec) is a computationally secure encryption scheme and let n = n(d) be any polynomial. Then ifO is computationally efficient, for every d \u2208N \u2223\u2223\u2223\u2223\u2223\u2223 PIdealAttackn,d [O] [Z2]\u2212 PAttackn,d [O] [Z2]\n\u2223\u2223\u2223\u2223\u2223\u2223 \u2264 negl(n) To prove both of these claims, for c \u2208 {1,2} we construct an adversary Bc that will attempt to use O to break the security of the encryption. We construct Bc in such a way that its advantage in breaking the security of encryption is precisely the difference in the probability of the event Zc between Attack and IdealAttack, which implies that the difference in probabilities is negligible. The simulator is given in Figure 9\nProof of Claims A.2, A.3. First, observe that for c \u2208 {1,2}, Bc is computationally efficient as long as F and O are both computationally efficient. It is not hard to see that our construction F is efficient and efficiency ofO is an assumption of the claim. Also notice B can determine whether Zc has occurred efficiently.\nNow we observe that when the oracle is E1 (the oracle that takes as input i andm and returns Enc(ski ,m)), and sk1, . . . , skN are chosen randomly from Gen(1\u03bb), then the view of the oracle is identical to Attackn,d[O]. Specifically, the oracle holds a random sample of pairs (i, ski) and is shown queries that are encryptions either under keys it knows or random unknown keys. Moreover, the messages being encrypted are chosen from the same distribution. On the other hand, when the oracle is E0 (the oracle that takes as input i and ct and returns Enc(ski ,0)), then\nthe view of the oracle is identical to Attackn,d[O]. Thus we have that for c \u2208 {1,2},\u2223\u2223\u2223\u2223\u2223\u2223 PIdealAttackn,d [O] [Zc]\u2212 PAttackn,d [O] [Zc] \u2223\u2223\u2223\u2223\u2223\u2223\n= \u2223\u2223\u2223\u2223\u2223\u2223 Psk1,...,skN\u2190RGen(1\u03bb) [ BE0(sk1,...,skN ,\u00b7)c,n,d = 1 ] \u2212 P sk1,...,skN\u2190RGen(1\u03bb) [ BE1(sk1,...,skN ,\u00b7)c,n,d = 1 ]\u2223\u2223\u2223\u2223\u2223\u2223 = negl(\u03bb) = negl(d) The last equality holds because we have chosen N = 2000n(d) = poly(d), and therefore we have \u03bb = d \u2212 dlogN e = d \u2212O(logd). This completes the proof of both claims."}], "references": [{"title": "Controlling the false discovery rate: a practical and powerful approach to multiple testing", "author": ["Yoav Benjamini", "Yosef Hochberg"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological),", "citeRegEx": "Benjamini and Hochberg.,? \\Q1995\\E", "shortCiteRegEx": "Benjamini and Hochberg.", "year": 1995}, {"title": "Bonferroni. Teoria statistica delle classi e calcolo delle probabilita", "author": ["Carlo Emilio"], "venue": "Pubbl. d. R. Ist. Super. di Sci. Econom. e Commerciali di Firenze.,", "citeRegEx": "Emilio,? \\Q1936\\E", "shortCiteRegEx": "Emilio", "year": 1936}, {"title": "Collusion-secure fingerprinting for digital data", "author": ["Dan Boneh", "James Shaw"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Boneh and Shaw.,? \\Q1998\\E", "shortCiteRegEx": "Boneh and Shaw.", "year": 1998}, {"title": "Fingerprinting codes and the price of approximate differential privacy", "author": ["Mark Bun", "Jonathan Ullman", "Salil P. Vadhan"], "venue": "In STOC,", "citeRegEx": "Bun et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bun et al\\.", "year": 2014}, {"title": "Tracing traitors", "author": ["Benny Chor", "Amos Fiat", "Moni Naor"], "venue": "In CRYPTO,", "citeRegEx": "Chor et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Chor et al\\.", "year": 1994}, {"title": "Guilt-free data exploration (tentative title)", "author": ["Cynthia Dwork", "Vitaly Feldman", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Aaron Roth"], "venue": null, "citeRegEx": "Dwork et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2014}, {"title": "Calibrating noise to sensitivity in private data analysis", "author": ["Cynthia Dwork", "Frank McSherry", "Kobbi Nissim", "Adam Smith"], "venue": "In TCC,", "citeRegEx": "Dwork et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2006}, {"title": "Revealing information while preserving privacy", "author": ["Irit Dinur", "Kobbi Nissim"], "venue": "In PODS, pages 202\u2013210", "citeRegEx": "Dinur and Nissim.,? \\Q2003\\E", "shortCiteRegEx": "Dinur and Nissim.", "year": 2003}, {"title": "On the complexity of differentially private data release: efficient algorithms and hardness results", "author": ["Cynthia Dwork", "Moni Naor", "Omer Reingold", "Guy N. Rothblum", "Salil P. Vadhan"], "venue": "In STOC,", "citeRegEx": "Dwork et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2009}, {"title": "Multiple comparisons among means", "author": ["Olive Jean Dunn"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Dunn.,? \\Q1961\\E", "shortCiteRegEx": "Dunn.", "year": 1961}, {"title": "On some classical results in probability theory", "author": ["N. Etemadi"], "venue": "Sankhya: The Indian Journal of Statistics, Series A (1961-2002),", "citeRegEx": "Etemadi.,? \\Q1985\\E", "shortCiteRegEx": "Etemadi.", "year": 1985}, {"title": "Dynamic traitor tracing", "author": ["Amos Fiat", "Tamir Tassa"], "venue": "J. Cryptology,", "citeRegEx": "Fiat and Tassa.,? \\Q2001\\E", "shortCiteRegEx": "Fiat and Tassa.", "year": 2001}, {"title": "Preventing false discovery in interactive data analysis is hard", "author": ["Moritz Hardt", "Jonathan Ullman"], "venue": "In FOCS. IEEE, October", "citeRegEx": "Hardt and Ullman.,? \\Q2014\\E", "shortCiteRegEx": "Hardt and Ullman.", "year": 2014}, {"title": "Efficient noise-tolerant learning from statistical queries", "author": ["Michael J. Kearns"], "venue": "In STOC, pages 392\u2013401", "citeRegEx": "Kearns.,? \\Q1993\\E", "shortCiteRegEx": "Kearns.", "year": 1993}, {"title": "Analysis of Boolean Functions", "author": ["Ryan O\u2019Donnell"], "venue": null, "citeRegEx": "O.Donnell.,? \\Q2014\\E", "shortCiteRegEx": "O.Donnell.", "year": 2014}, {"title": "Optimal probabilistic fingerprint codes", "author": ["G\u00e1bor Tardos"], "venue": "J. ACM,", "citeRegEx": "Tardos.,? \\Q2008\\E", "shortCiteRegEx": "Tardos.", "year": 2008}, {"title": "Answering n2+o(1) counting queries with differential privacy is hard", "author": ["Jonathan Ullman"], "venue": "In STOC, pages 361\u2013370", "citeRegEx": "Ullman.,? \\Q2013\\E", "shortCiteRegEx": "Ullman.", "year": 2013}, {"title": "Private multiplicative weights beyond linear queries", "author": ["Jonathan Ullman"], "venue": "CoRR, abs/1407.1571,", "citeRegEx": "Ullman.,? \\Q2014\\E", "shortCiteRegEx": "Ullman.", "year": 2014}], "referenceMentions": [], "year": 2017, "abstractText": "We show a tight bound on the number of adaptively chosen statistical queries that a computationally efficient algorithm can answer accurately given n samples from an unknown distribution. A statistical query asks for the expectation of a predicate over the underlying distribution, and an answer to a statistical query is accurate if it is \u201cclose\u201d to the correct expectation over the distribution. This question was recently considered by Dwork et al. [DFH+14], who showed that \u03a9\u0303(n2) queries can be answer efficiently, and also by Hardt and Ullman [HU14], who showed that answering \u00d5(n3) queries is computationally hard. We close the gap between the two bounds by proving a new, nearly-optimal hardness result. Specifically, we show that, under a standard hardness assumption, there is no computationally efficient algorithm that given n samples from an unknown distribution can give valid answers toO(n2) adaptively chosen statistical queries. An implication of our results is that computationally efficient algorithms for answering arbitrary, adaptively chosen statistical queries may as well be differentially private. We obtain our results via an optimal construction of a new combinatorial object that we call an interactive fingerprinting code, which may be of independent interest. \u2217Harvard University School of Engineering and Applied Sciences. Supported by NSF grant CCF-1116616. Email: tsteinke@seas.harvard.edu. \u2020Harvard University Center for Research on Computation and Society and Columbia University. Supported by NSF Grant CNS-1237235 and a Simons Society of Fellows Junior Fellowship. Email: jullman@cs.columbia.edu. ar X iv :1 41 0. 12 28 v1 [ cs .C R ] 5 O ct 2 01 4", "creator": "LaTeX with hyperref package"}}}