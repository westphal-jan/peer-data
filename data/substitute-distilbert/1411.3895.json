{"id": "1411.3895", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Nov-2014", "title": "Learning Fuzzy Controllers in Mobile Robotics with Embedded Preprocessing", "abstract": "the automatic design defining parameters for mobile robots usually requires two objectives. in the first stage, sensorial data are filtered or transformed into high level and meaningful values of properties whichare usually controlled without expert knowledge. in the second stage, a machine learning technique is applied toobtain a controller that maps these high level variables to the control commands that robotics actually sent tothe models. this paper describes an algorithm that is supposed to embed the preprocessing stage preceding the learningstage in order to get controllers directly calculated from sensorial raw data with no expert knowledgeinvolved. due to the high dimensionality of the sensorial data, this approach favors quantified objective rules ( qfrs ), that are able to transforming low - level query variables into high - level input variables, forcing dimensionality through summarization. the proposed learning algorithm, called projective quantifiedfuzzy spatial learning ( iqfrl ), is based classical genetic programming. iqfrl is able to handle rules with confidence, and can manage linguistic variables with multiple granularities. the algorithm has been testedwith different implementation evaluating the wall - map behavior both in several realistic simulated environmentswith different complexity and on a pioneer 3 - at once in two real environments. results have beencompared with several well - known learning algorithms evaluated with different data preprocessingtechniques, showing that iqfrl exhibits a profound and statistically improved performance. moreover, three virtual world applications for which iqfrl plays outstanding central role are also proved : path and objecttracking with static and moving obstacles disabled.", "histories": [["v1", "Fri, 14 Nov 2014 13:11:32 GMT  (2250kb,D)", "http://arxiv.org/abs/1411.3895v1", null]], "reviews": [], "SUBJECTS": "cs.RO cs.AI cs.LG", "authors": ["i rodr\\'iguez-fdez", "m mucientes", "a bugar\\'in"], "accepted": false, "id": "1411.3895"}, "pdf": {"name": "1411.3895.pdf", "metadata": {"source": "CRF", "title": "Learning Fuzzy Controllers in Mobile Robotics with Embedded Preprocessing", "authors": ["I. Rodr\u0131\u0301guez-Fdez", "M. Mucientes", "A. Bugar\u0131\u0301n"], "emails": ["ismael.rodriguez@usc.es"], "sections": [{"heading": null, "text": "The automatic design of controllers for mobile robots usually requires two stages. In the first stage, sensorial data are preprocessed or transformed into high level and meaningful values of variables which are usually defined from expert knowledge. In the second stage, a machine learning technique is applied to obtain a controller that maps these high level variables to the control commands that are actually sent to the robot. This paper describes an algorithm that is able to embed the preprocessing stage into the learning stage in order to get controllers directly starting from sensorial raw data with no expert knowledge involved. Due to the high dimensionality of the sensorial data, this approach uses Quantified Fuzzy Rules (QFRs), that are able to transform low-level input variables into high-level input variables, reducing the dimensionality through summarization. The proposed learning algorithm, called Iterative Quantified Fuzzy Rule Learning (IQFRL), is based on genetic programming. IQFRL is able to learn rules with different structures, and can manage linguistic variables with multiple granularities. The algorithm has been tested with the implementation of the wall-following behavior both in several realistic simulated environments with different complexity and on a Pioneer 3-AT robot in two real environments. Results have been compared with several well-known learning algorithms combined with different data preprocessing techniques, showing that IQFRL exhibits a better and statistically significant performance. Moreover, three real world applications for which IQFRL plays a central role are also presented: path and object tracking with static and moving obstacles avoidance.\nKeywords: mobile robotics, Quantified Fuzzy Rules, Iterative Rule Learning, Genetic Fuzzy System"}, {"heading": "1. Introduction", "text": "The control architecture of mobile robots usually includes a number of behaviors that are implemented as controllers, which are able to solve specific tasks such as motion planning, following a moving object, wall-following, avoiding collisions, etc. in real time. These behaviors are implemented as controllers whose outputs at each time point (control commands) depend on both the internal state of the robot and the environment in which it evolves. The robot sensors (e.g. laser range finders, sonars, cameras, etc.) are used in order to obtain the augmented state of the robot (internal state and environment). When the robot operates in real environments, both the data obtained by these sensors and the internal state of the robot present uncertainty or noise. Therefore, the use of mechanisms that manage them properly is necessary. The use of fuzzy rules is convenient to cope with this uncertainty, since it combines the interpretability and expressiveness of the rules with the ability of fuzzy logic for representing uncertainty.\nThe first step for designing controllers for mobile robots consists of the preprocessing of the raw sensor data: the low-level input variables obtained by the sensors are transformed into high-level variables that are significant for the\n\u2217Corresponding author. Tel.: +34 881816392. Email addresses: ismael.rodriguez@usc.es (I. Rodr\u0131\u0301guez-Fdez),\nmanuel.mucientes@usc.es (M. Mucientes), alberto.bugarin.diz@usc.es (A. Bugar\u0131\u0301n)\nbehavior to be learned. Usually, expert knowledge is used for the definition of these high-level variables and the mapping from the sensorial data. After this preprocessing stage, machine learning algorithms can be used to automatically obtain the mapping from the high-level input variables to the robot control commands. This paper describes an algorithm that is able to perform the preprocessing stage embedded in the learning stage, thus avoiding the use of expert knowledge. Therefore, the mapping between low-level and high-level input variables is done automatically during the learning phase of the controller.\nThe data provided by the sensors is of high dimensionality. For example, a robot equipped with two laser range finders can generate over 720 low-level variables. However, in mobile robotics it is more common to work with sets or groupings of these variables, (e.g. \u201cfrontal sector\u201d) that are much more significant and relevant for the behavior. As a result, it is necessary to use a model that is capable of grouping low-level variables, thus reducing the dimensionality of the problem and providing meaningful descriptions. The model should provide propositions that are able to summarize the data with expressions like \u201cpart of the distances in the frontal sector are high\u201d. This kind of expressions can model the underlying knowledge in a better way than just using average, maximum or minimum values of sets of low level variables. Moreover, these expressions also include the definition of the set of low-level variables to be used. Since these propositions involve fuzzy quantifiers (e.g. \u201cpart\u201d), they are called Quantified Fuzzy\nPreprint submitted to Applied Soft Computing November 17, 2014\nar X\niv :1\n41 1.\n38 95\nv1 [\ncs .R\nO ]\n1 4\nN ov\n2 01\n4\nPropositions (QFPs) [1]. QFP provide a formal model that is capable of modeling the knowledge involved in this grouping task.\nEvolutionary algorithms have some characteristics that make them suitable for learning fuzzy rules. The well-known combination of evolutionary algorithms and fuzzy logic (genetic fuzzy systems) is one of the approaches that aims to manage the balance between accuracy and interpretability of the rules [2, 3]. As it was pointed out before, fuzzy rules can be composed of both conventional and QFPs (therefore, they will be referred to as QFRs). Furthermore, the transformation from low-level to high-level variables using QFPs produces a variable number of propositions in the antecedent of the rules. Therefore, genetic programming, where the structure of individuals is a tree of variable size derived from a context-free grammar, is here the most appropriate choice.\nThis paper describes an algorithm that is able to learn QFRs of variable structure for the design of controllers with embedded preprocessing in mobile robotics. This proposal, called Iterative Quantified Fuzzy Rule Learning (IQFRL), is based on the Iterative Rule Learning (IRL) approach and uses linguistic labels defined with unconstrained multiple granularity, i.e. without limiting the granularity levels. This proposal has been designed to solve control (regression) problems in mobile robotics having as input variables the internal state of the robot and the sensors data. Expert knowledge is only used to generate the training data for each of the situations of the task to be learned and, also, to define the context-free grammar that specifies the structure of the rules.\nThe main contributions of the paper are: (i) the proposed algorithm is able to learn using the state of the robot and the sensors data, with no preprocessing. Instead, the mapping between low-level variables and high-level variables is done embedded in the algorithm; (ii) the algorithm uses QFPs, a model able to summarize the low-level input data; (iii) moreover, IQFRL uses linguistic labels with unconstrained multiple granularity. With this approach, the interpretability of the membership functions used in the resulting rules is unaffected while the flexibility of representation remains. The proposal was validated in several simulated and real environments with the wall-following behavior. Results show a better and statistically significant performance of IQFRL over several combinations of well-known learning algorithms and preprocessing techniques. The approach was also tested in three real world behaviors that were built as a combination of controllers: path tracking with obstacles avoidance, object tracking with fixed obstacles avoidance, and object tracking with moving obstacle avoidance.\nThe paper is structured as follows: Section 2 summarizes recent work related with this proposal and Section 3 presents the QFRs model and its advantages in mobile robotics. Section 4 describes the IQFRL algorithm that has been used to learn the QFRs. Section 5 presents the obtained results, and Section 6 shows three real world applications of IQFRL in robotics. Finally, Section 7 points out the most relevant conclusions."}, {"heading": "2. Related Work", "text": "The learning of controllers for autonomous robots has been dealt with by using different machine learning techniques. Among the most popular approaches can be found evolutionary algorithms [4, 5], neural networks [6] and reinforcement learning [7, 8]. Also hibridations of them, like evolutionary neural networks [9], reinforcement learning with evolutionary algorithms [10, 11], the widely used genetic fuzzy systems [12, 13, 14, 15, 16, 17, 18], or even more uncommon combinations like ant colony optimization with reinforcement learning [19] or differential evolution [20] or evolutionary group based particle swarm optimization [21] have been successfully applied. Furthermore, over the last few years, mobile robotic controllers have been getting some attention as a test case for the automatic design of type-2 fuzzy logic controllers [8, 5, 20].\nAn extensive use of expert knowledge is made in all of these approaches. In [12] 360 laser sensor beams are used as input data, and are heuristically combined into 8 sectors as inputs to the learning algorithm. On the other hand, in [9, 13, 14, 15, 16, 18, 19, 21] the input variables of the learning algorithm are defined by an expert. Moreover, in [13, 14, 16, 18, 20] the evaluation function of the evolutionary algorithm must be defined by an expert for each particular behavior. As in the latter case, the reinforcement learning approaches need the definition of an appropriate reward function using expert knowledge.\nThe approaches based on genetic fuzzy systems use different alternatives in the definition of the membership functions. In [10, 12, 16] the membership functions are defined heuristically. In [14, 15] labels have been uniformly distributed, but the granularity of each input variable is defined using expert knowledge. On the other hand, in [13, 17, 18, 19, 21] an approximative approach is used, i.e., different membership functions are learned for each rule, reducing the interpretability of the learned controller.\nThe main problem of learning behaviors using raw sensor input data is the curse of dimensionality. In [7], this issue has been managed from the reinforcement learning perspective, by using a probability density estimation of the joint space of states. Among all the approaches based on evolutionary algorithms, only in [4] no expert knowledge has been taken into account. In this work, the number of sensors and their position are learned from a reduced number of sensors.\nIn [22] a Genetic Cooperative-Competitive Learning (GCCL) approach was presented. The proposal learns knowledge bases without preprocessing raw data, but the rules involved approximative labels while the IQFRL proposal uses unconstrained multiple granularity. Moreover, in this approach it is difficult to adjust the balance between cooperation and competition, which is typical when learning rules in GCCL. As a result, the obtained rules where quite specific and the performance of the behavior was not comparable to other proposals based on expert knowledge."}, {"heading": "3. Quantified Fuzzy Rules (QFRs)", "text": ""}, {"heading": "3.1. QFRs for robotics", "text": "Machine learning techniques in mobile robotics are used to obtain the mapping from inputs to outputs (control commands). In general, two categories can be established for the input variables:\n\u2022 High-level input variables: variables that provide, by themselves, information that is relevant and meaningful to the expert for modeling the system (e.g. the linear velocity of the robot, or the right-hand distance from the robot to a wall).\n\u2022 Low-level input variables: variables that do not provide by themselves information for the expert to model the system (e.g. a single distance measure provided by a sensor). Relevance of these variables emerge when they are grouped into more significant sets of variables. For example, the control actions cannot be decided by simply analyzing the individual distance values provided by each beam of a laser range finder, since noisy measurements or gaps between objects (very frequent in cluttered environments) may occur. Instead, more significant variables and models involving complex groupings and structures are used.\nUsually, high-level variables, or sectors, consisting of a set of laser beam measures instead of the beam measures themselves (e.g., right distance, frontal distance, etc.) are used in mobile robotics. The low-level input variables are transformed into high-level input variables in a preprocessing stage previous to the learning of the controller. Traditionally, this transformation and the resulting high-level input variables are defined using expert knowledge. Doing this preprocessing automatically during the learning phase demands a model that groups the low-level input variables in an expressive and meaningful way. Within this context Quantified Fuzzy Propositions (QFPs) such as \u201cpart of the distances of the frontal sector are low\u201d are useful for representing relevant knowledge for the experts and therefore for performing intelligent control. Modeling with QFPs as in the previous example demands the definition of several elements:\n\u2022 part: how many distances of the frontal sector must be low?\n\u2022 frontal sector: which beams belong to the frontal sector?\n\u2022 low: what is the actual semantics of low?\nThis example clearly sets out the need to use propositions that are different from the conventional ones. The use of QFPs in robotics eliminates the need of expert knowledge in two ways: i) the preprocessing of the low-level variables can be embedded in the learning stage; ii) the definition of the high-level variables obtained from low-level variables is done automatically, also during the learning stage. In this paper QFPs are used for representing knowledge about high-level\nvariables that are defined as the grouping of low-level variables. Conventional fuzzy propositions are also used to represent conventional high-level variables, i.e., high-level variables not related to low-level ones (e.g. velocity)."}, {"heading": "3.2. QFRs model", "text": "An example of a QFR is shown in Fig. 1, involving both QFPs (1) and conventional ones (2); the outputs of the rule are also fuzzy sets. In order to determine the degree to which the output of the rule will be applied, it is necessary to reason about the propositions (using, for example, the Mamdani\u2019s reasoning scheme).\nThe general expression for QFPs in this case is:\nd (h) is F id in Q i of F ib (3)\nwhere, for each i=1, ..., gmaxb (g max b being the maximum possible number of sectors of distances):\n\u2022 d (h) is the signal. In this example, it represents the distance measured by beam h.\n\u2022 F id is a linguistic value for variable d (h) (e.g., \u201clow\u201d).\n\u2022 Qi is a (spatial, defined in the laser beam domain) fuzzy quantifier (e.g., \u201cpart\u201d).\n\u2022 F ib is a fuzzy set in the laser beam domain (e.g., the \u201cfrontal sector\u201d).\nEvaluation of the Degree of Fulfillment (DOF) for QFP (Eq. 3) is carried out using Zadeh\u2019s quantification model for proportional quantifiers (such as \u201cmost of\u201d, \u201cpart of\u201d, ...) [23]. This model allows to consider non-persistence, partial persistence and total persistence situations for the event \u201cd (h) is F id\u201d in the range of laser beams (spatial interval F i b). Therefore, for the considered example, it is possible to make a total or partial assessment on how many distances should be low, in order to decide the corresponding control action. This is a relevant feature of this model, since it allows to consider partial, single or total fulfillment of an event within the laser beams set.\nThe number of analyzed sectors of distances and their definition may vary for each of the rules. There can be very generic rules that only need to evaluate a single sector consisting of many laser beams, while other rules may need a finer granularity, with more specific laser sectors. Moreover, the rules may require a mix of QFPs and standard fuzzy\npropositions (for conventional high-level variables). Therefore, the automatic learning of QFRs demands an algorithm with the capability of managing rules with different structures."}, {"heading": "4. Iterative Quantified Fuzzy Rule Learning of Controllers", "text": ""}, {"heading": "4.1. Evolutionary learning of Knowledge Bases", "text": "Evolutionary learning methods follow two approaches in order to encode rules within a population of individuals [3, 24]:\n\u2022 Pittsburgh approach: each individual represents the entire rule base.\n\u2022 Michigan, IRL [25], and GCCL [26]: each individual codifies a rule. The learned rule base is the result of combining several individuals. The way in which the individuals interact during the learning process defines these three different approaches.\nThe discussion is focused on those approaches for which an individual represents a rule, discarding the Michigan approach as it is used in reinforcement learning problems in which the reward from the environment needs to be maximized [27]. Therefore, the IRL and GCCL approaches are analyzed.\nIn the IRL approach, the individuals compete among them but only a single rule is learned for each run (epoch) of the evolutionary algorithm. After each sequence of iterations, the best rule is selected and added to the final rule base. The selected rule must be penalized in order to induce niche formation in the search space. A common way to penalize the obtained rules is to delete the training examples that have been covered by the set of rules in the final rule base. The final step of the IRL approach is to check whether the obtained set of rules is a complete knowledge base. In the case it is not, the process is repeated. A weak point of this approach is that the cooperation among rules is not taken into account when a rule is evaluated. For example, a new rule could be added to the final rule base, deteriorating the behavior of the whole rule base over a set of examples that were already covered. The cooperation among rules can be improved with a posterior rules selection process.\nIn the GCCL approach the entire population codifies the rule base. That is, rules evolve together but competing among them to obtain the higher fitness. For this type of algorithm it is fundamental to include a mechanism to maintain the diversity of the population (niche induction). This mechanism must warrant that individuals of the same niche compete among themselves, but also has to avoid deleting those weak individuals that occupy a niche that remains uncovered. This is usually done using token competition [24].\nAlthough GCCL works well for classification problems [1], the same does not occur for regression problems [22], mostly due to the difficulty of achieving in this realm an adequate balance between cooperation and competition. It is frequent in regression that an individual tries to capture examples seized by other individual, improving the performance on many of the examples, but decreasing the accuracy on a few ones. In subsequent iterations, new and more specific individuals\nreplace the rule that was weakened. As a result, the individuals improve their individual fitness, but the performance of the knowledge base does not increase. In particular, for mobile robotics, the obtained knowledge bases over-fit the training data due to a polarization effect of the rule base: few very general rules and many very specific rules. Moreover, many times, the errors of the individual rules compensate each other, generating a good output of the rule base over the training data, but not on test data.\nThis proposal, called IQFRL (Iterative Quantified Fuzzy Rule Learning), is based on IRL. The learning process is divided into epochs (set of iterations), and at the end of each epoch a new QFR (Sec. 3.2) is obtained. The following sections describe each of the stages of the algorithm (Fig. 2)."}, {"heading": "4.2. Examples and Grammar", "text": "The learning process is based on a set of training examples. In mobile robotics, each example can be composed of several variables that define the state of the robot (position, orientation, linear and angular velocity, etc.), and the data measured by the sensors. If the robot is equipped with laser range finders, the sensors data are vectors of distances. A laser range finder provides the distances to the closest obstacle in each direction (Fig. 3) with a given angular resolution (number of degrees between two consecutive beams). In this paper, each example el is represented by a tuple:\nel = (d (1) , . . . , d (Nb) , velocity, vlin, vang) (4)\nwhere d (h) is the distance measured by beam h, Nb is the number of beams (e.g. 722 for a robot equipped with two Sick LMS200 laser range scanners as in Fig. 3), velocity is the measured linear velocity of the robot, and vlin and vang are the\noutput variables (control commands for the linear and angular velocities respectively).\nThe individuals in the population include both conventional propositions and QFPs (Sec. 3.2). Also, the number of relevant inputs can be different. Therefore, genetic programming is the most appropriate approach, as each individual is a tree of variable size. In order to generate valid individuals of the population, and to produce right structures for the individuals after crossover and mutation, some constraints have to be added. With a context-free grammar all the valid structures of a tree (genotype) in the population can be defined in a compact form. A context-free grammar is a quadruple (V, \u03a3, P, S), where V is a finite set of variables, \u03a3 is a finite set of terminal symbols, P is a finite set of rules or productions, and S the start symbol.\nThe basic grammar is described in Fig. 4. As usual, different productions for the same variable are separated by symbol \u201c|\u201d. Fig. 5 represents a typical chromosome generated with this context-free grammar. Terminal symbols (leaves of the tree) are represented by ellipses, and variables as rectangles. There are two different types of antecedents:\n\u2022 The sector antecedent. Consecutive beams are grouped into sectors in order to generate more general (high-level) variables (frontal distance, right distance, etc.). This type of antecedent is defined by the terminal symbols Fd, Fb and Q: i) the linguistic label Fd represents the measured distances (HIGH in Fig. 1, prop. 1); ii) Fb is the linguistic label that defines the sector, i.e., which beams belong to the sector (FRONT AL S ECTOR in Fig. 1, prop. 1); iii) Q is the quantifier (part in Fig. 1, prop. 1).\n\u2022 The measured linear velocity of the antecedent is defined by the Fv linguistic label.\nFinally, Flv and Fav are the linguistic labels of the linear and angular velocity control commands respectively, which are the consequents of the rule.\nThe linguistic labels of the antecedent (Fv, Fd, Fb) are defined using a multiple granularity approach. The universe of discourse of a variable is divided into a different number of equally spaced labels for each granularity. Specifically, a granularity givar divides the variable var in i uniformly spaced\nlabels, i.e., Aivar = {Ai, 1var , ..., Ai, ivar}. Fig. 6 shows a partitioning of up to granularity five. On the other hand, the linguistic labels of the consequents (Flv, Fav) are defined using a single granularity approach1.\n1Multiple granularity makes no sense if the labels are defined as singletons, which is the usual choice for the output variables in control applications.\nRequire: maskvar 1: i := g1var 2: result := \u2205 3: loop 4: for all j \u2208 [1, i] do 5: if support(maskvar) \u2265 support(Ai, jvar) then 6: if similarity(maskvar, Ai, jvar) >"}, {"heading": "4.3. Initialization", "text": "An individual (Fig. 5) is generated for each example in the training set. The consequent part (Flv and Fav) is initialized as Fvar = A gvar , \u03b2 var where \u03b2 = argmax j \u00b5 gvar , j var ( el ) , i.e., the label with the largest membership value for the example. The initialization of the antecedent part of a rule requires obtaining the most similar linguistic label to a given fuzzy membership function (which is called mask label). As the maximum granularity of the linguistic labels in the antecedent part of a rule is not limited, the function maskToLabel (Fig. 7) is applied to obtain the most appropriate linguistic label. This function uses a similarity measure defined as [28]:\nsimilarity(F\u03c6, F\u03c8) = 1 \u2212 \u2211\nx\u2208X |\u00b5\u03c6(x) \u2212 \u00b5\u03c8(x)| |X| (5)\nwhere F\u03c6 and F\u03c8 are the labels being compared and X is a finite set of points x uniformly distributed on the support of \u03c6 \u222a \u03c8.\nThe maskToLabel function (Fig. 7) receives a triangular membership function (maskvar) and searches for the label A i, j var with the highest similarity (Eq. 5, line 6) with less or equal support (line 5), starting from g1var (line 1).\nFor the initialization of the quantified propositions (sectors), the distances measured in the example are divided into groups of consecutive laser beams whose deviation does not exceed a certain threshold (\u03c3bd). Each group represents a sector that is going to be included in the individual. Afterwards, for each of the previously obtained sectors, the components (Fb, Fd and Q) are calculated:\n1. Fb = maskToLabel(maskb), with maskb = (leftb, centerb, rightb) where leftb is the lower beam of the group, rightb is the higher beam, centerb is the middle beam and the following properties are satisfied: \u00b5(leftb) = \u00b5(rightb) = 0.5 and \u00b5(centerb) = 1 as shown in Fig. 8(a). 2. Fd = maskToLabel(maskd), with maskd = (d\u0304 \u2212 \u03c3d, d\u0304, d\u0304 + \u03c3d) where d\u0304 is the mean of the distances\nmeasured by the beams of the group, \u03c3d is the standard deviation of these distances and the following properties are satisfied: \u00b5(d\u0304 \u2212 \u03c3d) = \u00b5(d\u0304 + \u03c3d) = 0.5 and \u00b5(d\u0304) = 1 as shown in Fig. 8(b).\n3. Q (Fig. 9) is calculated as the percentage of beams of the sector (h \u2208 Fb) that fulfill Fd:\nQ = \u2211 h\u2208Fb min ( \u00b5Fd (d(h)), \u00b5Fb (h) )\u2211 h\u2208Fb \u00b5Fb (h)\n(6)\nFinally, the velocity antecedent Fv is initialized as Fv = A giv, \u03b2 v where \u03b2 = argmax j \u00b5 giv, j v (el) and giv is the granularity that satisfies that two consecutive linguistic labels have a separation of \u03c3v, where \u03c3v is a threshold of the velocity deviation."}, {"heading": "4.4. Evaluation", "text": "The fitness of an individual of the population is calculated as follows. Firstly, it is necessary to estimate the probability that an example el matches the output (C j) associated to the j-th individual rule:\nP ( C j | el ) = exp \u2212 errorljME  (7)\nwhere ME is a parameter that defines the meaningful error and errorlj is the difference between output C j and the output codified in the example:\nerrorlj = \u2211\nk\n ylk \u2212 c j, kmaxk \u2212 mink 2 (8)\nwhere ylk is the value of the k-th output variable of example el, c j, k is the output of the k-th output variable associated to individual j, and maxk and mink are the maximum and minimum values of output variable k. In regression problems, there can be several consequents that are different from the one\ncodified in the example, but that produce small errors, i.e., that are very similar to the desired output. Thus, P ( C j | el ) can be interpreted as a normal distribution with covariance ME, and errorlj is the square of the difference between the mean (output codified in the example) and the output value proposed in the rule codified by the individual.\nIn an IRL approach, C j = CR j , i.e., the output coded in individual j is the output associated to rule j. The fitness of an individual in the population is calculated as the combination of two values. On one hand, the accuracy with which the individual covers the examples, called confidence. On the other hand, the ability of generalization of the rule, called support. The confidence can be defined as:\nconfidence = \u03c1u\u2211\nl DOF j(elu) (9)\nwhere DOF j(elu) is the degree of fulfillment of e l u for rule j, and elu \u2208 uncovex, where uncovex is defined as:\nuncovex = {el : DOFKBcur (el) < DOFmin} (10)\ni.e., the set of examples that are covered with a degree of fulfillment below DOFmin by the current final knowledge base (KBcur) (line 19, Fig. 2), and \u03c1u can be defined as:\n\u03c1u = \u2211\nl\nDOF j(elu) : P ( C j | elu ) > Pmin\nand DOF j(elu) > DOFmin (11)\nwhere Pmin is the minimum admissible accuracy. Therefore, the higher the accuracy over the examples covered by the rule (and not covered yet by the current knowledge base), the higher the confidence. Support is calculated as:\nsupport = \u03c1u\n#uncovex (12)\nThus, support measures the percentage of examples that are covered with accuracy, related to the total number of uncovered examples. Finally, f itness is defined as a linear combination of both values:\nfitness = \u03b1 f \u00b7 confidence + (1 \u2212 \u03b1 f ) \u00b7 support (13)\nwhich represents the strength of an individual over the set of examples in uncovex. \u03b1 f \u2208 [0, 1] is a parameter that codifies the trade-off between accuracy and generalization of the rule."}, {"heading": "4.5. Crossover", "text": "The matching of the pairs of individuals that are going to be crossed is implemented following a probability distribution defined as:\nPclose (\u03b1, \u03b2) = 1 \u2212 \u2211Nc k=1( c\u03b1, k \u2212 c\u03b2, k maxk \u2212 mink ) 2\nNc (14)\nwhere c\u03b1, k (c\u03b2, k) is the value of the k-th output variable of individual \u03b1 (\u03b2), and Nc is the number of consequents. With this probability distribution, the algorithm selects with\nRequire: ind\u03b1, ind\u03b2 1: a\u03b1 = a\u03b2 = \u2205 2: Na = gmaxb + 1 3: repeat 4: m = random \u2208 [1, Na] 5: if m is a sector then 6: a\u03b1 = argmaxr similarity(Fb, r, A gmaxb ,m b ) \u2265 0 : \u2200r \u2208\nhigher probability mates that have similar consequents. The objective is to extract information on which propositions of the antecedent part of the rules are important, and which are not. Crossover has been designed to generate more general individuals, as the initialization of the population produces very specific rules. The crossover operator generates two offsprings:\noffspring1 = crossover(indi, ind j) offspring2 = crossover(ind j, indi) (15)\nThis operator modifies a single proposition in antecedent part of the rule. As individuals have a variable number of antecedents, the total number of propositions can be different for two individuals. Moreover, the propositions can be defined using different granularities. Therefore, the first step is to select the propositions (one for each individual) to be crossed between both individuals (Fig. 10) as follows:\n1. Get the most specific granularity of the sectors of the individuals to cross (gmaxb ). Then, an antecedent m \u2208 [1, Na] is selected, where Na is gmaxb plus one, due to the velocity proposition.\n2. Check the existence of this antecedent in both individuals, according to the following criteria:\n(a) If the antecedent m is a sector, then calculate for each proposition of each individual the similarity between the definition of the sector for the proposition and the linguistic label that defines sector m. Finally, select for each individual the proposition with the highest similarity. (b) If the antecedent m is the velocity, then the corresponding proposition is Fv (in case it exists).\nOnce the propositions to be crossed have been selected, an operation must be picked depending on the existence of the antecedent in both parents (table 1):\n\u2022 If the proposition does not exist in the first individual but exists in the second one, then the proposition of the second individual is copied to the first one, as this proposition could be meaningful.\n\u2022 If the situation is the opposite to the previous one, then the proposition of the first individual is deleted, as it might be not important.\n\u2022 If the proposition exists in both individuals, then both propositions are combined in order to obtain a proposition that generalizes both antecedents.\nIn this last case, the combination of propositions is done by taking into account the degree of similarity (Eq. 5) between them (Fig. 11). If the proposition is of type sector, the similarity takes into account both Fb and Fd labels. Only when both similarities are partial, the propositions are merged:\n\u2022 If there is no similarity, then the propositions correspond to different situations. For example, \u201cthe distance is high in part of the frontal sector\u201d and \u201cthe distance is low in part of the frontal sector\u201d. This means that the proposition of the first individual might not contain meaningful information and it could be deleted to generalize the rule. For example, both individuals have the proposition \u201cthe distance is high in part of the frontal sector\u201d.\n\u2022 If the similarity is total, then, in order to obtain a new individual with different antecedents, the proposition is eliminated.\n\u2022 Finally, if the similarity is partial, then the propositions are merged in order to obtain a new one that combines the information provided by the two original propositions. For example, \u201cthe distance is high in part of the frontal sector\u201c and \u201cthe distance is medium-high in part of the frontal sector\u201c. Therefore, the individual is generalized. The merge action is defined as the process of finding the label with the highest possible granularity that has some similarity with the labels of both original propositions. This is done for both Fb and Fd labels. Q is calculated as the minimum Q of both individuals."}, {"heading": "4.6. Mutation", "text": "If crossover is not performed, both individuals are mutated. Mutation implements two different strategies (Fig. 12): generalize or specialize a rule. The higher the value of confidence (Eq. 9), the higher the probability to generalize the rule by mutation. This occurs with rules that cover their examples with high accuracy and that could be modified to cover other examples. On the contrary, when the confidence of the individual is low, this means that it is covering some of its examples with a low performance. In order to improve the rule some of the examples that are currently covered should be discarded in order to get a more specific rule.\nFor generalization, the following steps are performed:\n1. Select an example esel \u2208 uncov jex, where uncov jex = {elu : DOF j(elu) < DOFmin}, i.e. the set of examples that belong to uncovex and are not covered by individual j. The example is selected with a probability distribution given by P ( C j | elu ) (Eq. 7). The higher the similarity between\nthe output of the example and the consequent of rule j, the higher the probability of being selected. 2. The individual is modified in order to cover esel. Therefore, all the propositions that are not covering the example (those with \u00b5prop ( esel ) < DOFmin) are selected\nfor mutation. (a) For sector propositions (Eq. 1), there are three\ndifferent ways in which the proposition can be modified: Fd, Fb, and Q. The modification is selected among the three possibilities, with a probability proportional to the \u00b5prop ( esel ) value after applying each one. i. Fd and Fb are generalized choosing the most\nsimilar label in the adjacent partition with lower granularity. The process is repeated until \u00b5prop ( esel ) \u2265 DOFmin. ii. On the other hand, Q is decreased until \u00b5prop ( esel ) \u2265 DOFmin.\n(b) For velocity propositions (Eq. 2), generalization is done choosing the most similar label in the adjacent partition with lower granularity until \u00b5prop ( esel ) >\nDOFmin.\nFor specialization, the process is equivalent:\n1. Select an example esel \u2208 cov jex, where cov jex = {elu : DOF j(elu) > DOFmin}, i.e. the set of examples that belong to uncovex and are covered by individual j. The example is selected with a probability distribution that is inversely proportional to P ( C j | elu ) (Eq. 7). The higher\nthe similarity between the output of the example and the consequent of rule j, the lower the probability of being selected.\n2. Only one proposition needs to be modified to specialize the individual. This proposition is selected randomly.\n(a) For sector propositions there are, again, three different ways in which the proposition can be modified: Fd, Fb, and Q. The modification\nis selected among these three possibilities, with a probability that is inversely proportional to the \u00b5prop ( esel ) value after applying each one.\ni. Fd and Fb are specialized, choosing the most similar label in the adjacent partition with higher granularity. The process is repeated until \u00b5prop ( esel ) < DOFmin.\nii. On the other hand, Q is increased until \u00b5prop ( esel ) < DOFmin.\n(b) For velocity propositions, specialization is done by choosing the most similar label in the adjacent partition with higher granularity until \u00b5prop ( esel ) <\nDOFmin.\nFinally, once the antecedent is mutated, the consequent also mutates. Again, this mutation requires the selection of an example. If generalization was selected for the mutation of the antecedent, then the example will be esel. On the other hand, for specialization an example is randomly selected from those currently in cov jex. For each variable in the consequent part of the rule, the label of the individual is modified selecting a label following a probability distribution (Fig. 13):\nP ( Agvar , \u03b3var | Agvar , \u03b1var , Agvar , \u03b2var ) = 1 \u2212 |\u03b1 \u2212 \u03b3||\u03b1 \u2212 \u03b2| + 1 (16)\nwhere Agvar , \u03b1var is the label of each of the consequents of the individual, Agvar , \u03b2var is the label with the largest membership value for esel and Agvar , \u03b3var is a label between them. Thus, the labels closer to the label of the individual have a higher probability to be selected, while the labels closer to the example label have a lower one."}, {"heading": "4.7. Selection and replacement", "text": "Selection has been implemented following the binary tournament strategy. Replacement follows an steady-state approach. The new individuals and those of the previous population are joined, and the best popmax individuals are selected for the next population."}, {"heading": "4.8. Epoch loop", "text": "An epoch is a set of iterations at the end of which a new rule is added to KBcur. The stopping criterion of each epoch (inner loop in Fig. 2) is the number of iterations, but this limit varies according to the following criteria: once the number of iterations (it) reaches itmin, the algorithm stops if there are itcheck consecutive iterations (counted by equalind) with no change in the best individual (bestind). If the number of iterations reaches the maximum (itmax), then the algorithm stops regardless of the previous condition.\nWhen the epoch ends, the rule defined in bestind is added to KBcur. Moreover, the examples that are covered with accuracy (according to the criterion in Eq. 11) are marked as covered by the algorithm (line 20, Fig. 2). Finally, the algorithm stops when there are no uncovered examples."}, {"heading": "4.9. Rule subset selection", "text": "After the end of the iterative part of the algorithm, the performance of the obtained rule base can be improved selecting a subset of rules with better cooperation among them. The rule selection algorithm described in [1] has been used. The rule selection process has the following steps:\n1. Generate #Rgp rule bases, where #Rgp is the number of rules of the population obtained by the IQFRL algorithm (RBgp) Each rule base is coded as: RBi = ri1 \u00b7 \u00b7 \u00b7 ri#Rgp , with:\nrij = 0, i f j > i1, i f j \u2264 i (17) where rij indicates if the j-th rule of RBgp is included (rij = 1) or not (r i j = 0) in RBi. With this codification, RBi will contain the best i rules of RBgp, as these rules have been ranked in decreasing order of their individual fitness. Notice that RB#Rgp is RBgp 2. Evaluate all the rule bases, and select the best one, RBsel. 3. Execute a local search on RBsel to obtain the best rule set,\nRBbest.\nThe last step was implemented with the iterated local search (ILS) algorithm [29].\nthreshold (maxRestarts)."}, {"heading": "5. Results", "text": ""}, {"heading": "5.1. Experimental setup", "text": "The proposed algorithm has been validated with the well-known in mobile robotics wall-following behavior. The main objectives of a controller for this behavior are: to keep\na suitable distance between the robot and the wall, to move at the highest possible velocity, and to implement smooth control actions. The Player/Stage robot software [30] has been used for the tests on the simulated environments and also for the connection with the real robot Pioneer 3-AT (Fig. 14). This real robot was equipped with two laser range scanners with an amplitude of 180\u25e6 and a precision of 0.5\u25e6 (i.e. 361 measurements for each laser scan). Without loss of generality, all the examples and tests here described were made with the robot following the wall at its right.\nThe examples that have been used for learning were generated for three different situations (Fig. 15) that have been identified by an expert:\n1. Convex corner: it is characterized by the existence of a gap in the wall (like an open door) (labeled CX in Fig. 15). 2. Concave corner: it is a situation in which the robot finds a wall in front of it (labeled CC in Fig. 15). 3. Straight wall: any other situation (labeled SW in Fig. 15).\nFor each of the above situations, the robot was placed in different positions and the associated control order was the one that minimized the error. Therefore, each example consists of 722 distances (one for each laser beam), the current linear velocity of the robot, and the control commands (linear and angular velocity). The expert always tried to follow the wall at, approximately, 50 cm and the maximum values for the linear and angular velocities were 50 cm/s and 45os\u22121 respectively. 572 training examples were generated for the straight wall situation, 540 for the convex corner and 594 for the concave corner.\nThe IQFRL algorithm was used to learn a different controller for each of the three situations. In order to decide which\nknowledge base should be used at each time instant, the classification version of IQFRL (IQFRL-C, see Appendix A) was used. In this way, IQFRL learning could be tested with three completely different controllers.\nIn order to analyze the performance of the proposed learning algorithm, several tests were done in 15 simulated environments and two real ones. Table 2 shows some of the characteristics of the environments: the dimensions of the environment, the path length, the number of concave (#CC) and convex (#CX) corners, and the number of times that the robot has to cross a door (#doors). The action of crossing a door represents a high difficulty as the robot has to negotiate a convex corner with a very close wall in front of it.\nThe simulated environments are shown in Figs. 16 and 17. The trace of the robot is represented by marks, and the higher the concentration of marks, the lower the velocity of the robot. Furthermore, Fig. 18 shows the real environments. Each of them represents an occupancy grid map of the environment, together with the trajectory of the robot."}, {"heading": "5.2. Algorithms and parameters", "text": "The following values were used for the parameters of the evolutionary algorithm: ME = 0.02, DOFmin = 0.001, \u03b1 f = 0.99, Pcross = 0.8, popmax = 70, itmin = 50, itcheck = 10, itmax = 100, \u03c3bd = 0.01, \u03c3v = 0.1 and Pmin = 0.17. Pmin is a parameter that has a high influence in the performance of the system. A single value of Pmin was used in testing, obtained from Eqs. 7 and 8 for the case the error for each consequent is one label (Eq. 8). The granularities and the universe of discourse of each output of a rule are shown in table 3. For the rule subset selection algorithm, the parameters have values of radiusnbhood = 1 and maxRestarts = 2.\nThe fuzzy inference system used for the learned fuzzy rule sets uses the minimum t-norm for both the implication and conjunction operators, and the weighted average method as defuzzification operator.\nThe IQFRL approach was compared with three different algorithms:\nbase.\nThe soft-constrained MOGUL was used, as it has better performance in very hard problems [25]2.\n\u2022 Multilayer Perceptron Neural Network (MPNN): a single-hidden-layer neural network trained with the BFGS method [33] with the following parameters: abstol = 0.01, reltol = 0.0001 and maxit = 500. The number of neurons in the hidden layer varies from n to 2\u00b7n, being n the number of inputs3.\n\u2022 \u03bd-Support Vector Regression (\u03bd-SVR)4: a \u03bd-SVM [36] version for regression with a Gaussian RBF kernel. The parameter sigma is estimated based upon the 0.1 and 0.9 quantile of ||x \u2212 x\u2032||2.\n2The implementation in Keel [32], an open source (GPLv3) Java software tool to assess evolutionary algorithms for Data Mining problems, was used.\n3The package nnet [34] of the statistical software R was used. 4The package kernlab [35] of the statistical software R was used.\nAs mentioned before, in the IQFRL proposal the preprocessing of raw sensor data is embedded in the learning algorithm. Since the algorithms for the comparison need to preprocess the data before the learning phase, three different approaches were used for the transformation of the sensor data:\n\u2022 Min: the beams of the laser range finder are grouped in n equal sized sectors. For each sector, the minimum distance value is selected as input.\n\u2022 Sample: n equidistant beams are selected as the input data.\n\u2022 PCA: Principal Component Analysis computes the most meaningful basis to re-express the data. It is a simple, non-parametric method for extracting relevant information. The variances associated with the principal components can be examined in order to select only those that cover a percentage of the total variance.\nDifferent parameters have been used for the preprocessing approaches. For Min and Sample methods, the number of obtained inputs (n) was changed. For PCA, the percentage of variance (\u03c3PCA) indicates the principal components selected as input data. Table 4 shows the parameters used for the preprocessing methods. Moreover, table 5 shows the number of inputs obtained with PCA for the three datasets with each configuration."}, {"heading": "5.3. Comparison and statistical significance", "text": "Table 6 shows the training and test errors over a 5-fold cross-validation. For each algorithm and dataset the mean and standard deviation of the error (Eq. 8) were calculated.\nFor each preprocessing technique, a 5-fold cross-validation was performed for each combination of the parameters of the algorithms. For example, for the Min preprocessing with 16 equal size sectors, a 5-fold cross-validation was run for each number of neurons between 17 and 34 for the MPNN approach. Only the configuration of the algorithm with lowest test error for each configuration of the preprocessing methods was used for comparison purposes. Moreover, only those configurations of preprocessing techniques with the best results are shown in the tables of this section. Results for PCA preprocessing have\nnot been included, as the learning algorithms were not able to obtain adequate controllers.\nAlthough, the MSE (Mean Squared Error) is the usual measure of the performance of the algorithms, this is not a sufficient criterion in mobile robotics. A good controller must be robust and able to provide a good and smooth output in any situation. The only way to validate the controller is to test it on environments (simulated and real) with different difficulties and assessing on these tests a number of quality parameters such as mean distance to the wall, mean velocity along the paths, . . .\nTable 8 contains the results of the execution of each of the algorithms for the different simulated environments (Figs. 16 and 17). Furthermore, table 9 shows the average results for the following five different indicators: the distance to the wall at its right (Dist.), the linear velocity (Vel.), the change in the linear velocity between two consecutive cycles (Vel.ch.) \u2014which reflects the smoothness in the control\u2014, the time per lap, and the number of blockades of the robot along the path and cannot recover.\nThe robot is blocked if it hits a wall or if it does not move for 5 s. In this situation the robot is placed parallel to the wall at a distance of 0.5 m. The average values of the five indicators are calculated for each lap that the robot performs in the environment. Results presented in the table are the average and standard deviation values over five laps of the average values of the indicators over one lap. The dash symbol in the results table indicates that the controller could not complete the path. This usually occurs when the number of blockades per meter is high (greater than 5 blockades in a short period of time) or when the robot completely deviates from the path.\nMoreover, in order to evaluate the performance of a controller with a numerical value a general quality measure was defined. It is based on the error measure defined in [15], but\nincluding the number of blockades:\nquality = 1\n1 + (1 + #Blockades) \u00b7 (0.9 \u00b7 |Dist \u2212 dwall | + 0.1 \u00b7 |Vel \u2212 vmax |) (18)\nwhere dwall is the reference distance to the wall (50 cm) and vmax is the maximum value of the velocity (50 cm/s). The higher the quality, the better the controller. This measure takes the number of blockades into account in a linear form for comparison purposes. However, it should be noted that controllers with just a single blockade are not reliable and should not be implemented on a real robot.\nIn general, all the algorithms except MPNN with Sample 16 preprocessing, produced a distance that is very close to the reference (between 40 cm and 60 cm to the wall at its right). Note that in cases where the best distance is very different from that obtained by IQFRL, this is because several blockades happened. Therefore, those controllers have the advantage of being continually repositioned into the perfect situation. The best results in speed are those obtained by \u03bd-SVR and MOGUL but, in general, due to a worsening in the distance to the wall or an increase in the number of blockades. The same applies to the speed change. In those cases where it is too low, like in some cases for MOGUL or MPNN, the robot is not able to trace some curves safely. IQFRL is the approach that gets the best quality values, reflecting not only the adequate values for the distance, velocity and smoothness in all the environments but, also, its robustness: it is the unique approach that never blocked or failed to complete the laps in any of the environments.\nIn order to compare the experimental results, non-parametric tests of multiple comparisons have been used. Their use is recommended in those cases in which the objective is to compare the results of a new algorithm against various methods simultaneously. The Friedman test with Holm post-hoc test was selected as the method for detecting significant differences among the results. The test is performed for the quality indicator in table 8.\nThe statistical test (table 7) shows that the difference of the quality of the IQFRL approach is statistically significant. Only \u03bd-SVR and MOGUL with sample 16 preprocessing are comparable to IQFRL, as the number of blockades is very low or null in some environments.\nAdditionally, table 10 shows the results obtained by IQFRL in two real environments. As in the previous tables, the results are the average and standard deviation over 5 laps. The distance\nto the wall is lower than 60 cm, showing a good behavior, although the velocity seems to be low, this is because corners are very close to each other and the robot does not have time to accelerate. Also, the velocity change reflects a very smooth movement as changes in velocity take more time in the real robot.\nFinally, the IQFRL proposal was compared with the proposals presented in [15] for learning rules for the wall-following behavior. The purpose of this comparison is to check if IQFRL is competitive against other methods which use expert knowledge for sensor data preprocessing. Four different approaches were used: the COR methodology, the weighted COR methodology (WCOR), Hierarchical Systems of Weighted Linguistic Rules (HSWLR) and a local evolutionary learning of Takagi-Sugeno rules (TSK). For these approaches, four input variables were defined by an expert: right distance, left distance, velocity, and the orientation (alignment) of the robot to the wall at its right. Moreover, the granularities of each variable were also defined by the expert. Table 12 presents the comparison between these approaches and the IQFRL proposal on those environments which are common.\nThe IQFRL approach exhibited the highest quality in the two most complex environments (office and hospital). Moreover, table 11 shows the non-parametric tests performed over quality. The Friedman p-value is higher than in table 9, due to the low number of environments available for comparisons. As can be seen, there is no statistically significant difference regarding the quality. That is, the controllers learned with embedded preprocessing has similar performance to the methods that use expert knowledge to preprocess the data."}, {"heading": "5.4. Complexity of the Rules", "text": "An example of a rule learned by IQFRL is presented in Fig. 19. The antecedent part is composed of a single QFP. The linguistic value A5, 1d indicates a low distance, while A 4, 1 b denotes that the beams sector of the proposition is formed by the frontal and right parts of the robot. Therefore, the rule describes a situation where the robot is too close to the wall and, if it continues, it will collide. Because of that, the consequent indicates a zero linear velocity and a turn of the robot to the left, in order to get away from the wall without getting the robot into risk.\nTable 13 shows the number of rules learned for the different situations by each of the methods based on rules. MOGUL is implemented as a multiple-input single-output (MISO)\nTable 10: Average results (x \u00b1 \u03c3) of IQFRL for the real environments\nEnv. Dist.(cm) Vel.(cm/s) Vel.ch.(cm/s) Time(s) # Blockades quality\nreal env 1 54.13 \u00b1 2.59 19.86 \u00b1 1.52 1.36 \u00b1 0.21 100.70 0.00 \u00b1 0.00 0.13 real env 2 59.29 \u00b1 2.74 21.94 \u00b1 1.43 1.72 \u00b1 2.50 118.50 0.00 \u00b1 0.00 0.08\nTable 12: Average results (x \u00b1 \u03c3) of IQFRL and several approaches with preprocessing based on expert knowledge [15]\nAlg. Env. Dist.(cm) Vel.(cm/s) Vel.ch.(cm/s) Time(s) # Blockades quality\nIQFRL\nwsc8a 56.96 \u00b1 1.00 27.45 \u00b1 0.84 7.70 \u00b1 0.33 233.10 \u00b1 5.28 0.00 \u00b1 0.00 0.11 rooms 57.38 \u00b1 0.34 30.97 \u00b1 0.34 6.38 \u00b1 0.43 261.93 \u00b1 4.60 0.00 \u00b1 0.00 0.10 autolab 52.91 \u00b1 0.20 28.75 \u00b1 0.31 5.57 \u00b1 0.48 499.33 \u00b1 9.74 0.00 \u00b1 0.00 0.17 office 51.37 \u00b1 0.57 24.20 \u00b1 0.18 6.65 \u00b1 0.25 578.27 \u00b1 2.92 0.00 \u00b1 0.00 0.21 hospital 51.09 \u00b1 0.19 26.68 \u00b1 0.10 6.18 \u00b1 0.35 3608.07 \u00b1 21.72 0.00 \u00b1 0.00 0.23\nCOR\nwsc8a 53.20 \u00b1 1.33 39.86 \u00b1 0.71 5.67 \u00b1 0.83 174.98 \u00b1 1.79 0.00 \u00b1 0.00 0.17 rooms 46.80 \u00b1 0.59 37.82 \u00b1 0.41 6.76 \u00b1 0.31 227.16 \u00b1 1.03 0.00 \u00b1 0.00 0.16 autolab 56.88 \u00b1 0.91 25.69 \u00b1 0.79 10.79 \u00b1 0.21 587.96 \u00b1 39.72 0.00 \u00b1 0.00 0.09 office 55.97 \u00b1 1.65 32.48 \u00b1 0.90 4.06 \u00b1 0.28 457.58 \u00b1 15.00 0.00 \u00b1 0.00 0.11 hospital 54.12 \u00b1 0.92 35.63 \u00b1 0.77 6.95 \u00b1 0.28 2864.92 \u00b1 45.27 0.00 \u00b1 0.00 0.14\nWCOR\nwsc8a 52.79 \u00b1 1.36 36.98 \u00b1 1.85 7.37 \u00b1 0.62 187.90 \u00b1 9.78 0.00 \u00b1 0.00 0.17 rooms 51.17 \u00b1 0.77 37.19 \u00b1 0.27 9.15 \u00b1 0.24 234.04 \u00b1 2.70 0.00 \u00b1 0.00 0.23 autolab 52.97 \u00b1 1.10 33.47 \u00b1 0.89 7.12 \u00b1 0.52 455.98 \u00b1 41.60 0.00 \u00b1 0.00 0.16 office 54.59 \u00b1 1.10 33.13 \u00b1 0.97 6.76 \u00b1 0.53 448.16 \u00b1 10.36 0.00 \u00b1 0.00 0.13 hospital 55.26 \u00b1 1.01 33.71 \u00b1 0.14 6.52 \u00b1 0.12 3073.98 \u00b1 23.63 0.00 \u00b1 0.00 0.12\nHSWLR wsc8a 51.42 \u00b1 0.78 30.46 \u00b1 1.01 3.36 \u00b1 0.13 222.34 \u00b1 6.09 0.00 \u00b1 0.00 0.19 rooms 50.09 \u00b1 0.88 28.71 \u00b1 0.29 3.04 \u00b1 0.20 290.70 \u00b1 3.66 0.00 \u00b1 0.00 0.24 autolab 51.50 \u00b1 0.34 23.50 \u00b1 0.97 3.05 \u00b1 0.14 618.40 \u00b1 20.98 0.00 \u00b1 0.00 0.17 office 53.43 \u00b1 1.22 24.69 \u00b1 0.66 3.73 \u00b1 0.11 594.74 \u00b1 13.16 0.00 \u00b1 0.00 0.13\nhospital 54.60 \u00b1 1.65 25.07 \u00b1 0.49 3.89 \u00b1 0.06 4209.68 \u00b1 166.14 0.00 \u00b1 0.00 0.12\nTSK\nwsc8a 51.43 \u00b1 1.36 37.54 \u00b1 1.53 5.20 \u00b1 0.50 182.54 \u00b1 8.35 0.00 \u00b1 0.00 0.22 rooms 49.07 \u00b1 1.08 37.05 \u00b1 0.82 4.96 \u00b1 0.21 227.58 \u00b1 4.46 0.00 \u00b1 0.00 0.24 autolab 51.87 \u00b1 2.99 33.05 \u00b1 1.33 4.61 \u00b1 0.11 465.56 \u00b1 15.33 0.00 \u00b1 0.00 0.19 office 53.75 \u00b1 0.97 34.26 \u00b1 0.65 5.24 \u00b1 0.22 432.38 \u00b1 10.48 0.00 \u00b1 0.00 0.14 hospital 54.50 \u00b1 1.49 34.31 \u00b1 0.32 5.01 \u00b1 0.11 3053.74 \u00b1 123.72 0.00 \u00b1 0.00 0.13\nalgorithm, therefore for each output, different rule bases were learned. Moreover, table 14 shows the complexity of the learned rules in terms of mean and standard deviation of the number of propositions and granularities for each input\nvariable.\nThe IQFRL approach is able to learn knowledge bases with a much lower number of rules than MOGUL, even though it is learning both outputs at the same time. The learning of QFRs results in a low number of propositions per rule, thus demonstrating its generalization ability, in spite of the huge input space dimensionality. Moreover, the granularities of each of the input variables are, in general, also low. Therefore, the learned knowledge bases show a low complexity without losing accuracy.\nTable 13: Number of rules learned\nAlg. Preproc. Output #Rstraight #Rconvex #Rconcave\nIQFRL \u2212 Both 108.00 \u00b1 18.88 47.80 \u00b1 16.09 40.40 \u00b1 10.65\nMOGUL\nmin 16 vlin 548.60 \u00b1 25.60 308.20 \u00b1 12.12 680.20 \u00b1 24.43 vang 547.00 \u00b1 16.37 302.80 \u00b1 21.57 712.40 \u00b1 23.79 sample 16 vlin 507.80 \u00b1 29.88 268.20 \u00b1 12.66 664.80 \u00b1 8.52 vang 530.20 \u00b1 26.48 252.80 \u00b1 8.28 709.80 \u00b1 34.19\nTable 14: Complexity of the rules\nAlg. Preproc. Dataset Output Propositions gd gb gv\nIQFRL \u2212 Straight\nBoth 2.74 \u00b1 0.94 7.02 \u00b1 10.52 5.98 \u00b1 5.62 6.21 \u00b1 1.53\nConvex 2.68 \u00b1 0.69 15.37 \u00b1 23.59 11.22 \u00b1 8.50 6.55 \u00b1 1.03 Concave 2.78 \u00b1 1.18 3.80 \u00b1 1.79 7.07 \u00b1 6.86 6.16 \u00b1 1.42\nMOGUL\nmin 16\nStraight vlin 17.00 \u00b1 0.00 24.35 \u00b1 109.80 16.00 \u00b1 0.00 39.44 \u00b1 137.45 vang 17.00 \u00b1 0.00 24.49 \u00b1 107.66 16.00 \u00b1 0.00 35.19 \u00b1 117.75 Convex vlin 17.00 \u00b1 0.00 32.34 \u00b1 125.75 16.00 \u00b1 0.00 51.68 \u00b1 172.27 vang 17.00 \u00b1 0.00 38.99 \u00b1 144.86 16.00 \u00b1 0.00 45.07 \u00b1 146.38 Concave vlin 17.00 \u00b1 0.00 22.93 \u00b1 100.76 16.00 \u00b1 0.00 32.79 \u00b1 106.77 vang 17.00 \u00b1 0.00 23.35 \u00b1 103.39 16.00 \u00b1 0.00 37.56 \u00b1 122.75\nsample 16\nStraight vlin 17.00 \u00b1 0.00 26.23 \u00b1 117.41 16.00 \u00b1 0.00 33.98 \u00b1 108.16 vang 17.00 \u00b1 0.00 26.25 \u00b1 116.18 16.00 \u00b1 0.00 37.60 \u00b1 126.86 Convex vlin 17.00 \u00b1 0.00 25.68 \u00b1 103.29 16.00 \u00b1 0.00 49.61 \u00b1 160.18 vang 17.00 \u00b1 0.00 31.06 \u00b1 119.50 16.00 \u00b1 0.00 46.56 \u00b1 151.27 Concave vlin 17.00 \u00b1 0.00 23.50 \u00b1 105.79 16.00 \u00b1 0.00 33.62 \u00b1 112.09 vang 17.00 \u00b1 0.00 23.95 \u00b1 106.27 16.00 \u00b1 0.00 34.63 \u00b1 121.52"}, {"heading": "6. Real World Applications", "text": "Two of the most used behaviors in mobile robotics are path and object tracking. In recent years several real applications of these behaviors have been described in the literature in different realms. For instance, in [37], a tour-guide robot that can either follow a predefined route or a tour-guide person was shown. With a similar goal, an intelligent hospital service robot was presented in [38]. In this case, the robot can improve the services provided in the hospital through autonomous navigation based on following a path. More recently, in [39] a team of robots that cooperate in a building developing maintenance and surveillance tasks was presented.\nMore dynamic environments were described in [40, 41], where the robot had to operate in buildings and populated urban areas. These environments introduce numerous challenges to autonomous mobile robots as they are highly complex. Finally, in [42] the authors presented a motion planner that was able to generate paths taking into account the uncertainty due to controls and measurements.\nIn these and other real applications, the robot has to deal with static and moving objects, including the presence of people surrounding the robot, etc. All these difficulties make necessary the combination of behaviors to perform tasks like path or people tracking in real environments. In order to implement these tasks in a safe way, the robot must be endowed with the ability to avoid collisions with all the objects in the environment while implementing the tasks. These behaviors are challenging tasks that allow us to show the performance of the IQFRL-based approach in realistic conditions. The following behaviors are considered in this section, in order of increasing complexity:\n1. Path tracking with obstacles avoidance. In this behavior, the mobile robot must follow a path with obstacles in it. A typical application of this behavior is a tour-guide robot that has to follow a predefined tour in a museum. Although in the initial path there were no obstacles in the trajectory, the modification of the environment with new exhibitors and the presence of people make it necessary that the robot modify the predefined route, avoiding the collision with the obstacles and returning to the predefined path as quickly as possible.\n2. Object tracking with fixed obstacles avoidance. In this case, the robot has to follow the path of a moving object while being at a reference distance to the object. For instance, a tour-guide person being followed by a robot with extended information on a screen. If the followed object comes too close to an obstacle, the robot must avoid the collision while maintaining the tracking behavior.\n3. Object tracking with moving obstacle avoidance. This behavior is a modification of the previous one, and presents a more difficult problem. In addition to the fixed obstacles avoidance, the robot has to track an object while preventing collisions with moving obstacles that are crossing between the robot and the tracked object. These moving obstacles can be persons walking around or even other mobile robots doing their own behaviors.\nIn order to perform these behaviors, a fusion of two different controllers has been developed. On one hand, a tracking controller [43] was used in order to follow the path or the moving object. On the other hand, the wall-following controller learned with the IQFRL algorithm was used as the collision\navoidance behavior. Section 5.3 showed that this controller is robust and operates safely while performing the task. There were no blockades during the behavior in all the tests, neither from collisions nor from other reasons. The way in which the wall-following behavior is used in order to avoid collisions is: given an obstacle that is too close to the robot, it can be surrounded following the border of this obstacle in order to avoid a collision with it. The controller described in this paper follows the wall on its right, while for this task, the obstacle can be on both sides. This can easily be solved by a simple permutation of the laser beams depending on which side the obstacle is detected.\nThe wall-following behavior is only executed when the robot is too close to an object \u2014a value of 0.4 m has been used as threshold. The objective of the controller is to drive the robot to a state in which there is no danger of collision \u2014a value of 0.5 m has been established as a safe distance. As long as the robot is in a safe state the tracking behavior is resumed. This behavior controls the linear and angular velocities of the robot in order to place it at an objective point in every control cycle. This point is defined using the desired distance between the robot and the moving object. The tracking controller uses four different input variables:\n\u2022 The distance between the robot and the objective point:\nd =\n\u221a (xr \u2212 xob j)2 + (yr \u2212 yob j)2\ndre f (19)\nwhere (xr, yr) are the coordinates of the robot, (xob j, yob j) are the coordinates of the objective point and dre f is the reference distance between the robot and the objective point.\n\u2022 The deviation of the robot with respect to the objective point:\ndev = arctan (\nyob j \u2212 yr xob j \u2212 xr\n) \u2212 \u03b8r (20)\nwhere \u03b8r is the angle of the robot. A negative value of the deviation indicates that the robot is moving in a direction to the left of the objective point, while a positive value means that it is moving to the right.\n\u2022 The difference of velocity between the robot and the objective point:\n\u2206v = vr \u2212 vm\nvmax (21)\nwhere vr, vm and vmax are the linear velocities of the robot, the moving object, and the maximum velocity attainable by the robot.\n\u2022 The difference in angle between the object and the robot:\n\u2206\u03b8 = \u03b8m \u2212 \u03b8r (22)\nwhere \u03b8m is the angle of the moving object.\nThe reference distance (dre f ) is different depending on the type of behavior. For the path tracking behavior, there is no moving object tracking and, therefore, the robot follows the path with dre f = 0 in order to do a perfect path tracking. In the other two behaviors the robot follows a moving object, so it is necessary to keep a safe distance \u2014a value of dre f = 0.5 m was used in the experiments shown in this section.\nThe three behaviors have been validated in two different environments (M1 and Domus) which try to reproduce the plant of a museum (Fig. 20). Figs. 20(a) and 20(b) show the path tracking with obstacles avoidance behavior. The orange (medium grey) path represents the trajectory that has to be followed by the robot. This path also includes information of the velocity that the robot should have at each point. The higher the concentration of marks, the lower the linear velocity in that point of the path. Moreover, the path was generated without obstacles and, once the obstacles were added to the environment, the robot was placed at the beginning of the path in order to track it. The cyan (light grey) path indicates the trajectory implemented by the robot using the proposed combination of controllers (wall-following and tracking). It can be seen that the robot avoids successfully all the obstacles in its path, i.e., the wall following behavior deviates the robot from the predefined path when an obstacle generates a possibility of collision. When the robot overcomes the obstacle, it returns to the predefined path as quickly as possible.\nIn the case of the moving object tracking with fixed obstacles avoidance behavior (Figs. 20(c) and 20(d)), the cyan (light grey) line represents the path of the robot due to the combination of the controllers. Also, the orange (medium grey) path shows the trajectory of the moving object tracked by the robot. In this behavior, the moving object goes too close to some obstacles in several situations, forcing the controller to execute the wall following behavior in order to avoid collisions. Moreover, the wall-following controller is also executed when the moving object turns the corners very close to the obstacles, at a distance that is unsafe for the robot.\nThe last and most complex behavior is moving object tracking with moving obstacle avoidance (Figs. 20(e) and 20(f)). The cyan (light grey) path shows, once again, the path followed by the robot when it tracks the moving object (orange / medium grey path) while avoiding static and moving obstacles. Also, the path followed by the moving obstacle that should be avoided by the robot is shown in blue (dark grey). The arrows along the path indicate the places in which the obstacle interferes with the robot. This behavior shows the ability of the controller learned with the IQFRL algorithm to avoid collisions, even when the moving obstacle tries to force the robot to fail: the controller can detect the situation and perform the task safely, avoiding collisions."}, {"heading": "7. Conclusions", "text": "This paper describes a new algorithm which is able to learn controllers with embedded preprocessing for mobile robotics. The transformation of the low-level variables into high-level variables is done through the use of Quantified\nFuzzy Propositions and Rules. Furthermore, the algorithm involves linguistic labels defined by multiple granularity without limiting the granularity levels. The algorithm was extensively tested with the wall-following behavior both in several simulated environments and on a Pioneer 3-AT robot in two real environments. The results were compared with some of the most well-known algorithms for learning controllers in mobile robotics. Non-parametric significance tests have been\nperformed, showing a very good and a statistically significant performance of the IQFRL approach."}, {"heading": "8. Acknowledgements", "text": "This work was supported by the Spanish Ministry of Economy and Competitiveness under grants TIN2011-22935 and TIN2011-29827-C02-02. I. Rodriguez-Fdez is supported\nby the Spanish Ministry of Education, under the FPU national plan (AP2010-0627). M. Mucientes is supported by the Ramo\u0301n y Cajal program of the Spanish Ministry of Economy and Competitiveness. This work was supported in part by the European Regional Development Fund (ERDF/FEDER) under the projects CN2012/151 and CN2011/058 of the Galician Ministry of Education.\nNOTICE: this is the authors version of a work that was accepted for publication in Applied Soft Computing. Changes resulting from the publishing process, such as peer review, editing, corrections, structural formatting, and other quality control mechanisms may not be reflected in this document. Changes may have been made to this work since it was submitted for publication. A definitive version was subsequently published in Applied Soft Computing, 26:123-142, 2015, doi:10.1016/j.asoc.2014.09.021."}, {"heading": "Appendix A. IQFRL for Classification (IQFRL-C)", "text": "This section describes the modifications that are necessary to accomplish for adapting the IQFRL algorithm for classification problems."}, {"heading": "Appendix A.1. Examples and Grammar", "text": "The structure of the examples used for classification is very similar to the one described in expression 4:\nel = (d (1) , . . . , d (Nb) , velocity, class) (A.1)\nwhere class represents the class of the example. Furthermore, the consequent production (production 3) of the grammar (Fig. 4) must be modified to:\n3. consequent \u2212\u2192 Fc\nwhere Fc is the linguistic label of the class. The output variable (class) has a granularity g#classc ."}, {"heading": "Appendix A.2. Initialization", "text": "The consequent of the rules is initialized as Fc = A \u03b3 c where \u03b3 is the class that represents the example. Only those examples whose class is different from the default class (A fc ) are used in the initialization of a new individual."}, {"heading": "Appendix A.3. Evaluation", "text": "For each individual (rule) of the population, the following values are calculated:\n\u2022 True positives (tp): \u2013 #tp = \u2223\u2223\u2223\u2223{el : Cl = C j \u2227 DOF j (el) > 0}\u2223\u2223\u2223\u2223, where Cl\nis the class of example el, C j is the class in the consequent of the j-th rule, and DOF j ( el )\nis the DOF of the j-th rule for the example el. #tp represents the number of examples that have been correctly classified by the rule.\n\u2013 tpd = \u2211 l DOF j ( el )\n: Cl = C j, i.e., the sum of the DOFs of the examples contributing to #tp.\n\u2013 tp = #tp + tpd/#tp\n\u2022 False positives (fp): \u2013 #fp = \u2223\u2223\u2223\u2223{el : Cl , C j \u2227 DOF j (el) > 0}\u2223\u2223\u2223\u2223: number of\npatterns that have been classified by the rule but belong to a different class.\n\u2013 fpd = \u2211 l DOF j ( el )\n: Cl , C j, i.e., the sum of the DOFs of the patterns that contribute to #fp.\n\u2013 fp = #fp + fpd/#fp\n\u2022 False negatives (fn):\n\u2013 #fn = nC jex \u2212 #tp, where n C j ex = \u2223\u2223\u2223\u2223{el : Cl = C j}\u2223\u2223\u2223\u2223. #fn is the number of examples that have not been classified by the rule but belong to the class in the consequent of the rule.\nThe values of tp and fp take into account not only the number of examples that are correctly/incorrectly classified, but also the degree of fulfillment of the rule for each of the examples. In case that tpd \u2248 0, then tp \u2248 #tp, while if it is high (tpd \u2248 #tp) then tp \u2248 #tp + 1. Taking into account these definitions, the accuracy of an individual of the population can be described as:\nconfidence = 1\n10fp (A.2)\nwhile the ability of generalization of a rule is calculated as:\nsupport = tp\ntp + #fn (A.3)\nFinally, fitness is defined as the combination of both values:\nfitness = confidence \u00b7 support (A.4)\nwhich represents the strength of an individual."}, {"heading": "Appendix A.4. Mutation", "text": "For classification, the probability that an example matches the output associated to a rule (Eq. 7) is binary. Therefore, in order to select the example (esel) that is going to be used for mutation, the following criteria is used:\n\u2022 For generalization, the probability for an example el to be selected is:\nP(el = esel) = 1 \u2212 \u2211 j DOF j ( el ) \u00b7 confidence j\u2211\nj DOF j ( el ) (A.5)\nwhere confidence j is the confidence (Eq. A.2) of the j-th individual. This probability measures the accuracy with which the individuals of the population cover the example el.\nFinally, the consequent is mutated considering the class of the examples covered by the individual. Thus, the probability that the consequent of the individual j change to the class C\u03b3 is defined as:\nP ( j | C\u03b3 ) =\n\u2211 l DOF j ( el )\n: Cl = C\u03b3\u2211 l DOF j ( el ) (A.7)"}, {"heading": "Appendix A.5. Performance", "text": "The parameters used for IQFRL-C are the same as for regression (Sec. 5.2). Moreover, the default class is straight wall. Tables A.15 and A.16 show the number of rules learned by the classification method IQFRL-C and the complexity of the rules learned in terms of mean and standard deviation of the number of propositions and granularities for each input variable. The number of rules for each situation is very low, resulting in very interpretable knowledge bases. Furthermore, the complexity of the rules is also low, as the number of propositions and granularities learned show that the rules are very general.\nTable A.17 shows the confusion matrix for the learned classifier. The matrix was obtained as the average of a 5-fold cross-validation over the sets. Moreover, the performance of the classifier was analyzed with the accuracy and the Cohen\u2019s \u03ba [44]. Both measures are very close to 1, showing the high performance of the classifier obtained with IQFRL-C."}], "references": [{"title": "A", "author": ["M. Mucientes"], "venue": "Bugar\u0131\u0301n, People detection through quantified fuzzy temporal rules, Pattern Recognition 43 ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2010}, {"title": "Ten years of genetic fuzzy systems: current framework and new trends", "author": ["O. Cordon", "F. Gomide", "F. Herrera", "F. Hoffmann", "L. Magdalena"], "venue": "Fuzzy sets and systems 141 (1) ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2004}, {"title": "Genetic fuzzy systems: taxonomy", "author": ["F. Herrera"], "venue": "current research trends and prospects, Evolutionary Intelligence 1 (1) ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Automatically designing robot controllers and sensor morphology with genetic programming", "author": ["B. Bonte", "B. Wyns"], "venue": "in: Proceedings of the 6th IFIP Artificial Intelligence Applications and Innovations (AIAI)", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Genetic algorithm optimization for type-2 non-singleton fuzzy logic controllers, Recent Advances on Hybrid Approaches for Designing Intelligent Systems", "author": ["R. Mart\u0131\u0301nez-Soto", "O. Castillo", "J.R. Castro"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Learning from demonstration in robots: Experimental comparison of neural architectures", "author": ["M. Umar Suleman", "M. Awais"], "venue": "Robotics and Computer-Integrated Manufacturing 27 (4) ", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Reinforcement learning for robot control using probability density estimations", "author": ["A. Agostini", "E. Celaya Llover"], "venue": "in: Proceedings of the 7th International Conference on Informatics in Control (ICINCO)", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "An intelligent control system for mobile robot navigation tasks in surveillance", "author": ["C.W. Lo", "K.L. Wu", "Y.C. Lin", "J.S. Liu"], "venue": "in: Robot Intelligence Technology and Applications 2, Springer", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Evolutionary design and behavior analysis of neuromodulatory neural networks for mobile robots control", "author": ["T. Kondo"], "venue": "Applied Soft Computing 7 (1) ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2007}, {"title": "A highly interpretable fuzzy rule base using ordinal structure for obstacle avoidance of mobile robot", "author": ["K. Samsudin", "F. Ahmad", "S. Mashohor"], "venue": "Applied Soft Computing 11 (2) ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Evaluation on the robustness of genetic network programming with reinforcement learning", "author": ["S. Mabu", "A. Tjahjadi", "S. Sendari", "K. Hirasawa"], "venue": "in: Proceedings of the IEEE International Conference on Systems Man and Cybernetics (SMC)", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "Hybrid genetic-fuzzy approach to autonomous mobile robot", "author": ["K. Senthilkumar", "K. Bharadwaj"], "venue": "in: Proceedings of the IEEE International Conference on Technologies for Practical Robot Applications (TePRA)", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2009}, {"title": "A", "author": ["M. Mucientes", "D. Moreno"], "venue": "Bugar\u0131\u0301n, S. Barro, Design of a fuzzy controller in mobile robotics using genetic algorithms, Applied Soft Computing 7 (2) ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2007}, {"title": "Learning weighted linguistic rules to control an autonomous robot", "author": ["M. Mucientes", "R. Alcal\u00e1", "J. Alcal\u00e1-Fdez", "J. Casillas"], "venue": "International Journal of Intelligent Systems 24 (3) ", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2009}, {"title": "A case study for learning behaviors in mobile robotics by evolutionary fuzzy systems", "author": ["M. Mucientes", "J. Alcal\u00e1-Fdez", "R. Alcal\u00e1", "J. Casillas"], "venue": "Expert Systems With Applications 37 ", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "An evolutionary fuzzy behaviour controller using genetic algorithm in robocup soccer game", "author": ["J. Kuo", "Y. Ou"], "venue": "in: Proceedings of the Ninth International Conference on Hybrid Intelligent Systems (HIS), Vol. 1", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "An intelligent fuzzy controller based on genetic algorithms", "author": ["M. Khanian", "A. Fakharian", "M. Chegini", "B. Jozi"], "venue": "in: Proceedings of the IEEE International Symposium on Computational Intelligence in Robotics and Automation (CIRA)", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "A", "author": ["M. Mucientes", "D.L. Moreno"], "venue": "Bugar\u0131\u0301n, S. Barro, Evolutionary learning of a fuzzy controller for wall-following behavior in mobile robotics, Soft Computing 10 (10) ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2006}, {"title": "Reinforcement ant optimized fuzzy controller for mobile-robot wall-following control", "author": ["C. Juang", "C. Hsu"], "venue": "IEEE Transactions on Industrial Electronics 56 (10) ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "Evolutionary robot wall-following control using type-2 fuzzy controller with species-DE-activated continuous ACO", "author": ["C. Hsu", "C. Juang"], "venue": "IEEE Transactions on Fuzzy Systems 21 (1) ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2013}, {"title": "Evolutionary-group-based particle-swarm-optimized fuzzy controller with application to mobile-robot navigation in unknown environments", "author": ["C. Juang", "Y. Chang"], "venue": "IEEE Transactions on Fuzzy Systems 19 (2) ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "I", "author": ["M. Mucientes"], "venue": "Rodr\u0131\u0301guez-Fdez, A. Bugar\u0131\u0301n, Evolutionary learning of quantified fuzzy rules for hierarchical grouping of laser sensor data in intelligent control, in: Proceedings of the IFSA-EUSFLAT 2009 conference", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2009}, {"title": "A computational approach to fuzzy quantifiers in natural languages", "author": ["L. Zadeh"], "venue": "Computers & Mathematics with Applications 9 (1) ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1983}, {"title": "Genetic fuzzy systems: evolutionary tuning and learning of fuzzy knowledge bases", "author": ["O. Cord\u00f3n", "F. Herrera", "F. Hoffmann", "L. Magdalena"], "venue": "Vol. 19, World Scientific", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2001}, {"title": "Hybridizing genetic algorithms with sharing scheme and evolution strategies for designing approximate fuzzy rule-based systems", "author": ["O. Cord\u00f3n", "F. Herrera"], "venue": "Fuzzy sets and systems 118 (2) ", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2001}, {"title": "Competition-based induction of decision models from examples", "author": ["D. Greene", "S. Smith"], "venue": "Machine Learning 13 (2) ", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1993}, {"title": "Introduction to evolutionary computing", "author": ["A. Eiben", "J. Smith"], "venue": "Springer-Verlag", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2003}, {"title": "Fuzzy inclusion and similarity through coherent conditional probability", "author": ["R. Scozzafava", "B. Vantaggi"], "venue": "Fuzzy Sets and Systems 160 (3) ", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2009}, {"title": "Handbook of Metaheuristics", "author": ["H. Louren\u00e7o", "O. Martin", "T. St\u00fctzle"], "venue": "Kluwer Academic Publishers", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2003}, {"title": "The player/stage project: Tools for multi-robot and distributed sensor systems", "author": ["B. Gerkey", "R. Vaughan", "A. Howard"], "venue": "in: Proceedings of the 11th International Conference on Advanced Robotics (ICAR)", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2003}, {"title": "A three-stage evolutionary process for learning descriptive and approximate fuzzy-logic-controller knowledge bases from examples", "author": ["O. Cord\u00f3n", "F. Herrera"], "venue": "International Journal of Approximate Reasoning 17 (4) ", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1997}, {"title": "S", "author": ["J. Alcal\u00e1-Fdez", "L. S\u00e1nchez"], "venue": "Garc\u0131\u0301a, M. Del Jesus, S. Ventura, J. Garrell, J. Otero, C. Romero, J. Bacardit, V. Rivas, et al., Keel: a software tool to assess evolutionary algorithms for data mining problems, Soft Computing 13 (3) ", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2009}, {"title": "Use of a quasi-newton method in a feedforward neural network construction algorithm", "author": ["R. Setiono", "L. Hui"], "venue": "IEEE Transactions on Neural Networks 6 (1) ", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1995}, {"title": "Modern applied statistics with S", "author": ["W. Venables", "B. Ripley"], "venue": "Springer-Verlag", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2002}, {"title": "kernlab - An S4 Package for Kernel Methods in R", "author": ["A. Karatzoglou", "A. Smola", "K. Hornik", "A. Zeileis"], "venue": "Journal of Statistical Software 11 (9) ", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2004}, {"title": "New support vector algorithms", "author": ["B. Sch\u00f6lkopf", "A. Smola", "R. Williamson", "P. Bartlett"], "venue": "Neural Computation 12 (5) ", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2000}, {"title": "The autonomous tour-guide robot jinny", "author": ["G. Kim", "W. Chung", "K.-R. Kim", "M. Kim", "S. Han", "R.H. Shinn"], "venue": "in: Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems(IROS), Vol. 4, IEEE", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2004}, {"title": "Design of an intelligent hospital service robot and its applications", "author": ["M.-Y. Shieh", "J. Hsieh", "C. Cheng"], "venue": "in: Proceedings of the IEEE International Conference on Systems, Man and Cybernetics, Vol. 5, IEEE", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2004}, {"title": "Watchbot: A building maintenance and surveillance system based on autonomous robots", "author": ["J. L\u00f3pez", "D. P\u00e9rez", "E. Paz", "A. Santana"], "venue": "Robotics and Autonomous Systems 61 (12) ", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2013}, {"title": "P", "author": ["C. Gamallo", "C.V. Regueiro"], "venue": "Quint\u0131\u0301a, M. Mucientes, Omnivision-based kld-monte carlo localization, Robotics and Autonomous Systems 58 (3) ", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2010}, {"title": "A navigation system for robots operating in crowded urban environments", "author": ["R. K\u00fcmmerle", "M. Ruhnke", "B. Steder", "C. Stachniss", "W. Burgard"], "venue": "in: Proccedings of the IEEE International Conference on Robotics & Automation (ICRA)", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2013}, {"title": "A", "author": ["A. Gonz\u00e1lez-Sieira", "M. Mucientes"], "venue": "Bugar\u0131\u0301n, A state lattice approach for motion planning under control and sensor uncertainty, in: Proceedings of the First Iberian Robotics Conference (ROBOT), Madrid (Spain)", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2013}, {"title": "Quick design of fuzzy controllers with good interpretability in mobile robotics", "author": ["M. Mucientes", "J. Casillas"], "venue": "IEEE Transactions on Fuzzy Systems 15 (4) ", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2007}, {"title": "A lot of randomness is hiding in accuracy", "author": ["A. Ben-David"], "venue": "Engineering Applications of Artificial Intelligence 20 (7) ", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2007}], "referenceMentions": [{"referenceID": 0, "context": "Propositions (QFPs) [1].", "startOffset": 20, "endOffset": 23}, {"referenceID": 1, "context": "The well-known combination of evolutionary algorithms and fuzzy logic (genetic fuzzy systems) is one of the approaches that aims to manage the balance between accuracy and interpretability of the rules [2, 3].", "startOffset": 202, "endOffset": 208}, {"referenceID": 2, "context": "The well-known combination of evolutionary algorithms and fuzzy logic (genetic fuzzy systems) is one of the approaches that aims to manage the balance between accuracy and interpretability of the rules [2, 3].", "startOffset": 202, "endOffset": 208}, {"referenceID": 3, "context": "Among the most popular approaches can be found evolutionary algorithms [4, 5], neural networks [6] and reinforcement learning [7, 8].", "startOffset": 71, "endOffset": 77}, {"referenceID": 4, "context": "Among the most popular approaches can be found evolutionary algorithms [4, 5], neural networks [6] and reinforcement learning [7, 8].", "startOffset": 71, "endOffset": 77}, {"referenceID": 5, "context": "Among the most popular approaches can be found evolutionary algorithms [4, 5], neural networks [6] and reinforcement learning [7, 8].", "startOffset": 95, "endOffset": 98}, {"referenceID": 6, "context": "Among the most popular approaches can be found evolutionary algorithms [4, 5], neural networks [6] and reinforcement learning [7, 8].", "startOffset": 126, "endOffset": 132}, {"referenceID": 7, "context": "Among the most popular approaches can be found evolutionary algorithms [4, 5], neural networks [6] and reinforcement learning [7, 8].", "startOffset": 126, "endOffset": 132}, {"referenceID": 8, "context": "Also hibridations of them, like evolutionary neural networks [9], reinforcement learning with evolutionary algorithms [10, 11], the widely used genetic fuzzy systems [12, 13, 14, 15, 16, 17, 18], or even more uncommon combinations like ant colony optimization with reinforcement learning [19] or differential evolution [20] or evolutionary group based particle swarm optimization [21] have been successfully applied.", "startOffset": 61, "endOffset": 64}, {"referenceID": 9, "context": "Also hibridations of them, like evolutionary neural networks [9], reinforcement learning with evolutionary algorithms [10, 11], the widely used genetic fuzzy systems [12, 13, 14, 15, 16, 17, 18], or even more uncommon combinations like ant colony optimization with reinforcement learning [19] or differential evolution [20] or evolutionary group based particle swarm optimization [21] have been successfully applied.", "startOffset": 118, "endOffset": 126}, {"referenceID": 10, "context": "Also hibridations of them, like evolutionary neural networks [9], reinforcement learning with evolutionary algorithms [10, 11], the widely used genetic fuzzy systems [12, 13, 14, 15, 16, 17, 18], or even more uncommon combinations like ant colony optimization with reinforcement learning [19] or differential evolution [20] or evolutionary group based particle swarm optimization [21] have been successfully applied.", "startOffset": 118, "endOffset": 126}, {"referenceID": 11, "context": "Also hibridations of them, like evolutionary neural networks [9], reinforcement learning with evolutionary algorithms [10, 11], the widely used genetic fuzzy systems [12, 13, 14, 15, 16, 17, 18], or even more uncommon combinations like ant colony optimization with reinforcement learning [19] or differential evolution [20] or evolutionary group based particle swarm optimization [21] have been successfully applied.", "startOffset": 166, "endOffset": 194}, {"referenceID": 12, "context": "Also hibridations of them, like evolutionary neural networks [9], reinforcement learning with evolutionary algorithms [10, 11], the widely used genetic fuzzy systems [12, 13, 14, 15, 16, 17, 18], or even more uncommon combinations like ant colony optimization with reinforcement learning [19] or differential evolution [20] or evolutionary group based particle swarm optimization [21] have been successfully applied.", "startOffset": 166, "endOffset": 194}, {"referenceID": 13, "context": "Also hibridations of them, like evolutionary neural networks [9], reinforcement learning with evolutionary algorithms [10, 11], the widely used genetic fuzzy systems [12, 13, 14, 15, 16, 17, 18], or even more uncommon combinations like ant colony optimization with reinforcement learning [19] or differential evolution [20] or evolutionary group based particle swarm optimization [21] have been successfully applied.", "startOffset": 166, "endOffset": 194}, {"referenceID": 14, "context": "Also hibridations of them, like evolutionary neural networks [9], reinforcement learning with evolutionary algorithms [10, 11], the widely used genetic fuzzy systems [12, 13, 14, 15, 16, 17, 18], or even more uncommon combinations like ant colony optimization with reinforcement learning [19] or differential evolution [20] or evolutionary group based particle swarm optimization [21] have been successfully applied.", "startOffset": 166, "endOffset": 194}, {"referenceID": 15, "context": "Also hibridations of them, like evolutionary neural networks [9], reinforcement learning with evolutionary algorithms [10, 11], the widely used genetic fuzzy systems [12, 13, 14, 15, 16, 17, 18], or even more uncommon combinations like ant colony optimization with reinforcement learning [19] or differential evolution [20] or evolutionary group based particle swarm optimization [21] have been successfully applied.", "startOffset": 166, "endOffset": 194}, {"referenceID": 16, "context": "Also hibridations of them, like evolutionary neural networks [9], reinforcement learning with evolutionary algorithms [10, 11], the widely used genetic fuzzy systems [12, 13, 14, 15, 16, 17, 18], or even more uncommon combinations like ant colony optimization with reinforcement learning [19] or differential evolution [20] or evolutionary group based particle swarm optimization [21] have been successfully applied.", "startOffset": 166, "endOffset": 194}, {"referenceID": 17, "context": "Also hibridations of them, like evolutionary neural networks [9], reinforcement learning with evolutionary algorithms [10, 11], the widely used genetic fuzzy systems [12, 13, 14, 15, 16, 17, 18], or even more uncommon combinations like ant colony optimization with reinforcement learning [19] or differential evolution [20] or evolutionary group based particle swarm optimization [21] have been successfully applied.", "startOffset": 166, "endOffset": 194}, {"referenceID": 18, "context": "Also hibridations of them, like evolutionary neural networks [9], reinforcement learning with evolutionary algorithms [10, 11], the widely used genetic fuzzy systems [12, 13, 14, 15, 16, 17, 18], or even more uncommon combinations like ant colony optimization with reinforcement learning [19] or differential evolution [20] or evolutionary group based particle swarm optimization [21] have been successfully applied.", "startOffset": 288, "endOffset": 292}, {"referenceID": 19, "context": "Also hibridations of them, like evolutionary neural networks [9], reinforcement learning with evolutionary algorithms [10, 11], the widely used genetic fuzzy systems [12, 13, 14, 15, 16, 17, 18], or even more uncommon combinations like ant colony optimization with reinforcement learning [19] or differential evolution [20] or evolutionary group based particle swarm optimization [21] have been successfully applied.", "startOffset": 319, "endOffset": 323}, {"referenceID": 20, "context": "Also hibridations of them, like evolutionary neural networks [9], reinforcement learning with evolutionary algorithms [10, 11], the widely used genetic fuzzy systems [12, 13, 14, 15, 16, 17, 18], or even more uncommon combinations like ant colony optimization with reinforcement learning [19] or differential evolution [20] or evolutionary group based particle swarm optimization [21] have been successfully applied.", "startOffset": 380, "endOffset": 384}, {"referenceID": 7, "context": "Furthermore, over the last few years, mobile robotic controllers have been getting some attention as a test case for the automatic design of type-2 fuzzy logic controllers [8, 5, 20].", "startOffset": 172, "endOffset": 182}, {"referenceID": 4, "context": "Furthermore, over the last few years, mobile robotic controllers have been getting some attention as a test case for the automatic design of type-2 fuzzy logic controllers [8, 5, 20].", "startOffset": 172, "endOffset": 182}, {"referenceID": 19, "context": "Furthermore, over the last few years, mobile robotic controllers have been getting some attention as a test case for the automatic design of type-2 fuzzy logic controllers [8, 5, 20].", "startOffset": 172, "endOffset": 182}, {"referenceID": 11, "context": "In [12] 360 laser sensor beams are used as input data, and are heuristically combined into 8 sectors as inputs to the learning algorithm.", "startOffset": 3, "endOffset": 7}, {"referenceID": 8, "context": "On the other hand, in [9, 13, 14, 15, 16, 18, 19, 21] the input variables of the learning algorithm are defined by an expert.", "startOffset": 22, "endOffset": 53}, {"referenceID": 12, "context": "On the other hand, in [9, 13, 14, 15, 16, 18, 19, 21] the input variables of the learning algorithm are defined by an expert.", "startOffset": 22, "endOffset": 53}, {"referenceID": 13, "context": "On the other hand, in [9, 13, 14, 15, 16, 18, 19, 21] the input variables of the learning algorithm are defined by an expert.", "startOffset": 22, "endOffset": 53}, {"referenceID": 14, "context": "On the other hand, in [9, 13, 14, 15, 16, 18, 19, 21] the input variables of the learning algorithm are defined by an expert.", "startOffset": 22, "endOffset": 53}, {"referenceID": 15, "context": "On the other hand, in [9, 13, 14, 15, 16, 18, 19, 21] the input variables of the learning algorithm are defined by an expert.", "startOffset": 22, "endOffset": 53}, {"referenceID": 17, "context": "On the other hand, in [9, 13, 14, 15, 16, 18, 19, 21] the input variables of the learning algorithm are defined by an expert.", "startOffset": 22, "endOffset": 53}, {"referenceID": 18, "context": "On the other hand, in [9, 13, 14, 15, 16, 18, 19, 21] the input variables of the learning algorithm are defined by an expert.", "startOffset": 22, "endOffset": 53}, {"referenceID": 20, "context": "On the other hand, in [9, 13, 14, 15, 16, 18, 19, 21] the input variables of the learning algorithm are defined by an expert.", "startOffset": 22, "endOffset": 53}, {"referenceID": 12, "context": "Moreover, in [13, 14, 16, 18, 20] the evaluation function of the evolutionary algorithm must be defined by an expert for each particular behavior.", "startOffset": 13, "endOffset": 33}, {"referenceID": 13, "context": "Moreover, in [13, 14, 16, 18, 20] the evaluation function of the evolutionary algorithm must be defined by an expert for each particular behavior.", "startOffset": 13, "endOffset": 33}, {"referenceID": 15, "context": "Moreover, in [13, 14, 16, 18, 20] the evaluation function of the evolutionary algorithm must be defined by an expert for each particular behavior.", "startOffset": 13, "endOffset": 33}, {"referenceID": 17, "context": "Moreover, in [13, 14, 16, 18, 20] the evaluation function of the evolutionary algorithm must be defined by an expert for each particular behavior.", "startOffset": 13, "endOffset": 33}, {"referenceID": 19, "context": "Moreover, in [13, 14, 16, 18, 20] the evaluation function of the evolutionary algorithm must be defined by an expert for each particular behavior.", "startOffset": 13, "endOffset": 33}, {"referenceID": 9, "context": "In [10, 12, 16] the membership functions are defined heuristically.", "startOffset": 3, "endOffset": 15}, {"referenceID": 11, "context": "In [10, 12, 16] the membership functions are defined heuristically.", "startOffset": 3, "endOffset": 15}, {"referenceID": 15, "context": "In [10, 12, 16] the membership functions are defined heuristically.", "startOffset": 3, "endOffset": 15}, {"referenceID": 13, "context": "In [14, 15] labels have been uniformly distributed, but the granularity of each input variable is defined using expert knowledge.", "startOffset": 3, "endOffset": 11}, {"referenceID": 14, "context": "In [14, 15] labels have been uniformly distributed, but the granularity of each input variable is defined using expert knowledge.", "startOffset": 3, "endOffset": 11}, {"referenceID": 12, "context": "On the other hand, in [13, 17, 18, 19, 21] an approximative approach is used, i.", "startOffset": 22, "endOffset": 42}, {"referenceID": 16, "context": "On the other hand, in [13, 17, 18, 19, 21] an approximative approach is used, i.", "startOffset": 22, "endOffset": 42}, {"referenceID": 17, "context": "On the other hand, in [13, 17, 18, 19, 21] an approximative approach is used, i.", "startOffset": 22, "endOffset": 42}, {"referenceID": 18, "context": "On the other hand, in [13, 17, 18, 19, 21] an approximative approach is used, i.", "startOffset": 22, "endOffset": 42}, {"referenceID": 20, "context": "On the other hand, in [13, 17, 18, 19, 21] an approximative approach is used, i.", "startOffset": 22, "endOffset": 42}, {"referenceID": 6, "context": "In [7], this issue has been managed from the reinforcement learning perspective, by using a probability density estimation of the joint space of states.", "startOffset": 3, "endOffset": 6}, {"referenceID": 3, "context": "Among all the approaches based on evolutionary algorithms, only in [4] no expert knowledge has been taken into account.", "startOffset": 67, "endOffset": 70}, {"referenceID": 21, "context": "In [22] a Genetic Cooperative-Competitive Learning (GCCL) approach was presented.", "startOffset": 3, "endOffset": 7}, {"referenceID": 22, "context": ") [23].", "startOffset": 2, "endOffset": 6}, {"referenceID": 2, "context": "Evolutionary learning methods follow two approaches in order to encode rules within a population of individuals [3, 24]:", "startOffset": 112, "endOffset": 119}, {"referenceID": 23, "context": "Evolutionary learning methods follow two approaches in order to encode rules within a population of individuals [3, 24]:", "startOffset": 112, "endOffset": 119}, {"referenceID": 24, "context": "\u2022 Michigan, IRL [25], and GCCL [26]: each individual codifies a rule.", "startOffset": 16, "endOffset": 20}, {"referenceID": 25, "context": "\u2022 Michigan, IRL [25], and GCCL [26]: each individual codifies a rule.", "startOffset": 31, "endOffset": 35}, {"referenceID": 26, "context": "The discussion is focused on those approaches for which an individual represents a rule, discarding the Michigan approach as it is used in reinforcement learning problems in which the reward from the environment needs to be maximized [27].", "startOffset": 234, "endOffset": 238}, {"referenceID": 23, "context": "This is usually done using token competition [24].", "startOffset": 45, "endOffset": 49}, {"referenceID": 0, "context": "Although GCCL works well for classification problems [1], the same does not occur for regression problems [22], mostly due to the difficulty of achieving in this realm an adequate balance between cooperation and competition.", "startOffset": 53, "endOffset": 56}, {"referenceID": 21, "context": "Although GCCL works well for classification problems [1], the same does not occur for regression problems [22], mostly due to the difficulty of achieving in this realm an adequate balance between cooperation and competition.", "startOffset": 106, "endOffset": 110}, {"referenceID": 27, "context": "This function uses a similarity measure defined as [28]:", "startOffset": 51, "endOffset": 55}, {"referenceID": 0, "context": "\u03b1 f \u2208 [0, 1] is a parameter that codifies the trade-off between accuracy and generalization of the rule.", "startOffset": 6, "endOffset": 12}, {"referenceID": 0, "context": "The rule selection algorithm described in [1] has been used.", "startOffset": 42, "endOffset": 45}, {"referenceID": 28, "context": "The last step was implemented with the iterated local search (ILS) algorithm [29].", "startOffset": 77, "endOffset": 81}, {"referenceID": 29, "context": "The Player/Stage robot software [30] has been used for the tests on the simulated environments and also for the connection with the real robot Pioneer 3-AT (Fig.", "startOffset": 32, "endOffset": 36}, {"referenceID": 30, "context": "\u2022 Methodology to Obtain Genetic fuzzy rule-based systems Under the iterative Learning approach (MOGUL): a three-stage genetic algorithm [31]:", "startOffset": 136, "endOffset": 140}, {"referenceID": 24, "context": "The soft-constrained MOGUL was used, as it has better performance in very hard problems [25]2.", "startOffset": 88, "endOffset": 92}, {"referenceID": 32, "context": "\u2022 Multilayer Perceptron Neural Network (MPNN): a single-hidden-layer neural network trained with the BFGS method [33] with the following parameters: abstol = 0.", "startOffset": 113, "endOffset": 117}, {"referenceID": 35, "context": "\u2022 \u03bd-Support Vector Regression (\u03bd-SVR)4: a \u03bd-SVM [36] version for regression with a Gaussian RBF kernel.", "startOffset": 48, "endOffset": 52}, {"referenceID": 31, "context": "2The implementation in Keel [32], an open source (GPLv3) Java software tool to assess evolutionary algorithms for Data Mining problems, was used.", "startOffset": 28, "endOffset": 32}, {"referenceID": 33, "context": "3The package nnet [34] of the statistical software R was used.", "startOffset": 18, "endOffset": 22}, {"referenceID": 34, "context": "4The package kernlab [35] of the statistical software R was used.", "startOffset": 21, "endOffset": 25}, {"referenceID": 14, "context": "It is based on the error measure defined in [15], but", "startOffset": 44, "endOffset": 48}, {"referenceID": 14, "context": "Finally, the IQFRL proposal was compared with the proposals presented in [15] for learning rules for the wall-following behavior.", "startOffset": 73, "endOffset": 77}, {"referenceID": 14, "context": "Table 12: Average results (x \u00b1 \u03c3) of IQFRL and several approaches with preprocessing based on expert knowledge [15] Alg.", "startOffset": 111, "endOffset": 115}, {"referenceID": 36, "context": "For instance, in [37], a tour-guide robot that can either follow a predefined route or a tour-guide person was shown.", "startOffset": 17, "endOffset": 21}, {"referenceID": 37, "context": "With a similar goal, an intelligent hospital service robot was presented in [38].", "startOffset": 76, "endOffset": 80}, {"referenceID": 38, "context": "More recently, in [39] a team of robots that cooperate in a building developing maintenance and surveillance tasks was presented.", "startOffset": 18, "endOffset": 22}, {"referenceID": 39, "context": "More dynamic environments were described in [40, 41], where the robot had to operate in buildings and populated urban areas.", "startOffset": 44, "endOffset": 52}, {"referenceID": 40, "context": "More dynamic environments were described in [40, 41], where the robot had to operate in buildings and populated urban areas.", "startOffset": 44, "endOffset": 52}, {"referenceID": 41, "context": "Finally, in [42] the authors presented a motion planner that was able to generate paths taking into account the uncertainty due to controls and measurements.", "startOffset": 12, "endOffset": 16}, {"referenceID": 42, "context": "On one hand, a tracking controller [43] was used in order to follow the path or the moving object.", "startOffset": 35, "endOffset": 39}, {"referenceID": 43, "context": "Moreover, the performance of the classifier was analyzed with the accuracy and the Cohen\u2019s \u03ba [44].", "startOffset": 93, "endOffset": 97}], "year": 2014, "abstractText": "The automatic design of controllers for mobile robots usually requires two stages. In the first stage, sensorial data are preprocessed or transformed into high level and meaningful values of variables which are usually defined from expert knowledge. In the second stage, a machine learning technique is applied to obtain a controller that maps these high level variables to the control commands that are actually sent to the robot. This paper describes an algorithm that is able to embed the preprocessing stage into the learning stage in order to get controllers directly starting from sensorial raw data with no expert knowledge involved. Due to the high dimensionality of the sensorial data, this approach uses Quantified Fuzzy Rules (QFRs), that are able to transform low-level input variables into high-level input variables, reducing the dimensionality through summarization. The proposed learning algorithm, called Iterative Quantified Fuzzy Rule Learning (IQFRL), is based on genetic programming. IQFRL is able to learn rules with different structures, and can manage linguistic variables with multiple granularities. The algorithm has been tested with the implementation of the wall-following behavior both in several realistic simulated environments with different complexity and on a Pioneer 3-AT robot in two real environments. Results have been compared with several well-known learning algorithms combined with different data preprocessing techniques, showing that IQFRL exhibits a better and statistically significant performance. Moreover, three real world applications for which IQFRL plays a central role are also presented: path and object tracking with static and moving obstacles avoidance.", "creator": "LaTeX with hyperref package"}}}