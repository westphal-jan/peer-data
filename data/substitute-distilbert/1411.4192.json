{"id": "1411.4192", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Nov-2014", "title": "Introduction to ROSS: A New Representational Scheme", "abstract": "ross ( \" modelling, ontology, structure, star \" ) may introduced as a new method presenting knowledge representation that emphasizes representational constructs for physical structure. the ross representational scheme includes a language called \" star \" for the specification of ontology classes. the ross method also includes structured formal implementation called canonical \" instance model \". instance models are used in the area of natural language meaning attempting to represent items. this paper provides both the rationale and core philosophical background for the ross method.", "histories": [["v1", "Sat, 15 Nov 2014 22:31:05 GMT  (1085kb)", "http://arxiv.org/abs/1411.4192v1", "32 pages"]], "COMMENTS": "32 pages", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["glenn r hofford"], "accepted": false, "id": "1411.4192"}, "pdf": {"name": "1411.4192.pdf", "metadata": {"source": "META", "title": "Introduction to ROSS", "authors": ["Glenn R. Hofford"], "emails": [], "sections": [{"heading": null, "text": "Copyright \u00a9 2014 Glenn R. Hofford.\nRepresentation is a cross-discipline topic that includes knowledge representation from the field of artificial intelligence, meaning representation from the field of natural language understanding, and structured information from information processing. The field of logic is replete with methods for representation and reasoning. In the areas of AI knowledge representation and reasoning, leading approaches include first order logic, description logic, lambda calculus, semantic networks, framebased approaches and many others. Meaning representation techniques from the field of natural language understanding include the above in addition to approaches like conceptual dependency.\nROSS (\u201cRepresentation, Ontology, Structure, Star\u201d) is introduced as a new method for representation that emphasizes representational constructs for physical structure. The ROSS approach starts with a normal form that is self-consciously less-expressive than logic, and builds from the bottom-up to achieve the expressiveness that is needed for a domain. Information that uses the normal form exists within an analogical frame of reference. What is achieved is a greater degree of structure in the representations that use ROSS when compared with representations that are typically created using formal approaches such as FOL. The ROSS normal form involves a set of modeling guidelines and underlying ontological commitments that involve naive or intuitionistic assumptions.\nROSS can be used in several ways: it is a representational method for knowledge bases that contain class definitions; it is a method for representational artifacts that contain fact-like constructs; and, it provides a foundation for representations that support various forms of inference. The first two uses are described and a brief introduction to how ROSS supports reasoning techniques is presented. The principles of ROSS have been used to create an expert system for diagnosis and a proof of concept natural language understanding system for story comprehension; these principles are briefly described."}, {"heading": "1 Introduction", "text": "ROSS is introduced as a representational approach that contains unique features that assist with a number of important representation objectives. ROSS is an acronym composed of the initial letters from the words \u201cRepresentation\u201d, \u201cOntology\u201d, \u201cStructure\u201d, and \u201cStar language\u201d. The Star language is also introduced in this paper. ROSS provides an infrastructure and a set of implicit guidelines that help with the following tasks:\n Creation of knowledge bases that have well-organized entity and behavior clas-\nses.\n Generation of representation artifacts (containing instances of classes) that are\nhighly structured based on the use of a normal form for spatial/temporal location-related attributes.\nROSS accomplishes two things that relate to the use of the term \u201cstructure\u201d; the distinction between these two aspects is as follows:\n It represents the physical structure of a problem domain or domain of discourse\nin a way that is rich and deep. How this is specifically done is explained.\n The representational knowledge base or fact artifact itself is highly structured.\nTwo specific methods are presented: Star language definition documents and an XML-based format for instance models. (An instance model is a meaning representation artifact that is generated by the semantic processing of a natural language understanding program).\nIt will be shown that these two features of\nROSS are complementary with each other.\nROSS is also a representational platform for a variety of techniques for automated inference. The set of ROSS features for inference is briefly introduced."}, {"heading": "1.1 Context Within Information Processing,", "text": "AI and NLP\nThe field of information processing requires methods that support and facilitate structured storage (via key-based indexing), that in turn supports query and analysis. The DBMS field has well-established conventions and methods for these tasks. ROSS is useful for creating structured information artifacts that go beyond DBMS in the complexity of the subject matter or problem domain.\nThe field of symbol-based AI knowledge representation and reasoning requires techniques that allow automation of inference in its various forms. Formal methods for knowledge representation are necessary to facilitate reasoning. Knowledge representation artifacts can be classified with respect to the types of information they represent: artifacts that include abstract definitions, e.g. of classes, and rule-like constructs are referred to as knowledge bases or rule bases. Artifacts that include fact-like constructs, whether these are past facts, goals, plans, predicted states or other fact-like items are referred to herein as fact repositories or transcripts.\nIn the field of natural language processing (NLP) and natural language understanding (NLU), a meaning representation is a cohesive representational artifact that is the output of a process of natural language understanding or comprehension as this process is applied to a sentence, fragment, or document of human natural language text. Existing meaning representation approaches include first order logics, semantic networks, and frame-based approaches (Jurafsky and Martin, 2009). Other approaches include lambda calculus, description logic and conceptual graphs. The main objective of such natural language understanding meaning representation techniques and languages is that of representing the original information in a structured way \u2013 this enables further NLP objectives that include tasks as varied as summarization, named entity recognition, and relationship detection. Question answering systems require the transformation of questions into a structured form. NLU can also benefit from structured meaning representations that are a platform for inference about semantics and context: this allows for enrichment of the parsing and semantic processing steps. Semantic processing within NLU also involves the use of knowledge bases that contain classes of entities and behaviors; ROSS provides an infrastructure for this requirement.\nROSS is a representational method that is physical symbol-based 1 . Generally speaking it is based on the tenets of the Knowledge Representation Hypothesis 2 . Knowledge (definitions, facts, rules, etc.) is represented declaratively rather than procedurally. ROSS can be used as a representation and reasoning technique that assists human cognition, and, it is capable of automation. As a method that can be automated, it provides a representational infrastructure that allows for effective inference in an independent mechanistic manner."}, {"heading": "1.2 Ontological Basis", "text": "The ontology of ROSS is an \u201coperational ontology\u201d that has been worked out for the purpose of representation. ROSS starts with a seemingly simple ontological concept and works out the implications and details consistently. The concept addresses the question \u201cfor the purpose of constructing structured representational knowledge bases and artifacts, what exists in the physical or external world, that is, the world (whether real or hypothetical) that is represented?\u201d The answer is: unit-sized location entities 3 that do not move; these entities exist within a four-dimensional (4D) world that can be understood as consisting of Euclidean space with the added dimension of time. Cartesian coordinates are used with the important restriction that dimensions are only represented using integers, not real numbers (this restriction is necessitated by the requirement of indivisibility and is explained in the section on the ontology of ROSS). The ontological foundations thus share similarities with those of the fields of naive physics and commonsense representation and reasoning 4 .\nThe ontological concept involves the idea that a unit-sized location entity is an entity that has both spatial size and temporal duration. The representation of other entities, aspects, or characteristics of the represented world from the universe of discourse is accomplished using a variety of representational constructs for aggregation\n1 Cf. Newell and Simon (1976) for a general definition of a physical symbol system. 2 The Knowledge Representation Hypothesis is described in Smith (1982). 3 The term \u201centity\u201d is used somewhat imprecisely throughout this paper \u2013 in general it refers to a fixed location in space and time. The difference between \u201centity\u201d and \u201cobject\u201d will be explained in what follows. 4 Cf. Mueller (2006) - the discrete event calculus as an example of an integer-based system.\nor composition. For instance, larger entities are represented using a mechanism for the specification of structure within a hierarchy, and motion is broken down into a sequence of states, each of which is represented using attributes that specify the static features of a single-time-point entity.\nThe ontology of ROSS consists of these and several other ontological constraints and requirements, which collectively provide a basis for the creation of a set of knowledge base definitions. In the area of NLU for instance, these definitions can be used to assist or support the (human or automated) task of the creation of fact transcripts, or instance models that represent the subject matter of natural language textual input."}, {"heading": "1.3 Epistemology", "text": "ROSS in its current form does not directly address the epistemological (i.e. belief-related) aspects of representation. This is primarily due to the emphasis that is placed on the structural aspects of representation. An implicit assumption is involved wherein a ROSS fact repository is an artifact that represents a set of true facts about a situation (the degree of belief involves full certainty). Where a situation involves agents that themselves represent and communicate information, the agents\u2019 mental states and the communicative aspects are represented using the same fundamental approach that is used for representing entities and aspects of commonsense domains. (However, ROSS does have features for representation that involves a high level of abstraction; these features are well-suited for representations of representation, information, mental states, communication, etc.)."}, {"heading": "1.4 Is ROSS a Logic?", "text": "ROSS is a method that fits the definition of \u201crepresentational scheme\u201d (Hayes, 1974). ROSS has a set of syntactic rules and semantics that are based on a set of ontological assumptions and on an ontological framework that builds on these assumptions. ROSS shares many features with representational schemes that are referred to as \u201clogics\u201d such as first order logic and description logic. ROSS provides a foundation for reasoning, or inference; however, unlike most logics, the techniques for reasoning that use ROSS are loosely coupled with the representational system of ROSS. This loose coupling allows ROSS to support a wide range of methods for inference. However, some of the normally expected elements for a logic are not currently present in ROSS, such as a set of axioms; therefore the\nterm \u201crepresentational scheme\u201d, rather than \u201clogic\u201d, has been deemed as appropriate for ROSS.\nPractitioners who are familiar with using logic for the tasks that are addressed by ROSS may find that the concepts of ROSS seem somewhat cumbersome. ROSS is a paradigm shift from logic, and using it requires additional effort in some areas such as the tasks of modeling to create supporting definitions and to create intricate classes. In addition, ROSS imposes stringent restrictions on the modeling task; these may at first seem unnecessary. This paper attempts to show the benefits that result from the effort that is required by the technique."}, {"heading": "1.5 Comprehensiveness of Representation", "text": "A requirement for all structured representation approaches is that of comprehensiveness or completeness \u2013 the meaning representation language or logic must be capable of full coverage of the information for a problem domain or from a domain of discourse (for NLU, this is the domain of the information represented by the input natural language text). ROSS provides a framework that allows for comprehensive representation, both in knowledge bases and in fact-related artifacts.\nA sometimes-overlooked or misunderstood objective for a representation is that of organization. It is often mistakenly assumed that the way to achieve highly structured representational artifacts involves using highly refined, elegant and concise techniques (e.g. FOL, lambda calculus). These approaches are appropriate for some domains, such as the task of representing numerical concepts and computational processes. However what has been overlooked is that a method may be highly formalized and mathematically precise, yet at the same time it may be weak for practical use for domains and representational uses outside the scope to which it has been applied. In contrast, the premise of ROSS is that a large field of domains has a rich structure that is readily organized in ways that have not been accomplished with other techniques. 5"}, {"heading": "1.6 A Non-Objective: Conciseness of Expression", "text": "ROSS knowledge bases and representational artifacts are perhaps less concise than those of other\n5 Expressiveness, e.g. of FOL, as that which involves universal quantification, negation, disjunction and nested assertions is not viewed here as identical to comprehensiveness and is treated separately in this paper.\nlogics or other schemes. ROSS definitional constructs (attribute value sets, attribute types, classes, etc.) are somewhat elaborate. The goal of representation with ROSS is a high level of organization, not necessarily conciseness of its definitions and expressions. The task of modeling in order to create a set of classes and instances that are appropriately comprehensive and complex - even for some seemingly-simple assertions - necessitates a rich, complex and sophisticated representational approach. 6"}, {"heading": "1.7 Background", "text": "Throughout the 60-plus years of their respective histories, the fields of AI knowledge representation and reasoning and NLP natural language understanding have involved quests for representational methods that are capable of representing problem domains or the subject matter from domains of discourse in ways that are suitably rich and deep. A deep representation would be one that is comprehensive and that adequately captures the structure of the represented domain. The AI tasks of knowledge representation and commonsense reasoning have been addressed by practitioners using symbolic approaches as early as the 1960s and 1970s. This work flourished during that period and extended into the 1980s, but symbolic approaches ran into difficulties and did not achieve the successes that had been anticipated.\nAn example is the SHRDLU system of Terry Winograd, which focused on commonsense reasoning about simple domains and questionanswering (Winograd, 1971).\nWithin the field of natural language understanding, (Sowa, 2006) describes the shift that took place during the 1980\u2019s on the part of Terry Winograd and others:\n6 Nash (2013): a blog post entitled \u201cMake Things As Simple As Possible, But Not Simpler\u201d emphasizes the danger of oversimplification in technology. ROSS is aligned with the premise of the so-called Einstein\u2019s Razor: \u201cIt can scarcely be denied that the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience.\u201d (courtesy: http://en.wikiquote.org/wiki/Albert_Einstein) This can be summarized as \u201cMake things as simple as possible, but not simpler.\u201d Contrast with Occam\u2019s Razor: \u201cplurality must never be posited without necessity\u201d, which may in some cases be used as a justification for oversimplification.\nTerry Winograd, for example, called his first book Understanding Natural Language (1972) and his second book Language as a Cognitive Process: Volume I, Syntax (1983). But he abandoned the projected second volume on semantics when he realized that no existing semantic theory could explain how anyone, human or computer, could understand language. With his third book, coauthored with the philosopher Fernando Flores, Winograd (1986) switched to his later work on the design of human-computer interfaces. Winograd\u2019s shift in priorities is typical of much of the AI research over the past twenty years. Instead of language understanding, many people have turned to the simpler problems of text mining, information retrieval, and designing user interfaces.\nThe ambitious systems of the 1970s and 1980s were viewed either as overly-complex, cumbersome, and overly domain-specific. Some of these projects perhaps raised more questions than they answered. Subsequently, particularly in the NLP field, statistical approaches came to the fore and have tended to dominate the landscape.\nThe question of why the symbolic approaches failed - or only achieved partial success - has continued to perplex those who believe that important answers are yet to be discovered that involve symbolic approaches. The author\u2019s view is that the ROSS approach provides a foundational set of principles and a representational scheme that contain important answers to these questions."}, {"heading": "1.8 Comparisons", "text": "This paper compares ROSS against first order logic (FOL) and description logic; a few comparisons are also made against frames. In contrast to FOL, ROSS is based upon a set of explicit assumptions about the nature of the reality that is represented (the represented world) in order to achieve a greater degree of organization than is typically achieved using FOL. ROSS also includes important modeling restrictions that constrain the task of creating definitions that model the world or domain.\nIn contrast to description logic, ROSS is not built on a syllogistic categorical approach. ROSS classes are not representations of sets, a ROSS class is a mechanism for storing information about instances that get instantiated. Inheritance is optional in ROSS.\nROSS shares some similarities with frames 7 , but it has a much more elaborate infrastructure than frames for representing physical structure. For readers who are accustomed to the frames terminology, a ROSS attribute type is the rough equivalent of a frame slot, and a ROSS attribute value is the rough equivalent of a frame filler."}, {"heading": "2 Core Concepts", "text": "The following sections describe the core concepts of the ROSS approach."}, {"heading": "2.1 The Physical Structure of the Domain is Richly Represented", "text": "Can traditional logic represent the complex physical structure of a person? The answer in theory is yes; however in practice traditional logics provide little in the way of guidelines for accomplishing representational tasks like this. For instance, given a hypothetical \u201cperson\u201d class, how is the set of spatial relationships between the overall person and the sub-parts (components) such as person head and person body represented? How is physical size represented?\nThe representation of part to sub-part (\u201cPartOf\u201d) relationships is a foundational and well-studied task within AI knowledge representation 8 . A number of AI representational schemes, including frames and KL-ONE do represent physical structure and the PartOf relationship. However these techniques are limited 9 . In order to facilitate completeness of representation, firstly, a representational scheme should support the following features; these go well beyond predication of the existence of a \u201cPartOf\u201d relationship:\n attributes that can specify the location of a component part in relation to its parent ob-\nject.\n attributes that can specify the spatial orientation of a component in relation to its\nparent object.\n attributes that can specify the physical dimensions of a component (its size, or ex-\ntent) using a coordinate scheme that is defined in terms of its parent object.\n7 Minsky (1981) originated the frame concept; Minsky (1986) contains further elaborations on frames. 8 Sometimes referred to as mereology. 9 Minsky (1981), Brachman and Schmolze (1985)\nSecondly, this should be done in a way that is flexible, so that when instances get instantiated based on an entity class, they are created with a basic structure, but only the specifics that are known are specified."}, {"heading": "2.1.1 Object Frame Class", "text": "ROSS introduces two important representational constructs that handle structure. The first of these is called the object frame class. 10 An object frame class represents a specific physical location within a four-dimensional space-time frame of reference. The object frame class is a class that is used for the creation of object frame instances: an object frame instance is simply a location that is fixed in space and time. (Note: an object frame class is sometimes referred to as a \u201clocation entity\u201d class \u2013 these terms are synonymous). An object frame class or instance can be (spatially) \u201cunit-sized\u201d or \u201caggregate\u201d. An aggregate object frame instance is somewhat analogous to a rectangular wire frame. (The upcoming Ontology section describes the background of these concepts in greater detail)."}, {"heading": "2.1.2 Dimension System", "text": "The second representational construct is called the dimension system type, or dimension system. A dimension system is a group of closely-related dimensions. A dimension, or dimensional attribute, is like a single coordinate within a coordinate system such as the Cartesian coordinate system (e.g. the value of an x coordinate is a dimension). A dimension system includes a set of such attributes that must be used together in expressions that specify the location of a physical object. Dimension systems are used within object frame classes to provide a way of specifying locational 11 attributes of embedded component object frame classes. The component object frame class uses a special \u201cRelationshipToParent\u201d section, in which the dimension system items are used in order to specify the location and orientation of the component in relation to the parent, and in order to specify the dimensions (size or extent) of the component.\nFigure 1 shows the structure of the ROSS object frame class that represents the structure of a\n10\n\u201cFrame\u201d here is not equivalent to the AI frames; in\nthe context of \u201cobject frame class\u201d, it denotes a structural aspect. 11\nThe term \u201clocational\u201d is used by the author to refer\nto the location aspects of an entity; these can be spatial or temporal aspects.\nperson, called \u201cPersonObjectFrameClass\u201d. Note that the detail for each of the two dimension systems of the PersonObjectFrameClass is not shown.\nThe diagram provides an overview of how an object frame class represents structure. Because this is a class, the actual attribute values for a number of items are not filled in: they are designated as \u201cnil\u201d. When an instance is instantiated from the class, if specification information is available it will be used to fill in these values.\nObject frame classes and dimension systems facilitate the creation of representations that rep-\nresent dimensional structure. This dimensional structure is usually defined by the use of spatial and temporal dimensions; however other nonspecific dimensional attributes can be used, such as enumerated values. An example would be a dimension system that has a locational attribute with values of PersonHeadReceptacle and PersonBodyReceptacle. (A receptacle is an attribute value that designates a location that is distinct from other receptacles that are part of the enumerated list).\nThis approach provides an infrastructure for what is referred to as \u201cprimary information\u201d:\npropositional information that is tied into a frame of reference. This eliminates the need for a multiplicity of assertions that represents not only essential (qualitative) facts but the relational \u201cplace\u201d of the objects of those facts (such as is typically done with FOL). (As will be seen, relationships between location entities are handled by ROSS; such relational information is part of the category of secondary or derivative information)."}, {"heading": "2.2 Definitions of classes", "text": "Besides class definition statements that define object frame classes (aka \u201centity classes\u201d) ROSS contains other definitional constructs such as attribute types, attribute value sets, dimension systems and behavior classes. These are rich, sophisticated definitions that provide context for propositional expressions which are used in specific representations. Consequently, the instances that are instantiated from the object frame classes have a rich set of structural, attributive, relational and behavioral attributes.\nROSS classes can be compared to those of the\ndescription logics, where the concept can 12 represent a class. Description logics provide a way to define a unary predicate (concept) in terms of constituent features. Like description logic classes, ROSS classes can contain attributive and relational information (e.g. the class of gold coins has the attribute of having gold material composition). However ROSS classes also represent \u201ctype\u201d information involving dimension systems (i.e. dimension system \u201ctypes\u201d), attribute types and relationship types. In addition, structural information in a ROSS object frame class can be viewed as \u201ctype\u201d information), and object frame classes have lists of associated potential behaviors; this is another form of type information.\nIn contrast to some representational schemes and logics, a ROSS class is not equivalent to a mathematical set. A ROSS class is a mechanism for the aggregation of features.\nFigure 2 is an overview of the supporting definitions and of the main class types in a ROSS knowledge base:\n12\nBaader, et al.: \u201cThe vocabulary consists of con-\ncepts, which denote sets of individuals \u2026\u201d"}, {"heading": "2.3 Inheritance", "text": "The most basic form of ROSS does not mandate any form of inheritance. The process of instantiation of an instance of a locational entity (either by a human using the ROSS approach or in an automated system) may involve the use of a class, but it is not necessary for this class to exist within a hierarchical inheritance structure. The minimal requirement for such a class that is used for instantiation of instances is that it contains dimension system information and a reference to a universal structural parent 13 ."}, {"heading": "2.4 Grounding", "text": "The definitional classes of ROSS provide an important part of an answer to the symbol grounding problem 14 . In the field of natural language understanding, a related perspective was provided by Fillmore (1982). In his introduction to semantic frames, he states \u201cBy the term \u2018frame\u2019 I have in mind any system of concepts related in such a way that to understand any one of them you have to understand the whole structure in which it fits; when one of the things in such a structure is introduced into a text, or into a con-\n13\nA structural parent class is an object frame class\nthat is used for placement of other smaller embedded objects frame classes. The embedded object frame classes are usually not actual structural parts. The structural parent serves as a frame of reference. 14\nHarnad (1990) described the symbol grounding\nproblem as the task of mapping symbols to aspects of the external world.\nversation, all of the others are automatically made available\u201d. The definitions of ROSS provide this kind of infrastructure, so that when instantiation takes place, symbols have reference to more complex symbol-based constructs (the definitional classes).\n2.5 Granularity: \u201cGrain Size\u201d\nROSS is flexible with respect to the definitions that are used. Definitions are represented declaratively and thus an entire set of definitions is interchangeable with other similar such sets of definitions. The creation of a set of ROSS definitions starts with selection of one or more grain sizes (these are chosen per each class, or, where inheritance is used, the grain size can be defined for a higher-level base class). The grain sizes that are chosen for the base classes must be finegrained enough to accommodate the information that is anticipated. For instance, a set of definitions that is used for news stories about events in the \u201ceveryday world\u201d would require one set of grain sizes, whereas news stories about developments in the field of physics would require another set of grain sizes. (A single ROSS knowledge base can however accommodate all such needs if the higher level classes use appropriately-small grain sizes)."}, {"heading": "2.6 Primary Versus Secondary Information", "text": "ROSS maintains a distinction between \u201cprimary information\u201d and \u201csecondary information\u201d. Primary information is information that is specified in a way that is normalized with respect to a spatial/temporal frame of reference. It can be said to be \u201ccanonical\u201d 15 . It is entity-centric, not relationship-centric. There are many types of secondary information, and ROSS subdivides these using a stratification scheme.\nAn example of secondary information is the relationship between two locational entities within a frame of reference. A specific example of a relationship within a transcript about past facts would be an expression that specifies that the\n15\nWoods (1975) (III.B The Canonical Form Myth)\nargues that canonical forms are not likely to be possible, (and are not necessarily desirable). The author\u2019s view is as follows: 1) for knowledge base definitional information: ROSS class representations are partly analogical; object frame classes do make use of primary information, in particular by the use of class attributes which can use shape templates, and 2) for fact repository artifacts: a canonical form is possible but it is constrained by the availability of primary information.\nspatial distance at some specified point in time between Person1 and Person2 is 3 feet. (In contrast, the primary information about Person1 consists of attributes that specify its location in relation to a structural parent class).\nPrimary (canonical form/normal form) information can exist within an object frame class or within a fact repository artifact."}, {"heading": "2.7 Normal Form", "text": "For representation of factual information (excluding laws, rules, etc.), logic approaches can represent any assertion that can be represented in any other representational system. 16 However, when it is used to create fact artifacts, this expressive power can easily result in inconsistencies and redundancies. For example, a group of FOL expressions about a situation from a blocks world might mix together several distinct types of facts:\n\u018ex:Block(x) \u2013 the predicate is a category\n\u018ex:CompositionIsWood(x)\n- predicate is an attribute about the\ninternal structure or composition\n\u018ex,\u018ey:OnTopOf(x, y)\n- predicate is a relational attribute\nIn contrast the ROSS approach handles each of these cases in a different way. A ROSS artifact containing such facts would conform to normal form. In the examples shown here, for the first case, ROSS uses a class that has been fully and precisely defined in a definitions section of a knowledge base; in the second case, the assertion as expressed in ROSS would exist within a larger representational construct (primary information in normal form) that specifies not only the internal composition but also the location-related attributes of the object; in the third case the OnTopOf relationship would exist as part of a relationship construct that is handled as secondary information.\nNormal form provides a unified way to represent information, with the result that ROSS knowledge bases and fact-based artifacts are non-redundant and complete \u2013 insofar as primary information is available. In some applications (e.g. NLU) where secondary information such as relationships is prevalent ROSS provides infrastructure that allows for storage of the secondary\n16\nFor the sake of argument, neither the epistemologi-\ncal aspect (degree of belief or of certainty about the fact) nor the degree of truth (as in fuzzy logic) are considered here.\ninformation in a way that is consistently integrated with the primary information."}, {"heading": "2.8 Truth Theory Not Applicable to Primary Information", "text": "Negated assertions are absent from primary information: this has the implication that a ROSS class or fact repository instance does not participate in a truth theory or model. Brachman and Levesque (1985) discuss the spectrum of KR formalisms with respect to the level of expressiveness (from the simpler database schemes to the fully expressive FOL). The primary information form of ROSS is indeed closer to database, as it lacks universal quantification, negation, and disjunction. Primary information assertions are termed simple assertions that are true by default."}, {"heading": "2.9 Simple Assertions", "text": "Simple assertions can be understood as fact-like constructions. By definition, a ROSS simple assertion specifies a value for a location entity. It may pertain to a class of things (e.g. as an attribute for a class), or it may apply to real past situations. Other uses of simple assertions are for the description of hypothetical facts in a hypothetical world. A distinction is made between simple assertions that represent completed states (or events) (whether real or hypothetical) and those that represent predictions 17 (predicted states) or goals (e.g. within the context of AI planning)."}, {"heading": "2.10 Stratification: Layers of Secondary Information", "text": "The first stratum of secondary information involves disjunction: it consists of disjunctive expressions and their variants (the variants include attribute value subsets and ranges). Examples include:\n An object frame class for \u201chuman parent\u201d that contains a gender attribute involving\nvalues of male or female.\n A house cat class containing a structure section with an \u201canimal head\u201d part, where\nthe spatial relational aspects are defined using a range of values specifying that the cat\u2019s head is at located at least d1 inches but not more than d2 inches from the body.\n17\n\u201cPrediction\u201d here refers to a predicted state, a sort\nof \u201cfuture fact\u201d. This definition differs from the use of \u201cprediction\u201d in the context of machine learning.\n (in an NLU instance model) A house cat instance, where it is known from text input\nthat is sitting on a mat: the precise location is not specified; it is somewhere (within a range) on and above the mat. The second stratum involves negation. (Negation is viewed as a form of disjunction and therefore could be classified as part of the second stratum 18 ). For example:\n The class of house cats that are not black \u2013 the attribute for fur color has a set of val-\nues that includes all possible colors except black.\n The house cat instance that is not on the mat: its actual location is a set of attribute\nvalues that range over all other locations in the represented world. The following information types belong to the third stratum (alternately these are referred to as tertiary information).\n Collections (cf. universal quantification \u2013 the \u201cfor all x\u201d)\n Computed values, for instance counts (e.g. the count of legs of a house cat instance).\n Relationships"}, {"heading": "2.11 Incomplete Information", "text": "Brachman and Levesque (1985) (citing earlier research) have tied the expressive power of FOL to its capability for dealing with knowledge that is incomplete. Disjunctive and negated expressions are exemplary of such information. The objective of ROSS is not to subvert fundamental epistemic tenets; rather it involves the full exploitation of the information that is available in a situation or domain. This exploitation of primary information is best illustrated by the use of object frame classes with their capability for rich specificity."}, {"heading": "2.12 Axioms and Rules", "text": "The question of whether axioms in a KR scheme or a logic are actually rules, or something more fundamental and intrinsic, is not addressed here. It suffices to state that, where relevant, ROSS makes differentiations between the following categories of axiomatic, or \u201crule-like\u201d concepts and constructs:\n Definitional axioms (including set-theory axioms) (e.g. transitivity of PartOf:\n18\nThis view is possible based on the use of attribute\nvalue sets that are finite sets.\n\u201cPartOf(\u03b1,\u03b2) \u0245 PartOf(\u03b2,\u03b3) \u2192 PartOf(\u03b1,\u03b3)\u201d)\n Dimension system axioms/postulates (cf. geometrical axioms, e.g. the Pythagorean\ntheorem)\n Computational axioms/postulates (example include the axiom \u201c2 + 2 = 4\u201d, and\naxioms about prime numbers)\n Correlative rules: these includes rules that model causal phenomena (probabil-\nistically or otherwise) and rules that model statistical correlations."}, {"heading": "2.13 Correlative Rules", "text": "A ROSS correlative rule is a representational construct that represents correlation in a problem domain. Correlation may or may not involve causality (i.e. the laws for some domain). There is not a limit on the types of correlative rules that can be constructed using the ROSS KR scheme as a foundation - this is due to the view that inference (reasoning) is a multifaceted set of tasks that should not be overly constrained by predefined approaches. Rules are not a part of ROSS fact repository artifacts: since rules are handled separately from facts and other fact-like constructs, a variety of rule base approaches are possible."}, {"heading": "2.14 The ROSS Perspective on Implication and Entailment", "text": "The tradition within the AI KR&R field has usually involved a model of entailment that involves a single knowledge base (\u201cKB\u201d) that contains a mixture of definitions/classes, facts and rules. ROSS handles this somewhat differently as is explained here.\nWhere a ROSS class or instance is limited - involving a simple assertion (primary information in normal form), or a disjunction of simple assertions, and the negation operator is not\npresent - the concept of implication is limited to a form of meta-information reasoning that uses definitional axioms, or dimension-system axioms. (This is a sort of \u201cstatic\u201d reasoning that can be performed off-line if necessary in a given implementation).\nWhere the negation stratum is involved, the\nlaw for implication ((\u03b1 \u2192 \u03b2) \u2194 (\u00ac\u03b1 V \u03b2)) is relevant, and a ROSS processor can make use of this in order to perform inference.\nAlthough ROSS sharply differentiates definitions (ROSS KB) from facts (fact repository artifacts), the above reasoning can involve either a ROSS KB or fact artifact."}, {"heading": "2.15 Relating Antecedent to Consequent in a Correlative Rule", "text": "In the field of logic, connexive logic (e.g. relevance logic) addresses the need for correlating information in the antecedent of a rule with information in the consequent. ROSS formalizes the concept of associating antecedent with consequent using a representational construct that is a part of all correlative rules, referred to as the binder. A binder is an abstraction that is implemented in such a way that the locational attributes of entities in the antecedent of a rule are related to the locational attributes of entities in the consequent of the same rule. Otherwise ROSS does not place unnecessary restrictions on the structure of correlative rules; the resultant sophisticated rule structures are viewed as the basis for automated reasoning that has a corresponding level of complexity and sophistication."}, {"heading": "2.16 Instantiation", "text": "Within the context of automation, instantiation is the process of creating an instance of a class within some fact-containing repository such as an NLU instance model. The instance is based on the class.\nFigure 3 illustrates the general concept of instantiation by showing how it takes place within an NLU system. (In an NLU system, the task of instantiation is performed by a \u201csemantic engine\u201d)."}, {"heading": "2.17 Organizational Advantages of a Physical Symbol-based Approach", "text": "ROSS is the basis for a symbolic AI approach for both knowledge base abstract definitions and for fact transcripts and instance models. Knowledge base definitions are written in the Star language. Instance models are XML documents. A symbolbased approach has value in that it is very effective as a way of organizing information, and at the same time it is flexible in allowing references to or inclusion of non-symbolic representations. For instance, use of the XML standard for instance models allows for the specification of uniform resource identifiers (URIs) that specify abstract resources that are external to the XML document. (Example resources would include binary data objects, e.g. a file containing a bitmap, and web-based services)."}, {"heading": "2.18 Representation of Human Agents", "text": "A premise of ROSS is that aspects of human agency can be represented using the same underlying approach that is used for representing any other situation in the physical world. There are no special \u201cmeta-representational\u201d constructs in ROSS that would handle the domain of human agent cognitive processes differently from any-\nthing else in the physical world. The subjects of this type of representation include representational entities and processes themselves \u2013 wherever the problem situation or natural language subject matter consists of human thoughts (e.g. plans or intentions), and they include instances or artifacts of human communication (e.g. spoken sentences). Mental computational processes that are performed by humans are represented in a similar way; automated computational processes are also represented. Representations in ROSS of human or automated representations or computational processes are typically ones that utilize more-abstract physical spatial coordinates or spatial location dimensions. For example, to represent the fact that an intelligent agent has a cognitive representational concept that represents \u201cvehicles\u201d, it may be sufficient to describe the physical location of this concept as existing in the agent\u2019s memory and that it is spatially distinct from other related concepts. (Enumerated values that express spatial locations are useful for this type of situation)."}, {"heading": "2.19 Application to Abstract Areas", "text": "ROSS can handle representations of abstractions involving entities that have physical attributes that are not relevant to a given domain. A fuller treatment is given in the section that describes the features of ROSS."}, {"heading": "2.20 Star Language", "text": "ROSS includes a language referred to as the Star language (\u201cStar\u201d is derived from the word \u201cstructure\u201d). The Star language is used as the means for encoding the definitions, and as an alternate form (versus XML) for encoding instance models. The Star language was originally developed by the author as a computer software specification language; its role within ROSS has been expanded to allow representation at the widest level, i.e. covering all problem domains or domains of discourse."}, {"heading": "2.21 Knowledge Bases", "text": "A ROSS knowledge base contains class definitions, behavior definitions and other supporting definitions that use the Star language. For convenience the term \u201cInfopedia\u201d is used to refer to such a knowledge base. (A knowledge base that is used for automated inference also contains rules). Examples classes from the NLU area include an object frame class called \u201cPersonClass\u201d, and a behavior class called \u201cPersonHitsPerson\u201d."}, {"heading": "2.22 Fact Transcripts and Instance Models", "text": "A ROSS fact repository is a representational artifact that contains fact-like constructs. The following are two important categories of fact repositories:\n a specification transcript, or transcript contains a collection of related fact-like\nconstructs that exist for some storage or computational purpose. For instance it may be used in the context of automated reasoning (an example from AI planning is the specification transcript that contains specifications of predicted states, conditions and goals)\n instance models contain fact-like constructs and that are used in the area of\nNLU for meaning representation.\nIn the area of AI automated reasoning, various transcript types have been developed by the author: these include goal statement transcripts for computer software requirements and design specifications (this transcript looks somewhat similar to a computer program), and transcripts about past facts for a diagnostic expert system."}, {"heading": "2.23 Foundations for Correlative Inference", "text": "Correlative inference rules involve correlations between attribute values of at least two distinct locational entities (involving the binder concept). This type of reasoning include the following:\n Reasoning that uses rules that represent causality for a problem domain. Such\nrules may be \u201cif/then\u201d rules that involve descriptions of causes and effects that are propositional, or the rules may express a functional relationship.\n Reasoning that uses probabilistic rules that are descriptive of correlations that have\nbeen derived about a problem domain."}, {"heading": "2.24 Applications Within Implemented Systems", "text": "ROSS has been successfully applied in three separate systems: an expert system computer program generator (Hofford, 2001 and 2010), an expert system for diagnosis of network faults (Hofford, 2013), and a representational technique that exists in a natural language understanding system (referred to as \u201cModelBuilder\u201d). The ModelBuilder NLU system uses ROSS Star language definitions and generates instance models that use XML as an encoding format."}, {"heading": "3 Ontology", "text": "The ontological commitments of ROSS involve several conventions; these include a set of constraints and an important requirement. These modeling restrictions and requirements are essential for producing knowledge base and fact artifact representations that are structured. The ontology is restrictive for a purpose: traditional upper ontologies that involve a taxonomic tree of objects with \u201cthing\u201d, \u201csubstance\u201d, (or some variation thereof) at the root are not viewed as relevant for the purpose of organizing the represented world as it is addressed by ROSS.\nThe study of the \u201ccategories\u201d has a long tradition in philosophy \u2013 on that predates Aristotle. Aristotle described an upper ontology in his Categories. Tree-like ontologies have been predominant ever since and are still prevalent.\nRussell (1945) was a critic of Aristotle\u2019s tax-\nonomy; he provides an interesting perspective:\n\u201cI do not myself believe that the term \u201ccategory\u201d is in any way useful in philosophy, as representing any clear idea. There are, in Aristotle, ten categories: substance, quantity, quality, relation, place, time, position, state, action, and affectation\u2026 There is no suggestion of any principle on which the list of ten categories has been compiled. \u2026\nI conclude that the Aristotelian doctrines with which we have been concerned in this chapter are\nwholly false, with the exception of the formal theory of the syllogism, which is unimportant\u201d.\nRegarding the basis for a set of categories, the question of \u201cwhat exists\u201d has been addressed throughout the history of philosophy. The influential work of Quine (1948) acknowledges two kinds of existence: physical things, like the continent of Australia, and abstract things \u2013 e.g. prime numbers.\nIn contrast to the approaches that have been described, the ROSS approach is not based on a tree-like taxonomy at all. If a taxonomy of \u201cthings\u201d (\u201cwhat exists\u201d) were drawn, ROSS would only have one entity at the root, the unitsized location entity.\nBecause the ROSS ontology is itself a representational tool, many philosophical questions simply are not addressed \u2013 it is intended as an ontological framework that has been integrated with a representational methodology. The ROSS ontology is a sort of \u201cpseudo-ontology\u201d: it is the basis for a representational framework that is useful for a broad range of domains.\nAdherence to the ROSS ontological conventions facilitates modeling practices that ultimately result in definitions and expressions that are internally consistent, unambiguous, and nonredundant. These conventions apply to the modeling of the universe of discourse or a domain of discourse or problem domain. The ontological constraints are as follows."}, {"heading": "3.1 Fundamental Ontological Constraint", "text": "The first and most fundamental ontological convention is a constraint: a unit-sized location entity is the most basic \u2013 and only - thing that exists in a represented world. It is a single-time location within a dimension system (it is transitory). Such unit-sized entities do not move - the intuitive concept of movable object is not a first-class object of this ontology. Movable objects must be represented as an aggregation of unit-size objects. Likewise, anything else \u2013 entities, motion, state changes, etc. - that is represented using ROSS must build on the fundamental building block of the unit-sized location entity. 19\nAn implication of this constraint for ROSS representation is that unit-sized location entities are the only thing that can be existentially quanti-\n19\nThe unit-size location entity does have a single unit of duration in time. The term \u201ctransitory\u201d refers not to an instantaneous point in time, but to an interval of time.\nfied. (As will be explained however, within factcontaining repositories, ROSS does not actually use existential quantification)."}, {"heading": "3.2 Second Ontological Constraint", "text": "The second convention is also a constraint: a unit-sized location entity does not contain an \u201cobject\u201d; rather, the value of a location object is represented as consisting of a numerical value from the set of natural numbers. The Star language provides the infrastructure for describing sets of values using the attribute value set statement. As will be seen, other representations can be used in place of integers, such as enumerated values or string values.\nAn example of a fixed location with a specific value at a specific point in time involves the digits of the national debt clock (any particular digit) in New York City. The concept of a fixed location with a specific value at a specific point in time in ROSS can be seen as a generalization of this and many other instances. However as a generalization it extends even to movable objects such as a falling apple or a bouncing ball."}, {"heading": "3.3 An Ontological Requirement", "text": "The third convention is a requirement, and is related to the first constraint of the ontology: the universe or domain of discourse is viewed as consisting of at least one dimension system, so that at the least, a unit-sized object, designated \u201cObject-A\u201d, has a location that is distinct from the location of one, some or all other objects. This requirement results in representations that contain infrastructure that allows all entities to be correlated with each other within a central frame of reference. A dimension system can be very abstract, as is the case where specifics of a location do not need to be represented. Or, a dimension system can be very specific, for instance, it can be the implementation of a four-dimensional coordinate system with x, y, z, and t coordinates.\nWhy is the dimension system required for ROSS? The requirement for the existence of a dimension system is the foundation for an entire set of representational constructs that represent structure. A dimension system provides a frame of reference for all entities that are described. 20\n20\nNote that ROSS also contains the relationship\nconstruct (as secondary information) that is useful for representing specific relationships between two entities. An example would involve a person and a car in a parking lot: each of the objects (person and car) may be directly related to the object frame class for the"}, {"heading": "3.4 Implicit Existential Quantification", "text": "An implication of the above ontological requirement for dimension systems is as follows. The act of creating a structural parent object frame instance within a fact-containing repository (e.g. an NLU instance model) results in the existence of a dimension system that is housed within the structural parent instance (e.g. a Cartesian coordinate system). This can be visualized as a rectangular shaped region (a cube or rectangular right prism (a cuboid)). It is a collection, or aggregation of unit-sized location entity instances. Because this frame of reference exists, there is not a need for the use of the existential quantifier - as would be the case with FOL \u2013 for propositional ROSS expressions. Once this frame of reference has been created, the main subsequent representational task is that of infusing or populating the individual cells (like the cells in a matrix) with values."}, {"heading": "3.5 Atomism", "text": "The earliest known proponents of an atomic theory appear to have been the Greek philosophers Leucippus and Democritus (Guthrie, 1950). Their concept of atoms included the idea of indivisibility. (It is noteworthy that atomism was rejected by Aristotle and that the concept was dormant until the 19th century 21 ). The Greek word atomai means \u201cunsplittable\u201d and was used to describe the smallest existent particles - these particles were hypothesized as being solid, hard and indestructible. The modern physics concept of atom is more specific due to better detection devices (not to mention the body of analytic and empirical methods of modern science) \u2013 an atom is precisely defined with respect to its attributes, such as size and mass.\nThe ROSS approach borrows one aspect from Greek atomism: the unit-sized location entity of ROSS is indivisible. Indivisibility of ROSS atoms is necessary so that value set values can be used as descriptors. If a ROSS unit-sized location entity were divisible, a new set of attribute value sets would need to be created \u2013 one for each of the newly-created components.\nlarger parking lot using structural relationship-toparent attributes, but at the same time their explicit spatial relationship to each other may be represented in order to capture the meaning of the phrase \u201cthe woman stood near the car\u201d. 21\nCf. Sowa (2000) - Aristotle\u2019s concept of monads (units), specifically his idea of point and instant are somewhat similar to atoms.\nA key difference is that the ROSS \u201catom\u201d comes into existence, last for only one time interval, and cannot be said to exist again. It has \u2013 at the least - a numeric value. Insofar as the value can vary from one \u201catom\u201d to the next, the ROSS concept in this respect also differs from that of the early Greeks and from the physics atom, since both concepts involve a uniformity of all atoms.\nThe comparison between ROSS unit-sized entities and atoms from the field of physics breaks down with respect to specificity. Since ROSS is only a representational scheme, it does not involve any implicit claim that a unit-sized location entity actually exists. This allows for complete flexibility in modeling, as an atomic size may be chosen that is capable of representation for a problem domain or for a wide range of problem domains."}, {"heading": "3.6 Root size spatial unit is a black box", "text": "Tarski (1927) described a theory wherein a primitive - the smallest indivisible \u201cthing\u201d that exists - is a sphere. ROSS makes the ontological assumption that the shape of the primitive (smallest) existent entity for a given domain does not actually matter. For purposes of creating representations, it is only important to differentiate the value of the smallest locational entity from the values of other locational entities. In essence then, the internal composition of the smallest spatial unit (whatever this is chosen to be) is unimportant \u2013 it is a \u201cblack box\u201d. (However, it should be noted that when a Cartesian coordinate system is used, the unavoidable conclusion is that the shape is that of a cube).\n3.7 The Treatment of \u201cSpace\u201d\nAs described above, a transitory unit-sized location entity can only be described in terms of its locational properties and in terms of its internal value properties. A consequence of this is that \u201cspace\u201d is not a special case. Space is treated as a value, no differently from other values. Whether or not a unit-sized location entity has a value of \u201cspace\u201d is important in several areas: for \u201cshape patterns\u201d, and for rules for inference. (To accommodate these uses the Star language has a set of built-in value categories called \u201cSpace\u201d and \u201cNotSpace\u201d)."}, {"heading": "3.8 Substance", "text": "Substance is not given any special handling: substance is modeled in a way similar to motion \u2013 it is described in terms of attribute \u201cvalue\u201d values.\nFrom the ROSS perspective, substance does not necessarily \u201cexist\u201d at all. Rather, substance as a representational concept is a result of the modeling of location entities and their values, and of the causal phenomena that are associated with them."}, {"heading": "3.9 Time as Interval with Duration", "text": "Ontologies and representations of time are a much-researched area and detailed background is beyond the scope of this paper 22 .\nROSS is based on a particular view wherein time consists of a sequence of intervals during which motion does not take place, in other words, objects are \u201cfrozen\u201d. Subsequent to each interval, and instantaneously, objects then \u201cjump\u201d to the next location (or they remain in the same spatial location if they are not moving). This is not an ontological presupposition \u2013 it is the tenet for a representational approach. The question of whether or not the physical world actually behaves this way is left to the field of physics."}, {"heading": "3.10 Motion and Process", "text": "Motion is viewed as an aggregation of unit-sized location entities. The following example is pseudo-code that illustrates this concept, where t1 and t2 are the labels for two intervals along a timeline, and x, y and z values are integer-based coordinate values (note that the two location entities are adjacent). This represents some thing that \u201cmoves\u201d from x1 to x2.\n Entity-1-t1 at x1,y1,z1 @ t1 // value = solid  Entity-2-t1 at x2,y1,z1 @ t1 // value = space  Entity-1-t2 at x1,y1,z1 @ t2 // value = space\n Entity-2-t2 at x2,y1,z1 @ t2 // value = solid"}, {"heading": "3.11 Digital View", "text": "The ROSS approach can also be understood by way of comparison with approaches that involve a digital view of some domain. For instance, acoustic digital sampling produces data that represents a sound pattern at discrete time intervals. ROSS is similar in how it represents real world objects and events: it abstracts from the problem domain in order to create representational constructs that have application to discrete space and time intervals.\n22\nSome references for this area include Allen (1983),\nHayes (1996), Shanahan (1997), Sowa (2000), Russell and Norvig (2003)."}, {"heading": "3.12 Representation of Shape and \u201cTelescopic\u201d Dimension Systems", "text": "Shape is not a primitive concept in ROSS. However shape is addressed as part of two areas:\n Classes can be defined in terms of shape. For instance, a class that represents containers,\ne.g. cups, that holds liquids must be defined with respect to its shape.\n Rules that use ROSS as their underlying representation can involve specifications of\nshape.\nThe use of shape within a class definition is as follows:\n A dimension system and a specification system that uses it are defined. (This discussion\nwill use a dimension system that is a 3D Cartesian coordinate system). The specification system inner content section must incorporate a qualitative attribute type that uses an attribute value set that contains at least one value that inherits from the Space value category and at least one value that inherits from the NotSpace value category.\n An aggregate object frame class with a type of range is defined. (A range object frame\nclass is not defined in terms of named structural sub-parts but rather it is a group of spatially adjacent unit-sized locations, along a line, in a plane, or within a 3D cubical solid).\n Smallest possible shape: A pattern is created that represents a shape using as few locations\nas possible. (Note that in ROSS, a pattern can be minimally defined as one that involves a single unit-sized location entity with a specific value \u2013 an example is a single pixel on a computer screen with a color of red). A shape-representing pattern (ShapePattern) involves an aggregation of spatially-adjacent unit-sized locations each of which have a specific value that is only distinguished from other values with respect to whether or not it is a member of the Space or NotSpace value category.\n Note that a ROSS template is an aggregation of values or a mechanism for generating such\nvalues (e.g. a drawing instruction set) that involves the possibility of disparate values. For example a template for a house cat would likely use a variety of colors or compositional attributes. In contrast, a ROSS ShapePattern is limited to containing only values from the Space and NonSpace categories.\n Use of ShapePattern in class definitions, and magnification: a ROSS ShapePattern is used\nwithin a range object frame class, within the Attributes section, in order to specify the shape of the class in an abstract way that is not tied to specific spatial sizes. The process of instantiation uses the class and its shape pattern to create an instance: this process must specify specific spatial dimensions and therefore it involves a computational task called magnification, using the shape pattern in order to infuse the instance with a set of NotSpace values that correspond to the original NotSpace values of the ShapePattern.\n A telescopic dimension system mapping is used in order to accomplish the magnifica-\ntion of a shape pattern to generate an instance pattern for the shape. The ShapePattern as described above can also be used in rules."}, {"heading": "3.13 The Diorama Analogy", "text": "A diorama is a small-scale replica of a scene. The diorama presents a useful analogy for the structure that is instantiated when a ROSS NLU instance model (or KRR fact transcript) is created. The diorama typically has a physical frame \u2013 a ROSS instance model has a single structural parent object frame class instance, which provides a framework, and more specifically a dimension system within which to \u201cput\u201d things. The difference involves the aspect of time: an NLU instance model context 23 contains a timeline, and changes can take place, whereas the diorama is a way in which to present a static visual scene."}, {"heading": "3.13.1 The Cartoon Analogy", "text": "The modern cartoon provides the second analogy for ROSS representation instances. Cartoons achieve the appearance of motion through the utilization of fixed-location images. The continuous aspect of motion thus is not actually involved. ROSS as a representation technique uses the same fundamental approach."}, {"heading": "3.14 Convenience Assumptions", "text": "ROSS includes several concepts that can be used in the representation of facts \u2013 these are assumptions the use of which precludes the necessity for the excessive use of explicit assertions.\n23\nA context contains a top-level structural parent. (Cf.\nthe section on Instance Models for a full definition of the context)."}, {"heading": "3.15 The Empty Space Assumption", "text": "The empty space assumption has relevance specifically for fact repositories. This is the assumption that an instantiated instance has a value (if it is a unit-sized object instance) or consists of values that are members of the Space value category, unless specifically specified otherwise as is done with infusion. (By way of analogy, this is like placing a wire frame model into a diorama \u2013 it is initially empty, until it gets filled with something)."}, {"heading": "3.16 Perpetuation", "text": "The perpetuation assumption involves perpetuation of values along a time line; it can be used in similar fashion as the empty space assumption: the assumption is that for any unit-sized location that has been infused with a value at time t=n, it can be assumed that the subsequent unit-sized location at the same spatial location (at time t=(n+1)) will have the same value unless it is overtly specified to have a different value. This assumption is useful for stationary objects but does not address the representation of objects in motion."}, {"heading": "3.17 The Frame Problem", "text": "The frame problem is relevant for systems that perform inference; it is addressed in ROSS by the above two assumptions. At a deeper level, the frame problem does not present the same challenge to ROSS that it does for FOL-based systems due to the existence (in ROSS fact repositories) of a structural parent instance: by implication this involves the existence of all of its unitsized location entities (cells). Global assumptions like the empty space assumption and the perpetuation assumption are used in order to conveniently specify most values. Values that change through time (as part of state changes or motion) are explicitly set as indicated by the inference process."}, {"heading": "3.18 Dimension System Concepts", "text": "ROSS uses the term \u201cdimension system\u201d, rather than \u201ccoordinate system\u201d as a way of denoting that a dimension system is a flexible concept: it need not be tied to any pre-defined method for the representation of space and time (e.g. a Cartesian coordinate system). The basis for the dimension system concept is a cognitive process referred to here as segmentation. Segmentation is defined as the cognitive process of differentiating locations from each other. An instance of a pro-\ncess of binary segmentation yields two location entities: each entity can be represented with a symbol but little else is needed; for instance there is no \u201cdirectionality\u201d in the absence of a third reference point. However multi-part segmentation has the following implications: 1) general directionality emerges as soon as three entities exist, 2) numeric representation of locations using natural numbers (or integers) is useful, 3) an origin is needed for each dimension, and 4) specific directionality (within a dimension) (due to the existence of an origin and a numeric scheme) implies a set of relationships (e.g. \u201cless than\u201d and \u201cgreater than\u201d).\nDimension systems can be mapped from one to another, i.e. a set of specifiers that use one dimension system can be transformed into an equivalent set of specifiers that use another dimension system (e.g. geographical coordinates that use latitude and longitude can be transformed into Cartesian coordinates)."}, {"heading": "3.19 What are the ROSS Primitives?", "text": "The discussion of the ROSS ontological foundation is not complete without addressing the topic of primitives. From one perspective there is only one primitive in ROSS: the unit-sized location object; all other primitives are built as aggregations of this primitive. Nevertheless it is conceptually useful to delineate some of the aggregations that can be built and to relate other primitives that are abstractions to ROSS.\nThere are two categories of ROSS aggregation primitives: static primitives and dynamic primitives. The static primitive classes are as follows:\n The unit sized location entity as discussed above\n The range object frame class (it can be understood as a 3D array)\n The aggregate object frame class (containing named structural components/parts) The dynamic primitive classes are:\n The state change class\n The behavior class\n The 4D structural parent instance (containing multiple time points) What may appear to be missing are the following:\n Commonsense objects that move\n Motion and processes\n Events\n Agent actions\n Cause, effect\n Potential, force\nCommonsense objects and motion have been described (process is viewed as equivalent to motion). An event is a state change; an agent action is a process. Cause and effect are treated as dynamic aspects and are handled using rules. Potential and force are viewed as abstractions that augment the conceptualization of causality."}, {"heading": "3.20 Comparisons", "text": "The work of Hayes (1985) in the area of qualitative physics uses a four-dimensional approach. He states the following:\nA physical object is a three-dimensional entity which has an associated history representing the life-span of the object: a slice of this history (which we will call the life of the object), is the object at a given time.\nHayes\u2019 model of the physical world (for the purpose of describing liquids) is close to that of ROSS. A key distinction is that Hayes appears to preserve the concept of objects that exist through time whereas ROSS does not permit this.\nJohnston (2011) provides an overview of the objectives and architecture of the Comirit Objects project, a system that represents and reasons about things in the physical world. The knowledge representation approach centers around the voxel, which is defined as \u201cthe 3- dimensional equivalent of a pixel: it refers to a small cubic region in 3D space.\u201d Further definition is provided \u201cVoxels are the 3D equivalent of bit-mapped or raster images.\u201d The use of voxels for representation of physical objects is as follows \u201cInstead of representing an object by a complex polygonal structure, its shape can be approximated by a set of voxels that fill a similar space.\u201d The voxel concept shares a basic similarity with the ROSS unit-sized location entity. Whereas the characteristic of color can be attributed to a voxel, ROSS\u2018s implementation of the unit-sized location entity \u2013 the object frame class \u2013 is capable of association with any attribute that can be conceptualized (e.g. material composition, texture, mass). Further detailed comparison is beyond the scope of this paper: it should be noted that voxels can be described with meta-data that specifies structure and shape; this may correspond to the features of ROSS for handling structure and shape.\nRegarding representations of the dynamic or behavioral aspects, Johnston states \u201cVoxels will not be able to describe the workings of intricate machinery but they can capture the approximate\nshape of such machinery. If necessary, dynamics of machinery can be captured as a collection of models that show the sequence of actions.\u201d The ROSS approach parallels this capability with the behavior class."}, {"heading": "3.21 Summary of Ontology", "text": "The ontology of ROSS is rigid for a purpose: consistent adherence to these conventions and the afore-mentioned requirement serve as guidelines for modeling as it relates to creating definitions. The knowledge engineering task of creating definitions can be performed by a human or it can be automated (automated approaches are briefly described in the later section on knowledge acquisition)."}, {"heading": "4 Summary of ROSS Features", "text": "The ROSS features include the features of the Star language that are used for definitions, and features that are relevant for fact repository artifacts, e.g. instance models. The Star language features borrow to some extent from objectoriented programming languages such as C++."}, {"heading": "4.1 Specification with Natural Numbers and Integers", "text": "Numeric attribute values are either natural numbers or integers. Numeric attribute value sets that are used for locational attribute types must be members of the set of integers. Numeric attribute value sets that are used for qualitative attribute types must be finite subsets of the set of natural numbers. Within the primary information section of a fact repository artifact, where data or natural language text represents real numbers, or where values are computed (e.g. by division) to yield a real number, rounding or truncation of numeric values must take place. (Note: the use of real numbers as secondary information is not precluded from the ROSS model)."}, {"heading": "4.2 Feature: Attribute Value Ranges", "text": "Attribute value ranges have an important use within definitions of object frame classes \u2013 they allow for a component to be located approximately within the parent structure. For instance, a class called \u201cFrontEngineAutomobile\u201d would specify that the engine compartment is situated within a certain section of the parent class (the Automobile). The class definition does not specify the exact location \u2013 it is specified using a range of values (e.g. within the range of 5 cm to 100 cm from the front end of the car). Instances\nthat are based on the class can specify the exact location if this information is relevant."}, {"heading": "4.3 Feature: Star Language Definitions", "text": "Star language definitional constructs allow for the definition of attribute types, attribute value sets, and other definitional representational constructs that are used by a human or by an automated engine to construct meaning representations. An example of the Star language definitions is the dimension system, a unique feature of ROSS: it is a set of integrated definitional constructs that provides one or multiple locational attribute type definitions that must be used together in expressions that specify the location of a location object (i.e. an object frame class instance)."}, {"heading": "4.4 Feature: Inheritance", "text": "A distinction is made between entity classes that are used to directly instantiate instance entities, and higher level entity classes in an inheritance hierarchy. As has been stated, higher level classes and inheritance are important but optional features of ROSS and the Star language. However, the instantiation of an instance does require the use of at least one class. For use in generating an instance model, the typical case involves using an object frame class (an entity class), such as CarObjectFrameClass, which class either may contain all information, or it may rely on higher classes to contribute some of its features. The alternate case involves using a more-abstract object frame class referred to as ObjectObjectFrameClass. This class is abstract with the exception of dimension system information and a reference to a universal structural parent. For example, an NLU instance model may contain an instance that has been instantiated based on ObjectObjectFrameClass. Since the structural parent is known it can be inserted into the model. Subsequent contextual information in the input may subsequently be used to add attributive or behavioral information about the object instance."}, {"heading": "4.5 Feature: Dimension System", "text": "The next feature group is based on the ontological requirement that at least one dimension system must be chosen. The Star language feature is referred to as the DimensionSystem and it consists of a set of related location attribute types (e.g. x-coordinate, y-coordinate, z-coordinate, time). The location attributes describe where an entity is in space and time. When these defini-\ntions are used in generating or creating an instance model, type checking can and should be performed to ensure that each attribute type is used (in an instance model or fact transcript construct called the \u201cdimension set expression\u201d) \u2013 this provides for representation expressions that conform to the ROSS requirements for the specification of structure."}, {"heading": "4.6 Feature: Mapping Between Dimension Systems", "text": "Star includes a concept that allows for mapping between dimension systems. For instance this allows common-use everyday relational attributes to be used where greater precision is not needed \u2013 e.g. \u201cArizona is in the south west region of the United States\u201d. The enumerated value that represents \u201csouth west region\u201d can be mapped to a more precise set of locational coordinates such as latitude and longitude. This feature is especially important for natural language story understanding because human dialog is often imprecise with respect to place and time.\nThe ability to translate or map between different dimension systems is viewed as a key feature of ROSS; it is a reflection of how human memory and cognition work. Humans seem to have a general-purpose three-dimensional frame of reference that underlies (perhaps all) representations. The capability for representing the location of things in the physical world often involves smaller \u201ccustomized\u201d frames of reference. An example would be a mental representation that a particular house is at 1000 State Street, in some city. The custom frame of reference has a dimension system that consists of city identification (name), street name and street number. There is a mental capacity for going back and forth between this custom representation and the master (3D) frame of reference."}, {"heading": "4.7 Feature: Specification System", "text": "The specification system definitional construct contains definitions in each of two sections: the dimension system section and the inner content section. The dimension system has already been described. The inner content section either defines a set of attribute types that describes the value of an entity (e.g. the car is blue), or it is a specification of component-wise structure. The specification set expression uses a specification system similar to how the dimension set expression uses a dimension system."}, {"heading": "4.8 Feature: Aggregate Representational Constructs", "text": "The Star language ObjectFrameClass construct allows for the representation of a spatially adjacent aggregation of unit-size objects. An object frame class may represent a single unit-sized object frame or it may represent an aggregation of such units in which case it has the shape of a 3D cuboid."}, {"heading": "4.9 Feature: Structure", "text": "There are two ways to represent mereological structure in ROSS. First, a group of representational constructs enable the representation of structure that involves components: these include the structural parent entity, a set of \u201crelationship to parent\u201d locational attributes and a structure section for aggregate entities that models compositional (\u201cPartOf\") attributes. The infrastructure for representing this type of structure is complex; these features are explained in detail in the upcoming section on Star language definitions. The second approach is the object frame class range, described next."}, {"heading": "4.10 Feature: Object Frame Class Range", "text": "The object frame class range is a special type of aggregate object frame class (composed of multiple spatially adjacent unit-sized location entities that span one, two or all three dimensions). This construct does not have in internal structure that is composed of structural components; rather, it is a sort of drawing canvas on which a picture can be drawn. A simple example would involve a cubical object frame class range in which can be drawn a sphere. The representational construct that is used for the drawing is called a template class (described in the upcoming section on Star language features)."}, {"heading": "4.11 Feature: Multiple Parallel Structures to Support Drill-Down Analysis", "text": "The human cognitive capability for analyzing the structure of a physical object in a \u201cdrill-down\u201d fashion is the basis for a ROSS feature that allows for multiple representations of the same spatial structural area (cuboid region). An example involves a part of a push lawn mower: a mower blade is modeled as a structural component that contains individual parts such as the blade edge; however a parallel structure section consists of a single object frame range class (e.g. using a millimeter grain size). The object frame class range is modeled using a ROSS template,\nwhich in turn is infused using either a set of drawing instructions or a 3D bitmap."}, {"heading": "4.12 Feature: Higher Classes", "text": "The higher class construct allows for the creation of hierarchies of classes. Class inheritance is viewed solely as a way of aggregating or consolidating groups of attributes and structural features \u2013 it is a convenience mechanism, nothing more - higher classes (parent classes) supply additional representational information about a given class. ROSS allows for multiple inheritance (multiple parent classes per class).\nROSS also allows for multiple similar, or parallel, classes, based on the view that some classes, such as a \u201cperson class\u201d are not necessarily a single class, but are so potentially complex that the use of multiple such classes might be needed in order to model a variety of feature collections. Different domains would use different such classes. An example might involve several classes such as PersonAsCountryCitizenClass, PersonAsBiologicalLivingEntityClass, and PersonAsTravellerClass. Each of these would be useful in different domains."}, {"heading": "4.13 Feature: The Attribute", "text": "The Star attribute is an expression that closely corresponds to a FOL atomic sentence that contains a predicate and a term that is a single constant. An attribute is a strongly typed two-part construct. It consists of a pre-defined attribute type name and an attribute value that is a member of a pre-defined attribute value set. The ROSS notion of attribute type and attribute value is roughly the same as that which has been in widespread use in software applications for many years, for instance, the attribute from the field of logical data modeling for databases.\nAn example attribute is:\n<Attribute ref = VehicleExteriorColor\nval = \u201cSilver\u201d />\nThe attribute is composed of the \u201cAttribute\u201d keyword, then the \u201cref\u201d keyword (\u201creference\u201d) followed by an equal sign and a defined attribute type name, and the \u201cval\u201d keyword (\u201cvalue\u201d) followed by a value that had been defined as a member of an attribute value set (the attribute value set that was defined within an attribute type called \u201cVehicleExteriorColor\u201d).\nThe use of attributes rather than predicates (as with logic) provides for a set of criteria for in-\ndexing. For instance, the logic assertion \u201cE(x): Blue(x)\u201d (which can be read \u201cthere exists an object such that the object is blue\u201d), makes use of a predicate that actually corresponds to a Star attribute value, not the attribute type name. Attribute values do not provide a good basis for indexability since they may be members of very large sets. In contrast attribute types are more appropriate as criteria for indexing as it is needed to support queries of structured information.\nROSS attributes are not limited to containing constant values: an attribute value may consist of a value range, a math expression, or a function name that refers to a function that has been defined within the ROSS knowledge base. (An attribute value may also be a reference to a defined template)."}, {"heading": "4.14 Feature: The Two-part Attribute Cluster", "text": "The ROSS two-part attribute cluster is a conceptual feature that can take any of a variety of forms. The two-part attribute cluster satisfies the intuitive concept of a fully specified fact: it represents both the location and the value of an entity that exists in a 4D represented world. A two-part attribute cluster can exist within a class definition in a knowledge base or it may exist within a fact repository artifact. The Star language implementation of the two-part attribute cluster is a representational construct that consists of at least one attribute from the attribute super-type called \u201clocation attribute types\u201d, and at least one attribute from the attribute super-type called \u201cvalue attribute types\u201d. 24 The rationale behind this requirement is that it produces ROSS expressions that fully describe entities from the represented world. (The XML implementation of a two-part attribute cluster, e.g. in an NLU instance model, is not shown here).\nThe two-part attribute cluster is the equivalent of a set of propositions or assertions in logic; where these assertions would include one or more propositions that represent the location of an entity and one or more propositions that represent the value of the same entity.\nThe following is an example of a two-part attribute cluster. (The Star language fragment also\n24\nStar includes a somewhat-skeletal taxonomy of\nattribute types that has two main categories at the top of the tree; these are referred to as \u201cattribute supertypes\u201d: they are the category of location attribute types and the category of value (qualitative) attribute types.\nshows several preliminary definitions, followed by an attachment statement wherein an object frame instance is instantiated). This is a very simple example as might be used for children\u2019s stories; for the sake of brevity it does not show the structural parent and \u201cRelationshipToParent\u201d infrastructure.\n// Definitions\nObjectFrameClass VehicleObjectClass {\nAttributeTypes (\nAttributeType \u201cSpatialLocation\u201d (\n<SuperType val = \u201cLocational\u201d/>\n\u201cValues\u201d (\n\u201cGarage\u201d, \u201cDriveway\u201d, \u201cRoadway\u201d,\n);\n);\nAttributeType \u201cColor\u201d (\n<SuperType val = \u201cQualitative\u201d/>\n\u201cValues\u201d (\n\u201cRed\u201d, \u201cGreen\u201d, \u201cBlue\u201d\n);\n);\n);\n};\n// Attachments (Object Instantiations)\nattach VehicleObjectClass Car1;\n// Assertions\nassert Car1::\n( <Attribute ref = SpatialLocation\nval = \u201cDriveway\u201d />,\n<Attribute ref = Color\nval = \u201cBlue\u201d />\n);\nThe \u201cassert\u201d statement contains an expression that is the two-part attribute cluster: it can be interpreted as \u201cthe entity at the location called \u201cDriveway\u201d has a color value of \u201cBlue\u201d. The essential features of the two-part attribute cluster are illustrated here: it contains at least one locational attribute that specifies the location of the object frame instance (the entity), and at least one value attribute that specifies the infused or populated value of the object frame instance."}, {"heading": "4.15 Feature: The Collection", "text": "The collection is an abstraction that represents a set of object frame instances. The collection con-\ncept addresses the need for an implementation mechanism that corresponds to the universal quantifier of FOL."}, {"heading": "4.16 Feature: Separation of Simple Assertions from Implicative Assertions", "text": "ROSS differentiates assertions into two main groups: those that involve implication (implicative assertions) and those that do not: these are referred to as simple assertions. Simple assertions correspond to a variety of \u201cfact-like\u201d representations, depending on the problem domain, and implicative assertions correspond to rules."}, {"heading": "4.17 Feature: Rule Binder Construct", "text": "ROSS has a feature that is used in implicative assertions (rules) called the \u201cbinder\u201d. 25 A binder is a representational construct that explicitly specifies the locational relationship between all location entities in the antecedent and consequent of a rule."}, {"heading": "4.18 Feature: Representation of Abstract Entities", "text": "ROSS can handle the representation of abstractions that involve entities that have physical attributes that are not relevant to a given domain. Examples of abstract entities can be found in many domains. From the legal realm these include the law suit, tort, jurisdiction, legal action and will. Examples from the area of finance include income, expense and revenue. The areas of human cognitive concepts and mental processes, human emotions and natural language communication include many others. It can be argued that other abstractions include the physics concepts of force, energy and potential.\nThe underlying perspective is that all entities \u2013 whether they are perceived and conceptualized as \u201cconcrete\u201d or abstract are in fact concrete to the extent that they can be rooted in a spatial/temporal frame of reference. The Platonic form or ideal is not allowed existence in ROSS representations since all such supposed forms (e.g. a circle) only actually exist as concepts.\nRepresentation of abstract entities involves grounding of such entities in a physical spatial/temporal frame of reference (for instance, within an NLU instance model, the frame of reference is a structural parent object frame instance). Two approaches are possible: the first approach involves the use of dimension systems\n25\nHofford 2013 the U.S. patent \u201cExpert System and\nmethod\u201d introduced the binder concept.\nthat are skeletal (for instance, those that have less detail than a 3D Cartesian coordinate system). An example would be a dimension system that describes legal jurisdiction using an enumerated list of jurisdictional regions rather than morespecific geographical coordinates. The second approach happens during the assimilation of abstract entities into a structural parent frame of reference when they are instantiated in an instance model; during the attachment process they are imprecisely situated via the use of attribute value ranges.\nAn example involves the representation of revenue and is accomplished as follows. An instance of revenue (e.g. a sale of some item in a particular store) has at least some component in a four-dimensional space-time reality, but the coordinate system that is needed to describe it should be appropriate to the needs of the representation. This requires the use of a dimension system that has enumerated values that indicate time and place values. Secondly, the necessary attribute values are less-descriptive than those for physically concrete domains. For instance, the time at which a particular sales transaction took place may be specified as within the range of the business hours of the store where it was sold (e.g. TimeOfSale = range (9:00am \u2013 6:00pm)). The exact place is not needed, and therefore a general place can be specified (e.g. PlaceOfSale = \u201cMainStreetStore-399\u201d).\nIn many cases, an abstract entity is not one, but in fact an aggregation of multiple entities that exist at disparate places and times \u2013 a law suit would fit in this category. A ROSS fact repository can accommodate this type of aggregate entity \u2013 for instance an NLU instance model would contain specifications of various objects, processes, features, etc. of a law suit, using the standard set of ROSS primitives. However, entities that are involved in the law suit are also described as having attributes that are based on the fact that the humans that are involved have conceptualizations about such entities. E.g. the process of the initial filing of the law suit is performed (physically) by a person or persons, but it is also \u201cknown\u201d by various persons as being a process that involves physical entities that are part of the larger abstraction of the law suit.\nEntity classes that are defined primarily by their behavior are handled by the representational mechanism of the ROSS behavior class. In many situations, the spatial/temporal specifics are of minor importance relative to some essential functionality. An example is the abstraction\nof the physical harm cause that might be said to exist in relation to instances of a person class (this would be any thing \u2013 person or animal, falling rock, etc. that has a potential behavior involving \u201ccauses harm to a person\u201d). A ROSS entity class would be defined (PhysicalHarmCausalAgent) that has a structural parent that is identical to the one used by a threatened persons class. In a fact repository (e.g. NLU instance model) an instantiated instance of PhysicalHarmCausalAgent is an object frame instance that exists at a point on a timeline, having a set of spatial relationship attributes in relation to the harmed person."}, {"heading": "5 Star Language Definitions", "text": "This is an overview of the Star language syntactic features that are used for creating definitions. This section illustrates some of the main representation constructs using examples; other constructs are only briefly described 26 . (Note that comments are preceded by \u201c//\u201d)."}, {"heading": "5.1 Constant Set Name Keywords", "text": "Star contains the following keywords that are names for \u201cbuilt-in\u201d sets of constants:\n IntegerConstant\n FloatingPointConstant (although ROSS value sets are integer-based this is in-\ncluded for completeness)\n StringConstant"}, {"heading": "5.2 Built-in Attribute Super Types", "text": "There are two pre-defined attribute \u201csuper types\u201d, they are higher-level attribute type categories:\n Locational attribute types\n Qualitative attribute types"}, {"heading": "5.3 Built-in Attribute Value Set Super Types", "text": "There are also two pre-defined attribute value set \u201cusage\u201d super types, they correspond to the attribute type super types, and are:\n Locational attribute value set\n Qualitative attribute value set"}, {"heading": "5.4 Built-in Attribute Value Types", "text": "These are not \u201cset types\u201d \u2013 they are special categories for specific attribute values. They are:\n26\nA parser and processor for the Star language does exist that implements most of the features described herein.\n SpaceValue\n NonSpaceValue These categories play a special role in instance\nmodels and in inference."}, {"heading": "5.5 The Dictionary Element", "text": "The version of Star that is used for NLU applications contains an element called \u201cDictionary\u201d that can be used in a variety of contexts. This associates a set of words with a single concept. It has the capacity for multiple language support. In the following example, a Dictionary construct is used within an AttributeType statement in order to create a set of English words for each vehicle exterior color value.\nAttributeType \"VehicleExteriorColor\" (\n<SuperType val = \"QualityAttributeType\"/>\n\"Values\" (\n{ \"Black\": Dictionary\n( English\n( { \"black\", \"charcoal\" } ); ); ,\n\"Blue\": Dictionary\n( English\n( { \"blue\" } ); ); ,\n\"Silver\": Dictionary\n( English\n( { \"silver\", \"grey\" } ); ); ,\n\"White\": Dictionary\n( English\n( { \"white\", \"opal\" } ); );\n}\n);\n);\nA word that is defined within a dictionary element is not limited to use in that element: for instance, the word \u201copal\u201d in the example here may exist in any of a number of other places within other Dictionary elements."}, {"heading": "5.6 Attribute Value Sets", "text": "An attribute value set is defined using the \u201cValueSet\u201d keyword, followed by a value set name, and then by a value set expression. This example defines two value sets, \u201cMillimeter\u201d and \u201cVehiclePhysicalDimension\u201d, which uses Millimeter. A declaration is also included here for the purpose of defining a constant value (the maximum length of a vehicle dimension).\nValueSet \"Millimeter\" (\nIntegerConstant\n); Integer lenMaxVehiclePhysicalDimension =\n12000;\nValueSet \"VehiclePhysicalDimension\" (\n<BaseValueSet ref = Millimeter />\n// UnitOfMeasure\n<SuperTypeUsage val = \"Locational\" />\n{ 1, .. lenMaxVehiclePhysicalDimension }\n);\nThe attribute value sets defined here can subsequently be used in other statements and expressions as needed."}, {"heading": "5.7 Mappings", "text": "Mapping statements are useful for mapping members of one value set to members of another value set. (In the example here, the value sets named \u201cMeter\u201d and \u201cFoot\u201d have already been defined).\nMapping \"MeterToFoot\" (\n<Source ref = Meter /> <Dest ref = Foot /> <Function expr = (x$ * 3.2808) />\n);\nThis can now be used by system processing components that need to convert between members of the value sets."}, {"heading": "5.8 Attribute Types", "text": "The attribute type statement defines an attribute type. An example is as follows:\nAttributeType \"VehicleExteriorColor\" (\n<SuperType val = \"Qualitative\"/>\n\"Values\" (\n{ \"Black\": Dictionary\n( English\n( { \"black\", \"charcoal\" } ); ); ,\n\"Blue\": Dictionary\n( English\n( { \"blue\" } ); ); ,\n\"Silver\": Dictionary\n( English\n( { \"silver\", \"grey\" } ); ); ,\n\"White\": Dictionary\n( English\n( { \"white\", \"opal\" } ); );\n}\n);\n);\nOnce the attribute type has been defined, the defined attribute type name can then be used in other statements and expressions as needed. Where the attribute type is used, type checking can be performed for values that derive from the attribute value set."}, {"heading": "5.9 Dimension System Types", "text": "The dimension system type definition (sometimes referred to as just \u201cdimension system\u201d)\ncreates a dimension system (e.g. a coordinate system), that is used by object frame classes and instances. A dimension system is a means of aggregating attribute types that are intended for collective use into a group in order to fully describe the locational attributes of an object frame instance. (The expression that uses the attribute types in order to specify a specific set of attributes is referred to as a \u201cdimension set expression\u201d). For instance, a dimension system type for description of geographical positions would involve attribute type definitions for each of latitude and longitude. An example dimension system that represents Cartesian coordinates that use the millimeter as a grain size is as follows:\nDimensionSystem \"MillimeterCoordinates\" (\nSpatialAttributeTypes ( \"AttributeTypeX\" ( <SuperType val = \"Locational\"/> \"ValueSet\" ( <BaseValueSet ref = Millimeter /> <SuperTypeUsage val = \" Locational\" /> { 1, .. lenMaxSpatialDimensionMillimeters} ); ); \"AttributeTypeY\" ( <SuperType val = \"Locational\" /> \"ValueSet\" ( <BaseValueSet ref = Millimeter /> <SuperTypeUsage val = \"Locational\" /> { 1, .. lenMaxSpatialDimensionMillimeters } ); ); \"AttributeTypeZ\" ( <SuperType val = \"Locational\"/> \"ValueSet\" ( <BaseValueSet ref = Millimeter /> <SuperTypeUsage val = \"Locational\" /> { 1, .. lenMaxSpatialDimensionMillimeters } ); ); ); // TemporalAttributeTypes\n);\nNote that this dimension system does not include an optional section for temporal attribute types."}, {"heading": "5.10 Specification System Type", "text": "The specification system type incorporates a dimension system and an inner content section in order to create a system that can be used for fully specifying the place and qualitative value of unitsized or aggregate object frame instances. The\nexpression that uses a specification system is called a \u201cspecification set expression\u201d.\nAn example specification system that is useful for specifying the material composition of vehicle parts at the millimeter level of granularity is as follows: SpecificationSystem \"VehiclePartPhysicalComposition\" (\nDimensionSystem \"VehiclePartCoordinates\" (MillimeterCoordinates); InnerContent ( QualityAttributeTypes ( \"EssentialValueAttributeType\" (MaterialCompositionAttributeType); ); );\n);\nNote that the attribute type called \u201cMaterialCompositionAttributeType\u201d is not shown \u2013 this would consist of values such as \u201cAluminum\u201d, \u201cPlastic\u201d, \u201cFabric\u201d, etc."}, {"heading": "5.11 The Attribute", "text": "Attributes have already been described; attributes can exist within object frame classes, described next and they can exist within object frame instances within fact transcripts and instance models. An example of an attribute that belongs with a class would exist within a class for gold coins: all instances of this class can be said to have the attribute of compositionality of gold material."}, {"heading": "5.12 Object Frame Class", "text": "The object frame class is the foundation for representation of the instances that get instantiated and thus exist in a fact transcript or in an NLU instance model. Object frame classes are also used within definitions (within other object frame classes) and in rules. The object frame class structure is shown below (this description includes some NLU-specific features).\nObjectFrameClass ->\nObjectFrameClassName MassSubstance Boolean flag DictionaryPriorWord structure\n// (e.g. for \u201cfire engine\u201d)\nDictionary structure HigherClasses list StructuralParentClassesBase StructuralParentClassesTypicalImmediate RelationshipToParent structure AttributeTypes list Attributes list Templates (used for infusion) RelationshipTypes list DimensionSystems list Structure (list of ObjectFrameClass)\nBehaviorClass list\nThe HigherClasses list represents all higher classes in the optional inheritance hierarchy for an object frame class. For instance, a Car class may get some of its attributes and structure via inheritance from a Vehicle class. The structural parent class items are lists that usually consist of a single item that represents the structural parent class of the object frame class. The RelationshipToParent structure contains attributes that specify how the object frame class is tied to structural parent classes. An example would involve a set of attributes relating an Engine class to a Car class.\nThe Structure item is where unchangeable sub-parts of the class are represented. The BehaviorClass list contains references to behavior classes that can be associated with object frame instances that are instantiated from the object frame class.\nThe following example object frame class illustrates some of the object frame class features: this class would model a simple (old-style) vehicle ignition key. (Most of the detail is not shown here, as indicated by placeholders). ObjectFrameClass \"IgnitionKeyObjectFrameClass\" ( // placeholder: HigherClasses (); StructuralParentClassesBase ( { \"EverydayObjectStructuralParentClass\" } ); // placeholders: RelationshipToParent ( AtLocations (); OrientationSpecifiers (); OuterDimensionSystemExtents (); ); AttributeTypes ( AttributeType \"MaterialCompositionAttributeType\" ( <SuperType val = \"Qualitative\"/> \"Values\" ( <SuperTypeUsage val = \" Qualitative\" /> { \"Steel\", \u201cPlastic\u201d, \u201cFabric\u201d} ); ); ); Attributes ( // The presence here indicates that any instance of this class has this specific attribute: Attribute \"MaterialComposition\"\n( <Attribute ref = MaterialCompositionAttributeType val = \"Steel\" /> ); ); // placeholder: DimensionSystems (); // placeholder: Structure (); ); // IgnitionKeyObjectFrameClass\nThe potential behaviors of this class are not shown (this is explained in what follows). This class can be used to instantiate instances, e.g. in an NLU instance model. (For NLU applications, at the time of instantiation, a structural parent instance that derives from the \u201cEverydayObjectStructuralParentClass\u201d must exist or one will be automatically instantiated). It must be noted that the vehicle ignition key class shown here is dealt with only as a \u201cunit\u201d \u2013 for instance the \u201cMaterialComposition\u201d attribute is an attribute of the whole, not of its parts. The internal structure of such a class is dealt with using other features, as explained next."}, {"heading": "5.13 Explanatory Note: How an Object Frame Class Implements Structure", "text": "Several of the member fields of the object frame class as shown above are used in coordination in order to represent nested physical structures. For instance, to model a vehicle class, a \u201cvehicle\u201d object frame class would be created; it has a set of dimension systems (using the DimensionSystems list). One or more such dimension systems provide a basis for the specification of the location of the sub-part object frame classes of the vehicle class. An engine compartment class is created and added as an item to the Structure list of the vehicle class. Unless its relative place within the vehicle class is specified, the engine compartment class can be said to \u201cfloat\u201d somewhere within the perimeters of the vehicle class. The RelationshipToParent structure of the engine compartment class specifies either specific location attributes of this component in relation to the parent engine class, or it can be used to declare placeholders that are used for such specification in fact repository artifacts when such information is available. These location attributes make use of the dimension system of the parent (the vehicle class), in order to specify both spatial place and spatial size (referred to as \u201cextent\u201d).\nAn advantage of this approach is that it is effective for keeping track of real physical objects that have complex part-subpart structures."}, {"heading": "5.14 Template Class", "text": "The template class can be understood using the metaphor of drawing: a template class describes a method that is used to draw a picture within an object frame range instance. A simple example would be a template class that contains a function to draw an oval within an object frame range instance that has a rectangular shape. A more complex example would involve a set of drawing instructions that can be used for drawing a face, or for the 3D rendering of a person\u2019s head within a cuboid-shaped object frame range instance. The process of drawing/rendering is referred to as \u201cinfusion\u201d."}, {"heading": "5.15 Populated Object Class", "text": "The populated object class is a representational construct that allows for the application of a coordinated set of values to an aggregate object frame class. The process of applying a populated object class to an object frame class is referred to as \u201cpopulation\u201d. Populated object classes are used within behavior classes, described next."}, {"heading": "5.16 Behavior Class", "text": "The behavior class is the basis for describing behaviors. A behavior class associates a set of \u201cprior\u201d states with a set of \u201cpost\u201d states. Examples of behavior classes for the PersonObjectFrameClass class include \u201cPersonWalks\u201d and \u201cPersonCommunicates\u201d. Behavior classes have the following structure:\n A bridge structural parent class \u2013 a reference to an object frame class that con-\ntains a dimension system that must be shared by all object frame classes in the behavior class, so that locational relationships can be specified within the binder construct that ties objects of the prior states section to objects of the post states section.\n A PriorStates section, consisting of a list of populated object classes. This is like\nthe antecedent (the \u201cif part\u201d) within a rule.\n A PostStates section, consisting of a list of populated object classes. This is like\nthe consequent (the \u201cthen part\u201d) within a rule."}, {"heading": "5.17 Explanatory Note: How Behaviors are Related To Object Frame Classes and Instances", "text": "The object frame class and the behavior class have both been described, but the question of how they are related has not been addressed. It must be noted that an object frame class does not actually have behaviors \u2013 it only has a list of potential behaviors. An object frame instance does not have behaviors at all: it only implements states of a behavior at some point along a timeline. For example, within an NLU instance model, each single-time-point object frame instance participates in behaviors via attributes that specify its state. An aggregate object frame instance (at a single time point) can thus participate in multiple behaviors simultaneously due to its having multiple attributes, each of which represent some aspect of its state."}, {"heading": "6 Knowledge Base Concepts", "text": "This section deals with concepts that pertain to ROSS knowledge bases."}, {"heading": "6.1 Knowledge Bases", "text": "A ROSS knowledge base, or Infopedia, contains Star language definitions (and optionally, rules). It includes a mixture of definitions that cross the spectrum from universal and generic to domainspecific. There are generic object frame classes for high-level abstract objects, and moreimmediate object frame classes such as PersonClass and VehicleClass. The Infopedia also contains a variety of supporting definitions for attribute value sets, attribute types, value set mappings, and dimension system types."}, {"heading": "6.2 Knowledge Acquisition/Ontology Derivation", "text": "Learning of classes is an important area that can make use of the features of ROSS. The use of learning techniques is not an absolute necessity since both generic and domain-specific ROSS definitions can be created by a human knowledge engineer or ontology practitioner. (It is more ideal for some ROSS definitions at the higher levels of abstraction to be hand-crafted in advance rather than learned \u2013 e.g. attribute value sets, attribute types and dimension systems). Since knowledge engineering has long been recognized as a bottleneck for AI, automated approaches are viewed as highly valuable. The following are several broad categories of automated knowledge\nacquisition to learn classes and class features from natural language text:\n Intermediate-depth approaches that learn features based on associations. E.g. (unsu-\npervised) learning that cars can be blue based on sentences that associate \u201cblue\u201d with \u201ccar\u201d.\n Learning new sub-classes and their behaviors based on simple sentences of the form\n\u201can x is a y that does z\u201d. (E.g. \u201can electrician is a person who fixes electrical problems\u201d).\n Deeper approaches that learn structure, features and behaviors from NL descrip-\ntions that explicitly describe structure and features. (E.g. a \u201csimple encyclopedia\u201d entry on \u201cautomobile\u201d).\nThe Ontology derivation task is not limited to natural language-based approaches. Other possibilities include the use of interactive tools that such as those that would allow human users to draw objects. Another approach would involve the processing of engineered specifications to generate ROSS classes."}, {"heading": "7 Fact Repository Concepts", "text": "This section deals with concepts that pertain to ROSS fact repositories and with the processes such as instantiation that generate the information that exists in fact repositories."}, {"heading": "7.1 Fact Repositories: Transcripts and Instance Models", "text": "There are a variety of representational artifacts that use the ROSS approach with representational constructs that are fact-like. The term \u201cfactlike\u201d includes representations that are true \u201cfacts\u201d about past situations, and it includes other assertions such as plan goals and predictions. \u201cFact repository\u201d is defined to include any representational artifact containing such constructs. A fact repository has a top-level structure: the repository may represent multiple situations, e.g. situations that are a mixture of ones from the past (from various places and times), others that are present-tense, and some that are hypothetical."}, {"heading": "7.2 Transcript Types", "text": "A transcript is a document that contains fact-like representational constructs for use in AI automated reasoning applications. There are a num-\nber of transcript types that use ROSS. These include the following:\n Past fact transcripts that are useful for automated reasoning about past fact situa-\ntions (e.g. fault diagnosis)\n Specification transcripts for automated inference for design or planning problems;\nthese transcripts contain fact-like constructs that include predicted states and goals"}, {"heading": "7.3 Instance Model", "text": "An instance model is a type of fact repository for NLU: it is a meaning representation instance that represents factual information about past and/or present situations and events. It is an artifact that is a structured representation of the subject matter of an input natural language text fragment such as a story.\nAn instance model contains a list of contexts. The order of contexts in the list usually corresponds to the order of occurrence of sentences in the input text. (The appendix contains a partial instance model)."}, {"heading": "7.4 NLU Instance Model Context", "text": "An instance model context is a representational construct that pertains to a particular space and time frame of reference. (The structure that is contained within a single context is analogous to a diorama). The discourse of a story may have many such contexts. For instance, a story may contain the following two sentences in sequence: \u201cA Seattle home was burglarized late yesterday. John Smith owns the home\u201d. The first sentence is in the past tense and is the basis for a context. The second sentence is in the present tense and thus provides the basis for a second and separate context. An instance model contains at least one context.\nThe context concept may also be used to represent the content of spoken or written communication. In this case it designates a separate frame of reference that represents information that was communicated by a human agent.\nAn instance model context represents a single\nsituation, described next."}, {"heading": "7.5 The Fact Repository Situation", "text": "A fact repository may contain one or multiple situations. A situation is a collection of related facts, each of which involves entities that all share a common structural parent instance."}, {"heading": "7.6 The Structural Parent Class", "text": "Structural parent object frame classes exist in knowledge bases as definitions; structural parent object instances exist in fact repositories, e.g. in instance models."}, {"heading": "7.7 The Structural Parent Instance", "text": "A situation contains a single top-level object frame instance that serves a special function as a \u201cstructural parent\u201d. The structural parent object frame instance has an InstanceStructure section that specifies all object frame instances that are immediate children that are within the spatial and temporal range of the structural parent object frame instance."}, {"heading": "7.8 Object Instances", "text": "The structure of an object frame instance is shown here.\nObjectInstance ->\nObjectFrameClassName ObjectInstanceUniqueIdentifier CausalityRole PersonOrPlaceIndicator RelationshipToParent structure Attributes list Relationships list InstanceStructure (structure containing\nlist of object instances)\nObject instances are instantiated using object frame classes \u2013 thus the first field of an object instance is the object frame class from which it was instantiated. The next field is a unique identifier that refers to the instance as it exists or existed in the space-time frame of reference of the structural parent of the context.\nThe next field, CausalityRole, designates whether the object instance is part of a cause or part of an effect. (NLU-specific: the PersonOrPlace indicator represents information determined by a semantic engine that is used in creating bulleted summaries). If the object instance is the structural child of a parent object instance, the RelationshipToParent structure specifies the specific attributes that relate the child to the parent. The Attribute and Relationship lists contain attribute and relationship attribute information about the object instance. Finally, the InstanceStructure is a collection of references to all child instances. For instance, the representation of a \u201ccar\u201d instance would typically contain object instances here for \u201cengine\u201d, \u201ctransmission\u201d, \u201cbody frame\u201d, etc."}, {"heading": "7.9 Instantiation", "text": "Instantiation is the process of creating an object frame instance within a fact repository from an object frame class; it involves the sub-tasks of attachment and of infusion or population. (For purposes of illustration, each of these concepts is described here in terms how it is performed by a NLU semantic engine, e.g. when the engine generates an object instance within an instance model)."}, {"heading": "7.10 Attachment", "text": "Attachment is the process of creating an object frame instance. When a structural parent object frame instance is created within a situation, it is simply given a unique identifier or name. However when an object frame instance that is a child of a structural parent, or of other object frame instances is created, attachment involves creating the instance, giving it an identifier or name, and then setting its RelationshipToParent attributes. It also involves specifying a reference to the child instance within the InstanceStructure section of the parent instance.\nThe effect of performing a group of attachments can be visualized as analogous to a process of creating a diorama frame and then inserting various empty smaller wire-frame structures (some nested within others) into it."}, {"heading": "7.11 Infusion and Population", "text": "The process of infusion operates on empty object frame instances: it sets actual values for them. Infusion as applied to a unit-sized object frame instance just involves setting its value. Infusion of a value into an object frame range instance makes use of a template class. Population is similar to infusion and involves using a populated object class to set the values of an aggregate object frame instance."}, {"heading": "7.12 Permanence and Perpetuation", "text": "Practical considerations of creation and maintenance of representations in a fact repository artifact may necessitate the use of convenience assumptions (described in the above Ontology section). The first of these is the empty space assumption: within a structural parent (similar to a diorama), at the first time point and for all subsequent time points, any unit-sized location that has not been specifically and overtly infused or populated is assumed to have a value that inherits from the SpaceValue value category.\nThe perpetuation assumption involves perpetuation along a time line; it can be used in similar fashion as the empty space assumption: the assumption is that for any unit-sized location that has been infused with a value at time t=n, it can be assumed that the subsequent unit-sized location at the same spatial location (at time t=(n+1)) will have the same value unless it is overtly specified to have a different value. This assumption is useful for stationary objects but does not address the representation of objects in motion."}, {"heading": "8 Automation of Inference", "text": "The representational features of ROSS provide a foundation for automated reasoning that is openended and unrestricted due to the loose coupling between representation and reasoning. The following are a few examples of broad categories of reasoning tasks that can be accomplished using the ROSS method:\n Reasoning about situations and events that occurred in the past to perform past\nfact derivation. This category includes diagnosis of faults/failures.\n Reasoning from requirements specifications to generate design artifacts.\n Reasoning from plan goals to generate plans.\nDetailed information on the structure of rules and about the reasoning algorithms of the expert system for diagnosis that was developed by the author is available in Hofford (2013)."}, {"heading": "9 NLU: Semantic Processing", "text": "ROSS has capabilities that are important for NLU semantic analysis and processing. A semantic engine that is part of a modular NLU system (one that separates the syntactic processing stage from the semantic processing stage) is briefly described. The area of story comprehension \u2013 a restricted subset of the very broad range of NLU tasks - is used for purposes of demonstrating the operation of such a system as it uses and produces ROSS-based information."}, {"heading": "9.1 Data Flow", "text": "The semantic engine of such a system requires a set of Star language definitions as input. These definitions include supporting definitions, object frame classes and behavior classes. The Star language definitions are stored in text files and are read in at the time of system initialization and\nused to build an in-memory knowledge base (the Infopedia).\nThe second main input to the engine is a list of syntax trees that contain semantic role and other information. Each syntax tree in the list represents a single sentence; sentences may be nested within sentences.\nThe main output of the engine is an instance\nmodel."}, {"heading": "9.2 Class Selection Algorithm", "text": "An important task for the engine is that of class selection. For instance, the input may describe a \u201ccar\u201d. ROSS is not limited to a single \u201ccar class\u201d \u2013 there may be any of a number of classes that represent \u201ccar\u201d, each of which emphasizes some set of aspects of a car. For instance, employees in an automobile manufacturing plant would have a concept of car that differs in many ways from the concept of car that is used by consumers who are drivers. Each car class would associate the word \u201ccar\u201d with itself using the Star Dictionary element. The task of disambiguation in order to select the most appropriate class is potentially open-ended; a variety of heuristics and inference techniques may be used."}, {"heading": "9.3 Integration of the Syntactic and Semantic Phases", "text": "Automated reasoning by the NLU engine in order to provide feedback to the natural language parser for purposes of disambiguation is an area of ongoing research."}, {"heading": "10 Conclusion", "text": "In comparison with logic and other AI representational schemes, the essence of the ROSS approach centers on its ontological restrictions, or restrictions for modeling. This ontological framework is rooted in a na\u00efve view that uses discreteness of space and time as a basis. The benefits are very substantial in how it enables modeling and representations that are very rich and that are appropriate in semantic complexity for the comprehensive and well-organized representation of domains. The ROSS ontological restrictions and commitments provide a set of guidelines for the task of knowledge base creation and refinement. Furthermore, these restrictions facilitate the creation of fact representations that are highly structured, unambiguous and non-redundant. The ROSS framework for representing physical structure \u2013 using dimension systems, the structural features of the object\nframe class, and the structural parent instance concept - is beneficial for providing a frame of reference that provides an organizing infrastructure for the representation of relational attributes (the normal form). ROSS instance representations are implicitly hybrid, combining an analogical approach with a symbolic approach. The analogical aspect is present due to the use of a structural parent instance (as it houses a base/master dimension system). When this is used as a foundation for ROSS normal form information (e.g. instantiations of shape templates), the resultant fact instance representations provide for query (as against structured information) and are a platform for inference.\nThe ROSS approach to class hierarchies is bottom-up rather than top-down. The instantiation process that uses classes to create instances (e.g. in NLU instance models) starts from the perspective of assuming too little, not too much. For instance, during the NLU semantic processing phase, few details may be known about an instance of a class represented by a term in the input text; therefore ROSS starts with fewer assumptions about its class instance features, structure and attributes.\nSecondary information can be derived from primary information and stored in the same fact repository. ROSS normal form provides a foundation; the infrastructure (e.g. of an instance model) is flexible so that additional information such as relationships can be stored in the same artifact. Derived information such as collections also fits into the same representational artifact.\nThe richness of the ROSS approach has implications for the representation of commonsense knowledge \u2013 this has value for areas such as NLU story comprehension."}, {"heading": "10.1 Ongoing Research", "text": "A number of challenges have provided motivation for further research; they include:\n Coordination of the ROSS discrete model with representations of continuous phenom-\nena.\n Ontology derivation/knowledge acquisition.\n Integration of probabilistic information, e.g. classes with fuzzy boundaries.\n Integration of procedural \u201csub-symbolic\u201d connectionist approaches (e.g. neural net-\nworks) with ROSS.\nReference\nJames F. Allen. 1983. Maintaining Knowledge\nAbout Temporal Intervals, Communications of the ACM , 26(11):832-843.\nFranz Baader, Diego Calvanese, Deborah L.\nMcGuinness, Daniele Nardi, and Peter F. PatelSchneider. 2007. The Description Logic Handbook: Theory, Implementation and Applications, Second Edition, Cambridge University Press, Cambridge.\nRonald J. Brachman and Hector J. Levesque. 1985.\nA Fundamental Tradeoff in Knowledge Representation and Reasoning (Revised Version), Proc. CSCSI-84, London, Ontario, 141-152.\nRonald J. Brachman and James G. Schmolze. 1985.\nAn Overview of the KL-ONE Knowledge Representation System, Cognitive Science 9:171-216.\nCharles J. Fillmore. 1982. Frame semantics, in Lin-\nguistics in the Morning Calm. Hanshin Publishing Co., Seoul, 111-137.\nW.K.C. Guthrie. 1950. The Greek Philosophers:\nFrom Thales to Aristotle, Methuen & Company Limited, London, (reprinted 1975: Harper Colophon).\nStevan Harnad. 1990. The Symbol Grounding Prob-\nlem, Physica D, 42:335-346.\nPatrick J. Hayes. 1974. Some Problems and Non-\nProblems in Representation Theory, Proc. AISB Summer Conference, University of Sussex, 63-79.\nPatrick J. Hayes. 1985. Naive physics I: Ontology\nfor liquids, in: J. Hobbs and R. Moore (eds.), Formal Theories of the Commonsense World, Ablex, Norwood, NJ, 71-108.\nPatrick J. Hayes. 1996. A Catalog of Temporal The-\nories, Technical Report, UIUC-BI-AI-96-01, University of Illinois.\nGlenn Hofford. 2001. Expertise through Rules Based\nRepresentation: Why Can\u2019t a Computer Program Write Computer Programs?, in: PC AI, September/October 2001, Knowledge Technology, Inc. Phoenix.\nGlenn Hofford. 2010. Star: An Executable Software\nSystem Specification Language, Ip.com: http://ip.com/IPCOM/000202126, (04-Dec-2010), Available at http://www.softwareengineeringconcepts.com/Star Language2001Overview.pdf. Last accessed April 2014.\nGlenn Hofford, U.S. Patent 8,407,169 Expert system\nand method (issued March 26, 2013).\nBenjamin Johnston. 2011. The Collection of Physi-\ncal Knowledge and its Application in Intelligent\nSystems, International Conference on Artificial General Intelligence (2011).\nDaniel Jurafsky and James H. Martin. 2009. Speech\nand Language Processing, An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition (Second Edition) Pearson Education, Inc., Upper Saddle River, New Jersey.\nMarvin Minsky. 1981. A Framework for Represent-\ning Knowledge, Mind Design, ed. J. Haugeland, The MIT Press, Cambridge, MA, 95-128.\nMarvin Minsky. 1986. The Society of Mind, Simon\n& Schuster, New York.\nErik T. Mueller. 2006. Commonsense Reasoning,\nMorgan Kaufmann, San Francisco.\nAdam Nash. 2013. \u201cMake Things As Simple As\nPossible, But Not Simpler\u201d, Available at http://blog.adamnash.com/2013/09/25/makethings-as-simple-as-possible-but-not-simpler/ Last accessed April 2014.\nStuart J. Russell and Peter Norvig. 2003. Artificial\nIntelligence, A Modern Approach, (Prentice Hall), Pearson Education, Inc., Upper Saddle River, NJ.\nMurray Shanahan. 1997. Solving the Frame Prob-\nlem, A Mathematical Investigation of the Common Sense Law of Inertia, The MIT Press, Cambridge, MA.\nAllen Newell and Herbert A. Simon. 1976. Comput-\ner science as empirical inquiry: Symbols and search, Communications of the ACM, 19(3):113- 126.\nWillard Van Orman Quine. 1948. On What There Is,\nReview of Metaphysics, 1, 21-38. Reprinted in Willard Van Orman Quine. From a Logical Point of View: Logico-philosophical essays, Harvard University Press, 1953. Revised and reprinted later.\nBertrand Russell. 1945. A History of Western Phi-\nlosophy, Simon & Schuster, Inc., New York.\nBrian Cantwell Smith. 1982. Procedural Reflection\nin Programming Languages (vol. 1), Massachusetts Institute of Technology, Cambridge, MA.\nJohn F. Sowa. 2000. Knowledge Representation,\nLogical, Philosophical, and Computational Foundations, Brooks/Cole, Pacific Grove, CA.\nJohn F. Sowa. 2006. The Challenge of Knowledge\nSoup, in Research Trends in Science, Technology and Mathematics Education, ed. J. Ramadas & S. Chunawala, Homi Bhabha Centre, Mumbai.\nAlfred Tarski. 1927. Foundations of the Geometry of\nSolids, transl. J. Woodger, in: Logic, Semantics, Metamathematics, Papers from 1923 to 1938, Copyright 1983, Hackett Publishing Company, Inc., Indianapolis, Indiana, 24-29.\nTerry Winograd, \"Procedures as a Representation for\nData in a Computer Program for Understanding Natural Language\", MIT AI Technical Report 235, February 1971.\nWilliam A. Woods. 1975. What\u2019s in a Link: Founda-\ntions for Semantic Networks, in: Representation and Understanding: Studies in Cognitive Science, ed. D. Bobrow and A. Collins, Academic Press, New York, 35-82. Reprinted in R.Brachman and H. Levesque (eds.), Readings in Knowledge Representation, Morgan Kaufmann, San Mateo, 1985.\nAppendix: XML Instance Model (showing partial detail)\n{ Notes:\n- this is a fragment of an NLU instance model that contain an instance of a house cat (it is part of an instance model that can represent the sentence \u201cA cat is on a mat.\u201d) - the class names, e.g. HouseCatObjectFrameClass would have been defined in a knowledge base - this demonstrates the use of a timeline within a structural parent instance\n}\n<?xml version=\"1.0\" encoding=\"us-ascii\" standalone=\"yes\"?> <InstanceModel> <!\u2014NOT SHOWN: Source document information section --> <ConceptualModel> <GlobalAssumptions> <!-- Any location that has not been infused has a value that inherits from the \"EmptySpace\" value category --> <EmptySpaceAssumption value =\"true\" /> <!-- Attached objects are permanent through time --> <PermanentAttachmentsAssumption value = \"true\" /> <!-- Stationary values at t = n perpetuate forward in time --> <PerpetuationAssumption value =\"true\" /> </GlobalAssumptions> <!-- The following element attaches the main structural parent instance. This instance is analogous to a diorama. --> <StructuralParent class=\"EverydayObjectStructuralParentClass\" name=\"EverydayObjectStructuralParentInstance-1\" type=\"Range\" timeline=\"EverydayObjectStructuralParentClass.EverydayObjectBasicDimensionSystem\"> <TimePoint value = \"T01\"> <!-- The InstanceStructure element contains attachments, attributes, and templatebased infusions for each of the main components within the main structural parent instance. Each object frame instance, e.g. the cat, is analogous to an empty wire frame within the diorama.--> <InstanceStructure> <Component class=\"HouseCatObjectFrameClass\" name=\"CatObjectFrameClass-Instance1\" type=\"Aggregate\"> <!\u2014 Aggregate indicates it has components --> <!\u2014NOT SHOWN: - RelationshipToParent attributes (AtLocations, OrientationSpecifiers, Extents) - Infused values - Attributes of the whole, e.g. Height = 225 mm, e.g. FurColor = grey - Relationships of this instance, e.g. the distance to the mat - InstanceStructure, containing components, e.g. the cat\u2019s head and body -> Components such as cat\u2019s head may use templates or shape templates for infusions so that the 3D region has a set of populated values (representing a cat\u2019s head) --> </Component> </InstanceStructure> </TimePoint> </StructuralParent> </ConceptualModel> </InstanceModel>"}], "references": [{"title": "Maintaining Knowledge About Temporal Intervals, Communications of the ACM", "author": ["James F. Allen"], "venue": null, "citeRegEx": "Allen.,? \\Q1983\\E", "shortCiteRegEx": "Allen.", "year": 1983}, {"title": "The Description Logic Handbook: Theory, Implementation and Applications, Second Edition", "author": ["Franz Baader", "Diego Calvanese", "Deborah L. McGuinness", "Daniele Nardi", "Peter F. PatelSchneider"], "venue": null, "citeRegEx": "Baader et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Baader et al\\.", "year": 2007}, {"title": "A Fundamental Tradeoff in Knowledge Representation and Reasoning (Revised Version), Proc", "author": ["Ronald J. Brachman", "Hector J. Levesque."], "venue": "CSCSI-84, London, Ontario, 141-152.", "citeRegEx": "Brachman and Levesque.,? 1985", "shortCiteRegEx": "Brachman and Levesque.", "year": 1985}, {"title": "An Overview of the KL-ONE Knowledge Representation System, Cognitive Science 9:171-216", "author": ["Ronald J. Brachman", "James G. Schmolze"], "venue": null, "citeRegEx": "Brachman and Schmolze.,? \\Q1985\\E", "shortCiteRegEx": "Brachman and Schmolze.", "year": 1985}, {"title": "Frame semantics, in Linguistics in the Morning Calm", "author": ["Charles J. Fillmore."], "venue": "Hanshin Publishing Co., Seoul, 111-137.", "citeRegEx": "Fillmore.,? 1982", "shortCiteRegEx": "Fillmore.", "year": 1982}, {"title": "The Greek Philosophers: From Thales to Aristotle", "author": ["W.K.C. Guthrie"], "venue": "Methuen & Company Limited,", "citeRegEx": "Guthrie.,? \\Q1950\\E", "shortCiteRegEx": "Guthrie.", "year": 1950}, {"title": "Some Problems and NonProblems in Representation Theory, Proc", "author": ["Patrick J. Hayes."], "venue": "AISB Summer Conference, University of Sussex, 63-79.", "citeRegEx": "Hayes.,? 1974", "shortCiteRegEx": "Hayes.", "year": 1974}, {"title": "Naive physics I: Ontology for liquids, in: J", "author": ["Patrick J. Hayes."], "venue": "Hobbs and R. Moore (eds.), Formal Theories of the Commonsense World, Ablex, Norwood, NJ, 71-108.", "citeRegEx": "Hayes.,? 1985", "shortCiteRegEx": "Hayes.", "year": 1985}, {"title": "A Catalog of Temporal Theories, Technical Report, UIUC-BI-AI-96-01, University of Illinois", "author": ["Patrick J. Hayes"], "venue": null, "citeRegEx": "Hayes.,? \\Q1996\\E", "shortCiteRegEx": "Hayes.", "year": 1996}, {"title": "Expertise through Rules Based Representation: Why Can\u2019t a Computer Program Write Computer Programs?, in: PC AI, September/October 2001, Knowledge Technology, Inc", "author": ["Glenn Hofford."], "venue": "Phoenix.", "citeRegEx": "Hofford.,? 2001", "shortCiteRegEx": "Hofford.", "year": 2001}, {"title": "Star: An Executable Software System Specification Language, Ip.com: http://ip.com/IPCOM/000202126, (04-Dec-2010), Available at http://www.softwareengineeringconcepts.com/Star", "author": ["Glenn Hofford"], "venue": null, "citeRegEx": "Hofford.,? \\Q2010\\E", "shortCiteRegEx": "Hofford.", "year": 2010}, {"title": "Patent 8,407,169 Expert system and method", "author": ["U.S. Glenn Hofford"], "venue": "(issued March", "citeRegEx": "Hofford,? \\Q2013\\E", "shortCiteRegEx": "Hofford", "year": 2013}, {"title": "The Collection of Physical Knowledge and its Application in Intelligent", "author": ["Benjamin Johnston"], "venue": null, "citeRegEx": "Johnston.,? \\Q2011\\E", "shortCiteRegEx": "Johnston.", "year": 2011}, {"title": "Speech and Language Processing, An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition (Second Edition", "author": ["Daniel Jurafsky", "James H. Martin"], "venue": null, "citeRegEx": "Jurafsky and Martin.,? \\Q2009\\E", "shortCiteRegEx": "Jurafsky and Martin.", "year": 2009}, {"title": "A Framework for Representing Knowledge, Mind Design, ed", "author": ["Marvin Minsky."], "venue": "J. Haugeland, The MIT Press, Cambridge, MA, 95-128.", "citeRegEx": "Minsky.,? 1981", "shortCiteRegEx": "Minsky.", "year": 1981}, {"title": "The Society of Mind, Simon", "author": ["Marvin Minsky"], "venue": null, "citeRegEx": "Minsky.,? \\Q1986\\E", "shortCiteRegEx": "Minsky.", "year": 1986}, {"title": "Make Things As Simple As Possible, But Not Simpler", "author": ["Adam Nash"], "venue": "Available at http://blog.adamnash.com/2013/09/25/makethings-as-simple-as-possible-but-not-simpler/ Last accessed April", "citeRegEx": "Nash.,? \\Q2013\\E", "shortCiteRegEx": "Nash.", "year": 2013}, {"title": "Artificial Intelligence, A Modern Approach, (Prentice", "author": ["Stuart J. Russell", "Peter Norvig"], "venue": null, "citeRegEx": "Russell and Norvig.,? \\Q2003\\E", "shortCiteRegEx": "Russell and Norvig.", "year": 2003}, {"title": "Solving the Frame Problem, A Mathematical Investigation of the Common Sense Law of Inertia", "author": ["Murray Shanahan"], "venue": null, "citeRegEx": "Shanahan.,? \\Q1997\\E", "shortCiteRegEx": "Shanahan.", "year": 1997}, {"title": "Computer science as empirical inquiry: Symbols and search", "author": ["Allen Newell", "Herbert A. Simon"], "venue": "Communications of the ACM,", "citeRegEx": "Newell and Simon.,? \\Q1976\\E", "shortCiteRegEx": "Newell and Simon.", "year": 1976}, {"title": "On What There Is, Review of Metaphysics, 1, 21-38", "author": ["Willard Van Orman Quine."], "venue": "Reprinted in Willard Van Orman Quine. From a Logical Point of View: Logico-philosophical essays, Harvard University Press, 1953. Revised and reprinted later.", "citeRegEx": "Quine.,? 1948", "shortCiteRegEx": "Quine.", "year": 1948}, {"title": "A History of Western Philosophy, Simon", "author": ["Bertrand Russell"], "venue": null, "citeRegEx": "Russell.,? \\Q1945\\E", "shortCiteRegEx": "Russell.", "year": 1945}, {"title": "Procedural Reflection in Programming Languages (vol", "author": ["Brian Cantwell Smith."], "venue": "1), Massachusetts Institute of Technology, Cambridge, MA.", "citeRegEx": "Smith.,? 1982", "shortCiteRegEx": "Smith.", "year": 1982}, {"title": "Knowledge Representation, Logical, Philosophical, and Computational Foundations, Brooks/Cole, Pacific", "author": ["John F. Sowa"], "venue": null, "citeRegEx": "Sowa.,? \\Q2000\\E", "shortCiteRegEx": "Sowa.", "year": 2000}, {"title": "The Challenge of Knowledge Soup, in Research Trends in Science, Technology and Mathematics Education, ed", "author": ["John F. Sowa."], "venue": "J. Ramadas & S. Chunawala, Homi Bhabha Centre, Mumbai.", "citeRegEx": "Sowa.,? 2006", "shortCiteRegEx": "Sowa.", "year": 2006}, {"title": "Foundations of the Geometry of Solids, transl", "author": ["Alfred Tarski."], "venue": "J. Woodger, in: Logic, Semantics, Metamathematics, Papers from 1923 to 1938, Copyright 1983, Hackett Publishing Company, Inc., Indianapolis, Indiana, 24-29.", "citeRegEx": "Tarski.,? 1927", "shortCiteRegEx": "Tarski.", "year": 1927}, {"title": "Procedures as a Representation for Data in a Computer Program for Understanding Natural Language\", MIT AI", "author": ["Terry Winograd"], "venue": "Technical Report", "citeRegEx": "Winograd,? \\Q1971\\E", "shortCiteRegEx": "Winograd", "year": 1971}, {"title": "What\u2019s in a Link: Foundations for Semantic Networks, in: Representation and Understanding: Studies in Cognitive Science, ed", "author": ["William A. Woods."], "venue": "D. Bobrow and A. Collins, Academic Press, New York, 35-82. Reprinted in R.Brachman and H.", "citeRegEx": "Woods.,? 1975", "shortCiteRegEx": "Woods.", "year": 1975}, {"title": "Readings in Knowledge Representation", "author": ["Levesque (eds"], "venue": null, "citeRegEx": ".eds.,? \\Q1985\\E", "shortCiteRegEx": ".eds.", "year": 1985}], "referenceMentions": [{"referenceID": 13, "context": "Existing meaning representation approaches include first order logics, semantic networks, and frame-based approaches (Jurafsky and Martin, 2009).", "startOffset": 117, "endOffset": 144}, {"referenceID": 19, "context": "Newell and Simon (1976) for a general definition of a physical symbol system.", "startOffset": 0, "endOffset": 24}, {"referenceID": 22, "context": "scribed in Smith (1982). 3 The term \u201centity\u201d is used somewhat imprecisely", "startOffset": 11, "endOffset": 24}, {"referenceID": 6, "context": "ROSS is a method that fits the definition of \u201crepresentational scheme\u201d (Hayes, 1974).", "startOffset": 71, "endOffset": 84}, {"referenceID": 26, "context": "An example is the SHRDLU system of Terry Winograd, which focused on commonsense reasoning about simple domains and questionanswering (Winograd, 1971).", "startOffset": 133, "endOffset": 149}, {"referenceID": 24, "context": "Within the field of natural language understanding, (Sowa, 2006) describes the shift that took place during the 1980\u2019s on the part of Terry Winograd and others:", "startOffset": 52, "endOffset": 64}, {"referenceID": 16, "context": "6 Nash (2013): a blog post entitled \u201cMake Things As", "startOffset": 2, "endOffset": 14}, {"referenceID": 26, "context": "Terry Winograd, for example, called his first book Understanding Natural Language (1972) and his second book Language as a Cognitive Process: Volume I, Syntax (1983).", "startOffset": 6, "endOffset": 89}, {"referenceID": 26, "context": "Terry Winograd, for example, called his first book Understanding Natural Language (1972) and his second book Language as a Cognitive Process: Volume I, Syntax (1983). But he abandoned the projected second volume on semantics when he realized that no existing semantic theory could explain how anyone, human or computer, could understand language.", "startOffset": 6, "endOffset": 166}, {"referenceID": 26, "context": "Terry Winograd, for example, called his first book Understanding Natural Language (1972) and his second book Language as a Cognitive Process: Volume I, Syntax (1983). But he abandoned the projected second volume on semantics when he realized that no existing semantic theory could explain how anyone, human or computer, could understand language. With his third book, coauthored with the philosopher Fernando Flores, Winograd (1986) switched to his later work on the design of human-computer interfaces.", "startOffset": 6, "endOffset": 433}, {"referenceID": 14, "context": "7 Minsky (1981) originated the frame concept;", "startOffset": 2, "endOffset": 16}, {"referenceID": 3, "context": "9 Minsky (1981), Brachman and Schmolze (1985) Secondly, this should be done in a way that is flexible, so that when instances get instantiated based on an entity class, they are created with a basic structure, but only the specifics that are known are specified.", "startOffset": 17, "endOffset": 46}, {"referenceID": 4, "context": "In the field of natural language understanding, a related perspective was provided by Fillmore (1982). In his introduction to semantic frames, he states \u201cBy the term \u2018frame\u2019 I have in mind any system of concepts related in such a way that to understand any one of them you have to understand the whole structure in which it fits; when one of the things in such a structure is introduced into a text, or into a con-", "startOffset": 86, "endOffset": 102}, {"referenceID": 27, "context": "15 Woods (1975) (III.", "startOffset": 3, "endOffset": 16}, {"referenceID": 2, "context": "Brachman and Levesque (1985) discuss the spectrum of KR formalisms with respect to the level of expressiveness (from the simpler database schemes to the fully expressive FOL).", "startOffset": 0, "endOffset": 29}, {"referenceID": 11, "context": "ROSS has been successfully applied in three separate systems: an expert system computer program generator (Hofford, 2001 and 2010), an expert system for diagnosis of network faults (Hofford, 2013), and a representational technique that exists in a natural language understanding system (referred to as \u201cModelBuilder\u201d).", "startOffset": 181, "endOffset": 196}, {"referenceID": 21, "context": "Russell (1945) was a critic of Aristotle\u2019s taxonomy; he provides an interesting perspective:", "startOffset": 0, "endOffset": 15}, {"referenceID": 20, "context": "The influential work of Quine (1948) acknowledges two kinds of existence: physical things, like the continent of Australia, and abstract things \u2013 e.", "startOffset": 24, "endOffset": 37}, {"referenceID": 5, "context": "The earliest known proponents of an atomic theory appear to have been the Greek philosophers Leucippus and Democritus (Guthrie, 1950).", "startOffset": 118, "endOffset": 133}, {"referenceID": 23, "context": "Sowa (2000) - Aristotle\u2019s concept of monads", "startOffset": 0, "endOffset": 12}, {"referenceID": 0, "context": "22 Some references for this area include Allen (1983),", "startOffset": 41, "endOffset": 54}, {"referenceID": 6, "context": "The work of Hayes (1985) in the area of qualitative physics uses a four-dimensional approach.", "startOffset": 12, "endOffset": 25}, {"referenceID": 9, "context": "Detailed information on the structure of rules and about the reasoning algorithms of the expert system for diagnosis that was developed by the author is available in Hofford (2013).", "startOffset": 166, "endOffset": 181}], "year": 2014, "abstractText": "Representation is a cross-discipline topic that includes knowledge representation from the field of artificial intelligence, meaning representation from the field of natural language understanding, and structured information from information processing. The field of logic is replete with methods for representation and reasoning. In the areas of AI knowledge representation and reasoning, leading approaches include first order logic, description logic, lambda calculus, semantic networks, framebased approaches and many others. Meaning representation techniques from the field of natural language understanding include the above in addition to approaches like conceptual dependency. ROSS (\u201cRepresentation, Ontology, Structure, Star\u201d) is introduced as a new method for representation that emphasizes representational constructs for physical structure. The ROSS approach starts with a normal form that is self-consciously less-expressive than logic, and builds from the bottom-up to achieve the expressiveness that is needed for a domain. Information that uses the normal form exists within an analogical frame of reference. What is achieved is a greater degree of structure in the representations that use ROSS when compared with representations that are typically created using formal approaches such as FOL. The ROSS normal form involves a set of modeling guidelines and underlying ontological commitments that involve naive or intuitionistic", "creator": "Microsoft\u00ae Office Word 2007"}}}