{"id": "1412.1913", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Dec-2014", "title": "A Portfolio Approach to Algorithm Selection for Discrete Time-Cost Trade-off Problem", "abstract": "it has been currently known that performance of optimization for np - hard problems varies from instance to instance. this phenomenon has been observed, when teams comprehensively study multi - objective evolutionary algorithms ( moeas ) on a six benchmark matching of discrete time - cost squared - off problem ( dtctp ). instead of using this algorithm to solve dtctp, we use generic portfolio approach that takes multiple algorithms as its constituent. on this paper, we proposed portfolio comprising of four moeas, weighted - dominated sorting genetic algorithm 4 ( nsga 6 ), the strength pareto ea 2 ( spea 2 ), spectral archive evolutionary strategy ( paes ) and niched pareto genetic algorithm 2 ( rr 2 ) independently solve dtctp. the result shows that the portfolio approach exists noticeably fast and qualitatively superior toward its constituent algorithms for all benchmark instances. moreover, portfolio approach provides an insight in predicting the best algorithm for all instances of dtctp.", "histories": [["v1", "Fri, 5 Dec 2014 07:58:30 GMT  (527kb)", "http://arxiv.org/abs/1412.1913v1", "Working Paper"], ["v2", "Thu, 10 Aug 2017 16:48:09 GMT  (601kb)", "http://arxiv.org/abs/1412.1913v2", null]], "COMMENTS": "Working Paper", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["santosh mungle"], "accepted": false, "id": "1412.1913"}, "pdf": {"name": "1412.1913.pdf", "metadata": {"source": "CRF", "title": "A Portfolio Approach to Algorithm Selection for Discrete Time-Cost Trade-off Problem", "authors": ["Santosh Mungle"], "emails": [], "sections": [{"heading": null, "text": "instance to instance. This phenomenon has been observed, when we comprehensively studied multi-objective evolutionary algorithms (MOEAs) on a six benchmark instances of discrete timecost trade-off problem (DTCTP). Instead of using single algorithm to solve DTCTP, we use a portfolio approach that takes multiple algorithms as its constituent. In this paper, we proposed portfolio comprising of four MOEAs, Non-dominated sorting genetic algorithm 2 (NSGA 2), the strength Pareto EA 2 (SPEA 2), Pareto archive evolutionary strategy (PAES) and Niched Pareto Genetic Algorithm 2 (NPGA 2) to solve DTCTP. The result shows that the portfolio approach is computationally fast and qualitatively superior than its constituent algorithms for all benchmark instances. Moreover, portfolio approach provides an insight in selecting the best algorithm for all instances of DTCTP.\nKeywords: Time-cost trade-off, Algorithm portfolio, Multi-objective optimization. \u00a0"}, {"heading": "1. Introduction", "text": "The discrete time-cost trade-off problem (DTCTP) is an important aspect in the scheduling of construction project. In project planning and scheduling, selection of appropriate resources including crew sizes, equipment, methods and technologies to carry out a project are challenging decisions. These decisions ultimately affect the duration and cost of the project. In practice, if project is running behind the scheduled plan, acceleration of activity becomes essential by allowing additional resources which ultimately incurs additional cost (De et al., 1997). DTCTP is a process to identify a suitable activity for speeding up, and deciding \u201cby how much\u201d so as to attain the best possible savings in both time and cost (Zheng et al., 2005). Such optimization process includes hidden trade-off relationship between time and cost. This will create complex\nsituation for decision maker\u2019s to predict whether the total cost (i.e., the direct and indirect costs) would increase or decrease as a result of the schedule compression.\nOver the last few decades, various approaches have been proposed to optimize time and\ncost. They can be broadly classified based on mathematical models or heuristics. Many researchers developed new mathematical models by using linear programming, integer programming or dynamic programming to solve the time-cost optimization problem (Robinson, 1975; Siemens, 1971; Goyal, 1975). Heuristic or mathematical models showed both strengths and weaknesses in solving DTCTP. The heuristic approaches select the activities to be shortened or expanded based on certain selection criteria, which do not guarantee optimal solutions. On the other hand, mathematical models require great computational effort and some approaches do not provide the optimal solution either. In addition, for large-scale networks (several hundred activities with discrete time-cost relationships, which are common for most construction projects), neither heuristic methods nor mathematical models can offer optimal solutions efficiently (Ozgen, 2009). DTCTP is known as strong NP-hard problem that failed to maintain pseudo-polynomial time guarantee for complex project network using exact solution algorithms (De et al., 1997).\nRecently, many researchers proposed various metaheuristics such as genetic algorithm\n(GA), ant colony optimization (ACO), simulated annealing (SA) etc. to solve the DTCTP for large-scale networks to obtain near-optimal Pareto solution (Ozgen, 2009; Chassiakos and Sakellaropoulos, 2005; Feng and Liu, 1997; Pour et al., 2010; Zheng et al., 2004; Feng et al., 2000; Afshar et al., 2009; Mungle et al., 2013). However, it is difficult to inform in advance for decision maker which metaheuristic is the best to solve an instance of NP-hard optimization problem. Since a behavior of most metaheuristics for NP-hard problems are usually very difficult to characterize analytically and experimentally that further lead to algorithm selection problem (De et al., 1995). Previously, few attempts were made by researchers to solve algorithm selection problem for NP-hard problem by using experimental methods (Rice 1976; Guo and Hsu, 2007).\nDTCTP is a multi-objective optimization problem that attempts to strike a delicate\nbalance between project schedule time and cost. A multi-objective problem, in its real sense, requires the determination of a representative set of non-dominated or Pareto optimal solutions in the stipulated time frame to be presented to the decision maker. Last decade has witnessed a significant growth in the use of evolutionary meta-heuristics for complex multi-objective\noptimization problems (Deb, 2001). Continuous improvements in the past few years have spectacularly reduced the time of response of these meta-heuristics without much depreciation in terms of solution quality. In particular, state of the art MOEAs like Non-dominated Sorting Genetic Algorithm II (NSGA-II) (Deb et al., 2002), Strength Pareto Evolutionary Algorithm II (SPEA-II) (Zitzler et al., 2001) and Niched Pareto Genetic Algorithm II (NPGA-II) (Erickson et al., 2001) etc. have been extensively used and their robustness and capability to solve complex Multi-objective Combinatorial Optimization (MOCO) problems are well established.\nThe objective of this paper is to design a portfolio of four MOEAs namely NSGA-II (Deb\net al., 2002), SPEA-II (Zitzler et al., 2001), NPGA-II (Erickson et al., 2001) and PAES (Knowles and Corne, 1999), and its implementation on DTCTP. The four MOEAs are parallelly processed on two and four processors system. In addition, average quality metric is used to evaluate the quality of the approximated Pareto-optimal front. This aids in the decision making process to investigate the relative performance of various strategies embedded in the portfolio to get an insight into the solution quality of the Pareto-optimal front with the increasing problem size and complexity. A portfolio of algorithms is formally expressed as \u201cA collection of different algorithms and or different copies of the same algorithm running on different processors\u201d (Gomes and Selman, 2001; Huberman et al., 1997, Brown et al., 2003). Algorithm portfolio seeks to identify the best suited strategy and thereby amalgamate the performance of various algorithms thus enhancing the algorithm performance in dynamic environment. The effect can broadly be termed as performance maximizing superposition of algorithms where an algorithm performance is tailored by the performance of counterparts embedded in the portfolio. Finally, AHP method is adapted to determine the best portfolio case for DTCTP.\nThe remainder of the paper is organized as follows: Section 2 presents the mathematical\nformulation of DTCTP. Section 3 reviews some of the terminologies and techniques employed in the field of multi-objective optimization. Section 4 presents the computational study. Section 5 presents design of algorithm portfolio and its implementation. Section 6 includes the numerical results. Finally, section 7 concludes the paper with suggested future research works."}, {"heading": "2. Mathematical Formulation", "text": "To model the DTCTP, we start with the standard assumption for modeling the project network: the project network has no cycles, the start activity (activity 0, a dummy activity) is the\nonly activity that is not an immediate successor of any activity, and the finish activity (activity N+1, also a dummy activity) is the only activity that has no successors.\nIn time-cost optimization study, project completion time and implementation cost are\nconsidered as the main objectives in determining the best possible option for every activity in the project network."}, {"heading": "2.1. Project completion time", "text": "The project completion time is determined by scheduling the activities using the assigned\nactivity durations. It can be expressed as:\nmin max\u2208 \u2208\n1\nWhere,\nTotal number of activities in the project network Duration of option of activity , for 1, \u2026 , , 1, \u2026 If 1 then activity perform option,while 0 means not Activity sequence of path 1 , 2 , \u2026 , Sets of all path of a network 1, 2, \u2026 , Number of paths in a project network Number of time cost option for each activity , for 1, \u2026 , \u00a0"}, {"heading": "2.2. Project cost", "text": "The total project cost consists of direct and indirect cost. The direct cost is taken as the sum of direct cost of all activities within a project network. On the other hand, indirect cost is comprised of the expenditure on management during project implementation, which depends heavily upon the project duration, i.e., longer the duration, the higher the indirect cost. It can be expressed as:\nmin min max\u2208 \u2208\n2\nWhere,\n\u00a0\nDirect cost of option for activity , for 1, \u2026 , , 1, \u2026 , \u00a0 Indirect cost of option for activity , for 1, \u2026 , , 1, \u2026 , Material cost of option for activity , for 1, \u2026 , , 1, \u2026 , Duration of activity for option , for 1, \u2026 , , 1, \u2026 , Daily cost rate in $day for using option in activity , for 1, \u2026 , , 1, \u2026 ,"}, {"heading": "2.3. Constraints", "text": ""}, {"heading": "2.3.1. Network logic constraints", "text": "The completion time of a project can be constrained by one of two methods (Crowston, 1970). The first method allows precedence constraints for each immediate preceding relationship in the project network. The second method allows one constraint for each path from the first activity to the last one in the project network. In the present formulation, the first method is adopted. The logical relationship between any two consecutive activities i and its immediate successor k is expressed as:\n\u2200 1, \u2026 , , \u2200 \u2208 3 Where,\nScheduled start of immediate succesor of activity Scheduled finishing time of activity\nThe SFi equal scheduled start time (SSi) plus its duration. The logical relationship constraint can be expressed using following equation, in which Si is the set of successor activities to activity i.\n\u2200 1, \u2026 , , \u2200 \u2208 4"}, {"heading": "2.3.2. Project completion constraints", "text": "In real life scenario, we imply a constraint on project completion time and cost to ensure that the both the objective will complete under restriction. These constraints are expressed by the following equations in which is denoted as maximum allowable project duration and is denoted as maximum allowable project cost.\n\u2208 \u2208\n5\nmin \u2208 \u2208\n6\n\u00a0"}, {"heading": "3. Basic Concepts of Multi-objective Optimization", "text": "In this section, we briefly present the basic concepts of multi-objective optimization. Generally, multi-objective optimization problem can be formulated as follows:\nmaximize , \u2026 , (7) . . \u2208\nWhere, solution , \u2026 , is a vector of decision variables in a problem at hand and X is the set of feasible solutions available in a search space. If the variables in a problem at hand are discrete, the multi-objective optimization problem is called multiple-objective combinatorial optimization problems. The image of a solution x in the objective space is a point\n, \u2026 , , such that 1, \u2026 , (8) \u00a0\u00a0\u00a0\nPoint dominates , \u227b , if \u2200 and for at least one j. Solution dominates if the image of dominates the image of . A solution \u2208 is considered as Pareto-optimal if there is no \u2208 that dominates solution x. A point being an image of a Pareto-optimal solution is known as non-dominated point. The set of all Pareto-optimal solution is called the Pareto-optimal set. The image of the Pareto-optimal set in the objective space is called the non-dominated set or Pareto front. An approximation of the non-dominated set is a set A of feasible points (and corresponding solutions) such that , \u2208 such that \u227b . The point \u2217 composed of the best attainable objective function value is called the ideal point.\n\u2217 | \u2208 , 1, \u2026 , (9) An approximation of the ideal point based on set A is denoted by Z** (A)\n\u2217\u2217 max | \u2208 , 1, \u2026 , (10)\nFinding the complete Pareto front is a very difficult task computationally which is\nattributed to the presence of a large numbers of sub-optimal Pareto front. Considering an existing memory limitation, determining the complete Pareto front becomes infeasible, and thus requires the Pareto front to be diverse covering maximum possible regions of it. Therefore, a multiobjective algorithm aims to obtain an approximation of the Parent front (Jaszkiewicz, 2003).\nIn this paper, performance of algorithm portfolio is measured based on the quality of the\nobtained Pareto front, which is quantitatively evaluated using standard criteria or metrics. One such metric \u2018Average Quality\u2019 (AQ) (Jaszkiewicz, 2003) is utilized here. In past, the quality of\nthe Pareto-optimal set was measured in terms of Tchebycheff function S (Jaszkiewicz, 2003) and is defined in the following way:\n     0 0 0 ( , , ) max ( ) max ( ) j j j j\nj j jj\ns z z\nz f\n\n\n   \n \nz z\nx \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0(11)\nWhere is a reference point, \u2227 , \u2026 , is a weight vector such that 0 \u2200 and \u2203 | 0. Each weighted Tchebycheff scalarizing function has at least one global optimum belonging to the set of Pareto-optimal solutions. Note, however, that if the optimum is not unique, then some of the optima may be dominated, but must have at least one objective component equal to a Pareto-optimal solution. For each Pareto optimal solution x there exist a weighted Tchebycheff scalarizing function S such that x is a global optimum of S.\nHowever, this function tends to hide certain aspects regarding the solution set\u2019s quality\nbecause poor performance with respect to proximity may get compensated by good performance in distribution of solutions. In order to overcome this limitation, diversity indicators of spread and space are added to the formulation of AQ metric.\nAchievement scalarizing functions are defined in the following ways:\n 0 0 0 1\n( , , ) max , ( ) ( ) J\na j j j j j jj j S z z z z   \n    \n     zz \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0(12)\u00a0\nWhere \u03c1 = small positive number, 0< \u03c1<<1. All global optima of each achievement scalarizing\nfunction belong to the set of Pareto-optimal solutions.\nWeight vector that meets the following condition are called normalized weight vectors.\n\u2200 0, 1 13 \u00a0\nThe AQ metric uses a representative sample s of normalized weight vectors which is represented as:\n\u2227 , \u2026 , \u2208 | \u2208 0, , , \u2026 , , 1 (14)\nWhere,\ns = Set of normalized vector l = Sampling parameter We observe that s contain 1\n1 weight vectors. For each number of objectives J, the size of \u03a8s should at least 50 i.e., sampling parameter l is set as the lowest value that assures |\u03a8| 50. Therefore l set to be 49 for J = 2. Each weight vector \u2227\u2208 defines an achievement scalarizing function , ,\u2227, . All scalarizing functions defined by vectors from set \u03a8s constitute set Sa of functions.\nIn order to evaluate the quality of solution generated by algorithm portfolio, we first run\nthe algorithm portfolio. In result, an approximation A of the whole non-dominated set is obtained. Then for each function , ,\u2227, \u2208 the best solution x on this function is selected from set A. i.e., \u2200 \u2208 , ,\u2227, , ,\u2227, . Thus the average quality of solutions generated by the portfolio is\n\u2211 , ,\u2227,\u2208 | | 15\nWhere, Z0 = reference point which is an approximation of the ideal point X = best solution on function , ,\u2227, | \u2208 \u00a0 \u03c1 = parameter set as 0.01\nFor each test instance, an approximation of the ideal point was found by local\noptimization of individual objectives started from an initial solution. This approximation of the\nideal point is used as reference point in achievement scalarizing function , ,\u2227, . The objective ranges observed during local optimization of every individual objective is used to determine the range equalization factor which further helps to normalize the objective values before calculating scalarizing function.\nThe range equalization factors (Steur, 1986) are defined in the following ways:\n\u03a0 1 , 1, \u2026 , 16 \u00a0\nWhere, is the approximate range of objective function in the non-dominated set A.\nObjective values multiplied by the range equalization factors are called normalized objective function values."}, {"heading": "4. Computational Study", "text": ""}, {"heading": "4.1. Benchmark instances of DTCTP", "text": "In this paper, data sets of DTCTP are characterized based on the number of activities, possible schedules and number of total paths in the project network. Table 1 shows the benchmark instances of DTCTP with their aforementioned characteristics. In this study, total six data sets of DTCTP from very large to very small size have been considered. Among them, problems 1, 2, 3, 5 and 6 have been adapted respectively from (Ozgen, 2009), (Chassiakos and Sakellaropoulos, 2005), (Feng and Liu, 1997), (Pour et al., 2010) and (Zheng et al., 2004), and problem 4 is hypothetically generated with maximum 4 and minimum 2 execution modes for project activities. The solution to these problems has been attempted by integrating them in an algorithm portfolio that works on the strategy of minimizing the risk in terms of computational cost and the solution quality obtained."}, {"heading": "4.2. Multi-objective Evolutionary Algorithms (MOEAs)", "text": "In this paper, four establish MOEAs namely, NSGA-II (Deb et al., 2002), SPEA-II (Zitzler et al., 2001), NPGA-II (Erickson et al., 2001) and PAES (Knowles and Corne, 1999) is taken into consideration to design and implement the algorithm portfolio. The following discussion presents a brief overview of these four MOEAs."}, {"heading": "4.2.1. Non-dominated Sorting Genetic Algorithm-II (NSGA-II)", "text": "It was proposed by Deb et al. (2002). This algorithm is a revised version of Non-dominated Sorting Genetic algorithm (NSGA) proposed by Srinivas and Deb (1995) which has been criticized mainly for its high computational complexity, non-elitism approach and a need for specifying a sharing parameter. NSGA was based on Genetic algorithm (GA), which utilizes several layers of classification of the individuals. In the slow sorting approach, in order to find the first non-dominated front each solution in the population is compared with every other to find all the members which are non-dominated compared to others. These individuals comprises first non-dominated front. To find the members of the next front, all the members of the previous fronts are left temporarily and the aforementioned procedure is repeated. This leads to a high O (MN3) computational complexity where M is the number of objectives and N is the population size.\nHowever, NSGA-II followed a fast non-dominated sorting approach which requires O\n(MN2) comparisons. It also replaced the use of sharing function with the new crowded comparison approach that eliminates the need of any user defined parameter for maintaining diversity among population members. The other basic steps of NSGA-II are same as those of GA. Initially, a population double in size (2N) is randomly generated and is then sorted on the basis of non-dominance. Thereafter, the selection of best N members from the population is carried out. Crossover and Mutation is performed in order to utilize these genetic operations to produce better offspring. The parents and offspring are then combined to form the initial population for the next generation and the aforementioned procedure is repeated. The algorithm finally provides a well distributed Pareto set of solutions. In the present paper, two point crossover and bit-flip mutation have been used."}, {"heading": "4.2.2. Strength Pareto Evolutionary Algorithm II (SPEA-II)", "text": "It is a revised version of SPEA proposed by Zitzler and Thiele (2001). SPEA was developed on the basis of a previously carried comparative study and establish the multi-objective techniques commonly used in Evolutionary Algorithms (EAs) into a single meta-heuristic skeleton (Zitzler and Thiele, 1999). SPEA-II, an improved version of SPEA, utilizes an external memory for storing the non-dominated individuals. Each individual in the extended memory as well as in the current population is assigned a strength value based on the domination and density information. The rank value of an individual is determined by the summation of strength values of the individuals that dominate it. Density of each individual is estimated based on the kth nearest neighbor density estimation method. The final fitness value is then calculated as the sum of rank and density values. In addition, a hierarchical clustering based method (Morse, 1980) is adopted for the pruning of the external archive thereby maintaining diversity in the obtained Pareto front."}, {"heading": "4.2.3. Niched Pareto Genetic Algorithm-II (NPGA-II)", "text": "Erickson et al. (2001) proposed a revised version of the NPGA (Horn et al., 1994) called the NPGA-II. This algorithm uses Pareto ranking but keeps tournament selection (solving ties through fitness sharing as in the original NPGA). In this case, no external memory is used and the elitist mechanism is similar to the one adopted by the NSGA-II. Niche counts in the NPGA-II are calculated using individuals in the partially filled next generation, rather than using the current generation. This is called continuously updated fitness sharing, and was proposed by Oei et al. (1991)."}, {"heading": "4.2.4. Pareto Archived Evolution Strategy (PAES)", "text": "This algorithm was introduced by Knowles and Corne (1999). PAES consists of a (1 + 1) evolution strategy (i.e., a single parent that generates a single offspring) in combination with a historical archive that records the non-dominated solutions previously found. This archive is used as a reference set against which each mutated individual is being compared. Such a historical archive is the elitist mechanism adopted in PAES. However, an interesting aspect of this algorithm is the procedure used to maintain diversity which consists of a crowding procedure that divides objective space in a recursive manner. Each solution is placed in a certain grid location based on the values of its objectives (which are used as its \u201ccoordinates\u2019\u2019 or \u201cgeographical location\u2019\u2019). A map of such grid is maintained, indicating the number of solutions\nthat reside in each grid location. Since the procedure is adaptive, no extra parameters are required (except for the number of divisions of the objective space). Next subsection develops the mathematical insights supporting the use of portfolios."}, {"heading": "4.3. Computational Analysis", "text": "As we know that MOEAs do not always reach the optimal solution, even for long computation times. In addition, it is often impossible to obtain an analytical prediction of either the solution achievable within a given computation time or the time taken to find a solution of a given quality. The analysis of these measures is critical for the comparison between MOEAs. In literature, statistical analysis of these measures is known as \u201cUnivariate Model\u201d (Chiarandini et al., 2007). More specifically, Univariate model is the one in which either the solution cost or runtime is taken into consideration while analyzing the various metaheuristics.\nIn this paper, our concern is run-time that means computation time is measured when a\nsolution with a desired property is found. We assume that run-time corresponds to the number of iteration needed to achieve the desired solution quality.\nThe performance measure X (run-time) of a metaheuristics on the instances can be\ndescribed by a probability distribution function \u00a0 or equivalently by its cumulative (discrete) distribution function (CDF) \u2211 In the computational experiments, we observe data , , \u2026 , \u00a0 and then calculate the CDF. Once the CDF is known, parameter such as mean and variance of the iterations is calculated to compare the performance of each MOEA.\nInitiation of the experiment takes place by testing the four MOEAs on all the benchmark\ninstances for 50 trials and the results have been reported in Figures 1-6. In Figure 1-6, X-axis represents the iterations needed to satisfy the termination criteria and Y-axis represents the CDF value. The termination criteria for each MOEA set as the performance level within 10% of the best obtained AQ (average quality) metric value. The mean and variance of the number of iterations required by each algorithm for the six problems are provided in Table 2.\nProblem 5\nnumber of iterations to reach the termination criteria compared to other three MOEAs. For problem 2 and 5, NSGA-II takes less number of iterations compared to PAES, NPGA-II and SPEA-II. In addition, it shows expected variations in the outcome with the changing problem size. Moreover, it is important to compare the number of success amongst the 50 trials for each MOEA to reach the termination criteria. Figures 1-6 reveals that the performance of the all four MOEAs remained competitive for the six benchmark instances considered. More specifically, for problem 1, 3 and 4 PAES perform well compared to other three MOEA. For problem 2 and 5, NSGA-II performs well compared to other three MOEAs."}, {"heading": "5. Algorithm Portfolio", "text": "In this section, we present the design of algorithm portfolio and its implementation on DTCTP."}, {"heading": "5.1. Algorithm Portfolio Design", "text": "The deviation in the performance of the four MOEAs for DTCTP is the key to portfolio realization. Making use of the obtained variations, different portfolios have been conceived and analysis has been carried out. These experiments were performed with portfolios containing 2 and 4 algorithms on 2 and 4 processor systems. The detailed list containing the information pertaining to the algorithms embedded in various portfolios is provided in Table 3.\nFollowing criteria has been considered while designing these portfolios:\n Those algorithms were combined and placed in same portfolios which showed varied\nperformance.\n Strategies utilizing external memory for storing non dominated particles are tied with the\nstrategies that store such particles in the current population.\n Portfolios were designed keeping in mind the requirement to analyze the relative performance\nof various strategies utilized for maintaining diversity in the population.\nmaintaining strategies is also considered. Aforementioned criteria are clearly evident in the portfolio design utilized. The inferior performance of NPGA-II compared to other metaheuristics lowers the expectancy of competitive performance by the portfolios containing it. In addition, the similarity of its operators with NSGA-II, and much better performance by NSGAII, limits it utilization (as is evident from the lowest number of its portfolios) in further portfolio analysis."}, {"heading": "5.2. Implementation of Portfolio Approach", "text": "In practice, one may implement the portfolio following a few steps. First, a set of portfolio cases for different processors and its constituent algorithm should be identified. In this paper, we developed three portfolio cases, namely, 2 Algorithm-2 Processor (2A-2P), 2 Algorithm-4 Processor (2A-4P) and 4 Algorithm-4 Processor (4A-4P) (See Table 3). We then identified the constituent algorithm for each of these portfolio cases, as given in Table 3. When choosing the constituent algorithm, an intuition is that they should be more or less complementary. The constituent algorithms are combined and placed in portfolio based on their performances on all benchmark problems. As will be shown in our numerical results interpretation, choosing complementary constituent algorithms leads to good performances with same algorithms exploit on the different parallel processors on the same benchmark problems. More specifically, the\nconstituent algorithms should not only employ different operators but also exhibit different behaviors on problem sets. For second steps, algorithm portfolio framework should be highly capable to accommodate existing algorithms. However, due to the fact that some existing algorithms might have their own configuration, they merit little bit attention when incorporated into portfolio framework. In the present portfolio, some algorithms such as NSGA-II are highly capable to provide good solution quality beside its more run time complexity. This helps respective portfolio terminates quickly if the status of solution has reached predefined termination criteria.\nIn this paper, the termination criteria for the each portfolio run was set to be the\nperformance level within 10% of the best obtained AQ (average quality) metric value. Average quality (AQ) is used as standard criteria here to measure the quality of the obtained Pareto front of algorithm portfolio. More details of this issue are given in section 3. In final step of algorithm portfolio, number of iterations will be recorded after the termination criterion is satisfied. Number of iterations is taken as criteria to evaluate the computational efficiency of the each portfolio case.\nBefore running portfolio, part of our work is to allocate population size, generation size\nand other parameters values for each constituent algorithms of portfolio. Their values should be always same to evaluate the performances of each portfolio case.\n\u00a0\u00a0 6. Results and Discussion In order to perform the analysis, six benchmark instances are considered with varying problem size and complexity. Simulations were performed with various combinations of algorithms and processor systems. The algorithm combinations embedded in different portfolio cases is given in Table 3. Various combinations of algorithms are implemented in parallel on 2 and 4 processor systems which are detailed in coming subsection. These combinations or portfolios are represented by a \u2018/\u2019 notation. For example, the symbol 1/1 represents 2 algorithm-2 processor portfolio where first algorithm is run on first processor whiles the other one on the second processor. Similarly, 4/0/0/0 represents 4 algorithms-4 processor portfolios in which four copies of the first algorithm (Table 3) were run on all the four processors. Each combination was evaluated on the basis of its performance averaged over 50 independent runs."}, {"heading": "6.1. Experimental Runs", "text": "This subsection contains the experimental results obtained by considering various combinations utilized. Average number of iterations required by the portfolio to reach the desired quality level (10 % of the best) of Pareto-optimal front is again taken as the performance criteria. Different combinations of algorithms to be run on the processors and utilized in the experiment are given as follows:\nCase 4A- 4P Case 4A- 4P 1 4/0/0/0 9 0/3/1/0 2 3/1/0/0 10 0/4/0/0 3 3/0/1/0 11 1/0/3/0 4 3/0/0/1 12 1/2/0/1 5 2/1/1/0 13 0/0/4/0 6 2/1/0/1 14 1/1/0/2 7 1/0/1/2 15 0/1/0/3 8 0/2/1/1 16 0/0/0/4"}, {"heading": "6.2. Interpreting the Results", "text": "Having had the experimental results, the task to be accomplished is concerned to portfolio assessment. Generally processor availability for the parallel runs is limited in an organization; hence the selection strategy has to be executed separately for each of the two types of systems (2 Processor, 4 Processor) under consideration. The varying performance of different algorithms, and eventually the portfolios, poses enough challenge to select the best strategy among the instances explored in order to get the quality solution with minimum risk. Analytical Hierarchy Process (AHP) has long been utilized as a tool to decision makers for selecting the best alternative from the given alternatives in such situations. AHP employs hierarchical pairwise comparison to induce the weights of alternatives thorough their pairwise comparison.\nThis paper also addresses the selection of best portfolio problem from an AHP\nperspective. Each type of portfolio is recognized as an alternative for the particular processor system to which the portfolio belongs to and the results over six different problems are considered as of different attributes. First, a matrix A is constructed which is defined as follows,\n11 12\n21 22\na a\nA a a              \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0(17)\n\u00a0 Where, the column represent attribute , 6  in the underlying case (corresponding to\nproblem 1-6); row represent the alternatives (portfolio) explored; and ija represent the\nnormalized the objective value for the experiment characterizing by set (i, j), i.e.\n  OBJij\naij OBJijj  \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0(18)\n\u00a0 where, OBJij represent the objective value based on which the solution quality is to be\nmeasured. In this case, OBJij symbolizes the average number of generation required by the particular test alternative.\nThereafter a priority matrix i  is calculated for each attribute i, where\nijijk ik a a   \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0(19)\n\u00a0 The associated weight vector iW is then calculated for each attribute i by taking\ngeometric mean for the row corresponding to matrix \u2126i\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 1 { } i i jW w  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\n\u00a0 ijk k\n\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0(20) \u00a0\nThe calculation of weight vector is followed by their normalization, thus,  normalized\npriority vector sPV are obtained as\n1\ni ji j i jj w PV w    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0(21)\n\u00a0\nThe weighted sum of six priority vectors is now obtained that gives the relative rank\nvector RV for the alternatives. Here, priority weights are taken as 1/6 to ensure equal weightage to all attributes. For the two processor system, 8 portfolio combinations (due to repeat of several portfolios) have been evaluated. Similarly for four processor systems 16 combinations corresponding to both 2 algorithm and 4 algorithm cases are evaluated.\nThe final rank vectors and ranks for different alternatives are provided in Tables 5, 6 and\n7. As is evident, the aforementioned strategy provides a relative ranking between the various portfolio alternatives available. For the two algorithms with two processors system the portfolios comprising of algorithms NSGA-II and PAES characterized by (1/1) system is found to be the best. One of the possible reasons for this might be the complementary performance of both the algorithms on the problem scenario considered. As is evident from the individual performance profiles (Figures 1-6), in general, the performance of PAES was good for on all instances considered. On the contrary, the performance of NSGA-II was good for large and medium sized instances while considerably poor for the small sized problem. The results obtained with portfolios embedding NSGA-II are generally better thereby supporting our early assumptions for its increased number in the portfolios considered. It is also evident that NPGA-II, which performed poorly when considered individually, continued the show with the portfolios embedding it resulting in worst case performance.\nalgorithms NSGA-II and PAES characterized by (2/2) system is found to be the best. From result, it is clear that running algorithm on parallel processor is also found to be the best strategy when harmonizing portfolio. Similarly for the four algorithms case, the portfolio comprising of algorithms NSGA-II and PAES characterized by (3/1/0/0) system is found to be the best suited strategy.\nIn fact, the finding is attributed to the element of randomness inherited in the search\nprocedure. Randomness here does not mean uncertainty rather it refers to the ability of the heuristic to vary its performance based on the initial random seed. However, the reason can be deduced on the basis of performance profiles obtained with the single processor system (Figures 1-6).\nempirically suggestive of the aforementioned fact. Similar other interesting and supporting conclusions (for portfolio implementation) can be drawn from the analysis. However, before the implementation of this concept to the practical scenario a much detailed experimentation is required. This comprises of a much exhaustive list of algorithms and an augmented use of processors."}, {"heading": "7. Conclusion and Future Research", "text": "This paper proposes a portfolio approach to algorithm selection for discrete time-cost trade-off problem in multi-objective environment. The proposed algorithm portfolio containing NSGA-II, PAES, NPGA-II and SPEA-II is used to minimize the associated risk related to the selection of algorithm. Six benchmark instances of DTCTP of varying dimension and complexities are included to analyze the performances of portfolio approach. The four algorithms are parallelly processed on two and four processors system. The results showed an insight, suggesting the application of portfolios to select the best algorithm for computationally expensive multi-\nobjective optimization problems. Furthermore, the result shows a considerable decrease in the computational time by the parallel processing of algorithms.\nAs perspective for future work, much detailed analysis is needed prior to any suggestion\nfor algorithm portfolio usage. However, our preliminary results are encouraging new directions for implementation of algorithm portfolio on different multi-objective decision making problems."}], "references": [{"title": "Non-dominated Archiving Multicolony Ant Algorithm in Time-Cost Trade-off Optimization", "author": ["A. Afshar", "A.K. Ziaraty", "A. Kaveh", "F. Sharifi"], "venue": "Journal of Construction Engineering and Management,", "citeRegEx": "Afshar et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Afshar et al\\.", "year": 2009}, {"title": "A Portfolio Approach to Algorithm Selection, International Joint Conference in Artificial Intelligence, 15421543", "author": ["K.L. Brown", "E. Nudelman", "Andrew G", "McFadden J", "Y. Shoham"], "venue": null, "citeRegEx": "Brown et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Brown et al\\.", "year": 2003}, {"title": "Time Cost Optimization of Construction Projects with Generalized Activity Constraints", "author": ["A.P. Chassiakos", "S.P. Sakellaropoulos"], "venue": "Journal of Construction Engineering and Management,", "citeRegEx": "Chassiakos and Sakellaropoulos,? \\Q2005\\E", "shortCiteRegEx": "Chassiakos and Sakellaropoulos", "year": 2005}, {"title": "Experiments on metaheuristics: Methodological overview and open issues", "author": ["M. Chiarandini", "L. Paquete", "M. Preuss", "E. Ridge"], "venue": "Technical report, Department of Mathematics and Computer Science,", "citeRegEx": "Chiarandini et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Chiarandini et al\\.", "year": 2007}, {"title": "Decision CPM: Network Reduction and Solution", "author": ["W.B. Crowston"], "venue": "Operational Research Quarterly,", "citeRegEx": "Crowston,? \\Q1970\\E", "shortCiteRegEx": "Crowston", "year": 1970}, {"title": "The Discrete Time-Cost Trade-off Problem Revisited", "author": ["P. De", "E.J. Dunne", "J.B. Ghosh", "C.E. Wells"], "venue": "European Journal of Operation Research,", "citeRegEx": "De et al\\.,? \\Q1995\\E", "shortCiteRegEx": "De et al\\.", "year": 1995}, {"title": "Complexity of the Discrete TimeCost Trade-off Problem for Project", "author": ["P. De", "E.J. Dunne", "J.B. Ghosh", "C.E. Wells"], "venue": "Networks, Operations Research,", "citeRegEx": "De et al\\.,? \\Q1997\\E", "shortCiteRegEx": "De et al\\.", "year": 1997}, {"title": "Multi-objective Optimization using Evolutionary Algorithms", "author": ["K. Deb"], "venue": null, "citeRegEx": "Deb,? \\Q2001\\E", "shortCiteRegEx": "Deb", "year": 2001}, {"title": "A Fast and Elitist Multi-objective Genetic Algorithm: NSGA-II", "author": ["K. Deb", "A. Pratap", "Agrawal S", "T. Meyarivan"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "Deb et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Deb et al\\.", "year": 2002}, {"title": "The Niched Pareto Genetic Algorithm 2 Applied to the design of Groundwater Remediation", "author": ["M. Erickson", "A. Mayer", "J. Horn"], "venue": null, "citeRegEx": "Erickson et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Erickson et al\\.", "year": 2001}, {"title": "Using Genetic Algorithm to Solve Construction Time-Cost Tradeoff Problem", "author": ["C. Feng", "L. Liu"], "venue": "Journal of Computing in Civil Engineering,", "citeRegEx": "Feng and Liu,? \\Q1997\\E", "shortCiteRegEx": "Feng and Liu", "year": 1997}, {"title": "Stochastic Construction Time Cost Trade-off Analysis", "author": ["C. Feng", "L. Liang", "S. Burns"], "venue": "Journal of Computing in Civil Engineering,", "citeRegEx": "Feng et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Feng et al\\.", "year": 2000}, {"title": "Algorithm Portfolios", "author": ["C. Gomes", "B. Selman"], "venue": "Artificial Intelligence,", "citeRegEx": "Gomes and Selman,? \\Q2001\\E", "shortCiteRegEx": "Gomes and Selman", "year": 2001}, {"title": "A Simple CPM Time-Cost Trade-off Algorithm & quot", "author": ["S. Goyal"], "venue": "Management Science,", "citeRegEx": "Goyal,? \\Q1975\\E", "shortCiteRegEx": "Goyal", "year": 1975}, {"title": "A Machine Learning Approach to Algorithm Selection for NPHard Optimization Problems: A Case Study on the MPE Problem", "author": ["H. Guo", "W.H. Hsu"], "venue": "Annals of Operations Research,", "citeRegEx": "Guo and Hsu,? \\Q2007\\E", "shortCiteRegEx": "Guo and Hsu", "year": 2007}, {"title": "A Niched Pareto Genetic Algorithm for Multi-objective Optimization", "author": ["J. Horn", "N. Nafploitis", "D.E. Goldberg"], "venue": "Proc. of the First IEEE Conference on Evolutionary Computation,", "citeRegEx": "Horn et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Horn et al\\.", "year": 1994}, {"title": "Do Multiple-Objective Meta-heuristics Deliver on their Promises? A Computational Experiment on the Set-Covering Problem", "author": ["A. Jaszkiewicz"], "venue": "IEEE Transaction on Evolutionary Computation,", "citeRegEx": "Jaszkiewicz,? \\Q2003\\E", "shortCiteRegEx": "Jaszkiewicz", "year": 2003}, {"title": "The Pareto archived evolution strategy: A New Baseline Algorithm for Multi-objective Optimization", "author": ["J. Knowles", "D. Corne"], "venue": "Proceedings of the 1999 Congress on Evolutionary Computation, Piscataway: New Jersey: IEEE Service Center,", "citeRegEx": "Knowles and Corne,? \\Q1999\\E", "shortCiteRegEx": "Knowles and Corne", "year": 1999}, {"title": "Reducing the Size of the Non-dominated Set: Pruning by Clustering", "author": ["J. Morse"], "venue": "Computers & Operations Research,", "citeRegEx": "Morse,? \\Q1980\\E", "shortCiteRegEx": "Morse", "year": 1980}, {"title": "A fuzzy clustering-based genetic algorithm approach for time-cost-quality trade-off problems: A case study of highway construction project", "author": ["S. Mungle", "L. Benyoucef", "Y.J. Son", "M.K. Tiwari"], "venue": "Engineering Applications of Artificial Intelligence,", "citeRegEx": "Mungle et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mungle et al\\.", "year": 2013}, {"title": "Tournament Selection, Niching, and the Preservation of Diversity", "author": ["C.K. Oei", "D.E. Goldberg", "S.J. Chang"], "venue": null, "citeRegEx": "Oei et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Oei et al\\.", "year": 1991}, {"title": "Optimization of Time-Cost Resource Trade-off Problem in Project Scheduling using Metaheuristic Algorithms", "author": ["C. Ozgen"], "venue": "Doctoral Thesis Report,", "citeRegEx": "Ozgen,? \\Q2009\\E", "shortCiteRegEx": "Ozgen", "year": 2009}, {"title": "The Discrete TimeCost-Quality Trade-off using a Novel Hybrid Genetic Algorithm", "author": ["N. Pour", "N. Modarres", "M.B. Aryanejad", "R.D. Moghadam"], "venue": "Applied Mathematical Sciences,", "citeRegEx": "Pour et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Pour et al\\.", "year": 2010}, {"title": "The Algorithm Selection Problem", "author": ["J. Rice"], "venue": "Advances in Computers,", "citeRegEx": "Rice,? \\Q1976\\E", "shortCiteRegEx": "Rice", "year": 1976}, {"title": "A Dynamic Programming Solution to Time-Cost Trade-off for CPM", "author": ["D. Robinson"], "venue": "Management Science,", "citeRegEx": "Robinson,? \\Q1975\\E", "shortCiteRegEx": "Robinson", "year": 1975}, {"title": "A Simple CPM Time-Cost Trade-off Algorithm", "author": ["N. Siemens"], "venue": "Management Science,", "citeRegEx": "Siemens,? \\Q1971\\E", "shortCiteRegEx": "Siemens", "year": 1971}, {"title": "Multi-objective Optimization using Non-dominated Sorting Genetic Algorithms", "author": ["N. Srinivas", "K. Deb"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "Srinivas and Deb,? \\Q1995\\E", "shortCiteRegEx": "Srinivas and Deb", "year": 1995}, {"title": "Multiple Criteria Optimization: Theory, Computation and Application, Wiley: New York", "author": ["R. Steur"], "venue": null, "citeRegEx": "Steur,? \\Q1986\\E", "shortCiteRegEx": "Steur", "year": 1986}, {"title": "Multi-objective Evolutionary Algorithms: A Comparative Case Study and the Strength Pareto Approach", "author": ["E. Zitzler", "L. Thiele"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "Zitzler and Thiele,? \\Q1999\\E", "shortCiteRegEx": "Zitzler and Thiele", "year": 1999}, {"title": "SPEA2: Improving the Strength Pareto Evolutionary Algorithm", "author": ["E. Zitzler", "M. Laumanns", "L. Thiele"], "venue": "Swiss Federal Institute of Technology,", "citeRegEx": "Zitzler et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Zitzler et al\\.", "year": 2001}, {"title": "Applying Genetic Algorithm-Based Multi-objective Approach for Time-Cost Optimization", "author": ["D. Zheng", "S. Thomas", "M. Kumaraswamy"], "venue": "Journal of Construction Engineering and Management,", "citeRegEx": "Zheng et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Zheng et al\\.", "year": 2004}, {"title": "Applying Pareto Ranking and Niche Formation to Genetic Algorithm-Base Multi-objective Time-Cost Optimization, Journal of Construction", "author": ["Zheng D", "S. Thomas", "M. Kumaraswamy"], "venue": "Engineering and Management,", "citeRegEx": "D. et al\\.,? \\Q2005\\E", "shortCiteRegEx": "D. et al\\.", "year": 2005}], "referenceMentions": [{"referenceID": 6, "context": "In practice, if project is running behind the scheduled plan, acceleration of activity becomes essential by allowing additional resources which ultimately incurs additional cost (De et al., 1997).", "startOffset": 178, "endOffset": 195}, {"referenceID": 24, "context": "Many researchers developed new mathematical models by using linear programming, integer programming or dynamic programming to solve the time-cost optimization problem (Robinson, 1975; Siemens, 1971; Goyal, 1975).", "startOffset": 167, "endOffset": 211}, {"referenceID": 25, "context": "Many researchers developed new mathematical models by using linear programming, integer programming or dynamic programming to solve the time-cost optimization problem (Robinson, 1975; Siemens, 1971; Goyal, 1975).", "startOffset": 167, "endOffset": 211}, {"referenceID": 13, "context": "Many researchers developed new mathematical models by using linear programming, integer programming or dynamic programming to solve the time-cost optimization problem (Robinson, 1975; Siemens, 1971; Goyal, 1975).", "startOffset": 167, "endOffset": 211}, {"referenceID": 21, "context": "In addition, for large-scale networks (several hundred activities with discrete time-cost relationships, which are common for most construction projects), neither heuristic methods nor mathematical models can offer optimal solutions efficiently (Ozgen, 2009).", "startOffset": 245, "endOffset": 258}, {"referenceID": 6, "context": "DTCTP is known as strong NP-hard problem that failed to maintain pseudo-polynomial time guarantee for complex project network using exact solution algorithms (De et al., 1997).", "startOffset": 158, "endOffset": 175}, {"referenceID": 21, "context": "to solve the DTCTP for large-scale networks to obtain near-optimal Pareto solution (Ozgen, 2009; Chassiakos and Sakellaropoulos, 2005; Feng and Liu, 1997; Pour et al., 2010; Zheng et al., 2004; Feng et al., 2000; Afshar et al., 2009; Mungle et al., 2013).", "startOffset": 83, "endOffset": 254}, {"referenceID": 2, "context": "to solve the DTCTP for large-scale networks to obtain near-optimal Pareto solution (Ozgen, 2009; Chassiakos and Sakellaropoulos, 2005; Feng and Liu, 1997; Pour et al., 2010; Zheng et al., 2004; Feng et al., 2000; Afshar et al., 2009; Mungle et al., 2013).", "startOffset": 83, "endOffset": 254}, {"referenceID": 10, "context": "to solve the DTCTP for large-scale networks to obtain near-optimal Pareto solution (Ozgen, 2009; Chassiakos and Sakellaropoulos, 2005; Feng and Liu, 1997; Pour et al., 2010; Zheng et al., 2004; Feng et al., 2000; Afshar et al., 2009; Mungle et al., 2013).", "startOffset": 83, "endOffset": 254}, {"referenceID": 22, "context": "to solve the DTCTP for large-scale networks to obtain near-optimal Pareto solution (Ozgen, 2009; Chassiakos and Sakellaropoulos, 2005; Feng and Liu, 1997; Pour et al., 2010; Zheng et al., 2004; Feng et al., 2000; Afshar et al., 2009; Mungle et al., 2013).", "startOffset": 83, "endOffset": 254}, {"referenceID": 30, "context": "to solve the DTCTP for large-scale networks to obtain near-optimal Pareto solution (Ozgen, 2009; Chassiakos and Sakellaropoulos, 2005; Feng and Liu, 1997; Pour et al., 2010; Zheng et al., 2004; Feng et al., 2000; Afshar et al., 2009; Mungle et al., 2013).", "startOffset": 83, "endOffset": 254}, {"referenceID": 11, "context": "to solve the DTCTP for large-scale networks to obtain near-optimal Pareto solution (Ozgen, 2009; Chassiakos and Sakellaropoulos, 2005; Feng and Liu, 1997; Pour et al., 2010; Zheng et al., 2004; Feng et al., 2000; Afshar et al., 2009; Mungle et al., 2013).", "startOffset": 83, "endOffset": 254}, {"referenceID": 0, "context": "to solve the DTCTP for large-scale networks to obtain near-optimal Pareto solution (Ozgen, 2009; Chassiakos and Sakellaropoulos, 2005; Feng and Liu, 1997; Pour et al., 2010; Zheng et al., 2004; Feng et al., 2000; Afshar et al., 2009; Mungle et al., 2013).", "startOffset": 83, "endOffset": 254}, {"referenceID": 19, "context": "to solve the DTCTP for large-scale networks to obtain near-optimal Pareto solution (Ozgen, 2009; Chassiakos and Sakellaropoulos, 2005; Feng and Liu, 1997; Pour et al., 2010; Zheng et al., 2004; Feng et al., 2000; Afshar et al., 2009; Mungle et al., 2013).", "startOffset": 83, "endOffset": 254}, {"referenceID": 5, "context": "Since a behavior of most metaheuristics for NP-hard problems are usually very difficult to characterize analytically and experimentally that further lead to algorithm selection problem (De et al., 1995).", "startOffset": 185, "endOffset": 202}, {"referenceID": 23, "context": "Previously, few attempts were made by researchers to solve algorithm selection problem for NP-hard problem by using experimental methods (Rice 1976; Guo and Hsu, 2007).", "startOffset": 137, "endOffset": 167}, {"referenceID": 14, "context": "Previously, few attempts were made by researchers to solve algorithm selection problem for NP-hard problem by using experimental methods (Rice 1976; Guo and Hsu, 2007).", "startOffset": 137, "endOffset": 167}, {"referenceID": 7, "context": "optimization problems (Deb, 2001).", "startOffset": 22, "endOffset": 33}, {"referenceID": 8, "context": "In particular, state of the art MOEAs like Non-dominated Sorting Genetic Algorithm II (NSGA-II) (Deb et al., 2002), Strength Pareto Evolutionary Algorithm II (SPEA-II) (Zitzler et al.", "startOffset": 96, "endOffset": 114}, {"referenceID": 29, "context": ", 2002), Strength Pareto Evolutionary Algorithm II (SPEA-II) (Zitzler et al., 2001) and Niched Pareto Genetic Algorithm II (NPGA-II) (Erickson et al.", "startOffset": 61, "endOffset": 83}, {"referenceID": 9, "context": ", 2001) and Niched Pareto Genetic Algorithm II (NPGA-II) (Erickson et al., 2001) etc.", "startOffset": 57, "endOffset": 80}, {"referenceID": 8, "context": "The objective of this paper is to design a portfolio of four MOEAs namely NSGA-II (Deb et al., 2002), SPEA-II (Zitzler et al.", "startOffset": 82, "endOffset": 100}, {"referenceID": 29, "context": ", 2002), SPEA-II (Zitzler et al., 2001), NPGA-II (Erickson et al.", "startOffset": 17, "endOffset": 39}, {"referenceID": 9, "context": ", 2001), NPGA-II (Erickson et al., 2001) and PAES (Knowles and Corne, 1999), and its implementation on DTCTP.", "startOffset": 17, "endOffset": 40}, {"referenceID": 17, "context": ", 2001) and PAES (Knowles and Corne, 1999), and its implementation on DTCTP.", "startOffset": 17, "endOffset": 42}, {"referenceID": 12, "context": "A portfolio of algorithms is formally expressed as \u201cA collection of different algorithms and or different copies of the same algorithm running on different processors\u201d (Gomes and Selman, 2001; Huberman et al., 1997, Brown et al., 2003).", "startOffset": 168, "endOffset": 235}, {"referenceID": 4, "context": "Network logic constraints The completion time of a project can be constrained by one of two methods (Crowston, 1970).", "startOffset": 100, "endOffset": 116}, {"referenceID": 16, "context": "Therefore, a multiobjective algorithm aims to obtain an approximation of the Parent front (Jaszkiewicz, 2003).", "startOffset": 90, "endOffset": 109}, {"referenceID": 16, "context": "One such metric \u2018Average Quality\u2019 (AQ) (Jaszkiewicz, 2003) is utilized here.", "startOffset": 39, "endOffset": 58}, {"referenceID": 16, "context": "the Pareto-optimal set was measured in terms of Tchebycheff function S\uf0a5 (Jaszkiewicz, 2003) and is defined in the following way:", "startOffset": 72, "endOffset": 91}, {"referenceID": 27, "context": "The range equalization factors (Steur, 1986) are defined in the following ways:", "startOffset": 31, "endOffset": 44}, {"referenceID": 21, "context": "Among them, problems 1, 2, 3, 5 and 6 have been adapted respectively from (Ozgen, 2009), (Chassiakos and Sakellaropoulos, 2005), (Feng and Liu, 1997), (Pour et al.", "startOffset": 74, "endOffset": 87}, {"referenceID": 2, "context": "Among them, problems 1, 2, 3, 5 and 6 have been adapted respectively from (Ozgen, 2009), (Chassiakos and Sakellaropoulos, 2005), (Feng and Liu, 1997), (Pour et al.", "startOffset": 89, "endOffset": 127}, {"referenceID": 10, "context": "Among them, problems 1, 2, 3, 5 and 6 have been adapted respectively from (Ozgen, 2009), (Chassiakos and Sakellaropoulos, 2005), (Feng and Liu, 1997), (Pour et al.", "startOffset": 129, "endOffset": 149}, {"referenceID": 22, "context": "Among them, problems 1, 2, 3, 5 and 6 have been adapted respectively from (Ozgen, 2009), (Chassiakos and Sakellaropoulos, 2005), (Feng and Liu, 1997), (Pour et al., 2010) and (Zheng et al.", "startOffset": 151, "endOffset": 170}, {"referenceID": 30, "context": ", 2010) and (Zheng et al., 2004), and problem 4 is hypothetically generated with maximum 4 and minimum 2 execution modes for project activities.", "startOffset": 12, "endOffset": 32}, {"referenceID": 8, "context": "Multi-objective Evolutionary Algorithms (MOEAs) In this paper, four establish MOEAs namely, NSGA-II (Deb et al., 2002), SPEA-II (Zitzler et al.", "startOffset": 100, "endOffset": 118}, {"referenceID": 29, "context": ", 2002), SPEA-II (Zitzler et al., 2001), NPGA-II (Erickson et al.", "startOffset": 17, "endOffset": 39}, {"referenceID": 9, "context": ", 2001), NPGA-II (Erickson et al., 2001) and PAES (Knowles and Corne, 1999) is taken into consideration to design and implement the algorithm portfolio.", "startOffset": 17, "endOffset": 40}, {"referenceID": 17, "context": ", 2001) and PAES (Knowles and Corne, 1999) is taken into consideration to design and implement the algorithm portfolio.", "startOffset": 17, "endOffset": 42}, {"referenceID": 7, "context": "Non-dominated Sorting Genetic Algorithm-II (NSGA-II) It was proposed by Deb et al. (2002). This algorithm is a revised version of Non-dominated Sorting Genetic algorithm (NSGA) proposed by Srinivas and Deb (1995) which has been criticized mainly for its high computational complexity, non-elitism approach and a need for specifying a sharing parameter.", "startOffset": 72, "endOffset": 90}, {"referenceID": 7, "context": "Non-dominated Sorting Genetic Algorithm-II (NSGA-II) It was proposed by Deb et al. (2002). This algorithm is a revised version of Non-dominated Sorting Genetic algorithm (NSGA) proposed by Srinivas and Deb (1995) which has been criticized mainly for its high computational complexity, non-elitism approach and a need for specifying a sharing parameter.", "startOffset": 72, "endOffset": 213}, {"referenceID": 28, "context": "SPEA was developed on the basis of a previously carried comparative study and establish the multi-objective techniques commonly used in Evolutionary Algorithms (EAs) into a single meta-heuristic skeleton (Zitzler and Thiele, 1999).", "startOffset": 204, "endOffset": 230}, {"referenceID": 18, "context": "In addition, a hierarchical clustering based method (Morse, 1980) is adopted for the pruning of the external archive thereby maintaining diversity in the obtained Pareto front.", "startOffset": 52, "endOffset": 65}, {"referenceID": 27, "context": "Strength Pareto Evolutionary Algorithm II (SPEA-II) It is a revised version of SPEA proposed by Zitzler and Thiele (2001). SPEA was developed on the basis of a previously carried comparative study and establish the multi-objective techniques commonly used in Evolutionary Algorithms (EAs) into a single meta-heuristic skeleton (Zitzler and Thiele, 1999).", "startOffset": 96, "endOffset": 122}, {"referenceID": 15, "context": "(2001) proposed a revised version of the NPGA (Horn et al., 1994) called the NPGA-II.", "startOffset": 46, "endOffset": 65}, {"referenceID": 9, "context": "Niched Pareto Genetic Algorithm-II (NPGA-II) Erickson et al. (2001) proposed a revised version of the NPGA (Horn et al.", "startOffset": 45, "endOffset": 68}, {"referenceID": 9, "context": "Niched Pareto Genetic Algorithm-II (NPGA-II) Erickson et al. (2001) proposed a revised version of the NPGA (Horn et al., 1994) called the NPGA-II. This algorithm uses Pareto ranking but keeps tournament selection (solving ties through fitness sharing as in the original NPGA). In this case, no external memory is used and the elitist mechanism is similar to the one adopted by the NSGA-II. Niche counts in the NPGA-II are calculated using individuals in the partially filled next generation, rather than using the current generation. This is called continuously updated fitness sharing, and was proposed by Oei et al. (1991).", "startOffset": 45, "endOffset": 625}, {"referenceID": 17, "context": "Pareto Archived Evolution Strategy (PAES) This algorithm was introduced by Knowles and Corne (1999). PAES consists of a (1 + 1) evolution strategy (i.", "startOffset": 75, "endOffset": 100}, {"referenceID": 3, "context": "In literature, statistical analysis of these measures is known as \u201cUnivariate Model\u201d (Chiarandini et al., 2007).", "startOffset": 85, "endOffset": 111}], "year": 2014, "abstractText": "It has been widely known that performance of algorithms for NP-Hard problems varies from instance to instance. This phenomenon has been observed, when we comprehensively studied multi-objective evolutionary algorithms (MOEAs) on a six benchmark instances of discrete timecost trade-off problem (DTCTP). Instead of using single algorithm to solve DTCTP, we use a portfolio approach that takes multiple algorithms as its constituent. In this paper, we proposed portfolio comprising of four MOEAs, Non-dominated sorting genetic algorithm 2 (NSGA 2), the strength Pareto EA 2 (SPEA 2), Pareto archive evolutionary strategy (PAES) and Niched Pareto Genetic Algorithm 2 (NPGA 2) to solve DTCTP. The result shows that the portfolio approach is computationally fast and qualitatively superior than its constituent algorithms for all benchmark instances. Moreover, portfolio approach provides an insight in selecting the best algorithm for all instances of DTCTP.", "creator": "PScript5.dll Version 5.2.2"}}}