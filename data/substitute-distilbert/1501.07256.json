{"id": "1501.07256", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Jan-2015", "title": "An approach to multi-agent planning with incomplete information", "abstract": "multi - agent planning ( map ) approaches have been typically conceived for independent or loosely - coupled problems to enhance the benefits of distributed planning between governmental agents as solving this kind of problems require less coordination between multiple agents'sub - plans. however, when it comes to tightly - coupled officials'tasks, map has been relegated in favour without centralized approaches and little work is been done in this direction. in this paper, we present unique general - purpose map capable to efficiently handle planning problems with any difference of confidence between agents. we propose a cooperative management planning approach, built upon adaptive partial - order planning paradigm, that allows agents to work independently incomplete information and to have balanced views representing the world, i. e. being ignorant of other agents'information, as well as maintaining their remaining private information. we show various experiments to compare the functions of our system toward a distributed csp - based map approach over a suite of processes.", "histories": [["v1", "Wed, 28 Jan 2015 20:02:14 GMT  (53kb,D)", "http://arxiv.org/abs/1501.07256v1", "6 pages, 2 figures"]], "COMMENTS": "6 pages, 2 figures", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["alejandro torre\\~no", "eva onaindia", "\\'oscar sapena"], "accepted": false, "id": "1501.07256"}, "pdf": {"name": "1501.07256.pdf", "metadata": {"source": "CRF", "title": "An approach to multi-agent planning with incomplete information", "authors": ["Alejandro Torre\u00f1o", "\u00d3scar Sapena"], "emails": [], "sections": [{"heading": "1 INTRODUCTION", "text": "Multi-agent planning (MAP) refers to any planning or plan execution activity that involves several agents. In general terms, MAP is about the collective effort of multiple planning agents to combine their knowledge, information, and capabilities so as to develop solutions to problems that each could not have solved as well (if at all) alone [9]. There exists a great variety of tools and techniques for MAP. Agent-oriented MAP approaches put the emphasis on distributed execution, plan synchronization and collaborative activity at run-time planning to ensure that the agent\u2019s local objectives will be met [8, 16]. Another research line in MAP focuses on coordination of already completed plans that agents have constructed to achieve their individual goals, as for example plan merging [17, 6, 5]. In contrast, the cooperative distributed planning (CDP) approach puts the emphasis on planning and how it can be extended into a distributed environment, on building a competent plan carried out by multiple agents [8]. In CDP, agents typically exchange information about their plans, which they iteratively refine and revise until they fit together well.\nFollowing the cooperative approach, differences among MAP models lie in the integration of the planning and coordination stages [9, 7]. Some recent works on fully cooperative MAP have emerged lately. The work in [14] considers agents as having sequential threads of execution and interaction only occurs when distributing sub-plans to individual agents for plan execution. This approach follows a single-agent planning and distributed coordination. A centralized algorithm for MAP can be found in [2], where multiple agents do planning over a centralized plan interleaving planning and coordination.\n1 Universitat Polite\u0300cnica de Vale\u0300ncia, Camino de Vera s/n, 46022 Valencia, Spain\nIn a distributed version of this latter work, authors use a distributed CSP solver to handle coordination [15].\nThe aforementioned approaches are conceived for loosely-coupled problems (LCP), where agents have little interaction between each other, as these processes are likely to be inefficient in tightly-coupled problems (TCP) [15]. This way, the coupling level of a cooperative multi-agent system is formally defined as a set of parameters to limit the combinatorial blow-up of planning complexity [2]. On the other hand, these MAP models do not consider systems composed of multiple entities distributed functionally or spatially but rather agents endowed with the same capabilities and acting under complete information. When capabilities are distributed across the agents\u2019 domains, agents have necessarily to interact to solve the MAP problem while being unaware of the other agents\u2019 abilities or information about the world, i.e. working under incomplete information.\nIn this paper, we present a general-purpose MAP model able to work with inherently distributed entities and suitable for both LCP and TCP domains. Similarly to [11], we use an iterative planning refinement procedure that uses single-agent planning technology. Particularly, our model builds upon a partial-order planning (POP) paradigm, which also allow us to represent a collection of acting entities as a single agent. POP is a very suitable approach for centralized MAP with a small number of coordination points between agents [14], and the application of a multi-agent POP refinement framework also reveals as a very appropriate mechanism to address tightly-coupled problems.\nThis paper is organized as follows. The next section presents the specification of a MAP task. Following, we explain the POP refinement approach and the extensions we have introduced to deal with a multi-agent representation and incomplete information. The next sections describe our MAP task theoretical model and the refinement planning algorithm carried out by the agents. Following, we show the results of the tests we have performed, and finally, we conclude and outline the future lines of research."}, {"heading": "2 MULTI-AGENT PLANNING TASK", "text": "In our approach, the planning formalism of an agent is based on a STRIPS-like model of classical planning under partial observability. The model allows agents to represent their partial view of the world through the adoption of the open world assumption. States are represented in terms of state variables. O is a finite set of objects that model the elements of the planning domain; V is a finite set of state variables each with an associated finite domain, Dv , of mutually exclusive values. Values in Dv denote objects of the planning domain, i.e., \u2200v \u2208 V , Dv \u2286 O. A state is a set of positive fluents of the form \u3008v, d\u3009, and negative fluents of the form \u3008v,\u00acd\u3009, meaning that the variable takes on the value d or \u00acd, respectively. A formula (v, d) evaluates to true if the fluent \u3008v, d\u3009 is present in the state and it evalar X iv :1\n50 1.\n07 25\n6v 1\n[ cs\n.A I]\n2 8\nJa n\n20 15\nuates to false otherwise. More specifically, (v, d) evaluates to false if the fluent \u3008v,\u00acd\u3009 is in the state, or if no fluent relating the variable, v, and the value, d, is present in the state, in which case we say the current value of v is unknown. We will generally refer to as fluents both positive and negative fluents.\nActions are given as tuples a = \u3008pre(a), eff(a)\u3009, where pre(a) denotes the formulas that must hold in a state S for a to be applicable, and eff(a) represents the new fluents in the resulting state S\u2032. Effects of the form (v = d) add a fluent \u3008v, d\u3009 in the resulting state as well as a set of fluents {\u3008v,\u00acdj\u3009}, \u2200dj 6= d, dj \u2208 Dv , reflecting that (v, dj) evaluates to false in the resulting state. Effects of the form (v 6= d) add a fluent \u3008v,\u00acd\u3009 to the resulting state, which implies the current value of v is unknown unless there is a fluent \u3008v, d\u2032\u3009 in S\u2032, d 6= d\u2032.\nWe define a MAP task as a tuple T = \u3008AG,V,A, I,G\u3009 where: \u2022 AG = {1, . . . , n} is a finite non-empty set of planning agents. \u2022 V = {Vi}ni=1, where Vi is the set of state variables managed by\nagent i. Variables can be shared by two or more different agents. \u2022 A = {Ai}ni=1, where Ai is the set of actions that agent i can\nperform. Given two different agents i, j, Ai and Aj can share some common actions or be two disjoint sets. \u2022 I = {Ii}ni=1, where Ii is the set of fluents known by agent i that represents the initial state of the agent. If two agents share a variable v then they also share all of the fluents regarding v. \u2022 G = {Gi}ni=1, where Gi is a set of formulas known to agent i that must hold in the final state and denote the top-level goals of T .\nAs defined above, state variables may not be known to all agents. Given a state variable v \u2208 Vi and v 6\u2208 Vj , \u2200j 6= i, v is said to be private to agent i. Additionally, agents can have different visions of the domain of a state variable; that is, not every value in a variable domain has to be visible to all agents. Given an agent i, we denote its view of the domain of a variable v as Dvi \u2286 Dv . Thus, the domain of a state variable v can be defined as Dv = {Dvi} n i=1. Agents\u2019 incomplete views on the state variables and their domains directly affect the visibility of the fluents. \u2022 An agent i has full visibility of a fluent \u3008v, d\u3009 or \u3008v,\u00acd\u3009 if v \u2208 Vi\nand d \u2208 Dvi . \u2022 An agent i has partial visibility of a fluent \u3008v, d\u3009 or \u3008v,\u00acd\u3009 if\nv \u2208 Vi but d 6\u2208 Dvi . Given a state S, where \u3008v, d\u3009 \u2208 S, agent i will see instead a fluent \u3008v,\u22a5\u3009, where \u22a5 is the undefined value. \u2022 An agent i has no visibility of a fluent \u3008v, d\u3009 or \u3008v,\u00acd\u3009 if v 6\u2208 Vi. Our MAP model can be viewed as a POP-based, multi-agent refinement planning framework, a general method based on the refinement of the set of all possible partial-order plans [12]. An agent proposes a plan \u03a0 that typically enforces some top-level goals of the planning task; then, the rest of agents collaborate on the refinement of this base plan \u03a0 by proposing refinement steps that solve some open goals in openGoals(\u03a0). This way, agents cooperatively solve the MAP task by consecutively refining an initially empty plan \u03a0.\nA refinement step \u03a0i devised by an agent i over a base plan \u03a0g , where g \u2208 openGoals(\u03a0g), is a triple \u03a0i = \u3008\u2206, OR,CL\u3009, where \u2206 \u2208 Ai is a set of actions and OR and CL are sets of orderings and causal links over \u2206, respectively. \u03a0i is a plan free of threats [18] that solves g as well as all the new open goals that arise from this resolution and can only be achieved by agent i, \u3008v, d\u3009 or \u3008v,\u00acd\u3009, where (v \u2208 Vi) \u2227 (v 6\u2208 Vj , \u2200j 6= i). That is, when solving an open goal of a base plan, an agent i will also achieve the new arising open goals concerning fluents that are only visible to i, so are not visible to the rest of agents, leaving the rest of goals unsolved. Let g \u2208 openGoals(\u03a0g) be a formula of the form (v, d) or (v,\u00acd); an agent i computes a refinement step over \u03a0g iff v \u2208 Vi.\nPlans that agents build are concurrent multi-agent (MA) plans as two different actions in \u03a0 can now be executed concurrently by two different agents. Some MAP models adopt a simple form of concurrency: two actions can happen simultaneously if none of them changes the value of a state variable that the other relies on or affects, too [3]. We impose the additional concurrency constraint that the preconditions of two actions have to be mutually consistent [1]. This definition of concurrency is straightforwardly extended to a joint action a = \u3008a1, . . . , an\u3009. Agents address concurrency inconsistencies through the detection of threats over the causal links of their actions. This way, concurrency issues between two different actions may not arise until their preconditions are supported through causal links.\nA refinement plan \u03a0 devised by an agent i over a base plan \u03a0g is a concurrent MA plan that results from the composition of \u03a0g and a refinement step \u03a0i proposed by agent i. This refinement plan, which could eventually become a base plan, is defined as \u03a0 = \u03a0g \u25e6 \u03a0i, where \u25e6 represents the composition operation. A composite plan \u03a0 is a concurrent MA plan if for every pair of unequal actions ai and aj , i 6= j, \u2200pi \u2208 pre(ai), pi 6\u2208 openGoals(\u03a0), \u2200pj \u2208 pre(aj), pj 6\u2208 openGoals(\u03a0), ai and aj are concurrently consistent.\nIn our model, each agent implements a POP planner to compute refinement plans over a base plan \u03a0. If an agent is not capable to come up with a concurrent MA plan, then the agent refrains from suggesting such a refinement. If no agent elicits a consistent refinement plan for a base plan, the plan node is pruned.\nAlgorithm 1 Dis-RPG construction for an agent i Build initial RPGi repeat \u2200j 6= i, i sends j shareable fluents SFi\u2192j \u2208 RPGi of the form \u3008v, d\u3009 or \u3008v,\u00acd\u3009, where v \u2208 Vi \u2229 Vj and d \u2208 Dvi \u2229 Dvj \u2200j 6= i, i receives from j shareable fluents SFj\u2192i \u2208 RPGj of the form \u3008v, d\u3009 or \u3008v,\u00acd\u3009, where v \u2208 Vi\u2229Vj and d \u2208 Dvi\u2229Dvj\nRF \u2190 \u2205 \u2200j 6= i, RFi \u2190 RFi \u222a SFj\u2192i for all received fluents f \u2208 RFi do\nif f 6\u2208 RPGi then Insert f in RPGi costRPGi(f)\u2190 cost(f) end if if (f \u2208 RPGi) \u2227 (costRPGi(f) > cost(f)) then\ncostRPGi(f)\u2190 cost(f) end if\nend for Expand RPGi\nuntil RFi = \u2205"}, {"heading": "3 REFINEMENT PLANNING", "text": "The cooperative refinement planning algorithm starts with a preliminary information exchange by which agents communicate shareable information. After this initial stage, agents execute the multiagent refinement planning algorithm, which comprises two interleaved stages. First, agents individually elicit refinement plans over a centralized base plan through their embedded POP. Later, agents jointly select the most promising refinement as the next base plan."}, {"heading": "3.1 Information exchange", "text": "Agents receive the information on the MAP task through a set of definition files. These files are encoded in a MAP language that extends PDDL3.1 [13], including a :shared-data section to configure\nthe agent\u2019s vision of the planning task and which fluents it shares and with whom.\nPrior to executing the refinement procedure, agents share information by building a distributed Relaxed Planning Graph (dis-RPG), based on the approach of [19]. Agents exchange the fluents defined as shareable in the :shared-data section of the MAP definition files. Fluents are labeled with the list of agents that can achieve them, giving each agent a view of the possible interactions that can arise at planning time with other agents. Additionally, the dis-RPG provides an estimate of the best cost to achieve each fluent, a helpful information to design heuristics to guide the problem-solving process.\nAlgorithm 1 summarizes the construction of the dis-RPG. Agents compute an initial RPG and expand it by following the procedure in [10]. The RPG contains a set of fluent and action levels that are interleaved. The first fluent level contains the fluents that are part of the initial state, and the first action level includes all the actions whose preconditions appear in the first fluent level. The effects of these actions are placed in the second fluent level, and this way the graph is expanded until no new fluents are found.\nOnce all the agents have computed their initial RPGs, the iterative dis-RPG composition begins. As depicted in Algorithm 1, agents start each iteration by exchanging the the fluents shareable with other agents. An agent i will send agent j the set of fluents SFi\u2192j that are visible to agent j, i.e., the new fluents of the form \u3008v, d\u3009 or \u3008v,\u00acd\u3009, where v \u2208 Vi\u2229Vj and d \u2208 Dvi\u2229Dvj . Likewise, agent i will receive from all agents j 6= i the shareable fluents they have generated.\nAgent i updates then its RPGi with the set of new fluents it has received, RFi. If a fluent f is not yet in RPGi, it is stored according to cost(f). If f is already in RPGi, its cost is updated if costRPGi(f) > cost(f). Hence, agents only store the best estimated cost to reach each fluent. After updating RPGi, agent i expands it by checking whether the new inserted fluents trigger new actions in RPGi or not. The fluents produced as effects of these new actions will be shared in the next iteration.\nThe process finishes when there are no new fluents in the system. Following, agents start the refinement planning process to build a solution plan jointly."}, {"heading": "3.2 Multi-agent refinement planning", "text": "The refinement planning process is based on a democratic leadership by which a baton is scheduled among the agents following a roundrobin strategy. Agents carry out two interleaved stages: the individual construction of refinement plans through a POP, and a coordination process by which agents jointly search the refinement space.\nAlgorithm 2 describes the refinement planning process. Each agent i computes a finite set of refinement plans for \u03a0g , Refinementsi(\u03a0\ng), through its embedded POP planner. The internal POP system follows an A\u2217 search algorithm guided by a stateof-the-art POP heuristic function [18]. The resulting refinement plans are exchanged by the agents in the system for their evaluation (send and receive operations in Algorithm 2).\nAgent i has a local, partial vision of each refinement plan, viewi(\u03a0), according to its visibility over the planning task T . Thus, when receiving a refinement plan \u03a0, agent i will only view the open goals (v, d) \u2208 openGoals(\u03a0) | v \u2208 Vi. With respect to the fluents, agent i will only view those fluents for which it has full visibility. If i has partial visibility of a fluent \u3008v, d\u3009 or \u3008v,\u00acd\u3009, it will see instead a fluent \u3008v,\u22a5\u3009, where \u22a5 stands for the undefined value. This notion of partial view directly affects the evaluation of the refinements.\nThe evaluation of refinement plans is carried out through a utility function F (currently, we use the same heuristic function that guides\nthe agents\u2019 internal POP for this purpose) that allows agents to estimate the quality of the plans. Since agents do not have complete information on the MAP task or the refinement plans, they evaluate plans according to its own view of each refinement plan \u03a0, i.e., agent i evaluates a refinement plan \u03a0 according to F(viewi(\u03a0)) (see Algorithm 2).\nAlgorithm 2 Refinement planning process for an agent i \u03a0\u2190 \u03a00 R = \u2205 repeat\nSelect open goal g \u2208 openGoals(\u03a0) Refine base plan \u03a0g individually \u2200j 6= i, send Refinementsi(\u03a0g) to agent j \u2200j 6= i, receive Refinementsj(\u03a0g) Refinements(\u03a0g)\u2190 Refinementsi(\u03a0g) \u2200j 6= i, Refinements(\u03a0g)\u2190 Refinements(\u03a0g)\u222a Refinementsj(\u03a0\ng) for all plans \u03a0 \u2208 Refinements(\u03a0g) do\nEvaluate \u03a0 according to F(viewi(\u03a0)) end for R\u2190 R \u222aRefinements(\u03a0g) Select best-valued plan \u03a0best \u2208 R \u03a0\u2190 \u03a0best if openGoals(\u03a0) = \u2205 then\nreturn \u03a0 end if\nuntil R = \u2205\nOnce evaluated, the new refinement plans are stored in the set of refinements R. Next, each agent votes for the best-valued candidate \u03a0best \u2208 R. In case of a draw, the baton agent will choose the next base plan among the most voted alternatives.\nOnce a refinement plan is selected, agents adopt it as the new base plan \u03a0. If openGoals(\u03a0) = \u2205, a solution plan is returned. As some open goals might not be visible to some agents, every agent i must confirm that \u03a0 is a solution plan according to viewi(\u03a0), i.e., \u03a0 is a solution iff \u2200i \u2208 AG, openGoals(viewi(\u03a0)) = \u2205. If the plan has still pending goals, the baton agent selects the next open goal g \u2208 openGoals(\u03a0) to be solved, and a new iteration of the refinement planning process starts.\nThe planning algorithm carried out by the agents can be regarded as a joint exploration of the refinement space. Nodes in the search tree represent refinement plans and each iteration of the algorithm expands a different node."}, {"heading": "3.3 Soundness and completeness", "text": "The algorithm we have presented can be regarded as a multi-agent extension of the POP algorithm. A partial-order plan is sound if it is a threat-free plan. In our algorithm, we address inconsistencies among the concurrent MA plans by detecting and solving threats. Thus, in order to prove that our algorithm is sound, we should ensure that all the threats among the causal links of a concurrent MA plan are correctly detected and solved.\nUnder complete information, threats on a MA concurrent plan will be correctly detected by any agent, as all the fluents in the plan are fully visible. In our incomplete information model, we should study how visibility over fluents affects the detection of threats.\nLet \u03a0 be a MA concurrent plan and let \u3008v, d1\u3009 be a fluent in a causal link cl \u2208 CL(\u03a0). Suppose that an agent i builds a refinement \u03a0\u2032 over \u03a0 that adds a new action at to the plan which is not ordered with respect to cl and has an effect (v = d2). This effect causes a\nthreat over cl as it conflicts with \u3008v, d1\u3009. For \u03a0\u2032 to be sound, agent i should be able to detect such a threat whatever visibility it has over the fluent \u3008v, d1\u3009: \u2022 If i has full visibility over \u3008v, d1\u3009, the inconsistency between cl\nand at will be correctly detected. \u2022 If i has no visibility over \u3008v, d1\u3009, then v 6\u2208 Vi. In this case, agent i\ndoes not have an action at with an effect involving variable v, i.e., such a threat can never occur. \u2022 If i has partial visibility over \u3008v, d1\u3009, agent i will see instead a fluent \u3008v,\u22a5\u3009. Since\u22a56= d2, the threat will be detected and solved.\nTherefore, all the threats over MA concurrent plans are always detected and resolved, which proves that our MAP algorithm is sound.\nAs for completeness, we cannot ensure that our MAP algorithm is complete. According to the notion of refinement plan we have used in this work, the number of refinement plans that an agent can produce over a base plan may not be finite. Hence, we are implicitly pruning the refinement search space. Nevertheless, agents rely on an A\u2217 POP search process to build the refinement plans, which in most cases returns good refinement plans that guide the MAP algorithm towards a solution plan. The empirical results shown in the next section confirm our claim."}, {"heading": "4 EXPERIMENTAL RESULTS", "text": "We designed and executed a set of tests to compare the performance and scalability of our MAP-POP approach with another state-of-theart MAP system. Comparing the performance of multi-agent planning systems is not an easy task due to two main reasons. First, most MAP approaches are not general-purpose but domain-dependent systems specifically designed to address a particular problem, most typically traffic control or real-time planning applications. Second, unlike single-agent planners that have been promoted and populated through the celebration of the International Planning Competitions2 (IPC) and, therefore, have been made publicly available, it is difficult to find a multi-agent planner able to run the benchmark domains and planning problem suites created for the IPCs.\nDespite these drawbacks, we could assess the performance of MAP-POP and compare the results with those obtained in the Planning First approach presented in [15]3. Planning First is a MAP system that also makes use of single-agent planning technology. More precisely, it builds upon a single-agent state-based planner [4], and handles agent coordination by solving a distributed CSP.\nPlanning First defines public actions as the actions of an agent whose descriptions contain atoms affected by and/or affecting the 2 http://ipc.icaps-conference.org/ 3 We want to especially thank Raz Nissim for providing us with the source\ncode of his Planning First system for testing and comparison purposes.\nactions of another agent. Based on this concept, it defines the notion of coupling level as the average rate of public actions of an agent. A high value of coupling level results in many agent coordination points, thus giving rise to tightly-coupled problems. The approach followed by Planning First is especially effective when dealing with loosely-coupled problems (LCP) [15], but its performance decreases when tackling tightly-coupled problems (TCP).\nWe adapted the STRIPS problem files used in the IPCs to both our MAP language and Nissim\u2019s MA-STRIPS language. Problems from the IPCs turned out to be complex instances for Planning First because agents have necessarily to interact to each other and cooperate to find a solution plan for these problems and Planning First works better when plans for each agent can be computed (mostly) independently. For this reason, we encoded an additional set of problems limiting cooperation and interactions among agents as much as possible. Particularly, in these additional problems, agents can solve goals independently, i.e., an agent is able to solve a goal or set of goals by itself without need of interacting with the rest of agents (we will refer to these problems as independent problems in the remainder).\nTable 1 shows the results when comparing the quality of the solution plans obtained with MAP-POP and Planning First and the execution times4. The quality of the solution plans is assessed through three parameters: a) the number of actions of the plan; b) the duration of the plan, i.e. the number of time units or time steps required to execute the plan; and c) the number of agents that take part in the solution plan. This latter parameter gives an idea of how the effort on solving the problem has been distributed among the agents.\n4 All the tests were performed on a single machine with a 2.83 GHz Intel Core 2 Quad CPU and 8 GB RAM.\nProblems labeled with IPC are directly taken from the IPC benchmarks, while problems labeled with Ind are the extra set of independent problems we created to assess Planning First performance (for each domain, we show the results of 5 out of the 20 IPC problems we tested as well as 5 independent problems). The next three columns in the table show the difficulty of the planning problems: #Agents indicates the number of agents involved in the problem; %Coupling level estimates the coupling level of the problem as the average rate of instantiated public actions of agents (taking into consideration the notion of public and private action defined in [15]), and #Domain actions refers to the total number of instanced actions. The results for each planner include the number of actions(#Acts) and time steps (#TS) of the solution plan, respectively. #Partics indicates the number of agents that take part in the solution plan, and Time shows the total execution time. A dagger (\u2020) indicates that Planning First was not able to solve the problem.\nFor the most loosely-coupled problems, the satellite domain, MAP-POP exhibited an excellent performance as our results confirmed that it was able to solve 18 out of 20 IPC problems. For the five IPC problems for the satellite domain shown in Table 1, we can see that our approach deals very efficiently with complex problems up to 12 agents. It is also noticeable that at least one third of the participating agents take part in the solution plans, which has a positive impact on the plan duration, as actions are carried out in parallel by different agents. Although the IPC satellite problems do not present a high coupling level (less than 30% of public actions in the worst case), Planning First only solves the first IPC problem, as these problems require cooperation among agents and it is more necessary for larger instances. As for the additional problems we encoded (IndSat1, ..., IndSat5), we can see that Planning First is not able to solve the largest one, IndSat5. Planning First is faster than MAP-POP when\ndealing with small problems, but its performance decreases when the size of the problem increases. For instance, while the first three problems are solved faster by Planning First, it is slower than MAP-POP when solving IndSat4, and it does not find a solution to the most complex instance, IndSat5. MAP-POP proves also to be more effective at parallelizing actions in this domain as it obtains plans of equal or shorter duration than Planning First.\nWith respect to the rovers domain, our results confirmed that MAP-POP solves 15 out of the 20 IPC problems for this domain. For the five IPC rovers problems shown in Table 1, we can see the workload in this domain is better distributed than in the satellite domain as most of the agents participate in the solution plan, which considerably reduces the duration of the plan. For instance, the solution plan for problem IPCRov7 contains 18 actions and is solved in just 6 time steps. Planning First solves only the two smallest IPC problems. For the independent problems we modeled, Planning First obtains betterquality but more costly solutions than MAP-POP. The differences in execution time are far more noticeable than in the satellite domain. This is due to to the more tightly-coupled nature of the problems of this domain (45.5% coupling level for the independent problems), which affects negatively the performance of Planning First.\nFinally, the logistics domain has proven to be the most complex one for both multi-agent approaches. Agents in this domain are trucks and airplanes that must cooperate in most of the cases to transport packages. Hence, solutions for these problems are more costly than in the rovers and satellite domains, as they require agent coordination, an important feature to determine the efficiency of a MAP approach. Our results confirmed that MAP-POP loses performance in this domain, being able to solve only 9 out of 20 IPC problems. However, it distributes the workload effectively since all of the agents participate in all the solution plans obtained. Planning First shows\nalso a poorer performance in this domain as it is not able to solve any of the IPC problems. These results are in line with the conclusions exposed in [15], which reveals the difficulty of a CSP-based approach to deal efficiently with problems that exhibit a high level of inter-agent interaction. As for the independent problems, some of the solutions obtained by MAP-POP have better quality in terms of actions and duration than the solutions of Planning First. In addition, Planning First is still remarkably slower than MAP-POP, being unable to solve the IndLog5 problem, even though we defined rather small instances (notice the differences in execution time for the instance IndLog4). Again, Planning First only performs better than MAP-POP in the smaller problems.\nThe second test compares the scalability of both MAP frameworks, i.e. to which extent their efficiency is affected by the number of agents. In order to do so, we have run fourteen different tests for both the satellite and the rovers domains. Each test increases the number of agents in the task by one, from one agent to fourteen. The problems are modeled so that each of the participant agents has to achieve one of the problem\u2019s goals by itself.\nFigure 1 shows the scalability results for the satellite domain. As it can be observed, Planning First show a better performance when solving small problems (up to seven agents). However, its performance decreases quickly as we execute larger problems. MAP-POP is faster at solving the 8-agent satellite problem, and Planning First is unable to find a solution for the 9-agent problem upwards. MAPPOP, however, finds a solution for the 14 problem instances, and execution times suffer only a slight increase between problems.\nThe differences in performance of both systems are more noticeable in the more tightly-coupled rovers domain. The results of this test are depicted in figure 2. In this case, Planning First requires more than 40 minutes to solve the 6-agent rovers problem, while MAP-POP takes only 20 seconds. Again, MAP-POP solves all the problems without losing performance in the larger instances.\nIn conclusion, MAP-POP proves to be a more robust approach than Planning First as it can tackle larger and more complex planning problems. Moreover, while Planning First is designed for solving LCP, MAP-POP is a general-purpose method that tackles problems of different coupling levels. Although MAP-POP behaves better in LCP problems, it can also solve complex TCP problems. Scalability results show that Planning First performs better when dealing with simple problems that involve few agents. However, MAP-POP scales up far better, being able to solve much larger planning problems."}, {"heading": "5 CONCLUSIONS AND FUTURE WORK", "text": "This paper presents a general-purpose MAP model suitable to cope with a wide variety of MA planning domains under incomplete information. The ability to define incomplete views of the world for the agents allows us to deal with more real problems, from inherently distributed domains -functionally or spatially- to problems that handle global and centralized sources of information. Currently, we are testing our planner on large-size logistics applications in which agents are geographically distributed and are completely unaware of the other agent\u2019s information except for the coordination points within their working areas.\nThe MAP resolution process is a POP-based refinement planning approach that iteratively combines planning and coordination while maintaining for each agent only the information that is visible to the planning entity. This POP approach centered around the gradual construction of a joint solution plan for the MAP task highly benefits the resolution of cooperative distributed planning problems.\nWe have compared our MAP approach against Planning First, a\nsystem that handles agent coordination through a distributed CSP. Results show that MAP-POP efficiently solves loosely-coupled problems but it also shows competitive when solving problems that have a higher coupling level and when computing plans that require the cooperation among agents. Hence, we can conclude that MAP-POP is an efficient, domain-independent and general-purpose framework to solve MAP problems."}, {"heading": "ACKNOWLEDGEMENTS", "text": "This work has been partly supported by the Spanish MICINN under projects Consolider Ingenio 2010 CSD2007-00022 and TIN201127652-C03-01, and the Valencian Prometeo project 2008/051."}], "references": [{"title": "Partial-order planning with concurrent interacting actions", "author": ["C. Boutilier", "R.I. Brafman"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2001}, {"title": "From one to many: Planning for loosely coupled multi-agent systems", "author": ["R.I. Brafman", "C. Domshlak"], "venue": "in 18th International Conference on Automated Planning and Scheduling (ICAPS),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2008}, {"title": "Continual planning and acting in dynamic multiagent environments", "author": ["M. Brenner", "B. Nebel"], "venue": "Journal of Autonomous Agents and Multiagent Systems,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Teaching forward-chaining planning with JavaFF", "author": ["A.I. Coles", "M. Fox", "D. Long", "A. Smith"], "venue": "in Colloquium on AI Education, 23th AAAI Conference on Artificial Intelligence,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "An efficient algorithm for multiagent plan coordination", "author": ["J.S. Cox", "E.H. Durfee"], "venue": "in 4th International Conference on Autonomous Agents and Multiagent Systems (AAMAS),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2005}, {"title": "A distributed framework for solving the multiagent plan coordination problem", "author": ["J.S. Cox", "E.H. Durfee", "T. Bartold"], "venue": "in 4th International Conference on Autonomous Agents and Multiagent Systems (AAMAS),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2005}, {"title": "Introduction to planning in multiagent systems", "author": ["M. de Weerdt", "B. Clement"], "venue": "Multiagent and Grid Systems,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "Wolverton, \u2018A survey of research in distributed continual planning", "author": ["M.E. desJardins", "E.H. Durfee", "C.L. Ortiz", "M.J"], "venue": "AI Magazine,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1999}, {"title": "Distributed problem solving and planning\u2019, in Multiagent Systems and Applications (EASSS), volume", "author": ["E.H. Durfee"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2086}, {"title": "The FF planning system: Fast planning generation through heuristic search", "author": ["J. Hoffmann", "B. Nebel"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2001}, {"title": "Scaling up multiagent planning: A bestresponse approach", "author": ["A. Jonsson", "M. Rovatsos"], "venue": "in 21st International Conference on Automated Planning and Scheduling (ICAPS),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Refinement planning as a unifying framework for plan synthesis", "author": ["S. Kambhampati"], "venue": "AI Magazine,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1997}, {"title": "Complete BNF description of PDDL3.1", "author": ["D.L. Kovacs"], "venue": "Technical report,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2011}, {"title": "Planning for loosely coupled agents using partial order forward-chaining", "author": ["J. Kvarnstr\u00f6m"], "venue": "in 21st International Conference on Automated Planning and Scheduling (ICAPS),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2011}, {"title": "A general, fully distributed multi-agent planning algorithm", "author": ["R. Nissim", "R.I. Brafman", "C. Domshlak"], "venue": "in 9th International Conference on Autonomous Agents and Multiagent Systems (AAMAS),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Towards flexible teamwork", "author": ["M. Tambe"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1997}, {"title": "Plan coordination by revision in collective agent based systems", "author": ["H. Tonino", "A. Bos", "M. de Weerdt", "C. Witteveen"], "venue": "Artificial Intelligence,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2002}, {"title": "Vhpop: Versatile heuristic partial order planner", "author": ["H.L.S. Younes", "R.G. Simmons"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2003}, {"title": "Graph-based multi-agent replanning algorithm", "author": ["J.F. Zhang", "X.T. Nguyen", "R. Kowalczyk"], "venue": "in 6th International Conference on Autonomous Agents and Multiagent Systems (AAMAS),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2007}], "referenceMentions": [{"referenceID": 8, "context": "In general terms, MAP is about the collective effort of multiple planning agents to combine their knowledge, information, and capabilities so as to develop solutions to problems that each could not have solved as well (if at all) alone [9].", "startOffset": 236, "endOffset": 239}, {"referenceID": 7, "context": "Agent-oriented MAP approaches put the emphasis on distributed execution, plan synchronization and collaborative activity at run-time planning to ensure that the agent\u2019s local objectives will be met [8, 16].", "startOffset": 198, "endOffset": 205}, {"referenceID": 15, "context": "Agent-oriented MAP approaches put the emphasis on distributed execution, plan synchronization and collaborative activity at run-time planning to ensure that the agent\u2019s local objectives will be met [8, 16].", "startOffset": 198, "endOffset": 205}, {"referenceID": 16, "context": "Another research line in MAP focuses on coordination of already completed plans that agents have constructed to achieve their individual goals, as for example plan merging [17, 6, 5].", "startOffset": 172, "endOffset": 182}, {"referenceID": 5, "context": "Another research line in MAP focuses on coordination of already completed plans that agents have constructed to achieve their individual goals, as for example plan merging [17, 6, 5].", "startOffset": 172, "endOffset": 182}, {"referenceID": 4, "context": "Another research line in MAP focuses on coordination of already completed plans that agents have constructed to achieve their individual goals, as for example plan merging [17, 6, 5].", "startOffset": 172, "endOffset": 182}, {"referenceID": 7, "context": "In contrast, the cooperative distributed planning (CDP) approach puts the emphasis on planning and how it can be extended into a distributed environment, on building a competent plan carried out by multiple agents [8].", "startOffset": 214, "endOffset": 217}, {"referenceID": 8, "context": "Following the cooperative approach, differences among MAP models lie in the integration of the planning and coordination stages [9, 7].", "startOffset": 128, "endOffset": 134}, {"referenceID": 6, "context": "Following the cooperative approach, differences among MAP models lie in the integration of the planning and coordination stages [9, 7].", "startOffset": 128, "endOffset": 134}, {"referenceID": 13, "context": "The work in [14] considers agents as having sequential threads of execution and interaction only occurs when distributing sub-plans to individual agents for plan execution.", "startOffset": 12, "endOffset": 16}, {"referenceID": 1, "context": "A centralized algorithm for MAP can be found in [2], where multiple agents do planning over a centralized plan interleaving planning and coordination.", "startOffset": 48, "endOffset": 51}, {"referenceID": 14, "context": "1 Universitat Polit\u00e8cnica de Val\u00e8ncia, Camino de Vera s/n, 46022 Valencia, Spain In a distributed version of this latter work, authors use a distributed CSP solver to handle coordination [15].", "startOffset": 187, "endOffset": 191}, {"referenceID": 14, "context": "The aforementioned approaches are conceived for loosely-coupled problems (LCP), where agents have little interaction between each other, as these processes are likely to be inefficient in tightly-coupled problems (TCP) [15].", "startOffset": 219, "endOffset": 223}, {"referenceID": 1, "context": "This way, the coupling level of a cooperative multi-agent system is formally defined as a set of parameters to limit the combinatorial blow-up of planning complexity [2].", "startOffset": 166, "endOffset": 169}, {"referenceID": 10, "context": "Similarly to [11], we use an iterative planning refinement procedure that uses single-agent planning technology.", "startOffset": 13, "endOffset": 17}, {"referenceID": 13, "context": "POP is a very suitable approach for centralized MAP with a small number of coordination points between agents [14], and the application of a multi-agent POP refinement framework also reveals as a very appropriate mechanism to address tightly-coupled problems.", "startOffset": 110, "endOffset": 114}, {"referenceID": 11, "context": "Our MAP model can be viewed as a POP-based, multi-agent refinement planning framework, a general method based on the refinement of the set of all possible partial-order plans [12].", "startOffset": 175, "endOffset": 179}, {"referenceID": 17, "context": "\u03a0i is a plan free of threats [18] that solves g as well as all the new open goals that arise from this resolution and can only be achieved by agent i, \u3008v, d\u3009 or \u3008v,\u00acd\u3009, where (v \u2208 Vi) \u2227 (v 6\u2208 Vj , \u2200j 6= i).", "startOffset": 29, "endOffset": 33}, {"referenceID": 2, "context": "Some MAP models adopt a simple form of concurrency: two actions can happen simultaneously if none of them changes the value of a state variable that the other relies on or affects, too [3].", "startOffset": 185, "endOffset": 188}, {"referenceID": 0, "context": "We impose the additional concurrency constraint that the preconditions of two actions have to be mutually consistent [1].", "startOffset": 117, "endOffset": 120}, {"referenceID": 12, "context": "1 [13], including a :shared-data section to configure", "startOffset": 2, "endOffset": 6}, {"referenceID": 18, "context": "Prior to executing the refinement procedure, agents share information by building a distributed Relaxed Planning Graph (dis-RPG), based on the approach of [19].", "startOffset": 155, "endOffset": 159}, {"referenceID": 9, "context": "Agents compute an initial RPG and expand it by following the procedure in [10].", "startOffset": 74, "endOffset": 78}, {"referenceID": 17, "context": "The internal POP system follows an A\u2217 search algorithm guided by a stateof-the-art POP heuristic function [18].", "startOffset": 106, "endOffset": 110}, {"referenceID": 14, "context": "Despite these drawbacks, we could assess the performance of MAP-POP and compare the results with those obtained in the Planning First approach presented in [15].", "startOffset": 156, "endOffset": 160}, {"referenceID": 3, "context": "More precisely, it builds upon a single-agent state-based planner [4], and handles agent coordination by solving a distributed CSP.", "startOffset": 66, "endOffset": 69}, {"referenceID": 14, "context": "The approach followed by Planning First is especially effective when dealing with loosely-coupled problems (LCP) [15], but its performance decreases when tackling tightly-coupled problems (TCP).", "startOffset": 113, "endOffset": 117}, {"referenceID": 14, "context": "The tests presented here involve three of the benchmark domains used on the IPCs: satellite, rovers and logistics, which are the domains used in the results presented in [15] as well.", "startOffset": 170, "endOffset": 174}, {"referenceID": 14, "context": "The next three columns in the table show the difficulty of the planning problems: #Agents indicates the number of agents involved in the problem; %Coupling level estimates the coupling level of the problem as the average rate of instantiated public actions of agents (taking into consideration the notion of public and private action defined in [15]), and #Domain actions refers to the total number of instanced actions.", "startOffset": 345, "endOffset": 349}, {"referenceID": 14, "context": "These results are in line with the conclusions exposed in [15], which reveals the difficulty of a CSP-based approach to deal efficiently with problems that exhibit a high level of inter-agent interaction.", "startOffset": 58, "endOffset": 62}], "year": 2015, "abstractText": "Multi-agent planning (MAP) approaches have been typically conceived for independent or loosely-coupled problems to enhance the benefits of distributed planning between autonomous agents as solving this type of problems require less coordination between the agents\u2019 sub-plans. However, when it comes to tightlycoupled agents\u2019 tasks, MAP has been relegated in favour of centralized approaches and little work has been done in this direction. In this paper, we present a general-purpose MAP capable to efficiently handle planning problems with any level of coupling between agents. We propose a cooperative refinement planning approach, built upon the partial-order planning paradigm, that allows agents to work with incomplete information and to have incomplete views of the world, i.e. being ignorant of other agents\u2019 information, as well as maintaining their own private information. We show various experiments to compare the performance of our system with a distributed CSP-based MAP approach over a suite of problems.", "creator": "LaTeX with hyperref package"}}}