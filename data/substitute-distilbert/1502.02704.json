{"id": "1502.02704", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Feb-2015", "title": "Learning Reductions that Really Work", "abstract": "we provide a summary of the mathematical and algorithm techniques that have enabled learning reductions to effectively address a wide class using structures, and show that this approach to solving machine learning problems can be broadly useful.", "histories": [["v1", "Mon, 9 Feb 2015 22:05:25 GMT  (60kb,D)", "http://arxiv.org/abs/1502.02704v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["alina beygelzimer", "hal daum\\'e iii", "john langford", "paul mineiro"], "accepted": false, "id": "1502.02704"}, "pdf": {"name": "1502.02704.pdf", "metadata": {"source": "CRF", "title": "Learning Reductions that Really Work", "authors": ["Alina Beygelzimer", "John Langford"], "emails": ["beygel@yahoo-inc.com", "hal@umiacs.umd.edu", "jcl@microsoft.com", "pmineiro@microsoft.com"], "sections": [{"heading": "1 Introduction", "text": "In a reduction, a complex problem is decomposed into simpler subproblems so that a solution to the simpler subproblems gives a solution to the complex problem. When this is a simple process, it is conventionally called \u201cprogramming\u201d, while \u201creduction\u201d is reserved for more difficult applications of this technique. Computational complexity theory, for example, relies on reductions in an essential fashion to define computational complexity classes, most canonically NP-hard problems. In machine learning, reductions are often used constructively to build good solutions to hard problems.\nThe canonical example here is the one-against-all reduction, which solves k-way multiclass classification via reduction to k base predictions: The ith predictor is trained to predict whether a label is class i or not. Figure 1 shows how this reduction works experimentally, comparing the multiclass loss to the average loss of base predictors. There are no base predictors with small loss inducing a large multiclass loss\u2014as ruled out by theory.\nFor this paper, a learning reduction takes as input complex examples, transforms them into simpler examples, invokes an appropriate learning algorithm on the simpler examples, then transforms predictions on these simpler examples to a prediction on the complex examples. Learning reductions vary in the definition of \u201ccomplex examples\u201d, \u201csimpler examples\u201d, and \u201ctransforms\u201d.\nAre learning reductions an effective approach for solving complex machine learning problems? The answer is not obvious, because there is a nontrivial representational concern: maybe the process of reduction creates \u201chard\u201d problems that simply cannot be solved well? A simple example is given by 3-class classification with a single feature and a linear predictor. If class i has feature value i, then the 2 versus 1, 3 classifier necessarily has a large error rate, causing the one-against-all reduction to perform poorly. The all-pairs reduction, which learns a classifier for each pair of labels, does not suffer from this problem in this case.\nar X\niv :1\n50 2.\n02 70\n4v 1\n[ cs\n.L G\n] 9\nAlthough this concern is significant, it is of unclear strength as there are many computationally convenient choices made in machine learning, such as conjugate priors, proxy losses, and sigmoid link functions. Perhaps the representations created by natural learning reductions work well on natural problems? Or perhaps there is a theory of representation respecting learning reductions?\nWe have investigated this approach to machine learning for about a decade now, and provide a summary of results here, addressing several important desiderata:\n1. A well-founded theory for analysis. A well-founded theory makes the approach teachable, and provides a form of assurance that good empirical results should be expected, and carry over to new problems.\n2. Good statistical performance. In addition, the theory should provide some effective guidance about which learning algorithms are better than other learning algorithms.\n3. Good computational performance. Computational limitations in machine learning are often active, particularly when there are large amounts of data. This is critical for learning reductions, because the large data regime is where sound algorithmics begin to outperform clever representation and problem understanding.\n4. Good programmability. Programmability is a nontraditional concern for machine learning which can matter significantly in practice.\n5. A unique ability. Learning reductions must either significantly exceed the performance of existing systems on existing problems or provide a means to address an entirely new class of problems for the effort of mastering the approach to be justified.\nHere we show that all the above criteria have now been met."}, {"heading": "1.1 Strawman one-against-all", "text": "A common approach to implementing one-against-all for k-way multiclass classification is to create a script that processes the dataset k times, creating k intermediate binary datasets, then executes a binary learning algorithm k times, creating k different model files. For test time evaluation, another script then invokes a testing system k times for each example in a batch. The multiclass prediction is the label with a positive prediction, with ties broken arbitrarily.\nA careful study of learning reductions reveals that every aspect of this strawman approach can be improved."}, {"heading": "1.2 Organization", "text": "Section 2 discusses the kinds of reduction theory that have been developed and found most useful. Section 3 discusses the programming interface we have developed for learning reductions. Although programmability is a nonstandard concern in machine learning applications, we have found it of critical importance. Creating a usable interface which is not computationally constraining is critical to success.\nSection 4 discusses several problems for which the only known solution is derived via a reduction mechanism, providing evidence that the reduction approach is useful for research.\nSection 5 shows experimental results for a particularly complex \u201cdeep\u201d reduction for structured prediction, including comparisons with many other approaches.\nTogether, these sections show that learning reductions are a useful approach to research in machine learning."}, {"heading": "2 Reductions theory", "text": "There are several natural learning reduction theories on a spectrum from easy to powerful, which we discuss in turn."}, {"heading": "2.1 Error reductions", "text": "In an error reduction, a small error rate on the created problems implies a small error rate on the original problem. When multiple base problems are created, we measure the average error rate over the base problems. Since it is easy to resample examples or indicate via an importance weight that one example is more important than the other, nonuniform averages are allowed.\nFor example, in the strawman one-against-all reduction, an average binary classification error rate of implies a multiclass error rate of at most (k \u2212 1) (see [4, 29]). A careful examination of the analysis shows how to improve the error-transformation properties of the reduction: The first observation is that it helps to break ties randomly instead of arbitrarily. The second observation is that, in the absence of other errors, a false negative implies only a 1/k probability of making the right multiclass prediction, while for a false positive this probability is 1/2. Thus modifying the reduction to make the binary classifier more prone to output a positive, which can be done via an appropriate use of importance weighting, improves the error transform from (k\u22121) to roughly k2 . As predicted by theory, both of these elements yield an improvement in practice [11].\nAnother example of an error reduction for multiclass classification is based on error-correcting output codes [23,29].\nA valid criticism of error reductions is that the guarantees they provide become vacuous if the base problems they create are inherently noisy. For example, when no base binary classifier can achieve an error rate better than 2k , the one-against-all guarantee above is vacuous."}, {"heading": "2.2 Regret reductions", "text": "Regret analysis addresses this criticism by analyzing the transformation of excess loss, or regret. Here regret of a predictor is the difference between its loss and the minimum achievable loss on the same problem. In contrast to many other forms of learning theory, the minimum is over all predictors.\nA reduction that translates any optimal (i.e., no-regret) solution to the base problems into an optimal solution to the top-level problem is called consistent. Consistency is a basic requirement for a good reduction. Unfortunately, error reductions are generally inconsistent. To see that oneagainst-all is inconsistent, consider three classes with true conditional probabilities 12 \u2212 2\u03b4, 1 4 + \u03b4, and 14 + \u03b4. The optimal base binary prediction is always 0, resulting in multiclass loss of 2/3. The corresponding multiclass regret is 16 \u2212 2\u03b4, which is positive for any \u03b4 < 1/12.\nStrawman one-against-all can be easily made consistent by reducing to squared-loss regression instead of binary classification. The multiclass prediction is made by evaluating the learned regressor on all labels and predicting with the argmax. As shown below, this regression approach is consistent. It also resolves ties via precision rather than via randomization, as seems more likely to be effective in practice. Figure 2 illustrates the empirical superiority of reducing to regression rather than binary classification for the Mnist [41] data set.\nWe will analyze the regret transform of this approach for any fixed x, taking expectation over x at the end. Let f(x, a) be the learned regressor, predicting the conditional probability of class a on x. Let pa be the true conditional probability. The squared loss regret of f on the predicted\nclass a is\nEy |x[(f(x, a)\u2212 I(y = a))2 \u2212 (pa \u2212 I(y = a))2] =(pa \u2212 f(x, a))2.\nSimilarly, the regret of f on the optimal label a\u2217 = arg maxa pa is (pa\u2217 \u2212 f(x, a\u2217))2. To incur multiclass regret, we must have f(x, a) \u2265 f(x, a\u2217). The two regrets are convex and the minima is reached when f(x, a) = f(x, a\u2217) = pa+pa\u22172 . The corresponding squared loss regret suffered by f on both a and a\u2217 is (p\u2217a \u2212 pa)2/2. Since the regressor doesn\u2019t need to incur any loss on other predictions, the regressor can pay reg(f) = (p\u2217a \u2212 pa)2/2k in average squared loss regret to induce multiclass regret of pa\u2217 \u2212 pa on x. Solving for multiclass regret in terms of reg(f) shows that the multiclass regret of this approach is bounded by \u221a 2k reg(f). Since the adversary can play this optimal strategy the bound is tight. Although a regret reduction is more desirable than an error reduction, the typical square root dependence introduced when analyzing regret is not desirable. Nonetheless, moving from an error reduction to a regret reduction is often empirically beneficial (see Figure 2).\nThere are many known regret reductions for such problems as multiclass classification [33,47], costsensitive classification [12, 39], and ranking [2, 3]. There is also a rich body of work on so called surrogate regret bounds. It is common to use some efficiently minimizable surrogate loss instead of the loss one actually wishes to optimize. A surrogate regret bound quantifies the resulting regret in terms of the surrogate regret [2, 7, 55]. These results show that standard algorithms minimizing the surrogate are in fact consistent solutions to the problem at hand. In some cases, commonly used surrogate losses actually turn out to be inconsistent [27]."}, {"heading": "2.3 Adaptive reductions", "text": "Adaptive reductions create learning problems that are dependent on the solution to other learning problems. In general, adaptivity is undesirable, since conditionally defined problems are more difficult to form and solve well\u2014they are less amenable to parallelization, and more prone to overfitting due to propagation and compounding of errors.\nIn some cases, however, the best known reduction is adaptive. One such example is logarithmic time multiclass prediction, discussed in section 4.4. All known unconditional log-time approaches yield inconsistency in the presence on label noise [12].\nThe average base regret is still well defined as long as there is a partial order over the base problems, i.e., each base learning problem is defined given a predictor for everything earlier in the order.\nBoosting [49] can be thought of as an adaptive reduction for converting any weak learner into a strong learner. Typical boosting statements bound the error rate of the resulting classifier in terms of the weighted training errors t on the distributions createdy adaptively by the booster. Ability to boost is rooted in the assumption of weak learnability\u2014 a weak learner gets a positive edge over random guessing for any distribution created by the booster. As with any reduction, there is a concern that the booster may create \u201chard\u201d distributions, making it difficult to satisfy the assumption. Although linear separability with a positive margin implies weak learnability [49], linear separability is still a strong assumption. Despite this concern, boosting has been incredibly effective in practice."}, {"heading": "2.4 Optimization oracle reductions", "text": "When the problem is efficiently gathering information, as in active learning (discussed in section 4.3) or contextual bandit learning (discussed in section 4.2), previous types of reductions are inadequate because they lack any way to quantify progress made by the reduction as examples are used in learning.\nSuppose we have access to an oracle which when given a dataset returns an minimum loss predictor from a class of predictors H with a limited capacity. The form of the learning problem solved by the oracle can be binary classification, cost-sensitive classification, or any other reasonable primitive. Since many supervised learning algorithms approximate such an oracle, these reductions are immediately implementable.\nSince the capacity of H is limited, tools from statistical learning theory can be used to argue about the regret of the predictor returned by the oracle. Cleverly using this oracle can provide solutions to learning problems which are exponentially more efficient than simpler more explicit algorithms for choosing which information to gether [1, 9]."}, {"heading": "3 Interfaces for learning reductions", "text": "A good interface for learning reductions should simultaneously be performant, generally useful, easy to program, and eliminate systemic bugs."}, {"heading": "3.1 The Wrong Way", "text": "The strawman one-against-all approach illustrates interfacing failures well. In particular, consider an implementation where a binary learning executable, treated as a black box, is orchestrated to do the one-against-all approach via shell scripting.\n1. Scripting implies a mixed-language solution, which is relatively difficult to maintain or understand.\n2. The approach may easily fail under recursion. For example, if another script invokes the one-against-all training script multiple times, it is easy to imagine a problem where the saved models of one invocation overwrites the saved models of another invocation. In a good programming approach, these sorts of errors should not be possible.\n3. The transformation of multiclass examples into binary examples is separated from the transformation of binary predictions into multiclass predictions. This substantially raises the possibility of implementation bugs compared to an approach which has encoder and decoder implemented either side-by-side or conformally.\n4. For more advanced adaptive reductions, it is common to require a prediction before defining the created examples. Having a prediction script operate separately creates a circularity (training must succeed for prediction to work, but prediction is needed for training to occur) which is extremely cumbersome to avoid in this fashion.\n5. The training approach is computationally expensive since the dataset is replicated k times. Particularly when datasets are large, this is highly undesirable.\n6. The testing process is structurally slow, particularly when there is only one test example to label. The computational time is \u2126(pk) where p is the number of parameters in a saved model and k is the number of classes simply due to the overhead of loading a model.\n7. Even if all models are loaded into memory, the process of querying each model is inherently unfriendly to a hardware cache."}, {"heading": "3.2 A Better Way", "text": "Our approach [40] eliminates all of the above interfacing bugs, resulting in a system which is general, performant, and easily programmed while eliminating bugs due to antimodular implementation.\nWe require a base learning algorithm which presents two online interfaces:\n1. Predict(example e, instance i) returns a prediction for base problem i and is guaranteed to not update the internal state.\n2. Learn(example e, instance i) returns the same result as Predict, but may update the internal state.\nNote that although we require an online learning algorithm interface, there is no constraint that online learning must occur\u2014the manner in which state is updated by Learn is up to the base learning algorithm. The interface certainly favors online base learning algorithms, but we have an implementation of LBFGS [43] that functions as an effective (if typically slow) base learning algorithm.\nSince reductions are composable, this interface is both a constraint on the base learning algorithm and a constraint on the learning reduction itself\u2014the learning reduction must define its own Predict}and Learn}interfaces.\nIt is common for reductions to have some state which is summarized in a reduction-specific datastructure. Every reduction requires a base learner which may either be another reduction or a learning algorithm. Reductions also typically have some reduction-specific state such as number of classes k for the one-against-all reduction. In a traditional object-oriented language, these arguments can be provided to the constructor of the reduction and encapsulated in the reduction object. In a purely functional language, the input arguments can be augmented with an additional state variable (and the return value of Learn augmented with an updated state variable).\nThe above interface addresses all the previously mentioned problems except for problem (7). Consider a dense linear model with sparse features. In this situation, the speed of testing is commonly limited by the coherency of memory access due to caching effects. To use coherent access, we stripe models over memory. In particular, for a linear layout with 4 models, the memory for model i is at address i, i+4, i+8,... This layout is nearly transparent to learning reductions\u2014it is achieved by multiplying feature ids by the total number of models at the top of the reduction stack, using the instance to define offsets to feature values as an example descends the stack, and then requiring base learning algorithms to access example features via a foreach feature() function that transparently imposes the appropriate offset for a model."}, {"heading": "4 Uniquely solved problems", "text": "Do reductions just provide a modular alternative that performs as well as other, direct methods? Or do they provide solutions to otherwise unsolved problems? Rephrased, are learning reductions\na good first tool for developing solutions to new problems? We provide evidence that the answer is \u2018yes\u2019 by surveying an array of learning problems which have been effectively addressed only via reduction techniques so far. A common theme throughout these problems is computational efficiency. Often there are known inefficient approaches for solving intractable problems. Using a reduction approach, we can isolate the inefficiency of optimization, and remove other inefficiencies, often resulting in exponential improvements in efficiency in practice."}, {"heading": "4.1 Efficient Contextual Bandit Learning", "text": "In contextual bandit learning, a learning algorithm needs to be applied to exploration data to learn a policy for acting in the world. A policy is functionally equivalent to a multiclass classifier that takes as input some feature vector x and produces an action a. The term \u201cpolicy\u201d is used here, because the action is executed\u2014perhaps a news story is displayed, or a medical treatment is administered. Exploration data consists of quads (x, a, r, p) where x is a feature vector, a is an action, r is a reward, and p is the probability of choosing action a on x.\nEfficient non-reduction techniques exist only for special cases of this problem [35]. All known techniques for the general setting [10,28,56] use reduction approaches."}, {"heading": "4.2 Efficient Exploration in Contextual Bandits", "text": "Effectively doing contextual bandit learning in the online setting requires efficiently creating a good probability distribution over actions. There are approaches to this problem based on exponential weights [5] with a running time linear in the size of the policy set. Can this be done in more efficiently?\nThe answer turns out to be \u201cyes\u201d [1]. In particular, it is possible to reduce the problem to O( \u221a T ) instances of cost-sensitive classification which are each trained to find good-but-different solutions. This is an exponential improvement in computational complexity over the previous approach."}, {"heading": "4.3 Efficient Agnostic Selective Sampling", "text": "A learning algorithm with the power to choose which examples to label can be much more efficient than a learning algorithm that passively accepts randomly labeled examples. However, most such approaches break down if strong assumptions about the nature of the problem are not met.\nThe canonical example is learning a threshold on the real line in the absence of any noise. A passive learning approach requires O(1/ ) samples to achieve error rate , while selective sampling requires only O ( ln 1 ) samples using binary search. This exponential improvement, however, is quite brittle\u2014a small amount of label noise can yield an arbitrarily bad predictor. Inefficient approaches for addressing this brittleness statistically have been known [6, 30]. Is it possible to benefit from selective sampling in the agnostic setting efficiently? Two algorithms have been created [9,31] which reduce active learning for binary classification to importance-weighted binary classification, creating practical algorithms. No other efficient general approaches to agnostic selective sampling are known."}, {"heading": "4.4 Logarithmic Time Classification", "text": "Most multiclass learning algorithms have time and space complexities linear in the number of classes when testing or training. Furthermore, many of these approaches tend to be inconsistent in the presence of noise\u2014they may predict the wrong label regardless of the amount of data available when there is label noise.\nIt is easy to note that logarithmic time classification may be possible since the output need only be O(log k) bits to uniquely identify a class. Can logarithmic time classification be done in a consistent and robust fashion?\nTwo reduction algorithms [12,16] provide a solution to this. The first shows that consistency and robustness can be achieved with a logarithmic time approach, while the second addresses learning of the structure directly."}, {"heading": "5 Learning to search for structured prediction", "text": "Structured prediction is the task of mapping an input to some output with complex internal structure. For example, mapping an English sentence to a sequence of part of speech tags (part of speech tagging), to a syntactic structure (parsing) or to a meaning-equivalent sentence in Chinese (translation). Learning to search is a family of approaches for solving structured prediction tasks and encapsulates a number of specific algorithms (e.g., [18,20,22,24,25,32,44,48,50,53,54]). Learning to search approaches (1) decompose the production of the structure output in terms of an explicit search space (states, actions, etc.); and (2) learn hypotheses that control a policy that takes actions in this search space.\nWe implemented a learning to search algorithm (based on [20, 48]) that operates via reduction to cost sensitive classification which is then further reduced to regression. This algorithm was then extensively tested against a suite of many structured learning algorithms which we report here (see [21] for full details). The first task we considered was sequence labeling problem: Part of Speech tagging based on data form the Wall Street Journal portion of the Penn Treebank (45 labels, evaluated by Hamming loss, 912k words of training data). The second is a sequence chunking problem: named entity recognition using the CoNLL 2003 dataset (9 labels, macro-averaged Fmeasure, 205k words of training data).\nWe use the following freely available systems/algorithms as points of comparison:\n1. CRF++ The popular CRF++ toolkit [37] for conditional random fields [38], which implements both L-BFGS optimization for CRFs [45] as well as \u201cstructured MIRA\u201d [19,46].\n2. CRF SGD A stochastic gradient descent conditional random field package [14].\n3. Structured Perceptron An implementation of the structured perceptron [17] due to [15].\n4. Structured SVM The cutting-plane implementation [34] of the structured SVMs [52] for \u201cHMM\u201d problems.\n5. Structured SVM (DEMI-DCD) A multicore algorithm for optimizing structured SVMs called DEcoupled Model-update and Inference with Dual Coordinate Descent.\n6. VW Search Our approach is implemented in the Vowpal Wabbit toolkit on top of a cost-sensitive classifier [8] that reduces to regression trained with an online rule incorporating AdaGrad [26],\nper-feature normalized updates, and importance invariant updates. The variant VW Search (own fts) uses computationally inexpensive feature construction facilities available in Vowpal Wabbit (e.g., token prefixes and suffixes), whereas for comparison purposes VW Search uses the same features as the other systems.\n7. VW Classification An unstructured baseline that predicts each label independently, using oneagainst-all multiclass classification [8].\nThese approaches vary both objective function (CRF, MIRA, structured SVM, learning to search) and optimization approach (L-BFGS, cutting plane, stochastic gradient descent, AdaGrad). All implementations are in C/C++, except for the structured perceptron and DEMI-DCD (Java).\nIn Figure 3, we show trade-offs between training time (x-axis, log scaled) and prediction accuracy (y-axis) for the six systems described previously. The left figure is for part of speech tagging and the right figure is for named entity recognition. For POS tagging, the independent classifier is by far the fastest (trains in less than one minute) but its performance peaks at 95% accuracy. Three other approaches are in roughly the same time/accuracy tradeoff: VW Search, VW Search (own fts) and Structured Perceptron. All three can achieve very good prediction accuracies in just a few minutes of training. CRF SGD takes about twice as long. DEMI-DCD eventually achieves the same accuracy, but it takes a half hour. CRF++ is not competitive (taking over five hours to even do as well as VW Classification). Structured SVM (cutting plane implementation) runs out of memory before achieving competitive performance, likely due to too many constraints.\nFor NER the story is a bit different. The independent classifiers are far from competitive. Here, the two variants of VW Search totally dominate. In this case, Structured Perceptron, which did quite well on POS tagging, is no longer competitive and is essentially dominated by CRF SGD. The only system coming close to VW Search\u2019s performance is DEMI-DCD, although its performance flattens out after a few minutes.1\nIn addition to training time, test time behavior can be of high importance in natural applications. On NER, prediction times varied from 5.3k tokens/second (DEMI-DCD and Structured Perceptron to around 20k (CRF SGD and Structured SVM) to 100k (CRF++) to 220k (VW (own fts)) and 285k (VW). Although CRF SGD and Structured Perceptron fared well in terms of training time, their test-time behavior is suboptimal.\nWhen looking at POS tagging, the effect of the O(k) dependence on the size of the label set further increased the (relative) advantage of VW Search over alternatives."}, {"heading": "6 Summary and future directions", "text": "In working with learning reductions for several years, the greatest benefits seem to be incurred with modularity, deeper reductions, and computational efficiency.\nModularity means that the extra code required for multiclass classification (for example) is minor compared to the code required for binary classification. It also simplifies the use of a learning system, because (for example) learning rate flags apply to all learning algorithms. Modularity is\n1We also tried giving CRF SGD the features computed by VW Search (own fts) on both POS and NER. On POS, its accuracy improved to 96.5\u2014on par with VW Search (own fts)\u2014with essentially the same speed. On NER its performance decreased. For both tasks, clearly features matter. But which features matter is a function of the approach being taken.\nalso an easy experimentation and optimization tool, as one can plug in different black boxes for different modules.\nWhile there are many experiments showing near-parity prediction performance for simple reductions, it appears that for deeper reductions the advantage may become more pronounced. This is well illustrated for the learning to search results discussed in section 5, but has been observed with contextual bandit learning as well [1]. The precise reason for this is unclear, as it is very difficult to isolate the most important difference between very different approaches to solving the problem.\nNot all machine learning reductions provide computational benefits, but those that do may provide enormous benefits. These are mostly detailed in section 4, with benefits often including an exponential reduction in computational complexity.\nIn terms of the theory itself, we have often found that qualitative transitions from an error reduction to a regret reduction are beneficial. We have also found the isolation of concerns via encapsulation of the optimization problem to be quite helpful in developing solutions.\nWe have not found that precise coefficients are predictive of relative performance amongst two reductions accomplishing the same task with the same base learning algorithm but different representations. As an example, the theory for error correcting tournaments [12] is substantially stronger than for one-against-all, yet often one-against-all performs better empirically. The theory is of course not wrong, but since the theory is relativized by the performance of the base predictor, the representational compatibility issue can and does play a stronger role in predicting performance.\nThere are many questions we still have about learning reductions.\n1. Can the interface we have support effective use of SIMD/BLAS/GPU approaches to optimization? Marrying the computational benefits of learning reductions to the computational benefits of these approaches could be compelling.\n2. Is the learning reduction approach effective when the base learner is a multitask (possibly \u201cdeep\u201d) learning system? Often the different subproblems created by the reduction share enough structure that a multitask approach appears plausibly effective.\n3. Can the learning reduction approach be usefully applied at the representational level? Is there a theory of representational reductions?"}], "references": [{"title": "Taming the monster: A fast and simple algorithm for contextual bandits", "author": ["Alekh Agarwal", "Daniel Hsu", "Satyen Kale", "John Langford", "Lihong Li", "Robert E. Schapire"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Surrogate regret bounds for bipartite ranking via strongly proper losses", "author": ["Shivani Agarwal"], "venue": "Journal of Machine Learning Research", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Mohri,Preference-based learning to rank", "author": ["Nir Ailon", "Mehryar"], "venue": "Machine Learning Journal,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "Reducing multiclass to binary: A unifying approach for margin classifiers", "author": ["Erin Allwein", "Robert Schapire", "Yoram Singer"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2000}, {"title": "The non-stochastic multi-armed bandit problem", "author": ["Peter Auer", "Nicol\u00f2 Cesa-Bianchi", "Yoav Freund", "Robert E. Schapire"], "venue": "SIAM Journal on Computing,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2002}, {"title": "Convexity, classification and risk bounds", "author": ["Peter Bartlett", "Michael Jordan", "Jon McAuliffe"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Error limiting reductions between classification tasks", "author": ["Alina Beygelzimer", "Varsha Dani", "Tom Hayes", "John Langford", "Bianca Zadrozny"], "venue": "In Proceedings of the International Conference on Machine Learning (ICML),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2005}, {"title": "The Offset Tree for Learning with Partial Labels", "author": ["Alina Beygelzimer", "John Langford"], "venue": "KDD", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "Multi-core structural SVM training", "author": ["Kai-Wei Chang", "Vivek Srikumar", "Dan Roth"], "venue": "In Proceedings of the European Conference on Machine Learning (ECML),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms", "author": ["Michael Collins"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2002}, {"title": "Incremental parsing with the perceptron algorithm", "author": ["Michael Collins", "Brian Roark"], "venue": "In Proceedings of the Conference of the Association for Computational Linguistics (ACL),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2004}, {"title": "Ultraconservative online algorithms for multiclass problems", "author": ["Koby Crammer", "Yoram Singer"], "venue": "Journal of Machine Learning Research (JMLR),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2003}, {"title": "Search-based structured prediction", "author": ["Hal Daum\u00e9 III", "John Langford", "Daniel Marcu"], "venue": "Machine Learning Journal,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "Efficient programmable learning to search", "author": ["Hal Daum\u00e9 III", "John Langford", "St\u00e9phane Ross"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "Learning as search optimization: Approximate large margin methods for structured prediction", "author": ["Hal Daum\u00e9 III", "Daniel Marcu"], "venue": "In Proceedings of the International Conference on Machine Learning (ICML),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2005}, {"title": "Solving multiclass learning problems via error-correcting output codes", "author": ["Tom Dietterich", "G. Bakiri"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1995}, {"title": "Output space search for structured prediction", "author": ["Janardhan Rao Doppa", "Alan Fern", "Prasad Tadepalli"], "venue": "In Proceedings of the International Conference on Machine Learning (ICML),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "HC-Search: A learning framework for search-based structured prediction", "author": ["Janardhan Rao Doppa", "Alan Fern", "Prasad Tadepalli"], "venue": "Journal of Artificial Intelligence Research (JAIR),", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2014}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["John Duchi", "Elad Hazan", "Yoram Singer"], "venue": "Journal of Machine Learning Research (JMLR),", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2011}, {"title": "On the Consistency of Ranking Algorithms", "author": ["John Duchi", "Lester Mackey", "Michael I. Jordan"], "venue": "International Conference on Machine Learning (ICML)", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2010}, {"title": "Multiclass learning, boosting, and error-correcting codes", "author": ["Venkat Guruswami", "Amit Sahai"], "venue": "In Proceedings of the 12th Annual Conference on Computational Learning Theory (COLT),", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1999}, {"title": "Algorithms for Active Learning, Ph.D", "author": ["Daniel Hsu"], "venue": "Thesis, University of California, San Diego,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2010}, {"title": "Structured perceptron with inexact search", "author": ["Liang Huang", "Suphan Fayong", "Yang Guo"], "venue": "In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL),", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2012}, {"title": "The Error Coding Method and PICTs", "author": ["Gareth James", "Trevor Hastie"], "venue": "Journal of Computational and Graphical Statistics", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1998}, {"title": "Cutting-plane training of structural SVMs", "author": ["Thorsten Joachims", "Thomas Finley", "Chun-Nam Yu"], "venue": "Machine Learning Journal,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2009}, {"title": "Efficient bandit algorithms for online multiclass prediction", "author": ["Sham M Kakade", "Shai Shalev-Shwartz", "Ambuj Tewari"], "venue": null, "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2008}, {"title": "Online importance weight aware updates", "author": ["Nikos Karampatziakis", "John Langford"], "venue": "In UAI, pages 392\u2013399,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2011}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["John Lafferty", "Andrew McCallum", "Fernando Pereira"], "venue": "In Proceedings of the International Conference on Machine Learning (ICML),", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2001}, {"title": "Sensitive error correcting output codes", "author": ["John Langford", "Alina Beygelzimer"], "venue": "In Conference on Learning Theory (COLT),", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2005}, {"title": "Vowpal wabbit online learning project", "author": ["John Langford", "Lihong Li", "Alex Strehl"], "venue": "Technical report,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2007}, {"title": "Gradient-based learning applied to document recognition", "author": ["Yann Lecun", "L\u00e9on Bottou", "Yoshua Bengio", "Patrick Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 1998}, {"title": "On the Statistical Consistency of Plug-in Classifiers for Non-decomposable Performance Measures", "author": ["Harikrishna Narasimhany", "Rohit Vaishy", "Shivani Agarwal"], "venue": null, "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2014}, {"title": "Updating Quasi-Newton Matrices with Limited Storage", "author": ["Jorge Nocedal"], "venue": "Mathematics of Computation", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 1980}, {"title": "Boosting structured prediction for imitation learning", "author": ["Nathan Ratliff", "David Bradley", "J. Andrew Bagnell", "Joel Chestnutt"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2007}, {"title": "A comparison of algorithms for maximum entropy parameter estimation", "author": ["Robert Malouf"], "venue": "In Proceedings of CoNLL,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2002}, {"title": "Large margin online learning algorithms for scalable structured classification", "author": ["Ryan McDonald", "Koby Crammer", "Fernando Pereira"], "venue": "In NIPS Workshop on Learning with Structured Outputs,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2004}, {"title": "On the consistency of output code based learning algorithms for multiclass learning problems", "author": ["Harish Ramaswamy", "Balaji S.B", "Shivani Agarwal", "Robert Williamson"], "venue": "In Proceedings of the 27th Annual Conference on Learning Theory (COLT),", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2014}, {"title": "A reduction of imitation learning and structured prediction to no-regret online learning", "author": ["Stephane Ross", "Geoff J. Gordon", "J. Andrew Bagnell"], "venue": "In Proceedings of the Workshop on Artificial Intelligence and Statistics (AI-Stats),", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2011}, {"title": "Boosting: Foundations and Algorithms", "author": ["Robert E. Schapire", "Yoav Freund"], "venue": null, "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2012}, {"title": "A reduction from apprenticeship learning to classification", "author": ["Umar Syed", "Robert E. Schapire"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2011}, {"title": "Max-margin Markov networks", "author": ["Ben Taskar", "Carlos Guestrin", "Daphne Koller"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2003}, {"title": "Support vector machine learning for interdependent and structured output spaces", "author": ["Ioannis Tsochantaridis", "Thomas Hofmann", "Thorsten Joachims", "Yasmine Altun"], "venue": "In Proceedings of the International Conference on Machine Learning (ICML),", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2004}, {"title": "On learning linear ranking functions for beam search", "author": ["Yuehua Xu", "Alan Fern"], "venue": "In ICML,", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2007}, {"title": "Discriminative learning of beam-search heuristics for planning", "author": ["Yuehua Xu", "Alan Fern", "Sung Wook Yoon"], "venue": "In IJCAI,", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2007}, {"title": "Surrogate regret bounds for proper losses", "author": ["Mark Reid", "Robert Williamson"], "venue": "In ICML,", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2009}, {"title": "Policy mining: Learning decision policies from fixed sets of data, Ph.D", "author": ["Bianca Zadrozny"], "venue": "Thesis, University of California, San Diego,", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2003}], "referenceMentions": [{"referenceID": 3, "context": "For example, in the strawman one-against-all reduction, an average binary classification error rate of implies a multiclass error rate of at most (k \u2212 1) (see [4, 29]).", "startOffset": 159, "endOffset": 166}, {"referenceID": 20, "context": "For example, in the strawman one-against-all reduction, an average binary classification error rate of implies a multiclass error rate of at most (k \u2212 1) (see [4, 29]).", "startOffset": 159, "endOffset": 166}, {"referenceID": 15, "context": "Another example of an error reduction for multiclass classification is based on error-correcting output codes [23,29].", "startOffset": 110, "endOffset": 117}, {"referenceID": 20, "context": "Another example of an error reduction for multiclass classification is based on error-correcting output codes [23,29].", "startOffset": 110, "endOffset": 117}, {"referenceID": 30, "context": "Figure 2 illustrates the empirical superiority of reducing to regression rather than binary classification for the Mnist [41] data set.", "startOffset": 121, "endOffset": 125}, {"referenceID": 23, "context": "There are many known regret reductions for such problems as multiclass classification [33,47], costsensitive classification [12, 39], and ranking [2, 3].", "startOffset": 86, "endOffset": 93}, {"referenceID": 36, "context": "There are many known regret reductions for such problems as multiclass classification [33,47], costsensitive classification [12, 39], and ranking [2, 3].", "startOffset": 86, "endOffset": 93}, {"referenceID": 28, "context": "There are many known regret reductions for such problems as multiclass classification [33,47], costsensitive classification [12, 39], and ranking [2, 3].", "startOffset": 124, "endOffset": 132}, {"referenceID": 1, "context": "There are many known regret reductions for such problems as multiclass classification [33,47], costsensitive classification [12, 39], and ranking [2, 3].", "startOffset": 146, "endOffset": 152}, {"referenceID": 2, "context": "There are many known regret reductions for such problems as multiclass classification [33,47], costsensitive classification [12, 39], and ranking [2, 3].", "startOffset": 146, "endOffset": 152}, {"referenceID": 1, "context": "A surrogate regret bound quantifies the resulting regret in terms of the surrogate regret [2, 7, 55].", "startOffset": 90, "endOffset": 100}, {"referenceID": 5, "context": "A surrogate regret bound quantifies the resulting regret in terms of the surrogate regret [2, 7, 55].", "startOffset": 90, "endOffset": 100}, {"referenceID": 44, "context": "A surrogate regret bound quantifies the resulting regret in terms of the surrogate regret [2, 7, 55].", "startOffset": 90, "endOffset": 100}, {"referenceID": 19, "context": "In some cases, commonly used surrogate losses actually turn out to be inconsistent [27].", "startOffset": 83, "endOffset": 87}, {"referenceID": 38, "context": "Boosting [49] can be thought of as an adaptive reduction for converting any weak learner into a strong learner.", "startOffset": 9, "endOffset": 13}, {"referenceID": 38, "context": "Although linear separability with a positive margin implies weak learnability [49], linear separability is still a strong assumption.", "startOffset": 78, "endOffset": 82}, {"referenceID": 0, "context": "Cleverly using this oracle can provide solutions to learning problems which are exponentially more efficient than simpler more explicit algorithms for choosing which information to gether [1, 9].", "startOffset": 188, "endOffset": 194}, {"referenceID": 29, "context": "2 A Better Way Our approach [40] eliminates all of the above interfacing bugs, resulting in a system which is general, performant, and easily programmed while eliminating bugs due to antimodular implementation.", "startOffset": 28, "endOffset": 32}, {"referenceID": 32, "context": "The interface certainly favors online base learning algorithms, but we have an implementation of LBFGS [43] that functions as an effective (if typically slow) base learning algorithm.", "startOffset": 103, "endOffset": 107}, {"referenceID": 25, "context": "Efficient non-reduction techniques exist only for special cases of this problem [35].", "startOffset": 80, "endOffset": 84}, {"referenceID": 7, "context": "All known techniques for the general setting [10,28,56] use reduction approaches.", "startOffset": 45, "endOffset": 55}, {"referenceID": 45, "context": "All known techniques for the general setting [10,28,56] use reduction approaches.", "startOffset": 45, "endOffset": 55}, {"referenceID": 4, "context": "There are approaches to this problem based on exponential weights [5] with a running time linear in the size of the policy set.", "startOffset": 66, "endOffset": 69}, {"referenceID": 0, "context": "Can this be done in more efficiently? The answer turns out to be \u201cyes\u201d [1].", "startOffset": 71, "endOffset": 74}, {"referenceID": 21, "context": "Is it possible to benefit from selective sampling in the agnostic setting efficiently? Two algorithms have been created [9,31] which reduce active learning for binary classification to importance-weighted binary classification, creating practical algorithms.", "startOffset": 120, "endOffset": 126}, {"referenceID": 10, "context": ", [18,20,22,24,25,32,44,48,50,53,54]).", "startOffset": 2, "endOffset": 36}, {"referenceID": 12, "context": ", [18,20,22,24,25,32,44,48,50,53,54]).", "startOffset": 2, "endOffset": 36}, {"referenceID": 14, "context": ", [18,20,22,24,25,32,44,48,50,53,54]).", "startOffset": 2, "endOffset": 36}, {"referenceID": 16, "context": ", [18,20,22,24,25,32,44,48,50,53,54]).", "startOffset": 2, "endOffset": 36}, {"referenceID": 17, "context": ", [18,20,22,24,25,32,44,48,50,53,54]).", "startOffset": 2, "endOffset": 36}, {"referenceID": 22, "context": ", [18,20,22,24,25,32,44,48,50,53,54]).", "startOffset": 2, "endOffset": 36}, {"referenceID": 33, "context": ", [18,20,22,24,25,32,44,48,50,53,54]).", "startOffset": 2, "endOffset": 36}, {"referenceID": 37, "context": ", [18,20,22,24,25,32,44,48,50,53,54]).", "startOffset": 2, "endOffset": 36}, {"referenceID": 39, "context": ", [18,20,22,24,25,32,44,48,50,53,54]).", "startOffset": 2, "endOffset": 36}, {"referenceID": 42, "context": ", [18,20,22,24,25,32,44,48,50,53,54]).", "startOffset": 2, "endOffset": 36}, {"referenceID": 43, "context": ", [18,20,22,24,25,32,44,48,50,53,54]).", "startOffset": 2, "endOffset": 36}, {"referenceID": 12, "context": "We implemented a learning to search algorithm (based on [20, 48]) that operates via reduction to cost sensitive classification which is then further reduced to regression.", "startOffset": 56, "endOffset": 64}, {"referenceID": 37, "context": "We implemented a learning to search algorithm (based on [20, 48]) that operates via reduction to cost sensitive classification which is then further reduced to regression.", "startOffset": 56, "endOffset": 64}, {"referenceID": 13, "context": "This algorithm was then extensively tested against a suite of many structured learning algorithms which we report here (see [21] for full details).", "startOffset": 124, "endOffset": 128}, {"referenceID": 27, "context": "CRF++ The popular CRF++ toolkit [37] for conditional random fields [38], which implements both L-BFGS optimization for CRFs [45] as well as \u201cstructured MIRA\u201d [19,46].", "startOffset": 67, "endOffset": 71}, {"referenceID": 34, "context": "CRF++ The popular CRF++ toolkit [37] for conditional random fields [38], which implements both L-BFGS optimization for CRFs [45] as well as \u201cstructured MIRA\u201d [19,46].", "startOffset": 124, "endOffset": 128}, {"referenceID": 11, "context": "CRF++ The popular CRF++ toolkit [37] for conditional random fields [38], which implements both L-BFGS optimization for CRFs [45] as well as \u201cstructured MIRA\u201d [19,46].", "startOffset": 158, "endOffset": 165}, {"referenceID": 35, "context": "CRF++ The popular CRF++ toolkit [37] for conditional random fields [38], which implements both L-BFGS optimization for CRFs [45] as well as \u201cstructured MIRA\u201d [19,46].", "startOffset": 158, "endOffset": 165}, {"referenceID": 9, "context": "Structured Perceptron An implementation of the structured perceptron [17] due to [15].", "startOffset": 69, "endOffset": 73}, {"referenceID": 8, "context": "Structured Perceptron An implementation of the structured perceptron [17] due to [15].", "startOffset": 81, "endOffset": 85}, {"referenceID": 24, "context": "Structured SVM The cutting-plane implementation [34] of the structured SVMs [52] for \u201cHMM\u201d problems.", "startOffset": 48, "endOffset": 52}, {"referenceID": 41, "context": "Structured SVM The cutting-plane implementation [34] of the structured SVMs [52] for \u201cHMM\u201d problems.", "startOffset": 76, "endOffset": 80}, {"referenceID": 6, "context": "VW Search Our approach is implemented in the Vowpal Wabbit toolkit on top of a cost-sensitive classifier [8] that reduces to regression trained with an online rule incorporating AdaGrad [26],", "startOffset": 105, "endOffset": 108}, {"referenceID": 18, "context": "VW Search Our approach is implemented in the Vowpal Wabbit toolkit on top of a cost-sensitive classifier [8] that reduces to regression trained with an online rule incorporating AdaGrad [26],", "startOffset": 186, "endOffset": 190}, {"referenceID": 6, "context": "VW Classification An unstructured baseline that predicts each label independently, using oneagainst-all multiclass classification [8].", "startOffset": 130, "endOffset": 133}, {"referenceID": 0, "context": "This is well illustrated for the learning to search results discussed in section 5, but has been observed with contextual bandit learning as well [1].", "startOffset": 146, "endOffset": 149}], "year": 2015, "abstractText": "We provide a summary of the mathematical and computational techniques that have enabled learning reductions to effectively address a wide class of problems, and show that this approach to solving machine learning problems can be broadly useful.", "creator": "LaTeX with hyperref package"}}}