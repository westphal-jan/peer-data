{"id": "1502.05213", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Feb-2015", "title": "F0 Modeling In Hmm-Based Speech Synthesis System Using Deep Belief Network", "abstract": "in recent years multilayer perceptrons ( mlps ) with many unmarked - den layers selective neural network ( dnn ) has performed sur - prisingly well in many specialized schemes, i. e. speech recognition, speaker verification, speech synthesis etc. although in the context and f0 modeling these techniques has not been ex - ploited properly. in research paper, deep belief network ( dbn ), a class of dnn family'been derived and applied one model the f0 contour of input speech which was generated by hmm - based speech realization system. the experiment was done on random language. several dbn - dnn architectures targeted using four to seven hidden layers and 6 to 160 hid - den units per input layer was derived and evaluated. the results were compared against clustering tree techniques r - ularly found in statistical parametric speech synthesis. we show that from sequencing inputs dbn - dnn learns a high level structure which in turn improves f0 contour in areas of ob - jective and subjective tests.", "histories": [["v1", "Wed, 18 Feb 2015 13:15:13 GMT  (219kb)", "http://arxiv.org/abs/1502.05213v1", "OCOCOSDA 2014"]], "COMMENTS": "OCOCOSDA 2014", "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["sankar mukherjee", "shyamal kumar das mandal"], "accepted": false, "id": "1502.05213"}, "pdf": {"name": "1502.05213.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["sankar1535@gmail.com", "sdasmandal@cet.iitkgp.ernet.in"], "sections": [{"heading": null, "text": "ar X\niv :1\n50 2.\n05 21\n3v 1\n[ cs\n.L G\n] 1\n8 Fe\nIndex Terms\u2014 F0 Modeling, DBN, Speech Synthesis, Bengali."}, {"heading": "1. INTRODUCTION", "text": "Prosody plays the most important role in generating natural and intelligent speech. Prosody is a collection of suprasegmental features (duration, intonation, co-articulation pattern) which contributes additional information to speech that do not found in text. In prosody, F0 contour has a significant contribution that is crucial to human speech perception. Knowledge of these parameters are implicit in speech signal i.e. it\u2019s hard to capture the rules governing these knowledge. Traditional shallow architectures (i.e. statistical model with few levels of computation units) are fine in limited domain but they are not capable of handling these parameters when there are lots of variations in the test set. In this context, DNN is famous for its ability to capture internal representations that become increasingly complex.\nIn recent years there has been a lot of interest in applying DNN in different speech processing tasks. Main advantage of\nthese deep learning techniques that they can learn from unlabeled data and only a limited number of labeled example are needed to fine-tune the model according to the specific tasks at hand. DNNs are basically a multilayer perceptron with many hidden layers. DBN is a class of DNN family. It is a probabilistic generative model with multiple layers of stochastic, hidden variables. Each pair of layers is treated as a Restricted Boltzmann Machine (RBM) which is a bipartite undirected graphical model with two-layer architecture. The training of DBN as described in [1] is to first initialize the weights of each layer greedily in a purely unsupervised way and then fine-tune all the weights jointly to further improve the likelihood. The resulting DBN is considered as a hierarchy of non-linear feature detectors that can learn complex statistical patterns. Rather than initialize random weights in a DNN, the weights learned by DBN can be used as the weights of a DNN. This is commonly called pre-training of DNN. The whole DNN can be further fine-tune by a small number of labeled training data. DBN-DNN (DNN pre-trained by DBN and fine-tune by labeled data) is successfully applied in speech, audio, image and text data [2] [3]. This advances triggered interest in applying deep learning techniques in speech synthesis tasks. In recent years, DBNs have been successfully applied to modeling speech signals, such as spectrogram coding [4], speech recognition [5], and acousticarticulatory inversion mapping [6], where they mainly act as the pre-training methods for a deep autoencoder or a deep neural network (DNN). In statistical parametric speech synthesis domain DBNs have also been studied very recently [7] [8] [9].\nUse of DBN to model F0 contour [8] [10] was not new. But in [10] DBN was used as feature extractor for Gaussian Process Regression which is a non-parametric model. Our work was different in the sense that our prediction model was based on DNN with weight initialized by DBN. This makes the proposed model completely parametric which has many advantages like smaller foot print in contrast to nonparametric model. By doing that the proposed method could be used in hand held devices as a stand alone application. An-\nother aspect was rather than discontinues F0 contour [8] we train the DNN with continues F0 contour which adds simplicity to the model.\nThis paper organized as follows. In Section 2, we will briefly review the basic techniques of RBMs and DBNs. In Section 3, we will describe the details of our proposed method. Section 4 reports our experimental results. Section 5 gives the conclusion and the discussion on our future work."}, {"heading": "2. ARCHITECTURE OF DEEP BELIEF NETWORK", "text": ""}, {"heading": "2.1. Restricted Boltzmann Machines", "text": "RBM is a special type of Markov random field that has one layer of (Bernoulli) stochastic hidden units and one layer of (Bernoulli or Gaussian) stochastic visible or observable units. There are no visible-visible or hidden-hidden connections but all the visible units are connected to all the hidden units.The weights between the connections of the visible units v and hidden units h define a probability distribution over the visible units v via an energy function [11]. Depending on the visible unit (i.e. Bernoulli or Gaussian) there are two types of energy function (i.e. Bernoulli (visible)-Bernoulli (hidden) and Gaussian (visible)-Bernoulli (hidden)) of the joint configuration (v,h). Gaussian-Bernoulli RBMs is used to convert real-valued stochastic variables into to binary stochastic variables, which then further processed using the BernoulliBernoulli RBMs. In this work Bernoulli-Bernoulli is used and its energy function is defined as\nE(v, h; \u03b8) = \u2212 V\u2211\ni=1\nH\u2211\nj=1\nwijvihj \u2212\nV\u2211\ni=1\nbivi \u2212\nH\u2211\nj=1\najhj (1)\nWhere \u03b8 = (w, b, a) and wij represents the symmetric interaction term between visible unit vi and hidden unit hj , bi and aj the bias terms, and V and H are the numbers of visible and hidden units. The joint distribution p(v,h;\u03b8) over the visible units v and hidden units h, given the model parameters \u03b8, in terms of an energy function E(v,h;\u03b8) is defined as\np(v, h; \u03b8) = exp(\u2212E(v, h; \u03b8))\nZ (2)\nwhere Z = \u03a3v\u03a3hexp(\u2212E(v, h; \u03b8)) is a normalization factor. The marginal probability that the model assigns to a visible vector v is\np(v; \u03b8) = \u03a3hexp(\u2212E(v, h; \u03b8))\nZ (3)\nAs there are no hidden-hidden or visible-visible connections, the conditional distributions are factorial and are given by\np(hj = 1|v; \u03b8) = \u03c3( V\u2211\ni=1\nwijvi + aj) (4)\np(vj = 1|h; \u03b8) = \u03c3( H\u2211\ni=1\nwijhi + bi) (5)\nwhere\u03c3(x) is the activation function. Here \u03c3(x) = 1(1+exp(x)) was considered. Taking the stochastic gradient descent of the negative log likelihood l the update rule for the RBM weights as\n\u2206wij(t+ 1) = m\u2206wij(t)\u2212 \u03b1 \u2202l\n\u2202wij (6)\nwhere \u03b1 is the learning rate and m is the momentum factor used to smooth out the weight updates. General form of the derivative of the log likelihood of the data can be written as\n\u2212 \u2202l(\u03b8)\n\u2202wij = Edata(vi, hj)\u2212 Emodel(vi, hj) (7)\nwhere Edata(vi, hj) is the expectation observed in the training set and Emodel(vi, hj) is that same expectation under the distribution defined by the model. But, Emodel(vi, hj) is computationally very expensive to compute so the contrastive divergence (CD) algorithm [12] to the gradient is used where Edata(vi, hj) is replaced by running the Gibbs sampler initialized at the data for one full step."}, {"heading": "2.2. Deep Belief Network", "text": "A DBN is formed by Stacking a number of the RBMs learned layer by layer from bottom up. In this model, each layer captures the correlations among the activities of hidden features in the layer below. The top two layers of the DBN form an undirected bipartite graph. The lower layers form a directed graph with a top-down direction to generate the visible units. Given the training samples of the visible units, it is difficult to estimate the model parameters of a DBN directly under the maximum likelihood criterion due to the complex model structure with multiple hidden layers. Therefore, a greedy learning algorithm has been proposed and popularly applied to train the DBN in a layer-by-layer manner [1]. After learning Bernoulli-Bernoulli RBM the activation probabilities of its hidden units was treated as the data for training the Bernoulli-Bernoulli RBM one layer up. The activation probabilities of the 2nd-layer Bernoulli-Bernoulli RBM are then used as the visible data input for the 3rd-layer BernoulliBernoulli RBM, and so on. This greedy procedure above achieves approximate maximum likelihood learning. It has been proved that this greedy learning algorithm can improve the lower bound on the log-likelihood of the training samples by adding each new hidden layer [1] [13]. AIS-based partition function estimation with approximate inference [13] used to estimate the lower bound on the log-probability."}, {"heading": "3. PROPOSED F0 MODELING APPROACH", "text": "As shown in Figure 1, a database of speech and corresponding text sentences was used as the training corpus. CRBLP\nspeech corpus [14] is employed here for the whole experiment and it consists of one male voice of age 27. STRAIGHT [15], a high-quality analysis and synthesis algorithm, was adopted to estimate the spectrum and F0 contours with 10-ms frame rate. Continues F0 contour was formed using step described in [16] which resulted an approximation of original F0 contour consisting of third order polynomial segments. For the input of the neural network a set of textual features were extracted from the raw text. Table 1 illustrates the features considered for this work. The phoneme consists of 30 consonants and 16 vowels. Max syllable length 6 and max 10 syllable words was considered and which was sufficient for Bengali language. These features were re-encoded using Oneof-N codes which resulted 220 binary features. All though the phoneme and syllable properties may differ for language to language. To mitigate this language dependency problem we only need to adapt language specific text analysis module. Apart from the text analysis module the whole system is completely independent of Language."}, {"heading": "3.1. DBN Training", "text": "Input to the DBN was binary i.e. we used Bernoulli-Bernoulli RBM. From the corpus 7000 sentences are chosen to train the DBN. Each DBN layer was pre-trained for 50 epochs as a RBM with mini-batch of size 10. Average gradients were computed on the mini-batches and parameters were updated with a learning rate of 0.002 and a momentum of 0.95. Different architecture of DBN illustrated in Figure 3 were trained with these configuration."}, {"heading": "3.2. DNN Training", "text": "DNN is pre-trained by the DBN which means weights of the DNN is initialized from the trained DBN. In order to finetune the DNN 1000 sentences (excluding the previous 7000)\nare taken from the CRBLP corpus and they are phonetically aligned by HTK toolkit (5-state HMM). Finally the phonetic boundaries are manually corrected. From the 1000 sentences 500 are chosen to train, 200 to cross validation, 300 to test the DNN. Output of the DNN are log F0 values corresponds to each phoneme state. This is because sentences are segmented using 5-state HMMs which results 5 states for each phoneme or each observation corresponds to roughly 1/5 of the phonemes. F0 values corresponding to each state were calculated from the continues F0 contour with the duration information generated by HTK. These F0 values act as the output of DNN. We used mean squared error as the objective function with sparsity target of 0.05 and 0.002 weight decay. With mini-batches of 100 states backpropagation training was evaluated using a cross validation set. Loss is measured for the 10 epochs and if loss increased then learning rate was decreased by a factor of two.\nThe experiment was carried out on DELL precision T3600 workstation which is a 6 core computer with a CPU clock speed of 3.2 GHz, 12MB of L3 cache and 64GB DDR3 RAM. The training also used an NVIDIA Quadro 4000 general purpose graphical processing unit (GPGPU) for matrix multiplication."}, {"heading": "3.3. Synthesis Stage", "text": "Figure 2 shows the synthesis procedure of the proposed system. It has two main parts - generation of the cepstrum and duration, and prediction of the F0 values. At the synthesis time the same features were extracted corresponding to each phoneme and they were fed to the DNN. With the previously trained weights DNN then predict the F0 values. From the HTS phoneme state-duration model the duration of each states were extracted. Cubic spline interpolation were performed on the state F0 values with the duration information so that the resulted F0 has the same length. As a result, a\ncontinuous pitch contour was generated. Using MLSA filter synthesized speech was generated."}, {"heading": "4. RESULTS AND EVALUATION", "text": "Objective evaluation are conducted to evaluate the performance of the different DBN-DNN model. The best model is chosen to further be evaluated using subjective tests. In order to compare the proposed model against the clustering tree with multi-space probability distribution (MSD-HMM) F0 model included in the HTS synthesis engine toolkit [17], a Bengali-HTS [18] system is constructed. It is built with HTS 2.2 with 34th order MGC coefficient, 10ms Blackman window, 5ms shift and 0.53 frequency wrapping factor."}, {"heading": "4.1. Objective Evaluation and Model Selection", "text": "For the objective evaluation two types of metrics i.e. crosscorrelation (XCORR) and root mean square error (RMSE) have been calculated. Several architecture of DNN has been constructed and their performance is evaluated using these two metrics. Figure 3 illustrates the different RMSE and XCORR values of the predicted F0 values on the test set (300 sentences). From the Figure 3 it is clear that XCORR is improving on the test set with increasing hidden layer size but the performance of RMSE is decreasing. So we choose DBN-DNN (120U-7L) which yields the best performance according to the two metrics (RMSE 17 and XCORR 0.64). Table 2 presents the objective test results performed on the test set between MSD-HMM and DBN-DNN. DBN-DNN (120U-7L) is selected for subjective evaluation."}, {"heading": "4.2. Subjective Evaluation", "text": "For subjective measurement, ABX is performed with 5 subjects (3 male, 2 female). All subjects are not speech experts and native speakers of Bengali. In this experiment, the 50 test sentences are synthesized using DBN-DNN (120U-7L) and MSD-HMM. Participants are asked to choose their preferred one. It can be seen from Figure 4 that 82% of the time subjects has a preference towards one of the two systems and majority (54% vs 46%) preferred proposed system and it is statistically significant with p < 0.001."}, {"heading": "5. CONCLUSION & FUTURE WORKS", "text": "In this work we have applied Deep Belief Network (DBN) to model the F0 contour of synthesized speech which is generated by HMM-based Speech Synthesis System. DBN acted as a high level feature extractor from the raw input text. Neural network is trained for each phoneme properties i.e. for the input to the neural network textual features (phoneme identity, syllable counts etc.) and for the output normalized log F0 values are used. Although the whole experiment is conducted on Bengali Language but it can be applied to any languages. From the objective metrics and subjective test it is found that proposed model has more preference than MSD-HMM based model which is found in many standard text-to-speech synthesis systems."}, {"heading": "6. REFERENCES", "text": "[1] Geoffrey E Hinton, Simon Osindero, and Yee-Whye Teh, \u201cA fast learning algorithm for deep belief nets,\u201d Neural computation, vol. 18, no. 7, pp. 1527\u20131554, 2006.\n[2] Volodymyr Mnih and Geoffrey E Hinton, \u201cLearning to detect roads in high-resolution aerial images,\u201d in Computer Vision\u2013ECCV 2010, pp. 210\u2013223. Springer, 2010.\n[3] Ronan Collobert and Jason Weston, \u201cA unified architecture for natural language processing: Deep neural networks with multitask learning,\u201d in Proceedings of the 25th international conference on Machine learning (ICML). ACM, 2008, pp. 160\u2013167.\n[4] Li Deng, Michael L Seltzer, Dong Yu, Alex Acero, Abdel-rahman Mohamed, and Geoffrey E Hinton, \u201cBinary coding of speech spectrograms using a deep autoencoder,\u201d in INTERSPEECH. Citeseer, 2010, pp. 1692\u2013 1695.\n[5] George E Dahl, Dong Yu, Li Deng, and Alex Acero, \u201cContext-dependent pre-trained deep neural networks for large-vocabulary speech recognition,\u201d IEEE Transactions on Audio, Speech, and Language Processing, vol. 20, no. 1, pp. 30\u201342, 2012.\n[6] Benigno Uria, Steve Renals, and Korin Richmond, \u201cA deep neural network for acoustic-articulatory speech inversion,\u201d in NIPS Workshop on Deep Learning Unsupervised Feature Learning, 2011.\n[7] Heiga Zen, Andrew Senior, and Mike Schuster, \u201cStatistical parametric speech synthesis using deep neural networks,\u201d in ICASSP, 2013, pp. 7962\u20137966.\n[8] Shiyin Kang, Xiaojun Qian, and Helen Meng, \u201cMultidistribution deep belief network for speech synthesis,\u201d in International Conference on Acoustics, Speech and\nSignal Processing (ICASSP). IEEE, 2013, pp. 8012\u2013 8016.\n[9] Z-H Ling, Li Deng, and Dong Yu, \u201cModeling spectral envelopes using restricted boltzmann machines and deep belief networks for statistical parametric speech synthesis,\u201d IEEE Transactions on Audio, Speech, and Language Processing, vol. 21, no. 10, pp. 2129\u20132139, 2013.\n[10] Raul Fernandez, Asaf Rendel, Bhuvana Ramabhadran, and Ron Hoory, \u201cF0 contour prediction with a deep belief network-gaussian process hybrid model,\u201d in International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2013, pp. 6885\u20136889.\n[11] Max Welling, Michal Rosen-Zvi, and Geoffrey E Hinton, \u201cExponential family harmoniums with an application to information retrieval,\u201d in Advances in neural information processing systems, 2004, pp. 1481\u20131488.\n[12] Geoffrey E Hinton, \u201cTraining products of experts by minimizing contrastive divergence,\u201d Neural computation, vol. 14, no. 8, pp. 1771\u20131800, 2002.\n[13] Ruslan Salakhutdinov, Learning deep generative models, Ph.D. thesis, University of Toronto, 2009.\n[14] Sultana Dil Afroza Alam Firoj, Habib S. M. Murtoza and Khan Mumit, \u201cDevelopment of annotated bangla speech corpora, spoken language technologies for under-resourced language,\u201d in Proceedings of (SLTU10). Penang, Malasia, 2010, vol. 1, pp. 35 \u2013 41.\n[15] Hideki Kawahara, \u201cSpeech representation and transformation using adaptive interpolation of weighted spectrum: vocoder revisited,\u201d in International Conference on Acoustics, Speech, and Signal Processing. IEEE, 1997, vol. 2, pp. 1303\u20131306.\n[16] Shuichi Narusawa, Nobuaki Minematsu, Keikichi Hirose, and Hiroya Fujisaki, \u201cA method for automatic extraction of model parameters from fundamental frequency contours of speech,\u201d in International Conference on Acoustics, Speech, and Signal Processing (ICASSP). IEEE, 2002, vol. 1, pp. I\u2013509.\n[17] \u201cHMM-based speech synthesis system (HTS),\u201d [Online] Available: http://hts.sp.nitech.ac.jp/.\n[18] Sankar Mukherjee and Shyamal Kumar Das Mandal, \u201cA bengali hmm based speech synthesis system,\u201d in International Conference on Speech Database and Assessments (Oriental COCOSDA), 2012, pp. 225\u2013259."}], "references": [{"title": "A fast learning algorithm for deep belief nets", "author": ["Geoffrey E Hinton", "Simon Osindero", "Yee-Whye Teh"], "venue": "Neural computation, vol. 18, no. 7, pp. 1527\u20131554, 2006.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Learning to detect roads in high-resolution aerial images", "author": ["Volodymyr Mnih", "Geoffrey E Hinton"], "venue": "Computer Vision\u2013ECCV 2010, pp. 210\u2013223. Springer, 2010.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "A unified architecture for natural language processing: Deep neural networks with multitask learning", "author": ["Ronan Collobert", "Jason Weston"], "venue": "Proceedings of the 25th international conference on Machine learning (ICML). ACM, 2008, pp. 160\u2013167.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Binary coding of speech spectrograms using a deep autoencoder", "author": ["Li Deng", "Michael L Seltzer", "Dong Yu", "Alex Acero", "Abdel-rahman Mohamed", "Geoffrey E Hinton"], "venue": "INTERSPEECH. Citeseer, 2010, pp. 1692\u2013 1695.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition", "author": ["George E Dahl", "Dong Yu", "Li Deng", "Alex Acero"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 20, no. 1, pp. 30\u201342, 2012.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "A deep neural network for acoustic-articulatory speech inversion", "author": ["Benigno Uria", "Steve Renals", "Korin Richmond"], "venue": "NIPS Workshop on Deep Learning Unsupervised Feature Learning, 2011.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Statistical parametric speech synthesis using deep neural networks", "author": ["Heiga Zen", "Andrew Senior", "Mike Schuster"], "venue": "ICASSP, 2013, pp. 7962\u20137966.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Multidistribution deep belief network for speech synthesis", "author": ["Shiyin Kang", "Xiaojun Qian", "Helen Meng"], "venue": "International Conference on Acoustics, Speech and  Signal Processing (ICASSP). IEEE, 2013, pp. 8012\u2013 8016.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "Modeling spectral envelopes using restricted boltzmann machines and deep belief networks for statistical parametric speech synthesis", "author": ["Z-H Ling", "Li Deng", "Dong Yu"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 21, no. 10, pp. 2129\u20132139, 2013.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "F0 contour prediction with a deep belief network-gaussian process hybrid model", "author": ["Raul Fernandez", "Asaf Rendel", "Bhuvana Ramabhadran", "Ron Hoory"], "venue": "International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2013, pp. 6885\u20136889.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Exponential family harmoniums with an application to information retrieval", "author": ["Max Welling", "Michal Rosen-Zvi", "Geoffrey E Hinton"], "venue": "Advances in neural information processing systems, 2004, pp. 1481\u20131488.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2004}, {"title": "Training products of experts by minimizing contrastive divergence", "author": ["Geoffrey E Hinton"], "venue": "Neural computation, vol. 14, no. 8, pp. 1771\u20131800, 2002.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2002}, {"title": "Learning deep generative models, Ph.D", "author": ["Ruslan Salakhutdinov"], "venue": "thesis, University of Toronto,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Development of annotated bangla speech corpora, spoken language technologies for under-resourced language", "author": ["Sultana Dil Afroza Alam Firoj", "Habib S.M. Murtoza", "Khan Mumit"], "venue": "Proceedings of (SLTU10). Penang, Malasia, 2010, vol. 1, pp. 35 \u2013 41.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2010}, {"title": "Speech representation and transformation using adaptive interpolation of weighted spectrum: vocoder revisited", "author": ["Hideki Kawahara"], "venue": "International Conference on Acoustics, Speech, and Signal Processing. IEEE, 1997, vol. 2, pp. 1303\u20131306.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1997}, {"title": "A method for automatic extraction of model parameters from fundamental frequency contours of speech", "author": ["Shuichi Narusawa", "Nobuaki Minematsu", "Keikichi Hirose", "Hiroya Fujisaki"], "venue": "International Conference on Acoustics, Speech, and Signal Processing (ICASSP). IEEE, 2002, vol. 1, pp. I\u2013509.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2002}, {"title": "A bengali hmm based speech synthesis system", "author": ["Sankar Mukherjee", "Shyamal Kumar Das Mandal"], "venue": "International Conference on Speech Database and Assessments (Oriental COCOSDA), 2012, pp. 225\u2013259.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "The training of DBN as described in [1] is to first initialize the weights of each layer greedily in a purely unsupervised way and then fine-tune all the weights jointly to further improve the likelihood.", "startOffset": 36, "endOffset": 39}, {"referenceID": 1, "context": "DBN-DNN (DNN pre-trained by DBN and fine-tune by labeled data) is successfully applied in speech, audio, image and text data [2] [3].", "startOffset": 125, "endOffset": 128}, {"referenceID": 2, "context": "DBN-DNN (DNN pre-trained by DBN and fine-tune by labeled data) is successfully applied in speech, audio, image and text data [2] [3].", "startOffset": 129, "endOffset": 132}, {"referenceID": 3, "context": "In recent years, DBNs have been successfully applied to modeling speech signals, such as spectrogram coding [4], speech recognition [5], and acousticarticulatory inversion mapping [6], where they mainly act as the pre-training methods for a deep autoencoder or a deep neural network (DNN).", "startOffset": 108, "endOffset": 111}, {"referenceID": 4, "context": "In recent years, DBNs have been successfully applied to modeling speech signals, such as spectrogram coding [4], speech recognition [5], and acousticarticulatory inversion mapping [6], where they mainly act as the pre-training methods for a deep autoencoder or a deep neural network (DNN).", "startOffset": 132, "endOffset": 135}, {"referenceID": 5, "context": "In recent years, DBNs have been successfully applied to modeling speech signals, such as spectrogram coding [4], speech recognition [5], and acousticarticulatory inversion mapping [6], where they mainly act as the pre-training methods for a deep autoencoder or a deep neural network (DNN).", "startOffset": 180, "endOffset": 183}, {"referenceID": 6, "context": "In statistical parametric speech synthesis domain DBNs have also been studied very recently [7] [8] [9].", "startOffset": 92, "endOffset": 95}, {"referenceID": 7, "context": "In statistical parametric speech synthesis domain DBNs have also been studied very recently [7] [8] [9].", "startOffset": 96, "endOffset": 99}, {"referenceID": 8, "context": "In statistical parametric speech synthesis domain DBNs have also been studied very recently [7] [8] [9].", "startOffset": 100, "endOffset": 103}, {"referenceID": 7, "context": "Use of DBN to model F0 contour [8] [10] was not new.", "startOffset": 31, "endOffset": 34}, {"referenceID": 9, "context": "Use of DBN to model F0 contour [8] [10] was not new.", "startOffset": 35, "endOffset": 39}, {"referenceID": 9, "context": "But in [10] DBN was used as feature extractor for Gaussian Process Regression which is a non-parametric model.", "startOffset": 7, "endOffset": 11}, {"referenceID": 7, "context": "other aspect was rather than discontinues F0 contour [8] we train the DNN with continues F0 contour which adds simplicity to the model.", "startOffset": 53, "endOffset": 56}, {"referenceID": 10, "context": "The weights between the connections of the visible units v and hidden units h define a probability distribution over the visible units v via an energy function [11].", "startOffset": 160, "endOffset": 164}, {"referenceID": 11, "context": "But, Emodel(vi, hj) is computationally very expensive to compute so the contrastive divergence (CD) algorithm [12] to the gradient is used where Edata(vi, hj) is replaced by running the Gibbs sampler initialized at the data for one full step.", "startOffset": 110, "endOffset": 114}, {"referenceID": 0, "context": "Therefore, a greedy learning algorithm has been proposed and popularly applied to train the DBN in a layer-by-layer manner [1].", "startOffset": 123, "endOffset": 126}, {"referenceID": 0, "context": "It has been proved that this greedy learning algorithm can improve the lower bound on the log-likelihood of the training samples by adding each new hidden layer [1] [13].", "startOffset": 161, "endOffset": 164}, {"referenceID": 12, "context": "It has been proved that this greedy learning algorithm can improve the lower bound on the log-likelihood of the training samples by adding each new hidden layer [1] [13].", "startOffset": 165, "endOffset": 169}, {"referenceID": 12, "context": "AIS-based partition function estimation with approximate inference [13] used to estimate the lower bound on the log-probability.", "startOffset": 67, "endOffset": 71}, {"referenceID": 13, "context": "speech corpus [14] is employed here for the whole experiment and it consists of one male voice of age 27.", "startOffset": 14, "endOffset": 18}, {"referenceID": 14, "context": "STRAIGHT [15], a high-quality analysis and synthesis algorithm, was adopted to estimate the spectrum and F0 contours with 10-ms frame rate.", "startOffset": 9, "endOffset": 13}, {"referenceID": 15, "context": "Continues F0 contour was formed using step described in [16] which resulted an approximation of original F0 contour consisting of third order polynomial segments.", "startOffset": 56, "endOffset": 60}, {"referenceID": 9, "context": "of syllable in current word [10]", "startOffset": 28, "endOffset": 32}, {"referenceID": 11, "context": "Phoneme position in syllable [Forward/Backward] 6 * 2 = [12]", "startOffset": 56, "endOffset": 60}, {"referenceID": 16, "context": "of phonemes in syllable [Previous/Current/Next] 6 * 3 = [18]", "startOffset": 56, "endOffset": 60}, {"referenceID": 5, "context": "Vowel position in syllable [Forward] [6]", "startOffset": 37, "endOffset": 40}, {"referenceID": 15, "context": "Vowel identity in the syllable [16] Total 220", "startOffset": 31, "endOffset": 35}, {"referenceID": 16, "context": "In order to compare the proposed model against the clustering tree with multi-space probability distribution (MSD-HMM) F0 model included in the HTS synthesis engine toolkit [17], a Bengali-HTS [18] system is constructed.", "startOffset": 193, "endOffset": 197}], "year": 2015, "abstractText": "In recent years multilayer perceptrons (MLPs) with many hidden layers Deep Neural Network (DNN) has performed surprisingly well in many speech tasks, i.e. speech recognition, speaker verification, speech synthesis etc. Although in the context of F0 modeling these techniques has not been exploited properly. In this paper, Deep Belief Network (DBN), a class of DNN family has been employed and applied to model the F0 contour of synthesized speech which was generated by HMM-based speech synthesis system. The experiment was done on Bengali language. Several DBN-DNN architectures ranging from four to seven hidden layers and up to 200 hidden units per hidden layer was presented and evaluated. The results were compared against clustering tree techniques popularly found in statistical parametric speech synthesis. We show that from textual inputs DBN-DNN learns a high level structure which in turn improves F0 contour in terms of objective and subjective tests.", "creator": "LaTeX with hyperref package"}}}