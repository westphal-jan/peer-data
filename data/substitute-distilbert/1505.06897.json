{"id": "1505.06897", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-May-2015", "title": "Times series averaging from a probabilistic interpretation of time-elastic kernel", "abstract": "at the light of regularized interactive time warping kernels, this paper reconsider the concept of kernel elastic centroid ( dc ) for a set of time series. from this perspective, we query first how tec can easily be addressed citing his preimage problem. unfortunately this preimage problem is ill - posed, may suffer from over - estimated especially efficient long time series and getting a sub - redundant solution involves significantly computational costs. we then derive two new algorithms based on a computational interpretation dubbed kernel alignment matrices that reads in terms of probabilistic distributions vs sets versus alignment groups. the first algorithm is an iterative transformation heuristics inspired from the state of the art dtw barycenter averaging ( dba ) algorithm tested specifically for the dynamic time warping measure. the second proposed algorithm achieves accurate classical averaging into the aligned samples but also implements special advantage of the time of occurrences following the candidate samples. it poses a straightforward progressive agglomerative heuristics. an experimentation that scans for 45 time series datasets classification error rates obtained by first near neighbors classifiers exploiting a single medoid or discrete estimate to represent each categories show that : i ) results based entirely significantly outperform medoids based approaches, ii ) on the considered experience, the two proposed problems outperform the state of the art dba technique, and iii ) the second proposed algorithm that implements an averaging jointly in the sample space and avoids the time range emerges as the most significantly robust time elastic averaging heuristic with an interesting noise reduction capability. index terms - time series averaging time elastic kernel dynamic time warping time series clustering and classification.", "histories": [["v1", "Tue, 26 May 2015 11:02:36 GMT  (335kb)", "https://arxiv.org/abs/1505.06897v1", null], ["v2", "Sat, 30 May 2015 07:17:13 GMT  (336kb)", "http://arxiv.org/abs/1505.06897v2", null], ["v3", "Tue, 9 Jun 2015 12:00:52 GMT  (332kb)", "http://arxiv.org/abs/1505.06897v3", null]], "reviews": [], "SUBJECTS": "cs.LG cs.DS", "authors": ["pierre-fran\\c{c}ois marteau"], "accepted": false, "id": "1505.06897"}, "pdf": {"name": "1505.06897.pdf", "metadata": {"source": "CRF", "title": "Times series averaging from a probabilistic interpretation of time-elastic kernel", "authors": ["Pierre-Francois Marteau"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n50 5.\n06 89\n7v 3\n[ cs\n.L G\n] 9\nJ un\n2 01\n5 1\nIndex Terms\u2014Time series averaging Time elastic kernel Dynamic Time Warping Time series clustering and classification.\n2 Times series averaging from a probabilistic interpretation of time-elastic kernel\nPierre-Francois Marteau, Member, IEEE, E-mail: see http://people.irisa.fr/Pierre-Francois.Marteau/\n\u2726"}, {"heading": "1 INTRODUCTION", "text": "Since Maurice Fre\u0301chet\u2019s pioneering work [1] in the early 1900s, time-elastic matching of time series or symbolic sequences has attracted much attention from the scientific community in numerous fields such as information indexing and retrieval, pattern analysis, extraction and recognition, data mining, etc. This approach has impacted a very wide spectrum of applications relating to a multitude of socio-economic issues such as the environment, industry, health, energy, defense and so on. Among other time elastic measures, Dynamic Time Warping (DTW) was widely popularized during the 1970s with the advent of speech recognition systems [2], [3] and numerous variants that have since been proposed to match time series with a certain degree of time distortion tolerance. The main issue addressed here is time series or shape averaging in the context of a time elastic distance. This is a long-standing issue that is currently becoming increasingly prevalent; it is relevant for summarizing subsets of time series, defining significant prototypes, identifying outliers, performing data mining tasks (mainly exploratory data analysis such as clustering) and speeding up classification, as well as regression or data analysis processes in a big data context. In this paper, we specifically tackle the question of averaging subsets of time series, not from considering the DTWmeasure itself as has been already largely explored, but from the perspective of the so-called regularized DTW kernel (KDTW) that ensures positive definiteness. From this new perspective, the estimation of a time series average or centroid can be readily addressed as a preimage (inverse) problem. However, this approach has some theoretical and practical limitation that are discussed in the following sections. A more promising direct approach is developed here, which is based on a probabilistic interpretation of kernel alignment matrices, allowing a precise definition of the average of a pair of time series from the expected value of local alignments of samples. The tests carried out so far demonstrate the\n\u2022 P.-F. Marteau is with UMR CNRS IRISA, Universite\u0301 de Bretagne Sud, F-56000 Vannes, France.\nrobustness and the efficiency of this approach comparison to the state-of-the art approach. The structure of this paper is as follows: after an introduction, the second section summarizes the most relevant related studies on time series averaging as well as DTW kernelization. In the third section, we show how the estimation of a time-elastic centroid can be addressed as a preimage problem in the context of the DTW regularized kernel (KDTW). In the fourth section, we derive a probabilistic interpretation from the kernel alignment matrices evaluated on a pair of time series. In the fifth section, we define the average of a pair of time series, and based on this pairwise averaging procedure, we propose two sub-optimal algorithms designed for the averaging of any subset of time series."}, {"heading": "2 RELATED WORKS", "text": "Time series averaging in the context of (multiple) time elastic distance alignments has been mainly addressed in the scope of the Dynamic Time Warping (DTW) measure [2], [3]. Although other time elastic distance measures such as the Edit Distance With Real Penalty (ERP) [4] or the Time Warp Edit Distance (TWED) [5] could be considered instead, without loss of generality, we remain focused throughout this paper on DTW and its kernelization."}, {"heading": "2.1 DTW and time elastic centroid of a pair of time series", "text": "A classical formulation of DTW can be given as follows. If d is a fixed positive integer, we define a time series of length T as a multidimensional sequence v = v(i), such that, \u2200i \u2208 {1, .., T }, v(i) \u2208 Rd.\nDefinition 2.1: If u and v are two time series with respective lengths T1 and T2, an alignment path \u03c0 = (\u03c0k) of length p = |\u03c0| between u and u is represented by a sequence\n\u03c0 : {1, . . . , p} \u2192 {1, . . . , T1} \u00d7 {1, . . . , T2}\nsuch that \u03c01 = (1, 1), \u03c0p = (T1, T2), and (using the notation \u03c0k = (ik, jk), for all k \u2208 {1, . . . , p \u2212 1}, \u03c0k+1 = (ik+1, jk+1) \u2208 {(ik + 1, jk), (ik, jk + 1),\n3 (ik + 1, jk + 1)}.\nWe define \u2200k \u03c0k(1) = ik and \u03c0k(2) = jk, as the index access functions at step k of the mapped elements in the pair of aligned time series.\nIn other words, a warping path defines a way to travel along both time series simultaneously from beginning to end; it cannot skip a point, but it can advance one time step along one series without advancing along the other, thereby justifying the term time-warping. If \u03b4 is a distance on Rd, the global cost of a warping path \u03c0 is the sum of distances (or squared distances or local costs) between pairwise elements of the two time series along \u03c0, i.e.:\ncost(\u03c0) = \u2211\n(ik,jk)\u2208\u03c0\n\u03b4(vik , wjk )\nA common choice of distance on Rd is the one generated by the L2 norm:\n\u03b4(x, y) = \u2016x\u2212 y\u201622 = d \u2211\nl=1\n(xl \u2212 yl) 2.\nDefinition 2.2: For a finite time series, any warping path has a finite length, and thus the number of existing warping paths is finite. Hence, there exists at least one path \u03c0\u2217 whose cost is minimal, so we can define DTW(u, v) as the minimal cost taken over all existing warping paths. Hence\nDTW(u, v) = min \u03c0\ncost(\u03c0(u, v)) = cost(\u03c0\u2217(u, v)). (1)\nDefinition 2.3: From the DTW measure, it is straightforward to define the time elastic centroid c(u, v) of a pair of time series u and v as the time series (ck) whose elements are ck = Centroid(u(\u03c0\u2217k(1)), v(\u03c0 \u2217 k(2)), \u2200k \u2208 1, \u00b7 \u00b7 \u00b7 , |\u03c0\u2217|, where Centroid corresponds to the usual definition in Euclidean space."}, {"heading": "2.2 Time elastic centroid of a set of time series", "text": "A single alignment path is required to calculate the time elastic centroid of a pair of time series (Def. 2.3). However, multiple path alignments need to be considered to evaluate the centroid of a larger set of time series. Multiple alignments have been widely studied in bioinformatics [6], and it has been shown that the computational complexity of determining the optimal alignment of a set of sequences under the sum of all pairs (SP) score scheme is a NP-complete problem [7] [8]. The time and space complexity of this problem is O(Lk), where k is the number of sequences in the set and L is the length of the sequences when using dynamic programming to search for an optimal solution [9]. This latter result applies to the estimation of the time elastic centroid of a set of k time series with respect to the DTW measure. Since the search for an optimal\nsolution becomes rapidly intractable with increasing k, sub-optimal heuristic solutions have been subsequently proposed, most of them falling into one of the following three categories."}, {"heading": "2.2.1 Progressive heuristics", "text": "Progressive heuristic methods estimate the time elastic centroid of a set of k time series by combining pairwise centroids (Def. 2.3). This kind of approach constructs a binary tree whose leaves correspond to the time series of the data set, and whose nodes correspond to the calculation of a local pairwise centroid, such that, when the tree is complete, the root is associated with the estimated data set centroid. The proposed strategies differ in the way the tree is constructed. One popular approach consists of providing a random order for the leaves, and then constructing the binary tree up to the root using this ordering [10]. Another approach involves constructing a dendrogram (a hierarchical ascendant clustering) from the data set and then using this dendrogram to calculate pairwise centroids starting with the closest pairs of time series and progressively aggregating series that are farther away [11] as illustrated on the left of Fig. 1. Note that these heuristic methods are entirely based on the calculation of a pairwise centroid, so they do not explicitly require the evaluation of a DTW centroid for more than two time series. Their degree of complexity varies linearly with the number of time series in the data set."}, {"heading": "2.2.2 Iterative heuristics", "text": "Iterative heuristics are based on an iterated three-step process. For a given temporary centroid candidate, the first step consists of calculating the inertia, i.e. the sum of the DTW distances between the temporary centroid and each time series in the data set. The second step evaluates the best pairwise alignment with the temporary centroid for each time series uj(i) in the data set (j \u2208 {1 \u00b7 \u00b7 \u00b7n}). A new time series u\u0303j(i) is thus constructed that contains all the samples of time series uj(i), but with time being stretched or compressed according to the best alignment path. The third step consists of producing a new temporary centroid candidate c(i) from the set {u\u0303j(i)} by successively averaging (in the sense of the Euclidean centroid), the samples at every timestamp i of the u\u0303j(i) time series. Basically, c(i) = \u2211\nj=1..ni u\u0303j(i).11(i, j)/\n\u2211\nj=1..ni 11(i, j)), where 11(i, j) is an\nindicator function equal to 1 if time series u\u0303j is defined for timestamp i, but which is otherwise 0. Thus, the new centroid candidate replaces the previous one and the process is iterated until the inertia is no longer reduced or the maximum number of iterations is reached. Generally, the first temporary centroid candidate is taken as the DTW medoid of the considered data set. This process is illustrated on the right of Fig. 1. The three steps of this heuristic method were first proposed in [12]. The iterative aspect of this heuristic approach was initially introduced by [13] and refined by [14].\nNote that, in contrast to the progressive method, this kind of approach needs to evaluate, at each iteration, all the alignments with the current centroid candidate. The complexity of the iterative approach is higher than the progressive approach, the extra computational cost being linear with the number of iterations. More sophisticated approaches have been proposed to escape some local minima. [15] have evaluated a genetic algorithm for managing a population of centroid candidates, thus improving with some success the straightforward iterative heuristic methods."}, {"heading": "2.2.3 Optimization approaches", "text": "Given the entire set of time series S and a subset of n time series S = {uj}j=1\u00b7\u00b7\u00b7n \u2286 S, optimization approaches attempt to estimate the centroid of S from the definition of an optimization problem, which is generally expressed by Eq. 2 given below:\nc = argmin s\u2208S\nn \u2211\nj=1\nDTW(s, uj) (2)\nTo our knowledge, the first attempt to use this kind of direct approach for the estimation of time elastic centroid estimation was recently described in [16]. These authors (op.cit.) derived a solution of their original non-convex constrained optimization problem, by integrating a temporal weighting of local sample alignments to highlight the temporal region of interest in a time series data set, thus penalizing the other temporal regions. Two time elastic measures were specifically addressed: i) a dynamic time warping measure between a time series and a weighted time series (representing\nthe centroid estimate) and ii) an (indefinite) kernel DTW called DTAK [17]. Their results are very promising: although the number of parameters to optimize is linear with the size and the dimensionality of the time series, the two steps gradient-based optimization process they derived is very computationally efficient and shown to outperform the state of the art approaches on some challenging scalar and multivariate data sets. However, as numerous local optima exist in practice, the method is not guaranteed to converge toward the best possible centroid, which is anyway the case in all other approaches."}, {"heading": "2.3 Discussion and motivation", "text": "According to the state of the art in time elastic centroid estimation, an exact centroid, if it exists, can be calculated by solving a NP-complete problem whose complexity is exponential with the number of time series to be averaged. Heuristic methods with increasing time complexity have been proposed since the early 2000s. Simple pairwise progressive aggregation is a less complex approach, but which suffers from its dependence on initial conditions. Iterative aggregation is reputed to be more efficient, but entails a higher computational cost. It could be combined with ensemble methods or soft optimization such as genetic algorithms. The nonconvex optimization approach has the merit of directly addressing the mathematical formulation of the centroid problem in a time elastic distance context. This approach nevertheless involves a higher complexity and must deal with a relatively large set of parameters to be optimized (the weights and the sample of the centroid). Its scalability could be questioned, specifically for high dimensional multivariate time series.\n5 It should also be mentioned that some criticisms of these heuristic methods have been made in [18]. Among other drawbacks, the fact that DTW is not a metric (the triangle inequality is not satisfied) could explain the occurrence of unwanted behaviour such as centroid drift outside the time series cluster to be averaged. We should also be borne in mind that keeping a single best alignment (even though several may exist, without mentioning the good ones) can increase the dependence of the solution on the initial conditions. It may also increase the aggregating order of the time series proposed by the chosen method, or potentially enhance the convergence rate. In this study, we do not directly address the issue of time elastic centroid estimation from the DTW perspective, but rather from the point of view of the regularized dynamic time warping kernel (KDTW) [19]. This perspective allows us to consider centroid estimation as a preimage problem, which is in itself another optimization perspective. More importantly, the KDTW alignment matrices can be used to derive a probabilistic interpretation of the pairwise alignment of time series. This leads us to propose a robust interpolation scheme jointly along the time axis and in the sample space. We do not claim that using KDTW and its probabilistic interpretation can solve all or even any of the fundamental questions raised earlier: since the problem tackled here is NP-complete, an exact solution requires exponentially complex computations and any heuristic method must handle numerous local minima. Our aim is to throw some new light on the problem as well as obtain new quantitative results showing, in this difficult context, that the proposed alternative approach is worth considering."}, {"heading": "2.4 Time elastic kernels and their regularization", "text": "Dynamic Time Warping (DTW), [2], [3] as defined in Eq.1 can be recursively evaluated as\nddtw(Xp, Yq) = d 2 E(x(p), y(q)) (3)\n+ Min\n\n\n ddtw(Xp\u22121, Yq) sup ddtw(Xp\u22121, Yq\u22121) sub ddtw(Xp, Yq\u22121) ins\nwhere dE(x(p), y(q) is the Euclidean distance (eventually, the square of the Euclidean distance) defined on Rk between the two positions/?points in sequences X and Y taken at times p and q, respectively. Apart from the fact that the triangular inequality does not hold for the DTW distance measure, it is furthermore not possible to define a positive definite kernel directly from this distance. Hence, the optimization problem, which is inherent to the learning of a kernel machine, is no longer quadratic and, at least for some tasks, could be a source of limitation.\nRegularized DTW: recent studies [20], [19] lead us to propose new guidelines to ensure that kernels constructed from elastic measures such as DTW are positive\ndefinite. A simple instance of such a regularized kernel, derived from [19], can be expressed in the following form, which makes use of two recursive terms:\nKDTW(Xp, Yq) = K xy dtw(Xp, Yq) +K xx dtw(Xp, Yq)\nKxydtw(Xp, Yq) = 1 3e \u2212\u03bdd2E(x(p),y(q))\n\u2211\n\n\n h(p\u2212 1, q)Kxydtw(Xp\u22121, Yq) h(p\u2212 1, q \u2212 1)Kxydtw(Xp\u22121, Yq\u22121) h(p, q \u2212 1)Kxydtw(Xp, Yq\u22121)\nKxxdtw(Xp, Yq) = 1 3\n\u2211\n\n \n \nh(p\u2212 1, q)Kxxdtw(Xp\u22121, Yq)e \u2212\u03bdd2E(x(p),y(p)) \u2206p,qh(p, q)K xx dtw(Xp\u22121, Yq\u22121)e \u2212\u03bdd2E(x(p),y(q)) h(p, q \u2212 1)Kxxdtw(Xp, Yq\u22121)e \u2212\u03bdd2E(x(q),y(q))\n(4)\nwhere \u2206p,q is the Kronecker symbol, \u03bd \u2208 R+ is a stiffness parameter which weights the local contributions, i.e. the distances between locally aligned positions, and dE(., .) is a distance defined on Rk. The initialization is simply Kxydtw(X0, Y0) = Kxxdtw(X0, Y0) = 1.\nThe main idea behind this regularization is to replace the operators min and max (which prevent symmetrization of the kernel) by a summation operator ( \u2211\n). This allows us to consider the best possible alignment, as well as all the best (or nearly the best) paths by summing their overall cost. The parameter \u03bd is used to check what is termed as nearly-the-best alignment, thus penalizing alignments that are too far away from the optimal ones. This parameter can be easily optimized through a cross-validation."}, {"heading": "3 KDTW CENTROID AS A PREIMAGE PROBLEM", "text": "In this section, we tackle the centroid estimation question from a kernelized centroid point of view, the kernel of interest being KDTW.\nThe Moore-Aronszajn theorem [21] establishes that a reproducing kernel Hilbert space (RKHS) exists uniquely for every positive definite kernel and vice-versa. Let H be the RKHS associated to kernel \u03ba defined on a set X , and let \u3008., .\u3009H be the inner product defined on H. In addition, the representer property of the evaluation functional in H is expressed as: for any \u03c8 \u2208 H and any xj \u2208 X , \u03c8(xj) = \u3008\u03c8(.), \u03ba(., xj)\u3009H. Denoting \u03c6(.) as the map that assigns the kernel function \u03ba(., x) to each input x \u2208 X , the reproducing property of the kernel implies that for any (xi, xj) \u2208 X 2, \u03ba(xi, xj) = \u3008\u03c6(xi), \u03c6(xj)\u3009H. Furthermore, DH(xi, xj)\n2 = ||\u03c6(xi) \u2212 \u03c6(xj)||2H = \u3008\u03c6(xi), \u03c6(xi)\u3009H + \u3008\u03c6(xj), \u03c6(xj)\u3009H \u2212 2.\u3008\u03c6(xi), \u03c6(x)\u3009H is the generalization of the squared Euclidean distance defined\n6 in the feature space H, which can be expressed in kernel terms as: DH(xi, xj) 2 = \u03ba(xi, xi) 2+\u03ba(xj, xj)\n2\u22122.\u03ba(xi, xj) (the so-called kernel trick). Finally, the representer theorem [22] states that any function \u03d5(.)\u2217 of a RKHS H minimizing a regularized cost functional of the form:\nn \u2211\ni=1\nJ(\u03d5(xi), yi) + g(||\u03d5|| 2 H)\nwith predicted output \u03d5(xi) for input xi and desired output yj , where g(.) is a strictly monotonically increasing function on R+-, is equivalent to a kernel expansion expressed in terms of available data ({(xi, yi)})\n\u03d5\u2217(.) =\nn \u2211\ni=1\n\u03b3i\u03ba(xi, .), where \u2200i, \u03b3i \u2208 R. (5)\nHence, a direct definition of the kernelized centroid of the set {xi, i = 1..n} expressed in the RKHS H feature space associated with kernel \u03ba can be written as:\n\u03d5\u2217(.) = arg min \u03d5(.)\u2208H\nn \u2211\ni=1\n||\u03d5(.) \u2212 \u03ba(., xi)|| 2 H (6)\n= arg min \u03d5(.)\u2208H\nn \u00b7 ||\u03d5(.)||2H \u2212 2 \u00b7 n \u2211\nj=1\n\u3008\u03d5(.), \u03ba(., xj)\u3009H\nThe representer theorem applies and thus \u03d5\u2217(.) takes the form given in Eq. 5, which allows us to rewrite Eq. 6 as follows:\n\u03d5\u2217(.) = arg min {\u03bbi}i=1\u00b7\u00b7\u00b7n\nn \u2211\ni=1\nn \u2211\nj=1\n\u03b3i\u03b3j\u03ba(xi, xj)\n\u2212 2 \u00b7 n \u2211\ni=1\nn \u2211\nj=1\n\u03b3j\u03ba(xi, xj) (7)\nUnfortunately, if the kernelized centroid is related to a well-defined quadratic optimization problem in the RKHS space H (Eq. 7), it is an ill-posed problem in set X . This is known as the preimage problem, since the pre-image of \u03c6(.)\u2217 might not exist. Instead, we are seeking the best approximation, namely x\u2217 \u2208 X whose map \u03c6(x\u2217) = \u03ba(., x\u2217) is as close as possible to \u03d5(.)\u2217, as illustrated in Fig.2. Hence, if we remove the term that does depend upon x, the optimization problem becomes:\nx\u2217 = argmin x\u2208X\nn \u00b7 ||\u03ba(., x)||2H \u2212 2 \u00b7 n \u2211\nj=1\n\u3008\u03ba(., x), \u03ba(., xj)\u3009H\n= argmin x\u2208X\nn \u00b7 \u03ba(x, x) \u2212 2 \u00b7 n \u2211\nj=1\n\u03ba(x, xj) (8)\nFor KDTW, the non-convex optimization problem cannot be straightforwardly addressed using gradientbased approaches mainly because the derivative cannot be determined analytically. Moreover, the number of\nvariables (linear with the length of the time series and with the dimensionality of each sample) is generally high so this approach often encounters combinatorial difficulties related to the number of local minima. A derivative-free method could nevertheless be applied for local modelling of the functional to be optimized. In an attempt to carry out such a preimage formulation to estimate the time elastic centroid for a set of time series, we applied the state-of-the-art BOBYQA algorithm developed for bound constrained optimization without using derivatives [23]. Fig.3 and Fig.4 give the centroid estimations for each category of the CBF and Trace datasets, respectively [24]. On the top left diagram of the figures, the values of the function to be minimized are plotted against the number of iterations. The optimization process is initialized using the medoid for each category. We show that the required number of iterations is quite high and depends on the number of\n7 0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2\nx 10 4\n\u22121\n\u22120.8\n\u22120.6\n\u22120.4\n\u22120.2\n0\n0.2\n0.4\n0 50 100 150 200 250 300 \u22123\n\u22122\n\u22121\n0\n1\n2\n3\n4\n0 50 100 150 200 250 300 \u22122.5\n\u22122\n\u22121.5\n\u22121\n\u22120.5\n0\n0.5\n1\n0 50 100 150 200 250 300 \u22122.5\n\u22122\n\u22121.5\n\u22121\n\u22120.5\n0\n0.5\n1\n1.5\nFig. 4. Centroid estimations of the first three categories (out of four) contained in the Trace dataset as a solution of the preimage problem. In bold blue, the centroid time series; in light red, the time series of the averaged dataset. Top left diagram of figure shows value of the minimized functional expressed on a log-scale, plotted against the iteration index.\nvariables. For the CBF dataset, the time series is made up of 128 samples while there are 275 samples for the Trace dataset. The convergence rate is roughly ten times slower for the Trace data set compared with the CBF dataset, mainly because KDTW complexity is quadratic with the length of the time series. The iteration cost becomes somewhat prohibitive for long time series or large time series datasets. Although this approach could be possibly optimized, the parameters need to be carefully set up (basically, definition of the trust region) and, in any case, as stated above, the optimum so provided remains an estimation of the centroid that is sought. Finally, note that the functional starts to decrease after attaining the number of iterations (in this case, twice the length of the time series) initially required for local estimation of the functional."}, {"heading": "4 PROBABILISTIC INTERPRETATION OF TIME ELASTIC KERNEL ALIGNMENT MATRICES", "text": "In this section, we consider the recursive term Kxydtw(., .) that is used in Eq. 4. When evaluating the similarity between two time series Xp and Yq with respective lengths of p and q, this recursion allows the construction of an alignment matrix AM(i, j) with i \u2208 {1 \u00b7 \u00b7 \u00b7 p} and i \u2208 {1 \u00b7 \u00b7 \u00b7 q}. The cell at location (i, j) contains the summation of the global costs of all alignment paths, as defined in definition 2.1, that connect cell (1, 1) with cell (i, j). For any alignment path \u03c0, the global cost is expressed as:\ncost(\u03c0) =\n|\u03c0| \u220f\nk=1\ne\u2212\u03bdd 2 E(X(\u03c0k(1)),Y (\u03c0k(2))) (9)\ni.e. the product along the path of the local alignment costs. We can give a probabilistic interpretation of these local costs exp(\u2212\u03bdd2E(X(\u03c0k(1)), Y (\u03c0k(2)))): basically, we can assume that these local costs correspond (within the magnitude of the scalar multiplication constant) to the local a priori probability of aligning sample X(\u03c0k(1)) with sample Y (\u03c0k(2)). By making this assumption, we eventually attach a probability distribution to the set of all alignment paths, with the cost(\u03c0) corresponding (within the magnitude of the scalar multiplication constant) to the probability attached to alignment path \u03c0. Hence, the cell (i, j) of matrix AM , contains the sum of the probabilities (within the magnitude of the scalar multiplication constant) of the paths that connect cell (1, 1) to cell (i, j). Similarly, if, instead of X and Y , we evaluate the similarity between Xr and Yr derived from X and Y by reversing the temporal index, we obtain an alignment matrix AMr whose cell (i, j) contains the sum of the probabilities (to within a multiplicative scalar constant) of the paths that connect cell (p, q) tp cell (i, j). Finally, multiplying properly cells of AM with cells of AMr yields the Alignment Matrix Average (AMA) defined as:\nAMA(i, j) = AM(i, j) \u00b7AMr(p\u2212 i + 1, q \u2212 j + 1) (10)\nand whose cell (i, j) contains the sum of the probabilities (upto the normalization constant) of the paths that connect cell (1, 1) to cell (p, q) while going through the cell (i, j). From this path probability distribution, we can now derive an alignment probability distribution between the samples of X and the samples of Y as follows:\n\u2022 For all i, the probability of aligning sample X(i) is P (i) = 1; all samples need to be aligned. \u2022 Similarly, for all j, the probability of aligning sample Y (j) is P (j) = 1. \u2022 The probability of aligning sampleX(i)with sample Y (j) is P (i, j) = P (i|j).P (j) = P (i|j). P (i|j) is the probability that sample X(i) is aligned with sample Y (j) given that the alignment process is in state j. The estimation of P (i|j) is obtained by using matrix AMA:\nP (i|j) = AMA(i, j)\n\u2211p i=1 AMA(i, j)\n\u2022 Furthermore, the probability of aligning sample X(i)with sample Y (j) is also P (i, j) = P (j|i).P (i) = P (j|i). Similarly, the estimation of P (j|i) is obtained by using matrix AMA:\nP (j|i) = AMA(i, j)\n\u2211q j=1 AMA(i, j)\n(11)\nNote that the normalization constant mentioned above is eliminated. Since P (i, j) = P (i|j) = P (j|i), we can finally estimate the probability of aligning sampleX(i)with sample Y (j)\n8 as follows:\nP (i, j) = 1\n2 \u00b7\n(\nAMA(i, j) \u2211p\ni=1 AMA(i, j) +\nAMA(i, j) \u2211q\nj=1 AMA(i, j)\n)\n(12) Eq. 12 forms the basis of our pairwise time elastic time series averaging algorithm given below. As an example, Fig 5 presents the AMA matrix corresponding to the alignment of a positive halfwave with a sinus wave. The three potential alignment pathes are clearly identified in the light blue and red colors."}, {"heading": "5 TIME ELASTIC CENTROID BASED ON THE", "text": "AMA ALIGNMENT MATRIX\nBased on the structure of the KDTW kernel and the AMA matrix, and by using the so-called DtwBarycenter Averaging (DBA) method developed by [12], [14], [13], we first present the KernelDtwNarycenter Averaging (KDBA) algorithm for estimating a time elastic centroid for a set of time series according to an iterative agglomerative procedure as shown in Fig. 1b. Secondly, we detail the concept of a time elastic average for a pair of time series (KDTW-PWA), and then develop the progressive heuristic approach presented in Fig. 1a that uses KDTWPWA to estimate another kind of time elastic centroid (KDTW-C1) for a set of time series of any cardinal."}, {"heading": "5.1 KDTW-Centroid of a set of time series based on KDBA algorithm", "text": "Following the DBA algorithmic approach [12], [13], we present here the development of our kernelized version called KDBA. KDBA directly applies the definition of the alignment matrix average (AMA) as given in Eq.10 and its probabilistic interpretation Eq.12. Let us consider a set S of N time series, S = {S1, S2, \u00b7 \u00b7 \u00b7 , SN}, and R a reference time series. Let |R| and |Sn| be the lengths of R and Sn, respectively. Pn(i, j), with i = 1{1, ...|Sn|} and j = 1{1, ...|R|}, is obtained from the AMA matrix resulting from the alignment of Sn with R, according to Eq.12. Algorithm 1 computes an average time series A according to the following equation:\n\u2200i \u2208 {1, \u00b7 \u00b7 \u00b7 , |r|}, A(i) = 1\nN\nN \u2211\nn=1\n|Sn| \u2211\nj=1\nPn(i, j)Sn(j) (13)\nAlgorithm 1 KDBA\n1: procedure KDBA(R,S, \u03bd) 2: // R: a reference time series 3: // S: a set of time series {S1, \u00b7 \u00b7 \u00b7 , SN} 4: // \u03bd: the stiffness parameter of KDTW kernel 5: Double AMA(.,.); 6: Vector-Of-SetOfSamples SampleAssociations(L); 7: Ts A(|R|); //Create a D dimensional 8: //time series of length L; 9: for Int i = 1 to |R| do SampleAssociations(i)={};\n10: for Int n = 1 to |S| do 11: Evaluate AMA matrix for R, Sn with \u03bd; 12: Ts ts//containing L \u201dzeroed\u201d samples; 13: Double normFactor(|R|); 14: for Int i = 1 to |R| do 15: normFactor(i)=0; 16: for Int j = 1 to |Sn| do 17: ts(i) = ts(i) + Sn(j) \u2217AMA(i, j); 18: normFactor(i) = normFactor(i)+ 19: AMA(i, j);\n20: ts(i) = ts1(i)/normFactor(i); 21: SampleAssociations(i)=(ts(i));\n22: for Int i = 1 to |R| do 23: A(i)=barycenter(SampleAssociations(i));\n24: return A\nAlgorithm 2 iKDBA\n1: procedure IKDBA(C,S, \u03bd) 2: //C: a reference time series 3: //S: a set of time series 4: //maxIter: maximum number of iterations 5: //\u03bd: the stiffness parameter of KDTW kernel 6: Ts A; //a D dimensional Timeseries 7: Double inertia = computeInertia(C, S); 8: Boolean Continue=True; 9: Int i = 0;\n10: while Continue do 11: A=C; 12: C=KDTW-C2(C,S, \u03bd); 13: Double new inertia = computeInertia(C, S); 14: if new inertia > inertia OR i > maxIter then 15: Continue = False;\n16: i=i+1;\n17: return A\nNote that the iterative average of time series produced by algorithm 1 has the same size as the reference time series R. The algorithm 1 can be refined by iterating until no further improvement is obtained [14]. An improvement is observed when the sum of the distances (resp. similarities) between the current average R and the new pairwise average provided by KDBA, A, is lowered (resp. increased). Algorithm 2 implements this iterative strategy, which will necessarily find a local minimum\n9 or will stop when a maximum number of iterations has been reached."}, {"heading": "5.2 KDTW average of a pair of time series (KDTWPWA)", "text": "Algorithm 3 KDTW-PWA\n1: procedure KDTW-PWA(X ,Y , AMA) 2: //X,Y: two time series of D dimensional samples 3: //AMA: the average alignment matrix for X,Y 4: Int p = |X |, q = |Y |, L = max{p, q}; 5: Ts A(L), B(L); //Create 2 D dimensional 6: //time series of length L; 7: Double \u03b1; 8: Double NA(L), NB(L); //two double arrays 9: for Int i = 1 to L do\n10: for d=1 to D do 11: A(i, d) = 0, B(i, d) = 0;\n12: NA(i) = 0, NB(i) = 0;\n13: for Int i = 1 to L do 14: if i < p then 15: for Int j = 1 to q do 16: \u03b1 = (i+ j)/2\u2212 \u230a(i+ j)/2\u230b; 17: for d=1 to D do 18: A(\u230a(i+ j)/2\u230b, d)+ = 19: \u03b1 \u00b7 (X(i, d) + Y (j, d)) \u00b7AMA(i, j); 20: A(\u2308(i+ j)/2\u2309, d)+ = 21: (1\u2212\u03b1)\u00b7(X(i, d)+Y (j, d))\u00b7AMA(i, j);\n22: NA(\u230a(i+ j)/2\u230b)+ = \u03b1 \u2217AMA(i, j); 23: NA(\u2308(i+ j)/2\u2309)+ = (1\u2212\u03b1)\u2217AMA(i, j);\n24: if i < q then 25: for Int j = 1 to p do 26: \u03b1 = (i+ j)/2\u2212 \u230a(i+ j)/2\u230b; 27: for d=1 to D do 28: B(\u230a(i+ j)/2\u230b, d)+ = 29: \u03b1 \u00b7 (X(j, d) + Y (i, d)) \u00b7AMA(j, i); 30: B(\u2308(i+ j)/2\u2309, d)+ = 31: (1\u2212\u03b1)\u00b7(X(j, d)+Y (i, d))\u00b7AMA(j, i);\n32: NB(\u230a(i+ j)/2\u230b)+ = \u03b1 \u2217AMA(j, i); 33: NB(\u2308(i+ j)/2\u2309)+ = (1\u2212\u03b1)\u2217AMA(j, i);\n34: for Int i = 1 to L do 35: for d=1 to D do 36: A(i, d) = (A(i, d)/NA(i)+B(i, d)/NB(i))/4;\n37: return A\nSimilarly to DBA, the KDBA algorithm averages a set of time series in the sample space but not along the time axis. Basically, let us suppose we are averaging two triangular-shaped time series such as represented by the blue crosses and black dots on Fig.5.1. When using DBA or KDBA algorithms with one of the two time series acting as the reference, then the calculated average would be the reference distribution itself. However, we would also expect to average the time shift between the two series, thus obtaining the distribution indicated by the red dots in Fig.fig:time-shift. This is precisely our main motivation for the deriving the following Pair Wise Averaging (KDTW-PWA) algorithm designed to average\n10\na pair of time series in the sample space but also along the time axis. Algorithm 3 provides the KDTW-PWA average (A) of the two time series X and Y according to Eq.14.\n\u2200k = 1 \u00b7 \u00b7 \u00b7L, A(k) = \u2211\ni,j| i+j 2 =k\n(\nP (i, j) \u00b7 X(i) + Y (j)\n2\n)\n= \u2211\ni,j| i+j 2 =k\n(\nP (i|j) + P (j|i) 2 \u00b7 X(i) + Y (j) 2\n) (14)\nAs the time indices are considered discrete (integer values), the time averaging (i+j)/2 is smoothed between the floor and cell integer values, using the smoothing coefficient \u03b1 (line 17 of the algorithm). Thus, the KDTW-PWA jointly averages the sample values of the two time series and their time locations. Eq. 14 allows us to interpret the centroid of a pair of time series as the mathematical expectation of aligning the two sequences of samples.\nAs an example, the centroid corresponding to the pairwise alignment of the sinus experiment depicted in\nFig 5 is presented in Fig 8. Notice that in the centroid, the negative halfwaves of the sine wave have been filtered. This is because the negative halfwaves do not match with the positive halfwave that is aligned with the sine wave. In Fig 7, we present a very simple experiment that consists of averaging two identical triangular-shaped time series (on left of figure) and two time series with identical triangular shapes but shifted in time. At the bottom of the figure, the corresponding AMA matrices are presented. The KDTW-PWA distributions, presented in red, are multiplied by a factor of two to facilitate reading of the figure. We can see that, for both situations, the centroid is precisely located at the correct averaged time of occurrence of the two time series, whether or not they are shifted in time. The most likely alignment areas on the AMA matrices are shown in in red and the less likely alignment areas in blue. The time shift is clearly visible on the right-hand figure."}, {"heading": "5.3 KDTW-Centroid of a set of time series based on KDTW-PWA", "text": "Algorithm 4 pKDTW-PWA\n1: procedure PKDTW-PWA(S, \u03bd) 2: //S: a set of time series ofD dimensional samples 3: //\u03bd: the stiffness parameter of KDTW kernel 4: Ts A; //a D dimensional time series 5: SetOfTimeSeries S0; 6: while |S| > 1 do 7: S0 = \u2205 8: while |S| > 1 do 9: Let ts1, ts2 the first two time series in S; 10: Evaluate the AMA matrix for ts1 and ts2 11: with \u03bd as the stiffness parameter 12: A = KDTW-PWA(ts1, ts2, AMA); 13: S0 = S0 \u222a {A}; 14: S = S \\ {ts1, ts2};\n15: S = S0 \u222a S; 16: Let A be the single element of S; 17: return A\nTo average a larger set of time series using the pairwise average KDTW-PWA, we simply adopt the progressive agglomerative approach presented in Fig.1a. This heuristic approach, detailed in Algorithm 4 has O(n) complexity, n being the size of the considered set of time series. The figures presented in Table 1 compare the centroid estimates provided by the iterated DBA, iKDBA and pKDTW-PWA algorithms. For the experiment, The DBA and iKDBA were iterated at most 20 times. Although the DBA and iKDBA estimates appear quite similar, the centroid estimates provided by the pKDTW-PWA algorithm is much smoother. This is a general property of the latter algorithm, which implements a time averaging principle based on the time expectation of sample occurrences,\n11\nthus somehow allowing it to filter noisy data. Note also that the DBA and iKDBA estimates for the CBF data set are close to the results provided by the preimage approach (Fig.3)."}, {"heading": "6 EXPERIMENTATION", "text": "The purpose of this experiment is to evaluate the effectiveness of the proposed time elastic averaging methods against a double baseline, namely k-medoid-based approaches and the DBA algorithm. The first baseline allow us to compare centroid-based with medoid-based approaches. The second baseline highlights the advantages we can expect from using p.d elastic kernels instead of indefinite kernels such as DTW in the context of time series averaging. DBA is also currently considered as a state of the art method to average a set of sequences consistently with DTW. For this purpose, we empirically evaluate the effectiveness of the methods using a first nearest\ncentroid/medoid (1-NC) classification task on a set of time series derived from widely diverse fields of application. The task consists of representing each category contained in a training data set by estimating its medoid or centroid and then evaluating the error rate of a 1-NC classifier on an independent testing data set. Hence, the classification rule consists of assigning to the tested time series the category which corresponds to the closest (or most similar) medoid or centroid according to DTW or KDTW measures.\nIn [25] a nice generalized k-NC task is described. The authors demonstrate that by selecting the appropriate number k of centroids (using DBA and k-means), they achieve, without loss, a 70% speed-up in average, compared to the original k-Near Neighbor task. Although, in general, the classification accuracies is improved when several centroids are used to represent the TRAIN datasets, our main purpose is to highlight and amplify the discrimination between time series averaging meth-\n12\nods: this is why stick here with the 1-NC task. DBA and iKDBA iterative centroid methods are iterated at most 20 times and yield local estimates of the centroid. The pKDTW-PWA progressive agglomerative centroid method is only processed once, and hence is roughly 20 times faster than iKDBA and about 10 times faster than DBA.\nA collection of 45 data sets is used to assess the proposed algorithms. The collection includes synthetic and real data sets, as well as univariate and multivariate time series. These data sets are distributed as follows:\n\u2022 42 of these data sets are available at the UCR repository [24]. Basically, we used all the data sets except for StarLightCurves, Non-Invasive Fetal ECG Thorax1 and Non-Invasive Fetal ECG Thorax2. Although these last three data sets are still tractable, their computational cost is high because of their size and the length of the time series they contain. All the data sets are composed of scalar time series. \u2022 One data set, uWaveGestureLibrary 3D was constructed from the uWaveGestureLibrary X\u2014Y\u2014Z scalar data sets to compose a new set of multivariate (3D) time series. \u2022 One data set, CharTrajTT, is available at the UCI Repository [26] under the name Character Trajectories Data Set. This data set contains multivariate (3D) time series and is divided into two equal sized data sets (TRAIN and TEST) for the experiment. \u2022 The last data set, PWM2, which stands for Pulse Width Modulation [27], was specifically defined to demonstrate a weakness in dynamic time warping (DTW) pseudo distance. This data set is composed of artificial scalar time series.\nFor each dataset, a training subset (TRAIN) is defined as well as an independent testing subset (TEST). We use the training sets to extract single medoids or centroid estimates for each of the categories defined in the data sets. Furthermore, for KDTWMedoid, iKDBA and pKDTWPWA, the \u03bd parameter is optimized using a leave-one-out (LOO) procedure carried out on the TRAIN data sets. The \u03bd value is selected within the discrete set {.05, .1, .25, .5, 1, 2, 5, 10, 25, 50, 100}. The value that minimizes the LOO classification error rate on the TRAIN data is then used to provide the error rates that are estimated on the TEST data.\nThe classification results are given in Table 2. It can be seen from this experiment, that\ni) Centroid-based methods outperform medoid-based methods: DBA yields lower error rates compared to DTWMedoid, as do iKDBA and pKDTW-PWA compared to KDTWMedoid.\nii) iKDBA outperforms DBA: under the same experimental conditions (maximum of 20 iterations), the\nkernalized version of the DTW measure leads to better classification accuracy. To some extent, this confirms previous results obtained for SVM classification [19] on such kinds of datasets. iii) pKDTW-PWA outperforms iKDBA: this results seems to show that joint averaging in the sample space and along the time axis improves the classification accuracy. As pKDTW-PWA provides a centroid estimation in a single agglomerative step, we can conjecture that this method converges faster toward a satisfactory centroid candidate.\nThe average ranking for all five tested methods, which supports our preliminary conclusion, is given at the bottom of Table 2.\nFollowing the study of [28] on statistical tests available to evaluate the significance of differences in error rate between classifiers over multiple data sets, we conducted a Friedman\u2019s significance test, a sort of non-parametric counterpart of the well-known ANOVA. This test ranks the algorithms for each data set separately, the best performing algorithm being given a rank of 1, the second best rank 2, etc. According to this test, the null hypothesis is rejected (with a P \u2212 value < 2.2e \u2212 16). Post-hoc tests can then be carried out to compare pairwise algorithms using the Wilcoxon-Nemenyi-McDonald-Thompson test [29]. For this purpose, we use the R code provided by [30] to generate the parallel coordinate plots and boxplots presented in Fig.9 as well as the results reported in Table 3.\nTable 3 reports the P-values for each pair of tested algorithms. This post-hoc analysis partially confirms our previous analysis of the classification results. If we consider that the null hypothesis is rejected when the P-value is less than 0.05, the post-hoc analysis shows that centroid-based approaches perform significantly better than medoid-based approaches. Furthermore, KDTWMedoid appears to be significantly better than DTWMedoid.\n13\nFurthermore, pKDTW-PWA is evaluated as significantly better than DBA but not significantly better than iKDBA in this experiment. Note also that DBA is not shown to perform significantly better than KDTWMedoid.\nThis post-hoc analysis is summarized in Fig.10 which shows the ranking graph for the five algorithms tested\n14\nin our experiments."}, {"heading": "7 CONCLUSION", "text": "In this paper, we address the reputedly difficult problem of averaging a set of time series in the context of a time elastic distance measure such as Dynamic Time Warping. The new perspective provided by the kernelization of the elastic distance firstly allows us to consider the averaging of time series as a preimage problem. This latter is unfortunately an ill-posed non-convex problem that could suffer from combinatorial number of local optima when dealing with long multidimensional time series. Furthermore, this kind of preimage problem can only be resolved using gradient-free optimization procedures that are computationally very costly (since extensive functional evaluation is required). However, this new kernelization approach allows a re-interpretation of pairwise kernel alignment matrices as distributions of probability over alignment paths. Based on this re-interpretation, we propose two distinct algorithms, iKDBA and pKDTW-PWA, based on iterative and progressive agglomerative heuristic methods,\nrespectively, that are developed to compute approximate solutions to the multi-alignment of time series. We present an extensive experiment carried out on synthetic and real data sets, mostly containing univariate but also some multivariate time series. Our results show that centroid-based methods significantly outperform medoid-based methods in the context of a first nearest neighbour classification task. Most strikingly, the pKDTW-PWA algorithm, which integrates joint averaging in the sample space and along the time axis, is significantly better than the state-of-the art DBA algorithm, with a potentially lower computational cost. Indeed, the simple one-pass progressive agglomerative heuristic procedure is used in the pKDTW-PWA algorithm can be further optimized."}, {"heading": "ACKNOWLEDGMENTS", "text": "The authors thank the French Ministry of Research, the Brittany Region, the General Council of Morbihan and the European Regional Development Fund that partially funded this research. The authors also thank the promoters of the UCR and UCI data repositories for providing the time series data sets used in this study."}], "references": [{"title": "Sur quelques points du calcul fonctionnel", "author": ["M. Fr\u00e9chet"], "venue": "Ed. The\u0300se, Faculte\u0301 des sciences de Paris.,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1906}, {"title": "Automatic recognition of 200 words", "author": ["V.M. Velichko", "N.G. Zagoruyko"], "venue": "International Journal of Man-Machine Studies, vol. 2, pp. 223\u2013234, 1970.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1970}, {"title": "A dynamic programming approach to continuous speech recognition", "author": ["H. Sakoe", "S. Chiba"], "venue": "Proceedings of the 7th International Congress of Acoustic, 1971, pp. 65\u201368.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1971}, {"title": "On the marriage of lp-norms and edit distance", "author": ["L. Chen", "R. Ng"], "venue": "Proceedings of the Thirtieth International Conference on Very Large Data Bases - Volume 30, ser. VLDB \u201904. VLDB Endowment, September 2004, pp. 792\u2013803.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2004}, {"title": "Time warp edit distance with stiffness adjustment for time series matching", "author": ["P.-F. Marteau"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 31, no. 2, pp. 306\u2013318, Feb 2009.  15", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "An introduction to biological sequence analysis", "author": ["S.S.L.K.H. Fasman"], "venue": "Computational Methods in Molecular Biology,. In Salzberg, S.L., Searls, D.B., and Kasif, S., eds., Elsevier, 1998, pp. 21\u201342.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1998}, {"title": "On the complexity of multiple sequence alignment.", "author": ["L. Wang", "T. Jiang"], "venue": "Journal of Computational Biology,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1994}, {"title": "Computational complexity of multiple sequence alignment with sp-score", "author": ["W. Just", "W. Just"], "venue": "Journal of Computational Biology, vol. 8, pp. 615\u2013623, 1999.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1999}, {"title": "The multiple sequence alignment problem in biology", "author": ["H. Carrillo", "D. Lipman"], "venue": "SIAM J. Appl. Math., vol. 48, no. 5, pp. 1073\u20131082, Oct. 1988. [Online]. Available: http://dx.doi.org/10.1137/0148063", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1988}, {"title": "Nonlinear alignment and averaging for estimating the evoked potential", "author": ["L. Gupta", "D. Molfese", "R. Tammana", "P. Simos"], "venue": "Biomedical Engineering, IEEE Transactions on, vol. 43, no. 4, pp. 348\u2013 356, April 1996.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1996}, {"title": "Shape averaging under time warping", "author": ["V. Niennattrakul", "C. Ratanamahatana"], "venue": "Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology, 2009. ECTI-CON 2009. 6th International Conference on, vol. 02, May 2009, pp. 626\u2013 629.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "Cross-words reference template for dtw-based speech recognition systems", "author": ["W. Abdulla", "D. Chow", "G. Sin"], "venue": "TENCON 2003. Conference on Convergent Technologies for the Asia-Pacific Region, vol. 4, Oct 2003, pp. 1576\u20131579 Vol.4.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2003}, {"title": "Time-series clustering by approximate prototypes", "author": ["V. Hautamaki", "P. Nykanen", "P. Franti"], "venue": "Pattern Recognition, 2008. ICPR 2008. 19th International Conference on, Dec 2008, pp. 1\u20134.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2008}, {"title": "A global averaging method for dynamic time warping, with applications to clustering", "author": ["F. Petitjean", "A. Ketterlin", "P. Gan\u00e7arski"], "venue": "Pattern Recogn., vol. 44, no. 3, pp. 678\u2013693, Mar. 2011. [Online]. Available: http://dx.doi.org/10.1016/j.patcog.2010.09.013", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Summarizing a set of time series by averaging: From Steiner sequence to compact multiple alignment", "author": ["F. Petitjean", "P. Gan\u00e7arski"], "venue": "Journal of theoretical computer science, vol. 414, no. 1, pp. 76\u201391, Jan. 2012.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Time series centroid estimation under weighted and kernel dynamic time warping", "author": ["S. Soheily-Khal", "A. Douzal-Chouakria", "E. Gaussier"], "venue": "Personal communication (under submission), 2014.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "Dynamic Time-Alignment Kernel in Support Vector Machine", "author": ["H. Shimodaira", "K.I. Noma", "M. Nakai", "S. Sagayama"], "venue": "Advances in Neural Information Processing Systems 14, T. G. Dietterich, S. Becker, and Z. Ghahramani, Eds. Cambridge, MA: MIT Press, 2002.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2002}, {"title": "Inaccuracies of shape averaging method using dynamic time warping for time series data", "author": ["V. Niennattrakul", "C. Ratanamahatana"], "venue": "Computational Science \u2013 ICCS 2007, ser. Lecture Notes in Computer Science, Y. Shi, G. van Albada, J. Dongarra, and P. Sloot, Eds. Springer Berlin Heidelberg, 2007, vol. 4487, pp. 513\u2013520. [Online]. Available: http://dx.doi.org/10.1007/978-3-540-72584-8 68", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2007}, {"title": "On Recursive Edit Distance Kernels with Application to Time Series Classification", "author": ["P.-F. Marteau", "S. Gibet"], "venue": "IEEE Trans. on Neural Networks and Learning Systems, pp. 1\u201314, Jun. 2014. [Online]. Available: http://hal.inria.fr/hal-00486916", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "A kernel for time series based on global alignments", "author": ["M. Cuturi", "J.-P. Vert", "O. Birkenes", "T. Matsui"], "venue": "IEEE ICASSP 2007, vol. 2, April 2007, pp. II\u2013413\u2013II\u2013416.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2007}, {"title": "Theory of reproducing kernels", "author": ["N. Aronszajn"], "venue": "Transactions of the American Mathematical Society, vol. 68, 1950.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1950}, {"title": "A generalized representer theorem", "author": ["B. Sch\u00f6lkopf", "R. Herbrich", "A.J. Smola"], "venue": "Proceedings of the 14th Annual Conference on Computational Learning Theory and and 5th European Conference on Computational Learning Theory, ser. COLT \u201901/EuroCOLT \u201901. London, UK, UK: Springer-Verlag, 2001, pp. 416\u2013426. [Online]. Available: http://dl.acm.org/citation.cfm?id=648300.755324", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2001}, {"title": "The bobyqa algorithm for bound constrained optimization without derivatives", "author": ["M.J.D. Powell"], "venue": "Aug. 2009.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2009}, {"title": "The UCR time series classification-clustering datasets", "author": ["E.J. Keogh", "X. Xi", "L. Wei", "C. Ratanamahatana"], "venue": "2006, http://wwwcs.ucr.edu/ eamonn/time series data/.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2006}, {"title": "Dynamic time warping averaging of time series allows faster and more accurate classification", "author": ["F. Petitjean", "G. Forestier", "G. Webb", "A. Nicholson", "Y. Chen", "E. Keogh"], "venue": "Proceedings of the 14th IEEE International Conference on Data Mining, 2014, pp. 470\u2013479. [Online]. Available: http://dx.doi.org/10.1109/ICDM.2014.27", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2014}, {"title": "Uci machine learning repository", "author": ["M. Lichman"], "venue": "2013. [Online]. Available: http://archive.ics.uci.edu/ml", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2013}, {"title": "Pulse width modulation data sets", "author": ["P.-F. Marteau"], "venue": "2007. [Online]. Available: http://people.irisa.fr/Pierre-Francois.Marteau/PWM/", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2007}, {"title": "Statistical comparisons of classifiers over multiple data sets", "author": ["J. Dem\u0161ar"], "venue": "J. Mach. Learn. Res., vol. 7, pp. 1\u201330, Dec. 2006. [Online]. Available: http://dl.acm.org/citation.cfm?id=1248547.1248548", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2006}, {"title": "Nonparametric Statistical Methods, ser", "author": ["M. Hollander", "D. Wolfe"], "venue": "Wiley Series in Probability and Statistics. Wiley,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1999}, {"title": "R code for the friedman test post hoc analysis.", "author": ["T. Galili"], "venue": "february", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "Since Maurice Fr\u00e9chet\u2019s pioneering work [1] in the early 1900s, time-elastic matching of time series or symbolic sequences has attracted much attention from the scientific community in numerous fields such as information indexing and retrieval, pattern analysis, extraction and recognition, data mining, etc.", "startOffset": 40, "endOffset": 43}, {"referenceID": 1, "context": "Among other time elastic measures, Dynamic Time Warping (DTW) was widely popularized during the 1970s with the advent of speech recognition systems [2], [3] and numerous variants that have since been proposed to match time series with a certain degree of time distortion tolerance.", "startOffset": 148, "endOffset": 151}, {"referenceID": 2, "context": "Among other time elastic measures, Dynamic Time Warping (DTW) was widely popularized during the 1970s with the advent of speech recognition systems [2], [3] and numerous variants that have since been proposed to match time series with a certain degree of time distortion tolerance.", "startOffset": 153, "endOffset": 156}, {"referenceID": 1, "context": "Time series averaging in the context of (multiple) time elastic distance alignments has been mainly addressed in the scope of the Dynamic Time Warping (DTW) measure [2], [3].", "startOffset": 165, "endOffset": 168}, {"referenceID": 2, "context": "Time series averaging in the context of (multiple) time elastic distance alignments has been mainly addressed in the scope of the Dynamic Time Warping (DTW) measure [2], [3].", "startOffset": 170, "endOffset": 173}, {"referenceID": 3, "context": "Although other time elastic distance measures such as the Edit Distance With Real Penalty (ERP) [4] or the Time Warp Edit Distance (TWED) [5] could be considered instead, without loss of generality, we remain focused throughout this paper on DTW and its kernelization.", "startOffset": 96, "endOffset": 99}, {"referenceID": 4, "context": "Although other time elastic distance measures such as the Edit Distance With Real Penalty (ERP) [4] or the Time Warp Edit Distance (TWED) [5] could be considered instead, without loss of generality, we remain focused throughout this paper on DTW and its kernelization.", "startOffset": 138, "endOffset": 141}, {"referenceID": 5, "context": "Multiple alignments have been widely studied in bioinformatics [6], and it has been shown that the computational complexity of determining the optimal alignment of a set of sequences under the sum of all pairs (SP) score scheme is a NP-complete problem [7] [8].", "startOffset": 63, "endOffset": 66}, {"referenceID": 6, "context": "Multiple alignments have been widely studied in bioinformatics [6], and it has been shown that the computational complexity of determining the optimal alignment of a set of sequences under the sum of all pairs (SP) score scheme is a NP-complete problem [7] [8].", "startOffset": 253, "endOffset": 256}, {"referenceID": 7, "context": "Multiple alignments have been widely studied in bioinformatics [6], and it has been shown that the computational complexity of determining the optimal alignment of a set of sequences under the sum of all pairs (SP) score scheme is a NP-complete problem [7] [8].", "startOffset": 257, "endOffset": 260}, {"referenceID": 8, "context": "The time and space complexity of this problem is O(L), where k is the number of sequences in the set and L is the length of the sequences when using dynamic programming to search for an optimal solution [9].", "startOffset": 203, "endOffset": 206}, {"referenceID": 9, "context": "One popular approach consists of providing a random order for the leaves, and then constructing the binary tree up to the root using this ordering [10].", "startOffset": 147, "endOffset": 151}, {"referenceID": 10, "context": "Another approach involves constructing a dendrogram (a hierarchical ascendant clustering) from the data set and then using this dendrogram to calculate pairwise centroids starting with the closest pairs of time series and progressively aggregating series that are farther away [11] as illustrated on the left of Fig.", "startOffset": 277, "endOffset": 281}, {"referenceID": 11, "context": "The three steps of this heuristic method were first proposed in [12].", "startOffset": 64, "endOffset": 68}, {"referenceID": 12, "context": "The iterative aspect of this heuristic approach was initially introduced by [13] and refined by [14].", "startOffset": 76, "endOffset": 80}, {"referenceID": 13, "context": "The iterative aspect of this heuristic approach was initially introduced by [13] and refined by [14].", "startOffset": 96, "endOffset": 100}, {"referenceID": 14, "context": "[15] have evaluated a genetic algorithm for managing a population of centroid candidates, thus improving with some success the straightforward iterative heuristic methods.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "To our knowledge, the first attempt to use this kind of direct approach for the estimation of time elastic centroid estimation was recently described in [16].", "startOffset": 153, "endOffset": 157}, {"referenceID": 16, "context": "Two time elastic measures were specifically addressed: i) a dynamic time warping measure between a time series and a weighted time series (representing the centroid estimate) and ii) an (indefinite) kernel DTW called DTAK [17].", "startOffset": 222, "endOffset": 226}, {"referenceID": 17, "context": "It should also be mentioned that some criticisms of these heuristic methods have been made in [18].", "startOffset": 94, "endOffset": 98}, {"referenceID": 18, "context": "In this study, we do not directly address the issue of time elastic centroid estimation from the DTW perspective, but rather from the point of view of the regularized dynamic time warping kernel (KDTW) [19].", "startOffset": 202, "endOffset": 206}, {"referenceID": 1, "context": "Dynamic Time Warping (DTW), [2], [3] as defined in Eq.", "startOffset": 28, "endOffset": 31}, {"referenceID": 2, "context": "Dynamic Time Warping (DTW), [2], [3] as defined in Eq.", "startOffset": 33, "endOffset": 36}, {"referenceID": 19, "context": "Regularized DTW: recent studies [20], [19] lead us to propose new guidelines to ensure that kernels constructed from elastic measures such as DTW are positive definite.", "startOffset": 32, "endOffset": 36}, {"referenceID": 18, "context": "Regularized DTW: recent studies [20], [19] lead us to propose new guidelines to ensure that kernels constructed from elastic measures such as DTW are positive definite.", "startOffset": 38, "endOffset": 42}, {"referenceID": 18, "context": "A simple instance of such a regularized kernel, derived from [19], can be expressed in the following form, which makes use of two recursive terms:", "startOffset": 61, "endOffset": 65}, {"referenceID": 20, "context": "The Moore-Aronszajn theorem [21] establishes that a reproducing kernel Hilbert space (RKHS) exists uniquely for every positive definite kernel and vice-versa.", "startOffset": 28, "endOffset": 32}, {"referenceID": 21, "context": "Finally, the representer theorem [22] states that any function \u03c6(.", "startOffset": 33, "endOffset": 37}, {"referenceID": 22, "context": "In an attempt to carry out such a preimage formulation to estimate the time elastic centroid for a set of time series, we applied the state-of-the-art BOBYQA algorithm developed for bound constrained optimization without using derivatives [23].", "startOffset": 239, "endOffset": 243}, {"referenceID": 23, "context": "4 give the centroid estimations for each category of the CBF and Trace datasets, respectively [24].", "startOffset": 94, "endOffset": 98}, {"referenceID": 11, "context": "Based on the structure of the KDTW kernel and the AMA matrix, and by using the so-called DtwBarycenter Averaging (DBA) method developed by [12], [14], [13], we first present the KernelDtwNarycenter Averaging (KDBA) algorithm for estimating a time elastic centroid for a set of time series according to an iterative agglomerative procedure as shown in Fig.", "startOffset": 139, "endOffset": 143}, {"referenceID": 13, "context": "Based on the structure of the KDTW kernel and the AMA matrix, and by using the so-called DtwBarycenter Averaging (DBA) method developed by [12], [14], [13], we first present the KernelDtwNarycenter Averaging (KDBA) algorithm for estimating a time elastic centroid for a set of time series according to an iterative agglomerative procedure as shown in Fig.", "startOffset": 145, "endOffset": 149}, {"referenceID": 12, "context": "Based on the structure of the KDTW kernel and the AMA matrix, and by using the so-called DtwBarycenter Averaging (DBA) method developed by [12], [14], [13], we first present the KernelDtwNarycenter Averaging (KDBA) algorithm for estimating a time elastic centroid for a set of time series according to an iterative agglomerative procedure as shown in Fig.", "startOffset": 151, "endOffset": 155}, {"referenceID": 11, "context": "Following the DBA algorithmic approach [12], [13], we present here the development of our kernelized version called KDBA.", "startOffset": 39, "endOffset": 43}, {"referenceID": 12, "context": "Following the DBA algorithmic approach [12], [13], we present here the development of our kernelized version called KDBA.", "startOffset": 45, "endOffset": 49}, {"referenceID": 13, "context": "The algorithm 1 can be refined by iterating until no further improvement is obtained [14].", "startOffset": 85, "endOffset": 89}, {"referenceID": 24, "context": "In [25] a nice generalized k-NC task is described.", "startOffset": 3, "endOffset": 7}, {"referenceID": 23, "context": "\u2022 42 of these data sets are available at the UCR repository [24].", "startOffset": 60, "endOffset": 64}, {"referenceID": 25, "context": "\u2022 One data set, CharTrajTT, is available at the UCI Repository [26] under the name Character Trajectories Data Set.", "startOffset": 63, "endOffset": 67}, {"referenceID": 26, "context": "\u2022 The last data set, PWM2, which stands for Pulse Width Modulation [27], was specifically defined to demonstrate a weakness in dynamic time warping (DTW) pseudo distance.", "startOffset": 67, "endOffset": 71}, {"referenceID": 18, "context": "To some extent, this confirms previous results obtained for SVM classification [19] on such kinds of datasets.", "startOffset": 79, "endOffset": 83}, {"referenceID": 27, "context": "Following the study of [28] on statistical tests available to evaluate the significance of differences in error rate between classifiers over multiple data sets, we conducted a Friedman\u2019s significance test, a sort of non-parametric counterpart of the well-known ANOVA.", "startOffset": 23, "endOffset": 27}, {"referenceID": 28, "context": "Post-hoc tests can then be carried out to compare pairwise algorithms using the Wilcoxon-Nemenyi-McDonald-Thompson test [29].", "startOffset": 120, "endOffset": 124}, {"referenceID": 29, "context": "For this purpose, we use the R code provided by [30] to generate the parallel coordinate plots and boxplots presented in Fig.", "startOffset": 48, "endOffset": 52}], "year": 2015, "abstractText": "In the light of regularized dynamic time warping kernels, this paper re-considers the concept of time elastic centroid (TEC) for a set of time series. From this perspective, we show that TEC can be readily addressed as a preimage problem. However, this non-convex problem is ill-posed, and obtaining a sub-optimal solution may involve heavy computational costs, especially for long time series. We then derive two new algorithms based on a probabilistic interpretation of kernel alignment matrices that expresses the result in terms of probabilistic distributions over sets of alignment paths. The first algorithm is an agglomerative iterative heuristic procedure inspired from a state-of-the-art DTW barycentre averaging algorithm. The second proposed algorithm uses a progressive agglomerative heuristic method to perform classical averaging of the aligned samples but also averages the times of occurrence of the aligned samples. By comparing classification accuracies for 45 time series datasets obtained by first nearest centroid/medoid classifiers we show that: i) centroid-based approaches significantly outperform medoid-based approaches, ii) for the considered datasets, the second algorithm which combines averaging in the sample space and along the time axes, emerges as the most significantly robust heuristic model for time-elastic averaging with a promising noise reduction capability.", "creator": "LaTeX with hyperref package"}}}