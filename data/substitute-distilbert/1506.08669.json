{"id": "1506.08669", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Jun-2015", "title": "Efficient and Parsimonious Agnostic Active Learning", "abstract": "we develop in new active learning algorithm for the streaming setting satisfying three important properties : this ) it provably works for easy classifier representation and classification problem assisting those with severe faults. 2 ) it was efficiently implementable with an erm oracle. 3 ) it is weakly aggressive than all previous models satisfying 1 and 2. to do this we create an algorithm based on it newly emerged optimization problem and analyze it., also conduct the first experimental analysis of all efficient agnostic active learning algorithms, discovering that this one is typically better across a wide variety of datasets and label complexities.", "histories": [["v1", "Mon, 29 Jun 2015 15:02:55 GMT  (149kb,D)", "http://arxiv.org/abs/1506.08669v1", null], ["v2", "Wed, 6 Jan 2016 02:49:21 GMT  (441kb,D)", "http://arxiv.org/abs/1506.08669v2", null], ["v3", "Thu, 7 Jan 2016 18:27:33 GMT  (477kb,D)", "http://arxiv.org/abs/1506.08669v3", null]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["tzu-kuo huang", "alekh agarwal", "daniel j hsu", "john langford", "robert e schapire"], "accepted": true, "id": "1506.08669"}, "pdf": {"name": "1506.08669.pdf", "metadata": {"source": "CRF", "title": "Efficient and Parsimonious Agnostic Active Learning", "authors": ["Tzu-Kuo Huang", "Alekh Agarwal", "Daniel J. Hsu", "John Langford", "Robert E. Schapire"], "emails": ["tkhuang@microsoft.com", "alekha@microsoft.com", "djhsu@cs.columbia.edu", "jcl@microsoft.com", "schapire@microsoft.com"], "sections": [{"heading": "1 Introduction", "text": "How can you best learn a classifier given a label budget?\nActive learning approaches are known to yield exponential improvements over supervised learning under strong assumptions [Cohn et al., 1994]. Under much weaker assumptions, streaming-based agnostic active learning [Balcan et al., 2006, Beygelzimer et al., 2009, 2010, Dasgupta et al., 2007, Zhang and Chaudhuri, 2014] is particularly appealing since it is known to work for any classifier representation and any label noise distribution with an i.i.d. data source.1 Here, a learning algorithm decides for each unlabeled example in sequence whether or not to request a label, never revisiting this decision. Restated then: What is the best possible active learning algorithm which works for any classifier representation, any label noise distribution, and is computationally tractable?\nComputational tractability is a critical concern, because most known algorithms for this setting [e.g., Balcan et al., 2006, Koltchinskii, 2010, Zhang and Chaudhuri, 2014] require explicit enumeration of classifiers, implying exponentially-worse computational complexity compared to typical supervised learning algorithms. Active learning algorithms based on empirical risk minimization (ERM) oracles [Beygelzimer et al., 2009, 2010, Hsu, 2010] can overcome this intractability by using passive classification algorithms as the oracle to achieve a computationally acceptable solution.\nAchieving generality, robustness, and acceptable computation has a cost. For the above methods [Beygelzimer et al., 2009, 2010, Hsu, 2010], a label is requested on nearly every unlabeled example where two empirically good classifiers disagree. This results in a poor label complexity, well short of information-theoretic limits [Castro and Nowak, 2008] even for general robust solutions [Zhang and Chaudhuri, 2014]. Until now.\nIn Section 3, we design a new algorithm ACTIVE COVER (AC) for constructing query probability functions that minimize the probability of querying inside the disagreement region\u2014the set of points where good classifiers disagree\u2014and never query otherwise. This requires a new algorithm that maintains a parsimonious cover of the set of empirically good classifiers. The cover is a result of solving an optimization problem (in Section 5) specifying the properties of a desirable query probability function. The cover size provides a practical knob between computation and label complexity, as demonstrated by the complexity analysis we present in Section 5.\nIn Section 4, we provider our main results which demonstrate that AC effectively maintains a set of good classifiers, achieves good generalization error, and has a label complexity bound tighter than previous approaches. The label complexity bound depends on the disagreement coefficient [Hanneke, 2009], which does not completely capture the advantage of the algorithm. In Appendix 4.2.2, we provide an example of a hard active learning problem where AC is\n1See the monograph of Hanneke [2014] for an overview of the existing literature, including alternative settings where additional assumptions are placed on the data source (e.g., separability) as is common in other works [Dasgupta, 2005, Balcan et al., 2007, Balcan and Long, 2013].\nar X\niv :1\n50 6.\n08 66\n9v 1\n[ cs\n.L G\n] 2\n9 Ju\nn 20\n15\nsubstantially superior to previous tractable approaches. Together, these results show that AC is better and sometimes substantially better in theory. The key aspects in the proof of our generalization results are presented in Section 7, with more technical details and label complexity analysis presented in the appendix.\nDo agnostic active learning algorithms work in practice? No previous works have addressed this question empirically. Doing so is important because analysis cannot reveal the degree to which existing classification algorithms effectively provide an ERM oracle. We conduct an extensive study in Section 6 by simulating the interaction of the active learning algorithm with a streaming supervised dataset. The results show that an online variant of AC (called OAC) is typically superior across a wide array of datasets. A summary of our results is presented in Figure 1 which shows the fraction of datasets where an algorithm has a better test error than a random sub-sampling at different query rates across 23 datasets, with details in Section 6 and Appendix G."}, {"heading": "2 Preliminaries", "text": "Let H \u2286 {\u00b11}X be a set of binary classifiers, which we assume is finite for simplicity.2 Let EX [\u00b7] denote expectation with respect to X \u223c PX , the marginal of P over X . The error of a classifier h \u2208 H is err(h) := Pr(X,Y )\u223cP(h(X) 6= Y ), and the error minimizer is denoted by h\u2217 := arg minh\u2208H err(h). The (importance weighted) empirical error of h \u2208 H on a multiset S of importance weighted and labeled examples drawn from X \u00d7 {\u00b11}\u00d7R+ is err(h, S) := \u2211 (x,y,w)\u2208S w \u00b7 1(h(x) 6= y)/|S|. The disagreement region for a subset of classifiers A \u2286 H is DIS(A) := {x \u2208 X | \u2203h, h\u2032 \u2208 A such that h(x) 6= h\u2032(x)}. The regret of a classifier h \u2208 H relative to another h\u2032 \u2208 H is reg(h, h\u2032) := err(h)\u2212 err(h\u2032), and the analogous empirical regret on S is reg(h, h\u2032, S) := err(h, S)\u2212 err(h\u2032, S). When the second classifier h\u2032 in (empirical) regret is omitted, it is taken to be the (empirical) error minimizer inH.\nA streaming-based active learner receives i.i.d. labeled examples (X1, Y1), (X2, Y2), . . . from P one at a time; each label Yi is hidden unless the learner decides on the spot to query it. The goal is to produce a classifier h \u2208 H with low error err(h), while querying as few labels as possible.\nIn the IWAL framework [Beygelzimer et al., 2009], a decision whether or not to query a label is made randomly: the learner picks a probability p \u2208 [0, 1], and queries the label with that probability. Whenever p > 0, an unbiased error estimate can be produced using inverse probability weighting [Horvitz and Thompson, 1952]. Specifically, for any classifier h, an unbiased estimator E of err(h) based on (X,Y ) \u223c P and p is as follows: if Y is queried, then E = 1(h(X) 6= Y )/p; else, E = 0. It is easy to check that E(E) = err(h). Thus, when the label is queried, we\n2The assumption that H is finite can be relaxed to VC-classes using standard arguments.\nAlgorithm 1 ACTIVE COVER (AC) input: Constants c1, c2, c3, confidence \u03b4, error radius \u03b3, parameters \u03b1, \u03b2, \u03be for (OP), epoch schedule 0 = \u03c40 < 3 =\n\u03c41 < \u03c42 < \u03c43 < . . . < \u03c4M satisfying \u03c4m+1 \u2264 2\u03c4m for m \u2265 1. initialize: epoch m = 0, Z\u03030 := \u2205, \u22060 := c1 \u221a 1 + c2 1 log 3, where\nm := 32(log(|H|/\u03b4) + log \u03c4m)\n\u03c4m .\n1: for i = 4, . . . , n, do 2: if i = \u03c4m + 1 then 3: Set Z\u0303m = Z\u0303m\u22121 \u222a S, and S = \u2205. 4: Let\nhm+1 := arg min h\u2208H err(h, Z\u0303m), (1)\n\u2206m := c1 \u221a merr(hm+1, Z\u0303m) + c2 m log \u03c4m, (2)\nAm+1 := {h | err(h, Z\u0303m)\u2212 err(hm+1, Z\u0303m) \u2264 \u03b3\u2206m}. (3)\n5: Compute the solution Pm+1(\u00b7) to the optimization problem (5). 6: m := m+ 1. 7: end if 8: Receive unlabeled data point Xi. 9: if Xi \u2208 Dm := DIS(Am), then\n10: Draw Qi \u223c Bernoulli(Pm(Xi)). 11: Update the set of examples:4\nS := { S \u222a {(Xi, Yi, 1/Pm(Xi))}, Qi = 1 S \u222a {Xi, 1, 0}, otherwise.\n12: else S := S \u222a {(Xi, hm(Xi), 1)}. 13: 14: end if 15: end for 16: hM+1 := arg minh\u2208H err(h, Z\u0303M ).\nproduce the importance weighted labeled example (X,Y, 1/p).3"}, {"heading": "3 Algorithm", "text": "Our new algorithm, shown as Algorithm 1, breaks the example stream into epochs. The algorithm admits any epoch schedule so long as the epoch lengths satisfy \u03c4m\u22121 \u2264 2\u03c4m. For technical reasons, we always query the first 3 labels to kick-start the algorithm.At the start of epoch m, AC computes a query probability function Pm : X \u2192 [0, 1] which will be used for sampling the data points to query during the epoch. This is done by maintaining a few objects\n3If the label is not queried, we produce an ignored example of weight zero; its only purpose is to maintain the correct count of querying opportunities. This ensures that 1/|S| is the correct normalization in err(h, S).\n4See Footnote 3. Adding an example of importance weight zero simply increments |S| without updating other state of the algorithm, hence the label used does not matter.\nof interest during each epoch:\n1. In step 1, we compute the best classifier on the sample Z\u0303m that we have collected so far. Note that the sample consists of the queried, true labels on some examples, while predicted labels for the others.\n2. A radius \u2206m is computed in step 2 based on the desired level of concentration we want the various empirical quantities to satisfy.\n3. The set Am in step 3 consists of all the hypotheses which are good according to our sample Z\u0303m, with the notion of good being measured as empirical regret being at most \u2206m.\nWithin the epoch, Pm determines the probability of querying an example in the disagreement region for this set Am of \u201cgood\u201d classifiers; examples outside this region are not queried but given labels predicted by hm. Consequently, the sample is not unbiased unlike some of the predecessors of our work. The various constants in Algorithm 1 must satisfy:\n\u03b1 \u2265 1, \u03b7 \u2265 864, \u03be \u2264 1 8n M log n , \u03b22 \u2264 \u03b7 864\u03b3n M log n , \u03b3 \u2265 \u03b7/4,\nc1 \u2265 2\u03b1 \u221a 6, c2 \u2265 \u03b7c21/4, c3 \u2265 1. (4)\nEpoch Schedules: The algorithm as stated takes an arbitrary epoch schedule subject to \u03c4m < \u03c4m+1 \u2264 2\u03c4m. Two natural extremes are unit-length epochs, \u03c4m = m, and doubling epochs, \u03c4m+1 = 2\u03c4m. The main difference comes in the number of times (OP) is solved, which is a substantial computational consideration. Unless otherwise stated, we assume the doubling epoch schedule so that the query distribution and ERM classifier are recomputed only O(log n) times.\nOptimization problem (OP) to obtain Pm: AC computes Pm as the solution to the optimization problem (OP). In essence, the problem encodes the properties of a query probability function that are essential to ensure good generalization, while maintaining a low label complexity. As we will discuss later, some of the previous works can be seen as specific ways of construction feasible solutions to this optimization problem. The objective function of (OP) encourages small query probabilities in order to minimize the label complexity. It might appear odd that we do not use the more obvious choice for objective which would be EX [P (X)], however our choice simultaneously encourages low query probabilities and also provides a barrier for the constraint P (X) \u2264 1\u2013an important algorithmic aspect as we will discuss in Section F.\nThe constraints (5) in (OP) bound the variance in our importance-weighted regret estimates for every h \u2208 H. This is key to ensuring good generalization as we will later use Bernstein-style bounds which rely on our random variables having a small variance. Let us examine these constraints in more detail. The LHS of the constraints measures the variance in our empirical regret estimates for h, measured only on the examples in the disagreement region Dm. This is because the importance weights in the form of 1/Pm(X) are only applied to these examples; outside this region we use the predicted labels with an importance weight of 1. The RHS of the constraint consists of three terms. The first term ensures the feasibility of the problem, as P (X) \u2261 1/(2\u03b12) for X \u2208 Dm will always satisfy the constraints. The second empirical regret term makes the constraints easy to satisfy for bad hypotheses\u2013this is crucial to rule out large label complexities in case there are bad hypotheses that disagree very often with hm. A benefit of this is easily seen when \u2212hm \u2208 H, which might have a terrible regret, but would force a near-constant query probability on the disagreement region if \u03b2 = 0. Finally, the third term will be on the same order as the second one for hypotheses in Am, and is only included to capture the allowed level of slack in our constraints which will be exploited for the efficient implementation in Section 5.\nOf course, variance alone is not adequate to ensure concentration, and we also require the random variables of interest to be appropriately bounded. This is ensured through the constraints (6), which impose a minimum query probability on the disagreement region. Outside the disagreement region, we use the predicted label with an importance weight of 1, so that our estimates will always be bounded (albeit biased) in this region. Note that this optimization\nOptimization Problem (OP) to compute Pm\nmin P\nEX [\n1\n1\u2212 P (X) ] s.t. \u2200h \u2208 H EX [ 1(h(x) 6= hm(x) \u2227 x \u2208 Dm)\nP (X)\n] \u2264 bm(h), (5)\n\u2200x \u2208 X 0 \u2264 P (x) \u2264 1, and \u2200x \u2208 Dm P (x) \u2265 Pmin,m (6)\nwhere bm(h) = 2\u03b12EX [Imh (X)] + 2\u03b22\u03b3reg(h, hm, Z\u0303m\u22121)\u03c4m\u22121\u2206m\u22121 + \u03be\u03c4m\u22121\u22062m\u22121, and\nPmin,m = min  c3\u221a \u03c4m\u22121err(hm,Z\u0303m\u22121)\nn M + log \u03c4m\u22121\n, 1\n2\n . (7)\nproblem is written with respect to the marginal distribution of the data points PX , meaning that we might have infinite number of the latter constraints. In Section 5, we describe how to solve this optimization problem efficiently, and using access to only unlabeled examples drawn from PX .\nFinally we verify that the choices for Pm according to some of the previous methods are indeed feasible in (OP). This is most easily seen for Oracular CAL [Hsu, 2010] which queries with probability 1 if X \u2208 Dm and 0 otherwise. Since \u03b1 \u2265 1 (4) in the variance constraints (5), the choice P (X) \u2261 1 for X \u2208 Dm is feasible for (OP), and consequently Oracular CAL always queries more often than the optimal distribution Pm at each epoch. A similar argument can also be made for the IWAL method [Beygelzimer et al., 2010], which also queries in the disagreement region with probability 1, and hence suffers from the same suboptimality compared to our choice."}, {"heading": "4 Generalization and Label Complexity", "text": "We now present guarantees on the generalization error and label complexity of Algorithm 1 assuming a solver for (OP), which we provide in the next section."}, {"heading": "4.1 Generalization guarantees", "text": "Our first theorem provides a bound on generalization error. Define\nerrm(h) := 1\n\u03c4m m\u2211 j=1 (\u03c4j \u2212 \u03c4j\u22121)E(X,Y )\u223cP[1(h(X) 6= Y \u2227X \u2208 Dj)],\n\u2206\u22170 := \u22060 and \u2206 \u2217 m := c1 \u221a merrm(h\u2217) + c2 m log \u03c4m for m \u2265 1.\nEssentially \u2206\u2217m is a population counterpart of the quantity \u2206m used in Algorithm 1, and crucially relies on errm(h \u2217), the true error of h\u2217 restricted to the disagreement region instead of the empirical error of the ERM at epoch m. This quantity captures the inherent noisiness of the problem, and modulates the transition between O(1/ \u221a n) to O(1/n) type error bounds as we see next. Theorem 1. Pick any 0 < \u03b4 < 1/e such that |H|/\u03b4 > \u221a\n192. Then recalling that h\u2217 = arg minh\u2208H err(h), we have for all epochs m = 1, 2, . . . ,M , with probability at least 1\u2212 \u03b4\nreg(h, h\u2217) \u2264 16\u03b3\u2206\u2217m for all h \u2208 Am+1, and (8) reg(h\u2217, hm+1, Z\u0303m) \u2264 \u03b7\u2206m/4. (9)\nThe theorem is proved in Section 7.2.2, using the overall analysis framework described in Section 7. Since we use \u03b3 \u2265 \u03b7/4, the bound (9) implies that h\u2217 \u2208 Am for all epochs m. This also maintains that all the predicted labels used by our algorithm are identical to those of h\u2217, since no disagreement amongst classifiers in Am was observed on those examples. This observation will be critical to our proofs, where we will exploit the fact that using labels predicted by h\u2217 instead of observed labels on certain examples only introduces a bias in favor of h\u2217, thereby ensuring that we never mistakenly drop the optimal classifier from our version space Am.\nThe bound (8) shows that every hypothesis in Am+1 has a small regret to h\u2217. Since the ERM classifier hm+1 is always in Am+1, this yields our main generalization error bound on the classifier h\u03c4m+1 output by Algorithm 1. Additionally, it also clarifies the definition of the setsAm as the set of good classifiers: these are classifiers which have small population regret relative to h\u2217 indeed. In the worst case, if errm(h\u2217) is a constant, then the overall regret bound is O(1/ \u221a n). The actual rates implied by the theorem, however depend on the properties of the distribution and below we illustrate this with two corollaries. We start with a simple specialization to the realizable setting.\nCorollary 1. Under the conditions of Theorem 1, suppose further that err(h\u2217) = 0. Then \u2206m = \u2206\u2217m = c2\u03c4m log \u03c4m and hence reg(h, h\u2217) \u2264 16c2\u03c4m log \u03c4m for all hypotheses h \u2208 Am+1.\nIn words, the corollary demonstrates a O\u0303(1/n) rate after seeing n unlabeled examples in the realizable setting. Of course the use of errm(h\u2217) in defining \u2206\u2217m allows us to retain the fast rates even when h\n\u2217 makes some errors but they do not fall in the disagreement region of good classifiers. One intuitive condition that controls the errors within the disagreement region is the low-noise condition of Tsybakov [2004], which asserts that there exist constants \u03b6 > 0 and 0 < \u03c9 \u2264 1 such that\nPr(h(X) 6= h\u2217(X)) \u2264 \u03b6 \u00b7 (err(h)\u2212 err(h\u2217))\u03c9, \u2200h \u2208 H such that err(h)\u2212 err(h\u2217) \u2264 \u03b50. (10)\nUnder this assumption, the extreme \u03c9 = 0 corresponds to the worst-case setting while \u03c9 = 1 corresponds to h\u2217 having a zero error on disagreement set of the classifiers with regret at most \u03b50. Under this assumption, we get the following corollary of Theorem 1.\nCorollary 2. Under conditions of Theorem 1, suppose further that Tsybakov\u2019s low-noise condition (10) is satisfied with some parameters \u03b6, \u03c9, and \u03b50 = 1. Then after m epochs, we have reg(h, h\u2217) = O\u0303 ( \u03c4 \u2212 12\u2212\u03c9 m log(|H|/\u03b4) ) .\nThe proof of this result is deferred to Appendix E. It is worth noting that the rates obtained here are known to be unimprovable for even passive learning under the Tsybakov noise condition Castro and Nowak [2008].5 Consequently, there is no loss of statistical efficiency in using our active learning approach. The result is easily extended for other values of \u03b50 by using the worst-case bound until the first epoch m0 when 16\u03b3\u2206\u2217m0 drops below \u03b50 and then apply our analysis above from m0 onwards. We leave this development to the reader."}, {"heading": "4.2 Label complexity", "text": "Generalization alone does not convey the entire quality of an active learning algorithm, since a trivial algorithm queries always with probability 1, thereby matching the generalization guarantees of passive learning. In this section, we show that our algorithm can achieve the aforementioned generalization guarantees, despite having a small label complexity in favorable situations. We begin with a worst-case result in the agnostic setting, and then describe a specific example which demonstrates some key differences of our approach from its predecessors."}, {"heading": "4.2.1 Disagreement-based label complexity bounds", "text": "In order to quantify the extent of gains over passive learning, we measure the hardness of our problem using the disagreement coefficient [Hanneke, 2014], which is defined as\n5\u03c9 in our statement of the low-noise condition (10) corresponds to 1/\u03ba in the results of Castro and Nowak [2008].\n\u03b8 = \u03b8(h\u2217) := sup r>0 PX {x | \u2203h \u2208 H s.t.h\u2217(x) 6= h(x), PX {x\u2032 | h(x\u2032) 6= h\u2217(x\u2032)} \u2264 r} r . (11)\nIntuitively, given a set of classifiers H and a data distribution P, an active learning problem is easy if good classifiers disagree on only a small fraction of the examples, so that the active learning algorithm can increasingly restrict attention only to this set. With this definition, we have the following result for the label complexity of Algorithm 1.\nTheorem 2. Under conditions of Theorem 1, with probability at least 1 \u2212 \u03b4, the expected number6 of label queries made by Algorithm 1 after n examples over M epochs is at most\n2\u03b8errM (h \u2217)n+ \u03b8 \u00b7 O\u0303( \u221a nerrM (h\u2217) log(|H|/\u03b4) + log(|H|/\u03b4)).\nThe proof is in Appendix D. The dominant first term of the label complexity bound is linear in the number of unlabeled examples, but can be quite small if \u03b8 is small, or if errM (h\u2217) \u2248 0\u2014it is indeed 0 in the realizable setting. We illustrate this aspect of the theorem with a corollary for the realizable setting.\nCorollary 3. Under the conditions of Theorem 2, suppose further that err(h\u2217) = 0. Then the expected number of label queries made by Algorithm 1 is at most \u03b8O\u0303(log(|H|/\u03b4)).\nIn words, we attain a logarithmic label complexity in the realizable setting. We contrast this with the label complexity of IWAL [Beygelzimer et al., 2010], which grows as \u03b8 \u221a n independent of err(h\u2217). This leads to an exponential difference in the label complexities of the two methods in low-noise problems. A much closer comparison is with respect to the Oracular CAL algorithm [Hsu, 2010], which does have a dependence on \u221a nerr(h\u2217) in the second term, but has a worse dependence on \u03b8. Just like Corollary 2, we can also obtain improved bounds on label complexity under the Tsybakov noise condition.\nCorollary 4. Under conditions of Theorem 2, suppose further that Tsybakov\u2019s low-noise condition (10) is satisfied with some parameters \u03b6, \u03c9, and \u03b50 = 1. Then after m epochs, the expected number of label queries made by Algorithm 1 is at most O\u0303 ( \u03c4 2(1\u2212\u03c9) 2\u2212\u03c9 m log(|H|/\u03b4) ) .\nThe proof of this result is deferred to Appendix E. The label complexity obtained above is indeed optimal in terms of the dependence on n, the number of unlabeled examples, matching known information-theoretic rates of Castro and Nowak [2008]. This can be seen since the regret from Corollary 2 falls as a function of the number of queries at a rate of O\u0303(q \u2212 1 2(1\u2212\u03c9) m log(|H|/\u03b4)) after m epochs, where qm is the number of label queries. This is indeed optimal according to the lower bounds of Castro and Nowak [2008], after recalling that \u03c9 = 1/\u03ba in their results. Once again, the corollary highlights our improvements on top of IWAL, which does not attain this optimal label complexity.\nThese results, while strong, still do not completely capture the performance of our method. Indeed the proofs of these results are entirely based on the fact that we do not query outside the disagreement region, a property shared by the previous Oracular CAL algorithm [Hsu, 2010]. Indeed we only improve upon that result as we use more refined error bounds to define the disagreement region. However, such analysis completely ignores the fact that we construct a rather non-trivial query probability function on the disagreement region, as opposed to using any constant probability of querying over this entire region. This gives our algorithm the ability to query much more rarely even over the disagreement region, if the queries do not provide much information regarding the optimal hypothesis h\u2217. The next section illustrates an example where this gain can be quantified."}, {"heading": "4.2.2 Improved label complexity for a hard problem instance", "text": "We now present an example where the label complexity of Algorithm 1 is significantly smaller than both IWAL and Oracular CAL by virtue of rarely querying in the disagreement region. The example considers a distribution and a\n6Expectation is with respect to the coins tossed by the algorithm.\nclassifier space with the following structure: (i) for most examples a single good classifier predicts differently from the remaining classifiers (ii) on a few examples half the classifiers predict one way and half the other. In the first case, little advantage is gained from a label because it provides evidence against only a single classifier. ACTIVE COVER queries over the disagreement region with a probability close to Pmin in case (i) and probability 1 in case (ii), while others query with probability \u2126(1) everywhere implying O( \u221a n) times more queries.\nConcretely, we consider the following binary classification problem. Let H denote the finite classifier space (defined later), and distinguish some h\u2217 \u2208 H. Let U{\u22121, 1} denote the uniform distribution on {\u22121, 1}. The data distribution D(X ,Y) and the classifiers are defined jointly:\n\u2022 With probability ,\ny = h\u2217(x), h(x) \u223c U{\u22121, 1}, \u2200h 6= h\u2217.\n\u2022 With probability 1\u2212 ,\ny \u223c U{\u22121, 1}, h\u2217(x) \u223c U{\u22121, 1}, hr(x) = \u2212h\u2217(x) for some hr drawn uniformly at random fromH \\ h\u2217, h(x) = h\u2217(x) \u2200h 6= h\u2217 \u2227 h 6= hr.\nIndeed, h\u2217 is the best classifier because err(h\u2217) = \u00b70+(1\u2212 )(1/2) = (1\u2212 )/2, while err(h) = 1/2 \u2200h 6= h\u2217. This problem is hard because only a small fraction of examples contain information about h\u2217. Ideally we want to focus label queries on those informative examples while skipping the uninformative ones. However, algorithms like IWAL, or more generally, active learning algorithms that determine label query probabilities based on error differences between a pair of classifiers, query frequently on the uninformative examples. Let u(h, h\u2032) := 1(h(x) 6= y) \u2212 1(h\u2032(x) 6= y) denote the error difference between two different classifiers h and h\u2032. Let C be a random variable such that C = 1 for the case and C = 0 for the 1\u2212 case. Then it is easy to see that\nE[u(h, h\u2032) | C = 1] =  0, h 6= h\u2217, h\u2032 6= h\u2217, \u22121/2, h = h\u2217, h\u2032 6= h\u2217, 1/2, h 6= h\u2217, h\u2032 = h\u2217,\nE[u(h, h\u2032) | C = 0] = 0, \u2200h 6= h\u2032.\nTherefore, IWAL queries all the time on uninformative examples (C = 0). Now let us consider the label complexity of Algorithm 1 on this problem. Let us focus on the query probability inside the 1\u2212 region, and fix it to some constant p. Let us also allow a query probability of 1 on the region. Then the left hand side in the constraint (5) for any classifier h is at most +P (h(X) 6= hm(X))/p \u2264 +2/(p(|H|\u22121)), since h and hm disagree only on those points in the 1 \u2212 region where one of them is picked as the disagreeing classifier hr in the random draw. On the other hand, the RHS of the constraints is at least \u03be\u03c4m\u22121\u22062m\u22121 \u2265 \u03beerr(hm, Z\u0303m\u22121), which is at least \u03be/4 as long as is small enough and \u03c4m is large enough for empirical error to be close to true error. Consequently, assuming that \u2264 \u03be/8, we find that any p \u2265 16/(\u03be(|H| \u2212 1)) satisfies the constraints. Of course we also have that p \u2265 Pmin,m, which is O(1/ \u221a \u03c4m) in this case since errm(h\u2217) is a constant. Consequently, for |H| large enough p = Pmin,m is feasible and hence optimal for the population (OP). Since we find an approximately optimal solution based on Theorem 4, the label complexity at epoch m is O(1/\u221a\u03c4m). Summing things up, it can then be checked easily that we make O( \u221a n) queries over n examples, a factor of \u221a n smaller than baselines such as IWAL and Oracular CAL on this example."}, {"heading": "5 Efficient implementation", "text": "In Algorithm 1, the computation of hm is an ERM operation, which can be performed efficiently whenever an efficient passive learner is available. However, several other hurdles remain. Testing for x \u2208 Dm in the algorithm, as well\nAlgorithm 2 Coordinate ascent algorithm to solve (OP) input Accuracy parameter \u03b5 > 0. initialize \u03bb\u2190 0.\n1: loop 2: Rescale: \u03bb\u2190 s \u00b7 \u03bb where s = arg maxs\u2208[0,1]D(s \u00b7 \u03bb).\n3: Find h\u0304 = arg max h\u2208H EX [ Imh (X) P\u03bb(X) ] \u2212 bm(h).\n4: if EX [ Im h\u0304 (X)\nP\u03bb(X)\n] \u2212 bm(h\u0304) \u2264 \u03b5 then\n5: return \u03bb 6: else 7: Update \u03bbh\u0304 as \u03bbh\u0304 \u2190 \u03bbh\u0304 + 2 EX [Imh\u0304 (X)/P\u03bb(X)]\u2212 bm(h\u0304)\nEX [Imh\u0304 (X)/q\u03bb(X) 3]\n.\n8: end if 9: end loop\nas finding a solution to (OP) are considerably more challenging. The epoch schedule helps, but (OP) is still solved O(log n) times, necessitating an extremely efficient solver.\nStarting with the first issue, we follow Dasgupta et al. [2007] who cleverly observed that x \u2208 Dm can be efficiently determined using a single call to an ERM oracle. Specifically, to apply their method, we use the oracle to find7 h\u2032 = arg min{err(h, Z\u0303m\u22121) | h \u2208 H, h(x) 6= hm(x)}. It can then be argued that x \u2208 Dm = DIS(Am) if and only if the easily-measured regret of h\u2032 (that is, reg(h\u2032, hm, Z\u0303m\u22121)) is at most \u03b3\u2206m\u22121.\nSolving (OP) efficiently is a much bigger challenge because, as an optimization problem, it is enormous: There is one variable P (x) for every point x \u2208 X , one constraint (5) for each classifier h and bound constraints (6) on P (x) for every x. This leads to infinitely many variables and constraints, with an ERM oracle being the only computational primitive available. Another difficulty is that (OP) is defined in terms of the true expectation with respect to the example distribution PX , which is unavailable.\nIn the following we first demonstrate how to efficiently solve (OP) assuming access to the true expectation EX [\u00b7], and then discuss a relaxation that uses expectation over samples."}, {"heading": "5.1 Solving (OP) with the true expectation", "text": "The main challenge here is that the optimization variable P (x) is of infinite dimension. We deal with this difficulty using Lagrange duality, which leads to a dual representation of P (x) in terms of a set of classifiers found through successive calls to an ERM oracle. As will become clear shortly, each of these classifiers corresponds to the most violated variance constraint (5) under some intermediate query probability function. Thus at a high level, our strategy is to expand the set of classifiers for representing P (x) until the amount of constraint violation gets reduced to an acceptable level.\nWe start by eliminating the bound constraints using barrier functions. Notice that the objective EX [1/(1\u2212 P (x))] is already a barrier at P (x) = 1. To enforce the lower bound (6), we modify the objective to\nEX [\n1\n1\u2212 P (X)\n] + \u00b52EX [ 1(X \u2208 Dm)\nP (X)\n] , (12)\nwhere \u00b5 is a parameter chosen momentarily to ensure P (x) \u2265 Pmin,m for all x \u2208 Dm. Thus, the modified goal is to minimize (12) over non-negative P subject only to (5).\nWe solve the problem in the dual where we have a large but finite number of optimization variables, and efficiently maximize the dual using coordinate ascent with access to an ERM oracle over H. Let \u03bbh \u2265 0 denote the Lagrange\n7We only have access to an unconstrained oracle. But that is adequate to solve with one constraint. See Appendix F of [Karampatziakis and Langford, 2011] for details.\nmultiplier for the constraint (5) for classifier h. Then for any \u03bb, we can minimize the Lagrangian L(P,\u03bb) := EX [ 1\n1\u2212 P (X)\n] +\u00b52EX [ 1(X \u2208 Dm)\nP (X) ] \u2212 \u2211 h\u2208H \u03bbh ( bm(h)\u2212 EX [ 1(h(X) 6= hm(X) \u2227X \u2208 Dm) P (X) ]) over each primal variable P (X) yielding the solution\nP\u03bb(x) = 1(x \u2208 Dm)q\u03bb(x)\n1 + q\u03bb(x) , where q\u03bb(x) =\n\u221a \u00b52 + \u2211 h\u2208H \u03bbhImh (x) (13)\nand Imh (x) = 1(h(x) 6= hm(x) \u2227 x \u2208 Dm). Clearly, \u00b5/(1 + \u00b5) \u2264 P\u03bb(x) \u2264 1 for all x \u2208 Dm, so all the bound constraints (6) in (OP) are satisfied if we choose \u00b5 = 2Pmin,m. Plugging the solution P\u03bb into the Lagrangian, we obtain the dual problem of maximizing the dual objective\nD(\u03bb) = EX [ 1(X \u2208 Dm)(1 + q\u03bb(X))2 ] \u2212 \u2211 h\u2208H \u03bbhbm(h) + C0 (14)\nover \u03bb \u2265 0. The constant C0 is equal to 1\u2212Pr(Dm) where Pr(Dm) = Pr(X \u2208 Dm). An algorithm to approximately solve this problem is presented in Algorithm 2. The algorithm takes a parameter \u03b5 > 0 specifying the degree to which all of the constraints (5) are to be approximated. Since D is concave, the rescaling step can be solved using a straightforward numerical line search. The main implementation challenge is in finding the most violated constraint (Step 3). Fortunately, this step can be reduced to a single call to an ERM oracle. To see this, note that the constraint violation on classifier h can be written as\nEX [ Imh (X) P (X) ] \u2212 bm(h) = EX [ 1(X \u2208 Dm) ( 1 P (X) \u2212 2\u03b12 ) 1(h(X) 6= hm(X)) ] \u2212 2\u03b22\u03b3\u03c4m\u22121\u2206m\u22121(err(h, Z\u0303m\u22121)\u2212 err(hm, Z\u0303m\u22121))\u2212 \u03be\u03c4m\u22121\u22062m\u22121.\nThe first term of the right-hand expression is the risk (classification error) of h in predicting samples labeled according to hm with importance weights of 1/P (x)\u2212 2\u03b12 if x \u2208 Dm and 0 otherwise; note that these weights may be positive or negative. The second term is simply the scaled risk of h with respect to the actual labels. The last two terms do not depend on h. Thus, given access to PX (or samples approximating it, discussed shortly), the most violated constraint can be found by solving an ERM problem defined on the labeled samples in Z\u0303m\u22121 and samples drawn from PX labeled by hm, with appropriate importance weights detailed in Appendix F.1.\nWhen all primal constraints are approximately satisfied, the algorithm stops. Consequently, we can execute each step of Algorithm 2 with one call to an appropriately defined ERM oracle, and approximate primal feasibility is guaranteed when the algorithm stops. More specifically, we can prove the following guarantee on the convergence of the algorithm.\nTheorem 3. When run on the m-th epoch, Algorithm 2 has the following guarantees.\n1. It halts in at most Pr(Dm) 8P 3min,m\u03b5 2 iterations.\n2. The solution \u03bb\u0302 \u2265 0 it outputs has bounded `1 norm: \u2016\u03bb\u0302\u20161 \u2264 Pr(Dm)/\u03b5.\n3. The query probability function P\u03bb\u0302 satisfies:\n\u2022 The variance constraints (5) up to an additive factor of \u03b5, i.e.,\n\u2200h \u2208 H EX [ 1(h(x) 6= hm(x) \u2227 x \u2208 Dm)\nP\u03bb\u0302(X)\n] \u2264 bm(h) + \u03b5,\n\u2022 The simple bound constraints (6) exactly,\n\u2022 Approximate primal optimality: EX [ 1\n1\u2212 P\u03bb\u0302(X)\n] \u2264 EX [ 1\n1\u2212 P \u2217(X)\n] + 4Pmin,mPr(Dm), (15)\nwhere P \u2217 is the solution to (OP).\nThat is, we find a solution with small constraint violation to ensure generalization, and a small objective value to be label efficient. If \u03b5 is set to \u03be\u03c4m\u22121\u22062m\u22121, an amount of constraint violation tolerable in our analysis, the number of iterations in Theorem 3 varies between O(\u03c43/2m\u22121) and O(\u03c42m\u22121) as the err(hm, Z\u0303m\u22121) varies between a constant and O(1/\u03c4m\u22121). The theorem is proved in Appendix F.2."}, {"heading": "5.2 Solving (OP) with expectation over samples", "text": "So far we considered solving (OP) defined on the unlabeled data distribution PX , which is not available in practice. A simple and natural substitute for PX is an i.i.d. sample drawn from it. Here we show that solving a properly-defined sample variant of (OP) leads to a solution to the original (OP) with similar guarantees as in Theorem 3.\nMore specifically, we define the following sample variant of (OP). Let S be a large sample drawn i.i.d. from PX , and (OPS) be the same as (OP) except with all population expectations replaced by empirical expectations taken with respect to S. Now for any \u03b5 \u2265 0, define (OPS,\u03b5) to be the same as (OPS) except that the variance constraints (5) are relaxed by an additive slack of \u03b5.\nEvery time ACTIVE COVER needs to solve (OP) (Step 5 of Algorithm 1), it draws a fresh unlabeled i.i.d. sample S of size u from PX , which can be done easily in a streaming setting by collecting the next u examples. It then applies Algorithm 2 to solve (OPS,\u03b5) with accuracy parameter \u03b5. Note that this is different from solving (OPS) with accuracy parameter 2\u03b5. We establish the following convergence guarantees.\nTheorem 4. Let S be an i.i.d. sample of size u from PX . When run on the m-th epoch for solving (OPS,\u03b5) with accuracy parameter \u03b5, Algorithm 2 satisfies the following.\n1. It halts in at most P\u0302r(Dm) 8P 3min,m\u03b5\n2 iterations, where P\u0302r(Dm) := \u2211 X\u2208S 1(X \u2208 Dm)/u.\n2. The solution \u03bb\u0302 \u2265 0 it outputs has bounded `1 norm: \u2016\u03bb\u0302\u20161 \u2264 P\u0302r(Dm)/\u03b5.\n3. If u \u2265 O((1/(Pmin,m\u03b5)4 + \u03b14/\u03b52) log(|H|/\u03b4)), then with probability \u2265 1\u2212 \u03b4, the query probability function P\u03bb\u0302 satisfies:\n\u2022 All constraints of (OP) except with an additive slack of 2.5\u03b5 in the variance constraints (5), \u2022 Approximate primal optimality:\nEX [\n1\n1\u2212 P\u03bb\u0302(X)\n] \u2264 EX [ 1\n1\u2212 P \u2217(X)\n] + 8Pmin,mPr(Dm) + (2 + 4Pmin,m)\u03b5,\nwhere P \u2217 is the solution to (OP).\nThe proof is in Appendix F.3. Intuitively, the optimal solution P \u2217 to (OP) is also feasible in (OPS,\u03b5) since satisfying the population constraints leads to approximate satisfaction of sample constraints. Since our solution P\u03bb\u0302 is approximately optimal for (OPS,\u03b5) (this is essentially due to Theorem 3), this means that the sample objective at P\u03bb\u0302 is not much larger than P \u2217. We now use a concentration argument to show that this guarantee holds also for the population objective with slightly worse constants. The approximate constraint satisfaction in (OP) follows by a similar concentration argument. Our proofs use standard concentration inequalities along with Rademacher complexity to provide uniform guarantees for all vectors \u03bb with bounded `1 norm.\nThe first two statements, finite convergence and boundedness of \u2016\u03bb\u0302\u20161, are identical to Theorem 3 except Pr(Dm) is replaced by P\u0302r(Dm). When \u03b5 is set properly, i.e, to be \u03be2\u03c4m\u22121\u22062m\u22121, the number of unlabeled examples u in the third statement varies between O(\u03c42m\u22121) and O(\u03c44m\u22121) as the err(hm, Z\u0303m\u22121) varies between a constant and O(1/\u03c4m\u22121). The third statement shows that with enough unlabeled examples, we can get a query probability function almost as good as the solution to the population problem (OP)."}, {"heading": "6 Experiments with Agnostic Active Learning", "text": "While AC is efficient in the number of ERM oracle calls, it needs to store all past examples, resulting in large space complexity. As Theorem 3 suggests, the query probability function (13) may need as many asO(\u03c42i ) classifiers, further increasing storage demand. In Section 6.1 we discuss a scalable online approximation to ACTIVE COVER, ONLINE ACTIVE COVER (OAC), which we implemented and tested empirically with the setup in Section 6.2. Experimental results and discussions are in Section 6.3."}, {"heading": "6.1 Online Active Cover (OAC)", "text": "Algorithm 3 gives the online approximation that we implemented, which uses an epoch schedule of \u03c4i = i, assigning every new example to a new epoch. It involves some new notations which we explain below. To make explicit the dependence of a query probability function on both a weight vector \u03bb over classifiers and the current epoch, we write them as subscripts:\nq\u03bb,i(x) := \u221a (2Pmin,i)2 + \u2211 h \u03bbh1(h(x) 6= hi(x)), (20)\nP\u03bb,i(x) := 1(x \u2208 Di) q\u03bb,i(x)\n1 + q\u03bb,i(x) . (21)\nWe use 1h for a |H|-dimensional binary vector with 1 in the entry corresponding to the classifier h and 0 elsewhere. To explain the connections between Algorithms 1 (AC) and 3 (OAC), we start with the update of the ERM classifier and thresholds, corresponding to Step 1 of AC and Step 6 of OAC. Instead of batch ERM oracles, OAC invokes online importance weighted ERM oracles that are stateful and process examples in a streaming fashion without the need to store them. The specific importance weighted oracle we use is a reduction to online importance-weighted logistic regression [Karampatziakis and Langford, 2011] implemented in Vowpal Wabbit (VW).\nInstead of computing the query probability function by solving a batch optimization problem as in Step 5 of AC, OAC maintains a fixed number l of classifiers that are intended to be a cover of the set of good classifiers. On every new example, this cover undergoes a sequence of online, importance weighted updates (Steps 7 to 13 of OAC), which are meant to approximate the coordinate ascent steps in Algorithm 2. The importance structure (16) is derived from (57), accounting for the fact that the algorithm simply uses the incoming stream of examples to estimate EX [\u00b7] rather than a separate unlabeled sample. The same approximation is also present in the updates (17) and (18), which are online estimates of the numerator and the denominator of the additive coordinate update in Step 7 of Algorithm 2. Because (17) is an online estimate, we need to explicitly enforce non-negativity.\nFinally, Steps 9 to 14 of AC and Steps 14 to 26 of OAC perform the querying of labels. As pointed out in Section 5, the test in Step 16 of OAC is done via an online technique detailed in Appendix F of Karampatziakis and Langford [2011]."}, {"heading": "6.2 Setup", "text": "We conduct an empirical comparison of OAC with the following active learning algorithms.\n\u2022 IWAL: A slight modification of Algorithm 1 of Beygelzimer et al. [2010], which performs importance-weighted sampling of labels and maintains an unbiased estimate of classification error. In computing the query probability, rather than using a conservative, problem-independent threshold as in Beygelzimer et al. [2010], we use the following error-dependent quantity: \u221a\nC0 log k\nk \u2212 1 ek\u22121 +\nC0 log k\nk \u2212 1 , (22)\nwhere ek\u22121 is the importance-weighted error estimate after the algorithm processes k \u2212 1 examples. C0 is the only active learning hyper-parameter. The query probability is set to 1 if the error difference Gk, defined in Step 2 of Algorithm 1 of Beygelzimer et al. [2010], is smaller than the threshold (22), and otherwise a decreasing function of Gk.\nAlgorithm 3 ONLINE ACTIVE COVER input: cover size l, parameters c0 and \u03b1.\n1: Initialize online importance weighted minimization oracles {Ot}lt=0, each controlling a classifier and some associated weights {(h(t), \u03bb(t), \u03bd(t), \u03c9(t))}lt=1 with all weights initialized to 0. 2: Query the first three {Yi}3i=1 and stream {(Xi, Yi, 1)}2i=1 through O0. 3: Get classifier h3 and error estimate e2 from O0, and compute Pmin,3. 4: Let Y \u22173 := Y3, Y\u03033 := h3(X3) and W3 := 1. Set \u03b2 := ( \u221a \u03b1/c0)/10. 5: for i = 4, . . . , n, do 6: Update the ERM, the error estimate and the threshold\nhi := O0((Xi\u22121, Y \u2217 i\u22121,Wi\u22121)),\nei\u22121 := (i\u2212 2)ei\u22122 + 1(Y\u0303i\u22121 6= Y \u2217i\u22121)Wi\u22121\ni\u2212 1 , \u2206\u0302i\u22121 := \u221a c0ei\u22121/(i\u2212 1) + max(2\u03b1, 4)c0 log(i\u2212 1)/(i\u2212 1).\n7: for t = 1, . . . , l do 8: \u03bbt := \u2211 t\u2032<t \u03bb(t\u2032)1h(t\u2032) . 9: St := 2\u03b1 2 \u2212 1/P\u03bbt,i\u22121(Xi\u22121).\n10: Set up a vector c\ncy := 1(Xi\u22121 \u2208 Di\u22121)|St|1(y 6= sign(St)Y\u0303i\u22121)+ 2\u03b22(i\u2212 2)\u2206\u0302i\u22122 ( 1(Xi\u22121 /\u2208 Di\u22121)1(y 6= Y\u0303i\u22121) + 1(Xi\u22121 \u2208 Di\u22121)\nQi\u221211(y 6= Yi\u22121) Pi\u22121\n) . (16)\n11: Set Y(t) := arg miny cy and W(t) := |c1 \u2212 c\u22121|. 12: Update\nh(t) := Ot((Xi\u22121, Y(t),W(t))), \u03bd(t) := max ( \u03bd(t) \u2212 2 ( ch(t)(Xi\u22121) + min(St, 0)1(Xi\u22121 \u2208 Di\u22121) ) , 0 ) , (17)\n\u03c9(t) := \u03c9(t) + 1(h(t)(Xi\u22121) 6= Y\u0303i\u22121 \u2227Xi\u22121 \u2208 Di\u22121)\nq\u03bbt,i(Xi\u22121) 3\n, (18)\n\u03bb(t) := \u03bb(t) + \u03bd(t) \u03c9(t) 1 ( (\u03bd(t), \u03c9(t)) 6= (0, 0) ) . (19)\n13: end for 14: Receive data point Xi and predict Y\u0303i := hi(Xi). 15: Compute Pmin,i := min ( ( \u221a (i\u2212 1)ei\u22121 + log(i\u2212 1))\u22121, 1/2 ) . 16: if Xi \u2208 Di := DIS(Ai), then 17: Compute Pi := P\u03bb,i(Xi), where \u03bb := \u2211l t=1 \u03bb(t)1h(t) . 18: Draw Qi \u223c Bernoulli(Pi). 19: if Qi = 1 then 20: Query Yi and set Y \u2217i := Yi,Wi := 1/Pi. 21: else 22: Set Y \u2217i := 1,Wi := 0. 23: end if 24: else 25: Set Y \u2217i := Y\u0303i,Wi := 1. 26: end if 27: end for\n\u2022 ORA-I: An Oracular-CAL [Hsu, 2010] style variant of Algorithm 3. If the test in Step 16 of Algorithm 3 is true, meaning the new example Xi is in the current disagreement region, the query probability Pi is set to 1. This algorithm does not need to maintain a cover, but still uses two tuning parameters c0 and \u03b1 to compute the threshold (79). Note that both the generalization and label complexity guarantees (Theorems 1 and 2) apply to this variant if a batch ERM oracle is used.\n\u2022 ORA-II: An Oracular-CAL [Hsu, 2010] style variant of IWAL, where the query probability is set to 1 if the error difference Gk, defined in Step 2 of Algorithm 1 of Beygelzimer et al. [2010], is smaller than the threshold\u221a\nC0 log k\nk \u2212 1 ek\u22121 +\nC0 log k\nk \u2212 1 .\nOtherwise, the algorithm uses predicted labels by the current ERM hypothesis. Note that the error estimate ek\u22121 now uses both the queried labels and predicted labels, and is no longer unbiased. Like IWAL, it only has one hyper-parameter C0.\n\u2022 RANDOM: Passive learning on a labeled sub-sample drawn uniformly at random.\nWe implemented these algorithms8 in Vowpal Wabbit (VW) and performed experiments on 23 binary classification datasets with varying sizes (103 to 106) and diverse feature characteristics. Details about the datasets are in Appendix G.1. For each dataset we performed a random 80/20 training/testing split, ran the five algorithms under various hyperparameter settings each for one pass over the training data, and evaluated the learned classifiers on testing data. Our goals are:\n1. Understanding the trade-offs between test error and query rate achieved by different algorithms;\n2. Comparing different algorithms when each uses the best fixed hyper-parameter setting.\nWith regard to the second goal, note that it is in general very difficult to select active learning hyper-parameters on a per-task basis because labeled validation data are not available. However, with a variety of classification datasets, it might still be reasonable to look for the single hyper-parameter setting that performs the best on average across datasets, thereby reducing over-fitting to any individual dataset, and compare different algorithms under such fixed parameter settings. More details about hyper-parameters are in Appendix G.2."}, {"heading": "6.3 Results and Discussions", "text": "Figure 2 gives a summary of the performances of different algorithms. At a fixed query rate, defined as the fraction of label queries at the end of one pass over the training data, we consider the minimum test error achievable with at most that query rate. Taking this for each algorithm on each dataset, we compute the fraction of datasets on which an algorithm wins against RANDOM. Figure 2(a), which is the same as Figure 1, plots the win fractions9 at different query rates. OAC dominates all other agnostic active learning algorithms, and outperforms RANDOM except at low query rates where it is on parity. This result also shows that RANDOM is a strong baseline at low query rates.\nFigure 2(b) reveals the magnitude of the performance differences. Here we only show results for OAC and IWAL because ORA-I and ORA-II are significantly worse. To account for the varying hardness of different datasets, we scale the test error on a per-dataset basis. Formally, let error(a, p, d) denote the test error achieved by algorithm a with hyper-parameter setting p on dataset d. Let errormax(d) and errormin(d) denote the maximum and minimum test errors on dataset d any algorithm can achieve with any hyper-parameter setting. Then we define the relative test error as\nrel err(a, p, d) = error(a, p, d)\u2212 errormin(d) errormax(d)\u2212 errormin(d) . (23)\nAs in Figure 2(a), at a fixed query rate we consider the minimum relative test error achievable with at most that query rate. Taking this for each algorithm on each dataset, we compute the improvement in relative test error with respect to\n8For IWAL we use the existing implementation by the authors in VW. 9A tie counts as 0.5.\nRANDOM. Then we plot the medians, the 25-th and the 75-th quantiles of the improvements over datasets at different query rates. OAC is on par with RANDOM across the datasets at query rates lower than 10\u22122, and outperforms RANDOM at higher query rates. The magnitude of improvement is not very large, but it should be noted that on many of these datasets a very large improvement is not necessarily possible. In contrast, IWAL has higher relative test errors at query rates lower than 10\u22122, and only becomes competitive with RANDOM at higher query rates.\nFigure 3 shows minimum test errors at different query rates for three specific datasets. They are relatively large in size (more than 105 examples) and possess different levels of difficulties. The advantage of OAC over other algorithms is clear especially at low query rates. Results for the remaining 20 datasets are in Appendix G.3.\nFigure 4 gives results obtained by different algorithms under fixed hyper-parameter settings, which are selected to optimize trade-offs between test errors and query rates across all datasets. Let query(a, p, d) be the query rate of algorithm a with hyperparameters p on dataset d. Given a weight parameter w \u2208 [0, 1], we define for each algorithm a the best hyper-parameter setting as\np\u2217w(a) := arg min p median d perf(w, a) := {w \u00b7 query(a, p, d) + (1\u2212 w) \u00b7 rel err(a, p, d)} , (24)\nwhere rel err is as defined in Equation 23. Figures 4(a) and 4(b) demonstrate how well each algorithm optimizes the combined metric (24) by plotting the curve of cumulative fraction of datasets on which an algorithm, with parameters fixed at p\u2217w(a) across datasets, achieves no more than a certain value of the weighted sum perf(w, a) in (24). A higher curve thus means a better performance. When the weight on query rate is 0.1, perf(w, a) tends to care mostly about test error, and the unbiased nature of IWAL possibly helps it outperform other algorithms at high query rates, while OAC is competitive at low query rates. At the other extreme when the weight is 0.9, query rate matters much more and OAC is superior to others.\nFigure 5 plots relative test errors and query rates across all datasets achieved by each algorithm using its best single parameter p\u2217w(a) in (24), with w varying from 0.1 to 0.9. The markers are plotted at\n(median d {query(a, p\u2217w(a), d)},median d {rel err(a, p\u2217w(a), d)})\nfor each algorithm a, and the vertical bars extend from the 25th to the 75th quantile of each algorithm a\u2019s relative test errors achieved with p\u2217w(a) across datasets. OAC in general achieves test errors comparable to the other algorithms, but at lower query rates.\nHow much headroom for improvement is there by a better automatic tuning of hyperparameters? In addition to\nresults obtained with a fixed hyper-parameter setting, we examine performances of different algorithms when each uses the best hyper-parameter on a per-dataset basis. Figure 6 is the counterpart of Figure 4 in this setting, showing the cumulative fractions of datasets for which each algorithm a achieves a certain value of the performance metric perf in (24) when using dataset-dependent best hyper-parameters:\np\u2217w(a, d) := arg min p min d perf(w, a) :=\n{ w \u00b7 query(a, p, d) + (1\u2212 w) \u00b7 error(a, p, d)\u2212 errormin(d)\nerrormax(d)\u2212 errormin(d)\n} .\nFigure 6 suggests the possibility that with the right hyper-parameter settings, OAC may dominate all other algorithms at both extremes of the query-rate vs. test-error trade-off. Overall, we find that OAC achieves reasonable performance gains in terms of good generalization with a few labeled examples, compared with a number of baselines on a diverse collection of datasets."}, {"heading": "7 Analysis of generalization ability", "text": "In this section we present the main framework and analysis for the results on the generalization properties of the ACTIVE COVER algorithm. Our analysis is broken up into several steps. We start by setting up some additional notation for the proofs. Our analysis relies on two deviation bounds for the empirical regret and the empirical error of the ERM classifier. These are obtained by appropriately applying Freedman-style concentration bounds for martingales. Both these bounds depend on the variance and range of our error and regret estimates for all classifiers h \u2208 H, and these quantities are controlled using the constraints (5) and (6) in the definition of the optimization problem (OP). Since our data consists of examples from different epochs, which use different query probabilities Pm, the above steps with appropriate manipulations yield bounds for the epoch m, in terms of various quantities involving the previous epochs. Theorem 1 and its corollaries are then obtained by setting up appropriate inductive claims. We make this intuition precise in the following sections."}, {"heading": "7.1 Framework for generalization analysis", "text": "Before we can prove our main results, we recall some notations and introduce a few additional ones. We also prove some technical lemmas in this section which are used to prove our main results.\nRecall the notation reg(h, h\u2032) := err(h)\u2212 err(h\u2032), h\u2217 \u2208 arg minh\u2208H err(h), reg(h) := reg(h, h\u2217). Let Zm denote the set of importance-weighted examples in Z\u0303m, and the corresponding empirical error is denoted as:\nerr(h, Zm) := 1\n\u03c4m m\u2211 j=1 \u03c4j\u2211 i=\u03c4j\u22121+1 (Qi1(h(Xi) 6= Yi \u2227Xi \u2208 Dj) Pj(Xi) ) . (25)\nTaking expectations, we define the following quantities with respect to the sequence of regions {Dm}:\nerrm(h) := EX,Y [1(h(X) 6= Y \u2227X \u2208 Dm)], (26)\nerrm(h) := 1\n\u03c4m m\u2211 j=1 (\u03c4j \u2212 \u03c4j\u22121)errj(h).\nIntuitively, errm captures the population error of h, restricted to only the examples in the disagreement region. This is also the expectation of the sample error restricted to the importance-weighted examples in epoch m. Averaging these quantities, we obtain errm which is the expectation of the sample error over Zm. Centering around the corresponding errors of h\u2217, we obtain the following regret terms:\nregm(h) := errm(h)\u2212 errm(h\u2217),\nregm(h) := 1\n\u03c4m m\u2211 j=1 (\u03c4j \u2212 \u03c4j\u22121)regj(h).\nWhile the above quantities only concern the importance-weighted examples, it is also useful to measure error and regret terms over the entire biased sample. We define the empirical error and regret on Z\u0303m as follows:\nerr(h, Z\u0303m)\n:= 1\n\u03c4m m\u2211 j=1 \u03c4j\u2211 i=\u03c4j\u22121+1 ( 1(h(Xi) 6= hj(Xi) \u2227Xi /\u2208 Dj) + Qi1(h(Xi) 6= Yi \u2227Xi \u2208 Dj) Pj(Xi) ) ,\nreg(h, h\u2032, Z\u0303m) := err(h, Z\u0303m)\u2212 err(h\u2032, Z\u0303m),\nand the associated expected regret:\nreg\u2021m(h, h \u2032) := EX [(1(h(X) 6= hm(X))\u2212 1(h\u2032(X) 6= hm(X)))1(X /\u2208 Dm)] +\nEX,Y [(1(h(X) 6= Y )\u2212 1(h\u2032(X) 6= Y ))1(X \u2208 Dm)], (27)\nr\u0303egm(h, h \u2032) :=\n1\n\u03c4m m\u2211 j=1 (\u03c4j \u2212 \u03c4j\u22121)reg\u2021j(h, h \u2032). (28)\nTo simplify notation, we sometimes use the shorthand reg(h, Z\u0303m) := reg(h, hm+1, Z\u0303m). The quantity r\u0303egm(h, h \u2032) will play quite a central role in our analysis as it is the expectation of the empirical regret of h relative to h\u2032 on our biased sample Z\u0303m. We also recall the earlier notations\n\u2206m := c1 \u221a merr(hm+1, Z\u0303m) + c2 m log \u03c4m,\nAm+1 := {h | err(h, Z\u0303m)\u2212 err(hm+1, Z\u0303m) \u2264 \u03b3\u2206m}, and\n\u2206\u2217m :=\n{( c1 \u221a merrm(h\u2217) + c2 m log \u03c4m ) , m \u2265 1.\n\u22060, m = 0.\nThroughout the paper, we adopt the convention that the quantities (26) to (3) take the value of zero when m = 0. We use the shorthand m(i) to denote the epoch containing example i.\nWith the notations in place, we start with an extremely important lemma, which shows that the biased sample Z\u0303 which we create introduces a bias in the favor of good hypotheses, overly penalizing the bad hypotheses while favorably evaluating the optimal h\u2217.\nLemma 1 (Favorable Bias). \u2200m \u2265 1,\u2200h\u0304 \u2208 Am,\u2200h \u2208 H, the following holds:\nreg\u2021m(h, h\u0304) \u2265 reg(h, h\u0304).\nThe next key ingredient for our proofs is a deviation bound, which will be appropriately used to control the deviation of the empirical regret and error terms. Lemma 2 (Deviation Bounds). Pick 0 < \u03b4 < 1/e such that |H|/\u03b4 > \u221a\n192. With probability at least 1 \u2212 \u03b4 the following holds. For all (h, h\u2032) \u2208 H2 and \u2200m \u2265 1,\n|r\u0303egm(h, h\u2032)\u2212 reg(h, h\u2032, Z\u0303m)|\n\u2264 \u221a\u221a\u221a\u221a m \u03c4m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)EX [( 1(X /\u2208 Di) + 1(X \u2208 Di) Pi(X) ) 1(h(X) 6= h\u2032(X)) ] +\nm Pmin,m , (29)\n|err(h, Zm)\u2212 errm(h)|\n\u2264 \u221a\u221a\u221a\u221a m \u03c4m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)EX,Y [ 1(X \u2208 Di \u2227 h(X) 6= Y ) Pi(X) ] + m Pmin,m , (30)\nwhere\nm := 32\n( log(|H|/\u03b4) + log \u03c4m\n\u03c4m\n) .\nThe lemma is obtained by applying a form of Freedman\u2019s inequality presented in Appendix A. Intuitively, the deviations are small so long as the average importance weights over the disagreement region and the minimum query probability over the disagreement region are well-behaved. This lemma also highlights why r\u0303egm is a very natural quantity for our analysis, since the empirical regret on our biased sample Z\u0303 concentrates around it.\nTo keep the handling of probabilities simple, we assume for the bulk of this section that the conclusions of Lemma 2 hold deterministically. The failure probability is handled once at the end to establish our main results. Let E denote the event that the assertions of Lemma 2 hold deterministically, and we know that Pr(EC) \u2264 \u03b4. Based on the above lemma, we obtain the following propositions for the concentration of empirical regret and error terms.\nProposition 1 (Regret concentration). Fix an epoch m \u2265 1. Suppose the event E holds and assume that h\u2217 \u2208 Aj for all epochs j \u2264 m.\n|reg(h, h\u2217, Z\u0303m)\u2212 r\u0303egm(h, h\u2217)|\n\u2264 1 4 r\u0303egm(h) + 2\u03b1 \u221a\u221a\u221a\u221a m \u03c4m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)regi(hi) + 2\u03b1 \u221a 3errm(h\u2217) m\n+ \u03b2 \u221a\u221a\u221a\u221a2\u03b3 m\u2206m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)(reg(h, Z\u0303i\u22121) + reg(h\u2217, Z\u0303i\u22121)) + 4\u2206m\nWe need an analogous result for the empirical error of the ERM at each epoch.\nProposition 2 (Error concentration). Fix an epoch m \u2265 1. Suppose the event E holds and assume that h\u2217 \u2208 Aj for all epochs j \u2264 m.\n|errm(h\u2217)\u2212 err(hm+1, Z\u0303m)| \u2264 errm(h\n\u2217)\n2 + 3\u2206m 2 + reg(h\u2217, hm+1, Z\u0303m).\nWe now present the proofs of our main results based on these propositions."}, {"heading": "7.2 Proofs of main results", "text": "We prove a more general version of the theorem. Theorem 1 and its corollaries follow as consequences of this more general result.\nTheorem 5. For all epochs m = 1, 2, . . . ,M and all h \u2208 H, we have with probability at least 1\u2212 \u03b4\n|reg(h, h\u2217, Z\u0303m)\u2212 r\u0303egm(h, h\u2217)| \u2264 1\n2 r\u0303egm(h, h\n\u2217) + \u03b7\n4 \u2206m, (31)\nreg(h\u2217, hm+1, Z\u0303m) \u2264 \u03b7\u2206m\n4 , (32)\n|errm(h\u2217)\u2212 err(hm+1, Z\u0303m)| \u2264 errm(h\n\u2217)\n2 + \u03b7 2 \u2206m. (33)\nThe theorem is proved inductively. We first give the proof outline for this theorem, and then show how Theorem 1 and its corollaries follow."}, {"heading": "7.2.1 Proof of Theorem 5", "text": "The theorem is proved via induction. Let us start with the base case for m = 1. Clearly,\n|reg(h, h\u2217, Z\u03031)\u2212 r\u0303eg1(h, h\u2217)| \u2264 1 \u2264 \u03b7\u22061/4,\nsince Pmin,1 = 1. The conclusions for the second and third statements follow similarly. This establishes the base case. Let us now assume that the hypothesis holds for i = 1, 2, . . . ,m\u2212 1 and we establish it for the epoch i = m. We start from the conclusion of Proposition 1, which yields\n|reg(h, h\u2217, Z\u0303m)\u2212 r\u0303egm(h, h\u2217)|\n\u2264 1 4 r\u0303egm(h) + 2\u03b1 \u221a\u221a\u221a\u221a m \u03c4m m\u2211 i=1\n(\u03c4i \u2212 \u03c4i\u22121)regi(hi)\ufe38 \ufe37\ufe37 \ufe38 T1\n+ 2\u03b1 \u221a\n3errm(h\u2217) m\ufe38 \ufe37\ufe37 \ufe38 T2\n+ \u03b2 \u221a\u221a\u221a\u221a2\u03b3 m\u2206m m\u2211 i=1\n(\u03c4i \u2212 \u03c4i\u22121)(reg(h, Z\u0303i\u22121) + reg(h\u2217, Z\u0303i\u22121))\ufe38 \ufe37\ufe37 \ufe38 T3 +4\u2206m\nWe now control T1, T2 and T3 in the sum using our inductive hypothesis and the propositions in a series of lemmas. To state the lemmas cleanly, let Em refer to the event where the bounds (31)-(33) hold at epoch m. Then we have the following lemmas. The first lemma gives a bound on T1.\nLemma 3. Suppose that the event E holds and that the events Ei hold for all epochs i = 1, 2, . . . ,m \u2212 1. Then we have\n2\u03b1 \u221a\u221a\u221a\u221a m \u03c4m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)regi(hi) \u2264 \u03b7\u2206m 12 + 24\u03b12 m log \u03c4m.\nIntuitively, the lemma holds since Lemma 1 allows us to bound regi(hi) with r\u0303egi\u22121(hi). The latter is then controlled using the event Ei. Some algebraic manipulations then yield the lemma, with a detailed proofs in Appendix C. We next present a lemma that helps us control T2.\nLemma 4. Suppose that the event E holds and that the events Ei hold for all epochs i = 1, 2, . . . ,m \u2212 1. Then we have\n2\u03b1 \u221a 3errm(h\u2217) m \u2264 2\u03b1 \u221a 6 merr(hm+1, Z\u0303m) + \u2206m + 1\n4 reg(h\u2217, hm+1, Z\u0303m) + 33\u03b1 2 m.\nThe lemma follows more or less directly from Proposition 2 combined with some algebra. Finally, we present a lemma to bound T3.\nLemma 5. Suppose that the event E holds and that the events Ei hold for all epochs i = 1, 2, . . . ,m \u2212 1. Then we have\n\u03b2 \u221a\u221a\u221a\u221a2\u03b3 m\u2206m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)(reg(h, Z\u0303i\u22121) + reg(h\u2217, Z\u0303i\u22121)) \u2264 1 4 r\u0303egm(h, h \u2217) + 7\u03b7\u2206m 72 .\nThe reg(h\u2217, hi, Z\u0303i\u22121) terms in the lemma are bounded directly due to the event Ei. For the second term, we observe that the empirical regret of h relative to hi is not too different from the empirical regret to h\u2217 (since h\u2217 has a small empirical regret by Ei). Furthermore, the empirical regret to h\u2217 is close to r\u0303egi\u22121(h, h\u2217) by the event Ei. These observations, along with some technical manipulations yield the lemma.\nGiven these lemmas, we can now prove the theorem in a relatively straightforward manner. Given our inductive hypothesis, the events Ei indeed hold for all epochs i = 1, 2, . . . ,m \u2212 1 which allows us to invoke the lemmas. Substituting the above bounds on T1 from Lemma 3, T2 from Lemma 4 and T3 from 5 into Proposition 1 yields\n|reg(h, h\u2217, Z\u0303m)\u2212 r\u0303egm(h, h\u2217)|\n\u2264 1 4 r\u0303egm(h) + \u03b7\u2206m 12 + 24\u03b12 m log \u03c4m + 2\u03b1\n\u221a 6 merr(hm+1, Z\u0303m) + \u2206m\n+ 1\n4 reg(h\u2217, hm+1, Z\u0303m) + 33\u03b1\n2 m + 1\n4 r\u0303egm(h, h\n\u2217) + 7\u03b7\u2206m\n72 + 4\u2206m\n\u2264 1 2 r\u0303egm(h, h \u2217) + 57\u03b12 m log \u03c4m + 13\u03b7 72 \u2206m + 2\u03b1\n\u221a 6 merr(hm+1, Z\u0303m) + 5\u2206m\n+ 1\n4 reg(h\u2217, hm+1, Z\u0303m)\nFurther recalling that c1 \u2265 2\u03b1 \u221a 6 and c2 \u2265 57\u03b12 by our assumptions on constants, we obtain\n|reg(h, h\u2217, Z\u0303m)\u2212 r\u0303egm(h, h\u2217)| \u2264 1\n2 r\u0303egm(h, h\n\u2217) + 13\u03b7\n72 \u2206m + 6\u2206m +\n1 4 reg(h\u2217, hm+1, Z\u0303m). (34)\nTo complete the proof of the bound (31), we now substitute h = hm+1 in the above bound, which yields\n1 2 r\u0303egm(hm+1, h \u2217)\u2212 5 4 reg(h, h\u2217, Z\u0303m) \u2264 13\u03b7 72 \u2206m + 6\u2206m.\nSince h\u2217 \u2208 Ai for all epochs i \u2264 m, we have r\u0303egm(h, h\u2217) \u2265 reg(h, h\u2217) \u2265 0 for all classifiers h \u2208 H. Consequently, we see that\nreg(h\u2217, hm+1, Z\u0303m) = \u2212reg(hm+1, h\u2217, Z\u0303m) \u2264 52\u03b7\n360 \u2206m +\n24\n5 \u2206m \u2264\n\u03b7 4 \u2206m, (35)\nwhere the last inequality uses the condition 38\u03b7 \u2265 1728. We can now substitute this back into our earlier bound (34) and obtain\n|reg(h, h\u2217, Z\u0303m)\u2212 r\u0303egm(h, h\u2217)|\n\u2264 1 2 r\u0303egm(h, h \u2217) + 13\u03b7 72 \u2206m + 6\u2206m + \u03b7 16 \u2206m \u2264 1 2 r\u0303egm(h, h \u2217) + \u03b7 4 \u2206m,\nwhere we use the condition \u03b7/144 \u2265 6. This completes the proof of the first part of our inductive claim. For the second part, this is almost a by product of the first part through Equation (35). Recalling that \u03b3 \u2265 \u03b7/4 by assumption, this ensures that h\u2217 \u2208 Am+1. We next establish the third part of the claim. This is obtained by combining our bound (35) with Proposition 2. We have\n|errm(h\u2217)\u2212 err(hm+1, Z\u0303m)| \u2264 errm(h\n\u2217)\n2 + 3\u2206m 2 + reg(h\u2217, hm+1, Z\u0303m)\n\u2264 errm(h \u2217)\n2 + 3\u2206m 2 + \u03b7\u2206m 4\n\u2264 errm(h \u2217)\n2 + \u03b7\u2206m 2 ,\nsince \u03b7 \u2265 6. This completes the third part. Finally, note that our analysis has been conditioned on the event E so far. By Lemma 2, Pr(EC) \u2264 \u03b4, which completes the proof of the theorem. We now provide a proof for Theorem 1."}, {"heading": "7.2.2 Proof of Theorem 1", "text": "We only prove the first part of the theorem. The second part is simply a restatement of the inequality (32) in Theorem 5. The first part is essentially a restatement of (31) in Theorem 5, except the bound uses \u2206\u2217m instead of \u2206m. In order to prove the theorem, pick any epoch m \u2264M and h \u2208 Am+1. Because h\u2217 \u2208 Aj , 1 \u2264 j \u2264 m+ 1, we have by Lemma 1 that reg(h) \u2264 r\u0303egm(h, h\u2217). It then suffices to bound r\u0303egm(h, h \u2217). By the deviation bound (31), we have\nr\u0303egm(h, h \u2217) \u2264 reg(h, h\u2217, Z\u0303m) +\n1 2 r\u0303egm(h, h \u2217) + \u03b7 4 \u2206m\n\u2264 reg(h, hm+1, Z\u0303m) + 1\n2 r\u0303egm(h, h\n\u2217) + \u03b7\n4 \u2206m\n\u2264 1 2 r\u0303egm(h, h \u2217) +\n( \u03b3 + \u03b7\n4\n) \u2206m.\nRearranging terms leads to r\u0303egm(h, h\n\u2217) \u2264 4\u03b3\u2206m because \u03b3 \u2265 \u03b7/4. Now we show that \u2206m \u2264 4\u2206\u2217m, which leads to the desired result. It is trivially true for m = 1 because \u2206\u22171 = \u22061. For m \u2265 2, by the deviation bound on the empirical error (33) we have\n\u2206m \u2264 c1 \u221a m ( 3\n2 errm(h\u2217) +\n\u03b7 2 \u2206m\n) + c2 m log \u03c4m\n\u2264 2c1 \u221a merrm(h\u2217) + \u221a c21 m\u03b7\n2 \u2206m + c2 m log \u03c4m\n\u2264 2c1 \u221a merrm(h\u2217) + c21 m\u03b7\n4 + \u2206m 2 + c2 m log \u03c4m\n\u2264 2\u2206\u2217m + \u2206m 2 ,\nwhere the last inequality uses our choice of constants c21\u03b7/4 \u2264 c2. Rearranging terms completes the proof."}, {"heading": "8 Conclusion", "text": "In this paper, we proposed a new algorithm for agnostic active learning in a streaming setting. The algorithm has strong theoretical guarantees, maintaining good generalization properties while attaining a low label complexity in favorable settings. Specifically, we show that the algorithm has an optimal performance in a disagreement-based analysis of label complexity, as well in special cases such as realizable problems and under Tsybakov\u2019s low-noise condition. Additionally, we present an interesting example that highlights the structural difference between our algorithm and some predecessors in terms of label complexities. Indeed a key improvement of our algorithm is that we do not always need to query over the entire disagreement region\u2013a limitation of most computationally efficient predecessors. This is achieved through a careful construction of an optimization problem defining good query probability functions, which relies on using refined data-dependent error estimates.\nThe strong theoretical properties of our algorithm are also mirrored in the extensive empirical evaluation of an online variant, which performs well against a number of strong baselines across a suite of 23 datasets. Indeed this comprehensive empirical evaluation on a range of diverse datasets has not been previously done for agnostic active learning algorithms before to our knowledge, and is a key contribution of this work.\nWe believe that our work naturally leads to several interesting directions for future research. As the example in Section 4.2.2 reveals, the worst-case label complexity analysis in Theorem 2 is rather pessimistic. It would be interesting to obtain sharper characterization of the label complexity, by exploiting the structure of the query probability function over the disagreement region. This would likely involve understanding more fine-grained properties that make a problem easy or hard for active learning beyond the disagreement coefficient, and such a development might also lead to better algorithms. A limitation of the current theory is the somewhat poor dependence in Theorem 4 on the number of unlabeled examples needed to solve the optimization problem. Ideally, we would like to be able to use O(\u03c4m) unlabeled examples to solve (OP) at epoch m, and improving this dependence is perhaps the most important direction for future work. Finally, while AC is extremely attractive from a theoretical standpoint, a direct implementation still seems somewhat impractical. Obtaining theory for an algorithm even closer to the practical variant OAC would be an important step in bringing the theory and implementation closer."}, {"heading": "Acknowledgements", "text": "The authors would like to thank Kamalika Chaudhuri for helpful initial discussions."}, {"heading": "A Deviation bound", "text": "We use an adaptation of Freedman\u2019s inequality [Freedman, 1975] as the main concentration tool.\nLemma 6. Let X1, X2, . . . , Xn be a martingale difference sequence adapted to the filtration Fi. Suppose there exists a function bn of X1, . . . , Xn that satisfies\n\u22001 \u2264 i \u2264 n, |Xi| \u2264 bn, 1 \u2264 bn \u2264 bmax,\nwhere bmax is a non-random quantity that may depend on n. Define\nSn := n\u2211 i=1 Xi,\nVn := n\u2211 i=1 E[X2i | Fi\u22121].\nPick any 0 < \u03b4 < 1/e2 and n \u2265 3. We have Pr ( Sn \u2265 2 \u221a Vn log(1/\u03b4) + 3bn log(1/\u03b4) ) \u2264 4 \u221a \u03b4(2 + log2 bmax) log n.\nProof. Define rj := 2j for \u22121 \u2264 j \u2264 m := dlog2 bmaxe. Then we have Pr ( Sn \u2265 2 \u221a Vn log(1/\u03b4) + 3bn log(1/\u03b4) ) =\nm\u2211 j=0 Pr ( Sn \u2265 2 \u221a Vn log(1/\u03b4) + 3bn log(1/\u03b4) \u2227 rj\u22121 < bn \u2264 rj ) \u2264\nm\u2211 j=0 Pr ( Sn \u2265 2 \u221a Vn log(1/\u03b4) + 3rj\u22121 log(1/\u03b4) \u2227 bn \u2264 rj )\n\u2264 m\u2211 j=0 Pr\n( Sn \u2265 2 \u221a Vn log(1/\u03b4)\n2 + 3rj\nlog(1/\u03b4)\n2 \u2227 bn \u2264 rj\n)\n\u2264 m\u2211 j=0 4(log n) \u221a \u03b4 (36) \u2264 4 \u221a \u03b4(2 + log2 bmax) log n,\nwhere (36) is a direct consequence of Lemma 3 of Kakade and Tewari [2009] and the others result from simple algebra."}, {"heading": "B Auxiliary results for Theorem 1", "text": "Before presenting our regret analysis, we first establish several useful results.\nLemma 7. The threshold defined in (2) and the minimum probability Pmin,m defined in (7) satisfy the following for all m \u2265 1,\n\u03c4m\u22121\u2206m\u22121 \u2264 \u03c4m\u2206m, (37) Pmin,m \u2265 Pmin,m+1, (38) m\nPmin,m \u2264 \u2206m. (39)\nProof. Notice that\n\u03c4m\u22121 m\u22121 = 32(log(|H|/\u03b4) + log \u03c4m\u22121) \u2264 32(log(|H|/\u03b4) + log \u03c4m) = \u03c4m m. (40)\nWe first prove (37). It holds trivially for m = 1. For m \u2265 2 we have\n\u03c4m\u22121\u2206m\u22121\n= c1 \u221a \u03c42m\u22121 m\u22121err(hm, Z\u0303m\u22121) + c2\u03c4m\u22121 m\u22121 log \u03c4m\u22121\n\u2264 c1 \u221a (\u03c4m\u22121 m\u22121)\u03c4m\u22121err(hm+1, Z\u0303m\u22121) + c2\u03c4m\u22121 m\u22121 log \u03c4m\u22121\n\u2264 c1 \u221a (\u03c4m m)\u03c4merr(hm+1, Z\u0303m) + c2\u03c4m m log \u03c4m\n= \u03c4m\u2206m,\nwhere the first inequality is by the fact that hm minimizes the empirical error on Z\u0303m\u22121 and the second inequality is by \u03c4m\u22121 m\u22121 \u2264 \u03c4m m. Then for (38), it is easy to see\u221a\n\u03c4m\u22121err(hm, Z\u0303m\u22121)\nn M + log \u03c4m\u22121\n\u2264\n\u221a \u03c4m\u22121err(hm+1, Z\u0303m\u22121)\nn M + log \u03c4m\u22121\n\u2264\n\u221a \u03c4merr(hm+1, Z\u0303m)\nn M + log \u03c4m,\nfor m \u2265 1, implying Pmin,m \u2265 Pmin,m+1. Finally to prove (39), we have that\nm Pmin,m \u2264 m Pmin,m+1\n= max\n \u221a \u03c4m 2merr(hm+1, Z\u0303m)/(n M ) + m log \u03c4m\nc3 , 2 m  \u2264 max  \u221a merr(hm+1, Z\u0303m) + m log \u03c4m\nc3 , 2 m  \u2264 \u2206m,\nwhere the second inequality is by \u03c4m m \u2264 n M , and the third inequality is by our choices of c1, c2 and c3.\nWe also need a lemma regarding the epoch schedule.\nLemma 8. Let \u03c4m\u22121 < \u03c4m \u2264 2\u03c4m\u22121 for all m > 1. Then we have for all m \u2265 1, m\u2211 i=1 \u03c4i+1 \u2212 \u03c4i \u03c4i \u2264 4 log \u03c4m+1,\nm\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)\u2206i\u22121 \u2264 4\u03c4m\u2206m log \u03c4m.\nProof. Note that we can rewrite the summation in question as\nm\u2211 i=1 \u03c4i+1 \u2212 \u03c4i \u03c4i = m\u2211 i=1 \u03c4i+1\u2211 j=\u03c4i+1 1 \u03c4i\n\u2264 m\u2211 i=1 \u03c4i+1\u2211 j=\u03c4i+1 2 \u03c4i+1 ,\nwhere the second inequality uses our assumption on epoch lengths. The summation can then be further bounded as\nm\u2211 i=1 \u03c4i+1 \u2212 \u03c4i \u03c4i \u2264 m\u2211 i=1 \u03c4i+1\u2211 j=\u03c4i+1 2 j \u2264 \u03c4m+1\u2211 i=1 2 i\n\u2264 2(1 + log \u03c4m+1) (41) \u2264 4 log \u03c4m+1,\nwhere the third inequality is by the bound \u2211n i=1 1/i \u2264 1 + log n, and the final inequality is by 1 \u2264 log \u03c4m,m \u2265 1. To prove the second bound in the lemma, we write\nm\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)\u2206i\u22121 = \u03c41\u22060 + m\u22121\u2211 i=1 (\u03c4i+1 \u2212 \u03c4i)\u2206i\n= \u03c41\u22060 + m\u22121\u2211 i=1 \u03c4i+1 \u2212 \u03c4i \u03c4i \u03c4i\u2206i \u2264 \u03c41\u22060 + (2 + 2 log \u03c4m)\u03c4m\u2206m \u2264 (2 log \u03c41 \u2212 2)\u03c41\u22061 + (2 + 2 log \u03c4m)\u03c4m\u2206m \u2264 (2 log \u03c4m \u2212 2)\u03c4m\u2206m + (2 + 2 log \u03c4m)\u03c4m\u2206m = 4\u03c4m\u2206m log \u03c4m,\nwhere the first inequality is by (41) and \u03c4i\u2206i \u2264 \u03c4m\u2206m (Lemma 7), the second inequality is by our choice of \u22060 and the fact that \u03c41\u22061 \u2264 1, and the third inequality again uses \u03c4i\u2206i \u2264 \u03c4m\u2206m."}, {"heading": "C Proofs omitted from Section 7.2", "text": "We now provide the proofs of the lemmas and propositions from Section 7.2 that were used in proving Theorem 1. We start with proofs of Lemmas 1 and 2. Proof of Lemma 1\nPick any m \u2265 1, h \u2208 H and h\u0304 \u2208 Am. Note that the definitions of reg\u2021m(h, h\u0304) and reg(h, h\u0304) only differ on X /\u2208 Dm := DIS(Am), and \u2200X /\u2208 Dm, h\u0304(X) = hm(X). We thus have\nreg\u2021m(h, h\u0304)\u2212 reg(h, h\u0304) = EX,Y [ 1(X /\u2208 Dm) (( 1(h(X) 6= hm(X))\u2212 1(h\u0304(X) 6= hm(X)) ) \u2212 ( 1(h(X) 6= Y )\u2212 1(h\u0304(X) 6= Y )\n))] = EX,Y [1(X /\u2208 Dm) ( 1(h(X) 6= hm(X))\u2212 (1(h(X) 6= Y )\u2212 1(hm(X) 6= Y )) ) ].\nThe desired result then follows from the inequality that\n1(h(X) 6= Y )\u2212 1(hm(X) 6= Y ) \u2264 1(h(X) 6= hm(X)).\nProof of Lemma 2 Our proof strategy is to apply Lemma 6 to establish concentration of properly defined martingale difference sequences for fixed classifiers h, h\u2032 and some epochm, and then use a union bound to get the desired statement. First we look at the concentration of the empirical regret on Z\u0303m. To avoid clutter, we overload our notation so thatDi = Dm(i), hi = hm(i) and Pi = Pm(i) when i is the index of an example rather than a round.\nFor any pair of classifiers h and h\u2032, we define the random variables for the instantaneous regrets:\nR\u0303i := 1(Xi /\u2208 Di)(1(h(Xi) 6= hi(Xi))\u2212 1(h\u2032(Xi) 6= hi(Xi))) + 1(Xi \u2208 Di)(1(h(Xi) 6= Yi)\u2212 1(h\u2032(Xi) 6= Yi))Qi/Pi(Xi)\nand the associated \u03c3-fields Fi := \u03c3({Xj , Yj , Qj}ij=1). We have that R\u0303i is measurable with respect to Fi. Therefore R\u0303i \u2212E[R\u0303i | Fi\u22121] forms a martingale difference sequence adapted to the filtrations Fi, i \u2265 1, and\nE[R\u0303i | Fi\u22121] = reg\u2021m(i)(h, h \u2032)\naccording to (27) and the fact that Xi, Yi, Qi are independent from the past. To use Lemma 6, we first identify an upper bound on elements in the sequence:\n|R\u0303i \u2212E[R\u0303i | Fi\u22121]| = |R\u0303i \u2212 reg\u2021m(i)(h, h \u2032)| \u2264 max(R\u0303i, reg\u2021m(i)(h, h \u2032))\n\u2264 1 Pmin,m(i) \u2264 1 Pmin,m , (42)\nfor all i such that m(i) \u2264 m, where the last inequality is by Lemma 7. The definition of Pmin,m implies that\n1\nPmin,m \u2264 max(\n\u221a \u03c4m\u22121/(n M ) + log \u03c4m\u22121, 2) \u2264 2 \u221a \u03c4m\u22121 + 1 (43)\nbecause n M \u2265 1. Then we consider the conditional second moment. Using the fact that\n(1(h(Xi) 6= Yi)\u2212 1(h\u2032(Xi) 6= Yi))2 \u2264 1(h(Xi) 6= h\u2032(Xi)), (44)\nwe get\nE[(R\u0303i \u2212E[R\u0303i | Fi\u22121])2 | Fi\u22121] = E[(R\u0303i \u2212 reg\u2021m(i)(h, h \u2032))2 | Fi\u22121] \u2264 E[R\u03032i | Fi\u22121]\n\u2264 E [( 1(Xi /\u2208 Di) +\n1(Xi \u2208 Di)Qi Pi(Xi)\n)2 1(h(Xi) 6= h\u2032(Xi)) | Fi\u22121 ]\n= E [( 1(Xi /\u2208 Di) +\n1(Xi \u2208 Di)Qi Pi(Xi)2\n) 1(h(Xi) 6= h\u2032(Xi)) | Fi\u22121 ] = E [( 1(Xi /\u2208 Di) +\n1(Xi \u2208 Di) Pi(Xi)\n) 1(h(Xi) 6= h\u2032(Xi)) | Fi\u22121 ] = EX [( 1(X /\u2208 Di) +\n1(X \u2208 Di) Pi(X)\n) 1(h(X) 6= h\u2032(X)) ] = EX [( 1(X /\u2208 Dm(i)) +\n1(X \u2208 Dm(i)) Pm(i)(X)\n) 1(h(X) 6= h\u2032(X)) ] (45)\nwhere the last two equalities are from the fact that Xi is independent from the past and replacing our overloaded notation respectively. Lemma 6 with (42), (43), and (45) then implies for any 0 < \u03b4m < 1/e2 and m \u2265 1, the following holds with probability at most 8 \u221a \u03b4m(2 + log2(2 \u221a \u03c4m\u22121 + 1)) log \u03c4m:\n|reg(h, h\u2032, Z\u0303m)\u2212 r\u0303egm(h, h\u2032)|\n\u2265 \u221a\u221a\u221a\u221a4 log(1/\u03b4m) \u03c42m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)EX [( 1(X /\u2208 Di) + 1(X \u2208 Di) Pi(X) ) 1(h(X) 6= h\u2032(X)) ]\n+ 4 log(1/\u03b4m)\nnPmin,m . (46)\nThen we consider the concentration of the empirical error on the importance-weighted examples. Define the random examples for the empirical errors:\nEi := Qi1(h(Xi) 6= Yi \u2227Xi \u2208 Di)\nPi(Xi)\nand the associated \u03c3-fields Fi := \u03c3({Xj , Yj , Qj}ij=1). By the same analysis of the sequence of instantaneous regrets, we have Ei \u2212 E[Ei | Fi\u22121] is a martingale difference sequence adapted to the filtrations Fi, i \u2265 1, with the following properties:\nE[Ei | Fi\u22121] = E[1(Xi \u2208 Di \u2227 h(Xi) 6= Yi) | Fi\u22121] = errm(i)(h),\n|Ei \u2212 E[Ei | Fi\u22121]| \u2264 1 Pmin,m(i) \u2264 1 Pmin,m\n\u2264 2 \u221a \u03c4m\u22121 + 1,\nfor all i such that m(i) \u2264 m. Furthermore,\nE[(Ei \u2212 E[Ei | Fi\u22121])2 | Fi\u22121] \u2264 E [ 1(Xi \u2208 Di \u2227 h(Xi) 6= Yi)\nPi(Xi) \u2223\u2223\u2223\u2223 Fi\u22121] = EX,Y [ 1(X \u2208 Di \u2227 h(X) 6= Y )\nPi(X)\n] .\nWith these properties, Lemma 6 then implies for any 0 < \u03b4m < 1/e2 and m \u2265 1, the following holds with probability at most 8 \u221a \u03b4m(2 + log2(2 \u221a \u03c4m\u22121 + 1)) log \u03c4m:\n|err(h, Zm)\u2212 errm(h)| \u2265 \u221a\u221a\u221a\u221a4 log(1/\u03b4m) \u03c42m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)EX,Y [ 1(X \u2208 Di \u2227 h(X) 6= Y ) Pi(X) ]\n+ 4 log(1/\u03b4m)\nnPmin,m . (47)\nSetting\n\u03b4m =\n( \u03b4\n192|H|2\u03c42m(log \u03c4m)2 )2 ensures that the probability of the union of the bad events (46), and (47) over all pairs of classifiers h, h\u2032 and m \u2265 1 is bounded by \u03b4 > 0. Choosing \u03b4 \u2264 |H|/ \u221a 192, we have\nlog(1/\u03b4m) = 2 log\n( 192|H|2\u03c42m(log \u03c4m)2\n\u03b4 ) \u2264 2(2 log(|H|/\u03b4) + 4 log \u03c4m + log 192) \u2264 8(log(|H|/\u03b4) + log \u03c4m),\nleading to the desired statement.\nWe then provide the proofs of Propositions 1 and 2. Proof of Proposition 1 By the inequality (29) of Lemma 2, we have\n|reg(h, h\u2217, Z\u0303m)\u2212 r\u0303egm(h, h\u2217)|\n\u2264 \u221a\u221a\u221a\u221a\u221a\u221a\u221a m \u03c4m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)EX [( 1(X /\u2208 Di) + 1(X \u2208 Di) Pi(X) ) 1(h(X) 6= h\u2217(X)) ] \ufe38 \ufe37\ufe37 \ufe38\ndevm(h)\n+ m\nPmin,m (48)\nWe now control the term devm(h) in order to establish the proposition. We have\n\u03c4m m devm(h)\n= m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)EX [( 1(X \u2208 Di) Pi(X) + 1(X /\u2208 Di) ) 1(h(X) 6= h\u2217(X)) ]\n\u2264 m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)EX [ 1(X \u2208 Di) Pi(X) ( 1(h(X) 6= hi(X)) + 1(h\u2217(X) 6= hi(X)) ) + 1(X /\u2208 Di)1(h(X) 6= h\u2217(X))\n] \u2264\nm\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)EX [ 2\u03b121(X \u2208 Di) ( 1(h(X) 6= hi(X)) + 1(h\u2217(X) 6= hi(X)) ) + 2\u03b22\u03b3\u03c4i\u22121\u2206i\u22121(reg(h, Z\u0303i\u22121) + reg(h \u2217, Z\u0303i\u22121)) + 2\u03be\u03c4i\u22121\u2206 2 i\u22121\n+ 1(h(X) 6= h\u2217(X) \u2227X /\u2208 Di) ] ,\nwhere the second inequality uses our variance constraints in defining the distribution Pi for classifiers h and h\u2217. Note that\n1(h(X) 6= h\u2217(X)) \u2264 1(h(X) 6= Y ) + 1(h\u2217(X) 6= Y ) = (1(h(X) 6= Y )\u2212 1(h\u2217(X) 6= Y )) + 21(h\u2217(X) 6= Y ),\nso that the final inequality can be rewritten as\n\u03c4m m devm(h)\n\u2264 m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121) [ 2\u03b12(regi(h) + 2regi(hi)) + 12\u03b1 2erri(h \u2217) + 2\u03b22\u03b3\u03c4i\u22121\u2206i\u22121(reg(h, Z\u0303i\u22121)\n+ reg(h\u2217, Z\u0303i\u22121)) + 2\u03be\u03c4i\u22121\u2206 2 i\u22121 + EX [1(h(X) 6= h\u2217(X) \u2227X /\u2208 Di)]\n] .\nWith the assumptions \u03b1 \u2265 1 and h\u2217 \u2208 Ai for all epochs i \u2264 m, the first term regi(h) can be combined with the last disagreement term and bounded by 2\u03b12reg\u2021i (h). Further noting that \u03c4i\u22121\u2206i\u22121 \u2264 \u03c4m\u2206m by Lemma 7, we can further\nsimplify the inequality to\n\u03c4m m devm(h) \u2264 2\u03b12 m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)reg\u2021i (h) + 4\u03b1 2 m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)regi(hi) + 12\u03c4m\u03b12errm(h\u2217)\n+ 2\u03b22\u03b3\u03c4m\u2206m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)(reg(h, Z\u0303i\u22121)\n+ reg(h\u2217, Z\u0303i\u22121)) + 2\u03be m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)\u03c4i\u22121\u22062i\u22121.\nThe first summand is simply 2\u03b12\u03c4mr\u0303egm(h) by definition. The final summand above can be bounded using Lemmas 7 and 8 since\nm\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)\u03c4i\u22121\u22062i\u22121 = m\u22121\u2211 i=1 (\u03c4i+1 \u2212 \u03c4i)\u03c4i\u22062i \u2264 \u03c4m\u2206m m\u22121\u2211 i=1 (\u03c4i+1 \u2212 \u03c4i)\u2206i\n\u2264 4\u03c42m\u22062m log \u03c4m.\nSubstituting the above inequalities back, we obtain\n\u03c4m m devm(h) \u2264 2\u03b12\u03c4mr\u0303egm(h) + 4\u03b12 m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)regi(hi) + 12\u03c4m\u03b12errm(h\u2217)\n+ 2\u03b22\u03b3\u03c4m\u2206m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)(reg(h, Z\u0303i\u22121) + reg(h\u2217, Z\u0303i\u22121)) + 8\u03be\u03c42m\u22062m log \u03c4m.\nSince \u221a a+ b \u2264 \u221a a+ \u221a b, we can further bound\n\u221a devm(h) \u2264 \u221a 2\u03b12 mr\u0303egm(h) + 2\u03b1 \u221a\u221a\u221a\u221a m \u03c4m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)regi(hi) + 2\u03b1 \u221a 3errm(h\u2217) m\n+ \u03b2 \u221a\u221a\u221a\u221a2\u03b3 m\u2206m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)(reg(h, Z\u0303i\u22121) + reg(h\u2217, Z\u0303i\u22121))\n+ 2\u2206m \u221a 2\u03be\u03c4m m log \u03c4m.\nSubstituting this inequality back into our deviation bound (48), we obtain\n|reg(h, h\u2217, Z\u0303m)\u2212 r\u0303egm(h, h\u2217)|\n\u2264 m Pmin,m\n+ \u221a\n2\u03b12 mr\u0303egm(h) + 2\u03b1 \u221a\u221a\u221a\u221a m \u03c4m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)regi(hi) + 2\u03b1 \u221a 3errm(h\u2217) m\n+ \u03b2 \u221a\u221a\u221a\u221a2\u03b3 m\u2206m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)(reg(h, Z\u0303i\u22121) + reg(h\u2217, Z\u0303i\u22121)) + 2\u2206m \u221a 2\u03be\u03c4m m log \u03c4m.\nWe can further use Cauchy-Schwarz inequality to obtain the bound\n|reg(h, h\u2217, Z\u0303m)\u2212 r\u0303egm(h, h\u2217)|\n\u2264 1 4 r\u0303egm(h) + 2\u03b1 2 m + 2\u03b1 \u221a\u221a\u221a\u221a m \u03c4m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)regi(hi) + 2\u03b1 \u221a 3errm(h\u2217) m\n+ \u03b2 \u221a\u221a\u221a\u221a2\u03b3 m\u2206m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)(reg(h, Z\u0303i\u22121) + reg(h\u2217, Z\u0303i\u22121)) + 2\u2206m \u221a 2\u03be\u03c4m m log \u03c4m\n+ m\nPmin,m\n\u2264 1 4 r\u0303egm(h) + 2\u03b1 2 m + 2\u03b1 \u221a\u221a\u221a\u221a m \u03c4m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)regi(hi) + 2\u03b1 \u221a 3errm(h\u2217) m\n+ \u03b2 \u221a\u221a\u221a\u221a2\u03b3 m\u2206m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)(reg(h, Z\u0303i\u22121) + reg(h\u2217, Z\u0303i\u22121)) + \u2206m + m Pmin,m\n\u2264 1 4 r\u0303egm(h) + 2\u03b1 \u221a\u221a\u221a\u221a m \u03c4m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)regi(hi) + 2\u03b1 \u221a 3errm(h\u2217) m\n+ \u03b2 \u221a\u221a\u221a\u221a2\u03b3 m\u2206m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)(reg(h, Z\u0303i\u22121) + reg(h\u2217, Z\u0303i\u22121)) + 4\u2206m\nwhere the last two inequalities use our assumptions on \u03be and \u03b1 respectively.\nProof of Proposition 2 We start by observing that\n|errm(h\u2217)\u2212 err(hm+1, Z\u0303m)| \u2264 |errm(h\u2217)\u2212 err(h\u2217, Z\u0303m)|+ reg(h\u2217, hm+1, Z\u0303m).\nSince h\u2217 \u2208 Ai for all epochs i \u2264 m, we know that h\u2217 agrees with all the predicted labels. Consequently, err(h\u2217, Z\u0303m) = err(h\u2217, Zm), where we recall that Zm is the set of all examples where we queried labels up to epoch m. This allows us to rewrite\n|errm(h\u2217)\u2212 err(h\u2217, Z\u0303m)| = |errm(h\u2217)\u2212 err(h\u2217, Zm)|.\nUnder the event E , the above deviation is bounded, according to Lemma 2, by\u221a\u221a\u221a\u221a m \u03c4m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)EX,Y 1(h\u2217(X) 6= Y,X \u2208 Di) Pi(X) + m Pmin,m \u2264 \u221a m errm(h\u2217) Pmin,m + m Pmin,m ,\nwhere the inequality uses the bound Pi(X) \u2265 Pmin,i for all X \u2208 Di and Pmin,i \u2265 Pmin,m for all epochs i \u2264 m by Lemma 7. A further application of Cauchy-Schwarz inequality yields the bound\n|errm(h\u2217)\u2212 err(h\u2217, Z\u0303m)| \u2264 errm(h\n\u2217)\n2 + 3 m 2Pmin,m\n\u2264 errm(h \u2217)\n2 + 3\u2206m 2 .\nCombining the bounds yields\n|errm(h\u2217)\u2212 err(hm+1, Z\u0303m)| \u2264 errm(h\n\u2217)\n2 + 3\u2206m 2 + reg(h\u2217, hm+1, Z\u0303m),\nwhich completes the proof of the proposition.\nFinally, we prove Lemmas 3 to 5 used in the proof of Theorem 1. Proof of Lemma 3 We first bound the regi(hi) terms. For i = 1, we have\nreg1(h1) = reg(h1) \u2264 1 \u2264 \u03b7\u22060\n2\nby Pmin,1 = 1 and our choices of \u03b7 and \u22060. For 2 \u2264 i < m, we have\nregi(hi) = EX,Y [1(hi(X) 6= Y,X \u2208 Di)\u2212 1(h\u2217(X) 6= Y,X \u2208 Di)] = reg(hi) \u2264 r\u0303egi\u22121(hi, h\u2217),\nwhere the second equality uses the fact that h\u2217 \u2208 Ai for all i \u2264 m by inductive hypothesis (9) and the inequality uses Lemma 1. Consequently, we can bound regi\u22121(hi) using the event Ei, since reg(hi, h\u2217, Z\u0303i\u22121) = 0. The event Ei now further implies that\nregi(hi) \u2264 r\u0303egi\u22121(hi, h\u2217) \u2264 2reg(hi, h\u2217, Z\u0303i\u22121) + \u03b7\u2206i\u22121 2 \u2264 \u03b7\u2206i\u22121 2 .\nUsing this, we can simplify T1 as\nT1 = 2\u03b1 \u221a\u221a\u221a\u221a m \u03c4m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)regi(hi) \u2264 2\u03b1 \u221a\u221a\u221a\u221a m \u03c4m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121) \u03b7\u2206i\u22121 2 (49)\n\u2264 2\u03b1 \u221a\n2\u03b7 m\u2206m log \u03c4m\n\u2264 \u03b7\u2206m 12 + 24\u03b12 m log \u03c4m. (50)\nhere the second inequality is by Lemma 8 and the third inequality is by Cauchy-Schwarz.\nProof of Lemma 4 We first invoke Proposition 2, whose assumptions now hold due to the claim h\u2217 \u2208 Ai in Ei for all i \u2264 m, and obtain\nerrm(h \u2217) = 2err(hm+1, Z\u0303m) + 3\u2206m + 2reg(h \u2217, hm+1, Z\u0303m).\nThe above inequality allows us to simplify T2 as\nT2 = 2\u03b1 \u221a 3 merrm(h\u2217) \u2264 2\u03b1 \u221a 3 m ( 2err(hm+1, Z\u0303m) + 3\u2206m + 2reg(h\u2217, hm+1, Z\u0303m) ) \u2264 2\u03b1 \u221a 6 merr(hm+1, Z\u0303m) + 2\u03b1 \u221a 9 m\u2206m + 2\u03b1 \u221a 6 mreg(h\u2217, hm+1, Z\u0303m)\n\u2264 2\u03b1 \u221a 6 merr(hm+1, Z\u0303m) + \u2206m + 1\n4 reg(h\u2217, hm+1, Z\u0303m) + 33\u03b1 2 m, (51)\nwhere the last inequality uses the Cauchy-Schwarz inequality.\nProof of Lemma 5 Observe that the event Ei gives a direct bound of \u03b7\u2206i\u22121/4 on the reg(h\u2217, hi, Z\u0303i\u22121) terms. For the other term, recall by the same event that for all h \u2208 H and for all i = 1, 2 . . . ,m\u2212 1,\nreg(h, h\u2217, Z\u0303i) \u2264 3\n2 r\u0303egi(h, h\n\u2217) + \u03b7\n4 \u2206i.\nCombining with the empirical regret bound for h\u2217, this implies that\nreg(h, Z\u0303i) \u2264 3\n2 r\u0303egi(h, h\n\u2217) + \u03b7\n2 \u2206i.\nConsequently we have the bound\nT 23 \u2264 \u03b22\u03b3\u2206m m m\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121) ( 3r\u0303egi\u22121(h, h \u2217) + 3\u03b7 2 \u2206i\u22121 )\nTo simplify further, note that by the definition of r\u0303egi(h, h \u2217) and our earlier definition of reg\u2021i (h, h \u2217), we have\nm\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)r\u0303egi\u22121(h, h\u2217) = m\u22121\u2211 i=1 \u03c4i+1 \u2212 \u03c4i \u03c4i i\u2211 j=1 (\u03c4j \u2212 \u03c4j\u22121)reg\u2021j(h, h \u2217)\n= m\u22121\u2211 j=1 (\u03c4j \u2212 \u03c4j\u22121)reg\u2021j(h, h \u2217) m\u22121\u2211 i=j \u03c4i+1 \u2212 \u03c4i \u03c4i \u2264 4 log \u03c4m m\u22121\u2211 j=1 (\u03c4j \u2212 \u03c4j\u22121)reg\u2021j(h, h \u2217) \u2264 4\u03c4m log \u03c4m r\u0303egm(h, h\u2217),\nwhere the first equality uses our convention r\u0303eg0(h, h \u2217) = 0 and proper index shifting, and the first inequality uses Lemma 8. We also have\nm\u2211 i=1 (\u03c4i \u2212 \u03c4i\u22121)\u2206i\u22121 \u2264 4\u03c4m\u2206m log \u03c4m.\nby Lemma 8. Consequently, we can rewrite\nT 23 \u2264 \u03b22\u03b3\u2206m m ( 12\u03c4m log \u03c4m r\u0303egm(h, h \u2217) + 6\u03c4m\u03b7 log \u03c4m\u2206m )\n= \u03b22\u03b3\u03c4m m log \u03c4m\u2206m ( 12r\u0303egm(h, h \u2217) + 6\u03b7\u2206m ) \u2264 \u03b7\u2206mr\u0303egm(h, h \u2217)\n72 + \u03b72\u22062m 144 ,\nwhere the last inequality is by our choice of \u03b2 such that \u03b22\u03b3n n log n \u2264 \u03b7/864. Taking square roots, we obtain\nT3 \u2264 \u221a \u03b7\u2206mr\u0303egm(h, h \u2217)\n72 + \u03b72\u22062m 144\n\u2264 1 4 r\u0303egm(h, h \u2217) + 7\u03b7\u2206m 72\n(52)"}, {"heading": "D Label Complexity", "text": "Here we prove Theorem 2. Fix any epoch m and index i \u2264 \u03c4m. Consider Xi \u2208 Dm and define\nh\u0304i := { hm, hm(Xi) 6= h\u2217(Xi), h\u2032i, h \u2032 i(Xi) 6= h\u2217(Xi),\nwhere h\u2032i := arg minh\u2208H\u2227h(Xi)6=hm(Xi) err(h, Z\u0303m\u22121). Because Xi \u2208 DIS(Am), we have h\u2032i \u2208 Am, implying h\u0304i \u2208 Am. Theorem 5 shows that h\u2217 \u2208 Am, so we have\nPr(h\u0304i(X) 6= h\u2217(X)) = Pr(h\u0304i(X) 6= h\u2217(X) \u2227X \u2208 Dm) \u2264 regm(h\u0304i) + 2errm(h\u2217) \u2264 16\u03b3\u2206\u2217m\u22121 + 2errm(h\u2217),\nwhere the last inequality is by Theorem 1. This implies that\nXi \u2208 DIS({h | Pr(h(X) 6= h\u2217(X)) \u2264 16\u03b3\u2206\u2217m\u22121 + 2errm(h\u2217)}).\nWe thus have\nE[1(Xi \u2208 DIS(Am))] \u2264 E[1(Xi \u2208 DIS({h | Pr(h(X) 6= h\u2217(X)) \u2264 16\u03b3\u2206\u2217m\u22121 + 2errm(h\u2217)}))] \u2264 \u03b8(16\u03b3\u2206\u2217m\u22121 + 2errm(h\u2217)),\nwhere we the last inequality uses the definition of the disagreement coefficient\n\u03b8(h\u2217) := sup r>0 Pr({X | \u2203h \u2208 H s.t. Pr(h(X) 6= h\u2217(X)) \u2264 r, h\u2217(X) 6= h(X)}) r .\nThe expected number of label queries made by our algorithm after seeing n examples is upper-bounded w.p. 1\u2212 \u03b4 by\n3 + n\u2211 i=4 E[1(Xi \u2208 Dm(i))] \u2264 3 + M\u2211 j=2 (\u03c4j \u2212 \u03c4j\u22121)\u03b8(16\u03b3\u2206\u2217j\u22121 + 2errj(h\u2217))\n\u2264 3 + 2n\u03b8errM (h\u2217) + 16\u03b3\u03b8 M\u2211 j=2 (\u03c4j \u2212 \u03c4j\u22121)\u2206\u2217j\u22121\n= 3 + 2n\u03b8errM (h \u2217) + 16\u03b3\u03b8 M\u2211 j=2 (\u03c4j \u2212 \u03c4j\u22121) \u03c4j\u22121 \u03c4j\u22121\u2206 \u2217 j\u22121.\nA similar argument as Lemma 7 shows that \u03c4j\u2206\u2217j is increasing in j, so we have by a further invocation of Lemma 8\n3 + n\u2211 i=4 E[1(Xi \u2208 Dm(i))]\n\u2264 3 + 2n\u03b8errM (h\u2217) + 128\u03b3\u03b8(n\u2212 1)\u2206\u2217M\u22121 log(n\u2212 1) = 3 + 2n\u03b8errM (h \u2217)\n+\u03b8O (\u221a nerrM (h\u2217) ( log ( |H| \u03b4 ) log2 n+ log3 n ) + log ( |H| \u03b4 ) log2 n+ log3 n ) ."}, {"heading": "E Proofs for Tsybakov\u2019s low-noise condition", "text": "We begin with a lemma that captures the behavior of the \u2206\u2217m terms, errm(h\n\u2217) and the probability of disagreement region under the Tsybakov noise condition (10). The proofs of Corollaries 2 and 4 are immediate given the lemma.\nLemma 9. Under the conditions of Theorem 1, suppose further that the low-noise condition (10) holds. Then we have for all epochs m = 1, 2, . . . ,M\nerrm(h \u2217) \u2264 c m log \u03c4m \u03c4\n2(1\u2212\u03c9) 2\u2212\u03c9 m , and errm(h\u2217) \u2264 5c m log2 \u03c4m \u03c4 2(1\u2212\u03c9) 2\u2212\u03c9 m . (53)\nProof. We will establish the lemma inductively. We make the following inductive hypothesis. There exists a constant c > 0 (dependent on the distributional parameters) such that for all epochs j \u2265 1, the bounds (53) in the statement of the Lemma hold. The base case for j = 1 trivially follows since err1(h\u2217) = err1(h\u2217) = err(h\u2217) \u2264 1 \u2264 c 1 log \u03c41 \u03c4 2(1\u2212\u03c9) 2\u2212\u03c9 1 , which is clearly true for an appropriately large value of c. Suppose now that the claim is true for epochs j = 1, 2, . . . ,m\u2212 1. We will establish the claim at epoch m. To see this, first note that we have\nerrm(h \u2217) = Pr(1(h\u2217(X) 6= Y,X \u2208 Dm)) \u2264 Pr(X \u2208 Dm).\nUnder the noise condition, we can further upper bound the probability of the disagreement region, since by Theorem 1 we obtain\nPr(X \u2208 Dm) = Pr(X \u2208 DIS(Am)) \u2264 Pr ( X \u2208 DIS({h \u2208 H : reg(h) \u2264 16\u03b3\u2206\u2217m\u22121) ) \u2264 Pr ( X \u2208 DIS(h \u2208 H : Pr(h(X) 6= h\u2217(X)) \u2264 \u03b6 (16\u03b3\u2206\u2217m\u22121)\u03c9) ) ,\nwhere the first inequality follows from Theorem 1 and the second one is a consequence of Tsybakov\u2019s noise condition (10). Recalling the definition of disagreement coefficient (11), this can be further upper bounded by\nPr(X \u2208 Dm) \u2264 \u03b8\u03b6 (16\u03b3\u2206\u2217m\u22121)\u03c9. (54) Hence, we have obtained the bound\nerrm(h \u2217) \u2264 \u03b8\u03b6 (16\u03b3\u2206\u2217m\u22121)\u03c9.\nNote that \u2206\u2217m\u22121 = c1 \u221a m\u22121errm\u22121(h\u2217) + c2 m\u22121 log \u03c4m\u22121. Our inductive hypothesis (53) allows us to upper bound the errm\u22121 in this expression for \u2206\u2217m\u22121 and hence we obtain\n\u2206\u2217m\u22121 \u2264 c1 \u221a m\u22121 5c m\u22121 log 2 \u03c4m\u22121 \u03c4 2(1\u2212\u03c9) 2\u2212\u03c9 m\u22121 + c2 m\u22121 log \u03c4m\u22121\n\u2264 c1 m\u22121 log \u03c4m \u03c4 1\u2212\u03c9 2\u2212\u03c9 m \u221a 5c+ c2 m\u22121 log \u03c4m\u22121\n\u2264 m\u03c4m \u03c4m\u22121 log \u03c4m\n( c1 \u221a 5c\u03c4 1\u2212\u03c9 2\u2212\u03c9 m + c2 ) \u2264 2 m log \u03c4m ( c1 \u221a 5c\u03c4 1\u2212\u03c9 2\u2212\u03c9 m + c2 ) .\nSince \u03c4m \u2265 3 and 0 < \u03c9 \u2264 1, we can further write\n\u2206\u2217m\u22121 \u2264 2 m log \u03c4m \u03c4 1\u2212\u03c9 2\u2212\u03c9 m ( c1 \u221a 5c+ c2 ) . (55)\nSubstituting this inequality in our earlier bound on errm(h\u2217) yields\nerrm(h \u2217) \u2264 \u03b8\u03b6 ( 32\u03b3 m log \u03c4m \u03c4 1\u2212\u03c9 2\u2212\u03c9 m ( c1 \u221a 5c+ c2 ))\u03c9 .\nSince m\u03c4m log \u03c4m \u2265 1 and 0 < \u03c9 \u2264 1, we can further bound\nerrm(h \u2217) \u2264 \u03b8\u03b6 m\u03c4m log \u03c4m ( 32\u03b3 \u03c4 \u22121 2\u2212\u03c9 m ( c1 \u221a 5c+ c2 ))\u03c9 = \u03b8\u03b6 m\u03c4m log \u03c4m ( 32\u03b3 ( c1 \u221a 5c+ c2 ))\u03c9 \u03c4 \u2212\u03c9 2\u2212\u03c9 m\n= \u03b8\u03b6 m\u03c4 2(1\u2212\u03c9) 2\u2212\u03c9 m log \u03c4m ( 32\u03b3 ( c1 \u221a 5c+ c2 ))\u03c9 \u2264 c m log \u03c4m \u03c4 2(1\u2212\u03c9) 2\u2212\u03c9 m .\nHere the last bound follows for any choice of c such that\nc \u2265 \u03b8\u03b6 ( 32\u03b3 ( c1 \u221a 5c+ c2 ))\u03c9 .\nThe above inequality has a solution since the LHS is smaller than the RHS at c = 0, while for c large enough, the LHS grows linearly in c, while the RHS grows as c\u03c9/2, and hence is asymptotically smaller than the LHS.\nWe now verify the second part of our induction hypothesis for epoch m. Note that we have\nerrm(h \u2217) =\n1\n\u03c4m m\u2211 j=1 (\u03c4j \u2212 \u03c4j\u22121)errj(h\u2217)\n\u2264 1 \u03c4m m\u2211 j=1 (\u03c4j \u2212 \u03c4j\u22121) c j log \u03c4j \u03c4 2(1\u2212\u03c9) 2\u2212\u03c9 j\n= 1\n\u03c4m m\u2211 j=1 (\u03c4j \u2212 \u03c4j\u22121) \u03c4j c j\u03c4j log \u03c4j \u03c4 2(1\u2212\u03c9) 2\u2212\u03c9 j .\nWe now observe that \u03c4j is clearly increasing in j, and so is \u03c4j j by definition. Consequently, we can further upper bound this inequality by\nerrm(h \u2217) \u2264 1\n\u03c4m m\u03c4m log \u03c4m m\u2211 j=1 (\u03c4j \u2212 \u03c4j\u22121) \u03c4j c\u03c4 2(1\u2212\u03c9) 2\u2212\u03c9 j\n(a) \u2264 c m log \u03c4m \u03c4 2(1\u2212\u03c9) 2\u2212\u03c9 m 1 + m\u2211 j=2 (\u03c4j \u2212 \u03c4j\u22121) \u03c4j  = c m log \u03c4m \u03c4 2(1\u2212\u03c9) 2\u2212\u03c9 m\n1 + m\u22121\u2211 j=1 (\u03c4j+1 \u2212 \u03c4j) \u03c4j+1  \u2264 c m log \u03c4m \u03c4 2(1\u2212\u03c9) 2\u2212\u03c9 m\n1 + m\u22121\u2211 j=1 (\u03c4j+1 \u2212 \u03c4j) \u03c4j \nwhere the inequality (a) holds since \u03c4j is increasing in j and \u03c9 \u2208 (0, 1] so that the exponent on \u03c4j is non-negative, and the final inequality follows since \u03c4j \u2264 \u03c4j+1. Invoking Lemma 8, we obtain\nerrm(h \u2217) \u2264 m log \u03c4m (1 + 4c log \u03c4m) \u03c4\n2(1\u2212\u03c9) 2\u2212\u03c9\nm\n\u2264 5c m log2 \u03c4m \u03c4 2(1\u2212\u03c9) 2\u2212\u03c9 m ,\nwhere we used the fact that 1 \u2264 log \u03c4m. Therefore, we have established the second part of the inductive claim, finishing the proof of the lemma.\nUsing the lemma, we now prove the corollaries. Proof of Corollary 2 Based on the proof of Lemma 9, we see that \u2206\u2217m satisfies the bound (55). Plugging this into the statement of Theorem 1 immediately yields the lemma.\nProof of Corollary 4 Based on the proof of Lemma 9, we see that the probability of the disagreement region follows the bound (54). Substituting the bound (55) yields the stated result."}, {"heading": "F Analysis of the Optimization Algorithm", "text": "We begin by showing how to find the most violated constraint (Step 3) by calling an importance-weighted ERM oracle. Then we prove Theorem 3, followed by the framework and proof for Theorem 4.\nF.1 Finding the Most Violated Constraint Recall our earlier notation Imh (x) = 1(h(x) 6= hm(x) \u2227 x \u2208 Dm). Consider solving (OP) using an unlabeled sample S of size u. Note that Step 3 is equivalent to\narg minh\u2208H bm(h)\u2212 E\u0302X [ Imh (X) P\u03bb(X) ] (56)\n= arg minh\u2208H 2\u03b3\u03b2 2(\u03c4m \u2212 1)\u2206m\u22121err(h, Z\u0303m\u22121) + E\u0302X [( 2\u03b12 \u2212 1\nP\u03bb(X)\n) Imh (X) ] = arg minh\u2208H 2\u03b3\u03b2 2(\u03c4m \u2212 1)\u2206m\u22121err(h, Z\u0303m\u22121)\n+E\u0302X [(\n2\u03b12 \u2212 1 P\u03bb(X)\n) Imh (X) + max ( 1\nP\u03bb(X) \u2212 2\u03b12, 0\n) 1(X \u2208 Dm) ] = arg minh\u2208H 2\u03b3\u03b2 2(\u03c4m \u2212 1)\u2206m\u22121err(h, Z\u0303m\u22121)\n+E\u0302X [ max ( 2\u03b12 \u2212 1\nP\u03bb(X) , 0\n) 1(X \u2208 Dm)1(h(X) 6= hm(X)) ] +E\u0302X [ max ( 1\nP\u03bb(X) \u2212 2\u03b12, 0\n) 1(X \u2208 Dm)1(h(X) 6= \u2212hm(X)) ] = arg minh\u2208H 2\u03b3\u03b2\n2(\u03c4m \u2212 1)\u2206m\u22121err(h, Z\u0303m\u22121) +E\u0302X [|s\u03bb(X)|1(X \u2208 Dm)1(h(X) 6= sign(s\u03bb(X))hm(X))] ,\nwhere s\u03bb(X) := 2\u03b12\u2212 1/P\u03bb(X). In the above derivation, the second equality is by the fact that the extra term added to the objective is independent of h and hence does not change the minimizer. The third equality uses a case analysis on the sign of s\u03bb(X) and the identity 1\u2212 1(h(X) 6= hm(X)) = 1(h(X) 6= \u2212hm(X)). The last expression suggests that an importance-weighted error minimization oracle can find the desired classifier on examples {(X,Y \u2217,W )} with labels and importance weights defined as:\nY \u2217 := arg min Y c(X,Y ), W := |c(X, 1)\u2212 c(X,\u22121)|,\nwhere\nc(X,Y ) :=\n{ 2\u03b3\u03b22\u2206m\u22121 ( 1(Xi\u2208Dm(i)\u2227Y 6=Yi)Qi\nPm(i)(Xi) + 1(Xi /\u2208 Dm(i) \u2227 Y 6= hm(i)(Xi))\n) , X = Xi \u2208 Z\u0303m\u22121,\n1 u |s\u03bb(X)|1(X \u2208 Dm)1(Y 6= sign(s\u03bb(X))hm(X)), X \u2208 S.\n(57)\nF.2 Proof of Theorem 3 Where clear from context, we drop the subscript m.\nWe first show that each coordinate ascent step causes sufficient increase in the dual objective. Pick any h and \u03bb. Let \u03bb\u2032 be identical to \u03bb except that \u03bb\u2032h = \u03bbh + \u03b4 for some \u03b4 > 0. Then the increase in the dual objective D can be computed directly:\nD(\u03bb\u2032)\u2212D(\u03bb) = \u03b4EX [Imh (X)] + 2EX [1(X \u2208 Dm)( \u221a q\u03bb(X)2 + \u03b4Imh (X)\u2212 q\u03bb(X))]\u2212 \u03b4b(h)\n\u2265 \u03b4EX [Imh (X)] + 2EX [ q\u03bb(X) ( \u03b4Imh (X) 2q\u03bb(X)2 \u2212 \u03b4 2Imh (X)2 8q\u03bb(X)4 )] \u2212 \u03b4b(h) (58)\n= \u03b4EX [( 1 + 1\nq\u03bb(X)\n) Imh (X)\u2212 b(h) ] \u2212 \u03b42E [ Imh (X)2\n4q\u03bb(X)3 ] = \u03b4 ( EX [ Imh (X) P\u03bb(X) ] \u2212 b(h) ) \u2212 \u03b4 2 4 E [ Imh (X)2 q\u03bb(X)3 ] . (59)\nThe inequality (58) uses the fact that \u221a\n1 + z \u2265 1 + z/2 \u2212 z2/8 for all z \u2265 0 (provable, for instance, using Taylor\u2019s theorem). The lower bound (59) on the increase in the objective value is maximized exactly at\n\u03b4 = 2 E[Imh (X)/P\u03bb(X)\u2212 b(h)] EX [Imh (X)2/q\u03bb(X)3] , (60)\nas in Step (7). Plugging into (59), it follows that if h is chosen on some iteration of Algorithm 2 prior to halting then the dual objective D increases by at least\nEX [Imh (X)/P\u03bb(X)\u2212 b(h)]2\nEX [Imh (X)2/q\u03bb(X)3] \u2265 \u03b52\u00b53 (61)\nsince q\u03bb(x) \u2265 \u00b5, and since EX [Imh (X)/P\u03bb(X)\u2212 b(h)] \u2265 \u03b5. The initial dual objective is D(0) = (1 + \u00b5)2Pr(Dm). Further, by duality and the fact that P (X) = 1/2 is a feasible solution to the primal problem, we have D(\u03bb) \u2264 2(1 + \u00b52)Pr(Dm). And of course, rescaling can never cause the dual objective to decrease. Combining, it follows that the coordinate ascent algorithm halts in at most Pr(Dm)(2(1 + \u00b5\n2)\u2212 (1 + \u00b5)2)/(\u03b52\u00b53) \u2264 Pr(Dm)/(\u03b52\u00b53) rounds proving the bound given in the theorem. By this same reasoning, the left hand side of (61) is equal to \u03b4 \u00b7 EX [Imh (X)/P\u03bb(X)\u2212 b(h)], which is at least \u03b4\u03b5. That is, the change on each round in the dual objective D is at least \u03b5 times the change in one of the coordinates \u03bbh. Furthermore, the rescaling step can never cause the weights \u03bbh to increase. Therefore, \u03b5\u2016\u03bb\u0302\u20161 is upper bounded by the total change in the dual objective, which we bounded above. This proves the bound on \u2016\u03bb\u0302\u20161 given in the theorem.\nTo see (15), consider first the function g(s) = D(s \u00b7 \u03bb) for \u03bb as in the algorithm after the rescaling step has been executed. At this point, it is necessarily the case that s = 1 maximizes g over s \u2208 [0, 1] (since \u03bb has already been rescaled). This implies that g\u2032(1) \u2265 0 where g\u2032 is the derivative of g; that is,\n0 \u2264 g\u2032(1) = E [\u2211\nh \u03bbhImh (X) Ps\u00b7\u03bb(X) ] \u2212 \u2211 h \u03bbhb(h). (62)\nNow let F (P ) denote the modified primal objective function in (12), and let P\u0303 denote the minimum of this objective over all feasible solutions. Then\nF (P\u03bb\u0302) \u2264 F (P\u03bb\u0302) + \u2211 h \u03bb\u0302h ( EX [ Imh (X) P\u03bb\u0302(X) ] \u2212 b(h) ) (63)\n= min P L(P, \u03bb\u0302) (64) \u2264 max \u03bb min P L(P,\u03bb)\n= F (P\u0303 ). (65)\nHere, (63) follows from (62); (64) by the definition of P\u03bb(X) as the minimizer of the Lagrangian; and (65) is by strong duality. Then we have\nE [\n1\n1\u2212 P\u03bb\u0302(X)\n] \u2264 F (P\u03bb\u0302) \u2264 F (P\u0303 ) \u2264 F (P \u2217) \u2264 E [\n1\n1\u2212 P \u2217(X)\n] + \u00b5Pr(Dm).\nF.3 Proof of Theorem 4 For \u03b5 > 0, define \u039b\u03b5 := {\u03bb \u2208 RH : \u03bb \u2265 0, \u2016\u03bb\u20161 \u2264 1/\u03b5}. We begin with a simple lemma.\nLemma 10. Suppose \u03c6 : R\u00d7X \u2192 R beL-Lipschitz with respect to its first argument, and \u03c6( \u2211 h\u2208H \u03bbhImh (x), x) \u2264 R for all \u03bb \u2208 \u039b\u03b5 and x \u2208 X . Let E\u0302X [\u00b7] denote the empirical expectation with respect to an i.i.d. sample from PX . For any \u03b4 \u2208 (0, 1), with probability at least 1\u2212 \u03b4, every \u03bb \u2208 \u039b\u03b5 satisfies\u2223\u2223\u2223\u2223\u2223E\u0302X [ \u03c6 (\u2211 h\u2208H \u03bbhImh (X), X )] \u2212 EX [ \u03c6 (\u2211 h\u2208H \u03bbhImh (X), X\n)]\u2223\u2223\u2223\u2223\u2223 \u2264 2L \u03b5 \u00b7 \u221a 2 ln |H| u +R \u00b7 \u221a ln(1/\u03b4) u .\nProof. Let x \u2208 {0, 1}H denote the vector with xh = 1(h(x) 6= hm(x)), and define the linear function class\nF := {x 7\u2192 \u3008\u03bb,x\u3009 : \u03bb \u2208 \u039b\u03b5} .\nBy a simple variant of the argument by Bartlett and Mendelson [2002], with probability at least 1\u2212 \u03b4,\u2223\u2223\u2223\u2223\u2223E\u0302X [ \u03c6 (\u2211 h\u2208H \u03bbhImh (X), X )] \u2212 EX [ \u03c6 (\u2211 h\u2208H \u03bbhImh (X), X )]\u2223\u2223\u2223\u2223\u2223 \u2264 2L \u00b7 Ru(F) +R \u00b7 \u221a ln(1/\u03b4) u\nfor all \u03bb \u2208 \u039b\u03b5, where Ru(F) is the expected Rademacher average for the linear function class F for an i.i.d. sample of size n. By Kakade et al. [2009], this Rademacher complexity satisfies\nRu(F) \u2264 1\n\u03b5 \u221a 2 ln |H| u .\nThis completes the proof.\nLemma 11. Pick any \u03b4 \u2208 (0, 1). Let E\u0302X [\u00b7] denote the empirical expectation with respect to an i.i.d. sample from PX . With probability at least 1\u2212 \u03b4, every \u03bb \u2208 \u039b\u03b5 satisfies\u2223\u2223\u2223\u2223EX [ 11\u2212 P\u03bb(X) ] \u2212 E\u0302X [ 1 1\u2212 P\u03bb(X) ]\u2223\u2223\u2223\u2223 \u2264 \u221a 2 ln |H| \u00b52\u03b52u + \u221a (\u00b52 + 1/\u03b5) ln(3/\u03b4) u\nand for all h \u2208 H,\u2223\u2223\u2223\u2223EX [Imh (X)P\u03bb(X) ] \u2212 E\u0302X [ Imh (X) P\u03bb(X) ]\u2223\u2223\u2223\u2223 \u2264 \u221a 2 ln |H| \u00b54\u03b52u + \u221a ln(3|H|/\u03b4) \u00b52u + \u221a ln(6|H|/\u03b4) 2u\nand \u2223\u2223\u2223EX [Imh (X)]\u2212 E\u0302X [Imh (X)]\u2223\u2223\u2223 \u2264 \u221a\nln(6|H|/\u03b4) 2u .\nProof. Observe that 1/(1 \u2212 P\u03bb(x)) = 1 + q\u03bb(x) for all \u03bb \u2208 \u039b\u03b5 and x \u2208 X . Now we apply Lemma 10 to the function \u03c61(z, x) := \u221a \u00b52 + z, which is (2\u00b5)\u22121-Lipschitz with respect to its first argument. Since q\u03bb(x) =\nf1( \u2211 h\u2208H \u03bbhImh (x), x) \u2264 \u221a \u00b52 + 1/\u03b5 for all \u03bb \u2208 \u039b\u03b5 and x \u2208 X , Lemma 10 implies that, with probability at least 1\u2212 \u03b4/3, \u2223\u2223\u2223\u2223EX [ 11\u2212 P\u03bb(X) ] \u2212 E\u0302X [ 1 1\u2212 P\u03bb(X) ]\u2223\u2223\u2223\u2223 \u2264 1\u00b5\u03b5 \u221a 2 ln |H| u + \u221a (\u00b52 + 1/\u03b5) ln(3/\u03b4) u , \u2200\u03bb \u2208 \u039b\u03b5. (66)\nNext, observe that for every h \u2208 H and x \u2208 X ,\nImh (x) P\u03bb(x) = Imh (x) + Imh (x) q\u03bb(x) .\nBy Hoeffding\u2019s inequality and a union bound, we have with probability at least 1\u2212 \u03b4/3,\u2223\u2223\u2223EX [Imh (X)]\u2212 E\u0302X [Imh (X)]\u2223\u2223\u2223 \u2264 \u221a\nln(6|H|/\u03b4) 2u , \u2200h \u2208 H. (67)\nNow we apply Lemma 10 to the functions \u03c6h(z, x) := Imh (x)/ \u221a \u00b52 + z for each h \u2208 H; each function \u03c6h is (2\u00b52)\u22121-\nLipschitz with respect to its first argument. Furthermore, since \u03c6h( \u2211 h\u2208H \u03bbhImh (x), x) = Imh (x)/q\u03bb(x) \u2264 1/\u00b5 for all \u03bb \u2208 \u039b\u03b5 and x \u2208 X , Lemma 10 and a union bound over all h \u2208 H implies that, with probability at least 1\u2212 \u03b4/3\u2223\u2223\u2223\u2223EX [Imh (X)q\u03bb(X) ] \u2212 E\u0302X [ Imh (X) q\u03bb(X) ]\u2223\u2223\u2223\u2223 \u2264 \u221a 2 ln |H| \u00b54\u03b52u + \u221a ln(3|H|/\u03b4) \u00b52u , \u2200\u03bb \u2208 \u039b\u03b5, h \u2208 H. (68)\nFinally, by a union bound, all of (66), (67), and (68) hold simultaneously with probability at least 1\u2212 \u03b4.\nWe can now prove Theorem 4. We first state a slightly more explicit version of the theorem, which is then proved.\nTheorem 6. Let S be an i.i.d. sample of size u from the PX . Suppose Algorithm 2 is run on the m-th epoch for solving (OPS,\u03b5) up to slack \u03b5 in the variance constraints. Then the following holds:\n1. Algorithm 2 halts in at most P\u0302r(Dm) 8P 3min,m\u03b5\n2 iterations, where P\u0302r(Dm) := \u2211 X\u2208S 1(X \u2208 Dm)/u.\n2. The solution \u03bb\u0302 \u2265 0 it outputs has bounded `1 norm:\n\u2016\u03bb\u0302\u20161 \u2264 P\u0302r(Dm)/\u03b5.\n3. There exists an absolute constant C > 0 such that the following holds. If\nu \u2265 C \u00b7\n(( 1\nP 4min,m\u03b5 2\n+ \u03b14 ) \u00b7 log |H|\n\u03b52 +\n( 1\nP 2min,m +\n1 \u03b5 + \u03b14\n) \u00b7 log(1/\u03b4)\n\u03b52\n) ,\nthen with probability at least 1\u2212 \u03b4, the query probability function P\u03bb\u0302(x) satisfies\n\u2022 All constraints of (OP) except with slack 2.5\u03b5 in constraints (5), \u2022 Approximate primal optimality:\nEX [\n1\n1\u2212 P\u03bb\u0302(X)\n] \u2264 EX [ 1\n1\u2212 P \u2217(X)\n] + 8Pmin,mPr(Dm) + (2 + 4Pmin,m)\u03b5,\nwhere P \u2217 is the solution to (OP).\nTheorem 4 is just a result of some simplifications in the O(\u00b7) notation in the above result. We now prove the theorem. Proof of Theorem 6 The first two statements, finite convergence and boundedness of the solution\u2019s `1 norm, can be proved with the techniques in Appendix F.2 that establish the same for Theorem 3. We thus focus on proving the third statement here.\nLet E\u0302X [\u00b7] denote empirical expectation with respect to S. Hoeffding\u2019s inequality implies that with probability at least 1\u2212 \u03b4/2, E\u0302X [1(X \u2208 Dm)] \u2264 EX [1(X \u2208 Dm)] + \u03b5. (69) Also, Lemma 11 implies that with probability at least 1\u2212 \u03b4/2,\u2223\u2223\u2223\u2223E\u0302X [ 11\u2212 P\u03bb(X) ] \u2212 EX [ 1 1\u2212 P\u03bb(X)\n]\u2223\u2223\u2223\u2223 \u2264 \u03b5, \u2200\u03bb \u2208 \u039b\u03b5/2; (70)\u2223\u2223\u2223EX [Imh (X)]\u2212 E\u0302X [Imh (X)]\u2223\u2223\u2223 \u2264 \u03b5/(8\u03b12), \u2200h \u2208 H; (71)\u2223\u2223\u2223\u2223EX [Imh (X)P\u03bb(X) ] \u2212 E\u0302X [ Imh (X) P\u03bb(X)\n]\u2223\u2223\u2223\u2223 \u2264 \u03b5/4, \u2200\u03bb \u2208 \u039b\u03b5/2, h \u2208 H. (72) Therefore, by a union bound, there is an event of probability mass at least 1 \u2212 \u03b4 on which Eqs. (69), (70), (71), (72) hold simultaneously. We henceforth condition on this event.\nBy Theorem 3, \u03bb\u0302 satisfies \u2016\u03bb\u0302\u20161 \u2264 1/\u03b5, the bound constraints in (6), as well as E\u0302X [ Imh (X) P\u03bb\u0302(X) ] \u2264 bm(h) + 2\u03b5, \u2200h \u2208 H, (73)\nand\nE\u0302X [\n1\n1\u2212 P\u03bb\u0302(X)\n] \u2264 E\u0302X [ 1\n1\u2212 P\u0302 \u2217\u03b5 (X)\n] + 4Pmin,mE\u0302X [1(X \u2208 Dm)] (74)\nwhere P\u0302 \u2217\u03b5 is the optimal solution to (OPS,\u03b5). We use this to show that P\u03bb\u0302 is a feasible solution for (OP2.5\u03b5), and compare its objective value to the optimal objective value for (OP).\nApplying (71) and (72) to (73) gives EX [ Imh (X) P\u03bb\u0302(X) ] \u2264 bm(h) + 2.5\u03b5, \u2200h \u2208 H.\nSince P\u03bb\u0302 also satisfies the bound constraints in (6), it follows that P\u03bb\u0302 is feasible for (OP2.5\u03b5). Now we turn to the objective value. Applying (69) and (70) to (74) gives\nEX [\n1\n1\u2212 P\u03bb\u0302(X)\n] \u2264 E\u0302X [ 1\n1\u2212 P\u0302 \u2217\u03b5 (X)\n] + 4Pmin,mEX [1(X \u2208 Dm)] + (1 + 4Pmin,m)\u03b5. (75)\nWe need to relate the first term on the right-hand side to the optimal objective value for (OP). Let \u03bb\u2217 be the output of running Algorithm 2 for solving (OP) up to slack \u03b5/2. By Theorem 3, \u03bb\u2217 satisfies \u2016\u03bb\u2217\u20161 \u2264 2/\u03b5, the bound constraints in (6), as well as\nEX [ Imh (X) P\u03bb\u2217(X) ] \u2264 bm(h) + \u03b5/2, \u2200h \u2208 H,\nand\nEX [\n1\n1\u2212 P\u03bb\u2217(X)\n] \u2264 EX [ 1\n1\u2212 P \u2217(X)\n] + 4Pmin,mEX [1(X \u2208 Dm)]. (76)\nApplying (70) to (76), we have E\u0302X [ 1\n1\u2212 P\u03bb\u2217(X)\n] \u2264 EX [ 1\n1\u2212 P \u2217(X)\n] + 4Pmin,mEX [1(X \u2208 Dm)] + \u03b5. (77)\nAnd applying (71) and (72) to (76) gives E\u0302X [ Imh (X) P\u03bb\u2217(X) ] \u2264 bm(h) + \u03b5, \u2200h \u2208 H. (78)\nThis establishes that \u03bb\u2217 is a feasible solution for (OPS,\u03b5). In particular,\nE\u0302X\n[ 1\n1\u2212 P\u0302 \u2217\u03b5 (X)\n] \u2264 E\u0302X [ 1\n1\u2212 P\u03bb\u2217(X) ] \u2264 EX [ 1\n1\u2212 P \u2217(X)\n] + 4Pmin,mEX [1(X \u2208 Dm)] + \u03b5\nwhere the second inequality follows from (77). We now combine this with (75) to obtain EX [ 1\n1\u2212 P\u03bb\u0302(X)\n] \u2264 EX [ 1\n1\u2212 P \u2217(X)\n] + 8Pmin,mEX [1(X \u2208 Dm)] + (2 + 4Pmin,m)\u03b5."}, {"heading": "G Experimental Details", "text": "Here we provide more details about the experiments.\nG.1 Datasets Table 1 gives details about the 23 binary classification datasets used in our experiments, where n is the number of examples, d is the number of features, s is the average number of non-zero features per example, and r is the proportion of the minority class.\nG.2 Hyper-parameter Settings We start with the actual hyper-parameters used by OAC. Going back to Algorithm 1, we note that the tuning parameters get used in mostly the following three quantities: \u03b3\u2206i\u22121 , \u03b1 and \u03b2. We use this fact to reduce the number of input parameters. Let c0 := \u03b32c132(log(|H|/\u03b4) + log(i\u2212 1)) (treating log(i\u2212 1) as a constant) and set \u03b7 = 864, \u03b3 = \u03b7/4 and c2 = \u03b7c21/4 according to our theory. Then we have\n\u03b3\u2206i\u22121 = \u221a \u03b32c1 i\u22121err(hi, Z\u0303i\u22121) + \u03b3c2 i\u22121 log(i\u2212 1)\n=\n\u221a c0err(hi, Z\u0303i\u22121)\ni\u2212 1 + c0 c2 \u03b3c1 log(i\u2212 1) i\u2212 1 ,\nwhere c2\u03b3c1 = c1 = O(\u03b1). Based on this, we use\n\u2206\u0302i\u22121 :=\n\u221a c0err(hi, Z\u0303i\u22121)\ni\u2212 1 + max(2\u03b1, 4)c0 log(i\u2212 1) i\u2212 1\n(79)\nin Algorithm 3 in place of \u03b3\u2206i\u22121. Next we consider\n\u03b22 \u2264 1 216n n log n\n\u2248 \u03b3 2c1\n216c0 log n \u2235 n n \u2248 c0/(\u03b32c1) by treating log n as a constant = O ( \u03b1\nc0\n) by again treating log n as a constant and c1 = O(\u03b1).\nBased on the last expression, we set \u03b2 := \u221a \u03b1/c0 10 . In sum, the actual input parameters boil down to the cover size l, \u03b1 \u2265 1 and c0, and we use them to set\n\u03b3\u2206i\u22121 :=\n\u221a c0err(hi, Z\u0303i\u22121)\ni\u2212 1 + max(2\u03b1, 4)c0 log(i\u2212 1) i\u2212 1 , \u03b2 = \u221a \u03b1/c0 10 .\nFinally, we use the following setting for the minimum query probability:\nPmin,i = min  1\u221a (i\u2212 1)err(hi, Z\u0303i\u22121) + log(i\u2212 1) , 1 2  . Next we describe hyper-parameter settings for different algorithms. A common hyper-parameter is the learning rate of the underlying online oracle, which is a reduction to importance-weighted logistic regression. For all active learning algorithm, we try the following 11 learning rates: 10\u22121 \u00b7{2\u22122, 2\u22121, . . . , 28}. Active learning hyper-parameter settings are given in the following table:\nalgorithm parameter settings total number of settings OAC (l, \u03b1, c0) \u2208 {3, 6, 12, 24, 48} \u00d7 {20, 21, . . . , 24} \u00d7 {\n0.1 \u00b7 {2\u22124, 2\u22123, . . . , \u00b72\u22121}, 0.1, 0.3, . . . , 0.9, 20, 21, . . . , 23 } 325 ORA-I (\u03b1, c0) the same as OAC 65\nIWAL C0 \u2208 { 0.1 \u00b7 {2\u221210, 2\u22129, . . . , 20}, 20, 21, . . . , 23 }\n15\nORA-II C0 \u2208 {2\u221211, 2\u221210, . . . , 23} 15 RANDOM query rate \u2208 { 10\u22123{20, 21, . . . , 29}, 0.75, 1 } 12\nGood hyper-parameters of the algorithms usually lie in the interior of these value ranges.\nG.3 More Experimental Results We provide detailed per-dataset results in Figures 7 and 8, which show minimum test errors over hyper-parameter settings that are achievable at different query rates for small (fewer than 105 examples) and large (more than 105 examples) datasets. On small datasets, OAC is generally competitive with other algorithms. On all (including the three shown in Figure 3) but two large datasets, bio and kdda, OAC outperforms other algorithms at most query rates, with a clear advantage at low query rates. Note that both bio and kdda, as shown in Table 1, are imbalanced. The fraction of the minority class in bio is about 1%, and the minimum test error is about 0.4%, a quite significant difference. IWAL strongly dominates other algorithms on this dataset, which suggests that using predicted labels, as done by the other three agnostic active learning algorithms, may be undesirable for highly imbalanced classification problems. There is less class skewness in kdda, but the minimum test error 12% is only slightly lower than the fraction of the minority class 14.7%. On this hard dataset, ORA-I, i.e., the Oracular CAL variant of OAC, outperforms other algorithms."}], "references": [{"title": "Active and passive learning of linear separators under log-concave distributions", "author": ["Maria-Florina Balcan", "Phil Long"], "venue": "In Conference on Learning Theory,", "citeRegEx": "Balcan and Long.,? \\Q2013\\E", "shortCiteRegEx": "Balcan and Long.", "year": 2013}, {"title": "Agnostic active learning", "author": ["Maria-Florina Balcan", "Alina Beygelzimer", "John Langford"], "venue": "In Proceedings of the 23rd international conference on Machine learning,", "citeRegEx": "Balcan et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Balcan et al\\.", "year": 2006}, {"title": "Margin based active learning", "author": ["Maria-Florina Balcan", "Andrei Broder", "Tong Zhang"], "venue": "In Proceedings of the 20th annual conference on Learning theory,", "citeRegEx": "Balcan et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Balcan et al\\.", "year": 2007}, {"title": "Gaussian and Rademacher complexities: Risk bounds and structural results", "author": ["P. Bartlett", "S. Mendelson"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bartlett and Mendelson.,? \\Q2002\\E", "shortCiteRegEx": "Bartlett and Mendelson.", "year": 2002}, {"title": "Importance weighted active learning", "author": ["A. Beygelzimer", "S. Dasgupta", "J. Langford"], "venue": "In ICML,", "citeRegEx": "Beygelzimer et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Beygelzimer et al\\.", "year": 2009}, {"title": "Agnostic active learning without constraints", "author": ["A. Beygelzimer", "D. Hsu", "J. Langford", "T. Zhang"], "venue": "In NIPS,", "citeRegEx": "Beygelzimer et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Beygelzimer et al\\.", "year": 2010}, {"title": "Minimax bounds for active learning", "author": ["R.M. Castro", "R.D. Nowak"], "venue": "Information Theory, IEEE Transactions on,", "citeRegEx": "Castro and Nowak.,? \\Q2008\\E", "shortCiteRegEx": "Castro and Nowak.", "year": 2008}, {"title": "Improving generalization with active learning", "author": ["D. Cohn", "L. Atlas", "R. Ladner"], "venue": "Machine Learning,", "citeRegEx": "Cohn et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Cohn et al\\.", "year": 1994}, {"title": "Coarse sample complexity bounds for active learning", "author": ["S. Dasgupta"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Dasgupta.,? \\Q2005\\E", "shortCiteRegEx": "Dasgupta.", "year": 2005}, {"title": "A general agnostic active learning algorithm", "author": ["S. Dasgupta", "D. Hsu", "C. Monteleoni"], "venue": "In NIPS,", "citeRegEx": "Dasgupta et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Dasgupta et al\\.", "year": 2007}, {"title": "On tail probabilities for martingales", "author": ["D.A. Freedman"], "venue": "The Annals of Probability,", "citeRegEx": "Freedman.,? \\Q1975\\E", "shortCiteRegEx": "Freedman.", "year": 1975}, {"title": "Theoretical Foundations of Active Learning", "author": ["S. Hanneke"], "venue": "PhD thesis,", "citeRegEx": "Hanneke.,? \\Q2009\\E", "shortCiteRegEx": "Hanneke.", "year": 2009}, {"title": "Theory of disagreement-based active learning", "author": ["Steve Hanneke"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Hanneke.,? \\Q2014\\E", "shortCiteRegEx": "Hanneke.", "year": 2014}, {"title": "A generalization of sampling without replacement from a finite universe", "author": ["D.G. Horvitz", "D.J. Thompson"], "venue": "J. Amer. Statist. Assoc.,", "citeRegEx": "Horvitz and Thompson.,? \\Q1952\\E", "shortCiteRegEx": "Horvitz and Thompson.", "year": 1952}, {"title": "Algorithms for Active Learning", "author": ["Daniel J. Hsu"], "venue": "PhD thesis, University of California at San Diego,", "citeRegEx": "Hsu.,? \\Q2010\\E", "shortCiteRegEx": "Hsu.", "year": 2010}, {"title": "On the generalization ability of online strongly convex programming algorithms", "author": ["S.M. Kakade", "A. Tewari"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Kakade and Tewari.,? \\Q2009\\E", "shortCiteRegEx": "Kakade and Tewari.", "year": 2009}, {"title": "On the complexity of linear prediction: Risk bounds, margin bounds, and regularization", "author": ["Sham M Kakade", "Karthik Sridharan", "Ambuj Tewari"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Kakade et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Kakade et al\\.", "year": 2009}, {"title": "Online importance weight aware updates", "author": ["Nikos Karampatziakis", "John Langford"], "venue": "UAI", "citeRegEx": "Karampatziakis and Langford.,? \\Q2011\\E", "shortCiteRegEx": "Karampatziakis and Langford.", "year": 2011}, {"title": "Rademacher complexities and bounding the excess risk in active learning", "author": ["Vladimir Koltchinskii"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Koltchinskii.,? \\Q2010\\E", "shortCiteRegEx": "Koltchinskii.", "year": 2010}, {"title": "Optimal aggregation of classifiers in statistical learning", "author": ["A.B. Tsybakov"], "venue": "Ann. Statist.,", "citeRegEx": "Tsybakov.,? \\Q2004\\E", "shortCiteRegEx": "Tsybakov.", "year": 2004}, {"title": "Beyond disagreement-based agnostic active learning", "author": ["Chicheng Zhang", "Kamalika Chaudhuri"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Zhang and Chaudhuri.,? \\Q2014\\E", "shortCiteRegEx": "Zhang and Chaudhuri.", "year": 2014}, {"title": "By a simple variant of the argument by Bartlett and", "author": [], "venue": "\u039b\u03b5}", "citeRegEx": "F,? \\Q2002\\E", "shortCiteRegEx": "F", "year": 2002}], "referenceMentions": [{"referenceID": 7, "context": "1 Introduction How can you best learn a classifier given a label budget? Active learning approaches are known to yield exponential improvements over supervised learning under strong assumptions [Cohn et al., 1994].", "startOffset": 194, "endOffset": 213}, {"referenceID": 6, "context": "This results in a poor label complexity, well short of information-theoretic limits [Castro and Nowak, 2008] even for general robust solutions [Zhang and Chaudhuri, 2014].", "startOffset": 84, "endOffset": 108}, {"referenceID": 20, "context": "This results in a poor label complexity, well short of information-theoretic limits [Castro and Nowak, 2008] even for general robust solutions [Zhang and Chaudhuri, 2014].", "startOffset": 143, "endOffset": 170}, {"referenceID": 11, "context": "The label complexity bound depends on the disagreement coefficient [Hanneke, 2009], which does not completely capture the advantage of the algorithm.", "startOffset": 67, "endOffset": 82}, {"referenceID": 0, "context": "Under much weaker assumptions, streaming-based agnostic active learning [Balcan et al., 2006, Beygelzimer et al., 2009, 2010, Dasgupta et al., 2007, Zhang and Chaudhuri, 2014] is particularly appealing since it is known to work for any classifier representation and any label noise distribution with an i.i.d. data source.1 Here, a learning algorithm decides for each unlabeled example in sequence whether or not to request a label, never revisiting this decision. Restated then: What is the best possible active learning algorithm which works for any classifier representation, any label noise distribution, and is computationally tractable? Computational tractability is a critical concern, because most known algorithms for this setting [e.g., Balcan et al., 2006, Koltchinskii, 2010, Zhang and Chaudhuri, 2014] require explicit enumeration of classifiers, implying exponentially-worse computational complexity compared to typical supervised learning algorithms. Active learning algorithms based on empirical risk minimization (ERM) oracles [Beygelzimer et al., 2009, 2010, Hsu, 2010] can overcome this intractability by using passive classification algorithms as the oracle to achieve a computationally acceptable solution. Achieving generality, robustness, and acceptable computation has a cost. For the above methods [Beygelzimer et al., 2009, 2010, Hsu, 2010], a label is requested on nearly every unlabeled example where two empirically good classifiers disagree. This results in a poor label complexity, well short of information-theoretic limits [Castro and Nowak, 2008] even for general robust solutions [Zhang and Chaudhuri, 2014]. Until now. In Section 3, we design a new algorithm ACTIVE COVER (AC) for constructing query probability functions that minimize the probability of querying inside the disagreement region\u2014the set of points where good classifiers disagree\u2014and never query otherwise. This requires a new algorithm that maintains a parsimonious cover of the set of empirically good classifiers. The cover is a result of solving an optimization problem (in Section 5) specifying the properties of a desirable query probability function. The cover size provides a practical knob between computation and label complexity, as demonstrated by the complexity analysis we present in Section 5. In Section 4, we provider our main results which demonstrate that AC effectively maintains a set of good classifiers, achieves good generalization error, and has a label complexity bound tighter than previous approaches. The label complexity bound depends on the disagreement coefficient [Hanneke, 2009], which does not completely capture the advantage of the algorithm. In Appendix 4.2.2, we provide an example of a hard active learning problem where AC is 1See the monograph of Hanneke [2014] for an overview of the existing literature, including alternative settings where additional assumptions are placed on the data source (e.", "startOffset": 73, "endOffset": 2805}, {"referenceID": 4, "context": "In the IWAL framework [Beygelzimer et al., 2009], a decision whether or not to query a label is made randomly: the learner picks a probability p \u2208 [0, 1], and queries the label with that probability.", "startOffset": 22, "endOffset": 48}, {"referenceID": 13, "context": "Whenever p > 0, an unbiased error estimate can be produced using inverse probability weighting [Horvitz and Thompson, 1952].", "startOffset": 95, "endOffset": 123}, {"referenceID": 14, "context": "This is most easily seen for Oracular CAL [Hsu, 2010] which queries with probability 1 if X \u2208 Dm and 0 otherwise.", "startOffset": 42, "endOffset": 53}, {"referenceID": 5, "context": "A similar argument can also be made for the IWAL method [Beygelzimer et al., 2010], which also queries in the disagreement region with probability 1, and hence suffers from the same suboptimality compared to our choice.", "startOffset": 56, "endOffset": 82}, {"referenceID": 19, "context": "One intuitive condition that controls the errors within the disagreement region is the low-noise condition of Tsybakov [2004], which asserts that there exist constants \u03b6 > 0 and 0 < \u03c9 \u2264 1 such that Pr(h(X) 6= h\u2217(X)) \u2264 \u03b6 \u00b7 (err(h)\u2212 err(h\u2217))\u03c9, \u2200h \u2208 H such that err(h)\u2212 err(h\u2217) \u2264 \u03b50.", "startOffset": 110, "endOffset": 126}, {"referenceID": 6, "context": "It is worth noting that the rates obtained here are known to be unimprovable for even passive learning under the Tsybakov noise condition Castro and Nowak [2008].5 Consequently, there is no loss of statistical efficiency in using our active learning approach.", "startOffset": 138, "endOffset": 162}, {"referenceID": 12, "context": "1 Disagreement-based label complexity bounds In order to quantify the extent of gains over passive learning, we measure the hardness of our problem using the disagreement coefficient [Hanneke, 2014], which is defined as 5\u03c9 in our statement of the low-noise condition (10) corresponds to 1/\u03ba in the results of Castro and Nowak [2008].", "startOffset": 183, "endOffset": 198}, {"referenceID": 6, "context": "1 Disagreement-based label complexity bounds In order to quantify the extent of gains over passive learning, we measure the hardness of our problem using the disagreement coefficient [Hanneke, 2014], which is defined as 5\u03c9 in our statement of the low-noise condition (10) corresponds to 1/\u03ba in the results of Castro and Nowak [2008].", "startOffset": 309, "endOffset": 333}, {"referenceID": 5, "context": "We contrast this with the label complexity of IWAL [Beygelzimer et al., 2010], which grows as \u03b8 \u221a n independent of err(h\u2217).", "startOffset": 51, "endOffset": 77}, {"referenceID": 14, "context": "A much closer comparison is with respect to the Oracular CAL algorithm [Hsu, 2010], which does have a dependence on \u221a nerr(h\u2217) in the second term, but has a worse dependence on \u03b8.", "startOffset": 71, "endOffset": 82}, {"referenceID": 14, "context": "Indeed the proofs of these results are entirely based on the fact that we do not query outside the disagreement region, a property shared by the previous Oracular CAL algorithm [Hsu, 2010].", "startOffset": 177, "endOffset": 188}, {"referenceID": 6, "context": "The label complexity obtained above is indeed optimal in terms of the dependence on n, the number of unlabeled examples, matching known information-theoretic rates of Castro and Nowak [2008]. This can be seen since the regret from Corollary 2 falls as a function of the number of queries at a rate of \u00d5(q \u2212 1 2(1\u2212\u03c9) m log(|H|/\u03b4)) after m epochs, where qm is the number of label queries.", "startOffset": 167, "endOffset": 191}, {"referenceID": 6, "context": "The label complexity obtained above is indeed optimal in terms of the dependence on n, the number of unlabeled examples, matching known information-theoretic rates of Castro and Nowak [2008]. This can be seen since the regret from Corollary 2 falls as a function of the number of queries at a rate of \u00d5(q \u2212 1 2(1\u2212\u03c9) m log(|H|/\u03b4)) after m epochs, where qm is the number of label queries. This is indeed optimal according to the lower bounds of Castro and Nowak [2008], after recalling that \u03c9 = 1/\u03ba in their results.", "startOffset": 167, "endOffset": 467}, {"referenceID": 8, "context": "Starting with the first issue, we follow Dasgupta et al. [2007] who cleverly observed that x \u2208 Dm can be efficiently determined using a single call to an ERM oracle.", "startOffset": 41, "endOffset": 64}, {"referenceID": 17, "context": "See Appendix F of [Karampatziakis and Langford, 2011] for details.", "startOffset": 18, "endOffset": 53}, {"referenceID": 17, "context": "The specific importance weighted oracle we use is a reduction to online importance-weighted logistic regression [Karampatziakis and Langford, 2011] implemented in Vowpal Wabbit (VW).", "startOffset": 112, "endOffset": 147}, {"referenceID": 17, "context": "The specific importance weighted oracle we use is a reduction to online importance-weighted logistic regression [Karampatziakis and Langford, 2011] implemented in Vowpal Wabbit (VW). Instead of computing the query probability function by solving a batch optimization problem as in Step 5 of AC, OAC maintains a fixed number l of classifiers that are intended to be a cover of the set of good classifiers. On every new example, this cover undergoes a sequence of online, importance weighted updates (Steps 7 to 13 of OAC), which are meant to approximate the coordinate ascent steps in Algorithm 2. The importance structure (16) is derived from (57), accounting for the fact that the algorithm simply uses the incoming stream of examples to estimate EX [\u00b7] rather than a separate unlabeled sample. The same approximation is also present in the updates (17) and (18), which are online estimates of the numerator and the denominator of the additive coordinate update in Step 7 of Algorithm 2. Because (17) is an online estimate, we need to explicitly enforce non-negativity. Finally, Steps 9 to 14 of AC and Steps 14 to 26 of OAC perform the querying of labels. As pointed out in Section 5, the test in Step 16 of OAC is done via an online technique detailed in Appendix F of Karampatziakis and Langford [2011].", "startOffset": 113, "endOffset": 1307}, {"referenceID": 4, "context": "\u2022 IWAL: A slight modification of Algorithm 1 of Beygelzimer et al. [2010], which performs importance-weighted sampling of labels and maintains an unbiased estimate of classification error.", "startOffset": 48, "endOffset": 74}, {"referenceID": 4, "context": "\u2022 IWAL: A slight modification of Algorithm 1 of Beygelzimer et al. [2010], which performs importance-weighted sampling of labels and maintains an unbiased estimate of classification error. In computing the query probability, rather than using a conservative, problem-independent threshold as in Beygelzimer et al. [2010], we use the following error-dependent quantity: \u221a C0 log k k \u2212 1 ek\u22121 + C0 log k k \u2212 1 , (22) where ek\u22121 is the importance-weighted error estimate after the algorithm processes k \u2212 1 examples.", "startOffset": 48, "endOffset": 321}, {"referenceID": 4, "context": "\u2022 IWAL: A slight modification of Algorithm 1 of Beygelzimer et al. [2010], which performs importance-weighted sampling of labels and maintains an unbiased estimate of classification error. In computing the query probability, rather than using a conservative, problem-independent threshold as in Beygelzimer et al. [2010], we use the following error-dependent quantity: \u221a C0 log k k \u2212 1 ek\u22121 + C0 log k k \u2212 1 , (22) where ek\u22121 is the importance-weighted error estimate after the algorithm processes k \u2212 1 examples. C0 is the only active learning hyper-parameter. The query probability is set to 1 if the error difference Gk, defined in Step 2 of Algorithm 1 of Beygelzimer et al. [2010], is smaller than the threshold (22), and otherwise a decreasing function of Gk.", "startOffset": 48, "endOffset": 686}, {"referenceID": 14, "context": "\u2022 ORA-I: An Oracular-CAL [Hsu, 2010] style variant of Algorithm 3.", "startOffset": 25, "endOffset": 36}, {"referenceID": 14, "context": "\u2022 ORA-II: An Oracular-CAL [Hsu, 2010] style variant of IWAL, where the query probability is set to 1 if the error difference Gk, defined in Step 2 of Algorithm 1 of Beygelzimer et al.", "startOffset": 26, "endOffset": 37}, {"referenceID": 4, "context": "\u2022 ORA-II: An Oracular-CAL [Hsu, 2010] style variant of IWAL, where the query probability is set to 1 if the error difference Gk, defined in Step 2 of Algorithm 1 of Beygelzimer et al. [2010], is smaller than the threshold \u221a C0 log k k \u2212 1 ek\u22121 + C0 log k k \u2212 1 .", "startOffset": 165, "endOffset": 191}], "year": 2017, "abstractText": "We develop a new active learning algorithm for the streaming setting satisfying three important properties: 1) It provably works for any classifier representation and classification problem including those with severe noise. 2) It is efficiently implementable with an ERM oracle. 3) It is more aggressive than all previous approaches satisfying 1 and 2. To do this we create an algorithm based on a newly defined optimization problem and analyze it. We also conduct the first experimental analysis of all efficient agnostic active learning algorithms, discovering that this one is typically better across a wide variety of datasets and label complexities.", "creator": "LaTeX with hyperref package"}}}