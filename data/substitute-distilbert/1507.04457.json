{"id": "1507.04457", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jul-2015", "title": "Preference Completion: Large-scale Collaborative Ranking from Pairwise Comparisons", "abstract": "in this paper please consider the collaborative ranking setting : whose pool of users each provides a small number of pairwise preferences between $ d $ possible items ; from these we need to predict preferences of the users for items they have not physically seen. we do so by designing a rank $ r $ score matrix against the pairwise data, and offering 4 main contributions : ( a ) we show that an algorithm based or convex optimization provides better generalization guarantees { each user provides as narrow as $ \\ ( r \\ log ^ 2 d ) $ pairwise comparisons - - essentially matching the sample complexity required in the related matrix completion setting ( which uses actual numerical as presented in pairwise convex ), and ( b ) we develop a large - scale non - convex implementation, which we call altsvm, that trains a factored profile of the evaluation via alternating minimization ( which screens show reduces massive alternating svm problems ), and scales and parallelizes very well to large problem settings. intel also outperforms common baselines on implementing moderately large popular collaborative optimal datasets in both ndcg and in other measures of ranking performance.", "histories": [["v1", "Thu, 16 Jul 2015 06:00:51 GMT  (122kb,D)", "http://arxiv.org/abs/1507.04457v1", null]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["dohyung park", "joe neeman", "jin zhang", "sujay sanghavi", "inderjit s dhillon"], "accepted": true, "id": "1507.04457"}, "pdf": {"name": "1507.04457.pdf", "metadata": {"source": "CRF", "title": "Preference Completion: Large-scale Collaborative Ranking from Pairwise Comparisons", "authors": ["Dohyung Park", "Sujay Sanghavi"], "emails": ["dhpark@utexas.edu", "joeneeman@gmail.com", "zj@utexas.edu", "sanghavi@mail.utexas.edu", "inderjit@cs.utexas.edu"], "sections": [{"heading": "1 Introduction", "text": "This paper considers the following recommendation system problem: given a set of items, a set of users, and non-numerical pairwise comparison data, find the underlying preference ordering of the users. In particular, we are interested in the setting where data is of the form \u201cuser i preferes item j over item k\u201d, for different ordered user-item-item triples i, j, k. Pairwise preference data is wide-spread; indeed, almost any setting where a user is presented with a menu of options \u2013 and chooses one of them \u2013 can be considered to be providing a pairwise preference between the chosen item and every other item that is presented.\nCrucially, we are interested in the collaborative filtering setting, where (a) on the one hand the number of such pairwise preferences we have for any one user is woefully insufficient to infer\nar X\niv :1\n50 7.\n04 45\n7v 1\n[ st\nat .M\nanything for that user in isolation; and (b) on the other hand, we aim for personalization, i.e. for every user to possibly have different inferred preferences from every other. To reconcile these two requirements, our method relates the preferences of users to each other via a low-rank matrix, which we (implicitly) assume governs the observed preferences. Essentially, we fit a low-rank users \u00d7 items score matrix X to pairwise comparison data by trying to ensure that Xij \u2212Xik is positive when user i prefers item j to item k.\nOur contributions: We present two algorithms to infer the score matrix X from training data; once inferred, this can be used for predicting future preferences. While there has been some recent work on fitting low-rank score matrices to pairwise preference data (which we review and compare to below), in this paper we present the following two contributions: (a) A statistical analysis for the convex relaxation: we bound the generalization error of the solution to our convex program. Essentially, we show that the minimizer of the empirical loss also almost minimizes the true expected loss. We also give a lower bound showing that our error rate is sharp up to logarithmic factors. (b) A large-scale non-convex implementation: We provide a non-convex algorithm that we call Alternating Support Vector Machine (AltSVM). This non-convex algorithm is more practical than the convex program in a large-scale setting; it explicitly parameterizes the low-rank matrix in factored form and minimizes the hinge loss. Crucially, each step in this algorithm can be formulated as a standard SVM that updates one of the two factors; the algorithm proceeds by alternating updates to both factors. We apply a stochastic version of dual coordinate descent [7, 22] with lockfree parallelization. This exploits the problem structure and ensures it parallelizes well. We show that our algorithm outperforms several existing collaborative ranking algorithms in both speed and prediction accuracy, and it achieves significant speedups as the number of cores increases."}, {"heading": "1.1 Related Work", "text": "Ranking/learning preferences is a classical problem that has been considered in a large amount of work. There are many different settings for this problem, which we discuss below.\nLearning to Rank The main problem in this community has been to estimate a ranking function from given feature vectors and relevance scores. Depending on its application, a feature vector may correpond to a user-item pair or a single item. While there have been algorithms that use pairwise comparisons [6, 12] of the training samples, our setting is different in that our data consists only of pairwise comparisons. We refer the reader to the survey [15].\nOne ranking with pairwise comparisions In a single-user model, we are asked to learn a single ranking given pairwise comparisons. Jamieson & Nowak [10] and Ailon [1] consider an active query model with noiseless responses; Jamieson & Nowak [11] give an algorithm for exactly recovering the true ranking under a low-rank assumption similar to ours, while Ailon [1] approximately recovers the true ranking without such an assumption. Wauthier et al. [27] and Negahban et al. [18] learn a ranking from noisy pairwise comparisions; Negahban et al. [18] consider a Bradley-Terry-Luce model similar to ours and attempt to learn an underlying score vector, while Wauthier et al. [27] get by without structure assumptions, but only attempt to learn the ranking itself. Hajek et al. [5] considered a problem to learn a single ranking given a more generalized partial rankings from the Plackett-Luce model and provided a minimax-optimal algorithm.\nMany rankings with pairwise comparisions Given multiple users with different rankings, one could of course attempt to learn their rankings by simply applying an algorithm from the previous section to each user individually. However, it is more efficient \u2013 both statistically and computationally \u2013 to postulate some global structure and use it to relate the many users\u2019 rankings. This is the same idea that has been applied so successfully in collaborative filtering. Rendle et al. [20] and Liu et al. [14] were the first to take this approach. They modeled the observations as coming from a BTL model with low-rank structure (i.e., very similar to our model) and gave algorithms for learning the model parameters. Yi et al. [31] took a purely optimization-based approach. Rather than assuming a probabilistic model, they minimized a convex objective using the hinge loss on a low-rank matrix. In a slightly different model, Hu et al. [9] and Shi et al. [23] consider the problem of learning from latent feedback. Recently, Lu & Negahban [16] analyzed an algorithm which is very similar to ours for the Bradley-Terry-Luce model independently from our work.\nMany rankings with 1-bit ratings Instead of moving to pairwise comparisons, some work has suggested avoiding the difficulties of numerical ratings by instead asking users to give 1-bit ratings to items; that is, each user only indicates whether they like or dislike an item. In this setting, the work of Davenport et al. [4] is most closely related to ours, in that they assume an underlying lowrank structure and give an algorithm based on convex optimization. Also, our theoretical analysis owes a lot to their work. Xu et al. [30] consider a slightly different goal: rather than attempting to recover the preferences of each user, they try to cluster similar users and similar items together. Yun et al. [32] proposed an optimization problem motivated from robust binary classification and used stochastic gradient descent to solve the problem in a large-scale setting.\nMany rankings with numerical ratings The goal in this setting is the same as ours, except that the data is in the form of numerical ratings instead of pairwise comparisons. Weimer et al. [28] attempted to directly optimize Normalized Discounted Cumulative Gain (NDCG), a widely used performance measure for ranking problems. Balakrishnan & Chopra [2], and Volkovs & Zemel [26] converted this problem into a learning-to-rank problem and solved it using the existing algorithms. While these works considered the low-rank matrix model, different models are proposed by Weston et al. [29] and Lee et al. [13]. Weston et al. [29] proposed a tensor model to rank items for different queries and users, and [13] proposed a weighted sum of low-rank matrix models."}, {"heading": "2 Empirical Risk Minimization (ERM)", "text": "Let us first formulate the problem mathematically. The task is to estimate rankings of multiple users on multiple items. We denote the numbers of users by d1, and the number of items by d2. We are given a set of triples \u2126 \u2282 [d1] \u00d7 [d2] \u00d7 [d2], where the preference of user i between items j and k is observed if (i, j, k) \u2208 \u2126. The observed comparison is then given by {Yijk \u2208 {1,\u22121} : (i, j, k) \u2208 \u2126} where Yijk = 1 if user i prefers item j over item k, and Yijk = \u22121 otherwise. Let \u2126i = {(j, k) : (i, j, k) \u2208 \u2126} denote the set of item pairs that user i has compared.\nWe predict rankings for multiple users by estimating a score matrix X \u2208 Rd1\u00d7d2 such that Xij > Xik means that user i prefers item j over item k. Then the sorting order for each row provides the predicted ranking for the corresponding user.\nWe propose (as have others) that X is low-rank or close to low-rank, the intuition being that each user bases their preferences on a small set of features that are common among all the items.\nThen the empirical risk minimization (ERM) framework can naturally be formulated as\nminimize X \u2211 (i,j,k)\u2208\u2126 L(Yijk(Xij \u2212Xik)) (1)\nsubject to rank(X) \u2264 r\nwhere L(\u00b7) is a monotonically non-increasing loss function which induces Xij > Xik if Yijk = 1, and Xij < Xik otherwise. (e.g., hinge loss, logistic regression loss, etc.)\nSolving (1) is NP-hard because of the rank constraint. As a first alternative, we propose a straightforward convex relaxation."}, {"heading": "3 Convex Relaxation", "text": "Our first method is the convex relaxation of (1), which involves a nuclear norm constraint.\nminimize X \u2211 (i,j,k)\u2208\u2126 L(Yijk(Xij \u2212Xik)) (2)\nsubject to \u2016X\u2016\u2217 \u2264 \u221a \u03bbd1d2\nHere, for any matrix X, the nuclear/trace norm \u2016X\u2016\u2217 denotes the sum of its singular values; it is a well-recognized convex surrogate for low-rank structure (most famously in matrix completion).\nThe only parameter of this algorithm is \u03bb, which governs the trade-off between better optimizing the likelihood of the observed data, and the strictness in imposing approximate low-rank structure. Since we motivated our algorithm with the assumption that X has low rank, we should point out how our algorithm\u2019s parameter \u03bb compares to the rank: note that if X is a d1 \u00d7 d2 rank-r matrix whose largest absolute entry is bounded by C then \u2016X\u2016\u2217 \u2264 \u221a r\u2016X\u2016F \u2264 C \u221a rd1d2. In other words, \u03bb is a parameter that takes into account both the rank of X and the size of its elements, and it is roughly proportional to the rank."}, {"heading": "3.1 Analytic results", "text": "We analyze (2) by assuming a standard model for pairwise comparisons. Then we provide a statistical guarantee of the method under the model.\nRecall the classical Bradley-Terry-Luce model [3, 17] for pairwise preferences of a single user, which assumes that the probability of item j being preferred over k is given by a logistic of the difference of the underlying preference scores of the two items. For multiple users, we assume that there is some true score matrix X\u2217 \u2208 Rd1\u00d7d2 and\nPr(Yijk = 1) = exp(X\u2217ij \u2212X\u2217ik)\n1 + exp(X\u2217ij \u2212X\u2217ik) .\nAssume that each user-item-item triple (i, j, k) independently belongs to \u2126 with probability pi,j,k, and let m = \u2211 i,j,k pi,j,k be the expected size of \u2126. We will assume that the pi,j,k are approximately balanced in the sense that no user-item pair is observed too frequently:\nAssumption 3.1. There is a constant \u03ba > 0 such that for every i, j,\u2211 k pi,j,k \u2264 \u03ba m d1d2 .\nNote that if \u03ba = 1 in Assumption 3.1 then the pi,j,k are all equal, meaning that each user-itemitem triple has an equal chance to be observed.\nIn order to state our error bounds, we first introduce some notation: let PX be the distribution of {Yi,j,k : 1 \u2264 i \u2264 d1, 1 \u2264 j < k \u2264 d2} (i.e. the complete distribution of all pairwise preferences, even those that are not observed).\nOur main upper bound shows that if m is sufficiently large then our algorithm finds a solution with almost minimal risk. Given a loss function L, define the expected risk of X by\nR(X) = 1\nd1d22 d1\u2211 i=1 d2\u2211 j,k=1 EX\u2217L(Yijk(Xij \u2212Xik)),\nwhere the expectation is with respect to the distribution parametrized by the true parameters X\u2217.\nTheorem 3.1. Suppose that L is 1-Lipschitz, and let Y and \u2126 be distributed as PX\u2217 for some d1 \u00d7 d2 matrix X\u2217. Under Assumption 3.1,\nER(X\u0302) \u2264 inf {X:\u2016X\u2016\u2217\u2264 \u221a \u03bbd1d2}\nER(X) + C\u03ba \u221a \u03bb(d1 + d2)\nm log(d1 + d2),\nwhere C is a universal constant.\nWe recall that the parameter \u03bb is related to rank in that if X is a d1 \u00d7 d2 rank-r matrix whose largest absolute entry is bounded by C then \u2016X\u2016\u2217 \u2264 \u221a r\u2016X\u2016F \u2264 C \u221a rd1d2. In other words, \u03bb is a parameter that takes into account both the rank of X\u2217 and the size of its elements, and it is roughly proportional to the rank. In particular, Theorem 3.1 shows that once we observe m \u223c r(d1+ d2) log\n2(d1 + d2) pairwise comparisons, then we can accurately estimate the probability of any user preferring any item over any other. In other words, we need to observe about r(1+d2/d1) log\n2(d1 + d2) comparisons per user, which is substantially less than the rd2 log(d2) comparisons that we would have required if each user were modelled in isolation. Moreover, our lower bound (below) shows that at least r(1+d2/d1) comparisons per user are required, which is only a logarithmic factor from the upper bound.\nTheorem 3.2. Suppose that L\u2032(0) < 0. Let A be any algorithm that receives {Yi,j,k : (i, j, k) \u2208 \u2126} as input and produces X\u0302 as output. For any \u03bb \u2265 1 and m \u2265 d1 + d2, there exists X\u2217 with \u2016X\u2217\u2016\u2217 \u2264 \u221a \u03bbd1d2 such that when Y and \u2126 are distributed according to PX\u2217 then with probability at least 12 ,\nER(X\u0302) \u2265 R(X\u2217) + cmin { 1, \u221a \u03bb(d1 + d2)\nm\n} ,\nwhere c > 0 is a constant depending only on L.\nTogether, Theorems 3.1 and 3.2 show that (up to logarithmic factors) ifX\u2217 has rank r then about r(1 + d2/d1) comparisons per user are necessary and sufficient for learning the users\u2019 preferences."}, {"heading": "3.1.1 Maximum likelihood estimation of X\u2217", "text": "By specializing the loss function L, Theorem 3.1 has a simple corollary for maximum-likelihood estimation of X\u2217. Recall that if \u00b5 and \u03bd are two probability distributions on a finite set S the the\nKullback-Leibler divergence between them is\nD(\u00b5\u2016\u03bd) = \u2211 s\u2208S \u00b5(s) log \u00b5(s) \u03bd(s) ,\nunder the convention that 0 log 0 = 0. We recall that although D(\u00b7\u2016\u00b7) is not a metric it is always non-negative, and that D(\u00b5\u2016\u03bd) = 0 implies \u00b5 = \u03bd.\nCorollary 3.3. Let Y and \u2126 be distributed as PX\u2217 for some d1 \u00d7 d2 matrix X\u2217. Define the loss function L by L(z) = log(1 + exp(z))\u2212 z. Under Assumption 3.1,\n1\nd1d22 sup {X:\u2016X\u2016\u2217\u2264 \u221a \u03bbd1d2}\nD(PX\u2217\u2016PX\u0302)\u2212D(PX\u2217\u2016PX) \u2264 C\u03ba \u221a \u03bb(d1 + d2)\nm log(d1 + d2),\nwhere C is a universal constant.\nNote that the loss function in Corollary 3.3 is exactly the negative logarithm of the logistic function, and so X\u0302 in Corollary 3.3 is the maximum-likelihood estimate for X\u2217. Thus, Corollary 3.3 shows that the distribution induced by the maximum-likelihood estimator is close to the true distribution in Kullback-Leibler divergence."}, {"heading": "4 Large-scale Non-convex Implementation", "text": "While the convex relaxation is statistically near optimal, it is not ideal for large-scale datasets because it requires the solution of a convex program with d1 \u00d7 d2 variables. In this section we develop a non-convex variant which both scales and parallelizes very well, and has better empirical performance as compared to several existing empirical baseline methods.\nOur approach is based on the following steps:\n1. We represent the low-rank matrix in explicit factored form X = UV > and replace the regularizer appropriately. This results in a non-convex optimization problem in U \u2208 Rd1\u00d7r and V \u2208 Rd2\u00d7r, where r is the rank parameter.\n2. We solve the non-convex problem by alternating between updating U while keeping V fixed, and vice versa. With the hinge loss (which we found works best in experiments), each of these becomes an SVM problem - hence we call our algorithm AltSVM.\n3. The problem is of course not symmetric in U and V because users rank items but not vice versa. For the U update, each user vector naturally decouples and can be done in parallel (and in fact just reduces to the case of rankSVM [12]).\n4. For the V update, we show that this can also be made into an SVM problem; however it involves coupling of all item vectors, and all user ratings. We employ several tricks (detailed below) to speed up and effectively parallelize this step.\nThe non-convex problem can be written as\nmin U,V \u2211 (i,j,k)\u2208\u2126 L(Yijk \u00b7 u>i (vj \u2212 vk)) + \u03bb 2 (\u2016U\u20162F + \u2016V \u20162F ) (3)\nwhere we replace the nuclear norm regularizer using the property \u2016X\u2016\u2217 = minX=UV > 12(\u2016U\u2016 2 F + \u2016V \u20162F ) [24]. u>i and v>i denote the ith rows of U and V , respectively. While this is a non-convex algorithm for which it is hard to find the global optimum, it is computationally more efficient since only (d1 +d2)r variables are involved. We propose to use L2 hinge loss, i.e., L(x) = max(0, 1\u2212x)2.\nIn the alternating minimization of (3), the subproblem for U is to solve\nU \u2190 arg min U\u2208Rd1\u00d7r \u2211 (i,j,k)\u2208\u2126 L(Yijk \u00b7 u>i (vj \u2212 vj)) + \u03bb 2 \u2016U\u20162F , (4)\nwhile V is fixed. This can be decomposed into n independent problems for ui\u2019s where each solves for\nui \u2190 arg min u\u2208Rr\n\u03bb 2 \u2016u\u201622 + \u2211 (j,k)\u2208\u2126i L(Yijk \u00b7 u>(vj \u2212 vk). (5)\nThis part is in general a small-scale problem as the dimension is r, and the sample size is |\u2126i| for each user i.\nOn the other hand, solving for V with fixed U can be written as\nV \u2190 arg min V \u2208Rd2\u00d7r \u03bb2 \u2016V \u20162F + \u2211 (i,j,k)\u2208\u2126 L(\u3008V,A(u,i,j)\u3009)  (6) where A(i,j,k) \u2208 Rd2\u00d7r is such that the lth row of A(i,j,k) is Yijk \u00b7 u>i if l = j, \u2212Yijk \u00b7 u>i if l = k, and 0 otherwise. It is a much larger SVM problem than (5) as the dimension is d2r and the sample size is |\u2126|.\nWe note that the feature matrices {A(i,j,k) : (i, j, k) \u2208 \u2126} are highly sparse since in each feature matrix only 2r out of the d2r elements are nonzero. This motivates us to apply the stochastic dual coordinate descent algorithm [7, 22], which not only converges fast but also takes advantages of feature sparsity in linear SVMs. Each coordinate descent step takes O(r) computation, and iterations over |\u2126| coordinates provide linear convergence [22].\nNow we describe the dual problems of our two subproblems explicitly. Let \u03b1 \u2208 R|\u2126i| denote the dual vector for (5), in which each coordinate is denoted by \u03b1ijk where (j, k) \u2208 \u2126i. Then the dual problem of (5) is to solve\nmin \u03b1\u2208R|\u2126i|,\u03b1\u22650\n1\n2 \u2225\u2225\u2225\u2225\u2225\u2225 \u2211\n(j,k)\u2208\u2126i\n\u03b1ijkYijk(vj \u2212 vk) \u2225\u2225\u2225\u2225\u2225\u2225 2\n2\n+ 1\n\u03bb \u2211 (j,k)\u2208\u2126i L\u2217(\u2212\u03bb\u03b1ijk) (7)\nwhere L\u2217(z) is the convex conjugate of L. At each coordinate descent step for \u03b1ijk, we find the value of \u03b1ijk minimizing (7) while all the other variables are fixed. If we maintain ui =\u2211\n(j,k)\u2208\u2126i \u03b1ijkYijk(vj \u2212 vk), then the coordinate descent step is simply to find \u03b4 \u2217 minimizing\n1 2 \u2016ui + \u03b4\u2217Yijk(vj \u2212 vk)\u201622 + 1 \u03bb L\u2217(\u2212\u03bb(\u03b1ijk + \u03b4\u2217)) (8)\nand update \u03b1ijk \u2190 \u03b1ijk + \u03b4\u2217.\nAlgorithm 1 Alternating Support Vector Machine (AltSVM)\nRequire: \u2126, {Yijk : (i, j, k) \u2208 \u2126}, and \u03bb \u2208 R+ Ensure: U \u2208 Rd1\u00d7r, V \u2208 Rd2\u00d7r\n1: Initialize U , and set \u03b1, \u03b2 \u2190 0 \u2208 R|\u2126| 2: while not converged do 3: vj \u2190\n\u2211 (i,j,k)\u2208\u2126 \u03b2ijkYijkui \u2212 \u2211\n(i,k,j)\u2208\u2126 \u03b2ikjYikjui, \u2200j \u2208 [d2] 4: for all threads t = 1, . . . , T in parallel do 5: for s = 1, . . . , S do 6: Choose (i, j, k) \u2208 \u2126 uniformly at random 7: Find \u03b4\u2217 minimizing (10). 8: \u03b2ijk \u2190 \u03b2ijk + \u03b4\u2217 9: vj \u2190 vj + \u03b4\u2217Yijkui\n10: vk \u2190 vk \u2212 \u03b4\u2217Yijkui 11: end for 12: end for 13: ui \u2190 \u2211 (i,j,k)\u2208\u2126 \u03b1ijkYijk(vj \u2212 vk), \u2200i \u2208 [d1] 14: for all threads t = 1, . . . , T in parallel do 15: for s = 1, . . . , S do 16: Choose (i, j, k) \u2208 \u2126 uniformly at random. 17: Find \u03b4\u2217 minimizing (8). 18: \u03b1ijk \u2190 \u03b1ijk + \u03b4\u2217 19: ui \u2190 ui + \u03b4\u2217Yijk(vj \u2212 vk) 20: end for 21: end for 22: end while\nThe dual problem of (6) is to solve\nmin \u03b2\u2208R|\u2126|,\u03b2\u22650\n1\n2 \u2225\u2225\u2225\u2225\u2225\u2225 \u2211\n(i,j,k)\u2208\u2126\n\u03b2ijkA (i,j,k) \u2225\u2225\u2225\u2225\u2225\u2225 2\nF\n+ 1\n\u03bb \u2211 (i,j,k)\u2208\u2126 L\u2217(\u2212\u03bb\u03b2ijk) (9)\nwhere \u03b2 is the dual vector for the subproblem (6). Similarly to \u03b1ijk, the coordinate descent step for \u03b2ijk is to replace \u03b2ijk by \u03b2ijk + \u03b4 \u2217 where \u03b4\u2217 minimizes\n1\n2\n( \u2016vj + \u03b4\u2217Yijkui\u201622 + \u2016vk \u2212 \u03b4 \u2217Yijkui\u201622 ) + L\u2217(\u2212\u03bb(\u03b2ijk + \u03b4\u2217)), (10)\nand maintain V = \u2211\n(i,j,k)\u2208\u2126 \u03b2ijkYijkA (i,j,k).\nThe detailed description of AltSVM is presented in Algorithm 1. In each subproblem, we run the stochastic dual coordinate descent, in which a pairwise comparison (i, j, k) \u2208 \u2126 is chosen uniformly at random, and the dual coordinate descent for \u03b1ijk or \u03b2ijk is computed. We note that each coordinate descent step takes the same O(r) computational cost in both subproblems, while the subproblem sizes are much different."}, {"heading": "4.1 Parallelization", "text": "For each subproblem, we parallelize the stochastic dual coordinate descent algorithm asynchronously without locking. Given T processors, each processor randomly sample a triple (i, j, k) \u2208 \u2126 and update the corresponding dual variable and the user or item vectors. We note that this update is for a sparse subset of the parameters. In the user part, a coordinate descent step for one sample updates only r out of the rd1 variables. In the item part, one coordinate descent step for a sample update only 2r out of the rd2 variables. This motivates us not to lock the variables when updated, so that we ignore the conflicts. This lock-free parallelism is shown to be effective in [19] for stochastic gradient descent (SGD) on the sum of sparse functions. Moreover, in [8], it is also shown that the stochastic dual coordinate descent scales well without locking. We implemented the algorithm using the OpenMP framework. In our implementations, we also parallelized steps 3 and 13 of Algorithm 1. We show in the next section that our proposed algorithm scales up favorably."}, {"heading": "4.2 Remark on the implementation", "text": "In Algorithm 1, the subproblem for V comes first, and then it solves for the user vectors U . We empirically observed that this order gives better convergence on practical datasets. We also note that each subproblem reuses the dual variables in the previous outer iteration. When almost converged, the features (V for solving U , and U for solving V ) do not change too much. By reusing the dual variables in the previous iteration we can start with a feasible solution close to the optimum."}, {"heading": "5 Experimental results", "text": ""}, {"heading": "5.1 Pairwise data", "text": "We used the MovieLens 100k dataset, which contains 100,000 ratings given by 943 users on 1682 movies. The ratings are given as integers from one to five, but we converted them into preference data by declaring that a user preferred one movie to another if they gave it a higher rating (if two movies received the same rating, we treated it as though the user did not provide a preference). Then we held out 20% of the data as a test set.\nWe compared our algorithm to the following two:\n\u2022 Bayesian Personalized Ranking (BPR) [20]: This algorithm is based on a similar model to ours, but a different optimization procedure (essentially, a variant of stochastic gradient descent).\n\u2022 Matrix completion from pairwise differences : A standard matrix completion algorithm that observes \u2013 for various triples (i, j, k) \u2208 \u2126 \u2013 the difference between user i\u2019s ratings for item j and item k. Note that this algorithm has an advantage over (2) because it sees the magnitude of this difference instead of only its sign. Nevertheless, the matrix completion algorithm does not perform any better than (2). A similar phenomenon was also observed in [4].\nWe evaluate our performance by computing the proportion of pairwise comparisons in the test set T for which we correctly infer the user\u2019s preference.\n(Prediction error) = 1 |T | \u2211\n(i,j,k)\u2208T ,Yijk=1\nI(Xij > Xik)\nThis is similar to the AUC statistic measured by Rendle et al. [20], and if the data were fully observed then it would measure Kendall\u2019s distance between each user\u2019s true preferences and the learned ones. However, our main reason for choosing this measure of performance is that, as an average accuracy over all pairwise comparisions, it resembles the quantity that we study in our theoretical bounds.\nUnsurprisingly, we were more accurate at correctly inferring strong preferences; therefore, we have also shown the accuracy obtained by only measuring performance on pairs whose rankings differ by two or more. Both the methods we considered do measurably better at predicting these orderings."}, {"heading": "5.2 Large-scale experiments on rating data", "text": "Now we demonstrate that our algorithm performs well as a collaborative ranking method on rating data. We used the datasets specified in Table 1. Given a training set of ratings for each user, our algorithm will only use non-tying pairwise comparisons from the set, while other competing algorithms use the ratings themselves. Hence, they have more information than ours. The competing algorithms are those with publicly available codes provided by the authors.\n\u2022 CofiRank [28]1 This algorithm uses alternating minimization to directly optimize NDCG. 1http://www.cofirank.org, The dimension and the regularization parameter are set as suggested in the paper.\nFor the rest of the parameters, we left them as provided.\n\u2022 Local Collaborative Ranking (LCR) [13]2 : The main idea is to predict preferences from the weighted sum of multiple low-rank matrices model.\n\u2022 RobiRank [32]3 : This algorithm uses stochastic gradient descent to optimize the loss function motivated from robust binary classification.\n\u2022 Global Ranking : To see the effect of personalized ranking, we compare the results with a global ranking of the items. We fixed U to all ones and solved for V .\nThe algorithms are compared in terms of two standard performance measures of ranking, which are NDCG and Precision@K. NDCG@K is the ranking measure for numerical ratings. NDCG@K for user i is defined as\nNDCG@K(i) = DCG@K(i, \u03c0i)\nDCG@K(i, \u03c0\u2217i )\nwhere\nDCG@K(i, \u03c0i) = K\u2211 k=1 2Mi\u03c0i(k) \u2212 1 log2(k + 1) ,\nand \u03c0u(k) is the index of the kth ranked item of Ti in our prediction. Mij is the true rating of item j by user i in the given dataset, and \u03c0\u2217u is the permutation that maximizes DCG@K. This measure counts only the top K items in our predicted ranking and put more weights on the prediction of highly ranked items. We measured NDCG@10 in our experiments. Precision@K is the ranking measure for binary ratings. Precision@K for user i is defined as\nPrecision@K(i) = 1\nK \u2211 j\u2208PK(i) Mij\nwhere Mij is the binary rating on item j by user i given in the dataset. This counts the number of relevant items in the predicted top K recommendation. These two measures are averaged over all of the users.\nWe first compare our algorithm with numerical rating based algorithms, CofiRank and LCR. We follow the standard setting that are used in the collaborative ranking literature [28, 2, 26, 13].\n2http://prea.gatech.edu, We run the code with each of the 48 sets of loss function and parameters given in the main code, and the best result is reported. We could not run this algorithm on the Netflix dataset due to time constraint.\n3https://bitbucket.org/d_ijk_stra/robirank, We used the part for collaborative ranking from binary relevence score. We left the parameter settings as provide with the implementation.\nFor each user, we subsampled N ratings, used them for training, and took the rest of the ratings for test. The users with less than N + 10 ratings were dropped out. Table 2 compares AltSVM with numerical rating based algorithms. While N = 20 is too small so that a global ranking provides the best NDCG, our algorithm performs the best with larger N . We also ran our algorithm with subsampled pairwise comparions with the largest numerical gap (AltSVM-sub), which are as many as N for each user (the number of numerical ratings used in the other algorithms). Even with this, we could achieve better NDCG. We can also observe that the statistical performance is better with the hinge loss than with the logistic loss.\nWe have also experimented with collaborative ranking on binary ratings. We compare our algorithm against RobiRank [32], which is a recently proposed algorithm for collaborative ranking with binary ratings. We ran an experiment on a binarized version of the Movielens1m dataset. In this case, the movies rated by a user is assumed to be relevant to the user, and the other items are not. Since it is inefficient to take all possible comparisons which are in average a half million per user, we subsampled C comparisons for each user. Both algorithms are set to estimate rank-100 matrices. Table 3 shows that our algorithm provides better performance than RobiRank."}, {"heading": "5.3 Computational speed and Scalability", "text": "We now show the computational speed and scalability of our practical algorithm, AltSVM. The experiments were run on a single 16-core machine in the Stampede Cluster at University of Texas.\nFigures 2a and 2b show NDCG@10 over time of our algorithms with 1, 4, and 16 threads, com-\npared to CofiRank. Figure 2c shows Precision@10 over time of our algorithm with C = 5000. We note that our algorithm converges faster, while the sample size |\u2126| for our algorithm is larger than the number of training ratings that are used in the competing algorithms. Table 4 shows the scalability of AltSVM. We measured the time to achieve 10\u22125 tolerance on the binarized MovieLens1m dataset. As can be seen in the table, we could achieve significant speedup."}, {"heading": "6 Conclusion", "text": "We considered the collaborative ranking problem where one fits a low-rank matrix to the pairwise comparisons by multiple users. We showed that the convex relaxation of the empirical risk minimization provides good generalization guarantees. For the large-scale practical settings, we also proposed a non-convex algorithm, which alternately solves two SVM problems. Our algorithm was shown to outperform the existing ones and parallelizes well."}, {"heading": "A Proof of Theorem 3.1", "text": "We write L(X) for the function being optimized; i.e., L(X) = \u2211\n(i,j,k)\u2208\u2126\nL(Yi,j,k(Xi,j \u2212Xi,k)).\nNote that for any fixed X, PX\u2217L(X) = mR(X) (where PX\u2217 denotes the expectation taken with respect to future samples from PX\u2217 , as distinct from E which denotes the expectation over the samples used to generate X\u0302). Let K be the set of d1 \u00d7 d2 matrices with nuclear norm at most 1. The proof of Theorem 3.1 proceeds in three main steps.\n1. By some algebraic of manipulations L, we reduce the problem to showing a uniform law of large numbers for the family of functions {L(X) : X \u2208 \u221a \u03bbd1d2K}.\n2. Using symmetrization and duality properties of K, we reduce the problem to bounding the norm of a matrix M whose entries are sums of random signs.\n3. We bound the norm ofM using various concentration inequalities and a theorem of Seginer [21].\nSince X\u0302, by definition, minimizes L(X\u0302), for any X\u0303 \u2208 \u221a \u03bbd1d2K we can bound\nPX\u2217 [L(X\u0302)\u2212 L(X\u0303)] \u2264 PX\u2217 [L(X\u0302)]\u2212 L(X\u0302)\u2212 ( PX\u2217 [L(X\u0303)]\u2212 L(X\u0303) ) \u2264 2 sup\nX\u2208 \u221a \u03bbd1d2k\n|PX\u2217L(X)\u2212 L(X)|.\nIn other words, it suffices to show a uniform law of large numbers for {L(X) : X \u2208 \u221a \u03bbd1d2K}.\nLet i,j,k be i.i.d. \u00b11-valued variables and let \u03bei,j,k be the indicator that (i, j, k) \u2208 \u2126. By Gine\u0301-Zinn\u2019s symmetrization (as in [4]),\nsup X\u2208 \u221a \u03bbd1d2K\n|PX\u2217L(X)\u2212 L(X)|\n\u2264 2E sup X\u2208 \u221a \u03bbd1d2K \u2223\u2223\u2223\u2223\u2223\u2223 \u2211 i,j,k\u2208\u2126 i,j,kL(Yi,j,k(Xi,j \u2212Xi,k)) \u2223\u2223\u2223\u2223\u2223\u2223 . Since L is 1-Lipschitz, we obtain\nsup X\u2208 \u221a \u03bbd1d2K |PX\u2217 [L(X)]\u2212 L(X)| \u2264 2E sup X\u2208 \u221a \u03bbd1d2K \u2223\u2223\u2223\u2223\u2223\u2223 \u2211 i,j,k\u2208\u2126 i,j,kYi,j,k(Xi,j \u2212Xi,k) \u2223\u2223\u2223\u2223\u2223\u2223 = 2E sup\nX\u2208 \u221a \u03bbd1d2K \u2223\u2223\u2223\u2223\u2223\u2223 \u2211 i,j,k \u03bei,j,k i,j,k(Xi,j \u2212Xi,k) \u2223\u2223\u2223\u2223\u2223\u2223 , where in the last line, we recognized that i,j,kYi,j,k has the same distribution as i,j,k. Now, let M denote the matrix where Mij =\n\u2211 k(\u03bei,j,k i,j,k \u2212 \u03bei,k,j i,k,j). Then\u2211\ni,j,k\n\u03bei,j,k i,j,k(Xi,j \u2212Xi,k) = tr(MTX)\nand so sup\nX\u2208 \u221a \u03bbd1d2K \u2211 i,j,k \u03bei,j,k i,j,k(Xi,j \u2212Xi,k) = sup X\u2208 \u221a \u03bbd1d2K tr(MTX) = \u221a \u03bbd1d2\u2016M\u2016.\nPutting everything together, we have (for any X\u0303 \u2208 \u221a \u03bbd1d2K)\nE [ PX\u2217 [L(X\u0302)]\u2212 PX\u2217 [L(X\u0303)] ] \u2264 4 \u221a \u03bbd1d2E\u2016M\u2016.\nTogether with the following lemma (which we prove in Appendix B), this completes the proof of Theorem 3.1\nLemma A.1. With p = md1d2 ,\nE\u2016M\u2016 \u2264 C\u03ba \u221a p(d1 + d2) log(d1d2)."}, {"heading": "B Proof of Lemma A.1", "text": "We will decompose M into two parts, M = M (1) \u2212M (2), with\nM (1) ij = \u2211 k 6=j \u03bei,j,k i,j,k\nM (2) ij = \u2211 k 6=j \u03bei,k,j i,k,j .\nThen \u2016M\u2016 \u2264 \u2016M (1)\u2016+ \u2016M (2)\u2016. Since M (1) and M (2) have the same distribution,\nE\u2016M\u2016 \u2264 2E\u2016M (1)\u2016,\nand so we are reduced to studying M (1), which has i.i.d. entries. Now, we apply Seginer\u2019s theorem [21]:\nE\u2016M (1)\u2016 \u2264 C ( Emax\ni \u2016M (1)i\u2217 \u20162 + Emaxj \u2016M (1) \u2217j \u20162\n) , (11)\nwhere M (1) i\u2217 denotes the ith row of M (1) and M (1) \u2217j denotes the jth column, and \u2016 \u00b7 \u20162 denotes the Euclidean norm. We will separate the task of bounding Emaxi \u2016M (1)i\u2217 \u20162 into two parts: if \u2016x\u20160 denotes the\nnumber of non-zero coordinates in x and \u2016x\u2016\u221e denotes maxj |xj | then \u2016x\u20162 \u2264 \u221a \u2016x\u20160\u2016x\u2016\u221e; with the Cauchy-Schwarz inequality, this implies that( E [ max i \u2016M (1)i\u2217 \u20162 ])2 \u2264 E [ max i \u2016M (1)i\u2217 \u20160 ] E [ max i \u2016M (1)i\u2217 \u2016 2 \u221e ] (12)\nFirst, we will show that every row of M (1) is sparse. Let Zij = \u2211\nk 6=j \u03bei,j,k and let Yij be the indicator that Zij > 0. Recalling that E\u03bei,j,k = pi,j,k, we have (by Assumption 3.1) EZij \u2264 \u03bap. Since Zij takes non-negative integer values, we have Pr(Yij = 1) = Pr(Zij > 0) \u2264 \u03bap. By Bernstein\u2019s inequality, for any fixed i\nPr(\u2016M (1)i\u2217 \u20160 \u2265 \u03bad2p+ t) \u2264 Pr( d2\u2211 j=1 Yij \u2265 \u03bad2p+ t) \u2264 exp ( \u2212 t 2/2 \u03bapd2 + t/3 ) .\nIntegrating by parts, we have\nE [ \u2016M (1)i\u2217 \u20160 ] \u2264 \u03bad2p+ \u222b \u221e \u03bad2p Pr(\u2016M (1)i\u2217 \u20160 \u2265 t) dt \u2264 \u03bad2p+ 3 8 .\nNext, we will consider the size of the elements in M (1). First of all, M (1) ij \u2264 Zij (this fairly crude bound will lose us a factor of \u221a\nlog(d1d2)). Now, Bernstein\u2019s inequality applied to Zij gives\nPr(M (1) ij \u2265 \u03bap+ t) \u2264 Pr(Zij \u2265 \u03bap+ t) \u2264 exp\n( \u2212 t 2/2\n\u03bap+ t/3\n) .\nTaking a union bound over i and j, if t \u2265 C\u03ba log(d1d2) then\nPr(max ij\nM (1) ij \u2265 t) \u2264 d1d2 exp (\u2212ct) \u2264 exp(\u2212c \u2032t).\nIntegrating by parts, E [ max ij M (1) ij ] \u2264 \u03ba log2(d1d2) + \u222b \u221e \u03ba log2(d1d2) Pr(max ij M (1) ij \u2265 \u221a t) dt \u2264 \u03ba log2(d1d2) + C.\nGoing back to (12), we have shown that\nEmax i \u2016M (1)i\u2217 \u2016 \u2264 C\u03ba\n\u221a pd2 log(d1d2).\nThe same argument applies to M (1) \u2217j (but with \u221a pd1 instead of \u221a pd2), and so we conclude from (11) that E\u2016M (1)\u2016 \u2264 C\u03ba \u221a p(d1 + d2) log(d1d2)."}, {"heading": "C Proof of Theorem 3.2", "text": "C.1 A sketch of the proof\nThe proof of Theorem 3.2 uses Fano\u2019s inequality.\n1. We construct matrices X1, . . . , X`. These matrices all have small nuclear norm, and for every pair i, j the KL-divergence between the induced observation distributions is \u0398(log `). We construct these matrices randomly, using concentration inequalities and a union bound to show that we can take ` of the order \u221a \u03bbm(d1 + d2).\n2. We apply Fano\u2019s inequality to show that if we generate data according to a randomly chosen Xi, then any algorithm has a reasonable chance to choose a different Xj (using the fact that the KL-divergence is O(log `)). Since the KL-divergence is \u2126(log `), this implies that the algorithm incurs a substantial penalty whenever it makes a wrong choice.\nIn any application of Fano\u2019s inequality, the key is to construct a large number of admissible models that are close to one another in KL-divergence. Specifically, if we can construct distributions P1, . . . ,P` with D(Pi\u2016Pj) + 1 \u2264 12 log ` for all i, j, then given a single sample from some Pi, no algorithm can accurately identify which Pi it came from. In order to apply this denote by PX,m the distribution of the data when the true parameters are X. We will construct X1 . . . , X` \u2208 \u221a \u03bbd1d2K such that for all i 6= j,\nD(PXi,m\u2016PXj ,m) + 1 \u2264 1\n2 log `, (13)\nRj(X i) \u2265 Rj(Xj) + c\nlog `\nm (14)\nfor some constant c > 0, where Rj denotes the expected risk when the true parameters are given by Xj . Given a single observation from some PXj ,m, (13) will imply (by Fano\u2019s inequality) that no algorithm can correctly identify which Xj was the true parameter. On the other hand, (14) will imply that if the algorithm makes a mistake \u2013 say it chooses Xi for i 6= j \u2013 then its risk will be c log `m larger than the best in the class. In particular, if we can prove (13) and (14) with\nlog ` \u223c \u221a \u03bbm(d1 + d2) then it will imply Theorem 3.2.\nWe construct a set of matrices satisfying (13) and (14) using a probabilistic method. Supposing that d2 \u2265 d1, we choose a parameter \u03b3 > 0 and set B to be an integer that is approximately \u03bb\u03b3\u22122. We define X1 by filling its top B\u00d7d2 block with independent, uniform \u00b1\u03b3 entries, and then copying that top block B/d1 times to fill the matrix. Then let X\n2, . . . , X` be independent copies of X1. First of all, each Xi \u2208 \u221a \u03bbd1d2K because \u2016Xi\u2016\u2217 \u2264 \u221a rank(Xi)\u2016Xi\u2016F \u2264 \u221a \u03bbd1d2.\nNow, let us consider D(PX1,m\u2016PX2,m). For a single i, j, k triple, there is probability 1/4 of having X1i,j\u2212X1i,k different from X2i,j\u2212X2i,k, in which case they differ by 4\u03b3. If \u03b3 is bounded above, each different entry contributes \u0398(\u03b12\u03b32) to the KL-divergence between PX1,m and PX2,m. Since about m entries are observed in PX1,m, we see that\nD(PX1,m\u2016PX2,m) m\u03b32. (15)\nOn the other hand, R1(X 1) and R1(X 2) differ by \u0398(\u03b32), because for a constant fraction of triples i, j, k, the chance that Yi,j,k is 1 differs by O(\u03b3) in X\n1 and X2, and on the event that Yi,j,k differs in these two models the loss differs by another O(\u03b3) factor.\nApplying standard concentration inequalities, we show that one can apply the union bound to ` = exp(cBd2) of these matrices. In view of (13) and (15), we need to take Bd2 = \u03bb2\n\u03b32d1 m\u03b32. Eliminating \u03b3, we end up with log ` \u221a \u03bbm/d1 (which is within a constant factor of \u221a \u03bbm(d1 + d2) under our assumption that d2 \u2265 d1).\nC.2 Some concentration lemmas\nWe begin by quoting some standard concentration results (see, e.g. [25]).\nDefinition C.1. A random variable X is \u03c32-subgaussian if Ee\u03b8X \u2264 e\u03b82\u03c32/2 for all \u03b8 > 0. A random variable X is L-subexponential if Ee\u03b8X \u2264 (1\u2212 \u03b82L2) for \u03b8 < 1/L.\nOne can easily show that the product of two subgaussian variables is subexponential:\nLemma C.2. If X is \u03c32-subgaussian and Y is \u03c42-subgaussian then XY is C\u03c3\u03c4 -subexponential for a universal constant C.\nMoreover, one has a Bernstein-type inequality for sums of independent subexponential variables.\nLemma C.3. If X1, . . . , Xk are i.i.d. L-subexponential then\nPr( \u2211 i Xi \u2265 t) \u2264 exp ( \u2212 ct 2 L2k + Lt ) .\nC.3 Construction of a packing set\nLet 0 < \u03b3 < 1 be some parameter to be determined such that B := \u03bb\u03b3\u22122 is an integer.\nProposition C.4. Suppose that L\u2032(0) < 0. For every sufficiently small \u03b3 (depending on L), there exists a set X \u2282 \u221a \u03bbd1d2K of exp(cBd2) d1 \u00d7 d2 matrices such that for any two X1, X2 \u2208 X ,\n1\nd1d22 d1\u2211 i=1 d2\u2211 j,k=1 EX1 [L(Y (X2ij \u2212X2ik))\u2212 L(Y (X1ij \u2212X1ik))] \u2265 c\u03b32\nand for any m, 1\nm D(PX1,m\u2016PX2,m) \u2264 C\u03b32,\nwhere 0 < c < C are universal constants.\nFollowing Davenport et al., we construct this set X randomly: let X be a random B\u00d7d2 matrix, where each element is chosen independently to be either \u03b3 or \u2212\u03b3.\nLemma C.5. Let X1 and X2 be independent copies of X. Then with probability at least 1 \u2212 exp(\u2212cBd2),\nB\u2211 i=1 d2\u2211 j,k=1 (X1ij \u2212X1ik \u2212X2ij +X2ik)2 \u2265 2\u03b32Bd22,\nwhere c > 0 is a universal constant.\nBefore proving Lemma C.5, let us see how it implies Proposition C.4. First of all, for X a random B\u00d7d2 matrix as above, let X\u0303 be the d1\u00d7d2 matrix obtained by stacking dd1/Be copies of X, and filling out any remaining entries by zeros. Then, for random X and Y , with high probability\nd1\u2211 i=1 d2\u2211 j,k=1 (X\u03031ij \u2212 X\u03031ik \u2212 X\u03032ij + X\u03032ik)2 = dd1/Be B\u2211 i=1 d2\u2211 j,k=1 (X1ij \u2212X1ik \u2212X2ij +X2ik)2\n\u03b32d1d22, (16)\nwhere the lower bound for the last line came from Lemma C.5, and the upper bound just came from the observation that each term in the sum is bounded by 16\u03b32. Let X be the set obtained by choosing exp(cBd2/4) random copies of X\u0303 in this way. The high-probability estimate in Lemma C.5 implies that with high probability, every pair X\u03031, X\u03032 in X satisfies (16). Now,\nD(PX1,m\u2016PX2,m) = E\u2126  \u2211 (i,j,k)\u2208\u2126 D(f(X1ij \u2212X1ik)\u2016f(X2ij \u2212X2ik))  m d1d22 \u2211 i,j,k (X1ij \u2212X1ik \u2212X2ij +X2ik)2,\nwhere f(x) = ex/(1 + ex) is the logistic function, and the last line follows from a Taylor expansion of D(f(x)\u2016f(y)) around x = y, because all the X1ij and X2ij are bounded by \u03b3 < 1. Together with (16), this proves the first inequality in Proposition C.4; the second inequality follows because\neach term of the form D(f(Xij\u2212Xik)\u2016f(Yij\u2212Yik)) is bounded by a constant times \u03b32. This proves the second inequality of Proposition C.4.\nBy Taylor expansion again, if \u03b3 is sufficiently small (depending on L) then\nL(Yi,j,k(X2i,j \u2212X2i,k))\u2212 L(Yi,j,k(X1i,j \u2212X1i,k)) Yi,j,k(X1i,j \u2212X1i,k \u2212X2i,j +X2i,k).\nNow, if i, j, k is a triple for which 2\u03b3 = X1i,j\u2212X1i,k > X2i,j\u2212X2i,k (and under the event of Lemma C.5, there are at least cBd22 such triples) then EX1 [Yi,j,k] \u03b3 and so\nEX1 [L(Yi,j,k(X2i,j \u2212X2i,k))\u2212 L(Yi,j,k(X1i,j \u2212X1i,k))] \u03b32.\nThe same holds when i, j, k is a triple for which \u22122\u03b3 = X1i,j \u2212X1i,k < X2i,j \u2212X2i,k. Finally, if i, j, k is a triple such that X1i,j \u2212X1i,k = X2i,j \u2212X2i,k then the expectation is zero. Summing over all triples, we see that on the event that Lemma C.5 holds,\n1\nBd22 \u2211 i,j,k EX1 [L(Yi,j,k(X2i,j \u2212X2i,k))\u2212 L(Yi,j,k(X1i,j \u2212X1i,k))] \u2265 c\u03b32.\nAfter summing over all dd1/Be blocks, this proves the first inequality of Proposition C.4.\nProof of Lemma C.5. We expand the square:\u2211 ijk (Xij \u2212Xik \u2212 Yij + Yik)2 = 2 \u2211 ijk X2ij + Y 2 ij + 2XijYik \u2212XijXik \u2212 YijYik \u2212 2XijYij\n= 4\u03b32Bd22 + 2 \u2211 ijk 2XijYik \u2212XijXik \u2212 YijYik \u2212 2XijYij . (17)\nWe may study each of the cross-terms separately: for the XijYik term, note that \u2211 j Xij and \u2211\nk Yik are both \u03b32d2-subgaussian (by Hoeffding\u2019s inequality). Hence, \u2211 jkXijYik is C\u03b3\n2d2-subexponential (by Lemma C.2) and so by Lemma C.3,\nPr \u2223\u2223\u2223\u2223\u2223\u2223 \u2211 ijk XijYik \u2223\u2223\u2223\u2223\u2223\u2223 \u2265 18\u03b32Bd22  \u2264 2 exp(\u2212cBd2).\nThe similar argument applies to the XijXik term: \u2211 j Xij is \u03b3 2d2-subgaussian and so \u2211 ijkXijXik =\u2211\ni( \u2211 j Xij) 2 is C\u03b32d2-subexponential; hence\nPr \u2223\u2223\u2223\u2223\u2223\u2223 \u2211 ijk XijXik \u2223\u2223\u2223\u2223\u2223\u2223 \u2265 18\u03b32Bd22  \u2264 2 exp(\u2212cBd2).\nOf course, the YijYik term is identical. Finally, note that \u2211 ijkXijYij = d2 \u2211\nij XijYij . Since the terms in this sum are i.i.d., we may apply Hoeffding\u2019s inequality to obtain\nPr \u2223\u2223\u2223\u2223\u2223\u2223 \u2211 ijk XijYij \u2223\u2223\u2223\u2223\u2223\u2223 \u2265 18\u03b32Bd22  = Pr \u2223\u2223\u2223\u2223\u2223\u2223 \u2211 ij XijYij \u2223\u2223\u2223\u2223\u2223\u2223 \u2265 18\u03b32Bd2  \u2264 2 exp(\u2212cB2d22).\nPutting everything together, we see that with high probability, the total of all the cross-terms in (17) is at most half of the first term.\nC.4 Completing the proof\nLet C denote the constant from Proposition C.4. Assume that d1 \u2264 d2 and that m is large enough so \u221a\nd2 m \u2264 8C\n\u221a \u03bb \u2264\n\u221a m\nd2 . (18)\nNote that under the assumptions \u03bb \u2265 1 and m \u2265 d1 +d2 from Theorem 3.2, the lower bound of (18) is satisfied. Moreover, if the upper bound of (18) is not satisfied then we may decrease \u03bb until it is; the conclusion of Theorem 3.2 will not be affected because as long as (18) fails, the minimum in Theorem 3.2 will be 1.\nBy the lower bound in (18), there is an integer B such that B \u2264 \u221a \u03bbm\nd2 \u2264 2B;\nfix this B and define \u03b3 by\n\u03b32 = \u03bb/B \u221a \u03bbd2 m .\nBy the upper bound in (18), \u03b3 \u2264 1. Now, Fano\u2019s inequality states that if we first select a random X \u2208 X and then draw a sample from PX,m, then any algorithm trying to identify X can succeed with probability at most\nmin{D(PX,m\u2016P(Y,m)) : X,Y \u2208 X}+ 1 log |X | \u2264 2Cm\u03b3 2 Bd2 \u2264 1 2 .\nFinally, note that by the first inequality in Proposition C.4, the error incurred by choosing the wrong X \u2208 X is at least c\u03b32 \u221a\n\u03bbd2 m .\nNow, we have so far only discussed the case d2 \u2265 d1. The case d1 \u2264 d2 is not exactly equivalent because our model is not symmetric in its treatment of users and items. However, the proof of Theorem 3.2 does not change very much. We take horizontally stacked blocks of size d1\u00d7B instead of B \u00d7 d2. The main difference is in the calculation leading to (16): there are extra cross-terms appearing due to the fact that items in different blocks need to be compared with one another. However, all of these additional terms may be controlled with Lemmas C.2 and C.3 in much the same way as the existing terms are controlled."}, {"heading": "D Comparison to Stochastic Gradient Descent", "text": "Another practical algorithm to optimize (3) is Stochastic Gradient Descent (SGD). We have experimented SGD on the same datasets in Table 1. We ran the algorithm with the same regularization parameters and different step sizes. The statistical results for SGD were observed to be no better than AltSVM, and hence we did not present them in the main paper.\nLet us first describe the SGD procedure. At each step, ones chooses a triple (i, j, k) \u2208 \u2126\nuniformly at random and run a SGD step, which can be written as u+i \u2190 ui \u2212 \u03b7 \u00b7 { g \u00b7 (vj \u2212 vk) + \u03bb\n|\u2126i| ui } v+j \u2190 vj \u2212 \u03b7 \u00b7 { g \u00b7 ui + \u03bb\n|\u2126j | vj } v+j \u2190 vj \u2212 \u03b7 \u00b7 { \u2212g \u00b7 ui + \u03bb\n|\u2126k| vk } where \u2126(j) denotes the number of comparisons in \u2126 which involve item j. \u03b7 is a step size and g \u2208 \u2202L(u>i (vj \u2212 vk)).\nThe following tables show the statistical result of SGD. The step size is chosen by \u03b7 = \u03b11+\u03b2t as suggested in [33]. \u03b1 and \u03b2 were the powers of 10\u22121, and the best result is reported. The results are comparable to AltSVM, but it did not achieve better results. We note that this is the best result from several different step sizes, while AltSVM does not have any other parameter to choose except for the regularization parameter."}], "references": [{"title": "Active learning ranking from pairwise preferences with almost optimal query complexity", "author": ["Ailon", "Nir"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2011}, {"title": "Collaborative ranking", "author": ["Balakrishnan", "Suhrid", "Chopra", "Sumit"], "venue": "In ACM International Conference on Web Search and Data Mining (WSDM),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Rank analysis of incomplete block designs: I. the method of paired comparisons", "author": ["Bradley", "Ralph Allan", "Terry", "Milton E"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1952}, {"title": "1-bit matrix completion", "author": ["Davenport", "Mark A", "Plan", "Yaniv", "Berg", "Ewout van den", "Wootters", "Mary"], "venue": "Information and Inference,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Minimax-optimal inference from partial rankings", "author": ["Hajek", "Bruce", "Oh", "Sewoong", "Xu", "Jiaming"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Large Margin Rank Boundaries for Ordinal Regression, chapter 7, pp. 115\u2013132", "author": ["Herbrich", "Ralf", "Graepel", "Thore", "Obermayer", "Klaus"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2000}, {"title": "A dual coordinate descent method for large-scale linear SVM", "author": ["Hsieh", "Cho-Jui", "Chang", "Kai-Wei", "Lin", "Chih-Jen", "Keerthi", "S. Sathiya", "S. Sundararajan"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2008}, {"title": "PASSCoDe: Parallel asynchronous stochastic dual co-ordinate descent", "author": ["Hsieh", "Cho-Jui", "Yu", "Hsiang-Fu", "Dhillon", "Inderjit S"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Collaborative filtering for implicit feedback datasets", "author": ["Hu", "Yifan", "Koren", "Yehuda", "Volinsky", "Chris"], "venue": "In IEEE International Conference on Data Mining (ICDM),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "Active ranking using pairwise comparisons", "author": ["K.G. Jamieson", "R. Nowak"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Active ranking using pairwise comparisons", "author": ["Jamieson", "Kevin G", "Nowak", "Robert D"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Optimizing search engines using clickthrough data", "author": ["Joachims", "Thorsten"], "venue": "In SIGKDD,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2002}, {"title": "Local collaborative ranking", "author": ["Lee", "Joonseok", "Bengio", "Samy", "Kim", "Seungyeon", "Lebanon", "Guy", "Singer", "Yoram"], "venue": "In International World Wide Web Conference (WWW),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Probabilistic latent preference analysis for collaborative filtering", "author": ["Liu", "Nathan N", "Zhao", "Min", "Yang", "Qiang"], "venue": "In Proceedings of the 18th ACM conference on Information and knowledge management,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Learning to Rank for Information Retrieval", "author": ["Liu", "Tie-Yan"], "venue": "Now Publishers Inc.,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Individualized rank aggregation using nuclear norm regularization", "author": ["Lu", "Yu", "Negahban", "Sahand"], "venue": "ArXiv e-prints:", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "Iterative ranking from pair-wise comparisons", "author": ["Negahban", "Sahand", "Oh", "Sewoong", "Shah", "Devavrat"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "Hogwild: A lock-free approach to parallelizing stochastic gradient descent", "author": ["Niu", "Feng", "Recht", "Benjamin", "R\u00e9", "Christopher", "Wright", "Stephen"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "Bpr: Bayesian personalized ranking from implicit feedback", "author": ["Rendle", "Steffen", "Freudenthaler", "Christoph", "Gantner", "Zeno", "Schmidt-Thieme", "Lars"], "venue": "In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "The expected norm of random matrices", "author": ["Seginer", "Yoav"], "venue": "Combinatorics Probability and Computing,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2000}, {"title": "Stochastic dual coordinate ascent methods for regularized loss minimization", "author": ["Shalev-Shwartz", "Shai", "Zhang", "Tong"], "venue": "Journal of Machine Learning Research (JMLR),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "Climf: collaborative less-is-more filtering", "author": ["Shi", "Yue", "Karatzoglou", "Alexandros", "Baltrunas", "Linas", "Larson", "Martha", "Oliver", "Nuria", "Hanjalic", "Alan"], "venue": "In Proceedings of the Twenty-Third international joint conference on Artificial Intelligence,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2013}, {"title": "Maximum margin matrix factorization", "author": ["Srebro", "Nathan", "Rennie", "Jason", "Jaakkola", "Tommi"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2004}, {"title": "Compressed sensing: theory and applications, chapter Introduction to the non-asymptotic analysis of random matrices", "author": ["Vershynin", "Roman"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2012}, {"title": "Collaborative ranking with 17 parameters", "author": ["Volkovs", "Maksims N", "Zemel", "Richard S"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2012}, {"title": "Efficient ranking from pairwise comparisons", "author": ["Wauthier", "Fabian L", "Jordan", "Michael I", "Jojic", "Nebojsa"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2013}, {"title": "Cofirank: maximum margin matrix factorization for collaborative ranking", "author": ["Weimer", "Markus", "Karatzoglou", "Alexandros", "Le", "Quoc V", "Smola", "Alex"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2007}, {"title": "Latent collaborative retrieval", "author": ["Weston", "Jason", "Want", "Chong", "Weiss", "Ron", "Berenzeig", "Adam"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2012}, {"title": "Jointly clustering rows and columns of binary matrices: Algorithms and trade-offs", "author": ["Xu", "Jiaming", "Wu", "Rui", "Zhu", "Kai", "Hajek", "Bruce", "R Srikant", "Ying", "Lei"], "venue": "In ACM Sigmetrics,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2013}, {"title": "Inferring users preferences from crowdsourced pairwise comparisons: A matrix completion approach", "author": ["Yi", "Jinfeng", "Jin", "Rong", "Jain", "Shaili", "Anil"], "venue": "In First AAAI Conference on Human Computation and Crowdsourcing,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2013}, {"title": "Ranking via robust binary classification and parallel parameter estimation in large-scale data", "author": ["Yun", "Hyokun", "Raman", "Parameswaran", "S.V.N. Vishwanathan"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2014}], "referenceMentions": [{"referenceID": 6, "context": "We apply a stochastic version of dual coordinate descent [7, 22] with lockfree parallelization.", "startOffset": 57, "endOffset": 64}, {"referenceID": 20, "context": "We apply a stochastic version of dual coordinate descent [7, 22] with lockfree parallelization.", "startOffset": 57, "endOffset": 64}, {"referenceID": 5, "context": "While there have been algorithms that use pairwise comparisons [6, 12] of the training samples, our setting is different in that our data consists only of pairwise comparisons.", "startOffset": 63, "endOffset": 70}, {"referenceID": 11, "context": "While there have been algorithms that use pairwise comparisons [6, 12] of the training samples, our setting is different in that our data consists only of pairwise comparisons.", "startOffset": 63, "endOffset": 70}, {"referenceID": 14, "context": "We refer the reader to the survey [15].", "startOffset": 34, "endOffset": 38}, {"referenceID": 9, "context": "Jamieson & Nowak [10] and Ailon [1] consider an active query model with noiseless responses; Jamieson & Nowak [11] give an algorithm for exactly recovering the true ranking under a low-rank assumption similar to ours, while Ailon [1] approximately recovers the true ranking without such an assumption.", "startOffset": 17, "endOffset": 21}, {"referenceID": 0, "context": "Jamieson & Nowak [10] and Ailon [1] consider an active query model with noiseless responses; Jamieson & Nowak [11] give an algorithm for exactly recovering the true ranking under a low-rank assumption similar to ours, while Ailon [1] approximately recovers the true ranking without such an assumption.", "startOffset": 32, "endOffset": 35}, {"referenceID": 10, "context": "Jamieson & Nowak [10] and Ailon [1] consider an active query model with noiseless responses; Jamieson & Nowak [11] give an algorithm for exactly recovering the true ranking under a low-rank assumption similar to ours, while Ailon [1] approximately recovers the true ranking without such an assumption.", "startOffset": 110, "endOffset": 114}, {"referenceID": 0, "context": "Jamieson & Nowak [10] and Ailon [1] consider an active query model with noiseless responses; Jamieson & Nowak [11] give an algorithm for exactly recovering the true ranking under a low-rank assumption similar to ours, while Ailon [1] approximately recovers the true ranking without such an assumption.", "startOffset": 230, "endOffset": 233}, {"referenceID": 25, "context": "[27] and Negahban et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[18] learn a ranking from noisy pairwise comparisions; Negahban et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[18] consider a Bradley-Terry-Luce model similar to ours and attempt to learn an underlying score vector, while Wauthier et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[27] get by without structure assumptions, but only attempt to learn the ranking itself.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[5] considered a problem to learn a single ranking given a more generalized partial rankings from the Plackett-Luce model and provided a minimax-optimal algorithm.", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "[20] and Liu et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] were the first to take this approach.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[31] took a purely optimization-based approach.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[9] and Shi et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 21, "context": "[23] consider the problem of learning from latent feedback.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "Recently, Lu & Negahban [16] analyzed an algorithm which is very similar to ours for the Bradley-Terry-Luce model independently from our work.", "startOffset": 24, "endOffset": 28}, {"referenceID": 3, "context": "[4] is most closely related to ours, in that they assume an underlying lowrank structure and give an algorithm based on convex optimization.", "startOffset": 0, "endOffset": 3}, {"referenceID": 28, "context": "[30] consider a slightly different goal: rather than attempting to recover the preferences of each user, they try to cluster similar users and similar items together.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[32] proposed an optimization problem motivated from robust binary classification and used stochastic gradient descent to solve the problem in a large-scale setting.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[28] attempted to directly optimize Normalized Discounted Cumulative Gain (NDCG), a widely used performance measure for ranking problems.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "Balakrishnan & Chopra [2], and Volkovs & Zemel [26] converted this problem into a learning-to-rank problem and solved it using the existing algorithms.", "startOffset": 22, "endOffset": 25}, {"referenceID": 24, "context": "Balakrishnan & Chopra [2], and Volkovs & Zemel [26] converted this problem into a learning-to-rank problem and solved it using the existing algorithms.", "startOffset": 47, "endOffset": 51}, {"referenceID": 27, "context": "[29] and Lee et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13].", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[29] proposed a tensor model to rank items for different queries and users, and [13] proposed a weighted sum of low-rank matrix models.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[29] proposed a tensor model to rank items for different queries and users, and [13] proposed a weighted sum of low-rank matrix models.", "startOffset": 80, "endOffset": 84}, {"referenceID": 2, "context": "Recall the classical Bradley-Terry-Luce model [3, 17] for pairwise preferences of a single user, which assumes that the probability of item j being preferred over k is given by a logistic of the difference of the underlying preference scores of the two items.", "startOffset": 46, "endOffset": 53}, {"referenceID": 11, "context": "For the U update, each user vector naturally decouples and can be done in parallel (and in fact just reduces to the case of rankSVM [12]).", "startOffset": 132, "endOffset": 136}, {"referenceID": 22, "context": "where we replace the nuclear norm regularizer using the property \u2016X\u2016\u2217 = minX=UV > 12(\u2016U\u2016 2 F + \u2016V \u2016F ) [24].", "startOffset": 103, "endOffset": 107}, {"referenceID": 6, "context": "This motivates us to apply the stochastic dual coordinate descent algorithm [7, 22], which not only converges fast but also takes advantages of feature sparsity in linear SVMs.", "startOffset": 76, "endOffset": 83}, {"referenceID": 20, "context": "This motivates us to apply the stochastic dual coordinate descent algorithm [7, 22], which not only converges fast but also takes advantages of feature sparsity in linear SVMs.", "startOffset": 76, "endOffset": 83}, {"referenceID": 20, "context": "Each coordinate descent step takes O(r) computation, and iterations over |\u03a9| coordinates provide linear convergence [22].", "startOffset": 116, "endOffset": 120}, {"referenceID": 17, "context": "This lock-free parallelism is shown to be effective in [19] for stochastic gradient descent (SGD) on the sum of sparse functions.", "startOffset": 55, "endOffset": 59}, {"referenceID": 7, "context": "Moreover, in [8], it is also shown that the stochastic dual coordinate descent scales well without locking.", "startOffset": 13, "endOffset": 16}, {"referenceID": 18, "context": "We compared our algorithm to the following two: \u2022 Bayesian Personalized Ranking (BPR) [20]: This algorithm is based on a similar model to ours, but a different optimization procedure (essentially, a variant of stochastic gradient descent).", "startOffset": 86, "endOffset": 90}, {"referenceID": 3, "context": "A similar phenomenon was also observed in [4].", "startOffset": 42, "endOffset": 45}, {"referenceID": 18, "context": "[20], and if the data were fully observed then it would measure Kendall\u2019s distance between each user\u2019s true preferences and the learned ones.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "\u2022 CofiRank [28]1 This algorithm uses alternating minimization to directly optimize NDCG.", "startOffset": 11, "endOffset": 15}, {"referenceID": 12, "context": "\u2022 Local Collaborative Ranking (LCR) [13]2 : The main idea is to predict preferences from the weighted sum of multiple low-rank matrices model.", "startOffset": 36, "endOffset": 40}, {"referenceID": 30, "context": "\u2022 RobiRank [32]3 : This algorithm uses stochastic gradient descent to optimize the loss function motivated from robust binary classification.", "startOffset": 11, "endOffset": 15}, {"referenceID": 26, "context": "We follow the standard setting that are used in the collaborative ranking literature [28, 2, 26, 13].", "startOffset": 85, "endOffset": 100}, {"referenceID": 1, "context": "We follow the standard setting that are used in the collaborative ranking literature [28, 2, 26, 13].", "startOffset": 85, "endOffset": 100}, {"referenceID": 24, "context": "We follow the standard setting that are used in the collaborative ranking literature [28, 2, 26, 13].", "startOffset": 85, "endOffset": 100}, {"referenceID": 12, "context": "We follow the standard setting that are used in the collaborative ranking literature [28, 2, 26, 13].", "startOffset": 85, "endOffset": 100}, {"referenceID": 30, "context": "We compare our algorithm against RobiRank [32], which is a recently proposed algorithm for collaborative ranking with binary ratings.", "startOffset": 42, "endOffset": 46}], "year": 2015, "abstractText": "In this paper we consider the collaborative ranking setting: a pool of users each provides a small number of pairwise preferences between d possible items; from these we need to predict each users preferences for items they have not yet seen. We do so by fitting a rank r score matrix to the pairwise data, and provide two main contributions: (a) we show that an algorithm based on convex optimization provides good generalization guarantees once each user provides as few as O(r log d) pairwise comparisons \u2013 essentially matching the sample complexity required in the related matrix completion setting (which uses actual numerical as opposed to pairwise information), and (b) we develop a large-scale non-convex implementation, which we call AltSVM, that trains a factored form of the matrix via alternating minimization (which we show reduces to alternating SVM problems), and scales and parallelizes very well to large problem settings. It also outperforms common baselines on many moderately large popular collaborative filtering datasets in both NDCG and in other measures of ranking performance.", "creator": "LaTeX with hyperref package"}}}