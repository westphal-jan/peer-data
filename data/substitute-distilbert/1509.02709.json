{"id": "1509.02709", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Sep-2015", "title": "A Topological Approach to Meta-heuristics: Analytical Results on the BFS vs. DFS Algorithm Selection Problem", "abstract": "search is first central problem in artificial intelligence, and bfs and dfs the two most fundamental ways to search. in this report we derive results, average bfs and dfs runtime : for tree search, we employ a probabilistic model of goal distribution ; for graph search, the analysis depends on an additional proof of path redundancy given average branching probability. as an application, builders use the solution on two concrete grammar problems. the runtime assumption can be used to select the faster out of bfs and dfs for a given problem, and may form the basis for further inference of more advanced search alternatives. finally, we verify our results experimentally ; the weak approximations remarkably surprisingly opposite to everyday reality.", "histories": [["v1", "Wed, 9 Sep 2015 10:30:48 GMT  (344kb,D)", "http://arxiv.org/abs/1509.02709v1", "Main results published in 28th Australian Joint Conference on Artificial Intelligence, 2015"]], "COMMENTS": "Main results published in 28th Australian Joint Conference on Artificial Intelligence, 2015", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["tom everitt", "marcus hutter"], "accepted": false, "id": "1509.02709"}, "pdf": {"name": "1509.02709.pdf", "metadata": {"source": "CRF", "title": "A Topological Approach to Meta-heuristics: Analytical Results on the BFS vs. DFS Algorithm Selection Problem", "authors": ["Tom Everitt", "Marcus Hutter"], "emails": [], "sections": [{"heading": null, "text": "Keywords\nBFS, DFS, Analytical Algorithm Selection, Average runtime, Metaheuristics, Tree Search, Graph Search, Probabilistic Goal Distribution\nContents"}, {"heading": "1 Introduction 2", "text": ""}, {"heading": "2 Graph search problems 3", "text": "2.1 Algorithm performance . . . . . . . . . . . . . . . . . . . . . . . 5"}, {"heading": "3 Basic Search Algorithms 6", "text": "3.1 Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 3.2 Uninformed search methods . . . . . . . . . . . . . . . . . . . . . 6 3.3 Informed Constructive Methods . . . . . . . . . . . . . . . . . . . 7 3.4 Informed Local Search . . . . . . . . . . . . . . . . . . . . . . . . 8"}, {"heading": "4 Literature review 8", "text": "4.1 Feature-based Meta-heuristics . . . . . . . . . . . . . . . . . . . . 8 4.2 Learning the search policy . . . . . . . . . . . . . . . . . . . . . . 9\nar X\niv :1\n50 9.\n02 70\n9v 1\n[ cs\n.A I]\n9 S"}, {"heading": "5 Complete Binary Tree 10", "text": "5.1 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 5.2 Complete Binary Tree with a Single Goal Level . . . . . . . . . . 12 5.3 Complete Binary Tree with Multiple Goal Levels . . . . . . . . . 15\n5.3.1 DFS Analysis . . . . . . . . . . . . . . . . . . . . . . . . . 15 5.3.2 BFS Analysis . . . . . . . . . . . . . . . . . . . . . . . . . 16"}, {"heading": "6 Colliding Branches 17", "text": "6.1 DFS Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 6.2 BFS Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19"}, {"heading": "7 Grammar Problems 20", "text": "7.1 Binary Grammar . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 7.2 Random Grammar . . . . . . . . . . . . . . . . . . . . . . . . . . 22 7.3 Full Grammar . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23"}, {"heading": "8 Experimental verification 24", "text": ""}, {"heading": "9 Empirical Predictions 27", "text": ""}, {"heading": "10 Discussion 29", "text": ""}, {"heading": "A List of notation 33", "text": ""}, {"heading": "B List of search problems 34", "text": ""}, {"heading": "C List of Topological features 35", "text": ""}, {"heading": "1 Introduction", "text": "A wide range of problems in artificial intelligence can be naturally formulated as search problems (Russell and Norvig, 2010; Edelkamp and Schro\u0308dl, 2012). Examples include planning, scheduling, and combinatorial optimisation (TSP, graph colouring, etc.), as well as various toy problems such as Sudoku and the Towers of Hanoi. Search problems can be solved by exploring the space of possible solutions in a more or less systematic or clever order. Meta-heuristics are general search methods not aimed at a specific type of problem. They interact with the problem through abstract properties such as a neighbourhood relation on the space of feasible solutions, and a heuristic or objective function. One possible way to create flexible meta-heuristics is to combine a portfolio of search algorithms, and use problem features to predict which search algorithms works the best. Predicting the best algorithm is sometimes known as the algorithm selection problem (Rice, 1975).\nA number of studies have approached the algorithm selection problem with machine learning techniques (Kotthoff, 2014; Hutter et al., 2014). While demonstrably a feasible path, machine learning tend to be used as a black box, offering little insight into why a certain method works better on a given problem. On the other hand, most existing analytical results focus on worst-case big-O analysis, which is often less useful than average-case analysis when selecting algorithm. An important worst-case result is Knuth\u2019s (1975) simple but useful technique\nfor estimating the depth-first search tree size. Kilby et al. (2006) used it for algorithm selection in the SAT problem. See also the extensions by Purdom (1978), Chen (1992), and Lelis et al. (2013). Analytical IDA* runtime predictions based on problem features was obtained by Korf et al. (2001) and Zahavi et al. (2010). In this study we focus on theoretical analysis of average runtime of BFS and DFS. While the IDA* results can be interpreted to give rough estimates for average BFS search time, no similar results are available for DFS.\nTo facilitate the analysis, we use a probabilistic model of goal distribution and graph structure. Currently no method to automatically estimate the model parameters is available (this is an important line of future research). Regardless, the analysis still offers important theoretical insights into BFS and DFS search. The parameters of the model can also be interpreted as a Bayesian prior belief about goal distribution. A precise understanding of BFS and DFS performance is likely to have both practical and theoretical value: Practical, as BFS and DFS are both widely employed; theoretical, as BFS and DFS are two most fundamental ways to search, so their properties may be useful in analytical approaches to more advanced search algorithms as well. In particular, our results may be a first step to selecting search strategy based on the (local) topology of the problem graph, an aspect ignored by most meta-heuristics.\nOur main contribution is an analysis of expected BFS and DFS runtime as a function of tree depth, goal level, branching factor and path redundancy (Sections 5\u20137). We also verify the results experimentally (Section 8). Most of these results will be published as (Everitt and Hutter, 2015a,b). Definitions of different types of search problems and search algorithms are given in Section 2 and 3, and a review of related work can be found in Section 4. Conclusions and outlooks come in Section 9 and 10. Finally, Appendix A provides a list of notation, and Appendix B and C contain lists of search problems and potentially useful topological features."}, {"heading": "2 Graph search problems", "text": "A common feature of many search problems is that there are a set of operations for cheaply modifying a proposed solution into similar proposed solutions. This makes it natural to view the problem as a graph search problem, where proposed solutions are states or nodes, and the modification operations induce directed edges.\nWe define two kinds of graph search problems.\nDefinition 1 (Constructive graph search problem). A constructive graph search problem consists of a state space S, a starting state s0 \u2208 S, and the following efficiently computable functions:\n1. Neighbourhood N : S \u2192 2S\n2. Goal check C : S \u2192 {0, 1} 3. Edge cost: EC : (S \u00d7 S)\u2192 R+\n4. Heuristic h : S \u2192 R+\n5. Contract (tree/graph, solution depth, number of goals, admissible/consistent heuristic)\nItems 4 and 5 are optional. A constructive solution is a path s0, . . . , sn from the starting state s0 to a goal state sn with C(sn) = 1. The solution quality of the\npath s0, . . . , sn is \u2211n\u22121 i=0 EC (si, si+1).\nFor instance, planning problems are formalised as constructive graph search problems. The neighbourhood function gives a list of states reachable by a single action from the given state. The goal check indicates whether a state is a goal, and the edge cost indicates how costly it is to use a certain action (how it affects the solution quality). A solution is a sequence of actions leading to a goal state.\nA heuristic may give an estimate of how close the given state is to a goal state (in terms of edge cost). An important class of heuristics are the admissible ones, that never overestimate the distance. Consistent heuristics additionally respect the triangle inequality. The properties of the heuristics may be given in the contract. The contract is not formalised here, but may be given as a dictionary of known problem properties.\nDefinition 2 (Local graph search problem). A local graph search problem consists of a state space S together with the following efficiently computable functions:\n1. Neighbourhood N : S \u2192 2S\n2. Constraint C : S \u2192 {0, 1} 3. Objective function Q : S \u2192 R 4. Contract (continuity properties of the objective function)\nItem 4 is optional. A local solution is a state s \u2208 S, C(s) = 1, and its solution quality is Q(s).\nIn local graph search problems, the goal is to find an s \u2208 S that satisfies the constraints C and achieves as high objective value as possible. An objective function Q is (Lipschitz) continuous with respect to the neighbourhood topology with Lipschitz constant d if |Q(v1)\u2212Q(v2)| < d whenever v1 and v2 are neighbours. Lipschitz continuity can make a problem easier, as it allows the objective values of surrounding nodes to be estimated from the current target value.\nThe search for an optimal circuit layout is one example of a problem that naturally formalises as a local graph search problems. Neighbours are reached by modifying the current layout (changing one connection), and the objective function incorporates the component cost and the energy efficiency of the layout. The constraint disqualifies circuits that fail the specifications. Also, any constructive search problem G1 = \u3008S1, N1, C1,EC \u3009 may be formulated as local search problem G2 = \u3008S2, N2, C2, Q\u3009, by letting\n\u2022 S2 be the set of paths in G1, \u2022 the objective function Q be the negative sum of the path cost, \u2022 the constraint C2 check whether the last node of the path is a goal node,\nand\n\u2022 the neighbourhood function N2 extend or contract a path by adding or removing a final node according to N1 (better choices of N2 may be available).\nFor example, the travelling salesman problem can be viewed as a constructive problem where a path is built step-by-step, or as a local problem where a full path is modified by swapping edges, and the objective function equals the summed edge cost. Some potentially useful structure may be lost in the conversion from a constructive to a local problem.\nAlthough mixtures of local and constructive search problems are possible (e.g., combining an objective function with a constructive solution and edge cost), most practical graph search problems naturally formalises as either a constructive or a local graph search problem.\nConstraint Satisfaction Problems Search problem can also often be naturally cast as constraint satisfaction problems (CSPs). Blum and Roli (2003) suggest that this offers a unified view of many search problems. A CSP formulation also seems largely in line with what Pearl (1988) has in mind, although Pearl is less specific.\nConstructive graph problems may be formulated as a CSP by encoding the neighbourhood relation with constraints, without significant loss of structure. (If the state space is infinite, an infinite number of CSP variables may be necessary.) For other problems, like the Quadratic Assignment Problem or Eternity II1, the CSP formulation is more natural and retains more structure. More structure makes the space of policies richer, and permits more clever strategies. It can also make analytic results harder, however."}, {"heading": "2.1 Algorithm performance", "text": "A search algorithm is an algorithm that returns a solution (a state or a path) to a graph search problem, given oracle access to the functions N and C, and possibly either EC and h, or Q (depending on the type of the search problem).\nPerformance on a single problem may be defined in terms of:\n1. Solution quality.\n2. The number of explored states; a state s is considered explored if either N(s) or C(s) has been called.\n3. The running time of the algorithm.\n4. The memory consumption of the algorithm (typically measured by the maximum number of states kept in memory).\nTo measure performance on a finite class of graph problems, average or worstcase performance may be used. For infinite classes, items 1 and 2 are typically subject to worst-case analysis (is the procedure complete/optimal), and 3 and 4 to asymptotic worst-case or average-case analysis.\nWe will focus on constructive search, and measure performance by the average number of explored states until in a goal is found in. In many cases the number of explored states is proportional to the actual runtime of the algorithm (state expansion is often the dominant operation during search).\nSearch algorithms that always finds a goal (when there is one) are called complete, and algorithms that always finds an optimal solution (when there is one) are called optimal.\n1The Quadratic Assignment Problem is a classic combinatorial problem, and Eternity II is a famous puzzle competition by TOMY UK Ltd."}, {"heading": "3 Basic Search Algorithms", "text": "A plethora of search methods have been studied for both the constructive and the local search problems. We here review only a subset of the more important ones, and refer to the books (Russell and Norvig, 2010; Edelkamp and Schro\u0308dl, 2012) for more details. First some preliminaries on trees, a fundamental structure in search analysis."}, {"heading": "3.1 Trees", "text": "A rooted tree is a (directed) graph with a root s0 where every pair of nodes is connected by exactly one path. The level of a node v is the distance from the root s0 to v. The depth d is the length of a longest path starting from s0. If every node on level less than D \u2208 N has exactly b children, and nodes on level D are leafs (have no children), then the tree is complete with branching factor b and depth D. Such a tree will have bD leaves and (bD+1 \u2212 1)/(b\u2212 1) nodes. In particular, complete binary trees (with branching factor 2) have 2D leaves and 2D+1 \u2212 1 nodes.\nA node v is a descendant of a node u if there is a path from u to v (i.e., if v is a child of a child of . . . of u)."}, {"heading": "3.2 Uninformed search methods", "text": "Uninformed search refers to the case where neither a heuristic function nor an objective function is used for guidance of the search. The two standard methods for exploring a graph in this case are Breadth-first Search (BFS) and Depth-first Search (DFS). BFS searches a successively growing neighbourhood around the the start node, while DFS follows a single path as long as possible, and backtracks when stuck. Algorithm 1 and 2 give pseudo-code for BFS and DFS respectively, and Figure 1 shows the traversal order of BFS and DFS in a complete binary tree.\nAlgorithm 1 Pseudo-code for BFS\nQ \u2190 emtpyQueue Discovered \u2190 emptySet Q.add(start-node) Discovered.add(start-node) while Q not empty do\nu\u2190Q.pop() if C(u) then return u\nfor v in N(u) do if not v \u2208 Discovered then\nQ.add(v) Discovered.add(v)\nDFS is substantially more memory-efficient than BFS: O(d) compared to O(bd). However, BFS can be emulated by an iterative deepening DFS, with the same memory cost as DFS and only a small penalty in runtime in most graphs (in graphs with exponentially growing neighbourhoods, to be precise).\nAlgorithm 2 Pseudo-code for (Recursive) DFS\nfunction DFS-REC(N,C, u, Discovered) Discovered.add(u) if C(u) then return u\nBFS and DFS come in two flavors, depending on whether they keep track of visited nodes or not. The tree search variants do not keep track of visited nodes, while the graph search variants do. In trees (where each node can only be reached from one path), nothing is gained by keeping track of visited nodes. In contrast, keeping track of visited nodes can benefit search performance greatly in multiply connected graphs. Keeping track of visited nodes may also be expensive in terms of memory consumption, however.\nOne way to understand tree search behaviour in general graphs is to say that tree search algorithms effectively explore a tree; branches in this tree correspond to paths in the original graph, and copies of the same node v will appear in several places of the tree whenever v can be reached through several paths. DFS tree search may search forever if there are cycles in the graph. We always assume that path lengths are bounded by a constant D.\nDepending on the positions of the goals in the graph, DFS and BFS may have substantially different performance. In Sections 5\u20137 below, We investigate some simple models of how the goal position and the graph structure affect BFS and DFS performance."}, {"heading": "3.3 Informed Constructive Methods", "text": "Informed constructive search methods make use of a heuristic function. This often speeds up the search significantly. The most popular method for informed constructive search is A*. It may be seen as a generalisation of BFS. A* combines the heuristic information h(v) of a node v with the accumulated edge cost g(v) of the shortest found path from the start node to v. A* always expands the discovered node with the smallest g(v) +h(v). But when the heuristic function is\nsmaller for nodes closer to the goal, A* will prioritise more promising nodes and find the goal much faster than BFS. If in particular the heuristic is consistent (never overestimates distance and respects the triangle inequality), then A* is guaranteed to find an optimal solution. The tree search version of A* only requires the heuristic to be admissible (never overestimate search distance) for guaranteed optimality.\nOne of the main draw-backs of A* is its memory consumption. Iterative deepening A* (IDA*) uses a cutoff value c that is incremented between iterations. In each iteration, nodes v not satisfying g(v) + h(v) < c are ignored, while the rest are expanded in DFS manner. The memory consumption thus becomes on par with DFS. However, unlike iterative deepening BFS, the runtime slowdown of IDA* compared to A* may be exponentially worse, since it may only be possible to increase the cutoff c marginally between iterations if optimality of the solution must be guaranteed. A range of other memory-efficient versions of A* can be found in the literature.\nIf the edge cost is always 1 and the heuristic entirely uninformative h \u2261 0, then A* reduces to BFS and IDA* to iterative-deepening DFS.\nIn many cases the priority is to find a goal as fast as possible, and the goal does not need to be an optimal one. In these cases, a greedy best-first search strategy may be used, that expands nodes according to h(v) instead of g(v)+h(v). Greedy best-first may be seen as the most natural generalisation of DFS to the informed constructive scenario. Beam-search is a variant of greedy best-first that searches slightly more widely."}, {"heading": "3.4 Informed Local Search", "text": "Most informed local search algorithms strive to combine an exploiting, hillclimbing component with an exploration component. The simplest one is hillclimbing, which always goes to the neighbour with the highest objective value, and randomly restarts when stuck. More advanced methods include simulated annealing, which adds a random moves to hill-climbing. The randomness component decays over time. Genetic algorithms use a population of search nodes, and tries to find new search points by combining features of discovered ones."}, {"heading": "4 Literature review", "text": "We divide our review of related work into two subsections. The works in the first subsection assumes that a portfolio of predefined algorithms is given, and only tries to predict which algorithm in the portfolio is better for which problem. The second subsection reviews approaches that try to build new search policies, possibly using a set of basic algorithms as building blocks."}, {"heading": "4.1 Feature-based Meta-heuristics", "text": "The algorithm selection problem asks what algorithm best to use on a given problem (Rice, 1975; Kotthoff, 2014). Tightly related is the question of inferring the search time of different search algorithms on the problem, as this information can be used to select the fastest algorithm. Both analytical investigations and machine learning techniques applied to empirical data have been tried. The latter\nis sometimes known as empirical performance models. The most comprehensive surveys are given by Hutter et al. (2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011).\nFor DFS, Knuth (1975) made a simple but important observation how the branching factor seen during search can be used to estimate the size of the search tree and the runtime. Despite the simplicity of the scheme, the estimates work surprisingly well in practice. Several generalisations have been developed (Purdom, 1978; Chen, 1992). Kilby et al. (2006) generalise Knuth\u2019s method, and also use it to select search policy for the SAT problem based on which search policy has the lowest estimated runtime. Kullmann (2008) and Lelis et al. (2013) both develop estimation schemes for branch-and-bound algorithms. Haim and Walsh (2008) approach the SAT problem, and instead of branching factor use properties of the given formula (such as the number and the size of clauses) to be predict search time and best search policy.\nIn the case of informed search, Korf et al. (2001) developed an interesting analytic technique for estimating the search time of IDA*. Assuming a consistent heuristic function, the estimate is based on the distribution of heuristic function values at different depths of the search tree, rather than heuristic accuracy. Intuitively, the scheme works because the number of nodes expanded in each iteration of IDA* depends on the number of nodes with heuristic value less than the threshold. The distribution of heuristic values is also easy to estimate in practice. Zahavi et al. (2010) generalise the work of Korf et al. to non-consistent heuristics.\nMany other approaches instead try to directly infer the best search policy, without the intermediate step of estimating runtime. Fink (1998) does this for STRIPS-like learning using only the problem size to infer which method is likely to be more efficient. Schemes using much wider ranges of problem properties are applied to CSPs in (Thompson, 2011; Arbelaez Rodriguez, 2011), and to the NP-complete problems SAT, TSP and Mixed integer programming in (Hutter et al., 2014). Smith-Miles and Lopes (2012) review and discuss commonly used features for the algorithm selection problem, mainly applied to the local search scenario. They divide features into two main categories: General and problem-specific. General features usually phrased in terms of the fitness landscape (i.e., the target function and the neighbourhood structure). A common fitness landscape feature is for example the variability (ruggedness) of the target function. Another general feature is the performance of a simple, fast algorithm such as gradient descent. Problem-specific features are discussed for a range of NP-complete problems such as TSP and Bin-packing."}, {"heading": "4.2 Learning the search policy", "text": "Explanation-based Learning (EBL) (Dejong and Mooney, 1986; Mitchell et al., 1986; Minton, 1988) is a general method for learning from examples and domain knowledge. In the context of search, the domain knowledge is the neighbourhood function (or the consequence of applying an \u2018action\u2019 to a state). An example to learn from can be the search trace of an optimiser. The EBL learner analyses the different decisions represented in the search trace, judges whether they were good or bad, and tries to find the reason they were good or bad. Once a reason has been found, the gained understanding can be used to pick similar good decisions at an earlier point during the next search, and to avoid similar bad\ndecisions (decisions leading to paths where no goal will be found). EBL systems have been applied to STRIPS-like planning scenarios (Minton, 1988, 1990).\nOne characteristic feature of EBL is that it requires only one or a few training examples (in addition to the domain knowledge). While attractive, it can also lead to overspecific learning (Minton, 1988). Partial Evaluation (PE) is an alternative learning method that is more robust in this respect, with less dependency on examples (Etzioni, 1993). Leckie and Zukerman (1998) develops a more inductive way to learn search control knowledge (in contrast to the deductive generalisations performed by EBL and PE), where plenty of training examples substitute for domain knowledge.\nA more modern approach is known as hyper heuristics (Burke et al., 2003, 2013). It views the problem of inferring good search policies more abstractly. Rather than interacting with the neighbourhood structure/graph problem directly, the hyper heuristic only has access to a set of search policies for the original graph problem. The search policies are known as low-level heuristics in this literature (not to be confused with heuristic functions). The goal of the hyper heuristic is to find a good policy for when to apply which low-level heuristic. For example, Ross et al. (2002) used Genetic Algorithms to learn which binpacking heuristic to apply in which type of state in a bin-packing problem. The learned hyper heuristic outperformed all the provided low-level heuristics used by themselves. In applications of hyper heuristics, the low-level heuristics are typically simple search policies provided by the human programmers, although nothing prevents them from being arbitrarily advanced meta-heuristics. Some research is also being done on automatic construction of low-level heuristics (see (Burke et al., 2013) for references). A related approach directed at programming in general is programming by optimisation (Hoos, 2012), where machine learning techniques are used to find the best algorithm in a space of programs delineated by the human programmer."}, {"heading": "5 Complete Binary Tree", "text": "In a search graph, the neighbourhood relation N induces a topology on the state space S. The following two sections analytically explore how the structure and depth of the graph and the distribution of the goals can be used to predict the search performance of BFS and DFS. Figure 1 gives the intuition for the different search strategies BFS and DFS, and how they initially focus the search on different areas of the tree.\nAs a concrete example, consider the search problem of solving a Rubik\u2019s cube. There is an upper bound D = 20 to how many moves it can take to reach the goal (Rokicki and Kociemba, 2013). We may however suspect that most goals are located around level 17 (\u00b12 levels). If we consider search algorithms that do not remember where they have been, the search space becomes a complete tree with fixed branching factor 9. What would be the expected BFS and DFS search time for this problem? Which one would be faster?\nAfter some initial background in the first subsection, this section first investigates a model where goals are located on a single goal level g in Section 5.2, and then generalises it to multiple goal levels in Section 5.3. Section 6 develops techniques for analyzing the performance of the graph search variants of BFS and DFS, which recognize the path redundancies often present in problems. All\nanalytical runtime estimates are verified experimentally in Section 8."}, {"heading": "5.1 Preliminaries", "text": "For simplicity, we say that the runtime or search time of a search method (BFS or DFS) is the number of nodes explored until a first goal is found (5 and 6 respectively in Figure 1). This simplifying assumption relies on node expansion being the dominant operation, consuming similar time throughout the tree. If no goal exists, the search method will explore all nodes before halting. In this case, we define the runtime as the number of nodes in the search problem plus 1 (i.e., 2D+1 in the case of a binary tree of depth D).2\nLet \u0393 be the event that a goal exists, \u0393k the event that a goal exists on level k, and \u0393\u0304 and \u0393\u0304k their complements. Let Fk = \u0393k \u2229 ( \u22c2k\u22121 i=0 \u0393\u0304i) be the event that level k has the first goal. A random variable X is geometrically distributed Geo(p) if P (X = k) = (1\u2212 p)k\u22121p for k \u2208 {1, 2, . . . }. The interpretation of X is the number of trials until the first success when each trial succeeds with probability p. Its cumulative distribution function (CDF) is P (X \u2264 k) = 1 \u2212 (1 \u2212 p)k, and its average or expected value E[X] = 1/p. A random variable Y is truncated geometrically distributed X \u223c TruncGeo(p,m) if Y = (X | X \u2264 m) for X \u223c Geo(p), which gives\nP (Y = k) =\n{ (1\u2212p)kp\n1\u2212(1\u2212p)m for k \u2208 {1, . . . ,m} 0 otherwise.\nE[Y ] = E[X | X \u2264 m] = 1\u2212 (1\u2212 p) m(pm+ 1)\np(1\u2212 (1\u2212 p)m) .\nLet tc(p,m) denote the expected value of a truncated geometrically distributed variable with parameters p and m (i.e., tc(p,m) = E[Y ]). When p 1m , Y is approximately Geo(p), and tc(p,m) \u2248 1p . When p 1 m , Y becomes approximately uniform on {1, . . . ,m} and tc(p,m) \u2248 m2 . A random variable Z is exponentially distributed Exp(\u03bb) if P (Z \u2264 z) = 1\u2212 e\u2212\u03bbz for z \u2265 0. The expected value of Z is 1\u03bb , and the probability density function of Z is \u03bbe\u2212\u03bbz. An exponential distribution with parameter \u03bb = \u2212 ln(1\u2212p) might be viewed as the continuous counterpart of a Geo(p) distribution. We will use this approximation in Section 5.3.\nLemma 3 (Exponential approximation). Let Z \u223c Exp(\u2212 ln(1\u2212 p)) and X \u223c Geo(p). Then the CDFs for X and Z agree for integers k, P (Z \u2264 k) = P (X \u2264 k). The expectations of Z and X are also similar in the sense that 0 \u2264 E[X]\u2212E[Z] \u2264 1.\nProof. For z > 0, P (Z \u2264 z) = 1 \u2212 exp(z ln(1 \u2212 p)) = 1 \u2212 (1 \u2212 p)z, and P (X \u2264 z) = 1\u2212(1\u2212p)bzc. Thus, for integers k > 0, P (Z \u2264 k) = P (X \u2264 k) which proves the first statement. Further, 1\u2212(1\u2212p)bzc \u2264 1\u2212(1\u2212p)z < 1\u2212(1\u2212p)bz+1c, so P (X \u2264 z) \u2264 P (Z \u2264 z) < P (X \u2212 1 \u2264 z). Hence E[X] \u2265 E[Z] > E[X \u2212 1] = E[X]\u2212 1, which proves the second statement.\n2It may have seem more justified to set the non-goal case to the exact number of nodes instead of adding 1. However, adding 1 makes most expressions slightly more elegant, and does not affect the results in any substantial way.\nWe will occasionally make use of the convention 0 \u00b7 undefined = 0, and often expand expectations by conditioning on disjoint events:\nLemma 4. Let X be a random variable and let the sample space \u2126 = \u22c3\u0307 i\u2208ICi be\npartitioned by mutually disjoint events Ci. Then E[X] = \u2211 i\u2208I P (Ci)E[X | Ci]."}, {"heading": "5.2 Complete Binary Tree with a Single Goal Level", "text": "Consider a binary tree of depth D, where solutions are distributed on a single goal level g \u2208 {0, . . . , D}. At the goal level, any node is a goal with iid probability pg \u2208 [0, 1]. We will refer to this kind of problems as (single goal level) complete binary trees with depth D, goal level g and goal probability pg (Section 5.3 generalises the setup to multiple goal levels).\nThe probability that a goal exists is P (\u0393) = P (\u0393g) = 1 \u2212 (1 \u2212 pg)2 g\n. If a goal exists, let Y be the position of the first goal at level g. Conditioned on a goal existing, Y is a truncated geometric variable Y \u223c TruncGeo(pg, 2g). When pg 2\u2212g the goal position Y is approximately Geo(pg), which makes most expressions slightly more elegant. This is often a realistic assumption, since if p 6 2\u2212g, then often no goal would exist.\nProposition 5 (BFS runtime Single Goal Level). Let the problem be a complete binary tree with depth D, goal level g and goal probability pg. When a goal exists and has position Y on the goal level, the BFS search time is\ntBFSSGL(g, pg, Y ) = 2 g \u2212 1 + Y , with expectation\ntBFSSGL(g, pg | \u0393g) = 2g \u2212 1 + tc(pg, 2g) \u2248 2g \u2212 1 + 1\npg .\nIn general, when a goal does not necessarily exist, the expected BFS search time is\ntBFSSGL(g, pg) = P (\u0393) \u00b7 (2g \u2212 1 + tc(pg, 2g)) + P (\u0393\u0304) \u00b7 2D+1 \u2248 2g \u2212 1 + 1\npg .\nThe approximations are close when pg 2\u2212g.\nProof. When a goal exists, BFS will explore all of the top of the tree until depth g \u2212 1 (that is, 2(g\u22121)+1 = 2g nodes) and Y nodes on level g, before finding the first goal. That is, tBFSSGL(D, g, pg, Y ) = 2\ng \u2212 1 + Y , with expected value 2g \u2212 1 + tc(pg, 2g).\nIn the general case, the expected value of the search time X expands as\nE[X] = P (\u0393) \u00b7 E[X | \u0393] + P (\u0393\u0304) \u00b7 E[X | \u0393\u0304] = P (\u0393) \u00b7 tBFSSGL(D, p, pg | \u0393g) + P (\u0393\u0304) \u00b7 2D+1\n= P (\u0393) \u00b7 (2g \u2212 1 + tc(pg, 2g)) + P (\u0393\u0304) \u00b7 2D+1.\nWhen pg 2\u2212g, then \u0393 \u2248 1, \u0393\u0304 \u2248 0 and Y \u2248 Geo(p) which justifies the approximation.\nA memory-efficient tree-search variant of BFS can be implemented as iterative deepening DFS (ID-DFS). The runtime of ID-DFS is about twice the runtime of BFS; our results are only marginally affected by this. Korf et al. (2001) study\nIDA*, which may be seen as a generalised ID-DFS. Their Theorem 1 give a similar result to our Proposition 5 by setting: the heuristic h = 0, the number of i-level nodes Ni = 2\ni, the equilibrium distribution P (x) = 1, the edge cost = 1, and the cost bound c equal to our max depth D. Their bound then comes out as tBFSSGL(g) = 2\ng+1 \u2212 1, and as tBFSSGL(g) \u2248 2g+2 after iteration over all levels \u2264 g. This corresponds to the worst case in our scenario.\nProposition 6. Consider a complete binary tree with depth D, goal level g and goal probability pg. When a goal exists and has position Y on the goal level, the DFS search time is approximately\nt\u0303DFSSGL(D, g, pg, Y ) := (Y \u2212 1)2D\u2212g+1 + 2, with expectation t\u0303DFSSGL(D, g, pg | \u0393g) := ( 1 pg \u2212 1 ) 2D\u2212g+1 + 2.\nWhen pg 2\u2212g, the expected DFS search time when a goal does not necessarily exist is approximately\nt\u0303DFSSGL(D, g, pg) := P (\u0393)((tc(pg, 2 g)\u22121)2D\u2212g+1+2)+P (\u0393\u0304)2D+1\u2248\n( 1 pg \u22121 ) 2D\u2212g+1.\nProof. One way to count the nodes explored by DFS when a goal exists is the following. To the left of the first goal on level g, DFS will explore 2(Y \u22121) subtrees rooted at level g + 1. These subtrees will have depth D \u2212 (g + 1), and contain 2D\u2212g \u2212 1 nodes each. DFS will also explore Y nodes on level g and their parents, which amounts to about 2Y nodes. Summing the contributions up gives the DFS search time approximation t\u0303DFSSGL(D, g, pg, Y ) = 2(Y \u22121) \u00b7 (2D\u2212g\u22121) + 2Y = (Y \u2212 1)2D\u2212g+1 + 2.\nBy Lemma 4, the expected value of the search time X expands as\nE[X] = P (\u0393) \u00b7 E[X | \u0393] + P (\u0393\u0304) \u00b7 E[X | \u0393\u0304] = P (\u0393) \u00b7 E[t\u0303DFSSGL(D, g, pg, Y ) | \u0393] + P (\u0393\u0304) \u00b7 2D+1\n= P (\u0393) \u00b7 ((tc(pg, 2g)\u2212 1)2D\u2212g+1 + 2) + P (\u0393\u0304) \u00b7 2D+1\nwhere the last step uses that (Y | \u0393) \u223c TruncGeo(pg, 2g). When pg 2\u2212g, then \u0393 \u2248 1, \u0393\u0304 \u2248 0 and Y \u2248 Geo(pg) which justifies the approximation.\nFigure 2 shows the runtime estimates as a function of goal level.\nComparison BFS vs. DFS. Figure 6 on page 23 shows how the expected search time varies with goal depth (and also compares the results with the Binary Grammar Problem described in Section 7.1). The runtime estimates can be used to predict whether BFS or DFS will be faster, given the parameters D, g, and pg, as stated in the next Proposition.\nProposition 7. Let \u03b3pg = log2 (tc(pg, 2 g)\u2212 1) /2 \u2248 log2 ( 1\u2212pg pg ) /2. Given the approximation of DFS runtime of Proposition 6, BFS wins in expectation in a complete binary tree with depth D, goal level g and goal probability pg when\ng < D\n2 + \u03b3pg\nand DFS wins in expectation when g > D2 + \u03b3pg + 1 2 .\nThe term \u03b3pg is in the range [\u22121, 1] when pg \u2208 [0.2, 0.75], g \u2265 2, in which case Proposition 7 roughly says that BFS wins (in expectation) when the goal level g is located higher than the middle of the tree. For smaller pg, BFS benefits with the boundary level being shifted \u03b3pg \u2248 k/2 levels from the middle when pg \u2248 2\u2212k 2\u2212g. Figure 2 illustrates the prediction as a function of goal depth and tree depth for a fixed probability pg = 0.07.\nProof of Proposition 7. When no goal exists, BFS and DFS will perform the same. When the tree contains at least one goal node, BFS will found the goal somewhere on its sweep across level g, so the BFS runtime is bounded between 2g \u2264 tBFSSGL(g, pg) \u2264 2g+1.\nThe upper bound for tBFSSGL(g, pg) gives that t BFS SGL(g, pg) < tDFS(D, g, pg) when 2g+1 < (tc(pg, 2 g)\u2212 1) 2D\u2212g+1. Taking the binary logarithm of both sides yields\ng + 1 < log2 (tc(pg, 2 g)\u2212 1) +D \u2212 g + 1.\nCollecting the g\u2019s on one side and dividing by 2 gives the desired bound\ng < log2(tc(pg, 2 g)\u2212 1) 2 + D 2 = D 2 + \u03b3pg .\nSimilar calculations with the lower bound for tBFSSGL(g, pg) gives the condition for t\u0303DFSSGL(D, g, pg) < t BFS SGL(g, pg) when g > D 2 + \u03b3pg + 1 2 .\nIt is straightforward to generalise the calculations to arbitrary branching factor b, by just substituting the 2 in the base of tBFSSGL and t\u0303 DFS SGL for b. In Proposition 7, the change only affects the base of the logarithm in \u03b3pg .\nCorollary 8. Given the above approximations to BFS and DFS runtime, BFS wins in expectation in a complete tree with integer branching factor b \u2265 2, depth D, goal level g, and goal probability pg when g < D 2 + \u03b3b,pg , and DFS wins in expectation when g > D2 + \u03b3b,pg + 1 2 , where \u03b3b,pg = logb (tc(pg, b\ng)\u2212 1) /2 \u2248 logb( 1\u2212pg pg )/2."}, {"heading": "5.3 Complete Binary Tree with Multiple Goal Levels", "text": "We now generalise the model developed in the previous section to problems that can have goals on any number of levels. For each level k \u2208 {0, . . . , D}, let pk be the associated goal probability. Not every pk should be equal to 0. Nodes on level k have iid probability pk of being a goal. We will refer to this kind of problems as (multi goal level) complete binary trees with depth D and goal probabilities p."}, {"heading": "5.3.1 DFS Analysis", "text": "Our approximation of DFS performance in the case of multiple goal levels approximates the geometric distribution used in Proposition 6 with an exponential distribution (its continuous approximation by Lemma 3).\nProposition 9 (Expected Multi Goal Level DFS Performance). Consider a complete binary tree of depth D with goal probabilities p = [p0, . . . , pD] \u2208 [0, 1)D+1. If for at least one j, pj 2\u2212j, and for all k, pk 1, then the expected number of nodes DFS will search is approximately\nt\u0303DFSMGL(D,p) := 1/ D\u2211 k=0 ln(1\u2212 pk)\u221212\u2212(D\u2212k+1).\nThe proof constructs for each level k an exponential random variable Xk that approximates the search time before a goal is found on level k (disregarding goals on other levels). The minimum of all Xk then becomes an approximation of the search time to find a goal on any level. The approximations use exponential variables for easy minimisation.\nProof. The proof uses two approximations. First approximate the position of the first goal on level k with Yk \u223c Exp(\u03bbk), where \u03bbk = \u2212 ln(1 \u2212 pk). This is reasonable for the following reason. For pk 2\u2212k, Yk is approximately Geo(pk), so the approximation is justifiable by Lemma 3. For smaller pk, the probability that this level has a goal is small, so the imprecision of the approximation does not affect the result significantly (as long as not all pj are this small).\nSecond, disregarding goals on levels other than k, the total number of nodes that DFS needs to search before reaching a goal on level k is approximately Xk \u223c Exp(\u03bbk2\u2212(D\u2212k+1)). This follows from an approximation of Proposition 6: The number of nodes DFS needs to search to find a goal on level k is\nt\u0303DFSSGL(D, k, pk, Yk) = (Yk \u2212 1)2D\u2212k+1 + 2 \u2248 Yk \u00b7 2D\u2212k+1.\n(This is a reasonable estimate if Yk is large, which is likely given that pk 1 by assumption.) So Xk is approximately a multiple 2\nD\u2212k+1 of Yk. For any exponential random variable Z with parameter \u03bb, the scaled variable m \u00b7 Z is Exp(\u03bb/m). This completes the justification of the second approximation.\nThe result now follows by a standard minimisation of exponential variables. Since Xk approximates the number of nodes searched before finding a goal on level k, the number of nodes searched before finding a goal on any level is X = minkXk. The CDF for X is\nP (X \u2264 y) = 1\u2212 D\u220f k=0 P (Xk > y)\n= 1\u2212 D\u220f k=0 exp(\u2212\u03bbk2\u2212(D\u2212k+1)y)\n= 1\u2212 exp(\u2212y D\u2211 k=0 \u03bbk2 \u2212(D\u2212k+1)).\n(The minimum of exponential variables Zk \u223c Exp(\u03bek) is again an exponential variable Exp( \u2211 \u03bek).)\nSoX \u223c Exp( \u2211D k=0 \u03bbk2 \u2212(D\u2212k+1))) with the claimed expected value 1/ \u2211D k=0 \u03bbk2 \u2212(D\u2212k+1)).\nIn the special case of a single goal level, the approximation of Proposition 9 is similar to the one given by Proposition 6. When p only has a single element pj 6= 0, the expression t\u0303DFSMGL simplifies to\nt\u0303DFSMGL(D,p) = 1 \u03bbj 2D\u2212j+1 = \u2212 1 ln(1\u2212 pj) 2D\u2212j+1.\nFor pj not close to 1, the factor \u22121/ ln(1 \u2212 pj) is approximately the same as the corresponding factor 1/pj \u2212 1 in Proposition 6 (the Laurent expansion is \u22121/ ln(1\u2212 pj) = 1/pj \u2212 1/2 +O(pj))."}, {"heading": "5.3.2 BFS Analysis", "text": "The corresponding expected search time tBFSMGL(D,p) for BFS requires less insight and can be calculated exactly by conditioning on which level the first goal is. The resulting formula is less elegant, however. The same technique cannot be used for DFS, since DFS does not exhaust levels one by one.\nThe probability that level k has the first goal is P (Fk) = P (\u0393k) \u220fk\u22121 j=0 P (\u0393\u0304j),\nwhere P (\u0393i) = (1 \u2212 (1 \u2212 pi)2 i\n). The expected BFS search time gets a more uniform expression by the introduction of an extra hypothetical level D+ 1 where all nodes are goals. That is, level D + 1 has goal probability pD+1 = 1 and\nP (FD+1) = P (\u0393\u0304) = 1\u2212 \u2211D k=0 P (Fk).\nProposition 10 (Expected Multi Goal Level BFS Performance). The expected number of nodes tBFSMGL(p) that BFS needs to search to find a goal in a complete binary tree of depth D with goal probabilities p = [p0, . . . , pD], p 6= 0, is\ntBFSMGL(p) = D+1\u2211 k=0 P (Fk)t BFS SGL(k, pk | \u0393k) \u2248 D+1\u2211 k=0 P (Fk) ( 2k + 1 pk ) For pk = 0, the expression t BFS CB (k, pk) and 1/pk will be undefined, but this\nonly occurs when P (Fk) is also 0.\nProof. To BFS, the event Fk that level k has a goal is equivalent to the single goal level model of Section 5.2. Let X be BFS search time, and let (X | Fk) be the number of nodes that BFS needs to search when k is the first level with a goal. Then (X | Fk) = tBFSSGL(k, pk, X \u2212 (2k\u2212 1) | \u0393k), and E[X | Fk] = tBFSSGL(k, pk | \u0393k). The result follows by expanding E[X] over F0, . . . , FD+1 as in Lemma 4.\nThe approximation tends to be within a factor 2 of the correct expression, even when pk < 2\n\u2212k for some or all pk \u2208 p. The reason is that the corresponding P (Fk)\u2019s are small when the geometric approximation is inaccurate.\nBoth Proposition 9 and 10 naturally generalise to arbitrary branching factor b. Although their combination does not yield a similarly elegant expression as Proposition 7, they can still be naively combined to predict the BFS vs. DFS winner (Figure 8)."}, {"heading": "6 Colliding Branches", "text": "The last section predicted runtime of tree search algorithms that do not remember which nodes they visit, which means that the search graph always has shape of a tree (with the same node possibly occurring in several places). In this section, we explore the performance of graph search algorithms that avoid revisiting previously explored nodes by keeping track of which nodes have already been seen. Figure 3 gives an idea of the difference between BFS and DFS in multiply connected graphs (with bounded search depth).\nDefinition 11. For a given search problem: Let the level of a node v, level(v), be the length of a shortest path from the start node to v. Let D = maxv level(v) be the (generalised) depth of the search graph. Let \u03b4n be the first node on level n reached by DFS, 0 \u2264 n \u2264 D.\nThe descendant counter L plays a central role in the analysis. For a given search problem, let\nL(n, d) = |{v : level(v) = d, v \u2208 descendants(\u03b4n)}|\ncount the number of nodes on level d that are reachable from \u03b4n.\nAs in the previous section, we assume that goals are distributed by level in an iid manner according to a goal probability vector p. We will also assume that the probability of DFS finding a goal before finding \u03b4D is negligible. We will refer to\nthis kind of problems as search problems with depth D, goal probabilities p and descendant counter L. The rest of this section justifies the following proposition.\nProposition 12. The DFS and BFS runtime of a search problem can be roughly estimated from the descendant counter L, the depth D and the goal probabilities p = [p0, . . . , pD] when the probability of finding a goal before \u03b4D is negligible.\nThe assumption of DFS not finding a goal before \u03b4D is not always realistic, but is for example satisfied in the grammar problems considered in Section 7 below."}, {"heading": "6.1 DFS Analysis", "text": "The nodes \u03b40, . . . , \u03b4D play a central role in the analysis of DFS runtime, since all the descendants of \u03b4n+1 will be explored before the descendants of \u03b4n (excluding the \u03b4n+1 descendants). We say that DFS explores from \u03b4n after DFS has explored all descendants of \u03b4n+1 and until all descendants of \u03b4n have been explored. The general idea of the DFS analysis will be to count the number of nodes under each \u03b4n, and to compute the probability that any of these nodes is a goal.\nSome notation for this:\n\u2022 Let the \u03b4n-subgraph Sn = {v : v \u2208 descendants(\u03b4n)} be the set of nodes reachable from \u03b4n, with cardinality |Sn| = \u2211D i=0 L(n, i), 0 \u2264 n \u2264 D.\nLet SD+1 = \u2205 and let S\u22121 be a set of cardinality |S\u22121| = |S0| + 1 =\u2211D i=0 L(0, i) + 1.\n\u2022 Let the \u03b4n-explorables Tn = Sn \\ Sn+1 be the nodes explored from \u03b4n.\n\u2022 Let the number of level-d \u03b4n-explorables An,d = L(n, d)\u2212 L(n+ 1, d) be the number of level d descendants of \u03b4n that are not descendants of \u03b4n+1 for 0 \u2264 n, d \u2264 D. The relation between Tn and An,d is the following: |Tn| = \u2211D i=nAn,i.\nLet qk = 1\u2212 pk for 0 \u2264 k \u2264 D.\nLemma 13. Consider a search problem with depth D, goal probabilities p, and descendant counter L. The probability that the \u03b4n-explorables Tn contains a goal\nis \u03c4n := 1 \u2212 \u220fD k=0 q An,k k , and the probability that Tn contains the first goal is\n\u03c6n := \u03c4n \u220fD i=n+1(1\u2212 \u03c4i).\nProof. \u03c4n is 1 minus the probability of not hitting a goal at any level d, n \u2264 d \u2264 D, since at each level d, An,d probes are made when exploring from \u03b4n.\nProposition 14 (Colliding branches expected DFS search time). The expected DFS search time tDFSCB (D,p, L) in a search problem with depth D, goal probabilities p, and descendant counter L is bounded by\ntDFSCBL(D,p, L) := D\u2211 n=\u22121 |Sn+1|\u03c6n \u2264 tDFSCB (D,p, L) \u2264 D\u2211 n=\u22121 |Sn|\u03c6n := tDFSCBU(D,p, l) where \u03c6\u22121 = \u0393\u0304 = 1\u2212 \u2211D n=0 \u03c6n is the probability that no goal exists.\nThe arithmetic mean t\u0303DFSCB (D,p, L) := (t DFS CBL(D,p, L) + t DFS CBU(D,p, L))/2\nbetween the bounds can be used for a single runtime estimate.\nProof. Let X be the DFS search time in a search problem with the features described above. The expectation of X may be decomposed as\nE[X] = P (\u0393\u0304)E[X | \u0393\u0304] + D\u2211 n=0 P (first goal in Tn) \u00b7 E[X | first goal in Tn]. (1)\nThe conditional search time (X | first goal in Tn) is bounded by |Sn+1| \u2264 (X | first goal in Tn) \u2264 |Sn| for 0 \u2264 n \u2264 D, since to find a goal DFS will search the entire \u03b4n+1-subgraph Sn+1 before finding it when searching the \u03b4n-explorables Tn, but will not need to search more than the \u03b4n-subgraph Sn = Sn+1 \u222a Tn (disregarding the few probes made \u2018on the way down to\u2019 \u03b4n (i.e. to Tn); these probes were assumed negligible). The same bounds also hold with S0 and S\u22121 when no goal exists (recall that |S\u22121| := |S0| + 1). Therefore the conditional expectation satisfies\n|Sn+1| \u2264 E[X | first goal in Tn] \u2264 |Sn| (2)\nfor \u22121 \u2264 n \u2264 D. By Lemma 13, the probability that the first goal is among the \u03b4n-explorables Tn is \u03c6n, and the probability P (\u0393\u0304) that no goal exists is \u03c6\u22121 by definition.\nSubstituting \u03c6n and (2) into (1) gives the desired bounds for expected DFS search time t\u0303DFSCB (D,p, L) = E[X].\nThe informativeness of the bounds of Proposition 14 depends on the dispersion of nodes between the different Tn\u2019s. If most nodes belong to one or a few sets Tn, the bounds may be almost completely uninformative. This happens in the special case of complete trees with branching factor b, where a fraction (b\u2212 1)/b of the nodes will be in T0. The previous section derives techniques for these cases. The grammar problems investigated in Section 7 below show that the bounds may be relevant in more connected graphs, however."}, {"heading": "6.2 BFS Analysis", "text": "The analysis of BFS only requires the descendant counter L(0, \u00b7) with the first argument set to 0, and follows the same structure as Section 5.3.2. In contrast to the DFS bounds above, this analysis gives a precise expression for the expected runtime. The idea is to count the number of nodes in the upper k levels of the tree (derived from L(0, 0), . . . , L(0, k)), and to compute the probability that\nthey contain a goal. Let the upper subgraph Uk = \u2211k\u22121 i=0 L(0, i) be the number of nodes above level k When there is only a single goal level, Proposition 5 naturally generalises to the more general setting of this section.\nLemma 15 (BFS runtime Single Goal Level). For a search problem with depth D and descendant counter L, assume that the problem has a single goal level g with goal probability pg, and that pj = 0 for j 6= g. When a goal exists and has position Y on the goal level, the BFS search time is:\ntBFSCB (g, pg, L, Y ) = Ug + Y , with expected value\ntBFSCB (g, pg, L | \u0393g) = Ug + tc(pg, L(0, g))\nProof. When a goal exists, BFS will explore all of the top of the tree until depth g \u2212 1 (that is, Ug nodes) and Y nodes on level g before finding the first goal. The expected value of Y is tc(pg, L(0, g)).\nThe probability that level k has a goal is P (\u0393k) = 1 \u2212 qL(0,k)k , and the probability that level k has the first goal is P (Fk) = P (\u0393k) \u220fk\u22121 i=0 P (\u0393\u0304i). By the same argument as in Proposition 10, the following proposition holds.\nProposition 16 (Branch Colliding Expected BFS Performance). The expected number of nodes that BFS needs to search to find a goal in a search problem with depth D, goal probabilities p = [p0, . . . , pD], p 6= 0, and descendant counter L is\ntBFSCB (p, L) = D+1\u2211 k=0 P (Fk)t BFS CB (k, pk, L | \u0393k)\nwhere the goal probabilities have been extended with an extra element pD+1 = 1, and FD+1 = \u0393\u0304 is the event that no goal exists.\nFor pk = 0, t BFS CB will be undefined, but this only occurs when P (Fk) is also 0. Proposition 14 and 16 give (rough) estimates of average BFS and DFS graph search time given the goal distribution p and the structure parameter L. The results can be combined to make a decision whether to use BFS or DFS (Figure 5)."}, {"heading": "7 Grammar Problems", "text": "We now show how to apply the general theory of Section 6 to two concrete grammar problems. A grammar problem is a constructive search problem where nodes are strings over some finite alphabet B, and the neighbourhood relation is given by a set of production rules. Production rules are mappings x \u2192 y, x, y \u2208 B\u2217, defining how strings may be transformed. For example, the production rule S \u2192 Sa permits the string aSa to be transformed into aSaa. A grammar problem is defined by a set of production rules, together with a starting string and a set of goal strings. A solution is a sequence of production rule applications that transforms the starting string into a goal string. Many search problems can be formulated as grammar problems, with string representations of states modified by production rules. Their generality makes it computably undecidable whether a given grammar problem has a solution or not. We here consider a simplified version where the search depth is artificially limited, and goals are distributed according to a goal probability vector p.\nGrammar problems exhibit two features not present in the complete tree model. First, it is possible for branches of the grammar tree to \u2018die\u2019. This happens if no production rule is applicable to the string of the state. Second, often the same string can be produced by different sequences, which means that the grammar search graph in general is not a tree. The following subsections apply the theory of Section 6 of colliding branches to simple grammar problems."}, {"heading": "7.1 Binary Grammar", "text": "Let be the empty string. The binary grammar consists of two production rules, \u2192 a and \u2192 b over the alphabet B = {a, b}. The starting string is the empty\nstring . A maximum depth D of the search graph is imposed, and strings on level k are goals with iid probability pk, 0 \u2264 k \u2264 D. Since the left hand substring of both production rules is the empty string, both can always be applied at any place to a given string. The resulting graph is shown in Figure 4.\nConsider a node v at level d. Its children are reached by either adding an a or by adding a b. Let #a denote the number of a\u2019s in v, and let #b denote the number of b\u2019s in v. Then #a+ 1 distinct strings can be created by adding a b, and #b+ 1 distinct strings can be created by adding an a. In total then, v will have (#a+ 1) + (#b+ 1) = d+ 2 children. Nodes further to the right will have more of their children previously discovered. The number of parents of a node is the number of contiguous ai and bj segments. For example, bbaaab have three segments bb-aaa-b and three parents b aaa b, bb aa b and bb aaa. A parent always differs from a child by the removal of one letter from one segment, and within a segment it is irrelevant which letter is removed.\nThe first node on level n that DFS reaches in the binary grammar problem is \u03b4n = a\nn for 0 \u2264 n \u2264 D, assuming that the production rule \u2192 a is always used first by DFS. The following lemma derives an expression for the descendant counter LBG required by Proposition 14. Incidentally, the number of level-d \u03b4n explorables An,d (Section 6.1) gets an elegant form in the binary grammar problem.\nLemma 17. For n < d, let LBG(n, d) = |{v : level(v) = d, v \u2208 descendants(an)}| be the number of nodes reachable from an, and let An,d = L\nBG(n, d)\u2212LBG(n+1, d) be the number of descendants of an that are not descendants of an+1. Then LBG(n, d) = \u2211d\u2212n i=0 ( d i ) , and An,d = ( d d\u2212n ) .\nProof. The reachable nodes on level d that we wish to count are d\u2212n levels below an. To reach this level we must add i \u2264 d\u2212n number of b\u2019s and d\u2212n\u2212 i number of a\u2019s to an. The number of length d strings containing exactly i number of b\u2019s is ( d i ) (we are choosing positions for the b\u2019s non-uniquely with repetition among\nd\u2212 i+ 1 possible positions). Summing over i, we obtain LBG(n, d) = \u2211d\u2212n i=0 ( d i ) , and An,d = L BG(n, d)\u2212 LBG(n+ 1, d) = ( d d\u2212n ) .\nCorollary 18 (Expected Binary Grammar BFS Search Time). The expected BFS search time t\u0303DFSBG (p) in a Binary Grammar Problem of depth D with goal probabilities p = [p0, . . . , pD] is\ntBFSBG (p) = t BFS CB (p, L BG).\nCorollary 19 (Expected Binary Grammar DFS Search Time). The expected DFS search time t\u0303DFSBG (D,p) in a binary grammar problem of depth D with goal probabilities p = [p0, . . . , pD] is bounded between t DFS BGL(D,p) := t DFS CBL(D,p, L\nBG) and tDFSBGU(D,p) := t DFS CBU(D,p, L BG), and is approximately\nt\u0303DFSBG (D,p) := t\u0303 DFS CB (D,p, L BG).\nProof of Corollary 18 and 19. Direct application of Lemma 17, and Proposition 16 and 14 respectively.\nThe bounds are plotted for a single goal level in Figure 5 and 6."}, {"heading": "7.2 Random Grammar", "text": "The Random Grammar Problem has alphabet B = {S, a, b} and start string S, The production rules always include S \u2192 (with denoting the empty string) plus a random subset of the adding rules S \u2192 Sa, S \u2192 Sb, S \u2192 aS, S \u2192 bS, and a random subset of the moving rules Sa \u2192 aS, Sb \u2192 bS, aS \u2192 Sa, and bS \u2192 Sb. Only strings containing no S can be goal nodes. As usual, a maximum depth D and a goal probability vector p = [p0, . . . , pD] are given.\nFor simplified analysis, we will abuse notation the following way. We will consider S-less nodes to be one level higher than they actually are. For example, we will consider a to be on level 1, although it is technically on level 2 or lower (e.g. reached by the path S \u2192 Sa, S \u2192 ). A slight modification of BFS and DFS makes them always check the S-less child first (which is always child-less in turn), which means the change will only slightly affect search time. We will still consider \u03b4n = Sa n whenever S \u2192 Sa is among the production rules, however.\nComplete Binary Tree\nBinary Grammar\nThe general case of when a random set of production rules are used is explored experimentally in Section 9. The special case of a binary tree arises when none of the moving rules are used, and either only the first two or only the last two of the addition rules. The analysis of Section 5.2 applies to this case. The special case when all rules are present can be analysed analytically by the means of Section 6. We will call this case the full grammar problem."}, {"heading": "7.3 Full Grammar", "text": "The search graph of the full grammar problem is shown in Figure 7 (edges induced by moving rules are not shown). Since there are four adding rules that can be applied to each node, each node will have four children. Typically, when we move further to the right in the tree, more children will already have been discovered.\nThe full grammar problem can be analysed by a reduction to a binary grammar problem with the same parameters D and p. Assign to each string v of the binary grammar problem the set of strings that only differ from v by (at most) an extra S. We call such sets node clusters. For example, {a, Sa, aS} constitutes the node cluster corresponding to a. Due to the abusing of levels for the S-less strings, all members of a cluster appear on the same level in the full grammar problem (the level is equal to the number of a\u2019s and b\u2019s). The level is also the same as the corresponding string in the binary grammar problem.\nLemma 20 (Binary Grammar Reduction). For every n, d, n \u2264 d, the descendant counter LFG of the full grammar problem is LFG(n, d) = (d+ 2)LBG(n, d).\nProof. LBG(n, d) counts the level d descendants of an in the binary grammar problem (BGP), and LFG(n, d) counts the level d descendants of San in the full grammar problem (FGP). The node u is a child of v in BGP iff the members of the u node cluster are descendants of Su. Therefore the node clusters on level d descending from San in FGP correspond to the BGP nodes descending from an. At level d, each node cluster contains d+ 2 nodes.\nCorollary 21 (Expected Full Grammar BFS Search Time). The expected BFS search time t\u0303DFSFG (p) in a full grammar problem of depth D with goal probabilities p = [p0, . . . , pD] is\ntBFSFG (p) := t BFS CB (p, L FG).\nCorollary 22 (Expected Full Grammar DFS Search Time). The expected DFS search time t\u0303DFSFG (D, p) in a full grammar problem of depth D with goal probabilities p = [p0, . . . , pD] is bounded between t DFS FGL(D,p) := t DFS CBL(D,p, L\nFG) and tDFSFGU(D,p) := t DFS CBU(D,p, L FG), and is approximately\nt\u0303DFSFG (D,p) := t\u0303 DFS CB (D,p, L FG).\nProof of Corollary 21 and 22. Direct application of Lemma 20, and Proposition 16 and 14 respectively."}, {"heading": "8 Experimental verification", "text": "To verify the analytical results, we have implemented the models Sections 5\u20137 in Python 3 using the graph-tool package (Peixoto, 2015). The data reported in Tables 1\u20133 is based on an average of 1000 independently generated search problems with depth D = 14.\n\u2022 The first number in each box is the empirical average,\n\u2022 the second number is the analytical estimate, and\n\u2022 the third number is the percentage error of the analytical estimate.\nFor certain parameter settings, there is only a small chance (< 10\u22123) that there are no goals. In such circumstances, all 1000 generated search graphs typically inhabit a goal, and so the empirical search times will be comparatively small. However, since a tree of depth 14 has about 215 \u2248 3 \u00b7 105 nodes (and\na search algorithm must search through all of them in case there is no goal), the rarely occurring event of no goal can still influence the expected search time substantially. To avoid this sampling problem, we have ubiquitously discarded all instances where no goal is present, and compared the resulting averages to the analytical expectations conditioned on at least one goal being present.\nTo develop a concrete instance of the multi goal level model we consider the special case of Gaussian goal probability vectors, with two parameters \u00b5 and \u03c32. For a given depth D, the goal probabilities are given by\npi = min\n{ 1\n20 \u221a \u03c32 e(i\u2212\u00b5) 2/\u03c32 , 1 2\n} .\nThe parameter \u00b5 \u2208 [0, D] \u2229N is the goal peak, and the parameter \u03c32 \u2208 R+ is the goal spread. The factor 1/20 is arbitrary, and chosen to give an interesting dynamics between searching depth-first and breadth-first. No pi should be greater than 1/2, in order to (roughly) satisfy the assumption of Proposition 10. We call this model the Gaussian binary tree.\nComplete Tree The accuracy of the predictions of Proposition 5 and 6 are shown in Table 1, and the accuracy of Proposition 9 and 10 in Table 2. The relative error is always small for BFS (< 10%). For DFS the error is generally within 20%, except when the search time is small (< 35 probes), in which case the absolute error is always small. The decision boundary of Proposition 7 is\nshown in Figure 2, and the decision boundary of Proposition 9 vs. 10 is shown in Figure 8. These boundary plots show that the analysis generally predict the correct BFS vs. DFS winner.\nGrammar The binary grammar model of Section 7.1 serves to verify the general estimates of Proposition 14 and 16. The results are shown in Table 3. The estimates for BFS are accurate as usual (< 3% error). With few exceptions, the lower and the upper bounds tDFSBGL and t DFS BGU of Corollary 19 for DFS differ by at most 50% on the respective sides from the true (empirical) average.The arithmetic mean t\u0303DFSBG often give surprisingly accurate predictions (< 4%) except when tDFSBGL and t DFS BGU leave wide margins as to the expected search time (when g = 14, the margin is up to 84% downwards and 125% upwards). Even then, the t\u0303DFSBG error remains within 30%."}, {"heading": "9 Empirical Predictions", "text": "The Random Grammar model of Section 7.2 exhibits a rich variety of topological features such as properties of the branching factor distribution. It is an interesting\nBG are mostly\naccurate. Each box contains empirical average/analytical expectation/error percentage.\nquestion to what extent such features can be used to predict whether BFS or DFS is the better search method. However, it is harder to approach analytically, due to its many cases not the least. We therefore approached this problem empirically.\nWe generated a data set with 1827 randomly sampled random grammars. The sampling was done uniformly from the following sets: First sample a number of rules r \u2208 [4, 8] \u2229 N, then a random size r subset of the 8 possible production rules. Also sample maximum depth D \u2208 [11, 15] \u2229 N. Sample a number of goals n \u2208 [3, 5D] \u2229 N. Sample n times a level k \u2208 [1, D] \u2229 N and a node on level k; make the sampled node a goal.\nWe trained a Support Vector Machine from the scikit-learn package (Pedregosa et al., 2011) with a (Gaussian) Radial Basis Kernel to predict whether BFS or DFS would find a first goal faster. The features we predicted from were\n\u2022 Mean branching factor\n\u2022 Standard deviation of branching factor\n\u2022 Number of rules\n\u2022 Maximum depth\nThe best parameter settings for the support vector machine were C = 1000, degree = 3, \u03b3 = 0.1. Against a cross-validation data set, the trained support vector classifier got the BFS/DFS winner correct in 63% of the cases, in a dataset where DFS won 55% of the time. The results give an early indication that it may be possible to predict the best search method based solely on locally estimable features of the search graph."}, {"heading": "10 Discussion", "text": "Search and optimisation problems appears in different flavors throughout the field of artificial intelligence; in planning, problem solving, games, and learning. Therefore even minor improvements to search performance can potentially lead to gains in many aspects of intelligent systems. It is even possible to equate intelligence with (Bayesian expectimax) optimisation performance (Legg and Hutter, 2007).\nSummary. In this report we have derived analytical results for expected runtime performance. Section 5 focused on BFS and DFS tree search where explored nodes were not remembered. A vector p = (p1, . . . , pD) described a priori goal probabilities for the different levels of the tree. This concrete but general model of goal distribution allowed us to calculate approximate closedform expression of both BFS and DFS average runtime. Earlier studies have only addressed worst-case runtimes: Knuth (1975) and followers for DFS; Korf et al. (2001) and followers for IDA*, effectively a generalised version of BFS.\nSection 6 and 7 generalised the model of Section 5 to non-tree graphs. In addition to the goal probability vector p, the graph search analysis required additional structural information in the form of a descendant counter L. The graph search estimates also took the form of less precise bounds. The analysis of Section 6 does not supersede the analysis in Section 5, as the bounds of\nSection 6 become uninformative when the graph is a tree. The results are generally consistent with empirical reality.\nConclusions and Outlook. The value of the results are at least twofold. They offer a concrete means of deciding between BFS and DFS given some rough idea of the location of the goal (and the graph structure). To make the results more generally usable, automatic inference of model parameters would be necessary; primarily of goal distribution p and graph structure L. (The depth D will often be set by the searcher itself, and perhaps be iteratively increased.) There is good hope that the descendant counter L can be estimated online from the local sample obtained during search, similar to (Knuth, 1975). The goal distribution is likely to prove more challenging, but resembles the automatic creation of heuristic functions, so techniques such as relaxed problems could well prove useful (Pearl, 1984). Estimates of goal distribution could possible also be inferred from a heuristic function.\nThe results also offer theoretical insight into BFS and DFS performance. As BFS and DFS are in a sense the most fundamental search operations, we have high hopes that our results and techniques will prove useful as building blocks for analysis of more advanced search algorithms as well. For example, A* and IDA* may be viewed as a generalisations of BFS, and Beam Search and Greedy Best-First as generalisations of DFS."}, {"heading": "A List of notation", "text": "P Probability X, Y Random variables E[ \u00b7 ] Expectation of a random variable O Big-O notation EC Edge cost h Heuristic function g Accumulated path cost from start node Q Objective function D Maximum depth of search space pg Goal probability at a single goal level g pk Goal probability for a level k p Vector of probabilities for multiple goal levels \u00b5, \u03c32 Goal peak and goal spread in Gaussian binary tree \u0393 Probability that a goal exists \u0393k Probability that level k has a goal Fk Probability that level k has the first goal tBFSSGL, t\u0303 DFS SGL Expected BFS search time and approximate expected DFS search time in a complete tree with a single goal level tBFSMGL, t\u0303 DFS MGL Expected BFS search time and approximate expected DFS search time in a complete tree with multiple goal levels tBFSCB , t\u0303 DFS CB Expected BFS search time and approximate expected DFS search time in a graph with colliding branches tBFSBG , t\u0303 DFS BG Expected BFS search time and approximate expected DFS search time in the binary grammar problem tBFSFG , t\u0303 DFS FG Expected BFS search time and approximate expected DFS search time in the full grammar problem \u03b4n The first node on level n reached by DFS L(n, d) Descendant counter, counting the number of level d descendants reachable from \u03b4n LFG, LBG Descendant counters for the binary grammar problem and the full grammar problem An,d Number of nodes reachable from \u03b4n not reachable from \u03b4n+1 Sn Descendants of \u03b4n Tn Descendants of \u03b4n that are not descendants of \u03b4n+1 Un The number of nodes above level n. \u03c4n The probability that Tn contains a goal (Lemma 13) \u03c6n The probability that Tn inhabits the first goal b Branching factor Empty string"}, {"heading": "B List of search problems", "text": "The following is an incomplete list of problems naturally modelled as search problems, organised by type.\n\u2022 Puzzles\n\u2013 N-puzzle\n\u2013 Instant insanity (Knuth 1975)\n\u2013 Eternity II (Assembly puzzles)\n\u2022 Infinite\n\u2013 Grammar (aka Production system; simpler PSVN)\n\u2013 STRIPS planning (PDDL language)\n\u2013 Root-factorial (Knuth)\n\u2022 Real-world problems\n\u2013 MDP\n\u2013 SAT\n\u2013 VLSI chip design (cell layout, channel routing)\n\u2013 Robot navigation (continuous)\n\u2013 Route finding\n\u2013 Tour finding\n\u2013 Assembly sequencing\n\u2013 Protein design\n\u2013 Jobshop (who does what task when)\n\u2022 Other\n\u2013 Towers of Hanoi\n\u2013 Cannibal-missionary\n\u2013 Sokoban\n\u2013 Rubik\u2019s cube\n\u2013 Sudoku\n\u2013 Knight jumping\n\u2013 N-queens\n\u2013 Belief state (in a deterministic, partially observable world)\n\u2013 Quasigroup completion problem (Gomes et al., 1997), naturally CSP\n\u2013 Counterfeit coin problem (Pearl, 1988)"}, {"heading": "C List of Topological features", "text": "The neighbourhood relation N induces a topology on the state space S. The goal of this study is to closer investigate how topological features of the search graph affects search performance. Following is a list of potentially useful features, where +, ?, - ranks the features by a priori likelihood of being useful. Please refer to (Diestel, 2006) for a standard reference on graph theory and for explanations and definitions of below terms.\n\u2022 Problem type + Directed/undirected graph\n\u2022 State space + number of nodes (finite or infinite)\n- number of edges\n\u2022 Graph structure - bipartite/k-partite\n+ clique size distribution\n+ clique covering number (how many cliques are required to cover the graph?)\n- chordal (every cycle of length \u2265 4 has a \u201dchord\u201d) - stability number (greatest number of non-connected nodes)\n+ degree (max/min/average)\n- min cycle (girth)\n- max cycle (circumference)\n- diameter = maxx,y distance(x, y)\n- radius = minx maxy distance(x, y) (x is \u2018the centre\u2019 of the graph). The radius satisfies radius(G) \u2264 diameter(G) \u2264 2 \u00b7 radius(G).\n\u2022 Tree structure + height\n+ max width\n+ width as a function of depth\n\u2022 Branching factor + Distribution (possibly as a function of depth)\n+ Max\n+ Effective (when using heuristic)\n\u2022 Path length + Max/average path length from origin, repeating allowed/disallowed\n\u2022 Path redundancy + k-connectedness (every node pair have at least k independent paths)\n- l-edge-connectedness (no cutset of l edges)\n+ distribution of connectedness/revisiting frequency\n\u2022 Matrix properties + Spectrum (Spectral Graph Theory)\n\u2022 Edge space ? Cyclomatic number (defined in (Diestel, 2006, p. 24) as the dimension\nof the space formed by cycles \u2013 a subspace of the space of edges under \u201dsymmetric difference\u201d)\n- Cut space dimension\nMany properties of the search graph can be estimated from local samples. For example, Wu and Preciado (2013) show that the spectrum of the graph (i.e., the eigenvalues of the matrix representation of the graph) can be estimated this way."}], "references": [{"title": "Learning During Search", "author": ["A. Arbelaez Rodriguez"], "venue": "Phd thesis, University of Paris-Sud", "citeRegEx": "Rodriguez,? \\Q2011\\E", "shortCiteRegEx": "Rodriguez", "year": 2011}, {"title": "Metaheuristics in Combinatorial Optimization: Overview and Conceptual Comparison", "author": ["C. Blum", "A. Roli"], "venue": "ACM Computing Surveys,", "citeRegEx": "Blum and Roli,? \\Q2003\\E", "shortCiteRegEx": "Blum and Roli", "year": 2003}, {"title": "Hyper Heuristics: an emerging direction in modern search technology", "author": ["E. Burke", "E. Hart", "G. Kendall", "J. Newall", "P. Ross", "S. Schulenburg"], "venue": "Handbook of Metaheuristics,", "citeRegEx": "Burke et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Burke et al\\.", "year": 2003}, {"title": "Hyper-heuristics: a survey of the state of the art", "author": ["E.K. Burke", "M. Gendreau", "M. Hyde", "G. Kendall", "G. Ochoa 1\u00e3", "E. Zcan", "R. Qu"], "venue": "Journal of the Operational Research Society,", "citeRegEx": "Burke et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Burke et al\\.", "year": 2013}, {"title": "Heuristic Sampling: A Method for Predicting the Performance of Tree Searching Programs", "author": ["P.C. Chen"], "venue": "SIAM Journal on Computing,", "citeRegEx": "Chen,? \\Q1992\\E", "shortCiteRegEx": "Chen", "year": 1992}, {"title": "Explanation-based Learning: An Alternative View", "author": ["G. Dejong", "R. Mooney"], "venue": "Machine Learning,", "citeRegEx": "Dejong and Mooney,? \\Q1986\\E", "shortCiteRegEx": "Dejong and Mooney", "year": 1986}, {"title": "Graph Theory (Graduate Texts in Mathematics)", "author": ["R. Diestel"], "venue": null, "citeRegEx": "Diestel,? \\Q2006\\E", "shortCiteRegEx": "Diestel", "year": 2006}, {"title": "Acquiring search-control knowledge via static analysis", "author": ["O. Etzioni"], "venue": "Artificial Intelligence,", "citeRegEx": "Etzioni,? \\Q1993\\E", "shortCiteRegEx": "Etzioni", "year": 1993}, {"title": "Analytical Results on the BFS vs. DFS Algorithm Selection Problem", "author": ["T. Everitt", "M. Hutter"], "venue": "Part I: Tree Search. In 28th Australian Joint Conference on Artificial Intelligence", "citeRegEx": "Everitt and Hutter,? \\Q2015\\E", "shortCiteRegEx": "Everitt and Hutter", "year": 2015}, {"title": "Analytical Results on the BFS vs. DFS Algorithm Selection Problem. Part II: Graph Search", "author": ["T. Everitt", "M. Hutter"], "venue": "In 28th Australian Joint Conference on Artificial Intelligence", "citeRegEx": "Everitt and Hutter,? \\Q2015\\E", "shortCiteRegEx": "Everitt and Hutter", "year": 2015}, {"title": "How to Solve It Automatically: Selection Among ProblemSolving Methods", "author": ["E. Fink"], "venue": "In Proceedings of the Fourth International Conference on Artificial Intelligence Planning Systems,", "citeRegEx": "Fink,? \\Q1998\\E", "shortCiteRegEx": "Fink", "year": 1998}, {"title": "Heavy-tailed distributions in combinatorial search", "author": ["C.P. Gomes", "B. Selman", "N. Crato"], "venue": "Principles and Practice of Constraint", "citeRegEx": "Gomes et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Gomes et al\\.", "year": 1997}, {"title": "Online estimation of SAT solving runtime", "author": ["S. Haim", "T. Walsh"], "venue": "In Theory and Applications of Satisfiability Testing,", "citeRegEx": "Haim and Walsh,? \\Q2008\\E", "shortCiteRegEx": "Haim and Walsh", "year": 2008}, {"title": "Programming by optimization", "author": ["H.H. Hoos"], "venue": "Communications of the ACM,", "citeRegEx": "Hoos,? \\Q2012\\E", "shortCiteRegEx": "Hoos", "year": 2012}, {"title": "Algorithm runtime prediction: Methods & evaluation", "author": ["F. Hutter", "L. Xu", "H.H. Hoos", "K. Leyton-Brown"], "venue": "Artificial Intelligence,", "citeRegEx": "Hutter et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hutter et al\\.", "year": 2014}, {"title": "Estimating Search Tree Size", "author": ["P. Kilby", "J. Slaney", "S. Thi\u00e9baux", "T. Walsh"], "venue": "In Proc. of the 21st National Conf. of Artificial Intelligence,", "citeRegEx": "Kilby et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Kilby et al\\.", "year": 2006}, {"title": "Estimating the efficiency of backtrack programs", "author": ["D.E. Knuth"], "venue": "Mathematics of Computation,", "citeRegEx": "Knuth,? \\Q1975\\E", "shortCiteRegEx": "Knuth", "year": 1975}, {"title": "Time complexity of iterativedeepening-A", "author": ["R.E. Korf", "M. Reid", "S. Edelkamp"], "venue": "Artificial Intelligence,", "citeRegEx": "Korf et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Korf et al\\.", "year": 2001}, {"title": "Algorithm Selection for Combinatorial Search Problems: A Survey", "author": ["L. Kotthoff"], "venue": "AI Magazine,", "citeRegEx": "Kotthoff,? \\Q2014\\E", "shortCiteRegEx": "Kotthoff", "year": 2014}, {"title": "Fundaments of Branching Heuristics: Theory and Examples", "author": ["O. Kullmann"], "venue": "Technical report,", "citeRegEx": "Kullmann,? \\Q2008\\E", "shortCiteRegEx": "Kullmann", "year": 2008}, {"title": "Inductive learning of search control rules for planning", "author": ["C. Leckie", "I. Zukerman"], "venue": "Artificial Intelligence,", "citeRegEx": "Leckie and Zukerman,? \\Q1998\\E", "shortCiteRegEx": "Leckie and Zukerman", "year": 1998}, {"title": "Predicting the size of Depthfirst Branch and Bound search trees", "author": ["L.H.S. Lelis", "L. Otten", "R. Dechter"], "venue": "IJCAI International Joint Conference on Artificial Intelligence,", "citeRegEx": "Lelis et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Lelis et al\\.", "year": 2013}, {"title": "Learning Search Control Knowledge: An Explanation-Based Approach", "author": ["S. Minton"], "venue": null, "citeRegEx": "Minton,? \\Q1988\\E", "shortCiteRegEx": "Minton", "year": 1988}, {"title": "Quantitative results concerning the utility of explanationbased learning", "author": ["S. Minton"], "venue": "Artificial Intelligence,", "citeRegEx": "Minton,? \\Q1990\\E", "shortCiteRegEx": "Minton", "year": 1990}, {"title": "Explanation-based generalization: A unifying view", "author": ["T. Mitchell", "R. Keller", "S. Kedar-CabeUi"], "venue": "Machine Learning,", "citeRegEx": "Mitchell et al\\.,? \\Q1986\\E", "shortCiteRegEx": "Mitchell et al\\.", "year": 1986}, {"title": "Heuristics: Intelligent Search Strategies for Computer Problem Solving", "author": ["J. Pearl"], "venue": null, "citeRegEx": "Pearl,? \\Q1984\\E", "shortCiteRegEx": "Pearl", "year": 1984}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference", "author": ["J. Pearl"], "venue": null, "citeRegEx": "Pearl,? \\Q1988\\E", "shortCiteRegEx": "Pearl", "year": 1988}, {"title": "The graph-tool python library. figshare", "author": ["T.P. Peixoto"], "venue": null, "citeRegEx": "Peixoto,? \\Q2015\\E", "shortCiteRegEx": "Peixoto", "year": 2015}, {"title": "Tree Size by Partial Backtracking", "author": ["P.W. Purdom"], "venue": "SIAM Journal on Computing,", "citeRegEx": "Purdom,? \\Q1978\\E", "shortCiteRegEx": "Purdom", "year": 1978}, {"title": "The algorithm selection problem", "author": ["J.R. Rice"], "venue": "Advances in Computers,", "citeRegEx": "Rice,? \\Q1975\\E", "shortCiteRegEx": "Rice", "year": 1975}, {"title": "The diameter of the rubiks cube group is twenty", "author": ["T. Rokicki", "H. Kociemba"], "venue": "SIAM Journal on Discrete Mathematics,", "citeRegEx": "Rokicki and Kociemba,? \\Q2013\\E", "shortCiteRegEx": "Rokicki and Kociemba", "year": 2013}, {"title": "Hyperheuristics: learning to combine simple heuristics in bin-packing problems", "author": ["P. Ross", "S. Schulenburg", "J.G. Marin-Blazquez", "E. Hart"], "venue": null, "citeRegEx": "Ross et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Ross et al\\.", "year": 2002}, {"title": "Artificial intelligence: a modern approach", "author": ["S.J. Russell", "P. Norvig"], "venue": null, "citeRegEx": "Russell and Norvig,? \\Q2010\\E", "shortCiteRegEx": "Russell and Norvig", "year": 2010}, {"title": "Measuring instance difficulty for combinatorial optimization problems", "author": ["K. Smith-Miles", "L. Lopes"], "venue": "Computers and Operations Research,", "citeRegEx": "Smith.Miles and Lopes,? \\Q2012\\E", "shortCiteRegEx": "Smith.Miles and Lopes", "year": 2012}, {"title": "Metareasoning about propagators for constraint satisfaction", "author": ["C. Thompson"], "venue": "Phd thesis, University of Saskatchewan", "citeRegEx": "Thompson,? \\Q2011\\E", "shortCiteRegEx": "Thompson", "year": 2011}, {"title": "Laplacian Spectral Properties of Graphs from Random Local Samples", "author": ["Z. Wu", "V.M. Preciado"], "venue": null, "citeRegEx": "Wu and Preciado,? \\Q2013\\E", "shortCiteRegEx": "Wu and Preciado", "year": 2013}, {"title": "Predicting the performance of IDA* using conditional distributions", "author": ["U. Zahavi", "A. Felner", "N. Burch", "R.C. Holte"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Zahavi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Zahavi et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 32, "context": "A wide range of problems in artificial intelligence can be naturally formulated as search problems (Russell and Norvig, 2010; Edelkamp and Schr\u00f6dl, 2012).", "startOffset": 99, "endOffset": 153}, {"referenceID": 29, "context": "Predicting the best algorithm is sometimes known as the algorithm selection problem (Rice, 1975).", "startOffset": 84, "endOffset": 96}, {"referenceID": 18, "context": "A number of studies have approached the algorithm selection problem with machine learning techniques (Kotthoff, 2014; Hutter et al., 2014).", "startOffset": 101, "endOffset": 138}, {"referenceID": 14, "context": "A number of studies have approached the algorithm selection problem with machine learning techniques (Kotthoff, 2014; Hutter et al., 2014).", "startOffset": 101, "endOffset": 138}, {"referenceID": 14, "context": "A number of studies have approached the algorithm selection problem with machine learning techniques (Kotthoff, 2014; Hutter et al., 2014). While demonstrably a feasible path, machine learning tend to be used as a black box, offering little insight into why a certain method works better on a given problem. On the other hand, most existing analytical results focus on worst-case big-O analysis, which is often less useful than average-case analysis when selecting algorithm. An important worst-case result is Knuth\u2019s (1975) simple but useful technique", "startOffset": 118, "endOffset": 525}, {"referenceID": 12, "context": "Kilby et al. (2006) used it for algorithm selection in the SAT problem.", "startOffset": 0, "endOffset": 20}, {"referenceID": 12, "context": "Kilby et al. (2006) used it for algorithm selection in the SAT problem. See also the extensions by Purdom (1978), Chen (1992), and Lelis et al.", "startOffset": 0, "endOffset": 113}, {"referenceID": 4, "context": "See also the extensions by Purdom (1978), Chen (1992), and Lelis et al.", "startOffset": 42, "endOffset": 54}, {"referenceID": 4, "context": "See also the extensions by Purdom (1978), Chen (1992), and Lelis et al. (2013). Analytical IDA* runtime predictions based on problem features was obtained by Korf et al.", "startOffset": 42, "endOffset": 79}, {"referenceID": 4, "context": "See also the extensions by Purdom (1978), Chen (1992), and Lelis et al. (2013). Analytical IDA* runtime predictions based on problem features was obtained by Korf et al. (2001) and Zahavi et al.", "startOffset": 42, "endOffset": 177}, {"referenceID": 4, "context": "See also the extensions by Purdom (1978), Chen (1992), and Lelis et al. (2013). Analytical IDA* runtime predictions based on problem features was obtained by Korf et al. (2001) and Zahavi et al. (2010). In this study we focus on theoretical analysis of average runtime of BFS and DFS.", "startOffset": 42, "endOffset": 202}, {"referenceID": 1, "context": "Blum and Roli (2003) suggest that this offers a unified view of many search problems.", "startOffset": 0, "endOffset": 21}, {"referenceID": 1, "context": "Blum and Roli (2003) suggest that this offers a unified view of many search problems. A CSP formulation also seems largely in line with what Pearl (1988) has in mind, although Pearl is less specific.", "startOffset": 0, "endOffset": 154}, {"referenceID": 32, "context": "We here review only a subset of the more important ones, and refer to the books (Russell and Norvig, 2010; Edelkamp and Schr\u00f6dl, 2012) for more details.", "startOffset": 80, "endOffset": 134}, {"referenceID": 29, "context": "The algorithm selection problem asks what algorithm best to use on a given problem (Rice, 1975; Kotthoff, 2014).", "startOffset": 83, "endOffset": 111}, {"referenceID": 18, "context": "The algorithm selection problem asks what algorithm best to use on a given problem (Rice, 1975; Kotthoff, 2014).", "startOffset": 83, "endOffset": 111}, {"referenceID": 28, "context": "Several generalisations have been developed (Purdom, 1978; Chen, 1992).", "startOffset": 44, "endOffset": 70}, {"referenceID": 4, "context": "Several generalisations have been developed (Purdom, 1978; Chen, 1992).", "startOffset": 44, "endOffset": 70}, {"referenceID": 34, "context": "Schemes using much wider ranges of problem properties are applied to CSPs in (Thompson, 2011; Arbelaez Rodriguez, 2011), and to the NP-complete problems SAT, TSP and Mixed integer programming in (Hutter et al.", "startOffset": 77, "endOffset": 119}, {"referenceID": 14, "context": "Schemes using much wider ranges of problem properties are applied to CSPs in (Thompson, 2011; Arbelaez Rodriguez, 2011), and to the NP-complete problems SAT, TSP and Mixed integer programming in (Hutter et al., 2014).", "startOffset": 195, "endOffset": 216}, {"referenceID": 10, "context": "The most comprehensive surveys are given by Hutter et al. (2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011).", "startOffset": 44, "endOffset": 65}, {"referenceID": 10, "context": "The most comprehensive surveys are given by Hutter et al. (2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011).", "startOffset": 44, "endOffset": 85}, {"referenceID": 10, "context": "The most comprehensive surveys are given by Hutter et al. (2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011).", "startOffset": 44, "endOffset": 121}, {"referenceID": 0, "context": "(2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011). For DFS, Knuth (1975) made a simple but important observation how the branching factor seen during search can be used to estimate the size of the search tree and the runtime.", "startOffset": 76, "endOffset": 93}, {"referenceID": 0, "context": "(2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011). For DFS, Knuth (1975) made a simple but important observation how the branching factor seen during search can be used to estimate the size of the search tree and the runtime.", "startOffset": 76, "endOffset": 116}, {"referenceID": 0, "context": "(2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011). For DFS, Knuth (1975) made a simple but important observation how the branching factor seen during search can be used to estimate the size of the search tree and the runtime. Despite the simplicity of the scheme, the estimates work surprisingly well in practice. Several generalisations have been developed (Purdom, 1978; Chen, 1992). Kilby et al. (2006) generalise Knuth\u2019s method, and also use it to select search policy for the SAT problem based on which search policy has the lowest estimated runtime.", "startOffset": 76, "endOffset": 449}, {"referenceID": 0, "context": "(2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011). For DFS, Knuth (1975) made a simple but important observation how the branching factor seen during search can be used to estimate the size of the search tree and the runtime. Despite the simplicity of the scheme, the estimates work surprisingly well in practice. Several generalisations have been developed (Purdom, 1978; Chen, 1992). Kilby et al. (2006) generalise Knuth\u2019s method, and also use it to select search policy for the SAT problem based on which search policy has the lowest estimated runtime. Kullmann (2008) and Lelis et al.", "startOffset": 76, "endOffset": 615}, {"referenceID": 0, "context": "(2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011). For DFS, Knuth (1975) made a simple but important observation how the branching factor seen during search can be used to estimate the size of the search tree and the runtime. Despite the simplicity of the scheme, the estimates work surprisingly well in practice. Several generalisations have been developed (Purdom, 1978; Chen, 1992). Kilby et al. (2006) generalise Knuth\u2019s method, and also use it to select search policy for the SAT problem based on which search policy has the lowest estimated runtime. Kullmann (2008) and Lelis et al. (2013) both develop estimation schemes for branch-and-bound algorithms.", "startOffset": 76, "endOffset": 639}, {"referenceID": 0, "context": "(2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011). For DFS, Knuth (1975) made a simple but important observation how the branching factor seen during search can be used to estimate the size of the search tree and the runtime. Despite the simplicity of the scheme, the estimates work surprisingly well in practice. Several generalisations have been developed (Purdom, 1978; Chen, 1992). Kilby et al. (2006) generalise Knuth\u2019s method, and also use it to select search policy for the SAT problem based on which search policy has the lowest estimated runtime. Kullmann (2008) and Lelis et al. (2013) both develop estimation schemes for branch-and-bound algorithms. Haim and Walsh (2008) approach the SAT problem, and instead of branching factor use properties of the given formula (such as the number and the size of clauses) to be predict search time and best search policy.", "startOffset": 76, "endOffset": 726}, {"referenceID": 0, "context": "(2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011). For DFS, Knuth (1975) made a simple but important observation how the branching factor seen during search can be used to estimate the size of the search tree and the runtime. Despite the simplicity of the scheme, the estimates work surprisingly well in practice. Several generalisations have been developed (Purdom, 1978; Chen, 1992). Kilby et al. (2006) generalise Knuth\u2019s method, and also use it to select search policy for the SAT problem based on which search policy has the lowest estimated runtime. Kullmann (2008) and Lelis et al. (2013) both develop estimation schemes for branch-and-bound algorithms. Haim and Walsh (2008) approach the SAT problem, and instead of branching factor use properties of the given formula (such as the number and the size of clauses) to be predict search time and best search policy. In the case of informed search, Korf et al. (2001) developed an interesting analytic technique for estimating the search time of IDA*.", "startOffset": 76, "endOffset": 966}, {"referenceID": 0, "context": "(2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011). For DFS, Knuth (1975) made a simple but important observation how the branching factor seen during search can be used to estimate the size of the search tree and the runtime. Despite the simplicity of the scheme, the estimates work surprisingly well in practice. Several generalisations have been developed (Purdom, 1978; Chen, 1992). Kilby et al. (2006) generalise Knuth\u2019s method, and also use it to select search policy for the SAT problem based on which search policy has the lowest estimated runtime. Kullmann (2008) and Lelis et al. (2013) both develop estimation schemes for branch-and-bound algorithms. Haim and Walsh (2008) approach the SAT problem, and instead of branching factor use properties of the given formula (such as the number and the size of clauses) to be predict search time and best search policy. In the case of informed search, Korf et al. (2001) developed an interesting analytic technique for estimating the search time of IDA*. Assuming a consistent heuristic function, the estimate is based on the distribution of heuristic function values at different depths of the search tree, rather than heuristic accuracy. Intuitively, the scheme works because the number of nodes expanded in each iteration of IDA* depends on the number of nodes with heuristic value less than the threshold. The distribution of heuristic values is also easy to estimate in practice. Zahavi et al. (2010) generalise the work of Korf et al.", "startOffset": 76, "endOffset": 1501}, {"referenceID": 0, "context": "(2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011). For DFS, Knuth (1975) made a simple but important observation how the branching factor seen during search can be used to estimate the size of the search tree and the runtime. Despite the simplicity of the scheme, the estimates work surprisingly well in practice. Several generalisations have been developed (Purdom, 1978; Chen, 1992). Kilby et al. (2006) generalise Knuth\u2019s method, and also use it to select search policy for the SAT problem based on which search policy has the lowest estimated runtime. Kullmann (2008) and Lelis et al. (2013) both develop estimation schemes for branch-and-bound algorithms. Haim and Walsh (2008) approach the SAT problem, and instead of branching factor use properties of the given formula (such as the number and the size of clauses) to be predict search time and best search policy. In the case of informed search, Korf et al. (2001) developed an interesting analytic technique for estimating the search time of IDA*. Assuming a consistent heuristic function, the estimate is based on the distribution of heuristic function values at different depths of the search tree, rather than heuristic accuracy. Intuitively, the scheme works because the number of nodes expanded in each iteration of IDA* depends on the number of nodes with heuristic value less than the threshold. The distribution of heuristic values is also easy to estimate in practice. Zahavi et al. (2010) generalise the work of Korf et al. to non-consistent heuristics. Many other approaches instead try to directly infer the best search policy, without the intermediate step of estimating runtime. Fink (1998) does this for STRIPS-like learning using only the problem size to infer which method is likely to be more efficient.", "startOffset": 76, "endOffset": 1707}, {"referenceID": 0, "context": "(2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011). For DFS, Knuth (1975) made a simple but important observation how the branching factor seen during search can be used to estimate the size of the search tree and the runtime. Despite the simplicity of the scheme, the estimates work surprisingly well in practice. Several generalisations have been developed (Purdom, 1978; Chen, 1992). Kilby et al. (2006) generalise Knuth\u2019s method, and also use it to select search policy for the SAT problem based on which search policy has the lowest estimated runtime. Kullmann (2008) and Lelis et al. (2013) both develop estimation schemes for branch-and-bound algorithms. Haim and Walsh (2008) approach the SAT problem, and instead of branching factor use properties of the given formula (such as the number and the size of clauses) to be predict search time and best search policy. In the case of informed search, Korf et al. (2001) developed an interesting analytic technique for estimating the search time of IDA*. Assuming a consistent heuristic function, the estimate is based on the distribution of heuristic function values at different depths of the search tree, rather than heuristic accuracy. Intuitively, the scheme works because the number of nodes expanded in each iteration of IDA* depends on the number of nodes with heuristic value less than the threshold. The distribution of heuristic values is also easy to estimate in practice. Zahavi et al. (2010) generalise the work of Korf et al. to non-consistent heuristics. Many other approaches instead try to directly infer the best search policy, without the intermediate step of estimating runtime. Fink (1998) does this for STRIPS-like learning using only the problem size to infer which method is likely to be more efficient. Schemes using much wider ranges of problem properties are applied to CSPs in (Thompson, 2011; Arbelaez Rodriguez, 2011), and to the NP-complete problems SAT, TSP and Mixed integer programming in (Hutter et al., 2014). Smith-Miles and Lopes (2012) review and discuss commonly used features for the algorithm selection problem, mainly applied to the local search scenario.", "startOffset": 76, "endOffset": 2071}, {"referenceID": 5, "context": "Explanation-based Learning (EBL) (Dejong and Mooney, 1986; Mitchell et al., 1986; Minton, 1988) is a general method for learning from examples and domain knowledge.", "startOffset": 33, "endOffset": 95}, {"referenceID": 24, "context": "Explanation-based Learning (EBL) (Dejong and Mooney, 1986; Mitchell et al., 1986; Minton, 1988) is a general method for learning from examples and domain knowledge.", "startOffset": 33, "endOffset": 95}, {"referenceID": 22, "context": "Explanation-based Learning (EBL) (Dejong and Mooney, 1986; Mitchell et al., 1986; Minton, 1988) is a general method for learning from examples and domain knowledge.", "startOffset": 33, "endOffset": 95}, {"referenceID": 22, "context": "While attractive, it can also lead to overspecific learning (Minton, 1988).", "startOffset": 60, "endOffset": 74}, {"referenceID": 7, "context": "Partial Evaluation (PE) is an alternative learning method that is more robust in this respect, with less dependency on examples (Etzioni, 1993).", "startOffset": 128, "endOffset": 143}, {"referenceID": 3, "context": "Some research is also being done on automatic construction of low-level heuristics (see (Burke et al., 2013) for references).", "startOffset": 88, "endOffset": 108}, {"referenceID": 13, "context": "A related approach directed at programming in general is programming by optimisation (Hoos, 2012), where machine learning techniques are used to find the best algorithm in a space of programs delineated by the human programmer.", "startOffset": 85, "endOffset": 97}, {"referenceID": 5, "context": "Partial Evaluation (PE) is an alternative learning method that is more robust in this respect, with less dependency on examples (Etzioni, 1993). Leckie and Zukerman (1998) develops a more inductive way to learn search control knowledge (in contrast to the deductive generalisations performed by EBL and PE), where plenty of training examples substitute for domain knowledge.", "startOffset": 129, "endOffset": 172}, {"referenceID": 2, "context": "A more modern approach is known as hyper heuristics (Burke et al., 2003, 2013). It views the problem of inferring good search policies more abstractly. Rather than interacting with the neighbourhood structure/graph problem directly, the hyper heuristic only has access to a set of search policies for the original graph problem. The search policies are known as low-level heuristics in this literature (not to be confused with heuristic functions). The goal of the hyper heuristic is to find a good policy for when to apply which low-level heuristic. For example, Ross et al. (2002) used Genetic Algorithms to learn which binpacking heuristic to apply in which type of state in a bin-packing problem.", "startOffset": 53, "endOffset": 583}, {"referenceID": 30, "context": "There is an upper bound D = 20 to how many moves it can take to reach the goal (Rokicki and Kociemba, 2013).", "startOffset": 79, "endOffset": 107}, {"referenceID": 17, "context": "Korf et al. (2001) study", "startOffset": 0, "endOffset": 19}, {"referenceID": 27, "context": "To verify the analytical results, we have implemented the models Sections 5\u20137 in Python 3 using the graph-tool package (Peixoto, 2015).", "startOffset": 119, "endOffset": 134}, {"referenceID": 16, "context": "Earlier studies have only addressed worst-case runtimes: Knuth (1975) and followers for DFS; Korf et al.", "startOffset": 57, "endOffset": 70}, {"referenceID": 16, "context": "Earlier studies have only addressed worst-case runtimes: Knuth (1975) and followers for DFS; Korf et al. (2001) and followers for IDA*, effectively a generalised version of BFS.", "startOffset": 57, "endOffset": 112}, {"referenceID": 16, "context": ") There is good hope that the descendant counter L can be estimated online from the local sample obtained during search, similar to (Knuth, 1975).", "startOffset": 132, "endOffset": 145}, {"referenceID": 25, "context": "The goal distribution is likely to prove more challenging, but resembles the automatic creation of heuristic functions, so techniques such as relaxed problems could well prove useful (Pearl, 1984).", "startOffset": 183, "endOffset": 196}], "year": 2015, "abstractText": "Search is a central problem in artificial intelligence, and BFS and DFS the two most fundamental ways to search. In this report we derive results for average BFS and DFS runtime: For tree search, we employ a probabilistic model of goal distribution; for graph search, the analysis depends on an additional statistic of path redundancy and average branching factor. As an application, we use the results on two concrete grammar problems. The runtime estimates can be used to select the faster out of BFS and DFS for a given problem, and may form the basis for further analysis of more advanced search methods. Finally, we verify our results experimentally; the analytical approximations come surprisingly close to empirical reality.", "creator": "LaTeX with hyperref package"}}}