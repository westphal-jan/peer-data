{"id": "1510.07313", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Oct-2015", "title": "Safe Control under Uncertainty", "abstract": "controller synthesis for hybrid systems that satisfy particular specifications expressing various system properties is a challenging problem that has widespread wide attention of many researchers. therefore, making the assumption that such temporal properties are deterministic is predictable from formal reality. for example, many of the properties the controller has to satisfy are learned through machine learning techniques based on sensor input data. preparing this paper, we propose a new logic, probabilistic signal temporal logic ( prstl ), as an expressive language to define the stochastic properties, and enforce probabilistic guarantees on humans. we further show how to synthesize safe controllers using this logic for cyber - environment hazards under the assumption some somehow observed consequences get based on a set of structured random variables. one of the key distinguishing features of system is that the encoded logic is adaptive and changes as the system encounters additional data accurately updates its beliefs about the latent random variables that define the safety component. we highlight our approach by synthesizing safe controllers under the prstl specifications for multiple case studies including control of quadrotors and autonomous parameters in dynamic environments.", "histories": [["v1", "Sun, 25 Oct 2015 22:02:48 GMT  (330kb,D)", "http://arxiv.org/abs/1510.07313v1", "10 pages, 6 figures, Submitted to HSCC 2016"]], "COMMENTS": "10 pages, 6 figures, Submitted to HSCC 2016", "reviews": [], "SUBJECTS": "cs.SY cs.AI cs.LO cs.RO", "authors": ["dorsa sadigh", "ashish kapoor"], "accepted": false, "id": "1510.07313"}, "pdf": {"name": "1510.07313.pdf", "metadata": {"source": "CRF", "title": "Safe Control under Uncertainty", "authors": ["Dorsa Sadigh", "Ashish Kapoor"], "emails": ["dsadigh@berkeley.edu", "akapoor@microsoft.com"], "sections": [{"heading": "1. INTRODUCTION", "text": "Synthesizing safe controllers for cyber-physical systems (CPS) is a challenging problem, due to various factors that include uncertainty arising from the environment. For example, any safe control strategy for quadcopters need to incorporate predictive information about wind gusts and any associated uncertainty in such predictions. Similarly, in the case of autonomous driving, the controller needs a probabilistic predictive model about the other vehicles on the road in order to avoid collisions. Without a model of uncertainty that would characterize all possible outcomes, there is no guarantee that the synthesized control will be safe.\nThe field of Machine Learning has a rich set of tools that can characterize uncertainties. Specifically, Bayesian graph-\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. .\nical models [20] have been very popular in modeling uncertainties arising in scenarios common to CPS. For example, one of the common strategies in CPS is to build classifiers or predictors based on acquired sensor data. It is appealing to consider such predictive systems in synthesizing safe controllers for dynamical systems. However, it is well known that it is almost impossible to guarantee a prediction system that works perfectly all the time. Consequently, we need to devise control synthesis methodologies that are aware of such limitations imposed by the Machine Learning systems. Specifically, we need to build a framework that is capable of synthesis of safe controllers by being aware of when the prediction system would work and when it would fail.\nIn this paper, we propose a methodology for safe controller synthesis using the novel Probabilistic Signal Temporal Logic (PrSTL) that allows us to embed predictive models and their associated uncertainties. The key ingredient of the framework is a logic specification that allows embedding of uncertainties via probabilistic predicates that take random variables as parameters. These random variables allow incorporation of Bayesian graphical models in these predicates, thereby resulting in a powerful logic specification that can reason about safety under uncertainty. One of the main advantages of using Bayesian graphical models (or Bayesian methods in general) is the fact that the predictions provided are full distributions associated with the quantity of interest as opposed to a point estimate. For example, a classical Machine Learning method might just provide a value for wind speed, however under the Bayesian paradigm we would be recovering an entire probability distribution over all possible winds. Finally, another distinguishing aspect of our framework is that these probabilistic predicates are adaptive: as the system sees more and more data, the inferred distribution over the latent variables of interest can change leading to change in the predicates themselves.\nPrevious efforts for synthesizing safe controllers either operate under deterministic environments or model uncertainty only as part of the dynamics of the system. For example, Signal Temporal Logic (STL) [27] provides a framework for expressing real-valued dense-time temporal properties for safety, but assumes that the signal provided from the trajectory of the system is deterministically defined by the system dynamics. Similarly, other approaches that model uncertainty as a variable added to the dynamics [36, 13, 37, 11, 12] lack clear connections to various sources of uncertainty present in the environment. Specifically, with prior approaches there is no clear understanding of how uncertainty arising due to sensing and classification could be in-\nar X\niv :1\n51 0.\n07 31\n3v 1\n[ cs\n.S Y\n] 2\n5 O\nct 2\n01 5\ncorporated while reasoning about safe control trajectories. In this paper we aim to alleviate these issues by defining a probabilistic logical specification framework that has the capacity to reason about safe control strategies by embedding various predictions and their associated uncertainty. Specifically, our contributions in this paper are:\n\u2022 Formally define PrSTL, a logic for expressing probabilistic properties that can embed Bayesian graphical models.\n\u2022 Formalize a receding horizon control problem to satisfy PrSTL specifications.\n\u2022 Provide a novel solution for the controller synthesis problem using Mixed Integer Semi-Definite Programs.\n\u2022 Provide a toolbox implementing our algorithms and showcasing experiments in autonomous driving and control of quadrotors.\nThe rest of this paper is organized as follows: In Section 2 we go over some of the related work in the area of stochastic control, and controller synthesis under safety. In Section 3, we discuss the preliminaries, and in Section 4, we define the problem statement along with the formal definition of PrSTL. Section 5 illustrates our experimental results, and we conclude in Section 6."}, {"heading": "2. RELATED WORK", "text": "Over the years researchers have proposed different approaches for safe control of cyber-physical systems. For instance, designing controllers under reachability analysis is a well-studied method that allows specifying safety and reachability properties [29, 30]. More recently, safe learning approaches construct controllers that keep the system in the safe region, while the optimal strategy is learned online [15, 3, 1]. However, finding the reachable set is computationally expensive, which makes this approach impractical for most interesting cyber-physical systems. Controller synthesis under temporal specifications such as Linear Temporal Logic (LTL) allows expressing more interesting properties of the system and environment, e. g., safety, liveness, response, stability, etc., and has shown promising results in robotics applications [32, 23, 25, 43, 16]. However, synthesis for LTL requires time and space discretization, which again suffers from the curse of dimensionality. Although, this approach is effective at high level planning, it is unsuitable for synthesizing control inputs at the level of dynamical systems. More recently, Raman et al. have studied synthesis for Signal Temporal Logic (STL), which allows real-valued, dense-time properties in a receding horizon setting [34, 35]. Although, this approach requires solving mixed integer linear programs, it has shown promising results in practice. One downside of specifying properties in STL or LTL is that the properties of the system and environment have to be expressed deterministically. Knowledge of the exact parameters and bounds of the specification is an unrealistic assumption for most CPS applications, where the system interacts with uncertain environments, and has partial knowledge of the world based on its sensors and classifiers.\nThe problem of controller synthesis under uncertainty is also a well-studied topic. One of the most effective approaches in robust control under uncertainty is modeling the\nenvironment uncertainty as part of the dynamics of the system, and finding the optimal strategy for the worst case disturbance [22, 41, 44]. However, considering worst case environment is inapplicable and too conservative. More recently, researchers have proposed modeling the environment in a chance constrained framework, and there are some promising results in the area of urban autonomous driving [24, 39, 40, 6, 8]. In most previous work the uncertainty from the system or environment is modeled as part of the dynamics, and there is not an intuitive connection between the properties, and the sensing and classification capabilities of the system. In addition, there has been efforts in verification and synthesis of controllers for temporal properties given probabilistic transition systems [36, 13, 37, 11, 12, 33]. To best of our knowledge, none of the previous studies consider scenarios, where the uncertainty and confidence in properties is originated from classifiers rather than the dynamics of the system, and is expressed as part of the specification. In this work, we propose a more natural framework for expressing temporal and Boolean properties over different sources of uncertainty, and their interconnect, which allows synthesizing safe controllers while considering such probabilistic temporal specifications."}, {"heading": "3. PRELIMINARIES", "text": ""}, {"heading": "3.1 Hybrid Dynamical System", "text": "We consider a continuous time hybrid dynamical system:\nx\u0307t = f(xt, ut) yt = g(xt, ut). (1)\nHere, xt \u2208 X \u2286 (Rnc \u00d7 {0, 1}nd) is a signal representing the continuous and discrete mode of the system at time t, ut \u2208 U \u2286 (Rmc\u00d7{0, 1}md) is the control input and yt \u2208 Y \u2286 (Rpc \u00d7 {0, 1}pd) is the output of the system at time t. This continuous system can be discretized using time intervals dt > 0, and every discrete time step is k = bt/dtc. The discrete time hybrid dynamical system is formalized as:\nxk+1 = fd(xk, uk) yk = gd(xk, uk). (2)\nWe let x0 \u2208 X denote the initial state of the dynamical system. We express an infinite run of the system as: \u03be = (x0, u0), (x1, u1), . . . . Given the initial state x0, and a finite length input sequence: uH = u0, u1, . . . , uH\u22121, the finite horizon run or trajectory of the system following the dynamics in equation (2) is:\n\u03beH(x0,u H) = (x0, u0), (x1, u1), . . . , (xH , uH). (3)\nFurthermore, we let \u03be(t) = (xt, ut) be a signal consisting of the state and input of the system at time t; \u03bex(t) = xt is the state, and \u03beu(t) = ut is the input at time t.\nThe output of the system is also computed to be yH = y0, y1, . . . , yH\u22121. A cost function is defined for the finite horizon trajectory, denoted by J(\u03beH), and maps \u03beH \u2208 \u039e, the set of all trajectories to positive real valued costs in R+."}, {"heading": "3.2 Controller Synthesis for Signal Temporal Logic", "text": "Signal Temporal Logic (STL) is an expressive framework that allows reasoning about real-valued dense-time functions, and has been largely used for defining robustness mea-\nsures and monitoring properties of real-time signals of hybrid systems [27, 10, 9]. More recently there has been interest in synthesizing controllers that satisfy STL properties [34, 35].\nFormally, (\u03be, t) |= \u03d5 denotes that a signal \u03be satisfies the STL formula \u03d5 at time t. An atomic predicate of an STL formula is represented by inequalities of the form \u00b5(\u03be(t)) > 0, where \u00b5 is a function of the signal \u03be at time t. The truth value of the predicate \u00b5 is equivalent to \u00b5(\u03be(t)) > 0. Any STL formula consists of Boolean and temporal operations on these predicates and the syntax of STL formulae \u03d5 is defined recursively as follows:\n\u03d5 ::= \u00b5 | \u00ac\u00b5 | \u03d5 \u2227 \u03c8 |G[a,b]\u03c8 | \u03d5U[a,b]\u03c8, (4)\nwhere \u03c8 and \u03d5 are STL formulae, G denotes the globally operator and U is the until operator. For instance, \u03be |= G[a,b]\u03c8 specifies that \u03c8 must hold at all times in the given interval, t \u2208 [a, b] of signal \u03be. We can also define F the eventually operator, and F[a,b]\u03c8 = \u00acG[a,b]\u00ac\u03c8. Satisfaction of an STL formula \u03d5 for a signal \u03be at time t is formally defined as follows:\n(\u03be, t) |= \u00b5 \u21d4 \u00b5(\u03be(t)) > 0 (\u03be, t) |= \u00ac\u00b5 \u21d4 \u00ac((\u03be, t) |= \u00b5) (\u03be, t) |= \u03d5 \u2227 \u03c8 \u21d4 (\u03be, t) |= \u03d5 \u2227 (\u03be, t) |= \u03c8 (\u03be, t) |= \u03d5 \u2228 \u03c8 \u21d4 (\u03be, t) |= \u03d5 \u2228 (\u03be, t) |= \u03c8 (\u03be, t) |= G[a,b]\u03d5 \u21d4 \u2200t\u2032 \u2208 [t+ a, t+ b], (\u03be, t\u2032) |= \u03d5 (\u03be, t) |= F[a,b]\u03d5 \u21d4 \u2203t\u2032 \u2208 [t+ a, t+ b], (\u03be, t\u2032) |= \u03d5 (\u03be, t) |= \u03d5 U[a,b] \u03c8 \u21d4 \u2203t\u2032 \u2208 [t+ a, t+ b] s.t. (\u03be, t\u2032) |= \u03c8\n\u2227\u2200t\u2032\u2032 \u2208 [t, t\u2032], (\u03be, t\u2032\u2032) |= \u03d5. (5)\nAn STL formula \u03d5 is bounded-time if it contains no unbounded operators. The bound of a formula is defined as the maximum over the sum of all nested upperbounds on the STL formulae.\nSynthesizing controllers that satisfy STL properties is a non-trivial task. Most promising approaches are based on Receding Horizon Control or Model Predictive Control (MPC) [31] that aim to iteratively optimize a cost function J(\u03beH) of interest. Specifically, starting with an initial state x0, the MPC scheme aims to determine the optimal control strategy uH given the dynamics model of the system as in equation (2), while satisfying the STL formula \u03d5. The constraints represented using STL allow expression of temporal specifications on the runs of the system and environment and limit the allowed behavior of the closed loop system [35, 34].\nPrior work shows that MPC optimization with STL constraints \u03d5 can be posed as a Mixed Integer Linear Program (MILP) [34, 17]. It is well-known that the global optimality of this approach is not guaranteed; nonetheless, MPC is fairly used in practice, and has shown to perform well."}, {"heading": "3.3 Bayesian Methods to Model Uncertainty", "text": "Probability theory provides a natural way to represent uncertainty in the environment and recent advances in Machine Learning and Perception have heavily relied on Bayesian methods to infer distributions over latent phenomenon of interest [14, 20]. The two key ingredients include (a) Bayesian networks (equivalently graphical models) that allow expression of complex interactions between sets of latent variables and (b) the Bayesian inference procedure that numerically computes probability distributions over the variables of interest. One of the key distinguishing aspects of the Bayesian methodology is that, unlike other optimization based machine learning methods, the entire distributions over the variables of interest are available. Such distributions com-\npletely characterize the uncertainty present in the system and are crucial for our goal of synthesizing safe controllers.\nWhile a thorough discussion of Bayesian networks and associated methods to model uncertainty is beyond the scope of this paper, we highlight these methods on the task of inferring classifiers from observed training data. Formally, given a set of training data points XL = {x1, . . . ,xn}, with observations tL = {t1, . . . , tn}, where ti \u2208 {+1,\u22121}, we are interested in finding a hyperplane w that separates the points belonging to the two classes according to sgn(wTx). Under the Bayesian paradigm, we are interested in the distribution:\np(w|XL, tL) = p(w) \u00b7 p(tL|XL,w) = p(w) \u220f i p(ti|w,xi)\n= p(w) \u220f i I [sgn(wTxi) = ti].\n(6)\nThe first line in the above equation stems from the Bayes rule, and the second line simply exploits the fact that given the classifier w the labels for each of the points in the data set are independent. The expression I[\u00b7] in the third line is an indicator function which evaluates to 1 when the condition inside the brackets holds. Thus, equation (6) starts from a prior p(w) over the classifiers and eventually by incorporating the training data points, infers a posterior distribution over the set of all the classifiers that respect the observed labels and the points. While the above equation expresses the statistical dependencies among the various variables (i. e., the model), there are various Bayesian inference techniques [28, 4, 2] that would allow numerical computation of the posterior distribution p(w|XL, tL) of interest. In the above case of Bayesian classifier, the popular method of choice is to use Expectation Propagation [28] to infer p(w|XL, tL) as a Gaussian distribution N(w; w\u0304,\u03a3). Linear application of this classifier to a data point as wTx results in a Gaussian distribution of the prediction with the mean wTx and the variance xT\u03a3x. Similarly, for the case of Bayesian linear regression the same procedure can be followed, albeit with continuous target variables t \u2208 R.\nNote that these Bayesian linear classifiers and regressors are a fairly rich class of models and have similar or better representation capabilities as kernel machines [42]. In this work, we specifically aim to incorporate such rich family of classification models in safe controller synthesis."}, {"heading": "4. PROBLEM STATEMENT", "text": "We propose Probabilistic Signal Temporal Logic (PrSTL) that allows us to express uncertainty over the latent variables via probabilistic specifications. The key idea in our work is to first incorporate random variables in predicates, and then express temporal and Boolean operations on such predicates. The proposed logic provides an expressive framework for defining safety conditions under a wide variety of uncertainties, including the uncertainty that arises due to application of Machine Learning classifiers.\nThe core ingredient in this work is the insight that when the uncertainty over the random variable is reasoned out in a Bayesian framework, we can use the inferred probability distributions to efficiently derive constraints from the PrSTL specifications. We provide a novel solution for synthesizing controllers for dynamical systems given different\nPrSTL properties. An interesting aspect of this framework is that the PrSTL formulae can evolve at every step. For example, a classifier associated with the dynamical system can continue to learn with time, thereby changing the inferred probability distributions on the latent random variables."}, {"heading": "4.1 Probabilistic Signal Temporal Logic", "text": "PrSTL supports probabilistic temporal properties on realvalued, dense-time signals. Specifically, (\u03be, t) |= \u03d5 denotes that the signal \u03be satisfies the PrSTL formula \u03d5 at time t. We introduce the notion of a probabilistic atomic predicate \u03bb\u03b1t(\u03be(t)) of a PrSTL formula that is parameterized with a time-varying random variable \u03b1t drawn from a distribution p(\u03b1t) at every time step:\n(\u03be, t) |= \u03bb t\u03b1t \u21d0\u21d2 P (\u03bb\u03b1t(\u03be(t)) < 0) > 1\u2212 t. (7)\nHere P (\u00b7) represents the probability of the event and 1\u2212 t defines the tolerance level in satisfaction of the probabilistic properties. The parameter t \u2208 [0, 1] is a small time-varying positive number and represents the threshold on satisfaction probability of \u03bb\u03b1t(\u03be(t)) < 0. A signal \u03be(t) satisfies the PrSTL predicate \u03bb\u03b1t with confidence 1\u2212 t if and only if:\u222b\n\u03b1t\nI[\u03bb\u03b1t(\u03be(t)) < 0] p(\u03b1t) d\u03b1t > 1\u2212 t. (8)\nHere I[\u00b7] is an indicator function, and the equation marginalizes out the random variable \u03b1t with the probability density p(\u03b1t). The truth value of the PrSTL predicate \u03bb\nt \u03b1t thus is\nequivalent to satisfaction of the probabilistic constraint in equation (7). We would like to point out that computing such integrals for general distributions is computationally difficult; however, there are many parameterized distributions (e.g., Gaussian and other members of the exponential family) for which there exists either a closed form solution or efficient numerical procedures.\nNote that this probabilistic atomic predicate \u03bb\u03b1t(\u03be(t)) is a stochastic function of the signal \u03be at time t and expresses a model of the uncertainty in environment based on the observed signals. As the system evolves and observes more data about the environment, the distribution over the random variable \u03b1t changes over time, thereby leading to an adaptive PrSTL predicate. The PrSTL formula consists of Boolean and temporal operations over their predicates. We formulate PrSTL in negation normal form, and recursively define the syntax of the logic as:\n\u03d5 ::= \u03bb t\u03b1t | \u00ac\u0303\u03bb t \u03b1t | \u03d5 \u2227 \u03c8 |G[a,b]\u03c8 | \u03d5U[a,b]\u03c8. (9)\nHere, \u03d5 is a PrSTL formula, which is built upon predicates \u03bb t\u03b1t defined in equation (7), propositional formulae \u03d5 composed of the predicates and Boolean operators such as \u2227 (and), \u00ac\u0303 (negation), and temporal operators on \u03d5 such as G (globally), F (eventually) and U (until). Note, that in these operations the PrSTL predicates can have different probabilistic parameters, i. e., \u03b1t and t. In addition, satisfaction of the PrSTL formulae for each of the Boolean and temporal operations based on the predicates is defined as:\n(\u03be, t) |= \u03bb t\u03b1t \u21d4 P (\u03bb\u03b1t (\u03be(t)) < 0) > 1\u2212 t (\u03be, t) |= \u00ac\u0303\u03bb t\u03b1t \u21d4 (\u03be, t) |= \u2212\u03bb t \u03b1t (\u03be, t) |= \u03d5 \u2227 \u03c8 \u21d4 (\u03be, t) |= \u03d5 \u2227 (\u03be, t) |= \u03c8 (\u03be, t) |= \u03d5 \u2228 \u03c8 \u21d4 (\u03be, t) |= \u03d5 \u2228 (\u03be, t) |= \u03c8 (\u03be, t) |= G[a,b]\u03d5 \u21d4 \u2200t\u2032 \u2208 [t+ a, t+ b], (\u03be, t\u2032) |= \u03d5 (\u03be, t) |= F[a,b]\u03d5 \u21d4 \u2203t\u2032 \u2208 [t+ a, t+ b], (\u03be, t\u2032) |= \u03d5 (\u03be, t) |= \u03d5 U[a,b] \u03c8 \u21d4 \u2203t\u2032 \u2208 [t+ a, t+ b] s.t. (\u03be, t\u2032) |= \u03c8\n\u2227\u2200t\u2032\u2032 \u2208 [t, t\u2032], (\u03be, t\u2032\u2032) |= \u03d5. (10)\nRemark 1. Note that \u00ac\u0303 (negation) defined above, does not follow the traditional logical complement properties, i. e., a formula and its negation can both be satisfied or violated by our definition of negation. Satisfaction of a complement of a PrSTL formula is equivalent to negating the formula\u2019s function \u2212\u03bb t\u03b1t .\nRemark 2. The PrSTL framework reduces to STL, when the distribution p(\u03b1t) is a Dirac distribution. A Dirac or a point distribution over \u03b1t enforces \u03bb\u03b1t(\u03be(t)) < 0 to be deterministic and equivalent to an STL predicate \u00b5 defined in Section 3.2."}, {"heading": "4.2 Controller Synthesis for Probabilistic Signal Temporal Logic", "text": "We now formally define the controller synthesis problem in the MPC framework with PrSTL specifications.\nProblem 1. Given a hybrid dynamical system as in equation (2), an initial state x0, a PrSTL formula \u03d5, an MPC horizon H, and a cost function J(\u03beH) defined for a finite horizon trajectory \u03beH find:\nargmin uH\nJ(\u03beH(x0,u H))\nsubject to \u03beH(x0,u H) |= \u03d5.\n(11)\nProblem (1) formulates a framework for finding a control strategy uH that optimizes a given cost function, and satisfies a PrSTL formula. Finding the best strategy for this optimization given only deterministic PrSTL formulae, where \u03b1t is drawn from a Dirac distribution is the same as solving a set of mixed integer linear constraints. In this section, we show how the optimization can be solved for the general case of PrSTL by translating the formula to a set of mixed integer constraints. Specifically, we provide full solution for the Gaussian distributions in Problem 1, where the optimization reduces to mixed integer semi-definite programs.\n4.2.1 Mixed Integer Constraints We first discuss how every PrSTL formula generates a set\nof integer constraints. Given a PrSTL formula, we introduce two integer variables for every time step t, p\u03d5t and q\u03d5t \u2208 {0, 1}, which correspond to the truth value of the PrSTL formula and its negation respectively. These variables enforce satisfaction of the PrSTL formula \u03d5 as follows:\np\u03d5t = 1 =\u21d2 (\u03be, t) |= \u03d5 q\u03d5t = 1 =\u21d2 (\u03be, t) |= \u00ac\u0303\u03d5\n(12)\nThe formula \u03d5 holds true if p\u03d5t = 1, and its negation \u00ac\u0303\u03d5 (defined in Section 4.1) holds true if q\u03d5t = 1. Due to our definition of negation for probabilistic formulae, there exist signals for which p\u03d5t , and q \u03d5 t can both be set to 1, where both \u03d5, and \u00ac\u0303\u03d5 are satisfied by the signal. This explains the construction of two integer variables for every formula. Using both integer variables, we define the constraints required for logical and temporal operations of PrSTL on p\u03d5t and q \u03d5 t for all times. These integer variables enforce the truth value of the formula \u03d5, and we refer to them as truth value enforcers:\n\u2022 Negation (\u03d5 = \u00ac\u0303\u03c8) : p\u03d5t \u2264 q \u03c8 t and q \u03d5 t \u2264 p \u03c8 t\n\u2022 Conjunction (\u03d5 = \u2227Ni=1\u03c8i) : p\u03d5t \u2264 p \u03c8i t and q\u03d5t \u2264 \u2211N i=1 q \u03c8i t\n\u2022 Disjunction (\u03d5 = \u2228Ni=1\u03c8i) : \u03d5 = \u00ac\u0303 \u2227Ni=1 \u00ac\u0303\u03c8i\n\u2022 Globally (\u03d5 = G[a,b]\u03c8) :\np\u03d5t \u2264 p \u03c8 t\u2032 \u2200t \u2032 \u2208 [t+ a, min(t+ b,H\u22121)], q\u03d5t \u2264 \u2211t+b t\u2032=t+a q \u03c8 t\u2032 (Only for t < H \u2212 b).\n\u2022 Eventually (\u03d5 = F[a,b]\u03c8) : \u03d5 = \u00ac\u0303G[a,b]\u00ac\u0303\u03c8.\n\u2022 Unbounded Until (\u03d5 = \u03c81 U\u0303[0,\u221e)\u03c82) :\u2228H\u22121 t=0 ( (G[0,t]\u03c81) \u2227 (G[t,t]\u03c82) ) \u2228G[0,H\u22121]\u03c81\n\u2022 Bounded Until (\u03d5 = \u03c81 U[a,b]\u03c82) : \u03d5 = G[0,a]\u03c81 \u2227 F[a,b]\u03c82 \u2227G[a,a](\u03c81U\u0303[0,\u221e)\u03c82)\nHere, we have shown how p\u03d5t and q \u03d5 t are defined for every logical property such as negation, conjunction, and disjunction, and every temporal property such as globally, eventually, and until. We use U\u0303 to refer to unbounded until, and U for bounded until.\nNote that while synthesizing controllers for PrSTL formulae in an MPC scheme, we sometimes are required to evaluate satisfaction of the formula outside of the horizon range H. For instance, a property G[a,b]\u03d5 might need to be evaluated beyond H for some t\u2032 \u2208 [t+a, t+b]. In such cases, our proposal is to act optimistically, which means that we assume the formula holds true for the time steps outside of the horizon of globally operator, and similarly assume the formula does not hold true for the negation of the globally operator. This optimism is evident in formulating the truth value enforcers of the globally operator above, and based on that, it is specified for other temporal properties.\nBased on the recursive definition of PrSTL, and the above encoding, the truth value enforcers of every PrSTL formula is defined using a set of integer inequalities involving a composition of the truth value enforcers of the inner predicates.\n4.2.2 Satisfaction of PrSTL predicates We have defined the PrSTL predicate \u03bb t\u03b1t for a general\nfunction, \u03bb\u03b1t(\u03be(t)) of the signal \u03be at time t. In general, the function allows a random variable \u03b1t \u223c p(\u03b1t) drawn from any distribution at every time step. The general problem of controller synthesis that would satisfy the PrSTL predicates is computationally difficult due to the fact that evaluation of the predicates boils down to computing an integration depicted in equation (8). Consequently, in order to solve the control problem in equation (11) we need to enforce a structure on the predicates of \u03d5. In this section, we explore the linear-Gaussian structure of the predicates that appear in many of the real-world cases and show how they translate into Mixed Integer SDPs.\nFormally, if \u03d5 = \u03bb t\u03b1t is only a single predicate, the optimization in equation (11) will reduce to:\nargmin uH\nJ(\u03beH(x0,u H))\nsubject to (\u03be, t) |= \u03bb t\u03b1t \u2200t \u2208 {0, . . . , H\u22121}. (13)\nThis optimization translates to a chance constrained problem [5, 7, 39, 40, 24, 6] at every time step of the horizon,\nbased on the definition of PrSTL predicates in equation (7):\nargmin uH\nJ(\u03beH(x0,u H))\nsubject to P (\u03bb\u03b1t(\u03be(t)) < 0) > 1\u2212 t \u2200t \u2208 {0, . . . , H\u22121}.\n(14)\nOne of the big challenges with such chance constrained optimization is there are no guarantees that the above optimization in equation (14) is convex. The convexity of the problem depends on the structure of the function \u03bb\u03b1t , and the distribution p(\u03b1t).\nIt turns out that the problem takes a particularly simple convex form when the function \u03bb\u03b1t takes a linear-Gaussian form, i. e., the random variable \u03b1t comes from a Gaussian distribution and the function itself is linear in \u03b1t:\n\u03bb\u03b1t(\u03be(t)) = \u03b1t >\u03bex(t) = \u03b1t >xt, \u03b1t \u223c N (\u00b5t,\u03a3t). (15)\nIt is easy to show that for this structure of \u03bb\u03b1t , where \u03bb\u03b1t is a weighted sum of the states with Gaussian weights \u03b1t, the chance constrained optimization in equation (14) is convex [38, 21]. Specifically, the optimization problem can be transformed to a second-order cone program (SOCP). To see this, we consider normally distributed random variable \u03bd \u223c N (0, 1), its cumulative distribution function (CDF) \u03a6:\n\u03a6(z) = \u222b z \u2212\u221e 1\u221a 2\u03c0 e \u2212t2 2 dt. (16)\nThen, the chance constrained optimization reduces to SOCP via the following derivation:\nP (\u03bb\u03b1t(\u03be(t)) < 0) > 1\u2212 t \u21d0\u21d2 P (\u03b1>t xt < 0) > 1\u2212 t\n\u21d0\u21d2 P (\u03bd < \u2212\u00b5 > t xt\nx>t \u03a3txt ) > 1\u2212 t\n\u21d0\u21d2 \u222b \u2212\u00b5>t xt x>t \u03a3txt\n\u2212\u221e\n1\u221a 2\u03c0 e \u2212t2 2 dt > 1\u2212 t\n\u21d0\u21d2 \u03a6( \u00b5 > t xt\nx>t \u03a3txt ) < t\n\u21d0\u21d2 \u00b5>t xt \u2212 \u03a6\u22121( t)||\u03a3 1/2 t xt||2 < 0\n(17)\nIn this formulation, \u00b5>t xt is the linear term, where \u00b5t is the mean of the random variable \u03b1t at every time step, and ||\u03a31/2t xt||2 is the l2-norm representing a quadratic term, where \u03a3t is the variance of \u03b1t. This quadratic term is scaled by \u03a6\u22121( t), the inverse of the Normal CDF function, which is negative for small values of t \u2264 0.5. Thus, every chance constraint can be reformulated as a SOCP, and as a result with a convex cost function J(\u03beH), we can efficiently solve the following convex optimization for every predicate of PrSTL:\nminimize uH\nJ(\u03beH(x0,u H))\nsubject to \u00b5>t xt \u2212 \u03a6\u22121( t)||\u03a3 1/2 t xt||2 < 0\n\u2200t \u2208 {0, . . . , H \u2212 1}.\n(18)\nAssuming the a linear-Gaussian form of the function, we generate the SOCP above and easily translate it to a semidefinite program (SDP) by introducing auxiliary variables [7]. We can use this semi-definite program that solves the problem in equation (13) with a single constraint \u03d5 = \u03bb t\u03b1t as a building block, and use it multiple times to handle complex\nPrSTL formulae. Specifically, any PrSTL formula can be decomposed to its predicates by recursively introducing integer variables that correspond to the truth value enforcers of the formula at every step as discussed in Section 4.2.1.\nWe would like to point out that assuming linear-Gaussian form of the function \u03bb\u03b1t is not too restrictive. The linearGaussian form subsumes the case of Bayesian linear classifiers, and consequently the framework can be applied to a wide variety of scenarios where a classification or regression function needs to estimate quantities of interest that are critical for safety. Furthermore, the framework is applicable to all random variables whose distributions exhibit unimodal behavior and aligned with the large law of numbers. Finally, for the cases of non-Gaussian random variables, there are many approximate inference procedures that can approximate the distributions as Gaussian distributions effectively.\n4.2.3 Convex Subset of PrSTL As discussed in the previous section 4.2.2, at the pred-\nicate level of \u03d5, we create a chance constrained problem for predicates \u03bb t\u03b1t . These predicates of the PrSTL formulae can be reformulated as a semi-definite program, where the predicates are over intersections of cone of positive definite matrices with affine spaces. Semi-definite programs are special cases of convex optimization; consequently, solving Problem 1, only for PrSTL predicates is a convex optimization problem. Note that in Section 4.2.1 we introduced integer variables for temporal and Boolean operators of the PrSTL formula. Construction of such integer variables increases the complexity of Problem 1, and results in a mixed integer semi-definite program (MISDP). However, we are not always required to create integer variables for all temporal and Boolean operators. Therefore, we define Convex PrSTL as a subset of PrSTL formulae that can be solved without constructing integer variables.\nDefinition 1. Convex PrSTL is a subset of PrSTL such that it is recursively defined over the predicates by applying Boolean conjunctions, and the globally temporal operator. Satisfaction of a convex PrSTL formulae is defined as:\n(\u03be, t) |= \u03bb t\u03b1t \u21d4 P (\u03bb\u03b1t(\u03be(t)) < 0) > 1\u2212 t (\u03be, t) |= \u03d5 \u2227 \u03c8 \u21d4 (\u03be, t) |= \u03d5 \u2227 (\u03be, t) |= \u03c8 (\u03be, t) |= G[a,b]\u03d5 \u21d4 \u2200t\u2032 \u2208 [t+ a, t+ b], (\u03be, t\u2032) |= \u03d5 (19)\nTheorem 1. Given a convex PrSTL formula \u03d5, a hybrid dynamical system as in equation (2), and its initial state x0. The controller synthesis problem with convex PrSTL constraints \u03d5 defined in Problem 1 is a convex program.\nProof. We have shown that the predicates of \u03d5, i. e., \u03bb t\u03b1t create a set of convex constraints. The Boolean conjunction of convex programs are also convex; therefore, \u03d5 \u2227 \u03c8 result in convex constraints. In addition, the globally operator is defined as a set of finite conjunctions over its time interval: G[a,b]\u03d5 = \u2227b t=a \u03d5t. Thus, the globally operator retains the convexity property of the constraints. Consequently, Problem 1, with a convex PrSTL constraint \u03d5 is a convex program.\nTheorem 1 allows us to efficiently reduce the number of integer variables required for solving Problem 1. We only introduce integer variables when disjunctions, eventually, or until operators appear in the PrSTL constraints. Even when a\nAlgorithm 1 Controller Synthesis with PrSTL Formulae\n1: procedure Prob. Synthesis(f, x0, H, \u03c4, J, \u03d5)\n2: Let \u03c4 = [t1, t2] is the time interval of interest. 3: past \u2190 Initialize(t1) 4: for t = t1: dt: t2 5: flin = linearize(f, \u03be(t)) 6: \u03b1t \u2190 Update Distributions(\u03b1t\u2212dt, sense(\u03bex(t)) 7: \u03d5\u2190 \u03d5(\u03b1t, t) 8: CPrSTL = MISDP(\u03d5)\n9: C = CPrSTL \u2227 flin \u2227 [ \u03be(t1 \u00b7 \u00b7 \u00b7 t\u2212 dt) = past ] 10: uH = optimize ( J(\u03beH), C ) 11: xt+1 = f(xt, ut) 12: past \u2190 [past \u03be(t)] 13: end for\n14: end procedure\nformula is not completely part of the Convex PrSTL, integer variables are introduced only for the non-convex segments.\nWe show our complete method of controlling dynamical systems in uncertain environments in Algorithm 1. At the first time step t1, we run an open-loop control algorithm to populate past in line 3. We then run the closed-loop algorithm, finding the optimal strategy at every time step of the time interval \u03c4 = [t1, t2]. In the closed-loop algorithm, we linearize the dynamics at the current local state and time in line 5, and then update the distributions over the random variables in the PrSTL formula based on new sensor data in line 6. Then, we update the PrSTL formulae, based on the updated distributions. If there are any other dynamic parameters that change at every time step, they can also be updated in line 7. In line 8, we generate the mixed integer constraints in CPrSTL, and then populate C with all the constraints including the PrSTL constraints, linearized dynamics, and enforcing the past trajectory. Note that we do not construct integer variables if the formula is in the subset of Convex PrSTL. Then, we call the finite horizon optimization algorithm under the cost function J(\u03beH), and the constraints C in line 10, which provides a length H strategy uH . We advance the state with the first element of uH , and update the history of the trajectory in past. We continue running this loop and synthesizing controllers over all time steps in interval \u03c4 ."}, {"heading": "5. EXPERIMENTAL RESULTS", "text": "We implemented our controller synthesis algorithm for PrSTL formulae as a Matlab toolbox, available at: https://www.eecs.berkeley.edu/\u223cdsadigh/PrSTL. Our toolbox uses Yalmip [26] and Gurobi [18] as its optimization engine. For all the examples we tried, the optimization computed at every step completed in less than 2 seconds on a 2.3 GHz Intel Core i7 processor with 16 GB memory. We show some of our results for controlling quadrotors and autonomous driving under uncertain environments."}, {"heading": "5.1 Quadrotor Control", "text": "Controlling quadrotors in dynamic uncertain environments is a challenging task. Different sources of uncertainty appear while controlling quadrotors, e. g., uncertainty about the position of the obstacles based on classification methods, dis-\ntributions over wind profiles or battery profiles, etc. In this case study, we show how to express properties of different models of uncertainty over time, and we find an optimal strategy under such uncertain environments.\nWe follow the derivation of the dynamics model of a quadrotor in [19]. We consider a 12 dimensional system, where the state consists of the position and velocity of the quadrotor x, y, z and x\u0307, y\u0307, z\u0307, as well as the Euler angles \u03c6, \u03b8, \u03c8, i. e., roll, pitch, yaw, and the angular velocities p, q, r. Let x be:\nx = [x y z x\u0307 y\u0307 z\u0307 \u03c6 \u03b8 \u03c8 p q r]>. (20)\nThe system has a 4 dimensional control input: u = [ u1 u2 u3 u4 ]> , (21)\nwhere u1, u2 and u3 are the control inputs about each axis for roll, pitch and yaw respectively. u4 represents the thrust input to the quadrotor in the vertical direction (z-axis). The nonlinear dynamics of the system is:\nf1(x, y, z) = [ x\u0307 y\u0307 z\u0307 ]> f2(x\u0307, y\u0307, z\u0307) = [ 0 0 g ]> \u2212 R1(x\u0307, y\u0307, z\u0307) [0 0 0 u4]> m\nf3(\u03c6, \u03b8, \u03c8) = R2(x\u0307, y\u0307, z\u0307) [ \u03c6\u0307 \u03b8\u0307 \u03c8\u0307 ]> f4(p, q, r) = I\n\u22121 [u1 u2 u3]> \u2212R3(p, q, r)I [p q r]> , (22)\nwhere R1 and R2 are rotation matrices, relating body frame and inertial frame of the quadrotor, R3 is a skew-symmetric matrix, and I is the inertial matrix of the rigid body. Also g and m denote gravity and mass of the quadrotor. Then the dynamics equation is:\nf(x,u) = [ f1 f2 f3 f4 ]> . (23)\n.\n5.1.1 Control in an Uncertain Environments Our first goal is for a quadrotor to reach a point in the\nspace while avoiding obstacles. This is shown in Figure 1, where the quadrotor is shown by a green square at its starting position, the origin (0, 0, 0), and its objective is to reach the coordinates (1, 1, 0) smoothly. If we let z = 0 represent the ground level, the objective of the quadrotor is to take off and travel a distance, and then land on the ground again.\nNote that we use the convention, where z < 0 is above the ground level. We optimize the following objective:\nJ(\u03beH) = H\u22121\u2211 t=0 ||(xt, yt, zt)\u2212 (1, 1, 0)||22 + c||(\u03c6t, \u03b8t, \u03c8t)||22.\n(24) Here, we penalize the l2-norm of the Euler angles by a factor of c, since we look for a smooth trajectory. We chose c = 2 in our examples. In addition to initializing the state and control input at zero, we need to satisfy the following deterministic PrSTL formulae:\n\u03d5roll = G[0,\u221e)(||u1|| \u2264 0.3) Bounds on Roll Input \u03d5pitch = G[0,\u221e)(||u2|| \u2264 0.3) Bounds on Pitch Input \u03d5thrust = G[0,\u221e)(||u4|| \u2264 0.3) Bounds on Thrust\n(25) In Figure 1, the purple surface is a ceiling that the quadrotor should not collide with as it is taking off and landing at the final position. However, the quadrotor does not have a full knowledge of where the ceiling is exactly located. We define a sensing mechanism for the quadrotor, which consists of a meshgrid of points around the body of the quadrotor. As the system moves in the space, a Bayesian binary classifier is updated by providing a single label\u22121 (no obstacles present) or 1 (obstacle present) for each of the sensed points.\nThe Bayesian classifier is the same as the Gaussian Process based method as described in Section 3.3 and has the linear-Gaussian form. Applying this classifier results in a Gaussian distribution for every point in the 3D-space. We define our classifier with confidence 1 \u2212 t = 0.95, as the stochastic function \u03bb0.05\u03b1t (\u03be(t)) = \u03b1 > t [xt yt zt], where xt,yt, and zt define the coordinates of the sensing points in the space, and \u03b1t \u223c N (\u00b5t,\u03a3t) is the Gaussian weight inferred over time using the sensed data. So, we define a time-varying probabilistic constraint that needs to be held at every time step as its value changes over time. Our constraint specifies that given a classifier based on the sensing points parameterized by \u03b1t, we would enforce the quadrotor to stay within a safe region (defined by the classifier) with probability 1\u2212 t, for t = 0.05 at all times. Thus the probabilistic formula is:\n\u03d5classifier = G[0.1,\u221e)(\u03bb 0.05 \u03b1t ) which is equivalent to: \u03d5classifier = G[0.1,\u221e) ( P (\u03b1>t [xt yt zt] < 0) > 0.95 ) (26) We enforce this probabilistic predicate at all times in t \u2208 [0.1,\u221e), which verifies the property starting from a small time after the initial state, so the quadrotor has gathered some sensor data. In Figure 1, the orange surface, represents the second order cone created based on \u03d5classifier, at every time step. This surface is characterized by:\n\u00b5>t [ xt yt zt ] \u2212\u03a6\u22121(0.05)||\u03a31/2t [ xt yt zt ] ||2 < 0 (27)\nNote that the surface shown in Figure 1, at the initial time step is not an accurate estimate of where the ceiling is, and it is based on a distribution learned from the initial values of the sensors. Thus, if the quadrotor was supposed to follow this estimate without updating, it would collide with the ceiling, since the orange surface showing the belief of the location of the ceiling is above the purple surface representing the real position of the ceiling. However, the Bayesian inference running at every step of the optimization, updates the distribution over the classifier. As shown in Figure 2, the\norange surfaces changes at every time step, since the parameters of the learned random variable \u03b1t, which are \u00b5t, and \u03a3t are updated at every step. In Figure 2, the blue path represents the trajectory the quadrotor has already taken, and the dotted green line represents the future planned trajectory based on the current state of the classifier. The dotted green trajectory at the initial state goes through the ceiling, since the belief of the location of the ceiling is incorrect; however, the trajectory is modified at every step as the classifier values are updated, and the quadrotor safely reaches the final position. We solve the optimization using our toolbox, with dt = 0.03, and horizon length of H = 20. We emphasize that some of the constraints are time-varying, and we need to update them at every step of the optimization. We similarly update the dynamics at every time step, since we locally linearize the dynamics around the current position of the quadrotor at every step.\n5.1.2 Control under Battery Constraints We consider another scenario for controlling quadrotors,\nwhere we add a battery state to the state space of the system discussed above. So the quadrotor will be a 13 dimensional system, where the first 12 states follow the same order and dynamics of equations (20) and (21). We let xt(13) = bt denote the battery state, and we initialize it at b0 = 10. The state of bt evolves with the negative thrust value:\nf5(b) = \u2212|u4|. (28)\nSo the dynamics is f = [f1 f2 f3 f4 f5] >, and all the other states and inputs are initialized at zero. We enforce the same constraints as in equation (25), and the objective of the quadrotor is to reach the coordinates (1, 1,\u22120.9) smoothly, which corresponds to flying from the origin to the top diag-\nonal corner of the space. Furthermore, we impose that the quadrotor can fly above a specific height only if it is confident in its battery power. The formula F[0,0.3](zt \u2264 \u22120.1) encodes that eventually in the next 0.3 s, the quadrotor will fly above a threshold level of \u22120.1. Therefore, the truth of this formula should imply that the system is confident in the battery level, and consequently can make it to the goal position safely. However, we assume we don\u2019t have access to the exact value of battery state due to uncertain environment factors that can affect the battery level such as radio communication, etc. We use a stochastic linear classifier\n\u03bb\u03b1t( [ bt 1 ]> ) on a battery state augmented with value 1, to estimate the belief on the battery level. We allow the battery state to vary with a variance \u03c32 scaled at every time step of the horizon. So the formula ensuring that the quadrotor flies above a threshold only if its battery level is high enough is:\n\u03d5battery = G[0,\u221e) ( F[0,0.3](zt \u2264 \u22120.1)\u2192 \u03c8) ) ,\nwhere \u03c8 = G[0,\u221e) ( P (\u03b1>t [ bt 1 ] < 0) \u2265 1\u2212 t ) \u03b1t \u223c N ( [ \u22121 bmin ] , [ 0 0 0 t\u03c32 ] ), and t = 0.2.\n(29)\nWe let the confidence 1 \u2212 t = 0.8. The property \u03c8 can be reformulated as:\n\u03c8 = G[0,\u221e) ( P (bt +N (0, t\u03c32) \u2265 bmin) \u2265 0.8 ) (30)\nHere \u03bd \u223c N (0, 1), and t ranges over the horizon time steps. So, \u03c8 illustrates that the quadrotor has to be confident that its battery state perturbed by a time-varying variance is above bmin at all times. Therefore, \u03d5battery specifies that if the battery state is below some threshold, the quadrotor has to fly close to the ground. We synthesize a controller for the specifications, and the trajectory of the quadrotor is shown in Figure 3. The trajectory in Figure 3a corresponds to when \u03c3 = 0, i. e., the battery state changes deterministically, and Figure 3b, corresponds to \u03c3 = 10, when the quadrotor is more cautious about the state of the battery. So the trajectory does not pass the \u22120.1 height level whenever the confidence in the battery level is below 0.8."}, {"heading": "5.2 Autonomous Driving", "text": "In our second case study, we consider an autonomous driving scenario. We use a simple point-mass model to define the dynamics of the vehicles on the road. We let the state of the system be x = [x y \u03b8 v]>, where x, y denote the co-\nordinates of the vehicle, \u03b8 is the heading, and v is the speed. We let u = [u1 u2]\n> be the control inputs, where u1 is the steering input, and u2 is the acceleration. Further, we write the dynamics of the vehicle as:\nx\u0307 = v cos(\u03b8)\ny\u0307 = v sin(\u03b8)\n\u03b8\u0307 = v\nm u1\nv\u0307 = u2\n(31)\nFigure 4, shows a scenario for an autonomous vehicle making a right turn at a signalized intersection. We refer to the red car as the ego vehicle, i. e., the vehicle we control autonomously, and the yellow car as the environment vehicle. We would like to find a strategy for the ego vehicle, so it makes a safe right turn when the traffic light is red, while yielding to the oncoming traffic. The yellow car in the figure represents the oncoming traffic at this intersection. In this example, the ego vehicle only has a probabilistic model of the velocity of the environment car. All vehicles in this example follow the same dynamics as in equation (31). We refer to the states of the the ego vehicle as: [x y \u03b8 v]>, and the states of the environment vehicle as: [xenv yenv \u03b8env venv]>. While synthesizing a strategy for the red car, we would enforce a set of PrSTL specifications: (i) We enforce bounds on control inputs and states of the two vehicles, (ii) We encode the states and transitions of the traffic light, and enforce the vehicles to obey the traffic rules, (iii) We enforce that all vehicles remain within their road boundaries. In addition, we would like the two cars to avoid any collisions. We define collision avoidance as the following PrSTL property:\n\u03d5crash = G[0,\u221e) ( P ( xt \u2212 (xenvt + st,xt) \u2265 \u03b4 ) \u2265 1\u2212 t\n\u2228 P ( xt \u2212 (xenvt + st,xt) \u2264 \u2212\u03b4 ) \u2265 1\u2212 t\n\u2228 P ( yt \u2212 (yenvt + st,yt) \u2265 \u03b4 ) \u2265 1\u2212 t\n\u2228 P ( yt \u2212 (yenvt + st,yt) \u2264 \u2212\u03b4 ) \u2265 1\u2212 t\n) (32)\n[ st,x st,y ] = N (venvt , \u03c32) [ cos(\u03b8envt ) sin(\u03b8envt ) ] and \u03b4 = 0.4, t = 0.2.\nHere, \u03d5crash consists of a global operator at all times over the disjunction of four PrSTL predicates. Each probabilistic predicate encodes possible crash between the two vehicles. In equation (32), \u03b4 represents the minimum distance between the x and y coordinates of the two vehicles in either direction, which generates the four disjunctions on the predicates. The estimate of the distance between x and y coordinates of the two vehicles is encoded in each predicate, by considering the difference between the coordinates of the ego vehicle, and the propagated coordinates of the environment vehicle based on the value of its velocity. The veloc-\nity is a vector of Gaussian random variables [ st,x st,y ]> computed based on the current heading of the environment vehicle \u03b8envt , centered at the current speed v env t , and perturbed by a variance \u03c32. The predicates in \u03d5crash define a linear classifier on the signal representing the coordinates of the ego vehicle, parameterized by a random variable characterizing the velocity of the environment vehicle. These predicates can easily be reformulated to the nominal structure of a PrSTL predicate \u03bb t\u03b1t . However, we leave them as in equation (32) for better illustration.\nIn the autonomous driving example, we use a sampling time of dt = 0.1 s, and horizon of H = 20. In addition, we let \u03c3 = 0.4. We successfully synthesize a strategy for the autonomous vehicle by solving Problem 1, and following the steps in Algorithm 1. The trajectory generated using this strategy is shown by the solid blue line in Figure 4. The dotted green line is the future trajectory computed by the MPC scheme. In Figure 4a, the ego vehicle has a deterministic model of the environment vehicle as \u03c3 = 0; therefore, it performs the right turn before letting the environment vehicle pass. However, as shown in Figure 4b, given \u03c3 = 0.4, and t = 0.2, the ego vehicle is not confident enough in avoiding collisions, so it acts in a conservative manner and waits for the environment car to pass first, and then performs its right turn safely."}, {"heading": "6. CONCLUSION", "text": "We have presented a framework for safe controller synthesis under uncertainty. The key contributions include defining PrSTL, a logic for expressing probabilistic properties that allows embedding Bayesian graphical models. We also show how to synthesize control in a receding horizon framework under PrSTL specifications that express Bayesian linear classifiers. Another distinguishing aspect of this work is that the resulting logic adapts as more data is observed with the evolution of the system. We demonstrate the effectiveness of the approach by synthesizing safe strategies for a quadrotor and an autonomous vehicle traveling in uncertain environments.\nThe presented approach extends easily to distributions other than Gaussians via Bayesian approximate inference techniques [28, 4] that can project distributions to the Gaussian densities. Future work includes, extending controller synthesis for arbitrary distributions via sampling based approaches; we are also exploring using the proposed framework as a building block for complex robotic tasks that need to invoke higher level planning algorithms."}, {"heading": "7. REFERENCES", "text": "[1] A. K. Akametalu, S. Kaynama, J. F. Fisac, M. N. Zeilinger, J. H. Gillula, and C. J. Tomlin. Reachability-based safe learning with gaussian processes. In 2014 IEEE 53rd Annual Conference on Decision and Control. [2] C. Andrieu, N. De Freitas, A. Doucet, and M. I. Jordan. An introduction to mcmc for machine learning. Machine learning, 50(1-2):5\u201343, 2003. [3] A. Aswani, H. Gonzalez, S. S. Sastry, and C. Tomlin. Provably safe and robust learning-based model predictive control. Automatica, 49(5):1216\u20131226, 2013. [4] M. J. Beal. Variational algorithms for approximate Bayesian inference. University of London, 2003. [5] A. Ben-Tal, L. El Ghaoui, and A. Nemirovski. Robust optimization. Princeton University Press, 2009. [6] L. Blackmore, M. Ono, and B. C. Williams. Chance-constrained optimal path planning with obstacles. IEEE Transactions on Robotics, 27(6):1080\u20131094, 2011. [7] S. Boyd and L. Vandenberghe. Convex optimization. Cambridge university press, 2004. [8] A. Carvalho, Y. Gao, S. Lefevre, and F. Borrelli. Stochastic predictive control of autonomous vehicles in uncertain environments. In 12th International Symposium on Advanced Vehicle Control, 2014. [9] A. Donze\u0301, T. Ferrere, and O. Maler. Efficient robust monitoring for STL. In Computer Aided Verification. Springer, 2013.\n[10] A. Donze\u0301 and O. Maler. Robust Satisfaction of Temporal Logic over Real-Valued Signals. 2010. [11] J. Fu and U. Topcu. Integrating active sensing into reactive synthesis with temporal logic constraints under partial observations. arXiv:1410.0083, 2014. [12] J. Fu and U. Topcu. Probably approximately correct mdp learning and control with temporal logic constraints. arXiv:1404.7073, 2014. [13] J. Fu and U. Topcu. Computational methods for stochastic control with metric interval temporal logic specifications. arXiv:1503.07193, 2015. [14] A. Gelman, J. B. Carlin, H. S. Stern, and D. B. Rubin. Bayesian data analysis, volume 2. Taylor & Francis, 2014. [15] J. H. Gillula and C. J. Tomlin. Guaranteed safe online learning via reachability: tracking a ground target using a quadrotor. In 2012 IEEE International Conference on Robotics and Automation. [16] E. A. Gol, M. Lazar, and C. Belta. Temporal logic model predictive control. Automatica, 56:78\u201385, 2015. [17] I. Griva, S. G. Nash, and A. Sofer. Linear and nonlinear optimization. Siam, 2009. [18] I. Gurobi Optimization. Gurobi optimizer reference manual, 2015. [19] H. Huang, G. M. Hoffmann, S. L. Waslander, and C. J. Tomlin. Aerodynamics and control of autonomous quadrotor helicopters in aggressive maneuvering. In 2009 IEEE International Conference on Robotics and Automation. [20] M. Jordan. Learning in graphical models (adaptive computation and machine learning). 1998. [21] S. Kataoka. A stochastic programming model. Econometrica: Journal of the Econometric Society, 1963. [22] M. V. Kothare, V. Balakrishnan, and M. Morari. Robust constrained model predictive control using linear matrix inequalities. Automatica, 32(10):1361\u20131379, 1996. [23] H. Kress-Gazit, G. E. Fainekos, and G. J. Pappas. Temporal-logic-based reactive mission and motion planning. IEEE Transactions on Robotics, 25(6):1370\u20131381, 2009. [24] D. Lenz, T. Kessler, and A. Knoll. Stochastic model predictive controller with chance constraints for comfortable and safe driving behavior of autonomous vehicles. In\nIntelligent Vehicles Symposium (IV), 2015 IEEE. [25] S. C. Livingston, R. M. Murray, and J. W. Burdick.\nBacktracking temporal logic synthesis for uncertain environments. In 2012 IEEE International Conference on Robotics and Automation.\n[26] J. Lo\u0308fberg. Yalmip: A toolbox for modeling and optimization in matlab. In 2004 IEEE International Symposium on Computer Aided Control Systems Design. [27] O. Maler and D. Nickovic. Monitoring temporal properties of continuous signals. In Formal Techniques, Modelling and Analysis of Timed and Fault-Tolerant Systems. Springer. [28] T. P. Minka. A family of algorithms for approximate Bayesian inference. PhD thesis, Massachusetts Institute of Technology, 2001. [29] I. Mitchell and C. J. Tomlin. Level set methods for computation in hybrid systems. In Hybrid Systems: Computation and Control. Springer. [30] I. M. Mitchell, A. M. Bayen, and C. J. Tomlin. A time-dependent hamilton-jacobi formulation of reachable sets for continuous dynamic games. IEEE Transactions on Automatic Control, 50, 2005. [31] M. Morari, C. Garcia, J. Lee, and D. Prett. Model predictive control. Prentice Hall Englewood Cliffs, NJ, 1993. [32] N. Piterman, A. Pnueli, and Y. Sa\u2032ar. Synthesis of reactive (1) designs. In Verification, Model Checking, and Abstract Interpretation, pages 364\u2013380. Springer, 2006. [33] A. Puggelli, W. Li, A. L. Sangiovanni-Vincentelli, and S. A. Seshia. Polynomial-time verification of pctl properties of mdps with convex uncertainties. In Computer Aided Verification. Springer, 2013. [34] V. Raman, A. Donze\u0301, M. Maasoumy, R. M. Murray, A. Sangiovanni-Vincentelli, S. Seshia, et al. Model predictive control with signal temporal logic specifications. In 2014 IEEE 53rd Annual Conference on Decision and Control. [35] V. Raman, A. Donze\u0301, D. Sadigh, R. M. Murray, and S. A. Seshia. Reactive synthesis from signal temporal logic specifications. In 18th International Conference on Hybrid Systems: Computation and Control, 2015. [36] D. Sadigh, E. S. Kim, S. Coogan, S. S. Sastry, S. Seshia, et al. A learning based approach to control synthesis of markov decision processes for linear temporal logic specifications. In 2014 IEEE 53rd Annual Conference on Decision and Control. [37] M. Svoren\u030cova\u0301, J. Kr\u030cet\u0301\u0131nsky\u0300, M. Chmel\u0301\u0131k, K. Chatterjee,\nI. C\u030cerna\u0301, and C. Belta. Temporal logic control for stochastic linear systems using abstraction refinement of probabilistic games. In 18th International Conference on Hybrid Systems: Computation and Control, 2015.\n[38] C. Van de Panne and W. Popp. Minimum-cost cattle feed under probabilistic protein constraints. Management Science, 9(3):405\u2013430, 1963. [39] M. P. Vitus. Stochastic Control Via Chance Constrained Optimization and its Application to Unmanned Aerial Vehicles. PhD thesis, Stanford University, 2012. [40] M. P. Vitus and C. J. Tomlin. A probabilistic approach to planning and control in autonomous urban driving. In 2013 IEEE 52nd Annual Conference on Decision and Control. [41] Y. Wang, L. Xie, and C. E. de Souza. Robust control of a class of uncertain nonlinear systems. Systems & Control Letters, 19(2):139\u2013149, 1992. [42] C. K. Williams and C. E. Rasmussen. Gaussian processes for machine learning. the MIT Press, 2(3):4, 2006. [43] T. Wongpiromsarn, U. Topcu, and R. M. Murray. Receding horizon control for temporal logic specifications. In 13th ACM international conference on Hybrid systems: computation and control, 2010. [44] K. Zhou and J. C. Doyle. Essentials of robust control, volume 180. Prentice hall Upper Saddle River, NJ, 1998."}], "references": [{"title": "Reachability-based safe learning with gaussian processes", "author": ["A.K. Akametalu", "S. Kaynama", "J.F. Fisac", "M.N. Zeilinger", "J.H. Gillula", "C.J. Tomlin"], "venue": "IEEE 53rd Annual Conference on Decision and Control", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "An introduction to mcmc for machine learning", "author": ["C. Andrieu", "N. De Freitas", "A. Doucet", "M.I. Jordan"], "venue": "Machine learning, 50(1-2):5\u201343", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2003}, {"title": "Provably safe and robust learning-based model predictive control", "author": ["A. Aswani", "H. Gonzalez", "S.S. Sastry", "C. Tomlin"], "venue": "Automatica, 49(5):1216\u20131226", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Variational algorithms for approximate Bayesian inference", "author": ["M.J. Beal"], "venue": "University of London", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2003}, {"title": "Robust optimization", "author": ["A. Ben-Tal", "L. El Ghaoui", "A. Nemirovski"], "venue": "Princeton University Press", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Chance-constrained optimal path planning with obstacles", "author": ["L. Blackmore", "M. Ono", "B.C. Williams"], "venue": "IEEE Transactions on Robotics, 27(6):1080\u20131094", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Convex optimization", "author": ["S. Boyd", "L. Vandenberghe"], "venue": "Cambridge university press", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2004}, {"title": "Stochastic predictive control of autonomous vehicles in uncertain environments", "author": ["A. Carvalho", "Y. Gao", "S. Lefevre", "F. Borrelli"], "venue": "12th International Symposium on Advanced Vehicle Control", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Efficient robust monitoring for STL", "author": ["A. Donz\u00e9", "T. Ferrere", "O. Maler"], "venue": "Computer Aided Verification. Springer", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Robust Satisfaction of Temporal Logic over Real-Valued Signals", "author": ["A. Donz\u00e9", "O. Maler"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "Integrating active sensing into reactive synthesis with temporal logic constraints under partial observations", "author": ["J. Fu", "U. Topcu"], "venue": "arXiv:1410.0083", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Probably approximately correct mdp learning and control with temporal logic constraints", "author": ["J. Fu", "U. Topcu"], "venue": "arXiv:1404.7073", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "Computational methods for stochastic control with metric interval temporal logic specifications", "author": ["J. Fu", "U. Topcu"], "venue": "arXiv:1503.07193", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Bayesian data analysis", "author": ["A. Gelman", "J.B. Carlin", "H.S. Stern", "D.B. Rubin"], "venue": "volume 2. Taylor & Francis", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Guaranteed safe online learning via reachability: tracking a ground target using a quadrotor", "author": ["J.H. Gillula", "C.J. Tomlin"], "venue": "IEEE International Conference on Robotics and Automation", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Temporal logic model predictive control", "author": ["E.A. Gol", "M. Lazar", "C. Belta"], "venue": "Automatica, 56:78\u201385", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Linear and nonlinear optimization", "author": ["I. Griva", "S.G. Nash", "A. Sofer"], "venue": "Siam", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Aerodynamics and control of autonomous quadrotor helicopters in aggressive maneuvering", "author": ["H. Huang", "G.M. Hoffmann", "S.L. Waslander", "C.J. Tomlin"], "venue": "IEEE International Conference on Robotics and Automation", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2009}, {"title": "Learning in graphical models (adaptive computation and machine learning)", "author": ["M. Jordan"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1998}, {"title": "A stochastic programming model", "author": ["S. Kataoka"], "venue": "Econometrica: Journal of the Econometric Society", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1963}, {"title": "Robust constrained model predictive control using linear matrix inequalities", "author": ["M.V. Kothare", "V. Balakrishnan", "M. Morari"], "venue": "Automatica, 32(10):1361\u20131379", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1996}, {"title": "Temporal-logic-based reactive mission and motion planning", "author": ["H. Kress-Gazit", "G.E. Fainekos", "G.J. Pappas"], "venue": "IEEE Transactions on Robotics, 25(6):1370\u20131381", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2009}, {"title": "Stochastic model predictive controller with chance constraints for comfortable and safe driving behavior of autonomous vehicles", "author": ["D. Lenz", "T. Kessler", "A. Knoll"], "venue": "Intelligent Vehicles Symposium (IV),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2015}, {"title": "Backtracking temporal logic synthesis for uncertain environments", "author": ["S.C. Livingston", "R.M. Murray", "J.W. Burdick"], "venue": "IEEE International Conference on Robotics and Automation", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2012}, {"title": "Yalmip: A toolbox for modeling and optimization in matlab", "author": ["J. L\u00f6fberg"], "venue": "IEEE International Symposium on Computer Aided Control Systems Design", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2004}, {"title": "A family of algorithms for approximate Bayesian inference", "author": ["T.P. Minka"], "venue": "PhD thesis, Massachusetts Institute of Technology", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2001}, {"title": "A time-dependent hamilton-jacobi formulation of reachable sets for continuous dynamic games", "author": ["I.M. Mitchell", "A.M. Bayen", "C.J. Tomlin"], "venue": "IEEE Transactions on Automatic Control, 50", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2005}, {"title": "Model predictive control", "author": ["M. Morari", "C. Garcia", "J. Lee", "D. Prett"], "venue": "Prentice Hall Englewood Cliffs, NJ", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1993}, {"title": "and Y", "author": ["N. Piterman", "A. Pnueli"], "venue": " Sa\u2032ar. Synthesis of reactive (1) designs. In Verification, Model Checking, and Abstract Interpretation, pages 364\u2013380. Springer", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2006}, {"title": "Polynomial-time verification of pctl properties of mdps with convex uncertainties", "author": ["A. Puggelli", "W. Li", "A.L. Sangiovanni-Vincentelli", "S.A. Seshia"], "venue": "Computer Aided Verification. Springer", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2013}, {"title": "Model predictive control with signal temporal logic specifications", "author": ["V. Raman", "A. Donz\u00e9", "M. Maasoumy", "R.M. Murray", "A. Sangiovanni-Vincentelli", "S. Seshia"], "venue": "IEEE 53rd Annual Conference on Decision and Control", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2014}, {"title": "Reactive synthesis from signal temporal logic specifications", "author": ["V. Raman", "A. Donz\u00e9", "D. Sadigh", "R.M. Murray", "S.A. Seshia"], "venue": "18th International Conference on Hybrid Systems: Computation and Control", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2015}, {"title": "A learning based approach to control synthesis of markov decision processes for linear temporal logic specifications", "author": ["D. Sadigh", "E.S. Kim", "S. Coogan", "S.S. Sastry", "S. Seshia"], "venue": "IEEE 53rd Annual Conference on Decision and Control", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2014}, {"title": "J", "author": ["M. Svore\u0148ov\u00e1"], "venue": "K\u0159et\u0301\u0131nsk\u1ef3, M. Chme\u013a\u0131k, K. Chatterjee, I. \u010cern\u00e1, and C. Belta. Temporal logic control for stochastic linear systems using abstraction refinement of probabilistic games. In 18th International Conference on Hybrid Systems: Computation and Control", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2015}, {"title": "Minimum-cost cattle feed under probabilistic protein", "author": ["C. Van de Panne", "W. Popp"], "venue": "constraints. Management Science,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 1963}, {"title": "Stochastic Control Via Chance Constrained Optimization and its Application to Unmanned Aerial Vehicles", "author": ["M.P. Vitus"], "venue": "PhD thesis, Stanford University", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2012}, {"title": "A probabilistic approach to planning and control in autonomous urban driving", "author": ["M.P. Vitus", "C.J. Tomlin"], "venue": "IEEE 52nd Annual Conference on Decision and Control", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2013}, {"title": "and C", "author": ["Y. Wang", "L. Xie"], "venue": "E. de Souza. Robust control of a class of uncertain nonlinear systems. Systems & Control Letters, 19(2):139\u2013149", "citeRegEx": "41", "shortCiteRegEx": null, "year": 1992}, {"title": "Gaussian processes for machine learning", "author": ["C.K. Williams", "C.E. Rasmussen"], "venue": "the MIT Press, 2(3):4", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2006}, {"title": "Receding horizon control for temporal logic specifications", "author": ["T. Wongpiromsarn", "U. Topcu", "R.M. Murray"], "venue": "13th ACM international conference on Hybrid systems: computation and control", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2010}, {"title": "Essentials of robust control", "author": ["K. Zhou", "J.C. Doyle"], "venue": "volume 180. Prentice hall Upper Saddle River, NJ", "citeRegEx": "44", "shortCiteRegEx": null, "year": 1998}], "referenceMentions": [{"referenceID": 18, "context": "ical models [20] have been very popular in modeling uncertainties arising in scenarios common to CPS.", "startOffset": 12, "endOffset": 16}, {"referenceID": 32, "context": "Similarly, other approaches that model uncertainty as a variable added to the dynamics [36, 13, 37, 11, 12] lack clear connections to various sources of uncertainty present in the environment.", "startOffset": 87, "endOffset": 107}, {"referenceID": 12, "context": "Similarly, other approaches that model uncertainty as a variable added to the dynamics [36, 13, 37, 11, 12] lack clear connections to various sources of uncertainty present in the environment.", "startOffset": 87, "endOffset": 107}, {"referenceID": 33, "context": "Similarly, other approaches that model uncertainty as a variable added to the dynamics [36, 13, 37, 11, 12] lack clear connections to various sources of uncertainty present in the environment.", "startOffset": 87, "endOffset": 107}, {"referenceID": 10, "context": "Similarly, other approaches that model uncertainty as a variable added to the dynamics [36, 13, 37, 11, 12] lack clear connections to various sources of uncertainty present in the environment.", "startOffset": 87, "endOffset": 107}, {"referenceID": 11, "context": "Similarly, other approaches that model uncertainty as a variable added to the dynamics [36, 13, 37, 11, 12] lack clear connections to various sources of uncertainty present in the environment.", "startOffset": 87, "endOffset": 107}, {"referenceID": 26, "context": "For instance, designing controllers under reachability analysis is a well-studied method that allows specifying safety and reachability properties [29, 30].", "startOffset": 147, "endOffset": 155}, {"referenceID": 14, "context": "More recently, safe learning approaches construct controllers that keep the system in the safe region, while the optimal strategy is learned online [15, 3, 1].", "startOffset": 148, "endOffset": 158}, {"referenceID": 2, "context": "More recently, safe learning approaches construct controllers that keep the system in the safe region, while the optimal strategy is learned online [15, 3, 1].", "startOffset": 148, "endOffset": 158}, {"referenceID": 0, "context": "More recently, safe learning approaches construct controllers that keep the system in the safe region, while the optimal strategy is learned online [15, 3, 1].", "startOffset": 148, "endOffset": 158}, {"referenceID": 28, "context": ", and has shown promising results in robotics applications [32, 23, 25, 43, 16].", "startOffset": 59, "endOffset": 79}, {"referenceID": 21, "context": ", and has shown promising results in robotics applications [32, 23, 25, 43, 16].", "startOffset": 59, "endOffset": 79}, {"referenceID": 23, "context": ", and has shown promising results in robotics applications [32, 23, 25, 43, 16].", "startOffset": 59, "endOffset": 79}, {"referenceID": 39, "context": ", and has shown promising results in robotics applications [32, 23, 25, 43, 16].", "startOffset": 59, "endOffset": 79}, {"referenceID": 15, "context": ", and has shown promising results in robotics applications [32, 23, 25, 43, 16].", "startOffset": 59, "endOffset": 79}, {"referenceID": 30, "context": "have studied synthesis for Signal Temporal Logic (STL), which allows real-valued, dense-time properties in a receding horizon setting [34, 35].", "startOffset": 134, "endOffset": 142}, {"referenceID": 31, "context": "have studied synthesis for Signal Temporal Logic (STL), which allows real-valued, dense-time properties in a receding horizon setting [34, 35].", "startOffset": 134, "endOffset": 142}, {"referenceID": 20, "context": "One of the most effective approaches in robust control under uncertainty is modeling the environment uncertainty as part of the dynamics of the system, and finding the optimal strategy for the worst case disturbance [22, 41, 44].", "startOffset": 216, "endOffset": 228}, {"referenceID": 37, "context": "One of the most effective approaches in robust control under uncertainty is modeling the environment uncertainty as part of the dynamics of the system, and finding the optimal strategy for the worst case disturbance [22, 41, 44].", "startOffset": 216, "endOffset": 228}, {"referenceID": 40, "context": "One of the most effective approaches in robust control under uncertainty is modeling the environment uncertainty as part of the dynamics of the system, and finding the optimal strategy for the worst case disturbance [22, 41, 44].", "startOffset": 216, "endOffset": 228}, {"referenceID": 22, "context": "More recently, researchers have proposed modeling the environment in a chance constrained framework, and there are some promising results in the area of urban autonomous driving [24, 39, 40, 6, 8].", "startOffset": 178, "endOffset": 196}, {"referenceID": 35, "context": "More recently, researchers have proposed modeling the environment in a chance constrained framework, and there are some promising results in the area of urban autonomous driving [24, 39, 40, 6, 8].", "startOffset": 178, "endOffset": 196}, {"referenceID": 36, "context": "More recently, researchers have proposed modeling the environment in a chance constrained framework, and there are some promising results in the area of urban autonomous driving [24, 39, 40, 6, 8].", "startOffset": 178, "endOffset": 196}, {"referenceID": 5, "context": "More recently, researchers have proposed modeling the environment in a chance constrained framework, and there are some promising results in the area of urban autonomous driving [24, 39, 40, 6, 8].", "startOffset": 178, "endOffset": 196}, {"referenceID": 7, "context": "More recently, researchers have proposed modeling the environment in a chance constrained framework, and there are some promising results in the area of urban autonomous driving [24, 39, 40, 6, 8].", "startOffset": 178, "endOffset": 196}, {"referenceID": 32, "context": "In addition, there has been efforts in verification and synthesis of controllers for temporal properties given probabilistic transition systems [36, 13, 37, 11, 12, 33].", "startOffset": 144, "endOffset": 168}, {"referenceID": 12, "context": "In addition, there has been efforts in verification and synthesis of controllers for temporal properties given probabilistic transition systems [36, 13, 37, 11, 12, 33].", "startOffset": 144, "endOffset": 168}, {"referenceID": 33, "context": "In addition, there has been efforts in verification and synthesis of controllers for temporal properties given probabilistic transition systems [36, 13, 37, 11, 12, 33].", "startOffset": 144, "endOffset": 168}, {"referenceID": 10, "context": "In addition, there has been efforts in verification and synthesis of controllers for temporal properties given probabilistic transition systems [36, 13, 37, 11, 12, 33].", "startOffset": 144, "endOffset": 168}, {"referenceID": 11, "context": "In addition, there has been efforts in verification and synthesis of controllers for temporal properties given probabilistic transition systems [36, 13, 37, 11, 12, 33].", "startOffset": 144, "endOffset": 168}, {"referenceID": 29, "context": "In addition, there has been efforts in verification and synthesis of controllers for temporal properties given probabilistic transition systems [36, 13, 37, 11, 12, 33].", "startOffset": 144, "endOffset": 168}, {"referenceID": 9, "context": "sures and monitoring properties of real-time signals of hybrid systems [27, 10, 9].", "startOffset": 71, "endOffset": 82}, {"referenceID": 8, "context": "sures and monitoring properties of real-time signals of hybrid systems [27, 10, 9].", "startOffset": 71, "endOffset": 82}, {"referenceID": 30, "context": "More recently there has been interest in synthesizing controllers that satisfy STL properties [34, 35].", "startOffset": 94, "endOffset": 102}, {"referenceID": 31, "context": "More recently there has been interest in synthesizing controllers that satisfy STL properties [34, 35].", "startOffset": 94, "endOffset": 102}, {"referenceID": 27, "context": "Most promising approaches are based on Receding Horizon Control or Model Predictive Control (MPC) [31] that aim to iteratively optimize a cost function J(\u03be) of interest.", "startOffset": 98, "endOffset": 102}, {"referenceID": 31, "context": "The constraints represented using STL allow expression of temporal specifications on the runs of the system and environment and limit the allowed behavior of the closed loop system [35, 34].", "startOffset": 181, "endOffset": 189}, {"referenceID": 30, "context": "The constraints represented using STL allow expression of temporal specifications on the runs of the system and environment and limit the allowed behavior of the closed loop system [35, 34].", "startOffset": 181, "endOffset": 189}, {"referenceID": 30, "context": "Prior work shows that MPC optimization with STL constraints \u03c6 can be posed as a Mixed Integer Linear Program (MILP) [34, 17].", "startOffset": 116, "endOffset": 124}, {"referenceID": 16, "context": "Prior work shows that MPC optimization with STL constraints \u03c6 can be posed as a Mixed Integer Linear Program (MILP) [34, 17].", "startOffset": 116, "endOffset": 124}, {"referenceID": 13, "context": "Probability theory provides a natural way to represent uncertainty in the environment and recent advances in Machine Learning and Perception have heavily relied on Bayesian methods to infer distributions over latent phenomenon of interest [14, 20].", "startOffset": 239, "endOffset": 247}, {"referenceID": 18, "context": "Probability theory provides a natural way to represent uncertainty in the environment and recent advances in Machine Learning and Perception have heavily relied on Bayesian methods to infer distributions over latent phenomenon of interest [14, 20].", "startOffset": 239, "endOffset": 247}, {"referenceID": 25, "context": ", the model), there are various Bayesian inference techniques [28, 4, 2] that would allow numerical computation of the posterior distribution p(w|XL, tL) of interest.", "startOffset": 62, "endOffset": 72}, {"referenceID": 3, "context": ", the model), there are various Bayesian inference techniques [28, 4, 2] that would allow numerical computation of the posterior distribution p(w|XL, tL) of interest.", "startOffset": 62, "endOffset": 72}, {"referenceID": 1, "context": ", the model), there are various Bayesian inference techniques [28, 4, 2] that would allow numerical computation of the posterior distribution p(w|XL, tL) of interest.", "startOffset": 62, "endOffset": 72}, {"referenceID": 25, "context": "In the above case of Bayesian classifier, the popular method of choice is to use Expectation Propagation [28] to infer p(w|XL, tL) as a Gaussian distribution N(w; w\u0304,\u03a3).", "startOffset": 105, "endOffset": 109}, {"referenceID": 38, "context": "Note that these Bayesian linear classifiers and regressors are a fairly rich class of models and have similar or better representation capabilities as kernel machines [42].", "startOffset": 167, "endOffset": 171}, {"referenceID": 0, "context": "The parameter t \u2208 [0, 1] is a small time-varying positive number and represents the threshold on satisfaction probability of \u03bb\u03b1t(\u03be(t)) < 0.", "startOffset": 18, "endOffset": 24}, {"referenceID": 4, "context": "This optimization translates to a chance constrained problem [5, 7, 39, 40, 24, 6] at every time step of the horizon, based on the definition of PrSTL predicates in equation (7):", "startOffset": 61, "endOffset": 82}, {"referenceID": 6, "context": "This optimization translates to a chance constrained problem [5, 7, 39, 40, 24, 6] at every time step of the horizon, based on the definition of PrSTL predicates in equation (7):", "startOffset": 61, "endOffset": 82}, {"referenceID": 35, "context": "This optimization translates to a chance constrained problem [5, 7, 39, 40, 24, 6] at every time step of the horizon, based on the definition of PrSTL predicates in equation (7):", "startOffset": 61, "endOffset": 82}, {"referenceID": 36, "context": "This optimization translates to a chance constrained problem [5, 7, 39, 40, 24, 6] at every time step of the horizon, based on the definition of PrSTL predicates in equation (7):", "startOffset": 61, "endOffset": 82}, {"referenceID": 22, "context": "This optimization translates to a chance constrained problem [5, 7, 39, 40, 24, 6] at every time step of the horizon, based on the definition of PrSTL predicates in equation (7):", "startOffset": 61, "endOffset": 82}, {"referenceID": 5, "context": "This optimization translates to a chance constrained problem [5, 7, 39, 40, 24, 6] at every time step of the horizon, based on the definition of PrSTL predicates in equation (7):", "startOffset": 61, "endOffset": 82}, {"referenceID": 34, "context": "It is easy to show that for this structure of \u03bb\u03b1t , where \u03bb\u03b1t is a weighted sum of the states with Gaussian weights \u03b1t, the chance constrained optimization in equation (14) is convex [38, 21].", "startOffset": 183, "endOffset": 191}, {"referenceID": 19, "context": "It is easy to show that for this structure of \u03bb\u03b1t , where \u03bb\u03b1t is a weighted sum of the states with Gaussian weights \u03b1t, the chance constrained optimization in equation (14) is convex [38, 21].", "startOffset": 183, "endOffset": 191}, {"referenceID": 6, "context": "Assuming the a linear-Gaussian form of the function, we generate the SOCP above and easily translate it to a semidefinite program (SDP) by introducing auxiliary variables [7].", "startOffset": 171, "endOffset": 174}, {"referenceID": 24, "context": "Our toolbox uses Yalmip [26] and Gurobi [18] as its optimization engine.", "startOffset": 24, "endOffset": 28}, {"referenceID": 17, "context": "We follow the derivation of the dynamics model of a quadrotor in [19].", "startOffset": 65, "endOffset": 69}, {"referenceID": 25, "context": "The presented approach extends easily to distributions other than Gaussians via Bayesian approximate inference techniques [28, 4] that can project distributions to the Gaussian densities.", "startOffset": 122, "endOffset": 129}, {"referenceID": 3, "context": "The presented approach extends easily to distributions other than Gaussians via Bayesian approximate inference techniques [28, 4] that can project distributions to the Gaussian densities.", "startOffset": 122, "endOffset": 129}], "year": 2015, "abstractText": "Controller synthesis for hybrid systems that satisfy temporal specifications expressing various system properties is a challenging problem that has drawn the attention of many researchers. However, making the assumption that such temporal properties are deterministic is far from the reality. For example, many of the properties the controller has to satisfy are learned through machine learning techniques based on sensor input data. In this paper, we propose a new logic, Probabilistic Signal Temporal Logic (PrSTL), as an expressive language to define the stochastic properties, and enforce probabilistic guarantees on them. We further show how to synthesize safe controllers using this logic for cyber-physical systems under the assumption that the stochastic properties are based on a set of Gaussian random variables. One of the key distinguishing features of PrSTL is that the encoded logic is adaptive and changes as the system encounters additional data and updates its beliefs about the latent random variables that define the safety properties. We demonstrate our approach by synthesizing safe controllers under the PrSTL specifications for multiple case studies including control of quadrotors and autonomous vehicles in dynamic environments.", "creator": "LaTeX with hyperref package"}}}