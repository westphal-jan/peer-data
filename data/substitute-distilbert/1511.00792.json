{"id": "1511.00792", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Nov-2015", "title": "Fast Collaborative Filtering from Implicit Feedback with Provable Guarantees", "abstract": "building recommendation algorithms is one of generally most challenging tasks in machine learning. although there has been constant progress exploring building recommend systems when supplemental feedback is available from the users in the form of instruction or text, most of the applications don't receive such feedback. here we consider the recommendation task where the available data equals the record of identified nodes selected by successful users over windows for subscription or purchase. this is known as implicit feedback recommendation. such data are usually available as large amount of user logs stored over massively distributed storage systems such as hadoop. therefore it is essential to have a highly scalable algorithm to build a recommender system for such applications. here we realize a probabilistic algorithm - takes only two to three passes through the human organism to extract the model evaluated during the training phase. we demonstrate the competitive performance of candidates task in several empirical measures as well as the computation time in comparison with the training algorithms on various publicly available datasets.", "histories": [["v1", "Tue, 3 Nov 2015 06:43:54 GMT  (290kb,D)", "http://arxiv.org/abs/1511.00792v1", null], ["v2", "Wed, 4 Nov 2015 06:26:04 GMT  (290kb,D)", "http://arxiv.org/abs/1511.00792v2", null], ["v3", "Thu, 5 Nov 2015 13:06:07 GMT  (291kb,D)", "http://arxiv.org/abs/1511.00792v3", null], ["v4", "Tue, 10 Nov 2015 12:05:40 GMT  (291kb,D)", "http://arxiv.org/abs/1511.00792v4", null], ["v5", "Mon, 23 Nov 2015 10:05:40 GMT  (291kb,D)", "http://arxiv.org/abs/1511.00792v5", null], ["v6", "Thu, 24 Dec 2015 20:33:13 GMT  (293kb,D)", "http://arxiv.org/abs/1511.00792v6", null], ["v7", "Fri, 15 Jan 2016 15:44:30 GMT  (292kb,D)", "http://arxiv.org/abs/1511.00792v7", null], ["v8", "Sat, 6 Feb 2016 10:28:25 GMT  (146kb,D)", "http://arxiv.org/abs/1511.00792v8", null], ["v9", "Wed, 8 Jun 2016 16:33:38 GMT  (161kb,D)", "http://arxiv.org/abs/1511.00792v9", null], ["v10", "Sun, 21 Aug 2016 08:00:15 GMT  (130kb,D)", "http://arxiv.org/abs/1511.00792v10", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["sayantan dasgupta"], "accepted": false, "id": "1511.00792"}, "pdf": {"name": "1511.00792.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Sayantan Dasgupta"], "emails": ["sayantad@uci.edu"], "sections": [{"heading": "1 INTRODUCTION", "text": "Recommendation systems came into spotlight with the introduction of Netflix one million challenge. A number of recommendation algorithms have been developed using features extracted from the description or content of the items. However, these content based algorithms typically fail to capture the user opinion on different items. Collaborative filtering, on the other hand, relies on user feedback in some form or the other, and can provide with a better insight of user opinions. Most of the collaborative filtering systems built till date have presumed the availability of explicit feedback from users, either in the form of ratings, or texts, or even through \u2019like\u2019 tags. This, however, is neither always the case, may nor even be necessary. Moreover, rating provided by a user is usually subjective, and may depend upon the circumstance, or the mood of the user. Incorporating these effects can prove immensely challenging.\nThe selection of different items by a user can reflect his opinion with a great efficacy. The records of these selections are usually available as user logs, and for most of the applications enormous quantities of such logs are available. Examples of such Implicit recommendation systems are music recommendation, personalised search result recommendation or personalised news recommendation; for example, in a personalised news recommender system Das et al. (2007), we always know the articles a user read or liked from his click logs, but will never come to know the articles he did not like (Figure 1). Please note that the feedback available in the form of like or unlike tag is an explicit binary feedback, and must not be confused with implicit feedback systems, where we have only the knowledge of what the users liked before.\nMajority of the literature of recommender systems focus on cases where explicit feedback are available.There have been a few previous attempts to build recommendation systems based on implicit feedback, e.g. in personalized ranking of search results Lin et al. (2005) or personalized news recommendation Das et al. (2007). These recommendation algorithms usually rely on Probabilistic Latent Semantic Algorithm (PLSI) Hofmann (2004). PLSI deploys EM algorithm for training, and therefore suffers from local maxima problem. These recommendation systems often do not give\nar X\niv :1\n51 1.\n00 79\n2v 1\n[ cs\n.L G\n] 3\nN ov\n2 01\n5\noptimal performance. Also, most of the literature on implicit feedback, such as Lin et al. (2005) and Das et al. (2007) are published using proprietary datasets, and lack of publicly available dataset has also been a major impediment for academic contribution in this segment.\nHu et al. (2008) proposes a weighted matrix factorization (WRMF) for implicit feedback recommendation. The algorithm scans through the entire dataset for every iteration until convergence, and it may prove computationally very expensive for large amount of user logs stored across multiple nodes in a distributed ecosystem. Bayesian Personalized Ranking (BPR) inRendle et al. (2009) uses stochastic approach to train from a small batch size, and reduces the computation time significantly. These two methods are shown to outperform others such as similarity or neighbourhood based methods in Rendle et al. (2009), and hence we limit our discussion on BPR and WRMF in this article.\nThere have been recent developments on clustering algorithms based on Method of Moments (MoM), also referred to as Spectral Methods in the literature. Unlike traditional clustering algorithms which rely on EM and similar algorithms to maximize the likelihood of the data, MoM tries to learn the parameters from higher order moments of the data. The method can be proven to be globally convergent using PAC style proof (see Anandkumar et al. (2014)), and has been successfully applied for Hidden Markov Model in Hsu et al. (2012) and Song et al. (2010), for Topic Modeling in Anandkumar et al. (2012), for various Natural Language Processing applications in Cohen et al. (2014), Dhillon et al. (2012) and for Spectral Experts of Linear Regression in Chaganty & Liang (2013).\nHere we propose a generative model for implicit feedback recommendation system based on Method of Moments. We derive the model in the next section, and then show its competitive performance based on a few publicly available dataset which were released very recently."}, {"heading": "2 LATENT VARIABLE MODEL FOR METHOD OF MOMENTS", "text": "In this section we outline the generative latent variable model for Method of Moments, and derive the equations to extract the parameters of the model. We also show that the method yields unique model parameters.\nLet us assume that there are U users and D items, and the latent variable h can assume K states. For any user x \u2208 {x1, x2 . . . xU} we first choose a latent state of h from the discrete distribution P (h|x), then we choose an item y \u2208 {y1, y2 . . . yD} from the discrete distribution P (y|h). The generative process is as follows,\nh \u223c Discrete(P (h|x)) y \u223c Discrete(P (y|h)) (1)\nLet us denote the probability of the latent variable h assuming the state k \u2208 1 . . .K as,\n\u03c0k = P (h = k) (2)\nAlgorithm 1 Method of Moments for Parameter Extraction\nInput: Sparse Moments M\u03022 \u2208 RD\u00d7D and M\u03023 \u2208 RD\u00d7D\u00d7D Output: P (y|h) and P (h|x)\n1. Compute a singular value decomposition of M\u03022 as M\u03022 = U\u03a3V >, and estimate the whitening matrix W\u0302 = U\u03a3\u22121/2 so that W\u0302>M\u03022W\u0302 = I 2. Multiply M\u03023 with W\u0302 from all three directions to produce the tensor M\u03023(W\u0302 , W\u0302 , W\u0302 ) \u2208 RK\u00d7K\u00d7K . Compute eigenvalues {\u03bbk}Kk=1 and eigenvectors {vk}Kk=1 of M\u03023(W\u0302 , W\u0302 , W\u0302 ) through power iteration followed by deflation 3. Estimate the columns of O as \u02c6\u0304\u00b5k = \u03bbkW\u0302 \u2020vk, where W\u0302 \u2020 = W\u0302 (W\u0302>W\u0302 ) \u22121\n, and \u03c0\u0302k = \u03bb\u22122k , \u2200k \u2208 1, 2 . . .K\n4. Assign O\u0302 = [\u02c6\u0304\u00b51| \u02c6\u0304\u00b52| . . . | \u02c6\u0304\u00b5K ] and \u03c0\u0302 = [\u03c0\u03021\u03c0\u03022 . . . \u03c0\u0302K ]> 5. Estimate P (y|h = k) = O\u0302yk\u2211 y O\u0302yk ,\u2200k \u2208 1 . . .K, y \u2208 1 . . . D,\nP (h = k|x) = \u03c0\u0302k \u220f\ny\u2208Yx O\u0302yk\u2211K k=1 \u03c0\u0302k \u220f y\u2208Yx O\u0302yk \u2200k \u2208 1 . . .K, x \u2208 1 . . . U\nLet us define \u00b5\u0304k \u2208 RD as the probability vector of all the items conditional to the latent state k \u2208 1 . . .K, i.e.\n\u00b5\u0304k = P (y|h = k) (3)\nLet the matrix O \u2208 RD\u00d7K denote the conditional probabilities for the items, i.e. Oi,k = P (yi|h = k). Then O = [\u00b5\u03041|\u00b5\u03042| . . . |\u00b5\u0304K ]. We assume that the matrix O is of full rank, and the columns of O are fully identifiable. The aim of our algorithm is to estimate the matrix O as well as the vector \u03c0.\nFollowing the generative model in equation 1, if we choose three items u, v, w from the list of items associated to any user, then, P (u|h), P (v|h) and P (w|h) are conditionally independent given h. Let us note that P (u = yi), P (v = yi) and P (w = yi) all are synonymous with P [yi], since all of them represents the probability of the item yi appearing in the list of any user in the entire dataset. Therefore, P (u = yi|h = k) = P (yi|h = k) = Oi,k = [\u00b5\u0304k]i, and the same holds for P (v = yi|h = k) and P (w = yi|h = k). The probability of any item yi appearing in the list of a user is, therefore,\nP [yi] = P (u = yi) = K\u2211 k=1 P (u = yi|h = k)P (h = k) = K\u2211 k=1 Oi,k\u03c0k \u2200i \u2208 1 . . . D (4)\nHence the probability of each individual item across the entire dataset can be expressed as,\nM1 = P [y1,2...D] > = O\u03c0 = [\u00b5\u03041|\u00b5\u03042| . . . |\u00b5\u0304K ] \u00b7 [\u03c01, \u03c02 . . . \u03c0k]> = K\u2211 k=1 \u03c0k\u00b5\u0304k (5)\nThe probability of any two items yi and yj occurring together in the item list of any user can be defined as,\nP [yi, yj ] = P (u = yi, v = yj)\n= K\u2211 k=1 P (u = yi, v = yj |h = k)P (h = k)\n= K\u2211 k=1 P (u = yi|h = k)P (v = yj |h = k)\u03c0k\n= K\u2211 k=1 \u03c0k[\u00b5\u0304k]i[\u00b5\u0304k]j \u2200i = 1 . . . D,\u2200j = 1 . . . D (6)\nDefining M2 as the pairwise probability matrix, with [M2]i,j = P [yi, yj ], we can express it as,\nM2 = K\u2211 k=1 \u03c0k\u00b5\u0304k\u00b5\u0304 > k = K\u2211 k=1 \u03c0k\u00b5\u0304k \u2297 \u00b5\u0304k (7)\nSimilarly, the probability of any three items yi, yj and yl occurring together in the item list of any user can be defined as,\nP [yi, yj , yl] = P (u = yi, v = yj , w = yl)\n= K\u2211 k=1 P (u = yi, v = yj , w = yl|h = k)P (h = k)\n= K\u2211 k=1 P (u = yi|h = k)P (v = yj |h = k)P (w = yl|h = k)P (h = k)\n= K\u2211 k=1 P (u = yi|h = k)P (v = yj |h = k)P (w = yl|h = k)\u03c0k\n= K\u2211 k=1 \u03c0k[\u00b5\u0304k]i[\u00b5\u0304k]j [\u00b5\u0304k]l \u2200i = 1 . . . D,\u2200j = 1 . . . D,\u2200l = 1 . . . D (8)\nTherefore, the tensor M3 defined as the third order probability moment, with [M3]i,j,l = P [yi, yj , yl], can be represented as,\nM3 = K\u2211 k=1 \u03c0k\u00b5\u0304k \u2297 \u00b5\u0304k \u2297 \u00b5\u0304k (9)\nThe algorithm first computes a matrix W \u2208 RD\u00d7K for M2, such that W>M2W = I . This process is similar to whitening for independent component analysis (ICA), with the co-variance matrix being replaced by the co-occurrence probability matrix in our case. The whitening is usually done through singular value decomposition. Let us note that,\nW>M2W = W >( K\u2211\nk=1\n\u03c0k\u00b5\u0304k\u00b5\u0304 > k\n) W = K\u2211 k=1 (\u221a \u03c0kW >\u00b5\u0304k )(\u221a \u03c0kW >\u00b5\u0304k )> = K\u2211 k=1 \u00b5\u0303k\u00b5\u0303 > k = I (10)\nHence \u00b5\u0303k = \u221a \u03c0kW\n>\u00b5\u0304k are orthonormal vectors. Multiplying M3 from all three dimensions by W , we get\nM\u03033 = M3(W,W,W ) = K\u2211 k=1 \u03c0k(W >\u00b5\u0304k)\u2297 (W>\u00b5\u0304k)\u2297 (W>\u00b5\u0304k) = K\u2211 k=1 1 \u221a \u03c0k \u00b5\u0303k \u2297 \u00b5\u0303k \u2297 \u00b5\u0303k (11)\nHence the robust eigenvectors of M\u03033 are \u00b5\u0303k, whereas the eigenvalues are \u03c0k.\nWe use the tensor decomposition algorithm from Anandkumar et al. (2014), which computes the eigen-vectors of M\u03033 through power iteration followed by deflation (Algorithm 2). The space complexity of the algorithm isO(K3+DK), whereas time complexity isO((U+D)K3+NK), where N is the total number of < user, item > pairs in the dataset with a non-zero entry. Since the space complexity is independent of N , the algorithm has the capability to scale across a large amount of dataset.\nWe create an estimation of the sparse moments M2 and M3 by counting the occurrence, pairwise occurrence and three way occurrence of the items across the selections made by all the users in the dataset, and normalizing by the total number of occurrence in each case. Let us denote the estimates as M\u03022 and M\u03023. Then the method follows as Algorithm 1.\nAlgorithm 2 Power Iteration for Eigen-decomposition of a Third Order Symmetric Tensor\nInput: Symmetric Tensor T \u2208 RK\u00d7K\u00d7K , dimension K and tolerance Output: The set of eigenvalues {\u03bbk}Kk=1 and eigenvectors {vk}Kk=1 of T for k = 1 to K do\nInitialize \u03b8 at random from a unit sphere in RK repeat\nAssign \u03b80 \u2190 \u03b8 Assign \u03b8 \u2190 T (\u00b7,\u03b8,\u03b8)\u2016T (\u00b7,\u03b8,\u03b8)\u2016\nuntil \u2016\u03b8 \u2212 \u03b80\u2016 < Assign vk \u2190 \u03b8, \u03bbk \u2190 T (\u00b7,\u03b8,\u03b8)\u2016T (\u00b7,\u03b8,\u03b8)\u2016 Deflate the tensor as T \u2190 T \u2212 \u03bbk(vk \u2297 vk \u2297 vk)\nend for\nOnce we have O\u0302 and \u03c0\u0302, the user personalization probabilities P (h = k|x) can be estimated as,\nP (h = k|x) = P (h = k) \u220f y\u2208Yx P (y|h = k)\u2211K\nk=1 P (h = k) \u220f y\u2208Yx P (y|h = k)\n= \u03c0\u0302k \u220f y\u2208Yx O\u0302yk\u2211K\nk=1 \u03c0\u0302k \u220f y\u2208Yx O\u0302yk\n(12)\nwhere Yx is the list of items selected by the user x in the training set. The power iterations for computing the eigenvalues of a symmetric tensor is described in Algorithm 2. The product T (\u00b7, \u03b8, \u03b8) represents the vector resulting from product of the tensor T with the vector \u03b8 along any two axes. Although the dimensions of M2 and M3 are D2 and D3 respectively, in practice, these two quantities are extremely sparse. They can be extracted by one or two passes through the dataset. Once \u03c0k and \u00b5\u0304k are extracted, it requires one more pass through the entire dataset to compute the user probabilities (P (h|x)). Finally, the probability of a user x\u0303 selecting an item y\u0303 can be computed as the following equation, and the items with highest probability are usually recommended for the user x\u0303.\nP (y\u0303|x\u0303) = K\u2211 k=1 P (y\u0303|h = k)P (h = k|x\u0303) (13)\nCorollary. The parameters {\u03c0k}Kk=1 and {\u00b5\u0304k}Kk=1 are unique given the training set X Proof. The probability column vectors \u00b5\u0304k = 1\u221a\u03c0k ( W> )\u2020 \u00b5\u0303k consist of three terms, W , \u03c0k and \u00b5\u0303k. \u03c0k and \u00b5\u0303k are the eigenvalues and eigenvectors of the tensor M\u03033 = M3(W,W,W ). Since M2 andM3 are fixed given the dataset X , \u03c0k and \u00b5\u0303k also depend on W . The whitening matrix W is unique only upto a factor of Q \u2208 RK\u00d7K , such that Q>Q = I . Let us assume the whitening matrix W whitens M2, then any matrix W \u2032 = WQ also whitens M2, since\nW \u2032>M2W \u2032 = Q> ( W>M2W ) Q = Q>Q = I (14)\nNow, let us assume that we obtain the matrix W \u2032 as the whitening matrix, then similar to Equation 10,\nW \u2032>M2W \u2032 = Q>W> ( K\u2211 k=1 \u03c0k\u00b5\u0304k\u00b5\u0304 > k ) WQ\n= K\u2211 k=1 (\u221a \u03c0kQ >W>\u00b5\u0304k ) (\u221a \u03c0kQ >W>\u00b5\u0304k )> =\nK\u2211 k=1 \u00b5\u0303\u2032k\u00b5\u0303 \u2032> k = I\n(15)\nHence the new orthonormal vectors are \u00b5\u0303\u2032k, which vary from \u00b5\u0303k by a factor of Q >. Furthermore,\nM\u0303 \u20323 = M3(WQ,WQ,WQ)\n= K\u2211 k=1 \u03c0k(Q >W>\u00b5\u0304k)\u2297 (Q>W>\u00b5\u0304k)\u2297 (Q>W>\u00b5\u0304k)\n= K\u2211 k=1 1 \u221a \u03c0k \u00b5\u0303\u2032k \u2297 \u00b5\u0303\u2032k \u2297 \u00b5\u0303\u2032k\n(16)\nHence, the eigenvalues of M\u0303 \u20323 remain same as those of M\u03033, whereas the eigenvectors change to \u00b5\u0303\u2032k = Q >\u00b5\u0303k. {\u00b5\u0304k}Kk=1 can be computed back from {\u00b5\u0303\u2032k}Kk=1 as,\n\u00b5\u0304k = 1 \u221a \u03c0k\n( W \u2032> )\u2020 \u00b5\u0303\u2032k =\n1 \u221a \u03c0k W \u2032(W \u2032>W \u2032)\u22121\u00b5\u0303\u2032k (17)\nTherefore,\n\u00b5\u0304k = 1 \u221a \u03c0k WQ(Q>W>WQ)\u22121Q>\u00b5\u0303k = 1 \u221a \u03c0k WQQ\u22121(W>W )\u22121Q\u2212>Q>\u00b5\u0303k\n= 1 \u221a \u03c0k W (W>W )\u22121\u00b5\u0303k = 1 \u221a \u03c0k\n( W> )\u2020 \u00b5\u0303k\n(18)\nHence, {\u00b5\u0304k}Kk=1 are invariant of Q, and are unique as long as the eigenvector decomposition of the tensor M\u03033 is robust enough to produce unique eigenvectors. Any matrix W that can whiten M2 is sufficient to extract the parameters of the model.\nSince the parameters {\u03c0k}Kk=1 and {\u00b5\u0304k}Kk=1 are unique, the matrix O is unique, and therefore, from Equation 12, the user personalization parameters P (h = k|x) are also unique. Hence, the parameters extracted by method of moments are unique, and invariant to the whitening process."}, {"heading": "3 EXPERIMENTAL RESULTS", "text": "We show the implementation of our model on three publicly available datasets, so that the results can be reproduced whenever necessary. The different attributes of datasets are described in Table 1. Treating the dataset as a User\u00d7Item matrix, we can define the density of non-zero elements as,\nDensity = Number of < User, Item > Tuples Number of Users\u00d7 Number of Items\n(19)\nWe use K = 50 for all the models in our experiments; WRMF runs out of memory for higher values of K. We use the implementation of BPR and WRMF from MyMediaLite library available at http://www.mymedialite.net/ , developed by the authors of Rendle et al. (2009). For every dataset, we compute the Precision@\u03c4 , Recall@\u03c4 , and Mean Average Precision (MAP@\u03c4 ) for \u03c4 \u2208 {5, 10, 20, 40, 60, 80, 100, 200, 300, 400, 500}. The Precision-Recall curves as well as MAP@\u03c4 is shown in Figure 2. We also show the computation time averaged over 10 executions for each method in Figure 2. We carry out our experiments on Unix Platform on a single machine with Intel i5 Processor (2.4GHz) and 8GB memory, and no multi-threading or other performance enhancement technique is used in the code."}, {"heading": "3.1 TA-FENG DATASET", "text": "Ta-Feng dataset consists of online grocery purchase records for the months of January, February, November and December in 2001.We combine the records of January and November resulting in a training set consisting of around 24,000 users and 21,000 products, and around 470,000 sales records. The records of February and December are combined to form the test set. BPR achieves the highest MAP of all, but MoM yields the best Precision-Recall curve with slightly worse MAP than BPR. We also compare our result for Precison@5 with that obtained using Unified Boltzman Machine (UBM) in Gunawardana & Meek (2009) in Table 2."}, {"heading": "3.2 MILLION SONG DATASET", "text": "Million Song dataset contains the logs of 1 million users listening to 385,000 song tracks with 48 million observations. Here, we use a subset of the data consisting of 100,000 users and around 165,000 song tracks with around 1.45 million observations released in Kaggle. The MoM yields the best MAP, as well as the best Precision-Recall for lower values of \u03c4 , and it trains in similar time as BPR.\nWe also compare our result for MAP@500 with those of content based Music Recommendation using Deep Convolutional Neural Network (DCNN) in Van den Oord et al. (2013) for 9330 most popular songs with 20,000 users in Table 3. Our method is far less computationally expensive than Deep Convolutional Neural Network for large datasets."}, {"heading": "3.3 YANDEX SEARCH LOG DATASET", "text": "Yandex dataset got released in Kaggle very recently, and it contains the search logs of 27 days for 5.7 million users and 70.3 million URLs. However, only 12 million URLs have at least one click. We have selected a subset of 150,000 users and 624,000 URLs, and used the data of first 14 days as the training set, and the last 13 days as the test set. The WRMF performs best on Yandex dataset, however, it takes around 10x time to train compared to MoM or BPR. MoM, on the other hand, does reasonably well but only takes a fraction of the time taken by WRMF."}, {"heading": "4 CONCLUSION AND FUTURE WORKS", "text": "Here we have introduced a generative model based on Method of Moments for implicit feedback recommendations, and established its competitive performance on three datasets. BPR yields the best results for the Ta-Feng dataset, however, its performance degrades severely as the size and the\nsparsity of the data increases. WRMF, on the other hand, performs worse for Ta-Feng dataset, but the performance improves as the dataset becomes larger and sparser. However, its computation time is significantly higher than the other two algorithms, and for the Yandex dataset, it is almost 10x slower compared to BPR or MoM. MoM gives competitive performance for all the datasets, yet taking similar computation time as BPR. The competitive computational aspects of MoM may be even more evident when implemented on larger amounts of data stored across multiple nodes in a distributed ecosystem. Although WRMF is scalable, it scans through the entire dataset for every iteration, and after each iteration it has to synchronize across all the nodes in the distributed system. This results in a very high communication overhead across the nodes. MoM, on the other hand, can extract the moments M2 and M3 in one or two passes through the entire dataset. Although certain parts of our algorithm, such as whitening of M2, may require parallelization, it can be parallelized across much smaller number of nodes than required for the storage of the entire dataset. We wish to perform a competitive study of these algorithms implemented in distributed ecosystems in future.\nThere has been efforts to model Bayesian Non-parametrics using Method of Moments; Tung & Smola (2014) suggests a spectral method to draw inference in Indian Buffet Process. However, it does not highlight the scalability of the method. We also want to incorporate Bayesian Nonparametrics in Recommendation algorithms using Method of Moments in future. Also, we want to extend Method of Moments for rating prediction in explicit feedback recommendation systems."}], "references": [{"title": "A spectral algorithm for latent dirichlet allocation", "author": ["Anandkumar", "Anima", "Liu", "Yi-kai", "Hsu", "Daniel J", "Foster", "Dean P", "Kakade", "Sham M"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Anandkumar et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Anandkumar et al\\.", "year": 2012}, {"title": "Tensor decompositions for learning latent variable models", "author": ["Anandkumar", "Animashree", "Ge", "Rong", "Hsu", "Daniel", "Kakade", "Sham M", "Telgarsky", "Matus"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Anandkumar et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Anandkumar et al\\.", "year": 2014}, {"title": "Spectral experts for estimating mixtures of linear regressions", "author": ["Chaganty", "Arun Tejasvi", "Liang", "Percy"], "venue": "arXiv preprint arXiv:1306.3729,", "citeRegEx": "Chaganty et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Chaganty et al\\.", "year": 2013}, {"title": "Spectral learning of latent-variable pcfgs: algorithms and sample complexity", "author": ["Cohen", "Shay B", "Stratos", "Karl", "Collins", "Michael", "Foster", "Dean P", "Ungar", "Lyle H"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Cohen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cohen et al\\.", "year": 2014}, {"title": "Google news personalization: scalable online collaborative filtering", "author": ["Das", "Abhinandan S", "Datar", "Mayur", "Garg", "Ashutosh", "Rajaram", "Shyam"], "venue": "In Proceedings of the 16th international conference on World Wide Web,", "citeRegEx": "Das et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Das et al\\.", "year": 2007}, {"title": "Spectral dependency parsing with latent variables", "author": ["Dhillon", "Paramveer S", "Rodu", "Jordan", "Collins", "Michael", "Foster", "Dean P", "Ungar", "Lyle H"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,", "citeRegEx": "Dhillon et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Dhillon et al\\.", "year": 2012}, {"title": "A unified approach to building hybrid recommender systems", "author": ["Gunawardana", "Asela", "Meek", "Christopher"], "venue": "In Proceedings of the Third ACM Conference on Recommender Systems,", "citeRegEx": "Gunawardana et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Gunawardana et al\\.", "year": 2009}, {"title": "Latent semantic models for collaborative filtering", "author": ["Hofmann", "Thomas"], "venue": "ACM Trans. Inf. Syst.,", "citeRegEx": "Hofmann and Thomas.,? \\Q2004\\E", "shortCiteRegEx": "Hofmann and Thomas.", "year": 2004}, {"title": "A spectral algorithm for learning hidden markov models", "author": ["Hsu", "Daniel", "Kakade", "Sham M", "Zhang", "Tong"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Hsu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hsu et al\\.", "year": 2012}, {"title": "Collaborative filtering for implicit feedback datasets", "author": ["Hu", "Yifan", "Koren", "Yehuda", "Volinsky", "Chris"], "venue": "In Proceedings of the 2008 Eighth IEEE International Conference on Data Mining,", "citeRegEx": "Hu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Hu et al\\.", "year": 2008}, {"title": "Shifted power method for computing tensor eigenpairs", "author": ["Kolda", "Tamara G", "Mayo", "Jackson R"], "venue": "SIAM Journal on Matrix Analysis and Applications,", "citeRegEx": "Kolda et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kolda et al\\.", "year": 2011}, {"title": "Using probabilistic latent semantic analysis for personalized web search", "author": ["Lin", "Chenxi", "Xue", "Gui-Rong", "Zeng", "Hua-Jun", "Yu", "Yong"], "venue": "In Web Technologies Research and Development-APWeb", "citeRegEx": "Lin et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2005}, {"title": "Bpr: Bayesian personalized ranking from implicit feedback", "author": ["Rendle", "Steffen", "Freudenthaler", "Christoph", "Gantner", "Zeno", "Schmidt-Thieme", "Lars"], "venue": "In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Rendle et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Rendle et al\\.", "year": 2009}, {"title": "Hilbert space embeddings of hidden markov models", "author": ["Song", "Le", "Boots", "Byron", "Siddiqi", "Sajid M", "Gordon", "Geoffrey J", "Smola", "Alex J"], "venue": "In Proceedings of the 27th international conference on machine learning", "citeRegEx": "Song et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Song et al\\.", "year": 2010}, {"title": "Spectral methods for indian buffet process inference", "author": ["Tung", "Hsiao-Yu", "Smola", "Alex J"], "venue": "In Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems", "citeRegEx": "Tung et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Tung et al\\.", "year": 2014}, {"title": "Deep content-based music recommendation", "author": ["Van den Oord", "Aaron", "Dieleman", "Sander", "Schrauwen", "Benjamin"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Oord et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Oord et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 4, "context": "Examples of such Implicit recommendation systems are music recommendation, personalised search result recommendation or personalised news recommendation; for example, in a personalised news recommender system Das et al. (2007), we always know the articles a user read or liked from his click logs, but will never come to know the articles he did not like (Figure 1).", "startOffset": 209, "endOffset": 227}, {"referenceID": 4, "context": "Examples of such Implicit recommendation systems are music recommendation, personalised search result recommendation or personalised news recommendation; for example, in a personalised news recommender system Das et al. (2007), we always know the articles a user read or liked from his click logs, but will never come to know the articles he did not like (Figure 1). Please note that the feedback available in the form of like or unlike tag is an explicit binary feedback, and must not be confused with implicit feedback systems, where we have only the knowledge of what the users liked before. Majority of the literature of recommender systems focus on cases where explicit feedback are available.There have been a few previous attempts to build recommendation systems based on implicit feedback, e.g. in personalized ranking of search results Lin et al. (2005) or personalized news recommendation Das et al.", "startOffset": 209, "endOffset": 863}, {"referenceID": 4, "context": "Examples of such Implicit recommendation systems are music recommendation, personalised search result recommendation or personalised news recommendation; for example, in a personalised news recommender system Das et al. (2007), we always know the articles a user read or liked from his click logs, but will never come to know the articles he did not like (Figure 1). Please note that the feedback available in the form of like or unlike tag is an explicit binary feedback, and must not be confused with implicit feedback systems, where we have only the knowledge of what the users liked before. Majority of the literature of recommender systems focus on cases where explicit feedback are available.There have been a few previous attempts to build recommendation systems based on implicit feedback, e.g. in personalized ranking of search results Lin et al. (2005) or personalized news recommendation Das et al. (2007). These recommendation algorithms usually rely on Probabilistic Latent Semantic Algorithm (PLSI) Hofmann (2004).", "startOffset": 209, "endOffset": 917}, {"referenceID": 4, "context": "Examples of such Implicit recommendation systems are music recommendation, personalised search result recommendation or personalised news recommendation; for example, in a personalised news recommender system Das et al. (2007), we always know the articles a user read or liked from his click logs, but will never come to know the articles he did not like (Figure 1). Please note that the feedback available in the form of like or unlike tag is an explicit binary feedback, and must not be confused with implicit feedback systems, where we have only the knowledge of what the users liked before. Majority of the literature of recommender systems focus on cases where explicit feedback are available.There have been a few previous attempts to build recommendation systems based on implicit feedback, e.g. in personalized ranking of search results Lin et al. (2005) or personalized news recommendation Das et al. (2007). These recommendation algorithms usually rely on Probabilistic Latent Semantic Algorithm (PLSI) Hofmann (2004). PLSI deploys EM algorithm for training, and therefore suffers from local maxima problem.", "startOffset": 209, "endOffset": 1028}, {"referenceID": 4, "context": "Also, most of the literature on implicit feedback, such as Lin et al. (2005) and Das et al.", "startOffset": 59, "endOffset": 77}, {"referenceID": 1, "context": "(2005) and Das et al. (2007) are published using proprietary datasets, and lack of publicly available dataset has also been a major impediment for academic contribution in this segment.", "startOffset": 11, "endOffset": 29}, {"referenceID": 1, "context": "(2005) and Das et al. (2007) are published using proprietary datasets, and lack of publicly available dataset has also been a major impediment for academic contribution in this segment. Hu et al. (2008) proposes a weighted matrix factorization (WRMF) for implicit feedback recommendation.", "startOffset": 11, "endOffset": 203}, {"referenceID": 1, "context": "(2005) and Das et al. (2007) are published using proprietary datasets, and lack of publicly available dataset has also been a major impediment for academic contribution in this segment. Hu et al. (2008) proposes a weighted matrix factorization (WRMF) for implicit feedback recommendation. The algorithm scans through the entire dataset for every iteration until convergence, and it may prove computationally very expensive for large amount of user logs stored across multiple nodes in a distributed ecosystem. Bayesian Personalized Ranking (BPR) inRendle et al. (2009) uses stochastic approach to train from a small batch size, and reduces the computation time significantly.", "startOffset": 11, "endOffset": 569}, {"referenceID": 1, "context": "(2005) and Das et al. (2007) are published using proprietary datasets, and lack of publicly available dataset has also been a major impediment for academic contribution in this segment. Hu et al. (2008) proposes a weighted matrix factorization (WRMF) for implicit feedback recommendation. The algorithm scans through the entire dataset for every iteration until convergence, and it may prove computationally very expensive for large amount of user logs stored across multiple nodes in a distributed ecosystem. Bayesian Personalized Ranking (BPR) inRendle et al. (2009) uses stochastic approach to train from a small batch size, and reduces the computation time significantly. These two methods are shown to outperform others such as similarity or neighbourhood based methods in Rendle et al. (2009), and hence we limit our discussion on BPR and WRMF in this article.", "startOffset": 11, "endOffset": 799}, {"referenceID": 0, "context": "The method can be proven to be globally convergent using PAC style proof (see Anandkumar et al. (2014)), and has been successfully applied for Hidden Markov Model in Hsu et al.", "startOffset": 78, "endOffset": 103}, {"referenceID": 0, "context": "The method can be proven to be globally convergent using PAC style proof (see Anandkumar et al. (2014)), and has been successfully applied for Hidden Markov Model in Hsu et al. (2012) and Song et al.", "startOffset": 78, "endOffset": 184}, {"referenceID": 0, "context": "The method can be proven to be globally convergent using PAC style proof (see Anandkumar et al. (2014)), and has been successfully applied for Hidden Markov Model in Hsu et al. (2012) and Song et al. (2010), for Topic Modeling in Anandkumar et al.", "startOffset": 78, "endOffset": 207}, {"referenceID": 0, "context": "The method can be proven to be globally convergent using PAC style proof (see Anandkumar et al. (2014)), and has been successfully applied for Hidden Markov Model in Hsu et al. (2012) and Song et al. (2010), for Topic Modeling in Anandkumar et al. (2012), for various Natural Language Processing applications in Cohen et al.", "startOffset": 78, "endOffset": 255}, {"referenceID": 0, "context": "The method can be proven to be globally convergent using PAC style proof (see Anandkumar et al. (2014)), and has been successfully applied for Hidden Markov Model in Hsu et al. (2012) and Song et al. (2010), for Topic Modeling in Anandkumar et al. (2012), for various Natural Language Processing applications in Cohen et al. (2014), Dhillon et al.", "startOffset": 78, "endOffset": 332}, {"referenceID": 0, "context": "The method can be proven to be globally convergent using PAC style proof (see Anandkumar et al. (2014)), and has been successfully applied for Hidden Markov Model in Hsu et al. (2012) and Song et al. (2010), for Topic Modeling in Anandkumar et al. (2012), for various Natural Language Processing applications in Cohen et al. (2014), Dhillon et al. (2012) and for Spectral Experts of Linear Regression in Chaganty & Liang (2013).", "startOffset": 78, "endOffset": 355}, {"referenceID": 0, "context": "The method can be proven to be globally convergent using PAC style proof (see Anandkumar et al. (2014)), and has been successfully applied for Hidden Markov Model in Hsu et al. (2012) and Song et al. (2010), for Topic Modeling in Anandkumar et al. (2012), for various Natural Language Processing applications in Cohen et al. (2014), Dhillon et al. (2012) and for Spectral Experts of Linear Regression in Chaganty & Liang (2013). Here we propose a generative model for implicit feedback recommendation system based on Method of Moments.", "startOffset": 78, "endOffset": 428}, {"referenceID": 0, "context": "We use the tensor decomposition algorithm from Anandkumar et al. (2014), which computes the eigen-vectors of M\u03033 through power iteration followed by deflation (Algorithm 2).", "startOffset": 47, "endOffset": 72}, {"referenceID": 12, "context": "net/ , developed by the authors of Rendle et al. (2009). For every dataset, we compute the Precision@\u03c4 , Recall@\u03c4 , and Mean Average Precision (MAP@\u03c4 ) for \u03c4 \u2208 {5, 10, 20, 40, 60, 80, 100, 200, 300, 400, 500}.", "startOffset": 35, "endOffset": 56}, {"referenceID": 12, "context": "net/ , developed by the authors of Rendle et al. (2009). For every dataset, we compute the Precision@\u03c4 , Recall@\u03c4 , and Mean Average Precision (MAP@\u03c4 ) for \u03c4 \u2208 {5, 10, 20, 40, 60, 80, 100, 200, 300, 400, 500}. The Precision-Recall curves as well as MAP@\u03c4 is shown in Figure 2. We also show the computation time averaged over 10 executions for each method in Figure 2. We carry out our experiments on Unix Platform on a single machine with Intel i5 Processor (2.4GHz) and 8GB memory, and no multi-threading or other performance enhancement technique is used in the code. 3.1 TA-FENG DATASET Ta-Feng dataset consists of online grocery purchase records for the months of January, February, November and December in 2001.We combine the records of January and November resulting in a training set consisting of around 24,000 users and 21,000 products, and around 470,000 sales records. The records of February and December are combined to form the test set. BPR achieves the highest MAP of all, but MoM yields the best Precision-Recall curve with slightly worse MAP than BPR. We also compare our result for Precison@5 with that obtained using Unified Boltzman Machine (UBM) in Gunawardana & Meek (2009) in Table 2.", "startOffset": 35, "endOffset": 1198}, {"referenceID": 15, "context": "We also compare our result for MAP@500 with those of content based Music Recommendation using Deep Convolutional Neural Network (DCNN) in Van den Oord et al. (2013) for 9330 most popular songs with 20,000 users in Table 3.", "startOffset": 146, "endOffset": 165}], "year": 2017, "abstractText": "Building recommendation algorithms is one of the most challenging tasks in Machine Learning. Although there has been significant progress in building recommendation systems when explicit feedback is available from the users in the form of rating or text, most of the applications do not receive such feedback. Here we consider the recommendation task where the available data is the record of the items selected by different users over time for subscription or purchase. This is known as implicit feedback recommendation. Such data are usually available as large amount of user logs stored over massively distributed storage systems such as Hadoop. Therefore it is essential to have a highly scalable algorithm to build a recommender system for such applications. Here we propose a probabilistic algorithm that takes only two to three passes through the entire dataset to extract the model parameters during the training phase. We demonstrate the competitive performance of our algorithm in several empirical measures as well as the computation time in comparison with the existing algorithms on various publicly available datasets.", "creator": "LaTeX with hyperref package"}}}