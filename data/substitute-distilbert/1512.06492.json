{"id": "1512.06492", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Dec-2015", "title": "Remote Health Coaching System and Human Motion Data Analysis for Physical Therapy with Microsoft Kinect", "abstract": "this paper summarizes using recent experience we have made enhancing the computer vision technologies in physical therapy with economically accessible and affordable devices. we rapidly introduce the remote health coaching system we build with portable kinect. since the motion data captured by kinect is remote, we assume maximum data accuracy of kinect with respect to the high accuracy motion capture system. we also propose an outlier data removal algorithm based on the data distribution. in order to generate the kinematic parameter from this raw data captured by camera, we propose a kinematic filtering data bases on unscented kalman filter and the kinematic model of human skeleton. the proposed algorithm can obtain smooth kinematic parameter with reduced noise compared to the stimulus parameter generated from the raw motion data from kinect.", "histories": [["v1", "Mon, 21 Dec 2015 04:58:36 GMT  (159kb,D)", "http://arxiv.org/abs/1512.06492v1", "6 pages, Computer Vision for Accessible and Affordable HealthCare Workshop (ICCV2015)"]], "COMMENTS": "6 pages, Computer Vision for Accessible and Affordable HealthCare Workshop (ICCV2015)", "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["qifei wang", "gregorij kurillo", "ferda ofli", "ruzena bajcsy"], "accepted": false, "id": "1512.06492"}, "pdf": {"name": "1512.06492.pdf", "metadata": {"source": "CRF", "title": "Remote Health Coaching System and Human Motion Data Analysis for Physical Therapy with Microsoft Kinect", "authors": ["Qifei Wang", "Gregorij Kurillo", "Ferda Ofli", "Ruzena Bajcsy"], "emails": ["gregorij}@eecs.berkeley.edu", "fofli@qf.org.qa", "bajcsy@eecs.berkeley.edu"], "sections": [{"heading": "1. Introduction", "text": "In the last decade, we witness increasing interests for remote monitoring technologies in health care. Remote monitoring captures the activity and other anthropometric data from the subjects. It can perform online analysis of these data, provide health-care feedback to the subjects monitored, and also represent the data to the doctor for further analysis. One typical application is in the physical therapy, especially for the elderly subjects, the doctors need to monitor the subjects physical performance at home during the training sessions and provide further treatments based on the subjects performance.\n\u2217This research was supported by the National Science Foundation (NSF) under Grant No. 1111965.\nHuman performance capture systems have been widely studied and applied in many applications. However, traditional motion capture systems require particular system setup and markers attached to the subjects monitored which make it impractical for recording motion data at home. Other motion sensors, like the inertia sensors are sensitive to the noise make them also not suitable for motion capture in human daily activities. The emerging accessible and affordable sensing technologies, e.g. the depth sensor, such as Microsoft Kinect, make it possible to capture the humans motion data at home [1].\nRecently, we built an interactive exercise coaching system based on Microsoft Kinect [2] intended to encourage elderly adults to perform physical therapy at home. Since this type of sensors were not designed for medical purpose, the acquired motion data are usually noisy with low fidelity for the motion analysis. For example, the joint position data from Microsoft Kinect usually exhibits significant jitters caused by low depth accuracy, occlusions, ambiguity, and loss of tracking. The body segment lengths are also vary during the motion. In order to perform online analysis of subjects performance and feedback to the subjects, we further studied the motion data accuracy from Microsoft Kinect. We also studied the kinematic parameter extraction from the motion data captured by Kinect.\nThis paper is organized as following: Section 2 introduces the interactive system we have built for the remote physical therapy; Section 3 introduces the work we have done on motion data accuracy evaluation of Microsoft Kinect; Section 4 describes our work on the human kinematic parameters extraction from Kinect motion data; Conclusions are summarized in Section 5.\nar X\niv :1\n51 2.\n06 49\n2v 1\n[ cs\n.C V\n] 2"}, {"heading": "2. Interactive Exercise Coaching System", "text": "This system is built for automated exercise coaching of elderly users that would motivate them and track their physical performance when they perform physical therapy at home. The system contain four main modules: data acquisition, data processing, performance evaluation, and feedback. The pipeline of this system is shown in Fig. 1.\nIn the data acquisition module, we use the Microsoft Kinect camera to record the subjects motion. Microsoft Kinect capture both the texture and depth information of the scene and provide real-time human skeletal joint data [zhengyou zhang]. Based on the skeletal data estimated by Microsoft Kinect SDK, the data processing module remove the outlier data caused by loss tracking with the joint Gaussian and uniform distribution model introduced in Section 3. It further extracts the kinematic parameters from the skeletal motion data. The performance evaluation module does real-time motion analysis, including repetition counting, most moving joints, reachable range, and moving time, which can be further used to measure the flexibilities, endurance, strength, and balance of the subjects. The feedback module can illustrate the evaluation results in the user interface on the screen and also provide both the system automatically generated suggestions and doctors suggestion to the subject. Moreover, the system store the subjects motion data in the database for the further reference in the future."}, {"heading": "3. Kinect Data Accuracy Evaluation", "text": ""}, {"heading": "3.1. Data accuracy evaluation", "text": "In order to quantify the fidelity of the motion data captured by Microsoft Kinect, we evaluated its pose tracking with respect to the motion capture system [5]. In this study, we evaluate both the first and second generations of Microsoft Kinect which are called Kinect 1 and Kinect 2, respectively, in the following of this section. The motion capture system we use in this evaluation is the PhaseSpace optical motion capture system which can provide high precision motion capture data at 120 Hz. The Kinect 1 and\nKinect 2 capture the motion data at 20 Hz. During the evaluation, all these three systems capture the humans motion simultaneously. The motion data from these three devices are temporally synchronized using Network Time Protocol (NTP). The skeletal joint data from Kinect 1 and Kinect 2 are extracted based on the latest SDK of them. The skeletal joint data from motion capture system are obtained by the Recap2 software. We picked 20 common joints and 14 common segments among the three systems. The joints and segments picked in the evaluation are demonstrated in Fig. 2.\nDuring the evaluation, we perform 12 different exercises that six of them are in the sitting pose which are designed by the physical therapist for the elderly people with physical problems. The other six are in the standing pose which is the most common motion that people may perform in their daily live. Each exercise are performed by the subjects for five times and captured in three different view angles, including the frontal view, right side view with 30 degree and 60 degree. The degree here means the angle between the subjects frontal direction and the optical axis of the Kinect cameras.\nFor the joint position, we evaluate the offset and variance of the joint positions obtained by Kinect 1 and Kinect 2 with respect to the corresponding joint position captured by motion capture system. All the joint positions from these three systems are transformed into a unified coordinate system by the camera calibration performed before the motion capture.\nTables 1 and 2 shows the average joint offset and variance of the offset in the sitting and standing exercise, respectively.\nWe also evaluate the segment length based on the motion data. Tables 3 and 4 demonstrate the average segment length error and variance of the segment length in the sitting\nand standing exercises. The results shows that overall Microsoft Kinect 2 generates more stable skeletal joint tracking with less offset and variance as compared to Microsoft Kinect 1. The variance of the joint position and segment length are both increasing with the view angle increasing. Some joints usually have larger offset and variance than the other joints, e.g. the hip and knee joints in Kinect 1, the ankle and foot joints in Kinect 2."}, {"heading": "3.2. Outlier data removal", "text": "The joint position offsets and variance in general depend on various sources of error, such as systematic errors,\nnoise from depth quantization, occlusions, and ambiguity, etc. Compared to the multi-view motion capture system, the Kinect camera captures the motion data from a single view-point [7]. The occlusions and ambiguity from a single view-point will cause loss of tracking. Although the Kinect can infer the joint position based on the related body part [3], it is not reasonable to perform motion data analysis based on the inferred motion data due to tracking loss. Therefore, we analyze the error distribution to discriminate between the random errors and the errors due to tracking loss.\nGenerally, the random systematic errors follow the Gaussian distribution while the errors due to tracking loss can\nbe treated as outliers belonging to a uniform distribution. Therefore, we use a mixture model of a Gaussian distribution and a uniform distribution to approximate the distribution of the joint position offsets, as defined in equation 1.\np(\u03b8) = \u03c1\u00d7N(\u00b5, \u03c3) + (1\u2212 \u03c1)\u00d7 U(x1, x2). (1)\nIn equation 1, p denote the mixture distribution of joint position, \u03b8,N(\u00b5, \u03c3) andU(x1, x2) denote the Gaussian and uniform distribution, respectively, \u03c1 denotes the weighting parameter. Fig. 3 demonstrates the distribution fitting results for the right elbow in the exercise. The results show the mixture model of the Gaussian and uniform distributions overlaid on the data histograms.\nBy applying the mixture model and maximal likelihood estimation, we can remove the outlier data which satisfy the uniform distribution and make cleaner data for the further analysis. Table I demonstrates the joint offset of both standing and sitting exercises without the outlier data."}, {"heading": "4. Kinematic parameter estimation", "text": "The kinematic parameters, such as the segment length, joint quaternion, and positions are widely used in human motion analysis and human robotic interaction. For the high fidelity motion data, the kinematic parameters can be directly estimated from the skeletal joint position. However, generating the kinematic parameters from the noisy motion data captured by Kinect will propagate the noise into the following processing and analysis steps. In order to reduce the noise in the derived kinematic parameters from the\nKinect noise motion data, we propose a kinematic filtering approach in this section."}, {"heading": "4.1. Kinematic model", "text": "In motion analysis, the humans skeleton can be represented as a series joints which are connected by bones. Therefore, the each joint position can be derived by its parent joint position, the corresponding segment orientation and length. The humans skeleton can thus be represented as a kinematic chain. In this paper, we treat the root joint as the root of each kinematic chain. Based on the skeletal structure shown in Fig. 2, the SPINE, NECK, SHO L, SHO R, HIP L, and HIP R are modeled as the 3-DoF joints and their parent joints are ROOT, SPINE, NECK, NECK, ROOT, ROOT, respectively; The ELB L, ELB R, KNE L, KNE R are treated as the 1-DoF joints whose parent joints are SHO L, SHO R, HIP L, HIP R, respectively; The WRI L, WRI R, ANK L, and ANK R are the 2-DoF joints that their parent joints are ELB L, ELB R, KNE L, KNE R, respectively. For each joint, its position can be derived by its parent joint position, Tp, the segment length of its corresponding segment, lc, the relative rotation matrix of its corresponding segment, Rl, with respect to its parent segment, the rotation matrix of its parent segment, Rp, as the following function F:\n[Tc, 1] T = F (Tp, lc,Rl,Rp)\n=\n[ Rl \u00d7Rp Tp\n0 1\n] \u00d7  0 0 lc 1  (2)"}, {"heading": "4.2. Kinematic filtering", "text": "With the kinematic model presented in the last section, we propose a kinematic filtering algorithm based on Kalman filtering to generate the kinematic parameter from the Kinect motion data [6]. The input state vector is constituted by the root joint position, the segment length, and the segment rotation quaternion. The observation vector is constituted by the rest joint positions. The state transition is modeled by a random-walk process. The observation measuring function is a set of the kinematic model function as defined by equation 2. Since the state transition and the observation measuring functions are nonlinear, we apply the Unscented Kalman Filter (UKF) [4] for the filtering. Since the segment lengths for a certain person are constants, we propose a four-pass UKF to meet with this constraints. In the first forward pass, the UKF is defined by the following functions\nx(t) = x(t\u2212 1) + \u03b4(t) (3)\ny(t) = F(x(t)) + \u03b5(t) (4)\nIn equations 3 and 4, the x(t) and x(t + 1) denote the state vector at time t and t + 1, respectively, \u03b4 denote the random term in the random walk process, y denote the observation vector, \u03b5 denotes the observation noise. In the first backward pass, the observation measuring function is the same as equation 4. The state transition function is defined as\nx(t) = x(t+ 1) + \u03b4(t) (5)\nAfter the first two pass, the length of each segment are assigned as a constant in the following forward and backward passes. The covariance and the random terms in the random walk process of the segment lengths are all set to zeros.\nFig. 4 demonstrates the filtering results of UKF for the motion data from Kinect 1. The segment quaternion curves after filtering are much smoother than the input noisy data and also demonstrate strong periodic pattern which is in accordance to the input motion. Therefore, the UKF based on the kinematic model is a practical solution to extract kinematic parameters."}, {"heading": "5. Conclusions", "text": "This paper summarize the recent progress in the motion analysis for physical therapy with the affordable and accessible device like Microsoft Kinect. Based on preliminary studies, our remote health coaching system receive positive feedback from the users for its accessibility and interaction. Since the motion data captured by Microsoft Kinect is\nnoisy, we further studied the data fidelity of each joint position and segment length. We also propose a mixture model to distinguish the outlier data caused by loss of tracking. It can helps to reduce the noise in the further motion data analysis. Finally, the kinematic filtering based on UKF provide a solution to extract smooth kinematic parameters from the noisy motion data."}], "references": [{"title": "A review on technical and clinical impact of microsoft Kinect on physical therapy and rehabilitation", "author": ["H.M. Hondori", "M. Khademi"], "venue": "Journal of Medical Engineering,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Design and evaluation of an interactive exercise coaching system for older adults: Lessons learned", "author": ["F. Ofli", "G. Kurillo", "S. Obdrzalek", "R. Bajcsy", "H. Jimison", "M. Pavel"], "venue": "IEEE Journal of Biomedical and Health Informatics,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Real-time human pose recognition in parts from single depth images", "author": ["J. Shotton", "A. Fitzgibbon", "M. Cook", "T. Sharp", "M. Finocchio", "R. Moore", "A. Kipman", "A. Blake"], "venue": "In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "The unscented kalman filter for nonlinear estimation", "author": ["E. Wan", "R. Van Der Merwe"], "venue": "In Proceedings of IEEE Adaptive Systems for Signal Processing, Communications, and Control Symposium (AS-SPCC),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2000}, {"title": "Evaluation of pose tracking accuracy in the first and second generations of microsoft kinect", "author": ["Q. Wang", "G. Kurillo", "F. Ofli", "R. Bajcsy"], "venue": "arXiv preprint arXiv:1512.04134,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Unsupervised temporal segmentation of repetitive human actions based on kinematic modeling and frequency analysis", "author": ["Q. Wang", "G. Kurillo", "F. Ofli", "R. Bajcsy"], "venue": "In International Conference on 3D Vision", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Microsoft Kinect sensor and its effect", "author": ["Z. Zhang"], "venue": "MultiMedia, IEEE,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "the depth sensor, such as Microsoft Kinect, make it possible to capture the humans motion data at home [1].", "startOffset": 103, "endOffset": 106}, {"referenceID": 1, "context": "Recently, we built an interactive exercise coaching system based on Microsoft Kinect [2] intended to encourage elderly adults to perform physical therapy at home.", "startOffset": 85, "endOffset": 88}, {"referenceID": 4, "context": "In order to quantify the fidelity of the motion data captured by Microsoft Kinect, we evaluated its pose tracking with respect to the motion capture system [5].", "startOffset": 156, "endOffset": 159}, {"referenceID": 6, "context": "Compared to the multi-view motion capture system, the Kinect camera captures the motion data from a single view-point [7].", "startOffset": 118, "endOffset": 121}, {"referenceID": 2, "context": "Although the Kinect can infer the joint position based on the related body part [3], it is not reasonable to perform motion data analysis based on the inferred motion data due to tracking loss.", "startOffset": 80, "endOffset": 83}, {"referenceID": 5, "context": "With the kinematic model presented in the last section, we propose a kinematic filtering algorithm based on Kalman filtering to generate the kinematic parameter from the Kinect motion data [6].", "startOffset": 189, "endOffset": 192}, {"referenceID": 3, "context": "Since the state transition and the observation measuring functions are nonlinear, we apply the Unscented Kalman Filter (UKF) [4] for the filtering.", "startOffset": 125, "endOffset": 128}], "year": 2015, "abstractText": "This paper summarizes the recent progress we have made for the computer vision technologies in physical therapy with the accessible and affordable devices. We first introduce the remote health coaching system we build with Microsoft Kinect. Since the motion data captured by Kinect is noisy, we investigate the data accuracy of Kinect with respect to the high accuracy motion capture system. We also propose an outlier data removal algorithm based on the data distribution. In order to generate the kinematic parameter from the noisy data captured by Kinect, we propose a kinematic filtering algorithm based on Unscented Kalman Filter and the kinematic model of human skeleton. The proposed algorithm can obtain smooth kinematic parameter with reduced noise compared to the kinematic parameter generated from the raw motion data from Kinect.", "creator": "LaTeX with hyperref package"}}}