{"id": "1512.07074", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Dec-2015", "title": "Move from Perturbed scheme to exponential weighting average", "abstract": "in an online decision problem, one makes attempts often joining a pool of decision sequence called experts but without knowledge of the future. after each step, one pays a cost based on the decision and observed rate. one next goal assumed be to perform as well as the best expert in the pool. the modern and well - known way to show this limitation is the algorithm of exponential weighting. simply, now, another algorithm called follow us path leader problem developed and achieved about those same page. in our work, we first show optimal requirements shared in common by the two algorithms which explain the similarities on the performance. next we will show that for a specific perturbation, the two algorithms are identical. finally, we identify with some examples that follow - the - leader style algorithms extend naturally to a lower class of structured online problems for which the exponential algorithms are inefficient.", "histories": [["v1", "Tue, 22 Dec 2015 13:18:17 GMT  (571kb)", "http://arxiv.org/abs/1512.07074v1", "10 pages"]], "COMMENTS": "10 pages", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["chunyang xiao"], "accepted": false, "id": "1512.07074"}, "pdf": {"name": "1512.07074.pdf", "metadata": {"source": "CRF", "title": "Move from Perturbed scheme to exponential weighting average", "authors": ["Chunyang Xiao"], "emails": [], "sections": [{"heading": null, "text": "1 Online problem setting\nIn an online decision problem, one makes decisions often with a pool of decisions\u2019 sequence called experts but without knowledge of the future. After each step, one pays a cost based on the decision and observed state. As there is no prior knowledge on the accuracy of experts in the pool, one reasonable goal for this general problem would be to perform as well as the best expert in the pool after a number of steps. More precisely, we consider the following mathematical problem:\n\u2022 A set S of experts is given.\n\u2022 The algorithm interacts with an adversary in a series of T steps.\n\u2022 In each step j, the algorithm picks an expert \ud835\udc65\ud835\udc57 \u2208 \ud835\udc46 , and the adversary selects\na cost function \ud835\udc50\ud835\udc57: S \u2192 R. The adversary could be adaptive, in that \ud835\udc50\ud835\udc57 may depend on {\ud835\udc65\ud835\udc56 : \ud835\udc56 < \ud835\udc57}.\n\u2022 The algorithm incurs cost , and receives as feedback the value of \ud835\udc50\ud835\udc57(\ud835\udc65\ud835\udc57).\n\u2022 Minimize the algorithm\u2019s regret which is defined as difference in expected cost\nbetween the algorithm\u2019s sequence of choices and that of best fixed expert in S:\nThis version formulates the problem typically as predicting from expert advice problem. We consider here that we could only choose from the decision space of the experts. And we consider here only the full transparent model, i.e. after each step, all\nOne immediate consequence of this hypothesis is that for general weighted average forecaster, the given weighted average may not be in the decision space. However, we could get around this problem by reinterpreting the weights not as real weights but the probabilities in decision space. This is little bit more complicated than working in a continuous space but this framework will allow us to compare general weighted average forecaster with other forecasters perturbed leading expert more easily. Besides that, it occurs often that the decision space happens to be all the experts\u2019 decisions, i.e. at practice, we have to choose one expert to listen to.\nAnother remark that the problem that we describe here is very general and of course could include many specific kinds of problems. For example, in shortest paths problems, \ud835\udc50\ud835\udc57 are linear functions [1]. For certain algorithms (follow perturbed leading expert, for example), the functions min \ud835\udc65\u2208\ud835\udc46 \u2211 \ud835\udc38[\ud835\udc50\ud835\udc57(\ud835\udc65\ud835\udc57)]\ud835\udc57\ud835\udc57 would be needed to be calculated efficiently. This is really not a strict condition, as it satisfies for at least all convex functions.\n2 Two approaches\nThe modern and well known way to tackle the problem is exponential weighting scheme that have been discovered and rediscovered in many areas. A survey of these results could be found in [3]. However, in recent years, another scheme called follow perturbed leading expert has been discovered and achieved similar performance [2]. In this section, we will detail the two different approaches with some variants of the two approaches. Some theoretical bounds which have already been proven would also be indicated in this section. We remark in particularly some similarities in theoretical bounds for two approaches which suggest some relationship between the two approaches. This relationship will be studied further in the next section.\nAs its name suggests, weighted average forecaster forecasts the future based on a weighted average of the prediction of experts. Each expert is associated with a weight that we assign with its historic performance (the weight could be naturally updated after each step). After that, we take our decision as the weighted decision of experts. When the space is convex, it is possible for the forecaster to give rise to a new predicted decision value, different from decisions coming from all experts. Otherwise, in the case that we consider here, the weight would be considered as probability to take certain precisions. For example, in algorithm 1, the term \ud835\udc52\u2212\ud835\udefd\ud835\udc3f\ud835\udc56 ,\ud835\udc61\u22121 \u2211 \ud835\udc52\u2212\ud835\udefd\ud835\udc3f\ud835\udc56 ,\ud835\udc61\u22121\ud835\udc5b\ud835\udc56=1 is the probability (weight) to take the decision of expert i at step t.\nThe exponential weighted average forecaster we consider is the following:\nAlgorithm 1 weighted average forecaster\nAt each t, calculate loss of each expert amongst n experts:\n\ud835\udc3f\ud835\udc56,\ud835\udc61\u22121 = \u2211 \ud835\udc50\ud835\udc56,\ud835\udc57 \ud835\udc61\u22121 \ud835\udc57=1 (\ud835\udc53\ud835\udc56,\ud835\udc57), \ud835\udc53\ud835\udc56,\ud835\udc57 is the choice of expert i at step j\nChoose the decision of expert i at t with probability:\n\ud835\udc52\u2212\ud835\udefd\ud835\udc3f\ud835\udc56 , \ud835\udc61 \u2212 1\n\u2211 \ud835\udc52\u2212\ud835\udefd\ud835\udc3f\ud835\udc56 , \ud835\udc61 \u2212 1\ud835\udc5b\ud835\udc56=1\nFirst let\u2019s remark that the weighted average is a generalization of the randomized weighted majority algorithm that appeared in the survey of Blum [3]. The problem considered there is more strict, the loss would be specified only by 0 or 1. In other words, there is only one right answer and one wrong answer. At each step, randomized weighted majority algorithm updates the weight of wrong answer by multiplying its weight by a constant \ud835\udefe \u2264 1. By taking \ud835\udefe = \ud835\udc52\u2212\ud835\udefd it could be easily seen that weighted majority is just a special case of weighted average forecaster that we consider here. For randomized weighted majority algorithm, a bound is proven with the following theorem:\nTheorem 1 On any sequence of trials, the expected loss noted M made by\nrandomized weighted majority algorithm satisfies:\n\ud835\udc40 \u2264 \ud835\udc5a\ud835\udc59\ud835\udc5b (\n1 \ud835\udefd ) + \ud835\udc59\ud835\udc5b\ud835\udc5b\n1 \u2212 \ud835\udefd\nwhere n is the number of experts and m the minimal loss of all the experts\nso far.\nNow, we will consider an alternative approach to tackle the problem. Instead of taking a weighted average of all the experts, the most intuitive way would be to follow the best leading expert. However, this very intuitive idea does not perform well on some very simple cases. Consider a two-expert system that one always predicts 1 and the other always predicts 0. The cost sequence is (0,0.5) followed by alternating (1,0) and (0,1). Then, after n step, following the leader would lead to a loss of n well the best expert generates a loss of only n/2. Remark that weighted average performs well in this special case (as well as theory tells) because it leaves a possibility to the expert that performs a little less well in the history and thus avoid the tragedy of choosing always the bad expert. Another way to leave this possibility to all the experts and to not fix one is to introduce a perturbation before making the decision. This idea leads us to the following perturbed leading expert algorithm presented in the paper of Adam Kalai [2].\nAlgorithm 2 follow the perturbed leading expert\nOn each step t = 1, 2, ...\n1. For each expert \ud835\udc52 \u2208 {1,2, \u2026 }, pick \ud835\udc5d\ud835\udc61[\ud835\udc52] \u2265 0 from a distribution.\n2. Choose expert with minimal \ud835\udc50\ud835\udc61[\ud835\udc52] \u2212 \ud835\udc5d\ud835\udc61[\ud835\udc52], where \ud835\udc50\ud835\udc61[\ud835\udc52] = total cost of expert\ne so far.\nRemark first that we have a great amount of liberty here in this algorithm. The distribution is free to our choice and indeed, different choices of distributions induce different bounds. And according to situations, some distributions may be preferred comparing to others. Secondly, if this algorithm obtains about the same performance as weighted average algorithm, it would be still more interesting than the average weighted version. Observe that what we need here to choose the minimum is only a minimization oracle [1] as we do not update weight and thus modify the structure of the problem. Put it into another way, we have decoupled the problem with on the one hand, the search of perturbation, and on the other hand, a deterministic optimization problem which has been elegantly solved in various domains. Thus, our algorithm leads generally to a gain in speed. This point is particularly illustrated in the last section of applications with perturbation schemes.\nTo show the bound results of this class of algorithms. Let note D the decision domain and S the cost domain, |\ud835\udc65|1 as norm \ud835\udc3f 1 of x. The following theorem is presented in [2] for the case when the cost functions are all linear. It consists of a theorem which gives the bound for uniform and exponential distribution (noted FPL and FPL* respectively):\n\ud835\udc37 \u2265 |\ud835\udc51 \u2212 \ud835\udc51\u2032|, for all \ud835\udc51, \ud835\udc51\u2032 \u2208 \ud835\udc37 \ud835\udc45 \u2265 |\ud835\udc51. \ud835\udc60|, for all \ud835\udc51 \u2208 \ud835\udc37, \ud835\udc60 \u2208 \ud835\udc46 \ud835\udc34 \u2265 |\ud835\udc60|1, for all \ud835\udc60 \u2208 \ud835\udc46\nTheorem 2 Let s1, s2, ... , st be a cost sequence.\n(a) Running FPL with parameter \ud835\udf16 \u2264 1 gives\n(b) For non-negative \ud835\udc37, \ud835\udc46 \u2208 \ud835\udc45+ \ud835\udc5b , FPL* gives\nRemark that in particular, the bound given by FPL* resembles a lot the bound for randomized weighted majority given in theorem 1. We will show in the next section that indeed there exists a strong relationship between these two approaches. This relationship would be not only important in theoretical point of view but also important in practice. As the penalty of weights offers more insight on what kind of penalization we are applying whereas the follow perturbed leading expert could be likely much faster in running time. We will come up to this point later on.\n3 Relationship between two approaches\nIn this section, we show the properties which are shared by both FPL* and weighted average forecaster shown in algorithm 1. Recall the simple fact that weighted average forecaster is a generalization of weighted majority algorithm. After that, we apply the same techniques to deduce a \u201cweighted average forecaster\u201d for uniform distribution. The calculation to process the conversion will be shown when we deduce the first example.\nFirst consider the weighted average forecaster. At each step t, the choice of our algorithm is totally characterized by the probability (weight) attributed to the decision of each expert. Thus, it is also totally characterized by the probability ratio between any two probability (weight) . According to weighted average forecaster algorithm, at step t, this ratio could be written as:\n\ud835\udc43(\ud835\udc52\ud835\udc65\ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc61\ud835\udc56) \ud835\udc43(\ud835\udc52\ud835\udc65\ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc61\ud835\udc57) = \ud835\udc52\u2212\ud835\udefd(\ud835\udc3f\ud835\udc56,\ud835\udc61\u22121\u2212\ud835\udc3f\ud835\udc57,\ud835\udc61\u22121)\nThis ratio has an intuitive explanation. When \ud835\udc3f\ud835\udc56,\ud835\udc61\u22121 \u2212 \ud835\udc3f\ud835\udc57,\ud835\udc61\u22121 \u2264 0 , expert i is chosen with a probability much larger that expert j. That means we prefer the expert that generated small loss historically yet leave always a possibility to choose an expert which performed less well in the past. This possibility move towards one when the difference becomes negligible. Seen in the formula, the probability ratio is quantified as the exponential of the loss difference.\nNow let\u2019s examine the case of algorithm follow the perturbed leading expert. Intuitively, as a perturbation is added to each of the experts, we know that a possibility is generated to choose each expert. It is question to appropriately choose the perturbation distribution so that the previous probability ratio found in weighted average forecaster remains. In the next, we will show that the exponential distribution is a distribution that generates very similar conditions compared to the above condition.\nNote c the loss difference between expert i and expert j. Thus, = \ud835\udc3f\ud835\udc56,\ud835\udc61\u22121 \u2212 \ud835\udc3f\ud835\udc57,\ud835\udc61\u22121 . Without loss of generality, we suppose here that \ud835\udc50 \u2265 0 . Let us calculate the probability that the algorithm choose expert i over the other expert j.\n(1)\nwhere \ud835\udc51\ud835\udc56 and \ud835\udc51\ud835\udc57 are instances generated by independent exponential distributions. For the inequality holds, we consider for example \ud835\udc51\ud835\udc56 take a value v and \ud835\udc51\ud835\udc57 take a value more than v + c . As \ud835\udc51\ud835\udc56 and \ud835\udc51\ud835\udc57 are independent, the joint probability of the two events are written simply as the multiplication of the two terms. Thus, the above probability is the sum over all the possible v when the distribution \u00b5 has probability mass functions (particularly, it takes a finite number of values):\nIn the case that the distribution has probability density functions (particularly, it\ntakes an infinite number of values), the sum becomes an integral:\n\ud835\udc43(\ud835\udc50 + \ud835\udc51\ud835\udc56 \u2264 \ud835\udc51\ud835\udc57) = \u222b \ud835\udc53\ud835\udf07(\ud835\udc63) (\u222b \ud835\udc53\ud835\udf07 )(\ud835\udc65) \ud835\udc51\ud835\udc65) \ud835\udc51\ud835\udc63 , \ud835\udc65 \u2265 \ud835\udc63 + \ud835\udc50\nNow take the exponential distribution into the above equation (2) , we have:\n\ud835\udc43(\ud835\udc50 + \ud835\udc51\ud835\udc56 \u2264 \ud835\udc51\ud835\udc57) = \u222b \ud835\udf16\ud835\udc52 \u2212\ud835\udc65\ud835\udf16 (\u222b \ud835\udf16\ud835\udc52\u2212\ud835\udc66\ud835\udf16\n+\u221e\n\ud835\udc65+\ud835\udc50\n\ud835\udc51\ud835\udc66) \ud835\udc51\ud835\udc65 +\u221e\n0\n= \u222b \ud835\udf16\ud835\udc52\u2212\ud835\udc66\ud835\udf16 . \ud835\udf16\ud835\udc52\u2212(\ud835\udc65+\ud835\udc50)\ud835\udf16\ud835\udc51\ud835\udc65 +\u221e\n0\n= 1\n2 \ud835\udc52\u2212\ud835\udf16\ud835\udc65\nLet us put weighted average forecaster probability that we take now in the same\nform:\n\ud835\udc43(\ud835\udc52\ud835\udc65\ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc61\ud835\udc56)\n\ud835\udc43(\ud835\udc52\ud835\udc65\ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc61\ud835\udc56) + \ud835\udc43(\ud835\udc52\ud835\udc65\ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc61\ud835\udc57) =\n\ud835\udc52\u2212\ud835\udefd\ud835\udc50\n1 + \ud835\udc52\u2212\ud835\udefd\ud835\udc50\nThe two formulas are quite similar in the way that:\n\u2022 When the c is near zero, the two ratio gives unbiased probability 0.5\n\u2022 When the c is large, the two ratio gives an exponential dependence, the\nalgorithm follow the perturbed leader add a factor 0.5 compared to weighted average forecaster.\nFor another example, let us consider the algorithm follow the perturbed leader with uniform distribution in [0,\ud835\udf16]. In this case, it makes sense to suppose that \ud835\udc50 \u2264 \ud835\udf16 as otherwise, the probability of choose expert i over expert j would be 0. We suppose \ud835\udc50 \u2265 0 as usual, then by following the same calculus by using be 0. We suppose equation (1) and (2), we have:\n\ud835\udc43(\ud835\udc52\ud835\udc65\ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc61\ud835\udc56)\n\ud835\udc43(\ud835\udc52\ud835\udc65\ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc61\ud835\udc56) + \ud835\udc43(\ud835\udc52\ud835\udc65\ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc61\ud835\udc57) = \ud835\udc43(\ud835\udc50 + \ud835\udc51\ud835\udc56 \u2264 \ud835\udc51\ud835\udc57)\n= \u222b 1\n\ud835\udf16 (\u222b\n1 \ud835\udf16 \ud835\udc51\ud835\udc66\n\ud835\udf16\n\ud835\udc65+\ud835\udc50\n) \ud835\udc51\ud835\udc65 \ud835\udf16\u2212\ud835\udc50\n0\n= 1 \u2212 1\n2\ud835\udf162 (\ud835\udf162 \u2212 \ud835\udc502 + 2\ud835\udf16\ud835\udc50)\nWe could easily verify that c = 0 corresponds to a probability ratio 0.5, and \ud835\udc50 = \ud835\udf16 corresponds to a probability ratio 0. It means that the model becomes deterministic from a certain threshold \ud835\udf16 in contrary to the weighted average forecasting and the follow exponential perturbed leading expert algorithm. Meanwhile, we could note that the penalization is in the quadratic form. Thus compared to the previous perturbation, we have less penalization in loss here and lose probability or certain experts from a threshold. These two points are supposed to explain why this model possesses a bound that still depends on the step T.\n4 Towards exponential weighting\nThe distribution that we consider here is Gumbel distribution. Before the calculus, we will give a brief description about gumbel distribution which inspires us to consider this particular distribution. Gumbel distribution is frequently used to model the distribution of the maximum (or the minimum) of a number of samples of various distributions, thus such a distribution might be used to represent the distribution of the maximum level of a river in a particular year if there was a list of maximum values for the past ten years. It is a particular case of the generalized extreme value distribution. The very property that leads us to consider this distribution is stated as the following:\nProperty The difference of two Gumbel-distributed random variables has a\nlogistic distribution.\nThis gives birth directly to the perturbation result on probability ratio:\n\ud835\udc43(\ud835\udc52\ud835\udc65\ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc61\ud835\udc56)\n\ud835\udc43(\ud835\udc52\ud835\udc65\ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc61\ud835\udc56) + \ud835\udc43(\ud835\udc52\ud835\udc65\ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc61\ud835\udc57) = \ud835\udc43(\ud835\udc51\ud835\udc57 \u2212 \ud835\udc51\ud835\udc56 \u2265 \ud835\udc50) =\n\ud835\udc52 \u2212\n\ud835\udc50 \ud835\udefd\n1 + \ud835\udc52 \u2212\n\ud835\udc50 \ud835\udefd\nAs in the previous section, c is the loss difference between expert i and expert j\nrealized until considered step. It is obvious that by replacing \u03b2 here by 1\n\ud835\udefd , we obain the\nweighting average result. Thus we announce the following theorem:\nTheorem 3 The follow perturbed leading expert algorithm with perturbing\ndistribution as gumbel distribution \ud835\udc52\u2212\ud835\udc67\u2212\ud835\udc52 \u2212(\ud835\udc65\u2212\ud835\udf07)/\ud835\udefd is equivalent to an weighted majority algorithm with \ud835\udefd\u2032 = 1\n\ud835\udefd .\n5 Application of perturbation schemes\nThese follow-the-leader style algorithms extend naturally to a large class of structured online problems for which the exponential weighted average algorithms are inefficient[2]. This section illustrates some of these examples.\n5.1 Online shortest path problem\nIn this problem, one has a directed graph and a fixed pair of nodes (s, t). Each period, one has to pick a path from s to t, and then the times on all the edges are revealed. The per-period cost is the sum of the times on the edges of the chosen path. This problem could be viewed as an expert problem where each path consists of an expert. Naive weighted average algorithm could be applied to this problem but has high complexity as each (expert) path should be considered and their weights should be updated. Some clever schemes have been developed[5], but now let us consider just the algorithm Follow the perturbed leading expert:\nOn each period t = 1, 2,...,\n1. For each edge e, pick pt [e] randomly from an gumbel distribution. 2. Use the shortest path in the graph with weights ct [e]+ pt [e] on edge\ne, where ct [e] = total time on edge e so far.\nIt could be seen that this algorithm does not involve any update weight calculation.\nAs no weight update is used, what we need, as mentioned in[1], is just an optimization oracle that we have here Bellman algorithm, for example. And this algorithm achieves similar bounds as in [5].\n5.2 Image segmentation\nImage segmentation is a middle level image processing problem. One very popular approach to tackle this problem is to use MRF (Markov Random Fields). While there are many researches on the deterministic minimization on these fields and achieve good results, the accurate probability inference behind these problems generally require very time consuming MCMC techniques. The article [4] shows that with the addition of perturbation, the probability inference could be carried on easily. Besides, these techniques could be extended to parameter estimation by using moment matching rule.\n6 Conclusion\nWe show that for expert advice problem, the follow perturbed leading expert algorithm could be equivalent to the modern exponential weighted average algorithm by carefully choosing the perturbation distribution. We show that different perturbation distribution may be chosen according to different circumstances and the distribution choice could be interpreted as the penalization on the weights when we interpret the perturbed leading expert algorithm as a weighted average algorithm. We further argue that the separation of the online optimization problem into its online and offline components which appears in follow perturbed leading expert algorithm is helpful as only deterministic optimization oracle is needed for offline components.\nReferences [1] Baruch Awerbuch and Robert D Kleinberg. Adaptive Routing with Endto-End\nfeedback : Distributed Learning and Geometric Approaches. (x), 2004.\n[2] Adam Kalai and Santosh Vempala. Efficient algorithms for online decision\nproblems. Journal of Computer and System Sciences, 71(3):291\u2013307, October 2005.\n[3] Avrim L.Blum. On-line algorithms in machine learning. 1997.\n[4] George Papandreou and Alan L. Yuille. Perturb-and-MAP random fields: Using\ndiscrete optimization to learn and sample from energy models. 2011 International Conference on Computer Vision, pages 193\u2013200, November 2011.\n[5] Eiji Takimoto and Manfred K. Warmuth. Predicting nearly as well as the best\npruning of a planar decision graph. Theoretical Computer Science, 288(2):217\u2013235, October 2002."}], "references": [{"title": "Adaptive Routing with Endto-End feedback : Distributed Learning and Geometric Approaches", "author": ["Baruch Awerbuch", "Robert D Kleinberg"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2004}, {"title": "Efficient algorithms for online decision problems", "author": ["Adam Kalai", "Santosh Vempala"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2005}, {"title": "On-line algorithms in machine learning", "author": ["Avrim L.Blum"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1997}, {"title": "Perturb-and-MAP random fields: Using discrete optimization to learn and sample from energy models", "author": ["George Papandreou", "Alan L. Yuille"], "venue": "International Conference on Computer Vision,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Predicting nearly as well as the best pruning of a planar decision graph", "author": ["Eiji Takimoto", "Manfred K. Warmuth"], "venue": "Theoretical Computer Science,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2002}], "referenceMentions": [{"referenceID": 0, "context": "For example, in shortest paths problems, cj are linear functions [1].", "startOffset": 65, "endOffset": 68}, {"referenceID": 2, "context": "A survey of these results could be found in [3].", "startOffset": 44, "endOffset": 47}, {"referenceID": 1, "context": "However, in recent years, another scheme called follow perturbed leading expert has been discovered and achieved similar performance [2].", "startOffset": 133, "endOffset": 136}, {"referenceID": 2, "context": "First let\u2019s remark that the weighted average is a generalization of the randomized weighted majority algorithm that appeared in the survey of Blum [3].", "startOffset": 147, "endOffset": 150}, {"referenceID": 1, "context": "This idea leads us to the following perturbed leading expert algorithm presented in the paper of Adam Kalai [2].", "startOffset": 108, "endOffset": 111}, {"referenceID": 0, "context": "Observe that what we need here to choose the minimum is only a minimization oracle [1] as we do not update weight and thus modify the structure of the problem.", "startOffset": 83, "endOffset": 86}, {"referenceID": 1, "context": "The following theorem is presented in [2] for the case when the cost functions are all linear.", "startOffset": 38, "endOffset": 41}, {"referenceID": 1, "context": "These follow-the-leader style algorithms extend naturally to a large class of structured online problems for which the exponential weighted average algorithms are inefficient[2].", "startOffset": 174, "endOffset": 177}, {"referenceID": 4, "context": "Some clever schemes have been developed[5], but now let us consider just the algorithm Follow the perturbed leading expert:", "startOffset": 39, "endOffset": 42}, {"referenceID": 0, "context": "As no weight update is used, what we need, as mentioned in[1], is just an optimization oracle that we have here Bellman algorithm, for example.", "startOffset": 58, "endOffset": 61}, {"referenceID": 4, "context": "And this algorithm achieves similar bounds as in [5].", "startOffset": 49, "endOffset": 52}, {"referenceID": 3, "context": "The article [4] shows that with the addition of perturbation, the probability inference could be carried on easily.", "startOffset": 12, "endOffset": 15}], "year": 2015, "abstractText": "In an online decision problem, one makes decisions often with a pool of decisions\u2019 sequence called experts but without knowledge of the future. After each step, one pays a cost based on the decision and observed rate. One reasonal goal would be to perform as well as the best expert in the pool. The modern and well-known way to attain this goal is the algorithm of exponential weighting. However, recently, another algorithm called follow the perturbed leader is developed and achieved about the same performance. In our work, we first show the properties shared in common by the two algorithms which explain the similarities on the performance. Next we will show that for a specific perturbation, the two algorithms are identical. Finally, we show with some examples that follow-the-leader style algorithms extend naturally to a large class of structured online problems for which the exponential algorithms are inefficient. 1 Online problem setting In an online decision problem, one makes decisions often with a pool of decisions\u2019 sequence called experts but without knowledge of the future. After each step, one pays a cost based on the decision and observed state. As there is no prior knowledge on the accuracy of experts in the pool, one reasonable goal for this general problem would be to perform as well as the best expert in the pool after a number of steps. More precisely, we consider the following mathematical problem: \u2022 A set S of experts is given. \u2022 The algorithm interacts with an adversary in a series of T steps. \u2022 In each step j, the algorithm picks an expert xj \u2208 S , and the adversary selects a cost function cj: S \u2192 R. The adversary could be adaptive, in that cj may depend on {xi : i < j}. \u2022 The algorithm incurs cost , and receives as feedback the value of cj(xj). \u2022 Minimize the algorithm\u2019s regret which is defined as difference in expected cost between the algorithm\u2019s sequence of choices and that of best fixed expert in S:", "creator": "Microsoft\u00ae Word 2013"}}}