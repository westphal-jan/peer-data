{"id": "1601.01660", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Jan-2016", "title": "An Automaton Learning Approach to Solving Safety Games over Infinite Graphs", "abstract": "we propose a method to program finite - state reactive controllers for systems whose interactions with continuously adversarial behaviour involves modeled by infinite - duration two - player computation over ( endless ) infinite graphs. the proposed method targets safety games with infinitely many states or with such a large array of states that it would be impractical - - - if surely impossible - - - for conventional synthesis techniques that work on the entire state space. we resort to making finite - state controllers for such systems through an automata learning approach, utilizing a symbolic representation of one underlying game that is based on finite automata. throughout the learning process, the learner picks an approximation whenever the winning region ( represented as a finite map ) and refines effectively using different types of counterexamples provided by the teacher until every satisfactory controller can also derived ( if configuration exists ). we present their symbolic representation of sequential games ( inspired by regular model checking ), propose implementations of the learner and teacher, and evaluate their performance on examples motivated specifically robotic problem planning in dynamic environments.", "histories": [["v1", "Thu, 7 Jan 2016 20:42:19 GMT  (97kb,D)", "http://arxiv.org/abs/1601.01660v1", null]], "reviews": [], "SUBJECTS": "cs.FL cs.LG cs.LO", "authors": ["daniel neider", "ufuk topcu"], "accepted": false, "id": "1601.01660"}, "pdf": {"name": "1601.01660.pdf", "metadata": {"source": "CRF", "title": "An Automaton Learning Approach to Solving Safety Games over Infinite Graphs", "authors": ["Daniel Neider", "Ufuk Topcu"], "emails": [], "sections": [{"heading": null, "text": "I. INTRODUCTION\nWe propose an automata learning-based method to construct reactive controllers subject to safety specifications. We model the interaction between a controlled system and its possibly adversarial environment as a two-player game over a graph [1]. We consider games over infinite graphs. In this setting, the conventional techniques for reactive controller synthesis (e.g., fixed-point computations) are not applicable anymore. Therefore, we resort to a learning-based approach for constructing finite-state reactive controllers for the controlled system. The learning takes place in a setting akin to counterexample-guided inductive synthesis (CEGIS) [2] between a teacher, who has knowledge about the safety game in question, and a learner, whose objective is to identify a controller using information disclosed by the teacher in response to (incorrect) conjectures.\nA natural context for the proposed method is one in which the interaction between the controlled system and its environment is so complex that it can be represented only by graphs with infinitely many vertices (e.g., motion planning over unbounded grid worlds) or \u201cpractically infinitely many\" states (i.e., the number of possible configurations is so large that the game becomes impractical for conventional techniques). Additionally, in situations where a complete description of the game is not available in a format amenable to existing game solvers [3], [4], there may still exist human experts (or automated oracles, as in Section IV) who have sufficient insight into how the controlled system should behave and can act as teacher.\nWe focus on games with safety specifications, which already capture practically interesting properties (e.g., safety and bounded-horizon reachability). However, games over infinite graphs require special attention on the representation and manipulation of the underlying graph structure. Hence, one of our main contributions is a symbolic representation of safety games, called rational safety games, that follows the idea of regular model checking [5] in that it represent sets of vertices by regular languages and edges by so-called rational relations.\nA straightforward approach to solve (rational) safety games is computing a winning set for the controlled system (i.e., a safe subset of the vertices in which the system can force to remain). Once a winning set is computed, a strategy for the system is determined by choosing its moves (in each of its turns) to stay inside the set, which is possible regardless of the moves of the environment. We use winning sets as a proxy for an actual controller, and the objective of the learning task is the construction of a winning set. In fact, learning a winning set rather than a controller results in more permissive strategies (and potentially smaller solutions) as the moves of the system do not need to be fixed during the learning process.\nWe develop a framework for learning winning sets for rational safety games and particular implementations of a teacher and learner. The actual learning works iteratively. In each iteration, the learner conjectures a winning set, represented as a deterministic finite automaton. The teacher performs a number of checks and returns, based on whether the conjecture passes the checks, a counterexample. Following the ICE learning framework [6] and partially deviating from the classical learning frameworks for regular languages [7], [8], the counterexample may be one of the following four types: positive, negative, existential implication and universal implication counterexamples. Based on the response from the teacher, the learner updates his conjecture. If the conjecture passes all checks (i.e., the teacher returns no counterexample), the learning process terminates with the desired controller.\nA learning-based approach offers several advantages: First, even though the underlying game may be prohibitively large, the reactive controller necessary to realize the specifications often has a compact representation in practice; for example, depending on the given task specification in a robotic motion planning scenario, only a small subset of all possible rich interactions between the robot and its dynamic environment over a possibly large workspace is often relevant. Second, since\nar X\niv :1\n60 1.\n01 66\n0v 1\n[ cs\n.F L\n] 7\nJ an\n2 01\n6\nlearning-based approaches usually identify \u201csmall\" solutions (as they typically produce intermediate conjectures of increasing size), their runtime mainly depends on the size of the solution rather than the size of the underlying game. Third, learningbased approaches reduce the gap between human designers and construction of reactive controllers by hiding the complexity of the underlying game from the learner.\nFinally, we demonstrate the use of our overall learning-based framework empirically on a series of examples motivated by robotic motion planning in dynamic environments.\nRelated Work: Games over infinite graphs have been studied in the past, predominantly in the case of games over pushdown graphs [9]. The games we consider here, however, are played over a richer class of graphs and require different techniques to be solved. Also, a constraint-based approach to solving games over infinite graphs has recently been proposed [10].\nLearning-based techniques for games over infinite graphs have already been studied in the context of reachability games [11]; in fact, our symbolic representation of safety games is a generalization of the representation proposed there. In the context of safety games, recent work [12] has already demonstrated the ability of learning-based approaches to extract small reactive controllers from a priori constructed controllers with possibly large number of states. In this work, we by-pass the a priori construction of possibly large reactive controllers by learning (an appropriate representation of) a controller directly."}, {"heading": "II. RATIONAL SAFETY GAMES", "text": "This section recaps infinite-duration, two-player safety games\nas well as basic concepts of automata theory and introduces rational safety games.\na) Safety Games: We consider safety games (i.e., infinite duration two-person games on graphs) as popularized by McNaughton [1]. A safety game is played on an arena A = (V0, V1, E) consisting of two nonempty, disjoint sets V0, V1 of vertices (we denote their union by V ) and a directed edge relation E \u2286 V \u00d7 V . In contrast to the classical (finite) setting, we allow V0 and V1 to be countable sets. As shorthand notation, we write the successors of a set X \u2286 V of vertices as E(X) = {y | \u2203x \u2208 X : (x, y) \u2208 E}.\nWe consider safety games with initial vertices, which are defined as triples G = (A, F, I) consisting of an arena A = (V0, V1, E), a set F \u2286 V of safe vertices, and a set I \u2286 F of initial vertices. Such safety games are played by two players, named Player 0 and Player 1, as follows: A token is placed on some initial vertex v0 \u2208 I and, in each turn, the player owning the current vertex moves the token to a successor vertex of his choice. This process of moving the token is repeated ad infinitum, thereby forming an infinite sequence of vertices, which is called a play. Formally, a play is an infinite sequence \u03c0 = v0v1 . . . \u2208 V \u03c9 that satisfies v0 \u2208 I and (vi, vi+1) \u2208 E for all i \u2208 N. The set F defines the winning condition of the game in the sense that a play v0v1 . . . is winning for Player 0 if vi \u2208 F for all i \u2208 N\u2014otherwise it is winning for Player 1.\nA strategy for Player \u03c3, \u03c3 \u2208 {0, 1}, is a mapping f\u03c3 : V \u2217V\u03c3 \u2192 V , which prescribes how to continue playing. A\nstrategy f\u03c3 is called winning if any play v0v1 . . . that is played according to the strategy (i.e., that satisfies vi+1 = f\u03c3(v0 . . . vi) for all i \u2208 N and vi \u2208 V\u03c3) is winning for Player \u03c3. A winning strategy for Player 0 straightforwardly translates into a controller satisfying the given safety specifications and, hence, we restrict ourselves to compute winning strategies for Player 0.\nComputing a winning strategy for Player 0 is usually reduced to finding a so-called winning set.\nDefinition 1 (Winning set): For a safety game G = (A, I, F ) over the arena A = (V0, V1, E), a winning set is a set W \u2286 V satisfying (1) I \u2286 W , (2) W \u2286 F , (3) E({v}) \u2229W 6= \u2205 for all v \u2208W \u2229 V0 (existential closedness), and (4) E({v}) \u2286W for all v \u2208W \u2229 V1 (universal closedness).\nBy computing a winning set, one immediately obtains a strategy for Player 0: starting in an initial vertex, Player 0 simply moves to a successor vertex inside W whenever it is his turn. A straightforward induction over the length of plays proves that every play that is played according to this strategy stays inside F , no matter how Player 1 plays, and, hence, is won by Player 0 (since I \u2286W \u2286 F ). A winning set is what we want to compute\u2014or, more precisely, learn.\nGames over infinite arenas require a symbolic representation in order to work with them algorithmically. We follow the idea of regular model checking [5], an approach in verification, and represent sets of vertices by regular languages and edges by so-called rational relations. Before we can introduce our symbolic representation of safety games, however, we need to recap basic concepts and notations of automata theory.\nb) Basics of Automata Theory: An alphabet \u03a3 is a nonempty, finite set, whose elements are called symbols. A word over the alphabet \u03a3 is a sequence u = a1 . . . an of symbols ai \u2208 \u03a3 for i \u2208 {1, . . . , n}; the empty sequence is called empty word and denoted by \u03b5. Given two words u = a1 . . . am and v = b1 . . . bn, the concatenation of u and v is the word u \u00b7 v = uv = a1 . . . amb1 . . . bn. The set of all words over the alphabet \u03a3 is denoted by \u03a3\u2217, and a subset L \u2286 \u03a3\u2217 is called a language. The set of prefixes of a language L \u2286 \u03a3\u2217 is the set Pref (L) = {u \u2208 \u03a3\u2217 | \u2203v \u2208 \u03a3\u2217 : uv \u2208 L}.\nA nondeterministic finite automaton (NFA) is a tuple A = (Q,\u03a3, q0,\u2206, F ) consisting of a nonempty, finite set Q of states, an input alphabet \u03a3, an initial state q0 \u2208 Q, a transition relation \u2206 \u2286 Q\u00d7\u03a3\u00d7Q, and a set F \u2286 Q of final states. A run of an NFA A on a word u = a1 . . . an is a sequence of states q0, . . . , qn such that (qi\u22121, ai, qi) \u2208 \u2206 for i \u2208 {1, . . . , n}. We denote this run by A : q0\nu\u2212\u2192 qn. An NFA A accepts a word u \u2208 \u03a3\u2217 if A : q0\nu\u2212\u2192 q with q \u2208 F . The set L(A) = {u \u2208 \u03a3\u2217 | A : q0\nu\u2212\u2192 q, q \u2208 F} is called language of A. A language L is said to be regular if there exists an NFA A with L(A) = L. Finally, NFA\u03a3 denotes the set of all NFAs over \u03a3.\nA deterministic finite automaton (DFA) is an NFA in which (p, a, q) \u2208 \u2206, (p, a, q\u2032) \u2208 \u2206 implies q = q\u2032. We replace the transition relation \u2206 with a transition function \u03b4 : Q\u00d7\u03a3\u2192 Q.\nWe define rational relations by resorting to transducers. A transducer is an NFA T = (Q, \u03a3\u0302, q0,\u2206, F ) over the alphabet \u03a3\u0302 = (\u03a3 \u222a {\u03b5}) \u00d7 (\u0393 \u222a {\u03b5})\u2014\u03a3 and \u0393 are both alphabets\u2014 that processes pairs (u, v) \u2208 \u03a3\u2217 \u00d7 \u0393\u2217 of words. The run of\na transducer T on a pair (u, v) is a sequence q0, . . . , qn of states such that (qi\u22121, (ai, bi), qi) \u2208 \u2206 for all i \u2208 {1, . . . , n}, u = a1 . . . an, and v = b1 . . . bn; note that u and v do not need to be of equal length since any ai or bi can be \u03b5. A pair (u, v) is said to be accepted by T if there exists a run of T on (u, v) that starts in the initial state and ends in a final state. As an acceptor of pairs of words, a transducer T defines a relation, namely the relation consisting of exactly the pairs accepted by T , which we denote by R(T ). Finally, a relation R \u2286 \u03a3\u2217 \u00d7 \u0393\u2217 is called rational if there exists a transducer T with R(T ) = R. (This definition of rational relations is simplified from that in [13] but sufficient for our purpose.)\nOur learning framework relies on the two well-known facts. Lemma 1: Let R \u2286 \u03a3\u2217 \u00d7 \u0393\u2217 be a rational relation and X \u2286 \u03a3\u2217 a regular set. Then, (1) the relation R\u22121 = {(y, x) | (x, y) \u2208 R} is again rational, and a transducer defining this set can be constructed in linear time; and (2) the set R(X) = {y \u2208 \u0393\u2217 | \u2203x \u2208 X : (x, y) \u2208 R}, called the image of X under R, is again regular, and an NFA accepting this set can be constructed effectively.\nc) Rational Safety Games: A rational safety game is a symbolic representation of a safety game in terms of regular languages and rational relations.\nDefinition 2: A rational arena over the alphabet \u03a3 is an arena A\u03a3 = (V0, V1, E) where V0, V1 \u2286 \u03a3\u2217 are regular languages and E \u2286 V \u00d7 V is a rational relation.\nThe definition of rational safety games is now immediate. Definition 3: A rational safety game over the alphabet \u03a3 is\na safety game G\u03a3 = (A\u03a3, F, I) where A\u03a3 is a rational arena over \u03a3 and F, I \u2286 \u03a3\u2217 are regular languages.\nIn the remainder, we assume regular languages to be given as NFAs and rational relations as transducers. In addition, we use these notions interchangeably when referring to rational arenas and rational safety games; for instance, we write a rational area A\u03a3 = (V0, V1, E) as A\u03a3 = (AV0 ,AV1 , TE) given that L(AV0) = V0, L(AV1) = V1, and R(TE) = E.\nLet us illustrate rational safety games through an example. Example 1: Consider a simple example motivated by motion\nplanning, sketched in Figure 1a, in which a robot moves on an infinite, discrete one-dimensional grid that is \u201cbounded on the left\u201d. The robot can move left or right to an adjacent cell (provided that it has not reached edge of the grid) or it can stay at its current position. The grid is partitioned into a safe and an unsafe area, the former being shown shaded in Figure 1a. The safe area is parameterized by an integer k \u2208 N \\ {0} and consists of all position greater than or equal to k. The robot starts somewhere inside the safe area.\nThe robot\u2019s movement is governed by two adversarial players, called system and environment; the system can move the robot to the right or keep it at its current position, whereas the environment can move the robot to the left (if the edge has not been reached) or keep it at its current position. The players move the robot in alternation, and the system moves first. The system\u2019s objective is to stay within the safe area, whereas the environment wants to move the robot out of it. Note that the system can win, irrespective of k, by always moving right.\nA formalization as safety game is straightforward. Player 0 corresponds to the system and Player 1 corresponds to the environment. The arena A = (V0, V1, E) consists of vertices V0 = {s} \u00d7N and V1 = {e} \u00d7N\u2014s, respectively e, indicates the player moving next\u2014as well as the edge relation E ={(\n(s, i), (e, i + 1) ) | i \u2208 N } \u222a {( (e, i + 1), (s, i) ) | i \u2208 N } .\nThe safety game itself is the triple Gk = (A, F, I) with F = {s, e} \u00d7 {i \u2208 N | i \u2265 k} and I = {s} \u00d7 {i \u2208 N | i \u2265 k}. Figure 1b sketches the game Gk for the case k = 2.\nWe now turn Gk into a rational safety game. To this end, we label each vertex uniquely with a finite word. In our example, we choose \u03a3 = {s, e, l} and associate the vertex (x, i) \u2208 {s, e} \u00d7 N with the word xli where li is the encoding of i in unary. We represent the sets V0 and V1 by the following NFAs:\nAV0 : s\nl AV1 : e\nl\nMoreover, we represent the edges by the following transducer:\nTE : (s, e) (e, s)\n(l, l)\n(\u03b5, l)\n(l, l)\n(l, \u03b5)\nFinally, the NFA\n. . .AF : s, e l l l\nl\nk \u2212 1 states\nrepresents the set F ; similarly, I is represented by a copy of AF in which the transition labeled with e is omitted.\nIt is worth mentioning that rational arenas not only subsume finite arenas but also a rich class of of infinite arenas, including such encoding computations of Turing machines. Hence, the problem of determining the winner of a rational safety game is undecidable, and any algorithm for computing a winning set can at best be a semi-algorithm (i.e., an algorithm that, on termination, gives the correct answer but does not guarantee to halt). The algorithm we design in this paper is of this kind and guarantees to learn a winning set if one exists. To ease description, we always assume that a winning set set exists."}, {"heading": "III. THE LEARNING FRAMEWORK", "text": "Our learning framework is an extension of the ICE framework proposed by Garg et. al. [6], which deals with learning loop invariants from positive and negative data as well as\nimplications. The learning takes place between a teacher, who has (explicit or implicit) knowledge about the rational safety game in question, and a learner, whose objective is to learn a DFA accepting a winning set, but who is agnostic to the game. We assume that the teacher announces the alphabet of the game before the actual learning starts.\nThe learning proceeds in a CEGIS-style loop [2]. In every iteration, the learner conjectures a DFA, let us call it C, and the teacher checks whether L(C) is a winning set\u2014this kind of query is often called equivalence or correctness query. Although the teacher does not know a winning set (the overall objective is to learn one after all), he can resort to Conditions (1)\u2013(4) of Definition 1 in order to decide whether L(C) is a winning set. If L(C) satisfies Conditions (1)\u2013(4) (i.e., L(C) is a winning set), then the teacher replies \u201cyes\u201d and the learning ends. If this is not the case, the teacher returns a counterexample witnessing the violation of one of these conditions, and the learning continues with the next iteration. The definition below fixes the protocol between the teacher and the learner and defines counterexamples.\nDefinition 4 (Teacher for rational safety games): Let G\u03a3 = (A\u03a3, F, I) be a rational safety game over the rational arena A\u03a3 = (V0, V1, E). Confronted with a DFA C, a teacher for G\u03a3 replies as follows:\n1) If I 6\u2286 L(C), then the teacher returns a positive counterexample u \u2208 I \\ L(C).\n2) If L(C) 6\u2286 F , then the teacher returns a negative counterexample u \u2208 L(C) \\ F .\n3) If there exists u \u2208 L(C)\u2229V0 such that E({u})\u2229L(C) = \u2205, then the teacher picks such a u and returns an existential implication counterexample (u,A) \u2208 \u03a3\u2217 \u00d7NFA\u03a3 where L(A) = E({u}).\n4) If there exists u \u2208 L(C) \u2229 V1 such that E({u}) 6\u2286 L(C), then the teacher picks such a u and returns a universal implication counterexample (u,A) \u2208 \u03a3\u2217 \u00d7NFA\u03a3 where L(A) = E({u})."}, {"heading": "If C passes all four checks, the teacher replies \u201cyes\u201d. The", "text": "order in which the teacher performs these checks is arbitrary.\nIt is easy to see that the language of a conjecture is indeed a winning set if the teacher replies \u201cyes\u201d (since it satisfies all conditions of Definition 1). The meaning of a positive counterexample is that any conjecture needs to accepts it, but it was rejected. Similarly, a negative counterexample indicates that any conjecture has to reject it but it was accepted. An existential implication counterexample (u,A) means that any conjecture accepting u has to accept at least one v \u2208 L(A), which was violated by the current conjecture. Finally, a universal implication counterexample (u,A) means that any conjecture accepting u needs to accept all v \u2208 L(A). At this point, it is important to note that Definition 4 is sound (in particular, both types of implication counterexamples are well-defined due to Lemma 1 Part 2) and every counterexample is a finite object.\nLet us illustrate this learning framework through an example. Example 2: We revisit the setting of Example 1 for the case\nk = 2 and describe how the learner learns a winning set.\nSuppose that the learner conjectures the DFA C0 with L(C0) = \u2205. As C0 fails Check 1 (it passes all other checks), the teacher returns a positive counterexample, say u = sll \u2208 I .\nNext, suppose the learner conjectures the DFA C1 with L(C1) = {sln | n \u2265 2}, which passes all checks but Check 3 (as the players alternate but L(C1) does not contain a vertex of the environment). The teacher replies with an existential implication counterexample, say (sll,A) with L(A) = {ell, elll}.\nIn the next round, let us assume that the learner conjectures the DFA C2 with L(C2) = {sln | n \u2265 2} \u222a {elm | m \u2265 3}. This conjecture passes all checks (i.e., L(C2) is a winning set), the teacher replies \u201cyes\u201d, and the learning ends.\nIt is important to note that classical learning frameworks for regular languages that involve learning from positive and negative data only, such as Gold\u2019s passive learning [7] or Angluin\u2019s active learning [8], are insufficient in our setting. If the learner provides a conjecture C that violates Condition (3) or (4) of Definition 1, the teacher is stuck. For instance, if C does not satisfy Condition (4), the teacher does not know whether to exclude u or to include E({u}). Returning an implication counterexample, however, resolves this problem in that it communicates exactly why the conjecture is incorrect and, hence, allows the learner to make progress.1"}, {"heading": "IV. A GENERIC TEACHER", "text": "We now present a generic teacher that, taking a rational safety game as input, answers queries according to Definition 4. For the remainder of this section, fix a rational safety game G\u03a3 = (A\u03a3,AF ,AI) over the rational arena A\u03a3 = (AV0 ,AV1 , TE), and let C be a DFA conjectured by the learner.\nTo answer a query, the teacher performs Checks 1 to 4 of Definition 4 as described below. If the conjecture passes all checks, the teacher returns \u201cyes\u201d; otherwise, he returns a corresponding counterexample, as described next.\nCheck 1 (initial vertices): The teacher computes an NFA B with L(B) = L(AI) \\ L(C). If L(B) 6= \u2205, he returns a positive counterexample u \u2208 L(B).\nCheck 2 (safe vertices): The teacher computes an NFA B with L(B) = L(C) \\ L(AF ). If L(B) 6= \u2205, he returns a negative counterexample u \u2208 L(B).\nCheck 3 (existential closure): To check existential closure, the teacher successively computes three NFAs:\n1) An NFA B1 with L(B1) = R(TE)\u22121(L(C)); the language L(B1) contains all vertices that have a successor in L(C). 2) An NFA B2 with L(B2) = L(AV0)\\L(B1); the language L(B2) contains all vertices of Player 0 that have no successor in L(C). 3) An NFA B3 with L(B3) = L(C) \u2229 L(B2); the language L(B3) contains all vertices of Player 0 that belong to L(C) and have no successor in L(C).\nEvery u \u2208 L(B3) is a witness that C is not existentially closed. Hence, if L(B3) 6= \u2205, the teacher picks an arbitrary u \u2208 L(B3)\n1Garg et. al. [6] argue comprehensively why implications needed in a robust invariant learning framework. Their arguments also apply to our setting as one obtains a setting similar to Garg et. al.\u2019s by considering a solitary game with Player 1 as the only player.\nand returns the existential implication counterexample (u,A) where L(A) = R(TE)({u}). Check 4 (universal closure): To check universal closure, the teacher, again, computes three NFAs:\n1) An NFA B1 with L(B1) = ( L(AV0) \u222a L(AV1) ) \\ L(C);\nthe language L(B1) contains all vertices not in L(C). 2) An NFA B2 with L(B2) = R(TE)\u22121(L(B1)); the lan-\nguage L(B2) contains all vertices that have a successor not belonging to L(C). 3) An NFA B3 with L(B3) = L(AV1) \u2229 L(C) \u2229 L(B2); the language L(B3) contains all vertices of Player 1 that are in L(C) and have at least one successor not in L(C).\nEvery u \u2208 L(B3) is a witness that C is not universally closed. Hence, if L(B3) 6= \u2205, the teacher picks an arbitrary u \u2208 L(B3) and returns the universal implication counterexample (u,A) where L(A) = R(TE)({u}).\nAll checks can be performed using standard methods of automata theory, including product constructions, projections, determinizing automata, and emptiness checks (see Lemma 1)."}, {"heading": "V. A LEARNER FOR RATIONAL SAFETY GAMES", "text": "We design our learner with two key features: (1) the learner always conjectures a DFA consistent with the counterexamples received so far (we make this precise shortly), and (2) the learner always conjectures a minimal consistent DFA (i.e., a DFA with the least number of states among all DFAs that are consistent with the received counterexamples). The first design goal prevents the learner from making the same mistake twice, while the second design goal facilitates convergence of the overall learning (assuming that a winning set exists).\nTo meet these goals, our learner stores counterexamples in a data structure, which we call sample. Formally, a sample is a four-tuple S = (Pos,Neg ,Ex ,Uni) consisting of a finite set Pos \u2282 \u03a3\u2217 of positive words, a finite set Neg \u2282 \u03a3\u2217 of negative words, a finite set Ex \u2282 \u03a3\u2217 \u00d7 NFA\u03a3 of existential implications, and a finite set Uni \u2282 \u03a3\u2217 \u00d7NFA\u03a3 of universal implications. We encourage the reader to think of a sample as a finite approximation of the safety game learned thus far.\nIn every iteration, our learner constructs a minimal DFA consistent with the current sample. A DFA B is called consistent with a sample S = (Pos,Neg ,Ex ,Uni) if\n1) Pos \u2286 L(B); 2) Neg \u2229 L(B) = \u2205; 3) u \u2208 L(B) implies L(B)\u2229L(A) 6= \u2205 for each (u,A) \u2208 Ex ; 4) u \u2208 L(B) implies L(A) \u2286 L(B) for each (u,A) \u2208 Uni . Constructing a DFA that is consistent with a sample is\npossible only if the sample does not contain contradictory information. Contradictions can arise in two ways: first, Pos and Neg are not disjoint; second, the (alternating) transitive closure of the implications in Ex and Uni contains a pair (u, v) with u \u2208 Pos and v \u2208 Neg . This observation justifies to introduce the notion of contradiction-free samples: a sample S is called contradiction-free if a DFA that is consistent with S exists. Since we assume that Player 0 wins from set I , a\nAlgorithm 1: A learner for rational safety games 1 Initialize an empty sample S = (Pos,Neg ,Ex ,Uni) with Pos = \u2205, Neg = \u2205, Ex = \u2205, and Uni = \u2205; 2 repeat 3 Construct a minimal DFA AS consistent with S; 4 Submit AS to an equivalence query; 5 if the teacher returns a counterexample then 6 Add the counterexample to S; 7 end 8 until the teacher replies \u201cyes\u201d to an equivalence query; 9 return AS ;\nwinning set exists and the counterexamples returned by the teacher always form contradiction-free samples.2\nAfter having constructed a minimal consistent DFA, the learner conjectures it to the teacher. If the teacher replies \u201cyes\u201d, the learning terminates. If the teacher returns a counterexample, on the other hand, the learner adds it to the appropriate set in S and iterates. This procedure is sketched as Algorithm 1. Note that, by definition of the teacher, a conjecture is guaranteed to accept a wining set once the learning terminates.\nIt is left to describe how the learner actually constructs a minimal DFA that is consistent with the current sample. However, this task, known as passive learning, is computationally hard (i.e., the corresponding decision problem is NP-complete) already in the absence of implications [7]. Our strategy to approach this hurdle is to translate the original problem into a sequence of satisfiability problems of formulas in propositional Boolean logic and use highly optimized constraint solvers as a practically effective means to solve the resulting formulas (note that a translation into a logical formulation is a popular and effective strategy). More precisely, our learner creates and solves propositional Boolean formulas \u03d5Sn , for increasing values of n \u2208 N, n \u2265 1, with the following two properties:\n1) The formula \u03d5Sn is satisfiable if and only if there exists a DFA with n states that is consistent with S. 2) A model M of \u03d5Sn (i.e., a satisfying assignment of the variables in \u03d5Sn) contains sufficient information to construct a DFA, denoted by AM, that has n states and is consistent with S .\nIf \u03d5Sn is satisfiable, then Property 2 enables us to construct a consistent DFA from a model. However, if the formula is unsatisfiable, then the parameter n has been chosen too small and the learner increments it (e.g., by one or using a binary search). This procedure is summarized as Algorithm 2. We show its correctness shortly in Section V-B.\nThe key idea of the formula \u03d5Sn is to encode a DFA with n states by means of Boolean variables and to pose constraints on those variables. Our encoding relies on a simple observation: for every DFA there exists an isomorphic (hence, equivalent) DFA over the state set Q = {0, . . . , n\u2212 1} with initial state\n2In fact, checking for contradictions equips the learner with a means to detect that the game is won by Player 1. However, since determining the winner of a rational safety game is undecidable, any sample obtained during the learning might be contradiction-free despite the fact that Player 1 wins.\nAlgorithm 2: Computing a minimal consistent DFA.\nInput: A contradiction-free sample S Output: A minimal DFA that is consistent with S\n1 n\u2190 0; 2 repeat 3 n\u2190 n+ 1; 4 Construct and solve \u03d5Sn ; 5 until \u03d5Sn is satisfiable, say with model M; 6 return AM;\nq0 = 0; moreover, given that Q and q0 are fixed, any DFA with n states is uniquely determined by its transitions and final states. Therefore, we can fix the state set of the prospective DFA as Q = {0, . . . , n \u2212 1} and the initial state as q0 = 0; the alphabet \u03a3 is announced by the teacher.\nOur encoding of transitions and final states follows an idea from [14] (independently due to [15]). We introduce Boolean variables dp,a,q and fq where p, q \u2208 Q and a \u2208 \u03a3, which have the following meaning: setting dp,a,q to true means that the transition \u03b4(p, a) = q exists in the prospective DFA, and setting fq to true means that q is a final state.\nTo make sure that the variables dp,a,q encode a deterministic transition function, we impose two constraints:\u2227\np\u2208Q \u2227 a\u2208\u03a3 \u2227 q,q\u2032\u2208Q,q 6=q\u2032\n\u00acdp,a,q \u2228 \u00acdp,a,q\u2032 (1)\u2227 p\u2208Q \u2227 a\u2208\u03a3 \u2228 q\u2208Q dp,a,q (2)\nLet \u03d5DFAn be the conjunction of Formulas (1) and (2). Given a model M of \u03d5DFAn (we assume a model to be a map from the variables of a formula to the set {true, false}), deriving the encoded DFA is straightforward, as shown next.\nDefinition 5: Let M be a model of \u03d5DFAn . We define the DFA AM = (Q,\u03a3, q0, \u03b4, F ) by (1) \u03b4(p, a) = q for the unique q \u2208 Q with M(dp,a,q) = true; and (2) F = {q \u2208 Q | M(fq) = true}. (Recall that we fixed Q = {0, . . . , n\u2212 1} and q0 = 0.)\nTo enforce that AM is consistent with the given sample S = (Pos,Neg ,Ex ,Uni), we impose further constraints, corresponding to the four requirements of consistent DFAs: \u2022 a formula \u03d5Posn asserting Pos \u2286 L(AM); \u2022 a formula \u03d5Negn asserting Neg \u2229 L(AM) = \u2205; \u2022 a formula \u03d5Exn asserting that u \u2208 L(AM) implies L(AM) \u2229 L(A) 6= \u2205 for each (u,A) \u2208 Ex ; and\n\u2022 a formula \u03d5Unin asserting that u \u2208 L(AM) implies L(AM) \u2286 L(A) for each (u,A) \u2208 Uni . Then, \u03d5Sn := \u03d5 DFA n \u2227 \u03d5Posn \u2227 \u03d5Negn \u2227 \u03d5Exn \u2227 \u03d5Unin . We here sketch formula \u03d5Unin and refer the reader to Appendix A for a detailed presentation of the remaining formulas. A description of \u03d5Posn and \u03d5 Neg n can also be found in [14]."}, {"heading": "A. The formula \u03d5Unin", "text": "We break the construction of \u03d5Unin down into smaller parts. Roughly speaking, we construct for each universal implication\n\u03b9 = (u,A) \u2208 Uni a formula \u03d5\u03b9n that asserts L(A) \u2286 L(AM) if u \u2208 L(AM). The formulas \u03d5Unin is then the finite conjunction\u2227 \u03b9\u2208Uni \u03d5 \u03b9 n. For the remainder, let us fix a universal implication \u03b9 \u2208 Uni , say \u03b9 = (u,A) with A = (QA,\u03a3, qA0 ,\u2206A, FA), and let Ante(Uni) = {u | (u,A) \u2208 Uni} be the set of all words occurring as antecedent of a universal implication.\nAs a preparatory step, we introduce auxiliary Boolean variables that track the runs of AM on words of Pref (Ante(Uni)) in order to detect when AM accepts the antecedent of a universal implication. More precisely, we introduce variables xu,q where u \u2208 Pref (Ante(Uni)) and q \u2208 Q, which have the meaning that xu,q is set to true if AM : q0\nu\u2212\u2192 q (i.e., AM reaches state q on reading u):\nx\u03b5,q0 (3)\u2227 u\u2208Pref (Ante(Uni)) \u2227 q 6=q\u2032\u2208Q\n\u00acxu,q \u2228 \u00acxu,q\u2032 (4)\u2227 ua\u2208Pref (Ante(Uni)) \u2227 p,q\u2208Q (xu,p \u2227 dp,a,q)\u2192 xua,q (5)\nFormula (3) asserts that x\u03b5,q0 is set to true since any run starts in the initial state q0. Formula (4) enforces that for every u \u2208 Pref (Ante(Uni)) there exists at most one q \u2208 Q such that xu,q is set to true (in fact, the conjuction of Formulas (2)\u2013(5) implies that there exists a unique such state). Finally, Formula (5) prescribes how the run of AM on a word u \u2208 Pref (Ante(Uni)) proceeds: if AM reaches state p on reading u (i.e., xu,p is set to true) and there exists a transition from p to state q on reading the symbol a \u2208 \u03a3 (i.e., dp,a,q is set to true), then AM reaches state q on reading ua and xua needs to be set to true .\nWe now define \u03d5\u03b9n. The formula ranges, in addition to dp,a,q , fq, and xu,q, over Boolean variables y\u03b9q,q\u2032 where q \u2208 Q and q\u2032 \u2208 QA, which track runs of A and AM. Their precise meaning is the following: if there exists a word u \u2208 \u03a3\u2217 with AM : q0 u\u2212\u2192 q and A : qA0 u\u2212\u2192 q\u2032, then y\u03b9q,q\u2032 is set to true:\ny\u03b9q0,qA0 (6)\u2227\np,q\u2208Q \u2227 (p\u2032,a,q\u2032)\u2208\u2206A (y\u03b9p,p\u2032 \u2227 dp,a,q)\u2192 y\u03b9q,q\u2032 (7)\nFormula (6) enforces y\u03b9 q0,qA0 to be set to true because AM : q0 \u03b5\u2212\u2192 q0 and A : qA0\n\u03b5\u2212\u2192 qA0 . Formula (7) is similar to Formula (5) and describes how the runs of AM and A proceed: if there exists a word v such that AM : q0\nv\u2212\u2192 p and A : qA0\nv\u2212\u2192 p\u2032 (i.e., y\u03b9p,p\u2032 is set to true) and there are transitions (p\u2032, a, q\u2032) \u2208 \u2206A and \u03b4(p, a) = q in AM, then AM : q0\nva\u2212\u2192 q and A : qA0\nva\u2212\u2192 q\u2032, which requires y\u03b9q,q\u2032 to be set to true . Finally, the next constraint ensures that whenever AM accepts u (i.e., the antecedent is true), then all words that lead to an accepting state in A also lead to an accepting state in AM (i.e., the consequent is true).(\u2228\nq\u2208Q xu,q \u2227 fq ) \u2192 (\u2227 q\u2208Q \u2227 q\u2032\u2208FA y\u03b9q,q\u2032 \u2192 fq )\n(8)\nLet \u03d5Ante(Uni)n be the conjunction of Formulas (3), (4), and (5) as well as \u03d5\u03b9n the conjunction of Formulas (6), (7), and (8). Then, \u03d5Unin is the (finite) conjunction \u03d5 Ante(Uni) n \u2227 \u2227 \u03b9\u2208Uni \u03d5 \u03b9 n."}, {"heading": "B. Correctness of the Learner", "text": "We now sketch a correctness proof of the learner\u2014we refer the reader to Appendix B for a detailed proof. First, we state that \u03d5Sn has the desired properties.\nLemma 2: Let S be a sample, n \u2265 1, and \u03d5Sn be as defined above. Then, the following statements hold: (1) If M |= \u03d5Sn , then AM is a DFA with n states that is consistent with S. (2) If there exists a DFA that has n states and is consistent with S, then \u03d5Sn is satisfiable.\nNext, let us show the correctness of Algorithm 2. Theorem 1: Given a contradiction free-sample S , Algorithm 2\nreturns a minimal DFA (in terms of the number of states) that is consistent with S . If a minimal consistent DFA has k states, then Algorithm 2 terminates after k iterations.\nProof: Given a sample S, suppose that there exists a DFA that has k states and is consistent with S. Then, \u03d5Sn is satisfiable for all n \u2265 k (see Lemma 2). Moreover, if M is a model of \u03d5Sn , then AM is a DFA with n states that is consistent with S . Since Algorithm 2 increases the parameter n by one in every iteration (starting with n = 1), the algorithm eventually finds the smallest value for which \u03d5Sn is satisfiable (after k iterations) and, hence, a consistent DFA of minimal size.\nFinally, we can prove the correctness of our learner. Theorem 2: Given a teacher, Algorithm 1, equipped with\nAlgorithm 2 to construct conjectures, terminates and returns a (minimal) DFA accepting a winning set if one exists.\nProof: Theorem 2 follows from three observations about the learner: (1) The learner never conjectures the same DFA twice (due to Theorem 1 and the fact that counterexamples are added to the sample). (2) The conjectures grow monotonically in size (due to minimality of conjectures) with increasing n, and (3) adding counterexamples to a sample does not rule out any solution (as every DFA accepting a winning set is consistent with any sample produced during the learning). Now, suppose a DFA accepting a winning set exists, say with k states. Due to Observations 1 and 2, the learner eventually conjectures a DFA with k states and, moreover, cannot conjecture a larger DFA (due to Observation 3 and the minimality of conjectures). Hence, the learner eventually conjectures a DFA with k states that accepts a winning set, and the learning terminates."}, {"heading": "VI. EXPERIMENTS", "text": "In order to demonstrate the feasibility of our learning approach, we implemented a Java prototype using the BRICS automaton library [16] and Microsoft\u2019s Z3 [17] constraint solver. The source code, including the games used in the experiments, is available at http://preview.tinyurl.com/n7a7byj.\nIn addition to the learner of Section V, we implemented a learner based on the popular RPNI algorithm [18], which is a polynomial time algorithm for learning DFAs from positive and negative words. For this learner, we modified the RPNI algorithm such that it constructs a consistent DFA from existential and universal implications in addition to positive and negative words (a detailed presentation can be found in Appendix C). In contrast to Algorithm 2, our modified version of RPNI cannot guarantee to find smallest consistent DFAs\nand, hence, the resulting learner is a fast heuristic that is sound but in general not complete. Another limitation is that it can only handle implication counterexamples of the form (u,A) where L(A) is finite. We refer to the learner of Section V as SAT learner and the RPNI-based learner as RPNI learner.\nOur experiments are on a slightly restricted type of games: 1) Edge relations are automatic. Automatic relations are\ndefined by transducers that do not possess transitions of the form (a, \u03b5) and (\u03b5, b) but rather use a dedicated padding symbol to balance the length of their input-words.3\n2) Each vertex of an arena has a finite (but not necessarily bounded) number of outgoing edges.\nRestriction 1 simplifies the implementation of the teacher. Restriction 2 is due to the limitation of the RPNI learner.\nWe use two benchmark suits: the first suite serves to demonstrate the feasibility of our techniques for various examples, predominantly taken from the area of motion planning; the second suite serves to assess the performance of our techniques when confronted with games of increasing \u201ccomplexity\u201d. All games were given as finite automata, and we employed the teacher described in Section IV. We conducted all experiments on an Intel Core i7-4510U CPU (running Microsoft Windows 8.1) with a memory limit of 4 GiB and a runtime limit of 300 s."}, {"heading": "A. Examples", "text": "We consider the following examples. Diagonal game: A robot moves on an infinite, discrete twodimensional grid world from one cell to an adjacent cell. Player 0 controls the robot\u2019s vertical movement, whereas Player 1 controls the horizontal movement. Both players move the robot in alternation, and Player 0\u2019s objective is to stay inside a margin of two cells around the diagonal.\nBox game: A version of the diagonal game in which Player 0\u2019s objective is to stay within a horizontal stripe of width three.\nSolitary box game: A version of the box game in which Player 0 is the only player and has control over both the horizontal and the vertical movement.\nEvasion game: Two robots move in alternation on an infinite, two-dimensional grid. Each robot is controlled by a player. Player 0\u2019s objective is to avoid collision with Player 1\u2019s robot.\nFollow game: A version of the evasion game in which Player 0\u2019s objective is to keep his robot within a distance of two cells (in the Manhattan distance) from Player 1\u2019s robot.\nProgram-repair game: A finitely-branching version of the program-repair game described by Beyene et al. [10]. Table I lists the overall time taken by each of the two\nlearners to learn a winning set (including the time taken by the teacher) as well as further statistics of the learning process. The second column |G| corresponds to sum of states of all automata constituting a game (size of the game), which serves as measure for the complexity of a game. The remaining columns list the number of iterations, the number of states of the learned DFA, and the cardinality of each set of the final sample.\n3Automatic relations constitute a proper subset of rational relations, but are still expressive enough to encode computations of Turing machines.\nAs Table I shows, the SAT learner computed the winning sets for all games, whereas the RPNI learner computed the winning sets for all but the Follow game. Since the RPNI learner does not compute minimal consistent DFAs, we expected that it is on average faster than the SAT learner, which turned out to be the case. However, the RPNI learner fails to terminate within the time limit on the Follow game, and the large number of iterations seem to indicate that the learner in fact diverges.\nFinally, it is important to note that the teacher replied implication counterexamples in all but one experiment. This observation highlights that classical learning algorithms, which learn from positive and negative words only, are insufficient to learn winning sets (since the learning would be stuck at that point) and one has to move to a richer learning framework."}, {"heading": "B. Scalability Benchmarks", "text": "To assess the scalability of our technique when confronted with inputs of increasing size, we modified the game of Example 1 such that the safe region is now determined by two parameters, namely k and k\u2032, and contains all positions in the interval [k, k\u2032] (we assume k < k\u2032 and fix k = 1). In this new setting, the number of states of the automaton AF increases when k\u2032 increases as the automaton needs to count in unary to check the position of the robot.\nFigure 2 depicts the overall time taken to learn a winning set, depending on the parameter k\u2032. To put the runtimes into perspective, it also shows the size of the games.\nOn the scalability benchmark suite, the RPNI learner was about one order of magnitude faster than the SAT learner and can computed a winning set for games up to a combined size of 50 000. The SAT learner, on the other hand, computed a winning set for games up to a combined size of 10 000 but did not terminate for game with k\u2032 = 50 000. While a thorough assessment remains as part of future work, our results promise\napplicability to practically interesting problem instances."}, {"heading": "VII. CONCLUSION", "text": "We developed an automata learning method to construct finite-state reactive controllers for systems whose interactions with their environment are modeled by infinite-state games. We focused on the practically interesting family of safety games, utilized a symbolic representation of the underlying game, developed specific implementations of the learner and the teacher, and demonstrated the feasibility of the method on a set of problems motivated by robotic motion planning."}, {"heading": "APPENDIX A CONSTRUCTING CONSISTENT DFAS USING CONSTRAINT SOLVERS", "text": "The key building block of our learner is an algorithm that, given a sample S , produces a smallest DFA that is consistent with S. Recall that the learner translates this problem into a series of satisfiability problem of propositional Boolean formulas \u03d5Sn and uses a constraint solver to check their satisfiability.\nIn the following, we describe in detail how the formula \u03d5Sn is constructed. For the sake of a self-contained presentation, we repeat parts of Section V; as a beneficial side-effect, this repetition allows us to provide further explanations of the formulas presented in Section V. Moreover, to facilitate a more concise and accessible description, we define \u03d5Sn slightly different. In particular, we introduce a formula \u03d5Wn , which tracks the run of AM on words occurring in the sample (in Pos , Neg , and as antecedent of an implication). In contrast to Section V (where we defined the formula \u03d5Unin to track the run of AM on the set Ante(Uni)) this approach results in more concise and easier to understand formulas since (a prefix of) a word can occur more than once in a sample. As a consequence, however, the formula \u03d5Unin has to be changed in comparison to Section V.\nRecapping the main ideas and encoding of states and transitions\nThe key idea of the formula \u03d5Sn is to encode a DFA with n states by means of Boolean variables and to pose constraints on those variables in order to obtain a DFA that is consistent with the given sample. Our encoding relies on a simple observation: if we fix the alphabet, the set of states and the initial state, then any DFA with n states is uniquely determined (up to isomorphism) by its transitions and final states. Hence, we can without loss of generality fix the state set of the prospective DFA to be Q = {0, . . . , n \u2212 1} and the initial state to be q0 = 0; the alphabet \u03a3 is determined by the given game.\nTo encode the transitions and the final states, we introduce Boolean variables dp,a,q and fq where p, q \u2208 Q and a \u2208 \u03a3, which have the following meaning: assigning true to dp,a,q means that the transition \u03b4(p, a) = q exists in the prospective DFA, and assigning true to fq means that q is a final state.\nTo make sure that the variables dp,a,q indeed encode a deterministic transition function, we impose the following constraints.\u2227\np\u2208Q \u2227 a\u2208\u03a3 \u2227 q,q\u2032\u2208Q,q 6=q\u2032\n\u00acdp,a,q \u2228 \u00acdp,a,q\u2032 (9)\u2227 p\u2208Q \u2227 a\u2208\u03a3 \u2228 q\u2208Q dp,a,q (10)\nFormula (9) and (10) are the same as Formula (1) and (2) of Section V, respectively: Formula (9) enforces that dp,a,q encode a deterministic function, while Formula (10) asserts that the function is total.\nLet \u03d5DFAn (d, f) be the conjunction of Formulas (9) and (10) where d denotes the list of variables dp,a,q and f denotes the\nlist of variables fq for p, q \u2208 Q and a \u2208 \u03a3. Given a model M of \u03d5DFAn , deriving the encoded DFA is straightforward, as shown next.\nDefinition 6: Let M |= \u03d5DFAn (d, f). We define the DFA AM = (Q,\u03a3, q0, \u03b4, F ) by \u2022 \u03b4(p, a) = q for the unique q \u2208 Q with M(dp,a,q) = true;\nand \u2022 F = {q \u2208 Q |M(fq) = true}.\n(Recall that we fixed Q = {0, . . . , n\u2212 1} and q0 = 0.) To produce a DFA that is consistent with a sample, we add\nfurther constraints: \u2022 a formula \u03d5Posn asserting Pos \u2286 L(AM); \u2022 a formula \u03d5Negn asserting Neg \u2229 L(AM) = \u2205; \u2022 a formula \u03d5Exn asserting for each (u,A) \u2208 Ex that u \u2208 L(AM) implies L(AM) \u2229 L(A) 6= \u2205; and\n\u2022 a formula \u03d5Unin asserting for each (u,A) \u2208 Ex that u \u2208 L(AM) implies L(AM) \u2286 L(A). Moreover, we add an auxiliary formula \u03d5Wn , which we discuss shortly. Then,\n\u03d5Sn := \u03d5 DFA n \u2227 \u03d5Wn \u2227 \u03d5Posn \u2227 \u03d5Negn \u2227 \u03d5Exn \u2227 \u03d5Unin\nis the desired formula. The pivotal idea of these formulas is to impose constraints\non the variables dp,a,q and fq, which, in turn, determine the DFA AM. Having this in mind, it is easier to describe the effects of these constraints by referring to M rather then to the variables themselves. However, we thereby implicitly assume that the formula is satisfiable and that the valuation M is a model.\nTHE FORMULA \u03d5Wn To ensure that the prospective automaton AM is consistent with the given sample, we need a mechanism to determine whether AM accepts or rejects the words occurring in the sample. The idea is to track the run of AM on all prefixes of the set"}, {"heading": "W = Pos \u222aNeg \u222aAnte(Ex ) \u222aAnte(Uni),", "text": "which contains all positive and negative words as well as all words that occur as antecedent of an existential or universal implication. The idea is to introduce auxiliary Boolean variables xu,q where u \u2208 Pref (W ) and q \u2208 Q; the intended meaning of these variables is that if the prospective DFA AM reaches state q on reading the word u, then xu,q is set to true. The following constraints enforce this.\nx\u03b5,q0 (11)\u2227 u\u2208Pref (W ) \u2227 q 6=q\u2032\u2208Q\n\u00acxu,q \u2228 \u00acxu,q\u2032 (12)\u2227 ua\u2208Pref (W ) \u2227 p,q\u2208Q (xu,p \u2227 dp,a,q)\u2192 xua,q (13)\nSince any run starts in the initial state q0, Formula (11) asserts that x\u03b5,q0 is set to true . Formula (12) enforces that for every u \u2208 Pref (W ) there exists at most one q \u2208 Q such that\nxu,q is set to true (in fact, the conjuction of Formulas (10)\u2013 (13) implies that there exists a unique such state). Finally, Formula (13) prescribes how the run of AM on a word u \u2208 Pref (W ) proceeds: if AM reaches state p on reading u (i.e., xu,p is set to true) and there exists a transition from p to state q on reading the symbol a \u2208 \u03a3 (i.e., dp,a,q is set to true), then AM reaches state q on reading ua and xua is set to true .\nLet \u03d5Wn (d, f, x) be the conjunction of Formulas (11), (12), and (13) where d and f are as above and x is the list of variables xu,q for u \u2208 Pref (W ) and q \u2208 Q. Then a strightforward induction proves the following lemma (see, e.g., Neider and Jansen [14]).\nLemma 3: Let n \u2265 1, M a model of\n\u03d5DFAn (d, f) \u2227 \u03d5Wn (d, f, x),\nand AM the DFA defined according to Definition 6. Then, AM : q0 u\u2212\u2192 q implies M(xu,q) = true for all u \u2208 Pref (W ).\nTHE FORMULAS \u03d5Posn AND \u03d5 Neg n\nHaving introduced the formula \u03d5Wn , it is straightforward to enforce a correct behavior of AM on Pos and Neg . To assert that AM accepts all words in Pos , we impose the constraint\u2227\nu\u2208Pos \u2227 q\u2208Q xu,q \u2192 fq, (14)\nwhich ensures that state q is a final state if AM reaches q on reading a word u \u2208 Pos . Similarly, the constraint\u2227\nu\u2208Neg \u2227 q\u2208Q xu,q \u2192 \u00acfq (15)\nmakes sure that state q is not a final state if AM reaches q on reading a word u \u2208 Neg , hence, asserting that all words of Neg are rejected.\nLet \u03d5Posn (d, f, x) denote Formula (14) and \u03d5 Neg n (d, f, x) denote Formula (15) where d, f , and x are as above. Then, we obtain the following results.\nLemma 4: Let S = (Pos,Neg ,Ex ,Uni) be a sample, n \u2265 1, and\n\u03c8Posn (d, f, x) := \u03d5 DFA n (d, f) \u2227 \u03d5Wn (d, f, x) \u2227 \u03d5Posn (d, f, x).\nThen, the following statements hold: 1) If M |= \u03c8Posn , then AM is a DFA with n states that\nsatisfies Pos \u2286 L(AM). 2) If a DFA B with n states exists that satisfies Pos \u2286 L(B),\nthen \u03c8Posn is satisfiable. Lemma 5: Let S = (Pos,Neg ,Ex ,Uni) be a sample, n \u2265 1,\nand\n\u03c8Negn (d, f, x) := \u03d5 DFA n (d, f) \u2227 \u03d5Wn (d, f, x) \u2227 \u03d5Negn (d, f, x).\nThen, the following statements hold: 1) If M |= \u03c8Negn , then AM is a DFA with n states that\nsatisfies Neg \u2229 L(AM) = \u2205. 2) If a DFA B with n states exists that satisfies Neg\u2229L(B) = \u2205, then \u03c8Negn is satisfiable.\nLet us now prove Lemma 4. The proof of Lemma 5 is analogous.\nProof of Lemma 4: To prove the Statement 1, assume M |= \u03c8Posn and let AM be the DFA constructed according to Definition 6. Furthermore, pick an arbitrary u \u2208 Pos . Then, Lemma 3 implies that if AM reaches state q on reading u, then M(xu,q) = true . Additionally, Formula (14) asserts that q is a final state and, therefore, AM accepts u by Definition 6. Since this is true for all u \u2208 Pos , we obtain Pos \u2286 L(AM).\nTo prove the second statement, let B = (QB,\u03a3, qB0 , \u03b4B, FB) be a DFA with n states that satisfies Pos \u2286 L(B). The key idea is to translate B into a valuation V that satisfies \u03c8Posn . To simplify this translation a bit, we assume without loss of generality that the sets of states of B and AM coincide (i.e., QB = Q); one can easily achieve this by renaming states. The definition of V is a follows: \u2022 For each p, q \u2208 QB and a \u2208 \u03a3, we set dp,a,q to true if\nand only if \u03b4B(p, a) = q. \u2022 For each q \u2208 QB, we set fq to true if and only if q \u2208 FB. \u2022 For each u \u2208 W , we set xu,q to true if and only if B : qB0\nu\u2212\u2192 q. It is not hard to verify that V indeed satisfies \u03c8Posn since V(xu,q) is defined according to the runs of B on the inputs u \u2208W .\nTHE FORMULA \u03d5Unin The formula \u03d5Unin needs to enforce that L(AM) respects all universal implications in Uni . (Recall that the learner stores universal and existential implication as a pair (u,A) where u \u2208 \u03a3\u2217 is a word and A is an NFA over \u03a3.) To achieve this, we construct for each universal implication \u03b9 = (u,A) \u2208 Uni a formula \u03d5\u03b9n that asserts L(A) \u2286 L(AM) if u \u2208 L(AM). The formulas \u03d5Unin is then the (finite) conjunction \u2227 \u03b9\u2208Uni \u03d5 \u03b9 n.\nGiven a universal implication \u03b9 \u2208 Uni , say \u03b9 = (u,A) with A = (QA,\u03a3, qA0 ,\u2206A, FA), the key idea of the formula \u03d5\u03b9n is to track the runs of AM and A in parallel. To this end, we introduce new auxiliary variables y\u03b9q,q\u2032 where q \u2208 Q and q\u2032 \u2208 QA, which have the following meaning: the variable y\u03b9q,q\u2032 is set to true if there exists a word v \u2208 \u03a3\u2217 such that AM : q0 v\u2212\u2192 q and A : qA0 v\u2212\u2192 q\u2032. The following constraints assert this.\ny\u03b9q0,qA0 (16)\u2227\np,q\u2208Q \u2227 (p\u2032,a,q\u2032)\u2208\u2206A (y\u03b9p,p\u2032 \u2227 dp,a,q)\u2192 y\u03b9q,q\u2032 (17)\nFormula (16) enforces y\u03b9 q0,qA0 to be set to true because AM : q0 \u03b5\u2212\u2192 q0 and A : qA0\n\u03b5\u2212\u2192 qA0 . Formula (17) is similar to Formula (13) and describes how the runs of AM and A proceed: if there exists a word v such that AM : q0\nv\u2212\u2192 p and A : qA0\nv\u2212\u2192 p\u2032 (i.e., y\u03b9p,p\u2032 is set to true) and there are transitions (p\u2032, a, q\u2032) \u2208 \u2206A and \u03b4(p, a) = q in AM, then AM : q0\nva\u2212\u2192 q and A : qA0\nva\u2212\u2192 q\u2032, which requires that y\u03b9q,q\u2032 has to be set to true as well.\nNote that the variables y\u03b9q,q\u2032 do not track runs exactly: it is possible that a variable yq,q\u2032 is set to true even without the\nexistence of a word v \u2208 \u03a3\u2217 that induces the runs AM : q0 v\u2212\u2192 q and A : qA0 v\u2212\u2192 q\u2032. This inaccuracy, however, is sufficient to obtain the desired result. In order to express that AM indeed respects the universal implication \u03b9, we add the implication\u2228 q\u2208Q xu,q \u2227 fq \u2192 \u2227 q\u2208Q \u2227 q\u2032\u2208FA y\u03b9q,q\u2032 \u2192 fq\n . (18) This formula ensures that whenever AM accepts u (i.e., the antecedent is true), then all words that lead to an accepting state in A also lead to an accepting state in AM (i.e., the consequent is true).\nLet \u03d5\u03b9n(d, f, x, y\u03b9) be the conjunction of Formulas (16), (17), and (18) where d, f , as well as x are as above and y\u03b9 is the list of all y\u03b9q,q\u2032 for q \u2208 Q and q\u2032 \u2208 QA. Additionally, let \u03d5Exn be the conjunction\n\u03d5Unin (d, f, x, y) := \u2227\n\u03b9\u2208Uni \u03d5\u03b9n(d, f, x, y \u03b9),\nwhere y denotes the list of all variables occurring in y\u03b9 for each \u03b9 \u2208 Uni . Then, the following holds.\nLemma 6: Let S = (Pos,Neg ,Ex ,Uni) be a sample, n \u2265 1, and\n\u03c8Unin (d, f, x, y) := \u03d5 DFA n (d, f)\n\u2227 \u03d5Wn (d, f, x) \u2227 \u03d5Unin (d, f, x, y).\nThen, the following statements hold: 1) If M |= \u03c8Unin , then AM is a DFA with n states that\nsatisfies for all (u,A) \u2208 Uni that u \u2208 L(AM) implies L(A) \u2286 L(AM). 2) If a DFA with n states exists that satisfies for all (u,A) \u2208 Uni that u \u2208 L(AM) implies L(A) \u2286 L(AM), then \u03c8Unin is satisfiable. Proof: We split the proof in two parts: we first show\nStatement 1 and subsequently Statement 2.\nTo prove Statement 1, we show that for an universal implication \u03b9 = (u,A) \u2208 Uni , a model M of the formula\n\u03c8\u03b9n(d, f, x, y \u03b9) := \u03d5DFAn (d, f) \u2227 \u03d5Wn (d, f, x) \u2227 \u03d5\u03b9n(d, f, x, y\u03b9)\nresults in an automaton AM that respects \u03b9 (i.e., u \u2208 L(AM) implies L(A) \u2286 L(AM)). The claim of Statement 1 then follows immediately because \u03d5Unin is the conjunction of the individual formulas \u03d5\u03b9n. In the following, fix an universal implication \u03b9 = (u,A) \u2208 Uni , assume M |= \u03c8\u03b9n, and let AM be the DFA constructed according to Definition 6.\nGiven an universal implication \u03b9 = (u,A), say with A = (QA,\u03a3, q0,\u2206A, FA), we first show by induction over the length of inputs v \u2208 \u03a3\u2217 that the variables y\u03b9q,q\u2032 have indeed the desired meaning (i.e., AM : q0 v\u2212\u2192 q and A : qA0 v\u2212\u2192 q\u2032 imply M(y\u03b9q,q\u2032) = true). Base case (v = \u03b5) Both AM : q0 \u03b5\u2212\u2192 q0 and A : qA0\n\u03b5\u2212\u2192 qA0 hold by definition of runs. Moreover, Formula (16) enforces M(y\u03b9\nq0,qA0 ) = true . Thus, the claim holds.\nInduction step (v = v\u2032a) Assume AM : q0 v\u2032\u2212\u2192 p a\u2212\u2192 q and\nA : qA0 v\u2032\u2212\u2192 p\u2032 a\u2212\u2192 q\u2032. Thus, there exists transitions (p\u2032, a, q\u2032) \u2208 \u2206A and \u03b4(p, a) = q; the latter means M(dp,a,q) = true by Definition 6. Moreover, applying the induction hypothesis yields M(y\u03b9p,p\u2032) = true. In this situation, Formula (17) enforces M(y\u03b9q,q\u2032) = true , which proves the claim.\nHaving established the meaning of the variables y\u03b9q,q\u2032 , it is now straightforward to prove thatAM satisfies L(A) \u2286 L(AM) if u \u2208 L(AM). If AM accepts u, say AM : q0\nu\u2212\u2192 q with q \u2208 F , then we know that M(xu,q) = true (by Lemma 3) and M(fq) = true (by Definition 6). In this situation, the antecedent of Formula (18) is satisfied. Thus, its consequent is necessarily satisfied as well because M is a satisfying assignment of \u03c8Unin . This, in turn, ensures that whenever A accepts a word v \u2208 \u03a3\u2217, say A : q\u03b90\nv\u2212\u2192 q\u2032 with q\u2032 \u2208 FA, then the run AM : q0\nv\u2212\u2192 q is also accepting: the induction above shows that M(y\u03b9q,q\u2032) = true and, since the consequent of Formula (18) ensures that M(y\u03b9q,q\u2032) = true implies M(fq) = true for all q \u2208 Q and q\u2032 \u2208 FA, also M(fq) = true holds. Hence, L(A) \u2286 L(AM) because v was chosen arbitrarily. Since these arguments are true for all \u03b9 \u2208 Uni , the DFA AM respects all implications in Uni .\nTo prove Statement 2, suppose that B = (QB,\u03a3, qB0 , \u03b4B, FB) is a DFA with n states that respects all universal implications in Uni . Similar to the proof of Lemma 3, we translate this DFA into a assignment V that satisfies \u03c8Unin . For the sake of this translation, we assume without loss of generality that the state stets of B and AM coincide (i.e., QB = Q).\nThe translation is as follows: \u2022 For each p, q \u2208 QB and a \u2208 \u03a3, we set V(dp,a,q) = true\nis and only if \u03b4B(p, a) = q. \u2022 For each q \u2208 QB, we set V(fq) = true if and only if q \u2208 FB. \u2022 For each u \u2208W and q \u2208 QB, we set V(xu,q) = true if and only if B : qB0\nu\u2212\u2192 q. \u2022 For each universal implication \u03b9 = (u,A) \u2208 Uni with A = (QA,\u03a3, qA0 ,\u2206A, FA), q \u2208 QB, and q\u2032 \u2208 QA, we set V(y\u03b9q,q\u2032) = true if a v \u2208 \u03a3\u2217 exists such that B : q0\nv\u2212\u2192 q and A : qA0\nv\u2212\u2192 q\u2032. It is not hard to verify that V satisfies \u03d5DFAn \u2227\u03d5Wn . To show that is also satisfies \u03d5Unin , fix a universal implication \u03b9 = (u,A), say with A = (QA,\u03a3, qA0 ,\u2206A, FA). We first observe that V satisfies Formulas (16) and (17) since the variables y\u03b9q,q\u2032 track the runs of both automata on inputs v \u2208 \u03a3\u2217. Second, if u /\u2208 L(B), then V does not satisfy the antecedent of Formula (18) and, hence, satisfies Formula (18). If u \u2208 L(B), on the other hand, consider the runs B : qB0 v\u2212\u2192 q and A : qA0 v\u2212\u2192 q\u2032 on some input v \u2208 \u03a3\u2217. Then, V(y\u03b9q,q\u2032) = true by definition of V. Moreover, if A accepts v (i.e., q\u2032 \u2208 FA), then B accepts v as well (i.e., q \u2208 FB) because B respects all implications in Uni . Hence, V(fq) = true by definition of V. Thus, the valuation V satisfies the consequent of Formula (18) (since v was chosen arbitrary), which implies that V satisfies Formula (18). Finally,\nwe note that these arguments are true for each \u03b9 \u2208 Uni and, thus, V satisfies \u03d5Unin .\nTHE FORMULA \u03d5Exn\nThe formula \u03d5Exn needs to enforce that L(AM) respects all existential implications in Ex . Similar to the previous formula, we construct for each existential implication \u03b9 = (u,A) \u2208 Ex a formula \u03c6\u03b9n that asserts L(AM) \u2229 L(A) 6= \u2205 if u \u2208 L(AM). The formulas \u03d5Exn is then the (finite) conjunction \u2227 \u03b9\u2208Ex \u03c6 \u03b9 n.\nThe formulas \u03c6\u03b9n work similar to the formulas \u03d5 \u03b9 n introduced above. Given an existential implication \u03b9 = (u,A), say with A = (QA,\u03a3, qA0 ,\u2206A, FA), the key idea is again to track the runs of AM and A in parallel. In contrast to \u03d5Unin , however, it is no longer sufficient to build upon the variables yq,q\u2032 as they do not track the runs exactly; recall that yq,q\u2032 might be set to true even without the existence of a word that induces runs to the state q \u2208 AM and q\u2032 \u2208 A. This fact prevents us from enforcing the existence of a word in the intersection L(AM) \u2229 L(A) based on the variables yq,q\u2032 (should this be necessary due to AM accepting the antecedent of \u03b9).\nWe approach this problem by tracking the parallel runs of AM and A exactly, exploiting the following simple fact about finite automata.\nObservation 1: Let B1 = (QB1 ,\u03a3, q B1 0 ,\u2206B1 , FB1) and B2 = (QB2 ,\u03a3, q B2 0 ,\u2206B2 , FB2) be two NFAs. Then, a word w \u2208 \u03a3\u2217 with B1 : qB10 w\u2212\u2192 q and B2 : qB20\nw\u2212\u2192 q\u2032 exists if and only if a word w\u2032 \u2208 \u03a3\u2217 of length at most |QB1 ||QB2 | \u2212 1 with B1 : qB10 w\u2032\u2212\u2192 q and B2 : qB20 w\u2032\u2212\u2192 q\u2032 exists.\nTo see why Observation 1 is true, suppose there exists an input w \u2208 \u03a3\u2217 of length greater than k = |QB1 ||QB2 | \u2212 1 with B1 : qB10 w\u2212\u2192 q and B2 : qB20 w\u2212\u2192 q\u2032. Then, there has to be a pair of states occurring in these runs that repeats at least once. The (nonempty) part of w in between this repetition can be removed, resulting in a word w\u2032 with B1 : qB10\nw\u2032\u2212\u2192 q and B2 : qB20\nw\u2032\u2212\u2192 q\u2032. By repeating this argument successively, one obtains a word of length less of equal to k that leads to state q in B1 and state q\u2032 in B2.\nAs Observation 1 shows, it is indeed enough to consider words of length at most k = n|A| \u2212 1 in order to track the parallel runs of AM and A exactly. We do so by means of new auxiliary variables z\u03b9q,q\u2032,` where q \u2208 Q, q\u2032 \u2208 QA, and ` \u2208 {0, . . . , k}, which have the following meaning: the variable z\u03b9q,q\u2032,` is set to true if and only if there exists a word v \u2208 \u03a3\u2217 with |v| = ` such that AM : q0 v\u2212\u2192 q and A : qA0\nv\u2212\u2192 q\u2032. The following formulas constrain the variables zq,q\u2032,` as described.\nz\u03b9q0,qA0 ,0 \u2227 \u2227 (q,q\u2032)\u2208Q\u00d7QA\\{(q0,qA0 )} \u00acz\u03b9q,q\u2032,0\n(19)\u2227 p,q\u2208Q \u2227 (p\u2032,a,q\u2032)\u2208\u2206A \u2227 `\u2208{0,...,k\u22121} (z\u03b9p,p\u2032,` \u2227 dp,a,q)\u2192 z\u03b9q,q\u2032,`+1\n(20)\n\u2227 q\u2208Q \u2227 q\u2032\u2208QA \u2227 `\u2208{1,...,k}\nz\u03b9q,q\u2032,` \u2192\u2228 p\u2208Q \u2228 (p\u2032,a,q\u2032)\u2208\u2206A dp,a,q \u2227 z\u03b9p,p\u2032,`\u22121 (21)\nFormula (19) makes sure that z\u03b9 q0,qA0 ,0 is set to true , whereas all other variables z\u03b9q,q\u2032,0 are set to false, since AM : q0 \u03b5\u2212\u2192 q0 and A : qA0 \u03b5\u2212\u2192 qA0 are the only runs on the empty word. Formula (20) is similar to Formula (13) and describes how the runs of both automata proceed: if there exists a word v \u2208 \u03a3\u2217 with |v| < k that induces the runs AM : q0\nv\u2212\u2192 q and A : qA0\nv\u2212\u2192 q\u2032 (i.e., z\u03b9q,q\u2032,|v| is set to true) and there exists transitions (p\u2032, a, q\u2032) \u2208 \u2206A and \u03b4(p, a) = q (i.e., dp,a,q is set to true), then the word va induces the runs AM : q0\nva\u2212\u2192 q and A : qA0\nva\u2212\u2192 q\u2032, which implies that z\u03b9q,q\u2032,|va| has to be set to true as well. In a similar manner, Formula (21) prevents z\u03b9q,q\u2032,` from being set to true if there exists no input of length ` that leads to the states q in AM and state q\u2032 in A; an exemption to this constraint is the pair of initial states.\nFinally, adding the implication\u2228 q\u2208Q xu,q \u2227 fq \u2192 \u2228 q\u2208Q \u2228 q\u2032\u2208FA \u2228 `\u2208{0,...,k} z\u03b9q,q\u2032,` \u2227 fq  (22)\nenforces that L(AM) indeed respects the implication \u03b9 = (u,A): if AM accepts u (signaled by the antecedent being true), then there also has to exist an input on which both automata reach final states (indicated by the consequent being set to true), hence, proving L(AM) \u2229 L(A) 6= \u2205.\nLet \u03c6\u03b9n(d, f, x, z\u03b9) be the conjunction of Formulas (19)\u2013(22) where d, f , and x are as above and z\u03b9 is a list of variables z\u03b9q,q\u2032,` for q \u2208 Q, q\u2032 \u2208 QA, and ` \u2208 {0, . . . , k}. Moreover, let \u03d5Exn be the conjunction\n\u03d5Exn (d, f, x, z) := \u2227 \u03b9\u2208Ex \u03c6\u03b9n(d, f, x, z \u03b9),\nwhere z denotes the list of all variables occurring in z\u03b9. Then, the following holds.\nLemma 7: Let S = (Pos,Neg ,Ex ,Uni) be a sample, n \u2265 1, and\n\u03c8Exn (d, f, x, z) := \u03d5 DFA n (d, f)\u2227\u03d5Wn (d, f, x)\u2227\u03d5Exn (d, f, x, z).\nThen, the following statements hold:\n1) If M |= \u03c8Exn , then AM is a DFA with n states that satisfies for all (u,A) \u2208 Ex that u \u2208 L(AM) implies L(AM) \u2229 L(A) 6= \u2205. 2) If a DFA with n states exists that satisfies for all (u,A) \u2208 Ex that u \u2208 L(AM) implies L(AM) \u2229 L(A) 6= \u2205, then \u03c8Exn is satisfiable.\nProof of Lemma 7: This proof is similar to the proof of Lemma 6. Again, we split this proof into two part: we first prove Statement 1 and subsequently Statement 2.\nTo prove Statement 1, we show that for an existential implication \u03b9 = (u,A) \u2208 Ex , a model of the formula \u03c8\u03b9n(d, f, x, z\n\u03b9) := \u03d5DFAn (d, f) \u2227 \u03d5Wn (d, f, x) \u2227 \u03c6\u03b9n(d, f, x, z\u03b9) results in an automaton AM that respects \u03b9 (i.e., u \u2208 L(AM) implies L(AM) \u2229 L(A) 6= \u2205). The claim of Statement 1 then follows immediately because \u03d5Exn is the conjunction of the individual formulas \u03c6\u03b9n. In the following, fix an existential implication \u03b9 = (u,A) \u2208 Ex , assume M |= \u03c8\u03b9n, let AM be the DFA constructed according to Definition 6 and k = n|QA|\u22121.\nWe first prove that the variable z\u03b9q,q\u2032,`, where ` \u2208 {0, . . . , k}, is set to true if and only if there exists a v \u2208 \u03a3\u2217 with |v| \u2264 ` such that AM : q0 v\u2212\u2192 q and A : qA0 v\u2212\u2192 q\u2032. This proof proceeds by induction over `. Base case (` = 0) The empty word \u03b5 is the unique word v \u2208\n\u03a3\u2217 with |v| = 0. By definition of runs, AM : q0 \u03b5\u2212\u2192 q0 and A : qA0 \u03b5\u2212\u2192 qA0 . Moreover, Formula (19) makes sure that z\u03b9 q0,qA0 ,0\nis set to true, whereas z\u03b9q,q\u2032,0 is set to false for all other pairs of states. In addition, Formula (21) does not restrict any variable in the case ` = 0. Hence, the claim holds. Induction step (` = `\u2032 + 1) To prove the direction from left to right, assume M(y\u03b9q,q\u2032,`) = true. Then, Formula (21) asserts that there exists a state p \u2208 Q and a transition (p\u2032, a, q\u2032) \u2208 \u2206 such that M(z\u03b9p,p\u2032,`\u2032) = true and M(dp,a,q) = true (the latter means that AM contains the transition \u03b4(p, a) = q). In addition, applying the induction hypothesis yields that there exists a word v\u2032 \u2208 \u03a3\u2217 with |v\u2032| = `\u2032 such that AM : q0 v\u2212\u2192 p and A : qA0 v\u2212\u2192 p\u2032. Thus,\nv = v\u2032a is a word of length ` satisfying AM : q0 v\u2212\u2192 q and A : qA0 v\u2212\u2192 q\u2032, which proves the claim. To prove the reverse direction, let v = v\u2032a \u2208 \u03a3\u2217 be a word of length ` and assume that AM : q0\nv\u2212\u2192 p a\u2212\u2192 q and A : qA0\nv\u2212\u2192 p\u2032 a\u2212\u2192 q\u2032. Thus, we know that (p\u2032, a, q\u2032) \u2208 \u2206A and \u03b4(p, a) = q (the latter implying M(dp,a,q) = true). In addition, applying the induction hypothesis yields M(zp,p\u2032,`\u2032) = true. In this situation, Formula (20) enforces that zq,q\u2032,` has to be set to true, which proves the claim.\nHaving established the correct meaning of the variables zq,q\u2032,`, proving that AM satisfies L(AM) \u2229 L(A) 6= \u2205 if u \u2208 L(AM) is now straightforward: If u \u2208 L(AM), say AM : q0\nu\u2212\u2192 q with q \u2208 F , then we know that xu,q is set to true (by Lemma 3) and that M(fq) = true (by Definition 6). In this situation, the antecedent of Formula (19) is satisfied, which implies that its consequent is satisfied as well (since M is a model of \u03c8\u03b9n). This means that there exist q \u2208 Q, q\u2032 \u2208 FA, and ` \u2208 {0, . . . , k} such that both M(zq,q\u2032,`) = true and M(fq) = true . The former asserts that there exists a word v \u2208 \u03a3\u2217 (of length `) such that AM : q0 v\u2212\u2192 q and A : qA0 v\u2212\u2192 q\u2032 (according to the induction above); on the other hand, the latter means q \u2208 F . Hence v is accepted by both automata and, consequently, u \u2208 L(AM) implies L(AM) \u2229 L(A) 6= \u2205.\nTo prove Statement 2, let B = (QB,\u03a3, qB0 , \u03b4B, FB) be a DFA with n states that satisfies L(B) \u2229 L(A) 6= \u2205 if u \u2208 L(B) for\nall (u,A) \u2208 Ex . Similar to the previous proofs, we translate B into a satisfying valuation V of the variables d, f , x, and z. For the sake of this translation, we once more assume without loss of generality that the sets of states of B and AM coincide (i.e., QB = Q). The definition of V then is as follows: \u2022 For each p, q \u2208 QB and a \u2208 \u03a3, we set V(dp,a,q) = true\nif and only if \u03b4B(p, a) = q. \u2022 For each q \u2208 QB, we set V(fq) = true if and only if q \u2208 FB. \u2022 For each u \u2208W and q \u2208 QB, we set V(xu,q) = true if and only if B : qB0\nu\u2212\u2192 q. \u2022 For each \u03b9 = (u,A) \u2208 Ex , where A =\n(QA,\u03a3, q A 0 ,\u2206A, FA), q \u2208 QB, and q\u2032 \u2208 QA, we set V(z\u03b9q,q\u2032,`) = true if and only if there exists a word v \u2208 \u03a3\u2217 with length ` \u2264 n|QA| \u2212 1 such that B : qB0\nv\u2212\u2192 q and A : qA0\nv\u2212\u2192 q\u2032 . It is not hard to verify that V satisfies \u03d5DFAn \u2227\u03d5Wn . To see why it also satisfies \u03d5Exn , pick a universal implication (u,A) \u2208 Ex , say with A = (QA,\u03a3, qA0 ,\u2206A, FA), and let k = |QB||QA| (recall that |QB| = n = |Q|). First, it is not hard to see that V satisfies Formulas (19) to (21) since these formulas exactly describe the runs of B and A on words of length at most k. Second, if u /\u2208 L(B), then V does not satisfy the antecedent of Formula (22) and, hence, satisfies Formula (22). If u \u2208 L(B), on the other hand, we know that L(B) \u2229 L(A) 6= \u2205.\nIn other words, there exists a word v \u2208 L(B) \u2229 L(A) such that B : qB0 v\u2212\u2192 q and A : qA0 v\u2212\u2192 q\u2032 where q \u2208 FB and q\u2032 \u2208 FA. Moreover, Observation 1 allows us to assume without loss of generality that |v| \u2264 k. In this situation, V(z\u03b9q,q\u2032,|v|) = true and V(fq) = true holds by definition of V. Hence, V satisfies the consequent of Formula (22), which implies that V satisfies Formula (22) as well. Finally, since these arguments are true for each \u03b9 \u2208 Ex , the valuation V satisfies \u03d5Exn ."}, {"heading": "APPENDIX B CORRECTNESS OF THE SAT LEARNER", "text": "The fact that formula \u03d5Sn has the desired properties is a straightforward corollary of Lemmas 4 to 7.\nCorollary 1: Let S = (Pos,Neg ,Ex ,Uni) be a sample, n \u2265 1, and\n\u03d5Sn(d, f, x, y, z) := \u03d5 DFA n (d, f)\u2227\u03d5Wn (d, f, x)\u2227\u03d5Posn (d, f, x)\n\u2227 \u03d5Negn (d, f, x) \u2227 \u03d5Unin (d, f, x, y) \u2227 \u03d5Exn (d, f, x, z).\nThen, the following statements hold: 1) If M |= \u03d5Sn , then AM is a DFA with n states that is\nconsistent with S. 2) If a DFA with n states exists that is consistent with S,\nthen \u03d5Sn is satisfiable. Having established that formula \u03d5Sn has the desired properties, we can now show that Algorithm 2 computes a smallest DFA that is consistent with a given sample.\nTheorem 3: Given a contradiction free-sample S , Algorithm 2 returns a minimal DFA (in terms of the number of states) that is consistent with S . In addition, if a minimal consistent DFA has k states, then Algorithm 2 terminates after k iterations.\nProof of Theorem 3: Theorem 3 follows directly from the properties of the formula \u03d5Sn (see Corollary 1): Given a sample S , suppose that a DFA with k states that is consistent with S exists. Then, the formula \u03d5Sn is satisfiable for all n \u2265 k. Moreover, if M |= \u03d5Sn , then AM is a DFA with n states that is consistent with S . Since Algorithm 2 increases the parameter n by one in every iteration (starting with n = 1), the algorithm eventually finds the smallest value for which \u03d5Sn is satisfiable (after k iterations) and, thus, a consistent DFA of minimal size.\nWe are now ready to prove the correctness of the SAT learner.\nTheorem 4: Given a teacher for a rational safety game, Algorithm 1, equipped with Algorithm 2 to construct conjectures, terminates and returns a (minimal) DFA accepting a winning set if one exists.\nProof of Theorem 4: Due to the way the teacher answers queries, is is clear that the DFA returned by the SAT learner accepts a winning set. Thus, it is left to show that the SAT learner terminates (given that a winning set exists) and that its result is of minimal size. To this end, we first make three observations:\n1) The SAT learner never conjectures the same DFA twice. This is due to the fact that the SAT learner only conjectures DFAs that are consistent with the sample of the iteration in which is was constructed. Moreover, a simple proof by contradiction shows that the conjecture of the current iteration is also consistent with the samples of all previous iterations since a new sample results from adding a counterexample (i.e., a word or an implication) to the sample the previous iteration. Hence, the conjectures Ai of iteration i and Aj of iteration j < i differ at least on the counterexample added in iteration j.\n2) The SAT learner conjectures DFAs that grow monotonically in size. To see why, suppose that conjecture Ai+1 of iteration i+ 1 has less states than the conjecture Ai of iteration i. As argued above, Ai+1 is also consistent with the sample Si, but has fewer states than Ai. This, however, contradicts the fact that Algorithm 2 always constructs consistent DFAs of minimal size (see Theorem 3).\n3) Any DFA accepting a winning set is consistent with any sample produces during the learning. In other words, adding counterexamples does not rule out solutions.\nTheorem 4 can now be proven as follows. Suppose that a winning set exists and let A be a smallest DFA, say with k states, that accepts a winning set. Since no smaller DFA accepting a winning set exists and due to Observations 1 and 2, we know that the SAT learner eventually conjectures a DFA with at least k states. Towards a contradiction, assume that the SAT learner does not conjecture a DFA with k accepting a winning set. This means that the learner eventually conjectures a DFA with more than k states. Then, however, Observation 3 in connection with the fact that the SAT learner always produces smallest consistent DFAs implies that there exists no DFA with k states accepting a winning set. This is a contradiction. Hence, the SAT learner eventually conjectures a minimal DFA\naccepting a winning set, which passes the teacher\u2019s query, and terminates."}, {"heading": "APPENDIX C RPNI LEARNER", "text": "The RPNI learner works in a restricted setting in which every vertex of the arena has a finite (but not necessarily bounded) number of outgoing edges (i.e., E({v}) is finite for all v \u2208 V ). This implies that implication counterexamples are of the form (u,A) with L(A) being finite.\nThe RPNI learner works identical to the SAT learner, but uses a different method to construct a consistent DFA from a sample. While the SAT learner uses a constraint solver for this task (see Algorithm 2), the RPNI learner employs a modified version of the popular RPNI algorithm [18], which is a polynomial time heuristic for learning DFAs from positive and negative words (we adapted the RPNI algorithm such that it now learns DFAs not only from positive and negative words but also from existential and universal implications). In contrast to Algorithm 2, however, the modified RPNI algorithm does not, in general, produce minimal consistent DFAs but is much faster. Hence, we encourage the reader to think of the RPNI learner as a heuristic, which uses a faster means to construct conjectures but can no longer guarantee to terminate given that a winning set exists.\nAs a preparatory step, we first present the original RPNI algorithm. Then, we show how to modify the RPNI algorithm such that it can handle existantial and universal in addition to positive and negative words. Finally, we present the RPNI learner and"}, {"heading": "A. The RPNI Algorithm", "text": "The RPNI algorithm is a so-called passive learning algorithm for regular languages. It takes two disjoint, finite sets Pos \u2282 \u03a3\u2217 and Neg \u2282 \u03a3\u2217 as input and constructs a DFA A that satisfies Pos \u2286 L(A) and Neg \u2229 L(A) = \u2205. The algorithm runs in time and space polynomial in |Pref (Pos \u222aNeg)| and, hence, the constructed DFA can, in general, not be minimal (as the problem it solves is NP-complete, see Gold [7]). It turns out, however, that the RPNI algorithm often produces \u201csmall\u201d automata in practice.\nThe RPNI algorithm operates on given sets Pos and Neg as follows. It first constructs the prefix-tree acceptor of the set Pos (i.e., the tree-like automaton that accepts exactly the set Pos). Then, it successively tries to merges states of this automaton (in a fixed order), where a merge is considered to be successful if the resulting DFA still rejects all words in Neg . If a merge was successful, RPNI proceeds to merge further states of the resulting automaton. If it was not successful, the merged automaton is discarded and RPNI proceeds with the automaton of the last successful merge. The algorithm stops once there are no more merges left.\nFor our purpose, it is helpful to view the RPNI algorithm as a concrete instance of a generic state-merging algorithm,\nwhich is sketched in pseudo code as Algorithm 3.4 In this more abstract setting, the learning algorithm takes a finite collection \u03ba of data as input and outputs a DFA that satisfies a given (decidable) property p (which usually refers to \u03ba); in the case of RPNI, \u03ba is the pair (Pos,Neg) and the property p states that the resulting DFA has to accept all words in Pos and to reject all words in Neg . The pivotal idea of Algorithm 3 is to start with a potentially large initial DFA that satisfies property p and then reduce its size by merging states, thereby discarding merges that result in a DFA that violates p. Since merging states of a DFA increase its language, we encourage the reader to think of merging as a means of generalization.\nAlgorithm 3: Generic state-merging algorithm\nInput: A collection of data \u03ba Output: A DFA machine A that passes test(A)\n1 Ainit = (Q,\u03a3, q0, \u03b4, f)\u2190 init(\u03ba); 2 (q0, . . . , qn)\u2190 order(Q); 3 \u223c0\u2190 {(q, q) | q \u2208 Q}; 4 for i = 1, . . . , n do 5 if qi 6\u223ci\u22121 qj for all j \u2208 {0, . . . , i\u2212 1} then 6 j \u2190 0; 7 repeat 8 Let \u223c be the smallest congruence that contains \u223ci\u22121 and the pair (qi, qj); 9 j \u2190 j + 1;\n10 until test(Ainit/\u223c); 11 \u223ci\u2190\u223c; 12 else 13 \u223ci\u2190\u223ci\u22121; 14 15 end\n16 return Ainit/\u223cn ;\nAlgorithm 3 uses three functions init, order, and test, which have the following effects: \u2022 The function init receives a finite collection of data as\ninput and returns a (potentially large) DFA that satisfies property p (assuming that this is possible).\n\u2022 The function order receives a finite set Q as input and returns an ordered sequence of the elements of Q.\n\u2022 The function test receives a DFA as input and returns a Boolean value indicating whether this DFA satisfies property p.\n(We shortly introduce implementations of these functions that allows us to compute a DFA that is consistent with a given finite sample.)\nAlgorithm 3 runs in two consecutive phases. In the first phase (Lines 1 and 2), it calls the function init with parameter \u03ba to construct an initial DFA Ainit that satisfies p (recall that we assume that this is possible). Then, it fixes an order\n4The description here closely follows the more general description by Garg et al. [6].\nq0, . . . , qn of the states of Ainit by calling the function order with parameter Q.\nThe actual merging takes place in the second phase (Lines 3 to 15), according to the order determined in the first phase. For i = 1, . . . , n and j = 0, . . . , i \u2212 1, the algorithm tries to merge state qi with state qj if state qi has not already been merged with a smaller state; since a merge might introduce nondeterminism, the algorithm merges additional states until determinism is restored. Note that we represent merging of states abstractly as constructing a congruence relation \u223c\u2286 Q \u00d7 Q (i.e., an equivalence relation that is compatible with the transition function) and the result of the merging as the quotient automaton Ainit/\u223c, which is defined in the usual way. A merge is kept only if the resulting automaton passes test (otherwise it is discarded). This preserves the invariant that any intermediate DFA Ainit/\u223ck satisfies property p (since Ainit/\u223c0 = Ainit satisfies p by definition of init). Hence, the final DFA is guaranteed to satisfy p as well."}, {"heading": "B. Adapting the Generic State Merging Algorithm", "text": "In our setting, the collection \u03ba corresponds to a sample S = (Pos,Neg ,Ex ,Uni), and the property p is consistency with S . We now describe how to implement the functions init, order, and test such that the output of Algorithm 3 is a DFA that is consistent with the input-sample S.\na) Creating an initial DFA: Given a sample S , we need to construct a DFA satisfying p (i.e., a DFA consistent with S). To this end, we follow the idea of the RPNI algorithm, namely to construct the prefixtree acceptor of the set Pos . The prefix tree acceptor of a finite set X \u2282 \u03a3\u2217 is a partial DFA5 that accepts exactly the set X . It is defined as follows.\nDefinition 7: Given an alphabet \u03a3 and finite set X \u2286 \u03a3\u2217, the prefix tree acceptor is the partial DFA AX = (Q,\u03a3, q0, \u03b4, F ) defined by\n\u2022 Q = Pref (X); \u2022 q0 = \u03b5; \u2022 F = X; and\n\u2022 \u03b4(u, a) = { ua if ua \u2208 Pref (X) and; undefined otherwise.\nA straightforward induction over the length of input-words proves L(AX) = X .\nHowever, just starting with the prefix tree acceptor APos is not sufficient as APos is not necessarily consistent with S: an implication (u,A) might require to accept a word v \u2208 L(A) (because u \u2208 L(APos)) that is not an element of Pos and, hence, is rejected by APos . In the case of universal implications, the problem is easy to resolve by (temporarily) adding L(A) to Pos (recall that L(A) is finite). However, the problem becomes more involved in the presence of existential implications as it is no longer apparent which word v \u2208 L(A) one should add to Pos in order to obtain a consistent (and preferable small) prefix tree acceptor.\n5A DFA is called partial if not all transitions are defined. Runs that cannot be continue due to missing transition are considered to be rejecting.\nWe approach this problem by using a straightforward translation into a satisfiability problem of formulas in propositional Boolean logic (the resulting satisfiability problem is much simpler than those generated by the SAT learner as it does not involve finding a minimal solution). Given a sample S = (Pos,Neg ,Ex ,Uni), we introduce a Boolean variable xw for each word w of the set\nV = Pos \u222aNeg \u222aAnte(Ex ) \u222aAnte(Uni)\n\u222a  \u22c3 (u,A)\u2208Ex L(A)  \u222a  \u22c3 (u,A)\u2208Uni L(A)  , which consists of all words occurring (explicitly and implicitly) in S. Since the languages of the automata occurring in S is finite, V is a finite set and, hence, the number of variables is finite as well.\nThe desired meaning of the variables is the following: xw is set to true if w either belongs to Pos or it is needs to be added to Pos in order to satisfy the implications. The following constraints enforce this meaning.\n( \u2227 w\u2208Pos xw ) \u2227  \u2227 w\u2208Neg \u00acxw  (23) \u2227\n(u,A)\u2208Ex xu \u21d2 \u2228 v\u2208L(A) xv  (24) \u2227\n(u,A)\u2208Uni xu \u21d2 \u2227 v\u2208L(A) xv  (25) Let \u03c7(x) be the conjunction of Formulas (23), (24), and (25) where x is the list of all variables w \u2208 V . Then, \u03c7(x) is satisfiable since we assume any sample to be contradictionfree. Moreover, if M is a model of \u03c7(x), then the prefix tree acceptor APos\u2032 of the set\nPos \u2032 = {w \u2208 V |M(w) = true}\nis consistent with S (i.e., satisfies p), which is formalized by the lemma below. This automaton is what the function init returns.\nLemma 8: Let S = (Pos,Neg ,Ex ,Uni) a contradiction-free sample. Then, the following holds:\n1) The formula \u03c7(x) is satisfiable. 2) If M a model of \u03c7(x) and\nPos \u2032 = {w \u2208 V |M(w) = true},\nthen the prefix tree acceptor APos\u2032 is consistent with S. Proof of Lemma 8: Since S is contradiction-free, there exists a DFA, let us denote it by B, that is consistent with S. If we assign true to the variable xw if and only if w \u2208 L(B), then this assignment satisfies \u03c7(x). This proves the first claim.\nThe proof of the second claim relies on the fact that the prefix tree acceptor of a set X \u2286 \u03a3\u2217 indeed accepts exactly the set X , which can be shown by a simple induction. Given\nthis fact, we first observe that APos\u2032 accepts all words in Pos since L(APos\u2032) = Pos \u2032 and Formula (23) ensures that Pos \u2286 Pos \u2032; moreover, a similar argument shows that APos\u2032 rejects all words in Neg . Second, Formula (24) asserts for each existential implication (u,A) \u2208 Ex that u \u2208 Pos \u2032 implies the existence of a v \u2208 L(A) with v \u2208 Pos \u2032 = L(APos\u2032). Hence, APos\u2032 respects all existential implications. Moreover, one can establish the fact that APos\u2032 respects all universal implications in an analogous manner by referring to Formula (25).\nb) Choosing the Merging Order: The function init returns a DFA whose set of states consists of words over the alphabet \u03a3. The order function order takes this set and orders it according to the canonical order of words6. This order is also used by RPNI.\nc) Implementing the Test: The function test needs to check whether a given automaton A is consistent with the finite sample S. Since S is a finite a collection of words, consistency can be decided easily by computing the runs of A on those words and checking whether all four conditions (i.e., acceptance of all words in Pos , rejection of all words in Neg , and respecting both types of implications) are fulfilled."}, {"heading": "C. Correctness of the RPNI learner", "text": "The correctness of the RPNI learner relies on the correctness of Algorithm 3, which is stated in the next lemma.\nLemma 9: Given a contradiction-free sample S , Algorithm 3 modified as described in Appendix C-B constructs a DFA that is consistent with S. The resulting automaton comprises at most |V | states.\nProof of Lemma 9: Proving that Algorithm 3 constructs a DFA that is consistent with the given sample S is straightforward: the function init constructs an initial DFA that is consistent with S (see Lemma 8), and a merge is only kept if the merged DFA passes the check test (i.e., it is still consistent); hence, the final DFA is guaranteed to be consistent as well. Since the initial DFA has |V | states and merging of states reduces the number of states, the final DFA has at most |V | states.\nThe correctness of the RPNI learner immediately follows from the fact that the learning terminates only if the learner proposes a DFA accepting a winning set. In contrast to the SAT learner, however, the RPNI learner uses an algorithm to derive conjectures that does not necessarily produce consistent DFAs of minimal size. As a consequence, termination of the RPNI learner is not guaranteed even if a DFA accepting a winning set exists. The following theorem summarizes the main result.\nTheorem 5: Given a teacher for a rational safety game over a finitely branching arena, the RPNI learner (i.e., Algorithm 1 equipped with Algorithm 3 to construct conjectures) on termination returns a DFA accepting a winning set.\n6Given an alphabet \u03a3 and a total order <\u03a3\u2282 \u03a3\u00d7 \u03a3, the canonical order of words \u227a\u2282 \u03a3\u2217 \u00d7 \u03a3\u2217 is defined by a1 . . . am \u227a b1 . . . bn if and only if m < n or there exists an i \u2208 {1, . . . ,m} such that ai <\u03a3 bi and aj = bj for all j \u2208 {1, . . . , i\u2212 1}."}], "references": [{"title": "Infinite games played on finite graphs", "author": ["R. McNaughton"], "venue": "Ann. Pure Appl. Logic, vol. 65, no. 2, pp. 149\u2013184, 1993.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1993}, {"title": "A simple inductive synthesis methodology and its applications", "author": ["S. Itzhaky", "S. Gulwani", "N. Immerman", "M. Sagiv"], "venue": "OOPSLA 2010. ACM, 2010, pp. 36\u201346.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "Slugs GR(1) synthesizer", "author": ["R. Ehlers", "V. Raman", "C. Finucane"], "venue": "2014, available at https://github.com/LTLMoP/slugs/.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Acacia+, a tool for ltl synthesis", "author": ["A. Bohy", "V. Bruy\u00e8re", "E. Filiot", "N. Jin", "J.-F. Raskin"], "venue": "CAV, 2012, pp. 652\u2013657.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Regular model checking", "author": ["A. Bouajjani", "B. Jonsson", "M. Nilsson", "T. Touili"], "venue": "CAV 2000, ser. LNCS, vol. 1855. Springer, 2000, pp. 403\u2013418.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2000}, {"title": "ICE: A robust framework for learning invariants", "author": ["P. Garg", "C. L\u00f6ding", "P. Madhusudan", "D. Neider"], "venue": "CAV 2014, ser. LNCS, vol. 8559. Springer, 2014, pp. 69\u201387.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Complexity of automaton identification from given data", "author": ["E.M. Gold"], "venue": "Information and Control, vol. 37, no. 3, pp. 302\u2013320, 1978.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1978}, {"title": "Learning regular sets from queries and counterexamples", "author": ["D. Angluin"], "venue": "Inf. Comput., vol. 75, no. 2, pp. 87\u2013106, 1987.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1987}, {"title": "An automata-theoretic approach to infinite-state systems", "author": ["O. Kupferman", "N. Piterman", "M.Y. Vardi"], "venue": "Time for Verification, Essays in Memory of Amir Pnueli, ser. LNCS, vol. 6200. Springer, 2010, pp. 202\u2013259.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "A constraint-based approach to solving games on infinite graphs", "author": ["T.A. Beyene", "S. Chaudhuri", "C. Popeea", "A. Rybalchenko"], "venue": "POPL 2014. ACM, 2014, pp. 221\u2013234.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Reachability games on automatic graphs", "author": ["D. Neider"], "venue": "CIAA 2010, ser. LNCS, vol. 6482. Springer, 2010, pp. 222\u2013230.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "Small strategies for safety games", "author": ["\u2014\u2014"], "venue": "ATVA 2011, ser. LNCS, vol. 6996. Springer, 2011, pp. 306\u2013320.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "Finite presentations of infinite structures: Automata and interpretations", "author": ["A. Blumensath", "E. Gr\u00e4del"], "venue": "Theory Comput. Syst., vol. 37, no. 6, pp. 641\u2013674, 2004.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2004}, {"title": "Regular model checking using solver technologies and automata learning", "author": ["D. Neider", "N. Jansen"], "venue": "NFM 2013, ser. LNCS, vol. 7871. Springer, 2013, pp. 16\u201331.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Exact DFA identification using SAT solvers", "author": ["M. Heule", "S. Verwer"], "venue": "ICGI 2010, ser. LNCS, vol. 6339. Springer, 2010, pp. 66\u201379.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "dk.brics.automaton \u2013 finite-state automata and regular expressions for Java", "author": ["A. M\u00f8ller"], "venue": "2010, http://www.brics.dk/automaton/.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "Z3: an efficient SMT solver", "author": ["L.M. de Moura", "N. Bj\u00f8rner"], "venue": "TACAS 2008, ser. LNCS, vol. 4963. Springer, 2008, pp. 337\u2013340.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "We model the interaction between a controlled system and its possibly adversarial environment as a two-player game over a graph [1].", "startOffset": 128, "endOffset": 131}, {"referenceID": 1, "context": "learning takes place in a setting akin to counterexample-guided inductive synthesis (CEGIS) [2] between a teacher, who has knowledge about the safety game in question, and a learner, whose objective is to identify a controller using information disclosed by the teacher in response to (incorrect) conjectures.", "startOffset": 92, "endOffset": 95}, {"referenceID": 2, "context": "Additionally, in situations where a complete description of the game is not available in a format amenable to existing game solvers [3], [4], there may still exist human experts (or automated oracles, as in Section IV) who have sufficient insight into how the controlled system should behave and can act as teacher.", "startOffset": 132, "endOffset": 135}, {"referenceID": 3, "context": "Additionally, in situations where a complete description of the game is not available in a format amenable to existing game solvers [3], [4], there may still exist human experts (or automated oracles, as in Section IV) who have sufficient insight into how the controlled system should behave and can act as teacher.", "startOffset": 137, "endOffset": 140}, {"referenceID": 4, "context": "Hence, one of our main contributions is a symbolic representation of safety games, called rational safety games, that follows the idea of regular model checking [5] in that it represent sets of vertices by regular languages and edges by so-called rational relations.", "startOffset": 161, "endOffset": 164}, {"referenceID": 5, "context": "Following the ICE learning framework [6] and partially deviating from the classical learning frameworks for regular languages [7], [8], the counterexample may be one of the following four types: positive, negative, existential implication and universal", "startOffset": 37, "endOffset": 40}, {"referenceID": 6, "context": "Following the ICE learning framework [6] and partially deviating from the classical learning frameworks for regular languages [7], [8], the counterexample may be one of the following four types: positive, negative, existential implication and universal", "startOffset": 126, "endOffset": 129}, {"referenceID": 7, "context": "Following the ICE learning framework [6] and partially deviating from the classical learning frameworks for regular languages [7], [8], the counterexample may be one of the following four types: positive, negative, existential implication and universal", "startOffset": 131, "endOffset": 134}, {"referenceID": 8, "context": "in the past, predominantly in the case of games over pushdown graphs [9].", "startOffset": 69, "endOffset": 72}, {"referenceID": 9, "context": "Also, a constraint-based approach to solving games over infinite graphs has recently been proposed [10].", "startOffset": 99, "endOffset": 103}, {"referenceID": 10, "context": "Learning-based techniques for games over infinite graphs have already been studied in the context of reachability games [11]; in fact, our symbolic representation of safety games is a generalization of the representation proposed there.", "startOffset": 120, "endOffset": 124}, {"referenceID": 11, "context": "In the context of safety games, recent work [12] has already demonstrated the ability of learning-based approaches to extract small reactive controllers from a priori constructed controllers with possibly large number of states.", "startOffset": 44, "endOffset": 48}, {"referenceID": 0, "context": ", infinite duration two-person games on graphs) as popularized by McNaughton [1].", "startOffset": 77, "endOffset": 80}, {"referenceID": 4, "context": "We follow the idea of regular model checking [5], an approach in verification, and represent sets of vertices by regular languages and edges by so-called rational relations.", "startOffset": 45, "endOffset": 48}, {"referenceID": 12, "context": "(This definition of rational relations is simplified from that in [13] but sufficient for our purpose.", "startOffset": 66, "endOffset": 70}, {"referenceID": 5, "context": "[6], which deals with learning loop invariants from positive and negative data as well as", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "The learning proceeds in a CEGIS-style loop [2].", "startOffset": 44, "endOffset": 47}, {"referenceID": 6, "context": "It is important to note that classical learning frameworks for regular languages that involve learning from positive and negative data only, such as Gold\u2019s passive learning [7] or Angluin\u2019s active learning [8], are insufficient in our setting.", "startOffset": 173, "endOffset": 176}, {"referenceID": 7, "context": "It is important to note that classical learning frameworks for regular languages that involve learning from positive and negative data only, such as Gold\u2019s passive learning [7] or Angluin\u2019s active learning [8], are insufficient in our setting.", "startOffset": 206, "endOffset": 209}, {"referenceID": 5, "context": "[6] argue comprehensively why implications needed in a robust invariant learning framework.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": ", the corresponding decision problem is NP-complete) already in the absence of implications [7].", "startOffset": 92, "endOffset": 95}, {"referenceID": 13, "context": "Our encoding of transitions and final states follows an idea from [14] (independently due to [15]).", "startOffset": 66, "endOffset": 70}, {"referenceID": 14, "context": "Our encoding of transitions and final states follows an idea from [14] (independently due to [15]).", "startOffset": 93, "endOffset": 97}, {"referenceID": 13, "context": "A description of \u03c6 n and \u03c6 Neg n can also be found in [14].", "startOffset": 54, "endOffset": 58}, {"referenceID": 15, "context": "In order to demonstrate the feasibility of our learning approach, we implemented a Java prototype using the BRICS automaton library [16] and Microsoft\u2019s Z3 [17] constraint solver.", "startOffset": 132, "endOffset": 136}, {"referenceID": 16, "context": "In order to demonstrate the feasibility of our learning approach, we implemented a Java prototype using the BRICS automaton library [16] and Microsoft\u2019s Z3 [17] constraint solver.", "startOffset": 156, "endOffset": 160}, {"referenceID": 9, "context": "[10].", "startOffset": 0, "endOffset": 4}], "year": 2016, "abstractText": "We propose a method to construct finite-state reactive controllers for systems whose interactions with their adversarial environment are modeled by infinite-duration twoplayer games over (possibly) infinite graphs. The proposed method targets safety games with infinitely many states or with such a large number of states that it would be impractical\u2014 if not impossible\u2014for conventional synthesis techniques that work on the entire state space. We resort to constructing finitestate controllers for such systems through an automata learning approach, utilizing a symbolic representation of the underlying game that is based on finite automata. Throughout the learning process, the learner maintains an approximation of the winning region (represented as a finite automaton) and refines it using different types of counterexamples provided by the teacher until a satisfactory controller can be derived (if one exists). We present a symbolic representation of safety games (inspired by regular model checking), propose implementations of the learner and teacher, and evaluate their performance on examples motivated by robotic motion planning in dynamic environments.", "creator": "LaTeX with hyperref package"}}}