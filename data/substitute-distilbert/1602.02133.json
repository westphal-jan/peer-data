{"id": "1602.02133", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Feb-2016", "title": "Mining Software Quality from Software Reviews: Research Trends and Open Issues", "abstract": "software scraping text fragments have considerably valuable information about users experience. it includes to huge set of properties including the software quality. opinion mining or relationship analysis is concerned \" analyzing internal user judgments. the application of feedback analysis on software reviews can raise a quantitative value that represents software quality. although many software quality methods are proposed these are considered difficult to customize and many of them are limited. 3rd article investigates the scope of opinion mining as an approach to extract software quality properties. we found that the major issues of software reviews mining using sentiment analysis are due to software diversity and the diverse users and teams.", "histories": [["v1", "Fri, 5 Feb 2016 19:42:24 GMT  (606kb)", "http://arxiv.org/abs/1602.02133v1", "11 pages"]], "COMMENTS": "11 pages", "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["issa atoum", "ahmed otoom"], "accepted": false, "id": "1602.02133"}, "pdf": {"name": "1602.02133.pdf", "metadata": {"source": "CRF", "title": "Mining Software Quality from Software Reviews: Research Trends and Open Issues", "authors": ["Issa Atoum", "Ahmed Otoom"], "emails": ["@article{Atoum2016,", "Issa.Atoum@wise.edu.jo", "aotoom@rjaf.mil.jo"], "sections": [{"heading": null, "text": "considerably valuable information about users\u2019 experience. It includes a huge set of properties including the software quality. Opinion mining or sentiment analysis is concerned with analyzing textual user judgments. The application of sentiment analysis on software reviews can find a quantitative value that represents software quality. Although many software quality methods are proposed they are considered difficult to customize and many of them are limited. This article investigates the application of opinion mining as an approach to extract software quality properties. We found that the major issues of software reviews mining using sentiment analysis are due to software lifecycle and the diverse users and teams.\nKeywords\u2014Software Quality-in-use, Clustering, Topic Models, Opinion Mining Tasks\nI. INTRODUCTION\nThe World Wide Web and the social media are an invaluable source of business information. For instance, the software reviews on a website can help users make purchase decisions and enable enterprises to improve their business strategies. Studies showed that online reviews have real economic values [1].The process of extracting information for a decision making from text is referred to as opinion mining or sentiment analysis.\nFormally, \u201cSentiment analysis or opinion mining refers to the application of natural language processing, computational linguistics, and text analytics to identify and extract subjective information in source materials\u201d [2, p. 415]. Pang [3] stated that: although many authors use the term \u201csentiment analysis\u201d to refer to classifying reviews as positive or negative, nowadays it has been taken to mean the computational treatment of opinion, sentiment, and subjectivity in text [3]. Liu [4] identified that the sentiment analysis is more widely used in industry but sentiment analysis and opinion mining are both used in the academia [4]. Both terms are used interchangeably in this article.\nThus, opinion mining is important to organizations and individuals. Organizations can study the products (software) trends over time and respond accordingly. On the other hand, software users often seek advices on\nsoftware products by reading user reviews found on websites such cnet.com, epinions.com and amazon.com. The software reviews are helpful for users in that it has information about user experience (i.e. Software quality). Garvin [5] identified five views/approaches of quality. The nearest definition to this work is the user based approach definition \u201cmeeting customer needs\u201d.\nTo our knowledge little research has been published in the domain of opinion mining over software reviews [6], [7][8], [9]. Mining software reviews can save users time and can help them in software selection process that is time consuming. The most widely used surveys[2], [3], [10] are for products in general and none of them have studied the specialty of a specific review domain. The significance of this article is that it is showed by examples and it details the applicability of sentiment analysis tasks over software quality properties. Further this article identifies major issues to software quality mining using sentiment analysis.\nII. RELATED WORK\nSoftware quality has been studied in many models[11], [12] but [13] found that they are limited. Atoum et al. [13] have studied several issues with current software quality models. They showed that studied models are either limited or hard to customize. Atoum et al. [14] suggested to build a dataset of software quality-in-use toward solving this problem. They further proposed two frameworks towards solving this problem[6], [15]. A complete model of software prediction were also proposed in [7], [16]. Their frameworks are based on software quality-in-use keywords and a built ontology.\nOpinion mining can be framed as a text classification task where the categories are polarities (positive and negative). Text mining has been discussed in topic models[17] and features clusters (i.e. grouping) [18]. There are many text classification approaches; Na\u00efve Bayes[19], Support Vector Machines[20], and Maximum Entropy [21].\nThe semi-supervised learning approaches [20] uses a small set of labelled data and large set of unlabelled data for training. The technique is suitable to take buy in from the user without burdening him with costly labelling for all training data[22], [23], [24].\nIn the same category a famous family known as topic models are widely used[25][26], [27]. The Latent Semantic (LSA) model [25][26], [27] transforms text to low dimensional matrix and it finds the most common terms that can appear together in the processed text. Wendy et al.[25] applied the LSA in order get the software quality-in-use properties. [28] proposed Probabilistic Latent Semantic Analysis (PLSA) model. The approach aims automatic document indexing based on statistical latent model of counted terms per document.\nTo our knowledge, little research has been conducted in order to study the sentiment analysis on software quality. Most works considers various products while others are not comprehensive.\nIII. PROBLEM DEFINITION\n[29] defined opinion mining problem consisting of these components: topic, opinion holder, sentiment and claim. [30] defined it the same way but with different components: opinion holder, subject, aspect, evaluation where subject and aspect map to topic in Kim model [29], and evaluation maps to claim and sentiment. Probably the most comprehensive definition is given by Liu [2]. An Opinion is defined as (ei, aij,ooijkl,hk,tl) where ei is the name of an entity, aij is an aspect of ei, ooijkl is the orientation of the opinion about aspect aij of entity ei, hk is the opinion holder, and tl is the time when the opinion is expressed by hk. if the entity is merged with the aspect as an opinion target then the definition becomes (gi,ooijkl,hk,tl) such that g is topic/entity/properties. In other words, the ej and aij are the opinion target. The opinion orientation ooijkl can be positive, negative or neutral. When an opinion is on the entity itself as a whole a special aspect called GENERAL is used to represent the opinion. Throughout this article Liu [2] definition of opinion mining is adopted.\nThe Objective of opinion mining, given a set of opinionated reviews d , discover all opinion quintuples, then extract entity, aspects, time, opinion holder and then assign sentiment orientation to aspects and group them accordingly. As mentioned earlier, we are concerned with aspect extraction, aspect assignment orientation and aspect grouping tasks.\nHowever, the most important properties of an opinion mining are the aspects and opinions because the opinion holder and the time is usually known in software reviews. Furthermore, the concerned entity is implied by the software name because software granulates properties at the software level and not as a functional component. Therefore, this article concentrate on aspect, orientation and target.\nThe example below shows a text fragment of a software review (AVG antivirus) extracted from Cnet.com website which was posted on April 20, 2013 by kydna. The numbers indicate the sentence numbersub sentence:\n(1) I've used AVG Free for many years, and have been quite satisfied with it (2-1) until an alert from the software that stated, (2-2)\"Resident Shield component not active.\" (3-1)This means that the program is not updating itself as it should, (3-2) leaving one vulnerable to potential threats. (4-1)Every time I booted up my system, AVG would hang on updating itself, (4-2)chugging and churning for at least 4-5 minutes, (4-3) only to shut down and restart without a current update.\nThe opinion according to the previous definition is as\nfollows:\n Entity: AVG Free, software, program, system, Resident Shield component.\n Aspects: alert, boot, updating chugging and churning, hang.\n Opinion holder: Review author (kydna)\n Time: April 20, 2013\n Opinion Orientation: positive for sentence 1, negative for sentence 2-1,etc.\n Quintuples example: (AVG Free, GENERAL, positive, kydna, April 20,\n2013) from sentence (1)\nIV. OPINION MINING TASKS\nThe main task of sentiment classification is an effective set of features. So, given a set of reviews the general opining mining tasks are: identify and extract object features/entities, determine the opinion on them, group synonyms of features, and finally summarize and present data to users. Below are major research topics and tasks in opinion mining and sentiment analysis grouped in interrelated groups."}, {"heading": "Subjectivity Analysis", "text": "Subjectivity classification aims to find if a review sentence is subjective or objective, usually in the presence of an opinion expression in a sentence. A sentence is considered an objective sentence if it has some factual information and is considered subjective if it expresses personal feelings, views, emotions, or beliefs. For example the sentence \u201cThe layers tools need work.\u201d is an objective sentence while the sentence \u201cthat's great antivirus\u201d is a subjective sentence. However, it is not always easy to detect subjective sentences because sometimes objective sentences can contain opinion, for example the sentence \u201cTo use its best features, you must have the paid version.\u201d is an objective sentence but it indicates a negative opinion about the software.\nTwo classes of subjectivity detection approaches have been proposed; the supervised and the unsupervised learning approaches. In supervised learning approaches, subjectivity classification has been regularly solved as binary classification\nproblem[31]. Pang et al. [32] used min-cut partition based on the assumptions that nearby sentences usually discuss the same topics. [33]used election history to train a SVM on new election posts. [34] proposed an approach to automatically distinguish between subjective and objective segments and between implicit and explicit opinions based on 4 different classes of subjectivity.[35] classified the subjectivity of tweets based on features and Twitter clues. In unsupervised learning ,[36] used the presence of subjective expressions extracted using the concept of grade expressions [37]. A gradable expression has a varying strength depending on a standard; for example the small planet is larger than the large house. [38] used bootstrapping approach to learn two classifiers for subject/objective sentences based on lexical items.\nAnalyzing the software reviews; sentences are usually short and it is very common to find objective and subjective sentences. For example the sentences \u201cworks for me\u201d or \u201cits free\u201d are common in software reviews. These sentences are objective, but they indicate a positive opinion. There are also shorter sentence fragments such as the sentence \u201cselfupdating\u201d, \u201cself-regulating\u201d, \u201cOk.\u201d . Consequently, subjectivity analysis is very important to software quality."}, {"heading": "Opinion Lexical Expansion", "text": "To classify a review at the document level, the sentence level or at the aspect level, a set of opening words is needed. They are commonly called in literature as sentiment words, opening words, polar words, or opinion bearing words. These words carry the opinion on a specific entity, usually with a positive or negative polarity. The positive sentiment expresses some desired state or qualities whereas the negative sentiment words are used to express some undesired sates or qualities. Sentiment words have two types; the base type such as the words beautiful and bad, and the comparative type such as the words better, best, worst.\nThe collection of opinion expressions that are used for classification are called the lexicon. A lexicon is the set of opinion words, sentiment phrases and idioms. The lexicon acquisition or expansion is achieved through three techniques: the manual approach, the dictionarybased approach [39]\u2013[43] and the corpus-based approach [37], [44]\u2013[46].The manual approach is not feasible because it is very hard to build a comprehensive lexicon. The dictionary-based approaches use seed opinion words and grow set from an online dictionary like WordNet. The Corpus-based approach discovers additional sentiment words from a domain using general sentiment seeds and adapts general purpose sentiment using a domain corpus. The dictionary-based approach makes it is easy to get words from dictionary but it is domain independent and thus it may not identify the polarity of a word for a specific domain. On the\nother hand, while corpus-based approach can detect domain specific opinions it is still not easy to build since the same word may have a positive or negative polarity in the same domain in different contexts[47]. Other lexical expansion approaches are based on dependency parser[48], [49], connotation lexicon [50].\nTo our knowledge there is no special lexicon for software quality[14], [51]. Thus general lexicon words such as SentiWordNet words could be used. The investigation on a software reviews found that it is uncommon to find one lexicon word with two different orientations. The sentence \u201cLoads quick, scans quick too!\u201d is positive, while the sentence \u201cI have always wanted to see a quick disable function rather than clicking on the Resident Shield\u201d is negative."}, {"heading": "Classification", "text": "Classification at the Review Level:\nFrom information retrieval domain every review can be considered as a single document assuming that each opinionated document expresses an opinion on a single entity from a single holder. Reviewers have star rating of satisfaction starting by 1 and ending in 5. They can be used for classification (e.g. 1,2  negative, 3 neutral, 4,5 positive) by using any learning algorithm (e.g. Na\u00efve Bayes , SVM or Maximum Entropy.\nOther approaches uses the Term-Frequency Inverted-Document-Frequency (TF-IDF) information retrieval model. [52], [53] used review rating regression prediction models on user ratings. Turney proposed unsupervised learning approach [54]. Turney first extracted adjectives and adverbs confirming to a predefined syntactic rules and then estimated the orientation based on Point Mutual Inclusion measure equations from web search engine. Then finally, the average Sentiment orientation (SO) is computed for all phrases in the review. The review is classified as recommended if the average sentiment orientation is positive and not recommended otherwise.\nIs it helpful to classify software reviews at the document (review) level? Why? It depends on the needed task. If the task is just user satisfaction, it will be acceptable because sentences are usually short. More practically it can be good to have the classification at the level of review section (e.g. cent pros, cons or summary in cent.com reviews). If user needs to know the underlying topics that are being discussed, then this level will not be helpful.\nClassification at the Sentence Level:\nTo classify a sentence to its sentiments, it is first identified as a subjective or objective sentence. The assumption is that the sentence expresses a single opinion from a single holder. Most approaches use supervised learning to learn sentences polarity[31]. [31]\nproposed a minimum cuts graph-based approach, assuming that neighboring sentences should have the same subjectivity classification. [55] proposed a lexicon based algorithm to calculate the total orientation by summing the orientation of sentiment words in a sentence. Shein et al. [56] proposed to utilize a domain ontology to extract features and then they used binary SVM to classify sentences. [57] proposed an unsupervised approach that is based on the average Log-likehood of words in a sentence. [58] proposed a semi-supervised learning algorithm to learn from a small set of labeled sentences and a large set of unlabeled sentences. [59] identified that conditional sentences has to be taken in their algorithm to deal with different types of if statements. It is noted that sarcastic sentences are not very common in reviews of software reviews.\nIs it helpful to classify software reviews at sentence level? Why? Yes if it is linked with underlying topics (features). Another problem, many sentences has implicit topics that can be induced at the global sentence level. The sentence \u201cStops anything on the internet if there is a problem\u201d, indicates a positive opinion about antivirus protection feature. Therefore we should assume that each software sentence is talking about one topic. Consequently, the sentence classification is linked with feature classification in order to map topics to sentences."}, {"heading": "Classification at the Feature Level", "text": "The purpose of aspect (also called feature or topic) sentiment classification is to identify the sentiment or the opinion expressed on each aspect. The aspect sentiment classification methods frequently uses a lexicon , a list of opinion words and phrases to determine the orientation of an aspect in a sentence [45], [55]. They first marked opinion words as positive or negative. Next they handled opinion shifters (valence shifters). Then they aggregated opinion score as the summation of all opinions over the distance between the word and the aspect.\nThree main approaches are reported in literature; supervised[60] [61] [45] [62] [59], lexicon-based[63], [64] [65] [23], and topic modeling approaches[18], [21], [66], [67]. The supervised approach challenge is how to determine the scope of each sentiment expression over the aspect of the interest (i.e. dependency)[60]. Some of these works are discussed in the next section.\nIs it helpful to classify software reviews at feature level? Why? Yes if it shows user aspects and software features that makes it good or the software glitches that makes it bad."}, {"heading": "Feature Extraction", "text": "Classifying opinion texts at the document or sentence level is insufficient because no opinion targets are defined at that level. Although sentence level classification can give good results, it does not suit compound and complex sentences. [68] showed the emergence need to identify the topic of each sentence. Users need to discover the aspects and determine whether the sentiment is positive or negative on each aspect. The purpose of aspect sentiment analysis is to determine whether the opinions on different aspect are positive, negative or neutral. Given the sentence \u201cThe interface is quite better than the previous version\u201d and \u201cGreat Antivirus software\u201d we can say that both of them are positive but the second is about the GENERAL aspect or the entity Antivirus whereas the first is about interface of the antivirus. [54, p. 8] clarified that \u201cthe whole is not necessarily the sum of the parts\u201d. Wilson et al. [69] pointed out that the strength of opinions expressed in individual clauses is important as well as pointing out subjective and objective clauses in a sentence. They showed four sentiment levels (neutral, low, medium, high).\nExplicit Feature Extraction:\nFinding the important aspect of interest for a user is the most important task in sentiment analysis. Feature extraction has been studied in supervised learning approaches [70], [71], frequency based approaches [39], [55], [60], [72]\u2013[75], bootstrapping (from lexicon words or candidate features) [48], [49], [76]\u2013[79], and as a topic modeling approaches [18], [21], [66], [67].\nIn supervised mining [70], [71] proposed to use label sequential rules: The rules that involve a feature (called language patterns) are found given that it satisfies predefined support and confidence. Then the sentence segment is matched with language pattern and a feature is returned. [75] proposed a supervised based model based on Ku method [80]. The frequency-based approach [55]finds frequent nouns and noun phrases as aspects. It also finds infrequent aspect exploiting relationships between aspects and opinion words [72] [55] [72] [74] [80]. [60] integrated WordNet, and movie reviews to extract frequent feature and opinion pairs. [40] refined the frequent noun phrase to consider any noun phrase in sentiment bearings.\nVarious works [48], [49], [76]\u2013[78] extract domain independent aspect and opinion words. Qiu et al. [48] [49] double propagation approach is a bootstrapping method based on dependency grammar of [81].[77] extracted features that are associated with opinion words and ranked them according to additional patterns. Recently association between features and opinions using LSA and likelihood ratio test(LRT) has been employed to find frequent features [78]. [79] built iterative learning between aspects and opinion words.\nTopic modeling approaches based on LDA statistical mixture model have been studied extensively[82][83], however they have the problem of separating features from opinion words [82] [21].\nFeature extraction is still an open research area; model-based approaches[54], [55], [72] and statistical models[18], [21], [66] are competing. [84] studied feature-learning method completeness from different perspectives such as its ability to identify features or opinions words or phrases, ability to reveal intensifiers, ability to classify infrequent entities, and ability to classify sentence subjectively. They also studied the application of Conditional Random Fields (CRF) into mining consumer reviews [84].\nThe feature extraction is the most important part of sentiment analysis task. Without knowing the properties of software quality we can not granulate the overall software quality. For example, the features fast, load and speed may be mapped to software efficiency. The features work, job and function can be mapped to effectiveness property of software quality. Unlike many methods that use nouns as the baseline of feature extraction, in software quality the adjective can still refer to software feature. For example in the sentence \u201c this software is fast\u201d , the keyword fast my indicate the software speed feature (adjective).\nImplicit Feature Extraction:\nImplicit features can be detected at the global context level and cannot be detected from features because usually the feature is not found in the sentence. For example the review sentence \u201cBlocks suspicious and/or alternative sites from opening\u201d, implies that the functionality feature is positive. Many works takes the adjective or adverb and sometimes the verb as an implicit feature indicator[55] [85]. The manual mapping of implicit features is difficult. For example, \u201cThis IS a virus. Do not install it or any of its components\u201d; virus here means it is not removing threats or not functioning.\n[55] used seed sentiment word to extract infrequent features to the opinion word as an indicator of implicit feature. [73] applied co-occurrence words between implicit and explicit features using frequency, PMI variants. [79] extracted implicit features by exploiting a function between opinion words and features. The current state-of-the-art sequential learning methods are Hidden Markov models HMM [86] [66], and Conditional Random Fields (CRF) [87][88]. [89] used onceClass SVM which trains for aspects without any training for non-aspects. [90] proposed a supervised learning approach to extract implicit and explicit aspects.\nTopic modeling is unsupervised learning that assumes each document consists of a mixture of topics and each topic is a probability distribution over words. [91] proposed an aspect topic model based on the\nPLSA.[92] mapped implicit aspect expression (sentiment words) to explicit aspects using explicit mutual reinforcement relationship between explicit aspect and sentiment words.[93] used two phase cooccurrence association rule (explicit aspects and sentiment words)."}, {"heading": "Feature Grouping", "text": "The objective is to group features that have the same meaning together. Aspect expressions need to be grouped into synonyms aspect categories to represent unique aspects. For example short words such AV may represent an antivirus. Liu found that some aspects may be referred in many forms; \u201ccall quality\u201c and \u201cvoice quality\u201d. Many synonyms are domain dependent [71]; movie and picture are synonyms in movie reviews but they are not synonyms in camera reviews. The picture synonyms refer to picture and movie refers to video.\nThere are three major approaches for grouping: using semi-supervised learning seeds of features and their groups with matching rules [78], [94]\u2013[96], topic models [97], [98] and distributional/relatedness or similarity measures [71], [99]. [94], [95] used semisupervised learning method to group aspect expression into some user specified aspect categories using Expectation Maximization algorithm. Zhai et al. [24] used a semi supervised soft-constrained algorithm based on Expectation Maximization(EM) algorithm [100] , called soft-constrained EM (SC-EM) . [96] extracted domain-independent features from reviews and classify them. The [97] algorithm known as DFLDA, add domain knowledge to topic modeling by incorporating can-link and cannot-link between feature words. Multilevel latent categorization by [98] performs latent semantic analysis to group aspects at two levels.\n[99] defined several similarity metrics and distances measures using WordNet. It mapped learned features into a user-defined taxonomy of the entity\u2019s features using these measures. The same approach has been used in [71] but both Liu work and Carenini are domain dependent.[78] used the LSA and Likelihood Ratio Test(LRT) as an association between features and opinion candidates in order to find real features and opinions. [73] grouped explicit synonyms to a predefined most important features identified by user using HOWNET nearby synonyms.\nIt is clear that the candidate features in one software category is different the candidate features in another category. For example, in antivirus category we can get features like scan, detect, clean. In internet downloaders category we can get features like speed, kbs, download. A good grouping approach has to consider the domain specific features of each domain."}, {"heading": "Opinion Summarization", "text": "Opinion summarization aims to extract opinions from the text and present them in short form. For document based classification the summary is intuitive where we will get percentage of positive opinions versus negative opinions. For sentence based classification it is crucial to show users representative sentence for both positive and negative opinions. The most important summary is the summarization of user opinions on specific features. In other words, the Opinion quintuple aspect summary to capture the essence of opinion targets (entities and aspects). It can be used to show percentage of people in different groups based on interest.\nThere are three major different models to perform summarization of reviews ;1) sentiment match: extract sentences so that the average sentiment of the summary is close to average sentence review of an entity [101], 2) sentiment match plus aspect coverage(SMAC); a tradeoff aspect coverage/sentence entity [102], 3) sentiment aspect match(SAM); cover important aspect with appropriate sentiment [80], [103].[104] proposed an aspect-based opinion summarization (or structured summary) to detect Low-quality product review in opinion summarization. [105] used existing online ontology to organize opinions. [106] presented an aspect summary layout with a rating for each aspect. It identifies k interesting aspects and cluster head terms into those aspects.\nWhat we want to summarize for a software? Why? In software reviews we might be looking for trends in software use over time, software quality, the effect of software enhancement on user usage, the top k features that are important to users, the most competitive software to a particular software, etc. These needs could be presented in a graph based approach for users, or managers. If a user gets a graph based view of particular aspects of software then he can take a decision in a glance. Software vendor\u2019s management teams can know the performance of their product and a marketing strategy or business plans might get updated.\nV. OPEN RESEARCH ISSUES\nThere are many open research issues in opinion mining as applied on software reviews. We have identified the importance of the below issues:\nInadequate sentiment analysis models: currently the most famous model of opinion mining is the general model that represents the entity, aspect, opinion, opinion holder, and time. Although this model is general and can be used in many domains there might be a researcher need to model the opinion problem for specific domains or review formats. For example, it is generally correct that the pros and cons of software review documents contain positive and negative\nsentiments on topics discussed by the opinion holder. Knowing this fact and cross jointing them with the summary component we might find a better way to reduce duplication or summarization. For example, if one aspect is being repeated in the summary component and in the cons, it indicates that the holder is not happy about that aspect. The idea here is to utilize the lengthy summary in order to find implicit or explicit aspects or entities that might be difficult to find from the short cons or pros components of a review.\nIn our context of software reviews, a possible direction that also has not been studied before is the linkage between the editor review and the opinion holder review. The editorial review is usually lengthy and can contain many features of the software that it can do, so, why not looking for a way to incorporate this knowledge in opinion mining process in order to find real features.\nAnnotation schemes limitations: Annotation is a bottleneck for sentiment analysis (practically software reviews). Many works have verified their models using their own scheme and makes verifying such models reasonably persuasive. Many available annotations do not show details of opinion expressions [55], [74], [107].\nRecently [108] proposed a scheme to annotate a corpus of customer reviews by helping annotators using a tool. As a result the annotation contains opinion expression, opinion target, a holder, modifier and anaphoric expression. So results are fine-grain opinion properties that can enhance opinion target extraction and polarity assignment. The previous work showed the importance of an annotation scheme. Furthermore, there is still an immense need for a huge datasets that can be used publically for opinion mining testing similar to the projects of Question Answering challenges (TREC) and text entailments (RTE) projects. Without such type of datasets we believe the many opinion mining techniques will remain questionable unless it is verified by a publically available dataset.\nIssues software reviews data: To our knowledge there is no publicly data set that can be used for opinion mining on software reviews[14]. For software that is being developed by a single developer or a small group of users, best practices of software engineering are not usually followed or are ad hoc. Teams are homogenous from the globe and rarely meet face to face. This implies that the software project health status can change dramatically from time to time. As a result at a particular time of software development (or version), the software can get high user satisfaction (many reviews) but at another time it may not get any feedback. A solution of this problem triggers the need of a good opinion mining system that might need to\nconsider the demographics of certain software or to place needed assumptions before mining.\nTight deadlines can force developers to balance quality to time and scope. As a result, the number of users\u2019 feedbacks may get down. At this time, users usually start guiding each other to other possible competitive software alternatives.\nThe software project artefacts are diverse, ranging from the mailing list, forums, source code, change histories, bug reports, etc. So , each of them has an effect of software which means an opinion mining approach might need to consider more than one artefact to get the needed information.\nNoise elimination: studying reviews, many sentences have grammatical errors and spelling errors. Resolving these errors can enhance dependency parsers. It can enhance aspect extraction because sometimes aspects are spelled in different ways. Also resolving short text (acronyms) such as the word gr8 to represent the great keyword can enhance opinion orientation. Thus a database of such terms might be helpful. Current spell checkers may need further enhancement to support situations where words are very short or even written in different language. One possible way is to employ a language detector while parsing reviews text to know what the possible written text (by software user).\nAnother research might be important is the issue of computer generated reviews. Can an opinion mining system detect such type of reviews to eliminate the bias or noise?\nSentence classification: while a lot has been done in subjectivity classification, there is a need to filter objective sentences that do not have an opinion whether it is explicit or implied. In fact, this challenge is linked to other challenges such as sarcasm detection, automatic entity recognition.\nFurthermore, we found more than 40% of a sampled dataset is comparative sentences. Which means users often compare software products to others of the same family. For example, \u201cFirefox is faster than Internet Explorer.\u201d or \u201c the previous version is more tidy\u201d. Therefore, the required features and opinion expressions should be extracted from the challenging comparative sentences. In other words, at this point in time of software development the numbers of comparative sentences are very high compared to normal sentences. Given the fact that not all comparative sentences have an opinion special care might be needed to pre-process such reviews during this period. One way might be to link software batch release on the forums or software web sites with such type of reviews.\nReference resolution: Reference resolution is important to detect multiple expression /sentences/document referring to the same thing (same\nreferent) that will finally affect the sentiment. For example the sentence \u201cI bought an IPhone two days ago. It looks very nice. I made many calls\u201d. Detecting the reference of the article it is important or otherwise opinion mining model will lose recall (loose aspect opinions. Although there are many researches on reference resolution[109] finding an automatic way to resolve reference and disambiguate word senses is still challenging. It could be helpful for research if taggers can do this job automatically.\nWord sense disambiguation: Word sense disambiguation[110] is essential for software reviews due the fact that some words are context specific. Sometimes users might review software using asterisks, symbols, or numbers to point out their fulfilment of QinU. In other cases, words might be context specific, thus disambiguation might be required to build good opinion mining systems. For example, in the sentence \u201cI will have to give it time for all of the other details\u201d, \u2018time\u2019 here represents time spent by users rather than time spent by the software to do a task (efficiency). Furthermore, sometimes sentences are connected with a user story that moves from one topic to another.\nVI. CONCLUSIONS\nThe sentiment analysis tasks and related techniques were studied. We have studied the application of the sentiment analysis on software reviews. We found that there are many issues with sentiment analysis. However the sentiment analysis is promising in detecting software quality. We identified a list of major open issues in sentiment analysis applied on software quality. We conclude that the issues of software quality mining from software reviews are due to the dynamic diverse software lifecycle and the limited software quality datasets."}], "references": [{"title": "Estimating the Helpfulness and Economic Impact of Product Reviews: Mining Text and Reviewer Characteristics", "author": ["A. Ghose", "P.G. Ipeirotis"], "venue": "IEEE Trans. Knowl. Data Eng., vol. 23, no. 10, pp. 1498\u20131512, 2011.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "A Survey of Opinion Mining and Sentiment Analysis", "author": ["B. Liu", "L. Zhang"], "venue": "Mining Text Data, C. Aggarwal, Charu C. and Zhai, Ed. Springer US, 2012, pp. 415\u2013463.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Opinion mining and sentiment analysis", "author": ["B. Pang", "L. Lee"], "venue": "Found. trends Inf. Retr., vol. 2, no. 1\u20132, pp. 1\u2013135, 2008.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Sentiment Analysis and Opinion Mining", "author": ["B. Liu"], "venue": "Synth. Lect. Hum. Lang. Technol., vol. 5, no. 1, pp. 1\u2013167, May 2012.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "What does product quality really mean", "author": ["D.A. Garvin"], "venue": "Sloan Manage. Rev., vol. 26, no. 1, pp. 25\u201343, 1984.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1984}, {"title": "A Framework to Predict Software \u2018Quality in Use\u2019 from Software Reviews", "author": ["I. Atoum", "C.H. Bong"], "venue": "Proceedings of the First International Conference on Advanced Data and Information Engineering (DaEng-2013), vol. 285, J. Herawan, Tutut and Deris, Mustafa Mat and Abawajy, Ed. Kuala Lumpur: Springer Singapore, 2014, pp. 429\u2013436.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Evaluating  software quality in use using user reviews mining", "author": ["W. Leopairote", "A. Surarerks", "N. Prompoon"], "venue": "10th International Joint Conference on Computer Science and Software Engineering (JCSSE), 2013, pp. 257\u2013262.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Movie Review Classification and Feature based Summarization of Movie Reviews", "author": ["S.M. Basheer", "S. Farook"], "venue": "Int. J. Comput. Trends Technol., vol. 4, 2013.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "Mining trends of library usage", "author": ["Y.M. Mileva", "V. Dallmeier", "M. Burger", "A. Zeller"], "venue": "Proc. Jt. Int. Annu. ERCIM Work. Princ. Softw. Evol. Softw. Evol. Work. - IWPSE-Evol \u201909, p. 57, 2009.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "Sentiment analysis and subjectivity", "author": ["B. Liu"], "venue": "Handb. Nat. Lang. Process., vol. 2, p. 568, 2010.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2010}, {"title": "ISO/IEC 25010: 2011, Systems and software engineering--Systems and software Quality Requirements and Evaluation (SQuaRE)--System and software quality models", "author": ["ISO/IEC"], "venue": "International Organization for Standardization, Geneva, Switzerland, 2011.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "A model of quality-in-use for servicebased mobile ecosystem", "author": ["H.J. La", "S.D. Kim"], "venue": "2013 1st International Workshop on the Engineering of Mobile-Enabled Systems (MOBS), 2013, pp. 13\u201318.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Measuring Software Quality in Use: State-of-the-Art and Research Challenges", "author": ["I. Atoum", "C.H. Bong"], "venue": "ASQ.Software Qual. Prof., vol. 17, no. 2, pp. 4\u201315, 2015.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Building a Pilot Software Quality-in-Use Benchmark Dataset", "author": ["I. Atoum", "C.H. Bong", "N. Kulathuramaiyer"], "venue": "9th International Conference on IT in Asia, 2015.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Towards Resolving Software Quality-in-Use Measurement Challenges", "author": ["I. Atoum", "C.H. Bong", "N. Kulathuramaiyer"], "venue": "J. Emerg. Trends Comput. Inf. Sci., vol. 5, no. 11, pp. 877\u2013885, 2014.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "Software quality in use characteristic mining from customer reviews", "author": ["W. Leopairote", "A. Surarerks", "N. Prompoon"], "venue": "2012 Second International Conference on Digital Information and Communication Technology and it\u2019s Applications (DICTAP), 2012, pp. 434\u2013439.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "Probabilistic topic models", "author": ["D.M. Blei"], "venue": "Commun. ACM, vol. 55, no. 4, pp. 77\u201384, Apr. 2012.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "Modeling online reviews with multi-grain topic models", "author": ["I. Titov", "R. McDonald"], "venue": "Proceedings of the 17th international conference on World Wide Web, 2008, pp. 111\u2013 120.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2008}, {"title": "Data mining: concepts, models, methods, and algorithms", "author": ["M. Kantardzic"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "A Novel Method for Early Software Quality Prediction Based on Support Vector Machine", "author": ["X. Fei", "G. Ping", "M.R. Lyu"], "venue": "16th IEEE Int. Symp. Softw. Reliab. Eng., no. Issre, pp. 213\u2013222, 2005.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2005}, {"title": "Feature selection for sentiment analysis based on content and syntax models", "author": ["A. Duric", "F. Song"], "venue": "Decis. Support Syst., vol. 53, no. 4, pp. 704\u2013711, Nov. 2012.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2012}, {"title": "Text Classification from Labeled and Unlabeled Documents using EM", "author": ["K. Nigam", "A.K. Mccallum", "S. Thrun", "T. Mitchell"], "venue": "Mach. Learn., vol. 39, no. 2, pp. 103\u2013134, 2000.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2000}, {"title": "Mining the Sentiment expectation of nouns using Bootstrapping method", "author": ["M. Wen", "Y. Wu"], "venue": "Proceedings of the 5th international Joint conference on natural Language Processing (iJcnLP-2010), 2011, pp. 1423\u20131427.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}, {"title": "Product Feature Grouping for Opinion Mining", "author": ["Z. Zhai", "B. Liu", "J. Wang", "H. Xu", "P. Jia"], "venue": "Intell. Syst. IEEE, vol. 27, no. 4, pp. 37\u201344, 2012.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2012}, {"title": "Using Latent Semantic Analysis to Identify Quality in Use ( QU ) Indicators from User Reviews", "author": ["S.T.W. Wendy", "B.C. How", "I. Atoum"], "venue": "The International Conference on Artificial Intelligence and Pattern Recognition (AIPR2014), 2014, pp. 143\u2013151.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2014}, {"title": "Indexing by latent semantic analysis", "author": ["S. Deerwester", "S. Dumais"], "venue": "J. Am. Soc. Inf. Sci., vol. 41, no. 6, pp. 391\u2013407, Sep. 1990.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1990}, {"title": "An introduction to latent semantic analysis", "author": ["T.K. Landauer", "P.W. Foltz", "D. Laham"], "venue": "Discourse Process., vol. 25, no. 2\u20133, pp. 259\u2013284, 1998.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1998}, {"title": "Probabilistic latent semantic indexing", "author": ["T. Hofmann"], "venue": "Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, 1999, pp. 50\u201357.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1999}, {"title": "Determining the sentiment of opinions", "author": ["S.-M. Kim", "E. Hovy"], "venue": "Proceedings of the 20th international conference on Computational Linguistics, 2004.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2004}, {"title": "Extracting aspectevaluation and aspect-of relations in opinion mining", "author": ["N. Kobayashi", "K. Inui", "Y. Matsumoto"], "venue": "Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), 2007, pp. 1065\u20131074.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2007}, {"title": "A sentimental education: sentiment analysis using subjectivity summarization based on minimum cuts", "author": ["B. Pang", "L. Lee"], "venue": "Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, 2004.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2004}, {"title": "Development and use of a gold-standard data set for subjectivity classifications", "author": ["J.M. Wiebe", "R.F. Bruce", "T.P. O\u2019Hara"], "venue": "Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics, 1999, pp. 246\u2013253.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1999}, {"title": "Crystal: Analyzing predictive opinions on the web", "author": ["S.-M. Kim", "E. Hovy"], "venue": "Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), 2007, pp. 1056\u20131064.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2007}, {"title": "Towards context-based subjectivity analysis", "author": ["F. Benamara", "V. Popescu", "B. Chardon", "Y. Mathieu", "Others"], "venue": "Proceedings of 5th International Joint Conference on Natural Language Processing, 2011, pp. 1180\u20131188.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2011}, {"title": "Robust sentiment detection on Twitter from biased and noisy data", "author": ["L. Barbosa", "J. Feng"], "venue": "Proceedings of the 23rd International Conference on Computational Linguistics: Posters, 2010, pp. 36\u201344.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2010}, {"title": "Learning subjective adjectives from corpora", "author": ["J.M. Wiebe"], "venue": "Proceedings of the National Conference on Artificial Intelligence, 2000, pp. 735\u2013741.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2000}, {"title": "Predicting the semantic orientation of adjectives", "author": ["V. Hatzivassiloglou", "K.R. McKeown"], "venue": "Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and Eighth Conference of the European Chapter of the Association for Computational Linguistics, 1997, pp. 174\u2013 181.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 1997}, {"title": "Learning extraction patterns for subjective expressions", "author": ["E. Riloff", "J. Wiebe"], "venue": "Proceedings of the 2003 conference on Empirical methods in natural language processing, 2003, pp. 105\u2013112.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2003}, {"title": "Opinion extraction and summarization on the web", "author": ["M. Hu", "B. Liu"], "venue": "Proceedings Of The National Conference On Artificial Intelligence, 2006, vol. 21, no. 2, p. 1621.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2006}, {"title": "Building a sentiment summarizer for local service reviews", "author": ["S. Blair-Goldensohn", "K. Hannan", "R. McDonald", "T. Neylon", "G.A. Reis", "J. Reynar"], "venue": "WWW Workshop on NLP in the Information Explosion Era, 2008.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2008}, {"title": "Measuring praise and criticism: Inference of semantic orientation from association", "author": ["P.D. Turney", "M.L. Littman"], "venue": "ACM Trans. Inf. Syst., vol. 21, no. 4, pp. 315\u2013346, Oct. 2003.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2003}, {"title": "Using wordnet to measure semantic orientation of adjectives", "author": ["J. Kamps", "M. Marx", "R.J. Mokken", "M. de Rijke"], "venue": "Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC 2004), 2004, vol. IV, pp. 1115\u20131118.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2004}, {"title": "The viability of web-derived polarity lexicons", "author": ["L. Velikovich", "S. Blair-Goldensohn", "K. Hannan", "R. McDonald"], "venue": "Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, 2010, pp. 777\u2013785.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2010}, {"title": "Fully automatic lexicon expansion for domain-oriented sentiment analysis", "author": ["H. Kanayama", "T. Nasukawa"], "venue": "Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, 2006, pp. 355\u2013363.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2006}, {"title": "A holistic lexicon-based approach to opinion mining", "author": ["X. Ding", "B. Liu", "P.S. Yu"], "venue": "Proceedings of the international conference on Web search and web data mining, 2008, pp. 231\u2013240.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2008}, {"title": "Identifying noun product features that imply opinions", "author": ["L. Zhang", "B. Liu"], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers, 2011, vol. 2, pp. 575\u2013 580.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2011}, {"title": "Adapting information bottleneck method for automatic construction of domainoriented sentiment lexicon", "author": ["W. Du", "S. Tan", "X. Cheng", "X. Yun"], "venue": "Proceedings of the third ACM international conference on Web search and data mining, 2010, pp. 111\u2013120.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2010}, {"title": "Expanding domain sentiment lexicon through double propagation", "author": ["G. Qiu", "B. Liu", "J. Bu", "C. Chen"], "venue": "Proceedings of the 21st international jont conference on Artifical intelligence, 2009, pp. 1199\u20131204.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2009}, {"title": "Opinion word expansion and target extraction through double propagation", "author": ["G. Qiu", "B. Liu", "J. Bu", "C. Chen"], "venue": "Comput. Linguist., vol. 37, no. 1, pp. 9\u201327, 2011.", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning general connotation of words using graph-based algorithms", "author": ["S. Feng", "R. Bose", "Y. Choi"], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2011, pp. 1092\u20131103.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2011}, {"title": "About WordNet", "author": ["P. University"], "venue": "Princeton University, 2010. [Online]. Available: http://wordnet.princeton.edu.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2010}, {"title": "Review sentiment scoring via a parseand-paraphrase paradigm", "author": ["J. Liu", "S. Seneff"], "venue": "Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1 - Volume 1, 2009, pp. 161\u2013169.", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2009}, {"title": "The Bag-of-opinions Method for Review Rating Prediction from Sparse Text Patterns", "author": ["L. Qu", "G. Ifrim", "G. Weikum"], "venue": "Proceedings of the 23rd International Conference on Computational Linguistics, 2010, pp. 913\u2013921.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2010}, {"title": "Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews", "author": ["P.D.P. Turney"], "venue": "Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, 2002, no. July, pp. 417\u2013424.", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2002}, {"title": "Mining and summarizing customer reviews", "author": ["M. Hu", "B. Liu"], "venue": "Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, 2004, pp. 168\u2013177.", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2004}, {"title": "Sentiment Classification Based on Ontology and SVM Classifier", "author": ["K.P.P. Shein", "T.T.S. Nyunt"], "venue": "Second International Conference on Communication Software and Networks, 2010, pp. 169\u2013172.", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2010}, {"title": "Towards answering opinion questions: separating facts from opinions and identifying the polarity of opinion sentences", "author": ["H. Yu", "V. Hatzivassiloglou"], "venue": "Proceedings of the 2003 conference on Empirical methods in natural language processing, 2003, pp. 129\u2013136.", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2003}, {"title": "Pulse: Mining Customer Opinions from Free Text", "author": ["M. Gamon", "A. Aue"], "venue": "Advances in Intelligent Data Analysis VI, vol. 3646, A. Famili, A.Fazel and Kok, JoostN. and Pe\u00f1a, Jos\u00e9M. and Siebes, Arno and Feelders, Ed. Springer Berlin Heidelberg, 2005, pp. 121\u2013132.", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2005}, {"title": "Sentiment analysis of conditional sentences", "author": ["R. Narayanan", "B. Liu", "A. Choudhary"], "venue": "Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1 - Volume 1, 2009, pp. 180\u2013189.", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2009}, {"title": "Movie review mining and summarization", "author": ["L. Zhuang", "F. Jing", "X.-Y. Zhu"], "venue": "Proceedings of the 15th ACM international conference on Information and knowledge management, 2006, pp. 43\u201350.", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2006}, {"title": "Targetdependent twitter sentiment classification", "author": ["L. Jiang", "M. Yu", "M. Zhou", "X. Liu", "T. Zhao"], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, 2011, vol. 1, pp. 151\u2013160.", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2011}, {"title": "Sentiment learning on product reviews via sentiment ontology tree", "author": ["W. Wei", "J.A. Gulla"], "venue": "Proceedings of the  48th Annual Meeting of the Association for Computational Linguistics, 2010, pp. 404\u2013413.", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2010}, {"title": "Sentiment composition", "author": ["K. Moilanen", "S. Pulman"], "venue": "Proceedings of the Recent Advances in Natural Language Processing International Conference, 2007, pp. 378\u2013382.", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2007}, {"title": "Contextual Valence Shifters", "author": ["L. Polanyi", "A. Zaenen"], "venue": "Computing Attitude and Affect in Text: Theory and Applications, J. Shanahan, JamesG. and Qu, Yan and Wiebe, Ed. Springer Netherlands, 2006, pp. 1\u201310.", "citeRegEx": "64", "shortCiteRegEx": null, "year": 2006}, {"title": "Identifying comparative sentences in text documents", "author": ["N. Jindal", "B. Liu"], "venue": "Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, 2006, pp. 244\u2013251.", "citeRegEx": "65", "shortCiteRegEx": null, "year": 2006}, {"title": "A novel lexicalized HMM-based learning framework for web opinion mining", "author": ["W. Jin", "H.H. Ho"], "venue": "Proceedings of the 26th Annual International Conference on Machine Learning, 2009, pp. 465\u2013472.", "citeRegEx": "66", "shortCiteRegEx": null, "year": 2009}, {"title": "aspect extraction through Semi- Supervised modeling", "author": ["A. Mukherjee", "B. Liu"], "venue": "Proceedings of 50th anunal meeting of association for computational Linguistics (ACL-2012), 2012, no. July, pp. 339\u2013348.", "citeRegEx": "67", "shortCiteRegEx": null, "year": 2012}, {"title": "Thumbs up?: sentiment classification using machine learning techniques", "author": ["B. Pang", "L. Lee", "S. Vaithyanathan"], "venue": "Proceedings of the ACL-02 conference on Empirical methods in natural language processing - Volume 10, 2002, no. July, pp. 79\u201386.", "citeRegEx": "68", "shortCiteRegEx": null, "year": 2002}, {"title": "Just how mad are you? Finding strong and weak opinion clauses", "author": ["T. Wilson", "J. Wiebe", "R. Hwa"], "venue": "Proceedings of the National Conference on Artificial Intelligence, 2004, pp. 761\u2013769.", "citeRegEx": "69", "shortCiteRegEx": null, "year": 2004}, {"title": "Opinion feature extraction using class sequential rules", "author": ["M. Hu", "B. Liu"], "venue": "Proceedings of the Spring Symposia on Computational Approaches to Analyzing Weblogs, 2006, no. 3.", "citeRegEx": "70", "shortCiteRegEx": null, "year": 2006}, {"title": "Opinion observer: analyzing and comparing opinions on the Web", "author": ["B. Liu", "M. Hu", "J. Cheng"], "venue": "Proceedings of the 14th international conference on World Wide Web, 2005, pp. 342\u2013 351.", "citeRegEx": "71", "shortCiteRegEx": null, "year": 2005}, {"title": "OPINE: extracting product features and opinions from reviews", "author": ["A.-M. Popescu", "B. Nguyen", "O. Etzioni"], "venue": "Proceedings of HLT/EMNLP on Interactive Demonstrations, 2005, pp. 32\u201333.", "citeRegEx": "72", "shortCiteRegEx": null, "year": 2005}, {"title": "Weakness Finder: Find product weakness from Chinese reviews by using aspects based sentiment analysis", "author": ["W. Zhang", "H. Xu", "W. Wan"], "venue": "Expert Syst. Appl., vol. 39, no. 11, pp. 10283\u201310291, Sep. 2012.", "citeRegEx": "73", "shortCiteRegEx": null, "year": 2012}, {"title": "Sentiment analyzer: extracting sentiments about a given topic using natural language processing techniques", "author": ["J. Yi", "T. Nasukawa", "R. Bunescu", "W. Niblack"], "venue": "Third IEEE International Conference on Data Mining ICDM 2003., 2003, pp. 427\u2013434.", "citeRegEx": "74", "shortCiteRegEx": null, "year": 2003}, {"title": "Opinion Target Extraction for Short Comments", "author": ["L. Shang", "H. Wang", "X. Dai", "M. Zhang"], "venue": "PRICAI 2012 Trends Artif. Intell., vol. 7458, pp. 434\u2013439, 2012.", "citeRegEx": "75", "shortCiteRegEx": null, "year": 2012}, {"title": "A Domain Independent Framework to Extract and Aggregate Analogous Features in Online Reviews", "author": ["A. Bhattarai", "N. Niraula", "V. Rus", "K. Lin"], "venue": "Computational Linguistics and Intelligent Text Processing, vol. 7181, A. Gelbukh, Ed. Springer Berlin Heidelberg, 2012, pp. 568\u2013579.", "citeRegEx": "76", "shortCiteRegEx": null, "year": 2012}, {"title": "Extracting and ranking product features in opinion documents", "author": ["L. Zhang", "B. Liu", "S.H.S.H. Lim", "E. O\u2019Brien-Strain"], "venue": "Proceedings of the 23rd International Conference on Computational Linguistics: Posters, 2010, no. August, pp. 1462\u20131470.", "citeRegEx": "77", "shortCiteRegEx": null, "year": 2010}, {"title": "One seed to find them all: mining opinion features via association", "author": ["Z. Hai", "K. Chang", "G. Cong"], "venue": "Proceedings of the 21st ACM international conference on Information and knowledge management, 2012, pp. 255\u2013264.", "citeRegEx": "78", "shortCiteRegEx": null, "year": 2012}, {"title": "Bootstrapping both product features and opinion words from chinese customer reviews with crossinducing", "author": ["B. Wang", "H. Wang"], "venue": "Proceedings of The Third International Joint Conference on Natural Language Processing (IJCNLP), 2008.", "citeRegEx": "79", "shortCiteRegEx": null, "year": 2008}, {"title": "Opinion extraction,  summarization and tracking in news and blog corpora", "author": ["L. Ku", "Y. Liang", "H. Chen"], "venue": "Proceedings of AAAI-2006 Spring Symposium on Computational Approaches to Analyzing Weblogs, 2006, pp. 100\u2013107.", "citeRegEx": "80", "shortCiteRegEx": null, "year": 2006}, {"title": "A joint model of text and aspect ratings for sentiment summarization", "author": ["I. Titov", "R. McDonald"], "venue": "Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics, 2008, pp. 308\u2013316.", "citeRegEx": "82", "shortCiteRegEx": null, "year": 2008}, {"title": "Supervised topic models", "author": ["D.M. Blei", "J.D. McAuliffe"], "venue": "Advances in Neural Information Processing Systems 20 (NIPS 2007), 2007, pp. 121\u2013128.", "citeRegEx": "83", "shortCiteRegEx": null, "year": 2007}, {"title": "Comparison of feature-level learning methods for mining online consumer reviews", "author": ["L. Chen", "L. Qi", "F. Wang"], "venue": "Expert Syst. Appl., vol. 39, no. 10, pp. 9588\u20139601, Aug. 2012.", "citeRegEx": "84", "shortCiteRegEx": null, "year": 2012}, {"title": "Hidden sentiment association in chinese web opinion mining", "author": ["Q. Su", "X. Xu", "GuoHonglei", "Z. Guo", "X. Wu", "Z. Xiaoxun", "B. Swen", "Z. Su"], "venue": "Proceedings of the 17th international conference on World Wide Web, 2008, pp. 959\u2013968.", "citeRegEx": "85", "shortCiteRegEx": null, "year": 2008}, {"title": "A tutorial on hidden Markov models and selected applications in speech recognition", "author": ["L. Rabiner"], "venue": "Proc. IEEE, vol. 77, no. 2, pp. 257\u2013286, 1989.", "citeRegEx": "86", "shortCiteRegEx": null, "year": 1989}, {"title": "Extracting Opinion Targets in a Single- and Cross-domain Setting with Conditional Random Fields", "author": ["N. Jakob", "I. Gurevych"], "venue": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, 2010, pp. 1035\u2013 1045.", "citeRegEx": "87", "shortCiteRegEx": null, "year": 2010}, {"title": "Conditional Random Fields : Probabilistic Models for Segmenting and Labeling Sequence Data", "author": ["J. Lafferty", "A. Mccallum", "F.C.N. Pereira"], "venue": "Proceedings of ICML\u201901, 2001, vol. 2001, no. Icml, pp. 282\u2013289.", "citeRegEx": "88", "shortCiteRegEx": null, "year": 2001}, {"title": "Domain-assisted product aspect hierarchy generation: towards hierarchical organization of unstructured consumer reviews", "author": ["J. Yu", "Z.-J. Zha", "M. Wang", "K. Wang", "T.-S. Chua"], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2011, pp. 140\u2013150.", "citeRegEx": "89", "shortCiteRegEx": null, "year": 2011}, {"title": "Sentiment Analysis with Multisource Product Reviews", "author": ["H. Jin", "M. Huang", "X. Zhu"], "venue": "Intell. Comput. Technol., pp. 301\u2013 308, 2012.", "citeRegEx": "90", "shortCiteRegEx": null, "year": 2012}, {"title": "Topic sentiment mixture: modeling facets and opinions in weblogs", "author": ["Q. Mei", "X. Ling", "M. Wondra", "H. Su", "C. Zhai"], "venue": "Proceedings of the 16th international conference on World Wide Web, 2007, pp. 171\u2013180.", "citeRegEx": "91", "shortCiteRegEx": null, "year": 2007}, {"title": "From words to senses: a case study of subjectivity recognition", "author": ["F. Su", "K. Markert"], "venue": "Proceedings of the 22nd International Conference on Computational Linguistics - Volume 1, 2008, pp. 825\u2013832.", "citeRegEx": "92", "shortCiteRegEx": null, "year": 2008}, {"title": "Implicit Feature Identification via Co-occurrence Association Rule Mining", "author": ["J. Hai", "Zhen", "Chang", "Kuiyu", "Kim"], "venue": "Computational Linguistics and Intelligent Text Processing, A. Gelbukh, Ed. Springer Berlin Heidelberg, 2011, pp. 393\u2013404.", "citeRegEx": "93", "shortCiteRegEx": null, "year": 2011}, {"title": "Constrained LDA for Grouping Product Features in Opinion Mining", "author": ["Z. Zhai", "B. Liu", "H. Xu", "P. Jia"], "venue": "Advances in Knowledge Discovery and Data Mining, vol. 6634, J. Huang, L. Cao, and J. Srivastava, Eds. Springer Berlin Heidelberg, 2011, pp. 448\u2013459.", "citeRegEx": "94", "shortCiteRegEx": null, "year": 2011}, {"title": "Grouping product features using semi-supervised learning with soft-constraints", "author": ["Z. Zhai", "B. Liu", "H. Xu", "P. Jia"], "venue": "Proceedings of the 23rd International Conference on Computational Linguistics, 2010, pp. 1272\u20131280.", "citeRegEx": "95", "shortCiteRegEx": null, "year": 2010}, {"title": "Feature Specific Sentiment Analysis for Product Reviews", "author": ["S. Mukherjee", "P. Bhattacharyya"], "venue": "Computational Linguistics and Intelligent Text Processing, vol. 7181, A. Gelbukh, Ed. Springer Berlin / Heidelberg, 2012, pp. 475\u2013487.", "citeRegEx": "96", "shortCiteRegEx": null, "year": 2012}, {"title": "Incorporating domain knowledge into topic modeling via Dirichlet Forest priors", "author": ["D. Andrzejewski", "X. Zhu", "M. Craven"], "venue": "Proceedings of the 26th Annual International Conference on Machine Learning, 2009, vol. 382, no. 26, pp. 25\u201332.", "citeRegEx": "97", "shortCiteRegEx": null, "year": 2009}, {"title": "Product feature categorization with multilevel latent semantic association", "author": ["H. Guo", "H. Zhu", "Z. Guo", "X. Zhang", "Z. Su"], "venue": "Proceedings of the 18th ACM conference on Information and knowledge management, 2009, pp. 1087\u20131096.", "citeRegEx": "98", "shortCiteRegEx": null, "year": 2009}, {"title": "Extracting knowledge from evaluative text", "author": ["G. Carenini", "R.T. Ng", "E. Zwart"], "venue": "Proceedings of the 3rd international conference on Knowledge capture, 2005, pp. 11\u201318.", "citeRegEx": "99", "shortCiteRegEx": null, "year": 2005}, {"title": "Maximum likelihood from incomplete data via the EM algorithm", "author": ["A. Dempster", "N. Laird", "D. Rubin"], "venue": "J. R. Stat. Soc. Ser. B, pp. 1\u201338, 1977.", "citeRegEx": "100", "shortCiteRegEx": null, "year": 1977}, {"title": "Multi-document summarization of evaluative text", "author": ["R. Ng", "A. Pauls"], "venue": "In Proceedings of the 11st Conference of the European Chapter of the Association for Computational Linguistics, 2006.", "citeRegEx": "101", "shortCiteRegEx": null, "year": 2006}, {"title": "Generating fine-grained reviews of songs from album reviews", "author": ["S. Tata", "B. Di Eugenio"], "venue": "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, 2010, pp. 1376\u20131385.", "citeRegEx": "102", "shortCiteRegEx": null, "year": 2010}, {"title": "Sentiment summarization: evaluating and learning user preferences", "author": ["K. Lerman", "S. Blair-Goldensohn", "R. McDonald"], "venue": "Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, 2009, pp. 514\u2013522.", "citeRegEx": "103", "shortCiteRegEx": null, "year": 2009}, {"title": "Lowquality product review detection in opinion summarization", "author": ["J. Liu", "Y. Cao", "C.-Y. Lin", "Y. Huang", "M. Zhou"], "venue": "Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), 2007, pp. 334\u2013342.", "citeRegEx": "104", "shortCiteRegEx": null, "year": 2007}, {"title": "Exploiting structured ontology to organize scattered online opinions", "author": ["Y. Lu", "H. Duan", "H. Wang", "C. Zhai"], "venue": "Proceedings of the 23rd International Conference on Computational Linguistics, 2010, pp. 734\u2013742.", "citeRegEx": "105", "shortCiteRegEx": null, "year": 2010}, {"title": "Rated aspect summarization of short comments", "author": ["Y. Lu", "C. Zhai", "N. Sundaresan"], "venue": "Proceedings of the 18th international conference on World wide web, 2009, pp. 131\u2013 140.", "citeRegEx": "106", "shortCiteRegEx": null, "year": 2009}, {"title": "Annotating Expressions of Opinions and Emotions in Language", "author": ["J. Wiebe", "T. Wilson", "C. Cardie"], "venue": "Lang. Resour. Eval., vol. 39, no. 2\u20133, pp. 165\u2013210, 2005.", "citeRegEx": "107", "shortCiteRegEx": null, "year": 2005}, {"title": "Sentence and expression level annotation of opinions in user-generated discourse", "author": ["C. Toprak", "N. Jakob", "I. Gurevych"], "venue": "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, 2010, pp. 575\u2013584.", "citeRegEx": "108", "shortCiteRegEx": null, "year": 2010}, {"title": "Resolving object and attribute coreference in opinion mining", "author": ["X. Ding", "B. Liu"], "venue": "Proceedings of the 23rd International Conference on Computational Linguistics, 2010, pp. 268\u2013276.", "citeRegEx": "109", "shortCiteRegEx": null, "year": 2010}, {"title": "Subjectivity word sense disambiguation", "author": ["C. Akkaya", "J. Wiebe", "R. Mihalcea"], "venue": "Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1, 2009, pp. 190\u2013199.", "citeRegEx": "110", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "Studies showed that online reviews have real economic values [1].", "startOffset": 61, "endOffset": 64}, {"referenceID": 2, "context": "Pang [3] stated that: although many authors use the term \u201csentiment analysis\u201d to refer to classifying reviews as positive or negative, nowadays it has been taken to mean the", "startOffset": 5, "endOffset": 8}, {"referenceID": 2, "context": "subjectivity in text [3].", "startOffset": 21, "endOffset": 24}, {"referenceID": 3, "context": "Liu [4] identified that the", "startOffset": 4, "endOffset": 7}, {"referenceID": 3, "context": "sentiment analysis and opinion mining are both used in the academia [4].", "startOffset": 68, "endOffset": 71}, {"referenceID": 4, "context": "Garvin [5] identified five views/approaches of quality.", "startOffset": 7, "endOffset": 10}, {"referenceID": 5, "context": "To our knowledge little research has been published in the domain of opinion mining over software reviews [6], [7][8], [9].", "startOffset": 106, "endOffset": 109}, {"referenceID": 6, "context": "To our knowledge little research has been published in the domain of opinion mining over software reviews [6], [7][8], [9].", "startOffset": 111, "endOffset": 114}, {"referenceID": 7, "context": "To our knowledge little research has been published in the domain of opinion mining over software reviews [6], [7][8], [9].", "startOffset": 114, "endOffset": 117}, {"referenceID": 8, "context": "To our knowledge little research has been published in the domain of opinion mining over software reviews [6], [7][8], [9].", "startOffset": 119, "endOffset": 122}, {"referenceID": 1, "context": "The most widely used surveys[2], [3], [10] are for products in general and none of them have studied the specialty of a specific review domain.", "startOffset": 28, "endOffset": 31}, {"referenceID": 2, "context": "The most widely used surveys[2], [3], [10] are for products in general and none of them have studied the specialty of a specific review domain.", "startOffset": 33, "endOffset": 36}, {"referenceID": 9, "context": "The most widely used surveys[2], [3], [10] are for products in general and none of them have studied the specialty of a specific review domain.", "startOffset": 38, "endOffset": 42}, {"referenceID": 10, "context": "Software quality has been studied in many models[11], [12] but [13] found that they are limited.", "startOffset": 48, "endOffset": 52}, {"referenceID": 11, "context": "Software quality has been studied in many models[11], [12] but [13] found that they are limited.", "startOffset": 54, "endOffset": 58}, {"referenceID": 12, "context": "Software quality has been studied in many models[11], [12] but [13] found that they are limited.", "startOffset": 63, "endOffset": 67}, {"referenceID": 12, "context": "[13] have studied several issues with current software quality models.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] suggested to build a dataset of", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "They further proposed two frameworks towards solving this problem[6], [15].", "startOffset": 65, "endOffset": 68}, {"referenceID": 14, "context": "They further proposed two frameworks towards solving this problem[6], [15].", "startOffset": 70, "endOffset": 74}, {"referenceID": 6, "context": "prediction were also proposed in [7], [16].", "startOffset": 33, "endOffset": 36}, {"referenceID": 15, "context": "prediction were also proposed in [7], [16].", "startOffset": 38, "endOffset": 42}, {"referenceID": 16, "context": "Text mining has been discussed in topic models[17] and features clusters (i.", "startOffset": 46, "endOffset": 50}, {"referenceID": 17, "context": "grouping) [18].", "startOffset": 10, "endOffset": 14}, {"referenceID": 18, "context": "Bayes[19], Support Vector Machines[20], and", "startOffset": 5, "endOffset": 9}, {"referenceID": 19, "context": "Bayes[19], Support Vector Machines[20], and", "startOffset": 34, "endOffset": 38}, {"referenceID": 20, "context": "Maximum Entropy [21].", "startOffset": 16, "endOffset": 20}, {"referenceID": 19, "context": "The semi-supervised learning approaches [20] uses a small set of labelled data and large set of unlabelled data", "startOffset": 40, "endOffset": 44}, {"referenceID": 21, "context": "labelling for all training data[22], [23], [24].", "startOffset": 31, "endOffset": 35}, {"referenceID": 22, "context": "labelling for all training data[22], [23], [24].", "startOffset": 37, "endOffset": 41}, {"referenceID": 23, "context": "labelling for all training data[22], [23], [24].", "startOffset": 43, "endOffset": 47}, {"referenceID": 24, "context": "models are widely used[25][26], [27].", "startOffset": 22, "endOffset": 26}, {"referenceID": 25, "context": "models are widely used[25][26], [27].", "startOffset": 26, "endOffset": 30}, {"referenceID": 26, "context": "models are widely used[25][26], [27].", "startOffset": 32, "endOffset": 36}, {"referenceID": 24, "context": "Semantic (LSA) model [25][26], [27] transforms text to low dimensional matrix and it finds the most common", "startOffset": 21, "endOffset": 25}, {"referenceID": 25, "context": "Semantic (LSA) model [25][26], [27] transforms text to low dimensional matrix and it finds the most common", "startOffset": 25, "endOffset": 29}, {"referenceID": 26, "context": "Semantic (LSA) model [25][26], [27] transforms text to low dimensional matrix and it finds the most common", "startOffset": 31, "endOffset": 35}, {"referenceID": 24, "context": "[25] applied the LSA in order get the software quality-in-use properties.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[28] proposed Probabilistic Latent Semantic Analysis (PLSA) model.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[29] defined opinion mining problem consisting of these components: topic, opinion holder, sentiment and claim.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[30] defined it the same way but with different components: opinion holder, subject, aspect, evaluation where subject and aspect map to topic in Kim model [29], and evaluation maps to claim and sentiment.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[30] defined it the same way but with different components: opinion holder, subject, aspect, evaluation where subject and aspect map to topic in Kim model [29], and evaluation maps to claim and sentiment.", "startOffset": 155, "endOffset": 159}, {"referenceID": 1, "context": "Probably the most comprehensive definition is given by Liu [2].", "startOffset": 59, "endOffset": 62}, {"referenceID": 1, "context": "Throughout this article Liu [2] definition of opinion mining is adopted.", "startOffset": 28, "endOffset": 31}, {"referenceID": 30, "context": "problem[31].", "startOffset": 7, "endOffset": 11}, {"referenceID": 31, "context": "[32] used min-cut partition", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "[33]used election history to train a SVM on new election posts.", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "[34] proposed an", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "[35] classified the subjectivity of tweets based on features and Twitter clues.", "startOffset": 0, "endOffset": 4}, {"referenceID": 35, "context": "In unsupervised learning ,[36] used the presence of subjective expressions extracted using the concept of grade expressions [37].", "startOffset": 26, "endOffset": 30}, {"referenceID": 36, "context": "In unsupervised learning ,[36] used the presence of subjective expressions extracted using the concept of grade expressions [37].", "startOffset": 124, "endOffset": 128}, {"referenceID": 37, "context": "[38] used bootstrapping approach to learn two classifiers for", "startOffset": 0, "endOffset": 4}, {"referenceID": 38, "context": "based approach [39]\u2013[43] and the corpus-based", "startOffset": 15, "endOffset": 19}, {"referenceID": 42, "context": "based approach [39]\u2013[43] and the corpus-based", "startOffset": 20, "endOffset": 24}, {"referenceID": 36, "context": "approach [37], [44]\u2013[46].", "startOffset": 9, "endOffset": 13}, {"referenceID": 43, "context": "approach [37], [44]\u2013[46].", "startOffset": 15, "endOffset": 19}, {"referenceID": 45, "context": "approach [37], [44]\u2013[46].", "startOffset": 20, "endOffset": 24}, {"referenceID": 46, "context": "domain specific opinions it is still not easy to build since the same word may have a positive or negative polarity in the same domain in different contexts[47].", "startOffset": 156, "endOffset": 160}, {"referenceID": 47, "context": "parser[48], [49], connotation lexicon [50].", "startOffset": 6, "endOffset": 10}, {"referenceID": 48, "context": "parser[48], [49], connotation lexicon [50].", "startOffset": 12, "endOffset": 16}, {"referenceID": 49, "context": "parser[48], [49], connotation lexicon [50].", "startOffset": 38, "endOffset": 42}, {"referenceID": 13, "context": "To our knowledge there is no special lexicon for software quality[14], [51].", "startOffset": 65, "endOffset": 69}, {"referenceID": 50, "context": "To our knowledge there is no special lexicon for software quality[14], [51].", "startOffset": 71, "endOffset": 75}, {"referenceID": 51, "context": "[52], [53] used review rating regression prediction models on user ratings.", "startOffset": 0, "endOffset": 4}, {"referenceID": 52, "context": "[52], [53] used review rating regression prediction models on user ratings.", "startOffset": 6, "endOffset": 10}, {"referenceID": 53, "context": "Turney proposed unsupervised learning approach [54].", "startOffset": 47, "endOffset": 51}, {"referenceID": 30, "context": "supervised learning to learn sentences polarity[31].", "startOffset": 47, "endOffset": 51}, {"referenceID": 30, "context": "[31]", "startOffset": 0, "endOffset": 4}, {"referenceID": 54, "context": "[55] proposed a lexicon based algorithm to calculate the total orientation by", "startOffset": 0, "endOffset": 4}, {"referenceID": 55, "context": "[56] proposed to utilize a domain ontology to extract features and then they used binary SVM to classify sentences.", "startOffset": 0, "endOffset": 4}, {"referenceID": 56, "context": "[57] proposed an unsupervised approach that is based on the average Log-likehood of words in a sentence.", "startOffset": 0, "endOffset": 4}, {"referenceID": 57, "context": "[58] proposed a semi-supervised learning algorithm to learn from a small set of labeled sentences and a large set of unlabeled sentences.", "startOffset": 0, "endOffset": 4}, {"referenceID": 58, "context": "[59] identified that conditional sentences has to be taken in their algorithm to deal with different types of if statements.", "startOffset": 0, "endOffset": 4}, {"referenceID": 44, "context": "The aspect sentiment classification methods frequently uses a lexicon , a list of opinion words and phrases to determine the orientation of an aspect in a sentence [45], [55].", "startOffset": 164, "endOffset": 168}, {"referenceID": 54, "context": "The aspect sentiment classification methods frequently uses a lexicon , a list of opinion words and phrases to determine the orientation of an aspect in a sentence [45], [55].", "startOffset": 170, "endOffset": 174}, {"referenceID": 59, "context": "supervised[60] [61] [45] [62] [59], lexicon-based[63],", "startOffset": 10, "endOffset": 14}, {"referenceID": 60, "context": "supervised[60] [61] [45] [62] [59], lexicon-based[63],", "startOffset": 15, "endOffset": 19}, {"referenceID": 44, "context": "supervised[60] [61] [45] [62] [59], lexicon-based[63],", "startOffset": 20, "endOffset": 24}, {"referenceID": 61, "context": "supervised[60] [61] [45] [62] [59], lexicon-based[63],", "startOffset": 25, "endOffset": 29}, {"referenceID": 58, "context": "supervised[60] [61] [45] [62] [59], lexicon-based[63],", "startOffset": 30, "endOffset": 34}, {"referenceID": 62, "context": "supervised[60] [61] [45] [62] [59], lexicon-based[63],", "startOffset": 49, "endOffset": 53}, {"referenceID": 63, "context": "[64] [65] [23], and topic modeling approaches[18], [21], [66], [67].", "startOffset": 0, "endOffset": 4}, {"referenceID": 64, "context": "[64] [65] [23], and topic modeling approaches[18], [21], [66], [67].", "startOffset": 5, "endOffset": 9}, {"referenceID": 22, "context": "[64] [65] [23], and topic modeling approaches[18], [21], [66], [67].", "startOffset": 10, "endOffset": 14}, {"referenceID": 17, "context": "[64] [65] [23], and topic modeling approaches[18], [21], [66], [67].", "startOffset": 45, "endOffset": 49}, {"referenceID": 20, "context": "[64] [65] [23], and topic modeling approaches[18], [21], [66], [67].", "startOffset": 51, "endOffset": 55}, {"referenceID": 65, "context": "[64] [65] [23], and topic modeling approaches[18], [21], [66], [67].", "startOffset": 57, "endOffset": 61}, {"referenceID": 66, "context": "[64] [65] [23], and topic modeling approaches[18], [21], [66], [67].", "startOffset": 63, "endOffset": 67}, {"referenceID": 59, "context": "dependency)[60].", "startOffset": 11, "endOffset": 15}, {"referenceID": 67, "context": "[68] showed the", "startOffset": 0, "endOffset": 4}, {"referenceID": 68, "context": "[69] pointed out that the strength of opinions expressed in individual clauses is important as well as pointing out subjective and objective clauses in a sentence.", "startOffset": 0, "endOffset": 4}, {"referenceID": 69, "context": "extraction has been studied in supervised learning approaches [70], [71], frequency based approaches [39], [55], [60], [72]\u2013[75], bootstrapping (from lexicon words or candidate features) [48], [49], [76]\u2013[79], and as a topic modeling approaches [18], [21], [66], [67].", "startOffset": 62, "endOffset": 66}, {"referenceID": 70, "context": "extraction has been studied in supervised learning approaches [70], [71], frequency based approaches [39], [55], [60], [72]\u2013[75], bootstrapping (from lexicon words or candidate features) [48], [49], [76]\u2013[79], and as a topic modeling approaches [18], [21], [66], [67].", "startOffset": 68, "endOffset": 72}, {"referenceID": 38, "context": "extraction has been studied in supervised learning approaches [70], [71], frequency based approaches [39], [55], [60], [72]\u2013[75], bootstrapping (from lexicon words or candidate features) [48], [49], [76]\u2013[79], and as a topic modeling approaches [18], [21], [66], [67].", "startOffset": 101, "endOffset": 105}, {"referenceID": 54, "context": "extraction has been studied in supervised learning approaches [70], [71], frequency based approaches [39], [55], [60], [72]\u2013[75], bootstrapping (from lexicon words or candidate features) [48], [49], [76]\u2013[79], and as a topic modeling approaches [18], [21], [66], [67].", "startOffset": 107, "endOffset": 111}, {"referenceID": 59, "context": "extraction has been studied in supervised learning approaches [70], [71], frequency based approaches [39], [55], [60], [72]\u2013[75], bootstrapping (from lexicon words or candidate features) [48], [49], [76]\u2013[79], and as a topic modeling approaches [18], [21], [66], [67].", "startOffset": 113, "endOffset": 117}, {"referenceID": 71, "context": "extraction has been studied in supervised learning approaches [70], [71], frequency based approaches [39], [55], [60], [72]\u2013[75], bootstrapping (from lexicon words or candidate features) [48], [49], [76]\u2013[79], and as a topic modeling approaches [18], [21], [66], [67].", "startOffset": 119, "endOffset": 123}, {"referenceID": 74, "context": "extraction has been studied in supervised learning approaches [70], [71], frequency based approaches [39], [55], [60], [72]\u2013[75], bootstrapping (from lexicon words or candidate features) [48], [49], [76]\u2013[79], and as a topic modeling approaches [18], [21], [66], [67].", "startOffset": 124, "endOffset": 128}, {"referenceID": 47, "context": "extraction has been studied in supervised learning approaches [70], [71], frequency based approaches [39], [55], [60], [72]\u2013[75], bootstrapping (from lexicon words or candidate features) [48], [49], [76]\u2013[79], and as a topic modeling approaches [18], [21], [66], [67].", "startOffset": 187, "endOffset": 191}, {"referenceID": 48, "context": "extraction has been studied in supervised learning approaches [70], [71], frequency based approaches [39], [55], [60], [72]\u2013[75], bootstrapping (from lexicon words or candidate features) [48], [49], [76]\u2013[79], and as a topic modeling approaches [18], [21], [66], [67].", "startOffset": 193, "endOffset": 197}, {"referenceID": 75, "context": "extraction has been studied in supervised learning approaches [70], [71], frequency based approaches [39], [55], [60], [72]\u2013[75], bootstrapping (from lexicon words or candidate features) [48], [49], [76]\u2013[79], and as a topic modeling approaches [18], [21], [66], [67].", "startOffset": 199, "endOffset": 203}, {"referenceID": 78, "context": "extraction has been studied in supervised learning approaches [70], [71], frequency based approaches [39], [55], [60], [72]\u2013[75], bootstrapping (from lexicon words or candidate features) [48], [49], [76]\u2013[79], and as a topic modeling approaches [18], [21], [66], [67].", "startOffset": 204, "endOffset": 208}, {"referenceID": 17, "context": "extraction has been studied in supervised learning approaches [70], [71], frequency based approaches [39], [55], [60], [72]\u2013[75], bootstrapping (from lexicon words or candidate features) [48], [49], [76]\u2013[79], and as a topic modeling approaches [18], [21], [66], [67].", "startOffset": 245, "endOffset": 249}, {"referenceID": 20, "context": "extraction has been studied in supervised learning approaches [70], [71], frequency based approaches [39], [55], [60], [72]\u2013[75], bootstrapping (from lexicon words or candidate features) [48], [49], [76]\u2013[79], and as a topic modeling approaches [18], [21], [66], [67].", "startOffset": 251, "endOffset": 255}, {"referenceID": 65, "context": "extraction has been studied in supervised learning approaches [70], [71], frequency based approaches [39], [55], [60], [72]\u2013[75], bootstrapping (from lexicon words or candidate features) [48], [49], [76]\u2013[79], and as a topic modeling approaches [18], [21], [66], [67].", "startOffset": 257, "endOffset": 261}, {"referenceID": 66, "context": "extraction has been studied in supervised learning approaches [70], [71], frequency based approaches [39], [55], [60], [72]\u2013[75], bootstrapping (from lexicon words or candidate features) [48], [49], [76]\u2013[79], and as a topic modeling approaches [18], [21], [66], [67].", "startOffset": 263, "endOffset": 267}, {"referenceID": 69, "context": "In supervised mining [70], [71] proposed to use label sequential rules: The rules that involve a feature (called language patterns) are found given that it satisfies predefined support and confidence.", "startOffset": 21, "endOffset": 25}, {"referenceID": 70, "context": "In supervised mining [70], [71] proposed to use label sequential rules: The rules that involve a feature (called language patterns) are found given that it satisfies predefined support and confidence.", "startOffset": 27, "endOffset": 31}, {"referenceID": 74, "context": "[75] proposed a supervised based model", "startOffset": 0, "endOffset": 4}, {"referenceID": 79, "context": "based on Ku method [80].", "startOffset": 19, "endOffset": 23}, {"referenceID": 54, "context": "approach [55]finds frequent nouns and noun phrases as aspects.", "startOffset": 9, "endOffset": 13}, {"referenceID": 71, "context": "It also finds infrequent aspect exploiting relationships between aspects and opinion words [72]", "startOffset": 91, "endOffset": 95}, {"referenceID": 54, "context": "[55] [72] [74] [80].", "startOffset": 0, "endOffset": 4}, {"referenceID": 71, "context": "[55] [72] [74] [80].", "startOffset": 5, "endOffset": 9}, {"referenceID": 73, "context": "[55] [72] [74] [80].", "startOffset": 10, "endOffset": 14}, {"referenceID": 79, "context": "[55] [72] [74] [80].", "startOffset": 15, "endOffset": 19}, {"referenceID": 59, "context": "[60] integrated WordNet, and movie reviews to extract frequent feature and opinion pairs.", "startOffset": 0, "endOffset": 4}, {"referenceID": 39, "context": "[40] refined the frequent noun phrase to consider any", "startOffset": 0, "endOffset": 4}, {"referenceID": 47, "context": "Various works [48], [49], [76]\u2013[78] extract domain independent aspect and opinion words.", "startOffset": 14, "endOffset": 18}, {"referenceID": 48, "context": "Various works [48], [49], [76]\u2013[78] extract domain independent aspect and opinion words.", "startOffset": 20, "endOffset": 24}, {"referenceID": 75, "context": "Various works [48], [49], [76]\u2013[78] extract domain independent aspect and opinion words.", "startOffset": 26, "endOffset": 30}, {"referenceID": 77, "context": "Various works [48], [49], [76]\u2013[78] extract domain independent aspect and opinion words.", "startOffset": 31, "endOffset": 35}, {"referenceID": 47, "context": "[48]", "startOffset": 0, "endOffset": 4}, {"referenceID": 48, "context": "[49] double propagation approach is a bootstrapping", "startOffset": 0, "endOffset": 4}, {"referenceID": 76, "context": "[77] extracted features that are associated with opinion", "startOffset": 0, "endOffset": 4}, {"referenceID": 77, "context": "employed to find frequent features [78].", "startOffset": 35, "endOffset": 39}, {"referenceID": 78, "context": "[79] built iterative learning between aspects and opinion words.", "startOffset": 0, "endOffset": 4}, {"referenceID": 80, "context": "mixture model have been studied extensively[82][83],", "startOffset": 43, "endOffset": 47}, {"referenceID": 81, "context": "mixture model have been studied extensively[82][83],", "startOffset": 47, "endOffset": 51}, {"referenceID": 80, "context": "however they have the problem of separating features from opinion words [82] [21].", "startOffset": 72, "endOffset": 76}, {"referenceID": 20, "context": "however they have the problem of separating features from opinion words [82] [21].", "startOffset": 77, "endOffset": 81}, {"referenceID": 53, "context": "model-based approaches[54], [55], [72] and statistical models[18], [21], [66] are competing.", "startOffset": 22, "endOffset": 26}, {"referenceID": 54, "context": "model-based approaches[54], [55], [72] and statistical models[18], [21], [66] are competing.", "startOffset": 28, "endOffset": 32}, {"referenceID": 71, "context": "model-based approaches[54], [55], [72] and statistical models[18], [21], [66] are competing.", "startOffset": 34, "endOffset": 38}, {"referenceID": 17, "context": "model-based approaches[54], [55], [72] and statistical models[18], [21], [66] are competing.", "startOffset": 61, "endOffset": 65}, {"referenceID": 20, "context": "model-based approaches[54], [55], [72] and statistical models[18], [21], [66] are competing.", "startOffset": 67, "endOffset": 71}, {"referenceID": 65, "context": "model-based approaches[54], [55], [72] and statistical models[18], [21], [66] are competing.", "startOffset": 73, "endOffset": 77}, {"referenceID": 82, "context": "[84] studied feature-learning method completeness from different perspectives such as its ability to identify features or opinions words or phrases, ability to reveal intensifiers, ability to classify infrequent entities, and ability to classify sentence subjectively.", "startOffset": 0, "endOffset": 4}, {"referenceID": 82, "context": "They also studied the application of Conditional Random Fields (CRF) into mining consumer reviews [84].", "startOffset": 98, "endOffset": 102}, {"referenceID": 54, "context": "Many works takes the adjective or adverb and sometimes the verb as an implicit feature indicator[55] [85].", "startOffset": 96, "endOffset": 100}, {"referenceID": 83, "context": "Many works takes the adjective or adverb and sometimes the verb as an implicit feature indicator[55] [85].", "startOffset": 101, "endOffset": 105}, {"referenceID": 54, "context": "[55] used seed sentiment word to extract infrequent features to the opinion word as an indicator of implicit feature.", "startOffset": 0, "endOffset": 4}, {"referenceID": 72, "context": "[73] applied co-occurrence words between implicit and explicit features using frequency, PMI variants.", "startOffset": 0, "endOffset": 4}, {"referenceID": 78, "context": "[79] extracted implicit features by exploiting a function between opinion words and features.", "startOffset": 0, "endOffset": 4}, {"referenceID": 84, "context": "Hidden Markov models HMM [86] [66], and", "startOffset": 25, "endOffset": 29}, {"referenceID": 65, "context": "Hidden Markov models HMM [86] [66], and", "startOffset": 30, "endOffset": 34}, {"referenceID": 85, "context": "Conditional Random Fields (CRF) [87][88].", "startOffset": 32, "endOffset": 36}, {"referenceID": 86, "context": "Conditional Random Fields (CRF) [87][88].", "startOffset": 36, "endOffset": 40}, {"referenceID": 87, "context": "[89] used onceClass SVM which trains for aspects without any training for non-aspects.", "startOffset": 0, "endOffset": 4}, {"referenceID": 88, "context": "[90] proposed a supervised", "startOffset": 0, "endOffset": 4}, {"referenceID": 89, "context": "[91] proposed an aspect topic model based on the PLSA.", "startOffset": 0, "endOffset": 4}, {"referenceID": 90, "context": "[92] mapped implicit aspect expression", "startOffset": 0, "endOffset": 4}, {"referenceID": 91, "context": "[93] used two phase cooccurrence association rule (explicit aspects and", "startOffset": 0, "endOffset": 4}, {"referenceID": 70, "context": "Many synonyms are domain dependent [71]; movie and picture are synonyms in movie reviews but they are not synonyms in camera reviews.", "startOffset": 35, "endOffset": 39}, {"referenceID": 77, "context": "There are three major approaches for grouping: using semi-supervised learning seeds of features and their groups with matching rules [78], [94]\u2013[96], topic models [97], [98] and distributional/relatedness or similarity measures [71], [99].", "startOffset": 133, "endOffset": 137}, {"referenceID": 92, "context": "There are three major approaches for grouping: using semi-supervised learning seeds of features and their groups with matching rules [78], [94]\u2013[96], topic models [97], [98] and distributional/relatedness or similarity measures [71], [99].", "startOffset": 139, "endOffset": 143}, {"referenceID": 94, "context": "There are three major approaches for grouping: using semi-supervised learning seeds of features and their groups with matching rules [78], [94]\u2013[96], topic models [97], [98] and distributional/relatedness or similarity measures [71], [99].", "startOffset": 144, "endOffset": 148}, {"referenceID": 95, "context": "There are three major approaches for grouping: using semi-supervised learning seeds of features and their groups with matching rules [78], [94]\u2013[96], topic models [97], [98] and distributional/relatedness or similarity measures [71], [99].", "startOffset": 163, "endOffset": 167}, {"referenceID": 96, "context": "There are three major approaches for grouping: using semi-supervised learning seeds of features and their groups with matching rules [78], [94]\u2013[96], topic models [97], [98] and distributional/relatedness or similarity measures [71], [99].", "startOffset": 169, "endOffset": 173}, {"referenceID": 70, "context": "There are three major approaches for grouping: using semi-supervised learning seeds of features and their groups with matching rules [78], [94]\u2013[96], topic models [97], [98] and distributional/relatedness or similarity measures [71], [99].", "startOffset": 228, "endOffset": 232}, {"referenceID": 97, "context": "There are three major approaches for grouping: using semi-supervised learning seeds of features and their groups with matching rules [78], [94]\u2013[96], topic models [97], [98] and distributional/relatedness or similarity measures [71], [99].", "startOffset": 234, "endOffset": 238}, {"referenceID": 92, "context": "[94], [95] used semisupervised learning method to group aspect expression into some user specified aspect categories using Expectation Maximization algorithm.", "startOffset": 0, "endOffset": 4}, {"referenceID": 93, "context": "[94], [95] used semisupervised learning method to group aspect expression into some user specified aspect categories using Expectation Maximization algorithm.", "startOffset": 6, "endOffset": 10}, {"referenceID": 23, "context": "[24] used a semi supervised soft-constrained algorithm based on Expectation Maximization(EM) algorithm [100] , called soft-constrained EM (SC-EM) .", "startOffset": 0, "endOffset": 4}, {"referenceID": 98, "context": "[24] used a semi supervised soft-constrained algorithm based on Expectation Maximization(EM) algorithm [100] , called soft-constrained EM (SC-EM) .", "startOffset": 103, "endOffset": 108}, {"referenceID": 94, "context": "[96] extracted domain-independent features from reviews and classify them.", "startOffset": 0, "endOffset": 4}, {"referenceID": 95, "context": "The [97] algorithm known as DFLDA, add domain knowledge to topic modeling by incorporating can-link and cannot-link between feature words.", "startOffset": 4, "endOffset": 8}, {"referenceID": 96, "context": "Multilevel latent categorization by [98] performs latent semantic analysis to group aspects at two levels.", "startOffset": 36, "endOffset": 40}, {"referenceID": 97, "context": "[99] defined several similarity metrics and distances measures using WordNet.", "startOffset": 0, "endOffset": 4}, {"referenceID": 70, "context": "in [71] but both Liu work and Carenini are domain", "startOffset": 3, "endOffset": 7}, {"referenceID": 77, "context": "[78] used the LSA and Likelihood Ratio Test(LRT) as an association between features and opinion candidates in order to find real features and opinions.", "startOffset": 0, "endOffset": 4}, {"referenceID": 72, "context": "[73] grouped explicit synonyms to a predefined most important features identified by user", "startOffset": 0, "endOffset": 4}, {"referenceID": 99, "context": "There are three major different models to perform summarization of reviews ;1) sentiment match: extract sentences so that the average sentiment of the summary is close to average sentence review of an entity [101], 2) sentiment match plus aspect coverage(SMAC); a tradeoff aspect coverage/sentence entity [102], 3) sentiment aspect match(SAM); cover important aspect with appropriate sentiment [80], [103].", "startOffset": 208, "endOffset": 213}, {"referenceID": 100, "context": "There are three major different models to perform summarization of reviews ;1) sentiment match: extract sentences so that the average sentiment of the summary is close to average sentence review of an entity [101], 2) sentiment match plus aspect coverage(SMAC); a tradeoff aspect coverage/sentence entity [102], 3) sentiment aspect match(SAM); cover important aspect with appropriate sentiment [80], [103].", "startOffset": 305, "endOffset": 310}, {"referenceID": 79, "context": "There are three major different models to perform summarization of reviews ;1) sentiment match: extract sentences so that the average sentiment of the summary is close to average sentence review of an entity [101], 2) sentiment match plus aspect coverage(SMAC); a tradeoff aspect coverage/sentence entity [102], 3) sentiment aspect match(SAM); cover important aspect with appropriate sentiment [80], [103].", "startOffset": 394, "endOffset": 398}, {"referenceID": 101, "context": "There are three major different models to perform summarization of reviews ;1) sentiment match: extract sentences so that the average sentiment of the summary is close to average sentence review of an entity [101], 2) sentiment match plus aspect coverage(SMAC); a tradeoff aspect coverage/sentence entity [102], 3) sentiment aspect match(SAM); cover important aspect with appropriate sentiment [80], [103].", "startOffset": 400, "endOffset": 405}, {"referenceID": 102, "context": "[104] proposed an aspect-based opinion summarization (or structured summary) to detect Low-quality product review in opinion summarization.", "startOffset": 0, "endOffset": 5}, {"referenceID": 103, "context": "[105] used existing online ontology to organize opinions.", "startOffset": 0, "endOffset": 5}, {"referenceID": 104, "context": "[106] presented an aspect summary layout with a rating for each aspect.", "startOffset": 0, "endOffset": 5}, {"referenceID": 54, "context": "Many available annotations do not show details of opinion expressions [55], [74], [107].", "startOffset": 70, "endOffset": 74}, {"referenceID": 73, "context": "Many available annotations do not show details of opinion expressions [55], [74], [107].", "startOffset": 76, "endOffset": 80}, {"referenceID": 105, "context": "Many available annotations do not show details of opinion expressions [55], [74], [107].", "startOffset": 82, "endOffset": 87}, {"referenceID": 106, "context": "Recently [108] proposed a scheme to annotate a corpus of customer reviews by helping annotators using", "startOffset": 9, "endOffset": 14}, {"referenceID": 13, "context": "mining on software reviews[14].", "startOffset": 26, "endOffset": 30}, {"referenceID": 107, "context": "Although there are many researches on reference resolution[109] finding an automatic way to resolve reference and disambiguate word senses is still challenging.", "startOffset": 58, "endOffset": 63}, {"referenceID": 108, "context": "Word sense disambiguation: Word sense disambiguation[110] is essential for software reviews due the fact that some words are context specific.", "startOffset": 52, "endOffset": 57}], "year": 2016, "abstractText": "Software review text fragments have considerably valuable information about users\u2019 experience. It includes a huge set of properties including the software quality. Opinion mining or sentiment analysis is concerned with analyzing textual user judgments. The application of sentiment analysis on software reviews can find a quantitative value that represents software quality. Although many software quality methods are proposed they are considered difficult to customize and many of them are limited. This article investigates the application of opinion mining as an approach to extract software quality properties. We found that the major issues of software reviews mining using sentiment analysis are due to software lifecycle and the diverse users and teams. Keywords\u2014Software Quality-in-use, Clustering, Topic Models, Opinion Mining Tasks", "creator": "Microsoft\u00ae Word 2013"}}}