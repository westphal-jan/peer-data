{"id": "1603.08604", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Mar-2016", "title": "Classification-based Financial Markets Prediction using Deep Neural Networks", "abstract": "deep neural networks ( dnns ) are powerful types of intrinsic neural networks ( anns ) that use continuous hidden layers. they have recently gained considerable attention in the speech transcription and image recognition community ( krizhevsky et al., 2012 ) using their superior predictive systems including robustness dynamic overfitting. however their application to virtual trading has just been previously researched, partly because of their computational complexity. this paper describes the advantages of dnns to predicting financial market financing directions. in particular we describe the configuration and training approach and then demonstrate their application to justify a simple trading price over 43 different commodity and fx on mid - prices at 5 - minute intervals. all results in this paper are generated using hardware c + + system on the intel xeon phi co - processor logic is 11. 4x faster than the serial layout and web python strategy drafting environment both work which are available as open source code written by the authors.", "histories": [["v1", "Tue, 29 Mar 2016 01:26:04 GMT  (665kb,D)", "http://arxiv.org/abs/1603.08604v1", null], ["v2", "Tue, 13 Jun 2017 19:49:53 GMT  (513kb,D)", "http://arxiv.org/abs/1603.08604v2", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CE", "authors": ["matthew dixon", "diego klabjan", "jin hoon bang"], "accepted": false, "id": "1603.08604"}, "pdf": {"name": "1603.08604.pdf", "metadata": {"source": "CRF", "title": "Classification-based Financial Markets Prediction using Deep Neural Networks", "authors": ["Matthew Dixon", "Diego Klabjan", "Jin Hoon Bang"], "emails": ["matthew.dixon@stuart.iit.edu", "d-klabjan@northwestern.edu", "jinhoonbang@u.northwestern.edu"], "sections": [{"heading": "1 Introduction", "text": "Many of the challenges facing methods of financial econometrics include nonstationarity, non-linearity or noisiness of the time series. While the application of artificial neural networks (ANNs) to time series methods are well documented (Faraway and Chatfield, 1998; Refenes, 1994; Trippi and DeSieno, 1992; Kaastra and Boyd, 1995) their proneness to over-fitting, convergence problems, and difficulty of implementation raised concerns. Moreover, their departure from\nar X\niv :1\n60 3.\n08 60\n4v 1\nthe foundations of financial econometrics alienated the financial econometrics research community and finance practitioners.\nHowever, algotrading firms employ computer scientists and mathematicians who are able to perceive ANNs as not merely black-boxes, but rather a nonparametric approach to modeling based on minimizing an entropy function. As such, there has been a recent resurgence in the method, in part facilitated by advances in modern computer architecture (Chen et al., 2013; Niaki and Hoseinzade, 2013; Vanstone and Hahn, 2010).\nA deep neural network (DNN) is an artificial neural network with multiple hidden layers of units between the input and output layers. They have been popularized in the artificial intelligence community for their successful use in image classification (Krizhevsky et al., 2012) and speech recognition. The field is referred to as \u201dDeep Learning\u201d.\nIn this paper, we shall use DNNs to partially address some of the historical deficiencies of ANNs. Specifically, we model complex non-linear relationships between the independent variables and dependent variable and reduced tendency to overfit. In order to do this we shall exploit advances in low cost many-core accelerator platform to train and tune the parameters of our model.\nFor financial forecasting, especially in multivariate forecasting analysis, the feed-forward topology has gained much more attention and shall be the approach used here. Back-propagation and gradient descent have been the preferred method for training these structures due to the ease of implementation and their tendency to converge to better local optima in comparison with other trained models. However, these methods can be computationally expensive, especially when used to train DNNs.\nThere are many training parameters to be considered with a DNN, such as the size (number of layers and number of units per layer), the learning rate and initial weights. Sweeping through the parameter space for optimal parameters is not feasible due to the cost in time and computational resources. We shall use mini-batching (computing the gradient on several training examples at once rather than individual examples) as one common approach to speeding up computation. We go further by expressing the back-propagation algorithm in a form that is amenable to fast performance on an Intel Xeon Phi co-processor (Jeffers and Reinders, 2013). General purpose hardware optimized implementations of the back-propagation algorithm are described by Shekhar and Amin (1994), however our approach is tailored for the Intel Xeon Phi co-processor.\nThe main contribution of this paper is to describe the application of deep neural networks to financial time series data in order to classify financial market movement directions. Traditionally, researchers will iteratively experiment with a handful of signals to train a level based method, such as vector autoregression, for each instrument (see for example Kaastra and Boyd (1995); Refenes (1994); Trippi and DeSieno (1992)). More recently, however, Leung et al. (2000) provide evidence that classification based methods outperform level based methods in the prediction of the direction of stock movement and trading returns maximization.\nUsing 5 minute interval prices from June 1989 to March 2013, our approach\ndeparts from the literature by using state-of-the-art parallel computing architecture to simultaneously train a single model from a large number of signals across multiple instruments, rather than using one model for each instrument. By aggregating the data across multiple instruments and signals, we enable the model to capture a richer set of information describing the time-varying co-movements across signals for each instrument price movement. Our results show that our model is able to predict the direction of instrument movement to, on average, 42% accuracy with a standard deviation across instruments of 11%. In some cases, we are able to predict as high as 68%. We further show how backtesting accuracy translates into the P&L for a simple long-only trading strategy and demonstrate sample mean Annualized Sharpe Ratios as high as 3.29 with a standard deviation of 1.12.\nSo in summary, our approach differs from other financial studies described in the literature in two distinct ways:\n1. ANNs are applied to historical prices on an individual symbol and here 43 commodities and FX futures traded on the CME have been combined. Furthermore time series of lags, moving averages and moving correlations have been generated to capture memory and co-movements between symbols. Thus we have generated a richer dataset for the DNN to explore complex patterns.\n2. ANNs are applied as a regression, whereas here the output is one of {\u22121, 0, 1} representing a negative, flat or positive price movement respectively. The threshold for determining the zero state is set to 1\u00d710\u22123 (this is chosen to balance the class labels). The caveat is that restriction to a discrete set of output states may not replace a classical financial econometric technique, but it may be applicable for simple trading strategies which rely on the sign, and not the magnitude, of the forecasted price.\nIn the following section we introduce the back-propagation learning algorithm and use mini-batching to express the most compute intensive equations in matrix form. Once expressed in matrix form, hardware optimized numerical linear algebra routines are used to achieve an efficient mapping of the algorithm on to the Intel Xeon Phi co-processor. Section 3 describes the preparation of the data used to train the DNN. Section 4 describes the implementation of the DNN. Section 5 then presents results measuring the performance of a DNN. Finally in Section 6, we demonstrate the application of DNNs to backtesting using a walk forward methodology, and provide performance results for a simple buy-hold-sell strategy."}, {"heading": "2 Deep Neural Networks", "text": "We begin with mathematical preliminaries. Let D denote the historical dataset of M features and N observations. We draw a training subset Dtrain \u2282 D of Ntrain observations and a test subset of Dtest \u2282 D of Ntest observations.\nDenote the nth observation (feature vector) as xn \u2208 Dtrain. In an ANN, each element of the vector becomes a node in the input layer, as illustrated in the figure below for the case when there are 7 input variables (features) per observation. In a fully connected feed-forward network, each node is connected to every node in the next layer. Although not shown in the figure, associated with each edge between the ith node in the previous layer and the jth node in the current layer l is a weight w (l) ij .\nInput layer\nIn order to find optimal weightings w := {w(l)}l:=1\u2192L between nodes in a fully connected feed forward network with L layers, we seek to minimize a cross-entropy function of the form\nE(w) = \u2212 Ntest\u2211 n=1 en(w), en(w) := K\u2211 k=1 yknln (y\u0302kn) . (1)\nFor clarity of exposition, we drop the subscript n. The binary target y and output variables y\u0302 have a 1-of-k encoding for each symbol, where yk \u2208 {0, 1} and\u2211k\nk=1 yk = 1, so that each state associated with a symbol can be interpreted as\na probabilistic weighting. To ensure analytic gradient functions under the crossentropy error measure, the output layer is activated with a softmax function of the form\ny\u0302k := \u03c6softmax(s (L)) = exp(s (L) k )\u2211ks\nj=1 exp(s (L) j )\n. (2)\nThe gradient of the likelihood function w.r.t. s then takes the simple form:\n\u2202e(w) \u2202s (L) k = y\u0302k \u2212 yk (3)\nand in a fully connected feed-forward network s (l) k is the weighted sum of outputs from the previous layer l \u2212 1 that connect to node j in layer l:\ns (l) j = n(l\u22121)\u2211 i w (l) ij x (l\u22121) i + bias (l) j . (4)\nThe recursion relation for the back propagation using conjugate gradients is:\n\u03b4 (l\u22121) i = d(l\u22121)\u2211 j=1 \u03b4 (l) j w (l) ij \u03c3(s l\u22121) i )(1\u2212 \u03c3(s l\u22121) i ), (5)\nwhere we have used the analytic form of the derivative of the sigmoid function\n\u03c3\u2032(v) = \u03c3(v)(1\u2212 \u03c3(v)), (6)\nwhich is used to activate all hidden layer nodes. A trained feed-forward network can be used to predict the outputs states of all symbols, given any observation as an input, by recursively applying Equation 4. The description of how the network is trained now follows.\nStochastic Gradient Descent Following Rojas (1996), we now revisit the backpropagation learning algorithm based on the method of stochastic gradient descent (SGD) algorithm. After random sampling of an observation i, the SGD algorithm updates the parameter vector w(l) for the lth layer using\nw(l) = w(l) \u2212 \u03b3\u2207Ei(w(l)), (7)\nwhere \u03b3 is the learning rate. A high level description of the sequential version of the SGD algorithm is given in Algorithm 1. Note that for reasons of keeping the description simple, we have avoided some subtleties of the implementation.\nAlgorithm 1 Stochastic Gradient Descent\n1: w\u2190 r, ri \u2208 N (\u00b5, \u03c3), \u2200i 2: E \u2190 0 3: for i = 0 to n\u2212 1 do 4: E \u2190 E + Ei(w) 5: end for 6: while E \u2265 \u03c4 do 7: for t = 0 to n\u2212 1 do 8: i\u2190 sample with replacement in [0, n\u2212 1] 9: w\u2190 w \u2212 \u03b3\u2207Ei(w)\n10: end for 11: E \u2190 0 12: for i = 0 to n\u2212 1 do 13: E \u2190 E + Ei(w) 14: end for 15: end while"}, {"heading": "2.1 Mini-batching", "text": "It is well known that mini-batching improves the computational performance of the feedforward and back-propagation computations (Shekhar and Amin, 1994) . We process b observations in one mini-batch. This results in a change to the SGD algorithm and the dimensions of data-structures that are used to store variables. In particular, \u03b4, x, s and E now have a batch dimension. Note however that the dimensions of w(l) remain the same. The above equations can be now be modified.\nWith slight abuse of notation, we redefine the dimension \u03b4(l), X(l), S(l) \u2208 Rnl\u00d7b, \u2200l, E \u2208 RnL\u00d7b, where nl is the number of neurons in layer l and b is the size of the mini-batch.\nThe computation of the sum in the feed-forward network can be expressed as a matrix-matrix product at each layer\nS(l) = ( X\n(l\u22121) i\n)T w(l). (8)\nFor the ith neuron in output layer L and the jth observation in the mini-batch\n\u03b4 (L) ij = \u03c3 (L) ij (1\u2212 \u03c3 (L) ij )Eij . (9)\nFor all intermediate layers l < L, the recursion relation for \u03b4 is\n\u03b4 (l\u22121) ij = \u03c3 (l) ij (1\u2212 \u03c3 (l) ij )w (l) ij \u03b4 (l) ij . (10)\nThe weights are updated with matrix-matrix products for each layer\n\u2206w(l) = \u03b3X(l\u22121) ( \u03b4(l) )T . (11)"}, {"heading": "3 The Data", "text": "Our historical dataset contains 5 minute mid-prices for 43 CME listed commodity and FX futures from March 31st 1991 to September 30th, 2014. We use the most recent fifteen years of data because the previous period is less liquid for some of the symbols, resulting in long sections of 5 minute candles with no price movement. Each feature is normalized by subtracting the mean and dividing by the standard deviation. The training set consists of 25,000 consecutive observations and the test set consists of the next 12,500 observations. As described in Section 6, these sets are rolled forward ten times from the start of the liquid observation period, in 1000 observation period increments, until the final 37,500 observations from March 31st, 2005 until the end of the dataset.\nThe overall training dataset consists of the aggregate of feature training sets for each of the symbols. The training set of each symbol consists of price differences and engineered features including lagged prices differences from 1 to 100, moving price averages with window sizes from 5 to 100, and pair-wise correlations between the returns and the returns of all other symbols. The overall training set contains 9895 features. The motivation for including these features in the model is to capture memory in the historical data and co-movements between symbols."}, {"heading": "4 Implementation", "text": "The architecture of our network contains five learned fully connected layers. The first of the four hidden layers contains 1000 neurons and each subsequent layer is tapered by 100. The final layer contains 135 output neurons - three values per symbol of each of the 43 futures contracts. The result of including a large number of features and multiple hidden layers is that there are 12,174,500 weights in total.\nThe weights are initialized with an Intel MKL VSL random number generator implementation that uses the Mersenne Twistor (MT19937) routine. Gaussian random numbers are generated from transforming the uniform random numbers with an inverse Gaussian cumulative distribution function with zero mean and standard deviation of 0.01. We initialized the neuron biases in the hidden layers with the constant 1.\nWe used the same learning rate for all layers. The learning rate was adjusted according to a heuristic which is described in Algorithm 2 below and is similar to the approach taken by Krizhevsky et al. (2012) except that we use cross entropy rather than the validation error. We sweep the parameter space of the learning rate from [0.1, 1] with increments of 0.1. We further divide the learning rate by 2 if the cross-entropy does not decrease between epochs.\nIn Algorithm 2, the subset of the training set used for each epoch is defined as\nDe := {xnk \u2208 Dtrain | nk \u2208 U(1, Ntrain), k := 1, . . . , Nepoch} (12)\nAlgorithm 2 Deep Learning Methodology\n1: for \u03b3 := 0.1, 0.2, . . . , 1 do 2: w (l) i,j \u2190 r, r \u2208 N (\u00b5, \u03c3), \u2200i, j, l . Initialize all weights 3: for e = 1, . . . , Ne do . Iterate over epochs 4: Generate De 5: for m = 1, . . . ,M do . Iterate over mini-batches 6: Generate Dm 7: for l = 2, . . . , L do 8: Compute all x (l) j . Feed-Forward network construction\n9: end for 10: for l = L, . . . , 2 do 11: Compute all \u03b4 (l) j := \u2207s(l)j E . Backpropagation\n12: Update the weights: w(l) \u2190 w(l) \u2212 \u03b3X(l\u22121) ( \u03b4(l) )T 13: end for 14: end for 15: end for 16: If cross entropy(e) \u2264 cross entropy(e-1) then \u03b3 \u2190 \u03b3/2 17: end for 18: Return final weights w\n(l) i,j\nand the mini-batch with in each epoch set is defined as\nDm := {xnk \u2208 Dep | nk \u2208 U(1, Nepoch), k := 1, . . . , Nmini-batch}. (13)\nThe mini-batching formulation of the algorithm facilitates efficient parallel implementation, the details and timings of which are described by Dixon et al. (2015). The overall time to train a DNN on an Intel Xeon Phi using the data described above is approximately 10 hours when factoring in time for calculation of error measures on the test set and thus the training can be run as an overnight batch job. This is 10x faster than running the serial version of the algorithm."}, {"heading": "5 Results", "text": "This section describes the backtesting of DNNs for a simple algo-trading strategy. The purpose is to tie together classification accuracy with strategy performance measurements and is not intended to provided an exhaustive exploration of trading strategies. Figure 2 shows the classification accuracy of the DNN across the 43 CME Commodity and FX futures. The mean and the standard deviation envelope are also shown.\nFigure 3 below shows the distribution of the average classification accuracy over 10 samples of the DNN across the 45 CME Commodity and FX futures. There\u2019s a heavier density around an accuracy of 0.35 which is slightly better than a random selection.\nTable 1 shows the top five instruments for which the sample mean of the classification rate was highest on average over the ten walk forward experiments. Also shown are the F1-scores (\u2019harmonic means\u2019) which are considered to be a more robust measure of performance due to less sensitivity to class imbalance than classification accuracies. The mean and standard deviation of the sample averaged classification accuracies and F1-scores over the 43 futures are also provided.\nNote that the worst five performing instruments performed no better or even worse than white noise on average over the ten experiments."}, {"heading": "6 Strategy Backtesting", "text": "The paper has thus far considered the predictive properties of the deep neural network. Using commodity futures historical data at 5 minute intervals over the period from March 31st 1991 to September 30th, 2014, this section describes the application of a walk forward optimization approach for backtesting a simple trading strategy.\nFollowing the walk forward optimization approach described in Tomasini and Jaekle (2011), an initial optimization window of 25,000 5-minute observation periods or approximately 260 days (slightly more than a year) is chosen for training the model using all the symbol data and their engineered time series. The learning rate range is swept to find the model which gives the best outof-sample prediction rate - the highest classification rate on the out-of-sample (\u2019hold-out\u2019) set consisting of 12,500 consecutive and more recent observations.\nUsing the optimized model, the expected P&L of the trading strategy is then evaluated over the out-of-sample period consisting of 12,500 consecutive 5- minute observation periods or approximately 130 days. Even though all symbols are trained together using one DNN model, the cumulative P&L is calculated independently for each symbol. As illustrated in Figure 4, this step is repeated by sliding the training window forward by 1000 observation periods and repeating the out-of-sample error analysis and strategy performance measurement for\nten windows.\n."}, {"heading": "6.1 Example trading strategy", "text": "In order to demonstrate the approach to algorithmic trading, a simple buyhold-sell intraday test trading strategy is chosen contingent on whether the instrument price is likely to increase, be neutral, or decrease over the next time interval respectively. For simplicity, the strategy only takes single contract positions. The strategy closes out a short position and takes a long position if the label is 1, hold the position if the label is zero and closes out the long position and takes a short position if the label is -1. In calculating the cumulative P&L, the following assumptions are made:\n\u2022 the account is opened with $100k of USD;\n\u2022 there is sufficient surplus cash available in order to always maintain the brokerage account margin, through realization of the profit or otherwise;\n\u2022 there are no limits on the minimum or maximum holding period and positions can be held overnight;\n\u2022 the margin account is assumed to accrue zero interest;\n\u2022 transaction costs are ignored; and\n\u2022 the market is always sufficiently liquid that a limit order gets filled at the mid-price listed at 5 minute intervals, i.e. there are no slippage effects and the bid-ask spread can be considered negligible at one lot positions.\nReturns are calculated by first calculating daily returns and then annualizing them. No benchmark is used in the calculation of the Sharpe ratio. The Capability ratio is calculated under the assumption of normality or returns. See Kumiega and Van Vliet (2014) for further details of the Capability ratio.\nFigure 5 compares the Cumulative Net Dollar Profit of the strategy for the case when perfect forecasting information is available (\u2019perfect foresight\u2019) against using the DNN prediction (\u2019predict\u2019). The graph is shown for one 130 day trading horizon in PL futures.\nFigure 6 shows the range of annualized Sharpe ratios measured over each sliding period of 12,500 observation points for the top five performing futures contracts. This information is also supplemented in Table 2 which shows the top five instruments for which the mean annualized Sharpe ratio was highest on average over the ten walk forward experiments. The values in parenthesis denote the standard deviation over the ten experiments. Also shown, are the sample mean and standard deviations of the Capability ratios (where n = 130) under the assumption of normality of returns.\nTable 3 lists the initial margin, maintenance margin and contract size specified by the CME used to calculate the cumulative P&L and strategy performance for the top five performing futures positions."}, {"heading": "7 Conclusion", "text": "Deep neural networks (DNNs) are a powerful type of artificial neural network (ANN) that use several hidden layers. In this paper we describe the implementation and training of DNNs. We observe, for a historical dataset of 5 minute mid-prices of multiple CME listed futures prices and other lags and filters that DNNs have substantial predictive capabilities as classifiers if trained concurrently across several markets on labelled data. We further demonstrate the application of DNNs to backtesting a simple trading strategy and demonstrate the prediction accuracy and its relation to the strategy profitability. All results in this paper are generated using a C++ implementation on the Intel Xeon Phi co-processor which is 11.4x faster than the serial version and a Python strategy backtesting environment both of which are available as open source code written by the authors."}, {"heading": "8 Acknowledgements", "text": "The authors gratefully acknowledge the support of Intel Corporation in funding this research."}], "references": [{"title": "High technology ETF forecasting: Application of Grey Relational Analysis and Artificial Neural Networks", "author": ["J. Chen", "J.F. Diaz", "Y.F. Huang"], "venue": "Frontiers in Finance and Economics,", "citeRegEx": "Chen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2013}, {"title": "Implementing deep neural networks for financial market prediction on the intel xeon phi", "author": ["M. Dixon", "D. Klabjan", "J.H. Bang"], "venue": "In Proceedings of the 8th Workshop on High Performance Computational Finance,", "citeRegEx": "Dixon et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dixon et al\\.", "year": 2015}, {"title": "Time series forecasting with neural networks: a comparative study using the air line data", "author": ["J. Faraway", "C. Chatfield"], "venue": "Journal of the Royal Statistical Society: Series C (Applied Statistics),", "citeRegEx": "Faraway and Chatfield.,? \\Q1998\\E", "shortCiteRegEx": "Faraway and Chatfield.", "year": 1998}, {"title": "Intel Xeon Phi Coprocessor High Performance Programming", "author": ["J. Jeffers", "J. Reinders"], "venue": "USA, 1st edition,", "citeRegEx": "Jeffers and Reinders.,? \\Q2013\\E", "shortCiteRegEx": "Jeffers and Reinders.", "year": 2013}, {"title": "Forecasting futures trading volume using neural networks", "author": ["L. Kaastra", "M.S. Boyd"], "venue": "Journal of Futures Markets,", "citeRegEx": "Kaastra and Boyd.,? \\Q1995\\E", "shortCiteRegEx": "Kaastra and Boyd.", "year": 1995}, {"title": "Imagenet classification with deep convolutional neural networks. In Advances in neural information processing", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": null, "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Trading system capability", "author": ["A.N.T. Kumiega", "B. Van Vliet"], "venue": "Journal of Quantitative Finance,", "citeRegEx": "Kumiega and Vliet.,? \\Q2014\\E", "shortCiteRegEx": "Kumiega and Vliet.", "year": 2014}, {"title": "Forecasting stock indices: a comparison of classification and level estimation models", "author": ["M. Leung", "H. Daouk", "A.Chen"], "venue": "International Journal of Forecasting,", "citeRegEx": "Leung et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Leung et al\\.", "year": 2000}, {"title": "Forecasting S&P 500 index using artificial neural networks and design of experiments", "author": ["S. Niaki", "S. Hoseinzade"], "venue": "Journal of Industrial Engineering International,", "citeRegEx": "Niaki and Hoseinzade.,? \\Q2013\\E", "shortCiteRegEx": "Niaki and Hoseinzade.", "year": 2013}, {"title": "Neural Networks in the Capital Markets", "author": ["A.-P. Refenes"], "venue": null, "citeRegEx": "Refenes.,? \\Q1994\\E", "shortCiteRegEx": "Refenes.", "year": 1994}, {"title": "Neural Networks: A Systematic Introduction", "author": ["R. Rojas"], "venue": null, "citeRegEx": "Rojas.,? \\Q1996\\E", "shortCiteRegEx": "Rojas.", "year": 1996}, {"title": "A scalable parallel formulation of the backpropagation algorithm for hypercubes and related architectures", "author": ["V.K.S. Shekhar", "M.B. Amin"], "venue": "IEEE Transactions on Parallel and Distributed Systems,", "citeRegEx": "Shekhar and Amin.,? \\Q1994\\E", "shortCiteRegEx": "Shekhar and Amin.", "year": 1994}, {"title": "Trading equity index futures with a neural network", "author": ["R.R. Trippi", "D. DeSieno"], "venue": "The Journal of Portfolio Management,", "citeRegEx": "Trippi and DeSieno.,? \\Q1992\\E", "shortCiteRegEx": "Trippi and DeSieno.", "year": 1992}, {"title": "Designing Stock Market Trading Systems: With and Without Soft Computing", "author": ["B. Vanstone", "T. Hahn"], "venue": "Harriman House,", "citeRegEx": "Vanstone and Hahn.,? \\Q2010\\E", "shortCiteRegEx": "Vanstone and Hahn.", "year": 2010}], "referenceMentions": [{"referenceID": 5, "context": "They have recently gained considerable attention in the speech transcription and image recognition community (Krizhevsky et al., 2012) for their superior predictive properties including robustness to overfitting.", "startOffset": 109, "endOffset": 134}, {"referenceID": 2, "context": "While the application of artificial neural networks (ANNs) to time series methods are well documented (Faraway and Chatfield, 1998; Refenes, 1994; Trippi and DeSieno, 1992; Kaastra and Boyd, 1995) their proneness to over-fitting, convergence problems, and difficulty of implementation raised concerns.", "startOffset": 102, "endOffset": 196}, {"referenceID": 9, "context": "While the application of artificial neural networks (ANNs) to time series methods are well documented (Faraway and Chatfield, 1998; Refenes, 1994; Trippi and DeSieno, 1992; Kaastra and Boyd, 1995) their proneness to over-fitting, convergence problems, and difficulty of implementation raised concerns.", "startOffset": 102, "endOffset": 196}, {"referenceID": 12, "context": "While the application of artificial neural networks (ANNs) to time series methods are well documented (Faraway and Chatfield, 1998; Refenes, 1994; Trippi and DeSieno, 1992; Kaastra and Boyd, 1995) their proneness to over-fitting, convergence problems, and difficulty of implementation raised concerns.", "startOffset": 102, "endOffset": 196}, {"referenceID": 4, "context": "While the application of artificial neural networks (ANNs) to time series methods are well documented (Faraway and Chatfield, 1998; Refenes, 1994; Trippi and DeSieno, 1992; Kaastra and Boyd, 1995) their proneness to over-fitting, convergence problems, and difficulty of implementation raised concerns.", "startOffset": 102, "endOffset": 196}, {"referenceID": 0, "context": "As such, there has been a recent resurgence in the method, in part facilitated by advances in modern computer architecture (Chen et al., 2013; Niaki and Hoseinzade, 2013; Vanstone and Hahn, 2010).", "startOffset": 123, "endOffset": 195}, {"referenceID": 8, "context": "As such, there has been a recent resurgence in the method, in part facilitated by advances in modern computer architecture (Chen et al., 2013; Niaki and Hoseinzade, 2013; Vanstone and Hahn, 2010).", "startOffset": 123, "endOffset": 195}, {"referenceID": 13, "context": "As such, there has been a recent resurgence in the method, in part facilitated by advances in modern computer architecture (Chen et al., 2013; Niaki and Hoseinzade, 2013; Vanstone and Hahn, 2010).", "startOffset": 123, "endOffset": 195}, {"referenceID": 5, "context": "They have been popularized in the artificial intelligence community for their successful use in image classification (Krizhevsky et al., 2012) and speech recognition.", "startOffset": 117, "endOffset": 142}, {"referenceID": 3, "context": "We go further by expressing the back-propagation algorithm in a form that is amenable to fast performance on an Intel Xeon Phi co-processor (Jeffers and Reinders, 2013).", "startOffset": 140, "endOffset": 168}, {"referenceID": 0, "context": "As such, there has been a recent resurgence in the method, in part facilitated by advances in modern computer architecture (Chen et al., 2013; Niaki and Hoseinzade, 2013; Vanstone and Hahn, 2010). A deep neural network (DNN) is an artificial neural network with multiple hidden layers of units between the input and output layers. They have been popularized in the artificial intelligence community for their successful use in image classification (Krizhevsky et al., 2012) and speech recognition. The field is referred to as \u201dDeep Learning\u201d. In this paper, we shall use DNNs to partially address some of the historical deficiencies of ANNs. Specifically, we model complex non-linear relationships between the independent variables and dependent variable and reduced tendency to overfit. In order to do this we shall exploit advances in low cost many-core accelerator platform to train and tune the parameters of our model. For financial forecasting, especially in multivariate forecasting analysis, the feed-forward topology has gained much more attention and shall be the approach used here. Back-propagation and gradient descent have been the preferred method for training these structures due to the ease of implementation and their tendency to converge to better local optima in comparison with other trained models. However, these methods can be computationally expensive, especially when used to train DNNs. There are many training parameters to be considered with a DNN, such as the size (number of layers and number of units per layer), the learning rate and initial weights. Sweeping through the parameter space for optimal parameters is not feasible due to the cost in time and computational resources. We shall use mini-batching (computing the gradient on several training examples at once rather than individual examples) as one common approach to speeding up computation. We go further by expressing the back-propagation algorithm in a form that is amenable to fast performance on an Intel Xeon Phi co-processor (Jeffers and Reinders, 2013). General purpose hardware optimized implementations of the back-propagation algorithm are described by Shekhar and Amin (1994), however our approach is tailored for the Intel Xeon Phi co-processor.", "startOffset": 124, "endOffset": 2182}, {"referenceID": 0, "context": "As such, there has been a recent resurgence in the method, in part facilitated by advances in modern computer architecture (Chen et al., 2013; Niaki and Hoseinzade, 2013; Vanstone and Hahn, 2010). A deep neural network (DNN) is an artificial neural network with multiple hidden layers of units between the input and output layers. They have been popularized in the artificial intelligence community for their successful use in image classification (Krizhevsky et al., 2012) and speech recognition. The field is referred to as \u201dDeep Learning\u201d. In this paper, we shall use DNNs to partially address some of the historical deficiencies of ANNs. Specifically, we model complex non-linear relationships between the independent variables and dependent variable and reduced tendency to overfit. In order to do this we shall exploit advances in low cost many-core accelerator platform to train and tune the parameters of our model. For financial forecasting, especially in multivariate forecasting analysis, the feed-forward topology has gained much more attention and shall be the approach used here. Back-propagation and gradient descent have been the preferred method for training these structures due to the ease of implementation and their tendency to converge to better local optima in comparison with other trained models. However, these methods can be computationally expensive, especially when used to train DNNs. There are many training parameters to be considered with a DNN, such as the size (number of layers and number of units per layer), the learning rate and initial weights. Sweeping through the parameter space for optimal parameters is not feasible due to the cost in time and computational resources. We shall use mini-batching (computing the gradient on several training examples at once rather than individual examples) as one common approach to speeding up computation. We go further by expressing the back-propagation algorithm in a form that is amenable to fast performance on an Intel Xeon Phi co-processor (Jeffers and Reinders, 2013). General purpose hardware optimized implementations of the back-propagation algorithm are described by Shekhar and Amin (1994), however our approach is tailored for the Intel Xeon Phi co-processor. The main contribution of this paper is to describe the application of deep neural networks to financial time series data in order to classify financial market movement directions. Traditionally, researchers will iteratively experiment with a handful of signals to train a level based method, such as vector autoregression, for each instrument (see for example Kaastra and Boyd (1995); Refenes (1994); Trippi and DeSieno (1992)).", "startOffset": 124, "endOffset": 2637}, {"referenceID": 0, "context": "As such, there has been a recent resurgence in the method, in part facilitated by advances in modern computer architecture (Chen et al., 2013; Niaki and Hoseinzade, 2013; Vanstone and Hahn, 2010). A deep neural network (DNN) is an artificial neural network with multiple hidden layers of units between the input and output layers. They have been popularized in the artificial intelligence community for their successful use in image classification (Krizhevsky et al., 2012) and speech recognition. The field is referred to as \u201dDeep Learning\u201d. In this paper, we shall use DNNs to partially address some of the historical deficiencies of ANNs. Specifically, we model complex non-linear relationships between the independent variables and dependent variable and reduced tendency to overfit. In order to do this we shall exploit advances in low cost many-core accelerator platform to train and tune the parameters of our model. For financial forecasting, especially in multivariate forecasting analysis, the feed-forward topology has gained much more attention and shall be the approach used here. Back-propagation and gradient descent have been the preferred method for training these structures due to the ease of implementation and their tendency to converge to better local optima in comparison with other trained models. However, these methods can be computationally expensive, especially when used to train DNNs. There are many training parameters to be considered with a DNN, such as the size (number of layers and number of units per layer), the learning rate and initial weights. Sweeping through the parameter space for optimal parameters is not feasible due to the cost in time and computational resources. We shall use mini-batching (computing the gradient on several training examples at once rather than individual examples) as one common approach to speeding up computation. We go further by expressing the back-propagation algorithm in a form that is amenable to fast performance on an Intel Xeon Phi co-processor (Jeffers and Reinders, 2013). General purpose hardware optimized implementations of the back-propagation algorithm are described by Shekhar and Amin (1994), however our approach is tailored for the Intel Xeon Phi co-processor. The main contribution of this paper is to describe the application of deep neural networks to financial time series data in order to classify financial market movement directions. Traditionally, researchers will iteratively experiment with a handful of signals to train a level based method, such as vector autoregression, for each instrument (see for example Kaastra and Boyd (1995); Refenes (1994); Trippi and DeSieno (1992)).", "startOffset": 124, "endOffset": 2653}, {"referenceID": 0, "context": "As such, there has been a recent resurgence in the method, in part facilitated by advances in modern computer architecture (Chen et al., 2013; Niaki and Hoseinzade, 2013; Vanstone and Hahn, 2010). A deep neural network (DNN) is an artificial neural network with multiple hidden layers of units between the input and output layers. They have been popularized in the artificial intelligence community for their successful use in image classification (Krizhevsky et al., 2012) and speech recognition. The field is referred to as \u201dDeep Learning\u201d. In this paper, we shall use DNNs to partially address some of the historical deficiencies of ANNs. Specifically, we model complex non-linear relationships between the independent variables and dependent variable and reduced tendency to overfit. In order to do this we shall exploit advances in low cost many-core accelerator platform to train and tune the parameters of our model. For financial forecasting, especially in multivariate forecasting analysis, the feed-forward topology has gained much more attention and shall be the approach used here. Back-propagation and gradient descent have been the preferred method for training these structures due to the ease of implementation and their tendency to converge to better local optima in comparison with other trained models. However, these methods can be computationally expensive, especially when used to train DNNs. There are many training parameters to be considered with a DNN, such as the size (number of layers and number of units per layer), the learning rate and initial weights. Sweeping through the parameter space for optimal parameters is not feasible due to the cost in time and computational resources. We shall use mini-batching (computing the gradient on several training examples at once rather than individual examples) as one common approach to speeding up computation. We go further by expressing the back-propagation algorithm in a form that is amenable to fast performance on an Intel Xeon Phi co-processor (Jeffers and Reinders, 2013). General purpose hardware optimized implementations of the back-propagation algorithm are described by Shekhar and Amin (1994), however our approach is tailored for the Intel Xeon Phi co-processor. The main contribution of this paper is to describe the application of deep neural networks to financial time series data in order to classify financial market movement directions. Traditionally, researchers will iteratively experiment with a handful of signals to train a level based method, such as vector autoregression, for each instrument (see for example Kaastra and Boyd (1995); Refenes (1994); Trippi and DeSieno (1992)).", "startOffset": 124, "endOffset": 2680}, {"referenceID": 0, "context": "As such, there has been a recent resurgence in the method, in part facilitated by advances in modern computer architecture (Chen et al., 2013; Niaki and Hoseinzade, 2013; Vanstone and Hahn, 2010). A deep neural network (DNN) is an artificial neural network with multiple hidden layers of units between the input and output layers. They have been popularized in the artificial intelligence community for their successful use in image classification (Krizhevsky et al., 2012) and speech recognition. The field is referred to as \u201dDeep Learning\u201d. In this paper, we shall use DNNs to partially address some of the historical deficiencies of ANNs. Specifically, we model complex non-linear relationships between the independent variables and dependent variable and reduced tendency to overfit. In order to do this we shall exploit advances in low cost many-core accelerator platform to train and tune the parameters of our model. For financial forecasting, especially in multivariate forecasting analysis, the feed-forward topology has gained much more attention and shall be the approach used here. Back-propagation and gradient descent have been the preferred method for training these structures due to the ease of implementation and their tendency to converge to better local optima in comparison with other trained models. However, these methods can be computationally expensive, especially when used to train DNNs. There are many training parameters to be considered with a DNN, such as the size (number of layers and number of units per layer), the learning rate and initial weights. Sweeping through the parameter space for optimal parameters is not feasible due to the cost in time and computational resources. We shall use mini-batching (computing the gradient on several training examples at once rather than individual examples) as one common approach to speeding up computation. We go further by expressing the back-propagation algorithm in a form that is amenable to fast performance on an Intel Xeon Phi co-processor (Jeffers and Reinders, 2013). General purpose hardware optimized implementations of the back-propagation algorithm are described by Shekhar and Amin (1994), however our approach is tailored for the Intel Xeon Phi co-processor. The main contribution of this paper is to describe the application of deep neural networks to financial time series data in order to classify financial market movement directions. Traditionally, researchers will iteratively experiment with a handful of signals to train a level based method, such as vector autoregression, for each instrument (see for example Kaastra and Boyd (1995); Refenes (1994); Trippi and DeSieno (1992)). More recently, however, Leung et al. (2000) provide evidence that classification based methods outperform level based methods in the prediction of the direction of stock movement and trading returns maximization.", "startOffset": 124, "endOffset": 2726}, {"referenceID": 10, "context": "Stochastic Gradient Descent Following Rojas (1996), we now revisit the backpropagation learning algorithm based on the method of stochastic gradient descent (SGD) algorithm.", "startOffset": 38, "endOffset": 51}, {"referenceID": 11, "context": "It is well known that mini-batching improves the computational performance of the feedforward and back-propagation computations (Shekhar and Amin, 1994) .", "startOffset": 128, "endOffset": 152}, {"referenceID": 5, "context": "The learning rate was adjusted according to a heuristic which is described in Algorithm 2 below and is similar to the approach taken by Krizhevsky et al. (2012) except that we use cross entropy rather than the validation error.", "startOffset": 136, "endOffset": 161}, {"referenceID": 1, "context": "The mini-batching formulation of the algorithm facilitates efficient parallel implementation, the details and timings of which are described by Dixon et al. (2015). The overall time to train a DNN on an Intel Xeon Phi using the data described above is approximately 10 hours when factoring in time for calculation of error measures on the test set and thus the training can be run as an overnight batch job.", "startOffset": 144, "endOffset": 164}], "year": 2016, "abstractText": "Deep neural networks (DNNs) are powerful types of artificial neural networks (ANNs) that use several hidden layers. They have recently gained considerable attention in the speech transcription and image recognition community (Krizhevsky et al., 2012) for their superior predictive properties including robustness to overfitting. However their application to algorithmic trading has not been previously researched, partly because of their computational complexity. This paper describes the application of DNNs to predicting financial market movement directions. In particular we describe the configuration and training approach and then demonstrate their application to backtesting a simple trading strategy over 43 different Commodity and FX future mid-prices at 5-minute intervals. All results in this paper are generated using a C++ implementation on the Intel Xeon Phi co-processor which is 11.4x faster than the serial version and a Python strategy backtesting environment both of which are available as open source code written by the authors.", "creator": "LaTeX with hyperref package"}}}