{"id": "1603.09738", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Mar-2016", "title": "Pessimistic Uplift Modeling", "abstract": "uplift modeling is a machine learning technique that aims to model treatment effects heterogeneity. it has been used in business community health environments to predict the effect of a specific earthquake on a given individual. knowing its advantages, uplift models show high sensitivity to noise and disturbance, which leads to unreliable diagnosis. in this setting we outlined different approaches to address the problem of shock modeling, using demonstrate how disturbance in data can affect uplift measurement. we propose a new approach, we call it pessimistic uplift modeling, that minimizes disturbance effects. we mix our approach with the existing uplift methods, on aggregate and autonomous data - sets. the following show that our work outperforms the existing approaches, especially in the case of high noise data collects.", "histories": [["v1", "Thu, 31 Mar 2016 19:48:13 GMT  (562kb,D)", "http://arxiv.org/abs/1603.09738v1", "9 pages"], ["v2", "Wed, 19 Apr 2017 13:53:01 GMT  (0kb,I)", "http://arxiv.org/abs/1603.09738v2", "This paper has been withdrawn by the author(s) for improvement"]], "COMMENTS": "9 pages", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["atef shaar", "talel abdessalem", "olivier segard"], "accepted": false, "id": "1603.09738"}, "pdf": {"name": "1603.09738.pdf", "metadata": {"source": "CRF", "title": "Pessimistic Uplift Modeling", "authors": ["Atef Shaar", "Talel Abdessalem", "Olivier Segard"], "emails": ["atef.shaar@telecom-", "talel.abdessalem@telecom-", "olivier.segard@telecom-", "permissions@acm.org."], "sections": [{"heading": null, "text": "CCS Concepts \u2022Computing methodologies\u2192 Classification and regression trees; \u2022Applied computing \u2192 Marketing; Health informatics; \u2022Mathematics of computing \u2192 Causal networks;\nKeywords Uplift Modeling, Treatment effects heterogeneity, Deferential relational learning, Database Marketing"}, {"heading": "1. INTRODUCTION", "text": "The ambition of gauging the real impact of specific action on human behavior has always been a matter of debate, whether you are in business or in medical sector, the knowledge of how an action influences a desired behavior is good. Of course the possibility to predict a complicated and complex system as human decision system with all the technological advancement we have today is very limited. In the middle of this limitation and complication, uplift modeling appears to be the most reliable modeling technique that is\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. ACM SIGKDD \u201916 August-2016 San Francisco, California USA c\u00a9 2016 ACM. ISBN 123-4567-24-567/08/06. . . $15.00\nDOI: 10.475/123 4\naimed to focus on how an action could alter human decision, and by finding those differences in an action effects, we could apply our method to predict future events.\nMany approaches has been developed to address the problem of uplift, the core concept is to model the variability of a treatment impact over a controlled experiment population or what we call heterogeneous treatment effects. Although most of uplift modeling methods promise to perform well, but only few really do. With many names such as treatment effect heterogeneity, differential response, personalized treatment learning, net lift, true lift and uplift modeling. Most of them are subjective and customized to answer determined question based on research and market objectives. With the lack of a general measurement tool, as we cannot apply and not apply a treatment to an individual, only simulation data seems to give us a workaround to solve this problem. Although successful model in simulation data does not guarantee a success in a real data, but it is the most trustworthy testing measurement for uplift modeling. A success on simulation and real datasets will be a significant indicator of the model performance.\nModeling treatment heterogeneity suffers from high risk of over-fitting, noise modeling, variable correlation and disturbance, it is crucial to address those problem while building an uplift modeling method, Leo Guelman[3] has successfully created two personalized treatment learning approaches that proposed a solution for those problems. Guelman\u2019s approaches is created based on a modified predictive model, but still shows some passive sensibility to high noise data and correlated features.\nthis motivates us to research for a solution that could avoid noise sensibility, offers accurate predictive scores and could be applied using any convenient predictive algorithm. By looking at the problem from another perspective, we focused on building a new method, we call it Reflective Uplift that is less sensitive to the noise in data. we developed a new approach by using the Reflective Uplift as a stabilizer to our Model, in this case we catch more uplift effects inside noisy environment\nIn this paper we will cover the evolution of modeling treatment heterogeneous effects, different types and approaches of uplift modeling, we will discuss its weak points and the attempts that has been made to address those weaknesses. Then we will introduce our new approach, we will demonstrate its advantages over other approaches, and how it will provide a better and more reliable uplift predictions. We will show how our modeling technique outperforms others, specially in noisy data-set using experiments on simulation\nar X\niv :1\n60 3.\n09 73\n8v 1\n[ cs\n.L G\n] 3\n1 M\nar 2\n01 6\nand real word datasets."}, {"heading": "2. RELATED WORK", "text": "Uplift modeling tries to predict the effect of specific action on personal level. Usually two random samples required for uplift modeling, One sample called Treatment Sample, they receive an action, another monitored sample called Control Sample, they don\u2019t receive the action, then an uplift score would be measured by calculating the difference between predicted probabilities of each samples\u2019 predictive model. Most of uplift literature used this method in marketing domain, specifically it has been used to increase the effectiveness of marketing campaigns. An intuitive way for uplift modeling would follow its definition by building two predictive response models, one model would be built based on treatment sample, the second using control sample, then we get predicted uplift by simply subtract the two predicted probabilities.\nUplift = P (R|T, x)\u2212 P (R|C, x)\nUplift models goal is to classify individuals into four quarters(see Figure 1).\nWe can categorize uplift modeling techniques into direct and indirect methods. Direct uplift methods build only one model using the whole population to predict uplift. While indirect uplift methods build two separated models, one for each sample, then calculates uplift score as we mentioned earlier(see Figure2). The first uplift model by Radcliffe et\nal.[15] was a direct model using a modified CART (Classification and Regression Trees)Breiman 1984[2]. Various predictive methods have been used to build uplift models, Logisitc regression [4, 10], Neural Network [12], Decision\nTrees[4, 15, 17, 3], KNN[1, 20] and SVM [6]. Almost all direct uplift methods need to develop a modified version of a predictive model and customize it to predict uplift effects. On the other hand, all indirect models used convenient predictive methods to build uplift models. There is a trade-off between the simplicity in indirect methods and its accuracy. Despite that trade-off, there is one special method proposed by Lai[9], this method has higher predictability score comparing to other indirect method. Lai\u2019s Uplift Method was based on the idea of Positive and Negative Uplift. Lai argued that positive uplift will be inside the diagonal of Treated Respond and Controlled Not Respond, the gray areas in Figure 3. While the negative uplift is in the white area, in Treated Not Respond and Controlled Respond. After that a classifier has to be built to predict the probability of a new case to be in positive uplift.\nLai\u2019s method Uplift = P (TR + CNR)\u2212 P (TNR + CR)\nIn 2014 Kane et. al[8] proofed mathematically that Lai\u2019s uplift method is a special case of more general equation that has been introduced in Kane\u2019s paper, which is Lai\u2019s generalized method.\nLai\u2019s generalized Uplift\n= P (TR)\u2212 P (TNR)\nP (T ) + P (CNR)\u2212 P (CR) P (C)\nUplift models is a classification model, it tends to be very sensitive to noise in data. Indirect methods are more affected by noise[16] than direct methods. Despite its importance for uplift modeling, few have researched how noisy data could affect uplift model performance. In general there are two types of noise in data, Class Noise and Attribute Noise[23]. Class Noise happens because of contradictory and misclassified cases. Contradictory cases, when two different cases has same attributes values, but opposite classes, it is common noise with uplift data-sets, basically because consumer behavior causality chain is much more complicated to be naively characterized by a set of unique features. Misclassified cases, also common with uplift, because in general missing an action is recorded as not an action, It could happen because of monitoring error, sometimes because users have some sort of a technique to prevent monitoring the desired action, in this case even if the individual did an action, a \u201dno action\u201d will be recorded instead. Attribute noise which is more harmful for a classifier performance than class noise[23], happens when there is missing or Incorrect attribute data, it is a major problem for any classifier\nthat deals with personal data, it is related to the individual willingness to share data, this has a huge impact on uplift modeling, sometimes the effect of an action will lead to not sharing the data[11]. An Uplift model performance will be affected also by the correlation between attributes and by the fact that uplift effect of a treatment could be so much weaker than the real treatment effect[3, 21]. Leo Guelman[3] addressed those issues in uplift modeling and created two new uplift models Uplift Random Forests and Causal Conditional Inference Forests. Guelman showed that CCIF method outperformed other uplift methods."}, {"heading": "3. CONTRIBUTION", "text": "We introduce a new method for uplift modeling, reflective uplift , it provides an uplift score that is much less affected by Response Disturbances, it performs very well in supporting convenient uplift modeling technique to create a stable, less sensitive and reliable uplift model.\nAs we mentioned before uplift modeling sensitivity to noise could minimize its importance and reliably. A good uplift method would consider solving those issues. We want to solve uplift model problems using convenient predictive models. Looking as the four classification areas of uplift, we can see that there is two disturbance effect that could increase misclassification error. Main treatment effect or Response effect will be between two groups Responders and Non Responders(see Figure4), this effect happened because people who response usually have similarities, this effect is what a Response model will model. Usually it is much more stronger than the uplift effect. The second disturbance effect will be the Partitioning Effect, this will be between treatment and control areas, theoretically there should be no Partitioning Effect, but it is common to find this effect, mainly because human biased intervention. This effect could be minimized by proper sampling and by applying bagging algorithms.\nResponse effect: horizontal; Partitioning effect: vertical Randomized and proper sampling will minimize partitioning effect.\nA simple example of response disturbance is shown in the table 1, the table include imaginary data for ten clients of email marketing campaign. We have four columns, a binary treatment that indicate whether or not the client receive an email, a binary response and two predictors. If we want building an uplift decision tree and we want to split based (Coupon2) variable, this variable represents whether the client used coupon or not on his last purchase, obviously it will correlate even a little with the response variable. When we split based on Coupon, we will get split\nbased on Response, leading to wrong or disturbed predictions(see Figure 5). This example is an extreme case, usually there is no such a highly correlated variable, there is a set of correlated variables. The fact that responders usually share the same characteristics entails there will be variables that correlate with the response. A response model will use them for scoring, while an uplift model will try to find differences between those variables to differentiate between treatment and control responders. This is why we cannot fix respond disturbance by random sampling as we do with partitioning disturbance, respond disturbance contains an uplift informative values. In general response disturbance variables in data will lead to bias in splitting criteria and to an incorrect prediction score.\nSplit based on respond correlated variable (Coupon).Uplift decision trees that use Uplift as stopping criteria will be the most affected.\nWe favored Lai\u2019s uplift method among others as it is less biased toward disturbances, mainly because of the diagonal partitioning of the population. Lai\u2019s method is simple and\neffective, it can be applied easily using any binary classifier method. Also we found it logical to combine the negative uplift together, because individuals in those areas (TNR and CR) already made their mind Not to do the desired action under their circumstances. This made lai\u2019s method is a very good candidate to predict out basic uplift. We weighted lai\u2019s method by multiplying predicted probabilities by its cases proportions.\nUpliftlai = P (Positive|x)\u2217P ( positive\npopulation )\u2212P (Negative|x)\u2217P ( negative population )\nAlgorithm 1 Lai\u2019s Uplift Model\n1: Partition the population into two classes: 2: Positive Class: TR or CNR => Class = 1 3: Negative Class: TNR or CR => Class = 0 4: Build binary classification model with Class as a target\nvariable\n5: Positive Lift= P (Classpositive|xi) \u2217 positive cases\npopulation\n6: Negative Lift= P (Classnegative|xi) \u2217 negative cases population 7: Upliftlaii = Positife Lift\u2212Negative Lift 8: where xi is a vector of features for individual i\nTR and CNR is Positive; TNR and CR is NegativeNote that lai\u2019s method distribute the disturbance effects on the two partitions, so it minimize some of the disturbance\nby applying on our example data set, we get P (positive|Coupon = Y es) = 0.366, while the uplift score by its definition P (TR|coupon=Y es)\nP (T ) \u2212 P (CR|coupon=Y es) P (C) = 4 4 \u2212\n2 2\n= 0. We need an uplift model that should not affected by response disturbance biased, we need a model that can be used as a stabilizer to reduce disturbance sensitivity. This motivated us to build the reflective uplift model, it is a modified two model approach uplift modeling, it does not predict the probability of a case to respond after treatment, actually reflective uplift answer the question of what is the probability for a specific case to be in treatment area, given it responded. In this way we minimize the effect of respond disturbance. On the other hand we are aware that we maximized the sensitivity to partitioning disturbance, but as we mentioned earlier, portioning sensitivity is biased that can be avoided by proper sampling.\nTo build our reflective uplift model. First we partition the dataset into Respond and Not Respond, then we train a first model to predict the probability Treated Respond in\nResponders group, then we train the second model to predict the probability of Treated Not Respond in Non Responders group. Remember that P (CR|R) = 1\u2212 P (TR|R) and P (CNR|R) = 1 \u2212 P (TNR|R). SO we calculate uplift by subtracting the negative uplift from the positive uplift.\nPReflective(Positive|x) = Pmodel(T |R) \u2217 P (TR) + Pmodel(CNR|NR) \u2217 P (CNR)\nPReflective(Negative|x) = Pmodel(T |NR) \u2217 P (TNR) + Pmodel(C|R) \u2217 P (CR)\nUpliftreflective = PReflective(Positive|x)\u2212 PReflective(Negative|x)\nAlgorithm 2 Reflective Uplift\n1: Partition the Responders into two classes: 2: Treatment Class: TR => Class = 1 3: Control Class: CR => Class = 0 4: Build binary classification model with Class as a target\nvariable 5: M tri = P (Classtreatment|R, xi) 6: Partition the Non Responders into two classes: 7: Treatment Class: TNR => Class = 1 8: Control Class: CNR => Class = 0 9: Build binary classification model with Class as a target\nvariable 10: M tnri = P (Classtreatment|NR, xi) 11: Positive Uplift = M tri \u2217P (TR) + (1\u2212M tnri ) \u2217P (CNR) 12: Negative Uplift = M tnri \u2217P (TNR) + (1\u2212M tri )\u2217P (CR) 13: UpliftReflectivei = Positive Uplift\u2212Negative Uplift 14: where xi is a vector of features for individual i\nIf we apply reflective uplift to predict P (positive|Coupon = Y es), we get Upliftreflective = 0.266, which makes sense, as the number of treated respondents are bigger than the control once. We applied ensemble decision trees methods while building each model to minimized the over-fitting and misclassification error rate, ensemble methods showed great improvement in uplift model performance as Soltys et al. 2014[19] and Leo Guelman[3] demonstrated. We Calculated our final uplift score as followed\nPessimistic Uplift = 1/2 \u2217 (Upliftlaii + UplitReflectivei )\nBy combining Lai\u2019s with Reflected, we got Pessimistic Uplift, an equilibrium predictive model that have precision, robustness and reliability."}, {"heading": "4. EXPERIMENTS", "text": "We followed the steps of Leo Guelman[3] experiments,which is a modified version of Tian et. al experiment framework[21]. We evaluated our method within eight different scenarios, scenarios differs by the factor of strength of the main treatment effect over heterogeneity effect, the correlations between features and the magnitude of noise in the simulated data. Using simulation data for evaluation gave us the advantage of comparing uplift model score with the real personal uplift, this advantage that cannot be found in real data.\nWe benchmark models performance using spearman rank correlation between the real and predicted uplift. We used\nUplift R package, developed by Guelman[3] to produce the simulated data, also we used the same package for applying the CCIF ( Causal Conditional Inference Forests) method, we compared our method to Two Models method (Uplift = P (TR/T )\u2212P (CR/C))[10], generalized Lai\u2019s method, as proposed by Kane et. al[8] and CCIF[3] with its default settings.We used ensemble methods to build all the models but CCIF. It is important to compare with CCIF as CCIF is the most concrete method based on Guelman[3].\nThe first four scenarios has the main effect twice as big as the uplift effect (treatment heterogeneity), while the last four scenarios has the main effect four times bigger than the uplift effect. The correlation among features variates between 0 and 0.5, also the magnitude of noise switch between\u221a\n2 and 2 \u221a\n2 respectively. For more details about the simulation framework, you can check Guelman (2014)[3] and Tian (2014)[21].\nThe training data set contains 200 rows, and 10000 rows for validation dataset. Each dataset contains treatment column and response column, both of them are binary variables. Datasets contains twenty features named X1 to X20, only X1, X2, X3 and X4 has treatment heterogeneity effect. We build our models using Ensemble Regression Trees, one hundred ensemble trees, we included all features in building our models, with a fraction of 80% of training data for learning in each tree model and minimum 20 rows in each node split. We repeat each experiment one hundred times\nfor each scenario. We measure model performance using Spearman\u2019s rank correlation coefficient between the real uplift and the predicted uplift. As shown in the Figure 7 , each box-plot represent the average Spearman\u2019s rank correlation coefficient for that model.\nWe can see how our model almost scores the same as CCIF in the first, second, fifth and sixth,but our model outperforms CCIf in the third, fourth, seventh and eighth scenarios, those scenarios has more correlations between features, with the highest noise , our method performs better.\nWe did experiments on real data sets, the main problem of uplift models is the lack of reliable measurement tool, many measurements have been used, some used Gini and Top 15% Gini [8], others used an extension of Gain Curve, which is Qini Curve and Qini coefficien proposed by Nicholas Radcliffe[14], also Area Under Uplift Curve(AUUC) which is used by [7, 19, 17, 18, 22], some measurement techniques was subjected to the purpose of the uplift model, for example, authors in [16, 9] used net campaign profit to measure the success of am uplift model.\nFor the purpose of uplift model evaluation, we will compare models based on Real Uplift Curve(RUC), precision , and effectiveness. Real Uplift Curve shows the Real uplift of a population after applying the model on it. To draw RUC curve, we sorted our cases based on the modelPredicted Uplift scores, then we binned that data into ten bins with equal frequency, so each bin holds 10% of the data. Then we calculated each bin\u2019s Mean Predicted Uplift and Real uplift, after\nthat we draw the Real Uplift Curve where X axis represents the population and Y axis represents the Real uplift that we can get for each bin using the model.(see Figure15)\nModel precision is measured by doing Spearman\u2019s rank correlation coefficient between Mean Predicted Uplift and Real Uplift (See Table3). Finally we calculate model Effectiveness by summing all real uplift values of bins above the Random Uplift Line(See Table2). Random Uplift Line is a straight line(see Figure15) represents the general uplift score that you will get by randomly sorting the population, it is calculated by uplift definition P (TR|T ) \u2212 P (CR|C) . We used Splice and Breast-Cancer datasets from UCI Machine learning repository. We convert them to binary classification dataset. We followed the same way of binary conversion mentioned in [17, 18, 22, 19]. For Splice dataset, we chose treatment group when (attribute 1) attribute is equal to \u201dA\u201d or \u201dG\u201d, while control group is when (attribute 1) attribute is equal to \u201dT\u201d,\u201dD\u201d or \u201dC\u201d. A positive respond is when Class attribute equal \u201dIE\u201d, and negative respond is when Class attribute equal \u201dN\u201d.\nFor Breast-Cancer dataset, we used (menopause) attribute to partition into treatment and control group, and (Class) attribute as a target variable to predict.\nWe used Hillstrom visit dataset[5], this dataset contains data for an email marketing campaign experiment, it contains 64,000 different customers, spitted into three parts based on the type of email they got, Control Group got no-email, Women\u2019s Group and Men\u2019s Group. We used the\ndataset twice, once comparing Men\u2019s Group with Control, and another comparing Women\u2019s Group with Control.\nWe used Bone Marrow Transplant(BMT ) and Tamoxifen datasets[13], BMT dataset is about patients who got transplant of bone marrow, there is two sources of bone marrow, pelvic bone or peripheral blood. We partition the dataset to treatment and control samples based on the source of bone marrow (pelvic bone as control). BMT has been used twice for experiments, once to predict the occurrence of acute graft versus host disease (agvh), second time to predict the occurrence of chronic graft versus host disease (cgvh). Tamoxifen dataset[13] contains experiment data for treating breast cancer using Tamoxifen, trying to predict if the person is alive or not, we split the dataset into control group, those who received Tamoxifen alone,and treatment group, who received Tamoxifen and Radio Therapy together.\nFrom Our experiments on real datasets, we can see that both methods performed well by predicting uplift effects, Pessimistic Approach was more effective than CCIF, while CCIF shows some more Precision than Pessimistic specially with Hillstrom visit w. dataset.\nFrom Our experiments on real datasets, we can see that both methods performed well by predicting uplift effects, Pessimistic Approach was more effective than CCIF, while CCIF shows some more Precision than Pessimistic specially with Hillstrom visit w. dataset.\nFigure 17: Tamoxifen RUC\nFigure 18: Hillstrom Visit RUC"}, {"heading": "5. CONCLUSION", "text": "Uplift modeling is a technique to predict the influence of a specific action on an individual behavior. There are many approaches to build uplift models, most of them struggle to produce reliable scores in noisy datasets. Most of real world datasets contains noise and disturbances, specially for uplift modeling, as uplift effects tend to be smaller than the real treatment effect. This leads us to introduce our approach which is based on building a stabilizer model that would helps in avoiding results that are based on noise. We compared our approach with other uplift methods, using simulated and real datasets. We used Real Uplift Curves, effectiveness and precession to measure models. Our model shows more stable and effective model than other approaches. More research needed, to extend our method multi-treatment multi-target uplift modeling."}, {"heading": "6. REFERENCES", "text": "[1] F. Alemi, H. Erdman, I. Griva, and C. H. Evans.\nImproved statistical methods are needed to advance personalized medicine. The open translational medicine journal, 1:16, 2009.\n[2] L. Breiman, J. Friedman, C. Stone, and R. Olshen. Classification and Regression Trees. The Wadsworth and Brooks-Cole statistics-probability series. Taylor & Francis, 1984.\n[3] L. Guelman. Optimal personalized treatment learning models with insurance applications. PhD thesis, Universitat de Barcelona, 3 2015.\n[4] B. Hansotia and B. Rukstales. Incremental value modeling. Journal of Interactive Marketing, 16(3):35\u201346, 2002.\n[5] K. Hillstrome. The MineThatData E-Mail Analytics And Data Mining Challenge. http://blog.minethatdata.com/2008/03/ minethatdata-e-mail-analytics-and-data.html, 2008. [Online; accessed 10-Novemebr-2015].\n[6] K. Imai and M. Ratkovic. Estimating treatment effect heterogeneity in randomized program evaluation. Ann. Appl. Stat., 7(1):443\u2013470, 03 2013.\n[7] M. Jaskowski and S. Jaroszewicz. Uplift modeling for clinical trial data. ICML Workshop on Clinical Data Analysis, 2012.\n[8] K. Kane, V. S. Lo, and J. Zheng. True-lift modeling: Comparison of methods. J Market Anal, 2(4):218\u2013238, Dec 2014.\n[9] L. Y.-T. Lai. Influential marketing: a new direct marketing strategy addressing the existence of voluntary buyers. PhD thesis, Citeseer, 2006.\n[10] V. S. Lo. The true lift model: a novel data mining approach to response modeling in database marketing. ACM SIGKDD Explorations Newsletter, 4(2):78\u201386, 2002.\n[11] L. Mamlouk and O. Segard. Big data and intrusiveness: Marketing issues. Indian Journal of Science and Technology, 8(S4):189\u2013193, 2015.\n[12] C. Manahan. A proportional hazards approach to campaign list selection. In Proceedings of the thirtieth annual SAS users group international conference (SUGI), Philadelphia, PA. SAS Institute Inc., 2005.\n[13] M. Pintilie. Competing risks: a practical perspective, volume 58. John Wiley & Sons, 2006.\n[14] N. Radcliffe. Using control groups to target on predicted lift: Building and assessing uplift model. Direct Marketing Analytics Journal, pages 14\u201321, 2007.\n[15] N. Radcliffe and P. Surry. Differential response analysis: Modeling true response by isolating the effect of a single action. Credit Scoring and Credit Control VI. Edinburgh, Scotland, 1999.\n[16] N. J. Radcliffe and P. D. Surry. Real-world uplift modelling with significance-based uplift trees. White Paper TR-2011-1, Stochastic Solutions, 2011.\n[17] P. Rzepakowski and S. Jaroszewicz. Decision trees for uplift modeling. In Data Mining (ICDM), 2010 IEEE 10th International Conference on, pages 441\u2013450. IEEE, 2010.\n[18] P. Rzepakowski and S. Jaroszewicz. Decision trees for uplift modeling with single and multiple treatments. Knowledge and Information Systems, 32(2):303\u2013327, 2012.\n[19] M. SoA\u030aC\u0301tys, S. Jaroszewicz, and P. Rzepakowski. Ensemble methods for uplift modeling. Data Mining and Knowledge Discovery, pages 1\u201329, 2014.\n[20] X. Su, J. Kang, J. Fan, R. A. Levine, and X. Yan. Facilitating score and causal inference trees for large observational studies. The Journal of Machine Learning Research, 13(1):2955\u20132994, 2012.\n[21] L. Tian, A. A. Alizadeh, A. J. Gentles, and R. Tibshirani. A simple method for estimating interactions between a treatment and a large number of covariates. Journal of the American Statistical Association, 109(508):1517\u20131532, 2014.\n[22] L. Zaniewicz and S. Jaroszewicz. Support vector machines for uplift modeling. In Data Mining Workshops (ICDMW), 2013 IEEE 13th International Conference on, pages 131\u2013138, Dec 2013.\n[23] X. Zhu and X. Wu. Class noise vs. attribute noise: A quantitative study. Artificial Intelligence Review, 22(3):177\u2013210."}], "references": [{"title": "Improved statistical methods are needed to advance personalized medicine", "author": ["F. Alemi", "H. Erdman", "I. Griva", "C.H. Evans"], "venue": "The open translational medicine journal,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Classification and Regression Trees. The Wadsworth and Brooks-Cole statistics-probability series", "author": ["L. Breiman", "J. Friedman", "C. Stone", "R. Olshen"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1984}, {"title": "Optimal personalized treatment learning models with insurance applications", "author": ["L. Guelman"], "venue": "PhD thesis, Universitat de Barcelona,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Incremental value modeling", "author": ["B. Hansotia", "B. Rukstales"], "venue": "Journal of Interactive Marketing,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2002}, {"title": "The MineThatData E-Mail Analytics And Data Mining Challenge", "author": ["K. Hillstrome"], "venue": "http://blog.minethatdata.com/2008/03/ minethatdata-e-mail-analytics-and-data.html,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "Estimating treatment effect heterogeneity in randomized program evaluation", "author": ["K. Imai", "M. Ratkovic"], "venue": "Ann. Appl. Stat., 7(1):443\u2013470,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "Uplift modeling for clinical trial data", "author": ["M. Jaskowski", "S. Jaroszewicz"], "venue": "ICML Workshop on Clinical Data Analysis,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "True-lift modeling: Comparison of methods", "author": ["K. Kane", "V.S. Lo", "J. Zheng"], "venue": "J Market Anal,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Influential marketing: a new direct marketing strategy addressing the existence of voluntary buyers", "author": ["L.Y.-T. Lai"], "venue": "PhD thesis, Citeseer,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2006}, {"title": "The true lift model: a novel data mining approach to response modeling in database marketing", "author": ["V.S. Lo"], "venue": "ACM SIGKDD Explorations Newsletter,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2002}, {"title": "Big data and intrusiveness: Marketing issues", "author": ["L. Mamlouk", "O. Segard"], "venue": "Indian Journal of Science and Technology,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "A proportional hazards approach to campaign list selection. In Proceedings of the thirtieth annual SAS users group international conference (SUGI), Philadelphia, PA", "author": ["C. Manahan"], "venue": "SAS Institute Inc.,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2005}, {"title": "Competing risks: a practical perspective, volume 58", "author": ["M. Pintilie"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2006}, {"title": "Using control groups to target on predicted lift: Building and assessing uplift model", "author": ["N. Radcliffe"], "venue": "Direct Marketing Analytics Journal,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "Differential response analysis: Modeling true response by isolating the effect of a single action", "author": ["N. Radcliffe", "P. Surry"], "venue": "Credit Scoring and Credit Control VI. Edinburgh, Scotland,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1999}, {"title": "Real-world uplift modelling with significance-based uplift trees. White Paper TR-2011-1", "author": ["N.J. Radcliffe", "P.D. Surry"], "venue": "Stochastic Solutions,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Decision trees for uplift modeling", "author": ["P. Rzepakowski", "S. Jaroszewicz"], "venue": "In Data Mining (ICDM),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "Decision trees for uplift modeling with single and multiple treatments", "author": ["P. Rzepakowski", "S. Jaroszewicz"], "venue": "Knowledge and Information Systems,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "Ensemble methods for uplift modeling", "author": ["M. So\u00c5\u0106tys", "S. Jaroszewicz", "P. Rzepakowski"], "venue": "Data Mining and Knowledge Discovery,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Facilitating score and causal inference trees for large observational studies", "author": ["X. Su", "J. Kang", "J. Fan", "R.A. Levine", "X. Yan"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}, {"title": "A simple method for estimating interactions between a treatment and a large number of covariates", "author": ["L. Tian", "A.A. Alizadeh", "A.J. Gentles", "R. Tibshirani"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "Support vector machines for uplift modeling", "author": ["L. Zaniewicz", "S. Jaroszewicz"], "venue": "In Data Mining Workshops (ICDMW),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}], "referenceMentions": [{"referenceID": 2, "context": "Modeling treatment heterogeneity suffers from high risk of over-fitting, noise modeling, variable correlation and disturbance, it is crucial to address those problem while building an uplift modeling method, Leo Guelman[3] has successfully created two personalized treatment learning approaches that proposed a solution for those problems.", "startOffset": 219, "endOffset": 222}, {"referenceID": 14, "context": "[15] was a direct model using a modified CART (Classification and Regression Trees)Breiman 1984[2].", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "[15] was a direct model using a modified CART (Classification and Regression Trees)Breiman 1984[2].", "startOffset": 95, "endOffset": 98}, {"referenceID": 3, "context": "Various predictive methods have been used to build uplift models, Logisitc regression [4, 10], Neural Network [12], Decision Trees[4, 15, 17, 3], KNN[1, 20] and SVM [6].", "startOffset": 86, "endOffset": 93}, {"referenceID": 9, "context": "Various predictive methods have been used to build uplift models, Logisitc regression [4, 10], Neural Network [12], Decision Trees[4, 15, 17, 3], KNN[1, 20] and SVM [6].", "startOffset": 86, "endOffset": 93}, {"referenceID": 11, "context": "Various predictive methods have been used to build uplift models, Logisitc regression [4, 10], Neural Network [12], Decision Trees[4, 15, 17, 3], KNN[1, 20] and SVM [6].", "startOffset": 110, "endOffset": 114}, {"referenceID": 3, "context": "Various predictive methods have been used to build uplift models, Logisitc regression [4, 10], Neural Network [12], Decision Trees[4, 15, 17, 3], KNN[1, 20] and SVM [6].", "startOffset": 130, "endOffset": 144}, {"referenceID": 14, "context": "Various predictive methods have been used to build uplift models, Logisitc regression [4, 10], Neural Network [12], Decision Trees[4, 15, 17, 3], KNN[1, 20] and SVM [6].", "startOffset": 130, "endOffset": 144}, {"referenceID": 16, "context": "Various predictive methods have been used to build uplift models, Logisitc regression [4, 10], Neural Network [12], Decision Trees[4, 15, 17, 3], KNN[1, 20] and SVM [6].", "startOffset": 130, "endOffset": 144}, {"referenceID": 2, "context": "Various predictive methods have been used to build uplift models, Logisitc regression [4, 10], Neural Network [12], Decision Trees[4, 15, 17, 3], KNN[1, 20] and SVM [6].", "startOffset": 130, "endOffset": 144}, {"referenceID": 0, "context": "Various predictive methods have been used to build uplift models, Logisitc regression [4, 10], Neural Network [12], Decision Trees[4, 15, 17, 3], KNN[1, 20] and SVM [6].", "startOffset": 149, "endOffset": 156}, {"referenceID": 19, "context": "Various predictive methods have been used to build uplift models, Logisitc regression [4, 10], Neural Network [12], Decision Trees[4, 15, 17, 3], KNN[1, 20] and SVM [6].", "startOffset": 149, "endOffset": 156}, {"referenceID": 5, "context": "Various predictive methods have been used to build uplift models, Logisitc regression [4, 10], Neural Network [12], Decision Trees[4, 15, 17, 3], KNN[1, 20] and SVM [6].", "startOffset": 165, "endOffset": 168}, {"referenceID": 8, "context": "Despite that trade-off, there is one special method proposed by Lai[9], this method has higher predictability score comparing to other indirect method.", "startOffset": 67, "endOffset": 70}, {"referenceID": 7, "context": "al[8] proofed mathematically that Lai\u2019s uplift method is a special case of more general equation that has been introduced in Kane\u2019s paper, which is Lai\u2019s generalized method.", "startOffset": 2, "endOffset": 5}, {"referenceID": 15, "context": "Indirect methods are more affected by noise[16] than direct methods.", "startOffset": 43, "endOffset": 47}, {"referenceID": 10, "context": "that deals with personal data, it is related to the individual willingness to share data, this has a huge impact on uplift modeling, sometimes the effect of an action will lead to not sharing the data[11].", "startOffset": 200, "endOffset": 204}, {"referenceID": 2, "context": "An Uplift model performance will be affected also by the correlation between attributes and by the fact that uplift effect of a treatment could be so much weaker than the real treatment effect[3, 21].", "startOffset": 192, "endOffset": 199}, {"referenceID": 20, "context": "An Uplift model performance will be affected also by the correlation between attributes and by the fact that uplift effect of a treatment could be so much weaker than the real treatment effect[3, 21].", "startOffset": 192, "endOffset": 199}, {"referenceID": 2, "context": "Leo Guelman[3] addressed those issues in uplift modeling and created two new uplift models Uplift Random Forests and Causal Conditional Inference Forests.", "startOffset": 11, "endOffset": 14}, {"referenceID": 18, "context": "2014[19] and Leo Guelman[3] demonstrated.", "startOffset": 4, "endOffset": 8}, {"referenceID": 2, "context": "2014[19] and Leo Guelman[3] demonstrated.", "startOffset": 24, "endOffset": 27}, {"referenceID": 2, "context": "We followed the steps of Leo Guelman[3] experiments,which is a modified version of Tian et.", "startOffset": 36, "endOffset": 39}, {"referenceID": 20, "context": "al experiment framework[21].", "startOffset": 23, "endOffset": 27}, {"referenceID": 2, "context": "Uplift R package, developed by Guelman[3] to produce the simulated data, also we used the same package for applying the CCIF ( Causal Conditional Inference Forests) method, we compared our method to Two Models method (Uplift = P (TR/T )\u2212P (CR/C))[10], generalized Lai\u2019s method, as proposed by Kane et.", "startOffset": 38, "endOffset": 41}, {"referenceID": 9, "context": "Uplift R package, developed by Guelman[3] to produce the simulated data, also we used the same package for applying the CCIF ( Causal Conditional Inference Forests) method, we compared our method to Two Models method (Uplift = P (TR/T )\u2212P (CR/C))[10], generalized Lai\u2019s method, as proposed by Kane et.", "startOffset": 246, "endOffset": 250}, {"referenceID": 7, "context": "al[8] and CCIF[3] with its default settings.", "startOffset": 2, "endOffset": 5}, {"referenceID": 2, "context": "al[8] and CCIF[3] with its default settings.", "startOffset": 14, "endOffset": 17}, {"referenceID": 2, "context": "It is important to compare with CCIF as CCIF is the most concrete method based on Guelman[3].", "startOffset": 89, "endOffset": 92}, {"referenceID": 2, "context": "For more details about the simulation framework, you can check Guelman (2014)[3] and Tian (2014)[21].", "startOffset": 77, "endOffset": 80}, {"referenceID": 20, "context": "For more details about the simulation framework, you can check Guelman (2014)[3] and Tian (2014)[21].", "startOffset": 96, "endOffset": 100}, {"referenceID": 7, "context": "We did experiments on real data sets, the main problem of uplift models is the lack of reliable measurement tool, many measurements have been used, some used Gini and Top 15% Gini [8], others used an extension of Gain Curve, which is Qini Curve and Qini coefficien proposed by Nicholas Radcliffe[14], also Area Under Uplift Curve(AUUC) which is used by [7, 19, 17, 18, 22], some measurement techniques was subjected to the purpose of the uplift model, for example, authors in [16, 9] used net campaign profit to measure the success of am uplift model.", "startOffset": 180, "endOffset": 183}, {"referenceID": 13, "context": "We did experiments on real data sets, the main problem of uplift models is the lack of reliable measurement tool, many measurements have been used, some used Gini and Top 15% Gini [8], others used an extension of Gain Curve, which is Qini Curve and Qini coefficien proposed by Nicholas Radcliffe[14], also Area Under Uplift Curve(AUUC) which is used by [7, 19, 17, 18, 22], some measurement techniques was subjected to the purpose of the uplift model, for example, authors in [16, 9] used net campaign profit to measure the success of am uplift model.", "startOffset": 295, "endOffset": 299}, {"referenceID": 6, "context": "We did experiments on real data sets, the main problem of uplift models is the lack of reliable measurement tool, many measurements have been used, some used Gini and Top 15% Gini [8], others used an extension of Gain Curve, which is Qini Curve and Qini coefficien proposed by Nicholas Radcliffe[14], also Area Under Uplift Curve(AUUC) which is used by [7, 19, 17, 18, 22], some measurement techniques was subjected to the purpose of the uplift model, for example, authors in [16, 9] used net campaign profit to measure the success of am uplift model.", "startOffset": 353, "endOffset": 372}, {"referenceID": 18, "context": "We did experiments on real data sets, the main problem of uplift models is the lack of reliable measurement tool, many measurements have been used, some used Gini and Top 15% Gini [8], others used an extension of Gain Curve, which is Qini Curve and Qini coefficien proposed by Nicholas Radcliffe[14], also Area Under Uplift Curve(AUUC) which is used by [7, 19, 17, 18, 22], some measurement techniques was subjected to the purpose of the uplift model, for example, authors in [16, 9] used net campaign profit to measure the success of am uplift model.", "startOffset": 353, "endOffset": 372}, {"referenceID": 16, "context": "We did experiments on real data sets, the main problem of uplift models is the lack of reliable measurement tool, many measurements have been used, some used Gini and Top 15% Gini [8], others used an extension of Gain Curve, which is Qini Curve and Qini coefficien proposed by Nicholas Radcliffe[14], also Area Under Uplift Curve(AUUC) which is used by [7, 19, 17, 18, 22], some measurement techniques was subjected to the purpose of the uplift model, for example, authors in [16, 9] used net campaign profit to measure the success of am uplift model.", "startOffset": 353, "endOffset": 372}, {"referenceID": 17, "context": "We did experiments on real data sets, the main problem of uplift models is the lack of reliable measurement tool, many measurements have been used, some used Gini and Top 15% Gini [8], others used an extension of Gain Curve, which is Qini Curve and Qini coefficien proposed by Nicholas Radcliffe[14], also Area Under Uplift Curve(AUUC) which is used by [7, 19, 17, 18, 22], some measurement techniques was subjected to the purpose of the uplift model, for example, authors in [16, 9] used net campaign profit to measure the success of am uplift model.", "startOffset": 353, "endOffset": 372}, {"referenceID": 21, "context": "We did experiments on real data sets, the main problem of uplift models is the lack of reliable measurement tool, many measurements have been used, some used Gini and Top 15% Gini [8], others used an extension of Gain Curve, which is Qini Curve and Qini coefficien proposed by Nicholas Radcliffe[14], also Area Under Uplift Curve(AUUC) which is used by [7, 19, 17, 18, 22], some measurement techniques was subjected to the purpose of the uplift model, for example, authors in [16, 9] used net campaign profit to measure the success of am uplift model.", "startOffset": 353, "endOffset": 372}, {"referenceID": 15, "context": "We did experiments on real data sets, the main problem of uplift models is the lack of reliable measurement tool, many measurements have been used, some used Gini and Top 15% Gini [8], others used an extension of Gain Curve, which is Qini Curve and Qini coefficien proposed by Nicholas Radcliffe[14], also Area Under Uplift Curve(AUUC) which is used by [7, 19, 17, 18, 22], some measurement techniques was subjected to the purpose of the uplift model, for example, authors in [16, 9] used net campaign profit to measure the success of am uplift model.", "startOffset": 476, "endOffset": 483}, {"referenceID": 8, "context": "We did experiments on real data sets, the main problem of uplift models is the lack of reliable measurement tool, many measurements have been used, some used Gini and Top 15% Gini [8], others used an extension of Gain Curve, which is Qini Curve and Qini coefficien proposed by Nicholas Radcliffe[14], also Area Under Uplift Curve(AUUC) which is used by [7, 19, 17, 18, 22], some measurement techniques was subjected to the purpose of the uplift model, for example, authors in [16, 9] used net campaign profit to measure the success of am uplift model.", "startOffset": 476, "endOffset": 483}, {"referenceID": 16, "context": "We followed the same way of binary conversion mentioned in [17, 18, 22, 19].", "startOffset": 59, "endOffset": 75}, {"referenceID": 17, "context": "We followed the same way of binary conversion mentioned in [17, 18, 22, 19].", "startOffset": 59, "endOffset": 75}, {"referenceID": 21, "context": "We followed the same way of binary conversion mentioned in [17, 18, 22, 19].", "startOffset": 59, "endOffset": 75}, {"referenceID": 18, "context": "We followed the same way of binary conversion mentioned in [17, 18, 22, 19].", "startOffset": 59, "endOffset": 75}, {"referenceID": 4, "context": "We used Hillstrom visit dataset[5], this dataset contains data for an email marketing campaign experiment, it contains 64,000 different customers, spitted into three parts based on the type of email they got, Control Group got no-email, Women\u2019s Group and Men\u2019s Group.", "startOffset": 31, "endOffset": 34}, {"referenceID": 12, "context": "We used Bone Marrow Transplant(BMT ) and Tamoxifen datasets[13], BMT dataset is about patients who got transplant of bone marrow, there is two sources of bone marrow, pelvic bone or peripheral blood.", "startOffset": 59, "endOffset": 63}, {"referenceID": 12, "context": "Tamoxifen dataset[13] contains experiment data for treating breast cancer using Tamoxifen, trying to predict if the person is alive or not, we split the dataset into control group, those who received Tamoxifen alone,and treatment group, who received Tamoxifen and Radio Therapy together.", "startOffset": 17, "endOffset": 21}], "year": 2016, "abstractText": "Uplift modeling is a machine learning technique that aims to model treatment effects heterogeneity. It has been used in business and health sectors to predict the effect of a specific action on a given individual. Despite its advantages, uplift models show high sensitivity to noise and disturbance, which leads to unreliable results. In this paper we show different approaches to address the problem of uplift modeling, we demonstrate how disturbance in data can affect uplift measurement. We propose a new approach, we call it Pessimistic Uplift Modeling, that minimizes disturbance effects. We compared our approach with the existing uplift methods, on simulated and real datasets. The experiments show that our approach outperforms the existing approaches, especially in the case of high noise data environment.", "creator": "LaTeX with hyperref package"}}}