{"id": "1605.04614", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-May-2016", "title": "DeepLearningKit - an GPU Optimized Deep Learning Framework for Apple's iOS, OS X and tvOS developed in Metal and Swift", "abstract": "in this paper we announce deeplearningkit - an open source framework that supports using adobe deep learning apps ( convolutional neural networks ) for ios, os x and tvos. deeplearningkit is developed in metal in belgium to utilize legacy gpu efficiently and swift for integration with applications, e. g. custom - styled mobile apps on iphone / ipad, tvos - based browser for the big screen,. os x desktop applications. the results point to communicate using deep learning models trained with popular frameworks such as caffe, torch, eucalyptus, theano, pylearn, deeplearning4j - mocha. given the massive gpu resources and time required would train deep learning models we suggest an app store like model to distribute automatically download pretrained and reusable deep reading models.", "histories": [["v1", "Sun, 15 May 2016 23:19:48 GMT  (3390kb,D)", "http://arxiv.org/abs/1605.04614v1", "9 pages, 12 figures, open source documentation and code at deeplearningkit.org and github.com/deeplearningkit"]], "COMMENTS": "9 pages, 12 figures, open source documentation and code at deeplearningkit.org and github.com/deeplearningkit", "reviews": [], "SUBJECTS": "cs.LG cs.DC cs.NE", "authors": ["amund tveit", "torbj{\\o}rn morland", "thomas brox r{\\o}st"], "accepted": false, "id": "1605.04614"}, "pdf": {"name": "1605.04614.pdf", "metadata": {"source": "CRF", "title": "DeepLearningKit - an GPU Optimized Deep Learning Framework for Apple\u2019s iOS, OS X and tvOS developed in Metal and Swift", "authors": ["Amund Tveit", "Torbj\u00f8rn Morland"], "emails": ["opensource@deeplearningkit.org"], "sections": [{"heading": "1 GPU Accelerated Deep Learning Library", "text": "The Metal programming language is most the efficient way of utilizing the GPU on Apple\u2019s iOS since 2014 [1, 2, 3, 4] and OSX since 2015 [5, 6, 7]. This paper gives a brief overview of a Metal and Swift based Deep Learning library named DeepLearningKit, in particular parts of Metal convolutional neural network operators for the GPU. DeepLearningKit supports on-device Deep Learning on Apple\u2019s iOS, OS X and tvOS.\nDeepLearningKit currently has shader functions for convolutional neural networks implemented in Metal and parallelized for the GPU, operators include: convolution, pooling, rectifier layer and softmax. In terms of deep learning model supported it has support for Min Lin\u2019s Caffe-trained Network In Network[8] (NIN - trained on CIFAR-10, CIFAR-100 and ImageNet data sets). We also have preliminary support running Theano[9] trained LeNet (trained on MNIST digit classification dataset). The reason we have chosen NIN is that the network is small compared to other deep convolutional neural networks, but at the same time provide very high classification accuracy on images, e.g. better than AlexNet. GoogleLeNet (winner of Imagenet 2014) uses a similar approach as NIN[?]. NIN can perhaps also be used in non-image domains, e.g speech recognition[10] or natural language processing[11]. In particular one could attempt to adapt Zhang and Lecun\u2019s encoding and 1D convolutional operators in \u201cText Understanding from Scratch\u201d[12] and use it with NIN."}, {"heading": "1.1 Experiences with PowerVR G6430/GT7600 on iPhone 5S/6S", "text": "The performance of DeepLearningKit Deep Learning going from iPhone 5S (with PowerVR G6430 according to The iPhone 5S Review (AnandTech)) to iPhone 6S (with PowerVR GT7600 according to Apple iPhone 6S Plus vs. Samsung Galaxy S6 Edge+) we got 1 order of magnitude in improved performance. Calculation time to run through a 20 layer deep convolutional neural network model\n\u2217http://DeepLearningKit.org\nar X\niv :1\n60 5.\n04 61\n4v 1\n[ cs\n.L G\n] 1\n5 M\nfor image recognition went from approximately 2 seconds to less than 100 milliseconds. The network we we used was NIN network trained on CIFAR-10. Based on XCode profiling we suspect that the Metal compute drivers for the GPU weren\u2019t fine tuned, so with lower level tools (e.g. for OpenCL/Vulkan SPIR-V) for tuning for the GPU we could probably improve performance quite a bit.\n(Note that 100 milliseconds or in other words 0.1 seconds is what Jacob Nielsen stated is one of 3 important response times that a user feels a system reacts instantenously)"}, {"heading": "1.2 Effort needed to port from Metal/Swift to OpenCL/Vulkan Compute SPIR-V", "text": "Code needed to set up and run deep learning on the GPU, load/save data, and setup the deep learning pipeline (convolutional neural network)is done is done in Swift (for easy app integration on iOS, OS X and tvOS), but can be moved to a language of selection (e.g. Java on Android or C++/C on other devices). The Swift API for setting up Metal resembles the corresponding OpenCL C API as shown in Figure 2.\nThe Deep Learning GPU code (e.g. shader functions with calculations of convolution etc) is written in Metal, a language that is a subset C++-11 and also has its own (relatively few) additions compared to C++11. Porting the Metal code GPU code to OpenCL should be relatively straight forward since OpenCL is also a subset of C++, as an example see figures 3 and 4 for a rectifier function written in both Metal and OpenCL. Going from OpenCL to Vulkan SPIR-V can be done with compiler (figure 5) for further profiling and optimization.\nThe threading model supported by Vulkan is 1-1 with what is developed in DeepLearningKit with Metal (figure 6), so that should not be an issue (The equivalent classes to what Vulkan has in the figure in Metal is from left to right MTLCommandBuffer, MTLCommandQueue and MTLDevice)"}, {"heading": "1.3 Roadmap for Deep Learning for OpenCL/Vulkan (or Metal)", "text": "Here follows a brief overview of things we are working on or is on our roadmap.\n1. use FFT-based convolution - with precalculated convolution filters [13, 14]\n2. use lower resolution on floating point - in order to increase performance and support larger models (for now it uses 32 bit float or complex numbers - i.e. 2x32 bit per complex number to prepare for FFT-based convolution) [15, 16]\n3. avoid copying memory between CPU and GPU more than needed [17]\n4. add support for other types of pre-trained networks than deep convolutional neural networks, e.g. recurring neural networks[18, 19]\n5. look into more in-place calculations to save memory, i.e. supporting larger models\n6. try to exploit larger parts of Metal API wrt memory layout, threadgroups to increase performance (this relates to 1.) [20, 21, 22, 23, 24]\n7. Look into teacher-student deep networks or other compressed models for even smaller but still high quality models (recent research have shown AlexNet models being compressed from 240MB to 6.9MB), see the paper [A Deep Neural Network Compression Pipeline]\n8. Look into algorithms for approximate matrix multiplication (i.e. convolution step speedup) to further increase speed (and reduce energy usage), interesting techniques include a) [Approximating matrix multiplication and low-rank approximation], [Fast Approximate Matrix Multiplication by Solving Linear Systems] and [Fast Monte-Carlo Algorithms for Approximate Matrix Multiplications].\n9. Look into a broad set of Deep Learning applications, e.g. categories in figures 7, 8 and 9 from DeepLearningKit\u2019s research bibliography at [http://Deeplearning.University]. It might be application specific optimizations that can be done, e.g. in the case of natural language processing with convolutional neural networks one uses 1D convolution instead of 2D (as in image classification)."}, {"heading": "2 App Store for Deep Learning Models", "text": "Given the immense asymmetry in time taken to train a Deep Learning Model versus time needed to use it (e.g. to do image recognition), it makes perfect sense to build a large repository of pre-trained models that can be (re)used several times. Since there are several popular tools used to train Deep Learning models (e.g. Caffe, Torch, Theano, DeepLearning4J, PyLearn and Nervana) were working on supporting importing pre-trained models in those tools into an app store for deep learning models (currently weve been primarily been working with Caffe CNN models).\nThe tweet in Figure 10 illustrates how much energy is required to train a Deep Network (per night), some Deep Learning Models can take weeks of training on GPUs like the Nvidia TitanX, or in other words piles of wood of energy. Using a model is quite different since it requires less energy than lighting match. See figures 11 and 12 for an illustration of this.\nDeep Learning Models also typically have a (low) limit in the number of classes they can predict per model (e.g. in the ImageNet competition there are 1000 classes, CIFAR-100 100 classes and CIFAR10 10 classes). This means that in order to create real-life applications one need to intelligently (and very rapid load them from SSD into GPU accessible RAM) switch between several Deep Learning Models, or if there is enough capacity one can run several models in parallel on the same GPU. Selecting an approriate Deep Learning model (i.e. which is the most likely to work well in a given context) is to our knowledge not a well-studied field of research, and in some ways it resembles the meta or universal search problem found in web search (e.g. cross-model ranking), but latency plays an even bigger part in the mobile on-device case (dont have time to run many models). We have some ideas for a meta model for selecting a model to use, which can use input like location, time of day, and camera history to predict which models might be most relevant.\nWith state-of-the-art compression techniques for Convolutional Neural Network the (groundbreaking) AlexNet model from 2012 can be compressed from 240MB to 6.9MB. This means that one could theoretically fit more than eighteen thousand AlexNet models on a 128 GB mobile device like the iPhone 6!"}, {"heading": "3 Deep Learning Model Importer", "text": "Importing Deep Learning models into the model app store requires supporting the main Deep Learning tools. The most used ones in research are Torch and Caffe, and DeepLearningKit currently sup-\nports converting trained Caffe models to JSON (i.e. ready to be uploaded to app store) and then importing into Swift/Metal (or OpenCL/Vulkan with porting) for the mobile app. Making support for importing convolutional neural network from other tools might require getting intimate insight into the tools, but since convolutional neural networks are quite similar of nature the complexity and effort for creating importers is not horrific. Proposing and supporting standards - e.g. for\n1. deep learning network description (i.e input to training stage) 2. input data formats (images, text, etc input to training stage) 3. trained networks (i.e. input to DeepLearningKit deep learning)\nmight be a longer term goal since this will make it easier to use pretrained models with OpenCL/Vulkan no matter which tool they are created in."}, {"heading": "4 Conclusion", "text": "Have done a presentation of DeepLearningKit GPU accelerated Deep Learning for Metal/Swift and presented directions for how it can be ported/adapted to OpenCL/Vulkan SPIR-V."}], "references": [{"title": "Working with Metal - Overview", "author": ["Jeremy Sandmel"], "venue": "Apple WWDC, published online - https: //developer.apple.com/videos/wwdc/2014/,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Working with Metal - Fundamentals", "author": ["Richard Schreyer", "Aaftab Munshi"], "venue": "Apple WWDC, published online - https://developer.apple.com/videos/wwdc/2014/,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Working with Metal - Advanced", "author": ["Gokhan Avkarogullari", "Aaftab Munshi", "Serhat Tekin"], "venue": "Apple WWDC, published online - https://developer.apple.com/videos/wwdc/2014/,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "GPGPU Performance of Swift/Metal vs Accelerate on iPhone 6/5S, iPad Air and iPad Mini", "author": ["Amund Tveit"], "venue": "Memkite, published online http://memkite.com/blog/2014/12/18/ gpgpu-performance-of-swiftmetal-vs-accelerate-on-iphone-6-5s-ipad-air-and-ipad-mini/,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "What\u2019s New in Metal, Part 1. Apple WWDC, published online - https://developer", "author": ["Rav Dhiraj"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "What\u2019s New in Metal", "author": ["Dan Omachi", "Anna Tikhonova"], "venue": "Part 2. Apple WWDC, published online https://developer.apple.com/videos/wwdc/2015/,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Theano: a CPU and GPU math expression compiler", "author": ["James Bergstra", "Olivier Breuleux", "Fr\u00e9d\u00e9ric Bastien", "Pascal Lamblin", "Razvan Pascanu", "Guillaume Desjardins", "Joseph Turian", "David Warde-Farley", "Yoshua Bengio"], "venue": "In Proceedings of the Python for Scientific Computing Conference (SciPy),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "Deep Learning for Speech Recognition. published online http://memkite.com/ blog/2015/02/11/deep-learning-for-speech-recognition", "author": ["Amund Tveit"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "Deep Learning for Natural Language Processing. published online http://memkite", "author": ["Amund Tveit"], "venue": "com/blog/2015/01/29/deep-learning-for-natural-language-processing/,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Fast convolutional nets with fbfft: A GPU performance evaluation", "author": ["Nicolas Vasilache", "Jeff Johnson", "Micha\u00ebl Mathieu", "Soumith Chintala", "Serkan Piantino", "Yann LeCun"], "venue": "CoRR, abs/1412.7580,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Deep learning with limited numerical precision", "author": ["Suyog Gupta", "Ankur Agrawal", "Kailash Gopalakrishnan", "Pritish Narayanan"], "venue": "CoRR, abs/1502.02551,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Why are Eight Bits Enough for Deep Neural Networks?  published online http://petewarden.com/2015/05/23/ why-are-eight-bits-enough-for-deep-neural-networks", "author": ["Pete Warden"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Example of Sharing Memory Between GPU and CPU with Swift and Metal for iOS8", "author": ["Amund Tveit"], "venue": "Memkite, published online http://memkite.com/blog/2014/12/30/ example-of-sharing-memory-between-gpu-and-cpu-with-swift-and-metal-for-ios8,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "Deeplearning.University - Bibliographies from Lisa Labs (Yoshua Bengio\u2019s Lab).  published online http://memkite.com/blog/2015/04/17/ deeplearning-university-bibliographies-from-lisa-labs-yoshua-bengios-lab", "author": ["Amund Tveit"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "The Metal programming language is most the efficient way of utilizing the GPU on Apple\u2019s iOS since 2014 [1, 2, 3, 4] and OSX since 2015 [5, 6, 7].", "startOffset": 104, "endOffset": 116}, {"referenceID": 1, "context": "The Metal programming language is most the efficient way of utilizing the GPU on Apple\u2019s iOS since 2014 [1, 2, 3, 4] and OSX since 2015 [5, 6, 7].", "startOffset": 104, "endOffset": 116}, {"referenceID": 2, "context": "The Metal programming language is most the efficient way of utilizing the GPU on Apple\u2019s iOS since 2014 [1, 2, 3, 4] and OSX since 2015 [5, 6, 7].", "startOffset": 104, "endOffset": 116}, {"referenceID": 3, "context": "The Metal programming language is most the efficient way of utilizing the GPU on Apple\u2019s iOS since 2014 [1, 2, 3, 4] and OSX since 2015 [5, 6, 7].", "startOffset": 104, "endOffset": 116}, {"referenceID": 4, "context": "The Metal programming language is most the efficient way of utilizing the GPU on Apple\u2019s iOS since 2014 [1, 2, 3, 4] and OSX since 2015 [5, 6, 7].", "startOffset": 136, "endOffset": 145}, {"referenceID": 5, "context": "The Metal programming language is most the efficient way of utilizing the GPU on Apple\u2019s iOS since 2014 [1, 2, 3, 4] and OSX since 2015 [5, 6, 7].", "startOffset": 136, "endOffset": 145}, {"referenceID": 6, "context": "We also have preliminary support running Theano[9] trained LeNet (trained on MNIST digit classification dataset).", "startOffset": 47, "endOffset": 50}, {"referenceID": 7, "context": "g speech recognition[10] or natural language processing[11].", "startOffset": 20, "endOffset": 24}, {"referenceID": 8, "context": "g speech recognition[10] or natural language processing[11].", "startOffset": 55, "endOffset": 59}, {"referenceID": 9, "context": "use FFT-based convolution - with precalculated convolution filters [13, 14]", "startOffset": 67, "endOffset": 75}, {"referenceID": 10, "context": "2x32 bit per complex number to prepare for FFT-based convolution) [15, 16] 3.", "startOffset": 66, "endOffset": 74}, {"referenceID": 11, "context": "2x32 bit per complex number to prepare for FFT-based convolution) [15, 16] 3.", "startOffset": 66, "endOffset": 74}, {"referenceID": 12, "context": "avoid copying memory between CPU and GPU more than needed [17] 4.", "startOffset": 58, "endOffset": 62}, {"referenceID": 13, "context": "recurring neural networks[18, 19] 5.", "startOffset": 25, "endOffset": 33}], "year": 2016, "abstractText": "In this paper we present DeepLearningKit an open source framework that supports using pretrained deep learning models (convolutional neural networks) for iOS, OS X and tvOS. DeepLearningKit is developed in Metal in order to utilize the GPU efficiently and Swift for integration with applications, e.g. iOS-based mobile apps on iPhone/iPad, tvOS-based apps for the big screen, or OS X desktop applications. The goal is to support using deep learning models trained with popular frameworks such as Caffe, Torch, TensorFlow, Theano, Pylearn, Deeplearning4J and Mocha. Given the massive GPU resources and time required to train Deep Learning models we suggest an App Store like model to distribute and download pretrained and reusable Deep Learning models. 1 GPU Accelerated Deep Learning Library The Metal programming language is most the efficient way of utilizing the GPU on Apple\u2019s iOS since 2014 [1, 2, 3, 4] and OSX since 2015 [5, 6, 7]. This paper gives a brief overview of a Metal and Swift based Deep Learning library named DeepLearningKit, in particular parts of Metal convolutional neural network operators for the GPU. DeepLearningKit supports on-device Deep Learning on Apple\u2019s iOS, OS X and tvOS. DeepLearningKit currently has shader functions for convolutional neural networks implemented in Metal and parallelized for the GPU, operators include: convolution, pooling, rectifier layer and softmax. In terms of deep learning model supported it has support for Min Lin\u2019s Caffe-trained Network In Network[8] (NIN trained on CIFAR-10, CIFAR-100 and ImageNet data sets). We also have preliminary support running Theano[9] trained LeNet (trained on MNIST digit classification dataset). The reason we have chosen NIN is that the network is small compared to other deep convolutional neural networks, but at the same time provide very high classification accuracy on images, e.g. better than AlexNet. GoogleLeNet (winner of Imagenet 2014) uses a similar approach as NIN[?]. NIN can perhaps also be used in non-image domains, e.g speech recognition[10] or natural language processing[11]. In particular one could attempt to adapt Zhang and Lecun\u2019s encoding and 1D convolutional operators in \u201cText Understanding from Scratch\u201d[12] and use it with NIN. 1.1 Experiences with PowerVR G6430/GT7600 on iPhone 5S/6S The performance of DeepLearningKit Deep Learning going from iPhone 5S (with PowerVR G6430 according to The iPhone 5S Review (AnandTech)) to iPhone 6S (with PowerVR GT7600 according to Apple iPhone 6S Plus vs. Samsung Galaxy S6 Edge+) we got 1 order of magnitude in improved performance. Calculation time to run through a 20 layer deep convolutional neural network model \u2217http://DeepLearningKit.org 1 ar X iv :1 60 5. 04 61 4v 1 [ cs .L G ] 1 5 M ay 2 01 6", "creator": "LaTeX with hyperref package"}}}