{"id": "1605.05368", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-May-2016", "title": "Deep Action Sequence Learning for Causal Shape Transformation", "abstract": "deep learning ( dl ) became the method of choice in recent years performing various problems ranging from audio representation and speech recognition to robotic perception upon human disease prediction. unlike such paper, we present a hybrid architecture of convolutional neural nodes ( cnn ) and stacked autoencoders ( sae ) to learn a sequence of actions that visually transforms an input quantity dependent distribution into a target shape or distribution with the same support. while such a framework can be specified in a variety of problems such as reverse path planning, sequential decision - making in games and identifying material processing pathways to achieve natural microstructures, this paper focuses on controlling fluid deformations in a microfluidic channel by deliberately placing a sequence of pillars, which has a significant impact on downstream. biomedical designer textile applications where highly targeted shapes produce desired. we propose an architecture describing simultaneously predicts the intermediate curves lying in the nonlinear transformation pathway between the undeformed and desired flow shape, then learns the causal action - - called single pillar which results in the deformation slowing the flow - - one at a second. the learning of stage - wise transformations provides deep insights into the physical flow deformation. results show that under the current framework, our model is able to predict a sequence as pillars that maintains the flow position which highly resembles the desired shape.", "histories": [["v1", "Tue, 17 May 2016 21:07:18 GMT  (1072kb)", "http://arxiv.org/abs/1605.05368v1", null], ["v2", "Fri, 20 May 2016 02:01:37 GMT  (1071kb)", "http://arxiv.org/abs/1605.05368v2", "Submitted to NIPS2016. Differences: All vspaces removed and all figures in full size"], ["v3", "Tue, 8 Nov 2016 20:48:47 GMT  (1459kb)", "http://arxiv.org/abs/1605.05368v3", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CV cs.NE", "authors": ["kin gwn lore", "daniel stoecklein", "michael davies", "baskar ganapathysubramanian", "soumik sarkar"], "accepted": false, "id": "1605.05368"}, "pdf": {"name": "1605.05368.pdf", "metadata": {"source": "CRF", "title": "Deep Action Sequence Learning for Causal Shape Transformation", "authors": ["Kin Gwn Lore"], "emails": ["kglore@iastate.edu", "stoeckd@iastate.edu", "mdavies@iastate.edu", "baskarg@iastate.edu", "soumiks@iastate.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 5.\n05 36"}, {"heading": "1 Introduction", "text": "Hierarchical feature extraction using deep neural networks has been very successful in accomplishing various tasks such as objection recognition [1], speech recognition [2], scene understand-\nDepartment of Mechanical Engineering, Iowa State University. 2016.\ning [3, 4], multi-modal sensor fusion [5], prognostics [6], engineering design [7] and policy reward learning [8]. In addition, the field of biology has taken a huge interest in using deep learning (DL) methods for relating DNA variants to diseases [9] and detecting mitosis from cancer histology images [10]. This paper proposes a novel application of deep learning by fusing multiple architectures in solving design engineering problems, which has a great potential in accelerating the development of various fields such as manufacturing, chemical engineering, and biology.\nThe ability to control shape and location of fluid streams allows the capability of creating structured materials, preparing biological samples, and engineering heat and mass transport by ordering and structuring streams with precise sequences of fluid perturbations. Using microchannels populated with a set of pillars, the pillars can individually deform a flow to achieve the final desired shape [11]. Pre-computed deformations from individual pillars have been experimentally validated and enabled rapid simulation of an arbitrary microfluidic device in the order of seconds. Therefore, this mathematical operation (referred to as the forward problem) can elegantly yield the final flow shape for an arbitrary sequence without additional numerical simulation.\nHowever, practical applications require solving the inverse problem, that is, to generate a sequence of pillars given a user-defined flow shape. Without intelligent computer algorithms, such tasks require time-consuming trial and error design iterations. The automated determination of pillar sequences that yields a custom shape is a significant and impactful advance. Although works have been done to frame this inverse problem as an unconstrained optimization problem [12], they are invariable time-consuming. While many methods are used to solve the forward problem [13\u201316], only a limited amount of effort has been done in solving the inverse problem [7]. For practical and time-efficient applications, deep learning methods are explored to map user-defined flow shapes and the corresponding pillars of sequence.\nIn this paper, we propose a deep learning architecture which simultaneously predicts the intermediate shape between the two images and learns the causal action, i.e. by attributing the transformation to the identity of a pillar which results in a specific deformation of the flow as a classification problem. In fact, the proposed architecture is not limited to solve only the flow problem; as a general framework it can be easily modified for other applications such as (1) learning to transform the belief space for robotic path planning, (2) learning the material processing pathways to obtain desired microstructures, and (3) learning a sequence of manufacturing steps in additive manufacturing, with fast-design being the main advantage. Recurrent neural network (RNN)-like architectures [17] are deemed unsuitable because the elements in the output vector are generally independent of each other, unlike words in a sentence. A related concept is the spatial transformer network [18] where the localization network outputs geometrical transformation parameters; however we desire an exact class attributed to an arbitrary transformation function. Authors in [7] predicted the sequence of pillars which deforms into the target flow shape in a joint manner, although the resultant sequence is constrained in length and do not provide sufficient insight on the interplay between pillars causing the deformation. In this work, we predict the pillar sequence one pillar at a time, where the produced sequences are able to result in flow shape deformations which highly resemble the desired shape. The major contributions of the paper are outlined below:\n1. An integrated hierachical feature extraction approach using deep autoencoders (DAE) [19] with convolutional neural networks (CNN) [20] is proposed to capture multi-scale patterns of a deformed fluid flow to generate the associated sequence resulting in the deformation.\n2. The proposed approach is tested and validated via numerical simulations, with results showing competitive prediction accuracy over previously explored methods.\nCollaborators intend to utilize this framework for concrete biomedical applications that require the design of microfluidic devices. Possible applications include: (a) designing a device to move fluid surrounding cells (e.g. lymphoid leukemia cells) against a far wall of the microfluidic channel where it can be collected at high purity while the cells are maintained at the channel center. High purity allows the reuse of valuable reagents for staining cells during diagnosis, (b) wrapping a fluid around the microchannel surface to characterize binding p24 (an HIV viral capsid protein) to antip24 antibody immobilized on the microchannel surface. Flow sculpting can enhance reaction of low abundance proteins that can improve diagnostic limits of detection for various diseases. Hence, this study may promise new application areas for the machine learning community related to thermofluid sciences and design engineering."}, {"heading": "2 Problem setup", "text": "In this section we describe the problem setup, previous works, and our proposed architecture in addressing the inverse design problem."}, {"heading": "2.1 Flow sculpting", "text": "The shape of a fluid flow can be controlled by deliberately introducing obstacles inside the fluid channel in the form of micropillars, where pillar arrangement in a sequence will progressively contribute to the deformation of the flow shape (see Fig. 1). We are interested in the inverse problem\u2013 to predict the configurations of the pillars given a desired flow shape. To approach this problem, class indices are assigned to pillars with different specifications. For instance, a pillar located at position 0.0 with a diameter of 0.375 will be assigned an index of 1, whereas another pillar at position 0.125 and diameter 0.375 will be assigned an index of 2. Diameter and position values are represented as ratios with respect to the channel size and locations, so they are dimensionless quantities to help enabling the scalability of the fluid channel. Index assignment is performed over a finite combination of pillar positions and diameters that has been obtained by discretizing the design space. In the study, there are 32 possible indices (or classes) that describe the diameter and position of a single pillar."}, {"heading": "2.2 Simultaneous multi-class classification (SMC)", "text": "Simultaneous multi-class classification is a method proposed in [7] to solve a similar problem. Instead of solving a single classification problem, the model solves a sub-problem for each pillar based using the parameters learned by the CNN. This formulation requires a slight modification in the loss function: for pillar sequence with length np, the loss function to be minimized for a data set D is the negative log-likelihood defined as:\n\u2113total(\u03b8 = {W, b},D) = \u2212\nnp \u2211\nj=1\n|D| \u2211\ni=0\n[ log ( P (Y = y(i)|x(i),W, b) )]\nj\nwhere D denotes the training set, \u03b8 is the model parameters with W as the weights and b for the biases. y is predicted pillar index whereas x is the provided flow shape image. The total loss is computed by summing the individual losses for each pillar. While this method is capable of predicting a large number of different sequences in a total time of just seconds, the drawback is that the sequence length is constrained; a new model needs to be trained to generate a sequence with different lengths."}, {"heading": "2.3 Pillar prediction network (PPN)", "text": "To predict the sequence of pillars that results in the desired flow shape, this paper introduces the notion of transformation learning. Fig. 3 shows the learning approach by supplying juxtaposed flow shapes, one before deformation, and one after, into a CNN that extracts relevant features and predicts the class of the pillar causing the deformation. In the training data generation procedure, the input is comprised of three parts: (a) the pre-deformed flow shape, which is produced from a randomly generated sequence of varying length with values up to the number of classes of a single pillar; (b) a padding to prevent the convolutional kernels to pick up interfering features from the juxtaposed\nimages; and (c) the post-deformed shape produced from adding a random pillar index to the previous sequence. This newly-added pillar index will become the label to train the CNN. Essentially, the pillar prediction network, as the name suggests, predicts the index of the pillar (which describes its position and diameter in the flow channel) given a pre- and post-deformed shape.\nWhen actually inferencing, the right portion (part c) of the input image is replaced by the final target shape. The input image is fed into the CNN to obtain a pillar index, which is added to an initially empty pillar sequence. Because the forward model (i.e. going from sequence to flow shape) is not at all computationally expensive and takes merely milliseconds, this pillar sequence is used to regenerate the current shape which replaces the left portion (part a) of the input, while the right portion (part c, the target) remains the unchanged. The input enters the CNN again to obtain a second pillar index, and is subsequently added to the previously obtained pillar sequence. At this point, we have a sequence of length 2, where the sequence will then again used to regenerate a new current shape. The process is repeated until the current shape matches the target shape, until a user-defined stopping criterion is met.\nHowever, this method only works well for simpler target shapes. For more complex flow shapes (e.g. shapes with many sharp angles, jagged edges, swirls and curls; see Fig. 8 sample 20A for example), the transformation path may be highly nonlinear\u2013 the current shape may never converge to the final desired shape. Furthermore, the training data covers a vanishingly small fraction of the design space with coverage shrinking exponentially as the sequence length increases (i.e., an np sequence will result in 32np different combinations), so it is necessary to learn the transformations in a meaningful way. To help alleviate this issue, we will introduce the Intermediate Transformation Network (ITN) in the next subsection.\nAn alternative PPN is to feed the pre- and post-deformed shapes into the CNN separately with isolated channels before merging them together in the fully connected layer, which may or may not result in better classification performance. For the simplicity of analysis and efficient error backpropagation, we decided to focus our analysis solely on the aforementioned formulation where flow shape images are in juxtaposition.\nPPN parameters: The input image is comprised of two 12 \u00d7 100 px flow shape image with a 5 \u00d7 100 px padding in between, resulting in a final dimension of 29 \u00d7 100 px. The model contains two convolutional layers with 40 and 100 kernels respectively (sizes of 5 \u00d7 5 and 3 \u00d7 3 px), each followed by a 2 \u00d7 2 maxpooling layer. The fully connected layer has 500 hidden units. Training is done with 250,240 training examples and 60,000 validation examples in minibatches of 50 with a learning rate of 0.01. The training procedure employs the early stopping algorithm where training stops when validation error ceases to decrease.\n2.4 Intermediate transformation network (ITN)\nDuring inference, the edges in the outputs of the ITN may appear blur because the bridging shape is only an approximation (Fig. 4(c)). To obtain pure black and white images, we threshold the pixel values where pixel intensities larger or equal to 0.5 are set to 1, 0 otherwise.\nThe ITN may be extended to obtain several waypoints instead of only the midpoint. Doing so will allow a smoother transformation pathway, but will require some changes in the training data generation procedure. We leave this as a future work.\nITN parameters: The autoencoder has 3 layers of 500 hidden units each and accepts flow shape images of 12 \u00d7 100 px. Training was done on 500,000 training examples and 20,000 validation examples in minibatch of size 1,000 with a learning rate of 0.1 for pretraining and 0.01 for finetuning. Training is also done using the early-stopping algorithm."}, {"heading": "2.5 The integrated pipeline (PPN+ITN)", "text": "With the roles of the PPN and ITN clearly described, we can now integrate both networks to form an integrated pipeline. A schematic is shown in Fig. 5. At the very beginning, the ITN guesses a candidate for the bridging flow shape, which is then considered as the temporary target shape, and is concatenated with the undeformed shape placed to its left with a padding. The concatenated input is supplied into the PPN to predict the first pillar causing the deformation, and then added to the sequence which was initially empty, hence resulting in a sequence of length 1. The current shape is regenerated with the updated 1-pillar sequence and replaces the left portion of the input image for the next PPN iteration to obtain the second pillar index. The process is repeated as \u2018Stage A\u2019 (with the bridging shape as a temporary target) until the current shape is sufficiently similar to the\nbridging shape, or until an iteration limit is reached. Then, the right portion of the input image (which was the bridging shape) is replaced with the final desired shape as the target. This process is continued as \u2018Stage B\u2019 which undergoes the same process as \u2018Stage A\u2019, except the target shape is now the final desired shape. After each iteration, the predicted pillar index is added to the sequence until the reconstructed flow shape matches the desired shape or a stopping criterion is achieved. The resulting sequence will vary in length for different desired shapes."}, {"heading": "3 Results and discussions", "text": "In this section we first present the evaluation metrics used in the study, then show the results comparing CNN-SMC against our method using PPN and the PPN+ITN hybrid architecture."}, {"heading": "3.1 Performance evaluation metrics", "text": "To quantify the effectiveness of both approaches, we evaluated the pixel match rate (PMR) on 20 target flow shapes and computed appropriate statistics. Given an original flow shape image and an image generated from the predicted pillar sequences using the DL model, two pixels at corresponding locations match if they both have the same color. The PMR, defined in [7], is computed as follows:\nPMR = 1\u2212 ||p\u2212 p\u0302||1\n|p|\nwhere p is the target image vector, p\u0302 is the predicted image vector, and |p| denotes the number of elements in the vector (i.e., the total number of pixels in the image).\nAs a supplementary metric, the structural similarity index (SSIM) [21] is used to compare how structurally similar are the regenerated flow shape images (from predicted sequence) to the target flow shape. SSIM explores the change in image structure and incorporates pixel inter-dependencies. SSIM is expressed as:\nSSIM(x, y) = (2\u00b5x\u00b5y + c1)(2\u03c3xy + c2)\n(\u00b52x + \u00b5 2 y + c1)(\u03c3 2 x + \u03c3 2 y + c2)\nwhere \u00b5x is the average of window x, \u00b5y is the average of window y, \u03c32x is the variance of x, \u03c3 2 y is the variance of y, \u03c32xy is the covariance of x and y, c1 = (k1L) 2 and c2 = (k2L)2 are two variables to stabilize the division with weak denominator with k1 = 0.01 and k2 = 0.03 by default, and L is the dynamic range of pixel values."}, {"heading": "3.2 Predicting sequences with PPN and ITN", "text": "In all of our tests, the target flow shape is generated from a 10-pillar sequence which is sufficiently complex. Fig. 6 shows four example target shapes with the performance using only PPN (without\nbridging) and PPN+ITN (with bridging). In most cases, the PPN-only formulation produces pillar sequences resulting in flow shapes that do not resemble the target shape as close as using PPN+ITN. This can be clearly seen for cases C and D in Fig. 6. On the other hand, by using the bridging shape as a temporary target, the prediction performance saw great improvements. In addition, we see that most shapes are able to converge to both the bridging shape as well as the target in the PPN+ITN formulation. In realistic applications, the sequence may be stored in memory and post-processed to remove the redundant pillars, thus producing a shorter sequence which may increase financial savings during the manufacturing process."}, {"heading": "3.3 Comparison with CNN-SMC", "text": "20 sample-wise comparison on the performance of CNN-SMC, and our methods PPN and PPN+ITN are shown in Fig. 7 and tabulated in Table 1. The reconstructed flow shapes from the predicted sequences are shown in Fig. 8. In both Fig. 7(a) and Fig. 7(b), the PMR and SSIM for PPN and PPN+ITN are clearly higher than the CNN-SMC approach. We observe that for some target flow shapes, the predicted sequence for CNN-SMC may result in an entirely dissimilar shape (e.g. sample\n2, 19, 20). In some cases (e.g. samples 14, 15, 16) PPN fared better than the hybrid PPN+ITN model. However, PPN+ITN is consistently more superior in terms of both PMR and SSIM than the PPN-only architecture. This shows that having a bridging shape generally helps in producing sequences that generate complex flow shapes. The inferior performance of CNN-SMC is due the model being constrained to always generate a sequence with 10 pillars, thus the resultant flow shapes often become overcomplicated.\nA clear advantage of using both PPN and ITN together is that the model does not need to be retrained for variable sequence lengths, unlike in the CNN-SMC model where the number of pillars in the output sequence is constrained. This method is highly scalable, and has an enormous room for extension into sculpting more highly complex flow shapes."}, {"heading": "4 Conclusions and future work", "text": "This paper proposes a deep learning based approach to learn a sequence of actions that carries out the desired transformation over the input, which has potentially high impact on the innovation of manufacturing processes, material sciences, biomedical applications, decision planning, and many more. In the paper, we specifically focused in engineering microfluidic channels for flow sculpting. We demonstrated that creative integration of DL based tools can tackle the inverse fluid problem and achieve the required design accuracy while expediting the design process compared to laborious\ntrial-and-error design iterations. The training data generation and hierarchical feature extraction processes together proves to be quite useful for a scalable design tool. Current efforts are primarily focusing on optimizing the tool-chain (e.g. recursive ITN) as well as tailoring for specific application areas such as manufacturing and biology."}], "references": [{"title": "Classification using discriminative restricted boltzmann machines", "author": ["Hugo Larochelle", "Yoshua Bengio"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2008}, {"title": "Deep neural networks for acoustic modeling in speech recognition", "author": ["Geoffrey E. Hinton", "Li Deng", "Dong Yu", "George E. Dahl", "Abdel-rahman Mohamed", "Navdeep Jaitly", "Andrew Senior", "Vincent Vanhoucke", "Patrick Nguyen", "Tara N. Sainath", "Brian Kingsbury"], "venue": "IEEE Signal Processing Magazine,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Occlusion edge detection in rgb-d frames using deep convolutional networks", "author": ["Soumik Sarkar", "Vivek Venugopalan", "Kishore Reddy", "Michael Giering", "Julian Ryde", "Navdeep Jaitly"], "venue": "Proceedings of IEEE High Performance Exterme Computing Conference,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Indoor semantic segmentation using depth information", "author": ["Camille Couprie", "Cl\u00e9ment Farabet", "Laurent Najman", "Yann LeCun"], "venue": "arXiv preprint arXiv:1301.3572,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Multimodal learning with deep boltzmann machines", "author": ["Nitish Srivastava", "Ruslan R Salakhutdinov"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Early detection of combustion instability by neural-symbolic analysis on hi-speed video", "author": ["Soumalya Sarkar", "Kin Gwn Lore", "Soumik Sarkar"], "venue": "In Workshop on Cognitive Computation: Integrating Neural and Symbolic Approaches (CoCo@ NIPS", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Hierarchical feature extraction for efficient design of microfluidic flow patterns", "author": ["Kin Gwn Lore", "Daniel Stoecklein", "Michael Davies", "Baskar Ganapathysubramanian", "Soumik Sarkar"], "venue": "In Proceedings of The 1st International Workshop on \u201cFeature Extraction: Modern Questions and Challenges\u201d,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Deep value of information estimators for collaborative human-machine information gathering", "author": ["Kin Gwn Lore", "Nicholas Sweet", "Kundan Kumar", "Nisar Ahmed", "Soumik Sarkar"], "venue": "International Conference on Cyber-physical Systems (ICCPS). Vienna,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2016}, {"title": "Deep learning of the tissue-regulated splicing", "author": ["Michael K.K. Leung", "Hui Y. Xiong", "Leo J. Lee", "Brendan J. Frey"], "venue": "code. Bioinformatics,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Mitosis detection in breast cancer histology images with deep neural networks. In Medical Image Computing and Computer-Assisted Intervention\u2013MICCAI", "author": ["Dan C. Cire\u015fan", "Alessandro Giusti", "Luca M. Gambardella", "J\u00fcrgen Schmidhuber"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Engineering fluid flow using sequenced microstructures", "author": ["Hamed Amini", "Elodie Sollier", "Mahdokht Masaeli", "Yu Xie", "Baskar Ganapathysubramanian", "Howard A. Stone", "Dino Di Carlo"], "venue": "Nature Communications,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Optimization of micropillar sequences for fluid flow sculpting", "author": ["Daniel Stoecklein", "Chueh-Yu Wu", "Donghyuk Kim", "Dino Di Carlo", "Baskar Ganapathysubramanian"], "venue": "Physics of Fluids,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}, {"title": "Application of machine learning algorithms to flow modeling and optimization", "author": ["S.D. M\u00fcller", "M. Milano", "Petros Koumoutsakos"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1999}, {"title": "Closed-loop turbulence control using machine learning", "author": ["Thomas Duriez", "Vladimir Parezanovi\u0107", "Laurent Cordier", "Bernd R Noack", "Jo\u00ebl Delville", "Jean- Paul Bonnet", "Marc Segond", "Markus Abel"], "venue": "arXiv preprint arXiv:1404.4589,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Artificial neural networks approach for solving stokes problem", "author": ["Modjtaba Baymani", "Asghar Kerayechian", "Sohrab Effati"], "venue": "Applied Mathematics,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "The role of neural networks in fluid mechanics and heat transfer", "author": ["S. Ashforth-Frost", "V.N. Fontama", "K. Jambunathan", "S.L. Hartle"], "venue": "In Instrumentation and Measurement Technology Conference,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1995}, {"title": "Recurrent neural network based language model", "author": ["Tomas Mikolov", "Martin Karafi\u00e1t", "Lukas Burget", "Jan Cernock\u1ef3", "Sanjeev Khudanpur"], "venue": "In INTERSPEECH,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "Spatial transformer networks", "author": ["Max Jaderberg", "Karen Simonyan", "Andrew Zisserman"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Extracting and composing robust features with denoising autoencoders", "author": ["Pascal Vincent", "Hugo Larochelle", "Yoshua Bengio", "Pierre-Antoine Manzagol"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E. Hinton"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}, {"title": "Image quality assessment: from error visibility to structural similarity", "author": ["Zhou Wang", "Alan Conrad Bovik", "Hamid Rahim Sheikh", "Eero P Simoncelli"], "venue": "Image Processing, IEEE Transactions on,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2004}], "referenceMentions": [{"referenceID": 0, "context": "1 Introduction Hierarchical feature extraction using deep neural networks has been very successful in accomplishing various tasks such as objection recognition [1], speech recognition [2], scene understand-", "startOffset": 160, "endOffset": 163}, {"referenceID": 1, "context": "1 Introduction Hierarchical feature extraction using deep neural networks has been very successful in accomplishing various tasks such as objection recognition [1], speech recognition [2], scene understand-", "startOffset": 184, "endOffset": 187}, {"referenceID": 2, "context": "ing [3, 4], multi-modal sensor fusion [5], prognostics [6], engineering design [7] and policy reward learning [8].", "startOffset": 4, "endOffset": 10}, {"referenceID": 3, "context": "ing [3, 4], multi-modal sensor fusion [5], prognostics [6], engineering design [7] and policy reward learning [8].", "startOffset": 4, "endOffset": 10}, {"referenceID": 4, "context": "ing [3, 4], multi-modal sensor fusion [5], prognostics [6], engineering design [7] and policy reward learning [8].", "startOffset": 38, "endOffset": 41}, {"referenceID": 5, "context": "ing [3, 4], multi-modal sensor fusion [5], prognostics [6], engineering design [7] and policy reward learning [8].", "startOffset": 55, "endOffset": 58}, {"referenceID": 6, "context": "ing [3, 4], multi-modal sensor fusion [5], prognostics [6], engineering design [7] and policy reward learning [8].", "startOffset": 79, "endOffset": 82}, {"referenceID": 7, "context": "ing [3, 4], multi-modal sensor fusion [5], prognostics [6], engineering design [7] and policy reward learning [8].", "startOffset": 110, "endOffset": 113}, {"referenceID": 8, "context": "In addition, the field of biology has taken a huge interest in using deep learning (DL) methods for relating DNA variants to diseases [9] and detecting mitosis from cancer histology images [10].", "startOffset": 134, "endOffset": 137}, {"referenceID": 9, "context": "In addition, the field of biology has taken a huge interest in using deep learning (DL) methods for relating DNA variants to diseases [9] and detecting mitosis from cancer histology images [10].", "startOffset": 189, "endOffset": 193}, {"referenceID": 10, "context": "Using microchannels populated with a set of pillars, the pillars can individually deform a flow to achieve the final desired shape [11].", "startOffset": 131, "endOffset": 135}, {"referenceID": 11, "context": "Although works have been done to frame this inverse problem as an unconstrained optimization problem [12], they are invariable time-consuming.", "startOffset": 101, "endOffset": 105}, {"referenceID": 12, "context": "While many methods are used to solve the forward problem [13\u201316], only a limited amount of effort has been done in solving the inverse problem [7].", "startOffset": 57, "endOffset": 64}, {"referenceID": 13, "context": "While many methods are used to solve the forward problem [13\u201316], only a limited amount of effort has been done in solving the inverse problem [7].", "startOffset": 57, "endOffset": 64}, {"referenceID": 14, "context": "While many methods are used to solve the forward problem [13\u201316], only a limited amount of effort has been done in solving the inverse problem [7].", "startOffset": 57, "endOffset": 64}, {"referenceID": 15, "context": "While many methods are used to solve the forward problem [13\u201316], only a limited amount of effort has been done in solving the inverse problem [7].", "startOffset": 57, "endOffset": 64}, {"referenceID": 6, "context": "While many methods are used to solve the forward problem [13\u201316], only a limited amount of effort has been done in solving the inverse problem [7].", "startOffset": 143, "endOffset": 146}, {"referenceID": 16, "context": "Recurrent neural network (RNN)-like architectures [17] are deemed unsuitable because the elements in the output vector are generally independent of each other, unlike words in a sentence.", "startOffset": 50, "endOffset": 54}, {"referenceID": 17, "context": "A related concept is the spatial transformer network [18] where the localization network outputs geometrical transformation parameters; however we desire an exact class attributed to an arbitrary transformation function.", "startOffset": 53, "endOffset": 57}, {"referenceID": 6, "context": "Authors in [7] predicted the sequence of pillars which deforms into the target flow shape in a joint manner, although the resultant sequence is constrained in length and do not provide sufficient insight on the interplay between pillars causing the deformation.", "startOffset": 11, "endOffset": 14}, {"referenceID": 18, "context": "An integrated hierachical feature extraction approach using deep autoencoders (DAE) [19] with convolutional neural networks (CNN) [20] is proposed to capture multi-scale patterns of a deformed fluid flow to generate the associated sequence resulting in the deformation.", "startOffset": 84, "endOffset": 88}, {"referenceID": 19, "context": "An integrated hierachical feature extraction approach using deep autoencoders (DAE) [19] with convolutional neural networks (CNN) [20] is proposed to capture multi-scale patterns of a deformed fluid flow to generate the associated sequence resulting in the deformation.", "startOffset": 130, "endOffset": 134}, {"referenceID": 6, "context": "Simultaneous multi-class classification is a method proposed in [7] to solve a similar problem.", "startOffset": 64, "endOffset": 67}, {"referenceID": 6, "context": "The PMR, defined in [7], is computed as follows: PMR = 1\u2212 ||p\u2212 p\u0302||1 |p| where p is the target image vector, p\u0302 is the predicted image vector, and |p| denotes the number of elements in the vector (i.", "startOffset": 20, "endOffset": 23}, {"referenceID": 20, "context": "As a supplementary metric, the structural similarity index (SSIM) [21] is used to compare how structurally similar are the regenerated flow shape images (from predicted sequence) to the target flow shape.", "startOffset": 66, "endOffset": 70}], "year": 2017, "abstractText": "Deep learning (DL) became the method of choice in recent years for solving problems ranging from object recognition and speech recognition to robotic perception and human disease prediction. In this paper, we present a hybrid architecture of convolutional neural networks (CNN) and stacked autoencoders (SAE) to learn a sequence of actions that nonlinearly transforms an input shape or distribution into a target shape or distribution with the same support. While such a framework can be useful in a variety of problems such as robotic path planning, sequential decision-making in games and identifying material processing pathways to achieve desired microstructures, this paper focuses on controlling fluid deformations in a microfluidic channel by deliberately placing a sequence of pillars, which has a significant impact on manufacturing for biomedical and textile applications where highly targeted shapes are desired. We propose an architecture which simultaneously predicts the intermediate shape lying in the nonlinear transformation pathway between the undeformed and desired flow shape, then learns the causal action\u2013the single pillar which results in the deformation of the flow\u2013one at a time. The learning of stage-wise transformations provides deep insights into the physical flow deformation. Results show that under the current framework, our model is able to predict a sequence of pillars that reconstructs the flow shape which highly resembles the desired shape.", "creator": "LaTeX with hyperref package"}}}