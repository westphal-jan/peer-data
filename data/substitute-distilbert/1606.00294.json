{"id": "1606.00294", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jun-2016", "title": "Improved Parsing for Argument-Clusters Coordination", "abstract": "relational parsers perform poorly in exercises of argument - cluster coordination ( acc ). we change specific ptb representation of acc to be more suitable for learning by a statistical descriptive parser, affecting 125 trees in the training task. training on the modified trees yields a slight success in evalb scores on sections 22 by 23. the latter evaluation is on a corpus of 4th grade science exams, in which acc structures are prevalent. among their corpus, we obtain an impressive x2. 7 improvement in recovering acc structures compared to typical parser trained on the original ptb trees.", "histories": [["v1", "Wed, 1 Jun 2016 14:06:41 GMT  (195kb,D)", "http://arxiv.org/abs/1606.00294v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["jessica ficler", "yoav goldberg"], "accepted": true, "id": "1606.00294"}, "pdf": {"name": "1606.00294.pdf", "metadata": {"source": "CRF", "title": "Improved Parsing for Argument-Clusters Coordination", "authors": ["Jessica Ficler"], "emails": ["jessica.ficler@gmail.com", "yoav.goldbreg@gmail.com"], "sections": [{"heading": null, "text": "Syntactic parsers perform poorly in prediction of Argument-Cluster Coordination (ACC). We change the PTB representation of ACC to be more suitable for learning by a statistical PCFG parser, affecting 125 trees in the training set. Training on the modified trees yields a slight improvement in EVALB scores on sections 22 and 23. The main evaluation is on a corpus of 4th grade science exams, in which ACC structures are prevalent. On this corpus, we obtain an impressive \u00d72.7 improvement in recovering ACC structures compared to a parser trained on the original PTB trees."}, {"heading": "1 Introduction", "text": "Many natural language processing systems make use of syntactic representations of sentences. These representations are produced by parsers, which often produce incorrect analyses. Many of the mistakes are in coordination structures, and structures involving non-constituent coordination, such as Argument Cluster Coordination, Right Node-Raising and Gapping (Dowty, 1988), are especially hard.\nCoordination is a common syntactic phenomena and work has been done to improve coordination structures predication in the general case (Hogan, 2007; Hara et al., 2009; Shimbo and Hara, 2007; Okuma et al., 2009). In this work we focus on one particular coordination structure: Argument Cluster Coordination (ACC). While ACC are not common in the Penn TreeBank (Marcus et al., 1993), they commonly appear in other corpora. For example, in a dataset of questions from the Regents 4th grade science exam (the Aristo Challenge), 14% of the sentences include ACC.\nACC is characterized by non-constituent sequences that are parallel in structure. For instance, in \u201cI bought John a microphone on Monday and Richie a guitar on Saturday\u201d, the conjunction is between \u201cJohn a microphone on Monday\u201d and \u201cRichie a guitar on Saturday\u201d which are both nonconstituents and include parallel arguments: the NPs \u201cJohn\u201d and \u201cRichie\u201d; the NPs \u201ca microphone\u201d and \u201ca guitar\u201d; and the PPs \u201con Monday\u201d and \u201con Saturday\u201d.\nPrevious NLP research on the Argument Clusters Coordination (Mouret, 2006) as well as the Penn TreeBank annotation guidelines (Marcus et al., 1993; Bies et al., 1995) focused mainly on providing representation schemes capable of expressing the linguistic nuances that may appear in such coordinations. The resulting representations are relatively complex, and are not easily learnable by current day parsers, including parsers that refine the grammar by learning latent annotations (Petrov et al., 2006), which are thought to be more agnostic to the annotations scheme of the trees. In this work, we suggest an alternative, simpler representation scheme which is capable of representing most of the Argument Cluster coordination cases in the Penn Treebank, and is better suited for training a parser. We show that by changing the annotation of 125 trees, we get a parser which is substantially better at handling ACC structures, and is also marginally better at parsing general sentences."}, {"heading": "2 Arguments Cluster Coordination in the Penn Tree Bank", "text": "Argument Cluster Coordinations are represented in the PTB with two or more conjoined VPs, where the first VP contains a verb and indexed arguments, and the rest of the VPs lack a verb and include arguments with indices corresponding to\nar X\niv :1\n60 6.\n00 29\n4v 1\n[ cs\n.C L\n] 1\nJ un\n2 01\n6\nthose of the first conjoined VP. For example, consider the PTB representation of \u201cThe Q ratio was only 65% in 1987 and 68.9% in 1988\u201d:\nVP\nVP\nVBD\nwas\nNP-1\nonly 65 %\nPP-2\nin 1987\nCC\nand\nVP\nNP=1\n68.9 %\nPP=2\nin 1988\nThe main VP includes two conjoined VPs. The first VP includes the verb was and two indexed arguments: \u201conly 65%\u201d (1) and \u201cin 1987\u201d (2). The second VP does not include a verb, but only two arguments, that are co-indexed with the parallel argument at the first conjoined VP.\nACC structures in the PTB may include modifiers that are annotated under the main VP, and the conjoined VPs may includes arguments that are not part of the cluster. These are annotated with no index, i.e. \u201cinsurance costs\u201d in [1a].\nACC structures are not common in the PTB. The training set includes only 141 ACC structures of which are conjoined by and or or. Some of them are complex but most (78%) have the following pattern (NT is used to denote non-terminals):\nVP\nVP\nVerb NT-1 NT-2\nCC\nand/or\nVP\nNT=1 NT=2\nThese structures can be characterized as follows: (1) the first token of the first conjoined VP is a verb; (2) the indexed arguments are direct children of the conjoined VPs; (3) the number of the indexed arguments is the same for each conjoined VP.\nAlmost all of these cases (98%) are symmetric: each of the conjoined VPs has the same types of indexed arguments. Non-symmetric clusters (e.g. \u201cHe made [these gestures]1NP [to the red group] 2 PP and [for us]2PP [nothing] 1 NP \u201d) exist but are less common. We argue that while the PTB representation for ACC gives a clear structure and covers all the ACC forms, it is not a good representation for learning PCFG parsers from. The arguments in the clusters are linked via co-indexation, breaking the context-free assumptions that PCFG parsers rely on. PCFG parsers ignore the indexes, essentially losing all the information about the ACC construction. Moreover, ignoring the indexes result\nin \u201cweird\u201d CFG rules such as VP\u2192 NP PP. Not only that the RHS of these rules do not include a verbal component, it is also a very common structure for NPs. This makes the parser very likely to either mis-analyze the argument cluster as a nounphrase, or to analyze some NPs as (supposedly ACC) VPs. The parallel nature of the construction is also lost. To improve the parser performance for ACC structures prediction, we suggest an alternative constituency representation for ACC phrases which is easier to learn."}, {"heading": "3 Alternative Representation for ACC", "text": "Our proposed representation for ACC respects the context-free nature of the parser. In order to avoid incorrect syntactic derivations and derivations that allows conjoining of clusters with other phrases, as well as to express the symmetry that occur in many ACC phrases, we change the PTB representation for ACC as follows: (1) we move the verb and non-indexed elements out of the first argument cluster to under the main VP; (2) each argument cluster is treated as a phrase, with new non-terminal symbols specific to argument clusters; (3) the conjunction of clusters also receives a dedicated phrase level. For example see comparison between the original and new representations:\n[1]\nVP\nVP\nVBN\ndriven\nPRT\nup\nNP\ninsurance costs\nNP-1\n20%\nPP-2\nin Maryland\nCC\nand\nVP\nNP=1\n30%\nPP=2\nin California\n(a) PTB representation\nVP\nVBN\ndriven\nPRT\nup\nNP\ninsurance costs\nACCPHNP\nACCNP\u2212PP\nNP-1\n20%\nPP-2\nin Maryland\nCC\nand\nACCNP\u2212PP\nNP=1\n30%\nPP=2\nin California\n(b) Our modified tree\nThe main verb driven as well as the particle up and the non-indexed argument insurance costs are moved to the external VP. The two argument clusters (formerly VPs) receive dedicated phrase la-\nbels ACCX , where X reflects the syntactic types of the indexed elements (e.g. ACCNP\u2212PP for the first cluster in [1b] above). The most common cases are ACCNP\u2212PP which appears in 41.6% of the clusters, ACCADJP\u2212PP with 21.2% of the clusters and ACCPP\u2212PP with 5.3% of the clusters.\nFinally, we introduce a new phrase type (ACCPHX ) for the coordination of the two clusters. Here X denotes the main element in the clusters, determined heuristically by taking the first of the following types that appear in any of the clusters: NP, PP, ADJP, SBAR. Cases where the clusters contains an ADVP element are usually special (e.g. the following structure is missing \u201cpeople\u201d in the second cluster: ((NP 8000 people) (in Spain)) and ((NP 2000) (ADVP abroad))). For such cases, we add \u201cADVP\u201d to the ACCPH level label. Table 1 lists the ACCPH level labels and their number of the appearances in the 125 modified trees.1\nThe representation is capable of representing common cases of ACC where the cluster elements are siblings. We similarly handle also some of the more complex cases, in which an extra layer appears between an indexed argument and the conjoined VP to host an empty element, such as in the following case with an extra S layer above single-B-3:\nVP\nVP\nVBN\nrated\nS\nNP\n-NONE-\nADJP-1\nsingle-B-3\nPP-2\nby...\nCC\nand\nVP\nADJP=1\nsingle-B-plus\nPP=2\nby...\nin which we remove the empty NP as well as the extra S layer:\nVP\nVBN\nrated\nACCPHPP\nACCADJP\u2212PP\nADJP\nsingle-B-3\nPP\nby...\nCC\nand\nACCADJP\u2212PP\nADJP\nsingle-B-plus\nPP\nby...\n1Parsers that apply latent annotations to the grammar, such as the Berkeley Parser (Petrov et al., 2006) we use in our experiments, can potentially learn some of our proposed refinements on their own. However, as we show in the experiments section, the performance of the Berkeley Parser on ACC structures significantly improve when applying our transformations prior to training.\nLimitations Our representation is similar to the representation that was suggested for ACC by Huddleston et al. (2002) in their comprehensive linguistic description of the English grammar. However, while it is capable of representing the common cases of ACC, it does not cover some complex and rare cases encountered in the PTB: (1) Argument-Cluster structures that include errors such as missing indexed argument and a wrong POS tag for the main verb; (2) ACC constructions where the main verb is between the indexed arguments such as the following: \u201c([About half]1 invested [in government bonds]2) and ([about 10%]1 [in cash]2)\u201d; (3) ArgumentCluster structures that include an indexed phrase which is not a direct child of the cluster head and has non-empty siblings, such as in the following case that includes an indexed argument (8%) which is not directly under the conjoined VP and has non-empty sibling (of ): \u201csee a raise [[of] [8%]NP\u22121]PP in the first year] and [7%]NP=1 in each of the following two years\u201d.\nOur changes are local and appear in small number of trees (0.003% of the PTB train set). We also ignore more complex cases of ACC. Yet, training the parser with the modified trees significantly improves the parser results on ACC structures."}, {"heading": "4 Experiments", "text": "We converted 125 trees with ACC structures in the training sets (sections 2-21) of the PTB to the new representation, and trained the Berkeley parser (Petrov et al., 2006) with its default settings.\nAs the PTB test and dev sets have only 12 ACC structures that are coordinated by and or or, we evaluate the parser on Regents, a dataset in which ACC structures are prevalent (details below). As Regents does not include syntactic structures, we focus on the ACC phenomena and evaluate the parsers\u2019 ability to correctly identify the spans of the clusters and the arguments in them.\nTo verify that the new representation does not harm general parsing performance, we also eval-\nuate the parer on the traditional development and test sets (sections 22 and 23). As can be seen in Table 2, the parser results are slightly better when trained with the modified trees.2"}, {"heading": "4.1 Regents data-set", "text": "Regents \u2013 a dataset of questions from the Regents 4th grade science exam (the Aristo Challenge),3 includes 281 sentences with coordination phrases, where 54 of them include Argument Cluster coordination. We manually annotated the sentences by marking the conjuncts spans for the constituent coordination phrases, e.g.:\nWendy (ran 19 miles) and (walked 9 miles)\nas well as the spans of each component of the argument-cluster coordinations, including the inner span of each argument:\nMary paid ([$11.08] [for berries]) , ([$14.33] [for apples]) , and ([$9.31] [for peaches])\nThe bracketing in this set follow our proposed ACC bracketing, and we refer to it as ACCOUR.\nWe also created a version in which the bracketing follow the PTB scheme, with the verb included in span of the first cluster, e.g.:\nMary ([paid] [$11.08] [for berries]) , ([$14.33] [for apples]) , and ([$9.31] [for peaches])\nWe refer to this dataset as ACCPTB . 2The same trend holds also if we exclude the 12 modified trees from the evaluation sets. 3http://allenai.org/content/data/Regents.zip\nWe evaluate the parsers\u2019 ability to correctly recover the components of the coordination structures by computing the percentage of gold annotated phrases where the number of predicted conjunct is correct and all conjuncts spans (round brackets) are predicted correctly (Recall). For example, consider the following gold annotated phrase:"}, {"heading": "A restaurant served (9 pizzas during lunch) and (6 during dinner) today", "text": "A prediction of (\u201c9 pizzas during lunch\u201d, \u201c6 during dinner today\u201d) is considered as incorrect because the second conjunct boundaries are not matched to the gold annotation.\nWe compare the Recall score that the parser achieves when it is trained on the modified trees to the score when the parser is trained on the PTB trees.\nWhen evaluated on all coordination cases in the Regents dataset (both ACC and other cases of constituent coordination), the parser trained on the modified trees was successful in recovering 54.3% of the spans, compared to only 47% when trained on the original PTB trees.\nWe now focus on specifically on the ACC cases (Table 3). When evaluating the PTB-trained parser on ACCPTB , it correctly recovers only 13% of the ACC boundaries. Somewhat surprisingly, the PTB-trained parser performs better when evaluated against ACCOUR, correctly recovering 24.1% of the structures. This highlights how unnatural the original ACC representation is for the parser: it predicts the alternative representation more often than it predicts the one it was trained on. When the parser is trained on the modified trees, results on ACCOUR jump to 64.8%, correctly recovering \u00d72.7 more structures.\nThe previous results were on recovering the spans of the coordinated elements (the round brackets in the examples above). When measuring the Recall in recovering any of the arguments themselves (the elements surrounded by square brackets), the parser trained on the modified trees recovers 72.46% of the arguments in clusters, compared to only 58.29% recovery by the PTB-trained parser. We also measure in what percentage of the cases in which both the cluster boundaries (round brackets) were recovered correctly, all the internal structure (square brackets) was recovered correctly as well. The score is 80% when the parser trained on the modified trees com-\npared to 61.5% when it is trained on the PTB-trees. Overall, the parser trained on the modified trees significantly outperforms the one trained on the original trees in all the evaluation scenarios.\nAnother interesting evaluation is the ability of the parser that is trained on the modified trees to determine whether a coordination is of Argument Clusters type (that is, whether the predicted coordination spans are marked with the ACCPH label).4 The results are a Recall of 57.4% and Precision of 83.78%. When we further require that both the head be marked as ACCPH and the internal structure be correct, the results are 48.14% Recall and 70.27% Precision."}, {"heading": "5 Conclusions", "text": "By focusing on the details of a single and relatively rare syntactic construction, argument clusters coordination, we have been able to significantly improve parsing results for this construction, while also slightly improving general parsing results. More broadly, while most current research efforts in natural language processing and in syntactic parsing in particular is devoted to the design of general-purpose, data-agnostic techniques, such methods work on the common phenomena while often neglecting the very long tail of important constructions. This work shows that there are gains to be had also from focusing on the details of particular linguistic phenomena, and changing the data such that it is easier for a \u201cdata agnostic\u201d system to learn."}, {"heading": "Acknowledgments", "text": "This work was supported by The Allen Institute for Artificial Intelligence as well as the German Research Foundation via the German-Israeli Project Cooperation (DIP, grant DA 1600/1-1)."}], "references": [{"title": "Bracketing guidelines for treebank ii style penn treebank project", "author": ["Bies et al.1995] Ann Bies", "Mark Ferguson", "Karen Katz", "Robert MacIntyre", "Victoria Tredinnick", "Grace Kim", "Mary Ann Marcinkiewicz", "Britta Schasberger"], "venue": "Pennsyl-", "citeRegEx": "Bies et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Bies et al\\.", "year": 1995}, {"title": "Type raising, functional composition, and non-constituent conjuncThis measurement is relevant only when parsing", "author": ["David Dowty"], "venue": null, "citeRegEx": "Dowty.,? \\Q1988\\E", "shortCiteRegEx": "Dowty.", "year": 1988}, {"title": "Coordinate structure analysis with global structural constraints and alignment-based local features", "author": ["Hara et al.2009] Kazuo Hara", "Masashi Shimbo", "Hideharu Okuma", "Yuji Matsumoto"], "venue": "In Proceedings of the Joint Conference of the 47th Annual", "citeRegEx": "Hara et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hara et al\\.", "year": 2009}, {"title": "Coordinate noun phrase disambiguation in a generative parsing model. Association for Computational Linguistics", "author": ["Deirdre Hogan"], "venue": null, "citeRegEx": "Hogan.,? \\Q2007\\E", "shortCiteRegEx": "Hogan.", "year": 2007}, {"title": "The cambridge grammar of english", "author": ["Geoffrey K Pullum"], "venue": null, "citeRegEx": "Huddleston and Pullum,? \\Q2002\\E", "shortCiteRegEx": "Huddleston and Pullum", "year": 2002}, {"title": "Building a large annotated corpus of english: The penn treebank", "author": ["Mary Ann Marcinkiewicz", "Beatrice Santorini"], "venue": null, "citeRegEx": "Marcus et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Marcus et al\\.", "year": 1993}, {"title": "A phrase structure approach to argument cluster coordination", "author": ["Fran\u00e7ois Mouret"], "venue": "In Proceedings of the HPSG06 Conference,", "citeRegEx": "Mouret.,? \\Q2006\\E", "shortCiteRegEx": "Mouret.", "year": 2006}, {"title": "Bypassed alignment graph for learning coordination in japanese sentences", "author": ["Okuma et al.2009] Hideharu Okuma", "Kazuo Hara", "Masashi Shimbo", "Yuji Matsumoto"], "venue": "In Proceedings of the ACLIJCNLP 2009 Conference Short Papers,", "citeRegEx": "Okuma et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Okuma et al\\.", "year": 2009}, {"title": "Learning accurate, compact, and interpretable tree annotation", "author": ["Petrov et al.2006] Slav Petrov", "Leon Barrett", "Romain Thibaux", "Dan Klein"], "venue": "In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual", "citeRegEx": "Petrov et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Petrov et al\\.", "year": 2006}, {"title": "A discriminative learning model for coordinate conjunctions", "author": ["Shimbo", "Hara2007] Masashi Shimbo", "Kazuo Hara"], "venue": "In EMNLP-CoNLL,", "citeRegEx": "Shimbo et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Shimbo et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 1, "context": "Many of the mistakes are in coordination structures, and structures involving non-constituent coordination, such as Argument Cluster Coordination, Right Node-Raising and Gapping (Dowty, 1988), are especially hard.", "startOffset": 178, "endOffset": 191}, {"referenceID": 3, "context": "Coordination is a common syntactic phenomena and work has been done to improve coordination structures predication in the general case (Hogan, 2007; Hara et al., 2009; Shimbo and Hara, 2007; Okuma et al., 2009).", "startOffset": 135, "endOffset": 210}, {"referenceID": 2, "context": "Coordination is a common syntactic phenomena and work has been done to improve coordination structures predication in the general case (Hogan, 2007; Hara et al., 2009; Shimbo and Hara, 2007; Okuma et al., 2009).", "startOffset": 135, "endOffset": 210}, {"referenceID": 7, "context": "Coordination is a common syntactic phenomena and work has been done to improve coordination structures predication in the general case (Hogan, 2007; Hara et al., 2009; Shimbo and Hara, 2007; Okuma et al., 2009).", "startOffset": 135, "endOffset": 210}, {"referenceID": 5, "context": "While ACC are not common in the Penn TreeBank (Marcus et al., 1993), they commonly appear in other corpora.", "startOffset": 46, "endOffset": 67}, {"referenceID": 6, "context": "Previous NLP research on the Argument Clusters Coordination (Mouret, 2006) as well as the Penn TreeBank annotation guidelines (Marcus et al.", "startOffset": 60, "endOffset": 74}, {"referenceID": 5, "context": "Previous NLP research on the Argument Clusters Coordination (Mouret, 2006) as well as the Penn TreeBank annotation guidelines (Marcus et al., 1993; Bies et al., 1995) focused mainly on providing representation schemes capable of expressing the linguistic nuances that may appear in such coordinations.", "startOffset": 126, "endOffset": 166}, {"referenceID": 0, "context": "Previous NLP research on the Argument Clusters Coordination (Mouret, 2006) as well as the Penn TreeBank annotation guidelines (Marcus et al., 1993; Bies et al., 1995) focused mainly on providing representation schemes capable of expressing the linguistic nuances that may appear in such coordinations.", "startOffset": 126, "endOffset": 166}, {"referenceID": 8, "context": "The resulting representations are relatively complex, and are not easily learnable by current day parsers, including parsers that refine the grammar by learning latent annotations (Petrov et al., 2006), which are thought to be more agnostic to the annotations scheme of the trees.", "startOffset": 180, "endOffset": 201}, {"referenceID": 8, "context": "Parsers that apply latent annotations to the grammar, such as the Berkeley Parser (Petrov et al., 2006) we use in our experiments, can potentially learn some of our proposed refinements on their own.", "startOffset": 82, "endOffset": 103}, {"referenceID": 8, "context": "We converted 125 trees with ACC structures in the training sets (sections 2-21) of the PTB to the new representation, and trained the Berkeley parser (Petrov et al., 2006) with its default settings.", "startOffset": 150, "endOffset": 171}], "year": 2016, "abstractText": "Syntactic parsers perform poorly in prediction of Argument-Cluster Coordination (ACC). We change the PTB representation of ACC to be more suitable for learning by a statistical PCFG parser, affecting 125 trees in the training set. Training on the modified trees yields a slight improvement in EVALB scores on sections 22 and 23. The main evaluation is on a corpus of 4th grade science exams, in which ACC structures are prevalent. On this corpus, we obtain an impressive \u00d72.7 improvement in recovering ACC structures compared to a parser trained on the original PTB trees.", "creator": "LaTeX with hyperref package"}}}