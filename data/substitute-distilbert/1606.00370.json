{"id": "1606.00370", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jun-2016", "title": "Decoding Emotional Experience through Physiological Signal Processing", "abstract": "there is an increasing consensus among re - searchers that making a computer emotionally intelligent with the ability to decode human affective displays would allow a more meaningful and natural exploration of human - computer interactions ( hcis ). one stable and non - structured way of recognizing human affective states entails the exploration of how physiological signals vary under these emotional representations. in particular, this paper explores the correlation between autonomically - mediated changes in multimodal body physiology and discrete emotional states. in order to fully exploit user information in each mechanism, networks have provided an innovative classification approach for three specific physiological outputs including electromyogram ( emg ), blood volume pressure ( bvp ) and galvanic skin response ( gsr ). these stimuli are analyzed as inputs to an emotion encoding paradigm based on fusion of a series of weak triggers. our weak classification approach showed 88. 1 % recognition functionality, which outperformed the conventional support vector machine ( svm ) classifier gained 69 % accuracy improvement. furthermore, in order to avoid information redundancy and the resultant over - fitting, a feature reduction agenda is proposed applying primarily a correlation analysis to optimize the number of features required for training and accommodate each weak understanding. results showed that despite the feature space dimensionality reduction from 27 to 18 features, our methodology preserved word recognition accuracy of about 85. 0 %. this reduction product complexity will otherwise delayed one step closer towards embedding this human emotion encoder in either wireless smart wearable handwriting sensor.", "histories": [["v1", "Wed, 1 Jun 2016 17:52:30 GMT  (1159kb,D)", "http://arxiv.org/abs/1606.00370v1", null]], "reviews": [], "SUBJECTS": "cs.HC cs.LG", "authors": ["maria s perez-rosero", "behnaz rezaei", "murat akcakaya", "sarah ostadabbas"], "accepted": false, "id": "1606.00370"}, "pdf": {"name": "1606.00370.pdf", "metadata": {"source": "CRF", "title": "Decoding Emotional Experience through Physiological Signal Processing", "authors": ["Maria S. Perez-Rosero", "Behnaz Rezaei", "Murat Akcakaya", "Sarah Ostadabbas"], "emails": ["ostadabbas@ece.neu.edu)."], "sections": [{"heading": null, "text": "Index Terms\u2014 Correlation analysis, emotional experience, feature reduction, fusion algorithm, physiological signals, weak learners.\nI. INTRODUCTION\nProviding computers with emotional understanding along with their current mathematical-logical capabilities is considered a breakthrough in creating more intelligent and less exacerbating behaviors in Human-Computer Interaction (HCI) applications [1]. An example of an intelligent HCI is exploiting \u201dfeeling computers\u201d in enhancing distanceeducation experience. In [2], a facial recognition software has been introduced to detect specific feelings of students such as frustration and boredom during training sessions. Among the difficult challenges in these platforms is the ambiguity in recognizing emotions only from using the taxonomy of facial behaviors. This ambiguity is mainly due to the unrecognizable facial deformations such as wrinkling of the forehead or creasing around the mouth, eyes, or nose.\n1Maria S. Perez-Rosero, Behnaz Rezaei, and Sarah Ostadabbas are with the Augmented Cognition laboratory, Electrical and Computer Engineering Department, Northeastern University, MA, USA (corresponding author\u2019s email: ostadabbas@ece.neu.edu).\n2Murat Akcakaya is with the Electrical and Computer Engineering Department, University of Pittsburgh PA, USA.\nIn addition, facial expressions can be easily manipulated by the user, which produce faked affect signs.\nUnlike the facial expressions, physiological signals can not be manipulated. This characteristic makes them a robust alternative for emotion recognition systems. Knowledge of the natural processes that occur at different scales inside our body can be obtained by exploring different physiological signals and by drawing conclusions about how these biological processes are triggered, executed and connected between each other. In turn, this physiological information can be translated to advance the design and development of assistive and augmentative technologies which are human-centric and can empower people with different social, intellectual or emotional skills [3].\nIn particular, the aim of this paper is to explore the correlation between physiological changes and emotion experiences in order to develop a robust emotion recognition algorithm. As authors concluded in [4], much work remains before emotion interpretation by machine intelligence can occur at the level of human abilities. When it comes to the implementation of the emotional understanding and emotional perception in machines with high-constrained computational resources, a simple but efficient knowledge of the key features that trigger and characterize human emotions could be crucial. This knowledge would provide a framework of reference for the development of future applications in which small wearable electronics can be programmed with simple and concrete definitions about how an emotion is expected to be decoded from non-invasively accessible bodily signals."}, {"heading": "A. Related Works", "text": "Automatic emotion recognition is a field that has gained a lot of attention in the past few decades [5], [6], [7]. Much of the work in this area are through the exploration of diverse patterns drawn from physiological signals, and many of these signals and features are being extracted to train and test several supervised and unsupervised emotion classification methods [8], [9], [10]. Recent studies show that autonomic affective regulation in two direction of arousal and valance is indexed by these bodily signals such as skin conductance, respiration rate, and cardiac variables, which can be measured using standard psychophysiological methods [11]. In addition, there is good evidence that physiological activity associated with psychology or mental states can be distinguished and systematically organized [12]. For example, electro-cardiovascular (ECG), blood volume pressure (BVP), and electromyogram (EMG) activities have been used to examine the dimension of pleasure, or valence\nar X\niv :1\n60 6.\n00 37\n0v 1\n[ cs\n.H C\n] 1\nJ un\n2 01\n6\n(i.e, positive and negative affect) of human subjects [13], [14]. Galvanic skin response (GSR) activity has been also shown to be associated with task engagement [15].\nAlthough human physiological response to emotion has been subject of research for several years, a deeper understanding is needed to completely describe the relation between human emotional experience and each source of biosignals [16]. In addition, many efforts have also been focused on distinguishing and classifying human emotions across a 2-dimensional theoretical well-known model within the field of physiology [17], [9], [18]; however, rather than focusing effort towards that direction, if the classifier is robust enough to detect a selected variation of discrete emotions, the differentiation across any theoretical dimension could be also achieved as an implicit task.\nOn the other hand, extracting as many features as possible and focusing the effort to improve classification accuracy at any cost, might not be the optimal approach in all cases\u2013 for instance, when attempting to implement the designed classifier in a wearable platform with very limited computing/power resources for a specific HCI application [19]. Therefore, another interesting direction to explore within the automatic emotion recognition paradigm is to enhance the optimal feature selection, feature reduction, or feature transformation methods in order to cost efficiently (in terms of power, speed, storage, etc.) exploit the related information content of human physiological signals."}, {"heading": "B. Our Contribution", "text": "The present work extracts proper attributes from EMG, BVP, and GSR signals and feeds them to an innovative fusion-based classier to decode the correlation between the emotional experiences in different affective categories and these physiological signal modalities. Fig. 1 shows these three signals during eight discrete emotional experiences recorded over 20 minutes, which are obtained from [3]. Our automatic emotion decoding approach is based on output fusion of three weak learners, each built upon features extracted from the specific physiological signal modality, EMG, BVP, or GSR. The fusion algorithm is implemented to consolidate the prediction weights obtained from each of the weak learner, which are classifiers based on the linear discriminant analysis (LDA). Furthermore, a feature selection approach based on correlation analysis is performed to reduce the complexity of the algorithm implementation while keeping the classification performance in an acceptable range.\nThis paper contribution capitalizes the effect of a fusion algorithm which extracts highly relevant attributes from each modality and fuse the prediction outputs rather than mixing all of the data at the same time into a single classifier. In addition, our proposed emotion decoding system provides the benefit of lower computational complexity by simplifying each linear weak learner through feature space dimensionality reduction by discarding highly correlated features."}, {"heading": "II. METHODOLOGY", "text": "The general scheme for evaluating our alternative suggestion for emotion recognition from diverse physiological signals is exposed in Fig. 2. Given 19-day observations (training set), the objective is to recognize the corresponding emotions from the remaining 1-day observation (test set). A 20-fold with leave one fold out cross validation algorithm was performed in order to reduce the observation-dependent predication error. Also, the current implementation was done using MATLAB R2015b."}, {"heading": "A. Database Description", "text": "The database provided in [3] for research purposes, contains recordings of four physiological signals: Electromyogram (EMG), Blood Volume Pressure (BVP), Galvanic Skin Response (GSR), and Respiration (RSP) during 8 emotional states: (1) Baseline-No emotion (N.E.), (2) Anger, (3) Hate, (4) Grief, (5) Platonic Love, (6) Romantic Love, (7) Joy, and (8) Reverence. We will use these numbers as the emotion\u2019s IDs throughout this paper.\nBody signal recordings were collected at a sampling rate of 20Hz for a 25-minute time period during 30 days (one observation recorded per day) [4]. The following sensors were used for these recording: (1) a triode electromyogram measuring facial muscle tension along the masseter; (2) a photoplethysmyograph measuring blood volume pressure placed on the tip of the ring finger of the left hand; (3) a skin\nconductance sensor measuring electrodermal activity from the middle of the three segments of the index and middle fingers on the palm-side of the left hand; and (4) a Hall effect respiration sensor placed around the diaphragm.\nThe data was recorded from a female healthy graduate student with two years of acting experience and training in visualization. The participant sat in a quiet workspace early each day, at approximately the same time of day, and tried to experience eight affective states with the aid of a Sentograph, which is a computer controlled prompting system based on the protocol for eliciting emotion developed by Clynes [4], [20]. According to [4], [20], [21], the Clynes protocol has three features that contribute to help the participant feel the emotions and make the scenario appropriate for physiological data collection: (i) it sequences eight emotions in a way that makes the transition from one emotion to another easier; (ii) it engages physical expression by asking the participant to push a finger against a button with a dual axis pressure sensor in an expressive way that also limits the introduction of motion artifacts; (iii) it prompts the participant to repeatedly express the same emotion during an approximately three minute interval, at a rate dependent on the emotion in order to intensify the emotional experience.\nApproximately, in a third of the 30 days for which the data was collected, either one or more sensors failed during some portions of the 25-minute experiment. Therefore, two overlapping datasets (I and II) were constructed from the complete or nearly-complete sessions.\nSpecifically, for the scope of the present work, we are using dataset II with 3 out of the 4 physiological signals (which are EMG, BVP, and GSR), with all the 8 emotional states previously mentioned. Dataset II is the larger dataset, comprised of 20 days in which these three sensors did not fail during any part of the experiment, and which according to [3] an average of 10% gain in emotion recognition performance was reported when compared to the dataset I. For all of these 20 days, all of the samples available for each emotion were used plus additional transitional regions to avoid the bias and to maximize the available data for training and validation purposes."}, {"heading": "B. Database Challenge", "text": "The structure of this dataset could picture a real scenario in which this work is intended to perform: an accurate emotion recognition when provided with a single observation to test the classifier accuracy. However, although the dataset II is comprised of a 20-day data collection scenario and each day represents approximately a 25-minute recording, the single observation allowed for testing turns this classification task very prone to observation-dependent errors. Therefore, we applied the leave-one-out cross validation scheme by averaging the prediction errors to correct for these errors."}, {"heading": "C. Signal Pre-processing: Filtering and Smoothing", "text": "Fig. 1 presents a graphical example of the raw and filtered signals for each physiological input given the eight emotional states under study. The description of the filtering and smoothing processes applied to each of these signals is included below:\n\u2022 EMG: This signal was filtered using a first order lowpass Butterworth filter with cutoff frequency of 10 Hz. The smoothed version of the signal was obtained by computing the average of the upper and lower envelope of the filtered signal. A detailed explanation that justifies the pertinence of using a low sampling frequency to record EMG signals is provided in [4]. \u2022 BVP: The signal was filtered using a first order lowpass Butterworth filter with cutoff frequency of 19 Hz. No envelope smoothing process was applied to avoid loss of relevant information. \u2022 GSR: The signal was filtered using a first order low-pass Butterworth filter with cutoff frequency of 19 Hz (due to the fact that GSR signals are expected to be observed at 20 Hz). After filtering, the signal was smoothed by computing the average of the upper and lower envelope of the filtered signal.\nIn order to compensate the nonlinear phase distortion introduced by the Butterworth filter, specially around the cutoff frequencies, the coefficients obtained from the original Butterworth filter were applied to the signal using a zerophase digital filter known as filtfilt in MATLAB. filtfilt\nperforms filtering by processing the input data in both the forward and reverse directions: after filtering the data in the forward direction, it reverses the filtered sequence and runs it back through the filter [22]. By this mechanism, the output signal achieves the desired zero-phase behavior. However, as stated in [22], one of the disadvantages to be noted is that filtfilt would double the order of the original Butterworth filter.\nFinally, a Min-Max scaling procedure was performed across the 20-day measurements in order to avoid the effects of human initial statics in the resulting feature space. This step is highly recommended for the robust performance of the classifier."}, {"heading": "D. Feature Extraction", "text": "According to a literature review performed from [4], [23], [24], [25], [26], [27], nine features were extracted for each physiological signal including time, frequency, statistical and spectral relevant characteristics including: (1) max value, (2) min value, (3) number of peaks, (4) mean: first statistical moment, (5) variance: second statistical moment, (6) kurtosis: forth statistical moment, (7) entropy, (8) signal power, and (9) signal spectral power."}, {"heading": "E. Classifier Design", "text": "The blocks included on the right side of Fig. 2 explain the classifier design steps. Here, the proposed approach is based on specialized weak learners for each of the three physiological signals under study (EMG, BVP, GSR). A linear discriminant analysis (LDA) classifier was implemented as the weak learner for each signal. LDA is simple to calculate from data, which implies less complexity and also is reasonably robust, even when the classes do not behave as normal distributions [28], [29]. The aim of a linear discriminant classifier is to find decision rules gi(x) in terms of the minimum total error of classification and a monotonic transformation of the posterior probabilities P (ci|x):\ngi(x) = lnP (ci|x) i = 1, ..., 8. (1)\nwhere each of the eight emotions are considered as the target class ci, and x is the set of given observation. Let\u2019s assume that each class has multivariate normal distribution and all classes have the equal covariance matrix, \u03a3, but distinct mean values, \u00b5i. By Bayes theorem, gi(x), the joint posterior probability for 8 emotions can be written as a linear system:\ngi(x) = Wio +W T i x (2)\nwhere:\nWi = \u03a3 \u22121\u00b5i\nWio = \u2212 1\n2 \u00b5i\nT \u03a3\u22121\u00b5i + lnP (ci)\nand in a single LDA classifier, x belongs to emotion class ci if gi(x) > gj(x),\u2200i 6= j.\nHowever, in our classification design, rather than concluding the emotion class ci, from each LDA-based weak learner, the output from each of the three weak learners, gis, is expressed as a weighted prediction vector of the 8 emotions that a certain physiological input is likely to be constituted of. In turn, the three weighted predictions obtained from the three weak learners are consolidated in a robust decision by means of a fusion algorithm.\nThe block diagram of the proposed fusion algorithm is presented in Fig. 3. Here, the fusion algorithm combines the individual weighted predictions from the weak learners in a likelihood weight prediction matrix, from which a mean weight prediction vector is obtained by averaging the three weights given for each emotion. In our specific case, the dimension of the likelihood weight prediction matrix is 3\u00d78 due to the 3 physiological signals under study and the 8 discrete emotions as classification outputs. Once the likelihood weight prediction matrix is built, in order to consolidate all individual decisions from the weak learners into a robust decision, the mean value across the columns of\nthis matrix is computed to obtain a mean weight vector. From this mean weight vector, a discrete emotion classification is obtained by selecting the emotion for which the maximum mean weight was found. Within this concept, the idea of prediction weights can be associated with the probability of decoding eight discrete emotions from a given multimodal physiological input."}, {"heading": "III. RESULTS", "text": "In order to demonstrate the performance of the proposed classification approach, we compared its output recognition accuracy with a traditional support vector machine (SVM) classifier implemented through different kernel functions. Table I shows the recognition results achieved by the traditional SVM classifiers, the proposed weak learners algorithm, and its corresponding variant to reduce the feature space by implementing a correlation analysis. It is important also to note that these accuracy results were obtained while applying leave-one-out cross validation technique to observe a reliable average of the classification accuracy by setting each of the 20 observations as the sample test (one at a time), while the remaining 19 observations were considered as the training set for each case."}, {"heading": "A. SVM Classifiers", "text": "As the first attempt towards decoding emotions from physiological signals, different SVM classifiers with linear, radial basis and polynomial kernel functions were implemented. The training and test sets were built up using all the extracted features from the three physiological signals. Within this traditional classifier approach where all data were mixed in a single classifier; it can be verified from Table I that the best accuracy for the traditional SVM classifier was obtained through a radial basis kernel function with 72.5% recognition accuracy. Therefore, for the following sections and result discussion, the SVM classifier with radial basis function kernel will be the one considered to represent the SVM group behavior."}, {"heading": "B. Weak Learner-Based Classifier", "text": "Our weak learner-based classification approach was tested under the same conditions as the ones described for SVM which also involved the leave-one-out cross validation scheme. As a result, an overall recognition accuracy of 88.1% was achieved as it can be corroborated in Table I."}, {"heading": "C. Feature Selection based on Correlation Analysis", "text": "In order to perform feature selection without increasing the computational complexity as when translating the feature space to other dimensions (e.g., principle component analysis (PCA)), a feature correlation analysis was performed prior passing the features to each weak learner. In our setting, feature correlation analysis computes the correlation between each pair of features in the whole set, and allows to drop those that are correlated with a factor greater than a predefined threshold.\nIn our particular case, this threshold was set to 0.8, and from a feature space of 27 features per observation per emotion, the reduced feature space resulted in 18 uncorrelated features. Note that 27 features stand for the 9 features per each of the three physiological signals under study, and all those 27 features need to be in turn computed for each of the 20 day observations during the 8 emotion segments. Under this scenario, feature reduction from 27 to 18 features per observation per emotion represents a complexity reduction.\nWithin this context, by using the reduced feature space for building the training and test sets for each weak learner, the overall accuracy was preserved to 85.0%. Note that neither PCA nor LDA provide information regarding what exact features can be removed from the feature space to reduce implementation complexity. These methods transform data to a new reduced dimensional space by computing a linear weighted combination that still considers the participation of all of the original features."}, {"heading": "D. Emotion Decoding", "text": "This subsection focuses on presenting emotion classification results towards the concept of decoding emotional states from the physiological signals as inputs. Fig. 4 shows a variant of the receiver operating characteristic (ROC) curve, which is specialized to demonstrate true positive rate (TPR)\nand false positive rate (FPR) of a multi-class classifier. TPR represents the successful classification rate of a given class (emotion), and FPR represents the corresponding misclassification rate of that class among others. From the obtained curves in Fig. 4, it is clear that the proposed weak learnerbased classifier with and without correlation analysis classifier achieve a higher TPR and lower FPR when compared to the SVM (with radial basis kernel function) approach.\nFig. 4 indicates that the following emotion categories score a TPR lower than 0.9: romantic love, joy, hate, platonic love, and reverence. Based on this outcome, we explored which emotional sources provoked the TPR to fall below 0.9.\nFig. 5 shows a detailed overview about the sources which provoked misclassification for a given target emotion. Each subplot in Fig. 5 displays the misclassification rate (MSCR) for each of the eight target emotions under analysis when compared with the other seven remaining emotions (differentiated by their IDs). Specifically in our context, for a given target emotion, MSCR means how many times each of the other emotions provoked the classifier to misclassify the target emotion as one of them. Once again, we can corroborate that our proposed algorithm outperforms SVM,\nfor which the MSCR is always higher. Table II also provides a key summary of the emotional sources of missclassification for each of the five emotions with TPR lower than 0.9. The entries of the table are organized from lower to higher TPR and from higher to lower MSCR."}, {"heading": "E. Discussion", "text": "Fig. 5 and Table II imply that the current features computed for the emotions with TPR lower than 0.9 ( romantic love, joy, hate, platonic love, reverence) are not sufficient enough to provide a meaningful distinction among these classes; and therefore, more relevant features should be computed. In turn, when the work switches towards finding relevant features to improve the distinguishability among specific classes, a misclassification analysis like the one suggested in Fig. 5 might be useful to evaluate if the new set of given features are the correct ones.\nMoreover, the benefit of providing an alternative visualization method for detecting the sources of misclassification for each emotion is of high usability when addressing the task of re-computing the feature set for a given class in order to improve individual class recognition accuracy.\nOne interesting question that arises from the physiological dataset under study, is why the LDA classifier outperforms the SVM approach? - Even when considering the case of SVM with a linear kernel function, which did not achieved the best behaviour among the different kernels tested for SVM. Since the data shows to be linearly separable, the SVM approach of mapping data into a higher dimensional space in which it would be linearly separable turns out to be redundant. If the data was already observed to be linearly separable, LDA represents a good approach towards classification without overfitting the classification model [30]. The strength of our model then is mainly due to the fusion of multiple decisions provided by different weak learners each tuned for a specific input modality."}, {"heading": "IV. CONCLUSION AND FUTURE WORK", "text": "The proposed classification approach based on specialized weak learners for each physiological signal reported a higher accuracy than the common approach of designing a unique classifier intended to learn features from all the input signals. The suggested approach also highlights modularity benefits when considering to add extra information, without increasing the complexity granted in the case of employing a single classifier.\nIn fact, the proposed fusion algorithm is an alternative boosting approach for consolidating multiple decisions provided by different weak learners in a strong classification output. By working with prediction scores as outputs of each weak learner, we are considering more than one discrete emotion that a single test input is likely to be constituted of; and this flexibility obtained from the prediction scores can be extremely relevant when a final classification decision is made by combining the criteria provided by diverse weak learners.\nFurthermore, simple methods such as feature correlation analysis can be very helpful and powerful tools at the same time when the objective is to analyze redundancy across the feature set. By performing this prior correlation study, redundant features can be pruned, meaning that a finegrained feature selection can be passed as input to each of the weak learners to improve individual classification accuracy. Feature pruning referred as feature selection is of great interest when simple learning relations among features need to be drawn for classifier implementations where the computational resources are very limited.\nIt is important to also note that the proposed feature reduction approach based on correlation analysis automatically handles the procedure of removing features. In other words, due to the fact that for each training set the suitable features might be different, the number of features that are selected for each set changes accordingly.\nFinally, a great amount of further steps are required in order to fully exploit the capabilities of the proposed system. For instance, one interesting question regarding feature selection within the correlation analysis is to include a penalization not just for redundancy of information, but for considering the case of information confusion or mismatch between features. Another interesting direction is to explore the coherence of valence and arousal dimensions in which emotions are generally explained by a theoretical model with respect to the optimal number of orthogonal dimensions that techniques such as PCA may suggest to preserve a desired amount of information within an specific variance of the data."}], "references": [{"title": "Toward machines with emotional intelligence.", "author": ["R.W. Picard"], "venue": "pp. 29\u2013", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2004}, {"title": "Predicting learning and engagement in tutorial dialogue: A personality-based model", "author": ["A.K. Vail", "J.F. Grafsgaard", "J.B. Wiggins", "J.C. Lester", "K.E. Boyer"], "venue": "pp. 255\u2013262, 2014.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "Toward machine emotional intelligence: analysis of affective physiological state", "author": ["R.W. Picard", "E. Vyzas", "J. Healey"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 23, no. 10, pp. 1175\u20131191, Oct 2001.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2001}, {"title": "Automatic recognition of boredom in video games using novel biosignal moment-based features", "author": ["D. Giakoumis", "D. Tzovaras", "K. Moustakas", "G. Hassapis"], "venue": "IEEE Transactions on Affective Computing, vol. 2, no. 3, pp. 119\u2013133, July 2011.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Automatic emotion recognition based on body movement analysis: A survey", "author": ["H. Zacharatos", "C. Gatzoulis", "Y.L. Chrysanthou"], "venue": "IEEE Computer Graphics and Applications, vol. 34, no. 6, pp. 35\u201345, Nov 2014.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "A framework for automatic human emotion classification using emotion profiles", "author": ["E. Mower", "M.J. Mataric", "S. Narayanan"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 19, no. 5, pp. 1057\u20131070, July 2011.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2011}, {"title": "Nonlinear appraisal modeling: An application of machine learning to the study of emotion production", "author": ["B. Meuleman", "K.R. Scherer"], "venue": "IEEE Transactions on Affective Computing, vol. 4, no. 4, pp. 398\u2013411, Oct 2013.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "Emotion classification based on bio-signals emotion recognition using machine learning algorithms", "author": ["E.H. Jang", "B.J. Park", "S.H. Kim", "M.A. Chung", "M.S. Park", "J.H. Sohn"], "venue": "vol. 3, pp. 1373\u20131376, April 2014.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Emotion recognition based on multi-variant correlation of physiological signals", "author": ["W. Wen", "G. Liu", "N. Cheng", "J. Wei", "P. Shangguan", "W. Huang"], "venue": "IEEE Transactions on Affective Computing, vol. 5, no. 2, pp. 126\u2013140, April 2014.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Inferring psychological significance from physiological signals", "author": ["J.T. Cacioppo", "L.G. Tassinary"], "venue": "American Psychologist, vol. 45, no. 1, pp. 16\u201328, 1990.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1990}, {"title": "Emotion and motivation", "author": ["M.M. Bradley", "P.J. Lang"], "venue": "Handbook of psychophysiology, vol. 2, pp. 602\u2013642, 2000.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2000}, {"title": "Principles of psychophysiology: Physical, social and inferential elements, chapter the cardiovascular system", "author": ["J. Papillo", "D. Shapiro"], "venue": "1990.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1990}, {"title": "Social isolation and health, with an emphasis on underlying mechanisms", "author": ["J.T. Cacioppo", "L.C. Hawkley"], "venue": "Perspectives in biology and medicine, vol. 46, no. 3, pp. S39\u2013S52, 2003.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2003}, {"title": "The affective significance of skin conductance activity during a difficult problem-solving task", "author": ["A. Pecchinenda"], "venue": "Cognition & Emotion, vol. 10, no. 5, pp. 481\u2013504, 1996.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1996}, {"title": "Is there consistency and specificity of autonomic changes during emotional episodes? guidance from the conceptual act theory and psychophysiology", "author": ["K.S. Quigley", "L.F. Barrett"], "venue": "Biological psychology, vol. 98, pp. 82\u201394, 2014.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "Recognizing emotions induced by affective sounds through heart rate variability", "author": ["M. Nardelli", "G. Valenza", "A. Greco", "A. Lanata", "E.P. Scilingo"], "venue": "IEEE Transactions on Affective Computing, vol. 6, no. 4, pp. 385\u2013394, Oct 2015.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Bio-inspired wearable computing architecture and physiological signal processing for onroad stress monitoring", "author": ["S. Conjeti", "R.R. Singh", "R. Banerjee"], "venue": "pp. 479\u2013482, Jan 2012.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2012}, {"title": "Toward machine emotional intelligence: Analysis of affective physiological state", "author": ["R.W. Picard", "E. Vyzas", "J. Healey"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 23, no. 10, pp. 1175\u20131191, 2001.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2001}, {"title": "The psychophysiology of emotion", "author": ["J.T. Cacioppo", "G.G. Berntson", "J.T. Larsen", "K.M. Poehlmann", "T.A. Ito"], "venue": "Handbook of emotions,  vol. 2, pp. 173\u2013191, 2000.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2000}, {"title": "Finger-pressure waveforms measured on clynes\u2019 sentograph distinguished among emotions", "author": ["H. Hama", "K. Tsuda"], "venue": "Perceptual and Motor Skills, vol. 70, no. 2, pp. 371\u2013376, 1990.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1990}, {"title": "Affective man-machine interface: unveiling human emotions through biosignals", "author": ["E.L. Van Den Broek", "V. Lis\u1ef3", "J.H. Janssen", "J.H. Westerink", "M.H. Schut", "K. Tuinenbreijer"], "venue": "pp. 21\u201347, 2009.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2009}, {"title": "Multimodal fusion framework: A multiresolution approach for emotion classification and recognition from physiological signals", "author": ["G.K. Verma", "U.S. Tiwary"], "venue": "NeuroImage, vol. 102, Part 1, pp. 162 \u2013 172, 2014, multimodal Data Fusion. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S1053811913010999", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "Using ensemble classifier systems for handling missing data in emotion recognition from physiology: one step towards a practical system", "author": ["C. Setz", "J. Schumm", "C. Lorenz", "B. Arnrich", "G. Tr\u00f6ster"], "venue": "pp. 1\u20138, 2009.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2009}, {"title": "Emotion assessment: Arousal evaluation using eegs and peripheral physiological signals", "author": ["G. Chanel", "J. Kronegg", "D. Grandjean", "T. Pun"], "venue": "Multimedia content representation, classification and security, pp. 530\u2013537, 2006.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2006}, {"title": "Multimodal emotion recognition in response to videos", "author": ["M. Soleymani", "M. Pantic", "T. Pun"], "venue": "IEEE Transactions on Affective Computing, vol. 3, no. 2, pp. 211\u2013223, April 2012.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2012}, {"title": "Pattern classifiers methods and algorithms", "author": ["L. Kuncheva"], "venue": "pp. 45\u201346, 2004.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2004}, {"title": "Pattern classification, 2nd edition", "author": ["R. Duda", "P. Hart", "D. Stork"], "venue": "pp. 215\u2013218, 2001.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2001}, {"title": "On the design and analysis of the privacypreserving svm classifier", "author": ["K.P. Lin", "M.S. Chen"], "venue": "IEEE Transactions on Knowledge and Data Engineering, vol. 23, no. 11, pp. 1704\u20131717, Nov 2011.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": "less exacerbating behaviors in Human-Computer Interaction (HCI) applications [1].", "startOffset": 77, "endOffset": 80}, {"referenceID": 1, "context": "In [2], a facial recognition software has been introduced to detect specific feelings of students", "startOffset": 3, "endOffset": 6}, {"referenceID": 2, "context": "As authors concluded in [4], much work remains before emotion interpretation by machine intelligence can occur at the level of human abilities.", "startOffset": 24, "endOffset": 27}, {"referenceID": 3, "context": "Automatic emotion recognition is a field that has gained a lot of attention in the past few decades [5], [6], [7].", "startOffset": 100, "endOffset": 103}, {"referenceID": 4, "context": "Automatic emotion recognition is a field that has gained a lot of attention in the past few decades [5], [6], [7].", "startOffset": 105, "endOffset": 108}, {"referenceID": 5, "context": "Automatic emotion recognition is a field that has gained a lot of attention in the past few decades [5], [6], [7].", "startOffset": 110, "endOffset": 113}, {"referenceID": 6, "context": "of diverse patterns drawn from physiological signals, and many of these signals and features are being extracted to train and test several supervised and unsupervised emotion classification methods [8], [9], [10].", "startOffset": 198, "endOffset": 201}, {"referenceID": 7, "context": "of diverse patterns drawn from physiological signals, and many of these signals and features are being extracted to train and test several supervised and unsupervised emotion classification methods [8], [9], [10].", "startOffset": 203, "endOffset": 206}, {"referenceID": 8, "context": "of diverse patterns drawn from physiological signals, and many of these signals and features are being extracted to train and test several supervised and unsupervised emotion classification methods [8], [9], [10].", "startOffset": 208, "endOffset": 212}, {"referenceID": 9, "context": "and valance is indexed by these bodily signals such as skin conductance, respiration rate, and cardiac variables, which can be measured using standard psychophysiological methods [11].", "startOffset": 179, "endOffset": 183}, {"referenceID": 10, "context": "In addition, there is good evidence that physiological activity associated with psychology or mental states can be distinguished and systematically organized [12].", "startOffset": 158, "endOffset": 162}, {"referenceID": 11, "context": "e, positive and negative affect) of human subjects [13], [14].", "startOffset": 51, "endOffset": 55}, {"referenceID": 12, "context": "e, positive and negative affect) of human subjects [13], [14].", "startOffset": 57, "endOffset": 61}, {"referenceID": 13, "context": "shown to be associated with task engagement [15].", "startOffset": 44, "endOffset": 48}, {"referenceID": 14, "context": "derstanding is needed to completely describe the relation between human emotional experience and each source of biosignals [16].", "startOffset": 123, "endOffset": 127}, {"referenceID": 15, "context": "In addition, many efforts have also been focused on distinguishing and classifying human emotions across a 2-dimensional theoretical well-known model within the field of physiology [17], [9], [18]; however, rather than", "startOffset": 181, "endOffset": 185}, {"referenceID": 7, "context": "In addition, many efforts have also been focused on distinguishing and classifying human emotions across a 2-dimensional theoretical well-known model within the field of physiology [17], [9], [18]; however, rather than", "startOffset": 187, "endOffset": 190}, {"referenceID": 16, "context": "In addition, many efforts have also been focused on distinguishing and classifying human emotions across a 2-dimensional theoretical well-known model within the field of physiology [17], [9], [18]; however, rather than", "startOffset": 192, "endOffset": 196}, {"referenceID": 17, "context": "puting/power resources for a specific HCI application [19].", "startOffset": 54, "endOffset": 58}, {"referenceID": 2, "context": "Body signal recordings were collected at a sampling rate of 20Hz for a 25-minute time period during 30 days (one observation recorded per day) [4].", "startOffset": 143, "endOffset": 146}, {"referenceID": 2, "context": "experience eight affective states with the aid of a Sentograph, which is a computer controlled prompting system based on the protocol for eliciting emotion developed by Clynes [4], [20].", "startOffset": 176, "endOffset": 179}, {"referenceID": 18, "context": "experience eight affective states with the aid of a Sentograph, which is a computer controlled prompting system based on the protocol for eliciting emotion developed by Clynes [4], [20].", "startOffset": 181, "endOffset": 185}, {"referenceID": 2, "context": "According to [4], [20], [21], the Clynes protocol has three features that contribute to help the participant feel the emotions and make the scenario appropriate for physiological", "startOffset": 13, "endOffset": 16}, {"referenceID": 18, "context": "According to [4], [20], [21], the Clynes protocol has three features that contribute to help the participant feel the emotions and make the scenario appropriate for physiological", "startOffset": 18, "endOffset": 22}, {"referenceID": 19, "context": "According to [4], [20], [21], the Clynes protocol has three features that contribute to help the participant feel the emotions and make the scenario appropriate for physiological", "startOffset": 24, "endOffset": 28}, {"referenceID": 2, "context": "A detailed explanation that justifies the pertinence of using a low sampling frequency to record EMG signals is provided in [4].", "startOffset": 124, "endOffset": 127}, {"referenceID": 2, "context": "According to a literature review performed from [4], [23], [24], [25], [26], [27], nine features were extracted for each physiological signal including time, frequency, statistical and", "startOffset": 48, "endOffset": 51}, {"referenceID": 20, "context": "According to a literature review performed from [4], [23], [24], [25], [26], [27], nine features were extracted for each physiological signal including time, frequency, statistical and", "startOffset": 53, "endOffset": 57}, {"referenceID": 21, "context": "According to a literature review performed from [4], [23], [24], [25], [26], [27], nine features were extracted for each physiological signal including time, frequency, statistical and", "startOffset": 59, "endOffset": 63}, {"referenceID": 22, "context": "According to a literature review performed from [4], [23], [24], [25], [26], [27], nine features were extracted for each physiological signal including time, frequency, statistical and", "startOffset": 65, "endOffset": 69}, {"referenceID": 23, "context": "According to a literature review performed from [4], [23], [24], [25], [26], [27], nine features were extracted for each physiological signal including time, frequency, statistical and", "startOffset": 71, "endOffset": 75}, {"referenceID": 24, "context": "According to a literature review performed from [4], [23], [24], [25], [26], [27], nine features were extracted for each physiological signal including time, frequency, statistical and", "startOffset": 77, "endOffset": 81}, {"referenceID": 25, "context": "LDA is simple to calculate from data, which implies less complexity and also is reasonably robust, even when the classes do not behave as normal distributions [28], [29].", "startOffset": 159, "endOffset": 163}, {"referenceID": 26, "context": "LDA is simple to calculate from data, which implies less complexity and also is reasonably robust, even when the classes do not behave as normal distributions [28], [29].", "startOffset": 165, "endOffset": 169}, {"referenceID": 27, "context": "cation without overfitting the classification model [30].", "startOffset": 52, "endOffset": 56}], "year": 2016, "abstractText": "There is an increasing consensus among researchers that making a computer emotionally intelligent with the ability to decode human affective states would allow a more meaningful and natural way of human-computer interactions (HCIs). One unobtrusive and non-invasive way of recognizing human affective states entails the exploration of how physiological signals vary under different emotional experiences. In particular, this paper explores the correlation between autonomically-mediated changes in multimodal body signals and discrete emotional states. In order to fully exploit the information in each modality, we have provided an innovative classification approach for three specific physiological signals including Electromyogram (EMG), Blood Volume Pressure (BVP) and Galvanic Skin Response (GSR). These signals are analyzed as inputs to an emotion recognition paradigm based on fusion of a series of weak learners. Our proposed classification approach showed 88.1% recognition accuracy, which outperformed the conventional Support Vector Machine (SVM) classifier with 17% accuracy improvement. Furthermore, in order to avoid information redundancy and the resultant over-fitting, a feature reduction method is proposed based on a correlation analysis to optimize the number of features required for training and validating each weak learner. Results showed that despite the feature space dimensionality reduction from 27 to 18 features, our methodology preserved the recognition accuracy of about 85.0%. This reduction in complexity will get us one step closer towards embedding this human emotion encoder in the wireless and wearable HCI platforms.", "creator": "LaTeX with hyperref package"}}}