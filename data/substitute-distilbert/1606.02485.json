{"id": "1606.02485", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jun-2016", "title": "Exploring Implicit Human Responses to Robot Mistakes in a Learning from Demonstration Task", "abstract": "as you enter human environments, they none be expected but accomplish a tremendous range of tasks. it is not comfortable for robot designers to pre - program correct behaviors or publish them in advance, so one way towards address this is through end - user communications, such as via learning from demonstration ( lfd ). and computer work has initially done on the mechanics of enabling robot learning from human teachers, one unexplored aspect is indicating mutual feedback between both the human teacher and robot during the learning process, i. e., implicit learning. in this paper, we explore one aspect of this mutual interactions, grounding sequences, where both a human and robot provide non - verbal feedback to signify their true understanding during interaction. we conducted a study regarding people painted an autonomous humanoid robot a dance, and performed gesture analysis to measure viewer's responses to the robot during correct and incorrect demonstrations.", "histories": [["v1", "Wed, 8 Jun 2016 10:07:01 GMT  (4615kb,D)", "http://arxiv.org/abs/1606.02485v1", "7 pages, 2 figures, IEEE RO-MAN 2016, IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN 2016)"]], "COMMENTS": "7 pages, 2 figures, IEEE RO-MAN 2016, IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN 2016)", "reviews": [], "SUBJECTS": "cs.RO cs.AI cs.HC", "authors": ["cory j hayes", "maryam moosaei", "laurel d riek"], "accepted": false, "id": "1606.02485"}, "pdf": {"name": "1606.02485.pdf", "metadata": {"source": "CRF", "title": "Exploring Implicit Human Responses to Robot Mistakes in a Learning from Demonstration Task", "authors": ["Cory J. Hayes", "Maryam Moosaei", "Laurel D. Riek"], "emails": ["chayes3@nd.edu", "mmoosaei@nd.edu", "lriek@nd.edu"], "sections": [{"heading": null, "text": "I. INTRODUCTION\nRobots are becoming more commonplace in human environments, such as schools, homes, hospitals, and work settings, and are expected to accomplish a wide variety of tasks. Given the near infinite number of tasks robots might be expected to perform in these varied settings, it is not feasible for robot designers to completely pre-program machines before they are deployed. Many researchers have suggested this problem can be addressed via end-user robot programming, where users can modify and create new behaviors for their robot to best suit their needs and preferences [2], [1].\nLearning from demonstration (LfD) is one such method that enables people to readily develop custom robot behavior [2]. In LfD, a learner automatically creates a mapping between states and actions by watching a teacher perform the task; the learner can then replicate the teacher\u2019s actions. The main benefit of LfD is that it is an intuitive way for people to teach robots and does not require the teacher to have highly specialized knowledge, such as the ability to directly program the robot [3].\nThere has been significant research in how to design and implement LfD systems, including how people want to teach robots. Work by Thomaz et al. [23] showed that LfD systems could be improved for both the teacher and learner if greater communicative channels could be employed during the learning process. We build upon this work, and specifically are interested in ways to enable human teachers to have more efficient and naturalistic interactions, by way of a common human-human interaction (HHI) phenomena: grounding sequences.\n1Department of Computer Science & Engineering, University of Notre Dame, IN, USA {chayes3,mmoosaei,lriek}@nd.edu\nA grounding sequence is a communicative interchange between a speaker and addressee. In this exchange, both parties continually provide feedback within the conversation, which enables them to signify whether or not there is a mutual understanding of a topic [8]. Grounding occurs continuously within each moment in conversation, and is not solely confined to pauses in dialogue [4]. It is a three-part sequence that occurs when 1) a speaker makes a statement or asks a question, 2) the addressee provides a verbal or nonverbal signal in response to what the speaker has said, and 3) the speaker acknowledges this display (See Fig. 1).\nDuring a grounding sequence, the speaker does not simply notice the signal from the addressee and continue talking, but must also acknowledge the signal from the listener by providing an observable behavior in response [6]. Grounding is completed when both the speaker and addressee believe that there is a mutual understanding of what has been said.\nClark and Brennan [8] discuss three classes of responses that are used to show positive evidence of grounding. The first type is acknowledgement, where back-channel responses, such as a head nod or verbal utterance, is provided by the listener while the speaker is talking. The second type of response is the relevant next turn where the speaker gives the listener the chance to directly respond to what has been said, such as asking a question. The third type of response is continued attention, where the listener may look away from the speaker and in turn, and the speaker responds by changing his/her dialogue to recapture the attention of the listener. In this paper, we focus on the first type of response, acknowledgement.\nThere have been few studies that have explored the effects of robots generating aspects of grounding sequences in human-robot interaction (HRI). Sidner et al. [22] performed a study where a conversational robot nodded in response to head nods by participants, and found that people nodded more when the robot performed this action. Krosager et al. [13] explored the use of nodding as a back-channel response to a human speaker, and found that the physical presence of the robot had a significant impact on user perception when\nar X\niv :1\n60 6.\n02 48\n5v 1\n[ cs\n.R O\n] 8\nJ un\n2 01\n6\ncompared to using a virtual agent. Others have explored grounding from the perspective of gaze cues and discourse [7], [15], [16], [19].\nSince the concept of grounding focuses on mutual understanding, it can also be used to facilitate interactions with robots when they are given a task; this can be especially useful to correct robot mistakes that negatively impact users [24]. If the user is aware that the robot does not understand a command, the user can adjust the command delivery accordingly [12]. Conversely, if a robot is able to detect backchannel feedback from a human, it would be possible for the robot to automatically adjust its behavior, without requiring explicit human feedback. Giving robots the ability to learn from both implicit and explicit feedback may lead more natural and less frustrating interactions by reducing the current complete burden placed on human teachers.\nFurthermore, we can uncover principles that would assist in the development of policies to detect, classify, and make robot behavioral decisions based on implicit human feedback. This point motivates the study described in this paper. Our objective is to observe human behavior during an LfD interaction involving robot mistakes to eventually enable robots to automatically detect when these mistakes occur.\nIntuitively, there is likely a detectable difference in the behaviors people express when robots are performing tasks correctly compared to when they are making mistakes. The study in this paper focuses on the first step towards creating such a policy: observing what behaviors arise.\nIn this paper, we explore the occurrences of implicit human feedback in a recorded LfD scenario where a human teaches an autonomous humanoid robot (DARwIn-OP) to perform a dance. The robot detects dance movements from the human teacher and replicates the movements either correctly or incorrectly. Two independent coders performed a gestural analysis [5] of participant\u2019s implicit feedback conveyed to the robot, such as via head movements, facial expressions, eye gaze, and body postures. Additionally, we gathered qualitative feedback from participants which informed us of ways to further enable human teachers. We discuss these findings in Section III, and their implication and use for the HRI community in Section IV."}, {"heading": "II. METHODOLOGY", "text": "We conducted an LfD-centered study to uncover the relationship between a robot\u2019s behavior in the first stage of a grounding sequence, and a human\u2019s response in the second stage. This study is a within-subjects design, where each participant interacts with a robot that performs both correct and incorrect behaviors throughout the interaction.\nThis partial grounding sequence occurs while the robot is demonstrating the moves it has learned from the human teacher. The first stage of the sequence is the robot\u2019s nonverbal demonstration of a dance move. The second stage of the sequence is the nonverbal backchannel feedback the human teacher provides while the robot is performing dance moves. We say that our grounding sequence is partial because the third stage where the robot responds to human backchannel\nfeedback does not occur in the current implementation of our study. Instead, our main objective is to help inform the third stage of this grounding sequence.\nIn the study, participants taught a robot the \u201cHokey Pokey\u201d dance. This is a common dance performed by children in North America, and we chose it for two reasons. First, due to its repetitive nature, it seemed that it would be easy to learn and recall. We wanted to maximize the user\u2019s focus on the robot and less on recalling the mechanics of the task. Second, we wanted to limit the number of true errors participants made, as we employed intentional errors during learning.\nAfter considering the motion capabilities of our robot, the final dance consisted of the following sequence: limb in, limb out, limb in, limb shake, hokey pokey. For \u201climb in\u201d, the participant extends the respective limb towards the robot. For \u201climb out\u201d, the person returns to his or her default standing position. \u201cLimb shake\u201d is performed by making wide and repeated horizontal movements with the extended limb. Lastly, \u201chokey pokey\u201d consists of the person raising both arms above his or her head and shaking them side to side for a few seconds (See right portion of Fig. 2). This sequence is conducted across all four limbs (left arm, right arm, left leg, right leg)."}, {"heading": "A. Programming and Setup", "text": "Our LfD setup combined the capabilities of a DARwInOP humanoid robot and a Microsoft Kinect v2 sensor. Using a platform, the robot was positioned in a standing position on a table facing the participant at reasonable human height, as shown in the left side of Fig. 2.\nWe created a custom program that automated the interaction through the detection of specific participant movements and basic speech recognition. The Kinect sensor was placed at the base of the robot to limit distraction of its presence, while also being in a position that could reliably collect measurements of participant movements. Based on participant actions detected through 3D point tracking of skeletal joints, the Kinect program compiled robot actions and forwarded commands wirelessly to a custom C++ program running on the robot. Participant actions were limited to a set of positions associated with the dance; the program did not respond to any actions outside of this set.\nTwo RGB cameras were placed in the room to record the interaction. One camera was placed a few feet from the robot, facing the participant with the intention to record facial movements. The second camera was placed behind the participant, facing the robot to supplement the first camera. From this viewpoint, the second camera was able to see both the participant and the robot."}, {"heading": "B. Recruitment", "text": "We recruited 11 local participants via emails and word-ofmouth, 7 women, 4 men. All participants were native English speakers, and had resided in the United States for an average of 25.64 years (s.d. = 11.16 years). We recruited from this demographic to help ensure prior familiarity with the dance\ngiven the way it was implemented in this study. Participants were 27.09 years old on average (s.d. = 9.47).\nSince our study focuses on instinctive responses to robot mistakes, we did not inform participants of this true purpose out of concern that this knowledge would influence participant behavior. Therefore, the advertised purpose of this study to participants was that we were determining how effectively a person could teach a robot via a LfD task, regardless of their technical background."}, {"heading": "C. Preliminary Tasks", "text": "Prior to the interaction with the robot, each participant completed consent and demographics forms, and were given instructions for the study. To supplement the instruction form, participants also watched a tutorial video depicting an actor teaching the same robot the full dance. In the video, the actor performs the dance and demonstrates what actions to take when the robot performs the dance correctly and when it makes a mistake. Though the video teaches participants how to correct the robot, it does not show the robot making any mistakes or the human actor responding to robot actions beyond demonstrating the dance. At the end of the tutorial video, each participant was instructed to stand facing the robot from a distance of roughly 5-7 feet and the interaction began."}, {"heading": "D. Learning from Demonstration Task", "text": "The LfD dance portion consisted of two stages: training and teaching. We separated the interaction into two stages to give participants the opportunity to learn the dance, as it was implemented for the study, before teaching the robot.\n1) Training: The purpose of the training stage was to allow the participant to practice performing the Hokey Pokey dance moves and have these moves recognized by the Kinect. Participants initiated this stage by raising both arms out from the sides of their bodies in a \u201cT\u201d fashion. A voiced Kinect program directed participants by stating the move to perform and notified the participant if they did the move correctly or incorrectly. Though the robot is present during this stage, it does not make any signs of activity. At the conclusion of the training stage, the participant is instructed by the Kinect program to once again raise both arms out from their sides to begin teaching the robot.\n2) Teaching: Once the participant raises both arms the second time, the DARwIn-OP robot greets the participant by thanking them for their time and stating that it is ready to learn the dance. The Kinect program did not provide any audio output to show activity in this phase similar to how the robot did not make any signs of activity during the training phase. In this stage, the participant teaches the robot the Hokey Pokey dance one movement at a time. After seeing a movement, the robot gives verbal confirmation that it has processed the performed action and that the participant may continue on with the next movement. Participants are informed by both the instruction form and the tutorial video that the \u201chokey pokey\u201d action, which completes the movement sequence for a limb, is a signal for the robot to attempt all of what it has learned so far.\nWhen the robot sees the \u201chokey pokey\u201d action, it announces to the participant that it has detected this movement, will now attempt the dance, and asks the participant to watch it. After performing as much of the dance that it has learned, the robot asks the participant if it did the dance correctly, who in turns responds with a verbal \u201caffirmative\u201d or \u201cnegative\u201d. If the participant says \u201caffirmative\u201d, the robot asks which limb it will learn next, in which case the participant sticks out a new limb, waits for the robot\u2019s confirmation, returns to their default standing position, waits for another confirmation, and then begins teaching the movements. Similarly, if the participant says \u201cnegative\u201d, the same sequence occurs with the exception being that the presented limb is one that has already been taught.\nAs described earlier, our LfD system is designed to repeat any recognized participant movements, regardless of their order, for the purpose of simulating a true LfD scenario. The system is also designed to intentionally make a single apparent mistake during the interaction through a pronounced modification of detected movements. For the intended mistake, the system randomly decides between either adding 3 additional movements for a single limb sequence (e.g. a sequence such as limb in, out, in, shake, hokey pokey would become limb in, out, in, out, in, out, shake, hokey pokey) or performing just a single movement and immediately going to the \u201chokey pokey\u201d action. The second type of intended mistake can only occur if the limb movement sequence contained at least three actions, not counting the hokey\npokey, in order for the truncated move sequence to be noticeable.\nFrom initial testings of the dance interaction, we discovered that we could not reliably pinpoint the exact moments of the interaction where participants observed a robot mistake. There were instances where there were delayed responses to these mistakes as well as ones where mistakes were completely ignored either willingly to progress or mistakenly due to confusion. Therefore, we set the granularity of identifying mistakes on a per limb basis instead of a per movement basis. If a participant identifies a mistake while the robot performs movements for a specific limb, we consider all behavioral responses observed during that limb demonstration to be associated to robot mistakes; the same applies for correct robot behavior.\nSince one of our objectives is to explore the behaviors that arise when the robot performs correct and incorrect actions, coders split their behavioral action counts into three intervals for comparisons. The first interval is the \u201cCorrect Interval\u201d, which represents the accumulation of all time intervals per participant where the robot does the correct dance moves for a limb. The second is the \u201cIncorrect Interval\u201d, which is the accumulation of the time frames where the robot makes a mistake, identified by the participant afterwards. The third is a \u201cConfirmation Interval\u201d to represent the times where the robot asks the participant if it has correctly performed the dance, but before the participant gives their verbal response."}, {"heading": "E. Post-Interaction", "text": "After the robot correctly learned one full iteration of the dance, the interaction ended. Participants were then given an online survey that asked four questions about their perceived teaching abilities during the interaction and the robot\u2019s learning abilities. Finally, the participants were given a debriefing form that described the true purpose of the study and a $5 gift card."}, {"heading": "F. Measurement", "text": "Two independent coders employed gestural analysis to label participant interactions using both deductive and inductive coding steps. Deductive coding means that the coders had previous assumptions about the behaviors that would occur in the interaction before conducting the experiment. For example, one would reasonably assume participants would smile, frown, avert their glance, etc. at some point during the interaction. Inductive coding means that coders did not have assumptions prior to conducting the experiment, and created a coding scheme based on observations.\nThe coders viewed the participant videos and annotated all occurrences of the targeted behaviors during each instance of the robot demonstrating the dance until the participant gives the verbal confirmation to the robot at the end of a dance sequence; these annotations did not include behaviors that occurred while the participant was explicitly instructing the robot as they were trained to do. The coders then categorized the codes (behavior types) into specific hierarchies consisting of gross limb movements, facial movements, self-adaptors,\nand body postures. They subsequently discussed and resolved any disagreements between codes after analysis, and the recorded data had high inter-rater reliability (k-alpha = .937) as calculated on a subset of the data [11].\nWe focused on the nonverbal, human backchannel feedback and attentiveness behaviors shown in Table I with the corresponding action units from the Facial Action Coding System (FACS) [9].\nIt is worth noting that for this study, coders focused solely on easily observable human responses to robot behavior, and did not attempt to attribute them to any high-level cognitive or emotional states. While there has been previous work done in affective computing and HRI regarding inferring emotions during interaction (c.f., [18], [14], this seemed out of scope and overly restrictive for the current study.\nWe also did not analyze self-adaptors, which are behavioral responses commonly used to mitigate anxiety, stress, and other emotions [17]. Examples include scratching, selfgrooming, and throat clearing.\nFurthermore, because participants stand in one place throughout the length of our interaction, it is not surprising that frequent body repositioning would happen often, which is more likely to lead to self-adaptive behavior."}, {"heading": "III. RESULTS", "text": "Detailed analysis of participants\u2019 nonverbal behavior during interaction with the robot revealed several notable features. Averages of the raw data per category are reported in Table II."}, {"heading": "A. General findings", "text": "1) Individual differences in participant expressiveness: Observations of the recorded videos served as a reminder that individual differences in expressiveness is an important factor to consider when studying human behavior. While most participants displayed a reasonable number of observable behaviors (avg. of 31.91 responses detected per participant) across all three intervals, a few behaved in surprising ways.\nFor example, three participants conveyed hardly any of the behaviors in our coding scheme, even when they identified robot mistakes (\u00a112 responses each). They mostly stood still with the same posture and expressions throughout the all robot demonstration instances. It was very difficult to predict their response during the confirmation interval due to the lack of feedback. On the other end, one participant was substantially more expressive than all of the other participants (77.5 responses detected), and it was fairly easy to anticipate whether there would be a \u201cnegative\u201d or \u201caffirmative\u201d confirmation.\n2) Participant attentiveness: As the interactions progressed, we noticed that some participants paid less attention to the robot after it made at least one mistake. For example, one participant looked away from the robot throughout the entirety of it correctly performing the movements for a specific limb. Two participants retrieved and focused on an item while the robot was demonstrating a portion of the dance, with one participant removing an item from their pocket and the other grabbing the paper instruction form that was left on a desk a few feet behind them.\nWe suspect this behavior can be attributed to either boredom or frustration with a failing robot; however, as we did not analyze emotions in this study it is not possible to state this with certainty. Informally, three participants verbally mentioned to the researcher that they were frustrated at some point during the interaction.\n3) Gesture Congruency: Overall, the behaviors demonstrated by participants were congruous with their verbal confirmations. For example, participants who smiled and nodded along with the robot during a demonstration would typically respond with an \u201caffirmative\u201d when the robot asked if it had performed the dance correctly. Similarly, participants who shook their head, frowned, lowered their head with an averted gaze, or closed their eyes for an extended amount of time would typically respond with a \u201cnegative\u201d for the following robot query.\nHowever, there was one notable example of a participant displaying incongruent behavior that did not match our anticipated response. During one robot demonstration, the participant had a frown that lasted for a few seconds, sighed, closed their eyes for a couple of seconds, glanced away from the robot, and then frowned again with another glance.\nHowever, the participant responded with an \u201caffirmative\u201d when the robot asked about its correctness.\n4) Head Nodding: We also noticed parts of nonverbal grounding sequences for six out of eleven participants, with the primary action being head nods. These sequences rarely occurred at the beginning of the interaction, but became more common as the interaction progressed, especially after a robot made a mistake. For example, one participant displayed an increased focus on the robot, with fewer glances away, while it attempted dance movements on a limb which it had previously made a mistake on. After each movement for this specific limb, the participant nodded their head to acknowledge the correction; however, once the robot made a mistake again, this feedback ended."}, {"heading": "B. Questionnaire Results", "text": "Participants also completed a post-interaction questionnaire which asked them to reflect on their experiences interacting with the robot. These responses are summarized below.\n1) Beliefs about being a good teacher: Nearly all participants (9/11) responded affirmatively to the question, Do you believe you were a good teacher during the interaction with the robot? Why or why not?. Four participants stated they were good teachers because they believed they were patient with the robot throughout the interaction. Another participant responded similarly, but noted that their patience had waned substantially towards the end of the interaction.\nTwo participants responded negatively to this question, and stated that the robot did not seem to learn the dance. Four participants partially attributed the robot\u2019s failures to their own perceived errors during demonstrations, such as accidentally skipping a dance move or not clearly demonstrating a move to the robot.\n2) Theory of robot\u2019s mind during learning: Participants were asked, While you were teaching the robot the Hokey Pokey, did you have an idea of how well the robot understood what you were doing and saying? In other words, if the robot could \u201cthink\u201d like a person does, do you believe you could perceive these thoughts? What did the robot do to make you believe or not believe you could perceive its thoughts?.\n72% of participants (8/11) reported that they thought the robot understood the dance movements fairly well until it made its first mistake. Five participants noted that the robot\u2019s verbal feedback after each movement demonstration made them believe the robot had a good understanding until mistakes occurred. This verbal feedback simply consisted of utterances such as \u201calright\u201d, \u201cok\u201d, or \u201chmm\u201d followed by a direct request to continue to the next dance move.\nOne participant stated, \u201cNo, it didn\u2019t feel like he fully understood what I was doing and saying. But then again, I don\u2019t think I could perceive its thoughts if it had any. The main thing that made me not believe it was that once I changed my inflection on the word affirmative, and it didn\u2019t react to my voice at all.\u201d\n3) Ways the robot could better facilitate teaching: Participants were asked, What other actions could the robot\nhave done to help you be a more effective teacher?. Participants provided several informative suggestions. First, they suggested it would be helpful to be able to interrupt the robot when it made a mistake while demonstrating the dance. \u201cIt [would be better if it didn\u2019t repeat] the whole dance when it was wrong and only the limb that it had a problem with. I would lose focus and get distracted as it repeated the good parts again and then wonder if I had missed a mistake.\u201d\nSecond, participants requested the robot give more realtime feedback beyond the simple verbal utterances throughout the interaction. They suggested this could help give them better awareness of where they were in the teaching process, and also could reduce frustration. Examples discussed were the robot verbally or visually conveying this information by either stating the limb it had recognized or visually displaying this on a screen.\nFinally, another suggestion was that it would be helpful for the robot to mimic their actions in real time so they could more directly repair a mistake when it occurred. \u201cMaybe [it could] do the movements along with me so I know that it is understanding as we go along.\u201d\nThe responses to this question and the previous one address the secondary grounding sequence we focused on to enrich an interaction, where 1) the human teacher demonstrates an action, 2) the robot responds through backchannel feedback, and 3) the teacher acknowledges this feedback.\n4) Awareness of the true research objective: As mentioned in Section I, the advertised purpose of the study differed from the true purpose due to its nature. The researcher verbally asked each participant whether they realized the study\u2019s true intention at any point before being debriefed. None of the participants were aware of this true objective. One participant, with a background in psychology, expressed awareness that there may have been an ulterior motive behind the study, but was not able to determine this motive."}, {"heading": "IV. DISCUSSION", "text": "Grounding sequences are an important aspect of face-toface communication, and might prove invaluable in humanrobot interaction. One clear way to incorporate grounding sequences into HRI scenarios is within the space of LfD. Future policies could be created which enable robots to implicitly learn from their human teachers by perceiving their gross motor movements and facial expressions. While this is not always practical from a sensing perspective (occlusion, lighting, etc), it may be straightforward to build systems that can sense simple cues from participants.\nThe behaviors specified in our coding scheme can serve as a reasonable starting point for robot designers interested in pursuing this path. Given participants\u2019 individual differences (and our participant pool), it is not wise to make grand generalizations; however, it does seem that from our data, head nods and smiles appear to commonly be seen during confirmatory teaching sequences, and frowns and head shakes during incorrect ones.\nGlancing away from the robot also seemed to be a meaningful communicative signal during teaching, which aligns\nwith other HRI work [16]. However, it can also mean a person is accessing information, or is bored or disengaged. Additional work is needed to understand gaze cues within the context of robot teachers. A policy may likely need to consider information contained within combinations of movements and temporal analysis of the interaction itself. For example, a smile alone may be a response to correct robot behavior, but a smile combined with a head tilt and scrunched eyebrows could reflect a response to incorrect robot behavior (possible signal of confusion). Or it is possible that a person may be amused by a robot\u2019s mistake the first time it occurs, and therefore displays positive implicit feedback, but reverts to expected negative feedback after a mistake happens one or more additional times. This appeared to happen with some of our participants; so a longitudinal approach may be warranted.\nWe noted earlier that there was one prominent instance of a participant providing incongruent feedback which resulted in an unexpected response, as well as participants who provided very little feedback throughout the interaction. These sorts of behaviors will likely be reflected in actual LfD interactions in the future, possibly to a higher degree of ambiguity considering we observed this with just eleven participants.\nIncorporating individual differences may also be vital to give robots the ability to classify implicit human feedback. In addition to differences in expressivity, there may be significant variations in how one\u2019s cultural background affects gestures (for example, head nodding / shaking differences between participants from S.E. Asia vs. Europe and the United States). A follow-up to this study would incorporate some measures of individual characters, such as a personality assessment, analysis of attitudes towards robots, cultural effects, and so on [21], [20].\nAs reflected by participant responses, feedback from the robot is vital to provide transparency to users. This has been raised previously in the HRI literature [23], and we too found this in our study. In addition to the robot confirming that it had detected the participant\u2019s response, we also added more transparency in the case where a participant gave three consecutive \u201cnegative\u201d confirmations. When this happened, the robot stated that there must be a mismatch between what it detected and what the participant did, and therefore it would state each individual move it saw until the participant gives an \u201caffirmative\u201d confirmation. Participants noted that this kind of feedback was informative and decreased confusion.\nThere were a few limitations to our study. First, a number of unintended errors that arose during the interactions that were a result of a combination of human errors and machine recognition errors. We observed a few instances where participants demonstrated multiple moves at once, or individual movements that were ambiguous to the Kinect program. This problem mainly arose from the limb in and limb shake movements, which are very similar to each other.\nTo prevent these errors from negatively impacting participants\u2019 experiences, we ended each interaction after participants gave a \u201cnegative\u201d confirmation around 20 minutes into the interaction. While this may have yielded slightly less\ndata, we do not believe this adversely affected our findings. In closure, enabling robots to automatically detect implicit human feedback would be a vital ability to allow for more natural interactions with robots and help minimized the communicative burden placed on users. LfD techniques were developed to expand robot usability so that more people can interact with robots, and we seek to facilitate these interactions even further by incorporating implicit human feedback that is automatically generated by users.\nThe results of this study provided us with valuable information regarding this idea. We observed examples of positive implicit feedback (smiling, nodding, etc.) being generated as responses to correct robot behavior, and specific types of negative feedback (frowning, averted gazing, etc.) being generated by incorrect robot behavior. However, we also observed behavior that would require careful consideration in future studies, such as noticeable differences in the expressiveness of participants or incongruent behavior that blurs the separation of positive and negative implicit feedback. To further enable human teachers in LfD scenarios, we also gained insight from qualitative responses on how participants desired to teach a robot for this setup, which may be applicable to similar LfD setups. These observations should assist in future studies that focus on implicit human behavior in interactions with robots."}, {"heading": "ACKNOWLEDGMENT", "text": "This material is based upon work supported by the National Science Foundation under Grant No. IIS-1253935. The authors also thank Paige Rodeghero.\n1Note, due to a very small sample size (n = 11), it would be dubious to run statistical means comparisons, and one should not accept a p-value with certainty. Instead, we concur with Gelman [10] that reliable patterns can be found by averaging, as reported here."}], "references": [{"title": "Trajectories and Keyframes for Kinesthetic Teaching: A Human-Robot Interaction Perspective", "author": ["B. Akgun", "M. Cakmak", "J. Yoo", "A. Thomaz"], "venue": "7th ACM/IEEE Intl. Conference on Human-Robot Interaction,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "A survey of robot learning from demonstration", "author": ["B.D. Argall", "S. Chernova", "M. Veloso", "B. Browning"], "venue": "Robotics and Autonomous Systems,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Robot learning from demonstration", "author": ["C.G. Atkeson", "S. Schaal"], "venue": "14th Intl. Conference on Machine Learning,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1997}, {"title": "Dyadic evidence for grounding with abstract deictic gestures", "author": ["J. Bavelas", "G. Gerwing"], "venue": "Integrating gestures: The interdisciplinary nature of gestures,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Listeners as Co-Narrators", "author": ["J.B. Bavelas", "L. Coates", "T. Johnson"], "venue": "Journal of Personality and Social Psychology,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2000}, {"title": "Beyond backchannels: A three-step model of grounding in face-to-face dialogue", "author": ["J.B. Bavelas", "P.D. Jong", "H. Korman", "S.S. Jordan"], "venue": "Interdisciplinary Workshop on Feedback Behaviors in Dialog,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Grounding communication in autonomous robots: An experimental study", "author": ["A. Billard", "K. Dautenhahn"], "venue": "Robotics and Autonomous Systems,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1998}, {"title": "Grounding in communication", "author": ["H. Clark", "S. Brennan"], "venue": "Perspectives on socially shared cognition,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1991}, {"title": "What the Face Reveals: Basic and Applied Studies of Spontaneous Expression Using the Facial Action Coding System (FACS)", "author": ["P. Ekman", "E. Rosenberg"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2005}, {"title": "Commentary: P values and statistical practice", "author": ["A. Gelman"], "venue": "Epidemiology,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Answering the Call for a Standard Reliability Measure for Coding Data", "author": ["A.F. Hayes", "K. Krippendorff"], "venue": "Communication Methods and Measures,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2007}, {"title": "How people talk when teaching a robot", "author": ["E.S. Kim", "D. Leyzberg", "K.M. Tsui", "B. Scassellati"], "venue": "4th ACM/IEEE Intl. Conference on Human-Robot Interaction,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Backchannel Head Nods in Danish First Meeting Encounters with a Humanoid Robot: The Role of Physical Embodiment", "author": ["A. Krogsager", "N. Segato", "M. Rehm"], "venue": "9th ACM/IEEE Intl. Conference on Human- Robot Interaction,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Gracefully mitigating breakdowns in robotic services", "author": ["M.K. Lee", "S. Kiesler", "J. Forlizzi", "S. Srinivasa", "P. Rybski"], "venue": "5th ACM/IEEE Intl. Conference on Human-Robot Interaction,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Grounding the Interaction: Anchoring Situated Discourse in Everyday Human-Robot Interaction", "author": ["S. Lemaignan", "R. Ros", "E.A. Sisbot", "R. Alami", "M. Beetz"], "venue": "Intl. Journal of Social Robotics,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Nonverbal Leakage in Robots: Communication of Intentions through Seemingly Unintentional Behavior", "author": ["B. Mutlu", "F. Yamaoka", "T. Kanda", "H. Ishiguro", "N. Hagita"], "venue": "4th ACM/IEEE Intl. Conference on Human-Robot Interaction,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2009}, {"title": "Don\u2019t Scratch! Self-adaptors Reflect Emotional Stability", "author": ["M. Neff", "N. Toothman", "R. Bowmani", "J. Fox Tree", "M. Walker"], "venue": "Intelligent Virtual Agents,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "Computers that recognise and respond to user emotion: theoretical and practical implications", "author": ["R.W. Picard", "J. Klein"], "venue": "Interacting with Computers,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2002}, {"title": "Real-time empathy: Facial mimicry on a robot", "author": ["L.D. Riek", "P. Robinson"], "venue": "Workshop on Affective Interaction in Natural Environments at the Intl. Conference on Multimodal Interfaces,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "Would You Trust a (Faulty) Robot? Effects of Error, Task Type and Personality on Human-Robot Cooperation and Trust", "author": ["M. Salem", "G. Lakatos", "F. Amirabdollahian", "K. Dautenhahn"], "venue": "10th ACM/IEEE Intl. Conference on Human-Robot Interaction,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "Marhaba, how may I help you? Effects of Politeness and Culture on Robot Acceptance and Anthropomorphization", "author": ["M. Salem", "M. Ziadee", "M. Sakr"], "venue": "9th ACM/IEEE Intl. Conference on Human- Robot Interaction,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "The effect of head-nod recognition in human-robot conversation", "author": ["C.L. Sidner", "C. Lee", "L.-P. Morency", "C. Forlines"], "venue": "1st ACM/IEEE Intl. Conference on Human-Robot Interaction,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2006}, {"title": "Reinforcement Learning with Human Teachers: Understanding How People Want to Teach Robots", "author": ["A. Thomaz", "G. Hoffman", "C. Breazeal"], "venue": "IEEE Intl. Symposium on Robot and Human Interactive Communication,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2006}, {"title": "Psychological impact on human when a robot makes mistakes", "author": ["H. Yasuda", "M. Matsumoto"], "venue": "IEEE Intl. Symposium on System Integration,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2013}], "referenceMentions": [{"referenceID": 1, "context": "Many researchers have suggested this problem can be addressed via end-user robot programming, where users can modify and create new behaviors for their robot to best suit their needs and preferences [2], [1].", "startOffset": 199, "endOffset": 202}, {"referenceID": 0, "context": "Many researchers have suggested this problem can be addressed via end-user robot programming, where users can modify and create new behaviors for their robot to best suit their needs and preferences [2], [1].", "startOffset": 204, "endOffset": 207}, {"referenceID": 1, "context": "Learning from demonstration (LfD) is one such method that enables people to readily develop custom robot behavior [2].", "startOffset": 114, "endOffset": 117}, {"referenceID": 2, "context": "people to teach robots and does not require the teacher to have highly specialized knowledge, such as the ability to directly program the robot [3].", "startOffset": 144, "endOffset": 147}, {"referenceID": 22, "context": "[23] showed that LfD systems could be improved for both the teacher and", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "In this exchange, both parties continually provide feedback within the conversation, which enables them to signify whether or not there is a mutual understanding of a topic [8].", "startOffset": 173, "endOffset": 176}, {"referenceID": 3, "context": "Grounding occurs continuously within each moment in conversation, and is not solely confined to pauses in dialogue [4].", "startOffset": 115, "endOffset": 118}, {"referenceID": 5, "context": "During a grounding sequence, the speaker does not simply notice the signal from the addressee and continue talking, but must also acknowledge the signal from the listener by providing an observable behavior in response [6].", "startOffset": 219, "endOffset": 222}, {"referenceID": 7, "context": "Clark and Brennan [8] discuss three classes of responses that are used to show positive evidence of grounding.", "startOffset": 18, "endOffset": 21}, {"referenceID": 21, "context": "[22] performed a study where a conversational robot nodded in response to head nods by participants, and found that people nodded more when the robot performed this action.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] explored the use of nodding as a back-channel response to a human speaker, and found that the physical presence of the robot had a significant impact on user perception when ar X iv :1 60 6.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "grounding from the perspective of gaze cues and discourse [7], [15], [16], [19].", "startOffset": 58, "endOffset": 61}, {"referenceID": 14, "context": "grounding from the perspective of gaze cues and discourse [7], [15], [16], [19].", "startOffset": 63, "endOffset": 67}, {"referenceID": 15, "context": "grounding from the perspective of gaze cues and discourse [7], [15], [16], [19].", "startOffset": 69, "endOffset": 73}, {"referenceID": 18, "context": "grounding from the perspective of gaze cues and discourse [7], [15], [16], [19].", "startOffset": 75, "endOffset": 79}, {"referenceID": 23, "context": "robots when they are given a task; this can be especially useful to correct robot mistakes that negatively impact users [24].", "startOffset": 120, "endOffset": 124}, {"referenceID": 11, "context": "If the user is aware that the robot does not understand a command, the user can adjust the command delivery accordingly [12].", "startOffset": 120, "endOffset": 124}, {"referenceID": 4, "context": "Two independent coders performed a gestural analysis [5] of participant\u2019s implicit feedback conveyed to the robot, such as via head movements, facial expressions, eye gaze, and body postures.", "startOffset": 53, "endOffset": 56}, {"referenceID": 10, "context": "937) as calculated on a subset of the data [11].", "startOffset": 43, "endOffset": 47}, {"referenceID": 8, "context": "System (FACS) [9].", "startOffset": 14, "endOffset": 17}, {"referenceID": 17, "context": ", [18], [14], this seemed out of scope and overly restrictive for the current study.", "startOffset": 2, "endOffset": 6}, {"referenceID": 13, "context": ", [18], [14], this seemed out of scope and overly restrictive for the current study.", "startOffset": 8, "endOffset": 12}, {"referenceID": 16, "context": "ioral responses commonly used to mitigate anxiety, stress, and other emotions [17].", "startOffset": 78, "endOffset": 82}, {"referenceID": 15, "context": "Glancing away from the robot also seemed to be a meaningful communicative signal during teaching, which aligns with other HRI work [16].", "startOffset": 131, "endOffset": 135}, {"referenceID": 20, "context": "A follow-up to this study would incorporate some measures of individual characters, such as a personality assessment, analysis of attitudes towards robots, cultural effects, and so on [21], [20].", "startOffset": 184, "endOffset": 188}, {"referenceID": 19, "context": "A follow-up to this study would incorporate some measures of individual characters, such as a personality assessment, analysis of attitudes towards robots, cultural effects, and so on [21], [20].", "startOffset": 190, "endOffset": 194}, {"referenceID": 22, "context": "This has been raised previously in the HRI literature [23], and we too found this in our study.", "startOffset": 54, "endOffset": 58}], "year": 2016, "abstractText": "As robots enter human environments, they will be expected to accomplish a tremendous range of tasks. It is not feasible for robot designers to pre-program these behaviors or know them in advance, so one way to address this is through end-user programming, such as learning from demonstration (LfD). While significant work has been done on the mechanics of enabling robot learning from human teachers, one unexplored aspect is enabling mutual feedback between both the human teacher and robot during the learning process, i.e., implicit learning. In this paper, we explore one aspect of this mutual understanding, grounding sequences, where both a human and robot provide non-verbal feedback to signify their mutual understanding during interaction. We conducted a study where people taught an autonomous humanoid robot a dance, and performed gesture analysis to measure people\u2019s responses to the robot during correct and incorrect demonstrations.", "creator": "LaTeX with hyperref package"}}}