{"id": "1606.05464", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Jun-2016", "title": "Stance Detection with Bidirectional Conditional Encoding", "abstract": "stance detection is in task of classifying the attitude expressed in a text towards a target such as \" climate change is a real concern \" to portray \" positive \", \" negative \" or \" neutral \". previous work has assumed before either the target is mentioned in the reference or that training data for every target is given. this paper considers the more challenging version of this task, assuming targets are not always mentioned and no training data is available for the test targets. we experiment with email lstm encoding, which establishes a representation of the tweet that is dependent on the document, and demonstrate that it doubles the independent intelligence algorithms tweet and target. performance improves even clearer when platform interaction model is repeated with bidirectional encoding. the method is evaluated on the semeval 2016 task 6 twitter stance identification corpus program achieves performance second lowest only to task system trained on semi - automatically labelled tweets for the expected target. when such weak supervision is added, our analysis achieves state - of - the - art results.", "histories": [["v1", "Fri, 17 Jun 2016 09:39:47 GMT  (27kb)", "http://arxiv.org/abs/1606.05464v1", null], ["v2", "Mon, 26 Sep 2016 20:49:16 GMT  (23kb)", "http://arxiv.org/abs/1606.05464v2", "10 pages"]], "reviews": [], "SUBJECTS": "cs.CL cs.LG cs.NE", "authors": ["isabelle augenstein", "tim rockt\u00e4schel", "andreas vlachos", "kalina bontcheva"], "accepted": true, "id": "1606.05464"}, "pdf": {"name": "1606.05464.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["i.augenstein@ucl.ac.uk,", "t.rocktaschel@cs.ucl.ac.uk", "k.bontcheva}@sheffield.ac.uk", "@realDonaldTrump", "@GOP"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 6.\n05 46\n4v 1\n[ cs\n.C L\n] 1\n7 Ju\nStance detection is the task of classifying the attitude expressed in a text towards a target such as \u201cClimate Change is a Real Concern\u201d to be \u201cpositive\u201d, \u201cnegative\u201d or \u201cneutral\u201d. Previous work has assumed that either the target is mentioned in the text or that training data for every target is given. This paper considers the more challenging version of this task, where targets are not always mentioned and no training data is available for the test targets. We experiment with conditional LSTM encoding, which builds a representation of the tweet that is dependent on the target, and demonstrate that it outperforms the independent encoding of tweet and target. Performance improves even further when the conditional model is augmented with bidirectional encoding. The method is evaluated on the SemEval 2016 Task 6 Twitter Stance Detection corpus and achieves performance second best only to a system trained on semi-automatically labelled tweets for the test target. When such weak supervision is added, our approach achieves state\u2013of-the-art results."}, {"heading": "1 Introduction", "text": "The goal of stance detection is to classify the attitude expressed in a text, towards a given target, as \u201cpositive\u201d, \u201dnegative\u201d, or \u201dneutral\u201d. Such information can be useful for a variety of tasks, e.g. Mendoza et al. (2010) showed that tweets stating actual facts were affirmed by 90% of the tweets related to them, while tweets conveying false information were predominantly questioned or denied.\nThe focus of this paper is on a novel stance detection task, namely tweet stance detection towards previously unseen target entities (mostly entities such as politicians or issues of public interest), as defined in the SemEval Stance Detection for Twitter task (Mohammad et al., 2016). This task is rather difficult, firstly due to not having training data for the targets in the test set, and secondly, due to the targets not always being mentioned in the tweet. For example, the tweet \u201c@realDonaldTrump is the only honest voice of the @GOP\u201d expresses a positive stance towards the target Donald Trump. However, when stance is predicted with respect to Hillary Clinton as the target, this tweet expresses a negative stance, since supporting candidates from one party implies negative stance towards candidates from other parties.\nThus the challenge is twofold. First, we need to learn a model that interprets the tweet stance towards a target that might not be mentioned in the tweet itself. Second, we need to learn such a model without labelled training data for the target with respect to which we are predicting the stance. In the example above, we need to learn a model for Hillary Clinton by only using training data for other targets. While this renders the task more challenging, it is a more realistic scenario, as it is unlikely that labelled training data for each target of interest will be available.\nTo address these challenges we develop a neural network architecture based on conditional encoding (Rockta\u0308schel et al., 2016). A long-short term memory (LSTM) network (Hochreiter and Schmidhuber, 1997) is used to encode the target, followed by a second\nLSTM that encodes the tweet using the encoding of the target as its initial state. We show that this approach achieves better F1 than standard stance detection baselines, or an independent LSTM encoding of the tweet and the target. The latter achieves an F1 of 0.4169 on the test set. Results improve further (F1 of 0.4901) with a bidirectional version of our model, which takes into account the context on either side of the word being encoded. In the context of the shared task, this would be the second best result, except for an approach which uses automatically labelled tweets for the test targets (F1 of 0.5628). Lastly, when our bidirectional conditional encoding model is trained on such data, it achieves state-of-the-art performance (F1 of 0.5803)."}, {"heading": "2 Task Setup", "text": "The SemEval 2016 Stance Detection for Twitter task (Mohammad et al., 2016) consists of two subtasks, Task A and Task B. In Task A the goal is to detect the stance of tweets towards targets given labelled training data for all test targets (Climate Change is a Real Concern, Feminist Movement, Atheism, Legalization of Abortion and Hillary Clinton). In Task B, which is the focus of this paper, the goal is to detect stance with respect to an unseen target different from the ones considered in Task A, namely Donald Trump, for which labeled training/development data is not provided.\nSystems need to classify the stance of each tweet as \u201cpositive\u201d (FAVOR), \u201cnegative\u201d (AGAINST) or \u201cneutral\u201d (NONE) towards the target. The official metric reported is F1 macro-averaged over FAVOR and AGAINST. Although the F1 of NONE is not considered, systems still need to predict it to avoid precision errors for the other two classes.\nAlthough participants were not allowed to manually label data for the test target Donald Trump, they were allowed to label data automatically. The two best performing systems submitted to Task B, pkudblab (Wei et al., 2016b) and LitisMind (Zarrella and Marsh, 2016), both made use of this. Making use of such techniques renders the task intp weakly supervised seen target stance detection, instead of an unseen target task. Although the goal of this paper is to present stance detec-\ntion methods for targets for which no training data is available, we show that they can also be used in a weakly supervised framework and outperform the state-of-the-art on the SemEval 2016 Stance Detection for Twitter dataset."}, {"heading": "3 Methods", "text": "A common stance detection approach is to treat it as a sentence-level classification task similar to sentiment analysis (Pang and Lee, 2008, Socher et al., 2013). However, such an approach cannot capture the stance of a tweet with respect to a particular target, unless training data is available for each of the test targets. In such cases, we could learn that a tweet mentioning Donald Trump in a positive manner expresses a negative stance towards Hillary Clinton. Despite this limitation, we use two such baselines, one implemented with a Support Vector Machine (SVM) classifier and one with an LSTM, in order to assess whether we are successful in incorporating the target in stance prediction.\nA naive approach to incorporate the target in stance prediction would be to generate features concatenating the target with words from the tweet. In principle, this could allow the classifier to learn that some words in the tweets have target-dependent stance weights, but it still assumes that training data is available for each target.\nIn order to learn how to combine the target with the tweet in a way that generalises to unseen targets, we focus on learning distributed representations and ways to combine them. The following sections develop progressively the proposed bidirectional conditional LSTM encoding model, starting from the independent LSTM encoding."}, {"heading": "3.1 Independent Encoding", "text": "Our initial attempt to learn distributed representations for the tweets and the targets is to encode the target and tweet independently as k-dimensional dense vectors using two LSTMs (Hochreiter and Schmidhuber, 1997).\nH =\n[\nxt\nht\u22121\n]\nit = \u03c3(W i H+ bi)\nft = \u03c3(W f H+ bf )\not = \u03c3(W o H+ bo) ct = ft \u2299 ct\u22121 + it \u2299 tanh(W c H+ bc)\nht = ot \u2299 tanh(ct)\nHere, xt is an input vector at time step t, ct denotes the LSTM memory, ht \u2208 Rk is an output vector and the remaining weight matrices and biases are trainable parameters. We concatenate the two output vector representations and classify the stance using the softmax over a non-linear projection\nsoftmax(tanh(Wtahtarget +W tw htweet + b))\ninto the space of the three classes for stance detection where Wta,Wtw \u2208 R3\u00d7k are trainable weight matrices and b \u2208 R3 is a trainable class bias. This model learns target-independent distributed representations for the tweets and relies on the nonlinear projection layer to incorporate the target in the stance prediction."}, {"heading": "3.2 Conditional Encoding", "text": "In order to learn target-dependent tweet representations, we use conditional encoding as previously applied to the task of recognizing textual entailment\n(Rockta\u0308schel et al., 2016). We use one LSTM to encode the target as a fixed-length vector. Then, we encode the tweet with another LSTM, whose state is initialised with the representation of the target. Finally, we use the last output vector of the tweet LSTM to predict the stance of the target-tweet pair.\nThis effectively allows the second LSTM to read the tweet in a target-specific manner, which is crucial since the stance of the tweet depends on the target (recall the Donald Trump example above)."}, {"heading": "3.3 Bidirectional Conditional Encoding", "text": "Bidirectional LSTMs have been shown to learn improved representations of sequences by encoding a sequence from left to right and from right to left (Graves and Schmidhuber, 2005). Therefore, we adapt the conditional encoding model from Section 3.2 to use bidirectional LSTMs, which represent the target and the tweet using two vectors for each of them, one obtained by reading the target and then the tweet left-to-right (as in the conditional LSTM encoding) and one obtained by reading them rightto-left. To achieve this, we initialise the state of the bidirectional LSTM that reads the tweet by the last state of the forward and reversed encoding of the target (see Figure 1). The bidirectional encoding allows the model to construct target-dependent representations of the tweet such that when each word is considered, they take into account both the left- and the right-hand side context."}, {"heading": "3.4 Unsupervised Pretraining", "text": "In order to counter-balance the relatively small training data available (5628 instances in total), unsupervised pre-training is employed. It initialises the word embeddings used in the LSTMs with an appropriately trained word2vec model (Mikolov et al., 2013). Note that these embeddings are used only for initialisation, as we allow them to be optimised further during training.\nIn more detail, we train a word2vec model on a corpus of 395,212 unlabelled tweets, collected with the Twitter Keyword Search API1 between November 2015 and January 2016, plus all the tweets contained in the official SemEval 2016 Stance Detection datasets (Mohammad et al., 2016). The unlabelled tweets are collected so they contain the training, dev and test targets, using up to two keywords per target, namely \u201chillary\u201d, \u201cclinton\u201d, \u201ctrump\u201d, \u201cclimate\u201d, \u201cfemini\u201d, \u201caborti\u201d. Note that Twitter does not allow for regular expression search, so this is a free text search disregarding possible word boundaries. We combine this large unlabelled corpus with the official training data and train a skip-gram word2vec model (dimensionality 100, 5 min words, context window of 5). Tweets and targets are tokenised with the Twitter-adapted tokeniser twokenize2. Subsequently, all tokens are normalised to lower case, URLs are removed, and stopword tokens are filtered (i.e. punctuation characters, Twitter-specific stopwords (\u201crt\u201d, \u201c#semst\u201d, \u201cvia\u201d).\nAs demonstrated in our experiments, unsupervised pre-training is quite helpful, since it is difficult to learn representations for all the words using only the relatively small training datasets available. Finally, to ensure that the proposed neural network architectures contribute to the performance, we also use the word vectors from word2vec in a Bag-of-Word-Vectors baseline (BOWV), in which the tweet and target representations are fed into a logistic regression classifier with L2 regularization (Pedregosa et al., 2011).\n1 https://dev.twitter.com/rest/public/\nsearch 2 https://github.com/leondz/twokenize"}, {"heading": "4 Experiments", "text": "Experiments are performed on the SemEval 2016 Task 6 corpus for Stance Detection on Twitter (Mohammad et al., 2016). We report experiments for two different experimental setups: one is the unseen target setup (Section 5), which is the main focus of this paper, i.e. detecting the stance of tweets towards previously unseen targets. We show that conditional encoding, by reading the tweets in a target-specific way, generalises to unseen targets better than baselines which ignore the target. Next, we compare our approach to previous work in a weakly supervised framework (Section 6) and show that our approach outperforms the state-of-the-art on the SemEval 2016 Stance Detection Subtask B corpus.\nTable 1 lists the various corpora used in the experiments and their sizes. TaskA Tr+Dv is the official SemEval 2016 Twitter Stance Detection TaskA training and development corpus, which contain instances for the targets Legalization of Abortion, Atheism, Feminist Movement, Climate Change is a Real Concern and Hillary Clinton. TaskA Tr+Dv HC is the part of the corpus which contains only the Hillary Clinton tweets, which we use for development purposes. TaskB Test is the TaskB test corpus on which we report results containing Donald Trump testing instances. TaskB Unlab is an unlabelled corpus containing Donald Trump tweets supplied by the task organisers, and TaskB Auto-lab* is an automatically labelled version of a small portion of the corpus for the weakly supervised stance detection experiments reported in Section 6. Finally, Crawled Unlab* is\na corpus we collected for unsupervised pre-training (see Section 3.4).\nFor all experiments, the official task evaluation script is used. Predictions are postprocessed so that if the target is contained in a tweet, the highestscoring non-neutral stance is chosen. This was motivated by the observation that in the training data most target-containing tweets express a stance, with only 16% of them being neutral."}, {"heading": "4.1 Methods", "text": "We compare the following baseline methods:\n\u2022 SVM trained with word and character tweet n-grams features (SVM-ngramscomb) Mohammad et al. (2016) \u2022 a majority class baseline (Majority baseline), reported in (Mohammad et al., 2016) \u2022 bag of word vectors (BoWV) (see Section 3.4) \u2022 independent encoding of tweet and the target\nwith two LSTMs (Concat) (see Section 3.1) \u2022 encoding of the tweet only with an LSTM\n(TweetOnly) (see Section 3.1\nto three versions of conditional encoding:\n\u2022 target conditioned on tweet (TarCondTweet) \u2022 tweet conditioned on target (TweetCondTar) \u2022 a bidirectional encoding model (BiCond)"}, {"heading": "5 Unseen Target Stance Detection", "text": "As explained, the challenge is to learn a model without any manually labelled training data for the test target, but only using the data from the Task A targets. In order to avoid using any labelled data for Donald Trump, while still having a (labelled) development set to tune and evaluate our models, we used the tweets labelled for Hillary Clinton as a development set and the tweets for the remaining four targets as training. We refer to this as the development setup, and all models are tuned using this setup. The labelled Donald Trump tweets were only used in reporting our final results. For the final results we train on all the data from the development setup and evaluate on the official Task B test set, i.e. the Donald Trump tweets. We refer to this as our test setup.\nBased on a small grid search using the development setup, the following settings for LSTM-based\nmodels were chosen: input layer size 100 (equal to word embedding dimensions), hidden layer size 60, training for max 50 epochs with initial learning rate 1e-3 using ADAM (Kingma and Ba, 2014) for optimisation, dropout 0.1. Using one, relatively small hidden layer and dropout help avoid overfitting."}, {"heading": "5.1 Results and Discussion", "text": "Results for the unseen target setting show how well conditional encoding is suited for learning targetdependent representations of tweets, and crucially, how well such representations generalise to unseen targets. The best performing method on both development (Table 2) and test setups (Table 3) is BiCond, which achieves an F1 of 0.4722 and 0.4901 respectively. Notably, Concat, which learns an indepedent encoding of the target and the tweets, does not achieve big F1 improvements over TweetOnly, which learns a representation of the tweets only. This shows that it is not only important to learn target-depedent encodings, but also the way in which they are learnt matters. Models that learn to condition the encoding of tweets on targets outperform all baselines on the test set.\nIt is further worth noting that the Bag-of-WordVectors baseline achieves results comparable with TweetOnly, Concat and one of the conditional en-\ncoding models, TarCondTweet, on the dev set, even though it achieves significantly lower performance on the test set. This indicates that the pre-trained word embeddings on their own are already very useful for stance detection.\nOur best result in the test setup with BiCond is currently the second highest reported result on the Stance Detection corpus, however the first, third and fourth best approaches achieved their results by automatically labelling Donald Trump training data. BiCond for the unseen target setting outperforms the third and fourth best approaches by a large margin (5 and 7 points in Macro F1, respectively), as can be seen in Table 7. Results for weakly supervised stance detection are discussed in the next section.\nUnsupervised Pre-Training Table 4 shows the effect of unsupervised pre-training of word embeddings, and furthermore, the results of sharing these representations between the tweets and targets, on the development set. The first set of results is with a uniformly Random embeddings initialisation in [\u22120.1, 0.1]. PreFixed uses the pre-trained word embeddings, whereas PreCont uses the pre-trained word embeddings and continues training them during LSTM training.\nOur results show that, in the absence of a large\nlabelled training dataset, unsupervised pre-training of word embeddings is more helpful than random initialisation of embeddings. Sing vs Sep shows the difference between using shared vs two separate embeddings matrices for looking up the word embeddings. Sing means the word representations for tweet and target vocabularies are shared, whereas Sep means they are different. Using shared embeddings performs better, which we hypothesise is because the tweets contain some mentions of targets that are tested.\nTarget in Tweet vs Not in Tweet Table 5 shows results on the development set for BiCond, compared to the best unidirectional encoding model, TweetCondTar and the baseline Concat, split by tweets that contain the target and those that do not. All three models perform well when the target is mentioned in the tweet, but less so when the targets are not mentioned explicitly. In the case where the target is mentioned in the tweet, biconditional encoding outperforms unidirectional encoding and unidirectional encoding outperforms Concat. This shows that conditional encoding is able to learn useful dependencies between the tweets and the targets."}, {"heading": "6 Weakly Supervised Stance Detection", "text": "The previous section showed the usefulness of conditional encoding for unseen target stance detection and compared results against internal baselines. The goal of experiments reported in this section is to compare against participants in the SemEval 2016 Stance Detection Task B. While we consider an unseen target setup, most submissions, including the three highest ranking ones for Task B, pkudblab (Wei et al., 2016b), LitisMind (Zarrella and Marsh, 2016) and INFUFRGS (Wei et al., 2016a) considered a different experimental setup. They automatically annotated training data for the test target Donald Trump, thus rendering the task as a weakly supervised seen target stance detection. The pkudblab system uses a deep convolutional neural network that learns to make 2- way predictions on automatically labelled positive and negative training data for Donald Trump. The neutral class is predicted according to rules which are applied at test time.\nSince the best performing systems which participated in the shared task consider a weakly supervised setup, we further compare our proposed approach to the state-of-the-art using such a weakly\nsupervised setup. Note that, even though pkudblab, LitisMind and INF-UFRGS also use regular expressions to label training data automatically, the resulting datasets were not made available to us. Therefore, we had to develop our own automatic labelling method and dataset, which will be made publicly available on publication.\nWeakly Supervised Test Setup For this setup, the unlabelled Donald Trump corpus TaskB Unlab is annotated automatically. For this purpose we created a small set of regular expressions3 , based on inspection of the TaskB Unlab corpus, expressing positive and negative stance towards the target. The regular expressions for the positive stance were:\n\u2022 make( ?)america( ?)great( ?)again \u2022 trump( ?)(for|4)( ?)president \u2022 votetrump \u2022 trumpisright \u2022 the truth \u2022 #trumprules\nThe keyphrases for negative stance were: #dumptrump, #notrump, #trumpwatch, racist, idiot, fired\n3Note that \u201c|\u201d indiates \u201cor\u201d, ( ?) indicates optional space\nA tweet is labelled as positive if one of the positive expressions is detected, else negative if a negative expressions is detected. If neither are detected, the tweet is annotated as neutral randomly with 2% chance. The resulting corpus size per stance is shown in Table 1. The same hyperparameters for the LSTM-based models are used as for the unseen target setup described in the previous section."}, {"heading": "6.1 Results and Discussion", "text": "Table 6 lists our results in the weakly supervised setting. Table 7 shows all our results, including those using the unseen target setup, compared against the state-of-the-art on the stance detection corpus. It further lists baselines reported by Mohammad et al. (2016), namely a majority class baseline (Majority baseline), and a method using 1 to 3-gram bag-of-word and character n-gram features (SVM-ngrams-comb), which are extracted from the tweets and used to train a 3-way SVM classifier. Bag-of-word baselines (BoWV, SVM-\nngrams-comb) achieve results comparable to the majority baseline (F1 of 0.2972), which shows how difficult the task is. The baselines which only extract features from the tweets, SVM-ngrams-comb and TweetOnly perform worse than the baselines which also learn representations for the targets (BoWV, Concat). By training conditional encoding models on automatically labelled stance detection data we achieve state-of-the-art results. The best result (F1 of 0.5803) is achieved with the bi-directional conditional encoding model (BiCond). This shows that such models are suitable for unseen, as well as seen target stance detection."}, {"heading": "7 Related Work", "text": "Stance Detection: Previous work mostly considered target-specific stance prediction in debates (Hasan and Ng, 2013, Walker et al., 2012) or student essays (Faulkner, 2014). Recent work studied Twitter-based stance detection (Rajadesingan and Liu, 2014), which is also a task at SemEval 2016 (Mohammad et al., 2016). The latter is more challenging than stance detection in debates because, in addition to irregular language, the Mohammad et al. (2016) dataset is offered without any context, e.g., conversational structure or tweet metadata. The targets are also not always mentioned in the tweets, which makes the task very challenging (Augenstein et al., 2016) and distinguishes it from target-dependent (Vo and Zhang, 2015, Zhang et al., 2016, Alghunaim et al., 2015) and open-domain target-dependent sentiment analysis (Mitchell et al., 2013, Zhang et al., 2015).\nConditional Encoding: Conditional encoding has been applied in the related task of recognising textual entailment (Rockta\u0308schel et al., 2016), using a dataset of half a million training examples (Bowman et al., 2015) and numerous different hypotheses. Our experiments show that conditional encoding is also successful on a relatively small training set and when applied to an unseen testing target. Moreover, we augment conditional encoding with bidirectional encoding and demonstrate the added benefit of unsupervised pre-training of word embeddings on unlabelled domain data."}, {"heading": "8 Conclusions and Future Work", "text": "This paper showed that conditional LSTM encoding is a successful approach to stance detection for unseen targets. Our unseen target bidirectional conditional encoding approach achieves the second best results reported to date on the SemEval 2016 Twitter Stance Detection corpus. In a seen target minimally supervised scenario, as considered by prior work, our approach achieves the best results to date on the SemEval Task B dataset. We further show that in the absence of large labelled corpora, unsupervised pretraining can be used to learn target representations for stance detection and improves results on the SemEval corpus. Future work will investigate further the challenge of stance detection for tweets which do not contain explicit mentions of the target."}], "references": [{"title": "Scott Cyphers", "author": ["Abdulaziz Alghunaim", "Mitra Mohtarami"], "venue": "and Jim Glass.", "citeRegEx": "Alghunaim et al.2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Andreas Vlachos", "author": ["Isabelle Augenstein"], "venue": "and Kalina Bontcheva.", "citeRegEx": "Augenstein et al.2016", "shortCiteRegEx": null, "year": 2016}, {"title": "and Christopher D", "author": ["Samuel R. Bowman", "Gabor Angeli", "Christopher Potts"], "venue": "Manning.", "citeRegEx": "Bowman et al.2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Automated Classification of Stance in Student Essays: An Approach Using Stance Target Information and the Wikipedia Link-Based Measure", "author": ["Adam Faulkner"], "venue": null, "citeRegEx": "Faulkner.,? \\Q2014\\E", "shortCiteRegEx": "Faulkner.", "year": 2014}, {"title": "Framewise phoneme classification with bidirectional LSTM and other neural network architectures", "author": ["Graves", "Schmidhuber2005] Alex Graves", "J\u00fcrgen Schmidhuber"], "venue": "Neural Networks,", "citeRegEx": "Graves et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Graves et al\\.", "year": 2005}, {"title": "Stance Classification of Ideological Debates: Data, Models, Features, and Constraints. In IJCNLP, pages 1348\u20131356", "author": ["Hasan", "Ng2013] Kazi Saidul Hasan", "Vincent Ng"], "venue": "Asian Federation of Natural Language Processing / ACL", "citeRegEx": "Hasan et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Hasan et al\\.", "year": 2013}, {"title": "Long short-term memory", "author": ["Hochreiter", "Schmidhuber1997] Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Adam: A Method for Stochastic Optimization. CoRR, abs/1412.6980", "author": ["Kingma", "Ba2014] Diederik P. Kingma", "Jimmy Ba"], "venue": null, "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Barbara Poblete", "author": ["Marcelo Mendoza"], "venue": "and Carlos Castillo.", "citeRegEx": "Mendoza et al.2010", "shortCiteRegEx": null, "year": 2010}, {"title": "Greg Corrado", "author": ["Tomas Mikolov", "Kai Chen"], "venue": "and Jeffrey Dean.", "citeRegEx": "Mikolov et al.2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Theresa Wilson", "author": ["Margaret Mitchell", "Jacqui Aguilar"], "venue": "and Benjamin Van Durme.", "citeRegEx": "Mitchell et al.2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Xiaodan Zhu", "author": ["Saif M. Mohammad", "Svetlana Kiritchenko", "Parinaz Sobhani"], "venue": "and Colin Cherry.", "citeRegEx": "Mohammad et al.2016", "shortCiteRegEx": null, "year": 2016}, {"title": "Opinion mining and sentiment analysis", "author": ["Pang", "Lee2008] Bo Pang", "Lillian Lee"], "venue": "Foundations and trends in information retrieval,", "citeRegEx": "Pang et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Pang et al\\.", "year": 2008}, {"title": "and E", "author": ["F. Pedregosa", "G. Varoquaux", "A. Gramfort", "V. Michel", "B. Thirion", "O. Grisel", "M. Blondel", "P. Prettenhofer", "R. Weiss", "V. Dubourg", "J. Vanderplas", "A. Passos", "D. Cournapeau", "M. Brucher", "M. Perrot"], "venue": "Duchesnay.", "citeRegEx": "Pedregosa et al.2011", "shortCiteRegEx": null, "year": 2011}, {"title": "Identifying Users with Opposing Opinions in Twitter Debates", "author": ["Rajadesingan", "Liu2014] Ashwin Rajadesingan", "Huan Liu"], "venue": null, "citeRegEx": "Rajadesingan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Rajadesingan et al\\.", "year": 2014}, {"title": "Tom\u00e1\u0161 Ko\u010disk\u1ef3", "author": ["Tim Rockt\u00e4schel", "Edward Grefenstette", "Karl Moritz Hermann"], "venue": "and Phil Blunsom.", "citeRegEx": "Rockt\u00e4schel et al.2016", "shortCiteRegEx": null, "year": 2016}, {"title": "2016b. pkudblab at", "author": ["Chen", "Tengjiao Wang"], "venue": null, "citeRegEx": "Chen and Wang.,? \\Q2016\\E", "shortCiteRegEx": "Chen and Wang.", "year": 2016}, {"title": "Neural Networks for Open Do", "author": ["Duy Tin Vo"], "venue": null, "citeRegEx": "Vo.,? \\Q2015\\E", "shortCiteRegEx": "Vo.", "year": 2015}, {"title": "Gated Neural Networks for Targeted", "author": ["Tin Vo"], "venue": null, "citeRegEx": "Vo.,? \\Q2016\\E", "shortCiteRegEx": "Vo.", "year": 2016}], "referenceMentions": [], "year": 2017, "abstractText": "Stance detection is the task of classifying the attitude expressed in a text towards a target such as \u201cClimate Change is a Real Concern\u201d to be \u201cpositive\u201d, \u201cnegative\u201d or \u201cneutral\u201d. Previous work has assumed that either the target is mentioned in the text or that training data for every target is given. This paper considers the more challenging version of this task, where targets are not always mentioned and no training data is available for the test targets. We experiment with conditional LSTM encoding, which builds a representation of the tweet that is dependent on the target, and demonstrate that it outperforms the independent encoding of tweet and target. Performance improves even further when the conditional model is augmented with bidirectional encoding. The method is evaluated on the SemEval 2016 Task 6 Twitter Stance Detection corpus and achieves performance second best only to a system trained on semi-automatically labelled tweets for the test target. When such weak supervision is added, our approach achieves state\u2013of-the-art results.", "creator": "LaTeX with hyperref package"}}}