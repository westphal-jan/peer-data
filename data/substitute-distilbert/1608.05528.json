{"id": "1608.05528", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Aug-2016", "title": "Automatic Selection of Context Configurations for Improved Class-Specific Word Representations", "abstract": "recent work has demonstrated that state - of - the - art word embedding models uses different context types to produce high - quality representations for different word classes such as adjectives ( a ), verbs ( v ), and nouns ( n ). this area is concerned with identifying contexts useful for implementing a / v / n - specific meanings. we provide a simple yet effective framework for selecting class - derived context configurations that yield improved representations for each variable. we propose an automatic a * value selection hypothesis that effectively searches only large fraction of the large configuration space. the results efficiently predicting similarity scores for the ai, v, and n subsets of phrase benchmarking simlex - 999 evaluation set indicate that our paper is useful for each design : the effects are 6 % ( a ), 92 % ( v ), and 5 % ( n ) over the best previously proposed context type for each class. at the same time, the model costs on typically 14 % ( a ), 26. 2 % ( v ), hence 99. 6 % ( n ) of successive dependency - based contexts, resulting in much shorter training time.", "histories": [["v1", "Fri, 19 Aug 2016 08:30:35 GMT  (159kb,D)", "http://arxiv.org/abs/1608.05528v1", null], ["v2", "Wed, 7 Jun 2017 09:26:29 GMT  (160kb,D)", "http://arxiv.org/abs/1608.05528v2", "CoNLL 2017"], ["v3", "Mon, 12 Jun 2017 13:11:53 GMT  (153kb,D)", "http://arxiv.org/abs/1608.05528v3", "CoNLL 2017"]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["ivan vuli\\'c", "roy schwartz", "ari rappoport", "roi reichart", "anna korhonen"], "accepted": false, "id": "1608.05528"}, "pdf": {"name": "1608.05528.pdf", "metadata": {"source": "CRF", "title": "Automatic Selection of Context Configurations for Improved (and Fast) Class-Specific Word Representations", "authors": ["Ivan Vuli\u0107", "Roy Schwartz", "Ari Rappoport", "Roi Reichart", "Anna Korhonen"], "emails": ["iv250@cam.ac.uk", "alk23@cam.ac.uk", "roys02@cs.huji.ac.il", "arir@cs.huji.ac.il", "roiri@ie.technion.ac.il"], "sections": [{"heading": "1 Introduction", "text": "Dense real-valued distributed word representations, or word embeddings, have become ubiquitous in NLP, serving as invaluable features in a broad range of NLP tasks (Turian et al., 2010; Collobert et al., 2011; Chen and Manning, 2014). The omnipresent word2vec skip-gram model with negative sampling (SGNS) (Mikolov et al., 2013) is still considered the state-of-the-art word representation model, due to its simplicity, fast training, as well as its solid and robust performance across a wide variety of semantic tasks (Baroni et al., 2014; Levy et al., 2015).\nThe original implementation of SGNS learns word representations from local bag-of-words contexts (BOW). However, the underlying SGNS model is equally applicable to other context types (Levy and Goldberg, 2014a).\nRecent work demonstrated that reaching beyond the omnipresent BOW contexts towards contexts based on dependency parses (Bansal et al., 2014; Schwartz et al., 2016; Melamud et al., 2016) or symmetric patterns (Schwartz et al., 2015; Schwartz et al., 2016) yields significant improvements in learning representations for particular word classes such as adjectives (A) and verbs (V). Curiously enough, despite the success story with adjectives and verbs, SGNS with BOW contexts still outperforms all other context types in noun (N) representation learning.1\nFurther, several recent studies (Ling et al., 2015; Schwartz et al., 2016) suggested that \u201cnot all contexts are created equal\u201d: for instance, Schwartz et al. (2016) show that it is possible to learn highquality representations of verbs and adjectives using only a subset of dependency-based contexts that covers coordination structures for the SGNS training while discarding everything else. Besides their competitive performance on verb and adjective similarity measured on SimLex-999 (Hill et al., 2015), training with such coordination-based contexts is significantly faster due to the pre-training selection step.\nIn this work, we propose a simple yet effective general framework for selecting context configurations that yield improved and fast representations for verbs, adjectives, and nouns. Starting from a dependency-parsed training corpus, the key idea consists of two steps. First, we detect and retain only \u201cindividual\u201d context bags useful for a particular word class. Such context bags are labelled by\n1We refer the reader to the work of Schwartz et al. (2016) for a comprehensive overview of results on SimLex-999.\nar X\niv :1\n60 8.\n05 52\n8v 1\n[ cs\n.C L\n] 1\n9 A\nug 2\n01 6\nlanguage-universal typed dependency links, e.g., amod contexts or dobj contexts. Second, we select final class-specific context configurations by automatically searching the large configuration space using a novel A* style heuristic algorithm. For instance, our algorithm detects that the combination of amod and conj contexts is effective for adjective similarity).\nWe show that SGNS requires different context configurations to produce optimal results for each word class. Some context bags that boost learning representations for one word class (e.g., amod contexts for adjectives) may be uninformative or even harmful when learning representations for another word class (e.g., amod for verbs). By removing such uninformative context bags, we are able both to speed up the SGNS training (by reducing the number of training items) and to improve representations for each class (by using more focused contexts).\nThe results on the task of predicting similarity scores for the verb (V), adjective (A), and noun (N) portions of the benchmarking SimLex-999 evaluation set indicate that the proposed method is useful for each class. Using a standard experimental setup (Levy et al., 2015), we outperform the best baseline context type for each word class: the improvements are 6 \u03c1 points for adjectives, 6 for verbs, and 5 for nouns over the best previously proposed context type for each word class. At the same time, the model trains on only 14% (A), 26.2% (V), and 33.6% (N) of all dependency-based contexts. We also show that by building context configurations we obtain improvements on the entire SimLex-999 benchmark (4 \u03c1 points over the best baseline). Interestingly, this context configuration is not the optimal configuration for any word class.\nWe also demonstrate that the proposed method is robust: the improvements extend to another standard training setup (Schwartz et al., 2016) which uses more training data, as well as a different parser and a different dependency annotation scheme."}, {"heading": "2 Related Work", "text": "Word representations, also known as vector space models or word embeddings, date back to the early 1970s (Salton, 1971). Word representation models typically train on (word,context) pairs. Traditionally, most models use bag-of-words (BOW) contexts, which represent a word using its neighbouring words, irrespective of the syntactic or seman-\ntic relations between them (Collobert et al., 2011; Mikolov et al., 2013; Mnih and Kavukcuoglu, 2013; Pennington et al., 2014, inter alia).\nRecently, several alternative context types have been proposed, motivated by the limitations of BOW contexts, most notably their focus on topical rather than functional similarity (e.g., coffee:cup vs. coffee:tea). These include dependency contexts (Grefenstette, 1994; Pad\u00f3 and Lapata, 2007; Levy and Goldberg, 2014a), pattern contexts (Baroni et al., 2010; Schwartz et al., 2015) and substitute vectors (Yatbaz et al., 2012; Melamud et al., 2015).\nVery recently, several studies investigated the effect of different context types on word representation quality. Melamud et al. (2016) compared three context types on a set of intrinsic and extrinsic evaluation setups, and showed that the optimal type largely depends on the task at hand. Vulic\u0301 and Korhonen (2016) compared a few variants of dependency and BOW contexts across different languages, reaching similar conclusions. Schwartz et al. (2016), showed that symmetric patterns are very useful contexts for verb and adjective similarity, while BOW works best for nouns, measured on the benchmarking SimLex-999 (Hill et al., 2015) evaluation set. They also indicated that coordinations, a subset of dependency contexts, are more useful for verbs and adjectives than the entire set of dependencies.\nIn this work we propose an algorithm for a systematic and efficient inspection of the dependencybased context configuration space which yields superior class-specific representations, with substantial improvements for verbs, nouns and adjectives.\nPrevious attempts on improving word representations by specialising them for a particular relation (e.g., similarity vs relatedness, antonyms) operate in one of the two following frameworks: (1) modifying the prior or the regularisation of the original training procedure (Yu and Dredze, 2014; Wieting et al., 2015; Liu et al., 2015; Kiela et al., 2015; Ling et al., 2015); (2) \u201clight\u201d post-processing procedures which use lexical knowledge to refine offthe-shelf pre-trained word vectors (Faruqui et al., 2015; Mrk\u0161ic\u0301 et al., 2016). We suggest that the induced representations may also be specialised a priori (i.e., before training) using context selection."}, {"heading": "3 Methodology", "text": "Intro: Representation Model Following prior work (Schwartz et al., 2016; Vulic\u0301 and Korhonen,\n2016), we keep the word representation model fixed while varying only the context type. For all context configurations and all other (baseline) context types, we opt for the standard and very robust choice (Levy et al., 2015) in vector space modeling: SGNS (Mikolov et al., 2013). In all experiments we use word2vecf, a reimplementation of word2vec able to learn from arbitrary (word, context) pairs.2 To simplify the presentation, we adopt the assumption that all training data for SGNS are in the form of such (word, context) pairs (Levy and Goldberg, 2014a; Levy and Goldberg, 2014c), where word is the current target word, and context is its observed context (e.g., BOW, positional, dependency-based).\nBy fixing the representation model and varying only the context type, one may attribute all differences in results to a sole factor: the actual context type/configuration."}, {"heading": "3.1 Terminology and Background", "text": "Dependency-Based Contexts This work starts from dependency-based contexts (DEPS) (Pad\u00f3 and Lapata, 2007; Utt and Pad\u00f3, 2014), which were recently proven useful in learning word embeddings (Levy and Goldberg, 2014a; Melamud et al., 2016).\nGiven a parsed training corpus, for each target w with modifiers m1, . . . ,mk and a head h, w is paired with context elements m1_r1, . . . ,mk_rk, h_r\u22121h , where r is the type of the dependency relation between the head and the modifier (e.g., amod), and r\u22121 denotes an inverse relation. A naive version of DEPS extracts contexts from the parsed corpus without any post-processing (more on this later). Given an example from Fig. 1, the DEPS contexts of discovers are: scientist_nsubj, stars_dobj, telescope_nmod. Compared to BOW, DEPS capture longer-range relations (e.g., telescope) and filter out \u201caccidental contexts\u201d (e.g., Australian).\nBesides being oriented towards functional similarity through such more focused contexts, DEPS also provides a natural implicit grouping of related contexts. For instance, all pairs with the shared relation r and r\u22121 may be taken as an r-based context bag, e.g., pairs (scientist, Australian_amod), (Australian, scientist_amod\u22121) are labelled the amod\n2https://bitbucket.org/yoavgo/word2vecf For details concerning the implementation, we refer the reader to (Goldberg and Levy, 2014; Levy and Goldberg, 2014a).\ncontext bag, while (discovers, stars_dobj), (stars, discovers_dobj\u22121) are labelled dobj (Fig. 1).\nUniversal Dependencies as Labels Following recent initiatives on cross-linguistically consistent annotations, we adopt the Universal Dependencies (UD) annotation scheme3 (McDonald et al., 2013; Nivre et al., 2015) to serve as labels for individual context bags.4 The scheme leans on the universal Stanford dependencies (de Marneffe et al., 2014) complemented with the universal POS tagset (Petrov et al., 2012). It is straightforward to \u201ctranslate\u201d previous annotation schemes to UD (de Marneffe et al., 2014).\nUD scheme is becoming a de facto standard in dependency parsing. It provides a universal and consistent inventory of categories for similar syntactic constructions across multiple languages. This property could facilitate representation learning in languages other than English, cross-lingual modeling, and application of our methodology to other languages in future work.\nContext Configurations Assume that we have obtained M distinct dependency relations\n3http://universaldependencies.org/ (V1.2 used) 4http://universaldependencies.org/u/dep/index.html\nr1, . . . , rM after parsing and post-processing the corpus. The j-th individual context bag, j = 1, . . . ,M , labelled rj is a bag (or a multiset) of (word, context) pairs where context has one of the following forms: v_rj or v_r\u22121j , where v is some vocabulary word. A context configuration is then simply a set of individual context bags, e.g., R = {ri, rj , rk}, also labelled as R: ri + rj + rk. We call a configuration consisting of K individual context bags a K-set configuration (e.g., in this example, R is a 3-set configuration).\nIntuition behind Context Configurations The core idea of the work on building context configurations lies in the intuition that the distributional hypothesis (Harris, 1954) may be restated as a series of statements according to a particular dependency relation: for instance, \u201ctwo adjectives are similar if they modify similar nouns\u201d, which is captured by the amod typed dependency link. This could also be reversed to reflect noun similarity by saying that \u201ctwo nouns are similar if they are modified by similar adjectives\u201d. In another example, \u201ctwo verbs are similar if they are used as predicates of similar nominal subjects\u201d (nsubj and nsubjpass), etc."}, {"heading": "3.2 Individual Context Bags", "text": "Post-parsing steps are performed to obtain a comprehensive list of (language-universal) individual bags at the right level of granularity for computational feasibility (step 1), to enhance context expressiveness (steps 2-3), and to remove uninformative contexts (step 4). (1) Closely related bags are merged into a new broader bag: direct (dobj) and indirect objects (iobj) are merged into obj. Further, nsubj and nsubjpass are merged into one single bag subj, xcomp and ccomp into comp, advcl and advmod into adv. Note that these combinations are performed solely for efficiency reasons (i.e., to reduce the search space), without affecting any theoretical implications of the proposed algorithm (see later Alg. 1). (2) We perform the standard procedure of prepositional arc-collapsing (Levy and Goldberg, 2014a; Vulic\u0301 and Korhonen, 2016), illustrated in Fig. 1. Following the procedure, all pairs where the relation r has the form prep:X (where X is a preposition) are subsumed to an individual context bag labelled prep. (3) Coordination-based contexts are extracted as in prior work (Schwartz et al., 2016), distinguish-\ning between left and right contexts extracted from the conj relation.5 This context bag is called conjlr. We also utilize the variant that does not make the distinction, called conjll. If both are used together, the label is simply conj. (4) Optionally, it is possible to filter out all infrequent dependency relations (e.g., dep, goeswith, foreign) and (semantically) uninformative ones (e.g., punct, det, cop, aux).6\nAfter performing these steps, the final list of individual context bags we use in our experiments is as follows: subj, obj, comp, nummod, appos, nmod, acl, amod, prep, adv, compound, conjlr, conjll."}, {"heading": "3.3 Selection of Class-Specific Configurations", "text": "Initial Pools of Candidate Context Bags To reduce the number of possible configurations for each word class (again for efficiency reasons) it is possible to automatically pool only individual context bags that are potentially useful. For instance, since amod denotes an adjectival modifier of a noun, this bag can be safely removed from the pool of candidate bags for verbs. Using amod contexts for verb representation modeling may be a pure coincidence as a result of incorrect parses, and may eventually lead to deteriorated verb vectors. In another example, appositional modification captured by appos always denotes a relation between nouns, so it can be safely excluded as a candidate bag for adjectives and verbs. The construction of such initial class-specific pools is done automatically before the configuration search procedure starts (see line 1 in Alg. 1).\nBest Configuration Search Although a bruteforce exhaustive search over all possible configurations is possible in theory and for small pools (e.g., for adjectives, see Tab. 2), it becomes challenging or practically infeasible for large pools and large training data. For instance, based on the pool from Tab. 2, the search for the optimal configuration would involve trying out 27 \u2212 1 = 127 different configurations for verbs (i.e., training 127 different SGNS models) and 210 \u2212 1 = 1023 configurations for nouns (1023 SGNS models!). Therefore, to reduce the number of visited configurations, we have designed a simple heuristic search algorithm\n5Given the coordination structure boys and girls, training pairs are (boys, girls_conj), (girls, boys_conj\u22121).\n6Another choice is to retain all individual context bags and filter them later, see line 1 of Alg. 1.\ninspired by A* search (Hart et al., 1968).\nAlg. 1 provides a high-level overview of the algorithm while a toy example from Fig. 2 illustrates its flow. First, starting from all possible M individual context bags, the algorithm automatically detects the subset of K candidate individual bags that are used as the initial pool (line 1 of Alg. 1). The selection is based on some fitness (goal) function E. In our setup, E(R) is Spearman\u2019s \u03c1 correlation with human judgement scores obtained on the development set after training the SGNS model with the configuration R. The selection is automatic relying on a simple threshold. We use a threshold of \u03c1 \u2265 0.2 without any fine-tuning in all experiments with all word classes.\nThe algorithm then starts from the full K-set RPool configuration (line 3) and tests K (K \u2212 1)- set configurations where exactly one individual bag ri is removed to generate each such configuration (line 10). It then retains only (K\u22121)-set configurations that score higher than the higher-level origin K-set configuration from the previous step (lines 11-12, see Fig. 2). Using this principle, it continues searching only over lower-level (l \u2212 1)-set configurations that further improve performance over their l-set origin configuration. It stops if it reaches the lowest level or if it cannot improve the\nAlgorithm 1: Best Configuration Search Input :Set of M individual context bags:\n{r\u20321, r\u20322, . . . , r\u2032M} 1 build: pool of K \u2264M candidate individual context\nbags {r1, . . . , rK} according to the scores E(r\u20321), . . . , E(r \u2032 M ), where E(\u00b7) is a fitness function ;\n2 build: K-set configuration RPool = {r1, . . . , rK} ; 3 initialize: (1) set of candidate configurations R = {RPool} ; (2) current level l = K ; (3) best configuration Ro = \u2205 ; 4 search: 5 repeat 6 Rn \u2190 \u2205 ; 7 Ro \u2190 argmax\nR\u2208R E(R) ;\n8 foreach R \u2208 R do 9 foreach ri \u2208 R do\n10 build new (l \u2212 1)-set context configuration R\u00acri = R\u2212 {ri} ; 11 if E(R\u00acri) \u2265 E(R) then 12 Rn \u2190 Rn \u222a {R\u00acri} ;\n13 l\u2190 l \u2212 1 ; 14 R\u2190 Rn ; 15 until l == 0 or R == \u2205;\nOutput :Best configuration Ro\ngoal function any more (line 15). The best scoring configuration is returned (n.b., not guaranteed to be the global optimum).\nIn our experiments, with this heuristic, the search for the optimal configuration for verbs is performed only over 13 1-set configurations plus 26 other configurations (39 out of 133 possible configurations).7 For nouns, the advantage of the heuristic is even more dramatic: only 104 out of 1026 possible configurations were considered during the search.8"}, {"heading": "4 Experimental Setup", "text": "In terms of training data, pre-processing, parameter settings, and evaluation our setup is replicated from a recent related study by Levy et al. (2015).\nTraining Data All the representations in our comparison are induced from the cleaned and tokenised English Polyglot Wikipedia data (Al-Rfou et al., 2013).9 The corpus contains approx. 75M sentences and 1.5G word tokens.\n7The total is 133 and not 127 as we have to include 6 additional 1-group configurations that have to be tested but are not included in the initial pool for verbs, see Tab. 1 and Tab. 2.\n8We have also experimented with a less conservative algorithm variant which does not stop when lower-level configurations are unable to improve E; it instead follows the path of the best-scoring lower-level configuration even if its score is lower than the score of its origin. As we do not observe any significant difference between the two variants, we opt for the faster and simpler one.\n9https://sites.google.com/site/rmyeid/projects/polyglot\nThe Wikipedia data were POS-tagged with universal POS (UPOS) tags (Petrov et al., 2012) using state-of-the art TurboTagger (Martins et al., 2013)10, trained using default settings without any further parameter fine-tuning (SVM MIRA with 20 iterations) on the TRAIN+DEV portion of the UD treebank annotated with UPOS tags. The data were then parsed with UD11 using the graph-based Mate parser v3.61 (Bohnet, 2010)12 with standard settings on the TRAIN+DEV UD treebank portion.13\nEvaluation Following prior work (Schwartz et al., 2015; Schwartz et al., 2016), we experiment with the verb pair (222 pairs), adjective pair (111 pairs), and noun pair (666 pairs) portions of SimLex-999. We report Spearman\u2019s \u03c1 correlation between the ranks derived from the scores of the evaluated models and the human scores. Our final evaluation setup is borrowed from Levy et al. (2015): the context configurations are optimised on a development set, which is separate from the unseen test data. We perform 2-fold cross-validation; the reported scores are always the averages of the 2 runs. All scores are computed in the standard fashion, applying the cosine similarity to the vectors of words participating in a pair.\nBaseline Context Types We compare context configurations against relevant baseline context types from prior work (Melamud et al., 2016; Schwartz et al., 2016; Vulic\u0301 and Korhonen, 2016): - BOW: Standard bag-of-words contexts. - POSIT: Positional contexts (Sch\u00fctze, 1993; Levy and Goldberg, 2014b) which enrich BOW with information on the sequential position of each context word. Given the example from Fig. 1, POSIT with the window size 2 extracts these contexts for discovers: Australian_-2, scientist_-1, stars_+2, with_+1. - DEPS-All: All dependency links without any context selection, extracted from dependency-parsed data with prepositional arc collapsing. - COORD: Coordination-based contexts are used as fast lightweight contexts for improved representations of adjectives and verbs (Schwartz et al.,\n10http://www.cs.cmu.edu/~ark/TurboParser/ 11Such a language-universal tagging+parsing procedure has been chosen deliberately. As suggested by Vulic\u0301 and Korhonen (2016), the language-independent framework will facilitate extensions of this research to other languages in future work without any major language-specific adaptations.\n12https://code.google.com/archive/p/mate-tools/ 13We opt for the Mate parser due to its speed, simplicity,\nand state-of-the-art performance, see (Choi et al., 2015).\n2016). This is in fact the conjlr context bag, a subset of DEPS-All (see Step 3 in Sect. 3.2). - SP: Contexts based on symmetric patterns (SPs) (Davidov and Rappoport, 2006; Schwartz et al., 2015), lexico-syntactic constructs such as \u201cX and Y\u201d or \u201cX or Y\u201d; Y is then an SP context instance for X, and vice versa. The SP contexts, extracted from plain text, are very effective in modeling adjective and verb similarity, but they fall short of BOW and related approaches in noun similarity modeling (Schwartz et al., 2016).\nSGNS Preprocessing and Parameters The SGNS preprocessing scheme was replicated from (Levy and Goldberg, 2014a; Levy et al., 2015) with all context types. After lowercasing, all words and contexts that appeared less than 100 times were filtered. For DEPS-All, the vocabulary spans approx. 185K word types. The word2vecf SGNS for all models was trained using stochastic gradient descent and standard settings: 15 negative samples, global learning rate: 0.025, subsampling rate: 1e\u2212 4, 15 epochs.\nFurther, all representations were trained with d = 300 (very similar trends are observed with d = 100, 500). For BOW and POSIT, the window size was tuned on the dev set: its value is 2 in all experiments, which is aligned with prior work (Schwartz et al., 2015). Parameters for the extraction of SPs were also tuned on the dev set.14\n14The SP extraction algorithm is available online:\nBaselines (Verbs) BOW (win=2) 0.336 POSIT (win=2) 0.345 COORD (conjlr) 0.283 SP 0.349 DEPS-All 0.344\nBaselines (Nouns) BOW (win=2) 0.435 POSIT (win=2) 0.437 COORD (conjlr) 0.392 SP 0.372 DEPS-All 0.441"}, {"heading": "5 Results and Discussion", "text": "Not All Context Bags are Created Equal First, we test the performance of individual context bags across SimLex-999 adjective, verb, and noun subsets. Besides providing insight on the intuition behind context selection, these findings are important for the automatic selection of class-specific pools. The results are shown in Tab. 1.\nThe experiment supports our intuition (see Sect. 3.1): some context bags are definitely not useful for some classes and may be safely removed when performing the class-specific SGNS training. For instance, the amod bag is indeed important for adjective and noun similarity, and at the same time it does not encode any useful information regarding verb similarity; compound is, as expected, useful only for nouns. Tab. 1 also suggests that some\nhttp://www.cs.huji.ac.il/\u223croys02/software/dr06/dr06.html\ncontext bags (e.g., nummod) do not encode any informative contextual evidence regarding similarity, therefore they can be discarded. The initial results with individual context bags help to reduce the pool of candidate bags (line 1 in Alg. 1), see Tab. 2. Note that while Tab. 1 shows cross-validation results, the actual pool is based solely on the dev set performance.\nSearching for Optimal Configurations Next, we test if we can actually improve class-specific representations by selecting specialised configurations. We traverse the configuration search space on the dev set using the proposed algorithm (Alg. 1). The results per word class are summarised in Tables 3 and 4.\nClass-specific context configurations yield more accurate representations, as evident from scores on SimLex-999 subsets and improvements over all baselines. The improvements with the best classspecific configurations found by Alg. 1 are approximately 6 \u03c1 points for adjectives, 6 for verbs, and 5 for nouns over the best baseline for each class.\nThe improvements are visible even with configurations that simply pool all candidate individual bags (POOL-ALL), without running Alg. 1. However, further careful context selection, i.e., traversing the configuration space using Alg. 1 leads to additional improvements for V and N (gains of 3 and 2.2 \u03c1 points).\nIt is interesting to point out that the best configuration for verbs do not include subj or obj contexts, which seem to be more important in noun\nrepresentation modeling. Very similar improved scores are achieved with a variety of configurations (see Tab. 3), especially in the neighbourhood of the optimal configuration found by Alg. 1. This indicates that the method is quite robust: even sub-optimal solutions result in improved class-specific representations.\nTOEFL Evaluation The effects of per-class representation specialisation are further supported by evaluation on the A, V, and N TOEFL questions (Landauer and Dumais, 1997). The results are summarised in Tab. 5. However, the limited size (e.g., only 19 V and N questions, 41 A questions) prevents us from drawing any general conclusions with this evaluation set.\nTraining: Fast and/or Accurate? Since context configurations rely on the idea of context selection, their advantage also lies in reduced training times for SGNS. The configuration-based model trains on only 14% (A), 26.2% (V), and 33.6% (N) of all dependency-based contexts. Training times along with the total number of training pairs for each context type are displayed in Tab. 6. All SGNS models were trained using parallel word2vecf training on 10 Intel(R) Xeon(R) E5-2667 2.90GHz processors.\nThe results indicate that class-specific configurations are not as lightweight and fast as SP or COORD contexts (Schwartz et al., 2016). However, the results also suggest that such configurations provide a better trade-off between accuracy and speed: they reach peak performances for each word class, outscoring all baseline context types (including SP and COORD), while at the same time training is still much faster than with \u201cheavyweight\u201d full context types such as BOW, POSIT or DEPS-All.\nAnother Training Setup To demonstrate that context configurations generalise to settings with more training data, and other annotation and parser choices, in another experiment we have replicated the experimental setup of Schwartz et al. (2016).\nThe training corpus is now the 8G words corpus generated by the word2vec script.15 A preprocessing step now merges common word pairs and triplets to expression tokens (e.g., Bilbo_Baggins). The corpus is parsed with labeled Stanford dependencies (de Marneffe and Manning, 2008) following (Levy and Goldberg, 2014a; Schwartz et al., 2016): Stanford POS Tagger (Toutanova et al., 2003) and the stack version of the MALT parser (Goldberg and Nivre, 2012). SGNS preprocessing and parameters are also replicated; the only difference is training with 500-dimensional embeddings as in prior work.\nWe use the same set of individual context bags as before. The straightforward \u201ctranslation\u201d from labelled Stanford dependencies into UD is performed using the mapping from de Marneffe et al. (2014),\ne.g., nn is mapped into compound, and rcmod, partmod, infmod are all mapped into one individual bag acl.\nAs in previous experiments, we again build classspecific configurations and evaluate on A/V/N subsets of SimLex-999. We also evaluate another configuration found using Alg. 1, which targets the overall improved performance without any finergrained division to word classes (BEST-ALL). The results are provided in Tab. 7.\nClass-specific configurations again outperform competitive baseline context types for adjectives and nouns. The BEST-VERBS configuration is slightly outscored by the SP baseline, but the difference is not statistically significant. Further, SGNS with the BEST-ALL configuration (amod+subj+obj+compound+prep+adv+conj) outperforms all baseline models on the entire benchmark. This finding also extends to the previous training setup. Interestingly, the non-specific BEST-ALL configuration falls short of A/V/Nspecific configurations for each class."}, {"heading": "6 Conclusion", "text": "We have presented a novel framework for selecting class-specific context configurations which yield improved and fast representations for prominent word classes: adjectives, verbs, and nouns. Each word class requires a different configuration to produce optimal results on the class-specific subset of SimLex-999. We have also proposed an algorithm that is able to find a suitable class-specific configuration while making the search over the large space of possible context configurations computationally feasible.\nOur approach is designed to be as general as possible, and can be employed to other contexts types, evaluation tasks and languages. It is especially important to stress the language portability of our approach. It relies on language-agnostic annotations stemming from the initiative on Universal Dependencies, and it also uses language-agnostic POS taggers and dependency parsers. We have also conducted preliminary experiments using exactly the same framework with verb- and adjectivespecialised word representations for German and Italian. Evaluations on German and Italian SimLex999 (Leviant and Reichart, 2015)16 display similar patterns as for English, and demonstrate that our framework can be easily applied to other languages.\n16http://technion.ac.il/\u223cira.leviant/\nIn future work, we plan to test the framework with finer-grained individual context bags, and investigate beyond POS-based word classes and dependency relations; this may further refine and specialise induced vector spaces. We also plan to test the portability of the proposed approach to more languages."}], "references": [{"title": "Polyglot: Distributed word representations for multilingual NLP", "author": ["Al-Rfou et al.2013] Rami Al-Rfou", "Bryan Perozzi", "Steven Skiena"], "venue": "In CoNLL,", "citeRegEx": "Al.Rfou et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Al.Rfou et al\\.", "year": 2013}, {"title": "Tailoring continuous word representations for dependency parsing", "author": ["Bansal et al.2014] Mohit Bansal", "Kevin Gimpel", "Karen Livescu"], "venue": "In ACL,", "citeRegEx": "Bansal et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bansal et al\\.", "year": 2014}, {"title": "Strudel: A corpus-based semantic model based on properties and types", "author": ["Baroni et al.2010] Marco Baroni", "Brian Murphy", "Eduard Barbu", "Massimo Poesio"], "venue": "Cognitive Science,", "citeRegEx": "Baroni et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Baroni et al\\.", "year": 2010}, {"title": "Don\u2019t count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors", "author": ["Baroni et al.2014] Marco Baroni", "Georgiana Dinu", "Germ\u00e1n Kruszewski"], "venue": "In ACL,", "citeRegEx": "Baroni et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Baroni et al\\.", "year": 2014}, {"title": "Top accuracy and fast dependency parsing is not a contradiction", "author": ["Bernd Bohnet"], "venue": "In COLING,", "citeRegEx": "Bohnet.,? \\Q2010\\E", "shortCiteRegEx": "Bohnet.", "year": 2010}, {"title": "A fast and accurate dependency parser using neural networks", "author": ["Chen", "Manning2014] Danqi Chen", "Christopher D. Manning"], "venue": "In EMNLP,", "citeRegEx": "Chen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2014}, {"title": "It depends: Dependency parser comparison using a Web-based evaluation tool", "author": ["Choi et al.2015] Jinho D. Choi", "Joel Tetreault", "Amanda Stent"], "venue": "In ACL,", "citeRegEx": "Choi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Choi et al\\.", "year": 2015}, {"title": "Natural language processing (almost) from scratch", "author": ["Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel P. Kuksa"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Collobert et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Efficient unsupervised discovery of word categories using symmetric patterns and high frequency words", "author": ["Davidov", "Rappoport2006] Dmitry Davidov", "Ari Rappoport"], "venue": "In ACL,", "citeRegEx": "Davidov et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Davidov et al\\.", "year": 2006}, {"title": "The Stanford typed dependencies representation", "author": ["de Marneffe", "Christopher D. Manning"], "venue": "In Proceedings of the Workshop on Cross-Framework and Cross-Domain Parser Evaluation,", "citeRegEx": "Marneffe et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Marneffe et al\\.", "year": 2008}, {"title": "Universal Stanford dependencies: A cross-linguistic typology", "author": ["Timothy Dozat", "Natalia Silveira", "Katri Haverinen", "Filip Ginter", "Joakim Nivre", "Christopher D. Manning"], "venue": "In LREC,", "citeRegEx": "Marneffe et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Marneffe et al\\.", "year": 2014}, {"title": "Retrofitting word vectors to semantic lexicons", "author": ["Jesse Dodge", "Sujay Kumar Jauhar", "Chris Dyer", "Eduard Hovy", "Noah A. Smith"], "venue": "In NAACL-HLT,", "citeRegEx": "Faruqui et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Faruqui et al\\.", "year": 2015}, {"title": "A dynamic oracle for arc-eager dependency parsing", "author": ["Goldberg", "Nivre2012] Yoav Goldberg", "Joakim Nivre"], "venue": "In COLING,", "citeRegEx": "Goldberg et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Goldberg et al\\.", "year": 2012}, {"title": "Explorations in automatic thesaurus discovery", "author": ["Gregory Grefenstette"], "venue": null, "citeRegEx": "Grefenstette.,? \\Q1994\\E", "shortCiteRegEx": "Grefenstette.", "year": 1994}, {"title": "A formal basis for the heuristic determination of minimum cost paths", "author": ["Hart et al.1968] Peter E. Hart", "Nils J. Nilsson", "Bertram Raphael"], "venue": "IEEE Transactions on Systems Science and Cybernetics,", "citeRegEx": "Hart et al\\.,? \\Q1968\\E", "shortCiteRegEx": "Hart et al\\.", "year": 1968}, {"title": "SimLex-999: Evaluating semantic models with (genuine) similarity estimation", "author": ["Hill et al.2015] Felix Hill", "Roi Reichart", "Anna Korhonen"], "venue": null, "citeRegEx": "Hill et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hill et al\\.", "year": 2015}, {"title": "Specializing word embeddings for similarity or relatedness", "author": ["Kiela et al.2015] Douwe Kiela", "Felix Hill", "Stephen Clark"], "venue": "In EMNLP,", "citeRegEx": "Kiela et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kiela et al\\.", "year": 2015}, {"title": "Solutions to Plato\u2019s problem: The Latent Semantic Analysis theory of acquisition, induction, and representation of knowledge", "author": ["Landauer", "Dumais1997] Thomas K. Landauer", "Susan T. Dumais"], "venue": "Psychological Review,", "citeRegEx": "Landauer et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Landauer et al\\.", "year": 1997}, {"title": "Separated by an un-common language: Towards judgment language informed vector space modeling. CoRR, abs/1508.00106", "author": ["Leviant", "Reichart2015] Ira Leviant", "Roi Reichart"], "venue": null, "citeRegEx": "Leviant et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Leviant et al\\.", "year": 2015}, {"title": "Dependency-based word embeddings", "author": ["Levy", "Goldberg2014a] Omer Levy", "Yoav Goldberg"], "venue": "In ACL,", "citeRegEx": "Levy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Levy et al\\.", "year": 2014}, {"title": "Linguistic regularities in sparse and explicit word representations", "author": ["Levy", "Goldberg2014b] Omer Levy", "Yoav Goldberg"], "venue": "In CoNLL,", "citeRegEx": "Levy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Levy et al\\.", "year": 2014}, {"title": "Neural word embedding as implicit matrix factorization", "author": ["Levy", "Goldberg2014c] Omer Levy", "Yoav Goldberg"], "venue": "In NIPS,", "citeRegEx": "Levy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Levy et al\\.", "year": 2014}, {"title": "Improving distributional similarity with lessons learned from word embeddings", "author": ["Levy et al.2015] Omer Levy", "Yoav Goldberg", "Ido Dagan"], "venue": "Transactions of the ACL,", "citeRegEx": "Levy et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Levy et al\\.", "year": 2015}, {"title": "Not all contexts are created equal: Better word representations with variable attention", "author": ["Ling et al.2015] Wang Ling", "Yulia Tsvetkov", "Silvio Amir", "Ramon Fermandez", "Chris Dyer", "Alan W Black", "Isabel Trancoso", "Chu-Cheng Lin"], "venue": null, "citeRegEx": "Ling et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ling et al\\.", "year": 2015}, {"title": "Learning semantic word embeddings based on ordinal knowledge constraints", "author": ["Liu et al.2015] Quan Liu", "Hui Jiang", "Si Wei", "Zhen-Hua Ling", "Yu Hu"], "venue": null, "citeRegEx": "Liu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2015}, {"title": "Turning on the turbo: Fast third-order non-projective turbo parsers", "author": ["Miguel B. Almeida", "Noah A. Smith"], "venue": "In ACL,", "citeRegEx": "Martins et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Martins et al\\.", "year": 2013}, {"title": "Universal dependency annotation for multilingual parsing", "author": ["mee Lee"], "venue": "In ACL,", "citeRegEx": "Lee.,? \\Q2013\\E", "shortCiteRegEx": "Lee.", "year": 2013}, {"title": "Modeling word meaning in context with substitute vectors", "author": ["Melamud et al.2015] Oren Melamud", "Ido Dagan", "Jacob Goldberger"], "venue": "In NAACL-HLT,", "citeRegEx": "Melamud et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Melamud et al\\.", "year": 2015}, {"title": "The role of context types and dimensionality in learning word embeddings", "author": ["Melamud et al.2016] Oren Melamud", "David McClosky", "Siddharth Patwardhan", "Mohit Bansal"], "venue": null, "citeRegEx": "Melamud et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Melamud et al\\.", "year": 2016}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Gregory S. Corrado", "Jeffrey Dean"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Learning word embeddings efficiently with noise-contrastive estimation", "author": ["Mnih", "Kavukcuoglu2013] Andriy Mnih", "Koray Kavukcuoglu"], "venue": "In NIPS,", "citeRegEx": "Mnih et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mnih et al\\.", "year": 2013}, {"title": "Counter-fitting word vectors to linguistic", "author": ["Mrk\u0161i\u0107 et al.2016] Nikola Mrk\u0161i\u0107", "Diarmuid \u00d3 S\u00e9aghdha", "Blaise Thomson", "Milica Ga\u0161i\u0107", "Lina Maria Rojas-Barahona", "Pei-Hao Su", "David Vandyke", "Tsung-Hsien Wen", "Steve J. Young"], "venue": null, "citeRegEx": "Mrk\u0161i\u0107 et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Mrk\u0161i\u0107 et al\\.", "year": 2016}, {"title": "Universal Dependencies 1.2. LINDAT/CLARIN digital library at Institute of Formal and Applied Linguistics, Charles University in Prague", "author": ["Nivre et al.2015] Joakim Nivre"], "venue": null, "citeRegEx": "Nivre,? \\Q2015\\E", "shortCiteRegEx": "Nivre", "year": 2015}, {"title": "Dependency-based construction of semantic space models", "author": ["Pad\u00f3", "Lapata2007] Sebastian Pad\u00f3", "Mirella Lapata"], "venue": "Computational Linguistics,", "citeRegEx": "Pad\u00f3 et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Pad\u00f3 et al\\.", "year": 2007}, {"title": "Glove: Global vectors for word representation", "author": ["Richard Socher", "Christopher Manning"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Pennington et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "A universal part-ofspeech tagset", "author": ["Petrov et al.2012] Slav Petrov", "Dipanjan Das", "Ryan T. McDonald"], "venue": "In LREC,", "citeRegEx": "Petrov et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Petrov et al\\.", "year": 2012}, {"title": "The SMART Retrieval System: Experiments in Automatic Document Processing", "author": ["Gerard Salton"], "venue": null, "citeRegEx": "Salton.,? \\Q1971\\E", "shortCiteRegEx": "Salton.", "year": 1971}, {"title": "Part-of-speech induction from scratch", "author": ["Hinrich Sch\u00fctze"], "venue": "In ACL,", "citeRegEx": "Sch\u00fctze.,? \\Q1993\\E", "shortCiteRegEx": "Sch\u00fctze.", "year": 1993}, {"title": "Symmetric pattern based word embeddings for improved word similarity prediction", "author": ["Roi Reichart", "Ari Rappoport"], "venue": "In CoNLL,", "citeRegEx": "Schwartz et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Schwartz et al\\.", "year": 2015}, {"title": "Symmetric patterns and coordinations: Fast and enhanced representations of verbs and adjectives", "author": ["Roi Reichart", "Ari Rappoport"], "venue": "In NAACL-HLT,", "citeRegEx": "Schwartz et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Schwartz et al\\.", "year": 2016}, {"title": "Feature-rich part-of-speech tagging with a cyclic dependency network", "author": ["Dan Klein", "Christopher D. Manning", "Yoram Singer"], "venue": "In NAACL-HLT,", "citeRegEx": "Toutanova et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Toutanova et al\\.", "year": 2003}, {"title": "Word representations: A simple and general method for semi-supervised learning", "author": ["Lev-Arie Ratinov", "Yoshua Bengio"], "venue": "In ACL,", "citeRegEx": "Turian et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Turian et al\\.", "year": 2010}, {"title": "Crosslingual and multilingual construction of syntax-based vector space models", "author": ["Utt", "Pad\u00f32014] Jason Utt", "Sebastian Pad\u00f3"], "venue": "Transactions of the ACL,", "citeRegEx": "Utt et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Utt et al\\.", "year": 2014}, {"title": "Is \u201cuniversal syntax\u201d universally useful for learning distributed word representations", "author": ["Vuli\u0107", "Korhonen2016] Ivan Vuli\u0107", "Anna Korhonen"], "venue": "In ACL,", "citeRegEx": "Vuli\u0107 et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Vuli\u0107 et al\\.", "year": 2016}, {"title": "From paraphrase database to compositional paraphrase model and back", "author": ["Wieting et al.2015] John Wieting", "Mohit Bansal", "Kevin Gimpel", "Karen Livescu"], "venue": "Transactions of the ACL,", "citeRegEx": "Wieting et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wieting et al\\.", "year": 2015}, {"title": "Learning syntactic categories using paradigmatic representations of word context", "author": ["Enis Sert", "Deniz Yuret"], "venue": "In EMNLP,", "citeRegEx": "Yatbaz et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Yatbaz et al\\.", "year": 2012}, {"title": "Improving lexical embeddings with semantic knowledge", "author": ["Yu", "Dredze2014] Mo Yu", "Mark Dredze"], "venue": "In ACL,", "citeRegEx": "Yu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 41, "context": "Dense real-valued distributed word representations, or word embeddings, have become ubiquitous in NLP, serving as invaluable features in a broad range of NLP tasks (Turian et al., 2010; Collobert et al., 2011; Chen and Manning, 2014).", "startOffset": 164, "endOffset": 233}, {"referenceID": 7, "context": "Dense real-valued distributed word representations, or word embeddings, have become ubiquitous in NLP, serving as invaluable features in a broad range of NLP tasks (Turian et al., 2010; Collobert et al., 2011; Chen and Manning, 2014).", "startOffset": 164, "endOffset": 233}, {"referenceID": 29, "context": "The omnipresent word2vec skip-gram model with negative sampling (SGNS) (Mikolov et al., 2013) is still considered the state-of-the-art word representation model, due to its simplicity, fast training, as well as its solid and robust performance across a wide variety of semantic tasks (Baroni et al.", "startOffset": 71, "endOffset": 93}, {"referenceID": 3, "context": ", 2013) is still considered the state-of-the-art word representation model, due to its simplicity, fast training, as well as its solid and robust performance across a wide variety of semantic tasks (Baroni et al., 2014; Levy et al., 2015).", "startOffset": 198, "endOffset": 238}, {"referenceID": 22, "context": ", 2013) is still considered the state-of-the-art word representation model, due to its simplicity, fast training, as well as its solid and robust performance across a wide variety of semantic tasks (Baroni et al., 2014; Levy et al., 2015).", "startOffset": 198, "endOffset": 238}, {"referenceID": 1, "context": "Recent work demonstrated that reaching beyond the omnipresent BOW contexts towards contexts based on dependency parses (Bansal et al., 2014; Schwartz et al., 2016; Melamud et al., 2016) or symmetric patterns (Schwartz et al.", "startOffset": 119, "endOffset": 185}, {"referenceID": 39, "context": "Recent work demonstrated that reaching beyond the omnipresent BOW contexts towards contexts based on dependency parses (Bansal et al., 2014; Schwartz et al., 2016; Melamud et al., 2016) or symmetric patterns (Schwartz et al.", "startOffset": 119, "endOffset": 185}, {"referenceID": 28, "context": "Recent work demonstrated that reaching beyond the omnipresent BOW contexts towards contexts based on dependency parses (Bansal et al., 2014; Schwartz et al., 2016; Melamud et al., 2016) or symmetric patterns (Schwartz et al.", "startOffset": 119, "endOffset": 185}, {"referenceID": 38, "context": ", 2016) or symmetric patterns (Schwartz et al., 2015; Schwartz et al., 2016) yields significant improvements in learning representations for particular word classes such as adjectives (A) and verbs (V).", "startOffset": 30, "endOffset": 76}, {"referenceID": 39, "context": ", 2016) or symmetric patterns (Schwartz et al., 2015; Schwartz et al., 2016) yields significant improvements in learning representations for particular word classes such as adjectives (A) and verbs (V).", "startOffset": 30, "endOffset": 76}, {"referenceID": 23, "context": "1 Further, several recent studies (Ling et al., 2015; Schwartz et al., 2016) suggested that \u201cnot all contexts are created equal\u201d: for instance, Schwartz et al.", "startOffset": 34, "endOffset": 76}, {"referenceID": 39, "context": "1 Further, several recent studies (Ling et al., 2015; Schwartz et al., 2016) suggested that \u201cnot all contexts are created equal\u201d: for instance, Schwartz et al.", "startOffset": 34, "endOffset": 76}, {"referenceID": 15, "context": "Besides their competitive performance on verb and adjective similarity measured on SimLex-999 (Hill et al., 2015), training with such coordination-based contexts is significantly faster due to the pre-training selection step.", "startOffset": 94, "endOffset": 113}, {"referenceID": 1, "context": "Recent work demonstrated that reaching beyond the omnipresent BOW contexts towards contexts based on dependency parses (Bansal et al., 2014; Schwartz et al., 2016; Melamud et al., 2016) or symmetric patterns (Schwartz et al., 2015; Schwartz et al., 2016) yields significant improvements in learning representations for particular word classes such as adjectives (A) and verbs (V). Curiously enough, despite the success story with adjectives and verbs, SGNS with BOW contexts still outperforms all other context types in noun (N) representation learning.1 Further, several recent studies (Ling et al., 2015; Schwartz et al., 2016) suggested that \u201cnot all contexts are created equal\u201d: for instance, Schwartz et al. (2016) show that it is possible to learn highquality representations of verbs and adjectives using only a subset of dependency-based contexts that covers coordination structures for the SGNS training while discarding everything else.", "startOffset": 120, "endOffset": 720}, {"referenceID": 38, "context": "We refer the reader to the work of Schwartz et al. (2016) for a comprehensive overview of results on SimLex-999.", "startOffset": 35, "endOffset": 58}, {"referenceID": 22, "context": "Using a standard experimental setup (Levy et al., 2015), we outperform the best baseline context type for each word class: the improvements are 6 \u03c1 points for adjectives, 6 for verbs, and 5 for nouns over the best previously proposed context type for each word class.", "startOffset": 36, "endOffset": 55}, {"referenceID": 39, "context": "We also demonstrate that the proposed method is robust: the improvements extend to another standard training setup (Schwartz et al., 2016) which uses more training data, as well as a different parser and a different dependency annotation scheme.", "startOffset": 115, "endOffset": 138}, {"referenceID": 36, "context": "Word representations, also known as vector space models or word embeddings, date back to the early 1970s (Salton, 1971).", "startOffset": 105, "endOffset": 119}, {"referenceID": 13, "context": "These include dependency contexts (Grefenstette, 1994; Pad\u00f3 and Lapata, 2007; Levy and Goldberg, 2014a), pattern contexts (Baroni et", "startOffset": 34, "endOffset": 103}, {"referenceID": 45, "context": ", 2015) and substitute vectors (Yatbaz et al., 2012; Melamud et al., 2015).", "startOffset": 31, "endOffset": 74}, {"referenceID": 27, "context": ", 2015) and substitute vectors (Yatbaz et al., 2012; Melamud et al., 2015).", "startOffset": 31, "endOffset": 74}, {"referenceID": 27, "context": "Melamud et al. (2016) compared three context types on a set of intrinsic and extrinsic evaluation setups, and showed that the optimal type largely depends on the task at hand.", "startOffset": 0, "endOffset": 22}, {"referenceID": 27, "context": "Melamud et al. (2016) compared three context types on a set of intrinsic and extrinsic evaluation setups, and showed that the optimal type largely depends on the task at hand. Vuli\u0107 and Korhonen (2016) compared a few variants of", "startOffset": 0, "endOffset": 202}, {"referenceID": 38, "context": "Schwartz et al. (2016), showed that symmetric patterns are very useful contexts for verb and adjective similarity, while BOW works best for nouns, measured on", "startOffset": 0, "endOffset": 23}, {"referenceID": 15, "context": "the benchmarking SimLex-999 (Hill et al., 2015) evaluation set.", "startOffset": 28, "endOffset": 47}, {"referenceID": 44, "context": ", similarity vs relatedness, antonyms) operate in one of the two following frameworks: (1) modifying the prior or the regularisation of the original training procedure (Yu and Dredze, 2014; Wieting et al., 2015; Liu et al., 2015; Kiela et al., 2015; Ling et al., 2015); (2) \u201clight\u201d post-processing procedures which use lexical knowledge to refine offthe-shelf pre-trained word vectors (Faruqui et al.", "startOffset": 168, "endOffset": 268}, {"referenceID": 24, "context": ", similarity vs relatedness, antonyms) operate in one of the two following frameworks: (1) modifying the prior or the regularisation of the original training procedure (Yu and Dredze, 2014; Wieting et al., 2015; Liu et al., 2015; Kiela et al., 2015; Ling et al., 2015); (2) \u201clight\u201d post-processing procedures which use lexical knowledge to refine offthe-shelf pre-trained word vectors (Faruqui et al.", "startOffset": 168, "endOffset": 268}, {"referenceID": 16, "context": ", similarity vs relatedness, antonyms) operate in one of the two following frameworks: (1) modifying the prior or the regularisation of the original training procedure (Yu and Dredze, 2014; Wieting et al., 2015; Liu et al., 2015; Kiela et al., 2015; Ling et al., 2015); (2) \u201clight\u201d post-processing procedures which use lexical knowledge to refine offthe-shelf pre-trained word vectors (Faruqui et al.", "startOffset": 168, "endOffset": 268}, {"referenceID": 23, "context": ", similarity vs relatedness, antonyms) operate in one of the two following frameworks: (1) modifying the prior or the regularisation of the original training procedure (Yu and Dredze, 2014; Wieting et al., 2015; Liu et al., 2015; Kiela et al., 2015; Ling et al., 2015); (2) \u201clight\u201d post-processing procedures which use lexical knowledge to refine offthe-shelf pre-trained word vectors (Faruqui et al.", "startOffset": 168, "endOffset": 268}, {"referenceID": 11, "context": ", 2015); (2) \u201clight\u201d post-processing procedures which use lexical knowledge to refine offthe-shelf pre-trained word vectors (Faruqui et al., 2015; Mrk\u0161i\u0107 et al., 2016).", "startOffset": 124, "endOffset": 167}, {"referenceID": 31, "context": ", 2015); (2) \u201clight\u201d post-processing procedures which use lexical knowledge to refine offthe-shelf pre-trained word vectors (Faruqui et al., 2015; Mrk\u0161i\u0107 et al., 2016).", "startOffset": 124, "endOffset": 167}, {"referenceID": 22, "context": "For all context configurations and all other (baseline) context types, we opt for the standard and very robust choice (Levy et al., 2015) in vector space modeling: SGNS (Mikolov et al.", "startOffset": 118, "endOffset": 137}, {"referenceID": 29, "context": ", 2015) in vector space modeling: SGNS (Mikolov et al., 2013).", "startOffset": 39, "endOffset": 61}, {"referenceID": 35, "context": ", 2014) complemented with the universal POS tagset (Petrov et al., 2012).", "startOffset": 51, "endOffset": 72}, {"referenceID": 39, "context": "(3) Coordination-based contexts are extracted as in prior work (Schwartz et al., 2016), distinguishing between left and right contexts extracted from the conj relation.", "startOffset": 63, "endOffset": 86}, {"referenceID": 14, "context": "inspired by A* search (Hart et al., 1968).", "startOffset": 22, "endOffset": 41}, {"referenceID": 19, "context": "In terms of training data, pre-processing, parameter settings, and evaluation our setup is replicated from a recent related study by Levy et al. (2015).", "startOffset": 133, "endOffset": 152}, {"referenceID": 0, "context": "Training Data All the representations in our comparison are induced from the cleaned and tokenised English Polyglot Wikipedia data (Al-Rfou et al., 2013).", "startOffset": 131, "endOffset": 153}, {"referenceID": 35, "context": "The Wikipedia data were POS-tagged with universal POS (UPOS) tags (Petrov et al., 2012) using state-of-the art TurboTagger (Martins et al.", "startOffset": 66, "endOffset": 87}, {"referenceID": 25, "context": ", 2012) using state-of-the art TurboTagger (Martins et al., 2013)10, trained using default settings without any further parameter fine-tuning (SVM MIRA with 20 iterations) on the TRAIN+DEV portion of the UD treebank annotated with UPOS tags.", "startOffset": 43, "endOffset": 65}, {"referenceID": 4, "context": "61 (Bohnet, 2010)12 with standard settings on the TRAIN+DEV UD treebank portion.", "startOffset": 3, "endOffset": 17}, {"referenceID": 38, "context": "Evaluation Following prior work (Schwartz et al., 2015; Schwartz et al., 2016), we experiment with the verb pair (222 pairs), adjective pair (111 pairs), and noun pair (666 pairs) portions of SimLex-999.", "startOffset": 32, "endOffset": 78}, {"referenceID": 39, "context": "Evaluation Following prior work (Schwartz et al., 2015; Schwartz et al., 2016), we experiment with the verb pair (222 pairs), adjective pair (111 pairs), and noun pair (666 pairs) portions of SimLex-999.", "startOffset": 32, "endOffset": 78}, {"referenceID": 19, "context": "Our final evaluation setup is borrowed from Levy et al. (2015): the context configurations are optimised on a development set, which is separate from the unseen test data.", "startOffset": 44, "endOffset": 63}, {"referenceID": 28, "context": "configurations against relevant baseline context types from prior work (Melamud et al., 2016; Schwartz et al., 2016; Vuli\u0107 and Korhonen, 2016): - BOW: Standard bag-of-words contexts.", "startOffset": 71, "endOffset": 142}, {"referenceID": 39, "context": "configurations against relevant baseline context types from prior work (Melamud et al., 2016; Schwartz et al., 2016; Vuli\u0107 and Korhonen, 2016): - BOW: Standard bag-of-words contexts.", "startOffset": 71, "endOffset": 142}, {"referenceID": 6, "context": "com/archive/p/mate-tools/ We opt for the Mate parser due to its speed, simplicity, and state-of-the-art performance, see (Choi et al., 2015).", "startOffset": 121, "endOffset": 140}, {"referenceID": 38, "context": "- SP: Contexts based on symmetric patterns (SPs) (Davidov and Rappoport, 2006; Schwartz et al., 2015), lexico-syntactic constructs such as \u201cX and Y\u201d or \u201cX or Y\u201d; Y is then an SP context instance for X, and vice versa.", "startOffset": 49, "endOffset": 101}, {"referenceID": 39, "context": "The SP contexts, extracted from plain text, are very effective in modeling adjective and verb similarity, but they fall short of BOW and related approaches in noun similarity modeling (Schwartz et al., 2016).", "startOffset": 184, "endOffset": 207}, {"referenceID": 22, "context": "SGNS Preprocessing and Parameters The SGNS preprocessing scheme was replicated from (Levy and Goldberg, 2014a; Levy et al., 2015) with all context types.", "startOffset": 84, "endOffset": 129}, {"referenceID": 38, "context": "For BOW and POSIT, the window size was tuned on the dev set: its value is 2 in all experiments, which is aligned with prior work (Schwartz et al., 2015).", "startOffset": 129, "endOffset": 152}, {"referenceID": 39, "context": "The results indicate that class-specific configurations are not as lightweight and fast as SP or COORD contexts (Schwartz et al., 2016).", "startOffset": 112, "endOffset": 135}, {"referenceID": 38, "context": "Another Training Setup To demonstrate that context configurations generalise to settings with more training data, and other annotation and parser choices, in another experiment we have replicated the experimental setup of Schwartz et al. (2016).", "startOffset": 222, "endOffset": 245}, {"referenceID": 39, "context": "The corpus is parsed with labeled Stanford dependencies (de Marneffe and Manning, 2008) following (Levy and Goldberg, 2014a; Schwartz et al., 2016): Stanford POS Tagger (Toutanova et al.", "startOffset": 98, "endOffset": 147}, {"referenceID": 40, "context": ", 2016): Stanford POS Tagger (Toutanova et al., 2003) and the stack version of the MALT parser (Goldberg and Nivre, 2012).", "startOffset": 29, "endOffset": 53}, {"referenceID": 9, "context": "The straightforward \u201ctranslation\u201d from labelled Stanford dependencies into UD is performed using the mapping from de Marneffe et al. (2014),", "startOffset": 117, "endOffset": 140}, {"referenceID": 38, "context": "Table 7: Results on the A/V/N SimLex-999 subsets, and on the entire set (All) in the training setup from Schwartz et al. (2016). d = 500.", "startOffset": 105, "endOffset": 128}], "year": 2016, "abstractText": "Recent work has demonstrated that stateof-the-art word embedding models require different context types to produce highquality representations for different word classes such as adjectives (A), verbs (V), and nouns (N). This paper is concerned with identifying contexts useful for learning A/V/N-specific representations. We introduce a simple yet effective framework for selecting class-specific context configurations that yield improved representations for each class. We propose an automatic A* style selection algorithm that effectively searches only a fraction of the large configuration space. The results on predicting similarity scores for the A, V, and N subsets of the benchmarking SimLex-999 evaluation set indicate that our method is useful for each class: the improvements are 6% (A), 6% (V), and 5% (N) over the best previously proposed context type for each class. At the same time, the model trains on only 14% (A), 26.2% (V), and 33.6% (N) of all dependency-based contexts, resulting in much shorter training time.", "creator": "LaTeX with hyperref package"}}}