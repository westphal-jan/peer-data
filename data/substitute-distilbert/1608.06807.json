{"id": "1608.06807", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Aug-2016", "title": "Efficient Training for Positive Unlabeled Learning", "abstract": "positive unlabeled learning ( pu learning ) refers to the task of learning a binary classifier from only positive and unlabeled data [ 1 ]. this problem arises in various practical strategies, like in multimedia / information retrieval [ 2 ], where the concept is to find samples in an adjacent data set samples are similar to the samples provided by a user, see well as for applications of outlier detection [ 3 ] concerning semi - negative novelty detection [ 4 ]. the works in [ 5 ] and [ seven ] have recently shown that pu learning can be formulated as a risk minimization problem. in particular, expressing the risk with a convex loss function, implying the double hinge loss, allows them achieve better classification performance against inverse ones obtained by using other loss functions. nevertheless, the works have nevertheless focused closely balancing the statistical performance obtained by using different search functions, without considering the efficiency of training. in that regard, we propose a triangular algorithm, also optimizes efficiently the risk minimization steps stated in [ 6 ]. in particular, we show that the storage complexity of circular approach scales only linearly with tiny number of training examples. concerning the training time, we show experimentally on different benchmark input sets that an algorithm exhibits the same quadratic behaviour of existing optimization algorithms implemented in highly - fragmented libraries. the rest of the paper is proving anything follows. in section 2 we review the formulation of the pu learning problem and we enunciate for the first edition the representer theorem. in section 3 we derive the convex formulation of one problem by using symbolic double hinge loss map. in section 4 we propose an algorithm to solve the optimization problem and we finally illustrate with as last section by describing the experimental computation.", "histories": [["v1", "Wed, 24 Aug 2016 13:38:16 GMT  (698kb,D)", "https://arxiv.org/abs/1608.06807v1", "Technical Report"], ["v2", "Mon, 10 Oct 2016 20:14:08 GMT  (1180kb)", "http://arxiv.org/abs/1608.06807v2", "Submitted to IEEE TPAMI"], ["v3", "Wed, 12 Oct 2016 14:53:15 GMT  (1180kb)", "http://arxiv.org/abs/1608.06807v3", "Submitted to IEEE TPAMI"]], "COMMENTS": "Technical Report", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["emanuele sansone", "francesco g b de natale", "zhi-hua zhou"], "accepted": false, "id": "1608.06807"}, "pdf": {"name": "1608.06807.pdf", "metadata": {"source": "CRF", "title": "Efficient Training for Positive Unlabeled Learning", "authors": ["Emanuele Sansone", "Francesco G. B. De Natale"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n60 8.\n06 80\n7v 3\n[ cs\n.L G\n] 1\n2 O\nct 2\n01 6\nIndex Terms\u2014Machine learning, one-class classification, positive unlabeled learning, open set recognition, kernel methods\n\u2726"}, {"heading": "1 INTRODUCTION", "text": "POSITIVE unlabeled learning (PU learning) refers to thetask of learning a binary classifier from only positive and unlabeled data [1]. This classification problem arises in various practical situations. For example:\n\u2022 Retrieval [2], where the goal is to find samples in an unlabeled data set similar to samples provided by a user.\n\u2022 Inlier-based outlier detection [3], where the goal is to detect outliers from an unlabeled data set based on inlier samples.\n\u2022 One-vs-rest classification [4], which is typical of problems where the negative class is too diverse and it is therefore difficult to collect and label enough negative samples.\n\u2022 Open set recognition [5], where testing classes are unknown at training time and therefore the exploitation of unlabeled data may help to learn more robust concepts.\nNaive approaches are proposed to address PU learning. In particular, it is possible to distinguish between solutions that firstly identify reliable negative samples from the unlabeled data based on some heuristics and secondly train a standard binary classifier, and solutions based on binary classifiers that consider all unlabeled data as negative. In the former case, the approaches are heavily dependent on heuristics, while in the latter case, the approaches are prone to the problem of wrong label assignment.\nThe recent works in [6] and [7] formulate PU learning as optimization problems under the framework of statistical learning theory [8]. In both works, there is theoretical analysis of the problem with the derivation of generalization error bounds and study of the optimality of the obtained solutions. Nevertheless, there is still lack of theoretically grounded scalable algorithms. Therefore, this work focuses on studying the problem of scalability. In particular, starting from the formulation of a convex optimization problem, we derive an efficient algorithm, that requires less storage capacity as well as faster time execution than existing state-of-the-art approaches, and prove theoretically that the\nalgorithm is guaranteed to converge to the exact optimal solution.\nThe rest of the paper is organized as follows. Section 2 reviews the related work, starting from the comparison of PU learning with one-class classification and semisupervised learning and describing the main theoretical results achieved in PU learning. Section 3 provides a summary of the formulation of the optimization problem under the framework of statistical learning theory and enunciates for the first time the representer theorem for PU learning. Section 4 and Section 5 describe the USMO algorithm and prove its convergence, respectively. Section 6 provides a comprehensive evaluation of the proposed algorithm on a large collection of real-world data sets. Finally, we conclude this work with some considerations about future research directions."}, {"heading": "2 LITERATURE REVIEW", "text": "PU learning is very well known in the machine learning\ncommunity, since it is used in a variety of tasks ranging frommatrix completion [9], multi-view learning [10], as well as semi-supervised learning [11]. It is also applied in data mining to classify data streams [12] or time series [13] and to detect events, like co-occurrences, in graphs [14].\nThe majority of existing works in PU learning can be classified in two broad categories, characterized by two different ways of exploiting unlabeled data. The first category consists of two-stage approaches [15], [16], [17], [18], which firstly extract a set of reliable negative samples from the unlabeled data and secondly use them, together with the available positive data, to train a binary classifier. These methods are mainly heuristic and their performance strongly depend on the quality of extraction of negative samples. The second category consists of single stage approaches that regard all unlabeled data as negative samples. Positive and negative data are then used to train different classifiers based on SVM [1], [19], neural networks [20] or kernel density estimators [21]. These approaches are subject to the problem of wrong label assignment, whose effect depends on the\n2 proportion of positive samples in the unlabeled dataset. We will see later, in the discussion about theoretical studies of PU learning, how critical this issue is. For the moment, we focus on analyzing the relations of PU learning with one-class classification and semi-supervised learning, which enable us to draw some clear boundaries between these tasks and to highlight the novelty of the novelties of this work."}, {"heading": "2.1 Comparison with one-class classification", "text": "The main goal of one-class classification (OCC) is to estimate the support of data distribution, which is extremely useful in unsupervised learning, especially in high-dimensional feature spaces, where it is very difficult to perform density estimation.\nOCC is applied to many real-world problems, involving for example anomaly/novelty detection (see [22] for a recent survey and definition of anomaly detection and see [23], [24] for reviews about novelty detection). Other possible applications of OCC range from author verification in text documents [25], document retrieval [2], as well as collaborative filtering in social networks [26].\nAuthors is [27], [28] are among the first to develop OCC algorithms.1 In particular, the study in [27] proposes a classifier which finds the hyperplane separating data from the origin with the maximum margin, while authors in [28] propose a classifier which finds the mimimum radius hypersphere enclosing data. Despite the difference between these two approaches, it is proved in [27] that, for specific choices of kernel function (namely, in the case of translationinvariant kernels, like the Gaussian kernel), the obtained solutions are the same. Extensions of these two pioneering works, falling in the category of kernel methods, are proposed few years later. In fact, authors in [30] modify the model of [27] by incorporating a small training set of anomalies and using the centroid of this set, instead of the origin, as the reference point to find the hyperplane. Authors in [31] propose a strategy to automatically select the hyperparameters defined in [28] to increase the usability of the framework. Rather than repelling samples from a specific point, as in [27], [30], authors in [32] propose a strategy that attract samples towards the centroid. They solve a linear programming problem, where the average output of the target function computed on the training samples is minimized. Authors in [33] propose a similar strategy based on linear programming, where data are represented in a similarity/dissimilarity space. The framework is well suited for OCC applications involving strings, graphs or shapes. Other solutions different from kernel methods are also proposed. To mention a few, authors in [34] propose a neural network-based approach, where the goal is to learn the identity function. New samples are fed to the network and tested against their corresponding outputs. The test sample is considered as part of the class of interest only when the input and the output of the network are similar. Authors in [35] propose a one-class nearest neighbour, where a test sample is accepted as a member of the target class only when the distance from its neighbours is comparable to their local density. It is worth noting that the majority of works in OCC focuses on increasing classification\n1. More precisely, the term OCC was coined in 1996 [29].\nperfomance, rather than improving scalability. This can be arguably motivated by the fact that it is difficult in general to collect large amount of training samples from the concept/class of interest. Solutions to improve classification perfomance are obtained by applying classical strategies, like ensemble methods [36], bagging [37] or boosting [38] strategies. Authors in [39] argue that existing one-class classifiers fail when dealing with mixture distributions. To this purpose, they propose a multi-class classifier exploiting the supervised information of all classes of interest to refine support estimation.\nA very promising solution to increase performance of OCC consists of exploiting unlabeled data, which are usually available in large quantities. As discussed in [21], standard OCC algorithms are not designed to use unlabeled data and therefore make the implicit assumption that they are uniformly distributed on the support of nominal distribution, which does not hold in general. The recent work in [40] proves that, under some simple conditions,2\nlarge amount of unlabeled data can boost performance of OCC even in comparison with completely supervised approaches. Furthermore, the exploitation of unlabeled data allows building OCC classifiers in the context of open set recognition [5], where it is essential to learn robust concepts/functions. The primary goal of PU learning is therefore to exploit this unsupervised information. PU learning can be regarded as a generalization of OCC [41], in the sense that it can deal and manage unlabeled data coming from more general distributions than the uniform one."}, {"heading": "2.2 Comparison with semi-supervised learning", "text": "The idea of exploiting unlabeled data in semi-supervised learning is originally proposed by [42]. Most early studies do not provide any explanation about why the unlabeled data can be beneficial. Authors in [43] are among the first to analyze this aspect from a generative perspective. In particular, they assume that data are distributed according to a mixture of Gaussians and show that the class posterior distribution can be decomposed in two distinct terms, namely one depending on the class labels and the other one depending on the mixture components. The former can be therefore estimated using the labeled data, while the latter is estimated using the unlabeled data, thus improving the performance of the learnt classifier. Authors in [44] extend this analysis and consider that data can be correctly described by the more general class of parametric models. They show that if both the class posterior distribution and the data prior distribution are dependent on model parameters, then unlabeled examples can be exploited to learn a better set of parameters. Therefore, the key idea of semi-supervised learning is to exploit the distributional information contained in the unlabeled examples.\nMany approaches have been proposed. The work in [45] provides a reference taxonomy of semi-supervised learning algorithms. In particular, we distinguish among generative approaches, like the one in [46], which exploit the unlabeled data to better estimate the class-conditional densities and infer/predict the unknown labels based on the learnt model,\n2. The conditions are based on class prior and size of positive (class of interest) and negative (the rest) data.\n3 low-density separation methods, like the work in [47], which look for decision boundaries that correctly classify labeled data and are placed in regions with few unlabeled samples (the so called low-density regions), graph-based methods, like in [48], which exploit unlabeled data to build a similarity graph and then propagate labels based on the smoothness assumption, methods based on dimensionality reduction, like in [49], which use the unlabeled samples for representation learning and then perform classification on the learnt feature representation, and disagreement-based methods, discussed in [50], which exploit the disagreement among multiple base learners to learn more robust ensemble classifiers.\nThe scalability issue is largely studied in the context of semi-supervised learning. For example, the work in [51] proposes a framework to solve a mixed-integer programming problem, which runs multiple times the SVM algorithm. State-of-the-art implementations of SVM (see for example LIBSVM [52]) are based mainly on decomposition methods [53], like our proposed approach. Other semi-supervised approaches look for approximations of the fitness function involved in the optimization problem, like [54], [55].\nBoth semi-supervised and PU learning exploit unlabeled data to learn better classifiers. Nevertheless, there are substantial differences that make semi-supervised learning not applicable to PU learning tasks. An important aspect is the fact that the majority of works in semi-supervised learning make the assumption that unlabeled data are originated only from a set of known classes (i.e. close set environment) and do not cope therefore with the presence of unknown classes in the training and test datasets (i.e. open set environment). To the best of our knowledge, only few works like the study in [56] propose semi-supervised methods capable to handle this situation. Another important and more relevant aspect is that semi-supervised learning cannot learn a classifier when only one known class is present, since they require at least two known classes to decide where to place the decision boundary. On the contrary, recent works in [11], [40], show that it is possible to apply PU learning algorithms to solve semi-supervised learning tasks, even in the case of open set environment."}, {"heading": "2.3 Theoretical studies about PU learning", "text": "Inspired by the seminal work in [57] and by the first studies about OCC [27], [28], authors in [58], and later with an extended version in [59], are the first to define and theoretically analyze the problem of PU learning. In particular, the authors propose a framework based on the statistical query model [57] to have theoretical guarantees about classification performance and to derive algorithms based on decision trees. The authors study the problem of learning functions characterized by monotonic conjuctions, which are particularly useful in text classification, where documents can be represented with binary vectors, to model the presence/absence of words from an available dictionary. Instead of considering binary features, authors in [60] propose a Naive-Bayes classifier for categorical features in noisy environments. Their work is subject to the attribute independence assumption, which is useful for\nestimating class-conditional densities in high-dimensional spaces, but rather limiting when compared to discriminative approaches, which directly focus on classification and avoid performing density estimation [61].\nAs already mentioned at the beginning of this section, the majority of PU learning studies can be classified in two main categories, viz. two-stage approaches and single stage methods that regard all unlabeled data as negative. The former are based on heuristics to select a set of reliable negative samples from the unlabeled data and are not theoretically sound, while the latter are subject to the problem of wrong label assignment. In order to understand the criticality of this issue, consider the theoretical result of consistency presented in [21].3 For any set of classifiers F of Vapnik-Chervonenkis (VC) dimension V and any \u03b4 > 0, there exists a constant c such that the following bounds hold with probability 1\u2212 \u03b4:\nFNR(f)\u2212 FNR(f\u2217) \u2264 c\u01ebn, FPR(f)\u2212 FPR(f\u2217) \u2264 c\n1\u2212 \u03c0 (\u01ebn + \u01ebp),\nwhere FPR,FNR are the false positive/negative rates, f \u2208 F is the function obtained by using the abovementioned strategy, f\u2217 \u2208 F is the optimal function having access to the ground truth, \u03c0 is the positive class prior, \u01eb\u00b7 = \u221a V log(\u00b7)\u2212log(\u03b4) \u00b7 and p and n are the number of positive and \u201dnot labeled\u201d samples, respectively. In particular, if one considers a simple scenario, where the feature space is R100\nand V = 101 (in the case of linear classifiers), then it is possible to learn a classifier such that, with probability of 90%, the performance do not deviate from the optimal values for more than 10% (which is equivalent to setting \u03b4, \u01ebp, \u01ebn = 0.1). This is guaranteed when both positive and unlabeled sets consist of at least 105 training samples each. This is impractical in real world applications, since collecting and labelling that amount of data is usually very expensive. The effect of wrong label assignment is even more evident for larger values of positive class prior.\nRecently, authors in [6], [7] propose frameworks based on the statistical learning theory [8]. These works are free from heuristics (as opposite to two stage approaches), are not prone to the problem of wrong label assignment and are theoretically grounded, since they provide bounds on the generalization error. Nevertheless, there is lack of theoretically grounded scalable PU learning approaches."}, {"heading": "3 PU LEARNING FORMULATION", "text": "Assume that we are given a training dataset Db = {(xi, yi) : xi \u2208 X, yi \u2208 Y }mi=1, where X \u2286 Rd, Y = {\u22121, 1} and each pair of samples inDb is drawn independently from the same unknown joint distribution P defined over X and Y . The goal is to learn a function f that maps the input space X into the class set Y , known as the binary classification problem. According to statistical learning theory [8], the\n3. It is rewritten to be more consistent with the notation in this paper.\n4 function f can be learnt by minimizing the risk functional R, namely\nR(f) = \u2211\ny\u2208Y\n\u222b\n\u2113(f(x), y)P(x, y)dx\n=\u03c0\n\u222b\n\u2113(f(x), 1)P(x|y = 1)dx\n+ (1\u2212 \u03c0) \u222b \u2113(f(x),\u22121)P(x|y = \u22121)dx (1)\nwhere \u03c0 is the positive class prior and \u2113 is a loss function measuring the disagreement between the prediction and the ground truth for sample x, viz. f(x) and y, respectively.\nIn PU learning, the training set is split into two parts, namely a set of samples Dp = {xi \u2208 X}pi=1 drawn from the positive class and a set of \u201dnot labeled\u201d samples Dn = {xi \u2208 X}ni=1 drawn from both the positive and the negative classes. The goal is the same of the binary classification problem, but this time the supervised information is available only for one class. The learning problem can be still formulated as a risk minimization. In fact, since P(x) = \u03c0P(x|y = 1) + (1 \u2212 \u03c0)P(x|y = \u22121), (1) can be rewritten in the following way:\nR(f) =\u03c0 \u222b \u2113(f(x), 1)P(x|y = 1)dx\n+ (1\u2212 \u03c0) \u222b \u2113(f(x),\u22121)P(x)\u2212 \u03c0P(x|y = 1) 1\u2212 \u03c0 dx\n= \u03c0\n\u222b \u2113\u0303(f(x), 1)P(x|y = 1)dx+ \u222b\n\u2113(f(x),\u22121)P(x)dx (2)\nwhere \u2113\u0303(f(x), 1) = \u2113(f(x), 1) \u2212 \u2113(f(x),\u22121) is called the composite loss [7].\nThe risk functional in (2) can not be minimized since the distributions are unknown. In practice, one considers the empirical risk functional in place of (2), where expectation integrals are replaced with the empirical mean estimates computed over the available training data, namely\nRemp(f) = \u03c0 p \u2211\nxi\u2208Dp\n\u2113\u0303(f(xi), 1) + 1\nn\n\u2211\nxi\u2208Dn\n\u2113(f(xi),\u22121) (3)\nThe minimization of Remp is in general an ill-posed problem. A regularization term is usually added to Remp in order to restrict the solution space and to penalize complex solutions. The learning problem is therefore stated as an optimization task:\nf\u2217 = arg min f\u2208Hk\n{ Remp(f) + \u03bb\u2016f\u20162Hk }\n(4)\nwhere \u03bb is a positive real parameter weighting the relative importance of the regularizer with respect to the empirical risk and \u2016 \u00b7 \u2016Hk is the norm associated with the function space Hk. In this case, Hk refers to the Reproducing Kernel Hilbert Space (RKHS) associated with its Mercer kernel k : X \u00d7 X \u2192 R.4 Considering the problem in (4), we can enunciate the representer theorem for PU learning (proof in Appendix A): Representer Theorem 1. Given the training set D = Dp \u222a\nDn and the Mercer kernel k associated with the RKHS Hk, any minimizer f\u2217 \u2208 Hk of (4) admits the following representation\nf\u2217(x) = \u2211\ni:xi\u2208D\n\u03b1ik(x,xi)\n4. For an overview of RKHS and their properties, see the work in [62]\nwhere \u03b1i \u2208 R for all i.\nIt is worth mentioning that many types of representer theorem have been already proposed, but none of them can be applied to the PU learning problem. Just to mention a few, authors in [63] have provided a generalized version of the classical representer theorem for classification and regression tasks, while authors in [48] have derived the representer theorem for semi-supervised learning. More recently, the study in [64] has proposed a unified view of existing representer theorems, identifying the relations between these theorems and certain classes of regularization penalties. Nevertheless, the proposed theory does not apply to problem (4) due to the hypotheses made on the empirical risk functional.\nThis theorem shows that is is possible to learn functions defined on possibly-infinite dimensional spaces, namely the ones induced by the kernel k, but that depend only on a finite number of parameters (namely \u03b1i). The training focuses therefore on learning this restricted set of parameters. Another important aspect is that the representer theorem does not mention anything about the uniqueness of the solution and it only says that every minimum solution has the same parametric form. In other words, different solutions have different values of parameters. The uniqueness of the solution can be guaranteed only when the empirical risk functional in (4) is convex. A proper selection of the loss function is therefore necessary to achieve this condition. Authors in [7] have analysed the properties of loss functions for the PU learning problem and shown that a necessary condition for convexity is that the composite loss function in (3) is affine. This requirement is satisfied by some loss functions, like the squared loss, the modified Huber loss, the logistic loss, the perceptron loss and the double Hinge loss. In particular, better generalization performance can be achieved by using the double Hinge loss [7].5 Even, the comparison with non-convex loss functions [6], [7] suggests to use the double Hinge loss for the PU learning problem. The advantages are twofold: guarantee that the obtained solution is globally optimal, and possibility of exploiting the convex optimization theory to perform a more efficient training.\nThese considerations, together with the result stated by the representer theorem, allow us to rewrite problem (4) in an equivalent parametric form. In particular, by defining \u03b1 \u2208 R(p+n) as the vector of alpha values, \u03be \u2208 Rn as the vector of slack variables, K \u2208 R(p+n)\u00d7(p+n) as the Gram matrix computed using the training set D, and by considering without loss of generality, target functions in the form f(x) = \u2211\ni \u03b1ik(x,xi)+\u03b2, where \u03b2 is the bias of f , it is possible to derive the following optimization problem (derivation in Appendix B):\nmin \u03b1,\u03be,\u03b2\n{\n\u2212c11\u0303TK\u03b1\u2212 c11\u0303T1\u03b2 + c21Tn \u03be + 1\n2 \u03b1\nT K\u03b1\n}\ns.t. \u03be 0n, \u03be UK\u03b1+ \u03b21n,\n\u03be 1 2 1n + 1 2 UK\u03b1+ \u03b2 2 1n, (5)\n5. The double Hinge loss can be considered as the equivalent of the Hinge loss function for the binary classification problem.\n5 where 1\u0303 = [1, . . . , 1, 0, . . . , 0]T is a vector of size p + n with p non-zero entries, 1 and 1n are unitary vectors of size p+n and n, respectively,U is a n\u00d7 (p+n) matrix obtained through the concatenation of a n \u00d7 p null matrix and an identity matrix of size n, is an element-wise operator, c1 = \u03c0 2\u03bbp and c2 = 1\n2\u03bbn . The equivalent dual problem of (5) is more compactly\nexpressed as:\nmin \u03c3,\u03b4\n{1\n2 \u03c3\nT UKU T \u03c3 \u2212 c11\u0303TKUT\u03c3 \u2212 1\n2 1 T n\u03b4\n}\ns.t. 1T [ c11\u0303\u2212UT\u03c3 ] = 0,\n\u03c3 + 1\n2 \u03b4 c21n,\n\u03c3 \u2212 1 2 \u03b4 0n, 0n \u03b4 c21n, (6)\nwhere \u03c3, \u03b4 \u2208 Rn and are related to the Lagrange multipliers introduced during the derivation of the dual formulation (see Appendix B for details).\nDue to linearity of constraints in (5), Slater\u2019s condition is trivially satisfied6 and therefore strong duality holds. This means that (6) can be solved in place of (5) to get the primal solution. The optimal \u03b1 can be obtained from one of the stationarity conditions used during the Lagrangian formulation (details in Appendix B), namely using the following relation\n\u03b1 = c11\u0303\u2212UT\u03c3 (7)\nNote that the bias \u03b2 has to be considered separately, since problem (6) does not give any information on how to compute it (this will be discussed in the next section).\nIt is important to point out that (6) is a quadratic programming (QP) problem that can be solved by existing numerical QP optimization libraries. Nevertheless, it is memory inefficient, since it requires to store the Gram matrix which scales quadratically with the number of training samples. Due to this problem, a modern computer cannot manage to solve (6) even for a few thousands of samples. A question therefore arises: is it possible to efficiently find an exact solution to problem (6) without storing the whole Gram matrix?"}, {"heading": "4 USMO ALGORITHM", "text": "In order not to store the Gram matrix, we propose an\niterative algorithm that converts problem (6) into a sequence of smaller QP subproblems. Here, smaller refers to considering a subset of training samples, whose indices define the working set, and to compute and store temporarily the Gram matrix only for this reduced set. Each iteration of the USMO algorithm is composed by three main operations: the selection of the working set, called S, the computation of the Gram matrix only for samples associated to indices in S and the resolution of a QP subproblem, where only terms depending on S are considered. The details of the general algorithm are given in Algorithm 1.\nIt is important to mention that in principle this strategy allows decreasing the storage requirement at the expense\n6. See [65] for example.\nAlgorithm 1 General USMO algorithm\n1: k \u2190 1. 2: Initialize (\u03c31, \u03b41). 3: while (\u03c3k, \u03b4k) is not a stationary point of (6) do 4: Select the working set S \u2282 U = {u : xu \u2208 Dn} with |S| = 2. 5: Compute KSS , KSP and KSS\u0304 where P = {u : xu \u2208 Dp} and S\u0304 = U\\S. 6: Solve\nmin \u03c3k S ,\u03b4k S\n{1\n2 (\u03c3kS) T KSS\u03c3 k S + e T \u03c3 k S \u2212\n1 2 1 T \u03b4 k S\n}\ns.t. 1T\u03c3kS = c1p\u2212 1T\u03c3kS\u0304 \u03c3 k S + 1\n2 \u03b4 k S c21\n\u03c3 k S \u2212\n1 2 \u03b4 k S 0\n0 \u03b4kS c21 (8) where\ne = KSS\u0304\u03c3 k S\u0304 \u2212 c1KSP1p\nand\nK\u0303 =\n\n KPP KPS KPS\u0304 KSP KSS KSS\u0304 KS\u0304P KS\u0304S KS\u0304S\u0304\n\n , \u03c3\u0303k =\n[\n\u03c3kS \u03c3kS\u0304\n]\n, \u03b4\u0303k =\n[\n\u03b4kS \u03b4kS\u0304\n]\nK\u0303, \u03c3\u0303k and \u03b4\u0303k are permutations of K,\u03c3k and \u03b4k, respectively. In general, KVW is used to denote a matrix containing rows of K indexed by elements in set V and columns of K indexed by elements in set W .\n7: (\u03c3k+1S , \u03b4 k+1 S ) \u2190 (\u03c3kS , \u03b4kS). 8: k \u2190 k + 1. 9: end while\nof a higher computational complexity. In fact, it may happen that same samples are selected multiple times over iterations, thus requiring recomputing the same quantities, namely matrices KSS ,KSP and KSS\u0304 . We will see later, how to deal with this source of inefficiency.\nAnother important aspect is that at each iteration only few parameters are updated (the parameters indexed by the working set S, namely \u03c3kS and \u03b4 k S ), while the others are kept fixed. Here, we consider a working set of size two, since this allows us to solve the QP subproblem (8) in an analytical way without the need of further optimization algorithms. This is discussed in the next subsection."}, {"heading": "4.1 QP Subproblem", "text": "We start by considering the following Lemma (proof in Appendix C): Lemma 1. Given S = {i, j}, any optimal solution \u03c3\u2217S = [\u03c3\u2217i \u03c3 \u2217 j ] T , \u03b4\u2217S = [\u03b4 \u2217 i \u03b4 \u2217 j ]\nT of the QP subproblem (8) has to satisfy the following condition: \u2200u : xu \u2208 S \u2227 0 \u2264 \u03b4\u2217u \u2264 c2 either \u03c3 \u2217 u = c2 \u2212 \u03b4\u2217u 2 or \u03c3 \u2217 u = \u03b4\u2217u 2 .\nThis tells us that the optimal solution (\u03c3\u2217S , \u03b4 \u2217 S) assumes a specific form and therefore its computation can be per-\n6\nformed by searching in a smaller space. In particular, four possible subspaces for search can be identified:\nCase 1: \u03c3ki = c2 \u2212 \u03b4ki 2 \u2227 \u03c3kj = c2 \u2212 \u03b4kj 2 \u2227 0 \u2264 \u03b4ki , \u03b4kj \u2264 c2, Case 2: \u03c3ki = c2 \u2212 \u03b4ki 2 \u2227 \u03c3kj = \u03b4kj 2 \u2227 0 \u2264 \u03b4ki , \u03b4kj \u2264 c2, Case 3: \u03c3ki = \u03b4ki 2 \u2227 \u03c3kj = c2 \u2212 \u03b4kj 2 \u2227 0 \u2264 \u03b4ki , \u03b4kj \u2264 c2, Case 4: \u03c3ki = \u03b4ki 2 \u2227 \u03c3kj = \u03b4kj 2 \u2227 0 \u2264 \u03b4ki , \u03b4kj \u2264 c2, (9)\nTherefore, in order to solve the QP subproblem (8), one can solve four optimization problems, where the objective function is the same as (8), but the inequality constraints of (8) are simplified to (9). Indeed, each of these four subproblems can be expressed as an optimization problem of just one variable, by exploiting the equality constraints of both (8) and (9). Their solution can be therefore computed analytically without the need of further optimization algorithms. Table 1 reports the equations used to solve the four subproblems (we omit the derivation, which is straightforward), where \u03c3kj is computed for all four cases. All other variables, namely \u03c3ki , \u03b4 k i and \u03b4 k j , can be obtained in a second phase by simply exploiting the equality constraints in (8) and (9).\nThese equations do not guarantee in general that the inequalities in (9) are satisfied. To verify this, one can rewrite these inequalities as equivalent conditions of only \u03c3kj (by exploiting the equality constraints in (8) and (9)), and check \u03c3kj against them, as soon as all \u03c3 k j are available. In case these conditions are violated, a proper clipping is applied to \u03c3kj and feasibility is therefore restored. Table 1 summarizes these checking conditions.\nFinally, the minimizer of the QP subproblem (8) can be obtained by retaining only the solution with the lowest level of objective.\nAt each iteration, the output of the algorithm is both optimal and feasible for the QP subproblem (8). The question now is: when is it also optimal for the problem (6)? This is discussed in the next subsection."}, {"heading": "4.2 Optimality Conditions", "text": "A problem of any optimization algorithm is to determine the stop condition. In Algorithm 1, the search of the solution is stopped as soon as some stationarity conditions are met. These conditions, called Karush-Kuhn-Tucker (KKT) conditions, represent the certificates of optimality for the obtained solution. In case of (6) they are both necessary and sufficient conditions, since the objective is convex and the constraints\nare affine functions [66]. More in detail, an optimal solution has to satisfy the following relations:\n\u2202F (\u03c3,\u03b4)\n\u2202\u03c3u \u2212 \u03b2 = \u2212\u03bbu + \u00b5u,\n\u2202F (\u03c3,\u03b4) \u2202\u03b4u = \u2212\u03bbu 2 \u2212 \u00b5u 2 \u2212 \u03beu + \u03b7u,\n\u03bbu ( \u03c3u + \u03b4u 2 \u2212 c2 ) = 0, \u00b5u (\u03b4u 2 \u2212 \u03c3u ) = 0, \u03beu ( \u03b4u \u2212 c2 ) = 0,\n\u03b7u\u03b4u = 0,\n\u03bbu, \u00b5u, \u03beu, \u03b7u \u2265 0, (10) and this is valid for any component of the optimal solution, namely \u2200u : xu \u2208 Dn. In (10) F (\u03c3, \u03b4) is used as an abbreviation of the objective function of (6), while \u03b2, \u03bbu, \u00b5u, \u03beu, \u03b7u are the Lagrange multipliers introduced to deal with the constraints in (6). These conditions can be rewritten more compactly as:\n0 \u2264 \u03b4u<c2 \u2227 \u03c3u= \u03b4u 2 \u21d2 \u2202F (\u03c3,\u03b4) \u2202\u03c3u \u2212\u03b2 \u2265 1\n\u21d2 f(xu) \u2264 \u22121,\n0 \u2264 \u03b4u<c2 \u2227 \u03c3u=c2\u2212 \u03b4u 2 \u21d2 \u2202F (\u03c3,\u03b4) \u2202\u03c3u \u2212\u03b2 \u2264 \u22121\n\u21d2 f(xu) \u2265 1,\n\u03b4u=c2 \u2227 \u03c3u= c2 2 \u21d2 \u22121 \u2264 \u2202F (\u03c3,\u03b4) \u2202\u03c3u \u2212\u03b2 \u2264 1\n\u21d2 \u22121 \u2264 f(xu) \u2264 1, (11) In order to derive both (10) and (11), one can follow a strategy similar to the proof of Lemma 1. It is easy to verify that \u2202F (\u03c3,\u03b4) \u2202\u03c3u\n= \u2212f(xu) + \u03b2. Thus, (11) provides also conditions on the target function f . From now on, we will refer to (11) as the optimality conditions, to distinguish from approximate conditions used to deal with numerical approximations of calculators. To this aim, the \u03c4\u2212optimality conditions are introduced, namely:\n0 \u2264 \u03b4u<c2 \u2227 \u03c3u= \u03b4u 2 \u21d2 \u2202F (\u03c3,\u03b4) \u2202\u03c3u \u2212\u03b2 \u2265 1\u2212 \u03c4 2 ,\n\u21d2 f(xu) \u2264 \u22121 + \u03c4 2 ,\n0 \u2264 \u03b4u<c2 \u2227 \u03c3u=c2\u2212 \u03b4u 2 \u21d2 \u2202F (\u03c3,\u03b4) \u2202\u03c3u \u2212\u03b2 \u2264 \u22121 + \u03c4 2 ,\n\u21d2 f(xu) \u2265 1\u2212 \u03c4 2 ,\n\u03b4u=c2 \u2227 \u03c3u= c2 2 \u21d2 \u22121\u2212 \u03c4 2 \u2264\u2202F (\u03c3,\u03b4) \u2202\u03c3u \u2212\u03b2\u22641+ \u03c4 2 ,\n\u21d2 \u22121\u2212 \u03c4 2 \u2264 f(xu) \u2264 1+ \u03c4 2 , (12)\nwhere \u03c4 is a real-positive scalar used to perturb the optimality conditions.\nBy introducing the sets D1(\u03c3, \u03b4) = { xu \u2208 Dn : 0 \u2264 \u03b4u < c2 \u2227 \u03c3u = \u03b4u2 } , D2(\u03c3, \u03b4) = {\nxu \u2208 Dn : 0 \u2264 \u03b4u < c2 \u2227 \u03c3u = c2\u2212 \u03b4u 2 } andD3(\u03c3,\u03b4) = { xu \u2208 Dn : 0 < \u03b4u \u2264 c2\u2227 ( \u03c3u = \u03b4u 2 \u2228\u03c3u = c2 \u2212 \u03b4u2 )}\nand the quantities mmax1 (\u03c3, \u03b4) = maxxu\u2208D1 f(xu), mmin2 (\u03c3,\u03b4) = minxu\u2208D2 f(xu),m min 3 (\u03c3, \u03b4) = minxu\u2208D3 f(xU ) and mmax3 (\u03c3,\u03b4) = maxxu\u2208D3 f(xu), called the most critical values, it is possible to rewrite conditions (12) in the following equivalent way:\nmmax1 (\u03c3,\u03b4)\u2212mmin3 (\u03c3,\u03b4) \u2264 \u03c4, mmax3 (\u03c3,\u03b4)\u2212mmin2 (\u03c3,\u03b4) \u2264 \u03c4, mmax1 (\u03c3,\u03b4)\u2212mmin2 (\u03c3,\u03b4) + 2 \u2264 \u03c4, (13)\n7 Apart from being written more compactly than (12), conditions (13) have the advantage that they can be computed without knowing the bias \u03b2. Due to the dependence on \u03c3 and \u03b4, mmax1 , m min 2 , m min 3 m max 3 need to be tracked and computed at each iteration in order to check \u03c4\u2212optimality and to decide whether to stop the algorithm."}, {"heading": "4.3 Working Set Selection", "text": "A natural choice for selecting the working set is to look for pairs violating the \u03c4\u2212optimality conditions. In particular, Definition 1. Any pair (xi,xj) from Dn is a violating pair,\nif and only if it satisfies the following relations:\nxi \u2208 D1,xj \u2208 D3 \u21d2 f(xi)\u2212 f(xj) > \u03c4, xi \u2208 D3,xj \u2208 D1 \u21d2 f(xi)\u2212 f(xj) < \u2212\u03c4, xi \u2208 D2,xj \u2208 D3 \u21d2 f(xi)\u2212 f(xj) < \u2212\u03c4, xi \u2208 D3,xj \u2208 D2 \u21d2 f(xi)\u2212 f(xj) > \u03c4, xi \u2208 D1,xj \u2208 D2 \u21d2 f(xi)\u2212 f(xj) + 2 > \u03c4, xi \u2208 D2,xj \u2208 D1 \u21d2 f(xi)\u2212 f(xj)\u2212 2 < \u2212\u03c4, (14)\nConditions (13) are not satisfied as long as violating pairs are found. Therefore, the algorithm keeps looking for violating pairs and use them to improve the objective function until \u03c4\u2212optimality is reached.\nThe search of violating pairs as well as the computation of the most critical values go hand in hand in the optimization and follow two different approaches. The former consists of finding violating pairs and computing the most critical values based only on a subset of samples called the non-bound set, namely D\u2212n = (D1 \u2229 D3) \u222a (D2 \u2229 D3),7 while the latter consists of looking for violating pairs based on the whole set Dn by scanning all samples one by one. In this second approach, the most critical values are updated using the non-bound set together with the current examined sample. Only when all samples are examined, it is possible to check conditions (13), since the most critical values correspond to the original definition. The algorithm keeps using the first approach until \u03c4\u2212optimality for the non-bound set is reached, after that the second approach is used. This process is repeated until the \u03c4\u2212optimality for the whole set Dn is achieved. 8\nThe motivation of having two different approaches for selecting the violating pairs and computing the most critical values is to enhance efficiency in computation. This will be clarified in the next subsection."}, {"heading": "4.4 Function Cache and Bias Update", "text": "Recall that each iteration of the USMO algorithm is composed by three main operations, namely: the working set selection, the resolution of the associated QP subproblem, and the update of the most critical values based on the obtained solution. It is interesting to note that all these operations require to compute the target function f(xu) for all xu belonging either to the non-bound set or to the whole set Dn, depending on the approach selected by that iteration. In fact, the stage of working set\n7. The term non-bound comes from the fact that 0 < \u03b4u < c2 for all xu \u2208 Dn.\n8. This can be checked only when the second approach is used and after that the whole set Dn is scanned.\nselection requires to evaluate conditions in (14) for pairs of samples depending on f ; the equations used to solve the QP subproblem, shown in Table 1, depend on vector e = KSS\u0304\u03c3 k S\u0304 \u2212 c1KSP1p + KSS\u03c3k\u22121S \u2212 KSS\u03c3k\u22121S = \u2212[f(xi) \u2212 \u03b2, f(xj) \u2212 \u03b2]T \u2212 KSS\u03c3k\u22121S , which is also influenced by f ; finally, the computation of the most critical values requires to evaluate the target function f . Therefore, it is necessary to define a strategy that limits the number of times the target function is evaluated at each iteration. This can be achieved by considering the fact that the algorithm performs most of the iterations on samples in the nonbound set, while the whole set is used mainly to check if \u03c4\u2212optimality is reached, and then the values of the target function for those samples can be stored in a cache, called the function cache. Since usually |D\u2212n | \u226a |Dn|, storing f(xu) for all xu \u2208 D\u2212n is a cheap operation, which allows to save a huge amount of computation, thus increasing the computational efficiency.\nAt each iteration the function cache has to be updated in order to take into account the changes occured at some of the entries of vectors \u03c3 and \u03b4, or equivalently at some of the entries of \u03b1 . By defining Fk(xu) as the function cache for sample xu at iteration k, it is possible to perform the update operation using the following relation:\nFk(xu) =Fk\u22121(xu) + (\u03b1ki \u2212 \u03b1k\u22121u )k(xi,xu) + (\u03b1kj \u2212 \u03b1k\u22121j )k(xj ,xu) (15)\nSince all operations at each iteration are invariant with respect to \u03b2 (because they require to evaluate differences between target function values), \u03b2 can be computed at the end of the algorithm, namely when \u03c4\u2212optimality is reached. By exploiting the fact that the inequalities in (11) become simply equalities for samples in the non-bound set, meaning that the target function evaluated at those samples can assume only two values, 1 or -1,9 it is possible to compute \u03b2 for each of these samples in the following way:\n\u03b2u = { \u22121\u2212 F(xu), \u2200xu \u2208 D1 \u2229D3\n1\u2212 F(xu), \u2200xu \u2208 D2 \u2229D3 (16)\nThe final \u03b2 can be computed by averaging of (16) over all samples in the non-bound set, in order to reduce the effect of wrong label assignment."}, {"heading": "4.5 Initialization", "text": "As previously mentioned, the proposed algorithm is characterized by iterations focusing either on the whole training data set or on a smaller set of non-bound samples. The formers are computationally more expensive, not only because a larger amount of samples is involved in the optimization, but also because the algorithm has to perform many evaluation operations, which can be skipped in the latter case, thanks to the exploitation of the function cache. An example of this is provided in Figure 1: the chart on the left plots the time required by the algorithm to complete the corresponding set of iterations. Peaks correspond to cases where the whole training data set is considered, while valleys represent the cases where iterations are performed over the non-bound samples. The chart on the right plots the overall objective score vs. the different sets of iterations. Jumps are associated with cases where all training samples are involved in the optimization. As soon as the algorithm\n9. The same principle holds for conditions (12), but in this case the inequalities are defined over arbitrary small intervals centered at 1 and -1 rather than being equalities.\n8 Iterations 0 10 20 30 40 50 60 T im e (s ec s) 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5\n(a)\nIterations 0 10 20 30 40 50 60\nO bj\nec tiv\ne fu\nnc tio\nn\n71.5\n72\n72.5\n73\n73.5\n74\n(b)\nFig. 1. (a) plot of training time over iterations, (b) learning curve expressed in terms of objective function.\napproaches convergence, the contribution of the first kind of iterations becomes less and less relevant. Therefore, it is important to minimize the number of passes through the whole unlabeled data set by finding a good initialization point. To address this problem, we propose the following heuristic procedure. Labeled samples are used to train a oneclass SVM [67], that is in turn used to rank the unlabeled samples according to their value of estimated target function. From this ordered list it is possible to identify groups of samples that can be associated with the cases in (11). In particular, we identify five groups of samples corresponding to the following five cases:\n\u03b4(1)u = 0 \u2227 \u03c3(1)u = 0, 0 < \u03b4(2)u < c2 \u2227 \u03c3u = \u03b4 (2) u\n2 ,\n\u03b4(3)u = c2 \u2227 \u03c3(3)u = c2 2 , 0 < \u03b4(4)u < c2 \u2227 \u03c3(4)u = c2 \u2212 \u03b4u 2 , \u03b4(5)u = 0 \u2227 \u03c3(5)u = c2, (17)\nThe size of each group as well as the initial parameters for cases in (17) can be computed by solving an optimization problem, whose objective function is defined starting from the equality constraint in (6). In particular, by defining n1, n2, n3, n4, n5 as the sizes of the groups for the different cases and by assuming that n1 = (1 \u2212 \u03c0)an, n2 = bn, n3 = (1\u2212a\u2212b\u2212c)n, n4 = cn, n5 = \u03c0an, where a, b, c \u2208 R+, and that the parameters for the second and the fourth cases in (17), namely \u03c3 (2) u and \u03c3 (4) u , are the same, the optimization problem can be formulated in the following way:\nmin \u03c3 (2) u ,\u03c3 (4) u ,\na,b,c\n{ c1p\u2212 bn\u03c3(2)u \u2212 cn\u03c3(4)u \u2212 c2n [ \u03c0a+ 1\u2212 a\u2212 b\u2212 c\n2\n]}2\ns.t. 0 \u2264 a+ b+ c \u2264 1\u2212 1 n ,\nmax { 1\n\u03c0n ,\n1 (1\u2212 \u03c0)n } \u2264 a \u2264 min { 1 1\u2212 \u03c0 , 1 \u03c0 } ,\n1 n \u2264 b, c \u2264 log(n) n , 0 < \u03c3(2)u < c2 2 \u2227 c2 2 < \u03c3(4)u < c2, (18)\nwhere the constraints in (18) can be obtained by imposing n1 + n2 + n3 + n4 + n5 = n and 1 \u2264 n2, n3, n4, n5 \u2264 n. Furthermore, we decide to have some upper bounds for b and c to limit the size of the initial non-bound set.\nIn practice, after ranking the unlabeled samples through the one-class SVM and solving the optimization problem in (18), the initial solution is obtained by assigning to each sample the value of parameters corresponding to the case that sample belongs to. For example, if the samples are\nranked in ascending order, then the first n1 samples in the list have \u03c3u = 0 and \u03b4u = 0, the next n2 samples have \u03c3u = \u03c3 (2) u and \u03b4u = 2\u03c3u and the others follow the same strategy."}, {"heading": "5 THEORETICAL ANALYSIS", "text": "In this section, we present the main theoretical result, namely, we prove that Algorithm 1 converges to a \u03c4\u2212optimal solution.\nIt is important to recall that each iteration of USMO requires to solve an optimization subproblem, that depends on a single variable. In particular, if xi and xj correspond to the selected pair of points at one iteration, then the solution space corresponds to a line lying in the two-dimensional plane defined by the variables \u03c3i and \u03c3j . The feasible region in that plane can be subdivided into four parts, as defined according to Figure 2. These regions are considered closed sets, therefore including boundary points, like edges and corners. To consider only the interior of any set U , we use the notation int U . Based on these considerations, it is possible to prove the following lemma. Lemma 2. Let the vector z\u2032 = [\u03c3\u2032; \u03b4\u2032] be in the feasible set\nof (6) and (xi,xj) be a violating pair at point z \u2032. Let also z\u2217 = [\u03c3\u2217; \u03b4\u2217] be the solution obtained after applying one iteration of the Algorithm 1 using the working set S = {i, j} and starting from z\u2032. Then, the following results hold:\n(a) z\u2217 6= z\u2032, (b) After the minimization step, (xi,xj) is no more a violating pair, (c) (\u03c3\u2217i ,\u03c3 \u2217 j ) \u2208 int R1 \u222a int R3 \u21d2 fz\u2217(xj)\u2212fz\u2217(xi) = 0, (d) (\u03c3\u2217i ,\u03c3 \u2217 j ) \u2208 int R2 \u21d2 fz\u2217(xj)\u2212fz\u2217(xi) = 2, (e) (\u03c3\u2217i ,\u03c3 \u2217 j ) \u2208 int R4 \u21d2 fz\u2217(xj)\u2212fz\u2217(xi) = \u22122,\n(f) (\u03c3\u2217i ,\u03c3 \u2217 j ) \u2208 BE \u21d2 0 \u2264 fz\u2217(xj)\u2212fz\u2217(xi) \u2264 2,\n(g) (\u03c3\u2217i ,\u03c3 \u2217 j ) \u2208 DE \u21d2 0 \u2264 fz\u2217(xj)\u2212fz\u2217(xi) \u2264 2, (h) (\u03c3\u2217i ,\u03c3 \u2217 j ) \u2208 EF \u21d2 \u22122 \u2264 fz\u2217(xj)\u2212fz\u2217(xi) \u2264 0,\n(i) (\u03c3\u2217i ,\u03c3 \u2217 j ) \u2208 EH \u21d2 \u22122 \u2264 fz\u2217(xj)\u2212fz\u2217(xi) \u2264 0, (l) (\u03c3\u2217i ,\u03c3 \u2217 j ) \u2208 AB \u222aDI \u21d2 fz\u2217(xj)\u2212fz\u2217(xi) \u2265 0,\n(m) (\u03c3\u2217i ,\u03c3 \u2217 j ) \u2208 AF \u222aHI \u21d2 fz\u2217(xj)\u2212fz\u2217(xi) \u2264 0,\n(n) (\u03c3\u2217i ,\u03c3 \u2217 j ) \u2208 BC \u222a CD \u21d2 fz\u2217(xj)\u2212fz\u2217(xi) \u2265 2, (o) (\u03c3\u2217i ,\u03c3 \u2217 j ) \u2208 FG \u222aGH \u21d2 fz\u2217(xj)\u2212fz\u2217(xi) \u2264 \u22122, (p) F (\u03c3\u2032, \u03b4\u2032)\u2212 F (\u03c3\u2217, \u03b4\u2217) > \u03c4 2 \u221a 2 \u2016\u03c3\u2032 \u2212 \u03c3\u2217\u20162,\nwhere fz\u2217 represents the target function with coefficients \u03b1i computed according to (7) using z\u2217.\nProof: Note that the feasible region for the QP subproblem (8) is a portion of line with negative slope lying on the plane defined by variables \u03c3i and \u03c3j (see Figure 2).\n9 Thus, any point (\u03c3i, \u03c3j) on this line can be expressed using the following relationship:\n\u03c3i = \u03c3 \u2032 i + t, \u03c3j = \u03c3 \u2032 j \u2212 t, (19)\nwhere t \u2208 R. In particular, if t = 0, then (\u03c3i, \u03c3j) \u2261 (\u03c3\u2032i, \u03c3\u2032j) and, if t = t\u2217, then (\u03c3i, \u03c3j) \u2261 (\u03c3\u2217i , \u03c3\u2217j ).\nConsidering (19) and the fact that \u03b4xi=2\u03c3i \u2227 \u03b4j=2\u03c3j when (\u03c3i, \u03c3j) \u2208 R1, \u03b4xi=2\u03c3i\u2227\u03b4j=2c2\u22122\u03c3j when (\u03c3i, \u03c3j) \u2208 R2, \u03b4xi=c2 \u2212 2\u03c3i \u2227 \u03b4j=c2 \u2212 2\u03c3j when (\u03c3i, \u03c3j) \u2208 R3 and \u03b4xi=c2 \u2212 2\u03c3i \u2227 \u03b4j=2\u03c3j when (\u03c3i, \u03c3j) \u2208 R4, it is possible to rewrite the objective in (8) as a function of t, namely:\n\u03c6(t) = 1 2 (\u03c3\u2032i + t) 2k(xi,xi) + 1 2 (\u03c3\u2032j \u2212 t)2k(xj ,xj)+\n(\u03c3\u2032i + t)(\u03c3 \u2032 j \u2212 t)k(xi,xj) + hz(t) (20)\nwhere hz is a function defined in the following way:\nhz(t)=\n\n \n \n(e1\u22121)(\u03c3\u2032i+t)+(e2\u22121)(\u03c3\u2032j\u2212t), (\u03c3i,\u03c3j)\u2208R1, (e1\u22121)(\u03c3\u2032i+t)+(e2+1)(\u03c3\u2032j\u2212t)\u2212c2, (\u03c3i,\u03c3j)\u2208R2, (e1+1)(\u03c3 \u2032 i+t)+(e2+1)(\u03c3 \u2032 j\u2212t)\u22122c2,(\u03c3i,\u03c3j)\u2208R3, (e1+1)(\u03c3 \u2032 i+t)+(e2\u22121)(\u03c3\u2032j\u2212t)\u2212c2, (\u03c3i,\u03c3j)\u2208R4,\nNote that d 2\u03c6(t) dt2\n= k(xi,xi) + k(xj,xj) \u2212 2k(xi,xj) \u2265 0 (k is a Mercer kernel), meaning that (20) is convex.\nIf (\u03c3\u2217i , \u03c3 \u2217 j ) \u2208 int R1, then (\u03c3\u2217i , \u03c3\u2217j ) is the minimum and\nd\u03c6(t\u2217) dt = 0. Since d\u03c6(t \u2217) dt = fz\u2217(xj) \u2212 fz\u2217(xi) = 0, the first and the second conditions in (14), which are the only possibilities to have a violating pair, are not satisfied. Therefore, (xi,xj) is not violating at point z\n\u2217, but it is violating at z\u2032, implying that z\u2217 6= z\u2032. The same situation holds for (\u03c3\u2217i , \u03c3 \u2217 j ) \u2208 int R3 and this proves statement (c).10 Statements (d) and (e) can be proven in the same way, considering that the admissible conditions to have a violating pair are the first, the fourth and the fifth conditions for the former case and the second, the third and the sixth ones for the latter case.\nIf (\u03c3\u2217i ,\u03c3 \u2217 j ) \u2208 BE, there are two possibilities to compute the derivative depending on the position of (\u03c3\u2032i,\u03c3 \u2032 j), namely approaching (\u03c3\u2217i ,\u03c3 \u2217 j ) from the bottom or from the top of the constraint line. In the first case, the derivative is identified by d\u03c6(t \u2217)\ndt\u2212 , while in the second case by d\u03c6(t \u2217) dt+\n. Since (\u03c3\u2217i ,\u03c3 \u2217 j ) is the minimum and due to the convexity of function \u03c6(t), d\u03c6(t \u2217)\ndt\u2212 \u2265 0 and d\u03c6(t \u2217) dt+ \u2264 0. Furthermore, it is easy to verify that d\u03c6(t\n\u2217) dt\u2212 = fz\u2217(xj)\u2212fz\u2217(xi) and d\u03c6(t\u2217) dt+\n= fz\u2217(xj)\u2212fz\u2217(xi) \u2212 2. By combining these results, we obtain that 0 \u2264 fz\u2217(xj)\u2212fz\u2217(xi) \u2264 2. This, compared with the first condition in (14), guarantees that (xi,xj) is not a violating pair at z\u2217 and therefore that z\u2217 6= z\u2032. The same strategy can be applied to derive statements (g)-(o).\nFor the sake of notation compactness, we use \u03c6\u2032(t) to identify both the classical and the directional derivatives of \u03c6(t), viz. d\u03c6(t) dt , d\u03c6(t \u2217) dt\u2212 and d\u03c6(t \u2217) dt+ , respectively. Therefore, it is possible to show that \u03c6(t) = \u03c6(0) + \u03c6\u2032(0)t + \u03c6 \u2032\u2032(0) 2 t\n2. Furthermore, due to the convexity of \u03c6(t), we have that\n\u03c6\u2032(0) < 0 \u21d2 tq \u2265 t\u2217 > 0, \u03c6\u2032(0) > 0 \u21d2 tq \u2264 t\u2217 < 0, (21)\n10. In this case, the admissible conditions for violation are the second and the third conditions in (14).\nwhere tq = \u2212 \u03c6 \u2032(0)\n\u03c6\u2032\u2032(0) is the unconstrained minimum of \u03c6(t). From all these considerations, we can derive the following relation:\n\u03c6(t\u2217) \u2264 \u03c6(0) + \u03c6 \u2032(0)\n2 t\u2217 (22)\nIn fact, if \u03c6\u2032\u2032(0) = 0, then (22) trivially holds. If \u03c6\u2032\u2032(0) > 0, then\n\u03c6(t\u2217)\u2212 \u03c6(0) = \u03c6 \u2032(0) 2 t\u2217 ( 2tq \u2212 t\u2217 tq ) \u2264 \u03c6 \u2032(0) 2 t\u2217 (23)\nwhere the last inequality of (23) is valid because ( 2tq\u2212t\u2217 tq )\n\u2265 1, by simply applying (21).\nNote also that (19) can be used to derive the following result, namely:\n\u2016\u03c3\u2032 \u2212 \u03c3\u2217\u20162 = |t\u2217| \u221a 2 (24)\nBy combining (23) and (24) and considering that conditions (14) can be compactly rewritten as |\u03c6\u2032(0)| > \u03c4 , we obtain that\n\u03c6(0)\u2212 \u03c6(t\u2217) \u2265 \u2212\u03c6 \u2032(0)\n2 t\u2217 = |\u03c6\u2032(0)| 2 |t\u2217|\n> \u03c4 2 |t\u2217| = \u03c4 2 \u221a 2 \u2016\u03c3\u2032 \u2212 \u03c3\u2217\u20162, (25)\nFinally, statement (p) is obtained from (25), by taking into account that \u03c6(t\u2217) = F (\u03c3\u2217, \u03b4\u2217) and \u03c6(0) = F (\u03c3\u2032, \u03b4\u2032).\nLemma 2 states that each iteration of Algorithm 1 generates a solution that is \u03c4\u2212optimal for the indices in the working set S.\nThe convergence of USMO to a \u03c4\u2212optimal solution can be proven by contradiction by assuming that the algorithm proceeds indefinitely. This is equivalent to assume that (xik ,xjk) is violating \u2200k \u2265 0, where (ik, jk) represents the pair of indices selected at iteration k.\nSince {F (\u03c3k, \u03b4k)} is a decreasing sequence (due to the fact that zk 6= zk+1 \u2200k \u2265 011 and that the algorithm minimizes the objective function at each iteration) and bounded below (due to the existence of an unknown global optimum), it is convergent. By exploiting this fact and by considering that 2 \u221a 2\n\u03c4 [F (\u03c3k, \u03b4k)\u2212F (\u03c3k+l, \u03b4k+l)] >\n\u2016\u03c3k\u2212\u03c3k+l\u20162, \u2200k, l \u2265 0, which can be obtained from (p) of Lemma 2 by applying l times the triangle inequality, it is possible to conclude that {\u03c3k} is a Cauchy sequence. Therefore, since the sequence lies also in a closed feasible set, it is convergent. In other words, we have that \u03c3k \u2192 \u03c3\u0304 for k \u2192 \u221e, meaning that Algorithm 1 produces a convergent sequence of points. Now, it is important to understand if this sequence converges to a \u03c4\u2212optimal solution.\nFirst of all, let us define the set of indices that are encountered/selected by the algorithm infinitely many times:\nI\u221e = {(\u00b5, \u03bd) : \u2203{kt} \u2282 {k}, (ikt , jkt ) = (\u00b5, \u03bd),\u2200t \u2208 N} (26)\n{kt} is therefore a subsequence of {k}. It is also important to mention that since the number of iterations is infinite and the number of samples is finite, I\u221e cannot be an empty set. Based on this consideration, we define v\u00b5\u03bd as the vector, whose elements are the entries at position \u00b5 and \u03bd of a general vector v, and provide the following lemma.\nLemma 3. Assume (\u00b5, \u03bd) \u2208 I\u221e and let {kt} be the sequence of indices for which (ikt , jkt) = (\u00b5, \u03bd). Then,\n11. Statement (a) of Lemma 2.\n10\n(a) \u2200\u01eb > 0, \u2203t\u0302 > 0: \u2200t \u2265 t\u0302, \u2016\u03c3kt\u00b5\u03bd\u2212\u03c3\u0304\u00b5\u03bd\u2016 < \u01eb and \u2016\u03c3kt+1\u00b5\u03bd \u2212 \u03c3\u0304\u00b5\u03bd\u2016 < \u01eb (b) f\u03c3kt (x\u00b5)\u2212f\u03c3kt (x\u03bd) > \u03c4 \u21d2 f\u03c3\u0304(x\u00b5)\u2212f\u03c3\u0304(x\u03bd) \u2265 \u03c4 (c) f\u03c3kt (x\u00b5)\u2212f\u03c3kt (x\u03bd) < \u2212\u03c4 \u21d2 f\u03c3\u0304(x\u00b5)\u2212f\u03c3\u0304(x\u03bd) \u2264 \u2212\u03c4 (d) f\u03c3kt (x\u00b5)\u2212f\u03c3kt (x\u03bd) > \u03c4\u22122 \u21d2 f\u03c3\u0304(x\u00b5)\u2212f\u03c3\u0304(x\u03bd) \u2265 \u03c4\u22122 (e) f\u03c3kt (x\u00b5)\u2212f\u03c3kt (x\u03bd)<\u2212\u03c4+2 \u21d2 f\u03c3\u0304(x\u00b5)\u2212f\u03c3\u0304(x\u03bd)\u2264\u2212\u03c4+2\nwhere f\u03c3kt , f\u03c3\u0304 represent the target function with coefficients \u03b1i computed according to (7) using \u03c3\nkt and \u03c3\u0304, respectively.\nProof: Since {\u03c3k} is convergent and {kt}, {kt+1} are subsequences of {k}, {\u03c3kt} and {\u03c3kt+1} are also convergent sequences. In other words, \u2203t\u0302>0 such that \u2016\u03c3kt\u2212\u03c3\u0304\u2016<\u01eb and \u2016\u03c3kt+1 \u2212 \u03c3\u0304\u2016<\u01eb. Furthemore, \u2016\u03c3kt \u2212 \u03c3\u0304\u2016\u2265\u2016\u03c3kt\u00b5\u03bd \u2212 \u03c3\u0304\u00b5\u03bd\u2016 and \u2016\u03c3kt+1 \u2212 \u03c3\u0304\u2016\u2265\u2016\u03c3kt+1\u00b5\u03bd \u2212 \u03c3\u0304\u00b5\u03bd\u2016. By combining these two results, we obtain statement (a).\nConcerning statement (b), we have that f\u03c3kt (x\u00b5)\u2212f\u03c3kt (x\u03bd)>\u03c4 . Furthermore, from convergence of {\u03c3kt} and continuity of f , we obtain that \u2200\u01eb>0, \u2203t\u0303\u2265t\u0302: \u2200t\u2265t\u0303, \u2212\u01eb\u2264f\u03c3kt (x\u00b5)\u2212f\u03c3\u0304(x\u00b5)\u2264\u01eb and \u2212\u01eb\u2264f\u03c3kt (x\u03bd)\u2212f\u03c3\u0304(x\u03bd)\u2264\u01eb, meaning that both {f\u03c3kt (x\u00b5)} and {f\u03c3kt (x\u03bd)} are convergent. Therefore, f\u03c3kt (x\u00b5)\u2212f\u03c3kt (x\u03bd)>\u03c4 can be rewritten as\nf\u03c3kt (x\u00b5)\u2212f\u03c3kt (x\u03bd)+f\u03c3\u0304(x\u00b5)\u2212f\u03c3\u0304(x\u00b5)+f\u03c3\u0304(x\u03bd)\u2212f\u03c3\u0304(x\u03bd)>\u03c4\nand by applying the information about the convergence of both {f\u03c3kt (x\u00b5)} and {f\u03c3kt (x\u03bd)}, we get that\nf\u03c3\u0304(x\u00b5)\u2212 f\u03c3\u0304(x\u03bd) > \u03c4 \u2212 2\u01eb\nwhich is valid \u2200\u01eb > 0 and therefore proves statement (b). All other statements, namely (c)-(e), can be proven using the same approach. Lemma 3 states some conditions about the final target function and also states that the sequence output by Algorithm 1, after a sufficiently large number of iterations, is enclosed in a ball centered at \u03c3\u0304. This aspect is shown in Figure 3 for R1 and for different possible locations of \u03c3\u0304\u00b5,\u03bd . The same picture shows also the possible transitions that may happen at each iteration. In particular, we see that for \u03c3\u0304\u00b5,\u03bd lying on corners and edges, different kinds of transitions exist. In fact, we find transitions from border to border, transitions from border to inner points and viceversa, and transitions from inner points to inner points. These are indetified as bd \u2192 bd, bd \u2192 int, int \u2192 bd and int \u2192 int, respectively. Note that for \u03c3\u0304\u00b5,\u03bd not lying on borders, int \u2192 int is the only available kind of transition. Based on these considerations, it is possible to prove the following lemma.\nLemma 4. Let (\u00b5, \u03bd), {kt}, t\u0302 and \u01eb be defined according to Lemma 3. Then, \u2203t\u0304 \u2265 t\u0302 such that \u2200t \u2265 t\u0304 and for sequence\n{kt} the only allowed transitions are int \u2192 bd and bd \u2192 bd.\nProof: Consider region R1 and (\u03c3\u0304\u00b5, \u03c3\u0304\u03bd) \u2208 int R1. Then, the only admissible type of transitions for this case is int\u2192int. Therefore, based on statement (c) of Lemma 2 (and thanks also to statement (a) of Lemma 3), we obtain that \u2200t\u2265t\u0304, f\u03c3kt+1(x\u00b5)\u2212f\u03c3kt+1(x\u03bd)=0. By exploiting this fact, the continuity of f and the convergence of {\u03c3kt+1}, it is possible to show that\nf\u03c3\u0304(x\u00b5)\u2212f\u03c3\u0304(x\u03bd) = 0 (27)\nFurthermore, since (x\u00b5,x\u03bd) is a violating pair at all iterations and \u2200t\u2265t\u0304, \u03c3kt\u00b5\u03bd \u2208 int R1 (due to statement (a) of Lemma 3), (x\u00b5,x\u03bd) has to satisfy conditions (b) or (c) of Lemma 3. These conditions are in contradiction with (27), meaning that the int\u2192int transition is not allowed in this case.\nConsider now region R1 and (\u03c3\u0304\u00b5, \u03c3\u0304\u03bd) \u2208 E, or equivalently (\u03c3\u0304\u00b5, \u03c3\u0304\u03bd) \u2208 A. This time, the potential transitions are bd \u2192 bd, bd \u2192 int, int \u2192 bd and int \u2192 int. Nevertheless, it is always possible to define a subsequence containing only either int \u2192 int or bd \u2192 int and obtain therefore conclusions similar to the previous case. In fact, both int\u2192int and bd \u2192 int are not allowed transitions.\nThe same results can be obtained in a similar way for other edges, corners of R1 as well as for points in R3, upon selection of the proper conditions in Lemma 2.\nConsider now region R2 and (\u03c3\u0304\u00b5, \u03c3\u0304\u03bd) \u2208 int R2. The only admissible transition in this case is int \u2192 int. From statement (d) of Lemma 2, we have that \u2200t\u2265t\u0304, f\u03c3kt+1(x\u00b5)\u2212f\u03c3kt+1(x\u03bd)= \u2212 2 and, from the continuity of f and the convergence of {\u03c3kt+1}, it is possible to show that\nf\u03c3\u0304(x\u00b5)\u2212f\u03c3\u0304(x\u03bd) = \u22122 (28)\nFurthermore, since (x\u00b5,x\u03bd) is a violating pair at all iterations and \u2200t\u2265t\u0304, \u03c3kt\u00b5\u03bd \u2208 int R2, (x\u00b5,x\u03bd) has to satisfy conditions (b) or (d) of Lemma 3. These conditions are in contradiction with (28), meaning that the int\u2192int transition is not valid.\nFor all corners and edges ofR2, as well as for all points in R4, it is possible to show that int\u2192int and bd \u2192 int are not valid transitions. The proof is similar to the previous cases. Therefore, the only admissible transitions after a sufficiently large number of iterations are int \u2192 bd and bd \u2192 bd. It is interesting to note that each transition int \u2192 bd increases the number of components of\u03c3 belonging to borders of the four regions, by one or two, while each transition bd \u2192 bd leaves it unchanged. Since this number is bounded by n, transition int \u2192 bd cannot appear infinitely many times. Therefore, \u2203t\u2217 \u2265 t\u0304, \u2200t \u2265 t\u2217, bd \u2192 bd is the only valid transition.\nNote that bd \u2192 bdmay happen only when (\u03c3\u0304\u00b5, \u03c3\u0304\u03bd) is located at some specific corners of the feasible region, namely corners A or E for region R1, corners B or C for region R2, corners E or I for region R3 and corners F or H for region R4. For all cases, it is possible to define a subsequence that goes only from a vertical to a horizontal border and a subsequence that goes only from a horizontal to a vertical border. Without loss of generality, we can consider a specific case, namely (\u03c3\u0304\u00b5, \u03c3\u0304\u03bd) \u2208 A. Note that for the first subsequence, f\u03c3kt+1(x\u00b5)\u2212f\u03c3kt+1(x\u03bd)<\u2212 \u03c4 , since (x\u00b5,x\u03bd) has to be a violating pair in order not to stop the iterations and therefore,\n11\nfrom statement (c) of Lemma 3, f\u03c3\u0304(x\u00b5)\u2212f\u03c3\u0304(x\u03bd)< \u2212 \u03c4 . For the second subsequence, f\u03c3kt+1(x\u00b5)\u2212f\u03c3kt+1(x\u03bd)>\u03c4 and consequently f\u03c3\u0304(x\u00b5)\u2212f\u03c3\u0304(x\u03bd)>\u03c4 . This leads to a contradiction which holds \u2200(\u00b5, \u03bd) \u2208 I\u221e. Therefore, the assumption that Algorithm 1 proceeds indefinitely is not verified. In other words, there exists an iteration at which the algorithm stops because a \u03c4\u2212optimal solution is obtained."}, {"heading": "6 EXPERIMENTAL RESULTS", "text": "In this section, comprehensive evaluations are performed to verify the effectiveness of USMO. The proposed algorithm is compared against [7] and [6]. The code of USMO is developed in MATLAB and it is available at XXXX XXXX.12. Competitors are also implemented in MATLAB to guarantee fair comparisons. In particular, the method in [7] solves problem (6) using the MATLAB built-in function quadprog, combined with the second-order primal-dual interior point algorithm [68], while the method in [6] solves problem (4) with the ramp loss function using the quadprog function combined with the concave-convex procedure [69]. Experiments are run on a machine with 16 2.40 GHz cores and 64GB RAM. A large collection of real-world data sets from the UCI repository is used, namely 17 data sets, 12 of which contain few hundreds/thousands of samples, while the remaining 5 are consistently bigger. Table 2 shows some of their statistics.\nSince both USMO and [7] solve the same optimization problem, we firstly investigate whether the two algorithms achieve same solutions. To do this, we consider the Fmeasure in a transductive setting, to access the generalization performance, on all small-scale data sets and under different configurations of hyperparameters and kernel function used. In particular, we consider different values of \u03bb, viz. 0.0001, 0.001, 0.01, 0.1, and use the linear and the Gaussian kernels.13 In all experiments, only 20% of positive samples are labeled, while the remaining ones are considered unlabeled. Tables 3-6 show the results using the linear and the Gaussian kernel, respectively. In the majority\n12. Except for the initialization, which uses LIBSVM [52] to run the one-class classifier.\n13. The positive class prior \u03c0 is set to the class proportion in the training data sets. Methods like [21], [70], [71] can be used to estimate it.\nof cases, both algorithms achieve identical performance, thus same solutions. This fact is a direct consequence of the theory proved in Section 5, since USMO is guaranteed to converge to the same value of objective function obtained in [7]. For few cases, the small differences in performance are due to numerical approximations involved during computation. Concerning the training time, USMO outperforms the competitor in almost all cases when using the linear kernel, while obtains similar performance when using the Gaussian kernel. In the former case, the advantage of USMO is twofold, namely linear storage complexity, instead of quadratic, and faster convergence rate, while in the latter case, there is a clear advantage only in terms of storage complexity. In all cases USMO is therefore able to achieve the same solution of [7] in a more efficient way.\nSecondly, we investigate the quality of solutions obtained by USMO and [6]. To do this, we adopt the same configurations used in previous analysis. Tables 3-6 show the results using the linear and the Gaussian kernel, respectively. On average, USMO is performing better than [6]. There are cases in which the two methods achieve very different performance, for example see the house-votes, the ionosphere, the liverdisorders and the spectf datasets on Table 5. This is mainly due to the fact that the optimization problem solved in [6] is not convex, meaning that multiple local solutions are available. The choice of the starting point becomes therefore a critical operation, since it directly impacts the quality of the obtained solution. Furthermore, it is important to mention that USMO has a linear storage complexity instead of quadratic, as for [6].\nFinally, we investigate the performance of all algorithms on problems of larger scale. We use the 5 larger data sets and test the methods with a fixed number of positive labeled samples, viz. 100 instances randomly sampled from the positive class, and an increasing number of unlabeled samples. Regarding the multi-class data sets, namely statlog, MNIST and poker-hand, each of the available classes is considered positive and compared against the others, thus producing different experiments. In all cases, the linear kernel is used. Figure 4 and Figure 5 show all training time curves as well as the learning trends for the generalization performance (estimated over the test sets and using the Fmeasure). It is evident that the advantage of USMO over [7] and [6], in terms of both speed and storage, increases with the number of unlabeled samples. When the number of unlabeled samples exceeds 10000 units, the method in [7] and [6] becomes computationally intractable (in terms of storage) and only USMO can still provide a solution. Furthermore, USMO outperforms other approaches in terms of generalization performance on almost all cases."}, {"heading": "7 CONCLUSION", "text": "In this work an efficient algorithm for PU learning is proposed. Theoretical analysis is provided to ensure that the obtained solution recovers the optimum of the objective function. Experimental evaluation assesses the efficiency of the proposed method showing its potential applicability to real-world problems involving PU learning. Future research will extend this work and consider one-shot learning as well as representation learning.\n12"}, {"heading": "APPENDIX A PROOF OF THE REPRESENTER THEOREM", "text": "Similarly to [63], define \u03a6 as the set, whose elements are the representers of the training dataset D = Dp \u222a Dn, namely \u03a8 = {\n\u03d5xi \u2208 Hk|i : xi \u2208 D } . Be H\u03a8 the linear subspace of Hk spanned by the elements in \u03a8 and H\u0304\u03a8 its orthogonal complement, such that Hk = H\u03a8 \u2295 H\u0304\u03a8:\nH\u03a8 = { g \u2208 Hk|g = \u2211\ni:xi\u2208D\n\u03b1i\u03d5xi , \u03b1i \u2208 R }\nH\u0304\u03a8 = { h \u2208 Hk|\u3008h, g\u3009Hk = 0,\u2200g \u2208 H\u03a8 }\nTherefore, any function f \u2208 Hk can be decomposed in two orthogonal components, namely f = f\u2217 + f\u22a5 where f\u2217 \u2208 H\u03a8 and f\u22a5 \u2208 H\u0304\u03a8. Evaluating the function f at the training point xj is performed by exploiting the previous properties, viz.\nf(xj) = \u3008\u03d5xj , f\u2217 + f\u22a5\u3009Hk = \u3008\u03d5xj , f\u2217\u3009Hk = \u3008\u03d5xj , \u2211\ni:xi\u2208D\n\u03b1i\u03d5xi\u3009Hk\n= \u2211\ni:xi\u2208D\n\u03b1i\u3008\u03d5xj , \u03d5xi\u3009Hk\n= \u2211\ni:xi\u2208D\n\u03b1ik(xj ,xi)\n= \u2211\ni:xi\u2208D\n\u03b1ik(xi,xj)\nwhere the first and second equalities are due to the reproducing property of RKHS and orthogonality, respectively. The third and the fourth equalities are simple application of the inner product properties. The fifth equality holds by the definition of reproducing kernel, while the last one is valid thanks to the simmetry of any Mercer kernel. This relation highlights the fact that the evaluation of any function f at any training point xj is independent of f\n\u22a5. Consequently, since Remp(f) is a functional of f evaluated at all samples of the training dataset, we have that Remp(f) is also independent of f\u22a5. In other words, Remp(f) = Remp(f\n\u2217). Furthermore, thanks to the orthogonality property, one can express the regularization term in (4) in the following way:\n\u2016f\u20162Hk = \u2016f \u2217 + f\u22a5\u20162Hk = \u2016f \u2217\u20162Hk + \u2016f \u22a5\u20162Hk\nThe objective function in (4) can be therefore lower bounded in the following way:\nRemp(f) + \u03bb\u2016f\u20162Hk =Remp(f \u2217) + \u03bb\u2016f\u2217\u20162Hk + \u03bb\u2016f \u22a5\u20162Hk \u2265Remp(f\u2217) + \u03bb\u2016f\u2217\u20162Hk\nwhich is valid for any f \u2208 Hk. f\u2217 is therefore the minimizer of (4) and it assumes the following form:\nf\u2217(x) = \u2211\ni:xi\u2208D\n\u03b1i\u3008\u03d5xi , \u03d5x\u3009Hk = \u2211\ni:xi\u2208D\n\u03b1ik(xi,x)\nQ.E.D."}, {"heading": "APPENDIX B", "text": ""}, {"heading": "PU LEARNING FORMULATION", "text": "B.1 Derivation of the primal problem By taking into account the definition of the double Hinge loss function and its composite loss, namely \u2113(x, y) = max{\u2212xy,max{0, 12 \u2212 xy 2 }} and \u2113\u0303(x, y) = \u2212xy, we can\nexpress the empirical risk functional (3) in the following way:\n\u2212 \u03c0 p \u2211\ni:xi\u2208Dp\nf(xi)+ 1\nn\n\u2211\ni:xi\u2208Dn\nmax\n{\nf(xi),max { 0, 1\n2 +\nf(xi)\n2\n}\n}\n(29) and by exploiting the result stated by the representer\ntheorem, the optimization problem (4) becomes:\nmin \u03b1,\u03be,\u03b2\n{\n\u2212c1 \u2211\ni:xi\u2208Dp\n(\n\u2211\nj:xj\u2208D\n\u03b1jk(xi,xj) + \u03b2\n)\n+ c2 \u2211\ni:xi\u2208Dn\n\u03bei\n+ 1\n2\n\u2211\ni:xi\u2208D\n\u2211\nj:xj\u2208D \u03b1i\u03b1jk(xi,xj)\n}\ns.t. \u03bei \u2265 0, \u03bei \u2265 \u2211\nj:xj\u2208D\n\u03b1jk(xi,xj) + \u03b2,\n\u03bei \u2265 1 2 + 1 2\n(\n\u2211\nj:xj\u2208D\n\u03b1jk(xi,xj) + \u03b2\n)\n, (30)\nwhere c1 = \u03c0 2\u03bbp , c2 = 1\n2\u03bbn and \u03bei is the slack variable associated with sample xi \u2208 Dn. Notice that slack variables are used to make the objective function differentiable.\nFinally, by using vector notation, (30) can be rewritten in a more compact form:\nmin \u03b1,\u03be,\u03b2\n{ \u2212c11\u0303TK\u03b1\u2212 c11\u0303T1\u03b2 + c21Tn\u03be + 1\n2 \u03b1\nT K\u03b1\n}\ns.t. \u03be 0n, \u03be UK\u03b1+ \u03b21n,\n\u03be 1 2 1n + 1 2 UK\u03b1+ \u03b2 2 1n,\nB.2 Derivation of the dual problem\nThe Lagrangian function for problem (5) is defined as follows:\nL(\u03b1, \u03be, \u03b2,\u03b2,\u03b3, \u03b4) = 1 2 \u03b1 T K\u03b1\u2212 c11\u0303TK\u03b1\u2212 c11\u0303T1\u03b2 + c21Tn\u03be\n\u2212 \u03b7T \u03be + \u03b3T ( UK\u03b1+ \u03b21n \u2212 \u03be ) + \u03b4T ( 1\n2 1n +\n1 2 UK\u03b1+ \u03b2 2 1n \u2212 \u03be\n)\nwhere \u03b7 0n,\u03b3 0n and \u03b4 0n are vectors of size u containing the Lagrange multipliers associated to the constraints of the primal problem. By taking the derivatives of L with respect to \u03b1, \u03be, \u03b2 and equating them to zero, we obtain the following relations:\n\u2202L \u2202\u03b1 = 0n \u21d2 \u03b1 = c11\u0303\u2212UT\u03b3 \u2212 12U T\u03b4, \u2202L \u2202\u03b2 = 0 \u21d2 c11\u0303T1\u2212 \u03b3T1n \u2212 12\u03b4 T 1n = 0\n\u21d2 1T (\nc11\u0303\u2212UT\u03b3 \u2212 12U T \u03b4\n)\n= 0,\n\u2202L \u2202\u03be = 0n \u21d2 c21n \u2212 \u03b7 \u2212 \u03b3 \u2212 \u03b4 = 0n \u2227 \u03b7, \u03b3, \u03b4 0n \u21d2 \u03b3 + \u03b4 c21n \u2227 0n \u03b3, \u03b4 c21n,\n13\nwhich are then used to build the Lagrange dual function and consequently derive the following Lagrange dual problem (we skip the derivation due to lack of space):\nmax \u03b3,\u03b4\n{\n\u22121 2\n(\n\u03b3 + 1\n2 \u03b4\n)T\nUKU T\n(\n\u03b3 + 1\n2 \u03b4\n)\n+ c11\u0303 T KU T\n(\n\u03b3 + 1\n2 \u03b4\n)\n+ 1\n2 1 T n\u03b4\n}\ns.t. 1T [ c11\u0303\u2212UT ( \u03b3 + 1\n2 \u03b4\n)]\n= 0,\n\u03b3 + \u03b4 c21n, 0n \u03b3, \u03b4 c21n,\n(6) can be finally derived by defining \u03c3 = \u03b3 + 12\u03b4 and rewriting it as a minimization problem."}, {"heading": "APPENDIX C PROOF OF LEMMA 1", "text": "By introducing the following notation, namely\n\u03c3 k S =\n[\n\u03c3ki \u03c3kj\n]\n,\u03b4kS =\n[\n\u03b4ki \u03b4kj\n]\n,KSS =\n[\nk(xi,xi) k(xi,xj) k(xj ,xi) k(xj ,xj)\n]\n,e =\n[\ne1 e2\n]\nthe objective function of the QP subproblem (8) evaluated at (\u03c3kS , \u03b4 k S) can be rewritten as:\nF (\u03c3ki , \u03c3 k j )\u2212 \u03b4ki 2 \u2212 \u03b4 k j 2 (31)\nwhere\nF (\u03c3ki , \u03c3 k j ) =\n1\n2\n[\n\u03c3ki \u03c3 k j\n]\n[\nk(xi,xi) k(xi,xj) k(xj ,xi) k(xj ,xj)\n] [\n\u03c3ki \u03c3kj\n]\n+ [ e1 e2 ]\n[\n\u03c3ki \u03c3kj\n]\nand the constraints of (8) at (\u03c3kS , \u03b4 k S) are therefore:\n\u03c3ki + \u03c3 k j = a k,\n\u03c3ki + \u03b4ki 2 \u2264 c2 \u2227 \u03c3kj + \u03b4kj 2 \u2264 c2, \u03c3ki \u2212 \u03b4ki 2 \u2265 0 \u2227 \u03c3kj \u2212 \u03b4kj 2 \u2265 0, 0 \u2264 \u03b4ki , \u03b4kj \u2264 c2, (32)\nwhere ak = c1p\u2212 1T\u03c3kS\u0304 is a constant scalar for iteration k. Since (\u03c3\u2217S , \u03b4 \u2217 S) is an optimal solution of (8), it has to\nsatisfy the Karush-Kuhn-Tucker (KKT) conditions. In particular, the stationarity conditions can be expressed in the following way:\n\u2202L \u2202\u03c3ki = \u2202F (\u03c3\u2217i , \u03c3 \u2217 j ) \u03c3ki + \u03b2 + \u03bbi \u2212 \u00b5i = 0, \u2202L \u2202\u03c3kj = \u2202F (\u03c3\u2217i , \u03c3 \u2217 j ) \u03c3kj + \u03b2 + \u03bbj \u2212 \u00b5j = 0, \u2202L \u2202\u03b4ki =\u22121 2 + \u03bbi 2 + \u00b5i 2 + \u03bei \u2212 \u03b7i = 0, \u2202L \u2202\u03b4kj =\u22121 2 + \u03bbj 2 + \u00b5j 2 + \u03bej \u2212 \u03b7j = 0, (33)\nwhere L is the Lagrange dual function obtained from the QP subproblem and \u03b2, \u03bbi, \u03bbj , \u00b5i, \u00b5j , \u03bei, \u03bej , \u03b7i, \u03b7j are its Lagrange multipliers, namely:\nL =F (\u03c3\u2217i , \u03c3\u2217j )\u2212 \u03b4\u2217i 2 \u2212 \u03b4 \u2217 j 2 + \u03b2(\u03c3\u2217i + \u03c3 \u2217 j \u2212 ak)\n+ \u03bbi(\u03c3 \u2217 i + \u03b4\u2217i 2 \u2212 c2) + \u03bbj(\u03c3\u2217j + \u03b4\u2217j 2 \u2212 c2) \u2212 \u00b5i(\u03c3\u2217i \u2212 \u03b4\u2217i 2 )\u2212 \u00b5j(\u03c3\u2217j \u2212 \u03b4\u2217j 2 ) + \u03bei(\u03b4 \u2217 i \u2212 c2) + \u03bej(\u03b4\u2217j \u2212 c2)\u2212 \u03b7i\u03b4\u2217i \u2212 \u03b7j\u03b4\u2217j\nNow, focus on terms associated with sample xi and specifically on its inequality constraints in (32). Based on them, it is possible to distinguish the following four cases (Figure 6 helps to understand this):\n0 \u2264 \u03b4ki < c2 \u2227 \u03b4ki 2 < \u03c3ki < c2 \u2212 \u03b4ki 2 , (34) 0 \u2264 \u03b4ki < c2 \u2227 \u03c3ki = c2 \u2212 \u03b4ki 2 , (35) 0 \u2264 \u03b4ki < c2 \u2227 \u03c3ki = \u03b4ki 2 , (36) \u03b4ki = c2 \u2227 \u03c3ki = \u03b4ki 2 , (37)\nBy considering the KKT complementary slackness conditions together with (33), we can derive the following statements:\nCase (34) \u21d2 \u03bbi = 0, \u00b5i = 0, \u03bei = 0, \u03b7i \u2265 0\n\u21d2 \u2202F (\u03c3 \u2217 i , \u03c3 \u2217 j )\n\u03c3ki + \u03b2 = 0 \u2227 \u03b7i = \u22121 2 ,\nCase (35) \u21d2 \u03bbi \u2265 0, \u00b5i = 0, \u03bei = 0, \u03b7i \u2265 0\n\u21d2 \u2202F (\u03c3 \u2217 i , \u03c3 \u2217 j )\n\u03c3ki + \u03b2 \u2264 \u22121 \u2227 \u03bbi \u2265 1 \u2227 \u03b7i \u2265 0,\nCase (36) \u21d2 \u03bbi = 0, \u00b5i \u2265 0, \u03bei = 0, \u03b7i \u2265 0\n\u21d2 \u2202F (\u03c3 \u2217 i , \u03c3 \u2217 j )\n\u03c3ki + \u03b2 \u2265 1 \u2227 \u00b5i \u2265 1 \u2227 \u03b7i \u2265 0,\nCase (37) \u21d2 \u03bbi \u2265 0, \u00b5i \u2265 0, \u03bei \u2265 0, \u03b7i = 0,\n\u21d2 \u22121 \u2264 \u2202F (\u03c3 \u2217 i , \u03c3 \u2217 j )\n\u03c3ki + \u03b2 \u2264 1 \u2227 \u22121 \u2264 \u03bbi, \u00b5i \u2264 1,\n(38)\nThe first statement in (38) is clearly a contradiction, implying that condition (34) is not valid for KKT. In other words, any optimal solution (\u03c3\u2217i , \u03b4 \u2217 i ) does not satisfy condition (34), but only conditions (35)-(37). This fact is valid \u2200xu \u2208 S due to the symmetry of the QP subproblem (8), which concludes the proof.\n14"}, {"heading": "ACKNOWLEDGMENTS", "text": "This research was partially supported by NSFC (61333014) and the Collaborative Innovation Center of Novel Software Technology and Industrialization. We gratefully acknowledge the support of NVIDIA Corporation with the donation of a Titan X Pascal machine to support this research."}], "references": [{"title": "Learning Classifiers from Only Positive and Unlabeled Data", "author": ["C. Elkan", "K. Noto"], "venue": "ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 2008, pp. 213\u2013220.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2008}, {"title": "One Class Support Vector Machine Based Non-Relevance Feedback Document Retrieval", "author": ["T. Onoda", "H. Murata", "S. Yamada"], "venue": "IEEE International Joint Conference on Neural Networks, vol. 1. IEEE, 2005, pp. 552\u2013557.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2005}, {"title": "Inlier-Based Outlier Detection via Direct Density Ratio Estimation", "author": ["S. Hido", "Y. Tsuboi", "H. Kashima", "M. Sugiyama", "T. Kanamori"], "venue": "2008 Eighth IEEE International Conference on Data Mining. IEEE, 2008, pp. 223\u2013232.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "A Positive and Unlabeled Learning Algorithm for One-Class Classification of Remote-Sensing Data", "author": ["W. Li", "Q. Guo", "C. Elkan"], "venue": "IEEE Transactions on Geoscience and Remote Sensing, vol. 49, no. 2, pp. 717\u2013725, 2011.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Toward Open Set Recognition", "author": ["W.J. Scheirer", "A. de Rezende Rocha", "A. Sapkota", "T.E. Boult"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 35, no. 7, pp. 1757\u20131772, 2013.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Analysis of Learning from Positive and Unlabeled Data", "author": ["M. Du Plessis", "G. Niu", "M. Sugiyama"], "venue": "NIPS, 2014, pp. 703\u2013711.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Convex Formulation for Learning from Positive and Unlabeled Data", "author": ["\u2014\u2014"], "venue": "ICML, 2015, pp. 1386\u20131394.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "An Overview of Statistical Learning Theory", "author": ["V.N. Vapnik"], "venue": "Neural Networks, IEEE Transactions on, pp. 988\u2013999, 1999.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1999}, {"title": "PU Learning for Matrix Completion", "author": ["C.-J. Hsieh", "N. Natarajan", "I.S. Dhillon"], "venue": "ICML, 2015, pp. 2445\u20132453.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Multi-View Positive and Unlabeled Learning", "author": ["J.T. Zhou", "S.J. Pan", "Q. Mao", "I.W. Tsang"], "venue": "ACML, 2012, pp. 555\u2013570.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Beyond the Low-Density Separation Principle: A Novel Approach to Semi- Supervised Learning", "author": ["T. Sakai", "M.C. d. Plessis", "G. Niu", "M. Sugiyama"], "venue": "arXiv preprint arXiv:1605.06955, 2016.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2016}, {"title": "Positive Unlabeled Learning for Data Stream Classification", "author": ["X. Li", "S.Y. Philip", "B. Liu", "S.-K. Ng"], "venue": "SDM, vol. 9. SIAM, 2009, pp. 257\u2013268.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2009}, {"title": "Positive Unlabeled Leaning for Time Series Classification", "author": ["M.N. Nguyen", "X.-L. Li", "S.-K. Ng"], "venue": "IJCAI, vol. 11, 2011, pp. 1421\u2013 1426.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2011}, {"title": "Hypergraph-Based Anomaly Detection of High-Dimensional Co-Occurrences", "author": ["J. Silva", "R. Willett"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 31, no. 3, pp. 563\u2013569, 2009.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2009}, {"title": "Partially Supervised Classification of Text Documents", "author": ["B. Liu", "W.S. Lee", "P.S. Yu", "X. Li"], "venue": "ICML, vol. 2, 2002, pp. 387\u2013 394.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2002}, {"title": "PEBL: Positive Example Based Learning for Web Page Classification Using SVM", "author": ["H. Yu", "J. Han", "K.C.-C. Chang"], "venue": "International Conference on Knowledge Discovery and Data Mining. ACM, 2002, pp. 239\u2013248.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2002}, {"title": "Learning to Classify Texts Using Positive and Unlabeled Data", "author": ["X. Li", "B. Liu"], "venue": "IJCAI, vol. 3, 2003, pp. 587\u2013592.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2003}, {"title": "Single-Class Classification with Mapping Convergence", "author": ["H. Yu"], "venue": "Machine Learning, vol. 61, no. 1-3, pp. 49\u201369, 2005.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2005}, {"title": "Building Text Classifiers Using Positive and Unlabeled Examples", "author": ["B. Liu", "Y. Dai", "X. Li", "W.S. Lee", "P.S. Yu"], "venue": "Third IEEE International Conference on Data Mining. IEEE, 2003, pp. 179\u2013186.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2003}, {"title": "Single-class classifier learning using neural networks: An application to the prediction of mineral deposits", "author": ["A. Skabar"], "venue": "Machine Learning and Cybernetics, 2003 International Conference on, vol. 4. IEEE, 2003, pp. 2127\u20132132.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2003}, {"title": "Semi-Supervised Novelty Detection", "author": ["G. Blanchard", "G. Lee", "C. Scott"], "venue": "Journal of Machine Learning Research, vol. 11, no. Nov, pp. 2973\u20133009, 2010.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "Domain Anomaly Detection in Machine Perception: A System Architecture and Taxonomy", "author": ["J. Kittler", "W. Christmas", "T. De Campos", "D. Windridge", "F. Yan", "J. Illingworth", "M. Osman"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 36, no. 5, pp. 845\u2013859, 2014.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Novelty Detection: A ReviewPart 1: Statistical Approaches", "author": ["M. Markou", "S. Singh"], "venue": "Signal processing, vol. 83, no. 12, pp. 2481\u2013 2497, 2003.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2003}, {"title": "Novelty Detection: A ReviewPart 2: Neural Network Based Approaches", "author": ["\u2014\u2014"], "venue": "Signal processing, vol. 83, no. 12, pp. 2499\u20132521, 2003.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2003}, {"title": "Authorship Verification as a One-Class Classification Problem", "author": ["M. Koppel", "J. Schler"], "venue": "ICML, 2004, p. 62.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2004}, {"title": "One-Class Collaborative Filtering", "author": ["R. Pan", "Y. Zhou", "B. Cao", "N.N. Liu", "R. Lukose", "M. Scholz", "Q. Yang"], "venue": "Eighth IEEE International Conference on Data Mining. IEEE, 2008, pp. 502\u2013511.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2008}, {"title": "SV Estimation of a Distributions Support", "author": ["B. Sch\u00f6lkopf", "R. Williamson", "A. Smola", "J. Shawe-Taylor"], "venue": "NIPS, vol. 12, 1999.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1999}, {"title": "Support Vector Domain Description", "author": ["D.M. Tax", "R.P. Duin"], "venue": "Pattern Recognition Letters, vol. 20, no. 11, pp. 1191\u20131199, 1999.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1999}, {"title": "Network Constraints and Multi- Objective Optimization for One-Class Classification", "author": ["M.M. Moya", "D.R. Hush"], "venue": "Neural Networks, vol. 9, no. 3, pp. 463\u2013474, 1996.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1996}, {"title": "Kernel Method for Percentile Feature Extraction", "author": ["B. Sch\u00f6lkopf", "J.C. Platt", "A.J. Smola"], "venue": "2000.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2000}, {"title": "Uniform Object Generation for Optimizing One-Class Classifiers", "author": ["D.M. Tax", "R.P. Duin"], "venue": "Journal of Machine Learning Research, vol. 2, no. Dec, pp. 155\u2013173, 2001.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2001}, {"title": "A Linear Programming Approach to Novelty Detection", "author": ["C. Bennett", "K. Campbell"], "venue": "NIPS, vol. 13, no. 13, p. 395, 2001.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2001}, {"title": "One-Class LP Classifiers for Dissimilarity Representations", "author": ["E. Pekalska", "D. Tax", "R. Duin"], "venue": "NIPS, 2002, pp. 761\u2013768.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2002}, {"title": "One-Class SVMs for Document Classification", "author": ["L.M. Manevitz", "M. Yousef"], "venue": "Journal of Machine Learning Research, vol. 2, no. Dec, pp. 139\u2013154, 2001.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2001}, {"title": "One-Class Classification", "author": ["D.M. Tax"], "venue": "TU Delft, Delft University of Technology,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2001}, {"title": "Combining One-Class Classifiers", "author": ["D.M. Tax", "R.P. Duin"], "venue": "International Workshop on Multiple Classifier Systems. Springer, 2001, pp. 299\u2013308.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2001}, {"title": "Ensembles of One Class Support Vector Machines", "author": ["A.D. Shieh", "D.F. Kamm"], "venue": "International Workshop on Multiple Classifier Systems. Springer, 2009, pp. 181\u2013190.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2009}, {"title": "Constructing Boosting Algorithms from SVMs: An Application to One-Class Classification", "author": ["G. Ratsch", "S. Mika", "B. Scholkopf", "K.-R. Muller"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 24, no. 9, pp. 1184\u20131199, 2002.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2002}, {"title": "Multi-Class Supervised Novelty Detection", "author": ["V. Jumutc", "J.A. Suykens"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 36, no. 12, pp. 2510\u20132523, 2014.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2014}, {"title": "Theoretical Comparisons of Learning from Positive-Negative, Positive-Unlabeled, and Negative-Unlabeled Data", "author": ["G. Niu", "M.C. d. Plessis", "T. Sakai", "M. Sugiyama"], "venue": "arXiv preprint arXiv:1603.03130, 2016.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2016}, {"title": "One-Class Classification: Taxonomy of Study and Review of Techniques", "author": ["S.S. Khan", "M.G. Madden"], "venue": "The Knowledge Engineering Review, vol. 29, no. 03, pp. 345\u2013374, 2014.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2014}, {"title": "The Effect of Unlabeled Samples in Reducing the Small Sample Size Problem and Mitigating the Hughes Phenomenon", "author": ["B.M. Shahshahani", "D.A. Landgrebe"], "venue": "IEEE Transactions on Geoscience and remote sensing, vol. 32, no. 5, pp. 1087\u20131095, 1994.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 1994}, {"title": "A Mixture of Experts Classifier with Learning Based on Both Labelled and Unlabelled Data", "author": ["D.J. Miller", "H.S. Uyar"], "venue": "NIPS, 1997, pp. 571\u2013577.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 1997}, {"title": "The Value of Unlabeled Data for Classification Problems", "author": ["T. Zhang", "F. Oles"], "venue": "ICML, 2000, pp. 1191\u20131198.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2000}, {"title": "Semi-Supervised Learning (Chapelle, O. et al., Eds.; 2006)[Book reviews", "author": ["O. Chapelle", "B. Scholkopf", "A. Zien"], "venue": "IEEE Transactions on Neural Networks, vol. 20, no. 3, pp. 542\u2013542, 2009.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2009}, {"title": "Classtering: Joint Classification and Clustering with Mixture of Factor Analysers", "author": ["E. Sansone", "A. Passerini", "F.G.B.D. Natale"], "venue": "European Conference on Aritificial Intelligence (ECAI), 2016, pp. 1089\u20131095.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2016}, {"title": "Semi-Supervised Classification by Low Density Separation.", "author": ["O. Chapelle", "A. Zien"], "venue": "AISTATS,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2005}, {"title": "Manifold Regularization: A Geometric Framework for Learning from Labeled and Unlabeled Examples", "author": ["M. Belkin", "P. Niyogi", "V. Sindhwani"], "venue": "Journal of Machine Learning Research, vol. 7, pp. 2399\u20132434, 2006.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2006}, {"title": "Semi- Supervised Learning with Deep Generative Models", "author": ["D.P. Kingma", "S. Mohamed", "D.J. Rezende", "M. Welling"], "venue": "NIPS, 2014, pp. 3581\u20133589.  15", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2014}, {"title": "Semi-Supervised Learning by Disagreement", "author": ["Z.-H. Zhou", "M. Li"], "venue": "Knowledge and Information Systems, vol. 24, no. 3, pp. 415\u2013 439, 2010.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2010}, {"title": "Convex and Scalable Weakly Labeled SVMs", "author": ["Y.-F. Li", "I.W. Tsang", "J.T. Kwok", "Z.-H. Zhou"], "venue": "Journal of Machine Learning Research, vol. 14, no. 1, pp. 2151\u20132188, 2013.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2013}, {"title": "LIBSVM: A Library for Support Vector Machines", "author": ["C.-C. Chang", "C.-J. Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology (TIST), vol. 2, no. 3, p. 27, 2011.", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2011}, {"title": "A Study on SMO-Type Decomposition Methods for Support Vector Machines", "author": ["P.-H. Chen", "R.-E. Fan", "C.-J. Lin"], "venue": "IEEE Transactions on Neural Networks, vol. 17, no. 4, pp. 893\u2013908, 2006.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2006}, {"title": "Semi-Supervised Learning in Gigantic Image Collections", "author": ["R. Fergus", "Y. Weiss", "A. Torralba"], "venue": "NIPS, 2009, pp. 522\u2013530.", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2009}, {"title": "Large-Scale Manifold Learning", "author": ["A. Talwalkar", "S. Kumar", "H. Rowley"], "venue": "CVPR. IEEE, 2008, pp. 1\u20138.", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2008}, {"title": "Learning with Augmented Class by Exploiting Unlabeled Data", "author": ["Q. Da", "Y. Yu", "Z.-H. Zhou"], "venue": "AAAI, 2014, pp. 1760\u20131766.", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2014}, {"title": "Efficient Noise-Tolerant Learning from Statistical Queries", "author": ["M. Kearns"], "venue": "Journal of the ACM (JACM), vol. 45, no. 6, pp. 983\u20131006, 1998.", "citeRegEx": "57", "shortCiteRegEx": null, "year": 1998}, {"title": "Positive and Unlabeled Examples Help Learning", "author": ["F. De Comit\u00e9", "F. Denis", "R. Gilleron", "F. Letouzey"], "venue": "International Conference on Algorithmic Learning Theory. Springer, 1999, pp. 219\u2013230.", "citeRegEx": "58", "shortCiteRegEx": null, "year": 1999}, {"title": "Learning from Positive and Unlabeled Examples", "author": ["F. Letouzey", "F. Denis", "R. Gilleron"], "venue": "International Conference on Algorithmic Learning Theory. Springer, 2000, pp. 71\u201385.", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2000}, {"title": "Naive Bayes Classifier for Positive Unlabeled Learning with Uncertainty", "author": ["J. He", "Y. Zhang", "X. Li", "Y. Wang"], "venue": "SDM. SIAM, 2010, pp. 361\u2013372.", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2010}, {"title": "On Discriminative vs. Generative Classifiers: A Comparison of Logistic Regression and Naive Bayes", "author": ["A. Jordan"], "venue": "pp. 841\u2013848, 2002.", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2002}, {"title": "Theory of Reproducing Kernels", "author": ["N. Aronszajn"], "venue": "Transactions of the American Mathematical Society, pp. 337\u2013404, 1950.", "citeRegEx": "62", "shortCiteRegEx": null, "year": 1950}, {"title": "A Generalized Representer Theorem", "author": ["B. Sch\u00f6lkopf", "R. Herbrich", "A.J. Smola"], "venue": "COLT, 2001, pp. 416\u2013426.", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2001}, {"title": "A Unifying View of Representer Theorems", "author": ["A. Argyriou", "F. Dinuzzo"], "venue": "ICML, 2014, pp. 748\u2013756.", "citeRegEx": "64", "shortCiteRegEx": null, "year": 2014}, {"title": "Invexity and the Kuhn\u2013Tucker Theorem", "author": ["M.A. Hanson"], "venue": "Journal of Mathematical Analysis and Applications, vol. 236, no. 2, pp. 594\u2013 604, 1999.", "citeRegEx": "66", "shortCiteRegEx": null, "year": 1999}, {"title": "Estimating the Support of a High-dimensional Distribution", "author": ["B. Sch\u00f6lkopf", "J.C. Platt", "J. Shawe-Taylor", "A.J. Smola", "R.C. Williamson"], "venue": "Neural Computation, pp. 1443\u20131471, 2001.", "citeRegEx": "67", "shortCiteRegEx": null, "year": 2001}, {"title": "On the Implementation of a Primal-Dual Interior Point Method", "author": ["S. Mehrotra"], "venue": "SIAM Journal on Optimization, vol. 2, no. 4, pp. 575\u2013601, 1992.", "citeRegEx": "68", "shortCiteRegEx": null, "year": 1992}, {"title": "The Concave-Convex Procedure (CCCP)", "author": ["A.L. Yuille", "A. Rangarajan"], "venue": "NIPS, 2002, pp. 1033\u20131040.", "citeRegEx": "69", "shortCiteRegEx": null, "year": 2002}, {"title": "Learning with Positive and Unlabeled Examples Using Weighted Logistic Regression", "author": ["W.S. Lee", "B. Liu"], "venue": "ICML, vol. 3, 2003, pp. 448\u2013455.", "citeRegEx": "70", "shortCiteRegEx": null, "year": 2003}], "referenceMentions": [{"referenceID": 0, "context": "POSITIVE unlabeled learning (PU learning) refers to the task of learning a binary classifier from only positive and unlabeled data [1].", "startOffset": 131, "endOffset": 134}, {"referenceID": 1, "context": "\u2022 Retrieval [2], where the goal is to find samples in an unlabeled data set similar to samples provided by a user.", "startOffset": 12, "endOffset": 15}, {"referenceID": 2, "context": "\u2022 Inlier-based outlier detection [3], where the goal is to detect outliers from an unlabeled data set based on inlier samples.", "startOffset": 33, "endOffset": 36}, {"referenceID": 3, "context": "\u2022 One-vs-rest classification [4], which is typical of problems where the negative class is too diverse and it is therefore difficult to collect and label enough negative samples.", "startOffset": 29, "endOffset": 32}, {"referenceID": 4, "context": "\u2022 Open set recognition [5], where testing classes are unknown at training time and therefore the exploitation of unlabeled data may help to learn more robust concepts.", "startOffset": 23, "endOffset": 26}, {"referenceID": 5, "context": "The recent works in [6] and [7] formulate PU learning as optimization problems under the framework of statistical learning theory [8].", "startOffset": 20, "endOffset": 23}, {"referenceID": 6, "context": "The recent works in [6] and [7] formulate PU learning as optimization problems under the framework of statistical learning theory [8].", "startOffset": 28, "endOffset": 31}, {"referenceID": 7, "context": "The recent works in [6] and [7] formulate PU learning as optimization problems under the framework of statistical learning theory [8].", "startOffset": 130, "endOffset": 133}, {"referenceID": 8, "context": "PU learning is very well known in the machine learning community, since it is used in a variety of tasks ranging frommatrix completion [9], multi-view learning [10], as well as semi-supervised learning [11].", "startOffset": 135, "endOffset": 138}, {"referenceID": 9, "context": "PU learning is very well known in the machine learning community, since it is used in a variety of tasks ranging frommatrix completion [9], multi-view learning [10], as well as semi-supervised learning [11].", "startOffset": 160, "endOffset": 164}, {"referenceID": 10, "context": "PU learning is very well known in the machine learning community, since it is used in a variety of tasks ranging frommatrix completion [9], multi-view learning [10], as well as semi-supervised learning [11].", "startOffset": 202, "endOffset": 206}, {"referenceID": 11, "context": "It is also applied in data mining to classify data streams [12] or time series [13] and to detect events, like co-occurrences, in graphs [14].", "startOffset": 59, "endOffset": 63}, {"referenceID": 12, "context": "It is also applied in data mining to classify data streams [12] or time series [13] and to detect events, like co-occurrences, in graphs [14].", "startOffset": 79, "endOffset": 83}, {"referenceID": 13, "context": "It is also applied in data mining to classify data streams [12] or time series [13] and to detect events, like co-occurrences, in graphs [14].", "startOffset": 137, "endOffset": 141}, {"referenceID": 14, "context": "The first category consists of two-stage approaches [15], [16], [17], [18], which firstly extract a set of reliable negative samples from the unlabeled data and secondly use them, together with the available positive data, to train a binary classifier.", "startOffset": 52, "endOffset": 56}, {"referenceID": 15, "context": "The first category consists of two-stage approaches [15], [16], [17], [18], which firstly extract a set of reliable negative samples from the unlabeled data and secondly use them, together with the available positive data, to train a binary classifier.", "startOffset": 58, "endOffset": 62}, {"referenceID": 16, "context": "The first category consists of two-stage approaches [15], [16], [17], [18], which firstly extract a set of reliable negative samples from the unlabeled data and secondly use them, together with the available positive data, to train a binary classifier.", "startOffset": 64, "endOffset": 68}, {"referenceID": 17, "context": "The first category consists of two-stage approaches [15], [16], [17], [18], which firstly extract a set of reliable negative samples from the unlabeled data and secondly use them, together with the available positive data, to train a binary classifier.", "startOffset": 70, "endOffset": 74}, {"referenceID": 0, "context": "Positive and negative data are then used to train different classifiers based on SVM [1], [19], neural networks [20] or kernel density estimators [21].", "startOffset": 85, "endOffset": 88}, {"referenceID": 18, "context": "Positive and negative data are then used to train different classifiers based on SVM [1], [19], neural networks [20] or kernel density estimators [21].", "startOffset": 90, "endOffset": 94}, {"referenceID": 19, "context": "Positive and negative data are then used to train different classifiers based on SVM [1], [19], neural networks [20] or kernel density estimators [21].", "startOffset": 112, "endOffset": 116}, {"referenceID": 20, "context": "Positive and negative data are then used to train different classifiers based on SVM [1], [19], neural networks [20] or kernel density estimators [21].", "startOffset": 146, "endOffset": 150}, {"referenceID": 21, "context": "OCC is applied to many real-world problems, involving for example anomaly/novelty detection (see [22] for a recent survey and definition of anomaly detection and see [23], [24] for reviews about novelty detection).", "startOffset": 97, "endOffset": 101}, {"referenceID": 22, "context": "OCC is applied to many real-world problems, involving for example anomaly/novelty detection (see [22] for a recent survey and definition of anomaly detection and see [23], [24] for reviews about novelty detection).", "startOffset": 166, "endOffset": 170}, {"referenceID": 23, "context": "OCC is applied to many real-world problems, involving for example anomaly/novelty detection (see [22] for a recent survey and definition of anomaly detection and see [23], [24] for reviews about novelty detection).", "startOffset": 172, "endOffset": 176}, {"referenceID": 24, "context": "Other possible applications of OCC range from author verification in text documents [25], document retrieval [2], as well as collaborative filtering in social networks [26].", "startOffset": 84, "endOffset": 88}, {"referenceID": 1, "context": "Other possible applications of OCC range from author verification in text documents [25], document retrieval [2], as well as collaborative filtering in social networks [26].", "startOffset": 109, "endOffset": 112}, {"referenceID": 25, "context": "Other possible applications of OCC range from author verification in text documents [25], document retrieval [2], as well as collaborative filtering in social networks [26].", "startOffset": 168, "endOffset": 172}, {"referenceID": 26, "context": "Authors is [27], [28] are among the first to develop OCC algorithms.", "startOffset": 11, "endOffset": 15}, {"referenceID": 27, "context": "Authors is [27], [28] are among the first to develop OCC algorithms.", "startOffset": 17, "endOffset": 21}, {"referenceID": 26, "context": "In particular, the study in [27] proposes a classifier which finds the hyperplane separating data from the origin with the maximum margin, while authors in [28] propose a classifier which finds the mimimum radius hypersphere enclosing data.", "startOffset": 28, "endOffset": 32}, {"referenceID": 27, "context": "In particular, the study in [27] proposes a classifier which finds the hyperplane separating data from the origin with the maximum margin, while authors in [28] propose a classifier which finds the mimimum radius hypersphere enclosing data.", "startOffset": 156, "endOffset": 160}, {"referenceID": 26, "context": "Despite the difference between these two approaches, it is proved in [27] that, for specific choices of kernel function (namely, in the case of translationinvariant kernels, like the Gaussian kernel), the obtained solutions are the same.", "startOffset": 69, "endOffset": 73}, {"referenceID": 29, "context": "In fact, authors in [30] modify the model of [27] by incorporating a small training set of anomalies and using the centroid of this set, instead of the origin, as the reference point to find the hyperplane.", "startOffset": 20, "endOffset": 24}, {"referenceID": 26, "context": "In fact, authors in [30] modify the model of [27] by incorporating a small training set of anomalies and using the centroid of this set, instead of the origin, as the reference point to find the hyperplane.", "startOffset": 45, "endOffset": 49}, {"referenceID": 30, "context": "Authors in [31] propose a strategy to automatically select the hyperparameters defined in [28] to increase the usability of the framework.", "startOffset": 11, "endOffset": 15}, {"referenceID": 27, "context": "Authors in [31] propose a strategy to automatically select the hyperparameters defined in [28] to increase the usability of the framework.", "startOffset": 90, "endOffset": 94}, {"referenceID": 26, "context": "Rather than repelling samples from a specific point, as in [27], [30], authors in [32] propose a strategy that attract samples towards the centroid.", "startOffset": 59, "endOffset": 63}, {"referenceID": 29, "context": "Rather than repelling samples from a specific point, as in [27], [30], authors in [32] propose a strategy that attract samples towards the centroid.", "startOffset": 65, "endOffset": 69}, {"referenceID": 31, "context": "Rather than repelling samples from a specific point, as in [27], [30], authors in [32] propose a strategy that attract samples towards the centroid.", "startOffset": 82, "endOffset": 86}, {"referenceID": 32, "context": "Authors in [33] propose a similar strategy based on linear programming, where data are represented in a similarity/dissimilarity space.", "startOffset": 11, "endOffset": 15}, {"referenceID": 33, "context": "To mention a few, authors in [34] propose a neural network-based approach, where the goal is to learn the identity function.", "startOffset": 29, "endOffset": 33}, {"referenceID": 34, "context": "Authors in [35] propose a one-class nearest neighbour, where a test sample is accepted as a member of the target class only when the distance from its neighbours is comparable to their local density.", "startOffset": 11, "endOffset": 15}, {"referenceID": 28, "context": "More precisely, the term OCC was coined in 1996 [29].", "startOffset": 48, "endOffset": 52}, {"referenceID": 35, "context": "Solutions to improve classification perfomance are obtained by applying classical strategies, like ensemble methods [36], bagging [37] or boosting [38] strategies.", "startOffset": 116, "endOffset": 120}, {"referenceID": 36, "context": "Solutions to improve classification perfomance are obtained by applying classical strategies, like ensemble methods [36], bagging [37] or boosting [38] strategies.", "startOffset": 130, "endOffset": 134}, {"referenceID": 37, "context": "Solutions to improve classification perfomance are obtained by applying classical strategies, like ensemble methods [36], bagging [37] or boosting [38] strategies.", "startOffset": 147, "endOffset": 151}, {"referenceID": 38, "context": "Authors in [39] argue that existing one-class classifiers fail when dealing with mixture distributions.", "startOffset": 11, "endOffset": 15}, {"referenceID": 20, "context": "As discussed in [21], standard OCC algorithms are not designed to use unlabeled data and therefore make the implicit assumption that they are uniformly distributed on the support of nominal distribution, which does not hold in general.", "startOffset": 16, "endOffset": 20}, {"referenceID": 39, "context": "The recent work in [40] proves that, under some simple conditions, large amount of unlabeled data can boost performance of OCC even in comparison with completely supervised approaches.", "startOffset": 19, "endOffset": 23}, {"referenceID": 4, "context": "Furthermore, the exploitation of unlabeled data allows building OCC classifiers in the context of open set recognition [5], where it is essential to learn robust concepts/functions.", "startOffset": 119, "endOffset": 122}, {"referenceID": 40, "context": "PU learning can be regarded as a generalization of OCC [41], in the sense that it can deal and manage unlabeled data coming from more general distributions than the uniform one.", "startOffset": 55, "endOffset": 59}, {"referenceID": 41, "context": "2 Comparison with semi-supervised learning The idea of exploiting unlabeled data in semi-supervised learning is originally proposed by [42].", "startOffset": 135, "endOffset": 139}, {"referenceID": 42, "context": "Authors in [43] are among the first to analyze this aspect from a generative perspective.", "startOffset": 11, "endOffset": 15}, {"referenceID": 43, "context": "Authors in [44] extend this analysis and consider that data can be correctly described by the more general class of parametric models.", "startOffset": 11, "endOffset": 15}, {"referenceID": 44, "context": "The work in [45] provides a reference taxonomy of semi-supervised learning algorithms.", "startOffset": 12, "endOffset": 16}, {"referenceID": 45, "context": "In particular, we distinguish among generative approaches, like the one in [46], which exploit the unlabeled data to better estimate the class-conditional densities and infer/predict the unknown labels based on the learnt model,", "startOffset": 75, "endOffset": 79}, {"referenceID": 46, "context": "low-density separation methods, like the work in [47], which look for decision boundaries that correctly classify labeled data and are placed in regions with few unlabeled samples (the so called low-density regions), graph-based methods, like in [48], which exploit unlabeled data to build a similarity graph and then propagate labels based on the smoothness assumption, methods based on dimensionality reduction, like in [49], which use the unlabeled samples for representation learning and then perform classification on the learnt feature representation, and disagreement-based methods, discussed in [50], which exploit the disagreement among multiple base learners to learn more robust ensemble classifiers.", "startOffset": 49, "endOffset": 53}, {"referenceID": 47, "context": "low-density separation methods, like the work in [47], which look for decision boundaries that correctly classify labeled data and are placed in regions with few unlabeled samples (the so called low-density regions), graph-based methods, like in [48], which exploit unlabeled data to build a similarity graph and then propagate labels based on the smoothness assumption, methods based on dimensionality reduction, like in [49], which use the unlabeled samples for representation learning and then perform classification on the learnt feature representation, and disagreement-based methods, discussed in [50], which exploit the disagreement among multiple base learners to learn more robust ensemble classifiers.", "startOffset": 246, "endOffset": 250}, {"referenceID": 48, "context": "low-density separation methods, like the work in [47], which look for decision boundaries that correctly classify labeled data and are placed in regions with few unlabeled samples (the so called low-density regions), graph-based methods, like in [48], which exploit unlabeled data to build a similarity graph and then propagate labels based on the smoothness assumption, methods based on dimensionality reduction, like in [49], which use the unlabeled samples for representation learning and then perform classification on the learnt feature representation, and disagreement-based methods, discussed in [50], which exploit the disagreement among multiple base learners to learn more robust ensemble classifiers.", "startOffset": 422, "endOffset": 426}, {"referenceID": 49, "context": "low-density separation methods, like the work in [47], which look for decision boundaries that correctly classify labeled data and are placed in regions with few unlabeled samples (the so called low-density regions), graph-based methods, like in [48], which exploit unlabeled data to build a similarity graph and then propagate labels based on the smoothness assumption, methods based on dimensionality reduction, like in [49], which use the unlabeled samples for representation learning and then perform classification on the learnt feature representation, and disagreement-based methods, discussed in [50], which exploit the disagreement among multiple base learners to learn more robust ensemble classifiers.", "startOffset": 603, "endOffset": 607}, {"referenceID": 50, "context": "For example, the work in [51] proposes a framework to solve a mixed-integer programming problem, which runs multiple times the SVM algorithm.", "startOffset": 25, "endOffset": 29}, {"referenceID": 51, "context": "State-of-the-art implementations of SVM (see for example LIBSVM [52]) are based mainly on decomposition methods [53], like our proposed approach.", "startOffset": 64, "endOffset": 68}, {"referenceID": 52, "context": "State-of-the-art implementations of SVM (see for example LIBSVM [52]) are based mainly on decomposition methods [53], like our proposed approach.", "startOffset": 112, "endOffset": 116}, {"referenceID": 53, "context": "Other semi-supervised approaches look for approximations of the fitness function involved in the optimization problem, like [54], [55].", "startOffset": 124, "endOffset": 128}, {"referenceID": 54, "context": "Other semi-supervised approaches look for approximations of the fitness function involved in the optimization problem, like [54], [55].", "startOffset": 130, "endOffset": 134}, {"referenceID": 55, "context": "To the best of our knowledge, only few works like the study in [56] propose semi-supervised methods capable to handle this situation.", "startOffset": 63, "endOffset": 67}, {"referenceID": 10, "context": "On the contrary, recent works in [11], [40], show that it is possible to apply PU learning algorithms to solve semi-supervised learning tasks, even in the case of open set environment.", "startOffset": 33, "endOffset": 37}, {"referenceID": 39, "context": "On the contrary, recent works in [11], [40], show that it is possible to apply PU learning algorithms to solve semi-supervised learning tasks, even in the case of open set environment.", "startOffset": 39, "endOffset": 43}, {"referenceID": 56, "context": "Inspired by the seminal work in [57] and by the first studies about OCC [27], [28], authors in [58], and later with an extended version in [59], are the first to define and theoretically analyze the problem of PU learning.", "startOffset": 32, "endOffset": 36}, {"referenceID": 26, "context": "Inspired by the seminal work in [57] and by the first studies about OCC [27], [28], authors in [58], and later with an extended version in [59], are the first to define and theoretically analyze the problem of PU learning.", "startOffset": 72, "endOffset": 76}, {"referenceID": 27, "context": "Inspired by the seminal work in [57] and by the first studies about OCC [27], [28], authors in [58], and later with an extended version in [59], are the first to define and theoretically analyze the problem of PU learning.", "startOffset": 78, "endOffset": 82}, {"referenceID": 57, "context": "Inspired by the seminal work in [57] and by the first studies about OCC [27], [28], authors in [58], and later with an extended version in [59], are the first to define and theoretically analyze the problem of PU learning.", "startOffset": 95, "endOffset": 99}, {"referenceID": 58, "context": "Inspired by the seminal work in [57] and by the first studies about OCC [27], [28], authors in [58], and later with an extended version in [59], are the first to define and theoretically analyze the problem of PU learning.", "startOffset": 139, "endOffset": 143}, {"referenceID": 56, "context": "In particular, the authors propose a framework based on the statistical query model [57] to have theoretical guarantees about classification performance and to derive algorithms based on decision trees.", "startOffset": 84, "endOffset": 88}, {"referenceID": 59, "context": "Instead of considering binary features, authors in [60] propose a Naive-Bayes classifier for categorical features in noisy environments.", "startOffset": 51, "endOffset": 55}, {"referenceID": 60, "context": "Their work is subject to the attribute independence assumption, which is useful for estimating class-conditional densities in high-dimensional spaces, but rather limiting when compared to discriminative approaches, which directly focus on classification and avoid performing density estimation [61].", "startOffset": 294, "endOffset": 298}, {"referenceID": 20, "context": "In order to understand the criticality of this issue, consider the theoretical result of consistency presented in [21].", "startOffset": 114, "endOffset": 118}, {"referenceID": 5, "context": "Recently, authors in [6], [7] propose frameworks based on the statistical learning theory [8].", "startOffset": 21, "endOffset": 24}, {"referenceID": 6, "context": "Recently, authors in [6], [7] propose frameworks based on the statistical learning theory [8].", "startOffset": 26, "endOffset": 29}, {"referenceID": 7, "context": "Recently, authors in [6], [7] propose frameworks based on the statistical learning theory [8].", "startOffset": 90, "endOffset": 93}, {"referenceID": 7, "context": "According to statistical learning theory [8], the", "startOffset": 41, "endOffset": 44}, {"referenceID": 6, "context": "where l\u0303(f(x), 1) = l(f(x), 1) \u2212 l(f(x),\u22121) is called the composite loss [7].", "startOffset": 73, "endOffset": 76}, {"referenceID": 61, "context": "For an overview of RKHS and their properties, see the work in [62] where \u03b1i \u2208 R for all i.", "startOffset": 62, "endOffset": 66}, {"referenceID": 62, "context": "Just to mention a few, authors in [63] have provided a generalized version of the classical representer theorem for classification and regression tasks, while authors in [48] have derived the representer theorem for semi-supervised learning.", "startOffset": 34, "endOffset": 38}, {"referenceID": 47, "context": "Just to mention a few, authors in [63] have provided a generalized version of the classical representer theorem for classification and regression tasks, while authors in [48] have derived the representer theorem for semi-supervised learning.", "startOffset": 170, "endOffset": 174}, {"referenceID": 63, "context": "More recently, the study in [64] has proposed a unified view of existing representer theorems, identifying the relations between these theorems and certain classes of regularization penalties.", "startOffset": 28, "endOffset": 32}, {"referenceID": 6, "context": "Authors in [7] have analysed the properties of loss functions for the PU learning problem and shown that a necessary condition for convexity is that the composite loss function in (3) is affine.", "startOffset": 11, "endOffset": 14}, {"referenceID": 6, "context": "In particular, better generalization performance can be achieved by using the double Hinge loss [7].", "startOffset": 96, "endOffset": 99}, {"referenceID": 5, "context": "Even, the comparison with non-convex loss functions [6], [7] suggests to use the double Hinge loss for the PU learning problem.", "startOffset": 52, "endOffset": 55}, {"referenceID": 6, "context": "Even, the comparison with non-convex loss functions [6], [7] suggests to use the double Hinge loss for the PU learning problem.", "startOffset": 57, "endOffset": 60}, {"referenceID": 64, "context": "In case of (6) they are both necessary and sufficient conditions, since the objective is convex and the constraints are affine functions [66].", "startOffset": 137, "endOffset": 141}, {"referenceID": 65, "context": "Labeled samples are used to train a oneclass SVM [67], that is in turn used to rank the unlabeled samples according to their value of estimated target function.", "startOffset": 49, "endOffset": 53}, {"referenceID": 6, "context": "The proposed algorithm is compared against [7] and [6].", "startOffset": 43, "endOffset": 46}, {"referenceID": 5, "context": "The proposed algorithm is compared against [7] and [6].", "startOffset": 51, "endOffset": 54}, {"referenceID": 6, "context": "In particular, the method in [7] solves problem (6) using the MATLAB built-in function quadprog, combined with the second-order primal-dual interior point algorithm [68], while the method in [6] solves problem (4) with the ramp loss function using the quadprog function combined with the concave-convex procedure [69].", "startOffset": 29, "endOffset": 32}, {"referenceID": 66, "context": "In particular, the method in [7] solves problem (6) using the MATLAB built-in function quadprog, combined with the second-order primal-dual interior point algorithm [68], while the method in [6] solves problem (4) with the ramp loss function using the quadprog function combined with the concave-convex procedure [69].", "startOffset": 165, "endOffset": 169}, {"referenceID": 5, "context": "In particular, the method in [7] solves problem (6) using the MATLAB built-in function quadprog, combined with the second-order primal-dual interior point algorithm [68], while the method in [6] solves problem (4) with the ramp loss function using the quadprog function combined with the concave-convex procedure [69].", "startOffset": 191, "endOffset": 194}, {"referenceID": 67, "context": "In particular, the method in [7] solves problem (6) using the MATLAB built-in function quadprog, combined with the second-order primal-dual interior point algorithm [68], while the method in [6] solves problem (4) with the ramp loss function using the quadprog function combined with the concave-convex procedure [69].", "startOffset": 313, "endOffset": 317}, {"referenceID": 6, "context": "Since both USMO and [7] solve the same optimization problem, we firstly investigate whether the two algorithms achieve same solutions.", "startOffset": 20, "endOffset": 23}, {"referenceID": 51, "context": "Except for the initialization, which uses LIBSVM [52] to run the one-class classifier.", "startOffset": 49, "endOffset": 53}, {"referenceID": 20, "context": "Methods like [21], [70], [71] can be used to estimate it.", "startOffset": 13, "endOffset": 17}, {"referenceID": 68, "context": "Methods like [21], [70], [71] can be used to estimate it.", "startOffset": 19, "endOffset": 23}, {"referenceID": 6, "context": "This fact is a direct consequence of the theory proved in Section 5, since USMO is guaranteed to converge to the same value of objective function obtained in [7].", "startOffset": 158, "endOffset": 161}, {"referenceID": 6, "context": "In all cases USMO is therefore able to achieve the same solution of [7] in a more efficient way.", "startOffset": 68, "endOffset": 71}, {"referenceID": 5, "context": "Secondly, we investigate the quality of solutions obtained by USMO and [6].", "startOffset": 71, "endOffset": 74}, {"referenceID": 5, "context": "On average, USMO is performing better than [6].", "startOffset": 43, "endOffset": 46}, {"referenceID": 5, "context": "This is mainly due to the fact that the optimization problem solved in [6] is not convex, meaning that multiple local solutions are available.", "startOffset": 71, "endOffset": 74}, {"referenceID": 5, "context": "Furthermore, it is important to mention that USMO has a linear storage complexity instead of quadratic, as for [6].", "startOffset": 111, "endOffset": 114}, {"referenceID": 6, "context": "It is evident that the advantage of USMO over [7] and [6], in terms of both speed and storage, increases with the number of unlabeled samples.", "startOffset": 46, "endOffset": 49}, {"referenceID": 5, "context": "It is evident that the advantage of USMO over [7] and [6], in terms of both speed and storage, increases with the number of unlabeled samples.", "startOffset": 54, "endOffset": 57}, {"referenceID": 6, "context": "When the number of unlabeled samples exceeds 10000 units, the method in [7] and [6] becomes computationally intractable (in terms of storage) and only USMO can still provide a solution.", "startOffset": 72, "endOffset": 75}, {"referenceID": 5, "context": "When the number of unlabeled samples exceeds 10000 units, the method in [7] and [6] becomes computationally intractable (in terms of storage) and only USMO can still provide a solution.", "startOffset": 80, "endOffset": 83}, {"referenceID": 62, "context": "APPENDIX A PROOF OF THE REPRESENTER THEOREM Similarly to [63], define \u03a6 as the set, whose elements are the representers of the training dataset D = Dp \u222a Dn, namely \u03a8 = { \u03c6xi \u2208 Hk|i : xi \u2208 D }", "startOffset": 57, "endOffset": 61}], "year": 2016, "abstractText": "Positive unlabeled (PU) learning is useful in various practical situations, where there is a need to learn a classifier for a class of interest from an unlabeled data set, which may contain anomalies as well as samples from unknown classes. The learning task can be formulated as an optimization problem under the framework of statistical learning theory. Recent studies have theoretically analyzed its properties and generalization performance, nevertheless, little effort has been made to consider the problem of scalability, especially when large sets of unlabeled data are available. In this work we propose a novel scalable PU learning algorithm that is theoretically proven to provide the optimal solution, while showing superior computational and memory performance. Experimental evaluation confirms the theoretical evidence and shows that the proposed method can be successfully applied to a large variety of real-world problems involving PU learning.", "creator": "LaTeX with hyperref package"}}}