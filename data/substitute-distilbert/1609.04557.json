{"id": "1609.04557", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Sep-2016", "title": "Structured Dropout for Weak Label and Multi-Instance Learning and Its Application to Score-Informed Source Separation", "abstract": "many success stories describing relational neural networks are advantages of supervised learning, where available labels power gradient - informed learning methods. creating such labels, however, potential be expensive and thus there is increasing interest in weak labels which only provide coarse information, with uncertainty regarding motivation, location or value. using such labels often leads to considerable challenges for understanding learning process. current methods for weak - label training design employ standard supervised approaches that additionally reassign or prune labels during the learning process. the higher availability, however, is often limited as only limited importance of labels where the network already yields reasonable results toward boosted. we propose treating weak - foil training solve an unsupervised problem and use the labels to guide the representation learning to induce structure. to this task, we propose two autoencoder extensions : class activity penalties and penalty dropout. yet demonstrate the capabilities of our approach into the context of score - informed source separation of music.", "histories": [["v1", "Thu, 15 Sep 2016 09:50:55 GMT  (37kb,D)", "https://arxiv.org/abs/1609.04557v1", null], ["v2", "Mon, 26 Dec 2016 14:28:46 GMT  (37kb,D)", "http://arxiv.org/abs/1609.04557v2", null]], "reviews": [], "SUBJECTS": "cs.LG cs.SD", "authors": ["sebastian ewert", "mark b sandler"], "accepted": false, "id": "1609.04557"}, "pdf": {"name": "1609.04557.pdf", "metadata": {"source": "CRF", "title": "STRUCTURED DROPOUT FOR WEAK LABEL AND MULTI-INSTANCE LEARNING AND ITS APPLICATION TO SCORE-INFORMED SOURCE SEPARATION", "authors": ["Sebastian Ewert", "Mark B. Sandler"], "emails": [], "sections": [{"heading": null, "text": "Index Terms\u2014 Autoencoder, unsupervised learning, classactivity penalties, deep learning."}, {"heading": "1. INTRODUCTION", "text": "Training neural networks is often a complex endeavor, which is somewhat simplified if clear labels are available in a supervised learning scenario [1]. Annotating data, however, is typically an expensive process and hence there is increasing interest in using unlabeled data to support learning using smaller labeled dataset (semi-supervised learning) [2]. Another approach to address the cost issue are weak labels, where the annotator provides only relatively coarse information. For example, an annotator might indicate whether a car is shown in a 5-minute video, without specifying when, where or how long it is visible. Settings based on this type of weak labels are often referred to as multiple-instance learning, as one label provides spatially or temporally coarse information for a bag of instances [3]. Another type of weak label specifies several possible outcomes: A picture shows either a bird, a plane or a dark cloud, or in regression a value might be somewhere in an interval. For these two types, a weak label provides rough information about the existence of a concept, while the lack of a weak label gives clear information about its non-existence.\nThe effort to create weak labels is often only a fraction of highly detailed annotation. For learning, however, weak labels present considerable challenges [4]. For example, training a frame-wise car-detector can be difficult using weak labels if in a 5-minute clip labelled with \u2018car\u2019 the car is actually only shown for 3 seconds. A first naive way is to use supervised learning methods using the label \u2018car\u2019 for each frame in the 5-minutes block. Multiple-instance learning methods try to improve on this concept by iteratively relabeling instances as negative examples in a block [5] or pruning\nThis work was funded by EPSRC grant EP/L019981/1.\nthem [6, 7] if they are not clearly detected as positive after an initial naive training step, see also [8] for a comparison. Alternatively, one can learn using only the frame which yielded the clearest positive response in a block [9]. As a special case, one can use so called saliency maps to improve the temporal accuracy for networks with multi-frame inputs [10]. However, often such approaches are not effective [10], as re-labeling/pruning methods only re-interpret examples that are already correctly classified by the network (limiting the gain in information for the learning process), while highest-saliency learning ignores a considerable amount of annotated data that could be potentially useful for training.\nAll of these measures remain supervised learning methods, which requiring clear output labels cannot directly account for the fact that weak labels have an inherent uncertainty. In this paper, we propose to treat learning based on weak labels fundamentally as an unsupervised learning problem and use the labels only as a guidance to encourage structure in the learned representations. More precisely, we start from the standard autoencoder architecture [11], where one network transforms the input to a low-dimensional representation, which is then used to re-synthesize the input \u2013 differences between the input and output are measured using a reconstruction error term. Usually, this learned representation is not readily interpretable, which we change using the weak labels. To this end, before training, we associate each class to be detected with a number of units in the representation layer. Then, using the class activity information provided by weak labels, we encourage using an activity cost term on the representation that the units corresponding to the inactive classes are zero. This way, the encoder must model the input using only the units for the active classes in each frame. After training, activity in the output of this structured representation layer is already a surprisingly good indicator for class activity which only needs to be refined further in standard end-to-end learning (either as improved input or as a new, more accurate output target).\nTo enforce these activity constraints, one typically needs to drastically favor the activity cost over the reconstruction error. However, this sometimes had detrimental effects on the training efficiency: the gradient is dominated by the activity cost in this case and thus gradient-based learning methods often set all network weights to zero, thus deactivating all activity (i.e. ignoring the reconstruction error). This often slowed down training considerably. Therefore, we propose a second extension to accelerate training. More precisely, during a first training stage we propagate the input through the network and force-set the units associated with inactive classes to zero. This simple idea can be interpreted in several ways. First, it is a variant of the well-known stochastic dropout technique for regularization [12], just that our dropout is deterministic and induces structure instead of noise. Second, the decoder part of the network can operate early during training under conditions it will find once the network is fully trained, resembling properties of batch-normalization [13]. Third, the gradient is \u2018sharpened\u2019 crossing the representation layer and affects\nar X\niv :1\n60 9.\n04 55\n7v 2\n[ cs\n.L G\n] 2\n6 D\nec 2\n01 6\nin each input frame particularly those parts of the encoder network that are responsible for creating the active class representations.\nAs a further interpretation, this procedure can be seen as a nonlinear extension of non-negative matrix factorization (NMF) in combination with certain activity constraints [14]. This leads to an intuitive interpretation of our approach as a part-based representation of the input, similar to NMF. Therefore, we motivate our procedure starting from the well-known NMF and demonstrate the capabilities of our method using a task previously addressed with NMF: Score-informed source separation of music signals [14]. In this case, we have weak labels providing coarse information about the activity of notes, without specifying intensity or progression parameters. As shown by our experiments, our proposed system surpasses the NMF results by more than 0.5dB SDR without any specific hyperparameter tuning.\nThe remainder is organized as follows. In Section 2 we describe our proposed method in more detail. In Section 3, we show how our method can be employed for score-informed source separation and discuss in Section 4 our experimental results. We conclude in Section 5 with a prospect on future work."}, {"heading": "2. FROM NMF TO AN AUTOENCODER WITH STRUCTURED DROPOUT", "text": "The basic idea behind non-negative matrix factorization is to represent a series of N input vectors in the matrix V \u2208 RM\u00d7N\u22650 as a product of two matrices W \u2208 RM\u00d7K\u22650 and H \u2208 R K\u00d7N \u22650 with K < M . If we associate a specific class to be detected with one of the K NMF components (or a group thereof), we can incorporate information from weak labels into the NMF learning process by setting entries in H to zero: e.g. to express that class k will be inactive in input n, we can set Hk,n to zero \u2013 using multiplicative rules to iteratively updateW andH as usually done, these constraints will remain active throughout the learning process [15]. This way, we only specify which classes are not active but do not specify the exact intensity a class should have or whether it should be active at all.\nTo translate this NMF-based approach to incorporating weak labels to the world of neural networks, we first see that NMF and its learning process resemble the one of an autoencoder quite closely. Assuming we obtained a W and H with V \u2248 WH using NMF, it follows that H \u2248W+V , where W+ \u2208 RK\u00d7M is an approximation to a left-inverse of W , for example the Moore-Penrose pseudoinverse of W or simply the transpose of W if its columns are approximately orthogonal. We obtain V \u2248WW+V , which is an autoencoder with linear activation functions and some non-negativity constraints on its weight matrices [11].\nLet us generalize this a bit further. In particular, let h\u03a6 : RM \u2192 RK and f\u03a5 : RK \u2192 RM be multi-layer (feed-forward) networks with corresponding weight parameters in \u03a6 and \u03a5, respectively. From an autoencoder point of view, h is the encoder or analysis part transforming the input Vn to a K dimensional representation Rn := h\u03a6(Vn), that is then used by the decoder or synthesis part f to reconstruct the input from the low-dimensional information, compare Fig. 1a. Here, Vn denotes the n-th column of V . From an NMF point of view, h and f generalize the matrix productsW+V (as above) and WH to more general non-linear functions. The autoencoder f\u03a5 \u25e6 h\u03a6 is usually trained minimizing a distance function comparing the input with the reconstruction:\nargmin \u03a5,\u03a6\nc(\u03a6,\u03a5, V ) = 1\nN N\u2211 n=1 d(f\u03a5(h\u03a6(Vn)), Vn), (1)\nwhere d is a distance or divergence. This type of unsupervised feature-\nlearning has been found useful in a variety of tasks \u2013 however, the resulting low dimensional representation usually cannot easily be interpreted, in particular if f and h represent deep networks [11].\nNext, we extend this standard autoencoder to impose structure on the output of h. However, we cannot directly use the same approach as in NMF as we do not employ optimization rules based on multiplicative updates. Therefore, we propose a different approach and train the autoencoder to yield a network that behaves similarly. To this end, we first associate each unit (or dimension) in the output of h\u03a6 with a specific class used in our weak labels. Note that each class can (and often will) be associated with several units \u2013 in general, this is part of the application specific design process. Optionally, we can add some free units useful for noise or general background modelling. Next, we exploit the availability of weak labels to create a matrix L \u2208 {0, 1}K\u00d7N , which encodes the potential class activity in each input frame. More precisely, we set Lk,n = 1 if there is a weak label specifying that the class associated with unit k is potentially active in input frame n, while free units are always set to one. This approach generalizes ideas used in [16], which used a single class: noise or no-noise. We can now incorporate L into our objective function to discourage activity in units that should not be active in a frame:\nargmin \u03a5,\u03a6\nc(\u03a6,\u03a5, V, L) = 1\nN N\u2211 n=1 d(f\u03a5(h\u03a6(Vn)), Vn)\n+ \u03bb \u2225\u2225(1\u2212 Ln) h\u03a6(Vn)\u2225\u222522, (2)\nwhere \u03bb is a term balancing the reconstruction error and our activity cost and is the Hadamard product (point-wise multiplication), see also Fig. 1a. Using this modified `2 penalty on the output of h\u03a6, we penalize activity in units associated with classes known to be inactive and exclude the potentially active ones. Further, in contrast to classical supervised methods, we do not specify what should happen if a class is active, i.e. what value a unit should have. However, if a unit becomes active it is often a spatially/temporally accurate indicator that a certain class is present.\nIn practice, however, our new objective function led to some numerical problems, especially with deeper networks. In particular, to enforce the activity constraints, the parameter \u03bb needs to be set to a relatively high value. As a consequence, the gradient will be dominated by our new term, which in many cases steered the learning process towards a local minimum with all weights in \u03a6 set to zero, rather accepting the reconstruction error than making a mistake w.r.t. activity costs. A possible workaround was to employ a schedule for \u03bb that would slowly increase its value with the number of training iterations \u2013 setting such a schedule, however, can be difficult, as it\ndepends on properties of the error surface described by the objective function c. If the schedule is too slow, the convergence rate can be very slow, and if it is too fast, the training might not converge.\nWe therefore propose a different learning scheme, which is inspired by the idea of dropout [12]. Using the regular dropout, one multiplies the output of a network layer element-wise with a randomly generated binary dropout vector. The idea is to disable certain units in the network, which is thus encouraged to make the most important information redundantly available in the network [12, 17], a form of regularization. For our method, we will follow the same principle but use a deterministic and structured dropout vector. More precisely, we employ our binary label matrix L as follows (see also Fig. 1b):\nargmin \u03a5,\u03a6\nc(\u03a6,\u03a5, V, L) = 1\nN N\u2211 n=1 d(f\u03a5(Ln h\u03a6(Vn)), Vn). (3)\nThis simple modification has several advantages. First, similar to batch normalization [13], we can accelerate the training process by supplying the synthesis layers with the conditions we expect the analysis part to deliver once it is fully trained (i.e. the inactive classes are indeed inactive). Further, similar to regular dropout [12], setting some units to zero naturally cuts the error back propagation and channels the entire error information to those network weights in the analysis part that are actually responsible for the active classes in a frame. Overall, training the network using objective (3) in a first step followed by a refinement using objective (2) typically led to a drastic acceleration, in our specific application scenario often reducing the number of iterations by a factor of 1000 (however, we do not claim that this is generally the case). Further, with this two step procedure, we did not require a complicated schedule for \u03bb anymore."}, {"heading": "3. APPLICATION: SCORE-INFORMED SOURCE SEPARATION OF MUSIC SIGNALS", "text": "To demonstrate the capabilities of our proposed approach, we employ it in a specific application scenario. To this end, we assume we are given an audio recording and a MIDI file encoding the uninterpreted score for a piece of music. The note information given by the score provides coarse information when certain instruments and pitches are active. However, the score does not specify exactly when and how notes are played, how they spectrally manifest or what their temporal progression is. The MIDI events can thus be regarded as weak labels in both ways discussed in the introduction, i.e. the temporal information is coarse and target values are uncertain.\nBased on these labels, we could use our proposed method as a basis for a (frame-wise) instrument or pitch detection method. In this case, we would need to train an actual classifier based on our learned representation \u2013 using it either as an improved input or as a temporally more accurate target. However, instead of introducing this added complexity, we chose a task where we can use our autoencoder directly and still demonstrate the induced structure in the representation layer: score-informed source separation [18]. Here, the task is to extract those parts of the recording that correspond to a specified group of notes, for example, all notes associated with a specific instrument or a specific MIDI pitch. Next, we describe how a specific instance of our autoencoder can be used in this context.\nAs a start, we use the recording and compute a short-time Fourier transform (STFT) X \u2208 CM\u00d7N (Hann window of 93ms, stepsize 23ms) and use the frames of its magnitude V \u2208 RM\u00d7N\u22650 as input to our encoder. To keep it simple, we use for both f\u03a5 and h\u03a6 standard multi-layer feed-forward networks with sigmoid activation functions\n(to obtain a reasonable amount of non-linearity), except for the representation and output layer where we use rectified linear activations to enforce non-negativity. For the reconstruction error, we use the generalized Kullback-Leiber divergence, which was found useful in a variety of source separation applications [18]:\nd(a, b) := M\u2211 m=1 am log am + \u03b5 bm + \u03b5 \u2212 am + bm,\nwith some a, b \u2208 RM\u22650 and 0 < \u03b5 1. As in [14], we improve the temporal accuracy of the score information by employing the method described in [19] to temporally align the MIDI file to the given audio recording. This way, we at least roughly know where notes are being played by which instrument and which pitch they roughly have \u2013 all further details, however, are unknown. Next, we associate each combination of instrument and MIDI pitch (corresponding to a class) used in the piece with P \u2265 2 units in our representation layer. Each instrument-pitch class is further subdivided following ideas presented in [14]: In each block of P units, we associate the first unit with the onset of a note being \u2018active\u2019 and the remaining units with the sustain phase being \u2018active\u2019. Using these associations, we can create the label indicator matrix L, see Fig. 2 for an example. More precisely, for each MIDI note we read the start and end time, the instrument-ID and MIDI pitch. Using the instrument and pitch information, we identify the block of P associated units. If unit p in this block is the unit associated with the onset, we set an entry Lp,n = 1 if frame n is in a close vicinity of the start time of the note (for example \u00b10.5sec to account for possible inaccuracies in the MIDI-audio alignment). Similarly, if unit p in this block is associated with the sustain phase, we set an entryLp,n = 1 if frame n corresponds to a time point between the start and end time of the note, subject to a similar temporal tolerance. A simplified example is shown in Fig. 2: three different combinations of instrument and pitch, and with P = 3, we thus have 9 units overall. Using a total of four notes, we can see that the onset units are indicated by a short block of ones around the expected onset, and the remaining units encode the expected note length.\nUsing this L, we train our autoencoder using our proposed objectives (3) and (2), using the audio recording corresponding to the score as input. The actual separation is performed after convergence, where we can exploit the parts-based interpretation for our learned representation. To this end, we choose a group of notes N we aim to keep. Then, we set all entries in L that do not correspond to these notes to zero. Using this LN , the structured dropout will cancel all activity information related to unwanted notes when sending the input through the network. As a consequence we now expect at the output only the part of the magnitude spectrum that corresponds to the notes to be kept. We refer to this modified output as V\u0303N . Finally, we obtain our separation result via soft-masking (or Wiener filtering) V\u0303N\nV\u0303 X ,\nwhere the division is element-wise, and use an inverse STFT to obtain a time-domain signal.\nAs we will see in the next section this basic configuration already yields good separation results. However, we found a few simple tricks to improve the separation quality even further, which might be useful in other contexts as well. First, we observed that while our learned representation typically yields a parts-based representation, the subsequent synthesis function learned without any constraints can weaken this interpretation which then lowers the separation quality. In particular, if entries in the weight matrices used in the feed-forward network f\u03a5 can contain negative entries, the network can eliminate some energy associated with a specific note based on the energy associated with another note. The argument is the same used to compare Independent Component Analysis (ICA) and NMF [20]: the autoencoder is building the output not in a purely constructive way starting from the learned representation. Therefore, analogously to moving from ICA to NMF, we constrain in a variant of our method all weight matrices in \u03a5 to be non-negative. Note, as shown in [21], that this constraint does not lower the network\u2019s theoretical capability to approximate arbitrary functions. As a second extension, we used as input to our analysis network h\u03a6 not only a single frame of V but provided the surrounding frames as well. In this case, we select the center frame of the input as the target for our autoencoder, i.e. the output remains a single frame"}, {"heading": "4. EXPERIMENTS", "text": "To evaluate our method, we conducted a series of experiments following the experimental setup used in [14]. In particular, our task is to separate in piano recordings the notes played by the left hand from those played by the right hand. This task highlights, in contrast to general music source separation, our capability to separate arbitrary groups of notes, even originating from the same instrument. The dataset consists of four Bach pieces (mainly inventions) and six Chopin pieces (mainly preludes and mazurkas) and contains MIDI files from the Mutopia Project1 for each piece. As in [14], we conduct our quantitative experiments using synthetic data. To this end, we first synthesized the downloaded MIDI files using a high-quality, multi-sample wave table synthesizer (Native Instruments) to obtain corresponding audio recordings. Further, we synthesized the notes for the left and right hand separately for each piece, to obtain ground truth separation results. Each recording is 30 to 300 seconds long.\nWe implemented our proposed method in TensorFlow, with three layers for the analysis network h and two layers for the synthesis network f \u2013 more layers lowered the separation quality for variants of our method without non-negativity constrains on the synthesis network weights and did not improve the quality otherwise. Each intermediate layer used 1500 units \u2013 the size of the input, output and representation layers were defined by the input data. As optimizer, we used ADAM, a first-order method offering many features of secondorder approaches, a property often useful in cases where the objective function needs to be minimized with a relatively high accuracy [22]. All parameters were left at their recommended values [22], except for the step size which was decreased to 1/10th of its default. Further, since we trained a new network for each piece, we used full-batch training. The optional non-negativity constraints for the synthesis network were implemented using intermediate projection onto the non-negative orthant. As a proof of concept, we did not use any specific hyperparameter optimization nor regular dropout or batch normalization.\nSeparation quality is assessed using the BSSEVAL toolkit [23]. Note that, in contrast to [14], we here use the Normalized Signal-to-\n1http://www.mutopiaproject.org\nDistortion Ratio (NSDR), where we subtract from the actual SDR value the SDR value we obtain using the full mixture recording as the separation result. The NSDR value represents the gain a method yields over simply using the original mixture and, in contrast to the plain SDR, accounts for energy differences between sound sources which are a major factor influencing the difficulty to obtain a separation.\nFig. 3 shows the results for four methods. As we can see, the NMF baseline [14] already yields a relatively high separation quality of 12.4dB NSDR (method A). Using the same interpretation and dimension of the internal representation as used for NMF (i.e. K), our proposed method (B) without additional extensions yields results on a similar level but remains below the result for NMF. However, if we add the non-negativity constraints on the weight matrices for the synthesis network (method C), the differences switch and our proposed method improves upon the NMF baseline by 0.4dB. These results might indicate that the pure parts-based representation might indeed be an important factor for this application. Further, in comparison to the linear NMF model, the additional layers and non-linear sigmoids might enable the autoencoder to obtain a more meaningful learned representation. Finally, in a last modification we used several consecutive frames as input to our autoencoder. This extension improved the results again by a small margin of 0.15 db NSDR, leading to an overall improvement of 0.55dB NSDR."}, {"heading": "5. CONCLUSIONS", "text": "We presented a method for learning using weakly labeled data based on neural networks. Existing methods had previously tried to extend supervised learning methods to account for the often strong uncertainty in the labels. However, since these approaches typically only enhance the treatment of labels or classes for which the network already yields clear results, the impact on the learning process can be limited. As an alternative, we proposed treating the problem fundamentally as an unsupervised learning problem, i.e. starting without labels, and then only induce some structure in the resulting learned data representations based on the weak labels. To this end, we introduced an activity cost term, which enabled us to train an autoencoder and express our uncertainty about the target value of a weak label. To accelerate the training process, we additionally proposed a structured variant of dropout, where, compared to the regular dropout, labels are used to enforce a specific structure in the network early on during training. Our experiments based on score-informed source separation showed that indeed our proposed method can be used to induce structure in data representations learned via autoencoders. In the future, we plan to employ our proposed method in a variety of tasks, either as a pre-processing step to provide a semantically more meaningful input representation for actual classifiers or as a training target, enhancing the label accuracy of the weak labels."}, {"heading": "6. REFERENCES", "text": "[1] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton, \u201cDeep learning,\u201d Nature, vol. 521, no. 7553, pp. 436\u2013444, 2015.\n[2] Geoffrey E Hinton, Simon Osindero, and Yee-Whye Teh, \u201cA fast learning algorithm for deep belief nets,\u201d Neural Computation, vol. 18, no. 7, pp. 1527\u20131554, 2006.\n[3] James D Keeler, David E Rumelhart, and Wee-Kheng Leow, \u201cIntegrated segmentation and recognition of hand-printed numerals,\u201d in Advances in Neural Information Processing Systems (NIPS), 1990, p. 557563.\n[4] James Foulds and Eibe Frank, \u201cA review of multi-instance learning assumptions,\u201d The Knowledge Engineering Review, vol. 25, no. 01, pp. 1\u201325, 2010.\n[5] Stuart Andrews, Ioannis Tsochantaridis, and Thomas Hofmann, \u201cSupport vector machines for multiple-instance learning,\u201d in Advances in Neural Information Processing Systems (NIPS), 2002, pp. 561\u2013568.\n[6] Yixin Chen, Jinbo Bi, and James Ze Wang, \u201cMILES: Multipleinstance learning via embedded instance selection,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 28, no. 12, pp. 1931\u20131947, 2006.\n[7] Le Hou, Dimitris Samaras, Tahsin M Kurc, Yi Gao, James E Davis, and Joel H Saltz, \u201cPatch-based convolutional neural network for whole slide tissue image classification,\u201d arXiv preprint 1504.07947, 2015.\n[8] Michael I Mandel and Daniel PW Ellis, \u201cMultiple-instance learning for music information retrieval,\u201d in Proceedings of the International Society for Music Information Retrieval Conference (ISMIR), 2008, pp. 577\u2013582.\n[9] Zhi-Hua Zhou and Min-Ling Zhang, \u201cNeural networks for multi-instance learning,\u201d in Proceedings of the International Conference on Intelligent Information Technology (ICIIT), 2002, pp. 455\u2013459.\n[10] Jan Schlu\u0308ter, \u201cLearning to pinpoint singing voice from weakly labeled examples,\u201d in Proceedings of the International Society for Music Information Retrieval Conference (ISMIR), 2016, pp. 44\u201350.\n[11] Geoffrey E Hinton and Ruslan R Salakhutdinov, \u201cReducing the dimensionality of data with neural networks,\u201d Science, vol. 313, no. 5786, pp. 504\u2013507, 2006.\n[12] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov, \u201cDropout: a simple way to prevent neural networks from overfitting,\u201d Journal of Machine Learning Research, vol. 15, no. 1, pp. 1929\u20131958, 2014.\n[13] Sergey Ioffe and Christian Szegedy, \u201cBatch normalization: Accelerating deep network training by reducing internal covariate shift,\u201d arXiv preprint arXiv:1502.03167, 2015.\n[14] Sebastian Ewert and Meinard Mu\u0308ller, \u201cUsing score-informed constraints for NMF-based source separation,\u201d in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), Kyoto, Japan, 2012, pp. 129\u2013132.\n[15] Stanislaw Andrzej Raczynski, Nobutaka Ono, and Shigeki Sagayama, \u201cMultipitch analysis with harmonic nonnegative matrix approximation,\u201d in Proceedings of the International Conference on Music Information Retrieval (ISMIR), Vienna, Austria, 2007, pp. 381\u2013386.\n[16] Dan Stowell and Richard E Turner, \u201cDenoising without access to clean data using a partitioned autoencoder,\u201d arXiv preprint arXiv:1509.05982, 2015.\n[17] Stefan Wager, Sida Wang, and Percy S Liang, \u201cDropout training as adaptive regularization,\u201d in Advances in Neural Information Processing Systems (NIPS), 2013, pp. 351\u2013359.\n[18] Sebastian Ewert, Bryan Pardo, Meinard Mu\u0308ller, and Mark D. Plumbley, \u201cScore-informed source separation for musical audio recordings: An overview,\u201d IEEE Signal Processing Magazine, vol. 31, no. 3, pp. 116\u2013124, May 2014.\n[19] Sebastian Ewert, Meinard Mu\u0308ller, and Peter Grosche, \u201cHigh resolution audio synchronization using chroma onset features,\u201d in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), Taipei, Taiwan, 2009, pp. 1869\u20131872.\n[20] Daniel D. Lee and H. Sebastian Seung, \u201cLearning the parts of objects by non-negative matrix factorization,\u201d Nature, vol. 401, no. 6755, pp. 788\u2013791, 1999.\n[21] Jan Chorowski and Jacek M Zurada, \u201cLearning understandable neural networks with nonnegative weight constraints,\u201d IEEE Transactions on Neural Networks and Learning Systems, vol. 26, no. 1, pp. 62\u201369, 2015.\n[22] Diederik Kingma and Jimmy Ba, \u201cAdam: A method for stochastic optimization,\u201d in Proceedings of the International Conference for Learning Representations (arXiv preprint arXiv:1412.6980), 2015.\n[23] Emmanuel Vincent, Re\u0301mi Gribonval, and Ce\u0301dric Fe\u0301votte, \u201cPerformance measurement in blind audio source separation,\u201d IEEE Transactions on Audio, Speech, and Language Processing, vol. 14, no. 4, pp. 1462\u20131469, 2006."}], "references": [{"title": "Deep learning", "author": ["Yann LeCun", "Yoshua Bengio", "Geoffrey Hinton"], "venue": "Nature, vol. 521, no. 7553, pp. 436\u2013444, 2015.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "A fast learning algorithm for deep belief nets", "author": ["Geoffrey E Hinton", "Simon Osindero", "Yee-Whye Teh"], "venue": "Neural Computation, vol. 18, no. 7, pp. 1527\u20131554, 2006.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2006}, {"title": "Integrated segmentation and recognition of hand-printed numerals", "author": ["James D Keeler", "David E Rumelhart", "Wee-Kheng Leow"], "venue": "Advances in Neural Information Processing Systems (NIPS), 1990, p. 557563.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1990}, {"title": "A review of multi-instance learning assumptions", "author": ["James Foulds", "Eibe Frank"], "venue": "The Knowledge Engineering Review, vol. 25, no. 01, pp. 1\u201325, 2010.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Support vector machines for multiple-instance learning", "author": ["Stuart Andrews", "Ioannis Tsochantaridis", "Thomas Hofmann"], "venue": "Advances in Neural Information Processing Systems (NIPS), 2002, pp. 561\u2013568.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2002}, {"title": "MILES: Multipleinstance learning via embedded instance selection", "author": ["Yixin Chen", "Jinbo Bi", "James Ze Wang"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 28, no. 12, pp. 1931\u20131947, 2006.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1931}, {"title": "Patch-based convolutional neural network for whole slide tissue image classification", "author": ["Le Hou", "Dimitris Samaras", "Tahsin M Kurc", "Yi Gao", "James E Davis", "Joel H Saltz"], "venue": "arXiv preprint 1504.07947, 2015.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Multiple-instance learning for music information retrieval", "author": ["Michael I Mandel", "Daniel PW Ellis"], "venue": "Proceedings of the International Society for Music Information Retrieval Conference (ISMIR), 2008, pp. 577\u2013582.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2008}, {"title": "Neural networks for multi-instance learning", "author": ["Zhi-Hua Zhou", "Min-Ling Zhang"], "venue": "Proceedings of the International Conference on Intelligent Information Technology (ICIIT), 2002, pp. 455\u2013459.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2002}, {"title": "Learning to pinpoint singing voice from weakly labeled examples", "author": ["Jan Schl\u00fcter"], "venue": "Proceedings of the International Society for Music Information Retrieval Conference (ISMIR), 2016, pp. 44\u201350.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2016}, {"title": "Reducing the dimensionality of data with neural networks", "author": ["Geoffrey E Hinton", "Ruslan R Salakhutdinov"], "venue": "Science, vol. 313, no. 5786, pp. 504\u2013507, 2006.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2006}, {"title": "Dropout: a simple way to prevent neural networks from overfitting", "author": ["Nitish Srivastava", "Geoffrey E Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov"], "venue": "Journal of Machine Learning Research, vol. 15, no. 1, pp. 1929\u20131958, 2014.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1929}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["Sergey Ioffe", "Christian Szegedy"], "venue": "arXiv preprint arXiv:1502.03167, 2015.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Using score-informed constraints for NMF-based source separation", "author": ["Sebastian Ewert", "Meinard M\u00fcller"], "venue": "Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), Kyoto, Japan, 2012, pp. 129\u2013132.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "Multipitch analysis with harmonic nonnegative matrix approximation", "author": ["Stanislaw Andrzej Raczynski", "Nobutaka Ono", "Shigeki Sagayama"], "venue": "Proceedings of the International Conference on Music Information Retrieval (ISMIR), Vienna, Austria, 2007, pp. 381\u2013386.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2007}, {"title": "Denoising without access to clean data using a partitioned autoencoder", "author": ["Dan Stowell", "Richard E Turner"], "venue": "arXiv preprint arXiv:1509.05982, 2015.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Dropout training as adaptive regularization", "author": ["Stefan Wager", "Sida Wang", "Percy S Liang"], "venue": "Advances in Neural Information Processing Systems (NIPS), 2013, pp. 351\u2013359.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Score-informed source separation for musical audio recordings: An overview", "author": ["Sebastian Ewert", "Bryan Pardo", "Meinard M\u00fcller", "Mark D. Plumbley"], "venue": "IEEE Signal Processing Magazine, vol. 31, no. 3, pp. 116\u2013124, May 2014.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "High resolution audio synchronization using chroma onset features", "author": ["Sebastian Ewert", "Meinard M\u00fcller", "Peter Grosche"], "venue": "Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), Taipei, Taiwan, 2009, pp. 1869\u20131872.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning the parts of objects by non-negative matrix factorization", "author": ["Daniel D. Lee", "H. Sebastian Seung"], "venue": "Nature, vol. 401, no. 6755, pp. 788\u2013791, 1999.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1999}, {"title": "Learning understandable neural networks with nonnegative weight constraints", "author": ["Jan Chorowski", "Jacek M Zurada"], "venue": "IEEE Transactions on Neural Networks and Learning Systems, vol. 26, no. 1, pp. 62\u201369, 2015.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba"], "venue": "Proceedings of the International Conference for Learning Representations (arXiv preprint arXiv:1412.6980), 2015.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "Performance measurement in blind audio source separation", "author": ["Emmanuel Vincent", "R\u00e9mi Gribonval", "C\u00e9dric F\u00e9votte"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 14, no. 4, pp. 1462\u20131469, 2006.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [{"referenceID": 0, "context": "Training neural networks is often a complex endeavor, which is somewhat simplified if clear labels are available in a supervised learning scenario [1].", "startOffset": 147, "endOffset": 150}, {"referenceID": 1, "context": "Annotating data, however, is typically an expensive process and hence there is increasing interest in using unlabeled data to support learning using smaller labeled dataset (semi-supervised learning) [2].", "startOffset": 200, "endOffset": 203}, {"referenceID": 2, "context": "Settings based on this type of weak labels are often referred to as multiple-instance learning, as one label provides spatially or temporally coarse information for a bag of instances [3].", "startOffset": 184, "endOffset": 187}, {"referenceID": 3, "context": "For learning, however, weak labels present considerable challenges [4].", "startOffset": 67, "endOffset": 70}, {"referenceID": 4, "context": "Multiple-instance learning methods try to improve on this concept by iteratively relabeling instances as negative examples in a block [5] or pruning", "startOffset": 134, "endOffset": 137}, {"referenceID": 5, "context": "them [6, 7] if they are not clearly detected as positive after an initial naive training step, see also [8] for a comparison.", "startOffset": 5, "endOffset": 11}, {"referenceID": 6, "context": "them [6, 7] if they are not clearly detected as positive after an initial naive training step, see also [8] for a comparison.", "startOffset": 5, "endOffset": 11}, {"referenceID": 7, "context": "them [6, 7] if they are not clearly detected as positive after an initial naive training step, see also [8] for a comparison.", "startOffset": 104, "endOffset": 107}, {"referenceID": 8, "context": "Alternatively, one can learn using only the frame which yielded the clearest positive response in a block [9].", "startOffset": 106, "endOffset": 109}, {"referenceID": 9, "context": "As a special case, one can use so called saliency maps to improve the temporal accuracy for networks with multi-frame inputs [10].", "startOffset": 125, "endOffset": 129}, {"referenceID": 9, "context": "However, often such approaches are not effective [10], as re-labeling/pruning methods only re-interpret examples that are already correctly classified by the network (limiting the gain in information for the learning process), while highest-saliency learning ignores a considerable amount of annotated data that could be potentially useful for training.", "startOffset": 49, "endOffset": 53}, {"referenceID": 10, "context": "More precisely, we start from the standard autoencoder architecture [11], where one network transforms the input to a low-dimensional representation, which is then used to re-synthesize the input \u2013 differences between the input and output are measured using a reconstruction error term.", "startOffset": 68, "endOffset": 72}, {"referenceID": 11, "context": "First, it is a variant of the well-known stochastic dropout technique for regularization [12], just that our dropout is deterministic and induces structure instead of noise.", "startOffset": 89, "endOffset": 93}, {"referenceID": 12, "context": "Second, the decoder part of the network can operate early during training under conditions it will find once the network is fully trained, resembling properties of batch-normalization [13].", "startOffset": 184, "endOffset": 188}, {"referenceID": 13, "context": "As a further interpretation, this procedure can be seen as a nonlinear extension of non-negative matrix factorization (NMF) in combination with certain activity constraints [14].", "startOffset": 173, "endOffset": 177}, {"referenceID": 13, "context": "Therefore, we motivate our procedure starting from the well-known NMF and demonstrate the capabilities of our method using a task previously addressed with NMF: Score-informed source separation of music signals [14].", "startOffset": 211, "endOffset": 215}, {"referenceID": 14, "context": "to express that class k will be inactive in input n, we can set Hk,n to zero \u2013 using multiplicative rules to iteratively updateW andH as usually done, these constraints will remain active throughout the learning process [15].", "startOffset": 220, "endOffset": 224}, {"referenceID": 10, "context": "We obtain V \u2248WWV , which is an autoencoder with linear activation functions and some non-negativity constraints on its weight matrices [11].", "startOffset": 135, "endOffset": 139}, {"referenceID": 10, "context": "learning has been found useful in a variety of tasks \u2013 however, the resulting low dimensional representation usually cannot easily be interpreted, in particular if f and h represent deep networks [11].", "startOffset": 196, "endOffset": 200}, {"referenceID": 15, "context": "This approach generalizes ideas used in [16], which used a single class: noise or no-noise.", "startOffset": 40, "endOffset": 44}, {"referenceID": 11, "context": "We therefore propose a different learning scheme, which is inspired by the idea of dropout [12].", "startOffset": 91, "endOffset": 95}, {"referenceID": 11, "context": "The idea is to disable certain units in the network, which is thus encouraged to make the most important information redundantly available in the network [12, 17], a form of regularization.", "startOffset": 154, "endOffset": 162}, {"referenceID": 16, "context": "The idea is to disable certain units in the network, which is thus encouraged to make the most important information redundantly available in the network [12, 17], a form of regularization.", "startOffset": 154, "endOffset": 162}, {"referenceID": 12, "context": "First, similar to batch normalization [13], we can accelerate the training process by supplying the synthesis layers with the conditions we expect the analysis part to deliver once it is fully trained (i.", "startOffset": 38, "endOffset": 42}, {"referenceID": 11, "context": "Further, similar to regular dropout [12], setting some units to zero naturally cuts the error back propagation and channels the entire error information to those network weights in the analysis part that are actually responsible for the active classes in a frame.", "startOffset": 36, "endOffset": 40}, {"referenceID": 17, "context": "However, instead of introducing this added complexity, we chose a task where we can use our autoencoder directly and still demonstrate the induced structure in the representation layer: score-informed source separation [18].", "startOffset": 219, "endOffset": 223}, {"referenceID": 17, "context": "For the reconstruction error, we use the generalized Kullback-Leiber divergence, which was found useful in a variety of source separation applications [18]:", "startOffset": 151, "endOffset": 155}, {"referenceID": 13, "context": "As in [14], we improve the temporal accuracy of the score information by employing the method described in [19] to temporally align the MIDI file to the given audio recording.", "startOffset": 6, "endOffset": 10}, {"referenceID": 18, "context": "As in [14], we improve the temporal accuracy of the score information by employing the method described in [19] to temporally align the MIDI file to the given audio recording.", "startOffset": 107, "endOffset": 111}, {"referenceID": 13, "context": "Each instrument-pitch class is further subdivided following ideas presented in [14]: In each block of P units, we associate the first unit with the onset of a note being \u2018active\u2019 and the remaining units with the sustain phase being \u2018active\u2019.", "startOffset": 79, "endOffset": 83}, {"referenceID": 19, "context": "The argument is the same used to compare Independent Component Analysis (ICA) and NMF [20]: the autoencoder is building the output not in a purely constructive way starting from the learned representation.", "startOffset": 86, "endOffset": 90}, {"referenceID": 20, "context": "Note, as shown in [21], that this constraint does not lower the network\u2019s theoretical capability to approximate arbitrary functions.", "startOffset": 18, "endOffset": 22}, {"referenceID": 13, "context": "To evaluate our method, we conducted a series of experiments following the experimental setup used in [14].", "startOffset": 102, "endOffset": 106}, {"referenceID": 13, "context": "As in [14], we conduct our quantitative experiments using synthetic data.", "startOffset": 6, "endOffset": 10}, {"referenceID": 21, "context": "As optimizer, we used ADAM, a first-order method offering many features of secondorder approaches, a property often useful in cases where the objective function needs to be minimized with a relatively high accuracy [22].", "startOffset": 215, "endOffset": 219}, {"referenceID": 21, "context": "All parameters were left at their recommended values [22], except for the step size which was decreased to 1/10th of its default.", "startOffset": 53, "endOffset": 57}, {"referenceID": 22, "context": "Separation quality is assessed using the BSSEVAL toolkit [23].", "startOffset": 57, "endOffset": 61}, {"referenceID": 13, "context": "Note that, in contrast to [14], we here use the Normalized Signal-to-", "startOffset": 26, "endOffset": 30}, {"referenceID": 13, "context": "(A): NMF baseline [14].", "startOffset": 18, "endOffset": 22}, {"referenceID": 13, "context": "As we can see, the NMF baseline [14] already yields a relatively high separation quality of 12.", "startOffset": 32, "endOffset": 36}], "year": 2016, "abstractText": "Many success stories involving deep neural networks are instances of supervised learning, where available labels power gradient-based learning methods. Creating such labels, however, can be expensive and thus there is increasing interest in weak labels which only provide coarse information, with uncertainty regarding time, location or value. Using such labels often leads to considerable challenges for the learning process. Current methods for weak-label training often employ standard supervised approaches that additionally reassign or prune labels during the learning process. The information gain, however, is often limited as only the importance of labels where the network already yields reasonable results is boosted. We propose treating weak-label training as an unsupervised problem and use the labels to guide the representation learning to induce structure. To this end, we propose two autoencoder extensions: class activity penalties and structured dropout. We demonstrate the capabilities of our approach in the context of score-informed source separation of music.", "creator": "LaTeX with hyperref package"}}}