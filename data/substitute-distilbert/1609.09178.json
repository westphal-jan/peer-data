{"id": "1609.09178", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Sep-2016", "title": "OPML: A One-Pass Closed-Form Solution for Online Metric Learning", "abstract": "to achieve a reducing computational cost when performing online sparse learning for large - scale data, we present a one - pass closed - form solution namely validation in this paper. typically, the proposed opml first applied synchronized one - pass triplet construction strategy, which aims to use only a weakly small number of triplets to approximate the representation ability of whole original triplets obtained by batch - manner methods. then, opml employs continuous closed - form requirement to update the metric for new coming samples, which leads to a low space ( i. e., $ o ( d ) $ ) computation time ( ie. e., $ o ( d ^ 2 ) $ ) complexity, where $ d $ is the feature dimensionality. in addition, an extension of opml ( namely copml ) is increasingly proposed to enhance the robustness when in real case the first several samples come from at same class ( c. e., null start samples ). from the experiments, laboratories have systematically evaluated our methods ( op and copml ) : three typical tasks, including uci data classification, face verification, achieving abnormal event detection in videos, basically aims to fully use the proposed methods on different sample composition, different feature factors and different feature specification ways ( i. e., hand - crafted and deeply - learned ). the results show true opml and copml can obtain the promising performance with a very low computational cost. first, the versa. copml under the cold stopping setting is experimentally verified.", "histories": [["v1", "Thu, 29 Sep 2016 02:18:06 GMT  (8057kb)", "http://arxiv.org/abs/1609.09178v1", "12 pages"]], "COMMENTS": "12 pages", "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["wenbin li", "yang gao", "lei wang", "luping zhou", "jing huo", "yinghuan shi"], "accepted": false, "id": "1609.09178"}, "pdf": {"name": "1609.09178.pdf", "metadata": {"source": "CRF", "title": "OPML: A One-Pass Closed-Form Solution for Online Metric Learning", "authors": ["Wenbin Li", "Yang Gao", "Lei Wang", "Luping Zhou", "Jing Huo", "Yinghuan Shi"], "emails": ["liwenbin.nju@gmail.com", "gaoy@nju.edu.cn", "leiw@uow.edu.au", "lupingz@uow.edu.au", "huojing1989@gmail.com", "syh@nju.edu.cn"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 9.\n09 17\n8v 1\n[ cs\n.L G\n] 2\n9 Se\np 20\nIndex Terms\u2014One-pass, Online metric learning, Triplet construction, Face verification, Abnormal event detection.\nI. INTRODUCTION\nIN computer vision and machine learning, learning a mean-ingful distance/similarity metric on the original feature presentation of samples, with the given distance constraints (either pairwise similar/dissimilar distance constraints or triplet based relative distance constraints) at the same time, is usually regarded as a crucial and challenging problem, which has been actively studied over the decades. According to the different measure functions (e.g., Mahalanobis distance function and bilinear similarity function), the current metric learning methods can be roughly classified into two categories, i.e., Mahalanobis distance-based methods and bilinear similarity-based methods. The first class, Mahalanobis distance-based methods, refers to learning a pairwise real-valued distance function, which is parameterized by a symmetric Positive Semi-Definite (PSD) matrix. The second class, bilinear similarity-based methods, aims to learn a form of bilinear similarity function which does not need to impose the PSD constraint on learned metrics.\nEmail addresses: liwenbin.nju@gmail.com (Wenbin Li), gaoy@nju.edu.cn (Yang Gao), leiw@uow.edu.au (Lei Wang), lupingz@uow.edu.au (Luping Zhou), huojing1989@gmail.com (Jing Huo), syh@nju.edu.cn (Yinghuan Shi).\nRecently, instead of batch manner, learning the metric in an online manner, which refers to online metric learning (OML), has attracted lots of interests, with the goal of learning a discriminative metric with partially known sampled data for efficiently dealing with large-scale learning problem. Generally, to satisfy the online processing speed for large-scale learning problem, OML methods are required to well tackle the following two core issues: (1) how to fast construct the triplet (or pair) in the original data, especially for the largescale data, and (2) how to fast update the metric with the new coming samples in a real time manner.\nFor fast triplet (or pair) construction (first issue), existing OML methods usually assume that pairwise or triplet constraints can be obtained in advance [1], or by employing the random sampling strategy to reduce the size of triplets [2]. However, in real applications, it is usually infeasible to access the entire training set at a time, especially when the training set is relative large, constructing the constraints will be both timeand space-consuming. To this end, we propose a novel onepass triplet construction strategy to rapidly construct triplets in an online manner. In particular, the strategy selects two latest samples from both the same and different classes of currently available samples respectively, to construct a triplet. Compared with Online Algorithm for Scalable Image Similarity (OASIS) [2], which utilizes a random sampling strategy and stores the entire training data in memory with space complexity of O(md) (d is the feature dimensionality, and m is the data size, which is very large for large-scale data), our one-pass strategy can vastly reduce the space complexity to O(cd) (c is the total number of classes, which is usually small). Also, the time complexity of our triplet construction strategy is O(1), which is truly fast.\nFor fast metric updating (second issue), several studies [2], [3] try to adopt a closed-form solution for accurate computation. Among them, OASIS adopts bilinear similarity learning and has a closed-form solution, while it lacks a good interpretability as Mahalanobis distance metric learning (i.e., linear projection) and the learned similarity function is asymmetric. In contrast, LogDet Exact Gradient Online (LEGO) [3] attempts to learn a Mahalanobis distance and has a closedform solution. In addition, LEGO is not required to maintain the PSD constraint by using LogDet regularization, which is time-consuming in some Mahalanobis distance metric learning methods [1], [4], [5]. However, LEGO is designed for pairwise constraints. Compared with LEGO, we developed a different\n2\nMahalanobis distance-based OML method for triplet-based constraints, named as OPML, which also has the property of closed-form solution and does not need projection steps to maintain PSD constraint. Specifically, the proposed OPML directly learns the transformation matrix L (M = LTL is the symmetric PSD matrix usually learnt in Mahalanobis metric learning), such a setting does not require imposing the PSD constraint. By carefully analysing the structure of the triplets based loss and using a few fundamental properties (Lemma 2, Lemma 3), a closed-form solution at each step is obtained with the time complexity of O(d2). The major differences between OPML and OASIS/LEGO can be found in Table I.\nAlso, in some tasks, e.g., abnormal event detection in videos, the data is usually imbalanced: the first several samples may belong to the same class, then the triplet construction strategy will be invalid until the samples of different classes appear. We call this case as cold start case. Furthermore, to deal with the cold start issue, an extension namely COPML is developed in this paper. Specifically, COPML includes a prestage by constructing pairwise constraints for two adjacent samples (from the same class) to update the metric.\nTo summarize, compared with previous OML methods, the advantages of our work can be concluded as: First, the proposed OPML and COPML are easy to implement. Second, OPML and COPML are scalable to large datasets with a low space (i.e., O(d)) and time (i.e., O(d2)) complexity, where d is the feature dimensionality. Third, we have derived several theoretical explanations, including the difference bound between learned metrics of ones-pass and batch triplet construction strategies, the average loss bound between these two strategies and the regret bound, to guarantee the effectiveness of our methods.\nThe rest of this paper is organized as follows. In section II, we present the related works of OML methods. Section III provides the details of the proposed one-pass triplet construction strategy, OPML and COPML algorithms. In section IV, we give the theoretical guarantee of our algorithm. The experimental results, comparisons and analysis are given in section V, followed by conclusions in section VI."}, {"heading": "II. RELATED WORK", "text": "Typically, all the previous online metric learning methods can be roughly classified into two categories: bilinear\nsimilarity-based and Mahalanobis distance-based. A comparison of the most related works is given in Table I for better clarification.\nIn bilinear similarity-based methods, OASIS [2] is developed which is based on Passive-Aggressive algorithm [6], aiming to learn a similarity metric for image similarity. Sparse Online Metric Learning (SOML) [7] follows a similar setting as OASIS, but learns a diagonal matrix instead of a full matrix to handle very high-dimensional cases. In order to deal with multi-modal data, an online kernel based method, namely Online Multiple Kernel Similarity (OMKS), has been proposed by Xia et al. [8]. All these above methods are based on triplet constraints and they also assume that the constraints can be gained beforehand or could be randomly sampled on the entire dataset. Among them, OASIS is more relevant to the proposed OPML as both of them are Passive-Aggressive based. The differences between OASIS and the proposed OPML mainly include that OASIS learns a bilinear similarity metric (hard to interpret, and asymmetric) while OPML learns a Mahalanobis metric (good interpretability, and symmetric), OASIS randomly samples triplet constraints from the entire training set (with space complexity of O(md)), while OPML constructs triplet constraints in an online manner (with space complexity of O(cd) and time complexity of O(1)), which leads the solutions of objective functions largely different.\nIn Mahalanobis distance-based methods, Pseudo-Metric Online Learning Algorithm (POLA) [1] is the first OML method which introduces the successive projection operation to learn the optimal metric. LEGO [3] is an extended version of Information Theoretic Metric Learning-Online (ITML-Online) [5], by building the model with LogDet divergence regularization. Jin et al. [4] presented a regularized OML method namely RDML, with a provable regret bound. Also, Kunapuli and Shavlik proposed an unified approach based on composite mirror descent named as MDML [9]. These methods are all based on pairwise constraints, and they all assume that the pairwise constraints can be obtained in advance except RDML, which exactly receives two adjacent samples as a pairwise constraints at each time. In fact, pairwise constraints based methods can be easily converted to an online manner for pair construction by using the strategy of RDML. However, in general, triplet constraints are more effective than pairwise constraints for learning a metric [10], [2], [11], [12]. In contrast, the proposed OPML is a triplet constraints based Mahalanobis distance method. Besides, the proposed method has the properties of closed-form solution and does not enquire PSD constraint, making it more efficient."}, {"heading": "III. THE PROPOSED METHOD", "text": "We now first present our strategy for one-pass triplet construction, and then discuss the technical details of OPML and COPML, respectively."}, {"heading": "A. One-Pass Triplet Construction", "text": "When dealing with large-scale data, how to fast obtain the triplets is a crucial step, since the number of triplets usually determines the tradeoff between the performance effectiveness\n3 ... Class 1 Class 2 Class 3\nTime\nFig. 1. The illustration of one-pass triplet construction. x1,x2, . . . ,xt denote the samples at the 1-th, 2-th and t-th time steps, respectively\nand time efficiency. Inspired by the impressive scalability of one-pass strategies [13], [14], [15], we proposed a one-pass triplet construction strategy, aiming to quickly obtain all the triplets in a single pass over all data. Fig. 1 illustrates the main idea of the one-pass strategy of triplet construction. Formally, in an online manner, the sample at the t-th (t = 1, 2, . . . , T ) step is denoted as xt \u2208 Rd. An array H = {h1, h2, . . . , hc} is maintained, where c is the total number of classes, and hk \u2208 Rd (k = 1, 2, . . . , c) means the latest sample of the k-th class at the t-th time step.\nFor triplet construction, our goal is to obtain a typical triplet \u3008xt,xp,xq\u3009 (xt,xp and xq \u2208 Rd), which satisfies that xt and xp belong to the same class, while xt and xq belong to the different classes. Specifically, in one-pass triplet construction, at the t-th time step, given xt belonging to the k-th class, we assign hk as xp, and randomly pick hk \u2032 (k\u2032 = 1, 2, . . . , c., k\u2032 6= k) as xq. Then hk \u2208 H will be replaced by xt, and thus H consists of the latest sample of each class. Please note that if xt belongs to the (c + 1)-th class, we will assign xt to hc+1, and also update the number of classes as well as H accordingly.\nWe can observe that the space complexity of this strategy is O(cd). Basically, when the value of c is small, the space complexity can be regarded as O(d). Also, the time complexity of triplet construction at each time step is O(1)."}, {"heading": "B. OPML", "text": "We mainly focus on the Mahalanobis distance learning here, which aims to learn a symmetric PSD matrix M \u2208 Sd\u00d7d+ (cone of d\u00d7 d real-valued symmetric PSD matrices) and can be formally defined as follows:\nDM (xi,xj) = \u221a (xi \u2212 xj)\u22a4M(xi \u2212 xj), (1)\nwhere xi \u2208 Rd and xj \u2208 Rd are the i-th and j-th samples, respectively. M can be mathematically decomposed as L\u22a4L, where L \u2208 Rr\u00d7d (r is the rank of M ) denotes the transformation matrix. Then, we can rewrite Eq. (1) as:\nDL(xi,xj) = \u2016L(xi \u2212 xj)\u201622. (2)\nOur goal is to learn a transformation matrix L that satisfies the following large margin constraint:\nDL(xi,xl) > DL(xi,xj) + 1, \u2200xi,xj ,xl \u2208 Rd, (3)\nwhere xi and xj belong to the same class, while xi and xl belong to different classes. We can define the hinge loss function as below:\nG((xi,xj ,xl);L) = max ( 0, 1 +DL(xi,xj)\u2212DL(xi,xl) ) .\n(4) By applying the one-pass triplet construction, at the t-th time step, we can obtain the triplet \u3008xt,xp,xq\u3009. Thus, the online optimization formulation can be defined as follows by using Passive-Aggressive algorithm [6]:\nLt = argmin L \u0393(L)\n= argmin L\n1 2 \u2016L\u2212Lt\u22121\u20162F + \u03b3 2 [1 + \u2016L(xt \u2212 xp)\u201622\n\u2212 \u2016L(xt \u2212 xq)\u201622]+,\n(5)\nwhere \u03b3 is the regularization parameter, which is set into the range of (0, 14 ) as a sufficient condition to theoretically guarantee the positive definite property (see Lemma 2). \u2016\u00b7\u20162F means Frobenius norm, \u2016\u00b7\u20162 denotes \u21132\u2212norm, and [z]+ = max(0, z), namely the hinge loss G((xt,xp,xq);L).\nThe optimal solution can be obtained when the gradient vanishes \u2202\u0393(L)\n\u2202L = 0, hence we have:\n\u2202\u0393(L)\n\u2202L =\n\n\n\nL\u2212Lt\u22121 + \u03b3LAt = 0 [z]+ > 0 L\u2212Lt\u22121 = 0 [z]+ = 0, (6)\nwhere At = (xt \u2212 xp)(xt \u2212 xp)\u22a4 \u2212 (xt \u2212 xq)(xt \u2212 xq)\u22a4 \u2208 R\nd\u00d7d. Since xt,xp and xq are all nonzero vectors, xt 6= xp and xt 6= xq , the rank of (xt \u2212 xp)(xt \u2212 xp)\u22a4 and (xt \u2212 xq)(xt \u2212 xq)\u22a4 is 1. Hence, the rank of At is 1 or 2. When xt \u2212 xp 6= \u00b5(xt \u2212 xq), we can get that rank(At) = 2. Lemma 1. Let M1,M2 be two PSD matrices, and \u2126 = M1 \u2212 M2, the eigenvalue of \u2126, denoted by \u03bb(\u2126), satisfies the following equation:\n\u2212 \u03bbmax(M2) \u2264 \u03bb(\u2126) \u2264 \u03bbmax(M1), (7)\nwhere \u03bbmax(M1) and \u03bbmax(M2) are the maximum eigenvalues of M1 and M2, respectively.\nProof. \u2200x \u2208 Rd and x 6= 0, x\u22a4\u2126x = x\u22a4(M1 \u2212 M2)x. Since M1 and M2 are both PSD matrices, x\u22a4M1x \u2265 0 and x\u22a4M2x \u2265 0. Thus,\n\u2212 x \u22a4M2x x\u22a4x \u2264 x \u22a4 \u2126x x\u22a4x \u2264 x \u22a4M1x x\u22a4x . (8)\nAccording to Rayleigh quotient, we have \u03bbmin(\u2126) \u2264 x \u22a4 \u2126x x\u22a4x \u2264 \u03bbmax(\u2126). Assume x \u22a4 \u2126x\nx\u22a4x achieve its maximum \u03bbmax(\u2126) when\nx = e, i.e., e \u22a4 \u2126e\ne\u22a4e = \u03bbmax(\u2126). By Eq. (8), we obtain\n\u03bbmax(\u2126) = e\u22a4\u2126e e\u22a4e \u2264 e \u22a4M1e e\u22a4e \u2264 \u03bbmax(M1) (9)\nHence, \u03bbmax(\u2126) \u2264 \u03bbmax(M1). In the similar way, we can prove that \u2212\u03bbmax(M2) \u2264 \u03bbmin(\u2126). Thus,\n\u2212 \u03bbmax(M2) \u2264 \u03bbmin(\u2126) \u2264 \u03bb(\u2126) \u2264 \u03bbmax(\u2126) \u2264 \u03bbmax(M1). (10)\n4 Lemma 2. If 0 < \u03b3 < 14 and samples are normalized, I+\u03b3At is a positive definite matrix and also it is invertible, where I \u2208 Rd\u00d7d is the identity matrix. Proof. Let M1 = (xt \u2212 xp)(xt \u2212 xp)\u22a4, M2 = (xt \u2212 xq)(xt \u2212 xq)\u22a4 and At = M1 \u2212 M2. It is easy to obtain that, \u03bbmax(M1) = \u2016xt \u2212 xp\u201622 and \u03bbmax(M2) = \u2016xt \u2212 xq\u201622. According to Lemma 1, we can obtain that \u2212\u03bbmax(M2) \u2264 \u03bb(At) \u2264 \u03bbmax(M1). Thus,\n1\u2212 \u03b3\u03bbmax(M2) \u2264 \u03bb(I + \u03b3At) \u2264 1 + \u03b3\u03bbmax(M1). (11) For normalized samples, namely 0 \u2264 \u2016xt\u2016 \u2264 1, the ranges of \u03bbmax(M1) and \u03bbmax(M2) vary from [0,4]. Given 0 < \u03b3 < 14 , \u03bb(I + \u03b3At) \u2265 1 \u2212 \u03b3\u03bbmax(M2) > 0. Obviously, I + \u03b3At is a symmetric matrix. Hence, I + \u03b3At is a positive definite matrix, and it is invertible.\nAccording to Lemma 2, the optimal Lt can be updated as below:\nLt =\n\n\n\nLt\u22121(I + \u03b3At) \u22121 [z]+ > 0 Lt\u22121 [z]+ = 0. (12)\nIt is known that the time complexity of the matrix inversion in Eq. (12) is O(d3). However, the rank-2 property of At offers us a nice way to accelerate the speed by applying Lemma 3.\nLemma 3. [16] Given G and G + B as two nonsingular matrices, and let B have rank r > 0. Let B = B1+ \u00b7 \u00b7 \u00b7+Br, where each Bk has rank 1, also let Ck+1 = G+B1+\u00b7 \u00b7 \u00b7+Bk is nonsingular for k = 1, . . . , r. If C1 = G, then\n(G +B)\u22121 = C\u22121r \u2212 grC\u22121r BrC\u22121r , (13)\nwhere,\nC\u22121r+1 = C \u22121 r \u2212 grC\u22121r BrC\u22121r\ngr = 1\n1 + tr(C\u22121r Br) .\n(14)\nTheorem 1. If At is a rank-2 matrix and samples are normalized, then\n(I + \u03b3At) \u22121 = I \u2212 1\n\u03b7 + \u03b2 [\u03b7\u03b3At \u2212 (\u03b3At)2], (15)\nwhere \u03b7 = 1 + tr(\u03b3At), \u03b2 = 12 [(tr(\u03b3At)) 2 \u2212 tr(\u03b3At)2].\nProof. According to Lemma 3, we set G = I, B = \u03b3At, and rewrite B = B1 +B2, where B1 = \u03b3(xt \u2212 xp)(xt \u2212 xp)\u22a4, B2 = \u2212\u03b3(xt \u2212 xq)(xt \u2212 xq)\u22a4. It is obvious that the rank of B1 and B2 is 1. Utilizing the Lemma 3, we can obtain the Theorem 1.\nBy using Theorem 1, plugging Eq. (15) back into the first term of Eq. (12), we can obtain\nLt = Lt\u22121 \u2212 \u03b7\u03b3\n\u03b7 + \u03b2 (Lt\u22121aa\n\u22a4 \u2212Lt\u22121bb\u22a4)\n+ \u03b32\n\u03b7 + \u03b2 [(a\u22a4a)Lt\u22121aa \u22a4 \u2212 (a\u22a4b)Lt\u22121ab\u22a4\n\u2212 (b\u22a4a)Lt\u22121ba\u22a4 + (b\u22a4b)Lt\u22121bb\u22a4],\n(16)\nwhere a = xt \u2212 xp, and b = xt \u2212 xq.\nComplexity: The time complexity of calculating \u03b7 and \u03b2 in Eq. (16) is O(d2). In addition, a\u22a4a, a\u22a4b, b\u22a4a and b\u22a4b are scalars, for all of which time complexity is O(d). Also, the time complexity of calculating Lt\u22121aa\u22a4, Lt\u22121bb\u22a4, Lt\u22121ab\n\u22a4 and Lt\u22121ba\u22a4 is O(d2) respectively. Therefore, the time complexity of Eq. (16) is still O(d2). Now, we give the pseudo-code of OPML in Algorithm 1.\nAlgorithm 1 OPML\nInput: (xt, yt)|Tt=1, \u03b3. Output: L.\n1: L0 \u2190 I. 2: for t = 1, 2, . . . , T do 3: \u3008xt,xp,xq\u3009 \u2190 one-pass triplet construction 4: if G((xt,xp,xq);Lt\u22121) 6 0 then 5: Lt = Lt\u22121. 6: else 7: Lt \u2190 solution by Eq. (16) 8: end if 9: end for"}, {"heading": "C. Extended OPML to Cold Start Case", "text": "In practice, there is a case that the first several available samples belong to the same class, which is called as a cold start case. When cold start happens, since the triplet cannot be constructed, OPML will discard all these initial samples. To address this issue, we extend the proposed OPML to an enhanced version, namely COPML, which includes an additional pre-stage before calling OPML. Specifically, in the pre-stage, if the triplet cannot be constructed (i.e., the samples coming from different classes are not available), the metric L can only be updated based on the samples from the same class, which usually adopts the pairwise constraint for updating. Typically, pairwise constraint is mathematically set to \u3008xt,xt+1, y\u2217t,t+1\u3009, where y\u2217t,t+1 = 1 if two adjacent samples xt \u2208 Rd and xt+1 \u2208 Rd share the same class, and y\u2217t,t+1 = \u22121 otherwise. Actually, here we only need to consider the case when y\u2217t,t+1 = 1, because we can update the metric by calling OPML if y\u2217t,t+1 = \u22121 (the new coming sample belongs to a different class). After the pre-stage, OPML can be sequentially adopted for the following learning process.\nFormally, in the pre-stage when only the pairwise constraint \u3008xt,xt+1, y\u2217t,t+1\u3009 can be used, the online optimization formulation is formulated as follows:\nLt = argmin L \u0393(L)\n= argmin L\n1 2 \u2016L\u2212Lt\u22121\u20162F + \u03b31 2 y\u2217t,t+1\u2016L(xt \u2212 xt+1)\u201622,\n(17)\nwhere \u03b31 > 0 is the regularization parameter. The optimal solution can be obtained when the gradient vanishes \u2202\u0393(L)\n\u2202L =\n0, hence\n\u2202\u0393(L)\n\u2202L = L\u2212Lt\u22121 + \u03b31y\u2217t,t+1L\u039bt = 0, (18)\nwhere \u039bt = (xt \u2212 xt+1)(xt \u2212 xt+1)\u22a4. It is obvious that \u039bt is a rank-1 PSD matrix for xt 6= xt+1. Then we can get that I + \u03b31y \u2217 t,t+1\u039bt is a symmetric positive definite matrix, which\n5 is invertible, when y\u2217t,t+1 = 1. Then, the optimal Lt can be obtained as\nLt = Lt\u22121(I + \u03b31\u039bt) \u22121. (19)\nBy using the Sherman-Morrison formula, Eq. (19) can be equivalently rewritten as follows:\nLt = Lt\u22121 \u2212 \u03b31Lt\u22121(xt \u2212 xt+1)(xt \u2212 xt+1)\u22a4 1 + \u03b31(xt \u2212 xt+1)\u22a4(xt \u2212 xt+1) , (20)\nwhere we can observe that the time complexity of Eq. (20) is O(d2) too. Algorithm 2 shows the pseudo-code of COPML.\nAlgorithm 2 COPML\nInput: (xt, yt)|Tt=1, \u03b31, \u03b32. Output: L.\n1: L0 \u2190 I, c \u2190 0. 2: for t = 1, 2, . . . , T do 3: Maintain H = {h1, h2, \u00b7 \u00b7 \u00b7 , hc} 4: if yt = c = 1 then 5: \u3008xt,xt+1, y\u2217t,t+1\u3009 \u2190 adjacent two samples 6: Lt = Lt\u22121 \u2212 \u03b31Lt\u22121(xt\u2212xt+1)(xt\u2212xt+1) \u22a4\n1+\u03b31(xt\u2212xt+1)\u22a4(xt\u2212xt+1) .\n7: else if 1 \u2264 yt \u2264 c and c \u2265 2 then 8: L \u2190 call OPML(xt, yt, \u03b32) 9: else\n10: hc+1 \u2190 xt 11: c \u2190 c+ 1 12: end if 13: end for"}, {"heading": "IV. THEORETICAL GUARANTEE", "text": "The following theorems guarantee the effectiveness of our methods. Theorem 2 shows that the difference of learned metric between one-pass triplet construction strategy and batch triplet construction strategy is bounded. Note that, for a fair comparison, the batch triplet construction strategy here is considered in an online manner, that is to say, for each sample xt at the t-th time step, all past samples are stored to construct a triplet with xt (i.e., each triplet contains this xt). Theorem 3 also tries to explain that the one-pass triplet construction strategy can approximate the batch triplet construction, but from another perspective. Moreover, a regret bound has been proved for the proposed OPML algorithm, which can be found in Theorem 4. All details of the proofs for the theorems are provided in the appendix.\nTheorem 2. Let Lt be the solution output by OPML based on the one-pass triplet construction strategy at the t-th time step. Let L\u2217t be the solution output by OPML with the batch triplet construction strategy at the t-th time step. Assuming that \u2016x\u2016 \u2264 R (for all samples), \u2016Lt\u2016F \u2264 U and \u2016L\u2217t \u2016F \u2264 U , the bound of the difference between these two matrices is\n\u2016Lt\u2212L\u2217t\u2016F \u2264 U \u00b7 \u2225 \u2225 \u2225\nCN \u2211\ni=1\nBi+\nCN \u2211\ni=1,j=1,i<j\nBiBj+\u00b7 \u00b7 \u00b7+ CN \u220f\ni=1\nBi\n\u2225 \u2225 \u2225\nF ,\n(21) where \u2016B\u2016F \u2264 32 \u2223 \u2223 \u2223 \u03b32\n\u03b7+\u03b2\n\u2223 \u2223 \u2223 R4 + 4 \u221a 2 \u2223 \u2223 \u2223\n\u03b7\u03b3 \u03b7+\u03b2\n\u2223 \u2223 \u2223 R2 ( for all\nBi,Bj, \u00b7 \u00b7 \u00b7 ), \u03b3 \u2208 (0, 14 ), \u03b7 \u2208 (1 \u2212 54R2, 1 + 54R2), and \u03b2 \u2208 (\u2212R4, 2532R4).\nTheorem 3. Let \u3008xt,xp,xq\u3009 be the triplet constructed by the proposed one-pass triplet construction strategy at the t-th time step. Let {\u3008xt,xpi ,xqi\u3009}|Ci=1 be the triplet set constructed by the batch triplet construction strategy at the t-th time step. Assuming \u2016x\u20162 \u2264 R (for all samples), \u2016L\u2016F \u2264 U , \u2016L\u2217\u2016F \u2264 U and the angle \u03b8 between two samples coming from the same class is very small after the transformation of L or L\u2217 (i.e., cos \u03b8 = \u03b1, \u03b1 \u2265 0 and \u03b1 is close to 1), while \u03b8 is very large otherwise (i.e., cos \u03b8 = \u2212\u03be, \u03be \u2265 0 and \u03be is close to 1). Then the average loss bound between these two strategies at the t-th time step is\n\u03a81 \u2212\u03a82 \u2264 2(\u03b1+ \u03be + 1)R2U2, (22)\nwhere \u03a81 denotes the average loss generated by the one-pass triplet construction strategy, and \u03a82 refers to the average loss of the batch construction strategy.\nTheorem 4. Let \u3008x1,xp1 ,xq1\u3009, . . . , \u3008xT ,xpT ,xqT \u3009 be a sequence of triplets constructed by the proposed one-pass strategy. Let Lt|Tt=1 be the solution output by OPML at the t-th time step, and L\u2217 be the optimal offline solution. Assuming \u2016x\u20162 \u2264 R (for all samples), \u2016L\u2016F \u2264 U , \u2016L\u2217\u2016F \u2264 U and the angle \u03b8 between two samples coming from the same class is small after the transformation of L or L\u2217 (i.e., cos \u03b8 = \u03b1, \u03b1 \u2265 0 and \u03b1 is close to 1), while \u03b8 is large otherwise (i.e., cos \u03b8 = \u2212\u03be, \u03be \u2265 0 and \u03be is close to 1). Then the regret bound is\nR(L\u2217, T ) \u2264 2T (\u03b1+ \u03be + 1)R2U2 (23)"}, {"heading": "V. EXPERIMENTS", "text": "To verify the effectiveness of our methods, we evaluate OPML and COPML on three typical tasks, including (1) UCI data classification, (2) face verification, and (3) abnormal event detection in videos. Also, an additional experiment is conducted to validate the robustness of COPML when the cold start issue happens."}, {"heading": "A. UCI Data Classification", "text": "We introduce twelve datasets from the UCI repository for evaluation. The k-NN classifier is employed, since it is widelyused for classification with only one parameter. The detailed information of these datasets is presented in Table II. All these twelve datasets are normalized by Z-score. Also, for each dataset, 50% samples are randomly picked for training while the rest is used for testing. We adopt the error rate as the evaluation criterion, and to reduce the influence coming from the random partition, all the classification results are averaged over 100 individual runs.\nTo make an extensive comparison, we introduce several state-of-the-art methods, including batch metric learning and OML methods. Specifically, batch metric learning methods include: (1) Euclidean distance metric (Eucli for short); (2) Mahalanobis distance metric (Maha for short); (3) LMNN (Large Margin Nearest Neighbor) [10]; (4) ITML [5]. OML methods include: (1) OASIS [2]; (2) RDML [4]; (3) POLA\n6\n[1]; (4) LEGO [3]; (5) SOML-TG (SOML for short) [7]. The implementation of LMNN, ITML and OASIS was provided by the authors in their respective papers, while the rest methods were implemented by ourselves. The parameters of these methods were selected by cross-validation, except LMNN and ITML using the default settings. Since the pairwise or triplet constraints of POLA, LEGO and SOML need to be constructed in advance, we randomly sample 10000 constraints for these three methods (same setting as LEGO [3]). The error rates of the proposed methods and competitive methods are presented in Table II.\nMoreover, the p-values of student\u2019s t-test were calculated to check statistical significance. Also, the statistics of win/tie/loss is reported according to the obtained p-values (see Table II). It is observed that (1) the performance of our methods is comparable to LEGO, and slightly better than other OML methods; (2) the performance of our methods is close to batch metric learning methods, e.g., LMNN and ITML, and better\nthan Euclidean and Mahalanobis; (3) our methods are faster than other OML methods except comparable with RDML, since instead of constructing triplets, RDML only requires the pairwise constraint by receiving a pair of samples in each time.\nTo illustrate the performance with different numbers of triplet constraints on the learning of metric, we vary the numbers of triplet constraints as (100, 1000, 2000, 5000, 10000, 15000, 20000) for OASIS and SOML (see Fig. 2). Since the number of triplet constraint in OPML is a constant by using one-pass triplet construction, we can find that, OPML can achieve better performance by using fewer triplet constraints (except on UCI data 1, 3, 6)."}, {"heading": "B. Face Verification: PubFig", "text": "For face verification, we first evaluate our methods on the Public Figures Face Database (PubFig) [17]. PubFig dataset consists of two subsets: Development Set (7650 images of 60 individuals) and Evaluation Set (28954 images of 140\n7 0 100 1000 2000 5000 10000 15000 20000 25000 12 14 16 18 20 22 24 26 28 30 x=59\nThe Number of Triplet\nE rr\no r\nR at\ne (%\n) UCI Data: 1\nOPML OASIS SOML\n0 100 1000 2000 5000 10000 15000 20000 25000 0\n10\n20\n30\n40\n50\n60\nx=72\nThe Number of Triplet\nE rr\no r\nR at\ne (%\n)\nUCI Data: 2\nOPML OASIS SOML\n0 100 1000 2000 5000 10000 15000 20000 25000 0\n5\n10\n15\n20\n25\n30\nx=87\nThe Number of Triplet\nE rr\no r\nR at\ne (%\n)\nUCI Data: 3\nOPML OASIS SOML\n0 100 1000 2000 5000 10000 15000 20000 25000 30\n35\n40\n45\n50\n55\n60\n65\n70\n75\nx=103\nThe Number of Triplet\nE rr\no r\nR at\ne (%\n)\nUCI Data: 4\nOPML OASIS SOML\n0 100 1000 2000 5000 10000 15000 20000 25000 25\n30\n35\n40\n45\n50\nx=132\nThe Number of Triplet\nE rr\no r\nR at\ne (%\n)\nUCI Data: 5\nOPML OASIS SOML\n0 100 1000 2000 5000 10000 15000 20000 25000 5\n10\n15\n20\n25\n30\n35\n40\n45\n50\nx=172\nThe Number of Triplet\nE rr\no r\nR at\ne (%\n)\nUCI Data: 6\nOPML OASIS SOML\n0 100 1000 2000 5000 10000 15000 20000 25000 10\n15\n20\n25\n30\n35\n40\n45\n50\n55\nx=310\nThe Number of Triplet\nE rr\no r\nR at\ne (%\n)\nUCI Data: 7\nOPML OASIS SOML\n0 100 1000 2000 5000 10000 15000 20000 25000 \u22122\n0\n2\n4\n6\n8\n10\n12\n14\nx=340\nThe Number of Triplet\nE rr\no r\nR at\ne (%\n)\nUCI Data: 8\nOPML OASIS SOML\n0 100 1000 2000 5000 10000 15000 20000 25000 20\n25\n30\n35\n40\n45\nx=380\nThe Number of Triplet\nE rr\no r\nR at\ne (%\n)\nUCI Data: 9\nOPML OASIS SOML\n0 100 1000 2000 5000 10000 15000 20000 25000 0\n10\n20\n30\n40\n50\n60\n70\nx=1148\nThe Number of Triplet\nE rr\no r\nR at\ne (%\n)\nUCI Data: 10\nOPML OASIS SOML\n0 100 1000 2000 5000 10000 15000 20000 25000 20\n25\n30\n35\n40\n45\nx=2498\nThe Number of Triplet\nE rr\no r\nR at\ne (%\n)\nUCI Data: 11\nOPML OASIS SOML\n0 100 1000 2000 5000 10000 15000 20000 25000 0\n5\n10\n15\n20\n25\n30\n35\nx=2801\nThe Number of Triplet\nE rr\no r\nR at\ne (%\n)\nUCI Data: 12\nOPML OASIS SOML\nFig. 2. Error rates of different methods with different numbers of triplets on twelve UCI datasets (the number of triplets in OPML is a constant)\nindividuals). Following [17], we use the development set to develop all these methods, including parameters tuning, while the evaluation set is used for performance evaluation. The goal of face verification in PubFig is to determine whether a pair of face images belong to the same person. Please note that, images coming from the same person will be regarded as belonging to the same class. For all subsets, 10-fold cross validation is adopted to conduct the experiments, and each fold is disjoint by identity (i.e., one person will not appear in both the training and testing set). For testing each fold (with rest 9 folds used for training), we randomly sample 10000 pairs (5000 intra- and 5000 extra-personal pairs) for testing. Thus, the total number of pairs is 105. In each training phase, we also randomly select 10000 pairwise or triplet constraints for LEGO, POLA and SOML as the same settings on the UCI datasets.\nFor sufficient and fair comparison, we use two forms of features (i.e., attribute features and deep features) to evaluate the performance of all algorithms, respectively. Attribute features (73-dimension) provided by Kumar et al. [17] are \u2019high-level\u2019 features describing nameable attributes such as gender, race, age, hair etc., of a face image. For deep features, we use a VGG-Face model [18] to extract a 4096-dimensional feature for each face image which has been aligned and cropped. For easier handling, the 4096-dimensional feature is reduced to a 54-dimensional feature by Principal Component Analysis (PCA) algorithm.\nFor each testing pair, we first calculate the distance (similarity) between them by the learned metric obtained from\nrespective methods. Then, all the distances (similarities) are normalized into the range [0, 1]. Receiver Operating Characteristic (ROC) curves are provided in Fig. 3, with the corresponding AUC (Area under ROC) values calculated. It can be observed that OPML and COPML can obtain superior results compared with the state-of-the-art online/batch metric learning methods. Moreover, although the deep feature already has a strong representation ability, our proposed methods can still slightly improve the performance."}, {"heading": "C. Face Verification: LFW", "text": "For face verification, we also evaluate our methods on the Labeled Faces in the Wild Database (LFW) [19]. LFW is a widely used face verification benchmark with unconstrained images, which contains 13233 images of 5749 individuals. This dataset has two views: View 1 is used for development purposes (containing a training set and a test set); And, View 2 is taken as evaluation benchmark for comparison (i.e., a 10- fold cross-validation set). There are two forms of configuration in both views, that is, image restricted configuration and image unrestricted configuration. In the first formulation, the training information is restricted to the provided image pairs and additional information such as actual name information can not be used. In other words, we can only use the pairwise images for training without any label information can be used at all. While, in the second formulation, the actual name information (i.e., label information) can be used and as many pairs or triplets can be formulated as one desires. No matter which configuration we choose, the test procedure is the same\n8 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1\nFPR\nT P\nR\nRoc Curves for Development Set\nOPML (0.8297) COPML(0.8207) LEGO (0.8100) POLA (0.7934) ITML (0.7835) LMNN (0.7834) OASIS (0.7701) Eucli (0.7471) RDML (0.7287) Maha (0.7238) SOML (0.6956)\n0 0.2 0.4 0.6 0.8 1 0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nFPR\nT P\nR\nRoc Curves for Evaluation Set\nOPML (0.8114) COPML(0.8063) LEGO (0.8020) POLA (0.7823) LMNN (0.7617) OASIS (0.7584) RDML (0.7279) Eucli (0.7273) ITML (0.7171) Maha (0.7151) SOML (0.6965)\n0.02 0.04 0.06 0.08 0.1 0.12 0.14\nFPR\n0.86\n0.88\n0.9\n0.92\n0.94\n0.96\n0.98\nT P\nR\nRoc Curves for Development Set (Larger Version)\nOPML (0.9861) COPML(0.9864) LEGO (0.9860) POLA (0.9840) ITML (0.9758) LMNN (0.9805) OASIS (0.9732) Eucli (0.9854) RDML (0.9573) Maha (0.9829) SOML (0.6918)\n0.02 0.04 0.06 0.08 0.1 0.12\nFPR\n0.86\n0.88\n0.9\n0.92\n0.94 0.96 T P R\nRoc Curves for Evaluation Set (Larger Version)\nOPML (0.9858) COPML(0.9856) LEGO (0.9806) POLA (0.9734) LMNN (0.9749) OASIS (0.9726) RDML (0.9745) Eucli (0.9804) ITML (0.9810) Maha (0.9844) SOML (0.6228)\nFig. 3. ROC Curves of development set (left column) and evaluation set (right column) on the PubFig dataset. first row: attribute features; second row: deep features. AUC value of each method is presented in bracket\n0 0.2 0.4 0.6 0.8 1 FPR\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nT P\nR\nRoc Curves for LFW (SIFT)\nOPML (0.8606) COPML(0.8676) LEGO (0.7976) POLA (0.8442) LMNN (0.8634) OASIS (0.8267) Eucli (0.7335) RDML (0.6902) Maha (0.6570) SOML (0.5994)\n0 0.2 0.4 0.6 0.8 1 FPR\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nT P\nR\nRoc Curves for LFW (Attribute)\nOPML (0.9136) COPML(0.9143) LEGO (0.8629) POLA (0.9058) LMNN (0.9105) OASIS (0.8906) Eucli (0.8564) RDML (0.8368) Maha (0.8138) SOML (0.7265)\nFig. 4. ROC Curves of our methods and contrastive methods on the LFW dataset. left: sift features; right: attribute features. AUC value of each method is presented in bracket\n(i.e., using pairwise images for testing). In order to simulate the real online environment and because our methods and some methods (eg., OASIS [2], SOML [7]) are triplet-based methods, we adopt the image unrestricted configuration to construct the experiment. We use View 1 for parameter tuning and then evaluate the performance of all the algorithms on each fold (300 intra- and 300 extra-personal pairs) in View 2. Other settings are similar with the ones on the PubFig dataset.\nIn this experiment, we adopt two types of features (i.e., SIFT features and attribute features) to represent each face image, respectively. The SIFT features are provided by Guillaumin et al. [20] by extracting SIFT descriptors [21] at 9 fixed facial landmarks detected on a face, over three scales. Then we perform PCA algorithm to reduce the original 3456-dimensional feature to a 100-dimensional feature. Like PubFig, the attribute features of LFW are 73-dimensional \u2019high-level\u2019 features describing the nameable attributes of a face image [17]. To evaluate our methods and the contrastive methods, we report the ROC curves and AUC values of the corresponding methods (see Fig. 4). The results of ITML [5] aren\u2019t displayed for its difficulty of convergence in the training data. We can see that the proposed COPML method can achieve the-state-of-the-art performance compared with the contrastive metric learning\nmethods. Especially, when using SIFT features, our methods can significantly improve the AUC value over the Euclidean distance by 13% (5.8% with attribute features), showing the validity of the proposed methods. It is worth noting that some metric learning methods cannot even improve over the Euclidean distance, which has happened on the PubFig dataset. The reason why LMNN cannot achieve the best performance may be over-fitting for lacking of regularization."}, {"heading": "D. Abnormal Event Detection in Videos", "text": "The performance of the proposed methods is also evaluated on UMN dataset for abnormal event detection. UMN dataset contains 3 different scenes with 7739 frames in total: Scene1 (1453 frames), Scene2 (4144 frames) and Scene3 (2142 frames). In UMN dataset, people walking around is considered as normal, while people running away is regarded as abnormal. The resolution of the video is 320 \u00d7 240. We divide each frame into 5 \u00d7 4 non-overlapping 64 \u00d7 60 patches. For each patch, the MHOF (Multi-scale Histogram of Optical Flow) feature [22] was extracted from every two successive frames. The MHOF is a 16-dimensional feature, which can capture both motion direction and motion energy. For integrating the multi-patches features, we combine features from all patches in each frame, and form a 320-dimensional feature. For each scene, we perform 2-fold cross validation for evaluation. The distance metric is learnt from the training data in online way, then we use the SVM classifier to classify the testing frames after feature transformation by using the learned metric L.\nTable III reports the AUC of all the methods. We can notice that our methods is very effective and competitive, when compared with other methods. Fig. 5 exhibits the sample frames of normal and abnormal events in the 3 scenes respectively (top row), and shows the abnormal event detection results of our method (COPML) in the indication bars (green/red indicates normal/abnormal event). It\u2019s worth mentioning that in this experiment, COPML performs better than OPML, because the video data has the cold start issue especially at the beginning."}, {"heading": "E. COPML for Cold Start", "text": "We can observe that in the case free of the cold start issue (e.g., UCI data classification, face verification), OPML and\n9 Groundtruth\nOur Results\nScene1 Scene3Scene2\nScene1 Abnormal Scene2 Abnormal Scene3 AbnormalScene1 Normal Scene2 Normal Scene3 Normal\nFig. 5. Global abnormal event detection results of our method COPML and the ground truth on the UMN dataset\nCOPML can obtain comparable results, while in the case with cold start issue (e.g., abnormal event detection in videos), COPML is better than OPML. To further test the performance of COPML on an extreme case with cold start issue, we construct several datasets with specified structure to verify the different performance of COPML and OPML. Three datasets were picked from the UCI repository: (1) Image Segmentation (seg for short), with 7 classes, 19 features and 2310 samples; (2) EEG Eye State (eeg for short), with 2 classes, 15 features and 14980 samples; (3) Sensorless (sen for short), with 11 classes, 49 features and 58509 samples.\nFor each dataset, the samples from different classes are divided into disjoint 10/5/2 parts, then different parts of different classes are crosswise put together to construct a new dataset. Afterwards, the new dataset is divided into 2 folds. The first fold is used for training and the second fold is used for testing. As the previous setting for classification, we take a k-NN (k=5) classifier to get the final test results, shown in Table IV. The results prove that COPML performs better than OPML when the data has the cold start issue. Since when cold start occurs, COPML will incorporate both the pair and triplet information, instead of only using triplet in OPML."}, {"heading": "VI. CONCLUSION", "text": "We propose a one-pass closed-form solution for OML, namely OPML. It employs the one-pass triplet construction for fast triplet generation, together with a closed-form solution to update the metric with the new coming sample at each time step. Also, for cold start issue, COPML, an extended version of OPML is developed. The major advantages of our methods are: OPML and COPML are easy to implement. Also, OPML and COPML are very scalable with low space (i.e., O(d)) and time (i.e., O(d2)) complexity. In the experiments, we show\nthat our methods can obtain superior performance on three typical tasks, compared with the state-of-the-art methods."}, {"heading": "APPENDIX A PROOF OF THEOREM 2", "text": "Proof. Recall that the metric update formula of OPML is\nLt =\n\n\n\nLt\u22121(I + \u03b3At) \u22121 [z]+ > 0 Lt\u22121 [z]+ = 0. (24)\nAccording to the Theorem 1, we can obtain that,\n(I + \u03b3At) \u22121 = I \u2212 1\n\u03b7 + \u03b2 [\u03b7\u03b3At \u2212 (\u03b3At)2], (25)\nwhere \u03b7 = 1+tr(\u03b3At), \u03b2 = 12 [(tr(\u03b3At)) 2\u2212tr(\u03b3At)2]. Here, we only consider the case that [z]+ > 0. Then at t-th time step, the learned metric Lt of one-pass strategy can be expressed as below,\nLt = L0(I + \u03b3A1) \u22121(I + \u03b3A2) \u22121 \u00b7 \u00b7 \u00b7 (I + \u03b3At)\u22121. (26)\nNote that the batch triplet construction strategy here is considered in an online manner, that is to say, for each sample xt at the t-th time step, all past samples are stored to construct a triplet with xt (i.e., each triplet contains this xt). Similar to Lt, the learned metric L\u2217t of the batch strategy (at t-th time step, Ci|ti=1 triplets can be constructed) can be denoted as follows,\nL\u2217t =L \u2217 0\nC1 \u220f\ni=1\n(I+\u03b3A1i) \u22121\nC2 \u220f\ni=1\n(I+\u03b3A2i) \u22121 \u00b7 \u00b7 \u00b7\nCt \u220f\ni=1\n(I+\u03b3Ati) \u22121.\n(27) Let \u3008x1,xp1 ,xq1\u3009, . . . , \u3008xt,xpt ,xqt\u3009 be the sequence of triplets constructed by the proposed one-pass strategy, which is contained in the sequence of triplets constructed by the batch strategy. If we let the L\u2217 learn on the sequence of triplets\n10\nconstructed by the one-pass strategy first, the Eq. (27) can be reorganized as below,\nL\u2217t =L \u2217 0(I+\u03b3A1) \u22121\u00b7 \u00b7 \u00b7(I+\u03b3At)\u22121 \u00b7\nC1+\u00b7\u00b7\u00b7+Ct\u2212t \u220f\ni=1\n(I+\u03b3Ai) \u22121\n(L\u2217t learn on the sequence of Lt first)\n=Lt \u00b7 C1+\u00b7\u00b7\u00b7+Ct\u2212t \u220f\ni=1\n(I + \u03b3Ai) \u22121\n(L0 and L \u2217 0 are both initialized as identity matrices)\n=Lt \u00b7 C1+\u00b7\u00b7\u00b7+Ct\u2212t \u220f\ni=1\n(I +B)\n(by Theorem 1, where B= 1 \u03b7+\u03b2\n[\n(\u03b3Ai) 2\u2212\u03b7\u03b3Ai\n]\n)\n=Lt\n[\nI +\nCN \u2211\ni=1\nBi +\nCN \u2211\ni=1,j=1,i<j\nBiBj + \u00b7 \u00b7 \u00b7+ CN \u220f\ni=1\nBi\n]\n(where CN = C1 + \u00b7 \u00b7 \u00b7+ Ct \u2212 t). (28)\nThen we can calculate that\n\u2016Lt\u2212L\u2217t \u2016F = \u2225 \u2225 \u2225Lt [\nCN \u2211\ni=1\nBi+\nCN \u2211\ni=1,j=1,i<j\nBiBj+\u00b7 \u00b7 \u00b7+ CN \u220f\ni=1\nBi\n]\u2225\n\u2225 \u2225\nF\n\u2264\u2016Lt\u2016F \u00b7 \u2225 \u2225 \u2225\nCN \u2211\ni=1\nBi+\nCN \u2211\ni=1,j=1,i<j\nBiBj+\u00b7 \u00b7 \u00b7+ CN \u220f\ni=1\nBi\n\u2225 \u2225 \u2225\nF .\n(29)\nRecall that At = M1\u2212M2 = (xt\u2212xp)(xt\u2212xp)T \u2212 (xt\u2212 xq)(xt \u2212 xq)T \u2208 Rd\u00d7d, which is a symmetry square matrix. According to the definition of Frobenius norm,\n\u2016At\u2016F =\n\u221a \u221a \u221a \u221a d \u2211\ni=1\nd \u2211\ni=1\n|aij |2 =\n\u221a \u221a \u221a \u221a d \u2211\ni=1\n\u03c32i , (30)\nwhere \u03c3i are the singular values of At, which are equal to the eigenvalues of At. According to Lemma 1, \u2212\u03bbmax(M2) \u2264 \u03bb(At) \u2264 \u03bbmax(M1), where \u03bb(At) denotes the eigenvalue of At, and \u03bbmax(M) indicates the maximum eigenvalue of M . Assuming that \u2016xt\u20162 \u2264 R, then \u03bbmax(M1) belongs to the range of [0, 4R2]. And since the rank of At is 2 (which has been proved in section III-B), there are at most two nonzero eigenvalues. Thus we can easily obtain that \u2016A\u2016F \u2264 4 \u221a 2R2. Hence,\n\u2016B\u2016F = \u2016 \u03b32\n\u03b7 + \u03b2 A2t +\n\u03b7\u03b3\n\u03b7 + \u03b2 (\u2212At)\u2016F\n\u2264 \u2016 \u03b3 2\n\u03b7 + \u03b2 A2t \u2016F + \u2016\n\u03b7\u03b3\n\u03b7 + \u03b2 (\u2212At)\u2016F\n\u2264 \u2223 \u2223\n\u2223\n\u03b32\n\u03b7 + \u03b2\n\u2223 \u2223 \u2223 \u00b7 \u2016At\u2016F \u00b7 \u2016At\u2016F + \u2223 \u2223 \u2223 \u03b7\u03b3\n\u03b7 + \u03b2\n\u2223 \u2223 \u2223 \u00b7 \u2016At\u2016F\n\u2264 32 \u2223 \u2223\n\u2223\n\u03b32\n\u03b7 + \u03b2\n\u2223 \u2223 \u2223 R4 + 4 \u221a 2 \u2223 \u2223 \u2223 \u03b7\u03b3\n\u03b7 + \u03b2\n\u2223 \u2223 \u2223 R2.\n(31)\nThen, we can also calculate the range of \u03b7 and \u03b2 respectively.\n\u03b7 = 1 + tr(\u03b3At)\n= 1 + \u03b3 \u00b7 tr(At) = 1 + \u03b3 [ (xt \u2212 xp)T (xt \u2212 xp)\u2212 (xt \u2212 xq)T (xt \u2212 xq) ]\n= 1 + \u03b3 [\n\u2016xp\u201622 \u2212 \u2016xq\u201622 \u2212 2\u2016xTt \u20162 \u00b7 \u2016xp\u20162 cos \u03b81\n+ 2\u2016xTt \u20162 \u00b7 \u2016xq\u20162 cos \u03b82 ] .\n(32)\nSince the range of \u03b3 is (0, 14 ), and 0< \u2016xt\u20162\u2264R, we can calculate to get the range of tr(\u03b3At) (i.e., (\u2212 54R2, 54R2)), and the range of \u03b7 which is (1\u2212 54R2, 1+ 54R2). Recall that,\n\u03b2 = 1\n2\n[\n(tr(\u03b3At)) 2 \u2212 tr(\u03b3At)2\n]\n( by the rule of tr(cA)=c\u00b7tr(A) )\n= 1\n2\n[\n(tr(\u03b3At)) 2 \u2212 \u03b32tr(A2t )\n]\n( by the rule of tr(Ak)=\u2211i \u03bbki ,\nwhere \u03bbi is the eigenvalue of A)\n= 1\n2\n[\n(tr(\u03b3At)) 2 \u2212 \u03b32\nd \u2211\ni=1\n\u03bb2i\n]\n( by the rule of \u2016At\u2016F= \u221a\u2211 d i=1 \u03bb2 i )\n= 1\n2\n[\n(tr(\u03b3At)) 2 \u2212 \u03b32\u2016At\u20162F\n]\n(33)\nFor 0 < \u2016At\u20162F \u2264 32R4 and \u2212 54R2 < tr(\u03b3At) < 54R2, the range of \u03b2 is (\u2212R4, 2532R4)."}, {"heading": "APPENDIX B PROOF OF THEOREM 3", "text": "Proof. By applying the one-pass triplet construction strategy, at the t-th time step, we can obtain one triplet \u3008xt,xp,xq\u3009. While in the batch construction (all past samples will be stored), we can get a triplet set {\u3008xt,xpi ,xqi\u3009}|Ci=1. The average loss of these two strategies can be expressed as follows:\n\u03a81 = [ 1 + \u2016L(xt \u2212 xp)\u201622 \u2212 \u2016L(xt \u2212 xq)\u201622 ]\n+\n\u03a82 = 1\nC\nC \u2211\ni=1\n[ 1+\u2016L\u2217(xt\u2212xpi)\u201622\u2212\u2016L\u2217(xt\u2212xqi)\u201622 ]\n+ ,\n(34) where [z]+ = max(0, z), namely the hinge loss G((xt,xp,xq);L). For \u03a81, we only consider the case that z \u2265 0, which exactly affects the updating of the metric L. However, in \u03a82, some losses may be negative. Thus,\n\u03a81 = 1 + \u2016L(xt \u2212 xp)\u201622 \u2212 \u2016L(xt \u2212 xq)\u201622\n\u03a82 \u2264 1\nC\nC \u2211\ni=1\n[ 1 + \u2016L\u2217(xt \u2212 xpi)\u201622 \u2212 \u2016L\u2217(xt \u2212 xqi)\u201622 ] .\n(35)\n11\nThen we calculate the difference between the losses of these two strategies. That is,\n\u03a81 \u2212\u03a82 \u2264 1\nC\nC \u2211\ni=1\n\u2206\n\u2264 1 C\nC \u2211\ni=1\n[\n\u2016L(xt \u2212 xp)\u201622 \u2212 \u2016L\u2217(xt \u2212 xpi)\u201622\n+ \u2016L\u2217(xt \u2212 xqi)\u201622 \u2212 \u2016L(xt \u2212 xq)\u201622 ] .\n(36)\nFor simplicity, we just analysis the \u2206. By applying the rule of dot product (i.e., xTy = \u2016x\u2016\u00b7\u2016y\u2016\u00b7cos \u03b8), \u2206 can be expanded as follows,\n\u2206 = \u2016Lxp\u201622 \u2212 \u2016L\u2217xpi\u201622 + \u2016L\u2217xqi\u201622 \u2212 \u2016Lxq\u201622 \u2212 2\u2016Lxt\u2016\u00b7\u2016Lxp\u2016\u00b7cos \u03b81+2\u2016L\u2217xt\u2016\u00b7\u2016L\u2217xpi\u2016\u00b7cos\u03b82 \u2212 2\u2016L\u2217xt\u2016 \u00b7 \u2016L\u2217xqi\u2016 \u00b7 cos \u03b83 + 2\u2016Lxt\u2016 \u00b7 \u2016Lxq\u2016 \u00b7 cos \u03b84.\n(37)\nIn order to simplify the expression, we set\n1\u00a9 = \u22122\u2016Lxt\u2016 \u00b7 \u2016Lxp\u2016 \u00b7 cos \u03b81 2\u00a9 = 2\u2016L\u2217xt\u2016 \u00b7 \u2016L\u2217xpi\u2016 \u00b7 cos \u03b82 3\u00a9 = \u22122\u2016L\u2217xt\u2016 \u00b7 \u2016L\u2217xqi\u2016 \u00b7 cos \u03b83 4\u00a9 = 2\u2016Lxt\u2016 \u00b7 \u2016Lxq\u2016 \u00b7 cos \u03b84.\n(38)\nAssuming that the angle \u03b8 between two samples coming from the same class is very small after the transformation of L or L\u2217 (i.e., cos \u03b8 = \u03b1, \u03b1 \u2265 0 and \u03b1 is close to 1), while \u03b8 is very large otherwise (i.e., cos \u03b8 = \u2212\u03be, \u03be \u2265 0 and \u03be is close to 1). Thus,\n0 \u2264 cos \u03b81 \u2264 \u03b1 0 \u2264 cos \u03b82 \u2264 \u03b1 \u2212\u03be \u2264 cos \u03b83 \u2264 0 \u2212\u03be \u2264 cos \u03b84 \u2264 0,\n(39)\nwhere 0 \u2264 \u03b1 \u2264 1, 0 \u2264 \u03be \u2264 1 and both of them are close to 1. Then, we can obtain that,\n\u22122\u03b1\u2016Lxt\u2016 \u00b7 \u2016Lxp\u2016 \u2264 1\u00a9 \u2264 0 0 \u2264 2\u00a9 \u2264 2\u03b1\u2016L\u2217xt\u2016 \u00b7 \u2016L\u2217xpi\u2016 0 \u2264 3\u00a9 \u2264 2\u03be\u2016L\u2217xt\u2016 \u00b7 \u2016L\u2217xqi\u2016 \u22122\u03be\u2016Lxt\u2016 \u00b7 \u2016Lxq\u2016 \u2264 4\u00a9 \u2264 0. (40)\nHere, we only consider the upper bound of \u2206,\n\u2206 \u2264 \u2016Lxp\u201622 \u2212 \u2016L\u2217xpi\u201622 + \u2016L\u2217xqi\u201622 \u2212 \u2016Lxq\u201622 + 2\u03b1\u2016L\u2217xt\u2016 \u00b7 \u2016L\u2217xpi\u2016+ 2\u03be\u2016L\u2217xt\u2016 \u00b7 \u2016L\u2217xqi\u2016\n\u2264 \u2016Lxp\u201622 + \u2016L\u2217xqi\u201622 + 2\u03b1\u2016L\u2217xt\u2016 \u00b7 \u2016L\u2217xpi\u2016 + 2\u03be\u2016L\u2217xt\u2016 \u00b7 \u2016L\u2217xqi\u2016.\n(41)\nAccording to the property of compatible norms, that is,\n\u2016Ax\u20162 \u2264 \u2016A\u2016F \u00b7 \u2016x\u20162. (42) For assuming that \u2016x\u20162 \u2264 R (for all samples), \u2016L\u2016F \u2264 U and \u2016L\u2217\u2016F \u2264 U , we can obtain that,\n\u2206 \u2264 2(\u03b1+ \u03be + 1)R2U2\n\u03a81 \u2212\u03a82 \u2264 2(\u03b1+ \u03be + 1)R2U2. (43)\nThus, this theorem has be proved."}, {"heading": "APPENDIX C PROOF OF THEOREM 4", "text": "Proof. The regret can be defined (according to the definition of Chapter 3 in [28]) as below:\nR(L\u2217, T ) =\nT \u2211\nt=1\nGt(Lt)\u2212 T \u2211\nt=1\nGt(L\u2217), (44)\nwhere Gt(L) = [1+\u2016L(xt\u2212xp)\u201622\u2212\u2016L(xt\u2212xq)\u201622]+. Here, we also only consider the case that the loss is positive, which exactly affects the updating of the metric L. However, one triplet which generates a positive loss with L may incur a negative loss with L\u2217. Thus, after expanding,\nR(L\u2217, T ) \u2264 T \u2211\nt=1\n[\n\u2016Lt(xt \u2212 xp)\u201622 \u2212 \u2016Lt(xt \u2212 xq)\u201622\n\u2212 \u2016L\u2217(xt \u2212 xp)\u201622 + \u2016L\u2217(xt \u2212 xq)\u201622 ] .\n(45)\nIn the similar way of proving the Theorem 3, we can easily prove this theorem."}], "references": [{"title": "Online and batch learning of pseudo-metrics", "author": ["S. Shalev-Shwartz", "Y. Singer", "A.Y. Ng"], "venue": "Proceedings of the twenty-first International Conference on Machine Learning (ICML). ACM, 2004, p. 94.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2004}, {"title": "Large scale online learning of image similarity through ranking", "author": ["G. Chechik", "V. Sharma", "U. Shalit", "S. Bengio"], "venue": "The Journal of Machine Learning Research, vol. 11, pp. 1109\u20131135, 2010.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "Online metric learning and fast similarity search", "author": ["P. Jain", "B. Kulis", "I.S. Dhillon", "K. Grauman"], "venue": "Advances in Neural Information Processing Systems (NIPS), 2009, pp. 761\u2013768.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Regularized distance metric learning: Theory and algorithm", "author": ["R. Jin", "S. Wang", "Y. Zhou"], "venue": "Advances in Neural Information Processing Systems (NIPS), 2009, pp. 862\u2013870.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "Informationtheoretic metric learning", "author": ["J.V. Davis", "B. Kulis", "P. Jain", "S. Sra", "I.S. Dhillon"], "venue": "Proceedings of the 24th International Conference on Machine Learning (ICML). ACM, 2007, pp. 209\u2013216.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "Online passive-aggressive algorithms", "author": ["K. Crammer", "O. Dekel", "J. Keshet", "S. Shalev-Shwartz", "Y. Singer"], "venue": "The Journal of Machine Learning Research, vol. 7, pp. 551\u2013585, 2006.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2006}, {"title": "Soml: Sparse online metric learning with application to image retrieval", "author": ["X. Gao", "S.C. Hoi", "Y. Zhang", "J. Wan", "J. Li"], "venue": "Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence (AAAI), 2014.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Online multiple kernel similarity learning for visual search", "author": ["H. Xia", "S.C. Hoi", "R. Jin", "P. Zhao"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 36, no. 3, pp. 536\u2013549, 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Mirror descent for metric learning: A unified approach", "author": ["G. Kunapuli", "J. Shavlik"], "venue": "Machine Learning and Knowledge Discovery in Databases. Springer, 2012, pp. 859\u2013874.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Distance metric learning for large margin nearest neighbor classification", "author": ["K.Q. Weinberger", "L.K. Saul"], "venue": "The Journal of Machine Learning Research, vol. 10, pp. 207\u2013244, 2009.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning a distance metric from a network", "author": ["B. Shaw", "B. Huang", "T. Jebara"], "venue": "Advances in Neural Information Processing Systems (NIPS), 2011, pp. 1899\u20131907.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Efficient distance metric learning by adaptive sampling and mini-batch stochastic gradient descent (sgd)", "author": ["Q. Qian", "R. Jin", "J. Yi", "L. Zhang", "S. Zhu"], "venue": "Machine Learning, vol. 99, no. 3, pp. 353\u2013372, 2015.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning patterns of activity using real-time tracking", "author": ["C. Stauffer", "W.E.L. Grimson"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 22, no. 8, pp. 747\u2013757, 2000.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2000}, {"title": "Real-time abnormal event detection in complicated scenes", "author": ["Y. Shi", "Y. Gao", "R. Wang"], "venue": "20th International Conference on Pattern Recognition (ICPR). IEEE, 2010, pp. 3653\u20133656.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2010}, {"title": "One-pass auc optimization", "author": ["W. Gao", "R. Jin", "S. Zhu", "Z.-H. Zhou"], "venue": "Proceedings of the 30th International Conference on Machine Learning (ICML). ACM, 2013, pp. 906\u2013914.  12", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "On the inverse of the sum of matrices", "author": ["K.S. Miller"], "venue": "Mathematics Magazine, pp. 67\u201372, 1981.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1981}, {"title": "Attribute and simile classifiers for face verification", "author": ["N. Kumar", "A.C. Berg", "P.N. Belhumeur", "S.K. Nayar"], "venue": "IEEE 12th International Conference on Computer Vision (ICCV). IEEE, 2009, pp. 365\u2013372.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Deep face recognition", "author": ["O.M. Parkhi", "A. Vedaldi", "A. Zisserman"], "venue": "British Machine Vision Conference (BMVC), vol. 1, no. 3, 2015, p. 6.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Labeled faces in the wild: A database for studying face recognition in unconstrained environments", "author": ["G.B. Huang", "M. Ramesh", "T. Berg", "E. Learned-Miller"], "venue": "University of Massachusetts, Amherst, Tech. Rep. 07-49, October 2007.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2007}, {"title": "Is that you? metric learning approaches for face identification", "author": ["M. Guillaumin", "J. Verbeek", "C. Schmid"], "venue": "IEEE 12th International Conference on Computer Vision (ICCV). IEEE, 2009, pp. 498\u2013505.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2009}, {"title": "Distinctive image features from scale-invariant keypoints", "author": ["D.G. Lowe"], "venue": "International journal of computer vision, vol. 60, no. 2, pp. 91\u2013110, 2004.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2004}, {"title": "Sparse reconstruction cost for abnormal event detection", "author": ["Y. Cong", "J. Yuan", "J. Liu"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, 2011, pp. 3449\u20133456.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "Abnormal crowd behavior detection using social force model", "author": ["R. Mehran", "A. Oyama", "M. Shah"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, 2009, pp. 935\u2013942.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2009}, {"title": "Chaotic invariants of lagrangian particle trajectories for anomaly detection in crowded scenes", "author": ["S. Wu", "B.E. Moore", "M. Shah"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, 2010, pp. 2054\u20132060.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2010}, {"title": "Video anomaly detection based on local statistical aggregates", "author": ["V. Saligrama", "Z. Chen"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, 2012, pp. 2112\u20132119.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Multi-instance dictionary learning for detecting abnormal events in surveillance videos", "author": ["J. Huo", "Y. Gao", "W. Yang", "H. Yin"], "venue": "International Journal of Neural Systems, vol. 24, no. 03, p. 1430010, 2014.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "Combining motion and appearance cues for anomaly detection", "author": ["Y. Zhang", "H. Lu", "L. Zhang", "X. Ruan"], "venue": "Pattern Recognition, vol. 51, pp. 443\u2013452, 2016.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2016}, {"title": "Online learning: Theory, algorithms, and applications", "author": ["S. Shalev-Shwartz", "Y. Singer"], "venue": "2007.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2007}], "referenceMentions": [{"referenceID": 0, "context": "For fast triplet (or pair) construction (first issue), existing OML methods usually assume that pairwise or triplet constraints can be obtained in advance [1], or by employing the random sampling strategy to reduce the size of triplets [2].", "startOffset": 155, "endOffset": 158}, {"referenceID": 1, "context": "For fast triplet (or pair) construction (first issue), existing OML methods usually assume that pairwise or triplet constraints can be obtained in advance [1], or by employing the random sampling strategy to reduce the size of triplets [2].", "startOffset": 236, "endOffset": 239}, {"referenceID": 1, "context": "Compared with Online Algorithm for Scalable Image Similarity (OASIS) [2], which utilizes a random sampling strategy and stores the entire training data in memory with space complexity of O(md) (d is the feature dimensionality, and m is the data size, which is very large for large-scale data), our one-pass strategy can vastly reduce the space complexity to O(cd) (c is the total number of classes, which is usually small).", "startOffset": 69, "endOffset": 72}, {"referenceID": 1, "context": "For fast metric updating (second issue), several studies [2], [3] try to adopt a closed-form solution for accurate computation.", "startOffset": 57, "endOffset": 60}, {"referenceID": 2, "context": "For fast metric updating (second issue), several studies [2], [3] try to adopt a closed-form solution for accurate computation.", "startOffset": 62, "endOffset": 65}, {"referenceID": 2, "context": "In contrast, LogDet Exact Gradient Online (LEGO) [3] attempts to learn a Mahalanobis distance and has a closedform solution.", "startOffset": 49, "endOffset": 52}, {"referenceID": 0, "context": "In addition, LEGO is not required to maintain the PSD constraint by using LogDet regularization, which is time-consuming in some Mahalanobis distance metric learning methods [1], [4], [5].", "startOffset": 174, "endOffset": 177}, {"referenceID": 3, "context": "In addition, LEGO is not required to maintain the PSD constraint by using LogDet regularization, which is time-consuming in some Mahalanobis distance metric learning methods [1], [4], [5].", "startOffset": 179, "endOffset": 182}, {"referenceID": 4, "context": "In addition, LEGO is not required to maintain the PSD constraint by using LogDet regularization, which is time-consuming in some Mahalanobis distance metric learning methods [1], [4], [5].", "startOffset": 184, "endOffset": 187}, {"referenceID": 1, "context": "In bilinear similarity-based methods, OASIS [2] is developed which is based on Passive-Aggressive algorithm [6], aiming to learn a similarity metric for image similarity.", "startOffset": 44, "endOffset": 47}, {"referenceID": 5, "context": "In bilinear similarity-based methods, OASIS [2] is developed which is based on Passive-Aggressive algorithm [6], aiming to learn a similarity metric for image similarity.", "startOffset": 108, "endOffset": 111}, {"referenceID": 6, "context": "Sparse Online Metric Learning (SOML) [7] follows a similar setting as OASIS, but learns a diagonal matrix instead of a full matrix to handle very high-dimensional cases.", "startOffset": 37, "endOffset": 40}, {"referenceID": 7, "context": "[8].", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "In Mahalanobis distance-based methods, Pseudo-Metric Online Learning Algorithm (POLA) [1] is the first OML method which introduces the successive projection operation to learn the optimal metric.", "startOffset": 86, "endOffset": 89}, {"referenceID": 2, "context": "LEGO [3] is an extended version of Information Theoretic Metric Learning-Online (ITML-Online) [5], by building the model with LogDet divergence regularization.", "startOffset": 5, "endOffset": 8}, {"referenceID": 4, "context": "LEGO [3] is an extended version of Information Theoretic Metric Learning-Online (ITML-Online) [5], by building the model with LogDet divergence regularization.", "startOffset": 94, "endOffset": 97}, {"referenceID": 3, "context": "[4] presented a regularized OML method namely RDML, with a provable regret bound.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "Also, Kunapuli and Shavlik proposed an unified approach based on composite mirror descent named as MDML [9].", "startOffset": 104, "endOffset": 107}, {"referenceID": 9, "context": "However, in general, triplet constraints are more effective than pairwise constraints for learning a metric [10], [2], [11], [12].", "startOffset": 108, "endOffset": 112}, {"referenceID": 1, "context": "However, in general, triplet constraints are more effective than pairwise constraints for learning a metric [10], [2], [11], [12].", "startOffset": 114, "endOffset": 117}, {"referenceID": 10, "context": "However, in general, triplet constraints are more effective than pairwise constraints for learning a metric [10], [2], [11], [12].", "startOffset": 119, "endOffset": 123}, {"referenceID": 11, "context": "However, in general, triplet constraints are more effective than pairwise constraints for learning a metric [10], [2], [11], [12].", "startOffset": 125, "endOffset": 129}, {"referenceID": 12, "context": "Inspired by the impressive scalability of one-pass strategies [13], [14], [15], we proposed a one-pass triplet construction strategy, aiming to quickly obtain all the triplets in a single pass over all data.", "startOffset": 62, "endOffset": 66}, {"referenceID": 13, "context": "Inspired by the impressive scalability of one-pass strategies [13], [14], [15], we proposed a one-pass triplet construction strategy, aiming to quickly obtain all the triplets in a single pass over all data.", "startOffset": 68, "endOffset": 72}, {"referenceID": 14, "context": "Inspired by the impressive scalability of one-pass strategies [13], [14], [15], we proposed a one-pass triplet construction strategy, aiming to quickly obtain all the triplets in a single pass over all data.", "startOffset": 74, "endOffset": 78}, {"referenceID": 5, "context": "Thus, the online optimization formulation can be defined as follows by using Passive-Aggressive algorithm [6]: Lt = argmin L \u0393(L)", "startOffset": 106, "endOffset": 109}, {"referenceID": 3, "context": "(11) For normalized samples, namely 0 \u2264 \u2016xt\u2016 \u2264 1, the ranges of \u03bbmax(M1) and \u03bbmax(M2) vary from [0,4].", "startOffset": 96, "endOffset": 101}, {"referenceID": 15, "context": "[16] Given G and G + B as two nonsingular matrices, and let B have rank r > 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "Specifically, batch metric learning methods include: (1) Euclidean distance metric (Eucli for short); (2) Mahalanobis distance metric (Maha for short); (3) LMNN (Large Margin Nearest Neighbor) [10]; (4) ITML [5].", "startOffset": 193, "endOffset": 197}, {"referenceID": 4, "context": "Specifically, batch metric learning methods include: (1) Euclidean distance metric (Eucli for short); (2) Mahalanobis distance metric (Maha for short); (3) LMNN (Large Margin Nearest Neighbor) [10]; (4) ITML [5].", "startOffset": 208, "endOffset": 211}, {"referenceID": 1, "context": "OML methods include: (1) OASIS [2]; (2) RDML [4]; (3) POLA", "startOffset": 31, "endOffset": 34}, {"referenceID": 3, "context": "OML methods include: (1) OASIS [2]; (2) RDML [4]; (3) POLA", "startOffset": 45, "endOffset": 48}, {"referenceID": 0, "context": "[1]; (4) LEGO [3]; (5) SOML-TG (SOML for short) [7].", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[1]; (4) LEGO [3]; (5) SOML-TG (SOML for short) [7].", "startOffset": 14, "endOffset": 17}, {"referenceID": 6, "context": "[1]; (4) LEGO [3]; (5) SOML-TG (SOML for short) [7].", "startOffset": 48, "endOffset": 51}, {"referenceID": 2, "context": "Since the pairwise or triplet constraints of POLA, LEGO and SOML need to be constructed in advance, we randomly sample 10000 constraints for these three methods (same setting as LEGO [3]).", "startOffset": 183, "endOffset": 186}, {"referenceID": 16, "context": "Face Verification: PubFig For face verification, we first evaluate our methods on the Public Figures Face Database (PubFig) [17].", "startOffset": 124, "endOffset": 128}, {"referenceID": 16, "context": "Following [17], we use the development set to develop all these methods, including parameters tuning, while the evaluation set is used for performance evaluation.", "startOffset": 10, "endOffset": 14}, {"referenceID": 16, "context": "[17] are \u2019high-level\u2019 features describing nameable attributes such as gender, race, age, hair etc.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "For deep features, we use a VGG-Face model [18] to extract a 4096-dimensional feature for each face image which has been aligned and cropped.", "startOffset": 43, "endOffset": 47}, {"referenceID": 0, "context": "Then, all the distances (similarities) are normalized into the range [0, 1].", "startOffset": 69, "endOffset": 75}, {"referenceID": 18, "context": "Face Verification: LFW For face verification, we also evaluate our methods on the Labeled Faces in the Wild Database (LFW) [19].", "startOffset": 123, "endOffset": 127}, {"referenceID": 1, "context": ", OASIS [2], SOML [7]) are triplet-based methods, we adopt the image unrestricted configuration to construct the experiment.", "startOffset": 8, "endOffset": 11}, {"referenceID": 6, "context": ", OASIS [2], SOML [7]) are triplet-based methods, we adopt the image unrestricted configuration to construct the experiment.", "startOffset": 18, "endOffset": 21}, {"referenceID": 19, "context": "[20] by extracting SIFT descriptors [21] at 9 fixed facial landmarks detected on a face, over three scales.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[20] by extracting SIFT descriptors [21] at 9 fixed facial landmarks detected on a face, over three scales.", "startOffset": 36, "endOffset": 40}, {"referenceID": 16, "context": "Like PubFig, the attribute features of LFW are 73-dimensional \u2019high-level\u2019 features describing the nameable attributes of a face image [17].", "startOffset": 135, "endOffset": 139}, {"referenceID": 4, "context": "The results of ITML [5] aren\u2019t displayed for its difficulty of convergence in the training data.", "startOffset": 20, "endOffset": 23}, {"referenceID": 21, "context": "For each patch, the MHOF (Multi-scale Histogram of Optical Flow) feature [22] was extracted from every two successive frames.", "startOffset": 73, "endOffset": 77}, {"referenceID": 22, "context": "Method AUC Optical flow [23] 0.", "startOffset": 24, "endOffset": 28}, {"referenceID": 22, "context": "84 (average) Social Force [23] 0.", "startOffset": 26, "endOffset": 30}, {"referenceID": 23, "context": "96 (average) Chaotic Invariants [24] 0.", "startOffset": 32, "endOffset": 36}, {"referenceID": 24, "context": "99 (average) LSA [25] 0.", "startOffset": 17, "endOffset": 21}, {"referenceID": 13, "context": "985(average) STCOG [14] 0.", "startOffset": 19, "endOffset": 23}, {"referenceID": 21, "context": "966 Sparse [22] 0.", "startOffset": 11, "endOffset": 15}, {"referenceID": 25, "context": "964 MP-MIDL [26] 0.", "startOffset": 12, "endOffset": 16}, {"referenceID": 26, "context": "99 SVDD-based [27] 0.", "startOffset": 14, "endOffset": 18}, {"referenceID": 27, "context": "The regret can be defined (according to the definition of Chapter 3 in [28]) as below:", "startOffset": 71, "endOffset": 75}], "year": 2016, "abstractText": "To achieve a low computational cost when performing online metric learning for large-scale data, we present a onepass closed-form solution namely OPML in this paper. Typically, the proposed OPML first adopts a one-pass triplet construction strategy, which aims to use only a very small number of triplets to approximate the representation ability of whole original triplets obtained by batch-manner methods. Then, OPML employs a closed-form solution to update the metric for new coming samples, which leads to a low space (i.e., O(d)) and time (i.e., O(d)) complexity, where d is the feature dimensionality. In addition, an extension of OPML (namely COPML) is further proposed to enhance the robustness when in real case the first several samples come from the same class (i.e., cold start problem). In the experiments, we have systematically evaluated our methods (OPML and COPML) on three typical tasks, including UCI data classification, face verification, and abnormal event detection in videos, which aims to fully evaluate the proposed methods on different sample number, different feature dimensionalities and different feature extraction ways (i.e., hand-crafted and deeplylearned). The results show that OPML and COPML can obtain the promising performance with a very low computational cost. Also, the effectiveness of COPML under the cold start setting is experimentally verified.", "creator": "LaTeX with hyperref package"}}}