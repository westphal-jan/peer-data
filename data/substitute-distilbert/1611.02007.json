{"id": "1611.02007", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Nov-2016", "title": "Keyphrase Annotation with Graph Co-Ranking", "abstract": "keyphrase annotation is the task of identifying textual units that represent the descriptive content of a document. keyphrase annotation is either carried out variously extracting the most specific phrases from a document, keyphrase reduction, or by assigning entries from a controlled domain - specific vocabulary, keyphrase assignment. compilation methods are consistently more reliable. they provide better - formed keyphrases, as well as keyphrases that happen not occur in a document. but they function often silent on the contrary of extraction methods that don't depend on manually built dictionary. this paper proposes a functional method to perform both keyphrase extraction and equation derivation in an integrated and mutual reinforcing manner. experiments have been carried out on datasets covering different domains of humanities among creative sciences. they show statistically stable scores compared when both keyphrase extraction and type assignment state - of - the art methods.", "histories": [["v1", "Mon, 7 Nov 2016 12:08:13 GMT  (150kb)", "http://arxiv.org/abs/1611.02007v1", "Accepted at the COLING 2016 conference"]], "COMMENTS": "Accepted at the COLING 2016 conference", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["adrien bougouin", "florian boudin", "b\\'eatrice daille"], "accepted": false, "id": "1611.02007"}, "pdf": {"name": "1611.02007.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["adrien.bougouin@univ-nantes.fr", "florian.boudin@univ-nantes.fr", "beatrice.daille@univ-nantes.fr"], "sections": [{"heading": null, "text": "ar X\niv :1\n61 1.\n02 00\n7v 1\n[ cs\n.C L\n] 7\nN ov\n2 01\n6"}, {"heading": "1 Introduction", "text": "Keyphrases are words and phrases that give a synoptic picture of what is important within a document. They are useful in many tasks such as document indexing (Gutwin et al., 1999), text categorization (Hulth and Megyesi, 2006) or summarization (Litvak and Last, 2008). However, most documents do not provide keyphrases, and the daily flow of new documents makes the manual keyphrase annotation impractical. As a consequence, automatic keyphrase annotation has received special attention in the NLP community and many methods have been proposed (Hasan and Ng, 2014).\nThe task of automatic keyphrase annotation consists in identifying the main concepts, or topics, addressed in a document. Such task is crucial to access relevant scientific documents that could be useful for researchers. Keyphrase annotation methods fall into two broad categories: keyphrase extraction and keyphrase assignment methods. Keyphrase extraction methods extract the most important words or phrases occurring in a document, while assignment methods provide controlled keyphrases from a domain-specific terminology (controlled vocabulary).\nThe automatic keyphrase annotation task is often reduced to the sole keyphrase extraction task. Unlike assignment methods, extraction methods do not require domain specific controlled vocabularies that are costly to create and to maintain. Furthermore, they are able to identify new concepts that have not been yet recorded in the thesaurus or ontologies. However, extraction methods often output ill-formed or inappropriate keyphrases (Medelyan and Witten, 2008), and they produce only keyphrases that actually occur in the document.\nObservations made on manually assigned keyphrases from scientific papers of specialized domains show that professional human indexers both extract keyphrases from the content of the document and assign keyphrases based on their knowledge of the domain (Liu et al., 2011). Here, we propose an approach that mimics this behaviour and jointly extracts and assigns keyphrases. We use two graph representations, one for the document and one for the specialized domain. Then, we apply a co-ranking algorithm to perform both keyphrase extraction and assignment in a mutually reinforcing manner. We perform\nThis work is licensed under a Creative Commons Attribution 4.0 International Licence. Licence details: http://creativecommons.org/licenses/by/4.0/\nexperiments on bibliographic records in three domains belonging to humanities and social sciences: linguistics, information science and archaeology. Along with this approach come two contributions. First, we present a simple yet efficient assignment extension of a state-of-the-art graph-based keyphrase extraction method, TopicRank (Bougouin et al., 2013). Second, we circumvent the need for a controlled vocabulary by leveraging reference keyphrases from training data and further take advantage of their relationship within the training data."}, {"heading": "2 Related Work", "text": ""}, {"heading": "2.1 Keyphrase extraction", "text": "Keyphrase extraction is the most common approach to tackle the automatic keyphrase annotation task. Previous work includes many approaches (Hasan and Ng, 2014), from statistical ranking (Salton et al., 1975) to binary classification (Witten et al., 1999), through graph-based ranking (Mihalcea and Tarau, 2004) of keyphrase candidates. As our approach uses graph-based ranking, we focus on the latter. For a detailed overview of keyphrase extraction methods, refer to (Hasan and Ng, 2010; Hasan and Ng, 2014).\nSince the seminal work of Mihalcea and Tarau (2004), graph-based ranking approaches to keyphrase extraction are becoming increasingly popular. The original idea behind these approaches is to build a graph from the document and rank its nodes according to their importance using centrality measures.\nIn TextRank (Mihalcea and Tarau, 2004), the input document is represented as a co-occurrence graph in which nodes are words. Two words are connected by an edge if they co-occur in a fixed-sized window of words. A random walk algorithm is used to iteratively rank the words, then extract the keyphrases by concatenating the most important words.\nThe random walk algorithm simulates the \u201cvoting concept\u201d, or recommendation: a node is important if it is connected to many other nodes, and if many of those are important. Thus, let G \u201c pV,Eq be an undirected graph with a set of vertices V and a set of edges E, and let Epviq be the set of nodes connected to the node vi. The score Spviq of a vertex vi is initialized to 1 and computed iteratively until convergence using the following equation:\nSpviq \u201c p1\u00b4 \u03bbq ` \u03bb \u00ff\nvjPEpviq\nSpvjq\n|Epvjq| (1)\nwhere \u03bb is a damping factor that has been set to 0.85 by Brin and Page (1998) for a trade-off between ranking accuracy and fast convergence.\nFollowing up the work of Mihalcea and Tarau (2004), Wan and Xiao (2008) added edge weights (cooccurrence numbers) to the random walk and further improved the graph with co-occurrence information borrowed from similar documents. To extract keyphrases from a document, they first look for five similar documents, then use them to add new edges between words within the graph and reinforce the weight of existing edges. Liu et al. (2010) biased multiple graphs with topic probabilities drawn from LDA (Latent Dirichlet Allocation) (Blei et al., 2003), to rank the words regarding each graph and to merge the rankings together. This method performs as many rankings as the number of topics and gives higher importance scores to high-ranking words for as many topics as possible. By doing so, Liu et al. (2010) increase the topic coverage provided by the extracted keyphrases.\nMost recently, Zhang et al. (2013) and Bougouin et al. (2013) explored further the value of topics for keyphrase extraction. Zhang et al. (2013) used graph co-ranking to improve the method of Liu et al. (2010) by introducing LDA topics right inside the graph. Bougouin et al. (2013) proposed to represent topics as clusters of similar keyphrase candidates within the document (i.e. words and phrases from the document), to rank these topics instead of the words and to extract the most representative candidate as keyphrase for each important topic. As our work extends that of Bougouin et al. (2013), we present a detailed description of their method in Section 3.1."}, {"heading": "2.2 Keyphrase assignment", "text": "Keyphrase assignment provides keyphrases for every document of a specific domain using a controlled vocabulary. Dissimilar to keyphrase extraction, keyphrase assignment also aims to provide keyphrases that do not occur within the document. This task is more difficult than keyphrase extraction and has, therefore, seldom been employed for automatic keyphrase annotation. The state-of-the art method for keyphrase assignment is KEA++ (Medelyan and Witten, 2006).\nKEA++ uses a domain-specific thesaurus to assign keyphrases to a document. First, keyphrase candidates are selected among the n-grams of the document. N-grams that do not match a thesaurus entry are either removed or substituted by a synonym that matches a thesaurus entry. This candidate selection approach induces a limitation of keyphrase assignment, refered to as keyphrase indexing by Medelyan and Witten (2006), because it only assigns keyphrases if they occur within the document. Second, KEA++ exploits the semantic relationships between keyphrase candidates within the thesaurus as the main feature of a Naive Bayes classifier. Compared to similar methods without domain specific resources, KEA++ achieves better performance. However, such resources are not readily available for most domains, and if so, they could be quickly out of date. The application scenario of KEA++ are thus restricted.\nOur proposition is to model with graphs both keyphrase extraction and assignment and to take benefit of this unified modelling to perform accurate keyphrase annotation."}, {"heading": "3 Co-ranking for Keyphrase Annotation", "text": "This section presents TopicCoRank1, our keyphrase annotation method built on the existing method TopicRank (Bougouin et al., 2013) to which we add keyphrase assignment. We first detail TopicRank, then present our contributions."}, {"heading": "3.1 TopicRank", "text": "TopicRank is a graph-based keyphrase extraction method that relies on the following five steps:\n1. Keyphrase candidate selection. Following previous work (Hasan and Ng, 2010; Wan and Xiao, 2008), keyphrase candidates are selected from the sequences of adjacent nouns and adjectives that occur within the document (/(N|A)+/).\n2. Topical clustering. Similar keyphrase candidates c are clustered into topics based on the words they share. Bougouin et al. (2013) use a Hierarchical Agglomerative Clustering (HAC) with a stem overlap similarity (see equation 2) and an average linkage. At the beginning, each keyphrase candidate is a single cluster, then candidates sharing an average of 1{4 stemmed words with the candidates of another cluster are iteratively added to the latter.\nsimpci, cjq \u201c |stemspciq X stemspcjq| |stemspciq Y stemspcjq|\n(2)\nwhere stemspciq is the set of stemmed words of the keyphrase candidate ci.\n3. Graph construction. A complete graph is built, in which nodes are topics and edges are weighted according to the strength of the semantic relation between the connected topics. The closer are the pairs of candidates xci, cjy of two topics ti and tj within the document, the stronger is their semantic relation wi,j:\nwi,j \u201c \u00ff\nciPti\n\u00ff\ncjPtj\ndistpci, cjq (3)\ndistpci, cjq \u201c \u00ff\npiPpospciq\n\u00ff\npjPpospcjq\n1\n|pi \u00b4 pj | (4)\n1TopicCoRank is open source and publicly available at https://github.com/adrien-bougouin/KeyBench/tree/coling_2016/\nwhere pospciq represents all of the offset positions of the first word of the keyphrase candidate ci.\n4. Topic ranking. Topics t are ranked using the importance score Sptiq of the TextRank formula, as modified by Wan and Xiao (2008) to leverage edge weights:\nSptiq \u201c p1\u00b4 \u03bbq ` \u03bb \u00ff\ntjPEptiq\nwijSptjq \u00ff\ntkPEptjq\nwjk (5)\n5. Keyphrase selection. One keyphrase candidate is selected from each of the N most important topics: the first occurring keyphrase candidate.\nOur work extends TopicRank to assign domain-specific keyphrases that do not necessarily occur within the document. First, we add a second graph representing the domain and unify it to the topic graph. Second, we define a co-ranking scheme that leverages the new graph. Finally, we redefine the keyphrase selection step for both extracting and assigning keyphrases."}, {"heading": "3.2 Unified graph construction", "text": "TopicCoRank operates over a unified graph that connects two graphs representing the document topics, the controlled keyphrases and the relations between them (see Fig. 1). The controlled keyphrases are the keyphrases that were manually assigned to training documents. Considering the manually assigned keyphrases as the controlled vocabulary circumvents the need for a manually produced controlled vocabulary and also allows us to further take advantage of the semantic relatonship between the domainspecific (controlled) keyphrases. Because controlled keyphrases are presumably non-redundant, we do not topically cluster them as we do for keyphrase candidates.\nLet G \u201c pV \u201c T Y K,E \u201c Ein Y Eoutq denote the unified graph. Topics T \u201c tt1, t2, ..., tnu and controlled keyphrases K \u201c tk1, k2, ..., kmu are vertices V connected to their fellows by edges Ein \u010e T \u02c6 T YK \u02c6K and connected to the other vertices by edges Eout \u010e K \u02c6 T (see Fig. 1).\nTo unify the two graphs, we consider the controlled keyphrases as a category map and connect the document to its potential categories. We create an unweighted edge xki, tjy P Eout to connect a controlled keyphrase ki and a topic tj if the controlled keyphrase is a member of the topic, i.e. a keyphrase candidate of the topic2. We create an edge xti, tjy P Ein or xki, kjy P Ein between two topics ti and tj or two controlled keyphrases ki and kj when they co-occur within a sentence of the document or as keyphrases of a training document, respectively. Edges xti, tjy P Ein are weighted by the number of times (wi,j) topics ti and tj occur in the same sentence within the document. Edges xki, kjy P Ein are weighted by the number of times (wi,j) keyphrases ki and kj are associated to the same document among the training documents. Doing so, the weighting scheme of edges Ein is equivalent for both topics and controlled keyphrases. This equivalence is essential to ensure that not only controlled keyphrases occurring in the document can be assigned by properly co-ranking topics and controlled keyphrases.\n2To accept inflexions, such as plural inflexions, we follow Bougouin et al. (2013) and perform the comparison with stems."}, {"heading": "3.3 Graph-based co-ranking", "text": "TopicCoRank gives an importance score Sptiq or Spkiq to every topic or controlled keyphrase using graph co-ranking (see equations 6 and 7). Our graph co-ranking simulates the voting concept based on inner and outer recommendations.\nThe inner recommendation is similar to the recommendation computed in previous work (Bougouin et al., 2013; Mihalcea and Tarau, 2004; Wan and Xiao, 2008). The inner recommendation Rin comes from nodes of the same graph (see equation 8). A topic or a controlled keyphrase is important if it is strongly connected to other topics or controlled keyphrases, respectively.\nThe outer recommendation influences the ranking of topics by controlled keyphrases and of controlled keyphrases by topics. The outer recommendation Rout comes from nodes of the other graph (see equation 9). A topic or a controlled keyphrase gain more importance if it is connected to important controlled keyphrases or an important topic, respectively.\nSptiq \u201c p1\u00b4 \u03bbtq Routptiq ` \u03bbt Rinptiq (6)\nSpkiq \u201c p1\u00b4 \u03bbkq Routpkiq ` \u03bbk Rinpkiq (7)\nRinpviq \u201c \u00ff\nvjPEinpviq\nwijSpvjq \u00ff\nvkPEinpvjq\nwjk (8)\nRoutpviq \u201c \u00ff\nvjPEoutpviq\nSpvjq\n|Eoutpvjq| (9)\nwhere vi is a node representing a keyphrase or a topic. \u03bbt and \u03bbk are parameters that control the influence of the inner recommendation over the outer recommendation (0 \u010f \u03bbt \u010f 1 and 0 \u010f \u03bbk \u010f 1) for the topics and the controlled keyphrases, respectively."}, {"heading": "3.4 Keyphrase annotation", "text": "Keyphrases are extracted and assigned from the N-best ranked topics and controlled keyphrases, regardless of their nature.\nWe extract topic keyphrases using the former TopicRank strategy. Only one keyphrase is extracted per topic: the keyphrase candidate that first occurs within the document.\nWe assign controlled keyphrases only if they are directly or transitively connected to a topic of the document. If the ranking of a controlled keyphrase has not been affected by a topic of the document nor by controlled keyphrases connected to topics, then its importance score is not related to the content of the document and it should not be assigned.\nAt this step, two variants of TopicCoRank performing either extraction or assignment can be proposed, namely TopicCoRankextr and TopicCoRankassign. If keyphrases are only extracted from the topics, we obtain TopicCoRankextr . If keyphrases are only assigned from the controlled keyphrases, we obtain TopicCoRankassign."}, {"heading": "4 Experimental Setup", "text": ""}, {"heading": "4.1 Datasets", "text": "We conduct our experiments on data from the DEFT-2016 benchmark datasets (Daille et al., 2016)3 in three domains: linguistics, information Science and archaeology. Table 1 shows the factual information\n3Data has been provided by the TermITH project for both DEFT-2016 and this work. Parallely, the subset division has been modified for the purpose of DEFT-2016. Therefore, we use the same data as DEFT2016, but the subset division is different. The subset division we used for our experiences can be found here: https://github.com/adrien-bougouin/KeyBench/tree/coling_2016/datasets/\nabout the datasets. Each dataset is a collection of 706 up to 718 French bibliographic records collected from the database of the French Institute for Scientific and Technical Information4 (Inist). The bibliographic records contain a title of one scientific paper, its abstract and its keyphrases that were annotated by professional indexers (one per bibliographic record). Indexers were given the instruction to assign reference keyphrases from a controlled vocabulary and to extract new concepts or very specific keyphrases from the titles and the abstracts. Each dataset is divided into three sets: a test set, used for evaluation; a training set (denoted as train), used to represent the domain; and a development set (denoted as dev), used for parameter tuning.\nThe amount of missing keyphrases, i.e. keyphrases that cannot be extracted from the documents, shows the importance of keyphrase assignment in the context of scientific domains. More than half of the keyphrases of linguistics and information science domains can only be assigned, which confirms that these two datasets are difficult to process with keyword extraction approaches alone."}, {"heading": "4.2 Document preprocessing", "text": "We apply the following preprocessing steps to each document: sentence segmentation, word tokenization and Part-of-Speech (POS) tagging. Sentence segmentation is performed with the PunktSentenceTokenizer provided by the Python Natural Language ToolKit (NLTK) (Bird et al., 2009), word tokenization using the Bonsai word tokenizer5 and POS tagging with MElt (Denis and Sagot, 2009)."}, {"heading": "4.3 Baselines", "text": "To show the effectiveness of our approach, we compare TopicCoRank and its variants (TopicCoRankextr and TopicCoRankassign) with TopicRank and KEA++. For KEA++, we use the thesauri maintained by Inist6 to index the bibliographic records of Linguistics, Information Science and Archaeology."}, {"heading": "4.4 TopicCoRank setting", "text": "The \u03bbt and \u03bbk parameters of TopicCoRank were tuned on the development sets, and set to 0.1 and 0.5 respectively. This empirical setup means that the importance of topics is much more influenced by controlled keyphrases than other topics, and that the importance of controlled keyphrases is equally influenced by controlled keyphrases and topics. In other words, the domain has a positive influence on the joint task of keyphrase extraction and assignment."}, {"heading": "5 Experimental Results", "text": "This section presents and analyses the results of our experiments. For each document of each dataset, we compare the keyphrases outputed by each method to the reference keyphrases of the document. From the comparisons, we compute the macro-averaged precision (P), recall (R) and f1-score (F) per dataset and per method.\n4http://www.inist.fr 5The Bonsai word tokenizer is a tool provided with the Bonsai PCFG-LA parser:\nhttp://alpage.inria.fr/statgram/frdep/fr_stat_dep_parsing.html 6Thesauri are available from: http://deft2016.univ-nantes.fr/download/traindev/"}, {"heading": "5.1 Macro-averages results", "text": "Table 2 presents the macro-averaged precision, recall and f1-score in percentage when 10 keyphrases are extracted/assigned for each dataset by TopicRank, KEA++, TopicCoRankextr , TopicCoRankassign and TopicCoRank. First, we observe that the assignment baseline KEA++ mostly achieves the lowest performance, which is surprising compared to the performance reported by Medelyan and Witten (2006). The first reason for this observation is that KEA++ is restricted to thesauri entries while most keyphrases are missing within our documents. The second reason is that KEA++ relies on rich thesauri that contain an important amount of semantic relations between the entries, while our (real application) thesauri have a modest amount of semantic relations between the entries.\nOverall, using graph co-ranking significantly outperforms TopicRank and KEA++. Comparing TopicRank to TopicCoRankextr shows the positive influence of the domain (controlled keyphrases) on the ranking of the topics. TopicCoRankassign outperforms every method, including TopicCoRankextr and TopicCoRank. Controlled keyphrases are efficiently ranked and the predominance of missing keyphrases in the dataset leads to a better performance of TopicCoRankassign over TopicCoRank."}, {"heading": "5.2 Precision/recall curves", "text": "Additionally, we follow Hasan and Ng (2010) and analyse the precision-recall curves of TopicRank, KEA++ and TopicCoRank. To generate the curves, we vary the number of evaluated keyphrases (cutoff) from 1 to the total number of extracted/assigned keyphrases and compute the precision and recall for each cut-off. Such representation gives a good appreciation of the advantage of a method compared to others, especially if the other methods achieve performances in the Area Under the Curve (AUC).\nFigure 2 shows the precision/recall curves of TopicRank, KEA++ and TopicCoRank on each dataset. The final recall for the methods does not reach 100% because the candidate selection method does not provide keyphrases that do not occur within the document, as well as candidates that do not fit the POS tag pattern /(N|A)+/. Also, because TopicRank and TopicCoRank topically cluster keyphrase candidates\nand output only one candidate per topic, their final recall is lowered every time a wrong keyphrase is chosen over a correct one from the topic.\nWe observe that the curve for TopicCoRank is systematically above the others, thus showing improvements in the area under the curve and not just in point estimate such as f1-score. Also, the final recall of TopicCoRank is much higher than the final recall of TopicRank and KEA++."}, {"heading": "5.3 Extraction vs. assignment", "text": "As TopicCoRank is the first method for simultaneously extracting and assigning keyphrases, we perform an additional experiment that shows to which extent extraction and assignment contribute to the final results. To do so, we show the behavior of the extraction and the assignment depending on the influence of the inner recommendation on the ranking for each (test) document of each dataset.\nFig. 3 shows the behavior of TopicCoRankextr when \u03bbt varies from 0 to 1. When \u03bbt \u201c 0, only the domain influences the ranking of the topics. Slightly equivalent to KEA++, TopicCoRankextr with \u03bbt \u201c 0 mainly extracts keyphrases from topics connected to controlled keyphrases. When \u03bbt \u201c 1, the domain does not influence the ranking and the performance of TopicCoRankextr is in the range of TopicRank\u2019s performance. Overall, the performance curve of TopicCoRankextr decreases while \u03bbt increases. Thus, the experiment demonstrates that the domain has a positive influence on the keyphrase extraction.\nFig. 4 shows the behavior of TopicCoRankassign when \u03bbk varies from 0 to 1. When \u03bbk \u201c 0, only the document influences the ranking of the controlled keyphrases. As for TopicCoRankextr when \u03bbt \u201c 0, TopicCoRankassign is slightly similar to KEA++ when \u03bbk \u201c 0. When \u03bbk \u201c 1, TopicCoRankassign always outputs the same keyphrases: the ones that are the most important in the domain. The first half of the curve increases, showing that the relations between the controlled keyphrases have a positive influence on the ranking of the controlled keyphrases. Conversely, the second half of the curve decreases. Thus, the sole domain is not sufficient for keyphrase annotation."}, {"heading": "5.4 Qualitative example", "text": "To show the benefit of TopicCoRank, we compare it to TopicRank on one of our bibliographic records in Linguistics (see Figure 5). Over the nine reference keyphrases, TopicRank successfully identifies two of the reference keyphrases: \u201clexical semantics\u201d and \u201csemantic variation\u201d. TopicCoRank successfully identifies seven of them: \u201clexical semantics\u201d, \u201cverb\u201d, \u201csemantic variation\u201d, \u201cFrench\u201d, \u201csyntax\u201d, \u201csemantic interpretation\u201d and \u201cdistributional analysis\u201d.\nTopicCoRank mostly outperforms TopicRank because it finds keyphrases that do not occur within the document: \u201cFrench\u201d, \u201csyntax\u201d, \u201csemantic interpretation\u201d, and \u201cdistributional analysis\u201d. Some keyphrases, such as \u201cFrench\u201d, are frequently assigned because they are part of most of the bibliographic records of our dataset7 (48.9% of the Linguistics records contain \u201cFrench\u201d as a keyphrase); Other keyphrases, such as \u201csemantic interpretation\u201d, are assigned thanks to their strong connection with controlled keyphrases occurring in the abstract (e.g. \u201clexical semantics\u201d).\nInterestingly, the performance of TopicCoRank is not only better thanks to the assignment. For instance, we observe keyphrases, such as \u201cverb\u201d, that emerge from topics connected to other topics that distribute importance from controlled keyphrases (e.g. \u201csemantic variation\u201d)."}, {"heading": "6 Conclusion", "text": "In this paper, we have proposed a co-ranking approach to performing keyphrase extraction and keyphrase assignment jointly. Our method, TopicCoRank, builds two graphs: one with the document topics and one with controlled keyphrases (training keyphrases). We designed a strategy to unify the two graphs and rank by importance topics and controlled keyphrases using a co-ranking vote. We performed experiments on three datasets of different domains. Results showed that our approach benefits from both controlled keyphrases and document topics, improving both keyphrase extraction and keyphrase assignment baselines. TopicCoRank can be used to annotate keyphrases in scientific domains in a close way of professional indexers."}, {"heading": "Acknowledgments", "text": "This work was supported by the French National Research Agency (TermITH project \u2013 ANR-12-CORD-0029) and by the TALIAS project (grant of CNRS PEPS INS2I 2016, https://boudinfl.github.io/talias/).\n7Yet, TopicCoRank does not assign \u201cFrench\u201d to every bibliographic records."}], "references": [{"title": "Latent Dirichlet Allocation", "author": ["Blei et al.2003] David M. Blei", "Andrew Y. Ng", "Michael I. Jordan"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Blei et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Blei et al\\.", "year": 2003}, {"title": "TopicRank: Graph-Based Topic Ranking for Keyphrase Extraction", "author": ["Florian Boudin", "B\u00e9atrice Daille"], "venue": "In Proceedings of the 6th International Joint Conference on Natural Language Processing (IJCNLP),", "citeRegEx": "Bougouin et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bougouin et al\\.", "year": 2013}, {"title": "The Anatomy of a Large-Scale Hypertextual Web Search Engine", "author": ["Brin", "Page1998] Sergey Brin", "Lawrence Page"], "venue": "Computer Networks and ISDN Systems,", "citeRegEx": "Brin et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Brin et al\\.", "year": 1998}, {"title": "Indexation d\u2019articles scientifiques pr\u00e9sentation et r\u00e9sultats du d\u00e9fi fouille de textes deft 2016", "author": ["Sabine Barreaux", "Florian Boudin", "Adrien Bougouin", "Damien Cram", "Amir Hazem"], "venue": "In Actes de 12e De\u0301fi Fouille de Texte (DEFT),", "citeRegEx": "Daille et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Daille et al\\.", "year": 2016}, {"title": "Coupling an Annotated Corpus and a Morphosyntactic Lexicon for State-of-the-Art POS Tagging with Less Human Effort", "author": ["Denis", "Sagot2009] Pascal Denis", "Beno\u0131\u0302t Sagot"], "venue": "In Proceedings of the 23rd Pacific Asia Conference on Language, Information and Computation (PACLIC),", "citeRegEx": "Denis et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Denis et al\\.", "year": 2009}, {"title": "Improving Browsing in Digital Libraries with Keyphrase Indexes", "author": ["Gutwin et al.1999] Carl Gutwin", "Gordon Paynter", "Ian Witten", "Craig Nevill Manning", "Eibe Frank"], "venue": "Decision Support Systems,", "citeRegEx": "Gutwin et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Gutwin et al\\.", "year": 1999}, {"title": "Conundrums in Unsupervised Keyphrase Extraction: Making Sense of the State-of-the-Art", "author": ["Hasan", "Ng2010] Kazi Saidul Hasan", "Vincent Ng"], "venue": "In Proceedings of the 23rd International Conference on Computational Linguistics: Posters (COLING),", "citeRegEx": "Hasan et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Hasan et al\\.", "year": 2010}, {"title": "Automatic Keyphrase Extraction: A Survey of the State of the Art", "author": ["Hasan", "Ng2014] Kazi Saidul Hasan", "Vincent Ng"], "venue": "In Proceedings of the Association for Computational Linguistics (ACL),", "citeRegEx": "Hasan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hasan et al\\.", "year": 2014}, {"title": "A study on automatically extracted keywords in text categorization", "author": ["Hulth", "Megyesi2006] Anette Hulth", "Be\u00e1ta B. Megyesi"], "venue": "In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Hulth et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hulth et al\\.", "year": 2006}, {"title": "Graph-Based Keyword Extraction for SingleDocument Summarization", "author": ["Litvak", "Last2008] Marina Litvak", "Mark Last"], "venue": "In Proceedings of the Workshop on Multi-Source Multilingual Information Extraction and Summarization,", "citeRegEx": "Litvak et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Litvak et al\\.", "year": 2008}, {"title": "Automatic Keyphrase Extraction Via Topic Decomposition", "author": ["Liu et al.2010] Zhiyuan Liu", "Wenyi Huang", "Yabin Zheng", "Maosong Sun"], "venue": "In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing(EMNLP),", "citeRegEx": "Liu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2010}, {"title": "Automatic Keyphrase Extraction by Bridging Vocabulary Gap", "author": ["Liu et al.2011] Zhiyuan Liu", "Xinxiong Chen", "Yabin Zheng", "Maosong Sun"], "venue": "In Proceedings of the 15th Conference on Computational Natural Language Learning,", "citeRegEx": "Liu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2011}, {"title": "Thesaurus Based Automatic Keyphrase Indexing", "author": ["Medelyan", "Witten2006] Olena Medelyan", "Ian H Witten"], "venue": "In Proceedings of the 6th ACM/IEEE-CS joint conference on Digital libraries,", "citeRegEx": "Medelyan et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Medelyan et al\\.", "year": 2006}, {"title": "Domain-Independent Automatic Keyphrase Indexing with Small Training Sets", "author": ["Medelyan", "Witten2008] Olena Medelyan", "Ian H. Witten"], "venue": "Journal of the American Society for Information Science and Technology,", "citeRegEx": "Medelyan et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Medelyan et al\\.", "year": 2008}, {"title": "TextRank: Bringing Order Into Texts", "author": ["Mihalcea", "Tarau2004] Rada Mihalcea", "Paul Tarau"], "venue": "Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Mihalcea et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Mihalcea et al\\.", "year": 2004}, {"title": "A Vector Space Model for Automatic Indexing", "author": ["Salton et al.1975] Gerard Salton", "Andrew Wong", "Chungshu Yang"], "venue": "Communication ACM,", "citeRegEx": "Salton et al\\.,? \\Q1975\\E", "shortCiteRegEx": "Salton et al\\.", "year": 1975}, {"title": "Single Document Keyphrase Extraction Using Neighborhood Knowledge", "author": ["Wan", "Xiao2008] Xiaojun Wan", "Jianguo Xiao"], "venue": "In Proceedings of the 23rd National Conference on Artificial Intelligence - Volume", "citeRegEx": "Wan et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Wan et al\\.", "year": 2008}, {"title": "KEA: Practical Automatic Keyphrase Extraction", "author": ["Witten et al.1999] Ian H. Witten", "Gordon W. Paynter", "Eibe Frank", "Carl Gutwin", "Craig G. Nevill Manning"], "venue": "In Proceedings of the 4th ACM Conference on Digital Libraries,", "citeRegEx": "Witten et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Witten et al\\.", "year": 1999}, {"title": "WordTopic-MultiRank: A New Method for Automatic Keyphrase Extraction", "author": ["Zhang et al.2013] Fan Zhang", "Lian\u2019en Huang", "Bo Peng"], "venue": "In Proceedings of the Sixth International Joint Conference on Natural Language Processing,", "citeRegEx": "Zhang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 5, "context": "They are useful in many tasks such as document indexing (Gutwin et al., 1999), text categorization (Hulth and Megyesi, 2006) or summarization (Litvak and Last, 2008).", "startOffset": 56, "endOffset": 77}, {"referenceID": 11, "context": "Observations made on manually assigned keyphrases from scientific papers of specialized domains show that professional human indexers both extract keyphrases from the content of the document and assign keyphrases based on their knowledge of the domain (Liu et al., 2011).", "startOffset": 252, "endOffset": 270}, {"referenceID": 1, "context": "First, we present a simple yet efficient assignment extension of a state-of-the-art graph-based keyphrase extraction method, TopicRank (Bougouin et al., 2013).", "startOffset": 135, "endOffset": 158}, {"referenceID": 15, "context": "Previous work includes many approaches (Hasan and Ng, 2014), from statistical ranking (Salton et al., 1975) to binary classification (Witten et al.", "startOffset": 86, "endOffset": 107}, {"referenceID": 17, "context": ", 1975) to binary classification (Witten et al., 1999), through graph-based ranking (Mihalcea and Tarau, 2004) of keyphrase candidates.", "startOffset": 33, "endOffset": 54}, {"referenceID": 15, "context": "Previous work includes many approaches (Hasan and Ng, 2014), from statistical ranking (Salton et al., 1975) to binary classification (Witten et al., 1999), through graph-based ranking (Mihalcea and Tarau, 2004) of keyphrase candidates. As our approach uses graph-based ranking, we focus on the latter. For a detailed overview of keyphrase extraction methods, refer to (Hasan and Ng, 2010; Hasan and Ng, 2014). Since the seminal work of Mihalcea and Tarau (2004), graph-based ranking approaches to keyphrase extraction are becoming increasingly popular.", "startOffset": 87, "endOffset": 462}, {"referenceID": 0, "context": "(2010) biased multiple graphs with topic probabilities drawn from LDA (Latent Dirichlet Allocation) (Blei et al., 2003), to rank the words regarding each graph and to merge the rankings together.", "startOffset": 100, "endOffset": 119}, {"referenceID": 8, "context": "Liu et al. (2010) biased multiple graphs with topic probabilities drawn from LDA (Latent Dirichlet Allocation) (Blei et al.", "startOffset": 0, "endOffset": 18}, {"referenceID": 0, "context": "(2010) biased multiple graphs with topic probabilities drawn from LDA (Latent Dirichlet Allocation) (Blei et al., 2003), to rank the words regarding each graph and to merge the rankings together. This method performs as many rankings as the number of topics and gives higher importance scores to high-ranking words for as many topics as possible. By doing so, Liu et al. (2010) increase the topic coverage provided by the extracted keyphrases.", "startOffset": 101, "endOffset": 378}, {"referenceID": 0, "context": "(2010) biased multiple graphs with topic probabilities drawn from LDA (Latent Dirichlet Allocation) (Blei et al., 2003), to rank the words regarding each graph and to merge the rankings together. This method performs as many rankings as the number of topics and gives higher importance scores to high-ranking words for as many topics as possible. By doing so, Liu et al. (2010) increase the topic coverage provided by the extracted keyphrases. Most recently, Zhang et al. (2013) and Bougouin et al.", "startOffset": 101, "endOffset": 479}, {"referenceID": 0, "context": "(2010) biased multiple graphs with topic probabilities drawn from LDA (Latent Dirichlet Allocation) (Blei et al., 2003), to rank the words regarding each graph and to merge the rankings together. This method performs as many rankings as the number of topics and gives higher importance scores to high-ranking words for as many topics as possible. By doing so, Liu et al. (2010) increase the topic coverage provided by the extracted keyphrases. Most recently, Zhang et al. (2013) and Bougouin et al. (2013) explored further the value of topics for keyphrase extraction.", "startOffset": 101, "endOffset": 506}, {"referenceID": 0, "context": "(2010) biased multiple graphs with topic probabilities drawn from LDA (Latent Dirichlet Allocation) (Blei et al., 2003), to rank the words regarding each graph and to merge the rankings together. This method performs as many rankings as the number of topics and gives higher importance scores to high-ranking words for as many topics as possible. By doing so, Liu et al. (2010) increase the topic coverage provided by the extracted keyphrases. Most recently, Zhang et al. (2013) and Bougouin et al. (2013) explored further the value of topics for keyphrase extraction. Zhang et al. (2013) used graph co-ranking to improve the method of Liu et al.", "startOffset": 101, "endOffset": 589}, {"referenceID": 0, "context": "(2010) biased multiple graphs with topic probabilities drawn from LDA (Latent Dirichlet Allocation) (Blei et al., 2003), to rank the words regarding each graph and to merge the rankings together. This method performs as many rankings as the number of topics and gives higher importance scores to high-ranking words for as many topics as possible. By doing so, Liu et al. (2010) increase the topic coverage provided by the extracted keyphrases. Most recently, Zhang et al. (2013) and Bougouin et al. (2013) explored further the value of topics for keyphrase extraction. Zhang et al. (2013) used graph co-ranking to improve the method of Liu et al. (2010) by introducing LDA topics right inside the graph.", "startOffset": 101, "endOffset": 654}, {"referenceID": 0, "context": "(2010) biased multiple graphs with topic probabilities drawn from LDA (Latent Dirichlet Allocation) (Blei et al., 2003), to rank the words regarding each graph and to merge the rankings together. This method performs as many rankings as the number of topics and gives higher importance scores to high-ranking words for as many topics as possible. By doing so, Liu et al. (2010) increase the topic coverage provided by the extracted keyphrases. Most recently, Zhang et al. (2013) and Bougouin et al. (2013) explored further the value of topics for keyphrase extraction. Zhang et al. (2013) used graph co-ranking to improve the method of Liu et al. (2010) by introducing LDA topics right inside the graph. Bougouin et al. (2013) proposed to represent topics as clusters of similar keyphrase candidates within the document (i.", "startOffset": 101, "endOffset": 727}, {"referenceID": 0, "context": "(2010) biased multiple graphs with topic probabilities drawn from LDA (Latent Dirichlet Allocation) (Blei et al., 2003), to rank the words regarding each graph and to merge the rankings together. This method performs as many rankings as the number of topics and gives higher importance scores to high-ranking words for as many topics as possible. By doing so, Liu et al. (2010) increase the topic coverage provided by the extracted keyphrases. Most recently, Zhang et al. (2013) and Bougouin et al. (2013) explored further the value of topics for keyphrase extraction. Zhang et al. (2013) used graph co-ranking to improve the method of Liu et al. (2010) by introducing LDA topics right inside the graph. Bougouin et al. (2013) proposed to represent topics as clusters of similar keyphrase candidates within the document (i.e. words and phrases from the document), to rank these topics instead of the words and to extract the most representative candidate as keyphrase for each important topic. As our work extends that of Bougouin et al. (2013), we present a detailed description of their method in Section 3.", "startOffset": 101, "endOffset": 1045}, {"referenceID": 1, "context": "3 Co-ranking for Keyphrase Annotation This section presents TopicCoRank1, our keyphrase annotation method built on the existing method TopicRank (Bougouin et al., 2013) to which we add keyphrase assignment.", "startOffset": 145, "endOffset": 168}, {"referenceID": 1, "context": "3 Co-ranking for Keyphrase Annotation This section presents TopicCoRank1, our keyphrase annotation method built on the existing method TopicRank (Bougouin et al., 2013) to which we add keyphrase assignment. We first detail TopicRank, then present our contributions. 3.1 TopicRank TopicRank is a graph-based keyphrase extraction method that relies on the following five steps: 1. Keyphrase candidate selection. Following previous work (Hasan and Ng, 2010; Wan and Xiao, 2008), keyphrase candidates are selected from the sequences of adjacent nouns and adjectives that occur within the document (/(N|A)+/). 2. Topical clustering. Similar keyphrase candidates c are clustered into topics based on the words they share. Bougouin et al. (2013) use a Hierarchical Agglomerative Clustering (HAC) with a stem overlap similarity (see equation 2) and an average linkage.", "startOffset": 146, "endOffset": 739}, {"referenceID": 1, "context": "To accept inflexions, such as plural inflexions, we follow Bougouin et al. (2013) and perform the comparison with stems.", "startOffset": 59, "endOffset": 82}, {"referenceID": 1, "context": "The inner recommendation is similar to the recommendation computed in previous work (Bougouin et al., 2013; Mihalcea and Tarau, 2004; Wan and Xiao, 2008).", "startOffset": 84, "endOffset": 153}, {"referenceID": 3, "context": "1 Datasets We conduct our experiments on data from the DEFT-2016 benchmark datasets (Daille et al., 2016)3 in three domains: linguistics, information Science and archaeology.", "startOffset": 84, "endOffset": 105}], "year": 2016, "abstractText": "Keyphrase annotation is the task of identifying textual units that represent the main content of a document. Keyphrase annotation is either carried out by extracting the most important phrases from a document, keyphrase extraction, or by assigning entries from a controlled domain-specific vocabulary, keyphrase assignment. Assignment methods are generally more reliable. They provide better-formed keyphrases, as well as keyphrases that do not occur in the document. But they are often silent on the contrary of extraction methods that do not depend on manually built resources. This paper proposes a new method to perform both keyphrase extraction and keyphrase assignment in an integrated and mutual reinforcing manner. Experiments have been carried out on datasets covering different domains of humanities and social sciences. They show statistically significant improvements compared to both keyphrase extraction and keyphrase assignment state-of-the art methods.", "creator": "LaTeX with hyperref package"}}}