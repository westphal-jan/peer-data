{"id": "1611.07139", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Nov-2016", "title": "A Natural Language Query Interface for Searching Personal Information on Smartwatches", "abstract": "currently, personal assistant systems, relied on smartphones and use natural language interfaces. however, these systems rely much on the algorithm for finding information. rugged and wearable devices can collect an unprecedented amount of contextual personal data such as sleep and physical activities. artificial information objects and their applications are slowly becoming quantified - self, mobile health or food informatics, and they can be used to provide somehow deeper clues into our behavior. to our knowledge, existing personal assistant systems do rarely support all types of quantified - self queries. into response to this, we have invented a user study to interpret a set of \" textual questions / queries \" that users have able to search their quantified - self or mobile health data. meanwhile analyzing these questions, humans have constructed numerous light - weight natural language or query interface, including a text parser algorithm and a filter interface, to process the users'judgments that have been used for searching quantified - self information. this communication interface has been designed to operate on small devices, i. e. smartwatches, as well as augmenting the personal assistant systems by allowing them to process end users'natural language queries about their quantified - self variables.", "histories": [["v1", "Tue, 22 Nov 2016 03:42:44 GMT  (549kb)", "http://arxiv.org/abs/1611.07139v1", "6 pages, 4 figures, 2 tables"]], "COMMENTS": "6 pages, 4 figures, 2 tables", "reviews": [], "SUBJECTS": "cs.HC cs.CL cs.IR", "authors": ["reza rawassizadeh", "chelsea dobbins", "manouchehr nourizadeh", "zahra ghamchili", "michael pazzani"], "accepted": false, "id": "1611.07139"}, "pdf": {"name": "1611.07139.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "Keywords\u2014Quantified Self; Query; Natural Language Interface; Smartwatch\nI. INTRODUCTION & BACKGROUND Recently, we have observed the proliferation of personal assistant applications, such as Apple\u2019s Siri1, Google Google Now2 and Microsoft Cortana3. Devices that provide personal assistant (PA) services, especially smartphones, are usually pervasive, but have small displays, which leads to limited interaction facilities [1]. Moreover, PA systems are connected to the cloud, and often dynamically update the variety of services that they provide. However, frequently changing a graphical user interface (GUI), based on the newly supported services is not trivial, and thus it is not practical to use GUIs for PA systems. Therefore, existing implementations of these systems rely on voice user interfaces,\n1 www.apple.com/ios/siri 2 www.google.com/landing/now 3 www.microsoft.com/en-us/mobile/experiences/cortana\nwhich parse text at the end. This makes natural language interfaces (NLI) one of the most important components in a PA system. There are NLIs that host GUIs but they have significantly less flexibility in comparison to textual NLIs [2].\nIn other words, NLIs overcomes limitations of interacting with small pervasive displays. However, ubiquitous devices that host PA systems are capable of collecting detailed contextual information about their users, such as sleep patterns, physical activities, communications, etc. Nevertheless, existing PA services do not benefit from utilizing all of the existing data that is available. Only simple contextual data, such as the user\u2019s current location, is often used, and other data objects will be read from the web [3].\nWe have conducted a user study on Amazon Mechanical Turk. We have collected 716 sample queries from 131 participants, who have smartphones4. These participants are familiar with PA systems, but they may not necessarily be familiar with Quantified Self (QS) systems. Employing participants who are not familiar with these systems is an advantage of our user study. Those participants who are unfamiliar with QS systems have helped us to identify queries, which have not been addressed by previous works, such as monitoring the usage of a cloth before washing it, or measuring the amount of radiation produced by smartphones.\nPrevious QS based user studies [4, 5, 6] provide promising results, but they focus only on users who are familiar with QS systems. In particular, Li et al. [4] have identified information that are important for users, including status, history, goals, discrepancies, context, and factors. Choe et al. [5] have focused on what QS users have learnt from collecting their data and how they perform the data collection. Oh et al. [6] have classified QS users and the issues that are associated with tracking. Rawassizadeh et al. [7] list challenges of collecting QS data and users\u2019 expectations from these systems. All of these works focus on identifying \u201cmotivation\u201d, \u201cchallenges\u201d and \u201copportunities\u201d that QS users\n4 To allow full reproducibility of our results MTurk dataset, implementation of the algorithm with the query interface are all available. Please contact the first author to get access.\nfaces, while using QS systems. We have benefited from their findings in framing our user study questions. However, our focus is on quantifying the QS users\u2019 request (queries) from the system.\nIn this work, we propose a novel query interface for searching QS information. To implement this interface, first we need to identify elements of QS query construction. This means a major contribution of our research are NLI interfaces that identify queries [8,9,10,11].\nPopescu et al. [8] have identified traceable questions and have proposed a holistic framework to convert natural language (NL) questions/queries into SQL commands. Other works [9,10] use Semantic Web ontologies for query construction. For instance, Querix [9] provides a model to extract general query syntax. This allows users to benefits from a clarification dialogue (GUI) that recommends correct sentences, based on their given sentence, to match it with their underlying ontology for information retrieval. NLP-Reduce [10] employs a simple domain-independent NLI interface to translate different user queries, i.e. keywords and sentence fragments to SPARQL queries. NaLIR [11] is a recent work that provides a holistic approach to convert human queries to SQL commands.\nNevertheless, in contrast to the listed NLI works, our work is not holistic and it covers only QS queries. Moreover, all of these works have a translation component from end users\u2019 questions to machine languages, such as SQL or SPARQL. However, small devices, such as smartwatches, have limited resources [12]. Therefore, a light resource-efficient customized query module is favored over SQL, SPARQL or any other resource intensive query engines, which is not trivial to implement on small devices.\nOur contributions are two fold: first we conduct a study to understand QS queries of users to a PA system. Second, we propose a query interface, which includes an algorithm and a user interface that can identify important elements from user questions to construct machine understandable queries. It is notable that our work solely focuses only on a query interface, and thus retrieving information from underlying data stores is not in the scope of this paper.\nII. MATERIALS & METHODS We have performed a survey using Amazon Mechanical Turk (MTurk). This study has created a very promising dataset of textual queries that illustrates what end-users are willing to search from their QS data. After collecting this data, we have applied thematic (qualitative) and linguistic analysis (quantitative analysis based on our qualitative results) on the queries to identify elements that constitute a successful query. Afterwards, we have introduced our algorithm and the smartwatch user interface to extract and understand the required elements from the given textual queries."}, {"heading": "A. User Study", "text": "Objectives: To implement a query interface that operates on personal data, we need to understand: (i) What types of knowledge are users seeking to find from their available personal data (on\ntheir mobile or wearable devices)? (ii) How do users query to search their desired information? To answer both questions, we have conducted a survey on MTurk.\nParticipants: For the user study, Bargas-Avila and Hornb\u00e6k [13] recommends to not only focus on users who are familiar with a system for a user study, but to also consider users who are unfamiliar with the system. Therefore, our participation criteria include participants who own smartphones, but they do not necessarily need to be familiar with QS systems. The survey results show that users, who were not familiar with QS technologies, propose several interesting queries. This insight enables better quantification of end user queries, and covers even queries for the sensors that do not existed yet, e.g. a sensor to determine if a cloth requires washing or not. We have surveyed 131 participants, including 71 males and 60 females, with an age range from 23 to 64 (mean=32, SD=8.19).\nProcedure: Firstly, users were briefed with a one-page description about quantified-self technologiess [4,5,6,7]. This included information about what existing tools can track, and if the tracking tools require a manual user input or if the information can be collected automatically. For instance, \u201cstep count\u201d can be collected automatically, whereas \u201cvalence of the mood\u201d will need to be entered manually. To design the survey questions, we have used the method proposed by Rosenberg & Hovland [14] and thus our questions include cognitive, affective and behavioral lines of inquiry. In more technical sense, our survey includes three types of questions; the first type of questions focused on asking users \u201cwhat\u201d their expectation from a QS system is. This type of question was not limited to current capabilities of existing devices and let the user define their ideas for new applications. The second category of questions asked participants to describe \u201chow\u201d they are willing to search for the information. In contrast to the previous type, these questions were limited to existing technologies. Within this category, one specific question explicitly asks users to provide five to seven textual queries that they would use to search their personal information. Our linguistic analysis on constructing and modelling the query is based on these questions. The third category includes a single question (reverse score question). This question has three multiple choice sub-questions from the one-page description. It evaluates whether participants have understood the description and if their answer is valid for further analysis."}, {"heading": "B. Content Analysis and Query Construction", "text": "We have undertaken two types of analysis on the collected data from MTurk. Qualitative analysis has been undertaken using thematic analysis. Then, quantitative analysis has been conducted using linguistic analysis. Subsequently, based on both analysis, we construct the query parser and its user interface."}, {"heading": "1) Thematic Analysis", "text": "Inductive thematic analysis has been applied on queries and other textual descriptions that participants have provided. A researcher has then examined this text and has identified themes.\nAnother researcher has then analyzed the results and a consensus has been reached on the majority of queries. Using Fleiss Kappa, the inter-rater reliability, results in k = 0.74. Based on Landis and Koch\u2019s interpretation [15], this is a substantial agreement between two researchers. Table 1. shows the categorization of queries based on \u201cinductive thematic analysis\u201d.\nIdentified themes in Table 1 shows that there are limited categories of requests that a user could use to search their personal data repository. This finding has been used to constitute the foundation of our linguistic analysis algorithm."}, {"heading": "2) Linguistic Analysis", "text": "To perform the quantitative analysis, we have stemmed the questions, removed punctuations and stop words, and have determined the frequency of the words in the collected queries.\nThematic analysis demonstrates the limitation of queries and their categories. The results illustrate that there are four categories of words: (i) question words, (ii) words that present a temporal notion of the query, (ii) words that present the subject of tracking, e.g. sleep, walk, and (iv) aggregation words. Our algorithm also uses verb tense for query construction too, which will be explained later.\nFigures 1 (a, b, c) plots the frequency of words in categories i, ii and iii, which have been used 10 or more times. To preserve space, we do not plot aggregation words, including: average, miles, amount, next, last, more, often, daily, etc. Furthermore, users do not always provide aggregation words. Some participants have used a command term to start their query, such as \u201cfind\u201d,\n\u201ctell\u201d, \u201cgive\u201d and \u201cshow\u201d, which has been shown as \u201cCommands\u201d in Figure 1(a).\nThere are 68 (from 716) queries that do not include the listed question words and have used these command terms. Since these are less than 10% we have neglected to consider them in the implementation. Figure 1(b) includes words that have been used for category (ii). With the exception of 38 queries, all of the other queries included a notion of time, either implicitly or explicitly. In addition to the identified terms, our query parsing algorithm also handles months of the year and days of the week. From our sample, 22 (from 38) queries, which do not include a notion of time, do however include a notion of location (implicit or explicit), such as \u201cfind me a job that matches my qualifications.\u201d, or \u201cwhat are the available food deals?\u201d For these questions, we consider \u201cnow\u201d as the notion of time. Figure 1(c) includes the most frequently used words that have been used to describe the subject for tracking."}, {"heading": "3) Tokenization & Lexicon Extraction Algorithm", "text": "Many of existing NLP systems [8,9,10] create a \u201cparse tree\u201d from the given query, which is in text format. Parse tree creation is a computationally complex process but can be used to handle a large variety of texts. However, our approach does not need to cover a wide range of questions. Instead, we focus on QS queries. Moreover, smartwatches can not handle existing parse tree creation algorithm, which usually are computationally complex process. In the evaluation section we describe this in more detail. Here question words (tokenization elements) are limited and known (at least to an extent).\nQS queries are usually simple sentences and it is rare that queries include more than one sentences. Therefore, based on the identified word categories, we can parse input queries as a \u201cbag of words\u201d. However, the bag of words parsing style has a problem of not considering the \u201corder\u201d of the words. Nevertheless, our term categorization model resolves the need to support order of words. For instance, the following queries have the same semantics; however, they have been written differently. Our parser recognizes them as being similar: \u201cOn average, how often do I eat daily?\u201d, \u201cHow often, do I eat, on average?\u201d.5\nIn our model, a query is constituted of five-tuples <qw ,v ,t , s, a>. \u2018qw\u2019 for the question word, \u2018v\u2019 for the verb tense, \u2018t\u2019 for notion of time, \u2018s\u2019 for subject(s) of tracking and \u2018a\u2019 for the aggregation term. There might be queries that do not provide \u2018a\u2019 and \u2018t\u2019 explicitly, and thus they should be extracted by the query parser. \u2018t\u2019 will be either substituted by \u201cnow\u201d or based on the tense identified by the last occurrences (maximum of \u2018t\u2019) of the tracking subject. For instance, \u201cWhen did I talk to Sally?\u201d. By checking the verb tense \u2018did\u2019 the query parser can retrieve the last time that the user has talked to Sally. The evaluation section reports about the impact of \u2018a\u2019 and \u2018t\u2019 substitution in more detail. We have found that less than 10% (69 out of 716) of the queries were not retrospective, and were prospective recall e.g. searching for an appointment or doing a prediction e.g. \u201cWhen will my next medical check-up be?\u201d However, there are some queries that perform comparisons. In those queries, there are more than one \u2018t\u2019. When the algorithm identifies more than one \u2018t\u2019, it assumes that a comparison is required and tries to find the nearest aggregation word to the \u2018t\u2019 (if they are the same). For instance, \u201cAm I more active this month or last month?\u201d, or \u201cDid I sleep more hours on average in March or June?\u201d.\nThis version of the algorithm implements the comparison only, it does not support conjunctions terms such as OR, AND, and NOT, because they have not been used in our sample queries."}, {"heading": "C. User Interface", "text": "The tokenization and lexicon extraction model that we have proposed is resource efficient and later we show that the response time of question parsing is very insignificant, that means there is no need to analyze battery use.\nHowever, due its robust input format requirement, the user entry could be error prone. Therefore, similar to the aforementioned NLP works, we rely on user interaction to refine the input. The user interaction should benefit from auxiliary components [8,9] that recommend users what to provide as input into the system.\n5 We use the underline for \u201cverb words\u201d, the red color is for \u201caggregated words\u201d, blue\nis for \u201cquestion words\u201d, green is for the \u201cnotion of time\u201d, and magenta is for the \u201csubject(s) of tracking\u201d. (Please read this section in color)\nNevertheless, considering the miniature-sized screens of smartwatches, our user interface, as it can be seen in Figure 2, recommends only words, and not a complete sentence.\nLikewise, it uses three small buttons to notify the user about the missing words in the query. These buttons were assumed as auxiliary controller to assist correcting users\u2019 input.\nIn particular, these buttons are used for \u2018qw\u2019, \u2018t\u2019, \u2018s\u2019 elements, only words in category i, ii and iii and not \u2018v\u2019 and \u2018a\u2019. If a word, in any of these three categories, has been missed, the related button color will be turned to \u2018red\u2019. Otherwise the color is green. To our knowledge there are few works that provide UI designs for smartwatches. Despite its simplicity, we believe this interface is among the first works that integrates NLP UI for smartwatches.\nIII. EVALUATION We propose four evaluations: query response time, users\u2019 accuracy while using the system, and two usability analysis for the smartwatch user interface.\nRunning the query interface on the device should have a higher response time. To demonstrate this, we have compared our approach with two state-of the-art methods Apache\u2019s OpenNLP [16] and Google\u2019s TensorFlow, SyntaxNet package [17]. The implementation of OpenNLP and SytaxNet are not light, and they should run outside the Smartwatch. Therefore, we have transferred the data through Bluetooth to the smartphone (OpenNLP), or using the WiFi on the phone to transfer it into the external web server (SyntaxNet). OpenNLP is light enough to run on the smartphone, but not smartwatch. SyntaxNet can not be executed on the smartphone and requires a web server (we used Tomcat Apache Server).\nTable 2. shows a comparison of the average response times between our approach and SyntaxNet, OpenNLP for 20 sample queries. As it can be seen, our approach clearly outperforms both methods. For this experiment, we have used a Moto 360 smartwatch (version 2015). The desktop that hosts the NLP server includes a 2.5 GHz Intel Core i5 CPU and 8GB of memory. The\nsmartphone used to transfer the data from the watch to the desktop is Sony Xperia Z5 with 2.0 GHz Quad-core CPU and 3 GB memory. To transfer the data, we have used the embedded Low Power Bluetooth module (BLE) of the smartwatch.\nOur experiment uses the WiFi of a local machine. It is notable that in the real-world applications, if we use SyntaxNet the query will be transferred to a cloud and not a local host. Therefore, the parser response time could be more than 3639 milliseconds. Latency is a major challenge for user interaction [18] and results in Table 2 demonstrate that our on-device analysis can resolve the inherit latency of interacting with the smartwatch.\nThe second evaluation evaluates if the query parser can correctly identify all query elements or not. To analyze each feature, we have selected 10 new test users, 4 males and 6 females, age range from 26 to 35 (mean=29, SD=2.1).\nAll participants are familiar with both PA and QS systems, we have asked them to issue 6-8 queries using three different settings.\nIn summary, each user has issued 20-24 queries. A researcher manually checked whether the system could identify all query elements correctly or not. We have used a manual approach, rather than a standard metric, such as \u201cWord Error Rate\u201d, because all query elements should be identified correctly and partial correctness of some elements in a sentence is counted as error. The first setting, baseline (BL), is only a bag of words with no additional checking and finds three elements of each query: \u2018qw\u2019, \u2018t\u2019, \u2018s\u2019. The second settings checks \u201cthe verb tense\u201d (IV) in addition to BL checks. The third settings has checked both \u201cverb tense\u201d and also \u201ctime\u201d comparison (IVT).\nFor the implementation, we have used a third party voice recognition (Google Speech API), and we have neglected voice recognition errors. Voice recognition errors are not in the scope of this paper. Figure 3 shows the number of errors based on the number of experiments. In the beginning, the users made many mistakes. However, as they progressed, they learned the system and performed better. Moreover, IVT performs better than BL and IV. IV also performs slightly better than BL, but not significantly. After the 10th query, there are very few errors in creating queries that seems acceptable. We can conclude that by this point, users understand how to construct the query questions correctly and thus the errors have been reduced.\nThe third evaluation focuses on our UI usability and its two main features, i.e. colored buttons and tool tips. In this experiment, the optimal case is enabling both features (BT). We have then enabled the tooltip and disabled the colored buttons (TT). Afterward, we have disabled the tooltip and enabled the colored buttons (CB). As it has been shown in Figure 4, providing the tooltip performs better than the colored buttons, in helping users correctly constructing their queries.\nHowever, as the BT results illustrate, if both tooltip and colored buttons have been used together, we get better results. It is notable that to prevent users learning the system this evaluation has been done in parallel to the previous evaluation. Therefore, the error/correct ratio is rather high in Figure 3. In other words, participants were in learning phase of using the system.\nThe fourth evaluation is also focuses on the UI usability. For this evaluation we have used Nielesen Heuristics [19]. Nielsen Heuristics evaluates followings: visibility of system status, match between system and the real-world, user control, consistency and standards, error prevention, recognition rather than recall, flexibility and efficiency of use, aesthetic and minimalistic design, help users recognize, diagnose and recover from errors, and finally help and documentations.\nWe have designed a survey included Nielsen\u2019s principles for user interface design. We have adapted those principles in form of questions (in Likert scale) and asked participants to rank the application accordingly. The result of the evaluation shows Aesthetic and Minimalist Design received the lowest score (2.9 from 5), but other Nilsen\u2019s heuristic factors received satisfactory scores (3.6 \u2013 4.8 from 5). The highest one was\nRecognition rather than recall that receives the average of 4.8 from 5. Based on participants\u2019 feedback the high rank of Recognition rather than recall is because of the use of tooltip in the user interface.\nPlease consider that the implementation of the information retrieval component is not the scope of this work. Here our focus is on understanding queries and constructing a query interface to identify the required elements of a query from a given sentence.\nIV. CONCLUSION & FUTURE WORK In this work, we have conducted a user study, through MTurk, to collect a dataset of 716 quantified-self queries that users are willing to issue through their personal assistant systems. We have then presented and evaluated a query interface that includes a user interface and an algorithm for parsing textual quantified-self queries. Our users\u2019 accuracy and usability evaluations show that our approach is capable to parse most of the identified quantifiedself queries from the survey.\nIn our future work, we plan to optimize the query interface with subtler term recommendations that are based on the k-nearest neighbor words retrieved from the history of queries. Moreover, we will develop a retrieval component that can search and show behavioral patterns [20] of the smartwatch to the user. This work focused only on query and not information retrieval.\nV. REFERENCES\n[1] Rawassizadeh, R., Price, B.A. & Petre, M. 2014. Wearables: has the age of smartwatches finally arrived? Communications of the ACM, vol. 58, no. 1, 45- 47.\n[2] Llopis, M., & Ferr\u00e1ndez, A. 2013. How to make a natural language interface to query databases accessible to everyone: An example. Computer Standards & Interfaces, vol. 35, no. 5, pp. 470-481.\n[3] Guha, R., Gupta, V., Raghunathan, V. and Srikant, R. 2015. User Modeling for a Personal Assistant. Proceedings of the Eighth ACM International Conference on Web Search and Data Mining, WSDM \u201915, pp. 275-284.\n[4] Li, I., Dey, A.K. and Forlizzi, J. 2011. Understanding my Data, Myself: Supporting Self-Reflection with Ubicomp Technologies. Proceedings of the 13th Int. Conf. on Ubiquitous Computing, UbiComp \u201911, pp. 405-414.\n[5] Choe, E. K., Lee, N. B., Lee, B., Pratt, W., & Kientz, J. A. 2014. Understanding Quantified-Selfers' Practices in Collecting and Exploring Personal Data. Proceedings of the 32nd ACM conference on Human factors in Computing Systems. CHI \u201914, pp.1143-1152.\n[6] Oh, J. & Lee, U. 2015. Exploring UX issues in Quantified Self technologies. International Conference on Mobile Computing and Ubiquitous Networking, ICMU \u201915, pp. 53 -59.\n[7] Rawassizadeh, R., Momeni, E., Dobbins, C., Mirza-Babaei, P., & Rahnamoun, R. 2015. Lesson Learned from Collecting Quantified Self Information via Mobile and Wearable Devices. Journal of Sensor Actuator Network. 2015, vol. 4, no. 4, pp. 315-335.\n[8] Popescu, A. M., Etzioni, O., & Kautz, H. 2003. Towards a theory of natural language interfaces to databases. Proceedings of the 8th international conference on Intelligent user interfaces. IUI \u201903. pp. 149-157.\n[9] Kaufmann, E., Bernstein, A., & Zumstein, R. 2006. Querix: A Natural Language Interface to Query Ontologies based on Clarification Dialogs. 5th Int. Semantic Web Conference, ISWC \u201806. pp. 980-981.\n[10] Kaufmann, E., Bernstein, A., & Fischer, L. 2007. NLP-Reduce: A \u201cna\u0131ve\u201d but Domain-independent Natural Language Interface for Querying Ontologies. 4th European Semantic Web Conference, ESWC \u201807.\n[11] Li, F. & Jagadish, H. V. 2014. NaLIR: An Interactive Natural Language Interface for Querying Relational Databases. Proc. of the 2014 ACM SIGMOD Int. Conf. on Management of data. SIGMOD \u201914. pp. 709-712.\n[12] Rawassizadeh, R., Tomitsch, M., Nourizadeh, M., Momeni, E., Peery, A., Ulanova, L., & Pazzani, M. 2015. Energy-Efficient Integration of Continuous Context Sensing and Prediction into Smartwatches. Sensors, vol. 15, no. 9, pp. 22616-22645.\n[13] Bargas-Avila, J., & Hornb\u00e6k, K. 2012. Foci and blind spots in user experience research. ACM Interactions, vol. 19, no. 6, 24-27.\n[14] Rosenberg, M.J., & Hovland C.I. 1960. Cognitive, affective, and behavioral components of attitudes. Attitude organization and change: An analysis of consistency among attitude components, 1-14.\n[15] Landis, J.R., & Kock, G.G. 1977. The measurement of observed agreement for categorical data. Biometrics, 33, 159-174.\n[16] Baldridge, J. 2005. The openNLP project. http://opennlp.apache.org/index.html, (accessed 2 July 2016).\n[17] Andor, D., Alberti, C., Weiss, D., Severyn, A., Presta, A., Ganchev, K., Petrov, S. and Collins, M., 2016. Globally Normalized Transition-based Neural Networks. arXiv preprint arXiv:1603.06042.\n[18] Lagar-Cavilla, H. A., Tolia, N., De Lara, E., Satyanarayanan, M., & O\u2019Hallaron, D. 2007. Interactive resource-intensive applications made easy. In ACM/IFIP/USENIX International Conference on Distributed Systems Platforms and Open Distributed Processing. pp. 43-163.\n[19] Nielsen, J. (1994). Ten Usability Heuristics. http://www.useit.com/papers/heuristic/heuristic_list.html\n[20] Rawassizadeh, R., Momeni, E., Dobbins, C., Gharibshah, J. & Pazzani, M. 2016. Scalable Daily Human Behavioral Pattern Mining from Multivariate Temporal Data. In IEEE Transactions on Knowledge and Data Engineering. vol. 28, no. 11, pp. 3098-3112,"}], "references": [{"title": "Wearables: has the age of smartwatches finally arrived", "author": ["R. Rawassizadeh", "B.A. Price", "M. Petre"], "venue": "Communications of the ACM,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "How to make a natural language interface to query databases accessible to everyone: An example", "author": ["M. Llopis", "A. Ferr\u00e1ndez"], "venue": "Computer Standards & Interfaces,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "User Modeling for a Personal Assistant", "author": ["R. Guha", "V. Gupta", "V. Raghunathan", "R. Srikant"], "venue": "Proceedings of the Eighth ACM International Conference on Web Search and Data Mining,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Understanding my Data, Myself: Supporting Self-Reflection with Ubicomp Technologies", "author": ["I. Li", "A.K. Dey", "J. Forlizzi"], "venue": "Proceedings of the 13th Int. Conf. on Ubiquitous Computing,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Understanding Quantified-Selfers' Practices in Collecting and Exploring Personal Data", "author": ["E.K. Choe", "N.B. Lee", "B. Lee", "W. Pratt", "J.A. Kientz"], "venue": "Proceedings of the 32nd ACM conference on Human factors in Computing Systems. CHI \u201914,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Exploring UX issues in Quantified Self technologies", "author": ["J. Oh", "U. Lee"], "venue": "International Conference on Mobile Computing and Ubiquitous Networking, ICMU \u201915,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Lesson Learned from Collecting Quantified Self Information via Mobile and Wearable Devices", "author": ["R. Rawassizadeh", "E. Momeni", "C. Dobbins", "P. Mirza-Babaei", "R. Rahnamoun"], "venue": "Journal of Sensor Actuator Network. 2015,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Towards a theory of natural language interfaces to databases", "author": ["A.M. Popescu", "O. Etzioni", "H. Kautz"], "venue": "Proceedings of the 8th international conference on Intelligent user interfaces. IUI", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2003}, {"title": "Querix: A Natural Language Interface to Query Ontologies based on Clarification Dialogs", "author": ["E. Kaufmann", "A. Bernstein", "R. Zumstein"], "venue": "5th Int. Semantic Web Conference,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2006}, {"title": "NLP-Reduce: A \u201cna\u0131ve\u201d but Domain-independent Natural Language Interface for Querying Ontologies", "author": ["E. Kaufmann", "A. Bernstein", "L. Fischer"], "venue": "4th European Semantic Web Conference,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2007}, {"title": "NaLIR: An Interactive Natural Language Interface for Querying Relational Databases", "author": ["F. Li", "H.V. Jagadish"], "venue": "Proc. of the 2014 ACM SIGMOD Int. Conf. on Management of data", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Energy-Efficient Integration of Continuous Context Sensing and Prediction into Smartwatches", "author": ["R. Rawassizadeh", "M. Tomitsch", "M. Nourizadeh", "E. Momeni", "A. Peery", "L. Ulanova", "M. Pazzani"], "venue": "Sensors, vol. 15,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Foci and blind spots in user experience research", "author": ["J. Bargas-Avila", "K. Hornb\u00e6k"], "venue": "ACM Interactions,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Cognitive, affective, and behavioral components of attitudes. Attitude organization and change: An analysis of consistency among attitude", "author": ["M.J. Rosenberg", "Hovland C.I"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1960}, {"title": "The measurement of observed agreement for categorical data", "author": ["J.R. Landis", "G.G. Kock"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1977}, {"title": "The openNLP project. http://opennlp.apache.org/index.html, (accessed 2 July 2016)", "author": ["J. Baldridge"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2005}, {"title": "Interactive resource-intensive applications made easy", "author": ["H.A. Lagar-Cavilla", "N. Tolia", "E. De Lara", "M. Satyanarayanan", "D. O\u2019Hallaron"], "venue": "In ACM/IFIP/USENIX International Conference on Distributed Systems Platforms and Open Distributed Processing", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}, {"title": "Ten Usability Heuristics", "author": ["J. Nielsen"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1994}, {"title": "Scalable Daily Human Behavioral Pattern Mining from Multivariate Temporal Data", "author": ["R. Rawassizadeh", "E. Momeni", "C. Dobbins", "J. Gharibshah", "M. Pazzani"], "venue": "In IEEE Transactions on Knowledge and Data Engineering", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "Devices that provide personal assistant (PA) services, especially smartphones, are usually pervasive, but have small displays, which leads to limited interaction facilities [1].", "startOffset": 173, "endOffset": 176}, {"referenceID": 1, "context": "There are NLIs that host GUIs but they have significantly less flexibility in comparison to textual NLIs [2].", "startOffset": 105, "endOffset": 108}, {"referenceID": 2, "context": "Only simple contextual data, such as the user\u2019s current location, is often used, and other data objects will be read from the web [3].", "startOffset": 130, "endOffset": 133}, {"referenceID": 3, "context": "Previous QS based user studies [4, 5, 6] provide promising results, but they focus only on users who are familiar with QS systems.", "startOffset": 31, "endOffset": 40}, {"referenceID": 4, "context": "Previous QS based user studies [4, 5, 6] provide promising results, but they focus only on users who are familiar with QS systems.", "startOffset": 31, "endOffset": 40}, {"referenceID": 5, "context": "Previous QS based user studies [4, 5, 6] provide promising results, but they focus only on users who are familiar with QS systems.", "startOffset": 31, "endOffset": 40}, {"referenceID": 3, "context": "[4] have identified information that are important for users, including status, history, goals, discrepancies, context, and factors.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] have focused on what QS users have learnt from collecting their data and how they perform the data collection.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] have classified QS users and the issues that are associated with tracking.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] list challenges of collecting QS data and users\u2019 expectations from these systems.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "This means a major contribution of our research are NLI interfaces that identify queries [8,9,10,11].", "startOffset": 89, "endOffset": 100}, {"referenceID": 8, "context": "This means a major contribution of our research are NLI interfaces that identify queries [8,9,10,11].", "startOffset": 89, "endOffset": 100}, {"referenceID": 9, "context": "This means a major contribution of our research are NLI interfaces that identify queries [8,9,10,11].", "startOffset": 89, "endOffset": 100}, {"referenceID": 10, "context": "This means a major contribution of our research are NLI interfaces that identify queries [8,9,10,11].", "startOffset": 89, "endOffset": 100}, {"referenceID": 7, "context": "[8] have identified traceable questions and have proposed a holistic framework to convert natural language (NL) questions/queries into SQL commands.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "Other works [9,10] use Semantic Web ontologies for query construction.", "startOffset": 12, "endOffset": 18}, {"referenceID": 9, "context": "Other works [9,10] use Semantic Web ontologies for query construction.", "startOffset": 12, "endOffset": 18}, {"referenceID": 8, "context": "For instance, Querix [9] provides a model to extract general query syntax.", "startOffset": 21, "endOffset": 24}, {"referenceID": 9, "context": "NLP-Reduce [10] employs a simple domain-independent NLI interface to translate different user queries, i.", "startOffset": 11, "endOffset": 15}, {"referenceID": 10, "context": "NaLIR [11] is a recent work that provides a holistic approach to convert human queries to SQL commands.", "startOffset": 6, "endOffset": 10}, {"referenceID": 11, "context": "However, small devices, such as smartwatches, have limited resources [12].", "startOffset": 69, "endOffset": 73}, {"referenceID": 12, "context": "Participants: For the user study, Bargas-Avila and Hornb\u00e6k [13] recommends to not only focus on users who are familiar with a system for a user study, but to also consider users who are unfamiliar with the system.", "startOffset": 59, "endOffset": 63}, {"referenceID": 3, "context": "Procedure: Firstly, users were briefed with a one-page description about quantified-self technologiess [4,5,6,7].", "startOffset": 103, "endOffset": 112}, {"referenceID": 4, "context": "Procedure: Firstly, users were briefed with a one-page description about quantified-self technologiess [4,5,6,7].", "startOffset": 103, "endOffset": 112}, {"referenceID": 5, "context": "Procedure: Firstly, users were briefed with a one-page description about quantified-self technologiess [4,5,6,7].", "startOffset": 103, "endOffset": 112}, {"referenceID": 6, "context": "Procedure: Firstly, users were briefed with a one-page description about quantified-self technologiess [4,5,6,7].", "startOffset": 103, "endOffset": 112}, {"referenceID": 13, "context": "To design the survey questions, we have used the method proposed by Rosenberg & Hovland [14] and thus our questions include cognitive, affective and behavioral lines of inquiry.", "startOffset": 88, "endOffset": 92}, {"referenceID": 14, "context": "Based on Landis and Koch\u2019s interpretation [15], this is a substantial agreement between two researchers.", "startOffset": 42, "endOffset": 46}, {"referenceID": 7, "context": "3) Tokenization & Lexicon Extraction Algorithm Many of existing NLP systems [8,9,10] create a \u201cparse tree\u201d from the given query, which is in text format.", "startOffset": 76, "endOffset": 84}, {"referenceID": 8, "context": "3) Tokenization & Lexicon Extraction Algorithm Many of existing NLP systems [8,9,10] create a \u201cparse tree\u201d from the given query, which is in text format.", "startOffset": 76, "endOffset": 84}, {"referenceID": 9, "context": "3) Tokenization & Lexicon Extraction Algorithm Many of existing NLP systems [8,9,10] create a \u201cparse tree\u201d from the given query, which is in text format.", "startOffset": 76, "endOffset": 84}, {"referenceID": 7, "context": "The user interaction should benefit from auxiliary components [8,9] that recommend users what to provide as input into the system.", "startOffset": 62, "endOffset": 67}, {"referenceID": 8, "context": "The user interaction should benefit from auxiliary components [8,9] that recommend users what to provide as input into the system.", "startOffset": 62, "endOffset": 67}, {"referenceID": 15, "context": "To demonstrate this, we have compared our approach with two state-of the-art methods Apache\u2019s OpenNLP [16] and Google\u2019s TensorFlow, SyntaxNet package [17].", "startOffset": 102, "endOffset": 106}, {"referenceID": 16, "context": "Latency is a major challenge for user interaction [18] and results in Table 2 demonstrate that our on-device analysis can resolve the inherit latency of interacting with the smartwatch.", "startOffset": 50, "endOffset": 54}, {"referenceID": 17, "context": "For this evaluation we have used Nielesen Heuristics [19].", "startOffset": 53, "endOffset": 57}, {"referenceID": 18, "context": "Moreover, we will develop a retrieval component that can search and show behavioral patterns [20] of the smartwatch to the user.", "startOffset": 93, "endOffset": 97}], "year": 2016, "abstractText": "Currently, personal assistant systems, run on smartphones and use natural language interfaces. However, these systems rely mostly on the web for finding information. Mobile and wearable devices can collect an enormous amount of contextual personal data such as sleep and physical activities. These information objects and their applications are known as quantified-self, mobile health or personal informatics, and they can be used to provide a deeper insight into our behavior. To our knowledge, existing personal assistant systems do not support all types of quantified-self queries. In response to this, we have undertaken a user study to analyze a set of \u201ctextual questions/queries\u201d that users have used to search their quantified-self or mobile health data. Through analyzing these questions, we have constructed a light-weight natural language based query interface including a text parser algorithm and a user interface to process the users\u2019 queries that have been used for searching quantified-self information. This query interface has been designed to operate on small devices, i.e. smartwatches, as well as augmenting the personal assistant systems by allowing them to process end users\u2019 natural language queries about their quantified-self data. Keywords\u2014Quantified Self; Query; Natural Language Interface; Smartwatch", "creator": "Word"}}}