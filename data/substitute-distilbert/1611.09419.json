{"id": "1611.09419", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Nov-2016", "title": "Safety-Aware Robot Damage Recovery Using Constrained Bayesian Optimization and Simulated Priors", "abstract": "the simultaneously introduced intelligent trial - and - error ( it & amp ; rd ) algorithm showed that robots can adapt to damage in a matter of a few cases. the success of this algorithm relies on two components : prior knowledge acquired through simulation with safely intact robot, and bayesian optimization ( rr ) that operates on - line, on the damaged robot. while it & ems ; e leads via fast damage recovery, it does not incorporate any safety constraints that prevent degraded robot from attempting harmful behaviors. in this work, we address this limitation by replacing the bo model with best passive bo procedure. students evaluate our approach on rescuing simulated damaged humanoid robot that needs to crawl as soft as possible, while performing not few unsafe trials as possible. we compare given new \" safety - aware it & ot ; e \" algorithm to it & amp ; e and a multi - objective version of it & amp ; e in contrast the safety constraints are dealt their separate objectives. our results show that our algorithm outperforms the main approaches, both in linear speed within the safe regions and number of unsafe trials.", "histories": [["v1", "Mon, 28 Nov 2016 22:56:24 GMT  (1438kb,D)", "https://arxiv.org/abs/1611.09419v1", "Accepted at the BayesOpt 2016 NIPS workshop, 5 pages, 2 figures, 1 algorithm"], ["v2", "Wed, 30 Nov 2016 23:28:57 GMT  (1429kb,D)", "http://arxiv.org/abs/1611.09419v2", "Accepted at the BayesOpt 2016 NIPS workshop, 5 pages, 2 figures, 1 algorithm"], ["v3", "Fri, 2 Dec 2016 09:33:07 GMT  (1429kb,D)", "http://arxiv.org/abs/1611.09419v3", "Accepted at the BayesOpt 2016 NIPS workshop, 5 pages, 2 figures, 1 algorithm"]], "COMMENTS": "Accepted at the BayesOpt 2016 NIPS workshop, 5 pages, 2 figures, 1 algorithm", "reviews": [], "SUBJECTS": "cs.RO cs.LG", "authors": ["vaios papaspyros", "konstantinos chatzilygeroudis", "vassilis vassiliades", "jean-baptiste mouret"], "accepted": false, "id": "1611.09419"}, "pdf": {"name": "1611.09419.pdf", "metadata": {"source": "CRF", "title": "Safety-Aware Robot Damage Recovery Using Constrained Bayesian Optimization and Simulated Priors", "authors": ["Vaios Papaspyros", "Konstantinos Chatzilygeroudis", "Vassilis Vassiliades", "Jean-Baptiste Mouret"], "emails": ["jean-baptiste.mouret@inria.fr"], "sections": [{"heading": "1 Introduction", "text": "Current robots would greatly benefit from being capable of carrying on with their mission when they are damaged, as illustrated by the recent DARPA Robotics Challenge [1, 4]. When damaged, most robots attempt to diagnose the fault and search for a contingency plan; but they could also exploit a reinforcement learning algorithm so that they can find compensatory behaviors without having to \"understand\" the damage [7, 15]. If they follow this second approach, robots need learning algorithms that are highly data-efficient [5] because too many trials would waste precious time to achieve the mission.\nOne of the most promising approaches for data-efficient robot damage recovery is the recently introduced Intelligent Trial-and-Error algorithm (IT&E) [7]. It combines two ideas: (1) a Bayesian optimization (BO) algorithm [16] that optimizes a reward function, because it is a generic, dataefficient policy search algorithm [3], and (2) a behavior-performance map generated before the mission with a simulation of the intact robot, which acts both as a prior for the Bayesian optimization algorithm and as a dimension reduction algorithm. This combination allowed a damaged 6-legged robot to find a new gait in about a dozen of trials (less than 2 minutes), and a robotic arm to overcome several blocked joints in a few minutes [7].\nUnfortunately, trial-and-error approaches, like IT&E, are likely to damage the robot even more because they will often try behaviors that are too extreme for the mechanical design. More generally,\n\u2217Corresponding author: jean-baptiste.mouret@inria.fr 1 Inria, Villers-l\u00e8s-Nancy, F-54600, France. 2 CNRS, Loria, UMR 7503, Vand\u0153uvre-l\u00e8s-Nancy, F-54500, France. 3 Universit\u00e8 de Lorraine, Loria, UMR 7503, Vand\u0153uvre-l\u00e8s-Nancy, F-54500, France. 4 University of Patras, 26500 Rion, Patras, Greece\n30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\nar X\niv :1\n61 1.\n09 41\n9v 3\n[ cs\n.R O\n] 2\nD ec\nlearning algorithms will push robots to their limits because they focus solely on maximizing the reward intake2. This issue is especially concerning for expensive prototypes like the iCub robot [13, 17]: these robots are too expensive (around 250k euros for the iCub) and too fragile to try risky behaviors.\nWhile recent methods, like SafeOPT [2], tackle this issue successfully, they require an initial safe set of parameters, that is hard to estimate in an unknown damage setting. In this paper, we extend the IT&E algorithm [7] by adding safety constraints [9] and automatically computing priors over the safety of controller parameters, so that the probability of breaking the robot during the learning process is as low as possible. We evaluate our algorithm using a simulated damaged iCub robot."}, {"heading": "2 Safety-aware Intelligent Trial & Error Algorithm", "text": "The first step of IT&E is to create a low-dimensional behavior-performance map with a simulation of the intact robot. This step is achieved with an evolutionary algorithm called MAP-Elites [14], which, instead of searching for a single, best solution, like standard optimization algorithms, searches for the highest-performing individual for each point in a user-defined space. This user-defined space is often called the behavior space, because the dimensions of variation (behavior descriptors) usually measure behavioral characteristics. For example, by defining one dimension for each leg\u2019s fraction of time spent on the ground, MAP-Elites produces a wide variety of walking gaits for a hexapod robot [7].\nTo search for the best behavior on the damaged robot, IT&E alters the classical BO scheme [7] by (1) searching a behavior in the map, instead of searching the best policy parameters, and (2) modeling the difference between the performance predicted by the map (M(\u00b7)) and the actual performance, instead of directly modeling the performance function. Thus, at each step of the adaptation algorithm, the BO procedure selects the most promising behavior from the map, executes it on the damaged robot, observes the performance, and updates its predictions accordingly.\nMore precisely, the performance function, f(x), is modeled as a Gaussian process (GP):\nf(x) \u223c GP (m(x), k(x,x\u2032)) (1)\np(f(x)|X1:t,x) = N(m(x), \u03c32(x)) (2) where:\nm(x) =M(x) + kT (K+ \u03c32nI) \u22121(X1:t \u2212M(x1:t)) (3)\n\u03c32(x) = k(x,x)\u2212 kT (K+ \u03c32nI)\u22121k (4) and K is the kernel matrix with Kij = k(xi,xj), k = k(X1:t,x) and X1:t the set of observations.\nThis approach leads to short adaptation times in several experiments with damaged robots [7], but it has a serious limitation that prevents it from being used with expensive robots: it lacks safety constraints, that is, nothing prevents the robot from trying dangerous behaviors. Because we have access to a simulator of the robot, one could think that the safety of a potential behavior could be evaluated using the simulation; however, this is likely to not be sufficient because high-performing controllers for the intact robot might have considerably different behavior and often be harmful on the damaged robot. More often than not, such behaviors are highly dependent on the robot\u2019s legs, wheels,\n2Interestingly, learning algorithms also push robot simulators to their limits as they often exploit simulation inaccuracies.\netc., the failure of which would result in a radically different outcome in the damaged case. IT&E having no prior knowledge about the damage or any safety limitations, will most likely attempt more than a few of these dangerous behaviors. These behaviors constitute a big risk for further damaging fragile robots. To make matters worse, a damage recovery algorithm would have to compensate for the reality gap [11, 12] as well3. In particular, even for intact robots, the behaviors contained in the behavior-performance maps are not likely to be reproduced exactly on the physical robot.\nWe address these issues by introducing a safety-aware IT&E algorithm (sIT&E; see Fig. 1). sIT&E uses a constrained BO procedure [9] in which each user-defined safety constraint, ci(x), is modeled as a separate GP. The next sample is selected by optimizing the Expected Constrained Improvement (ECI) acquisition function [9]:\nECI(x\u0302) = EI(x\u0302) n\u220f i=1 p(ci(x\u0302) \u2265 0) (5)\nwhere x\u0302 is the candidate point, ci(x\u0302), i \u2208 {1, \u00b7 \u00b7 \u00b7 , n} are the n constraint functions and EI(x\u0302) is the standard expected improvement [9].\nThe differences between sIT&E (see Alg.1) and IT&E are as follows: (1) the behavior descriptor in MAP-Elites is augmented with extra dimensions for each safety constraint, so that sIT&E will have a good estimate of the safe regions (i.e., where all inequality safety constraints are fulfilled); for example, these dimensions could be torque or IMU measurements that should not exceed a specific threshold; (2) during the on-line adaptation step, sIT&E optimizes for performance while also guiding the search through the safe regions.\nAlgorithm 1 Safety-aware Intelligent Trial-and-Error (sIT&E) procedure SIT&E\nBefore mission (intact robot in simulation): Create Behavior-Performance Map via MAP-Elites storing safety related information while in mission do if significant performance drop then\nAdaptation Step (via M-CBO Algorithm) procedure MAP-BASED CONSTRAINED BAYESIAN OPTIMIZATION (M-CBO) \u2200x \u2208 map : p(f(x)|x) = N(m(x), k(x,x)) p(ci(x)|x) = N(mci(x), kci(x,x)), i \u2208 {1, \u00b7 \u00b7 \u00b7 , n}\nwhile stopping criteria not met do xt+1 = argmaxxECI(x|X1:t, C1:t) {c1(xt+1), . . . , cn(xt+1), f(xt+1)} = execute_behavior(xt+1) X1:t+1 = {f(xt+1), X1:t} C1:t+1 = {\u3008c1(xt+1), . . . , cn(xt+1)\u3009, C1:t} Update GPs for the objective function/safety constraints"}, {"heading": "3 Crawling humanoid robot experiments", "text": "To evaluate our algorithm, we use a simulated iCub robot [13, 17] performing a crawling task. Learning how to crawl could prove especially useful in humanoid robot damage recovery, where attempting to walk again might constitute a big risk for further damages or be infeasible altogether (e.g. traversing a short or tight tunnel). Furthermore, solving this task serves as a stepping stone towards damage recovery for more advanced tasks (e.g. walking).\nTo generate a diversity of behaviors with MAP-Elites, we augment an initially 4D behavior descriptor, defined as the fraction of time each arm/leg spent on the ground, with a safety dimension that encodes the sum of contact point forces. sIT&E optimizes for crawling speed and is constrained by a safety threshold for the sum of contact point forces. This threshold is determined after conducting several preliminary experiments in order to understand the correlation between the robot\u2019s behavior and the contact point forces at high crawling speeds. To optimize the acquisition function, we iterate over all\n3The reality gap refers to the differences between simulated and physical systems.\nthe points in the behavior-performance map (which contains approximately 1500 behaviors), and select a behavior that is estimated to be the most promising above the safety threshold.\nWe compare 3 algorithms in terms of the best safe performance observed and unsafe trials attempted: (1) IT&E maximizing crawling speed; (2) a multi-objective [8] IT&E algorithm (MO-IT&E; based on the Expected Hypervolume Improvement [10, 18]), that maximizes the crawling speed and minimizes the sum of contact point forces, therefore, building a Pareto front from which the safest behavior can be chosen; and (3) sIT&E maximizing crawling speed within the safe region as described above. We test 4 damage conditions: (1) locked shoulder joint, (2) locked hip joint, (3) locked shoulder joint & angled elbow, and (4) combination of 2 & 3.\nTo avoid depending on a single behavior-performance map, we use 4 independently-generated maps and run each algorithm 20 times for 30 trials. We use the squared exponential kernel with \u03c3 = 0.1 and a GP noise value of 0.01. When using IT&E, the median number of dangerous trials is approximately equal to 29 (out of 30) in all damage settings (Fig. 2, lower row). For MO-IT&E, this number decreases, but it is still greater than 22. In contrast, sIT&E requires less than 10 unsafe trials for damages 1, 2, and 4, and 14 for damage 3. Pairwise comparisons indicate that the results are highly significant (p < 0.0001, Mann-Whitney U test). In terms of safe performance (crawling speed in m/s), sIT&E dominates over both IT&E and MO-IT&E in all damage settings (Fig. 2, upper row), with the results being statistically significant (p < 0.001) in all cases apart from damage 3.\nAll experiments were conducted using the limbo framework [6]. A supplementary video is available at https://youtu.be/8esrj-7WhsQ."}, {"heading": "4 Conclusion", "text": "Our experiments show that the vanilla IT&E algorithm finds high-performing behaviors in a few trials, but most of the behaviors tested, including the best, final ones, are unsafe for the robot. Since the multi-objective approach searches for a set of Pareto-optimal trade-offs, it can find safe and high-performing behaviors; however, this approach still tests many unsafe behaviors during the learning phase. By contrast, the sIT&E algorithm finds gaits that are both safe and high-performing with only a handful of unsafe trials. Thanks to this property, we are confident that sIT&E is less likely to damage the real iCub than IT&E or BO. In future work, we will compare our results to approaches based on safety regions [2], which might be safer, but may prove too conservative performance-wise. Overall, this work shows that safety is a critical component for any robot learning algorithm and that constrained BO can provide a good basis to design algorithms that are both data-efficient and safe."}, {"heading": "Acknowledgments", "text": "This work received funding from the European Research Council (ERC) under the European Union\u2019s Horizon 2020 research and innovation program (grant agreement number 637972, project \u201cResiBots\u201d)."}], "references": [{"title": "What happened at the DARPA robotics challenge, and why? submitted to the DRC", "author": ["Christopher G. Atkeson"], "venue": "Finals Special Issue of the Journal of Field Robotics,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "Bayesian optimization with safety constraints: safe and automatic parameter tuning in robotics", "author": ["Felix Berkenkamp", "Andreas Krause", "Angela P Schoellig"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}, {"title": "An experimental comparison of Bayesian optimization for bipedal locomotion", "author": ["Roberto Calandra", "Andr\u00e9 Seyfarth", "Jan Peters", "Marc Peter Deisenroth"], "venue": "In 2014 IEEE International Conference on Robotics and Automation (ICRA),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "How UGVs physically fail in the field", "author": ["Jennifer Carlson", "Robin R. Murphy"], "venue": "IEEE Transactions on Robotics,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2005}, {"title": "Reset-free Trial-and-Error Learning for Data-Efficient Robot Damage Recovery", "author": ["Konstantinos Chatzilygeroudis", "Vassilis Vassiliades", "Jean-Baptiste Mouret"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "Limbo: A fast and flexible library for bayesian optimization", "author": ["Antoine Cully", "Konstantinos Chatzilygeroudis", "Federico Allocati", "Jean-Baptiste Mouret"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}, {"title": "Robots that can adapt like animals", "author": ["Antoine Cully", "Jeff Clune", "Danesh Tarapore", "Jean-Baptiste Mouret"], "venue": "Nature, 521(7553):503\u2013507,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Multi-objective optimization. In Search methodologies, pages 403\u2013449", "author": ["Kalyanmoy Deb"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Bayesian optimization with inequality constraints", "author": ["Jacob R Gardner", "Matt J Kusner", "Zhixiang Eddie Xu", "Kilian Q Weinberger", "John Cunningham"], "venue": "In ICML,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Faster exact algorithms for computing expected hypervolume improvement", "author": ["Iris Hupkens", "Andr\u00e9 Deutz", "Kaifeng Yang", "Michael Emmerich"], "venue": "In International Conference on Evolutionary Multi-Criterion Optimization,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "Noise and the reality gap: The use of simulation in evolutionary robotics", "author": ["Nick Jakobi", "Phil Husbands", "Inman Harvey"], "venue": "In European Conference on Artificial Life,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1995}, {"title": "The transferability approach: Crossing the reality gap in evolutionary robotics", "author": ["Sylvain Koos", "Jean-Baptiste Mouret", "St\u00e9phane Doncieux"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "The iCub humanoid robot: an open platform for research in embodied cognition", "author": ["Giorgio Metta", "Giulio Sandini", "David Vernon", "Lorenzo Natale", "Francesco Nori"], "venue": "In Proceedings of the 8th workshop on performance metrics for intelligent systems,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2008}, {"title": "Illuminating search spaces by mapping elites", "author": ["Jean-Baptiste Mouret", "Jeff Clune"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "Multiple chaotic central pattern generators with learning for legged locomotion and malfunction compensation", "author": ["Guanjiao Ren", "Weihai Chen", "Sakyasingha Dasgupta", "Christoph Kolodziejski", "Florentin W\u00f6rg\u00f6tter", "Poramate Manoonpong"], "venue": "Information Sciences,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Taking the human out of the loop: A review of Bayesian optimization", "author": ["Bobak Shahriari", "Kevin Swersky", "Ziyu Wang", "Ryan P Adams", "Nando de Freitas"], "venue": "Proceedings of the IEEE,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}, {"title": "iCub: the design and realization of an open humanoid platform for cognitive and neuroscience research", "author": ["Nikolaos G. Tsagarakis", "Giorgio Metta", "Giulio Sandini", "David Vernon", "Ricardo Beira", "Francesco Becchi", "Ludovic Righetti", "Jose Santos-Victor", "Auke Jan Ijspeert", "Maria Chiara Carrozza", "Darwin G. Caldwell"], "venue": "Advanced Robotics,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2007}, {"title": "Expected hypervolume improvement algorithm for PID controller tuning and the multiobjective dynamical control of a biogas plant", "author": ["Kaifeng Yang", "Daniel Gaida", "Thomas B\u00e4ck", "Michael Emmerich"], "venue": "IEEE Congress on Evolutionary Computation (CEC),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "Current robots would greatly benefit from being capable of carrying on with their mission when they are damaged, as illustrated by the recent DARPA Robotics Challenge [1, 4].", "startOffset": 167, "endOffset": 173}, {"referenceID": 3, "context": "Current robots would greatly benefit from being capable of carrying on with their mission when they are damaged, as illustrated by the recent DARPA Robotics Challenge [1, 4].", "startOffset": 167, "endOffset": 173}, {"referenceID": 6, "context": "When damaged, most robots attempt to diagnose the fault and search for a contingency plan; but they could also exploit a reinforcement learning algorithm so that they can find compensatory behaviors without having to \"understand\" the damage [7, 15].", "startOffset": 241, "endOffset": 248}, {"referenceID": 14, "context": "When damaged, most robots attempt to diagnose the fault and search for a contingency plan; but they could also exploit a reinforcement learning algorithm so that they can find compensatory behaviors without having to \"understand\" the damage [7, 15].", "startOffset": 241, "endOffset": 248}, {"referenceID": 4, "context": "If they follow this second approach, robots need learning algorithms that are highly data-efficient [5] because too many trials would waste precious time to achieve the mission.", "startOffset": 100, "endOffset": 103}, {"referenceID": 6, "context": "One of the most promising approaches for data-efficient robot damage recovery is the recently introduced Intelligent Trial-and-Error algorithm (IT&E) [7].", "startOffset": 150, "endOffset": 153}, {"referenceID": 15, "context": "It combines two ideas: (1) a Bayesian optimization (BO) algorithm [16] that optimizes a reward function, because it is a generic, dataefficient policy search algorithm [3], and (2) a behavior-performance map generated before the mission with a simulation of the intact robot, which acts both as a prior for the Bayesian optimization algorithm and as a dimension reduction algorithm.", "startOffset": 66, "endOffset": 70}, {"referenceID": 2, "context": "It combines two ideas: (1) a Bayesian optimization (BO) algorithm [16] that optimizes a reward function, because it is a generic, dataefficient policy search algorithm [3], and (2) a behavior-performance map generated before the mission with a simulation of the intact robot, which acts both as a prior for the Bayesian optimization algorithm and as a dimension reduction algorithm.", "startOffset": 168, "endOffset": 171}, {"referenceID": 6, "context": "This combination allowed a damaged 6-legged robot to find a new gait in about a dozen of trials (less than 2 minutes), and a robotic arm to overcome several blocked joints in a few minutes [7].", "startOffset": 189, "endOffset": 192}, {"referenceID": 12, "context": "This issue is especially concerning for expensive prototypes like the iCub robot [13, 17]: these robots are too expensive (around 250k euros for the iCub) and too fragile to try risky behaviors.", "startOffset": 81, "endOffset": 89}, {"referenceID": 16, "context": "This issue is especially concerning for expensive prototypes like the iCub robot [13, 17]: these robots are too expensive (around 250k euros for the iCub) and too fragile to try risky behaviors.", "startOffset": 81, "endOffset": 89}, {"referenceID": 1, "context": "While recent methods, like SafeOPT [2], tackle this issue successfully, they require an initial safe set of parameters, that is hard to estimate in an unknown damage setting.", "startOffset": 35, "endOffset": 38}, {"referenceID": 6, "context": "In this paper, we extend the IT&E algorithm [7] by adding safety constraints [9] and automatically computing priors over the safety of controller parameters, so that the probability of breaking the robot during the learning process is as low as possible.", "startOffset": 44, "endOffset": 47}, {"referenceID": 8, "context": "In this paper, we extend the IT&E algorithm [7] by adding safety constraints [9] and automatically computing priors over the safety of controller parameters, so that the probability of breaking the robot during the learning process is as low as possible.", "startOffset": 77, "endOffset": 80}, {"referenceID": 13, "context": "This step is achieved with an evolutionary algorithm called MAP-Elites [14], which, instead of searching for a single, best solution, like standard optimization algorithms, searches for the highest-performing individual for each point in a user-defined space.", "startOffset": 71, "endOffset": 75}, {"referenceID": 6, "context": "For example, by defining one dimension for each leg\u2019s fraction of time spent on the ground, MAP-Elites produces a wide variety of walking gaits for a hexapod robot [7].", "startOffset": 164, "endOffset": 167}, {"referenceID": 6, "context": "To search for the best behavior on the damaged robot, IT&E alters the classical BO scheme [7] by (1) searching a behavior in the map, instead of searching the best policy parameters, and (2) modeling the difference between the performance predicted by the map (M(\u00b7)) and the actual performance, instead of directly modeling the performance function.", "startOffset": 90, "endOffset": 93}, {"referenceID": 6, "context": "This approach leads to short adaptation times in several experiments with damaged robots [7], but it has a serious limitation that prevents it from being used with expensive robots: it lacks safety constraints, that is, nothing prevents the robot from trying dangerous behaviors.", "startOffset": 89, "endOffset": 92}, {"referenceID": 10, "context": "To make matters worse, a damage recovery algorithm would have to compensate for the reality gap [11, 12] as well3.", "startOffset": 96, "endOffset": 104}, {"referenceID": 11, "context": "To make matters worse, a damage recovery algorithm would have to compensate for the reality gap [11, 12] as well3.", "startOffset": 96, "endOffset": 104}, {"referenceID": 8, "context": "sIT&E uses a constrained BO procedure [9] in which each user-defined safety constraint, ci(x), is modeled as a separate GP.", "startOffset": 38, "endOffset": 41}, {"referenceID": 8, "context": "The next sample is selected by optimizing the Expected Constrained Improvement (ECI) acquisition function [9]:", "startOffset": 106, "endOffset": 109}, {"referenceID": 8, "context": "where x\u0302 is the candidate point, ci(x\u0302), i \u2208 {1, \u00b7 \u00b7 \u00b7 , n} are the n constraint functions and EI(x\u0302) is the standard expected improvement [9].", "startOffset": 139, "endOffset": 142}, {"referenceID": 12, "context": "To evaluate our algorithm, we use a simulated iCub robot [13, 17] performing a crawling task.", "startOffset": 57, "endOffset": 65}, {"referenceID": 16, "context": "To evaluate our algorithm, we use a simulated iCub robot [13, 17] performing a crawling task.", "startOffset": 57, "endOffset": 65}, {"referenceID": 7, "context": "We compare 3 algorithms in terms of the best safe performance observed and unsafe trials attempted: (1) IT&E maximizing crawling speed; (2) a multi-objective [8] IT&E algorithm (MO-IT&E; based on the Expected Hypervolume Improvement [10, 18]), that maximizes the crawling speed and minimizes the sum of contact point forces, therefore, building a Pareto front from which the safest behavior can be chosen; and (3) sIT&E maximizing crawling speed within the safe region as described above.", "startOffset": 158, "endOffset": 161}, {"referenceID": 9, "context": "We compare 3 algorithms in terms of the best safe performance observed and unsafe trials attempted: (1) IT&E maximizing crawling speed; (2) a multi-objective [8] IT&E algorithm (MO-IT&E; based on the Expected Hypervolume Improvement [10, 18]), that maximizes the crawling speed and minimizes the sum of contact point forces, therefore, building a Pareto front from which the safest behavior can be chosen; and (3) sIT&E maximizing crawling speed within the safe region as described above.", "startOffset": 233, "endOffset": 241}, {"referenceID": 17, "context": "We compare 3 algorithms in terms of the best safe performance observed and unsafe trials attempted: (1) IT&E maximizing crawling speed; (2) a multi-objective [8] IT&E algorithm (MO-IT&E; based on the Expected Hypervolume Improvement [10, 18]), that maximizes the crawling speed and minimizes the sum of contact point forces, therefore, building a Pareto front from which the safest behavior can be chosen; and (3) sIT&E maximizing crawling speed within the safe region as described above.", "startOffset": 233, "endOffset": 241}, {"referenceID": 5, "context": "All experiments were conducted using the limbo framework [6].", "startOffset": 57, "endOffset": 60}, {"referenceID": 1, "context": "In future work, we will compare our results to approaches based on safety regions [2], which might be safer, but may prove too conservative performance-wise.", "startOffset": 82, "endOffset": 85}], "year": 2016, "abstractText": "The recently introduced Intelligent Trial-and-Error (IT&E) algorithm showed that robots can adapt to damage in a matter of a few trials. The success of this algorithm relies on two components: prior knowledge acquired through simulation with an intact robot, and Bayesian optimization (BO) that operates on-line, on the damaged robot. While IT&E leads to fast damage recovery, it does not incorporate any safety constraints that prevent the robot from attempting harmful behaviors. In this work, we address this limitation by replacing the BO component with a constrained BO procedure. We evaluate our approach on a simulated damaged humanoid robot that needs to crawl as fast as possible, while performing as few unsafe trials as possible. We compare our new \u201csafety-aware IT&E\u201d algorithm to IT&E and a multi-objective version of IT&E in which the safety constraints are dealt as separate objectives. Our results show that our algorithm outperforms the other approaches, both in crawling speed within the safe regions and number of unsafe trials.", "creator": "LaTeX with hyperref package"}}}