{"id": "1612.09434", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Dec-2016", "title": "Data driven estimation of Laplace-Beltrami operator", "abstract": "approximations utilizing laplace - beltrami operators on manifolds across graph \u03b3 - cians arguably become popular tools in data analysis and machine learning. these discretized operators ultimately depend on local parameters whose tuning remains a theoretical and practical problem. in this paper, we address this problem involving the unnormalized graph laplacian as establishing an oracle inequality that opens the door to a well - valid data - driven procedure about the bandwidth selection. our approach relies on recent results by lacour and massart [ lm15 ] on the so - called weber's scale.", "histories": [["v1", "Fri, 30 Dec 2016 09:33:07 GMT  (234kb,D)", "http://arxiv.org/abs/1612.09434v1", null]], "reviews": [], "SUBJECTS": "cs.CG cs.LG math.ST stat.TH", "authors": ["fr\u00e9d\u00e9ric chazal", "ilaria giulini", "bertrand michel"], "accepted": true, "id": "1612.09434"}, "pdf": {"name": "1612.09434.pdf", "metadata": {"source": "CRF", "title": "Data driven estimation of Laplace-Beltrami operator", "authors": ["Fr\u00e9d\u00e9ric Chazal", "Ilaria Giulini"], "emails": ["frederic.chazal@inria.fr", "ilaria.giulini@me.com", "bertrand.michel@ec-nantes.fr"], "sections": [{"heading": "1 Introduction", "text": "The Laplace-Beltrami operator is a fundamental and widely studied mathematical tool carrying a lot of intrinsic topological and geometric information about the Riemannian manifold on which it is defined. Its various discretizations, through graph Laplacians, have inspired many applications in data analysis and machine learning and led to popular tools such as Laplacian EigenMaps [BN03] for dimensionality reduction, spectral clustering [VL07], or semi-supervised learning [BN04], just to name a few.\nDuring the last fifteen years, many efforts, leading to a vast literature, have been made to understand the convergence of graph Laplacian operators built on top of (random) finite samples to LaplaceBeltrami operators. For example pointwise convergence results have been obtained in [BN05] (see also [BN08]) and [HAL07], and a (uniform) functional central limit theorem has been established in [GK06]. Spectral convergence results have also been proved by [BN07] and [VLBB08]. More recently, [THJ11] analyzed the asymptotic of a large family of graph Laplacian operators by taking the diffusion process approach previously proposed in [NLCK06].\nGraph Laplacians depend on scale or bandwidth parameters whose choice is often left to the user. Although many convergence results for various metrics have been established, little is known about how to rigorously and efficiently tune these parameters in practice. In this paper we address this problem in the case of unnormalized graph Laplacian. More precisely, given a Riemannian manifold M of known dimension d and a function f : M \u2192 R , we consider the standard unnormalized graph Laplacian operator defined by\n\u2206\u0302hf(y) = 1\nnhd+2 \u2211 i K ( y \u2212Xi h ) [f(Xi)\u2212 f(y)] , y \u2208M,\n30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\nar X\niv :1\n61 2.\n09 43\n4v 1\n[ cs\n.C G\n] 3\nwhere h is a bandwidth, X1, . . . , Xn is a finite point cloud sampled on M on which the values of f can be computed, and K is the Gaussian kernel: for y \u2208 Rm\nK(y) = 1\n(4\u03c0)d/2 e\u2212\u2016y\u2016 2 m/4, (1)\nwhere \u2016y\u2016m is the Euclidean norm in the ambiant space Rm. In this case, previous results (see for instance [GK06]) typically say that the bandwidth parameter h in \u2206\u0302h should be taken of the order of n\u2212 1 d+2+\u03b1 for some \u03b1 > 0, but in practice, for a given point cloud, these asymptotic results are not sufficient to choose h efficiently. In the context of neighbor graphs [THJ11] proposes self-tuning graphs by choosing h locally in terms of the distances to the k-nearest neighbor, but note that k still need to be chosen and moreover as far as we know there is no guarantee for such method to be rate-optimal. More recently a data driven method for spectral clustering has been proposed in [Rie15]. Cross validation [AC+10] is the standard approach for tuning parameters in statistics and machine learning. Nevertheless, the problem of choosing h in \u2206\u0302h is not easy to rewrite as a cross validation problem, in particular because there is no obvious contrast corresponding to the problem (see [AC+10]).\nThe so-called Lepski\u2019s method is another popular method for selecting the smoothing parameter of an estimator. The method has been introduced by Lepski [Lep92b, Lep93, Lep92a] for kernel estimators and local polynomials for various risks and several improvements of the method have then been proposed, see [LMS97, GL09, GL+08]. In this paper we adapt Lepski\u2019s method for selecting h in the graph Laplacian estimator \u2206\u0302h. Our method is supported by mathematical guarantees: first we obtain an oracle inequality - see Theorem 3.1 - and second we obtain the correct rate of convergence - see Theorem 3.3 - already proved in the asymptotical studies of [BN05] and [GK06] for non data-driven choices of the bandwidth. Our approach follows the ideas recently proposed in [LM15], but for the specific problem of Laplacian operators on smooth manifolds. In this first work about the data-driven estimation of Laplace-Beltrami operator, we focus as in [BN05] and [GK06] on the pointwise estimation problem: we consider a smooth function f on M and the aim is to estimate \u2206\u0302f for the L2-norm \u2016 \u00b7 \u20162,M on M \u2282 Rm. The data driven method presented here may be adapted and generalized for other types of risks (uniform norms on functional family and convergence of the spectrum) and other types of graph Laplacian operators, this will be the subject of future works.\nThe paper is organized as follows: Lepski\u2019s method is introduced in Section 2. The main results are stated in Section 3 and a sketch of their proof is given in Section 4 (the complete proofs are given in the supplementary material). A numerical illustration and a discussion about the proposed method are given in Sections 5 and 6 respectively."}, {"heading": "2 Lepski\u2019s procedure for estimating the Laplace-Beltrami operator", "text": "All the Riemannian manifolds considered in the paper are smooth compact d-dimensional submanifolds (without boundary) of Rm endowed with the Riemannian metric induced by the Euclidean structure of Rm. Recall that, given a compact d-dimensional smooth Riemannian manifold M with volume measure \u00b5, its Laplace-Beltrami operator is the linear operator \u2206 defined on the space of smooth functions on M as \u2206(f) = \u2212div(\u2207f) where \u2207f is the gradient vector field and div the divergence operator. In other words, using the Stoke\u2019s formula, \u2206 is the unique linear operator satisfying \u222b\nM \u2016\u2207f\u20162d\u00b5 = \u222b M \u2206(f)fd\u00b5.\nReplacing the volume measure \u00b5 by a distribution P which is absolutely continuous with respect to \u00b5, the weighted Laplace-Beltrami operator \u2206P is defined as\n\u2206Pf = \u2206f + 1\np \u3008\u2207p,\u2207f\u3009 , (2)\nwhere p is the density of P with respect to \u00b5. The reader may refer to classical textbooks such as, e.g., [Ros97] or [Gri09] for a general and detailed introduction to Laplace operators on manifolds.\nIn the following, we assume that we are given n points X1, . . . , Xn sampled on M according to the distribution P. Given a smooth function f on M , the aim is to estimate \u2206Pf , by selecting\nan estimator in a given finite family of graph Laplacian (\u2206\u0302hf)h\u2208H, where H is a finite family of bandwidth parameters.\nLepski\u2019s procedure is generally presented as a method for selecting bandwidth in an adaptive way. More generally, this method can be seen as an estimator selection procedure."}, {"heading": "2.1 Lepski\u2019s procedure", "text": "We first shortly explain the ideas of Lepski\u2019s method. Consider a target quantity s, a collection of estimators (s\u0302h)h\u2208H and a loss function `(\u00b7, \u00b7). A standard objective when selecting s\u0302h is trying to minimize the risk E`(s, s\u0302h) among the family of estimators. In most settings, the risk of an estimator can be decomposed into a bias part and a variance part. Of course neither the risk, the bias nor the variance of an estimator are known in practice. However in many cases, the variance term can be controlled quite precisely. Lepski\u2019s method requires that the variance of each estimator s\u0302h can be tightly upper bounded by a quantity v(h). In most cases, the bias can be written as `(s, s\u0304h) where s\u0304h corresponds to some (deterministic) averaged version of s\u0302h. It thus seems natural to estimate `(s, s\u0304h) by `(s\u0302h\u2032 , s\u0302h) for some h\u2032 smaller than h. The later quantity incorporates some randomness while the bias does not. The idea is to remove the \u201crandom part\" of the estimation by considering [`(s\u0302h\u2032 , s\u0302h)\u2212 v(h)\u2212 v(h\u2032)]+, where [ ]+ denotes the positive part. The bias term is estimated by considering all pairs of estimators (sh, s\u0302h\u2032) through the quantity suph\u2032\u2264h [`(s\u0302h\u2032 , s\u0302h)\u2212 v(h)\u2212 v(h\u2032)]+. Finally, the estimator minimizing the sum of the estimated bias and variance is selected, see eq. (3) below.\nIn our setting, the control of the variance of the graph Laplacian estimators \u2206\u0302h is not tight enough to directly apply the above described method. To overcome this issue, we use a more flexible version of Lepski\u2019s method that involves some multiplicative coefficients a and b introduced in the variance and bias terms. More precisely, let V (h) = Vf (h) be an upper bound for E[\u2016(E[\u2206\u0302h]\u2212 \u2206\u0302h)f\u201622,M ]. The bandwidth h\u0302 selected by our Lepski\u2019s procedure is defined by\nh\u0302 = h\u0302f = arg min h\u2208H {B(h) + bV (h)} (3)\nwhere B(h) = Bf (h) = max\nh\u2032\u2264h, h\u2032\u2208H\n[ \u2016(\u2206\u0302h\u2032 \u2212 \u2206\u0302h)f\u201622,M \u2212 aV (h\u2032) ] +\n(4)\nwith 0 < a \u2264 b. The calibration of the constants a and b in practice is beyond the scope of this paper, but we suggest a heuristic procedure inspired from [LM15] in section 5."}, {"heading": "2.2 Variance of the graph Laplacian for smooth functions", "text": "In order to control the variance term, we consider for this paper the set F of smooth functions f : M \u2192 R uniformly bounded up to the third order. For some constant CF > 0 , let\nF = { f \u2208 C3(M,R) , \u2016f (k)\u2016\u221e \u2264 CF , k = 0, . . . , 3 } (5)\nHere, by \u2016f (k)\u2016\u221e \u2264 CF we mean that in any normal coordinate systems all the partial derivatives of order k of f are bounded by CF .\nWe introduce some notation before giving the variance term for f \u2208 F . Define\nD\u03b1 = 1\n(4\u03c0)d \u222b Rd ( C\u2016u\u2016\u03b1+2d 2 + C1\u2016u\u2016\u03b1d ) e\u2212\u2016u\u2016 2 d/4 du (6)\nD\u0303\u03b1 = 1\n(4\u03c0)d/2 \u222b Rd ( C\u2016u\u2016\u03b1+2d 4 + C1\u2016u\u2016\u03b1d ) e\u2212\u2016u\u2016 2 d/8 du (7)\nwhere \u2016\u2016d is the euclidean norm in Rd and where C and C1 are geometric constants that only depend on the metric structure of M (see Lemma 6.1 in the appendices). We also introduce the d-dimensional Gaussian kernel on Rd:\nKd(u) = 1\n(4\u03c0)d/2 e\u2212\u2016u\u2016 2 d/4, u \u2208 Rd\nand we denote by \u2016 \u00b7 \u2016p,d the Lp-norm on Rd. The next proposition provides an explicit bound V (h) on the variance term. Let \u03c9d = 3\u00d7 2d/2\u22121 (8) and\n\u03b1d(h) = h 2 ( D4 + 3\n2 \u03c9d \u2016Kd\u201622,d +\n2\u00b5(M)\n(4\u03c0)d\n) + h4\nD6 4 . (9)\nWe first need to control the variance of \u2206\u0302hf over F . This will be possible by considering Taylor Young expansions of f in normal coordinates. For that purpose, for technical reasons following from Lemma 6.1, we constrain the parameter h to satisfy the following inequality\n2 \u221a d+ 4h log(h\u22121)1/2 \u2264 \u03c1(M), (10)\nwhere \u03c1(M) is a geometric constant that only depends on the reach and the injectivity radius of M.\nProposition 2.1. Given h \u2208 H and for any f \u2208 F , we have\nV (h) := 2C2F nhd+2\n[ wd\u2016Kd\u201622,d + \u03b1d(h) ] \u2264 E[\u2016(E[\u2206\u0302h]\u2212 \u2206\u0302h)f\u201622,M ].\nFor the proof we refer to section 6.1."}, {"heading": "3 Results", "text": "We now give the main result of the paper: an oracle inequality for the estimator \u2206\u0302h\u0302, or in other words, a bound on the risk that shows that the performance of the estimator is almost as good as it would be if we knew the risks of each estimator. In particular it performs an (almost) optimal trade-off between the variance term V (h) and the approximation term\nD(h) = Df (h) = max { \u2016(p\u2206P \u2212 E[\u2206\u0302h])f\u20162,M , sup\nh\u2032\u2264h \u2016(E[\u2206\u0302h\u2032 ]\u2212 E[\u2206\u0302h])f\u20162,M } \u2264 2 sup\nh\u2032\u2264h \u2016(p\u2206P \u2212 E[\u2206\u0302h\u2032 ])f\u20162,M .\nTheorem 3.1. According to the notation introduced in the previous section, let = \u221a a/2\u2212 1 and\n\u03b4(h) = \u2211 h\u2032\u2264h max { exp ( \u2212min{ 2, } \u221a n 24 ) , exp ( \u2212 2 3 \u03b3d(h \u2032) )} and\n\u03b3d(h) = 1\nhd\u2016p\u2016\u221e\n[ \u03c9d \u2016Kd\u201622,d + \u03b1d(h)\n(\u03c9d \u2016Kd\u20161,d + \u03b2d(h))2 ] where \u03b1d is defined by (9) and where\n\u03b2d(h) = h ( \u03c9d \u2016Kd\u20161,d + 2\u00b5(M)\n(4\u03c0)d/2\n) + h2D\u03033 +\nh3D\u03034 2 . (11)\nGiven f \u2208 C2(M,R), with probability at least 1\u2212 2 \u2211 h\u2208H \u03b4(h),\n\u2016(p\u2206P \u2212 \u2206\u0302h\u0302)f\u20162,M \u2264 infh\u2208H\n{ 3D(h) + (1 + \u221a 2) \u221a bV (h) } .\nBroadly speaking, Theorem 3.1 says that there exists an event of large probability for which the estimator selected by Lepski\u2019s method is almost as good as the best estimator in the collection. Note that the size of the bandwidth familyH has an impact on the probability term 1\u2212 2 \u2211 h\u2208H \u03b4(h). If H is not too large, an oracle inequality for the risk of \u2206\u0302h\u0302f can be easily deduced from the later result. Henceforth we assume that f \u2208 F . We first give a control on the approximation term D(h).\nProposition 3.2. Assume that the density p is C2. It holds that D(h) \u2264 \u03b3 CFh where CF is defined in eq. (5) and \u03b3 > 0 is a constant depending on M , \u2016p\u2016\u221e, \u2016p\u2032\u2016\u221e and \u2016p\u2032\u2032\u2016\u221e, where \u2016p(k)\u2016\u221e denotes the supremum of the absolute value of the partial derivatives of p in any normal coordinates system.\nWe consider the following grid of bandwidths: H = { e\u2212k , dlog log(n)e \u2264 k \u2264 blog(n)c } .\nNote that this choice ensures that Condition (10) is always satisfied for n large enough. The previous results lead to the pointwise rate of convergence of the graph Laplacian selected by Lepski\u2019s method: Theorem 3.3. Assume that the density p is C2. For any f \u2208 F , we have\nE [ \u2016(p\u2206P \u2212 \u2206\u0302h\u0302)f\u20162,M ] . n\u2212 1 d+4 . (12)"}, {"heading": "4 Sketch of the proof of Theorem 3.1", "text": "We observe that the following inequality holds \u2016(p\u2206P \u2212 \u2206\u0302h\u0302)f\u20162,M \u2264 D(h) + \u2016(E[\u2206\u0302h]\u2212 \u2206\u0302h)f\u20162,M + \u221a 2 (B(h) + bV (h)). (13) Indeed, for h \u2208 H, \u2016(p\u2206P \u2212 \u2206\u0302h\u0302)f\u20162,M \u2264 \u2016(p\u2206P \u2212 E[\u2206\u0302h])f\u20162,M + \u2016(E[\u2206\u0302h]\u2212 \u2206\u0302h)f\u20162,M + \u2016(\u2206\u0302h \u2212 \u2206\u0302h\u0302)f\u20162,M\n\u2264 D(h) + \u2016(E[\u2206\u0302h]\u2212 \u2206\u0302h)f\u20162,M + \u2016(\u2206\u0302h \u2212 \u2206\u0302h\u0302)f\u20162,M .\nBy definition of B(h), for any h\u2032 \u2264 h,\n\u2016(\u2206\u0302h\u2032 \u2212 \u2206\u0302h)f\u201622,M \u2264 B(h) + aV (h\u2032) \u2264 B(max{h, h\u2032}) + aV (min{h, h\u2032}),\nso that, according to the definition of h\u0302 in eq. (3) and recalling that a \u2264 b,\n\u2016(\u2206\u0302h\u0302 \u2212 \u2206\u0302h)f\u2016 2 2,M \u2264 2 [B(h) + aV (h)] \u2264 2 [B(h) + bV (h)]\nwhich proves eq. (13).\nWe are now going to bound the terms that appear in eq. (13). The bound for D(h) is already given in Proposition 3.2, so that in the following we focus on B(h) and \u2016(E[\u2206\u0302h] \u2212 \u2206\u0302h)f\u20162,M . More precisely the bounds we present in the next two propositions are based on the following lemma from [LM15].\nLemma 4.1. Let X1, . . . , Xnbe an i.i.d. sequence of variables. Let S\u0303 a countable set of functions and let \u03b7(s) = 1n \u2211 i [gs(Xi)\u2212 E[gs(Xi)]] for any s \u2208 S\u0303. Assume that there exist constants \u03b8 and vg such that for any s \u2208 S\u0303 \u2016gs\u2016\u221e \u2264 \u03b8 and Var[gs(X)] \u2264 vg. Denote H = E[sups\u2208S\u0303 \u03b7(s)]. Then for any > 0 and any H \u2032 \u2265 H\nP [ sup s\u2208S\u0303 \u03b7(s) \u2265 (1 + )H \u2032 ] \u2264 max { exp ( \u2212 2nH \u20322 6vg ) , exp ( \u2212min{ 2, }nH \u2032 24 \u03b8 )} .\nProposition 4.2. Let = \u221a a 2 \u2212 1. Given h \u2208 H, define\n\u03b41(h) = \u2211 h\u2032\u2264h max { exp ( \u2212min{ 2, } \u221a n 24 ) , exp ( \u2212 2 3 \u03b3d(h \u2032) )} .\nWith probability at least 1\u2212 \u03b41(h) B(h) \u2264 2D(h)2.\nProposition 4.3. Let \u0303 = \u221a a\u2212 1. Given h \u2208 H, define\n\u03b42(h) = max\n{ exp ( \u2212min{\u0303 2, \u0303} \u221a n\n24\n) , exp ( \u2212 \u0303 2\n3 \u03b3d(h)\n)} .\nWith probability at least 1\u2212 \u03b42(h) \u2016(E[\u2206\u0302h]\u2212 \u2206\u0302h)f\u20162,M \u2264 \u221a aV (h).\nCombining the above propositions with eq. (13), we get that, for any h \u2208 H, with probability at least 1\u2212 (\u03b41(h) + \u03b42(h)),\n\u2016(p\u2206P \u2212 \u2206\u0302h\u0302)f\u20162,M \u2264 D(h) + \u221a aV (h) + \u221a 4D(h)2 + 2bV (h)\n\u2264 3D(h) + (1 + \u221a 2) \u221a bV (h)\nwhere we have used the fact that a \u2264 b. Taking a union bound on h \u2208 H we conclude the proof."}, {"heading": "5 Numerical illustration", "text": "In this section we illustrate the results of the previous section on a simple example. In section 5.1, we describe a practical procedure when the data set X is sampled according to the uniform measure on M . A numerical illustration us given in Section 5.2 when M is the unit 2-dimensional sphere in R3."}, {"heading": "5.1 Practical application of the Lepksi\u2019s method", "text": "Lepski\u2019s method presented in Section 2 can not be directly applied in practice for two reasons. First, we can not compute the L2-norm \u2016 \u20162,M onM , the manifoldM being unknown. Second, the variance terms involved in Lepski\u2019s method are not completely explicit.\nRegarding the first issue, we can approximate \u2016 \u20162,M by splitting the data into two samples: an estimation sample X1 for computing the estimators and a validation sample X2 for evaluating this norm. More precisely, given two estimators \u2206\u0302hf and \u2206\u0302h\u2032f computed using X1, the quantity \u2016(\u2206\u0302h \u2212 \u2206\u0302h\u2032)f\u201622,M/\u00b5(M) is approximated by the averaged sum 1n2 \u2211 x\u2208X2 |\u2206\u0302hf(x)\u2212 \u2206\u0302h\u2032f(x)|\n2, where n2 is the number of points in X2. We use these approximations to evaluate the bias terms B(h) defined by (4).\nThe second issue comes from the fact that the variance terms involved in Lepski\u2019s method depend on the metric properties of the manifold and on the sampling density, which are both unknown. Theses variance terms are thus only known up to a multiplicative constant. This situation contrasts with more standard frameworks for which a tight and explicit control on the variance terms can be proposed, as in [Lep92b, Lep93, Lep92a]. To address this second issue, we follow the calibration strategy recently proposed in [LM15] (see also [LMR16]). In practice we remove all the multiplicative constants from V (h): all these constants are passed into the terms a and b. This means that we rewrite Lepski\u2019s method as follows:\nh\u0302(a, b) = arg min h\u2208H\n{ B(h) + b 1\nnh4 } where\nB(h) = max h\u2032\u2264h, h\u2032\u2208H\n[ \u2016(\u2206\u0302h\u2032 \u2212 \u2206\u0302h)f\u201622,M \u2212 a 1\nnh\u20324 ] + .\nWe choose a and b according to the following heuristic:\n1. Take b = a and consider the sequence of selected models: h\u0302(a, a), 2. Starting from large values of a, make a decrease and find the location a0 of the main\nbandwidth jump in the step function a 7\u2192 h\u0302(a, a), 3. Select the model h\u0302(a0, 2a0).\nThe justification of this calibration method is currently the subject of mathematical studies ([LM15]). Note that a similar strategy called \"slope heuristic\" has been proposed for calibrating `0 penalties in various settings by strong mathematical results, see for instance [BM07, AM09, BMM12]."}, {"heading": "5.2 Illustration on the sphere", "text": "In this section we illustrate the complete method on a simple example with data points generated uniformly on the sphere S2 in R3. In this case, the weighted Laplace-Beltrami operator is equal to the (non weighted) Laplace-Beltrami operator on the sphere.\nWe consider the function f(x, y, z) = (x2 + y2 + z) sinx cosx. The restriction of this function on the sphere has the following representation in spherical coordinates:\nf\u0303(\u03b8, \u03c6) = (sin2 \u03c6+ cos\u03c6) sin(sin\u03c6 cos \u03b8) cos(sin\u03c6 cos \u03b8).\nIt is well known that the Laplace-Beltrami operator on the sphere satisfies (see Section 3 in [Gri09]):\n\u2206S2u = 1\nsin2 \u03c6\n\u22022u \u2202\u03b82 + 1 sin\u03c6 \u2202 \u2202\u03c6\n( sin\u03c6 \u2202u\n\u2202\u03c6 ) for any smooth polar function u. This allows us to derive an analytic expression of \u2206S2 f\u0303 .\nWe sample n1 = 106 points on the sphere for computing the graph Laplacians and we use n = 103 points for approximating the norms \u2016(\u2206\u0302h \u2212 \u2206\u0302h\u2032)f\u0303\u201622,M . We compute the graph Laplacians for bandwidths in a grid H between 0.001 and 0.8 (see fig. 1). The risk of each graph Laplacian is estimated by a standard Monte Carlo procedure (see fig. 2).\nFigure 3 illustrates the calibration method. On this picture, the x-axis corresponds to the values of a and the y-axis represents the bandwidths. The blue step function represents the function a 7\u2192 h\u0302(a, a). The red step function gives the model selected by the rule a 7\u2192 h\u0302(a, 2a). Following the heuristics given in Section 5.1, one could take for this example the value a0 \u2248 3.5 (location of the bandwidth jump for the blue curve) which leads to select the model h\u0302(a0, 2a0) \u2248 0.2 (red curve)."}, {"heading": "6 Discussion", "text": "This paper is a first attempt for a complete and well-founded data driven method for inferring LaplaceBeltrami operators from data points. Our results suggest various extensions and raised some questions of interest. For instance, other versions of the graph Laplacian have been studied in the literature (see for instance [HAL07, BN08]), for instance when data is not sampled uniformly. It would be relevant to propose a bandwidth selection method for these alternative estimators also.\nFrom a practical point of view, as explained in section 5, there is a gap between the theory we obtain in the paper and what can be done in practice. To fill this gap, a first objective is to prove an oracle inequality in the spirit of Theorem 3.1 for a bias term defined in terms of the empirical norms\ncomputed in practice. A second objective is to propose mathematically well-founded heuristics for the calibration of the parameters a and b.\nTuning bandwidths for the estimation of the spectrum of the Laplace-Beltrami operator is a difficult but important problem in data analysis. We are currently working on the adaptation of our results to the case of operator norms and spectrum estimation."}, {"heading": "Appendix: the geometric constants C and C1", "text": "The following classical lemma (see, e.g. [GK06][Prop. 2.2 and Eq. 3.20]) relates the constants C and C1 introduced in Equations (6) and (7) to the geometric structure of M . Lemma 6.1. There exist constants C,C1 > 0 and a positive real number r > 0 such that for any x \u2208M , and any v \u2208 TxM such that \u2016v\u2016 \u2264 r,\u2223\u2223\u2223\u2223\u221adet(gij)(v)\u2212 1\u2223\u2223\u2223\u2223 \u2264 C1\u2016v\u20162d and 12\u2016v\u20162d \u2264 \u2016v\u20162d \u2212 C\u2016v\u20164d \u2264 \u2016Ex(v)\u2212 x\u20162m \u2264 \u2016v\u20162d (14) where Ex : TxM \u2192M is the exponential map and (gi,j)i,j \u2208 {1, \u00b7 \u00b7 \u00b7 , d} are the components of the metric tensor in any normal coordinate system around x.\nAlthough the proof of the lemma is beyond the scope of this paper, notice that one can indeed give explicit bounds on r and C in terms of the reach and injectivity radius of the submanifold M ."}, {"heading": "Acknowledgments", "text": "The authors are grateful to Pascal Massart for helpful discussions on Lepski\u2019s method and to Antonio Rieser for his careful reading and for pointing a technical bug in a preliminary version of this work. This work was supported by the ANR project TopData ANR-13-BS01-0008 and ERC Gudhi No. 339025"}, {"heading": "Appendix: Proofs", "text": "For the sake of simplicity, we introduce the renormalized kernel\nHh(y) = 1\nhd+2 K (y/h) =\n1\nhd+2(4\u03c0)d/2 e\u2212\u2016y\u2016 2 m/4h 2 , y \u2208 Rm,\nso that \u2206\u0302h rewrites as\n\u2206\u0302hf(y) = 1\nn n\u2211 i=1 Hh(y \u2212Xi) [f(Xi)\u2212 f(y)]\nwhere we recall that X1, . . . , Xn is a finite point cloud (i.i.d.) sampled on M . Note that the expectation \u2206h of \u2206\u0302h satisfies\n\u2206hf(y) = E\u2206\u0302hf(y) = \u222b Hh(y \u2212 x) [f(x)\u2212 f(y)] dP(x).\nWe present a technical result that is useful in the following and whose proof is postpone to section 6.5.\nLemma 6.2. Let x \u2208 M and h \u2208 H. According to the notation introduced in section 2.2 and in section 3\u222b\nM\n|Hh(y \u2212 x)(f(x)\u2212 f(y))| d\u00b5(y) \u2264 CF h\n[ wd\u2016Kd\u20161,d + \u03b2d(h) ] =: I1(h) (15)\nMoreover\u222b M |Hh(y \u2212 x)(f(x)\u2212 f(y))|2 d\u00b5(y) \u2264 2C2F hd+2 [ wd\u2016Kd\u201622,d + \u03b1d(h) ] =: I2(h). (16)\nWe also observe the following facts.\nRemark 6.3. Given t \u2208 R and s, q > 0,\ntqe\u2212t 2/s2 \u2264 \u03bbe\u2212t 2/2s2\nwhere \u03bb = sqqq/2e\u2212q/2.\nRemark 6.4. Given a, b > 0, e\u2212(a\u2212b) \u2212 e\u2212a \u2264 be\u2212a/2\nso that, under the assumptions of Lemma 6.1, given s > 0,\ne\u2212\u2016Ex(v)\u2212x\u2016 2 m/s 2 \u2212 e\u2212\u2016v\u2016 2 d/s 2 \u2264 e\u2212(\u2016v\u2016 2 d\u2212C\u2016v\u2016 4 d)/s 2 \u2212 e\u2212\u2016v\u2016 2 d/s 2 \u2264 C\u2016v\u2016 4 d\ns2 e\u2212\u2016v\u2016 2 d/2s 2 ."}, {"heading": "6.1 Proof of Proposition 2.1", "text": "In order to get the bound V (h) for E[\u2016(E[\u2206\u0302h] \u2212 \u2206\u0302h)f\u201622,M ] we observe that, according to the definition of \u2206\u0302h and using the fact that the sample is i.i.d.,\nE[\u2016(E[\u2206\u0302h]\u2212 \u2206\u0302h)f\u201622,M ] \u2264 1 n E [\u222b |Hh(y \u2212X)(f(X)\u2212 f(y)|2 d\u00b5(y) ] \u2264 1 n I2(h)\nwhere the last line follows from Lemma 6.2."}, {"heading": "6.2 Proof of Theorem 3.1", "text": "According to the sketch of the proof provided in section 4, we only need to prove Proposition 4.2 and Proposition 4.3."}, {"heading": "6.2.1 Proof of Proposition 4.2", "text": "Recalling the definition of B(h), since, for any h\u2032 \u2264 h,\n\u2016(\u2206\u0302h\u2032 \u2212 \u2206\u0302h)f\u201622,M \u2264 2 [ \u2016(\u2206\u0302h\u2032 \u2212\u2206h\u2032 + \u2206h \u2212 \u2206\u0302h)f\u201622,M + \u2016(\u2206h\u2032 \u2212\u2206h)f\u201622,M ] \u2264 2 [ \u2016(\u2206\u0302h\u2032 \u2212\u2206h\u2032 + \u2206h \u2212 \u2206\u0302h)f\u201622,M +D(h)2\n] we get\nB(h) \u2264 max h\u2032\u2264h\n[ 2\u2016(\u2206\u0302h\u2032 \u2212\u2206h\u2032 + \u2206h \u2212 \u2206\u0302h)f\u201622,M + 2D(h)2 \u2212 aV (h\u2032) ] + .\nThus it is sufficient to prove that\n2\u2016(\u2206\u0302h\u2032 \u2212\u2206h\u2032 + \u2206h \u2212 \u2206\u0302h)f\u201622,M \u2264 aV (h\u2032).\nWe can write\n\u2016(\u2206\u0302h\u2032 \u2212\u2206h\u2032 + \u2206h \u2212 \u2206\u0302h)f\u20162,M = sup t\u2208B2,M (1) \u03b7(f, t)\nwhere B2,M (1) = { t \u2208 L2(M) | \u2016t\u20162,M = 1 } ,\n\u03b7(f, t) = \u3008t, (\u2206\u0302h\u2032 \u2212\u2206h\u2032 + \u2206h \u2212 \u2206\u0302h)f\u3009 = 1\nn n\u2211 i=1 gt,f (Xi)\u2212 E[gt,f (X)]\nand\ngt,f (x) = \u222b t(y) [Hh\u2032(y \u2212 x)\u2212Hh(y \u2212 x)] (f(x)\u2212 f(y)) d\u00b5(y).\nSince the function t 7\u2192 \u03b7(f, t) is continuous on B2,M (1), we consider t \u2208 T where T is a countable set of B2,M (1). In order to apply Lemma 4.1 we need to compute the quantities \u03b8, vg and H .\nLemma 6.5. Let t \u2208 T . With the same notation as in Lemma 6.2\n\u2016gt,f\u2016\u221e \u2264 2 I2(h\u2032)1/2 =: \u03b8\nVar[gt,f (X)] \u2264 4\u2016p\u2016\u221e I1(h\u2032)2 =: vg E [ sup t\u2208T \u03b7(f, t) ] \u2264 2\u221a n I2(h\u2032)1/2 =: H.\nProof. Using the Cauchy-Schwarz inequality and the fact that t \u2208 B2,M we get\n|gt,f (x)| \u2264 \u2016t\u20162,M (\u222b \u2223\u2223\u2223 (Hh\u2032(y \u2212 x)\u2212Hh(y \u2212 x)) (f(x)\u2212 f(y))\u2223\u2223\u22232 d\u00b5(y))1/2\n\u2264 ( 2 \u222b \u2223\u2223\u2223Hh\u2032(y \u2212 x)(f(x)\u2212 f(y))\u2223\u2223\u22232 d\u00b5(y) + 2\n\u222b \u2223\u2223\u2223Hh(y \u2212 x)(f(x)\u2212 f(y))\u2223\u2223\u22232 d\u00b5(y))1/2. According to Lemma 6.2 and recalling that h\u2032 \u2264 h we get\n|gt,f (x)| \u2264 ( 2I2(h\u2032) + 2I2(h) )1/2 \u2264 2 I2(h\u2032)1/2\nwhich proves the first bound. To prove the second inequality we observe that, by the Cauchy-Schwarz inequality,\nVar[gt,f (X)] \u2264 E [ gt,f (X) 2 ]\n= E [(\u222b t(y) [(Hh\u2032 \u2212Hh)(y \u2212X)] (f(X)\u2212 f(y)) d\u00b5(y) )2]\n\u2264 E [ \u2223\u2223\u2223\u2223\u222b t(y)2 ((Hh\u2032 \u2212Hh)(y \u2212X)) (f(X)\u2212 f(y)) d\u00b5(y)\u2223\u2223\u2223\u2223\u00d7 \u00d7 \u2223\u2223\u2223\u2223\u222b ((Hh\u2032 \u2212Hh)(y \u2212X)) (f(X)\u2212 f(y)) d\u00b5(y)\u2223\u2223\u2223\u2223 ] .\nAccording to Lemma 6.2\u2223\u2223\u2223\u2223\u222b ((Hh\u2032 \u2212Hh)(y \u2212X)) (f(X)\u2212 f(y)) d\u00b5(y)\u2223\u2223\u2223\u2223 \u2264 I1(h\u2032) + I1(h) \u2264 2 I1(h\u2032) so that, recalling that the distribution P has a density p with respect to \u00b5,\nVar[gt,f (X)] \u2264 2 I1(h\u2032) E [ \u2223\u2223\u2223\u2223\u222b t(y)2 ((Hh\u2032 \u2212Hh)(y \u2212X)) (f(X)\u2212 f(y)) d\u00b5(y)\u2223\u2223\u2223\u2223 ]\n\u2264 2 I1(h\u2032) \u222b \u2223\u2223t(y)2 ((Hh\u2032 \u2212Hh)(y \u2212X)) (f(X)\u2212 f(y))\u2223\u2223 p(x) d\u00b5(x)d\u00b5(y)\n\u2264 2\u2016p\u2016\u221e I1(h\u2032) \u222b t(y)2 (\u222b |(Hh\u2032 \u2212Hh)(y \u2212X)(f(X)\u2212 f(y))| d\u00b5(x) ) d\u00b5(y).\nUsing again Lemma 6.2 and the fact that t \u2208 B2,M we conclude that Var[gt,f (X)] \u2264 4\u2016p\u2016\u221e I1(h\u2032)2. To get the last inequality we follow the proof of Proposition 2.1. We observe that\nE [ sup t\u2208T \u03b7(f, t)2 ] = E [\u2225\u2225\u2225(\u2206\u0302h\u2032 \u2212 \u2206\u0302h)f \u2212 E [(\u2206\u0302h\u2032 \u2212 \u2206\u0302h)f]\u2225\u2225\u22252 2,M ] \u2264 1 n E [\u222b |(Hh\u2032 \u2212Hh)(y \u2212X)(f(X)\u2212 f(y))|2 d\u00b5(y) ] .\nAccording to Lemma 6.2, E [ sup t\u2208T \u03b7(f, t)2 ] \u2264 2 n (I2(h\u2032) + I2(h)) \u2264 4 n I2(h\u2032) which concludes the proof.\nAccording to Lemma 4.1, with probability at least 1 \u2212 max { exp ( \u2212 2nH2\n6vg\n) , exp ( \u2212min{\n2, }nH 24\u03b8\n)} ,\n\u2016(\u2206\u0302h\u2032 \u2212\u2206h\u2032 + \u2206h \u2212 \u2206\u0302h)f\u20162,M \u2264 (1 + )H where\nH\n\u03b8 = 1\u221a n\nand H2 vg = I2(h\u2032) nI1(h\u2032) = 2 n\u2016p\u2016\u221eh\u2032d\n[ \u03c9d \u2016Kd\u201622,d + \u03b1d(h\u2032)\n(\u03c9d \u2016Kd\u20161,d + \u03b2d(h\u2032))2\n] = 2\u03b3d(h \u2032)\nn .\nMoreover, by definition, H2 \u2264 4V (h\u2032), so that choosing such that a \u2265 4(1 + )2 we get that with probability at least 1\u2212max { exp ( \u2212min{ 2, } \u221a n\n24\n) , exp ( \u2212 2 3 \u03b3d(h \u2032) )}\n2\u2016(\u2206\u0302h\u2032 \u2212\u2206h\u2032 + \u2206h \u2212 \u2206\u0302h)f\u201622,M \u2264 4(1 + )2V (h\u2032) \u2264 aV (h\u2032).\nIn particular we choose = \u221a a/2\u2212 1. The result follows taking a union bound on h\u2032."}, {"heading": "6.2.2 Proof of Proposition 4.3", "text": "The proof follows the one of Proposition 4.2. We can write\n\u2016(\u2206h \u2212 \u2206\u0302h)f\u20162,M = sup t\u2208B2,M (1) \u03b7\u0303(f, t)\nwhere\n\u03b7\u0303(f, t) = 1\nn n\u2211 i=1 ( g\u0303t,f (Xi)\u2212 E[g\u0303t,f (Xi)] ) and\ng\u0303t,f (x) = \u222b t(y)Hh(y \u2212 x)(f(x)\u2212 f(y)) d\u00b5(y).\nMoreover we observe that we can consider t \u2208 T where T \u2282 B2,M (1) is a countable set. Lemma 6.6. Let t \u2208 T . With the notation of Lemma 6.2\n\u2016g\u0303t,f\u2016\u221e \u2264 I2(h)1/2 =: \u03b8\u0303\nVar[g\u0303t,f (X)] \u2264 \u2016p\u2016\u221e I1(h)2 =: v\u0303g E [ sup t\u2208T \u03b7\u0303(f, t) ] \u2264 1\u221a n I2(h)1/2 =: H\u0303.\nProof. We proceed as in the proof of Lemma 6.5. By the Cauchy-Schwarz inequality and Lemma 6.2, recalling that t \u2208 B2,M , we get\n|g\u0303t,f (x)| \u2264 \u2016t\u20162,M (\u222b |Hh(y \u2212 x)(f(x)\u2212 f(y))|2 d\u00b5(y) )1/2 \u2264 I2(h)1/2\nwhich proves the first inequality. To get the second one, we observe that Var[g\u0303t,f (X)] \u2264 E [ g\u0303t,f (X) 2 ]\n\u2264 E [ \u2223\u2223\u2223\u2223\u222b t(y)2Hh(y \u2212X)(f(X)\u2212 f(y)) d\u00b5(y)\u2223\u2223\u2223\u2223 \u00d7 \u2223\u2223\u2223\u2223\u222b Hh(y \u2212X)(f(X)\u2212 f(y)) d\u00b5(y)\u2223\u2223\u2223\u2223\n] \u2264 \u2016p\u2016\u221e I1(h)2.\nTo prove the last inequality we observe that E [ sup t\u2208T \u03b7\u0303(f, t)2 ] = E [\u2225\u2225\u2225\u2206\u0302hf \u2212 E [\u2206\u0302hf]\u2225\u2225\u22252 2,M ] \u2264 1 n E [\u222b |Hh(y \u2212X)(f(X)\u2212 f(y))|2 d\u00b5(y) ] \u2264 1 n I2(h).\nAccording to Lemma 4.1, with probability at least 1 \u2212 max { exp ( \u2212 \u0303 2nH\u03032\n6v\u0303g\n) , exp ( \u2212min{\u0303\n2,\u0303}nH\u0303 24 \u03b8\u0303\n)} , we have\n\u2016(\u2206h \u2212 \u2206\u0302h)f\u20162,M \u2264 (1 + \u0303)H\u0303\nwhere\nH\u0303/\u03b8\u0303 = 1/ \u221a n and H\u03032/v\u0303g = I2(h) n\u2016p\u2016\u221eI1(h) = 2 n\u2016p\u2016\u221ehd\n[ 2\u03c9d \u2016Kd\u201622,d + \u03b1d(h)\n(2\u03c9d \u2016Kd\u20161,d + \u03b2d(h))2\n] = 2\u03b3d(h)\nn .\nMoreover, since H\u03032 = V (h), choosing such that a \u2265 (1 + \u0303)2 we get that with probability at least 1\u2212max { exp ( \u2212min{\u0303 2,\u0303} \u221a n\n24\n) , exp ( \u2212 \u0303 2 3 \u03b3d(h) )}\n\u2016(\u2206h \u2212 \u2206\u0302h)f\u201622,M \u2264 aV (h).\nIn particular choosing \u0303 = \u221a a\u2212 1 we conclude the proof."}, {"heading": "6.3 Proof of Proposition 3.2", "text": "We first prove that, given x \u2208M , |p(x)\u2206Pf(x)\u2212\u2206h\u2032f(x)| \u2264 \u03a6F (h\u2032) (17) where\n\u03a6F (h \u2032) = h\u2032 CF [ 5\u03c4d ( \u2016p\u2016\u221e\n3 + \u2016p\u2032\u2016\u221e + \u2016p\u2032\u2032\u2016\u221e\n) + \u2016p\u2016\u221eD\u03033 +\n2\n(4\u03c0)d/2 ] + h\u20322 CF [ 35\n4 \u2016p\u2032\u2032\u2016\u221e\u03c4d +\n( \u2016p\u2032\u2016\u221e + D\u03034\n\u2016p\u2016\u221e 2 )] + 1\n2 h\u20323 CFD\u03035\n( \u2016p\u2016\u221e\n3 + \u2016p\u2032\u2016\u221e + \u2016p\u2032\u2032\u2016\u221e\n) + 1\n4 h\u20324 CF\u2016p\u2032\u2032\u2016\u221eD\u03036\n+ \u03bad CF (\u2016p\u2032\u2016\u221e + \u2016p\u2016\u221e/2)\n(4\u03c0)d/2 (4(d+ 3))d/2 log(h\u2032\u22121)d/2h\u2032d+3\n+ \u03bad\u22121 CF\u2016p\u2016\u221e\n(4\u03c0)d/2 (4(d+ 3))(d\u22121)/2 log(h\u2032\u22121)(d\u22121)/2h\u2032d+2\nwith\n\u03c4d = 1\n(4\u03c0)d/2 \u222b Rd e\u2212\u2016u\u2016 2 d/8 du\n\u03bad+\u03c3 = 2 \u0393 ( (d+ \u03c3 + 1)/2 )Fd+\u03c3(\u221a2(d+ \u03c3)), \u03c3 \u2208 Z, and\nFd+\u03c3(x) =\n\u222b\u221e x td+\u03c3+1e\u2212t 2/4 dt\nxd+\u03c3e\u2212x2/4 . (18)\nIntroduce B = { y \u2208M | \u2016y \u2212 x\u2016m < Lh\u2032 log(h\u2032\u22121)1/2 } with L > 0 to be chosen and observe that\n\u2206h\u2032f(x) = 1\nh\u2032d+2(4\u03c0)d/2 (\u222b B + \u222b Bc e\u2212\u2016y\u2212x\u2016 2 m/4h \u20322 (f(y)\u2212 f(x)) dP(y) ) =: IBf(x) + IBcf(x).\nWe first recall that the distribution P has a density p with respect to \u00b5.Moreover on B, in the x-normal coordinates, \u00b5 has a density \u221a det(gij) and the Taylor expansion of f is\nf(Ex(v))\u2212 f(x) = f(Ex(v))\u2212 f(Ex(0)) = \u3008f \u2032(x), v\u3009+ 1 2 \u3008f \u2032\u2032(x)v, v\u3009+ 1 6 f \u2032\u2032\u2032(\u03be)(v, v, v)\nfor a suitable \u03be = \u03be(x) \u2208M and where f (k) denotes the k-th derivate with respect to v of f \u25e6 Ex(v). Thus we can write\nIBf(x) = 1\nh\u2032d+2(4\u03c0)d/2 \u222b B e\u2212\u2016y\u2212x\u2016 2 m/4h \u20322 (f(y)\u2212 f(x)) dP(y)\n= 1\nh\u2032d+2(4\u03c0)d/2 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h \u20322 ( \u3008f \u2032(x), v\u3009+ 1 2 \u3008f \u2032\u2032(x)v, v\u3009 ) p(Ex(v)) \u221a det(gij)(v) dv\n+ 1\n6h\u2032d+2(4\u03c0)d/2 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h \u20322 f \u2032\u2032\u2032(\u03be)(v, v, v) p(Ex(v)) \u221a det(gij)(v) dv.\nUsing now the Taylor expansion of p in x-normal coordinates\np(Ex(v)) = p(x) + \u3008p\u2032(x), v\u3009+ 1\n2 \u3008p\u2032\u2032(\u03b6)v, v\u3009\nfor a suitable \u03b6 = \u03b6(x) \u2208M and where as before p(k) denotes k-th derivate of p \u25e6 Ex, we have that\n|\u2206h\u2032f(x)\u2212 p(x)\u2206Pf(x)| \u2264 I1f(x) + I2f(x) + I3f(x) + I4f(x) + I5f(x) + I6f(x) + IBcf(x)\nwhere, denoting by\nS(u) = \u3008f \u2032(x), u\u3009\u3008p\u2032(x), u\u3009+ p(x) 2 \u3008f \u2032\u2032(x)u, u\u3009, (19)\nI1f(x) = \u2223\u2223\u2223\u2223\u2223 1h\u2032d+2(4\u03c0)d/2 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h \u20322 S(v) \u221a det(gij)(v) dv \u2212 p(x)\u2206Pf(x) \u2223\u2223\u2223\u2223\u2223 I2f(x) = 1\nh\u2032d+2(4\u03c0)d/2 \u2223\u2223\u2223\u2223\u2223 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h \u20322 p(x) \u3008f \u2032(x), v\u3009 \u221a det(gij)(v) dv \u2223\u2223\u2223\u2223\u2223 I3f(x) = 1\n2h\u2032d+2(4\u03c0)d/2 \u2223\u2223\u2223\u2223\u2223 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h \u20322 \u3008f \u2032(x), v\u3009 \u3008p\u2032\u2032(\u03b6)v, v\u3009 \u221a det(gij)(v) dv \u2223\u2223\u2223\u2223\u2223 I4f(x) = 1\n2h\u2032d+2(4\u03c0)d/2 \u2223\u2223\u2223\u2223\u2223 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h \u20322 \u3008f \u2032\u2032(x)v, v\u3009\u3008p\u2032(x), v\u3009 \u221a det(gij)(v) dv \u2223\u2223\u2223\u2223\u2223 I5f(x) = 1\n4h\u2032d+2(4\u03c0)d/2 \u2223\u2223\u2223\u2223\u2223 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h \u20322 \u3008f \u2032\u2032(x)v, v\u3009\u3008p\u2032\u2032(\u03b6)v, v\u3009 \u221a det(gij)(v) dv \u2223\u2223\u2223\u2223\u2223 I6f(x) = 1\n6h\u2032d+2(4\u03c0)d/2 \u2223\u2223\u2223\u2223\u2223 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h \u20322 f \u2032\u2032\u2032(\u03be)(v, v, v) p(Ex(v)) \u221a det(gij)(v) dv \u2223\u2223\u2223\u2223\u2223 . Let us now bound each term separately. We first observe that by definition\nIBcf(x) \u2264 2CF\nh\u2032d+2\u2212L2/4(4\u03c0)d/2 .\nFor the proofs of Lemma 6.7 and Lemma 6.8 we refer to section 6.6.\nLemma 6.7. It holds I1f(x) \u2264 CF (\u2016p\u2032\u2016\u221e + \u2016p\u2016\u221e/2) [\n\u03bad (4\u03c0)d/2 Ld log(h\u2032\u22121)d/2h\u2032L 2/4 + D\u03034 h\n\u20322 ] .\nLemma 6.8. It holds I2f(x) \u2264 CF\u2016p\u2016\u221e [ \u03bad\u22121\n(4\u03c0)d/2 Ld\u22121 log(h\u2032\u22121)(d\u22121)/2h\u2032L\n2/4\u22121 + D\u03033 h \u2032 ]\nI3f(x) \u2264 CF\u2016p\u2032\u2032\u2016\u221e h\u2032 (\n5\u03c4d + D\u03035 2 h\u20322\n)\nI4f(x) \u2264 CF\u2016p\u2032\u2016\u221e h\u2032 (\n5\u03c4d + D\u03035 2 h\u20322\n)\nI5f(x) \u2264 CF\u2016p\u2032\u2032\u2016\u221e h\u20322 ( 35\n4 \u03c4d + D\u03036 4 h\u20322\n)\nI6f(x) \u2264 CF\u2016p\u2016\u221eh\u2032 (\n5\u03c4d 3 + D\u03035 6 h\u20322\n) .\nWe choose L = 2 \u221a d+ 3 and we note that Condition 10 is then satisfied. This concludes the proof."}, {"heading": "6.4 Proof of Theorem 3.3", "text": "We first prove the following lemma: Lemma 6.9. Assume that the density p of P is in C1(M,R+). For f \u2208 F , we have\nE [ \u2016(p\u2206P \u2212 \u2206\u0302h\u0302)f\u2016 2 2,M ] \u2264 2 inf\nh\u2208H\n{ 9D(h)2 + (1 + \u221a 2)2bV (h) } + 2 C2F\n\u2211 h\u2208H \u03b4(h) [ 1 hd+2min ( wd\u2016Kd\u201622,d + \u03b1d(hmax) ) + 9 ( \u2016p\u2032\u2016\u221e + \u2016p\u2016\u221e/2 )2 \u00b5(M)\u03c42d ] , (20)\nwhere we recall that \u03c4d = 1(4\u03c0)d/2 \u222b Rd e \u2212\u2016u\u20162d/8 du.\nProof. Let A be the set on which the oracle inequality in Theorem 3.1 holds true. Then E [ \u2016(p\u2206P \u2212 \u2206\u0302h\u0302)f\u2016 2 2,M ] \u2264 E [ \u2016(p\u2206P \u2212 \u2206\u0302h\u0302)f\u2016 2 2,M1A ] + 2E [( \u2016p\u2206Pf\u201622,M + \u2016\u2206\u0302h\u0302f\u2016 2 2,M ) 1Ac ] . (21)\nObserve that to bound the first term, it is sufficient to use Theorem 3.1. Thus we only have to consider the second term. According to eq. (2), we can rewrite the weighted Laplace-Beltrami operator in x-normal coordinates as\n\u2206Pf(x) = 1\n(4\u03c0)d/2\n\u222b e\u2212\u2016u\u2016 2 d/4 ( \u3008p\u2032(x), u\u3009 p(x) \u3008f \u2032(x), u\u3009+ 1 2 \u3008f \u2032\u2032(x)u, u\u3009 ) du,\nso that\n\u2016p\u2206Pf\u201622,M = 1\n(4\u03c0)d\n\u222b (\u222b e\u2212\u2016u\u2016 2 d/4 ( \u3008p\u2032(x), u\u3009 \u3008f \u2032(x), u\u3009+ p(x)\n2 \u3008f \u2032\u2032(x)u, u\u3009\n) du )2 d\u00b5(x)\n\u2264 C 2 F (\u2016p\u2032\u2016\u221e + \u2016p\u2016\u221e/2) 2 \u00b5(M)\n(4\u03c0)d\n(\u222b e\u2212\u2016u\u2016\n2 d/4\u2016u\u20162d du )2 \u2264 9C2F (\u2016p\u2032\u2016\u221e + \u2016p\u2016\u221e/2) 2 \u00b5(M)\u03c42d\nwhere in the last line we have used remark 6.3 with s = 2, q = 2 so that \u03bb \u2264 3. Moreover for any h \u2208 H by Lemma 6.2\n\u2016\u2206\u0302hf\u201622,M \u2264 1\nn2 ( n\u2211 i=1 \u2016Hh(\u00b7 \u2212Xi) (f(Xi)\u2212 f(\u00b7)) \u20162,M )2\n\u2264 I2(h) \u2264 2C2F hd+2min\n[ wd\u2016Kd\u201622,d + \u03b1d(hmax) ] .\nHence E [( \u2016p\u2206Pf\u201622,M + \u2016\u2206\u0302h\u0302f\u2016 2 2,M ) 1Ac ] \u2264 C2F [ 1\nhd+2min\n( wd\u2016Kd\u201622,d + \u03b1d(hmax) ) + 9 ( \u2016p\u2032\u2016\u221e + \u2016p\u2016\u221e/2 )2 \u00b5(M)\u03c42d ] \u2211 h\u2208H \u03b4(h).\nWe now prove Theorem 3.3. Note that \u03b3d(h\u2032) \u2265 Cdh\u2032d with Cd = 1 \u2016p\u2016\u221e\n[ \u03c9d \u2016Kd\u201622,d+\u03b1d(hmin)\n(\u03c9d \u2016Kd\u20161,d+\u03b2d(hmax))2\n] .\nThus,\u2211 h\u2208H \u03b4(h) \u2264 \u2211 h\u2208H \u2211 h\u2032\u2264h max { exp ( \u2212min{ 2, } \u221a n 24 ) , exp ( \u2212Cd c 2 h\u2032d )}\n\u2264 |H|2 exp ( \u2212min{\n2, } C\u2032d hdmax\n)\nwhere C\u2032d > 0 is a constant and |H| denotes the cardinality of the bandwidth setH. For\nH = { e\u2212k , dlog log(n)e \u2264 k \u2264 blog(n)c } ,\nwe get that the second term in eq. (20) is negligible with respect to the first one. Finally, observe that combining Proposition 3.2 with the definition of the variance term V (h), the optimal trade-off in Lemma 6.9 is given by h \u223c n\u2212 1 d+4 , which concludes the proof."}, {"heading": "6.5 Proof of Lemma 6.2", "text": "In order to prove eq. (15), we consider\nB = Bx(h) = {y \u2208M | \u2016y \u2212 x\u2016m < Lh log(h\u22121)1/2} \u2282M\nwhere L > 0 has to be chosen and we observe that\n1\nhd+2(4\u03c0)d/2 \u222b B\u222aBc e\u2212\u2016y\u2212x\u2016 2 m/4h 2 |f(x)\u2212 f(y)|d\u00b5(y).\nWe first look at the integral on B and we consider the x-normal coordinates. Taking into account that the measure \u00b5 has a density \u221a detgij in the x-normal coordinates, we get\n1\nhd+2(4\u03c0)d/2 \u222b B e\u2212\u2016y\u2212x\u2016 2 m/4h 2 |f(x)\u2212 f(y)|d\u00b5(y)\n= 1\nhd+2(4\u03c0)d/2 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h 2 |f(x)\u2212 f(Ex(v))| \u221a detgij(v) dv\n\u2264 1 hd+2(4\u03c0)d/2 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h 2 |f(x)\u2212 f(Ex(v))| (1 + C1\u2016v\u20162d) dv\nwhere in the last line we have used eq. (14). Using the Taylor expansion of f in x-normal coordinates\nf(Ex(v))\u2212 f(x) = f(Ex(v))\u2212 f(Ex(0)) = \u3008f \u2032(x), v\u3009+ 1\n2 \u3008f \u2032\u2032(\u03be)v, v\u3009 (22)\nwhere \u03be = \u03be(x) \u2208 M and f (k) denotes the k-th derivate with respect to v of f \u25e6 Ex(v) the above chain of inequalities is bounded by\n1\nhd+2(4\u03c0)d/2 [\u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h 2 |\u3008f \u2032(x), v\u3009| (1 + C1\u2016v\u20162d) dv\n+ 1\n2 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h 2 |\u3008f \u2032\u2032(\u03be)v, v\u3009| (1 + C1\u2016v\u20162d) dv ]\n\u2264 CF hd+2(4\u03c0)d/2 [\u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h 2 \u2016v\u2016d (1 + C1\u2016v\u20162d) dv\n+ 1\n2 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h 2 \u2016v\u20162d (1 + C1\u2016v\u20162d) dv ]\nwhere in the last line we have used the fact f \u2208 F is uniformly bounded up to the third order. We now consider the two terms separately. We write\n1\nhd+2(4\u03c0)d/2 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h 2 \u2016v\u2016d (1 + C1\u2016v\u20162d) dv\n= 1\nhd+2(4\u03c0)d/2 \u222b E\u22121x (B) e\u2212\u2016v\u2016 2 d/4h 2 \u2016v\u2016d dv +R1\nwhere, according to remark 6.4,\nR1 = 1\n(4\u03c0)d/2hd+2 \u222b E\u22121x (B) ( e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h 2 \u2212 e\u2212\u2016v\u2016 2 d/4h 2 ) \u2016v\u2016d dv\n+ C1\n(4\u03c0)d/2hd+2 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h 2 \u2016v\u20163d dv\n\u2264 1 (4\u03c0)d/2hd+2 \u222b Rd ( C\u2016v\u20165d 4h2 + C1\u2016v\u20163d ) e\u2212\u2016v\u2016 2 d/8h 2 dv = hD\u03033\nand by remark 6.3\n1\n(4\u03c0)d/2hd+2 \u222b E\u22121x (B) e\u2212\u2016v\u2016 2 d/4h 2 \u2016v\u2016d dv \u2264 3 2(4\u03c0)d/2hd+1 \u222b Rd e\u2212\u2016v\u2016 2 d/8h 2 dv\n= 3\u00d7 2d/2\n2(4\u03c0)d/2h \u222b Rd e\u2212\u2016u\u2016 2 d/4 dv = 3\u00d7 2d/2\u22121\u2016Kd\u20161,d h .\nSimilarly, the second term can be written as\n1\nhd+2(4\u03c0)d/2 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h 2 \u2016v\u20162d (1 + C1\u2016v\u20162d) dv\n= 1\nhd+2(4\u03c0)d/2 \u222b E\u22121x (B) e\u2212\u2016v\u2016 2 d/4h 2 \u2016v\u20162d dv +R2\nwhere, according to remark 6.4,\nR2 = 1\n(4\u03c0)d/2hd+2 \u222b E\u22121x (B) ( e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h 2 \u2212 e\u2212\u2016v\u2016 2 d/4h 2 ) \u2016v\u20162d dv\n+ C1\n(4\u03c0)d/2hd+2 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h 2 \u2016v\u20164d dv \u2264 h2D\u03034\nand by remark 6.3 1\n(4\u03c0)d/2hd+2 \u222b E\u22121x (B) e\u2212\u2016v\u2016 2 d/4h 2 \u2016v\u20162d dv \u2264 3\u00d7 2d/2\u2016Kd\u20161,d.\nThis proves that, on B,\n1\nhd+2(4\u03c0)d/2 \u222b B e\u2212\u2016y\u2212x\u2016 2 m/4h 2 |f(x)\u2212 f(y)|d\u00b5(y)\n\u2264 CF\n[ \u03c9d\u2016Kd\u20161,d\nh + \u03c9d\u2016Kd\u20161,d + hD\u03033 + h2D\u03034 2 ] where we recall the definition of \u03c9d = 3\u00d7 2d/2\u22121 in eq. (8). We now consider the integral on Bc. According to the definition of B\n1\nhd+2(4\u03c0)d/2 \u222b B e\u2212\u2016y\u2212x\u2016 2 m/4h 2 |f(x)\u2212 f(y)|d\u00b5(y) \u2264 2CF\u00b5(M) (4\u03c0)d/2hd+2\u2212L2/4 .\nChoosing L = 2 \u221a d+ 2 so that d+ 2\u2212 L2/4 = 0 we prove eq. (15). In a similar way we prove eq. (16). We consider again the ball B defined as above and we write 1\nh2d+4(4\u03c0)d \u222b B\u222aBc e\u2212\u2016y\u2212x\u2016 2 m/2h 2 |f(x)\u2212 f(y)|2 d\u00b5(y).\nProceeding as above, on B we consider the x-normal coordinates and according to eq. (14) we get\n1\nh2d+4(4\u03c0)d \u222b B e\u2212\u2016y\u2212x\u2016 2 m/2h 2 |f(x)\u2212 f(y)|2 d\u00b5(y)\n\u2264 1 h2d+4(4\u03c0)d \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/2h 2 |f(x)\u2212 f(Ex(v))|2 (1 + C1\u2016v\u20162d) dv.\nUsing the Taylor expansion of f in eq. (22) we bound the above quantity by\n2\nh2d+4(4\u03c0)d [\u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/2h 2 \u3008f \u2032(x), v\u30092 (1 + C1\u2016v\u20162d) dv\n+ 1\n4 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/2h 2 \u3008f \u2032\u2032(\u03be)v, v\u30092 (1 + C1\u2016v\u20162d) dv ]\n\u2264 2C 2 F\nh2d+4(4\u03c0)d [\u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/2h 2 \u2016v\u20162 (1 + C1\u2016v\u20162d) dv\n+ 1\n4 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/2h 2 \u2016v\u20164 (1 + C1\u2016v\u20162d) dv ] where in the last line we have used the fact that f \u2208 F . We observe that the first term can be written as\n1\nh2d+4(4\u03c0)d \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/2h 2 \u2016v\u20162 (1 + C1\u2016v\u20162d) dv\n= 1\nh2d+4(4\u03c0)d \u222b E\u22121x (B) e\u2212\u2016v\u2016 2 d/2h 2 \u2016v\u20162 dv + R\u03031\nwhere, by remark 6.4,\nR\u03031 = 1\n(4\u03c0)dh2d+4 \u222b E\u22121x (B) ( e\u2212\u2016Ex(v)\u2212x\u2016 2 m/2h 2 \u2212 e\u2212\u2016v\u2016 2 d/2h 2 ) \u2016v\u20162d dv\n+ C1\n(4\u03c0)dh2d+4 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/2h 2 \u2016v\u20164d dv\n\u2264 1 (4\u03c0)dh2d+4 \u222b E\u22121x (B) ( C\u2016v\u20166d 2h2 + C1\u2016v\u20164d ) e\u2212\u2016v\u2016 2 d/4h 2 dv \u2264 D4 hd\nand according to remark 6.3 with s2 = 2h2 and q = 2 so that \u03bb \u2264 3h 2\n2 ,\n1\n(4\u03c0)dh2d+4 \u222b E\u22121x (B) e\u2212\u2016v\u2016 2 d/2h 2 \u2016v\u20162d dv \u2264 3 2(4\u03c0)dh2d+2 \u222b Rd e\u2212\u2016v\u2016 2 d/4h 2 dv\n= 3\u00d7 2d/2\n2(4\u03c0)dhd+2 \u222b Rd e\u2212\u2016u\u2016 2 d/2 du = 3\u00d7 2d/2\u22121\u2016Kd\u201622,d hd+2 .\nMoreover the second term writes\n1\nh2d+4(4\u03c0)d \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/2h 2 \u2016v\u20164 (1 + C1\u2016v\u20162d) dv\n= 1\nh2d+4(4\u03c0)d \u222b E\u22121x (B) e\u2212\u2016v\u2016 2 d/2h 2 \u2016v\u20164 dv + R\u03032\nwhere, using again remark 6.4,\nR\u03032 = 1\n(4\u03c0)dh2d+4 \u222b E\u22121x (B) ( e\u2212\u2016Ex(v)\u2212x\u2016 2 m/2h 2 \u2212 e\u2212\u2016v\u2016 2 d/2h 2 ) \u2016v\u20164d dv\n+ C1\n(4\u03c0)dh2d+4 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/2h 2 \u2016v\u20166d dv\n\u2264 1 (4\u03c0)dh2d+4 \u222b Rd ( C\u2016v\u20168d 2h2 + C1\u2016v\u20166d ) e\u2212\u2016v\u2016 2 d/4h 2 dv = D6 hd\u22122\nand by remark 6.3 with \u03bb \u2264 9h4,\n1\n(4\u03c0)dh2d+4 \u222b E\u22121x (B) e\u2212\u2016v\u2016 2 d/2h 2 \u2016v\u20164d dv \u2264 9\u00d7 2d/2\u2016Kd\u201622,d hd .\nThen on B we have\n1\nh2d+4(4\u03c0)d \u222b B e\u2212\u2016y\u2212x\u2016 2 m/2h 2 |f(x)\u2212 f(y)|2 d\u00b5(y)\n\u2264 2C2F [ \u03c9d\u2016Kd\u201622,d hd+2 + D4 + 3\u03c9d\u2016Kd\u201622,d/2 hd + D6 4hd\u22122 ] while on Bc\n1\nh2d+4(4\u03c0)d \u222b Bc e\u2212\u2016y\u2212x\u2016 2 m/2h 2 |f(x)\u2212 f(y)|2 d\u00b5(y) \u2264 4C 2 F\u00b5(M) (4\u03c0)dh2d+4\u2212L2/2 .\nThus choosing L = \u221a 2(d+ 4) so that 2d+ 4\u2212 L2/2 = d we conclude the proof."}, {"heading": "6.6 Proofs of the technical lemmas in section 6.3", "text": ""}, {"heading": "6.6.1 Proof of Lemma 6.7", "text": "According to eq. (14),\nI1f(x) \u2264 \u2223\u2223\u2223\u2223\u2223 1h\u2032d+2(4\u03c0)d/2 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h \u20322 S(v) dv \u2212 p(x)\u2206Pf(x) \u2223\u2223\u2223\u2223\u2223 +\nC1 h\u2032d+2(4\u03c0)d/2 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h \u20322 S(v)\u2016v\u20162d dv\n\u2264 \u2223\u2223\u2223\u2223\u2223 1h\u2032d+2(4\u03c0)d/2 \u222b E\u22121x (B) e\u2212\u2016v\u2016 2 d/4h \u20322 S(v) dv \u2212 p(x)\u2206Pf(x) \u2223\u2223\u2223\u2223\u2223+R1 where\nR1 \u2264 1\nh\u2032d+2(4\u03c0)d/2 \u2223\u2223\u2223\u2223\u2223 \u222b E\u22121x (B) ( e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h \u20322 \u2212 e\u2212\u2016v\u2016 2 d/4h \u20322 ) S(v) dv \u2223\u2223\u2223\u2223\u2223 +\nC1 h\u2032d+2(4\u03c0)d/2 \u2223\u2223\u2223\u2223\u2223 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h \u20322 \u2016v\u20162d S(v) dv \u2223\u2223\u2223\u2223\u2223 . Since |S(t)| \u2264 CF (\u2016p\u2032\u2016\u221e + \u2016p\u2016\u221e/2) \u2016t\u20162d by remark 6.3\nR1 \u2264 CF (\u2016p\u2032\u2016\u221e + \u2016p\u2016\u221e/2)\nh\u2032d+2(4\u03c0)d/2\n\u222b E\u22121x (B) e\u2212\u2016v\u2016 2 d/8h \u20322 \u2016v\u20162d ( C\u2016v\u20164d 4h\u20322 + C1\u2016v\u20162d ) dv\n\u2264 CF (\u2016p\u2032\u2016\u221e + \u2016p\u2016\u221e/2) D\u03034 h\u20322.\nMoreover according to eq. (2) we can rewrite the weighted Laplace-Beltrami operator in x-normal coordinates as\n\u2206Pf(x) = 1\n(4\u03c0)d/2\n\u222b e\u2212\u2016u\u2016 2 d/4 ( \u3008p\u2032(x), u\u3009 p(x) \u3008f \u2032(x), u\u3009+ 1 2 \u3008f \u2032\u2032(x)u, u\u3009 ) du,\nso that\np(x)\u2206Pf(x) = 1\n(4\u03c0)d/2\n\u222b e\u2212\u2016u\u2016 2 d/4S(u) du.\nHence, denoting\nB\u0303 := { v \u2208 Rd | \u2016v\u2016d < Lh\u2032 log(h\u2032\u22121)1/2 } \u2282 E\u22121x (B).\nwe get \u2223\u2223\u2223\u2223 1h\u2032d+2(4\u03c0)d/2 \u222b E\u22121x (B) e\u2212\u2016v\u2016 2 d/4h \u20322 S(v) dv \u2212 p(x)\u2206Pf(x) \u2223\u2223\u2223\u2223 = 1\nh\u2032d+2(4\u03c0)d/2 \u2223\u2223\u2223\u2223\u2223 \u222b (E\u22121x (B)) c e\u2212\u2016v\u2016 2 d/4h \u20322 S(v) dv \u2223\u2223\u2223\u2223\u2223 \u2264 CF (\u2016p\n\u2032\u2016\u221e + \u2016p\u2016\u221e/2) h\u2032d+2(4\u03c0)d/2 \u222b B\u0303c e\u2212\u2016v\u2016 2 d/4h \u20322 \u2016v\u20162d dv\n\u2264 CF (\u2016p \u2032\u2016\u221e + \u2016p\u2016\u221e/2) (4\u03c0)d/2 \u222b {\u2016u\u2016d>L log(h\u2032\u22121)1/2} e\u2212\u2016u\u2016 2 d/4\u2016u\u20162d du \u2264 \u03bad CF (\u2016p \u2032\u2016\u221e + \u2016p\u2016\u221e/2)\n(4\u03c0)d/2 Ld log(h\u2032\u22121)d/2h\u2032L 2/4\nwhich concludes the proof."}, {"heading": "6.6.2 Proof of Lemma 6.8", "text": "By eq. (14)\nI2f(x) \u2264 \u2016p\u2016\u221e\nh\u2032d+2(4\u03c0)d/2 \u2223\u2223\u2223\u2223\u2223 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h \u20322 \u3008f \u2032(x), v\u3009 ( 1 + C1\u2016v\u20162d ) dv \u2223\u2223\u2223\u2223\u2223 \u2264 \u2016p\u2016\u221e h\u2032d+2(4\u03c0)d/2 \u2223\u2223\u2223\u2223\u2223 \u222b E\u22121x (B) e\u2212\u2016v\u2016 2 d/4h \u20322 \u3008f \u2032(x), v\u3009dv\n\u2223\u2223\u2223\u2223\u2223+R2 where\nR2 = \u2016p\u2016\u221e\nh\u2032d+2(4\u03c0)d/2 [\u222b E\u22121x (B) ( e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h \u20322 \u2212 e\u2212\u2016v\u2016 2 d/4h \u20322 ) \u3008f \u2032(x), v\u3009dv\n+ C1 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h \u20322 \u2016v\u20162d \u3008f \u2032(x), v\u3009dv ]\nObserve that, by remark 6.3 and eq. (14),\nR2 \u2264 CF\u2016p\u2016\u221e\nh\u2032d+2(4\u03c0)d/2 [\u222b E\u22121x (B) ( e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h \u20322 \u2212 e\u2212\u2016v\u2016 2 d/4h \u20322 ) \u2016v\u2016d dv\n+ C1 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h \u20322 \u2016v\u20163d dv ]\n\u2264 CF\u2016p\u2016\u221e h\u2032d+2(4\u03c0)d/2 \u222b E\u22121x (B) \u2016v\u2016d e\u2212\u2016v\u2016 2 d/8h \u20322 ( C\u2016v\u20164d 4h\u20322 + C1\u2016v\u20162d ) dv\n\u2264 CF\u2016p\u2016\u221eD\u03033 h\u2032\nwhere in the last line we have used the definition of D\u0303\u03b1 introduced in eq. (7). Moreover, observe that\u222b Rd e\u2212\u2016v\u2016 2 d/4h \u20322 \u3008f \u2032(x), v\u3009dv = 0\nand define\nB\u0303 := { v \u2208 Rd | \u2016v\u2016d < Lh\u2032 log(h\u2032\u22121)1/2 } \u2282 E\u22121x (B).\nThen we get\n\u2016p\u2016\u221e h\u2032d+2(4\u03c0)d/2 \u2223\u2223\u2223\u2223\u2223 \u222b E\u22121x (B) e\u2212\u2016v\u2016 2 d/4h \u20322 \u3008f \u2032(x), v\u3009dv \u2223\u2223\u2223\u2223\u2223 =\n\u2016p\u2016\u221e h\u2032d+2(4\u03c0)d/2 \u2223\u2223\u2223\u2223\u2223 \u222b E\u22121x (B)c e\u2212\u2016v\u2016 2 d/4h \u20322 \u3008f \u2032(x), v\u3009dv \u2223\u2223\u2223\u2223\u2223 \u2264 \u2016p\u2016\u221e h\u2032d+2(4\u03c0)d/2 \u2223\u2223\u2223\u2223\u222b B\u0303c e\u2212\u2016v\u2016 2 d/4h \u20322 \u3008f \u2032(x), v\u3009dv\n\u2223\u2223\u2223\u2223 \u2264 CF\u2016p\u2016\u221e h\u2032d+2(4\u03c0)d/2 \u222b B\u0303c e\u2212\u2016v\u2016 2 d/4h \u20322 \u2016v\u2016d dv\n\u2264 CF\u2016p\u2016\u221e h\u2032(4\u03c0)d/2 \u222b {\u2016u\u2016d>L log(h\u2032\u22121)1/2} e\u2212\u2016u\u2016 2 d/4\u2016u\u2016d dv\n\u2264 \u03bad\u22121 CF\u2016p\u2016\u221e (4\u03c0)d/2 Ld\u22121 log(h\u2032\u22121)(d\u22121)/2h\u2032L 2/4\u22121.\nSimilarly we can bound I3f(x). By eq. (14) we have\nI3f(x) \u2264 CF\u2016p\u2032\u2032\u2016\u221e\n2h\u2032d+2(4\u03c0)d/2 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h \u20322 \u2016v\u20163d ( 1 + C1\u2016v\u20162d ) dv\n= CF\u2016p\u2032\u2032\u2016\u221e\n2h\u2032d+2(4\u03c0)d/2 \u222b E\u22121x (B) e\u2212\u2016v\u2016 2 d/4h \u20322 \u2016v\u20163d dv +R3\nwhere, according to remark 6.3,\nR3 = CF\u2016p\u2032\u2032\u2016\u221e\n2h\u2032d+2(4\u03c0)d/2 [\u222b E\u22121x (B) ( e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h \u20322 \u2212 e\u2212\u2016v\u2016 2 d/4h \u20322 ) \u2016v\u20163d dv\n+ C1 \u222b E\u22121x (B) e\u2212\u2016Ex(v)\u2212x\u2016 2 m/4h \u20322 \u2016v\u20165d dv ]\n\u2264 1 2 CF\u2016p\u2032\u2032\u2016\u221eD\u03035 h\u20323\nand by remark 6.3 with s = 2h\u2032 and q = 3 so that \u03bb \u2264 10h\u20323\nCF\u2016p\u2032\u2032\u2016\u221e 2h\u2032d+2(4\u03c0)d/2 \u222b E\u22121x (B) e\u2212\u2016v\u2016 2 d/4h \u20322 \u2016v\u20163d dv \u2264 5CF\u2016p\u2032\u2032\u2016\u221e\u03c4d h\u2032.\nThe bounds for I4f(x), I5f(x), I6f(x) are obtained in the same way."}], "references": [{"title": "A survey of cross-validation procedures for model selection", "author": ["Sylvain Arlot", "Alain Celisse"], "venue": "Statistics surveys,", "citeRegEx": "Arlot and Celisse,? \\Q2010\\E", "shortCiteRegEx": "Arlot and Celisse", "year": 2010}, {"title": "Data-driven calibration of penalties for least-squares regression", "author": ["Sylvain Arlot", "Pascal Massart"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Arlot and Massart.,? \\Q2009\\E", "shortCiteRegEx": "Arlot and Massart.", "year": 2009}, {"title": "Minimal penalties for gaussian model selection", "author": ["Lucien Birg\u00e9", "Pascal Massart"], "venue": "Probability theory and related fields,", "citeRegEx": "Birg\u00e9 and Massart.,? \\Q2007\\E", "shortCiteRegEx": "Birg\u00e9 and Massart.", "year": 2007}, {"title": "Slope heuristics: overview and implementation", "author": ["Jean-Patrick Baudry", "Cathy Maugis", "Bertrand Michel"], "venue": "Statistics and Computing,", "citeRegEx": "Baudry et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Baudry et al\\.", "year": 2012}, {"title": "Laplacian eigenmaps for dimensionality reduction and data representation", "author": ["Mikhail Belkin", "Partha Niyogi"], "venue": "Neural computation,", "citeRegEx": "Belkin and Niyogi.,? \\Q2003\\E", "shortCiteRegEx": "Belkin and Niyogi.", "year": 2003}, {"title": "Semi-supervised learning on riemannian manifolds", "author": ["Mikhail Belkin", "Partha Niyogi"], "venue": "Machine learning,", "citeRegEx": "Belkin and Niyogi.,? \\Q2004\\E", "shortCiteRegEx": "Belkin and Niyogi.", "year": 2004}, {"title": "Towards a theoretical foundation for laplacian-based manifold methods", "author": ["Mikhail Belkin", "Partha Niyogi"], "venue": "In Learning theory,", "citeRegEx": "Belkin and Niyogi.,? \\Q2005\\E", "shortCiteRegEx": "Belkin and Niyogi.", "year": 2005}, {"title": "Convergence of laplacian eigenmaps", "author": ["Mikhail Belkin", "Partha Niyogi"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "Belkin and Niyogi.,? \\Q2007\\E", "shortCiteRegEx": "Belkin and Niyogi.", "year": 2007}, {"title": "Towards a theoretical foundation for laplacian-based manifold methods", "author": ["Mikhail Belkin", "Partha Niyogi"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Belkin and Niyogi.,? \\Q2008\\E", "shortCiteRegEx": "Belkin and Niyogi.", "year": 2008}, {"title": "Empirical graph laplacian approximation of laplace\u2013beltrami operators: Large sample results", "author": ["E. Gin\u00e9", "V. Koltchinskii"], "venue": "In High dimensional probability,", "citeRegEx": "Gin\u00e9 and Koltchinskii.,? \\Q2006\\E", "shortCiteRegEx": "Gin\u00e9 and Koltchinskii.", "year": 2006}, {"title": "Universal pointwise selection rule in multivariate function estimation", "author": ["Alexander Goldenshluger", "Oleg Lepski"], "venue": null, "citeRegEx": "Goldenshluger and Lepski,? \\Q2008\\E", "shortCiteRegEx": "Goldenshluger and Lepski", "year": 2008}, {"title": "Structural adaptation via lp-norm oracle inequalities", "author": ["A. Goldenshluger", "O. Lepski"], "venue": "Probability Theory and Related Fields,", "citeRegEx": "Goldenshluger and Lepski.,? \\Q2009\\E", "shortCiteRegEx": "Goldenshluger and Lepski.", "year": 2009}, {"title": "Heat kernel and analysis on manifolds, volume 47", "author": ["Alexander Grigoryan"], "venue": "American Mathematical Soc.,", "citeRegEx": "Grigoryan.,? \\Q2009\\E", "shortCiteRegEx": "Grigoryan.", "year": 2009}, {"title": "Graph laplacians and their convergence on random neighborhood graphs", "author": ["M. Hein", "JY Audibert", "U.von Luxburg"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Hein et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Hein et al\\.", "year": 2007}, {"title": "On problems of adaptive estimation in white gaussian noise", "author": ["Oleg V Lepski"], "venue": "Topics in nonparametric estimation,", "citeRegEx": "Lepski.,? \\Q1992\\E", "shortCiteRegEx": "Lepski.", "year": 1992}, {"title": "Asymptotically minimax adaptive estimation", "author": ["OV Lepskii"], "venue": "i: Upper bounds. optimally adaptive estimates. Theory of Probability & Its Applications,", "citeRegEx": "Lepskii.,? \\Q1992\\E", "shortCiteRegEx": "Lepskii.", "year": 1992}, {"title": "Asymptotically minimax adaptive estimation. ii. schemes without optimal adaptation: Adaptive estimators", "author": ["OV Lepskii"], "venue": "Theory of Probability & Its Applications,", "citeRegEx": "Lepskii.,? \\Q1993\\E", "shortCiteRegEx": "Lepskii.", "year": 1993}, {"title": "Minimal penalty for goldenshluger-lepski method", "author": ["Claire Lacour", "Pascal Massart"], "venue": "arXiv preprint arXiv:1503.00946,", "citeRegEx": "Lacour and Massart.,? \\Q2015\\E", "shortCiteRegEx": "Lacour and Massart.", "year": 2015}, {"title": "Estimator selection: a new method with applications to kernel density estimation", "author": ["Claire Lacour", "Pascal Massart", "Vincent Rivoirard"], "venue": "arXiv preprint arXiv:1607.05091,", "citeRegEx": "Lacour et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lacour et al\\.", "year": 2016}, {"title": "Optimal spatial adaptation to inhomogeneous smoothness: an approach based on kernel estimates with variable bandwidth selectors", "author": ["Oleg V Lepski", "Enno Mammen", "Vladimir G Spokoiny"], "venue": "The Annals of Statistics,", "citeRegEx": "Lepski et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Lepski et al\\.", "year": 1997}, {"title": "Diffusion maps, spectral clustering and reaction coordinates of dynamical systems", "author": ["B. Nadler", "S. Lafon", "RR Coifman", "IG Kevrekidis"], "venue": "Applied and Computational Harmonic Analysis,", "citeRegEx": "Nadler et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Nadler et al\\.", "year": 2006}, {"title": "A topological approach to spectral clustering", "author": ["Antonio Rieser"], "venue": null, "citeRegEx": "Rieser.,? \\Q2015\\E", "shortCiteRegEx": "Rieser.", "year": 2015}, {"title": "The Laplacian on a Riemannian manifold: an introduction to analysis on manifolds. Number 31", "author": ["Steven Rosenberg"], "venue": null, "citeRegEx": "Rosenberg.,? \\Q1997\\E", "shortCiteRegEx": "Rosenberg.", "year": 1997}, {"title": "An analysis of the convergence of graph laplacians", "author": ["Daniel Ting", "Ling Huang", "Michael Jordan"], "venue": "arXiv preprint arXiv:1101.5435,", "citeRegEx": "Ting et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ting et al\\.", "year": 2011}, {"title": "Consistency of spectral clustering", "author": ["Ulrike Von Luxburg", "Mikhail Belkin", "Olivier Bousquet"], "venue": "The Annals of Statistics,", "citeRegEx": "Luxburg et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Luxburg et al\\.", "year": 2008}], "referenceMentions": [], "year": 2017, "abstractText": "Approximations of Laplace-Beltrami operators on manifolds through graph Laplacians have become popular tools in data analysis and machine learning. These discretized operators usually depend on bandwidth parameters whose tuning remains a theoretical and practical problem. In this paper, we address this problem for the unnormalized graph Laplacian by establishing an oracle inequality that opens the door to a well-founded data-driven procedure for the bandwidth selection. Our approach relies on recent results by Lacour and Massart [LM15] on the so-called Lepski\u2019s method.", "creator": "LaTeX with hyperref package"}}}