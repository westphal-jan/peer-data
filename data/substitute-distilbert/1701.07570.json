{"id": "1701.07570", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Jan-2017", "title": "Strongly Adaptive Regret Implies Optimally Dynamic Regret", "abstract": "increasing aid with changing environments, recent literature publishing online learning has introduced the concepts of adaptive regret and dynamic regret independently. from this paper, we illustrate an intrinsic connection between these two concepts by arguing that the dynamic regret can be expressed in terms of the adaptive regret and dependent functional variation. this observation implies that strongly adaptive algorithms ever be directly leveraged accurately minimize the dynamic regret. as a result, we present a series of strongly adaptive algorithms whose dynamic regrets are minimax optimal stationary convex functions, exponentially concave functions, alternatively strongly convex functions, respectively. to the best of our knowledge, this is first time that such kind of psychological regret treatment is established for exponentially progressive functions. moreover, all of those adaptive algorithms do readily need current prior knowledge of the functional variation, which retains a significant advantage requiring previous specialized methods for minimizing dynamic regret.", "histories": [["v1", "Thu, 26 Jan 2017 03:54:21 GMT  (18kb)", "https://arxiv.org/abs/1701.07570v1", null], ["v2", "Wed, 22 Feb 2017 15:12:55 GMT  (20kb)", "http://arxiv.org/abs/1701.07570v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["lijun zhang", "tianbao yang", "rong jin", "zhi-hua zhou"], "accepted": false, "id": "1701.07570"}, "pdf": {"name": "1701.07570.pdf", "metadata": {"source": "CRF", "title": "Strongly Adaptive Regret Implies Optimally Dynamic Regret", "authors": ["Lijun Zhang", "Tianbao Yang", "Rong Jin", "Zhi-Hua Zhou"], "emails": ["zhanglj@lamda.nju.edu.cn", "tianbao-yang@uiowa.edu", "jinrong.jr@alibaba-inc.com", "zhouzh@lamda.nju.edu.cn"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 1.\n07 57\n0v 2\n[ cs\n.L G"}, {"heading": "1. Introduction", "text": "Online convex optimization is a powerful paradigm for sequential decision making (Shalev-Shwartz, 2011). It can be viewed as a game between a learner and an adversary: In the t-th round, the learner selects a decision wt \u2208 \u2126, simultaneously the adversary chooses a function ft(\u00b7) : \u2126 7\u2192 R, and then the learner suffers an instantaneous loss ft(wt). This study focuses on the full-information setting (Cesa-Bianchi and Lugosi, 2006), where the function ft(\u00b7) is revealed to the leaner at the end of each round. The goal of the learner is to minimize the cumulative loss over T periods. The standard performance measure is regret, which is the difference between the loss incurred by the learner and that of the best fixed decision in hindsight, i.e.,\nRegret(T ) =\nT\u2211\nt=1\nft(wt)\u2212 min w\u2208\u2126\nT\u2211\nt=1\nft(w).\nThe above regret is typically referred to as static regret in the sense that the comparator is time-invariant. The rationale behind this evaluation metric is that one of the decision in \u2126 is reasonably good over the T rounds. However, when the underlying distribution of loss functions changes, the static regret may be too optimistic and fails to capture the hardness of the problem.\nTo address this limitation, new forms of performance measure, including adaptive regret (Hazan and Seshadhri, 2007, 2009) and dynamic regret (Zinkevich, 2003), were proposed and received significant interest recently. Given a parameter \u03c4 , which is the length of the interval, the strong version of adaptive regret is defined as\nSA-Regret(T, \u03c4) = max [s,s+\u03c4\u22121]\u2286[T ]\n( s+\u03c4\u22121\u2211\nt=s\nft(wt)\u2212 min w\u2208\u2126\ns+\u03c4\u22121\u2211\nt=s\nft(w)\n) . (1)\nFrom the definition, we observe that minimizing the adaptive regret enforces the learner has small static regret over any interval of length \u03c4 . Since the best decision for different intervals could be different, the learner is essentially competing with a changing comparator.\nA parallel line of research introduces the concept of dynamic regret, where the cumulative loss of the learner is compared against a comparator sequence u1, . . . ,uT \u2208 \u2126, i.e.,\nD-Regret(u1, . . . ,uT ) = T\u2211\nt=1\nft(wt)\u2212 T\u2211\nt=1\nft(ut). (2)\nIt is well-known that in the worst case, a sublinear dynamic regret is impossible unless we impose some regularities on the comparator sequence or the function sequence (Jadbabaie et al., 2015). A representative example is the functional variation defined below\nVT =\nT\u2211\nt=2\nmax w\u2208\u2126\n|ft(w)\u2212 ft\u22121(w)|. (3)\nBesbes et al. (2015) have proved that as long as VT is sublinear in T , there exists an algorithm that achieves a sublinear dynamic regret. Furthermore, under the noisy gradient feedback, a general restarting procedure is developed, and it enjoys O(T 2/3V 1/3 T ) and\nO(log T \u221a TVT ) rates for convex functions and strongly convex functions, respectively. This result is very strong in the sense that these rates are (almost) minimax optimal. However, the restarting procedure can only be applied when an upper bound of VT is known beforehand, thus limiting its application in practice.\nWhile both the adaptive and dynamic regrets aim at coping with changing environments, little is known about their relationship. This paper makes a step towards understanding their connections. Specifically, we show that the strongly adaptive regret in (1), together with the functional variation, can be used to upper bound the dynamic regret in (2). Thus, an algorithm with a small strongly adaptive regret is automatically equipped with a tight dynamic regret. As a result, we obtain a series of algorithms for minimizing the dynamic regret that do not need any prior knowledge of the functional variation. The main contributions of this work are summarized below.\n\u2022 We provide a general theorem that upper bounds the dynamic regret in terms of the strongly adaptive regret and the functional variation.\n\u2022 For convex functions, we show that the strongly adaptive algorithm of Jun et al. (2016) has a dynamic regret of O(T 2/3V\n1/3 T log 1/3 T ), which matches the minimax rate, up to a polylogarithmic factor. \u2022 For exponentially concave functions, we propose a strongly adaptive algorithm that allows us to control the tradeoff between the adaptive regret and the computational cost explicitly. Furthermore, we demonstrate that its dynamic regret is O( \u221a TVT log T ),\nand this is the first time such kind of dynamic regret bound is established for exponentially concave functions. \u2022 Since strongly convex functions with bounded gradients are also exponentially concave, our previous result immediately implies a dynamic regret of O( \u221a TVT log T ),\nwhich is also minimax optimal up to a polylogarithmic factor. It also indicates our bound for exponentially concave functions is almost optimal."}, {"heading": "2. Related Work", "text": "In this section, we give a brief introduction to previous work on static, adaptive, and dynamic regrets in the context of online convex optimization."}, {"heading": "2.1 Static Regret", "text": "The majority of studies in online learning are focused on static regret Shalev-Shwartz and Singer (2007); Langford et al. (2009). For general convex functions, the classical online gradient descent achieves O( \u221a T ) and O(log T ) regret bounds for convex and strongly convex functions, respectively (Zinkevich, 2003; Hazan et al., 2007; Shalev-Shwartz et al., 2007). Both the O( \u221a T ) and O(log T ) rates are known to be minimax optimal (Abernethy et al., 2009). When functions are exponentially concave, a different algorithm, named online Newton step, is developed and enjoys an O(log T ) regret bound (Hazan et al., 2007)."}, {"heading": "2.2 Adaptive Regret", "text": "The concept of adaptive regret is introduced by Hazan and Seshadhri (2007), and later strengthened by Daniely et al. (2015). To distinguish between them, we refer to the definition of Hazan and Seshadhri (2007) as weakly adaptive regret and the one of Daniely et al. (2015) as strongly adaptive regret. The weak version is given by\nWA-Regret(T ) = max [s,q]\u2286[T ]\nq\u2211\nt=s\nft(wt)\u2212 min w\u2208\u2126\nq\u2211\nt=s\nft(w).\nTo minimize the adaptive regret, Hazan and Seshadhri (2007) have developed two metaalgorithms: an efficient algorithm with O(log T ) computational complexity per iteration and an inefficient one with O(T ) computational complexity per iteration. These metaalgorithms use an existing online method (that was possibly designed to have small static regret) as a subroutine.1 For convex functions, the efficient and inefficient meta-algorithms\n1. For brevity, we ignored the factor of subroutine in the statements of computational complexities. The O(\u00b7) computational complexity should be interpreted as O(\u00b7) \u00d7 s space complexity and O(\u00b7) \u00d7 t time complexity, where s and t are space and time complexities of the subroutine per iteration, respectively.\nhave O( \u221a T log3 T ) and O( \u221a\nT log T ) regret bounds, respectively. For exponentially concave functions, those rates are improved to O(log2 T ) and O(log T ), respectively. We can see that the price paid for the adaptivity is very small: The rates of weakly adaptive regret differ from those of static regret only by logarithmic factors.\nA major limitation of weakly adaptive regret is that it does not respect short intervals well. Taking convex functions as an example, the O( \u221a T log3 T ) and O( \u221a T log T ) bounds\nare meaningless for intervals of length O( \u221a T ). To overcome this limitation, Daniely et al. (2015) proposed a refined adaptive regret that takes the length of the interval as a parameter \u03c4 , as indicated in (1). If the strongly adaptive regret is small for all \u03c4 < T , we can guarantee the learner has small regret over any interval of any length. In particular, Daniely et al. (2015) introduced the following definition.\nDefinition 1 Let R(\u03c4) be the minimax static regret bound of the learning problem over \u03c4 periods. An algorithm is strongly adaptive, if\nSA-Regret(T, \u03c4) = O(poly(log T ) \u00b7R(\u03c4)).\nIt is easy to verify that the meta-algorithms of Hazan and Seshadhri (2007) are strongly adaptive for exponentially concave functions,2 but not for convex functions. Thus, Daniely et al. (2015) developed a new meta-algorithm that satisfies SA-Regret(T, \u03c4) = O( \u221a \u03c4 log T ) for convex functions, and thus is strongly adaptive. The algorithm is also efficient and the computational complexity per iteration is O(log T ). Later, the strongly adaptive regret of convex functions was improved to O( \u221a \u03c4 log T ) by Jun et al. (2016)."}, {"heading": "2.3 Dynamic Regret", "text": "In a seminal work, Zinkevich (2003) proposed to use the path-length defined as\nP(u1, . . . ,uT ) = T\u2211\nt=2\n\u2016ut \u2212 ut\u22121\u20162\nto upper bound the dynamic regret. Specifically, Zinkevich (2003) proved that for any sequence of convex functions, the dynamic regret of online gradient descent can be upper bounded by O( \u221a TP(u1, . . . ,uT )). Another regularity of the comparator sequence, which is similar to the path-length, is defined as\nP \u2032(u1, . . . ,uT ) = T\u2211\nt=2\n\u2016ut \u2212 \u03a6t(ut\u22121)\u20162\nwhere \u03a6t(\u00b7) is a dynamic model that predicts a reference point for the t-th round. Hall and Willett (2013) developed a novel algorithm named dynamic mirror descent and proved that its dynamic regret is on the order of \u221a TP \u2032(u1, . . . ,uT ) . The advantage of P \u2032(u1, . . . ,uT ) is that when the comparator sequence follows the dynamical model closely, it can be much smaller than the path-length P(u1, . . . ,uT ). 2. That is because (i) SA-Regret(T, \u03c4 ) \u2264 WA-Regret(T ), and (ii) there is a poly(log T ) factor in the\ndefinition of strong adaptivity.\nLetw\u2217t \u2208 argminw\u2208\u2126 ft(w) be a local minimizer of ft(\u00b7). For any sequence of u1, . . . ,uT \u2208 \u2126, we have\nD-Regret(u1, . . . ,uT ) =\nT\u2211\nt=1\nft(wt)\u2212 T\u2211\nt=1\nft(ut)\n\u2264D-Regret(w\u22171, . . . ,w\u2217T ) = T\u2211\nt=1\nft(wt)\u2212 T\u2211\nt=1\nmin w\u2208\u2126 ft(w).\nThus, D-Regret(w\u22171, . . . ,w \u2217 T ) can be treated as the worst case of the dynamic regret, and there are many work that were devoted to minimizing D-Regret(w\u22171, . . . ,w \u2217 T ) (Jadbabaie et al., 2015; Mokhtari et al., 2016; Yang et al., 2016; Zhang et al., 2016).\nWhen a prior knowledge of P(w\u22171, . . . ,w\u2217T ) is available, D-Regret(w\u22171, . . . ,w\u2217T ) can be upper bounded by O( \u221a TP(w\u22171, . . . ,w\u2217T )) (Yang et al., 2016). If all the functions are strongly convex and smooth, the upper bound can be improved to O(P(w\u22171, . . . ,w\u2217T )) (Mokhtari et al., 2016). The O(P(w\u22171, . . . ,w\u2217T )) rate is also achievable when all the functions are convex and smooth, and all the minimizersw\u2217t \u2019s lie in the interior of \u2126 (Yang et al., 2016). In a recent study, Zhang et al. (2016) introduced a new regularity\u2014squared pathlength\nS(w\u22171, . . . ,w\u2217T ) = T\u2211\nt=2\n\u2016w\u2217t \u2212w\u2217t\u22121\u201622\nwhich could be much smaller than the path-length P(w\u22171, . . . ,w\u2217T ) when the difference between successive local minimizers is small. Zhang et al. (2016) developed a novel algorithm named online multiple gradient descent, and proved that D-Regret(w\u22171, . . . ,w \u2217 T ) is on the order of min(P(w\u22171, . . . ,w\u2217T ),S(w\u22171, . . . ,w\u2217T )) for (semi-)strongly convex and smooth functions.\nAlthough closely related, adaptive regret and dynamic regret are studied independently and there are few discussions of their relationships. In the literature, dynamic regret is also referred to as tracking regret or shifting regret (Littlestone and Warmuth, 1994; Herbster and Warmuth, 1998, 2001). In the setting of \u201cprediction with expert advice\u201d, Adamskiy et al. (2012) have shown that the tracking regret can be derived from the adaptive regret. In the setting of \u201conline linear optimization in the simplex\u201d, Cesa-bianchi et al. (2012) introduced a generalized notion of shifting regret which unifies adaptive regret and shifting regret. Different from previous work, this paper considers the setting of online convex optimization, and illustrates that the dynamic regret can be upper bounded by the adaptive regret and the functional variation."}, {"heading": "3. From Adaptive to Dynamic", "text": "In this section, we first introduce a general theorem that bounds the dynamic regret by the adaptive regret, and then derive specific regret bounds for convex functions, exponentially concave functions, and strongly convex functions."}, {"heading": "3.1 Adaptive-to-Dynamic Conversion", "text": "Let I1 = [s1, q1],I2 = [s2, q2], . . . ,Ik = [sk, qk] be a partition of [1, T ]. That is, they are successive intervals such that\ns1 = 1, qi + 1 = si+1, i \u2208 [k \u2212 1], and qk = T. (4)\nDefine the local functional variation of the i-th interval as\nVT (i) =\nqi\u2211\nt=si+1\nmax w\u2208\u2126\n|ft(w)\u2212 ft\u22121(w)|\nand it is obvious that \u2211k\ni=1 VT (i) \u2264 VT .3 Then, we have the following theorem for bounding the dynamic regret in terms of the strongly adaptive regret and the functional variation.\nTheorem 1 Let w\u2217t \u2208 argminw\u2208\u2126 ft(w). We have\nD-Regret(w\u22171, . . . ,w \u2217 T ) \u2264 min\nI1,...,Ik\nk\u2211\ni=1\n( SA-Regret(T, |Ii|) + 2|Ii| \u00b7 VT (i) )\nwhere the minimization is taken over any sequence of intervals that satisfy (4).\nThe above theorem is analogous to Proposition 2 of Besbes et al. (2015), which provides an upper bound for a special choice of the interval sequence. The main difference is that there is a minimization operation in our bound, which allows us to get ride of the issue of parameter selection. For a specific type of problems, we can plug in the corresponding upper bound of strongly adaptive regret, and then choose any sequence of intervals to obtain a concrete upper bound. In particular, the choice of the intervals may depend on the (possibly unknown) functional variation.\nBefore proceeding to specific bounds, we introduce the following common assumption.\nAssumption 1 Both the gradient and the domain are bounded. \u2022 The gradients of all the online functions are bounded by G, i.e., maxw\u2208\u2126 \u2016\u2207ft(w)\u2016 \u2264\nG for all ft. \u2022 The diameter of the domain \u2126 is bounded by B, i.e., max w,w\u2032\u2208\u2126 \u2016w \u2212w\u2032\u2016 \u2264 B."}, {"heading": "3.2 Convex Functions", "text": "For convex functions, we choose the meta-algorithm of Jun et al. (2016) and take the online gradient descent as its subroutine. The following theorem regarding the adaptive regret can be obtained from that paper.\nTheorem 2 Under Assumption 1, the meta-algorithm of Jun et al. (2016) is strongly adaptive with\nSA-Regret(T, \u03c4) \u2264 (\n12BG\u221a 2\u2212 1\n+ 8 \u221a 7 log T + 5 )\u221a \u03c4 = O( \u221a \u03c4 log T ).\n3. Note that in certain cases, the sum of local functional variation \u2211k\ni=1 VT (i) can be much smaller than the total functional variation VT . For example, when the sequence of functions only changes k times, we can construct the intervals based on the changing rounds such that \u2211k i=1 VT (i) = 0.\nFrom Theorems 1 and 2, we derive the following bound for the dynamic regret.\nCorollary 3 Under Assumption 1, the meta-algorithm of Jun et al. (2016) satisfies\nD-Regret(w\u22171, . . . ,w \u2217 T ) \u2264max    (c+ 9 \u221a 7 log T + 5) \u221a T (c+ 8 \u221a 5)T 2/3V 1/3 T\nlog1/6 T + 24T 2/3V 1/3 T log 1/3 T\n=O ( max {\u221a T log T , T 2/3V\n1/3 T log\n1/3 T })\nwhere c = 12BG/( \u221a 2\u2212 1).\nAccording to Theorem 2 of Besbes et al. (2015), we know that the minimax dynamic regret of convex functions is O(T 2/3V 1/3 T ). Thus, our upper bound is minimax optimal up to a polylogarithmic factor. The key advantage of the meta-algorithm of Jun et al. (2016) over the restarted online gradient descent of Besbes et al. (2015) is that the former one do not need any prior knowledge of the functional variation VT . Notice that the meta-algorithm of Daniely et al. (2015) can also be used here, and its dynamic regret is on the order of max {\u221a\nT log T, T 2/3V 1/3 T log\n2/3 T } ."}, {"heading": "3.3 Exponentially Concave Functions", "text": "We first provide the definition of exponentially concave (abbr. exp-concave) functions (Cesa-Bianchi and Lugosi, 2006).\nDefinition 2 A function f(\u00b7) : \u2126 7\u2192 R is \u03b1-exp-concave if exp(\u2212\u03b1f(\u00b7)) is concave over domain \u2126.\nExponential concavity is stronger than convexity but weaker than strong convexity. It can be used to model many popular losses used in machine learning, such as the square loss in regression, logistic loss in classification and negative logarithm loss in portfolio management (Koren, 2013).\nFor exp-concave functions, Hazan and Seshadhri (2007) have developed two meta-algorithms that take the online Newton step as its subroutine, and proved the following properties.\n\u2022 The inefficient one has O(T ) computational complexity per iteration, and its weakly adaptive regret is O(log T ). \u2022 The efficient one has O(log T ) computational complexity per iteration, and its weakly adaptive regret is O(log2 T ).\nAs can be seen, there is a tradeoff between the computational complexity and the weakly adaptive regret: A lighter computation incurs a looser bound and a tighter bound requires a higher computation. In Section 4, we develop a unified approach, i.e., Algorithm 1, that allows us to trade effectiveness for efficiency explicitly. Lemma 6 indicates the proposed algorithm has\n(\u230alogK T \u230b+ 1) (K \u2212 1) = O ( K log T\nlogK\n)\ncomputational complexity per iteration, where K is a tunable parameter. On the other hand, Theorem 6 implies that for \u03b1-exp-concave functions that satisfy Assumption 1, the strongly adaptive regret of Algorithm 1 is\n( (5d+ 1)m\u0304+ 2\n\u03b1 + 5dm\u0304GB\n) log T = O ( log2 T\nlogK\n)\nwhere d is the dimensionality and m\u0304 = (\u230alogK T \u230b+ 1). We list several choices of K and the resulting theoretical guarantees in Table 1, and have the following observations.\n\u2022 WhenK = 2, we recover the guarantee of the efficient algorithm of Hazan and Seshadhri (2007), and when K = T , we obtain the inefficient one. \u2022 By setting K = T 1/\u03b3 where \u03b3 > 1 is a small constant, such as 10, the strongly adaptive regret can be viewed as O(log T ), and at the same time, the computational complexity is also very low for a large range of T .\nAccording to Definition 1, Algorithm 1 in this paper, as well as the two meta-algorithms of Hazan and Seshadhri (2007), is strongly adaptive. Based on Theorem 1, we derive the dynamic regret of the proposed algorithm.\nCorollary 4 Let K = T 1/\u03b3 , where \u03b3 > 1 is a small constant. Suppose Assumption 1 holds, \u2126 \u2282 Rd, all the functions are \u03b1-exp-concave. Algorithm 1, with online Newton step as its subroutine, is strongly adaptive with\nSA-Regret(T, \u03c4) \u2264 ( (5d + 1)(\u03b3 + 1) + 2\n\u03b1 + 5d(\u03b3 + 1)GB\n) log T = O (\u03b3 log T ) = O (log T )\nand its dynamic regret satisfies\nD-Regret(w\u22171, . . . ,w \u2217 T )\n\u2264 ( (5d + 1)(\u03b3 + 1) + 2\n\u03b1 + 5d(\u03b3 + 1)GB + 2\n) max { log T, \u221a TVT log T }\n=O ( max { log T, \u221a TVT log T }) .\nTo the best of our knowledge, this is the first time such kind of dynamic regret bound is established for exp-concave functions. Furthermore, the discussions in Section 3.4 implies our upper bound is minimax optimal, up to a polylogarithmic factor."}, {"heading": "3.4 Strongly Convex Functions", "text": "In the following, we study strongly convex functions, defined below.\nDefinition 3 A function f(\u00b7) : \u2126 7\u2192 R is \u03bb-strongly convex if\nf(y) \u2265 f(x) + \u3008\u2207f(x),y \u2212 x\u3009+ \u03bb 2 \u2016y \u2212 x\u201622, \u2200x,y \u2208 \u2126.\nIt is easy to verify that strongly convex functions with bounded gradients are also expconcave (Hazan et al., 2007).\nLemma 4 Suppose f(\u00b7) : \u2126 7\u2192 R is \u03bb-strongly convex and \u2207f(w) \u2264 G for all w \u2208 \u2126. Then, f(\u00b7) is \u03bb\nG2 -exp-concave.\nThus, Corollary 4 can be directly applied to strongly convex functions, and yields a dynamic regret of O( \u221a TVT log T ). According to Theorem 4 of Besbes et al. (2015), the minimax\ndynamic regret of strongly convex functions is O( \u221a TVT ), which implies our upper bound is almost minimax optimal. A limitation of Corollary 4 is that the constant in the upper bound depends on the dimensionality d. In the following, we show that when the functions are strongly convex and online gradient descent is used as the subroutine of Algorithm 1, both the adaptive and dynamic regrets are independent from d.\nCorollary 5 Let K = T 1/\u03b3 , where \u03b3 > 1 is a small constant. Suppose Assumption 1 holds, and all the functions are \u03bb-strongly convex. Algorithm 1, with online gradient descent as its subroutine, is strongly adaptive with\nSA-Regret(T, \u03c4) \u2264 G 2\n2\u03bb\n( \u03b3 + 1 + (3\u03b3 + 7) log T ) = O (\u03b3 log T ) = O (log T )\nand its dynamic regret satisfies\nD-Regret(w\u22171, . . . ,w \u2217 T ) \u2264max    \u03b3G2 \u03bb + ( 5\u03b3G2 \u03bb + 2 ) log T \u03b3G2\n\u03bb \u221a TVT log T + ( 5\u03b3G2 \u03bb + 2 )\u221a TVT log T\n=O ( max { log T, \u221a TVT log T }) ."}, {"heading": "4. An Unified Adaptive Algorithm", "text": "In this section, we introduce a unified approach for minimizing the adaptive regret of expconcave functions, as well as strongly convex functions.\nLet E be an online learning algorithm that is designed to minimize the static regret of exp-concave functions or strongly convex functions, e.g., online Newton step (Hazan et al., 2007) or online gradient descent (Zinkevich, 2003). Similar to the approach of following the leading history (FLH) (Hazan and Seshadhri, 2007), at any time t, we will instantiate an expert by applying the online learning algorithm E to the sequence of loss functions\nft, ft+1, . . ., and utilize the strategy of learning from expert advice to combine solutions of different experts (Herbster and Warmuth, 1998). Our method is named as improved following the leading history (IFLH), and is summarized in Algorithm 1.\nLet Et be the expert that starts to work at time t. To control the computational complexity, we will associate an ending time et for each Et. The expert Et is alive during the period [t, et \u2212 1]. In each round t, we maintain a working set of experts St, which contains all the alive experts, and assign a probability pjt for each E\nj \u2208 St. In Steps 6 and 7, we remove all the experts whose ending times are no larger than t. Since the number of alive experts has changed, we need to update the probability assigned to them, which is performed in Steps 12 to 14. In Steps 15 and 16, we add a new expert Et to St, calculate its ending time according to Definition 5 introduced below, and set ptt = 1 t . It is easy to\nverify \u2211\nj\u2208St pjt = 1. Let w j t be the output of E j at the t-th round, where t \u2265 j. In Step 17, we submit the weighted average of wjt with coefficient p j t as the output wt, and suffer the loss ft(wt). From Steps 18 to 25, we use the exponential weighting scheme to update the weight for each expert Ej based on its loss ft(w j t ). In Step 21, we pass the loss function to all the alive experts such that they can update their predictions for the next round. The difference between our IFLH and the original FLH is how to decide the ending time et of expert Et. In this paper, we propose the following base-K ending time.\nDefinition 5 (Base-K Ending Time) Let K be an integer, and the representation of t in the base-K number system as\nt = \u2211\n\u03c4\u22650\n\u03b1\u03c4K \u03c4\nwhere 0 \u2264 \u03b1\u03c4 < K, for all \u03c4 \u2265 0. Let k be the smallest integer such that \u03b1\u03c4 > 0, i.e.,\nk = min{\u03c4 : \u03b1\u03c4 > 0}.\nThen, the base-K ending time of t is defined as\nEK(t) = \u2211\n\u03c4\u2265k+1\n\u03b1\u03c4K \u03c4 +Kk+1."}, {"heading": "In other words, the ending time is the number represented by the new sequence obtained by setting the first nonzero elements in the sequence \u03b10, \u03b11, . . . to be 0 and adding 1 to the element after it.", "text": "Let\u2019s take the decimal system as an example (i.e., K = 10). Then,\nE10(1) = E10(2) = \u00b7 \u00b7 \u00b7 = E10(9) = 10, E10(11) = E10(12) = \u00b7 \u00b7 \u00b7 = E10(19) = 20, E10(10) = E10(20) = \u00b7 \u00b7 \u00b7 = E10(90) = 100.\nWe note that a similar strategy for deciding the ending time was proposed by Gyo\u0308rgy et al. (2012), and a discussion about the difference is given in the supplementary.\nWhen the base-K ending time is used in Algorithm 1, we have the following properties.\nLemma 6 Suppose we use the base-K ending time in Algorithm 1.\nAlgorithm 1 Improved Following the Leading History (IFLH)\n1: Input: An integer K 2: Initialize S0 = \u2205. 3: for t = 1, . . . , T do 4: Set Zt = 0 {Remove some existing experts} 5: for Ej \u2208 St\u22121 do 6: if ej \u2264 t then 7: Update St\u22121 \u2190 St\u22121 \\ {Ej} 8: else 9: Set Zt = Zt + p\u0302 j t\n10: end if 11: end for {Normalize the probability} 12: for Ej \u2208 St\u22121 do 13: Set pjt = p\u0302jt Zt ( 1\u2212 1t ) 14: end for {Add a new expert Et} 15: Set St = St\u22121 \u222a {Et} 16: Compute the ending time et = EK(t) according to Definition 5 and set ptt = 1t {Compute the final predicted model} 17: Submit the solution\nwt = \u2211\nEj\u2208St\npjtw j t\nand suffer loss ft(wt) {Update weights and expert}\n18: Set Zt+1 = 0 19: for Ej \u2208 St do 20: Compute pjt+1 = p j t exp(\u2212\u03b1ft(wjt )) and Zt+1 = Zt+1 + pjt+1 21: Pass the function ft(\u00b7) to Ej 22: end for 23: for Ej \u2208 St do 24: Set p\u0302jt+1 = p\u0302jt+1 Zt+1 25: end for 26: end for\n1. For any t \u2265 1, we have\n|St| \u2264 (\u230alogK t\u230b+ 1) (K \u2212 1) = O ( K log t\nlogK\n) .\n2. For any interval I = [r, s] \u2286 [T ], we can always find m segments\nIj = [tj , e tj \u2212 1], j \u2208 [m]\nwith m \u2264 \u230alogK s\u230b+ 1, such that t1 = r, e\ntj = tj+1, j \u2208 [m\u2212 1], and etm > s. The first part of Lemma 6 implies that the size of St is O(K log t/ logK). An example of St in the decimal system is given below.\nS486 =    481, 482, . . . , 486, 410, 420, . . . , 480,\n100, 200, . . . , 400\n   .\nThe second part of Lemma 6 implies that for any interval I = [r, s], we can findO(log s/ logK) experts such that their survival periods cover I. Again, we present an example in the decimal system: The interval [111, 832] can be covered by\n[111, 119], [120, 199], and [200, 999]\nwhich are the survival periods of experts E111, E120, and E200, respectively. Recall that E10(111) = 120, E10(120) = 200, and E10(200) = 1000.\nBased on Lemma 6, we have the following theorem regarding the adaptive regret of exp-concave functions.\nTheorem 6 Suppose Assumption 1 holds, \u2126 \u2282 Rd, all the functions are \u03b1-exp-concave. If online Newton step is used as the subroutine in Algorithm 1, we have\ns\u2211\nt=r\nft(wt)\u2212 min w\u2208\u2126\ns\u2211\nt=r\nft(w) \u2264 ( (5d+ 1)m+ 2\n\u03b1 + 5dmGB\n) log T\nwhere m \u2264 \u230alogK s\u230b+ 1. And thus,\nSA-Regret(T, \u03c4) \u2264 ( (5d+ 1)m\u0304+ 2\n\u03b1 + 5dm\u0304GB\n) log T = O ( log2 T\nlogK\n)\nwhere m\u0304 = (\u230alogK T \u230b+ 1). From Lemma 6 and Theorem 6, we observe that the adaptive regret is a decreasing function of K, while the computational cost is an increasing function of K. Thus, we can control the tradeoff by tuning the value of K.\nFor strongly convex functions, we have a similar guarantee but without any dependence on the dimensionality d, as indicated below.\nTheorem 7 Suppose Assumption 1 holds, and all the functions are \u03bb-strongly convex. If online gradient descent is used as the subroutine in Algorithm 1, we have\ns\u2211\nt=r\nft(wt)\u2212 min w\u2208\u2126\ns\u2211\nt=r\nft(w) \u2264 G2\n2\u03bb\n( m+ (3m+ 4) log T )\nwhere m \u2264 \u230alogK s\u230b+ 1. And thus\nSA-Regret(T, \u03c4) \u2264 G 2\n2\u03bb\n( m\u0304+ (3m\u0304+ 4) log T ) = O\n( log2 T\nlogK\n)\nwhere m\u0304 = (\u230alogK T \u230b+ 1)."}, {"heading": "5. Analysis", "text": "We here present the proofs of main theorems. The omitted proofs are provided in the supplementary."}, {"heading": "5.1 Proof of Theorem 1", "text": "First, we upper bound the dynamic regret in the following way\nD-Regret(w\u22171, . . . ,w \u2217 T )\n= k\u2211\ni=1\n( qi\u2211\nt=si\nft(wt)\u2212 qi\u2211\nt=si\nmin w\u2208\u2126 ft(w)\n)\n= k\u2211\ni=1\n  qi\u2211\nt=si\nft(wt)\u2212 min w\u2208\u2126\nqi\u2211\nt=si\nft(w)\n\ufe38 \ufe37\ufe37 \ufe38 :=ai\n+min w\u2208\u2126\nqi\u2211\nt=si\nft(w)\u2212 qi\u2211\nt=si\nmin w\u2208\u2126 ft(w)\n\ufe38 \ufe37\ufe37 \ufe38 :=bi\n  .\n(5)\nFrom the definition of strongly adaptive regret, we can upper bound ai by\nqi\u2211\nt=si\nft(wt)\u2212 min w\u2208\u2126\nqi\u2211\nt=si\nft(w) \u2264 SA-Regret(T, |Ii|).\nTo upper bound bi, we follow the analysis of Proposition 2 of Besbes et al. (2015).\nmin w\u2208\u2126\nqi\u2211\nt=si\nft(w)\u2212 qi\u2211\nt=si\nmin w\u2208\u2126 ft(w) = min w\u2208\u2126\nqi\u2211\nt=si\nft(w)\u2212 qi\u2211\nt=si\nft(w \u2217 t )\n\u2264 qi\u2211\nt=si\nft(w \u2217 si)\u2212\nqi\u2211\nt=si\nft(w \u2217 t ) \u2264 |Ii| \u00b7 max\nt\u2208[si,qi]\n( ft(w \u2217 si)\u2212 ft(w\u2217t ) ) .\n(6)\nFurthermore, for any t \u2208 [si, qi], we have\nft(w \u2217 si)\u2212 ft(w\u2217t ) = ft(w\u2217si)\u2212 fsi(w\u2217si) + fsi(w\u2217si)\u2212 ft(w\u2217t )\n\u2264ft(w\u2217si)\u2212 fsi(w\u2217si) + fsi(w\u2217t )\u2212 ft(w\u2217t ) \u2264 2VT (i). (7)\nCombining (6) with (7), we have\nmin w\u2208\u2126\nqi\u2211\nt=si\nft(w)\u2212 qi\u2211\nt=si\nmin w\u2208\u2126\nft(w) \u2264 2|Ii| \u00b7 VT (i).\nSubstituting the upper bounds of ai and bi into (5), we arrive at\nD-Regret(w\u22171, . . . ,w \u2217 T ) \u2264\nk\u2211\ni=1\n(SA-Regret(T, |Ii|) + 2|Ii| \u00b7 VT (i)) .\nSince the above inequality holds for any partition of [1, T ], we can take minimization to get a tight bound."}, {"heading": "5.2 Proof of Corollary 3", "text": "To simplify the upper bound in Theorem 1, we restrict to intervals of the same length \u03c4 , and in this case k = T/\u03c4 . Then, we have\nD-Regret(w\u22171, . . . ,w \u2217 T )\n\u2264 min 1\u2264\u03c4\u2264T\nk\u2211\ni=1\n( SA-Regret(T, \u03c4) + 2\u03c4VT (i) ) = min\n1\u2264\u03c4\u2264T\n( SA-Regret(T, \u03c4)T\n\u03c4 + 2\u03c4\nk\u2211\ni=1\nVT (i)\n)\n\u2264 min 1\u2264\u03c4\u2264T\n( SA-Regret(T, \u03c4)T\n\u03c4 + 2\u03c4VT\n) .\nCombining with Theorem 2, we have\nD-Regret(w\u22171, . . . ,w \u2217 T ) \u2264 min\n1\u2264\u03c4\u2264T\n( (c+ 8 \u221a 7 log T + 5)T\u221a\n\u03c4 + 2\u03c4VT\n) .\nwhere c = 12BG/( \u221a 2\u2212 1).\nIn the following, we consider two cases. If VT \u2265 \u221a log T/T , we choose\n\u03c4 =\n( T \u221a log T\nVT\n)2/3 \u2264 T\nand have\nD-Regret(w\u22171, . . . ,w \u2217 T )\n\u2264(c+ 8 \u221a 7 log T + 5)T 2/3V 1/3 T\nlog1/6 T + 2T 2/3V 1/3 T log 1/3 T\n\u2264(c+ 8 \u221a 5)T 2/3V 1/3 T\nlog1/6 T + (2 + 8\n\u221a 7)T 2/3V\n1/3 T log 1/3 T.\nOtherwise, we choose \u03c4 = T , and have\nD-Regret(w\u22171, . . . ,w \u2217 T )\n\u2264(c+ 8 \u221a 7 log T + 5) \u221a T + 2TVT \u2264(c+ 8 \u221a 7 log T + 5) \u221a T + 2T \u221a log T\nT\n\u2264(c+ 9 \u221a 7 log T + 5) \u221a T ."}, {"heading": "6. Proof of Theorem 6", "text": "From the second part of Lemma 6, we know that there exist m segments\nIj = [tj, e tj \u2212 1], j \u2208 [m]\nwith m \u2264 \u230alogK s\u230b+ 1, such that\nt1 = r, e tj = tj+1, j \u2208 [m\u2212 1], and etm > s.\nFurthermore, the expert Etj is alive during the period [tj , e tj \u2212 1].\nUsing Claim 3.1 of Hazan and Seshadhri (2009), we have\netj\u22121\u2211\nt=tj\nft(wt)\u2212 ft(wtjt ) \u2264 1\n\u03b1\n log tj + 2 etj\u22121\u2211\nt=tj+1\n1\nt\n  , \u2200j \u2208 [m\u2212 1]\nwhere w tj tj , . . . ,w tj etj\u22121 is the sequence of solutions generated by the expert Etj . Similarly, for the last segment, we have\ns\u2211\nt=tm\nft(wt)\u2212 ft(wtmt ) \u2264 1\n\u03b1\n( log tm + 2 s\u2211\nt=tm+1\n1\nt\n) .\nBy adding things together, we have\nm\u22121\u2211\nj=1\n  etj\u22121\u2211\nt=tj\nft(wt)\u2212 ft(wtjt )\n + s\u2211\nt=tm\nft(wt)\u2212 ft(wtmt )\n\u2264 1 \u03b1\nm\u2211\nj=1\nlog tj + 2\n\u03b1\ns\u2211\nt=r+1\n1 t \u2264 m+ 2 \u03b1 log T.\n(8)\nAccording to the property of online Newton step (Hazan et al., 2007, Theorem 2), we have, for any w \u2208 \u2126,\netj\u22121\u2211\nt=tj\nft(w tj t )\u2212 ft(w) \u2264 5d\n( 1\n\u03b1 +GB\n) log T, \u2200j \u2208 [m\u2212 1] (9)\nand s\u2211\nt=tm\nft(w tm t )\u2212 ft(w) \u2264 5d\n( 1\n\u03b1 +GB\n) log T. (10)\nCombining (8), (9), and (10), we have,\ns\u2211\nt=r\nft(wt)\u2212 s\u2211\nt=r\nft(w) \u2264 ( (5d + 1)m+ 2\n\u03b1 + 5dmGB\n) log T\nfor any w \u2208 \u2126."}, {"heading": "7. Proof of Corollary 4", "text": "The first part of Corollary 4 is a direct consequence of Theorem 6 by setting K = T 1/\u03b3 .\nNow, we prove the second part. Following similar analysis of Corollary 3, we have\nD-Regret(w\u22171, . . . ,w \u2217 T ) \u2264 min\n1\u2264\u03c4\u2264T\n{( (5d+ 1)(\u03b3 + 1) + 2\n\u03b1 + 5d(\u03b3 + 1)GB\n) T log T\n\u03c4 + 2\u03c4VT\n} .\nThen, we consider two cases. If VT \u2265 log T/T , we choose\n\u03c4 =\n\u221a T log T\nVT \u2264 T\nand have\nD-Regret(w\u22171, . . . ,w \u2217 T ) \u2264\n( (5d+ 1)(\u03b3 + 1) + 2\n\u03b1 + 5d(\u03b3 + 1)GB + 2\n)\u221a TVT log T .\nOtherwise, we choose \u03c4 = T , and have\nD-Regret(w\u22171, . . . ,w \u2217 T ) \u2264\n( (5d + 1)(\u03b3 + 1) + 2\n\u03b1 + 5d(\u03b3 + 1)GB\n) log T + 2TVT\n\u2264 ( (5d + 1)(\u03b3 + 1) + 2\n\u03b1 + 5d(\u03b3 + 1)GB\n) log T + 2T log T\nT\n=\n( (5d + 1)(\u03b3 + 1) + 2\n\u03b1 + 5d(\u03b3 + 1)GB + 2\n) log T."}, {"heading": "8. Proof of Theorem 7", "text": "Lemma 4 implies that all the \u03bb-strongly convex functions are also \u03bb G2 -exp-concave. As a result, we can reuse the proof of Theorem 6. Specifically, (8) with \u03b1 = \u03bb G2 becomes\nm\u22121\u2211\nj=1\n  etj\u22121\u2211\nt=tj\nft(wt)\u2212 ft(wtjt )\n + s\u2211\nt=tm\nft(wt)\u2212 ft(wtmt ) \u2264 (m+ 2)G2\n\u03bb log T. (11)\nAccording to the property of online gradient descent (Hazan et al., 2007, Theorem 1), we have, for any w \u2208 \u2126,\netj\u22121\u2211\nt=tj\nft(w tj t )\u2212 ft(w) \u2264\nG2 2\u03bb (1 + log T ), \u2200j \u2208 [m\u2212 1] (12)\nand s\u2211\nt=tm\nft(w tm t )\u2212 ft(w) \u2264\nG2 2\u03bb (1 + log T ). (13)\nCombining (11), (12), and (13), we have,\ns\u2211\nt=r\nft(wt)\u2212 s\u2211\nt=r\nft(w) \u2264 G2\n2\u03bb\n( m+ (3m+ 4) log T )\nfor any w \u2208 \u2126."}, {"heading": "9. Proof of Corollary 5", "text": "The first part of Corollary 5 is a direct consequence of Theorem 7 by setting K = T 1/\u03b3 . The proof of the second part is similar to that of Corollary 4. First, we have\nD-Regret(w\u22171, . . . ,w \u2217 T ) \u2264 min\n1\u2264\u03c4\u2264T\n{ G2\n2\u03bb\n( \u03b3 + 1 + (3\u03b3 + 7) log T )T \u03c4 + 2\u03c4VT\n}\n\u2264 min 1\u2264\u03c4\u2264T\n{ (\u03b3 + 5\u03b3 log T )G2T\n\u03bb\u03c4 + 2\u03c4VT\n}\nwhere the last inequality is due to the condition \u03b3 > 1. Then, we consider two cases. If VT \u2265 log T/T , we choose\n\u03c4 =\n\u221a T log T\nVT \u2264 T\nand have\nD-Regret(w\u22171, . . . ,w \u2217 T ) \u2264\n\u03b3G2\n\u03bb \u221a TVT log T + 5\u03b3G2 \u03bb \u221a TVT log T + 2 \u221a TVT log T\n= \u03b3G2\n\u03bb \u221a TVT log T + ( 5\u03b3G2 \u03bb + 2 )\u221a TVT log T .\nOtherwise, we choose \u03c4 = T , and have\nD-Regret(w\u22171, . . . ,w \u2217 T ) \u2264\n(\u03b3 + 5\u03b3 log T )G2\n\u03bb + 2TVT\n\u2264(\u03b3 + 5\u03b3 log T )G 2\n\u03bb + 2T\nlog T\nT\n= \u03b3G2\n\u03bb +\n( 5\u03b3G2\n\u03bb + 2\n) log T."}, {"heading": "10. Conclusions and Future Work", "text": "In this paper, we demonstrate that the dynamic regret can be upper bounded by the adaptive regret and the functional variation, which implies strongly adaptive algorithms are automatically equipped with tight dynamic regret bounds. As a result, we are able to derive dynamic regret bounds for convex functions, exponentially concave functions, and strongly convex functions. All of these upper bounds are almost minimax optimal and this is the first time that such kind of dynamic regret bound is proved for exponentially concave functions.\nThe adaptive-to-dynamic conversion leads to a series of dynamic regret bounds in terms of the functional variation. As we mentioned in Section 2.3, dynamic regret can also be upper bounded by other regularities such as the path-length. It is interesting to investigate whether those kinds of upper bounds can also be established for strongly adaptive algorithms. Since we derive dynamic regret from adaptive regret, we conjecture that adaptive regret is more fundamental, and will try to give a rigorous proof in the future."}, {"heading": "Appendix A. Proof of Theorem 2", "text": "As pointed out by Daniely et al. (2015), the static regret of online gradient descent (Zinkevich, 2003) over any interval of length \u03c4 is upper bounded by 3BG \u221a \u03c4 . Combining this fact with Theorem 2 of Jun et al. (2016), we get Theorem 2 in this paper."}, {"heading": "Appendix B. Proof of Lemma 4", "text": "The gradient of exp(\u2212\u03b1f(w)) is\n\u2207 exp(\u2212\u03b1f(w)) = exp(\u2212\u03b1f(w))\u2212\u03b1\u2207f(w) = \u2212\u03b1 exp(\u2212\u03b1f(w))\u2207f(w).\nand the Hessian is\n\u22072 exp(\u2212\u03b1f(w)) =\u2212\u03b1 exp(\u2212\u03b1f(w))\u2212\u03b1\u2207f(w)\u2207\u22a4f(w)\u2212 \u03b1 exp(\u2212\u03b1f(w))\u22072f(w) =\u03b1 exp(\u2212\u03b1f(w)) ( \u03b1\u2207f(w)\u2207\u22a4f(w)\u2212\u22072f(w) ) .\nThus, f(\u00b7) is \u03b1-exp-concave if\n\u03b1\u2207f(w)\u2207\u22a4f(w) \u22072f(w).\nWe complete the proof by noticing\n\u03bb\nG2 \u2207f(w)\u2207\u22a4f(w) \u03bbI \u22072f(w)."}, {"heading": "Appendix C. Proof of Lemma 6", "text": "We first prove the first part of Lemma 6. Let m = \u230alogK t\u230b. Then, integer t can be represented in the base-K number system as\nt = m\u2211\nj=0\n\u03b1jK j.\nFrom the definition of base-K ending time, integers that are no larger than t and alive at t are\n   1 \u2217K0 + m\u2211 j=1 \u03b1jK j, 2 \u2217K0 + m\u2211 j=1 \u03b1jK j, . . . , \u03b10 \u2217K0 + m\u2211 j=1 \u03b1jK j 1 \u2217K1 + m\u2211 j=2 \u03b1jK j, 2 \u2217K1 + m\u2211 j=2 \u03b1jK j, . . . , \u03b11 \u2217K1 + m\u2211 j=2 \u03b1jK j . . .\n1 \u2217Km\u22121 + \u03b1mKm, 1 \u2217Km\u22121 + \u03b1mKm, . . . , \u03b1m\u22121 \u2217Km\u22121 + \u03b1mKm 1 \u2217Km, 2 \u2217Km, . . . , \u03b1mKm\n   .\nThe total number of alive integers are upper bounded by\nm\u2211\ni=0\n\u03b1i \u2264 (m+ 1)(K \u2212 1).\nWe proceed to prove the second part of Lemma 6. Let m = \u230alogK r\u230b, and the representation of r in the base-K number system be\nr =\nm\u2211\nj=0\n\u03b1jK j.\nWe generate a sequence of segments as\n  m\u2211\nj=0\n\u03b1jK j, (\u03b11 + 1)K 1 + m\u2211\nj=2\n\u03b1jK j \u2212 1   ,\n (\u03b11 + 1)K1 + m\u2211\nj=2\n\u03b1jK j, (\u03b12 + 1)K 2 +\nm\u2211\nj=3\n\u03b1jK j \u2212 1   ,\n. . . [ (\u03b1m\u22121 + 1)Km\u22121 + \u03b1mK m, (\u03b1m + 1)K m \u2212 1 ] , [ (\u03b1m + 1)K m,Km+1 \u2212 1 ] , [ Km+1,Km+2 \u2212 1 ] ,\n. . .\nuntil s is covered. It is easy to verify that the number of segments is at most \u230alogK s\u230b+ 1.\nAppendix D. More Discussions about the Base-K Ending Time\nIn a study of \u201cprediction with expert advice\u201d, Gyo\u0308rgy et al. (2012) have introduced a similar strategy for deciding the ending time of experts. The main difference is that their strategy is built upon base-2 number system and introduces an additional parameter g to compromise between the computational complexity and the regret, in contrast our method relies on base-K number system and uses K to control the tradeoff. Lemma 2 of Gyo\u0308rgy et al. (2012) indicates an O(g log t) bound on the number of alive experts, which is worse than our O(K log t/ logK) bound by a logarithmic factor."}], "references": [{"title": "A stochastic view of optimal regret through minimax duality", "author": ["Jacob Abernethy", "Alekh Agarwal", "Peter L. Bartlett", "Alexander Rakhlin"], "venue": "In Proceedings of the 22nd Annual Conference on Learning Theory,", "citeRegEx": "Abernethy et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Abernethy et al\\.", "year": 2009}, {"title": "A closer look at adaptive regret", "author": ["Dmitry Adamskiy", "Wouter M. Koolen", "Alexey Chernov", "Vladimir Vovk"], "venue": "In Proceedings of the 23rd International Conference on Algorithmic Learning Theory,", "citeRegEx": "Adamskiy et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Adamskiy et al\\.", "year": 2012}, {"title": "Non-stationary stochastic optimization", "author": ["Omar Besbes", "Yonatan Gur", "Assaf Zeevi"], "venue": "Operations Research,", "citeRegEx": "Besbes et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Besbes et al\\.", "year": 2015}, {"title": "Prediction, Learning, and Games", "author": ["Nicol\u00f2 Cesa-Bianchi", "G\u00e1bor Lugosi"], "venue": null, "citeRegEx": "Cesa.Bianchi and Lugosi.,? \\Q2006\\E", "shortCiteRegEx": "Cesa.Bianchi and Lugosi.", "year": 2006}, {"title": "Mirror descent meets fixed share (and feels no regret)", "author": ["Nicol\u00f2 Cesa-bianchi", "Pierre Gaillard", "Gabor Lugosi", "Gilles Stoltz"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Cesa.bianchi et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Cesa.bianchi et al\\.", "year": 2012}, {"title": "Strongly adaptive online learning", "author": ["Amit Daniely", "Alon Gonen", "Shai Shalev-Shwartz"], "venue": "In Proceedings of The 32nd International Conference on Machine Learning,", "citeRegEx": "Daniely et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Daniely et al\\.", "year": 2015}, {"title": "Efficient tracking of large classes of experts", "author": ["Andr\u00e1s Gy\u00f6rgy", "Tam\u00e1s Linder", "G\u00e1bor Lugosi"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Gy\u00f6rgy et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gy\u00f6rgy et al\\.", "year": 2012}, {"title": "Dynamical models and tracking regret in online convex programming", "author": ["Eric C. Hall", "Rebecca M. Willett"], "venue": "In Proceedings of the 30th International Conference on Machine Learning,", "citeRegEx": "Hall and Willett.,? \\Q2013\\E", "shortCiteRegEx": "Hall and Willett.", "year": 2013}, {"title": "Adaptive algorithms for online decision problems", "author": ["Elad Hazan", "C. Seshadhri"], "venue": "Electronic Colloquium on Computational Complexity,", "citeRegEx": "Hazan and Seshadhri.,? \\Q2007\\E", "shortCiteRegEx": "Hazan and Seshadhri.", "year": 2007}, {"title": "Efficient learning algorithms for changing environments", "author": ["Elad Hazan", "C. Seshadhri"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "Hazan and Seshadhri.,? \\Q2009\\E", "shortCiteRegEx": "Hazan and Seshadhri.", "year": 2009}, {"title": "Logarithmic regret algorithms for online convex optimization", "author": ["Elad Hazan", "Amit Agarwal", "Satyen Kale"], "venue": "Machine Learning,", "citeRegEx": "Hazan et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Hazan et al\\.", "year": 2007}, {"title": "Tracking the best expert", "author": ["Mark Herbster", "Manfred K. Warmuth"], "venue": "Machine Learning,", "citeRegEx": "Herbster and Warmuth.,? \\Q1998\\E", "shortCiteRegEx": "Herbster and Warmuth.", "year": 1998}, {"title": "Tracking the best linear predictor", "author": ["Mark Herbster", "Manfred K. Warmuth"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Herbster and Warmuth.,? \\Q2001\\E", "shortCiteRegEx": "Herbster and Warmuth.", "year": 2001}, {"title": "Online optimization : Competing with dynamic comparators", "author": ["Ali Jadbabaie", "Alexander Rakhlin", "Shahin Shahrampour", "Karthik Sridharan"], "venue": "In Proceedings of the 18th International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Jadbabaie et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Jadbabaie et al\\.", "year": 2015}, {"title": "Improved strongly adaptive online learning using coin betting", "author": ["Kwang-Sung Jun", "Francesco Orabona", "Rebecca Willett", "Stephen Wright"], "venue": "ArXiv e-prints,", "citeRegEx": "Jun et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Jun et al\\.", "year": 2016}, {"title": "Open problem: Fast stochastic exp-concave optimization", "author": ["Tomer Koren"], "venue": "In Proceedings of the 26th Annual Conference on Learning Theory, pages 1073\u20131075,", "citeRegEx": "Koren.,? \\Q2013\\E", "shortCiteRegEx": "Koren.", "year": 2013}, {"title": "Sparse online learning via truncated gradient", "author": ["John Langford", "Lihong Li", "Tong Zhang"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Langford et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Langford et al\\.", "year": 2009}, {"title": "The weighted majority algorithm", "author": ["Nick Littlestone", "Manfred K. Warmuth"], "venue": "Information and Computation,", "citeRegEx": "Littlestone and Warmuth.,? \\Q1994\\E", "shortCiteRegEx": "Littlestone and Warmuth.", "year": 1994}, {"title": "Online optimization in dynamic environments: Improved regret rates for strongly convex problems", "author": ["Aryan Mokhtari", "Shahin Shahrampour", "Ali Jadbabaie", "Alejandro Ribeiro"], "venue": "ArXiv e-prints,", "citeRegEx": "Mokhtari et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Mokhtari et al\\.", "year": 2016}, {"title": "Online learning and online convex optimization", "author": ["Shai Shalev-Shwartz"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Shalev.Shwartz.,? \\Q2011\\E", "shortCiteRegEx": "Shalev.Shwartz.", "year": 2011}, {"title": "A primal-dual perspective of online learning algorithms", "author": ["Shai Shalev-Shwartz", "Yoram Singer"], "venue": "Machine Learning,", "citeRegEx": "Shalev.Shwartz and Singer.,? \\Q2007\\E", "shortCiteRegEx": "Shalev.Shwartz and Singer.", "year": 2007}, {"title": "Pegasos: primal estimated subgradient solver for SVM", "author": ["Shai Shalev-Shwartz", "Yoram Singer", "Nathan Srebro"], "venue": "In Proceedings of the 24th International Conference on Machine Learning,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2007}, {"title": "Tracking slowly moving clairvoyant: Optimal dynamic regret of online learning with true and noisy gradient", "author": ["Tianbao Yang", "Lijun Zhang", "Rong Jin", "Jinfeng Yi"], "venue": "In Proceedings of the 33rd International Conference on Machine Learning,", "citeRegEx": "Yang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2016}, {"title": "Improved dynamic regret for non-degeneracy functions", "author": ["Lijun Zhang", "Tianbao Yang", "Jinfeng Yi", "Rong Jin", "Zhi-Hua Zhou"], "venue": "ArXiv e-prints,", "citeRegEx": "Zhang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2016}, {"title": "Online convex programming and generalized infinitesimal gradient ascent", "author": ["Martin Zinkevich"], "venue": "In Proceedings of the 20th International Conference on Machine Learning,", "citeRegEx": "Zinkevich.,? \\Q2003\\E", "shortCiteRegEx": "Zinkevich.", "year": 2003}], "referenceMentions": [{"referenceID": 19, "context": "Introduction Online convex optimization is a powerful paradigm for sequential decision making (Shalev-Shwartz, 2011).", "startOffset": 94, "endOffset": 116}, {"referenceID": 3, "context": "This study focuses on the full-information setting (Cesa-Bianchi and Lugosi, 2006), where the function ft(\u00b7) is revealed to the leaner at the end of each round.", "startOffset": 51, "endOffset": 82}, {"referenceID": 24, "context": "To address this limitation, new forms of performance measure, including adaptive regret (Hazan and Seshadhri, 2007, 2009) and dynamic regret (Zinkevich, 2003), were proposed and received significant interest recently.", "startOffset": 141, "endOffset": 158}, {"referenceID": 13, "context": "It is well-known that in the worst case, a sublinear dynamic regret is impossible unless we impose some regularities on the comparator sequence or the function sequence (Jadbabaie et al., 2015).", "startOffset": 169, "endOffset": 193}, {"referenceID": 14, "context": "\u2022 For convex functions, we show that the strongly adaptive algorithm of Jun et al. (2016) has a dynamic regret of O(T 2/3V 1/3 T log 1/3 T ), which matches the minimax rate, up to a polylogarithmic factor.", "startOffset": 72, "endOffset": 90}, {"referenceID": 24, "context": "For general convex functions, the classical online gradient descent achieves O( \u221a T ) and O(log T ) regret bounds for convex and strongly convex functions, respectively (Zinkevich, 2003; Hazan et al., 2007; Shalev-Shwartz et al., 2007).", "startOffset": 169, "endOffset": 235}, {"referenceID": 10, "context": "For general convex functions, the classical online gradient descent achieves O( \u221a T ) and O(log T ) regret bounds for convex and strongly convex functions, respectively (Zinkevich, 2003; Hazan et al., 2007; Shalev-Shwartz et al., 2007).", "startOffset": 169, "endOffset": 235}, {"referenceID": 21, "context": "For general convex functions, the classical online gradient descent achieves O( \u221a T ) and O(log T ) regret bounds for convex and strongly convex functions, respectively (Zinkevich, 2003; Hazan et al., 2007; Shalev-Shwartz et al., 2007).", "startOffset": 169, "endOffset": 235}, {"referenceID": 0, "context": "Both the O( \u221a T ) and O(log T ) rates are known to be minimax optimal (Abernethy et al., 2009).", "startOffset": 70, "endOffset": 94}, {"referenceID": 10, "context": "When functions are exponentially concave, a different algorithm, named online Newton step, is developed and enjoys an O(log T ) regret bound (Hazan et al., 2007).", "startOffset": 141, "endOffset": 161}, {"referenceID": 16, "context": "1 Static Regret The majority of studies in online learning are focused on static regret Shalev-Shwartz and Singer (2007); Langford et al.", "startOffset": 88, "endOffset": 121}, {"referenceID": 14, "context": "1 Static Regret The majority of studies in online learning are focused on static regret Shalev-Shwartz and Singer (2007); Langford et al. (2009). For general convex functions, the classical online gradient descent achieves O( \u221a T ) and O(log T ) regret bounds for convex and strongly convex functions, respectively (Zinkevich, 2003; Hazan et al.", "startOffset": 122, "endOffset": 145}, {"referenceID": 7, "context": "2 Adaptive Regret The concept of adaptive regret is introduced by Hazan and Seshadhri (2007), and later strengthened by Daniely et al.", "startOffset": 66, "endOffset": 93}, {"referenceID": 5, "context": "2 Adaptive Regret The concept of adaptive regret is introduced by Hazan and Seshadhri (2007), and later strengthened by Daniely et al. (2015). To distinguish between them, we refer to the definition of Hazan and Seshadhri (2007) as weakly adaptive regret and the one of Daniely et al.", "startOffset": 120, "endOffset": 142}, {"referenceID": 5, "context": "2 Adaptive Regret The concept of adaptive regret is introduced by Hazan and Seshadhri (2007), and later strengthened by Daniely et al. (2015). To distinguish between them, we refer to the definition of Hazan and Seshadhri (2007) as weakly adaptive regret and the one of Daniely et al.", "startOffset": 120, "endOffset": 229}, {"referenceID": 5, "context": "2 Adaptive Regret The concept of adaptive regret is introduced by Hazan and Seshadhri (2007), and later strengthened by Daniely et al. (2015). To distinguish between them, we refer to the definition of Hazan and Seshadhri (2007) as weakly adaptive regret and the one of Daniely et al. (2015) as strongly adaptive regret.", "startOffset": 120, "endOffset": 292}, {"referenceID": 8, "context": "To minimize the adaptive regret, Hazan and Seshadhri (2007) have developed two metaalgorithms: an efficient algorithm with O(log T ) computational complexity per iteration and an inefficient one with O(T ) computational complexity per iteration.", "startOffset": 33, "endOffset": 60}, {"referenceID": 5, "context": "To overcome this limitation, Daniely et al. (2015) proposed a refined adaptive regret that takes the length of the interval as a parameter \u03c4 , as indicated in (1).", "startOffset": 29, "endOffset": 51}, {"referenceID": 5, "context": "To overcome this limitation, Daniely et al. (2015) proposed a refined adaptive regret that takes the length of the interval as a parameter \u03c4 , as indicated in (1). If the strongly adaptive regret is small for all \u03c4 < T , we can guarantee the learner has small regret over any interval of any length. In particular, Daniely et al. (2015) introduced the following definition.", "startOffset": 29, "endOffset": 337}, {"referenceID": 5, "context": "To overcome this limitation, Daniely et al. (2015) proposed a refined adaptive regret that takes the length of the interval as a parameter \u03c4 , as indicated in (1). If the strongly adaptive regret is small for all \u03c4 < T , we can guarantee the learner has small regret over any interval of any length. In particular, Daniely et al. (2015) introduced the following definition. Definition 1 Let R(\u03c4) be the minimax static regret bound of the learning problem over \u03c4 periods. An algorithm is strongly adaptive, if SA-Regret(T, \u03c4) = O(poly(log T ) \u00b7R(\u03c4)). It is easy to verify that the meta-algorithms of Hazan and Seshadhri (2007) are strongly adaptive for exponentially concave functions,2 but not for convex functions.", "startOffset": 29, "endOffset": 626}, {"referenceID": 5, "context": "To overcome this limitation, Daniely et al. (2015) proposed a refined adaptive regret that takes the length of the interval as a parameter \u03c4 , as indicated in (1). If the strongly adaptive regret is small for all \u03c4 < T , we can guarantee the learner has small regret over any interval of any length. In particular, Daniely et al. (2015) introduced the following definition. Definition 1 Let R(\u03c4) be the minimax static regret bound of the learning problem over \u03c4 periods. An algorithm is strongly adaptive, if SA-Regret(T, \u03c4) = O(poly(log T ) \u00b7R(\u03c4)). It is easy to verify that the meta-algorithms of Hazan and Seshadhri (2007) are strongly adaptive for exponentially concave functions,2 but not for convex functions. Thus, Daniely et al. (2015) developed a new meta-algorithm that satisfies SA-Regret(T, \u03c4) = O( \u221a \u03c4 log T ) for convex functions, and thus is strongly adaptive.", "startOffset": 29, "endOffset": 744}, {"referenceID": 5, "context": "To overcome this limitation, Daniely et al. (2015) proposed a refined adaptive regret that takes the length of the interval as a parameter \u03c4 , as indicated in (1). If the strongly adaptive regret is small for all \u03c4 < T , we can guarantee the learner has small regret over any interval of any length. In particular, Daniely et al. (2015) introduced the following definition. Definition 1 Let R(\u03c4) be the minimax static regret bound of the learning problem over \u03c4 periods. An algorithm is strongly adaptive, if SA-Regret(T, \u03c4) = O(poly(log T ) \u00b7R(\u03c4)). It is easy to verify that the meta-algorithms of Hazan and Seshadhri (2007) are strongly adaptive for exponentially concave functions,2 but not for convex functions. Thus, Daniely et al. (2015) developed a new meta-algorithm that satisfies SA-Regret(T, \u03c4) = O( \u221a \u03c4 log T ) for convex functions, and thus is strongly adaptive. The algorithm is also efficient and the computational complexity per iteration is O(log T ). Later, the strongly adaptive regret of convex functions was improved to O( \u221a \u03c4 log T ) by Jun et al. (2016).", "startOffset": 29, "endOffset": 1077}, {"referenceID": 24, "context": "3 Dynamic Regret In a seminal work, Zinkevich (2003) proposed to use the path-length defined as", "startOffset": 36, "endOffset": 53}, {"referenceID": 24, "context": "Specifically, Zinkevich (2003) proved that for any sequence of convex functions, the dynamic regret of online gradient descent can be upper bounded by O( \u221a TP(u1, .", "startOffset": 14, "endOffset": 31}, {"referenceID": 7, "context": "Hall and Willett (2013) developed a novel algorithm named dynamic mirror descent and proved that its dynamic regret is on the order of \u221a TP (u1, .", "startOffset": 0, "endOffset": 24}, {"referenceID": 13, "context": ",w \u2217 T ) (Jadbabaie et al., 2015; Mokhtari et al., 2016; Yang et al., 2016; Zhang et al., 2016).", "startOffset": 9, "endOffset": 95}, {"referenceID": 18, "context": ",w \u2217 T ) (Jadbabaie et al., 2015; Mokhtari et al., 2016; Yang et al., 2016; Zhang et al., 2016).", "startOffset": 9, "endOffset": 95}, {"referenceID": 22, "context": ",w \u2217 T ) (Jadbabaie et al., 2015; Mokhtari et al., 2016; Yang et al., 2016; Zhang et al., 2016).", "startOffset": 9, "endOffset": 95}, {"referenceID": 23, "context": ",w \u2217 T ) (Jadbabaie et al., 2015; Mokhtari et al., 2016; Yang et al., 2016; Zhang et al., 2016).", "startOffset": 9, "endOffset": 95}, {"referenceID": 22, "context": ",w T )) (Yang et al., 2016).", "startOffset": 8, "endOffset": 27}, {"referenceID": 18, "context": ",w T )) (Mokhtari et al., 2016).", "startOffset": 8, "endOffset": 31}, {"referenceID": 22, "context": ",w T )) rate is also achievable when all the functions are convex and smooth, and all the minimizersw t \u2019s lie in the interior of \u03a9 (Yang et al., 2016).", "startOffset": 132, "endOffset": 151}, {"referenceID": 13, "context": ",w \u2217 T ) (Jadbabaie et al., 2015; Mokhtari et al., 2016; Yang et al., 2016; Zhang et al., 2016). When a prior knowledge of P(w\u2217 1, . . . ,w T ) is available, D-Regret(w 1, . . . ,w T ) can be upper bounded by O( \u221a TP(w\u2217 1, . . . ,w T )) (Yang et al., 2016). If all the functions are strongly convex and smooth, the upper bound can be improved to O(P(w\u2217 1, . . . ,w T )) (Mokhtari et al., 2016). The O(P(w\u2217 1, . . . ,w T )) rate is also achievable when all the functions are convex and smooth, and all the minimizersw t \u2019s lie in the interior of \u03a9 (Yang et al., 2016). In a recent study, Zhang et al. (2016) introduced a new regularity\u2014squared pathlength", "startOffset": 10, "endOffset": 607}, {"referenceID": 17, "context": "In the literature, dynamic regret is also referred to as tracking regret or shifting regret (Littlestone and Warmuth, 1994; Herbster and Warmuth, 1998, 2001).", "startOffset": 92, "endOffset": 157}, {"referenceID": 18, "context": "Zhang et al. (2016) developed a novel algorithm named online multiple gradient descent, and proved that D-Regret(w 1, .", "startOffset": 0, "endOffset": 20}, {"referenceID": 1, "context": "In the setting of \u201cprediction with expert advice\u201d, Adamskiy et al. (2012) have shown that the tracking regret can be derived from the adaptive regret.", "startOffset": 51, "endOffset": 74}, {"referenceID": 1, "context": "In the setting of \u201cprediction with expert advice\u201d, Adamskiy et al. (2012) have shown that the tracking regret can be derived from the adaptive regret. In the setting of \u201conline linear optimization in the simplex\u201d, Cesa-bianchi et al. (2012) introduced a generalized notion of shifting regret which unifies adaptive regret and shifting regret.", "startOffset": 51, "endOffset": 241}, {"referenceID": 2, "context": "The above theorem is analogous to Proposition 2 of Besbes et al. (2015), which provides an upper bound for a special choice of the interval sequence.", "startOffset": 51, "endOffset": 72}, {"referenceID": 14, "context": "2 Convex Functions For convex functions, we choose the meta-algorithm of Jun et al. (2016) and take the online gradient descent as its subroutine.", "startOffset": 73, "endOffset": 91}, {"referenceID": 14, "context": "2 Convex Functions For convex functions, we choose the meta-algorithm of Jun et al. (2016) and take the online gradient descent as its subroutine. The following theorem regarding the adaptive regret can be obtained from that paper. Theorem 2 Under Assumption 1, the meta-algorithm of Jun et al. (2016) is strongly adaptive with SA-Regret(T, \u03c4) \u2264 ( 12BG \u221a 2\u2212 1 + 8 \u221a 7 log T + 5 )\u221a \u03c4 = O( \u221a \u03c4 log T ).", "startOffset": 73, "endOffset": 302}, {"referenceID": 14, "context": "Corollary 3 Under Assumption 1, the meta-algorithm of Jun et al. (2016) satisfies", "startOffset": 54, "endOffset": 72}, {"referenceID": 2, "context": "According to Theorem 2 of Besbes et al. (2015), we know that the minimax dynamic regret of convex functions is O(T 2/3V 1/3 T ).", "startOffset": 26, "endOffset": 47}, {"referenceID": 2, "context": "According to Theorem 2 of Besbes et al. (2015), we know that the minimax dynamic regret of convex functions is O(T 2/3V 1/3 T ). Thus, our upper bound is minimax optimal up to a polylogarithmic factor. The key advantage of the meta-algorithm of Jun et al. (2016) over the restarted online gradient descent of Besbes et al.", "startOffset": 26, "endOffset": 263}, {"referenceID": 2, "context": "According to Theorem 2 of Besbes et al. (2015), we know that the minimax dynamic regret of convex functions is O(T 2/3V 1/3 T ). Thus, our upper bound is minimax optimal up to a polylogarithmic factor. The key advantage of the meta-algorithm of Jun et al. (2016) over the restarted online gradient descent of Besbes et al. (2015) is that the former one do not need any prior knowledge of the functional variation VT .", "startOffset": 26, "endOffset": 330}, {"referenceID": 2, "context": "According to Theorem 2 of Besbes et al. (2015), we know that the minimax dynamic regret of convex functions is O(T 2/3V 1/3 T ). Thus, our upper bound is minimax optimal up to a polylogarithmic factor. The key advantage of the meta-algorithm of Jun et al. (2016) over the restarted online gradient descent of Besbes et al. (2015) is that the former one do not need any prior knowledge of the functional variation VT . Notice that the meta-algorithm of Daniely et al. (2015) can also be used here, and its dynamic regret is on the order of max {\u221a T log T, T 2/3V 1/3 T log 2/3 T } .", "startOffset": 26, "endOffset": 474}, {"referenceID": 3, "context": "exp-concave) functions (Cesa-Bianchi and Lugosi, 2006).", "startOffset": 23, "endOffset": 54}, {"referenceID": 15, "context": "It can be used to model many popular losses used in machine learning, such as the square loss in regression, logistic loss in classification and negative logarithm loss in portfolio management (Koren, 2013).", "startOffset": 193, "endOffset": 206}, {"referenceID": 8, "context": "For exp-concave functions, Hazan and Seshadhri (2007) have developed two meta-algorithms that take the online Newton step as its subroutine, and proved the following properties.", "startOffset": 27, "endOffset": 54}, {"referenceID": 8, "context": "\u2022 WhenK = 2, we recover the guarantee of the efficient algorithm of Hazan and Seshadhri (2007), and when K = T , we obtain the inefficient one.", "startOffset": 68, "endOffset": 95}, {"referenceID": 8, "context": "\u2022 WhenK = 2, we recover the guarantee of the efficient algorithm of Hazan and Seshadhri (2007), and when K = T , we obtain the inefficient one. \u2022 By setting K = T 1/\u03b3 where \u03b3 > 1 is a small constant, such as 10, the strongly adaptive regret can be viewed as O(log T ), and at the same time, the computational complexity is also very low for a large range of T . According to Definition 1, Algorithm 1 in this paper, as well as the two meta-algorithms of Hazan and Seshadhri (2007), is strongly adaptive.", "startOffset": 68, "endOffset": 481}, {"referenceID": 10, "context": "It is easy to verify that strongly convex functions with bounded gradients are also expconcave (Hazan et al., 2007).", "startOffset": 95, "endOffset": 115}, {"referenceID": 2, "context": "According to Theorem 4 of Besbes et al. (2015), the minimax dynamic regret of strongly convex functions is O( \u221a TVT ), which implies our upper bound is almost minimax optimal.", "startOffset": 26, "endOffset": 47}, {"referenceID": 10, "context": ", online Newton step (Hazan et al., 2007) or online gradient descent (Zinkevich, 2003).", "startOffset": 21, "endOffset": 41}, {"referenceID": 24, "context": ", 2007) or online gradient descent (Zinkevich, 2003).", "startOffset": 35, "endOffset": 52}, {"referenceID": 8, "context": "Similar to the approach of following the leading history (FLH) (Hazan and Seshadhri, 2007), at any time t, we will instantiate an expert by applying the online learning algorithm E to the sequence of loss functions", "startOffset": 63, "endOffset": 90}, {"referenceID": 11, "context": ", and utilize the strategy of learning from expert advice to combine solutions of different experts (Herbster and Warmuth, 1998).", "startOffset": 100, "endOffset": 128}, {"referenceID": 6, "context": "We note that a similar strategy for deciding the ending time was proposed by Gy\u00f6rgy et al. (2012), and a discussion about the difference is given in the supplementary.", "startOffset": 77, "endOffset": 98}, {"referenceID": 2, "context": "To upper bound bi, we follow the analysis of Proposition 2 of Besbes et al. (2015).", "startOffset": 62, "endOffset": 83}, {"referenceID": 8, "context": "1 of Hazan and Seshadhri (2009), we have ej\u22121 \u2211 t=tj ft(wt)\u2212 ft(w t ) \u2264 1 \u03b1 \uf8eb \uf8edlog tj + 2 ej\u22121 \u2211", "startOffset": 5, "endOffset": 32}], "year": 2017, "abstractText": "To cope with changing environments, recent developments in online learning have introduced the concepts of adaptive regret and dynamic regret independently. In this paper, we illustrate an intrinsic connection between these two concepts by showing that the dynamic regret can be expressed in terms of the adaptive regret and the functional variation. This observation implies that strongly adaptive algorithms can be directly leveraged to minimize the dynamic regret. As a result, we present a series of strongly adaptive algorithms whose dynamic regrets are minimax optimal for convex functions, exponentially concave functions, and strongly convex functions, respectively. To the best of our knowledge, this is the first time that such kind of dynamic regret bound is established for exponentially concave functions. Moreover, all of those adaptive algorithms do not need any prior knowledge of the functional variation, which is a significant advantage over previous specialized methods for minimizing dynamic regret.", "creator": "LaTeX with hyperref package"}}}