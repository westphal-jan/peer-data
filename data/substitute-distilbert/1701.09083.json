{"id": "1701.09083", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Jan-2017", "title": "Efficient Rank Aggregation via Lehmer Codes", "abstract": "we propose a novel rank aggregation program based when converting permutations into their corresponding lehmer codes or other subdiagonal images. gradient codes, also known as inversion vectors, are hybrid representations of permutations in which each coordinate directly indicate values not restricted by the values of corresponding coordinates. this transformation requires 3d decoupling of arbitrary coordinates and for performing aggregation via discrete scalar median or inverted computations. we present simulation results illustrating simulation performance of this completely parallelizable approach and analytically prove that both the mode and median aggregation procedure recover effectively correct centroid aggregate with small sample complexity when the permutations are drawn according to the latest - known mallows models. the proposed lehmer code approach may also be used on partial rankings, with similar performance guarantees.", "histories": [["v1", "Sat, 28 Jan 2017 19:28:29 GMT  (426kb)", "http://arxiv.org/abs/1701.09083v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["pan li", "arya mazumdar", "olgica milenkovic"], "accepted": false, "id": "1701.09083"}, "pdf": {"name": "1701.09083.pdf", "metadata": {"source": "CRF", "title": "Efficient Rank Aggregation via Lehmer Codes", "authors": ["Pan Li", "Arya Mazumdar", "Olgica Milenkovic"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n70 1.\n09 08\n3v 1\n[ cs\n.L G\n] 2\n8 Ja\nn 20\n17\nWe propose a novel rank aggregation method based on converting permutations into their corresponding Lehmer codes or other subdiagonal images. Lehmer codes, also known as inversion vectors, are vector representations of permutations in which each coordinate can take values not restricted by the values of other coordinates. This transformation allows for decoupling of the coordinates and for performing aggregation via simple scalar median or mode computations. We present simulation results illustrating the performance of this completely parallelizable approach and analytically prove that both the mode and median aggregation procedure recover the correct centroid aggregate with small sample complexity when the permutations are drawn according to the well-known Mallows models. The proposed Lehmer code approach may also be used on partial rankings, with similar performance guarantees."}, {"heading": "1 Introduction", "text": "Rank aggregation is a family of problems concerned with fusing disparate ranking information, and it arises in application areas as diverse as social choice, meta-search, natural language processing, bioinformatics, and information retrieval [1, 2, 3]. The observed rankings are either linear orders (permutations) or partial (element-tied) rankings1. Sometimes, rankings are assumed to be of the form of a set of pairwise comparisons [4, 5]. Note that, many massive ordinal datasets arise from ratings, rather than actual comparisons. Rank aggregation, rather than averaging of ratings, is justified due to the fact that most raters have different rating \u201cscales\u201d. As an example, the rating three of one user may indicate that the user liked the item, while the rating three by another user may indicate that the user disliked the item. Hence, actual preferences can only be deduced using ranked ratings.\nIn rank aggregation, the task at hand is to find a ranking that is at the smallest cumulative distance from a given set of rankings. Here, the cumulative distance from a set equals the sum of the distances from each element of the set, and the most frequently used distance measure for the case of permutations is the Kendall \u03c4 distance. For the case of partial rankings, the distance of choice is the Kemeny distance [6]. The Kendall \u03c4 distance between two permutations equals the smallest number of adjacent transpositions needed to convert one permutation into the other. The Kemeny distance contains an additional weighted correction term that accounts for ties in the rankings.\nIt is well known that for a wide range of distance functions, learning the underlying models and aggregating rankings is computationally hard [7]. Nevertheless, for the case when the distance measure is the Kendall \u03c4 distance, a number of approximation algorithms have been developed that offer various trade-offs between quality of aggregation and computational complexity [8, 9]. The techniques used for aggregating permutations in a given set include randomly choosing a permutation from the set (PICK-A-PERM), pivoting via random selections of elements and divide-and-conquer approaches (FAS-PIVOT), Markov chain methods akin to PageRank, and minimum weight graph matching methods exploiting the fact that the Kendall \u03c4 distance is well-approximated by the Spearman footrule distance (SM) [10]. Methods with provable performance guarantees \u2013 PICK-A-PERM, FAS-PIVOT, and SM \u2013 give a 2-approximation for the objective function, although combinations thereof are known to improve the constant to 11/7 or 4/3 [9]. There also exists a polynomial time approximation scheme (PTAS) for the aggregation problem [11].\nUnfortunately, most of these known approximate rank aggregation algorithms have high complexity for use with massive datasets and may not be implemented in a parallel fashion. Furthermore, they do\n\u2217A shorter version of this will appear in Artificial Intelligence and Statistics (AISTATS), 2017. \u2020The authors are with the Coordinated Science Laboratory, Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign (email: panli2@illinois.edu, milenkov@illinois.edu) \u2021The author is with Department of Computer Science, University of Massachusetts(email: arya@cs.umass.edu). 1In the mathematics literature, partial rankings are commonly referred to as weak orders, while the term partial order is used to describe orders of subsets of elements of a ground set. We nevertheless use the term partial ranking to denote orders with ties, as this terminology is more widely adopted by the machine learning community.\nnot easily extend to partial rankings. In many cases, a performance analysis on probabilistic models [12] such as the Plackett-Luce model [13] or the Mallows model [14, 15], is intractable.\nIn this paper, we propose a new approach to the problem of rank aggregation that uses a combinatorial transform, the Lehmer code (LC). The gist of the approach is to convert permutations into their Lehmer code representations, in which each coordinate takes values independently from other coordinates. Aggregation over the Lehmer code domain reduces to computing the median or mode of a bounded set of numbers, which can be done in linear time. Furthermore, efficient conversion algorithms between permutations and Lehmer codes \u2013 also running in linear time \u2013 are known, making the overall complexity of the parallel implementation of the scheme O(m + n), where m denotes the number of permutations to be aggregated, and n denotes the length (size) of the permutations. To illustrate the performance of the Lehmer code aggregators (LCAs) on permutations, we carry out simulation studies showing that the algorithms perform comparably with the best known methods for approximate aggregation, but at a significantly lower computational cost. We then proceed to establish a number of theoretical performance guarantees for the LCA algorithms: In particular, we consider the Mallows model with the Kendall \u03c4 distance for permutations and Kemeny distance for partial rankings where ties are allowed. We show that the centroid permutation of the model or a derivative thereof may be recovered from O(log n) samples from the corresponding distribution with high probability.\nThe paper is organized as follows. Section 2 contains the mathematical preliminaries and the definitions used throughout the paper. Section 3 introduces our new aggregation methods for two types of rankings, while Section 4 describes our analysis pertaining to the Mallows and generalized Mallows models. Section 5 contains illustrative simulation results comparing the performance of the LC aggregators to that of other known aggregation methods, both on simulated and real ranking data. A number of technical results, namely detailed proofs of theorems and lemmas, can be found in the Appendix."}, {"heading": "2 Mathematical Preliminaries", "text": "Let S denote a set of n elements, which without loss of generality we assume to be equal to [n] \u2261 {1, 2, . . . , n}. A ranking is an ordering of a subset of elements Q of [n] according to a predefined rule. When Q = [n], we refer to the order as a permutation (full ranking). When a ranking includes ties, we refer to it as a partial ranking (weak or bucket order). Partial rankings may be used to complete rankings of subsets of element in [n] in a number of different ways [16], one being to tie all unranked elements at the last position.\nRigorously, a permutation is a bijection \u03c3 : [n] \u2192 [n], and the set of permutations over [n] forms the symmetric group of order n! denoted by Sn. For any \u03c3 \u2208 Sn and x \u2208 [n], \u03c3(x) denotes the rank (position) of the element x in \u03c3. We say that x is ranked higher than y (ranked lower than y) iff \u03c3(x) < \u03c3(y) (\u03c3(x) > \u03c3(y)). The inverse of a permutation \u03c3 is denoted by \u03c3\u22121 : [n] \u2192 [n]. Clearly, \u03c3\u22121(i) represents the element ranked at position i in \u03c3. We define the projection of a permutation \u03c3 over a subset of elements Q \u2286 [n], denoted by \u03c3Q : Q \u2192 [|Q|], as an ordering of elements in Q such that x, y \u2208 Q, \u03c3Q(x) > \u03c3Q(y) iff \u03c3(x) > \u03c3(y). As an example, the projection of \u03c3 = (2, 1, 4, 5, 3, 6) over Q = {1, 3, 5, 6} equals \u03c3Q = (1, 3, 2, 4), since \u03c3(1) < \u03c3(5) < \u03c3(3) < \u03c3(6). As can be seen, \u03c3Q(x) equals the rank of element x \u2208 Q in \u03c3.\nWe use a similar set of definitions for partial rankings [16]. A partial ranking \u03c3 is also defined as a mapping [n] \u2192 [n]. In contrast to permutations, where the mapping is a bijection, the mapping in partial ranking allows for ties, i.e., there may exist two elements x 6= y such that \u03c3(x) = \u03c3(y). A partial ranking is often represented using buckets, and is in this context referred to as a bucket order [16]. In a bucket order, the elements of the set [n] are partitioned into a number of subsets, or buckets, B1,B2, ...,Bt. We let \u03c3(x) denote the index of the bucket containing the element x in \u03c3, so the element x is assigned to bucket B\u03c3(x). Two elements x, y lie in the same bucket if and only if they are tied in \u03c3. We may also define a projection of a partial ranking \u03c3 over a subset of elements Q \u2282 [n], denoted by \u03c3Q, so that for x, y \u2208 Q, \u03c3Q(x) > \u03c3Q(y) iff \u03c3(x) > \u03c3(y) and \u03c3Q(x) = \u03c3Q(y) iff \u03c3(x) = \u03c3(y). For a given partial ranking \u03c3, we use B1(\u03c3),B2(\u03c3), ...,Bt(\u03c3) to denote its corresponding buckets. In addition, we define rk(\u03c3) , \u2211k j=1 |Bj(\u03c3)| and lk(\u03c3) , \u2211k\u22121\nj=1 |Bj(\u03c3)|+ 1. Based on the previous discussion, r\u03c3(x)(\u03c3)\u2212 l\u03c3(x)(\u03c3) + 1 = |B\u03c3(x)(\u03c3)| (the number of elements that are in the bucket containing x). When referring to the bucket for a certain element x, we use B\u03c3(x), r\u03c3(x), l\u03c3(x) whenever no confusion arises. Note that if we arbitrarily break ties in \u03c3 to create a permutation \u03c3\u2032, then l\u03c3(x) \u2264 \u03c3\n\u2032(x) \u2264 r\u03c3(x); clearly, if \u03c3 is a permutation, we have l\u03c3(i) = \u03c3(i) = r\u03c3(i).\nA number of distance functions between permutations are known from the social choice, learning and discrete mathematics literature [10]. One distance function of interest is based on transpositions: A\ntransposition (a, b) is a swap of elements at positions a and b, a 6= b. If |a \u2212 b| = 1, the transposition is referred to as an adjacent transposition. It is well known that transpositions (adjacent transpositions) generate Sn, i.e., any permutation \u03c0 \u2208 Sn can be converted into another permutation \u03c3 \u2208 Sn through a sequence of transpositions (adjacent transpositions) [17]. The smallest number of adjacent transpositions needed to convert a permutation \u03c0 into another permutation \u03c3 is known as the Kendall \u03c4 distance between \u03c0 and \u03c3, and is denoted by d\u03c4 (\u03c0, \u03c3). Alternatively, the Kendall \u03c4 distance between two permutations \u03c0 and \u03c3 over [n] equals the number of mutual inversions between the elements of the two permutations:\nd\u03c4 (\u03c3, \u03c0) = |{(x, y) : \u03c0(x) > \u03c0(y), \u03c3(x) < \u03c3(y)}|. (1)\nAnother distance measure, that does not rely on transpositions, is the Spearman footrule, defined as\ndS(\u03c3, \u03c0) = \u2211\nx\u2208[n]\n|\u03c3(x) \u2212 \u03c0(x)|.\nA well known result by Diaconis and Graham [10] asserts that d\u03c4 (\u03c0, \u03c3) \u2264 dS(\u03c0, \u03c3) \u2264 2d\u03c4 (\u03c0, \u03c3). One may also define an extension of the Kendall \u03c4 distance for the case of two partial rankings \u03c0 and \u03c3 over the set [n], known as the Kemeny distance:\ndK(\u03c0, \u03c3) =|{(x, y) : \u03c0(x) > \u03c3(y), \u03c0(x) < \u03c3(y)}|\n+ 1\n2 |{(x, y) : \u03c0(x) = \u03c0(y), \u03c3(x) > \u03c3(y),\nor \u03c0(x) > \u03c0(y), \u03c3(x) = \u03c3(y), }|. (2)\nThe Kemeny distance includes a component equal to the Kendal \u03c4 distance between the linear chains in the partial rankings, and another, scaled component that characterizes the distance of tied pairs of elements [16]. The Spearman footrule distance may also be defined to apply to partial rankings [16], and it equals the sum of the absolute differences between \u201cpositions\u201d of elements in the partial rankings. Here, the position of an element x in a partial ranking \u03c3 is defined as\npos\u03c3(x) ,\n\u03c3(x)\u22121 \u2211\nj=1\n|Bj(\u03c3)| + |B\u03c3(x)(\u03c3)|+ 1\n2 .\nThe above defined Spearman distance is a 2-approximation for the Kemeny distance between two partial rankings [16].\nA permutation \u03c3 = (\u03c3(1), . . . , \u03c3(n)) \u2208 Sn may be uniquely represented via its Lehmer code (also called the inversion vector), i.e. a word of the form\nc\u03c3 \u2208 Cn , {0} \u00d7 [0, 1]\u00d7 [0, 2]\u00d7 \u00b7 \u00b7 \u00b7 \u00d7 [0, n\u2212 1],\nwhere for i = 1, . . . , n,\nc\u03c3(x) = |{y : y < x, \u03c3(y) > \u03c3(x)}|, (3)\nand for integers a \u2264 b, [a, b] \u2261 [a, a + 1, . . . , b]. By default, c\u03c3(1) = 0, and is typically omitted. For instance, we have\ne 1 2 3 4 5 6 7 8 9 \u03c3 2 1 4 5 7 3 6 9 8 c\u03c3 0 1 0 0 0 3 1 0 1\nIt is well known that the Lehmer code is bijective, and that the encoding and decoding algorithms have linear complexity (n) [18, 19]. Codes with similar properties to the Lehmer codes have been extensively studied under the name of subdiagonal codes. An overview of such codes and their relationship to Mahonian statistics on permutations may be found in [20].\nWe propose next our generalization of Lehmer codes to partial rankings. Recall that the x-th entry in the Lehmer code of a permutation \u03c3 is the number of elements with index smaller than x that are ranked lower than x in \u03c3 (3). For a partial ranking, in addition to c\u03c3, we use another code that takes into account ties according to:\nc \u2032 \u03c3(x) = |{y \u2208 [n] : y < x, \u03c3(y) \u2265 \u03c3(x)}|. (4)\nClearly, c\u2032\u03c3(x) \u2265 c\u03c3(x) for all x \u2208 [n]. It is straightforward to see that using c\u03c3(x) and c \u2032 \u03c3(x), one may recover the original partial ranking \u03c3. In fact, we prove next that the linear-time Lehmer encoding and decoding algorithms may be used to encode and decode c\u03c3 and c \u2032 \u03c3 in linear time as well.\nGiven a partial ranking \u03c3, we may break the ties in each bucket to arrive at a permutation \u03c3\u2032 as follows: For x, y \u2208 S, if \u03c3(x) = \u03c3(y),\n\u03c3\u2032(x) < \u03c3\u2032(y) if and only if x < y. (5)\nWe observe that the entries of the Lehmer codes of \u03c3 and \u03c3\u2032 satisfy the following relationships for all i \u2208 [n]:\nc \u2032 \u03c3(x) = c\u03c3\u2032(x) + INx \u2212 1, c\u03c3(x) = c\u03c3\u2032(x),\nwhere INx = |{y \u2208 [n] \u2229 B\u03c3(x) : y \u2264 x}|. An example illustrating these concepts is given below.\ne 1 2 3 4 5 6 7 8 9 \u03c3 1 1 2 2 3 1 2 3 3 \u03c3\u2032 1 2 4 5 7 3 6 8 9 c\u03c3\u2032 0 0 0 0 0 3 1 0 0 IN 1 2 1 2 1 3 3 2 3 c\u03c3 0 0 0 0 0 3 1 0 0 c \u2032 \u03c3 0 1 0 1 0 5 3 1 2\nNote that INx, as well as c\u03c3 and c \u2032 \u03c3 may be computed in linear time. The encoding procedure is\noutlined in Algorithm 1.\nAlgorithm 1: Lehmer encoder for partial rankings Input: a partial ranking \u03c3; 1: Set N to be the number of buckets in \u03c3; 2: Initialize IN = (0, 0, ..., 0) \u2208 Nn\nand BucketSize = (0, 0, ..., 0) \u2208 NN ; 3: For x from 1 to n do 4: BucketSize(\u03c3(x)) + +; 5: IN(x) \u2190 BucketSize(\u03c3(x)); 6: Break ties of \u03c3 to get \u03c3\u2032 according to (5); 7: c\u03c3\u2032 \u2190 Lehmer code of \u03c3\n\u2032; Output: Output c\u03c3 = c\u03c3\u2032 , c \u2032 \u03c3 = c\u03c3 + IN\u2212 1;"}, {"heading": "3 Aggregation Algorithms", "text": "Assume that we have to aggregate a set of m rankings, denoted by \u03a3 = (\u03c31, \u03c32, . . . , \u03c3m), \u03c3k \u2208 Sn, 1 \u2264 k \u2264 m. Aggregation may be performed via the distance-based Kemeny-Young model, in which one seeks a ranking \u03c3 that minimizes the cumulative Kendall \u03c4 (Kemeny) distance d\u03c4 (dK) from the set \u03a3, formally defined as:\nD(\u03a3, \u03c3) =\nm \u2211\ni=1\nd\u03c4 (\u03c3i, \u03c3).\nNote that when the set \u03a3 comprises permutations only, \u03c3 is required to be a permutation; if \u03a3 comprises partial rankings, we allow the output to be either a permutation or a partial ranking.\nThe LCA procedure under the Kendall \u03c4 distance is described in Algorithm 2. Note that each step of the algorithm may be executed in parallel. If no parallelization is used, the first step requires O(mn) time, given that the Lehmer codes may be computed in O(n) time [18, 19]. If parallelization on \u03a3 is used instead, the time reduces to O(m + n). Similarly, without parallelization the second step requires O(mn) time, while coordinate parallelization reduces this time to O(m). This third step requires O(n) computations. Hence, the overall complexity of the algorithm is either O(mn) or O(m + n), depending on parallelization being used or not.\nAlgorithm 2: The LCA Method (Permutations) Input: \u03a3 = {\u03c31, \u03c32, ..., \u03c3m}, where \u03c3i \u2208 Sn, i \u2208 [n]. 1: Compute the Lehmer codewords c\u03c3j for all \u03c3j \u2208 \u03a3. 2: Compute the median/mode of the coordinates:\nc\u0302(i) = median/mode ( c\u03c31(i), c\u03c32(i), . . . , c\u03c3m(i) ) .\n3: Compute \u03c3\u0302, the inverse Lehmer code of c\u0302. Output: Output \u03c3\u0302.\nFor permutations, the aggregation procedure may be viewed as specialized voting: The ranking \u03c3k casts a vote to rank x at position x\u2212 c\u03c3k(x), for the case that only elements \u2264 x are considered (A vote corresponds to some score confined to [0, 1]). However, when \u03c3k is a partial ranking involving ties, the vote should account for all possible placements between x\u2212c\u2032\u03c3(x) and x\u2212c\u03c3(x). More precisely, suppose that the vote cast by \u03c3k to place element x in position y \u2208 [x] is denoted by vk\u2192x(y). Then, one should have\nvk\u2192x(y) =\n{\n1, for the mode, 1\nc \u2032 \u03c3(x)\u2212c\u03c3(x)+1\n, for the median, (6)\nif and only if y \u2208 [x \u2212 c\u2032\u03c3(x), x \u2212 c\u03c3(x)], and zero otherwise. Note that when the mode is used, the \u201cpositive votes\u201d are all equal to one, while when the median is used, a vote counts only a fractional value dictated by the length of the \u201cranking interval\u201d.\nNext, we use Vx(y) = \u2211m\nk=1 vk\u2192x(y) to denote the total voting score element x received to be ranked at position y. The inverse Lehmer code of the aggregator output \u03c3\u0302 is computed as:\nmode: c\u0302(x) = argy\u2208[x]maxVx(y)\u2212 1, (7)\nmedian: c\u0302(x) = min{k :\n\u2211k y=1 Vx(y)\nm \u2265 1/2} \u2212 1.\nTo compute the values Vx(y) for all y \u2208 [x], the LCA algorithm requires O(mx) time, which yields an overall aggregation complexity of O(mn2) when no parallelization is used. This complexity is reduced to O(m + n2) for the parallel implementation. Note that the evaluations of the V functions may be performed in a simple iterative manner provided that the votes vk\u2192x(y) are positive constants, leading to a reduction in the overall complexity of this step to O(mn+n2) when no parallelization is used. Relevant details regarding the iterative procedure may be found in Appendix G.\nNote that the output \u03c3\u0302 of Algorithm 2 is a permutation. To generate a partial ranking that minimizes the Kemeny distance while being consistent2 with \u03c3\u0302, one can use a O(mn2+n3)-time algorithm outlined in Appendix G. Alternatively, the following simple greedy method always produces practically good partial rankings with O(mn) complexity: Scan the elements in the output permutation from highest (j = 1) to lowest rank (j = n \u2212 1) and decide to put \u03c3\u0302\u22121(j + 1) and \u03c3\u0302\u22121(j) in the same bucket or not based on which of the two choices offers smaller Kemeny distance with respect to the subset {\u03c3\u0302\u22121(1), ..., \u03c3\u0302\u22121(j)}.\nDiscussion. In what follows, we briefly outline the similarities and differences between the LCA method and existing positional as well as InsertionSort based aggregation methods. Positional methods are a class of aggregation algorithms that seek to output a ranking in which the position of each element is \u201cclose\u201d to the position of the element in \u03a3. One example of a positional method is Borda\u2019s algorithm, which is known to produce a 5-approximation to the Kemeny-Young problem for permutations [21]. Another method is the Spearman footrule aggregation method which seeks to find a permutation that minimizes the sum of the Spearman footrule distance between the output and each ranking in \u03a3. As already mentioned, the latter method produces a 2-approximation for the Kendall \u03c4 aggregate for both permutations and partial ranking. LCA also falls under the category of positional methods, but the positions on which scoring is performed are highly specialized by the Lehmer code. And although it appears hard to prove worst-case performance guarantees for the method, statistical analysis on particular ranking models shows that it can recover the correct results with small sample complexity. It also offers significant reductions in computational time compared to the Spearman footrule method, which reduces to solving a weighted bipartite matching problem and hence has complexity at least O(mn2 + n3) [22], or O(mn) when implemented in MapReduce [23].\nA related type of aggregation is based on InsertionSort [8, 22]. In each iteration, an element is randomly chosen to be inserted into the sequence containing the already sorted elements. The position of\n2We say that two partial rankings \u03c3, \u03c0 are consistent if for any two elements x, y, \u03c3(x) < \u03c3(y) if and only if \u03c0(x) \u2264 \u03c0(y) and vise versa.\nthe insertion is selected as follows. Assume that the elements are inserted according to the identity order e = (1, 2, . . . , n) so that at iteration t, element t is chosen to be inserted into some previously constructed ranking over [t\u2212 1]. Let St\u22121 = [t\u2212 1] and the symbol t is inserted into the ranking over St\u22121 to arrive at \u03c3St , the ranking available after iteration t. If t is inserted between two adjacent elements \u03c3 \u22121 St\u22121 (i\u2212 1) and \u03c3\u22121St\u22121(i), then one should have \u03c3St(x) = \u03c3St\u22121(x) when \u03c3St\u22121(x) \u2264 i \u2212 1, \u03c3St(x) = \u03c3St\u22121(x \u2212 1) + 1 when \u03c3St\u22121(x) \u2265 i and \u03c3St(t) = i. Let \u03c3St(t) denote the rank assigned to element t over St, the choice of which may vary from method to method. The authors of [8] proposed setting \u03c3St(t) to\nmax\n\n\n\ni \u2208 [t\u2212 1] : \u2211\nk\u2208[m]\n1\u03c3k(t)<\u03c3k(\u03c3\u22121St\u22121 (i)) <\nm\n2\n\n\n\n,\nor t when the above set is empty. This insertion rule does not ensure a constant approximation guarantee in the worst case (It has an expected worst-case performance guarantee of \u2126(n)), although it leads to a Locally Kemeny optimal solution.\nWe next describe how the LCA method may be viewed as an InsertionSort method with a special choice of \u03c3St(t). Consider the permutation LCA method of Algorithm 2, and focus on estimating the t-th coordinate of the Lehmer code c\u0302(t) (step 2) and the inverse Lehmer code via insertion (step 3) simultaneously. Once c\u0302(t) is generated, it\u2019s corresponding inverse Lehmer transform may be viewed as the operation of placing the element t at position (t \u2212 c\u0302(t)) over St. In other words, inverting the incomplete ranking reduces to setting \u03c3St(t) = (t \u2212 c\u0302(t)), where \u03c3St(t) essentially equals the mode or median of the positions of t in the rankings of \u03a3, projected onto St. The same is true of partial rankings, with the only difference being that the selection of \u03c3St(t) has to be changed because of ties between elements."}, {"heading": "4 Analysis of the Mallows Model", "text": "We provide next a theoretical performance analysis of the LCA algorithm under the assumption that the rankings are generated according to the Mallows and generalized Mallows Model. In the Mallows model MM(\u03c30, \u03c6) with parameters \u03c30 and \u03c6, \u03c30 denotes the centroid ranking and \u03c6 \u2208 (0, 1] determines the variance of the ranking with respect to \u03c30. The probability of a permutation \u03c3 is proportional to \u03c6d\u03c4 (\u03c30,\u03c3). For partial rankings, we assume that the samples are generated from a generalized Mallows Model (GMM) whose centroid is allowed to be a partial ranking and where the distance is the Kemeny dk, rather than the Kendall \u03c4 distance d\u03c4 .\nOur analysis is based on the premise that given a sufficiently large number of samples (permutations), one expects the ranking obtained by a good aggregation algorithm to be equal to the centroid \u03c30 with high probability. Alternative methods to analytically test the quality of an aggregation algorithm are to perform a worst-case analysis, which for the LCA method appears hard, or to perform a simulation-based analysis which produces a comparison of the objective function values for the Kemeny-Young problem given different aggregation methods. We report on the latter study in the section to follow.\nTo ease the notational burden, we henceforth use \u03c6s:t , \u2211t k=s \u03c6 k in all subsequent results and derivations. Detailed proofs are relegated to the appendix. One of our main theoretical result is the following.\nTheorem 4.1. Assume that \u03a3 = {\u03c31, \u03c32, ..., \u03c3m}, where \u03c3k i.i.d \u223c MM(\u03c30, \u03c6), k \u2208 [m], arem i.i.d. samples of the given Mallows model. If \u03c6+ \u03c62 < 1 + \u03c6n and m \u2265 c log n 2\n2\u03b4 with c = 2(1+q)2 (1\u2212q)4 and q = \u03c61:n\u22121 1+\u03c63:n , then\nthe output ranking of Algorithm 2 under the mode rule equals \u03c30 with probability at least 1\u2212 \u03b4.\nThe idea behind the proof is to view the LCA procedure as an InsertionSort method, in which the probability of the event that the selected position is incorrect with respect to \u03c30 is very small for sufficiently large m. Based on the lemma that follows (Lemma 4.2), one may show that if \u03c6 satisfies \u03c6+\u03c62 < 1+\u03c6n, the most probable position of an element in a ranking \u03c3 \u223c MM(\u03c30, \u03c6) corresponds to its rank in the centroid \u03c30. Given enough samples, one can estimate the rank of an element in the centroid by directly using the mode of the rank of the element in the drawn samples.\nLemma 4.2. Let \u03c3 \u223c MM(\u03c30, \u03c6). Consider an element u. Then, the following two statements describe\nthe distribution of \u03c3(u):\n1) P[\u03c3(u) = j + 1]\nP[\u03c3(u) = j] \u2208 [\u03c6, \u03c61:n\u22121 1 + \u03c63:n ] when \u03c30(u) \u2264 j < n.\n2) P[\u03c3(u) = j \u2212 1]\nP[\u03c3(u) = j] \u2208 [\u03c6, \u03c61:n\u22121 1 + \u03c63:n ] when 1 < j \u2264 \u03c30(u).\nIn 1), the upper bound is achieved when \u03c30(u) = n\u2212 1 and j = \u03c30(u), while the lower bound is achieved when \u03c30(u) = 1. In 2), the upper bound is achieved when \u03c30(u) = 2 and j = \u03c30(u), while the lower bound is achieved when \u03c30(u) = n.\nRemark 4.1. The result above may seem counterintuitive since it implies that for \u03c6 + \u03c62 > 1 + \u03c6n, the probability of ranking some element u at a position different from its position in \u03c30 is larger than the probability of raking it at position \u03c30(u). An easy-to-check example that shows that this indeed may be the case corresponds to \u03c30 = (1, 2, 3, 4) and \u03c6 = 0.9. Here, we have P[\u03c3(3) = 3] = 0.2559 < P[\u03c3(3) = 4] = 0.2617.\nLemma 4.2 does not guarantee that in any single iteration the position of the element will be correct, since the ranking involves only a subset of elements. Therefore, Lemma 4.3, a generalized version for the subset-projected ranking, is required for the proof.\nLemma 4.3. Let \u03c3 \u223c MM(\u03c30, \u03c6) and let A \u2282 [n]. Consider an element u \u2208 A. Then, the following two statements describe the distribution of \u03c3A(u):\n1) P[\u03c3A(u) = j + 1]\nP[\u03c3A(u) = j] \u2264 max l\u2208[0,n\u2212|A|] \u03c6+ \u03c6l\u03c62:n\u2212l\u22121 1 + \u03c62l\u03c63:n\u2212l\nwhen |A| > j \u2265 \u03c30,A(u).\n2) P[\u03c3A(u) = j \u2212 1]\nP[\u03c3A(u) = j] \u2264 max l\u2208[0,n\u2212|A|] \u03c6+ \u03c6l\u03c62:n\u2212l\u22121 1 + \u03c62l\u03c63:n\u2212l\nwhen 1 < j \u2264 \u03c30,A(u).\nObserve that the conditions that allow one to achieve the upper bound in Lemma 4.2 also ensure that the upper bounds are achieved in Lemma 4.3. Moreover, when \u03c6+ \u03c62 < 1 + \u03c6n, the right hand sides are \u2264 \u03c61:n\u221211+\u03c63:n .\nThe next result establishes the performance guarantees for the LCA algorithm with the median operation.\nTheorem 4.4. Assume that \u03a3 = {\u03c31, \u03c32, ..., \u03c3m}, where \u03c3k i.i.d \u223c MM(\u03c30, \u03c6), k \u2208 [m]. If \u03c6 < 0.5 and m \u2265 c log 2n\u03b4 , where c = 2\n(1\u22122\u03c6)2 , then the output of Algorithm 2 under the median operation equals \u03c30 with probability at least 1\u2212 \u03b4.\nThe proof follows by observing that if the median of the Lehmer code c\u03c3k(t) over all k \u2208 [m] converges to t \u2212 \u03c30,St(t) as m \u2192 \u221e, then each \u03c3k should have P[\u03c3k,St(t) > \u03c30,St(t)],P[\u03c3k,St(t) < \u03c30,St(t)] < 1/2. According to the following Lemma, in this case, one needs \u03c6 < 0.5.\nLemma 4.5. Let \u03c3 \u223c MM(\u03c30, \u03c6) and let A \u2286 [n]. For any u \u2208 A, the following two bounds hold:\n1) P[\u03c3A(u) > \u03c30,A(u)] \u2264 \u03c61:(|A|\u2212\u03c30,A(u))\n\u03c60:(|A|\u2212\u03c30,A(u)) < \u03c6,\n2) P[\u03c3A(u) < \u03c30,A(u)] \u2264 \u03c61:\u03c30,A(u)\n\u03c60:\u03c30,A(u) < \u03c6.\nThe inequality 1) is met for A = S and \u03c30(u) = 1, while the inequality 2) is met for A = S and \u03c30(u) = n.\nWe now turn our attention to partial rankings and prove the following extension of the previous result for the GMM, under the LCA algorithm that uses the median of coordinate values. Note that the output of Algorithm 2 is essentially a permutation, although it may be transformed into a partial ranking via the bucketing method described in Section 2.\nTheorem 4.6. Assume that \u03a3 = {\u03c31, \u03c32, ..., \u03c3m}, where \u03c3k i.i.d \u223c GMM(\u03c30, \u03c6), k \u2208 [m]. If \u03c6 + \u03c6 1/2 < 1 and m \u2265 c log 2n\u03b4 with c = 2 (1\u22122q\u2032)2 , where q \u2032 = 1 \u2212 12\u03c6 1/2 \u2212 12\u03c6, then the output ranking of the LCA algorithm (see Appendix E) under the median operation is in \u03a30 with probability at least 1 \u2212 \u03b4. Here, \u03a30 denotes the set of permutations generated by breaking ties in \u03c30.\nThe proof of this theorem relies on showing that the InsertionSort procedure places elements in their correct position with high probability. If the median is used for partial ranking aggregation, one vote is uniformly distributed amongst all possible positions in the range given by (6). To ensure that the output permutation is in \u03a30, we need to guarantee that the median of the positions of the votes for t over St is in [l\u03c30,St(t), r\u03c30,St(t)] for large enough m (as in this case, [l\u03c30,St(t), r\u03c30,St(t)] represents the bucket in \u03c30 that contains t).\nFor a \u03c3 \u223c GMM(\u03c30, \u03c6), let v(j) be the vote that the partial ranking \u03c3 cast for position j. Then, one requires that\nE[\nr\u03c30,A(u) \u2211\nk=1\nv(j)] > 0.5 and E[\nn \u2211\nk=l\u03c30,A(u)\nv(j)] > 0.5.\nThe expectations in the expressions above may be evaluated as follows (We only consider the expectation on the left because of symmetry). If the eventW = {r\u03c3St (t) \u2264 r\u03c30,St (t)} occurs, then the vote of \u03c3 that contributes to the sum equals 1. If the event Q = \u222a n\u2212r\u03c30,St (t)\nj=1 Qj , where Qj = {r\u03c3St (t) = j+r\u03c30,St (t), l\u03c3St(t) \u2264\nr\u03c30,St (t)} occurs, then the vote that \u03c3 contributes to the sum equals Vj = r\u03c30,St (t) \u2212l\u03c3St (t) +1\nr\u03c3St (t) \u2212l\u03c3St (t)\n+1 . Therefore,\nwe have\nE[\nr\u03c30,St (t) \u2211\nk=1\nv(k)] = P[W ] +\nn\u2212r\u03c30(u) \u2211\nj=1\nVjP[Qj ]. (8)\nThe following lemma describes a lower bound for (8).\nLemma 4.7. Let \u03c3 \u223c GMM(\u03c30, \u03c6) and let A \u2286 [n] be such that it contains a predefined element u. Let A\u2032 = A\u2212 {x \u2208 A : x 6= u, \u03c30,A(x) \u2264 \u03c30,A(u)}. Define\nW = {r\u03c3A(u) \u2264 r\u03c30,A(u)},\nQj = {r\u03c3A(u) = j + r\u03c30,A(u), l\u03c3A(u) \u2264 r\u03c30,A(u)}, W \u2032 = {r\u03c3A\u2032 (u) \u2264 r\u03c30,A\u2032 (u)}, Q\u2032j = {r\u03c3A\u2032 (u) = j + r\u03c30,A\u2032 (u), l\u03c3\u2032A(u) \u2264 r\u03c30,A\u2032 (u)}.\nThen, one can prove that\nP[W ] + \u2211|A|\u2212r\u03c30,A (u)\nj=1 VjP[Qj ]\n\u2265 P[W \u2032] + \u2211|A\u2032|\u2212r\u03c3 0,A\u2032 (u)\nj=1 1 j+1VjP[Q \u2032 j]\n\u2265 1\u2212 12\u03c6 1/2 \u2212 12\u03c6.\nIf \u03c6+\u03c61/2 < 1, the lower bound above exceeds 1/2. Theorem 4.6 then follows using the union bound and Hoeffding\u2019s inequality."}, {"heading": "5 Performance Evaluation", "text": "We next evaluate the performance of the LCA algorithms via experimental methods and compare it to that of other rank aggregation methods using both synthetic and real datasets. For comparative analysis, we choose the Fas-Pivot and FasLP-Pivot (LP) methods [9], InsertionSort with Comparison (InsertionComp) from [8], and the optimal Spearman Footrule distance aggregator (Spearman) [10]. For the randomized algorithms Fas-Pivot and FasLP-Pivot, the pivot in each iteration is chosen randomly. For InsertionSort with Comparison, the insertion order of the elements is also chosen randomly. Furthermore, for all three methods, the procedure is executed five times, and the best solution is selected. For Fas-Pivot and FasLP-Pivot, we chose the better result of Pick-A-Perm and the given method, as suggested in [9].\nIn the context of synthetic data, we only present results for the Mallows model in which the number of ranked items equals n = 10, and the number of rankings equals m = 50. The variance parameter was chosen according to \u03c6 = e\u2212\u03bb, where \u03bb is allowed to vary in [0, 1]. For each parameter setting, we ran 50 independent simulations and computed the average cumulative Kendall \u03c4 distance (normalized by m) between the output ranking and \u03a3, given as Dav = D(\u03c3,\u03a3)\nm . We then normalized the Dav value of each algorithm by that of FasLP-Pivot, since FasLP-Pivot always offered the best performance. The results\nare depicted in Fig. 1. Note that we used MostProb to describe the most probable ranking, which is the centroid for the Mallows Model.\nNote that for parameter values \u03bb \u2265 0.6 LCA algorithms perform almost identically to the best aggregation method, the LP-based pivoting scheme. For smaller values of \u03bb, small performance differences may be observed; these are compensated by the significantly smaller complexity of the LCA methods which in the parallel implementation mode is only linear in n and m. Note that the InsertionSort Comp method performs poorly, although it ensures local Kemeny optimality.\nWe also conducted experiments on a number of real-world datasets. To test the permutation LCA aggregation algorithms, we used the Sushi ranking dataset [24] and the Jester dataset [25]. The Sushi dataset consists of 5000 permutations involving n = 10 types of sushi. The Jester dataset contains scores in the continuous interval [\u221210, 10] for n = 100 jokes submitted by 48483 individuals. We chose the scores of 14116 individuals who rated all 100 jokes and transformed the rating into permutations by sorting the scores. For each dataset, we tested our algorithms by randomly choosing m many samples out of the complete list and by computing the average cumulative Kendall \u03c4 distance normalized by m via 50 independent tests. The results are listed in the Table 1 and Table 2.\nTo test our partial ranking aggregation algorithms, we used the complete Jester dataset [25] and the Movielens dataset [26]. For the Jester dataset, we first rounded the scores to the nearest integer and\nthen placed the jokes with the same integer score in the same bucket of the resulting partial ranking. We also assumed that the unrated jokes were placed in a bucket ranked lower than any other bucket of the rated jokes. The movielens dataset contains incomplete lists of scores for more than 1682 movies rated by 943 users. The scores are integers in [5], so that many ties are present. We chose the 50 most rated movies and 500 users who rated these movies with largest coverage. Similarly as for the Jester dataset, we assumed that the unrated movies were tied for the last position. In each test, we used the iterative method described in Section 3 to transform permutations into partial rankings. Note that when computing the Kemeny distance between two partial rankings of (2), we omitted the penalty incurred by ties between unrated elements, because otherwise the iterative method would yield too many ties in the output partial ranking. More precisely, we used the following formula to assess the distance between two incomplete partial rankings (9):\nd\u03c4 (\u03c0, \u03c3) = |{(x, y) : \u03c0(x) > \u03c3(y), \u03c0(x) < \u03c3(y)}|\n+ 1\n2 |{(x, y) : [\u03c0(x) = \u03c0(y), \u03c3(x) > \u03c3(y), x, y rated by\u03c0]\nor [\u03c0(x) > \u03c0(y), \u03c3(x) = \u03c3(y), x, y rated by\u03c3]}|. (9)\nThe results are listed in Table 3 and Table 4. As may be seen, the parallelizable, low-complexity LCA methods tend to offer very similar performance to that of the significantly more computationally demanding LP pivoting algorithm."}, {"heading": "A Proof of Lemma 4.2", "text": "Before proceeding with the proof, we remark that some ideas in our derivatione have been motivated by Lemma 10.7 of [27].\nLet i , \u03c30(u). Suppose that n > j \u2265 i and that we want to prove statement 1) (the second case when 0 < j \u2264 i may be handled similarly). When i = 1, the underlying ratio is exactly equal to \u03c6. Hence, we only consider the case when i > 1. Let E = {\u03c3 : \u03c3(u) = j} and T = {\u03c3 : \u03c3(u) = j + 1}. In this case, P[\u03c3(u) = j] = P[E] and P[\u03c3(u) = j + 1] = P[T ]. Define the sets:\nE1 = {\u03c3 : \u03c3(u) = j, \u03c30(\u03c3 \u22121(j + 1)) > i}, E2 = {\u03c3 : \u03c3(u) = j, \u03c30(\u03c3 \u22121(j + 1)) < i}, T1 = {\u03c3 : \u03c3(u) = j + 1, \u03c30(\u03c3 \u22121(j)) > i}, T2 = {\u03c3 : \u03c3(u) = j + 1, \u03c30(\u03c3 \u22121(j)) < i}.\nClearly, P[E] = P[E1] +P[E2] and P[T ] = P[T1] +P[T2]. By swapping u and \u03c3 \u22121(j+1), we can construct two bijections E1 \u2194 T1 and E2 \u2194 T2. Statement 1) can then be easily proved by using the following three claims:\nP[T1] = \u03c6P[E1], P[T2] = 1\n\u03c6 P[S2],\n0 < P[T2] a) \u2264 \u03c61:n\u22121P[T1]. (10)\nObserve that inequality is achieved in a) when j = n \u2212 1. The first two claims are straightforward to check, and hence we only prove the third claim.\nConsider a mapping from T2 to T1 based on circular swapping of elements, and let \u03c3 \u2208 T2. Since \u03c3(u)\u22121 = j \u2265 i and \u03c30(\u03c3\n\u22121(j)) < i, there must exist an element x such that \u03c30(x) > \u03c30(u) and \u03c3(x) < j. Choose the element x with the largest corresponding value of \u03c3(x) and construct a new ranking \u03c3\u2032 such that\n\u03c3\u2032(y) =\n\n\n \u03c3(y), if \u03c3(y) < \u03c3(x) or \u03c3(y) \u2265 \u03c3(u), \u03c3(y)\u2212 1, if \u03c3(x) < \u03c3(y) \u2264 \u03c3(u), j, if \u03c3(y) = \u03c3(x).\nIt is easy to see that \u03c3\u2032 \u2208 T1. Given that all elements ranked between x and u in \u03c3 have rank higher than \u03c30(x), we have P[\u03c3] = \u03c6\n\u03c3(u)\u2212\u03c3(x)\u22121P[\u03c3\u2032] = \u03c6j\u2212\u03c3(x)P[\u03c3\u2032]. Note that the above mapping is neither a bijection nor an injection. Denote the mapping by M : Tj,2 \u2192 T2. For each \u03c3\n\u2032 \u2208 T1, define T2,\u03c3\u2032 \u2282 T2, so that for all \u03c3 \u2208 T2,\u03c3\u2032 , M(\u03c3) = \u03c3\n\u2032. Then, \u222a\u03c3\u2032\u2208T1T2,\u03c3\u2032 = T2 forms a partition of the set T2. Next, consider two distinct rankings \u03c31, \u03c32 \u2208 T2,\u03c3\u2032 . These rankings must rank the element x differently, i.e., one must have \u03c31(x) 6= \u03c32(x). Therefore, P[T2,\u03c0\u2032 ] \u2264 P[\u03c0 \u2032]\u03c61:j\u22121 = P[\u03c0 \u2032]\u03c61:j\u22121. As a result, P[T2] \u2264 P[T1]\u03c61:n\u22121, which proves the third claim. We conclude by observing that the condition under which equality is achieved in the bound stated in the lemma is exactly the same condition under which equality is achieved in the bound stated in the third claim."}, {"heading": "B Proof of Lemma 4.3", "text": "Let i , \u03c30,A(u). Suppose that n > j \u2265 i and that we want to prove statement 1) (the case when 0 < j \u2264 i may be handled similarly). Let E = {\u03c0 : \u03c0A(u) = j} and T = {\u03c0 : \u03c0A(u) = j + 1}. The left-hand-side in the statement of 1) equals the ratio P[T ] P[E] . Note that removing a fixed number of elements in S of lowest (or highest) rank in the centroid ranking does not change the probability of the ranking involving the remaining elements (see Lemma F.1 for the proof). We can hence assume that \u03c3\u221210,A(1) is the element with highest rank in \u03c30.\nWhen i = 1, for any ranking \u03c3 in T , we can swap the element u with the element x \u2208 A for which \u03c3A(x) = \u03c3A(u) \u2212 1 to obtain another ranking \u03c3\n\u2032 \u2208 E. Moreover, it is easy to check that P[\u03c3\u2032]\u03c6 \u2265 P[\u03c3], so that the ratio in the statement 1) does not exceed \u03c6. Note that we have inequality \u201c \u2265\u2032\u2032 instead of equality \u201c =\u2032\u2032 in P[\u03c3\u2032]\u03c6 \u2265 P[\u03c3], since there may potentially exists other elements in S/A ranked between x and u in \u03c3.\nNext, consider the case when i > 1. Define the sets\nE1 = {\u03c3 : \u03c3A(u) = j, \u03c30,A(\u03c3 \u22121 A (j + 1)) > i}, E2 = {\u03c3 : \u03c3A(u) = j, \u03c30,A(\u03c3 \u22121 A (j + 1)) < i}, T1 = {\u03c3 : \u03c3A(u) = j + 1, \u03c30,A(\u03c3 \u22121 A (j + 1)) > i}, T2 = {\u03c3 : \u03c3A(u) = j + 1, \u03c30,A(\u03c3 \u22121 A (j + 1)) < i}.\nThen, P[E] = P[E1] + P[E2] and P[T ] = P[T1] + P[T2]. By swapping u and \u03c3 \u22121 A (j + 1), we can construct two bijections E1 \u2194 T1 and E2 \u2194 T2 as follows. Let us consider a finer partition of T2 in terms of permutations with four labels. More precisely, associate each ranking \u03c3 \u2208 T2 with a label vector (x1, x2, \u21131, \u21132), where:\nx1 = \u03c0 \u22121(j). Note that \u03c30,A(x1) < i due to the definition of T2.\nx2 = argmaxx:\u03c30,A(x)>i,\u03c3A(x)<\u03c3A(u) \u03c3A(x); the label x2 is well-defined due to the pigeon-hole principle.\n\u21131 = the cardinality of the set F1 defined as\nF1 = {x \u2208 [n] : \u03c30(x1) < \u03c30(x) < \u03c30(u), \u03c3(\u03c3 \u22121 A (j \u2212 1)) < \u03c3(x) < \u03c3(x1)}.\n\u21132 = the cardinality of the set F2 defined as\nF2 = {x \u2208 [n] : \u03c30(x1) < \u03c30(x) < \u03c30(u), \u03c3(x1) < \u03c3(x) < \u03c3(u)}.\nWe summarize those labels in a vector L = (x1, x2, \u21131, \u21132) and thus partition T2 according to different label vectors L, i.e.,\nT2 = \u222aLT2,L. (11)\nA ranking in T2 is in T2,L if its corresponding label vector equals L. We further construct a mapping M from T2 to T1 by swapping elements ranked between x1 and x2, so that \u03c3\u2032 = M(\u03c3) equals\n\u03c3\u2032A(x) =\n\n  \n   j, \u03c3A(x) = \u03c3A(x2), \u03c3A(x)\u2212 1, \u03c3A(x2) < \u03c3A(x) < j, \u03c3A(x)\u2212 1, \u03c3A(x) = \u03c3A(x1), \u03c3A(x), for other x \u2208 A.\nThe above mapping basically performs circular swapping by moving x2 to the position one rank higher and adjacent to u and by moving each element in A between x2 and x1, including x1, to a higher position adjacent to the original one. Based on M, one can also form a partition of T1 as\nT1 = (\u222aLT1,L) \u222a T1,Lc (12)\nwhere T1,L contains the rankings mapped from T2,L via M. Note that T1,Lc denote the \u201cremainder set\u201d of permutations that do not have a preimage in T2. In this remainder set, a ranking \u03c3 has the property that the elements \u03c3\u22121A (j) and \u03c3 \u22121 A (j\u2212 1) are both ranked lower than u in the centroid ranking. Since the swapping operations establish a bijection between E1 \u2194 T1 and E2 \u2194 T2, one can also partition E1, E2 as\nE1 = (\u222aLE1,L) \u222a E1,Lc , (13)\nE2 = \u222aLE2,L. (14)\nLet R(L) denote P[\u222aL\u2208L(T1,L\u222aT2,L)] P[\u222aL\u2208L(E1,L\u222aE2,L)] and let R(L) denote the same type of ratio but for a specific choice\nof L, i.e., P[T1,L\u222aT2,L] P[E1,L\u222aE2,L] . Also, let L0 denote the set of all possible values of L. To prove the upper bound on P[T ] P[E] , we proceed through four steps.\n1. Partition T and E and verify the validity of (11), (12), (13) and (14).\n2. Prove that P[T1,Lc ] P[E1,Lc ] \u2264 \u03c6.\n3. Prove the upper bound for R(L) when \u21131 = \u21132.\n4. Prove the upper bound for R(L \u222a L\u2032), where L = (k1, k2, \u21131, \u21132) and L \u2032 = (k1, k2, \u21132, \u21131), for the\ncase that \u21131 6= \u21132.\nThe second step is easy to prove by directly swapping \u03c3\u22121A (j) and u in any given ranking \u03c3 \u2208 T1,Lc . We hence only need to establish the validity of the results in Steps 3 and 4.\nFor any L = (k1, k2, \u21131, \u21132), the following claims hold:\nP[E1,L] \u2265 \u03c6 \u22121 P[T1,L], P[E2,L] = \u03c6 1+2\u21132P[T2,L],\nP[T2,L] \u2264 \u03c6 2\u21131fLP[T1,L], where fL \u2264 \u03c61:|A|\u22122\u2212\u21131\u2212\u21132 , (15)\nwhere the first two claims are easy to prove, while the equation (15) may be verified similarly as (10) in the proof of Lemma 5.2 (See Appendix A).\nFor any \u03c3 \u2208 T2,L, \u03c3 \u2032 = M(\u03c3) \u2208 T1,L. Given that all the elements in A ranked between x2 and u in \u03c3\nare ranked lower than u, x2 in the centroid, and due to swapping, we have\nP[\u03c3] P[\u03c3\u2032] \u2264 \u03c6\u03c3A(u)\u2212\u03c3A(x2)\u22121+2\u21131 = \u03c6j\u2212\u03c3A(x2)+2\u21131 .\nConsider two distinct rankings \u03c31, \u03c32 \u2208 T2,L. If M(\u03c31) = M(\u03c32), both rankings rank the element x2 differently over A, i.e., \u03c31,A(x2) 6= \u03c32,A(x2). Therefore, we must have\n\u2211\n\u03c3:M(\u03c3)=\u03c3\u2032\nP[\u03c3] P[\u03c3\u2032] \u2264 \u03c62(\u21131+\u21132)\u03c61:|A|\u22122\u2212\u21131\u2212\u21132 .\nBy examining all mappings from P[T2,L] to P[T1,L], we conclude that fL(\u03c6) = \u03c6 \u22122(\u21131+\u21132) P[T2,L]\nP[T1,L] \u2264\n\u03c61:|A|\u22122\u2212s, which establishes the third claim in (15). Substituting the above expressions into R(L), we have\nR(L) \u2264 1 + \u03c62\u21131\u03c61:|A|\u22122\u2212\u21131\u2212\u21132\n\u03c6\u22121 + \u03c61+2(\u21131+\u21132)\u03c61:|A|\u22122\u2212\u21131\u2212\u21132 . (16)\nSuppose next that \u21131 = \u21133 = \u2113. Then,\nR(L) \u2264 1 + \u03c62\u2113\u03c61:|A|\u22122\u22122\u2113\n\u03c6\u22121 + \u03c61+4\u2113\u03c61:|A|\u22122\u22122\u2113 . (17)\nwhich completes the proof of the bound in Step 3. Let us now consider the bound in Step 4. When \u21131 6= \u21132, direct optimization over \u21131, \u21132 cannot yield the required upper bound as \u21132 \u2192 \u221e may increase the right-hand-side of (18). Hence, in addition to L = (k1, k2, \u21131, \u21132), let us also simultaneously consider L\n\u2032 = (k1 , k2 , \u21132, \u21131), as a larger \u21132 will yield a smaller R(L\u2032), .\nWithout loss of generality, suppose that \u21132 > \u21131. First, we prove the following Lemma.\nLemma B.1. For a pair (L, L\u2032) defined as above with \u21132 > \u21131, one has\nP[T1,L] P[T1,L\u2032 ] \u2264 \u03c6(\u21132\u2212\u21131).\nProof. Recall the definition of the set F2 and the fact that for a ranking \u03c3 \u2208 T1,L, \u03c3 is obtained via M(\u03c0) for some \u03c0 \u2208 T2,L. Hence, in \u03c3, the elements in F1 are now ranked higher than x2 and lower than x1, while the elements in F2 are now ranked higher than u and lower than x2. Based on this structure of \u03c3, for each ranking \u03c3 \u2208 T1,L, one may perform a swapping operation to obtain another ranking \u03c3\n\u2032 in T1,L\u2032. The swapping constitutes a bijection. To see this, consider the set of \u21132 \u2212 \u21131 elements with highest rank in \u03c3F2 (Note that we assumed \u21132 > \u21131 but could have otherwise considered the \u21131 \u2212 \u21132 elements with lowest rank in \u03c3F1 .). Swapping the element x2 and the selected elements in F2 ranked from high to low yields a ranking \u03c3\u2032 \u2208 T1,L\u2032. Since for any element x \u2208 F2, \u03c30(x) < \u03c30(u) < \u03c30(x2), we have P([\u03c3]) \u2264 P([\u03c3\u2032])\u03c6\u21132\u2212\u21131 . This completes the proof.\nLet P , P[T1,L] P[T1,L\u2032 ] . Substituting the results of all claims (15) into R(L \u222a L\u2032), we obtain\nR(L \u222a L\u2032) = P[T1,L \u222a T2,L] + P[T1,L\u2032 \u222a T2,L\u2032 ]\nP[E1,L \u222a E2,L] + P[E1,L\u2032 \u222a E2,L\u2032 ] (18)\n\u2264 P (1 + \u03c62\u21131\u03c61:|A|\u22122\u2212\u21131\u2212\u21132) + (1 + \u03c6 2\u21132\u03c61:|A|\u22122\u2212\u21131\u2212\u21132)\n(P + 1)(\u03c6\u22121 + \u03c61+2(\u21131+\u21132)\u03c61:|A|\u22122\u2212\u21131\u2212\u21132) (19)\nb) \u2264 1 + \u03c6\u21131+\u21132\u03c61:|A|\u22122\u2212\u21131\u2212\u21132\n(\u03c6\u22121 + \u03c62(\u21131+\u21132)\u03c62:|A|\u22121\u2212\u21131\u2212\u21132) . (20)\nHere, the inequality b) follows from Lemma B.1. By using |A| \u2264 n and letting \u2113 = \u21131 + \u21132, we obtain\nR(L \u222a L\u2032) \u2264 1 + \u03c6\u2113\u03c61:n\u2212\u2113\u22122\n\u03c6\u22121 + \u03c62\u2113\u03c62:n\u2212\u2113\u22121 ,\nwhich completes the proof of the result in Step 4.\nLemma B.2. If \u03c6+ \u03c62 < 1 + \u03c6n, for all \u2113 \u2208 N, one has\n1 + \u03c6\u2113\u03c61:n\u2212\u2113\u22122 \u03c6\u22121 + \u03c62\u2113\u03c62:n\u2212\u2113\u22121 \u2264 \u03c61:n\u22121 1 + \u03c63:n .\nProof. First, for \u2113 \u2265 1,\n\u03c6\u2113+1\n\u03c62\u2113+1:2\u2113+2 \u2212 \u03c6n+\u2113 \u2265\n1\n\u03c6+ \u03c62 \u2212 \u03c6n\u22121 > 1.\nThus,\n\u03c62:\u2113+1 \u03c63:2\u2113+2 \u2212 \u03c6n+1:n+\u2113 =\n\u2211\u2113 t=1 \u03c6 t+1\n\u2211\u2113 t=1 \u03c62t+1:2t+2 \u2212 \u2211\u2113 t=1 \u03c6\nn+t > 1.\nSince we also have \u03c61:n\u221211+\u03c63:n < 1, it follows that\n\u03c61:n\u22121 1 + \u03c63:n > \u03c61:n\u22121 \u2212 \u03c62:\u2113+1 1 + \u03c63:n \u2212 (\u03c63:2\u2113+2 \u2212 \u03c6n+1:n+\u2113) = \u03c6+ \u03c6\u2113\u03c62:n\u2212\u2113\u22121 1 + \u03c62\u2113\u03c63:n\u2212\u2113 .\nThis proves the claimed result and completes the proof of the lemma."}, {"heading": "C Proof of Lemma 4.5", "text": "Lemma 4.5 is a corollary of the following lemma.\nLemma C.1. Let \u03c3 \u223c MM(\u03c30, \u03c6). If two subsets of elements A, A \u2032 satisfy A\u2032 = A \u222a {x}, where x /\u2208 A, and if u \u2208 A, then for all t \u2208 [|A|] one has\n1) P[\u03c3A(u) \u2265 t] \u2264 P[\u03c3A\u2032(u) \u2265 t].\n2) P[\u03c3A(u) \u2264 t] \u2264 P[\u03c3A\u2032(u) \u2264 t+ 1].\nProof. Because of symmetry, it suffices to prove the first claim only. The left-hand-side of the first inequality equals the probability of the event that the element u is ranked in the t-th position or lower within the set of elements in A. The right-hand-side of the inequality equals the probability of the event that the element u is ranked in the t-th position or lower within the set of elements in A\u2032. Since A\u2032 is the union of A and another element x /\u2208 A, inserting x into a ranking may only increase the rank of already present elements.\nNow, consider Lemma 4.5 in the main text. Choose an element x \u2208 S if there is such and element that satisfies \u03c30(x) > \u03c3(u). Let A\n\u2032 = A \u222a {x}. Then, the statement of the above result implies that the probability that element u is ranked lower than or equal to its correct rank \u03c30,A(u) will increase if we add an element x to A that is ranked lower than u in \u03c30. Therefore, by removing all elements from A that are ranked lower than u in \u03c30, we obtain a new subset A\n\u2032\u2032 and consequently have P[\u03c3A(u) \u2265 \u03c30,A(u)] \u2265 P[\u03c3A\u2032\u2032(u) \u2265 \u03c30,A\u2032\u2032 (u)]. Note that u is the element with the lowest rank in \u03c30,A\u2032\u2032 . Therefore, it is easy to check that P[\u03c3A\u2032\u2032(u) = \u03c30,A\u2032\u2032(u)] \u2265\n1 \u03c60:|A\u2032\u2032|\u22121 . Then, one has the inequality P[\u03c3A(u) \u2265 \u03c30,A(u)] \u2265 1 \u03c60:|A\u2032\u2032|\u22121 ."}, {"heading": "D Proof of Lemma 4.7", "text": "For convenience, we restate Lemma 4.7 first.\nLemma D.1. Let \u03c3 \u223c GMM(\u03c30, \u03c6) and let A be a subset of elements containing an element u. Let A\u2032 = A \u2212 {x \u2208 A : x 6= u, \u03c30,A(x) \u2264 \u03c30,A(u)}. Define W = {r\u03c3A(u) \u2264 r\u03c30,A(u)}, Qj = {r\u03c3A(u) = j + r\u03c30,A(u), l\u03c3A(u) \u2264 r\u03c30,A(u)}, W \u2032 = {r\u03c3A\u2032 (u) \u2264 r\u03c30,A\u2032 (u)} and Q \u2032 j = {r\u03c3A\u2032 (u) = j + r\u03c30,A\u2032 (u), l\u03c3\u2032A(u) \u2264 r\u03c30,A\u2032 (u)}. Then, the following two claims hold.\nP[W ]+\n|A|\u2212r\u03c30,A (u) \u2211\nj=1\nVjP[Qj ]\n\u2265P[W \u2032] +\n|A\u2032|\u2212r\u03c3 0,A\u2032\n(u) \u2211\nj=1\n1\nj + 1 VjP[Q\n\u2032 j] (21)\n\u22651\u2212 1\n2 \u03c61/2 \u2212\n1 2 \u03c6. (22)\nProof. The idea behind the proof is similar to that of the proof of Lemma C.1. Our first goal is to show that removing the element x from A that is ranked highest in \u03c30,A decreases the left-hand-side of (21). Then, by induction, we may prove (21).\nFor simplicity, let A\u2032\u2032 = A\u2212{x}. Note that because of the choice of the rank of the element x in \u03c30,A, we have r\u03c30,A\u2032\u2032 (u) = r\u03c30,A(u) \u2212 1 and l\u03c30,A\u2032\u2032 (u) = l\u03c30,A(u) \u2212 1. For a ranking \u03c3 \u2208 {\u03c3 : l\u03c3A(u) \u2264 r\u03c30,A(u)}, the removal of x produces another ranking \u03c3\u2032\u2032. When r\u03c3A(x) < r\u03c3A(u), \u03c3 and \u03c3 \u2032\u2032 will contribute the same \u201cvote\u201d to the left-hand-side of (21). When r\u03c3A(x) = r\u03c3A(u), \u03c3 \u2032\u2032 contributes the same vote when \u03c3 \u2208 W , or smaller vote when \u03c3 \u2208 Qj for some j. When r\u03c3A(x) > r\u03c3A(u), \u03c3 \u2032\u2032 will always contribute a smaller vote. For a ranking \u03c3 /\u2208 {\u03c3 : l\u03c3A(u) \u2264 r\u03c30,A(u)}, both \u03c3 and \u03c3 \u2032\u2032 contribute a zero vote. Therefore, removing x from A strictly decreases the left-hand-side of (21). We now prove inequality (22). Note that due to the definition of A\u2032, we have r\u03c30,A\u2032 (y) = 1. Also, due to Lemma F.1 of this document, we can further assume that r\u03c30(y) = 1, i.e., that y is the only element in the first bucket of \u03c30. Because of its definition, W\n\u2032 includes the rankings \u03c3 such that y is the only element in the first bucket of \u03c3\u2032A while Q \u2032 j includes the rankings \u03c3 such that there are, in addition to y, some j other elements in the first bucket of \u03c3\u2032A. Partition W \u2032 according to the size of the second bucket of \u03c3\u2032A, i.e., let W \u2032 = \u222a|B2(\u03c3\u2032A)|=jW \u2032 j . Then, we can construct a bijection from W \u2032j to Q \u2032 j by putting y into the second bucket. It is easy to check that\nP[Q\u2032j] \u2264 P[W \u2032 j ]\u03c6 j/2.\nDenote the set of partial rankings \u03c3 for which the first bucket of \u03c3A does not contain y but some j other elements in U \u2032j . We can also construct a mapping from Q \u2032 j to U \u2032 j by moving y from the first bucket to any other possible position higher than the first bucket. Hence, we have\nP[U \u2032j] \u2264 P[Q \u2032 j ]\u03c6 j/2(1 + \u03c61/2 + \u03c6+ \u00b7 \u00b7 \u00b7 ) \u2264 P[Q\u2032j ] \u03c6j/2\n1\u2212 \u03c61/2 .\nLet Z \u2032j = W \u2032 j \u222aQ \u2032 j \u222a U \u2032 j , so that \u222ajZ \u2032 j covers all possible partial rankings. Hence,\nP(W \u2032j) + 1 j+1P(Q \u2032 j)\nP(Z \u2032j) =\nP(W \u2032j) + 1 j+1P(Q \u2032 j)\nP(W \u2032j) + P(Q \u2032 j) + P(U \u2032 j)\n\u2265 1 + 1j+1\u03c6 j/2\n1 + \u03c6j/2 + \u03c6 j\n1\u2212\u03c61/2\n\u2265 1 + 12\u03c6 1/2\n1 + \u03c61/2 + \u03c6 1\u2212\u03c61/2\n= 1\u2212 1\n2 \u03c61/2 \u2212\n1 2 \u03c6,\nwhere the second inequality follows from \u03c61/2 + \u03c6 < 1. This completes the proof."}, {"heading": "E Proof of the Main Results", "text": ""}, {"heading": "E.1 Proof for permutation aggregation", "text": "Let the Lehmer code of the output permutation \u03c3 be denoted by c\u0302\u03c3. We say that the LCA algorithm succeeds if \u03c3 = \u03c30, or equivalently, if c\u0302\u03c3 = c\u03c30 . Given that c\u0302\u03c3(1) = 0 = c\u03c30(1), by using the union\nbound, we arrive at\nP[\u03c3 = \u03c30] = P[c\u0302\u03c3 = c\u03c30 ] \u2265 1\u2212\nn\u22121 \u2211\nt=2\nP[c\u0302\u03c3(t) 6= c\u03c30(t)].\nIn Section 4, we explained that the algorithm based on the Lehmer code c\u0302\u03c3 may be viewed as a form of InsertionSort, in which during the t-th iteration one places the element t at the (t \u2212 c\u0302\u03c3(t))-th position over the subset of elements St = [t]. With this specific choice of subset St, for any permutation \u03c0, we have \u03c0St(t) = t\u2212 c\u03c0(t). Hence, the event {c\u0302\u03c3(t) 6= c\u03c30(t)} is equivalent to the event {\u03c3St(t) 6= \u03c30,St(t)}, which we denote by Dt. For convenience, we let i , \u03c30,St(t). Given that the ranking \u03c3k \u2208 \u03a3 is sampled from a MM(\u03c30, \u03c6) distribution, we also define a random variable Xk(j) = 1{\u03c3k,St (t)=j} to indicate whether the element t is ranked at the j-th position in \u03c3k,St . Therefore, \u2211\nk\u2208[m] Xk(j) equals the number of rankings in \u03a3 in which element t is ranked at the j-th position."}, {"heading": "E.1.1 Proof of Theorem 4.1 (Mode)", "text": "Given that we aggregate using the mode function, we have \u03c3St(t) = argmaxj\u2208[t] \u2211 k\u2208[m] Xk(j). In what follows, we aim to prove an upper bound on P[\u03c3St(t) 6= \u03c30,St(t)] = P[D(t)].\nTo this end, let q = \u03c61:n\u221211+\u03c63:n , so that when \u03c6 + \u03c6 2 < 1 + \u03c6n, we have q < 1. Based on Lemma 4.3 in\nthe main text, we have\nP[Xk(i) = 1] = P[Xk(i) = 1]\n\u2211t j=1 P[Xk(j) = 1]\n= P[\u03c3k,St(t) = i]\n\u2211t j=1 P[\u03c3k,St(t) = j]\n\u2265 1\n1 + 2q/(1\u2212 q) =\n1\u2212 q 1 + q .\nMoreover, if E = E[Xk(i)\u2212Xk(j)], then\nE \u2265 P[Xk(i) = 1](1 \u2212 q |i\u2212j|) \u2265\n(1 \u2212 q)2\n1 + q .\nTherefore, since the \u03c3k, k \u2208 [m], are i.i.d, Hoeffding\u2019s inequality establishes\nP[ \u2211\nk\u2208[m]\nXk(i) < \u2211\nk\u2208[m]\nXk(j)] = P[ \u2211\nk\u2208[m]\n(Xk(i)\u2212Xk(j)) \u2264 0] \u2264 exp(\u2212 mE2\n2 ) \u2264 exp(\u2212\nm(1\u2212 q)4 2(1 + q)2 ).\nHence,\nP[Dt] \u2264 \u2211\nj\u2208[t],j 6=i\nP\n\n\n\u2211\nk\u2208[m]\nXk(i) < \u2211\nk\u2208[m]\nXk(j)\n  < (t\u2212 1) exp(\u2212 m(1\u2212 q)4\n2(1 + q)2 ).\nAs a result, for m \u2265 c log n 2 2\u03b4 with c = 2(1+q)2 (1\u2212q)4 and q = \u03c61:n\u22121 1+\u03c63:n , we have P[\u03c3 = \u03c30] > 1\u2212 \u03b4."}, {"heading": "E.1.2 Proof of Theorem 4.3 (Median)", "text": "Let Yk(j0) = \u2211j0 j=1 Xk(j). Since we use the median to form the aggregate, we need to establish that \u03c3St(t) = min{j : 1 m \u2211 k\u2208[m] Yk(j) \u2265 0.5}. According to Lemma 4.5 of the main text, we have P[Yk(i) = 1] = 1 \u2212 P[\u03c3k,A(x) > i] \u2265 1 \u2212 \u03c6 while P[Yk(i\u2212 1) = 1] = P[\u03c3k,A(x) < i] \u2264 \u03c6. Therefore, if \u03c6 < 0.5, using Hoeffding\u2019s inequality, we have\nP[Dt] \u2264 P\n\n\n1\nm\n\u2211\nk\u2208[m]\nYk(i) < 0.5\n\n + P\n\n\n1\nm\n\u2211\nk\u2208[m]\nYk(i \u2212 1) > 0.5\n\n \u2264 2e\u22122m( 1 2\u2212\u03c6) 2 .\nAs a result, for m \u2265 c log 2n\u03b4 with c = 2 (1\u22122\u03c6)2 , we have P[\u03c3 = \u03c30] > 1\u2212 2ne \u22122m(12\u2212\u03c6) 2 \u2265 1\u2212 \u03b4."}, {"heading": "E.2 Proof of the Performance Guarantees for Partial Ranking Aggregation", "text": "Denote the Lehmer code of the output permutation \u03c3 of Algorithm 2 of the main text by c\u0302\u03c3. We say that the LCA algorithm succeeds if \u03c3 is in \u03a30, which is equivalent to saying that c\u0302\u03c3(t) \u2208 [c\u03c3(t), c \u2032 \u03c3(t)]. Given that c\u0302\u03c3(1) = 0 = c\u03c30(1) = c \u2032 \u03c3(1), from the union bound, we have\nP[\u03c3 \u2208 \u03a30] = P[c\u0302\u03c3(t) \u2208 [c\u03c3(t), c \u2032 \u03c3(t)], \u2200t] \u2265 1\u2212\nn\u22121 \u2211\nt=2\nP[c\u0302\u03c3(t) 6\u2208 [c\u03c3(t), c \u2032 \u03c3(t)]].\nIn Section 4 of the main text, we explained how the Lehmer code transform c\u0302\u03c3 may be viewed as a form of InsertionSort, which in the t-th iteration places the element t at the (t\u2212 c\u0302\u03c3(t))th position within the subset of elements St = [t]. With this choice of subset St, for any \u03c0, we have that \u03c0St(t) = t \u2212 c\u03c0(t). Hence, the event {c\u0302\u03c3(t) 6\u2208 [c\u03c3(t), c\n\u2032 \u03c3(t)]} is equivalent to the event {\u03c3St(t) < l\u03c30,St (t) or \u03c3St(t) > r\u03c30,St (t)},\nwhich we denote by Dt. The proof reduces to finding a lower bound on P[Dt]. For convenience, we let l , l\u03c30,St (t) and r , r\u03c30,St (t). Given that the ranking \u03c3k \u2208 \u03a3 is sampled from a GMM(\u03c30, \u03c6), we define the random variable Xk(j) as the vote that \u03c3k cast for t to be at position j in St. Then, V (j) = \u2211\nk\u2208[m] Xk(j) is the total vote cast by all partial rankings in \u03a3 to rank t at the j-th position."}, {"heading": "E.2.1 Proof of Theorem 4.6 (Median)", "text": "Let Yk(j0) = \u2211j0\nj=1 Xk(j). Since we use the median to form the aggregate, we have \u03c3St(t) = min{j : 1 m \u2211 k\u2208[m] Yk(j) \u2265 0.5}. Define the event W = {r\u03c3k,St (t) \u2264 r}. When W occurs, \u03c3k contributes 1 to Yk(r). Let Q = \u222a n\u2212r j=1Qj, where Qj = {r\u03c3k,St (t) = j + r, l\u03c3k,St(u) \u2264 r}. When Qj occurs, \u03c3k contributes a fractional vote Vj to Yk(r), where Vj = r\u2212l\u03c3k,St (t) +1\nr\u03c3k,St (t) \u2212l\u03c3k,St (t)\n+1 \u2265 V \u2032 j = 1 j+1 . In fact, Vj = V \u2032 j when\nl\u03c3k,St(t) = r. Therefore, based on the Lemma 4.7 of the main text, we have\nE[Yk(r)] \u2265 P[W ] +\nt\u2212r \u2211\nj=1\n1\nj + 1 P[Qj ] (23)\n\u2265 1\u2212 1\n2 \u03c61/2 \u2212\n1 2 \u03c6. (24)\nLet q\u2032 = 1 \u2212 12\u03c6 1/2 \u2212 12\u03c6. When \u03c6 1/2 + \u03c6 < 1, it follows that q\u2032 > 0.5. By using Hoeffding\u2019s inequality, we obtain\nP\n\n\n1\nm\n\u2211\nk\u2208[m]\nYk(r) < 0.5\n\n \u2264 exp(\u22122m(1/2\u2212 q\u2032)2).\nLet Zk(j0) = \u2211t\nj=j0 Xk(j). In an analogous manner, we can prove that\nP\n\n\n1\nm\n\u2211\nk\u2208[m]\nZk(l) < 0.5\n\n \u2264 exp(\u22122m(1/2\u2212 q\u2032)2).\nTherefore, the probability of success of iteration t may be bounded as\nP[Dt] \u2264P\n[\n1\nm\nm \u2211\nk=1\nYk(r) < 0.5\n]\n+ P\n[\n1\nm\nm \u2211\nk=1\nZk(l) < 0.5\n]\n\u2264 2e\u22122m(1/2\u2212q \u2032)2 .\nAs a result, when m \u2265 c log 2n\u03b4 with c = 2 (1\u22122q\u2032)2 , where q \u2032 = 1\u2212 12\u03c6 1/2 \u2212 12\u03c6, we have P[\u03c3 \u2208 \u03a30] > 1\u2212 \u03b4."}, {"heading": "F Other Lemmas and Proofs", "text": "Lemma F.1. Let \u03c30 be a ranking over S and let A \u2286 S be such that A contains the elements ranked highest in \u03c30. Consider a ranking \u03c3 \u223cMM(\u03c30, \u03c6). Then, the marginal distribution of \u03c3 over S/A is the distribution MM(\u03c30,S/A, \u03c6).\nProof. It suffices to prove the result for A = {x}, where x is the element ranked highest in \u03c30, as this result may be applied inductively. Consider all permutations \u03c3 such that for \u03c3S/{x} = \u03c0 and some j \u2208 [|S|], one has\n\u03c3\u22121(t) =\n\n\n \u03c0\u22121(t), 1 \u2264 t < j, \u03c0\u22121(t\u2212 1), j < t \u2264 |S|, x, t = j.\nFor simplicity of notation, we use \u03c3(j) to denote a permutation with the above property. Then,\nP[\u03c3S/{x} = \u03c3 \u2032] =\n|S| \u2211\nj=1\nP[\u03c3(j)] = 1\nZ|S|\n|S| \u2211\nj=1\n\u03c6d\u03c4 (\u03c3 (j) ,\u03c30) =\n1\nZ|S|\n|S| \u2211\nj=1\n\u03c6j\u22121+d\u03c4 (\u03c3 (j) S/{x} ,\u03c30,S/{x})\n=\n\u2211|S| j=1 \u03c6 j\u22121\nZ|S| \u03c6d\u03c4 (\u03c0,\u03c30,S/{x}) =\n1\nZ|S/{x}| \u03c6d\u03c4 (\u03c0,\u03c30,S/{x}),\nwhere Zn = \u220fn\u22121\ni=1 \u2211i j=0 \u03c6 j denotes the normalization constant in the Mallows distribution of permutations with n elements.\nObserve that the same result holds when A is assumed to contain the lowest ranked element in \u03c30."}, {"heading": "G Supplementary Algorithms", "text": ""}, {"heading": "G.1 Efficient Algorithms for Computing the Mode/Median for Partial Ranking Aggregation", "text": "In Section 3 of the main text which discusses partial ranking aggregation, we pointed out that one can efficiently compute the voting function Vx(y), and hence the mode/median c\u0302 as well. Algorithm VII.1 of this text explains how to efficiently compute Vx(y), provided that for fixed k, x, vk\u2192x(y) is positive over a continuous interval, or more precisely, when [x \u2212 c\u03c3k(x), x\u2212 c\u03c3\u2032k(x)]. Algorithm VII.1 has complexity O(m+x) and the computation of the mode/median of the component c\u0302(x) requires O(x) time. Therefore, the total complexity of Algorithm 2 of the main text for partial rankings equals O(mn+ n2).\nAlgorithm VII.1: Computing {Vx(y)}y\u2208[x] when vk\u2192x(y) is positive over [x\u2212 c\u03c3k(x), x\u2212 c\u03c3\u2032k(x)] Input: c\u03c3k , c \u2032 \u03c3k , votes vk\u2192x(y) = vk\u2192x1x\u2212c\u2032\u03c3k\u2264y\u2264x\u2212c\u03c3k , \u2200 k \u2208 [m];\n1: Initialize Vx(y) = 0, for all y \u2208 [x+ 1]; 2: For k from 1 to m do 3: Vx(x\u2212 c\n\u2032 \u03c3k (x)) = Vx(x\u2212 c \u2032 \u03c3k (x)) + vk\u2192x;\n4: Vx(x+ 1\u2212 c\u03c3k(x)) = Vx(x+ 1\u2212 c\u03c3k(x)) \u2212 vk\u2192x; 5: For k from 2 to x+ 1 do 6: Vx(y) = Vx(y \u2212 1) + Vx(y); 7: Output: Vx(y);"}, {"heading": "G.2 A Kemeny-Distance Optimal Algorithm for Transforming Permutations into Partial Rankings", "text": "In Section 3 of the main text pertaining to partial ranking aggregation, we pointed out that one can optimally transform the permutation output of Algorithm 2 into a partial ranking. Algorithm VII.2 of this text explains how to perform this transform. In the description of the algorithm, we used a : b = (a, a+1, ..., b) where a, b \u2208 Z, b \u2265 a. For a vector V , we used V (a : b) to denote (V (a), V (a+1), ..., V (b)). Algorithm VII.2 has complexity O(mn2 + n3).\nAlgorithm VII.2: Transforms a Permutation into a Partial Ranking that is Kemeny-Distance Optimal Input: Permutation \u03c3, Set of partial rankings \u03a3; 1: Initialize BucketSize= (1, 1, ..., 1) \u2208 Nn; 2: Initialize W = {wij}i,j\u2208[n] where wij = 1 m \u2211 k\u2208[m] 1\u03c3k(\u03c3\u22121(i))<\u03c3k(\u03c3\u22121(j));\n3: [Val, BucketSize]=Dynamic-Programming(W , BucketSize); 4: Construct a partial ranking \u03c3\u2032 by putting the lowest BucketSize(1) many elements of \u03c3 into B1(\u03c3\n\u2032); Proceed by taking BucketSize(2) many elements of \u03c3 and placing them into B2(\u03c3\n\u2032) and so on; 5: Output: \u03c3\u2032. Dynamic-Programming(W , BucketSize) 1: n\u2032 =length(BucketSize); 2: If n\u2032 = 1 return [0, BucketSize]; 3: s = \u230an\u2032/2\u230b; When \u03c3\u22121(s) and \u03c3\u22121(s+ 1) are in different buckets (4-6) 4: [Val1, BucketSize1]=Dynamic-Programming(W (1 : s, 1 : s), BucketSize(1 : s)); 5: [Val2, BucketSize2]=Dynamic-Programming(W (s+ 1 : n\u2032, s+ 1 : n\u2032), BucketSize(s+ 1 : n));\n6: Val-div=Val1+Val2+ \u2211n\u2032\ni=s+1 \u2211s j=1 wij + 1 2\n\u2211n\u2032\ni=s+1 \u2211s j=1(BucketSize(i) \u2217 BucketSize(j)\u2212 wji \u2212 wij).\nWhen \u03c3\u22121(s) and \u03c3\u22121(s+ 1) are in the same bucket (7-13) 7: wsi = wsi + w(s+1)i, for all i \u2208 [n\n\u2032]; 8: wis = wis + wi(s+1), for all i \u2208 [n\n\u2032]; 9: Val3=1/2 \u2217 wss ; 10: Construct W \u2032 \u2208 Rn \u2032\u22121\u00d7n\u2032\u22121 by deleting the s+ 1th row and s+ 1th column of W ; 11: Construct newBucketSize: newBucketSize(i)=BucketSize(i) for 1 \u2264 i \u2264 s; newBucketSize(i)=BucketSize(i+ 1) for s+ 1 \u2264 i \u2264 n\u2032 \u2212 1; newBucketSize(s)=BucketSize(s)+BucketSize(s+ 1); 12: [Val4, BucketSize3]=Dynamic-Programming(W \u2032, newBucketSize); 13: Val-con= Val3+Val4; 14: if Val-con>Val-div,\nConstruct BucketSize4 via concatenation of BucketSize1 and BucketSize2; return [Val-div, BucketSize4];\n15: else return [Val-con, BucketSize3];"}], "references": [{"title": "Learning to rank using gradient descent", "author": ["Chris Burges", "Tal Shaked", "Erin Renshaw", "Ari Lazier", "Matt Deeds", "Nicole Hamilton", "Greg Hullender"], "venue": "Proceedings of the 22nd international conference on Machine learning. ACM, 2005, pp. 89\u201396.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2005}, {"title": "Learning to rank for information retrieval", "author": ["Tie-Yan Liu"], "venue": "Foundations and Trends in Information Retrieval, vol. 3, no. 3, pp. 225\u2013331, 2009.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2009}, {"title": "Hydra: gene prioritization via hybrid distancescore rank aggregation", "author": ["Minji Kim", "Farzad Farnoud", "Olgica Milenkovic"], "venue": "Bioinformatics, p. btu766, 2014.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Iterative ranking from pair-wise comparisons", "author": ["Sahand Negahban", "Sewoong Oh", "Devavrat Shah"], "venue": "Advances in Neural Information Processing Systems, 2012, pp. 2474\u20132482.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Pairwise ranking aggregation in a crowdsourced setting", "author": ["Xi Chen", "Paul N Bennett", "Kevyn Collins-Thompson", "Eric Horvitz"], "venue": "Proceedings of the sixth ACM international conference on Web search and data mining. ACM, 2013, pp. 193\u2013202.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Mathematics without numbers", "author": ["John G Kemeny"], "venue": "Daedalus, vol. 88, no. 4, pp. 577\u2013591, 1959.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1959}, {"title": "A computational study of the kemeny rule for preference aggregation", "author": ["Andrew Davenport", "Jayant Kalagnanam"], "venue": "AAAI, 2004, vol. 4, pp. 697\u2013702.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2004}, {"title": "Rank aggregation revisited", "author": ["Cynthia Dwork", "Ravi Kumar", "Moni Naor", "D Sivakumar"], "venue": "2001.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2001}, {"title": "Aggregating inconsistent information: ranking and clustering", "author": ["Nir Ailon", "Moses Charikar", "Alantha Newman"], "venue": "Journal of the ACM (JACM), vol. 55, no. 5, pp. 23, 2008.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2008}, {"title": "Spearman\u2019s footrule as a measure of disarray", "author": ["Persi Diaconis", "Ronald L Graham"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological), pp. 262\u2013268, 1977.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1977}, {"title": "How to rank with few errors", "author": ["Claire Kenyon-Mathieu", "Warren Schudy"], "venue": "Proceedings of the thirty-ninth annual ACM symposium on Theory of computing. ACM, 2007, pp. 95\u2013103.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "Probability models and statistical analyses for ranking data, vol", "author": ["Michael A Fligner", "Joseph S Verducci"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1993}, {"title": "Efficient bayesian inference for generalized bradley\u2013terry models", "author": ["Francois Caron", "Arnaud Doucet"], "venue": "Journal of Computational and Graphical Statistics, vol. 21, no. 1, pp. 174\u2013196, 2012.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning mallows models with pairwise preferences", "author": ["Tyler Lu", "Craig Boutilier"], "venue": "Proceedings of the 28th International Conference on Machine Learning (ICML-11), 2011, pp. 145\u2013152.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Cranking: Combining rankings using conditional probability models on permutations", "author": ["Guy Lebanon", "John Lafferty"], "venue": "ICML. Citeseer, 2002, vol. 2, pp. 363\u2013370.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2002}, {"title": "Comparing and aggregating rankings with ties", "author": ["Ronald Fagin", "Ravi Kumar", "Mohammad Mahdian", "D Sivakumar", "Erik Vee"], "venue": "Proceedings of the twenty-third ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems. ACM, 2004, pp. 47\u201358.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2004}, {"title": "Enumerative combinatorics, Number 49", "author": ["Richard P Stanley"], "venue": "Cambridge university press,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "Linear-time ranking of permutations", "author": ["Martin Mare\u0161", "Milan Straka"], "venue": "Algorithms\u2013ESA 2007, pp. 187\u2013193. Springer, 2007.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2007}, {"title": "Ranking and unranking permutations in linear time", "author": ["Wendy Myrvold", "Frank Ruskey"], "venue": "Information Processing Letters, vol. 79, no. 6, pp. 281\u2013284, 2001.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2001}, {"title": "Lehmer code transforms and mahonian statistics on permutations", "author": ["Vincent Vajnovszki"], "venue": "Discrete Mathematics, vol. 313, no. 5, pp. 581\u2013589, 2013.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2013}, {"title": "Ordering by weighted number of wins gives a good ranking for weighted tournaments", "author": ["Don Coppersmith", "Lisa Fleischer", "Atri Rudra"], "venue": "Proceedings of the seventeenth annual ACM-SIAM symposium on Discrete algorithm. Society for Industrial and Applied Mathematics, 2006, pp. 776\u2013 782. 11", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2006}, {"title": "Rank aggregation methods for the web", "author": ["Cynthia Dwork", "Ravi Kumar", "Moni Naor", "Dandapani Sivakumar"], "venue": "Proceedings of the 10th international conference on World Wide Web. ACM, 2001, pp. 613\u2013622.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2001}, {"title": "Efficient large-scale graph analysis in mapreduce", "author": ["Karthik Kambatla", "Georgios Kollias", "Ananth Grama"], "venue": "2012.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Nantonac collaborative filtering: recommendation based on order responses", "author": ["Toshihiro Kamishima"], "venue": "Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2003, pp. 583\u2013588.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2003}, {"title": "Eigentaste: A constant time collaborative filtering algorithm", "author": ["Ken Goldberg", "Theresa Roeder", "Dhruv Gupta", "Chris Perkins"], "venue": "Information Retrieval, vol. 4, no. 2, pp. 133\u2013151, 2001.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2001}, {"title": "The movielens datasets: History and context", "author": ["F Maxwell Harper", "Joseph A Konstan"], "venue": "ACM Transactions on Interactive Intelligent Systems (TiiS), vol. 5, no. 4, pp. 19, 2016.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "Rank aggregation is a family of problems concerned with fusing disparate ranking information, and it arises in application areas as diverse as social choice, meta-search, natural language processing, bioinformatics, and information retrieval [1, 2, 3].", "startOffset": 242, "endOffset": 251}, {"referenceID": 1, "context": "Rank aggregation is a family of problems concerned with fusing disparate ranking information, and it arises in application areas as diverse as social choice, meta-search, natural language processing, bioinformatics, and information retrieval [1, 2, 3].", "startOffset": 242, "endOffset": 251}, {"referenceID": 2, "context": "Rank aggregation is a family of problems concerned with fusing disparate ranking information, and it arises in application areas as diverse as social choice, meta-search, natural language processing, bioinformatics, and information retrieval [1, 2, 3].", "startOffset": 242, "endOffset": 251}, {"referenceID": 3, "context": "Sometimes, rankings are assumed to be of the form of a set of pairwise comparisons [4, 5].", "startOffset": 83, "endOffset": 89}, {"referenceID": 4, "context": "Sometimes, rankings are assumed to be of the form of a set of pairwise comparisons [4, 5].", "startOffset": 83, "endOffset": 89}, {"referenceID": 5, "context": "For the case of partial rankings, the distance of choice is the Kemeny distance [6].", "startOffset": 80, "endOffset": 83}, {"referenceID": 6, "context": "It is well known that for a wide range of distance functions, learning the underlying models and aggregating rankings is computationally hard [7].", "startOffset": 142, "endOffset": 145}, {"referenceID": 7, "context": "Nevertheless, for the case when the distance measure is the Kendall \u03c4 distance, a number of approximation algorithms have been developed that offer various trade-offs between quality of aggregation and computational complexity [8, 9].", "startOffset": 227, "endOffset": 233}, {"referenceID": 8, "context": "Nevertheless, for the case when the distance measure is the Kendall \u03c4 distance, a number of approximation algorithms have been developed that offer various trade-offs between quality of aggregation and computational complexity [8, 9].", "startOffset": 227, "endOffset": 233}, {"referenceID": 9, "context": "The techniques used for aggregating permutations in a given set include randomly choosing a permutation from the set (PICK-A-PERM), pivoting via random selections of elements and divide-and-conquer approaches (FAS-PIVOT), Markov chain methods akin to PageRank, and minimum weight graph matching methods exploiting the fact that the Kendall \u03c4 distance is well-approximated by the Spearman footrule distance (SM) [10].", "startOffset": 411, "endOffset": 415}, {"referenceID": 8, "context": "Methods with provable performance guarantees \u2013 PICK-A-PERM, FAS-PIVOT, and SM \u2013 give a 2-approximation for the objective function, although combinations thereof are known to improve the constant to 11/7 or 4/3 [9].", "startOffset": 210, "endOffset": 213}, {"referenceID": 10, "context": "There also exists a polynomial time approximation scheme (PTAS) for the aggregation problem [11].", "startOffset": 92, "endOffset": 96}, {"referenceID": 11, "context": "In many cases, a performance analysis on probabilistic models [12] such as the Plackett-Luce model [13] or the Mallows model [14, 15], is intractable.", "startOffset": 62, "endOffset": 66}, {"referenceID": 12, "context": "In many cases, a performance analysis on probabilistic models [12] such as the Plackett-Luce model [13] or the Mallows model [14, 15], is intractable.", "startOffset": 99, "endOffset": 103}, {"referenceID": 13, "context": "In many cases, a performance analysis on probabilistic models [12] such as the Plackett-Luce model [13] or the Mallows model [14, 15], is intractable.", "startOffset": 125, "endOffset": 133}, {"referenceID": 14, "context": "In many cases, a performance analysis on probabilistic models [12] such as the Plackett-Luce model [13] or the Mallows model [14, 15], is intractable.", "startOffset": 125, "endOffset": 133}, {"referenceID": 15, "context": "Partial rankings may be used to complete rankings of subsets of element in [n] in a number of different ways [16], one being to tie all unranked elements at the last position.", "startOffset": 109, "endOffset": 113}, {"referenceID": 15, "context": "We use a similar set of definitions for partial rankings [16].", "startOffset": 57, "endOffset": 61}, {"referenceID": 15, "context": "A partial ranking is often represented using buckets, and is in this context referred to as a bucket order [16].", "startOffset": 107, "endOffset": 111}, {"referenceID": 9, "context": "A number of distance functions between permutations are known from the social choice, learning and discrete mathematics literature [10].", "startOffset": 131, "endOffset": 135}, {"referenceID": 16, "context": ", any permutation \u03c0 \u2208 Sn can be converted into another permutation \u03c3 \u2208 Sn through a sequence of transpositions (adjacent transpositions) [17].", "startOffset": 137, "endOffset": 141}, {"referenceID": 9, "context": "A well known result by Diaconis and Graham [10] asserts that d\u03c4 (\u03c0, \u03c3) \u2264 dS(\u03c0, \u03c3) \u2264 2d\u03c4 (\u03c0, \u03c3).", "startOffset": 43, "endOffset": 47}, {"referenceID": 15, "context": "(2) The Kemeny distance includes a component equal to the Kendal \u03c4 distance between the linear chains in the partial rankings, and another, scaled component that characterizes the distance of tied pairs of elements [16].", "startOffset": 215, "endOffset": 219}, {"referenceID": 15, "context": "The Spearman footrule distance may also be defined to apply to partial rankings [16], and it equals the sum of the absolute differences between \u201cpositions\u201d of elements in the partial rankings.", "startOffset": 80, "endOffset": 84}, {"referenceID": 15, "context": "The above defined Spearman distance is a 2-approximation for the Kemeny distance between two partial rankings [16].", "startOffset": 110, "endOffset": 114}, {"referenceID": 0, "context": "a word of the form c\u03c3 \u2208 Cn , {0} \u00d7 [0, 1]\u00d7 [0, 2]\u00d7 \u00b7 \u00b7 \u00b7 \u00d7 [0, n\u2212 1], where for i = 1, .", "startOffset": 35, "endOffset": 41}, {"referenceID": 1, "context": "a word of the form c\u03c3 \u2208 Cn , {0} \u00d7 [0, 1]\u00d7 [0, 2]\u00d7 \u00b7 \u00b7 \u00b7 \u00d7 [0, n\u2212 1], where for i = 1, .", "startOffset": 43, "endOffset": 49}, {"referenceID": 17, "context": "e 1 2 3 4 5 6 7 8 9 \u03c3 2 1 4 5 7 3 6 9 8 c\u03c3 0 1 0 0 0 3 1 0 1 It is well known that the Lehmer code is bijective, and that the encoding and decoding algorithms have linear complexity (n) [18, 19].", "startOffset": 186, "endOffset": 194}, {"referenceID": 18, "context": "e 1 2 3 4 5 6 7 8 9 \u03c3 2 1 4 5 7 3 6 9 8 c\u03c3 0 1 0 0 0 3 1 0 1 It is well known that the Lehmer code is bijective, and that the encoding and decoding algorithms have linear complexity (n) [18, 19].", "startOffset": 186, "endOffset": 194}, {"referenceID": 19, "context": "An overview of such codes and their relationship to Mahonian statistics on permutations may be found in [20].", "startOffset": 104, "endOffset": 108}, {"referenceID": 17, "context": "If no parallelization is used, the first step requires O(mn) time, given that the Lehmer codes may be computed in O(n) time [18, 19].", "startOffset": 124, "endOffset": 132}, {"referenceID": 18, "context": "If no parallelization is used, the first step requires O(mn) time, given that the Lehmer codes may be computed in O(n) time [18, 19].", "startOffset": 124, "endOffset": 132}, {"referenceID": 0, "context": "For permutations, the aggregation procedure may be viewed as specialized voting: The ranking \u03c3k casts a vote to rank x at position x\u2212 c\u03c3k(x), for the case that only elements \u2264 x are considered (A vote corresponds to some score confined to [0, 1]).", "startOffset": 239, "endOffset": 245}, {"referenceID": 20, "context": "One example of a positional method is Borda\u2019s algorithm, which is known to produce a 5-approximation to the Kemeny-Young problem for permutations [21].", "startOffset": 146, "endOffset": 150}, {"referenceID": 21, "context": "It also offers significant reductions in computational time compared to the Spearman footrule method, which reduces to solving a weighted bipartite matching problem and hence has complexity at least O(mn + n) [22], or O(mn) when implemented in MapReduce [23].", "startOffset": 209, "endOffset": 213}, {"referenceID": 22, "context": "It also offers significant reductions in computational time compared to the Spearman footrule method, which reduces to solving a weighted bipartite matching problem and hence has complexity at least O(mn + n) [22], or O(mn) when implemented in MapReduce [23].", "startOffset": 254, "endOffset": 258}, {"referenceID": 7, "context": "A related type of aggregation is based on InsertionSort [8, 22].", "startOffset": 56, "endOffset": 63}, {"referenceID": 21, "context": "A related type of aggregation is based on InsertionSort [8, 22].", "startOffset": 56, "endOffset": 63}, {"referenceID": 7, "context": "The authors of [8] proposed setting \u03c3St(t) to", "startOffset": 15, "endOffset": 18}, {"referenceID": 8, "context": "For comparative analysis, we choose the Fas-Pivot and FasLP-Pivot (LP) methods [9], InsertionSort with Comparison (InsertionComp) from [8], and the optimal Spearman Footrule distance aggregator (Spearman) [10].", "startOffset": 79, "endOffset": 82}, {"referenceID": 7, "context": "For comparative analysis, we choose the Fas-Pivot and FasLP-Pivot (LP) methods [9], InsertionSort with Comparison (InsertionComp) from [8], and the optimal Spearman Footrule distance aggregator (Spearman) [10].", "startOffset": 135, "endOffset": 138}, {"referenceID": 9, "context": "For comparative analysis, we choose the Fas-Pivot and FasLP-Pivot (LP) methods [9], InsertionSort with Comparison (InsertionComp) from [8], and the optimal Spearman Footrule distance aggregator (Spearman) [10].", "startOffset": 205, "endOffset": 209}, {"referenceID": 8, "context": "For Fas-Pivot and FasLP-Pivot, we chose the better result of Pick-A-Perm and the given method, as suggested in [9].", "startOffset": 111, "endOffset": 114}, {"referenceID": 0, "context": "The variance parameter was chosen according to \u03c6 = e, where \u03bb is allowed to vary in [0, 1].", "startOffset": 84, "endOffset": 90}, {"referenceID": 23, "context": "To test the permutation LCA aggregation algorithms, we used the Sushi ranking dataset [24] and the Jester dataset [25].", "startOffset": 86, "endOffset": 90}, {"referenceID": 24, "context": "To test the permutation LCA aggregation algorithms, we used the Sushi ranking dataset [24] and the Jester dataset [25].", "startOffset": 114, "endOffset": 118}, {"referenceID": 24, "context": "To test our partial ranking aggregation algorithms, we used the complete Jester dataset [25] and the Movielens dataset [26].", "startOffset": 88, "endOffset": 92}, {"referenceID": 25, "context": "To test our partial ranking aggregation algorithms, we used the complete Jester dataset [25] and the Movielens dataset [26].", "startOffset": 119, "endOffset": 123}, {"referenceID": 4, "context": "The scores are integers in [5], so that many ties are present.", "startOffset": 27, "endOffset": 30}, {"referenceID": 0, "context": "[1] Chris Burges, Tal Shaked, Erin Renshaw, Ari Lazier, Matt Deeds, Nicole Hamilton, and Greg Hullender, \u201cLearning to rank using gradient descent,\u201d in Proceedings of the 22nd international conference on Machine learning.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] Tie-Yan Liu, \u201cLearning to rank for information retrieval,\u201d Foundations and Trends in Information Retrieval, vol.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] Minji Kim, Farzad Farnoud, and Olgica Milenkovic, \u201cHydra: gene prioritization via hybrid distancescore rank aggregation,\u201d Bioinformatics, p.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] Sahand Negahban, Sewoong Oh, and Devavrat Shah, \u201cIterative ranking from pair-wise comparisons,\u201d in Advances in Neural Information Processing Systems, 2012, pp.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] Xi Chen, Paul N Bennett, Kevyn Collins-Thompson, and Eric Horvitz, \u201cPairwise ranking aggregation in a crowdsourced setting,\u201d in Proceedings of the sixth ACM international conference on Web search and data mining.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] John G Kemeny, \u201cMathematics without numbers,\u201d Daedalus, vol.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] Andrew Davenport and Jayant Kalagnanam, \u201cA computational study of the kemeny rule for preference aggregation,\u201d in AAAI, 2004, vol.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] Cynthia Dwork, Ravi Kumar, Moni Naor, and D Sivakumar, \u201cRank aggregation revisited,\u201d 2001.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] Nir Ailon, Moses Charikar, and Alantha Newman, \u201cAggregating inconsistent information: ranking and clustering,\u201d Journal of the ACM (JACM), vol.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] Persi Diaconis and Ronald L Graham, \u201cSpearman\u2019s footrule as a measure of disarray,\u201d Journal of the Royal Statistical Society.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] Claire Kenyon-Mathieu and Warren Schudy, \u201cHow to rank with few errors,\u201d in Proceedings of the thirty-ninth annual ACM symposium on Theory of computing.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] Michael A Fligner and Joseph S Verducci, Probability models and statistical analyses for ranking data, vol.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] Francois Caron and Arnaud Doucet, \u201cEfficient bayesian inference for generalized bradley\u2013terry models,\u201d Journal of Computational and Graphical Statistics, vol.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] Tyler Lu and Craig Boutilier, \u201cLearning mallows models with pairwise preferences,\u201d in Proceedings of the 28th International Conference on Machine Learning (ICML-11), 2011, pp.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15] Guy Lebanon and John Lafferty, \u201cCranking: Combining rankings using conditional probability models on permutations,\u201d in ICML.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] Ronald Fagin, Ravi Kumar, Mohammad Mahdian, D Sivakumar, and Erik Vee, \u201cComparing and aggregating rankings with ties,\u201d in Proceedings of the twenty-third ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] Richard P Stanley, Enumerative combinatorics, Number 49.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] Martin Mare\u0161 and Milan Straka, \u201cLinear-time ranking of permutations,\u201d in Algorithms\u2013ESA 2007, pp.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19] Wendy Myrvold and Frank Ruskey, \u201cRanking and unranking permutations in linear time,\u201d Information Processing Letters, vol.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] Vincent Vajnovszki, \u201cLehmer code transforms and mahonian statistics on permutations,\u201d Discrete Mathematics, vol.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[21] Don Coppersmith, Lisa Fleischer, and Atri Rudra, \u201cOrdering by weighted number of wins gives a good ranking for weighted tournaments,\u201d in Proceedings of the seventeenth annual ACM-SIAM symposium on Discrete algorithm.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[22] Cynthia Dwork, Ravi Kumar, Moni Naor, and Dandapani Sivakumar, \u201cRank aggregation methods for the web,\u201d in Proceedings of the 10th international conference on World Wide Web.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[23] Karthik Kambatla, Georgios Kollias, and Ananth Grama, \u201cEfficient large-scale graph analysis in mapreduce,\u201d 2012.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] Toshihiro Kamishima, \u201cNantonac collaborative filtering: recommendation based on order responses,\u201d in Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[25] Ken Goldberg, Theresa Roeder, Dhruv Gupta, and Chris Perkins, \u201cEigentaste: A constant time collaborative filtering algorithm,\u201d Information Retrieval, vol.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[26] F Maxwell Harper and Joseph A Konstan, \u201cThe movielens datasets: History and context,\u201d ACM Transactions on Interactive Intelligent Systems (TiiS), vol.", "startOffset": 0, "endOffset": 4}], "year": 2017, "abstractText": "We propose a novel rank aggregation method based on converting permutations into their corresponding Lehmer codes or other subdiagonal images. Lehmer codes, also known as inversion vectors, are vector representations of permutations in which each coordinate can take values not restricted by the values of other coordinates. This transformation allows for decoupling of the coordinates and for performing aggregation via simple scalar median or mode computations. We present simulation results illustrating the performance of this completely parallelizable approach and analytically prove that both the mode and median aggregation procedure recover the correct centroid aggregate with small sample complexity when the permutations are drawn according to the well-known Mallows models. The proposed Lehmer code approach may also be used on partial rankings, with similar performance guarantees.", "creator": "LaTeX with hyperref package"}}}