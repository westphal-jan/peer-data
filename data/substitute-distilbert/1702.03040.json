{"id": "1702.03040", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Feb-2017", "title": "Following the Leader and Fast Rates in Linear Prediction: Curved Constraint Sets and Other Regularities", "abstract": "the follow the loop ( ftl ) algorithm, perhaps amongst simplest of rigorous online learning algorithms, is known to perform well? random loss functions it is used on are convex and positively curved. in this paper we ask whether there are other \" lucky \" reductions when ftl achieves sublinear, \" small \" regret. in this, we solve the fundamental problem of linear prediction over a non - empty convex, compact domain. amongst other results, we result that the curvature of the boundary versus the domain can act as if the losses were mutual : in this case, we prove that as long as the mean of the loss parameters have positive lengths bounded away from zero, ftl deserves a dynamic growth rate of regret, while, e. g., for polytope domains and stochastic data it enjoys finite expected regret. building on good previously known meta - algorithm, we would get an algorithm implemented simultaneously enjoys exact worst - case guarantees and the bound available for complexity.", "histories": [["v1", "Fri, 10 Feb 2017 01:59:02 GMT  (1791kb,D)", "http://arxiv.org/abs/1702.03040v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["ruitong huang", "tor lattimore", "andr\u00e1s gy\u00f6rgy", "csaba szepesv\u00e1ri"], "accepted": true, "id": "1702.03040"}, "pdf": {"name": "1702.03040.pdf", "metadata": {"source": "CRF", "title": "Following the Leader and Fast Rates in Linear Prediction: Curved Constraint Sets and Other Regularities\u2217", "authors": ["Ruitong Huang", "Tor Lattimore", "Andr\u00e1s Gy\u00f6rgy", "Csaba Szepesv\u00e1ri"], "emails": [], "sections": [{"heading": null, "text": "known to perform well when the loss functions it is used on are convex and positively curved. In this paper we ask whether there are other \u201clucky\u201d settings when FTL achieves sublinear, \u201csmall\u201d regret. In particular, we study the fundamental problem of linear prediction over a non-empty convex, compact domain. Amongst other results, we prove that the curvature of the boundary of the domain can act as if the losses were curved: In this case, we prove that as long as the mean of the loss vectors have positive lengths bounded away from zero, FTL enjoys a logarithmic growth rate of regret, while, e.g., for polytope domains and stochastic data it enjoys finite expected regret. Building on a previously known meta-algorithm, we also get an algorithm that simultaneously enjoys the worst-case guarantees and the bound available for FTL."}, {"heading": "1 Introduction", "text": "Learning theory traditionally has been studied in a statistical framework, discussed at length, for example, by Shalev-Shwartz and Ben-David (2014). The issue with this approach is that the analysis of the performance of learning methods seems to critically depend on whether the data generating mechanism satisfies some probabilistic assumptions. Realizing that these assumptions are not necessarily critical, much work has been devoted recently to studying learning algorithms in the so-called online learning framework (Cesa-Bianchi and Lugosi, 2006). The online learning framework makes minimal assumptions about the data generating mechanism, while allowing one to replicate results of the statistical framework through online-to-batch conversions (Cesa-Bianchi et al., 2004). By following a minimax approach, however, results proven in the online learning setting, at least initially, led to rather conservative results and algorithm designs, failing to capture how more regular, \u201ceasier\u201d data, may give rise to faster learning speed. This is problematic as it may suggest overly conservative learning strategies, missing opportunities to extract more information when the data is nicer. Also, it is hard to argue that data resulting from passive data collection, such as weather data, would ever be adversarially generated (though it is equally hard to defend that such data satisfies precise stochastic assumptions). Realizing this issue, during recent years much work has been devoted to understanding what regularities and how can lead to faster learning speed. For example, much work has been devoted to showing that faster learning speed (smaller \u201cregret\u201d) can be achieved in the online convex optimization setting when the loss functions are \u201ccurved\u201d, such as when the loss functions are strongly convex or exp-concave, or when the losses show small variations, or the best prediction in hindsight has a small total loss, and that these properties can be exploited in an adaptive manner (e.g., Merhav and Feder 1992, Freund and Schapire 1997, Gaivoronski and Stella 2000, Cesa-Bianchi and Lugosi 2006, Hazan et al. 2007, Bartlett \u2217R. Huang and Cs. Szepesv\u00e1ri are with the Department of Computing Science, University of Alberta, AB, Canada, email: ruitong@ualberta.ca, szepesva@ualberta.ca. T. Lattimore was with the School of Informatics and Computing, Indiana University, IN, USA, email: tor.lattimore@gmail.com. A. Gy\u00f6rgy is with the Department of Electrical and Electronic Engineering, Imperial College London, UK, email: a.gyorgy@imperial.ac.uk.\nar X\niv :1\n70 2.\n03 04\n0v 1\n[ cs\n.L G\n] 1\n0 Fe\nb 20\net al. 2007, Kakade and Shalev-Shwartz 2009, Orabona et al. 2012, Rakhlin and Sridharan 2013, van Erven et al. 2015, Foster et al. 2015).\nIn this paper we contribute to this growing literature by studying online linear prediction and the follow the leader (FTL) algorithm. Online linear prediction is arguably the simplest yet fundamental of all the learning settings, and lies at the heart of online convex optimization, while it also serves as an abstraction of core learning problems such as prediction with expert advice. FTL, the online analogue of empirical risk minimization of statistical learning, is the simplest learning strategy, one can think of. Although the linear setting of course removes the possibility of exploiting the curvature of losses, as we will see, there are multiple ways online learning problems can present data that allows for small regret, even for FTL. As is it well known, in the worst case, FTL suffers a linear regret (e.g., Example 2.2 of Shalev-Shwartz (2012)). However, for \u201ccurved\u201d losses (e.g., exp-concave losses), FTL was shown to achieve small (logarithmic) regret (see, e.g., Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al. (2007)).\nIn this paper we take a thorough look at FTL in the case when the losses are linear, but the problem perhaps exhibits other regularities. The motivation comes from the simple observation that, for prediction over the simplex, when the loss vectors are selected independently of each other from a distribution with a bounded support with a nonzero mean, FTL quickly locks onto selecting the loss-minimizing vertex of the simplex, achieving finite expected regret. In this case, FTL is arguably an excellent algorithm. In fact, FTL is shown to be the minimax optimizer for the binary losses in the stochastic expert setting in the paper of Kot\u0142owski (2016). Thus, we ask the question of whether there are other regularities that allow FTL to achieve nontrivial performance guarantees. Our main result shows that when the decision set (or constraint set) has a sufficiently \u201ccurved\u201d boundary (equivalently, if it is strongly convex) and the linear loss is bounded away from 0, FTL is able to achieve logarithmic regret even in the adversarial setting, thus opening up a new way to prove fast rates not based on the curvature of losses, but on that of the boundary of the constraint set and non-singularity of the linear loss. In a matching lower bound we show that this regret bound is essentially unimprovable. We also show an alternate bound for polytope constraint sets, which allows us to prove that (under certain technical conditions) for stochastic problems the expected regret of FTL will be finite. To finish, we use (A, B)-prod of Sani et al. (2014) to design an algorithm that adaptively interpolates between the worst case O( \u221a n logn) regret and the smaller regret bounds, which we prove here for \u201ceasy data.\u201d We also show that if the constraint set is the unit ball, both the follow the regularized leader (FTRL) algorithm and a combination of FTL and shrinkage, which we call follow the shrunken leader (FTSL), achieve logarithmic regret for easy data. Simulation results on artificial data complement the theoretical findings.\nWhile we believe that we are the first to point out that the curvature of the constraint set W can help in speeding up learning, this effect is known in convex optimization since at least the work of Levitin and Polyak (1966), who showed that exponential rates are attainable for strongly convex constraint sets if the norm of the gradients of the objective function admit a uniform lower bound. More recently, Garber and Hazan (2015) proved an O(1/n2) optimization error bound (with problem-dependent constants) for the Frank-Wolfe algorithm for strongly convex and smooth objectives and strongly convex constraint sets. The effect of the shape of the constraint set was also discussed by Abbasi-Yadkori (2010) who demonstrated O( \u221a n) regret in the linear bandit setting. While these results at a high level are similar to ours, our proof technique is rather different than that used there."}, {"heading": "2 Preliminaries, online learning and the follow the leader algorithm", "text": "We consider the standard framework of online convex optimization, where a learner and an environment interact in a sequential manner in n rounds: In round every round t = 1, . . . , n, first the learner predicts wt \u2208 W. Then the environment picks a loss function `t \u2208 L, and the learner suffers loss `t(wt) and observes `t. Here, W is a non-empty, compact convex subset of Rd and L is a set of convex functions, mapping W to the reals. The elements of L are called loss functions. The performance of the learner is measured in terms of\nits regret,\nRn = n\u2211 t=1 `t(wt)\u2212 min w\u2208W n\u2211 t=1 `t(w) .\nThe simplest possible case, which will be the focus of this paper, is when the losses are linear, i.e., when `t(w) = \u3008ft, w\u3009 for some ft \u2208 F \u2282 Rd. In fact, the linear case is not only simple, but is also fundamental since the case of nonlinear loss functions can be reduced to it: Indeed, even if the losses are nonlinear, defining ft \u2208 \u2202`t(wt) to be a subgradient1 of `t at wt and letting \u02dc\u0300t(u) = \u3008ft, u\u3009, by the definition of subgradients, `t(wt)\u2212 `t(u) \u2264 `t(wt)\u2212 (`t(wt) + \u3008ft, u\u2212 wt\u3009) = \u02dc\u0300t(wt)\u2212 \u02dc\u0300t(u), hence for any u \u2208 W,\u2211\nt `t(wt)\u2212 \u2211 t `t(u) \u2264 \u2211 t \u02dc\u0300 t(wt)\u2212 \u2211 t \u02dc\u0300 t(u) .\nIn particular, if an algorithm keeps the regret small no matter how the linear losses are selected (even when allowing the environment to pick losses based on the choices of the learner), the algorithm can also be used to keep the regret small in the nonlinear case. Hence, in what follows we will study the linear case `t(w) = \u3008ft, w\u3009 and, in particular, we will study the regret of the so-called \u201cFollow The Leader\u201d (FTL) learner, which, in round t \u2265 2 picks\nwt = argmin w\u2208W t\u22121\u2211 i=1 `i(w) .\nFor the first round, w1 \u2208 W is picked in an arbitrary manner. When W is compact, the optimal w of minw\u2208W \u2211t\u22121 i=1\u3008w, ft\u3009 is attainable, which we will assume henceforth. If multiple minimizers exist, we simply fix one of them as wt. We will also assume that F is non-empty, compact and convex."}, {"heading": "2.1 Support functions", "text": "Let \u0398t = \u2212 1t \u2211t i=1 fi be the negative average of the first t vectors in (ft)nt=1, ft \u2208 F . For convenience, we define \u03980 := 0. Thus, for t \u2265 2,\nwt = argmin w\u2208W t\u22121\u2211 i=1 \u3008w, fi\u3009 = argmin w\u2208W \u3008w,\u2212\u0398t\u22121\u3009 = argmax w\u2208W \u3008w,\u0398t\u22121\u3009 .\nDenote by \u03a6(\u0398) = maxw\u2208W\u3008w,\u0398\u3009 the so-called support function of W. The support function, being the maximum of linear and hence convex functions, is itself convex. Further \u03a6 is positive homogenous: for a \u2265 0 and \u03b8 \u2208 Rd, \u03a6(a\u03b8) = a\u03a6(\u03b8). It follows then that the epigraph epi(\u03a6) = { (\u03b8, z) | z \u2265 \u03a6(\u03b8), z \u2208 R, \u03b8 \u2208 Rd } of \u03a6 is a cone, since for any (\u03b8, z) \u2208 epi(\u03a6) and a \u2265 0, az \u2265 a\u03a6(\u03b8) = \u03a6(a\u03b8), (a\u03b8, az) \u2208 epi(\u03a6) also holds. The differentiability of the support function is closely tied to whether in the FTL algorithm the choice of wt is uniquely determined:\nProposition 2.1. Let W 6= \u2205 be convex and closed. Fix \u0398 and let Z := {w \u2208 W | \u3008w,\u0398\u3009 = \u03a6(\u0398)}. Then, \u2202\u03a6(\u0398) = Z and, in particular, \u03a6(\u0398) is differentiable at \u0398 if and only if maxw\u2208W\u3008w,\u0398\u3009 has a unique optimizer. In this case, \u2207\u03a6(\u0398) = argmaxw\u2208W\u3008w,\u0398\u3009.\nThe proposition follows from Danskin\u2019s theorem when W is compact (e.g., Proposition B.25 of Bertsekas 1999), but a simple direct argument can also be used to show that it also remains true even when W is unbounded. 2 By Proposition 2.1, when \u03a6 is differentiable at \u0398t\u22121, wt = \u2207\u03a6(\u0398t\u22121). 1 We let \u2202g(x) denote the subdifferential of a convex function g : dom(g) \u2192 R at x, i.e., \u2202g(x) ={ \u03b8 \u2208 Rd | g(x\u2032) \u2265 g(x) + \u3008\u03b8, x\u2032 \u2212 x\u3009 \u2200x\u2032 \u2208 dom(g) } , where dom(g) \u2282 Rd is the domain of g.\n2 The proofs not given in the main text can be found in the appendix."}, {"heading": "3 Non-stochastic analysis of FTL", "text": "We start by rewriting the regret of FTL in an equivalent form, which shows that we can expect FTL to enjoy a small regret when successive weight vectors move little. A noteworthy feature of the next proposition is that rather than bounding the regret from above, it gives an equivalent expression for it.\nProposition 3.1. The regret Rn of FTL satisfies\nRn = n\u2211 t=1 t \u3008wt+1 \u2212 wt,\u0398t\u3009 .\nThe result is a direct corollary of Lemma 9 of McMahan (2010), which holds for any sequence of losses, even in the lack of convexity. It is also a tightening of the well-known inequality Rn \u2264 \u2211n t=1 `t(wt)\u2212 `t(wt+1), which again holds for arbitrary loss sequences (e.g., Lemma 2.1 of Shalev-Shwartz (2012)). To keep the paper self-contained, we give an elegant, short direct proof, based on the summation by parts formula:\nProof. The summation by parts formula states that for any u1, v1, . . . , un+1, vn+1 reals, \u2211n t=1 ut (vt+1\u2212 vt) =\n(ut+1vt+1 \u2212 u1v1) \u2212 \u2211n t=1(ut+1 \u2212 ut) vt+1. Applying this to the definition of regret with ut := wt,\u00b7 and vt+1 := t\u0398t, we get\nRn = \u2212 n\u2211 t=1 \u3008wt, t\u0398t \u2212 (t\u2212 1)\u0398t\u22121\u3009+ \u3008wn+1, n\u0398n\u3009\n= \u2212 { hhhhhh\u3008wn+1, n\u0398n\u3009 \u2212 0\u2212\nn\u2211 t=1 \u3008wt+1 \u2212 wt, t\u0398t\u3009\n} +hhhhhh\u3008wn+1, n\u0398n\u3009.\nOur next proposition gives another formula that is equal to the regret. As opposed to the previous result, this formula is appealing as it is independent of wt; but it directly connects the sequence (\u0398t)t to the geometric properties of W through the support function \u03a6. For this proposition we will momentarily assume that \u03a6 is differentiable at (\u0398t)t\u22651; a more general statement will follow later.\nProposition 3.2. If \u03a6 is differentiable at \u03981, . . . ,\u0398n,\nRn = n\u2211 t=1 tD\u03a6(\u0398t,\u0398t\u22121) , (1)\nwhere D\u03a6(\u03b8\u2032, \u03b8) = \u03a6(\u03b8\u2032)\u2212 \u03a6(\u03b8)\u2212 \u3008\u2207\u03a6(\u03b8), \u03b8\u2032 \u2212 \u03b8\u3009 is the Bregman divergence of \u03a6 and we use the convention that \u2207\u03a6(0) = w1.\nProof. Let v = argmaxw\u2208W\u3008w, \u03b8\u3009, v\u2032 = argmaxw\u2208W\u3008w, \u03b8\u2032\u3009. When \u03a6 is differentiable at \u03b8,\nD\u03a6(\u03b8\u2032, \u03b8) = \u03a6(\u03b8\u2032)\u2212 \u03a6(\u03b8)\u2212 \u3008\u2207\u03a6(\u03b8), \u03b8\u2032\u2212 \u03b8\u3009 = \u3008v\u2032, \u03b8\u2032\u3009\u2212 \u3008v, \u03b8\u3009 \u2212 \u3008v, \u03b8\u2032\u2212 \u03b8\u3009 = \u3008v\u2032\u2212 v, \u03b8\u2032\u3009 . (2)\nTherefore, by Proposition 3.1, Rn = \u2211n t=1 t\u3008wt+1 \u2212 wt,\u0398t\u3009 = \u2211n t=1 tD\u03a6(\u0398t,\u0398t\u22121).\nWhen \u03a6 is non-differentiable at some of the points \u03981, . . . ,\u0398n, the equality in the above proposition can be replaced with inequalities. Defining the upper Bregman divergence D\u03a6(\u03b8\u2032, \u03b8) = supw\u2208\u2202\u03a6(\u03b8) \u03a6(\u03b8\u2032)\u2212 \u03a6(\u03b8)\u2212 \u3008w, \u03b8\u2032 \u2212 \u03b8\u3009 and the lower Bregman divergence D\u03a6(\u03b8\u2032, \u03b8) similarly with inf instead of sup, we can easily obtain an analogue of Proposition 3.2:\nn\u2211 t=1 tD\u03a6(\u0398t,\u0398t\u22121) \u2264 Rn \u2264 n\u2211 t=1 tD\u03a6(\u0398t,\u0398t\u22121) . (3)"}, {"heading": "3.1 Constraint sets with positive curvature", "text": "The previous results show in an implicit fashion that the curvature ofW controls the regret. Before presenting our first main result, which makes this connection explicit, we define some basic notions from differential geometry related to the curvature (all differential geometry concept and results that we need can be found in Section 2.5 of Schneider, 2014).\nGiven a C2 (twice continuously differentiable) planar curve \u03b3 in R2, there exists a parametrization with respect to the curve length s, such that \u2016\u03b3\u2032(s)\u2016 = \u2016 (x\u2032(s), y\u2032(s)) \u2016 = x\u2032(s)2+y\u2032(s)2 = 1. Under the curve length parametrization, the curvature of \u03b3 at \u03b3(s) is \u2016\u03b3\u2032\u2032(s)\u2016. Define the unit normal vector n(s) as the unit vector that is perpendicular to \u03b3\u2032(s).3 Note that n(s) \u00b7\u03b3\u2032(s) = 0. Thus 0 = (n(s) \u00b7 \u03b3\u2032(s))\u2032 = n\u2032(s) \u00b7\u03b3\u2032(s)+n(s) \u00b7\u03b3\u2032\u2032(s), and \u2016\u03b3\u2032\u2032(s)\u2016 = \u2016n(s) \u00b7 \u03b3\u2032\u2032(s)\u2016 = \u2016n\u2032(s) \u00b7 \u03b3\u2032(s)\u2016 = \u2016n\u2032(s)\u2016. Therefore, the curvature of \u03b3 at point \u03b3(s) is the length of the differential of its unit normal vector.\nDenote the boundary of W by bd(W). We shall assume that W is C2, that is, bd(W) is a twice continuously differentiable submanifold of Rd. We denote the tangent plane of bd(W) at point w by TwW. Now there exists a unique unit vector at w that is perpendicular to TwW and points outward of W. In fact, one can define a continously differentiable normal unit vector field on bd(W), uW : bd(W) \u2192 Sd\u22121, the so-called Gauss map, which maps a boundary point w \u2208 bd(W) to the unique outer normal vector to W at w, where Sd\u22121 = { x \u2208 Rd | \u2016x\u20162 = 1 } denotes the unit sphere in d-dimensions. The differential of the Gauss map, \u2207uW(w), defines a linear endomorphism of TwW. Moreover, \u2207uW(w) is a self-adjoint operator, with nonnegative eigenvalues. The differential of the Gauss map, \u2207uW(w), describes the curvature of bd(W) via the second fundamental form. In particular, the principal curvatures of bd(W) at w \u2208 bd(W) is defined as the eigenvalues of \u2207uW(w). Perhaps a more intuitive, yet equivalent definition, is that the principal curvatures are the eigenvalues of the Hessian of f = fw in the parameterization t 7\u2192 w + t\u2212 fw(t)uW(w) of bd(W) which is valid in a small open neighborhood of w, where fw : TwW \u2192 [0,\u221e) is a suitable convex, nonnegative valued function that also satisfies fw(0) = 0 and where TwW, a hyperplane of Rd, denotes the tangent space of W at w, obtained by taking the support plane H of W at w and shifting it by \u2212w. Thus, the principal curvatures at some point w \u2208 bd(W) describe the local shape of bd(W) up to the second order. In this paper, we are interested in the minimum principal curvature at w \u2208 bd(W), which can be intepreated as the minimum curvature at w over all the planar curves \u03b3 \u2208 bd(W) that go through w.\nA related concept that has been used in convex optimization to show fast rates is that of a strongly convex constraint set (Levitin and Polyak, 1966; Garber and Hazan, 2015): W is \u03bb-strongly convex with respect to the norm \u2016\u00b7\u2016 if, for any x, y \u2208 W and \u03b3 \u2208 [0, 1], the \u2016\u00b7\u2016-ball with origin \u03b3x+ (1\u2212 \u03b3)y and radius \u03b3(1 \u2212 \u03b3)\u03bb \u2016x\u2212 y\u20162 /2 is included in W. We show in Proposition A.1 in the appendix that a convex body W \u2208 C2 is \u03bb-strongly convex with respect to \u2016\u00b7\u20162 if and only if the principal curvatures of the surface bd(W) are all at least \u03bb.\nAs promised, our next result connects the principal curvatures of bd(W) to the regret of FTL and shows that FTL enjoys logarithmic regret for highly curved surfaces, as long as \u2016\u0398t\u20162 is bounded away from zero.\nTheorem 3.3. Let W \u2282 Rd be a C2 convex body4 with d \u2265 2. Let M = maxf\u2208F \u2016f\u20162 and assume that \u03a6 is differentiable at (\u0398t)t. Assume that the principal curvatures of the surface bd(W) are all at least \u03bb0 for some constant \u03bb0 > 0 and Ln := min1\u2264t\u2264n \u2016\u0398t\u20162 > 0. Choose w1 \u2208 bd(W). Then\nRn \u2264 2M2\n\u03bb0Ln (1 + log(n)) .\nAs we will show later in an essentially matching lower bound, this bound is tight, showing that the forte of FTL is when Ln is bounded away from zero and \u03bb0 is large. Note that the bound is vacuous as soon as Ln = O(log(n)/n) and is worse than the minimax bound of O( \u221a n) when Ln = o(log(n)/ \u221a n). One possibility to reduce the bound\u2019s sensitivity to Ln is to use the trivial bound \u3008wt+1 \u2212 wt,\u0398t\u3009 \u2264 LW = L supw,w\u2032\u2208W \u2016w \u2212 w\u2032\u20162 for indices t when \u2016\u0398t\u2016 \u2264 L. Then, by optimizing the bound over L, one gets\n3There exist two unit vectors that are perpendicular to \u03b3\u2032(s) for each point on \u03b3. Pick the ones that are consistently oriented. 4Following Schneider (2014), a convex body of Rd is any non-empty, compact, convex subset of Rd.\na data-dependent bound of the form infL>0 ( 2M2 \u03bb0L (1 + log(n)) + LW \u2211n t=1 t I (\u2016\u0398t\u2016 \u2264 L) ) , which is more complex, but is free of Ln and thus reflects the nature of FTL better. Note that in the case of stochastic problems, where f1, . . . , fn are independent and identically distributed (i.i.d.) with \u00b5 := \u2212E [\u0398t] 6= 0, the probability that \u2016\u0398t\u20162 < \u2016\u00b5\u20162 /2 is exponentially small in t. Thus, selecting L = \u2016\u00b5\u20162 /2 in the previous bound, the contribution of the expectation of the second term is O(\u2016\u00b5\u20162W ), giving an overall bound of the form O( M 2\n\u03bb0\u2016\u00b5\u20162 log(n) + \u2016\u00b5\u20162W ). After the proof we will provide some simple examples that should make it\nmore intuitive how the curvature of W helps keeping the regret of FTL small.\nProof. Fix \u03b81, \u03b82 \u2208 Rd and let w(1) = argmaxw\u2208W\u3008w, \u03b81\u3009, w(2) = argmaxw\u2208W\u3008w, \u03b82\u3009. Note that if \u03b81, \u03b82 6= 0 then w(1), w(2) \u2208 bd(W). Below we will show that\n\u3008w(1) \u2212 w(2), \u03b81\u3009 \u2264 1 2\u03bb0 \u2016\u03b82 \u2212 \u03b81\u201622 \u2016\u03b82\u20162 . (4)\nProposition 3.1 suggests that it suffices to bound \u3008wt+1 \u2212 wt,\u0398t\u3009. By (4), we see that it suffices to bound how much \u0398t moves. A straightforward calculation shows that \u0398t cannot move much: for any norm \u2016\u00b7\u2016 on F , we have\n\u2016\u0398t \u2212\u0398t\u22121\u2016 = \u2225\u2225\u2225\u2225\u2225 1t\u2212 1 t\u22121\u2211 i=1 fi \u2212 1 t t\u2211 i=1 fi \u2225\u2225\u2225\u2225\u2225 = \u2225\u2225\u2225\u2225\u2225 t\u22121\u2211 i=1 ( 1 t\u2212 1 \u2212 1 t ) fi \u2212 1 t ft \u2225\u2225\u2225\u2225\u2225 \u2264\n\u2225\u2225\u2225\u2225\u2225 t\u22121\u2211 i=1 ( 1 t\u2212 1 \u2212 1 t ) fi \u2225\u2225\u2225\u2225\u2225+ \u2225\u2225\u2225\u22251t ft \u2225\u2225\u2225\u2225 = \u2225\u2225\u2225\u2225\u2225 t\u22121\u2211 i=1 1 t(t\u2212 1)fi \u2225\u2225\u2225\u2225\u2225+ \u2225\u2225\u2225\u22251t ft \u2225\u2225\u2225\u2225 = 1 t \u2225\u2225\u2225\u2225\u2225 1t\u2212 1 t\u22121\u2211 i=1 fi\n\u2225\u2225\u2225\u2225\u2225+ 1t \u2016ft\u2016 \u2264 2tM . (5) where M = maxf\u2208F \u2016f\u2016 is a constant that depends on F and the norm \u2016\u00b7\u2016.\nCombining inequality (4) with Proposition 3.1 and (5), we get\nRn = n\u2211 t=1 t\u3008wt+1 \u2212 wt,\u0398t\u3009 \u2264 n\u2211 t=1 t 2\u03bb0 \u2016\u0398t \u2212\u0398t\u22121\u201622 \u2016\u0398t\u22121\u20162\n\u2264 2M 2\n\u03bb0 n\u2211 t=1 1 t\u2016\u0398t\u22121\u20162 \u2264 2M 2 \u03bb0Ln n\u2211 t=1 1 t \u2264 2M 2 \u03bb0Ln (1 + log(n)) .\nTo finish the proof, it thus remains to show (4). The following elementary lemma relates the cosine of the angle between two vectors \u03b81 and \u03b82 to the squared normalized distance between the two vectors, thereby reducing our problem to bounding the cosine of this angle. For brevity, we denote by cos(\u03b81, \u03b82) the cosine of the angle between \u03b81 and \u03b82.\nLemma 3.4. For any non-zero vectors \u03b81, \u03b82 \u2208 Rd,\n1\u2212 cos(\u03b81, \u03b82) \u2264 1 2 \u2016\u03b81 \u2212 \u03b82\u201622 \u2016\u03b81\u20162\u2016\u03b82\u20162 . (6)\nProof. Note that \u2016\u03b81\u20162\u2016\u03b82\u20162 cos(\u03b81, \u03b82) = \u3008\u03b81, \u03b82\u3009. Therefore, (6) is equivalent to 2\u2016\u03b81\u20162\u2016\u03b82\u20162 \u2212 2\u3008\u03b81, \u03b82\u3009 \u2264 \u2016\u03b81 \u2212 \u03b82\u201622, which, by algebraic manipulations, is itself equivalent to 0 \u2264 (\u2016\u03b81\u20162 \u2212 \u2016\u03b82\u20162)2.\nWith this result, we see that it suffices to upper bound cos(\u03b81, \u03b82) by 1 \u2212 \u03bb0\u3008w(1) \u2212 w(2), \u03b81\u2016\u03b81\u20162 \u3009. To develop this bound, let \u03b8\u0303i = \u03b8i\u2016\u03b8i\u20162 for i = 1, 2. The angle between \u03b81 and \u03b82 is the same as the angle between the normalized vectors \u03b8\u03031 and \u03b8\u03032. To calculate the cosine of the angle between \u03b8\u03031 and \u03b8\u03032, let P be a plane spanned by \u03b8\u03031 and w(1) \u2212 w(2) and passing through w(1) (P is uniquely determined if \u03b8\u03031 is not parallel to\nw(1) \u2212 w(2); if there are multiple planes, just pick any of them). Further, let \u03b8\u03022 \u2208 Sd\u22121 be the unit vector along the projection of \u03b8\u03032 onto the plane P , as indicated in Fig. 1. Clearly, cos(\u03b8\u03031, \u03b8\u03032) \u2264 cos(\u03b8\u03031, \u03b8\u03022).\nConsider a curve \u03b3(s) on bd(W) connecting w(1) and w(2) that is defined by the intersection of bd(W) and P and is parametrized by its curve length s so that \u03b3(0) = w(1) and \u03b3(l) = w(2), where l is the length of the curve \u03b3 between w(1) and w(2). Let uW(w) denote the outer normal vector to W at w as before, and let u\u03b3 : [0, l]\u2192 Sd\u22121 be such that u\u03b3(s) = \u03b8\u0302 where \u03b8\u0302 is the unit vector parallel to the projection of uW(\u03b3(s)) on the plane P . By definition, u\u03b3(0) = \u03b8\u03031 and u\u03b3(l) = \u03b8\u03022. Note that in fact \u03b3 exists in two versions since W is a compact convex body, hence the intersection of P and bd(W) is a closed curve. Of these two versions we choose the one that satisfies that \u3008\u03b3\u2032(s), \u03b8\u03031\u3009 \u2264 0 for s \u2208 [0, l].5 Given the above, we have\ncos(\u03b8\u03031, \u03b8\u03022) = \u3008\u03b8\u03022, \u03b8\u03031\u3009 = 1+ \u3008\u03b8\u03022 \u2212 \u03b8\u03031, \u03b8\u03031\u3009 = 1+ \u2329\u222b l\n0 u\u2032\u03b3(s)ds, \u03b8\u03031\n\u232a = 1+ \u222b l 0 \u3008u\u2032\u03b3(s), \u03b8\u03031\u3009ds. (7)\nNote that \u03b3 is a planar curve on bd(W), thus its curvature \u03bb(s) satisfies \u03bb(s) \u2265 \u03bb0 for s \u2208 [0, l]. Also, for any w on the curve \u03b3, \u03b3\u2032(s) is a unit vector parallel to P . Moreover, u\u2032\u03b3(s) is parallel to \u03b3\u2032(s) and \u03bb(s) = \u2016u\u2032\u03b3(s)\u20162. Therefore,\n\u3008u\u2032\u03b3(s), \u03b8\u03031\u3009 = \u2016u\u2032\u03b3(s)\u20162\u3008\u03b3\u2032(s), \u03b8\u03031\u3009 \u2264 \u03bb0\u3008\u03b3\u2032(s), \u03b8\u03031\u3009,\nwhere the last inequality holds because \u3008\u03b3\u2032(s), \u03b8\u03031\u3009 \u2264 0. Plugging this into (7), we get the desired\ncos(\u03b8\u03031, \u03b8\u03022) \u2264 1 + \u03bb0 \u222b l\n0 \u3008\u03b3\u2032(s), \u03b8\u03031\u3009ds = 1 + \u03bb0 \u2329\u222b l 0 \u03b3\u2032(s)ds, \u03b8\u03031 \u232a = 1\u2212 \u03bb0\u3008w(1) \u2212 w(2), \u03b8\u03031\u3009 .\nReordering and combining with (6) we obtain\n\u3008w(1) \u2212 w(2), \u03b8\u03031\u3009 \u2264 1 \u03bb0\n( 1\u2212 cos(\u03b8\u03031, \u03b8\u03022) ) \u2264 1 \u03bb0 (1\u2212 cos(\u03b81, \u03b82)) \u2264 1 2\u03bb0 \u2016\u03b81 \u2212 \u03b82\u201622 \u2016\u03b81\u20162\u2016\u03b82\u20162 .\nMultiplying both sides by \u2016\u03b81\u20162 gives (4), thus, finishing the proof.\nExample 3.5. The smallest principal curvature of some common convex bodies are as follows:\n\u2022 The smallest principal curvature \u03bb0 of the Euclidean ball W = {w | \u2016w\u20162 \u2264 r} of radius r satisfies \u03bb0 = 1r .\n\u2022 Let Q be a positive definite matrix. If W = { w |w>Qw \u2264 1 } then \u03bb0 = \u03bbmin/ \u221a \u03bbmax, where \u03bbmin and\n\u03bbmax are the minimal, respectively, maximal eigenvalues of Q. (Polovinkin 1996 also derived this result for the strong convexity definition (ii) in Proposition A.1.)\n\u2022 In general, let \u03c6 : Rd \u2192 R be a C2 convex function. Then, for W = {w |\u03c6(w) \u2264 1}, \u03bb0 = minw\u2208bd(W) minv : \u2016v\u20162=1,v\u22a5\u03c6\u2032(w) v>\u22072\u03c6(w)v \u2016\u03c6\u2032(w)\u20162 .\n5\u03b3\u2032 and u\u2032\u03b3 denote the derivatives of \u03b3 and u, respectively, which exist since W is C2.\nWe only prove the last statement, since it implies the other two.\nProof. Fix w \u2208 bd(W). Note that \u03c6\u2032(w) is a normal vector at w for bd(W), thus TwW = {v : v \u22a5 \u03c6\u2032(w)}. Then the Gauss map uW of W satisfies uW(w) = \u03c6 \u2032(w) \u2016\u03c6\u2032(w)\u20162 for w \u2208 bd(W).\nNext we compute the Weingarten map Ww(v) : TwW \u2192 TwW, which, by definition, is the differential of uW(w) restricted to TwW. Note that the Weingarten map is a linear map.\nWw(v) = d uW d w \u2223\u2223\u2223\u2223 TwW (v) = \u2207 2(w)v \u2016\u03c6\u2032(w)\u20162 \u2212 \u03c6 \u2032(w)\u22072\u03c6(w)\u03c6\u2032(w)T v \u2016\u03c6\u2032(w)\u201632 = \u2207 2(w)v \u2016\u03c6\u2032(w)\u20162 .\nBy (Schneider, 2014, page 105), the principal curvature of W at w are the eigenvalues of the Weingarten map Ww(v). Therefore, the smallest principal curvature at w is minv : \u2016v\u20162=1,v\u22a5\u03c6\u2032(w) v>\u22072\u03c6(w)v \u2016\u03c6\u2032(w)\u20162 . Taking minimum over all w \u2208 bd(W) finishes the proof.\nO D = w\u2217\nA = \u2212\u00b5t\nB B\u0303\nA\u0303 = w\u0302t\nC\nA\u2032\nA\u0303\u2032\n= \u2212\u00b5\nFigure 2: Illustration of how curvature helps to keep the regret small.\nIn the stochastic i.i.d. case, when E [\u0398t] = \u2212\u00b5, we have \u2016\u0398t + \u00b5\u20162 = O(1/ \u221a t) with high probability. Thus say, for W being the unit ball of Rd, one has wt = \u0398t/ \u2016\u0398t\u20162; therefore, a crude bound suggests that \u2016wt \u2212 w\u2217\u20162 = O(1/ \u221a t), overall predicting that\nE [Rn] = O( \u221a n), while the previous result predicts that Rn is much smaller. In the next example we look at the unit ball, to explain geometrically, what \u201ccauses\u201d the smaller regret.\nExample 3.6. Let W = {w | \u2016w\u20162 \u2264 1} and consider a stochastic setting where the fi are i.i.d. samples from some underlying distribution with expectation E [fi] = \u00b5 = (\u22121, 0, . . . , 0) and \u2016fi\u2016\u221e \u2264M . It is straightforward to see that w\u2217 = (1, 0, . . . , 0), and thus \u3008w\u2217, \u00b5\u3009 = \u22121. Let E = {\u2212\u03b8 | \u2016\u03b8 \u2212 \u00b5\u20162 \u2264 }. As suggested beforehand, we expect \u2212\u00b5t \u2208 E with high probability. As shown in Fig. 2, the excess loss of an estimate # \u00bbOA is \u3008 # \u00bb OA\u0303, # \u00bb\nOD\u3009 \u2212 1 = |B\u0303D|. Similarly, the excess loss of an estimate # \u00bb\nOA\u2032 in the figure is |CD|. Therefore, for an estimate \u2212\u00b5t \u2208 E, the point A is where the largest excess loss is incurred. The triangle OAD is similar to the triangle ADB. Thus |BD||AD| = |AD| |OD| . Therefore, |BD| = 2 and since |B\u0303D| \u2264 |BD|, if \u2016\u00b5t \u2212 \u00b5\u20162 \u2264 , the excess error is at most 2 = O(1/t), making the regret Rn = O(logn).\nOur last result in this section is an asymptotic lower bound for the linear game, showing that FTL achieves the optimal rate under the condition that mint \u2016\u0398t\u20162 \u2265 L > 0.\nTheorem 3.7. Let \u03bb, L \u2208 (0, 1). Assume that {(1,\u2212L), (\u22121,\u2212L)} \u2282 F and let\nW = { (x, y) \u2208 R2 : x2 + y 2 \u03bb2 \u2264 1 }\nbe an ellipsoid with principal curvature h. Then, for any learning strategy, there exists a sequence of losses in F such that Rn = \u2126 (log(n)/(Lh)) and \u2016\u0398t\u20162 \u2265 L for all t.\nNote that by Example 3.5, the minimal principal curvature of W in the above theorem is \u03bb. In fact, it is not too hard to extend the above argument for any set W such that there is w \u2208 bd(W) where the curvature is h, and the curvature is a continuous function in a neighborhood of w over the boundary bd(W). The constants in the bound then depend on how fast the curvature changes within this neighborhood.\nProof. We define a random loss sequence, and we will show that no algorithm on this sequence can achieve an o(logn/(\u03bb0L) regret. Let P be a random variable with Beta(K,K) distribution for some K > 0,\nand, given P , assume that Xt, t \u2265 1 are i.i.d. Bernoulli random variables with parameter P . Let ft = Xt(1,\u2212L) + (1 \u2212 Xt)(\u22121,\u2212L) = (2Xt \u2212 1,\u2212L). Thus, the second coordinate of ft is always \u2212L, and so \u2016\u0398t\u20162 = \u2225\u2225\u2225 1t \u2211ti=1 fi\u2225\u2225\u22252 \u2265 L. Furthermore, the conditional expectation of the loss vector is fp 4= E [ft|P = p] = (2p\u2212 1,\u2212L).\nNote that Xt is a function of ft for all t; thus the conditional expectation of P , given f1, . . . , ft\u22121, can be determined by the well-known formula P\u0302t\u22121 = E [P | f1 . . . ft\u22121] = K+ \u2211t\u22121 i=1 Xi\n2K+t\u22121 . Given p, denote the optimizer of fp by wp, that is, wp = argminw\u2208W \u3008w, fp\u3009. Then the Bayesian optimal choice in round t is\nargmin w\u2208W\nE [ [ \u2329 w, fP \u232a\u2223\u2223 f1 . . . ft\u22121] = argmin w\u2208W \u2329 w,E [ fP \u2223\u2223 f1 . . . ft\u22121]\u232a\n= argmin w\u2208W\n\u2329 w, f P\u0302t\u22121 \u232a = wP\u0302t\u22121 , (8)\nwhere the first equality follows by linearity of the inner product, the second since fp is a linear function of p and the third by the definition of wp.\nThus, denoting by Wt the prediction of an arbitrary algorithm in round t, the expected regret can be bounded from below as\nE [Rn] = E [\nmax w\u2208W n\u2211 t=1 \u3008Wt \u2212 w, ft\u3009\n] = E [ E [ max w\u2208W n\u2211 t=1 \u3008Wt \u2212 w, ft\u3009 \u2223\u2223\u2223\u2223\u2223P ]]\n\u2265 E [ E [ n\u2211 t=1 \u2329 Wt \u2212 wP , ft \u232a\u2223\u2223\u2223\u2223\u2223P ]] = E [ n\u2211 t=1 E [\u2329 Wt \u2212 wP , ft \u232a\u2223\u2223P, f1, . . . , ft\u22121]]\n= E [\nn\u2211 t=1 E [\u2329 Wt \u2212 wP , fP \u232a\u2223\u2223 f1, . . . , ft\u22121]] (9) \u2265 E\n[ n\u2211 t=1 min w\u2208W E [\u2329 w \u2212 wP , fP \u232a\u2223\u2223 f1, . . . , ft\u22121]]\n= E [\nn\u2211 t=1 E [\u2329 wP\u0302t\u22121 \u2212 wP , fP \u232a\u2223\u2223\u2223 f1, . . . , ft\u22121]] (10) =\nn\u2211 t=1 E [\u2329 wP\u0302t\u22121 \u2212 wP , fP \u232a] ,\nwhere (9) holds because of the independence of the fs given P and since Wt is chosen based on f1, . . . , tt\u22121 (but not on P ), and (10) holds by (8).\nBy Lemma A.4 we have\nn\u2211 t=1 E [\u2329 wP\u0302t\u22121 \u2212 wP , fP \u232a] \u2265 hL2 n\u2211 t=1 E  ( 2P\u0302t\u22121\u22122P hL )2 \u221a 1 + ( 1\u22122P\nhL )2(1 + ( 1\u22122P\u0302t\u22121hL )2)  (11)\n= 2 hL n\u2211 t=1 E  1\u221a 1 + ( 1\u22122P hL )2E  (P\u0302t\u22121 \u2212 P )2 1 + ( 1\u22122P\u0302t\u22121 hL )2 \u2223\u2223\u2223\u2223\u2223\u2223\u2223P  \n\u2265 2 hL n\u2211 t=1 E  1\u221a 1 + ( 1\u22122P hL )2E  (P\u0302t\u22121 \u2212 P )2 1 + 2 ( 1\u22122P hL )2 + 2( 2P\u22122P\u0302t\u22121hL )2 \u2223\u2223\u2223\u2223\u2223\u2223\u2223P   , (12)\nwhere in the last step we used (a+ b)2 \u2264 a2 + b2. Let Gt be the event that |P\u0302t \u2212 P | \u2264 K|1\u22122P |2K+t + thL\n2K+t ; note that Gt holds with high probability by Lemma A.2. Then, lower bounding the first term by 0, (12) can be lower bounded by\n2 hL n\u22121\u2211 t=1 E  1\u221a 1 + ( 1\u22122P hL )2E  (P\u0302t \u2212 P )2 1 + 2 ( 1\u22122P hL )2 + 2( 2P\u22122P\u0302thL )2 I(Gt) \u2223\u2223\u2223\u2223\u2223\u2223\u2223P  \n\u2265 2 hL n\u22121\u2211 t=1 E  1\u221a 1 + ( 1\u22122P hL )2 E [ (P\u0302t \u2212 P )2I(Gt) \u2223\u2223\u2223P]( 1 + 2 ( 1\u22122P\nhL )2 + 2( 2K2K+t |1\u22122P |hL + 2t2K+t)2) \n\u2265 2 hL n\u22121\u2211 t=1 E  1\u221a 1 + ( 1\u22122P hL )2 E [ (P\u0302t \u2212 P )2I(Gt) \u2223\u2223\u2223P]( 9 + 4 ( 1\u22122P hL )2 + 8 |1\u22122P |hL )  .\nCombining the above, and using (P\u0302t\u2212P )2 \u2264 1 together with the upper bound on the probability of the event Gct , the complement of Gt, given in Lemma A.2, we get\nE [Rn] \u2265 2 hL n\u22121\u2211 t=1 E  1\u221a 1 + ( 1\u22122P hL )2 E [ (P\u0302t \u2212 P )2 \u2223\u2223\u2223P]\u2212 P [Gct ]( 9 + 4 ( 1\u22122P hL )2 + 8 |1\u22122P |hL ) \n\u2265 2 hL n\u22121\u2211 t=1\nE  1\u221a\n1 + ( 1\u22122P\nhL\n)2 E [ (P\u0302t \u2212 P )2 \u2223\u2223\u2223P]( 9 + 4 ( 1\u22122P\nhL )2 + 8 |1\u22122P |hL ) \u2212 e\u2212(t\u22121)h2L2  \u2265 2 hL n\u22121\u2211 t=1 E  1\u221a 1 + ( 1\u22122P hL )2 E [ (P\u0302t \u2212 P )2 \u2223\u2223\u2223P]( 9 + 4 ( 1\u22122P hL )2 + 8 |1\u22122P |hL )  \u2212 1 1\u2212 e\u2212h2L2\n . (13) Now, by Lemma A.3, we have\nE [ (P\u0302t \u2212 P )2 \u2223\u2223\u2223P] = K2(1\u2212 2P )2(2K + t)2 + tP (1\u2212 P )(2K + t)2 \u2265 P (1\u2212 P ) ( 1 t \u2212 2 t(2K + t) ) .\nCombining this with (13) and introducing the constant\nC = E  1\u221a 1 + ( 1\u22122P hL )2 P (1\u2212 P )(9 + 4 ( 1\u22122PhL )2 + 8 |1\u22122P |hL ) \nwe obtain, for any K > 0,\nlim inf n\u2192\u221e E [Rn] logn \u2265 lim infn\u2192\u221e 2 hL logn\n[ \u2212 1\n1\u2212 e\u2212h2L2 + n\u22121\u2211 t=1 C ( 1 t \u2212 2 t(2K + t) )] = 2C hL . (14)\nIt remains to calculate a constant lower bound for C that is independent of h and L. Denote |1\u22122P |hL by Y ; then 0 \u2264 P (1 \u2212 P ) = 1\u2212Y 2h2L2\n4 \u2264 1/4. Define G\u0302 to be the event when |Y | \u2264 1. Since P has Beta(K,K) distribution, E [P ] = 12 and Var(P ) = 1 8K . Therefore, by Chebyshev\u2019s inequality,\nP [ G\u0302c ] = P [\u2223\u2223\u2223\u2223P \u2212 12 \u2223\u2223\u2223\u2223 > hL2 ] \u2264 12Kh2L2 .\nTherefore,\nC = E [\n1\u221a 1 + Y 2 1\u2212 Y 2h2L2 4(9 + 4Y 2 + 8Y )\n] \u2265 E [ 1\u221a\n1 + Y 2 1\u2212 Y 2h2L2 4(9 + 4Y 2 + 8Y ) I(G\u0302) ]\n\u2265 1 84 \u221a 2 E [ (1\u2212 Y 2h2L2)I(G\u0302) ] \u2265 1 84 \u221a 2 ( E [ 1\u2212 Y 2h2L2 ] \u2212 P [ G\u0302c ])\n\u2265 1 84 \u221a 2\n( 1\u2212 E [ (1\u2212 2P )2 ] \u2212 12Kh2L2 ) = 1 84 \u221a 2 ( 1 2 \u2212 h2L2 2 ) .\nTherefore,\nlim inf n\u2192\u221e E [Rn] logn \u2265 1 84 \u221a 2 ( 1 hL \u2212 hL ) \u2265 1 84 \u221a 2 ( 1 hL \u2212 1 ) .\nThe result is completed by noting that the worst-case regret is at least as big as the expected regret, thus, for every n, there exist a P and a sequence of loss vectors f1, . . . , fn such that the regret Rn is at least \u2126( lognhL )."}, {"heading": "3.2 Other regularities", "text": "So far we have looked at the case when FTL achieves a low regret due to the curvature of bd(W). The next result characterizes the regret of FTL when W is a polytope, which has a flat, non-smooth boundary and thus Theorem 3.3 is not applicable. For this statement recall that given some norm \u2016 \u00b7 \u2016, its dual norm is defined by \u2016w\u2016\u2217 = sup\u2016v\u2016\u22641\u3008v, w\u3009.\nTheorem 3.8. Assume that W is a polytope and that \u03a6 is differentiable at \u0398i, i = 1, . . . , n. Let wt = argmaxw\u2208W\u3008w,\u0398t\u22121\u3009, W = supw1,w2\u2208W \u2016w1 \u2212 w2\u2016\u2217 and F = supf1,f2\u2208F \u2016f1 \u2212 f2\u2016. Then the regret of FTL is\nRn \u2264W n\u2211 t=1 t I(wt+1 6= wt)\u2016\u0398t \u2212\u0398t\u22121\u2016 \u2264 FW n\u2211 t=1 I(wt+1 6= wt) .\nNote that when W is a polytope, wt is expected to \u201csnap\u201d to some vertex of W. Hence, we expect the regret bound to be non-vacuous, if, e.g., \u0398t \u201cstabilizes\u201d around some value. Some examples after the proof will illustrate this.\nProof. Let v=argmaxw\u2208W\u3008w, \u03b8\u3009, v\u2032=argmaxw\u2208W\u3008w, \u03b8\u2032\u3009. Similarly to the proof of Theorem 3.3,\n\u3008v\u2032 \u2212 v, \u03b8\u2032\u3009 = \u3008v\u2032, \u03b8\u2032\u3009 \u2212 \u3008v\u2032, \u03b8\u3009+ \u3008v\u2032, \u03b8\u3009 \u2212 \u3008v, \u03b8\u3009+ \u3008v, \u03b8\u3009 \u2212 \u3008v, \u03b8\u2032\u3009 \u2264 \u3008v\u2032, \u03b8\u2032\u3009 \u2212 \u3008v\u2032, \u03b8\u3009+ \u3008v, \u03b8\u3009 \u2212 \u3008v, \u03b8\u2032\u3009 = \u3008v\u2032 \u2212 v, \u03b8\u2032 \u2212 \u03b8\u3009 \u2264W I(v\u2032 6= v)\u2016\u03b8\u2032 \u2212 \u03b8\u2016,\nwhere the first inequality holds because \u3008v\u2032, \u03b8\u3009 \u2264 \u3008v, \u03b8\u3009. Therefore, by Eq. (5),\nRn = n\u2211 t=1 t \u3008wt+1 \u2212 wt,\u0398t\u3009 \u2264W n\u2211 t=1 t I(wt+1 6=wt)\u2016\u0398t \u2212\u0398t\u22121\u2016 \u2264 FW n\u2211 t=1 I(wt+1 6=wt) .\nAs noted before, sinceW is a polytope, wt is (generally) attained at the vertices. In this case, the epigraph of \u03a6 is a polyhedral cone. Then, the event when wt+1 6= wt, i.e., when the \u201cleader\u201d switches corresponds to when \u0398t and \u0398t\u22121 belong to different linear regions corresponding to different linear pieces of the graph of \u03a6.\nWe now spell out a corollary for the stochastic setting. In particular, in this case FTL will often enjoy a constant regret:\nCorollary 3.9 (Stochastic setting). Assume that W is a polytope and that (ft)1\u2264t\u2264n is an i.i.d. sequence of random variables such that E [fi] = \u00b5 and \u2016fi\u2016\u221e \u2264 M . Let W = supw1,w2\u2208W \u2016w1 \u2212 w2\u20161. Further assume that there exists a constant r > 0 such that \u03a6 is differentiable for any \u03bd such that \u2016\u03bd \u2212 \u00b5\u2016\u221e \u2264 r. Then,\nE [Rn] \u2264 2MW (1 + 4dM2/r2) .\nThe condition on \u03a6 means that r can be selected to be the radius of the largest ball such that the optimal decisions for expected losses \u00b5 and \u03bd (i.e., the maximizers defining \u03a6(\u2212\u00b5) and \u03a6(\u2212\u03bd)) belong to the same face of W.\nProof. Let V = {\u03bd | \u2016\u03bd \u2212 \u00b5\u2016\u221e \u2264 r}. Note that the epigraph of the function \u03a6 is a polyhedral cone. Since \u03a6 is differentiable in the interior of V , {(\u03b8,\u03a6(\u03b8)) | \u03b8 \u2208 V } is a subset of a linear subspace. Therefore, for \u2212\u0398t,\u2212\u0398t\u22121 \u2208 V , wt+1 = wt. Hence, by Theorem 3.8,\nE [Rn] \u2264 2MW n\u2211 t=1\nP [\u2212\u0398t,\u2212\u0398t\u22121 /\u2208 V ] \u2264 4MW (\n1 + n\u2211 t=1\nP [\u2212\u0398t /\u2208 V ] ) .\nOn the other hand, note that \u2016fi\u2016\u221e \u2264M . Then\nP [\u2212\u0398t /\u2208 V ] = P [\u2225\u2225\u2225\u2225\u22251t t\u2211 i=1 fi \u2212 \u00b5 \u2225\u2225\u2225\u2225\u2225 \u221e \u2265 r ] \u2264 d\u2211 j=1 P [\u2223\u2223\u2223\u2223\u22231t t\u2211 i=1 fi,j \u2212 \u00b5j \u2223\u2223\u2223\u2223\u2223 \u2265 r ] \u2264 2de\u2212 tr2 2M2 ,\nwhere the last inequality is due to Hoeffding\u2019s inequality. Now, using that for \u03b1 > 0, \u2211n t=1 exp(\u2212\u03b1t) \u2264\u222b n\n0 exp(\u2212\u03b1t)dt \u2264 1 \u03b1 , we get E [Rn] \u2264 2MW (1 + 4dM 2/r2).\nThe condition that \u03a6 is differentiable for any \u03bd such that \u2016\u03bd \u2212 \u00b5\u2016\u221e \u2264 r is equivalent to that \u03a6 is differentiable at \u00b5. By Proposition 2.1, this condition requires that at \u00b5, maxw\u2208W\u3008w, \u03b8\u3009 has a unique optimizer. Note that the volume of the set of vectors \u03b8 with multiple optimizers is zero."}, {"heading": "4 Adaptive algorithm for the linear game", "text": "While as shown in Theorem 3.3, FTL can exploit the curvature of the surface of the constraint set to achieve O(logn) regret, it requires the curvature condition and mint \u2016\u0398t\u20162 \u2265 L being bounded away from zero, or it may suffer even linear regret. On the other hand, many algorithms, such as the \"Follow the regularized leader\" (FTRL) algorithm (see,e.g., Shalev-Shwartz, 2012), are known to achieve a regret guarantee of O( \u221a n) even for the worst-case data in the linear setting. This raises the question whether one can have an algorithm that can achieve constant or O(logn) regret in the respective settings of Corollary 3.9 or Theorem 3.3, while it still maintains O( \u221a n) regret for worst-case data. One way to design an adaptive algorithm is to use the (A, B)-prod algorithm of Sani et al. (2014), trivially leading to the following result:\nProposition 4.1. Consider (A, B)-prod of Sani et al. (2014), where algorithm A is chosen to be FTRL with an appropriate regularization term, while B is chosen to be FTL. Then the regret of the resulting hybrid algorithm H enjoys the following guarantees:\n\u2022 If FTL achieves constant regret as in the setting of Corollary 3.9, then the regret of H is also constant. \u2022 If FTL achieves a regret of O(logn) as in the setting of Theorem 3.3, then the regret of H is also O(logn). \u2022 Otherwise, the regret of H is at most O( \u221a n logn).\nIn the next section we show that if the constraint set is the unit ball, it is possible to design adaptive algorithms directly.\nAlgorithm 1 Follow The Shrunken Leader (FTSL 1: Predict w1 = 0; 2: for t = 2, ..., n\u2212 1 do 3: FTL: Compute w\u0303t = argminw\u2208W \u3008w,Ft\u22121\u3009 4: Shrinkage: Predict wt = \u2016Ft\u22121\u20162\u221a\u2016Ft\u22121\u201622+t+2 w\u0303t\n5: end for 6: FTL: Compute w\u0303n = argminw\u2208W \u3008w,Fn\u22121\u3009 7: Shrinkage: Predict wn = \u2016Fn\u22121\u20162\u221a\u2016Fn\u22121\u201622+n w\u0303n"}, {"heading": "4.1 Adaptive Algorithms for the Unit Ball Constraint Set", "text": "In this section we provide some interesting results about adaptive algorithms for the case when W is the unit ball in Rd (naturally, the results easily generalize to any ball centered at the origin). First, we show that a variant of FTL using shrinkage as regularization has O(log(n)) regret when \u2016\u0398t\u20162 \u2265 L > 0 for all t, but it also has O( \u221a n) worst case guarantee. Furthermore, we show that the standard FTRL algorithm is adaptive if the constraint set is the unit ball and the loss vectors are stochastic. Throughout the section we will use the notation Ft = \u2212(t\u2212 1)\u0398t = \u2211t\u22121 i=1 fi."}, {"heading": "4.1.1 Follow the Shrunken Leader", "text": "In this section we are going to analyze a combination of the FTL algorithm and the idea of shrinkage often used for regularization purposes in statistics. We assume that W = { x \u2208 Rd | \u2016x\u20162 \u2264 1 } is the unit ball and, without loss of generality, we further assume that \u2016f\u20162 \u2264 1 for all f \u2208 F .\nTheorem 4.2. The Follow The Shrunken Leader (FTSL) algorithm is given in Algorithm 1. The main idea of the algorithm is to predict a shrunken version of the FTL prediction, in this way keeping it away from the boundary of W. The next theorem shows that the right amount of shrinkage leads to a robust, adaptive algorithm:\n\u2022 If there exists L such that \u2016\u0398t\u20162 \u2265 L > 0 for 1 \u2264 t \u2264 n, then the regret of FTSL is O(log(n)/L). \u2022 Otherwise, the regret of FTSL is at most O( \u221a n).\nProof. By the definition of Ft and W, w\u0303t = \u2212Ft\u22121/\u2016Ft\u22121\u20162. Let \u03c3n = \u2016Fn\u22121\u20162\u221a\u2016Fn\u22121\u201622+n . Our proof follows the idea of Abernethy et al. (2008). We compute the upper bound on the value of the game for each round backwards for t = n, n\u2212 1, . . . , 1, by solving the optimal strategies for ft. The value of the game using FTSL is defined as\nVn = max f1,...,fn n\u2211 t=1 \u3008wt, ft\u3009 \u2212 min w\u2208W \u3008w,Fn\u3009\n= max f1,...,fn\u22121 n\u22121\u2211 t=1 \u3008wt, ft\u3009+ max fn \u2016Fn\u22121 + fn\u20162 + \u3008fn, wn\u3009\ufe38 \ufe37\ufe37 \ufe38\n=:Un We first prove that Un, the second term above, is bounded from above by \u221a \u2016Fn\u22121\u201622 + n. To see this, let fn = anF\u0303n\u22121 + bn\u2126n\u22121 where F\u0303n\u22121 is the unit vector parallel to Fn\u22121 and \u2126n\u22121 is a unit vector orthogonal\nto Fn\u22121. Furthermore, since \u2016fn\u20162 \u2264 1, we have a2n + b2n \u2264 1. Thus,\nUn = max fn\n\u221a \u2016Fn\u22121\u201622 + 2an\u2016Fn\u22121\u20162 + a2n + b2n \u2212 an\u03c3n\n\u2264 max a\n\u221a \u2016Fn\u22121\u201622 + 2a\u2016Fn\u22121\u20162 + n\u2212 a\u03c3n\n= \u221a \u2016Fn\u22121\u201622 + n,\nwhere the last equality follows since the maximum is attained at a = 0. A similar statement holds for the other time indices: for any t \u2265 1,\nmax ft\n\u221a \u2016Ft\u22121 + ft\u201622 + t+ 1 + \u3008ft, wt\u3009 \u2264 \u221a \u2016Ft\u22121\u201622 + t+\n1\u221a t . (15)\nBefore proving this inequality, let us see how it implies the second statement of the theorem:\nVn \u2264 max f1,...,fn\u22121 n\u22121\u2211 t=1 \u3008wt, ft\u3009+ \u221a \u2016Fn\u22121\u201622 + n\n\u2264 max f1,...,fn\u22122 n\u22122\u2211 t=1 \u3008wt, ft\u3009+ \u221a \u2016Fn\u22122\u201622 + n\u2212 1 + 1\u221a n\n\u2264 . . .\n\u2264 1 + n\u2211 t=1 1\u221a t = O( \u221a n).\nMoreover, if \u2016\u0398t\u20162 \u2265 L for 1 \u2264 t \u2264 n, a stronger version of (15) also holds:\nmax ft\n\u221a \u2016Ft\u22121 + ft\u201622 + t+ 1 + \u3008ft, wt\u3009 \u2264 \u221a \u2016Ft\u22121\u201622 + t+\n1 (t\u2212 1)L. (16)\nThis implies the first statement of the theorem, since\nVn \u2264 max f1,...,fn\u22121 n\u22121\u2211 t=1 \u3008wt, ft\u3009+ \u221a \u2016Fn\u22121\u201622 + n\n\u2264 max f1,...,fn\u22122 n\u22122\u2211 t=1 \u3008wt, ft\u3009+ \u221a \u2016Fn\u22122\u201622 + n\u2212 1 + 1 (n\u2212 1)L\n\u2264 . . . \u2264 1 + n\u22121\u2211 t=1 1 tL = O(log(n)/L).\nTo finish the proof, it remains to show (15) and (16). Let ft = atF\u0303t\u22121 + bt\u2126t\u22121 where F\u0303t\u22121 is the unit vector parallel to Ft\u22121 and \u2126t\u22121 is a unit vector orthogonal to Ft\u22121. Since \u2016ft\u20162 \u2264 1, observe that\na2t + b2t = \u2016ft\u20162 \u2264 1. Furthermore, let \u03c3t = \u2016Ft\u22121\u20162\u221a \u2016Ft\u22121\u201622+t+2 . Then, for any t \u2265 1,\n\u2206t = max ft\n\u221a \u2016Ft\u22121\u201622 + 2at\u2016Ft\u22121\u20162 + a2t + b2t + t+ 1\u2212 at\u03c3t \u2212 \u221a \u2016Ft\u22121\u201622 + t\n\u2264 max at\n\u221a \u2016Ft\u22121\u201622 + 2at\u2016Ft\u22121\u20162 + t+ 2\u2212 at\u03c3t \u2212 \u221a \u2016Ft\u22121\u201622 + t\n= \u221a \u2016Ft\u22121\u201622 + t+ 2\u2212 \u221a \u2016Ft\u22121\u201622 + t = 2\u221a \u2016Ft\u22121\u201622 + t+ 2 + \u221a \u2016Ft\u22121\u201622 + t\n(17)\n\u2264 1\u221a t .\nThis proves (15). Moreover, if \u2016Ft\u22121\u20162 = \u2016(t\u2212 1)\u0398\u20162 \u2265 (t\u2212 1)L, by (17) we obtain\n\u2206t \u2264 2\u221a \u2016Ft\u22121\u201622 + t+ 2 + \u221a \u2016Ft\u22121\u201622 + t \u2264 1 \u2016Ft\u22121\u20162 \u2264 1(t\u2212 1)L,\nproving (16)."}, {"heading": "4.1.2 FTRL for the case of the unit ball constraint set", "text": "This section is to show that in the case when W is the unit ball in `2 norm, FTRL with R(w) = 12\u2016w\u2016 2 as its regularization is an adaptive algorithm. To fix the notation, in round t, FTLR predicts\nwt = argmin w\u2208W \u03b7t\u3008Ft\u22121, w\u3009+R(w),\nif t > 1 and w1 = 0. It has been well known that FTRL with \u03b7t = 1/ \u221a t\u2212 1 is guaranteed to achieve O( \u221a n) regret in the adversarial setting, see, e.g., (Shalev-Shwartz, 2012). It remains to prove that FTRL indeed achieves a fast rate in the stochastic setting.\nTheorem 4.3. Assume that the sequence of loss vectors, f1, . . . , fn \u2208 Rd satisfies \u2016ft\u20162 \u2264 1 almost surely and E [ft] = \u00b5 for all t with some \u2016\u00b5\u20162 > 0. Then FTRL with \u03b7t = 1/ \u221a t\u2212 1 suffers O(logn) regret .\nProof. Using R(w) = 12\u2016w\u2016 2 as its regularization, in round t > 1 FTRL predicts\nwt = argmin w\u2208W\n\u03b7t\u3008Ft\u22121, w\u3009+R(w) = { 1\u221a t\u22121Ft\u22121 if \u2016Ft\u22121\u2016 \u2264 \u221a t\u2212 1\nFt\u22121 \u2016Ft\u22121\u2016 otherwise.\n(18)\nFor any 1 \u2264 t \u2264 n, denote the event \u2016Ft\u2016 \u2265 \u221a t by Et. Note that if \u2016Ft\u22121\u2016 \u2265 \u221a t\u2212 1, FTRL predicts exactly the same wt as FTL. Denote the accumulate loss of FTL in n rounds by LFTLn . Thus, the regret of FTRL is\nE [Rn] = E [\nn\u2211 t=1 \u3008ft, wt\u3009 \u2212 min w\u2208W \u3008ft, w\u3009\n]\n= E [\nn\u2211 t=1 \u3008ft, wt\u3009 \u2212 LFTLn\n] + E [ LFTLn \u2212 min\nw\u2208W \u3008ft, w\u3009\n]\n\u2264 2 n\u2211 t=1 P [Ect ] +O(logn),\nwhere, to obtain the last inequality, we applied (18) for the first term, while the second term is O(logn) by the discussion following Theorem 3.3. It remains to bound the first term, 2 \u2211n t=1 P [Ect ] in the above. For any t > 4\u2016\u00b5\u201622 ,\nP [ \u2016Ft\u20162 \u2264 \u221a t ] \u2264 P [ \u2016Ft\u20162 < t 2\u2016\u00b5\u20162 ] \u2264 d\u2211 i=1 P [ |Ft,i| < t 2 |\u00b5i| ]\n\u2264 d\u2211 i=1 P [ |Ft,i \u2212 t\u00b5i| > t 2 |\u00b5i| ] \u2264 2 d\u2211 i=1 e\u2212 \u00b52 i 4 t\nThus,\nn\u2211 t=1 P [Ect ] = 4/\u2016\u00b5\u201622\u2211 t=1 P [Ect ] + n\u2211\nt=4/\u2016\u00b5\u201622\nP [Ect ]\n\u2264 4 \u2016\u00b5\u201622 + 2 d\u2211 i=1 n\u2211 t=0 e\u2212 \u00b52 i 4 t\n\u2264 4 \u2016\u00b5\u201622 + 2 d\u2211 i=1\n1\n1\u2212 e\u2212 \u00b52 i 4\n\u2264 4 \u2016\u00b5\u201622 + 2 d\u2211 i=1 \u00b52i 4 = 4 \u2016\u00b5\u201622 + \u2016\u00b5\u2016 2 2 2 .\nwhere in the last inequality we used 1/(1\u2212 e\u2212a) \u2264 a. Therefore, if \u2016\u00b5\u2016 > 0, the regret of FTRL satisfies\nE [Rn] \u2264 8 \u2016\u00b5\u201622 + \u2016\u00b5\u201622 +O(logn) = O(logn)."}, {"heading": "5 Simulations", "text": "We performed three simulations to illustrate the differences between FTL, FTRL with the regularizer R(w) = 12 \u2016w\u2016 2 2 when wt = argminw\u2208W \u2211t\u22121 i=1\u3008fi\u22121, w\u3009+R(w), and the adaptive algorithm (A, B)-prod (AB) using FTL and FTRL as its candidates, which we shall call AB(FTL,FTRL). For the experiments the constraint setW was chosen to be a slightly elongated ellipsoid in the 4-dimensional Euclidean space, with volume matching that of the 4-dimensional unit ball. The actual ellipsoid is given by W = { w \u2208 R4 |w>Qw \u2264 1 } where Q is randomly generated as\nQ =  4.3367 3.6346 \u22122.2250 3.5628 3.6346 3.9966 \u22122.3613 3.2817 \u22122.2250 \u22122.3613 2.0589 \u22122.1295 3.5628 3.2817 \u22122.1295 3.4206  . We experimented with 3 types of data to illustrate the behavior of the different algorithms: stochastic, \u201chalf-adversarial\u201d, and \u201cworst-case\u201d data (worst-case for FTL), as will be explained below. The first two datasets are random, so the experiments were repeated 100 times, and we report the average regret with its standard deviation; the worst case data is deterministic, so there no repetition was needed. For each experiment, we set n = 2500. The regularization coefficient for the FTRL, and the learning rate for AB were chosen based on their theoretical bounds minimizing the worst-case regret.\nStochastic data. In this setting we used the following model to generate ft: Let (f\u0302t)t be an i.i.d. sequence drawn from the 4-dimensional standard normal distribution, and let f\u0303t = f\u0302t/ \u2225\u2225\u2225f\u0302t\u2225\u2225\u2225 2 . Then, ft is defined as\nft = f\u0303t + Le1 where e1 = (1, 0, . . . , 0)>. Therefore, E [\u2225\u2225\u2225 1t \u2211ts=1 fs\u2225\u2225\u22252]\u2192 L as t\u2192\u221e. In the experiments we picked L \u2208 {0, 0.1}. The results are shown in Fig. 3. On the left-hand side we plotted the regret against the logarithm of the number of rounds, while on the right-hand side we plotted the regret against the square root of the number of rounds, together with the standard deviation of the results over the 100 independent runs. As can be seen from the figures, when L = 0.1, the growth-rate of the regret of FTL is indeed logarithmic, while when L = 0, the growth-rate is \u0398( \u221a n). In particular, when L = 0.1, FTL enjoys a major advantage compared to FTRL, while for L = 0, FTL and FTRL perform essentially the same (in this special case, the regret of FTL will indeed be O( \u221a n) as wt will stay bounded but \u2016\u0398t\u2016 = O(1/ \u221a t)). As expected, AB(FTL,FTRL), gets the better of the two regrets with little to no extra penalty.\n\u201cHalf-adversarial\u201d data The half-adversarial data used in this experiment is the optimal solution for the adversary in the linear game when W is the unit ball (Abernethy et al., 2008). This data is generated as follows: The sequence f\u0302t for t = 1, . . . , n is generated randomly in the (d \u2212 1)-dimensional subspace S = span{e2, . . . , ed} (here ei is the ith unit vector in Rd) as follows: f\u03021 is drawn from the uniform distribution on the unit sphere of S (actually Sd\u22122. For t = 2, . . . , n, f\u0302t is drawn from the uniform distribution on the unit sphere of the intersection of S and the hyperplane perpendicular to \u2211t\u22121 i=1 f\u0302i and going through the origin.\nThen, ft = Le1 + \u221a\n1\u2212 L2f\u0302t for some L \u2265 0. The results are reported in Fig. 4. When L = 0, the regret of both FTL and FTRL grows as O( \u221a n). When L = 0.1, FTL achieves O(logn) regret, while the regret of FTRL appears to be O( \u221a n). AB(FTL,FTRL) closely matches the regret of FTL.\nWorst-case data We also tested the algorithms on data where FTL is known to suffer linear regret, mainly to see how well AB(FTL,FTRL) is able to deal with this setting. In this case, we set ft,i = 0 for all t and i \u2265 2, while for the first coordinate, f1,1 = 0.9, and ft,1 = 2(t mod 2)\u2212 1 for t \u2265 2.\nThe results are reported in Fig. 5. It can be seen that the regret of FTL is linear (as one can easily verify theoretically), and AB(FTL,FTRL) succeeds to adapt to FTRL, and they both achieve a much smaller\nO( \u221a n) regret.\nThe unit ball We close this section by comparing the performance of our adaptive algorithms on the unit ball, namely, FTL, FTSL, FTLR, and AB(FTL,FTRL). All these algorithms are parametrized as above. The problem setup is similar to the stochastic data setting and the worst-case data setting. Again, we consider a 4-dimensional setting, that is, W is the unit ball in R4 centered at the origin. The worst-case data is generated exactly as above, while the generation process of the stochastic data is slightly modified to increase the difference between FTLR and FTL: we sample the i.i.d. vectors f\u0302t from a zero-mean normal distribution with independent components whose variance is 1/16, and let f\u0303t = f\u0302t if \u2016f\u0302t\u20162 \u2264 1 and f\u0303t = f\u0302t/\n\u2225\u2225\u2225f\u0302t\u2225\u2225\u2225 2 when\u2225\u2225\u2225f\u0302t\u2225\u2225\u2225\n2 > 1 (i.e., we only normalize if f\u0302t falls outside of the unit ball). The reason of this modification is to\nencourage the occurrence of the event \u2016Ft\u22121\u20162 < \u221a t\u2212 1. Recall that when \u2016Ft\u22121\u20162 \u2265 \u221a t\u2212 1, the prediction of FTRL matches that of FTL, so we are trying to create some data where their behavior is actually different.\nAs a result, we will be able to observe that the predictions of FTL and FTRL are different in the early rounds. Finally, as before, we let ft = f\u0303t + Le1, and set the time horizon to n = 20, 000.\nThe results of the simulation of the stochastic data setting are shown in Figure 6. In the case of L = 0.1, FTRL suffers more regret at the beginning for some rounds, but then succeeds to match the performance of FTL. The results of the simulation of the worst-case data setting are shown in Figure 7, where FTSL has similar performance as FTRL."}, {"heading": "6 Conclusion", "text": "FTL is a simple method that is known to perform well in many settings, while existing worst-case results fail to explain its good performance. While taking a thorough look at why and when FTL can be expected to achieve small regret, we discovered that the curvature of the boundary of the constraint and having average loss vectors bounded away from zero help keep the regret of FTL small. These conditions are significantly different from previous conditions on the curvature of the loss functions which have been considered extensively in the literature. It would be interesting to further investigate this phenomenon for other algorithms or in other learning settings."}, {"heading": "A Appendix: Technical results", "text": "A.1 Strongly convex sets and principal curvatures Recall that a convex set W \u2282 Rd is \u03bb-strongly convex if for any x, y \u2208 W, \u03b3 \u2208 [0, 1], W contains the ball of center \u03b3x + (1 \u2212 \u03b3)y that has a radius of \u03b3(1 \u2212 \u03b3)\u03bb2 \u2016x\u2212 y\u2016\n2. That is, for any z \u2208 Rd with \u2016z\u2016 = 1, \u03b3x+ (1\u2212 \u03b3)y + \u03b3(1\u2212 \u03b3)\u03bb2 \u2016x\u2212 y\u2016 2 z \u2208 W. Let Br(x) = { y \u2208 Rd | \u2016x\u2212 y\u20162 \u2264 r } denote the Euclidean ball of radius r centered at x.\nProposition A.1. Let W \u2282 Rd be a C2 convex body with support function \u03d5, and let \u03bb be an arbitrary positive number. Then the following statements are equivalent:\n(i) The smallest principal curvature of W is at least \u03bb.\n(ii) W = \u2229\u03b8\u2208Sd\u22121B1/\u03bb(w\u03b8 \u2212 \u03b8/\u03bb) where w\u03b8 \u2208 \u2202\u03d5(\u03b8) \u2282 bd(W).\n(iii) W is \u03bb-strongly convex.\nCondition (ii), which is actually the definition of Polovinkin (1996) for strongly convex sets, means that W can be obtained as the intersection of closed balls of radius 1/\u03bb, such that there is one ball for every boundary point w and tangent hyperplane P where the ball touches P in w. Note that a ball with radius 1/\u03bb satisfies all conditions: (i) and (ii) by definition, while (iii) holds, e.g., by Example 13 of Journ\u00e9e et al. (2010).\nProof. We show that (i) implies (ii), (ii) implies (iii), and (iii) implies (i). We start with showing that (i) implies (ii). First note that all principal curvatures of the d-dimensional ball B = B1/\u03bb(0) with radius 1/\u03bb (centered at the origin) are \u03bb. Therefore, (i) and Theorem 3.2.9 of Schneider (2014) implies that there is a convex body M such that W +M = B, where for two sets, S1, S2 \u2282 Rd, S1 +S2 is defined as {s1 + s2 | s1 \u2208 S1, s2 \u2208 S2}. For any \u03b8 \u2208 Sd\u22121, let m\u03b8 \u2208 argmaxm\u2208M\u3008m, \u03b8\u3009. Then clearly w\u03b8 +m\u03b8 maximizes \u3008b, \u03b8\u3009 for b \u2208 W +M. Therefore, W +m\u03b8 is a subset of B and touches it at w\u03b8 +m\u03b8, or equivalently W \u2282 B \u2212m\u03b8 and they touch each other, and a tangent hyperplane with normal vector \u03b8, in w\u03b8. This proves that (i) implies (ii).\nNext we prove that (ii) implies (iii). Assuming (ii) holds, let w \u2208 W be any point in the interior of W, and let p \u2208 bd(W) be the closest boundary point to w, and recall that TpW is the tangent space of W at p. By construction, B\u2016w\u2212p\u20162(w) touches the boundary of W at p (in the sense that they do not intersect, but they can have multiple common points), and so w \u2212 p is orthogonal to TpW. Therefore, B\u2016w\u2212p\u20162(w) also touches the boundary of the ball B = B1/\u03bb(p+ w\u2212p\u03bb\u2016w\u2212p\u20162 ), which contains W by assumption (ii). Now consider any two points x, y \u2208 W and \u03b3 \u2208 [0, 1] such that w = \u03b3x + (1 \u2212 \u03b3)y. Then the ball with radius \u03bb\u03b3(1\u2212 \u03b3)\u2016x\u2212 y\u201622/2 centered at w is contained in B, since B is \u03bb-strongly convex. But then its radius is at most \u2016p\u2212 w\u20162, and so it is also contained in W. This shows that W is \u03bb-strongly convex, thus (iii) holds.\nTo finish the proof of the proposition, assume (iii). To prove that (i) holds, we have to show, that for any point p on bd(W) and for any unit vector v \u2208 TpW, the curvature of the boundary along v is at least \u03bb. Let P be the hyperplane spanned by v and the outer normal vector u of W at point p, and consider the planar curve \u03b3 defined by bd(W) \u2229 P . Using v as the axis of a local coordinate system, a point w(s) on the\ncurve \u03b3 in the neighborhood of p can be expressed as w(s) = p+ sv\u2212 f(s)u for an appropriate function f , as illustrated in Fig. 8.\nNote that f \u2032(0) = 0, and by Proposition 2.1 of Pressley (2010), the curvature of \u03b3 at p can be obtained as\nf \u2032\u2032(s)\u221a 1 + f \u2032(s)23 \u2223\u2223\u2223\u2223\u2223 s=0 = f \u2032\u2032(0) .\nNow since w(s), w(\u2212s) \u2208 W for a sufficiently small s, the strong convexity of W applied to w(s) and w(\u2212s) with \u03b3 = 1/2 implies that q = w(s)+w(\u2212s)2 + \u03bb 8 \u2016w(s) \u2212 w(\u2212s)\u2016 2 2u \u2208 W. Substituting the definition of w(s) and w(\u2212s), we get\nq = p\u2212 u [ f(s) + f(\u2212s)\n2 \u2212 \u03bb 8\n( 4s2 + (f(s)\u2212 f(\u2212s))2 )] .\nTherefore, q \u2208 W implies f(s) + f(\u2212s) \u2265 \u03bbs2, and so\nf \u2032\u2032(0) = lim s\u21920\nf(s)\u2212f(0) s \u2212 f(0)\u2212f(\u2212s) s\ns = f(s) + f(\u2212s) s2 \u2265 \u03bb.\nThus (i) holds, finishing the proof of the proposition.\nA.2 Proof of Proposition 2.1 Under the extra condition that W is compact the result follows from Danskin\u2019s theorem (e.g., Proposition B.25 of Bertsekas 1999). However, compactness is not required. For completeness, we provide a short, direct proof. We need to show that Z = \u2202\u03d5(\u0398) where recall that\n\u2202\u03d5(\u0398) = { u \u2208 Rd |\u03d5(\u0398) + \u3008u, \u00b7 \u2212\u0398\u3009 \u2264 \u03d5(\u00b7) } = { u \u2208 Rd |\u03d5(\u0398) \u2264 \u3008u,\u0398\u3009+ \u03d5(\u00b7)\u2212 \u3008u, \u00b7\u3009 } .\nSince Z \u2282 W, if w \u2208 Z, \u03d5(\u0398\u2032) \u2265 \u3008w,\u0398\u2032\u3009 for any \u0398\u2032 by the definition of \u03d5. Hence, \u03d5(\u0398) = \u3008w,\u0398\u3009 \u2264 \u3008w,\u0398\u3009+ \u03d5(\u0398\u2032)\u2212 \u3008w,\u0398\u2032\u3009 for any \u0398\u2032, implying that w \u2208 \u2202\u03d5(\u0398).\nOn the other hand, assume w \u2208 \u2202\u03d5(\u0398). Then \u03d5(\u0398) \u2264 \u3008w,\u0398\u3009 since \u03d5(0) = \u3008w, 0\u3009 = 0. Since W is closed, Z is also closed. Therefore, if w 6\u2208 Z, the strict separation theorem (applied to {w}, a convex compact set, and Z, a convex closed set) implies that there exists \u03c1 \u2208 Rd such that \u3008z, \u03c1\u3009 < \u3008w, \u03c1\u3009 for all z \u2208 Z. Let \u0398\u2032 = \u0398 + \u03c1. Then, \u03d5(\u0398\u2032) = maxu\u2208W\u3008u,\u0398\u3009+ \u3008u, \u03c1\u3009 < \u03d5(\u0398) + \u3008w,\u0398\u2032 \u2212\u0398\u3009 \u2264 \u3008w,\u0398\u2032\u3009 \u2264 \u03d5(\u0398\u2032), a contradiction. Hence, w \u2208 Z.\nA.3 Technical lemmas for the lower bound Theorem 3.7 Lemma A.2 (Concentration of P\u0302t). For any u > 0,\nP [ |P\u0302t \u2212 P | > K\n2K + t |1\u2212 2P |+ t 2K + tu \u2223\u2223\u2223\u2223P] \u2264 2 exp(\u2212tu2) .\nProof. Recall that P\u0302t = K+ \u2211t i=1 Xi 2K+t . Thus,\nP [ |P\u0302t \u2212 P | > u \u2223\u2223\u2223P] = P[\u2223\u2223\u2223\u2223\u2223K + \u2211t i=1Xi 2K + t \u2212 P \u2223\u2223\u2223\u2223\u2223 > K2K + t |1\u2212 2P |+ t2K + tu \u2223\u2223\u2223\u2223\u2223P ]\n= P [\u2223\u2223\u2223\u2223\u2223 t\u2211 i=1 Xi \u2212 Pt+K(1\u2212 2P ) \u2223\u2223\u2223\u2223\u2223 > K|1\u2212 2P |+ tu \u2223\u2223\u2223\u2223\u2223P ]\n\u2264 P [\u2223\u2223\u2223\u2223\u2223 t\u2211 i=1 Xi \u2212 Pt \u2223\u2223\u2223\u2223\u2223 > tu \u2223\u2223\u2223\u2223\u2223P ] , (19)\nwhere the last inequality is due to P [|A+ b| > c] \u2264 P [|A| > c\u2212 |b|]. Note that conditioned on P , X1, . . . , Xt are independent Bernoulli random variables with expectation P , thus (19) holds by Hoeffding\u2019s inequality (see, e.g., (Cesa-Bianchi and Lugosi, 2006, Corollary A.1)).\nLemma A.3. E [ (P \u2212 P\u0302t)2 \u2223\u2223\u2223P] = K2(1\u2212 2P )2(2K + t)2 + tP (1\u2212 P )(2K + t)2 .\nProof. Recall that P\u0302t = K+ \u2211t i=1 Xi 2K+t .Thus,\nE [ (P \u2212 P\u0302t)2 \u2223\u2223\u2223P] = E (K(1\u2212 2P ) 2K + t + \u2211t i=1Xi \u2212 Pt 2K + t )2\u2223\u2223\u2223\u2223\u2223\u2223P \n= K 2(1\u2212 2P )2 (2K + t)2 + 1 (2K + t)2E ( t\u2211 i=1 Xi \u2212 tP )2\u2223\u2223\u2223\u2223\u2223\u2223P \n= K 2(1\u2212 2P )2 (2K + t)2 + tP (1\u2212 P ) (2K + t)2 ,\nwhere the second equality is due to E [\u2211t i=1Xi \u2212 Pt \u2223\u2223\u2223P] = 0, and the last equality is due to that conditioned\non P , \u2211t i=1Xi has a Binomial distribution with parameters t and P .\nLemma A.4. Under the assumptions of Theorem 3.7, for any 0 < P1, P2 < 1,\n\u2329 wP2 \u2212 wP1 , fP1 \u232a \u2265 hL2\n( 2P2\u22122P1 hL )2\u221a 1 + ( 1\u22122P1 hL\n)2 (1 + ( 1\u22122P2hL )2) . Proof. It is easy to see that for any p, wp is on the boundary of W, that is, wp = argminw\u2208W \u3008w, fp\u3009 = (cos(\u03d5p), h sin(\u03d5p)) for some \u03d5p. Then \u3008wp, fp\u3009 = (2p\u2212 1) cos(\u03d5p)\u2212 Lh sin(\u03d5p), and so taking the derivative it is easy to verify that tan(\u03d5p) = Lh1\u22122p and sin(\u03d5 p) = Lh\u221a (Lh)2+(1\u22122p)2 > 0. Thus, 1\u2212 2P1 = Lh cos(\u03d5 P1 ) sin(\u03d5P1 ) . To\nsimplify notation, let \u03d51 = \u03d5P1 and \u03d52 = \u03d5P2 . Then,\n\u3008wP2 \u2212 wP1 , fP1\u3009 = \u2329(\ncos\u03d52 \u2212 cos\u03d51 h (sin\u03d52 \u2212 sin\u03d51)\n) , ( \u2212hL cos\u03d51 sin\u03d51 \u2212L )\u232a = \u2212hL ( (cos(\u03d52)\u2212 cos(\u03d51))\ncos(\u03d51) sin(\u03d51)\n+ (sin(\u03d52)\u2212 sin(\u03d51)) )\n= \u2212hLsin(\u03d51) ( cos(\u03d52) cos(\u03d51)\u2212 cos2(\u03d51) + sin(\u03d51) sin(\u03d52)\u2212 sin2(\u03d51) ) = hLsin(\u03d51) (1\u2212 cos(\u03d52) cos(\u03d51)\u2212 sin(\u03d51) sin(\u03d52))\n= hLsin(\u03d51) (1\u2212 cos(\u03d51 \u2212 \u03d52))\n= hLsin(\u03d51) ( 1 2 (cos(\u03d51 \u2212 \u03d52)\u2212 1) 2 + 12 sin 2(\u03d51 \u2212 \u03d52) ) (20)\n\u2265 hL2 sin(\u03d51) sin2(\u03d51 \u2212 \u03d52)\n= hL2 sin(\u03d51) sin 2 \u03d52 (cot(\u03d51)\u2212 cot(\u03d52))2 . (21)\nThe proof is finished by substituting cot(\u03d5i) = 1\u22122PihL , sin(\u03d51) = 1\u221a\n1+( 1\u22122P1Lh ) 2 and sin2(\u03d52) = 11+( 1\u22122P2Lh ) 2 ."}, {"heading": "Acknowledgements", "text": "This work was supported in part by the Alberta Innovates Technology Futures through the Alberta Ingenuity Centre for Machine Learning and by NSERC. During part of this work, T. Lattimore was with the Department of Computing Science, University of Alberta."}], "references": [{"title": "Forced-exploration based algorithms for playing in bandits with large action sets", "author": ["Y. Abbasi-Yadkori"], "venue": "Library and Archives Canada,", "citeRegEx": "Abbasi.Yadkori.,? \\Q2010\\E", "shortCiteRegEx": "Abbasi.Yadkori.", "year": 2010}, {"title": "Optimal strategies and minimax lower bounds for online convex games", "author": ["J. Abernethy", "P.L. Bartlett", "A. Rakhlin", "A. Tewari"], "venue": "In 21st Annual Conference on Learning Theory (COLT),", "citeRegEx": "Abernethy et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Abernethy et al\\.", "year": 2008}, {"title": "Adaptive online gradient descent", "author": ["P.L. Bartlett", "E. Hazan", "A. Rakhlin"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Bartlett et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bartlett et al\\.", "year": 2007}, {"title": "Nonlinear Programming", "author": ["D. Bertsekas"], "venue": "Athena Scientific,", "citeRegEx": "Bertsekas.,? \\Q1999\\E", "shortCiteRegEx": "Bertsekas.", "year": 1999}, {"title": "Prediction, Learning, and Games", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": null, "citeRegEx": "Cesa.Bianchi and Lugosi.,? \\Q2006\\E", "shortCiteRegEx": "Cesa.Bianchi and Lugosi.", "year": 2006}, {"title": "On the generalization ability of on-line learning algorithms", "author": ["N. Cesa-Bianchi", "A. Conconi", "C. Gentile"], "venue": "IEEE Trans. Information Theory,", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2004}, {"title": "Adaptive online learning", "author": ["D.J. Foster", "A. Rakhlin", "K. Sridharan"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Foster et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Foster et al\\.", "year": 2015}, {"title": "A decision-theoretic generalization of on-line learning and an application to boosting", "author": ["Y. Freund", "R. Schapire"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Freund and Schapire.,? \\Q1997\\E", "shortCiteRegEx": "Freund and Schapire.", "year": 1997}, {"title": "Stochastic nonstationary optimization for finding universal portfolios", "author": ["A.A. Gaivoronski", "F. Stella"], "venue": "Annals of Operations Research,", "citeRegEx": "Gaivoronski and Stella.,? \\Q2000\\E", "shortCiteRegEx": "Gaivoronski and Stella.", "year": 2000}, {"title": "Faster rates for the frank-wolfe method over strongly-convex sets", "author": ["D. Garber", "E. Hazan"], "venue": "In Proceedings of the 32nd International Conference on Machine Learning (ICML),", "citeRegEx": "Garber and Hazan.,? \\Q2015\\E", "shortCiteRegEx": "Garber and Hazan.", "year": 2015}, {"title": "Logarithmic regret algorithms for online convex optimization", "author": ["E. Hazan", "A. Agarwal", "S. Kale"], "venue": "Machine Learning,", "citeRegEx": "Hazan et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Hazan et al\\.", "year": 2007}, {"title": "Generalized power method for sparse principal component analysis", "author": ["M. Journ\u00e9e", "Y. Nesterov", "P. Richt\u00e1rik", "R. Sepulchre"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Journ\u00e9e et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Journ\u00e9e et al\\.", "year": 2010}, {"title": "Mind the duality gap: Logarithmic regret algorithms for online optimization", "author": ["S.M. Kakade", "S. Shalev-Shwartz"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Kakade and Shalev.Shwartz.,? \\Q2009\\E", "shortCiteRegEx": "Kakade and Shalev.Shwartz.", "year": 2009}, {"title": "Minimax strategy for prediction with expert advice under stochastic assumptions", "author": ["W. Kot\u0142owski"], "venue": "Algorithmic Learning Theory (ALT),", "citeRegEx": "Kot\u0142owski.,? \\Q2016\\E", "shortCiteRegEx": "Kot\u0142owski.", "year": 2016}, {"title": "Constrained minimization methods", "author": ["E.S. Levitin", "B.T. Polyak"], "venue": "USSR Computational Mathematics and Mathematical Physics,", "citeRegEx": "Levitin and Polyak.,? \\Q1966\\E", "shortCiteRegEx": "Levitin and Polyak.", "year": 1966}, {"title": "Follow-the-regularized-leader and mirror descent: Equivalence theorems and implicit updates", "author": ["H.B. McMahan"], "venue": "arXiv,", "citeRegEx": "McMahan.,? \\Q2010\\E", "shortCiteRegEx": "McMahan.", "year": 2010}, {"title": "Universal sequential learning and decision from individual data sequences", "author": ["N. Merhav", "M. Feder"], "venue": "In 5th Annual ACM Workshop on Computational Learning Theory (COLT),", "citeRegEx": "Merhav and Feder.,? \\Q1992\\E", "shortCiteRegEx": "Merhav and Feder.", "year": 1992}, {"title": "Beyond logarithmic bounds in online learning", "author": ["F. Orabona", "N. Cesa-Bianchi", "C. Gentile"], "venue": "In Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics (AISTATS),", "citeRegEx": "Orabona et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Orabona et al\\.", "year": 2012}, {"title": "Strongly convex analysis", "author": ["E.S. Polovinkin"], "venue": "Sbornik: Mathematics,", "citeRegEx": "Polovinkin.,? \\Q1996\\E", "shortCiteRegEx": "Polovinkin.", "year": 1996}, {"title": "Elementary differential geometry", "author": ["A.N. Pressley"], "venue": "Springer Science & Business Media,", "citeRegEx": "Pressley.,? \\Q2010\\E", "shortCiteRegEx": "Pressley.", "year": 2010}, {"title": "Online learning with predictable sequences", "author": ["A. Rakhlin", "K. Sridharan"], "venue": "In 26th Annual Conference on Learning Theory (COLT),", "citeRegEx": "Rakhlin and Sridharan.,? \\Q2013\\E", "shortCiteRegEx": "Rakhlin and Sridharan.", "year": 2013}, {"title": "Exploiting easy data in online optimization", "author": ["A. Sani", "G. Neu", "A. Lazaric"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Sani et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sani et al\\.", "year": 2014}, {"title": "Convex Bodies: The Brunn\u2013Minkowski Theory. Encyclopedia of Mathematics and its Applications", "author": ["R. Schneider"], "venue": null, "citeRegEx": "Schneider.,? \\Q2014\\E", "shortCiteRegEx": "Schneider.", "year": 2014}, {"title": "Online learning and online convex optimization", "author": ["S. Shalev-Shwartz"], "venue": "Foundations and trends in Machine Learning,", "citeRegEx": "Shalev.Shwartz.,? \\Q2012\\E", "shortCiteRegEx": "Shalev.Shwartz.", "year": 2012}, {"title": "Understanding Machine Learning: From Theory to Algorithms", "author": ["S. Shalev-Shwartz", "S. Ben-David"], "venue": null, "citeRegEx": "Shalev.Shwartz and Ben.David.,? \\Q2014\\E", "shortCiteRegEx": "Shalev.Shwartz and Ben.David.", "year": 2014}, {"title": "Fast rates in statistical and online learning", "author": ["T. van Erven", "P. Gr\u00fcnwald", "N. Mehta", "M. Reid", "R. Williamson"], "venue": "Journal of Machine Learning Research (JMLR),", "citeRegEx": "Erven et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Erven et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 4, "context": "Realizing that these assumptions are not necessarily critical, much work has been devoted recently to studying learning algorithms in the so-called online learning framework (Cesa-Bianchi and Lugosi, 2006).", "startOffset": 174, "endOffset": 205}, {"referenceID": 5, "context": "The online learning framework makes minimal assumptions about the data generating mechanism, while allowing one to replicate results of the statistical framework through online-to-batch conversions (Cesa-Bianchi et al., 2004).", "startOffset": 198, "endOffset": 225}, {"referenceID": 17, "context": "1 Introduction Learning theory traditionally has been studied in a statistical framework, discussed at length, for example, by Shalev-Shwartz and Ben-David (2014). The issue with this approach is that the analysis of the performance of learning methods seems to critically depend on whether the data generating mechanism satisfies some probabilistic assumptions.", "startOffset": 127, "endOffset": 163}, {"referenceID": 4, "context": "2015, Foster et al. 2015). In this paper we contribute to this growing literature by studying online linear prediction and the follow the leader (FTL) algorithm. Online linear prediction is arguably the simplest yet fundamental of all the learning settings, and lies at the heart of online convex optimization, while it also serves as an abstraction of core learning problems such as prediction with expert advice. FTL, the online analogue of empirical risk minimization of statistical learning, is the simplest learning strategy, one can think of. Although the linear setting of course removes the possibility of exploiting the curvature of losses, as we will see, there are multiple ways online learning problems can present data that allows for small regret, even for FTL. As is it well known, in the worst case, FTL suffers a linear regret (e.g., Example 2.2 of Shalev-Shwartz (2012)).", "startOffset": 6, "endOffset": 888}, {"referenceID": 4, "context": "2015, Foster et al. 2015). In this paper we contribute to this growing literature by studying online linear prediction and the follow the leader (FTL) algorithm. Online linear prediction is arguably the simplest yet fundamental of all the learning settings, and lies at the heart of online convex optimization, while it also serves as an abstraction of core learning problems such as prediction with expert advice. FTL, the online analogue of empirical risk minimization of statistical learning, is the simplest learning strategy, one can think of. Although the linear setting of course removes the possibility of exploiting the curvature of losses, as we will see, there are multiple ways online learning problems can present data that allows for small regret, even for FTL. As is it well known, in the worst case, FTL suffers a linear regret (e.g., Example 2.2 of Shalev-Shwartz (2012)). However, for \u201ccurved\u201d losses (e.g., exp-concave losses), FTL was shown to achieve small (logarithmic) regret (see, e.g., Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al.", "startOffset": 6, "endOffset": 1035}, {"referenceID": 3, "context": ", Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al.", "startOffset": 27, "endOffset": 58}, {"referenceID": 3, "context": ", Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al.", "startOffset": 27, "endOffset": 89}, {"referenceID": 3, "context": ", Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al. (2007)).", "startOffset": 27, "endOffset": 110}, {"referenceID": 3, "context": ", Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al. (2007)). In this paper we take a thorough look at FTL in the case when the losses are linear, but the problem perhaps exhibits other regularities. The motivation comes from the simple observation that, for prediction over the simplex, when the loss vectors are selected independently of each other from a distribution with a bounded support with a nonzero mean, FTL quickly locks onto selecting the loss-minimizing vertex of the simplex, achieving finite expected regret. In this case, FTL is arguably an excellent algorithm. In fact, FTL is shown to be the minimax optimizer for the binary losses in the stochastic expert setting in the paper of Kot\u0142owski (2016). Thus, we ask the question of whether there are other regularities that allow FTL to achieve nontrivial performance guarantees.", "startOffset": 27, "endOffset": 767}, {"referenceID": 3, "context": ", Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al. (2007)). In this paper we take a thorough look at FTL in the case when the losses are linear, but the problem perhaps exhibits other regularities. The motivation comes from the simple observation that, for prediction over the simplex, when the loss vectors are selected independently of each other from a distribution with a bounded support with a nonzero mean, FTL quickly locks onto selecting the loss-minimizing vertex of the simplex, achieving finite expected regret. In this case, FTL is arguably an excellent algorithm. In fact, FTL is shown to be the minimax optimizer for the binary losses in the stochastic expert setting in the paper of Kot\u0142owski (2016). Thus, we ask the question of whether there are other regularities that allow FTL to achieve nontrivial performance guarantees. Our main result shows that when the decision set (or constraint set) has a sufficiently \u201ccurved\u201d boundary (equivalently, if it is strongly convex) and the linear loss is bounded away from 0, FTL is able to achieve logarithmic regret even in the adversarial setting, thus opening up a new way to prove fast rates not based on the curvature of losses, but on that of the boundary of the constraint set and non-singularity of the linear loss. In a matching lower bound we show that this regret bound is essentially unimprovable. We also show an alternate bound for polytope constraint sets, which allows us to prove that (under certain technical conditions) for stochastic problems the expected regret of FTL will be finite. To finish, we use (A, B)-prod of Sani et al. (2014) to design an algorithm that adaptively interpolates between the worst case O( \u221a n logn) regret and the smaller regret bounds, which we prove here for \u201ceasy data.", "startOffset": 27, "endOffset": 1669}, {"referenceID": 3, "context": ", Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al. (2007)). In this paper we take a thorough look at FTL in the case when the losses are linear, but the problem perhaps exhibits other regularities. The motivation comes from the simple observation that, for prediction over the simplex, when the loss vectors are selected independently of each other from a distribution with a bounded support with a nonzero mean, FTL quickly locks onto selecting the loss-minimizing vertex of the simplex, achieving finite expected regret. In this case, FTL is arguably an excellent algorithm. In fact, FTL is shown to be the minimax optimizer for the binary losses in the stochastic expert setting in the paper of Kot\u0142owski (2016). Thus, we ask the question of whether there are other regularities that allow FTL to achieve nontrivial performance guarantees. Our main result shows that when the decision set (or constraint set) has a sufficiently \u201ccurved\u201d boundary (equivalently, if it is strongly convex) and the linear loss is bounded away from 0, FTL is able to achieve logarithmic regret even in the adversarial setting, thus opening up a new way to prove fast rates not based on the curvature of losses, but on that of the boundary of the constraint set and non-singularity of the linear loss. In a matching lower bound we show that this regret bound is essentially unimprovable. We also show an alternate bound for polytope constraint sets, which allows us to prove that (under certain technical conditions) for stochastic problems the expected regret of FTL will be finite. To finish, we use (A, B)-prod of Sani et al. (2014) to design an algorithm that adaptively interpolates between the worst case O( \u221a n logn) regret and the smaller regret bounds, which we prove here for \u201ceasy data.\u201d We also show that if the constraint set is the unit ball, both the follow the regularized leader (FTRL) algorithm and a combination of FTL and shrinkage, which we call follow the shrunken leader (FTSL), achieve logarithmic regret for easy data. Simulation results on artificial data complement the theoretical findings. While we believe that we are the first to point out that the curvature of the constraint set W can help in speeding up learning, this effect is known in convex optimization since at least the work of Levitin and Polyak (1966), who showed that exponential rates are attainable for strongly convex constraint sets if the norm of the gradients of the objective function admit a uniform lower bound.", "startOffset": 27, "endOffset": 2378}, {"referenceID": 3, "context": ", Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al. (2007)). In this paper we take a thorough look at FTL in the case when the losses are linear, but the problem perhaps exhibits other regularities. The motivation comes from the simple observation that, for prediction over the simplex, when the loss vectors are selected independently of each other from a distribution with a bounded support with a nonzero mean, FTL quickly locks onto selecting the loss-minimizing vertex of the simplex, achieving finite expected regret. In this case, FTL is arguably an excellent algorithm. In fact, FTL is shown to be the minimax optimizer for the binary losses in the stochastic expert setting in the paper of Kot\u0142owski (2016). Thus, we ask the question of whether there are other regularities that allow FTL to achieve nontrivial performance guarantees. Our main result shows that when the decision set (or constraint set) has a sufficiently \u201ccurved\u201d boundary (equivalently, if it is strongly convex) and the linear loss is bounded away from 0, FTL is able to achieve logarithmic regret even in the adversarial setting, thus opening up a new way to prove fast rates not based on the curvature of losses, but on that of the boundary of the constraint set and non-singularity of the linear loss. In a matching lower bound we show that this regret bound is essentially unimprovable. We also show an alternate bound for polytope constraint sets, which allows us to prove that (under certain technical conditions) for stochastic problems the expected regret of FTL will be finite. To finish, we use (A, B)-prod of Sani et al. (2014) to design an algorithm that adaptively interpolates between the worst case O( \u221a n logn) regret and the smaller regret bounds, which we prove here for \u201ceasy data.\u201d We also show that if the constraint set is the unit ball, both the follow the regularized leader (FTRL) algorithm and a combination of FTL and shrinkage, which we call follow the shrunken leader (FTSL), achieve logarithmic regret for easy data. Simulation results on artificial data complement the theoretical findings. While we believe that we are the first to point out that the curvature of the constraint set W can help in speeding up learning, this effect is known in convex optimization since at least the work of Levitin and Polyak (1966), who showed that exponential rates are attainable for strongly convex constraint sets if the norm of the gradients of the objective function admit a uniform lower bound. More recently, Garber and Hazan (2015) proved an O(1/n2) optimization error bound (with problem-dependent constants) for the Frank-Wolfe algorithm for strongly convex and smooth objectives and strongly convex constraint sets.", "startOffset": 27, "endOffset": 2587}, {"referenceID": 0, "context": "The effect of the shape of the constraint set was also discussed by Abbasi-Yadkori (2010) who demonstrated O( \u221a n) regret in the linear bandit setting.", "startOffset": 68, "endOffset": 90}, {"referenceID": 15, "context": "The result is a direct corollary of Lemma 9 of McMahan (2010), which holds for any sequence of losses, even in the lack of convexity.", "startOffset": 47, "endOffset": 62}, {"referenceID": 15, "context": "The result is a direct corollary of Lemma 9 of McMahan (2010), which holds for any sequence of losses, even in the lack of convexity. It is also a tightening of the well-known inequality Rn \u2264 \u2211n t=1 `t(wt)\u2212 `t(wt+1), which again holds for arbitrary loss sequences (e.g., Lemma 2.1 of Shalev-Shwartz (2012)).", "startOffset": 47, "endOffset": 306}, {"referenceID": 14, "context": "A related concept that has been used in convex optimization to show fast rates is that of a strongly convex constraint set (Levitin and Polyak, 1966; Garber and Hazan, 2015): W is \u03bb-strongly convex with respect to the norm \u2016\u00b7\u2016 if, for any x, y \u2208 W and \u03b3 \u2208 [0, 1], the \u2016\u00b7\u2016-ball with origin \u03b3x+ (1\u2212 \u03b3)y and radius \u03b3(1 \u2212 \u03b3)\u03bb \u2016x\u2212 y\u2016 /2 is included in W.", "startOffset": 123, "endOffset": 173}, {"referenceID": 9, "context": "A related concept that has been used in convex optimization to show fast rates is that of a strongly convex constraint set (Levitin and Polyak, 1966; Garber and Hazan, 2015): W is \u03bb-strongly convex with respect to the norm \u2016\u00b7\u2016 if, for any x, y \u2208 W and \u03b3 \u2208 [0, 1], the \u2016\u00b7\u2016-ball with origin \u03b3x+ (1\u2212 \u03b3)y and radius \u03b3(1 \u2212 \u03b3)\u03bb \u2016x\u2212 y\u2016 /2 is included in W.", "startOffset": 123, "endOffset": 173}, {"referenceID": 22, "context": "4Following Schneider (2014), a convex body of Rd is any non-empty, compact, convex subset of Rd.", "startOffset": 11, "endOffset": 28}, {"referenceID": 21, "context": "One way to design an adaptive algorithm is to use the (A, B)-prod algorithm of Sani et al. (2014), trivially leading to the following result: Proposition 4.", "startOffset": 79, "endOffset": 98}, {"referenceID": 21, "context": "One way to design an adaptive algorithm is to use the (A, B)-prod algorithm of Sani et al. (2014), trivially leading to the following result: Proposition 4.1. Consider (A, B)-prod of Sani et al. (2014), where algorithm A is chosen to be FTRL with an appropriate regularization term, while B is chosen to be FTL.", "startOffset": 79, "endOffset": 202}, {"referenceID": 1, "context": "Our proof follows the idea of Abernethy et al. (2008). We compute the upper bound on the value of the game for each round backwards for t = n, n\u2212 1, .", "startOffset": 30, "endOffset": 54}, {"referenceID": 23, "context": ", (Shalev-Shwartz, 2012).", "startOffset": 2, "endOffset": 24}, {"referenceID": 1, "context": "\u201cHalf-adversarial\u201d data The half-adversarial data used in this experiment is the optimal solution for the adversary in the linear game when W is the unit ball (Abernethy et al., 2008).", "startOffset": 159, "endOffset": 183}, {"referenceID": 17, "context": "Condition (ii), which is actually the definition of Polovinkin (1996) for strongly convex sets, means that W can be obtained as the intersection of closed balls of radius 1/\u03bb, such that there is one ball for every boundary point w and tangent hyperplane P where the ball touches P in w.", "startOffset": 52, "endOffset": 70}, {"referenceID": 11, "context": ", by Example 13 of Journ\u00e9e et al. (2010). Proof.", "startOffset": 19, "endOffset": 41}, {"referenceID": 11, "context": ", by Example 13 of Journ\u00e9e et al. (2010). Proof. We show that (i) implies (ii), (ii) implies (iii), and (iii) implies (i). We start with showing that (i) implies (ii). First note that all principal curvatures of the d-dimensional ball B = B1/\u03bb(0) with radius 1/\u03bb (centered at the origin) are \u03bb. Therefore, (i) and Theorem 3.2.9 of Schneider (2014) implies that there is a convex body M such that W +M = B, where for two sets, S1, S2 \u2282 R, S1 +S2 is defined as {s1 + s2 | s1 \u2208 S1, s2 \u2208 S2}.", "startOffset": 19, "endOffset": 348}, {"referenceID": 19, "context": "1 of Pressley (2010), the curvature of \u03b3 at p can be obtained as f \u2032\u2032(s) \u221a 1 + f \u2032(s)2 \u2223\u2223\u2223\u2223 s=0 = f \u2032\u2032(0) .", "startOffset": 5, "endOffset": 21}], "year": 2017, "abstractText": "The follow the leader (FTL) algorithm, perhaps the simplest of all online learning algorithms, is known to perform well when the loss functions it is used on are convex and positively curved. In this paper we ask whether there are other \u201clucky\u201d settings when FTL achieves sublinear, \u201csmall\u201d regret. In particular, we study the fundamental problem of linear prediction over a non-empty convex, compact domain. Amongst other results, we prove that the curvature of the boundary of the domain can act as if the losses were curved: In this case, we prove that as long as the mean of the loss vectors have positive lengths bounded away from zero, FTL enjoys a logarithmic growth rate of regret, while, e.g., for polytope domains and stochastic data it enjoys finite expected regret. Building on a previously known meta-algorithm, we also get an algorithm that simultaneously enjoys the worst-case guarantees and the bound available for FTL.", "creator": "LaTeX with hyperref package"}}}