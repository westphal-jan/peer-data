{"id": "1702.04282", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Feb-2017", "title": "T-SKIRT: Online Estimation of Student Proficiency in an Adaptive Learning System", "abstract": "we study t - skirt : a temporal, structured - knowledge, irt - based method for predicting student responses online. by improving accounting for student learning and employing a structured, empirical representation of student proficiencies, the matrix outperforms standard web - based methods on an online response prediction task when applied to real responses collected evaluating students viewed with diverse pools of educational content.", "histories": [["v1", "Tue, 14 Feb 2017 16:42:49 GMT  (137kb,D)", "http://arxiv.org/abs/1702.04282v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["chaitanya ekanadham", "yan karklin"], "accepted": false, "id": "1702.04282"}, "pdf": {"name": "1702.04282.pdf", "metadata": {"source": "META", "title": "T-SKIRT: Online Estimation of Student Proficiency in an Adaptive Learning System", "authors": ["Chaitanya Ekanadham", "Yan Karklin"], "emails": ["CHAITU@KNEWTON.COM", "YAN@KNEWTON.COM"], "sections": [{"heading": "1. Introduction", "text": "Accurately predicting student responses is an important task for adaptive learning systems. Better predictions enable more efficient diagnosis and remediation of student deficiencies. When reported as analytics, these predictions can also provide the student or teacher with actionable information to improve student outcomes. Traditional approaches mostly consider single-session assessments (e.g., a standardized examination), but to work in learning environments, adaptive systems must deal with significant challenges:\n\u2022 student knowledge states are constantly fluctuating, due to online or offline learning, forgetting, and varying levels of engagement with the content\n\u2022 lack of control over the user experience: students may do different, unrelated, assignments on their own schedule, and at different paces\n\u2022 student paths through content are often heavily correlated for pedagogical reasons (contrary to an ideal\nProceedings of the 31 st International Conference on Machine Learning, Lille, France, 2015. JMLR: W&CP volume 37. Copyright 2015 by the author(s).\nrandomized controlled trial) and may include repeat attempts and/or be subject to selection bias\n\u2022 up-to-date predictions must be available as soon as a new response is made (imagine a student aces a quiz and submits, then gets recommended similar material)\n\u2022 accurate inferences and sensible recommendations must be made even at the beginning of a session, when little data about the student is available\n\u2022 the pool of content is very diverse: fitting a model of student responses to one set of content may not generalize to another set. Furthermore, relationships between content are difficult to establish and represent in the model, even given expert labels (Lindsey et al., 2014).\nBayesian Knowledge Tracing (BKT) is a framework that explicitly models student learning (Corbett & Anderson, 1994) but it accounts for diversity in neither students nor content. On the other hand, Item Response Theory (IRT) is a framework for modeling responses by estimating both student and content properties (Rasch, 1960; Lord, 1980), but it does not account for student learning. Several recent efforts have attempted to combine the complementary benefits of these two frameworks, with some success (Gonza\u0301lez-Brenes et al., 2013; Khajah et al., 2014; SohlDickstein, 2013; Lan et al., 2014). However, a few gaps remain: First, the way in which these models are evaluated is not consistent with the requirements of an adaptive learning system, which has access to all previous responses and is tasked with predicting the outcome of one or more prospective pairings of students and questions. Instead, model performance is gauged by predicting randomly held out chunks of responses (which is not a realistic task even if these responses are in the future and contiguous in time) for each student, or all responses for a randomly chosen subset of students (an approach that does not leverage currently available information). Second, the benefit of temar X iv :1 70 2.\n04 28\n2v 1\n[ cs\n.A I]\n1 4\nFe b\n20 17\nporal methods over standard IRT methods has not been empirically observed. This could be due to high correlation in student paths through the content (observed in some of our data as well). Third, previous models either do not account for multiple dimensions of knowledge, or assume they can be modelled independently. Finally, data are typically collected via a highly instrumented and standardized system (intelligent tutoring system), which is unlike several other online learning environments.\nWe develop a unified IRT-based model that allows for student and item parameters, temporal fluctuation of student abilities, and content diversity. We compare this model with standard IRT models on an evaluation task identical to that performed in a production setting: predicting the next response given all previous responses to date. Our findings are twofold: First, incorporating temporality into our model yields a significant performance boost. Second, modeling multiple dimensions of knowledge along with the connections between them (based on labels from subject matter experts) provides additional improvement in performance."}, {"heading": "2. Background", "text": ""}, {"heading": "2.1. Knowledge tracing", "text": "Knowledge tracing (Corbett & Anderson, 1994) (KT) is a framework for modeling the process of students mastering one or more skills while completing a sequence of assessments. At each time t, Zt is an unobserved binary variable indicating whether the student has mastered the skill or not, and Xt is an observed binary variable indicating the correctness value of the completed assessment. A Hidden Markov Model is used to capture the statistical relationships between these. Emission probabilities govern how likely a correct response is given each hidden state. Transition probabilities govern how a student transitions between the hidden states. Several KT variants have been proposed to individually handle student abilities, multiple skills, assessment difficulty, and external aids (see (Khajah et al., 2014) and the references therein). In (Gonza\u0301lez-Brenes et al., 2013; Khajah et al., 2014), a unifying framework for these is proposed where the probabilities are parameterized in terms of these observed features."}, {"heading": "2.2. Item response theory", "text": "Item response theory (IRT) (Lord, 1980; Rasch, 1993) is a framework for modeling binary student responses on a set of assessments. In the two-parameter formulation the probability that a student s answers an assessment q correctly is given by:\npsq = f(\u03b1q(\u03b8s \u2212 \u03b2q)) (1)\nwhere \u03b8s is the student proficiency, \u03b2q is the assessment difficulty, and \u03b1q is the assessment discrimination which governs how sensitive the correctness probability is to the students proficiency. The function f(.) is known as the item response function and increases monotonically from 0 to 1. We choose f(x) = \u03a6(x), the cumulative distribution function of the normal distribution. This model is known as the two-parameter ogive, or 2PO model (Rasch, 1993).\nAn underlying assumption of this model is that student abilities (\u03b8s) remain constant over time, making this more applicable to responses from an examination rather than a learning experience over an extended period of time. In (Gonza\u0301lez-Brenes et al., 2013) and (Sohl-Dickstein, 2013), the IRT framework is augmented to handle temporal fluctuations in student proficiencies. However, the benefits over standard IRT were not empirically realized in the former, while the latter required considerable amount of computing resources and time to fit.\nNote also that none of the models in the KT or IRT families have been rigorously evaluated on the online prediction task."}, {"heading": "3. T-SKIRT", "text": ""}, {"heading": "3.1. Temporality", "text": "We extend the 2PO model by modeling the student proficiencies over time as a Wiener process. Under this model, the conditional relationships are given by\nP (\u03b8t+\u03c4 |\u03b8t) = \u03c6\u03b8t,\u03bd2\u03c4 (\u03b8t+\u03c4 ) (2) where \u03c6\u00b5,\u03c32(.) is the probability density function of the normal distribution with mean \u00b5 and variance \u03c32. The proportionality constant \u03bd2 on the conditional variance is a model parameter, tuned to maximize prediction accuracy on a separate dataset). Under this model, the joint probability over responses and proficiencies for a single student is given by:\nP (r1:t, \u03b81:t) = P (r1:t|\u03b81:t)P (\u03b81:t) (3)\n= P (\u03b81) t\u220f i=2 P (\u03b8i|\u03b8i\u22121) t\u220f i=1 P (ri|\u03b8i)\n= \u03c6\u00b50,\u03c320 (\u03b81) t\u220f i=2 \u03c6\u03b8i\u22121,\u03bd2(\u03b8i) t\u220f i=1 prii (1\u2212 pi) 1\u2212ri\nwhere pi = \u03a6(\u03b1qi(\u03b8i \u2212 \u03b2qi)) is the probability of correct on the i\u2032th response to question qi, as per Eq. 1. The primary task is to infer the posterior distribution over the current proficiencies \u03b8t given all past responses. We assume that item parameters have been learned previously\nand are fixed. Let r1:n and \u03b81:n denote sequences of binary responses and real-valued proficiencies, respectively. The posterior is then given by:\nP (\u03b8t|r1:t) \u221d P (r1:t|\u03b8t)P (\u03b8t) (4)\nTo evaluate the first term on the right-hand side, it is necessary to integrate out all possible paths \u03b81:t\u22121:\nP (r1:t|\u03b8t) = \u222b P (r1:t, \u03b81:t\u22121|\u03b8t)d\u03b81:t\u22121\nHowever, computing this integral is expensive, especially in an online setting. For computational efficiency, we make the following approximation:\nP (r1:t|\u03b8t) \u2248 t\u220f i=1 P (ri|\u03b8t)\n= t\u220f i=1 \u222b P (ri, |\u03b8i)P (\u03b8i|\u03b8t)d\u03b8i\n= t\u220f i=1 \u222b prii (1\u2212 pi) 1\u2212ri\u03c6\u03b8t,\u03bd2(t\u2212i)(\u03b8i)d\u03b8i (5)\nUsing the definition of pi and the fact that \u222b\n\u03a6(\u03b1(x \u2212 \u03b2))\u03c6\u00b5,\u03c32(x)dx = \u03a6 ( \u03b1(\u03b2\u2212\u00b5)\u221a 1+\u03b12\u03c32 ) , we can simplify this to:\nP (r1:t|\u03b8t) \u2248 t\u220f i=1 p\u0303rii (1\u2212 p\u0303i) 1\u2212ri (6)\nwhere:\np\u0303i = \u03a6(\u03b1\u0303i(\u03b8t \u2212 \u03b2qi))\n\u03b1\u0303i = \u03b1qi\u221a\n1 + \u03b12qi\u03bd 2(t\u2212 i)\n(7)\nNote that this formulation is exactly the same as the likelihood under a non-temporal IRT model, with \u03b1qi replaced by \u03b1\u0303i. Therefore, we refer to \u03b1\u0303i as the \u201ceffective discrimination\u201d of the i\u2019th response on the student\u2019s current proficiency \u03b8t. Note that the further back in time the response, the lower the effective discrimination and thus the smaller effect it has on the posterior over \u03b8t in Eq. 4. Finally, we can substitute Eq. 6 into Eq. 4 and take the log to get the approximate log-posterior:\nlogP (\u03b8t|r1:t) \u2248 logP (\u03b8t) + t\u2211 i=1 ri log(p\u0303i) (8)\n+ (1\u2212 ri) log(p\u0303i) (9)"}, {"heading": "3.2. Structured, multidimensional prior over student proficiencies", "text": "When the content pool is very diverse, summarizing student proficiency with a single number (varying over time) may not be enough to capture the student response patterns. Content can be organized into groups against which student proficiency is measured. These groups have been referred to as knowledge components (Corbett et al., 1997) or skills (Lindsey et al., 2014; Lan et al., 2014). The content used in our experiments has been grouped by subject matter experts into groups called concepts. Each student\u2019s proficiency at a single time is now represented by a vector of proficiencies in each concept, ~\u03b8t \u2208 RC where C is the total number of concepts. The IRT likelihood (Eq. 1) can then be rewritten as:\npsq = f(\u03b1q(\u03b8scq \u2212 \u03b2q)) (10)\nwhere cq is the concept assessed by question q.\nExperts also identify prerequisite relationships between concepts indicating that content in one concept cannot be mastered without having mastered content in another concept. For more details see (Wilson & Nichols, 2014). These concepts and prerequisite relationships define a directed acyclic graph, and from this we can define a prior distribution over ~\u03b8t that captures the conceptual relationships (similar to how expert labels were used in (Lindsey et al., 2014)). We employ a specific multivariate Gaussian prior whose log-probability is given by:\nlogP (~\u03b8t) = \u2212\u03bb N\u2211 n=1 \u03b82tn \u2212 \u03b3 \u2211 n,m:n\u227am (\u03b8n \u2212 \u03b8m)2 (11)\nwhere \u03b8tn is the n\u2019th element of the vector ~\u03b8t, n \u227a m indicates that concept n is prerequisite to concept m, and the parameters \u03bb and \u03b3 control the overall variance and relative correlations, respectively. Note that the precision matrix has non-zero entries along the diagonal and only for pairs of concepts that have a prerequisite relationship. This defines a prior over proficiencies at any fixed point in time. In order to incorporate this into the temporal model, we make the following approximation for computational tractability:\nP (~\u03b8i|~\u03b8t) \u2248 \u220f n P (\u03b8in|\u03b8tn) (12)\nwhich allows us to have a multivariate analog of Eq. 9:\nlogP (~\u03b8t|r1:t) \u2248 logP (~\u03b8t) + t\u2211 i=1 ri log(p\u0303i) (13)\n+ (1\u2212 ri) log(p\u0303i) (14)\nSubstituting Eq. 11 into Eq. 14 gives:\nlogP (~\u03b8t|r1:t) \u2248\u2212 \u03bb N\u2211 n=1 \u03b82tn (15)\n\u2212 \u03b3 \u2211\nn,m:n\u227am (\u03b8n \u2212 \u03b8m)2\n+ t\u2211 i=1 ri log(p\u0303i) + (1\u2212 ri) log(p\u0303i)"}, {"heading": "4. Experimental setup", "text": "Data was collected from a variety of educational products integrated with Knewton\u2019s adaptive learning platform and used in various classroom settings across the world. These products vary with respect to the educational content used (disciplines spanned math, science, and English language learning) as well as the way in which students are guided through the content. For example, students may take an initial assessment and then be remediated on areas needing improvement. In other products, student start from the beginning and work toward a predefined goal set by the teacher. In all of these settings, Knewton receives data about each interaction (anonymized student id, content module id, correctness, and timestamp).\nWe utilized approximately 1M responses of 6.3K randomly sampled students on 105.6K questions spanning roughly 4 months. Students who worked on fewer than 5 questions total were excluded. For each student/question pair, only the most recent 4 responses were used to avoid long strings of multiple attempts on questions. After pre-processing, student history lengths ranged from 5 to 3.2K responses, including repeat attempts (see Fig 1). The overall percent correct of these responses is 54.6%."}, {"heading": "5. Results", "text": "We compare the following student response models:\n\u2022 student percent-correct (SPC): predict correct if and only if the majority of previous responses for the student are correct.\n\u2022 2PO IRT: standard ogive model, equivalent to Eq. 9 with \u03bd = 0 and \u03bb = 1.0.\n\u2022 2PO temporal IRT: same as above but with \u03bd = 10.0.\n\u2022 Factorial MVN 2PO IRT: factorial multivariate Gaussian prior on proficiencies per concept (labelled by experts), using Eq. 15 with \u03bd = 0, \u03b3 = 0 and \u03bb = 1.0.\n\u2022 Correlated MVN 2PO IRT: same as above but with \u03b3 = 0.5.\n\u2022 Correlated MVN temporal 2PO IRT (T-SKIRT): same as above but with \u03b3 = 0.5, \u03bd = 0.1.\nTo compare model performance in a task relevant for online adaptive learning systems, we measured the accuracy of predicting each student response given only the previous history of that student. For the SPC model this amounts to predicting correct if the majority of previous interactions are correct. For models with latent student abilities, this entails estimating \u03b8t (or ~\u03b8t for multi-dimensional proficiency models) by maximizing the logarithm of the (approximate) posterior probability (Eq. 9 for single-dimensional, Eq. 15 for multi-dimensional). Note that both of these objective functions are convex w.r.t. the proficiencies and are easily optimized using first- or second-order gradient-based methods. We use this estimate to predict the correctness of the next interaction via Eq. 10, and record the fraction of predictions that matched the observed responses.\nThe data was split into two parts. The first was used to estimate item difficulties (\u03b2q\u2019s) and discriminations (\u03b1q\u2019s) using a standard 2PO IRT model with normal priors (\u03b2q \u223c N (0, 1), \u03b1q \u223c N (1, 0.5)). The parameters \u03bb, \u03b2, \u03bd2 were also tuned to optimize prediction accuracy on this data set. The second data set was used to evaluate and compare the models.\nThe results are summarized in Table. 5. Adding a temporal component to the standard 2PO IRT model (using the effective discriminations in Eq. 7) yields a 2% increase in\naccuracy. Using multidimensional proficiencies based on conceptual groupings identified by experts gives a 1.6% increase. Adding information about conceptual relationships (using a correlated multivariate prior) brings this improvement to 1.9%. Combining the multidimensional prior with the temporal component yields a total of 2.8% improvement over standard 2PO IRT.\nFigure 3 plots the improvement per student as a function of the student\u2019s overall fraction of correct responses, illustrating that the majority of the improvement comes from responses for students that are most difficult to predict. TSKIRT does slightly worse than 2PO IRT for students who are doing very well or very poorly, and we are investigating why it underperforms in this regime.\nModel Accuracy \u00b1 1 SEM AUC SPC 0.7085 \u00b1 0.0021 n/a 2PO IRT 0.7201 \u00b1 0.0018 0.7954 2PO temporal IRT 0.7420 \u00b1 0.0018 0.8119 Spherical MVN 2PO IRT 0.7362 \u00b1 0.0016 0.8056 Correlated MVN 2PO IRT 0.7390 \u00b1 0.0016 0.8110 T-SKIRT 0.7478 \u00b1 0.0016 0.8194"}, {"heading": "6. Conclusions", "text": "We developed a model, T-SKIRT, for predicting student responses that addresses two major challenges faced by an adaptive learning system: accounting for student learning and handling diversity in student ability and content properties. We evaluated this model on a task required in a production environment (predicting the next response of a student given all previous responses) and found that it gives superior predictions over standard IRT-based models when applied to real student data despite the large variability in content discipline, grade level, and learning environment.\nIn contrast to (Gonza\u0301lez-Brenes et al., 2013), incorporating temporality into the model yielded significant benefits over standard IRT. We also found that conceptual groupings and prerequisite relationships provided by experts also yielded significant improvement in contrast with (Lindsey et al., 2014) where expert labels did not yield better predictions.\nOur model can be improved or extended in several ways. For example, the temporal model can be augmented to account for observable events where learning is likely to occur (e.g., completing a lesson, using learning aids or hints). The model can also be extended to account for more gradual learning or forgetting of material by incorporating drift terms into the Wiener process prior. Another area of active research focuses on whether concept-module and inter-concept relationships can be automatically determined from data within this framework (e.g., (Lindsey et al., 2014; Lan et al., 2014)) and encoded in a structured prior over student proficiencies. Finally, our inference method makes an approximation of conditional independence for the sake of tractability \u2013 we find that this yields improved performance, but are also investigating the theoretical validity of this approximation."}], "references": [{"title": "Knowledge tracing: Modeling the acquisition of procedural knowledge", "author": ["Corbett", "Albert T", "Anderson", "John R"], "venue": "User modeling and user-adapted interaction,", "citeRegEx": "Corbett et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Corbett et al\\.", "year": 1994}, {"title": "Intelligent tutoring systems", "author": ["Corbett", "Albert T", "Koedinger", "Kenneth R", "Anderson", "John R"], "venue": "Handbook of human computer interaction,", "citeRegEx": "Corbett et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Corbett et al\\.", "year": 1997}, {"title": "Integrating knowledge tracing and item response theory: A tale of two frameworks", "author": ["Khajah", "Mohammad M", "Huang", "Yun", "Gonz\u00e1lez-Brenes", "Jos\u00e9 P", "Mozer", "Michael C", "Brusilovsky", "Peter"], "venue": "Personalization Approaches in Learning Environments,", "citeRegEx": "Khajah et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Khajah et al\\.", "year": 2014}, {"title": "Time-varying learning and content analytics via sparse factor analysis", "author": ["Lan", "Andrew S", "Studer", "Christoph", "Baraniuk", "Richard G"], "venue": "In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "Lan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lan et al\\.", "year": 2014}, {"title": "Automatic discovery of cognitive skills to improve the prediction of student learning", "author": ["Lindsey", "Robert V", "Khajah", "Mohammad", "Mozer", "Michael C"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Lindsey et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lindsey et al\\.", "year": 2014}, {"title": "Applications of item response theory to practical testing problems", "author": ["Lord", "Frederic M"], "venue": null, "citeRegEx": "Lord and M.,? \\Q1980\\E", "shortCiteRegEx": "Lord and M.", "year": 1980}, {"title": "Studies in mathematical psychology: I. probabilistic models for some intelligence and attainment tests", "author": ["Rasch", "Georg"], "venue": null, "citeRegEx": "Rasch and Georg.,? \\Q1960\\E", "shortCiteRegEx": "Rasch and Georg.", "year": 1960}, {"title": "Probabilistic models for some intelligence and attainment tests", "author": ["Rasch", "Georg"], "venue": "ERIC,", "citeRegEx": "Rasch and Georg.,? \\Q1993\\E", "shortCiteRegEx": "Rasch and Georg.", "year": 1993}, {"title": "Personalized learning and temporal modeling at khan academy", "author": ["Sohl-Dickstein", "Jascha"], "venue": "In Workshop on Data Driven Education in Neural Information Processing Systems (NIPS), Lake Tahoe,", "citeRegEx": "Sohl.Dickstein and Jascha.,? \\Q2013\\E", "shortCiteRegEx": "Sohl.Dickstein and Jascha.", "year": 2013}], "referenceMentions": [{"referenceID": 4, "context": "Furthermore, relationships between content are difficult to establish and represent in the model, even given expert labels (Lindsey et al., 2014).", "startOffset": 123, "endOffset": 145}, {"referenceID": 2, "context": "Several recent efforts have attempted to combine the complementary benefits of these two frameworks, with some success (Gonz\u00e1lez-Brenes et al., 2013; Khajah et al., 2014; SohlDickstein, 2013; Lan et al., 2014).", "startOffset": 119, "endOffset": 209}, {"referenceID": 3, "context": "Several recent efforts have attempted to combine the complementary benefits of these two frameworks, with some success (Gonz\u00e1lez-Brenes et al., 2013; Khajah et al., 2014; SohlDickstein, 2013; Lan et al., 2014).", "startOffset": 119, "endOffset": 209}, {"referenceID": 2, "context": "Several KT variants have been proposed to individually handle student abilities, multiple skills, assessment difficulty, and external aids (see (Khajah et al., 2014) and the references therein).", "startOffset": 144, "endOffset": 165}, {"referenceID": 2, "context": "In (Gonz\u00e1lez-Brenes et al., 2013; Khajah et al., 2014), a unifying framework for these is proposed where the probabilities are parameterized in terms of these observed features.", "startOffset": 3, "endOffset": 54}, {"referenceID": 1, "context": "These groups have been referred to as knowledge components (Corbett et al., 1997) or skills (Lindsey et al.", "startOffset": 59, "endOffset": 81}, {"referenceID": 4, "context": ", 1997) or skills (Lindsey et al., 2014; Lan et al., 2014).", "startOffset": 18, "endOffset": 58}, {"referenceID": 3, "context": ", 1997) or skills (Lindsey et al., 2014; Lan et al., 2014).", "startOffset": 18, "endOffset": 58}, {"referenceID": 4, "context": "These concepts and prerequisite relationships define a directed acyclic graph, and from this we can define a prior distribution over ~ \u03b8t that captures the conceptual relationships (similar to how expert labels were used in (Lindsey et al., 2014)).", "startOffset": 224, "endOffset": 246}], "year": 2017, "abstractText": "We develop T-SKIRT: a temporal, structuredknowledge, IRT-based method for predicting student responses online. By explicitly accounting for student learning and employing a structured, multidimensional representation of student proficiencies, the model outperforms standard IRTbased methods on an online response prediction task when applied to real responses collected from students interacting with diverse pools of educational content.", "creator": "LaTeX with hyperref package"}}}