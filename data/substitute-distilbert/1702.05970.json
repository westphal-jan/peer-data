{"id": "1702.05970", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Feb-2017", "title": "Automatic Liver and Tumor Segmentation of CT and MRI Volumes using Cascaded Fully Convolutional Neural Networks", "abstract": "automatic segmentation of the lung and hepatic lesions is an important step that deriving quantitative biomarkers for accurate clinical diagnosis and computer - aided decision support systems. this paper presents a method to automatically segment clusters and lesions in ct and mri abdomen images using cascaded locally processed neural networks ( cfcns ) : the segmentation of a large - scale medical trial demonstrating quantitative image analysis. we train and cascade two sensors for a combined scan of the liver and medicare lesions. in the first step, we train a fcn to segment the liver as roi input for initial migration checkpoint. the second fcn solely segments lesions within the predicted liver areas of step 1. cfcn models were trained on an abdominal exam dataset comprising 100 hepatic tumor volumes. validations on both datasets show efficient cfcn - based semantic liver and lesion segmentation achieves objective scores over 94 % to liver with computation times below rs per cell. we further experimentally demonstrate the robustness of the proposed method accompanying an upstream mri liver tumor volumes and the public 3dircad dataset.", "histories": [["v1", "Mon, 20 Feb 2017 13:52:57 GMT  (3920kb,D)", "http://arxiv.org/abs/1702.05970v1", "Under Review"], ["v2", "Thu, 23 Feb 2017 15:02:59 GMT  (3921kb,D)", "http://arxiv.org/abs/1702.05970v2", "Under Review"]], "COMMENTS": "Under Review", "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["patrick ferdinand christ", "florian ettlinger", "felix gr\\\"un", "mohamed ezzeldin a elshaera", "jana lipkova", "sebastian schlecht", "freba ahmaddy", "sunil tatavarty", "marc bickel", "patrick bilic", "markus rempfler", "felix hofmann", "melvin d anastasi", "seyed-ahmad ahmadi", "georgios kaissis", "julian holch", "wieland sommer", "rickmer braren", "volker heinemann", "bjoern menze"], "accepted": false, "id": "1702.05970"}, "pdf": {"name": "1702.05970.pdf", "metadata": {"source": "CRF", "title": "Automatic Liver and Tumor Segmentation of CT and MRI Volumes using Cascaded Fully Convolutional Neural Networks", "authors": ["Patrick Christ", "Florian Ettlinger", "Felix Gr\u00fcn", "Mohamed Ezzeldin A. Elshaer", "Jana Lipkov\u00e1", "Sebastian Schlecht", "Freba Ahmaddy", "Sunil Tatavarty", "Marc Bickel", "Patrick Bilic", "Markus Rempfler", "Felix Hofmann", "Melvin D\u2019Anastasi", "Seyed-Ahmad Ahmadi", "Georgios Kaissis", "Julian Holch", "Wieland Sommer", "Rickmer Braren", "Volker Heinemann", "Bjoern Menze"], "emails": [], "sections": [{"heading": null, "text": "Automatic segmentation of the liver and hepatic lesion is an important step towards deriving quantitative biomarkers for accurate clinical diagnosis and computer-aided decision support systems. This paper presents a method to automatically segment liver and lesions in CT and MRI abdomen images using cascaded fully convolutional neural networks (CFCNs) enabling the segmentation of a large-scale medical trial or quantitative image analysis. We train and cascade two FCNs for a combined segmentation of the liver and its lesions. In the first step, we train a FCN to segment the liver as ROI input for a second FCN. The second FCN solely segments lesions within the predicted liver ROIs of step 1. CFCN models were trained on an abdominal CT dataset comprising 100 hepatic tumor volumes. Validations on further datasets show that CFCN-based semantic liver and lesion segmentation achieves Dice scores over 94% for liver with computation times below 100s per volume. We further experimentally demonstrate the robustness of the proposed method on an 38 MRI liver tumor volumes and the public 3DIRCAD dataset.\nKeywords: Liver, Lesion, Segmentation, FCN, CRF, Deep Learning"}, {"heading": "1. Introduction", "text": ""}, {"heading": "1.1. Motivation", "text": "Anomalies in the shape and texture of the liver and visible lesions in CT are important biomarkers for initial disease diagnosis and progression in both primary and secondary hepatic tumor disease [1].\nPrimary tumors such as breast, colon and pancreas cancer often spread metastases to the liver during the course of disease. Therefore, the liver and its lesions are analyzed in\n1Authors contributed equally\nPreprint submitted to Medical Image Analysis February 21, 2017\nar X\niv :1\n70 2.\n05 97\n0v 1\n[ cs\n.C V\n] 2\n0 Fe\nprimary tumor staging. In addition, the liver is also a site of primary tumor disease such as Hepatocellular carcinoma (HCC). Hepatocellular carcinoma (HCC) presents the sixth-most common cancer and the third-most common cause of cancer-related deaths worldwide [2]. HCC comprises a genetically and molecularly highly heterogeneous group of cancers that commonly arise in a chronically damaged liver. Importantly, HCC subtypes differ significantly in clinical outcome. The stepwise transformation to HCC is accompanied by major changes in tissue architecture including an increase in cellularity and a switch in vascular supply (i.e. arterialization). These quantifiable changes in tissue architecture provide the basis for the non-invasive detection of HCC in imaging [3], but also lead to highly variable structures and shapes.\nIn clinical routine, manual or semi-manual segmentation techniques are applied. These, however, are subjective, operator-dependent and very time-consuming. In order to improve the productivity of radiologists, computer-aided methods have been developed in the past. However, an automated robust segmentation of combined liver and lesion remains still an open problem because of challenges as a low-contrast between liver and lesion, different types of contrast levels (hyper-/hypo-intense tumors), abnormalities in tissues (such as after surgical resection of metastasis), size and varying number of lesions. As shown in figure 1 the heterogeneity in liver and lesion contrast is very large among subjects. Different acquisition protocols, differing contrast-agents, varying levels of contrast enhancements and dissimilar scanner resolutions lead to unpredictable intensity differences between liver and lesion tissue. This complexity of contrast differences make it difficult for intensity-based methods to generalize to unseen test cases from different clinical sites. In addition, the varying shape of lesions due to irregular tumor growth and response to treatment (i.e surgical resection) reduce efficiency of the shape based methods."}, {"heading": "1.2. Related Works", "text": "Nevertheless, several interactive and automatic methods have been developed to segment the liver and liver lesions in CT volumes. In 2007 and 2008, two Grand Challenges benchmarks on liver and liver lesion segmentation have been conducted [1, 4]. Methods presented at the challenges were mostly based on statistical shape models. Furthermore, grey level and texture based methods have been developed [1]. Recent work on liver and lesion segmentation employs graph cut and level set techniques [5, 6, 7], sigmoid edge modeling [8] or manifold and machine learning [9, 10, 11, 12]. However, these methods are not widely applied in clinics, due to their speed and robustness on heterogeneous, low-contrast real-life CT data. To overcome these weaknesses, interactive methods were still developed [13] to overcome these weaknesses.\nDeep Convolutional Neural Networks (CNN) have gained a new attention in the scientific community for solving computer vision tasks such as object recognition, classification and segmentation [14, 15], often out-competing state-of-the art methods. Most importantly, CNN methods have proven to be highly robust to varying image appearance, which motivates us to apply them to fully automatic liver and lesions segmentation in CT volumes.\nSemantic image segmentation methods based on fully convolutional neural networks FCN were developed in [15], with impressive results in natural image segmentation competitions\n[16, 17]. Likewise, new segmentation methods based on CNN and FCNs were developed for medical image analysis, with highly competitive results compared to state-of-the-art. [18, 19, 20, 21, 22, 23, 24, 25]."}, {"heading": "1.3. Contribution:", "text": "In this work, we demonstrate the combined automatic segmentation of the liver and its lesions in low-contrast heterogeneous medical volumes. Our contributions are three-fold. First, we train and apply fully convolutional CNN on CT volumes of the liver for the first time, demonstrating the adaptability to challenging segmentation of hepatic liver lesions. Second, we propose to use a cascaded fully convolutional neural network (CFCN) on CT slices, which segments liver and lesions sequentially, leading to significantly higher segmentation quality, as demonstrated on a public challenge dataset. Third, we experimentally demonstrate the generalization and scalability of our methods to different modalities and diverse real-life datasets, including a novel DW-MRI dataset and a clinical CT dataset. A preliminary version of this work was presented in MICCAI 2016 [26] and will be presented at ISBI 20172. In this paper, we have substantially revised and extended the original papers. The main modifications include an elaborated description of the proposed methods, an analysis of underlying design principles and architectures as well as the application to\n2Reference will be added after publication\nnew datasets and modalities.\nIn the following sections, we will describe our proposed pipeline (2.1) including CFCN (2.3) and 3D CRF (2.4). The experiments are illustrated in section (3)."}, {"heading": "2. Methods", "text": ""}, {"heading": "2.1. Overview of our proposed segmentation workflow", "text": "Our proposed segmentation workflow is depicted in figure 2. The workflow consists of three major parts. The first part (e.g. section 2.2) deals with data preprocessing and preparation for the neural network segmentation part 2 (e.g. section 2.3). In the neural network segmentation part, two cascaded fully convolutional neural networks first segment the liver and then lesions within the liver region-of-interest (ROI). The calculated probabilities of CFCN will be refined using a dense 3D conditional random field to produce the final segmentation result in the part three."}, {"heading": "2.2. Data preparation", "text": "The following section deals with data preprocessing and augmentation for CT data. Preprocessing was carried out in a slice-wise fashion. First, the Hounsfield unit values were windowed in the range [\u2212100, 400] to exclude irrelevant organs and objects. Figure 3 shows the effect of our applied preprocessing to a raw medical slice. We increased contrast through histogram equalization. Figure 3 shows also the final slice after HU-windowing and contrastenhancement. The contrast within the liver has been enhanced to allow better differentiation of abnormal liver tissue. For DW-MRI the data preparation scheme is similar and differs in the data normalization, which additionally performs N4bias correction [27].\nAs in [18, 22], to teach the network the desired invariance properties, several data augmentations steps, such as elastic deformation, translation, rotation and addition of Gaussian noise with standard deviation of the current slice, have been employed to increase the training data for the CFCN. Our data augmentation schemes can be found in our sourcecode3."}, {"heading": "2.3. Cascaded Fully Convolutional Neural Network", "text": "In the following section, we denote the 3D image volume as I, the total number of voxels as N and the set of possible labels as L = {0, 1, . . . , l}. For each voxel i, we define a variable xi \u2208 L that denotes the assigned label. The probability of a voxel i belonging to label k given the image I is described by P (xi = k|I) and will be modelled by the FCN. In our particular study, we use L = {0, 1, 2} for background, liver and lesion, respectively.\n3Sourcecode and models are available at https://github.com/IBBM/Cascaded-FCN"}, {"heading": "2.3.1. From AlexNET to UNET", "text": "Long et al. (2015) presented the first fully convolutional network architecture for semantic segmentation [15]. The main idea in their work is to replace the last fully connected layers of a classification network such as the AlexNet [14] with fully convolutional layers to allow dense pixel-wise predictions. The last fully convolutional layers have to be upscaled to match the input dimensions. In comparison to prior work, the AlexFCN allows pixelwise prediction from full-sized medical slices, instead of patch-wise classification. Figures 4a and 4b show the training curves for training the AlexFCN (without class balancing) on 3DIRCAD dataset. Both training curves converged fast to a steady state in training and test Dice overlap. Both training curves show a large overfitting of the AlexFCN without class balancing, with Dice overlaps of 71%/90% in test/training data for liver, and 24%/60% for lesions. In general the lesion Dice of 24% at test time is comparable low. Long et al. (2015) explicitly stated that they did not need to apply class balancing to their natural image segmentation problem. A reason for this is that they used pretrained AlexNet weights trained on natural images, i.e. ImageNet data. However, for many medical applications it is mandatory to apply class balancing since pre-trained networks from natural images cannot be used properly and the class of interest occurs more seldomly in the dataset. Figures 4c and 4d show the importance of class balancing in medical image segmentation. The training and test Dice for both liver and lesions increases noticeably to 78% for liver and 38% for lesions. A further large improvement can be obtained by applying the UNET Architecture proposed by Ronneberger et al. (2015) [18]. Besides the increased depth of 19 layers and learnable upscaling (up-convolution), the UNET provides a superior design pattern of skip connections between different stages of the neural network.\nIn early stages of the neural network, spatial information is present in the activations of the current stage. In later stages of the neural network, spatial information gets transferred to semantic information at sacrifice of spatial information due to small sizes of activations of 28x28 in the UNET bottleneck. Ronneberger et al. introduced skip-connections to allow\nutilization of spatial and semantic information at later stage, since the spatial information from earlier stage can be fused in the neural network at later stages. Thus the neural network at later stages can utilize semantic and spatial information to infer information."}, {"heading": "2.3.2. From FCN to CFCN", "text": "We used the UNet architecture [18] to compute the soft label probability maps P (xi|I). The UNet architecture enables accurate pixel-wise prediction by combining spatial and contextual information in a network architecture comprising 19 convolutional layers. Figures 4e and 4f show the training curves for the UNet on 3DIRCAD data set. The overall performance of the lesion segmentation is further increased to 53% test Dice. The UNet learned features to discriminate liver and lesion at the same time. As one of our main contributions, we propose a cascaded training of FCNs to learn specific features for solving a segmentation task once per training, which leads to higher segmentation performance.\nThe motivation behind the cascade approach is that it has been shown that UNets and other forms of CNNs learn a hierarchical representation of the provided data. The stacked layers of convolutional filters are tailored towards the desired classification in a data-driven manner, as opposed to designing hand-crafted features for separation of different tissue types. By cascading two UNets, we ensure that the UNet in step 1 learns filters that are specific for the detection and segmentation of the liver from an overall abdominal CT scan, while the UNet in step 2 arranges a set of filters for separation of lesions from the liver tissue. Furthermore, the liver ROI helps in reducing false positives for lesions. Figures 5 and 6 illustrate our proposed method. We train one network to segment the liver in abdomen slices (step 1). This network can solely concentrate on learning discriminative features for liver vs. background segmentation, e.g. figure 5. After that we train another network to segment the lesions, given an image of the liver (step 2). The segmented liver from step 1 is cropped and re-sampled to the required input size for the cascaded UNet in step 2. All nonliver regions are masked out and the second UNet can concentrate on learning discriminative features for lesion vs. liver background segmentation."}, {"heading": "2.3.3. Effect of Class Balancing", "text": "A crucial step in training FCNs is appropriate class balancing according to the pixel-wise frequency of each class in the data. In contrast to [15], we observed that training the network to segment small structures such as lesions is not possible without class balancing, due to the high class imbalance. Therefore we introduced an additional weighting factor \u03c9class in the cross entropy loss function L of the FCN.\nL = \u2212 1 n N\u2211 i=1 \u03c9classi [ P\u0302i logPi + (1\u2212 P\u0302i) log(1\u2212 Pi) ] (1)\nPi denotes the probability of voxel i belonging to the foreground, P\u0302i represents the ground truth. We chose \u03c9classi to be 1 |Pixels of Class xi=k| ."}, {"heading": "2.3.4. Transfer Learning and Pretraining", "text": "A common concept in deep learning is transfer learning using pretrained neural network models. Neural networks pretrained on a other task e.g. image classification can be used as initialization of the network weights when training on a new task e.g. image segmentation. The intuition behind this idea is, that also for other tasks or dataset the first layers of neural networks learn similar concepts to recognize basic structures such as blobs and edges. This concepts do not have be trained again from scratch when using pretrained models. For our experiments we used pretrained UNet models provided by Ronneberger et al. (2015), which were trained on cell image segmentation data [18]. We have released our trained models on liver and lesion segmentation to allow other researcher to start their training with learned liver and lesion concepts4."}, {"heading": "2.4. 3D Conditional Random Field", "text": "Volumetric FCN implementation with 3D convolutions was strongly limited by GPU hardware and available VRAM [21]. Recent work such as VNET and 3DUNET, allow nowadays 3D FCNs at decreased resolution [28, 29]. In addition, the anisotropic resolution of medical volumes (e.g. 0.57-0.8mm in xy and 1.25-4mm in z voxel dimension in 3DIRCADb) complicates the training of discriminative 3D filters. Instead, to capitalise on the locality information across slices within the dataset, we utilize 3D dense conditional random fields CRFs as proposed by [30]. To account for 3D information, we consider all slice-wise predictions of the FCN together in the CRF applied to the entire volume at once.\n4Sourcecode and models are available at https://github.com/IBBM/Cascaded-FCN\nWe formulate the final label assignment given the soft predictions (probability maps) from the FCN as maximum a posteriori (MAP) inference in a dense CRF, allowing us to consider both spatial coherence and appearance.\nWe specify the dense CRF following [30] on the complete graph G = (V , E) with vertices i \u2208 V for each voxel in the image and edges eij \u2208 E = {(i, j) \u2200i, j \u2208 V s.t. i < j} between all vertices. The variable vector x \u2208 LN describes the label of each vertex i \u2208 V . The energy function that induces the according Gibbs distribution is then given as:\nE(x) = \u2211 i\u2208V \u03c6i(xi) + \u2211 (i,j)\u2208E \u03c6ij(xi, xj) , (2)\nwhere \u03c6i(xi) = \u2212 logP (xi|I) are the unary potentials that are derived from the FCNs probabilistic output, P (xi|I). \u03c6ij(xi, xj) are the pairwise potentials, which we set to:\n\u03c6ij(xi, xj) = \u00b5(xi, xj) ( wpos exp ( \u2212 |pi\u2212pj | 2\n2\u03c32pos ) +wbil exp ( \u2212 |pi\u2212pj | 2\n2\u03c32bil \u2212 |Ii\u2212Ij | 2 2\u03c32int\n)) , (3)\nwhere \u00b5(xi, xj) = 1(xi 6= xj) is the Potts function, |pi \u2212 pj| is the spatial distance between voxels i and j and |Ii \u2212 Ij| is their intensity difference in the original image. The influence of the pairwise terms can be adjusted with their weights wpos and wbil and their effective range is tuned with the kernel widths \u03c3pos, \u03c3bil and \u03c3int.\nWe estimate the best labelling x\u2217 = arg minx\u2208LN E(x) using the efficient mean field approximation algorithm of [30]. The weights and kernels of the CRF were chosen using a random search algorithm."}, {"heading": "2.5. Quality measures", "text": "We assessed the performance of our proposed method using the quality metrics introduced in the grand challenges for liver and lesion segmentation by [1, 4].\nOur main metric is the Dice score. Additionally we report Jaccard coefficent (JC), Volume Overlap Error (VOE), Relative Volume Difference (RVD), Average Symmetric Surface Distance (ASD), Symmetric Maximum Surface Distance (MSD). Metrics are applied to binary valued volumes, so a metric computed on the lesions for example considers only lesion objects as foreground and everything else as background. We refer to the foreground object in the ground truth as object A, and object B for the predicted object."}, {"heading": "2.5.1. Dice score (DICE)", "text": "The Dice score or F1 measure is evalutes as:\nDICE(A,B) = 2|A \u2229B| |A|+ |B|\nwhere the Dice score is in the interval [0,1]. A perfect segmentation yields a Dice score of 1."}, {"heading": "2.5.2. Jaccard coefficient (JC)", "text": "The Jaccard coefficient is computed as follows :\nJC(A,B) = |A \u2229B| |A \u222aB|\nwhere the value is in the interval [0, 1]."}, {"heading": "2.5.3. Volume Overlap Error (VOE)", "text": "VOE is the just the complement of the Jaccard coefficient :\nV OE(A,B) = 1\u2212 JC(A,B)"}, {"heading": "2.5.4. Relative Volume Difference (RVD)", "text": "RVD is an asymmetric metric. All other metrics are symmetric and give no information whether there are more false positives or false negatives in the predicted segmentation. It is defined as follows :\nRVD(A,B) = |B| \u2212 |A| |A|\nIt is the fraction of the difference in volume sizes to the volume size of the ground truth object. If the predicted 3D object is smaller than the ground truth, the value is negative The value of RVD is theoretically in the range [\u22121, \u221e], with 0 being the best score when the volume size of the predicted object is exactly the same as the true object. Note however that RVD only measures volume quantities, with no regard to whether the objects overlap at all. A negative value indicates a smaller predicted object volume, and a positive value indicates a larger predicted object volume compared to the true object volume. RVD lacks symmetry and thus does not fulfil mathematical requirements for a metric."}, {"heading": "2.5.5. Average Symmetric Surface Distance (ASD)", "text": "ASD between two objects is calculated by first computing the surface of each object (the exterior voxels touching the background voxels), then a correspondence is built between each point on the surface of the first object with the closest point on the surface of the second object. Finally, the distances between all pairs are averaged; the denominator of of the average is the number of surface points of the first object."}, {"heading": "2.5.6. Maximum Surface Distance (MSD)", "text": "MSD is also known as the Symmetric Hausdorff Distance. Maximum Surface Distance (MSD) is similar to ASD, except that the maximum distance is taken instead of the average."}, {"heading": "3. Experiments and Results", "text": "For clinical routine usage, methods and algorithms have to be developed, trained and evaluated on heterogeneous real-life data. In this work we want to demonstrate the robustness, generalization and scalability of our proposed method by applying it to a public dataset for comparison (section 3.1), a clinical CT dataset (section 3.2) and finally a clinical MRI dataset (section 3.3)."}, {"heading": "3.1. 3DIRCAD", "text": ""}, {"heading": "3.1.1. Dataset", "text": "We evaluated our proposed method on the 3DIRCADb dataset5 [31]. In comparison to the grand challenge datasets, the 3DIRCADb dataset offers a higher variety and complexity of livers and its lesions and is publicly available. The 3DIRCADb dataset includes 20 venous phase enhanced CT volumes from various European hospitals with different CT scanners. For our study, we trained and evaluated our models using the 15 volumes containing hepatic tumors in the liver with 2-fold cross validation. The analyzed CT volumes differ substantially in the level of contrast-enhancement, size and number of tumor lesions (1 to 42)."}, {"heading": "3.1.2. Experimental setting", "text": "Data was prepared as described in section 2.2. Our data augmentation scheme lead to a total training data size of 22693 image slices. The CFCN were trained on a recent desktop PC with a single NVIDIA Titan X GPU with 12 GB VRAM. The neural networks were implemented and trained using the deep learning framework caffe [32] from University of Berkeley. We used stochastic gradient descent as optimizer with a learning rate of 0.001 and a momentum of 0.8. To reduce overfitting we applied a weight decay of 0.0005."}, {"heading": "3.1.3. Effect of Class Balancing", "text": "The effect of class balancing can be seen in figure 4a - 4d. Introducing class balancing improved the segmentation Dice score on both liver and lesion, while simultaneously decreasing over-fitting. The effect is less for liver, since the percentage of liver voxels in a CT abdomen dataset is on the order of 7%, in comparison to 0.25% for lesions. For all following experiments we accounted for class imbalance by weighting the imbalanced class according to its frequency in the dataset by introducing a weight factor described in section 2.3.3."}, {"heading": "3.1.4. Qualitative and quantitative results", "text": "The qualitative results of the automatic segmentation are presented in figure 7. The complex and heterogeneous structure of the liver and all lesions were detected in the shown images. The cascaded FCN approach yielded an enhancement for lesions with respect to segmentation accuracy compared to a single FCN as can be seen in figure 7. In general, we observe significant6 additional improvements for slice-wise Dice overlaps of liver segmentations, from mean Dice 93.1% to 94.3% after applying the 3D dense CRF. For lesions we could achieve a Dice score of 56%\u00b1 27% with a 2 fold cross-validation.\n5The dataset is available on http://ircad.fr/research/3d-ircadb-01 6Two-sided paired t-test with p-value < 4 \u00b7 10\u221219"}, {"heading": "3.2. Clinical Dataset CT", "text": ""}, {"heading": "3.2.1. Dataset", "text": "The second dataset we evaluated is a real-life clinical CT dataset from multiple CT scanners. It compromises 100 CT scans from different patients. The examined patients were suffering from different kind of cancerous diseases with different manifestations in the liver. The dataset ranges from single HCC lesions to diffusive and confluent metastatic lesions. In addition different contrast agents and therefore different levels of contrast enhancement are present in this dataset. Human rater ground truth was obtained through manual volumetric segmentation using the software TurtleSeg7 [35, 36]."}, {"heading": "3.2.2. Experimental setting", "text": "The clinical CT dataset was prepared and augmented in the same way as the 3DIRCAD dataset as described in 2.2. The data set was split in 60 for training, 20 for test and 20 for validation. The neural networks, where trained on the same setup and training parameters as the 3DIRCAD dataset. In this experiment, an Adam optimizer was applied with = 0.1 [37]."}, {"heading": "3.2.3. Qualitative and quantitative results", "text": "As shown in table 1 the Cascaded FCN and Cascaded FCN + 3DCRF reach up to 88% and 91% Dice score on this dataset. An inter-rater Dice comparison among 5 training cases yielded a Dice overlap score of 95%. Considering the inter-rater Dice score, the proposed method provides remarkable segmentations. Furthermore, our proposed method achieves a Dice overlap score of 61%\u00b1 25% for lesions on the validation set."}, {"heading": "3.3. Clinical Dataset MRI", "text": ""}, {"heading": "3.3.1. Dataset", "text": "To demonstrate the generalization to other modalities we employed our methods to a clinical DW-MRI dataset. 31 Patients underwent clinical assessment and MR imaging for the primary diagnosis of HCC. Imaging was performed using a 1.5 T clinical MRI scanner (Avanto, Siemens) with a standard imaging protocol including axial and coronal T2w, axial T1w images before and after application of Gadolinium-DTPA contrast agent. Diffusion weighted imaging was performed using a slice thickness of 5mm and a matrix size of 192 by 192."}, {"heading": "3.3.2. Experimental setting", "text": "In comparison to the CT datasets, the DW-MRI dataset was prepared differently. The DW-MRI dataset was normalized using the N4Bias correction algorithm [27]. Afterwards the same pre-processing steps were carried out as for CT. The CFCN for the DW-MRI dataset, where trained on the same hardware and training setup. The optimizer in this experiment was an Adam optimizer with = 0.1.\n7www.turtleseg.com"}, {"heading": "3.3.3. Qualitative and quantitative results", "text": "As seen in figure 8, the CFCN was able to segment the liver lesion correctly. In both cases the CFCN undersegments the lesion leading to a Dice score of 85% in both cases. The quantitative segmentation results are shown in table 1. The Cascaded UNET was able to reach a dice score for liver in MR-DWI of 87%. For lesion we found a mean dice score of 69.7%."}, {"heading": "3.4. HCC Survival Prediction based on automatic liver and lesion segmentation", "text": "Accurate liver and lesion segmentation are necessary for advance medical image analysis. In this paragraph we want to introduce a possible applications of our automatic liver and lesion segmentation algorithms in medical imaging. Survival and outcome predictions are important fields in medical image analysis. For hepatic- cellular carcinoma HCC, prior work relied on manual liver and lesion segmentation in DW-MRI to calculate features over the liver and lesion ROI in the ADC sequence to predict patient survival. In contrast to prior work, we trained a CFCN to automatically segment liver and lesion segmentation in DW-MRI to allow automatic survival predictions. We formulate this task as a classification problem with classes being \u201clow risk\u201d and \u201chigh risk\u201d represented by longer or shorter survival times than the median survival. We predict HCC malignancy in two steps: As the first step we automatically segment HCC tumor lesions using our proposed method of cascaded fully convolutional neural networks (CFCN). As the second step we predict the HCC lesions\u2019 malignancy from the HCC tumor segmentation in the MR-DWI sequence using classical texture features and 3D CNN features. As one of our main contributions we found, that endto-end assessment of tumor malignancy based on our proposed cascaded fully convolutional neural networks (CFCN) corresponds to assessment based on expert annotations with high significance (p > 0.95). Detailed information can be found in Christ, Ettlinger & Kaissis et al. (2017)8."}, {"heading": "4. Discussion", "text": ""}, {"heading": "4.1. Combined segmentation and clinical relevance", "text": "In comparison to state-of-the-art, such as [8, 6, 5, 33], we presented a framework, which is capable of a combined segmentation of the liver and its lesion. Moreover, we presented the clinical relevance of our proposed method by utilisation of our automatic segmentations to derive quantitative medical insights. Furthermore, and in contrast to prior work such as [1, 38, 39, 40], our proposed method could be generalized to segment the liver and lesion in different modalities and also multiple organs in medical data. As recent results from natural image segmentation indicate, fully convolutional networks are capable of segmenting dozens of labels with ease. In addition with a runtime per slice of 0.19ms and 0.59ms our proposed method enables automatic segmentation of large-scale clinical trials in days and not months 9 using a single desktop PC.\n8Reference will be added after Publication 9Estimating 3000 CT volumes for a large-scale clinical trial"}, {"heading": "4.2. 3D CNN and FCN Architectures", "text": "Recent works such as DeepMedic [22], the V-NET [28] and the 3D UNet [29] became possible due to efficient implementations of 3D convolutions on GPUs, and they show promising results on their respective segmentation tasks. The proposed idea of cascaded FCN could also be applied to novel 3D CNN and 3D FCN architectures. The restriction of the Region of Interest ROI to relevant organs as shown for the 2D UNET, when restricting to liver only pixels for segmenting lesions, significantly boosts the segmentation accuracy. The intuition that more specific filters for the underlying problem could be trained, when restricting the relevant regions, holds for 3D as well. Future work will show whether 3D architectures could cope with less training data available for lesion segmentation."}, {"heading": "4.3. 3D Conditional Random Field", "text": "We showed a statistically significant improvement of segmentation quality, when applying the 3DCRF to our segmentation problem. However, tuning of hyperparameters such as those of the 3DCRF is very time-consuming and task dependent. We found that for highly heterogeneous structures in shape and appearance, such as HCC lesions, it is hard to find a hyperparameter set that generalizes to unseen cases with a random search. A similar conclusion was made in [22] when applying a 3DCRF to heterogeneous brain lesions. Recent work successfully integrated the learning of the CRF hyperparameter in the training process [17]. This approach in combination with additional pairwise terms that incorporate prior knowlegde of the problem could lead to a improvement of the CRF for this task."}, {"heading": "5. Conclusion", "text": "Cascaded FCNs and dense 3D CRFs trained on CT volumes are suitable for automatic localization and combined volumetric segmentation of the liver and its lesions. Our proposed method competes with state-of-the-art. We provide our trained models under open-source license allowing fine-tuning for other medical applications in CT data 10. Additionally, we introduced and evaluated dense 3D CRF as a post-processing step for deep learning-based medical image analysis. Furthermore, and in contrast to prior work such as [8, 6, 5], our proposed method could be generalized to segment multiple organs in medical data using multiple cascaded FCNs. As future work, the application of further cascaded FCNs on lesions ROIs to classify malignancy of the lesions as well as advanced techniques such as data augmentation using adversarial networks could enhance the accuracy of the segmentation further. All in all, heterogeneous CT and DW-MRI volumes from different scanners and protocols can be segmented in under 100s each with the proposed approach. We conclude that CFCNs are promising tools for automatic analysis of liver and its lesions in clinical routine and large-scale clinical trials.\n10Trained models are available at https://github.com/IBBM/Cascaded-FCN"}], "references": [{"title": "Comparison and evaluation of methods for liver segmentation from ct datasets", "author": ["T. Heimann"], "venue": "IEEE Transactions on Medical Imaging", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Estimates of worldwide burden of cancer in 2008: Globocan 2008", "author": ["J. Ferlay", "H.-R. Shin", "F. Bray", "D. Forman", "C. Mathers", "D.M. Parkin"], "venue": "International Journal of Cancer 127 (12) ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "Editorial: 3d segmentation in the clinic: a grand challenge ii-liver tumor segmentation", "author": ["X. Deng", "G. Du"], "venue": "in: MICCAI Workshop", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "Automatic liver segmentation based on shape constraints and deformable graph cut in ct images", "author": ["G. Li", "X. Chen", "F. Shi", "W. Zhu", "J. Tian", "D. Xiang"], "venue": "Image Processing, IEEE Transactions on 24 (12) ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "A likelihood and local constraint level set model for liver tumor segmentation from ct volumes", "author": ["C. Li", "X. Wang", "S. Eberl", "M. Fulham", "Y. Yin", "J. Chen", "D.D. Feng"], "venue": "Biomedical Engineering, IEEE Transactions on 60 (10) ", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Tumor burden analysis on computed tomography by automated liver and tumor segmentation", "author": ["M.G. Linguraru", "W.J. Richbourg", "J. Liu", "J.M. Watt", "V. Pamulapati", "S. Wang", "R.M. Summers"], "venue": "Medical Imaging, IEEE Transactions on 31 (10) ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Improved segmentation of low-contrast lesions using sigmoid edge model", "author": ["A.H. Foruzan", "Y.-W. Chen"], "venue": "International Journal of Computer Assisted Radiology and Surgery ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Metastatic liver tumour segmentation from discriminant grassmannian manifolds", "author": ["S. Kadoury", "E. Vorontsov", "A. Tang"], "venue": "Physics in Medicine and Biology 60 (16) ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Liver tumors segmentation from cta images using voxels classification and affinity constraint propagation", "author": ["M. Freiman", "O. Cooper", "D. Lischinski", "L. Joskowicz"], "venue": "International Journal of Computer Assisted Radiology and Surgery 6 (2) ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Automatic liver tumor segmentation in follow-up ct scans: Preliminary method and results", "author": ["R. Vivanti", "A. Ephrat", "L. Joskowicz", "N. Lev-Cohain", "O.A. Karaaslan", "J. Sosna"], "venue": "in: International Workshop on Patch-based Techniques in Medical Imaging, Springer", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Semi-automatic liver tumor segmentation with hidden markov measure field model and non-parametric distribution estimation", "author": ["Y. H\u00e4me", "M. Pollari"], "venue": "Medical Image Analysis 16 (1) ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "in: NIPS", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "U-net: Convolutional networks for biomedical image segmentation", "author": ["O. Ronneberger", "P. Fischer", "T. Brox"], "venue": "in: MICCAI, Vol. 9351", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Detection of glands and villi by collaboration of domain knowledge and deep learning", "author": ["J. Wang", "J.D. MacKenzie", "R. Ramachandran", "D.Z. Chen"], "venue": "in: MICCAI", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep feature learning for knee cartilage segmentation using a triplanar convolutional neural network", "author": ["A. Prasoon", "K. Petersen", "C. Igel", "F. Lauze", "E. Dam", "M. Nielsen"], "venue": "in: MICCAI, Vol. 16", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "18  B", "author": ["K. Kamnitsas", "C. Ledig", "V.F. Newcombe", "J.P. Simpson", "A.D. Kane", "D.K. Menon", "D. Rueckert"], "venue": "Glocker, Efficient multi-scale 3d cnn with fully connected crf for accurate brain lesion segmentation, Medical Image Analysis 36 ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2017}, {"title": "Deeporgan: Multi-level deep convolutional networks for automated pancreas segmentation", "author": ["H.R. Roth", "L. Lu", "A. Farag", "H.-C. Shin", "J. Liu", "E.B. Turkbey", "R.M. Summers"], "venue": "in: MICCAI", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2015}, {"title": "Parallel multi-dimensional lstm", "author": ["M.F. Stollenga", "W. Byeon", "M. Liwicki", "J. Schmidhuber"], "venue": "with application to fast biomedical volumetric image segmentation, in: Advances in Neural Information Processing Systems", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "M", "author": ["P.F. Christ", "M.E.A. Elshaer", "F. Ettlinger", "S. Tatavarty", "M. Bickel", "P. Bilic", "M. Rempfler", "M. Armbruster", "F. Hofmann"], "venue": "D\u2019Anastasi, W. H. Sommer, S.-A. Ahmadi, B. H. Menze, Automatic Liver and Lesion Segmentation in CT Using Cascaded Fully Convolutional Neural Networks and 3D Conditional Random Fields, MICCAI, Cham", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2016}, {"title": "N4ITK: Improved N3 bias correction", "author": ["N.J. Tustison", "B.B. Avants", "P.A. Cook", "Y. Zheng", "A. Egan", "P.A. Yushkevich", "J.C. Gee"], "venue": "IEEE Transactions on Medical Imaging 29 (6) ", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2010}, {"title": "V-net: Fully convolutional neural networks for volumetric medical image segmentation", "author": ["F. Milletari", "N. Navab", "S.-A. Ahmadi"], "venue": "in: 3D Vision (3DV), 2016 Fourth International Conference on, IEEE", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2016}, {"title": "3d u-net: learning dense volumetric segmentation from sparse annotation", "author": ["\u00d6. \u00c7i\u00e7ek", "A. Abdulkadir", "S.S. Lienkamp", "T. Brox", "O. Ronneberger"], "venue": "in: International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2016}, {"title": "Efficient inference in fully connected crfs with gaussian edge potentials", "author": ["P. Kr\u00e4henb\u00fchl", "V. Koltun"], "venue": "in: NIPS", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2011}, {"title": "J", "author": ["L. Soler", "A. Hostettler", "V. Agnus", "A. Charnoz", "J. Fasquel", "J. Moreau", "A. Osswald", "M. Bouhadjar"], "venue": "Marescaux, 3d image reconstruction for comparison of algorithm database: a patient-specific anatomical and medical image database ", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2012}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "in: Proceedings of the ACM International Conference on Multimedia, ACM", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2014}, {"title": "Semi-automated liver ct segmentation using laplacian meshes", "author": ["G. Chartrand", "T. Cresson", "R. Chav", "A. Gotra", "A. Tang", "J. DeGuise"], "venue": "in: ISBI, IEEE", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2014}, {"title": "Fully Convolutional Network for Liver Segmentation and Lesions Detection", "author": ["A. Ben-Cohen", "I. Diamant", "E. Klang", "M. Amitai", "H. Greenspan"], "venue": "Springer International Publishing, Cham", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2016}, {"title": "Spotlight: Automated confidence-based user guidance for increasing efficiency in interactive 3d image segmentation", "author": ["A. Top", "G. Hamarneh", "R. Abugharbieh"], "venue": "in: MICCAI", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2010}, {"title": "Active learning for interactive 3d image segmentation", "author": ["A. Top", "G. Hamarneh", "R. Abugharbieh"], "venue": "in: MICCAI, Vol. 6893", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2011}, {"title": "A 3-d liver segmentation method with parallel computing for selective internal radiation therapy", "author": ["M. Goryawala", "M.R. Guillen", "M. Cabrerizo", "A. Barreto", "S. Gulec", "T.C. Barot", "R.R. Suthar", "R.N. Bhatt", "A. Mcgoron", "M. Adjouadi"], "venue": "Transactions on Information Technology in Biomedicine 16 (1) ", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2012}, {"title": "J", "author": ["F. L\u00f3pez-Mir", "P. Gonz\u00e1lez", "V. Naranjo", "E. Pareja", "S. Morales"], "venue": "Solaz-M\u0131\u0301nguez, A method for liver segmentation on computed tomography images in venous phase suitable for real environments, Journal of Medical Imaging and Health Informatics 5 (6) ", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2015}, {"title": "Liver segmentation with constrained convex variational model", "author": ["J. Peng", "Y. Wang", "D. Kong"], "venue": "Pattern Recognition Letters 43 ", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "Anomalies in the shape and texture of the liver and visible lesions in CT are important biomarkers for initial disease diagnosis and progression in both primary and secondary hepatic tumor disease [1].", "startOffset": 197, "endOffset": 200}, {"referenceID": 1, "context": "Hepatocellular carcinoma (HCC) presents the sixth-most common cancer and the third-most common cause of cancer-related deaths worldwide [2].", "startOffset": 136, "endOffset": 139}, {"referenceID": 0, "context": "In 2007 and 2008, two Grand Challenges benchmarks on liver and liver lesion segmentation have been conducted [1, 4].", "startOffset": 109, "endOffset": 115}, {"referenceID": 2, "context": "In 2007 and 2008, two Grand Challenges benchmarks on liver and liver lesion segmentation have been conducted [1, 4].", "startOffset": 109, "endOffset": 115}, {"referenceID": 0, "context": "Furthermore, grey level and texture based methods have been developed [1].", "startOffset": 70, "endOffset": 73}, {"referenceID": 3, "context": "Recent work on liver and lesion segmentation employs graph cut and level set techniques [5, 6, 7], sigmoid edge modeling [8] or manifold and machine learning [9, 10, 11, 12].", "startOffset": 88, "endOffset": 97}, {"referenceID": 4, "context": "Recent work on liver and lesion segmentation employs graph cut and level set techniques [5, 6, 7], sigmoid edge modeling [8] or manifold and machine learning [9, 10, 11, 12].", "startOffset": 88, "endOffset": 97}, {"referenceID": 5, "context": "Recent work on liver and lesion segmentation employs graph cut and level set techniques [5, 6, 7], sigmoid edge modeling [8] or manifold and machine learning [9, 10, 11, 12].", "startOffset": 88, "endOffset": 97}, {"referenceID": 6, "context": "Recent work on liver and lesion segmentation employs graph cut and level set techniques [5, 6, 7], sigmoid edge modeling [8] or manifold and machine learning [9, 10, 11, 12].", "startOffset": 121, "endOffset": 124}, {"referenceID": 7, "context": "Recent work on liver and lesion segmentation employs graph cut and level set techniques [5, 6, 7], sigmoid edge modeling [8] or manifold and machine learning [9, 10, 11, 12].", "startOffset": 158, "endOffset": 173}, {"referenceID": 8, "context": "Recent work on liver and lesion segmentation employs graph cut and level set techniques [5, 6, 7], sigmoid edge modeling [8] or manifold and machine learning [9, 10, 11, 12].", "startOffset": 158, "endOffset": 173}, {"referenceID": 9, "context": "Recent work on liver and lesion segmentation employs graph cut and level set techniques [5, 6, 7], sigmoid edge modeling [8] or manifold and machine learning [9, 10, 11, 12].", "startOffset": 158, "endOffset": 173}, {"referenceID": 10, "context": "To overcome these weaknesses, interactive methods were still developed [13] to overcome these weaknesses.", "startOffset": 71, "endOffset": 75}, {"referenceID": 11, "context": "Deep Convolutional Neural Networks (CNN) have gained a new attention in the scientific community for solving computer vision tasks such as object recognition, classification and segmentation [14, 15], often out-competing state-of-the art methods.", "startOffset": 191, "endOffset": 199}, {"referenceID": 12, "context": "[18, 19, 20, 21, 22, 23, 24, 25].", "startOffset": 0, "endOffset": 32}, {"referenceID": 13, "context": "[18, 19, 20, 21, 22, 23, 24, 25].", "startOffset": 0, "endOffset": 32}, {"referenceID": 14, "context": "[18, 19, 20, 21, 22, 23, 24, 25].", "startOffset": 0, "endOffset": 32}, {"referenceID": 15, "context": "[18, 19, 20, 21, 22, 23, 24, 25].", "startOffset": 0, "endOffset": 32}, {"referenceID": 16, "context": "[18, 19, 20, 21, 22, 23, 24, 25].", "startOffset": 0, "endOffset": 32}, {"referenceID": 17, "context": "[18, 19, 20, 21, 22, 23, 24, 25].", "startOffset": 0, "endOffset": 32}, {"referenceID": 18, "context": "A preliminary version of this work was presented in MICCAI 2016 [26] and will be presented at ISBI 2017.", "startOffset": 64, "endOffset": 68}, {"referenceID": 19, "context": "For DW-MRI the data preparation scheme is similar and differs in the data normalization, which additionally performs N4bias correction [27].", "startOffset": 135, "endOffset": 139}, {"referenceID": 12, "context": "As in [18, 22], to teach the network the desired invariance properties, several data augmentations steps, such as elastic deformation, translation, rotation and addition of Gaussian noise with standard deviation of the current slice, have been employed to increase the training data for the CFCN.", "startOffset": 6, "endOffset": 14}, {"referenceID": 15, "context": "As in [18, 22], to teach the network the desired invariance properties, several data augmentations steps, such as elastic deformation, translation, rotation and addition of Gaussian noise with standard deviation of the current slice, have been employed to increase the training data for the CFCN.", "startOffset": 6, "endOffset": 14}, {"referenceID": 11, "context": "The main idea in their work is to replace the last fully connected layers of a classification network such as the AlexNet [14] with fully convolutional layers to allow dense pixel-wise predictions.", "startOffset": 122, "endOffset": 126}, {"referenceID": 12, "context": "(2015) [18].", "startOffset": 7, "endOffset": 11}, {"referenceID": 12, "context": "From FCN to CFCN We used the UNet architecture [18] to compute the soft label probability maps P (xi|I).", "startOffset": 47, "endOffset": 51}, {"referenceID": 12, "context": "(2015), which were trained on cell image segmentation data [18].", "startOffset": 59, "endOffset": 63}, {"referenceID": 14, "context": "Volumetric FCN implementation with 3D convolutions was strongly limited by GPU hardware and available VRAM [21].", "startOffset": 107, "endOffset": 111}, {"referenceID": 20, "context": "Recent work such as VNET and 3DUNET, allow nowadays 3D FCNs at decreased resolution [28, 29].", "startOffset": 84, "endOffset": 92}, {"referenceID": 21, "context": "Recent work such as VNET and 3DUNET, allow nowadays 3D FCNs at decreased resolution [28, 29].", "startOffset": 84, "endOffset": 92}, {"referenceID": 22, "context": "Instead, to capitalise on the locality information across slices within the dataset, we utilize 3D dense conditional random fields CRFs as proposed by [30].", "startOffset": 151, "endOffset": 155}, {"referenceID": 22, "context": "We specify the dense CRF following [30] on the complete graph G = (V , E) with vertices i \u2208 V for each voxel in the image and edges eij \u2208 E = {(i, j) \u2200i, j \u2208 V s.", "startOffset": 35, "endOffset": 39}, {"referenceID": 22, "context": "We estimate the best labelling x\u2217 = arg minx\u2208LN E(x) using the efficient mean field approximation algorithm of [30].", "startOffset": 111, "endOffset": 115}, {"referenceID": 0, "context": "We assessed the performance of our proposed method using the quality metrics introduced in the grand challenges for liver and lesion segmentation by [1, 4].", "startOffset": 149, "endOffset": 155}, {"referenceID": 2, "context": "We assessed the performance of our proposed method using the quality metrics introduced in the grand challenges for liver and lesion segmentation by [1, 4].", "startOffset": 149, "endOffset": 155}, {"referenceID": 0, "context": "where the Dice score is in the interval [0,1].", "startOffset": 40, "endOffset": 45}, {"referenceID": 0, "context": "where the value is in the interval [0, 1].", "startOffset": 35, "endOffset": 41}, {"referenceID": 23, "context": "Dataset We evaluated our proposed method on the 3DIRCADb dataset [31].", "startOffset": 65, "endOffset": 69}, {"referenceID": 24, "context": "The neural networks were implemented and trained using the deep learning framework caffe [32] from University of Berkeley.", "startOffset": 89, "endOffset": 93}, {"referenceID": 12, "context": "In the first row, the false positive lesion prediction in B of a single UNet as proposed by [18] were eliminated in C by CFCN as a result of restricting lesion segmentation to the liver ROI region.", "startOffset": 92, "endOffset": 96}, {"referenceID": 12, "context": "UNET as in [18] 3DIRCAD 39 87 19.", "startOffset": 11, "endOffset": 15}, {"referenceID": 3, "context": "[5] (liver-only) 3DIRCAD 9.", "startOffset": 0, "endOffset": 3}, {"referenceID": 25, "context": "[33] (semi-automatic) 3DIRCAD 6.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[6] (liver-only) 3DIRCAD 94.", "startOffset": 0, "endOffset": 3}, {"referenceID": 26, "context": "[34] (liver-only) Own Clinical CT 89 Cascaded UNET MR-DWI 23 14 5.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "Human rater ground truth was obtained through manual volumetric segmentation using the software TurtleSeg [35, 36].", "startOffset": 106, "endOffset": 114}, {"referenceID": 28, "context": "Human rater ground truth was obtained through manual volumetric segmentation using the software TurtleSeg [35, 36].", "startOffset": 106, "endOffset": 114}, {"referenceID": 19, "context": "The DW-MRI dataset was normalized using the N4Bias correction algorithm [27].", "startOffset": 72, "endOffset": 76}, {"referenceID": 6, "context": "In comparison to state-of-the-art, such as [8, 6, 5, 33], we presented a framework, which is capable of a combined segmentation of the liver and its lesion.", "startOffset": 43, "endOffset": 56}, {"referenceID": 4, "context": "In comparison to state-of-the-art, such as [8, 6, 5, 33], we presented a framework, which is capable of a combined segmentation of the liver and its lesion.", "startOffset": 43, "endOffset": 56}, {"referenceID": 3, "context": "In comparison to state-of-the-art, such as [8, 6, 5, 33], we presented a framework, which is capable of a combined segmentation of the liver and its lesion.", "startOffset": 43, "endOffset": 56}, {"referenceID": 25, "context": "In comparison to state-of-the-art, such as [8, 6, 5, 33], we presented a framework, which is capable of a combined segmentation of the liver and its lesion.", "startOffset": 43, "endOffset": 56}, {"referenceID": 0, "context": "Furthermore, and in contrast to prior work such as [1, 38, 39, 40], our proposed method could be generalized to segment the liver and lesion in different modalities and also multiple organs in medical data.", "startOffset": 51, "endOffset": 66}, {"referenceID": 29, "context": "Furthermore, and in contrast to prior work such as [1, 38, 39, 40], our proposed method could be generalized to segment the liver and lesion in different modalities and also multiple organs in medical data.", "startOffset": 51, "endOffset": 66}, {"referenceID": 30, "context": "Furthermore, and in contrast to prior work such as [1, 38, 39, 40], our proposed method could be generalized to segment the liver and lesion in different modalities and also multiple organs in medical data.", "startOffset": 51, "endOffset": 66}, {"referenceID": 31, "context": "Furthermore, and in contrast to prior work such as [1, 38, 39, 40], our proposed method could be generalized to segment the liver and lesion in different modalities and also multiple organs in medical data.", "startOffset": 51, "endOffset": 66}, {"referenceID": 15, "context": "Recent works such as DeepMedic [22], the V-NET [28] and the 3D UNet [29] became possible due to efficient implementations of 3D convolutions on GPUs, and they show promising results on their respective segmentation tasks.", "startOffset": 31, "endOffset": 35}, {"referenceID": 20, "context": "Recent works such as DeepMedic [22], the V-NET [28] and the 3D UNet [29] became possible due to efficient implementations of 3D convolutions on GPUs, and they show promising results on their respective segmentation tasks.", "startOffset": 47, "endOffset": 51}, {"referenceID": 21, "context": "Recent works such as DeepMedic [22], the V-NET [28] and the 3D UNet [29] became possible due to efficient implementations of 3D convolutions on GPUs, and they show promising results on their respective segmentation tasks.", "startOffset": 68, "endOffset": 72}, {"referenceID": 15, "context": "A similar conclusion was made in [22] when applying a 3DCRF to heterogeneous brain lesions.", "startOffset": 33, "endOffset": 37}, {"referenceID": 6, "context": "Furthermore, and in contrast to prior work such as [8, 6, 5], our proposed method could be generalized to segment multiple organs in medical data using multiple cascaded FCNs.", "startOffset": 51, "endOffset": 60}, {"referenceID": 4, "context": "Furthermore, and in contrast to prior work such as [8, 6, 5], our proposed method could be generalized to segment multiple organs in medical data using multiple cascaded FCNs.", "startOffset": 51, "endOffset": 60}, {"referenceID": 3, "context": "Furthermore, and in contrast to prior work such as [8, 6, 5], our proposed method could be generalized to segment multiple organs in medical data using multiple cascaded FCNs.", "startOffset": 51, "endOffset": 60}], "year": 2017, "abstractText": "Automatic segmentation of the liver and hepatic lesion is an important step towards deriving quantitative biomarkers for accurate clinical diagnosis and computer-aided decision support systems. This paper presents a method to automatically segment liver and lesions in CT and MRI abdomen images using cascaded fully convolutional neural networks (CFCNs) enabling the segmentation of a large-scale medical trial or quantitative image analysis. We train and cascade two FCNs for a combined segmentation of the liver and its lesions. In the first step, we train a FCN to segment the liver as ROI input for a second FCN. The second FCN solely segments lesions within the predicted liver ROIs of step 1. CFCN models were trained on an abdominal CT dataset comprising 100 hepatic tumor volumes. Validations on further datasets show that CFCN-based semantic liver and lesion segmentation achieves Dice scores over 94% for liver with computation times below 100s per volume. We further experimentally demonstrate the robustness of the proposed method on an 38 MRI liver tumor volumes and the public 3DIRCAD dataset.", "creator": "LaTeX with hyperref package"}}}