{"id": "1702.06478", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Feb-2017", "title": "Syst\\`emes du LIA \\`a DEFT'13", "abstract": "the 2013 d \\'efi de fouille de textes ( deft ) campaign is interested some two types of language analysis schemes, the document classification and the information extraction in the wider domain of cuisine recipes. we present the systems that the lia labs used in late 2013. our systems show interesting results, mainly though the complexity of the proposed protocols.", "histories": [["v1", "Tue, 21 Feb 2017 17:14:56 GMT  (15kb)", "http://arxiv.org/abs/1702.06478v1", "12 pages, 3 tables, (Paper in French)"]], "COMMENTS": "12 pages, 3 tables, (Paper in French)", "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["xavier bost", "ilaria brunetti", "luis adri\\'an cabrera-diego", "jean-val\\`ere cossu", "r\\'ea linhares", "mohamed morchid", "juan-manuel torres-moreno", "marc el-b\\`eze", "richard dufour"], "accepted": false, "id": "1702.06478"}, "pdf": {"name": "1702.06478.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Xavier Bost", "Ilaria Brunetti", "Luis Adri\u00e1n Cabrera-Diego", "Jean-Val\u00e8re Cossu", "Andr\u00e9a Linhares", "Mohamed Morchid", "Juan-Manuel Torres-Moreno", "Marc El-B\u00e8ze", "Richard Dufour"], "emails": ["prenom.nom@univ-avignon.fr"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 2.\n06 47\n8v 1\nThe 2013 D\u00e9fi de Fouille de Textes (DEFT) campaign is interested in two types of language analysis tasks, the document classification and the information extraction in the specialized domain of cuisine recipes. We present the systems that the LIA has used in DEFT 2013. Our systems show interesting results, even though the complexity of the proposed tasks.\nMOTS-CL\u00c9S : Classification de textes ; Extraction d\u2019information ; M\u00e9thodes statistiques ; Domaine de sp\u00e9cialit\u00e9.\nKEYWORDS: Text Classification ; Information Extraction ; Statistical Methods ; Speciality domain."}, {"heading": "1 Description des t\u00e2ches et des donn\u00e9es", "text": "Le D\u00e9fi Fouille de Textes (DEFT) s\u2019int\u00e9resse en 2013 \u00e0 deux types de fonction d\u2019analyse du langage, la classification de documents (t\u00e2ches 1 \u00e0 3) et l\u2019extraction d\u2019information (t\u00e2che 4), ceci dans un domaine de sp\u00e9cialit\u00e9 : les recettes de cuisine. Pour cette nouvelle \u00e9dition du d\u00e9fi 1, l\u2019\u00e9quipe du Laboratoire Informatique d\u2019Avi-\n1. http://deft.limsi.fr/2013/\ngnon (LIA) a d\u00e9cid\u00e9 de participer aux t\u00e2ches suivantes :\n\u2014 T1. L\u2019identification \u00e0 partir du titre et du texte de la recette de son niveau de difficult\u00e9 sur une \u00e9chelle \u00e0 4 niveaux : tr\u00e8s facile, facile, moyennement difficile, difficile ; \u2014 T2. L\u2019identification \u00e0 partir du titre et du texte de la recette du type de plat pr\u00e9par\u00e9 : entr\u00e9e, plat principal, dessert ; \u2014 T4. L\u2019extraction \u00e0 partir du titre et du texte d\u2019une recette de la liste de ses ingr\u00e9dients.\nLe corpus, fourni par DEFT au format XML, est compos\u00e9 de 13 684 recettes. Nous avons choisi d\u2019augmenter notre base de donn\u00e9es en extrayant des recettes de cuisine \u00e0 partir de 4 sites sp\u00e9cialis\u00e9s : Cuisine AZ (http://www.cuisineaz.fr), Madame Le Figaro (http://madame.lefigaro.fr/recettes), 750 grammes (http://www.750g.com/) et Ptit Chef (http://www.ptitchef.com/). Environ 50k recettes suppl\u00e9mentaires ont pu \u00eatre obtenues \u00e0 partir de ces sites. Notons cependant que les recettes t\u00e9l\u00e9charg\u00e9es ne comportaient pas toujours les m\u00eames champs d\u2019information que ceux contenus dans les recettes fournies par les organisateurs de la campagne.\n2 M\u00e9thodes utilis\u00e9es\nPour r\u00e9pondre \u00e0 ce d\u00e9fi, nous avons employ\u00e9 plusieurs m\u00e9thodes de classification (mod\u00e8les probabilistes discriminants, boosting de caract\u00e9ristiques textuelles) et d\u2019extraction d\u2019information, ainsi que leurs combinaisons."}, {"heading": "2.1 Mod\u00e8les discriminants", "text": "Le syst\u00e8me DISCOMP_LIA a \u00e9t\u00e9 appliqu\u00e9 aux t\u00e2ches 1 et 2. Son fonctionnement repose essentiellement sur les mod\u00e8les discriminants d\u00e9crits dans (Torres-Moreno et al., 2011). Ces mod\u00e8les servent aussi bien \u00e0 agglutiner des mots afin de produire des termes composites ayant un fort pouvoir discriminant (sans toutefois passer en dessous d\u2019un seuil pr\u00e9fix\u00e9 de couverture), qu\u2019\u00e0 pond\u00e9rer de fa\u00e7on plus appropri\u00e9e ces termes dans le calcul de l\u2019indice de similarit\u00e9 (ici Cosine revisit\u00e9e) entre chaque recette et le sac de mots de chacune des classes (3 ou 4 selon les t\u00e2ches).\nTrois nouveaut\u00e9s ont \u00e9t\u00e9 introduites pour prendre en compte les particularit\u00e9s du d\u00e9fi :\n\u2014 nous avons opt\u00e9 pour une approche hi\u00e9rarchique propre \u00e0 chacune des 2 t\u00e2ches : \u2014 pour la t\u00e2che T1 : identification du niveau facile ou difficile d\u2019une re-\ncette, puis dans chacun des 2 groupes, diff\u00e9renciation en 2 sous-groupes (moyennement ou tr\u00e8s difficile) ; \u2014 pour la t\u00e2che T2 : identification du type dessert ou autre ; dans le cas d\u2019une identification en type autre, diff\u00e9renciation entre plat principal et entr\u00e9e ; \u2014 nous avons appliqu\u00e9 le m\u00eame syst\u00e8me avec un param\u00e9trage ad hoc \u00e0 2 jeux\nde donn\u00e9es : le titre de la recette seul pour le premier et pour le second l\u2019ensemble form\u00e9 par le contenu et le titre de la recette. Une combinaison lin\u00e9aire entre les scores des 2 syst\u00e8mes a permis d\u2019obtenir une nouvelle distribution de probabilit\u00e9s sur les hypoth\u00e8ses de classes ; \u2014 la formation par agglutination des termes et ce, surtout dans le titre, a fait appara\u00eetre des sous-types de recettes (quiches, soupes, g\u00e2teaux) qui ont permis fournir aux mod\u00e8les de meilleurs points d\u2019appui pour identifier la classe vis\u00e9e. Dans les cas o\u00f9 l\u2019indice de puret\u00e9 de Gini valait 1, et o\u00f9 la couverture \u00e9tait \u00e9lev\u00e9e, nous avons enrichi le sac de mots avec des composants factices de fa\u00e7on \u00e0 compenser le bruit qui pouvait \u00eatre engendr\u00e9 par le reste de la recette. Ceci a \u00e9t\u00e9 fait de fa\u00e7on semi-automatique, mais devrait pouvoir \u00eatre compl\u00e8tement automatis\u00e9. Notons par ailleurs que nous nous sommes servis du crit\u00e8re de puret\u00e9 de Gini pour s\u00e9lectionner quelques mots erron\u00e9s ce qui, apr\u00e8s correction, a permis d\u2019augmenter leur couverture sans alt\u00e9rer leur pouvoir discriminant.\n2.2 Algorithmes de boosting\nPour les t\u00e2ches de classification (1 et 2), nous proposons une mani\u00e8re de combiner diff\u00e9rentes caract\u00e9ristiques textuelles et num\u00e9riques au moyen d\u2019un algorithme d\u2019apprentissage automatique : le Boosting (Schapire, 2003). Son objectif principal est d\u2019am\u00e9liorer (de \u00ab booster \u00bb) la pr\u00e9cision de n\u2019importe quel algorithme d\u2019apprentissage permettant d\u2019associer, \u00e0 une s\u00e9rie d\u2019exemples, leur classe correspondante. Le principe g\u00e9n\u00e9ral du Boosting est assez simple : la combinaison pond\u00e9r\u00e9e d\u2019un ensemble de classifieurs binaires (appel\u00e9s classifieurs faibles), chacun associ\u00e9 \u00e0 une r\u00e8gle diff\u00e9rente de classification tr\u00e8s simple et peu efficace, permettant au final d\u2019obtenir une classification robuste et tr\u00e8s pr\u00e9cise (classifieur fort). La seule contrainte de ces classifieurs faibles est d\u2019obtenir des performances meilleures que le hasard. Dans le cas des classifieurs binaires, l\u2019objectif est de classifier plus de 50 % des donn\u00e9es correctement.\nNous proposons d\u2019utiliser l\u2019algorithme AdaBoost car il pr\u00e9sente de nombreux avantages dans le cadre des t\u00e2ches de classification propos\u00e9es. En effet, l\u2019algorithme est tr\u00e8s rapide et simple \u00e0 programmer, applicable \u00e0 de nombreux domaines, adaptable aux probl\u00e8mes multi-classes. Il fonctionne sur le principe du Boosting, o\u00f9 un classifieur faible est obtenu \u00e0 chaque it\u00e9ration de l\u2019algorithme AdaBoost. Chaque exemple d\u2019apprentissage poss\u00e8de un poids, chaque tour de classification permettant de les re-pond\u00e9rer selon le classifieur faible utilis\u00e9. Le poids d\u2019un exemple bien cat\u00e9goris\u00e9 est diminu\u00e9, au contraire d\u2019un exemple mal cat\u00e9goris\u00e9, pour lequel on augmente son poids. L\u2019it\u00e9ration suivante se focalisera ainsi sur les exemples les plus \u00ab difficiles \u00bb (poids les plus \u00e9lev\u00e9s). L\u2019algorithme a \u00e9t\u00e9 impl\u00e9ment\u00e9 dans l\u2019outil de classification \u00e0 large-marge BoosTexter (Schapire and Singer, 2000), permettant de fournir comme caract\u00e9ristiques au classifieur des donn\u00e9es num\u00e9riques mais \u00e9galement des donn\u00e9es textuelles. Les classifieurs faibles sur les donn\u00e9es textuelles peuvent prendre en compte des n-grammes de mots. Nous avons utilis\u00e9 l\u2019outil IcsiBoost (Favre et al., 2007), qui est l\u2019impl\u00e9mentation open-source de cet outil. IcsiBoost a notamment l\u2019avantage de pouvoir fournir, pour chaque exemple \u00e0 classifier, un score de confiance pour chacune des classes entre 0 (peu confiant) et 1 (tr\u00e8s confiant)."}, {"heading": "2.2.1 Niveau de difficult\u00e9", "text": "Pour l\u2019approche utilisant l\u2019algorithme de classification AdaBoost, nous avons retenu diff\u00e9rentes caract\u00e9ristiques qui ont \u00e9t\u00e9 fournies en entr\u00e9e pour l\u2019apprentissage du classifieur :\n\u2014 donn\u00e9es textuelles\n1. n-grammes de mots du titre de la recette avec taille maximum de 3 mots ;\n2. n-grammes demots du texte de la recette avec taille maximum de 4mots ;\n3. uni-gramme sur la liste des ingr\u00e9dients obtenue automatiquement (voir section 2.6).\n\u2014 donn\u00e9es num\u00e9riques continues\n1. nombre de mots du titre de la recette ;\n2. nombre de mots du texte de la recette ;\n3. nombre de phrases du texte de recette ;\n4. nombre de s\u00e9parateurs du texte de la recette (point, virgule, deux-points, etc.) ;\n5. taille de la liste des ingr\u00e9dients obtenue automatiquement.\n\u00c0 la fin de ce processus d\u2019apprentissage, la liste des classifieurs s\u00e9lectionn\u00e9s est obtenue tout comme le poids de chacun d\u2019eux, afin d\u2019utiliser les exemples les plus discriminants pour chaque classe (chaque niveau de difficult\u00e9 est consid\u00e9r\u00e9 dans cette t\u00e2che comme une classe). Nous avons compos\u00e9 un sous-corpus \u00e0 partir du corpus d\u2019apprentissage fourni par les organisateurs de la t\u00e2che afin d\u2019optimiser le nombre de classifieurs faibles n\u00e9cessaires. Ce sous-corpus est compos\u00e9 de 3 863 recettes respectant la distribution des classes, le reste \u00e9tant utilis\u00e9 pour l\u2019apprentissage (environ 72% des donn\u00e9es d\u2019apprentissage). Notons que tout le corpus d\u2019apprentissage sera n\u00e9anmois utilis\u00e9 pour entra\u00eener les classifieurs pendant la phase de test de la campagne. Enfin, une attention particuli\u00e8re a \u00e9t\u00e9 port\u00e9e sur la normalisation des donn\u00e9es textuelles du titre et de la description des recettes. En effet, les donn\u00e9es textuelles \u00ab brutes \u00bb fournies par les organisateurs poss\u00e9daient un vocabulaire tr\u00e8s bruit\u00e9 principalement \u00e0 cause des nombreuses abbr\u00e9viations (par exemple \u00ab th \u00bb pour \u00ab thermostat \u00bb) et fautes d\u2019othographe (par exemple \u00ab \u00e9chalote \u00bb et \u00ab \u00e9chalotte \u00bb). Quatre traitements particuliers ont \u00e9t\u00e9 appliqu\u00e9s sur le texte :\n1. suppression de la ponctuation et isolation de chaque mot (exemple : \u00ab et couper l\u2019oignon. \u00bb devient \u00ab et\u2294couper\u2294l\u2019\u2294oignon \u00bb) ;\n2. utilisation d\u2019une listemanuelle de normalisation demots (exemple : \u00ab kg \u00bb devient \u00ab kilogramme \u00bb) ;\n3. conversion automatique des chiffres en lettres ;\n4. regroupement des n-grammes demots les plus fr\u00e9quents au sein d\u2019une m\u00eame entit\u00e9 au moyen de l\u2019outil lia_tagg 2 (exemple : \u00ab il y a \u00bb est consid\u00e9r\u00e9 comme un mot \u00ab il_y_a \u00bb).\nCe texte normalis\u00e9 est utilis\u00e9 par l\u2019algorithme AdaBoost pour la recherche des classifieurs faibles sur les donn\u00e9es textuelles lors de la phase d\u2019apprentissage, mais \u00e9galement pour la recherche du niveau de difficult\u00e9 associ\u00e9 \u00e0 une recette lors de la\n2. http ://lia.univ-avignon.fr/fileadmin/documents/Users/Intranet/chercheurs/bechet/download_fred.html\nphase de test. Au final, nous obtenons pour chaque recette \u00e0 classifier, un score de confiance pour chaque niveau de difficult\u00e9, permettant de choisir le niveau de difficult\u00e9 de la recette (score le plus \u00e9lev\u00e9)."}, {"heading": "2.2.2 Type de plat", "text": "Dans ce probl\u00e8me de classification au moyen de l\u2019approche par Boosting, nous avons utilis\u00e9 les m\u00eames caract\u00e9ristiques et normalisations que celles d\u00e9crites dans la t\u00e2che de recherche du niveau de difficult\u00e9 (voir section 2.2.1). Pour chaque recette, nous obtenons donc un score de confiance pour chaque type de plat qui pourra \u00eatre utilis\u00e9 pour choisir la classe \u00e0 associer \u00e0 une recette."}, {"heading": "2.3 SVMs", "text": "Le corpus des recettesX \u00e9tant donn\u00e9, il s\u2019agit d\u2019\u00e9laborer \u00e0 partir d\u2019un sous-ensemble D \u2282 X de recettes annot\u00e9es par classe (niveau de difficult\u00e9 ou type de plat selon la t\u00e2che), une m\u00e9thode de classification \u03b3 qui \u00e0 toute recette associe une classe. En notant C l\u2019ensemble des classes, nous avons donc :\n\u03b3 : X \u2212\u2192 C (1)\nLa troisi\u00e8me des m\u00e9thodes appliqu\u00e9es a consist\u00e9, pour chaque couple de classes (c, c\u2032) \u2208 C\u00d7C (avec c 6= c\u2032), \u00e0 apprendre et \u00e0 appliquer un classifieur binaire \u03b3(c,c\u2032) : X\u2192 {c, c\u2032} \u00e0 base de SVMs.\nEn notant s(c,c\u2032)(r) le score obtenu selon le classifieur \u03b3(c,c\u2032) par la recette r \u2208 X, nous avons alors, avec c\u2032 \u2208 C :\n\u03b3(r) = argmax c\u2208C s(c,c\u2032)(r)\n(2)\nLors des phases d\u2019apprentissage et d\u2019application des classifieurs binaires, les recettes ont \u00e9t\u00e9 repr\u00e9sent\u00e9es vectoriellement dans l\u2019espace du lexique de r\u00e9f\u00e9rence. Le poids w(t) du terme t d\u2019une recette r dans le vecteur associ\u00e9 est donn\u00e9 par :\nw(t) = t f (t).id f (t) = t f (t). log\n|X|\nd f (t)\n(3)\no\u00f9 t f (t) d\u00e9signe le nombre d\u2019occurrences du terme t dans la recette et d f (t) le nombre de recettes du corpus X o\u00f9 le terme t appara\u00eet. L\u2019approche d\u00e9crite a \u00e9t\u00e9 appliqu\u00e9e pour les deux t\u00e2ches de classification.\nDans le cas de la pr\u00e9diction du type de plat, le lexique a cependant \u00e9t\u00e9 filtr\u00e9 avant vectorisation des recettes sur le crit\u00e8re de l\u2019information mutuelle entre un terme t et une classe c \u2208 C (Manning et al., 2008). Apr\u00e8s s\u00e9lection des termes, seuls les 10 000 termes les plus porteurs d\u2019information sur les classes ont alors \u00e9t\u00e9 retenus."}, {"heading": "2.4 Similarit\u00e9 cosinus", "text": "La quatri\u00e8me approche, seulement utilis\u00e9e pour la pr\u00e9diction du type de plat, repose elle aussi sur une repr\u00e9sentation vectorielle des documents : \u00e0 chaque recette r,\nnous faisons correspondre un vecteur vr dont les composantes wr(t) dans l\u2019espace du lexique sont donn\u00e9es, pour chaque terme t pr\u00e9sent dans le corps de la recette, par :\nwr(t) = t f (t).id f (t).G(t)\n= t f (t).id f (t). \u2211\nc\u2208C\nP 2(c|t)\n= t f (t).id f (t). \u2211\nc\u2208C\nd fc(t)\nd fT(t)\n2 (4)\no\u00f9 G(t) d\u00e9signe l\u2019indice de Gini, d fT(t) est le nombre de recettes du corpus d\u2019apprentissage T \u2282 X contenant le terme t et d fc(t) correspond au nombre de recettes du corpus d\u2019apprentissage annot\u00e9es selon le type c \u2208 C.\nA chaque classe c \u2208 C, nous faisons par ailleurs correspondre un vecteur dont les composantes wc(t) sont donn\u00e9es dans l\u2019espace du lexique par :\nwc(t) = d fc(t).id f (t).G(t) (5)\no\u00f9 d fc(t) d\u00e9signe le nombre de recettes annot\u00e9es selon le type de plat c o\u00f9 le terme t appara\u00eet.\nUne mesure de similarit\u00e9 s(r, c) entre une recette r \u2208 X et un type de plat c \u2208 C est alors donn\u00e9e par le cosinus de l\u2019angle form\u00e9 par les vecteurs vr et vc :\ns(r, c) = cos(\u00d6vr , vc) = \u2211\nt\u2208r\u2229c wr(t).wc(t)\u00c6\u2211 t wr(t) 2.wc(t)2 (6)\nDans ces conditions la classe \u03b3(c) attribu\u00e9e \u00e0 une recette r est celle qui maximise la mesure de similarit\u00e9 cosine :\n\u03b3(r) = argmax c\u2208C (s(r, c)) (7)\nLe vocabulaire utilis\u00e9 lors de la phase de vectorisation \u00e9tait constitu\u00e9 des seuls termes t dont l\u2019indice de Gini G(t) \u00e9tait au moins \u00e9gal \u00e0 0.45.\nCe seuil a \u00e9t\u00e9 fix\u00e9 empiriquement par maximisation du macro F-score sur un corpus de d\u00e9veloppement constitu\u00e9 de 3 864 des 13 864 recettes du corpus d\u2019apprentissage."}, {"heading": "2.5 Fusion des syst\u00e8mes", "text": "Pour chacune des t\u00e2ches de classification, plusieurs m\u00e9thodes ont donc \u00e9t\u00e9 appliqu\u00e9es : trois pour la t\u00e2che 1, quatre pour la t\u00e2che 2.\nPour chaque couple (r, c) \u2208 X\u00d7C associant une recette du corpus \u00e0 une classe, nous disposions donc d\u2019un score si(r, c) pour chacune desm\u00e9thodes de classification (avec i = 1, ..., 3 ou i = 1, ..., 4 selon la t\u00e2che)."}, {"heading": "2.5.1 Normalisation des r\u00e9sultats par m\u00e9thode", "text": "Les scores produits en sortie des diff\u00e9rents syst\u00e8mes de classification ont d\u2019abord \u00e9t\u00e9 normalis\u00e9s de mani\u00e8re \u00e0 ce que la somme des pr\u00e9dictions sur l\u2019ensemble des classes pour unem\u00e9thode donn\u00e9e soit \u00e9gale \u00e0 1. En notant ni(r, c) le score normalis\u00e9 obtenu selon la i\u2212\u00e8me m\u00e9thode pour le couple (r, c) \u2208 X\u00d7C, nous avons donc :\nni(r, c) = si(r, c)\u2211|C| j=1 si(r, c j)\n(8)\no\u00f9 c j d\u00e9signe la j\u2212\u00e8me classe ( j = 1, ..., 4 ou j = 1, ...3 selon la t\u00e2che de classification).\nDeux m\u00e9thodes de fusion ont \u00e9t\u00e9 appliqu\u00e9es apr\u00e8s normalisation des scores si(r, c)."}, {"heading": "2.5.2 Combinaison lin\u00e9aire des scores", "text": "La premi\u00e8re m\u00e9thode de fusion a consist\u00e9, pour une recette donn\u00e9e r, \u00e0 d\u00e9partager les classes candidates par combinaison lin\u00e9aire des scores obtenus selon les diff\u00e9rentes m\u00e9thodes de classification. En notant \u03b3(r) la classe conjectur\u00e9e, on a donc :\n\u03b3(r) = argmax c\u2208C\nm\u2211\ni=1\nni(r, c)\n(9)\no\u00f9 m correspond au nombre de m\u00e9thodes appliqu\u00e9es pour la t\u00e2che consid\u00e9r\u00e9e."}, {"heading": "2.5.3 M\u00e9thode ELECTRE", "text": "Issue du domaine de l\u2019optimisation multi-objectif discr\u00e8te, la m\u00e9thode ELECTRE (Roy, 1991) consiste \u00e0 d\u00e9finir sur l\u2019ensemble C des classes candidates une relation S \u2282 C\u00d7C dite de surclassement. De mani\u00e8re informelle, nous pouvons dire qu\u2019une classe c surclasse une classe c\u2032 si elle la domine sur un nombre \u00ab important \u00bb de m\u00e9thodes et si, sur les \u00e9ventuelles m\u00e9thodes restantes o\u00f9 elle est domin\u00e9e par c\u2032, elle ne l\u2019est pas au-del\u00e0 d\u2019un certain seuil fix\u00e9 pour chaque m\u00e9thode. Plus formellement :\ncS c\u2032 \u21d0\u21d2\n\u00a8 conc(c, c\u2032) \u00be sc\nv(c, c\u2032) = 0 (10)\no\u00f9 conc(c, c\u2032) \u2208 [0,1] d\u00e9signe l\u2019indice de concordance entre les classes candidates c et c\u2032, sc \u2208 [0,1] un seuil dit de concordance fix\u00e9 empiriquement et v(c, c\u2032) \u2208 {0,1} un indice binaire dit de veto.\nL\u2019indice de concordance conc(c, c\u2032) \u00e9value le taux de m\u00e9thodes (\u00e9ventuellement pond\u00e9r\u00e9es) selon lesquelles c domine c\u2032 :\nconc(c, c\u2032) = \u2211 i\u2208M(c,c\u2032) pi\u2211\ni\u2208M pi (11)\no\u00f9 M d\u00e9signe l\u2019ensemble des m\u00e9thodes, M(c, c\u2032) l\u2019ensemble des m\u00e9thodes sur lesquelles c domine (non strictement) c\u2032 et pi le poids accord\u00e9 \u00e0 chaque m\u00e9thode i \u2208 M .\nL\u2019indice binaire v(c, c\u2032) (\u00e0 valeurs dans l\u2019ensemble {0,1}) fixe la valeur du veto de c\u2032 vers c selon les modalit\u00e9s suivantes (en notant ni(r, c) le score obtenu selon la i-\u00e8me m\u00e9thode par le couple (r, c) associant une recette \u00e0 une classe) :\nv(c, c\u2032) =\n\u00a8 1\u21d0\u21d2\u2203i \u2208 M : ni(r, c \u2032) > ni(r, c) et ni(r, c \u2032)\u2212 ni(r, c) \u00be vi\n0 sinon (12)\no\u00f9 v(i) \u2208 [0,1] est la valeur de veto associ\u00e9e \u00e0 la i\u2212\u00e8me m\u00e9thode.\nLes valeurs des diff\u00e9rents param\u00e8tres ont \u00e9t\u00e9 fix\u00e9es empiriquement \u00e0 partir du corpus de d\u00e9veloppement par maximisation des m\u00e9triques appliqu\u00e9es pour \u00e9valuer la classification.\nLes poids pi associ\u00e9s aux diff\u00e9rentes m\u00e9thodes ont tous \u00e9t\u00e9 fix\u00e9s \u00e0 pi = 1. Le seuil de concordance a \u00e9t\u00e9 fix\u00e9 \u00e0 sc = 0,7 pour la t\u00e2che 1 et sc = 0,6 pour la t\u00e2che 2 ; enfin, la valeur de veto vi a \u00e9t\u00e9 fix\u00e9e \u00e0 vi = 0,5 pour chacune des m\u00e9thodes et quelle que soit la t\u00e2che consid\u00e9r\u00e9e.\nLe noyau de la relation S \u2282 C\u00d7C est alors constitu\u00e9 des \u00e9ventuelles classes candidates non surclass\u00e9es.\nDans le cas d\u2019un noyau singleton, la classe conjectur\u00e9e pour la recette est l\u2019unique classe \u00e9l\u00e9ment du noyau.\nDans le cas de noyau vide ou de noyau form\u00e9 de plusieurs classes concurrentes, c\u2019est la meilleure classe candidate selon la m\u00e9thode de combinaison lin\u00e9aire qui a \u00e9t\u00e9 retenue."}, {"heading": "2.6 Extraction d\u2019ingr\u00e9dients", "text": "La t\u00e2che 4 est une t\u00e2che pilote d\u2019extraction d\u2019information. La difficult\u00e9 est multiple, car les auteurs des recettes n\u2019utilisent pas tous les ingr\u00e9dients, ou ils ont introduit librement des ingr\u00e9dients non list\u00e9s. Par exemple, il n\u2019est pas rare d\u2019avoir des passages comme \u00abm\u00e9langer \u00e9nergiquement tous les ingr\u00e9dients \u00bb (recette 27174), qui ne permettent pas d\u2019extraire directement les ingr\u00e9dients.\nNous avons attaqu\u00e9 ce probl\u00e8me en utilisant deux approches : l\u2019une \u00e0 base de r\u00e8gles et l\u2019autre probabiliste. L\u2019id\u00e9e de base pour les r\u00e8gles a \u00e9t\u00e9 la suivante : soit A l\u2019ensemble demots de la recette i ; soit B l\u2019ensemble demots de la liste DEFT (r\u00e9f\u00e9rences d\u2019apprentissage ou gold-standard d\u2019\u00e9valuation). \u00c9liminer tous les mots de A qui ne sont pas dans B. Cela produit une liste d\u2019ingr\u00e9dients candidats Lc .\nCette liste peut contenir des termes g\u00e9n\u00e9riques comme \u00abVIANDE \u00bb, \u00ab FROMAGE \u00bb ou \u00ab POISSON \u00bb, pr\u00e9sents dans le texte de la recette. Afin de mieux identifier ce terme, nous avons employ\u00e9 une approche probabiliste na\u00efve. Nous avons calcul\u00e9 la probabilit\u00e9 d\u2019avoir un certain type de viande x , \u00e9tant donn\u00e9 une liste d\u2019ingr\u00e9dients Lc = (L1, L2, ..., Ln) :\np(x |Lc) = P(x \u2229 Lc)/p(Lc); x = {VIANDE, FROMAGE, POISSON} (13)\nLes termes ainsi identifi\u00e9s, sont alors inject\u00e9s dans la liste extraite Lc , ce qui produit la liste deifnitive L.\nLa liste d\u2019ingr\u00e9dients L ainsi obtenue a \u00e9t\u00e9 utilis\u00e9e dans les syst\u00e8mes de boosting (c.f. section2.2) dans les t\u00e2ches T1 et T2."}, {"heading": "3 R\u00e9sultats et discussion", "text": "Les syst\u00e8mes ont \u00e9t\u00e9 \u00e9valu\u00e9s en utilisant les mesures propos\u00e9es par DEFT : le F-score pour les t\u00e2ches 1 et 2, et la mesure Mean Average Precision (MAP) de TREC pour la t\u00e2che d\u2019extraction."}, {"heading": "3.1 T\u00e2ches de classification", "text": "Pour la t\u00e2che de classification en niveau de difficult\u00e9 (T1), nos trois runs \u00e9taient donn\u00e9s par :\n\u2014 Run 1 : SVMs seuls ; \u2014 Run 2 : fusion des trois m\u00e9thodes par ELECTRE ; \u2014 Run 3 : combinaison lin\u00e9aire des trois m\u00e9thodes.\nPour la t\u00e2che de classification en type de plat (T2) :\n\u2014 Run 1 : Mod\u00e8le discriminant seul ; \u2014 Run 2 : fusion des quatre m\u00e9thodes par ELECTRE ; \u2014 Run 3 : combinaison lin\u00e9aire des quatre m\u00e9thodes.\nLes r\u00e9sultats obtenus sont r\u00e9capitul\u00e9s dans les tableaux 1 (t\u00e2che 1) et 2 (t\u00e2che 2).\nPour la t\u00e2che 1 et pour chacun des trois runs, nous fournissons, outre les F-scores, la distance moyenne (micro-\u00e9cart) de l\u2019hypoth\u00e8se \u00e0 la r\u00e9f\u00e9rence sur l\u2019\u00e9chelle des quatre niveaux de difficult\u00e9, deux niveaux contig\u00fcs \u00e9tant distants de 1.\nPour la t\u00e2che 2, la combinaison des m\u00e9thodes permet d\u2019obtenir des scores syst\u00e9matiquement sup\u00e9rieurs \u00e0 ceux que nous obtenons en appliquant une m\u00e9thode isol\u00e9e.\nPour la t\u00e2che d\u2019\u00e9valuation du niveau de difficult\u00e9, les b\u00e9n\u00e9fices retir\u00e9s de l\u2019utilisation d\u2019une m\u00e9thode de fusion sont moins nets et apparaissent d\u00e9pendants de la m\u00e9trique appliqu\u00e9e lors de l\u2019\u00e9valuation.\nCeci a permis au LIA de se positionner dans la t\u00e2che 1 : 3\u00e8me/6 et dans la t\u00e2che 2 : 1er/5.\nEn ce qui concerne la t\u00e2che T2, nous croyons que l\u2019\u00e9valuation aurait d\u00fb prendre en compte la dimension muti-labels de plusieurs recettes. Par exemple la recette 18 052 (pr\u00e9sente dans le test) se termine par \u00ab servir ti\u00e8de ( aussi bon chaud que froid ou r\u00e9chauff\u00e9), en entr\u00e9e ou en plat \u00bb est annot\u00e9e uniquement comme une entr\u00e9e. Si un syst\u00e8me produit l\u2019\u00e9tiquette plat principal, faut-il pour autant compter cela comme une erreur?\nRelevons aussi l\u2019aspect subjectif de la t\u00e2che T1. En effet, dire qu\u2019une recette est facile ou difficile sans tenir compte qui en est l\u2019auteur c\u2019est faire fi de son niveau d\u2019expertise ! ! !\nNous \u00e9mettons \u00e9galement l\u2019id\u00e9e que les macro-mesures devraient \u00eatre privil\u00e9gi\u00e9es aux micro-mesures car ces derni\u00e8res pousseraient \u00e0 mettre en \u0153uvre des strat\u00e9gies n\u00e9gligeant les classes minoritaires. Nous pensons donc que cette fa\u00e7on d\u2019\u00e9valuer serait plus adapt\u00e9e \u00e0 une utilisation orient\u00e9e application."}, {"heading": "3.2 T\u00e2che d\u2019extraction", "text": "L\u2019\u00e9valuation de cette t\u00e2che est assez subjective, malgr\u00e9 son caract\u00e8re d\u2019extraction d\u2019information. Par exemple, dans l\u2019ensemble d\u2019apprentissage, la recette 10 514 dit : \u00ab 40 cl d\u2019Apremont ou autre blanc de Savoie sec (facultatif, mais donne plus de go\u00fbt) \u00bb. Les r\u00e9f\u00e9rences DEFT indiquent mais comme ingr\u00e9dient de la tartiflette. Evidemment nous n\u2019avons pas incorpor\u00e9 l\u2019information des ingr\u00e9dients d\u2019apprentissage, \u00e0 la diff\u00e9rence de la m\u00e9thode DEFT ayant g\u00e9n\u00e9r\u00e9 le gold-standard.\nNous avons obtenu un score de MAP=0.6364 en mesure qrel dans le corpus d\u2019apprentissage, et dans le classement officiel un score de MAP=0.6287 dans le corpus de test. Cela a positionn\u00e9 l\u2019\u00e9quipe du LIA au rang 3\u00e8me/5. Bien que standard, la mesure MAP pourrait avoir int\u00e9gr\u00e9 les accents dans l\u2019\u00e9valuation des ingr\u00e9dients extraits : cela aurait permis de lever des ambigu\u00eft\u00e9s qui ont \u00e9t\u00e9 inutilement introduites par la d\u00e9saccentuation.\nNous pensons que les r\u00e9f\u00e9rences fournies par DEFT dans l\u2019ensemble d\u2019apprentissage, ont contribu\u00e9 \u00e0 rendre la t\u00e2che floue. En effet, cela n\u2019a pas de sens d\u2019extraire papier sulfuris\u00e9 ou couteau (extraite \u00e0 partir de pointe de couteau) comme ingr\u00e9dients. De m\u00eame, l\u2019ingr\u00e9dient ma\u00efs, incorrectement extrait des recettes d\u2019apprentissage comportant l\u2019expression mais..., n\u2019est pas apparu dans les recettes de test comportant ladite expression."}, {"heading": "3.3 Comparaison versus les humains", "text": "Nous avons mis en place une petite exp\u00e9rience impliquant des \u00eatres humains. Pour la t\u00e2che T4, nous avons demand\u00e9 \u00e0 7 annotateurs (experts ou non en mati\u00e8re culinaire), d\u2019effectuer la t\u00e2che DEFT. Ceci nous a permis de positionner nos syst\u00e8mes\npar rapport aux performances des personnes. Puisque les personnes ont des connaissances extra-linguistiques, les juges humains ont eu comme seule consigne celle de ne pas consulter des ressources externes (par exemple des ressources \u00e9lectroniques ou des livres de cuisine) pour classer les recettes ou pour extraire les ingr\u00e9dients. Le tableau 3 montre la moyenne MAP pour chaque annotateur Ai sur 50 recettes de la t\u00e2che T4, choisies au hasard. La moyenne g\u00e9n\u00e9rale pour les personnes est de MAP=0.5433 et pour le syst\u00e8me S de MAP=0.6570. Ceci montre que dans ce sousensemble, nos syst\u00e8mes sont au-dessus des performances atteintes par les humains.\nIl est clair que, m\u00eame les humains ayant une expertise culinaire, ont obtenu de pi\u00e8tres notes dans cette t\u00e2che. Cela s\u2019explique par la mauvaise qualit\u00e9 du gold standard fourni par DEFT. Par exemple, la cr\u00e8me ou le caf\u00e9 (cuill\u00e8re \u00e0 caf\u00e9, recette 90 806) semblent subir une extraction de nature al\u00e9atoire... D\u2019ailleurs, nous avons souvent \u00e9t\u00e9 surpris par les ingr\u00e9dients de r\u00e9f\u00e9rence de DEFT utilis\u00e9s dans telle ou telle recette, qui ne peuvent en aucun cas avoir \u00e9t\u00e9 employ\u00e9s de fa\u00e7on conjointe. Par exemple, dans la recette 64 761 (dessert), la r\u00e9f\u00e9rence DEFT liste parmi les ingr\u00e9dients \u00ab moules \u00bb et \u00ab caramel \u00bb ! \u00c9videmment il s\u2019agit de l\u2019ustensile moule \u00e0 charlotte. Malheureusement il s\u2019agit de probl\u00e8mes r\u00e9currents. Sans parler de l\u2019eau ou de la p\u00e2te (d\u00e9clin\u00e9e comme p\u00e2t\u00e9, p\u00e2tes fra\u00eeches, bris\u00e9e, sabl\u00e9e, etc.) qui semblent \u00eatre d\u00e9tect\u00e9es al\u00e9atoirement. Pour r\u00e9pondre au d\u00e9fi, nous avons d\u00e9velopp\u00e9 plusieurs syst\u00e8mes d\u2019extraction d\u2019ingr\u00e9dients qui ont d\u00fb \u00eatre modifi\u00e9s (souvent \u00e0 l\u2019encontre de ce qui nous semblait logique) afin de rendre une sortie proche de celle des r\u00e9f\u00e9rences. Ceci revient en fin de compte \u00e0 mod\u00e9liser la machine d\u2019extraction de DEFT. Les r\u00e9f\u00e9rences \u00e9tant de qualit\u00e9 discutable, est-il int\u00e9ressant de chercher \u00e0 reproduire la sortie d\u2019une telle machine?"}, {"heading": "4 Conclusions", "text": "Malgr\u00e9 la quantit\u00e9 d\u2019erreurs pr\u00e9sentes dans le corpus d\u2019apprentissage, nos algorithmes ont conduit \u00e0 des r\u00e9sultats int\u00e9ressants. Nous voulons ajouter quelques commentaires par rapport \u00e0 ce d\u00e9fi. Nous avons observ\u00e9 que l\u2019auto-\u00e9valuation du niveau de difficult\u00e9 des recettes par ceux qui les publient est un exercice tr\u00e8s subjectif, assez souvent sujet \u00e0 caution. En ce qui concerne le type de plat, l\u2019\u00e9volution du mode de vie rend assez floue la distinction entre plat principal et hors d\u2019\u0153uvre. Les tartes sal\u00e9es, les quiches ou les tartines sont de plus en plus consid\u00e9r\u00e9es comme des plats \u00ab de r\u00e9sistance \u00bb. Ceci conduit souvent les internautes \u00e0 exprimer de fa\u00e7on explicite leur ind\u00e9cision quant \u00e0 la cat\u00e9gorie \u00e0 retenir. Ces observations n\u2019ont pas suffi \u00e0 att\u00e9nuer notre perplexit\u00e9 lorsque nous avons constat\u00e9 que certaines m\u00e9thodes \u00e0 base de \u00ab cuisine \u00bb algorithmique r\u00e9ussissaient \u00e0 faire mieux que des approches sophistiqu\u00e9es. Pour autant, nous n\u2019avons pas c\u00e9d\u00e9 \u00e0 la tentation de les retenir pour en faire une soumission !\nRemerciements\nNous remercions les annotateurs qui ont bien voulu nous aider dans cette t\u00e2che ! Patricia Vel\u00e1zquez, Sulan Wong, Mariana Tello, Alejandro Molina et Gr\u00e9goire Moreau. Nous tenons aussi \u00e0 remercier les organisateurs de la campagne d\u2019\u00e9valuation, sans qui nous n\u2019aurions pu participer \u00e0 ce d\u00e9fi.\nR\u00e9f\u00e9rences\nFavre, B., Hakkani-T\u00fcr, D., and Cuendet, S. (2007). Icsiboost. http://code.google.com/p/icsiboost.\nManning, C. D., Raghavan, P., and Sch\u00fctze, H. (2008). Introduction to Information Retrieval. Cambridge University Press, New York, NY, USA.\nRoy, B. (1991). The outranking approach and the foundations of ELECTRE methods. Theory and Decision, 31 :49\u201373.\nSchapire, R. E. (2003). The Boosting Approach toMachine Learning : An Overview. In Nonlinear Estimation and Classification.\nSchapire, R. E. and Singer, Y. (2000). BoosTexter : A boosting-based system for text categorization. In Machine Learning, volume 39, pages 135\u2013168.\nTorres-Moreno, J., El-B\u00e8ze, M., Bellot, P., and F., B. (2011). Peut-on voir la d\u00e9tection d\u2019opinions comme un probl\u00e8me de classification th\u00e9matique?, chapter 9. Hermes Lavoisier."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "The Systems of LIA at DEFT\u201913 The 2013 D\u00e9fi de Fouille de Textes (DEFT) campaign is interested in two types of language analysis tasks, the document classification and the information extraction in the specialized domain of cuisine recipes. We present the systems that the LIA has used in DEFT 2013. Our systems show interesting results, even though the complexity of the proposed tasks. MOTS-CL\u00c9S : Classification de textes ; Extraction d\u2019information ; M\u00e9thodes statistiques ; Domaine de sp\u00e9cialit\u00e9.", "creator": "LaTeX with hyperref package"}}}