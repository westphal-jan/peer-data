{"id": "1702.08451", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Feb-2017", "title": "Approches d'analyse distributionnelle pour am\\'eliorer la d\\'esambigu\\\"isation s\\'emantique", "abstract": "word sense disambiguation ( wsd ) improves many natural language processing ( nat ) applications such as information retrieval, machine translation adaptive lexical simplification. wsd is the ability of determining a word sense merging different ones within a polysemic lexical unit taking into action the context. the simplest straightforward approach uses a semantic proximity measure between the word sense candidates of the target word and those of its context. such cluster method one easily entails a significant explosion. in this paper, we propose two methods rely on distributional analysis which enable to reduce the exponential complexity times losing the coherence. we present a comparison between binary selection : distributional neighbors and the linearly nearest neighbors. the figures obtained from thus selecting distributional neighbors correspond to better results.", "histories": [["v1", "Mon, 27 Feb 2017 13:38:08 GMT  (670kb)", "http://arxiv.org/abs/1702.08451v1", "in French, Journ\\'ees internationales d'Analyse statistique des Donn\\'ees Textuelles (JADT), Jun 2016, Nice, France"]], "COMMENTS": "in French, Journ\\'ees internationales d'Analyse statistique des Donn\\'ees Textuelles (JADT), Jun 2016, Nice, France", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["mokhtar billami", "n\\'uria gala"], "accepted": false, "id": "1702.08451"}, "pdf": {"name": "1702.08451.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Mokhtar Boumedyen Billami", "N\u00faria Gala", "BOUMEDYEN BILLAMI", "NURIA GALA"], "emails": [], "sections": [{"heading": null, "text": "JADT 2016 : 13\u00e8me Journ\u00e9es internationales d\u2019Analyse statistique des Donn\u00e9es Textuelles\nR\u00e9sum\u00e9 La d\u00e9sambigu\u00efsation s\u00e9mantique permet d\u2019am\u00e9liorer de nombreuses applications en traitement automatique des langues (TAL) comme la recherche d\u2019information, la traduction automatique ou la simplification lexicale de textes. Elle consiste \u00e0 choisir le sens des unit\u00e9s lexicales polys\u00e9miques dans un texte et s\u2019effectue en tenant compte du contexte. L\u2019approche la plus directe consiste \u00e0 estimer la proximit\u00e9 s\u00e9mantique entre chaque sens candidat et les sens des mots du contexte. Cette m\u00e9thode engendre rapidement une explosion combinatoire. Dans cet article, nous proposons deux approches \u00e0 base d\u2019analyse distributionnelle permettant de r\u00e9duire la complexit\u00e9 exponentielle et de ne pas perdre de la coh\u00e9rence au niveau de la d\u00e9sambigu\u00efsation, cela en s\u00e9lectionnant les voisins distributionnels les plus proches. Nous pr\u00e9sentons une comparaison entre la s\u00e9lection des voisins distributionnels et les voisins les plus proches lin\u00e9airement. Les r\u00e9sultats montrent que la s\u00e9lection des voisins distributionnels est bien meilleure.\nKeywords: unsupervised word sense disambiguation, distributional analysis, dependency parsing, continuous vectorial representation.\nMots cl\u00e9s: d\u00e9sambigu\u00efsation s\u00e9mantique non supervis\u00e9e, analyse distributionnelle, analyse syntaxique en d\u00e9pendances, repr\u00e9sentation vectorielle continue."}, {"heading": "1. Introduction", "text": "La d\u00e9sambigu\u00efsation des sens de mots est essentielle pour accomplir la plupart des t\u00e2ches de traitement des langues (Navigli, 2009), par exemple, la recherche d\u2019information, la traduction automatique, l\u2019extraction d\u2019information, l\u2019analyse du contenu, la fouille de textes ainsi que la simplification lexicale de textes. La d\u00e9sambigu\u00efsation s\u00e9mantique permet de choisir le sens des unit\u00e9s lexicales polys\u00e9miques dans un texte. Elle s'effectue en tenant compte des contextes o\u00f9 un sens peut appara\u00eetre (Ide et V\u00e9ronis, 1998). L'approche la plus directe consiste \u00e0 estimer la proximit\u00e9 s\u00e9mantique entre chaque sens candidat et chaque sens de chaque mot appartenant au contexte du mot \u00e0 d\u00e9sambigu\u00efser. Une application de cette m\u00e9thode est propos\u00e9e dans (Pedersen et al., 2005). Le principal probl\u00e8me est la rapide explosion combinatoire qu'elle engendre (complexit\u00e9 exponentielle). En d\u2019autres termes, si le\nJADT 2016 : 13\u00e8me Journ\u00e9es internationales d\u2019Analyse statistique des Donn\u00e9es Textuelles\nsens s\u00e9lectionn\u00e9 d\u2019un mot dans une combinaison est et une liste de mots appartenant au contexte du mot polys\u00e9mique \u00e0 d\u00e9sambigu\u00efser alors le score de combinaison est et il y a en tout combinaisons \u00e0 \u00e9valuer, avec le nombre de sens du mot w. Par exemple, pour une phrase de 10 mots avec 10 sens en moyenne, il y aurait 1010 combinaisons possibles. Consid\u00e9rons la phrase suivante tir\u00e9e du corpus d\u2019\u00e9valuation que nous d\u00e9crivons par la suite dans l\u2019article, [Place flat palms on either side of the head a_few inches away from the ears, fingers pointing toward the shoulders.], \u00ab place_Verbe \u00bb a 16 sens selon le r\u00e9seau s\u00e9mantique BabelNet (Navigli et Ponzetto, 2012), \u00ab flat_Adj \u00bb 15, \u00ab palm_Nom \u00bb 4, \u00ab side_Nom \u00bb 15, \u00ab head_Nom \u00bb 40, \u00ab a few_Adj \u00bb 1, \u00ab inch_Nom \u00bb 2, \u00ab away_Adj \u00bb 3, \u00ab ear_Nom \u00bb 6, \u00ab finger_Nom \u00bb 4, \u00ab point_Verbe \u00bb 14 et \u00ab shoulder_Nom \u00bb 5, il y a alors 5 806 080 000 combinaisons de sens possibles \u00e0 analyser. Ce calcul exhaustif est donc tr\u00e8s compliqu\u00e9 \u00e0 r\u00e9aliser dans des conditions r\u00e9elles et rend impossible l\u2019utilisation d\u2019un contexte de taille importante.\nDans cet article, nous utilisons deux approches totalement diff\u00e9rentes \u00e0 base d'analyse distributionnelle permettant \u00e0 la fois de r\u00e9duire le nombre de combinaisons \u00e0 \u00e9valuer et de ne pas perdre de la coh\u00e9rence au niveau de la d\u00e9sambigu\u00efsation, voire m\u00eame de l'am\u00e9liorer. Baroni et Lenci (2010) ont propos\u00e9 un travail de synth\u00e8se sur les proc\u00e9dures relatives au calcul distributionnel. La cl\u00e9 de notre m\u00e9thode de d\u00e9sambigu\u00efsation est la s\u00e9lection des voisins distributionnels les plus proches pour chaque mot polys\u00e9mique dans le texte. Un travail proche du n\u00f4tre est propos\u00e9 dans (McCarthy et al., 2004). La premi\u00e8re approche consiste \u00e0 r\u00e9aliser une analyse syntaxique en d\u00e9pendances permettant d'extraire un ensemble de traits syntaxiques pour chaque mot analys\u00e9 suivant la m\u00e9thode de Lin (1998). Cette m\u00e9thode vise \u00e0 d\u00e9terminer la similarit\u00e9 distributionnelle entre un mot polys\u00e9mique et l\u2019un de ses voisins, en se r\u00e9f\u00e9rant aux traits syntaxiques partag\u00e9s. La deuxi\u00e8me approche consiste \u00e0 utiliser un mod\u00e8le de repr\u00e9sentation vectorielle continue des mots (Word2vec) dans un espace \u00e0 n dimensions. Nous utilisons le mod\u00e8le propos\u00e9 par (Mikolov et al., 2013). La similarit\u00e9 consiste ici \u00e0 comparer le vecteur du mot polys\u00e9mique et le vecteur de chacun de ses voisins.\nCet article est organis\u00e9 comme suit. La section 2 pr\u00e9sente un \u00e9tat de l\u2019art des diff\u00e9rentes m\u00e9thodes et travaux de d\u00e9sambigu\u00efsation s\u00e9mantique. L\u2019approche de d\u00e9sambigu\u00efsation s\u00e9mantique fond\u00e9e sur des m\u00e9thodes d\u2019analyse distributionnelle ainsi que les donn\u00e9es de travail sont pr\u00e9sent\u00e9es dans la section 3. La section 4 pr\u00e9sente les exp\u00e9riences ainsi que les r\u00e9sultats obtenus avant de conclure dans la section 5."}, {"heading": "2. Travaux ant\u00e9rieurs", "text": "Il existe plusieurs m\u00e9thodes de d\u00e9sambigu\u00efsation s\u00e9mantique, deux cat\u00e9gories majoritaires peuvent \u00eatre distingu\u00e9es. La premi\u00e8re rassemble des syst\u00e8mes supervis\u00e9s et repose sur l\u2019utilisation d\u2019un corpus d'apprentissage r\u00e9unissant des exemples d'instances d\u00e9sambigu\u00efs\u00e9es de mots (Bakx, 2006 ; Navigli, 2009). La deuxi\u00e8me rassemble des syst\u00e8mes non supervis\u00e9s et utilise des connaissances provenant de r\u00e9seaux s\u00e9mantiques (Tchechmedjiev, 2012, Lafourcade, 2011, Navigli, 2009). Il existe une autre cat\u00e9gorie de syst\u00e8mes non supervis\u00e9s permettant l\u2019exploitation des r\u00e9sultats de m\u00e9thodes d\u2019acquisition automatique de sens. Dans cet article, nous nous int\u00e9ressons uniquement aux m\u00e9thodes reposant sur l\u2019utilisation d\u2019un syst\u00e8me de d\u00e9sambigu\u00efsation \u00e0 base de connaissances.\nPlusieurs campagnes d\u2019\u00e9valuation ont \u00e9t\u00e9 organis\u00e9es pour \u00e9valuer la performance des algorithmes de d\u00e9sambigu\u00efsation : Senseval-1 (Kilgarriff et Rosenzweig, 2000), Senseval-2 (Edmonds, 2002), Senseval-3 (Mihalcea et Edmonds, 2004) pour l\u2019anglais et RomansEval,\nJADT 2016 : 13\u00e8me Journ\u00e9es internationales d\u2019Analyse statistique des Donn\u00e9es Textuelles\nd\u00e9sambigu\u00efsation s\u00e9mantique des sens pour des langues romanes telles que le fran\u00e7ais et l\u2019italien (Segond, 2000; Calzolari et Corazzari, 2000). La suite des travaux de d\u00e9sambigu\u00efsation a \u00e9t\u00e9 explor\u00e9e dans des campagnes successives qui ont eu lieu tous les trois ans entre 1998 et 2010 et annuellement depuis 2012. Par exemple, SemEval-2007 (Navigli et al., 2007), SemEval-2013 (Navigli et al., 2013) et SemEval-2015 (Moro et Navigli, 2015).\nL\u2019un des obstacles majeurs d\u2019une d\u00e9sambigu\u00efsation s\u00e9mantique pour atteindre de bons r\u00e9sultats est la granularit\u00e9 fine des inventaires de sens. Dans Senseval-3, les syst\u00e8mes ayant particip\u00e9 \u00e0 la t\u00e2che English All Words (EAW) ont atteint une performance autour de 65% (Snyder et Palmer, 2004) avec WordNet (Fellbaum, 1998). Ce dernier a \u00e9t\u00e9 adopt\u00e9 comme inventaire de sens. Une performance de 72,9% a \u00e9t\u00e9 obtenue sur la t\u00e2che English Lexical Sample (ELS). Malheureusement, WordNet est une ressource poss\u00e9dant une granularit\u00e9 fine dont la distinction des sens est difficile \u00e0 reconna\u00eetre par les annotateurs humains (Edmonds et Kilgarriff, 2002). Une d\u00e9sambigu\u00efsation avec un inventaire de sens \u00e0 granularit\u00e9 forte a alors \u00e9t\u00e9 propos\u00e9e dans SemEval-2007 sur les m\u00eames t\u00e2ches de Senseval-3 (EAW et ELS). Les r\u00e9sultats ont \u00e9t\u00e9 meilleurs : 82-83% pour EAW et 88,7% pour ELS. Cela montre que la repr\u00e9sentation des sens des unit\u00e9s lexicales a un impact d\u00e9cisif lorsqu\u2019on souhaite atteindre des performances dans les 80-90%. La granularit\u00e9 de l\u2019inventaire de sens est \u00e9galement d\u00e9cisive.\n3. M\u00e9thodologie\nNos m\u00e9thodes de d\u00e9sambigu\u00efsation s\u00e9mantique prennent en consid\u00e9ration des crit\u00e8res distributionnels. Les exp\u00e9riences que nous avons men\u00e9es ont \u00e9t\u00e9 r\u00e9alis\u00e9es sur un corpus en anglais. Nous avons d\u00e9j\u00e0 men\u00e9 une premi\u00e8re exp\u00e9rience pour le fran\u00e7ais en utilisant seulement l\u2019approche distributionnelle \u00e0 base de traits syntaxiques (Billami, 2015), le corpus d\u2019\u00e9valuation \u00e9tait de petite taille (6 235 occurrences de mots) et il \u00e9tait difficile de tirer des conclusions sur les r\u00e9sultats obtenus. Les exp\u00e9riences que nous pr\u00e9sentons dans cet article sont fond\u00e9es non seulement sur une seule approche distributionnelle mais aussi sur un corpus d\u2019\u00e9valuation de taille importante nous permettant ainsi de valider notre approche."}, {"heading": "3.1. Donn\u00e9es de travail", "text": ""}, {"heading": "3.1.1. Corpus de travail", "text": "Nous utilisons le corpus Europarl1, European Parliament Proceedings Parallel Corpus (Koehn, 2005). Dans le but de valider nos r\u00e9sultats sur le fran\u00e7ais, nous avons choisi ce corpus car il s\u2019agit d\u2019un corpus parall\u00e8le. Pour l\u2019anglais, Europarl contient plus de 2 millions de phrases (2 218 201) et pr\u00e8s de 54 millions de mots (53 974 751). Nous utilisons MateTools2 (Bohnet et Nivre, 2012) pour la lemmatisation du corpus, l\u2019annotation en parties du discours ainsi que pour l\u2019extraction des d\u00e9pendances syntaxiques. Le syst\u00e8me utilis\u00e9 permet de coupler l\u2019\u00e9tiquetage morphosyntaxique et l\u2019analyse de d\u00e9pendances avec des arbres non projectifs. Les mod\u00e8les que nous utilisons sont entra\u00een\u00e9s sur les donn\u00e9es de CoNLL shared task 20093 (Haji\u010d et al., 2009).\n1 http://www.statmt.org/europarl, nous utilisons la version 7 du corpus.\n2 https://code.google.com/archive/p/mate-tools\n3 http://ufal.mff.cuni.cz/conll2009-st\nJADT 2016 : 13\u00e8me Journ\u00e9es internationales d\u2019Analyse statistique des Donn\u00e9es Textuelles\n3.1.2. Corpus d\u2019\u00e9valuation\nLe test et l'\u00e9valuation de notre m\u00e9thode portent sur le corpus SemCor (Miller et al., 1993). Il s\u2019agit du corpus le plus connu, le plus grand et le plus largement utilis\u00e9 en termes de sens \u00e9tiquet\u00e9s manuellement avec WordNet. Il contient pr\u00e8s de 250 000 occurrences de mots contenues dans 352 textes, dont 80% proviennent du Corpus Brown et 20% proviennent d\u2019un roman \u00ab The Red Badge of Courage \u00bb pour lesquels les mots pleins4 ont \u00e9t\u00e9 \u00e9tiquet\u00e9s avec WordNet. Au total, SemCor contient 11 860 paragraphes et 37 176 phrases. Tous les mots sont lemmatis\u00e9s et annot\u00e9s en parties du discours dans le corpus (le traitement avec MateTools se r\u00e9v\u00e8le, de ce fait, inn\u00e9cessaire)."}, {"heading": "3.1.3. Ressource lexicale BabelNet", "text": "BabelNet5 (Navigli et Ponzetto, 2012) est un r\u00e9seau s\u00e9mantique multilingue permettant de fournir des sens de mots. Nous avons choisi d\u2019utiliser BabelNet comme base de connaissances au lieu de WordNet parce qu\u2019il propose plus d\u2019informations sur les sens provenant de diff\u00e9rentes ressources (Wikip\u00e9dia, Wiktionnaire, Wikidata, Omega wiki, Open Multilingual WordNet) y compris WordNet.\nComme BabelNet permet d\u2019avoir les correspondances de ses sens avec ceux de WordNet et comme SemCor utilise WordNet comme inventaire de sens, nous avons choisi d\u2019adopter BabelNet pour marquer les \u00e9tiquettes des sens de mots dans SemCor. Un avantage qu\u2019offre BabelNet est qu\u2019il permet de diff\u00e9rencier un concept d\u2019une entit\u00e9 nomm\u00e9e. Dans ce travail, nous consid\u00e9rons les sens comme \u00e9tant des concepts et nous ne tenons pas compte de la pr\u00e9sence des entit\u00e9s nomm\u00e9es. BabelNet propose un mapping avec les sens de la version 3.0 de WordNet, nous avons donc utilis\u00e9 la version 3.0 de SemCor. Malheureusement, certains mots sont annot\u00e9s avec des sens provenant de la version 1.6 de WordNet et n\u2019ont pas une correspondance avec les sens de BabelNet. Il s\u2019agit de 1 728 sens uniques provenant de WordNet 1.6 correspondant \u00e0 8 721 occurrences de mots \u00e9tiquet\u00e9es. En termes d\u2019annotation s\u00e9mantique avec BabelNet, nous avons \u00e0 disposition de 25 881 sens uniques correspondant \u00e0 225 415 occurrences de mots annot\u00e9s dont seulement 224 370 sont annot\u00e9s comme \u00e9tant des concepts. Parmi ces 224 370 occurrences, 699 occurrences sont annot\u00e9es avec plus d\u2019un sens. Nous avons une proportion de 96,28% de mots annot\u00e9s manuellement dans SemCor, couverts par BabelNet, et de 95,83% de cas que nous traitons sur l\u2019ensemble des mots annot\u00e9s.\n3.2. M\u00e9thodes d\u2019analyse distributionnelle\nCes m\u00e9thodes permettent de mesurer la similarit\u00e9 distributionnelle indiquant le degr\u00e9 de cooccurrence entre un mot cible et son voisin apparaissant dans des contextes similaires. Plus la similarit\u00e9 distributionnelle entre un mot \u00e0 d\u00e9sambigu\u00efser et ses voisins est forte plus la probabilit\u00e9 d\u2019avoir le sens le plus probable est grande."}, {"heading": "3.2.1. Analyse syntaxique en d\u00e9pendances", "text": "Nous utilisons la m\u00e9thode propos\u00e9e par Lin (1998) \u00e0 partir des d\u00e9pendances syntaxiques extraites automatiquement depuis notre corpus de travail. Ces d\u00e9pendances sont stock\u00e9es et index\u00e9es. Nous avons \u00e0 disposition un ensemble de relations grammaticales de d\u00e9pendances\n4 Mots pleins : noms, verbes, adjectifs et adverbes.\n5 Nous utilisons la version 2.5.1 de cette ressource lexicale. http://babelnet.org\nJADT 2016 : 13\u00e8me Journ\u00e9es internationales d\u2019Analyse statistique des Donn\u00e9es Textuelles\nsyntaxiques. Cet ensemble nous permet de mesurer le degr\u00e9 de cooccurrence entre deux mots. La seule condition pour que la m\u00e9thode fonctionne est que les deux mots doivent partager la m\u00eame partie du discours. Prenons l\u2019exemple suivant : \u00ab we \u2018ve moved on \u00bb. Les triplets6 de d\u00e9pendances syntaxiques retourn\u00e9s par Mate-Tools sont : (move, sbj, we), (move, aux, have), (move, advmod, on) et (move, punct, .). Nous pouvons voir les triplets comme des traits syntaxiques : pour le triplet (move, advmod, on), on a pour trait syntaxique advmod (move). La similarit\u00e9 distributionnelle entre deux mots est d\u00e9finie par la fonction suivante :\nF (w1) et F (w2) repr\u00e9sentent l\u2019ensemble des traits syntaxiques poss\u00e9d\u00e9s respectivement par w1 et w2. repr\u00e9sente l\u2019ensemble des traits syntaxiques communs entre w1 et w2. Si I(S) est la quantit\u00e9 d\u2019information contenue dans l\u2019ensemble des traits de S alors o\u00f9 P(f) est la probabilit\u00e9 d\u2019avoir le trait syntaxique f. Cette similarit\u00e9 prend une valeur entre 0 et 1. Elle retourne 1 si w1 et w2 partagent les m\u00eames traits syntaxiques et retourne 0 si aucun trait syntaxique de w1 n\u2019est partag\u00e9 avec les traits syntaxiques de w2. La probabilit\u00e9 P(f) est estim\u00e9e par le pourcentage des mots poss\u00e9dant le trait syntaxique f parmi l\u2019ensemble des mots ayant la m\u00eame partie du discours du mot analys\u00e9."}, {"heading": "3.2.2. Word2vec", "text": "Les repr\u00e9sentations vectorielles continues des unit\u00e9s lexicales sont en plein essor et ont d\u00e9j\u00e0 \u00e9t\u00e9 appliqu\u00e9es avec succ\u00e8s \u00e0 de nombreuses t\u00e2ches en traitement automatique de la langue (Sahlgren, 2008 ; Baroni et Lenci, 2010 ; Mikolov et al., 2013). Il s\u2019agit de projeter les mots selon un mod\u00e8le de langage dans un espace dans lequel les relations s\u00e9mantiques entre ces mots peuvent \u00eatre observ\u00e9es ou mesur\u00e9es. La technique des Word2vec (Mikolov et al., 2013) construit un r\u00e9seau de neurones dont le but est de projeter les mots d\u2019une langue (contenus dans une fen\u00eatre s\u00e9mantique d\u00e9finie) dans un espace de repr\u00e9sentation vectorielle. Chaque mot est repr\u00e9sent\u00e9 par un vecteur plein, de taille mod\u00e9r\u00e9e, qui correspond \u00e0 une projection du mot dans un espace o\u00f9 les distances mod\u00e9lisent les relations inter-mots. Cette projection permet de tirer profit des mots selon leurs sens dans une r\u00e9gion de l\u2019espace s\u00e9mantique proche. Par exemple, \u00ab Paris \u00bb et \u00ab London \u00bb peuvent partager l\u2019id\u00e9e de \u00ab capital city \u00bb.\nIl y a deux types de mod\u00e8les Word2vec : le premier repose sur une architecture fond\u00e9e sur les sacs-de-mots continus (continuous bag of words ou CBOW), le deuxi\u00e8me repose sur une architecture fond\u00e9 sur les Skip-Grams. Ces architectures sont manipul\u00e9es par un r\u00e9seau de neurones. Le mod\u00e8le CBOW cherche \u00e0 pr\u00e9dire un mot selon son contexte alors que le mod\u00e8le Skip-Grams cherche \u00e0 pr\u00e9dire un contexte sachant un mot. Dans notre travail, nous utilisons le mod\u00e8le Skip-Grams parce que nous nous int\u00e9ressons \u00e0 la s\u00e9lection d\u2019un contexte r\u00e9duit en terme de taille et permettant de retourner un certain nombre k des mots les plus pertinents par rapport au contexte d\u2019origine. Nous utilisons une alternative du projet Word2vec7 fait en java par l\u2019\u00e9quipe Medallia8 pour l\u2019int\u00e9grer dans notre programme principal, fait en java, de\n6 Un triplet de d\u00e9pendance syntaxique se compose d'un nom de la relation, d'un gouverneur et d\u2019un d\u00e9pendant.\n7 https://github.com/medallia/Word2VecJava\n8 http://engineering.medallia.com\nJADT 2016 : 13\u00e8me Journ\u00e9es internationales d\u2019Analyse statistique des Donn\u00e9es Textuelles\nd\u00e9sambigu\u00efsation s\u00e9mantique. L\u2019entra\u00eenement du r\u00e9seau de neurones est r\u00e9alis\u00e9 sur les m\u00eames donn\u00e9es du corpus de travail avec un pr\u00e9traitement. Tous les mots sont lemmatis\u00e9s et annot\u00e9s en parties du discours avec la cha\u00eene de traitement Mate-Tools. Par exemple, la phrase \u00ab In short, the issue is an important one. \u00bb est remplac\u00e9 par \u00ab in_IN short_Adj ,_, the_DT issue_N be_V an_DT important_Adj one_N ._. \u00bb. Pour le param\u00e9trage du r\u00e9seau de neurones, nous avons choisi une fen\u00eatre d\u2019une taille de 20 mots (leur fr\u00e9quence d\u2019apparition est d\u2019un minimum \u00e9gal \u00e0 5, la dimension des vecteurs est de 300, le nombre d\u2019exemples n\u00e9gatifs est de 7 avec une utilisation de l\u2019alternative \u00ab softmax hi\u00e9rarchique \u00bb). Pour mesurer la similarit\u00e9 entre mots, nous utilisons la mesure cosinus. Cette m\u00e9thode poss\u00e8de l\u2019avantage de ne pas \u00eatre d\u00e9pendante de la partie du discours des mots \u00e0 comparer."}, {"heading": "3.3. Similarit\u00e9s s\u00e9mantiques", "text": "Nous utilisons l\u2019algorithme de Lesk (1986) et ses variantes pour mesurer la similarit\u00e9 s\u00e9mantique. Ces algorithmes n\u00e9cessitent un dictionnaire (BabelNet dans notre cas) et aucun apprentissage. L\u2019algorithme de base de Lesk est tr\u00e8s simple : il consid\u00e8re la similarit\u00e9 entre deux sens comme le nombre de mots pleins en commun dans leurs d\u00e9finitions que nous appelons par la suite \u00ab traits s\u00e9mantiques \u00bb, sans tenir compte de l\u2019ordre des mots. Nous utilisons Mate-Tools pour obtenir ces traits s\u00e9mantiques. La fonction utilis\u00e9e pour mesurer la similarit\u00e9 s\u00e9mantique se pr\u00e9sente par :\nDans le cas o\u00f9 aucune d\u00e9finition n\u2019est propos\u00e9e pour un sens, nous tenons compte des synonymes. D\u2019un autre c\u00f4t\u00e9, nous utilisons une variante de l\u2019algorithme de Lesk (Navigli, 2009) consistant \u00e0 comparer chaque sens candidat avec le contexte du mot w \u00e0 d\u00e9sambigu\u00efser. Comme contexte, nous tenons compte de la phrase dont laquelle le mot polys\u00e9mique appara\u00eet. La fonction utilis\u00e9e se pr\u00e9sente par :\nSi est l\u2019III\u00e8me sens du mot w. L\u2019algorithme de Lesk est tr\u00e8s sensible \u00e0 la pr\u00e9sence des mots. Une absence des mots repr\u00e9sentant fortement les sens dans les d\u00e9finitions retourne des r\u00e9sultats qui ne sont pas de bonne qualit\u00e9. Nous utilisons l\u2019algorithme de Lesk \u00e9tendu (Banerjee et Pedersen, 2002) pour faire face \u00e0 cette limite. Nous avons pr\u00e9f\u00e9r\u00e9 d\u2019utiliser une version simplifi\u00e9e9 de l\u2019algorithme au lieu de la version originale pour des raisons calculatoires. Cette version simplifi\u00e9e consiste \u00e0 comparer les traits s\u00e9mantiques dans les d\u00e9finitions des sens des mots du contexte ainsi que dans les d\u00e9finitions des sens provenant de diff\u00e9rentes relations telles que l\u2019hyperonymie, l\u2019hyponymie, la m\u00e9ronymie ou l\u2019holonymie."}, {"heading": "3.4. D\u00e9sambigu\u00efsation", "text": "Nous pouvons voir notre m\u00e9thode comme un processus \u00e0 deux niveaux : le premier s\u00e9lectionne les voisins les plus proches au moyen d'une similarit\u00e9 distributionnelle, le deuxi\u00e8me permet de lever les ambigu\u00eft\u00e9s au moyen d'une similarit\u00e9 s\u00e9mantique. La similarit\u00e9 distributionnelle entre le mot \u00e0 d\u00e9sambigu\u00efser et chacun des voisins s\u00e9lectionn\u00e9s est plus forte que celle du mot \u00e0 d\u00e9sambigu\u00efser et chacun des autres mots du contexte. La similarit\u00e9 s\u00e9mantique utilis\u00e9e tient compte des traits s\u00e9mantiques provenant des d\u00e9finitions des sens. Le sens candidat choisi pour un mot polys\u00e9mique est cens\u00e9 \u00eatre celui qui partage le plus de traits\n9 Nous faisons une comparaison entre des unit\u00e9s lexicales (mots) et non pas sur des s\u00e9quences de mots.\nJADT 2016 : 13\u00e8me Journ\u00e9es internationales d\u2019Analyse statistique des Donn\u00e9es Textuelles\ns\u00e9mantiques avec les sens des voisins s\u00e9lectionn\u00e9s. A titre d'exemple, le sens lawyer (homme de loi) du mot lawyer partage plus de traits s\u00e9mantiques avec le sens law (loi) du mot law que le sens lawyer (poisson) peut partager. Nous adaptons une m\u00e9thode structurelle fond\u00e9e sur une distance s\u00e9mantique entre sens selon la formule propos\u00e9e par (Navigli, 2009) :\net est l\u2019ensemble ordonn\u00e9 des voisins les plus proches du mot cible . est l\u2019ensemble des sens du voisin et est l\u2019ensemble des sens du mot cible . est la fonction utilis\u00e9e pour mesurer la similarit\u00e9 entre deux sens et . Nous utilisons la phrase, dans laquelle le mot \u00e0 d\u00e9sambigu\u00efser appara\u00eet, comme contexte. Dans le cas d\u2019une \u00e9galit\u00e9 de score entre plusieurs sens candidats, nous utilisons une heuristique qui tient compte du sens poss\u00e9dant le plus grand nombre de connexions s\u00e9mantiques dans le r\u00e9seau BabelNet.\n4. Exp\u00e9riences\nDans Senseval-1 et Senseval-2, des variantes de l\u2019algorithme de Lesk ont \u00e9t\u00e9 consid\u00e9r\u00e9es soit comme des approches de base soit comme des syst\u00e8mes complets. Dans Senseval-1, la plupart des syst\u00e8mes de d\u00e9sambigu\u00efsation ayant particip\u00e9 \u00e0 la t\u00e2che All-Words (AW) ont \u00e9t\u00e9 surclass\u00e9s par une variante de Lesk (Kilgarriff, Rosenzweig, 2000). D\u2019un autre c\u00f4t\u00e9, durant Senseval-2, les algorithmes \u00e0 base de Lesk ont \u00e9t\u00e9 surclass\u00e9s par la plupart des syst\u00e8mes ayant particip\u00e9 \u00e0 la t\u00e2che Lexical-Sample.\nNotre syst\u00e8me retourne le m\u00eame nombre de r\u00e9ponses que les donn\u00e9es sur lesquelles nous prenons une r\u00e9f\u00e9rence (224 370 occurrences de mots dont 191 146 occurrences sont pour des mots polys\u00e9miques). Afin de mesurer la performance de notre syst\u00e8me de d\u00e9sambigu\u00efsation, nous ne tenons pas compte des mots o\u00f9 BabelNet renvoie un seul sens candidat. Nous utilisons le taux d\u2019exactitude pour mesurer cette performance."}, {"heading": "4.1. Protocole exp\u00e9rimental", "text": "Pour comparer les performances de notre approche, nous avons choisi d\u2019une part de faire des exp\u00e9riences sur l\u2019ensemble des mots polys\u00e9miques du corpus d\u2019\u00e9valuation et, d\u2019autre part, de faire des exp\u00e9riences sur un \u00e9chantillon de mots polys\u00e9miques. Notre \u00e9valuation se porte sur la s\u00e9lection des voisins distributionnels ainsi que sur l\u2019algorithme de d\u00e9sambigu\u00efsation. Nous faisons une comparaison avec les voisins les plus proches lin\u00e9airement en les s\u00e9lectionnant de la droite vers la gauche. Nous utilisons un param\u00e8tre k pour choisir le nombre de voisins \u00e0 s\u00e9lectionner. Le choix se porte sur une valeur entre 2 et 7. Nous avons pr\u00e9sent\u00e9 dans la soussection 3.2 deux mesures distributionnelles, la premi\u00e8re repose sur la m\u00e9thode de Lin et la deuxi\u00e8me sur la m\u00e9thode Word2vec (W2V). Dans nos exp\u00e9riences, nous utilisons une autre mesure distributionnelle (ALL) repr\u00e9sentant une combinaison10 des deux mesures."}, {"heading": "4.2. Jeu de test", "text": "Les mots du jeu de test sont choisis selon leur niveau d\u2019ambigu\u00eft\u00e9 (peu ambigu, ambigu ou tr\u00e8s ambigu). Nous avons fait une s\u00e9lection de quatre mots pour les cat\u00e9gories grammaticales\n10 Nous utilisons une moyenne entre les deux mesures et prenons en compte des voisins partageant la m\u00eame partie du discours avec le mot \u00e0 d\u00e9sambigu\u00efser.\nJADT 2016 : 13\u00e8me Journ\u00e9es internationales d\u2019Analyse statistique des Donn\u00e9es Textuelles\nnoms, verbes et adjectifs : noms= {argument, disc, paper, plan}, verbes= {operate, note, add, begin}, adjectifs= {black, valid, wet, narrow}. Nous avons \u00e0 disposition un ensemble de 12 mots repr\u00e9sentant 1 022 occurrences dans SemCor. Nous comparons nos r\u00e9sultats avec Babelfy (Moro et al., 2014), un syst\u00e8me de d\u00e9sambigu\u00efsation utilisant BabelNet comme base de connaissances."}, {"heading": "4.3. R\u00e9sultats", "text": "Le tableau 1 pr\u00e9sente les r\u00e9sultats obtenus sur l\u2019ensemble des mots polys\u00e9miques trait\u00e9s dans le corpus SemCor (191 146 occurrences de mots). Ce tableau tient compte de toutes les m\u00e9thodes d\u2019analyse distributionnelle et tous les algorithmes utilis\u00e9s de d\u00e9sambigu\u00efsation en s\u00e9lectionnant quatre voisins. Sur ce m\u00eame tableau, nous pr\u00e9sentons une comparaison avec la s\u00e9lection des voisins les plus proches lin\u00e9airement. L\u2019algorithme LeskVar fait r\u00e9f\u00e9rence \u00e0 la variante de Lesk, LeskB-PPVL pr\u00e9sente l\u2019application de l\u2019algorithme de base de Lesk sur les voisins les plus proches lin\u00e9airement, LeskES-PPVL fait r\u00e9f\u00e9rence \u00e0 l\u2019application de l\u2019algorithme de Lesk \u00e9tendu simplifi\u00e9 sur ces m\u00eames voisins, LeskB-PPVD pour l\u2019algorithme de base de Lesk en utilisant les voisins distributionnels et LeskES-PPVD pour l\u2019application de l\u2019algorithme de Lesk \u00e9tendu simplifi\u00e9 sur ces voisins distributionnels.\nAlgorithmes/\nPOS LeskVar\nLeskB-\nPPVL\nLeskES-\nPPVL\nLeskB-PPVD LeskES-PPVD\nLin W2V ALL Lin W2V ALL\nNoms 40,7% 40,6% 45,3% 41,4% 40,0% 41,3% 47,3% 44,7% 47,2%\nVerbes 34,4% 25,2% 30,0% 29,9% 28,0% 30,0% 30,2% 26,1% 30,2%\nAdjectifs 48,3% 45,3% 44,8% 48,0% 43,3% 47,9% 49,4% 40,4% 49,4%\nAdverbes 45,9% 47,6% 42,0% 45,8% 46,4% 45,7% 42,3% 41,7% 42,3%\nTableau 1 : Taux d\u2019exactitude obtenus selon diff\u00e9rents algorithmes de d\u00e9sambigu\u00efsation (k=4)\nEn termes de comparaison des m\u00e9thodes d\u2019analyse distributionnelle, il s\u2019av\u00e8re que l\u2019utilisation de la m\u00e9thode de Lin est plus rentable et meilleure, en qualit\u00e9, que l\u2019utilisation de la m\u00e9thode W2V. Nous remarquons aussi que la combinaison des deux m\u00e9thodes ne retourne pas des r\u00e9sultats aussi meilleurs que la simple utilisation de la m\u00e9thode de Lin. L\u2019utilisation d\u2019une analyse syntaxique en d\u00e9pendances pour la t\u00e2che de d\u00e9sambigu\u00efsation s\u00e9mantique reste meilleure. L\u2019algorithme de Lesk \u00e9tendu simplifi\u00e9 retourne les meilleurs r\u00e9sultats pour les noms et les adjectifs. Pour le cas des verbes, nous pouvons avoir les meilleurs r\u00e9sultats sans aller chercher l\u2019information s\u00e9mantique dans les relations s\u00e9mantiques, il suffit de tenir compte des mots du contexte (variante de Lesk). Pour le type des voisins \u00e0 utiliser (distributionnel vs lin\u00e9aire), le voisin distributionnel rend la d\u00e9sambigu\u00efsation s\u00e9mantique encore meilleure que le voisin le plus proche lin\u00e9airement et cela pour les noms, verbes et adjectifs. Une exception est \u00e0 noter pour les adverbes o\u00f9 les r\u00e9sultats sont plus ou moins proches selon l\u2019algorithme utilis\u00e9.\nLa figure 1 pr\u00e9sente l\u2019application de l\u2019algorithme de Lesk \u00e9tendu simplifi\u00e9 dont le nombre de voisins est variable. Nous remarquons que l\u2019utilisation d\u2019un petit nombre de voisins distributionnels peut nous mener \u00e0 atteindre les meilleurs r\u00e9sultats. La figure 2 pr\u00e9sente les r\u00e9sultats seulement sur les occurrences de mots annot\u00e9es manuellement avec le sens le plus fort dans BabelNet. Nous aurions pu imaginer avec l\u2019heuristique utilis\u00e9e qu\u2019on peut atteindre\ndes r\u00e9sultats dans les 80-90% mais ce n\u2019est pas le cas. Nous atteignons seulement 75% pour les noms et 67% sur l\u2019ensemble des mots avec une utilisation de la m\u00e9thode de Lin (cf. figure 2). BabelNet comme WordNet et comme toute autre ressource lexicale contient des erreurs et des incoh\u00e9rences et celles-ci se traduisent souvent par des anomalies dans SemCor.\nLa figure 3 pr\u00e9sente les r\u00e9sultats sur les mots du jeu de test par application de la m\u00e9thode de Lin. La figure 4 pr\u00e9sente les r\u00e9sultats sur ces m\u00eames mots par application des diff\u00e9rentes m\u00e9thodes d\u2019analyse distributionnelle et selon l\u2019algorithme LeskES-PPVD. A ce stade, le meilleur taux d\u2019exactitude est de 58% contre 61% seulement pour Babelfy.\nde l\u2019algorithme de Lesk \u00e9tendu simplifi\u00e9 sur\nl\u2019ensemble des mots polys\u00e9miques du corpus\nSemCor\nmots ayant \u00e9t\u00e9 annot\u00e9s manuellement par le\nsens le plus fort selon BabelNet, application\nde l\u2019algorithme de Lesk \u00e9tendu simplifi\u00e9 avec\nk=4\nJADT 2016 : 13\u00e8me Journ\u00e9es internationales d\u2019Analyse statistique des Donn\u00e9es Textuelles"}, {"heading": "5. Conclusion", "text": "Cet article propose une m\u00e9thode permettant de r\u00e9duire la complexit\u00e9 exponentielle qu\u2019engendre l\u2019algorithme le plus direct de d\u00e9sambigu\u00efsation s\u00e9mantique. Nous avons remarqu\u00e9 que l\u2019utilisation des voisins distributionnels permet non seulement de r\u00e9duire cette complexit\u00e9 mais aussi de garder une coh\u00e9rence au niveau de la d\u00e9sambigu\u00efsation. Pour lever l\u2019ambigu\u00eft\u00e9 des noms et des adjectifs, l\u2019utilisation des voisins distributionnels reste meilleure que la simple utilisation des voisins les plus proches lin\u00e9airement. Nous pr\u00e9voyons, en perspectives, d\u2019\u00e9tendre cette \u00e9tude en travaillant sur d\u2019autres similarit\u00e9s s\u00e9mantiques que la simple comparaison par \u00e9galit\u00e9 des traits s\u00e9mantiques entre sens afin d\u2019augmenter les performances de notre syst\u00e8me. Nous pouvons utiliser les mesures de similarit\u00e9 distributionnelles propos\u00e9es pour calculer une proximit\u00e9 s\u00e9mantique entre sens et cela en tenant compte de chaque paire possible de mots.\nR\u00e9f\u00e9rences\nBakx G. E. (2006). Machine Learning Techniques for Word Sense Disambiguation. Dept. LSI. Universitat Polit\u00e8cnica de Catalunya, Barcelona, Catalunya.\nBanerjee S. et Pedersen T. (2002). An adapted lesk algorithm for word sense disambiguation using wordnet. In CICLing, London, UK, pages 136\u2013145.\nBaroni M. et Lenci A. (2010). Distributional memory: A general framework for corpus based semantics. Computational Linguistics, 36(4), 673\u2013721.\nBillami M. B. (2015). D\u00e9sambigu\u00efsation lexicale \u00e0 base de connaissances par s\u00e9lection distributionnelle et traits s\u00e9mantiques. Actes de la 22e conf\u00e9rence en Traitement Automatique des Langues Naturelles, session RECITAL, Caen, pages 13\u201324.\nBohnet B. et Nivre J. (2012). A Transition-Based System for Joint Part-of-Speech Tagging and Labeled Non-Projective Dependency Parsing. EMNLP-CoNLL, pages 1455\u20131465.\nCalzolari N. et Corazzari O. (2000). Senseval/Romanseval: The Framework for Italian, Computers and the Humanities 34: 61\u201378, Kluwer Academic Publishers, Printed in Netherland.\nEdmonds P. (2002). SENSEVAL: The Evaluation of Word Sense Disambiguation Systems, ELRA Newsletter, Vol. 7, No. 3.\nEdmonds P. et Kilgarriff A. (2002). Introduction to the special issue on evaluating word sense disambiguation systems. Journal of Natural Language Engineering, 8(4):279\u2013291.\nFellbaum C. (1998). WordNet: an Electronic Lexical Database. MIT Press. Haji\u010d J., Ciaramita M., Johansson R., Kawahara D., Marti M. A., M\u00e0rquez L., Meyers A., Nivre J.,\nPad\u00f3 S., \u0160t\u011bp\u00e1nek J., Stra\u0148\u00e1k P., Surdeanu M., Xue N. et Zhang Y. (2009). The conll-2009 shared task: Syntactic and semantic dependencies in multiple languages. In Proceedings of the 2009 CoNLL Shared Task, pages 1\u201318.\nIde N. et V\u00e9ronis J. (1998). Word sense disambiguation: The state of the art. Computat. Ling. 24(1), 1\u201341, MIT Press, Cambridge, MA, USA.\nKilgarriff A. et Rosenzweig J. (2000). Framework and Results for English SENSEVAL, Computers and the Humanities, 34, pages 15\u201348.\nKoehn P. (2005). Europarl: A Parallel Corpus for Statistical Machine Translation, MT Summit 2005. Lafourcade M. (2011). Lexique et analyse s\u00e9mantique de textes \u2013 structures, acquisition, calculs et\njeux de mots. M\u00e9moire d\u2019habilitation \u00e0 diriger les recherches, Universit\u00e9 Montpellier 2, LIRMM. Soutenu le 7 d\u00e9cembre 2011.\nJADT 2016 : 13\u00e8me Journ\u00e9es internationales d\u2019Analyse statistique des Donn\u00e9es Textuelles\nLesk M. (1986). Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone. In Proceedings of the 5th SIGDOC, New York, pages 24\u201326.\nLin D. (1998). An information-theoretic definition of similarity. In Proceedings of the 15th International Conference on Machine Learning (ICML, Madison, WI), pages, 296\u2013304.\nMccarthy D., Koeling R., Weeds, J. et Carroll J. (2004). Finding predominant senses in untagged text. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, Barcelona, Spain, pages 280\u2013287.\nMihalcea R., Edmonds P. (2004). Proceedings of the 3rd International Workshop on the Evaluation of Systems for the Semantic Analysis of Text (Senseval-3, Barcelona, Spain).\nMikolov T. et Corrado G., Chen K. et Dean J. (2013). Efficient Estimation of Word Representations in Vector Space. Proceedings of the International Conference on Learning Representations (ICLR 2013), pages 1\u201312.\nMiller G. A., Leacock C., Tengi R. et Bunker R. T. (1993). A semantic concordance. In Proceedings of the ARPA Workshop on Human Language Technology, pages 303\u2013308.\nMoro A. et Navigli R. (2015) SemEval-2015 Task 13: Multilingual All-Words Sense Disambiguation and Entity Linking. Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval), in the 2015 Conference of the North American Chapter of the Association for\nComputational Linguistics (NAACL 2015), Denver, Colorado, June 4-5th, 2015, pages 288\u2013297. Moro A., Raganato A. et Navigli R. (2014). Entity Linking meets Word Sense Disambiguation: a\nUnified Approach. Transactions of the Association for Computational Linguistics (TACL), 2, pages 231\u2013244.\nNavigli R. (2009). Word Sense Disambiguation: a Survey. ACM Computing Surveys, 41(2), ACM Press, 2009, pages 1\u201369.\nNavigli R., Jurgens D. A. et Vannella D. (2013). SemEval-2013 Task 12: Multilingual Word Sense Disambiguation. Proceedings of 7th International Workshop on Semantic Evaluation (SemEval), in the Second Joint Conference on Lexical and Computational Semantics, Atlanta, USA, June 14- 15th, 2013, pages 222\u2013231.\nNavigli R., Litkowski K. et Hargraves O. (2007) SemEval-2007 Task 07: Coarse-Grained English AllWords Task. Proceedings of Semeval-2007 Workshop (SEMEVAL), in the 45th Annual Meeting of the Association for Computational Linguistics (ACL 2007), Prague, Czech Republic, June 23-24th, 2007, pages 30\u201335.\nNavigli R. et Ponzetto S. (2012). BabelNet: The Automatic Construction, Evaluation and Application of a Wide-Coverage Multilingual Semantic Network. Artificial Intelligence, 193, Elsevier, 2012, pages 217\u2013250.\nPedersen T., Banerjee S. et Patwardhan S. (2005). Maximizing Semantic Relatedness to Perform Word Sense Disambiguation. Research Report UMSI 2005/25, University of Minnesota Supercomputing Institute.\nSahlgren M. (2008). The distributional hypothesis. Italian Journal of Linguistics, 20(1), 33\u201354. Segond F. (2000). Framework and Results for French, Computers and the Humanities 34: 49\u201360,\nKluwer Academic Publishers, Printed in Netherland. Snyder B. et Palmer. M. (2004). The English All-Words Task. In Proceedings of SENSEVAL-3, pages\n41\u201343. Tchechmedjiev A. (2012). \u00c9tat de l\u2019art : mesures de similarit\u00e9 s\u00e9mantique locales et algorithmes\nglobaux pour la d\u00e9sambigu\u00efsation lexicale \u00e0 base de connaissances. In Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 3: RECITAL, ATALA/AFCP. June 2012, Grenoble, France, pages 295\u2013308."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "Word sense disambiguation (WSD) improves many Natural Language Processing (NLP) applications such as Information Retrieval, Machine Translation or Lexical Simplification. WSD is the ability of determining a word sense among different ones within a polysemic lexical unit taking into account the context. The most straightforward approach uses a semantic proximity measure between the word sense candidates of the target word and those of its context. Such a method very easily entails a combinatorial explosion. In this paper, we propose two methods based on distributional analysis which enable to reduce the exponential complexity without losing the coherence. We present a comparison between the selection of distributional neighbors and the linearly nearest neighbors. The figures obtained show that selecting distributional neighbors leads to better results. R\u00e9sum\u00e9 La d\u00e9sambigu\u00efsation s\u00e9mantique permet d\u2019am\u00e9liorer de nombreuses applications en traitement automatique des langues (TAL) comme la recherche d\u2019information, la traduction automatique ou la simplification lexicale de textes. Elle consiste \u00e0 choisir le sens des unit\u00e9s lexicales polys\u00e9miques dans un texte et s\u2019effectue en tenant compte du contexte. L\u2019approche la plus directe consiste \u00e0 estimer la proximit\u00e9 s\u00e9mantique entre chaque sens candidat et les sens des mots du contexte. Cette m\u00e9thode engendre rapidement une explosion combinatoire. Dans cet article, nous proposons deux approches \u00e0 base d\u2019analyse distributionnelle permettant de r\u00e9duire la complexit\u00e9 exponentielle et de ne pas perdre de la coh\u00e9rence au niveau de la d\u00e9sambigu\u00efsation, cela en s\u00e9lectionnant les voisins distributionnels les plus proches. Nous pr\u00e9sentons une comparaison entre la s\u00e9lection des voisins distributionnels et les voisins les plus proches lin\u00e9airement. Les r\u00e9sultats montrent que la s\u00e9lection des voisins distributionnels est bien meilleure.", "creator": "Microsoft\u00ae Word 2013"}}}