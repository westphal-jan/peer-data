{"id": "1703.01461", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Mar-2017", "title": "Addressing Appearance Change in Outdoor Robotics with Adversarial Domain Adaptation", "abstract": "appearance changes due to weather and seasonal flows represent a strong impediment to the robust implementation unlike machine learning systems in autonomous robotics. while the model largely optimised for various training domain it will deliver degraded performance in application domains that underlie processing shifts caused by these changes. traditionally, collision problem has been addressed via the detection of labelled data in multiple domains or by imposing priors on the type of shift between applied domains. we frame the problem surrounding the scenarios of unsupervised domain adaptation and apply an adversarial logic i train a cooperative neural network with the additional features to align features across domains. generic approach benefits above adding unlabelled data and is generally applicable to many state - of - the - art architectures. moreover, as adversarial training is notoriously nonlinear to stabilise, we first perform an extensive ablation puzzle exploring a surrogate classification task underlying the same appearance change and then apply the distilled insights to the problem of free - space segmentation for motion planning.", "histories": [["v1", "Sat, 4 Mar 2017 14:28:51 GMT  (1293kb,D)", "http://arxiv.org/abs/1703.01461v1", null], ["v2", "Sun, 17 Sep 2017 13:44:28 GMT  (1438kb,D)", "http://arxiv.org/abs/1703.01461v2", "In Proceedings of the 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2017)"]], "reviews": [], "SUBJECTS": "cs.RO cs.LG", "authors": ["markus wulfmeier", "alex bewley", "ingmar posner"], "accepted": false, "id": "1703.01461"}, "pdf": {"name": "1703.01461.pdf", "metadata": {"source": "CRF", "title": "Addressing Appearance Change in Outdoor Robotics with Adversarial Domain Adaptation", "authors": ["Markus Wulfmeier", "Alex Bewley", "Ingmar Posner"], "emails": ["ingmar@robots.ox.ac.uk"], "sections": [{"heading": null, "text": "I. INTRODUCTION\nIn this paper we revisit the prominent issue in field robotics of appearance change under the influence of numerous factors including time of day, weather, and seasonal variation. Dealing with these changes becomes relevant in all modules of the robotic perception system including localisation [1], mapping [2] and obstacle detection [3]. Given the recent adoption of high capacity deep neural networks for many robotic vision tasks, the effects of condition variation have been moderately alleviated with the assumption that the labelled training data is diverse enough to capture the variation expected during deployment. However, due to the expense and impracticality of collecting labels across all environmental conditions, the training data is commonly captured in a subset of episodes which exacerbates the effects of appearance change when deployed.\nThis work addresses the problem of appearance change by reframing it in the context of unsupervised domain adaptation. With this view, we are acknowledging that the underlying distribution of our labelled training data may differ considerably from unlabelled data encountered in the application domain. Methods for domain adaptation have already found success in robotics for transfer from 3D models to laser data [4] or from simulation to real images collected indoors [5]. Here we focus on developing a general and flexible framework for adapting supervised machine learning models to address appearance change for outdoor robotics problems (as depicted in Figure 1).\n1The authors are with the Oxford Robotics Institute, Department of Engineering Science, University of Oxford, United Kingdom; markus, bewley, ingmar@robots.ox.ac.uk\nTraditional approaches for addressing the general domain adaptation problem have focused on modelling the density of the source and target distributions separately [6] or with imposed prior structure [7]. However, density estimation itself is a challenging issue, particularly for appearance, as it is difficult to impose a prior without making assumptions on the distribution. Recently, generative adversarial networks (GAN) were proposed [8] as a framework to model any arbitrary distribution where a generating network is optimised to produce data indistinguishable from real data as considered by a discriminating network. Building on the flexibility of GANs, adversarial domain adaptation (ADA) has demonstrated astonishing performance for unsupervised domain adaption [9], [10].\nWe develop a straightforward framework for the adaptation of existing, commonly used network architectures that allows to benefit from recent progress in deep learning. To demonstrate the widespread applicability of ADA with this schema, we modify two popular network architectures, AlexNet [11] and FCN-VGG16 [12] which are known to work well for the tasks of classification and pixel-wise image segmentation respectively. When considered in an outdoor context, both tasks are affected by change in appearance caused by factors such as time of day or weather conditions.\nDue to the documented evidence of training instability of adversarial training procedures [8], [13], [14], we first use place classification as a surrogate task to perform an extensive evaluation of approaches for balancing our objectives and\nar X\niv :1\n70 3.\n01 46\n1v 1\n[ cs\n.R O\n] 4\nM ar\n2 01\n7\nstabilising the training process. The reduction in complexity enables us to enumerate and explore various potential configurations of the network structure and training procedures to identify the key factors of influence before scaling up to the more challenging segmentation task. Particularly, we seek to answer the following questions:\n1) Trade-offs: How do we stabilise training and balance supervised and adversarial objectives? 2) Architecture: How can we directly adapt existing network architectures that are known to perform well? 3) Performance: Where does ADA work best and how do larger appearance changes influence performance?\nA series of experiments is presented to provide valuable insights around the above questions facilitating the extension to full image pixelwise traversability segmentation commonly used as an input to motion planning systems. In the final segmentation task we see a significant performance increase in the target domain by applying ADA over the FCNVGG16 [12] baseline. Furthermore, we also demonstrate that the approach can act as a regulariser and leads to performance gains within the original domain as more unlabelled data become available."}, {"heading": "II. RELATED WORK", "text": "In robotics, the problem of appearance change has long been an issue for both laser and image data. Lai and Fox [4] presented an exemplar based approach to align spin-image features from web based 3D models to dense laser scan. For visual appearance, the colour-constant transform [15] is commonly applied directly on the image to achieve lighting invariance for localisation [16], visual teach and repeat [1] and segmentation [3]. Other works in localisation take a multiview approach by either exploiting temporal structure [17] or by accumulating multiple experiences covering different appearances [2] to avoid the issue of modelling appearance change. The work of Neubert et al. [18] is the closest to our approach where they learn synthesise stored images into the current season. By casting the appearance change issue as an unsupervised domain adaption problem our approach differs from the previous work as we do not require known cross domain correspondences.\nIn the context of domain shift between training and test data, Ben-David et al. [19] derived theoretical upper bounds on a classifiers performance. While unsupervised domain adaptation is an open research problem in theoretical and practical terms [10], [20], recent successes have shown the capability to train expressive, flexible models and address high dimensional input distributions and therefore made first steps in enabling real world applicability [9], [21].\nThe majority of recent successes have built on the empirical superiority of Neural Networks that enable hierarchical representation learning with respect to arbitrary combinations of differential objectives. In the context of domain adaptation we can minimise the mutual information between feature representations and the underlying domain while maximising relevance towards a supervised objective in the source domain. Long et al [22] focus on minimising the Maximum Mean\nDiscrepancy for the feature distributions of multiple layers of the network architecture. Sun et al. [23] align second order statistics of layer activations for source and target domain.\nRecently, the field has been extended with adversarial methods to domain adaptation [24], [25] which have resulted in strong performance benefits [10]. Adversarial unsupervised domain adaptation relies on training a discriminator to differentiate the domains underlying feature distributions while competing against an encoder which attempts to conceal the origin domain of input samples. While the loss formulation for the discriminator stays consistent between most approaches, different objectives have been applied for the encoder, including the minimax formulation resulting from a \u2018gradient reversal layer\u2019 [24], and the confusion loss [26] that was found to address problems with vanishing gradients based on discriminator saturation in Generative Adversarial Networks (GAN) [8]. These methods have recently been employed to address tasks in medical image segmentation [27], gaze estimation [9] and transfer for reinforcement learning [5]."}, {"heading": "III. ADVERSARIAL DOMAIN ADAPTATION", "text": "The principal goal of ADA is to maximise the performance of a supervised task not only in the source domain - where labels are available - but also in the unlabelled target domain. As a domain shift potentially exists between training and application domains, the approach tries to align the marginal feature distributions independent of label for both domains to achieve its goal.\nTherefore, we train the supervised task module and encoder to maximise the likelihood of source labels given the source inputs. Additionally, to adapt the model towards performing well in the target domain, we train the encoder to confuse a discriminator which tries to estimate the domain of a data sample and serves as density model.\nThe adversarial training process works towards aligning the marginal feature distributions of source and target domain which given partial structural similarity of both domains implicitly also aligns the conditional distributions given the labels. Finally, by aligning the distributions, ADA increases the performance of a supervised module with decision boundaries optimised for the source domains as displayed in Figure 2.\nAn existing network architecture is divided into two functional blocks referred to as encoder and supervised task as represented in Figure 3. Let E : Rn \u2192 Rm be the encoder that transforms an input image ii into the feature representation fi, which subsequently serves as input for both the supervised task S : Rm \u2192 Rc producing label li and the adversarial domain discriminator D : Rm \u2192 R computing domain label di. To reduce the memory footprint of the model, we can remove the discriminator at test time as it is only an auxiliary module to determine the encoder objective.\nThe model tries to simultaneously minimise supervised and adversarial losses, respectively LS and LA, where the adversarial loss is furthermore divided into the loss applying to the encoder LAE and discriminator LAD (see Equations 1 and 3). The supervised objective is minimising the crossentropy loss from Equation 2. While the adversarial encoder and discriminator losses both depend on encoder parameters \u03b8E and discriminator parameters \u03b8D, each loss is only applied to the corresponding module to realise the adversarial training procedure. The filters of the supervised module \u03b8S are only optimised with respect to the supervised loss. The factor \u03bb determines the relative strength of supervised and adversarial objective. In this arrangement, the encoder is encouraged to extract features that balance the relevance the supervised task and the maximisation of domain invariance.\nL(\u03b8S ,\u03b8D,\u03b8E) = LS(\u03b8S ,\u03b8E) + \u03bbLA(\u03b8D,\u03b8E) (1) LS(\u03b8S ,\u03b8E) = El=S(E(i,\u03b8E),\u03b8S),i\u223cS [\u2212 log(l)] (2) LA(\u03b8D,\u03b8E) = LAD(\u03b8D) + LAE(\u03b8E) (3) LAD(\u03b8D) = Ef=E(i),i\u223cS [\u2212 log(D(f, \u03b8D))] + (4)\nEf=E(i),i\u223cT [\u2212 log(1\u2212D(f, \u03b8D))]\nMost existing work describes the adversarial encoder loss via a gradient reversal layer simply as the negated discriminator loss. To retain consistent with multiple possibilities known from the GAN framework, we treat it separately in our formulation.\nThe original generator loss in the GAN framework, similar to the resulting encoder loss in the ADA framework when\napplied with gradient reversal, is the minimax loss in Equation 5. Contrary to the GAN framework, the loss applies to samples from both domains instead of only applying to generated samples. An alternative formulation is to train the encoder to maximise the discriminator\u2019s confusion [8], [26] (see Equation 6). Both approaches are evaluated in Section IV-A.\nminimax loss : LAE(\u03b8E) = \u2212LAD (5)\n= Ef=E(i,\u03b8E),i\u223cS [log(D(f))] +Ef=E(i,\u03b8E),i\u223cT [log(1\u2212D(f))]\nconfusion loss : LAE(\u03b8E) = \u2212Ef=E(i,\u03b8E),i\u223cS [log(1\u2212D(f))](6)\n\u2212Ef=E(i,\u03b8E),i\u223cT [log(D(f))]"}, {"heading": "IV. ABLATION STUDY", "text": "Unsupervised domain adaptation is an inherently complex task as the lack of labelled information complicates the alignment between feature representations from source and target domain. While a high capacity encoder such as a deep neural network is per se capable of modelling even complex relations, the process of alignment might remove important information if it simplifies the alignment. The difficulty of the process is proportional to the difference between the underlying source and target domains. The field of autonomous driving presents a strong opportunity here as the the use of overlapping routes can provide a partial alignment which simplifies the overall learning process.\nWe focus for our main evaluation on the surrogate task of classification and extend the evaluation subsequently to image segmentation with focus on path proposals for autonomous driving [28]. The hyperparameter study is built on a small subset of labelled data from the publicly available Oxford RobotCar Dataset that includes over 1000 km of driving data including images, LIDAR, GPS and INS data [29].\nThe principal experiments were performed based on 9,000 training and 1,000 test images for each domain and 20 distinct location classes. We focus on the adaptation between overcast weather to sunny as displayed in Figure 4.\nThe network architecture builds on AlexNet [11] and while we adapt the split between encoder and classifier / discriminator, the overall pipeline from image to location label is kept the same for all experiments, making this approach easy to apply to other common architectures such as FCNVGG [12], which underlies the segmentation experiments.\nWe determine the mean classification accuracy PT and standard deviation \u03c3 for all tested hyperparameter configurations over 5 runs to investigate for GAN-typical training instability. All experiments are performed on an NVIDIA GTX TITAN GPU. All evaluations included in this work are run with the best found set of hyperparameters for the fixed parameters in each test.\nThe following subsections now address the questions posed in Section I.\nA. Trade-offs: How do we stabilise training and balance supervised and adversarial objectives?\nOne of the most common issues with ADA is the potential inability to learn task-relevant and informative features as the domain confusion loss tries to reduce discriminator performance and can result in degenerate feature representations.\n1) Stabilising: Pretraining and Supervised Warm-up: Initialising network architectures via pretraining of convolutional layers on large and diverse datasets is generally known to speed up the learning process as well as leading to better generalisation [30]. Furthermore, in the context of ADA, it can be helpful to include a warmup phase where only the supervised task loss is used before switching on the adversarial loss. We evaluate pretrained convolutional layers for AlexNet (based on ImageNet classification task [31]) as well as a supervised warmup phase of 15 epochs which, based on a small test run, has been found to work well in a large range of evaluation settings.\nTable I shows that for the given small number of samples, supervised warmup on its own does not suffice for a strong, classifier relevant feature representation therefore we build our following evaluation on pretrained convolutional layers as well as a 15 epochs supervised warmup phase.\n2) Balancing: Adversarial Loss: While the discriminator loss stays fixed across most recent work on ADA based on Equation 4, the choice of the encoder loss varies and has been shown to have significant influence on convergence properties and stability of training in Generative Adversarial Networks [14], which have strong similarities with ADA. The two main generator objectives to consider are the minimax formulation (negated discriminator loss) which is equal to\nthe gradient reversal layer [24] and the confusion loss [26], which has found to prevent vanishing gradients with saturated discriminator but displays higher variance in the gradients [14]. Additionally, the factor \u03bb is used to vary the relative strength of the adversarial loss in the overall training process to balance both objectives.\nFigure 5 shows minimax and confusion loss and gradients in dependence to the discriminator performance on source and target domain data. When the discriminator achieves high performance (close to 1 for source data and 0 for target data), the confusion loss results in significantly stronger gradients which will support a more stable adversarial training process.\nThe evaluation for the minimax loss in Table II begins with considerably lower weights as higher values for \u03bb as 10\u22122\nresulted in significant training instability risking the collapse of the target performance to chance ( 5%). We have found the confusion loss significantly easier to apply as it renders the game between the adversarial modules more stable as displayed in Figure 5. The original minimax-loss formulation was successfully employed in a number of recent works [24], [10], however, we have found the tuning process more complex and obtained significantly stronger results based on the confusion loss.\nB. Architecture: How can we directly adapt existing network architectures that are known to perform well?\nWhen applying ADA to a new task, one can greatly benefit from applying existing network architectures that have been optimised and proven to perform well on similar tasks. This section addresses how to adapt existing architectures easily to incorporate the additional discriminator module.\nThe expressiveness and flexibility of encoder and discriminator directly influence the performance of our domain adaptation task. While the flexibility of the discriminator limits the types of domain discrepancies that can be detected, the encoder structure affects the efficiency of concealing the originating domain from the discriminator while generating relevant feature distributions for classification.\n1) Choice of Split Layer: The following evaluation focuses in particular on AlexNet [11], which we adapt by providing the feature output of a particular layer additionally to a discriminator module. Following Figure 3, the encoder module now includes all layers before the split layer and is shared for source and target domain. We duplicate the architecture following the split layer for supervised module and discriminator and adapt the discriminator to output a single value per input as domain classifier. By varying the split layer with this approach we directly influence the capacity ratio between encoder and discriminator while keeping the overall number of layers for the supervised task fixed.\nThe best possible split results in the middle of the network as both - encoder and discriminator - have enough capacity to fulfil their respective tasks (see Table III). An earlier split layer significantly reduces the encoders capacity to minimise mutual information with respect to the domain while encoding classification-relevant features. A later split decreases the expressiveness of the discriminator\u2019s density model such that less variations can be detected.\n2) Capacity of Discriminator: While the choice of split layer as displayed above has strong influence on the effectiveness of domain adaptation, the approach might benefit from separately adapting the discriminator capacity to improve domain discrimination while keeping the rest of the architecture fixed. In this context, we now evaluate the performance with respect to varying capacity of the discriminator by either adding or removing 2 fully connected layers before the final layer.\nTable IV presents that changing the capacity with the best split layer configuration (layer 4) leads to no improvement and it can be seen for all split layer configurations that trimming layers from the discriminator reduces target performance as\nthe discriminator expressiveness is diminished. Furthermore, extending the discriminator leads to lowered accuracy as the model might overfit to domain discrepancy between both domain\u2019s training sets.\nC. Performance: Where does ADA work best and how do larger appearance changes influence performance?\nTo provide bounds for the performance of the approach we evaluate the classification accuracy of the classifier only trained on training data from the source domain as lower bound and only with training data from the target domain as upper bound. Note, all models are initialised with pretrained convolutional layers pretrained on ImageNet [31].\nAs the complexity for unsupervised domain adaptation directly correlates with the difference between the distributions, we evaluate benefits of the approach on the following source-target pairs Sunny - Overcast and Day - Night with the latter representing a significantly more complex transfer as visualised in Figure 6.\nBy increasing the domain shift occurring between source an target data, we can investigate limitations of the ADA . While the approach leads to performance gains in both scenarios, it is clearly better suited to address domains with limited\n\u2217Performance with available training labels on the target domain. This serves as upper bound for performance.\nshift, such as the overcast-sunny scenario, and performs significantly closer to the upper bound obtained from training on labelled target data.\n1) Improving Performance in Source Domain: To fully evaluate the suitability of ADA for long-term robotics applications, this section aims at investigating the source performance PS as the original labelled domain is still of relevance. In addition to improving target performance, ADA can acts as a regulariser to improve generalisation and test performance in the source domain as represented in Table VI. This gain in performance is only possible as long as both domains have significant structural similarities and the dominant variations are shared by both domains. With increasing discrepancy between the domains, it can however reduce performance on the source domain as it might diminish information that helps it to generalise in source but not in the target domain, as can be seen with respect to the day-night adaptation in Table VI."}, {"heading": "V. SEGMENTATION TASK", "text": "Following the optimisation for our surrogate task, we now apply the distilled insights for optimising ADA to the task of free space segmentation as possible input data for motion planning systems. We use the fully convolutional FCN-VGG16 [12] architecture, which is split - similar to the classification tests - into encoder and classifier/discriminator. We set the split layer towards the middle of the architecture after the 4th maxpool operation (see [12] for the exact architecture) with fixed capacity of the discriminator architecture and apply the confusion loss.\nBoth source and target datasets include 1000 training and 100 test images based on a midday to early evening adaptation scenario such that the domain shift is intuitively smaller than in the full day to night transfer from section IV-C. The segmentation labels are generated for free-space/obstacles following the approach of Barnes et al [28].\nThe domain adapted segmentation network performs significantly better than the basic supervised approach and is able to bridge the gap towards performance with available labels in the target domain.\nAs the segmentation output of the approach has a limited receptive field for each pixel location we additionally evaluate a patch-wise discriminator in line with research on imageto-image translation with conditional Generative Adversarial Networks (cGAN) [32]. This approach enables to keep the size of the receptive field fixed between the supervised and adversarial task. While Isola et al [32] have found the patch\ndiscriminator to work better for their task based on cGANs, it resulted in reduced accuracy for our application on ADA."}, {"heading": "VI. LIMITATIONS OF UNSUPERVISED ADVERSARIAL DOMAIN ADAPTATION", "text": "While we have shown domain adaptation to be beneficial in many scenarios, it must be marked that the current approach finds its limitations when the differences between source and target domains are too severe. As exemplified by the day to night transfer scenario, the approach still leads to some improvement but with stronger variation in the underlying domains, the adversarial encoder loss might even lead to reduced performance if weighted improperly against the supervised loss. If the adversarial loss dominates in such situations the encoder features might lose more information relevant for the supervised task.\nFinally, to overcome the limitation of significant domain shifts, semi-supervised approaches can be employed to incorporate further structure and align the conditional distributions over feature representations given the labels comparable to [26]."}, {"heading": "VII. DISCUSSION", "text": "Adversarial training frameworks such as ADA tend to be notoriously hard to train. However, a limited number hyperparameters has strong influence for a given problem and can be adapted to stabilise and optimise the training process.\nWhile the detailed performance depends on architecture and task, we found the principal factors for optimising performance to be:\n\u2022 Using relevant initialisation including supervised warmup helps to guide the training process. \u2022 Applying the confusion loss for the encoder enables better balancing and stabilising. \u2022 The optimum position for the split layer is mid network. Particularly the application in earlier layers can significantly reduce the benefits.\nAdditional to the main evaluation above, we tested the influence of other advancements from the related GAN framework. It was found that neither mini-batch discriminator [33] nor discriminator noise [33] brought significant advances. This is justified as the former addresses generator mode collapse which in the context of ADA will be less of a problem as the supervised loss guides towards more versatile solutions. The latter seems to have negligible influence in comparison to the GAN framework as the discriminator\u2019s task is of higher complexity and with reasonable loss settings, the risk of the discriminator saturating is minimal.\nAs a side note, we find it helpful in this adversarial training framework to apply gradient clipping to prevent abrupt instabilities when one of the adversarial models finds a strong exploit."}, {"heading": "VIII. CONCLUSION AND FUTURE WORK", "text": "In this paper, we cast the common problem of appearance change problem in outdoor robotics as a domain adaptation problem and employ the recent adversarial paradigm to enhance the performance of existing architectures in unlabelled domains. While instabilities of adversarial training can inhibit the extension to large scale problems, our extensive tests on a surrogate task with moderate complexity expose the most significant factors of influence. With this evaluation we hope to pave the way for further application on real world tasks, in particular in the context of autonomous mobility where strong structural similarities can exist between different domains, e.g. based on spatial overlay of driven routes.\nBeyond dealing with appearance change we see many potential applications of ADA in robotics where sensor modalities may change, or even transferring models from a simulated virtual environment to improve their performance in the real world.\nFinally, the application of ADA represents a strong opportunity to address curriculum learning to overcome strong domain shifts as were shown in this paper to produce significant challenges for direct adaptation. As many appearance changes happen continuously over time, one can imagine adapting models more gradually for changing daytime, season, or weather."}], "references": [{"title": "It\u2019s not easy seeing green: Lighting-resistant stereo visual teach & repeat using color-constant images", "author": ["Michael Paton", "Kirk MacTavish", "Chris J Ostafew", "Timothy D Barfoot"], "venue": "In Robotics and Automation (ICRA),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Experience-based Navigation for Long-term Localisation", "author": ["Winston Churchill", "Paul Newman"], "venue": "The International Journal of Robotics Research (IJRR),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Illumination invariant imaging: Applications in robust vision-based localisation, mapping and classification for autonomous vehicles", "author": ["Will Maddern", "Alex Stewart", "Colin McManus", "Ben Upcroft", "Winston Churchill", "Paul Newman"], "venue": "In Proceedings of the Visual Place Recognition in Changing Environments Workshop, IEEE International Conference on Robotics and Automation", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "3d laser scan classification using web data and domain adaptation", "author": ["Kevin Lai", "Dieter Fox"], "venue": "In Robotics: Science and Systems,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Towards adapting deep visuomotor representations from simulated to real environments", "author": ["Eric Tzeng", "Coline Devin", "Judy Hoffman", "Chelsea Finn", "Xingchao Peng", "Sergey Levine", "Kate Saenko", "Trevor Darrell"], "venue": "arXiv preprint arXiv:1511.07111,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Domain adaptation for statistical classifiers", "author": ["Hal Daume III", "Daniel Marcu"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "Direct importance estimation with model selection and its application to covariate shift adaptation", "author": ["Masashi Sugiyama", "Shinichi Nakajima", "Hisashi Kashima", "Paul V Buenau", "Motoaki Kawanabe"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2008}, {"title": "Generative adversarial nets", "author": ["Ian Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Learning from simulated and unsupervised images through adversarial training", "author": ["Ashish Shrivastava", "Tomas Pfister", "Oncel Tuzel", "Josh Susskind", "Wenda Wang", "Russ Webb"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2016}, {"title": "Domain separation networks", "author": ["Konstantinos Bousmalis", "George Trigeorgis", "Nathan Silberman", "Dilip Krishnan", "Dumitru Erhan"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "Imagenet classification with deep convolutional neural networks. In Advances in neural information processing", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Fully convolutional networks for semantic segmentation", "author": ["Jonathan Long", "Evan Shelhamer", "Trevor Darrell"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "NIPS 2016 tutorial", "author": ["Ian J. Goodfellow"], "venue": "Generative adversarial networks. CoRR,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2017}, {"title": "Towards principled methods for training generative adversarial networks", "author": ["Martin Arjovsky", "L\u00e9on Bottou"], "venue": "In NIPS 2016 Workshop on Adversarial Training. In review for ICLR,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2017}, {"title": "Study of the photodetector characteristics of a camera for color constancy in natural scenes", "author": ["Sivalogeswaran Ratnasingam", "Steve Collins"], "venue": "JOSA A,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Dealing with shadows: Capturing intrinsic scene appearance for imagebased outdoor localisation", "author": ["Peter Corke", "Rohan Paul", "Winston Churchill", "Paul Newman"], "venue": "In Intelligent Robots and Systems (IROS),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Seqslam: Visual route-based navigation for sunny summer days and stormy winter nights", "author": ["Michael J Milford", "Gordon F Wyeth"], "venue": "In Robotics and Automation (ICRA),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "Appearance change prediction for long-term navigation across seasons", "author": ["Peer Neubert", "Niko Sunderhauf", "Peter Protzel"], "venue": "In Mobile Robots (ECMR),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Analysis of representations for domain adaptation", "author": ["Shai Ben-David", "John Blitzer", "Koby Crammer", "Fernando Pereira"], "venue": "Advances in neural information processing systems,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2007}, {"title": "Unsupervised pixel-level domain adaptation  with generative adversarial networks", "author": ["Konstantinos Bousmalis", "Nathan Silberman", "David Dohan", "Dumitru Erhan", "Dilip Krishnan"], "venue": "arXiv preprint arXiv:1612.05424,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "SSPP- DAN: Deep Domain Adaptation Network for Face Recognition with Single Sample Per Person. page 5, feb 2017", "author": ["Sungeun Hong", "Woobin Im", "Jongbin Ryu", "Hyun S. Yang"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2017}, {"title": "Deep transfer learning with joint adaptation", "author": ["Mingsheng Long", "Jianmin Wang", "Michael I. Jordan"], "venue": "networks. CoRR,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2016}, {"title": "Correlation alignment for unsupervised domain adaptation", "author": ["Baochen Sun", "Jiashi Feng", "Kate Saenko"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1939}, {"title": "Domain-Adversarial Training of Neural Networks", "author": ["Yaroslav Ganin", "Evgeniya Ustinova", "Hana Ajakan", "Pascal Germain", "Hugo Larochelle", "Fran\u00e7ois Laviolette", "Mario Marchand", "Victor Lempitsky", "Urun Dogan", "Marius Kloft", "Francesco Orabona", "Tatiana Tommasi"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2016}, {"title": "Simultaneous deep transfer across domains and tasks", "author": ["Eric Tzeng", "Judy Hoffman", "Trevor Darrell", "Kate Saenko"], "venue": "In Proceedings of the IEEE International Conference on Computer Vision,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2015}, {"title": "Unsupervised domain adaptation in brain lesion segmentation with adversarial networks", "author": ["Konstantinos Kamnitsas", "Christian F. Baumgartner", "Christian Ledig", "Virginia F.J. Newcombe", "Joanna P. Simpson", "Andrew D. Kane", "David K. Menon", "Aditya Nori", "Antonio Criminisi", "Daniel Rueckert", "Ben Glocker"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2016}, {"title": "Find your own way: Weakly-supervised segmentation of path proposals for urban autonomy", "author": ["Dan Barnes", "William P. Maddern", "Ingmar Posner"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2016}, {"title": "Year, 1000km: The Oxford RobotCar Dataset", "author": ["Will Maddern", "Geoff Pascoe", "Chris Linegar", "Paul Newman"], "venue": "The International Journal of Robotics Research (IJRR),", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2016}, {"title": "What makes imagenet good for transfer learning", "author": ["Mi-Young Huh", "Pulkit Agrawal", "Alexei A. Efros"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2016}, {"title": "Imagenet large scale visual recognition challenge", "author": ["Olga Russakovsky", "Jia Deng", "Hao Su", "Jonathan Krause", "Sanjeev Satheesh", "Sean Ma", "Zhiheng Huang", "Andrej Karpathy", "Aditya Khosla", "Michael Bernstein"], "venue": "International Journal of Computer Vision,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2015}, {"title": "Image-toimage translation with conditional adversarial networks", "author": ["Phillip Isola", "Jun-Yan Zhu", "Tinghui Zhou", "Alexei A Efros"], "venue": "arXiv preprint arXiv:1611.07004,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2016}, {"title": "Improved techniques for training gans", "author": ["Tim Salimans", "Ian Goodfellow", "Wojciech Zaremba", "Vicki Cheung", "Alec Radford", "Xi Chen"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "Dealing with these changes becomes relevant in all modules of the robotic perception system including localisation [1], mapping [2] and obstacle detection [3].", "startOffset": 115, "endOffset": 118}, {"referenceID": 1, "context": "Dealing with these changes becomes relevant in all modules of the robotic perception system including localisation [1], mapping [2] and obstacle detection [3].", "startOffset": 128, "endOffset": 131}, {"referenceID": 2, "context": "Dealing with these changes becomes relevant in all modules of the robotic perception system including localisation [1], mapping [2] and obstacle detection [3].", "startOffset": 155, "endOffset": 158}, {"referenceID": 3, "context": "Methods for domain adaptation have already found success in robotics for transfer from 3D models to laser data [4] or from simulation to real images collected", "startOffset": 111, "endOffset": 114}, {"referenceID": 4, "context": "indoors [5].", "startOffset": 8, "endOffset": 11}, {"referenceID": 5, "context": "adaptation problem have focused on modelling the density of the source and target distributions separately [6] or with imposed prior structure [7].", "startOffset": 107, "endOffset": 110}, {"referenceID": 6, "context": "adaptation problem have focused on modelling the density of the source and target distributions separately [6] or with imposed prior structure [7].", "startOffset": 143, "endOffset": 146}, {"referenceID": 7, "context": "Recently, generative adversarial networks (GAN) were proposed [8] as a framework to model any arbitrary distribution where a generating network is optimised to produce data indistinguishable from real data as considered by a discriminating network.", "startOffset": 62, "endOffset": 65}, {"referenceID": 8, "context": "domain adaption [9], [10].", "startOffset": 16, "endOffset": 19}, {"referenceID": 9, "context": "domain adaption [9], [10].", "startOffset": 21, "endOffset": 25}, {"referenceID": 10, "context": "To demonstrate the widespread applicability of ADA with this schema, we modify two popular network architectures, AlexNet [11] and FCN-VGG16 [12] which are known to work well for the tasks of classification and pixel-wise image segmentation respectively.", "startOffset": 122, "endOffset": 126}, {"referenceID": 11, "context": "To demonstrate the widespread applicability of ADA with this schema, we modify two popular network architectures, AlexNet [11] and FCN-VGG16 [12] which are known to work well for the tasks of classification and pixel-wise image segmentation respectively.", "startOffset": 141, "endOffset": 145}, {"referenceID": 7, "context": "Due to the documented evidence of training instability of adversarial training procedures [8], [13], [14], we first use", "startOffset": 90, "endOffset": 93}, {"referenceID": 12, "context": "Due to the documented evidence of training instability of adversarial training procedures [8], [13], [14], we first use", "startOffset": 95, "endOffset": 99}, {"referenceID": 13, "context": "Due to the documented evidence of training instability of adversarial training procedures [8], [13], [14], we first use", "startOffset": 101, "endOffset": 105}, {"referenceID": 11, "context": "VGG16 [12] baseline.", "startOffset": 6, "endOffset": 10}, {"referenceID": 3, "context": "Lai and Fox [4] presented an exemplar based approach to align spin-image features from web based 3D models to dense laser scan.", "startOffset": 12, "endOffset": 15}, {"referenceID": 14, "context": "For visual appearance, the colour-constant transform [15] is commonly applied directly on the image to achieve lighting invariance for localisation [16], visual teach and repeat [1] and segmentation [3].", "startOffset": 53, "endOffset": 57}, {"referenceID": 15, "context": "For visual appearance, the colour-constant transform [15] is commonly applied directly on the image to achieve lighting invariance for localisation [16], visual teach and repeat [1] and segmentation [3].", "startOffset": 148, "endOffset": 152}, {"referenceID": 0, "context": "For visual appearance, the colour-constant transform [15] is commonly applied directly on the image to achieve lighting invariance for localisation [16], visual teach and repeat [1] and segmentation [3].", "startOffset": 178, "endOffset": 181}, {"referenceID": 2, "context": "For visual appearance, the colour-constant transform [15] is commonly applied directly on the image to achieve lighting invariance for localisation [16], visual teach and repeat [1] and segmentation [3].", "startOffset": 199, "endOffset": 202}, {"referenceID": 16, "context": "Other works in localisation take a multiview approach by either exploiting temporal structure [17] or by accumulating multiple experiences covering different appearances [2] to avoid the issue of modelling appearance change.", "startOffset": 94, "endOffset": 98}, {"referenceID": 1, "context": "Other works in localisation take a multiview approach by either exploiting temporal structure [17] or by accumulating multiple experiences covering different appearances [2] to avoid the issue of modelling appearance change.", "startOffset": 170, "endOffset": 173}, {"referenceID": 17, "context": "[18] is the closest to our approach where they learn synthesise stored images into the current season.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19] derived theoretical upper bounds on a classifiers performance.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "While unsupervised domain adaptation is an open research problem in theoretical and practical terms [10], [20], recent successes have shown the", "startOffset": 100, "endOffset": 104}, {"referenceID": 19, "context": "While unsupervised domain adaptation is an open research problem in theoretical and practical terms [10], [20], recent successes have shown the", "startOffset": 106, "endOffset": 110}, {"referenceID": 8, "context": "capability to train expressive, flexible models and address high dimensional input distributions and therefore made first steps in enabling real world applicability [9], [21].", "startOffset": 165, "endOffset": 168}, {"referenceID": 20, "context": "capability to train expressive, flexible models and address high dimensional input distributions and therefore made first steps in enabling real world applicability [9], [21].", "startOffset": 170, "endOffset": 174}, {"referenceID": 21, "context": "Long et al [22] focus on minimising the Maximum Mean Discrepancy for the feature distributions of multiple layers of the network architecture.", "startOffset": 11, "endOffset": 15}, {"referenceID": 22, "context": "[23] align second order statistics of layer activations for source and target domain.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "Recently, the field has been extended with adversarial methods to domain adaptation [24], [25] which have resulted in strong performance benefits [10].", "startOffset": 84, "endOffset": 88}, {"referenceID": 9, "context": "Recently, the field has been extended with adversarial methods to domain adaptation [24], [25] which have resulted in strong performance benefits [10].", "startOffset": 146, "endOffset": 150}, {"referenceID": 23, "context": "While the loss formulation for the discriminator stays consistent between most approaches, different objectives have been applied for the encoder, including the minimax formulation resulting from a \u2018gradient reversal layer\u2019 [24], and the confusion loss [26] that was found to address problems with vanishing gradients based on discriminator saturation in Generative Adversarial Networks (GAN) [8].", "startOffset": 224, "endOffset": 228}, {"referenceID": 24, "context": "While the loss formulation for the discriminator stays consistent between most approaches, different objectives have been applied for the encoder, including the minimax formulation resulting from a \u2018gradient reversal layer\u2019 [24], and the confusion loss [26] that was found to address problems with vanishing gradients based on discriminator saturation in Generative Adversarial Networks (GAN) [8].", "startOffset": 253, "endOffset": 257}, {"referenceID": 7, "context": "While the loss formulation for the discriminator stays consistent between most approaches, different objectives have been applied for the encoder, including the minimax formulation resulting from a \u2018gradient reversal layer\u2019 [24], and the confusion loss [26] that was found to address problems with vanishing gradients based on discriminator saturation in Generative Adversarial Networks (GAN) [8].", "startOffset": 393, "endOffset": 396}, {"referenceID": 25, "context": "These methods have recently been employed to address tasks in medical image segmentation [27], gaze estimation [9] and transfer for reinforcement learning [5].", "startOffset": 89, "endOffset": 93}, {"referenceID": 8, "context": "These methods have recently been employed to address tasks in medical image segmentation [27], gaze estimation [9] and transfer for reinforcement learning [5].", "startOffset": 111, "endOffset": 114}, {"referenceID": 4, "context": "These methods have recently been employed to address tasks in medical image segmentation [27], gaze estimation [9] and transfer for reinforcement learning [5].", "startOffset": 155, "endOffset": 158}, {"referenceID": 7, "context": "An alternative formulation is to train the encoder to maximise the discriminator\u2019s confusion [8], [26] (see Equation 6).", "startOffset": 93, "endOffset": 96}, {"referenceID": 24, "context": "An alternative formulation is to train the encoder to maximise the discriminator\u2019s confusion [8], [26] (see Equation 6).", "startOffset": 98, "endOffset": 102}, {"referenceID": 26, "context": "We focus for our main evaluation on the surrogate task of classification and extend the evaluation subsequently to image segmentation with focus on path proposals for autonomous driving [28].", "startOffset": 186, "endOffset": 190}, {"referenceID": 27, "context": "RobotCar Dataset that includes over 1000 km of driving data including images, LIDAR, GPS and INS data [29].", "startOffset": 102, "endOffset": 106}, {"referenceID": 10, "context": "The network architecture builds on AlexNet [11] and", "startOffset": 43, "endOffset": 47}, {"referenceID": 11, "context": "while we adapt the split between encoder and classifier / discriminator, the overall pipeline from image to location label is kept the same for all experiments, making this approach easy to apply to other common architectures such as FCNVGG [12], which underlies the segmentation experiments.", "startOffset": 241, "endOffset": 245}, {"referenceID": 28, "context": "1) Stabilising: Pretraining and Supervised Warm-up: Initialising network architectures via pretraining of convolutional layers on large and diverse datasets is generally known to speed up the learning process as well as leading to better generalisation [30].", "startOffset": 253, "endOffset": 257}, {"referenceID": 29, "context": "We evaluate pretrained convolutional layers for AlexNet (based on ImageNet classification task [31]) as well as a supervised warmup phase of 15 epochs which, based on a small test run, has been found to work well in a large range of evaluation settings.", "startOffset": 95, "endOffset": 99}, {"referenceID": 13, "context": "2) Balancing: Adversarial Loss: While the discriminator loss stays fixed across most recent work on ADA based on Equation 4, the choice of the encoder loss varies and has been shown to have significant influence on convergence properties and stability of training in Generative Adversarial Networks [14], which have strong similarities with ADA.", "startOffset": 299, "endOffset": 303}, {"referenceID": 23, "context": "two main generator objectives to consider are the minimax formulation (negated discriminator loss) which is equal to the gradient reversal layer [24] and the confusion loss [26], which has found to prevent vanishing gradients with saturated discriminator but displays higher variance in the gradients [14].", "startOffset": 145, "endOffset": 149}, {"referenceID": 24, "context": "two main generator objectives to consider are the minimax formulation (negated discriminator loss) which is equal to the gradient reversal layer [24] and the confusion loss [26], which has found to prevent vanishing gradients with saturated discriminator but displays higher variance in the gradients [14].", "startOffset": 173, "endOffset": 177}, {"referenceID": 13, "context": "two main generator objectives to consider are the minimax formulation (negated discriminator loss) which is equal to the gradient reversal layer [24] and the confusion loss [26], which has found to prevent vanishing gradients with saturated discriminator but displays higher variance in the gradients [14].", "startOffset": 301, "endOffset": 305}, {"referenceID": 23, "context": "The original minimax-loss formulation was successfully employed in a number of recent works [24], [10], however, we have found the tuning process more complex and obtained significantly stronger results based on the confusion loss.", "startOffset": 92, "endOffset": 96}, {"referenceID": 9, "context": "The original minimax-loss formulation was successfully employed in a number of recent works [24], [10], however, we have found the tuning process more complex and obtained significantly stronger results based on the confusion loss.", "startOffset": 98, "endOffset": 102}, {"referenceID": 10, "context": "1) Choice of Split Layer: The following evaluation focuses in particular on AlexNet [11], which we adapt by providing the feature output of a particular layer additionally to a discriminator module.", "startOffset": 84, "endOffset": 88}, {"referenceID": 29, "context": "Note, all models are initialised with pretrained convolutional layers pretrained on ImageNet [31].", "startOffset": 93, "endOffset": 97}, {"referenceID": 11, "context": "We use the fully convolutional FCN-VGG16 [12] architecture, which is split - similar to the classification tests - into encoder and classifier/discriminator.", "startOffset": 41, "endOffset": 45}, {"referenceID": 11, "context": "We set the split layer towards the middle of the architecture after the 4th maxpool operation (see [12] for the exact architecture) with fixed capacity of the discriminator architecture and apply the confusion loss.", "startOffset": 99, "endOffset": 103}, {"referenceID": 26, "context": "The segmentation labels are generated for free-space/obstacles following the approach of Barnes et al [28].", "startOffset": 102, "endOffset": 106}, {"referenceID": 30, "context": "As the segmentation output of the approach has a limited receptive field for each pixel location we additionally evaluate a patch-wise discriminator in line with research on imageto-image translation with conditional Generative Adversarial Networks (cGAN) [32].", "startOffset": 256, "endOffset": 260}, {"referenceID": 30, "context": "While Isola et al [32] have found the patch discriminator to work better for their task based on cGANs, it resulted in reduced accuracy for our application on ADA.", "startOffset": 18, "endOffset": 22}, {"referenceID": 24, "context": "over feature representations given the labels comparable to [26].", "startOffset": 60, "endOffset": 64}, {"referenceID": 31, "context": "It was found that neither mini-batch discriminator [33] nor discriminator noise [33] brought significant advances.", "startOffset": 51, "endOffset": 55}, {"referenceID": 31, "context": "It was found that neither mini-batch discriminator [33] nor discriminator noise [33] brought significant advances.", "startOffset": 80, "endOffset": 84}], "year": 2017, "abstractText": "Appearance changes due to weather and seasonal conditions represent a strong impediment to the robust implementation of machine learning systems in outdoor robotics. While the model is optimised for the training domain it will deliver degraded performance in application domains that underlie distributional shifts caused by these changes. Traditionally, this problem has been addressed via the collection of labelled data in multiple domains or by imposing priors on the type of shift between both domains. We frame the problem in the context of unsupervised domain adaptation and apply an adversarial framework to train a deep neural network with the additional objective to align features across domains. This approach benefits from adding unlabelled data and is generally applicable to many state-of-the-art architectures. Moreover, as adversarial training is notoriously hard to stabilise, we first perform an extensive ablation study on a surrogate classification task underlying the same appearance change and then apply the distilled insights to the problem of free-space segmentation for motion planning.", "creator": "LaTeX with hyperref package"}}}