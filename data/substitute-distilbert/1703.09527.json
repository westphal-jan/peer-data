{"id": "1703.09527", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Mar-2017", "title": "Is This a Joke? Detecting Humor in Spanish Tweets", "abstract": "while humor has been freely studied from a psychological, ideological and educational standpoint, its study from a computational perspective is an area yet generally be explored in computational linguistics. rumors exist some previous works, but a characterization of humor that allows its automatic recognition and generation is far from being specified. in this work we build a crowdsourced corpus simply labeled tweets, annotated according to key humor value, letting the annotators actually decide which are humorous. a humor classifier for spanish tweets is assembled based on empirical learning, reaching a precision of 91 % and a recall approaching 36 %.", "histories": [["v1", "Tue, 28 Mar 2017 12:08:46 GMT  (101kb,D)", "http://arxiv.org/abs/1703.09527v1", "Preprint version, without referral"]], "COMMENTS": "Preprint version, without referral", "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["santiago castro", "mat\\'ias cubero", "diego garat", "guillermo moncecchi"], "accepted": false, "id": "1703.09527"}, "pdf": {"name": "1703.09527.pdf", "metadata": {"source": "CRF", "title": "Is This a Joke? Detecting Humor in Spanish Tweets", "authors": ["Santiago Castro", "Mat\u00edas Cubero", "Diego Garat", "Guillermo Moncecchi"], "emails": ["gmonce}@fing.edu.uy"], "sections": [{"heading": null, "text": "Keywords: Humor \u00b7 Computational Humor \u00b7 Humor Recognition \u00b7 Machine Learning \u00b7 Natural Language Processing"}, {"heading": "1 Introduction", "text": "The human being as a species is characterized by laughter. Humor, which is a potential cause of laughter, is an essential component of human communication. Not only does it allow people to feel comfortable, but also produces a cozier environment. While humor has been studied from a psychological, cognitive [8] and even linguistic [16] standpoint, its study from a computational viewpoint is still an area to be explored within Computational Linguistics. There exist some previous works [14]; however, a humor characterization that allows its automatic recognition and generation is far from being specified, particularly for the Spanish language.\nIdentifying humor in a text can be seen as an intermediate step for the resolution of more complex tasks. It would be interesting to generate jokes, or humor in general, based on the knowledge of which attributes enrich texts in a better way. Another appealing use case is to exploit the outcome of a humor detector to decide automatically if a text span can be taken seriously or not. On the other hand, by way of a more direct use, humor identification can be used to find jokes on Twitter, to search for potentially funny tweets about certain trending topic or to search for humorous answers to comments on the social network. ar X\niv :1\n70 3.\n09 52\n7v 1\n[ cs\n.C L\n] 2\n8 M\nar 2\n01 7\nWe address herein the problem of detecting humor in Spanish tweets. It should be noted that this is different from trying to recognize humor in arbitrary texts, due to tweets\u2019 length. Here it could be assumed that tweets are either humorous or not, but not both, because they are brief (up to 140 characters). This is not always the case in others texts, as jokes could only exist in some parts but not on the whole text. Another advantage considered is that there are plenty of tweets available to analyze.\nSince there is no clear definition of what humor is, how can we detect something that is in principle vaguely stated? We explore different ideas, and we finally decide to let people define it themselves by voting tweets from a web page and an Android app, in which they can label a tweet as humorous or not humorous. Once we have defined which tweets are humorous, we tackle the problem of humor detection using a supervised learning approach. In other words, we infer a function that identifies humor from labeled data. We use several techniques such as Support Vector Machine, Nearest Neighbors, Decision Trees and Naive Bayes. In order to build a set of features, we first study the state of the art of the Computational Humor area, focused on recognition and in Spanish.\nIn Sect. 2 we present the humor detection problem and its state of the art, including features studied in previous works. In Subsect. 3.1 we show the corpus built for this purpose and in Subsect. 3.2 we describe the classifier used. Afterwards, we present an experimental evaluation in Sect. 4 and finally the conclusions in Sect. 5."}, {"heading": "2 Computational Humor", "text": "Computational Humor is a recent field of study about recognizing and generating humor through automatic processing. The task of language understanding is rather hard, and so are tasks related to humor. Furthermore, humor entails the usage of figurative language, which obviously makes language handling harder.\nHumor by itself is not a clearly determined concept. According to Real Academia Espa\u00f1ola1, humor is defined as a way of presenting reality, highlighting the comic or ridiculous side. As for comedy, it is a kind of drama meant to cause laughter. However, what causes laughter? There are several theories which try to answer this question, and consequently attempt to find what humor is. A report on the state of the art about Humor and Computational Humor [14] enumerates some of them. The main ideas of these theories are described hereinafter. Readers will notice that these ideas are similar, in spite of putting the focus on different attributes.\nGruner [6] develops a theory which claims that humor is related to superiority feelings, asserting that there is always a winner in every joke. Freud and Strachey [4] and Minsky [13] state that humor is about relieving repressed feelings. In this case, laughter relieves the stress caused by taboo topics, such as death, marriage or sex. The Theory of the Incongruity Resolution [21] claims that two objects\n1 http://dle.rae.es/\nare presented under the same concept, with details applying to both and with similarities, but as narration progresses it turns out that only one is possible. Furthermore, we have The Semantic Script Theory of Humor and The General Theory of Verbal Humor [1], [20]. They state that humor is about two scripts which come into conflict with each other, where there are two opposed subjects contrasted, such as big vs small, death vs life, normal vs abnormal, among others.\nLet us introduce an example2:\n\u2014 Nada es imposible. \u2014 A ver, tocate la espalda con la rodilla, mente positivista.\n\u2014 Nothing is impossible. \u2014 Seriously? Touch your back with your knee, you positivist mind.\nFollowing the Superiority Theory, the reader is the winner when he laughs at the positive person, feeling superior as the latter lose the dispute. According to the Relief Theory, we laugh with the purpose of releasing tension, which in this case can be provoked by talking about the limits of life, such as when saying \u201cnothing is impossible\u201d. The Theory of the Incongruity Resolution also applies here due to the fact that there is ambiguity; with \u201cnothing is impossible\u201d the example implies that all your dreams may come true, but the person is answered as if the statement was literal.\n2.1 Humor Detection\nThe concrete goal of this research is to classify tweets written in Spanish as humorous or not humorous. In order to accomplish this, jokes need to be completely expressed within the text, and no further information must be required (apart from contextual information). Since Twitter allows only brief publications \u2014 no more than 140 characters \u2014 we freely assume the text to be a unit: either the whole tweet is humorous, or it is not.\n2.2 State of the Art\nWe did not find any attempt to automatically recognize humor for Spanish. Notwithstanding, Mihalcea and Strapparava [12] and Mulder and Nijholt [14] built humor detectors for English making use of one-liners, i. e., texts of approximately fifteen words. Supervised learning was used to produce an outcome \u2014 humorous or not humorous content \u2014 based on features which might reflect certain properties that humor should satisfy. Furthermore, Reyes, Buscaldi, and Rosso [18] and Reyes et al. [19] have gathered and studied features specific to humor, without having the objective of creating a recognizer.\nA concise compilation of the features presented in these works is shown below: 2 Taken from https://twitter.com/chistetipico/status/430549009812291584. It has been slightly adapted to maintain an appropriate language.\nAdult Slang: According to Mihalcea and Strapparava [12], adult slang is popular in jokes. Let us remember that the Relief Theory states that laughter releases stress caused by taboo subjects, and adult slang could be one. WordNet Domains [23] can be used to search for words tagged with the domain \u201cSexuality\u201d in potentially humorous texts. Alliteration: This is about the repetition of phonemes in a text. It is a generalization of the rhyme. As stated in [12], structural and phonetic properties of jokes are at least as important as their content. Ambiguity: It may be explained by the Incongruity Resolution Theory that ambiguity plays an important role, as it gives more than one interpretation to texts. Sj\u00f6bergh and Araki [22], Basili and Zanzotto [2], and Reyes, Buscaldi, and Rosso [18] mention different ways to measure it, such as counting the number of meanings of the words that appear or counting the number of possible syntax trees. Antonymy: Following the Semantic Script Theory of Humor, we could look for opposed terms in texts, and that is how this feature is supported. The idea is to take into account pairs of antonym words mentioned in texts. Wordnet [3] is useful since it is a lexical database which contains antonyms for English words, among other relations. Keywords: There are certain words that are more used in humorous contexts than in normal situations [22]. An example of these are words related to animal contexts, lawyers, etc. Language model perplexity: In Reyes, Buscaldi, and Rosso [18] a language model is built from narrative texts, and perplexity3 is used as a feature. Humorous texts have a higher perplexity than those which are not humorous. Negativity: There is a certain kind of humor which tends to have negative connotations [9] [19]. It can be about denying, such as when saying \u201cno\u201d, \u201cdon\u2019t\u201d or \u201cnever\u201d, when talking about subjects with negative polarity such as \u201cbad\u201d, \u201cillegal\u201d or \u201cwrong\u201d or when it is related to words referring to stressful subjects, such as \u201calcohol\u201d or \u201clie\u201d. People-centered words: Humorous texts are constantly referring to scenarios related to people, with dialogues and references such as \u201cyou\u201d, \u201cI\u201d, \u201cwoman\u201d and \u201cmy\u201d. This is supported by Mihalcea and Pulman [9] and Mihalcea and Strapparava [11].\nMihalcea and Strapparava [12] used the features Adult Slang, Alliteration and Antonymy, while Sj\u00f6bergh and Araki [22] focused on Alliteration, Ambiguity, Keywords and People-centered words. Both studies collected humorous oneliners from the Internet. Sj\u00f6bergh and Araki [22] employed only the British National Corpus (BNC) as negative samples whereas Mihalcea and Strapparava [12] additionally used proverbs and news headlines from Reuters. In both works 3 Perplexity is a measurement of how well a probability model predicts a sample. Low perplexity indicates the probability model is good at predicting the sample. It is defined as 2\u2212 1 n \u2211n i=1\nlog2 p(xi), where x1, . . . , xn are the sample data and p(xi) is the probability assigned to each one.\nthey tried with Na\u00efve Bayes and Support Vector Machine classifiers, resulting in no significant difference between these techniques. On one hand, Mihalcea and Strapparava [12] achieved their best accuracy with headlines: 96.85%, while they reached 84.82% with proverbs and 79.15% with the BNC. Alliteration proved to be the most accurate feature. On the other hand, Sj\u00f6bergh and Araki [22] achieved an accuracy of 85.40%, with Keywords being the most useful. Table 1 summarizes the main differences and compares both studies.\n3 Proposal\n3.1 Corpus\nOur first goal is to build a corpus with samples of humorous and non-humorous tweets. Based on Mihalcea and Strapparava [12], we choose to use non-humorous sample tweets that fall into the following topics: news, reflections and curious facts. For humorous samples, we extracted tweets from accounts which appeared after having searched for the keyword \u201cchistes\u201d (\u201cjokes\u201d in Spanish). In total, 16,488 tweets were extracted from humorous accounts and 22,875 from nonhumorous. The two groups are composed of 9 Twitter accounts each, with the non-humorous containing 3 of each topic. The amount of tweets in each topic is similar.\nWe tagged all tweets from news, reflections and curious facts as non-humorous, as random sampling showed that there was no humor in them. Conversely, not all tweets that were extracted from a humorous account were in fact humorous. Many of them were used to increase their number of followers, to express their opinion about a fact or to support a cause through retweets.\nA crowdsourced web4 and a mobile5 annotation was carried out in order to tag all tweets from humorous accounts. In order to obtain as many annotations 4 http://clasificahumor.com 5 https://play.google.com/store/apps/details?id=com.clasificahumor.android\nas possible, we wanted to keep it simple. Therefore, we showed random tweets to annotators (avoiding duplicates), providing no instructions, and let them implicitly define what humor is. In addition, the user interface was simple, as shown in Fig. 1. The users could either provide a ranking of humor between one and five, express that the tweet was not humorous or skip it.\nIn total, 33,531 annotations were achieved, after filtering some of them that occurred in a short time lapse in the same session and with the same tag. About half of the labels were non-humorous, while the other half was divided approximately between the five rankings. A histogram of the annotations is shown in Fig. 2. Regarding the agreement among annotators, the Fleiss\u2019 Kappa measurement for tweets with 2 annotations6 is 0.416 and for those with 6 annotations it is 0.325.\nBased on this analysis, we have to decide which tweets are considered humorous. Let us define the tweets considered humorous as positives and the ones considered as non-humorous as negatives. The decision consisted in marking as positives those tweets whose ratio of humorous annotations is greater than or equal to 0.6 and as negatives those lower than or equal to 0.3. The rest are considered as doubtful. The criterion of giving a 0.1 handicap to the positives was thereby performed, as they are obtained from humorous accounts. This may be seen as if the source is giving its opinion too. Additionally, those tweets 6 Note that Kappa assumes a fixed number of annotators. For this reason, we measure it with 2 and 6, in order to give an idea of the agreement having a value with many tweets but few annotators, and other value with few tweets but many annotators.\nwith no annotations fall into the category of doubtful. Figure 3a illustrates the proportions of each category. To sum up, 5,952 tweets are considered positive. The rest of the tweets obtained from humorous accounts are not taken into account, even though the negatives can also be used. The corpus composition is shown in Fig. 3b.\n3.2 Classifier\nFirstly, we split data into 80% for training and 20% for later evaluation. Similarly to the works mentioned in this document, we built a humor classifier but for the Spanish language. Such works used Support Vector Machine (SVM) and a Multinomial version of Na\u00efve Bayes (MNB). However, more machine learning techniques are tried here: Decision Trees (DT), k Nearest Neighbors (kNN) and a Gaussian version of Na\u00efve Bayes (GNB). Tweets are tokenized using Freeling [15]. Also, a higher quantity of features was implemented, which is described below.7\nAdult slang: Here we count the relative number of tokens in the tweets which appeared in a previously built dictionary about adult slang. This dictionary contains 132 words, and it was built using bootstrapping, in a similar manner to Mihalcea and Strapparava [10], with a seed of 21 words. Dictionary-lookup features are computed with this formula (where the multiset intersection is used):\n7 The codebase for the classifier and the corpus built can be found in https://github. com/pln-fing-udelar/pghumor.\n(a) Graph showing the percentage of tweets from humorous accounts in each category.\n(b) Pie displaying the ratio between positives and negatives in the corpus, after the decision was made.\nFig.3\nfeatureV alue(tweet) = |tweet \u2229 dictionary|\u221a |tweet|\nAnimal presence: In this case we compare against a handcrafted dictionary about animals. This dictionary contains 103 names, including typical typographic misspellings and grammatical mistakes.\nAntonyms: Given a tweet, this feature counts the relative number of pairs of antonyms existing in it. WordNet [3] antonymy relationship and Spanish language enrichment provided by the Multilingual Central Repository [5] are used for this. This feature was discarded since after performing Recursive Feature Elimination [7] (RFE) we found out the classification worsened.\nDialog: This feature only establishes if a tweet is a dialog. Exclamations: The relative number of exclamation marks are counted. First and Second person: These two features try to capture verbs conjugated\nin the first and second persons and nouns and adjectives which agree with such conjugations (in Spanish, nouns and adjectives express gender and number at the end of the word).\nHashtags: The amount of hashtags in the tweet is counted. It is suspected that the higher this amount is, the more informal the tweet is. Thus, it is more likely to be humorous.\nKeywords: An intuitively handmade dictionary of 43 common words found in jokes was built for this, and it was used for checking purposes.\nLinks: This feature counts the number of links contained in a tweet. Negation: Here we count the relative quantity of times the word \u201cno\u201d appears\nin the tweet. It was removed after running RFE. Non-Spanish words: The relative number of words containing non-Spanish\nwords is counted. It was discarded after running RFE. Out of vocabulary: The idea behind this is to keep record of the relative\ncount of words not found in dictionaries. These are four features based on the combination of the dictionaries used: Freeling, Freeling-Google 8, Freeling-Wiktionary 9 and Wiktionary.\nQuestions-answers: One interesting attribute for tweets is to count how many questions and answers are present, one after another.\nTopic distance: The idea is to check if a tweet is somewhat near to a joke category in Chistes.com, or whether it is closer to a Wikipedia\u2019s sentence, from Wikicorpus [17]. This is carried out using a Multinomial Na\u00efve Bayes classifier together with the Bag of Words technique.\nUppercase words: The relative amount of words completely in uppercase is counted.\n8 https://www.google.com 9 https://www.wiktionary.org"}, {"heading": "4 Experimental Evaluation", "text": "Provided that our work is the only one using this corpus, and even the only one with the goal of classifying humor in Spanish, we cannot directly compare it with any other work. Hence, we developed two baselines to compare it with, aiming them to be simple ideas which could be crafted to face this task. The first one (BL1) is a Multinomial Na\u00efve Bayes classifier combined with Bag of Words similarly to the Topic Distance feature. The second one (BL2) is a classifier which predicts all tweets with the most likely outcome, non-humorous, having a frequency of almost 83%.\nA comparison using mainly the F1 score is intended. We want to pay attention to the positives (the humorous) but also granting the same degree of importance to false positives and false negatives. Nonetheless, we take advantage of the runs in order to also pay attention to other measurements. The results are shown in Table 2.\nThe best results are obtained with SVM, even in terms of accuracy. Also, kNN shows satisfactory output. These two approaches outperform the baselines, with the former clearly surpassing the latter. Meanwhile, GNB and DT have poor precision, although GNB certainly does a better job among these two and has the best recall. The confusion matrix for SVM is shown in Table 3."}, {"heading": "5 Conclusions", "text": "A crowdsourced corpus has been assembled, which serves the purpose of this work and could be useful for future research. It contains over 30,000 annotations for 16,488 tweets, coming from humorous accounts, and it also counts with 22,875 sourced from non-humorous accounts. Uses of such corpus include analyzing its data, as well as performing tasks similar to the work described herein.\nWe have built a classifier which outperforms the baselines outlined. Support Vector Machine proved to be the best technique. It has a precision of 83.6%, a recall of 68.9%, a F1 score of 75.5% and an accuracy of 92.5%. Nevertheless, it must be highlighted that the corpus built does not depict a great variety of humor. Hence, some features perform well in this work but might not perform so well in another context.\nAs a future work, more complex features could be crafted, such as trying to detect wordplay and puns, ambiguity, perplexity against some language model, inter alia. Other Machine Learning techniques could also be tried. It would be interesting if we take advantage of the star ranking people provided; maybe this can also suggest how funny a joke is. As a harder task, humor generation could be tackled. Finally, it could be studied how the influence of humor varies between different social contexts, depending on gender, age, interest areas, mood, etc."}], "references": [{"title": "Script theory revis(it)ed: Joke similarity and joke representation model", "author": ["S. Attardo", "V. Raskin"], "venue": "Humor: International Journal of Humor Research", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1991}, {"title": "Parsing Engineering and Empirical Robustness", "author": ["R. Basili", "F.M. Zanzotto"], "venue": "Natural Language Engineering 8(3), 97\u2013120", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2002}, {"title": "Jokes and Their Relation to the Unconscious", "author": ["S. Freud", "J. Strachey"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1905}, {"title": "Multilingual Central Repository version 3.0: upgrading a very large lexical knowledge base", "author": ["A. Gonzalez-Agirre", "E. Laparra", "G. Rigau"], "venue": "Proceedings of the 6th Global WordNet Conference (GWC 2012),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "The Game of Humor: A Comprehensive Theory of Why We Laugh", "author": ["C. Gruner"], "venue": "Transaction Publishers", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2000}, {"title": "Gene Selection for Cancer Classification using Support Vector Machines", "author": ["I. Guyon", "J. Weston", "S. Barnhill", "V. Vapnik"], "venue": "Machine Learning 46(1-3), 389\u2013422", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2002}, {"title": "HUMOR, (1988)", "author": ["International Journal of Humor Research"], "venue": "http://www.degruyter. com/view/j/humr", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Characterizing humour: An exploration of features in humorous texts", "author": ["R. Mihalcea", "S. Pulman"], "venue": "Computational Linguistics and Intelligent Text Processing,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2007}, {"title": "Bootstrapping for fun: Web-based construction of large data sets for humor recognition", "author": ["R. Mihalcea", "C. Strapparava"], "venue": "Proceedings of the Workshop on Negotiation, Behaviour and Language (FINEXIN 2005), pp. 84\u201393", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2005}, {"title": "Making Computers Laugh: Investigations in Automatic Humor Recognition", "author": ["R. Mihalcea", "C. Strapparava"], "venue": "Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing. HLT \u201905, pp. 531\u2013538. Association for Computational Linguistics, Vancouver, British Columbia, Canada", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2005}, {"title": "Jokes and the logic of the cognitive unconscious", "author": ["M. Minsky"], "venue": "Springer", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1980}, {"title": "Humour Research: State of Art", "author": ["M.P. Mulder", "A. Nijholt"], "venue": "Technical Report TR-CTIT-02-34, Enschede: Centre for Telematics and Information Technology University of Twente", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2002}, {"title": "FreeLing 3.0: Towards Wider Multilinguality", "author": ["L. Padr\u00f3", "E. Stanilovsky"], "venue": "Proceedings of the Language Resources and Evaluation Conference (LREC", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Semantic Mechanisms of Humor", "author": ["V. Raskin"], "venue": "Springer", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1985}, {"title": "Wikicorpus: A Word-Sense Disambiguated Multilingual Wikipedia Corpus", "author": ["S. Reese", "G. Boleda", "M. Cuadros", "L. Padr\u00f3", "G. Rigau"], "venue": "Proceedings of 7th Language Resources and Evaluation Conference (LREC\u201910), La Valleta, Malta", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}, {"title": "An Analysis of the Impact of Ambiguity on Automatic Humour Recognition", "author": ["A. Reyes", "D. Buscaldi", "P. Rosso"], "venue": "TSD, pp. 162\u2013169", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2009}, {"title": "Caracter\u00edsticas y rasgos afectivos del humor: un estudio de reconocimiento autom\u00e1tico del humor en textos escolares en catal\u00e1n", "author": ["A. Reyes", "P. Rosso", "M.A. Mart\u00ed", "M. Taul\u00e9"], "venue": "Procesamiento del Lenguaje Natural 43, 235\u2013243", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "Toward an Empirical Verification of the General Theory of Verbal Humor", "author": ["W. Ruch", "S. Attardo", "V. Raskin"], "venue": "HUMOR: the International Journal of Humor Research", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1993}, {"title": "Stand-up as Interaction: Performance and Audience in Comedy Venues", "author": ["J. Rutter"], "venue": "Citeseer", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1997}, {"title": "Recognizing Humor Without Recognizing Meaning", "author": ["J. Sj\u00f6bergh", "K. Araki"], "venue": "Masulli, F., Mitra, S., and Pasi, G. (eds.) WILF. Lecture Notes in Computer Science, pp. 469\u2013476. Springer", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2007}, {"title": "WordNet Affect: an Affective Extension of WordNet", "author": ["C. Strapparava", "A. Valitutti"], "venue": "LREC, pp. 1083\u20131086", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2004}], "referenceMentions": [{"referenceID": 6, "context": "While humor has been studied from a psychological, cognitive [8] and even linguistic [16] standpoint, its study from a computational viewpoint is still an area to be explored within Computational Linguistics.", "startOffset": 61, "endOffset": 64}, {"referenceID": 13, "context": "While humor has been studied from a psychological, cognitive [8] and even linguistic [16] standpoint, its study from a computational viewpoint is still an area to be explored within Computational Linguistics.", "startOffset": 85, "endOffset": 89}, {"referenceID": 11, "context": "There exist some previous works [14]; however, a humor characterization that allows its automatic recognition and generation is far from being specified, particularly for the Spanish language.", "startOffset": 32, "endOffset": 36}, {"referenceID": 11, "context": "A report on the state of the art about Humor and Computational Humor [14] enumerates some of them.", "startOffset": 69, "endOffset": 73}, {"referenceID": 4, "context": "Gruner [6] develops a theory which claims that humor is related to superiority feelings, asserting that there is always a winner in every joke.", "startOffset": 7, "endOffset": 10}, {"referenceID": 2, "context": "Freud and Strachey [4] and Minsky [13] state that humor is about relieving repressed feelings.", "startOffset": 19, "endOffset": 22}, {"referenceID": 10, "context": "Freud and Strachey [4] and Minsky [13] state that humor is about relieving repressed feelings.", "startOffset": 34, "endOffset": 38}, {"referenceID": 18, "context": "The Theory of the Incongruity Resolution [21] claims that two objects", "startOffset": 41, "endOffset": 45}, {"referenceID": 0, "context": "Furthermore, we have The Semantic Script Theory of Humor and The General Theory of Verbal Humor [1], [20].", "startOffset": 96, "endOffset": 99}, {"referenceID": 17, "context": "Furthermore, we have The Semantic Script Theory of Humor and The General Theory of Verbal Humor [1], [20].", "startOffset": 101, "endOffset": 105}, {"referenceID": 9, "context": "Notwithstanding, Mihalcea and Strapparava [12] and Mulder and Nijholt [14] built humor detectors for English making use of one-liners, i.", "startOffset": 42, "endOffset": 46}, {"referenceID": 11, "context": "Notwithstanding, Mihalcea and Strapparava [12] and Mulder and Nijholt [14] built humor detectors for English making use of one-liners, i.", "startOffset": 70, "endOffset": 74}, {"referenceID": 15, "context": "Furthermore, Reyes, Buscaldi, and Rosso [18] and Reyes et al.", "startOffset": 40, "endOffset": 44}, {"referenceID": 16, "context": "[19] have gathered and studied features specific to humor, without having the objective of creating a recognizer.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "Adult Slang: According to Mihalcea and Strapparava [12], adult slang is popular in jokes.", "startOffset": 51, "endOffset": 55}, {"referenceID": 20, "context": "WordNet Domains [23] can be used to search for words tagged with the domain \u201cSexuality\u201d in potentially humorous texts.", "startOffset": 16, "endOffset": 20}, {"referenceID": 9, "context": "As stated in [12], structural and phonetic properties of jokes are at least as important as their content.", "startOffset": 13, "endOffset": 17}, {"referenceID": 19, "context": "Sj\u00f6bergh and Araki [22], Basili and Zanzotto [2], and Reyes, Buscaldi, and Rosso [18] mention different ways to measure it, such as counting the number of meanings of the words that appear or counting the number of possible syntax trees.", "startOffset": 19, "endOffset": 23}, {"referenceID": 1, "context": "Sj\u00f6bergh and Araki [22], Basili and Zanzotto [2], and Reyes, Buscaldi, and Rosso [18] mention different ways to measure it, such as counting the number of meanings of the words that appear or counting the number of possible syntax trees.", "startOffset": 45, "endOffset": 48}, {"referenceID": 15, "context": "Sj\u00f6bergh and Araki [22], Basili and Zanzotto [2], and Reyes, Buscaldi, and Rosso [18] mention different ways to measure it, such as counting the number of meanings of the words that appear or counting the number of possible syntax trees.", "startOffset": 81, "endOffset": 85}, {"referenceID": 19, "context": "Keywords: There are certain words that are more used in humorous contexts than in normal situations [22].", "startOffset": 100, "endOffset": 104}, {"referenceID": 15, "context": "Language model perplexity: In Reyes, Buscaldi, and Rosso [18] a language model is built from narrative texts, and perplexity3 is used as a feature.", "startOffset": 57, "endOffset": 61}, {"referenceID": 7, "context": "Negativity: There is a certain kind of humor which tends to have negative connotations [9] [19].", "startOffset": 87, "endOffset": 90}, {"referenceID": 16, "context": "Negativity: There is a certain kind of humor which tends to have negative connotations [9] [19].", "startOffset": 91, "endOffset": 95}, {"referenceID": 7, "context": "This is supported by Mihalcea and Pulman [9] and Mihalcea and Strapparava [11].", "startOffset": 41, "endOffset": 44}, {"referenceID": 9, "context": "Mihalcea and Strapparava [12] used the features Adult Slang, Alliteration and Antonymy, while Sj\u00f6bergh and Araki [22] focused on Alliteration, Ambiguity, Keywords and People-centered words.", "startOffset": 25, "endOffset": 29}, {"referenceID": 19, "context": "Mihalcea and Strapparava [12] used the features Adult Slang, Alliteration and Antonymy, while Sj\u00f6bergh and Araki [22] focused on Alliteration, Ambiguity, Keywords and People-centered words.", "startOffset": 113, "endOffset": 117}, {"referenceID": 19, "context": "Sj\u00f6bergh and Araki [22] employed only the British National Corpus (BNC) as negative samples whereas Mihalcea and Strapparava [12] additionally used proverbs and news headlines from Reuters.", "startOffset": 19, "endOffset": 23}, {"referenceID": 9, "context": "Sj\u00f6bergh and Araki [22] employed only the British National Corpus (BNC) as negative samples whereas Mihalcea and Strapparava [12] additionally used proverbs and news headlines from Reuters.", "startOffset": 125, "endOffset": 129}, {"referenceID": 9, "context": "On one hand, Mihalcea and Strapparava [12] achieved their best accuracy with headlines: 96.", "startOffset": 38, "endOffset": 42}, {"referenceID": 19, "context": "On the other hand, Sj\u00f6bergh and Araki [22] achieved an accuracy of 85.", "startOffset": 38, "endOffset": 42}, {"referenceID": 9, "context": "Mihalcea and Strapparava [12] Sj\u00f6bergh and Araki [22]", "startOffset": 25, "endOffset": 29}, {"referenceID": 19, "context": "Mihalcea and Strapparava [12] Sj\u00f6bergh and Araki [22]", "startOffset": 49, "endOffset": 53}, {"referenceID": 9, "context": "Based on Mihalcea and Strapparava [12], we choose to use non-humorous sample tweets that fall into the following topics: news, reflections and curious facts.", "startOffset": 34, "endOffset": 38}, {"referenceID": 12, "context": "Tweets are tokenized using Freeling [15].", "startOffset": 36, "endOffset": 40}, {"referenceID": 8, "context": "This dictionary contains 132 words, and it was built using bootstrapping, in a similar manner to Mihalcea and Strapparava [10], with a seed of 21 words.", "startOffset": 122, "endOffset": 126}, {"referenceID": 3, "context": "WordNet [3] antonymy relationship and Spanish language enrichment provided by the Multilingual Central Repository [5] are used for this.", "startOffset": 114, "endOffset": 117}, {"referenceID": 5, "context": "This feature was discarded since after performing Recursive Feature Elimination [7] (RFE) we found out the classification worsened.", "startOffset": 80, "endOffset": 83}, {"referenceID": 14, "context": "com, or whether it is closer to a Wikipedia\u2019s sentence, from Wikicorpus [17].", "startOffset": 72, "endOffset": 76}], "year": 2017, "abstractText": "While humor has been historically studied from a psychological, cognitive and linguistic standpoint, its study from a computational perspective is an area yet to be explored in Computational Linguistics. There exist some previous works, but a characterization of humor that allows its automatic recognition and generation is far from being specified. In this work we build a crowdsourced corpus of labeled tweets, annotated according to its humor value, letting the annotators subjectively decide which are humorous. A humor classifier for Spanish tweets is assembled based on supervised learning, reaching a precision of 84% and a recall of 69%.", "creator": "LaTeX with hyperref package"}}}