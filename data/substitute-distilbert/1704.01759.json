{"id": "1704.01759", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Apr-2017", "title": "A Multi-view Context-aware Approach to Android Malware Detection and Malicious Code Localization", "abstract": "subsequent android malware detection approaches use a variety of features such as security sensitive keys, system calls, control - flow structures and information flows in conjunction with machine learning classifiers to achieve accurate detection. each of these feature sets provides a unique semantic perspective ( or view ) of apps'behaviours with inherent strengths overcoming limitations. meaning, some views plead more amenable to detect certain attacks but may not be suitable enough characterise several other properties. most common the existing malware detection approaches use tier one ( still a selected few ) of the aforementioned feature sets which prevent them from running a vast majority of attacks. addressing this condition, we possess mkldroid, a validation framework that systematically integrates multiple views requiring apps for performing comprehensive malware detection requires malicious code localisation. the rationale is that, while removing malware app can disguise intent in some views, disguising in every view while retaining malicious intent will be much harder.", "histories": [["v1", "Thu, 6 Apr 2017 09:44:08 GMT  (4931kb,D)", "https://arxiv.org/abs/1704.01759v1", null], ["v2", "Sat, 8 Apr 2017 13:10:50 GMT  (4931kb,D)", "http://arxiv.org/abs/1704.01759v2", null]], "reviews": [], "SUBJECTS": "cs.CR cs.AI cs.SE", "authors": ["annamalai narayanan", "mahinthan chandramohan", "lihui chen", "yang liu"], "accepted": false, "id": "1704.01759"}, "pdf": {"name": "1704.01759.pdf", "metadata": {"source": "CRF", "title": "A Multi-view Context-aware Approach to Android Malware Detection and Malicious Code Localization", "authors": ["Annamalai Narayanan", "Mahinthan Chandramohan", "Lihui Chen", "Yang Liu"], "emails": [], "sections": [{"heading": null, "text": "MKLDroid uses a graph kernel to capture structural and contextual information from apps\u2019 dependency graphs and identify malice code patterns in each view. Subsequently, it employs Multiple Kernel Learning (MKL) to find a weighted combination of the views which yields the best detection accuracy. Besides multi-view learning, MKLDroid\u2019s unique and salient trait is its ability to locate fine-grained malice code portions in dependency graphs (e.g., methods/classes). Malicious code localization caters several important applications such as supporting human analysts studying malware behaviors, engineering malware signatures, and other counter-measures. Through our large-scale experiments on several datasets (incl. wild apps), we demonstrate that MKLDroid outperforms three state-of-the-art techniques consistently, in terms of accuracy while maintaining comparable efficiency. In our malicious code localization experiments on a dataset of repackaged malware, MKLDroid was able to identify all the malice classes with 94% average recall. Our work opens up two new avenues in malware research: (i) enables the research community to elegantly look at Android malware behaviors in multiple perspectives simultaneously, and (ii) performing precise and scalable malicious code localization.\nKeywords Android Malware Detection, Graph Kernels, Multiple Kernel Learning, Malicious Code Localization"}, {"heading": "1 Introduction", "text": "Over the past few years, proliferation of malware for mobile platforms such as Android has been severe. For instance, Kaspersky reports [1] discovering nearly 4.1 million new malware in 2016 which is a 17% increase over 2015. A major reason for such tremendous volume and growth rate is the production of repackaged malware variants. Typically, these variants are produced through repackaging popular legitimate applications (apps) with similar malicious code. The Android app packaging and distribution model offers painless and straightforward opportunities for attackers to piggyback (i.e., inject) their malice code on benign apps which could then be spread through several third-party markets. Many empirical studies [30, 55\u201357] manifest that an overwhelming majority of Android malware are nothing but repackaged versions\nannamala002@e.ntu.edu.sg, {mahinthan,elhchen,yangliu}@ntu.edu.sg Nanyang Technological University Singapore\nar X\niv :1\n70 4.\n01 75\n9v 2\n[ cs\n.C R\n] 8\nA pr\n2 01\n7\nof benign apps. The sheer volume, growth rate and evolution of repackaged and other types of malware highlight an imperative need for developing effective and scalable automated malware detection techniques [55\u201357].\nTo perform automated detection, recent approaches from both academia and industry increasingly resort to program analysis and machine learning (ML) techniques. Typically, the detection process involves extracting semantic features from suitable representations of programs (e.g., assembly code, call graphs (CGs), etc.) and identifying malicious code/behaviour patterns using ML classifiers [22\u201325, 27, 28, 31, 38, 39]. Notably, higher level semantic representations such as CGs, control- and data-flow graphs mostly stay similar even when the code is considerably altered [23, 24, 27, 28, 31] (we use a common term \u2019Program Representation Graph\u2019 (PRG) to refer to any of the aforementioned graphs). As they are inherently resilient against variants, many works in the past have used these PRGs to perform effective detection. In essence, such works cast malware detection as a graph classification problem and apply existing graph mining and classification techniques [21, 24, 25, 28, 37, 74].\nThe efficacy of such approaches depends primarily on the features that they extract from PRGs. Prominent robust approaches from literature have used a variety of features such as API sequences [24, 25, 27], permissions used [22, 34], information flows observed [45], instruction sequences used [28] and Control Flow Graph (CFG) patterns [18, 23] to learn discriminatory functions that could differentiate malware and benign apps. Understandably, each of these features represent a unique perspective (interchangeably referred as view) of apps, having their own merits and limitations.\n1.1 Challenges in ML based malware detection\nIn general, these ML and PRG based approaches are typically plagued by four challenges that make them unsuitable for large-scale malware detection in-the-wild:\n(C1) Expressiveness. PRGs are known to be rich, complex and expressive data structures that characterize topological relationships among program entities. Representing them as vectors or other formats amenable for applying ML algorithms is a non-trivial task [48]. In many cases, such representations fail to capture all the vital information from PRGs, thus losing their expressiveness, resulting in suboptimal detection rates [20, 28, 37, 74].\n(C2) Scalability. The scale of malware detection problem is such that we have millions of samples already and thousands streaming in every day. Many classic graph mining based approaches (e.g., [48]) are NP hard and have severe scalability issues, making them impractical for malware detection in the wild [30, 75].\n(C3) Integrating multiple views. Each of the aforementioned feature sets (API sequences, information flows, etc.) provide a complementary view of the app, but no one view is completely sufficient to determine whether or not it is malicious. More specifically, some views are more amenable to detect certain attacks while they may not characterize other attacks well. For instance, information flow features are amenable for detecting \u2019privacy leak\u2019 attacks but are incapable of revealing \u2019privilege escalations\u2019. A majority of existing approaches use either one or a selected few of the aforementioned views but not all of them. This prevents them from detecting a substantial majority of attacks.\n(C4) Malicious code localization. In general, almost all the ML based approaches act as holistic black-box solutions as they just predict whether or not a given app (as a whole) is malicious (examples: [18, 22\u201325, 27\u201329, 31, 36\u201338, 40, 45\u201347]). Such approaches are incapable of locating malice code portions (e.g., classes/methods containing such code). In general, precise malicious code localization would not only help to assess the approaches\u2019 trustworthiness but also cater several important applications such as supporting human analysts studying malware behaviors, engineering malware signatures and other countermeasures. Malicious code localization becomes particularly useful in the case of repackaged malware, as a predominant portion of their code remains benign and only a small portion is attack related.\n1.2 Our Approach\nWe take these four challenges into consideration and propose MKLDroid, a unified framework which integrates all the above mentioned five views, namely, API dependencies, permission dependencies, information source and sink dependencies, instruction sequences and CFG patterns to perform effective detection. Furthermore, leveraging on its multi-view analysis, it precisely locates malicious code portions in apps. In particular, MKLDroid is developed with the three following design goals:\n1. Accuracy. Accuracy of MKLDroid, which is a multi-view PRG based approach depends on two factors: (i) how well it retains PRG\u2019s expressiveness and (ii) how effectively it integrates different views. In other words, it depends on how well challenges C1 and C3 are addressed. To address C1, we leverage on our previous work [20] and use the Contextual Weisfeiler-Lehman Kernel (CWLK) that is specifically designed to perform accurate malware detection by capturing both structural and contextual information from PRGs. To address C3, we resort to Multiple Kernel Learning (MKL) [68], a well-known principled approach to integrate multiple feature sets with different modalities. To the best of our knowledge, ours is the first approach that captures contextual and structural information from different dependencies that emanate from PRGs representing different semantic views of an app.\n2. Efficiency. MKLDroid achieves its efficiency through the combined use of a scalable graph kernel (i.e., CWLK) and an efficient MKL approach, namely, Sequential Minimal Optimization (SMO) MKL [69]. This addresses challenge C2.\n3. Locating malice code. Besides effective detection, a salient feature of MKLDroid is its ability to locate malicious code portions in PRGs. We achieve this by meticulously extracting explainable features from each view and combining them in an interpretable manner. To this end, we propose a method for training a MKL Support Vector Machine (SVM) in the dual formulation and subsequently switching to primal formulation for prediction and interpretation. This process allows MKLDroid to assign a maliciousness scores (m-scores, for short) to each node in the PRG which are then aggregated to arrive at m-scores of methods and classes that encompass them. Again, to the best of our knowledge, ours is the first approach that performs such fine-grained malicious code localization without requiring any apriori information on apps\u2019 piggybacking or composition. This, in effect, addresses challenge C4.\nExperiments. MKLDroid is evaluated through large-scale experiments on more than 60,000 apps from benchmark datasets and collected in-the-wild. On benchmark datasets, MKLDroid achieves more than 97% F-measure, which is comparable to state-of-the-art approaches. More importantly, in an experiment closer to the real-world setting where the test-set is historically posterior (nearly by 2 years) to the training set, MKLDroid achieves 71% F-measure outperforming state-of-the-art techniques by 11%. On recent wild apps, it achieves 72% F-measure, outperforming state-of-the-art approaches by 8%. In all these experimental settings, MKLDroid maintained better efficiency than two state-of-the-art techniques. In malicious code localization experiments, our approach, on average, located more than 94% of all malice classes within its top 10 classes with highest m-scores.\nContributions. In this work, we make the following contributions:\n\u2013 We leverage on CWLK, a graph kernel we proposed in our previous work [20] that is specially designed to perform malware detection by capturing both structural and contextual information from PRGs. Using CWLK we extract five different embeddings of an app\u2019s PRGs each representing a unique semantic view of the app. \u2013 We propose MKLDroid, a novel malware detection framework which systematically integrates these views using MKL thereby extracting a semantically richer representation. This helps MKLDroid achieve superior accuracies over approaches which use either one or a selected few of the perspectives. \u2013 We propose a kernel method based novel approach to locate and explain malicious code portions (i.e., methods/classes) in PRGs. To the best of our knowledge, ours is the first approach that performs automatic multi-view malicious code localization. \u2013 We contribute to future research on malicious code localization by releasing MKLDroid\u2019s results. Mscores for all basic blocks, methods and classes from apps in the benchmark datasets, Drebin [22] and Mystique [73] are made available at: [13].\nThe remainder paper is organized as follows: We begin by introducing the background and motivations for our framework\u2019s design in \u00a72 . The proposed MKLDroid framework is presented in \u00a73. The experimental design and implementation details are furnished in \u00a74. Evaluation results and discussions are presented in section \u00a75. Related work, limitations and conclusions are provided in \u00a76, \u00a77 and \u00a78, respectively."}, {"heading": "2 Background and Motivations", "text": "In this section, the background on kernel methods, Android malware detection and motivations for the two main components of the MKLDroid framework, namely, CWLK and MKL are presented.\n2.1 Kernel Methods and Graph Kernels\nKernel methods have been highly successful in solving a specific class of problems where feature vector representations of samples are not readily obtainable. Malware detection using PRGs is one of such problems. For many well-known classifiers, the data samples have to be explicitly represented as feature vectors through a user-specified feature map, \u03c6. In contrast, kernel methods require only a user-specified kernel k, i.e., a similarity function over pairs of samples in their native representations. Kernel methods work by mapping the samples into a feature space, implicitly and finding an appropriate decision boundary in the new feature space. Here, feature map \u03c6(\u00b7) is realized through the kernel function k, which facilitates computing inner products in the feature space using the samples in their native representation, i.e., for a pair of samples xi and xj , k(xi, xj) = \u3008\u03c6(xi), \u03c6(xj)\u3009.\nGraph Kernels. Formally, a graph kernel k : G \u00d7 G \u2192 R is a kernel function defined on a domain of graphs, G. Hence, given a labeled graph dataset Dg = (g1, y1), ..., (gn, yn) and a graph kernel k, a kernel classifier (e.g., Support Vector Machine (SVM)) can be directly used to perform graph classification. Graph kernels usually belong to the family of R convolution kernels. These kernels decompose graphs into substructures such as walks, subgraphs etc. The comparison of two graphs is then based on the similarity between all pairs of such substructures. Several graph kernels have been proposed based on this idea [59, 60, 62, 63].\nExplicit vs. Implicit Feature mapping. Existing graph kernels can be classified into approaches that use explicit feature mapping (\u03c6) and those that directly compute a kernel function (i.e., \u03c6 is not necessarily known and may be of infinite dimension) [58]. Examples of former category include Weisfeiler-Lehman Kernel (WLK) [62], Neighborhood Hashing Graph Kernel (NHGK) [63] and CWLK, and that of latter category are Random Walk (RW) [59] and Shortest Path (SP) [60] kernels. Kernels that support explicit feature mapping have two advantages that make them particularly suitable for the malware detection problem: (1) Scalability. If explicit representations are manageable, these approaches usually outperform other kernels regarding runtime on large datasets, since the number of vector representations scales linear with the dataset size [58, 62]. (2) Explainability. These kernels support extracting substructures of graphs as features and building a vocabulary of such features. This facilitates building explicit feature vector representation of individual graphs [62, 64]. This aspect makes this category of kernels amenable for performing explainable malware detection [58].\nCWLK, being a kernel with explicit feature maps achieves both high scalability and building explainable representations.\n2.2 Motivations for CWLK\nThis subsection explains with an example why considering structural information alone from PRGs is insufficient to determine the maliciousness of a sample and how supplementing it with contextual information helps to increase detection accuracy. To motivate this necessity, we use a primitive variant of malware from the Geinimi family which steals users\u2019 private information and contrast its behavior with that of a well-known benign app, Yahoo Weather.\nGeinimi\u2019s execution. The app is launched through a background event such as receiving a SMS or call. Once launched, it reads the user\u2019s personal information such as geographic location and leaks the same\nto a remote server. The (simplified) malicious code portion pertaining to the location information leak is shown in Fig. 1 (a). The method leak location reads the geographic location through getLatitude and getLongitude APIs. Subsequently, it calls leak info to url method to leak the location details (through DataOutputStream.writeBytes) to a specific server. The API dependency graph (ADG)1 corresponding to the code snippet is shown in Fig. 1 (b). The nodes in ADG are labeled with the sensitive APIs that they invoke and the edges denote the control-flow dependencies.\nYahoo Weather\u2019s execution. On the other hand, Yahoo Weather could be launched only by user\u2019s interaction with the device (e.g., by clicking the app\u2019s icon on the dash board). The app then reads the user\u2019s location and sends the same to its weather server to retrieve location-specific weather predictions. Hence, ADG portions of Yahoo Weather is same as that of Geinimi.\nContextual information. From the explanations above, it is clear that both the apps leak the same information in the same fashion. However, what makes Geinimi malicious is the fact that its leak happens without the user\u2019s consent. In other words, unlike Yahoo Weather, Geinimi leaks private information through an event which is not triggered by user\u2019s interaction. We refer to this as a leak happening in userunaware context. On the same lines, we refer to Yahoo Weather\u2019s leak as happening in user-aware context. As explained in [25] and [24], one could determine whether a PRG node is reachable under user-aware or user-unaware context by examining its entry point nodes. Following this procedure we identify and add the context as an attribute to every ADG node to obtain the contextual ADG (CAGD). CADGs of Geinimi Yahoo Weather are shown in Fig. 1 (c) and (d), respectively.\nRequirements for effective detection. From the aforementioned example the two key requirements that make a malware detection process effective can be identified: (R1) Capturing structural information. Since malicious behaviors often span across multiple nodes in PRGs, just considering individual nodes (and their attributes) in isolation is not enough. For instance, in the case of Geinimi, the privacy leak attack spans across three ADG nodes. Therefore, capturing the structural (i.e., neighborhood) information from PRGs is of paramount importance. (R2) Capturing contextual information. Considering just the structural information without the context is not enough to determine whether a sensitive behavior is triggered with or without users\u2019 knowledge. For instance, if structural information alone is considered, the features of both Geinimi and Yahoo Weather apps become identical, thus making the latter a false positive. Hence, it is important for the detection process to capture the contextual information as well to make it more precise.\nMany existing graph kernels could address the first requirement well. However, the second requirement which is more domain-specific makes the problem particularly challenging. To the best of our knowledge, the only graph kernel that addresses our two-fold requirement is CWLK [20]. Hence, we intend to use CWLK in this work for capturing both the aforementioned types of information from PRGs.\n2.3 Motivations for MKL\nTo illustrate the necessity to integrate multiple views, we consider a complex and more recent variant from the Geinimi family. Besides leaking the geographic location, this variant leaks other sensitive information such as device identifiers and contacts. The (simplified) malicious code portion that is responsible for these activities is shown in Fig. 2 (a). Firstly, the malware reads the geographic location and sends this information to a remote server, which acts as the command-and-control (C&C) server, thereafter (lines 8- 9). Subsequently, the malware reads the users\u2019 contacts (i.e., names and phone numbers) from the content provider database and sends it to the C&C server along with the IMEI number that serves as a unique identifier for the victimized device (lines 16-39). This malicious privacy leak comprises of a variety of actions that involves using APIs and URIs that are related to permissions, information sources and sinks (viz. openConnection, getDeviceId, Contacts.CONTENT URI, Phone.CONTENT URI) and other security-sensitive APIs (viz. getLatitude, getLongitude, getContentResolver, query).\nThrough statically analysing the app, the graphs in Fig. 2 (b) to (g) are constructed. While the formal definitions and detailed explanation of these graphs are provided later in \u00a73.2, brief explanations are provided here to motivate capturing multiple views of an app through them.\nThe Inter-procedural CFG (ICFG) corresponding to the aforementioned code is shown in Fig. 2 (b). The basic blocks (i.e., is a sequence of instructions in a method with only one entry point and one exit point which represents the largest piece of the program that is always executed altogether) of methods form the nodes of the ICFG and the edges denote the control flow across these nodes. The node headers indicate the method name and the basic block number. The node content specifies the line numbers of code\n1The detailed procedure for constructing the ADG is provided later in \u00a73.2.\ninstructions belonging to the basic block. Subsequently, the context under which each ICFG node is reached is determined and added as a node attribute to obtain the Contextual ICFG (CICFG). In this particular case, all ICFG nodes are reached in the user-unaware context. In sum, CICFG represents the control flow structure of the code in a precise and granular manner along with the contextual information.\nAbstraction to arrive at multiple views. Having, constructed CICFG of an app, one way to detect malicious behavior is to abstract the functionalities performed by its nodes and subsequently, detect the contextual subgraph patterns that correspond to such behaviors. We precisely follow this approach and propose five different abstractions of CICFG, each of which represent a semantic view of the app. They are, CADG (mentioned previously in \u00a72.2), Contextual Permission Dependency Graph (CPDG), Contextual Source & Sink Dependency Graph (CSSDG), CICFGins: CICFG nodes labeled with the Dalvik instructions that they access and CICFGsigns: CICFG nodes labeled with structured control flow signatures. These graphs for the Geinimi example are depicted in Fig. 2 (c) to (g).\nThe CADG in Fig. 2 (c), is obtained by considering only the CICFG nodes that access security-sensitive Android APIs. All other nodes are removed and paths that exists between these nodes in the CICFG conditionally become edges in CADG. The CADG nodes are labeled with the sensitive APIs that they access. Similarly, we take into consideration the permissions, information sources/sinks and Dalvik instructions accessed in every CICFG node to produce CPDG, CSSDG and CICFGins respectively. Lastly, CICFGsigns is obtained by labeling every CICFG node with a textual signature that represents basic block\u2019s control flow structure. A control-flow analysis encoding grammar proposed by Cesare and Xiang in [17] is used to infer these textual signatures.\nComplementary nature of the views. With all these graphs constructed, it could be seen from Fig.2 (c) that considering only the API dependencies, we could capture the behavior corresponding to leaking location information and IMEI number. However, behavior corresponding to leaking the contacts could not be detected. Similarly, considering only the permission dependencies (see Fig.2 (d)), we could capture the behaviour corresponding to leaking the contacts but not the one corresponding to location information. Considering the dependencies among information sources and sinks, captures both the aforementioned leaks but fails to capture leaking IMEI (see Fig.2 (e)). Also, CSSDG may not capture common malicious behaviours such as gaining root access or installing additional apps as they do not involve sources or sinks [45]. CICFGins characterizes apps through the structural dependency among Dalvik instructions. For instance, the privacy leaks in the example is characterized in a sequence involving nodes with move and invoke instructions. CICFGsigns characterizes apps based on the control-flow structure of the code. This helps to model unusual control flow jumps, heavy usage of junk/unwanted instructions and complex loops which are predominant in malware [17, 23].\nIn summary, each of these graphs represent different perspectives of a given app, capturing information at different levels of granularity with different modalities. While, each of these perspectives are capable of capturing certain characteristics of malware, they fail to capture certain other important characteristics due to their inherent limitations. We hypothesize that a much comprehensive and accurate malware detection model could be constructed by appropriately combining information from all these perspectives. Driven by this motivation, we construct a unified malware detection framework that is able to systematically integrate all the aforementioned views in the hope that, while a malware can disguise itself in some views, disguising itself in every view while maintaining malice intent will prove to be more strenuous."}, {"heading": "3 Methodology", "text": "The methodology of MKLDroid framework designed to perform multi-views, context-aware malware detection and malicious code localization is presented in this section. We begin by describing the framework overview and subsequently, explain each component of the framework in separate subsections.\n3.1 MKLDroid \u2013 Framework Overview\nAs with any ML based framework, MKLDroid has a separate model building (training) phase and evaluation (testing) phase. In the training phase, a set of known malware and benign apps are used to build the detection model. In the testing phase, the model is evaluated for its capability to automatically detect previously unseen malware. The overview of MKLDroid framework is presented in Fig. 3. The framework has four components as described below.\n1. Static Analysis. To begin with, we perform static analysis on a given app and construct its CICFG. Subsequently, we construct the five above mentioned PRGs, namely, CADG, CPDG, CSSDG, CICFGins and CICFGsigns each of which represent a unique perspective of the app. This procedure is explained in detail in \u00a73.2.\n2. Feature Extraction, Selection and Representation. Our framework considers contextual subgraphs from these five PRGs as semantic features to perform malware detection. Hence, after these PRGs are constructed, those subgraphs which represent security-sensitive events that happen in an app along with their context(s) are extracted as using CWLK [20]. CWLK yields separate feature vector representations for each PRG. In some cases when the dimensionality of these vectors are large, we use feature selection to reduce them. The detailed feature extraction, selection and representation procedure is explained in \u00a73.3.\n3. Multiple Kernel Learning. After representing each of the PRGs as vectors, we need to appropriately combine them to build a single ML classifier that thoroughly leverages the strengths of individual views and remains robust to their weaknesses. In other words, the views have to be combined in a way that they complement each other and enhance the prediction accuracy. MKL [68], provides a principled way to facilitate learning from this multi-view, multi-granular and multi-modal data. Therefore, we use SMO-MKL [69], a well-known MKL algorithm, to combine representations from all these PRGs and train an SVM to perform malware detection. The detailed procedure is explained in \u00a73.4. Subsequent to this training MKLDroid is ready to perform malware detection at scale.\n4. Malicious Code Localization. During evaluation, if MKLDroid predicts a sample to be malware, it further locates and reports the nodes in the CICFG (i.e., basic blocks) that perform malice operations and end up contributing significantly to the final prediction. That is, each CICFG node is assigned an m-score that quantifies the statistical significance of malice operation(s) it is involved in. The m-scores of basic blocks are aggregated to arrive at the same of their encompassing methods and classes. In most cases, nodes with high m-scores reveal the app\u2019s characteristics related to its malice behaviors. The detailed procedure is presented in \u00a73.5.\nNow, each components of MKLDroid is explained in detail in the four following subsections.\n3.2 Static Analysis\nAs a first step towards constructing the five above mentioned PRGs for a given app, we perform static control-flow analysis and construct its ICFG. Formally, an ICFG is defined as follows:\nDefinition 1 (ICFG). ICFG = (Ni, Ei) for an app a is a directed graph in which each node bb \u2208 Ni denotes a basic block of a method m in a, and each edge e(bb1, bb2) \u2208 Ei denotes either an intra-procedural control-flow dependence from bb1 to bb2 or a calling relationship from bb1 to bb2 and Ei \u2286 Ni \u00d7Ni.\nCompared to other well-known PRGs such as CG, ICFG is a more fine-grained representation of the control flow sequence inside an app. Hence working on abstractions of ICFGs enable us to capture the finer details of apps, which are helpful in distinguishing malicious and benign behaviors with greater precision. Hence, we choose to abstract apps\u2019 behaviors from their ICFGs.\nCICFG construction. Once an app\u2019s ICFG is constructed, we proceed towards identifying contexts under which every ICFG node is reached to build its CICFG. Several works such as DroidSIFT [24], AppContext [25] and Elish et al. [26] have proposed techniques to identify whether a PRG node is reached under the user-aware or -unaware context by analyzing their entry-points (i.e., nodes that do not have any incoming edge). We follow the approach mentioned in DroidSIFT [24]. Formally a CICFG, is defined as follows:\nDefinition 2 (CICFG). CICFG = (Ni, Ei, \u03be) of an app a is a directed graph in which each node bb \u2208 Ni denotes a basic block of a method m in a, and each edge e(bb1, bb2) \u2208 Ei denotes either an intraprocedural control-flow or a calling relationship from bb1 to bb2. \u03be is a set of contexts through which every node bb \u2208 Ni could be reached.\nOnce the CICFG of an app is constructed, we abstract it with various Android platform specific analysis to construct the five different PRGs that MKLDroid leverages on. For each of the PRGs, the procedure to construct them and their formal definitions are provided along with relevant explanations below.\nCADG construction. Intuitively, CADG of an app is obtained from its CICFG by considering only the nodes that access security-sensitive APIs2. All other nodes are removed and paths that exists between such nodes in the CICFG become edges in CADG, if they satisfy certain conditions as described in the definition below. If multiple APIs are invoked in a single CICFG node, it is labeled with the sorted list of unique APIs being invoked. CADG\u2019s formal definition is as follows:\nDefinition 3 (CADG). CADG can be represented as a 4-tuple, CADG = (NA, EA, \u03bbA, \u03be), where NA is a finite set of nodes and n \u2208 NA is a basic block that accesses at least one security-sensitive API. EA \u2286 NA \u00d7 NA is a set of directed edges where an edge from e(n1, n2) \u2208 E exists, iff there exists a path p(n1, n2) between these two nodes in the CICFG and method(n1) = method(n2), where method(n) denotes the method that encompasses basic block n3. \u03bbA is the set of labels representing the security-sensitive APIs and `A : NA \u2192 \u03bbA is a labeling function which assigns a label to each node. \u03be is a set of contexts through which every node in the CADG could be reached and C \u2192 \u03be is a function which assigns the context to each node.\nCPDG. Similarly, CPDG of an app is obtained from its CICFG by considering only the nodes whose functionality pertains to using Android permission(s). APIs and URIs observed in nodes are used to determine their permissions pertinence4. All other nodes are removed and paths that exists between such nodes in the CICFG conditionally become edges in CPDG. If multiple permissions are used in a single CICFG node, then the same strategy followed in CADG is used to label corresponding CPDG nodes.\nDefinition 4 (CPDG). Formally, CPDG = (NP , EP , \u03bbP , \u03be), and node n \u2208 NP is a basic block whose functionality pertains to using permissions. EP \u2286 NP \u00d7 NP is a set of directed edges where an edge from e(n1, n2) \u2208 EP exists, iff there exists a path p(n1, n2) between these two nodes in the CICFG and method(n1) = method(n2). \u03bbP is the set of labels representing the concerned permission(s) and \u03be is a set of contexts through which every node in the CPDG could be reached.\nCSSDG. CSSDG of an app is obtained from its CICFG by considering only the nodes whose functionality pertains5 to using information sources (e.g., contacts) and sinks (e.g., network). All other nodes are removed and paths that exists between such nodes in the CICFG conditionally become edges in CSSDG.\nDefinition 5 (CSSDG). Formally, CSSDG = (NS , ES , \u03bbS , \u03be), and node n \u2208 NS is a basic block whose functionality pertains to information sources or sinks. ES \u2286 NS \u00d7 NS is a set of directed edges where an edge from e(n1, n2) \u2208 ES exists, iff there exists a path p(n1, n2) between these two nodes in the CICFG and method(n1) = method(n2). \u03bbS is the set of labels representing the concerned source(s) or sink(s) and \u03be is a set of contexts through which every node could be reached.\nCICFGins. Recently, studies such as Adagio [28] demonstrated that structural information from PRGs labeled with Dalvik instruction categories (e.g., move, add, iget, etc.) could capture security-sensitive behaviors and thus help detecting malware effectively. Inspired by them, we extend this approach by supplementing the instruction-level structural information with contextual information. To this end, we build CICFGins as described below.\nDefinition 6 (CICFGins) Formally, CICFGins = (Ni, Ei, \u03bbI , \u03be), where Ni, Ei and \u03be are the nodes, edges and node contexts in the CICFG, respectively. The function `i : Ni \u2192 \u03bbI labels every node n \u2208 Ni with the categories of Dalvik instructions6 that it accesses.\nCICFGsigns. Similar to Adagio, Allix et. al. [23] proposed an approach which leverages on control-flow structural information. They represent the structure of basic blocks in every method as textual signatures\n2Two existing works, PScout [15] and SUSI [16] list commonly known security-sensitive Android APIs. We use these two lists to identify sensitive APIs.\n3This follows from the observation that in most malware the malice code portion is closely-knit i.e., spanning only to a few methods. We also attempted two other variants of CADG. We reduce the path in CICFG to edges in CADG (i) only if the calling and called nodes belong to the same package and (ii) only if the calling and called nodes belong to the same class. Both these variants contained much larger number of edges and also failed to capture the attacks as effectively as the CADG defined above (experimentally verified).\n4PScout [15] provides a mapping from Android APIs and URIs to permissions required to access them. Furthermore, we infer the usage of intents, reflection and native code through relevant APIs and consider them as using special permissions. We use these mappings to build CPDGs.\n5To identify information sources and sinks accessed in CICFG nodes, we leverage on SUSI [16] and MUDFLOW [45]. Together, these works map Android APIs and URIs to 15 source and 18 sink categories.\n6To determine the categories of Dalvik instructions to be used as CICFGins node labels, we refer to Adagio [28]. The authors manually analyzed and categorized all the instructions into 15 distinct categories (such as move, invoke, etc.).\nfollowing a method devised by Pouik et al. [10]7. This signature is an abstraction of code\u2019s structure, but discards low-level details such as variable/register names and numbers. This property is particularly desirable for malware detection as variants from same family may share the same abstract CFG while having different bytecode. Also, this helps to model unusual control flow structure such as jumps, heavy usage of junk/unwanted instructions and complex loops which are tell-tale signs of malware [8, 18, 23, 28]. Overall, using an abstract signature representation of CFG basic blocks could allow taming common obfuscations used by malware. Inspired by Allix et. al\u2019s approach, we extend it by supplementing the CFG signature-level structural information with contextual information. To this end, we build CICFGsigns as described below.\nDefinition 7 (CICFGsigns) Formally, CICFGsigns = (Ni, Ei, \u03bbs, \u03be), where Ni, Ei and \u03be are the nodes, edges and contexts in the CICFG, respectively. The function `s : N \u2192 \u03bbs labels every node n \u2208 Ni with the control-flow signatures arrived at using Cesare and Xiang\u2019s grammar [17].\n3.3 Feature Extraction, Selection and Representation\nOnce the five PRGs are constructed as described above, we proceed to extract and select contextual subgraph features from each of them using CWLK and represent them as vectors.\nFeature Extraction using CWLK. CWLK, a graph kernel developed in our previous work [20] is specifically designed to cater effective malware detection by capturing both structural and contextual information from PRGs. This directly addresses the requirements R1 and R2 stated in 2.2. Since CWLK could be used with any type of PRG, we explain its working in general irrespective of the PRG type. It is used in the same manner to represent all our PRGs as vectors.\nThe main idea behind CWLK is to condense the structural and contextual information contained in a PRG neighborhood into a single label value. CWLK computes the similarities between a given pair of PRGs G = (N,E, \u03bb, \u03be) and G\u2032 = (N \u2032, E\u2032, \u03bb, \u03be) based on the 1-dimensional WL test of graph isomorphism [62]. The algorithm works by iteratively augmenting the node labels by the sorted set of labels of neighboring nodes along with their context(s). This label-enrichment process is referred as contextual relabeling and new labels are referred as contextual neighborhood labels. Thus, in each iteration i of the algorithm, for each node n \u2208 N , we get a new contextual neighborhood label, \u03b3i(n) that encompass the ith degree neighborhood around n and along with n\u2019s context. This characterizes that the neighborhood, \u03b3i(n) could be reached under the context, \u03be(n). For graph G, this contextual relabeling process yields a Contextual WL (CWL) graph at height i, denoted as Gi = (N,E, \u03b3). Thus for any given graph G, we could obtain a sequence of CWL graphs as defined below.\nDefinition 8 (CWL sequence). Define the CWL graph at height i of the graph G = (N,E, \u03bb, \u03be) as the graph Gi = (N,E, \u03b3i). The sequence of graphs\nG0,G1, ...,Gh = (N,E, \u03b30), (N,E, \u03b31), ..., (N,E, \u03b3h) (1)\nis called the CWL sequence up to height h of G, where G0 = G (i.e., \u03b30 = \u03bb) is the original graph and G1 = r(G0) is the graph resulting from the first relabeling, and so on.\nContextual Relabeling Algorithm. Since the contextual relabeling algorithm is the key step in computing CWLK value between a given pair of PRGs, we explain the same in detail through algorithm 3 in Appendix 9.1.\nOnce the CWL sequences for a pair of PRGs are computed, the CWLK kernel over them is defined as follows:\nDefinition 9 (CWLK). Given a valid kernel k(., .) and the CWL sequence of graph of a pair of PRGs G and G\u2032, the contextual WL graph kernel with h iterations is defined as\nk (h) CWL(G,G \u2032) = k(G0,G\u20320) + ...+ k(Gh,G\u2032h) (2)\nwhere h is the number of CWL iterations and G0,G1, ...,Gh and G\u20320,G\u20321, ...,G\u2032h are the CWL sequences of G and G\u2032, respectively.\nExample of CWLK\u2019s working. Having presented the formulations for CWLK, we now illustrate how it helps to detect malicious subgraphs regions from PRGs with an example. Lets consider the Geinimi and Yahoo Weather examples mentioned in \u00a72.2. Applying CWLK on the CADGs of Geinimi and Yahoo Weather examples (see Fig. 1 (c) and (d)), for the node getLatitude, for heights h = 0, 1, we get the neighborhood labels as shown in Fig. 4 (a)-(d).\n7Pouik et al. [10] leveraged on a grammar proposed by Cesare and Xiang [17] to represent CFG textual signatures in their work on establishing similarity between Android apps.\nIn both cases, the node getLatitude has only one degree-1 neighbor, writeBytes and this fact is reflected in the neighborhood label. Clearly, CWLK captures the structural information around the node getLatitude, incrementally in every iteration of h. In fact, neighborhood label for h = 1 captures that a sensitive node, writeBytes lies in the neighborhood of getLatitude, which highlights a possible privacy leak (see Fig. 4 (c) and (d)). However, looking at only the structural information, one cannot distinguish the Geinimi\u2019s malicious and Yahoo Weather\u2019s benign information leak.\nAs it is evident from the figure, besides capturing the composition of the neighborhood, CWLK also captures whether the neighborhood is reached in user-aware or unaware context. Clearly, the contextual neighborhood labels of Geinimi reveal that the sensitive operations are performed in the user-unaware context, unlike Yahoo Weather.\nHence, it is evident that the CWLK\u2019s contextual relabeling provides a means to appropriately distinguish malicious PRG neighborhoods from the benign ones, establishing its suitability for malware detection.\nCWLK time complexity and validity. The runtime complexity of CWLK with h iterations on a graph with n nodes and e edges is O(he) which is same as that of WLK. Meaning, capturing contextual information does not reduce the efficiency. For more information on derivation of CWLK\u2019s time complexity and proof of positive semi-definiteness, we refer the reader to the original work [20].\nExplicit feature vector representation. Give a dataset of K PRGs, CWLK uses Bag-of-Features (BoF) model to yield their feature vector representations (i.e., graph embeddings) and subsequently kernel matrix could be computed. This process involves the following steps:\n\u2013 A vocabulary \u03a3\u2217 of all the contextual neighborhood labels of nodes across K graphs is obtained. Thus each graph is represented as |\u03a3\u2217| dimensional vector. \u2013 Subsequently, K \u00d7K kernel matrix can be computed from the dot product of these vectors.\nFeature selection. With the kernel matrix thus obtained, an MKL classifier could be trained to detect malware. However, we note that the vocabularies of contextual subgraph features, \u03a3\u2217, for CICFGins and CICFGsigns\n8 are extremely large (more than 500,000 features emerge from these views in all our experiments. See \u00a75 for more details). This leads to building very high dimensional embeddings which adversely affects both the accuracy and efficiency. Hence, to mitigate this, we perform feature selection over the CICFGins and CICFGsigns embeddings using the chi-squared feature selection algorithm [71] and then compute their respective kernel matrices. The number of features to be selected from these PRGs is empirically determined to be 5,000. This helps to retain only the informative subgraph features, thereby preventing overfitting and improving efficiency.\n3.4 Multiple Kernel Learning\nOnce the feature vectors of all the apps in the training-set are built for all five views, we train an MKL classifier. This procedure is explained below with relevant notations.\nNotations. Denote the features of an app x corresponding to each of views as following vectors: CADG: \u2212\u2192x a = [x1a, x2a, ...]T , CPDG:\n\u2212\u2192x p = [x1p, x2p, ...]T , CSSDG: \u2212\u2192x ss = [x1ss, x2ss, ...]T , CICFGins:\u2212\u2192x in = [x1in, x2in, ...]T , Signature:\n\u2212\u2192x si = [x1si, x2si, ...]T where xiv denotes individual features emerging from view v and the set of all the views is denoted as V = {a, p, ss, in, si}. The label corresponding to an app x(i)\n8The reason why such an issue rises only in the case of CICFGins and CICFGsigns is understandable. That is, in the case of CADG, CPDG and CSSDG, the number of unique node labels is limited by the APIs, permissions, information source and sink categories available. Consequently, limited contextual neighborhood labels to emerge from the relabeling process and thereby limiting the size of the vocabulary. However, in the case of CICFGins and CICFGsigns, the number of unique node labels (i.e., the number of unique instruction sequence and CFG signatures, respectively) across the whole dataset is extremely large, leading to mammoth vocabulary \u03a3\u2217.\nis denoted as y(i) \u2208 {\u22121,+1}, where \u22121 indicates benign and +1 indicates malicious apps. Let the total number of apps in the training set be K. The kernel value between a pair of apps x(i) and x(j) corresponding to each view is computed as follows:\nkv(x (i),x(j)) = \u3008\u2212\u2192x (i)v , \u2212\u2192x (j)v \u3009 (3)\nwhere \u2212\u2192x (i)v denotes the vector representation of x(i) in view v and \u3008\u00b7, \u00b7\u3009 denotes dot product over a pair of vectors. Meaning, the similarity measured in view v is nothing but the normalized linear kernel. Following this procedure, the kernel matrix across all the apps in the training set for each view is arrived. For the sake of simplicity, we refer to the kernel built from CADG view as API kernel. Similarly, the four remaining kernels are referred as Permission, Src-sink, Instruction and Signature kernels.\nKernel methods. Given a kernel matrix over the training samples, the goal of classical kernel-based learning with SVMs is to learn the vector, \u03b1, describing each sample x\u2019s contribution to the hyperplane that separates the points of the two classes (aka decision boundary) with a maximal margin [72] and can be found with the following optimization problem:\nmin \u03b1\n( 1\n2 K\u2211 i=1 K\u2211 j=1 \u03b1(i)\u03b1(j)y(i)y(j)k ( x(i),x(j) ) \u2212 K\u2211 i=1 \u03b1(i) )\n(4)\nsubject to constraints,\nK\u2211 i=1 \u03b1(i)y(i) = 0\n0 \u2264 \u03b1(i) \u2264 C\n(5)\nEq. (5) constrains the \u03b1\u2019s to be non-negative and less than some constant C. C allows for soft-margins, meaning that some of the examples may fall between the margins. This helps to prevent over-fitting the training data and allows for better generalization.\nGiven \u03b1 found in eq. (4), we have the following decision function:\nf(x) = sign ( K\u2211 i=1 \u03b1(i)y(i)k(x(i),x) ) (6)\nwhere the function sign returns +1 if the summation term is positive, and \u22121 otherwise. If there exist vectorial representations \u2212\u2192x (i) for each sample x(i) in the training set, then a vector \u2212\u2192w (called weight vector) could be deduced such that,\n\u2212\u2192w = K\u2211 i=1 \u03b1(i)y(i)\u2212\u2192x (i) (7)\nand eq. (6) could be written equivalently as,\nf(x) = sign ( \u3008\u2212\u2192w ,\u2212\u2192x \u3009 ) = sign ( |x|\u2211 f=1 wfxf )\n(8)\nIt is noted that, in eq. (8), individual component of the weight vector wf denotes the weight (or relative importance) of feature f and xf denotes the frequency of occurrence of f in x. Alternatively, f(x) could be formulated as an optimization problem over w and solved as follows:\nmin\u2212\u2192w ||\u2212\u2192w ||2 + K\u2211 i=1 max(0, 1\u2212 y(i)f(\u2212\u2192x (i))) (9)\nMKL. With MKL, we are interested in finding \u03b2, in addition to the standard \u03b1 of SVMs, such that\nkcomb(x (i),x(j)) = \u2211 v\u2208V \u03b2vkv(x (i),x(j)) (10)\nis a linear combination of all the kernels v \u2208 V with \u03b2v \u2265 0, where each kernel, kv, uses a distinct set of features emanating from different views of apps [68]. The general outline of the algorithm is to first combine the kernels with \u03b2v = 1/|V |, find \u03b1, and then iteratively keep optimizing for \u03b2 and \u03b1 until convergence. \u03b2v is also referred as the weight of kernel v, which quantifies the relative importance of view v \u2208 V .\nSMO-MKL. To solve for kernel weights (\u03b2), and support vectors (\u03b1), simultaneously, we use the SMO based MKL algorithm proposed in [69]. For details on SMO optimization and subsequent computations of \u03b1 and \u03b2, we refer the reader to the original work by Vishwanathan et. al. [69].\nThis method of MKL using the SMO algorithm is reported to be very efficient. Solving for \u03b2 and \u03b1 with as many as 50,000 samples and 300,000 kernels has been shown to take just over 30 minutes on many applications from different domains such as Computer Vision and Bioinformatics [69]. In the MKL context, eq. (6) used to predict the label of a given sample is realized as follows:\nf(x) = sign ( K\u2211 i=1 \u03b1(i)y(i)kcomb(x (i),x) ) (11)\nFinding the kernel weights and support vectors across all views culminates the training process, yielding an MKL-SVM ready to perform multi-view malware detection.\n3.5 Malicious code localization\nOnce the MKL-SVM is trained, we use it to predict the labels of test-set apps. Subsequent to predicting an app x to be malicious, MKLDroid performs the following:\n\u2013 Awards an m-score to every node in x\u2019s CICFG. This helps to locate basic blocks that perform malice operations. We choose to locate malice nodes from CICFG as all the five PRGs used in MKLDroid are its abstractions and hence all contextual subgraph features emerging from individual views could be traced back to CICFG, only. \u2013 The m-scores of all the methods and classes in x are deduced by aggregating the m-scores of their constituent basic blocks. This helps to locate larger portions of malice codes capable enough to explain x\u2019s attacks.\nOur procedure to award m-scores requires interpreting the predictions of MKL-SVM. Before delving into the details of m-score computation algorithm, we introduce some preliminaries required for this interpretation.\nInterpretability: primal vs. dual formulations. The formulation of SVM discussed in eqs. (4) to (6) is known as \u2019dual formulation\u2019 and one mentioned in eq. (8) and (9) is known \u2019primal formulation\u2019. In general, SVMs built in the former formulation are uninterpretable. On the contrary, interpreting the predictions in primal formulation is a well-studied problem as discussed in [22, 28, 66]. These methods enable us to determine the contribution of each feature to the final class prediction as described below.\nBased on eq. (8), for a given sample x, during the prediction of its label, f(x), the contributions of individual features towards placing the sample on the positive (or negative) side of the decision boundary are identified by performing a point-wise multiplication of the weight and sample\u2019s vectors, i.e., the contribution of feature f is deduced as:\ncf = wf \u00b7 xf (12)\nwhere xf denotes the frequency of occurrence of feature f in x and wf is its relative importance. Meaning, high frequency of features with high positive (or negative) weight would result in large positive (or negative) value of cf, pushing sample x significantly towards the positive (or negative) side of the decision boundary.\nIn the malware detection case, features with large positive and negative values of cf characterize strong malice and benign behaviors, respectively. This interpretablity procedure could be adopted to locate contextual subgraph features from our PRGs that contribute significantly to placing a sample on the positive (i.e., malicious) side of the decision boundary.\nInterpretability in MKL scenario. However, adopting this procedure with MKL-SVMs is not straight-forward, as they are learnt strictly in the dual formulation. More specifically, we need the following in the MKL scenario to offer interpretations:\n\u2013 An explicit and composite representation of a sample x with features from all the base kernels. \u2013 A weight vector which quantifies the weights of features from all the base kernels.\nAlgorithm 1: PredictAndInterpret input : xtrain \u2014 Training set samples.\nytrain \u2014 Training set labels. \u03b1 \u2014 Support vectors learnt through linear MKL in the dual formulation. \u03b2 = {\u03b2v1 , \u03b2v2 , ...} \u2014 Weights of base kernels learnt through linear MKL. xtest \u2014 Test-set samples. CICFGtest \u2014 CICFGs of test-set samples.\noutput: y\u0302test \u2014 Predicted labels of the test-set samples. m-scorestest \u2014 Maliciousness scores CICFG nodes of test-set samples.\n1 begin 2 Initialize: y\u0302test = {} and m-scorestest= {}\n// compute composite representations of training-set samples\n3 for i \u2208 [1, |xtrain|] do 4 \u2212\u2192 X(i) = \u2295 v\u2208V \u221a \u03b2v \u00b7 \u2212\u2192x (i)v\n// compute the composite weight vector\n5 \u2212\u2192 W = \u2211|xtrain| i=1 \u03b1 (i)y(i) \u2212\u2192 X(i) = [w1,w2, ...]T 6 for x \u2208 xtest do // compute x\u2019s composite representation 7 \u2212\u2192 X = \u2295 v\u2208V \u221a \u03b2v \u00b7 \u2212\u2192x v = [x1, x2, ...]T\n// Predict x\u2019s label in the primal formulation\n8 f(x) = Sign (\u3008 \u2212\u2192 X, \u2212\u2192 W\u3009) = sign (\u2211|\u2212\u2192X| f=1 w fxf )\n9 y\u0302test[x] = f(x) 10 if f(x) is +1 then 11 m-scorestest[x] = AwardMaliciousnessScore ( \u2212\u2192 X, CICFGtest[x], , \u2212\u2192 W)\n12 return y\u0302test, m-scorestest\nThese two vectors are not obtainable with SMO-MKL. Hence, we obtain the primal version of our MKLSVM and use it for interpreting its predictions and computing the m-scores as explained in algorithm 1.\nAlgorithm: PredictAndInterpret. The algorithm takes as inputs the training samples (xtrain) along with their labels (ytrain), the support vectors (\u03b1) and base kernel weights (\u03b2) learnt in the dual formulation, test samples (xtest) and their CIFCGs (CICFGtest) for which m-scores have be computed.\nFirstly, The predicted labels of test samples (y\u0302test) and their m-scored CICFGs (m-scorestest) are initialized to empty sets (line 2).\nThen the composite representation of every training sample \u2212\u2192 X(i) is computed in lines 3 and 4. Here, \u2295 denotes concatenation operation and \u2212\u2192 X is obtained by concatenating the feature vectors from individual base kernels after scaling them with corresponding base kernel weights. It could be seen that,\n\u3008 \u2212\u2192 X(i), \u2212\u2192 X(j)\u3009 = \u2211 v\u2208V \u03b2v\u3008\u2212\u2192x (i)v , \u2212\u2192x (j)v \u3009 = \u2211 v\u2208V \u03b2vkv(x (i),x(j)) =\nkcomb(x (i),x(j))\nThus, the composite representations encompass features from all views incorporating their relative importances. Subsequently, the composite weight vector, \u2212\u2192 W, required for predictions and interpretations is obtained from representations of support vector instances in line 5. Clearly, in this vector, wf, the weight of the base kernel feature f accounts for both the kernel\u2019s and feature\u2019s relative importance.\nOnce the weight vector of the MKL-SVM is obtained, we predict the label of every test-set sample using the primal formulation9 in line 8. If a sample, x, is predicted to be malware (i.e., f(x) is + 1), we compute the m-scores of all nodes in its CICFG in line 11. The detailed procedure for m-score computation is explained separately in algorithm 2. Once all the test-set samples are subjected to prediction and m-score computation the results are returned in line 12.\nAlgorithm: AwardMaliciousnessScore. Given the CICFG of a sample x that is predicted to be a malware, the goal of this algorithm is to award m-scores to each of its nodes that quantify the severity of their malice operations. To achieve this, the algorithm needs the explicit composite representation of x\n9From eq. (9), it could be noted that, the prediction made in this fashion will be equivalent to one made with a linear\nSVM learnt as an optimization on \u2212\u2192 W as follows:min\u2212\u2192 W || \u2212\u2192 W||2 + \u2211N i=1max(0, 1\u2212 y(i)f( \u2212\u2192 X(i))).\nAlgorithm 2: AwardMaliciousnessScore\ninput : \u2212\u2192 X \u2014 Composite representation of test-set sample x predicted to be malware. CICFG = (Ni, Ei) \u2014 x\u2019s CICFG.\u2212\u2192 W \u2014 Composite weight vector.\noutput: m-scores - maliciousness scores of all the nodes in x\u2019s CICFG. 1 begin 2 Initialize: m-scores = {}\n// Calculate maliciousness scores for every node in x\u2019s CICFG\n3 for n \u2208 Ni do // Compute vector representation of node n 4 \u2212\u2192 Xn = In(f, n) \u00b7 \u2212\u2192 X = [x1n, x 2 n, ...] T\n// In(f, n) =\n{ 1, if feature f emerges from node n\n0, otherwise\n// Arrive at maliciousness score of node n\n5 m-scores[n] = \u3008 \u2212\u2192 W, \u2212\u2192 Xn\u3009 = \u2211|\u2212\u2192Xn| f=1 w fxfn = \u2211|\u2212\u2192Xn| f=1 c f n\n6 return m-scores\n(i.e., \u2212\u2192 X) and the MKL-SVM\u2019s weight vector (i.e., \u2212\u2192 W). These values are passed as its inputs (from line 11 of algorithm 1).\nTo begin with, a dictionary of m-scores of all the nodes are initialized (line 2). Subsequently, we loop through every node n \u2208 Ni in x\u2019s CICFG and compute their m-scores with a 2-step procedure in lines 4 and 5.\nIn line 4, node n\u2019s composite representation, \u2212\u2192 Xn, is obtained from the sample\u2019s vector by unmasking only the contextual subgraph features that emerge from n. The identifier function In helps this unmasking. Clearly, \u2212\u2192 Xn encompasses features from all the five views.\nOnce node n\u2019s representation is arrived at, we could calculate the contributions of individual features emerging from n to the final prediction of \u2212\u2192 X using eq. (12). That is, the contribution of a feature f from node n to the final prediction f(x) is: cfn = w f \u00b7 xfn (where xfn denotes the frequency of occurrence of f in n). Therefore, to calculate the m-score of n, we just need to aggregate cfn as in line 5. Finally, the m-scores of all nodes in x\u2019s CICFG thus computed are returned in line 6.\nOnce the testing and interpretation phase finishes, we would have the predictions for all test-set samples (y\u0302test) and the CICFGs of predicted malware with m-scores of their nodes (m-scorestest). Subsequently, mscores of nodes are aggregated to compute the same for classes and methods encompassing them as follows:\nm-score(m) = \u2211 n\u2208Ni Im(n,m) \u00b7m-score(n) (13)\nm-score(c) = \u2211 n\u2208Ni Ic(n, c) \u00b7m-score(n) (14)\nwhere the indicator function Im and Ic are defined as,\nIm(n,m) =\n{ 1, if basic block n is contained in method m\n0, otherwise\nIc(n, c) =\n{ 1, if basic block n is contained in class c\n0, otherwise\nComputing the m-scores of methods and classes culminates MKLDroid\u2019s automated detection and malicious code localization procedures. Subsequently, analysts could investigate methods and classes with high scores so as to understand malware\u2019s attacks and evasion footprints.\nIt could be easily seen that this process of computing m-scores could be used with base kernels to determine scores from individual views (i.e., API kernel m-scores will depend only on CADG contextual subgraphs and so on.). However, thanks to the multi-view analysis, the MKL based m-scores are more comprehensive and robust in locating malice code than those from individual views (demonstrated later through evaluations in \u00a75.3).\nIn sum, for interpretable multi-view detection, we have trained the MKL-SVM in the dual formulation and predicted the labels of the test-set apps in the primal formulation, which helps to compute the significance of every feature towards the final prediction. To the best of our knowledge, there is no other work that switches MKL-SVMs formulations like ours, as this interpretablity requirement is unique to our goal of malicious code localization.\nOverall, MKLDroid reaps the following advantages through its MKL:\n(i) MKL elegantly combines features from five different views of the app, in a way which allows the learning algorithm to take advantage of all of them simultaneously.\n(ii) MKLDroid\u2019s learning is extendable in the sense that new semantic views (e.g., dynamic analysis or data-flows based views) could be easily added to the model without complicating the final result.\n(iii) MKLDroid\u2019s detection process is parallelizable: constructing representations and computing kernel values for unseen testset apps can all be done in parallel, the implication being that larger datasets can easily be handled. (iv) Interpretability achieved over MKL allows MKLDroid to perform precise multi-view malicious code localization."}, {"heading": "4 Experimental Design and Implementation", "text": "We conducted several large-scale experiments to evaluate MKLDroid\u2019s accuracy, efficiency and malicious code localization capabilities. We also perform comparative analysis with three state-of-the-art Android malware detection solutions. In this section, experimental design aspects such as research questions (RQs) addressed, datasets used, evaluation setup and metrics are presented along with implementation details.\n4.1 Research Questions\nWe intend to address the following RQs through our evaluations: (RQ1 Accuracy) How accurate are MKLDroid\u2019s individual views in detecting malware and how does it benefit from appropriately combining them? Accuracy under different experimental settings are investigated through the following sub-RQs: (RQ1.1) How accurate is MKLDroid in detecting unseen malware when trained with an up-to-date dataset and how does it compare to state-of-the-art approaches? (RQ1.2) How accurate is MKLDroid in detecting unseen malware when trained with a dataset that is historically anterior to the evaluation set? (RQ1.3) How accurate is MKLDroid in detecting recent malware apps collected in-the-wild? (RQ1.4) Which views of MKLDroid are most (and least) effective and does combining them through MKL offer significant improvements? (RQ2 Efficiency) How efficient are MKLDroid\u2019s individual views in terms of overall training and prediction time and does combining them incur significant overhead? (RQ3 Locating malice) How accurately does MKLDroid locate malice code in a given sample and does it explain the malicious behavior exhibited by the sample?\n4.2 Datasets & Experiments\nWe conducted experiments with both benchmark datasets and apps collected in-the-wild. These datasets with details such as number of samples and time of compilation are presented in Table 1. A total of 60,561 apps have been used in our evaluations. The design of all our experiments are summarized in Table 2."}, {"heading": "4.2.1 Controlled Experiments", "text": "Controlled experiments were conducted on malware samples from well-known benchmark datasets and benign apps from Google Play. Three controlled experiments (CE1, CE2 and CE3) were conducted as described below. CE1: 5,560 malware apps from DR and 5,000 benign apps from GP1 collections were used to form the dataset for experiment CE1. The model is trained using 70% of these samples chosen at random and is\ntested for accuracy on the remaining 30% samples. CE2: 24,317 malware apps from VS and 10,000 benign apps from GP2 collections were used to form the dataset for experiment CE2. The training and test-set apps ratio is same as CE1. CE3: It could be observed that the process followed in CE1 and CE2 (i.e., splitting the malware and benign samples randomly into training and test-sets and performing evaluation) is followed in almost all the previous malware detection methods such as [22, 25, 28, 45]. However, this type of evaluation has two issues: (1) Malware in benchmark datasets were collected at a particular point in time and hence are homogeneous in terms of their attack vectors. However, malware continue to evolve and more sophisticated variants are produced subsequent to publishing such datasets [23, 29]. (2) As observed by Allix et al. [18], in these experiments, samples in the training set may be historically posterior to those in the test-set. While, in the real-world/AV industry settings, when a new unseen app must be processed for detection, the training sets used are, necessarily, historically anterior to the new app. This constraint is not considered in experiments similar to CE1 and CE2.\nWe address these two issue, in experiment CE3, by enforcing that the training set used for building the classifier is historically anterior to the test-set. We achieve this by using the samples from DR dataset which were collected from 2010 to 2012 to train the detection model (along with GP1 benign apps) and we use the samples from VS dataset which were collected from 2013 to 2014 to test the classifier (along with GP2 benign apps)."}, {"heading": "4.2.2 Wild Experiments", "text": "The controlled experiments CE1, CE2 and CE3 were conducted on malware from benchmark datasets. A common observation is that real-world malware, due to their rapid evolution are more challenging to detect that the ones in the benchmark datasets [73]. A technique\u2019s effectiveness in detecting malware in the wild could not be determined through testing on such outdated homogeneous datasets. To address this, we also test our model on a large collection of recent apps from popular third-party markets (in experiment WEx). To this end, a total of 14,684 apps from five different third-party markets were collected from Aug. 2013 to Sep. 2016. To test the model on these apps, we need the ground truth labels of these apps (i.e., whether they are malicious or benign). To this end, following the software security research practices proposed in [22] and [23], we leveraged on the VirusTotal web portal10 to infer their ground truth labels. Out of these apps, 6,128 are found to be malware. Thus, in WEx, all the malware apps from DR and VS (29,877 in total) and\n10https://www.virustotal.com\nbenign apps from GP1 and GP2 (15,000 in total) collections were used to train the classifier. The test-set comprises of 14,684 wild apps."}, {"heading": "4.2.3 Malicious Code Localization Experiment", "text": "In this experiment, we intend to evaluate MKLDroid\u2019s capabilities to locate the malicious code in a given sample. More specifically, we explore whether it could locate malice methods or classes involved in the sample\u2019s attacks.\nQuantitative Evaluation. As mentioned earlier, though a vast body of literature on Android malware detection approaches exists, none of them systematically addressed the problem of locating malice code in given sample. This is partly due to the fact that none of existing datasets (incl. DR [22], VS [55], AndroZoo [54]) provide ground-truth on the location of malice code11 such as names of methods/classes involving in malice operations. They just provide labels to ascertain whether a sample holistically is benign or malicious. Obviously, with these datasets, one could not quantitatively evaluate malicious code localization capabilities. In order to address this, we extended an existing dataset as follows. Recently, Mystique [73] proposed an Evolutionary Computation based method to automatically generate new malware samples learning from attack and evasion strategies of benchmark malware. Mystique provided a dataset of 10,000 such automatically generated malware with the names of the classes that contain malice code. However, almost all the code in these samples are either malicious or from commonly used libraries (e.g., android.support) and there are no benign functionalities. In other words, none of these apps are repackaged malware and hence do not cater well to the real-world needs of locating malice code in repackaged malware. Hence to extend it by randomly choosing 3,000 apps from this dataset and piggybacked the same on benign apps from Google Play. Hence, for each of these apps we are certain of the following: (i) they contain both benign and malice code, (ii) names of the classes that contain malice code. We refer to this dataset as MYST and use the same in experiment MCLEx, where we investigate MKLDroid\u2019s malicious code localization capabilities quantitatively, as follows.\nWe train our model using 2,000 malware from MYST dataset and 2,000 benign apps (that were not used for piggybacking). Subsequently, we test the model on the remaining 1,000 MYST samples. Remember, during testing, MKLDroid assigns m-scores to every class in an app. Hence, we investigate whether the classes with highest m-scores are indeed malicious using MYST\u2019s ground-truth.\nQualitative Evaluation. To perform qualitative evaluation we do not need manual annotations on classes/methods containing malice code. All we need are samples that contain malice code at least in one of their classes/methods and we could use MKLDroid on them to investigate if it locates such code. Hence, for qualitative evaluation, we choose the DR dataset12 that contains real-world malware with malice code spread across many methods and classes. The experimental settings in CE1 are reused in this evaluation. We manually investigate whether classes and methods with high m-scores correspond to the sample\u2019s attacks.\n4.3 Experimental Setup\nAll the experiments were conducted on a server with 20 cores of Intel(R) Xeon(R) CPU E5-2699 v3 @ 2.30GHz and 200 GB RAM running Ubuntu 14.04.\n4.4 Implementation and Comparative Analysis\nMKLDroid is implemented in approximately 9,700 lines of Python, Java and C++ code. Androguard [8] and Soot [12] have been used to build the PRGs and infer the reachability contexts of PRG nodes. For SMO-MKL functionalities, the source code provided by SVN Vishwanathan et al. [69] has been used.\nComparison with state-of-the-art solutions. Our approach is compared against three state-of-theart ML based Android malware detection solutions, namely, Drebin [22], Allix et al. [23] and Adagio [28]. To this end, we re-implemented Drebin and Allix et al.\u2019s approaches. For Adagio, an open-source\n11Recently, Li et al. [55] provided a dataset of repackaged apps of the form: (app1, app2), where app1 is the original (benign) app and (app2) is the repackaged version of app1. However, they do not ascertain whether or not the new code injected in app2 is malicious. In fact, exploring this dataset, we observe that a majority of the repackaged apps were adware or other type of PHAs. Hence, we refrain from using this dataset which lacks precise ground truth labels on malice methods and classes in our experiments.\n12More than 80% of samples in this dataset are piggybacked malware thus making this dataset amenable for our qualitative analysis [55].\nimplementation [11] provided by the authors is used. Since the accuracy of these solutions predominantly depend on the features they use, we briefly introduce them here.\nDrebin [22] is well-known for its scalable and explainable detection. It extracts light-weight semantic features such as APIs and permissions used, URLs accessed, names of components from apps and subsequently, trains a linear SVM to distinguish malware from benign apps.\nAllix et al. [23] proposed another scalable approach using signatures of basis blocks in CFGs. Therefore, we refer to this technique as CFG Signature Based Detection (CSBD) in the reminder of the paper. CSBD constructs CFGs of individual methods and encodes them as text-signatures following Cesare and Xiang\u2019s grammar [17]. Subsequently, a RF classifier is trained with these signatures to detect malware subsequently used as features.\nAdagio [28] constructs CGs and uses byte-code instructions to assign labels to nodes. NHGK [63] is used to extract CG neighborhoods as features and a histogram-intersection (HI) kernel SVM is trained to detect malware. Adagio uses HI kernel in the primal formulation to achieve interpretable results.\nWe re-implemented Drebin and CSBD in 1400 and 900 lines (approx.) of Python code, respectively. Authenticity and correctness of our re-implementations is verified as we observe their accuracy and scalability values very similar to the ones reported in the original work on similar experiments (see \u00a75). Besides this, re-implementations have been done in consultation with the authors of original work.\n4.5 Evaluation metrics\nStandard evaluation metrics such as Precision, Recall and F-measure are used to determine the effectiveness of malware detection. All these values are in the range [0, 1]. Higher values indicate accurate detection. Efficiency is determined in terms of training and testing durations (in seconds). Lower training and testing durations indicate scalable detection. For evaluating malicious code localization, False Positive Rate (FPR) and False Negative Rate (FNR) measures are used. These are expressed as percentage values. Lower FPR and FNR indicate precision and completeness in detection, respectively."}, {"heading": "5 Results and Discussions", "text": "The evaluation, results and relevant discussions pertaining to each of the RQs is presented in this section. The accuracy and efficiency results for controlled and in-the-wild experiments is presented in subsections \u00a75.1 and \u00a75.2, respectively. For malicious code localization, a qualitative evaluation which involves case studies on two well-known malware families and a quantitative evaluation on the homegrown dataset are presented in \u00a75.3.\n5.1 RQ1: Accuracy"}, {"heading": "5.1.1 RQ1.1 Accuracy on benchmark datasets", "text": "As mentioned earlier, in experiments CE1 and CE2, 70% of samples were randomly chosen from the evaluation datasets and used for training the classifier and the remaining 30% samples are used to test its performance. The hyper-parameters of classifier are determined on the training set (using 5-fold cross-validation), whereas the test-set is only used for determining the final detection performance. We repeat this procedure five times and average the results. In order to study the effectiveness of individual views, we report the prediction results using individual base kernels and the uniform kernel (which is the mean of all base kernels).\nThe results for experiments CE1 and CE2 along with comparison to state-of-the-art techniques is presented in tables 3 and 4, respectively. The following inferences are drawn from these tables:\n\u2013 At the outset, we observe that all individual views have certain effectiveness in detecting malware. This is reflected by the fact that all the base kernels get more than 75% F-measure in both the experiments. In fact, 4 out of 5 base kernels offer comparable F-measures to state-of-the-art approaches. \u2013 Out of the base kernels, API kernel achieves the best performance in both the experiments. Meaning, context-aware structural API dependencies turn out to be excellent features for detecting malware. In fact, this observation goes hand-in-hand with the fact that API related features (API frequencies and ngrams [22, 34], API sequences [27], subgraphs [20, 21, 25, 31, 65], dependencies [45, 46], etc.) are the most popular features in Android malware detection literature.\n\u2013 The performances of instruction and signature kernels are very close in both the experiments and are marginally less effective than those of API kernel. This is because both these kernels capture structural dependencies from the apps that are sparse, obfuscation resilient and abstract. \u2013 Permission kernel achieves significantly lesser standalone F-measure than the three above mentioned kernels. Understandably, permissions are more coarse-grained features compared to API and instruction sequences. This leads to many misclassifications thereby hampering the kernel\u2019s accuracy. \u2013 Src-sink kernel obtains the least F-measure indicating that it exhibits least malware detection potential. Note that CSSDG actually captures control flows across source and sink nodes and this does not necessarily mean there are data-flows (i.e., information leak) in the suspected control flow paths13. We conjecture that considering control-flow paths as proxies for detecting information leak attacks leads to considerable false positives and thus resulting in a poor detection. \u2013 The main justifications for using MKL to integrate the views could be observed by comparing the uniform kernel and MKLDroid\u2019s performances. The uniform kernel which assigns equal weights to all the base kernels performs on par with MKLDroid obtaining best F-measure in CE1. However, in CE2, which involves larger datasets with more families of malware, the former fails to outperform the latter. Leveraging on MKL, our approach identifies the most appropriate linear combination of the base kernels and obtains better precision, recall and F-measure. This justifies the need for having a non-uniform combination of the base kernels. \u2013 Comparing against state-of-the-art approaches, we observe that MKLDroid achieves performance on par with the best performing technique i.e., Drebin, while outperforming CSBD and Adagio in CE1. It is important to note that Drebin\u2019s features are perfectly engineered to offer excellent performance on the DR dataset. Similar observations have been reported through other large-scale studies such as [53]. Hence achieving on-par performance convincingly reveals the detection potentials of MKLDroid. Notably, all the approaches exhibit lesser F-measure in CE2 than in CE1, revealing that the former setting is more challenging. Interestingly, MKLDroid achieves best results in CE2 outperforming all the state-of-the-art approaches and the uniform kernel.\nHaving sufficiently established the detection capabilities of base kernels and the need for MKL, we exclude evaluations and discussions on individual base kernels in forthcoming sub-RQ 1.2 and 1.3."}, {"heading": "5.1.2 RQ1.2 History-aware training and evaluation", "text": "We now report the results on experiment CE3, where we enforced the constraint: the training set is historically anterior to the test-set in Table 5. Before discussing the results of individual techniques, we present an\n13Remember, we intend to avoid computing expensive data-flows in the app and believe other views (computed at much lesser expense) would complement and mitigate the absence of data-flow related features.\nimportant inference from Table 5: the performances of all the state-of-the-art methods (and MKLDroid) are significantly worse when the test-set is posterior to the training set. This is in-line with the observations reported in [18] and [29]. The reason for this drop in performance and relevant observations are reported below.\nUnlike experiments CE1 and CE2, in CE3, the test-set apps are almost one year historically posterior to the training set ones. Some of these malware could belong to a new family that emerged after the training set was compiled or could be a more sophisticated variant of a family that surfaced in the training set. Hence, all the knowledge acquired and used by the classifier would not be sufficient or relevant.\nIn this aspect, CE3 models the real-world detection settings more closely. The practical potentials of a technique will be revealed in this experiment. Only techniques that capture most aspects of an app that distinguishes malicious behavior from benign ones could perform well. Techniques that overfit the training set will perform poorly particularly in CE3.\nFrom Table 5, it is evident that MKLDroid outperforms all the state-of-the-art techniques, significantly in CE3. The margin of improvement is 11% which is much higher compared to that of CE1 and CE2. Furthermore, the following observations are made from Table 5:\n\u2013 Clearly the precision of all the techniques under comparison are very high and almost same (in the range [0.98,0.99]). This reveals that all the techniques could very well detect test-set malware that are similar to training set malware (e.g., similar variants of families exposed during training). \u2013 However, the real difference between MKLDroid and other techniques lies in the recall value. The other techniques have much poorer recall (well below 0.50). This reveals that even though they could detect known malware, they do not generalize well to find newer variants or families. MKLDroid\u2019s recall value suggests that, it detects newer variants/families better. Nevertheless, its recall is also not very high, indicating high number of false negatives. This is because, though MKLDroid can generalize well, it cannot automatically adapt to the evolution in malware samples. More specifically,, MKLDroid is a batch-learning based approach, where we use a batch of samples to train the model. Subsequent to training, the model is used only to predict the labels of the samples that stream-in. It cannot automatically update its learning unless it is retrained with a fresher or more recent training set. As noted in [21] and [40], this is an inherent limitation of batch-learning based solutions. We discuss our measures to address this adaptiveness issue, later in \u00a77. \u2013 Particularly, the recall and F-measure values of Drebin, which performed well in CE1 and CE2 are very poor in CE3. This indicates that the features captured by Drebin, are too much dependent on the training set and it could reliably detect a new test-set malware only if it is very similar to training set malware. In other words, Drebin suffers from overfitting. This observation is reinforced by the fact that some of Drebin\u2019s features such as URLs, names of components, etc. do not adapt to unseen test-set apps well. For instance, the component names in test-set apps may be vastly different from training set ones and learning these becomes useless during testing. This introduces noisy features, leading to overfitting and poor detection rates. \u2013 Unlike Drebin, both Adagio and CSBD use features that are not very much training set-specific. This helps them generalize well. Furthermore, CSBD uses feature selection to prune irrelevant features and this helps improving its recall and F-measure. However, these approaches perform more like signaturebased detection approaches (as they learn instruction and CFG signatures) and this leads to an overall poor performance in CE3 where there is significant drift in the test-set. MKLDroid outperforms these approaches by 11% or more F-measure."}, {"heading": "5.1.3 RQ1.3 Accuracy on the wild dataset", "text": "We now report the detection results obtained on recent wild apps. In this experiment, WEx, the models are trained using all the malware from benchmark datasets and benign apps from Google Play and tested on apps collected from third-party markets. The precision, recall and F-measure values of all the approaches under comparison are presented in Table 6.\nEvidently, in this experiment, MKLDroid outperforms the state-of-the-art approaches significantly (i.e., by 8% or more F-measure), similar to CE3. The following observations are made from Table 6.\n\u2013 At the outset, conspicuously, for all the approaches under study, performing detection on the wild dataset is more challenging than the benchmark ones. All the four methods produce F-measure in the range [0.60,0.72] in WEx. This observation holds despite the fact that all models are trained with the largest amount of data in WEx, out of all the four experiments. This reveals that the homogeneity observed in the attack vectors of benchmark malware is not observed in the same magnitude among malware apps in the wild. \u2013 Even though the F-measures of these approaches in WEx are similar to those of CE3, a major difference lies in the precision values. In CE3, all the approaches identified test-set malware that exposed in the training set quite well, leading them to better precisions (i.e., in the range [0.98, 0.99]). However, in WEx, their precision values are in the range [0.47, 0.60]. This on average is 45% lesser than CE3\u2019s precision values. This clearly illustrates that the false positives are significant across all these approaches, as distinguishing the behaviors of benign and malware apps in the wild is more challenging. \u2013 In CE3, the test-set malware are entirely posterior to the training set ones, leading to a larger scope for malware evolution. Consequently, all the four approaches obtained poor recall values (i.e., in the range [0.43,0.55]). However, in WEx, the period of collection of test samples, overlaps with certain months of the training set compilation period. This enables the detection models to operate under a less vigorous population drift setting. This directly reflects in their lesser false negative and consequently, better recall values. However, we note these precision and recall values are not as high as in CE1 and CE2, reinforcing the need for detecting and adapting to malware population drift observed in the wild. \u2013 Out of the state-of-the-art approaches, Drebin and CSBD perform reasonably better than Adagio. MKLDroid outperforms these methods by 8% or more F-measure."}, {"heading": "5.1.4 RQ1.4 Effectiveness of individual views", "text": "Having sufficiently established that capturing context-aware multi-view features facilitates MKLDroid to achieve superior accuracies, we now intend to gain insights into the contributions of individual views to its performance. In this sub-RQ, we perform a sensitivity analysis on MKLDroid\u2019s base kernels both quantitatively and qualitatively. In particular, we study whether there is any correlation between the weights that MKL offers to individual base kernels and their detection rate, rank the views based on these weights and also suggest which views to use when resources and time are at a premium.\nQuantitative analysis. As explained in \u00a73.4, the SMO-MKL algorithm used in MKLDroid assigns weights to individual base kernels yielding an appropriate linear combination of the base kernels. These weights of the base kernels in CE1 and CE2 are reported in Table 7. The following observations are made from the table:\n\u2013 A straight-forward observation is that, in our framework, the weight of a base kernel signifies its malware detection potential. Higher the weight, better is the kernel\u2019s detection potential. For instance, the API and Src-sink kernels get the most and least significant weights in both the experiments. This is in line with the fact that these kernels offered the best and the worst standalone accuracies, respectively. However, we note that there need not be direct correlation between the base kernel weights and their accuracies\nwhen non-linear kernel combinations or hyper-kernels are used. Our base kernels\u2019 weight assignments are particularly intuitive as we perform linear MKL in our framework. \u2013 Also, the weights of Instruction and Signature kernels are very similar. This stems from the fact that these kernels capture similar structural information at similar level of granularity, exhibiting identical detection capabilities. Interestingly, Signature kernel obtains more weight than Instruction kernel in CE1, whereas the weight significances are other way around in CE2. We believe this due to the fact that the dataset used in CE1 (i.e., DR) is comparatively more homogeneous than in CE2 (i.e., VS). Homogeneous malware tend to exhibit similar CFG signature thereby helping the Signature kernel to get a trifle better detection rates. \u2013 Permission kernel\u2019s weights rank just below the Signature and Instruction kernels, going hand-in-hand with its prediction quality.\nQualitative analysis. Due to space limitations, the results of qualitative analysis (and visualization of kernel matrices) that reinforce those of quantitative analysis are presented in Appendix 9.2.\nRanking the individual views. With the explanations mentioned above, it is straight-forward to rank the kernels. Considering that the base kernel weights quantifies their relative importances in the MKL setting, the following rankings are obtained: rank 1: API kernel, rank 2: shared by Signature and Instruction kernels, rank 4: Permission kernel and rank 5: Src-sink kernel. However, the scalability of these kernels differ significantly. Hence we defer discussing which subset of kernels to use, when time/resources are scarce, to \u00a75.2, where we report the base kernel efficiencies.\nSummarizing the inferences from RQ1, we conclude that individual base kernels of MKLDroid exhibit subpar malware detection potentials and combining them appropriately through MKL allows them to complement each other to achieve superior accuracies. This context-aware multi-view learning makes MKLDroid powerful enough to detect more sophisticated and newer variants of malware, leading it to significantly outperform state-of-the-art methods in challenging real-world experimental settings.\n5.2 RQ2: Efficiency\nWe now present the results for efficiency of our base kernels, MKLDroid and state-of-the-art approaches in terms of average training and testing durations in experiments CE1 and CE2 (across 5 runs) in Table 8. The training and testing time depends on factors such as sample size, number of features and type of the kernel/learner being used. Hence, these values are also reported. It is noted that the trend in efficiency values remain same in other experiments (i.e., CE3 and WEx) as well. Owing to space constraints, they are omitted.\nThe following are noted as well: (i) for the base kernels that involve feature selection (Instruction & Signature) the reported training duration includes time taken for feature selection, corresponding dimensionality reduction and training the models, and (ii) in the case of MKLDroid, testing duration includes time taken for switching from dual to primal formulation and then predicting the labels (see \u00a73.5). Expectedly, CE2\u2019s training and testing durations are longer than CE1 as it involves larger datasets. From Table 8 the following inferences are drawn:\n\u2013 Since PRG vectors from individual views (e.g., CADG vectors for API kernel, and so on) are used in conjunction with linear SVMs, their base kernel training and testing durations is very less. Since, both uniform kernel and MKL perform classification through linear combinations of base kernels, they require slightly more training and testing durations. \u2013 Comparing individual views. Out of the base kernels, Src-sink and Permission use least number of features and hence emerge as the fastest ones in terms of both training and testing durations. On the other hand, API kernel uses very large number of features and hence emerges as the slowest base kernel. As mentioned earlier in 3.3, in the case of Instruction and Signature kernels, we obtain extremely large number of features (i.e., more than 500,000) and hence feature selection is used choose and retain only 5,000 most informative features. This results in significantly larger training and testing durations. In summary, in terms of efficiency, MKLDroid\u2019s base kernels could be ranked as follows: rank 1: Src-sink, rank 2: Permission, rank 3: is shared by both Instruction and Signature and rank 5: API. Evidently, when we take into account accuracy results from tables 3 and 4 as well, the two most efficient views are not sufficiently accurate. Hence, when there are severe resource/time constraints, we recommend using only the Instruction and/or Signature kernels which achieve high accuracy with reasonable efficiency. Following the above-mentioned strategy, the accuracy-efficiency trade-off among the individual views of\nMKLDroid could be learnt from tables 3, 4 and 8. For particular time or resource constraints, one may decide on which views to use, based on this trade-off. \u2013 Vs. Drebin. Drebin extracts light-weight features (i.e, no PRG based features are extracted) and uses linear SVM for classification. This helps Drebin to achieve very high efficiency. Comparing Drebin\u2019s efficiency against those of MKLDroid\u2019s base kernels, we could see that all of them are much faster than Drebin. This is mainly because these base kernels use lesser number of features than Drebin. Uniform kernel\u2019s efficiency is comparable to that of Drebin. However, none of the base kernels could outperform Drebin in terms of accuracy. Meaning, base kernels achieve this efficiency at the cost of accuracy. Also, when the base kernels are integrated, MKLDroid becomes almost 5 to 6 times slower in terms of training duration and 42 to 44 times slower in terms of testing duration than Drebin. This is mainly because of the time MKLDroid spends to learn the base kernel weights using SMO-MKL and switching to primal formulation, subsequently. \u2013 Vs. CSBD. CSBD uses RF classifier with 100 estimators and 5000 features (selected using Information Gain values). Since RFs are quasi-linear models they require significantly more training and testing durations than approaches that use linear models (i.e., Drebin and MKLDroid). In particular, MKLDroid is more than 2 times faster in terms of training and more than 17 times faster in terms of testing durations than CSBD. \u2013 Vs. Adagio. Adagio uses a kernel SVM, a computationally heavy learner, as it aims to learn non linear decision boundaries. Furthermore, it uses HI kernel with large number of features in the primal formulation, as it aims to build an interpretable model. These factors render the approach very much inefficient with practically intractable training and testing durations. In particular, MKLDroid is more than 595 times faster in terms of training and more than 10,924 times faster testing durations than Adagio.\nSummarizing RQ2 evaluations, we conclude, though MKLDroid uses five base kernels, it sticks to a linear combination of the kernels and hence requires modest training and testing durations. It is more efficient than two of the state-of-the-art approaches. Furthermore, the trade-off between base kernels\u2019 accuracy and efficiency is determined, which would help in using a select few of them when resources and time constraints are severe.\n5.3 RQ3: Locating Malice Code\nIn this RQ, we intend to investigate whether MKLDroid is capable of reliably locating malice code in a given sample both qualitatively and quantitatively. As stated earlier, all the existing approaches14 (incl. Drebin and CSBD) are not capable of doing such localization. Since, fine-grained malicious code localization is MKLDroid\u2019s unique feature, we could not compare this with any existing technique. Hence, we illustrate how MKLDroid achieves it in this subsection and discuss how it supports human analysts to visualize PRGs from different perspectives facilitating precise understanding of malice behaviors\n14Though Adagio, in principle could identify malice methods from CGs, the implementation provided at [11] does not include this."}, {"heading": "5.3.1 Qualitative Evaluation", "text": "To perform qualitative evaluation we trained the model as in experiment CE1 and use it to locate malice code in the test-set apps. Once a test-set app is predicted to be malicious, MKLDroid assigns m-scores to each CICFG nodes (i.e., basic block) as described in \u00a73.5. Hence, for the qualitative analysis part, we manually investigate the code in basic blocks with high m-scores to check whether they indeed are a part of the malware\u2019s attack vector.\nThe above mentioned analysis yielded interesting and useful results for a substantial majority of the test-set apps. We choose to explain the results of two popular malware families, ADRD and Geinimi. ADRD is a family of malware that was wide-spread during the earlier versions of Android, had simple attack vectors to perform privacy leaks and were not repackaged malware. Meaning, almost all the code in the ADRD samples are mal-intended. On the other hand, Genimi performs more sensitive privacy leak attacks with more sophistication. Also, Geinimi samples in the DR dataset are repackaged versions of popular benign apps. Meaning, only a minority of the code in the Geinimi samples are mal-intended.\nCase Study 1: ADRD . The ADRD sample15 used in this study attempts to perform the following malice actions in the background after the phone is booted: accessing users\u2019 personal sensitive information (e.g., IMEI, IMSI and network information) and sending them to remote servers, sending and deleting SMS messages, downloading unsolicited apps, and issuing HTTP search requests.\nThe five different views derived from the app\u2019s CICFG are presented in figures 5 (a) to (e). For the API kernel\u2019s view (in Fig. 5 (a)), the CICFG nodes are awarded m-scores based only the CADG contextual subgraph features that emerge from them. Similar m-score assignments are done to CICFG nodes in the remaining views in sub-figures (b) to (e). Finally, MKL based m-scores (which is a weighted sum of individual views\u2019 m-scores) are assigned to the CICFG nodes in Fig. 5 (f). The nodes are scaled in size and colored according to their m-score. Larger/warmer (i.e., reddish) nodes denote nodes with high m-scores which are potentially malicious and smaller/cooler (i.e., blueish) denote nodes that supposedly do not involve in attack related activities.\nThe following observations are made from Fig. 5 (a):\n\u2013 From API view, we could see that several basic blocks from classes such as com.xxx.yyy.MyService, com.xxx.yyy.MyBoolService and com.xxx.yyy.adad.GetOrder get high API m-scores. We inspected each of these methods manually and realized that these methods indeed perform malice activities. The precise dissection is presented below: \u2013 Trigger. Similar to many popular malware families this ADRD sample uses broadcast notifications and alarm manager APIs to trigger its malicious operations. More specifically, method com.xxx.yyy.MyBoolService.OnReceive uses Intent.getBroadcast API to listen to a specific broadcast message notifying the BOOT COMPLETED event. Once it receives the message, it sets an alarm that is fired periodically using the AlarmManager.set API. These alarms would start a background service named MyService. \u2013 Reading private data. MyService begins its lifecycle execution through invoking the com.xxx.yyy.MyService.OnCreate and com.xxx.yyy.MyService.OnStart methods. In the OnCreate method, the IMEI and IMSI numbers are collected by invoking getDeviceId and getSubsriberId APIs. Also, it registers an object handler to access the SMS database (content://sms/). The OnStart method collects some more private information such as network information (e.g., type of the network \u2014\u2019wifi\u2019 or \u2019UNIWAP\u2019) by invoking getActiveNetworkInfo and getTypeName APIs. \u2013 Leaking private data. Once all this information is collected, the sample encrypts and leaks them over the internet. This is done in methods com.xxx.yyy.adad.GetOrder, com.xxx.yyy.UpdateHelper.GetO and com.xxx.yyy.qzl.GetO. The methods invoke sensitive APIs such as DefaultHttpClient.init, java.io.FileOutputStream.write and DefaultHttpClient.execute. Alternatively, the same information is exfiltrated through SMS using the APIs SmsManager.getDefault and sendTextMessage in method com.xxx.yyy.ssmm.Gef. \u2013 Reading and deleting SMS. Besides this, the service uses method xxx.yyy.SMSObserver.deleteSpecSMS to monitor changes to the SMS database by calling ContentObserver.onChange API and deleting particular messages using ContentResolver.delete API. \u2013 Downloading unsolicited apks. Moreover, the sample attempts to download a new unsolicited apk named \u2019myupdate.apk \u2019 and install the same on the device in method com.tt.yy.loginActivity.Login. 15MD5: 1944d8ee5bdda3a1bd06555fdb10d3267ab0cc4511d1e40611baf3ce1b81e5e8\nAll these operations involved invoking sensitive APIs and hence are adequately captured in the API view. We now turn our attention to other remaining views. The following inferences from figures 5 (b) to (e):\n\u2013 The Permission view (fig. 5 (b)) depicts the CICFG nodes scaled according to CPDG features based m-scores. As mentioned earlier, this ADRD sample\u2019s attack is simple and it turns out that only four permissions are required to carry out this, namely, READ PHONE STATE (for reading IMEI, IMSI etc.), ACCESS NETWORK STATE (for reading the network type), INTERNET(for leaking information through the network and communicating to C&C server) and SEND SMS (for leaking information through SMS). Evidently, much less number of nodes correspond to code that uses these permissions and only these nodes get significant Permission m-scores. This is why we could see a lot of cooler/smaller nodes in this view. Out of the permissions, INTERNET is leveraged by almost all the ADRD variants for leaking information and are more popular than leaks via SMS. Consequently, the CPDG features related to former permission get higher m-scores than the latter ones. The features related to other two permissions are assigned lesser m-scores as well. Interestingly, the APIs used to read and delete SMS are not permission protected and hence they are assigned insignificant m-scores. Overall, in this view, we have only a few suspicious nodes and they are from the following methods: com.xxx.yyy.UpdateHelper.GetO, com.xxx.yyy.adad.GetOrder, com.xxx.yyy.qzl.GetO and com.tt.yy.loginActivity.Login. \u2013 The Src-sink view (fig. 5 (c)) depicts the CICFG nodes scaled according to Src-sink mscores. There exists only one sensitive control flow path in this CICFG and it originates from com.xxx.yyy.MyService.OnCreate method. This path connects the source UNIQUE IDENTIFIER to sinks FILE16 and SMS. We note that this sample leverages ICCs heavily. As our method does not capture ICCs and some paths that exist between other sources such as content resolver and FILE/SMS might be missed by our approach. Overall, in this view, we have only one suspicious node. \u2013 Evidently, the Permission and Src-sink views over-abstract the semantics of the samples compared to the API view. Moreover, in the case of this sample, the information captured by the two former views is a supplementary to that captured in the API view. In other words, this example clearly reinforces the finding from RQ1 that the level of abstraction attained in the Permission and Src-sink views are too coarse-grained to be effective. \u2013 As in figures 5 (d) and (e), the CICFGs scaled according to the Instruction and Signature m-scores and look very much different from the three aforementioned views. This is expected as those three views are closely related and capture similar semantics of the app. However, Instruction and Signature views, as discussed before, footprint the apps more like syntax-based detectors rather than semantics-based ones. For instance, the methods considered as significant in these two views are ones that belong to classes com.xxx.yyy.SMSEntity, com.xxx.yyy.SMSObserver. These two classes are present in the same composition in more than 27% of the ADRD samples in the DR dataset. These methods predominantly contain utilities code that is common across multiple variants of the ADRD family. Meaning, their CFG signatures and instruction sequences remain same across multiple samples and act as good features to characterize code that is unique in malware samples, but not necessarily malice. These two views precisely exploit these features to detect ADRD footprints. Figures 5 (d) and (e) visually illustrate that these two views capture information that is complementary to the three other views. \u2013 Finally, we scale the nodes according to MKLDroid\u2019s m-scores, which is nothing but the linear combinations of their m-scores in each of the five views. Evidently, this multi-view representation retains useful information from all the views. For instance, this view considers both com.xxx.yyy.UpdateHelper.GetO which is significant due to its semantic functionalities and com.xxx.yyy.SMSObserver.FindReturnMsg which is significant due to its popularity across multiple ADRD variants as more or less equally malicious. \u2013 Finally, we note that this sample is not piggybacked. Meaning, much of the code (i.e., CICFG nodes) take part in the attack performing potentially harmful operations. This is indeed reflected well when we visualize MKLDroid\u2019s results as most nodes are larger and warmer looking (i.e., assigned high m-scores).\nCase Study 2: Geinimi. The Geinimi sample17 used in this case study is the real-world version of the working example presented in \u00a72. Unlike the ADRD sample, this is a repackaged malware. This sample\u2019s malice code is piggybacked on a popular benign game app. Also, the malicious functionalities in this sample are more sophisticated than ADRD . Geinimi \u2019s malice code is triggered through a systemgenerated broadcast message. On receiving it, Geinimi starts a service in the background. This service read\n16In this context, the leaks through internet is considered akin to writing into a file and hence we see a FILE sink instead of a NETWORK sink.\n17MD5: 7bbd566f2f3abb78b3ffcc23ba4ad84e06a00f758d245c660c61b21814a850a5\nvolumes of personal data such as the users\u2019 location, contacts, emails and leaks them through internet and SMS messages.\nThe five different views derived from the app\u2019s CICFG are presented in figures 5 (a) to (e). At the outset, it is evident that unlike ADRD , across all the views, only a few nodes actually potentially malicious and have received high m-scores. This is because in the case of this piggybacked Genimi app, only a few nodes involve in mal-intended operations (i.e., rider code) and the majority of the code is benign (i.e., host app\u2019s code).\nThe following observations are made from Fig. 6 (a):\n\u2013 Trigger. On receiving the BOOT COMPLETED event notification, a service named com.geinimi.AdService is started. This service continues to collect a variety of private information and leaks the same as described below. \u2013 Collecting location information. Geinimi collects user\u2019s geographic location in method geinimi.c.d.a using APIs getLastKnownLocation, getLatitude and getLongitude. \u2013 Collecting device identifiers. The method geinimi.c.k.init collects 13 different types of private information including phone number, IMEI, IMSI, mobile service operator\u2019s name, etc. using several APIs such as getLine1Number, getSimSerialNumber, getSimOperatorName, etc. \u2013 Collecting contacts. This sample attempts to read users\u2019 contacts stored in the content providers through invoking getContentResolver and ContentResolver.query APIs. These operations are performed in methods geinimi.c.b.a and geinimi.c.b.b. The former method just reads the contact\u2019s display name, last contacted time and phone number. The latter method collects email addresses along with the above-mentioned information and bundles the same with the device\u2019s unique identifier making them ready to be leaked. \u2013 Collecting emails related information. The emails stored in the content resolver are read using several methods in the class geinimi.ads.h and method f in this class bundles the emails\u2019 to address, cc/bcc address list, subject and content into an intent message (using ICC related APIs such as Intent.putExtra) and send them across to other methods for leaking them over internet. \u2013 Leaking over internet and SMS. Finally, this sample leaks the collected private information over the internet in method geinimi.c.l.b using APIs such as java.net.HttpURLConnection.init, java.net.URL.init, URL.openconnection, java.io.DataOutputStream.write, flush, close and HttpURLConnection.disconnect. Alternatively, the same private contents are leaked through SMS in method geinimi.c.i.a. This method uses APIs SMSManager.getDefault and sendTextMessage.\nSimilar to the case of ADRD \u2019s API view, all these operations in Geinimi involved invoking sensitive APIs and hence are adequately captured in this view. We now make the following observations from figures 6 (b) to (f):\n\u2013 Similar to the Permission view in the previous case study, only a minority of Geinimi \u2019s APIs/URIs are permission protected and consequently, receive high Permission m-scores. Predominantly, the following permissions are used by this sample to carry out the privacy leaks: ACCESS COARSE LOCATION, ACCESS FINE LOCATION, READ CONTACTS, READ PHONE STATE, INTERNET and SEND SMS. All these permissions are leveraged by the methods discussed above. Interestingly, since the method geinimi.c.k.init involves accessing a large number of device identifier related APIs across its different basic blocks, it happens to use READ PHONE STATE permission repeatedly. This behavior has rewarded more significant weights to these basic blocks in the Permission view than the CADG one. Also, another method, com.geinimi.AdActivity.isRunningServices, that helps to obfuscate Geinimi \u2019s attacks through using APIs such as Class.forName and getClassName. These are not permission protected APIs, however, we mapped them to special permissions (see \u00a73.2) and this has yielded the corresponding nodes, more significant mscores in the Permission view compared to other views. \u2013 Since Geinimi \u2019s privacy leaks involve more variety of information sources being read and leaked than ADRD , we could see several nodes with large m-scores in the Src-sink view in Fig. 6 (c). Typically, these control flow paths originate from the following methods: com.geinimi.c.b.a, com.geinimi.c.b.b and com.geinimi.c.d.a. \u2013 Similar to the observations made in ADRD , both the Permission and Src-sink views over-abstract Geinimi \u2019s attacks. For instance, the sensitive operations in methods com.geinimi.ads.h.f and com.geinimi.c.l.b are not adequately captured in both these views. However, these two views could capture some critical information which is not reflected in API views. For instance, they exclusively reveal the sensitive operations in methods such as com.geinimi.AdActivity.isRunningServices. \u2013 Similar to the ADRD sample\u2019s case, the Instruction and Signature views footprint methods are statistically prominent across multiple variants of the Geinimi family. Specifcially, two methods\ncom.geinimi.ads.a and com.geinimi.ads.b which figure in more than 15% of the Geinimi samples in the same composition are leveraged to footprint them in both these views. \u2013 Finally, all the aforementioned views are integrated using MKL in Fig. 6 (f). Evidently, semantically significant nodes from methods such as com.geinimi.c.b.a and utility code related nodes from methods such as com.geinimi.ads.a receive high m-scores thus capturing the best of both worlds, helping effective detection. Overall, since this app is piggybacked with a large amount of benign code, one could see a large number of cooler/smaller nodes in MKLDroid\u2019s multi-view CICFG. This is in sharp contrast from ADRD \u2019s multi-view CICFG in Fig. 5 (f)."}, {"heading": "5.3.2 Quantitative Evaluation", "text": "We now present the results of quantitative evaluation of our experiments to locate malice code from MYST dataset. As mentioned earlier, in this experiment, the model is trained using 2,000 MYST malware and 2,000 benign apps. This model is then allowed to locate malice classes in each of the remaining 1,000 MYST apps. We consider classes with highest MKL based m-scores as malicious and compare them against the ground-truth on names of malice classes to compute the correctness and completeness of detection.\nOn average, we have 70.38 classes in MYST apps and according to ground truth, 2.48 of them are malicious. Given this statistics, we consider that malice code is indeed present in top 10 classes with highest m-scores awarded by MKLDroid. Meaning for an analyst working on this dataset, MKLDroid would reduce the search space for seeing malice code by 1/7th of the total code, on average. FPR, FNR, precision and recall values averaged across all the 1,000 appss are presented in Table 9. The following inferences are drawn from the table:\n\u2013 The average FNR is just over 5% and the recall values is more than 94%. Meaning, while inspecting only 1/7th of the code, MKLDroid facilitates the analysts to detect and inspect more than 94% of all the classes that are involved in malice operations. This is immensely helpful for analysts as it narrows down their search to potentially malice code locations. \u2013 The average FPR and precision value is seemingly poor i.e., 17% and 14.34%, respectively. The major reason for high FPR and low precision lies in the ratio between the number of actual and predicted malice classes. The average number of malice classes in the MYST dataset is as low as 2.48. However, remember, the malice code in MYST dataset is automatically generated and not very much close to the real-world scenario, where we would have a larger number of malice classes on average. For instance, even in the primitive ADRD and Geinimi samples that were used in our case studies contained 32 and 82 malice classes, respectively. Given this statistics, in order to contain FNs, we have considered 10 classes with highest m-scores to be malice indeed. Since, the ratio of ground truth malice classes and predicted malice classes is very much skewed (i.e., 2.48/10), we obtain low average FPR and precision values. Furthermore, unlike automated detection, from an analysis view-point, 17% of FPs is permissible. Meaning, while inspecting roughly 1/7th of the whole code, only 17% of the times MKLDroid would present a false positive class for review to the analyst. Just by reviewing the preliminary details such as name of the class (i.e., whether it is from libraries, or from host app and not the rider code), the analyst could quickly spot these FPs. Hence, given the nature of our application, low average FPR and precision could be justified.\nSummarizing RQ3 inferences, it is clear that MKLDroid\u2019s individual views, owing to their inherent limitations, could only reveal a minority of malicious code portions. MKLDroid achieves more comprehensive and precise malicious code localization results by appropriately combining the m-scores from individual views."}, {"heading": "6 Related Work", "text": "Many well-known malware detection techniques have been reviewed in previous sections. We throw light on remaining works and contrast them from MKLDroid in this section under three categories: (1) PRG\nbased approaches that use only one set of features, (2) approaches that use multiple feature-sets and (3) approaches that attempted coarse-grained malicious code localization.\n6.1 PRG based Android malware detection\nStructural features from PRGs (subgraphs, walks, etc.) have been used by a family of approaches reviewed below.\nAdagio\u2019s structural detection and comparison has been already discussed in detail in \u00a74.4 and \u00a75. DroidMiner [27] proposes a two-tiered behavior graph to model malicious program logic into a vector of threat modalities, and then applies classification according to these modalities. DroidSIFT [24] models API-relevant behaviors into weighted CADGs and classifies malware based on a vocabulary of known malicious CADG subgraphs. However, unlike MKLDroid, DroidSIFT uses a fixed vocabulary of handpicked subgraphs to construct feature vector representations. This limits the recall of the model when used over a longer period of time. Recently, AppContext [25] proposes differentiating malicious and benign behaviors based on the contexts similar to ours. However, it ends up capturing contextual features from individual nodes without their topological structural information. MassVet [30] statically analyzes apps\u2019 UI code to extract a graph that expresses UI states and transitions. Subsequently, it uses a DiffCom analysis to detect repackaged malware. MaMaDroid [29] constructs CGs, models API call sequences as Morkov Chain features and uses Instance-based classifiers (RFs and kNNs) for detection. Both MassVet and MaMaDroid do not capture contextual information.\nOn the other hand, a prominent set of works which leverage on PRGs for information-flow analysis include FlowDroid [41], IccTA [42], Mudflow [45] and DroidSafe [43]. These works predominantly use only the data-flow view and target detecting privacy leak attacks and related malware.\nIn sum, all the above-mentioned approaches capture PRGs\u2019 structural information from only one perspective, unlike MKLDroid.\n6.2 Multi-perspective approaches\nRecently, quite a few approaches leveraging on multiple features sets with different modalities have been proposed. However, MKLDroid differs from them in two ways: (i) none of them use both context-aware and structural features which complement each other yielding better accuracies, and (ii) the way MKLDroid appropriately and systematically integrates multiple views.\nProminent works that employ multiple static and dynamic analysis-based feature-sets are discussed below. Drebin\u2019s methodology which uses as many as 8 feature-sets has been explained and compared in \u00a74.4 and \u00a75. Sahs and Khan [31] extract a variety of features including tokens from user-defined permissions, standard permissions and CFG signatures and subsequently takes an anomaly detection approach using a One-Class SVM to detect malware. Peiravian et al. [35] take a simpler approach by considering permissions and API calls as features. MAST [32] uses selected permissions, Intent filters, the existence of native code and zip files, then applies Multiple Correspondence Analysis to perform malware detection. MADAM [33] uses five feature-sets that includes system calls, critical APIs, user-interaction based features and metadata related features (e.g., rating, number of downloads, etc.). RevealDroid [46] uses four feature-sets namely, sensitive APIs, information flows, Intent actions and package-level API informations with Decision Tree classifier to perform detection.\nHowever, all the above-mentioned approaches just perform an early fusion of their multi-modal features i.e., just concatenate the feature vectors from individual perspectives. This results in obtaining a performance on par with uniform kernel of these features. As demonstrated in \u00a75.1, this results in sub-optimal accuracies. Unlike these approaches, thanks to its MKL phase, MKLDroid arrives at the most appropriate combination of its perspectives that offers best accuracy and explainability.\nTo the best of our knowledge, the only other work that uses MKL for multi-view Android malware detection is HADM [37]. MKLDroid differs from this work in the following aspects: (i) HADM uses primitive features such as frequencies of APIs, advertisement network names etc. along with similar structural features. In other words, HADM does not use robust context-aware features like our approach, (ii) HADM uses a non-linear combination of base-kernels and hence its predictions are inexplainable, rendering it incapable of performing malicious code localization.\n6.3 Malicious code localization\nAs mentioned earlier, multi-perspective malicious code localization is a unique feature of MKLDroid. However, we note that recently, two approaches have attempted to locate malice portion of PRGs. They are reviewed and contrasted below.\nDrDroid [57]. This approach is specifically designed to detect repackaged malware and locate the injected malice code. DrDroid achieves this by splitting an app\u2019s CG into multiple regions called as DRegions and predicts whether each of them is malicious or benign. However, on many occasions, this method finds only one DRegion in apps, thus labeling all the code in an app as either malicious or benign. In fact, out 5,600 apps in Drebin [22] dataset, this approach marked the entire code as malicious in 3,757 apps. Also, this approach could not rank portions of apps such as methods or classes based on their severity or degree of maliciousness. Meaning, all the code portions in the malice DRegion are considered equally malice.\nHookRanker [56]. This approach is designed to identify piggybacked packages that are potentially malice from repackaged version of benign apps. HookRanker makes a strong assumption that malice code in repackaged malware will be contained in separate packages. While the validity of this assumption is debatable, this approach is incapable of identifying finer malice portions like methods and classes. As pointed out in [30] and [52], in many cases only certain classes and methods of the injected code are malice. In fact, HookRanker states \u201dwe consider all the injected code as malicious, even if the actual malicious payload is only some part of the added code\u201d. HookRanker is also incapable of discriminating code portions based on their degree of maliciousness.\nIn-principle, both these approaches are not designed to detect malware that are not piggybacked and hence could not be deployed as general malware detection solutions.\nIn sum, none of the above-mentioned techniques exhibit all the three qualities that MKLDroid possesses: context-aware, multi-view malware detection and malicious code localization."}, {"heading": "7 Limitations", "text": "Lack of data-flow and dynamic analyses. The goal of MKLDroid is to take context-aware multiview approach towards comprehensive malware detection and our evaluations in RQ1 (\u00a75.1) demonstrated MKLDroid\u2019s efficacy in such a detection. However, MKLDroid, cannot generally detect all sorts of malicious behaviors, as it builds on concepts of static analysis and lacks dynamic inspection. Moreover, information leak attacks identified by our approach are prone to false positive, as it takes into account only control-flow features and lacks data-flow analysis. As a natural extension of MKLDroid, we intend to integrate these two perspectives in our future work. The reason behind not including them in the current work, is their poor scalability18.\nIn the current work, we mitigate the absence dynamic analysis features by maneuvering our multi-view analysis as follows: Permission view extracts API calls related to obfuscation, reflection, and loading of code, such as reflect.Constructor and DexClassLoader.loadClass and considers their invocations as use of special permissions. These CPDG features enable us to at least spot the execution of hidden code\u2014even if we cannot further analyze it. In combinations with features from other views, MKLDroid is still able to identify malicious behaviors despite the use of some obfuscation techniques.\nPopulation drift. Recently, malware population drift (i.e., drift in malicious characteristics induced by malware evolution over time) has been studied closely by the research community and considered as serious and legitimate threat to practicality of malware detection techniques [21, 40, 49]. These works suggest using incremental ML techniques (e.g., online and active learning) to handle this drift, automatically. As noted through our evaluations in RQ 1.4 (\u00a75.1.3) MKLDroid, being a batch-learning based framework, falls short of handling this drift and its recall keeps reducing over time. We intend to address this using Online MKL [70] approaches in the future.\nAdversarial attacks. Another limitation which follows from the use of ML is the possibility of attacks by adversaries such as poisoning (see [50, 67]). While common obfuscation strategies, such as identifier renaming and code reordering do not affect MKLDroid, adversaries may succeed in reducing its accuracy by incorporating benign contextual subgraph features or fake invariants into malicious apps. Even though such adversarial attacks against ML based detectors cannot be ruled out in general, meticulous sanitization of training data (see [50]) can limit their impact.\n18As discussed in [19, 22, 27, 45, 46] performing precise data-flow and dynamic analysis to extract features is computationally heavy."}, {"heading": "8 Conclusions & Future Works", "text": "In this paper, we propose MKLDroid, a framework that performs context-aware, multi-view malware detection and malicious code localization. In its pipeline of detection and localization process, firstly, MKLDroid deploys static analysis and graph kernels to extract five complementary sets of semantic views of apps. Subsequently, it combines these views in a systematic and scalable manner using MKL and performs malware detection. Finally, ensuing detection, MKLDroid uses a novel kernel methods based approach to award m-scores to every basic block, method and class in an app which quantifies the degree of malice activities it performs. This helps to precisely locate malice code portions. Through our large-scale experiments on both benchmark and wild dataset apps, we demonstrate that MKLDroid outperforms state-of-the-art techniques in terms of accuracy (particularly, by more than 11% F-measure on real-world experimental settings), while maintaining high efficiency. Also, in malicious code localization experiments, it identifies all the malice classes in piggybacked malware apps with 94% average recall.\nFuture work. In our future work, we plan to investigate replacing MKLDroid\u2019s batch MKL with online MKL algorithms [70] so that it automatically adapts to malware evolution and population drift. Another straight-forward extension of our framework would be to use more semantic views towards performing more comprehensive detection. To this end, we plan to incorporate dynamic analysis based features.\nRelease of results. In order to provide scope for persuasive research on malicious code localization, we release the results of qualitative and quantitative evaluations of all the apps in Drebin [22] and Mystique [73] datasets at [13]."}, {"heading": "9 Appendix", "text": "9.1 Contextual relabeling Algorithm\nAlgorithm 3: CWLK - Contextual relabeling input : G = G0 = (N,E, \u03bb, \u03be) \u2014 PRG with set of nodes (N), set of edges (E) and set of node labels (\u03bb) and contexts (\u03be)\nh \u2014 number of iterations output: {G0,G1, ...,Gh} \u2014 contextual WL sequence of height h\n1 begin 2 for i = 0 to h do 3 for n \u2208 N do 4 \u03c3i(n) = {} 5 if i > 0 then // neighbourhood (i.e., degree 1 neighbors) of n 6 N (n) = {m | (n,m) \u2208 E} 7 Mi(n) = {\u03bbi\u22121(m) | m \u2208 N (n)} // neighbourhood label 8 \u03bbi(n) = \u03bbi\u22121(n)\u2295 sort(Mi(n))\n// adding context to the neighborhood label 9 for c \u2208 \u03be(n) do\n10 \u03c3i(n) = \u03c3i(n) \u222a c\u2295 \u03bbi(n) // contextual neighbourhood label 11 \u03c3i(n) = join(\u03c3i(n)) // optional step: label compression 12 \u03b3i(n) = fc(\u03c3i(n))\n// Contextual WL graph at height i 13 Gi = (N,E, \u03b3i) 14 return {G0,G1, ...,Gh}\nAlgorithm 3 presents the contextual relabeling process. The inputs to the algorithm are PRG, G and the degree of neighborhoods to be considered for re-labeling, h. The output is the sequence of CWL graphs, {G0,G1, ...,Gh}={(N,E, \u03b30), (N,E, \u03b31), ..., (N,E, \u03b3h)}, where \u03b31, ..., \u03b3h are constructed using the contextual relabeling procedure.\nFor the initial iteration i = 0, no neighborhood information needs to be considered. Hence the contextual neighborhood label \u03b30(n) for all nodes n \u2208 N is obtained by justing prefixing the contexts to the original node labels to arrive at \u03c30(n) (lines 9-11). \u03c30(n) could be optionally compressed with a compression function fc to compute \u03b30(n) (line 12). For i>0, the following procedure is used for contextual re-labeling. Firstly, for a node n \u2208 N , all of its neighboring nodes are obtained and stored in N (n) (line 6). For each node\nm \u2208 N (n) the neighborhood label up to degree i \u2212 1 is obtained and stored in multiset Mi(n) (line 7). \u03bbi\u22121(n), neighborhood label of n till degree i\u22121 is concatenated to the sorted value of Mi(n) to obtain the current neighborhood label, \u03bbi(n) (line 8). Finally the current neighborhood label is prefixed with the contexts of node n to obtain \u03c3i(n) which is then compressed to arrive at, \u03b3i(n), the contextual neighborhood label (lines 9-12). For every iteration i, this process of contextual relabeling yields CWL graph at height i, Gi (line 13). Finally, the CWL sequence comprising CWL graphs from height 0 to h are returned (line 14).\n9.2 Qualitative Analysis of Base Kernels\nThe detection capabilities of the base kernels and kernel combinations could also be inferred by visualizing the kernel matrices. To this end, we present the kernel matrix of all the samples used in CE1 as a heat map in Fig. 7. The first (top-left) 5,000 samples are the benign apps from the GP1 collection and the subsequent (bottom-right) 5,600 samples malware from DR collection. Every cell in the kernel matrix represents the similarity value between a pair of apps. Dark and light shades in cells indicate low and high similarity values, respectively.\nIt could be clearly seen that the malware apps exhibit high similarities among them in all the views compared to the benign apps. This qualitative depiction reinforces the observations on homogeneity in DR collection that we discussed above. Also, the inferences on individual base kernel\u2019s detection potentials discussed in RQ1.1 are observed qualitatively from figures 7 (a) - (e). For instance, the API kernels separates the malware and benign samples better than other base kernels. Also, the non-uniform linear combination of kernels learnt by SMO-MKL (Fig. 7 (g)) offers the best separation between the samples of the two classes."}], "references": [{"title": "An introduction to variable and feature selection", "author": ["I. Guyon", "A. Elisseeff"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2003}, {"title": "Pscout: analyzing the android permission specification.", "author": ["Au", "Kathy Wain Yee"], "venue": "Proceedings of the 2012 ACM conference on Computer and communications security. ACM,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "A Machine-learning Approach for Classifying and Categorizing Android Sources and Sinks.", "author": ["Rasthofer", "Siegfried", "Steven Arzt", "Eric Bodden"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "Classification of malware using structured control flow", "author": ["S. Cesare", "Xiang", "January"], "venue": "In Proceedings of the Eighth Australasian Symposium on Parallel and Distributed Computing-Volume", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "Machine Learning-Based Malware Detection for Android Applications: History Matters", "author": ["Allix", "Kevin"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}, {"title": "The Evolution of Android Malware and Android Analysis Techniques.", "author": ["Tam", "Kimberly"], "venue": "ACM Computing Surveys (CSUR)", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2017}, {"title": "Contextual Weisfeiler-Lehman Graph Kernel For Malware Detection.", "author": ["Narayanan", "Annamalai"], "venue": "The 2016 International Joint Conference on Neural Networks (IJCNN)", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "Adaptive and Scalable Android Malware Detection through Online Learning.", "author": ["Narayanan", "Annamalai"], "venue": "The 2016 International Joint Conference on Neural Networks (IJCNN)", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2016}, {"title": "Drebin: Effective and explainable detection of android malware in your pocket.", "author": ["Arp", "Daniel"], "venue": "Proceedings of the Annual Symposium on Network and Distributed System Security (NDSS)", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "Empirical assessment of machine learning-based malware detectors for Android.", "author": ["Allix", "Kevin"], "venue": "Empirical Software Engineering", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "Semantics-aware Android malware classification using weighted contextual API dependency graphs.", "author": ["Zhang", "Mu"], "venue": "Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security. ACM,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2014}, {"title": "Appcontext: Differentiating malicious and benign mobile app behaviors using context.", "author": ["Yang", "Wei"], "venue": "Proc. of the International Conference on Software Engineering (ICSE)", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2015}, {"title": "Profiling user-trigger dependence for Android malware detection.", "author": ["Elish", "Karim O"], "venue": "Computers & Security", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2015}, {"title": "Droidminer: Automated mining and characterization of fine-grained malicious behaviors in android applications.", "author": ["Yang", "Chao"], "venue": "Security-ESORICS", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2014}, {"title": "Structural detection of android malware using embedded call graphs.", "author": ["Gascon", "Hugo"], "venue": "Proceedings of the 2013 ACM workshop on Artificial intelligence and security. ACM,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2013}, {"title": "MAMADROID: Detecting Android Malware by Building Markov Chains of Behavioral Models.", "author": ["Mariconti", "Enrico"], "venue": "arXiv preprint arXiv:1612.04433", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2016}, {"title": "Finding unknown malice in 10 seconds: Mass vetting for new threats at the google-play scale.", "author": ["Chen", "Kai"], "venue": "24th USENIX Security Symposium (USENIX Security", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2015}, {"title": "A machine learning approach to android malware detection.", "author": ["Sahs", "Justin", "Latifur Khan"], "venue": "Intelligence and Security Informatics Conference (EISIC), 2012 European", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2012}, {"title": "Mast: triage for market-scale mobile malware analysis.", "author": ["Chakradeo", "Saurabh"], "venue": "Proceedings of the sixth ACM conference on Security and privacy in wireless and mobile networks. ACM,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2013}, {"title": "Madam: Effective and efficient behavior-based android malware detection and prevention.", "author": ["Saracino", "Andrea"], "venue": "IEEE Transactions on Dependable and Secure Computing", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2016}, {"title": "DroidAPIMiner: Mining API-level features for robust malware detection in android.", "author": ["Aafer", "Yousra"], "venue": "International Conference on Security and Privacy in Communication Systems. Springer International Publishing,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2013}, {"title": "Machine learning for android malware detection using permission and api calls.", "author": ["Peiravian", "Naser", "Xingquan Zhu"], "venue": "IEEE 25th International Conference on Tools with Artificial Intelligence", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2013}, {"title": "Checking app behavior against app descriptions.", "author": ["Gorla", "Alessandra"], "venue": "Proceedings of the 36th International Conference on Software Engineering", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2014}, {"title": "HADM: Hybrid Analysis for Detection of Malware.", "author": ["Xu", "Lifan"], "venue": "SAI Intelligent Systems Conference (IntelliSys) \u2013 London,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2016}, {"title": "DroidScribe: Classifying Android Malware Based on Runtime Behavior.", "author": ["Dash", "Santanu Kumar"], "venue": "Mobile Security Technologies (MoST", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2016}, {"title": "DroidSieve: Fast and Accurate Classification of Obfuscated Android Malware.", "author": ["Suarez-Tangil", "Guillermo"], "venue": null, "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2016}, {"title": "Prescience: Probabilistic Guidance on the Retraining Conundrum for Malware Detection", "author": ["Deo", "Amit"], "venue": "Proceedings of the 2016 ACM workshop on Artificial intelligence and security", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2016}, {"title": "Flowdroid: Precise context, flow, field, object-sensitive and lifecycle-aware taint analysis for android apps.", "author": ["Arzt", "Steven"], "venue": "Acm Sigplan Notices", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2014}, {"title": "Iccta: Detecting inter-component privacy leaks in android apps.", "author": ["Li"], "venue": "Proceedings of the 37th International Conference on Software Engineering-Volume", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2015}, {"title": "Information Flow Analysis of Android Applications in DroidSafe.", "author": ["Gordon", "Michael I"], "venue": "NDSS", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2015}, {"title": "Composite constant propagation: Application to android inter-component communication analysis.", "author": ["Octeau", "Damien"], "venue": "Proceedings of the 37th International Conference on Software Engineering-Volume", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2015}, {"title": "Mining apps for abnormal usage of sensitive data.", "author": ["Avdiienko", "Vitalii"], "venue": "Software Engineering (ICSE),", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2015}, {"title": "Obfuscation-resilient, efficient, and accurate detection and family identification of android malware.", "author": ["Garcia", "Joshua"], "venue": null, "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2015}, {"title": "Crowdroid: behavior-based malware detection system for android.", "author": ["Burguera", "Iker"], "venue": "Proceedings of the 1st ACM workshop on Security and privacy in smartphones and mobile devices. ACM,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2011}, {"title": "Synthesizing near-optimal malware specifications from suspicious behaviors.", "author": ["Fredrikson", "Matt"], "venue": "Security and Privacy (SP),", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2010}, {"title": "Tracking concept drift in malware families.", "author": ["Singh", "Anshuman"], "venue": "Proceedings of the 5th ACM workshop on Security and artificial intelligence. ACM,", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2012}, {"title": "Approaches to adversarial drift.", "author": ["Kantchelian", "Alex"], "venue": "Proceedings of the 2013 ACM workshop on Artificial intelligence and security. ACM,", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2013}, {"title": "Identifying suspicious URLs: an application of large-scale online learning.", "author": ["Ma", "Justin"], "venue": "Proceedings of the 26th Annual International Conference on Machine Learning", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2009}, {"title": "Dissecting android malware: Characterization and evolution.", "author": ["Zhou", "Yajin", "Xuxian Jiang"], "venue": "Security and Privacy (SP),", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2012}, {"title": "Experimental study with real-world data for android app security analysis using machine learning.", "author": ["Roy", "Sankardas"], "venue": "Proceedings of the 31st Annual Computer Security Applications Conference. ACM,", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2015}, {"title": "Androzoo: Collecting millions of android apps for the research community.", "author": ["Allix", "Kevin"], "venue": "Proceedings of the 13th International Conference on Mining Software Repositories", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2016}, {"title": "Understanding Android App Piggybacking: A Systematic Study of Malicious Code Grafting.", "author": ["Li"], "venue": "IEEE Transactions on Information Forensics and Security", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2017}, {"title": "Automatically Locating Malicious Packages in Piggybacked Android Apps.", "author": ["Li"], "venue": "Proceedings of the International Workshop on Mobile Software Engineering and Systems", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2017}, {"title": "Analysis of Code Heterogeneity for High-Precision Classification of Repackaged Malware.", "author": ["Tian", "Ke"], "venue": "Security and Privacy Workshops (SPW),", "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2016}, {"title": "A Unifying View of Explicit and Implicit Feature Maps for Structured Data: Systematic Studies of Graph Kernels.", "author": ["Kriege", "Nils M"], "venue": null, "citeRegEx": "58", "shortCiteRegEx": "58", "year": 2017}, {"title": "On graph kernels: Hardness results and efficient alternatives.", "author": ["G\u00e4rtner", "Thomas"], "venue": "Learning Theory and Kernel Machines. Springer Berlin Heidelberg,", "citeRegEx": "59", "shortCiteRegEx": "59", "year": 2003}, {"title": "Shortest-path kernels on graphs.", "author": ["Borgwardt", "Karsten M", "Hans-Peter Kriegel"], "venue": "Fifth IEEE International Conference on Data Mining (ICDM\u201905)", "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2005}, {"title": "Efficient graphlet kernels for large graph comparison.", "author": ["Shervashidze", "Nino"], "venue": "AISTATS. Vol", "citeRegEx": "61", "shortCiteRegEx": "61", "year": 2009}, {"title": "Weisfeiler-lehman graph kernels.", "author": ["Shervashidze", "Nino"], "venue": "The Journal of Machine Learning Research", "citeRegEx": "62", "shortCiteRegEx": "62", "year": 2011}, {"title": "A linear-time graph kernel.", "author": ["Hido", "Shohei", "Hisashi Kashima"], "venue": "Data Mining,", "citeRegEx": "63", "shortCiteRegEx": "63", "year": 2009}, {"title": "Deep graph kernels.", "author": ["P. Yanardag", "S. Vishwanathan"], "venue": "In Proc. of SIGKDD,", "citeRegEx": "64", "shortCiteRegEx": "64", "year": 2015}, {"title": "subgraph2vec: Learning distributed representations of rooted sub-graphs from large graphs.", "author": ["Narayanan", "Annamalai"], "venue": "In Workshop on Mining and Learning with Graphs,", "citeRegEx": "65", "shortCiteRegEx": "65", "year": 2016}, {"title": "Why Should I Trust You?\u201d: Explaining the Predictions of Any Classifier", "author": ["Ribeiro", "M. T"], "venue": "In Proc. of SIGKDD,", "citeRegEx": "66", "shortCiteRegEx": "66", "year": 2016}, {"title": "Poisoning behavioral malware clustering.", "author": ["Biggio", "Battista"], "venue": "Proceedings of the 2014 Workshop on Artificial Intelligent and Security Workshop", "citeRegEx": "67", "shortCiteRegEx": "67", "year": 2014}, {"title": "Multiple kernel learning algorithms.", "author": ["G\u00f6nen", "Mehmet", "Ethem Alpayd\u0131n"], "venue": "Journal of Machine Learning Research", "citeRegEx": "68", "shortCiteRegEx": "68", "year": 2011}, {"title": "Multiple kernel learning and the SMO algorithm. In Advances in neural information processing systems (pp. 2361-2369)", "author": ["Z. Sun", "N. Ampornpunt", "M. Varma", "S. Vishwanathan"], "venue": null, "citeRegEx": "69", "shortCiteRegEx": "69", "year": 2010}, {"title": "Online multiple kernel classification.", "author": ["Hoi", "Steven CH"], "venue": "Machine Learning", "citeRegEx": "70", "shortCiteRegEx": "70", "year": 2013}, {"title": "An extensive empirical study of feature selection metrics for text classification.", "author": ["Forman", "George"], "venue": "Journal of machine learning research", "citeRegEx": "71", "shortCiteRegEx": "71", "year": 2003}, {"title": "A tutorial on support vector machines for pattern recognition.\u201d Data mining and knowledge discovery", "author": ["Burges", "Christopher JC"], "venue": null, "citeRegEx": "72", "shortCiteRegEx": "72", "year": 1998}, {"title": "Mystique: Evolving Android Malware for Auditing Anti-Malware Tools.", "author": ["Meng", "Guozhu"], "venue": "Proceedings of the 11th ACM on Asia Conference on Computer and Communications Security", "citeRegEx": "73", "shortCiteRegEx": "73", "year": 2016}, {"title": "Parallelization of Machine Learning Applied to Call Graphs of Binaries for Malware Detection.", "author": ["Searles", "Robert"], "venue": "Proceedings of the 25th Euromicro International Conference on Parallel, Distributed and Network-Based Processing,", "citeRegEx": "75", "shortCiteRegEx": "75", "year": 2017}], "referenceMentions": [{"referenceID": 16, "context": "Many empirical studies [30, 55\u201357] manifest that an overwhelming majority of Android malware are nothing but repackaged versions", "startOffset": 23, "endOffset": 34}, {"referenceID": 41, "context": "Many empirical studies [30, 55\u201357] manifest that an overwhelming majority of Android malware are nothing but repackaged versions", "startOffset": 23, "endOffset": 34}, {"referenceID": 42, "context": "Many empirical studies [30, 55\u201357] manifest that an overwhelming majority of Android malware are nothing but repackaged versions", "startOffset": 23, "endOffset": 34}, {"referenceID": 43, "context": "Many empirical studies [30, 55\u201357] manifest that an overwhelming majority of Android malware are nothing but repackaged versions", "startOffset": 23, "endOffset": 34}, {"referenceID": 41, "context": "The sheer volume, growth rate and evolution of repackaged and other types of malware highlight an imperative need for developing effective and scalable automated malware detection techniques [55\u201357].", "startOffset": 191, "endOffset": 198}, {"referenceID": 42, "context": "The sheer volume, growth rate and evolution of repackaged and other types of malware highlight an imperative need for developing effective and scalable automated malware detection techniques [55\u201357].", "startOffset": 191, "endOffset": 198}, {"referenceID": 43, "context": "The sheer volume, growth rate and evolution of repackaged and other types of malware highlight an imperative need for developing effective and scalable automated malware detection techniques [55\u201357].", "startOffset": 191, "endOffset": 198}, {"referenceID": 8, "context": ") and identifying malicious code/behaviour patterns using ML classifiers [22\u201325, 27, 28, 31, 38, 39].", "startOffset": 73, "endOffset": 100}, {"referenceID": 9, "context": ") and identifying malicious code/behaviour patterns using ML classifiers [22\u201325, 27, 28, 31, 38, 39].", "startOffset": 73, "endOffset": 100}, {"referenceID": 10, "context": ") and identifying malicious code/behaviour patterns using ML classifiers [22\u201325, 27, 28, 31, 38, 39].", "startOffset": 73, "endOffset": 100}, {"referenceID": 11, "context": ") and identifying malicious code/behaviour patterns using ML classifiers [22\u201325, 27, 28, 31, 38, 39].", "startOffset": 73, "endOffset": 100}, {"referenceID": 13, "context": ") and identifying malicious code/behaviour patterns using ML classifiers [22\u201325, 27, 28, 31, 38, 39].", "startOffset": 73, "endOffset": 100}, {"referenceID": 14, "context": ") and identifying malicious code/behaviour patterns using ML classifiers [22\u201325, 27, 28, 31, 38, 39].", "startOffset": 73, "endOffset": 100}, {"referenceID": 17, "context": ") and identifying malicious code/behaviour patterns using ML classifiers [22\u201325, 27, 28, 31, 38, 39].", "startOffset": 73, "endOffset": 100}, {"referenceID": 24, "context": ") and identifying malicious code/behaviour patterns using ML classifiers [22\u201325, 27, 28, 31, 38, 39].", "startOffset": 73, "endOffset": 100}, {"referenceID": 25, "context": ") and identifying malicious code/behaviour patterns using ML classifiers [22\u201325, 27, 28, 31, 38, 39].", "startOffset": 73, "endOffset": 100}, {"referenceID": 9, "context": "Notably, higher level semantic representations such as CGs, control- and data-flow graphs mostly stay similar even when the code is considerably altered [23, 24, 27, 28, 31] (we use a common term \u2019Program Representation Graph\u2019 (PRG) to refer to any of the aforementioned graphs).", "startOffset": 153, "endOffset": 173}, {"referenceID": 10, "context": "Notably, higher level semantic representations such as CGs, control- and data-flow graphs mostly stay similar even when the code is considerably altered [23, 24, 27, 28, 31] (we use a common term \u2019Program Representation Graph\u2019 (PRG) to refer to any of the aforementioned graphs).", "startOffset": 153, "endOffset": 173}, {"referenceID": 13, "context": "Notably, higher level semantic representations such as CGs, control- and data-flow graphs mostly stay similar even when the code is considerably altered [23, 24, 27, 28, 31] (we use a common term \u2019Program Representation Graph\u2019 (PRG) to refer to any of the aforementioned graphs).", "startOffset": 153, "endOffset": 173}, {"referenceID": 14, "context": "Notably, higher level semantic representations such as CGs, control- and data-flow graphs mostly stay similar even when the code is considerably altered [23, 24, 27, 28, 31] (we use a common term \u2019Program Representation Graph\u2019 (PRG) to refer to any of the aforementioned graphs).", "startOffset": 153, "endOffset": 173}, {"referenceID": 17, "context": "Notably, higher level semantic representations such as CGs, control- and data-flow graphs mostly stay similar even when the code is considerably altered [23, 24, 27, 28, 31] (we use a common term \u2019Program Representation Graph\u2019 (PRG) to refer to any of the aforementioned graphs).", "startOffset": 153, "endOffset": 173}, {"referenceID": 7, "context": "In essence, such works cast malware detection as a graph classification problem and apply existing graph mining and classification techniques [21, 24, 25, 28, 37, 74].", "startOffset": 142, "endOffset": 166}, {"referenceID": 10, "context": "In essence, such works cast malware detection as a graph classification problem and apply existing graph mining and classification techniques [21, 24, 25, 28, 37, 74].", "startOffset": 142, "endOffset": 166}, {"referenceID": 11, "context": "In essence, such works cast malware detection as a graph classification problem and apply existing graph mining and classification techniques [21, 24, 25, 28, 37, 74].", "startOffset": 142, "endOffset": 166}, {"referenceID": 14, "context": "In essence, such works cast malware detection as a graph classification problem and apply existing graph mining and classification techniques [21, 24, 25, 28, 37, 74].", "startOffset": 142, "endOffset": 166}, {"referenceID": 23, "context": "In essence, such works cast malware detection as a graph classification problem and apply existing graph mining and classification techniques [21, 24, 25, 28, 37, 74].", "startOffset": 142, "endOffset": 166}, {"referenceID": 10, "context": "Prominent robust approaches from literature have used a variety of features such as API sequences [24, 25, 27], permissions used [22, 34], information flows observed [45], instruction sequences used [28] and Control Flow Graph (CFG) patterns [18, 23] to learn discriminatory functions that could differentiate malware and benign apps.", "startOffset": 98, "endOffset": 110}, {"referenceID": 11, "context": "Prominent robust approaches from literature have used a variety of features such as API sequences [24, 25, 27], permissions used [22, 34], information flows observed [45], instruction sequences used [28] and Control Flow Graph (CFG) patterns [18, 23] to learn discriminatory functions that could differentiate malware and benign apps.", "startOffset": 98, "endOffset": 110}, {"referenceID": 13, "context": "Prominent robust approaches from literature have used a variety of features such as API sequences [24, 25, 27], permissions used [22, 34], information flows observed [45], instruction sequences used [28] and Control Flow Graph (CFG) patterns [18, 23] to learn discriminatory functions that could differentiate malware and benign apps.", "startOffset": 98, "endOffset": 110}, {"referenceID": 8, "context": "Prominent robust approaches from literature have used a variety of features such as API sequences [24, 25, 27], permissions used [22, 34], information flows observed [45], instruction sequences used [28] and Control Flow Graph (CFG) patterns [18, 23] to learn discriminatory functions that could differentiate malware and benign apps.", "startOffset": 129, "endOffset": 137}, {"referenceID": 20, "context": "Prominent robust approaches from literature have used a variety of features such as API sequences [24, 25, 27], permissions used [22, 34], information flows observed [45], instruction sequences used [28] and Control Flow Graph (CFG) patterns [18, 23] to learn discriminatory functions that could differentiate malware and benign apps.", "startOffset": 129, "endOffset": 137}, {"referenceID": 31, "context": "Prominent robust approaches from literature have used a variety of features such as API sequences [24, 25, 27], permissions used [22, 34], information flows observed [45], instruction sequences used [28] and Control Flow Graph (CFG) patterns [18, 23] to learn discriminatory functions that could differentiate malware and benign apps.", "startOffset": 166, "endOffset": 170}, {"referenceID": 14, "context": "Prominent robust approaches from literature have used a variety of features such as API sequences [24, 25, 27], permissions used [22, 34], information flows observed [45], instruction sequences used [28] and Control Flow Graph (CFG) patterns [18, 23] to learn discriminatory functions that could differentiate malware and benign apps.", "startOffset": 199, "endOffset": 203}, {"referenceID": 4, "context": "Prominent robust approaches from literature have used a variety of features such as API sequences [24, 25, 27], permissions used [22, 34], information flows observed [45], instruction sequences used [28] and Control Flow Graph (CFG) patterns [18, 23] to learn discriminatory functions that could differentiate malware and benign apps.", "startOffset": 242, "endOffset": 250}, {"referenceID": 9, "context": "Prominent robust approaches from literature have used a variety of features such as API sequences [24, 25, 27], permissions used [22, 34], information flows observed [45], instruction sequences used [28] and Control Flow Graph (CFG) patterns [18, 23] to learn discriminatory functions that could differentiate malware and benign apps.", "startOffset": 242, "endOffset": 250}, {"referenceID": 34, "context": "Representing them as vectors or other formats amenable for applying ML algorithms is a non-trivial task [48].", "startOffset": 104, "endOffset": 108}, {"referenceID": 6, "context": "In many cases, such representations fail to capture all the vital information from PRGs, thus losing their expressiveness, resulting in suboptimal detection rates [20, 28, 37, 74].", "startOffset": 163, "endOffset": 179}, {"referenceID": 14, "context": "In many cases, such representations fail to capture all the vital information from PRGs, thus losing their expressiveness, resulting in suboptimal detection rates [20, 28, 37, 74].", "startOffset": 163, "endOffset": 179}, {"referenceID": 23, "context": "In many cases, such representations fail to capture all the vital information from PRGs, thus losing their expressiveness, resulting in suboptimal detection rates [20, 28, 37, 74].", "startOffset": 163, "endOffset": 179}, {"referenceID": 34, "context": ", [48]) are NP hard and have severe scalability issues, making them impractical for malware detection in the wild [30, 75].", "startOffset": 2, "endOffset": 6}, {"referenceID": 16, "context": ", [48]) are NP hard and have severe scalability issues, making them impractical for malware detection in the wild [30, 75].", "startOffset": 114, "endOffset": 122}, {"referenceID": 60, "context": ", [48]) are NP hard and have severe scalability issues, making them impractical for malware detection in the wild [30, 75].", "startOffset": 114, "endOffset": 122}, {"referenceID": 4, "context": "In general, almost all the ML based approaches act as holistic black-box solutions as they just predict whether or not a given app (as a whole) is malicious (examples: [18, 22\u201325, 27\u201329, 31, 36\u201338, 40, 45\u201347]).", "startOffset": 168, "endOffset": 208}, {"referenceID": 8, "context": "In general, almost all the ML based approaches act as holistic black-box solutions as they just predict whether or not a given app (as a whole) is malicious (examples: [18, 22\u201325, 27\u201329, 31, 36\u201338, 40, 45\u201347]).", "startOffset": 168, "endOffset": 208}, {"referenceID": 9, "context": "In general, almost all the ML based approaches act as holistic black-box solutions as they just predict whether or not a given app (as a whole) is malicious (examples: [18, 22\u201325, 27\u201329, 31, 36\u201338, 40, 45\u201347]).", "startOffset": 168, "endOffset": 208}, {"referenceID": 10, "context": "In general, almost all the ML based approaches act as holistic black-box solutions as they just predict whether or not a given app (as a whole) is malicious (examples: [18, 22\u201325, 27\u201329, 31, 36\u201338, 40, 45\u201347]).", "startOffset": 168, "endOffset": 208}, {"referenceID": 11, "context": "In general, almost all the ML based approaches act as holistic black-box solutions as they just predict whether or not a given app (as a whole) is malicious (examples: [18, 22\u201325, 27\u201329, 31, 36\u201338, 40, 45\u201347]).", "startOffset": 168, "endOffset": 208}, {"referenceID": 13, "context": "In general, almost all the ML based approaches act as holistic black-box solutions as they just predict whether or not a given app (as a whole) is malicious (examples: [18, 22\u201325, 27\u201329, 31, 36\u201338, 40, 45\u201347]).", "startOffset": 168, "endOffset": 208}, {"referenceID": 14, "context": "In general, almost all the ML based approaches act as holistic black-box solutions as they just predict whether or not a given app (as a whole) is malicious (examples: [18, 22\u201325, 27\u201329, 31, 36\u201338, 40, 45\u201347]).", "startOffset": 168, "endOffset": 208}, {"referenceID": 15, "context": "In general, almost all the ML based approaches act as holistic black-box solutions as they just predict whether or not a given app (as a whole) is malicious (examples: [18, 22\u201325, 27\u201329, 31, 36\u201338, 40, 45\u201347]).", "startOffset": 168, "endOffset": 208}, {"referenceID": 17, "context": "In general, almost all the ML based approaches act as holistic black-box solutions as they just predict whether or not a given app (as a whole) is malicious (examples: [18, 22\u201325, 27\u201329, 31, 36\u201338, 40, 45\u201347]).", "startOffset": 168, "endOffset": 208}, {"referenceID": 22, "context": "In general, almost all the ML based approaches act as holistic black-box solutions as they just predict whether or not a given app (as a whole) is malicious (examples: [18, 22\u201325, 27\u201329, 31, 36\u201338, 40, 45\u201347]).", "startOffset": 168, "endOffset": 208}, {"referenceID": 23, "context": "In general, almost all the ML based approaches act as holistic black-box solutions as they just predict whether or not a given app (as a whole) is malicious (examples: [18, 22\u201325, 27\u201329, 31, 36\u201338, 40, 45\u201347]).", "startOffset": 168, "endOffset": 208}, {"referenceID": 24, "context": "In general, almost all the ML based approaches act as holistic black-box solutions as they just predict whether or not a given app (as a whole) is malicious (examples: [18, 22\u201325, 27\u201329, 31, 36\u201338, 40, 45\u201347]).", "startOffset": 168, "endOffset": 208}, {"referenceID": 26, "context": "In general, almost all the ML based approaches act as holistic black-box solutions as they just predict whether or not a given app (as a whole) is malicious (examples: [18, 22\u201325, 27\u201329, 31, 36\u201338, 40, 45\u201347]).", "startOffset": 168, "endOffset": 208}, {"referenceID": 31, "context": "In general, almost all the ML based approaches act as holistic black-box solutions as they just predict whether or not a given app (as a whole) is malicious (examples: [18, 22\u201325, 27\u201329, 31, 36\u201338, 40, 45\u201347]).", "startOffset": 168, "endOffset": 208}, {"referenceID": 32, "context": "In general, almost all the ML based approaches act as holistic black-box solutions as they just predict whether or not a given app (as a whole) is malicious (examples: [18, 22\u201325, 27\u201329, 31, 36\u201338, 40, 45\u201347]).", "startOffset": 168, "endOffset": 208}, {"referenceID": 33, "context": "In general, almost all the ML based approaches act as holistic black-box solutions as they just predict whether or not a given app (as a whole) is malicious (examples: [18, 22\u201325, 27\u201329, 31, 36\u201338, 40, 45\u201347]).", "startOffset": 168, "endOffset": 208}, {"referenceID": 6, "context": "To address C1, we leverage on our previous work [20] and use the Contextual Weisfeiler-Lehman Kernel (CWLK) that is specifically designed to perform accurate malware detection by capturing both structural and contextual information from PRGs.", "startOffset": 48, "endOffset": 52}, {"referenceID": 54, "context": "To address C3, we resort to Multiple Kernel Learning (MKL) [68], a well-known principled approach to integrate multiple feature sets with different modalities.", "startOffset": 59, "endOffset": 63}, {"referenceID": 55, "context": ", CWLK) and an efficient MKL approach, namely, Sequential Minimal Optimization (SMO) MKL [69].", "startOffset": 89, "endOffset": 93}, {"referenceID": 6, "context": "\u2013 We leverage on CWLK, a graph kernel we proposed in our previous work [20] that is specially designed to perform malware detection by capturing both structural and contextual information from PRGs.", "startOffset": 71, "endOffset": 75}, {"referenceID": 8, "context": "Mscores for all basic blocks, methods and classes from apps in the benchmark datasets, Drebin [22] and Mystique [73] are made available at: [13].", "startOffset": 94, "endOffset": 98}, {"referenceID": 59, "context": "Mscores for all basic blocks, methods and classes from apps in the benchmark datasets, Drebin [22] and Mystique [73] are made available at: [13].", "startOffset": 112, "endOffset": 116}, {"referenceID": 45, "context": "Several graph kernels have been proposed based on this idea [59, 60, 62, 63].", "startOffset": 60, "endOffset": 76}, {"referenceID": 46, "context": "Several graph kernels have been proposed based on this idea [59, 60, 62, 63].", "startOffset": 60, "endOffset": 76}, {"referenceID": 48, "context": "Several graph kernels have been proposed based on this idea [59, 60, 62, 63].", "startOffset": 60, "endOffset": 76}, {"referenceID": 49, "context": "Several graph kernels have been proposed based on this idea [59, 60, 62, 63].", "startOffset": 60, "endOffset": 76}, {"referenceID": 44, "context": ", \u03c6 is not necessarily known and may be of infinite dimension) [58].", "startOffset": 63, "endOffset": 67}, {"referenceID": 48, "context": "Examples of former category include Weisfeiler-Lehman Kernel (WLK) [62], Neighborhood Hashing Graph Kernel (NHGK) [63] and CWLK, and that of latter category are Random Walk (RW) [59] and Shortest Path (SP) [60] kernels.", "startOffset": 67, "endOffset": 71}, {"referenceID": 49, "context": "Examples of former category include Weisfeiler-Lehman Kernel (WLK) [62], Neighborhood Hashing Graph Kernel (NHGK) [63] and CWLK, and that of latter category are Random Walk (RW) [59] and Shortest Path (SP) [60] kernels.", "startOffset": 114, "endOffset": 118}, {"referenceID": 45, "context": "Examples of former category include Weisfeiler-Lehman Kernel (WLK) [62], Neighborhood Hashing Graph Kernel (NHGK) [63] and CWLK, and that of latter category are Random Walk (RW) [59] and Shortest Path (SP) [60] kernels.", "startOffset": 178, "endOffset": 182}, {"referenceID": 46, "context": "Examples of former category include Weisfeiler-Lehman Kernel (WLK) [62], Neighborhood Hashing Graph Kernel (NHGK) [63] and CWLK, and that of latter category are Random Walk (RW) [59] and Shortest Path (SP) [60] kernels.", "startOffset": 206, "endOffset": 210}, {"referenceID": 44, "context": "If explicit representations are manageable, these approaches usually outperform other kernels regarding runtime on large datasets, since the number of vector representations scales linear with the dataset size [58, 62].", "startOffset": 210, "endOffset": 218}, {"referenceID": 48, "context": "If explicit representations are manageable, these approaches usually outperform other kernels regarding runtime on large datasets, since the number of vector representations scales linear with the dataset size [58, 62].", "startOffset": 210, "endOffset": 218}, {"referenceID": 48, "context": "This facilitates building explicit feature vector representation of individual graphs [62, 64].", "startOffset": 86, "endOffset": 94}, {"referenceID": 50, "context": "This facilitates building explicit feature vector representation of individual graphs [62, 64].", "startOffset": 86, "endOffset": 94}, {"referenceID": 44, "context": "This aspect makes this category of kernels amenable for performing explainable malware detection [58].", "startOffset": 97, "endOffset": 101}, {"referenceID": 11, "context": "As explained in [25] and [24], one could determine whether a PRG node is reachable under user-aware or user-unaware context by examining its entry point nodes.", "startOffset": 16, "endOffset": 20}, {"referenceID": 10, "context": "As explained in [25] and [24], one could determine whether a PRG node is reachable under user-aware or user-unaware context by examining its entry point nodes.", "startOffset": 25, "endOffset": 29}, {"referenceID": 6, "context": "To the best of our knowledge, the only graph kernel that addresses our two-fold requirement is CWLK [20].", "startOffset": 100, "endOffset": 104}, {"referenceID": 3, "context": "A control-flow analysis encoding grammar proposed by Cesare and Xiang in [17] is used to infer these textual signatures.", "startOffset": 73, "endOffset": 77}, {"referenceID": 31, "context": "Also, CSSDG may not capture common malicious behaviours such as gaining root access or installing additional apps as they do not involve sources or sinks [45].", "startOffset": 154, "endOffset": 158}, {"referenceID": 3, "context": "This helps to model unusual control flow jumps, heavy usage of junk/unwanted instructions and complex loops which are predominant in malware [17, 23].", "startOffset": 141, "endOffset": 149}, {"referenceID": 9, "context": "This helps to model unusual control flow jumps, heavy usage of junk/unwanted instructions and complex loops which are predominant in malware [17, 23].", "startOffset": 141, "endOffset": 149}, {"referenceID": 6, "context": "Hence, after these PRGs are constructed, those subgraphs which represent security-sensitive events that happen in an app along with their context(s) are extracted as using CWLK [20].", "startOffset": 177, "endOffset": 181}, {"referenceID": 54, "context": "MKL [68], provides a principled way to facilitate learning from this multi-view, multi-granular and multi-modal data.", "startOffset": 4, "endOffset": 8}, {"referenceID": 55, "context": "Therefore, we use SMO-MKL [69], a well-known MKL algorithm, to combine representations from all these PRGs and train an SVM to perform malware detection.", "startOffset": 26, "endOffset": 30}, {"referenceID": 10, "context": "Several works such as DroidSIFT [24], AppContext [25] and Elish et al.", "startOffset": 32, "endOffset": 36}, {"referenceID": 11, "context": "Several works such as DroidSIFT [24], AppContext [25] and Elish et al.", "startOffset": 49, "endOffset": 53}, {"referenceID": 12, "context": "[26] have proposed techniques to identify whether a PRG node is reached under the user-aware or -unaware context by analyzing their entry-points (i.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "We follow the approach mentioned in DroidSIFT [24].", "startOffset": 46, "endOffset": 50}, {"referenceID": 14, "context": "Recently, studies such as Adagio [28] demonstrated that structural information from PRGs labeled with Dalvik instruction categories (e.", "startOffset": 33, "endOffset": 37}, {"referenceID": 9, "context": "[23] proposed an approach which leverages on control-flow structural information.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "They represent the structure of basic blocks in every method as textual signatures 2Two existing works, PScout [15] and SUSI [16] list commonly known security-sensitive Android APIs.", "startOffset": 111, "endOffset": 115}, {"referenceID": 2, "context": "They represent the structure of basic blocks in every method as textual signatures 2Two existing works, PScout [15] and SUSI [16] list commonly known security-sensitive Android APIs.", "startOffset": 125, "endOffset": 129}, {"referenceID": 1, "context": "4PScout [15] provides a mapping from Android APIs and URIs to permissions required to access them.", "startOffset": 8, "endOffset": 12}, {"referenceID": 2, "context": "5To identify information sources and sinks accessed in CICFG nodes, we leverage on SUSI [16] and MUDFLOW [45].", "startOffset": 88, "endOffset": 92}, {"referenceID": 31, "context": "5To identify information sources and sinks accessed in CICFG nodes, we leverage on SUSI [16] and MUDFLOW [45].", "startOffset": 105, "endOffset": 109}, {"referenceID": 14, "context": "6To determine the categories of Dalvik instructions to be used as CICFGins node labels, we refer to Adagio [28].", "startOffset": 107, "endOffset": 111}, {"referenceID": 4, "context": "Also, this helps to model unusual control flow structure such as jumps, heavy usage of junk/unwanted instructions and complex loops which are tell-tale signs of malware [8, 18, 23, 28].", "startOffset": 169, "endOffset": 184}, {"referenceID": 9, "context": "Also, this helps to model unusual control flow structure such as jumps, heavy usage of junk/unwanted instructions and complex loops which are tell-tale signs of malware [8, 18, 23, 28].", "startOffset": 169, "endOffset": 184}, {"referenceID": 14, "context": "Also, this helps to model unusual control flow structure such as jumps, heavy usage of junk/unwanted instructions and complex loops which are tell-tale signs of malware [8, 18, 23, 28].", "startOffset": 169, "endOffset": 184}, {"referenceID": 3, "context": "The function `s : N \u2192 \u03bbs labels every node n \u2208 Ni with the control-flow signatures arrived at using Cesare and Xiang\u2019s grammar [17].", "startOffset": 127, "endOffset": 131}, {"referenceID": 6, "context": "CWLK, a graph kernel developed in our previous work [20] is specifically designed to cater effective malware detection by capturing both structural and contextual information from PRGs.", "startOffset": 52, "endOffset": 56}, {"referenceID": 48, "context": "CWLK computes the similarities between a given pair of PRGs G = (N,E, \u03bb, \u03be) and G\u2032 = (N \u2032, E\u2032, \u03bb, \u03be) based on the 1-dimensional WL test of graph isomorphism [62].", "startOffset": 157, "endOffset": 161}, {"referenceID": 3, "context": "[10] leveraged on a grammar proposed by Cesare and Xiang [17] to represent CFG textual signatures in their work on establishing similarity between Android apps.", "startOffset": 57, "endOffset": 61}, {"referenceID": 6, "context": "For more information on derivation of CWLK\u2019s time complexity and proof of positive semi-definiteness, we refer the reader to the original work [20].", "startOffset": 143, "endOffset": 147}, {"referenceID": 57, "context": "Hence, to mitigate this, we perform feature selection over the CICFGins and CICFGsigns embeddings using the chi-squared feature selection algorithm [71] and then compute their respective kernel matrices.", "startOffset": 148, "endOffset": 152}, {"referenceID": 58, "context": "Given a kernel matrix over the training samples, the goal of classical kernel-based learning with SVMs is to learn the vector, \u03b1, describing each sample x\u2019s contribution to the hyperplane that separates the points of the two classes (aka decision boundary) with a maximal margin [72] and can be found with the following optimization problem:", "startOffset": 279, "endOffset": 283}, {"referenceID": 54, "context": "is a linear combination of all the kernels v \u2208 V with \u03b2v \u2265 0, where each kernel, kv, uses a distinct set of features emanating from different views of apps [68].", "startOffset": 156, "endOffset": 160}, {"referenceID": 55, "context": "To solve for kernel weights (\u03b2), and support vectors (\u03b1), simultaneously, we use the SMO based MKL algorithm proposed in [69].", "startOffset": 121, "endOffset": 125}, {"referenceID": 55, "context": "[69].", "startOffset": 0, "endOffset": 4}, {"referenceID": 55, "context": "Solving for \u03b2 and \u03b1 with as many as 50,000 samples and 300,000 kernels has been shown to take just over 30 minutes on many applications from different domains such as Computer Vision and Bioinformatics [69].", "startOffset": 202, "endOffset": 206}, {"referenceID": 8, "context": "On the contrary, interpreting the predictions in primal formulation is a well-studied problem as discussed in [22, 28, 66].", "startOffset": 110, "endOffset": 122}, {"referenceID": 14, "context": "On the contrary, interpreting the predictions in primal formulation is a well-studied problem as discussed in [22, 28, 66].", "startOffset": 110, "endOffset": 122}, {"referenceID": 52, "context": "On the contrary, interpreting the predictions in primal formulation is a well-studied problem as discussed in [22, 28, 66].", "startOffset": 110, "endOffset": 122}, {"referenceID": 8, "context": "Malware Datasets Drebin (DR) [22] 5,560 Aug\u201910 - Oct\u201912 Virus-share (VS) [9] 24,317 May\u201913 - Mar\u201914", "startOffset": 29, "endOffset": 33}, {"referenceID": 59, "context": "Aug\u201913 - Sep\u201916 AnZhi (AZ) [4] 3,027 AppsApk (AA) [5] 2,481 FDroid (FD) [6] 1,007 SlideMe (SM) [7] 5,770 Dataset annotated with locations of malice code Mystique (MYST) [73] 3,000 Dec\u201915", "startOffset": 169, "endOffset": 173}, {"referenceID": 8, "context": ", splitting the malware and benign samples randomly into training and test-sets and performing evaluation) is followed in almost all the previous malware detection methods such as [22, 25, 28, 45].", "startOffset": 180, "endOffset": 196}, {"referenceID": 11, "context": ", splitting the malware and benign samples randomly into training and test-sets and performing evaluation) is followed in almost all the previous malware detection methods such as [22, 25, 28, 45].", "startOffset": 180, "endOffset": 196}, {"referenceID": 14, "context": ", splitting the malware and benign samples randomly into training and test-sets and performing evaluation) is followed in almost all the previous malware detection methods such as [22, 25, 28, 45].", "startOffset": 180, "endOffset": 196}, {"referenceID": 31, "context": ", splitting the malware and benign samples randomly into training and test-sets and performing evaluation) is followed in almost all the previous malware detection methods such as [22, 25, 28, 45].", "startOffset": 180, "endOffset": 196}, {"referenceID": 9, "context": "However, malware continue to evolve and more sophisticated variants are produced subsequent to publishing such datasets [23, 29].", "startOffset": 120, "endOffset": 128}, {"referenceID": 15, "context": "However, malware continue to evolve and more sophisticated variants are produced subsequent to publishing such datasets [23, 29].", "startOffset": 120, "endOffset": 128}, {"referenceID": 4, "context": "[18], in these experiments, samples in the training set may be historically posterior to those in the test-set.", "startOffset": 0, "endOffset": 4}, {"referenceID": 59, "context": "A common observation is that real-world malware, due to their rapid evolution are more challenging to detect that the ones in the benchmark datasets [73].", "startOffset": 149, "endOffset": 153}, {"referenceID": 8, "context": "To this end, following the software security research practices proposed in [22] and [23], we leveraged on the VirusTotal web portal to infer their ground truth labels.", "startOffset": 76, "endOffset": 80}, {"referenceID": 9, "context": "To this end, following the software security research practices proposed in [22] and [23], we leveraged on the VirusTotal web portal to infer their ground truth labels.", "startOffset": 85, "endOffset": 89}, {"referenceID": 8, "context": "DR [22], VS [55], AndroZoo [54]) provide ground-truth on the location of malice code such as names of methods/classes involving in malice operations.", "startOffset": 3, "endOffset": 7}, {"referenceID": 41, "context": "DR [22], VS [55], AndroZoo [54]) provide ground-truth on the location of malice code such as names of methods/classes involving in malice operations.", "startOffset": 12, "endOffset": 16}, {"referenceID": 40, "context": "DR [22], VS [55], AndroZoo [54]) provide ground-truth on the location of malice code such as names of methods/classes involving in malice operations.", "startOffset": 27, "endOffset": 31}, {"referenceID": 59, "context": "Recently, Mystique [73] proposed an Evolutionary Computation based method to automatically generate new malware samples learning from attack and evasion strategies of benchmark malware.", "startOffset": 19, "endOffset": 23}, {"referenceID": 55, "context": "[69] has been used.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "Our approach is compared against three state-of-theart ML based Android malware detection solutions, namely, Drebin [22], Allix et al.", "startOffset": 116, "endOffset": 120}, {"referenceID": 9, "context": "[23] and Adagio [28].", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[23] and Adagio [28].", "startOffset": 16, "endOffset": 20}, {"referenceID": 41, "context": "[55] provided a dataset of repackaged apps of the form: (app1, app2), where app1 is the original (benign) app and (app2) is the repackaged version of app1.", "startOffset": 0, "endOffset": 4}, {"referenceID": 41, "context": "12More than 80% of samples in this dataset are piggybacked malware thus making this dataset amenable for our qualitative analysis [55].", "startOffset": 130, "endOffset": 134}, {"referenceID": 8, "context": "Drebin [22] is well-known for its scalable and explainable detection.", "startOffset": 7, "endOffset": 11}, {"referenceID": 9, "context": "[23] proposed another scalable approach using signatures of basis blocks in CFGs.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "CSBD constructs CFGs of individual methods and encodes them as text-signatures following Cesare and Xiang\u2019s grammar [17].", "startOffset": 116, "endOffset": 120}, {"referenceID": 14, "context": "Adagio [28] constructs CGs and uses byte-code instructions to assign labels to nodes.", "startOffset": 7, "endOffset": 11}, {"referenceID": 49, "context": "NHGK [63] is used to extract CG neighborhoods as features and a histogram-intersection (HI) kernel SVM is trained to detect malware.", "startOffset": 5, "endOffset": 9}, {"referenceID": 8, "context": "In fact, this observation goes hand-in-hand with the fact that API related features (API frequencies and ngrams [22, 34], API sequences [27], subgraphs [20, 21, 25, 31, 65], dependencies [45, 46], etc.", "startOffset": 112, "endOffset": 120}, {"referenceID": 20, "context": "In fact, this observation goes hand-in-hand with the fact that API related features (API frequencies and ngrams [22, 34], API sequences [27], subgraphs [20, 21, 25, 31, 65], dependencies [45, 46], etc.", "startOffset": 112, "endOffset": 120}, {"referenceID": 13, "context": "In fact, this observation goes hand-in-hand with the fact that API related features (API frequencies and ngrams [22, 34], API sequences [27], subgraphs [20, 21, 25, 31, 65], dependencies [45, 46], etc.", "startOffset": 136, "endOffset": 140}, {"referenceID": 6, "context": "In fact, this observation goes hand-in-hand with the fact that API related features (API frequencies and ngrams [22, 34], API sequences [27], subgraphs [20, 21, 25, 31, 65], dependencies [45, 46], etc.", "startOffset": 152, "endOffset": 172}, {"referenceID": 7, "context": "In fact, this observation goes hand-in-hand with the fact that API related features (API frequencies and ngrams [22, 34], API sequences [27], subgraphs [20, 21, 25, 31, 65], dependencies [45, 46], etc.", "startOffset": 152, "endOffset": 172}, {"referenceID": 11, "context": "In fact, this observation goes hand-in-hand with the fact that API related features (API frequencies and ngrams [22, 34], API sequences [27], subgraphs [20, 21, 25, 31, 65], dependencies [45, 46], etc.", "startOffset": 152, "endOffset": 172}, {"referenceID": 17, "context": "In fact, this observation goes hand-in-hand with the fact that API related features (API frequencies and ngrams [22, 34], API sequences [27], subgraphs [20, 21, 25, 31, 65], dependencies [45, 46], etc.", "startOffset": 152, "endOffset": 172}, {"referenceID": 51, "context": "In fact, this observation goes hand-in-hand with the fact that API related features (API frequencies and ngrams [22, 34], API sequences [27], subgraphs [20, 21, 25, 31, 65], dependencies [45, 46], etc.", "startOffset": 152, "endOffset": 172}, {"referenceID": 31, "context": "In fact, this observation goes hand-in-hand with the fact that API related features (API frequencies and ngrams [22, 34], API sequences [27], subgraphs [20, 21, 25, 31, 65], dependencies [45, 46], etc.", "startOffset": 187, "endOffset": 195}, {"referenceID": 32, "context": "In fact, this observation goes hand-in-hand with the fact that API related features (API frequencies and ngrams [22, 34], API sequences [27], subgraphs [20, 21, 25, 31, 65], dependencies [45, 46], etc.", "startOffset": 187, "endOffset": 195}, {"referenceID": 8, "context": "003) Drebin [22] 0.", "startOffset": 12, "endOffset": 16}, {"referenceID": 14, "context": "002) Adagio [28] 0.", "startOffset": 12, "endOffset": 16}, {"referenceID": 9, "context": "967 CSBD [23] 0.", "startOffset": 9, "endOffset": 13}, {"referenceID": 8, "context": "009) Drebin [22] 0.", "startOffset": 12, "endOffset": 16}, {"referenceID": 14, "context": "006) Adagio [28] 0.", "startOffset": 12, "endOffset": 16}, {"referenceID": 9, "context": "960 CSBD [23] 0.", "startOffset": 9, "endOffset": 13}, {"referenceID": 39, "context": "Similar observations have been reported through other large-scale studies such as [53].", "startOffset": 82, "endOffset": 86}, {"referenceID": 8, "context": "71 Drebin [22] 0.", "startOffset": 10, "endOffset": 14}, {"referenceID": 14, "context": "52 Adagio [28] 0.", "startOffset": 10, "endOffset": 14}, {"referenceID": 9, "context": "58 CSBD [23] 0.", "startOffset": 8, "endOffset": 12}, {"referenceID": 4, "context": "This is in-line with the observations reported in [18] and [29].", "startOffset": 50, "endOffset": 54}, {"referenceID": 15, "context": "This is in-line with the observations reported in [18] and [29].", "startOffset": 59, "endOffset": 63}, {"referenceID": 7, "context": "As noted in [21] and [40], this is an inherent limitation of batch-learning based solutions.", "startOffset": 12, "endOffset": 16}, {"referenceID": 26, "context": "As noted in [21] and [40], this is an inherent limitation of batch-learning based solutions.", "startOffset": 21, "endOffset": 25}, {"referenceID": 8, "context": "72 Drebin [22] 0.", "startOffset": 10, "endOffset": 14}, {"referenceID": 14, "context": "63 Adagio [28] 0.", "startOffset": 10, "endOffset": 14}, {"referenceID": 9, "context": "61 CSBD [23] 0.", "startOffset": 8, "endOffset": 12}, {"referenceID": 55, "context": "Table 7: Weights of MKLDroid\u2019s base kernels - learnt using SMO-MKL [69]", "startOffset": 67, "endOffset": 71}, {"referenceID": 8, "context": "Drebin [22] Linear 170185 0.", "startOffset": 7, "endOffset": 11}, {"referenceID": 9, "context": "0020 CSBD [23] N/A 5000 13.", "startOffset": 10, "endOffset": 14}, {"referenceID": 14, "context": "34 Adagio [28] HI kernel 32768 2783 792 32768 5188 961", "startOffset": 10, "endOffset": 14}, {"referenceID": 13, "context": "DroidMiner [27] proposes a two-tiered behavior graph to model malicious program logic into a vector of threat modalities, and then applies classification according to these modalities.", "startOffset": 11, "endOffset": 15}, {"referenceID": 10, "context": "DroidSIFT [24] models API-relevant behaviors into weighted CADGs and classifies malware based on a vocabulary of known malicious CADG subgraphs.", "startOffset": 10, "endOffset": 14}, {"referenceID": 11, "context": "Recently, AppContext [25] proposes differentiating malicious and benign behaviors based on the contexts similar to ours.", "startOffset": 21, "endOffset": 25}, {"referenceID": 16, "context": "MassVet [30] statically analyzes apps\u2019 UI code to extract a graph that expresses UI states and transitions.", "startOffset": 8, "endOffset": 12}, {"referenceID": 15, "context": "MaMaDroid [29] constructs CGs, models API call sequences as Morkov Chain features and uses Instance-based classifiers (RFs and kNNs) for detection.", "startOffset": 10, "endOffset": 14}, {"referenceID": 27, "context": "On the other hand, a prominent set of works which leverage on PRGs for information-flow analysis include FlowDroid [41], IccTA [42], Mudflow [45] and DroidSafe [43].", "startOffset": 115, "endOffset": 119}, {"referenceID": 28, "context": "On the other hand, a prominent set of works which leverage on PRGs for information-flow analysis include FlowDroid [41], IccTA [42], Mudflow [45] and DroidSafe [43].", "startOffset": 127, "endOffset": 131}, {"referenceID": 31, "context": "On the other hand, a prominent set of works which leverage on PRGs for information-flow analysis include FlowDroid [41], IccTA [42], Mudflow [45] and DroidSafe [43].", "startOffset": 141, "endOffset": 145}, {"referenceID": 29, "context": "On the other hand, a prominent set of works which leverage on PRGs for information-flow analysis include FlowDroid [41], IccTA [42], Mudflow [45] and DroidSafe [43].", "startOffset": 160, "endOffset": 164}, {"referenceID": 17, "context": "Sahs and Khan [31] extract a variety of features including tokens from user-defined permissions, standard permissions and CFG signatures and subsequently takes an anomaly detection approach using a One-Class SVM to detect malware.", "startOffset": 14, "endOffset": 18}, {"referenceID": 21, "context": "[35] take a simpler approach by considering permissions and API calls as features.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "MAST [32] uses selected permissions, Intent filters, the existence of native code and zip files, then applies Multiple Correspondence Analysis to perform malware detection.", "startOffset": 5, "endOffset": 9}, {"referenceID": 19, "context": "MADAM [33] uses five feature-sets that includes system calls, critical APIs, user-interaction based features and metadata related features (e.", "startOffset": 6, "endOffset": 10}, {"referenceID": 32, "context": "RevealDroid [46] uses four feature-sets namely, sensitive APIs, information flows, Intent actions and package-level API informations with Decision Tree classifier to perform detection.", "startOffset": 12, "endOffset": 16}, {"referenceID": 23, "context": "To the best of our knowledge, the only other work that uses MKL for multi-view Android malware detection is HADM [37].", "startOffset": 113, "endOffset": 117}, {"referenceID": 43, "context": "DrDroid [57].", "startOffset": 8, "endOffset": 12}, {"referenceID": 8, "context": "In fact, out 5,600 apps in Drebin [22] dataset, this approach marked the entire code as malicious in 3,757 apps.", "startOffset": 34, "endOffset": 38}, {"referenceID": 42, "context": "HookRanker [56].", "startOffset": 11, "endOffset": 15}, {"referenceID": 16, "context": "As pointed out in [30] and [52], in many cases only certain classes and methods of the injected code are malice.", "startOffset": 18, "endOffset": 22}, {"referenceID": 38, "context": "As pointed out in [30] and [52], in many cases only certain classes and methods of the injected code are malice.", "startOffset": 27, "endOffset": 31}, {"referenceID": 7, "context": ", drift in malicious characteristics induced by malware evolution over time) has been studied closely by the research community and considered as serious and legitimate threat to practicality of malware detection techniques [21, 40, 49].", "startOffset": 224, "endOffset": 236}, {"referenceID": 26, "context": ", drift in malicious characteristics induced by malware evolution over time) has been studied closely by the research community and considered as serious and legitimate threat to practicality of malware detection techniques [21, 40, 49].", "startOffset": 224, "endOffset": 236}, {"referenceID": 35, "context": ", drift in malicious characteristics induced by malware evolution over time) has been studied closely by the research community and considered as serious and legitimate threat to practicality of malware detection techniques [21, 40, 49].", "startOffset": 224, "endOffset": 236}, {"referenceID": 56, "context": "We intend to address this using Online MKL [70] approaches in the future.", "startOffset": 43, "endOffset": 47}, {"referenceID": 36, "context": "Another limitation which follows from the use of ML is the possibility of attacks by adversaries such as poisoning (see [50, 67]).", "startOffset": 120, "endOffset": 128}, {"referenceID": 53, "context": "Another limitation which follows from the use of ML is the possibility of attacks by adversaries such as poisoning (see [50, 67]).", "startOffset": 120, "endOffset": 128}, {"referenceID": 36, "context": "Even though such adversarial attacks against ML based detectors cannot be ruled out in general, meticulous sanitization of training data (see [50]) can limit their impact.", "startOffset": 142, "endOffset": 146}, {"referenceID": 5, "context": "18As discussed in [19, 22, 27, 45, 46] performing precise data-flow and dynamic analysis to extract features is computationally heavy.", "startOffset": 18, "endOffset": 38}, {"referenceID": 8, "context": "18As discussed in [19, 22, 27, 45, 46] performing precise data-flow and dynamic analysis to extract features is computationally heavy.", "startOffset": 18, "endOffset": 38}, {"referenceID": 13, "context": "18As discussed in [19, 22, 27, 45, 46] performing precise data-flow and dynamic analysis to extract features is computationally heavy.", "startOffset": 18, "endOffset": 38}, {"referenceID": 31, "context": "18As discussed in [19, 22, 27, 45, 46] performing precise data-flow and dynamic analysis to extract features is computationally heavy.", "startOffset": 18, "endOffset": 38}, {"referenceID": 32, "context": "18As discussed in [19, 22, 27, 45, 46] performing precise data-flow and dynamic analysis to extract features is computationally heavy.", "startOffset": 18, "endOffset": 38}, {"referenceID": 56, "context": "In our future work, we plan to investigate replacing MKLDroid\u2019s batch MKL with online MKL algorithms [70] so that it automatically adapts to malware evolution and population drift.", "startOffset": 101, "endOffset": 105}, {"referenceID": 8, "context": "In order to provide scope for persuasive research on malicious code localization, we release the results of qualitative and quantitative evaluations of all the apps in Drebin [22] and Mystique [73] datasets at [13].", "startOffset": 175, "endOffset": 179}, {"referenceID": 59, "context": "In order to provide scope for persuasive research on malicious code localization, we release the results of qualitative and quantitative evaluations of all the apps in Drebin [22] and Mystique [73] datasets at [13].", "startOffset": 193, "endOffset": 197}], "year": 2017, "abstractText": "Existing Android malware detection approaches use a variety of features such as securitysensitive APIs, system calls, control-flow structures and information flows in conjunction with Machine Learning classifiers to achieve accurate detection. Each of these feature sets provides a unique semantic perspective (or view) of apps\u2019 behaviors with inherent strengths and limitations. Meaning, some views are more amenable to detect certain attacks but may not be suitable to characterize several other attacks. Most of the existing malware detection approaches use only one (or a selected few) of the aforementioned feature sets which prevents them from detecting a vast majority of attacks. Addressing this limitation, we propose MKLDroid, a unified framework that systematically integrates multiple views of apps for performing comprehensive malware detection and malicious code localization. The rationale is that, while a malware app can disguise itself in some views, disguising in every view while maintaining malicious intent will be much harder. MKLDroid uses a graph kernel to capture structural and contextual information from apps\u2019 dependency graphs and identify malice code patterns in each view. Subsequently, it employs Multiple Kernel Learning (MKL) to find a weighted combination of the views which yields the best detection accuracy. Besides multi-view learning, MKLDroid\u2019s unique and salient trait is its ability to locate fine-grained malice code portions in dependency graphs (e.g., methods/classes). Malicious code localization caters several important applications such as supporting human analysts studying malware behaviors, engineering malware signatures, and other counter-measures. Through our large-scale experiments on several datasets (incl. wild apps), we demonstrate that MKLDroid outperforms three state-of-the-art techniques consistently, in terms of accuracy while maintaining comparable efficiency. In our malicious code localization experiments on a dataset of repackaged malware, MKLDroid was able to identify all the malice classes with 94% average recall. Our work opens up two new avenues in malware research: (i) enables the research community to elegantly look at Android malware behaviors in multiple perspectives simultaneously, and (ii) performing precise and scalable malicious code localization.", "creator": "LaTeX with hyperref package"}}}