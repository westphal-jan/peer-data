{"id": "1704.05347", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Apr-2017", "title": "Baselines and test data for cross-lingual inference", "abstract": "research towards natural language inference is currently annexed to english. here, we propose to advance explicit multilingual evaluation. to that end, we provide test data for four major languages. we experiment also a set of baselines based when cross - lingual embeddings and machine translation. while given best system scores an uncertainty accuracy of just over 75 %, we focus largely on financing further research in multilingual inference.", "histories": [["v1", "Tue, 18 Apr 2017 14:12:37 GMT  (43kb,D)", "http://arxiv.org/abs/1704.05347v1", "Submitted for review at EMNLP 2017"]], "COMMENTS": "Submitted for review at EMNLP 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["\\v{z}eljko agi\\'c", "natalie schluter"], "accepted": false, "id": "1704.05347"}, "pdf": {"name": "1704.05347.pdf", "metadata": {"source": "CRF", "title": "Baselines and test data for cross-lingual inference", "authors": ["\u017deljko Agi\u0107", "Natalie Schluter"], "emails": ["zeag@itu.dk", "nael@itu.dk"], "sections": [{"heading": "1 Introduction", "text": "Natural language processing is marking a very recent resurgence of interest in textual entailment. Now revamped as natural language inference (NLI) by Bowman et al. (2015) with their SNLI dataset, the task of differentiating contradictory, entailing, and unrelated pairs of sentences (Fig. 1) has entertained a large number of proposals.1 The timely challenge lends itself to various deep learning approaches such as by Rockta\u0308schel et al. (2015), Parikh et al. (2016), or Wang et al. (2017), which mark a string of very notable results.\nYet, the SNLI corpus is in English only. As of recently, it includes more test data from multiple genres,2 but it remains exclusive to English. Following Bender (2009) in seeking true language independence, we propose to extend the current NLI research beyond English, and further into the majority realm of low-resource languages.\nSince training data is generally unavailable for most languages, work on transfer learning is abundant for the basic NLP tasks such as tagging and syntactic parsing (Das and Petrov, 2011; Ammar\n1 https://nlp.stanford.edu/projects/snli/ 2 https://repeval2017.github.io/shared/\net al., 2016). By contrast, the research in crosslingual entailment is not as plentiful (Negri et al., 2013). To the best of our knowledge, at this point there are no contributions to SNLI-style crosslingual inference, or for that matter, work on languages other than English at all.\nContributions. In the absence of training data for languages other than English, we propose a set of baselines for cross-lingual neural inference. We adapt to the target languages either by i) employing multilingual word embeddings or alternatively by ii) translating the inputs into English.\nWe create multilingual test data to facilitate evaluation by manually translating 1,332 sentence pairs from the English SNLI test data into four other major languages: Arabic, French, Russian, and Spanish. We also experiment with automatic translations of the SNLI test data to serve as a proxy for large-scale evaluations in the absence of manually produced data."}, {"heading": "2 Cross-lingual inference", "text": "Following the success of neural networks in SNLIstyle inference, we take the neural attention-based model of Parikh et al. (2016) as our starting point. To date, their system remains competitive with the current state of the art. As their attention model is based solely on word embeddings, and is independent of word order, it is particularly suitable for the baseline we present here: a purely multilingual embeddings based cross-lingual NLI sys-\nar X\niv :1\n70 4.\n05 34\n7v 1\n[ cs\n.C L\n] 1\n8 A\npr 2\n01 7\ntem. Moreover, their approach is computationally much leaner than most competitors, making it a fast and scalable choice.3\nIn short, the Parikh et al. (2016) model sends sentence pairs, i.e., premises and hypotheses, through a neural pipeline that consists of three separate components:\ni) ATTENTION: Scores combinations of pairs of words across input sentence pairs. Scores of these word pairs are given by a feed-forward network with ReLU activations that is assumed to model a homomorphic function for linear-time computation. Attention weights for phrases softly aligned with a word are obtained by summing their component vectors each factored by their normalized score. ii) COMPARISON: Word vectors and their aligned phrase counterparts are compared and combined into a single vector using a feed-forward neural network. iii) CONCATENATION: A network that sums over the above output vectors for each input sentence, concatenates this representation and feeds it through a final feed-forward network followed by a linear layer.\nTo be trained, the model expects SNLI annotations, and an ideally very large vocabulary of distributed word representations.\nIn this paper, we have at our disposal only a large training corpus of English NLI examples, but a distinct language in which we want to predict for NLI: the target language. We train the system described above on the English training set. We exploit the fact that the system is purely embeddings-based and train with multilingual embeddings for a set of languages including English and the prediction language. Multilingual embeddings are sets of word embeddings generated for multiple languages where the embeddings from the union of these sets are meant to correspond to one another semantically independent of the language the words the embeddings correspond to actually belong. At prediction time, we can safely use the embeddings of the target language.\nMapping. One method for obtaining multilingual word embeddings is to apply the translation matrix technique to a set of monolingual embeddings (Mikolov et al., 2013a) with the aid of a\n3For more details, see the original paper, and an illustrative overview of the model: https://explosion.ai/blog/ deep-learning-formula-nlp.\nbilingual dictionary containing the source-target word pairs. The method works by finding a transformation matrix from the target language monolingual embeddings to the English monolingual embeddings that minimizes the total least-squared error. This transformation matrix can then be used on words not seen in the bilingual dictionary.\nMultilingual embeddings. If parallel sentences or even just parallel documents are available for two or more languages, we can use this data to embed their vocabularies in a shared representation. For example, through an English-Russian parallel corpus we would represent the words of the two languages in a shared space.\nThere are several competing approaches to training word embeddings over parallel sentences. In this paper, we experiment with four.\nBICVM: The seminal approach by Hermann and Blunsom (2014) for inducing bilingual compositional representations from sentence-aligned parallel corpora only.4 INVERT: Inverted indexing over parallel corpus sentence IDs as indexing features, with SVD dimensionality reduction on top, following S\u00f8gaard et al. (2015) in the recent implementation by Levy et al. (2017).5 Instead of embedding just language pairs, this method embeds multiple languages into the same space. It is thus distinctly multilingual, rather than just bilingual. RANDOM: Our implementation of the approach by Vulic\u0301 and Moens (2016) whereby bilingual SGNS embeddings of Mikolov et al. (2013b) are trained on top of merged pairs of parallel sentences with randomly shuffled tokens. RATIO: Similar to RANDOM, except the tokens in bilingual sentences are not shuffled, but inserted successively by following the token ratio between the two sentences.\nMachine translation. One alternative to adapting via shared distributed representations is to use machine translation.\nIf high-quality translation systems are readily available, or if we can build them from abundant parallel corpora, we can simply translate any input to English and run a pre-trained English NLI model over it. Moreover, we can translate the training data and train target language models similar to Tiedemann et al. (2014) in cross-lingual de-\n4 https://github.com/karlmoritz/bicvm 5 https://bitbucket.org/omerlevy/xling_embeddings/\npendency parsing. The MT approach only lends itself to mediumto high-density languages. The mapping requires only the monolingual data and bilingual dictionaries, while the bilingual embeddings need parallel texts or documents, both of which are feasible for true low-resource languages."}, {"heading": "3 Test data", "text": "The SNLI data are essentially pairs of sentences\u2014 premises and hypotheses\u2014each paired with a relation label: contradiction, entailment, or neutral. We had human experts manually translate the first 1,332 test pairs from English into Arabic, French, Russian, and Spanish. We simply copied over the original labeling of relations. That way we can directly evaluate the NLI performance for these five languages.\nFurther, we translated our test sets into English by Google Translate for our MT-based system as it adapts through translation and thus expects input in English. We also automatically translated the 1,332 original English sentences into our new test languages to check how well we can approximate the \u201ctrue\u201d accuracies by using translated test data. This way we can facilitate cross-lingual NLI evaluations on a larger scale.\nThe BLEU scores for the two translation directions are given in Table 1, where we see a clear typological split."}, {"heading": "4 Experiment", "text": "Our experiment involves adapting a neural NLI classifier through multilingual word embeddings and machine translation.\nWe run the Kim et al. (2017) implementation of the attention-based system of Parikh et al. (2016).6 All models are trained for 15 epochs and otherwise with default settings. While this system typically peaks at over 100 epochs, we sacrifice some accuracy for more breadth in the comparison.\n6 https://github.com/harvardnlp/struct-attn\nWe set the dimensionality to 300 for all our embeddings. Other than that, they are trained with their default settings. In mapping we use the pretrained FASTTEXT vectors7 for all five languages (Bojanowski et al., 2016). We map the target language embeddings to English as Mikolov et al. (2013a), using the Dinu et al. (2014) implementation8 and Wiktionary data.9\nWe train our bilingual embeddings on the UN corpus (Ziemski et al., 2016). The corpus covers English and the four target languages with 11M sentences each. The sentences are aligned across all five languages. The Moses tokenizer10 (Koehn et al., 2007) was used to preprocess the corpus and the test data for training and evaluation.\nIn the MT approach, we only experiment with translating the input, and not with translating the training data due to time constraints. There, we use two English SNLI models: one with FASTTEXT and the other with GLOVE 840B embeddings (Pennington et al., 2014).11\nResults. We report the overall accuracy and F1 scores for the three labels. Table 2 gives the overall scores of our cross-lingual NLI approaches. In general, the more resources we have, the better the scores: Training bilingual embeddings surpasses the mapping to English, while translating to English using a top-level MT system tops the adaptation via embeddings.\nThe mapping to English works slightly better\n7 https://github.com/facebookresearch/fastText/\nblob/master/pretrained-vectors.md 8 http://clic.cimec.unitn.it/\u02dcgeorgiana.dinu/down/\n9 https://dumps.wikimedia.org/\n10 https://github.com/moses-smt/mosesdecoder/ 11 https://nlp.stanford.edu/projects/glove/\nfor Arabic than for the other languages, and scores an average of 52%. The RANDOM bilingual embeddings top their group with an average accuracy of 59.6% followed by INVERT at 58.1%, while RATIO and BICVM are below at 56.1 and 57.4%. The MT approach expectedly tops the table at 75.5% accuracy. In Table 3 we see that our best bilingual embeddings system RANDOM has a preference for entailment, with ca 9% in F1 over the other two labels, which makes sense for a model aimed at capturing semantic similarity. This also holds true for the original Parikh et al. (2016) evaluation on English.\nWe report all our English scores as a sanity check. In 100 training epochs, Parikh et al. (2016) score 86.8% with GLOVE 840B as their top score, while we mark 83.4% in 15 epochs. With the significantly smaller FASTTEXT embeddings we reach an accuracy of 79.7%. The multilingual embeddings average at 76.7% for English, where RATIO peaks at 78.1%, likely as its sequential shuffling of parallel texts most closely captures the English sentence structure.\nDiscussion. Figure 2 plots a learning curve for the French RANDOM approach. We see that its accuracy steadily increases by adding more parallel data into building the bilingual embeddings. As a side note, the MT-based system benefits if the\nEnglish side of the embeddings grows in size and quality. The figure points out that i) adding more data benefits the task, and that ii) the accuracy of our RANDOM approach stabilizes at around 1M parallel sentences. As per S\u00f8gaard et al. (2015) most language pairs can offer no more than 100k sentence pairs, this puts forth a challenge for future cross-lingual NLI learning research.\nReplacing the manually prepared test sets with the ones automatically translated from English underestimates the true accuracy by absolute -2.57% on average. The higher the translation quality, the better the estimates we observe: While the difference is around -1% for French and Spanish, it is -7% for Arabic. Still, in proxy evaluation, as with our MT-based adaptation approach in general, we exercise caution: SNLI sentences are image captions, mostly \u226415 words long and thus relatively easy to translate (cf. Bowman et al. 2015, Fig. 2) in comparison to, e.g., newspaper text."}, {"heading": "5 Related work", "text": "Prior to SNLI, there has been work in cross-lingual textual entailment using parallel corpora (Mehdad et al., 2011) and lexical resources (Castillo, 2011), or crowdsourcing for multilingual training data by Negri et al. (2011). We also note two shared tasks, on cross-lingual entailment with five languages (Negri et al., 2013) and English relatedness and inference (Marelli et al., 2014).\nSNLI is the first large-scale dataset for NLI in English (Bowman et al., 2015), two orders of magnitude larger than any predecessor. It was recently expanded with test data for multiple genres of English to allow for cross-domain evaluation.12 Prior to our work, there have been no SNLI-style crosslingual methods or evaluations."}, {"heading": "6 Conclusions", "text": "We have proposed the first set of cross-lingual approaches to natural language inference, together with novel test data for four major languages. In experiments with three types of transfer systems, we record viable scores, while at the same time exploring the scalability of cross-lingual inference for low-resource languages.\nWe are actively enlarging the test data and introducing new languages. Our multilingual test sets and word embeddings are freely available.13\n12 https://www.nyu.edu/projects/bowman/multinli/ 13 https://bitbucket.org/nlpitu/xnli"}, {"heading": "Acknowledgements", "text": "We thank Ivan Vulic\u0301 and Nikola Mrks\u030cic\u0301 for their help with the bilingual embeddings. We also acknowledge the NVIDIA Corporation for supporting our research."}], "references": [{"title": "Linguistically na\u0131\u0308ve !=", "author": [], "venue": null, "citeRegEx": "Bender.,? \\Q2009\\E", "shortCiteRegEx": "Bender.", "year": 2009}, {"title": "Structured attention networks", "author": ["Yoon Kim", "Carl Denton", "Luong Hoang", "Alexander M Rush."], "venue": "arXiv preprint arXiv:1702.00887 .", "citeRegEx": "Kim et al\\.,? 2017", "shortCiteRegEx": "Kim et al\\.", "year": 2017}, {"title": "A strong baseline for learning cross-lingual word embeddings from sentence alignments", "author": ["Omer Levy", "Anders S\u00f8gaard", "Yoav Goldberg."], "venue": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Lin-", "citeRegEx": "Levy et al\\.,? 2017", "shortCiteRegEx": "Levy et al\\.", "year": 2017}, {"title": "Semeval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and tex", "author": ["Marco Marelli", "Luisa Bentivogli", "Marco Baroni", "Raffaella Bernardi", "Stefano Menini", "Roberto Zamparelli"], "venue": null, "citeRegEx": "Marelli et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Marelli et al\\.", "year": 2014}, {"title": "Using bilingual parallel corpora for cross-lingual textual entailment", "author": ["Yashar Mehdad", "Matteo Negri", "Marcello Federico."], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Tech-", "citeRegEx": "Mehdad et al\\.,? 2011", "shortCiteRegEx": "Mehdad et al\\.", "year": 2011}, {"title": "Exploiting similarities among languages for machine translation", "author": ["Tomas Mikolov", "Quoc Le", "Ilya Sutskever."], "venue": "arXiv preprint arXiv:1309.4168 .", "citeRegEx": "Mikolov et al\\.,? 2013a", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."], "venue": "Advances in Neural Information Processing Systems. pages 3111\u20133119.", "citeRegEx": "Mikolov et al\\.,? 2013b", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Divide and conquer: Crowdsourcing", "author": ["Matteo Negri", "Luisa Bentivogli", "Yashar Mehdad", "Danilo Giampiccolo", "Alessandro Marchetti"], "venue": null, "citeRegEx": "Negri et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Negri et al\\.", "year": 2011}, {"title": "Semeval-2013 task 8: Cross-lingual textual entailment for content synchronization", "author": ["Matteo Negri", "Alessandro Marchetti", "Yashar Mehdad", "Luisa Bentivogli", "Danilo Giampiccolo."], "venue": "Second Joint Conference on Lexical and Computational Seman-", "citeRegEx": "Negri et al\\.,? 2013", "shortCiteRegEx": "Negri et al\\.", "year": 2013}, {"title": "A decomposable attention model for natural language inference", "author": ["Ankur Parikh", "Oscar T\u00e4ckstr\u00f6m", "Dipanjan Das", "Jakob Uszkoreit."], "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. Association", "citeRegEx": "Parikh et al\\.,? 2016", "shortCiteRegEx": "Parikh et al\\.", "year": 2016}, {"title": "Glove: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher Manning."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computa-", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Reasoning about entailment with neural attention", "author": ["Tim Rockt\u00e4schel", "Edward Grefenstette", "Karl Moritz Hermann", "Tom\u00e1\u0161 Ko\u010disk\u1ef3", "Phil Blunsom."], "venue": "arXiv preprint arXiv:1509.06664 .", "citeRegEx": "Rockt\u00e4schel et al\\.,? 2015", "shortCiteRegEx": "Rockt\u00e4schel et al\\.", "year": 2015}, {"title": "Inverted indexing for crosslingual nlp", "author": ["Anders S\u00f8gaard", "\u017deljko Agi\u0107", "H\u00e9ctor Mart\u0131\u0301nez Alonso", "Barbara Plank", "Bernd Bohnet", "Anders Johannsen"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association", "citeRegEx": "S\u00f8gaard et al\\.,? \\Q2015\\E", "shortCiteRegEx": "S\u00f8gaard et al\\.", "year": 2015}, {"title": "Treebank translation for cross-lingual parser induction", "author": ["J\u00f6rg Tiedemann", "\u017deljko Agi\u0107", "Joakim Nivre."], "venue": "Proceedings of the Eighteenth Conference on Computational Natural Language Learning. Association for Computational", "citeRegEx": "Tiedemann et al\\.,? 2014", "shortCiteRegEx": "Tiedemann et al\\.", "year": 2014}, {"title": "Bilingual distributed word representations from document-aligned comparable data", "author": ["Ivan Vuli\u0107", "Marie-Francine Moens."], "venue": "Journal of Artificial Intelligence Research 55:953\u2013994. https://doi.org/doi:10.1613/jair.4986.", "citeRegEx": "Vuli\u0107 and Moens.,? 2016", "shortCiteRegEx": "Vuli\u0107 and Moens.", "year": 2016}, {"title": "Bilateral multi-perspective matching for natural language sentences", "author": ["Zhiguo Wang", "Wael Hamza", "Radu Florian."], "venue": "arXiv preprint arXiv:1702.03814 .", "citeRegEx": "Wang et al\\.,? 2017", "shortCiteRegEx": "Wang et al\\.", "year": 2017}, {"title": "The united nations parallel corpus v1.0", "author": ["Micha\u0142 Ziemski", "Marcin Junczys-Dowmunt", "Bruno Pouliquen"], "venue": "In Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016)", "citeRegEx": "Ziemski et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ziemski et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 10, "context": "1 The timely challenge lends itself to various deep learning approaches such as by Rockt\u00e4schel et al. (2015), Parikh et al.", "startOffset": 83, "endOffset": 109}, {"referenceID": 9, "context": "(2015), Parikh et al. (2016), or Wang et al.", "startOffset": 8, "endOffset": 29}, {"referenceID": 9, "context": "(2015), Parikh et al. (2016), or Wang et al. (2017), which mark a string of very notable results.", "startOffset": 8, "endOffset": 52}, {"referenceID": 0, "context": "Following Bender (2009) in seeking true language independence, we propose to extend the current NLI research beyond English, and further into the majority realm of low-resource languages.", "startOffset": 10, "endOffset": 24}, {"referenceID": 9, "context": "Following the success of neural networks in SNLIstyle inference, we take the neural attention-based model of Parikh et al. (2016) as our starting point.", "startOffset": 109, "endOffset": 130}, {"referenceID": 9, "context": "In short, the Parikh et al. (2016) model sends sentence pairs, i.", "startOffset": 14, "endOffset": 35}, {"referenceID": 5, "context": "One method for obtaining multilingual word embeddings is to apply the translation matrix technique to a set of monolingual embeddings (Mikolov et al., 2013a) with the aid of a", "startOffset": 134, "endOffset": 157}, {"referenceID": 11, "context": "sentence IDs as indexing features, with SVD dimensionality reduction on top, following S\u00f8gaard et al. (2015) in the recent implementation by Levy et al.", "startOffset": 87, "endOffset": 109}, {"referenceID": 2, "context": "(2015) in the recent implementation by Levy et al. (2017).5 Instead of embedding just language pairs, this method embeds multiple languages into", "startOffset": 39, "endOffset": 58}, {"referenceID": 12, "context": "RANDOM: Our implementation of the approach by Vuli\u0107 and Moens (2016) whereby bilingual SGNS embeddings of Mikolov et al.", "startOffset": 46, "endOffset": 69}, {"referenceID": 5, "context": "RANDOM: Our implementation of the approach by Vuli\u0107 and Moens (2016) whereby bilingual SGNS embeddings of Mikolov et al. (2013b) are trained on top of merged pairs of parallel sentences with randomly shuffled tokens.", "startOffset": 106, "endOffset": 129}, {"referenceID": 13, "context": "Moreover, we can translate the training data and train target language models similar to Tiedemann et al. (2014) in cross-lingual de-", "startOffset": 89, "endOffset": 113}, {"referenceID": 1, "context": "We run the Kim et al. (2017) implementation of the attention-based system of Parikh et al.", "startOffset": 11, "endOffset": 29}, {"referenceID": 1, "context": "We run the Kim et al. (2017) implementation of the attention-based system of Parikh et al. (2016).6 All models are trained for 15 epochs and otherwise with default settings.", "startOffset": 11, "endOffset": 98}, {"referenceID": 5, "context": "We map the target language embeddings to English as Mikolov et al. (2013a), using the Dinu et al.", "startOffset": 52, "endOffset": 75}, {"referenceID": 5, "context": "We map the target language embeddings to English as Mikolov et al. (2013a), using the Dinu et al. (2014) implementation8 and Wiktionary data.", "startOffset": 52, "endOffset": 105}, {"referenceID": 16, "context": "We train our bilingual embeddings on the UN corpus (Ziemski et al., 2016).", "startOffset": 51, "endOffset": 73}, {"referenceID": 10, "context": "There, we use two English SNLI models: one with FASTTEXT and the other with GLOVE 840B embeddings (Pennington et al., 2014).", "startOffset": 98, "endOffset": 123}, {"referenceID": 9, "context": "This also holds true for the original Parikh et al. (2016) evaluation on English.", "startOffset": 38, "endOffset": 59}, {"referenceID": 9, "context": "In 100 training epochs, Parikh et al. (2016) score 86.", "startOffset": 24, "endOffset": 45}, {"referenceID": 12, "context": "As per S\u00f8gaard et al. (2015) most language pairs can offer no more than 100k sentence pairs, this puts forth a challenge for future cross-lingual NLI learning research.", "startOffset": 7, "endOffset": 29}, {"referenceID": 4, "context": "Prior to SNLI, there has been work in cross-lingual textual entailment using parallel corpora (Mehdad et al., 2011) and lexical resources (Castillo, 2011), or crowdsourcing for multilingual training data by", "startOffset": 94, "endOffset": 115}, {"referenceID": 8, "context": "We also note two shared tasks, on cross-lingual entailment with five languages (Negri et al., 2013) and English relatedness and inference (Marelli et al.", "startOffset": 79, "endOffset": 99}, {"referenceID": 3, "context": ", 2013) and English relatedness and inference (Marelli et al., 2014).", "startOffset": 46, "endOffset": 68}], "year": 2017, "abstractText": "Research in natural language inference is currently exclusive to English. Here, we propose to advance toward multilingual evaluation. To that end, we provide test data for four major languages. We experiment with a set of baselines based on cross-lingual embeddings and machine translation. While our best system scores an average accuracy of just over 75%, we focus largely on enabling further research in multilingual inference.", "creator": "LaTeX with hyperref package"}}}