{"id": "1705.01172", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-May-2017", "title": "Imagining Probabilistic Belief Change as Imaging (Technical Report)", "abstract": "imaging is a form of probabilistic belief change analyses need be employed for both revision and enhancement. in this paper, we propose a new framework for probabilistic theory change based on imaging, called time distance improvement ( edi ). edi is sufficiently general to define bayesian conditioning and other forms of imaging previously studied in the literature. we argue that, and investigate how, edi can thus used for both revision and update. edi'overall definition implies crucially whenever a weight function whose properties are studied and whose effect on subsequent change operations is analysed. finally, four discrete instantiations are proposed, two for revision and two gradual update, including probabilistic rationality postulates are suggested for their analysis.", "histories": [["v1", "Tue, 2 May 2017 20:50:59 GMT  (52kb,D)", "http://arxiv.org/abs/1705.01172v1", "21 pages"]], "COMMENTS": "21 pages", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["gavin rens", "thomas meyer"], "accepted": false, "id": "1705.01172"}, "pdf": {"name": "1705.01172.pdf", "metadata": {"source": "CRF", "title": "Imagining Probabilistic Belief Change as Imaging (Technical Report)", "authors": ["Gavin Rens"], "emails": ["grens@cs.uct.ac.za", "tmeyer@cs.uct.ac.za"], "sections": [{"heading": "1 Introduction", "text": "From the perspective of classical (Boolean) belief change, the work of Alchourr\u00f3n et al. (1985) is regarded as the foundation theory for belief revision (AGM theory). Typically, belief change (in a static world) can be categorized as expansion, revision or contraction, and is performed on a belief set, the set of sentences K closed under logical consequence. Revision is when new information \u03b1 is (possibly) inconsistent with K and K is (minimally) modified so that the new K remains consistent and entails \u03b1. Revision is the process which takes place when an agent modifies its beliefs due to receiving new information not previously known or which is more relevant or trustworthy. Except for the movement of information, the physical world is assumed to be completely unchanging.\nWhereas belief revision is considered to take place in a static environment, belief update is thought to be the change in beliefs which takes place due to a dynamic environment. Update refers to the process of bringing beliefs up to date precisely because the world has changed and the agent needs a new, \u2018matching\u2019 view on the world.\nFrom the perspective of classical (Boolean) belief change, Katsuno and Mendelzon (1992) developed the first serious theory of update (KM theory). Their theory is different from that of AGM in that their rationality postulates are derived from the understanding that update occurs in a dynamic environment.\nHowever, simply applying AGM theory for revision and KM theory for update has been (indirectly) challenged (Friedman and Halpern, 1999; Kern-Isberner, 2001; Nayak, 2011; Lang, 2007). Further, how to categorize a belief change operator is more challenging when notions of uncertainty are considered, for instance, when using probabilities and rankings. The very definition of belief revision and belief update become more problematic under notions of uncertainty.\nOne kind of probabilistic belief change operation which could potentially \u2018relax\u2019 the tension between revision and update is imaging. David Lewis (1976) first proposed imaging to analyse conditional reasoning in probabilistic settings, and it has recently been the focus of several works on probabilistic belief change (Ramachandran et al., 2010; Chhogyal et al., 2014; Rens et al., 2016). Imaging is the approach of moving the belief in worlds possible at one moment to similar worlds compatible with evidence received at a next moment. In other words, the \u2018belief-mass\u2019 is shifted to the \u2018images\u2019 of the worlds currently believed possible, where the images are the worlds related via new evidence to the currently believed worlds.\nOne of the main benefits of imaging is that it overcomes the problem with Bayesian conditioning, namely, being undefined when evidence is inconsistent with current beliefs. G\u00e4rdenfors (1988) and Rens et al. (2016) proposed generalizations of Lewis\u2019s original definition. In this paper we propose a new generalization of imaging \u2013 or a family\nar X\niv :1\n70 5.\n01 17\n2v 1\n[ cs\n.A I]\n2 M\nay 2\nof imaging-based belief change operators \u2013 and analyse other probabilistic belief change methods with respect to it. In particular, we propose a version of imaging based on the movement of probability mass weighted by the inverse of distances between possible worlds.\nWhether imaging is applicable to revision or update (or both) is still an open question. G\u00e4rdenfors (1988) says \"...the imaging method is a general revision method because it gives nontrivial results when...the new information to be accommodated...[contradicts the current beliefs]\". Chhogyal et al. (2014) explore the use of Lewis imaging as a means to construct probabilistic belief revision. They present explicit constructions of three candidates strategies based on imaging and investigate their properties. (Rens et al., 2016) define an imaging operation which relaxes the unique-closest-world assumption of Lewis imaging, and they provide a method of revising (via imaging) a potentially infinite set of belief states in a finite procedure. On the other hand, some researchers have considered imaging to be the probabilistic version of update (Katsuno and Mendelzon, 1992; Dubois and Prade, 1993; Nayak, 2011). Ramachandran et al. (2010) propose a version of imaging for probabilistic belief erasure. In fact, Lewis (1976) himself never said that imaging was meant to be interpreted as one or the other. In this paper we continue to investigate the relationship of imaging to revision and update.\nThe paper makes four contributions. 1) We define Expected Distance Imaging (EDI) and show how Bayesian conditioning, Lewis imaging and generalized imaging can be couched as EDI operations. 2) We define four (new) instantiations of the EDI operation. 3) We define a weight function (as used in EDI), and several properties such a function might have, and explore which of these properties are satisfied by different instantiations of weight functions (for different versions of the EDI operator). 4) We propose a set of rationality postulates for probabilistic belief update.\nDue to space limitations, all proofs of propositions have been omitted. Please refer to the appendix for the proofs."}, {"heading": "2 Background", "text": "We shall work with a finitely generated classical propositional logic. Let P be a finite set of n atoms. Formally, a world w is a unique assignment of truth values to all the atoms in P . There are thus 2n conceivable worlds. An agent may consider some non-empty subset W of the conceivable worlds; W is called the possible worlds. The classical notion of satisfaction is used. World w satisfies (is a model of) \u03b1 is written w \u03b1. Let L be all propositional formulae which can be formed from P and the logical connectives \u2227 and \u00ac, with > abbreviating tautology and \u22a5 abbreviating contradiction. Let \u03b2 be a sentence in L. Mod(\u03b2) denotes the set of models of \u03b2. \u03b2 entails \u03b1 (denoted \u03b2 |= \u03b1) iff Mod(\u03b2) \u2286 Mod(\u03b1). \u03b2 is equivalent to \u03b1 (denoted \u03b2\u2261\u03b1) iff Mod(\u03b2) = Mod(\u03b1).\nOften, in the exposition of this paper, a world will be referred to by its truth vector. For instance, if a two-atom vocabulary is placed in order \u2329q,r \u232a and w3 \u00acq \u2227 r , then w3 may be referred to as 01.\nIn this work, the basic semantic element of an agent\u2019s beliefs is a probability distribution or a belief state\nb = {(w1, p1), (w2, p2), . . . , (wn , pn)},\nwhere {w1, w2, . . . , wn} = W and pi is the probability (real number) that wi is the actual world in which the agent is, with \u2211 (w,p)\u2208b p = 1. For parsimony, let b = \u2329p1, . . . , pn\u232a be the probabilities that belief state b assigns to w1, . . . , wn where, for instance, \u2329w1, w2, w3, w4\u232a = \u232911,10,01,00\u232a, and \u2329w1, w2, . . . , w8\u232a = \u2329111,110, . . . ,000\u232a. b(\u03b1) abbreviates\u2211 w\u2208Mod(\u03b1) b(w).\nIt is not yet universally agreed what belief change means in a probabilistic setting. One school of thought says that probabilistic expansion (restricted revision) is equivalent to Bayesian conditioning (G\u00e4rdenfors (1988, Chap. 5) and Voorbraak (1999) mention this, but no not necessarily agree with it). This is evidenced by Bayesian conditioning (BC) being defined only when b(\u03b1) 6= 0, thus making BC expansion equivalent to BC revision. In other words, one could define expansion to be bBC\u03b1= {(w, p) | w \u2208W, p = b(w |\u03b1),b(\u03b1) 6= 0}, where b(w |\u03b1) can be defined as b(\u03c6w \u2227\u03b1)/b(\u03b1) and \u03c6w is a sentence identifying w (i.e., a complete theory for w). Note that bBC\u03b1=; iff b(\u03b1) = 0. This implies that BC is ill-defined when b(\u03b1) = 0.\nWe may write b \u2217\u03b1 as b\u2217\u03b1 so that we can write b\u2217\u03b1(w), where \u2217 is an arbitrary belief change operator. The technique of Lewis imaging for the revision of belief states requires a notion of similarity between worlds. In fact, he implicitly assumes the availability of a mapping of worlds to a total order \u2264w on worlds for every fixed w \u2208W . Let w\u03b1 be the least \u03b1-world with respect to \u2264w . That is, w\u03b1 \u03b1 and: if w 6 \u03b1, then w\u03b1 \u2264w w \u2032\u2032 for all w \u2032\u2032 \u2208 Mod(\u03b1), and if w \u03b1, then w\u03b1 = w .\nIf we indicate Lewis\u2019s original imaging operation with LI, then his definition can be stated as\nbLI\u03b1 := {(w, p) | w \u2208W, p = 0 if w 6 \u03b1, else p = \u2211 w \u2032\u2208W,w \u2032\u03b1=w b(w \u2032)}.\nHe calls bLI\u03b1 the image of b on \u03b1. In words, bLI\u03b1(w) is zero if w does not model \u03b1, but if it does, then w retains all the probability it had and accrues the probability mass from all the non-\u03b1-worlds closest to it. This form of imaging only shifts probabilities around; no probabilities are magnified or shrunk. The probabilities in bLI\u03b1 thus sum to 1 without the need for any normalization."}, {"heading": "3 Non-unique-closest-world Approaches", "text": "Every world having a unique closest \u03b1-world is quite a strong requirement. We now mention an approach which relaxes the uniqueness requirement.\nG\u00e4rdenfors (1988) describes his generalization of Lewis imaging (which he calls general imaging) as \u201c... instead of moving all the probability assigned to a world W i by a probability function P to a unique (\u201cclosest\u201d) A-world W j , when imaging on A, one can introduce the weaker requirement that the probability of W i be distributed among several A-worlds (that are \u201cequally close\u201d).\u201d If we interpret G\u00e4rdenfors\u2019 approach correctly, he does not provide a constructive method but insists that b#\u03b1(\u03b1) = 1, where b#\u03b1 is the image (change) of b on \u03b1.\nRens et al. (2016) introduced generalized imaging via a constructive method. It is a particular instance of G\u00e4rdenfors\u2019 general imaging. They use a pseudo-distance measure between worlds, as defined by Lehmann et al. (2001) and adopted by Chhogyal et al. (2014).\nDefinition 3.1. A pseudo-distance function d : W \u00d7W \u2192 Z satisfies the following four conditions: for all worlds w, w \u2032, w \u2032\u2032 \u2208W ,\n1. d(w, w \u2032) \u2265 0 (Non-negativity) 2. d(w, w) = 0 (Identity) 3. d(w, w \u2032) = d(w \u2032, w) (Symmetry) 4. d(w, w \u2032)+d(w \u2032, w \u2032\u2032) \u2265 d(w, w \u2032\u2032) (Triangular\nInequality)\nNote that d induces a mapping from worlds to total preorders \u2264dw on worlds as follows. w \u2032 \u2264dw w \u2032\u2032 iff d(w, w \u2032) \u2264 d(w, w \u2032\u2032). Note that conditions 2 and 4 make \u2264dw a total preorder, and that adding conditions 1 and 3 do not necessarily make \u2264dw a (total) partial order. This makes it possible for a world to have more than one closest worlds. One may also want to impose a condition on a distance function such that any two distinct worlds must have some distance between them: For all w, w \u2032 \u2208W , if w 6= w \u2032, then d(w, w \u2032) > 0 (Faithfulness).\nLet Min(\u03b1, w,d) be the set of \u03b1-worlds closest to w with respect to pseudo-distance d . Formally,\nMin(\u03b1, w,d) := {w \u2032 \u03b1 | \u2200w \u2032\u2032 \u03b1,d(w \u2032, w) \u2264 d(w \u2032\u2032, w)},\nwhere d(\u00b7) is some pseudo-distance measure between worlds (e.g., Hamming or Dalal distance). For instance, using Hamming distance for d and vocabulary {q,r },\n\u2022 Min(\u00acq,11,d) = {01} \u2022 Min(\u00acq,10,d) = {00} \u2022 Min(\u00acq,01,d) = {01} \u2022 Min(\u00acq,00,d) = {00} Generalized imaging (denoted GI) is defined as\nbGI\u03b1 := {(w, p) | w \u2208W, p = 0 if w 6 \u03b1,else p = \u2211 w \u2032\u2208W\nw\u2208Min(\u03b1,w \u2032,d)\nb(w \u2032)/|Min(\u03b1, w \u2032,d)|}.\nb GI\u03b1 is the new belief state produced by taking the generalized image of b on \u03b1. In words, the probability mass of non-\u03b1-worlds is shifted to their closest \u03b1-worlds, such that if a non-\u03b1-world w\u00d7 with probability p has n closest \u03b1-worlds (equally distant), then each of these closest \u03b1-worlds gets p/n mass from w\u00d7.\nAs an example, let belief state b1.0 := \u23291,0,0,0\u232a and let belief state b.3/.7 := \u23290.3,0.7,0,0\u232a for vocabulary {q,r }. Then \u2022 b0.3/0.7 GI\u00acq(11) = b0.3/0.7 GI\u00acq(10) = 0 \u2022 b0.3/0.7 GI\u00acq(01) = 0.3/1+0/1 = 0.3 \u2022 b0.3/0.7 GI\u00acq(00) = 0.7/1+0/1 = 0.7\nand\n\u2022 b1.0 GI\u00acq(11) = b1.0 GI\u00acq(10) = 0 \u2022 b1.0 GI\u00acq(01) = 1/1+0/1 = 1 \u2022 b1.0 GI\u00acq(00) = 0/1+0/1 = 0"}, {"heading": "4 Expected Distance Imaging", "text": "In this section, we define expected distance imaging (EDI) and some properties of interest, then we define two instantiations of EDI and define Bayesian conditioning, Lewis imaging and generalized imaging in terms of EDI. Each operator is considered with respect to the properties. We end with a discussion about the five operations."}, {"heading": "4.1 Definition and Properties", "text": "Rens and Meyer (2015) proposed determining the new probability of an \u03b1-world w\u03b1 as the weighted average of the current probabilities of all worlds w \u2032, where the weights are (inversely) proportional to the distance between w\u03b1 and the w \u2032. The reason for bringing in weights is that the probability of worlds w \u2032 less (more) similar to the \u03b1-world w\u03b1 under consideration, should contribute less (more) to the new probability mass of w\u03b1. (Distance and similarity are taken to be inversely proportional in this context.) Building on that idea, we introduce an imaging framework based on weighted distances. The weight functions are defined in terms of inverse-distance functions, which are defined in terms of the pseudo-distance function.\nFirst, we introduce potentially inverse-distance functions \u03b9d : W \u00d7W \u2192 R and propose considering the following seven postulates for such functions. For all w, w \u2032, w \u2032\u2032, w \u2032\u2032\u2032 \u2208W and all pseudo-distance functions d ,\n1. \u03b9d (w, w \u2032) \u2265 0 (Non-negativity) 2. \u03b9d (w, w) = 1 (Identity) 3. \u03b9d (w, w \u2032) = \u03b9d (w \u2032, w) (Symmetry) 4. if d(w, w \u2032) \u2265 d(w \u2032\u2032, w \u2032\u2032\u2032), then \u03b9d (w, w \u2032) \u2264 \u03b9d (w \u2032\u2032, w \u2032\u2032\u2032) (Weak Inversity) 5. if d(w, w \u2032) > d(w \u2032\u2032, w \u2032\u2032\u2032), then \u03b9d (w, w \u2032) < \u03b9d (w \u2032\u2032, w \u2032\u2032\u2032) (Strict Inversity) 6. if d(w, w \u2032) = d(w \u2032\u2032, w \u2032\u2032\u2032), then \u03b9d (w, w \u2032) = \u03b9d (w \u2032\u2032, w \u2032\u2032\u2032) (Equi-distance). 7. if w 6= w \u2032, then \u03b9d (w, w \u2032) < 1 (Faithfulness)\nDefinition 4.1. A weight function is a function \u03b4d : L \u00d7W \u00d7W \u2192 R. We say that postulate non-negativity, identity, symmetry, weak inversity, strict inversity, equi-distance or faithfulness is satisfied by \u03b4d (\u03b1, w, w \u2032) iff the respective postulate is satisfied by \u03b9d (w, w \u2032).\nTo start off with, weight functions should be in the range [0,1] so as to support the notion of the expectation of probability. A weight function should thus be non-negative and have a maximum of 1. Moreover, a world\u2019s probability should carry the maximum weight when compared with itself (identity). Symmetry seems like a very natural property to expect of a weight function, especially given the close relationship that such functions have with distance. Weak inversity seems to be the weakest property that promotes some sort of inversity. It would be a useful distinction to be able to say that a weight function is weakly inverse, but not strictly so. Hence the definition of strict inversity. Knowing whether the property of equi-distance holds also seems useful and interesting. Note that equidistance implies symmetry due to symmetry of the pseudo-distance function, and by logic, equi-distance implies weak\ninversity. Finally, whether a weight function is faithfulness seems like a natural question to ask. And note that identity together with strict inversity implies faithfulness.\nDefinition 4.2. Let b be an epistemic state and \u03b1 a new piece of information. Then the new epistemic state changed with \u03b1 via EDI is defined as\nbEDI\u03b1 := {(w, p) | p = 0 if w 6 \u03b1, else p = 1 \u03b3 \u2211 w \u2032\u2208W b(w \u2032)\u03b4d (\u03b1, w, w \u2032)},\nwhere \u03b3 :=\u2211w\u2208Mod(\u03b1) \u2211w \u2032\u2208W b(w \u2032)\u03b4d (\u03b1, w, w \u2032) is a normalizing factor. We may write EDI\u2217 to indicate that \u03b4d is instantiated as \u03b4\u2217d . For any probabilistic belief change operator \u2206, we say that \u2206 is EDI-compatible if and only if there exists a function \u03b4\u2217d such that b\u2206\u03b1= bEDI\u2217\u03b1 for all b and \u03b1. In the rest of the paper, we shall omit the subscript from \u03b4d as long is it is clear from the context or unnecessary to specify for which pseudo-distance function \u03b4 is defined.\nDefinition 4.3. A weight function is an inverse-distance weight function iff it satisfies postulates 1-4 above.\nConsider the following three properties a weight function might have.\n\u2022 \u2200\u03b1 \u2208 L,\u2200w, w \u2032 \u2208W , if w \u03b1 and w \u2032 \u03b1, then \u03b4(\u03b1, w, w \u2032) 6= 0 (Evidence Relaxation) \u2022 \u2200\u03b1 \u2208 L,\u2200w, w \u2032 \u2208W , if w \u03b1 and w \u2032 6 \u03b1, then \u03b4(\u03b1, w, w \u2032) 6= 0 (Non-evidence Relaxation) \u2022 \u2200\u03b1 \u2208 L,\u2200w, w \u2032 \u2208W , if w \u03b1 and w \u2032 \u03b1 and w 6= w \u2032, then \u03b4(\u03b1, w, w \u2032) = 0 (Retention)\n(In the following, an \u03b1-world is a world satisfying the new evidence \u03b1.) We shall call a weight function e-relaxed iff it satisfies evidence relaxation, and n-e-relaxed iff it satisfies non-evidence relaxation. We shall say that a weight function is relaxed iff it is both e-relaxed and n-e-relaxed. Later, we shall show how \u03b1-worlds \u2018share\u2019 their mass with other \u03b1-worlds during the change process if EDI is applied with an e-relaxed weight function. In such operations, belief mass tends to \u2018spread\u2019 among worlds consistent with the same evidence (after repeated change operations). Bayesian conditioning and the versions of imaging mentioned so far are not like this. In the latter operations, \u03b1-worlds never give up their mass; they are \u2018retentive\u2019. The idea captured by the retention condition says that when collecting probability mass for w (because it is an \u03b1 world), then do not collect anything from other \u03b1 worlds. This rule affects equi-distance, weak and strict inversity. In Section 5.1, the reader will see that n-e-relaxed weight functions are also useful.\nDefinition 4.4. The EDI operation is said to be relaxed or retentive iff it satisfies the relaxation, respectively, retention property.\nObserve that a weight functions which satisfy e-relaxation cannot satisfy retention, and vice versa."}, {"heading": "4.2 Reciprocal Weights", "text": "Rens and Meyer (2015) define the weight to be applied to b(w \u2032) when determining the new probability of w as 1/d(w,w \u2032)\u2211 w \u2032\u2032\u2208W,w \u2032\u2032 6=w 1/d(w,w \u2032\u2032)\n. It is, however, ill-defined because it is undefined when d(w, w \u2032) = 0 or d(w, w \u2032\u2032) = 0 (i.e., when w = w \u2032 or w = w \u2032\u2032).1 We thus adapt their definition based on the reciprocal of distance as follows. Definition 4.5. \u03b4rcp(\u03b1, w, w \u2032) := \u03b7d(w,w \u2032)+\u03b7 , for \u03b7> 0, where \u03b7 is a real number.\nBecause this definition is independent of evidence \u03b1, we shall usually omit mentioning the evidence and simply write \u03b4rcp(w, w \u2032).\nIn the rest of this section, we use vocabulary {q,r } and let \u03b7 = 1, unless stated otherwise. Recall that b1.0 := \u23291,0,0,0\u232a and b.3/.7 := \u23290.3,0.7,0,0\u232a. Two example applications of EDIrcp follow. Example 4.1.\n1Actually, Rens and Meyer (2015) proposed two definitions for weights, one to be applied when \u201cadding worlds\u201d after a belief change and another when \u201cremoving worlds\u201d. In this paper, we use the on for adding worlds.\n\u2022 b0.3/0.7 EDIrcp \u00acq(11) = 0 \u2022 b0.3/0.7 EDIrcp \u00acq(10) = 0 \u2022 b0.3/0.7 EDIrcp \u00acq(01) = 1\u03b3 [0.3\u03b4rcp(01,11)+0.7\u03b4rcp(01,10)+0\u03b4rcp(01,01)+0\u03b4rcp(01,00)] = 1\u03b3 [0.3\u00d7 (1/2)+0.7\u00d7\n(1/3)] = 1\u03b3 [0.383\u0304] = 0.46\n\u2022 b0.3/0.7 EDIrcp \u00acq(00) = 1\u03b3 [0.3\u03b4rcp(00,11)+0.7\u03b4rcp(00,10)+0\u03b4rcp(00,01)+0\u03b4rcp(00,00)] = 1\u03b3 [0.3\u00d7 (1/3)+0.7\u00d7 (1/2)] = 1\u03b3 [0.45] = 0.54\nExample 4.2.\n\u2022 b1.0 EDIrcp \u00acq(11) = 0 \u2022 b1.0 EDIrcp \u00acq(10) = 0 \u2022 b1.0 EDIrcp \u00acq(01) = 1\u03b3 [1\u03b4rcp(01,11)+0\u03b4rcp(01,10)+0\u03b4rcp(01,01)+0\u03b4rcp(01,00)] = 1\u03b3 [1\u00d7 (1/2)] = 1\u03b3 [0.5] = 0.6\n\u2022 b1.0 EDIrcp \u00acq(00) = 1\u03b3 [1\u03b4rcp(00,11)+0\u03b4rcp(00,10)+0\u03b4rcp(00,01)+0\u03b4rcp(00,00)] = 1\u03b3 [1\u00d7 (1/3)] = 1\u03b3 [0.3\u0304] = 0.4\nProposition 4.1. \u03b4rcp is an inverse-distance weight function, and also satisfies strict inversity, equi-distance and faithfulness, and is relaxed.\nProof. For all w, w \u2032, w \u2032\u2032, w \u2032\u2032\u2032 \u2208W : Non-negativity: d(w, w \u2032) \u2265 0 and \u03b7> 0. Thus, \u03b4rcp(w, w \u2032) = \u03b7/(d(w, w \u2032)+\u03b7) > 0. Identity: By the identity constraint of d , d(w, w) = 0 for all w \u2208W . Hence, \u03b4rcp(w, w) = \u03b7/(d(w, w)+\u03b7) = 1. Inversity: Assume d(w, w \u2032) > d(w \u2032\u2032, w \u2032\u2032\u2032). Then \u03b4rcp(w, w \u2032) = \u03b7/(d(w, w \u2032)+\u03b7) < \u03b7/(d(w \u2032\u2032, w \u2032\u2032\u2032)+\u03b7) = \u03b4rcp(w \u2032\u2032, w \u2032\u2032\u2032). This implies that \u03b4rcp is weakly and strictly inverse. Equi-distance: Assume d(w, w \u2032) = d(w \u2032\u2032, w \u2032\u2032\u2032). Then \u03b4rcp(w, w \u2032) = \u03b7/(d(w, w \u2032) + \u03b7) = \u03b7/(d(w \u2032\u2032, w \u2032\u2032\u2032) + \u03b7 = \u03b4rcp(w \u2032\u2032, w \u2032\u2032\u2032). Symmetry is implied by equi-distance. Faithfulness: Assume w 6= w \u2032. Then, by the faithfulness of d , d(w, w \u2032) > 0. Thus, \u03b4rcp(w, w \u2032) = \u03b7/(d(w, w \u2032)+\u03b7) < 1. For all w, w \u2032 \u2208W , \u03b7/(d(w, w \u2032)+\u03b7) > 0. Relaxation (evidence and non-evidence) is thus satisfied."}, {"heading": "4.3 Difference Weights", "text": "A new definition with a similar meaning follows.It is also inversely proportional to distance. It is based on the difference between some particular applicable distance and the maximum distance.\nDefinition 4.6. \u03b4dfr(\u03b1, w, w \u2032) := d max+\u03b7\u2212d(w,w \u2032)d max+\u03b7 , for \u03b7 > 0, where \u03b7 is a real number and d max := max{d(w, w \u2032) | w, w \u2032 \u2208W }.\nBecause this definition is independent of evidence \u03b1, we shall usually omit mentioning the evidence and simply write \u03b4dfr(w, w \u2032). Two examples applications of EDIdfr follow.\nExample 4.3.\n\u2022 b0.3/0.7 EDIdfr \u00acq(11) = 0 \u2022 b0.3/0.7 EDIdfr \u00acq(10) = 0 \u2022 b0.3/0.7EDIdfr\u00acq(01) = 1\u03b3 [0.3\u03b4dfr(01,11)+0.7\u03b4dfr(01,10)+0\u03b4dfr(01,01)+0\u03b4dfr(01,00)] = 1\u03b3 [0.3\u00d7(3\u2212d(01,11))/3+\n0.7\u00d7 (3\u2212d(01,10))/3] = 1\u03b3 [0.3\u00d7 (2/3)+0.7\u00d7 (1/3)] = 1\u03b3 [0.43\u0304] = 0.43\u0304\n\u2022 b0.3/0.7 EDIdfr \u00acq(00) = 1\u03b3 [0.3\u03b4dfr(00,11)+ 0.7\u03b4dfr(00,10)+ 0\u03b4dfr(00,01)+ 0\u03b4dfr(00,00)] = 1\u03b3 [0.3\u00d7 (1/3)+ 0.7\u00d7 (2/3)] = 1\u03b3 [0.56\u0304] = 0.56\u0304\nExample 4.4.\n\u2022 b1.0 EDIdfr \u00acq(11) = 0 \u2022 b1.0 EDIdfr \u00acq(10) = 0 \u2022 b1.0EDIdfr\u00acq(01) = 1\u03b3 [1\u03b4dfr(01,11)+0\u03b4dfr(01,10)+0\u03b4dfr(01,01)+0\u03b4dfr(01,00)] = 1\u03b3 [1\u00d7(3\u2212d(01,11))/3] = 1\u03b3 [1\u00d7\n(2/3)] = 0.6\u0304 \u2022 b1.0 EDIdfr \u00acq(00) = 1\u03b3 [1\u03b4dfr(00,11)+0\u03b4dfr(00,10)+0\u03b4dfr(00,01)+0\u03b4dfr(00,00)] = 1\u03b3 [1\u00d7 (1/3)] = 0.3\u0304 If \u03b7 were allowed to equal zero, there would be cases when EDI-belief-change is undefined for \u03b4 instantiated as \u03b4dfr . For instance, suppose b(10) = 1 and the evidence is \u00acq \u2227 r . Using Hamming distance for d , \u03b4dfr(01,10) = 0. Hence, b EDI\u00acq\u2227r (01) = 1\u03b3 [0+b(10)\u03b4dfr(01,10)+0+0] = 1\u03b30, which is undefined because \u03b3= 0. But as soon as \u03b7> 0, \u03b4dfr(01,10) > 0 and b EDI \u00acq \u2227 r (01) = 1. Proposition 4.2. \u03b4dfr is an inverse-distance weight function, and also satisfies strict inversity, equi-distance and faithfulness, and is relaxed.\nProof. For all w, w \u2032, w \u2032\u2032, w \u2032\u2032\u2032 \u2208W : Non-negativity: By the definition of d max, d max +\u03b7\u2212d(w, w \u2032) \u2265 0, for all w, w \u2032 \u2208W . And due to the faithfulness condition of the pseudo-distance function, d max > 0. Thus, d max+\u03b7\u2212d(w,w \u2032)d max+\u03b7 \u2265 0. Identity: By the identity constraint of d , d(w, w) = 0 for all w \u2208W . Hence, d max+\u03b7\u2212d(w,w)d max+\u03b7 = 1. Equi-distance: Assume d(w, w \u2032) = d(w \u2032\u2032, w \u2032\u2032\u2032). Then d max+\u03b7\u2212d(w,w \u2032)d max+\u03b7 = d max+\u03b7\u2212d(w \u2032\u2032,w \u2032\u2032\u2032) d max+\u03b7 .\nSymmetry is implied by equi-distance. Inversity: Assume d(w, w \u2032) > d(w \u2032\u2032, w \u2032\u2032\u2032). Then \u03b4dfr(w, w \u2032) = d max+\u03b7\u2212d(w,w \u2032)d max+\u03b7 < d max+\u03b7\u2212d(w \u2032\u2032,w \u2032\u2032\u2032) d max+\u03b7 = \u03b4dfr(w \u2032\u2032, w \u2032\u2032\u2032). This implies that \u03b4dfr is weakly and strictly inverse. Faithfulness: Assume w 6= w \u2032. Then, by the faithfulness of d , d(w, w \u2032) > 0. Thus, \u03b4dfr(w, w \u2032) = d max+\u03b7\u2212d(w,w \u2032)d max+\u03b7 < 1. For all w, w \u2032 \u2208W , d max +\u03b7\u2212d(w, w) > 0. Relaxation (evidence and non-evidence) is thus satisfied."}, {"heading": "4.4 Bayesian Conditioning i.t.o. EDI", "text": "Bayesian conditioning can be nicely simulated as an EDI operator. Let \u03b4BC be defined as follows.\n\u03b4BC (\u03b1, w, w \u2032) := {\n1 if w = w \u2032 0 otherwise\nBecause the definition of \u03b4BC is independent of evidence \u03b1, we shall usually omit mentioning the evidence and simply write \u03b4BC (w, w \u2032).\nProposition 4.3. bBC\u03b1= bEDIBC \u03b1 iff b(\u03b1) > 0. That is, BC is EDI-compatible iff b(\u03b1) > 0. Proof.\nbBC\u03b1(w) = b(w,\u03b1) b(\u03b1) ,b(\u03b1) > 0\n= {\n0 if w 6 \u03b1 b(w) b(\u03b1) otherwise\n= {\n0 if w 6 \u03b1 1 \u03b3b(w) otherwise, where \u03b3= b(\u03b1)\n= {\n0 if w 6 \u03b1 1 \u03b3 \u2211 w \u2032\u2208W b(w \u2032)\u03b4BC (w, w \u2032) otherwise,\nwhere \u03b3= \u2211 w\u2208Mod(\u03b1) \u2211 w \u2032\u2208W b(w \u2032)\u03b4BC (w, w \u2032)\nimplying that bBC\u03b1= {(w, p) | p = 0 if w 6 \u03b1, else p = 1\u03b3 \u2211 w \u2032\u2208W b(w \u2032)\u03b4BC (w, w \u2032)} = bEDIBC \u03b1, for b(\u03b1) > 0.\nProposition 4.4. \u03b4BC is an inverse-distance weight function satisfying equi-distance, symmetry, retention and faithfulness, but not strict inversity.\nProof. For all w, w \u2032, w \u2032\u2032, w \u2032\u2032\u2032 \u2208W : Clearly, \u03b4BC (w, w \u2032) is non-negative. Identity follows directly from the definition. Weak Inversity: Assume d(w, w \u2032) > d(w \u2032\u2032, w \u2032\u2032\u2032). There are two cases to consider: Either d(w, w \u2032) > d(w \u2032\u2032, w \u2032\u2032\u2032) = 0 or d(w, w \u2032) > d(w \u2032\u2032, w \u2032\u2032\u2032) 6= 0. Assume d(w, w \u2032) > d(w \u2032\u2032, w \u2032\u2032\u2032) = 0. Then w \u2032\u2032 = w \u2032\u2032\u2032 and w 6= w \u2032, in which case, 0 = \u03b4BC (w, w \u2032) < \u03b4BC (w \u2032\u2032, w \u2032\u2032\u2032) = 1. Now assume d(w, w \u2032) > d(w \u2032\u2032, w \u2032\u2032\u2032) 6= 0. Then w \u2032\u2032 6= w \u2032\u2032\u2032 and w 6= w \u2032, in which case, \u03b4BC (w, w \u2032) = \u03b4BC (w \u2032\u2032, w \u2032\u2032\u2032) = 0. By combining the two cases, one sees that the desired result follows. \u03b4BC is thus an inverse-distance weight function.\nEqui-distance: Assume d(w, w \u2032) = d(w \u2032\u2032, w \u2032\u2032\u2032). There are two cases to consider: Either d(w, w \u2032) = d(w \u2032\u2032, w \u2032\u2032\u2032) = 0 or d(w, w \u2032) = d(w \u2032\u2032, w \u2032\u2032\u2032) 6= 0. Assume d(w, w \u2032) = d(w \u2032\u2032, w \u2032\u2032\u2032) = 0. Then w = w \u2032 and w \u2032\u2032 = w \u2032\u2032\u2032, in which case, \u03b4BC (w, w \u2032) = \u03b4BC (w \u2032\u2032, w \u2032\u2032\u2032) = 1. Now assume d(w, w \u2032) = d(w \u2032\u2032, w \u2032\u2032\u2032) 6= 0. Then w 6= w \u2032 and w \u2032\u2032 6= w \u2032\u2032\u2032, in which case, \u03b4BC (w, w \u2032) = \u03b4BC (w \u2032\u2032, w \u2032\u2032\u2032) = 0.\nSymmetry is implied by equi-distance. Faithfulness follows directly from the definition. Assume again that d(w, w \u2032) > d(w \u2032\u2032, w \u2032\u2032\u2032) 6= 0. Then w \u2032\u2032 6= w \u2032\u2032\u2032 and w 6= w \u2032, in which case, \u03b4BC (w, w \u2032) =\n\u03b4BC (w \u2032\u2032, w \u2032\u2032\u2032) = 0. Thus strict inversity does not hold. Proposition 4.5. \u03b4BC is retentive.\nProof. For all w, w \u2032, w \u2032\u2032, w \u2032\u2032\u2032 \u2208W : Assume w \u03b1 and w \u2032 \u03b1 and w 6= w \u2032. Then, immediately, by the definition of \u03b4BC , \u03b4BC (w, w \u2032) = 0."}, {"heading": "4.5 Lewis Imaging i.t.o. EDI", "text": "Lewis imaging can be simulated as an EDI operator, but not as cleanly as BC. Let \u03b4LI be defined as follows.\n\u03b4LI (\u03b1, w, w \u2032) :=  x if w 6 \u03b1 1 if w \u2208 Min(\u03b1, w \u2032,d LI ) 0 otherwise,\nwhere x is fixed between 0 and 1, inclusive, and pseudo-distance function d LI induces a mapping from worlds to total orders (instead of the weaker total pre-orders).\nProposition 4.6. bLI\u03b1= bEDILI \u03b1. That is, LI is EDI-compatible. Proof. Let w 6 \u03b1. Then, independent of the definition of \u03b4LI , bLI\u03b1(w) = bEDILI \u03b1(w) = 0.\nNow let w \u03b1. Then,\nbLI\u03b1(w) = \u2211 w \u2032\u2208W\nw \u2032\u03b1=w\nb(w \u2032)\n= \u2211 w \u2032\u2208W b(w \u2032)\u03b4LI\u2212(w, w \u2032),\nwhere\n\u03b4LI\u2212(w, w \u2032) := {\n1 if w \u2032\u03b1 = w 0 otherwise\n= {\n1 if w \u2208 Min(\u03b1, w \u2032,d LI ) 0 otherwise\nNoting that the first line of the definition of \u03b4LI is applicable only if w 6 \u03b1, then the result follows when combining the cases when w 6 \u03b1 and w \u03b1.\nWhereas Proposition 4.6 says that there exists a weight function for simulating Lewis imaging with EDI, Proposition 4.7 says that the function cannot be inverse-distance.\nProposition 4.7. There exists no inverse-distance weight function \u03b4\u2217 for which bLI\u03b1= bEDI\u2217\u03b1. Proof. We provide an example for which weak inversity must fail. \u03b4LI is thus not an inverse-distance weight function for this example, nor in general.\nRecall that d LI is such that for every \u03b1, for each of the worlds, a unique closest \u03b1-world can be identified. Observe that EDILI is retentive: Recall the retention property: if w \u03b1 and w \u2032 \u03b1 and w 6= w \u2032, then \u03b4LI (\u03b1, w, w \u2032) = 0. Directly, the first line of the definition of \u03b4LI is not applicable, and it is impossible for w \u2208 Min(\u03b1, w \u2032,d LI ) and w \u2032 \u03b1 and w 6= w \u2032, making the second line inapplicable. Only the third line is applicable, and retention thus holds.\nNow let d LI (w, w \u2032) = d LI (w \u2032\u2032, w \u2032\u2032\u2032). And let w, w \u2032\u2032, w \u2032\u2032\u2032 \u03b1. Then Min(w,\u03b1,d LI ) = {w}, Min(w \u2032\u2032,\u03b1,d LI ) = {w \u2032\u2032}, Min(w \u2032\u2032\u2032,\u03b1,d LI ) = {w \u2032\u2032\u2032} and let Min(w \u2032,\u03b1,d LI ) = {w}. Note that \u03b4LI(\u03b1, w, w \u2032) must equal 1 (second line of definition) and by retention, \u03b4LI (\u03b1, w \u2032\u2032, w \u2032\u2032\u2032) = 0. Therefore, d LI (w, w \u2032) \u2265 d LI (w \u2032\u2032, w \u2032\u2032\u2032), but \u03b4LI (\u03b1, w, w \u2032) 6\u2264 \u03b4LI (\u03b1, w \u2032\u2032, w \u2032\u2032\u2032). Proposition 4.8. \u03b4LI is retentive.\nProof. Assume w, w \u2032 \u03b1 and w 6= w \u2032. Only the second and third lines of the definition of \u03b4LI are applicable. We know that whenever w \u2032\u2032 \u03b1, then Min(w \u2032\u2032,\u03b1,d LI ) = {w \u2032\u2032}. Hence, due to w 6= w \u2032, the second line cannot be applicable. Therefore, \u03b4LI (\u03b1, w, w \u2032) = 0."}, {"heading": "4.6 Generalized Imaging i.t.o. EDI", "text": "Generalized imaging can be simulated as an EDI operator, and where LI is always retentive, GI is only retentive under a reasonable condition. Let \u03b4GI be defined as follows.\n\u03b4GI (\u03b1, w, w \u2032) :=  1 if w = w \u2032 and w 6 \u03b1 1/|Min(\u03b1, w \u2032,d)| if w \u2208 Min(\u03b1, w \u2032,d) 0 otherwise\nProposition 4.9. bGI\u03b1= bEDIGI \u03b1. That is, GI is EDI-compatible. Proof. Let w 6 \u03b1. Then, independent of the definition of \u03b4GI , bGI\u03b1(w) = bEDIGI \u03b1(w) = 0.\nNow let w \u03b1. Then,\nbGI\u03b1(w) = \u2211 w \u2032\u2208W\nw\u2208Min(\u03b1,w \u2032,d)\nb(w \u2032)/|Min(\u03b1, w \u2032,d)|\n= \u2211 w \u2032\u2208W b(w \u2032)\u03b4GI\u2212(w, w \u2032),\nwhere\n\u03b4GI\u2212(w, w \u2032) := {\n1/|Min(\u03b1, w \u2032,d)| if w \u2208 Min(\u03b1, w \u2032,d) 0 otherwise\nNoting that the first line of the definition of \u03b4GI is applicable only if w 6 \u03b1, then the result follows when combining the cases when w 6 \u03b1 and w \u03b1.\nFor example, the reader can confirm that b0.3/0.7GI\u00acq = b0.3/0.7EDIGI \u00acq and b1.0GI\u00acq = b1.0EDIGI \u00acq . Whereas Proposition 4.9 says that there exists a weight function for simulating generalized imaging with EDI,\nProposition 4.10 says that the function cannot be inverse-distance.\nProposition 4.10. There exists no inverse-distance weight function \u03b4\u2217 for which bGI\u03b1= bEDI\u2217\u03b1. Proof. Lewis imaging is a specialization of generalized imaging. The proposition is thus entailed by Proposition 4.7.\nLemma 4.1. Let w \u03b1. Then, \u2200w \u2208W,Min(w,\u03b1,d) = {w} iff d is faithful.\nProof. Recall that Min(\u03b1, w,d) = {w \u2032 \u03b1 | \u2200w \u2032\u2032 \u03b1,d(w \u2032, w) \u2264 d(w \u2032\u2032, w)}. Assume d is faithful. Then for all w, w \u2032 \u2208W , if w 6= w \u2032, then d(w, w \u2032) > 0. By identity of d , d(w, w) = 0. Hence, Min(w,\u03b1,d) = {w}. Assume d is not faithful. Then there exists a pair of worlds w, w \u2032 \u2208 W , such that if w 6= w \u2032, then d(w, w \u2032) = 0. Hence, {w, w \u2032} \u2286 Min(w,\u03b1,d). Therefore, it is not the case that Min(w,\u03b1,d) = {w}. Proposition 4.11. \u03b4GId is retentive iff d is faithful.\nProof. Assume d is faithful. Assume w, w \u2032 \u03b1 and w 6= w \u2032. Only the second and third lines of the definition of \u03b4GI are potentially applicable. By Lemma 4.1, we know that whenever w \u03b1, then Min(w \u2032,\u03b1,d) = {w} such that w = w \u2032. Hence, due to our assumption that w 6= w \u2032, the second line cannot be applicable. Therefore, \u03b4GI (\u03b1, w, w \u2032) = 0.\nAssume d is not faithful. Assume w, w \u2032 \u03b1 and w 6= w \u2032. Only the second and third lines of the definition of \u03b4GI are potentially applicable. By Lemma 4.1, we know that whenever w \u03b1, then {w, w \u2032} \u2286 Min(w \u2032,\u03b1,d) such that w 6= w \u2032. Hence, due to our assumption that w 6= w \u2032, the second line might be applicable. Therefore, it could be that \u03b4GI (\u03b1, w, w \u2032) = 1/|Min(\u03b1, w \u2032,d) > 0.\nFaithfulness is a reasonable property to expect of a distance function. \u03b4GId is thus retentive under reasonable conditions."}, {"heading": "4.7 Discussion", "text": "To summarize, \u03b4rcp and \u03b4dfr are relaxed, and \u03b4BC and \u03b4LI are retentive, and \u03b4GI is retentive iff the associated pseudodistance function is faithful.\nLet \u03b4rlx be \u03b4rcp or \u03b4dfr . Let \u03b1 be a particular piece of evidence and bt the belief state resulting from the t-th repeated application of EDIrlx on the resulting belief states for \u03b1. That is, b1 = bEDIrlx\u03b1, b2 = b1EDIrlx\u03b1, and so on. By running multiple experiments on a computer, we noticed that, as t increases, bt settles on a particular belief state, that is, bt\u22121 \u2248 bt . (Belief states had eight worlds.) We ran 100 trials for each of the four combinations of choices for \u03b4rlx and \u03b7 = 1 or \u03b7 = 0.0001. For each trial, an initial belief state and evidence was chosen randomly. \u03b1 \u2261 > and \u03b1 \u2261 \u22a5 were ignored. Per trial, operation EDI was applied to the resulting belief state ten times with the \u03b1 selected for that trial. The difference between the probabilities of a world at successive applications of EDI were recorded, and the difference of all worlds averaged. See Figure 1. The figure shows the average for the 100 trials of the average difference at each application of the change operation. Note how the differences asymptotically decrease. Note that these results do not imply that belief states become uniform distributions over \u03b1-worlds. In fact, distributions are typically not uniform; distributions seem to be dictated by the mutual reinforcement of \u03b1-world probabilities and their corresponding distances from each other. However, whenever exactly two worlds model \u03b1, the probability is eventually divided exactly (uniformly) between the two worlds.\nProposition 4.12. Let \u03b1 be a particular piece of evidence and bt the belief state resulting from the t-th repeated application of EDIrtv on the resulting belief states for \u03b1, where \u03b4rtv is a retentive inverse-distance weight function. That is, b1 = bEDIrtv\u03b1, b2 = b1EDIrtv\u03b1, and so on. Then bt = b1 for all t > 1. Proof. By definition of EDIrtv, if w 6 \u03b1, then b1(w) = 0, that is, if b1(w) > 0, then w \u03b1. Therefore, we are only interested in the potential change in probability of \u03b1-worlds. Hence, we consider only \u03b4rtv(w, w \u2032) such that w \u03b1. And because w \u2032 contributes no mass to w if w \u2032 6 \u03b1, we consider only \u03b4rtv(w, w \u2032) such that w, w \u2032 \u03b1. Then by retention and identity of an inverse-distance weight function, \u03b4rtv(w, w \u2032) = 1 iff w = w \u2032, else it equals 0. Hence, for all w \u03b1, bt (w) =\u2211w \u2032\u2208W bt\u22121(w \u2032)\u03b4rtv(w, w \u2032) = bt\u22121(w) for all t > 1.\nThe difference between retention and relaxation seems important, from the perspective of (formal) epistemology. Suppose w1 \u03b1 and w2 \u03b2 have probabilities 0.4, respectively, 0.6. Now if \u03b1\u2227\u03b2 is successively observed, then according to, for instance, Bayesian conditioning and Lewis imaging, the probabilities of w1 and w2 will not change. We argue that there are situations when their probabilities should be allowed to change. One could argue that if \u03b1 and \u03b2 are always observed together, then the probabilities of w1 and w2 should become equal. To put it differently, the fact that the same information is continually received should make a difference to the spread of the likelihood of the constituent parts (atoms) of the information. Nonetheless, information received in a static environment has a different flavor to information received in a dynamic environment (giving rise to belief revision, resp., belief update): Repeated observation of the same piece of information \u03b1\u2032 should not change beliefs therein, beyond the first revision.\nThe first in the series of observations revises beliefs, but subsequent observations of \u03b1\u2032 have no effect because it is \u2018old news\u2019/already learnt. In this sense, revision corresponds to retentive belief change. On the other hand, when the same signal is observed in the environment, every new observation is a further confirmation of the truth of \u03b1\u2032, thus modifying one\u2019s belief in the atoms of \u03b1\u2032 with every new observation instance (of the same \u03b1\u2032). In this sense, update corresponds to evidence-relaxed belief change."}, {"heading": "5 EDI for Revision vs. EDI for Update", "text": "In this section, we couch all belief change operations as EDI. For each of revision and update, EDI will be specialized into two proposed definitions. One of the specializations in each case will have the following pattern: Apply the classical operation to determine the newly believed worlds, and then use EDI to determine a probability distribution over them. The other specialization in each case will be a more direct use of EDI. We shall also check, for each of the four operations, which properties the corresponding weight function satisfies. We end this section with a discussion of what it takes to translate classical belief change as EDI in terms of uniform probability distributions.\nKatsuno and Mendelzon (1992) use an example involving a room with a table, a book and a magazine in it to illustrate the difference between revision and update. Suppose we only know that either the book is on the table or the magazine is on the table, but not both. Let book mean the book is on the floor and mag mean the magazine is on the floor. Then our belief state can reasonably be represented as b = \u23290,0.5,0.5,0\u232a, that is b(book \u2227\u00acmag) = b(\u00acbook\u2227mag) = 0.5 and b(book\u2227mag) = b(\u00acbook\u2227\u00acmag) = 0. Katsuno and Mendelzon (1992) argued that after revision with book, one should believe book\u2227\u00acmag. We thus want\nbEDI\u25e6 book = \u23290,1,0,0\u232a,\nwhere \u25e6 indicates revision. And they argued that after update with book, one should believe book. We thus want\nbEDI\u00a6 book = \u23290.5,0.5,0,0\u232a,\nwhere \u00a6 indicates update. This is the case when \u25e6 is BC, and when \u00a6 is rcp or dfr after an infinite number of EDI\u00a6 with book. However, in this example, b(book) > 0. The question is, What should probabilistic revision (and update) correspond to when b(book) = 0? For instance, what if \u03b1 = book \u2194 mag, given the agent currently believes book \u2194 \u00acmag? Furthermore, we would like the same operation to be applicable whether or not the evidence contradicts current beliefs."}, {"heading": "5.1 Probabilistic Revision via Classical Revision", "text": "This approach is to determine the new knowledge base exactly as one would in classical belief revision, and then to assign probabilities to the newly believed worlds.\nLet W b := {w \u2208W | (w, p) \u2208 b, p 6= 0}.\nLet \u03c8b be a sentence modeled by all worlds in W b and no other worlds. Let \u03b4\u00e0ClsRev be defined as follows.\n\u03b4 \u00e0ClsRev(\u03b1, w, w \u2032) :=  1 if w = w \u2032 \u03b4(\u03b1, w, w \u2032) if w \u2208 Mod(\u03c8b \u25e6\u03b1) 0 otherwise,\nwhere \u25e6 is some (acceptable) revision operator and \u03b4 is a retentive inverse-distance weight function. Unfortunately, \u03b4\u00e0ClsRev is not well defined, because bEDI\u00e0ClsRev\u03b1 might not be a belief state. For example, suppose there are four worlds w1, w2, w3 and w4, where b(w1) = 1 and only w4 \u03b1 (w1, w2, w3 6 \u03b1). Let \u03b4 be an inversedistance weight function such that \u03b4(\u03b1, w1, w4) = \u03b4(\u03b1, w4, w1) = 0. Then, intuitively, we want bEDI\u00e0ClsRev\u03b1(w4) = 1. By definition, bEDI\u00e0ClsRev\u03b1(wi ) = 0 for i = 1,2,3. We know that Mod(\u03c8b \u25e6\u03b1) = Mod(\u03b1) = {w4}. To compute bEDI\n\u00e0ClsRev\u03b1(w4), the second line of the definition of \u03b4\u00e0ClsRev is applicable, hence, bEDI\n\u00e0ClsRev\u03b1(w4) = 1 \u03b3 \u2211 w \u2032\u2208W b(w \u2032)\u03b4(\u03b1, w4, w \u2032)\n= 1 \u03b3\n( b(w1)\u03b4(\u03b1, w4, w1)+b(w2)\u03b4(\u03b1, w4, w2)+b(w3)\u03b4(\u03b1, w4, w3)+b(w4)\u03b4(\u03b1, w4, w4) ) = 1\n\u03b3\n( 1\u00d70+0\u00d7?+0\u00d7?+0\u00d7?).\nThis problem would not occur if \u03b4(\u03b1, w1, w4) = 0 were not allowed. We thus define \u03b4ClsRev as\n\u03b4ClsRev(\u03b1, w, w \u2032) :=  1 if w = w \u2032 \u03b4(\u03b1, w, w \u2032) if w \u2208 Mod(\u03c8b \u25e6\u03b1) 0 otherwise,\nwhere \u25e6 is some (acceptable) revision operator and \u03b4 is a non-evidence (n-e-) relaxed and retentive inverse-distance weight function.\nProposition 5.1. \u03b4ClsRev is retentive.\nProof. Assume w, w \u2032 \u03b1 and w 6= w \u2032. Then only the second and third lines of the definition of \u03b4ClsRev are applicable. If w 6\u2208 Mod(\u03c8b \u25e6\u03b1), then the third line would be applicable, making \u03b4ClsRev(\u03b1, w, w \u2032) = 0. Thus, the proposition\u2019s veracity depends only on the value of \u03b4(\u03b1, w, w \u2032). And due to the condition (\u201cif w, w \u2032 \u03b1 and w 6= w \u2032\u201d) in the first line of the definition of \u03b4, \u03b4ClsRev(\u03b1, w, w \u2032) = \u03b4\u2032(\u03b1, w, w \u2032) = 0. Proposition 5.2. \u03b4ClsRev satisfies non-negativity and identity.\nProof. Non-negativity and identity follow directly from the definition of \u03b4ClsRev.\nProposition 5.3. \u03b4ClsRev does not satisfy symmetry, weak inversity, strong inversity nor equi-distance.\nProof. Suppose the vocabulary has three atoms, the distance function is Hamming and\n\u03b4(\u03b1, w, w \u2032) := {\n0 if w, w \u2032 \u03b1 and w 6= w \u2032 \u03b4rcp(\u03b1, w, w \u2032) otherwise,\nwith \u03b7 = 1. Note that \u03b4 is an n-e-relaxed and retentive inverse-distance weight function. Assume Mod(\u03c8b) = {101,001,000} and 111,110,011,010 \u03b1 and all other worlds do not model \u03b1. Finally, assume that \u25e6 is defined such that Mod(\u03c8b \u25e6\u03b1) = {111,011,010}. Note that Mod(\u03c8b \u25e6\u03b1) \u2286 Mod(\u03b1).\nThen d(010,000) = d(110,010) = 1, \u03b4ClsRev(\u03b1,010,000) = \u03b4(\u03b1,010,000) = \u03b4rcp(\u03b1,010,000) = 1/2 and \u03b4ClsRev(\u03b1,110,010) = 0. Therefore, d(010,000) \u2265 d(110,010), but \u03b4ClsRev(\u03b1,010,000) 6\u2264 \u03b4ClsRev(\u03b1,110,010). Hence, weak inversity fails for \u03b4ClsRev. This case also proves that equi-distance fails.\nDue to strict inversity implying weak inversity, by contraposition, strict inversity fails. To check symmetry, observe that \u03b4ClsRev(\u03b1,000,010) = 0 because 000 6= 010 and 000 6\u2208 Mod(\u03c8b \u25e6\u03b1). But as we see\nabove, \u03b4ClsRev(\u03b1,010,000) = 1/2. Thus, symmetry fails. Corollary 5.1. Because \u03b4ClsRev is not symmetric or weakly inverse, it is not an inverse-distance weight function.\nProposition 5.4. \u03b4ClsRev is faithful iff \u03b4 is.\nProof. Assume w 6= w \u2032. Assume \u03b4 is not faithful. It could thus happen that \u03b4(\u03b1, w, w \u2032) = 1. Next, assume that w \u2208 Mod(\u03c8b \u25e6\u03b1) and w \u2032 6 \u03b1, implying that \u03b4ClsRev(\u03b1, w, w \u2032) = \u03b4(\u03b1, w, w \u2032). Hence, \u03b4ClsRev is not faithful. Now assume \u03b4 is faithful. Only the second and third lines are applicable. In both cases, \u03b4ClsRev(\u03b1, w, w \u2032) < 1 (particularly, \u03b4(\u03b1, w, w \u2032) < 1, becausew 6= w \u2032)."}, {"heading": "5.2 Probabilistic Revision with EDI Directly", "text": "The approach here is that revision should satisfy the retentive property. Let\n\u03b4=0(\u03b1, w, w \u2032) :=  1 if w = w \u2032 \u03b4(\u03b1, w, w \u2032) if w 6 \u03b1 or w \u2032 6 \u03b1, else 0 otherwise\nwhere \u03b4 is an inverse-distance weight function. Note that \u03b4=0(\u03b1, w, w \u2032) = 0 whenever w, w \u2032 \u03b1 and w 6= w \u2032 (retention). Proposition 5.5. \u03b4=0(\u03b1, w, w \u2032) = 0 does not satisfy weak inversity. Proof. Assume d(w, w \u2032) = d(w \u2032\u2032, w \u2032\u2032\u2032) 6= 0. Then, by the identity condition of d , w 6= w \u2032 and w \u2032\u2032 6= w \u2032\u2032\u2032. Assume w \u2032 6 \u03b1, and w \u2032\u2032, w \u2032\u2032\u2032 \u03b1. Then \u03b4=0(\u03b1, w, w \u2032) = \u03b4(\u03b1, w, w \u2032) and \u03b4=0(\u03b1, w \u2032\u2032, w \u2032\u2032\u2032) = 0. Now it could happen that \u03b4(\u03b1, w, w \u2032) > 0, in which case, d(w, w \u2032) \u2265 d(w \u2032\u2032, w \u2032\u2032\u2032), but \u03b4=0(\u03b1, w, w \u2032) 6\u2264 \u03b4=0(\u03b1, w \u2032\u2032, w \u2032\u2032\u2032).\n\u03b4=0 does not work as desired when b(\u03b1) > 0 (\u03b4 is instantiated as \u03b4dfr and \u03b7= 1):\nbEDI =0 book (11) = 1\n\u03b3\n[ b(10)\u03b4=0(\u03b1,11,10)+\nb(01)\u03b4=0(\u03b1,11,01) ]\n= 1 \u03b3\n[ 0.5\u00d70+0.5\u00d7 2+1\u22121 2+1 ]\n= 1 \u03b3 [2 3 ] = 0.5\nbEDI =0 book (10) = 1\n\u03b3\n[ b(10)\u03b4=0(\u03b1,10,10)+\nb(01)\u03b4=0(\u03b1,10,01) ]\n= 1 \u03b3\n[ 0.5\u00d71+0.5\u00d7 2+1\u22122 2+1 ]\n= 1 \u03b3 [2 3 ] = 0.5\nWe thus propose to use \u03b4DctRev in general for probabilistic belief revision:\n\u03b4DctRev(\u03b1, w, w \u2032) := { \u03b4BC (w, w \u2032) if b(\u03b1) > 0 \u03b4=0(\u03b1, w, w \u2032) otherwise\nThe following definition is derived from the one above.\nDefinition 5.1. \u03b4DctRev(\u03b1, w, w \u2032) := { \u03b4BC (w, w \u2032) if b(\u03b1) > 0 \u03b4=0(\u03b1, w, w \u2032) otherwise\nwhere \u03b4 is a non-evidence (n-e-) relaxed and an inverse-distance weight function.\nThe reason why \u03b4 is n-e-relaxed is similar to the reason why \u03b4 of \u03b4ClsRev is. Recall that b(book) 6= 0. Then\nbEDI DctRev book (11) = 1\n\u03b3\n[ b(10)\u03b4DctRev(\u03b1,11,10)+\nb(01)\u03b4DctRev(\u03b1,11,01) ]\n= 1 \u03b3\n[ 0.5\u00d70+0.5\u00d70 ] = 0\nbEDI DctRev book (10) = 1\n\u03b3\n[ b(10)\u03b4DctRev(\u03b1,10,10)+\nb(01)\u03b4DctRev(\u03b1,10,01) ]\n= 1 \u03b3\n[ 0.5\u00d71+0.5\u00d70 ] = 1\nAnd EDIDctRev can also be used in cases where b(\u03b1) = 0: Let b = \u23290.3,0.7,0,0\u232a and let \u03b1=\u00acbook. Observe that \u03b1 contradicts the agent\u2019s current belief state b. Let\n\u03b4(\u03b1, w, w \u2032) := {\n0 if w, w \u2032 \u03b1 and w 6= w \u2032 \u03b4dfr(\u03b1, w, w \u2032) otherwise,\nwith \u03b7= 0.1. Note that \u03b4 is an n-e-relaxed and retentive inverse-distance weight function.\nbEDI DctRev \u00acbook (01) = 1\n\u03b3\n[ b(11)\u03b4DctRev(\u03b1,01,11)+\nb(10)\u03b4DctRev(\u03b1,01,10) ]\n= 1 \u03b3\n[ 0.3\u03b4dfr(01,11)+0.7\u03b4dfr(01,10) ] = 1\n\u03b3\n[ 0.3\n2.1\u22121 2.1 +0.7 2.1\u22122 2.1 ] = 1\n\u03b3\n[ 0.16+0.03 ] = 0.3\u0304\nbEDI DctRev \u00acbook (00) = 1\n\u03b3\n[ b(11)\u03b4DctRev(\u03b1,00,11)+\nb(10)\u03b4DctRev(\u03b1,00,10) ]\n= 1 \u03b3\n[ 0.3\u03b4dfr(00,11)+0.7\u03b4dfr(00,10) ] = 1\n\u03b3\n[ 0.3\n2.1\u22122 2.1 +0.7 2.1\u22121 2.1 ] = 1\n\u03b3\n[ 0.01+0.37 ] = 0.6\u0304\nInitially, the agent is certain that the book is on the floor and there is a relatively high likelihood (0.7) that the magazine is on the table. Then the agent hears from a reliable source that actually the book is definitely on the table. The agent revises its beliefs accordingly, and reasonably still believes to a relatively high degree (0.6\u0304) that the magazine is on the table.\nProposition 5.6. \u03b4DctRev is retentive.\nProof. Assume w, w \u2032 \u03b1 and w 6= w \u2032. Assume b(\u03b1) = 0. Then only the second line of the definition of \u03b4DctRev is applicable. That is, \u03b4DctRev = 0. Now assume b(\u03b1) 6= 0. Again, only the second line is applicable, making \u03b4DctRev = 0. The retention property is thus satisfied.\nProposition 5.7. \u03b4DctRev satisfies non-negativity, identity and symmetry.\nProof. Non-negativity follows directly. If w = w \u2032, then only the first and third lines are applicable. In both cases, identity holds.\nThe first line of the definition is satisfied for \u03b4DctRev(\u03b1, w, w \u2032) iff it is satisfied for \u03b4DctRev(\u03b1, w \u2032, w). Similarly for the second line. Because \u03b4 is assumed to be an inverse-distance weight function, \u03b4 is symmetrical. It thus follows that \u03b4DctRev satisfies symmetry.\nProposition 5.8. \u03b4DctRev does not satisfy weak inversity, strict inversity nor equi-distance.\nProof. For all w, w \u2032, w \u2032\u2032, w \u2032\u2032\u2032 \u2208W : Assume d(w, w \u2032) = d(w \u2032\u2032, w \u2032\u2032\u2032). If d(w, w \u2032) = d(w \u2032\u2032, w \u2032\u2032\u2032) 6= 0, then, by the identity condition of d , w 6= w \u2032 and w \u2032\u2032 6= w \u2032\u2032\u2032, and only the second and third lines are applicable. Assume \u201cw \u2032\u2032, w \u2032\u2032\u2032 \u03b1 if b(\u03b1) = 0\u201d holds, but that \u201cw, w \u2032 \u03b1 if b(\u03b1) = 0\u201d does not hold. Then \u03b4DctRev(\u03b1, w, w \u2032) = \u03b4(\u03b1, w, w \u2032) and \u03b4DctRev(\u03b1, w \u2032\u2032, w \u2032\u2032\u2032) = 0. Now, it could be that \u03b4(\u03b1, w, w \u2032) > 0. Hence, if d(w, w \u2032) \u2265 d(w \u2032\u2032, w \u2032\u2032\u2032) it is not in general the case that \u03b4DctRev(\u03b1, w, w \u2032) \u2264 \u03b4DctRev(\u03b1, w \u2032\u2032, w \u2032\u2032\u2032). Thus, weak inversity fails. This case also shows that equi-distance and strict inversity fail.\nProposition 5.9. \u03b4DctRev is faithful iff \u03b4 is.\nProof. Assume w 6= w \u2032. Assume \u03b4 is not faithful. Assume b(\u03b1) = 0 and w \u2032 6 \u03b1. Then only the third line is applicable. It could happen that \u03b4(\u03b1, w, w \u2032) = 1, making \u03b4DctRev(\u03b1, w, w \u2032) = 1, making \u03b4DctRev unfaithful. Now assume \u03b4 is faithful. Only the second and third lines are applicable. In both cases, \u03b4DctRev(\u03b1, w, w \u2032) < 1 (particularly, \u03b4(\u03b1, w, w \u2032) < 1, because w 6= w \u2032)."}, {"heading": "5.3 Probabilistic Update via Classical Update", "text": "This approach is the same as we took for probabilistic revision via classical revision; to determine the new knowledge base exactly as one would in classical belief update, and then to assign probabilities to the newly believed worlds.\nRecall that W b := {w \u2208W | (w, p) \u2208 b, p 6= 0} and \u03c8b is a sentence modeled by all worlds in W b and no others. Let \u03b4ClsUpd be defined as follows.\n\u03b4ClsUpd(\u03b1, w, w \u2032) :=  1 if w = w \u2032 \u03b4(\u03b1, w, w \u2032) if w \u2208 Mod(\u03c8b \u00a6\u03b1) 0 otherwise,\nwhere \u00a6 is some (acceptable) update operator and \u03b4 is a relaxed inverse-distance weight function. Proposition 5.10. If Mod(\u03c8b \u00a6\u03b1) = Mod(\u03b1), then \u03b4ClsUpd is relaxed. Proof. Assume Mod(\u03c8b \u00a6\u03b1) = Mod(\u03b1). Assume w \u03b1. If w = w \u2032, then only the first line of the definition of \u03b4ClsUpd is applicable, and \u03b4ClsUpd(\u03b1, w, w \u2032) 6= 0. If w 6= w \u2032, then only the second and third lines are applicable. But actually, by the two assumptions, only the second line is applicable. This implies that for all w, w \u2032 \u2208 W , if w \u03b1, then \u03b4ClsUpd(\u03b1, w, w \u2032) 6= 0. Therefore, \u03b4ClsUpd is relaxed. Proposition 5.11. \u03b4ClsUpd satisfies non-negativity, identity and symmetry.\nProof. Non-negativity and identity follow directly from the definition of \u03b4ClsUpd. We look at the three cases (lines) which make up the definition of \u03b4ClsUpd. If w = w \u2032, then \u03b4ClsUpd(\u03b1, w, w \u2032) = \u03b4ClsRev(\u03b1, w \u2032, w) = 1. If w \u2208 Mod(\u03c8b \u00a6\u03b1), then \u03b4ClsUpd(\u03b1, w, w \u2032) = \u03b4(\u03b1, w, w \u2032). But \u03b4(\u03b1, w, w \u2032) is assumed to be an inverse-distance weight function, which implies that \u03b4(\u03b1, w, w \u2032) is symmetrical. For all other cases (third line), it must be that \u03b4ClsUpd(\u03b1, w, w \u2032) = \u03b4ClsUpd(\u03b1, w \u2032, w) = 0.\nProposition 5.12. \u03b4ClsUpd does not satisfy weak inversity, strong inversity nor equi-distance.\nProof. Suppose the vocabulary has three atoms, the distance function is Hamming and \u03b4 is \u03b4rcp with \u03b7= 1. Assume Mod(\u03c8b) = {101,001,000} and 111,110,011,010 \u03b1 and all other worlds do not model \u03b1. Finally, assume that \u00a6 is defined such that Mod(\u03c8b \u00a6\u03b1) = {111,011,010}. Note that Mod(\u03c8b \u00a6\u03b1) \u2286 Mod(\u03b1).\nThen d(010,000) = d(110,010) = 1, \u03b4ClsUpd(\u03b1,010,000) = \u03b4rcp(\u03b1,010,000) = 1/2 and \u03b4ClsUpd(\u03b1,110,010) = 0. Therefore, d(010,000) \u2265 d(110,010), but \u03b4ClsUpd(\u03b1,010,000) 6\u2264 \u03b4ClsUpd(\u03b1,110,010). Hence, weak inversity fails for \u03b4ClsUpd. This case also proves that equi-distance fails.\nDue to strict inversity implying weak inversity, by contraposition, strict inversity fails.\nCorollary 5.2. Because \u03b4ClsUpd is not weakly inverse, it is not an inverse-distance weight function.\nProposition 5.13. \u03b4ClsUpd is faithful iff \u03b4 is.\nProof. Assume w 6= w \u2032. Assume \u03b4 is not faithful. Next, assume that w \u2208 Mod(\u03c8b \u00a6\u03b1). It could thus happen that \u03b4(\u03b1, w, w \u2032) = 1, implying that \u03b4ClsUpd is not faithful. Now assume \u03b4 is faithful. Only the second and third lines are applicable. In both cases, \u03b4ClsUpd(\u03b1, w, w \u2032) < 1 (particularly, \u03b4(\u03b1, w, w \u2032) < 1, because w 6= w \u2032)."}, {"heading": "5.4 Probabilistic Update with EDI Directly", "text": "Finally, we propose to use any relaxed (e-relaxed and n-e-relaxed) inverse-distance weight function for update. That is, we propose that one may use operation EDIDctUpd for updating, such that it is relaxed and where \u03b4DctUpd is an inverse-distance weight function.\nRecall the example in Section 5.2, where b = \u23290.3,0.7,0,0\u232a, \u03b1=\u00acbook, \u03b4DctRev is instantiated as \u03b4dfr and \u03b7= 0.1. Notice that if an agent were to update its beliefs (\u23290.3,0.7,0,0\u232a) with \u00acbook, the resulting belief state would be exactly the same as for revision via EDIDctRev: \u23290,0,0.3\u0304,0.6\u0304\u232a. The reader may confirm that on the second application of EDIDctRev, the agent still believes \u23290,0,0.3\u0304,0.6\u0304\u232a. On the second application of EDIDctUpd, however, the agent believes \u23290,0,0.45,0.55\u232a.\nEach of strict inversity, equi-distance and faithfulness might be satisfied, depending on the particular instantiation of \u03b4DctUpd."}, {"heading": "6 Rationality Postulates for EDI", "text": "In this section, we present and propose rationality postulates \u2013 conditions which should be satisfied \u2013 for belief revision and belief update. We do not claim that these are sufficient. Some of them are necessary, but some may not be. Nonetheless, the postulates have been given due consideration. For this study, we identify three core (necessary) rationality postulates for revision and update. We prove that EDIClsRev and EDIDctRev satisfy the three core revision postulates, and that EDIClsUpd and EDIDctUpd satisfy the three core update postulates."}, {"heading": "6.1 Probabilistic Revision Postulates", "text": "We adopt the rationality postulates for probabilistic belief revision from G\u00e4rdenfors (1988) and we employ probabilistic versions of the rationality postulates for (non-probabilistic) belief update from Katsuno and Mendelzon (1992).\nFirst, we discuss the operation called expansion, because it is mentioned in the postulates below. Conventionally, (classical) expansion (denoted +) is the logical consequences of K \u222a {\u03b1}, where \u03b1 is new information and K is the current belief set. Or if the current beliefs can be captured as a single sentence \u03b2, expansion is defined simply as \u03b2+\u03b1\u2261\u03b2\u2227\u03b1. We denote the expansion of belief state b with \u03b1 as b+\u03b1 .\n(Unless stated otherwise, it is assumed that \u03b1 is logically satisfiable.) The probabilistic belief revision postulates (adapted from (G\u00e4rdenfors, 1988)) in our notation are\n(P\u25e61) b\u25e6\u03b1 is a belief state (P\u25e62) b\u25e6\u03b1(\u03b1) = 1 (P\u25e63) If \u03b1\u2261\u03b2, then b\u25e6\u03b1 = b\u25e6\u03b2\n(P\u25e64) If b(\u03b1) > 0, then b\u25e6\u03b1 = b+\u03b1 (P\u25e65) If b\u25e6\u03b1(\u03b2) > 0, then b\u25e6\u03b1\u2227\u03b2 = (b\u25e6\u03b1)+\u03b2\nWe take P\u25e61 - P\u25e63 to be self explanatory, and to be the three core postulates. P\u25e64 is an interpretation of the AGM postulate which says that if the evidence is consistent with the currently held beliefs, then revision amounts to expansion.\nP\u25e65 says that if \u03b2 is deemed possible in the belief state revised with \u03b1, then expanding the revised belief state with \u03b2 should be equal to revising the original belief state with the conjunction of \u03b1 and \u03b2.\nWe propose adding this postulate:\n(P\u25e66) If \u03b2 |=\u03b1, then b\u25e6\u03b1(\u03b2) \u2265 b(\u03b2) P\u25e66 says that the belief in an \u03b1-world cannot decrease due to the reception of information that \u03b1.\nRecall that\n\u03b4ClsRev(\u03b1, w, w \u2032) :=  1 if w = w \u2032 \u03b4(\u03b1, w, w \u2032) if w \u2208 Mod(\u03c8b \u25e6\u03b1) 0 otherwise,\nwhere \u25e6 is some (acceptable) revision operator and \u03b4 is a non-evidence relaxed and retentive inverse-distance weight function.\nProposition 6.1. (P\u25e61) is satisfied for EDIClsRev.\nProof. Due to normalization (via \u03b3) in the definition of EDI (Def. 4.2), b\u25e6\u03b1 is a belief state whenever there exists at least one world w \u2208 W s.t. if w \u03b1, then \u2211w \u2032\u2208W b(w \u2032)\u03b4ClsRev(\u03b1, w, w \u2032) > 0. Assume that w \u03b1. It must be shown that there exists at least one world w \u2032 for which b(w \u2032) > 0 and \u03b4ClsRev(\u03b1, w, w \u2032) > 0.\nProof by contradiction: Let w be an arbitrary world in W . (Main assumption) Assume there exists no world w \u2032 for which b(w \u2032) > 0 and \u03b4ClsRev(\u03b1, w, w \u2032) > 0. Assume w = w \u2032. Then the first line of the definition of \u03b4ClsRev is applicable and it must be that b(w \u2032) = 0. But this is impossible because it implies that for all worlds w , b(w) = 0 (b is implicitly assumed to be well-defined). Therefore, it must be that w 6= w \u2032.\nLet w \u2208 Mod(\u03c8b \u25e6\u03b1) (there must exists at least one such w). Then the second line is applicable. Let b(w \u2032) > 0 (there must exist at least on such w \u2032). This implies that \u03b4ClsRev(\u03b1, w, w \u2032) = 0, which implies that \u03b4(\u03b1, w, w \u2032) = 0. Now, either w \u2032 \u03b1 or w \u2032 6 \u03b1.\nAssume w \u2032 \u03b1. Recall that b(w \u2032) > 0. Note that the first line will eventually become applicable, making \u03b4ClsRev(\u03b1, w \u2032, w \u2032) = 1 and contradicting the main assumption. Therefore, it must be the case that w \u2032 6 \u03b1. Recall that \u03b4 is n-e-relaxed, that is, \u2200w, w \u2032 \u2208 W , if w \u03b1 and w \u2032 6 \u03b1, then \u03b4(\u03b1, w, w \u2032) 6= 0. This also contradicts the main assumption.\nThere is no other way to satisfy the main assumption. It must thus be the case that there exists some world w \u2032 for which b(w \u2032) > 0 and \u03b4ClsRev(\u03b1, w, w \u2032) > 0, implying that there exists at least one world w \u2208 W s.t. if w \u03b1, then\u2211\nw \u2032\u2208W b(w \u2032)\u03b4ClsRev(\u03b1, w, w \u2032) > 0. Proposition 6.2. (P\u25e62) is satisfied for EDIClsRev.\nProof. The proposition is satisfied when bEDI ClsRev \u03b1 (\u03b1) = 1. It is almost a direct consequence of the definition of EDI: \u2200w \u2208W , bEDIClsRev\u03b1 (w) > 0 only if w \u03b1. Proposition 6.3. (P\u25e63) is satisfied for EDIClsRev.\nProof. If \u03b1\u2261\u03b2, then \u2200w \u2208W , w \u03b1 iff w \u03b2 and bEDIClsRev\u03b1 (w) = bEDI ClsRev \u03b2 (w), implying that bEDI ClsRev \u03b1 = bEDI ClsRev \u03b2 .\nRecall that\n\u03b4DctRev(\u03b1, w, w \u2032) := { \u03b4BC (w, w \u2032) if b(\u03b1) > 0 \u03b4=0(\u03b1, w, w \u2032) otherwise\nwhere \u03b4 is a non-evidence relaxed and an inverse-distance weight function.\nProposition 6.4. (P\u25e61) is satisfied for EDIDctRev.\nProof. Due to normalization (via \u03b3) in the definition of EDI (Def. 4.2), b\u25e6\u03b1 is a belief state whenever there exists at least one world w \u2208 W s.t. if w \u03b1, then \u2211w \u2032\u2208W b(w \u2032)\u03b4DctRev(\u03b1, w, w \u2032) > 0. Assume that w \u03b1. It must be shown that there exists at least one world w \u2032 for which b(w \u2032) > 0 and \u03b4DctRev(\u03b1, w, w \u2032) > 0.\nProof by contradiction: Let w be an arbitrary world in W . (Main assumption) Assume there exists no world w \u2032 for which b(w \u2032) > 0 and \u03b4DctRev(\u03b1, w, w \u2032) > 0.\nEither b(\u03b1) = 0 or b(\u03b1) > 0. Assume b(\u03b1) > 0. Then there exists at least one \u03b1-world with probability greater than zero. Let w be that world. Thus, when w = w \u2032, \u03b4DctRev(\u03b1, w, w \u2032) = 1 (first line of definition) and the main assumption fails in this case. Assume b(\u03b1) = 0. Then there exists at least one non-\u03b1-world with probability greater than zero. Let w \u2032 be that world. Hence, the first and second lines are inapplicable, because \u201cw, w \u2032 \u03b1 if b(\u03b1) = 0\u201d fails. Therefore, only the third line is applicable. \u03b4 is n-e-relaxed, so \u2200w, w \u2032 \u2208 W , if w \u03b1 and w \u2032 6 \u03b1, then \u03b4(\u03b1, w, w \u2032) 6= 0. By the main assumption, this implies that for all worlds w \u2032, b(w) = 0. But this contradicts our deduction that there exists some w \u2032 for which b(w \u2032) > 0.\nThere is no other way to satisfy the main assumption. It must thus be the case that there exists some world w \u2032 for which b(w \u2032) > 0 and \u03b4DctRev(\u03b1, w, w \u2032) > 0, implying that there exists at least one world w \u2208 W s.t. if w \u03b1, then\u2211\nw \u2032\u2208W b(w \u2032)\u03b4DctRev(\u03b1, w, w \u2032) > 0. Proposition 6.5. (P\u25e62) is satisfied for EDIDctRev.\nProof. The proposition is satisfied when bEDI DctRev \u03b1 (\u03b1) = 1. It is almost a direct consequence of the definition of EDI: \u2200w \u2208W , bEDIDctRev\u03b1 (w) > 0 only if w \u03b1. Proposition 6.6. (P\u25e63) is satisfied for EDIDctRev.\nProof. If \u03b1\u2261\u03b2, then \u2200w \u2208W , w \u03b1 iff w \u03b2 and bEDIDctRev\u03b1 (w) = bEDI DctRev \u03b2 (w), implying that bEDI DctRev \u03b1 = bEDI DctRev \u03b2 ."}, {"heading": "6.2 Probabilistic Update Postulates", "text": "A set of probabilistic belief update postulates is now adapted from (Katsuno and Mendelzon, 1992)\u2019s classical postulates. Each classical postulate is translated into probabilistic counterpart (in our notation).\n(U 1) \u03b2\u00a6\u03b1 |=\u03b1 (P\u00a61) b\u00a6\u03b1(\u03b1) = 1\n(U 2) if \u03b2 |=\u03b1, then \u03b2\u00a6\u03b1\u2261\u03b2 (P\u00a62a) if b(\u03b1) = 1, then b\u00a6\u03b1 = b (P\u00a62b) if \u03c6 |=\u03b1, b(\u03c6) > 0 iff b\u00a6\u03b1(\u03c6) > 0 (P\u00a62c) if \u03c6 |=\u03b1, then if b(\u03c6) > 0, then b\u00a6\u03b1(\u03c6) > 0\nIt is arguable which of P\u00a62a, P\u00a62b or P\u00a62c are appropriate translations of U 2 (if any). P\u00a62a is perhaps too strong and P\u00a62c perhaps too weak. If P\u00a62b is taken to be an appropriate translation, then we argue that in a probabilistic setting, it is too strong. For instance, it implies that if b(\u03c6) = 0, then b\u00a6\u03b1(\u03c6) = 0, but this is not the case when \u00a6 is e-relaxed.\n(U 3) if both \u03b2 and \u03b1 are satisfiable, then \u03b2\u00a6\u03b1 is also satisfiable (P\u00a63) b\u00a6\u03b1 is a belief state\nP\u00a63 has the simpler form because \u03b1 is assumed satisfiable and b is assumed to be a belief state.\n(U 4) if \u03b21 \u2261\u03b22 and \u03b11 \u2261\u03b12, then \u03b21 \u00a6\u03b11 \u2261\u03b22 \u00a6\u03b12 (P\u00a64) if \u03b11 \u2261\u03b12, then b\u00a6\u03b11 = b\u00a6\u03b12 (U 5) (\u03b2\u00a6\u03b1)\u2227\u03c6 |=\u03b2\u00a6 (\u03b1\u2227\u03c6) (P\u00a65) if \u03b1\u2227\u03c6 is satisfiable and \u03c8 |=\u03c6, then: b\u00a6\u03b1\u2227\u03c6(\u03c8) \u2265 b\u00a6\u03b1(\u03c8)\nSuppose \u03ba is a knowledge base and \u03ba\u2227\u03b1\u2032 implies \u03ba\u2227\u03b2\u2032. Then in terms of probabilities, one should expect b(\u03b2\u2032) \u2265 b(\u03b1\u2032), where b is the \u2018knowledge base\u2019. Given this metaphor, one can derive from U 5 the translation \u2018if \u03b1\u2227\u03c6 is satisfiable, then for all w \u2208W , if w \u03c6, then b\u00a6\u03b1\u2227\u03c6(w) \u2265 b\u00a6\u03b1(w), of which P\u00a65 is the sentential version.\n(U 6) if \u03b2\u00a6\u03b11 |=\u03b12 and \u03b2\u00a6\u03b12 |=\u03b11, then: \u03b2\u00a6\u03b11 \u2261\u03b2\u00a6\u03b12 (P\u00a66a) if b\u00a6\u03b11 (\u03b12) = 1 and b\u00a6\u03b12 (\u03b11) = 1, then: b\u00a6\u03b11 = b\u00a6\u03b12 (P\u00a66b) if b\u00a6\u03b11 (\u03b12) = 1 and b\u00a6\u03b12 (\u03b11) = 1, then: b\u00a6\u03b11 (\u03c6) > 0 \u21d0\u21d2 b\u00a6\u03b12 (\u03c6) > 0\nP\u00a66b is weaker than P\u00a66a but arguably more reasonable/rational in a probabilistic setting.\n(U 7) if \u03b2 is complete, then: \u03b2\u00a6\u03b11 \u2227\u03b2\u00a6\u03b12 |=\u03b2\u00a6 (\u03b11 \u2228\u03b12) (P\u00a67) if there exists a w s.t. b(w) = 1, then: min{b\u00a6\u03b11 (\u03c6),b \u00a6 \u03b12\n(\u03c6)} \u2264 b\u00a6\u03b11\u2228\u03b12 (\u03c6) \u2264 b\u00a6\u03b11 (\u03c6)+b\u00a6\u03b12 (\u03c6) KM\u2019s justification for U 7 is \u201cIf some possible world results from updating a complete KB with \u00b51 and it also results from updating it with \u00b52, then this possible world must also result from updating the KB with \u00b51 \u2228\u00b52\u201d. However, we go a step farther (given a probabilistic setting), and say that the belief in any \u03b2 given complete belief state resulting from updating with \u00b51 \u2228\u00b52 should be no less than the least of the beliefs in \u03b2 after updating the belief state with \u00b51 and updating it with \u00b52 separately, and no more than the sum of the belief in \u03b2 after updating the belief state with \u00b51 and updating it with \u00b52 separately.\n(U 8) (\u03b21 \u2228\u03b22)\u00a6\u03b1\u2261 (\u03b21 \u00a6\u03b1)\u2228 (\u03b22 \u00a6\u03b1) At this time, we do not have a satisfactory translation for U 8.\nP\u00a61, P\u00a63 and P\u00a64 are taken to be the three core postulates.\nRecall that\n\u03b4ClsUpd(\u03b1, w, w \u2032) :=  1 if w = w \u2032 \u03b4(\u03b1, w, w \u2032) if w \u2208 Mod(\u03c8b \u00a6\u03b1) 0 otherwise,\nwhere \u00a6 is some (acceptable) update operator and \u03b4 is a relaxed inverse-distance weight function. Proposition 6.7. (P\u00a61) is satisfied for EDIClsUpd.\nProof. The proposition is satisfied when bEDI ClsUpd \u03b1 (\u03b1) = 1. It is almost a direct consequence of the definition of EDI: \u2200w \u2208W , bEDIClsUpd\u03b1 (w) > 0 only if w \u03b1. Proposition 6.8. (P\u00a63) is satisfied for EDIClsUpd.\nProof. We must prove that bEDI ClsUpd\n\u03b1 is a belief state. Due to normalization (via \u03b3) in the definition of EDI (Def. 4.2), bEDI ClsUpd \u03b1 is a belief state whenever there exists at least one world w \u2208W s.t. if w \u03b1, then \u2211\nw \u2032\u2208W b(w \u2032)\u03b4ClsUpd(\u03b1, w, w \u2032) > 0. Assume that w \u03b1. It must be shown that there exists at least one world w \u2032 for which b(w \u2032) > 0 and \u03b4ClsUpd(\u03b1, w, w \u2032) > 0.\nProof by contradiction: Let w be an arbitrary world in W . (Main assumption) Assume there exists no world w \u2032 for which b(w \u2032) > 0 and \u03b4ClsUpd(\u03b1, w, w \u2032) > 0. Assume w = w \u2032. Then the first line of the definition of \u03b4ClsUpd is applicable and it must be that b(w \u2032) = 0. But this is impossible because it implies that for all worlds w , b(w) = 0 (b is implicitly assumed to be well-defined). Therefore, it must be that w 6= w \u2032.\nLet w \u2208 Mod(\u03c8b \u00a6\u03b1) (there must exists at least one such w). Then the second line is applicable. Let b(w \u2032) > 0 (there must exist at least on such w \u2032). This implies that \u03b4ClsUpd(\u03b1, w, w \u2032) = 0, which implies that \u03b4(\u03b1, w, w \u2032) = 0. Now, either w \u2032 \u03b1 or w \u2032 6 \u03b1.\nAssume w \u2032 \u03b1. Recall that b(w \u2032) > 0. Note that the first line will eventually become applicable, making \u03b4ClsUpd(\u03b1, w \u2032, w \u2032) = 1 and contradicting the main assumption. Therefore, it must be the case that w \u2032 6 \u03b1. Recall\nthat \u03b4 is relaxed and thus n-e-relaxed \u2013 that is, \u2200w, w \u2032 \u2208 W , if w \u03b1 and w \u2032 6 \u03b1, then \u03b4(\u03b1, w, w \u2032) 6= 0. This also contradicts the main assumption.\nThere is no other way to satisfy the main assumption. It must thus be the case that there exists some world w \u2032 for which b(w \u2032) > 0 and \u03b4ClsUpd(\u03b1, w, w \u2032) > 0, implying that there exists at least one world w \u2208 W s.t. if w \u03b1, then\u2211\nw \u2032\u2208W b(w \u2032)\u03b4ClsUpd(\u03b1, w, w \u2032) > 0. Proposition 6.9. (P\u00a64) is satisfied for EDIClsUpd.\nProof. If \u03b1 \u2261 \u03b2, then \u2200w \u2208 W , w \u03b1 iff w \u03b2 and bEDIClsUpd\u03b1 (w) = bEDI ClsUpd \u03b2 (w), implying that bEDI ClsUpd \u03b1 = bEDI ClsUpd\n\u03b2 .\nRecall that \u03b4DctUpd is a relaxed inverse-distance weight function.\nProposition 6.10. (P\u00a61) is satisfied for EDIDctUpd.\nProof. The proposition is satisfied when bEDI DctUpd \u03b1 (\u03b1) = 1. It is almost a direct consequence of the definition of EDI: \u2200w \u2208W , bEDIDctUpd\u03b1 (w) > 0 only if w \u03b1. Proposition 6.11. (P\u00a63) is satisfied for EDIDctUpd.\nProof. We must prove that bEDI DctUpd\n\u03b1 is a belief state. Due to normalization (via \u03b3) in the definition of EDI (Def. 4.2), bEDI DctUpd \u03b1 is a belief state whenever there exists at least one world w \u2208W s.t. if w \u03b1, then \u2211\nw \u2032\u2208W b(w \u2032)\u03b4DctUpd(\u03b1, w, w \u2032) > 0. Assume that w \u03b1. It must be shown that there exists at least one world w \u2032 for which b(w \u2032) > 0 and \u03b4DctUpd(\u03b1, w, w \u2032) > 0.\nLet b(w \u2032) > 0 (there must exist at least one such). By relaxation, \u03b4DctUpd(\u03b1, w, w \u2032) > 0. Proposition 6.12. (P\u00a64) is satisfied for EDIDctUpd.\nProof. If \u03b1 \u2261 \u03b2, then \u2200w \u2208 W , w \u03b1 iff w \u03b2 and bEDIDctUpd\u03b1 (w) = bEDI DctUpd \u03b2 (w), implying that bEDI DctUpd \u03b1 = bEDI DctUpd\n\u03b2 ."}, {"heading": "7 Conclusion", "text": "We have proposed probabilistic belief revision and belief update operators, both within an imaging framework. The role of a weight function \u2013 usually expected to be inversely proportional to the \u2019distance\u2019 between worlds \u2013 is central to the Expected Distance Imaging (EDI) framework. In this paper, we have only begun the investigation into the behavior or properties of various instantiations of a general form of imaging. There is still much work to be done. For instance, what is the effect of retention versus relaxation and when is one more appropriate than the other? We have worked with the hypothesis that retention relates to revision and that relaxation relates to update, but to what degree is this hypothesis true? What is the meaning of the effect of the size of \u03b7 in \u03b4rcp and \u03b4dfr?\nWe would like to make a deeper study of the probabilistic rationality postulates, especially those for update (as they have not been given much attention in the literature). We would then like to test various EDI instantiations against the postulates and use the results to perhaps design new EDI operators. We hope that these insights might lead to further insights in order to better understand the relationship between revision and update, whether classical or not."}], "references": [{"title": "On the logic of theory change: Partial meet contraction and revision functions", "author": ["C. Alchourr\u00f3n", "P. G\u00e4rdenfors", "D. Makinson"], "venue": "Journal of Symbolic Logic,", "citeRegEx": "Alchourr\u00f3n et al\\.,? \\Q1985\\E", "shortCiteRegEx": "Alchourr\u00f3n et al\\.", "year": 1985}, {"title": "Probabilistic belief revision via imaging", "author": ["K. Chhogyal", "A. Nayak", "R. Schwitter", "A. Sattar"], "venue": "PRICAI 2014: Trends in Artif. Intell.: Thirteenth Pacific Rim Intl. Conf. on Artif. Intell.,", "citeRegEx": "Chhogyal et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chhogyal et al\\.", "year": 2014}, {"title": "Belief revision and updates in numerical formalisms: An overview, with new results for the possibilistic framework", "author": ["D. Dubois", "H. Prade"], "venue": "In Proceedings of the Thirteenth Intl. Joint Conf. on Artif. Intell", "citeRegEx": "Dubois and Prade,? \\Q1993\\E", "shortCiteRegEx": "Dubois and Prade", "year": 1993}, {"title": "Modeling belief in dynamic systems. Part II: Revision and update", "author": ["N. Friedman", "J. Halpern"], "venue": "Journal of Artif. Intell. Research (JAIR),", "citeRegEx": "Friedman and Halpern,? \\Q1999\\E", "shortCiteRegEx": "Friedman and Halpern", "year": 1999}, {"title": "Knowledge in Flux: Modeling the Dynamics of Epistemic States", "author": ["P. G\u00e4rdenfors"], "venue": null, "citeRegEx": "G\u00e4rdenfors,? \\Q1988\\E", "shortCiteRegEx": "G\u00e4rdenfors", "year": 1988}, {"title": "On the difference between updating a knowledge base and revising", "author": ["H. Katsuno", "A.O. Mendelzon"], "venue": null, "citeRegEx": "Katsuno and Mendelzon,? \\Q1992\\E", "shortCiteRegEx": "Katsuno and Mendelzon", "year": 1992}, {"title": "Revising and updating probabilistic beliefs", "author": ["G. Kern-Isberner"], "venue": null, "citeRegEx": "Kern.Isberner,? \\Q2001\\E", "shortCiteRegEx": "Kern.Isberner", "year": 2001}, {"title": "Belief update revisited", "author": ["J. Lang"], "venue": "In de Mantaras,", "citeRegEx": "Lang,? \\Q2007\\E", "shortCiteRegEx": "Lang", "year": 2007}, {"title": "Distance semantics for belief revision", "author": ["D. Lehmann", "M. Magidor", "K. Schlechta"], "venue": "Journal of Symboloc Logic,", "citeRegEx": "Lehmann et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Lehmann et al\\.", "year": 2001}, {"title": "Probabilities of conditionals and conditional probabilities", "author": ["D. Lewis"], "venue": "Philosophical Review,", "citeRegEx": "Lewis,? \\Q1976\\E", "shortCiteRegEx": "Lewis", "year": 1976}, {"title": "Is revision a special kind of update", "author": ["A.C. Nayak"], "venue": "In AI 2011: Advances in Artif. Intell.: Proceedings of the Twenty-fourth Australasian Joint Conf.,", "citeRegEx": "Nayak,? \\Q2011\\E", "shortCiteRegEx": "Nayak", "year": 2011}, {"title": "Belief erasure using partial imaging", "author": ["R. Ramachandran", "A. Nayak", "M. Orgun"], "venue": "AI 2010: Advances in Artif. Intell.: Proceedings of the Twenty-third Australasian Joint Conf., volume 6464 of LNAI,", "citeRegEx": "Ramachandran et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ramachandran et al\\.", "year": 2010}, {"title": "A new approach to probabilistic belief change", "author": ["G. Rens", "T. Meyer"], "venue": "Proceedings of the Intl. Florida AI Research Society Conf. (FLAIRS),", "citeRegEx": "Rens and Meyer,? \\Q2015\\E", "shortCiteRegEx": "Rens and Meyer", "year": 2015}, {"title": "On revision of partially specified convex probabilistic belief bases", "author": ["G. Rens", "T. Meyer", "G. Casini"], "venue": "Proceedings of the Twenty-second European Conference on Artificial Intelligence", "citeRegEx": "Rens et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Rens et al\\.", "year": 2016}, {"title": "Probabilistic belief change: Expansion, conditioning and constraining", "author": ["F. Voorbraak"], "venue": "In Proceedings of the Fifteenth Conf. on Uncertainty in Artif. Intell.,", "citeRegEx": "Voorbraak,? \\Q1999\\E", "shortCiteRegEx": "Voorbraak", "year": 1999}], "referenceMentions": [{"referenceID": 3, "context": "However, simply applying AGM theory for revision and KM theory for update has been (indirectly) challenged (Friedman and Halpern, 1999; Kern-Isberner, 2001; Nayak, 2011; Lang, 2007).", "startOffset": 107, "endOffset": 181}, {"referenceID": 6, "context": "However, simply applying AGM theory for revision and KM theory for update has been (indirectly) challenged (Friedman and Halpern, 1999; Kern-Isberner, 2001; Nayak, 2011; Lang, 2007).", "startOffset": 107, "endOffset": 181}, {"referenceID": 10, "context": "However, simply applying AGM theory for revision and KM theory for update has been (indirectly) challenged (Friedman and Halpern, 1999; Kern-Isberner, 2001; Nayak, 2011; Lang, 2007).", "startOffset": 107, "endOffset": 181}, {"referenceID": 7, "context": "However, simply applying AGM theory for revision and KM theory for update has been (indirectly) challenged (Friedman and Halpern, 1999; Kern-Isberner, 2001; Nayak, 2011; Lang, 2007).", "startOffset": 107, "endOffset": 181}, {"referenceID": 11, "context": "David Lewis (1976) first proposed imaging to analyse conditional reasoning in probabilistic settings, and it has recently been the focus of several works on probabilistic belief change (Ramachandran et al., 2010; Chhogyal et al., 2014; Rens et al., 2016).", "startOffset": 185, "endOffset": 254}, {"referenceID": 1, "context": "David Lewis (1976) first proposed imaging to analyse conditional reasoning in probabilistic settings, and it has recently been the focus of several works on probabilistic belief change (Ramachandran et al., 2010; Chhogyal et al., 2014; Rens et al., 2016).", "startOffset": 185, "endOffset": 254}, {"referenceID": 13, "context": "David Lewis (1976) first proposed imaging to analyse conditional reasoning in probabilistic settings, and it has recently been the focus of several works on probabilistic belief change (Ramachandran et al., 2010; Chhogyal et al., 2014; Rens et al., 2016).", "startOffset": 185, "endOffset": 254}, {"referenceID": 0, "context": "From the perspective of classical (Boolean) belief change, the work of Alchourr\u00f3n et al. (1985) is regarded as the foundation theory for belief revision (AGM theory).", "startOffset": 71, "endOffset": 96}, {"referenceID": 0, "context": "From the perspective of classical (Boolean) belief change, the work of Alchourr\u00f3n et al. (1985) is regarded as the foundation theory for belief revision (AGM theory). Typically, belief change (in a static world) can be categorized as expansion, revision or contraction, and is performed on a belief set, the set of sentences K closed under logical consequence. Revision is when new information \u03b1 is (possibly) inconsistent with K and K is (minimally) modified so that the new K remains consistent and entails \u03b1. Revision is the process which takes place when an agent modifies its beliefs due to receiving new information not previously known or which is more relevant or trustworthy. Except for the movement of information, the physical world is assumed to be completely unchanging. Whereas belief revision is considered to take place in a static environment, belief update is thought to be the change in beliefs which takes place due to a dynamic environment. Update refers to the process of bringing beliefs up to date precisely because the world has changed and the agent needs a new, \u2018matching\u2019 view on the world. From the perspective of classical (Boolean) belief change, Katsuno and Mendelzon (1992) developed the first serious theory of update (KM theory).", "startOffset": 71, "endOffset": 1207}, {"referenceID": 0, "context": "From the perspective of classical (Boolean) belief change, the work of Alchourr\u00f3n et al. (1985) is regarded as the foundation theory for belief revision (AGM theory). Typically, belief change (in a static world) can be categorized as expansion, revision or contraction, and is performed on a belief set, the set of sentences K closed under logical consequence. Revision is when new information \u03b1 is (possibly) inconsistent with K and K is (minimally) modified so that the new K remains consistent and entails \u03b1. Revision is the process which takes place when an agent modifies its beliefs due to receiving new information not previously known or which is more relevant or trustworthy. Except for the movement of information, the physical world is assumed to be completely unchanging. Whereas belief revision is considered to take place in a static environment, belief update is thought to be the change in beliefs which takes place due to a dynamic environment. Update refers to the process of bringing beliefs up to date precisely because the world has changed and the agent needs a new, \u2018matching\u2019 view on the world. From the perspective of classical (Boolean) belief change, Katsuno and Mendelzon (1992) developed the first serious theory of update (KM theory). Their theory is different from that of AGM in that their rationality postulates are derived from the understanding that update occurs in a dynamic environment. However, simply applying AGM theory for revision and KM theory for update has been (indirectly) challenged (Friedman and Halpern, 1999; Kern-Isberner, 2001; Nayak, 2011; Lang, 2007). Further, how to categorize a belief change operator is more challenging when notions of uncertainty are considered, for instance, when using probabilities and rankings. The very definition of belief revision and belief update become more problematic under notions of uncertainty. One kind of probabilistic belief change operation which could potentially \u2018relax\u2019 the tension between revision and update is imaging. David Lewis (1976) first proposed imaging to analyse conditional reasoning in probabilistic settings, and it has recently been the focus of several works on probabilistic belief change (Ramachandran et al.", "startOffset": 71, "endOffset": 2041}, {"referenceID": 0, "context": "From the perspective of classical (Boolean) belief change, the work of Alchourr\u00f3n et al. (1985) is regarded as the foundation theory for belief revision (AGM theory). Typically, belief change (in a static world) can be categorized as expansion, revision or contraction, and is performed on a belief set, the set of sentences K closed under logical consequence. Revision is when new information \u03b1 is (possibly) inconsistent with K and K is (minimally) modified so that the new K remains consistent and entails \u03b1. Revision is the process which takes place when an agent modifies its beliefs due to receiving new information not previously known or which is more relevant or trustworthy. Except for the movement of information, the physical world is assumed to be completely unchanging. Whereas belief revision is considered to take place in a static environment, belief update is thought to be the change in beliefs which takes place due to a dynamic environment. Update refers to the process of bringing beliefs up to date precisely because the world has changed and the agent needs a new, \u2018matching\u2019 view on the world. From the perspective of classical (Boolean) belief change, Katsuno and Mendelzon (1992) developed the first serious theory of update (KM theory). Their theory is different from that of AGM in that their rationality postulates are derived from the understanding that update occurs in a dynamic environment. However, simply applying AGM theory for revision and KM theory for update has been (indirectly) challenged (Friedman and Halpern, 1999; Kern-Isberner, 2001; Nayak, 2011; Lang, 2007). Further, how to categorize a belief change operator is more challenging when notions of uncertainty are considered, for instance, when using probabilities and rankings. The very definition of belief revision and belief update become more problematic under notions of uncertainty. One kind of probabilistic belief change operation which could potentially \u2018relax\u2019 the tension between revision and update is imaging. David Lewis (1976) first proposed imaging to analyse conditional reasoning in probabilistic settings, and it has recently been the focus of several works on probabilistic belief change (Ramachandran et al., 2010; Chhogyal et al., 2014; Rens et al., 2016). Imaging is the approach of moving the belief in worlds possible at one moment to similar worlds compatible with evidence received at a next moment. In other words, the \u2018belief-mass\u2019 is shifted to the \u2018images\u2019 of the worlds currently believed possible, where the images are the worlds related via new evidence to the currently believed worlds. One of the main benefits of imaging is that it overcomes the problem with Bayesian conditioning, namely, being undefined when evidence is inconsistent with current beliefs. G\u00e4rdenfors (1988) and Rens et al.", "startOffset": 71, "endOffset": 2812}, {"referenceID": 0, "context": "From the perspective of classical (Boolean) belief change, the work of Alchourr\u00f3n et al. (1985) is regarded as the foundation theory for belief revision (AGM theory). Typically, belief change (in a static world) can be categorized as expansion, revision or contraction, and is performed on a belief set, the set of sentences K closed under logical consequence. Revision is when new information \u03b1 is (possibly) inconsistent with K and K is (minimally) modified so that the new K remains consistent and entails \u03b1. Revision is the process which takes place when an agent modifies its beliefs due to receiving new information not previously known or which is more relevant or trustworthy. Except for the movement of information, the physical world is assumed to be completely unchanging. Whereas belief revision is considered to take place in a static environment, belief update is thought to be the change in beliefs which takes place due to a dynamic environment. Update refers to the process of bringing beliefs up to date precisely because the world has changed and the agent needs a new, \u2018matching\u2019 view on the world. From the perspective of classical (Boolean) belief change, Katsuno and Mendelzon (1992) developed the first serious theory of update (KM theory). Their theory is different from that of AGM in that their rationality postulates are derived from the understanding that update occurs in a dynamic environment. However, simply applying AGM theory for revision and KM theory for update has been (indirectly) challenged (Friedman and Halpern, 1999; Kern-Isberner, 2001; Nayak, 2011; Lang, 2007). Further, how to categorize a belief change operator is more challenging when notions of uncertainty are considered, for instance, when using probabilities and rankings. The very definition of belief revision and belief update become more problematic under notions of uncertainty. One kind of probabilistic belief change operation which could potentially \u2018relax\u2019 the tension between revision and update is imaging. David Lewis (1976) first proposed imaging to analyse conditional reasoning in probabilistic settings, and it has recently been the focus of several works on probabilistic belief change (Ramachandran et al., 2010; Chhogyal et al., 2014; Rens et al., 2016). Imaging is the approach of moving the belief in worlds possible at one moment to similar worlds compatible with evidence received at a next moment. In other words, the \u2018belief-mass\u2019 is shifted to the \u2018images\u2019 of the worlds currently believed possible, where the images are the worlds related via new evidence to the currently believed worlds. One of the main benefits of imaging is that it overcomes the problem with Bayesian conditioning, namely, being undefined when evidence is inconsistent with current beliefs. G\u00e4rdenfors (1988) and Rens et al. (2016) proposed generalizations of Lewis\u2019s original definition.", "startOffset": 71, "endOffset": 2835}, {"referenceID": 13, "context": "(Rens et al., 2016) define an imaging operation which relaxes the unique-closest-world assumption of Lewis imaging, and they provide a method of revising (via imaging) a potentially infinite set of belief states in a finite procedure.", "startOffset": 0, "endOffset": 19}, {"referenceID": 5, "context": "On the other hand, some researchers have considered imaging to be the probabilistic version of update (Katsuno and Mendelzon, 1992; Dubois and Prade, 1993; Nayak, 2011).", "startOffset": 102, "endOffset": 168}, {"referenceID": 2, "context": "On the other hand, some researchers have considered imaging to be the probabilistic version of update (Katsuno and Mendelzon, 1992; Dubois and Prade, 1993; Nayak, 2011).", "startOffset": 102, "endOffset": 168}, {"referenceID": 10, "context": "On the other hand, some researchers have considered imaging to be the probabilistic version of update (Katsuno and Mendelzon, 1992; Dubois and Prade, 1993; Nayak, 2011).", "startOffset": 102, "endOffset": 168}, {"referenceID": 2, "context": "G\u00e4rdenfors (1988) says \".", "startOffset": 0, "endOffset": 18}, {"referenceID": 1, "context": "Chhogyal et al. (2014) explore the use of Lewis imaging as a means to construct probabilistic belief revision.", "startOffset": 0, "endOffset": 23}, {"referenceID": 1, "context": "Chhogyal et al. (2014) explore the use of Lewis imaging as a means to construct probabilistic belief revision. They present explicit constructions of three candidates strategies based on imaging and investigate their properties. (Rens et al., 2016) define an imaging operation which relaxes the unique-closest-world assumption of Lewis imaging, and they provide a method of revising (via imaging) a potentially infinite set of belief states in a finite procedure. On the other hand, some researchers have considered imaging to be the probabilistic version of update (Katsuno and Mendelzon, 1992; Dubois and Prade, 1993; Nayak, 2011). Ramachandran et al. (2010) propose a version of imaging for probabilistic belief erasure.", "startOffset": 0, "endOffset": 661}, {"referenceID": 1, "context": "Chhogyal et al. (2014) explore the use of Lewis imaging as a means to construct probabilistic belief revision. They present explicit constructions of three candidates strategies based on imaging and investigate their properties. (Rens et al., 2016) define an imaging operation which relaxes the unique-closest-world assumption of Lewis imaging, and they provide a method of revising (via imaging) a potentially infinite set of belief states in a finite procedure. On the other hand, some researchers have considered imaging to be the probabilistic version of update (Katsuno and Mendelzon, 1992; Dubois and Prade, 1993; Nayak, 2011). Ramachandran et al. (2010) propose a version of imaging for probabilistic belief erasure. In fact, Lewis (1976) himself never said that imaging was meant to be interpreted as one or the other.", "startOffset": 0, "endOffset": 746}, {"referenceID": 4, "context": "One school of thought says that probabilistic expansion (restricted revision) is equivalent to Bayesian conditioning (G\u00e4rdenfors (1988, Chap. 5) and Voorbraak (1999) mention this, but no not necessarily agree with it).", "startOffset": 118, "endOffset": 166}, {"referenceID": 3, "context": "G\u00e4rdenfors (1988) describes his generalization of Lewis imaging (which he calls general imaging) as \u201c.", "startOffset": 0, "endOffset": 18}, {"referenceID": 3, "context": "G\u00e4rdenfors (1988) describes his generalization of Lewis imaging (which he calls general imaging) as \u201c... instead of moving all the probability assigned to a world W i by a probability function P to a unique (\u201cclosest\u201d) A-world W j , when imaging on A, one can introduce the weaker requirement that the probability of W i be distributed among several A-worlds (that are \u201cequally close\u201d).\u201d If we interpret G\u00e4rdenfors\u2019 approach correctly, he does not provide a constructive method but insists that b# \u03b1(\u03b1) = 1, where b# \u03b1 is the image (change) of b on \u03b1. Rens et al. (2016) introduced generalized imaging via a constructive method.", "startOffset": 0, "endOffset": 571}, {"referenceID": 3, "context": "G\u00e4rdenfors (1988) describes his generalization of Lewis imaging (which he calls general imaging) as \u201c... instead of moving all the probability assigned to a world W i by a probability function P to a unique (\u201cclosest\u201d) A-world W j , when imaging on A, one can introduce the weaker requirement that the probability of W i be distributed among several A-worlds (that are \u201cequally close\u201d).\u201d If we interpret G\u00e4rdenfors\u2019 approach correctly, he does not provide a constructive method but insists that b# \u03b1(\u03b1) = 1, where b# \u03b1 is the image (change) of b on \u03b1. Rens et al. (2016) introduced generalized imaging via a constructive method. It is a particular instance of G\u00e4rdenfors\u2019 general imaging. They use a pseudo-distance measure between worlds, as defined by Lehmann et al. (2001) and adopted by Chhogyal et al.", "startOffset": 0, "endOffset": 776}, {"referenceID": 1, "context": "(2001) and adopted by Chhogyal et al. (2014).", "startOffset": 22, "endOffset": 45}, {"referenceID": 12, "context": "1 Definition and Properties Rens and Meyer (2015) proposed determining the new probability of an \u03b1-world w as the weighted average of the current probabilities of all worlds w \u2032, where the weights are (inversely) proportional to the distance between w and the w \u2032.", "startOffset": 28, "endOffset": 50}, {"referenceID": 12, "context": "2 Reciprocal Weights Rens and Meyer (2015) define the weight to be applied to b(w \u2032) when determining the new probability of w as 1/d(w,w \u2032) \u2211 w \u2032\u2032\u2208W,w \u2032\u2032 6=w 1/d(w,w \u2032\u2032) .", "startOffset": 21, "endOffset": 43}, {"referenceID": 12, "context": "1Actually, Rens and Meyer (2015) proposed two definitions for weights, one to be applied when \u201cadding worlds\u201d after a belief change and another when \u201cremoving worlds\u201d.", "startOffset": 11, "endOffset": 33}, {"referenceID": 5, "context": "Katsuno and Mendelzon (1992) use an example involving a room with a table, a book and a magazine in it to illustrate the difference between revision and update.", "startOffset": 0, "endOffset": 29}, {"referenceID": 5, "context": "Katsuno and Mendelzon (1992) use an example involving a room with a table, a book and a magazine in it to illustrate the difference between revision and update. Suppose we only know that either the book is on the table or the magazine is on the table, but not both. Let book mean the book is on the floor and mag mean the magazine is on the floor. Then our belief state can reasonably be represented as b = \u30080,0.5,0.5,0\u3009, that is b(book \u2227\u00acmag) = b(\u00acbook\u2227mag) = 0.5 and b(book\u2227mag) = b(\u00acbook\u2227\u00acmag) = 0. Katsuno and Mendelzon (1992) argued that after revision with book, one should believe book\u2227\u00acmag.", "startOffset": 0, "endOffset": 531}, {"referenceID": 4, "context": ") The probabilistic belief revision postulates (adapted from (G\u00e4rdenfors, 1988)) in our notation are (P\u25e61) b\u25e6 \u03b1 is a belief state (P\u25e62) b\u25e6 \u03b1(\u03b1) = 1 (P\u25e63) If \u03b1\u2261\u03b2, then b\u25e6 \u03b1 = b\u25e6 \u03b2", "startOffset": 61, "endOffset": 79}, {"referenceID": 4, "context": "We adopt the rationality postulates for probabilistic belief revision from G\u00e4rdenfors (1988) and we employ probabilistic versions of the rationality postulates for (non-probabilistic) belief update from Katsuno and Mendelzon (1992).", "startOffset": 75, "endOffset": 93}, {"referenceID": 4, "context": "We adopt the rationality postulates for probabilistic belief revision from G\u00e4rdenfors (1988) and we employ probabilistic versions of the rationality postulates for (non-probabilistic) belief update from Katsuno and Mendelzon (1992). First, we discuss the operation called expansion, because it is mentioned in the postulates below.", "startOffset": 75, "endOffset": 232}, {"referenceID": 5, "context": "A set of probabilistic belief update postulates is now adapted from (Katsuno and Mendelzon, 1992)\u2019s classical postulates.", "startOffset": 68, "endOffset": 97}], "year": 2017, "abstractText": "Imaging is a form of probabilistic belief change which could be employed for both revision and update. In this paper, we propose a new framework for probabilistic belief change based on imaging, called Expected Distance Imaging (EDI). EDI is sufficiently general to define Bayesian conditioning and other forms of imaging previously defined in the literature. We argue that, and investigate how, EDI can be used for both revision and update. EDI\u2019s definition depends crucially on a weight function whose properties are studied and whose effect on belief change operations is analysed. Finally, four EDI instantiations are proposed, two for revision and two for update, and probabilistic rationality postulates are suggested for their analysis.", "creator": "LaTeX with hyperref package"}}}