{"id": "1705.05326", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-May-2017", "title": "Constrained Bayesian Networks: Theory, Optimization, and Applications", "abstract": "we develop the theory & practice of an approach to modelling and probabilistic inference in causal networks that is suitable when criteria - designing or analysis - specific constraints should induce such inference or when little or no data for the learning of causal network structure or probability values surrounding nodes are useful. constrained bayesian networks generalize a bayesian network such that probabilities can be symbolic, arithmetic expressions and where the meaning of the network is constrained by comparing many algorithms from the theory of the reals. a formal semantics for constrained bayesian networks over first - order logic of the reals is given, which enables non - coding and non - exponential optimisation algorithms that rely on decision procedures for this logic, thus supports algebraic composition of generic constrained bayesian networks. a none - trivial framework study in arms control, where few comparatively no data are available to disclose the effectiveness of an arms inspection process, evaluates our approach. strong open - access prototype implementation of these indicates that their framework uses the smt solver z3 as decision procedure, leverages an open - source package for statistical inference to practical computation, and is evaluated experimentally.", "histories": [["v1", "Mon, 15 May 2017 16:48:12 GMT  (979kb,D)", "http://arxiv.org/abs/1705.05326v1", "43 pages, 18 figures"]], "COMMENTS": "43 pages, 18 figures", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["paul beaumont", "michael huth"], "accepted": false, "id": "1705.05326"}, "pdf": {"name": "1705.05326.pdf", "metadata": {"source": "CRF", "title": "Constrained Bayesian Networks: Theory, Optimization, and Applications", "authors": ["Paul Beaumont"], "emails": ["m.huthu@imperial.ac.uk"], "sections": [{"heading": null, "text": "Keywords: Bayesian Belief Network. Imprecise Probabilities. Lack of Prior Data. NonLinear Optimization. Confidence Building in Nuclear Arms Control."}, {"heading": "1 Introduction", "text": "Bayesian Networks (BN) [36, 37, 35] are a prominent, well established, and widely used formalism for expressing discrete probability distributions in terms of directed, acyclic graphs (DAG) that encode conditional independence assumptions of distributions. Bayesian Networks have a wide range of applications \u2013 for example, trouble shooting [12], design of experiments [30, 28], and digital forensics to support legal reasoning [38]. Their graph-based formalism and automated support for probabilistic inference seem to lower adaption hurdles for a diverse set of users with different technical backgrounds. Bayesian Networks are also appealing since we may combine, within the same Bayesian Network, different aspects such as subjective beliefs expressed in probabilities, implicit trust assumptions reflected in a bias of information processing or the combinatorial logic of a process. Probabilistic inference for such combinations is supported, including belief updates based on observed evidence.\nBayesian Networks also come with methodological support for learning an appropriate graph structure as well as appropriate prior probability values at nodes in such graphs from\nar X\niv :1\n70 5.\n05 32\n6v 1\n[ cs\n.A I]\n1 5\nM ay\n2 01\n7\npre-existing data (see for example [29, 19]). The appropriateness of chosen prior probability values may depend on a variety of factors: the quality and quantity of data used for learning these values or the trust we place in experts who determine such values subjectively \u2013 to give two examples. We would therefore like reassurance that the prior distributions represented by such values are robust enough in that small changes to such values only result in small changes of posterior distributions of interest. This naturally leads to the consideration of robust Bayesian statistics [9, 10].\nA popular idea here is to approximate prior probabilities with intervals and to then calculate \u2013 somehow \u2013 the intervals that correspond to posterior probabilities. A good conceptual explanation of this is Good\u2019s black box model [26, 27], in which interval information of priors is submitted into a black box that contains all the usual methods associated with precise computations in Bayesian Networks, and where the box then outputs intervals of posteriors without limiting any interpretations or judgments on those output intervals.\nOur engagement with a problem owner in arms control made us realize the benefits of Good\u2019s black box model and made us identify opportunities for extending it to increase the confidence that users from such problem domains can place in models and their robustness. Specifically, we want to be able to\nR1 re-interpret compactly a BN as a possibly infinite set of BNs over the same graph, with robustness being analyzable over that re-interpretation\nR2 add logical constraints to capture domain knowledge or dependencies, and reflect constraints in robustness analyses in a coherent manner\nR3 compare models, within a composition context, to determine any differences in the robustness that they may offer for supporting decision making\nR4 parametrize the use of such a box so that it can produce outputs for any quantitative measure of interest definable as an arithmetic term\nR5 retain the \u201cblackness\u201d of the box so that the user neither has to see nor has to understand its inner workings\nR6 interpret outputs of the black box within the usual methodology of Bayesian Networks in as far as this may be possible.\nWe believe that these requirements are desired or apt in a wide range of problem domains, in addition to the fact that they should enhance usability of such a methodology in practice. We develop constrained Bayesian Networks in this paper and show that they meet the above requirements. This development is informed by advances made in areas of Symbolic Computation [34] and Automated Theorem Proving [23] (with its applications to Non-Linear, Non-Convex Optimization [8]), Three-Valued Model Checking [13], and Abstract Interpretation [15]. Concretely, we allow prior probabilities to be arithmetic expressions that may contain variables, and we enrich this model with logical constraints expressed in the theory of the reals.\nWe draw comparisons to related work, including Credal Networks [16, 22, 33] and Constraint Networks [24]. We then highlight similarities, differences, and complementary value of our approach to this previous work.\nContributions and methodology of the paper We develop a formal syntax and semantics of constrained Bayesian Networks which denote an empty, finite or infinite set of Bayesian Networks over the same directed acyclic graph. We support this concept with a composition operator in which two or more constrained Bayesian Networks with different or \u201coverlapping\u201d graphs may be combined for cross-model analysis, subject to constraints that are an optional parameter of that composition. We formulate a three-valued semantics of the theory of the reals over constrained BNs that captures the familiar duality of satisfiability and validity but over the set of Bayesian Networks that a constrained Bayesian Network denotes. This semantics is used to reduce the computation of its judgments to satisfiability checks in the first-order logic over the reals. We then apply that reduction to design optimization algorithms that can compute, for any term definable in that logic, infima and suprema up to a specified accuracy \u2013 for example for terms that specify the meaning of marginal probabilities symbolically. These optimization algorithms and their term parameter allow us to explore or verify the robustness of a constrained Bayesian Network including, but not limited to, the robustness of posterior distributions. We demonstrate the use of such extended robustness analyses on a non-trivial case study in the domain of arms control. We also report a tool prototype that we have implemented and used to conduct these analyses; it uses an SMT solver as a feasibility checker to implement these optimization algorithms; and it adapts an open-source package for Bayesian inference to symbolic computations.\nOur principal theoretical contribution is the introduction of the concept of a Constrained Bayesian Network itself, as well as its intuitive yet formal semantics. Our theoretical results, such as those for computational complexity and algorithm design, follow rather straightforwardly from these definitions. This is because the latter allow us to appeal directly to existing results from the existential theory of the reals and optimization based thereupon.\nOur main practical contribution is the successful integration of a number of disparate techniques and approaches into a coherent semantic framework and tool prototype that supports a range of modelling and analysis capabilities, and does so in a highly automated manner."}, {"heading": "2 Background on Bayesian Networks", "text": "A Bayesian Network (BN) is a graph-based statistical model for expressing and reasoning about probabilistic uncertainty. The underlying graph is directed and acyclic, a DAG. Nodes in this DAG represent random variables defined by discrete probability distributions that are also a function of the random variables represented by the parent nodes in the DAG. In other words, a random variable is conditioned on the random variables of its parent nodes.\nWe can use a BN to compute probabilities for events of interest over these random variables. Bayesian inference also allows us to revise such probabilities when additional observations of \u201cevidence\u201d have been made.\nFigure 1 shows a simple BN, which is part of the folklore of example Bayesian Networks. It depicts the possible causes of wet grass on two neighbours\u2019 lawns. For example, the probabilities of Holmes\u2019 Grass Wet is conditioned on its parents\u2019 output \u2013 whether It Rains and Holmes\u2019 Sprinkler is turned On or Off. The probability of Holmes\u2019 Grass Wet = T, given that Holmes\u2019 Sprinkler = Off, Rain = F, for instance, is computed to be 0.05, and is formally\nstated as: ppHolmes\u2019 Grass Wet = T | Sprinkler = Off, Rain = Fq \u201c 0.05\nThis approach naturally gives cause to computations of the \u201coverall\u201d probability of an event happening, referred to as the marginal probability. In the Bayesian approach, the Junction Tree Algorithm (JTA) (see e.g. Chapter 6 in [6] for further details) may be used to revise a marginal of a BN because of \u201chard\u201d, respectively \u201csoft\u201d, evidence \u2013 the definite, respectively probabilistic, observation of an additional or new event.\nWe now formalize BNs and use this below to enrich BNs with modeling and reasoning capabilities that realize the aforementioned requirements.\nDefinition 1 1. A Bayesian network (BN) is a pair pG, \u03c0q where G is a finite, directed, acyclic graph G \u201c pN,Eq of nodes N and edge relation E \u0102 N \u02c6N , and where \u03c0 is a tuple p\u03c0nqnPN of formal probability tables.\n2. The formal probability table \u03c0n is defined as follows. Let pntpnq \u201c tn1 P N | pn1, nq P Eu be the (possibly empty) set of parents of n in DAG G and On the set of outcomes of the random variable at node n. Then \u03c0n is a discrete probability distribution, a function \u03c0n of type ` \u015b n1PpntpnqOn1 \u02d8 \u02c6On \u00d1 r0, 1s such that its mass \u0159 e \u03c0npeq equals 1.\nAbove, it is understood that \u015b n1PHOn1 equals t\u02dau; in that case, \u03c0n has type isomorphic to On \u00d1 r0, 1s."}, {"heading": "3 Constrained Bayesian Networks", "text": "Informally, a constrained BN is obtained from a BN by replacing one or more probabilities in its probability tables with symbolic expressions, and by adding constraints for variables used in these expressions or in quantitative terms of interest, and for variables that refer to marginal probabilities of interest. We write BCX for constrained BN with set of constraints C and variable set X.\nTo illustrate, in Figure 2 the probability tables for two nodes Sprinkler and Rain of the BN in Figure 1 are made symbolic with a variable x to obtain a constrained BN. This allows us to model strict uncertainty (also known as Knightian uncertainty) in the actual value of such probabilities. Our approach allows variables to be shared across such tables, as x is shared across the tables for Sprinkler and Rain. This is certainly useful, e.g., to express that a certain subjective probability is twice as likely as another one.\nWe use variables mpH and mpW to refer to marginal probabilities\nppHolmes\u2019 Grass Wet = Trueq (1) ppHolmes\u2019 Grass Wet = True | Watson\u2019s Grass Wet = Trueq (2)\nrespectively. The constraints we then consider are 0 \u010f x \u010f 1, to ensure that symbolic expressions still specify probability distributions, as well as the symbolic meaning of the marginal probabilities mpH and mpW which are captured in two non-linear equations in x as\nmpH \u201c 0.495\u02dax\u02dax` 0.5\u02dax\u02dap\u00b40.95\u02dax` 0.95q ` 0.7\u02dax\u02dap\u00b40.5\u02dax` 1q ` 1.0\u02dap\u00b40.5\u02dax` 1q\u02dap\u00b40.05\u02dax` 0.05q (3)\nmpW \u02dap0.35\u02dax\u02dax` 0.025\u02dax\u02dap\u00b40.95\u02dax` 0.95q ` 0.7\u02dax\u02dap\u00b4x\u02da0.5` 1q ` 0.025\u02dax\u02dap\u00b40.05\u02dax` 0.05q ` 0.05\u02dap\u00b40.95\u02dax` 0.95q\u02dap\u00b4x\u02da0.5` 1q ` 0.05\u02dap\u00b4x\u02da0.5` 1q\u02dap\u00b40.05\u02dax` 0.05qq \u201c p0.3465\u02dax\u02dax` 0.025\u02dax\u02dap\u00b40.95\u02dax` 0.95q ` 0.49\u02dax\u02dap\u00b4x\u02da0.5` 1q ` 0.05\u02dap\u00b4x\u02da0.5` 1q\u02dap\u00b40.05\u02dax` 0.05qq (4)\nThe above equations are constructed through symbolic interpretations of computations of marginals, for example of the Junction Tree Algorithm, and subsequent elimination of\nt ::\u201c c | mp | x | t` t | t \u02da t \u03d5 ::\u201c true | t \u010f t | t \u0103 t | \u03d5 | \u03d5^ \u03d5 \u03c6 ::\u201c \u03d5 | Dx : \u03c6 | \u03c6 | \u03c6^ \u03c6\nFigure 3: BNF grammars for real-valued terms t, constraints \u03d5, and queries \u03c6 where x are variables from set Xx, c are constant reals, mp are variables from set Xmp denoting marginal probabilities, and true denotes logical truth\ndivision operators. The latter computes a normal form of rational terms from which these equations are easily derived."}, {"heading": "3.1 Theoretical Foundations", "text": "We begin the formal development by defining grammars for symbolic expressions that occur in probability tables and for properties that contain such expressions as arguments. Figure 3 shows definitions for real-valued terms t, where c ranges over real constants, and x and mp are real variables ranging over variable sets Xx and Xmp, respectively. The distinction between mp and x is one of modelling intent. Variables mp refer to marginal probabilities of a constrained BN BCX . The meaning of these symbolic marginals is defined via constraints in C. Variables in Xx may occur in symbolic expressions in probability tables of nodes or denote any quantitative measures of interest. We write X \u201c XxYXmp for the disjoint union of such variable sets.\nConstraints \u03d5 are quantifier-free formulas built from inequalities over terms t, logical truth constant true, and propositional operators. Queries \u03c6 are built out of constraints and first-order quantifiers.\nDefinition 2 We write T rXs for the set of all terms t, CrXs for the set of all constraints \u03d5 generated in this manner, and we write QrXs for the set of all queries \u03c6 generated in this manner from variable set X.\nWe write T , C, and Q whenever X is clear from context and write _, \u00b4, \u201c, \u0105 and so forth for derived logical, arithmetic, and relational operators.\nWe may think of a constrained BN BCX as a BN B in which entries in probability tables of nodes may not only be concrete probabilities but terms t of the grammar in Figure 3 over variable set Xx, and where the BN is enriched with a finite set of constraints C \u201c t\u03d5i | 1 \u010f i \u010f nu. The intuition is that BCX denotes a set of BNs that all have the same graph and the same structure of probability tables but where probability values may be uncertain, modelled as arithmetic terms, and subject to application-specific or analysis-specific constraints. The only difference in two BNs from that set may be in the real number entries in those probability tables, and those real numbers are instantiations of the specified arithmetic terms such that all constraints are met. We formalize this:\nDefinition 3 A constrained BN of type pXx, Xmpq \u2013 denoted as X \u201c Xx Y Xmp by abuse of notation \u2013 is a triple pG,C, \u03c0q where G \u201c pN,Eq is a finite DAG, C a finite set of constraints from CrXs, and \u03c0 a tuple p\u03c0nqnPN of symbolic probability tables with On as the\nset of outcomes of random variable at node n:\n\u03c0n : `\n\u017a\nn1Ppntpnq\nOn1 \u02d8 \u02c6On \u00d1 T rXxs\nNote that a symbolic probability table has the same input type as a formal probability table, but its output type is a set of terms not the unit interval. Let us first define syntactic restrictions for constrained BNs.\nDefinition 4 1. A constrained BN pG,C, \u03c0q of type X is well-formed if\n(a) X \u201c Xx YXmp equals the set of variables that occur in C (b) all mp in Xmp have exactly one defining equation mp \u201c t or mp\u02da t \u201c t1 in C where\nneither t nor t1 contain variables from Xmp.\n2. When G and \u03c0 are determined by context, we refer to a well-formed, constrained BN pG,C, \u03c0q of type X as BCX .\nItem 1(a) says that all variables in X occur in some constraint from C. Item 1(b) ensures all variables mp that model marginal probabilities have a defined meaning in C. Note that item 1(b) is consistent with having other constraints on such variables in C, for example a constraint saying that 0.1 \u010f mp \u010f x \u02da y. These items create a two-level term language, with variables in Xx informing meaning of variables in Xmp.\nA sound, constrained BN has a semantic requirement about its concretizations, which we now formalize using assignments for quantifier-free formulas.\nDefinition 5 1. An assignment \u03b1 is a function \u03b1 : X \u00d1 R. For c in R and x in X, assignment \u03b1rx \u00de\u00d1 cs equals \u03b1 except at x, where it outputs c.\n2. The meaning \u03b1ptq of term t in T under \u03b1, as well as the judgment \u03b1 |\u00f9 \u03c6 for all \u03c6 in Q, are defined in Figure 4.\nNote that \u03b1ptq extends \u03b1 : X \u00d1 R to type T rXs \u00d1 R. The judgment \u03b1 |\u00f9 \u03c6 is satisfaction of first-order logic over the reals. We use these judgments to define the set of concretizations of a well-formed, constrained BN:\nDefinition 6 Let BCX \u201c pG,C, \u03c0q be a well-formed, constrained BN where G \u201c pN,Eq. Let \u03b1 : X \u00d1 R be an assignment.\n1. We write BCXr\u03b1s for the BN pG, \u03c0r\u03b1sq that forgets C from BCX and has formal probability table \u03c0r\u03b1sn for each node n with \u03c0r\u03b1sn \u201c \u03bbe : \u03b1p\u03c0npeqq.\n2. The set \u201c |BCX | \u2030 of BNs that BCX denotes, its set of concretizations, is\n\u201c |BCX | \u2030 \u201c tBCXr\u03b1s | \u03b1 : X \u00d1 R and \u03b1 |\u00f9 \u013e \u03d51PC \u03d51u (5)\nNote that the formal probability table \u03c0r\u03b1sn computes \u03c0r\u03b1snpeq as \u03b1ptq where t is the term \u03c0npeq in T rXxs. We can now define sound constrained BNs.\nDefinition 7 Let BCX \u201c pG,C, \u03c0q be a well-formed, constrained BN. Then BCX is sound if for all BCXr\u03b1s that are concretizations of BCX we have, for all nodes n and inputs e of \u03c0r\u03b1sn, that \u03c0r\u03b1snpeq is in r0, 1s and \u0159 e \u03c0r\u03b1snpeq \u201c 1.\nSoundness is saying that all concretizations of a well-formed, constrained BN are actually BNs: for each such BCXr\u03b1s and node n in it, \u03c0r\u03b1sn is a discrete probability distribution.\nAssumption 1 All constrained BNs used in this paper are sound.\nIt is important to know whether \u201c |BCX | \u2030 is non-empty.\nDefinition 8 A constrained BCX is consistent iff \u201c |BCX | \u2030 \u201c H.\nThe techniques developed in the next Section 3.2 will also allow us to decide whether a constrained BN is consistent."}, {"heading": "3.2 Semantic Judgments", "text": "How should we best reason about a set of BNs \u201c |BCX | \u2030\n? We propose two semantic judgments that allow us to explore worst-case and best-case properties of BCX . A judicious combination of these judgments also enables us to express optimizations over the imprecision and probabilistic uncertainty inherent in BCX , whilst reflecting any application-specific or analysis-specific constraints. Both semantic judgments rest on a satisfaction relation between concretization BNs and queries. We define this formally.\nDefinition 9 Let BCX be a constrained BN. For all \u03c6 in Q, the two semantic judgments |\u00f9must and |\u00f9may are defined as\nBCX |\u00f9must\u03c6 iff for all BCXr\u03b1s in BCX we have \u03b1 |\u00f9 \u03c6 (6) BCX |\u00f9may\u03c6 iff for some BCXr\u03b1s in BCX we have \u03b1 |\u00f9 \u03c6 (7)\nThe definition in (6) allows us to discover invariants : truth of BCX |\u00f9must\u03c6 implies that \u03c6 holds no matter what concrete instance in \u201c\n|BCX | \u2030\nthe modeller may face, a form of worst-case reasoning. Dually, the truth of BCX |\u00f9may\u03c6 in (7) implies it is possible that the modeller faces a BN in \u201c\n|BCX | \u2030 that satisfies \u03c6, a form of best-case reasoning. We may formalize this duality.\nTheorem 1 For all constrained BNs BCX and \u03c6 in Q we have\n1. BCX |\u00f9must\u03c6 iff not BCX |\u00f9may \u03c6\n2. BCX |\u00f9may\u03c6 iff not BCX |\u00f9must \u03c6\n3. BCX |\u00f9must\u03c61 ^ \u03c62 iff (BCX |\u00f9must\u03c61 and BCX |\u00f9must\u03c62)\n4. BCX |\u00f9may\u03c61 _ \u03c62 iff (BCX |\u00f9may\u03c61 or BCX |\u00f9may\u03c62)\nWe illustrate this formalization of constrained BNs with an example.\nExample 1 The constrained BN from Figures 1 and 2 is sound and consistent. Consider the query \u03d5H being mpH \u0103 0.3 where we use variable mpH to denote the marginal probability ppHolmes\u2019 Grass Wet = Trueq. We mean to compute whether BCX |\u00f9must\u03d5H and BCX |\u00f9may\u03d5H hold for this constrained BN. We conclude that BCX |\u00f9must\u03d5H does not hold: ppHolmes\u2019 Grass Wet = Trueq equals 0.35255 for \u03b1pxq \u201c 0.3 and so \u03b1pmpHq \u201c 0.35255 as well, and we have \u03b1 |\u00f9 \u0179\n\u03d51PC \u03d5 1 and 0.35255 \u0119 0.3. On the other hand, BCX |\u00f9may\u03d5H holds\nsince for \u03b11pxq \u201c 0.1 we have \u03b11 |\u00f9 \u0179 \u03d51PC \u03d5 1 and \u03b11pmpHq \u201c 0.15695 is less than or equal to 0.3. Observing additional hard evidence that Watson\u2019s grass is wet, we similarly evaluate judgments BCX |\u00f9may\u03d5 and BCX |\u00f9must\u03d5 when \u03d5 contains mpW which refers to marginal\nppHolmes\u2019 Grass Wet = True | Watson\u2019s Grass Wet = Trueq"}, {"heading": "3.3 Consistent constrained BNs", "text": "It is important to understand how the semantic judgments |\u00f9may and |\u00f9must relate to consistent or inconsistent constrained BNs. We can characterize consistency through properties of these semantic judgments:\nTheorem 2 Let BCX be a constrained BN. Then the following are all equivalent:\n1. BCX |\u00f9maytrue holds.\n2. BCX is consistent.\n3. For all \u03c6 in Q, we have that BCX |\u00f9must\u03c6 implies BCX |\u00f9may\u03c6.\n4. For all \u03c6 in Q, we have that BCX |\u00f9may\u03c6_ \u03c6 holds.\n5. For all \u03c6 in Q, we have that BCX |\u00f9must\u03c6^ \u03c6 does not hold.\nWe stress that it is vital to check the consistency of BCX prior to relying on any findings of its further analysis. If BCX is inconsistent, then \u201c |BCX | \u2030\nis empty and so BCX |\u00f9must\u03c6 holds trivially for all \u03c6 in Q since the universal quantification of its defining semantics in (6) ranges over the empty set. Not detecting such inconsistency may thus lead to unintended and flawed reasoning. In our tool, this is a non-issue as it uses these judgments within optimization algorithms that either report a concretization as witness or report a discovered inconsistency.\nConsistency checking is NP-hard: checking the satisfiability of constraints in logic C is NP-hard. And so this hardness is inherited for any notion of size of a constrained BN that includes the sum of the sizes of all its constraints."}, {"heading": "3.4 Reducing |\u00f9may and |\u00f9must to satisfiability checking", "text": "Our case studies involving constrained BNs suggest that it suffices to consider elements of C, i.e. to consider formulas of Q that are quantifier-free. The benefit of having the more expressive logic Q, however, is that its quantifiers allow us to reduce the decisions for BCX |\u00f9may\u03d5 and BCX |\u00f9must\u03d5 for quantifier-free formulas \u03d5 to satisfiability checking, respectively validity checking in the logic Q \u2013 which we now demonstrate. For sound, constrained BNs BCX , the judgment BCX |\u00f9may\u03d5 asks whether there is an assignment \u03b1 : X \u00d1 R such that \u03b1 |\u00f9 \u0179 \u03d51PC \u03d5 1 and \u03b1 |\u00f9 \u03d5 both hold. Since C is contained in Q, we may capture this meaning within the logic Q itself as a satisfiability check. Let set X equal tx1, . . . , xnu. Then, asking whether \u03b1 |\u00f9 \u0179\n\u03d51PC \u03d5 1 and \u03b1 |\u00f9 \u03d5 hold, asks whether the formula in (8) of logic Q is satisfiable:\nDx1 : . . . : Dxn : \u03d5^ \u013e \u03d51PC \u03d51 (8)\nDefinition 10 For a constrained BN BCX and \u03d5 in C, we write ExpBCX , \u03d5q to denote the formula defined in (8).\nNote that ExpBCX , \u03d5q depends on BCX : namely on its set of variables X and constraint set C, the latter reflecting symbolic meanings of marginal probabilities. Let us illustrate this by revisiting Example 1.\nExample 2 For \u03d5H as in Example 1 with type X \u201c txuY tmpHu, the formula we derive for BCX |\u00f9may\u03d5H is\nDmpH : Dx : pmpH \u0103 0.3q ^ p0.1 \u010f xq ^ px \u010f 0.3q ^ (9) p0.5 \u02da x` p1\u00b4 0.5 \u02da xq \u201c 1q ^ px` p1\u00b4 xq \u201c 1q ^ pmpH \u201c tq\nwhere t is the term on the righthand side of the equation in (3).\nWe can summarize this discussion, where we also appeal to the first item of Theorem 1 to get a similar characterization for |\u00f9must.\nTheorem 3 Let BCX be a constrained BN and \u03d5 in C. Then we have:\n1. Formula ExpBCX , \u03d5q in (8) is in Q and in the existential fragment of Q.\n2. Truth of BCX |\u00f9may\u03d5 is equivalent to the satisfiability of ExpBCX , \u03d5q in Q.\n3. BCX |\u00f9may\u03d5 can be decided in PSPACE in the size of formula ExpBCX , \u03d5q.\n4. BCX |\u00f9must\u03d5 can be decided in PSPACE in the size of formula ExpBCX , \u03d5q.\nThis result of deciding semantic judgments in polynomial space pertains to the size of formulas ExpBCX , \u03d5q and ExpBCX , \u03d5q, and these formulas contain equations that define the meaning of marginals symbolically. There is therefore an incentive to simplify such symbolic expressions prior to their incorporation into C and these formulas, and we do such simplifications in our implementation."}, {"heading": "3.5 Constrained Union Operator", "text": "We also want the ability to compare two or more constrained BNs or to discover relationships between them. This is facilitated by a notion of composition of constrained BNs, which we now develop. Consider two constrained BNs BC1X1 and B C2 X2\n. Our intuition for composition is to use a disjoint union of the graphs of each of these constrained BNs such that each node in this unioned DAG still has its symbolic probability table as before. This union operator renames nodes that appear in both graphs so that the union is indeed disjoint. As a set of constraints for the resulting constrained BN, we then consider C1 Y C2.\nIt is useful to make this composition depend on another set of constraints C. The idea is that C can specify known or assumed relationships between these BNs. The resulting composition operator CY defines the composition\nBC1X1 CYBC2X2 (10)\nas the constrained BN with graph and probability tables obtained by disjoint union of the graphs and symbolic probability tables of BC1X1 and B C2 X2\n, where the set of constraints for this resulting constrained BN is now C1 Y C2 Y C.\nThis composition operator has an implicit assumption for being well defined, namely that C does not contain any equations that (re)define the (symbolic) meaning of marginal probabilities given in C1 Y C2.\nWe give an example of such a union of constrained BNs that already illustrates some reasoning capabilities to be developed in this paper:\nExample 3 Figure 5 specifies a constrained BN B C10 X 10\nthat is similar to constrained BN BC0X0 defined in Figure 2 but that models rain with more specificity. Variables y and z are used in symbolic probabilities, and variables mp1H and mp 1 W refer to the marginals in (1) and (2) respectively. The constraint 0.1 \u010f 5\u02day \u010f 0.3 in C 10 corresponds to the constraint 0.1 \u010f x \u010f 0.3 in C0 and so term 5 \u02da y in some way reflects x, that it rains according to BC0X0.\nThe constraint set C that binds the two models together is t2 \u02da z \u201c xu, which ensures that the probability for the sprinkler to be on is the same in both models. In the constrained\nBN BC0X0 CYBC\n1 0\nX 10 , we want to understand the difference in the marginal probabilities mpW and\nmp1W , expressed by term diff \u201c mpW \u00b4mp1W . Subtraction \u00b4 and equality \u201c are derived operations in Q. The methods we will develop in this paper allow us to conclude that the maximal value of diff is in the closed interval r0.134079500198, 0.134079508781s, with diff being 0.134079500198 when\nx \u201c 0.299999999930 z \u201c 0.149999999965 y \u201c 0.020000000003 mpW \u201c 0.663714285678 mp1W \u201c 0.529634782614\nSimilarly, we may infer that the minimum of diff is in the closed interval\nr\u00b40.164272228181,\u00b40.164272221575s\nwith diff being \u00b40.164272221575 when\nx \u201c 0.100000000093 z \u201c 0.050000000046 y \u201c 0.059999999855 mpW \u201c 0.472086956699 mp1W \u201c 0.636359183424"}, {"heading": "In particular, the absolute value of the difference of the marginal probability (2) in those", "text": "constrained BNs is less than 0.1643, attained for the values just shown.\nThese union operators are symmetric in that BC1X1 CYBC2X2 and B C2 X2 CYBC1X1 satisfy the same judgments |\u00f9must and |\u00f9may for all \u03c6 in Q. Idempotency won\u2019t hold in general as unions may introduce a new set of constraints C. Associativity holds, assuming all compositions in (11) give rise to sound constrained BNs:\npBC1X1 CYBC2X2q C1YBC3X3 is equivalent to B C1 X1 CYpBC2X2 C1YBC3X3q (11)\nAssumption 2 All composed, constrained BNs BC1X1 CYBC2X2 used in this paper are sound."}, {"heading": "3.6 Non-Linear Optimization", "text": "We next relate the judgments |\u00f9may and |\u00f9must to optimization problems that seek to minimize or maximize values of terms t of interest in a constrained BN BCX , and where B C X itself may well be the result of a composition of constrained BNs as just described. We define the set of \u201cconcretizations\u201d of term t for BCX :\nDefinition 11 Let t be a term whose variables are all in X for a constrained BN BCX . Then t| t |u \u010e R is defined as set t\u03b1ptq | BCXr\u03b1s P \u201c |BCX | \u2030 u.\nNote that t| t |u does depend on C and X as well, but this dependency will be clear from context. We can compute approximations of sup t| t |u and inf t| t |u, assuming that these values are finite. To learn that sup t| t |u is bounded above by a real high, we can check whether BCX |\u00f9mustt \u010f high holds. To learn whether sup t| t |u is bounded below by a real low, we can check whether BCX |\u00f9maylow \u010f t holds. Gaining such knowledge involves both judgments |\u00f9must and |\u00f9may. So we cannot compute approximations of sup t| t |u directly in the existential fragment of Q but search for approximations by repeatedly deciding such judgments.\nWe want to do this without making any assumptions about the implementation of a decision procedure for logic Q or its existential fragment. This can be accommodated through the use of extended binary search, as seen in Figure 6, to derive an algorithm Sup for computing a closed interval rlow, highs of length at most \u03b4 \u0105 0 such that sup t| t |u is guaranteed to be in rlow, highs. This algorithm has as input a constrained BN BCX with X as set of variables for constraint set C, a term t in T rXs, and a desired accuracy \u03b4 \u0105 0. This algorithm assumes that BXC is consistent and that 0 \u0103 sup t| t |u \u0103 8. We explain below how we can weaken those assumptions to sup t| t |u \u0103 8.\nAlgorithm Sup first uses a satisfiability witness \u03b1 to compute a real value \u03b1ptq that t can attain for some BCXr\u03b1s in \u201c |BCX | \u2030\nsuch that \u03b1ptq \u0105 0. It then stores this real value in a cache and increases the value of cache each time it can find a satisfiability witness that makes the value of t at least twice that of the current cache value. Since sup t| t |u \u0103 8, this while loop terminates. The subsequent assignments to low and high establish an invariant that there is a value in t| t |u that is greater or equal to low, but that there is no value in t| t |u that is greater or equal to high.\nThe second while statement maintains this invariant but makes progress using bisection of the interval rlow, highs. This is achieved by deciding whether there is a value in t| t |u that is greater or equal to the arithmetic mean of low and high. If so, that mean becomes the new value of low, otherwise that mean becomes the new value of high. By virtue of these invariants, the returned closed interval rlow, highs contains sup t| t |u as desired. We capture this formally:\nTheorem 4 Let BCX be a consistent constrained BN and \u03b4 \u0105 0. Let 0 \u0103 sup t| t |u \u0103 8. Then we have:\n1. Algorithm Suppt, \u03b4, BCXq terminates, sup t| t |u is in the returned closed interval rl, hs of length \u010f \u03b4, and BCX |\u00f9mayt \u011b l is true.\n2. Let c be the initial value of cache. Then the algorithm makes at most t2\u00a8log2psup t| t |uq\u00b4 log2pcq \u00b4 log2p\u03b4q ` 1u satisfiability checks for formulas ExpBCX , t \u011b rq or ExpBCX , t \u0105 rq,\nSuppt, \u03b4, BCXq t let \u03b1 : X \u00d1 R make ExpBCX , t \u0105 0q true; cache \u201c \u03b1ptq; while pExpBCX , t \u011b 2 \u02da cacheq satisfiableq t let \u03b11 : X \u00d1 R make ExpBCX , t \u011b 2 \u02da cacheq true; cache \u201c \u03b11ptq; u low \u201c cache; high \u201c 2 \u02da cache; assert ppExpBCX , t \u011b lowq satisfiableq&& pExpBCX , t \u011b highq unsatisfiableqq; while p| high\u00b4 low | \u0105 \u03b4q t if pExpBCX , t \u011b low` | high\u00b4 low | { 2qq satisfiableq t low \u201c low` | high\u00b4 low | { 2; assert ppExpBCX , t \u011b lowq satisfiableq&& pExpBCX , t \u011b highq unsatisfiableqq; u else t high \u201c low` | high\u00b4 low | { 2; assert ppExpBCX , t \u011b lowq satisfiableq&& ExpBCX , t \u011b highq unsatisfiableqq; u u return rlow, highs; u\nWe now give an example of using algorithm Sup. Our specifications of optimization algorithms such as that of algorithm Sup in Figure 6 do not return witness information, we omitted such details for sake of simplicity.\nExample 4 For constrained BN BC0X0 of Figure 2, SuppmpW , \u03b4, B C0 X0 q terminates for \u03b4 \u201c 0.000000001 with output r0.663714282364, 0.663714291751s. The value 0.663714282364 is attained when x equals 0.299999999188.\nAn algorithm Infpt, \u03b4, BCXq is defined in Figure 7. It assumes that BCX is consistent and that inf t| t |u is a subset of R`0 and contains a positive real \u2013 conditions we will weaken below. In that case, it terminates and returns a closed interval rl, hs such that inf t| t |u is in rl, hs. We prove this formally:\nTheorem 5 Let BCX be a consistent constrained BN and \u03b4 \u0105 0. Let t| t |u \u010e R`0 contain a positive real. Then we have:\n1. Algorithm Infpt, \u03b4, BCXq terminates and inf t| t |u is in the returned interval rl, hs such that h\u00b4 l \u010f \u03b4 and BCX |\u00f9mayt \u010f h are true.\nInfpt, \u03b4, BCXq t let \u03b1 : X \u00d1 R make ExpBCX , t \u0105 0q true; cache \u201c \u03b1ptq; while pExpBCX , t \u010f 0.5 \u02da cacheq satisfiable and 0.5 \u02da cache \u0105 \u03b4q t let \u03b11 : X \u00d1 R make ExpBCX , t \u010f 0.5 \u02da cacheq true; cache \u201c \u03b11ptq; u if pExpBCX , t \u010f 0.5 \u02da cacheq satisfiableq t return r0, 0.5 \u02da caches; u low \u201c 0.5 \u02da cache; high \u201c cache; assert pExpBCX , t \u010f lowq unsatisfiableq&& pExpBCX , t \u010f highq satisfiableqq; while p| high\u00b4 low | \u0105 \u03b4q t if pExpBCX , t \u010f low` | high\u00b4 low | { 2qq satisfiableq t high \u201c low` | high\u00b4 low | { 2; assert ppExpBCX , t \u010f lowq unsatisfiableq&& pExpBCX , t \u010f highq satisfiableqq; u else t low \u201c low` | high\u00b4 low | { 2; assert ppExpBCX , t \u010f lowq unsatisfiableq&& pExpBCX , t \u010f highq satisfiableqq; u u return rlow, highs; u\nWe now show how we can relax the conditions of BCX being consistent and of 0 \u0103 sup t| t |u \u0103 8 to sup t| t |u \u0103 8. In Figure 8, we see this modified algorithm Sup\u02da which relies on both Sup and Inf. It returns a closed interval with the same properties as that returned by Sup but where sup t| t |u only need be finite. We state the correctness of this algorithm formally:\nTheorem 6 Let BCX be a constrained BN, \u03b4 \u0105 0, and sup t| t |u \u0103 8. Then Sup\u2039pt, \u03b4, BCXq terminates and its calls to Sup and Inf meet their preconditions. Moreover, it either correctly identifies that BCX is inconsistent, that 0 is the maximum of t| t |u or it returns a closed interval rl, hs such that sup t| t |u is in that interval, h \u00b4 l \u010f is less than or equal to \u03b4, and BCX |\u00f9mayt \u011b l holds.\nWe conclude this section by leveraging Sup\u2039 to an algorithm Inf\u2039, seen in Figure 9. Algorithm Inf\u2039 relaxes that t| t |u contains a positive real and is a subset of R`0 to a more general pre-condition \u00b48 \u0103 inf t| t |u, and it has correct output for inconsistent, constrained BNs. We formalize this:\nSup\u2039pt, \u03b4, BCXq t if pExpBCX , t \u0105 0q satisfiableq t return Suppt, \u03b4, BCXq; u\nelseif pExpBCX , t \u201c 0q satisfiableq t return 0 as maximum for t; u\nelseif pExpBCX , t \u0103 0q satisfiableq t let rl, hs \u201c Infp\u00b4t, \u03b4, BCXq; return r\u00b4h,\u00b4ls; u return BCX is inconsistent; u\nFigure 8: Algorithm Sup\u2039 uses algorithms Sup and Inf and terminates whenever sup t| t |u \u0103 8. It either recognizing that 0 is the maximum of t| t |u, returns a closed interval rl, hs with h\u00b4 l \u010f \u03b4 such that sup t| t |u is in rl, hs, or it detects that BCX is inconsistent\nInf\u2039pt, \u03b4, BCXq t let x \u201c Sup\u2039p\u00b4t, \u03b4, BCXq; if px reports that BCX is inconsistentq t return BCX is inconsistent; u elseif px reports 0 as maximum for \u00b4tq t return 0 as minimum for t; u elseif px reports interval rl, hsq t return r\u00b4h,\u00b4ls; u u\nFigure 9: Algorithm Inf\u2039 uses algorithm Sup\u2039 and terminates whenever \u00b48 \u0103 inf t| t |u. It either recognizes that 0 is the minimum of t| t |u, returns a closed interval rl, hs with h\u00b4 l \u010f \u03b4 such that inf t| t |u is in rl, hs, or it detects that BCX is inconsistent\nTheorem 7 Let BCX be a constrained BN, \u03b4 \u0105 0, and t a term with \u00b48 \u0103 inf t| t |u. Then Inf\u2039pt, \u03b4, BCXq terminates and either correctly identifies that BCX is inconsistent, that 0 is the minimum of t| t |u or it returns a closed interval rl, hs of length \u010f \u03b4 such that inf t| t |u is in rl, hs and BCX |\u00f9mayt \u010f h holds.\nLet us revisit Example 3 to illustrate use of Sup\u2039.\nExample 5 Let C\u03030 be C0 Y t0.1 \u010f x \u010f 0.2u. For constrained BN BC\u03030X0 CYBC\n1 0\nX 10 , we maximise\ndiff using Sup\u2039pdiff, 0.000000001, BC\u03030X0 CYBC\n1 0\nX 10 q, which returns the interval\nr\u00b40.055219501217,\u00b40.0552194960809s\narising from the third case of Sup\u2039 as both ExpBCX , t \u0105 0q and ExpBCX , t \u201c 0q are unsatisfiable, but formula ExpBCX , t \u0103 0q is satisfiable. It shows that marginal mpW is always smaller than marginal mp1W in this constrained BN, in contrast to the situation of Example 3."}, {"heading": "4 Detailed Case Study", "text": "We now apply and evaluate the foundations for constrained BNs on a case study in the context of arms control. Article VI of the Treaty on the Non-Proliferation of Nuclear Weapons (NPT) [1] states that each treaty party\n\u201cundertakes to pursue negotiations in good faith on effective measures relating to cessation of the nuclear arms race at an early date and to nuclear disarmament, and on a treaty on general and complete disarmament under strict and effective international control.\u201d\nOne important aspect of meeting such treaty obligations may be the creation and execution of trustworthy inspection processes, for example to verify that a treaty-accountable item has been made inoperable. Designing such processes is challenging as it needs to guarantee sufficient mutual trust between the inspected and inspecting party in the presence of potentially conflicting interests. Without such trust, the parties might not agree to conduct such inspections.\nThe potential benefit of mathematical models for the design and evaluation of such inspection processes is apparent. Bayesian Networks can capture a form of trust \u2013 through an inherent bias of processing imperfect information \u2013 and different degrees of beliefs \u2013 expressed, e.g., in subjective probabilities. Bayesian Networks can also represent objective data accurately, and their graphical formalism may be understood by domain experts such as diplomats. These are good reasons for exploring Bayesian Networks for modeling and evaluating inspection processes. But Bayesian Networks do not seem to have means of building confidence in their adequacy and utility, especially in this domain in which prior data for learning both graph structure and probabilities at nodes in such a graph are hard to find. We now show how constrained BNs can be used to build such confidence in mathematical models of an inspection process."}, {"heading": "4.1 An Arms Control Inspection Process", "text": "Consider the situation of two fictitious nation states. The inspecting nation is tasked with identifying whether an item belonging to the host nation, available to inspect in a controlled inspection facility and declared by the host nation to be a nuclear weapon, is indeed a nuclear weapon. This situation is similar to a scenario that had been explored in the UK/Norway initiative in 2007 [3, 4].\nGiven the nations\u2019 non-proliferation obligations and national security concerns, the design details of the inspected item must be protected: the inspecting nation will have no visual access to the item. Instead the nations agree that the to-be-inspected item contain Plutonium with the isotopic ratio 240Pu:239Pu below a certain threshold value, which they set at 0.1.\nIn order to draw conclusions about whether an item presented for inspection is a weapon, the inspecting nation uses an information barrier (IB) system comprising a HPGe detector and bespoke electronics with well-understood performance characteristics (see Figure 10, [3]) to conduct measurements on the item while the item is concealed in a box. The IB system displays a green light if it detects a gamma-ray spectrum indicative of the presence of Plutonium with the appropriate isotopic ratio; if it does not detect this spectrum for whatever reason, it shows a red light. No other information is provided, and weapon-design information is thus protected [4].\nThe inspecting nation believes that it may be possible for the host nation to spoof a radioactive signal \u2013 or in some way provide a surrogate \u2013 to fool the detector, or that the host nation may have just placed Plutonium with the appropriate isotopic ratio in the box rather than a weapon. These subjective assessments should be reflected in the mathematical model alongside the error rates of the IB system that reflect the reliability of that device.\nIn order to deter cheating, the inspecting nation is allowed to choose the IBs used in the verification from a pool of such devices provided by the host nation, and may choose one or two IBs to that end. From that same pool of devices, the inspecting nation may take some unused IBs away for authentication \u2013 activities designed to assess whether the host nation tampered with the IBs. But the inspecting nation must not inspect any used IBs, to prevent it from exploiting any residual information still present in such used IBs to its advantage.\nThis selection process of IBs is therefore designed to ensure that a nefarious host nation\nis held at risk of detection should it decide to tamper with the IBs used in verification: it would run the risk of one or more tampered IBs being selected for authentication by the inspecting nation. Although such authentication cannot be assumed to be perfect \u2013 and this fact, too, should be modelled \u2013 the prospect of detection may deter such a host.\nWe model this inspection process through constrained BNs that are abstracted from a sole BN with DAG shown in Figure 11 and based on a design developed by the Arms Control Verification Research group at AWE. This DAG depicts different aspects of the verification procedure in four key areas:\n\u2022 the selection of the IBs for inspection or authentication purposes,\n\u2022 the workings of the IB in the inspection itself,\n\u2022 authentication of (other) IBs, and\n\u2022 the combination of these aspects to assess any possibility of cheating overall, be it through IB tampering, surrogate nuclear sources, and so forth.\nThe selection of the IBs starts with the IB pool size; a selection of IBs built by the host nation, from which there will be a Number of IBs picked for authentication and Number of IBs picked for use by the inspecting nation. Should a Number of tampered IBs exist, then the selection process (blind to such a tamper) follows a Hypergeometric distribution and will probabilistically determine whether such tampered IBs make it into use in the verification process, authentication process or neither. The choice of distribution reflects that IBs \u2013 once chosen for either verification or authentication \u2013 cannot be used for any other purpose.\nThe IBs picked for either authentication or verification help the inspecting nation to judge whether the item under inspection Is a weapon. A weapon or a Surrogate Pu source determine physical nuclear properties about the Isotopic ratio of Plutonium elements. Our mathematical model captures a possible inspector judgment that a surrogate source would only be used if the host felt that it was extremely likely to pass the IBs verification tests. Therefore, any surrogate source would have isotopic properties at least as good as those of a real weapon.\nWe stress that the probabilities chosen for each isotopic ratio, conditioned on whether the item under test is or is not a weapon, are not derived from real-world weapons data, but instead reflect in broad terms that Plutonium with a higher isotopic ratio than the chosen threshold is less likely to be found in a nuclear weapon. A bespoke algorithm is used by the IB system on the collected gamma-ray spectrum to test whether both the Peaks are in the expected locations and the Peak aspect ratio are as expected. If all 5 peaks are present and the Ratio of 240/239 isotopes is acceptable, then one or both of the First IB result or Second IB result are reported, conditional on any tampering and depending on whether or not two IBs are used to test the same item.\nA mathematical model cannot hope to reflect each potential tamper. Therefore, we model authentication as an assessment of the Inspector\u2019s authentication capabilities: the better these are, the more likely the Tamper will be found, and this requires that at least one tampered IB exists and was selected for authentication. This is controlled by the parent nodes: the aforementioned Hypergeometric distribution, and a node Chance of picking a tampered IB for authentication.\nThe mathematical model is drawn together by the overarching question of \u201cIs the Host cheating?\u201d. If so, we then determine a Cheating method, which reflects the understanding of the inspecting nation about the possible ways that the host nation could try to cheat, as outlined above, and the prior beliefs of the inspecting nation about the relative likelihood of the use of each method if the host nation were to be cheating.\nFinally, we check whether a Portal monitor is used to stop transportation of radioactive material \u2013 which could be used as a surrogate source \u2013 in and out of the facility, although we do not model this aspect in greater detail.\nThe probabilities used in this BN stem from a variety of sources. Some are somewhat arbitrarily selected, as described above, and therefore need means of building confidence in their choice. Probabilities relating to the performance of the IB system are derived from experimental analysis of the UKNI IB [4, 3].\nThe size of the probability tables for nodes of the BN in Figure 11 range from small (a few or tens of entries), to medium (hundreds of entries) and larger ones (thousands of entries). Given that complexity, we refrain from specifying more details on these tables within the paper itself.\nOur evaluation of the methods developed in Section 3 will abstract the BN described above (see Figure 11) into constrained BNs, and demonstrate that these abstractions can inform decision support given the sparsity or lack of prior data that informed its choices of probabilities.\nAssumption 3 For convenience, this case study will not explicitly list or show the constraints that define the meaning of marginals symbolically. These meanings are included in the open-access research code cited on page 34."}, {"heading": "4.2 Impact of Cheating Method on Tamper Detection", "text": "We want to understand how the choice of cheating method can impact the probability of detecting a tamper. The uncertainty about what cheating method the host nation will adopt is modelled in a constrained BN BC1X1 that takes the BN from Figure 11 and replaces the probability table for its node Cheating Method as specified in Figure 12. We use variables x, y, and u to denote, respectively, the probability of IB tamper only, Surrogate source tamper only, and both IB tamper and surrogate source tamper. The variable mptf refers to the marginal probability ppWill tamper be found? = Yesq.\nWe compute the interval rl, hs \u201c r0.197137598548, 0.197137608314s as output of the function call Sup\u2039pmptf , 0.00000001, BC1X1q. The witness information for the existentially quantified variables x, y, u, and mptf pertains to value l \u201c 0.197137598548:\nx \u201c 0.000000010001153 y \u201c 0.000000010001153 u \u201c 0.999999979997693\nWe compute the interval rl\u0303, h\u0303s \u201c r5.875158e\u00b409, 1.1750316e\u00b408s as output of function call Inf\u2039pmptf , 0.00000001, BC1X1q. The witness information is now for the value h\u0303 \u201c 1.1750316e\u0301 08 of mptf and we get\nx \u201c 0.000000030265893 y \u201c 0.999999939468212 u \u201c 0.000000030265893\nCheating Method\nWe may combine this information, for example to bound the range of values that mptf can possibly attain, as the interval\nrl\u0303, hs \u201c r0.000000000587, 0.197137608314s\nWe therefore conclude that this marginal probability can only vary by less than 0.19714 in the given strict uncertainty of the model.\nLet us now ask for what values of x can mptf be within 0.01 of the lower bound l \u201c 0.197137598548 returned for Sup\u2039 above. To that end, we consider the constrained BN B\nC11 X1\nwhere C 11 \u201c C1 Y t| mptf \u00b4 0.197137598548 | \u010f 0.01u and compute lower and upper bounds for x in this constrained BN:\nrlx, hxs \u201c Sup\u2039px, 0.00000001, BC 1 1\nX1 q \u201c r0.999999994824, 1.00000000196s\nrl\u0303x, h\u0303xs \u201c Inf\u2039px, 0.00000001, BC 1 1\nX1 q \u201c r7.4505805e\u0301 09, 1.4901161e\u0301 08s\nFrom this we can learn that\n@x : \u201c p1.4901161e\u0301 08 \u010f x \u010f 0.999999994824q ^ \u013e C1 \u2030\n\u00d1 | mptf \u00b4 0.197137598548 | \u010f 0.01 (12)\nis logically valid: whenever x is in that value range and all constraints in C1 are satisfied (which is true for all concretizations of BC1X1), then the marginal mptf is within 0.01 of the lower bound for its maximal value.\nRepeating these optimizations above for variables y and u, we determine similar formulas that are logically valid:\n@y : \u201c p1.209402e\u0301 08 \u010f y \u010f 0.0507259986533q ^ \u013e C1 \u2030\n\u00d1 | mptf \u00b4 0.197137598548 | \u010f 0.01\n@u : \u201c p1.4901161e\u0301 08 \u010f u \u010f 0.999999998164q ^ \u013e C1 \u2030\n\u00d1 | mptf \u00b4 0.197137598548 | \u010f 0.01\nThese results say that the marginal mptf is insensitive to changes to x, which is able to vary across the whole range p0.0, 1.0q without having much impact on the results; the\nAuthentication Capabilities\nsituation is very similar for variable u. For variable y, the range at which mptf is not too sensitive on changes of y is much smaller \u2013 just over 0.05. Overall, we conclude that the model remains in the area of highest probability for detecting tampering as long as x or u are large.\nOur analysis shows that the \u201ctamper\u201d cheating method is the one for which there is the highest chance of detecting cheating. However, our results also highlight that unless both tamper and surrogate source, or tamper on its own are used, there are limited ways in which to detect cheating through these nodes. From this we learn that use of a portal monitor is advisable, as any increase in y moves the marginal out of the region of highest probability of detecting cheating, and decreases the chance of cheating being detected otherwise. Related to this is that the range of y gives potential insight into future work required on tamper detection for the inspecting nation. Despite contributing neither to an IB tamper nor detection, y can vary by over 0.05 \u2013 over five times that of the movement away from the marginal mptf \u2019s maximum point by only 0.01. This suggests there are other limiting factors to tamper detection, such as capability, that could be better reflected in a mathematical model."}, {"heading": "4.3 Comparing two BN models", "text": "We now illustrate the benefits of composing two constrained BNs (see Section 3.5). Two constrained BNs, BC2X2 and B C12 X 12 , are defined in Figure 13. Both have symbolic and equivalent probability tables for node Authentication Capabilities but consider different hard evidence for the probability of a tamper to be found. In BC2X2 , there is 1 IB machine picked for authentication whereas in B C12 X 12 there are 5 IB machines picked to that end, resulting in the respective marginals\nppWill tamper be found? = Yes | Host cheating = Yes, (13) Number of IBs picked for authentication = 1q\nppWill tamper be found? = Yes | Host cheating = Yes, (14) Number of IBs picked for authentication = 5q\nIn both models, the probability for state \u201cGood\u201d is bounded by 0.6667 so that there is a \u201cgradient\u201d pivoting around Medium capabilities fixed at 0.3333.\nWe seek decision support on how much to prioritise research into IB authentication ca-\npabilities, each of BC2X2 and B C12 X 12 representing a different capability scenario. Of interest here is the change in the likelihood that a tamper will be found. We can simply model this by defining a new term\ndiff \u201c mptf2 \u00b4mptf 12 (15)\nVariable diff is in Xx for the constrained BN B C2 X2\nCYBC 1 2\nX 12 where the constraint set C for this\ncombination is tdiff \u201c mptf2 \u00b4mptf 12u. We compute the value of diff for each combination of values px, yq from set\nS \u201c tp0.0` 0.01 \u00a8 a, 0.0` 0.01 \u00a8 bq | 0 \u010f a, b \u010f 67u (16)\nand linearly interpolate the result as a surface seen in Figure 14. The linear relationship between the symbolic probabilities of node Authentication Capability to that of its child node Will the tamper be found? make this surface flat.\nWe can now use the method familiar from our earlier analyses to assess the value range of\nterm diff in this composed, constrained BN. The function call Sup\u2039pdiff, 0.00000001, BC2X2 CYBC\n1 2\nX 12 q\nreturns the interval\nrl, hs \u201c r0.0711404333363, 0.0711404338663s\nNext, Inf\u2039pdiff, 0.00000001, BC2X2 CYBC\n1 2\nX 12 q is computed as the interval\nrl\u0303, h\u0303s \u201c r\u00b40.307085548061,\u00b40.307085547533s\nIn particular, the values of diff for all concretizations of BC2X2 CYBC\n1 2\nX 12 lie in the interval\nr\u00b40.307085548061, 0.0711404338663s\nThe blue surface of diff in Figure 14 is mostly negative (below the red plane). This shows that the case of testing 5 IBs for tampers is nearly always better, irrespective of the confidence one may have in one\u2019s ability to find a tamper. This is true, other than for the most extreme cases when there is the least confidence in authentication capabilities when testing five IBs (for y \u201c 0) and most confidence when testing one (for x \u201c 0.667).\nLet us next explore a situation in which the inspector believes to have high authentication capabilities, regardless of whether 1 or 5 IBs are picked for authentication. We can easily model this by setting C 1 \u201c C Y t0.467 \u010f x, y \u010f 0.667u and refining the composed model using C 1. We compute the output of Sup\u2039pdiff, 0.00000001, BC2X2 CY 1 B C12 X 12 q to be the interval\nrl, hs \u201c r\u00b40.0282766319763,\u00b40.0282766314489s\nand Inf\u2039pdiff, 0.00000001, BC2X2 CY 1 B C12 X 12 q to be the interval\nrl\u0303, h\u0303s \u201c r\u00b40.141568560141,\u00b40.141568559299s\nNow diff is in r\u00b40.141568560141,\u00b40.0282766314489s and the largest absolute difference between picking 1 and 5 IBs for authentication is greater than 0.14, witnessed when the inspector has a particularly high capability in authenticating 5 IBs, (when y \u201c 0.667 and mptf 12 \u201c 0.24932) compared with only inspecting one IB with more moderate capability (when x \u201c 0.467,mptf2 \u201c 0.10696).\nA decision maker could vary the use of the above approach in order to weigh the cost of IB production against the cost of developing and employing more advanced authentication capabilities. He or she could also query in detail how the results of such cost-benefit analyses might change as new information is learned or new techniques deployed. This capability might help decision makers to balance their priorities and to gain the best assurance possible within a cost budget that the verification regime they implement is effective."}, {"heading": "4.4 Determining equivalent decision support", "text": "We assess the consistency of two different constrained BNs of equal intent of decision support. Constrained BNs BC3X3 and B C13 X 13 are identical to BC1X1 and its symbolic probability table for node Cheating Method as in Figure 12, except that th is an additional variable used to model decision support. Variable set Xmp also changes. For B C3 X3\nwe have Xmp \u201c tmptf3u and for B\nC13 X 13\nwe set Xmp \u201c tmptf 13u instead. Variable mptf3 denotes marginal probabilities for hard evidence that Initial Pool Size = 10 IBs in (17), whereas variable mptf 13 denotes a marginal for hard evidence Initial Pool Size = 20 IBs in (18):\nppWill tamper be found? = Yes | Initial Pool Size = 10q (17) ppWill tamper be found? = Yes | Initial Pool Size = 20q (18)\nThese are marginal probabilities that the nation which is authenticating IBs will find a tamper. A decision \u2013 for example that an IB has been tampered with \u2013 may then be supported if such a marginal is above a certain threshold th. We now want to understand whether the\ntwo constrained BNs would support decisions in the same manner, and for what values or value ranges of th.\nFor any value th, consider the constraint \u03d5th in Q given by\n\u201c` pth \u0103 mptf3q ^ pmptf 13 \u010f thq \u02d8 _ ` pth \u0103 mptf 13q ^ pmptf3 \u010f thq \u02d8\u2030\nWe can now analyze whether both constrained BNs will always support decisions through threshold th by evaluating\nBC3X3 CYBC\n1 3\nX 13 |\u00f9must\u03d5th (19)\nwhere C equals t0 \u0103 th \u0103 1u. By Theorem 1, judgment (19) is equivalent to\nnot BC3X3 CYBC\n1 3\nX 13 |\u00f9may\n` pth \u0103 mptf3q ^ pmptf 13 \u010f thq \u02d8 _ ` pth \u0103 mptf 13q ^ pmptf3 \u010f thq \u02d8\n(20)\nSetting \u03d51 \u201d pth \u0103 mptf3q ^ pmptf 13 \u010f thq and \u03d52 \u201d pth \u0103 mptf 13q ^ pmptf3 \u010f thq, the same theorem tells us that (20) is equivalent to\n\u201c not BC3X3 CYBC\n1 3\nX 13 |\u00f9may\u03d51\n\u2030 and \u201c not BC3X3 CYBC\n1 3\nX 13 |\u00f9may\u03d52\n\u2030\n(21)\nUsing our tool, we determine that ExpBC3X3 CYBC\n1 3\nX 13 , \u03d51q is unsatisfiable and so \u2013 by appeal to\nTheorem 3 \u2013 the first proof obligation of (21) holds. Similarly, we evaluate the satisfiability of ExpBC3X3 CYBC 1 3 X 13 , \u03d52q. Our tool reports this to be satisfiable and so the two constrained BNs do not always support the same decision. We now want to utilize our non-linear optimization method to compute ranges of the th itself for which both models render the same decision. Understanding such a range will be useful to a modeller as both models are then discovered to be in agreement for all values of th in such a range.\nSince ExpBC3X3 CYBC\n1 3\nX 13 , \u03d51q is unsatisfiable, we use C 1 \u201c t0 \u0103 th \u0103 1, \u03d52u which forces truth\nof \u03d52, and compute Sup \u2039pth, 0.00000001, BC3X3\nC1YBC 1 3\nX 13 q to maximise expression th. This obtains\nthe interval rl, hs \u201c r0.259147588164, 0.259147588909s\nComputing Inf\u2039pth, 0.00000001, BC3X3 C1YBC 1 3 X 13 q outputs the interval\nrl\u0303, h\u0303s \u201c r\u00b49.31322e\u0301 10,\u00b44.65661e\u0301 10s\nFor the given accuracy \u03b4, the interval rl\u0303, h\u0303s may be interpreted as 0. Thus, we can say that for all th in r0, 0.259147588909s the use of either BC3X3 or B C13 X3\ncould support different decisions. More importantly, we now know that both constrained BNs always support the same decision as described above when the value of the threshold th for decision making is greater or equal to 0.2592, say.\nThe range of th for which both models can support different decisions may seem rather large and it may be surprising that it goes down to zero. But this is a function of the chance and capability of finding a tamper in an IB. Intuitively, the models tend to disagree most in situations where the chance of cheating by tampering is highest, when x \u201c 1, and thus where\nCheating Method\nauthenticating the IB has benefit. Our approach gave a decision maker safe knowledge that any threshold for decision making outside the range r\u00b49.31322e\u0301 10, 0.259147588909s would statistically agree and lead to the same decision regarding finding tampers, irrespective of the initial number of IBs \u2013 either 10 or 20 \u2013 in the pool. Dependent on the nations involved, and the tolerances for decision making they are willing to set, it could be decided \u2013 for instance \u2013 that building only 10 IBs per inspection would be enshrined in the treaty to avoid unnecessary expense and so forth. This would undoubtedly be an important data-driven decision for diplomats and negotiators to make."}, {"heading": "4.5 Symbolic sensitivity analysis", "text": "It is well known that BNs may be sensitive to small changes in probability values in tables of some nodes. Sensitivity analyses have therefore been devised as a means for assessing the degree of such sensitivities and the impact this may have on decision support. See, e.g., the sensitivity value defined in [32, 31].\nWe now leverage such analyses to our approach by computing such sensitivity measures symbolically as terms of the logic Q. Then we may analyze such terms using the methods Sup\u2039 and Inf\u2039 as before to understand how such sensitivity measures may vary across concretizations of a constrained BN. We illustrate this capability for constrained BN BC4X4 , which is similar to BC1X1 but has probability table for node Cheating Method as shown in Figure 15. The sensitivity value describes the change in the posterior output of the hypothesis for small variations in the likelihood of the evidence under study. The larger the sensitivity value, the less robust the posterior output of the hypothesis. In other words, a likelihood value with a large sensitivity value is prone to generate an inaccurate posterior output. If the sensitivity value is less than 1, then a small change in the likelihood value has a minimal effect on the result of the posterior output of the hypothesis.\nA modeller may be uncertain about the sensitivity of event Will tamper be found? = Yes to the authentication of IBs if probabilities in node Authentication Capability of the IB were to change. Our tool can compute such a sensitivity value s symbolically for the sensitivity of event Will tamper be found? = Yes to small perturbations in probabilities of node Authentication Capability.\ns = 250.0*(0.000333567254313619*x + 0.171472799414097)* (0.000400681386562896*x + 0.205973332629545)**2* (0.000400681386562899*x + 0.205973332629545)* (0.00133627242418726*x + 0.686921064319534)/ ((0.19713762029366*x + 0.0638269490499437)* (4.01363933844916e-6*x**2 + 0.00412648402564936*x + 1.06062534386303)**2)\nwhere terms PO, Px, POx and PxO are defined as\nPO \u201d ppAuthentication Capability = Lowq (23) Px \u201d ppFinding a tamper in IB = Yesq\nPOx \u201d ppAuthentication Capability = Low | Finding a tamper in IB = Yesq PxO \u201d ppFinding a tamper in IB = Yes | Authentication Capability = Lowq\nAll three marginals of Authentication Capability are considered using just two functions POx and 1 \u00b4 POx. In (23), PO is a modelling choice that combines the states of Medium and High into one state (1\u00b4POx). Term 1\u00b4POx accounts for situations in which an inspector is relatively good at authentication, with POx representing situations in which they are less capable. Other modelling choices would lead to a marginally small difference in s.\nOur tool can compute an explicit function of s in variable x, as defined in (22). This symbolic expression for s is depicted in Figure 16 and shown as a function of x in Figure 17. This confirms that as the value of x increases, and thus the probability of \u201cIB tamper only\u201d seen in Figure 15 decreases, the marginal of interest for Will tamper be found? = Yes becomes less sensitive to changes in the probabilities of the node Authentication Capability of IB.\nWe can now determine the worst-case sensitivity value by computing the interval returned by function call Sup\u2039pts, 0.00000001, BC4X4q as r3.5838265468, 3.5838265475s where ts is the term in the righthand side of the equation in Figure 16 that describes s as a function of x. Thus we learn that this sensitivity cannot be larger than 3.5838265475 for all concretizations of constrained BN BC4X4 . As is evident from the graph, there are no valid values of x where the sensitivity value drops below 1.0 \u2013 the aforementioned bound at which a sensitivity score, and therefore its corresponding marginal probability, is deemed to be robust.\nThe output r1.17313380051, 1.17313380116s of Inf\u2039ps, 0.00000001, BC4X4q confirms this, and shows that s is always above 1.17313380051 for all concretizations of constrained BN BC4X4 . Knowing this may indicate to a decision-maker that potential deviations in the real domain from the model of node Authentication Capability will require close attention, irrespective of the value of x and thus of the perceived marginal probabilities of the states of node Cheating Method."}, {"heading": "5 Implementation and Evaluation", "text": ""}, {"heading": "5.1 Software Engineering", "text": "The numerical results reported in previous sections were computed by a prototype implementation of the approach developed in this paper. This implementation uses Python to capture a data model for Bayesian Networks and constraints, to formulate marginals of interest, and to interface with the SMT solver Z3 [23]. The latter we use as a decision procedure for logic Q that also returns witness information for all variables. The computation of symbolic meaning of marginals relies on the Junction Tree Algorithm and is achieved through software from an open-source Python package provided in [5].\nPython also supports a lightweight and open-source library for symbolic computation, sympy [34], which we can employ to run the Junction Tree Algorithm in [5] fully symbolically. The generated symbolic expressions are then simplified using a method of sympy before they are put into constraints such as in (3) and added to the SMT solver for analysis."}, {"heading": "5.2 Validation and Evaluation", "text": "Some symbolic marginals that we generated for analyses but not reported in our case study were too large to be handled by the SMT solver we used: the string representation of the symbolic meaning was about 25 Megabytes. We performed linear regression on those symbolic expressions and then validated that this approximation has higher precision than the accuracy \u03b4, before defining the meaning of marginal variables as these regressed expressions. Our openaccess research data, discussed on page 34, contains details on these analyses.\nWe evaluated the performance of the symbolic interpretation of the JTA as implemented in\n[5] on randomly generated constrained BNs. This does not evaluate our approach per se, but the manner in which we interpreted an existing inference implementation symbolically. We refer to our open-access data repository for more details on model generation: key parameters are the number of nodes |N |, the number of variables |Xx |, and a random choice of the number of states for each node (between 1 and 10 uniformly at random). Terms in probability tables have form c, x or 1\u00b4x for constants c or x in Xx. In generated models, a random node was picked to determine hard evidence \u2013 its first state having probability 1. The JTA was run for that hard evidence, and the time to complete it was recorded. These automated test suites ran on an institutional server with 64 Intel Xeon E5/Core i7 processors, on Ubuntu 14.04.\nMany of these tests terminated very quickly. Though, as the number of nodes per graph and the number of states per node increased, the running times increased on some but not all tests. The size of Xx seemed to have a limited effect, possibly indicating that the additional overhead of our approach to running the JTA implementation of [5] symbolically in Python is not huge.\nFigure 18 shows plots for the computation times (in seconds) of 1000 such test cases against the number of nodes, the size of Xx, the number of node states in total (a summation over all nodes) and the average length over all nodes of the outputted marginal text string in characters.\nFor this randomized test suite, there was a small trend for the running times to increase with the size of the DAG. But computations were still quicker for many of the BNs of larger size compared to smaller ones. The size of Xx appears to have little impact on computation time, nor any strong correlation to the length of the computed symbolic marginal. This suggests that use of symbolic probabilities may not in and of itself increase such empirical complexity."}, {"heading": "6 Discussion", "text": "Our approach advocates the use of constrained Bayesian Networks as a means of gaining confidence into Bayesian Network modelling and inference in the face of little or no data. A modeler may thus start with a BN, turn it into several constrained BNs and subject them to analysis, and perhaps modify the BN based on such findings. Witness information computed in analyses could, in principle, be fed back into a BN modeling tool so that users can see a concrete BN that would, for example, explain how a marginal of interest can attain a certain value in a constrained BN.\nThe ability to represent witness information as a concrete BN is also a means of testing whether the computation of symbolic meaning of marginals is free of errors. We have indeed conducted such tests to gain confidence into the correctness of our tool and the packages that it depends upon. Note also that errors in the symbolic meaning of marginals are likely to create numerical inconsistencies, so our analyses would detect such an inconsistent, constrained BN.\nThe algorithms that we devised for non-linear optimization made no assumptions about the internal workings of the decision procedure used and its witness information apart from that such results would be semantically correct. Knowledge of such internal details could,\nhowever, be exploited to speed up computation. For example, such a method is used in the SMT solver Z3 to optimize linear objective functions. One could therefore run different methods in parallel or even let them share information in between search iterations.\nOur tool prototype interprets the JTA implementation provided in [5] symbolically, and symbolic meanings of marginal variables may contain divisions. Of course, we could translate away all division operators without changing meaning \u2013 to match this with the formal setting of Section 3. We did not do this since our foundations apply equally to Q extended with division, such translations would increase the size of these terms, and the SMT solver we used, Z3, was able to process and reason with such or suitably simplified terms."}, {"heading": "7 Related Work", "text": "In [21], it is shown how probabilistic inference in Bayesian Networks can be represented through the evaluation and formal differentiation of a \u201cnetwork polynomial\u201d. The size of the polynomial can be reduced by its representation in an arithmetic circuit, in which evaluation and differentiation are more efficient. It would be of interest to determine whether this work can be extended to make the computation of symbolic marginals generated in our approach more efficient.\nFor Bayesian Networks there are methods for learning the structure of a DAG and for learning the probabilities within nodes of such a graph (see e.g. [29, 19]) \u2013 based on existing empirical data. We assumed in this paper that little or no data are available, ruling out the effective use of such learning methods. But our approach is consistent with settings in which plenty of data are available.\nBayesian Networks have tool support such as the software JavaBayes [2], which is able to perform robustness analysis. But this software can neither cope with the Knightian uncertainty of our approach, nor fuse networks of different structures together with non-trivial constraints.\nOur work in [8] reported early attempts of developing the approach presented in this paper: in [8], a much simpler Bayesian Network of a nuclear inspection process is presented and some analyses with preliminary versions of our tool are discussed; but that work offered neither formal foundations nor greater technical details for the methods it used. The more detailed Bayesian Network we studied in Section 4 was discussed in [7], along with a nontechnical summary of our general approach and some of its analysis findings.\nCredal networks \u2013 see e.g. [16] \u2013 refer to the theory and practice of associating a convex set of probability measures with directed, acyclic graphs. Credal networks are also referred to as the Theory of Imprecise Probabilities [39] or as the Quasi-Bayesian Theory [25].\nThe generalization of probability measures to sets of such measures can accommodate a formal notion of probabilistic independence, rooted in axioms of preferences as developed in [16]. The approach is based on constraints for such convex sets of probability measures. Inference algorithms and their approximations are bespoke for an interpretation of constraints; an interpretation is called an \u201cextension\u201d in [16].\nTo compare this to our approach, we follow Good\u2019s black box model in that our semantics and optimizations reflect Bayesian inference \u2013 even though this is done symbolically. Another difference is that a constrained Bayesian Network may have nodes with non-convex sets of\nprobability measures as meaning, for example when logical constraints on variables rule out certain points in intervals. Our approach is also more practical in outlook, since we rely on reductions to known and tried techniques, such as satisfiability checking for the existential theory of the reals. In contrast, theoretical results for Credal Networks range from different evidence propagation and inference methods (see e.g. [17, 20]) to deep relationships to logic programming and its semantics [18].\nIn [11], a methodology is developed for assessing sensitivity of lower and upper probabilities in Credal networks. It is shown that for some classes of parameters in Bayesian networks one may replace the Credal sets of probability measures associated with such parameters with a sole such measure. It would be of interest to determine whether these or similar results are attainable for suitable classes of constrained Bayesian Networks.\nConstraint Networks [24] are graphical representations that are meant to guide solution strategies for constraint satisfaction problems. In our tool prototype, we decoupled the choice of graph structure for a constrained Bayesian Network from the use of strategies for solving satisfiability problems over the existential theory of the reals. It may be beneficial to couple graph structure and satisfiability checking in tool support of our approach that relies on constraint satisfaction solvers."}, {"heading": "8 Conclusions", "text": "This work was motivated by the fact that some problem domains have little or no data that one could use to learn the structure of a causal network or the probabilities for nodes within that structure \u2013 whatever the reasons for such sparsity of data may be in such a domain. This led us to consider suitable generalizations of Bayesian Networks. Ideally, we wanted a formalism that those who already use Bayesian Networks for modeling and analysis would find easy to adopt. In particular, we sought to preserve \u2013 as much as possible \u2013 the manner in which probabilistic inference is done in Bayesian Networks. Crucially, we wanted a set of methods whose use could help us to build sufficient confidence into the quality, suitability or robustness of models expressed in such a formalisms in the face of little or no empirical data.\nWe propose constrained Bayesian Networks as such a formalism. The derivation of that concept is a contribution in and of itself, and it used first-order logic and its semantics as well as syntactic criteria for wellformedness. But it also required methods from three-valued logic to define a precise yet intuitive semantics for a constrained BN.\nWe also developed meta-properties of this semantics, including checks for the consistency of a constrained Bayesian Network. These properties were needed to prove the correctness of our optimization algorithms, which can compute suprema or infima of bounded arithmetic terms up to a specific accuracy. These optimization algorithms are non-standard in that they rely on a decision procedure for the theory of reals and in that the optimization problems are generally non-linear and non-convex.\nThe marginals in a constrained Bayesian Network are computed symbolically, but computed in the same manner as the marginals for a Bayesian Network \u2013 a concretization of that constrained Bayesian Network. This is appealing as it allows reuse of known and trusted methods such as the Junction Tree Algorithm. But it also creates a potential computational bottleneck with scope for future work that may extend an approach in [21] to our setting.\nWe implemented our approach in a tool prototype, which benefitted from the significant advances in symbolic computation and in the implementation of theorem provers such as SMT solvers. We evaluated this prototype through stress tests and a non-trivial case study in the domain of nuclear arms control. The latter is a domain in which the availability of data is very limited and where any means of building confidence into the trustworthiness of mathematical models are expected to have positive impact on arms reduction efforts.\nWe used this case study to illustrate some pertinent types of analyses of a constrained Bayesian Network that our approach can accommodate: a range analysis that computes infima and suprema for a term of interest to determine their robustness, the comparison of two or more constrained Bayesian Networks to assess modeling impact, the ability to determine ranges of threshold values that would render equivalent decision support, and the symbolic computation of a sensitivity measure for a given node \u2013 with the ability to optimize this to understand worst-case sensitivities. We trust that the approach presented in this paper will be useful for other applications in the arms-control domain, as well as in other domains \u2013 particularly those with a lack of data.\nAcknowledgements: This work was supported by AWE plc, and in part by the UK Engineering and Physical Sciences Research Council grants EP/N020030/1 and EP/N023242/1.\nOpen Access: The Python and SMT code for the queries and models of this paper and raw SMT analysis results are found in the public data repository\nbitbucket.org/pjbeaumont/beaumonthuthcbns/"}, {"heading": "A Mathematical Proofs", "text": "Proof of Theorem 1:\n1. We have that BCX |\u00f9must\u03c6 holds iff for all concretizations BCXr\u03b1s of BCX we have that \u03b1 |\u00f9 \u03c6 holds iff for all concretizations BCXr\u03b1s of BCX we have that \u03b1 |\u00f9 \u03c6 does not hold iff BCX |\u00f9may \u03c6 does not hold.\n2. We have that BCX |\u00f9may\u03c6 holds iff there is some concretization BCXr\u03b1s of BCX such that \u03b1 |\u00f9 \u03c6 holds iff there is some concretization BCXr\u03b1s of BCX such that \u03b1 |\u00f9 \u03c6 does not hold iff BCX |\u00f9must \u03c6 does not hold.\n3. (a) Let BCX |\u00f9must\u03c61 ^ \u03c62 hold. Let BCXr\u03b1s be a concretization of BCX . Then we know that \u03b1 |\u00f9 \u03c61^\u03c62 holds. This implies that \u03b1 |\u00f9 \u03c6i holds for i \u201c 1, 2. But then both BCX |\u00f9must\u03c61 and BCX |\u00f9must\u03c62 hold since BCXr\u03b1s was an arbitrary concretization of BCX .\n(b) Let both BCX |\u00f9must\u03c61 and BCX |\u00f9must\u03c62 hold. Let BCXr\u03b1s be a concretization of BCX . Then BCX |\u00f9must\u03c6i implies that \u03b1 |\u00f9 \u03c6i holds for i \u201c 1, 2. Therefore, we get that \u03b1 |\u00f9 \u03c61 ^ \u03c62 holds as well. Since BCXr\u03b1s was an arbitrary concretization of BCX , this gives us that BCX |\u00f9must\u03c61 ^ \u03c62 holds.\n4. (a) Let BCX |\u00f9may\u03c61 _ \u03c62 hold. Then there is some concretization BCXr\u03b1s of BCX such that \u03b1 |\u00f9 \u03c61 _ \u03c62 holds. This implies that \u03b1 |\u00f9 \u03c6i holds for some i \u201c 1, 2. But then BCX |\u00f9may\u03c6i holds as claimed.\n(b) Let one of BCX |\u00f9may\u03c61 and BCX |\u00f9may\u03c62 hold, say BCX |\u00f9may\u03c6i. Then there is some concretization BCXr\u03b1s of BCX such that \u03b1 |\u00f9 \u03c6i holds. This implies that \u03b1 |\u00f9 \u03c61_\u03c62 holds as well. Since BCXr\u03b1s is a concretization of BCX , we get that BCX |\u00f9may\u03c61 _ \u03c62 holds.\nProof of Theorem 2:\n\u2022 Item 1 implies item 2: Let BCX |\u00f9maytrue hold. By definition of |\u00f9may, there then is some concretization BCXr\u03b1s of BCX such that \u03b1 |\u00f9 true holds. Therefore the set of concretizations of BCX is non-empty and so B C X is consistent.\n\u2022 Item 2 implies item 3: Let BCX be consistent. Suppose that \u03c6 is in Q such that BCX |\u00f9must\u03c6 holds. Since BCX is consistent, there is some concretization BCXr\u03b1s of BCX . Since BCX |\u00f9must\u03c6 holds, we get that \u03b1 |\u00f9 \u03c6 holds. But then we have BCX |\u00f9may\u03c6 be definition of |\u00f9may.\n\u2022 Item 3 implies item 4: Let BCX |\u00f9must\u03c6 imply BCX |\u00f9may\u03c6 for all \u03c6 in Q. Let \u03c8 be in Q. We claim that BCX |\u00f9may\u03c8 _ \u03c8 holds. By Theorem 1.4, it suffices to show that BCX |\u00f9may\u03c8 or BCX |\u00f9may \u03c8 holds. If the former holds, we are done. Otherwise, we have that BCX |\u00f9may\u03c8 does not hold. By Theorem 1.2, this implies that BCX |\u00f9must \u03c8 holds.\n\u2013 Next, we show that BCX has to be consistent: note that B C X |\u00f9musttrue holds by\nthe definitions of |\u00f9must and |\u00f9. Therefore, we get that BCX |\u00f9maytrue holds by item 3 \u2013 and we already showed that this implies that BCX is consistent.\nLet BCXr\u03b1s be a concretization of BCX , which exists as BCX is consistent. Since we showed BCX |\u00f9must \u03c6, the latter implies that \u03b1 |\u00f9 \u03c6. But then BCX |\u00f9may \u03c6 follows given the definition of |\u00f9may.\n\u2022 Item 4 implies item 5: Let BCX |\u00f9may\u03c6_ \u03c6 hold for all \u03c6 in Q. Let \u03c8 be in Q. Then we have that BCX |\u00f9may\u03c8 _ \u03c8 holds, and we need to show that BCX |\u00f9must\u03c8 ^ \u03c8 does not hold. Proof by contradiction: assume that BCX |\u00f9must\u03c8^ \u03c8 holds. Since BCX |\u00f9may\u03c8_ \u03c8 holds, we know that there is some concretization BCXr\u03b1s of BCX such that \u03b1 |\u00f9 \u03c8 _ \u03c8 holds. Since BCX |\u00f9must\u03c8^ \u03c8 holds, we know that BCX |\u00f9must\u03c8 and BCX |\u00f9must \u03c8 hold by Theorem 1.3. We do a case analysis on the truth of judgment \u03b1 |\u00f9 \u03c8 _ \u03c8:\n\u2013 Let \u03b1 |\u00f9 \u03c8 hold . Since BCX |\u00f9must \u03c8 holds, this implies that \u03b1 |\u00f9 \u03c8 holds. This contradicts that \u03b1 |\u00f9 \u03c8 holds.\n\u2013 Let \u03b1 |\u00f9 \u03c8 hold. Since BCX |\u00f9must\u03c8 holds, this implies that \u03b1 |\u00f9 \u03c8 holds. This contradicts that \u03b1 |\u00f9 \u03c8 holds.\n\u2022 Item 5 implies item 1: Let BCX |\u00f9must\u03c6 ^ \u03c6 not hold, for all \u03c6 in Q. Since true is in Q, we know that BCX |\u00f9musttrue ^ true does not hold. By definition of |\u00f9must and |\u00f9, we have that BCX |\u00f9musttrue holds. By Theorem 1.3 and since BCX |\u00f9musttrue^ true does not hold, we infer that BCX |\u00f9must true does not hold. By Theorem 1.2, this implies that BCX |\u00f9maytrue holds as claimed.\nProof of Theorem 3:\n1. Constraints \u03d51 in C and \u03d5 are quantifier-free formulas of Q with variables contained in X, which equals tx1, x2, . . . , xnu. Therefore, the formula in (8) is in Q, and contains only existential quantifiers and all in front of the formula.\n2. We prove this claim by structural induction over \u03d5:\n\u2022 Let \u03d5 be true. Then ExpBCX , trueq equals Dx1 : . . . : Dxn : true ^ \u0179 \u03d51PC \u03d5 1 and this\nis satisfiable iff there is an assignment \u03b1 such that \u03b1 |\u00f9 \u0179 \u03d51PC \u03d5 1 and \u03b1 |\u00f9 true both hold (the latter holding by definition) iff there is a concretization BCXr\u03b1s of BCX iff B C X is consistent iff (by Theorem 2) B C X |\u00f9maytrue holds.\n\u2022 Let \u03d5 be t1 \u010f t2. Then ExpBCX , t1 \u010f t2q equals Dx1 : . . . : Dxn : pt1 \u010f t2q ^ \u0179 \u03d51PC \u03d5 1\nand this is satisfiable iff there is an assignment \u03b1 such that \u03b1 |\u00f9 \u0179 \u03d51PC \u03d5 1 and \u03b1 |\u00f9\nt1 \u010f t2 both hold iff there is a concretization BCXr\u03b1s of BCX such that \u03b1 |\u00f9 t1 \u010f t2 holds iff BCX |\u00f9mayt1 \u010f t2 holds. \u2022 Let \u03d5 be t1 \u0103 t2. Then ExpBCX , t1 \u0103 t2q equals Dx1 : . . . : Dxn : pt1 \u0103 t2q ^ \u0179 \u03d51PC \u03d5 1\nand this is satisfiable iff there is an assignment \u03b1 such that \u03b1 |\u00f9 \u0179 \u03d51PC \u03d5 1 and \u03b1 |\u00f9\nt1 \u0103 t2 both hold iff there is a concretization BCXr\u03b1s of BCX such that \u03b1 |\u00f9 t1 \u0103 t2 holds iff BCX |\u00f9mayt1 \u0103 t2 holds. \u2022 Let \u03d5 be \u03c8. Then ExpBCX , \u03c8q equals Dx1 : . . . : Dxn : \u03c8 ^ \u0179 \u03d51PC \u03d5 1 and this\nis satisfiable iff there is an assignment \u03b1 such that \u03b1 |\u00f9 \u0179 \u03d51PC \u03d5 1 and \u03b1 |\u00f9 \u03c8\nboth hold iff there is a concretization BCXr\u03b1s of BCX such that \u03b1 |\u00f9 \u03c8 holds iff BCX |\u00f9may \u03c8 holds. \u2022 Let \u03d5 be \u03d51^\u03d52. Then ExpBCX , \u03d51 ^ \u03d52q equals Dx1 : . . . : Dxn : \u03d51^\u03d52^ \u0179 \u03d51PC \u03d5 1\nand this is satisfiable iff there is an assignment \u03b1 such that \u03b1 |\u00f9 \u0179 \u03d51PC \u03d5 1 and \u03b1 |\u00f9 \u03d51^\u03d52 both hold iff there is a concretization BCXr\u03b1s of BCX such that \u03b1 |\u00f9 \u03d51^\u03d52 holds iff BCX |\u00f9may\u03d51 ^ \u03d52 holds.\n3. By the previous item, we may decide BCX |\u00f9may\u03d5 by deciding whether formula ExpBCX , \u03d5q is satisfiable. By item 1 above, that formula is in the existential fragment of Q. By [14], deciding the satisfiability (truth) of such formulas is in PSPACE in the size of such formulas.\n4. By Theorem 1.1, we have that BCX |\u00f9must\u03d5 holds iff BCX |\u00f9may \u03d5 does not hold. By item 2 above, the latter is equivalent to ExpBCX , \u03d5q not being satisfiable. By [14], this can be decided in PSPACE in the size of formula ExpBCX , \u03d5q.\nProof of Theorem 4: The arguments below make use of Theorems 1 and 3 without explicit reference to them. Note that consistency of BCX and 0 \u0103 sup t| t |u guarantee that the first let statement in Sup can find such a \u03b1. In particular, we see that 0 \u0103 cache becomes an invariant and so cache \u0103 2 \u02da cache is another invariant.\n1. First, we show that the asserts hold prior to the execution of the second while loop. Note that cache is always assigned reals of form \u03b7ptq for some concretization BCXr\u03b7s of BCX . So when low is initialized with the last updated value of cache, then B C X |\u00f9mayt \u010f\nlow clearly holds after the first assignment to low (witnessed by the assignment that gave rise to the last value of cache) and prior to its reassignment. By definition of the initial value of high, we have that BCX |\u00f9mayt \u011b high does not hold after that initial assignment and prior to the reassignment of high. Therefore, both asserts in front of the second while loop hold, and we get that low \u010f high is an invariant. Second, we show that each iteration of the second while loop preserves the asserts. This is clear as the Boolean guard of the if statement tests for preservation of these asserts, and makes the correct, invariant-preserving assignment accordingly.\nThird, let rl, hs be the returned closed interval. It is clear that h \u00b4 l \u010f \u03b4 holds as required. We argue that sup t| t |u is in rl, hs. Since the asserts hold for l and h, we know that BCX |\u00f9mayt \u011b l holds, but BCX |\u00f9mayt \u011b h does not hold. Let c be in t| t |u. Then there is some \u03b1 with c \u201c \u03b1ptq. Since BCX |\u00f9mayt \u011b h does not hold, we get that \u03b1ptq \u0103 \u03b1phq \u201c h. Therefore, h is an upper bound of t| t |u which implies sup t| t |u \u010f h. Since BCX |\u00f9mayt \u011b l holds, we have some concretization BCXr\u03b11s with \u03b11 |\u00f9 t \u011b l. This means \u03b11ptq \u011b l. But sup t| t |u \u011b \u03b11ptq as the latter is an element of t| t |u. Thus, l \u010f sup t| t |u follows.\n2. Let s be sup t| t |u. For the first while loop, we have at least k iterations if s \u011b 2k \u00a8 c, i.e. if s \u00a8 c\u00b41 \u011b k, i.e. if k \u010f log2psq \u00b4 log2pcq. So the real number log2psq \u00b4 log2pcq is an upper bound on the number of iterations of the first while loop.\nTo get an upper bound for the number of iterations of the second while loop, we know that high is of form 2l`1 \u00a8 c and so low equals 2l \u00a8 c. But then high\u00b4 low equals 2l \u00a8 c. Since this is monotone in l, we may use the upper bound for the number of iterations of the first while loop as an upper bound of l, to get 2log2psq\u00b4log2pcq \u00a8 c \u201c s \u00a8 c\u00b41 \u00a8 c \u201c s as an upper bound on the value of | high\u00b4 low | before the Boolean guard of the second while is first evaluated. This allows us to derive an upper bound on the number of iterations of the second while loop, since the larger that value is, the more iterations take place. Based on the bisection in each iteration, there are at least k iterations if s \u00a8 2\u00b4k \u0105 \u03b4, i.e. if k \u0103 log2psq \u00b4 log2p\u03b4q. Therefore, the total number of iterations of both while loops combined is plog2psq \u00b4 log2pcqq ` plog2psq \u00b4 log2p\u03b4qq. The claim now follows given that each iteration makes exactly one satisfiability check and since there is an initial satisfiability check as well.\nProof of Theorem 5:\n1. The argument is similar to the one for Theorem 4 but there are important differences. Note that cache \u0105 0 is also here an invariant, guaranteed by the fact that t| t |u contains a positive real. We know that p0.5n \u02da cacheqnPN converges to 0 for any positive constant cache. Since 0 \u0103 \u03b4 and since \u03b11ptq \u010f 0.5 \u02da cache for the \u03b11ptq assigned to cache, there is some n0 such that 0.5\nn0 \u02da cache \u010f \u03b4. This proves that the first while statement terminates.\n(a) Suppose that the return statement in the line after the first while loop is executed. Then ExpBCX , t \u010f 0.5 \u02da cacheq is satisfiable and so there is some concretization BCXr\u03b1s such that \u03b1ptq \u010f 0.5 \u02da cache. But then inf t| t |u \u010f 0.5 \u02da cache as well. From t| t |u \u010e R`0 , we get 0 \u010f inf t| t |u. Therefore, inf t| t |u is in the returned interval r0, 0.5 \u02da caches and BCX |\u00f9mayt \u010f 0.5 \u02da cache is true. Moreover, the length of the interval is 0.5 \u02da cache, which must be less than or equal to \u03b4 as the first while loop just terminated and the first conjunct of its Boolean guard is true \u2013 forcing 0.5 \u02da cache \u0105 \u03b4 to be false.\n(b) Otherwise, ExpBCX , t \u010f 0.5 \u02da cacheq is not satisfiable but the formula ExpBCX , t \u010f cacheq is satisfiable. From that, it should then be clear that the asserts in front of the second while statement hold when they are reached. That each iteration of the second while statement maintains these two asserts is reasoned similarly as for Sup.\nSo we have that BCX |\u00f9mayt \u010f h and BCX |\u00f9mustt \u0105 l are invariants. This means that l is a lower bound of t| t |u and \u03b1ptq \u010f h for some \u03b1ptq in t| t |u. But then l \u010f inf t| t |u \u010f \u03b1ptq \u010f h shows that inf t| t |u is in rl, hs.\n2. Let i be inf t| t |u. We derive an upper bound on the number of iterations for the first while loop. Because we are interested in upper bounds, we may assume that the \u03b11ptq assigned to cache equals 0.5 \u00a8cache for the current value of cache. We then have at least k iterations if \u03b4 \u0103 c \u00a8 2\u00b4k and i \u010f c \u00a8 2\u00b4k. Since we are interested in upper bounds on that number of iterations, we get at least k iterations if both \u03b4 \u010f c \u00a8 2\u00b4k and i \u010f c \u00a8 2\u00b4k hold, i.e. if minp\u03b4, iq \u010f c \u00a8 2\u00b4k. But this is equivalent to k \u010f log2pcq \u00b4 log2pminpi, \u03b4qq. We now derive an upper bound on the number of iterations of the second while loop. The initial value of high\u00b4low equals cache\u00b40.5\u00a8cache \u201c 0.5\u00a8cache for the current value of cache when entering that loop. The value of cache is monotonically decreasing during program execution and so c{2 is an upper bound of high\u00b4 low. We may therefore use c{2 as initial value of high\u00b4 low since this can only increase the number of iterations, for which we seek an upper bound. There are now at least k iterations if pc{2q \u00a82\u00b4k \u0105 \u03b4 which is equivalent to k \u0103 log2pcq \u00b4 1\u00b4 log2p\u03b4q. The total number of iterations for both while loops is therefore plog2pcq\u00b4log2pminpi, \u03b4qqq` plog2pcq \u00b4 1 \u00b4 log2p\u03b4qq \u201c 2 \u00a8 log2pcq \u00b4 log2pminpi, \u03b4qq \u00b4 1. From this the claim follows since each iteration has exactly one satisfiability check of the stated form, and there is one more satisfiability check between the first and second while loop.\nProof of Theorem 6:\n1. We do a case analysis:\n(a) If algorithm Sup is called, then consistency of BCX and 0 \u0103 sup t| t |u follow from the Boolean guard that triggered the call. Since sup t| t |u \u0103 8 is assumed, we get 0 \u0103 sup t| t |u \u0103 8 and so Sup terminates by Theorem 4.\n(b) If 0 is returned as a maximum, the algorithm clearly terminates and no preconditions are needed.\n(c) If Inf is called, we have to show that t| \u00b4t |u is a subset of R`0 that contains a positive real. Since the first two return statements were not reached, we know that BCX is consistent and t| t |u is a subset of R\u00b4. But then t| \u00b4t |u is a subset of R`.\n2. If the algorithm reports that 0 is the maximum for t, then we know that t| t |u cannot contain a positive real (first if-statement), and that it contains 0 (second if-statement). Clearly, this means that 0 is the supremum of t| t |u and so also its maximum as 0 is in t| t |u.\n3. Let Sup\u2039pt, \u03b4, BCXq return an interval r\u00b4h,\u00b4ls. Then rl, hs is the interval returned by a call to Infp\u00b4t, \u03b4, BCXq. By the first item and Theorem 5, we get that BCX |\u00f9may \u00b4 t \u010f h holds, inf t| \u00b4t |u is in rl, hs, and h\u00b4l \u010f \u03b4 . Therefore, we conclude that BCX |\u00f9mayt \u011b \u00b4h holds as claimed. Moreover, since inf t| \u00b4t |u equals \u00b4 sup t| t |u, this implies that sup t| t |u is in the closed interval r\u00b4h,\u00b4ls, whose length is that of rl, hs and so \u010f \u03b4.\n4. If the algorithm returns saying thatBCX is inconsistent, then all three formulas ExpBCX , t \u0105 0q, ExpBCX , t \u201c 0q, and ExpBCX , t \u0103 0q are unsatisfiable. But then we know that the three judgments BCX |\u00f9mayt \u0105 0, BCX |\u00f9mayt \u201c 0, and BCX |\u00f9mayt \u0103 0 do not hold, by Theorem 3. This means that BCX is inconsistent: for all concretization B C Xr\u03b1s we have that\n\u03b1 |\u00f9 pt \u0105 0q _ pt \u201c 0q _ pt \u0103 0q holds as that query is a tautology over the theory of reals; and then Theorem 3.4 yields a contradiction to BCX being consistent.\nProof of Theorem 7: The correctness of the first two claims in that theorem (inconsistency and minimum) for \u00b48 \u0103 inf t| t |u follows from the corresponding items of Theorem 6. The general identity inftxi | i P Iu \u201c \u00b4 supt\u00b4xi | i P Iu shows that \u00b48 \u0103 inftxi | i P Iu iff \u00b4 supt\u00b4xi | i P Iu \u0103 8 and so preconditions are also met. Finally, to see the correctness of Inf\u2039 when interval rl, hs is returned, note that this means that interval r\u00b4h,\u00b4ls is returned for the call Sup\u2039p\u00b4t, \u03b4, BCXq and so BCX |\u00f9may \u00b4 t \u011b \u00b4h holds by Theorem 6. But this implies that BCX |\u00f9mayt \u010f h holds as claimed."}, {"heading": "B Quantitative Information about the BN of Figure 11", "text": "Table 1 shows quantitative information about the size and complexity of the BN in Figure 11."}], "references": [{"title": "Bayesian Reasoning and Machine Learning", "author": ["David Barber"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "An in-depth case study: modelling an information barrier in Bayesian belief networks", "author": ["Paul Beaumont", "Edward Day", "Neil Evans", "Sam Haworth", "Michael Huth", "Tom Plant", "Catherine Roberts"], "venue": "In Journal of the Institute of Nuclear Materials Management,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Confidence analysis for nuclear arms control: SMT abstractions of Bayesian Belief Networks", "author": ["Paul Beaumont", "Neil Evans", "Michael Huth", "Tom Plant"], "venue": "In Computer Security - ESORICS 2015 - 20th European Symposium on Research in Computer Security, Vienna,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Bayesian Robustness, pages 1\u201332", "author": ["James O. Berger", "David \u0154\u0131os Insua", "Fabrizio Ruggeri"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2000}, {"title": "Exploiting Bayesian Network Sensitivity Functions for Inference in Credal Networks", "author": ["Janneke H. Bolt", "Jasper De Bock", "Silja Renooij"], "venue": "In ECAI 2016 - 22nd European Conference on Artificial Intelligence,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "Decision-theoretic troubleshooting: A framework for repair and experiment", "author": ["John S. Breese", "David Heckerman"], "venue": "Proceedings of the Twelfth Annual Conference on Uncertainty in Artificial Intelligence, Reed College,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1996}, {"title": "Model checking partial state spaces with 3-valued temporal logics", "author": ["Glenn Bruns", "Patrice Godefroid"], "venue": "In Computer Aided Verification, 11th International Conference,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1999}, {"title": "The complexity of Robot Motion Planning", "author": ["J.F. Canny"], "venue": "PhD thesis, MIT,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1988}, {"title": "Abstract interpretation: past, present and future", "author": ["Patrick Cousot", "Radhia Cousot"], "venue": "In Joint Meeting of the Twenty-Third EACSL Annual Conference on Computer Science Logic (CSL) and the Twenty-Ninth Annual ACM/IEEE Symposium on Logic in Computer Science (LICS), CSL-LICS \u201914,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Inference with Separately Specified Sets of Probabilities in Credal Networks", "author": ["Fabio Gagliardi Cozman", "Jose C.F. da Rocha"], "venue": "Proceedings of the Eighteenth conference on Uncertainty in artificial intelligence,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2002}, {"title": "The Structure and Complexity of Credal Semantics", "author": ["F\u00e1bio Gagliardi Cozman", "Denis Deratani Mau\u00e1"], "venue": "In Proc. of the Third International Workshop on Probabilistic Logic Programming,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2016}, {"title": "Polyhedral aspects of score equivalence in Bayesian network structure learning", "author": ["James Cussens", "David Haws", "Milan Studeny"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "Evidence Propagation in Credal Networks: An Exact Algorithm Based on Separately Specified Sets of Probability", "author": ["Jos\u00e9 Carlos Ferreira da Rocha", "F\u00e1bio Gagliardi Cozman"], "venue": "In Advances in Artificial Intelligence, 16th Brazilian Symposium on Artificial Intelligence,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2002}, {"title": "A differential approach to inference in Bayesian networks", "author": ["Adnan Darwiche"], "venue": "J. ACM,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2003}, {"title": "The inferential complexity of Bayesian and credal networks", "author": ["Cassio Polpo de Campos", "F\u00e1bio Gagliardi Cozman"], "venue": "Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2005}, {"title": "An Efficient SMT Solver", "author": ["Leonardo De Moura", "Nikolaj Bj\u00f8rner. Z"], "venue": "In Proceedings of the Theory and Practice of Software, 14th International Conference on Tools and Algorithms for the Construction and Analysis of Systems,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2008}, {"title": "Quasi-Bayesian behaviour: A more realistic approach to decision making", "author": ["F.J. Giron", "S. Rios"], "venue": "Trabajos de Estadistica Y de Investigacion Operativa,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1980}, {"title": "Could a machine make probability judgments", "author": ["Irving John Good"], "venue": "Computation and Automation,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1959}, {"title": "Degrees of Belief", "author": ["Irving John Good"], "venue": "In Encyclopedia of Statistical Sciences,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1982}, {"title": "Bayesian methods for elucidating genetic regulatory networks", "author": ["Alexander J. Hartemink", "David K. Gifford", "Tommi S. Jaakkola", "Richard A. Young"], "venue": "IEEE Intelligent Systems,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2002}, {"title": "A Tutorial on Learning With Bayesian Networks", "author": ["David Heckerman"], "venue": "Technical Report MSR-TR-95-06,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1995}, {"title": "Experimental design of time series data for learning from dynamic Bayesian networks", "author": ["C. David Page Jr.", "Irene M. Ong"], "venue": "In Biocomputing", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2006}, {"title": "Sensitivity analysis of Bayesian networks used in forensic investigations", "author": ["Michael Y.K. Kwan", "Richard E. Overill", "Kam-Pui Chow", "Hayson Tse", "Frank Y.W. Law", "Pierre K.Y. Lai"], "venue": "In Advances in Digital Forensics VII - 7th IFIP WG 11.9 International Conference on Digital Forensics,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2011}, {"title": "Sensitivity analysis for probability assessments in Bayesian networks", "author": ["Kathryn Blackmond Laskey"], "venue": "IEEE Trans. Systems, Man, and Cybernetics,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1995}, {"title": "Probabilistic inference in credal networks: New complexity results", "author": ["Denis Deratani Mau\u00e1", "Cassio Polpo De Campos", "Alessio Benavoli", "Alessandro Antonucci"], "venue": "J. Artif. Int. Res.,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2014}, {"title": "Sympy: Symbolic computing in python", "author": ["Aaron Meurer", "Christopher P. Smith", "Mateusz Paprocki", "Ondrej Cert\u0301\u0131k", "Matthew Rocklin", "Amit Kumar", "Sergiu Ivanov", "Jason K. Moore", "Sartaj Singh", "Thilina Rathnayake", "Sean Vig", "Brian E. Granger", "Richard P. Muller", "Francesco Bonazzi", "Harsh Gupta", "Shivam Vats", "Fredrik Johansson", "Fabian Pedregosa", "Matthew J. Curry", "Ashutosh Saboo", "Isuru Fernando", "Sumith Kulal", "Robert Cimrman", "Anthony M. Scopatz"], "venue": "PeerJ PrePrints,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2016}, {"title": "Probabilistic Reasoning in Expert Systems: Theory and Algorithms", "author": ["Richard E. Neapolitan"], "venue": null, "citeRegEx": "35", "shortCiteRegEx": "35", "year": 1990}, {"title": "Bayesian networks: A model of self-activated memory for evidential reasoning", "author": ["J. Pearl"], "venue": "Technical Report CSD-850021,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 1985}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference", "author": ["Judea Pearl"], "venue": null, "citeRegEx": "37", "shortCiteRegEx": "37", "year": 1988}, {"title": "Reasoning about evidence using Bayesian networks. In Advances in Digital Forensics VIII - 8th IFIP WG", "author": ["Hayson Tse", "Kam-Pui Chow", "Michael Y.K. Kwan"], "venue": "International Conference on Digital Forensics,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2012}], "referenceMentions": [{"referenceID": 27, "context": "Bayesian Networks (BN) [36, 37, 35] are a prominent, well established, and widely used formalism for expressing discrete probability distributions in terms of directed, acyclic graphs (DAG) that encode conditional independence assumptions of distributions.", "startOffset": 23, "endOffset": 35}, {"referenceID": 28, "context": "Bayesian Networks (BN) [36, 37, 35] are a prominent, well established, and widely used formalism for expressing discrete probability distributions in terms of directed, acyclic graphs (DAG) that encode conditional independence assumptions of distributions.", "startOffset": 23, "endOffset": 35}, {"referenceID": 26, "context": "Bayesian Networks (BN) [36, 37, 35] are a prominent, well established, and widely used formalism for expressing discrete probability distributions in terms of directed, acyclic graphs (DAG) that encode conditional independence assumptions of distributions.", "startOffset": 23, "endOffset": 35}, {"referenceID": 5, "context": "Bayesian Networks have a wide range of applications \u2013 for example, trouble shooting [12], design of experiments [30, 28], and digital forensics to support legal reasoning [38].", "startOffset": 84, "endOffset": 88}, {"referenceID": 21, "context": "Bayesian Networks have a wide range of applications \u2013 for example, trouble shooting [12], design of experiments [30, 28], and digital forensics to support legal reasoning [38].", "startOffset": 112, "endOffset": 120}, {"referenceID": 19, "context": "Bayesian Networks have a wide range of applications \u2013 for example, trouble shooting [12], design of experiments [30, 28], and digital forensics to support legal reasoning [38].", "startOffset": 112, "endOffset": 120}, {"referenceID": 29, "context": "Bayesian Networks have a wide range of applications \u2013 for example, trouble shooting [12], design of experiments [30, 28], and digital forensics to support legal reasoning [38].", "startOffset": 171, "endOffset": 175}, {"referenceID": 20, "context": "pre-existing data (see for example [29, 19]).", "startOffset": 35, "endOffset": 43}, {"referenceID": 11, "context": "pre-existing data (see for example [29, 19]).", "startOffset": 35, "endOffset": 43}, {"referenceID": 3, "context": "This naturally leads to the consideration of robust Bayesian statistics [9, 10].", "startOffset": 72, "endOffset": 79}, {"referenceID": 17, "context": "A good conceptual explanation of this is Good\u2019s black box model [26, 27], in which interval information of priors is submitted into a black box that contains all the usual methods associated with precise computations in Bayesian Networks, and where the box then outputs intervals of posteriors without limiting any interpretations or judgments on those output intervals.", "startOffset": 64, "endOffset": 72}, {"referenceID": 18, "context": "A good conceptual explanation of this is Good\u2019s black box model [26, 27], in which interval information of priors is submitted into a black box that contains all the usual methods associated with precise computations in Bayesian Networks, and where the box then outputs intervals of posteriors without limiting any interpretations or judgments on those output intervals.", "startOffset": 64, "endOffset": 72}, {"referenceID": 25, "context": "This development is informed by advances made in areas of Symbolic Computation [34] and Automated Theorem Proving [23] (with its applications to Non-Linear, Non-Convex Optimization [8]), Three-Valued Model Checking [13], and Abstract Interpretation [15].", "startOffset": 79, "endOffset": 83}, {"referenceID": 15, "context": "This development is informed by advances made in areas of Symbolic Computation [34] and Automated Theorem Proving [23] (with its applications to Non-Linear, Non-Convex Optimization [8]), Three-Valued Model Checking [13], and Abstract Interpretation [15].", "startOffset": 114, "endOffset": 118}, {"referenceID": 2, "context": "This development is informed by advances made in areas of Symbolic Computation [34] and Automated Theorem Proving [23] (with its applications to Non-Linear, Non-Convex Optimization [8]), Three-Valued Model Checking [13], and Abstract Interpretation [15].", "startOffset": 181, "endOffset": 184}, {"referenceID": 6, "context": "This development is informed by advances made in areas of Symbolic Computation [34] and Automated Theorem Proving [23] (with its applications to Non-Linear, Non-Convex Optimization [8]), Three-Valued Model Checking [13], and Abstract Interpretation [15].", "startOffset": 215, "endOffset": 219}, {"referenceID": 8, "context": "This development is informed by advances made in areas of Symbolic Computation [34] and Automated Theorem Proving [23] (with its applications to Non-Linear, Non-Convex Optimization [8]), Three-Valued Model Checking [13], and Abstract Interpretation [15].", "startOffset": 249, "endOffset": 253}, {"referenceID": 14, "context": "We draw comparisons to related work, including Credal Networks [16, 22, 33] and Constraint Networks [24].", "startOffset": 63, "endOffset": 75}, {"referenceID": 24, "context": "We draw comparisons to related work, including Credal Networks [16, 22, 33] and Constraint Networks [24].", "startOffset": 63, "endOffset": 75}, {"referenceID": 0, "context": "Chapter 6 in [6] for further details) may be used to revise a marginal of a BN because of \u201chard\u201d, respectively \u201csoft\u201d, evidence \u2013 the definite, respectively probabilistic, observation of an additional or new event.", "startOffset": 13, "endOffset": 16}, {"referenceID": 1, "context": "Figure 11: A BN [7] which details aspects of an arms inspection process.", "startOffset": 16, "endOffset": 19}, {"referenceID": 23, "context": ", the sensitivity value defined in [32, 31].", "startOffset": 35, "endOffset": 43}, {"referenceID": 22, "context": ", the sensitivity value defined in [32, 31].", "startOffset": 35, "endOffset": 43}, {"referenceID": 23, "context": "The sensitivity value [32, 31] is defined in this instance as", "startOffset": 22, "endOffset": 30}, {"referenceID": 22, "context": "The sensitivity value [32, 31] is defined in this instance as", "startOffset": 22, "endOffset": 30}, {"referenceID": 15, "context": "This implementation uses Python to capture a data model for Bayesian Networks and constraints, to formulate marginals of interest, and to interface with the SMT solver Z3 [23].", "startOffset": 171, "endOffset": 175}, {"referenceID": 25, "context": "Python also supports a lightweight and open-source library for symbolic computation, sympy [34], which we can employ to run the Junction Tree Algorithm in [5] fully symbolically.", "startOffset": 91, "endOffset": 95}, {"referenceID": 13, "context": "In [21], it is shown how probabilistic inference in Bayesian Networks can be represented through the evaluation and formal differentiation of a \u201cnetwork polynomial\u201d.", "startOffset": 3, "endOffset": 7}, {"referenceID": 20, "context": "[29, 19]) \u2013 based on existing empirical data.", "startOffset": 0, "endOffset": 8}, {"referenceID": 11, "context": "[29, 19]) \u2013 based on existing empirical data.", "startOffset": 0, "endOffset": 8}, {"referenceID": 2, "context": "Our work in [8] reported early attempts of developing the approach presented in this paper: in [8], a much simpler Bayesian Network of a nuclear inspection process is presented and some analyses with preliminary versions of our tool are discussed; but that work offered neither formal foundations nor greater technical details for the methods it used.", "startOffset": 12, "endOffset": 15}, {"referenceID": 2, "context": "Our work in [8] reported early attempts of developing the approach presented in this paper: in [8], a much simpler Bayesian Network of a nuclear inspection process is presented and some analyses with preliminary versions of our tool are discussed; but that work offered neither formal foundations nor greater technical details for the methods it used.", "startOffset": 95, "endOffset": 98}, {"referenceID": 1, "context": "The more detailed Bayesian Network we studied in Section 4 was discussed in [7], along with a nontechnical summary of our general approach and some of its analysis findings.", "startOffset": 76, "endOffset": 79}, {"referenceID": 16, "context": "Credal networks are also referred to as the Theory of Imprecise Probabilities [39] or as the Quasi-Bayesian Theory [25].", "startOffset": 115, "endOffset": 119}, {"referenceID": 9, "context": "[17, 20]) to deep relationships to logic programming and its semantics [18].", "startOffset": 0, "endOffset": 8}, {"referenceID": 12, "context": "[17, 20]) to deep relationships to logic programming and its semantics [18].", "startOffset": 0, "endOffset": 8}, {"referenceID": 10, "context": "[17, 20]) to deep relationships to logic programming and its semantics [18].", "startOffset": 71, "endOffset": 75}, {"referenceID": 4, "context": "In [11], a methodology is developed for assessing sensitivity of lower and upper probabilities in Credal networks.", "startOffset": 3, "endOffset": 7}, {"referenceID": 13, "context": "But it also creates a potential computational bottleneck with scope for future work that may extend an approach in [21] to our setting.", "startOffset": 115, "endOffset": 119}], "year": 2017, "abstractText": "We develop the theory and practice of an approach to modeling and probabilistic inference in causal networks that is suitable when application-specific or analysis-specific constraints should inform such inference or when little or no data for the learning of causal network structure or probability values at nodes are available. Constrained Bayesian Networks generalize a Bayesian Network such that probabilities can be symbolic, arithmetic expressions and where the meaning of the network is constrained by finitely many formulas from the theory of the reals. A formal semantics for constrained Bayesian Networks over first-order logic of the reals is given, which enables non-linear and non-convex optimization algorithms that rely on decision procedures for this logic, and supports the composition of several constrained Bayesian Networks. A non-trivial case study in arms control, where few or no data are available to assess the effectiveness of an arms inspection process, evaluates our approach. An open-access prototype implementation of these foundations and their algorithms uses the SMT solver Z3 as decision procedure, leverages an open-source package for Bayesian inference to symbolic computation, and is evaluated experimentally.", "creator": "LaTeX with hyperref package"}}}