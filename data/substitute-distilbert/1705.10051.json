{"id": "1705.10051", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-May-2017", "title": "Learning Network Structures from Contagion", "abstract": "in essence, amin, heidari, and kearns proved that tree networks can be learned by observing only the infected set of vertices of the encoding process with the independent cascade model, in versus the active and passive query models. they also showed empirically that simple extensions of their algorithms work on sparse networks. in such work, we focus on the active model. we prove that a simple modification surrounding amin et al.'s algorithm seeks beyond more general components of networks, namely ( i ) networks with guaranteed girth and low path transport rate, spanning ( ii ) networks with bounded degree. this also provides partial theoretical extensions for amin et al.'s experiments on sparse networks.", "histories": [["v1", "Mon, 29 May 2017 06:53:13 GMT  (12kb)", "http://arxiv.org/abs/1705.10051v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.SI", "authors": ["adisak supeesun", "jittat fakcharoenphol"], "accepted": false, "id": "1705.10051"}, "pdf": {"name": "1705.10051.pdf", "metadata": {"source": "CRF", "title": "Learning Network Structures from Contagion", "authors": ["Adisak Supeesun"], "emails": ["jittat}@gmail.com"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 5.\n10 05\n1v 1\n[ cs\n.L G\n] 2\n9 M\nIn 2014, Amin, Heidari, and Kearns proved that tree networks can be learned by observing only the infected set of vertices of the contagion process under the independent cascade model, in both the active and passive query models. They also showed empirically that simple extensions of their algorithms work on sparse networks. In this work, we focus on the active model. We prove that a simple modification of Amin et al.\u2019s algorithm works on more general classes of networks, namely (i) networks with large girth and low path growth rate, and (ii) networks with bounded degree. This also provides partial theoretical explanation for Amin et al.\u2019s experiments on sparse networks.\nKeywords: Graph Algorithms, Learning, Contagion, Network Structures, Large Girth"}, {"heading": "1 Introduction", "text": "Edge information of a network is essential to many network analysis applications, e.g., in social network analysis [10, 16, 15], in epidemiology [3], and in viral marketing [12]. However, in some type of networks, e.g., online social networks or the network of customers of a rival company, it is not easy to obtain this information. Therefore, in these settings, it is more practical to infer the network structures from observable data.\nThis paper considers a problem of inferring the network structure from a contagion process, known as the independent cascade model (defined by Goldenberg et al. [6, 7] and Kempe et al. [11]). The problem was first considered by Gomez-Rodriguez, Leskovec, and Krause [9]. While most results utilize the orders of infections to infer the network structures (e.g., [9, 13, 8, 14, 1]), the set of infected vertices are clearly easier to observe. Thus, we follow a recent work by Amin, Heidari, and Kearns [2] who introduced a problem of learning unknown network structure by observing only sets of initial infected vertices and sets of final infected vertices. Amin et al. considered both the active model where the algorithm can make active seed queries and the passive model where the algorithm only observes the seed and the set of infected vertices, and\nproposed algorithms for exactly learning tree networks under these two models. They also proposed another algorithm for learning general networks, called the K-lifts algorithm, that works well empirically under real networks and random networks. Amin et al. proved that the K-lifts algorithm can learn cycle networks and provided an example which is a union of a star and a large cycle that the algorithm fails to learn.\nIn this paper, we consider the active model and extend the approach of Amin et al. [2], to\ntwo other classes of networks, as described below.\nNetworks with large girth and low path growth rate. Essentially, these are networks that behave almost like trees. We consider two parameters of the networks: (1) the girth, which is the size of the smallest cycle in the network and (2) the growth rate on the number of paths between two vertices over the length of the paths. We show that if the girth of a network is large enough and the growth rate is small enough, the network can be exactly learned by an algorithm that uses only a polynomial number of queries in term of the number of vertices and \u2206, the contagion parameter (to be defined in the next section). Since a tree does not contain any cycle, its girth is \u221e; this class of networks generalizes the tree networks considered in [2]. This class also includes a counter example for the K-lifts algorithm provided in [2]. While the focus of this work is extending the theoretical limitation of Amin et al. [2]\u2019s work, this type of networks may appear in advisor-advisee networks where cross-field advising happens on rare occasions or in organizational networks, networks that represent ranks and relations of people in organizations, where few low-ranking workers may report to more than one middle managers, resulting in large cycles that span the people at the top-most levels of the organizations.\nBounded degree networks. We also show that if the maximum degree of vertices in the network is bounded above by a constant, the network can be exactly learned with polynomial queries as well.\nThe paper is organized as follows. In the next section, we state problem definitions and discuss previous results. Section 3 shows that a large girth network with low path growth can be learned in the contagion model. In section 4, we show that if the maximum degree of a network is bounded by a constant, the network can also be learned."}, {"heading": "2 Definitions and Results", "text": "We formally describe the contagion process. Let G = (V,E) be an undirected network whose edges are unknown with n vertices. Let S \u2286 V be the seed set, the set of initially infected vertices. From S, a contagion proceeds in discrete steps under the independent cascade model defined by Goldenberg et al. [6, 7] and Kempe et al. [11], as follows. We assume that every vertex in S becomes infected at step t = 0. At each step t = 1, 2, 3, . . ., every vertex u \u2208 V which became infected at step t\u22121 tosses a coin to spread the disease to each of its uninfected adjacent vertices v \u2208 V with the infectious probability puv. If v receives the disease from u, we say that v becomes infected at step t. In this case, we say that the edge (u, v) is active, otherwise (u, v) is inactive. Note that when referring to an edge as active or inactive, the order of its end points\nin the tuple is important (e.g., when (u, v) is active, (v, u) is inactive). The contagion proceeds until there are no newly infected vertices. Note that spreading of disease through edge (u, v) occurs only once at the first step when u or v become infected. The minimum and maximum infectious probabilities are denoted by \u03b1 and \u03b2, respectively. We define the contagion parameter \u2206 = min{\u03b1, 1 \u2212 \u03b2}.\nThe problem of learning network structure from contagion is defined as follows. For a network G = (V,E), we are given the set of vertices V and the contagion parameter \u2206, but for all edges (u, v) \u2208 E, (u, v) and puv are unknown. We will describe the version for the active model here and refer to the Previous Results section for the description of the passive model. Under the active query model, for each round i = 1, 2, . . . ,M , the algorithm can perform a query by choosing a seed set Si \u2286 V . The contagion process described above then starts from Si and returns the set of infected vertices Ai. The goal of the problem is to find an algorithm that uses a small number of rounds M , and correctly returns the edge set E.\nPrevious Results. Amin, Heidari, and Kearns [2] considered the problem in both active model and passive model. They proved that tree networks can be exactly learned in both models. In addition, they also considered the problem for learning non-tree networks.\nSince our focus is on the active model, we start by describing their algorithm for learning trees in this model, later referred to as the AHK algorithm. For any vertex u \u2208 V , the algorithm repeatedly queries with the seed set containing only a single vertex u in order to infer the set of vertices \u0393(u) adjacent to u. Let Ru(v) be the set of rounds that v becomes infected while {u} be the seed set, i.e., Ru(v) = {i : v \u2208 Ai and Si = {u}}. The algorithm infers that u and v are adjacent if and only if there does not exist a vertex w \u2208 V \\{u, v} such that Ru(v) \u2286 Ru(w). The algorithm needs O( n \u22062 log n\u03b4 ) queries to learn the tree with probability at least 1 \u2212 \u03b4. We note that the AHK algorithm could fail when applying to non-tree networks because a vertex can be infected from the seed set through many possible paths.\nFor the passive model, the seed sets are chosen randomly from a distribution where each vertex is chosen independently. The algorithm presented by Amin et al. for this model employs the lift function L(v|u) which is the increase in the probability that vertex v becomes infected when u is in the seed set. The algorithm finds an estimate L\u0302 of L, and if L\u0302 is close to L, they showed that the algorithm can exactly learn the tree.\nFor non-tree networks, Amin et al. presented an algorithm, called the K-lifts algorithm, which can be viewed as a generalized version of the algorithm for learning trees in the passive model. Given the number of edges K, the algorithm returns K pairs of vertices with highest estimated lift scores as network edges. The experimental results showed that the K-lifts algorithm performs well when learning sparse random networks (under the Erdo\u030bs-Re\u0301nyi model [4, 5] and the Small-World model [17]). On the positive side, Amin et al. proved that the K-lifts algorithm can learn cycle networks. However, they showed that the K-lifts algorithm fails to learn a network H on 2n \u2212 1 vertices constructed by joining a star with n vertices rooted at vertex v0 and an n-cycle containing v0 at v0.\nOur Results. Here we state our results formally. Our first result considers large girth\nnetworks. For a network G = (V,E), the girth g of G is the length of the shortest cycle in the network. We also need another property related to the number of simple paths. Denote by P(u, v) the set of simple paths from vertex u \u2208 V to vertex v \u2208 V in G, and Pd(u, v) the set of paths of length d in P(u, v). Let pd be the maximum number of simple paths of length d between any pair of vertices, i.e., pd = maxu\u2208V,v\u2208V |Pd(u, v)|. We define the path growth rate \u03c1 = maxd(pd) 1/d. The parameter \u03c1 intuitively represents the growth rate for the number of simple paths in the network. Note that for tree networks, g can be regarded as \u221e and \u03c1 = 1.\nWe show that if \u03c1(1\u2212\u2206) < 1 and g > f(\u2206, \u03c1), for some function f (stated in Theorem 3.7), we\ncan successfully learn the network in the active model with O( n \u22062 log n\u03b4 ) queries with probability at least 1 \u2212 \u03b4. We note that our algorithm can successfully learn the Amin et al.\u2019s counter example H (discussed in Theorem 6 in [2]) since the girth of H is n and its path growth ratio is 22/n, which is close to 1.\nThe algorithm requires O( n \u22062 log n\u03b4 ) active queries, which is the same bound as the AHK algorithm of Amin et al. under the same model. While the bound itself does not depend on the values of \u03c1 and g, our proofs of correctness require the network to satisfies certain conditions on \u2206, \u03c1 and g (see Theorem 3.7).\nThe second result is on the bounded-degree networks. We show that, if the maximum degree of the network is D, in the active model, these networks can be exactly learned by a very simple algorithm that makes at most O( n \u22062D log n\u03b4 ) queries with probability at least 1\u2212 \u03b4."}, {"heading": "3 Learning Large Girth Networks", "text": "This section describes an algorithm that learns large-girth networks. We start with a crucial lemma on the properties of these networks. As in the AHK algorithm, we would like to filter out non-adjacent pairs of vertices. We focus on pairs of vertices that are close, but not adjacent. Let duv be the shortest path distance from u to v.\nThe following lemma is a key observation.\nLemma 3.1. Let G = (V,E) be a network with girth g. For any pair of vertices u, v \u2208 V such that 1 < duv < g/2, there is a unique shortest path from u to v, and all other paths from u to v have length greater than g/2.\nProof. We prove by contradiction. Let P1 be the shortest path from u to v of length k1 < g/2 and let P2 be another path from u to v of length k2 where k1 \u2264 k2 \u2264 g/2. We can take a union of P1 and P2 and obtain a cycle of length at most k1+ k2 < g, contradicting the fact that G has girth g.\nUsing Lemma 3.1 with appropriate value of g, we can show that it is very unlikely that, when {u} is the seed set, v is infected through paths other than the unique shortest path from u. This implies that in most rounds when v is infected, every intermediate vertex w in the shortest path from u to v must be infected as well.\nRecall that Ru(v) be the set of rounds that v becomes infected while {u} be the seed set. In a tree network, the rejection criteria of the AHK algorithm works because Ru(v) \u2286 Ru(w) for any intermediate vertex w in the shortest path from u to v. However, in general, since v can be infected through other paths, we need a milder criteria. Instead of requiring that Ru(v) \u2286 Ru(w) to reject (u, v), we shall reject (u, v) as an edge when there exists a vertex w such that w appears too often with v, i.e., when the set Ru(v) \u2229Ru(w) is large.\nLet m be the number of rounds that we query for a single seed set (to be specified later). Our modification of the AHK algorithm to learn large girth networks is shown in Algorithm 1. Note that although the contagion parameter \u2206 is required to make decision in Algorithm 1, it is enough to use its lower bound. The AHK algorithm itself does not require \u2206, but the parameter is implicitly needed to make sure that the number of queries is large enough.\nAlgorithm 1 Algorithm for learning a large girth network G = (V,E)\nE \u2032 \u2190 \u2205\nfor all u in V do\nfor i = 1 to m do\nquery with seed set Si = {u}, then receive the set of infected vertices Ai\nend for for all v in V \\{u} do\nif \u2200w \u2208 V \\{u, v}, |Ru(v)\\Ru(w)| > 3\u22062m\n8 then\nE \u2032 \u2190 E \u2032 \u222a {(u, v)}\nend if\nend for\nend for return E \u2032.\nWe shall show that the Algorithm 1 returns edges E with high probability after querying\nM = nm rounds in total, if m is large enough.\nWe would like to point out that our algorithm works only when \u03c1(1\u2212\u2206) < 1. This bound is essential for preventing issues that may occur when high growth rate compensates the infectious failure based on our analysis techniques. See a discussion at the end of Lemma 3.2.\nAfter each round of query we say that path P is active if every edge in P is active. (Note that each edge must be active in the right direction.) On the other hand, P is inactive if there exists an inactive edge in the path.\nThe next lemma shows that if \u03c1(1 \u2212\u2206) < 1, the probability that there is an active path of\nlength k from vertex u to vertex v depends on \u03c1(1\u2212\u2206).\nLemma 3.2. For any network G = (V,E), if parameter \u03c1 of G satisfies the condition that \u03c1 < 1/(1\u2212\u2206), then for any vertex u \u2208 V and vertex v \u2208 V , the probability that u infects v along any paths of length at least k is at most (\u03c1(1\u2212\u2206)) k\n1\u2212\u03c1(1\u2212\u2206) .\nProof. Using the union bound, the probability that u infects v along any paths of length at least k is at most\nn\u22121 \u2211\nd=k\n(|Pd(u, v)| \u00d7 \u03b2 d) \u2264\nn\u22121 \u2211\nd=k\n\u03c1d\u03b2d \u2264 n\u22121 \u2211\nd=k\n(\u03c1(1\u2212\u2206))d\n= (\u03c1(1 \u2212\u2206))k \u2212 (\u03c1(1\u2212\u2206))n\n1\u2212 \u03c1(1\u2212\u2206) \u2264\n(\u03c1(1 \u2212\u2206))k\n1\u2212 \u03c1(1\u2212\u2206) .\nNote that we use the fact that \u03c1(1\u2212\u2206) < 1 in the last inequality.\nThe requirement that \u03c1(1\u2212\u2206) < 1 is essential to ensure that the sum \u2211n\u22121 d=k \u03c1 d\u03b2d converges nicely even when n is large. Note that when the requirement is not true, the contagion process starting at a single seed vertex can reach a vertex very far from the seed. To see this, take a perfect k-any tree with L levels. The contagion process starting at the root resembles the branching process where the offspring distribution is binomial with parameter k and p, where p is the infectious probability. It is known that if the infectious probability is 1/k + \u01eb, it is very likely that some leaf on the L-th level will be infected. Since our analysis uses a simple union bound that neglects dependencies between paths, it fails to distinguish this situation with the one where a lot of leaves are infected, and finally it fails to show that the probability that a particular node far away from the seed becomes infected is very small.\nFrom Lemma 3.2, we have the next corollary that provides the lower bound on the girth so that the probability of having long active paths is at most \u22062/4. The ceiling function appears because Lemma 3.2 works only when k is an integer, and as a by-product, that the lower bound on g is even.\nCorollary 3.3. For a contagion process with parameter \u2206 over a network G = (V,E), if the girth g of G and the path growth rate \u03c1 satisfy the following inequalities:\n1 \u2264 \u03c1 < 1\n1\u2212\u2206 (1)\ng \u2265 2\n\u2308\n2 log \u22062 + log(1\u2212 \u03c1(1\u2212\u2206))\nlog \u03c1(1 \u2212\u2206)\n\u2309\n(2)\nthen for any pair of vertices u \u2208 V and v \u2208 V , the probability that there exists an active path of length at least g/2 between u and v is at most \u22062/4.\nWe shall use the bound of g in the previous corollary as the lower bound of the girth. Note that the lower bound is not extremely large. When \u2206 = 1/2 and \u03c1 = 1.25, the algorithm works when g \u2265 16. When \u2206 = 1/2 and \u03c1 = 1.5, g \u2265 30.\nLater on in this section, we assume that we work on the network whose parameter \u03c1 and girth g satisfy inequalities (1) and (2), respectively. Moreover, for technical reasons (see the proof of Lemma 3.4), we also assume w.l.o.g. that g is even. When the girth g of the network is odd but satisfies condition (2) from Corollary 3.3, we can take g\u2032 = g \u2212 1 as its lower bound on the girth and apply the results.\nOur main theorem shows that for any network G = (V,E) in this class, the Algorithm 1 returns the edges E with high probability. To prove the theorem, we need the following 3 lemmas.\nThe following lemma deals with the case that (u, v) is an edge in the network.\nLemma 3.4. Assume that the network does not have any cycle of length shorter than g, when g is even, and all the network parameters satisfy the conditions in Corollary 3.3. For any pair of adjacent vertices u, v \u2208 V and any vertex w \u2208 V \\ {u, v}, in any round i where the algorithm queries with seed set Si = {u}, the probability that v \u2208 Ai, but w /\u2208 Ai is at least 7\u2206 2/8. Thus, the expected size of Ru(v)\\Ru(w) is at least 7\u2206 2m/8.\nProof. We first analyze the probability. There are two cases.\nCase 1: v is in a shortest path from u to w. Let P be the shortest path from u to w containing v. Note that since (u, v) \u2208 E, edge (u, v) is the first edge in the path. Let e be an edge in P adjacent to edge (u, v), i.e., e is the next edge after (u, v) in P .\nLet A be the event that (u, v) is active, B be the event that e is active and C be the event that there exists an active path in P(u,w). Note that when event A \u2229 B \u2229 C occurs, we know that v \u2208 Ai and w /\u2208 Ai. Thus, we have\nPr[v \u2208 Ai, w /\u2208 Ai] \u2265 Pr[A \u2229 B \u2229 C] = Pr[A]\u00d7 Pr[B|A]\u00d7 Pr[C|A \u2229 B]\n\u2265 \u22062 \u00d7 (1\u2212 Pr[C|A \u2229 B])\nThe last inequality holds because A and B are independent, and each occurs with probability at least \u2206.\nWe are left to compute the upper bound of the probability of the event C given A\u2229B. The condition A \u2229 B implies that P , which is a shortest path, is inactive. There are two possible subcases that w can be infected: (i) from a path P \u2032 in P(u,w) that uses edge (u, v) or (ii) from a path P \u2032\u2032 in P(u,w) that does not use (u, v).\nLet\u2019s consider subcase (i) first. Since P is a shortest path; the postfix Pv of P starting at v ending at w is also a shortest path from v to w. Let P \u2032v be the postfix of P \u2032 starting at v. We claim that P \u2032v is of length at least g/2. This is true when the shortest path Pv is of length at least g/2. Thus, assume otherwise, i.e., Pv is of length less than g/2; applying Lemma 3.1, we have that all other paths from v to w are of length greater than g/2 as required. Since the paths are long, Corollary 3.3 implies that the probability that we have an active path is at most \u22062/4 \u2264 1/16.\nNext, consider subcase (ii). Using the same argument as in subcase (i), we have that P \u2032\u2032 is of length at least g/2; thus, the probability that we have an active path in this case is at most \u22062/4 \u2264 1/16.\nCombining these two subcases using the union bound, we have that Pr[C|A \u2229 B] \u2264 \u22062/4 +\n\u22062/4 \u2264 1/8. Therefore, the probability that v \u2208 Ai and w /\u2208 Ai is at least 7\u2206 2/8.\nCase 2: v is not in any shortest paths between u and w. Let P be a shortest path from u to w and e be an edge in P that is adjacent to u (i.e., e is the first edge in P ). Provided\nthat (u, v) is active but e is inactive, w \u2208 Ai only when there exists an active path in P(u,w). Again, let A be the event that (u, v) is active, B be the event that e is active, and C be the event that there exists an active path in P(u,w). As in the previous case, we have that Pr[v \u2208 Ai, w /\u2208 Ai] \u2265 Pr[A \u2229 B \u2229 C].\nWe focus on the event C given A\u2229B. If an active path P \u2032 in P(u,w) uses edge (u, v), it has to be of length greater than g/2 because v is not in any shortest paths from u to w. Since g is even, g/2 is an integer; thus, the length of P \u2032 is at least g/2+1. This implies that the postfix of P \u2032 starting at v is of length at least g/2. From Corollary 3.3, the probability that there exists an active path in this case is at most \u22062/4 \u2264 1/16. On the other hand, as e is inactive, an active path from u to w, not going through (u, v), has length at least g/2. Again, Corollary 3.3 implies that the probability of this case is at most \u22062/4 \u2264 1/16. With the union bound, we have that Pr[C|A \u2229 B] \u2264 1/16 + 1/16 = 1/8. Hence, Pr[v \u2208 Ai, w /\u2208 Ai] is at least\nPr[A \u2229 B \u2229 C] = Pr[A]\u00d7 Pr[B|A]\u00d7 Pr[C|A \u2229 B] \u2265 \u22062 \u00d7 (7/8) = 7\u22062\n8 .\nSince for both cases, the probability Pr[v \u2208 Ai, w /\u2208 Ai] is at least 7\u2206 2/8 and the algorithm makes m rounds of queries with seed set {u}, the expected size of Ru(v)\\Ru(w) is at least 7\u22062m/8, as required.\nThe next two lemmas consider non-adjacent vertices u and v. When u is close to v, we use Lemma 3.5; otherwise, we use Lemma 3.6, whose proof uses Corollary 3.3 and is omitted to save space.\nLemma 3.5. For any pair of non-adjacent vertices u, v \u2208 V where duv < g/2, there exists a vertex w \u2208 V \\{u, v} such that in any round i where the algorithm queries with the seed set Si = {u}, the probability that v \u2208 Ai, but w /\u2208 Ai is at most \u2206 2/4. Thus, the expected size of Ru(v)\\Ru(w) is at most \u2206 2m/4.\nProof. From Lemma 3.1, there is only one shortest path from u to v. Let w be the second vertex in the shortest path from u to v. Consider the case that v \u2208 Ai but w /\u2208 Ai. In this case, the edge (u,w) must be inactive. This implies that the shortest path from u to v is also inactive, thus the seed u infects v along a non-shortest path. From Lemma 3.1, any non-shortest paths is of length greater than g/2. Using Corollary 3.3, we have that Pr[v \u2208 Ai, w /\u2208 Ai] \u2264 \u2206 2/4. Since the algorithm makes m rounds of queries with seed set {u}, the expected size of Ru(v)\\Ru(w) is at most \u22062m/4.\nLemma 3.6. For any pair of non-adjacent vertices u, v \u2208 V where duv \u2265 g/2, in any round i where the algorithm queries with the seed set Si = {u}, the probability that v \u2208 Ai is at most \u22062/4. Thus, the expected size of Ru(v) is at most \u2206 2m/4.\nLemma 3.6 implies that for any vertex w, the expected size of Ru(v) \\ Ru(w) is at most \u22062m/4. The previous 3 lemmas show the expectation gap between 7\u22062m/8 and \u22062m/4 of the size of Ru(v) \\ Ru(w) for some vertex w. Using the Chernoff bound, we can prove the main theorem. Its proof is omitted to save space.\nTheorem 3.7. Suppose network G = (V,E) has the parameter\n\u03c1 \u2208 [1, 1\n1\u2212\u2206 ) and g \u2265 2\n\u2308\n2 log \u22062 + log(1\u2212 \u03c1(1\u2212\u2206))\nlog \u03c1(1\u2212\u2206)\n\u2309\n.\nThe Algorithm 1 returns the edges E with probability at least 1 \u2212 \u03b4 after querying at most O( n\u22062 log n \u03b4 ) rounds."}, {"heading": "4 Learning Bounded Degree Networks", "text": "This section shows that if the maximum degree of a network is D, we can recover all edges of the network with probability at least 1\u2212 \u03b4 using polynomial queries in term of n, 1/\u2206 and 1/\u03b4. The key idea is that if the maximum degree of the network is bounded, we could observe a single edge from the results of queries. The algorithm is fairly straight-forward. For each vertex u \u2208 V , the algorithm repeatedly selects {u} to be the seed set for m rounds, where m = O( 1 \u22062D log n\u03b4 ). For any vertex v \u2208 V , the algorithm includes (u, v) to the set E\u2032(u), if there exists round i such that Si = {u} and Ai = {u, v}. After receiving all results of nm queries, the algorithm returns E\u2032 = \u222au\u2208V E \u2032(u).\nTheorem 4.1. Let G = (V,E) be a network with maximum degree D. The algorithm described above can return the edges E with probability at least 1 \u2212 \u03b4 by querying at most O( n \u22062D log n\u03b4 ) rounds.\nProof. Since the algorithm will not include edges not in E, we consider the probability that the algorithm recovers all edges in E.\nConsider edge (u, v) \u2208 E. Consider the round i where {u} is the seed set, i.e., Si = {u}.\nThe probability that we observe only edge (u, v), i.e., Ai = {u, v}, is\npuv \u00d7 \u220f\nw\u2208\u0393(u)\\{v}\n(1\u2212 puw)\u00d7 \u220f\nw\u2208\u0393(v)\\{u}\n(1\u2212 pvw) \u2265 \u2206 2D,\nwhere \u0393(u), for any u \u2208 V , is a set of neighbors of u.\nSince we perform m rounds of queries for u, the probability that we fail to observe edge\n(u, v), when the seed set is {u}, is at most\n(1\u2212\u22062D)m \u2264 exp(\u2212m\u22062D).\nIf we let m = O( 1 \u22062D log n\u03b4 ), the failure probability is at most \u03b4/n 2. Using the union bound, the probability that the algorithm fails to observe any edge is at most |E| \u00b7 \u03b4/n2 \u2264 \u03b4."}, {"heading": "Acknowledgements", "text": "We would like to thank anonymous reviewers for their very helpful comments. We gratefully acknowledge the Thailand Research Fund (TRF) for financial support through the Royal Golden Jubilee (RGJ) Ph.D. Programme under the Grant No. PHD/0310/2550."}], "references": [{"title": "Trace complexity of network inference", "author": ["Bruno D. Abrahao", "Flavio Chierichetti", "Robert Kleinberg", "Alessandro Panconesi"], "venue": "In The 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Learning from contagion (without timestamps)", "author": ["Kareem Amin", "Hoda Heidari", "Michael Kearns"], "venue": "In Proceedings of the 31th International Conference on Machine Learning,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Infection in social networks: Using network analysis to identify high-risk individuals", "author": ["R.M. Christley", "G.L. Pinchbeck", "R.G. Bowers", "D. Clancy", "N.P. French", "R. Bennett", "J. Turner"], "venue": "American Journal of Epidemiology, 162(10):1024\u20131031,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2005}, {"title": "On random graphs", "author": ["P. Erd\u0151s", "A. R\u00e9nyi"], "venue": "I. Publ. Math. Debrecen, 6:290\u2013297,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1959}, {"title": "Random graphs", "author": ["E.N. Gilbert"], "venue": "Ann. Math. Statist., 30(4):1141\u20131144, 12", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1959}, {"title": "Talk of the network: A complex systems look at the underlying process of word-of-mouth", "author": ["Jacob Goldenberg", "Barak Libai", "Eitan Muller"], "venue": "Marketing Letters,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2001}, {"title": "Using complex systems analysis to advance marketing theory development", "author": ["Jacob Goldenberg", "Barak Libai", "Eitan Muller"], "venue": "Academy of Marketing Science Review,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2001}, {"title": "Submodular inference of diffusion networks from multiple trees", "author": ["Manuel Gomez-Rodriguez", "Bernhard Sch\u00f6lkopf"], "venue": "In Proceedings of the 29th International Conference on Machine Learning,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Inferring networks of diffusion and influence", "author": ["Manuel Gomez-Rodriguez", "Jure Leskovec", "Andreas Krause"], "venue": "In Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "The strength of weak ties", "author": ["M.S. Granovetter"], "venue": "The American Journal of Sociology, 78(6): 1360\u20131380,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1973}, {"title": "Maximizing the spread of influence through a social network", "author": ["David Kempe", "Jon M. Kleinberg", "\u00c9va Tardos"], "venue": "In Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2003}, {"title": "The dynamics of viral marketing", "author": ["Jure Leskovec", "Lada A. Adamic", "Bernardo A. Huberman"], "venue": "In Proceedings 7th ACM Conference on Electronic Commerce,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2006}, {"title": "On the convexity of latent social network inference", "author": ["Seth A. Myers", "Jure Leskovec"], "venue": "In Advances in Neural Information Processing Systems 23: 24th Annual Conference on Neural Information Processing Systems,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}, {"title": "Learning the graph of epidemic cascades", "author": ["Praneeth Netrapalli", "Sujay Sanghavi"], "venue": "In ACM SIGMETRICS/PERFORMANCE Joint International Conference on Measurement and Modeling of Computer Systems,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "A survey of models and algorithms for social influence analysis", "author": ["Jimeng Sun", "Jie Tang"], "venue": "Social Network Data Analytics,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2011}, {"title": "Social influence analysis in large-scale networks", "author": ["Jie Tang", "Jimeng Sun", "Chi Wang", "Zi Yang"], "venue": "In Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2009}, {"title": "Collective dynamics of \u2018small-world", "author": ["Duncan J. Watts", "Steven H. Strogatz"], "venue": "networks. Nature,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1998}], "referenceMentions": [{"referenceID": 9, "context": ", in social network analysis [10, 16, 15], in epidemiology [3], and in viral marketing [12].", "startOffset": 29, "endOffset": 41}, {"referenceID": 15, "context": ", in social network analysis [10, 16, 15], in epidemiology [3], and in viral marketing [12].", "startOffset": 29, "endOffset": 41}, {"referenceID": 14, "context": ", in social network analysis [10, 16, 15], in epidemiology [3], and in viral marketing [12].", "startOffset": 29, "endOffset": 41}, {"referenceID": 2, "context": ", in social network analysis [10, 16, 15], in epidemiology [3], and in viral marketing [12].", "startOffset": 59, "endOffset": 62}, {"referenceID": 11, "context": ", in social network analysis [10, 16, 15], in epidemiology [3], and in viral marketing [12].", "startOffset": 87, "endOffset": 91}, {"referenceID": 5, "context": "[6, 7] and Kempe et al.", "startOffset": 0, "endOffset": 6}, {"referenceID": 6, "context": "[6, 7] and Kempe et al.", "startOffset": 0, "endOffset": 6}, {"referenceID": 10, "context": "[11]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "The problem was first considered by Gomez-Rodriguez, Leskovec, and Krause [9].", "startOffset": 74, "endOffset": 77}, {"referenceID": 8, "context": ", [9, 13, 8, 14, 1]), the set of infected vertices are clearly easier to observe.", "startOffset": 2, "endOffset": 19}, {"referenceID": 12, "context": ", [9, 13, 8, 14, 1]), the set of infected vertices are clearly easier to observe.", "startOffset": 2, "endOffset": 19}, {"referenceID": 7, "context": ", [9, 13, 8, 14, 1]), the set of infected vertices are clearly easier to observe.", "startOffset": 2, "endOffset": 19}, {"referenceID": 13, "context": ", [9, 13, 8, 14, 1]), the set of infected vertices are clearly easier to observe.", "startOffset": 2, "endOffset": 19}, {"referenceID": 0, "context": ", [9, 13, 8, 14, 1]), the set of infected vertices are clearly easier to observe.", "startOffset": 2, "endOffset": 19}, {"referenceID": 1, "context": "Thus, we follow a recent work by Amin, Heidari, and Kearns [2] who introduced a problem of learning unknown network structure by observing only sets of initial infected vertices and sets of final infected vertices.", "startOffset": 59, "endOffset": 62}, {"referenceID": 1, "context": "[2], to two other classes of networks, as described below.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "Since a tree does not contain any cycle, its girth is \u221e; this class of networks generalizes the tree networks considered in [2].", "startOffset": 124, "endOffset": 127}, {"referenceID": 1, "context": "This class also includes a counter example for the K-lifts algorithm provided in [2].", "startOffset": 81, "endOffset": 84}, {"referenceID": 1, "context": "[2]\u2019s work, this type of networks may appear in advisor-advisee networks where cross-field advising happens on rare occasions or in organizational networks, networks that represent ranks and relations of people in organizations, where few low-ranking workers may report to more than one middle managers, resulting in large cycles that span the people at the top-most levels of the organizations.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6, 7] and Kempe et al.", "startOffset": 0, "endOffset": 6}, {"referenceID": 6, "context": "[6, 7] and Kempe et al.", "startOffset": 0, "endOffset": 6}, {"referenceID": 10, "context": "[11], as follows.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "Amin, Heidari, and Kearns [2] considered the problem in both active model and passive model.", "startOffset": 26, "endOffset": 29}, {"referenceID": 3, "context": "The experimental results showed that the K-lifts algorithm performs well when learning sparse random networks (under the Erd\u0151s-R\u00e9nyi model [4, 5] and the Small-World model [17]).", "startOffset": 139, "endOffset": 145}, {"referenceID": 4, "context": "The experimental results showed that the K-lifts algorithm performs well when learning sparse random networks (under the Erd\u0151s-R\u00e9nyi model [4, 5] and the Small-World model [17]).", "startOffset": 139, "endOffset": 145}, {"referenceID": 16, "context": "The experimental results showed that the K-lifts algorithm performs well when learning sparse random networks (under the Erd\u0151s-R\u00e9nyi model [4, 5] and the Small-World model [17]).", "startOffset": 172, "endOffset": 176}, {"referenceID": 1, "context": "\u2019s counter example H (discussed in Theorem 6 in [2]) since the girth of H is n and its path growth ratio is 22/n, which is close to 1.", "startOffset": 48, "endOffset": 51}], "year": 2017, "abstractText": "In 2014, Amin, Heidari, and Kearns proved that tree networks can be learned by observing only the infected set of vertices of the contagion process under the independent cascade model, in both the active and passive query models. They also showed empirically that simple extensions of their algorithms work on sparse networks. In this work, we focus on the active model. We prove that a simple modification of Amin et al.\u2019s algorithm works on more general classes of networks, namely (i) networks with large girth and low path growth rate, and (ii) networks with bounded degree. This also provides partial theoretical explanation for Amin et al.\u2019s experiments on sparse networks.", "creator": "LaTeX with hyperref package"}}}