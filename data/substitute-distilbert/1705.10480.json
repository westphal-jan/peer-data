{"id": "1705.10480", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-May-2017", "title": "Preliminary results on Ontology-based Open Data Publishing", "abstract": "for the current interest in open data publishing, a formal and comprehensive methodology supporting an organization in deciding which data to publish and carrying out precise procedures for publishing high - quality data, is still missing. in this purpose we argue that the ontology - based data management paradigm can strengthen a theoretical basis for a principled approach currently promoting high quality, semantically annotated open data. we describe two main approaches to using an ontology for this endeavor, and then we present some technical discussions on bottom of the approaches, called bottom - up, where the specification of the data to be compiled is given in terms underlying the sources, and specific techniques allow deriving suitable examples for composing complete web data under the light of the ontology.", "histories": [["v1", "Tue, 30 May 2017 07:16:45 GMT  (30kb)", "https://arxiv.org/abs/1705.10480v1", null], ["v2", "Thu, 13 Jul 2017 13:40:52 GMT  (30kb)", "http://arxiv.org/abs/1705.10480v2", null]], "reviews": [], "SUBJECTS": "cs.DB cs.AI", "authors": ["gianluca cima"], "accepted": false, "id": "1705.10480"}, "pdf": {"name": "1705.10480.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Gianluca Cima"], "emails": ["cima@diag.uniroma1.it"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 5.\n10 48\n0v 2\n[ cs\n.D B\n] 1\n3 Ju\ncomprehensive methodology supporting an organization in deciding which data to publish and carrying out precise procedures for publishing high-quality data, is still missing. In this paper we argue that the Ontology-based Data Management paradigm can provide a formal basis for a principled approach to publish highquality, semantically annotated Open Data. We describe two main approaches to using an ontology for this endeavor, and then we present some technical results on one of the approaches, called bottom-up, where the specification of the data to be published is given in terms of the sources, and specific techniques allow deriving suitable annotations for interpreting the published data under the light of the ontology."}, {"heading": "1 Introduction", "text": "In many aspects of our society there is growing awareness and consent on the need\nfor data-driven approaches that are resilient, transparent and fully accountable. But to\nachieve a data-driven society, it is necessary that the data needed for public goods are readily available. Thus, it is no surprising that in recent years, both public and private\norganizations have been faced with the issue of publishing Open Data, in particular with\nthe goal of providing data consumers with suitable information to capture the semantics of the data they publish. Significant efforts have been devoted to defining guidelines concerning the management and publication of Open Data. Notably, the W3C1 has formed a working group, whose objective is the release of a first draft on Open Data Standards2. The focus of the document are areas such as metadata, data formats,\ndata licenses, data quality, etc., which are treated in very general terms, with no reference to any specifical technical methodology.More generally, although there are several\nworks on platforms and architectures for publishing Open Data, there is still no formal\nand comprehensive methodology supporting an organization in (i) deciding which data to publish, and (ii) carrying out precise procedures for publishing and documenting\nhigh-quality data. One of the reasons of this lack of formal methods is that the problem of Open Data Publishing is strictly related to the problem of managing the data\n1 World Wide Web Consortium: https://www.w3.org/ 2 Data on the Web Best Practice: https://www.w3.org/TR/dwbp/\nwithin an organization. Indeed, a necessary prerequisite for an organization for pub-\nlishing relevant and meaningful data is to be able to manage, maintain and document\nits own information system. The recent paradigm of Ontology-basedData Management (OBDM) [16] (used and experimented in practice in the last years, see, e.g., [3]) is an\nattempt to provide the principles and the techniques for addressing this challenge. An OBDM system is constituted by an ontology, the data sources forming the information\nsystem, and the mapping between the ontology and the sources. The ontology is a for-\nmal representation of the domain underlying the information system, and the mapping is a precise specification of the relationship between the data at the sources and the\nconcepts in the ontology.\nIn this paper we argue that the OBDM paradigm can provide a formal basis for\na principled approach to publish high-quality, semantically annotated Open Data. The\nmost basic task in Open Data is the extraction of the correct content for the dataset(s) to be published, where by \u201ccontent\u201d we mean both the extensional information (i.e., facts\nabout the domain of interest) conveyed by the dataset, and the intensional knowledge\nrelevant to document such facts (e.g., concepts that intensionally describe facts), and \u201ccorrect\u201d means that the aspect of the domain captured by the dataset is coherent with\na requirement formally expressed in the organization.\nCurrent practices for publishing Open Data focus essentially on providing exten-\nsional information (often in very simple forms, such as CSV files), and they carry out the task of documenting data mostly by using metadata expressed in natural languages,\nor in terms of record structures. As a consequence, the semantics of datasets is not\nformally expressed in a machine-readable form. Conversely, OBDM opens up the possibility of a new way of publishing data, with the idea of annotating data items with the\nontology elements that describe them in terms of the concepts in the domain of the orga-\nnization. When an OBDM is available in an organization, an obvious way to proceed to Open Data publication is as follows: (i) express the dataset to be published in terms of\na SPARQL query over the ontology, (ii) compute the certain answers to the query, and\n(iii) publish the result of the certain answer computation, using the query expression and the ontology as a basis for annotating the dataset with suitable metadata expressing\nits semantics. We call such method top-down. Using this method, the ontology is the heart of the task: it is used for expressing the content of the dataset to be published (in\nterms of a query), and it is used, together with the query, for annotating the published\ndata.\nUnfortunately, in many organizations (for example, in Public Administrations) it\nmay be the case that people are not ready yet to manage their information systems through the OBDM paradigm. In these cases, the bottom-up approach could be more\nappropriate. For example, in the Italian Public Administration system, it is very unlikely\nthat local administration people are able to express their queries over the ontology using SPARQL. Typically, the ontology and the mapping have been designed by third parties,\nwith no or little involvement with IT people responsible of the local administration information system. In other words, these people probably cannot follow the top-down\napproach, and they are more confident to express the specification of the dataset to be\npublished directly in terms of the source structures (i.e., the relational tables in their databases), or, more generally, in terms of a view over the sources. But how can we au-\ntomatically publish both the content and the semantics of the dataset if its specification\nis given in terms of the data sources? We argue that we can achieve this goal by fol-\nlowing what we call the bottom-up approach: the organization expresses its publishing requirement as a query over the sources, and, by using the ontology and the mapping,\na suitable algorithm computes the corresponding query over the ontology. With such query at hand, we have reduced the problem in such a way that the top-down approach\ncan now be followed, and the required data can be published according to the method\ndescribed above. So, at the heart of the bottom-up approach there is a conceptual issue to address:\n\u201dGiven a query Q over the sources, which is the query over the ontology that characterizes Q at best (independently from the current source database)?\u201d\nNote that the answer to this question is relevant also for other tasks related to the man-\nagement of the information system, e.g., the task of explaining the semantics of the various data sources within the organization. The question implicitly refers to a sort\nof reverse engineering problem, which is a novel aspect in the investigation of both\nOBDM and data integration. Indeed, most of (if not all) the literature about managing data sources through an ontology (see, e.g., [5, 18]), or more generally, about data\nintegration [15] assume that the user query is expressed over the global schema, and\nthe goal is to find a rewriting (i.e., a query over the source schema) that captures the original query in the best way, independently from the current source database. Here,\nthe problem is reversed, because we start with a source query and we aim at deriving a corresponding query over the ontology, called a source-to-target rewriting.\nIn this paper we study the above described bottom-up approach, and provide the\nfollowing contributions.\n\u2013 We introduce the concept of source-to-target rewriting (see Section 3), the main\ntechnical notion underlying the bottom-up approach, and we describe two computation problems related to it, namely the recognition problem, and the finding\nproblem. The former aims at checking whether a query over the ontology is a source-to-target rewriting of a given query over the sources, taking into account\nthe mapping between the sources and the ontology. The latter aims at computing\na suitable source-to-target rewriting of a given source query, with respect to the\nmapping. \u2013 We discuss two different semantics for source-to-target rewritings, one based on\nthe logical models of the OBDM specification, and one based on certain answers.\nThe former is somehow the natural choice, given the first-order semantics behind OBDM. The latter is a significant alternative, that may better capture the intuition\nof a user who is accustomed to think of query semantics in terms of certain answers. \u2013 We show that, although the ideal notion is the one of \u201cexact\u201d source-to-target rewrit-\ning, it is important to resort to approximations to exact rewriting when exactness\ncannot be achieved. For this reason, we introduce the notion of sound and complete\nsource-to-target rewritings. \u2013 For the case of complete source-to-target rewritings, we present algorithms both for\nthe recognition (Section 4), and for the finding (Section 5) problem, in particular for\nthe setting where the ontology is expressed in DL-LiteA,id, and the queries involved in the specification are conjunctive queries."}, {"heading": "2 Preliminaries", "text": "We assume familiarity with classical databases [1], Description Logics [4], and the\nOBDM paradigm. In this section, we (i) review the most basic notions of non-ground\ninstances, and their correlation with conjunctive queries; (ii) briefly discuss the chase of a possible non-ground instance; (iii) discuss the relevant aspects of notation we use\nin the following regarding the OBDM paradigm.\nFor a possible non-ground instance D, we assume that each value in dom(D), i.e., the set of values occurring in D, comes from the union of two fixed disjoint infinite\nsets: the set Const of all constants, and the set NullD of all labeled nulls. We also let null(D) := dom(D) \u2229 NullD. In particular, each labeled null in a non-ground instance is treated as an unknown value (and hence, an incomplete information), rather than to\na non-existent value [20]. Thus, a non-ground instance represents a number of ground instances obtained by assigning constants to each labeled null. More precisely, let D be a non-ground instance, and v be a mapping v : null(D) \u2192 Const. Then, v is called a valuation of D, and we indicate, with v(D), the ground instance obtained from D by replacing elsewhere each labeled null x \u2208 D with v(x). We also extend this to tuples, that is, given a tuple u = (u1, ..., un) of both constants and labeled nulls, with v(u) we indicate the tuple (v\u2032(u1), ..., v \u2032(un)), where v \u2032(ui) = ui if ui is a constant; otherwise (ui is a labeled null), v \u2032(ui) = v(ui). Given an instance D it is possible to construct in linear time a boolean CQ qD that fully captures it, and vice versa. We also let qD(x) denoting the transformation of qD by removing the existential quantification of the variables x in qD. Moreover, given a non-boolean CQ q (with x as distinguished variables), we associate to it the instance Dq by considering the variables in x as if they were existentially quantified. For ease of presentation, we extend CQs to allow also queries of the form {x | \u22a5(x)} and {x | \u22a4(x)}, with their usual meaning. We also denote with tup(q) the tuple composed by the terms in head of q.\nGiven a source schema S; a target schema T ; a set M of st-tgds (i.e., assertions of the form \u2200x, y(\u03c6(x, y) \u2192 \u2203z\u03d5(x, z)), where \u03c6 is a CQ over S, and \u03d5 is a CQ over T); and a set \u03a3t of egds (i.e., assertions of the form \u2200x(\u03c6T(x) \u2192 (x1 = x2)), where \u03c6T is a CQ over T, and x1, x2 are among the variables in x), the chase procedure of a possibly non-ground source instance D consists in: (i) the chase of D w.r.t. M, where, for every st-tgd \u03c6(x, y) \u2192 \u2203z\u03d5(x, z) in M and for every pair of tuples (a, b) such that D |= \u03c6(a, b), there is the introduction of new facts in the instance J of the target schema T so that\u03d5(a, u) holds, where u consists in a fresh tuple of distinct labeled nulls coming from an infinite set Null\u03a3 disjoint from NullD; (ii) the chase of J w.r.t. \u03a3t, where, for every egd \u2200x(\u03c6T(x) \u2192 (x1 = x2)) and for every tuple a such that J |= \u03c6T(a) and a1 6= a2, we equate the two terms. Equating a1 with a2 means choosing one of the two so that the other is replaced elsewhere in J by the one chosen. In particular, if one is a\nlabeled null and the other is a constant, then the chase choose the constant; if both are labeled nulls, one coming from NullD and the other from Null\u03a3 , it always choose the one coming fromNullD; if both are constants, then the chase fail. Moreover, with \u03c8 we denote the set of equalities applied by the chase of J w.r.t. a set of egds on variables\ncoming from NullD. This can be done by keeping track of the substitution applied by the chase. For example, if the chase equates the variable y \u2208 NullD with the variable x \u2208 NullD, and then equates the variable z \u2208 NullD with the variable w \u2208 NullD, and\nthen w with the constant a, given the tuple (x, y, z, w), \u03c8(x, y, z, w) indicates the tuple (x, x, a, a). Note that, we can compute the certain answers of a boolean union of CQs (UCQ) q with at most one inequality per disjunct by splitting q as a boolean UCQ q16= with exactly one inequality per disjunct, and a boolean UCQ q06= with no inequality per disjunct. The key idea is that the negation of q16= consists in a set of egds, hence, the certain answers of q can be computed by applying the chase procedure over the instance J (i.e., the instance produced by the chase of C w.r.t.M and \u03a3t) w.r.t. \u00acq16=, where, if the chase fail then the answer is true; otherwise, if the instance J \u2032 produced satisfy one of the conjunctive query in q06=, then the answer is true, else the answer is false . We\nrefer to [10] for more details. Given an OBDM specification I = \u3008O,M,S\u3009, where O is a TBox, and M is a set of st-tgds, and given a non-ground source instance D for S, and a set of egds \u03a3t, we denote with AD,\u03a3 , where \u03a3 = M \u222a \u03a3t, the ABox computed as follows: (i) chase the non-ground source instance D w.r.t. \u03a3; (ii) freeze the instance (or equivalently, the\nABox with variables) obtained, i.e., variables in this instance are now considered as constant. Note that, such ABoxAD,\u03a3 may also not exists due to the failing of the chase, in this case, we denoteAD,\u03a3 with the symbol\u22a5.\nFor an OBDM specification I = \u3008O,M,S\u3009, and for a source database C for I (i.e., a ground instance over the schema S), we denote by semC(I) the set of models B for I relative to C such that: (i) B |= O; (ii) (B, C) |= M. Given a query q over O, we denote by cert(q, I, C) the set of certain answers to q in I relative to C. It is defined as: cert(q, I, C) = \u22c2 {qB | B \u2208 semC(I)} if semC(I) 6= \u2205; otherwise, cert(q, I, C) = AllTup(q, C), where AllTup(q, C) is the set of all possible tuples of constants in C whose arity is the one of the query q. Furthermore, given a DL-LiteA,id [5] TBox O and a DL-LiteA,id ABox A we are able to: (i) check whether \u3008O,A\u3009 is satisfiable by computing the answers of a suitable boolean queryQsat (a UCQ with at most one inequality per disjunct) over the ABox A considered as a relational database. We see Qsat as the union of Q 06= sat (the UCQ containing every disjunct not comprising inequalities in Qsat ) and Q 16= sat (the UCQ containing every disjunct comprising inequalities in Qsat ); (ii) compute the certain answers to a UCQ Qg over a satisfiable \u3008O,A\u3009, denoted with cert(Qg, \u3008O,A\u3009), by producing a perfect reformulation (denoted as a function pr(\u00b7)) of such query, and then computing the answers of pr(Qg) over the ABox A considered as a relational database. See [6] for more details."}, {"heading": "3 The notion of source-to-target rewriting", "text": "In what follows, we implicitly refer to (i) an OBDM specification I = \u3008O,M,S\u3009; (ii) a queryQs over the source schema S; (iii) a queryQg over the ontologyO.\nAs we said in the introduction, there are at least two different ways to formally\ndefine a source-to-target rewriting (s-to-t rewriting in the following) for each of the three variants, namely \u201cexact\u201d, \u201ccomplete\u201d, and \u201csound\u201d. The first one is captured by\nthe following definition.\nDefinition 1. Qg is a complete (resp., sound, exact) s-to-t rewriting of Qs with respect to I under the model-based semantics, if for each source database C and for each model B \u2208 semC(I), we have that QCs \u2286 Q B g (resp.,Q B g \u2286 Q C s , Q B g = Q C s ).\nIntuitively, a complete s-to-t rewriting of Qs w.r.t. I under the model-based semantics is a query overO that, when evaluated over a model B \u2208 semC(I) for a source database C, returns all the answers of the evaluation ofQs over C. In other words, for every source database C, the queryQg overO captures all the semantics thatQs expresses over C. Similar arguments hold for the notions of sound and exact s-to-t rewriting under this semantics. Moreover, from the formal definition of source-to-target rewriting\nand the usual definition of target-to-source rewriting (simply called rewriting) used in data integration, it is easy to see that Qg is a complete (resp., sound) source-to-target rewriting of Qs w.r.t. I under the model-based semantics, if and only if Qs is a sound (resp., complete) rewriting ofQs w.r.t. I, implying that,Qg is an exact source-to-target rewriting of Qs w.r.t. I under the model-based semantics, if and only if Qs is an exact rewriting of Qg w.r.t. I.\nThe second possible way to formally define a source-to-target rewriting is as fol-\nlows.\nDefinition 2. Qg is a complete (resp., sound, exact) s-to-t rewriting of Qs with respect to I under the certain answers-based semantics, if for each source database C such that semC(I) 6= \u2205, we have that QCs \u2286 cert(Qg, I, C) (resp., cert(Qg, I, C) \u2286 Q C s , QCs = cert(Qg, I, C)).\nIn this new semantics, in order to capture a query Qs over S, we resort to the notion of certain answers. Indeed, a complete s-to-t rewriting of Qs w.r.t. I under the certain answers-based semantics is a query over O such that, when we compute its certain answers for a source database C, we get all the answers of the evaluation of Qs over C. As before, similar arguments hold for the notions of sound and exact s-to-t rewriting under this semantics. Note also the strong correspondence between the exact s-to-t rewriting under the certain answers-based semantics and the notion of perfect rewriting. We remind that a perfect rewriting of Qg w.r.t. I is a query Qs over S that computes cert(Qg, I, C) for every source database C such that semC(I) 6= \u2205 [8]. Indeed, we have that Qg is an exact s-to-t rewriting of Qs w.r.t. I under the certain answers-based semantics if and only if Qs is a perfect rewriting of Qg w.r.t. I. Note that the above observations imply that the two semantics are indeed different, since it is well-known that the two notions of exact rewriting and perfect rewriting ofQg w.r.t. I are different. The difference between the two semantics is confirmed by the following example.\nExample 1. O := \u2205 (i.e., no TBox assertions in O); S contains a binary relation r1 and a unary relation r2; M := {\u2200x\u2200y(r1(x, y) \u2192 G(x, y)), \u2200x(r2(x) \u2192 \u2203Y.G(x, Y ))}; Qs := {(w) | \u2203Z.r1(Z,w)}; Qg := {(w) | \u2203Z.G(Z,w)}.\nIt is easy to see that Qg is a sound s-to-t rewriting of Qs w.r.t. I under the certain answers-based semantics (more precisely, it is an exact s-to-t rewriting of Qs w.r.t. I under such semantics), while it is not sound under the model-based semantics. In fact, for the source database C with rC1 = {(a, b)} and r C 2 = {(c)}, and for the model B with G B = {(a, b), (c, d)}, we have B \u2208 semC(I), and QBg 6\u2286 Q C s . \u2293\u2294\nIntuitively, for the sound case, the model-based semantics is too strong, in the sense that under such semantics, a model B may contain not only facts depending on how data in the source C are linked to O throughM, but additionally arbitrary facts, with the only constraint of satisfying O. One might think that, in order to address this issue, it is\nsufficient to resort to a sort of minimizations of the models of O. Actually, the above example shows that, even if we restrict the set of models to the set of minimal models (i.e., models B such that (i) B \u2208 semC(I) and (ii) there is no modelB\u2032 \u2208 semC(I) such that B\u2032 \u2282 B), and adopt a semantics like the model-based one but restricted to the set of minimal models,Qg is still not a sound s-to-t rewriting (this can be seen considering that the target database B defined earlier is a minimal model). Observe that the above considerations show the difference in the two semantics by\nreferring to sound and exact s-to-t rewritings. It is interesting to ask whether the difference shows up when restricting our attention to complete rewritings. The following\nproposition deals with this question.\nProposition 1. Qg is a complete s-to-t rewriting of Qs with respect to I under the model-based semantics if and only if it is so under the certain answers-based semantics.\nProof (Sketch).One direction is trivial. Indeed, whenQg is a complete s-to-t rewriting of Qs with respect to I under the model-based semantics, by definition of certain answers, for each source database C such that semC(I) 6= \u2205 we have that QCs \u2286 cert(Qg, I, C). For the other direction, suppose that Qg is not a complete s-to-t rewriting ofQs w.r.t. I under the model-based semantics. It follows that, there exists a source database C and a model B \u2208 semC(I) such that QCs 6\u2286 Q B g , implying that, Q C s 6\u2286 cert(Qg, I, C), which, in turn, implies thatQg is not a complete s-to-t rewriting ofQs w.r.t. I under the certain answers-based semantics. \u2293\u2294\nObviously, the query over the ontology which captures at best a given query q over the source schema is the exact s-to-t rewriting of q. However, the following example\nshows that even for very simple OBDM specifications, an exact s-to-t rewriting of even\ntrivial queries, may not exist.\nExample 2. O := \u2205 (i.e., no TBox assertions inO); S contains two unary relationsman and woman ; M := {\u2200x(man(x) \u2192 Person(x)), \u2200x(woman(x) \u2192 Person(x))}; Qs := {(x) | woman(x)}.\nIt is possible to show that the only sound s-to-t rewriting of Qs w.r.t. I under both semantics is the query Qg := {(x) | \u22a5(x)}, which is obviously not a complete s-to-t rewriting of Qs w.r.t. I neither under the model-based semantics, nor under the certain answers-based semantics. On the other hand, the most immediate and intuitive complete s-to-t rewriting of Qs w.r.t. I is the query Q\u2032g := {(x) | Person(x)}. Furthermore, as we will see in Section 5, this query is an \u201coptimal\u201d complete s-to-t rewriting ofQs w.r.t. I, where the term optimal will be precisely defined. \u2293\u2294\nAs we said in the introduction, in the rest of this paper we focus on complete s-to-t-\nrewritings. In particular, we will address both the recognition problem (see Section 4), and the finding problem (see Section 5) in a specific setting, characterized as follows:\n\u2013 The ontologyO in an OBDM specification I = \u3008O,M,S\u3009 is expressed as a TBox in DL-LiteA,id. \u2013 The mappingM in I is a set of GLAVmapping assertions (or, st-tgds), where each assertion expresses a correspondence between a conjunctive query over the source\nschema and a conjunctive query over the ontology.\n\u2013 In the recognition problem, both the query over the source schema and the query\nover the ontology are conjunctive queries. Similarly, in the finding problem, the\nquery over the source schema is a conjunctive query."}, {"heading": "4 The recognition problem for complete s-to-t rewritings", "text": "We implicitly refer to the setting described at the end of the previous section. The recognition problem associated to the complete s-to-t rewriting is the following decision problem: Given an OBDM specification I = \u3008O,M,S\u3009, a queryQs over the source schema S, and a queryQg over the ontologyO, check whetherQg is a complete s-to-t rewriting of Qs with respect to I. The next lemma is the starting point of our solution.\nLemma 1. Qg is not a complete s-to-t rewriting of Qs with respect to I = \u3008O,M,S\u3009 if and only if there is a valuation v of DQs and a model B \u2208 sem\nv(DQs )(I) such that v(tup(Qs)) 6\u2208 QBg .\nProof. \u201d\u21d0=\u201d Suppose that there exists a valuation v of DQs and a modelB \u2208 sem v(DQs )(I) such that v(tup(Qs)) 6\u2208 QBg . Obviously, v(tup(Qs)) \u2208 Q v(DQs ) s . It follows that, there exist a source database v(DQs), a model B \u2208 sem v(DQs )(I), and a tuple v(tup(Qs)) such that v(tup(Qs)) 6\u2208 QBg and v(tup(Qs)) \u2208 Q v(DQs ) s .\n\u201d=\u21d2\u201d Suppose that Qg is not a complete s-to-t rewriting of Qs w.r.t. I, i.e., there is a source database C, a model B \u2208 semC(I), and a tuple t such that t \u2208 QCs and t 6\u2208 QBg . The fact that t \u2208 Q C s implies the existence of a homomorphism v : DQs \u2192 C such that v(tup(Qs)) = t. Note also, that since C is a ground instance, v is a valuation of DQs such that v(DQs) \u2286 C. Obviously, B \u2208 sem\nv(DQs )(I), this can be seen by considering that (i) B |= O is true from the supposition that B \u2208 semC(I); and (ii) (B, v(DQs)) |= M is true by considering that, (B, C) |= M (which holds from the supposition that B \u2208 semC(I)), v(DQs) \u2286 C, and the queries in M are monotone queries. It follows that, there is a valuation v of DQs and a model B \u2208 sem\nv(DQs )(I) such that v(tup(Qs)) 6\u2208 QBg . \u2293\u2294\nRelying on the above lemma, we are now ready to present the algorithm CheckComplete for the recognition problem.\nAlgorithm 1: CheckComplete(I,Qs, Qg)\nInput: OBDM specification I = \u3008O,S,M\u3009, queryQs over S, queryQg overO. Output: true or false.\n1: Compute DQs fromQs (i.e., the instance, possibly with incomplete information,\nassociated to the queryQs), and denote it with D.\n2: ComputeAD,\u03a3 , where \u03a3 = M\u222a\u00acQ 16= sat , and let \u03c8 be the set of equality applied\nto the variables in D by the chase.\n3: If AD,\u03a3 = \u22a5, then return true. 4: If the evaluation of Q 06= sat overAD,\u03a3 considered as a relational database is {()}\n(i.e.,AD,\u03a3 |= Q 06= sat ), then return true.\n5: If \u03c8(tup(Qs)) \u2208 cert(Qg, \u3008O,AD,\u03a3\u3009) then return true, else return false.\nThe next theorem establishes the correctness of the above algorithm.\nTheorem 1. CheckComplete(I, Qs, Qg) terminates, and returns true if and only if Qg is a complete s-to-t rewriting of Qs w.r.t. I.\nProof (Sketch). Termination of the algorithm easily follows by the termination of the chase procedure, and by the obvious termination of computing the certain answers of a CQ over \u3008O,AD,\u03a3\u3009.\nFor the \u201d=\u21d2\u201d direction, suppose that the algorithm returns false, i.e.,AD,\u03a3 6|= Q 06= sat , and \u03c8(tup(Qs)) 6\u2208 cert(Qg, \u3008O,AD,\u03a3\u3009). Now, if we extend \u03c8(D) by considering the freezing of this instance (i.e., variables are now considered as constants), it is easy to see that we obtain a valuation v of D such that (v(D),AD,\u03a3) |= M, and such that semv(D)(I) 6= \u2205. Moreover, the fact that \u03c8(tup(Qs)) 6\u2208 cert(Qg, \u3008O,AD,\u03a3\u3009), implies, by the property of certain answers, that there is at least one model B |= \u3008O,AD,\u03a3\u3009, and hence B \u2208 semv(D)(I) (because (v(D),AD,\u03a3) |= M) such that v(tup(Qs)) 6\u2208 QBg . It follows, from Lemma 1, that Qg is not a complete s-to-t rewriting of Qs w.r.t. I.\nFor the \u201d\u21d0=\u201d direction, in the cases that AD,\u03a3 = \u22a5 or AD,\u03a3 |= Q 06= sat , it is easy to see that for every valuation v of D, either the chase of v(D) will fail, or every ABox A such that (v(D),A) |= M and A |= \u00acQ16=sat will be such that A |= Q 06= sat , implying that, for every valuation v of D, semv(D) = \u2205. It follows, from Lemma 1, that in this case Qg is a complete s-to-t rewriting of Qs w.r.t. I. While, in the cases that \u03c8(tup(Qs)) \u2208 cert(Qg, \u3008O,AD,\u03a3\u3009), it is easy to see that, for every valuation v of D either semv(D) = \u2205, or if we compute Av(D),\u03a3 , we have that v(tup(Qs)) \u2208 cert(Qg, \u3008O,Av(D),\u03a3\u3009). More generally, every A obtained by chasing v(D) w.r.t. M and \u00acQ16=sat , and then choosing arbitrary constants for the possible remaining variables, is such that v(tup(Qs)) \u2208 cert(Qg, \u3008O,A\u3009). Hence, for every model B such that B |= \u3008O,A\u3009, we have that v(tup(Qs)) \u2208 QBg . Also, we observe that the set of models semv(D) coincides with the set of all modelsB such that B |= \u3008O,A\u3009 for all the possible ABox A obtained using the above procedure. It follows that, for every possible valuation v of D and for every possible B \u2208 semv(D)(I), we have that v(tup(Qs)) \u2208 QBg , implying, from Lemma 1, that also in this case Qg is a complete s-to-t rewriting of Qs w.r.t. I. \u2293\u2294\nAs for complexity issues of the algorithm, we observe: (i) it runs in PTIME in the size of Qs. Indeed, computing D (the instance associated to the query Qs) can be done in linear time, and chasing an instance in the presence of a weakly acyclic set of tgds (as in our case) is PTIME in the size of D (M and \u03a3 are considered fixed); (ii) it runs in PTIME in the size of O. Indeed, Qsat and the evaluation of the certain answers of Qg can be both computed in PTIME in the size ofO; (iii) it runs in EXPTIME in the size of M. This can be seen from the obvious EXPTIME process of transferring data from D to AD,\u03a3 ; (iv) the problem is NP-complete in the size ofQg because computing the certain answers of a UCQ query is NP-complete in the size of the query (query complexity)."}, {"heading": "5 Finding optimal complete s-to-t rewritings", "text": "In this section we study the problem of finding optimal complete s-to-t rewritings. The first question to ask is which rewriting we chose in the case where several complete\nrewritings exist. The obvious choice is to define the notion of \u201coptimal\u201d complete s-to-t rewriting: one such rewriting r is optimal if there is no complete s-to-t rewriting that is contained in r. In order to formalize this notion, we introduce the following definitions (where MOD(O) denotes the set of models of O).\nDefinition 3. Qg is contained in Q \u2032 g with respect to O, denoted Qg \u2286O Q \u2032 g , if for every model B \u2208 MOD(O) we have that Qg B \u2286 Q\u2032g B . Qg is proper contained in Q\u2032g with respect to O, denoted Qg \u2282O Q \u2032 g, if Qg \u2286O Q \u2032 g and for at least one model B \u2208 MOD(O) we have that Qg B \u2282 Q\u2032g B .\nDefinition 4. Qg is an optimal complete s-to-t rewriting of Qs with respect to I, if Qg is a complete s-to-t rewriting ofQs with respect to I, and there exists no queryQ\u2032g such that Q\u2032g is a complete s-to-t rewriting of Qs with respect to I andQ \u2032 g \u2282O Qg.\nWe are ready to present an algorithm for computing an optimal complete s-to-t rewriting\nof a query over the source schema. For the termination and the complexity of this algo-\nAlgorithm 2: FindOptimalComplete(I,Qs)\nInput: OBDM specification I = \u3008O,S ,M\u3009, CQQs over S . Output: query Qg over O.\n1: Compute DQs from Qs (i.e., the instance, possibly with incomplete information, associated\nto the query Qs), and denote it with D.\n2: Chase D w.r.t.M to produce an instance J \u2032. 3: Chase J \u2032 w.r.t. \u00acQ16=\nsat ; if the chase fails, then stop and return the query\n{tup(Qs) | \u22a5(tup(Qs))}; otherwise, let J be the instance produced, and let \u03c8 be the set of equality applied to the variables in D by the chase.\n4: Evaluate Q 06= sat over J ; if the answer is {()} (i.e., J |= Q06= sat ), then stop and return the query\n{tup(Qs) | \u22a5(tup(Qs))}. 5: If J = \u2205 (i.e., no atoms in the instance J), then stop and return the query\n{tup(Qs) | \u22a4(tup(Qs))}; otherwise, let QJ be the boolean conjunctive query associated to the instance J . 6: Let w be the tuple composed by all terms in \u03c8(tup(Qs)) not appearing in J . If such tuple is not empty, then return {\u03c8(tup(Qs)) | QJ (\u03c8(tup(Qs)) \u2227 \u22a4(w)}; otherwise, return {\u03c8(tup(Qs)) | QJ (\u03c8(tup(Qs)))}.\nrithm hold the same considerations done for the termination and the complexity of the CheckComplete algorithm. In particular, FindOptimalComplete(I,Qs) terminates, and it runs in (i) PTIME in the size of Qs; (ii) PTIME in the size of O; (iii) EXPTIME in the size ofM. Whereas, the correctness is established by the next theorem.\nTheorem 2. FindOptimalComplete(I, Qs) returns an optimal complete s-to-t rewriting of Qs w.r.t. I.\nProof (Sketch). When the algorithm returns the query {tup(Qs) | \u22a5(tup(Qs))}, it is easy to see that, regardless of which is the query Qg , if we run the algorithm CheckComplete(I,Qs,Qg) it returns true (also in this case, either the chase will fail, or the\nABox AD,\u03a3 produced will satisfy Q 06= sat ), and hence, by Theorem 1, Qg is a complete s-to-t rewriting of Qs w.r.t. I. It follows that, also {tup(Qs) | \u22a5(tup(Qs))} is a complete s-to-t rewriting, and, by definition of such query, it is an optimal complete s-to-t rewriting of Qs w.r.t. I. When the algorithm returns the query Qg = {\u03c8(tup(Qs)) | QJ(\u03c8(tup(Qs)) \u2227 \u22a4(w)} (or {tup(Qs) | \u22a4(tup(Qs))}, in the case J = \u2205), if we run the algorithm CheckComplete(I,Qs,Qg), it computes the ABoxAD,\u03a3 , where tup(Qs) \u2208 cert(Qg, \u3008O,AD,\u03a3\u3009) holds because Qg corresponds exactly to AD,\u03a3 (before to be freezed) extended with \u22a4(w) for all terms w in \u03c8(tup(Qs)) not appearing in AD,\u03a3 . It follows that, also in this case, CheckComplete(I,Qs,Qg) returns true, implying, from Theorem 1, that Qg is a complete s-to-t rewriting of Qs w.r.t. I.\nWe now prove that the query Qg = {\u03c8(tup(Qs)) | QJ(\u03c8(tup(Qs)) \u2227 \u22a4(w)} (or {tup(Qs) | \u22a4(tup(Qs))}, in the case J = \u2205) is also an optimal complete s-to-t rewriting of Qs w.r.t. I. In particular, suppose that there exist a query Q\u2032g such that Q \u2032 g \u2282O Qg, i.e., Q\u2032g \u2286O Qg , and there is a model B \u2208 sem C(I) and a tuple t such that t \u2208 QBg and t 6\u2208 Q\u2032g B . The fact that t \u2208 QBg implies the existence of a valuation v to all the variables in Qg that makes Qg true in B. Note that, we can extend the valuation v by assigning a new fresh constant to every variable appearing in D and not appearing in Qg . The valuation v obtained is now a valuation for D, and obviously t \u2208 Q v(D) s . Moreover, if we apply the same valuation v to the instance J , it is easy to see that we obtain a ground instance J \u2032 such that (v(D), J \u2032) |= M (we recall that Qg is the CQ associated to the instance J). Obviously, J \u2032 \u2286 B, and hence, (v(D),B) |= M holds because queries in the mapping M are monotone queries. Moreover, we also have that B \u2208 semv(D)(I) (the fact that B |= O holds from the initial supposition). Hence, for the source database v(D) there is a model B \u2208 semv(D)(I) and a tuple t such that t \u2208 Q v(D) s and t 6\u2208 Q\u2032g B , implying that, Q\u2032g is not a complete s-to-t rewriting of Qs w.r.t. I. \u2293\u2294\nIt is easy to prove that the query returned by the algorithm is not only an optimal complete s-to-t rewriting ofQs w.r.t. I, but it is also the unique (up to equivalence) optimal complete s-to-t rewriting of Qs w.r.t. I. Furthermore, the above result implies that an optimal complete s-to-t rewriting of Qs w.r.t. I can always be expressed as a CQ."}, {"heading": "6 Conclusion", "text": "We have introduced the notion of Ontology-based Open Data Publishing, whose idea is\nto use an OBDM specification as a basis for carrying out the task of publishing highquality open data.\nIn this paper, we have focused on the bottom-up approach to ontology-based open\ndata publishing, we have introduced the notion of source-to-target rewriting, and we have developed algorithms for two problems related to complete source-to-target rewrit-\nings, namely the recognition and the finding problem. We plan to continue our work on several directions. In particular, we plan to investigate the notion of sound rewriting un-\nder different semantics. Also, we want to study the top-down approach, especially with\nthe goal of devising techniques for deriving which intensional knowledge to associate to datasets in order to document their content in a suitable way."}], "references": [{"title": "and V", "author": ["S. Abiteboul", "R. Hull"], "venue": "Vianu. Foundations of Databases.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1995}, {"title": "Answering aggregate queries in data exchange", "author": ["F.N. Afrati", "P.G. Kolaitis"], "venue": "pages 129\u2013 138,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "Ontology-based data management for the italian public debt", "author": ["N. Antonioli", "F. Castan\u00f2", "S. Coletta", "S. Grossi", "D. Lembo", "M. Lenzerini", "A. Poggi", "E. Virardi", "P. Castracane"], "venue": "pages 372\u2013 385,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "editors", "author": ["F. Baader", "D. Calvanese", "D. McGuinness", "D. Nardi", "P.F. Patel-Schneider"], "venue": "The Description Logic Handbook: Theory, Implementation and Applications.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2003}, {"title": "M", "author": ["D. Calvanese", "G. De Giacomo", "D. Lembo", "M. Lenzerini", "A. Poggi"], "venue": "Rodr\u0131\u0301guez-Muro, and R. Rosati. Ontologies and databases: The DL-Lite approach. volume 5689, pages 255\u2013356.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Tractable reasoning and efficient query answering in description logics: The DL-Lite family", "author": ["D. Calvanese", "G. De Giacomo", "D. Lembo", "M. Lenzerini", "R. Rosati"], "venue": "39(3):385\u2013429,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2007}, {"title": "Path-based identification constraints in description logics", "author": ["D. Calvanese", "G. De Giacomo", "D. Lembo", "M. Lenzerini", "R. Rosati"], "venue": "pages 231\u2013241,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "View-based query processing: On the relationship between rewriting, answering and losslessness", "author": ["D. Calvanese", "G. De Giacomo", "M. Lenzerini", "M.Y. Vardi"], "venue": "volume 3363, pages 321\u2013 336,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2005}, {"title": "Optimal implementation of conjunctive queries in relational data bases", "author": ["A.K. Chandra", "P.M. Merlin"], "venue": "pages 77\u201390,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1977}, {"title": "Data exchange: Semantics and query answering", "author": ["R. Fagin", "P.G. Kolaitis", "R.J. Miller", "L. Popa"], "venue": "pages 207\u2013224,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2003}, {"title": "Data exchange: Getting to the core", "author": ["R. Fagin", "P.G. Kolaitis", "L. Popa"], "venue": "ACM Trans. Database Syst., 30(1):174\u2013210, mar", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2005}, {"title": "Answering non-monotonic queries in relational data exchange", "author": ["A. Hernich"], "venue": "pages 143\u2013154,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "Closed world data exchange", "author": ["A. Hernich", "L. Libkin", "N. Schweikardt"], "venue": "ACM Trans. Database Syst., 36(2):14:1\u201314:40,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2011}, {"title": "Jr", "author": ["T. Imielinski", "W. Lipski"], "venue": "Incomplete information in relational databases. J. ACM, 31(4):761\u2013791,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1984}, {"title": "Data integration: A theoretical perspective", "author": ["M. Lenzerini"], "venue": "pages 233\u2013246,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2002}, {"title": "Ontology-based data management", "author": ["M. Lenzerini"], "venue": "pages 5\u20136,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Data exchange and schema mappings in open and closed worlds", "author": ["L. Libkin", "C. Sirangelo"], "venue": "pages 139\u2013148,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2008}, {"title": "Linking data to ontologies", "author": ["A. Poggi", "D. Lembo", "D. Calvanese", "G. De Giacomo", "M. Lenzerini", "R. Rosati"], "venue": "X:133\u2013173,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2008}, {"title": "The complexity of relational query languages", "author": ["M.Y. Vardi"], "venue": "pages 137\u2013146,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1982}, {"title": "Database relations with null values", "author": ["C. Zaniolo"], "venue": "In Proc. of PODS, pages 27\u201333,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1982}], "referenceMentions": [{"referenceID": 15, "context": "The recent paradigm of Ontology-basedData Management (OBDM) [16] (used and experimented in practice in the last years, see, e.", "startOffset": 60, "endOffset": 64}, {"referenceID": 2, "context": ", [3]) is an attempt to provide the principles and the techniques for addressing this challenge.", "startOffset": 2, "endOffset": 5}, {"referenceID": 4, "context": ", [5, 18]), or more generally, about data integration [15] assume that the user query is expressed over the global schema, and the goal is to find a rewriting (i.", "startOffset": 2, "endOffset": 9}, {"referenceID": 17, "context": ", [5, 18]), or more generally, about data integration [15] assume that the user query is expressed over the global schema, and the goal is to find a rewriting (i.", "startOffset": 2, "endOffset": 9}, {"referenceID": 14, "context": ", [5, 18]), or more generally, about data integration [15] assume that the user query is expressed over the global schema, and the goal is to find a rewriting (i.", "startOffset": 54, "endOffset": 58}, {"referenceID": 0, "context": "We assume familiarity with classical databases [1], Description Logics [4], and the OBDM paradigm.", "startOffset": 47, "endOffset": 50}, {"referenceID": 3, "context": "We assume familiarity with classical databases [1], Description Logics [4], and the OBDM paradigm.", "startOffset": 71, "endOffset": 74}, {"referenceID": 19, "context": "In particular, each labeled null in a non-ground instance is treated as an unknown value (and hence, an incomplete information), rather than to a non-existent value [20].", "startOffset": 165, "endOffset": 169}, {"referenceID": 9, "context": "We refer to [10] for more details.", "startOffset": 12, "endOffset": 16}, {"referenceID": 4, "context": "Furthermore, given a DL-LiteA,id [5] TBox O and a DL-LiteA,id ABox A we are able to: (i) check whether \u3008O,A\u3009 is satisfiable by computing the answers of a suitable boolean queryQsat (a UCQ with at most one inequality per disjunct) over the ABox A considered as a relational database.", "startOffset": 33, "endOffset": 36}, {"referenceID": 5, "context": "See [6] for more details.", "startOffset": 4, "endOffset": 7}, {"referenceID": 7, "context": "I is a query Qs over S that computes cert(Qg, I, C) for every source database C such that sem(I) 6= \u2205 [8].", "startOffset": 102, "endOffset": 105}], "year": 2017, "abstractText": "Despite the current interest in Open Data publishing, a formal and comprehensive methodology supporting an organization in deciding which data to publish and carrying out precise procedures for publishing high-quality data, is still missing. In this paper we argue that the Ontology-based Data Management paradigm can provide a formal basis for a principled approach to publish highquality, semantically annotated Open Data. We describe two main approaches to using an ontology for this endeavor, and then we present some technical results on one of the approaches, called bottom-up, where the specification of the data to be published is given in terms of the sources, and specific techniques allow deriving suitable annotations for interpreting the published data under the light of", "creator": "LaTeX with hyperref package"}}}