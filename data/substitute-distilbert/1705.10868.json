{"id": "1705.10868", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-May-2017", "title": "Lifelong Multi-Agent Path Finding for Online Pickup and Delivery Tasks", "abstract": "the multi - agent path - finding ( mapf ) problem once recently received a lot of support. however, it does not capture important characteristics of many real - world domains, such as automated warehouses, where agents are constantly placed elsewhere delivering tasks. in this paper, we therefore create a lifelong variety of the bribery problem, targeting the multi - agent pickup and delivery ( mapd ) task. in the mapd problem, agents have to attend to a stream of delivery tasks in live online setting. one scenario has to be addressed to each delivery task. requesting agent has to first move regarding a given pickup location and then to a given payment location while periodically battles with other agents. we present two decoupled rendezvous algorithms, token passing ( tp ) and token passing with task swaps ( tpts ). finally, experiments show that they solve all non - characterized mapd instances, a realistic subclass of mapd instances. experimentally, we swap them against a centralized strawman mapd algorithm without this guarantee in a simulated business system. tp can easily be extended to a fully distributed mapd algorithm and is the best choice when real - time computation is of primary concern since convergence remains useful for mapd instances with hundreds of agents and tasks. tpts requires limited communication among agents and balances well between tp and the centralized mapd algorithm.", "histories": [["v1", "Tue, 30 May 2017 21:08:16 GMT  (829kb,D)", "http://arxiv.org/abs/1705.10868v1", "In AAMAS 2017"]], "COMMENTS": "In AAMAS 2017", "reviews": [], "SUBJECTS": "cs.AI cs.MA cs.RO", "authors": ["hang ma", "jiaoyang li", "t k satish kumar", "sven koenig"], "accepted": false, "id": "1705.10868"}, "pdf": {"name": "1705.10868.pdf", "metadata": {"source": "CRF", "title": "Lifelong Multi-Agent Path Finding for Online Pickup and Delivery Tasks\u2217", "authors": ["Hang Ma", "Jiaoyang Li", "Satish Kumar", "Sven Koenig"], "emails": ["hangma@usc.edu", "lijiaoyang13@mails.tsinghua.edu.cn", "tkskwork@gmail.com", "skoenig@usc.edu"], "sections": [{"heading": null, "text": "Keywords agent coordination; multi-agent path finding; path planning; pickup and delivery tasks; task assignment"}, {"heading": "1. INTRODUCTION", "text": "Many real-world applications of multi-agent systems require agents to operate in known common environments.\n\u2217Our research was supported by NSF under grant numbers 1409987 and 1319966. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the sponsoring organizations, agencies or the U.S. government.\nAppears in: Proc. of the 16th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2017), S. Das, E. Durfee, K. Larson, M. Winikoff (eds.), May 8\u201312, 2017, Sa\u0303o Paulo, Brazil. Copyright c\u00a9 2017, International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved.\nThe agents are constantly engaged with new tasks and have to navigate between locations where the tasks need to be executed. Examples include aircraft-towing vehicles [18], warehouse robots [31], office robots [28], and game characters in video games [21]. In the near future, for instance, aircraft-towing vehicles might navigate autonomously to aircraft and tow them from the runways to their gates so as to reduce pollution, energy consumption, congestion, and human workload. Today, warehouse robots already navigate autonomously to inventory pods and move them from their storage locations to packing stations.\nPast research efforts have concentrated mostly on a \u201cone-shot\u201d version of this problem, called the multi-agent path-finding (MAPF) problem, which has been studied in artificial intelligence, robotics, and operations research. In the MAPF problem, each agent has to move from its current location to its destination while avoiding collisions with other agents in a known common environment. The number of agents is the same as the number of destinations, and the MAPF task ends once all agents reach their destinations. Therefore, the MAPF problem does not capture important characteristics of many real-world domains, such as automated warehouses, where agents are constantly engaged with new tasks.\nIn this paper, we therefore study a \u201clifelong\u201d version of the MAPF problem, called the multi-agent pickup and delivery (MAPD) problem. In the MAPD problem, agents have to attend to a stream of delivery tasks in a known common environment that is modeled as an undirected graph. Tasks can enter the system at any time and are modeled as exogenous events that are characterized by a pickup location and a delivery location each. An agent that is currently not executing any task can be assigned to an unexecuted task. In order to execute the task, the agent has to first move from its current location to the pickup location and then to the delivery location of the task while avoiding collisions with other agents. We first formalize the MAPD problem and then present two decoupled MAPD algorithms, Token Passing (TP) and Token Passing with Task Swaps (TPTS), both of which are based on existing MAPF algorithms. Theoretically, we show that they solve all well-formed MAPD instances [2], a realistic subclass of MAPD instances. Experimentally, we compare them against a centralized strawman MAPD algorithm without this guarantee in a simulated warehouse system. ar X iv :1\n70 5.\n10 86\n8v 1\n[ cs\n.A I]\n3 0\nM ay\n2 01"}, {"heading": "2. BACKGROUND AND RELATED WORK", "text": "The MAPD problem requires both the assignment of agents to tasks in an online and lifelong setting and the planning of collision-free paths. In a lifelong setting, agents have to attend to a stream of tasks. Therefore, agents cannot rest in their destinations after they finish executing tasks. In an online setting, tasks can enter the system at any time. Therefore, assigning agents to tasks and path planning cannot be done in advance but rather need to be done during execution in real-time.\nThe decentralized assignment of agents to more than one task each has been studied before in isolation [26, 33, 17]. The decentralized planning of collision-free paths has also been studied before in isolation, including with reactive approaches [27] and prioritized approaches [6], but these approaches can result in deadlocks. The planning of collisionfree paths has also been studied in the context of the MAPF problem, which is a one-shot (as opposed to a lifelong) version of the MAPD problem. It is NP-hard to solve optimally for minimizing flowtime (the sum of the number of timesteps required by all agents to reach their destinations and stop moving) and NP-hard to approximate within any constant factor less than 4/3 for minimizing makespan (the timestep when all agents have reached their destinations and stop moving) [16]. It can be solved via reductions to Boolean Satisfiability [25], Integer Linear Programming [32], and Answer Set Programming [5]. Optimal dedicated MAPF algorithms include Independence Detection with Operator Decomposition [22], Enhanced Partial Expansion A* [7], Increasing Cost Tree Search [20], M* [29], and ConflictBased Search [19, 1, 3]. Suboptimal dedicated MAPF algorithms include Windowed-Hierarchical Cooperative A* [21, 23], Push and Swap/Rotate [12, 4], TASS [10], BIBOX [24], and MAPP [30]. The MAPF problem has recently been generalized to more clearly resemble real-world settings [8, 14, 9, 15, 13] but these versions are still one-shot."}, {"heading": "3. PROBLEM DEFINITION", "text": "In this section, we first formalize the MAPD problem and then define well-formed MAPD instances."}, {"heading": "3.1 MAPD Problem", "text": "An instance of the MAPD problem consists of m agents A = {a1, a2 . . . am} and an undirected connected graph G = (V,E) whose vertices V correspond to locations and whose edges E correspond to connections between locations that the agents can move along. Let li(t) \u2208 V denote the location of agent ai in discrete timestep t. Agent ai starts in its initial location li(0). In each timestep t, the agent either stays in its current location li(t) or moves to an adjacent location, that is, li(t + 1) = li(t) or (li(t), li(t + 1)) \u2208 E. Agents need to avoid collisions with each other: (1) Two agents cannot be in the same location in the same timestep, that is, for all agents ai and ai\u2032 with ai 6= ai\u2032 and timesteps t: li(t) 6= li\u2032(t); and (2) two agents cannot move along the same edge in opposite directions in the same timestep, that is, for all agents ai and ai\u2032 with ai 6= ai\u2032 and all timesteps t: li(t) 6= li\u2032(t+ 1) or li\u2032(t) 6= li(t+ 1). A path is a sequence of locations with associated timesteps, that is, a mapping from an interval of timesteps to locations. Two paths collide iff the two agents that move along them collide.\nConsider a task set T that contains the set of unexecuted tasks. In each timestep, the system adds all new tasks\nto the task set. Each task \u03c4j \u2208 T is characterized by a pickup location sj \u2208 V and a delivery location gj \u2208 V . An agent is called free iff it is currently not executing any task. Otherwise, it is called occupied. A free agent can be assigned to any task \u03c4j \u2208 T . It then has to move from its current location via the pickup location sj of the task to the delivery location gj of the task. (Any agent that had been assigned to this task previously no longer has this obligation.) When the agent reaches the pickup location, it starts to execute the task and the task is removed from T . When it reaches the delivery location, it finishes executing the task, which implies that it becomes free again and is no longer assigned to the task. Note that any free agent can be assigned to any task in the task set. An agent can be assigned to a different task in the task set while it is still moving to the pickup location of the task it is currently assigned to but it has first to finish executing the task after it has reached its pickup location. These properties model delivery tasks, where agents can often be re-tasked before they have picked up a good but have to deliver it afterward.\nThe objective is to finish executing each task as quickly as possible. Consequently, the effectiveness of a MAPD algorithm is evaluated by the average number of timesteps, called service time, needed to finish executing each task after it was added to the task set. A MAPD algorithm solves a MAPD instance iff the resulting service time of all tasks is bounded."}, {"heading": "3.2 Well-Formed MAPD Instances", "text": "Not every MAPD instance is solvable. Figure 1 shows an example with two free agents a1 and a2 where neither agent can finish executing task \u03c41 with pickup location s1 and delivery location g1. We now provide a sufficient condition that makes MAPD instances solvable, namely being well-formed [2]. The intuition is that agents should only be allowed to rest (that is, stay forever) in locations, called endpoints, where they cannot block other agents. For example, office workspaces are typically placed in office environments so as not to block routes. The set Vep of endpoints of a MAPD instance contains all initial locations of agents, all pickup and delivery locations of tasks, and perhaps additional designated parking locations. Let Vtsk denote the set of all possible pickup and delivery locations of tasks, called the task endpoints. The set Vep \\ Vtsk is called the set of non-task endpoints.\nDefinition 1. A MAPD instance is well-formed iff a) the number of tasks is finite, b) there are no fewer non-task endpoints than the number of agents, and c) for any two endpoints, there exists a path between them that traverses no other endpoints.\nWell-formed MAPD instances (with at least one task) have at least m+ 1 endpoints. Figure 2 shows three MAPD instances. The MAPD instance on the left is well-formed. The MAPD instance in the center is not well-formed because there are two agents but only one non-task endpoint. The\nMAPD instance on the right is not well-formed because, for example, all paths between endpoints e2 and e3 traverse endpoint e1. We design two decoupled MAPD algorithms in the following that both solve all well-formed MAPD instances (even though they might not execute all tasks in case the number of tasks is infinite)."}, {"heading": "4. DECOUPLED MAPD ALGORITHMS", "text": "In this section, we present first a simple decoupled MAPD algorithm, called Token Passing (TP), and then an improved version, called Token Passing with Task Swaps (TPTS), that is more effective. Decoupled MAPD algorithms are those where each agent assigns itself to tasks and computes its own collision-free paths given some global information."}, {"heading": "4.1 Token Passing (TP)", "text": "Token Passing (TP) is based on an idea similar to Cooperative A* [21], where agents plan their paths one after the other. Its task set contains all tasks that have no agents assigned to them. We describe a version of TP that uses token passing and can thus easily be extended to a fully distributed MAPD algorithm. The token is a synchronized shared block of memory that contains the current paths of all agents, task set, and agent assignments. All MAPD algorithms in this paper, including TP, always assume that an agent rests (that is, stays forever) in the last location of its path in the token when it reaches the end of it. Token passing has previously been used to develop COBRA [2], which is a MAPF-like algorithm that does not take into account that pickup or delivery locations of tasks can be occupied by agents not executing them and can thus result in deadlocks.\nAlgorithm 1 shows the pseudo-code of TP, where loc(ai) denotes the current location of agent ai. Agent ai finds all paths via A* searches in a state space whose states are pairs of locations and timesteps. A directed edge exists from state (l, t) to state (l\u2032, t + 1) iff l = l\u2032 or (l, l\u2032) \u2208 E. State (l, t) is removed from the state space iff ai being in location l at timestep t results in it colliding with other agents that move along their paths in the token. Similarly, the edge from state (l, t) to state (l\u2032, t + 1) is removed from the state space iff ai moving from location l to location l\n\u2032 at timestep t results in it colliding with other agents that move along their paths in the token. Since cost-minimal paths need to be found only to endpoints, the path costs from all locations to all endpoints are computed in a preprocessing phase and then used as h-values for all A* searches. TP works as follows: The system initializes the token with the trivial paths where all agents rest in their initial locations [Line 2]. In each\nAlgorithm 1: Token Passing (TP)\n1 /* system executes now */; 2 Initialize token with the (trivial) path [loc(ai)] for each agent ai; 3 while true do 4 Add all new tasks, if any, to the task set T ; 5 while agent ai exists that requests token do 6 /* system sends token to ai - ai executes now */; 7 T \u2032 \u2190 {\u03c4j \u2208 T |no other path in token ends in sj or gj}; 8 if T \u2032 6= \u2205 then 9 \u03c4 \u2190 argmin\u03c4j\u2208T \u2032 h(loc(ai), sj); 10 Assign ai to \u03c4 ; 11 Remove \u03c4 from T ; 12 Update ai\u2019s path in token with Path1(ai, \u03c4 , token); 13 else if no task \u03c4j \u2208 T exists with gj = loc(ai) then 14 Update ai\u2019s path in token with the path [loc(ai)];\n15 else 16 Update ai\u2019s path in token with Path2(ai, token);\n17 /* ai returns token to system - system executes now */;\n18 All agents move along their paths in token for one timestep; 19 /* system advances to the next timestep */;\ntimestep, the system adds all new tasks, if any, to the task set [Line 4]. Any agent that has reached the end of its path in the token requests the token once per timestep. (It turns out that one can easily drop the condition and let any free agent request the token once per timestep for both decoupled MAPD algorithms in this paper.) The system then sends the token to each agent that requests it, one after the other [Lines 5-6]. The agent with the token chooses a task from the task set such that no path of other agents in the token ends in the pickup or delivery location of the task [Line 7].\n\u2022 If there is at least one such task, then the agent assigns itself to the one with the smallest h-value from its current location to the pickup location of the task and removes this task from the task set [Lines 9-11]. The agent then calls function Path1 to update its path in the token with a cost-minimal path that a) moves from its current location via the pickup location of the task to the delivery location of the task and b) does not collide with the paths of other agents stored in the token [Line 12].\n\u2022 If there is no such task, then the agent does not assign itself to a task in the current timestep. If the agent is not in the delivery location of a task in the task set, then it updates its path in the token with the trivial path where it rests in its current location [Line 14]. Otherwise, to avoid deadlocks, it calls function Path2 to update its path in the token with a costminimal path that a) moves from its current location to an endpoint such that the delivery locations of all tasks in the task set are different from the chosen endpoint and no path of other agents in the token ends in the chosen endpoint and b) does not collide with the paths of other agents stored in the token [Line 16].\nFinally, the agent returns the token to the system and moves along its path in the token [Lines 17-18].\nWe now prove that the agent is always able to find a path because it finds a path only when it is at an endpoint and thus has to find only a path from an endpoint to an endpoint.\nProperty 1. Function Path1 returns a path successfully for well-formed MAPD instances.\nProof. We construct a path from the current location loc(ai) of agent ai (which is an endpoint) via the pickup location sj of task \u03c4j to the delivery location gj of task \u03c4j that does not collide with the paths of other agents stored in the token. Due to Definition 1, there exists a path from loc(ai) via sj to gj that traverses no other endpoints. All paths stored in token end in endpoints that are different from loc(ai), sj , and gj . Thus, this path does not collide with the paths of the other agents if ai moves along it after all other agents have moved along their paths.\nProperty 2. Function Path2 returns a path successfully for well-formed MAPD instances.\nProof. Due to Definition 1, there exist at least m non-task endpoints and thus at least one non-task endpoint such that no path of agents other than agent ai in the token ends in the non-task endpoint. Of course, the delivery locations of all tasks in the task set are different from the non-task endpoint as well. We construct a path from the current location loc(ai) of agent ai (which is an endpoint) to the chosen endpoint that does not collide with the paths of other agents stored in the token. Due to Definition 1, there exists a path from loc(ai) to the chosen endpoint that traverses no other endpoints. All paths stored in token end in endpoints that are different from loc(ai) and the chosen endpoint. Thus, this path does not collide with the paths of the other agents if ai moves along it after all other agents have moved along their paths.\nTheorem 3. All well-formed MAPD instances are solvable, and TP solves them.\nProof. We show that each task is eventually assigned some agent and executed by it. Each agent requests the token after a bounded number of timesteps, and no agent rests in the delivery location of a task in the task set due to Line 16. Thus, the condition on Line 8 becomes eventually satisfied and some agent assigns itself to some task on Line 10. The agent is then able to execute it due to Properties 1 and 2."}, {"heading": "4.2 Token Passing with Task Swaps (TPTS)", "text": "TP is simple but can be made more effective. Token Passing with Task Swaps (TPTS) is similar to TP except that its task set now contains all unexecuted tasks, rather than only all tasks that have no agents assigned. This means that an agent with the token can assign itself not only to a task that has no agent assigned but also to a task that is already assigned another agent as long as that agent is still moving to the pickup location of the task. This might be beneficial when the former agent can move to the pickup location of the task in fewer timesteps than the latter agent. The latter agent is then no longer assigned to the task and no longer needs to execute it. The former agent therefore sends the token to the latter agent so that the latter agent can try to assign itself to a new task.\nAlgorithm 2 shows the pseudo-code of TPTS. It uses the same main loop [Lines 3-10] and the same functions Path1 and Path2 as TP. Agent ai with the token executes function GetTask [Line 7], where it tries to assign itself to a task in the task set T and find a path to an endpoint. The call of function GetTask returns success (true) if agent ai finds a path to an endpoint and failure (false) otherwise.\nAlgorithm 2: Token Passing with Task Swaps (TPTS)\n1 /* system executes now */; 2 Initialize token with the (trivial) path [loc(ai)] for each agent ai; 3 while true do 4 Add all new tasks, if any, to the task set T ; 5 while agent ai exists that requests token do 6 /* system sends token to ai - ai executes now */; 7 GetTask(ai, token); 8 /* ai returns token to system - system executes now */;\n9 All agents move along their paths in token for one timestep and remove tasks from T when they start to execute them;\n10 /* system advances to the next timestep */;\n11 Function GetTask(ai, token) 12 T \u2032 \u2190 {\u03c4j \u2208 T |no other path in token ends in sj or gj}; 13 while T \u2032 6= \u2205 do 14 \u03c4 \u2190 argmin\u03c4j\u2208T \u2032 h(loc(ai), sj); 15 Remove \u03c4 from T \u2032; 16 if no agent is assigned to \u03c4 then 17 Assign ai to \u03c4 ; 18 Update ai\u2019s path in token with Path1(ai, \u03c4 , token); 19 return true;\n20 else 21 Remember token, task set, and agent assignments; 22 ai\u2032 \u2190 agent that is assigned to \u03c4 ; 23 Unassign ai\u2032 from \u03c4 and assign ai to \u03c4 ; 24 Remove ai\u2032 \u2019s path from token; 25 Path1(ai, \u03c4 , token); 26 Compare when ai reaches sj on its path in token to when ai\u2032 reaches sj on its path in token\u2019; 27 if ai reaches sj earlier than ai\u2032 then 28 /* ai sends token to ai\u2032 - ai\u2032 executes now */; 29 success \u2190 GetTask(a\u2032i, token); 30 /* ai\u2032 returns token to ai - ai executes now */; 31 if success then 32 return true;\n33 Restore token, task set, and agent assignments;\n34 if loc(ai) is not an endpoint then 35 Update ai\u2019s path in token with Path2(ai, token); 36 if path was found then 37 return true;\n38 else 39 if no task \u03c4j \u2208 T exists with gj = loc(ai) then 40 Update ai\u2019s path in token with the path [loc(ai)];\n41 else 42 Update ai\u2019s path in token with Path2(ai, token);\n43 return true;\n44 return false;\nWhen executing function GetTask, agent ai considers all tasks \u03c4 from the task set such that no path of other agents in the token ends in the pickup or delivery location of the task [Line 12], one after the other in order of increasing hvalues from its current location to the pickup locations of the tasks [Lines 13-15]. If no agent is assigned to the task, then (as in TP) agent ai assigns itself to the task, updates its path in the token with function Path1 and returns success [Lines 17-19]. Otherwise, agent ai unassigns the agent ai\u2032 assigned to the task and assigns itself to the task [Line 23]. It removes the path of agent ai\u2032 from the token and updates its own path in the token with function Path1 [Lines 24-25]. If agent ai reaches the pickup location of the task with fewer timesteps than agent ai\u2032 , then it sends the token to agent ai\u2032 , which executes function GetTask to try to assign itself to a new task and eventually returns the token to agent ai [Lines 28-30]. If agent ai\u2032 returns success, then agent ai returns success as well [Lines 31-32]. In all other cases, agent ai reverses all changes to the paths in the token, task set, and\nagent assignments and then considers the next task \u03c4 [Lines 33].\nOnce agent ai has considered all tasks \u03c4 unsuccessfully, then it does not assign itself to a task in the current timestep. If it is not in an endpoint (which can happen only during a call of Function GetTask on Line 29), then it updates its path in the token with function Path2 to move to an endpoint [Line 35]. The call can fail since agent ai is not at an endpoint. Agent ai returns success or failure depending on whether it was able to find a path [Lines 37 and 44]. Otherwise, (as in TP) if the agent is not in the delivery location of a task in the task set, then it updates its path in the token with the trivial path where it rests in its current location [Line 40]. Otherwise, to avoid deadlocks, it updates its path in the token with Function Path2 [Line 42]. In both cases, it returns success [Line 43].\nFinally, the agent returns the token to the system and moves along its path in the token, removing the task that it is assigned to (if any) from the task set once it reaches the pickup location of the task (and thus starts to execute it) [Lines 8-9].\nProperty 4. Function GetTask returns successfully for well-formed MAPD instances when called on Line 7.\nProof. Function GetTask returns in finite time (and the number of times an agent can unassign another agent from any task is bounded during its execution) because a) the number of tasks in the task set is finite; b) an agent can unassign another agent from a task only if it reaches the pickup location of the task with fewer timesteps than the other agent; c) a task that has some agent assigned always continues to have some agent assigned until it has been executed; and d) the functions Path1 and Path2 return in finite time. We show that an agent that executes function GetTask on Line 7 finds a path to an endpoint. The agent is always able to find paths with functions Path1 and Path 2 on all lines but Line 35 because it is then at an endpoint and thus has to find a path from an endpoint to an endpoint. The proofs are similar to those of Properties 1 and 2. However, the agent is not guaranteed to find a path with function Path2 on Line 35 because it is then not at an endpoint and thus has to find a path from a non-endpoint to an endpoint. Since the agent is at an endpoint during the call of function GetTask on Line 7, it does not execute Line 35, finds a path, and returns success.\nTheorem 5. TPTS solves all well-formed MAPD instances.\nProof. The proof is similar to the one of Theorem 3 but uses Property 4.\nTPTS is often more effective than TP but Figure 3 shows that this is not guaranteed. The figure shows a MAPD instance with two agents a1 and a2 and two tasks \u03c41 and \u03c42. The pickup location is the same as the delivery location for each task. Assume that both a1 and a2 request the token and the system sends it to a1 first. a1 assigns itself to \u03c41. Figure 3 (left) shows the path of a1. The system then sends the token to a2 next. In TP, a2 assigns itself to \u03c42. Figure 3 (center) shows the paths of a1 and a2. The resulting service time is two. In TPTS, however, a2 assigns itself to \u03c41 because it can reach the pickup location of \u03c41 with fewer timesteps than a1. In return, a1 assigns itself\nto \u03c42. Figure 3 (right) shows the paths of a1 and a2. The service time is three (the average of five and one)."}, {"heading": "5. CENTRALIZED ALGORITHM", "text": "In this section, we develop a centralized strawman MAPD algorithm, CENTRAL, to evaluate how effective our decoupled MAPD algorithms are. We want CENTRAL to be reasonably efficient and effective but do not require that it is optimally effective or even solves all well-formed MAPD instances. The agents of a centralized MAPD algorithm can communicate more than the ones of TPTS, and the ones of TPTS communicate more than the ones of TP. Thus, we expect the MAPD algorithms to be in increasing order of effectiveness: TP, TPTS, and CENTRAL. For the same reason, we expect the MAPD algorithms to be in increasing order of efficiency: CENTRAL, TPTS, and TP.\nIn each timestep, CENTRAL first assigns endpoints to all agents and then solves the resulting MAPF instance to plan paths for all agents from their current locations to their assigned endpoints simultaneously. Finally, all agents move along their paths for one timestep and the procedure repeats. Agent Assignment First, CENTRAL considers each agent, one after the other, that rests at the pickup location of an unexecuted task. If the delivery location of the task is currently not assigned to other agents, CENTRAL assigns the agent to the corresponding unexecuted task (if it is not assigned to the task already) and assigns the delivery location of the task to the agent. The agent then starts to execute the task and thus becomes occupied. Then, CENTRAL assigns each free agent either the pickup location of an unexecuted task or some other endpoint as parking location. To make the resulting MAPF problem solvable, the endpoints assigned to all agents must be pairwise different. Agents are assigned pickup locations of unexecuted tasks in order to execute the tasks afterward. Thus, when CENTRAL assigns pickup locations of unexecuted tasks to agents, we want the delivery locations of these tasks to be different from the endpoints assigned to all agents (except for their own pickup locations) and from each other. CENTRAL achieves these constraints as follows:\nFirst, CENTRAL greedily constructs a set of possible endpoints X for the free agents as follows: CENTRAL greedily constructs a subset T \u2032 of unexecuted tasks, starting with the empty set, by checking for each unexecuted task, one after the other, whether its pickup and delivery locations are different from the delivery locations of all executed tasks\nand the pickup and delivery locations of all unexecuted tasks already added to T \u2032 and, if so, adds it to T \u2032. CENTRAL then sets X to the pickup locations of all tasks in T \u2032. If the number of free agents is larger than |X|, then CENTRAL needs to add endpoints to X as parking locations for some free agents. Since it is not known a priori which free agents these parking locations will be assigned to, there should be one good parking location available for each free agent, which is possible due to Definition 1. CENTRAL thus greedily determines a good parking location for each free agent ai, one after the other, as the endpoint e that minimizes the cost c(ai, e) (\u201cis closest to the agent\u201d) among all endpoints that are different from the delivery locations of all executed tasks, the pickup and delivery locations of all tasks in T \u2032, and the parking locations already determined, where c(ai, e) is the cost of a cost-minimal path that moves from the current location of free agent ai to endpoint e. It then adds this endpoint to X.\nSecond, CENTRAL assigns each free agent an endpoint in X to satisfy all constraints. It uses the Hungarian Method [11] for this purpose with the modified costs c\u2032(ai, e) for each pair of free agent ai and endpoint e, where c is the number of free agents, C is a sufficiently large constant (for example, the maximum over all costs c(ai, e) plus one), and c\u2032(ai, e) = c \u00b7C \u00b7 c(ai, e) if e is a pickup location of a task in T \u2032 and c\u2032(ai, e) = c \u00b7 C2 + c(ai, e) if e is a parking location. The modified costs have two desirable properties: a) The modified cost of assigning a pickup location to a free agent is always smaller than the modified cost of assigning a parking location to the same agent. Therefore, assigning pickup locations is more important than assigning rest locations. b) Assigning a closer pickup location to a single free agent that is assigned a pickup location reduces the total modified cost more than assigning closer parking locations to all free agents that are assigned rest locations. Therefore, assigning closer pickup locations is more important than assigning closer parking locations. Path Planning CENTRAL uses the optimally effective MAPF algorithm Conflict-Based Search [19] to plan collisionfree paths for all agents from their current locations to their assigned endpoints simultaneously. These paths minimize the sum of the number of timesteps required by all agents to reach their assigned endpoints and stop moving. We noticed that CENTRAL becomes significantly more efficient if it plans paths in two stages: First, it plans paths for all agents that become occupied in the current timestep to their assigned endpoints (using the approach described above but treating the most recently calculated paths of all other agents as spatio-temporal obstacles. Then, it plans paths for all free agents to their assigned endpoints (again using the approach described above but treating the most recently calculated paths of all other agents as spatio-temporal obstacles). In general, two smaller MAPF instances can be solved much faster than their union due to the NP-hardness of the problem. Also, CENTRAL can then determine a more informed cost c(ai, e) as the cost of a cost-minimal path that a) moves from the current location of agent ai to endpoint e and b) does not collide with the paths of the occupied agents (as described for TP).\nProperty 6. Path planning for all agents that became occupied in the current timestep returns paths successfully for well-formed MAPD instances.\nProof. We construct paths for all agents that became occupied in the current timestep from their current locations to their assigned endpoints that do not collide with the most recently calculated paths of all other agents: Assume that all other agents move along their most recently calculated paths. When all of them have reached the ends of their paths, move all agents that became occupied one after the other to their assigned endpoints, which is possible due to Definition 1 since their current locations are endpoints and their assigned endpoints are different from the endpoints that all other agents now occupy.\nProperty 7. Path planning for all free agents returns paths successfully for well-formed MAPD instances.\nProof. We construct paths for all free agents from their current locations to their assigned endpoints that do not collide with the most recently calculated paths of all other agents: Assume that all agents move along their most recently calculated paths. When all of them have reached the ends of their paths, move all free agents one after the other to their assigned endpoints, which is possible due to Definition 1 since the locations that they now occupy are endpoints. Directly before an agent moves to its assigned endpoint, check whether this endpoint is blocked by another agent. If so, move this other agent to an unoccupied endpoint first. Such an endpoint exists since there are at least m+ 1 endpoints for m agents due to Definition 1."}, {"heading": "6. EXPERIMENTAL EVALUATION", "text": "In this section, we describe our experimental results on a 2.50 GHz Intel Core i5-2450M laptop with 6 GB RAM. We ran TP, TPTS, and CENTRAL in the small simulated warehouse environment shown in Figure 4. We generated a sequence of 500 delivery tasks by randomly choosing their pickup and delivery locations from all task endpoints. The initial locations of the agents are the only non-task endpoints. We used 6 different task frequencies (numbers of tasks that are added (in order) from the sequence to the task set in each timestep): 0.2 (one task every 5 timesteps), 0.5, 1, 2, 5, and 10. For each task frequency, we used 5 different numbers of agents: 10, 20, 30, 40, and 50. Table 1 reports the makespans, the service times, the runtimes per timestep (in ms), the ratios of the service times of TPTS and TP, and the ratios of the service times of CENTRAL\nand TP. The measures for a task frequency of 10 tasks per timestep are reasonably representative of the case where all tasks are added in the beginning of the operation since the tasks are added over the first 50 timesteps only. Makespans and Service Times The MAPD algorithms in increasing order of their makespans and service times tend to be: CENTRAL, TPTS, and TP. For example, the service time of TPTS (and CENTRAL) is up to about 42 percent (and 48 percent, respectively) smaller than the one of TP for some experimental runs. The makespans tend to be large for low task frequencies and small for high task frequencies because the number of tasks is constant and thus more time steps are needed to add all tasks for low task frequencies. On the other hand, the service times tend to be small for low task frequencies and high for high task frequencies because the agents tend to be able to attend to tasks fast if the number of tasks in the system is small. The makespans and service times tend to be large for small numbers of agents and small for large numbers of agents because the agents tend to be able to attend to tasks fast if the number of agents is large (although congestion increases). The makespans and service times for a task frequency of 0.2 tasks per timestep are about the same for all numbers of agents because 10 agents already attend to all tasks as fast as the MAPD algorithms allow. The makespans are similar for all MAPD algorithms and all numbers of agents for the task frequency of 0.2 tasks per timestep because 10 agents already execute tasks faster than they are added. The makespans then depend largely on how fast the agents execute the last few tasks. On the other hand, the makespans of MAPD algorithms increase substantially when tasks pile up because the agents execute them more slowly than they are added. This allows us to estimate the smallest number of agents needed for a lifelong operation as a function of the task frequency and MAPD algorithm. For example, the makespan of TPTS increases substantially when the number of agents are reduced from 20 to 10 for a task frequency of 1 task per timestep. Thus, one needs between about 10 and 20 agents for a lifelong operation with TPTS.\nRuntimes per Timestep The MAPF algorithms in increasing order of their runtimes per timestep tend to be: TP, TPTS, and CENTRAL. For example, the runtime of TPTS (and CENTRAL) is two orders of magnitude larger than the runtime of TP (and TPTS, respectively) for some experimental runs. The runtimes of TP are less than 10 milliseconds, the runtimes of TPTS are less than 200 milliseconds, and the runtimes of CENTRAL are less than 4,000 milliseconds in all experimental runs. We consider runtimes below one second to allow for real-time lifelong operation. The runtimes tend not to be correlated with the task frequencies. They tend to be small for small numbers of agents and large for large numbers of agents because all agents need to perform computations, which are not run in parallel in our experiments. Number of Executed Tasks The service times vary over time since only very few tasks are available in the first and last time steps. The steady state is in between these two extremes. Figure 5 therefore visualizes the number of tasks added and executed by 50 agents during the 100-timestep window [t \u2212 99, t] for all MAPD algorithms as a function of the timestep t. For low task frequencies, the numbers of tasks added match the numbers of tasks executed closely for all MAPD algorithms. Differences between them arise for higher task frequencies. For example, for the task frequency of 2 tasks per timestep, the number of tasks executed by CENTRAL increases faster and reaches a higher level than the numbers of tasks executed by TP and TPTS. The 100- timestep window [150, 249] at time step t = 249 is a close approximation of the steady state since all tasks are added at a steady rate during the first 250 timesteps. CENTRAL executes more tasks during this 100-timestep window than TP and TPTS and thus has a smaller service time. However, the numbers of tasks executed are smaller for all MAPD algorithms than the number of tasks added, and tasks thus pile up for all of them in the steady state. Scalability To evaluate how the MAPD algorithms scale in the size of the environment, we ran TP, TPTS, and CENTRAL in the large simulated warehouse environment shown in Figure 6. We generated a sequence of 1,000 delivery tasks by randomly choosing their pickup and delivery locations from all task endpoints. The initial locations of the agents are the only non-task endpoints. We used a task frequency of 50 tasks per timestep and 100, 200, 300, 400, and 500 agents. TPTS and CENTRAL did not allow for real-time lifelong operation for large numbers of agents. Figure 7 therefore reports, for TP only, the service times and the runtimes per timestep (in ms) in the table as well as the numbers of tasks added and executed during a 100-timestep window for different numbers of agents in the charts. The runtime of TP is smaller than 500 milliseconds for 200 agents, allowing for real-time lifelong operation."}, {"heading": "7. CONCLUSIONS", "text": "In this paper, we studied a lifelong version of the multiagent path finding (MAPF) problem, called the multi-agent pickup and delivery (MAPD) problem, to capture important characteristics of many real-world domains. In the MAPD problem, agents have to attend to a stream of delivery tasks in an online setting by first moving to the pickup locations of the tasks and then to the delivery locations of the tasks while avoiding collisions with other agents. We presented two decoupled MAPD algorithms, Token Passing (TP) and\nToken Passing with Task Swaps (TPTS). Theoretically, we showed that both MAPD algorithms solve all wellformed MAPD instances. Experimentally, we compared them against the centralized strawman MAPD algorithm CENTRAL without this guarantee in a simulated warehouse system. The MAPD algorithms in increasing order of their makespans and service times tend to be: CENTRAL, TPTS, and TP. The MAPF algorithms in increasing order of their runtimes per timestep tend to be: TP, TPTS, and CENTRAL. TP can easily be extended to a fully distributed MAPD algorithm and is the best choice when real-time computation is of primary concern since it remains efficient for MAPD instances with hundreds of agents and tasks. TPTS requires limited communication among agents and balances well between TP and CENTRAL."}], "references": [{"title": "ICBS: Improved conflict-based search algorithm for multi-agent pathfinding", "author": ["E. Boyarski", "A. Felner", "R. Stern", "G. Sharon", "D. Tolpin", "O. Betzalel", "S.E. Shimony"], "venue": " agents 100 200 300 400 500 service time 463.25 330.19 301.97 289.08 284.24 runtime 90.83 538.22 1,854.44 3,881.11 6,121.06 0  100  200  300  400  500  600  700  800  900  1000 0 100 200 300 400 500 600 700 800 900 1000 1100  100 200 300 400 500 tasks added Figure 7: The figure shows the experimental results for TP in the large simulated warehouse environment. In International Joint Conference on Artificial Intelligence, pages 740\u2013746", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "Complete decentralized method for on-line multi-robot trajectory planning in well-formed infrastructures", "author": ["M. C\u00e1p", "J. Vok\u0155\u0131nek", "A. Kleiner"], "venue": "International Conference on Automated Planning and Scheduling, pages 324\u2013332", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Improved solvers for bounded-suboptimal multi-agent path finding", "author": ["L. Cohen", "T. Uras", "T.K.S. Kumar", "H. Xu", "N. Ayanian", "S. Koenig"], "venue": "International Joint Conference on Artificial Intelligence, pages 3067\u20133074", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}, {"title": "Push and rotate: Cooperative multi-agent path planning", "author": ["B. de Wilde", "A.W. ter Mors", "C. Witteveen"], "venue": "In International Conference on Autonomous Agents and Multi-Agent Systems,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "A general formal framework for pathfinding problems with multiple agents", "author": ["E. Erdem", "D.G. Kisa", "U. Oztok", "P. Schueller"], "venue": "AAAI Conference on Artificial Intelligence, pages 290\u2013296", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "On multiple moving objects", "author": ["M.A. Erdmann", "T. Lozano-P\u00e9rez"], "venue": "Algorithmica, 2:477\u2013521", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1987}, {"title": "Enhanced Partial Expansion A", "author": ["M. Goldenberg", "A. Felner", "R. Stern", "G. Sharon", "N.R. Sturtevant", "R.C. Holte", "J. Schaeffer"], "venue": "Journal of Artificial Intelligence Research, 50:141\u2013187", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Multi-agent path finding with kinematic constraints", "author": ["W. H\u00f6nig", "T.K.S. Kumar", "L. Cohen", "H. Ma", "H. Xu", "N. Ayanian", "S. Koenig"], "venue": "International Conference on Automated Planning and Scheduling, pages 477\u2013485", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2016}, {"title": "Formation change for robot groups in occluded environments", "author": ["W. H\u00f6nig", "T.K.S. Kumar", "H. Ma", "N. Ayanian", "S. Koenig"], "venue": "IEEE/RSJ International Conference on Intelligent Robots and Systems, pages 4836\u20134842", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2016}, {"title": "A polynomial-time algorithm for non-optimal multi-agent pathfinding", "author": ["M. Khorshid", "R. Holte", "N. Sturtevant"], "venue": "Annual Symposium on Combinatorial Search", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "The Hungarian method for the assignment problem", "author": ["H.W. Kuhn"], "venue": "Naval Research Logistics Quarterly, 2:83\u201397", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1955}, {"title": "Push and Swap: Fast cooperative path-finding with completeness guarantees", "author": ["R. Luna", "K.E. Bekris"], "venue": "International Joint Conference on Artificial Intelligence, pages 294\u2013300", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "Optimal target assignment and path finding for teams of agents", "author": ["H. Ma", "S. Koenig"], "venue": "International Conference on Autonomous Agents and Multiagent Systems, pages 1144\u20131152", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2016}, {"title": "Overview: Generalizations of multi-agent path finding to real-world scenarios", "author": ["H. Ma", "S. Koenig", "N. Ayanian", "L. Cohen", "W. H\u00f6nig", "T.K.S. Kumar", "T. Uras", "H. Xu", "C. Tovey", "G. Sharon"], "venue": "IJCAI-16 Workshop on Multi-Agent Path Finding", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "Multi-agent path finding with delay probabilities", "author": ["H. Ma", "T.K.S. Kumar", "S. Koenig"], "venue": "AAAI Conference on Artificial Intelligence", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2017}, {"title": "Multi-agent path finding with payload transfers and the package-exchange robot-routing problem", "author": ["H. Ma", "C. Tovey", "G. Sharon", "T.K.S. Kumar", "S. Koenig"], "venue": "AAAI Conference on Artificial Intelligence, pages 3166\u20133173", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2016}, {"title": "SCRAM: Scalable collision-avoiding role assignment with minimal-makespan for formational positioning", "author": ["P. MacAlpine", "E. Price", "P. Stone"], "venue": "AAAI Conference on Artificial Intelligence, pages 2096\u20132102", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Planning", "author": ["R. Morris", "C. Pasareanu", "K. Luckow", "W. Malik", "H. Ma", "S. Kumar", "S. Koenig"], "venue": "scheduling and monitoring for airport surface operations. In AAAI-16 Workshop on Planning for Hybrid Systems", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2016}, {"title": "Conflict-based search for optimal multi-agent pathfinding", "author": ["G. Sharon", "R. Stern", "A. Felner", "N.R. Sturtevant"], "venue": "Artificial Intelligence, 219:40\u201366", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "The increasing cost tree search for optimal multi-agent pathfinding", "author": ["G. Sharon", "R. Stern", "M. Goldenberg", "A. Felner"], "venue": "Artificial Intelligence, 195:470\u2013495", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2013}, {"title": "Cooperative pathfinding", "author": ["D. Silver"], "venue": "Artificial Intelligence and Interactive Digital Entertainment, pages 117\u2013122", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2005}, {"title": "Complete algorithms for cooperative pathfinding problems", "author": ["T.S. Standley", "R.E. Korf"], "venue": "International Joint Conference on Artificial Intelligence, pages 668\u2013673", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "Improving collaborative pathfinding using map abstraction", "author": ["N.R. Sturtevant", "M. Buro"], "venue": "Artificial Intelligence and Interactive Digital Entertainment, pages 80\u201385", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2006}, {"title": "A novel approach to path planning for multiple robots in bi-connected graphs", "author": ["P. Surynek"], "venue": "IEEE International Conference on Robotics and Automation, pages 3613\u20133619", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2009}, {"title": "Reduced time-expansion graphs and goal decomposition for solving cooperative path finding sub-optimally", "author": ["P. Surynek"], "venue": "International Joint Conference on Artificial Intelligence, pages 1916\u20131922", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "The generation of bidding rules for auction-based robot coordination", "author": ["C. Tovey", "M. Lagoudakis", "S. Jain", "S. Koenig"], "venue": "F. S. L. Parker and A. Schultz, editors, Multi-Robot Systems. From Swarms to Intelligent Automata, volume 3, chapter 1, pages 3\u201314. Springer", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2005}, {"title": "Reciprocal collision avoidance with acceleration-velocity obstacles", "author": ["J.P. van den Berg", "J. Snape", "S.J. Guy", "D. Manocha"], "venue": "In IEEE International Conference on Robotics and Automation,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2011}, {"title": "CoBots: Robust symbiotic autonomous mobile service robots", "author": ["M. Veloso", "J. Biswas", "B. Coltin", "S. Rosenthal"], "venue": "International Joint Conference on Artificial Intelligence, pages 4423\u20134429", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2015}, {"title": "Subdimensional Expansion: A Framework for Computationally Tractable Multirobot Path Planning", "author": ["G. Wagner"], "venue": "PhD thesis, Carnegie Mellon University", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2015}, {"title": "MAPP: a scalable multi-agent path planning algorithm with tractability and completeness guarantees", "author": ["K. Wang", "A. Botea"], "venue": "Journal of Artificial Intelligence Research, 42:55\u201390", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2011}, {"title": "R", "author": ["P.R. Wurman"], "venue": "D\u2019Andrea, and M. Mountz. Coordinating hundreds of cooperative, autonomous vehicles in warehouses. AI Magazine, 29(1):9\u201320", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2008}, {"title": "Planning optimal paths for multiple robots on graphs", "author": ["J. Yu", "S.M. LaValle"], "venue": "IEEE International Conference on Robotics and Automation, pages 3612\u20133617", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2013}, {"title": "K-swaps: Cooperative negotiation for solving task-allocation problems", "author": ["X. Zheng", "S. Koenig"], "venue": "International Joint Conference on Artifical Intelligence, pages 373\u2013378", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 17, "context": "Examples include aircraft-towing vehicles [18], warehouse robots [31], office robots [28], and game characters in video games [21].", "startOffset": 42, "endOffset": 46}, {"referenceID": 30, "context": "Examples include aircraft-towing vehicles [18], warehouse robots [31], office robots [28], and game characters in video games [21].", "startOffset": 65, "endOffset": 69}, {"referenceID": 27, "context": "Examples include aircraft-towing vehicles [18], warehouse robots [31], office robots [28], and game characters in video games [21].", "startOffset": 85, "endOffset": 89}, {"referenceID": 20, "context": "Examples include aircraft-towing vehicles [18], warehouse robots [31], office robots [28], and game characters in video games [21].", "startOffset": 126, "endOffset": 130}, {"referenceID": 1, "context": "Theoretically, we show that they solve all well-formed MAPD instances [2], a realistic subclass of MAPD instances.", "startOffset": 70, "endOffset": 73}, {"referenceID": 25, "context": "The decentralized assignment of agents to more than one task each has been studied before in isolation [26, 33, 17].", "startOffset": 103, "endOffset": 115}, {"referenceID": 32, "context": "The decentralized assignment of agents to more than one task each has been studied before in isolation [26, 33, 17].", "startOffset": 103, "endOffset": 115}, {"referenceID": 16, "context": "The decentralized assignment of agents to more than one task each has been studied before in isolation [26, 33, 17].", "startOffset": 103, "endOffset": 115}, {"referenceID": 26, "context": "The decentralized planning of collision-free paths has also been studied before in isolation, including with reactive approaches [27] and prioritized approaches [6], but these approaches can result in deadlocks.", "startOffset": 129, "endOffset": 133}, {"referenceID": 5, "context": "The decentralized planning of collision-free paths has also been studied before in isolation, including with reactive approaches [27] and prioritized approaches [6], but these approaches can result in deadlocks.", "startOffset": 161, "endOffset": 164}, {"referenceID": 15, "context": "It is NP-hard to solve optimally for minimizing flowtime (the sum of the number of timesteps required by all agents to reach their destinations and stop moving) and NP-hard to approximate within any constant factor less than 4/3 for minimizing makespan (the timestep when all agents have reached their destinations and stop moving) [16].", "startOffset": 332, "endOffset": 336}, {"referenceID": 24, "context": "It can be solved via reductions to Boolean Satisfiability [25], Integer Linear Programming [32], and Answer Set Programming [5].", "startOffset": 58, "endOffset": 62}, {"referenceID": 31, "context": "It can be solved via reductions to Boolean Satisfiability [25], Integer Linear Programming [32], and Answer Set Programming [5].", "startOffset": 91, "endOffset": 95}, {"referenceID": 4, "context": "It can be solved via reductions to Boolean Satisfiability [25], Integer Linear Programming [32], and Answer Set Programming [5].", "startOffset": 124, "endOffset": 127}, {"referenceID": 21, "context": "Optimal dedicated MAPF algorithms include Independence Detection with Operator Decomposition [22], Enhanced Partial Expansion A* [7], Increasing Cost Tree Search [20], M* [29], and ConflictBased Search [19, 1, 3].", "startOffset": 93, "endOffset": 97}, {"referenceID": 6, "context": "Optimal dedicated MAPF algorithms include Independence Detection with Operator Decomposition [22], Enhanced Partial Expansion A* [7], Increasing Cost Tree Search [20], M* [29], and ConflictBased Search [19, 1, 3].", "startOffset": 129, "endOffset": 132}, {"referenceID": 19, "context": "Optimal dedicated MAPF algorithms include Independence Detection with Operator Decomposition [22], Enhanced Partial Expansion A* [7], Increasing Cost Tree Search [20], M* [29], and ConflictBased Search [19, 1, 3].", "startOffset": 162, "endOffset": 166}, {"referenceID": 28, "context": "Optimal dedicated MAPF algorithms include Independence Detection with Operator Decomposition [22], Enhanced Partial Expansion A* [7], Increasing Cost Tree Search [20], M* [29], and ConflictBased Search [19, 1, 3].", "startOffset": 171, "endOffset": 175}, {"referenceID": 18, "context": "Optimal dedicated MAPF algorithms include Independence Detection with Operator Decomposition [22], Enhanced Partial Expansion A* [7], Increasing Cost Tree Search [20], M* [29], and ConflictBased Search [19, 1, 3].", "startOffset": 202, "endOffset": 212}, {"referenceID": 0, "context": "Optimal dedicated MAPF algorithms include Independence Detection with Operator Decomposition [22], Enhanced Partial Expansion A* [7], Increasing Cost Tree Search [20], M* [29], and ConflictBased Search [19, 1, 3].", "startOffset": 202, "endOffset": 212}, {"referenceID": 2, "context": "Optimal dedicated MAPF algorithms include Independence Detection with Operator Decomposition [22], Enhanced Partial Expansion A* [7], Increasing Cost Tree Search [20], M* [29], and ConflictBased Search [19, 1, 3].", "startOffset": 202, "endOffset": 212}, {"referenceID": 20, "context": "Suboptimal dedicated MAPF algorithms include Windowed-Hierarchical Cooperative A* [21, 23], Push and Swap/Rotate [12, 4], TASS [10], BIBOX [24], and MAPP [30].", "startOffset": 82, "endOffset": 90}, {"referenceID": 22, "context": "Suboptimal dedicated MAPF algorithms include Windowed-Hierarchical Cooperative A* [21, 23], Push and Swap/Rotate [12, 4], TASS [10], BIBOX [24], and MAPP [30].", "startOffset": 82, "endOffset": 90}, {"referenceID": 11, "context": "Suboptimal dedicated MAPF algorithms include Windowed-Hierarchical Cooperative A* [21, 23], Push and Swap/Rotate [12, 4], TASS [10], BIBOX [24], and MAPP [30].", "startOffset": 113, "endOffset": 120}, {"referenceID": 3, "context": "Suboptimal dedicated MAPF algorithms include Windowed-Hierarchical Cooperative A* [21, 23], Push and Swap/Rotate [12, 4], TASS [10], BIBOX [24], and MAPP [30].", "startOffset": 113, "endOffset": 120}, {"referenceID": 9, "context": "Suboptimal dedicated MAPF algorithms include Windowed-Hierarchical Cooperative A* [21, 23], Push and Swap/Rotate [12, 4], TASS [10], BIBOX [24], and MAPP [30].", "startOffset": 127, "endOffset": 131}, {"referenceID": 23, "context": "Suboptimal dedicated MAPF algorithms include Windowed-Hierarchical Cooperative A* [21, 23], Push and Swap/Rotate [12, 4], TASS [10], BIBOX [24], and MAPP [30].", "startOffset": 139, "endOffset": 143}, {"referenceID": 29, "context": "Suboptimal dedicated MAPF algorithms include Windowed-Hierarchical Cooperative A* [21, 23], Push and Swap/Rotate [12, 4], TASS [10], BIBOX [24], and MAPP [30].", "startOffset": 154, "endOffset": 158}, {"referenceID": 7, "context": "The MAPF problem has recently been generalized to more clearly resemble real-world settings [8, 14, 9, 15, 13] but these versions are still one-shot.", "startOffset": 92, "endOffset": 110}, {"referenceID": 13, "context": "The MAPF problem has recently been generalized to more clearly resemble real-world settings [8, 14, 9, 15, 13] but these versions are still one-shot.", "startOffset": 92, "endOffset": 110}, {"referenceID": 8, "context": "The MAPF problem has recently been generalized to more clearly resemble real-world settings [8, 14, 9, 15, 13] but these versions are still one-shot.", "startOffset": 92, "endOffset": 110}, {"referenceID": 14, "context": "The MAPF problem has recently been generalized to more clearly resemble real-world settings [8, 14, 9, 15, 13] but these versions are still one-shot.", "startOffset": 92, "endOffset": 110}, {"referenceID": 12, "context": "The MAPF problem has recently been generalized to more clearly resemble real-world settings [8, 14, 9, 15, 13] but these versions are still one-shot.", "startOffset": 92, "endOffset": 110}, {"referenceID": 1, "context": "We now provide a sufficient condition that makes MAPD instances solvable, namely being well-formed [2].", "startOffset": 99, "endOffset": 102}, {"referenceID": 20, "context": "Token Passing (TP) is based on an idea similar to Cooperative A* [21], where agents plan their paths one after the other.", "startOffset": 65, "endOffset": 69}, {"referenceID": 1, "context": "Token passing has previously been used to develop COBRA [2], which is a MAPF-like algorithm that does not take into account that pickup or delivery locations of tasks can be occupied by agents not executing them and can thus result in deadlocks.", "startOffset": 56, "endOffset": 59}, {"referenceID": 10, "context": "It uses the Hungarian Method [11] for this purpose with the modified costs c(ai, e) for each pair of free agent ai and endpoint e, where c is the number of free agents, C is a sufficiently large constant (for example, the maximum over all costs c(ai, e) plus one), and c(ai, e) = c \u00b7C \u00b7 c(ai, e) if e is a pickup location of a task in T \u2032 and c(ai, e) = c \u00b7 C + c(ai, e) if e is a parking location.", "startOffset": 29, "endOffset": 33}, {"referenceID": 18, "context": "Path Planning CENTRAL uses the optimally effective MAPF algorithm Conflict-Based Search [19] to plan collisionfree paths for all agents from their current locations to their assigned endpoints simultaneously.", "startOffset": 88, "endOffset": 92}], "year": 2017, "abstractText": "The multi-agent path-finding (MAPF) problem has recently received a lot of attention. However, it does not capture important characteristics of many real-world domains, such as automated warehouses, where agents are constantly engaged with new tasks. In this paper, we therefore study a lifelong version of the MAPF problem, called the multiagent pickup and delivery (MAPD) problem. In the MAPD problem, agents have to attend to a stream of delivery tasks in an online setting. One agent has to be assigned to each delivery task. This agent has to first move to a given pickup location and then to a given delivery location while avoiding collisions with other agents. We present two decoupled MAPD algorithms, Token Passing (TP) and Token Passing with Task Swaps (TPTS). Theoretically, we show that they solve all well-formed MAPD instances, a realistic subclass of MAPD instances. Experimentally, we compare them against a centralized strawman MAPD algorithm without this guarantee in a simulated warehouse system. TP can easily be extended to a fully distributed MAPD algorithm and is the best choice when real-time computation is of primary concern since it remains efficient for MAPD instances with hundreds of agents and tasks. TPTS requires limited communication among agents and balances well between TP and the centralized MAPD algorithm.", "creator": "LaTeX with hyperref package"}}}