{"id": "1706.03906", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jun-2017", "title": "A New Probabilistic Algorithm for Approximate Model Counting", "abstract": "system counting seem important in domains ranging from artificial intelligence to finite analysis. there are today a few approaches for counting models over various types of constraints. recently, hashing - based approaches achieve both theoretical guarantees and scalability, but still rely on solution enumeration. in this paper, a new probabilistic polynomial time approximate filtering counter is proposed, a is also a hashing - strict universal framework, but ignores only satisfiability queries. solution variant with a dynamic stopping criterion is also presented. empirical evaluation over benchmarks on mathematical logic phrases and smt ( bv ) formulas shows that the approach sounded promising.", "histories": [["v1", "Tue, 13 Jun 2017 05:26:02 GMT  (207kb,D)", "http://arxiv.org/abs/1706.03906v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["cunjing ge", "feifei ma", "tian liu", "jian zhang"], "accepted": false, "id": "1706.03906"}, "pdf": {"name": "1706.03906.pdf", "metadata": {"source": "CRF", "title": "A New Probabilistic Algorithm for Approximate Model Counting", "authors": ["Cunjing Ge", "Feifei Ma", "Tian Liu", "Jian Zhang"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "Constrained counting, the problem of counting the number of solutions for a set of constraints, is important in theoretical computer science and artificial intelligence. Its interesting applications in several fields include probabilistic inference [25,10], planning [12], combinatorial designs and software engineering [23,15]. Constrained counting for propositional formulas is also called model counting, to which probabilistic inference is easily reducible. However, model counting is a canonical #P-complete problem, even for polynomial-time solvable problems like 2-SAT [31], thus presents fascinating challenges for both theoreticians and practitioners.\nThere are already a few approaches for counting solutions over propositional logic formulas and SMT(BV) formulas. Recently, hashing-based approximate counting achieves both strong theoretical guarantees and good scalability [24]. The use of universal hash functions in counting problems began in [28,30], but the resulting algorithm scaled poorly in practice. A scalable approximate counter ApproxMC in [8] scales to large problem instances, while preserves rigorous approximation guarantees. ApproxMC has been extended to finite-domain discrete integration, with applications to probabilistic inference [13,5,2], and improved by designing efficient universal hash functions [19,6] and reducing the use of NP-oracle calls from linear to logarithmic [9].\n? Corresponding author\nar X\niv :1\n70 6.\n03 90\n6v 1\n[ cs\n.A I]\n1 3\nThe basic idea in ApproxMC is to estimate the model count by randomly and iteratively cutting the whole space down to a small \u201cenough\u201d cell, using hash functions, and sampling it. The total model count is estimated by a multiplication of the number of solutions in this cell and the ratio of whole space to the small cell. To determine the size of the small cell, which is essentially a small-scale model counting problem with the model counts bounded by some thresholds, a model enumeration in the cell is adopted. In previous works, the enumeration query was handled by transforming it into satisfiability queries, which is much more time-consuming than a single satisfiability query. An algorithm called MBound [17] only invokes satisfiability query once for each cut. Its model count is determined with high precision by the number of cuts down to the boundary of being unsatisfiable. However, this property is not strong enough to give rigorous guarantees, and MBound only returns an approximation of upper or lower bound of the model count.\nIn this paper, a new hashing-based approximate counting algorithm, with only satisfiability query, is proposed, building on a correlation between the model count and the probability of the hashed formula being unsatisfiable. Dynamic stopping criterion for the algorithm to terminate, once meeting the theoretical guarantee of accuracy, are presented. Like previous works, a theoretical termination bound T is shown. Theoretical insights over the efficiency of a prevalent heuristic strategy called leap-frogging are also provided.\nThe proposed approach is a general framework easy to handle various types of constraints. Prototype tools for propositional logic formulas and SMT(BV) formulas are implemented. An extensive evaluation on a suite of benchmarks demonstrates that (i) the approach significantly outperforms the state-of-the-art approximate model counters, including a counter designed for SMT(BV) formulas, and (ii) the dynamic stopping criterion is promising. The statistical results fit well with the theoretical bound of approximation, and it terminates much earlier before termination bound T is met.\nThe rest of this paper is organized as follows. Preliminary material is in Section 2, related works in Section 3, the algorithm in Section 4, analysis in Section 5, experimental results in Section 6, and finally, concluding remarks in Section 7."}, {"heading": "2 Preliminaries", "text": "Let F (x) denote a propositional logic formula on n variables x = (x1, . . . , xn). Let S and SF denote the whole space and the solution space of F , respectively. Let #F denote the cardinality of SF , i.e. the number of solutions of F . ( , \u03b4)-bound To count #F , an ( , \u03b4) approximation algorithm is an algorithm which on every input formula F , > 0 and \u03b4 > 0, outputs a number Y\u0303 such that Pr[(1 + )\u22121#F \u2264 Y\u0303 \u2264 (1 + )#F ] \u2265 1 \u2212 \u03b4. These are called ( , \u03b4)-counters and ( , \u03b4)bound, respectively [21]. Hash Function LetHF be a family of XOR-based bit-level hash functions on the variables of a formulaF . Each hash functionH \u2208 HF is of the formH(x) = a0 \u2295n i=1 aixi, where a0, . . . , an are Boolean constants. In the hashing procedure Hashing(F), a functionH \u2208 HF is generated by independently and randomly choosing ais from a uniform distribution. Thus for an assignment \u03b1, it holds that PrH\u2208HF (H(\u03b1) = true) = 1 2 .\nGiven a formula F , let Fi denote a hashed formula F \u2227H1\u2227\u00b7 \u00b7 \u00b7\u2227Hi, whereH1, . . . ,Hi are independently generated by the hashing procedure.\nSatisfiability Query Let Solving(F) denote the satisfiability query of a formula F . With a target formula F as input, the satisfiability of F is returned by Solving(F).\nEnumeration Query Let Counting(F, p) denote the bounded solution enumeration query. With a constraint formula F and a threshold p (p \u2265 2) as inputs, a number s is returned such that s = min(p \u2212 1,#F ). Specifically, 0 is returned for unsatisfiable F , or p = 1 which is meaningless.\nSMT(BV) Formula SMT(BV) formulas are quantifier-free and fixed-size that combine propositional logic formulas with constraints of bit-vector theory. For example, \u00ac(x + y = 0) \u2228 (x = y << 1), where x and y are bit-vector variables, << is the shift-left operator, is a propositional logic formula \u00acA \u2228 B that combines bit-vector constraints A \u2261 (x + y = 0) and B \u2261 (x = y << 1). To apply hash functions to an SMT(BV) formula, a bit-vector is treated as a set of Boolean variables."}, {"heading": "3 Related Works", "text": "[1] showed that almost uniform sampling from propositional constraints, a closely related problem to constrained counting, is solvable in probabilistic polynomial time with an NP oracle. Building on this, [8] proposed the first scalable approximate model counting algorithm ApproxMC for propositional formulas. ApproxMC is based on a family of 2-universal bit-level hash functions that compute XOR of randomly chosen propositional variables. Subsequently, [6] presented an approximate model counter that uses word-level hash functions, which directly leverage the power of sophisticated SMT solvers, though the framework of the probabilistic algorithm is similar to [8]. In the current work, the family of hash functions in [8] is adopted, which was shown to be 3-independent in [18], and is revealed to possess better properties than expected by the experimental results and the theoretical analysis in the current work.\nFor completeness, ApproxMC [8,11] is listed here as Algorithm 1. Its inputs are a formula F and two accuracy parameters T and pivot. T determines the number of times ApproxMCCore invoked, and pivot determines the threshold of the enumeration query. The function ApproxMCCore starts from the formula F0, iteratively calls Counting and Hashing over each Fi, to cut the space (cell) of all models of F0 using random hash functions, until the count of Fi is no larger than pivot, then breaks out the loop and adds the approximation 2is into list C. The main procedure ApproxMC repeatedly invokes ApproxMCCore and collects the returned values, at last returning the median number of list C. The general algorithm in [6] is similar to Algorithm 1, but could cut the cell with dynamically determined proportion instead of the constant 12 , due to the word-level hash functions. [9] improves ApproxMCCore via binary search to reduce the number of enumeration queries from linear to logarithmic. This binary search improvement is orthogonal to the proposed algorithm in the current work.\nAlgorithm 1 1: function APPROXMC(F , T , pivot) 2: for 1 to T do 3: c\u2190 ApproxMCCore(F , p, pivot) 4: if (c 6= 0) then AddToList(C, c) 5: end for 6: return FindMedian(C) 7: end function 8: function APPROXMCCORE(F , pivot) 9: F0 \u2190 F 10: for i\u2190 0 to\u221e do 11: s\u2190 Counting(Fi, pivot+ 1) 12: if (0 \u2264 s \u2264 pivot) then return 2is 13: Hi+1 \u2190 Hashing(F ) 14: Fi+1 \u2190 Fi \u2227Hi+1 15: end for 16: end function"}, {"heading": "4 Algorithm", "text": "In this section, a new hashing-based algorithm for approximate model counting, with only satisfiability queries, will be proposed, building on some probabilistic approximate correlations between the model count and the probability of the hashed formula being unsatisfiable.\nLet Fd = F \u2227H1 \u2227 \u00b7 \u00b7 \u00b7 \u2227Hd be a hashed formula resulted by iteratively hashing d times independently over a formula F . Fd is unsatisfiable if and only if no solution of F satisfies Fd, thus PrFd(Fd is unsat) = PrFd(Fd(\u03b1) = false, \u03b1 \u2208 SF ). The following approximation is a key for the new algorithm\nPr Fd\n(Fd is unsat) \u2248 (1\u2212 2\u2212d)#F . (1)\nBased on Equation (1), an approximation of #F is achieved by taking logarithm on the value of PrFd(Fd is unsat), which is estimated in turn by sampling Fd. However, Equation (1) can not be proven directly, since it is equivalent to PrFd(Fd(\u03b1) = false, \u03b1 \u2208 SF ) \u2248 \u220f \u03b1\u2208SF PrFd(Fd(\u03b1) = false), but HF was only known to be 3-independent. In the following, we consider a similar but different family of hash functions to provide some intuition (not proof) about Equation (1). From the definition H(x) = a0 \u2295n i=1 aixi, it holds that (i) PrH(H(\u03b1) = true) = 1 2 for any assignment \u03b1, and (ii) |SH | = |S|2 , unless a1 = \u00b7 \u00b7 \u00b7 = an = 0. Now let G be a family of hash functions also with these properties, defined as follows. Each hash function G in G is of the form\nG(x) = { true x \u2208 SG false x 6\u2208 SG .\nThe solution set SG is generated by sampling |S| 2 points in S without replacement (simple random sample). For any given assignment \u03b1, obviously PrG(G(\u03b1) = true) = 12 .\nMoreover, G is not k-independent for k > |S|2 , since the probability of more than |S| 2 variables having the same value is always zero.\nTheorem 1. Let G\u0302d = G1 \u2227 \u00b7 \u00b7 \u00b7 \u2227 Gd, where G1, . . . , Gd are independently sampled from G, and let F \u2032d = F \u2227 G\u0302d. Then\nlim n\u2192\u221e Pr F \u2032d\n(F \u2032d is unsat) = (1\u2212 2\u2212d)#F . (2)\nProof. Since PrG(G(\u03b1) = true) = 12 andGis are independent, we have PrG\u0302d(G\u0302d(\u03b1) = true) = ( 1 2 )d . Let SG\u0302d denote the solution space of G\u0302d, then the expectation E(|SG\u0302d |)\n= ( 1 2 )d |S| = 2n\u2212d. Since eachGi is generated by simple random sample and uniquely determined by its solution set, the number of distinct functions of G\u0302d is ( |S| |SG\u0302d | ) , and the\nnumber of distinct G\u0302ds which are unsatisfiable over SF is (|S\u2212SF | |SG\u0302d | ) . The probability of SF \u2229 SG\u0302d = \u2205 is(|S\u2212SF | |SG\u0302d |\n) ( |S| |SG\u0302d | ) = (2n\u2212#F2n\u2212d )( 2n 2n\u2212d ) = (2n \u2212#F )!(2n \u2212 2n\u2212d)! (2n)!(2n \u2212#F \u2212 2n\u2212d)!\n= (2n \u2212 2\u2212d2n) 2n (2n \u2212 2\u2212d2n \u2212 1) 2n \u2212 1 . . . (2n \u2212 2\u2212d2n \u2212#F + 1) 2n \u2212#F + 1 . (3)\nThe LHS (left-hand-side) of (3) is also PrF \u2032d(F \u2032 d is unsat). The RHS of (3) converges to (1\u2212 2\u2212d)#F as n\u2192\u221e. ut\nSinceHF and G have some common characteristics, Equations (2) and (1) may also hold for HF . In practice for finite n, Equation (2) only holds approximately. To make the value of PrF \u2032d(F \u2032 d is unsat) arbitrarily close to (1 \u2212 2\u2212d)#F , dummy variables can be inserted into F while keeping #F unchanged, such as inserting a new variable xn+1 with constraint xn+1 = true. These variables and constraints are meaningless for SAT solvers and ignored at the beginning of the search. Experimental results indicate that Equation (1) holds even without inserting any dummy variable. Here we assume Equation (1) holds in convenience of describing our approach.\nThe pseudo-code for our approach is presented in Algorithm 2. The inputs are the target formula F and a constant T which determines the number of times GetDepth invoked. GetDepth calls Solving and Hashing repeatedly until an unsatisfiable formula Fdepth is encountered, and returns the depth. Every time GetDepth returns a depth, the value of C[i] is increased, for all i < depth. At line 9, the algorithm picks a number d such that C[d] is close to T/2, since the error estimation fails when C[d]/T is close to 0 or 1. The final counting result is returned by the formula log1\u2212(1/2)d counter T at line 11. Theoretical analysis of the value of T and the correctness of algorithm are in Section 5.\nDynamic Stopping Criterion The essence of Algorithm 2 is a randomized sampler over a binomial distribution. The number of samples is determined by the value of T , which\nAlgorithm 2 Satisfiability Testing based Approximate Counter (STAC) 1: function STAC(F , T ) 2: initialize C[i]s with zeros 3: for t\u2190 1 to T do 4: depth\u2190 GetDepth(F ) 5: for i\u2190 0 to depth\u2212 1 do 6: C[i]\u2190 C[i] + 1 7: end for 8: end for 9: pick a number d such that C[d] is closest to T/2 10: counter \u2190 T \u2212 C[d] 11: return log1\u22122\u2212d counter T\n/* return 0 when d = 0 */ 12: end function 13: function GETDEPTH(F ) 14: F0 \u2190 F 15: for i\u2190 0 to\u221e do 16: b\u2190 Solving(Fi) 17: if (b is false) then return i 18: Hi+1 \u2190 Hashing(Fi) 19: Fi+1 \u2190 Fi \u2227Hi+1 20: end for 21: end function\nis pre-computed for a given ( , \u03b4)-bound, and we loosen the bound of T to meet the guarantee in theoretical analysis. However, it usually does not loop T times in practice. A variation with dynamic stopping criterion is presented in Algorithm 3.\nLine 2 to 7 is the same as Algorithm 2, still setting T as a stopping rule and terminating whenever t = T . Line 8 to 16 is the key part of this variation, calculating the binomial proportion confidence interval [L,U ] of an intermediate result M for each\ncycle. A commonly used formula q\u00b1z1\u2212\u03b4 \u221a q(1\u2212q) t [3,32] is adopted, which is justified by the central limit theorem to compute the 1 \u2212 \u03b4 confidence interval. The exact count #F lies in the interval [L,U ] with probability 1 \u2212 \u03b4. Combining the inequalities presented in line 13, the interval [(1+ )\u22121M, (1+ )M ] is the ( , \u03b4)-bound. The algorithm terminates when the condition in line 13 comes true, and its correctness is obvious. The time complexity of Algorithm 3 is still the same as the original algorithm, though it usually terminates earlier.\nSatisfiability And Enumeration Query For a propositional logic formula or an SMT formula, there is a direct way to enumerate solutions with satisfiability queries. For example, we assert the negation of a solution which is found by satisfiability query, so that the constraint solver will provide other models. So Counting(F, p) invokes up to p times Solving(F) by this way. This method is adopted by all previous hashingbased ( , \u03b4)-counters [8,11,6].\nLeap-frogging Strategy Recall that GetDepth is invoked T times with the same arguments, and the loop of line 15 to 20 in the pseudo-code of GetDepth in Algorithm 2\nAlgorithm 3 STAC with Dynamic Stopping Criterion 1: function STAC DSC(F , T , , \u03b4) 2: initialize C[i]s with zeros 3: for t\u2190 1 to T do 4: depth\u2190 GetDepth(F ) 5: for i\u2190 0 to depth\u2212 1 do 6: C[i]\u2190 C[i] + 1 7: end for 8: for each d that C[d] > 0 do 9: q \u2190 t\u2212C[d]\nt\n10: M \u2190 log1\u22122\u2212d q 11: U \u2190 log1\u22122\u2212d(q \u2212 z1\u2212\u03b4 \u221a q(1\u2212q) t )\n12: L\u2190 log1\u22122\u2212d(q + z1\u2212\u03b4 \u221a q(1\u2212q) t ) 13: if U < (1 + )M and L > (1 + )\u22121M then 14: return M 15: end if 16: end for 17: end for 18: end function\nis time consuming for large i. A heuristic called leap-frogging to overcome this bottleneck was proposed in [7,8]. Their experiments indicate that this strategy is extremely efficient in practice. The average depth d\u0304 of each invocation of GetDepth is recorded. In all subsequent invocations, the loop starts by initializing i to d\u0304\u2212 offset, and sets i to d\u0304 \u2212 2 \u2217 offset for unsatisfiable Fi repeatedly until a proper i is found for a satisfiable Fi. In practice, the constant offset is usually set to 5. Theorem 4 in Section 5 shows that the depth computed by GetDepth lies in an interval [d, d + 7] with probability over 90%. So it suffices to invoke Solving in constant time since the second iteration.\nWilson Score Interval The central limit theorem applies poorly to binomial distributions for small sample size or proportion close to 0 or 1. The following interval [34]\n1\n1 + z 2\nt\n[q + z2 2t \u00b1 z \u221a q(1\u2212 q) t + z2 4t2 ]\nhas good properties to achieve better approximations. Note that the overhead of computing intervals is negligible."}, {"heading": "5 Analysis", "text": "In this section, we assume Equation (1) holds. Based on this assumption, theoretical results on the error estimation of our approach are presented. Recall that in Algorithm 2, #F is approximated by a value log1\u22122\u2212d counter T , based on Equation (1). Let qd denote the value of (1 \u2212 2\u2212d)#F . We will assume that Pr(Fd is unsat) = qd for a randomly\ngenerated formula Fd. This assumption is justified by Equations (1) and (2). Then the counter in Algorithm 2 is a random variable following a binomial distribution B(T, qd). Since the ratio counterT is the proportion of successes in a Bernoulli trial process, it is used to estimate the value of qd.\nTheorem 2. Let z1\u2212\u03b4 be the 1\u2212 \u03b4 quantile of N(0, 1) and\nT = max ( d( z1\u2212\u03b4\n2qd(1\u2212 q d) )2e, d( z1\u2212\u03b4 2(q (1+ )\u22121 d \u2212 qd) )2)e\n) . (4)\nThen Pr[#F1+ \u2264 log1\u22122\u2212d counter T \u2264 (1 + )#F ] \u2265 1\u2212 \u03b4.\nProof. By above discussions, the ratio counterT is the proportion of successes in a Bernoulli trial process which follows the distribution B(T, qd). Then we use the approximate formula of a binomial proportion confidence interval qd \u00b1 z1\u2212\u03b4 \u221a qd(1\u2212qd) T , i.e., Pr[qd \u2212\nz1\u2212\u03b4\n\u221a qd(1\u2212qd)\nT \u2264 counter T \u2264 qd + z1\u2212\u03b4 \u221a qd(1\u2212qd) T ] \u2265 1 \u2212 \u03b4. The log function is\nmonotone, so we only have to consider the following two inequalities:\nlog1\u22122\u2212d (qd \u2212 z1\u2212\u03b4\n\u221a qd(1\u2212 qd)\nT ) \u2264 (1 + )#F, (5)\n(1 + )\u22121#F \u2264 log1\u22122\u2212d (qd + z1\u2212\u03b4\n\u221a qd(1\u2212 qd)\nT ). (6)\nWe first consider Equation (5). By substituting log1\u22122\u2212d qd for #F , we have\nlog1\u22122\u2212d (qd \u2212 z1\u2212\u03b4\n\u221a qd(1\u2212 qd)\nT ) \u2264 (1 + ) log1\u22122\u2212d qd\n\u21d4 qd \u2212 z1\u2212\u03b4\n\u221a qd(1\u2212 qd)\nT \u2265 q(1+ )d\n\u21d4 qd(1\u2212 q d) \u2265 z1\u2212\u03b4\n\u221a qd(1\u2212 qd)\nT\n\u21d4 T \u2265 ( z1\u2212\u03b4 qd(1\u2212 q d) )2qd(1\u2212 qd).\nSince 0 \u2264 qd \u2264 1, we have \u221a qd(1\u2212 qd) \u2264 12 . Therefore, T = d( z1\u2212\u03b4 2qd(1\u2212q d)\n)2e \u2265 ( z1\u2212\u03b4qd(1\u2212q d)\n)2qd(1\u2212 qd). We next consider Equation (6). Similarly, we have\nlog1\u22122\u2212d (qd + z1\u2212\u03b4\n\u221a qd(1\u2212 qd)\nT ) \u2265 (1 + )\u22121 log1\u22122\u2212d qd\n\u21d4 qd + z1\u2212\u03b4\n\u221a qd(1\u2212 qd)\nT \u2264 q1/(1+ )d\n\u21d4 T \u2265 ( z1\u2212\u03b4 q 1/(1+ ) d \u2212 qd )2qd(1\u2212 qd).\nSo Equation (4) implies Equations (5) and (6).\nTheorem 2 shows that the result of Algorithm 2 lies in the interval [(1+ )\u22121#F, (1+ )#F ] with probability at least 1 \u2212 \u03b4 when T is set to a proper value. So we focus on the possible smallest value of T in subsequent analysis.\nThe next two lemmas are easy to show by derivations.\nLemma 1. z1\u2212\u03b42x(1\u2212x ) is monotone increasing and monotone decreasing in [(1+ ) \u2212 1 , 1] and [0, (1 + )\u2212 1 ] respectively.\nLemma 2. z1\u2212\u03b4 2(x1/(1+ )\u2212x) is monotone increasing and monotone decreasing in [(1 +\n)\u2212 1+ , 1] and [0, (1 + )\u2212 1+ ] respectively.\nTheorem 3. If #F > 5, then there exists a proper integer value of d such that qd \u2208 [0.4, 0.65].\nProof. Let x denote the value of qd = (1 \u2212 12d ) #F , then we have (1 \u2212 1 2d+1 )#F =\n( 12 + x\n1 #F 2 ) #F . Consider the derivation\nd d#F ( 1 2 +\nx 1 #F\n2 ) #F = (\n1 2 + x\n1 #F 2 )#F ln ( 1 2 + x 1 #F 2 ) x 1 #F 2 lnx d d#F (#F\u22121).\nNote that ( 12 + x\n1 #F 2 ) #F and x 1 #F 2 are the positive terms and ln ( 1 2 + x 1 #F\n2 ), lnx and d\nd#F (#F \u22121) are the negative terms. Therefore, the derivation is negative, i.e., ( 12 + x 1 #F\n2 ) #F is monotone decreasing with respect to #F . In addition, ( 12 +\nx 1 5\n2 ) 5 is the\nupper bound when #F \u2265 5. Let x = 0.4, then (1\u2212 1\n2d+1 )#F \u2264 ( 12 +\n0.4 1 5\n2 ) 5 \u2248 0.65. Since (1\u2212 120 ) #F = 0 and limd\u2192+\u221e(1\u2212 12d ) #F = 1 and (1\u2212 1 2d\n)#F is continuous with respect to d, we consider the circumstances close to the interval [0.4, 0.65]. Assume there exists an integer \u03c3 such that (1\u2212 12\u03c3 ) #F < 0.4 and (1\u2212 12\u03c3+1 ) #F > 0.65. According to the intermediate value theorem, we can find a value e > 0 such that (1\u2212 12\u03c3+e ) #F = 0.4. Obviously, we have (1\u2212 12\u03c3+e+1 ) #F \u2264 0.65 which is contrary with the monotone decreasing property.\nFrom Theorem 3 and Lemma 1 and 2, it suffices to consider the results of Equation (4) when qd = 0.4 and qd = 0.65. For example, T = 22 for = 0.8 and \u03b4 = 0.2, T = 998 for = 0.1 and \u03b4 = 0.1, etc. We therefore pre-computed a table of the value of T . The proof of next theorem is omitted.\nTheorem 4. There exists an integer d such that qd < 0.05 and qd+7 > 0.95.\nLet depth denote the result of GetDepth in Algorithm 2. Then Fd is unsatisfiable only if d \u2265 depth. Theorem 4 shows that there exists an integer d such that Pr(depth < d) < 0.05 and Pr(depth < d + 7) > 0.95, i.e., Pr(d \u2264 depth \u2264 d + 7) > 0.9. So in most cases, the value of depth lies in an interval [d, d + 7]. Also, it is easy to see that log2 #F lies in this interval as well. The following theorem is obvious now.\nTheorem 5. Algorithm 2 runs in time linear in log2 #F relative to an NP-oracle."}, {"heading": "6 Evaluation", "text": "To evaluate the performance and effectiveness of our approach, two prototype implementations STAC CNF and STAC BVwith dynamic stopping criterion for propositional logic formulas and SMT(BV) formulas are built respectively. We considered a wide range of benchmarks from different domains: grid networks, plan recognition, DQMR networks, Langford sequences, circuit synthesis, random 3-CNF, logistics problems and program synthesis [26,22,8,6]. For lack of space, we present results for only for a subset of the benchmarks. All our experiments were conducted on a single core of an Intel Xeon 2.40GHz (16 cores) machine with 32GB memory and CentOS6.5 operating system."}, {"heading": "6.1 Quality of Approximation", "text": "Recall that our approach is based on Equation (1) which has not been proved. So we would like to see whether the approximation fits the bound. We experimented 100 times on each instance.\nIn Table 1, column 1 gives the instance name, column 2 the number of Boolean variables n, column 3 the exact counts #F , and column 4 the interval [1.8\u22121#F, 1.8#F ]. The frequencies of approximations that lie in the interval [1.8\u22121#F, 1.8#F ] in 100 times of experiments are presented in column 5. The average time consumptions, average number of iterations, and average number of SAT query invocations are presented in column 6, 7 and 8 respectively, which also indicate the advantages of our approach.\nUnder the dynamic stopping criterion, the counts returned by our approach should lie in an interval [1.8\u22121#F, 1.8#F ] with probability 80% for = 0.8 and \u03b4 = 0.2. The statistical results in Table 1 show that the frequencies are around 80 for 100-times experiments which fit the 80% probability. The average number of iterations T\u0304 listed in Table 1 is smaller than the theoretical termination bound T which is 22, indicating that the dynamic stopping technique significantly improves the efficiency. In addition,\nthe values of T\u0304 appear to be stable for different instances, hinting that there exists a constant upper bound on T which is irrelevant to instances.\nIn Section 4, we considered a similar but different function family G and proved Equation (2). It suggests that Equation (1) may hold on H for infinite n. However, our approach does not insert any dummy variables to increase n. Intuitively, our approach may start to fail on \u201cloose\u201d formulas, i.e., with an \u201cinfinitesimal\u201d fraction of non-models. Instance special-1 and special-3 are such \u201cloose\u201d formulas where special-1 has 220 models with only 20 variables and special-3 has 225 \u2212 1 models with 25 variables. Instance special-2 is another extreme case which only has one model. The results in Table 1 demonstrate that STAC CNF works fine even on these extreme cases.\nWe also considered another pair of parameters = 0.2, \u03b4 = 0.1. Then the interval should be [1.2\u22121#F, 1.2#F ] and the probability should be 90%. Table 2 shows the results on such parameter setting. The frequencies that the approximation lies in interval [1.2\u22121#F, 1.2#F ] are all around or over 90 which fits the 90% probability.\nTable 3 similarly shows the results of 100-times experiments on STAC BV. Its column 2 gives the sum of widths of all bit-vector variables (Boolean variable is counted as a bit-vector of width 1) instead. The statistical results demonstrate that the dynamic stopping criterion is also promising on SMT(BV) problems."}, {"heading": "6.2 Performance Comparison with ( , \u03b4)-counters", "text": "We compared our tools with ApproxMC2 [9] and SMTApproxMC [6] which are hashingbased ( , \u03b4)-counters. Both STAC CNF and ApproxMC2 use CryptoMiniSAT [29], an efficient SAT solver designed for XOR clauses. STAC BV and SMTApproxMC use the state-of-the-art SMT(BV) solver Boolector [4].\nWe first conducted experiments with = 0.8, \u03b4 = 0.2 which are also used in evaluation in previous works [9,6]. Figure 1 presents a comparison on performance between STAC CNF and ApproxMC2. Each point represents an instance, whose xcoordinate and y-coordinate are the running times of STAC CNF and ApproxMC2 on this instance, respectively. The figure is in logarithmic coordinates and demonstrates that STAC CNF outperforms ApprxMC2 by about one order of magnitude. Figure 2 presents a similar comparison on performance between STAC BV and SMTApproxMC, showing that STAC BV outperforms SMTApproxMC by one or two order of magnitude. Furthermore, the advantage enlarges as the scale grows.\nTable 4 presents more experimental results with ( , \u03b4) parameters other than (0.8, 0.2). Nine pairs of parameters were experimented. \u201cTime Ratio\u201d represents the ratio of the running times of ApproxMC2 to STAC CNF. \u201c#Calls Ratio\u201d represents the ratio of the number of SAT calls of ApproxMC2 to STAC CNF. The results show that ApproxMC2 gains advantage as decreases and STAC CNF gains advantage as \u03b4 decreases. On the whole, ApproxMC2 gains advantage when and \u03b4 both decrease. Note that the numbers of SAT calls represent the complexity of both algorithms. In Table 4, #Calls Ratio\nis more stable than Time Ratio among different pairs of parameters and also different instances. It indicates that the difficulty of NP-oracle is also an important factor of running time performance."}, {"heading": "6.3 Performance Comparison with Bounding and Guarantee-less Counters", "text": "Since our approach is not a ( , \u03b4)-counter in theory, we also compared STAC CNF with bounding counters (SampleCount [16], MBound [17]) and guarantee-less counters (ApproxCount [33], SampleTreeSearch [14]). Table 5 shows the experimental results.\nFor SampleCount, we used \u03b1 = 2 and t = 3.5 so that \u03b1t = 7, giving a correctness confidence of 1 \u2212 2\u22127 = 99%. The number of samples per variable setting, z, was chosen to be 20. Our results show that the lower-bound approximated by SampleCount is smaller than exact count #F by one or more orders of magnitude. We tried larger z, such as z = 100 and z = 1000, but still failed to obtain a lower-bound larger than #F/10. Moreover, there are some wrong approximations on DQMR networks problems, e.g., or-100-20-6-UC-60 only has 2.8 \u00d7 107 models but SampleCount returns a lower-bound\u2265 1.1\u00d7 1029. SampleCount is more efficient on Langford problems and random 3-CNF problems, but weak on problems with a large number of variables, such as blockmap problems.\nFor MBound, we used \u03b1 = 1 and t = 7 so that \u03b1t = 7, also giving a correctness confidence of 1\u22122\u22127 = 99%. MBound also employs a family of XOR hashing function\nTa bl\ne 5.\nPe rf\nor m\nan ce\nco m\npa ri\nso n\nof S T A C C N F\nw ith\nex is\ntin g\nbo un\ndi ng\nco un\nte rs\nan d\ngu ar\nan te\nele\nss co\nun te\nrs\nIn st\nan ce\nn # F\nS T A C C N F\nS a m p l e C o u n t\nM B o u n d\nA p p r o x C o u n t\nS a m p l e T r e e S e a r c h\n(i fk\nno w\nn) (\n= 0 .8 ,\u03b4\n= 0 .2\n) (9\n9% co\nnfi de\nnc e)\n(9 9%\nco nfi\nde nc e) M od el s Ti m e L -b ou nd Ti m e L -b ou nd Ti\nm e\nM od\nel s\nTi m\ne M\nod el\ns Ti\nm e\nbl oc\nkm ap\n05 01\n14 11\n64 0\n\u2248 8 0 7\n1 s\n\u2265 2 2\n11 6\ns >\n6 4\n9 s\n= 6 4 0\n7 s\n\u2248 6 4 6\n71 s\nbl oc\nkm ap\n05 02\n17 38\n9 .4 \u00d7\n1 0 6 \u2248\n7 .1 \u00d7\n1 0 6\n16 s\n3 .6 \u00d7\n1 0 4\n5 m\n> 2 .1 \u00d7\n1 0 6\n5 m\n= 9 .4 \u00d7\n1 0 6\n13 s\n\u2248 9 .4 \u00d7\n1 0 6\n11 4 s bl oc km ap 10 01 11 32 8 2 .9 \u00d7 1 0 6 \u2248 2 .6 \u00d7 1 0 6 96 s \u2014 \u2265 8 h > 5 .2 \u00d7 1 0 5 9 m \u2014 \u2265 8 h \u2248 3 .0 \u00d7 1 0 6 62 m bl oc km ap 15 01 33 03 5 \u2014 \u2248 2 .0 \u00d7 1 0 9 41 m \u2014 \u2265 8 h \u2014 \u2265 8 h \u2014 \u2265 8 h \u2014 \u2265 8 h fs -0 1 32 76 8 \u2248 7 0 9 0. 1 s \u2265 6 8 0. 2 s > 6 4 2 s \u2248 9 2 5 17 s \u2248 7 6 9 0. 1 s\nPL A\nN R\nE C\nO G\nN IT\nIO N\n5s te\np 17\n7 8 .1 \u00d7\n1 0 4 \u2248\n8 .1 \u00d7\n1 0 4\n0. 2\ns \u2265\n2 .8 \u00d7\n1 0 3\n4 s\n> 8 .2 \u00d7\n1 0 3\n6 s\n= 8 .1 \u00d7\n1 0 4\n18 s\n\u2248 7 .5 \u00d7\n1 0 4\n1 s\ntir e-\n1 35\n2 7 .3 \u00d7\n1 0 8 \u2248\n9 .8 \u00d7\n1 0 8\n64 m\n\u2265 7 .0 \u00d7\n1 0 5\n14 s\n> 6 .7 \u00d7\n1 0 7\n8 h\n= 7 .3 \u00d7\n1 0 8\n48 s\n\u2248 7 .6 \u00d7\n1 0 8\n5 s\ntir e-\n3 57\n7 2 .2 \u00d7\n1 0 1 1\n\u2014 \u2265\n8 h \u2265\n1 .3 \u00d7\n1 0 6\n49 s\n\u2014 \u2265\n8 h \u2248\n2 .1 \u00d7\n1 0 1 1\n63 s\n\u2248 1 .2 \u00d7\n1 0 1 1\n5 s\nL A\nN G\nFO R\nD PR\nO B S. la ng 12\n57 6\n2 .2 \u00d7\n1 0 5 \u2248\n3 .2 \u00d7\n1 0 5\n80 m\n\u2265 3 .6 \u00d7\n1 0 3\n3 m\n> 1 .6 \u00d7\n1 0 4\n4 h\n\u2248 0\n11 1\ns \u2248\n1 .9 \u00d7\n1 0 5\n10 1 m la ng 15 10 24 \u2014 \u2014 \u2265 8 h \u2265 4 .7 \u00d7 1 0 5 4 m \u2014 \u2265 8 h \u2248 0 12 2 s \u2014 \u2265 8 h\nD Q\nM R\nN E\nT W\nO R\nK S\nor -1\n00 -2\n0- 6-\nU C\n-6 0\n20 0\n2 .8 \u00d7\n1 0 7 \u2248\n3 .4 \u00d7\n1 0 7\n14 m\n\u2265 1 .1 \u00d7\n1 0 2 9\n15 s\n> 4 .2 \u00d7\n1 0 6\n6 m\n\u2248 0\n17 s\n\u2248 2 .8 \u00d7\n1 0 7\n0. 8 s or -5 0- 10 -1 0- U C -4 0 10 0 3 .1 \u00d7 1 0 3 \u2248 3 .2 \u00d7 1 0 3 0. 1 s \u2265 2 .7 \u00d7 1 0 2 0. 1 s > 5 .1 \u00d7 1 0 2 4 s \u2248 2 .1 \u00d7 1 0 1 6 68 s \u2248 3 .1 \u00d7 1 0 3 0. 5 s or -5 0- 20 -1 0- U C -3 0 10 0 6 .8 \u00d7 1 0 8 \u2248 7 .4 \u00d7 1 0 8 35 m \u2265 6 .0 \u00d7 1 0 7 0. 2 s > 1 .3 \u00d7 1 0 8 3 h \u2248 2 .7 \u00d7 1 0 1 6 62 s \u2248 7 .9 \u00d7 1 0 8 0. 7 s or -6 0- 10 -1 0- U C -3 0 12 0 6 .8 \u00d7 1 0 7 \u2248 6 .2 \u00d7 1 0 7 4 m \u2265 1 .0 \u00d7 1 0 1 7 9 s > 1 .7 \u00d7 1 0 7 38 m \u2248 2 .4 \u00d7 1 0 1 9 83 s \u2248 6 .5 \u00d7 1 0 7 1 s or -6 0- 5- 2- U C -4 0 12 0 2 .1 \u00d7 1 0 6 \u2248 1 .9 \u00d7 1 0 6 6 s \u2265 1 .0 \u00d7 1 0 1 7 16 s > 5 .2 \u00d7 1 0 5 19 9 s \u2248 2 .3 \u00d7 1 0 1 9 89 s \u2248 2 .1 \u00d7 1 0 6 0. 9 s or -7 0- 10 -6 -U C -4 0 14 0 1 .2 \u00d7 1 0 4 \u2248 7 .2 \u00d7 1 0 3 0. 1 s \u2265 1 .0 \u00d7 1 0 2 0 7 s > 2 .0 \u00d7 1 0 3 4 s \u2248 0 16 5 s \u2248 1 .2 \u00d7 1 0 4 0. 5 s or -7 0- 5- 2- U C -3 0 14 0 1 .7 \u00d7 1 0 7 \u2248 4 .7 \u00d7 1 0 7 51 s \u2265 1 .0 \u00d7 1 0 2 0 10 s > 2 .1 \u00d7 1 0 6 11 m \u2248 0 16 5 s \u2248 1 .7 \u00d7 1 0 7 0. 8 s\nR A\nN D\nO M\n3- C\nN F\nra n6\n30 1 .2 \u00d7\n1 0 6 \u2248\n1 .9 \u00d7\n1 0 6\n0. 6\ns \u2265\n1 .1 \u00d7\n1 0 5\n0. 2\ns >\n1 .3 \u00d7\n1 0 5\n11 s\n\u2248 8 .3 \u00d7\n1 0 5\n23 s\n\u2248 1 .3 \u00d7\n1 0 6\n0. 2 s ra n1 2 40 3 .5 \u00d7 1 0 8 \u2248 4 .2 \u00d7 1 0 8 10 m \u2265 3 .1 \u00d7 1 0 7 0. 5 s > 6 .7 \u00d7 1 0 7 15 m \u2248 2 .6 \u00d7 1 0 8 23 s \u2248 3 .9 \u00d7 1 0 8 0. 3 s ra n2 7 50 1 .5 \u00d7 1 0 8 \u2248 1 .2 \u00d7 1 0 8 8 m \u2265 1 .3 \u00d7 1 0 7 18 s > 1 .7 \u00d7 1 0 7 28 m \u2248 5 .5 \u00d7 1 0 7 59 s \u2248 1 .1 \u00d7 1 0 8 0. 3 s ra n4 4 60 1 .1 \u00d7 1 0 6 \u2248 1 .9 \u00d7 1 0 6 6 s \u2265 9 .5 \u00d7 1 0 4 8 s > 1 .3 \u00d7 1 0 5 52 s \u2248 3 .3 \u00d7 1 0 5 13 9 s \u2248 9 .1 \u00d7 1 0 5 0. 5 s\nwhich is similar to the function used by our approach. The size of XOR constraints k should be no more than half of the number of variables n, i.e., k \u2264 n/2. We found that XOR constraints start to fail as k << n/2. So in our experiments, k was chosen to be close to n/2. Since MBound can only check the bound and may return failure as the bound too close to the exact count, we implemented a binary search to find the best lower-bound verified by MBound. The results in Table 5 are the best lower-bounds and the running times of the whole binary search procedure. Though the lower-bounds are better than SampleCount, they are still around #F/10. Similar to our approach, the running times of MBound are also quite relevant to the size of #F .\nFor ApproxCount, we manually increased the value of \u201ccutoff\u201d as ApproxCount required. Note that ApproxCount calls exact model counter Cachet [27] and Relsat [20] after formula simplifications, so it sometimes returns the exact counts, such as blockmap 05 01, blockmap 05 02, 5step and tire-1. On Langford problems and DQMR networks problems, wrong approximations were provided. On other instances, the results show that STAC CNF usually outperforms ApproxCount.\nFor SampleTreeSearch, we used its default setting about the number of samples, which is a constant. The results show that it is very efficient and provides good approximations. Our approach only outperforms SampleTreeSearch on blockmap problems which consist of a large number of variables. However, there is a lack of analysis on the accuracy of the approximation of SampleTreeSearch, i.e., no explicit relation between the number of samples and the accuracy."}, {"heading": "7 Conclusion", "text": "In this paper, we propose a new hashing-based approximate algorithm with dynamic stopping criterion. Our approach has two key strengths: it requires only one satisfiability query for each cut, and it terminates once meeting the theoretical guarantee of accuracy. We implemented prototype tools for propositional logic formulas and SMT(BV) formulas. Extensive experiments demonstrate that our approach is efficient and promising. Despite that we are unable to prove the correctness of Equation (1), the experimental results fit it quite well. This phenomenon might be caused by some hidden properties of the hash functions. To fully understand these functions and their correlation with the model count of the hashed formula might be an interesting problem to the community. In addition, extending the idea in this paper to count solutions of other formulas is also a direction of future research."}], "references": [{"title": "Uniform generation of NP-witnesses using an NP-oracle", "author": ["M. Bellare", "O. Goldreich", "E. Petrank"], "venue": "Inf. Comput.,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2000}, {"title": "Hashing-based approximate probabilistic inference in hybrid domains", "author": ["V. Belle", "G.V. Broeck", "A. Passerini"], "venue": "In Proc. of UAI,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Interval estimation for a binomial proportion", "author": ["L.D. Brown", "T.T. Cai", "A. Dasgupta"], "venue": "Statistical Science,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2001}, {"title": "Boolector: An efficient SMT solver for bit-vectors and arrays", "author": ["R. Brummayer", "A. Biere"], "venue": "In Proc. of TACAS,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Distribution-aware sampling and weighted model counting for SAT", "author": ["S. Chakraborty", "D.J. Fremont", "K.S. Meel", "S.A. Seshia", "M.Y. Vardi"], "venue": "In Proc of AAAI,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Approximate probabilistic inference via word-level counting", "author": ["S. Chakraborty", "K.S. Meel", "R. Mistry", "M.Y. Vardi"], "venue": "In Proc. of AAAI,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}, {"title": "A scalable and nearly uniform generator of SAT witnesses", "author": ["S. Chakraborty", "K.S. Meel", "M.Y. Vardi"], "venue": "In Proc. of CAV,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "A scalable approximate model counter", "author": ["S. Chakraborty", "K.S. Meel", "M.Y. Vardi"], "venue": "In Proc. of CP,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Algorithmic improvements in approximate counting for probabilistic inference: From linear to logarithmic SAT calls", "author": ["S. Chakraborty", "K.S. Meel", "M.Y. Vardi"], "venue": "In Proc. of IJCAI,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2016}, {"title": "On probabilistic inference by weighted model counting", "author": ["M. Chavira", "A. Darwiche"], "venue": "Artif. Intell.,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2008}, {"title": "Approximate counting in SMT and value estimation for probabilistic programs", "author": ["D. Chistikov", "R. Dimitrova", "R. Majumdar"], "venue": "In Proc. of TACAS,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Probabilistic planning via heuristic forward search and weighted model counting", "author": ["C. Domshlak", "J. Hoffmann"], "venue": "J. Artif. Intell. Res. (JAIR),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2007}, {"title": "Embed and project: Discrete sampling with universal hashing", "author": ["S. Ermon", "C.P. Gomes", "A. Sabharwal", "B. Selman"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "Uniform solution sampling using a constraint solver as an oracle", "author": ["S. Ermon", "C.P. Gomes", "B. Selman"], "venue": "In Proc. UAI,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "Probabilistic symbolic execution", "author": ["J. Geldenhuys", "M.B. Dwyer", "W. Visser"], "venue": "In Proc. of ISSTA,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "From sampling to model counting", "author": ["C.P. Gomes", "J. Hoffmann", "A. Sabharwal", "B. Selman"], "venue": "In Proc. of IJCAI,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2007}, {"title": "Model counting: A new strategy for obtaining good bounds", "author": ["C.P. Gomes", "A. Sabharwal", "B. Selman"], "venue": "In Proc. of AAAI,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2006}, {"title": "Near-uniform sampling of combinatorial spaces using XOR constraints", "author": ["C.P. Gomes", "A. Sabharwal", "B. Selman"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2006}, {"title": "On computing minimal independent support and its applications to sampling and counting", "author": ["A. Ivrii", "S. Malik", "K.S. Meel", "M.Y. Vardi"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2016}, {"title": "Using CSP look-back techniques to solve real-world SAT instances", "author": ["R.J. Bayardo Jr.", "R. Schrag"], "venue": "In Proc. of AAAI,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1997}, {"title": "Monte-carlo approximation algorithms for enumeration problems", "author": ["R.M. Karp", "M. Luby", "N. Madras"], "venue": "J. Algorithms,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1989}, {"title": "Leveraging belief propagation, backtrack search, and statistics for model counting", "author": ["L. Kroc", "A. Sabharwal", "B. Selman"], "venue": "Annals of OR,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "Program analysis: from qualitative analysis to quantitative analysis", "author": ["S. Liu", "J. Zhang"], "venue": "In Proc. of ICSE,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2011}, {"title": "Constrained sampling and counting: Universal hashing meets SAT solving", "author": ["K.S. Meel", "M.Y. Vardi", "S. Chakraborty", "D.J. Fremont", "S.A. Seshia", "D. Fried", "A. Ivrii", "S. Malik"], "venue": "In Proceedings of Workshop on Beyond NP(BNP),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2016}, {"title": "On the hardness of approximate reasoning", "author": ["D. Roth"], "venue": "Artif. Intell.,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1996}, {"title": "Performing bayesian inference by weighted model counting", "author": ["T. Sang", "P. Beame", "H.A. Kautz"], "venue": "In Proc. of AAAI,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2005}, {"title": "Combining component caching and clause learning for effective model counting", "author": ["Tian Sang", "Fahiem Bacchus", "Paul Beame", "Henry A. Kautz", "Toniann Pitassi"], "venue": "In Proc. of SAT,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2004}, {"title": "A complexity theoretic approach to randomness", "author": ["M. Sipser"], "venue": "In Proc. of the 15th Annual ACM Symposium on Theory of Computing,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1983}, {"title": "Extending SAT solvers to cryptographic problems", "author": ["M. Soos", "K. Nohl", "C. Castelluccia"], "venue": "In Proc. of SAT,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2009}, {"title": "The complexity of approximate counting (preliminary version)", "author": ["L.J. Stockmeyer"], "venue": "In Proc. of the 15th Annual ACM Symposium on Theory of Computing,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1983}, {"title": "The complexity of enumeration and reliability problems", "author": ["L.G. Valiant"], "venue": "SIAM J. Comput.,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1979}, {"title": "Binomial confidence intervals and contingency tests: Mathematical fundamentals and the evaluation of alternative methods", "author": ["S. Wallis"], "venue": "Journal of Quantitative Linguistics,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2013}, {"title": "A new approach to model counting", "author": ["W. Wei", "B. Selman"], "venue": "In Proc. of SAT,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2005}, {"title": "Probable inference, the law of succession and statistical inference", "author": ["E.B. Wilson"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 1927}], "referenceMentions": [{"referenceID": 24, "context": "Its interesting applications in several fields include probabilistic inference [25,10], planning [12], combinatorial designs and software engineering [23,15].", "startOffset": 79, "endOffset": 86}, {"referenceID": 9, "context": "Its interesting applications in several fields include probabilistic inference [25,10], planning [12], combinatorial designs and software engineering [23,15].", "startOffset": 79, "endOffset": 86}, {"referenceID": 11, "context": "Its interesting applications in several fields include probabilistic inference [25,10], planning [12], combinatorial designs and software engineering [23,15].", "startOffset": 97, "endOffset": 101}, {"referenceID": 22, "context": "Its interesting applications in several fields include probabilistic inference [25,10], planning [12], combinatorial designs and software engineering [23,15].", "startOffset": 150, "endOffset": 157}, {"referenceID": 14, "context": "Its interesting applications in several fields include probabilistic inference [25,10], planning [12], combinatorial designs and software engineering [23,15].", "startOffset": 150, "endOffset": 157}, {"referenceID": 30, "context": "However, model counting is a canonical #P-complete problem, even for polynomial-time solvable problems like 2-SAT [31], thus presents fascinating challenges for both theoreticians and practitioners.", "startOffset": 114, "endOffset": 118}, {"referenceID": 23, "context": "Recently, hashing-based approximate counting achieves both strong theoretical guarantees and good scalability [24].", "startOffset": 110, "endOffset": 114}, {"referenceID": 27, "context": "The use of universal hash functions in counting problems began in [28,30], but the resulting algorithm scaled poorly in practice.", "startOffset": 66, "endOffset": 73}, {"referenceID": 29, "context": "The use of universal hash functions in counting problems began in [28,30], but the resulting algorithm scaled poorly in practice.", "startOffset": 66, "endOffset": 73}, {"referenceID": 7, "context": "A scalable approximate counter ApproxMC in [8] scales to large problem instances, while preserves rigorous approximation guarantees.", "startOffset": 43, "endOffset": 46}, {"referenceID": 12, "context": "ApproxMC has been extended to finite-domain discrete integration, with applications to probabilistic inference [13,5,2], and improved by designing efficient universal hash functions [19,6] and reducing the use of NP-oracle calls from linear to logarithmic [9].", "startOffset": 111, "endOffset": 119}, {"referenceID": 4, "context": "ApproxMC has been extended to finite-domain discrete integration, with applications to probabilistic inference [13,5,2], and improved by designing efficient universal hash functions [19,6] and reducing the use of NP-oracle calls from linear to logarithmic [9].", "startOffset": 111, "endOffset": 119}, {"referenceID": 1, "context": "ApproxMC has been extended to finite-domain discrete integration, with applications to probabilistic inference [13,5,2], and improved by designing efficient universal hash functions [19,6] and reducing the use of NP-oracle calls from linear to logarithmic [9].", "startOffset": 111, "endOffset": 119}, {"referenceID": 18, "context": "ApproxMC has been extended to finite-domain discrete integration, with applications to probabilistic inference [13,5,2], and improved by designing efficient universal hash functions [19,6] and reducing the use of NP-oracle calls from linear to logarithmic [9].", "startOffset": 182, "endOffset": 188}, {"referenceID": 5, "context": "ApproxMC has been extended to finite-domain discrete integration, with applications to probabilistic inference [13,5,2], and improved by designing efficient universal hash functions [19,6] and reducing the use of NP-oracle calls from linear to logarithmic [9].", "startOffset": 182, "endOffset": 188}, {"referenceID": 8, "context": "ApproxMC has been extended to finite-domain discrete integration, with applications to probabilistic inference [13,5,2], and improved by designing efficient universal hash functions [19,6] and reducing the use of NP-oracle calls from linear to logarithmic [9].", "startOffset": 256, "endOffset": 259}, {"referenceID": 16, "context": "An algorithm called MBound [17] only invokes satisfiability query once for each cut.", "startOffset": 27, "endOffset": 31}, {"referenceID": 20, "context": "These are called ( , \u03b4)-counters and ( , \u03b4)bound, respectively [21].", "startOffset": 63, "endOffset": 67}, {"referenceID": 0, "context": "[1] showed that almost uniform sampling from propositional constraints, a closely related problem to constrained counting, is solvable in probabilistic polynomial time with an NP oracle.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "Building on this, [8] proposed the first scalable approximate model counting algorithm ApproxMC for propositional formulas.", "startOffset": 18, "endOffset": 21}, {"referenceID": 5, "context": "Subsequently, [6] presented an approximate model counter that uses word-level hash functions, which directly leverage the power of sophisticated SMT solvers, though the framework of the probabilistic algorithm is similar to [8].", "startOffset": 14, "endOffset": 17}, {"referenceID": 7, "context": "Subsequently, [6] presented an approximate model counter that uses word-level hash functions, which directly leverage the power of sophisticated SMT solvers, though the framework of the probabilistic algorithm is similar to [8].", "startOffset": 224, "endOffset": 227}, {"referenceID": 7, "context": "In the current work, the family of hash functions in [8] is adopted, which was shown to be 3-independent in [18], and is revealed to possess better properties than expected by the experimental results and the theoretical analysis in the current work.", "startOffset": 53, "endOffset": 56}, {"referenceID": 17, "context": "In the current work, the family of hash functions in [8] is adopted, which was shown to be 3-independent in [18], and is revealed to possess better properties than expected by the experimental results and the theoretical analysis in the current work.", "startOffset": 108, "endOffset": 112}, {"referenceID": 7, "context": "For completeness, ApproxMC [8,11] is listed here as Algorithm 1.", "startOffset": 27, "endOffset": 33}, {"referenceID": 10, "context": "For completeness, ApproxMC [8,11] is listed here as Algorithm 1.", "startOffset": 27, "endOffset": 33}, {"referenceID": 5, "context": "The general algorithm in [6] is similar to Algorithm 1, but could cut the cell with dynamically determined proportion instead of the constant 12 , due to the word-level hash functions.", "startOffset": 25, "endOffset": 28}, {"referenceID": 8, "context": "[9] improves ApproxMCCore via binary search to reduce the number of enumeration queries from linear to logarithmic.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "A commonly used formula q\u00b1z1\u2212\u03b4 \u221a q(1\u2212q) t [3,32] is adopted, which is justified by the central limit theorem to compute the 1 \u2212 \u03b4 confidence interval.", "startOffset": 42, "endOffset": 48}, {"referenceID": 31, "context": "A commonly used formula q\u00b1z1\u2212\u03b4 \u221a q(1\u2212q) t [3,32] is adopted, which is justified by the central limit theorem to compute the 1 \u2212 \u03b4 confidence interval.", "startOffset": 42, "endOffset": 48}, {"referenceID": 7, "context": "This method is adopted by all previous hashingbased ( , \u03b4)-counters [8,11,6].", "startOffset": 68, "endOffset": 76}, {"referenceID": 10, "context": "This method is adopted by all previous hashingbased ( , \u03b4)-counters [8,11,6].", "startOffset": 68, "endOffset": 76}, {"referenceID": 5, "context": "This method is adopted by all previous hashingbased ( , \u03b4)-counters [8,11,6].", "startOffset": 68, "endOffset": 76}, {"referenceID": 6, "context": "A heuristic called leap-frogging to overcome this bottleneck was proposed in [7,8].", "startOffset": 77, "endOffset": 82}, {"referenceID": 7, "context": "A heuristic called leap-frogging to overcome this bottleneck was proposed in [7,8].", "startOffset": 77, "endOffset": 82}, {"referenceID": 33, "context": "The following interval [34]", "startOffset": 23, "endOffset": 27}, {"referenceID": 25, "context": "We considered a wide range of benchmarks from different domains: grid networks, plan recognition, DQMR networks, Langford sequences, circuit synthesis, random 3-CNF, logistics problems and program synthesis [26,22,8,6].", "startOffset": 207, "endOffset": 218}, {"referenceID": 21, "context": "We considered a wide range of benchmarks from different domains: grid networks, plan recognition, DQMR networks, Langford sequences, circuit synthesis, random 3-CNF, logistics problems and program synthesis [26,22,8,6].", "startOffset": 207, "endOffset": 218}, {"referenceID": 7, "context": "We considered a wide range of benchmarks from different domains: grid networks, plan recognition, DQMR networks, Langford sequences, circuit synthesis, random 3-CNF, logistics problems and program synthesis [26,22,8,6].", "startOffset": 207, "endOffset": 218}, {"referenceID": 5, "context": "We considered a wide range of benchmarks from different domains: grid networks, plan recognition, DQMR networks, Langford sequences, circuit synthesis, random 3-CNF, logistics problems and program synthesis [26,22,8,6].", "startOffset": 207, "endOffset": 218}, {"referenceID": 8, "context": "We compared our tools with ApproxMC2 [9] and SMTApproxMC [6] which are hashingbased ( , \u03b4)-counters.", "startOffset": 37, "endOffset": 40}, {"referenceID": 5, "context": "We compared our tools with ApproxMC2 [9] and SMTApproxMC [6] which are hashingbased ( , \u03b4)-counters.", "startOffset": 57, "endOffset": 60}, {"referenceID": 28, "context": "Both STAC CNF and ApproxMC2 use CryptoMiniSAT [29], an efficient SAT solver designed for XOR clauses.", "startOffset": 46, "endOffset": 50}, {"referenceID": 3, "context": "STAC BV and SMTApproxMC use the state-of-the-art SMT(BV) solver Boolector [4].", "startOffset": 74, "endOffset": 77}, {"referenceID": 8, "context": "2 which are also used in evaluation in previous works [9,6].", "startOffset": 54, "endOffset": 59}, {"referenceID": 5, "context": "2 which are also used in evaluation in previous works [9,6].", "startOffset": 54, "endOffset": 59}, {"referenceID": 15, "context": "Since our approach is not a ( , \u03b4)-counter in theory, we also compared STAC CNF with bounding counters (SampleCount [16], MBound [17]) and guarantee-less counters (ApproxCount [33], SampleTreeSearch [14]).", "startOffset": 116, "endOffset": 120}, {"referenceID": 16, "context": "Since our approach is not a ( , \u03b4)-counter in theory, we also compared STAC CNF with bounding counters (SampleCount [16], MBound [17]) and guarantee-less counters (ApproxCount [33], SampleTreeSearch [14]).", "startOffset": 129, "endOffset": 133}, {"referenceID": 32, "context": "Since our approach is not a ( , \u03b4)-counter in theory, we also compared STAC CNF with bounding counters (SampleCount [16], MBound [17]) and guarantee-less counters (ApproxCount [33], SampleTreeSearch [14]).", "startOffset": 176, "endOffset": 180}, {"referenceID": 13, "context": "Since our approach is not a ( , \u03b4)-counter in theory, we also compared STAC CNF with bounding counters (SampleCount [16], MBound [17]) and guarantee-less counters (ApproxCount [33], SampleTreeSearch [14]).", "startOffset": 199, "endOffset": 203}, {"referenceID": 26, "context": "Note that ApproxCount calls exact model counter Cachet [27] and Relsat [20] after formula simplifications, so it sometimes returns the exact counts, such as blockmap 05 01, blockmap 05 02, 5step and tire-1.", "startOffset": 55, "endOffset": 59}, {"referenceID": 19, "context": "Note that ApproxCount calls exact model counter Cachet [27] and Relsat [20] after formula simplifications, so it sometimes returns the exact counts, such as blockmap 05 01, blockmap 05 02, 5step and tire-1.", "startOffset": 71, "endOffset": 75}], "year": 2017, "abstractText": "Constrained counting is important in domains ranging from artificial intelligence to software analysis. There are already a few approaches for counting models over various types of constraints. Recently, hashing-based approaches achieve both theoretical guarantees and scalability, but still rely on solution enumeration. In this paper, a new probabilistic polynomial time approximate model counter is proposed, which is also a hashing-based universal framework, but with only satisfiability queries. A variant with a dynamic stopping criterion is also presented. Empirical evaluation over benchmarks on propositional logic formulas and SMT(BV) formulas shows that the approach is promising.", "creator": "LaTeX with hyperref package"}}}