{"id": "1707.00418", "review": {"conference": "aaai", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Jul-2017", "title": "Learning Deep Latent Spaces for Multi-Label Classification", "abstract": "multi - label classification is a practical yet challenging task in machine learning related fields, since neurons allow the prediction of more than one fuzzy category and each input instance. we propose a novel deep neural map ( dnn ) based model, canonical correlated autoencoder ( c2ae ), for solving this task. aiming at better relating feature and label type data for improved classification, we explicitly perform joint feature and label estimation by calculating a deep latent dependence, followed by the introduction of label - correlation chain loss function for recovering the predicted label outputs. our c2ae is achieved by integrating the dnn architectures of canonical model analysis and autoencoder, which allows end - to - end learning coefficient prediction without the ability helps exploit label dependency. moreover, our c2ae can be easily extended to address spatial learning problem with missing labels. our experiments on multiple datasets with arbitrary scales confirm the effectiveness and effectiveness of her proposed method, which is shown to perform favorably at state - of - the - art methods for multi - regression classification.", "histories": [["v1", "Mon, 3 Jul 2017 06:37:01 GMT  (611kb,D)", "http://arxiv.org/abs/1707.00418v1", "published in AAAI-2017"]], "COMMENTS": "published in AAAI-2017", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["chih-kuan yeh", "wei-chieh wu", "wei-jen ko", "yu-chiang frank wang"], "accepted": true, "id": "1707.00418"}, "pdf": {"name": "1707.00418.pdf", "metadata": {"source": "CRF", "title": "Learning Deep Latent Spaces for Multi-Label Classification", "authors": ["Chih-Kuan Yeh", "Wei-Chieh Wu", "Wei-Jen Ko", "Yu-Chiang Frank Wang"], "emails": ["jason6582@gmail.com,", "b01901162}@ntu.edu.tw,", "ycwang@citi.sinica.edu.tw"], "sections": [{"heading": "Introduction", "text": "With rich information presented in multimedia data, many real-world classification tasks require one to assign more than one label to each instance. For example, multiple types of objects in an image need to be annotated, or different identities need to be determined from an audio clip (Zhang and Zhou 2014). Thus, different from standard multi-class recognition problems (i.e., only one class label for each input data), multi-label classification typically requires additional efforts in extracting and describing the associated data/label information to produce satisfactory performances.\nBy dividing the original multi-label classification problem into multiple independent binary classification tasks, binary relevance (Tsoumakas and Katakis 2006) is a straightforward technique and solution, which has been widely applied by users in related fields. However, in addition to the concern of high computational costs, such techniques cannot identify the correlation between label information, which would limit the resulting prediction performance. As a result, methods proposed by (Read et al. 2011; Cheng, Hu\u0308llermeier, and \u2217- indicates equal contribution. Copyright c\u00a9 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\nDembczynski 2010) aim at exploiting the cross-label dependency by assuming label prior information. Unfortunately, since these approaches perform a series of classification for multi-label prediction, parallel implementation is not applicable if reducing computation loads is desirable.\nDeriving a latent label space with reduced dimensionality is also a popular technique for multi-label classification (Balasubramanian and Lebanon 2012; Tai and Lin 2012; Chen and Lin 2012; Bi and Kwok 2013; Hsu et al. 2009; Zhang and Schneider 2012; Zhou, Tao, and Wu 2012; Lin et al. 2014; Yu et al. 2014; Li and Guo 2015; Bhatia et al. 2015). Its goal is to transform the label space into a latent subspace, followed by the association between the projected input and label data for classification purposes. With a proper decoding process which maps the projected data back to the original label space, the task of multi-label prediction is achieved. Since the learning of such latent subspaces not only reduces the classification time, the correlation between the labels can be implicitly exploited. Instead of observing latent spaces with reduced dimensions, (Tsoumakas, Katakis, and Vlahavas 2011; Ferng and Lin 2013) proposed to derive high-dimensional label embedding space for performing the above task. Nevertheless, the above latent space learning algorithms can all be viewed as label embedding based approaches. Moreover, the ability to handle missing labels during the learning of multi-label classification models is also practical for real-world application like image annotation. Incomplete labeled data during training might result in noisy classifiers with insufficient prediction capability. While this is typically not well addressed in existing methods, (Wu et al. 2014) chose a transductive setting with label smoothness regularization, and (Wu, Lyu, and Ghanem 2015) approached the problem by formulating a convex quadratic matrix optimization problem.\nAmong the first to utilize neural network architectures, BP-MLL (Zhang and Zhou 2006) not only treated each output node as a binary classification task, and relied on the architecture itself to exploit the dependency across labels. Later, it was extended by (Nam et al. 2014) with additional deep neural networks (DNN) techniques. Some recent works proposed different loss functions (Gong et al. 2013) or architectures (Wei et al. 2014) for further improving the performance. For example, CNN-RNN (Wang et al. 2016) chose to learn a linear label embedding function, with label co-\nar X\niv :1\n70 7.\n00 41\n8v 1\n[ cs\n.L G\n] 3\nJ ul\n2 01\n7\noccurrence information observed by recurrent neural networks (RNN). However, since only linear embedding was considered, higher order dependency between different labels might not be successfully discovered.\nIn this paper, we present a novel DNN-based framework, Canonical-Correlated Autoencoder (C2AE), for multi-label classification. Different from most label embedding based methods which typically view label embedding and prediction as two separate tasks, our C2AE advances deep canonical correlation analysis (DCCA) and autoencoder to learn a feature-aware latent subspace for label embedding and multi-label classification. Moreover, with label-correlation aware loss functions introduced at the decoding outputs, our C2AE is able to better exploit cross-label dependency during both label embedding and prediction processes. The main contributions of this paper are highlighted as follows:\n\u2022 By utilizing and integrating the architectures of deep canonical correlation analysis and autoencoder, our Canonical-Correlated Autoencoder (C2AE) is among the first DNN-based label embedding frameworks for multilabel classification.\n\u2022 Our C2AE is able to perform feature-aware label embedding and label-correlation aware prediction. The former is realized by joint learning of DCCA and the encoding stage of autoencoder, while the latter is achieved by the introduced loss functions for the decoding outputs.\n\u2022 Without modifying the proposed architecture, our C2AE can be easily extended to handle missing label problems. Our experiments verify that we perform significantly better than state-of-the-art approaches on multi-label classification tasks with/without missing labels."}, {"heading": "Related Work", "text": "While binary relevance (Tsoumakas and Katakis 2006) is among the popular techniques for multi-label classification, the lack of sufficient ability to discover interdependency between labels would be its concern.\nTo address the above issue, approaches based on classifier chains were proposed. For example, probabilistic classifier chains (PCC) aim at capturing conditional label dependency via the product rule of probabilities (Cheng, Hu\u0308llermeier, and Dembczynski 2010). While beam search (Kumar et al. 2013) and advanced inference procedure (Dembczynski, Waegeman, and Hu\u0308llermeier 2012) were further extended from PCC, these approaches are typically computationally expensive, and cannot be easily extended to problems with a large number of labels.\nLabel embedding (LE) is another popular strategy for multi-label classification. It transforms the label vectors into a subspace with latent embedding of the corresponding information, and the correlation between labels can be implicitly described. With additional mapping (from the input vectors) and decoding (for prediction) stages derived for this latent label space, one can perform multi-label prediction with reduced computation costs (Hsu et al. 2009; Balasubramanian and Lebanon 2012; Tai and Lin 2012; Chen and Lin 2012; Zhang and Schneider 2012; Zhou,\nTao, and Wu 2012; Bi and Kwok 2013; Yu et al. 2014; Lin et al. 2014; Li and Guo 2015). For example, in (Hsu et al. 2009), the label embedding was obtained via random projections, while principal component based projections (e.g., principal label space transformation (PLST) (Tai and Lin 2012) and its conditional version (CPLST) (Chen and Lin 2012)) were later utilized. Variants of LE like (Lin et al. 2014), (Bhatia et al. 2015), and (Li and Guo 2015) are also available, which aim at improving the predictability and recoverability of proposed models. Recently, (Wang et al. 2016) presented CNN-RNN, which applied linear label embedding followed by recurrent neural networks (RNN) for better identifying the co-occurrence of labels.\nWe note that, existing LE approaches typically consider linear embedding functions, while some apply standard kernel functions (e.g., low-degree polynomial kernels) for nonlinear embedding. Moreover, only few methods jointly utilize the input feature space for label embedding (e.g., (Chen and Lin 2012; Lin et al. 2014; Li and Guo 2015)). In this paper, we advance deep neural networks for exploiting label correlation during the embedding process. In particular, we propose Canonical-Correlated Autoencoder (C2AE), which can be viewed as a feature-aware label embedding framework with ability in exploiting label interdependency during both embedding and prediction processes. We will detail our proposed DNN model in the following section."}, {"heading": "Our Proposed Method", "text": ""}, {"heading": "Canonical-Correlated Autoencoder (C2AE)", "text": "Let D = {(xi, yi)}Ni=1 = {X,Y} denote a set of d dimensional training instances X \u2208 IRd\u00d7N and the associated labels Y \u2208 {0, 1}m\u00d7N , where N and m are the numbers of instances and label attributes, respectively. By observing D, the goal of multi-label classification is to derive a proper learning model, so that the label y\u0302 of a test instance x\u0302 can be predicted accordingly.\nMotivated by label embedding and the recent developments in deep learning, we propose a novel DNN architecture of Canonical-Correlated Autoencoder (C2AE), as depicted in Figure 1. Our C2AE utilizes Deep Canonical Correlation Analysis (DCCA) and autoencoder structures, which learns a latent subspace from both feature and label domains for multi-label classification.\nAs illustrated in Figure 1, our C2AE (denoted by \u0398) integrates two effective DNN models (i.e., DCCA and autoencoder) with three mapping functions to be determined: feature mapping Fx, encoding function Fe, and decoding function Fd. During the training stage, the input of C2AE are the observed training instances X and their labels Y, while the recovered output is the label of interest Y (i.e., same as the input labels). Aiming at determining the latent space L, the DCCA component of our C2AE associates X and Y, while the autoencoder part enforces the output is recovered as Y. Thus, the objective function of C2AE can be formulated as follows:\n\u0398 = min Fx,Fe,Fd \u03a6(Fx,Fe) + \u03b1\u0393(Fe,Fd), (1)\nwhere \u03a6(Fx,Fe) and \u0393(Fe,Fd) denote the losses at the latent space and output of C2AE, respectively. And, we have the parameter \u03b1 balances between the above two types of loss functions.\nOnce the learning of our C2AE is complete, it can be easily applied for predicting the labels of test inputs. To be more precise, a test input x\u0302 will be first transformed into the derived latent space by Fx, followed by the decoding mapping of Fd for predicting its output label y\u0302 (i.e., y\u0302 = Fd(Fx(x\u0302))."}, {"heading": "Learning Deep Latent Spaces for Joint Feature & Label Embedding", "text": "We now discuss why we advance DCCA in our C2AE for feature and label-aware embedding. For the sake of completeness, we first briefly review the ideas of CCA and DCCA (Hotelling 1936; Andrew et al. 2013; Wang et al. 2015).\nAs a standard statistical technique for relating crossdomain data (e.g., input feature data X and their label data Y), CCA determines linear projection matrices W1 and W2 for each domain, aiming at observing a subspace in which the correlation of projected data is maximized (i.e., corr(WT1 X,W T 2 Y)). With the two linear projections replaced by DNNs, DCCA solves the same objective function with the DNN models learned/updated by gradient descent techniques (Andrew et al. 2013).\nTo determine \u03a6(Fx,Fe) in (1), we adapt the idea of (Kettenring 1971) and rewrite the correlation-based objective function as the following deep version:\nmin Fx,Fe \u2016Fx(X)\u2212 Fe(Y)\u20162F s.t. Fx(X)Fx(X)T = Fe(Y)Fe(Y)T = I, (2)\nwhere Fx(X) and Fe(Y) denote the transformed feature and label data in the derived latent space L, respectively.\nAnd, I \u2208 IRl\u00d7l is the identity matrix, where l is the dimension of the latent spaceL. As explained in (Kettenring 1971), the above identity constraint would make the above formulation equivalent to the standard CCA objection function of correlation maximization. Compared to the standard CCA optimization task, the above formulation allows us to calculate the network loss and the corresponding gradient descent function efficiently.\nBy solving Fx(X) and Fe(Y) in (2) with DNN models, we enforce the learned deep latent space to jointly associate feature and label data. It is worth noting that, while existing multi-label classification approaches based on label embedding (Tai and Lin 2012; Chen and Lin 2012; Lin et al. 2014; Li and Guo 2015) perform subspace learning using feature and/or label data, they typically learn an additional model relating feature data and the derived subspace for prediction purposes. In other words, the tasks of label embedding and multi-label prediction are performed separately, which might not be preferable. In our work, we not only utilize (2) for joint feature and label embedding with classification guarantees, our integration with autoencoder architectures further allows satisfactory recoverability for prediction purposes (see the following subsection for details)."}, {"heading": "Learning and Recovering Label-Correlated Outputs", "text": "With the DCCA component in our C2AE performing DCCA for joint feature and label embedding, we further advance the autoencoder in C2AE for recovering label outputs, with a particular goal of preserving cross-label dependency.\nInspired by (Zhang and Zhou 2006), we introduce a labelcorrelation aware loss function at the output of our C2AE, which is determined as follows:\n\u0393(Fe,Fd) = N\u2211 i=1 Ei\nEi = 1 |y1i ||y0i | \u2211\n(p,q)\u2208y1i\u00d7y 0 i\nexp(Fd(Fe(yi)) q \u2212 Fd(Fe(yi))p),\n(3) where y1i denotes the set of the positive labels in yi for the ith instance xi, and y0i is that of the negative labels. Given the input xi, Fd(Fe(xi))p returns the pth entry of the C2AE output. Thus, minimizing the above loss function is equivalent to maximizing the prediction outputs of all positivenegative label attribute pairs, which implicitly enforces the preservation of label co-occurrence information. If standard mean square error or cross-entropy losses are considered, such label dependency cannot be successfully identified.\nWith the above loss function, our C2AE integrating DCCA and autoencoder can be viewed as an end-to-end DNN, which performs joint feature/label embedding and label-correlate aware prediction in a unified model. To be more precise, we are able to learn feature embedding Fx, label embedding Fe, and label prediction Fd in a unified framework. As noted earlier, most existing linear or nonlinear label-embedding based approaches derive the above models separately with no performance correlation guarantees. Later in our experiments, we will verify the effectiveness of our approach over such methods.\nLearning from Data with Missing Labels\nAs highlighted earlier, our C2AE can be further extended to multi-label classification problems with missing labels. That is, we need to learn a robust C2AE model, when missing labels during the training stage are expected.\nTo solve this challenging yet practical task, we now easily apply a more general setting for determining the loss function for our C2AE. More specifically, for an instance with positive, negative, and some missing label attributes, we determine the loss function of (3) by calculating the losses derived from known label pairs only (i.e, available positivenegative label pairs). This would make our C2AE robust to missing labels, and exhibits sufficient abilities in exploiting the label dependency from the known label attributes.\nIn addition to extending our loss function at the output layer of C2AE for handling data with missing labels, we also perform a simple preprocessing stage for such data before feeding them into our network. To be more precise, we set the positive labels in an instance to be 1, the missing labels to be 0, and the negative labels to be \u2212 |y\n1 i | |y0i |\nfor keeping the average of the labels to 0. This is to guarantee that the missing labels would not be fed into the DNN model since its value is set to 0, which effectively suppresses the noise (coming from the missing labels) to be mapping into the latent space."}, {"heading": "Optimization", "text": "To learn the model of C2AE, we need to solve the optimization problem of (1), in which the loss terms \u03a6(Fx,Fe) and \u0393(Fe,Fd) are calculated at the latent space and the output of C2AE, respectively.\nSimilar to the derivation of existing DNN models, we apply the technique of gradient descent for each loss term for updating the corresponding network parameters. As shown in Figure 1, the gradient of \u03a6(Fx,Fe) updates the feature mapping Fx and encoding Fe, while that of \u0393(Fe,Fd) updates both encoding Fe and decoding functions Fd.\nTo calculate the gradient term of \u03a6(Fx,Fe), we reformulate (2) with the aid of Lagrange multipliers:\n\u03a6(Fx,Fe) = Tr(C1 TC1) + \u03bbTr(C2 TC2 + C3 TC3),\nwhere C1 = Fx(X)\u2212 Fe(Y) C2 = Fx(X)Fx(X)\nT \u2212 I C3 = Fe(Y)Fe(Y)\nT \u2212 I. Thus, the gradient of \u03a6(Fx,Fe) with respect to Fx(X) and Fe(Y) can be derived as:\n\u2202\u03a6(Fx,Fe)\n\u2202Fx(X) = 2C1 + 4\u03bbFx(X)C2, (4)\n\u2202\u03a6(Fx,Fe)\n\u2202Fe(Y) = 2C1 + 4\u03bbFe(X)C3, (5)\nNext, we discuss how to calculate the gradient of \u0393(Fe,Fd) (as determined in (3)) with respect to each\nAlgorithm 1: Learning of C2AE Input: Feature matrix X, label matrix Y, parameter \u03b1,\nand dimension l of the latent space Output: Fx, Fd, and Fe Randomly initialize Fx, Fd, Fe. repeat\nRandomly select a batch of data S[X] and S[Y] Define the loss function by (1) Perform gradient descent on Fd by (6) Perform gradient descent on Fx by (4) Perform gradient descent on Fe by (5) and (6)\nuntil Converge\nFd(Fe(xi)) j . For simplicity, we let cji = Fd(Fe(yi)) j , and thus the above gradient can be derived as follows:\n\u2202\u0393(Fe,Fd)\n\u2202cji = N\u2211 i=1 \u2202Ei \u2202cji\n\u2202Ei \u2202cji =  \u2212 1 |y1i ||y0i | \u2211 q\u2208y0i exp(\u2212(cji \u2212 c q i )), if j \u2208 y 1 i 1\n|y1i ||y0i | \u2211 p\u2208y1i exp(\u2212(cpi \u2212 c j i )), if j \u2208 y 0 i ,\n(6) where y1i denotes the set of the positive labels in yi for the ith instance xi, and y0i is that of the negative labels.\nWith the above derivations, we can learn our C2AE by gradient descent, and the pseudo code is summarized in Algorithm 1. Once the learning of C2AE is complete, label prediction of a test input x\u0302 can be easily achieved by rounding y\u0302 = Fd(Fx(x\u0302))."}, {"heading": "Experiments", "text": ""}, {"heading": "Datasets and Settings", "text": "To evaluate the performance of our proposed method, we consider the following datasets for experiments: iaprtc12, ESPGame, mirflickr, tmc2007, and NUS-WIDE. The first three datasets are image datasets used in (Guillaumin et al. 2009), where 1000-dimensional Bag-of-Words features (based on SIFT) are extracted. We note that tmc2007 is a large-scale text dataset downloaded from Mulan (Tsoumakas et al. 2011), and NUS-WIDE is a large-scale image dataset typically applied for image annotation tasks. The details of each dataset are listed in Table 1. For NUS-WIDE, we follow the setting of (Gong et al. 2013) by discarding\nthe instances with no positive labels and randomly select 150,000 instances for training and the remaining for testing. For fair comparisons with other CNN-based methods, we extract 4096-dimensional fc-7 feature for NUS-WIDE using a pre-trained AlexNet model.1\nFor the architecture of our C2AE, we have Fx composed of 2 layers of fully connected layers, while Fd and Fe are both single fully connected layer structures. For each fully connected layer, a total of 512 neurons are deployed. A leaky ReLU activation function is considered, while the batch size is fixed as 500. To select the parameters for C2AE, we randomly hold 1/6 of our training data for validation (with \u03b1 selected from [0.1, 10] and \u03bb fixed as 0.5). We also perform the same validation process for selecting the parameters (including the threshold for predicting the final labels) for other methods to be compared in our experiments. As for the evaluation metrics, we consider micro-F1 and macro-F1 (Tang, Rajan, and Narayanan 2009).\nComparisons with Label Embedding based Approaches We first consider the approaches based on label embedding for comparisons: Conditional Principal Label Space Transformation (CPLST) (Chen and Lin 2012), Feature-aware Implicit Label space Encoding (FaIE) (Lin et al. 2014), Low rank Empirical risk minimization for Multi-Label Learning (LEML) (Yu et al. 2014), Sparse Local Embeddings for Extreme Multi-label Classification (SLEEC) (Bhatia et al. 2015), and the baseline method of partial binary relevance (PBR) (Chen and Lin 2012). In addition, we replace the linear regressors in CPLST and FAIE by DNN regressors, and\n1The experimental code implemented in matlab can be found at https://github.com/yankeesrules/C2AE.\ndenote such methods as Deep CPLST and Deep FAIE. Figure 2 illustrates and compares the performances of the above methods, in which the horizontal axis denotes the ratio of the latent space dimension (l/m). From this figure, we see that our C2AE performed favorably against all label embedding methods (with and without DNN introduced) in most cases, which supports our exploitation of nonlinear joint feature and label embedding for multi-label classification. We also see that, with the introduction of DNN architectures for CPLST and FAIE, their DNN versions were not able to achieve comparable performances as ours did. This further verifies the effectiveness of our C2AE in learning deep latent spaces from both feature and label data, and with additional abilities in identifying label co-occurrences.\nTo further verify the effectiveness of our derived deep latent space, we consider several example labels from IAPRTC-12, and list their corresponding neighboring ones in Figure 3. From this figure, we see that the neighboring labels observed in the latent space exhibit highly correlated semantic information. This confirms our C2AE in sufficiently exploiting label dependency during the learning process."}, {"heading": "Comparisons with DNN-based Approaches", "text": "We further compare our C2AE with recent DNN-based methods for multi-label classification. In addition of a basline method of DNN (as a deep version of binary relevance with the loss function of BCE (Nam et al. 2014) and BP-MLL (Zhang and Zhou 2006)), we have (1) WARP (Gong et al. 2013), which is a CNN network with the WARP loss function, and (2) CNN-RNN (Wang et al. 2016), which is a state-of-the-art DNN combining CNN and RNN for multi-label prediction.\nThe large-scale image annotation dataset of NUS-WIDE is applied for evaluation and comparisons. As noted earlier, for fair comparison purposes, we extract 4096-dimensional fc7 features from NUS-WIDE using a pre-trained AlexNet network (Krizhevsky, Sutskever, and Hinton 2012) as the feature inputs for C2AE and other methods. And, since existing DNN approaches do not perform dimension reduction from the label space, we fix our dimension reduction ratio l/m as 1. The metrics of per-class and overall precision (C-P and O-P), including the recall scores (C-R and O-R) are considered in accordance with (Gong et al. 2013; Wang et al. 2016).\nTable 2 lists and compares the classification performances of different DNN-based methods. It can be seen that DNNBCE and CNN-WARP did not exhibit abilities in exploiting label co-occurrence information, so they were not able to achieve satisfactory performances. While such capabilities were introduced in BP-MLL and CNN-RNN via linear embedding, our approach still produced promising performances among all DNN methods considered. This supports our use of DNN models in both feature/label embedding and label correlation exploitation.\nTo make additional remarks on the computation time, our C2AE only takes 10-15 minutes to perform training on NUSWIDE using a titan X GPU, which is much more efficient than training other DNN-based approaches, especially those require the learning of RNN. Nevertheless, our C2AE not only achieves satisfactory classification performance, it is also an efficiently preferable DNN model to consider."}, {"heading": "Performance Evaluation with Missing Labels", "text": "Finally, we handle the challenging task in which missing labels are presented in the training set. To conduct the experiments, we vary the label missing rate from 10% to 50%, while enforcing at least one positive label to be preserved for each instance. Three state-of-the-art approaches are now considered: (1) LEML, (2) Multi-label Learning with Miss-\ning Labels (MLML) (Wu et al. 2014), and (3) ML-MG (i.e., Multi-label Learning with Missing Labels Using a Mixed Graph (ML-PGD) (Wu, Lyu, and Ghanem 2015)). We show the performance comparisons in Figure 4, in which our C2AE consistently and remarkably performed against other approaches. It is worth noting that, existing solutions typically learn linear regressors as their predictors, with additional regularization to handle missing labels. Our C2AE uniquely performs an end-to-end learning with joint feature and label embedding. Its effectiveness for multi-label classification and robustness to missing label problems can be successfully verified by the above experiments."}, {"heading": "Conclusion", "text": "We proposed Canonical Correlated Autoencoder (C2AE) for solving the task of multi-label classification. By uniquely integrating DCCA and autoencoder in a unified DNN model, we are able to perform joint feature and label embedding for relating such cross-domain data. With label-correlation sensitive loss functions introduced at the outputs of C2AE, additional ability of exploiting cross-label dependency is further introduced into our learning model. In the experiments, we showed that our C2AE not only performed favorably against baseline and state-of-the-art methods on multiple datasets, we further confirmed that our C2AE can be easily applied for learning tasks with varying amounts of missing labels. Thus, the effectiveness and robustness of our proposed method can be successfully verified."}, {"heading": "Acknowledgements", "text": "This work was supported in part by the Ministry of Science and Technology of Taiwan under Grant MOST105-2221-E001-028-MY2."}], "references": [{"title": "J", "author": ["G. Andrew", "R. Arora", "Bilmes"], "venue": "A.; and Livescu, K.", "citeRegEx": "Andrew et al. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "and Lebanon", "author": ["K. Balasubramanian"], "venue": "G.", "citeRegEx": "Balasubramanian and Lebanon 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "Sparse local embeddings for extreme multi-label classification", "author": ["Bhatia"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Bhatia,? \\Q2015\\E", "shortCiteRegEx": "Bhatia", "year": 2015}, {"title": "J", "author": ["W. Bi", "Kwok"], "venue": "T.-Y.", "citeRegEx": "Bi and Kwok 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "and Lin", "author": ["Chen", "Y.-N."], "venue": "H.-T.", "citeRegEx": "Chen and Lin 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "K", "author": ["W. Cheng", "E. H\u00fcllermeier", "Dembczynski"], "venue": "J.", "citeRegEx": "Cheng. H\u00fcllermeier. and Dembczynski 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "An analysis of chaining in multi-label classification", "author": ["Waegeman Dembczynski", "K. H\u00fcllermeier 2012] Dembczynski", "W. Waegeman", "E. H\u00fcllermeier"], "venue": null, "citeRegEx": "Dembczynski et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Dembczynski et al\\.", "year": 2012}, {"title": "and Lin", "author": ["Ferng", "C.-S."], "venue": "H.-T.", "citeRegEx": "Ferng and Lin 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Deep convolutional ranking for multilabel image annotation", "author": ["Gong"], "venue": "arXiv preprint arXiv:1312.4894", "citeRegEx": "Gong,? \\Q2013\\E", "shortCiteRegEx": "Gong", "year": 2013}, {"title": "Tagprop: Discriminative metric learning in nearest neighbor models for image autoannotation", "author": ["Guillaumin"], "venue": "IEEE 12th international conference on computer vision,", "citeRegEx": "Guillaumin,? \\Q2009\\E", "shortCiteRegEx": "Guillaumin", "year": 2009}, {"title": "Multi-label prediction via compressed sensing", "author": ["Hsu"], "venue": "In NIPS,", "citeRegEx": "Hsu,? \\Q2009\\E", "shortCiteRegEx": "Hsu", "year": 2009}, {"title": "J", "author": ["Kettenring"], "venue": "R.", "citeRegEx": "Kettenring 1971", "shortCiteRegEx": null, "year": 1971}, {"title": "G", "author": ["A. Krizhevsky", "I. Sutskever", "Hinton"], "venue": "E.", "citeRegEx": "Krizhevsky. Sutskever. and Hinton 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "A", "author": ["A. Kumar", "S. Vembu", "Menon"], "venue": "K.; and Elkan, C.", "citeRegEx": "Kumar et al. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "and Guo", "author": ["X. Li"], "venue": "Y.", "citeRegEx": "Li and Guo 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Large-scale multi-label text classificationrevisiting neural networks", "author": ["Nam"], "venue": "In Joint European Conference on Machine Learning and Knowledge Discovery in Databases,", "citeRegEx": "Nam,? \\Q2014\\E", "shortCiteRegEx": "Nam", "year": 2014}, {"title": "Classifier chains for multi-label classification. Machine learning 85(3):333\u2013359", "author": ["Read"], "venue": null, "citeRegEx": "Read,? \\Q2011\\E", "shortCiteRegEx": "Read", "year": 2011}, {"title": "and Lin", "author": ["F. Tai"], "venue": "H.-T.", "citeRegEx": "Tai and Lin 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "V", "author": ["L. Tang", "S. Rajan", "Narayanan"], "venue": "K.", "citeRegEx": "Tang. Rajan. and Narayanan 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "and Katakis", "author": ["G. Tsoumakas"], "venue": "I.", "citeRegEx": "Tsoumakas and Katakis 2006", "shortCiteRegEx": null, "year": 2006}, {"title": "Mulan: A java library for multi-label learning", "author": ["Tsoumakas"], "venue": "Journal of Machine Learning Research 12(Jul):2411\u20132414", "citeRegEx": "Tsoumakas,? \\Q2011\\E", "shortCiteRegEx": "Tsoumakas", "year": 2011}, {"title": "Random k-labelsets for multilabel classification", "author": ["Katakis Tsoumakas", "G. Vlahavas 2011] Tsoumakas", "I. Katakis", "I. Vlahavas"], "venue": "IEEE Transactions on Knowledge and Data Engineering", "citeRegEx": "Tsoumakas et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Tsoumakas et al\\.", "year": 2011}, {"title": "On deep multi-view representation learning", "author": ["Wang"], "venue": "In Proc. of the 32st Int. Conf. Machine Learning", "citeRegEx": "Wang,? \\Q2015\\E", "shortCiteRegEx": "Wang", "year": 2015}, {"title": "Cnn-rnn: A unified framework for multi-label image classification", "author": ["Wang"], "venue": "arXiv preprint arXiv:1604.04573", "citeRegEx": "Wang,? \\Q2016\\E", "shortCiteRegEx": "Wang", "year": 2016}, {"title": "Cnn: Single-label to multilabel", "author": ["Wei"], "venue": "arXiv preprint arXiv:1406.5726", "citeRegEx": "Wei,? \\Q2014\\E", "shortCiteRegEx": "Wei", "year": 2014}, {"title": "Multi-label learning with missing labels", "author": ["Wu"], "venue": "In ICPR,", "citeRegEx": "Wu,? \\Q2014\\E", "shortCiteRegEx": "Wu", "year": 2014}, {"title": "Ml-mg: Multi-label learning with missing labels using a mixed graph", "author": ["Lyu Wu", "B. Ghanem 2015] Wu", "S. Lyu", "B. Ghanem"], "venue": "In Proceedings of the IEEE International Conference on Computer Vision,", "citeRegEx": "Wu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2015}, {"title": "I", "author": ["H.-F. Yu", "P. Jain", "P. Kar", "Dhillon"], "venue": "S.", "citeRegEx": "Yu et al. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "and Schneider", "author": ["Y. Zhang"], "venue": "J.", "citeRegEx": "Zhang and Schneider 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "and Zhou", "author": ["Zhang", "M.-L."], "venue": "Z.-H.", "citeRegEx": "Zhang and Zhou 2006", "shortCiteRegEx": null, "year": 2006}, {"title": "and Zhou", "author": ["Zhang", "M.-L."], "venue": "Z.-H.", "citeRegEx": "Zhang and Zhou 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Compressed labeling on distilled labelsets for multilabel learning. Machine Learning 88(1-2):69\u2013126", "author": ["Tao Zhou", "T. Wu 2012] Zhou", "D. Tao", "X. Wu"], "venue": null, "citeRegEx": "Zhou et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2012}], "referenceMentions": [], "year": 2017, "abstractText": "Multi-label classification is a practical yet challenging task in machine learning related fields, since it requires the prediction of more than one label category for each input instance. We propose a novel deep neural networks (DNN) based model, Canonical Correlated AutoEncoder (C2AE), for solving this task. Aiming at better relating feature and label domain data for improved classification, we uniquely perform joint feature and label embedding by deriving a deep latent space, followed by the introduction of label-correlation sensitive loss function for recovering the predicted label outputs. Our C2AE is achieved by integrating the DNN architectures of canonical correlation analysis and autoencoder, which allows end-to-end learning and prediction with the ability to exploit label dependency. Moreover, our C2AE can be easily extended to address the learning problem with missing labels. Our experiments on multiple datasets with different scales confirm the effectiveness and robustness of our proposed method, which is shown to perform favorably against state-of-the-art methods for multi-label classification.", "creator": "LaTeX with hyperref package"}}}