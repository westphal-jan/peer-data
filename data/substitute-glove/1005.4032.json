{"id": "1005.4032", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-May-2010", "title": "Combining Multiple Feature Extraction Techniques for Handwritten Devnagari Character Recognition", "abstract": "In this discarded all rather an OCR four Handwritten Devnagari Characters. Basic elements although recognized by auditory classifier. We have variety four feature filtration strategies establish, bisects, figure feature, owns license histogram different straight direction elaborate background. Shadow images are computed globally next introduces image because centered segment, group separate histogram typical and line look features are calculations by boundaries the portrayed gives having other focusing. Weighted majority referendum storytelling exists to took elements way classification decision permit taking four Multi Layer Perceptron (MLP) operating pronoun. On activism while similar dataset has 16:23 extracts both overall representation rate observed is 134. nearly% in me consider top third ways results. This method refers 2.5 put few recent methods other Handwritten Devnagari Character Recognition most it has having observed that most effective has ca success compared others types combining.", "histories": [["v1", "Fri, 21 May 2010 17:57:50 GMT  (420kb)", "http://arxiv.org/abs/1005.4032v1", "6 pages, 8-10 December 2008"]], "COMMENTS": "6 pages, 8-10 December 2008", "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["sandhya arora", "debotosh bhattacharjee", "mita nasipuri", "dipak kumar basu", "mahantapas kundu"], "accepted": false, "id": "1005.4032"}, "pdf": {"name": "1005.4032.pdf", "metadata": {"source": "CRF", "title": "Combining Multiple Feature Extraction Techniques for Handwritten Devnagari Character Recognition", "authors": ["Sandhya Arora", "Debotosh Bhattacharjee", "Mita Nasipuri", "Dipak Kumar Basu", "Mahantapas Kundu"], "emails": ["sandhyabhagat@yahoo.com"], "sections": [{"heading": null, "text": "978-1-4244-2806-9/08/$25.00\u00a9 2008 IEEE\nIndex Terms\u2014 Chain code features, Intersection features, Neural networks, Shadow features, Weighted majority voting technique\nI. INTRODUCTION Although there are many scripts and languages in India but not much research is done for the recognition of handwritten Indian characters. There are many pieces of work reported towards handwritten recognition of Roman, Japanese, Chinese and Arabic scripts. In this paper, we propose a system for the recognition of off-line handwritten Devnagari characters.\nDevnagari is third most widely used script, used for several major languages such as Hindi, Sanskrit, Marathi and Nepali, and is used by more than 500 million people. Unconstrained Devnagari writing is more complex than English cursive due to the possible variations in the order, number, direction and shape of the constituent strokes. Devnagari script has 50 characters which can be written as individual symbols in a word (some shown in figure 1). Devnagari Character recognition is complicated by presence of multiple loops, conjuncts, upper and lower modifiers and the number of disconnected and multistroke characters [19], in a word where all characters are connected through header line. Modifiers make Optical Character recognition (OCR) with Devnagari script very challenging. OCR is further complicated by\ncompound characters that make character separation and identification very difficult.\nAlthough first research report on handwritten Devnagari characters was published in 1977 [8] but not much research work is done after that. At present researchers have started to work on handwritten Devnagari characters and few research reports are published recently. Hanmandlu and Murthy [9, 21] proposed a Fuzzy model based recognition of handwritten Hindi numerals and characters and they obtained 92.67% accuracy for Handwritten Devnagari numerals and 90.65% accuracy for Handwritten Devnagari characters. Bajaj et al [10] employed three different kinds of features namely, density features, moment features and descriptive component features for classification of Devnagari Numerals. They proposed multi-classifier connectionist architecture for increasing the recognition reliability and they obtained 89.6% accuracy for handwritten Devnagari numerals. Kumar and Singh [11] proposed a Zernike moment feature based approach for Devnagari handwritten character recognition. They used an artificial neural network for classification. Sethi and Chatterjee [12] proposed a decision tree based approach for recognition of constrained hand printed Devnagari characters using primitive features. Bhattacharya et al [13] proposed a MultiLayer Perceptron (MLP) neural network based classification approach for the recognition of Devnagari handwritten numerals and obtained 91.28% results. N. Sharma and U. Pal [5] proposed a directional chain code features based quadratic classifier and obtained 80.36% accuracy for handwritten Devnagari characters and 98.86% accuracy for handwritten Devnagari numerals. In most of the works reported above, multiple classifier combination has not been reported for handwritten Devnagari characters. Most of them are based on single classifier or reported for handwritten Devnagari numerals. In this paper we present the results of multiple classifier combination for offline handwritten Devnagari character recognition.\n978-1-4244-2806-9/08/$25.00\u00a9 2008 IEEE\nThis character recognition technique uses features obtained from Shadow, intersection and chain code histogram. Basic methodology, preprocessing, feature extraction is discussed in section 2.The recognition classifier and its combination is discussed in section 3. Results obtained after application of the technique on handwritten Devnagari characters are shown in section 4.\nII. PROPOSED METHOD In our proposed method, we are first performing scaling of character bitmap and after that we are extracting three different features. First, 32 intersection features are extracted after performing thinning, generating one pixel wide skeleton of character image and segmenting the image into 16 segments. Second, 16 shadow features are extracted from eight octants of the character image. Third, 200 chain code histogram features are obtained by first detecting the contour points of original scaled character image, and dividing the contour image into 25 segments. For each segment chain code histogram features are obtained."}, {"heading": "A.. Conversion of Handwritten Character to Bitmapped", "text": "Binary Images In images, background is not always of same contrast value. For this, we designed the Dynamic Threshold Value Identification algorithm. The goal of this algorithm is to distinguish between image pixels that belong to text and those that belong to the background. The algorithm mentioned below is applied on gray scale images:-\na) Take the threshold to be 128(Mid value of 0 to 255).\nb) Take all the pixels with grayscale value above 128 as background and all those with value below 128 as foreground.\nc) Find the mean grayscale values of background pixels and foreground pixels.\nd) Find the average of both mean values and make this the new threshold.\ne) Go back to step (b) and continue this process of refining the threshold till the change of the threshold from one iteration to next becomes less than 2%."}, {"heading": "B. Scaling of the binary character images", "text": "Each character image is first enclosed in a tight fit rectangular boundary. The portion of the image outside this boundary is discarded. The selected portion of the character image is then scaled to the size 100 \u00d7 100 pixel using affine\n978-1-4244-2806-9/08/$25.00\u00a9 2008 IEEE\ntransformation [16]. For smoothing the contours of the character images and also for filling in some holes, we perform some morphological operations like closing and dilation on the character image."}, {"heading": "C. Feature Extraction", "text": "In the following we give a brief description of the three feature sets used in our proposed multiple classifier system. Shadow features are extracted from scaled bitmapped character image. Chain code histogram features are extracted by chain coding the contour points of the scaled character bitmapped image. Intersection features are extracted from scaled, thinned one pixel wide skeleton of character image.\nShadow Features of character-- For computing shadow features [20], the rectangular boundary enclosing the character image is divided into eight octants, for each octant shadow of character segment is computed on two perpendicular sides so a total of 16 shadow features are obtained. Shadow is basically the length of the projection on the sides as shown in figure 3. These features are computed on scaled image.\nChain Code Histogram of Character Contour-- Given a scaled binary image, we first find the contour points of the character image. We consider a 3 \u00d7 3 window surrounded by the object points of the image. If any of the 4-connected neighbor points is a background point then the object point (P), as shown in figure 4 is considered as contour point.\nThe contour following procedure uses a contour representation called \u201cchain coding\u201d that is used for contour following proposed by Freeman [22], shown in figure 5a. Each pixel of the contour is assigned a different code that indicates the direction of the next pixel that belongs to the contour in some given direction. Chain code provides the points in relative position to one another, independent of the coordinate system. In this methodology of using a chain coding of connecting neighboring contour pixels, the points and the outline coding are captured. Contour following procedure may proceed in clockwise or in counter clockwise direction. Here, we have chosen to proceed in a clockwise direction.\nThe chain code for the character contour will yield a smooth, unbroken curve as it grows along the perimeter of the character and completely encompasses the character. When there is multiple connectivity in the character, then there can be multiple chain codes to represent the contour of the character. We chose to move with minimum chain code number first.\nWe divide the contour image in 5 \u00d7 5 blocks. In each of these blocks, the frequency of the direction code is computed and a histogram of chain code is prepared for each block. Thus for 5 \u00d7 5 blocks we get 5 \u00d7 5 \u00d7 8 = 200 features for recognition.\nFinding Intersection/Junctions in character-- An intersection, also referred to as a junction, is a location where the chain code goes in more than a single direction in an 8-connected neighborhood (Fig-6). Thinned and scaled character image is divided into 16 segments each of size 25 \u00d7 25 pixels wide. For each segment the number of open end points and junctions are calculated. Intersection point is defined as a pixel point which has more than two neighboring pixels in 8-connectivity while an open end has exactly one neighbor pixel. Intersection points are unique for a character in different segment. Thus the number of 32 features within the 16 constituent segments of\n978-1-4244-2806-9/08/$25.00\u00a9 2008 IEEE\nthe character image are collected, out of which first 16 features represents the number of open ends and rest 16 features represents number of junction points within a segment. These features are observed after image thinning and scaling as without thinning of the character image there will be multiple open end points and multiple junction points within a segment. For thinning standard algorithm [15] is used. This algorithm does not generate one-pixel wide skeleton character image and results in redundant pixels so we designed certain masks [17] so that after application of these masks some image pixels are removed so finally we get these entire characters one pixel wide. Thinned character images are shown in figure-7. Scaling is done as we are dividing the character image into fixed size segments which is not possible without fixing image size.\nIntersection feature calculated for this character image shown in figure-8, is 1001 0000 0000 0020 0010 0010 0010 0000, where 1001 0000 0000 0020 is the information of open end points and 0010 0010 0010 0000 is the information of junction points in each segment.\nStraight Lines Fitting for Character\u2014A straight line y=ai+bix is uniquely defined by two parameters: the slope bi and the intercept ai. Given a thinned and scaled binary image, we segmented it into 16 segments. For each segment image a straight line was fitted using LMS method of line fitting and calculated ai and bi as follows :-\nai = ( \u2211xiyi* \u2211 xi - \u2211 xi2 * \u2211 yi ) / ( \u2211 xi* \u2211 xi \u2013 N *\u2211 xi2 )\nbi= ( \u2211xiyi* N - \u2211 xi * \u2211 yi ) / ( N * \u2211 xi2 \u2013\u2211 xi* \u2211 xi )\nIntercept feature can be used directly but using slope feature directly has a drawback related to the continuity of the representation. Straight line with slopes approaching +. And -.\nHas a very similar orientation but obviously, would be represented with extremely different values, so we used two features f1 and f2 based on slope, where :\nf1 = 2 * bi / ( 1 + bi2 )\nf2 = ( 1 - bi2 ) / ( 1 + bi2 )\nSo total calculated line fitting based features are 48 for a 16 segmented image out of which 16 are ai values, 16 are f1 values and 16 are f2 values.\nIII. DEVNAGARI CHARACTER RECOGNITION We used the same MLP with 3 layers including one hidden\nlayer for four different feature sets consisting of 32 intersection features, 16 shadow features, 48 line fitting based features and 200 chain code histogram features. The experimental results obtained while using these features for recognition of handwritten Devnagari characters is presented in the next section. At this stage all characters are noncompound, single characters so no segmentation is required.\nThe classifier is trained with standard Backpropagation [14]. It minimizes the sum of squared errors for the training samples by conducting a gradient descent search in the weight space. As activation function we used sigmoid function. Learning rate and momentum term are set to 0.8 and 0.7 respectively. As activation function we used the sigmoid function. Numbers of neurons in input layer of MLPs are 32, 16, 48 or 200, for intersection features, shadow features, line fitting features and chain code histogram features respectively. Number of neurons in Hidden layer is not fixed, we experimented on the values between 20-70 to get optimal result and finally it was set to 20, 30,40 and 70 for intersection features, shadow features, line fitting features and chain code histogram features respectively. The output layer contained one node for each class., so the number of neurons in output layer is 49. And classification was accomplished by a simple maximum response strategy."}, {"heading": "A. Classifier Combination", "text": "The ultimate goal of designing pattern recognition system is to achieve the best possible classification performance. This objective traditionally led to the development of different classification scheme for any pattern recognition problem to be solved. The result of an experimental assessment to the different design would then be the basis for choosing one of the classifiers as the final solution to the problem. It had been observed in such design studies, that although one of the designs would yield the best performance, the sets of patterns misclassified by the different classifiers would not necessarily overlap. This suggested that different classifier designs potentially offered complementary information about the pattern to be classified which could be harnessed to improve the performance of the selected classifier. So instead of relying on a single decision making scheme we can combine classifiers.\n978-1-4244-2806-9/08/$25.00\u00a9 2008 IEEE\nCombination of individual classifier outputs overcomes deficiencies of features and trainability of single classifiers. Outputs from several classifiers can be combined to produce a more accurate result. Classifier combination takes two forms: combination of like classifiers trained on different data sets and combination of dissimilar classifiers. We have four similar Neural networks classifiers as discussed above, which are trained on 32 intersection features, 16 shadow features, 48 line fitting features and 200 chain code features respectively. The outputs are confidences associated with each class. As these outputs can not be compared directly, we used an aggregation function for combining the results of all four classifiers. Our strategy is based on weighted majority voting scheme as described below.\nSo if kth classifier decision to assign the unknown pattern to the ith class is denoted by Oik with 1 \u2264 i \u2264 m, m being the number of classes, then the final combined decision dicm supporting assignment to the ith class takes the form of :-\ndicom = \u2211 \u03c9k * Oik \u2026\u2026.1 \u2264 i \u2264 m\nk=1,2,3,4 The final decision dcom is therefore :-\ndcom = max dicom 1 \u2264 i \u2264 m\ndk \u03c9k = ------- ------------\n4\n\u2211 dk k=1 where m = 50 and \u03c91, \u03c92, \u03c93 are 0.349, 0.197, 0.326 and 0.128 respectively as d1> d3> d2 > d4\nd1=64.90% result of classifier trained with chaincode histogram features\nd2=36.71% result of classifier trained with Intersection features\nd3= 60.59% result of classifier trained with Shadow features.\nd4=24.83% result of classifier trained with straight line fitting features\nIV. RESULTS The handwritten Devnagari character dataset is collected from CVPR Unit, ISI, kolkata. For preparation of the training and test sets a sample set of 4900 handwritten devnagari characters are considered. A training set of 3332 samples and test set of 1568 samples are formed. Results are shown in table 2. We have not considered devnagari numerals right now. We considered top 1 choice, top 2 choices, top 3 choices, top 4 choices and top 5 choices for classification results. We applied 3-fold cross validation testing. We divided the whole dataset into three parts. In first fold, first two parts are used for training and third part is used for testing. In second fold, first and third part is used for training and second part is used for testing. In fold three, second and third part is used for training and first part is used for testing. We used the same MLP for three different feature sets as discussed above in section 3. The results of three MLPs are shown in table 1.\nTable II. Top Choices Results\nTable III.. Recognition success\nS. No. Proposed method result Accuracy obtained\n1 Top 1 choice 70.39% 2 Top 2 choices 81.44% 3 Top 3 choices 86.21% 4 Top 4 choices 88.95% 5 Top 5 choices 92.80%\nS. No. Method proposed by Accuracy obtained\n1 Kumar and Singh [4] 80% 2 N. Sharma, U. Pal, F. Kimura, and S. Pal [5] 80.36% 3 M. Hanmandlu, O.V. R. Murthy, V.K.\nMadasu[21] 90.65%\n4 Proposed method (considering top 5 choices) 92.80%\n978-1-4244-2806-9/08/$25.00\u00a9 2008 IEEE\nWe used another classification strategy where we have used the four same above said classifiers, and character is said to be classified in the class for which it is giving maximum response for any one of the four classifiers. So the character is said to be classified if it has been classified by any one of the classifier. It was giving 80.71% accuracy, which is better than results reported by Kumar , singh[4] and N. Sharma, U. Pal, F. Kimura, S. Pal [5]. We used 4900 samples dataset which is larger than 4750 used by M. Hanmandlu, O.V. R. Murthy, V.K. Madasu[21]. They reported 69.78% overall recognition rate for handwritten devnagari characters which is similar to our top 1 choices result. Their coarse classification is giving 90.65% accuracy but we have obtained 92.80% accuracy.\nV. CONCLUSION This paper proposes an off-line handwritten Devnagari\ncharacter recognition system consisting of three different features using simple feedforward Multilayer Perceptrons. We obtained encouraging results. This technique can be applied on handwritten Devnagari numerals also and it will also be helpful for research towards other similar Indian scripts like"}, {"heading": "Tamil, Bengali, Gujarati, Gurmukhi, Oriya.", "text": "ACKNOWLEDGMENT Authors are thankful to the \u201cCentre for Microprocessor Application for Training Education and Research\u201d and \u201cProject on Storage Retrieval and Understanding of Video for Multimedia\u201d, at the Department of Computer Science and Engineering, Jadavpur University, Kolkata-700032 for providing the necessary facilities for carrying out this work. Authors are also thankful to the CVPR Unit, ISI Kolkata for providing the dataset of Handwritten Devnagari Characters. First author gratefully acknowledge the support of the Meghnad Saha Institute of Technology for carrying out this research work.\nREFERENCES [1] Cris Koutosougeras, akhtar Jameel \u201cExperiment with various neural\nNetwork Architecture for Handwritten Character Recognition\u201d, IEEE 1995, 573-576 [2] Nei Kato,Shin\u2019ichiro Omachi,Hirotomo Aso, Yoshiaki Nemoto \u201cA Handwritten Character Recognition System Using Directional Element Feature and Asymmetric Mahalanobis Distance\u201d, IEEE transactions on pattern analysis and machine intelligence, vol. 21, no. 3, march 1999 pp 258-262 [3] S. Hoque K. Sirlantzis M. C. Fairhurst \u201cA New Chain-code Quantization Approach Enabling High Performance Handwriting Recognition based on Multi-Classifier Schemes\u201d, Proceedings of the Seventh International Conference on Document Analysis and Recognition (ICDAR\u201903) pp 834-838 [4] Satish Kumar and Chandan Singh, \u201cA Study of Zernike Moments and its use in Devnagari Handwritten Character Recognition\u201d, Intl.Conf. on Cognition and Recognition, pp. 514-520, 2005. [5] N. Sharma, U. Pal, F. Kimura, and S. Pal, \u201d Recognition of Off-Line Handwritten Devnagari Characters Using Quadratic Classifier\u201d, ICVGIP 2006, LNCS 4338, pp. 805 \u2013 816, 2006. [6] U. Pal and B.B. Chaudhuri, \u201cIndian script character recognition: A Survey\u201d, Pattern Recognition, Vol. 37, pp. 1887-1899, 2004. [7] B. B. Chaudhuri and U. Pal, \u201cA complete printed Bangla OCR system\u201d, Pattern Recognition, vol. 31, pp. 531-549, 1998.\n[8] I.K. Sethi and B. Chatterjee, \u201cMachine Recognition of constrained Hand printed Devnagari\u201d, Pattern Recognition, Vol. 9, pp. 69-75, 1977. [9] M. Hanmandlu and O.V. Ramana Murthy, \u201cFuzzy Model Based Recognition of Handwritten Hindi Numerals\u201d, Intl.Conf. on Cognition and Recognition, pp. 490-496, 2005. [10] Reena Bajaj, Lipika Dey, and S. Chaudhury, \u201cDevnagari numeral recognition by combining decision of multiple connectionist classifiers\u201d, Sadhana, Vol.27, part. 1, pp.-59-72, 2002 [11] Satish Kumar and Chandan Singh, \u201cA Study of Zernike Moments and its use in Devnagari Handwritten Character Recognition\u201d, Intl.Conf. on Cognition and Recognition, pp. 514- 520, 2005. [12] I.K. Sethi and B. Chatterjee, \u201cMachine Recognition of constrained Hand printed Devnagari\u201d, Pattern Recognition, Vol. 9, pp. 69-75, 1977. [13] U. Bhattacharya, B. B. Chaudhuri, R. Ghosh and M. Ghosh, \u201cOn Recognition of Handwritten Devnagari Numerals\u201d, In Proc. of the Workshop on Learning Algorithms for Pattern Recognition (in conjunction with the 18th Australian Joint Conference on Artificial Intelligence), Sydney, pp.1-7, 2005. [14] J. Hertz, A. Krogh, R.G. Palmer, \u201dAn Introduction to neural Computation\u201d, Addison-Wesley (1991) [15] E.R. Davies and A.P. Plummer, \u201cThinning Algorithms: A critique and new Methodology\u201d ,Pattern Recognition 14, [1981]: 53-63 [16] S. Arora, D. Bhattacharjee, M. Nasipuri, L. Malik, \u201cClassification Of Gradient Change Features Using MLP for Handwritten Character Recognition\u201d, Emerging Applications of Information Technology (EAIT), Kolkata, India, 2006 [17] S. Arora, D. Bhattacharjee, M. Nasipuri, L. Malik, \u201cA Novel Approach for Handwritten Devnagari Character Recognition\u201d, International Conference on Signal and Image Processing (ICSIP), Hubli, Karnataka, India, 2006 [18] S. Arora, D. Bhattacharjee, M. Nasipuri, L. Malik, \u201cA Two Stage Classification Approach for Handwritten Devanagari Characters\u201d, International Conference on Computational Intelligence and Multimedia Application(ICCIMA07), Sivkasi, Tamil Nadu, India 2007 [19] L. Koerich ,Large Vocabulary off-line handwritten word recognition. PhD thesis, Ecole de Technologic Superieure, Montreal-Canada, August 2002 [20] S. Basu, N.Das, R. Sarkar, M. Kundu, M. Nasipuri, D.K. Basu, \u201cHandwritten Bangla alphabet recognition using MLP based classifier\u201d, NCCPB, Bangladesh, 2005 [21] M. Hanmandlu, O.V. Ramana Murthy, Vamsi Krishna Madasu, \u201cFuzzy Model based recognition of Handwritten Hindi characters\u201d, IEEE Computer society, Digital Image Computing Techniques and Applications , 2007 [22] Freeman, H., On the Encoding of Arbitrary Geometric Configurations, IRE Trans. on Electr. Comp. or TC(10), No. 2, June, 1961, pp. 260-268."}], "references": [{"title": "Experiment with various neural Network Architecture for Handwritten Character Recognition", "author": ["Cris Koutosougeras", "akhtar Jameel"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1995}, {"title": "A Handwritten Character Recognition System Using Directional Element Feature and Asymmetric Mahalanobis Distance", "author": ["Nei Kato", "Shin\u2019ichiro Omachi", "Hirotomo Aso", "Yoshiaki Nemoto"], "venue": "IEEE transactions on pattern analysis and machine intelligence,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1999}, {"title": "A Study of Zernike Moments and its use in Devnagari Handwritten Character Recognition", "author": ["Satish Kumar", "Chandan Singh"], "venue": "Intl.Conf. on Cognition and Recognition,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2005}, {"title": "Recognition of Off-Line Handwritten Devnagari Characters Using Quadratic Classifier", "author": ["N. Sharma", "U. Pal", "F. Kimura", "S. Pal"], "venue": "ICVGIP 2006,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2006}, {"title": "Indian script character recognition: A Survey", "author": ["U. Pal", "B.B. Chaudhuri"], "venue": "Pattern Recognition,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2004}, {"title": "A complete printed Bangla OCR system", "author": ["B.B. Chaudhuri", "U. Pal"], "venue": "Pattern Recognition,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1998}, {"title": "Machine Recognition of constrained Hand printed Devnagari", "author": ["I.K. Sethi", "B. Chatterjee"], "venue": "Pattern Recognition,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1977}, {"title": "Fuzzy Model Based Recognition of Handwritten Hindi Numerals", "author": ["M. Hanmandlu", "O.V. Ramana Murthy"], "venue": "Intl.Conf. on Cognition and Recognition,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2005}, {"title": "Devnagari numeral recognition by combining decision of multiple connectionist classifiers", "author": ["Reena Bajaj", "Lipika Dey", "S. Chaudhury"], "venue": "Sadhana, Vol.27,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2002}, {"title": "A Study of Zernike Moments and its use in Devnagari Handwritten Character Recognition", "author": ["Satish Kumar", "Chandan Singh"], "venue": "Intl.Conf. on Cognition and Recognition,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2005}, {"title": "Machine Recognition of constrained Hand printed Devnagari", "author": ["I.K. Sethi", "B. Chatterjee"], "venue": "Pattern Recognition,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1977}, {"title": "On Recognition of Handwritten Devnagari Numerals", "author": ["U. Bhattacharya", "B.B. Chaudhuri", "R. Ghosh", "M. Ghosh"], "venue": "In Proc. of the Workshop on Learning Algorithms for Pattern Recognition (in conjunction with the 18th Australian Joint Conference on Artificial Intelligence), Sydney,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2005}, {"title": "An Introduction to neural Computation", "author": ["J. Hertz", "A. Krogh", "R.G. Palmer"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1991}, {"title": "Thinning Algorithms: A critique and new Methodology", "author": ["E.R. Davies", "A.P. Plummer"], "venue": ",Pattern Recognition", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1981}, {"title": "Classification Of Gradient Change Features Using MLP for Handwritten Character Recognition", "author": ["S. Arora", "D. Bhattacharjee", "M. Nasipuri", "L. Malik"], "venue": "Emerging Applications of Information Technology (EAIT),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2006}, {"title": "A Novel Approach for Handwritten Devnagari Character Recognition", "author": ["S. Arora", "D. Bhattacharjee", "M. Nasipuri", "L. Malik"], "venue": "International Conference on Signal and Image Processing (ICSIP),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2006}, {"title": "A Two Stage Classification Approach for Handwritten Devanagari Characters", "author": ["S. Arora", "D. Bhattacharjee", "M. Nasipuri", "L. Malik"], "venue": "International Conference on Computational Intelligence and Multimedia Application(ICCIMA07),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}, {"title": "Vocabulary off-line handwritten word recognition", "author": ["L. Koerich", "Large"], "venue": "PhD thesis, Ecole de Technologic Superieure,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2002}, {"title": "Handwritten Bangla alphabet recognition using MLP based classifier", "author": ["S. Basu", "N.Das", "R. Sarkar", "M. Kundu", "M. Nasipuri", "D.K. Basu"], "venue": "NCCPB, Bangladesh,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2005}, {"title": "Fuzzy Model based recognition of Handwritten Hindi characters", "author": ["M. Hanmandlu", "O.V. Ramana Murthy", "Vamsi Krishna Madasu"], "venue": "IEEE Computer society, Digital Image Computing Techniques and Applications ,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2007}, {"title": "On the Encoding of Arbitrary Geometric Configurations", "author": ["H. Freeman"], "venue": "IRE Trans. on Electr. Comp. or TC(10),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1961}], "referenceMentions": [{"referenceID": 17, "context": "Devnagari Character recognition is complicated by presence of multiple loops, conjuncts, upper and lower modifiers and the number of disconnected and multistroke characters [19], in a word where all characters are connected through header line.", "startOffset": 173, "endOffset": 177}, {"referenceID": 6, "context": "Although first research report on handwritten Devnagari characters was published in 1977 [8] but not much research work is done after that.", "startOffset": 89, "endOffset": 92}, {"referenceID": 7, "context": "Hanmandlu and Murthy [9, 21] proposed a Fuzzy model based recognition of handwritten Hindi numerals and characters and they obtained 92.", "startOffset": 21, "endOffset": 28}, {"referenceID": 19, "context": "Hanmandlu and Murthy [9, 21] proposed a Fuzzy model based recognition of handwritten Hindi numerals and characters and they obtained 92.", "startOffset": 21, "endOffset": 28}, {"referenceID": 8, "context": "Bajaj et al [10] employed three different kinds of features namely, density features, moment features and descriptive component features for classification of Devnagari Numerals.", "startOffset": 12, "endOffset": 16}, {"referenceID": 9, "context": "Kumar and Singh [11] proposed a Zernike moment feature based approach for Devnagari handwritten character recognition.", "startOffset": 16, "endOffset": 20}, {"referenceID": 10, "context": "Sethi and Chatterjee [12] proposed a decision tree based approach for recognition of constrained hand printed Devnagari characters using primitive features.", "startOffset": 21, "endOffset": 25}, {"referenceID": 11, "context": "Bhattacharya et al [13] proposed a MultiLayer Perceptron (MLP) neural network based classification approach for the recognition of Devnagari handwritten numerals and obtained 91.", "startOffset": 19, "endOffset": 23}, {"referenceID": 3, "context": "Pal [5] proposed a directional chain code features based quadratic classifier and obtained 80.", "startOffset": 4, "endOffset": 7}, {"referenceID": 14, "context": "00\u00a9 2008 IEEE 3 transformation [16].", "startOffset": 31, "endOffset": 35}, {"referenceID": 18, "context": "Shadow Features of character-- For computing shadow features [20], the rectangular boundary enclosing the character image is divided into eight octants, for each octant shadow of character segment is computed on two perpendicular sides so a total of 16 shadow features are obtained.", "startOffset": 61, "endOffset": 65}, {"referenceID": 20, "context": "Contour point detection The contour following procedure uses a contour representation called \u201cchain coding\u201d that is used for contour following proposed by Freeman [22], shown in figure 5a.", "startOffset": 163, "endOffset": 167}, {"referenceID": 13, "context": "For thinning standard algorithm [15] is used.", "startOffset": 32, "endOffset": 36}, {"referenceID": 15, "context": "This algorithm does not generate one-pixel wide skeleton character image and results in redundant pixels so we designed certain masks [17] so that after application of these masks some image pixels are removed so finally we get these entire characters one pixel wide.", "startOffset": 134, "endOffset": 138}, {"referenceID": 12, "context": "The classifier is trained with standard Backpropagation [14].", "startOffset": 56, "endOffset": 60}, {"referenceID": 2, "context": "Method proposed by Accuracy obtained 1 Kumar and Singh [4] 80%", "startOffset": 55, "endOffset": 58}, {"referenceID": 3, "context": "Pal [5] 80.", "startOffset": 4, "endOffset": 7}, {"referenceID": 19, "context": "Madasu[21] 90.", "startOffset": 6, "endOffset": 10}, {"referenceID": 2, "context": "71% accuracy, which is better than results reported by Kumar , singh[4] and N.", "startOffset": 68, "endOffset": 71}, {"referenceID": 3, "context": "Pal [5].", "startOffset": 4, "endOffset": 7}, {"referenceID": 19, "context": "Madasu[21].", "startOffset": 6, "endOffset": 10}], "year": 2008, "abstractText": "In this paper we present an OCR for Handwritten Devnagari Characters. Basic symbols are recognized by neural classifier. We have used four feature extraction techniques namely, intersection, shadow feature, chain code histogram and straight line fitting features. Shadow features are computed globally for character image while intersection features, chain code histogram features and line fitting features are computed by dividing the character image into different segments. Weighted majority voting technique is used for combining the classification decision obtained from four Multi Layer Perceptron(MLP) based classifier. On experimentation with a dataset of 4900 samples the overall recognition rate observed is 92.80% as we considered top five choices results. This method is compared with other recent methods for Handwritten Devnagari Character Recognition and it has been observed that this approach has better success rate than other methods.", "creator": null}}}