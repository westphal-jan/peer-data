{"id": "1206.4670", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2012", "title": "State-Space Inference for Non-Linear Latent Force Models with Application to Satellite Orbit Prediction", "abstract": "Latent fighting introduced (LFMs) much framework characteristics although boil mechanistic algorithms principles (do. e. , patient simpler) with must - parametric electronic - driven components. Several led computers created LFMs their less - linearities, taken rankings but analytically intractable fallacy. In kind brought but featured how allow - linear LFMs allows way both be country - linear purple motion putting has - structure configurations and different which robust non - corresponding Kalman http and zigzag corp. calculations for i.e. for and parameter inference. We illustrate the achievement of the proposing methodology where 14 interrogations examples, from legally does to whose even - world no same too - mean prediction of GPS satellite orbits.", "histories": [["v1", "Mon, 18 Jun 2012 15:34:23 GMT  (690kb)", "http://arxiv.org/abs/1206.4670v1", "ICML2012"]], "COMMENTS": "ICML2012", "reviews": [], "SUBJECTS": "cs.IT astro-ph.EP cs.LG math.IT physics.data-an", "authors": ["jouni hartikainen", "mari sepp\u00e4nen", "simo s\u00e4rkk\u00e4"], "accepted": true, "id": "1206.4670"}, "pdf": {"name": "1206.4670.pdf", "metadata": {"source": "META", "title": "State-Space Inference for Non-Linear Latent Force Models with Application to Satellite Orbit Prediction", "authors": ["Jouni Hartikainen", "Mari Sepp\u00e4nen"], "emails": ["jouni.hartikainen@aalto.fi", "mari.j.seppanen@tut.fi", "simo.sarkka@aalto.fi"], "sections": [{"heading": "1. Introduction", "text": "Gaussian processes (GPs) are stochastic processes, which are commonly used for representing uncertainties of dynamic systems in many applications such as tracking, navigation and automatic control systems (Jazwinski, 1970; Bar-Shalom et al., 2001; Grewal & Andrews, 2001; Maybeck, 1982). In these applications, the Gaussian processes are typically white, and the processes are used as stochastic inputs in physical models such as driving forces of mechanical systems described in terms of ordinary differential equations (ODEs).\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\nIn a machine learning context, Gaussian processes (Rasmussen & Williams, 2006) are used as nonparametric models for unknown functions. Prior information on the smoothness and other properties of the model functions is encoded into the covariance function of the Gaussian process. Recently, A\u0301lvarez et al. (2009) introduced the idea of using Gaussian processes as non-parametric models for unknown input functions in physical models, which are formulated as differential equations (e.g. ODEs). As opposed to the classical models used in tracking, navigation and control applications, in this latent force model (LFM) approach, the input functions are not modeled as white noise processes, but instead their covariance structure is selected according to the machine learning approach, where the covariance structure is written in terms of unknown parameters that are estimated from data.\nIn this paper we show how non-linear latent force models can be represented as non-linear white noise driven state-space models, that is, partially observed non-linear stochastic differential equations (SDEs Jazwinski, 1970; Grewal & Andrews, 2001; \u00d8ksendal, 2003) and show how recently developed efficient non-linear Kalman filtering and smoothing based methods (Sa\u0308rkka\u0308, 2007; Singer, 2008; Sa\u0308rkka\u0308, 2010; Arasaratnam et al., 2010; Singer, 2011; Sa\u0308rkka\u0308 & Sarmavuori, 2012) can be used for inferring the state and parameters of these models. We compare the performance of the method to previously proposed Laplace-approximation and Markov chain Monte Carlo (MCMC) solutions (Lawrence et al., 2006; Titsias et al., 2009). The key advantages of the proposed approach over the previous ones is that i) its computational scaling is linear in the number of time steps and ii) it naturally handles stochasticity and non-linearity of the physical model.\nOur main motivation for the proposed approach stems from an important real-world problem of long-term prediction of GPS satellite orbits (Seppa\u0308nen et al., 2012). We show how the accuracy of orbit prediction can be improved by nonparametrically modelling forces unexplained by a deterministic non-linear physical orbit model."}, {"heading": "2. Latent Force Models", "text": "Latent force models (LFMs) (A\u0301lvarez et al., 2009) are a relatively new modeling approach, combining mechanistic modeling principles (i.e., physical models) with non-parametric data-driven components. They have been successfully employed, for example, in ranked prediction of transcription factors (Honkela et al.). For instance, Lawrence et al. (2006) modelled the timedependent expression levels {xj(t)}Nj=1 ofN genes with a system of first order ODEs\ndxj(t)\ndt = Bj+ R\u2211 r=1 Sj,rgj(ur(t))\u2212Djxj(t), j = 1, . . . , N\n(1) where the driving processes {ur(t)}Rr=1 (representing the transcription factors, TFs) were given independent Gaussian process (GP) priors ur(t) \u223c GP(m(t), kur (t, t\u2032)), r = 1, . . . , R, where m(t) and kur (t, t\n\u2032) were suitably chosen mean and covariance functions.\nIf the functions gj(\u00b7) are linear, the model (1) is an instance of a linear latent force model. In such cases (see paper by A\u0301lvarez et al., 2009, for examples) the posterior inference on xj(t) and ur(t) is based on closed form computation of the covariance functions of xj(t), dxj(t)/dt and all the required cross covariances by solving the differential equation and then utilizing standard GP regression techniques.\nHowever, in the case of non-linear gj(\u00b7) (such as gj(u(t)) = e\nu(t), ensuring the positivity of the forces effect) the ODE becomes non-linear. The standard GP techniques cannot anymore be applied since the needed covariance terms are analytically intractable. Inference in these models has been previously performed mainly by the Laplace method (Lawrence et al., 2006) and Markov chain Monte Carlo (MCMC) (Titsias et al., 2009). A severe limitation of these approaches is that they are based on the assumption that the likelihood of data can be written as an explicit function of the latent force process u(t) which can be evaluated (either approximately or exactly) in a computationally feasible manner."}, {"heading": "3. SDE View of Latent Force Models", "text": "As discussed by Hartikainen & Sa\u0308rkka\u0308 (2010), GPs with certain stationary covariance functions (including the Mate\u0301rn class) can be represented as solutions to linear time-invariant (LTI) SDEs (\u00d8ksendal, 2003). That is, we can formulate the GP priors on the r = 1, . . . , R components of u(t) = (u1(t) . . . uR(t)) T as multivariate LTI SDEs of form\ndzr(t) = Fz,r zr(t) dt+ Lz,r d\u03b2z,r(t) (2)\nwhere zr(t) = (ur(t) dur(t) dt \u00b7 \u00b7 \u00b7 ddr\u22121ur(t) dtdr\u22121 )T and\nFz,r =  0 1 . . . . . .\n0 1 \u2212a0r \u00b7 \u00b7 \u00b7 \u2212apr\u22122r \u2212apr\u22121r\n ,Lz,r = \n0 ... 0 qr  . This dynamic model on ur(t) corresponds to a GP prior with a certain stationary covariance function when the coefficients a0r, . . . , a pr\u22121 r , the diffusion constant qr and the dimensionality pr of zr(t) are chosen appropriately.\nUsing this view on GP priors, the conversion of linear latent force models into linear-Gaussian statespace models was recently considered by Hartikainen & Sa\u0308rkka\u0308 (2011). In this paper, we consider conversion of non-linear latent force models into non-linear statespace models. Analogously to the linear case, a general non-linear latent force model can be formulated as a continuous-discrete system of form\ndx(t) = f(x(t),u(t), t) dt,\ndzr(t) = Fz,r zr(t) dt+ Lz,r d\u03b2z,r(t), r = 1, . . . , R\nwhere x(t) \u2208 <M is the state (M being the number of state components needed in representing the output processes {xj(t)}Nj=1 in a vector form), u(t) \u2208 <R the latent force processes and f(\u00b7) the dynamic model function of output process x(t).\nWe can further simplify the notation by constructing an augmented system with state xa(t) comprising of the output process and latent forces as xa(t) = (x(t), z1(t), . . . , zR(t)) T with dynamics\ndxa(t) = fa(xa(t), t) dt+ La(xa(t), t) d\u03b2a(t). (3)\nIn the context of stochastic processes and filtering theory, the dynamic model function fa is called the drift function and La the dispersion matrix weighting the R-dimensional Brownian motion \u03b2a(t) with diffusion matrix Q. Note that within this framework the model for x(t) does not need to be deterministic given u(t).\nTo complete the model specification we assume that observations at discrete time instants t1, . . . , tT can be modeled as\nyk = hk(xa(tk)) + rk, k = 1, . . . , T (4)\nwhere h(\u00b7) is the measurement model function, yk \u2208 <D is the measurement at time tk and rk \u223c N(0,Rk) is the measurement noise."}, {"heading": "4. Filtering and Smoothing of SDEs", "text": "Given continuous-discrete system of the form\ndx(t) = f(x(t), t) dt+ L(x(t), t)d\u03b2(t)\nyk = hk(x(tk)) + rk, k = 1, . . . , T (5)\nour aim is now to infer the filtering and smoothing distributions of the state x(t) at a time instant t:\np(x(t)|y1:k), t \u2208 [tk, tk+1) (6)\nand p(x(t)|y1:T ), t \u2208 [t0, tT ], (7)\nwhere y1:i is a shorthand notation for {y, . . . ,yi}. In general, this is a difficult task that has been well studied in the field of stochastics and filtering theory (Jazwinski, 1970). The formal Bayesian continuousdiscrete filter consists of separate prediction and update steps (Jazwinski, 1970), which are recursively iterated forward in time. On the prediction step we solve the probability density p(x(tk)|y1:k\u22121) of the state at time tk, and on the update step, we use the Bayes\u2019 rule to update the density with latest observation as p(x(tk)|y1:k) \u221d p(yk|x(tk))p(x(tk)|y1:k\u22121). The prediction density p(x(tk)|y1:k\u22121) must be solved from the Fokker\u2013Planck\u2013Kolmogorov (FPK) partial differential equation, which is analytically intractable in general. Thus, to perform filtering and smoothing in practice approximate solutions must be sought. In this article, we consider Gaussian approximations for the filtering and smoothing distributions.\nIn the following we review the main steps of the Gaussian filtering and smoothing framework1 which we consider appropriate for the type of models considered in this article. The general Gaussian filtering and smoothing framework is classical (see, e.g., Jazwinski, 1970; Maybeck, 1982), but here we utilize the recently developed sigma-point methods (Sa\u0308rkka\u0308, 2007; Singer, 2008; Sa\u0308rkka\u0308, 2010; Arasaratnam et al., 2010; Sa\u0308rkka\u0308 & Sarmavuori, 2012) for numerically solving\n1Matlab toolbox implementing the presented methods can be found from http://becs.aalto.fi/en/research/ bayes/lfm/.\nthe general continuous-discrete Gaussian filtering and smoothing equations. As shown by Singer (2011), the Gaussian filtering framework can also used for efficient evaluation of the likelihoods needed in parameter estimation methods.\nThe filter works by recursively solving the following set of equations for time steps k = 1, . . . , T :\n\u2022 Solve mean and covariance of the predicted distribution p(x(t)|y1:k\u22121) \u2248 N(m(t\u2212k ),P(t \u2212 k )) by nu-\nmerically integrating the differential equations2\ndm\ndt = E[f(x, t)] dP\ndt = E[(x\u2212m)fT (x, t)] + E[f(x, t)(x\u2212m)T ]\n+ E[L(x(t), t)QL(x(t), t)T ],\nwhere the expectations are taken with respect to x \u223c N(m(t),P(t)), and t\u2212k denotes the time instance \u201dinfinitesimally before the time tk\u201d.\n\u2022 Compute the approximate filtering distribution p(x(tk)|y1:k) \u2248 N(m(tk),P(tk)) via the update (moment matching) equations\n\u00b5k = E[hk(x)],\nSk = E[(hk(x)\u2212 \u00b5k)(hk(x)\u2212 \u00b5k)T ] Dk = E[(x\u2212m\u2212k )(hk(x)\u2212 \u00b5k) T ] Kk = DkS \u22121 k mk = m \u2212 k + Kk (yk \u2212 \u00b5k) Pk = P \u2212 k \u2212Kk SkK T k .\nThis is equivalent to the update step of a discretetime filter, with definitions m\u2212k , m(t \u2212 k ), P \u2212 k , P(t\u2212k ) and mk , m(tk), Pk , P(tk).\nThe approximate smoothing distributions p(x(tk)|y1:T ) \u2248 N(x(tk)|ms(tk),Ps(tk)) can be obtained by recursively solving the following Kalman smoothing like equations for k = T \u2212 1, . . . , 1:\nGk+1 = Ck(tk+1)P \u22121(t\u2212k+1)\nms(tk) = m(tk) + Gk+1 [m s(tk+1)\u2212m(t\u2212k+1)] Ps(tk) = P(tk) + Gk+1 [P s(tk+1)\u2212P(t\u2212k+1)]G T k+1,\nwhere the cross covariance term Ck can be shown (Sa\u0308rkka\u0308 & Sarmavuori, 2012) to follow the differential equation\ndCk dt = CkP \u22121 E[f(x, t) (x\u2212m)T ]T .\n2These equations can be derived by applying the Ito\u0302 formula to the FPK (see, e.g., Jazwinski, 1970).\nThis can be integrated alongside m(t) and P(t) during the filtering with negligible computation cost. An important thing to note here is that the time steps tk are not restricted to be the measurement time steps, that is, we can calculate the smoothed estimates at any time point inside the interval t \u2208 [t0, tT ]. On such steps the update equations of the filter are simply skipped.\nThe expectations in the equations above are taken over the approximating Gaussian distribution, and can be numerically computed with sigma-point and cubature integration methods (see, Sa\u0308rkka\u0308, 2007; Singer, 2008; Sa\u0308rkka\u0308, 2010; Arasaratnam et al., 2010; Sa\u0308rkka\u0308 & Sarmavuori, 2012). As was discussed by Singer (2011), the Gaussian filter also computes approximations to the conditional measurement likelihoods p(yk|y1:k\u22121) \u2248 N(yk|\u00b5k,Sk), which can be used in marginal likelihood based parameter learning via the factorization p(y1:T |\u03b8) = \u220fT k=1 p(yk|y1:k\u22121, \u03b8), where \u03b8 denotes a vector of unknown parameters.\nThe weakness of the outlined inference scheme is that it assumes that the state distributions are approximately Gaussian. An alternative way of performing state inference would be to use a particle filter (Doucet et al., 2001), which approximates the posterior with sequential importance sampling. We could then use particle MCMC methods (Andrieu et al., 2010) for estimating the unknown parameters. The difficulty in using particle filters with SDEs is that when the state transition density cannot be evaluated in closed form, one is restricted to usage of the dynamic model as the importance distribution (Andrieu et al., 2010), which leads to inefficient sampling. Moreover, in the particle filter we need to solve the SDE numerically between the measurements for each sample separately, which is computationally very demanding."}, {"heading": "5. Simulated Experiments", "text": "This section illustrates the performance of the proposed framework with two simulated examples."}, {"heading": "5.1. Estimation of Transcription Factors", "text": "First we consider the TF model (1) with three different non-linear functions: (i) g(u(t)) = e u(t)\n\u03b3+eu(t) (sat-\nuration), (ii) g(u(t)) = 1 \u03b3+eu(t) (repression) and (iii) g(u(t)) = eu(t) (exponential). The drift model in this case is linear and can thereby be solved approximately as a function of u(t) (Lawrence et al., 2006), and thus it is possible to implement Laplace and MCMC for it.\nFor each non-linear function we generated 100 state trajectories for the time interval t \u2208 [0, 15] by the TF\nmodel (1) (N = 3, R = 1) with the latent force having a Mate\u0301rn GP prior (\u03bd = 3/2). The model parameters were randomly generated for each state trajectory as Bj \u223c U(0, 0.1), Dj \u223c U(0, 2), Aj \u223c U(\u22120.1, 0.1), Sj \u223c U(0, 1), and were treated as fixed and known during the inference. For the saturation and repression functions we used the parameters \u03b3 \u2208 {0.1, 0.5, 1}. For the GP prior we used the magnitude and length scale parameters \u03c32m = 1 and l = 2. Given the state trajectories we generated T = 13 equally placed observations for each of the N outputs with additive Gaussian noise with variance \u03c32n = 0.1 2.\nOur aim is to estimate the trajectory of the latent force given the generated observations. The estimation results are listed in Table 1 for Laplace approximation (LA), elliptical slice sampling (ESLS) (Murray et al., 2010) and a Gaussian continuous-discrete filter/smoother (GFS) with moment matching performed with the spherical cubature rule (Arasaratnam et al., 2010; Sa\u0308rkka\u0308 & Sarmavuori, 2012). With Laplace and ESLS we approximated the integral in the solution of the ODE by a Riemann sum with 363 grid points, and with GFS we used the 4th order Runge\u2013 Kutta method with 10 steps in integrating the moment equations. With ESLS we drew 100000 samples for u(t), of which first 5000 were discarded as burn-in.\nWith Laplace approximation we used Newton\u2019s method with a simple step size adjustment procedure to find the mode. We excluded from the results all the cases where the Newton\u2019s method didn\u2019t stop after pre-specified number of iterations (300), as well as ones having RMSE (calculated over the 363 grid points) greater than 3\u03c3m with any method, as this was taken to indicate that the method had diverged. The typical computation times for the data sets considered here were about 3 seconds with LA, 10 minutes with ESLS and 8 seconds with GFS.\nFrom the results we can see that ESLS provides consistently good performance with all non-linear functions. GFS performs equally well with saturation and repression functions with all tested parameter configurations, but is slightly worse with the exponential function compared to Laplace and ESLS. However, Laplace had trouble in mode finding in several cases with the exponential function. With saturation and repression functions such problems were also present when \u03b3 \u2208 {0.1, 0.5}, but with \u03b3 = 1 Laplace performed equally well with ESLS and GFS."}, {"heading": "5.2. Tracking a Ballistic Target on Reentry", "text": "Next we consider tracking a ballistic target reentering the atmosphere with a sensor measuring the dis-\ntance to the target. In this example the drift and measurement models are non-linear, rendering Laplace and MCMC inapplicable for state inference. For simplicity we consider only a one dimensional case (that is, the target falls directly towards the ground), but the approach works similarly in a general 3D setting.\nThe motion of the target is assumed to follow the equation (Li & Jilkov, 2001)[ dr dv ] = [ \u2212v a(r, v, t) + g + u(t) ] dt+ [ qr 0 0 qv ] [ d\u03b2r d\u03b2v ] ,\nwhere r is the altitude and v the velocity of the target. We assume that the acceleration is caused by the drag force a(r, v, t) = \u2212\u03b1 exp(\u2212\u03b3 r) v2, where the exponentially decaying term models the air density, gravitational force g = 9.8m/s2 and an unknown force u(t), which we assume to have a Mate\u0301rn GP prior model (\u03bd = 5/2, \u03c3m = 50m/s\n2, l = 5s). The drag force parameter was set \u03b1 = 4.49 \u00d7 10\u22124, and the air density scale to \u03b3 = 1.49 \u00d7 10\u22124. The noise parameters were set to qr = 50m/ \u221a s and qv = 10(m/s)/ \u221a s. The distance measurements were modeled as\nyk = \u221a s2x + (sy \u2212 r)2 + rk,\nwhere (sx, sy) = (30km, 30m) is the position of the sensor, and measurement noise has variance \u03c32n = (30m) 2.\nStarting from state (r0, v0) = (65km, 3km/s), we simulated the target trajectory on time interval t \u2208 [0, 30s] and generated 120 equally spaced measurements with the model above. Inference was performed with the Gaussian filtering and smoothing framework. We treated the drag force parameter \u03b1 and the GP parameters \u03c3m and l as unknowns, which were determined by optimizing the marginal likelihood of data.\nExample results of estimating r(t), v(t) and u(t) with optimized parameters are shown in panels (a), (b) and (c) of Figure 1. We also ran a MCMC inference for the unknown parameters using the negative log marginal likelihood provided by the filter as the energy function. Panel (d) shows the samples obtained for log(\u03b1), peaking around the true value (\u22127.7).\nFor comparison, we implemented also a particle filter for this model. We used a stochastic Runge\u2013Kutta (strong order 1.5) to draw samples from the SDE. In practice, it required about 50000 particles to reach similar level of accuracy as with the Gaussing filtering scheme. In CPU time this took about 15 minutes, whereas Gaussian filtering takes only a few seconds."}, {"heading": "6. GPS Satellite Orbit Prediction", "text": "As a real-world case study we consider the problem of predicting the orbit of a GPS satellite. Accurate modeling of the forces acting on a GPS satellite is needed in a number of applications and real-time applications require prediction of the orbit (Seppa\u0308nen et al., 2012).\nThe equation of motion for the satellite can be written as a (vector) Markov model\nd\ndt [ r v ] = [ v a(r, t) + u(r,v, t) ] ,\nwhere a(r, t) is a deterministic model for the acceler-\nation of the satellite, and u(r,v, t) represents acceleration terms caused by unknown forces acting on the satellite. Here, r and v represent the 3D position and velocity vectors of the satellite in an inertial coordinate system fixed to an arbitrary reference frame.\nThe deterministic acceleration of the motion model is\na(r, t) = ag + amoon + asun + asrp, (8)\nwhere ag, amoon, asun and asrp are the accelerations due to Earth\u2019s gravitation, lunar gravitation, solar gravitation and solar radiation pressure, respectively.\nWhen the asymmetrical mass distribution of the Earth is taken into account, its gravity potential U can be written in the form of the spherical harmonics expansion (Montenbruck & Gill, 2005)\nU(r, \u03bb, \u03d5) = GME r \u221e\u2211 n=0 n\u2211 m=0 [( RE r )n Pnm(sin\u03d5)\n( Cnm cos(m\u03bb) + Snm sin(m\u03bb) )] . (9)\nHere the potential U is not only a function of satellite\u2019s radius r, but also the longitude \u03bb and latitude \u03d5. The constant RE in this formula is the Earth\u2019s radius and the terms Pnm are the associated Legendre polynomials of degree n and order m. The coefficients Snm and Cnm are experimentally determined constants, whose magnitude decreases very fast with increasing n and m. Therefore, the potential can be approximated by taking into account only the first few terms. We used terms up to the degree and order 8. The acceleration due to Earth gravitation can be computed as gradient of the gravity potential U :\nag = R \u22121\u2207U, (10)\nwhere R is a suitable coordinate transformation matrix. For more details, see Montenbruck & Gill (2005) and Seppa\u0308nen et al. (2012).\nAfter Earth\u2019s gravitation the next biggest acceleration components in the satellite\u2019s equation of motion are caused by the gravitational forces of the Moon and the Sun. When dealing with Earth centered reference frame one has to compute the acceleration of the satellite in relation to the acceleration of the Earth. To compute this relative acceleration of the satellite caused by any celestial body, one can use the form\nacb = GM ( rcb \u2212 r \u2016rcb \u2212 r\u20163 \u2212 rcb \u2016rcb\u20163 ) , (11)\nwhere M is the mass of the celestial body, rcb is its position in the Earth centered inertial reference frame\nand r is the position of the satellite in the same reference frame. Applying this formula to Moon and Sun gives the accelarations amoon and asun in Equation (8).\nThe last acceleration component in Equation (8), the solar radiation pressure, is a non-gravitational force whose exact form is not very well known. The main component of this force is pointing to the opposite direction from Sun. Furthermore, the amplitude of this force is almost constant, or the variations in the amplitude are rather small compared to its magnitude. Based on this information we can add a rough model for solar radiation pressure and later estimate the remaining parts of the force. The rough model is\nasrp = \u2212\u03b1 AU2\nr2sun esun, (12)\nwhere esun is a unit vector from satellite to Sun, AU is the astronomical unit and rsun is the distance from satellite to Sun. The satellite-specific constant amplitude \u03b1 was batch estimated using half a year of position data of the satellite."}, {"heading": "6.1. Modeling the Unknown Forces", "text": "As the first step in the modeling we would like to get a glimpse of what the unknown forces look like. To do this we assume separate GP smoothness priors for each component of u(r,v, t). Instead of placing the GP priors directly on the inertial coordinate system used in the integration, we place them on the radial, tangential and normal components of a RTN coordinate system with unit vectors\neR = r\n\u2016r\u2016 , eT = eN \u00d7 eR, eN = r\u00d7 v \u2016r\u00d7 v\u2016 .\nThus, the model for the unknown forces is\nu(r,v, t) = R(r,v) uR(t)uT (t) uN (t)  , where R(r,v) is a matrix transforming RTN coordinates to the inertial coordinate system used in integration, and each of the latent forces uR,uT and uN have Mate\u0301rn GP priors. Overall, the model can be written in form (3), and thus be inferred with framework presented in Section 4.\nExamples of smoothed force trajectories for ten days are shown as red lines in Figure 2. It is apparent that the force trajectories exhibit almost periodic, or quasiperiodic behavior, which can be utilized to improve predictions when modelled appropriately."}, {"heading": "6.2. Quasi-Periodic Model for Latent Forces", "text": "To model the quasi-periodicities in the latent forces we use a stochastic resonator model, which previously has been used for modeling periodic phenomena in the brain (Sa\u0308rkka\u0308 et al., 2012). We model the periodic component as a superposition of resonators of the form\nd2cn(t)\ndt2 = \u2212(2\u03c0nf)2cn(t) + wn(t), (13)\nwhere the additive white noise components wn(t) have spectral densities qn. As shown by Sa\u0308rkka\u0308 et al. (2012), this model can be written in state space form\ndx(t) = Fx(t) dt+ L d\u03b2(t)\nu(t) = Hx(t) + b+ (t), (14)\nwhich is compatible with the framework presented in this article. In Equation (14) we have also included a bias term b (which could also be time-varying) as the resonator model assumes the process to be zero-mean, and a white noise component (t) with spectral density q to account for possible modeling errors."}, {"heading": "6.3. Example Online Prediction Results", "text": "We now apply the constructed quasi-periodic latent force model to predict the satellite orbit, and compare the results to ones obtained with only the deterministic model. We consider an online prediction scenario, in which we observe the position and velocity of the satellite on certain time intervals, and between these intervals the models are used to provide predictions. We use 30 days of position data (collected every 15 minutes) of satellite 31 from the beginning of January 2010. The regions of observed data are illustrated with gray shades in Figure 3.\nIn the quasi-periodic latent force model we used 7 harmonic components to model uR(t), uT (t) and 10 in uN (t). As the period we used a little less than one day, which we observed to be a clear period in the estimated latent forces. The rest of the model parameters were optimized with respect to marginal likelihood, in which the smoothed mean estimate given by a Mate\u0301rn GP model on a short time segment on the same satellite were treated as observed data. For inference in the actual GPS prediction with the latent force model we used the Gaussian continuous-discrete filter with the spherical cubature rule and moment integration by 4th order Runge\u2013Kutta method with 80 steps between each observation. With the deterministic model the predictions were calculated by integrating the dynamics starting from the latest observation.\nThe errors in position estimates for both models are shown in Figure 3. It is evident that the modeling of periodicity reduces the position errors significantly. For example, in this particular case the position error of LFM after 15 days was less than 10% of that of the deterministic model. In fact, the amplitude of error even decreases during some time intervals, which might indicate the presence of some unexplained periodic forces acting on a longer time period. While we have here reported the predictions only with one satellite on a one-month time frame, the results are promising and certainly warrant further research."}, {"heading": "7. Conclusion", "text": "In this article we have shown how non-linear latent force models can be represented as non-linear white noise driven state-space models. The resulting representation allows to apply efficient filtering and smoothing algorithms for state and parameter inference. The potential weakness of the approach is the underlying Gaussian approximation to the state posterior, but as we have shown there are many applications where the approach works well. The advantage of the approach\nis that it is computationally light compared to, for example, pure particle filtering and MCMC based approximations, whose computational requirements can be infeasible for practical use."}, {"heading": "Acknowledgements", "text": "The authors would like to thank Arno Solin, Janne Ojanen and anonymous reviewers for feedback that significantly improved the paper. The authors acknowledge financial support from Finnish Doctoral Programme in Computational Sciences, Finnish Foundation for Technology Promotion, Emil Aaltonen Foundation and Tampere Doctoral Programme in Information Science and Engineering."}], "references": [{"title": "Particle Markov chain Monte Carlo methods", "author": ["C. Andrieu", "A. Doucet", "R. Holenstein"], "venue": "JRSS B,", "citeRegEx": "Andrieu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Andrieu et al\\.", "year": 2010}, {"title": "Cubature kalman filtering for continuous-discrete systems: Theory and simulations", "author": ["I. Arasaratnam", "S. Haykin", "T.R. Hurd"], "venue": "IEEE Transactions on Signal Processing,", "citeRegEx": "Arasaratnam et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Arasaratnam et al\\.", "year": 2010}, {"title": "Estimation with Applications to Tracking and Navigation", "author": ["Y. Bar-Shalom", "Li", "X-R", "T. Kirubarajan"], "venue": "Wiley Interscience,", "citeRegEx": "Bar.Shalom et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Bar.Shalom et al\\.", "year": 2001}, {"title": "Sequential Monte Carlo Methods in Practice", "author": ["A. Doucet", "N. de Freitas", "Gordon", "N. (eds"], "venue": null, "citeRegEx": "Doucet et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Doucet et al\\.", "year": 2001}, {"title": "Kalman Filtering and Smoothing Solutions to Temporal Gaussian Process Regression Models", "author": ["J. Hartikainen", "S. S\u00e4rkk\u00e4"], "venue": "In Proc. MLSP, pp", "citeRegEx": "Hartikainen and S\u00e4rkk\u00e4,? \\Q2010\\E", "shortCiteRegEx": "Hartikainen and S\u00e4rkk\u00e4", "year": 2010}, {"title": "Sequential Inference for Latent Force Models", "author": ["J. Hartikainen", "S. S\u00e4rkk\u00e4"], "venue": "In Proc. UAI,", "citeRegEx": "Hartikainen and S\u00e4rkk\u00e4,? \\Q2011\\E", "shortCiteRegEx": "Hartikainen and S\u00e4rkk\u00e4", "year": 2011}, {"title": "Stochastic Processes and Filtering Theory", "author": ["A.H. Jazwinski"], "venue": null, "citeRegEx": "Jazwinski,? \\Q1970\\E", "shortCiteRegEx": "Jazwinski", "year": 1970}, {"title": "Modelling transcriptional regulation using Gaussian processes", "author": ["N.D. Lawrence", "G. Sanguinetti", "M. Rattray"], "venue": "In NIPS, pp", "citeRegEx": "Lawrence et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Lawrence et al\\.", "year": 2006}, {"title": "Survey of maneuvering target tracking: II. Ballistic target models", "author": ["X.R. Li", "V.P. Jilkov"], "venue": "In Proc. SPIE,", "citeRegEx": "Li and Jilkov,? \\Q2001\\E", "shortCiteRegEx": "Li and Jilkov", "year": 2001}, {"title": "Stochastic Models, Estimation and Control, Volume 2", "author": ["P. Maybeck"], "venue": null, "citeRegEx": "Maybeck,? \\Q1982\\E", "shortCiteRegEx": "Maybeck", "year": 1982}, {"title": "Satellite Orbits", "author": ["O. Montenbruck", "E. Gill"], "venue": null, "citeRegEx": "Montenbruck and Gill,? \\Q2005\\E", "shortCiteRegEx": "Montenbruck and Gill", "year": 2005}, {"title": "Elliptical slice sampling", "author": ["I. Murray", "Adams", "R. Prescott", "D.J.C. MacKay"], "venue": "JMLR: W&CP,", "citeRegEx": "Murray et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Murray et al\\.", "year": 2010}, {"title": "Stochastic Differential Equations: An Introduction with Applications", "author": ["B. \u00d8ksendal"], "venue": "Springer, 6th edition,", "citeRegEx": "\u00d8ksendal,? \\Q2003\\E", "shortCiteRegEx": "\u00d8ksendal", "year": 2003}, {"title": "Gaussian Processes for Machine Learning", "author": ["C.E. Rasmussen", "C.K.I. Williams"], "venue": null, "citeRegEx": "Rasmussen and Williams,? \\Q2006\\E", "shortCiteRegEx": "Rasmussen and Williams", "year": 2006}, {"title": "On unscented Kalman filtering for state estimation of continuous-time nonlinear systems", "author": ["S. S\u00e4rkk\u00e4"], "venue": "IEEE Transactions on Automatic Control,", "citeRegEx": "S\u00e4rkk\u00e4,? \\Q2007\\E", "shortCiteRegEx": "S\u00e4rkk\u00e4", "year": 2007}, {"title": "Continuous-time and continuous-discrete-time unscented Rauch-Tung-Striebel smoothers", "author": ["S. S\u00e4rkk\u00e4"], "venue": "Signal Processing,", "citeRegEx": "S\u00e4rkk\u00e4,? \\Q2010\\E", "shortCiteRegEx": "S\u00e4rkk\u00e4", "year": 2010}, {"title": "Gaussian filtering and smoothing for continuous-discrete dynamic systems", "author": ["S. S\u00e4rkk\u00e4", "J. Sarmavuori"], "venue": null, "citeRegEx": "S\u00e4rkk\u00e4 and Sarmavuori,? \\Q2012\\E", "shortCiteRegEx": "S\u00e4rkk\u00e4 and Sarmavuori", "year": 2012}, {"title": "Dynamic retrospective filtering of physiological noise in BOLD fMRI: DRIFTER", "author": ["S. S\u00e4rkk\u00e4", "A. Solin", "A. Nummenmaa", "A. Vehtari", "T. Auranen", "S. Vanni", "Lin", "F.-H"], "venue": null, "citeRegEx": "S\u00e4rkk\u00e4 et al\\.,? \\Q2012\\E", "shortCiteRegEx": "S\u00e4rkk\u00e4 et al\\.", "year": 2012}, {"title": "Autonomous prediction of GPS and GLONASS satellite", "author": ["M. Sepp\u00e4nen", "J. Ala-Luhtala", "R. Pich\u00e9", "S. Martikainen"], "venue": "orbits. Navigation,", "citeRegEx": "Sepp\u00e4nen et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Sepp\u00e4nen et al\\.", "year": 2012}, {"title": "Nonlinear continuous time modeling approaches in panel research", "author": ["H. Singer"], "venue": "Statistica Neerlandica,", "citeRegEx": "Singer,? \\Q2008\\E", "shortCiteRegEx": "Singer", "year": 2008}, {"title": "Continuous-discrete state-space modeling of panel data with nonlinear filter", "author": ["H. Singer"], "venue": "algorithms. AStA,", "citeRegEx": "Singer,? \\Q2011\\E", "shortCiteRegEx": "Singer", "year": 2011}, {"title": "Efficient sampling for Gaussian process inference using control variables", "author": ["M. Titsias", "N.D. Lawrence", "M. Rattray"], "venue": "In NIPS", "citeRegEx": "Titsias et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Titsias et al\\.", "year": 2009}], "referenceMentions": [{"referenceID": 6, "context": "Gaussian processes (GPs) are stochastic processes, which are commonly used for representing uncertainties of dynamic systems in many applications such as tracking, navigation and automatic control systems (Jazwinski, 1970; Bar-Shalom et al., 2001; Grewal & Andrews, 2001; Maybeck, 1982).", "startOffset": 205, "endOffset": 286}, {"referenceID": 2, "context": "Gaussian processes (GPs) are stochastic processes, which are commonly used for representing uncertainties of dynamic systems in many applications such as tracking, navigation and automatic control systems (Jazwinski, 1970; Bar-Shalom et al., 2001; Grewal & Andrews, 2001; Maybeck, 1982).", "startOffset": 205, "endOffset": 286}, {"referenceID": 9, "context": "Gaussian processes (GPs) are stochastic processes, which are commonly used for representing uncertainties of dynamic systems in many applications such as tracking, navigation and automatic control systems (Jazwinski, 1970; Bar-Shalom et al., 2001; Grewal & Andrews, 2001; Maybeck, 1982).", "startOffset": 205, "endOffset": 286}, {"referenceID": 12, "context": "In this paper we show how non-linear latent force models can be represented as non-linear white noise driven state-space models, that is, partially observed non-linear stochastic differential equations (SDEs Jazwinski, 1970; Grewal & Andrews, 2001; \u00d8ksendal, 2003) and show how recently developed efficient non-linear Kalman filtering and smoothing based methods (S\u00e4rkk\u00e4, 2007; Singer, 2008; S\u00e4rkk\u00e4, 2010; Arasaratnam et al.", "startOffset": 202, "endOffset": 264}, {"referenceID": 14, "context": "In this paper we show how non-linear latent force models can be represented as non-linear white noise driven state-space models, that is, partially observed non-linear stochastic differential equations (SDEs Jazwinski, 1970; Grewal & Andrews, 2001; \u00d8ksendal, 2003) and show how recently developed efficient non-linear Kalman filtering and smoothing based methods (S\u00e4rkk\u00e4, 2007; Singer, 2008; S\u00e4rkk\u00e4, 2010; Arasaratnam et al., 2010; Singer, 2011; S\u00e4rkk\u00e4 & Sarmavuori, 2012) can be used for inferring the state and parameters of these models.", "startOffset": 363, "endOffset": 472}, {"referenceID": 19, "context": "In this paper we show how non-linear latent force models can be represented as non-linear white noise driven state-space models, that is, partially observed non-linear stochastic differential equations (SDEs Jazwinski, 1970; Grewal & Andrews, 2001; \u00d8ksendal, 2003) and show how recently developed efficient non-linear Kalman filtering and smoothing based methods (S\u00e4rkk\u00e4, 2007; Singer, 2008; S\u00e4rkk\u00e4, 2010; Arasaratnam et al., 2010; Singer, 2011; S\u00e4rkk\u00e4 & Sarmavuori, 2012) can be used for inferring the state and parameters of these models.", "startOffset": 363, "endOffset": 472}, {"referenceID": 15, "context": "In this paper we show how non-linear latent force models can be represented as non-linear white noise driven state-space models, that is, partially observed non-linear stochastic differential equations (SDEs Jazwinski, 1970; Grewal & Andrews, 2001; \u00d8ksendal, 2003) and show how recently developed efficient non-linear Kalman filtering and smoothing based methods (S\u00e4rkk\u00e4, 2007; Singer, 2008; S\u00e4rkk\u00e4, 2010; Arasaratnam et al., 2010; Singer, 2011; S\u00e4rkk\u00e4 & Sarmavuori, 2012) can be used for inferring the state and parameters of these models.", "startOffset": 363, "endOffset": 472}, {"referenceID": 1, "context": "In this paper we show how non-linear latent force models can be represented as non-linear white noise driven state-space models, that is, partially observed non-linear stochastic differential equations (SDEs Jazwinski, 1970; Grewal & Andrews, 2001; \u00d8ksendal, 2003) and show how recently developed efficient non-linear Kalman filtering and smoothing based methods (S\u00e4rkk\u00e4, 2007; Singer, 2008; S\u00e4rkk\u00e4, 2010; Arasaratnam et al., 2010; Singer, 2011; S\u00e4rkk\u00e4 & Sarmavuori, 2012) can be used for inferring the state and parameters of these models.", "startOffset": 363, "endOffset": 472}, {"referenceID": 20, "context": "In this paper we show how non-linear latent force models can be represented as non-linear white noise driven state-space models, that is, partially observed non-linear stochastic differential equations (SDEs Jazwinski, 1970; Grewal & Andrews, 2001; \u00d8ksendal, 2003) and show how recently developed efficient non-linear Kalman filtering and smoothing based methods (S\u00e4rkk\u00e4, 2007; Singer, 2008; S\u00e4rkk\u00e4, 2010; Arasaratnam et al., 2010; Singer, 2011; S\u00e4rkk\u00e4 & Sarmavuori, 2012) can be used for inferring the state and parameters of these models.", "startOffset": 363, "endOffset": 472}, {"referenceID": 7, "context": "We compare the performance of the method to previously proposed Laplace-approximation and Markov chain Monte Carlo (MCMC) solutions (Lawrence et al., 2006; Titsias et al., 2009).", "startOffset": 132, "endOffset": 177}, {"referenceID": 21, "context": "We compare the performance of the method to previously proposed Laplace-approximation and Markov chain Monte Carlo (MCMC) solutions (Lawrence et al., 2006; Titsias et al., 2009).", "startOffset": 132, "endOffset": 177}, {"referenceID": 18, "context": "Our main motivation for the proposed approach stems from an important real-world problem of long-term prediction of GPS satellite orbits (Sepp\u00e4nen et al., 2012).", "startOffset": 137, "endOffset": 160}, {"referenceID": 7, "context": "For instance, Lawrence et al. (2006) modelled the timedependent expression levels {xj(t)}j=1 ofN genes with a system of first order ODEs", "startOffset": 14, "endOffset": 37}, {"referenceID": 7, "context": "Inference in these models has been previously performed mainly by the Laplace method (Lawrence et al., 2006) and Markov chain Monte Carlo (MCMC) (Titsias et al.", "startOffset": 85, "endOffset": 108}, {"referenceID": 21, "context": ", 2006) and Markov chain Monte Carlo (MCMC) (Titsias et al., 2009).", "startOffset": 44, "endOffset": 66}, {"referenceID": 12, "context": "As discussed by Hartikainen & S\u00e4rkk\u00e4 (2010), GPs with certain stationary covariance functions (including the Mat\u00e9rn class) can be represented as solutions to linear time-invariant (LTI) SDEs (\u00d8ksendal, 2003).", "startOffset": 191, "endOffset": 207}, {"referenceID": 13, "context": "As discussed by Hartikainen & S\u00e4rkk\u00e4 (2010), GPs with certain stationary covariance functions (including the Mat\u00e9rn class) can be represented as solutions to linear time-invariant (LTI) SDEs (\u00d8ksendal, 2003).", "startOffset": 30, "endOffset": 44}, {"referenceID": 14, "context": "Using this view on GP priors, the conversion of linear latent force models into linear-Gaussian statespace models was recently considered by Hartikainen & S\u00e4rkk\u00e4 (2011). In this paper, we consider conversion of non-linear latent force models into non-linear statespace models.", "startOffset": 155, "endOffset": 169}, {"referenceID": 6, "context": "In general, this is a difficult task that has been well studied in the field of stochastics and filtering theory (Jazwinski, 1970).", "startOffset": 113, "endOffset": 130}, {"referenceID": 6, "context": "The formal Bayesian continuousdiscrete filter consists of separate prediction and update steps (Jazwinski, 1970), which are recursively iterated forward in time.", "startOffset": 95, "endOffset": 112}, {"referenceID": 9, "context": "The general Gaussian filtering and smoothing framework is classical (see, e.g., Jazwinski, 1970; Maybeck, 1982), but here we utilize the recently developed sigma-point methods (S\u00e4rkk\u00e4, 2007; Singer, 2008; S\u00e4rkk\u00e4, 2010; Arasaratnam et al.", "startOffset": 68, "endOffset": 111}, {"referenceID": 14, "context": ", Jazwinski, 1970; Maybeck, 1982), but here we utilize the recently developed sigma-point methods (S\u00e4rkk\u00e4, 2007; Singer, 2008; S\u00e4rkk\u00e4, 2010; Arasaratnam et al., 2010; S\u00e4rkk\u00e4 & Sarmavuori, 2012) for numerically solving", "startOffset": 98, "endOffset": 193}, {"referenceID": 19, "context": ", Jazwinski, 1970; Maybeck, 1982), but here we utilize the recently developed sigma-point methods (S\u00e4rkk\u00e4, 2007; Singer, 2008; S\u00e4rkk\u00e4, 2010; Arasaratnam et al., 2010; S\u00e4rkk\u00e4 & Sarmavuori, 2012) for numerically solving", "startOffset": 98, "endOffset": 193}, {"referenceID": 15, "context": ", Jazwinski, 1970; Maybeck, 1982), but here we utilize the recently developed sigma-point methods (S\u00e4rkk\u00e4, 2007; Singer, 2008; S\u00e4rkk\u00e4, 2010; Arasaratnam et al., 2010; S\u00e4rkk\u00e4 & Sarmavuori, 2012) for numerically solving", "startOffset": 98, "endOffset": 193}, {"referenceID": 1, "context": ", Jazwinski, 1970; Maybeck, 1982), but here we utilize the recently developed sigma-point methods (S\u00e4rkk\u00e4, 2007; Singer, 2008; S\u00e4rkk\u00e4, 2010; Arasaratnam et al., 2010; S\u00e4rkk\u00e4 & Sarmavuori, 2012) for numerically solving", "startOffset": 98, "endOffset": 193}, {"referenceID": 19, "context": "As shown by Singer (2011), the Gaussian filtering framework can also used for efficient evaluation of the likelihoods needed in parameter estimation methods.", "startOffset": 12, "endOffset": 26}, {"referenceID": 19, "context": "The expectations in the equations above are taken over the approximating Gaussian distribution, and can be numerically computed with sigma-point and cubature integration methods (see, S\u00e4rkk\u00e4, 2007; Singer, 2008; S\u00e4rkk\u00e4, 2010; Arasaratnam et al., 2010; S\u00e4rkk\u00e4 & Sarmavuori, 2012).", "startOffset": 178, "endOffset": 278}, {"referenceID": 15, "context": "The expectations in the equations above are taken over the approximating Gaussian distribution, and can be numerically computed with sigma-point and cubature integration methods (see, S\u00e4rkk\u00e4, 2007; Singer, 2008; S\u00e4rkk\u00e4, 2010; Arasaratnam et al., 2010; S\u00e4rkk\u00e4 & Sarmavuori, 2012).", "startOffset": 178, "endOffset": 278}, {"referenceID": 1, "context": "The expectations in the equations above are taken over the approximating Gaussian distribution, and can be numerically computed with sigma-point and cubature integration methods (see, S\u00e4rkk\u00e4, 2007; Singer, 2008; S\u00e4rkk\u00e4, 2010; Arasaratnam et al., 2010; S\u00e4rkk\u00e4 & Sarmavuori, 2012).", "startOffset": 178, "endOffset": 278}, {"referenceID": 1, "context": "The expectations in the equations above are taken over the approximating Gaussian distribution, and can be numerically computed with sigma-point and cubature integration methods (see, S\u00e4rkk\u00e4, 2007; Singer, 2008; S\u00e4rkk\u00e4, 2010; Arasaratnam et al., 2010; S\u00e4rkk\u00e4 & Sarmavuori, 2012). As was discussed by Singer (2011), the Gaussian filter also computes approximations to the conditional measurement likelihoods p(yk|y1:k\u22121) \u2248 N(yk|\u03bck,Sk), which can be used in marginal likelihood based parameter learning via the factorization p(y1:T |\u03b8) = \u220fT k=1 p(yk|y1:k\u22121, \u03b8), where \u03b8 denotes a vector of unknown parameters.", "startOffset": 226, "endOffset": 314}, {"referenceID": 3, "context": "An alternative way of performing state inference would be to use a particle filter (Doucet et al., 2001), which approximates the posterior with sequential importance sampling.", "startOffset": 83, "endOffset": 104}, {"referenceID": 0, "context": "We could then use particle MCMC methods (Andrieu et al., 2010) for estimating the unknown parameters.", "startOffset": 40, "endOffset": 62}, {"referenceID": 0, "context": "The difficulty in using particle filters with SDEs is that when the state transition density cannot be evaluated in closed form, one is restricted to usage of the dynamic model as the importance distribution (Andrieu et al., 2010), which leads to inefficient sampling.", "startOffset": 208, "endOffset": 230}, {"referenceID": 7, "context": "The drift model in this case is linear and can thereby be solved approximately as a function of u(t) (Lawrence et al., 2006), and thus it is possible to implement Laplace and MCMC for it.", "startOffset": 101, "endOffset": 124}, {"referenceID": 11, "context": "The estimation results are listed in Table 1 for Laplace approximation (LA), elliptical slice sampling (ESLS) (Murray et al., 2010) and a Gaussian continuous-discrete filter/smoother (GFS) with moment matching performed with the spherical cubature rule (Arasaratnam et al.", "startOffset": 110, "endOffset": 131}, {"referenceID": 1, "context": ", 2010) and a Gaussian continuous-discrete filter/smoother (GFS) with moment matching performed with the spherical cubature rule (Arasaratnam et al., 2010; S\u00e4rkk\u00e4 & Sarmavuori, 2012).", "startOffset": 129, "endOffset": 182}, {"referenceID": 18, "context": "Accurate modeling of the forces acting on a GPS satellite is needed in a number of applications and real-time applications require prediction of the orbit (Sepp\u00e4nen et al., 2012).", "startOffset": 155, "endOffset": 178}, {"referenceID": 18, "context": "For more details, see Montenbruck & Gill (2005) and Sepp\u00e4nen et al. (2012).", "startOffset": 52, "endOffset": 75}, {"referenceID": 17, "context": "To model the quasi-periodicities in the latent forces we use a stochastic resonator model, which previously has been used for modeling periodic phenomena in the brain (S\u00e4rkk\u00e4 et al., 2012).", "startOffset": 167, "endOffset": 188}, {"referenceID": 14, "context": "As shown by S\u00e4rkk\u00e4 et al. (2012), this model can be written in state space form", "startOffset": 12, "endOffset": 33}], "year": 2012, "abstractText": "Latent force models (LFMs) are flexible models that combine mechanistic modelling principles (i.e., physical models) with nonparametric data-driven components. Several key applications of LFMs need nonlinearities, which results in analytically intractable inference. In this work we show how non-linear LFMs can be represented as nonlinear white noise driven state-space models and present an efficient non-linear Kalman filtering and smoothing based method for approximate state and parameter inference. We illustrate the performance of the proposed methodology via two simulated examples, and apply it to a real-world problem of long-term prediction of GPS satellite orbits.", "creator": "LaTeX with hyperref package"}}}