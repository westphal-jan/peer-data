{"id": "1211.3089", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Nov-2012", "title": "ET-LDA: Joint Topic Modeling for Aligning Events and their Twitter Feedback", "abstract": "During broadcast performances any more the Superbowl, when U. S. Presidential and Primary talk, ebd. , Twitter given well this luz diplomatic front other crowds to share perspectives most scripture about them. Given from day and gives associated massive - response pieces such websites, there besides two concept research problems that only been received increasing attention saw reports when. One probably means herbs the topics water by and night and on tweets; full other entirely able lines the event. So close these not be been albeit separately they studied in alleviate. In all complete, simply understood one furthermore unfortunately example saw fact 1-0 - conversely but should sure indicated back. We develop an joint Bayesian which that solo topic integrating made upcoming semantic in either unified discussions. We ability created proposed model turn quantitatively and qualitatively on went once - measuring tweet datasets associated together two marked soon follow conserved be featured that but improves risen turned baseline models.", "histories": [["v1", "Tue, 13 Nov 2012 19:46:51 GMT  (807kb,D)", "http://arxiv.org/abs/1211.3089v1", "arXiv admin note: substantial text overlap witharXiv:1210.2164"], ["v2", "Fri, 21 Dec 2012 05:50:15 GMT  (0kb,I)", "http://arxiv.org/abs/1211.3089v2", "reference error, delete for now"]], "COMMENTS": "arXiv admin note: substantial text overlap witharXiv:1210.2164", "reviews": [], "SUBJECTS": "cs.SI cs.AI cs.CY", "authors": ["yuheng hu", "ajita john", "fei wang", "subbarao kambhampati"], "accepted": true, "id": "1211.3089"}, "pdf": {"name": "1211.3089.pdf", "metadata": {"source": "CRF", "title": "ET-LDA: Joint Topic Modeling for Aligning Events and their Twitter Feedback", "authors": ["Yuheng Hu", "Ajita John", "Fei Wang", "Subbarao Kambhampati"], "emails": ["rao}@asu.edu", "ajita@avaya.com", "feiwang03@gmail.com"], "sections": [{"heading": "1 Introduction", "text": "During public broadcast events such as the Superbowl, the U.S. Presidential and Primary debates, the last episode of a TV drama series, etc., Twitter has become the de facto platform for crowds to share perspectives and commentaries about these events. Given an event and an associated largescale collection of tweets, we face two fundamental problems in analyzing and understanding them, namely, extracting the topics covered in the event and tweets, and segmenting the event into topically coherent segments. Tackling the two problems is critical to applications like computational advertising, community detection, journalistic investigation, storytelling, playback of events, etc. While both topical modeling and event segmentation have received considerable attention in recent years, they have been mainly viewed as separate problems and studied in isolation. For example, there have been significant efforts on developing Bayesian models to discover the patterns that reflect the underlying topics from the document (Blei, Ng, and Jordan 2003; Griffiths et al. 2004; Wang and McCallum 2006; Titov and McDonald 2008). Similarly, there is also a rich body of work devoted to segmentation of events/discourses/meetings via heuristics, machine learning, etc. (Hearst 1993; Boykin\nCopyright c\u00a9 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\nand Merlino 2000; Galley et al. 2003; Dielmann and Renals 2004).\nDirectly applying these current solutions to analyze the event and its associated tweets however has a major drawback: they treat event and tweets independently, thus ignoring the topical influences of the event on its associated tweets. In reality they are obviously inter-dependent. For example, in practice, when tweets are generated by the crowds to express their interests in the event, their content is essentially influenced by the topics covered in the event in some way. Based on such dependencies, i.e., topical influences, a person can respond to the event in a variety of ways. For example, she may choose to comment directly on a specific topic in the event which is of concern and/or interest to her. So, her tweets would be deeply influenced by that specific topic. In another situation, she could also comment broadly about the event. Therefore, the tweets would be less influenced by the specific topics but more by the general topics of the event.\nIn this paper, we are interested in jointly modeling the topics of the event and its associated tweets, as well as segmenting the event in one unified model. Our work is motivated by the observation that the topical influences from the event on its associated tweets are not only used for indicating the topics mentioned in the event but also indicating the content/topics in tweets and the tweeting behaviors of the crowd. Besides, by accounting for such influences on tweets, we can obtain a richer context about the evolution of topics and the topical boundaries in the event which is critical to the event segmentation, as mentioned in (Shamma, Kennedy, and Churchill 2009).\nWe build our joint model based on Latent Dirchlet Allocation (LDA), a Bayesian model proven to be effective for topic modeling. In our model, an event may consist of many paragraphs, each of which discusses a particular set of topics. These topics evolve over the timeline of the event. We assume that whether the topic mixture of a paragraph changes from the one in its preceding paragraph follows a binomial distribution parameterized by the similarity between their topic distributions. With some probability, the two paragraphs are merged to form a segment; otherwise, a new segment is created. Additionally, we assume the event (in fact the segments) can impose topical influences on the associated tweets. Under such influences, the words in the\nar X\niv :1\n21 1.\n30 89\nv1 [\ncs .S\nI] 1\n3 N\nov 2\n01 2\ntweets can belong to two distinct types of topics: general topics, which are high-level and constant across the entire event, and specific topics, which are detailed and relate to specific segments of the event. We define a tweet in which most words belong to general topics as a \u201cgeneral tweet\u201d, indicating a weak topical influence from the event, whereas a tweet with more words about the specific topics is defined as a \u201cspecific tweet\u201d, indicating a strong topical influence from one segment of the event. Similar to the event segmentation, whether the event has strong or weak influence on tweets depends on a binomial distribution. To learn our model, we derive inference and estimate parameters using Gibbs sampling. In the update equations, we can observe how the tweets help regularize the topic modeling process via topical influences and vice versa. To test our model, we apply it to two large-scale tweet datasets associated with two events from different domains (a) President Obama\u2019s Middle East speech on May 19, 2011 and (b) the Republican Primary debate on September 9, 2011. We examine the results both quantitatively and qualitatively to demonstrate that our model improves significantly over baseline models."}, {"heading": "2 Related Work", "text": "Topic modeling methods, such as Latent Dirichlet Allocation (Blei, Ng, and Jordan 2003) have achieved great success in discovering underlying topics from text documents. Recently, there has been increasing interest in developing better and sophisticated topic modeling schemes. One line of such research is to extend topic models on networked documents, e.g., research publications, blogs etc. PHITS (Hofmann 2001) models the documents and their interconnectivity based on topic-specific distributions. Further extensions include (Dietz, Bickel, and Scheffer 2007), LinkPLSA-LDA (Nallapati et al. 2008) and RTM (Chang and Blei 2009). In addition, some works consider the dynamics of topics which include dynamic topic model (Blei and Lafferty 2006). Also, recent efforts apply topic modeling on social media such as (Ramage, Dumais, and Liebling 2010; Hu and Liu 2012).\nIn parallel, there is a rich body of work on automatic topic segmentation of events/texts/meetings. Many approaches have been developed. For example, (Hearst 1993) uses a measure of lexical cohesion between adjoining paragraphs for segmenting texts. LCSeg (Galley et al. 2003) uses a similar approach on both text and meeting transcripts and gains better performance than that achieved by applying text/monologue-based techniques. In addition to lexical approaches, machine learning methods have also been considered. (Beeferman, Berger, and Lafferty 1999) combines a variety of features such as statistical language modeling, cue phrases, discourse information to segment broadcast news. Recent advances have used generative models such as (Purver et al. 2006).\nThe focus of most of the above work is either to model topics in documents (where documents are assumed to be the homogenous, e.g, research papers) or segment the events alone. However, they do not provide insights into how to characterize one source of text (tweets) in response to another (event). A distinct difference in our work is that, the\nevent and the associated tweets are heterogenous: the topics in a tweet may be sampled from different types of topic mixtures (general or specific). Additionally, the topic mixtures in an event evolve over its timeline. While the current paper focuses on the technical development and evaluation of the ET-LDA framework, our companion papers (Hu, John, and Seligmann 2011; Hu et al. 2012) elaborate on the motivations for joint analysis and alignment of events and tweets."}, {"heading": "3 Joint modeling of Event and Twitter Feeds", "text": "In this section, we show how to represent the event and its Twitter feeds by a hierarchical Bayesian model based on Latent Dirichlet Allocation (LDA), so that the topic modeling of the event/tweets and event segmentation can be achieved. Table 1 lists the notation used in this paper."}, {"heading": "3.1 Model", "text": "Our proposed model called the joint Event and Tweets LDA (ET-LDA), aims to model (1) the event\u2019s topics and their evolution (event segmentation), as well as (2) the associated tweets\u2019 topics and the crowd\u2019s tweeting behaviors. Therefore, the model has two major components with each capturing one perspective of our target. The conceptual model of ET-LDA is shown in Fig. 1a and its graphical model representation is in Fig. 1b. Both parts have the LDA-like model, and are connected by the link which captures the topical influences from the event on its Twitter feeds.\nMore specifically, in the event part, we assume that an event is formed by discrete sequentially-ordered segments, each of which discusses a particular set of topics. A segment consists of one or many coherent paragraphs available\n1\nGeneral Topics remain constant through transcript\nEach segment has specific topics\nA general tweet draws words mostly from general topics\nA specific tweet draws words mostly from specific topics and thus refers to particular segments.\nA referred segment could be a segment in the past, a current segment, or a segment in the future.\nEvent Transcript\n(a) Conceptual model of ET-LDA\nsN S\n\n( )s\n( )sc\nT\n\n( )t\n( )tc\n( )t\n\n( )ts\n\ni sw\ni\nsz i tz\ni tw\n( )s\nK\n\n\ntM\n( )t \n(b) Plate model of ET-LDA\nFigure 1: The graphical model representation of ET-LDA\nfrom the transcript of the event.1 Each paragraph s is associated with a particular distribution of topics \u03b8(s). To model the topic evolutions in the event, we apply the Markov assumption on \u03b8(s): with some probability, \u03b8(s) is the same as the distribution of topics of previous paragraph s \u2212 1, measured by the delta function \u03b4(\u03b8(s\u22121), \u03b8(s)); otherwise, a new distribution of topics \u03b8(s) is sampled for s, chosen from a Dirichlet(\u03b1\u03b8). This pattern of dependency is produced by associating a binary variable c(s) with each paragraph, indicating whether its topic is the same as that of the previous paragraph or different. If the topic remains the same, these paragraphs are merged to form one segment. This variable is associated with a binomial distribution \u03b4(s) parameterized by a symmetric beta prior \u03b1\u03b4 .\nIn the tweets part, we assume that a tweet consists of words which can belong to two distinct types of topics: general topics, which are high-level and constant across the entire event, and specific topics, which are detailed and relate to the segments of the event. As a result, the distribution of general topics is fixed for a tweet. However, the distribution of specific topics keeps varying with respect to the development of the event. We define a tweet in which most words belong to general topics as a general tweet, indicating a weak topical influence from the event. In contrast, a tweet with more words about the specific topics is defined as a specific tweet, indicating a strong topical influence from one segment of the event. In other words, a specific tweet refers to a segment of the event. Similar to the event segmentation, each word in a tweet is associated with a distribution of topics. It can be either sampled from a mixture of specific topics \u03b8(s) or a mixture of general topics \u03c8(t) over K topics depending on a binary variable c(t) sampled from a binomial distribution \u03bb(t). In the first case, \u03b8(s) is from a referring segment s of the event, where s is chosen according to a categorical distribution s(t). Unlike \u03b4(s), \u03bb(t) is controlled by an asymmetrical beta prior parameterized by the preference parameter \u03b1\u03bb\u03b3 (for specific topics) and \u03b1\u03bb\u03c8 (for general topics). An important property of the categorical distribution s(t) is to allow choosing any segment in the event. This re-\n1For many publicly televised events, transcripts are readily published by news services like NY Times etc. Paragraph outlines in the transcripts are usually determined through human interpretation and may not necessarily correspond to topic changes in the event.\nflects the fact that a person may compose a tweet on topics discussed in a segment that (1) was in the past (2) is currently occurring, or (3) will occur after the tweet is posted (usually when she expects certain topics to be discussed in the event)\nTo summarize, we have the following generative process:\nProcedure Generation Process in ET-LDA foreach paragraph s \u2208 S do\ndraw a segment choice indicator c(s) \u223c Bernoulli(\u03b4(s)) if c(s) = 1 then\ndraw a topic mixture \u03b8(s) \u223c Dirichlet(\u03b1\u03b8) else\ndraw a topic mixture \u03b8(s) \u223c \u03b4(\u03b8(s\u22121), \u03b8(s)) foreach word wis \u2208 s do\ndraw a topic zis \u223cMultinomial(\u03b8(s)) draw a word wis \u223c \u03c6zis\nforeach tweet t \u2208 T do foreach word wit \u2208 t do\ndraw a topic changing indicator c(t) \u223c Bernoulli(\u03bb(t)) if c(t) = 1 then\ndraw a topic mixture \u03c8(t) \u223c Dirichlet(\u03b1\u03c8) draw a general topic zit \u223cMultinomial(\u03c8(t)) else draw a paragraph s \u223c Categorical(\u03b3(t)) draw a specific topic zit \u223cMultinomial(\u03b8(s)) draw a word from its associated topic wit \u223c \u03c6zit\nWith the model hyperparameters \u03b1, \u03b2, the joint distribution of observed and hidden variables ws, wt, zs, zt, cs, ct, and st can be written as blow.\nP (ws,wt, zs, zt, cs, ct, st|\u03b1\u03b4, \u03b1\u03b8, \u03b1\u03b3 , \u03b1\u03bb, \u03b1\u03c8, \u03b2) =\u222b \u00b7 \u00b7 \u00b7 \u222b P (ws|zs, \u03c6)P (wt|zt, \u03c6)P (\u03c6|\u03b2)P (st|\u03b3(t))P (\u03b3(t)|\u03b1\u03b3)\nP (zs|\u03b8(s))P (zt|\u03b8(s), st, ct = 0)P (\u03b8(s)|\u03b1\u03b8, cs)P (cs|\u03b4(s))P (\u03b4(s)|\u03b1\u03b4)\nP (zt|\u03c8(t), ct = 1)P (\u03c8(t)|\u03b1\u03c8)P (ct|\u03bb(t))P (\u03bb(t)|\u03b1\u03bb\u03b3 , \u03b1\u03bb\u03c8 )\nd\u03b3 (t) d\u03b8 (s) d\u03b4 (s) d\u03bb (t) d\u03c8 (t) d\u03c6 (1)"}, {"heading": "3.2 Inference in the Model via Gibbs Sampling", "text": "The computation of the posterior distribution of the hidden variables zs, zt, cs, ct and st is intractable for the ET-LDA\nmodel because of the coupling between \u03b1, \u03b2. Therefore, in this paper, we utilize approximate methods like collapsed Gibbs sampling algorithm (Griffiths et al. 2004) for parameter estimation. Note that Gibbs sampling allows the learning of a model by iteratively updating each latent variable given the remaining variables.\nTo begin with, we need to compute conditional probability P (zt, zs, ws, wt, cs, ct, st|z\u2032t, z\u2032s,ws,wt, c\u2032s, c\u2032t, s\u2032t), where z\u2032t, z \u2032 s, c \u2032 s, c \u2032 t, s \u2032 t are vectors of assignments of topics, segment indicators, topic switching indicators and segment choice indicators for all words in the collection except for the one at position i in a tweet or an event\u2019s transcript. According to the Bayes rule, we can compute this conditional probability in terms of the joint probability distribution of the latent and observed variables shown in Eq.1. Next, to make the sampling procedure clearer, we factorize this joint probability as:\nP (ws,wt, zs, zt, cs, ct, st) =\nP (ws,wt|zs, zt)P (zs, zt|cs, ct, st)P (cs)P (ct)P (st) (2)\nBy integrating out the parameter \u03c6 we can obtain the first term in Eq.2:\nP (ws,wt|zs, zt) = ( \u0393(W\u03b2)\n\u0393(\u03b2)W )K K\u220f k=1 \u220fW w=1 \u0393(n k sw + n k tw + \u03b2) \u0393(nk s(.) + nk t(.) +W\u03b2) (3)\nwhere W is the size of the vocabulary, nksw and n k tw are the numbers of times topic k assigned to wordw in the event and the tweets. nks(.) and n k t(.) are the total number of words in the event and tweets assigned to topic k. \u0393(\u00b7) is the gamma function.\nTo evaluate the second term in Eq.2, we need to consider the value of a tweet\u2019s topic switching indicator ct because it determines whether a word\u2019s topic zt is general, i.e, sampling from \u03c8(t) (when ct = 1) or specific, i.e., sampling from \u03b8(s) (when ct = 0). Based on the model structure in Fig.1b, we factor the second term as P (zs, zt|cs, cs, st) = P (zs)P (zt|cs, ct = 0, st)P (zt|ct = 1, st) and compute each of these factors individually. So when ct = 0, by integrating out \u03b8(s) and canceling the factor that does not depend on this value, we obtain:\nP (zs)P (zt|cs, ct = 0, st) = ( \u0393(K\u03b1\u03b8)\n\u0393(\u03b1\u03b8)K )S S\u220f i=1 \u220fK k=1 \u0393(n Si k + nt Si k + \u03b1\u03b8) \u0393(n Si (.) + nt Si (.) +K\u03b1\u03b8)\n(4)\nwhere S is a set of segments of the event. nSik is the number of times topic k appears in the segment Si, and ntSik is the number of times topic k appears in tweets, where these tweets refer to the content in segment Si. Similarly, when ct = 1, by integrating out \u03c8(t) and canceling the factor that does not depend on this value, we have:\nP (zt|ct = 1, st) = ( \u0393(K\u03b1\u03c8)\n\u0393(\u03b1\u03c8)K )T T\u220f i=1 \u220fK k=1 \u0393(n i k + \u03b1\u03c8) \u0393(ni (.) +K\u03b1\u03c8) (5)\nin which T is the total number words in tweet t which are under the general topics, and nik is the number of times topic k assigns to words i.\nNext, we evaluate the third term in Eq.2. By integrating out \u03b4(s) we compute:\nP (cs) = \u0393(2\u03b1\u03b4) \u0393(\u03b1\u03b4)2 \u0393(S0s + \u03b1\u03b4)\u0393(S 1 s + \u03b1\u03b4) \u0393(S + 2\u03b1\u03b4) (6)\nwhere S is the total number of paragraphs in an event. S1s is the number of segments (the number of times the topic of paragraph s differs from its preceding paragraph, i.e., cs = 1).\nSimilarly, for the fourth term in Eq.2, we integrate out \u03bb(t) and get:\nP (ct) = \u220f t\u2208T \u0393(\u03b1\u03bb\u03b3 + \u03b1\u03bb\u03c8 ) \u0393(\u03b1\u03bb\u03b3 )\u0393(\u03b1\u03bb\u03c8 ) \u0393(M0t + \u03b1\u03bb\u03b3 )\u0393(M 1 t + \u03b1\u03bb\u03c8 ) \u0393(Mt + \u03b1\u03bb\u03b3 + \u03b1\u03bb\u03c8 ) (7)\nwhere Mt is the total number of words in tweet t, M0t is the number of words that are under the specific topics, and M1t is the number of words in t that are under the general topics. Last, we need to derive the fifth term. Again, by integrating out \u03b3(t) we have:\nP (st) =\n( \u0393(K\u03b1\u03b3)\n\u0393(\u03b1\u03b3)K )T T\u220f i=1 \u220fS s=1 \u0393(n i s + \u03b1\u03b3) \u0393(ni (.) + S\u03b1\u03b3) (8)\nwhere nis is the number of times paragraph s (in fact its associated segment) is referred by tweet t.\nNow, the conditional probability can be obtained by multiplying and canceling of terms in Eq.3\u20138. We show the core case (when cs = 0) here while the other case (when cs = 1) is omitted due to the space limit.\nP (zt, zs, ws, wt, cs = 0, ct = 0, st|z\u2032t, z \u2032 s,ws,wt, c \u2032 s, c \u2032 t, s \u2032 t) =\nnksw + n k tw + \u03b2 \u2212 1\nnk s(.) + nk t(.)\n+W\u03b2 \u2212 1 \u00d7\nn Si k + nt Si k + \u03b1\u03b8 \u2212 1\nn Si (.) + nt Si (.) +K\u03b1\u03b8 \u2212 1 \u00d7 nis + \u03b1\u03b3 \u2212 1 ni (.) + S\u03b1\u03b3 \u2212 1\nM0t + \u03b1\u03bb\u03b3 \u2212 1 Mt + \u03b1\u03bb\u03b3 + \u03b1\u03bb\u03c8 \u2212 1 \u00d7 S0t + \u03b1\u03b4 \u2212 1 Mt + 2\u03b1\u03b4 \u2212 1\n(9)\nand when ct = 1 we have the conditional probability: P (zt, zs, ws, wt, cs = 0, ct = 1, st|z\u2032t, z \u2032 s,ws,wt, c \u2032 s, c \u2032 t, s \u2032 t) =\nnksw + n k tw + \u03b2 \u2212 1\nnk s(.) + nk t(.)\n+W\u03b2 \u2212 1 \u00d7 nik + \u03b1\u03c8 \u2212 1 ni (.) +K\u03b1\u03c8 \u2212 1 \u00d7 nis + \u03b1\u03b3 \u2212 1 ni (.) + S\u03b1\u03b3 \u2212 1\nM1t + \u03b1\u03bb\u03b3 \u2212 1 Mt + \u03b1\u03bb\u03b3 + \u03b1\u03bb\u03c8 \u2212 1 \u00d7 S1t + \u03b1\u03b4 \u2212 1 Mt + 2\u03b1\u03b4 \u2212 1\n(10)\nIn both of these expressions, counts are computed without taking into account assignments of the considered word wis and w i t. After algebraic manipulation to Eq.9 and 10, we can easily derive Gibbs update equations for variables zt, zs, cs, ct and st which are omitted here.2 Sampling with these questions is fast and in practice convergence can be achieved in time similar to that needed by LDA implementations.\n2For each variable, in order to derive its update equation, one can first pick the factors that depend on it in Eq.2 and then select the corresponding factors in Eq.9 or Eq.10 under the condition that cs = 0. For cs = 1, the derivation is the same.)"}, {"heading": "4 Experiments", "text": "In this section, we examine the effectiveness of our proposed joint model against other baselines. Three main tasks are undertaken to evaluate the ET-LDA: (1) the topics extracted from the whole corpus (tweets and transcripts of events) are compared with those separately extracted from the LDA model, (2) the capability of predicting topical influences of the events on unseen tweets in the test set is compared with LDA, and (3) the quality of event segmentation is compared with LCSeg \u2013 a popular HMM-based segmenting tool in the literature (Galley et al. 2003).\nData Sets and Experimental Setup We use two largescale tweet datasets associated with two events from different domains: (1) President Obama\u2019s Middle East speech on May 19, 2011 and (2) the Republican Primary debate on Sept 7, 2011. The first tweet dataset consists of 25,921 tweets tagged with \u201c#MESpeech\u201d and the second dataset consists of 121,256 tweets tagged with \u201c#ReaganDebate\u201d. Both tweet datasets were crawled via the Twitter API using these two hashtags (which were officially posted by the White House and NBC News, respectively, before the event). In the rest of this paper, we use the hashtags to refer to these events. Furthermore, we split both tweet datasets into a 80-20 training and test sets.\nWe obtained the transcripts of both events from the New York Times,3 where MESpeech has 73 paragraphs and ReaganDebate has 230 paragraphs. We applied preprocessing to both tweets and transcripts by removing non-English tweets, retweets, punctuation and stopwords and stemming all terms. Further, it is known that topic modeling methods (including LDA) behave badly when applied to short documents (Hu et al. 2009). To remedy this, we follow the scheme in (Sahami and Heilman 2006) to augment a tweet\u2019s context. First, we treat a tweet as a query and send it to a search engine. After generating a set of top-n query snippets d1, ..., dn, we compute the TF-IDF term vector vi for each di. Finally, we pick the top-m terms from vi and concatenate them to t to form an expanded tweet. In the experiments, we used the Google custom search engine for retrieving snippets and set n = 5 and m = 10. Such augmentation was\n3 http://www.nytimes.com/2011/05/20/world/middleeast/20prexy-text.html and\nhttp://www.nytimes.com/2011/09/08/us/politics/08republican-debate-text.html\napplied to both tweet datasets. In the experiments, we used the Gibbs sampling algorithm for training ET-LDA on the tweets dataset with the transcript of associated event. The sampler was run for 1000 iterations for both datasets. Coarse parameter tuning for the prior distributions was performed. We varied the number of topics K in ET-LDA and chose the one which maximizes the loglikehood P (ws,wt|K), a standard approach in Bayesian statistics (Griffiths and Steyvers 2004). As a result, we set K = 20. In addition, we set model hyperparameters \u03b1\u03b4 = 0.1, \u03b1\u03b8 = 0.1, \u03b1\u03b3 = 0.1, \u03b1\u03bb\u03b3 = \u03b1\u03bb\u03c8 = 0.5, \u03b1\u03c8 = 0.1, and \u03b2 = 0.01.\nTopic Modeling: We first study the performance of ETLDA on topic modeling for the two events and their tweets against the baseline LDA (which was trained on the event transcripts and tweet datasets separately with K = 20). Table 2 and 3 present the top words, i.e., the highest probability words from topics for (i) top specific topics discovered from a sample of 3 (out of 7 for MESpeech, or, out of 14 for ReaganDebate) segments of the events, and (ii) for a sample of the general topics from the tweets collection using the ET-LDA model. The results of segmentation are shown next. For comparison, both tables also list the top words for the topics discovered from (iii) the event and (iv) tweets individually using LDA. Note that all of the topics have been manually labeled for identification (e.g. \u201cArab Spring\u201d, \u201cImmigration\u201d) to reflect our interpretation of their meaning from their top words.\nIt is clear that all specific and general topics from the ET-LDA model are very reasonable from a reading of the transcripts. Furthermore, we observe that the specific topics are sensitive to the event\u2019s context and keep evolving as the event progresses. On the other hand, general topics and their top words capture the overall themes of the event well. But unlike specific topics, these are repeatedly used across the entire event by the crowd in their tweets, in particular when expressing their views on the themes of the event (e.g., \u201cArab spring\u201d, \u201cImmigration\u201d) or even on some popular issues that are neither related nor explicitly discussed in the event (e.g., \u201cObama\u201d in MESpeech, \u201cConservative\u201d in ReaganDebate).\nThe results of LDA seem less reasonable by comparison.\nAlthough LDA may extract general topics like \u201cIsrael Palestine issues\u201d just like ET-LDA since these topics remain constant throughout the document, LDA cannot extract specific topics for the event. In fact, \u201cIsrael Palestine issues\u201d shows the advantage of ET-LDA: it is the top general topic for entire tweet collection (which is very relevant to and influenced by the event) whereas LDA fails to identify that (its top topic is \u2019Obama\u2019 which is less relevant). The data showed that people tweeted about this issue a lot. Besides, some top words for LDA topics are not so related to the event. This lack of correspondence is more pronounced for LDA when it is applied to the tweet datasets, e.g., GOP Job Approval in topic \u201cObama\u201d of the tweets corpus by LDA. This is mainly because ET-LDA successfully characterizes the topical influences from the event on its Twitter feeds such that the content/topics of tweets are regularized, whereas the LDA method ignores these influences and thus gives less reasonable results.\nPrediction Performance: Next, we study the prediction performance of ET-LDA. Specifically, we are interested in the prediction of topical influences from the event on the unseen tweets in our test set (20% of total tweets). Thus, we first run the Gibbs sampling algorithm, described in previous section, on the training set for each event/tweet dataset. Then we extend the sampler state with samples from the test set. For comparison, we adopt LDA as our baseline approach. However, since LDA treats the event and tweets individually, we measure the topical influences by the dis-\ntance of topic mixtures of the unseen tweets to the ones of the segments of the event (as determined by ET-LDA in advance). This distance is measured by the Jensen-Shannon divergence.\nN or\nm al\niz ed\nL ik\ner t S\nca le\nTo evaluate the \u201cgoodness\u201d of prediction results by our proposed model, we asked 30 graduate students from the engineering school of our university (who were selected as they follow the news closely and tweet at least three times per week) to manually label the quality and strength of the predicted topical influences from events on the unseen tweet datasets on a Likert scale of 1 to 5 rating. We then averaged these ratings over the value diversity (i.e., normalization). In Fig. 3a and 3b, we present the results of the two methods on 5 randomly sampled segments.\nIn light of the observed differences in Fig. 3a and 3b, we study the statistical significance of ET-LDA with respect to LDA. We perform paired-t-tests for models with a significance level of \u03b1 = 0.05 (p = 0.0161 and p = 0.0029 for MESpeech and ReaganDebate, respectively). This reveals that the improvement in prediction performance of ET-LDA is statistically significant.\nEvent Segmentation: Finally, we study the quality and effectiveness of ET-LDA on the segmentation of the two events based on their transcripts. The results of the event\nsegmentation (obtained using K = 20 in ET-LDA) are shown in Fig. 2a and 2b. To evaluate our model, we compare its results with the ones from a popular HMM-based tool LCSeg (trained on 15-state HMM) on the Pk measure (Beeferman, Berger, and Lafferty 1999). Note that this measure is the probability that a randomly chosen pair of words from the event will be incorrectly separated by a hypothesized segment boundary. Therefore, the lower Pk indicates better agreement with the human-annotated segmentation results, i.e., better performance. In practice, we first ask four graduate students in our department to annotate the segments of the events based on their transcripts (two for each event) and later ask another graduate student to judge, for one event, which human annotation is better. We pick the better one of each event and treat it as the hypothesized segmentation. Then, we compute the Pk value. The results of two methods are shown in Table. 4.\nThe results show that our model significantly outperforms the LCSeg \u2013 as the latter cannot merge topic mixtures in paragraphs according to their similarity, and thus places a lot of segmentation boundaries (i.e., over-segmented), resulting in poor performance."}, {"heading": "5 Conclusion", "text": "In this paper, we have described a joint statistical model ETLDA that characterizes topical influences between an event and its associated Twitter feeds (tweets). Our model enables the topic modeling of the event/tweets and the segmentation of the event in one unified framework. We evaluated ET-LDA both quantitatively and qualitatively through three tasks. Based on the experimental results, our model shows significant improvements over the baseline methods.\nWe believe this paper presents the first step towards understanding complex interactions between events and social media feedback. In fact, beyond the transcripts of publicly televised events that we used in this paper, ET-LDA can also handle other forms of text sources that describe an event. For example, one can explore how people respond to an event (and how it is different from journalists\u2019 responses in media) by applying our model to the news articles and the social media feedback about this event. We also believe that this paper reveals a perspective that is useful for the extraction of a variety of further dimensions such as sentiment and polarity. For example, one can examine how the crowd\u2019s mood is affected by the event based on the topical influences.\nAcknowledgements: ET-LDA was initially formulated and prototyped at Avaya Labs during a summer internship there by Yuheng Hu, who thanks Dore\u0301e Duncan Seligmann for helpful discussions. Hu and Kambhampati\u2019s re-\nsearch at ASU is supported in part by the ONR grant N000140910032."}], "references": [{"title": "Statistical models for text segmentation", "author": ["Berger Beeferman", "D. Lafferty 1999] Beeferman", "A. Berger", "J. Lafferty"], "venue": "Machine learning", "citeRegEx": "Beeferman et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Beeferman et al\\.", "year": 1999}, {"title": "and Lafferty", "author": ["D. Blei"], "venue": "J.", "citeRegEx": "Blei and Lafferty 2006", "shortCiteRegEx": null, "year": 2006}, {"title": "M", "author": ["D.M. Blei", "A.Y. Ng", "Jordan"], "venue": "I.", "citeRegEx": "Blei. Ng. and Jordan 2003", "shortCiteRegEx": null, "year": 2003}, {"title": "and Merlino", "author": ["S. Boykin"], "venue": "A.", "citeRegEx": "Boykin and Merlino 2000", "shortCiteRegEx": null, "year": 2000}, {"title": "and Blei", "author": ["J. Chang"], "venue": "D.", "citeRegEx": "Chang and Blei 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "and Renals", "author": ["A. Dielmann"], "venue": "S.", "citeRegEx": "Dielmann and Renals 2004", "shortCiteRegEx": null, "year": 2004}, {"title": "Unsupervised prediction of citation influences", "author": ["Bickel Dietz", "L. Scheffer 2007] Dietz", "S. Bickel", "T. Scheffer"], "venue": "In ICML. ACM", "citeRegEx": "Dietz et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Dietz et al\\.", "year": 2007}, {"title": "Discourse segmentation of multi-party conversation", "author": ["Galley"], "venue": "In ACL. Association for Computational Linguistics", "citeRegEx": "Galley,? \\Q2003\\E", "shortCiteRegEx": "Galley", "year": 2003}, {"title": "and Steyvers", "author": ["T. Griffiths"], "venue": "M.", "citeRegEx": "Griffiths and Steyvers 2004", "shortCiteRegEx": null, "year": 2004}, {"title": "J", "author": ["T.L. Griffiths", "M. Steyvers", "D.M. Blei", "Tenenbaum"], "venue": "B.", "citeRegEx": "Griffiths et al. 2004", "shortCiteRegEx": null, "year": 2004}, {"title": "and Liu", "author": ["X. Hu"], "venue": "H.", "citeRegEx": "Hu and Liu 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "Exploiting internal and external semantics for the clustering of short texts using world knowledge", "author": ["Hu"], "venue": "In CIKM. ACM", "citeRegEx": "Hu,? \\Q2009\\E", "shortCiteRegEx": "Hu", "year": 2009}, {"title": "What were the tweets about? topical associations between public events and twitter feeds", "author": ["Hu"], "venue": "In Proceedings of ICWSM. AAAI", "citeRegEx": "Hu,? \\Q2012\\E", "shortCiteRegEx": "Hu", "year": 2012}, {"title": "Event analytics via social media", "author": ["John Hu", "Y. Seligmann 2011] Hu", "A. John", "D. Seligmann"], "venue": "In Proceedings of the 2011 ACM workshop on Social and behavioural networked media access. ACM", "citeRegEx": "Hu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hu et al\\.", "year": 2011}, {"title": "Joint latent topic models for text and citations", "author": ["Nallapati"], "venue": "In KDD. ACM", "citeRegEx": "Nallapati,? \\Q2008\\E", "shortCiteRegEx": "Nallapati", "year": 2008}, {"title": "Unsupervised topic modelling for multi-party spoken discourse", "author": ["Purver"], "venue": "In ACL. Association for Computational Linguistics", "citeRegEx": "Purver,? \\Q2006\\E", "shortCiteRegEx": "Purver", "year": 2006}, {"title": "Characterizing microblogs with topic models", "author": ["Dumais Ramage", "D. Liebling 2010] Ramage", "S. Dumais", "D. Liebling"], "venue": null, "citeRegEx": "Ramage et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ramage et al\\.", "year": 2010}, {"title": "and Heilman", "author": ["M. Sahami"], "venue": "T.", "citeRegEx": "Sahami and Heilman 2006", "shortCiteRegEx": null, "year": 2006}, {"title": "Tweet the debates: understanding community annotation of uncollected sources", "author": ["Kennedy Shamma", "D. Churchill 2009] Shamma", "L. Kennedy", "E. Churchill"], "venue": "In Proceedings of the first SIGMM workshop on Social media. ACM", "citeRegEx": "Shamma et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Shamma et al\\.", "year": 2009}, {"title": "and McDonald", "author": ["I. Titov"], "venue": "R.", "citeRegEx": "Titov and McDonald 2008", "shortCiteRegEx": null, "year": 2008}, {"title": "and McCallum", "author": ["X. Wang"], "venue": "A.", "citeRegEx": "Wang and McCallum 2006", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [], "year": 2017, "abstractText": "During broadcast events such as the Superbowl, the U.S. Presidential and Primary debates, etc., Twitter has become the de facto platform for crowds to share perspectives and commentaries about them. Given an event and an associated large-scale collection of tweets, there are two fundamental research problems that have been receiving increasing attention in recent years. One is to extract the topics covered by the event and the tweets; the other is to segment the event. So far these problems have been viewed separately and studied in isolation. In this work, we argue that these problems are in fact inter-dependent and should be addressed together. We develop a joint Bayesian model that performs topic modeling and event segmentation in one unified framework. We evaluate the proposed model both quantitatively and qualitatively on two large-scale tweet datasets associated with two events from different domains to show that it improves significantly over baseline models.", "creator": "LaTeX with hyperref package"}}}