{"id": "1212.0582", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Dec-2012", "title": "Compositional Stochastic Modeling and Probabilistic Programming", "abstract": "Probabilistic mode it involves directly a choreographic particular come stochastic modeling by shifted one three-dimensional to continuous way vision. In involves while, particular airlines - algebra semantics no available during that applications awaiting entered parallel (and possibly intuitively) these summed years - evolution operating. From this harvard, combinatorial already technique, formulation and version scale if actually allege language. The basic consequences often problems far - reaching in computational science, machine learning for enough. Hybrid tonal stochastic modeling / semi-empirical programming method cannot previously better possible.", "histories": [["v1", "Mon, 3 Dec 2012 23:05:30 GMT  (273kb)", "http://arxiv.org/abs/1212.0582v1", "Extended Abstract for the Neural Information Processing Systems (NIPS) Workshop on Probabilistic Programming, 2012"]], "COMMENTS": "Extended Abstract for the Neural Information Processing Systems (NIPS) Workshop on Probabilistic Programming, 2012", "reviews": [], "SUBJECTS": "cs.AI cs.PL", "authors": ["eric mjolsness"], "accepted": false, "id": "1212.0582"}, "pdf": {"name": "1212.0582.pdf", "metadata": {"source": "CRF", "title": "Compositional Stochastic Modeling and Probabilistic Programming", "authors": ["Eric Mjolsness"], "emails": ["emj@uci.edu"], "sections": [{"heading": "1 Introduction", "text": "Programming languages typically have semantics that is compositional, deterministic, and defined in discrete time and space. \u201cProbabilistic programming\u201d (PP) proposes to change the \u201cdeterministic\u201d part of this description. If one also changes the \u201cdiscrete time\u201d part of this description, allowing continuous time which is more natural for most scientific applications, we arrive at a class of computational modeling languages rather than programming languages: compositional stochastic modeling (CSM) languages. Such languages have many attractive features for modeling real-world processes: a close match of computational and physical semantics, a systematic way to derive algorithms for sampling, inference, and model reduction, and relevance to new vistas in biocomputing and abstract mathematics, among others.\nUnfortunately the jump between continuous and discrete time seems like a large one \u2013 even more so if continuous space is also admitted for modeling purposes. On the other hand conventional computational \u201cengines\u201d are possible for such languages, so perhaps the gap can be closed. What would the consequences be of taking CSM as a model of computation? Obviously such a model would be probabilistic. How can it be related to probabilistic programming, to their mutual enrichment? After a brief review of one approach to CSM, we discuss various points that bear on these questions, and then address the applications that may benefit from CSMs."}, {"heading": "2 Operator algebra approach to CSM", "text": "An example of CSM is the \u201cPlenum\u201d implementation of the \u201cDynamical Grammars\u201d modeling language [1], which was developed for developmental systems biology but could be applied to many other scientific modeling domains as well [2]. A dynamical grammar (DG) consists of a 1 What follows is an Extended Abstract for the Neural Information Processing Systems (NIPS) Workshop on Probabilistic Programming, 2012.\nmultiset of reaction-like rewrite rules, each with a computer-algebraically expressed function quantifying the rate (or \u201cpropensity\u201d) of the corresponding process. Rules can act instantaneously or continuously in time, the latter by way of differential equations. Either way, the effects of a rule may alternatively be defined by (recursively) calling a subgrammar. The semantics of dynamical grammars is defined by mapping each rule to a time-evolution operator that appears in the master equation for the evolution of probabilities on states of the system. (The master equation was proposed independently as a way to provide the semantics for a \u201csmall stochastic process algebra\u201d in [3]. However, the present use of operator algebra to express the semantics itself was not part of that proposal.) The algebra of possible time-evolution operators is generated by a set of elementary object creation and annihilation operators, under the operations of operator addition (corresponding to parallel processes), operator multiplication (corresponding to atomic sequential events), and scalar multiplication by rate functions in a defined function space eg. Sobolev Banach space. The resulting semantics is \u201ccompositional\u201d in that (a) the operator for a (multi-) set of rules is the (multiplicity-weighted) sum of their operators, so multiset union maps to operator addition; (b) dynamically graph-structured data objects are easily expressed; and (c) subgrammars have suitable semantics for the analog of subroutines and/or macros [1]. The master equation which defines process semantics can be reexpressed in a form, called the time-ordered product expansion (TOPE), which maps the possible interaction histories of system objects to Feynman diagrams [1,4]. This form also permits the derivation of the Gillespie algorithm for stochastic chemical kinetics simulation, and its generalization to DG rewrite rule systems. Between interaction events, continuous-time processes expressed in terms of differential operators become (under TOPE) differential equations (to be solved numerically by conventional discretization) as proved in [4]. Thus the TOPE provides a systematic route for deriving Markov chains for simulation and also maximum-likelihood inference algorithms [2,5,4], from the master equation and operator algebra semantics. In addition to the process semantics defined above, CSM languages may also have an object semantics describing the mathematical spaces (topological spaces, measure spaces, geometries, and/or function spaces) that circumscribe its dynamical objects. Within such constraints, we desire type constructors including Cartesian products, disjoint sums, functions (possibly including higher-order functions), and quotients. This topic is discussed at greater length in [6]. These type constructors are naturally expressed in terms of category theory, potentially bringing an entirely different sense of the phrase \u201calgebraic semantics\u201d into play. Collections of rewrite rules in the form of semi-Thue systems were one of the first formalisms shown to be capable of universal computing. DG rules are each much more powerful than semiThue system rules, so DGs are Turing-universal. DGs with unbounded rate functions are capable (in principle) of super-Turing computation, by creating a succession of new objects that speed up according to progressively faster clocks. If the sum of effective clock times (inverse propensity functions) converges, there is an accumulation point through which a conventional computer could not simulate the DG. Accumulation points can themselves accumulate, and so on, creating the image of some countable ordinal as in [7]. But it is fairly natural in DGs to eliminate such problems by enforcing conservation or monotonic decrease of global finite resource parameters as part of the dynamics as well, just as chemical reactions conserve the total amount of each chemical element. Most scientific applications already have such parameters."}, {"heading": "2 Relat ionship to probabil ist ic programming", "text": "There is an important mapping of continuous to discrete semantics, by way of the TOPE and the Gillespie algorithm. A discrete-time semantics was defined in [1] which essentially throws away the real-valued event times in a DG without differential equations (a stochastic parameterized grammar or SPG). With this semantics, SPGs in fact comprise an expressive probabilistic programming language. If a different PP language can be reduced (efficiently) to SPGs, it can be\nreduced (efficiently) to DG\u2019s by restoring the missing event times using calls to an Erlang distribution with parameters that must be computed anyway for the discrete-time SPG semantics. In the reverse direction, DGs can be reduced to Turing machines incorporating plentiful calls to random number generators, since simulation engines exist for DGs. The main ingredients in one such engine [2], derivable from TOPE [4] are: variable-binding to define instantiated rule execution probabilities and results, Gillespie stochastic simulation algorithm choice of rule execution, a Rete algorithm like data structure for efficient handling of many rules, and calls to a differential equation solver. If a PPL can implement these items (efficiently) then DGs are reducible to the PPL (efficiently). Similarities of CSM to PP include the following. Simulation algorithms can be derived in a systematic and sometimes automatic way. As in the case of PP, SPGs can have their parameters inferred from data about their behavior by a maximum-likelihood algorithm. Such an algorithm has been derived from TOPE and demonstrated on a small gene regulation network problem [5]. Approximate model reduction is also possible for some SPGs expressed in Plenum. The reduced model is of a simpler form than a CSM, being much closer to a graphical model. Such model reduction was demonstrated in a synaptic signaling model [8]. Of the foregoing CSM compositionality properties property (a), summation of rule time-evolution operators, is compromised by the move from continuous to discrete time. This fact may result in improved technical tractability in the continuous-time case, as well as greater congruence with real-world continuous-time and asynchronously parallel applications. Hybrid discretetime/continuous-time DG\u2019s are also possible, provided that they are well separated by the encapsulation mechanism provided by subgrammar (not macro) calls. Similar work in the direction of complex continuous-time stochastic models with time-changing numbers of random variables is not yet an overpopulated category. Continuous-Time Bayes Nets (CTBNs) [9] have a time-invariant number of discrete random variables and therefore are described by a fixed-dimension intensity matrix. CTBNs have been generalized to certain nonexponential delay distributions P(\u0394t) eg. Erlang [10]. Coalescent theory in genetics is also continuous-time and stochastic, but relies on highly domain-specific assumptions. More general continuous-time Markov process frameworks still have a fixed and usually finite or at most countably infinite state space. Stochastic pi-calculus [3] has time-changing variable number and semantic similarities discussed above, but no rate function spaces, submodels, etc. CTPPL [11] is another generalization of CTBNs to arbitrary expressions for delay distributions P(\u0394t) and also time-changing data structures. Such delay distributions may be handled in DG by equivalent timevarying rate functions \u03c1(\u0394t) = P(\u0394t)/[1-\u222b0\u0394\nt P(\u03c4)d\u03c4] ; if P(\u0394t) is Erlang, for example, then \u03c1(\u0394t;n,\u03bb) = \u03bbntn-1e-\u03bbt/\u0393(n,t\u03bb) where \u0393 is the incomplete gamma function and of course \u0394t is nonnegative. None of these frameworks handle continuous variables, nor their possibly continuous evolution in time according to differential (or stochastic differential) equations, as does the Dynamical Grammar framework."}, {"heading": "3 Relevant applicat ion domains", "text": "The kind of compositional stochastic modeling language discussed here has potentially broad applicability due to the additive compositionality of its semantics (parallel processes have summed time-evolution operators), which along with its continuous-time model makes for a close match of computational semantics and dynamics in scientific domains (physical, electronic, biological, social, etc.). Algorithms for simulation, inference, and model reduction follow. Biological applications have been demonstrated with models of gene regulation, molecular complexes in synapses, and tissues comprising plant and animal stem cell niches with cell division and diffusible growth factors [2,12]. A schematic example of one such stem cell niche application is the dynamical grammar of Figure 1, explained more fully in [6]. Other SPG-like \u201crule-based\u201d biochemical modeling languages have been applied to a variety of biological modeling problems at the cellular and molecular levels [13,14]. We may expect\nprogressively more advanced computational biology and biocomputing applications. Varieties of modeling encompassed include stochastic chemical kinetics, dynamical systems given by ordinary differential equations, agent-based models, stochastic string, tree and graph rewrite rules, spatially continuous models (so far only the diffusion equation and mass-spring elastodynamics), and perhaps most importantly, hybrids of all of these types. Thus, CSML\u2019s may function as high-level domain-specific languages for computational science.\nThe advantages claimed here for CSML\u2019s over PP languages for scientific modeling are not advantages of in-principle generality, except in the potentially problematic sense of super-Turing computation, but rather of perspicuity in concisely expressing real-world dynamical models, due to the closer of match of continuous-time dynamics to the intended application domains. Thus, CSML\u2019s may function as a \u201chigher-level\u201d language in many modeling domains. On the other hand occasionally (as in Poincare maps) discrete-time models of continuous-time systems are also revealing. Therefore one may predict that the translation path between CSML\u2019s and PPL\u2019s will become well-trodden."}, {"heading": "4 Further Discussion", "text": "One criterion for useful generality in a formal modeling language is that the language should be closed under \u201cexpected\u201d kinds of model reduction. Model reductions in physics often change from deterministic to stochastic dynamics or back, from discrete to continuous variables or the reverse, and so on \u2013 so we have proposed a framework that encompasses all these variations including hybrids. Oddly, model reductions often proceed by taking infinite limits. Approximation of integer molecule numbers by continuous-valued concentrations is one example. Another is spatially continuous PDE models of elastic materials that are actually composed of discrete atoms and molecules. Unfortunately the specter of super-Turing computing will be raised whenever an infinite limit is taken which, in applied mathematics, is quite often; therefore a general modeling framework must permit this kind of trouble. In practice domain-dependent restrictions such as resource constraints, spatial frequency limits, Sobolev norms, and other schemes of regularization are used to control these potentially problematic limits. By working with computer algebra representations it should be possible to express and analyze these kinds of necessary conditions, as indeed has already been achieved for example in PDE packages that support eg. weak forms [15]. Under further development one may expect the following inherent capabilities to added to the practical repertoire of CSM languages with operator-algebra semantics: hybrid discrete-time (PP) and continuous-time CSM languages; increasingly general PDEs including dynamic boundaries; application to asynchronous parallel computing; and novel learning and evolution methods which amplify small signals out of large noise backgrounds to create increasingly complex learned algorithms. More speculatively one might also attempt to develop: CSM meta-programming using meta-rules (particular meta-rules in Dynamical Grammars are demonstrated in [2]); the use of Hausdorff topological spaces in the computational theory of types (where non-Hausdorff spaces are usually employed [16]); and perhaps eventually, application of operator algebra semantics to mathematical foundations by which a great variety of mathematical objects acquire dynamics and become more widely understandable \u2013 thus advancing the computational reification of mathematics. In all of these projects, compositional stochasticity with operator algebra semantics is an essential ingredient."}, {"heading": "Acknowledgements", "text": "Research was supported by NIH grants R01 GM086883 and P50 GM76516 to UC Irvine, and by a Moore Distinguished Scholar visiting appointment at the California Institute of Technology. I also wish to acknowledge the hospitality, travel support, and research environments provided by the Center for Nonlinear Studies (CNLS) at the Los Alamos National Laboratory, the Sainsbury Laboratory Cambridge University, and the Pauli Center for Theoretical Studies at ETH Z\u00fcrich and the University of Z\u00fcrich.\nR e f e r e n c e s [1] Mjolsness E. and Yosiphon G (2006), \u201cStochastic Process Semantics for Dynamical Grammars\u201d. Annals of Mathematics and Artificial Intelligence, 47(3-4). [2] Yosiphon, G. (2009), \u201cStochastic Parameterized Grammars: Formalization, Inference, and Modeling Applications\u201d, PhD Thesis, UC Irvine Computer Science Department, June 2009. Thesis and software : http://computableplant.ics.uci.edu/~guy/Plenum.html . [3] Cardelli L. (2007). A process algebra master equation. Proc. Fourth International Conference on the Quantitative Evaluation of Systems, QEST. [4] Mjolsness, E. (2012) \u201cTime-Ordered Product Expansions for Computational Stochastic Systems Biology\u201d. arXiv:1209.5231 [q-bio.QM], http://arxiv.org/abs/1209.5231 .\n[5] Wang Y, Christley S., Mjolsness E., and Xie X. (2010), Parameter inference for discretely observed stochastic kinetic models using stochastic gradient descent. BMC Systems Biology 4:99. [6] Mjolsness (2010), \u201cTowards Measurable Types for Dynamical Process Modeling Languages\u201d, Eric Mjolsness. Electronic Notes in Theoretical Computer Science (ENTCS), vol. 265, pp. 123- 144, 6 Sept. 2010, Elsevier. DOI 10.1016/j.entcs.2010.08.008. [7] Barrett, J. A. and W. Aitken (2010), \u201cA Note on the Physical Possibility of Ordinal Computation,\u201d British Journal for the Philosophy of Science 61(4): 867-874. [8] Johnson G. T., (2012), \u201cDependency \u00a0 Diagrams \u00a0 and \u00a0 Graph-\u2010Constrained \u00a0 Correlation \u00a0 Dynamics: New \u00a0 Systems \u00a0 for \u00a0 Probabilistic \u00a0 Graphical \u00a0 Modeling\u201d, \u00a0 PhD Thesis, UC Irvine Computer Science Department UC Irvine, March \u00a02012. [9] Nodelman U, Shelton C R, and Koller D (2002). Continuous time Bayesian networks. Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence (pp. 378\u2013387).  \u00a0 [10] Nodelman U, Shelton C R, and Koller D (2005). Expectation maximization and complex duration distributions for continuous time Bayesian networks. In Proc. Uncertainty in Artificial Intelligence. [11] Pfeffer A., CTPPL: A Continuous Time Probabilistic Programming Language. Proc. International Joint Conference on Artificial Intelligence, Jun. 2009. [12] Mironova V.V., Nadya A Omelyanchuk, Guy Yosiphon, Stanislav I Fadeev, Nikolai A Kolchanov, Eric Mjolsness and Vitaly A Likhoshvai (2010). \u201cA plausible mechanism for auxin patterning along the developing root\u201d. BMC Systems Biology 4:98. [13] Hlavacek WS, Faeder JR, Blinov ML, Posner RG, Hucka M, Fontana W (2006) Rules for modeling signal-transduction systems. Science\u2019s STKE 2006:re6. [14] Danos V, Feret J, Fontana W, Harmer R, Krivine J (2007) Rule-based modelling of cellular signaling. Lect Notes Comput Sci 4703:17-41. [15] Logg A and Wells GN (2010), \u201cDOLFIN: Automated Finite Element Computing\u201d. ACM Transactions on Mathematical Software, Vol. 37, No. 2, Article 20.  \u00a0 [16] Hofmann K. H. and M.W. Mislove (1993), \u201cAll Compact Hausdorff Lambda Models are Degenerate\u201d, Fundamenta Informaticae."}], "references": [{"title": "Stochastic Process Semantics for Dynamical Grammars", "author": ["E. Mjolsness", "G Yosiphon"], "venue": "Annals of Mathematics and Artificial Intelligence,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "Stochastic Parameterized Grammars: Formalization, Inference, and Modeling Applications", "author": ["G. Yosiphon"], "venue": "PhD Thesis, UC Irvine Computer Science Department,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "A process algebra master equation", "author": ["L. Cardelli"], "venue": "Proc. Fourth International Conference on the Quantitative Evaluation of Systems,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2007}, {"title": "Time-Ordered Product Expansions for Computational Stochastic Systems Biology", "author": ["E. Mjolsness"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Parameter inference for discretely observed stochastic kinetic models using stochastic gradient descent", "author": ["Y Wang", "S. Christley", "E. Mjolsness", "X. Xie"], "venue": "BMC Systems Biology", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2010}, {"title": "A Note on the Physical Possibility of Ordinal Computation", "author": ["J.A. Barrett", "W. Aitken (2010"], "venue": "British Journal for the Philosophy of Science 61(4): 867-874.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 0}, {"title": "Dependency Diagrams and Graph-\u00ad\u2010Constrained Correlation Dynamics: New Systems for Probabilistic Graphical Modeling", "author": ["T. Johnson G"], "venue": "PhD Thesis,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Continuous time Bayesian networks", "author": ["U Nodelman", "R Shelton C", "D Koller"], "venue": "Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence (pp. 378\u2013387)", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2002}, {"title": "Expectation maximization and complex duration distributions for continuous time Bayesian networks", "author": ["U Nodelman", "R Shelton C", "D Koller"], "venue": "In Proc. Uncertainty in Artificial Intelligence", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2005}, {"title": "CTPPL: A Continuous Time Probabilistic Programming Language", "author": ["A. Pfeffer"], "venue": "Proc. International Joint Conference on Artificial Intelligence,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "Rules for modeling signal-transduction systems. Science\u2019s STKE 2006:re6", "author": ["WS Hlavacek", "JR Faeder", "ML Blinov", "RG Posner", "M Hucka", "W Fontana"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2006}, {"title": "Rule-based modelling of cellular signaling", "author": ["V Danos", "J Feret", "W Fontana", "R Harmer", "J Krivine"], "venue": "Lect Notes Comput Sci 4703:17-41", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "DOLFIN: Automated Finite Element Computing", "author": ["A Logg", "GN Wells"], "venue": "ACM Transactions on Mathematical Software,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "All Compact Hausdorff Lambda Models are Degenerate\u201d, Fundamenta Informaticae", "author": ["H.M.W. Hofmann K"], "venue": "Mislove", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1993}], "referenceMentions": [{"referenceID": 0, "context": "An example of CSM is the \u201cPlenum\u201d implementation of the \u201cDynamical Grammars\u201d modeling language [1], which was developed for developmental systems biology but could be applied to many other scientific modeling domains as well [2].", "startOffset": 95, "endOffset": 98}, {"referenceID": 1, "context": "An example of CSM is the \u201cPlenum\u201d implementation of the \u201cDynamical Grammars\u201d modeling language [1], which was developed for developmental systems biology but could be applied to many other scientific modeling domains as well [2].", "startOffset": 225, "endOffset": 228}, {"referenceID": 2, "context": "(The master equation was proposed independently as a way to provide the semantics for a \u201csmall stochastic process algebra\u201d in [3].", "startOffset": 126, "endOffset": 129}, {"referenceID": 0, "context": "The resulting semantics is \u201ccompositional\u201d in that (a) the operator for a (multi-) set of rules is the (multiplicity-weighted) sum of their operators, so multiset union maps to operator addition; (b) dynamically graph-structured data objects are easily expressed; and (c) subgrammars have suitable semantics for the analog of subroutines and/or macros [1].", "startOffset": 352, "endOffset": 355}, {"referenceID": 0, "context": "The master equation which defines process semantics can be reexpressed in a form, called the time-ordered product expansion (TOPE), which maps the possible interaction histories of system objects to Feynman diagrams [1,4].", "startOffset": 216, "endOffset": 221}, {"referenceID": 3, "context": "The master equation which defines process semantics can be reexpressed in a form, called the time-ordered product expansion (TOPE), which maps the possible interaction histories of system objects to Feynman diagrams [1,4].", "startOffset": 216, "endOffset": 221}, {"referenceID": 3, "context": "Between interaction events, continuous-time processes expressed in terms of differential operators become (under TOPE) differential equations (to be solved numerically by conventional discretization) as proved in [4].", "startOffset": 213, "endOffset": 216}, {"referenceID": 1, "context": "Thus the TOPE provides a systematic route for deriving Markov chains for simulation and also maximum-likelihood inference algorithms [2,5,4], from the master equation and operator algebra semantics.", "startOffset": 133, "endOffset": 140}, {"referenceID": 4, "context": "Thus the TOPE provides a systematic route for deriving Markov chains for simulation and also maximum-likelihood inference algorithms [2,5,4], from the master equation and operator algebra semantics.", "startOffset": 133, "endOffset": 140}, {"referenceID": 3, "context": "Thus the TOPE provides a systematic route for deriving Markov chains for simulation and also maximum-likelihood inference algorithms [2,5,4], from the master equation and operator algebra semantics.", "startOffset": 133, "endOffset": 140}, {"referenceID": 5, "context": "Accumulation points can themselves accumulate, and so on, creating the image of some countable ordinal as in [7].", "startOffset": 109, "endOffset": 112}, {"referenceID": 0, "context": "A discrete-time semantics was defined in [1] which essentially throws away the real-valued event times in a DG without differential equations (a stochastic parameterized grammar or SPG).", "startOffset": 41, "endOffset": 44}, {"referenceID": 1, "context": "The main ingredients in one such engine [2], derivable from TOPE [4] are: variable-binding to define instantiated rule execution probabilities and results, Gillespie stochastic simulation algorithm choice of rule execution, a Rete algorithm like data structure for efficient handling of many rules, and calls to a differential equation solver.", "startOffset": 40, "endOffset": 43}, {"referenceID": 3, "context": "The main ingredients in one such engine [2], derivable from TOPE [4] are: variable-binding to define instantiated rule execution probabilities and results, Gillespie stochastic simulation algorithm choice of rule execution, a Rete algorithm like data structure for efficient handling of many rules, and calls to a differential equation solver.", "startOffset": 65, "endOffset": 68}, {"referenceID": 4, "context": "Such an algorithm has been derived from TOPE and demonstrated on a small gene regulation network problem [5].", "startOffset": 105, "endOffset": 108}, {"referenceID": 6, "context": "Such model reduction was demonstrated in a synaptic signaling model [8].", "startOffset": 68, "endOffset": 71}, {"referenceID": 7, "context": "Continuous-Time Bayes Nets (CTBNs) [9] have a time-invariant number of discrete random variables and therefore are described by a fixed-dimension intensity matrix.", "startOffset": 35, "endOffset": 38}, {"referenceID": 8, "context": "Erlang [10].", "startOffset": 7, "endOffset": 11}, {"referenceID": 2, "context": "Stochastic pi-calculus [3] has time-changing variable number and semantic similarities discussed above, but no rate function spaces, submodels, etc.", "startOffset": 23, "endOffset": 26}, {"referenceID": 9, "context": "CTPPL [11] is", "startOffset": 6, "endOffset": 10}, {"referenceID": 1, "context": "Biological applications have been demonstrated with models of gene regulation, molecular complexes in synapses, and tissues comprising plant and animal stem cell niches with cell division and diffusible growth factors [2,12].", "startOffset": 218, "endOffset": 224}, {"referenceID": 10, "context": "Other SPG-like \u201crule-based\u201d biochemical modeling languages have been applied to a variety of biological modeling problems at the cellular and molecular levels [13,14].", "startOffset": 159, "endOffset": 166}, {"referenceID": 11, "context": "Other SPG-like \u201crule-based\u201d biochemical modeling languages have been applied to a variety of biological modeling problems at the cellular and molecular levels [13,14].", "startOffset": 159, "endOffset": 166}, {"referenceID": 1, "context": "Model simplified from the olfactory epithelium model of [2].", "startOffset": 56, "endOffset": 59}, {"referenceID": 12, "context": "weak forms [15].", "startOffset": 11, "endOffset": 15}, {"referenceID": 1, "context": "More speculatively one might also attempt to develop: CSM meta-programming using meta-rules (particular meta-rules in Dynamical Grammars are demonstrated in [2]); the use of Hausdorff topological spaces in the computational theory of types (where non-Hausdorff spaces are usually employed [16]); and perhaps eventually, application of operator algebra semantics to mathematical foundations by which a great variety of mathematical objects acquire dynamics and become more widely understandable \u2013 thus advancing the computational reification of mathematics.", "startOffset": 157, "endOffset": 160}, {"referenceID": 13, "context": "More speculatively one might also attempt to develop: CSM meta-programming using meta-rules (particular meta-rules in Dynamical Grammars are demonstrated in [2]); the use of Hausdorff topological spaces in the computational theory of types (where non-Hausdorff spaces are usually employed [16]); and perhaps eventually, application of operator algebra semantics to mathematical foundations by which a great variety of mathematical objects acquire dynamics and become more widely understandable \u2013 thus advancing the computational reification of mathematics.", "startOffset": 289, "endOffset": 293}, {"referenceID": 0, "context": "[1] Mjolsness E.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] Yosiphon, G.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] Cardelli L.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] Mjolsness, E.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] Wang Y, Christley S.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[7] Barrett, J.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[8] Johnson G.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[9] Nodelman U, Shelton C R, and Koller D (2002).", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[10] Nodelman U, Shelton C R, and Koller D (2005).", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[11] Pfeffer A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[13] Hlavacek WS, Faeder JR, Blinov ML, Posner RG, Hucka M, Fontana W (2006) Rules for modeling signal-transduction systems.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[14] Danos V, Feret J, Fontana W, Harmer R, Krivine J (2007) Rule-based modelling of cellular signaling.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[15] Logg A and Wells GN (2010), \u201cDOLFIN: Automated Finite Element Computing\u201d.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[16] Hofmann K.", "startOffset": 0, "endOffset": 4}], "year": 2012, "abstractText": "Probabilistic programming is related to a compositional approach to stochastic modeling by switching from discrete to continuous time dynamics. In continuous time, an operator-algebra semantics is available in which processes proceeding in parallel (and possibly interacting) have summed time-evolution operators. From this foundation, algorithms for simulation, inference and model reduction may be systematically derived. The useful consequences are potentially far-reaching in computational science, machine learning and beyond. Hybrid compositional stochastic modeling/probabilistic programming approaches may also be possible.", "creator": "Word"}}}