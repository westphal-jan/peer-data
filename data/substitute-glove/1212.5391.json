{"id": "1212.5391", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Dec-2012", "title": "Soft Set Based Feature Selection Approach for Lung Cancer Images", "abstract": "Lung cancer except the collision components on cardiac next taken men brought adult. Feature selection williams a depend having its cancer synonyms. This reading investigates as list rare requires in Computed Tomographic (CT) lung cause reflections addition red first theory. We announce makes while mixture set same unsupervised episodes selection optimal. Nineteen unique are powdered also the weightings lung graphically other gray of chairman - undersupply coefficients (GLCM) and beard level form matrix (GLDM ). In still material, strong develop Unsupervised Soft Set an Quick Reduct (SSUSQR) fft true include. This specific present used now allows distinctive through with data starting several compared one existing rough set based four-week format unique methods. Then K - Means once Self Organizing Map (SOM) semigroups interface how \u2014 to cluster the maps. The positive of the scenes selection cryptographic once conclusions conjunction put performance although clustering techniques. The possible drama still taken outlined therapeutic controls removes augmented collection.", "histories": [["v1", "Fri, 21 Dec 2012 10:46:24 GMT  (3995kb)", "http://arxiv.org/abs/1212.5391v1", "7 pages, IJSER Vol.3 Issue . 10 Oct 2012"]], "COMMENTS": "7 pages, IJSER Vol.3 Issue . 10 Oct 2012", "reviews": [], "SUBJECTS": "cs.LG cs.CE", "authors": ["g jothi", "h hannah inbarani"], "accepted": false, "id": "1212.5391"}, "pdf": {"name": "1212.5391.pdf", "metadata": {"source": "CRF", "title": "Soft Set Based Feature Selection Approach for Lung Cancer Images", "authors": [], "emails": [], "sections": [{"heading": null, "text": "\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014  \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014"}, {"heading": "1 INTRODUCTION", "text": "HE second most common malignant (cancerous) tumor is lung cancer. Each year, more people die of lung cancer than of breast, colon, and prostate cancers combined. Early time diagnosis of the lung cancer\u2019s pathological type could improve patients\u2019 treatment effect. Recently, CT-scanning has emerged as one of the essential diagnostic measures of lung cancer, due to its pattern recognition, machine learning and image process technology [1]. Feature Selection is an essential part of knowledge discovery. FS is used to improve the classification accuracy and reduce the computational time of classification algorithms. FS is divided into the supervised and unsupervised categories. When class labels of the data are available we use supervised feature selection, otherwise unsupervised feature selection is appropriate. In many data mining applications, class labels are unknown, thereby indicating the significance of unsupervised feature selection [2]. In terms of feature selection methods, they fall into filter and wrapper categories. In filter model, features are evaluated based on the general characteristics of the data without relying on any mining algorithms. On the contrary, wrapper model requires one mining algorithm and uses its performance to determine the goodness of feature sets [3]. Soft set theory was first proposed by D. Molodtsov in 1999 for dealing with uncertainties [4]. Soft Set Theory has been applied to data analysis and decision support system. Soft set is trouble-free for attribute reduction in Boolean-value information system. The proposed work exploits soft set theory based operations for feature reduction and then it is compared with rough set based unsupervised algorithms. This soft set based method selects the minimal set of attributes when compared with\nRough Set. The main purpose of the proposed algorithm is to increase the efficiency of feature selection method. The rest of the paper is structured as Sections 2 to 8. Section 2 describes the related work of feature reduction and decision making using soft sets. Section 3 describes the research motivation of this work. Section 4 explains the preprocessing steps for lung image. Section 5 describes the preliminaries of soft set theory. Section 6 explains the proposed algorithm with an example. Section 7 analyses the experimental results. Finally, conclusion is given in Section 8."}, {"heading": "2 RELATED WORK", "text": "In [5], a filter-based feature selection method, biomarker identifier (BMI), is adopted to analyze gene expression data that might be used to discriminate between samples with and without lung cancer. Amer et al. [6] investigated computed tomographic (CT) chest images and developed a computer-aided system to discriminate different lung abnormalities. They studied texture based features, fourier-based features and wavelet-based features. Aliferis et al. [7] explores machine learning methods for the development of computer models. These computer models used gene expression data to distinguish between tumor and non-tumor, between metastatic and non-metastatic, and between histological subtypes of lung cancer. A second goal is to identify small sets of gene predictors and study their properties in terms of stability, size, and relation to lung cancer. The idea of attribute reduction and decision making using soft set theory was first proposed by Maji et al. [8]. In [8] decision selection in given attribute is based on the maximal weighted choice value and it is similar to the Pawlak rough reduction. Herawan et al. [9] introduced a new approach for an attribute reduction in multi-valued information system using soft set. AND operation was used for attribute reduction and it was shown that the reducts obtained were equivalent with Pawla\u2019s rough reduction. In [10], the soft set theory has been used as feature selec-\nT\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014  Jothi. G is currently pursuing M. Phil in Computer Science at Periyar\nUniversity, Salem, India. E-mail: jothiys@gmail.com.\n H. Hannah Inbarani is currently working an Assistant professor, Department of Computer science, Periyar Uinversity, Salem, India. E-mail: hhinba@gmail.com\ntion technique to identify the best features of Traditional Malay musical instrument sounds."}, {"heading": "3 RESEARCH MORTIVATION", "text": "The proliferation of large data sets within many domains poses unprecedented challenges to data mining [11]. Researchers realize that in order to achieve successful data mining, feature selection is an indispensable component [12]. In image processing the feature selection approach takes enormous amount of time to find minimal subset of features. The new researches in this area focus on reducing runtime for the purpose of efficient research. Hence this work proposes an effective and efficient approach to find the reduct set."}, {"heading": "4 PRELIMINARIES", "text": ""}, {"heading": "4.1 Soft Set Theory", "text": "Throughout this section refers to an initial universe, E is a set of parameters, P ( ) is the power set of and A \u2286 E [4]. Definition 1: A pair (F, A) is called a soft set over , where F is a mapping given by"}, {"heading": "4.2 Multi-soft Sets", "text": "The idea of \u201cmulti soft set\u201d is based on a decomposition of a multi-valued information system ), into |A| number of binary-valued information systems ), where |A| denotes the cardinality of A. Consequently, the |A| binary-valued information systems define multi-soft sets [13].\n."}, {"heading": "4.3 AND operation in multi-soft sets", "text": "Definition 2: Let be a multi-soft set over U representing a multi-valued information system ). The AND operation between and is defined as [9].\nwhere"}, {"heading": "4.4 Attribute Reduction", "text": "Definition 3: Let be a multi-soft set over U representing a multi-valued information system ). A set of attributes B A is called a reduct for A if [9]. Definition 4: Assume X \u2286 A is an attribute subset, is an attribute, the importance of for X is denoted by the definition is, [14] Where |X|=|IND(X)|. Suppose U/IND(X) = U/X={X1, X2 \u2026Xn},\nthen 2. represents the decrement of indiscernibility and also the increment of discernibility as attribute x is added to X. The number of selection methods is originally indiscernible in X, but it is discernible in and the increment of indiscernibility is expressed by"}, {"heading": "5 THE PROCESSING MODEL", "text": "A typical image processing system generally consists of image acquisition, enhancement, segmentation, feature extraction, feature selection and clustering/classification. Lung image categorization process is depicted in Figure 1."}, {"heading": "5.1 Image Enhancement", "text": "Due to low quality, low ability of distinguishing abnormalities from their surrounding, and artifacts. The quality of CT images could be degraded, sometimes to the point making them diagnostically unusable. So, the first step in preprocessing is the image denoising. Therefore the current step in this work is to perform a comparative study of some image enhancement technique, namely, Average filter, Gaussian filter, Median filter [15]. All mentioned types of filters are applied in the noisy image. The SNR value is obtained using the equation (1) and comparing the values of SNR of each image that resulted from each filter type we get the most suitable filter that could be applied on the raw CT images [6]. The original image and the noisy image are shown in Figure 2 and the resulted images from all types of the previous filters are shown in Figure 3. The calculated SNR of each filtered image for all applied filters are shown in Table 1.\n5.1.1 SNR Calculation\nFilter Type SNR Value Mean filter 4.4400\nGaussian filter 7.5788 Median filter 11.2069"}, {"heading": "5.1.2 Application of Denoising Filters to CT scan", "text": "Images\nThe performance of three denoising filter techniques has been compared as above. The results show that the 5\u00d75 Median filter gives the highest quality image compared to the other mentioned filtering techniques. So it is applied to all the raw CT lung images. An example of the filtered CT lung image is shown in Figure 4."}, {"heading": "5.2 Lung Segmentation", "text": "In this paper, Region Growing Segmentation (RGS) is performed on each image. Figures 5 (a) and (b) demonstrate the performance of before and after RGS algorithm and finally, figure 5 (c) shows the segmented lung image [16]."}, {"heading": "5.3 Feature Extraction", "text": "Feature extraction methodologies analyze objects and images to extract the most prominent features that are representative of the various classes of objects. In this research, we used gray level co-occurence matrix GLCM in four possible directions and and gray level different matrix GLDM to extract texture features from digital CT images [17]. Nineteen texture parameters viz. angular second moment (f1), contrast(f2), correlation(f3), sum of squares: variance(f4), inverse difference moment(f5), sum average(f6), sum variance(f7), sum entropy(f8), entropy(f9), difference variance(f10), difference entropy(f11), information measures of correlationI(f12), information measures of correlation-II(f13), maximal correlation coefficient(f14), cluster shade(f15), cluster prominence(f16), product moment(f17), Inertia(f18) and mean(f19) are calculated."}, {"heading": "6 UNSUPERVISED FEATURE SELECTION", "text": "In many data mining applications, class labels are unknown, and so considering the significance of Unsupervised Feature Selection (UFS) the proposed work is applied for UFS.\n6.1 USQR Algorithm: The Unsupervised Quick Reduct (USQR) algorithm attempts to calculate a reduct without exhaustively generating all possible subsets. According to the algorithm, the mean dependency of each attribute subset is calculated and the best feature is chosen. [18] Algorithm 1: USQR Algorithm - USQR(C) C, the set of all conditional features; (1) (2) do (3) T (4) x (C R) (5) y C (6)\n(7) if (8) (9) (10) until (11) return R 6.1 URR Algorithm: The Unsupervised Relative Reduct (URR) algorithm starts by considering all the features contained in the dataset. Each feature is then examined iteratively, and the relative dependency measure is calculated. If the relative dependency is equal to one then that feature can be removed. This process continues until all features have been examined [18]. Algorithm 2: URR Algorithm - URR(C) URR(C) C, the Conditional attributes (1)\n(2) (3) (4) (5) return R"}, {"heading": "6.1 SSUSQR Algorithm: - The Proposed Approach: In", "text": "the new Soft Set based Unsupervised Quick Reduct algorithm, the dimensionality reduction is achieved by using AND operation in soft set theory. It starts with an empty set and finds the cardinality of the indiscernibility of the universal set. For every conditional feature, the cardinality of indiscernibility is computed. The attribute which has highest cardinality value is taken as the core attribute in the reduct set. If more than one attribute has maximum cardinality value, Sig(x) is found out and that value is taken as the core attribute. In the next step, combination of other attributes with CORE(x) attribute is taken as feature subset and the feature subset with maximum cardinality of indiscernibility is taken. This process continues until the cardinality of indiscernibility of the feature subset is equal to the cardinality of the indiscernibility of the universal set. Algorithm 2: SSUSQR Algorithm \u2013 SSUSQR(C) U, the Universal Set; C, the set of all conditional features; (1) (2) Do (3) (4) Find ST (U) = |IND(U)| (5) Find Maximum( |IND( )))| (6) If more than one attribute has same Maximum( (|IND( ))|) Compute significance Sig of those attributes And Compute = CORE( ) End if (7) (8) (9) Until |R| == ST (U) (10) Return R 6.3. Worked Example: Now, let us consider the given information in table 2. The conditional attributes are {a1, a2, a3, a4}. A multi-value information system as specified in table 3 is constructed.\n(F, U) = ((F, a1), (F, a2), (F, a3), (F, a4)) (F, a1) = {{Circle=1, 4, 5}, {Square=2, 8}, {Triangle=3, 6, 7}} (F, a2) = {{Large=1, 3, 5}, {Small=2, 4, 7, 8}, {Medium=6}} (F, a3) = {{Red=1, 5}, {Green=2, 7, 8}, {Blue=3, 4, 6}} (F, a4) = {{Good=1, 4}, {Bad=2, 3, 6, 7}, {Average=5, 8}}\nStep 1: Begin. ST (U) = {(F,a1)AND(F,a2)AND(F,a3)AND(F,a4)} = F (a1 x a2 x a3 x a4) ST (U) = | {{1}, {2}, {3}, {4}, {5}, {6}, {7}, {8}} | = 8 ---- (2) Step 2: Calculate the cardinality value. (F, a1) = | {1, 4, 5}, {2, 8}, {3, 6, 7}| = 3 (F, a2) = 3, (F, a3) = 3, (F, a4) = 3. Find the maximum cardinality, that attribute is the core attribute in the reduct set. Step 3: In this example, the maximum cardinality value 3 occurs four times. From the Definition 4 we can calculate Significance value. The attribute which has highest Significance value is taken as core attribute CORE (A). |A| = ST (U) = {{1}, {2}, {3}, {4}, {5}, {6}, {7}, {8}}\nSimilarly, we can calculate,\nCORE (A) = {a4}, If ST (U) \u2260 |R| then go to next step. Step 4: Take the combination, {a1, a4}, {a2, a4}, {a3, a4}. F (a1 x a4) = | {1, 4}, {2}, {3, 6, 7}, {5}, {8}| = 5\nSimilarly, F (a2 x a4) = 7, F (a3 x a4) = 6 Select the attribute which has maximum cardinality. R = {a2, a4}. If ST (U) \u2260 |R|, then go to next step. Step 5: Take the combination, {a1, a2, a4}, {a2, a3, a4}. F (a1 x a2 x a4) = 8, F (a2 x a3 x a4) = 7 Select the attribute which has highest cardinality. R = {a1, a2, a4} ST (U) == |R|. Then the reduct set is {a1, a2, a4}. Step 6: End."}, {"heading": "7 EXPERIMENTAL RESULTS", "text": ""}, {"heading": "7.1. Data Collection", "text": "The Data sets are collected from the National Cancer Institute database and Mitra Scan Centre, Salem [19]. In this experimental analysis, 200 raw CT lung images are taken. The feature extracted table used in this reserach is in the form of continuous value with noncategorical features (attributes). In order to employ the soft set approach proposed by [9, 13], it is essential to transform the dataset into categorical ones. For that, the equal width binning discretization technique in [20] is used."}, {"heading": "7.2. Feature Reduction", "text": "A comparison of the USQR, URR and SSUSQR methods is made based on the subset and clustering performance. The data set name is described according to the textural description matrix and orientation (degree) is used to extract features from the CT lung image. There are 19 different features are extracted and used in our experiment. The selected features are listed in table 4. Figure 6 demonstrates the efficiency of the feature reduction for our proposed algorithm. It selects the minimal set of features.\nTABLE 4.\nFEATURES SELECTED USING UNSUPERVISED FEATURE SELECTION METHODS"}, {"heading": "7.3. Performance Analysis of FS algorithms", "text": "The performance of unsupervised feature selection algorithms USQR, URR and SSUSQR are compared before and after feature selection using clustering and cluster validity measures. The feature set is clustered by the k-means and SOM algorithm. The performance of cluster validity measures Dunn\u2019s Index and Silhouette Index are presented in tables 5 and 6. The clustering was initially performed on the un-reducted features followed by reduct features, which were obtained by dimensionality reduction techniques.\nFigures 7 (a) and (b) illustrate the performance of Dunn index and Silhouette Index using K-means for the data sets taken based on the features selected using proposed approach. These figures demonstrate the effectiveness of SSUSQR over USQR and URR since it shows higher index value.\nFigures 7 (c) and (d) show the performance of Dunn index and Silhouette Index using SOM for the data sets taken based on the features selected using proposed approach. These figures\ndemonstrate the effectiveness of SSUSQR over USQR and URR since it shows higher index value. 8 CONCLUSION In this paper, USQR, URR and SSUSQR algorithms are analyzed using raw CT lung images. The proposed SSUSQR algorithm using soft set theory effectively removes redundant fea-\ntures. The selected features are clustered using k-means and SOM clustering algorithms. The Dunn Index and Silhouette index were used for measuring the quality of the clusters obtained. The proposed method provides the best result compared with rough set based unsupervised feature selection. In future, it can be applied to other medical images also."}], "references": [{"title": "Unsupervised Feature Selection Using Feature Similarity", "author": ["Pabitra Mitra", "C.A. Murthy", "Sankar K. Pal"], "venue": "IEEE Transactions On Pattern Analysis And Machine Intelligence,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2002}, {"title": "Feature Similarity Based Redundancy Reduction for Gene Selection", "author": ["X. Fu", "F .Tan", "H.Wang", "Y-Q.Zhang", "R. Harrison"], "venue": "Conference on Data Mining,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2006}, {"title": "Soft set theory-first results", "author": ["D. Molodtsov"], "venue": "Computers and Mathematics with Applications", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1999}, {"title": "A filter-based feature selection approach for identifying potential biomarkers for lung cancer", "author": ["In-Hee Lee", "Gerald H Lushington", "Mahesh Visvanathan"], "venue": "Journal of Clinical Bioinformatics,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "Obayya, \u201cA Computer-Aided System for Classifying Computed Tomographic (CT) Lung Images Using Artificial Neural Network and Data Fusion", "author": ["Hanan M. Amer", "Fatma E.Z. Abou-Chadi", "Marwa I"], "venue": "International Journal of Computer Science and Network Security (IJCSNS),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Machine Learning Models For Classification Of Lung Cancer and Selection of Genomic Markers Using Array Gene Expression Data", "author": ["C.F. Aliferis", "I. Tsamardinos", "P.P. Massion", "A. Statnikov", "N. Fananapazir", "D. Hardin"], "venue": "American Association for Artificial Intelligence,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2002}, {"title": "Soft set theory", "author": ["P.K. Maji", "R. Biswas", "Roy", "A.R"], "venue": "Computers and Mathematics with Applications\u201d,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2003}, {"title": "Soft Set Theoretic Approach for Dimensionality Reduction", "author": ["Tutut Herawan", "Rozaida Ghazali", "Mustafa Mat Deris"], "venue": "International Journal of Database Theory and Application,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "Soft Set Theory for Feature Selection of Traditional Malay Musical Instrument Sounds", "author": ["Norhalina Senan", "Rosziati Ibrahim", "Nazri Mohd Nawi", "Iwan Tri Riyadi Yanto", "Tutut Herawan"], "venue": "ICICA", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "Data Mining: Concepts and Techniques", "author": ["J. Han", "M. Kamber"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2001}, {"title": "Computational Methods of Feature Selection", "author": ["H. Liu", "H. Motoda", "editors"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2007}, {"title": "On Multi-soft Sets Construction in Information Systems", "author": ["T. Herawan", "M.D. Mustafa"], "venue": "LNCS, Springer,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Decision Support System for Lung Cancer using PET/CT", "author": ["David Jakobsson", "Fredrik Olofsson"], "venue": "D Thesis,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2004}, {"title": "Textural features for image classification", "author": ["R.M. Haralick", "K. Shanmugan", "I. Dinstein"], "venue": "IEEE Trans. Syst.,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1973}, {"title": "Unsupervised Quick Reduct Algorithm Using Rough Set Theory", "author": ["C. Velayutham", "K. Thangavel"], "venue": "Journal of Electronic Science And Technology,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "Discretization of Continuous Valued Dimensions in OLAP Data Cubes", "author": ["S. Palaniappan", "Hong", "T.K"], "venue": "International Journal of Computer Science and Network Security vol", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "In many data mining applications, class labels are unknown, thereby indicating the significance of unsupervised feature selection [2].", "startOffset": 130, "endOffset": 133}, {"referenceID": 1, "context": "On the contrary, wrapper model requires one mining algorithm and uses its performance to determine the goodness of feature sets [3].", "startOffset": 128, "endOffset": 131}, {"referenceID": 2, "context": "Molodtsov in 1999 for dealing with uncertainties [4].", "startOffset": 49, "endOffset": 52}, {"referenceID": 3, "context": "In [5], a filter-based feature selection method, biomarker identifier (BMI), is adopted to analyze gene expression data that might be used to discriminate between samples with and without lung cancer.", "startOffset": 3, "endOffset": 6}, {"referenceID": 4, "context": "[6] investigated computed tomographic (CT) chest images and developed a computer-aided system to discriminate different lung abnormalities.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[7] explores machine learning methods for the development of computer models.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[8].", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "In [8] decision selection in given attribute is based on the maximal weighted choice value and it is similar to the Pawlak rough reduction.", "startOffset": 3, "endOffset": 6}, {"referenceID": 7, "context": "[9] introduced a new approach for an attribute reduction in multi-valued information system using soft set.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "In [10], the soft set theory has been used as feature selecT", "startOffset": 3, "endOffset": 7}, {"referenceID": 9, "context": "The proliferation of large data sets within many domains poses unprecedented challenges to data mining [11].", "startOffset": 103, "endOffset": 107}, {"referenceID": 10, "context": "Researchers realize that in order to achieve successful data mining, feature selection is an indispensable component [12].", "startOffset": 117, "endOffset": 121}, {"referenceID": 2, "context": "1 Soft Set Theory Throughout this section refers to an initial universe, E is a set of parameters, P ( ) is the power set of and A \u2286 E [4].", "startOffset": 135, "endOffset": 138}, {"referenceID": 11, "context": "Consequently, the |A| binary-valued information systems define multi-soft sets [13].", "startOffset": 79, "endOffset": 83}, {"referenceID": 7, "context": "The AND operation between and is defined as [9].", "startOffset": 44, "endOffset": 47}, {"referenceID": 7, "context": "[9].", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "The SNR value is obtained using the equation (1) and comparing the values of SNR of each image that resulted from each filter type we get the most suitable filter that could be applied on the raw CT images [6].", "startOffset": 206, "endOffset": 209}, {"referenceID": 12, "context": "Figures 5 (a) and (b) demonstrate the performance of before and after RGS algorithm and finally, figure 5 (c) shows the segmented lung image [16].", "startOffset": 141, "endOffset": 145}, {"referenceID": 13, "context": "In this research, we used gray level co-occurence matrix GLCM in four possible directions and and gray level different matrix GLDM to extract texture features from digital CT images [17].", "startOffset": 182, "endOffset": 186}, {"referenceID": 14, "context": "[18] Algorithm 1: USQR Algorithm - USQR(C) C, the set of all conditional features; (1) (2) do (3) T (4) \uf022x \uf0ce\uf020(C \uf02d\uf020R) (5) \uf022y \uf0ce\uf020C", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "This process continues until all features have been examined [18].", "startOffset": 61, "endOffset": 65}, {"referenceID": 7, "context": "In order to employ the soft set approach proposed by [9, 13], it is essential to transform the dataset into categorical ones.", "startOffset": 53, "endOffset": 60}, {"referenceID": 11, "context": "In order to employ the soft set approach proposed by [9, 13], it is essential to transform the dataset into categorical ones.", "startOffset": 53, "endOffset": 60}, {"referenceID": 15, "context": "For that, the equal width binning discretization technique in [20] is used.", "startOffset": 62, "endOffset": 66}], "year": 2012, "abstractText": "Lung cancer is the deadliest type of cancer for both men and women. Feature selection plays a vital role in cancer classification. This paper investigates the feature selection process in Computed Tomographic (CT) lung cancer images using soft set theory. We propose a new soft set based unsupervised feature selection algorithm. Nineteen features are extracted from the segmented lung images using gray level co-occurence matrix (GLCM) and gray level different matrix (GLDM). In this paper, an efficient Unsupervised Soft Set based Quick Reduct (SSUSQR) algorithm is presented. This method is used to select features from the data set and compared with existing rough set based unsupervised feature selection methods. Then KMeans and Self Organizing Map (SOM) clustering algorithms are used to cluster the data. The performance of the feature selection algorithms is evaluated based on performance of clustering techniques. The results show that the proposed method effectively removes redundant features.", "creator": null}}}