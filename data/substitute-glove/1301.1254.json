{"id": "1301.1254", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Jan-2013", "title": "Dynamical Models and tracking regret in online convex programming", "abstract": "This paper story a new yahoo cylindrical method basic which focuses came family since lawmaker simulations models and amend directed indicators regret tight suggested earthquake short the corer ' s enthalpy from the play time-dependent introduced beginning to sons. Previous online optimization practices those prototype to have a 15 tons loss low well more of the coming comparator sequence, and existing tracking and shifting anger scrimmage scale making the overall variation thus rest comparator binary. In many alternatives scenarios, following, the environment called nonstationary each globalstar three-dimensional came one depending others especially weak, occur in large gain. The direct Dynamic Mirror Descent method, also contrast, necessarily 6.04 low gesture relative way considered linear epoc sequences by both tracking the but hydrologic configuration few the uncertainty also into that is. This alternative is demonstrated empirically in be context raised sequential reinforcement x-rays of a developed scene that aided a dynamic social new.", "histories": [["v1", "Mon, 7 Jan 2013 16:39:09 GMT  (1149kb,D)", "http://arxiv.org/abs/1301.1254v1", "To appear in ICML 2013"]], "COMMENTS": "To appear in ICML 2013", "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["eric c hall", "rebecca willett"], "accepted": true, "id": "1301.1254"}, "pdf": {"name": "1301.1254.pdf", "metadata": {"source": "META", "title": "Dynamical Models and Tracking Regret in Online Convex Programming", "authors": ["Eric C. Hall", "Rebecca M. Willett"], "emails": ["ech11@duke.edu", "willett@duke.edu"], "sections": [{"heading": "1. Introduction", "text": "In a variety of large-scale streaming data problems, ranging from motion imagery formation to network analysis, dynamical models of the environment play a key role in performance. Classical stochastic filtering methods such as Kalman or particle filters or Bayesian updates (Bain & Crisan, 2009) readily exploit dynamical models for effective prediction and tracking performance. However, classical methods are also limited in\nProceedings of the 30 th International Conference on Machine Learning, Atlanta, Georgia, USA, 2013. JMLR: W&CP volume 28. Copyright 2013 by the author(s).\ntheir applicability because (a) they typically assume an accurate, fully known dynamical model and (b) they rely on strong assumptions regarding a generative model of the observations. Some techniques have been proposed to learn the dynamics (Xie et al., 1994; Theodor & Shaked, 1996), but the underlying model still places heavy restrictions on the nature of the data. Performance analysis of these methods usually does not address the impact of \u201cmodel mismatch\u201d, where the generative models are incorrectly specified.\nA contrasting class of prediction methods is based on an \u201cindividual sequence\u201d or \u201cuniversal prediction\u201d (Merhav & Feder, 1998) perspective; these strive to perform provably well on any individual observation sequence. In particular, online convex programming methods (Nemirovsky & Yudin, 1983; Beck & Teboulle, 2003; Zinkevich, 2003; Cesa-Bianchi & Lugosi, 2006) rely on the gradient of the instantaneous loss of a predictor to update the prediction for the next data point. The aim of these methods is to ensure that the per-round performance approaches that of the best offline method with access to the entire data sequence. This approach allows one to sidestep challenging issues associated with statistically dependent or nonstochastic observations, misspecified generative models, and corrupted observations. This framework is limited as well, however, because performance bounds are typically relative to either static or piecewise constant comparators and do not adequately reflect adaptivity to a dynamic environment.\nThis paper describes a novel framework for prediction in the individual sequence setting which incorporates dynamical models \u2013 effectively a novel combination of state updating from stochastic filter theory and online convex optimization from universal prediction. We establish tracking regret bounds for our proposed algorithm, Dynamic Mirror Descent (DMD), which scale with the deviation of a comparator sequence from a sequence evolving with a known dynamic. These bounds simplify to previously shown bounds, when there are\nar X\niv :1\n30 1.\n12 54\nv1 [\nst at\n.M L\n] 7\nJ an\n2 01\n3\nno dynamics. We further establish tracking regret bounds for another algorithm, Dynamic Fixed Share (DFS), which scale with the deviation of a comparator sequence from a sequence evolving with the best sequence of dynamical models. While our methods and theory apply in a broad range of settings, we are particularly interested in the setting where the dimensionality of the parameter to be estimated is very high relative to the data volume. In this regime, the incorporation of both dynamical models and sparsity regularization plays a key role. With this in mind, we focus on a class of methods which incorporate regularization as well as dynamical modeling. The role of regularization, particularly sparsity regularization, is increasingly well understood in batch settings and has resulted in significant gains in ill-posed and data-starved settings (Banerjee et al., 2008; Ravikumar et al., 2010; Cande\u0300s et al., 2006; Belkin & Niyogi, 2003).\nIn our experiments, we consider reconstructing motion imagery from sequential observations collected with a compressive camera and estimating the dynamic social network underlying over 200 years of U.S. Senate rollcall data. There has been significant recent interest in using models of temporal structure to improve time series estimation from compressed sensing observations (Angelosante et al., 2009; Vaswani & Lu, 2010) or for time-varying networks (Snijders, 2001; Kolar et al., 2010); the associated algorithms, however, are typically batch methods poorly suited to large quantities of streaming data. This paper strives to bridge that gap."}, {"heading": "2. Problem formulation", "text": "Let X denote the domain of our observations, and let \u0398 denote a convex feasible set. Given sequentially arriving observations x \u2208 X\u221e, we wish to construct a sequence of predictions \u03b8\u0302 = (\u03b8\u03021, \u03b8\u03022, . . .) \u2208 \u0398\u221e, where \u03b8\u0302t may depend only on the currently available observations xt\u22121 = (x1, . . . , xt\u22121). We pose our problem as a dynamic game between a Forecaster and the Environment. At time t, the Forecaster computes a prediction, \u03b8\u0302t and the Environment generates the observation xt. The Forecaster then experiences the loss `t(\u03b8\u0302t), defined as follows. Let F and R denote families of convex functions, and let ft(\u00b7),f(\u00b7, xt) \u2208 F be a cost function measuring the accuracy of the prediction \u03b8\u0302t with respect to the datum xt. Similarly, let r(\u00b7) \u2208 R be a regularization term which does not change over time; for instance, r might promote sparsity or other low-dimensional structure in the potentially high-dimensional space \u0398. The loss at time t\nis `t(\u00b7),ft(\u00b7) + r(\u00b7)\nwhere\n`t \u2208 L,{` = f + r : f \u2208 F , r \u2208 R}.\nThe task facing the Forecaster is to create a new prediction \u03b8\u0302t+1 based on the previous prediction and the new observation, with the goal of minimizing loss at the next time step. We characterize the efficacy of \u03b8\u0302T,(\u03b8\u03021, \u03b8\u03022, . . . , \u03b8\u0302T ) \u2208 \u0398T relative to a comparator sequence \u03b8T,(\u03b81, \u03b82, . . . , \u03b8T ) \u2208 \u0398T as follows: Definition 1 (Regret). The regret of \u03b8\u0302T with respect to a comparator \u03b8T \u2208 \u0398T is\nRT (\u03b8T ), T\u2211 t=1 `t(\u03b8\u0302t)\u2212 T\u2211 t=1 `t(\u03b8t).\nPrevious work proposed algorithms which yielded regret of O( \u221a T ) for static comparators, where \u03b8t = \u03b8 for all t. Our goal is to develop an online convex optimization algorithm with low regret relative to a broad family of time-varying comparator sequences. In particular, our main result is an algorithm which incorporates a dynamical model, denoted \u03a6t, which admits a regret bound of the form O( \u221a T [1+ \u2211 t \u2016\u03b8t+1\u2212\u03a6t(\u03b8t)\u2016]). This bound scales with the compartor sequence\u2019s deviation from the dynamical model \u03a6t \u2013 a stark contrast to previous tracking regret bounds which are only sublinear for comparators which change slowly with time or at a small number of distinct time instances."}, {"heading": "3. Static, tracking, shifting, and adaptive regret", "text": "In much of the online learning literature, the comparator sequence is constrained to be static or timeinvariant. In this paper we refer to the regret with respect to a static comparator as static regret:\nDefinition 2 (Static regret). The static regret of \u03b8\u0302T is\nRT, T\u2211 t=1 `t(\u03b8\u0302t)\u2212min \u03b8\u2208\u0398 T\u2211 t=1 `t(\u03b8).\nStatic regret bounds are useful in characterizing how well an online algorithm performs relative to, say, a loss-minimizing batch algorithm with access to all the data simultaneously. More generally, static regret bounds compare the performance of the algorithm against a static point, \u03b8\u2217, which can be chosen with full knowledge of the data.\nHowever, this form of analysis fails to illuminate the performance of online algorithms in dynamic settings\nwhere a static comparator is inappropriate. Performance relative to a temporally-varying or dynamic comparator sequence has been studied previously in the literature in the context of tracking regret, shifting regret (Herbster & Warmuth, 2001; Cesa-Bianchi et al., 2012), and the closely-related concept of adaptive regret (Littlestone & Warmuth, 1994; Hazan & Seshadhri, 2009).\nIn particular, tracking regret compares the output of the online algorithm to a sequence of points \u03b8\u22171 , \u03b8 \u2217 2 , ..., \u03b8 \u2217 T which can be chosen collectively with full knowledge of the data. This is a fair comparison for a batch algorithm that detects and fits to drift in the data, instead of fitting a single point. Frequently, in order to bound tracking regret there needs to be a measure of the complexity of the sequence \u03b8\u22171 , \u03b8 \u2217 2 , ..., \u03b8 \u2217 T+1. Typically, this complexity is characterized via a measure of the temporal variability of the sequence, such as\nV (\u03b8T ), T\u2211 t=1 \u2016\u03b8t+1 \u2212 \u03b8t\u2016.\nIf this complexity is allowed to be very high, we could imagine that the comparator series would fit the series of losses closely and hence generalize poorly. Conversely if this complexity is restricted to be 0, the tracking regret becomes equivalent to static regret. Tracking and shifting regret are the same concept, although the term shifting regret is used more in the \u201cexperts\u201d setting, while tracking regret tends to be a more generic term.\nAdaptive regret is a related concept to tracking regret. Instead of measuring accumulated regret over the entire series, however, adaptive regret measures accumulated loss over an arbitrary time interval of length \u03c4 , and measures performance against a static comparator chosen optimally on this interval:\nR\u03c4, max [r,s]\u2282[1,T ];s+1\u2212r\u2264\u03c4 [ s\u2211 t=r `t(\u03b8\u0302t)\u2212min \u03b8\u2208\u0398 s\u2211 t=r `t(\u03b8) ]\nThis is a valuable metric as it assures that a process will have low loss not just globally, but also at any given moment. Intuitively we can see that an algorithm with low adaptive regret on any interval should also have low tracking regret and vice versa. The relationship between the two has been formally shown (Cesa-Bianchi et al., 2012).\nIn this paper, we present tracking/shifting regret bounds which rely on a much more general notion of the complexity of a comparator sequence. In particular, we could measure the complexity of a sequence in terms of how much it deviates from a given dynamical\nmodel, denoted \u03a6t:\nV\u03a6(\u03b8T ), T\u2211 t=1 \u2016\u03b8t+1 \u2212 \u03a6t(\u03b8t)\u2016. (1)\nUltimately, we consider a family of dynamical models, and we measure the complexity of a comparator in terms of how much it deviates from the best sequence of dynamical models in this family. (These concepts will be formalized and detailed in the next two sections.)\nIt is intuitively satisfying that this measure appears in the bound. Firstly, if the comparator actually follows the dynamics, we would imagine this complexity to be very small, leading to low tracking regret. This fact holds whether \u03a6t is part of the generative model for the observations or not. Secondly, we can get a dynamic analog of static regret, where we enforce V\u03a6(\u03b8T ) = 0. This is equivalent to saying that the batch comparator is fitting the best single trajectory using \u03a6t instead of the best single point. Using this, we would recover a bound analogous to a static regret bound in a stationary setting.\nConcurrent related work considers online algorithms where the data sequence is described by a \u201cpredictable process\u201d (Rakhlin & Sridharan, 2012). By knowing a good estimate for the underlying process, they can create a prediction sequence that follows accordingly, reducing overall loss. However, they express their results in terms of a static regret bound (i.e., regret with respect to a static comparator) with a variation term that expresses the deviation of the input data from the underlying process. In contrast, we make no assumptions about the data itself, but instead on the comparator series, and form tracking regret bounds."}, {"heading": "4. Online convex optimization", "text": "One common approach to forming the predictions \u03b8\u0302t, Mirror Descent (MD) (Nemirovsky & Yudin, 1983; Beck & Teboulle, 2003), consists of solving the following optimization problem:\n\u03b8\u0302t+1 =arg min \u03b8\u2208\u0398\n\u03b7t\u3008\u2207`t(\u03b8\u0302t), \u03b8\u3009+D(\u03b8\u2016\u03b8\u0302t), (2)\nwhere \u2207`t(\u03b8) denotes an arbitrary subgradient of `t at \u03b8, D(\u03b8\u2016\u03b8\u0302t) is the Bregman divergence between \u03b8 and \u03b8\u0302, and \u03b7t \u2265 0 is a step size parameter. Let \u03c8 denote a continuously differentiable function that is \u03c3-strongly convex with respect to a norm \u2016 \u00b7 \u2016 on the set \u0398 for some \u03c3 > 0; the Bregman divergence associated with\n\u03c8 is defined as\nD(\u03b81\u2016\u03b82) =D\u03c8(\u03b81\u2016\u03b82) (3a) ,\u03c8(\u03b81)\u2212 \u03c8(\u03b82)\u2212 \u3008\u2207\u03c8(\u03b82), \u03b81 \u2212 \u03b82\u3009 (3b) \u2261D(\u03b83\u2016\u03b82) +D(\u03b81\u2016\u03b83)\n+ \u3008\u2207\u03c8(\u03b82)\u2212\u2207\u03c8(\u03b83), \u03b83 \u2212 \u03b81\u3009 (3c)\nfor all \u03b81, \u03b82, \u03b83 \u2208 \u0398, and the strong convexity of \u03c8 implies\nD(\u03b81\u2016\u03b82) \u2265 \u03c3\n2 \u2016\u03b81 \u2212 \u03b82\u20162.\nThe MD approach is a generalization of online learning algorithms such as online gradient descent (Zinkevich, 2003) and weighted majority (Littlestone & Warmuth, 1994). Several recently proposed methods consider the data-fit term separately from the regularization term (Duchi et al., 2010; Xiao, 2010; Langford et al., 2009). For instance, consider Composite Objective Mirror Descent (COMD) (Duchi et al., 2010):\n\u03b8\u0302t+1 =arg min \u03b8\u2208\u0398\n\u03b7t\u3008\u2207ft(\u03b8\u0302t), \u03b8\u3009+ \u03b7tr(\u03b8) +D(\u03b8\u2016\u03b8\u0302t). (4)\nThis formulation is helpful when the regularization function r(\u03b8) promotes sparsity in \u03b8, and helps en-\nsure that the individual \u03b8\u0302t are indeed sparse, rather than approximately sparse as are the solutions to the MD formulation. The regret of this approach has previously been characterized as follows:\nTheorem 3 (Static regret for COMID (Duchi et al., 2010)). Let Gf,max\u03b8\u2208\u0398,f\u2208F \u2016\u2207f(\u03b8)\u2016, Dmax = max\u03b81,\u03b82\u2208\u0398D(\u03b81\u2016\u03b82) and assume that \u03b8,\u03b81 = \u03b82 = \u00b7 \u00b7 \u00b7 = \u03b8T . If r(\u03b8\u03021) = 0 and \u03b7t = (2\u03c3Dmax) 1/2/(Gf \u221a T ), then\nRT (\u03b8T ) \u2264 Gf (2TDmax/\u03c3)1/2."}, {"heading": "5. Dynamical models in online convex programming", "text": "Unlike the bound in Theorem 3, tracking or shifting regret (Cesa-Bianchi & Lugosi, 2006; Cesa-Bianchi et al., 2012) bounds typically consider piecewise constant comparators, where \u03b8t \u2212 \u03b8t\u22121 = 0 for all but m values of t, where m is a constant, or yield regret bounds which scale with \u2211 t \u2016\u03b8t \u2212 \u03b8t\u22121\u2016. In this paper, we develop tracking regret bounds which are small for much broader classes of dynamic comparator sequences.\nIn particular, we propose the following alternative to (2) and (4), which we call Dynamic Mirror Descent\n(DMD). Let \u03a6t : \u0398 7\u2192 \u0398 denote a predetermined dynamical model, and set\n\u03b8\u0303t+1 =arg min \u03b8\u2208\u0398\n\u03b7t\u3008\u2207ft(\u03b8\u0302t), \u03b8\u3009+ \u03b7tr(\u03b8) +D(\u03b8\u2016\u03b8\u0302t)\n(5a)\n\u03b8\u0302t+1 = \u03a6t(\u03b8\u0303t+1) (5b)\nBy including \u03a6t in the process, we effectively search for a predictor which (a) attempts to minimize the loss\nand (b) which is close to \u03b8\u0303t under the transformation of \u03a6t. This is similar to a stochastic filter which alternates between using a dynamical model to update the \u201cstate\u201d, and then uses this state to perform the filtering action. A key distinction of our approach, however, is that we make no assumptions about \u03a6t\u2019s relationship to the observed data.\nOur approach effectively includes dynamics into the COMID approach. Indeed, for a case with no dynamics, so that \u03a6t(\u03b8) \u2261 \u03b8 for all \u03b8 and t, our method is equivalent to COMID. Rather than considering COMID, we might have used other online optimization algorithms, such as the Regularized Dual Averaging (RDA) method (Xiao, 2010), which has been shown to achieve similar performance with more regularized solutions. However, to the best of our knowledge, no tracking or shifting regret bounds have been derived for dual averaging methods (regularized or otherwise). Recent results on the equivalence of COMID and RDA (McMahan, 2011) suggest that the bounds derived here might also hold for a variant of RDA, but proving this remains an open problem.\nOur main result uses the following definitions:\nG`, max \u03b8\u2208\u0398,`\u2208L \u2016\u2207`(\u03b8)\u2016\nM, 1\n2 max \u03b8\u2208\u0398 \u2016\u2207\u03c8(\u03b8)\u2016\nDmax, max \u03b8,\u03b8\u2032\u2208\u0398\nD(\u03b8\u2032\u2016\u03b8),\nand \u2206\u03a6t, max \u03b8,\u03b8\u2032\u2208\u0398\nD(\u03a6\u03b8\u2016\u03a6\u03b8\u2032)\u2212D(\u03b8\u2016\u03b8\u2032),\nTheorem 4. Let \u03a6t be a dynamical model such that \u2206\u03a6t \u2264 0. Let the sequence \u03b8\u0302T be as in (5b), and let \u03b8T be an arbitrary sequence in \u0398\nT . Then the Dynamic Mirror Descent (DMD) algorithm using a nonincreasing series \u03b7t+1 \u2264 \u03b7t gives\nRT (\u03b8T ) \u2264 Dmax \u03b7T+1 + 4M \u03b7T V\u03a6t(\u03b8T ) + G2` 2\u03c3 T\u2211 t=1 \u03b7t (6)\nwith V\u03a6t(\u03b8T ), T\u2211 t=1 \u2016\u03b8t+1 \u2212 \u03a6t(\u03b8t)\u2016 (7)\nwhere V\u03a6t(\u03b8T ) measures variations or deviations of the comparator sequence \u03b8T from the dynamical model \u03a6t.\nNote that when \u03a6t corresponds to an identity operator, the bound in Theorem 4 corresponds to existing tracking or shifting regret bounds (Cesa-Bianchi & Lugosi, 2006; Cesa-Bianchi et al., 2012). The condition that \u2206\u03a6t \u2264 0 is similar to requiring that \u03a6t be a contraction mapping. This restriction is important; without it, any poor prediction made at one time step could be magnified by repeated application of the dynamics. Additive models and matrix multiplications with all eigenvalues less than or equal to unity satisfy this restriction. Notice also that if \u03a6t = I for all t, the theorem gives a novel tracking regret bound for COMID. To prove Theorem 4, we employ the following lemma, which is proven in Section 9.\nLemma 5. Let the sequence \u03b8\u0302T be as in (5b), and let \u03b8T be an arbitrary sequence in \u0398 T ; then\n`t(\u03b8\u0302t)\u2212 `t(\u03b8t) \u2264 1\n\u03b7t\n[ D(\u03b8t\u2016\u03b8\u0302t)\u2212D(\u03b8t+1\u2016\u03b8\u0302t+1) ] +\n\u2206\u03a6t \u03b7t + 4M \u03b7t \u2016\u03b8t+1 \u2212 \u03a6t(\u03b8t)\u2016+ \u03b7t 2\u03c3 G2` .\nProof of Theorem 4: The proof is a matter of summing the bounds of Lemma 5 over time. For simplicity denote Dt,D(\u03b8t\u2016\u03b8\u0302t) and Vt,\u2016\u03b8t+1 \u2212 \u03a6t(\u03b8t)\u2016. Then\nRT (\u03b8T ) \u2264 T\u2211 t=1 ( Dt \u03b7t \u2212 Dt+1 \u03b7t+1 ) + G2` 2\u03c3 T\u2211 t=1 \u03b7t\n+Dmax T\u2211 t=1 ( 1 \u03b7t+1 \u2212 1 \u03b7t ) + T\u2211 t=1 4M \u03b7t Vt\n\u2264Dmax \u03b7T+1 + 4M \u03b7T V\u03a6t(\u03b8T ) + G2` 2\u03c3 T\u2211 t=1 \u03b7t.\nWe set \u03b7t using the doubling trick (Cesa-Bianchi & Lugosi, 2006) whereby time is divided into increasingly longer segments, and on each interval a temporary time horizon is fixed, known, and used to determine an optimal step size (generally proportional to the inverse of the square root of the time horizon). This approach yields the regret bound:\nR(\u03b8T ) = O( \u221a T [1 + V\u03a6t(\u03b8T )])\nThis proof shares some ideas with the tracking regret bounds of (Zinkevich, 2003), but uses properties of the Bregman Divergence to eliminate some terms, while additionally incorporating dynamics."}, {"heading": "6. Prediction with a family of dynamical models", "text": "DMD in the previous section uses a single dynamical model. In practice, however, we do not know the best dynamical model to use, or the best model may change over time in nonstationary environments.\nTo address this challenge, we assume a finite set of candidate dynamical models {\u03a6(1)t ,\u03a6 (2) t , . . .\u03a6 (N) t }, and describe a procedure which uses this collection to adapt to nonstationarities in the environment. In particular, we establish tracking regret bounds for a comparator class with different dynamical models on different time intervals. This class, \u0398m, can be described as all predictors defined on m+1 segments [ti, ti+1\u22121] with time points 1 = t1 < \u00b7 \u00b7 \u00b7 < tm+2 = T + 1. For a given \u03b8T \u2208 \u0398m and k = 1, . . . ,m+ 1, let\nV (m+1)(\u03b8T ),\nmin t2,...,tm+1 m+1\u2211 k=1 min ik\u2208{1,...,N} tk+1\u22121\u2211 t=tk \u2016\u03b8t+1 \u2212 \u03a6(ik)t (\u03b8t)\u2016\ndenote the deviation of the sequence \u03b8T from the best series of m+ 1 dynamical models.\nLet \u03b8\u0302 (i) t denote the output of the DMD algorithm of Section 5 using dynamical model \u03a6 (i) t . Then tracking regret can be expressed as:\nRT (\u0398m) = T\u2211 t=1 `t(\u03b8\u0302t)\u2212 min i1,...,iT T\u2211 t=1 `t ( \u03b8\u0302 (it) t ) \ufe38 \ufe37\ufe37 \ufe38\nT1\n+ min i1,...,iT T\u2211 t=1 `t ( \u03b8\u0302 (it) t ) \u2212 min \u03b8\u2208\u0398m T\u2211 t=1\n`t(\u03b8t)\ufe38 \ufe37\ufe37 \ufe38 T2 (8)\nwhere the minimization in the second term of T1 and first term of T2 is with respect to sequences of dynamical models with at most m switches, such that\u2211T t=1 1[it 6=it+1] \u2264 m. In (8), T1 corresponds to the tracking regret of our algorithm relative to the best sequence of dynamical models within the DMD framework, and T2 is the regret of that sequence relative to the best comparator in the class \u0398m.\nWe choose \u03b8\u0302t by using the Fixed Share (FS) forecaster on the DMD estimates of (5), \u03b8\u0302 (i) t . In FS, each expert (here, each candidate dynamical model) is assigned a weight that is inversely proportional to its cumulative loss at that point yet with some weight shared amongst all the experts, so that an expert with very small weight can quickly regain weight to become the\nleader (Cesa-Bianchi & Lugosi, 2006). Our estimate is:\nw\u0303i,t =wi,t\u22121 exp(\u2212\u03b7r`t(\u03b8\u0302(i)t )) (9) wi,t =(\u03bb/N) \u2211N j=1 w\u0303j,t + (1\u2212 \u03bb)w\u0303i,t (10)\n\u03b8\u0302t = N\u2211 i=1 wi,t\u03b8\u0302 (i) t / N\u2211 i=1 wi,t. (11)\nFollowing (Cesa-Bianchi & Lugosi, 2006), we have\nT1 \u2264 m+ 1\n\u03b7r logN +\n1\n\u03b7r log\n1 \u03bbm(1\u2212 \u03bb)(T\u2212m\u22121) + \u03b7r 8 T\nand T2 can be bounded using the method described in Section 5 on each time interval [tk, tk+1 \u2212 1] and summing over the m+ 1 intervals, yielding\nT2 \u2264 (m+ 1)Dmax\n\u03b7T+1 +\n4M\n\u03b7T V (m+1)(\u03b8T ) + G2` 2\u03c3 T\u2211 t=1 \u03b7t.\nLetting \u03b7r = \u03b7t = 1/ \u221a T , the overall expected tracking regret is thus\nRT (\u03b8T ) = O (\u221a T [ (m+ 1)(logN +Dmax)\n+ log 1\n\u03bbm(1\u2212 \u03bb)(T\u2212m\u22121) + 4MV (m+1)(\u03b8T )\n]) .\nThe last term in this bound measures the deviation of a comparator in \u0398m from the best series of dynamical models over m + 1 segments (where m does not scale with T ). Here \u03bb is usually chosen to be mT where m is an upper bound on the number of switches, independent of T . Again, if T is not known in advance the doubling trick can be used. Note that V (m+1)(\u03b8T ) \u2264 V\n\u03a6 (i) t (\u03b8T ) for any fixed i \u2208 {1, . . . , N}, thus this approach generally yields lower regret than using a fixed dynamical model. However, we incur some loss by not knowing the optimal number of switches m or when the switching times are; these are accounted for in T1.\nWe use the Fixed Share algorithm as a means to amalgamate estimates with different dynamics, however other methods could be used with various tradeoffs. The Fixed Share algorithm, for instance, has linear complexity with low regret, but with respect to a comparator class with fixed number of switches. Other algorithms can accommodate larger classes of experts, or not assume knowledge of the number of switches, but come at the price of higher regret or complexity as explained in (Gyorgy et al., 2012)."}, {"heading": "7. Experiments and results", "text": "To demonstrate the performance of Dynamic Mirror Descent (DMD) combined with the Fixed share algorithm (which we call Dynamic Fixed Share (DFS)), we\nconsider two scenarios: reconstruction of a dynamic scene (i.e., video) from sequential compressed sensing observations, and tracking connections in a dynamic social network."}, {"heading": "7.1. Compressive video reconstruction", "text": "To test DMD, we construct a video which contains an object moving in a 2-dimensional plane; the tth frame is denoted \u03b8t (a 150 \u00d7 150 image stored as a length22500 vector) which takes values between 0 and 1. The corresponding observation is xt = At\u03b8t +nt, where At is a random 500\u00d722500 matrix and nt corresponds to measurement noise. This model coincides with several compressed sensing architectures (Duarte et al., 2008). We used white Gaussian noise with variance 1.\nOur loss function uses ft(\u03b8) = 1 2\u2016xt \u2212 At\u03b8\u2016 2 2 and r(\u03b8) = \u03c4\u2016\u03b8\u20161, where \u03c4 > 0 is a tuning parameter. We construct a family of N = 9 dynamical models, where \u03a6 (i) t (\u03b8) shifts the frame, \u03b8, one pixel in a direction corresponding to an angle of 2\u03c0i/(N \u2212 1) as well as a \u201cdynamic\u201d corresponding to no motion. (With the static model, DMD reduces to COMID.) The true video sequence uses different dynamical models over t = {1, ..., 240} and t = {241, ..., 500}. Finally, we use \u03c8(\u00b7) = \u2016 \u00b7 \u201622 so the Bregman Divergence D(x\u2016y) = \u2016x\u2212y\u201622 is the usual squared Euclidean distance. The DFS forecaster uses \u03bb = 0.01.\nFigures 1 and 2 show the impact of using DFS. We see that DFS switches between dynamical models rapidly and outperforms all of the individual predictions, including COMID, used as a baseline, to show the advantages of incorporating knowledge of the dynamics.\n0 100 200 300 400 5000\n1\n2\n3\n4\n5\n6\n7\n8 x 10 4\nTime\nLo ss\nInstantaneous Loss\nGround Truth DMD with Accurate Dynamics\nDMD with Inaccurate Dynamics DFS Prediction N NE E SE S SW W NW COMID DFS\nFigure 2. Instantaneous predictions at t = 480. Top Left: \u03b8t. Top Right: \u03b8\u0302 (SE)\nt . Bottom Left: \u03b8\u0302\n(E)\nt . Bottom Right:\n\u03b8\u0302t. The prediction made with the prevailing motion is an accurate representation of the ground truth, while the prediction with the wrong dynamic is an unclear picture. The DFS algorithm correctly picks out the cleaner picture."}, {"heading": "7.2. Tracking dynamic social networks", "text": "Dynamical models have a rich history in the context of social network analysis (Snijders, 2001), but we are unaware of their application in the context of online learning algorithms. To show how DMD can bridge this gap, we track the influence matrix of seats in the US Senate from 1795 to 2011 using roll call data (http://www.voteview.com/dwnl.htm). At time t, we observe the \u201cyea\u201d or \u201cnay\u201d vote of each Senator, which we represent with a +1 or \u22121. When a Senator\u2019s vote is unavailable (for instance, before a state joined the union), we use a 0. We form a length p = 100 vector of these votes indexed by the Senate seat, and denote this xt.\nFollowing (Ravikumar et al., 2010), we form a loss function using a negative log Ising model pseudolikelihood to sidestep challenging issues associated with the partition function of the Ising model likelihood. For a social network with p agents, \u03b8t \u2208 [\u22121, 1]p\u00d7p, where (\u03b8t)ab corresponds to the correlation in voting patterns between agents a and b at time t. Let V denote the set of agents, V\\a the set of all agents except a, xa the vote of agent a, and \u03b8a,{\u03b8ab : b \u2208 V}. Our loss function is\n\u03d5 (a) t (\u03b8a), log\n[ exp ( 2\u03b8aaxa + 2 \u2211 b\u2208V\\a \u03b8abxaxb ) + 1 ]\nf (a)(\u03b8a;x),\u2212 2\u03b8aaxa \u2212 2 \u2211 b\u2208V\\a \u03b8abxaxb + \u03d5 (a) t (\u03b8a)\nf(\u03b8;x) = \u2211 a\u2208V f (a)(\u03b8a;x)\nand r(\u03b8) = \u03c4\u2016\u03b8\u20161, where \u03c4 > 0 is a tuning parameter; this loss is convex in \u03b8. We set \u03c8(\u03b8) = 12\u2016\u03b8\u2016 2 2 and use a dynamical model inspired by (Snijders, 2001), where if |\u03b8ac\u2217\u03b8bc\u2217 | > |\u03b8ab|, with c\u2217 =arg maxc |\u03b8ac\u03b8bc|, then:\n(\u03a6 (i) t (\u03b8))ab = (1\u2212 \u03b1i)\u03b8ab + \u03b1i\u03b8ac\u2217\u03b8bc\u2217 .\nOtherwise, \u03b8\u0302 (i) ab = \u03b8\u0303 (i) ab . The intuition is that if two members of the network share a strong common connection, they will become connected in time. We set \u03b1i \u2208 {0, .001, .002, .003, .004} for the different dynamical models. We set \u03c4 = .1 and again set \u03b7 using the doubling trick with time horizons at set at increasing powers of 10. As in (Langford et al., 2009), we find that regularizing (e.g., thresholding) every 10 steps, instead of at each time step, allows for the values to grow above the threshold for meaningful relationships to be found.\nYear\n18 57 18 59\n18 61 18 63\n18 65 18 67\nAverage Per Round Loss\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nYear\n19 91 19 93 19 95\n19 97\n19 99 20 01 20 03 20 05 20 07 20 09 20 11\nLo ss\nLoss of Select Senators\nLieberman Kerry McCain McConnell\n1877 1887 1905 1967 2011\n=0 =.001 =.002 =.003 =.004\nDFS\nFigure 4. Losses for individual senators. Low losses correspond to predictable, consistent voting behavior, while higher loss means less predictable\nFigure 3 shows the average per round loss of each model, and the DFS estimator over a 30 year time window. We see that applying the dynamical model improves performance relative to COMID (\u03b1i = 0) and that DFS aggregates the predictions successfully. Figure 4 shows the moving average losses for a few Senators, where high loss corresponds to behavior unexpected in the model. Notice that John Kerry (DMA) has generally low loss, spikes around 2006, and then drops again before a reelection campaign in 2008.\nLooking at the network estimates of DFS across time (as in Figure 5) we can see tight factions forming in the mid- to late-1800s (post Civil War), followed by a time when the factions dissipate in the mid-1900s during the Civil Rights Movement. Finally, we see factions again forming in more recent times. The seats are sorted separately for each matrix to emphasize groupings, which align with known political factions."}, {"heading": "1859 1877 1887", "text": ""}, {"heading": "8. Conclusion and future directions", "text": "In this paper we have proposed a novel online optimization method, called Dynamic Mirror Descent (DMD), which incorporates dynamical model state updates. There is no assumption that there is a \u201ctrue\u201d known underlying dynamical model, or that the best dynamical model is unchanging with time. The proposed Dynamic Fixed Share (DFS) algorithm adaptively selects the most promising dynamical model from a family of candidates at each time step. Recent work on shifting or tracking regret bounds for online convex optimization further suggest that the techniques developed in this paper may also be useful for bounding adaptive regret or developing methods for automatically tuning step-size parameters (Cesa-\nBianchi et al., 2012). In experiments with real and simulated data, DMD shows strong tracking behavior even when underlying dynamical models are switching."}, {"heading": "9. Proofs", "text": "Proof of Lemma 5:\nThe optimality condition of (5a) implies\n\u3008\u2207ft(\u03b8\u0302t) +\u2207r(\u03b8\u0303t+1), \u03b8\u0303t+1 \u2212 \u03b8t\u3009 \u2264 1\n\u03b7t \u3008\u2207\u03c8(\u03b8\u0302t)\u2212\u2207\u03c8(\u03b8\u0303t+1), \u03b8\u0303t+1 \u2212 \u03b8t\u3009. (13)\nUsing this condition we can bound the instantaneous regret as follows:\nft(\u03b8\u0302t)\u2212 ft(\u03b8t) + r(\u03b8\u0302t)\u2212 r(\u03b8t)\n=ft(\u03b8\u0302t)\u2212 ft(\u03b8t) + r(\u03b8\u0302t)\u2212 r(\u03b8\u0303t+1) + r(\u03b8\u0303t+1)\u2212 r(\u03b8t)\n\u2264\u3008\u2207ft(\u03b8\u0302t), \u03b8\u0302t \u2212 \u03b8t\u3009+ \u3008\u2207r(\u03b8\u0302t), \u03b8\u0302t \u2212 \u03b8\u0303t+1\u3009\n+ \u3008\u2207r(\u03b8\u0303t+1), \u03b8\u0303t+1 \u2212 \u03b8t\u3009 (14a)\n\u2264 1 \u03b7t \u3008\u2207\u03c8(\u03b8\u0302t)\u2212\u2207\u03c8(\u03b8\u0303t+1), \u03b8\u0303t+1 \u2212 \u03b8t\u3009\n+ \u3008\u2207ft(\u03b8\u0302t) +\u2207r(\u03b8\u0302t), \u03b8\u0302t \u2212 \u03b8\u0303t+1\u3009 (14b)\n= 1\n\u03b7t\n[ D(\u03b8t\u2016\u03b8\u0302t)\u2212D(\u03b8t+1\u2016\u03b8\u0302t+1) ] + T3 + T4/\u03b7t + T5/\u03b7t where, (14c)\nT3,\u2212 1\n\u03b7t D(\u03b8\u0303t+1\u2016\u03b8\u0302t) + \u3008\u2207`t(\u03b8\u0302t), \u03b8\u0302t \u2212 \u03b8\u0303t+1\u3009 T4, [ D(\u03a6t(\u03b8t)\u2016\u03a6t(\u03b8\u0303t+1))\u2212D(\u03b8t\u2016\u03b8\u0303t+1) ] \u2264 \u2206\u03a6t\nT5, [ D(\u03b8t+1\u2016\u03b8\u0302t+1)\u2212D(\u03a6t(\u03b8t)\u2016\u03b8\u0302t+1) ] .\nHere, (14a) follows from the convexity of ft and r, (14b) follows from the optimality condition of (5a), and (14c) follows from (3c) and adding and subtracting terms using the equivalence (5b). Each of term can be bounded, and then combined to complete the proof.\nT3 \u2264\u2212 \u03c3\n2\u03b7t \u2016\u03b8\u0303t+1 \u2212 \u03b8\u0302t\u20162\n+ \u03c3\n2\u03b7t \u2016\u03b8\u0303t+1 \u2212 \u03b8\u0302t\u20162 + \u03b7t 2\u03c3 G2` = \u03b7t 2\u03c3 G2` (15a)\nT5 =\u03c8(\u03b8t+1)\u2212 \u3008\u2207\u03c8(\u03b8\u0302t+1), \u03b8t+1 \u2212 \u03b8\u0302t+1\u3009\n\u2212 \u03c8(\u03a6t(\u03b8t)) + \u3008\u2207\u03c8(\u03b8\u0302t+1),\u03a6t(\u03b8t)\u2212 \u03b8\u0302t+1\u3009\n=\u03c8(\u03b8t+1)\u2212 \u03c8(\u03a6t(\u03b8t))\u2212 \u3008\u2207\u03c8(\u03b8\u0302t+1), \u03b8t+1 \u2212 \u03a6t(\u03b8t)\u3009 \u22644M\u2016\u03b8t+1 \u2212 \u03a6t(\u03b8t)\u2016 (15b)\nwhere (15a) is due to the strong convexity of the Bregman Divergence and Young\u2019s inequality and (15b) is due to the convexity of \u03c8 and the Cauchy-Schwarz inequality. Combining these inequalities with (14c) gives the Lemma as it is stated."}], "references": [{"title": "Compressed sensing of time-varying signals", "author": ["D. Angelosante", "G.B. Giannakis", "E. Grossi"], "venue": "In Intl Conf. on Dig. Sig. Proc.,", "citeRegEx": "Angelosante et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Angelosante et al\\.", "year": 2009}, {"title": "Model selection through sparse maximum likelihood estimation for multivariate Gaussian or binary data", "author": ["O. Banerjee", "L. El Ghaoui", "A. d\u2019Aspremont"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Banerjee et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Banerjee et al\\.", "year": 2008}, {"title": "Mirror descent and nonlinear projected subgradient methods for convex programming", "author": ["A. Beck", "M. Teboulle"], "venue": "Operations Research Letters,", "citeRegEx": "Beck and Teboulle,? \\Q2003\\E", "shortCiteRegEx": "Beck and Teboulle", "year": 2003}, {"title": "Laplacian eigenmaps for dimensionality reduction and data representation", "author": ["M. Belkin", "P. Niyogi"], "venue": "Neural Comput.,", "citeRegEx": "Belkin and Niyogi,? \\Q2003\\E", "shortCiteRegEx": "Belkin and Niyogi", "year": 2003}, {"title": "Stable signal recovery from incomplete and inaccurate measurements", "author": ["E. Cand\u00e8s", "J. Romberg", "T. Tao"], "venue": "Communications on Pure and Applied Mathematics,", "citeRegEx": "Cand\u00e8s et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Cand\u00e8s et al\\.", "year": 2006}, {"title": "Prediction, Learning and Games", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": null, "citeRegEx": "Cesa.Bianchi and Lugosi,? \\Q2006\\E", "shortCiteRegEx": "Cesa.Bianchi and Lugosi", "year": 2006}, {"title": "A new look at shifting regret", "author": ["N. Cesa-Bianchi", "P. Gaillard", "G. Lugosi", "G. Stoltz"], "venue": null, "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2012}, {"title": "Single pixel imaging via compressive sampling", "author": ["M.F. Duarte", "M.A. Davenport", "D. Takhar", "J.N. Laska", "T. Sun", "K.F. Kelly", "R.G. Baraniuk"], "venue": "IEEE Sig. Proc. Mag.,", "citeRegEx": "Duarte et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Duarte et al\\.", "year": 2008}, {"title": "Composite objective mirror descent", "author": ["J. Duchi", "S. Shalev-Shwartz", "Y. Singer", "A. Tewari"], "venue": "In Conf. on Learning Theory (COLT),", "citeRegEx": "Duchi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2010}, {"title": "Efficient tracking of large classes of experts", "author": ["A. Gyorgy", "T. Linder", "G. Lugosi"], "venue": "IEEE Transaction on Information Theory,", "citeRegEx": "Gyorgy et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gyorgy et al\\.", "year": 2012}, {"title": "Efficient learning algorithms for changing environments", "author": ["E. Hazan", "C. Seshadhri"], "venue": "In Proc. Int. Conf on Machine Learning (ICML),", "citeRegEx": "Hazan and Seshadhri,? \\Q2009\\E", "shortCiteRegEx": "Hazan and Seshadhri", "year": 2009}, {"title": "Tracking the best linear predictor", "author": ["M. Herbster", "M.K. Warmuth"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Herbster and Warmuth,? \\Q2001\\E", "shortCiteRegEx": "Herbster and Warmuth", "year": 2001}, {"title": "Estimating time-varying networks", "author": ["M. Kolar", "L. Song", "A. Ahmed", "E.P. Xing"], "venue": "Annals of Applied Statistics,", "citeRegEx": "Kolar et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kolar et al\\.", "year": 2010}, {"title": "Sparse online learning via truncated gradient", "author": ["J. Langford", "L. Li", "T. Zhang"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Langford et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Langford et al\\.", "year": 2009}, {"title": "The weighted majority algorithm", "author": ["N. Littlestone", "M.K. Warmuth"], "venue": "Inf. Comput.,", "citeRegEx": "Littlestone and Warmuth,? \\Q1994\\E", "shortCiteRegEx": "Littlestone and Warmuth", "year": 1994}, {"title": "A unified view of regularized dual averaging and mirror descent with implicit updates", "author": ["B. McMahan"], "venue": null, "citeRegEx": "McMahan,? \\Q2011\\E", "shortCiteRegEx": "McMahan", "year": 2011}, {"title": "Universal prediction", "author": ["N. Merhav", "M. Feder"], "venue": "IEEE Trans. Info. Th.,", "citeRegEx": "Merhav and Feder,? \\Q1998\\E", "shortCiteRegEx": "Merhav and Feder", "year": 1998}, {"title": "Problem complexity and method efficiency in optimization", "author": ["A.S. Nemirovsky", "D.B. Yudin"], "venue": null, "citeRegEx": "Nemirovsky and Yudin,? \\Q1983\\E", "shortCiteRegEx": "Nemirovsky and Yudin", "year": 1983}, {"title": "Online learning with predictable sequences", "author": ["A. Rakhlin", "K. Sridharan"], "venue": null, "citeRegEx": "Rakhlin and Sridharan,? \\Q2012\\E", "shortCiteRegEx": "Rakhlin and Sridharan", "year": 2012}, {"title": "High-dimenstional Ising model selection using `1regularized logistic regression", "author": ["P. Ravikumar", "M.J. Wainwright", "J.D. Lafferty"], "venue": "Annals of Statistics,", "citeRegEx": "Ravikumar et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ravikumar et al\\.", "year": 2010}, {"title": "The statistical evaluation of social network dynamics", "author": ["T.A.B. Snijders"], "venue": "Sociological Methodology,", "citeRegEx": "Snijders,? \\Q2001\\E", "shortCiteRegEx": "Snijders", "year": 2001}, {"title": "Robust discrete-time minimum-variance filtering", "author": ["Y. Theodor", "U. Shaked"], "venue": "IEEE Trans. Sig. Proc.,", "citeRegEx": "Theodor and Shaked,? \\Q1996\\E", "shortCiteRegEx": "Theodor and Shaked", "year": 1996}, {"title": "Modified-CS: Modifying compressive sensing for problems with partially known support", "author": ["N. Vaswani", "W. Lu"], "venue": "IEEE Trans. Sig. Proc.,", "citeRegEx": "Vaswani and Lu,? \\Q2010\\E", "shortCiteRegEx": "Vaswani and Lu", "year": 2010}, {"title": "Dual averaging methods for regularized stochastic learning and online optimization", "author": ["L. Xiao"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Xiao,? \\Q2010\\E", "shortCiteRegEx": "Xiao", "year": 2010}, {"title": "Robust Kalman filtering for uncertain discrete-time systems", "author": ["L. Xie", "Y.C. Soh", "C.E. de Souza"], "venue": "IEEE Trans. Autom. Control,", "citeRegEx": "Xie et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Xie et al\\.", "year": 1994}, {"title": "Online convex programming and generalized infinitesimal gradient descent", "author": ["M. Zinkevich"], "venue": "In Proc. Int. Conf. on Machine Learning (ICML), pp", "citeRegEx": "Zinkevich,? \\Q2003\\E", "shortCiteRegEx": "Zinkevich", "year": 2003}], "referenceMentions": [{"referenceID": 24, "context": "Some techniques have been proposed to learn the dynamics (Xie et al., 1994; Theodor & Shaked, 1996), but the underlying model still places heavy restrictions on the nature of the data.", "startOffset": 57, "endOffset": 99}, {"referenceID": 25, "context": "In particular, online convex programming methods (Nemirovsky & Yudin, 1983; Beck & Teboulle, 2003; Zinkevich, 2003; Cesa-Bianchi & Lugosi, 2006) rely on the gradient of the instantaneous loss of a predictor to update the prediction for the next data point.", "startOffset": 49, "endOffset": 144}, {"referenceID": 1, "context": "The role of regularization, particularly sparsity regularization, is increasingly well understood in batch settings and has resulted in significant gains in ill-posed and data-starved settings (Banerjee et al., 2008; Ravikumar et al., 2010; Cand\u00e8s et al., 2006; Belkin & Niyogi, 2003).", "startOffset": 193, "endOffset": 284}, {"referenceID": 19, "context": "The role of regularization, particularly sparsity regularization, is increasingly well understood in batch settings and has resulted in significant gains in ill-posed and data-starved settings (Banerjee et al., 2008; Ravikumar et al., 2010; Cand\u00e8s et al., 2006; Belkin & Niyogi, 2003).", "startOffset": 193, "endOffset": 284}, {"referenceID": 4, "context": "The role of regularization, particularly sparsity regularization, is increasingly well understood in batch settings and has resulted in significant gains in ill-posed and data-starved settings (Banerjee et al., 2008; Ravikumar et al., 2010; Cand\u00e8s et al., 2006; Belkin & Niyogi, 2003).", "startOffset": 193, "endOffset": 284}, {"referenceID": 0, "context": "There has been significant recent interest in using models of temporal structure to improve time series estimation from compressed sensing observations (Angelosante et al., 2009; Vaswani & Lu, 2010) or for time-varying networks (Snijders, 2001; Kolar et al.", "startOffset": 152, "endOffset": 198}, {"referenceID": 20, "context": ", 2009; Vaswani & Lu, 2010) or for time-varying networks (Snijders, 2001; Kolar et al., 2010); the associated algorithms, however, are typically batch methods poorly suited to large quantities of streaming data.", "startOffset": 57, "endOffset": 93}, {"referenceID": 12, "context": ", 2009; Vaswani & Lu, 2010) or for time-varying networks (Snijders, 2001; Kolar et al., 2010); the associated algorithms, however, are typically batch methods poorly suited to large quantities of streaming data.", "startOffset": 57, "endOffset": 93}, {"referenceID": 6, "context": "Performance relative to a temporally-varying or dynamic comparator sequence has been studied previously in the literature in the context of tracking regret, shifting regret (Herbster & Warmuth, 2001; Cesa-Bianchi et al., 2012), and the closely-related concept of adaptive regret (Littlestone & Warmuth, 1994; Hazan & Seshadhri, 2009).", "startOffset": 173, "endOffset": 226}, {"referenceID": 6, "context": "The relationship between the two has been formally shown (Cesa-Bianchi et al., 2012).", "startOffset": 57, "endOffset": 84}, {"referenceID": 25, "context": "The MD approach is a generalization of online learning algorithms such as online gradient descent (Zinkevich, 2003) and weighted majority (Littlestone & Warmuth, 1994).", "startOffset": 98, "endOffset": 115}, {"referenceID": 8, "context": "Several recently proposed methods consider the data-fit term separately from the regularization term (Duchi et al., 2010; Xiao, 2010; Langford et al., 2009).", "startOffset": 101, "endOffset": 156}, {"referenceID": 23, "context": "Several recently proposed methods consider the data-fit term separately from the regularization term (Duchi et al., 2010; Xiao, 2010; Langford et al., 2009).", "startOffset": 101, "endOffset": 156}, {"referenceID": 13, "context": "Several recently proposed methods consider the data-fit term separately from the regularization term (Duchi et al., 2010; Xiao, 2010; Langford et al., 2009).", "startOffset": 101, "endOffset": 156}, {"referenceID": 8, "context": "For instance, consider Composite Objective Mirror Descent (COMD) (Duchi et al., 2010):", "startOffset": 65, "endOffset": 85}, {"referenceID": 8, "context": "Theorem 3 (Static regret for COMID (Duchi et al., 2010)).", "startOffset": 35, "endOffset": 55}, {"referenceID": 6, "context": "Unlike the bound in Theorem 3, tracking or shifting regret (Cesa-Bianchi & Lugosi, 2006; Cesa-Bianchi et al., 2012) bounds typically consider piecewise constant comparators, where \u03b8t \u2212 \u03b8t\u22121 = 0 for all but m values of t, where m is a constant, or yield regret bounds which scale with \u2211 t \u2016\u03b8t \u2212 \u03b8t\u22121\u2016.", "startOffset": 59, "endOffset": 115}, {"referenceID": 23, "context": "Rather than considering COMID, we might have used other online optimization algorithms, such as the Regularized Dual Averaging (RDA) method (Xiao, 2010), which has been shown to achieve similar performance with more regularized solutions.", "startOffset": 140, "endOffset": 152}, {"referenceID": 15, "context": "Recent results on the equivalence of COMID and RDA (McMahan, 2011) suggest that the bounds derived here might also hold for a variant of RDA, but proving this remains an open problem.", "startOffset": 51, "endOffset": 66}, {"referenceID": 6, "context": "Note that when \u03a6t corresponds to an identity operator, the bound in Theorem 4 corresponds to existing tracking or shifting regret bounds (Cesa-Bianchi & Lugosi, 2006; Cesa-Bianchi et al., 2012).", "startOffset": 137, "endOffset": 193}, {"referenceID": 25, "context": "This proof shares some ideas with the tracking regret bounds of (Zinkevich, 2003), but uses properties of the Bregman Divergence to eliminate some terms, while additionally incorporating dynamics.", "startOffset": 64, "endOffset": 81}, {"referenceID": 9, "context": "Other algorithms can accommodate larger classes of experts, or not assume knowledge of the number of switches, but come at the price of higher regret or complexity as explained in (Gyorgy et al., 2012).", "startOffset": 180, "endOffset": 201}, {"referenceID": 7, "context": "This model coincides with several compressed sensing architectures (Duarte et al., 2008).", "startOffset": 67, "endOffset": 88}, {"referenceID": 20, "context": "Dynamical models have a rich history in the context of social network analysis (Snijders, 2001), but we are unaware of their application in the context of online learning algorithms.", "startOffset": 79, "endOffset": 95}, {"referenceID": 19, "context": "Following (Ravikumar et al., 2010), we form a loss function using a negative log Ising model pseudolikelihood to sidestep challenging issues associated with the partition function of the Ising model likelihood.", "startOffset": 10, "endOffset": 34}, {"referenceID": 20, "context": "We set \u03c8(\u03b8) = 1 2\u2016\u03b8\u2016 2 2 and use a dynamical model inspired by (Snijders, 2001), where if |\u03b8ac\u2217\u03b8bc\u2217 | > |\u03b8ab|, with c\u2217 =arg maxc |\u03b8ac\u03b8bc|, then:", "startOffset": 63, "endOffset": 79}, {"referenceID": 13, "context": "As in (Langford et al., 2009), we find that regularizing (e.", "startOffset": 6, "endOffset": 29}], "year": 2013, "abstractText": "This paper describes a new online convex optimization method which incorporates a family of candidate dynamical models and establishes novel tracking regret bounds that scale with the comparator\u2019s deviation from the best dynamical model in this family. Previous online optimization methods are designed to have a total accumulated loss comparable to that of the best comparator sequence, and existing tracking or shifting regret bounds scale with the overall variation of the comparator sequence. In many practical scenarios, however, the environment is nonstationary and comparator sequences with small variation are quite weak, resulting in large losses. The proposed Dynamic Mirror Descent method, in contrast, can yield low regret relative to highly variable comparator sequences by both tracking the best dynamical model and forming predictions based on that model. This concept is demonstrated empirically in the context of sequential compressive observations of a dynamic scene and tracking a dynamic social network.", "creator": "LaTeX with hyperref package"}}}