{"id": "1301.1392", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jan-2013", "title": "Answer Set Programming for Stream Reasoning", "abstract": "The crucial of Internet and Sensor tool has own just new pose evoked before both phenomenon similar frequency accurate portions. Beyond pressure data processing, application outside anything ambient helped living, robotics, ; dynamic sorts relating complex explain providing. We discussion although scenarios and lavish being approaches to knowledge - relentless stream validity, information then Answer Set Programming (ASP ). While influences ASP approach are methods there suffix be obstacles, all develop only techniques soon pave and continue reasons dealing others expand as ones new adv08 comparison began a enhances way.", "histories": [["v1", "Tue, 8 Jan 2013 02:29:44 GMT  (40kb,D)", "http://arxiv.org/abs/1301.1392v1", "Proceedings of Answer Set Programming and Other Computing Paradigms (ASPOCP 2012), 5th International Workshop, September 4, 2012, Budapest, Hungary"]], "COMMENTS": "Proceedings of Answer Set Programming and Other Computing Paradigms (ASPOCP 2012), 5th International Workshop, September 4, 2012, Budapest, Hungary", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["martin gebser", "torsten grote", "roland kaminski", "philipp obermeier", "orkunt sabuncu", "torsten schaub"], "accepted": false, "id": "1301.1392"}, "pdf": {"name": "1301.1392.pdf", "metadata": {"source": "CRF", "title": "Answer Set Programming for Stream Reasoning", "authors": ["M. Gebser", "T. Grote", "R. Kaminski", "P. Obermeier", "T. Schaub"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "The advance of Internet and Sensor technology has brought about new challenges evoked by the emergence of continuous data streams, like web logs, mobile locations, or online measurements. While existing data stream management systems [4] allow for high-throughput stream processing, they lack complex reasoning capacities [5]. We address this shortcoming and elaborate upon approaches to knowledge-intense stream reasoning, based on Answer Set Programming (ASP; [6]) as a prime tool for Knowledge Representation and Reasoning (KRR; [7]). The emphasis thus shifts from rapid data processing towards complex reasoning, as required in application areas like ambient assisted living, robotics, or dynamic scheduling.\nIn contrast to traditional ASP methods, which are devised for singular problem solving, \u201cstream reasoning, instead, restricts processing to a certain window of concern, focusing on a subset of recent statements in the stream, while ignoring previous statements\u201d [8]. To accommodate this in ASP, we develop new techniques to formulate and process problems dealing with emerging as well as expiring data in a seamless way. Our modeling approaches rely on the novel concept of time-decaying logic programs [1], where logic program parts are associated with life spans to steer their emergence as well as expiration upon continuous reasoning. Time-decaying logic programs are implemented as a recent extension of the reactive ASP system oclingo [9], using the ASP grounder gringo [10] for the recurrent composition of a static \u201coffline\u201d encoding with dynamic \u201conline\u201d data into queries to the ASP solver clasp [11].\nWhile oclingo makes powerful ASP technology accessible for stream reasoning, its continuous query formulation and processing impose particular modeling challenges.\n? This paper complements a short KR\u201912 paper [1]; an extended draft [2] is available at [3]. ?? Affiliated with Simon Fraser University, Canada, and Griffith University, Australia.\nar X\niv :1\n30 1.\n13 92\nv1 [\ncs .A\nI] 8\nJ an\n2 01\n3\nFirst, re-grounding parts of an encoding wrt. new data shall be as economical as possible. Second, traditional modeling techniques, eg. frame axioms [12], need to be reconsidered in view of the expiration of obsolete program parts. Third, the re-use of propositional atoms and rules shall be extensive to benefit from conflict-driven learning (cf. [13]). We here tackle such issues in continuous reasoning over data from a sliding window [4]. In a nutshell, we propose to encode knowledge about any potential window contents offline, so that dynamic logic program parts can concentrate on activating readily available rules (via transient online data). Moreover, we show how default conclusions, eg. expressed by frame axioms, can be faithfully combined with transient data.\nAfter providing the necessary background, we demonstrate modeling approaches on three toy domains. The underlying principles are, however, of general applicability and thus establish universal patterns for ASP-based reasoning over sliding windows.3"}, {"heading": "2 Background", "text": "We presuppose familiarity with (traditional) ASP input languages (cf. [14,15]) and (extended) logic programs (cf. [16,6]). They provide the basis of incremental logic programs [17], where additional keywords, \u201c#base,\u201d \u201c#cumulative,\u201d and \u201c#volatile,\u201d allow for partitioning rules into a static, an accumulating, and a transient program part. The latter two usually refer to some constant t, standing for a step number. In fact, when gradually increasing the step number, starting from 1, ground instances of rules in a #cumulative block are successively generated and joined with ground rules from previous steps, whereas a #volatile block contributes instances of its rules for the current step only. Unlike accumulating and transient program parts, which are re-processed at each incremental step, the static part indicated by #base is instantiated just once, initially, so that its rules correspond to a \u201c0th\u201d #cumulative block.\nApplication areas of incremental logic programs include planning (cf. [18]) and finite model finding (cf. [19]). For instance, (a variant of) the well-known Yale shooting problem (cf. [20]) can be modeled by an incremental logic program as follows: #base. { loaded }. live(0). #cumulative t. { shoot(t+1) }. ab(t) :- shoot(t), loaded.\nlive(t) :- live(t-1), not ab(t). #volatile t. :- live(t). :- shoot(t+1).\nThe first answer set, containing loaded, live(0), live(1), shoot(2), and ab(2), is generated from the following ground rules at step 2: % #base. { loaded }. live(0).\n3 For formal details on time-decaying logic programs and a discussion of related work in stream processing, we refer the interested reader to [1,2].\n% #cumulative 1. % #cumulative 2. { shoot(2) }. { shoot(3) }. ab(1) :- shoot(1), loaded. ab(2) :- shoot(2), loaded. live(1) :- live(0), not ab(1). live(2) :- live(1), not ab(2). % #volatile 2. :- live(2). :- shoot(3).\nObserve that the static #base part is augmented with rules from the #cumulative block for step 1 and 2, whereas #volatile rules are included for step 2 only.\nThe reactive ASP system oclingo extends offline incremental logic programs by functionalities to incorporate external online information from a controller, also distinguishing accumulating and transient external inputs. For example, consider a character stream over alphabet {a, b} along with the task of continuously checking whether a stream prefix at hand matches regular expression (a|b)\u2217aa. To provide the stream prefix aab, the controller component of oclingo can successively pass facts as follows: #step 1. read(a,1). #step 2. read(a,2). #step 3. read(b,3).\nThe number i in \u201c#step i.\u201d directives informs oclingo about the minimum step number up to which an underlying offline encoding must be instantiated in order to incorporate external information (given after a #step directive) in a meaningful way. In fact, the following offline encoding builds on the assumption that values i in atoms of the form read(a,i) or read(b,i) are aligned with characters\u2019 stream positions:\n#iinit 0. #cumulative t. #external read(a,t+1). #external read(b,t+1). accept(t) :- read(a,t), read(a,t-1), not read(a;b,t+1).\nThe (undefined) atoms appearing after the keyword \u201c#external\u201d are declared as inputs to #cumulative blocks; that is, they are protected from program simplifications until they become defined (by external rules from the controller). Observe that any instance of the predicate read/2 is defined externally. In particular, future inputs that can be provided at (schematic) step t+1 are used to cancel an obsolete rule defining accept(t), once it does no longer refer to the last position of a stream prefix. Given that inputs are expected from step 1 = t+1 on, the directive \u201c#iinit 0.\u201d specifies t = 0 as starting value to instantiate #cumulative blocks for, so that read(a,1) and read(b,1) are initially declared as external inputs. In view of this, the answer set obtained for stream prefix aa at step 2 includes accept(2) (generated via \u201caccept(2) :- read(a,2), read(a,1), not read(a,3), not read(b,3).\u201d), while accept(3) does not belong to the answer set for aab at step 3. Note that acceptance at different stream positions is indicated by distinct instances of accept/1; this is important to comply with modularity conditions (cf. [1,2]) presupposed by oclingo, which essentially object to the (re)definition of (ground) head atoms at different steps.\nAlthough the presented reactive ASP encoding correctly accepts stream prefixes matching (a|b)\u2217aa, the fact that external instances of read/2 are accumulated over time is a major handicap, incurring memory pollution upon running oclingo for a (quasi)\nunlimited number of steps.4 To circumvent this, external inputs could be made transient, as in the following alternative sequence of facts from oclingo\u2019s controller component: #step 1. #volatile. read(a,1,1). #step 2. #volatile. read(a,1,2). read(a,2,2). #step 3. #volatile. read(a,2,3). read(b,3,3). Note that the first two readings, represented by read(a,1,1) and read(a,2,2) as well as read(a,1,2) and read(a,2,3), are provided by facts twice, where the respective (last) stream position is included as additional argument to avoid redefinitions. In view of this, the previous offline encoding could be replaced by the following one: #cumulative t. #external read(a,t-1;t,t). #external read(b,t-1;t,t). accept(t) :- read(a,t-1,t), read(a,t,t). While the automatic expiration of transient inputs after each inquiry from the controller (along with the possible use of \u201c#forget i.\u201d directives) omits a blow-up in space as well as an explicit cancelation of outdated rules, it leads to the new problem that the whole window contents (two readings in this case) must be passed in each inquiry from the controller. This delegates the bookkeeping of sliding window contents to the controller, which then works around limitations of reactive ASP as introduced in [9].\nArguably, neither accumulating inputs (that are no longer inspected) over time nor replaying window contents (the width of the window many times) is acceptable in performing continuous ASP-based stream reasoning. To overcome the preexisting limitations, we introduced time-decaying logic programs [1] that allow for associating arbitrary life spans (rather than just 1) with transient program parts. Such life spans are given by integers l in directives of the form \u201c#volatile : l.\u201d (for online data) or \u201c#volatile t : l.\u201d (for offline encoding parts). With our example, stream readings can now be conveniently passed in #volatile blocks of life span 2 as follows: #step 1. #volatile : 2. read(a,1). #step 2. #volatile : 2. read(a,2). #step 3. #volatile : 2. read(b,3). In view of automatic expiration in two steps (eg. at step 3 for read(a,1) provided at step 1), the following stripped-down offline encoding correctly handles stream prefixes:\n#cumulative t. #external read(a,t). #external read(b,t). accept(t) :- read(a,t-1), read(a,t).\nNote that the embedding of encoding rules in a #cumulative block builds on automatic rule simplifications relative to expired inputs. As an (equivalent) alternative, one could use \u201c#volatile t : 2.\u201d to discard outdated rules via internal assumption literals (cf. [17]). However, we next investigate more adept uses of blocks for offline rules."}, {"heading": "3 Modeling and Reasoning", "text": "The case studies provided below aim at illustrating particular features in modeling and reasoning with time-decaying logic programs and stream data. For the sake of clarity,\n4 Disposal of elapsed input atoms that are yet undefined, such as read(b,1), read(b,2), and read(a,3) wrt. stream prefix aab, can be accomplished via \u201c#forget i.\u201d directives. Ground rules mentioning such atoms are in turn \u201cautomatically\u201d simplified by clasp (cf. [17]).\nListing 1. Stream of user accesses with life span of 3 steps 1 #step 1. #volatile : 3. 2 access(alice,granted,1). 3 #step 2. #volatile : 3. 4 access(alice,denied,3). 5 access(bob,denied,3). 6 #step 3. #volatile : 3. 7 access(alice,denied,2). 8 access(claude,granted,5). 9 #step 4. #volatile : 3.\n10 access(bob,denied,2). access(bob,denied,4). 11 access(claude,denied,2). 12 #step 5. #volatile : 3. 13 access(alice,denied,4). 14 access(claude,denied,3). access(claude,denied,4). 15 #step 6. #volatile : 3. 16 access(alice,denied,6). 17 #step 7. #volatile : 3. 18 access(alice,denied,8). 19 #step 8. #volatile : 3. 20 access(alice,denied,7).\nwe concentrate on toy domains rather than any actual target application. We begin with modelings of the simple task to monitor consecutive user accesses, proceed with an overtaking scenario utilizing frame axioms, and then turn to the combinatorial problem of online job scheduling; the corresponding encodings can be downloaded at [3]."}, {"heading": "3.1 Access Control", "text": "Our first scenario considers users attempting to access some service, for instance, by logging in via a website. Access attempts can be denied or granted, eg. depending on the supplied password, and a user account is (temporarily) closed in case of three access denials in a row. A stream segment of access attempts is shown in Listing 1. It provides data about three users, alice, bob, and claude. As specified by \u201c#volatile : 3.\u201d (for each step), the life span of access data is limited to three incremental steps (which may be correlated to some period of real time), aiming at an (automatic) reopening of closed user accounts after some waiting period has elapsed. We further assume that time stamps in the third argument of facts over access/3 deviate from i in \u201c#step i.\u201d by at most 2; that is, the terms used in transient facts are coupled to the step number (in an underlying incremental logic program). Given the segment in Listing 1, the following table summarizes non-expired logged accesses per step, where granted accesses are enclosed in brackets and sequences of three consecutive denials are underlined:\ni 1 2 3 4 5 6 7 8\nalice [1] [1] 3 [1] 2 3 2 3 2 4 4 6 4 6 8 6 7 8 bob 3 3 2 3 4 2 4 2 4\nclaude [5] 2 [5] 2 3 4 [5] 2 3 4 3 4 For instance, observe that the three denied accesses by bob logged in the second and fourth step are consecutive in view of the time stamps 3, 2, and 4 provided as argument values, eg. in access(bob,denied,3) expiring at step 5.\nListing 2. Cumulative access control encoding 1 #const window=3. #const offset=2. #const denial=3. #iinit 1-offset.\n3 #base. 4 user(bob;alice;claude). % some users 5 signal(denied;granted). % some signals 6 { account(U,closed) : user(U) }. 7 account(U,open) :- user(U), not account(U,closed).\n9 #cumulative t. 10 #external access(U,S,t+offset) : user(U) : signal(S). 11 denied(U,1, t) :- access(U,denied,t+offset). 12 denied(U,N+1, t) :- access(U,denied,t+offset), 13 denied(U,N,t-1), N < denial. 14 denied(U,denial,t) :- denied(U,denial,t-1). 15 :- denied(U,denial,t), not account(U,closed).\n17 #volatile t. 18 :- account(U,closed), not denied(U,denial,t).\nOur first offline encoding is shown in Listing 2. To keep the sliding window width, matching the life span of stream transients, adjustable, the constant window is introduced in Line 1 (and set to default value 3). Similarly, the maximum deviation of time stamps from incremental step numbers and the threshold of consecutive denied accesses at which an account is closed are represented by the constants offset and denial. After introducing the three users and the possible outcomes of their access attempts via facts, the static #base part includes in Line 6 a choice rule on whether the status of a user account is closed, while it remains open otherwise. In fact, the dynamic parts of the incremental program solve the task to identify the current status of the account of a user U and represent it by including either account(U,closed) or account(U,open) in an answer set, yet without redefining account/2 over steps. This makes sure that stepwise (ground) incremental program parts are modularly composable (cf. [1,2]), which is required for meaningful closed-world reasoning by oclingo in reactive settings.\nThe encoding in Listing 2 (mainly) relies on accumulating rules given below \u201c#cumulative t.\u201d (in Line 9), resembling incremental planning encodings (cf. [17]) based on a history of actions. In order to react to external inputs, the #external directive in Line 10 declares (undefined) atoms as inputs that can be provided by the environment, ie. the controller component of oclingo. Note that instances of access/3 with time stamp t+offset (where offset is the maximum deviation from t) are introduced at incremental step t; in this way, ground rules are prepared for shifted access data arriving early. The rules in Line 11\u201313 implement the counting of consecutive denied access attempts per user, up to the threshold given by denial; if this threshold is reached (wrt. non-expired access data), the account of the respective user is temporarily closed. The \u201cpositive\u201d conclusion from denial many denied access attempts to closing an account is encoded via the integrity constraint in Line 15, while more care is needed in concluding the opposite: the right decision whether to leave an account open can be made only after inspecting the whole window contents. To this end, the rule in Line 14 passes information about the threshold being reached on to later steps, and the query\nin Line 18, refuting an account to be closed if there were no three consecutive denied access attempts, is included only for the (currently) last incremental step.\nFor the stream segment in Listing 1, in the fourth incremental step, we have that denied(bob,3,4) is derived in view of (transient) facts access(bob,denied,3), access(bob,denied,2), and access(bob,denied,4). Due to the integrity constraint in Line 15 of Listing 2, this enforces account(bob,closed) to hold. Since access(bob,denied,3) expires at step 5, we can then no longer derive denied(bob,3,4), and denied(bob,3,5) does not hold either; the query in Line 18 thus enforces account(bob,closed) to be false in the fifth incremental step. Similarly, we have that account(claude,closed) or account(alice,closed) hold at step 5, 6, and 8, respectively, but are enforced to be false at any other step. As one may have noticed, given the values of constants in Listing 2, the consideration of atoms over access/3 starts at t+offset = 3 for t = 1. To still initialize the first (two) windows wrt. the \u201cpast,\u201d an #iinit directive is provided in Line 1. By using 1-offset = \u22121 as starting value for t, once the first external inputs are processed, ground rules treating access data with time stamps 1, 2, and 3 are readily available, which is exactly the range admitted at the first step. Moreover, at a step like 6, the range of admissible time stamps starts at 4, and it increases at later steps; that is, inputs with time stamp 3, declared at step 1, are not anymore supposed to occur in stream data. To enable program simplifications by fixing such atoms to false, online data can be accompanied by \u201c#forget i.\u201d directives, and they are utilized in practice to dispose of elapsed input atoms (cf. [3]).\nIn addition to the cumulative encoding in Listing 2, we also devised a volatile variant (cf. extended draft [2]) in which outdated rules expire along with stream data. Both the cumulative and the volatile encoding have the drawback that the knowledge-intensive logic program part is (gradually) replaced at each step. While this is tolerable in the simple access scenario, for more complex problems, it means that the internal problem representation of a solving component like clasp changes significantly upon processing stream data, so that a potential re-use of learned constraints is limited. In order to reinforce conflict-driven learning, we next demonstrate a modeling approach allowing for the preservation of a static problem representation in view of fixed window capacity.\nAt the beginning (up to Line 5), our static access control encoding, shown in Listing 3, is similar to the cumulative approach (Listing 2), while the #base part is significantly extended in the sequel. In fact, the constant modulo, calculated in Line 6, takes into account that at most window many consecutive online inputs are jointly available (preceding ones are expired) and that terms representing time stamps may deviate by up to offset (both positively and negatively) from incremental step numbers. Given this, window+2\u2217offset slots are sufficient to accommodate all distinct time stamps provided as argument values in instances of access/3 belonging to a window, and one additional slot is added in Line 6 as separator between the largest and the smallest (possibly) referenced time stamp. The available slots are then arranged in a cycle (via modulo arithmetic) in Line 7, and the counting of denied access attempts per user, implemented in Line 9\u201311, traverses consecutive slots according to instances of the predicate next/2. Importantly, counting does not rely on transient external inputs, ie. access/3, but instead refers to instances of baseaccess/3, provided by the choice rule in Line 8; in\nListing 3. Static access control encoding 6 #const modulo=window+2*offset+1. #iinit 2-modulo. 7 next(T,(T+1) #mod modulo) :- T := 0..modulo-1. 8 { baseaccess(U,denied,T) : user(U) : next(T,_) }. 9 denied(U,1, T) :- baseaccess(U,denied,T).\n10 denied(U,N+1,S) :- baseaccess(U,denied,S), next(T,S), 11 denied(U,N,T), N < denial. 12 account(U,closed) :- denied(U,denial,T). 13 account(U,open) :- user(U), not account(U,closed).\n15 #cumulative t. 16 #external access(U,S,t+offset) : user(U) : signal(S). 17 :- access(U,denied,T), T := t+offset, 18 not baseaccess(U,denied,T #mod modulo).\n20 #volatile t : modulo. 21 :- baseaccess(U,denied,(T+modulo) #mod modulo), 22 not access(U,denied,T), T := t+offset.\nthis way, the atoms and rules in the #base program part can be re-used in determining the status of user accounts wrt. transient access data from a stream.\nTo get decisions on closing accounts right (via the rules in Line 12\u201313), synchronization between instances of baseaccess/3 and (transient) facts over access/3 is implemented in the #cumulative and #volatile parts in Listing 3. Beyond declaring inputs in the same way as before (cf. Line 10 in Listing 2), for any non-expired online input of the form access(U,denied,t+offset), the integrity constraint in Line 17\u201318 enforces the corresponding instance of baseaccess/3, calculated via \u201c(t+offset) #mod modulo,\u201d to hold. Note that this constraint does not need to be expired explicitly (yet it could be moved to the #volatile block below) because elapsed input atoms render it ineffective anyway. However, the integrity constraint in Line 21\u201322, enforcing baseaccess/3 counterparts of non-provided facts of the form access(U,denied,t+offset) to be false, must be discharged once the sliding window progresses (by modulo many steps). For instance, when offset = 2 and modulo = 8, input atoms of the form access(U,denied,3), introduced at the first step, map to baseaccess(U,denied,3), and the same applies to instances of access(U,denied,11), becoming available at the ninth incremental step. Since the smallest time stamp that can be mentioned by non-expired inputs at the ninth step is 5 (inputs given before step 7 are expired), the transition of integrity constraints (mapping time stamp 11 instead of 3 to slot 3) is transparent. In addition, as expired inputs with time stamp 4 enforce atoms of the form baseaccess(U,denied,4) to be false (via the integrity constraint in Line 21\u201322 instantiated for step 2), denial counting in Line 9\u2013 11 stops at atoms baseaccess(U,denied,3), representing latest stream data at the ninth step. Hence, denial many consecutive instances of baseaccess(U,denied,T), needed to close the account of a user U, correspond to respective facts over access/3 in the current window. Finally, to avoid initial guesses over baseaccess/3 wrt. (nonexisting) denied accesses lying in the past, \u201c#iinit 2-modulo.\u201d is included in Line 6. Then, instances of baseaccess/3 for (positive) values \u201c(T+modulo) #mod modulo,\u201d calculated in Line 21, are (temporarily) enforced to be false when they match access/3 instances with non-positive time stamps."}, {"heading": "3.2 Overtaking Maneuver Recognition", "text": "Our second scenario deals with recognizing the completion of overtaking maneuvers by a car, eg. for signaling it to the driver. The recognition follows the transitions of the automaton in Figure 1.5 Starting from state \u2205, representing that a maneuver has not yet been initiated, sensor information about being \u201cbehind,\u201d \u201cnextto,\u201d or \u201cinfront\u201d of another car enables transitions to corresponding states B, N , and F . As indicated by the output \u201cOT!\u201d in F , an overtaking maneuver is completed when F is reached from \u2205 via a sequence of \u201cbehind,\u201d \u201cnextto,\u201d and \u201cinfront\u201d signals. Additional \u03b5 transitions model the progression from one time point to the next in the absence of signals: while such transitions are neutral in states \u2205, B, and N , the final state F is abandoned (after outputting \u201cOT!\u201d). For instance, the automaton in Figure 1 admits the following trajectory (indicating a state at time point i by \u201c@i\u201d and providing signals in-between states):\n(\u2205@0, behind, B@1, \u03b5, B@2, nextto, N@3, infront, F@4, \u03b5, \u2205@5, nextto,\u2205@6, behind, B@7, nextto, N@8, \u03b5,N@9).\nHere, an overtaking maneuver is completed when F is reached at time 4, and \u03b5 transitions preserveB andN , but not F . In the following, we consider overtaking maneuvers that are completed in at most 6 steps; that is, for a given time point i, the automaton in Figure 1 is assumed to start from \u2205 at time i\u22126.\nSimilar to the static access control encoding in Listing 3, our encoding of overtaking maneuver recognition, shown in Listing 4, uses modulo arithmetic to map time stamps in stream data to a corresponding slot of atoms and rules provided in the #base program part. In more detail, transient (external) facts of the form at(P,C,T) (in which P is behind, nextto, or infront and C refers to a red, blue, or green car) are matched with corresponding instances of baseat/3 by means of the #cumulative and #volatile parts in Line 20\u201324. As before, these parts implement a transparent shift from steps i to i+modulo, provided that transient stream data is given in\n5 Unlike in this simple example scenario, transition systems are usually described compactly in terms of state variables and operators on them, eg. defined via action languages (cf. [21]). The automaton induced by a compact description can be of exponential size, and an explicit representation like in Figure 1 is often inaccessible in practice.\nListing 4. Static overtaking maneuver recognition encoding 1 #const modulo=6. #iinit 2-modulo. 2 #base. 3 position(behind;nextto;infront). % relative positions 4 car(red;blue;green). % some cars 5 time(0..modulo-1). % time slots\n7 next(T,(T+1) #mod modulo) :- time(T), not now(T). 8 { now(T) : time(T) } 1. 9 { baseat(P,C,T) : position(P) : car(C) : time(T) }.\n10 baseat(C,T) :- baseat(_,C,T).\n12 state(behind, C,T) :- baseat(behind,C,T). 13 state(nextto, C,S) :- baseat(nextto,C,S), next(T,S), 14 1 { state(behind,C,T), state(nextto,C,T) }. 15 state(infront,C,S) :- baseat(infront,C,S), now(S), 16 next(T,S), state(nextto,C,T). 17 state(P, C,S) :- state(P,C,T), P != infront, 18 next(T,S), not baseat(C,S).\n20 #cumulative t. 21 #external at(P,C,t) : position(P) : car(C). 22 :- at(P,C,t), not baseat(P,C,t #mod modulo). 23 #volatile t : modulo. 24 :- baseat(P,C,(t+modulo) #mod modulo), not at(P,C,t). 25 #volatile t. 26 :- not now(t #mod modulo).\n\u201c#volatile : modulo.\u201d blocks. Then, the rules in Line 12\u201316 model state transitions based on signals, and the one in Line 17\u201318 implements \u03b5 transitions (making use of projection in Line 10) as specified by the automaton in Figure 1. In particular, the completion of an overtaking maneuver in the current step, indicated by deriving infront as state for a car C and a time slot S via the rule in Line 15\u201316, relies on now(S) (explained below). Also note that state \u2205 is left implicit, ie. it applies to a car C and a slot T if baseat(P,C,T) does not hold for any relative position P, and that the frame axioms represented in Line 17\u201318 do not apply to infront states.\nWhile a next/2 predicate had also been defined in Listing 3 to arrange the time slots of the #base program in a cycle, the corresponding rule in Line 7 of Listing 4 relies on the absence of now(T) for linking a time slot T to \u201c(T+1) #mod modulo.\u201d In fact, instances of now/1 are provided by the choice rule in Line 8 and synchronized with the incremental step counter t via the integrity constraint \u201c:- not now(t #mod modulo).\u201d of life span 1 (cf. Line 25\u201326). Unlike the previous approach to access counting (introducing an empty slot), making the current time slot explicit enables the linearization of a time slot cycle also in the presence of frame axioms, which could propagate into the \u201cpast\u201d otherwise. In fact, if prerequisites regarding now/1 were dropped in Line 7 and 15, one could, beginning with at(behind,C,7) as input and its corresponding atom baseat(behind,C,1), derive state(infront,C,4) at step 7 for a car C subject to the trajectory given above. Such a conclusion is clearly unintended, and the technique in Line 7\u20138 and 25\u201326, using now/1 to linearize a time slot cycle, provides a general solution for this issue. Finally, \u201c#iinit 2-modulo.\u201d is again included in Line 1 to avoid initial guesses over baseat/3 wrt. (non-existing) past signals."}, {"heading": "3.3 Online Job Scheduling", "text": "After inspecting straightforward data evaluation tasks, we now turn to a combinatorial problem in which job requests of different durations must be scheduled to machines without overlapping one another. Unlike in offline job scheduling [22], where requests are known in advance, we here assume a stream of job requests, provided via (transient) facts job(I,M,D,T) such that I is a job ID, M is a machine, D is a duration, and T is the arrival time of a request. In addition, we assume a deadline T+max step, for some integer constant max step, by which the execution of a job I submitted at step T must be completed. For instance, an (initial) segment of a job request stream can be as follows: #step 1 : 0. #volatile : 21. job(1,1,1,1). job(2,1,5,1). job(3,1,5,1). job(4,1,5,1). job(5,1,5,1). #step 21 : 0. #volatile : 21. job(1,1,5,21). job(2,1,5,21). job(3,1,5,21). job(4,1,5,21).\nThat is, five jobs with ID 1 to 5 (of durations 1 and 5) are submitted at step 1 and ought to be completed on machine 1 within the deadline 1+max step = 21 (taking max step = 20). Four more jobs with ID 1 to 4 of duration 5, submitted at step 21, also need to be executed on machine 1. As a matter of fact, a schedule to finish all jobs within their deadlines must first launch the five jobs submitted at step 1, thus occupying machine 1 at time points up to 21, before the other jobs can use machine 1 from time point 22 to 41. However, when a time-decaying logic program does not admit any answer set at some step (ie. if there is no schedule meeting all deadlines), the default behavior of oclingo is to increase the incremental step counter until an answer set is obtained. This behavior would lead to the expiration of pending job requests, so that a schedule generated in turn lacks part of the submitted jobs. Since such (partial) schedules are unintended here, we take advantage of the enriched directive \u201c#step i : \u03b4.\u201d to express that increases of the step counter must not exceed i+\u03b4, regardless of whether an answer set has been obtained at step i+\u03b4 (or some greater step). In fact, since \u03b4 = 0 is used above, oclingo does not increase the step counter beyond i, but rather returns \u201cunsatisfiable\u201d as result if there is no answer set.\nIn Line 1\u20134, our (static) job scheduling encoding, shown in Listing 5, defines the viable durations, IDs of jobs requested per step, and the available machines in terms of corresponding constants. Furthermore, deadlines for the completion of jobs are obtained by adding max step (set to 20 in Line 2) to request submission times. As a consequence, jobs with submission times i \u2264 j such that j \u2264 i+max step may need to be scheduled jointly, and the minimum window width modulo required to accommodate the (maximum) completion times of jointly submitted jobs is calculated accordingly in Line 2. Given the value of modulo, the time slots of the #base program part are in Line 5 again arranged in a cycle (similar to access counting in Listing 3). The technique applied in Line 15\u201319 to map job requests given by transient (external) facts over job/4 to corresponding instances of basejob/4, provided by the choice rule in Line 7, remains the same as in previous static encodings (cf. Listing 3 and 4). But note that job IDs can be shared between jobs submitted at different steps, so that pairs (I,T) of an ID I and a slot T identify job requests uniquely in the sequel.\nThe rules in Line 8\u201313 of the #base program accomplish the non-overlapping scheduling of submitted jobs such that they are completed within their deadlines. In fact,\nListing 5. Static online job scheduling encoding 1 #const max duration = 5. #const max jobid = 5. #const num machines = 5. 2 #const max step = 20. #const modulo = 2*max step+1. #iinit 2-modulo. 3 #base. 4 duration(1..max duration). jobid(1..max jobid). machine(1..num machines). 5 next(T,(T+1) #mod modulo) :- T := 0..modulo-1.\n7 { basejob(I,M,D,T) : jobid(I) : machine(M) : duration(D) : next(T,_) }. 8 1 { jobstart(I,T,(T..T+max step+1-D) #mod modulo) } 1 :- basejob(I,_,D,T).\n10 occupy(M,I,T,D, S) :- basejob(I,M,D,T), jobstart(I,T,S). 11 occupy(M,I,T,D-1,S) :- occupy(M,I,T,D,R), next(R,S), D > 1. 12 occupy(M,I,T,S) :- occupy(M,I,T,_,S). 13 :- occupy(M,I1,T1,S), occupy(M,I2,T2,S), (I1,T1) < (I2,T2).\n15 #cumulative t. 16 #external job(I,M,D,t) : jobid(I) : machine(M) : duration(D). 17 :- job(I,M,D,t), not basejob(I,M,D,t #mod modulo). 18 #volatile t : modulo. 19 :- basejob(I,M,D,(t+modulo) #mod modulo), not job(I,M,D,t).\nthe choice rule in Line 8 expresses that a job of duration D with submission time slot T must be launched such that its execution finishes at slot \u201c(T+max step) #mod modulo\u201d (at the latest). Given the slots at which jobs are started, the rules in Line 10\u201312 propagate the occupation of machines M wrt. durations D, and the integrity constraint in Line 13 makes sure that the same machine is not occupied by distinct jobs at the same time slot. For instance, the following atoms of an answer set represent starting times such that the jobs requested in the stream segment given above do not overlap and are processed within their deadlines: jobstart(1,1,1) jobstart(2,1,2) jobstart(1,21,22) jobstart(3,1,7) jobstart(2,21,27) jobstart(4,1,12) jobstart(3,21,32) jobstart(5,1,17) jobstart(4,21,37)\nNote that the execution of the five jobs submitted at step 1 is finished at their common deadline 21, and the same applies wrt. the deadline 41 of jobs submitted at step 21. Since machine 1 is occupied at all time slots, executing all jobs within their deadlines would no longer be feasible if a job request like job(5,1,1,21) were added. In such a case, oclingo outputs \u201cunsatisfiable\u201d and waits for new online input, which may shift the window and relax the next query due to the expiration of some job requests.\nA future extension of oclingo regards optimization (via #minimize/#maximize) wrt. online data, given that solutions violating as few (soft) constraints as possible may be more helpful than just reporting unsatisfiability. In either mode of operation, the static representation of problems over a window of fixed width, illustrated in Listing 3, 4, and 5, enables the re-use of constraints learned upon solving a query for answering further queries asked later on.\nAlthough oclingo is still in a prototypical state, we performed some preliminary experiments in order to give an indication of the impact of different encoding variants. As the first two example scenarios model pure data evaluation tasks (not requiring search), experiments with them did not exhibit significant runtimes, and we thus focus on re-\nsults for online job scheduling. In particular, we assess oclingo on the static encoding in Listing 5 as well as a cumulative variant (analog to the cumulative access control encoding in Listing 2); we further consider the standard ASP system clingo, processing each query independently via relaunching wrt. the current window contents. Table 2(a) provides average runtimes of the investigated configurations in seconds, grouped by satisfiable (\u2205S) and unsatisfiable (\u2205U) queries, on 12 randomly generated data streams with 200 online inputs each. These streams vary in the values used for constants, eg. max jobid = 5, max duration = 3, num machines = 5, and max step = 15 with the three \u201c5x3x5 15 n\u201d streams, and the respective numbers of satisfiable (#S) and unsatisfiable (#U) queries. First of all, we observe that the current prototype version of oclingo cannot yet compete with clingo. The reason for this is that oclingo\u2019s underlying grounding and solving components were not designed with expiration in mind, so that they currently still remember the names of expired atoms (while irrelevant constraints referring to them are truly deleted). The resulting low-level overhead in each step explains the advantage of relaunching clingo from scratch. When comparing oclingo\u2019s performance wrt. encoding variants, the static encoding appears to be generally more effective than its cumulative counterpart, albeit some unsatisfiable queries stemming from the last three example streams in Table 2(a) are solved faster using the latter.\nThe plot in Figure 2(b) provides a more fine-grained picture by displaying runtimes for individual queries from stream \u201c5x3x5 15 1,\u201d where small bars on the x-axis indicate unsatisfiable queries. While the static encoding yields a greater setup time of oclingo at the very beginning, it afterwards dominates the cumulative encoding variant, which requires the instantiation and integration of rules unrolling the horizons of new job requests at each step. Unlike this, the static encoding merely maps input atoms to their representations in the #base part, thus also solving each query wrt. the same (static) set of atoms. As a consequence, after initial unsatisfiable queries (yielding spikes in all configurations\u2019 runtimes), oclingo with the static encoding is sometimes able to outperform clingo for successive queries remaining unsatisfiable. In fact, when the initial reasons for unsatisfiability remain in the window, follow-up queries are rather easy\ngiven the previously learned constraints, and we observed that some of these queries could actually be solved without any guessing."}, {"heading": "4 Discussion", "text": "We have devised novel modeling approaches for continuous stream reasoning based on ASP, utilizing time-decaying logic programs to capture sliding window data in a natural way. While such data is transient and subject to routine expiration, we provided techniques to encode knowledge about potential window contents statically. This reduces the dynamic tasks of re-grounding and integrating rules of an offline encoding in view of new data to matching inputs to a corresponding internal representation. As a consequence, reasoning also concentrates on a fixed propositional representation (whose parts are selectively activated wrt. actual window contents), which enables the re-use of constraints gathered by conflict-driven learning. Although we illustrated modeling principles, including an approach to propagate frame axioms along time slot cycles, on toy domains only, the basic ideas are of general applicability. This offers interesting prospects for implementing knowledge-intense forms of stream reasoning, as required in application areas like ambient assisted living, robotics, or dynamic scheduling.\nOur approach to ASP-based stream reasoning is prototypically implemented as an extension of the reactive ASP system oclingo, and preliminary experiments clearly show the need of improved low-level support of data expiration. In fact, we plan to combine the process of redesigning oclingo with the addition of yet missing functionalities, such as optimization in incremental and reactive settings. Future work also regards the consolidation of existing and the addition of further directives to steer incremental grounding and solving. For instance, beyond step-wise #cumulative and #volatile directives, we envisage #assert and #retract statements, as offered by Prolog (cf. [23]), to selectively (de)activate logic program parts. As with traditional ASP methods, the objective of future extensions is to combine high-level declarative modeling with powerful reasoning technology, automating both grounding and search. The investigation of sliding window scenarios performed here provides a first step towards gearing ASP to continuous reasoning tasks. Presupposing appropriate technology support, we think that many dynamic domains may benefit from ASP-based reasoning.\nAcknowledgments We are grateful to the anonymous referees for helpful comments. This work was partially funded by the German Science Foundation (DFG) under grant SCHA 550/8-1/2 and by the European Commission within EasyReach (www. easyreach-project.eu) under grant AAL-2009-2-117."}], "references": [{"title": "Stream reasoning with answer set programming: Preliminary report", "author": ["M. Gebser", "T. Grote", "R. Kaminski", "P. Obermeier", "O. Sabuncu", "T. Schaub"], "venue": "In Eiter, T., McIlraith, S., eds.: Proceedings of the Thirteenth International Conference on Principles of Knowledge Representation and Reasoning (KR\u201912), AAAI Press", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Stream reasoning with answer set programming: Extended version", "author": ["M. Gebser", "T. Grote", "R. Kaminski", "P. Obermeier", "O. Sabuncu", "T. Schaub"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Data Stream Management", "author": ["L. Golab", "M. \u00d6zsu"], "venue": "Synthesis Lectures on Data Management, Morgan and Claypool Publishers", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "It\u2019s a streaming world! reasoning upon rapidly changing information", "author": ["E. Della Valle", "S. Ceri", "F. van Harmelen", "D. Fensel"], "venue": "IEEE Intelligent Systems 24(6)", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Knowledge Representation, Reasoning and Declarative Problem Solving", "author": ["C. Baral"], "venue": "Cambridge University Press", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2003}, {"title": "Handbook of Knowledge Representation", "author": ["V. Lifschitz", "F. van Harmelen", "B. Porter", "eds."], "venue": "Elsevier Science", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Deductive and inductive stream reasoning for semantic social media analytics", "author": ["D. Barbieri", "D. Braga", "S. Ceri", "E. Della Valle", "Y. Huang", "V. Tresp", "A. Rettinger", "H. Wermser"], "venue": "IEEE Intelligent Systems 25(6)", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Conflict-driven answer set solving", "author": ["M. Gebser", "B. Kaufmann", "A. Neumann", "T. Schaub"], "venue": "In Veloso, M., ed.: Proceedings of the Twentieth International Joint Conference on Artificial Intelligence (IJCAI\u201907), AAAI Press/MIT Press", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "Answer set programming and plan generation", "author": ["V. Lifschitz"], "venue": "Artificial Intelligence 138(1-2)", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2002}, {"title": "Handbook of Satisfiability", "author": ["A. Biere", "M. Heule", "H. van Maaren", "T. Walsh", "eds."], "venue": "Volume 185 of Frontiers in Artificial Intelligence and Applications, IOS Press", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Extending and implementing the stable model semantics", "author": ["P. Simons", "I. Niemel\u00e4", "T. Soininen"], "venue": "Artificial Intelligence 138(1-2)", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2002}, {"title": "Engineering an incremental ASP solver", "author": ["M. Gebser", "R. Kaminski", "B. Kaufmann", "M. Ostrowski", "T. Schaub", "S. Thiele"], "venue": "In Garcia de la Banda, M., Pontelli, E., eds.: Proceedings of the Twenty-fourth International Conference on Logic Programming (ICLP\u201908). Volume 5366 of Lecture Notes in Computer Science, Springer-Verlag", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2008}, {"title": "Automated Planning: Theory and Practice", "author": ["D. Nau", "M. Ghallab", "P. Traverso"], "venue": "Morgan Kaufmann Publishers", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2004}, {"title": "An incremental answer set programming based system for finite model computation", "author": ["M. Gebser", "O. Sabuncu", "T. Schaub"], "venue": "AI Communications 24(2)", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2011}, {"title": "A simple solution to the Yale shooting problem", "author": ["A. Baker"], "venue": "In Brachman, R., Levesque, H., Reiter, R., eds.: Proceedings of the First International Conference on Principles of Knowledge Representation and Reasoning (KR\u201989), Morgan Kaufmann Publishers", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1989}, {"title": "Nonmonotonic causal theories", "author": ["E. Giunchiglia", "J. Lee", "V. Lifschitz", "N. McCain", "H. Turner"], "venue": "Artificial Intelligence 153(1-2)", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2004}, {"title": "Scheduling Algorithms", "author": ["P. Brucker"], "venue": "Springer-Verlag", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2007}, {"title": "Algorithm = logic + control", "author": ["R. Kowalski"], "venue": "Communications of the ACM 22(7)", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1979}, {"title": "Proceedings of the Eleventh International Conference on Logic Programming and Nonmonotonic Reasoning (LPNMR\u201911)", "author": ["J. Delgrande", "W. Faber", "eds."], "venue": "Volume 6645 of Lecture Notes in Artificial Intelligence, Springer-Verlag", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 2, "context": "While existing data stream management systems [4] allow for high-throughput stream processing, they lack complex reasoning capacities [5].", "startOffset": 46, "endOffset": 49}, {"referenceID": 3, "context": "While existing data stream management systems [4] allow for high-throughput stream processing, they lack complex reasoning capacities [5].", "startOffset": 134, "endOffset": 137}, {"referenceID": 4, "context": "We address this shortcoming and elaborate upon approaches to knowledge-intense stream reasoning, based on Answer Set Programming (ASP; [6]) as a prime tool for Knowledge Representation and Reasoning (KRR; [7]).", "startOffset": 135, "endOffset": 138}, {"referenceID": 5, "context": "We address this shortcoming and elaborate upon approaches to knowledge-intense stream reasoning, based on Answer Set Programming (ASP; [6]) as a prime tool for Knowledge Representation and Reasoning (KRR; [7]).", "startOffset": 205, "endOffset": 208}, {"referenceID": 6, "context": "In contrast to traditional ASP methods, which are devised for singular problem solving, \u201cstream reasoning, instead, restricts processing to a certain window of concern, focusing on a subset of recent statements in the stream, while ignoring previous statements\u201d [8].", "startOffset": 262, "endOffset": 265}, {"referenceID": 0, "context": "Our modeling approaches rely on the novel concept of time-decaying logic programs [1], where logic program parts are associated with life spans to steer their emergence as well as expiration upon continuous reasoning.", "startOffset": 82, "endOffset": 85}, {"referenceID": 7, "context": "Time-decaying logic programs are implemented as a recent extension of the reactive ASP system oclingo [9], using the ASP grounder gringo [10] for the recurrent composition of a static \u201coffline\u201d encoding with dynamic \u201conline\u201d data into queries to the ASP solver clasp [11].", "startOffset": 267, "endOffset": 271}, {"referenceID": 0, "context": "? This paper complements a short KR\u201912 paper [1]; an extended draft [2] is available at [3].", "startOffset": 45, "endOffset": 48}, {"referenceID": 1, "context": "? This paper complements a short KR\u201912 paper [1]; an extended draft [2] is available at [3].", "startOffset": 68, "endOffset": 71}, {"referenceID": 8, "context": "frame axioms [12], need to be reconsidered in view of the expiration of obsolete program parts.", "startOffset": 13, "endOffset": 17}, {"referenceID": 9, "context": "[13]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "We here tackle such issues in continuous reasoning over data from a sliding window [4].", "startOffset": 83, "endOffset": 86}, {"referenceID": 10, "context": "[16,6]).", "startOffset": 0, "endOffset": 6}, {"referenceID": 4, "context": "[16,6]).", "startOffset": 0, "endOffset": 6}, {"referenceID": 11, "context": "They provide the basis of incremental logic programs [17], where additional keywords, \u201c#base,\u201d \u201c#cumulative,\u201d and \u201c#volatile,\u201d allow for partitioning rules into a static, an accumulating, and a transient program part.", "startOffset": 53, "endOffset": 57}, {"referenceID": 12, "context": "[18]) and finite model finding (cf.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[19]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[20]) can be modeled by an incremental logic program as follows:", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "3 For formal details on time-decaying logic programs and a discussion of related work in stream processing, we refer the interested reader to [1,2].", "startOffset": 142, "endOffset": 147}, {"referenceID": 1, "context": "3 For formal details on time-decaying logic programs and a discussion of related work in stream processing, we refer the interested reader to [1,2].", "startOffset": 142, "endOffset": 147}, {"referenceID": 0, "context": "[1,2]) presupposed by oclingo, which essentially object to the (re)definition of (ground) head atoms at different steps.", "startOffset": 0, "endOffset": 5}, {"referenceID": 1, "context": "[1,2]) presupposed by oclingo, which essentially object to the (re)definition of (ground) head atoms at different steps.", "startOffset": 0, "endOffset": 5}, {"referenceID": 0, "context": "To overcome the preexisting limitations, we introduced time-decaying logic programs [1] that allow for associating arbitrary life spans (rather than just 1) with transient program parts.", "startOffset": 84, "endOffset": 87}, {"referenceID": 11, "context": "[17]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[17]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "alice [1] [1] 3 [1] 2 3 2 3 2 4 4 6 4 6 8 6 7 8", "startOffset": 6, "endOffset": 9}, {"referenceID": 0, "context": "alice [1] [1] 3 [1] 2 3 2 3 2 4 4 6 4 6 8 6 7 8", "startOffset": 10, "endOffset": 13}, {"referenceID": 0, "context": "alice [1] [1] 3 [1] 2 3 2 3 2 4 4 6 4 6 8 6 7 8", "startOffset": 16, "endOffset": 19}, {"referenceID": 3, "context": "claude [5] 2 [5] 2 3 4 [5] 2 3 4 3 4 For instance, observe that the three denied accesses by bob logged in the second and fourth step are consecutive in view of the time stamps 3, 2, and 4 provided as argument values, eg.", "startOffset": 7, "endOffset": 10}, {"referenceID": 3, "context": "claude [5] 2 [5] 2 3 4 [5] 2 3 4 3 4 For instance, observe that the three denied accesses by bob logged in the second and fourth step are consecutive in view of the time stamps 3, 2, and 4 provided as argument values, eg.", "startOffset": 13, "endOffset": 16}, {"referenceID": 3, "context": "claude [5] 2 [5] 2 3 4 [5] 2 3 4 3 4 For instance, observe that the three denied accesses by bob logged in the second and fourth step are consecutive in view of the time stamps 3, 2, and 4 provided as argument values, eg.", "startOffset": 23, "endOffset": 26}, {"referenceID": 0, "context": "[1,2]), which is required for meaningful closed-world reasoning by oclingo in reactive settings.", "startOffset": 0, "endOffset": 5}, {"referenceID": 1, "context": "[1,2]), which is required for meaningful closed-world reasoning by oclingo in reactive settings.", "startOffset": 0, "endOffset": 5}, {"referenceID": 11, "context": "[17]) based on a history of actions.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "extended draft [2]) in which outdated rules expire along with stream data.", "startOffset": 15, "endOffset": 18}, {"referenceID": 15, "context": "[21]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "Unlike in offline job scheduling [22], where requests are known in advance, we here assume a stream of job requests, provided via (transient) facts job(I,M,D,T) such that I is a job ID, M is a machine, D is a duration, and T is the arrival time of a request.", "startOffset": 33, "endOffset": 37}, {"referenceID": 17, "context": "[23]), to selectively (de)activate logic program parts.", "startOffset": 0, "endOffset": 4}], "year": 2013, "abstractText": "The advance of Internet and Sensor technology has brought about new challenges evoked by the emergence of continuous data streams. Beyond rapid data processing, application areas like ambient assisted living, robotics, or dynamic scheduling involve complex reasoning tasks. We address such scenarios and elaborate upon approaches to knowledge-intense stream reasoning, based on Answer Set Programming (ASP). While traditional ASP methods are devised for singular problem solving, we develop new techniques to formulate and process problems dealing with emerging as well as expiring data in a seamless way.", "creator": "LaTeX with hyperref package"}}}