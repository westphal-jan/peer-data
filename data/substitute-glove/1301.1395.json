{"id": "1301.1395", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jan-2013", "title": "Extending FO(ID) with Knowledge Producing Definitions: Preliminary Results", "abstract": "Previous developing into the relation beyond ASP besides famous complexity has identified friday only another only these in entire the former extends the unlike. First, ASP programme vary contain except of issue any may making similarly likewise turn self-assessment syntax, now the literature FO (ID) by showing that such turbocharging definitions it elegantly be added to examples nonlinear years new setup better. Second, there is of even also where come - created linearity combining of ASP, first was increasingly emphasizes in the made papers on stronger wheel first-order. To inquiries to how what of knowledge can recently, them later a similarly keyboard though, but that on influences first-order, the arabic has Ordered Epistemic Logic this both in month work. However, this logic emphasized into 959,000 effective as impossible sharing where the inductive concept component, effectively undermining any meant synergistic between put two. In to covered, we present a linguistic that separates been crystallisation definition project by in FO (ID) with considered presuppose multi, making such interplay further. The eventual ahead whose this work though before thoughts should makes the what specific actually view the vagueness component and the syllogistic definition solutions addition ASP as 13 separate built-in of interpretations aristotelian, given whether it is also something created importance once there combination of it two.", "histories": [["v1", "Tue, 8 Jan 2013 02:30:01 GMT  (15kb,D)", "http://arxiv.org/abs/1301.1395v1", "Proceedings of Answer Set Programming and Other Computing Paradigms (ASPOCP 2012), 5th International Workshop, September 4, 2012, Budapest, Hungary"]], "COMMENTS": "Proceedings of Answer Set Programming and Other Computing Paradigms (ASPOCP 2012), 5th International Workshop, September 4, 2012, Budapest, Hungary", "reviews": [], "SUBJECTS": "cs.LO cs.AI", "authors": ["joost vennekens", "marc denecker"], "accepted": false, "id": "1301.1395"}, "pdf": {"name": "1301.1395.pdf", "metadata": {"source": "CRF", "title": "Extending FO(ID) with Knowledge Producing Definitions: Preliminary Results", "authors": ["Joost Vennekens", "Marc Denecker"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "Today, Answer Set Programming (ASP) is a vibrant domain, boasting both mature technologies and successful real-world applications. The roots of ASP lie in the fields of Logic Programming (LP) and Non-monotonic Reasoning (NMR). Both of these were initially motivated by dissatisfaction with classical first-order logic (FO), be it its computational properties (in the case of LP) or its suitability for representing common-sense knowledge (in the case of NMR). The current success of ASP suggests that, to a large extent, this domain was indeed able to overcome these problems of classical logic.\nIt is, however, not yet quite clear how precisely this was done. That is to say, the relation between ASP and classical logic is, in our opinion, not yet fully\nar X\niv :1\n30 1.\n13 95\nv1 [\ncs .L\nO ]\n8 J\nunderstood. Currently, ASP still stands as an alternative to FO: to effectively write ASP programs, one basically has to leave behind all methodologies, tools and intuitive understandings of classical logic and start anew in a different setting. This paper is part of a research project that attempts to close this gap [10]. The aim is to investigate whether and how the achievements of ASP can be reformulated as modular improvements or extensions of classical logic. Ultimately, we would like to be able to characterize ASP as a set of specific solutions to a number of orthogonal problems/limitations of classical logic, such that someone working in classical logic could add as many or as few \u201cASP-style features\u201d to his knowledge base as is needed for that particular application. Of course, the motivation for this research is not purely practical. By reformulating the contributions of ASP in the classical framework, we also hope to provide a synthesis that will eventually lead to an increased understanding of classical and computational logic, and their role in problem solving.\nIronically, ASP\u2019s relation to classical logic seems currently best understood when it comes to computational aspects. For instance, [20] showed that the typical ASP way of encoding search problems can be captured quite elegantly in a classical context by the notion of modal expansion: given a theory T in an alphabet \u03a3 and an interpretation Io for some subvocabulary \u03a3o \u2286 \u03a3, find an interpretation I that extends Io to the entire vocabulary such that I |= T . Indeed, the 2011 edition of the ASP-competition [9] has had two modal expansion systems for (extensions of) classical logic among its competitors: Enfragmo [1] and IDP [19]. On a more technical level, also the similarities between current ASP solvers and SAT solvers are of course well understood (e.g., [16,11,15]).\nWhen it comes to the knowledge representation properties of ASP (i.e., the intuitive meaning of expressions and the modeling methodologies that have to be followed), the relation to classical logic is less clear. As pointed out by [5], one of the key problems lies in the interpretation of the semantic structures: whereas an answer set in ASP is traditionally interpreted in an epistemic way, as a representation of the knowledge of some rational agent, classical logic is based on the Tarskian view of a model as a representation of a possible objective state of affairs. Nevertheless, a series of papers by Denecker et al. [4,8,7] has shown that a substantial portion of ASP can be understood as a combination of classical FO axioms and inductive definitions.\nAn inductive definitions is a well-understood mathematical construct, that is usually represented by a set of natural language if-then-statements. As shown in [4,8,7], we can view a set of normal logic programming rules as a formal representation of such an inductive definition. For instance, the following pair of rules: {\nT (x, y)\u2190 T (x, z) \u2227 T (z, y). T (x, y)\u2190 E(x, y). } define T as the transitive closure of E. This is of course not overly surprising and it indeed goes back to the views of Van Gelder [21] and Clark [2]. Nevertheless, taking this observation seriously immediately suggests a clean and well-defined \u201cplugin\u201d that can modularly add an ASP-style component to a classical FO the-\nory. Indeed, because an inductive definition is nothing more than a generalization of the way in which relations are usually (non-inductively) defined by means of an FO equivalence, there should be nothing problematic (either conceptually or mathematically) about allowing such \u201csets of rules that form an inductive definition\u201d anywhere one is allowed to use an equivalence. FO(ID) (previously known as ID-logic) is the language that does precisely this: it extends FO, in a completely modular way, with a rule-based representation for inductive definition [3]. Representing a search problem as a model expansion problem in FO(ID) often yields results that are almost identical to a Generate-Define-Test program in ASP [17], apart from minor syntactic details [18,5]. In this way, FO(ID) therefore fits nicely into our stated goal, by identifying one concrete way in which ASP improves upon FO and packing this up in a language construct that can be added to an existing FO knowledge base at will.\nWhile FO(ID) seems able to naturally represent already a surprisingly large part of existing ASP practice, it by no means covers everything. One class of examples that remains out of scope is that of the epistemic examples that originally motivated the stable model semantics [12,13]. This is epitomized by the well-known interview example [14], which is expressed in ASP as:\nEligible(x)\u2190 HighGPA(x). Eligible(x)\u2190Minority(x), FairGPA(x). \u00acEligible(x)\u2190 \u00acFairGPA(x). Interview(x)\u2190 not Eligible(x), not \u00acEligible(x).\nRecent efforts have attempted to reformulate also this kind of example in a way that explains its relation to FO. In [23], the language of Ordered Epistemic Logic (OEL) is developed for this. Here, an ordered set of FO theories is considered, and each theory T is allowed to make use of modal operators KT \u2032 that refer to the knowledge entailed by a theory T \u2032 < T . The interview example would consist of two theories T1, T2 with T1 < T2, such that T1 is a normal FO knowledge base containing facts about Minority, HighGPA and FairGPA, and a definition of Eligible. The theory T2 consists of the single equivalence:\n\u2200x Interview(x)\u21d4 \u00acKT1Eligible(x) \u2227 \u00acKT1Eligible(x).\nThis logic extends FO in a way which is completely orthogonal to FO(ID). There is nothing to prevent the different knowledge bases of an OEL theory from containing, in addition to regular FO formulas, also inductive definitions, but if they do, there is no interplay with the epistemic operators. In other words, FO(ID) and OEL both isolate one particular non-classical aspect of ASP, and show how it can be modularly added to FO, but they do so independently. This presupposes that there is nothing of importance in ASP\u2019s combination of epistemic and \u201cinductive definition\u201d reasoning. However, it does not seem a priori obvious that this is the case.\nIn this paper, we will therefore investigate how an epistemic component can be added to the inductive definition construct of FO(ID) itself. The key idea\nhere is to allow both a relation and an agent\u2019s knowledge about this relation to be defined together in a single knowledge producing definition, as we will call it. The semantics of such a knowledge producing definition is defined by a constructive process that creates, in parallel, the relations that are being defined and the agent\u2019s knowledge about them. In this way, we obtain a language in which, unlike the FO(ID)+OEL approach, interaction between the epistemic and definitional component is possible. The hope is that such a language might shed more light on the epistemic component of ASP and its relation to both classical FO and the inductive definitions of FO(ID).\nThe work presented in this paper is still at a preliminary stage, but we will attempt to sketch interesting avenues for future research. Because one of our main design goals is to make our approximate knowledge structures integrate seamlessly with the inductive definition construct as it already exists in FO(ID), we will need to spend some time recalling the details of this, before we can develop our extension."}, {"heading": "2 Preliminaries: the semantics of inductive definitions", "text": "Inductive definitions are constructive. In mathematical texts, they are typically represented by a set of if-then statements, which may be applied to add new elements to the relation(s) that is (or are, in the case of a definition by simultaneous induction) being defined. The formal representation of such a definition in FO(ID) is by a set of rules of the form\n\u2200x P (t)\u2190 \u03c6, (1)\nwhere P (t) is an atom and \u03c6 an FO formula.For monotone definitions, the relation being defined is simply the least relation that is closed under application of the rules, and it can be constructed by exhaustively applying them. For nonmonotone definitions, the relation being defined is no longer the least relation closed under the rules, and there may, in fact, be many minimal relations closed under the rules instead of a single least one. In mathematical texts, such a nonmonotone definition is always accompanied by a well-founded order over which the induction is performed. While the characterization as a least set breaks down, the constructive characterization still works: the defined relation can still be constructed by repeated application of the rules, provided that these rules are applied in an order that respects the given well-founded order of induction. For instance, the standard definition of satisfaction in classical logic is a definition over the subformula order, which means that we may only apply a rule that derives that I |= \u03c6 for some \u03c6 after all rules that could derive I |= \u03c8 for a subformula \u03c8 of \u03c6 have been applied.\nOf course, for a correct inductive definition, it is important that the structure of the rules also respects the well-founded order. For instance, in an definition over the subformula order, it makes no sense for a rule to define whether a formula is satisfied in terms of the satisfaction of a larger formula. Therefore, the structure of the rules and the well-founded order are not independent. In\nfact, the well-founded order is already entirely implicit in the structure of the rules! As shown in [8] and a series of prior papers, the well-founded semantics (WFS) [22] can actually be seen as a mathematical construct to recover the well-founded order from the structure of the rules.\nFor simplicity, in the technical material of this paper, we will restrict attention to ground formulas only.\nSince its original definition, a number of alternative ways of defining the WFS have been developed. One of these is to start from the following method of evaluating a formula \u03c6 in a pair of interpretations (I, J):\n\u2013 For an atom P (t), (I, J) |= P (t) iff I |= P (t), \u2013 For a formula \u00ac\u03c8, (I, J) |= \u00ac\u03c8 iff (J, I) 6|= \u03c8, \u2013 For a formula \u03c81 \u2228 \u03c82, (I, J) |= \u03c81 \u2228 \u03c82 iff (I, J) |= \u03c81 or (I, J) |= \u03c82, \u2013 For a formula \u03c81 \u2227 \u03c82, (I, J) |= \u03c81 \u2227 \u03c82 iff (I, J) |= \u03c81 and (I, J) |= \u03c82.\nThe crux of this definition lies in the case for negation, which switches the roles of I and J , thus ensuring that positive occurrences of atoms are evaluated in I and negative occurrences in J . We will call a pair (I, J) for which I \u2264 J an approximating pair, because it can be seen as an approximation of the set of interpretations K such that I \u2264 K and K \u2264 J . Indeed, if (I, J) |= \u03c6, according to the above definition, then K |= \u03c6 for all such K. Moreover, if K |= \u03c6 for at least one such K, then (J, I) |= \u03c6. For pairs (I, J) such that I = J , the evaluation (I, J) |= \u03c6 reduces to classical satisfaction I |= \u03c6. Pairs for which this is the case are called total.\nThe WFS can then be defined as the unique limit of a sequence of pairs of interpretations (Ii, Ji)i\u22650. This sequence starts from the least precise pair of interpretations (\u22a5\u03a3 ,>\u03a3), where \u22a5\u03a3 is the interpretation in which all atoms is false and >\u03a3 the interpretation in which all atoms are true. There are then two acceptable ways of going from (Ii, Ji) to (Ii+1, Ji+1):\n\u2013 Either Ji+1 = Ji and Ii+1 is the union Ii + {P (t)}, with P (t) an atom for which there exists a rule of the form P (t)\u2190 \u03c6 with (Ii, Ji) |= \u03c6; \u2013 Or Ii+1 = Ii and Ji+1 is such that Ii \u2264 Ji+1 \u2264 Ji and for all atoms P (t) in the set difference Ji \u2212 Ji+1 and all rules P (t)\u2190 \u03c6, (Ji+1, Ii) 6|= \u03c6\nIntuitively, the first of these two cases allows us to derive the head of a rule once it is certain that its body is satisfied (in the sense that K |= \u03c6 for all K approximated by (Ii, Ji)). The second case allows us to assume that a set of atoms must all be false if this assumption would make us certain that all bodies \u03c6 of rules with one of these atoms in the head are false (i.e., K 6|= \u03c6 for all K approximated by (Ii, Ji+1)). The set Ji+1 \u2212 Ji of atoms that are falsified in this operation is known as an unfounded set.\nA sequence constructed in this way is called an induction sequence. The wellfounded model (WFM) is now precisely the unique limit (V,W ) to which all such induction sequences converge. If this WFM is total (i.e., V = W ), then the definition completely determines the extension of the predicates it defines. Clearly, this is a desirable property for an inductive definition. Therefore, FO(ID) allows only total models.\nSo far, we have tacitly assumed that all predicates in the vocabulary \u03a3 are defined by the definition. In mathematics, however, this is rarely the case, since most definitions serve to define some relation(s) in terms of some other relation(s). This is also possible in FO(ID). For a definition \u2206 (i.e., a set of rules of form (1)), the predicate symbols appearing in the head of at least one of these rules are called the defined predicates of \u2206. The set of all defined predicates is denoted as Def(\u2206). The remaining predicates (i.e., those that belong to \u03a3 \u2212 Def(\u2206)) are called open, and the set of all such predicates is denoted by Op(\u2206). The purpose of a definition is then to characterize the defined predicates Def(\u2206) in terms of the open predicates Op(\u2206). Formally, this is done by parametrizing the construction process by an interpretation for the open predicates: for an interpretation O of Op(\u2206), an induction sequence given O is defined as a sequence of interpretation (Ii, Ji)i\u22650, in which all interpretations Ii and Ji extend the given interpretation O. The starting point of this sequence is the pair (I0, J0) such that I0 = O +\u22a5Def(\u2206) and J0 = O +>Def(\u2206).\nAn interpretation I is then called a model of a definition \u2206, denoted I |= \u2206, if the unique limit of the induction sequences for \u2206 given I|Op(\u2206) (i.e., the restriction of I to the open predicates of \u2206) is precisely the total pair (I, I).\nFO(ID) now consists of classical first-order logic FO extended with these definitions. While some versions of this logic allow boolean combinations of classical formulas and inductive definitions, we will, for simplicity, restrict attention in this paper to FO(ID) theories that consist of precisely one FO formula \u03c6 and one inductive definition \u2206. For such a theory T = {\u03c6,\u2206}, we define that I is a model of T , denoted I |= T , iff both I |= \u03c6 (in the classical sense) and I |= \u2206 (as defined above)."}, {"heading": "3 Knowledge producing definitions", "text": "The goal of this paper is take the concept of an inductive definition as it exists in FO(ID) and extend it by allowing definitions that not only define the objective extension of their defined predicates, but, at the same time, also define a rational agent\u2019s knowledge about these predicates. A modal literal is a formula of the form K\u03c8 where \u03c8 is an FO formula. By FO(K), we denote the language that extends FO by allowing modal literals to appear anywhere an atom P (t) may appear. Note that FO(K) therefore does not allow nesting of the operator K. A knowledge producing definition \u03ba is a set of rules of either the form\n\u2200x K\u03c8 \u2190 \u03c6, (2)\nor \u2200x P (t)\u2190 \u03c6. (3)\nHere, K\u03c8 is a modal literal and P (t) an atom. In both cases, \u03c6 is an FO(K) formula. Again, in our formal treatment, we will always assume that these rules have already been appropriately grounded. The defined predicates of a knowledge producing definition \u03ba are all the predicates P that appear in the head of a rule\nof form (3). All other predicates, including those that appear only in the formula \u03c8 of a rule of form (2), are open.\nFor this formalism, the basic semantic structure will consist of a pair of an interpretation I, representing the real world, and a set of interpretations W , representing the agent\u2019s knowledge about the world. We call such a pair (I,W ) a knowledge structure and call it consistent if I \u2208W . It is obvious how to evaluate a knowledge formula in such a knowledge structure.\nDefinition 1. For a knowledge formula \u03c6 and a knowledge structure S = (I,W ), we define S |= \u03c6 as follows:\n\u2013 For an atom P (t), S |= P (t) iff I |= P (t), \u2013 For a modal literal K\u03c8, S |= K\u03c8 iff for each J in W , (J,W ) |= \u03c8, \u2013 The other cases are defined as usual.\nLike the WFS, which construct a single interpretation K through a series of increasingly precise approximations by pairs of interpretations (Ii, Ji), our semantics will construct a single knowledge structure (I,W ) through a series of increasingly precise approximations of it. Part of these approximations will again be a pair of interpretations (Ii, Ji), which form an increasingly precise sequence of approximations of the real extension K of the defined predicates. At each stage of this approximating sequence, we will also keep track of the agent\u2019s knowledge about it. Therefore, at each step i, we will also have a set Wi of pairs of interpretations; if (I \u2032, J \u2032) \u2208 Wi, then this means that the agent considers it possible that (I \u2032, J \u2032) occurs somewhere in the real approximating sequence. The way in which we will ensure this property, is to, on the one hand, apply the same derivation rules we apply to the real sequence to the pairs that the agent considers possible. On the other hand, when the agent\u2019s knowledge increases due to a modal literal in the head of a rule, this will eliminate some of the possibilities (i.e., some of these pairs (I \u2032, J \u2032) are removed from Wi), but it will not change any of the possibilities themselves (i.e., the remaining pairs do not change).\nThe following will serve as our basic semantic structure.\nDefinition 2. An approximate knowledge structure A is a pair ((I, J),W) of an approximating pair (I, J) and a set W of approximating pairs (I \u2032, J \u2032).\nEvaluating an FO(K) formula in such an approximate knowledge structure is again a matter of switching the approximating pairs when negation is encountered. Formally, we define that, for an approximate knowledge structure A = ((I, J),W),\n\u2013 For an atom P (t), A |= P (t) iff I |= P (t); \u2013 For a modal literal K\u03c8, A |= K\u03c8 iff for each (I \u2032, J \u2032) \u2208 W, ((I \u2032, J \u2032),W) |= \u03c8; \u2013 For a formula \u00ac\u03c6, A |= \u00ac\u03c6 iff ((J, I),W) |= \u03c6, where W = {(J \u2032, I \u2032) |\n(I \u2032, J \u2032) \u2208 W}; \u2013 The other cases are defined as usual.\nWe now construct an increasingly precise sequence (Ai)i\u22650 of approximate knowledge structures. If we project this sequence unto the approximating pair (I, J) of each approximate knowledge structures ((I, J),W), the result will essentially be just a regular induction sequence. The sequence again takes as input a knowledge structure (O,M) for the open predicates, and its starting point is then the approximate knowledge structure\nA0 = ((O +\u22a5Def(\u03ba), O +>Def(\u03ba)), {(O\u2032 +\u22a5Def(\u03ba), O\u2032 +>Def(\u03ba)) | O\u2032 \u2208M}).\nWe construct subsequent elements of the sequence by applying one of the following operations.\nOperation 1. Ai+1 = ((Ii + {P (t)}, Ji),Wi) where Ai = ((Ii, Ji),Wi) such that there is a rule r of the form P (t)\u2190 \u03c6 with ((Ii, Ji),Wi) |= \u03c6.\nThis operation is just the obvious analogue to the first operation used in building normal induction sequences. The only difference is that the agent\u2019s knowledgeWi is dragged along as an additional argument, which is used to evaluate occurrences of modal literals in the rule bodies.\nOperation 2. Ai+1 = ((Ii, Ji),Wi+1) where Ai = ((Ii, Ji),Wi) and Wi+1 = Wi \u2212 {(I \u2032i, J \u2032i)} + {(I \u2032i + {P (t)}, Ji)} such that there is a rule r of the form P (t)\u2190 \u03c6 with ((I \u2032i, J \u2032i),Wi) |= \u03c6.\nThis operation is essentially the same as the previous one, with the only difference being that it is now not applied to the approximating pair (Ii, Ji), but to one of the approximating pairs (I \u2032i, J \u2032 i) inWi. Where the previous two operations are analogous to the production operation of the normal induction sequence, the next two mimic the unfounded set operation.\nOperation 3. Ai+1 = ((Ii, Ji+1),Wi) where Ai = ((Ii, Ji),Wi) and Ji+1 is such that Ii \u2264 Ji+1 \u2264 Ji and for all atoms P (t) \u2208 Ji \u2212 Ji+1 and all rules r of the form P (t)\u2190 \u03c6, it holds that (Ji+1, Ii) 6|= \u03c6.\nAgain, this operation can either be performed on the approximating pair (Ii, Ji), as above, or on one of the pairs in the set Wi, as below:\nOperation 4. Or Ai+1 = ((Ii, Ji),Wi+1) where Ai = ((Ii, Ji),Wi) andWi+1 = Wi\u2212{(I \u2032i, J \u2032i)}+{(I \u2032i, J \u2032i+1)} and J \u2032i+1 is such that I \u2032i \u2264 J \u2032i+1 \u2264 J \u2032i and for all atoms P (t) \u2208 J \u2032i \u2212 J \u2032i+1 and all rules r of the form P (t) \u2190 \u03c6, it holds that ((J \u2032i+1, I \u2032 i),Wi) 6|= \u03c6.\nThe final operation takes care of the effect of knowledge producing rules.\nOperation 5. Ai+1 = ((Ii, Ji),Wi+1) where Ai = ((Ii, Ji),Wi) and Wi+1 = {(I, J) \u2208 Wi | (J, I) |= \u03c8} and there exists a rule r of the form K\u03c8 \u2190 \u03c6 such that ((Ii, Ji),Wi) |= \u03c6.\nNote that the condition for removing a pair (I, J) fromWi is that (J, I) 6|= \u03c8, i.e., that no interpretation approximated by (I, J) still satisfies \u03c8.\nThe semantics of a knowledge producing definition is now defined in terms of sequences that are constructed by these operations.\nDefinition 3. Let \u03ba by a knowledge producing definition. Let (O,M) be a knowledge structure describing the agent\u2019s initial knowledge about the open predicates. A knowledge derivation sequence is a sequence (Ai)i\u22650 of approximate knowledge structures, starting from\nA0 = ((O +\u22a5Def(\u03ba), O +>Def(\u03ba)), {(O\u2032 +\u22a5Def(\u03ba), O\u2032 +>Def(\u03ba)) | O\u2032 \u2208M}),\nsuch that each Ai+1 is obtained from Ai by applying one of the five operations defined above and, to prevent the same operation from being applied again and again, Ai+1 6= Ai. Such a sequence is called complete if there is no way to extend it further without violating this condition. It is called sound if every operation that is used to construct Ai+1 from Ai remains applicable in all Aj with j > i. It is called total if it terminates in an approximate knowledge structure ((I, J),W) such that I = J and for each (I \u2032, J \u2032) \u2208 W also I \u2032 = J \u2032.\nThe condition of totality is borrowed from FO(ID), where, as mentioned, it is used to ensure that each inductive definition correctly and completely defines the relations it sets out to define. It is therefore also a natural requirement in our context.\nThe condition of soundness is meant to avoid situations in which the sequence ends up contradicting itself, as it might for the following example:\n{Kp\u2190 \u00acKp.}\nHere, the fact that the agent does not know p will produce the knowledge that p. This is not only conceptually problematic, but also creates the practical problem that the order in which operations are applied might have an effect on the final outcome. For instance, the knowledge definition{\nKq \u2190 \u00acKp. Kp\u2190 \u00acKq.\n}\nhas both a derivation sequence that starts with the first rule and therefore ends up knowing q but not knowing p, and one that starts with the second rule and ends up knowing p but not q.\nThis can only happen with sequences that are not sound, as the following proposition shows.\nProposition 1. All complete and sound knowledge derivation sequences that start from the same knowledge structure (O,M) terminate in the same approximate knowledge structure A.\nProof (sketch). At any particular point in the derivation sequence, many operation may be applicable. We have to show that it does not matter which of these we choose. First, because the sequence is sound, we know that even if we do not choose to apply an operation now, we will always get a chance to apply it later. Second, the effect of an operation usually does not depend on when it is\nexecuted. The only exception to this is Operation 5, because the set of approximating pairs may of course change throughout the sequence. However, the only changes to this set are that (1) pairs are removed and that (2) pairs become more precise (i.e., that either the first element I of a pair (I, J) becomes larger or that J becomes smaller, so that fewer interpretations K lie between I and J). Clearly, (1) is not a problem, because if a pair gets removed later on any way, it does not matter if we already remove it now or not. Also (2) is not a problem, because the condition for removing a pair (I, J), namely that (J, I) 6|= \u03c6, also implies that, for any more precise pair (I \u2032, J \u2032) (i.e., such that I \u2264 I \u2032 and J \u2032 \u2264 J), it will be the case that (J \u2032, I \u2032) 6|= \u03c6 as well. The only effect of postponing the application of an Operation 5 to a later stage is therefore that we might end up removing more pairs than if we had applied it now. However, if we apply the operation now, then at the later stage we will have another Operation 5 available, namely the one that removes precisely those pairs that form the difference. Since this operation will remain applicable and therefore must eventually be applied, the end result will be the same.\nut\nMoreover, the only way in which it is possible to obtain unsound derivations is by negated modal literals.\nProposition 2. For a knowledge producing definition in which each body of a rule contain only positive occurrences of modal literals K\u03c8, each knowledge derivation sequence is sound.\nProof (sketch). The differences between one approximate knowledge structure Ai = ((Ii, Ji),Wi) and an approximate knowledge structure Aj = ((Ij , Jj),Wj) that occurs later in the derivation sequence are:\n\u2013 Ii \u2264 Ij and Jj \u2264 Ji: this implies that whenever ((Ii, Ji),W) |= \u03c6 for some W and \u03c6, also ((Ij , Jj),W) |= \u03c6 \u2013 Wj consists of pairs (I \u2032j , J \u2032j) for which there exists a corresponding pair (I \u2032i, J \u2032 i) \u2208 Wi such that, again, I \u2032i \u2264 I \u2032j and J \u2032j \u2264 J \u2032i , and therefore when-\never ((I \u2032i, J \u2032 i),W) |= \u03c6 also ((I \u2032j , J \u2032j),W) |= \u03c6\n\u2013 for some (I \u2032j , J \u2032 j) \u2208 Wj , there may not exist a corresponding pair in Wi\nPutting the second and third point together, it is obvious thatWj always knows everything that Wi knows, and possibly more. Therefore, only rule bodies containing a negative occurrence of a modal literal may becomes false in Wj after they were true in Wi.\nut\nThis result seems to suggest that it might be possible to impose syntactic constraints on a knowledge producing definition to ensure that it only has sound derivations, by limiting the way in which negated modal literals are allowed to appear. However, it is not enough to, e.g., just require that these definitions are stratified, because gaining new knowledge about one predicate may have \u201cside\neffects\u201d where also knowledge about another predicate is produced. For instance, consider the following definition which, at first sight, contains no cycles at all: q \u2190 p. Kq \u2190 r. r \u2190 \u00acKp.  Even though there are no syntactic cycles, once the agent learns q, this will also produce the knowledge that p (since q is only true in worlds where p also holds). Because of the \u00acKp in the body of the rule for r, this will lead to an unsound derivation.\nOur approach in this paper will be to ignore the existence of unsound derivations and view the unique limit of the sound derivations as the semantics of a knowledge producing definition\u2014at least, if this unique limit is total. If the limit is not total (given a particular knowledge structure S for the open predicates), then, just like in FO(ID), the knowledge producing definition simply has no models (for that particular S). If no sound derivations exists (for that S), then again the knowledge producing definition has no models (for that S)."}, {"heading": "4 Adding knowledge producing definitions to FO", "text": "The previous section defined the concept of a knowledge producing definition in isolation. Of course, our goal is to add this construct to FO(K), in the same way as FO(ID) has added inductive definitions to FO. We will again consider only theories of the form T = {\u03c6, \u03ba}, were \u03c6 is now an FO(K) formula and \u03ba a knowledge producing definition. We define that a consistent knowledge structure S = (I,W ) is a weak model of T if S |= \u03c6 and the approximate knowledge structure ((I, I), {(J, J) | J \u2208 W}) is the unique total limit of each sound derivation sequence that starts from (I|Op(\u03ba), {L|Op(\u03ba) | L \u2208W}).\nA problem with these weak models is they might contain knowledge that is not warranted. Consider, for instance, the following example:\n{q \u2190 Kp} .\nHere, there is no reason at all for knowing p, yet this knowledge producing definition has a weak model ({p, q}, {{p, q}}). To avoid such models, we introduce the following concept.\nDefinition 4. Let T = {\u03c6, \u03ba}, were \u03c6 is an FO(K) formula and \u03ba a knowledge producing definition. A knowledge structure S = (I,W ) is a strong model of T , denoted S |= T , if S |= \u03c6 and the approximate knowledge structure ((I, I), {(J, J) | J \u2208 W}) is the unique total limit of each sound derivation sequence that starts from (I|Op(\u03ba), O) where O is the set of all L|Op(\u03ba) such that there exists a W \u2032 for which (L,W \u2032) is a weak model of T .\nBy always using the set O as the set of possible worlds for the open predicates, this definition prevents the knowledge producing definition from arbitrarily knowing more about its open predicates than it should."}, {"heading": "5 Examples", "text": "In the logic we have now defined, it is straightforward to represent the Interview example.{\nEligible(x)\u2190 (HighGPA(x) \u2228 (Minority(x) \u2227 FairGPA(x)). Interview(x)\u2190 \u00acK Eligible(x) \u2227 \u00acK \u00acEligible(x). } \u2200x HighGPA(x)\u21d4 x = Mary. \u2200x FairGPA(x)\u21d4 x = John.\nMinority(Mary).\nHere, the soundness condition on the derivation sequence means that we first have to apply the first rule of the knowledge producing definition to exhaustion, before starting with the second rule. There are two possible interpretations for the open predicates of the definition that satisfy the FO part of the theory:\nO1 = {HighGPA(Mary), FairGPA(John),Minority(Mary)}, O2 = {HighGPA(Mary), FairGPA(John),Minority(Mary),Minority(John)}.\nEach strong model will therefore have to be produced by a derivation sequence in which W0 = {O1, O2} is used as the agent\u2019s knowledge about the open predicates. Let us first consider a sound derivation sequence that interprets the open predicates by the knowledge structure S1 = (O1,W0). The first step is A0 = (A, {A,B}) with:\nA = (O1 +\u22a5Def(\u03ba), O1 +>Def(\u03ba)) B = (O2 +\u22a5Def(\u03ba), O2 +>Def(\u03ba))\nIn the approximating pair A, we can apply the first rule of the knowledge producing definition to derive that Eligible(Mary), and we can also apply an unfounded set operation to derive that Eligible(John) is false. This leads to the new approximating pair (we abbreviate the names of the predicates):\nA\u2032 = (O1 + {Elig(Mary)}, O1 + {Elig(Mary), Int(Mary), Int(John)})\nIn the approximating pair B, on the other hand, we can derive that both Eligible(John) and Eligible(Mary). This leads to the new pair:\nB\u2032 = (O2 + {Elig(Mary), Elig(John)}, O2 + {Elig(Mary), Elig(John), Int(Mary), Int(John)})\nAfter applying these six operations (two times two for A, and two for B) to the approximate knowledge structure W0, we will therefore eventually end up in\nW6 = (A\u2032, {A\u2032, B\u2032})\nNow, {A\u2032, B\u2032} |= K Elig(Mary), because Elig(Mary) holds in both underestimatesO1+{Elig(Mary)} andO2+{Elig(Mary), Elig(John)}. Also, {A\u2032, B\u2032} |= \u00acK Elig(John), since Elig(John) does not hold in the overestimate (the negation switches the pairs) ofA\u2032, namelyO1+{Elig(Mary), Int(Mary), Int(John)}. Finally, {A\u2032, B\u2032} |= \u00acK \u00acElig(John) holds as well, since Elig(John) does not belong to the underestimate (the two negations switch the pairs twice) of A\u2032, namely O1 + {Elig(Mary)}. Therefore, we can apply to both A\u2032 and B\u2032 an unfounded set operation (Operations 3 and 4) to derive that Mary should not be interviewed, and we can apply the last rule of the definition to derive that John should. After six more steps (two times two for A\u2032, and two for B\u2032), we therefore end up in the limit W9 = (A\u2032\u2032, {A\u2032\u2032, B\u2032\u2032}), where\nA\u2032\u2032 =(I, I) with I = O1 + {Elig(Mary), Int(John)} B\u2032\u2032 =(J, J) with J = O1 + {Elig(Mary), Elig(John), Int(John)}\nThis structure is total and therefore the single knowledge structure (I, {I, J}) that it approximates is a model of this theory. By a similar reasoning, there is also a second model, namely (J, {I, J}).\n5.1 Another version of the Interview example\nIn the above version of this example, we are basically already encoding the solution to the problem by ordering the agent to interview everyone whose eligibility is not known. Using a knowledge producing definition, however, it is also possible to let the semantics do more of the work.\n Eligible(x)\u2190 (HighGPA(x) \u2228 (Minority(x) \u2227 FairGPA(x)).\nK Minority(x)\u2190 Interview(x) \u2227Minority(x). K \u00acMinority(x)\u2190 Interview(x) \u2227 \u00acMinority(x).  (\u2200x HighGPA(x)\u21d4 x = Mary) \u2227 (\u2200x FairGPA(x)\u21d4 x = John) \u2227Minority(Mary).\n\u2200x K Eligible(x) \u2228K \u00acEligible(x).\nHere, we are just telling the agent that the action of interviewing a candidate will reveal his minority status, without explicitly saying who should be interviewed. The FO(K) constraint then orders the agent to make sure that for each candidate, it is known whether he is eligible of not. Generating models for this theory will then correctly produce plans in which people whose minority status is unknown will be interviewed."}, {"heading": "5.2 Sensing actions", "text": "A successful application area of ASP is planning. This also falls naturally in the scope of FO(ID), since theories in the situation or event calculus are essentially just an inductive definition of the values of the fluents at different points in time\n[6]. Here is an example of a theory in FO(ID) that represents a small action domain in which there is a dirty glass that can be cleaned by wiping it.\n{ Clean(t+ 1)\u2190Wipe(t) \u2228 Clean(t).\nClean(0)\u2190 InitClean. } \u00acInitClean\nIf the agent now does not know whether the glass is initially clean, we may be interested in finding a plan that will allow it to know with certainty that it will be clean at a certain point in time. This can be accomplished by just adding, e.g., K Clean(2) as an FO(K) constraint to the theory. More interestingly, knowledge producing definitions can also be used to add sensing actions, such as an action Inspect that allows the agent to discover whether the glass is clean.\n Clean(t+ 1)\u2190Wipe(t) \u2228 Clean(t). Clean(0)\u2190 InitClean. K Clean(t+ 1)\u2190 Inspect \u2227 Clean(t).\nK \u00acClean(t+ 1)\u2190 Inspect \u2227 \u00acClean(t).  K Clean(2)."}, {"heading": "6 Discussion", "text": "ASP is able to express epistemic examples by interpreting an answer set as a set of literals that are believed by a rational agent. This is one of the most radical ways in which ASP departs from classical logic, in which models or interpretations always represent the objective state of the world. In the classical setting, one typically resorts to sets of interpretations (or the related concept of a Kripke structure) to represent beliefs.\nIn order to relate this aspect of ASP to classical logic, or to even integrate the two, it is necessary to construct a formalisation which sticks to these classical semantics objects. In this paper, we have introduced knowledge producing definitions for this purpose. As our examples have shown, these are able to mimic the ASP representation of, e.g., the Interview example, while at the same time also introducing some interesting new possibilities, such as the ability to distinguish between some atom P (t) becoming objectively true (by having P (t) in the head of a rule) and the agent learning this atom (by having K P (t) in the head)."}], "references": [{"title": "Enfragmo: A system for modelling and solving search problems with logic", "author": ["A. Aavani", "X. Wu", "E. Ternovska", "D. Mitchell"], "venue": "In LPAR-18,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Negation as failure", "author": ["K. Clark"], "venue": "In Logic and Data Bases, pages 293\u2013322. Plenum Press,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1978}, {"title": "Extending classical logic with inductive definitions", "author": ["M. Denecker"], "venue": "In CL, volume 1861 of LNCS, pages 703\u2013717,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2000}, {"title": "Logic programming revisited: Logic programs as inductive definitions", "author": ["M. Denecker", "M. Bruynooghe", "V. Marek"], "venue": "ACM Transactions on Computational Logic (TOCL), 2(4):623\u2013654,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2001}, {"title": "A Tarskian informal semantics for ASP", "author": ["M. Denecker", "Y. Lierler", "M. Truszczynski", "J. Vennekens"], "venue": "In Technical Communications of the 28th International Conference on Logic Programming,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "Inductive situation calculus", "author": ["M. Denecker", "E. Ternovska"], "venue": "Artificial Intelligence, 171(5-6):332\u2013360,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2007}, {"title": "A logic of nonmonotone inductive definitions", "author": ["M. Denecker", "E. Ternovska"], "venue": "ACM Transactions on Computational Logic (TOCL), 9(2):Article 14,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Well-founded semantics and the algebraic theory of non-monotone inductive definitions", "author": ["M. Denecker", "J. Vennekens"], "venue": "In LPNMR, pages 84\u201396,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2007}, {"title": "The second answer set programming system competition", "author": ["M. Denecker", "J. Vennekens", "S. Bond", "M. Gebser", "M. Truszczynski"], "venue": "In LPNMR, pages 637\u2013654,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "Answer set programming\u2019s contributions to classical logic", "author": ["M. Denecker", "J. Vennekens", "H. Vlaeminck", "J. Wittocx", "M. Bruynooghe"], "venue": "An analysis of ASP methodology. In MG-65: Symposium on Constructive Mathematics in Computer Science. Lexington, October 26-27,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2010}, {"title": "Tableau Calculi for Answer Set Programming", "author": ["M. Gebser", "T. Schaub"], "venue": "In ICLP, pages 11-25,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2006}, {"title": "The stable model semantics for logic programming", "author": ["M. Gelfond", "V. Lifschitz"], "venue": "In ICLP/SLP, pages 1070\u20131080. MIT Press,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1988}, {"title": "Logic programs with classical negation", "author": ["M. Gelfond", "V. Lifschitz"], "venue": "In ICLP, pages 579\u2013597. MIT Press,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1990}, {"title": "Classical negation in logic programs and disjunctive databases", "author": ["M. Gelfond", "V. Lifschitz"], "venue": "New Generation Computing, 9(3/4):365\u2013386,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1991}, {"title": "On the relation among answer set solvers", "author": ["E. Giunchiglia", "N. Leone", "M. Maratea"], "venue": "In Ann. Math. Artif. Intell", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2008}, {"title": "Abstract answer set solvers with backjumping and learning", "author": ["Y. Lierler"], "venue": "Theory and Practice of Logic Programming (TPLP) 11(2-3): 135-169,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Answer set programming and plan generation", "author": ["V. Lifschitz"], "venue": "Artificial Intelligence, 138:39\u201354,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2002}, {"title": "On the relation between ID-Logic and Answer Set Programming", "author": ["M. Mari\u00ebn", "D. Gilis", "M. Denecker"], "venue": "In JELIA, volume 3229 of LNCS, pages 108\u2013120. Springer,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2004}, {"title": "The IDP framework for declarative problem solving", "author": ["M. Mari\u00ebn", "J. Wittocx", "M. Denecker"], "venue": "In Search and Logic: Answer Set Programming and SAT, pages 19\u201334,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2006}, {"title": "A framework for representing and solving NP search problems", "author": ["D. Mitchell", "E. Ternovska"], "venue": "In AAAI, pages 430\u2013435,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2005}, {"title": "The alternating fixpoint of logic programs with negation", "author": ["A. Van Gelder"], "venue": "Journal of Computer and System Sciences, 47(1):185\u2013221,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1993}, {"title": "The well-founded semantics for general logic programs", "author": ["A. Van Gelder", "K. Ross", "J. Schlipf"], "venue": "Journal of the ACM, 38(3):620\u2013650,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1991}, {"title": "Ordered epistemic logic", "author": ["H. Vlaeminck", "J. Vennekens", "M. Bruynooghe", "M. Denecker"], "venue": "In Proceedings of the 13th International Conference on Principles of Knowledge Representation and Reasoning,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 9, "context": "This paper is part of a research project that attempts to close this gap [10].", "startOffset": 73, "endOffset": 77}, {"referenceID": 19, "context": "For instance, [20] showed that the typical ASP way of encoding search problems can be captured quite elegantly in a classical context by the notion of modal expansion: given a theory T in an alphabet \u03a3 and an interpretation Io for some subvocabulary \u03a3o \u2286 \u03a3, find an interpretation I that extends Io to the entire vocabulary such that I |= T .", "startOffset": 14, "endOffset": 18}, {"referenceID": 8, "context": "Indeed, the 2011 edition of the ASP-competition [9] has had two modal expansion systems for (extensions of) classical logic among its competitors: Enfragmo [1] and IDP [19].", "startOffset": 48, "endOffset": 51}, {"referenceID": 0, "context": "Indeed, the 2011 edition of the ASP-competition [9] has had two modal expansion systems for (extensions of) classical logic among its competitors: Enfragmo [1] and IDP [19].", "startOffset": 156, "endOffset": 159}, {"referenceID": 18, "context": "Indeed, the 2011 edition of the ASP-competition [9] has had two modal expansion systems for (extensions of) classical logic among its competitors: Enfragmo [1] and IDP [19].", "startOffset": 168, "endOffset": 172}, {"referenceID": 15, "context": ", [16,11,15]).", "startOffset": 2, "endOffset": 12}, {"referenceID": 10, "context": ", [16,11,15]).", "startOffset": 2, "endOffset": 12}, {"referenceID": 14, "context": ", [16,11,15]).", "startOffset": 2, "endOffset": 12}, {"referenceID": 4, "context": "As pointed out by [5], one of the key problems lies in the interpretation of the semantic structures: whereas an answer set in ASP is traditionally interpreted in an epistemic way, as a representation of the knowledge of some rational agent, classical logic is based on the Tarskian view of a model as a representation of a possible objective state of affairs.", "startOffset": 18, "endOffset": 21}, {"referenceID": 3, "context": "[4,8,7] has shown that a substantial portion of ASP can be understood as a combination of classical FO axioms and inductive definitions.", "startOffset": 0, "endOffset": 7}, {"referenceID": 7, "context": "[4,8,7] has shown that a substantial portion of ASP can be understood as a combination of classical FO axioms and inductive definitions.", "startOffset": 0, "endOffset": 7}, {"referenceID": 6, "context": "[4,8,7] has shown that a substantial portion of ASP can be understood as a combination of classical FO axioms and inductive definitions.", "startOffset": 0, "endOffset": 7}, {"referenceID": 3, "context": "As shown in [4,8,7], we can view a set of normal logic programming rules as a formal representation of such an inductive definition.", "startOffset": 12, "endOffset": 19}, {"referenceID": 7, "context": "As shown in [4,8,7], we can view a set of normal logic programming rules as a formal representation of such an inductive definition.", "startOffset": 12, "endOffset": 19}, {"referenceID": 6, "context": "As shown in [4,8,7], we can view a set of normal logic programming rules as a formal representation of such an inductive definition.", "startOffset": 12, "endOffset": 19}, {"referenceID": 20, "context": "This is of course not overly surprising and it indeed goes back to the views of Van Gelder [21] and Clark [2].", "startOffset": 91, "endOffset": 95}, {"referenceID": 1, "context": "This is of course not overly surprising and it indeed goes back to the views of Van Gelder [21] and Clark [2].", "startOffset": 106, "endOffset": 109}, {"referenceID": 2, "context": "FO(ID) (previously known as ID-logic) is the language that does precisely this: it extends FO, in a completely modular way, with a rule-based representation for inductive definition [3].", "startOffset": 182, "endOffset": 185}, {"referenceID": 16, "context": "Representing a search problem as a model expansion problem in FO(ID) often yields results that are almost identical to a Generate-Define-Test program in ASP [17], apart from minor syntactic details [18,5].", "startOffset": 157, "endOffset": 161}, {"referenceID": 17, "context": "Representing a search problem as a model expansion problem in FO(ID) often yields results that are almost identical to a Generate-Define-Test program in ASP [17], apart from minor syntactic details [18,5].", "startOffset": 198, "endOffset": 204}, {"referenceID": 4, "context": "Representing a search problem as a model expansion problem in FO(ID) often yields results that are almost identical to a Generate-Define-Test program in ASP [17], apart from minor syntactic details [18,5].", "startOffset": 198, "endOffset": 204}, {"referenceID": 11, "context": "One class of examples that remains out of scope is that of the epistemic examples that originally motivated the stable model semantics [12,13].", "startOffset": 135, "endOffset": 142}, {"referenceID": 12, "context": "One class of examples that remains out of scope is that of the epistemic examples that originally motivated the stable model semantics [12,13].", "startOffset": 135, "endOffset": 142}, {"referenceID": 13, "context": "This is epitomized by the well-known interview example [14], which is expressed in ASP as:", "startOffset": 55, "endOffset": 59}, {"referenceID": 22, "context": "In [23], the language of Ordered Epistemic Logic (OEL) is developed for this.", "startOffset": 3, "endOffset": 7}, {"referenceID": 7, "context": "fact, the well-founded order is already entirely implicit in the structure of the rules! As shown in [8] and a series of prior papers, the well-founded semantics (WFS) [22] can actually be seen as a mathematical construct to recover the well-founded order from the structure of the rules.", "startOffset": 101, "endOffset": 104}, {"referenceID": 21, "context": "fact, the well-founded order is already entirely implicit in the structure of the rules! As shown in [8] and a series of prior papers, the well-founded semantics (WFS) [22] can actually be seen as a mathematical construct to recover the well-founded order from the structure of the rules.", "startOffset": 168, "endOffset": 172}, {"referenceID": 5, "context": "[6].", "startOffset": 0, "endOffset": 3}], "year": 2013, "abstractText": "Previous research into the relation between ASP and classical logic has identified at least two different ways in which the former extends the latter. First, ASP program typically contain sets of rules that can be naturally interpreted as inductive definitions, and the language FO(ID) has shown that such inductive definitions can elegantly be added to classical logic in a modular way. Second, there is of course also the well-known epistemic component of ASP, which was mainly emphasized in the early papers on stable model semantics. To investigate whether this kind of knowledge can also, and in a similarly modular way, be added to classical logic, the language of Ordered Epistemic Logic was presented in recent work. However, this logic views the epistemic component as entirely separate from the inductive definition component, thus ignoring any possible interplay between the two. In this paper, we present a language that extends the inductive definition construct found in FO(ID) with an epistemic component, making such interplay possible. The eventual goal of this work is to discover whether it is really appropriate to view the epistemic component and the inductive definition component of ASP as two separate extensions of classical logic, or whether there is also something of importance in the combination of the two.", "creator": "LaTeX with hyperref package"}}}