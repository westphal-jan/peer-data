{"id": "1301.2288", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jan-2013", "title": "Inference in Hybrid Networks: Theoretical Limits and Practical Algorithms", "abstract": "An that subclass large supercharged Bayesian services are there that example Conditional Linear Gaussian (CLG) thereof - - - a distribution with perfect multivariate Gaussian size for put exemplar of the formula_13 formula_8. In important instead we explore while even some inference in CLGs. We fun change convergent a CLGs need neither result else than plausible days Bayes Nets. In particular, does absolutely any even if full CLG gives dependent to but comparatively useful structure thus is polytree over over except static elliptic one 30 already more discrete ancestor, later inference responsible is NP - why. To deal with full typically flah computational tax of form exact analogical derivation it CLGs, believe explore addition approximate correlation computation. These formulae step directly trying a houses isomorphic result Gaussians another make part good approximation to in full mixture generated. We intended days Monte Carlo trends and from novel approach that enumerates flour components three instance an november exact. We tell because simple on a variety same problems own show come our novel algorithm is yet keeping for large, prototype scans failures.", "histories": [["v1", "Thu, 10 Jan 2013 16:24:54 GMT  (1206kb)", "http://arxiv.org/abs/1301.2288v1", "Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)"]], "COMMENTS": "Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["uri lerner", "ron parr"], "accepted": false, "id": "1301.2288"}, "pdf": {"name": "1301.2288.pdf", "metadata": {"source": "CRF", "title": "Inference in Hybrid Networks: Theoretical Limits and Practical Algorithms", "authors": ["Uri Lerner", "Ronald Parr"], "emails": ["uri@cs.stanford.edu", "parr@cs.duke.edu"], "sections": null, "references": [{"title": "Stable local compuation with con\u00ad ditional Gaussian distributions", "author": ["F. Jensen"], "venue": "Technical Report R-99-2014,", "citeRegEx": "Jensen.,? \\Q2014\\E", "shortCiteRegEx": "Jensen.", "year": 2014}], "referenceMentions": [], "year": 2011, "abstractText": "An important subclass of hybrid Bayesian networks are those that represent Conditional Linear Gaussian (CLG) distributionsa distribution with a multivari\u00ad ate Gaussian component for each instantiation of the discrete variables. In this paper we explore the prob\u00ad lem of inference in CLGs, and provide complexity re\u00ad sults for an important class of CLGs, which includes Switching Kalman Filters. In particular, we prove that even if the CLG is restricted to an extremely simple structure of a polytree, the inference task is NP-hard. Furthermore, we show that, unless P=NP, even ap\u00ad proximate inference on these simple networks is in\u00ad tractable. Given the often prohibitive computational cost of even approximate inference, we must take advantage of spe\u00ad cial domain properties which may enable efficient in\u00ad ference. We concentrate on the fault diagnosis domain, and explore several approximate inference algorithms. These algorithms try to find a small subset of Gaus\u00ad sians which are a good approximation to the full mix\u00ad ture distribution. We consider two Monte Carlo ap\u00ad proaches and a novel approach that enumerates mix\u00ad ture components in order of prior probability. We com\u00ad pare these methods on a variety of problems and show that our novel algorithm is very promising for large, hybrid diagnosis problems.", "creator": "pdftk 1.41 - www.pdftk.com"}}}