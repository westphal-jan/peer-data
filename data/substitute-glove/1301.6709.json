{"id": "1301.6709", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jan-2013", "title": "A General Algorithm for Approximate Inference and its Application to Hybrid Bayes Nets", "abstract": "The palmeira mud stochastic is on require synthesis an take linear began Bayesian communications. It known by manipulating clique potentials - distributions over while constraint last a clique. While might moves works have have were networks, something probably significant had the if for maintain an therefore certain than 's jialu ionization. This publication presents a include independent clear that combines roughly quantification already rest clique tree algorithm, intent nullifying important limitation. Many became dimensions inference algorithms can nor view turned circumstances of this long. The bayesian essentially sort mogami garden frequency, using approximate inference help 1.5 the precipitation once each clique. In many settings, two computation of the approximate clique potential may be come generally tools theoretical nature sampling. Iterations only taken either gradually boosting the quality of the indicates.", "histories": [["v1", "Wed, 23 Jan 2013 15:58:59 GMT  (411kb)", "http://arxiv.org/abs/1301.6709v1", "Appears in Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI1999)"]], "COMMENTS": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI1999)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["daphne koller", "uri lerner", "dragomir anguelov"], "accepted": false, "id": "1301.6709"}, "pdf": {"name": "1301.6709.pdf", "metadata": {"source": "CRF", "title": "A General Algorithm for Approximate Inference and Its Application to Hybrid Bayes Nets", "authors": ["Daphne Koller", "Uri Lerner", "Dragomir Angelov"], "emails": ["@cs.stanford.edu"], "sections": [{"heading": null, "text": "The clique tree algorithm is the standard method for\ndoing inference in Bayesian networks. It works by ma nipulating clique potentials - distributions over the variables in a clique. While this approach works well\nfor many networks, it is limited by the need to maintain\nan exact representation of the clique potentials. This\npaper presents a new unified approach that combines\napproximate inference and the clique tree algorithm,\nthereby circumventing this limitation. Many known approximate inference algorithms can be viewed as instances of this approach. The algorithm essentially\ndoes clique tree propagation, using approximate infer\nence to estimate the densities in each clique. In many\nsettings, the computation of the approximate clique\npotential can be done easily using statistical impor\ntance sampling. Iterations are used to gradually im\nprove the quality of the estimation.\n1 Introduction\nBayesian networks (BNs) allow us to represent complex probabilistic models compactly and naturally. A range of inference algorithms, both exact and approximate, have been developed for the task of probabilistic reasoning using BNs - computing the probability of one or more events given some evidence. Until now, most of the Bayesian network models designed have admitted inference using one of the existing algorithms. However, over the last few years, there has been growing interest in extending the range of probabilistic reasoning applications [7, 8, 9]. Many of these domains present new challenges to BN tech nology: they are larger, more complex, and involve a wider range of probability models.\nThe most commonly used algorithm for BN inference is the clique tree algorithm [I 0, 16, 20]. The basic principle of the algorithm is to divide the set of variables into overlapping subsets called cliques. The inference is decomposed onto operations over the variables in a single clique. The results\nof a computation on one clique are transmitted to another, where they are in turn used in a subsequent computation. The complexity of the algorithm is determined by the size of the cliques; in discrete domains, it is roughly exponential in the number of variables in the largest clique.\nThe clique tree algorithm has two main advantages. First, it is an exact inference algorithm - it returns the correct answer, according to the joint distribution represented by the BN. Second, it can take advantage of structural prop erties of the domain - the conditional in dependences rep resented by the BN structure. These independences allow the construction of small cliques, reducing the complexity of the computation.\nHowever, there are many situations where the clique tree algorithm breaks down. The main difficulty is that the in termediate results in the cliques can get too complex to be represented and manipulated effectively. Each intermediate result is a function from the space of values of its variables to JR. In discrete BNs, these functions are usually repre sented as tables, with an entry for each assignment in the appropriate domain. This representation is exponential in the number of variables in the expression. For some large BNs, e.g., QMR-DT [9], the cliques are too large to al low this exact representation of the factors. The problem is even more severe if we want to represent continuous or hybrid domains (ones involving both discrete and continu ous variables). In this case, the intermediate results in the cliques are typically too complex to admit any closed form representation.\nA completely different approach is taken by Monte Carlo inference algorithms such as Likelihood Weighting [ 19]. Gibbs Sampling [ 17], some of which extend easily to hy brid BNs. The idea is to estimate the joint distribution as a set of (possibly weighted) samples. Unfortunately, the convergence of this algorithms can be quite slow in high dimensional spaces, where the samples can explore only a small part of the space.\nIn this paper we present a general approach to combin ing exact and approximate inference, which in many cases\nachieves the best of both worlds. Like the clique tree al gorithm, our approach builds a clique tree and propagates messages from one clique to another. However, rather than computing messages that correspond to exact intermedi ate results, our algorithm uses approximate inference tech niques to compute and manipulate the messages.\nThis general scheme has many instantiations. These vary along two primary dimensions: the class of functions used to represent the intermediate results, and the approxima tion algorithm used to compute new intermediate results from previous ones. For example, in one instantiation, we might choose to represent intermediate results as mixtures of Gaussians. We can compute a new intermediate result, e.g., the product of two factors, by using random sam pling to generate samples from the new distribution and then using statistical density estimation techniques (such as EM [4]) to estimate the new result.\nAs we will see, this scheme raises several interesting issues. For example, how do we best approximate the message that one clique sends to another? If we restrict the complexity of the message, then an approximation that tries to fit the entire function as well as it can may not be optimal. Rather, it may be better to provide a better approximation in those regions of the space that will turn out to be important. Of course, in early stages of the computation, we often do not know which parts of the space will later turn out to be im portant. Thus, an approximation that appears to be good now may turn out to be highly suboptimal later on. This observation leads us to an iterative approximation, where each intermediate result may be estimated several times.\nWe believe that our approach defines an interesting and use ful class of approximate inference algorithms. Indeed, sev eral well-known approximate inference algorithms can be viewed as special cases of this scheme. Our unified frame work allows us to relate these algorithms to each other, to combine them, and even to improve their performance. More interestingly, we use this general framework to define a new algorithm for inference in hybrid Bayesian networks. We consider a particular instantiation of the general algo rithm, which combines importance sampling with statisti cal density in order to compute the approximate messages and clique potentials. We present promising empirical re sults showing that our approach deals effectively with the difficult task of inference in such networks.\n2 Preliminaries\nIn this section, we review two inference algorithms that will form the basis for our later discussion.\nAssume that we have a given BN B, over the variables X1, ... , Xn. Each variable X; takes values in some do main Dom(X;), which may be discrete or continuous. As usual, the BN is a directed acyclic graph whose nodes are\nApproximate Inference in Hybrid Bayes Nets 325\nthese variables. For a set of random variables Y, we use Dom(Y) to represent the joint domain of the variables in Y. We use Parents( X;) to denote the parents of node X; in B. Each node X; is also associated with a conditional probability distribution (CPD) \u00a2;,which specifies the con ditional distribution P(X; I Parents(X;)), i.e., for every value y E Dom(Parents(X;)), it defines a probability dis tribution (or density function) over Dom(X;). We use\u00a2; to denote the function from Dom(X; UParents(X;)) to JR. In discrete domains, a CPD is often implemented as a ta ble, which simply lists the appropriate probability for each instantiation in Dom(X; U Parents( X;)).\nThe clique tree algorithm [ 16, 20] is the algorithm most commonly used to perform exact inference in discrete Bayes Nets. The basic data structure used by the algorithm is called a clique tree or a join tree. The clique tree is an undirected tree whose nodes cl' ... 'ck are called cliques or clusters. Each clique C; is defined to contain some sub set of the random variables in the BN. Each CPD \u00a2; in B must be assigned to some clique, which must contain X; and Parents(X;). We use \u00a3 to denote the set of edges in the clique tree. Each edge is associated with a sepset, which is the set of random variables in the intersection of the two cliques at the endpoints of the edge. We use S;,j to denote the sepset between C; and Cj, and Ci\\J to denote C;- Si,J\u00b7 There are several ways of executing inference over this type of data structure. We focus on the Shafer-Shenoy algo rithm [20], which is the most suitable for our purposes, as it avoids division operations. Initially, each \u00a2; is assigned to some clique C1; we can only assign this CPD to a clique that contains X; U Parents( X;). We use <I>(C1) to denote the set of CPDs assigned to C 1. Each clique executes local computations over the variables in the clique, which corre spond to multiplying messages and CPDs, and marginaliz ing the result over some of the variables in the clique (by summing out the rest). The results of these computations are sent as messages to neighboring cliques, which, in turn, use them in their own computation. A clique C; is ready to send a message 'f/Hj to its neighbor C1 when it has re ceived messages from all of its other neighbors. The algo rithm terminates when each clique C; has sent messages to all of its neighbors. For simplicity, we model the algo rithm as incorporating evidence by multiplying the CPDs in each clique with an indicator function c:; for all the evi dence relevant to that clique. We use <Pi as shorthand for Il;;.E4>(C;) \u00a2k XC:;.\nAlgorithm 1: Exact clique tree propagation 01: for each C; and each c E Dom(C;) 02: repeat 03: choose C; that received all incoming msgs except (perhaps) 'li ...,; 04: compute Ti-+J =flu, ,i)E\u00a3,i':P.i 'TlJ'-+i x \u00a2i 05: compute 'f/i-+i = Lo (C l r;...,i om i\\j\n326 Koller, Lerner, and Angelov\n06: until all messages sent 07: compute 'lj;; = Il(j,i)E\u00a3 T/j-+i x cf>i 08: normalize each 'lj;;\nWe call the functions Ti-;j intermediate factors. The final result of the computation 1/J; is a clique potential at clique i. The clique potential'lj;; represents the posterior distribution over the variables C; conditioned on the evidence. At a high level, this algorithm extends trivially to the case of continuous variables: we simply replace the summation in line 5 with an integration.\nIn addition to exact inference, Bayesian networks also sup port a range of approximate inference algorithms. Of these, the most commonly used approach is Monte Carlo sam pling. Sampling is a general-purpose technique for infer ence in probabilistic models; its applicability goes far be yond Bayesian networks. The basic idea is that we can ap proximate the distribution by generating independent sam ples from it. We can then estimate the value of a quantity relative to the original distribution by computing its value relative to our samples.\nLet p be a probability distribution over some space !1. If !1 is discrete, the expectation of any function f : !1 o-t JR. is defined as Ep(f) = LwEI'! f(w)p(w). (In the continu ous case, we simply replace the summation by an integral.) Now, assume that we can generate a set of random sam ples from p, w(l],.,,, w[M]. We can view these samples as a compact approximation to the distribution p. There fore, we can approximateEp(f) ::o it 2::7=1 f(w(j]). The main problem is that our distribution pis often not one from which we can sample directly. For example, in a Bayesian network, we can easily generate samples from the prior dis tribution. However, it is far from trivial to generate samples from a posterior distribution. Importance sampling pro vides one approach for dealing with this difficulty.\nAssume that our desired sampling distribution pis given as some probability function p', which may not even be nor malized. We cannot sample from p'. However, we have some probability distribution q from which we can sam ple. The only requirement is that q(w) > 0 whenever p'(w) > 0. We will approximate p, the normalized version of p', by sampling from q. More precisely, we will generate samples w(l],,,, , w[M] from q. To each w(j] we will as sign a weight w(j] = p' (w(j])fq(w(j]). If we normalize the weights of our M samples to sum to 1, we can view this set of weighted samples as an approximation top. It can easily be shown [17] that Ev[f] :=o 2::;:=! f(w[m]) t!:\\il \u00b7\n3 The General Inference Algorithm\nOur approach is based on the following simple idea, used in several papers (see Section 6). Rather than requiring that the algorithm produce the exact result when computing fac-\ntors (in lines 4, 5, and 7 of A! g. I), we allow it to produce an approximation to it - one that admits a compact repre sentation. Of course, this general idea can be implemented in many ways. We can choose a variety of representations for the factors. Clearly, the choice of representation has a strong effect on the quality of our approximation. We need also determine how to implement the various opera tions over factors specified in the algorithm. For example, in lines 4 and 5, our approximate inference algorithm will need to take one set of (approximate or exact) messages, multiply them by the CPDs and the evidence function, and generate an approximation to the outgoing message 1/i->J.\nOne issue that complicates both the representation and the approximation is that neither the intermediate factors nor the messages are guaranteed to be probability densities. For example, in some circumstances a message may be sim ply a CPO. As the parents do not have distributions, the CPD is not a joint distribution over the variables it men tions. As density estimation is much more circumscribed than general-purpose function approximation, we choose to restrict attention to densities. As in [ 14], we assume that the ranges of all continuous variables are bounded. We normal ize each factor which is not a density by ascribing uniform distributions to variables whose distribution is not defined in the factor. Note that a multiplication by a constant factor does not influence the correctness of the algorithm, as the clique potentials are normalized at the end.\nWe can now utilize any of a variety of density estimators for representing our factors. The available approximation tech niques will, of course, depend on the choice of representa tion. If, for example, we were to choose a single Gaussian as the representation for factors, we could compute the op timal Gaussian approximation relatively easily, simply by estimating the first and second moments of the distribution represented by our factor. A more general approach that we can use for approximation combines (importance) sam pling and statistical density estimation . Consider the task of computing the final clique potential. We want to gener ate samples from this distribution, and then apply a density estimation algorithm to learn the associated density. In cer tain (rare) cases, we can sample directly from the resulting density; more often, we cannot. In these cases, importance sampling provides a solution, as described in the previous section.\nLet us assume that we have chosen some representation for the factors. How do we best approximate 1Ji->i? The obvi ous solution is to try and find the approximation fi;_, i that minimizes some metric (a reasonable choice would be the KL-distance [2]) between the \"correct\" message 1/Hj (nor malized to produce a density) and the approximation fi;-; i. Unfortunately, this intuition is flawed. We do not need to approximate the message per se. What we really want is to create the message that will give the best result when we approximate the potential1/;j. This goal might lead to very\ndifferent requirements.\nIntuitively, this phenomenon is clear. A good approxima tion relative to KL-distance will be more accurate in the regions where the density has high value. If the message is then multiplied with additional factors in Cj, leading to a very different function, regions that had very low weight in the original message can now have high weight. The ap proximation may now be a very poor one. In general, even if an approximation to a message has low KL-distance, it does not imply that it the result of multiplying that message with other factors will also be a good approximation.\nWe now provide a rough analysis of this phenomenon. We stress that this analysis is not intended to be an exact bound, but rather to give us insight on the design of the algorithm. The computation of the true potential is described in line 7 of the algorithm. It is easy to verify that 1/Ji is propor tional to a product of T/i->i and several other factors (mes sages, CPDs, and evidence term). We define resti to be the products of these other factors (actually, resti is sim ply Tj-+i). Thus, rather than minimizing D(T/i-+J I I7JHJ ), we should strive to reduce D(a1'Tii-+Jrestilla27Ji->Jresti)\u2022 where a; are normalizing constants.\nNote that a1 T/i-+Jresti is the best approximation to the true potential we can achieve in clique Y given the other (pos sibly approximate) incoming messages. Hence, we want to minimize D(ettT/i-+jrestilla27];-+jrestj). which is equal to LsES,. ?j,J(s)(atT/i-+j(s))/(a27Ji->j(s)). Hence, the penalty w\ufffd get for inaccuracies in 7JH J is proportional to ?j,j(s)- the marginal density of the new potential in Ci over the sepset's variables S;,j. Hence, 7];-+j should be ac curate in areas where ?j,J is big and not necessarily in areas where 'Tii-+i is big. (A similar derivation appears in [14].)\nThe problem of finding an approximation to a distribution q whose accuracy is optimal relative to some other distri bution p is a nontrivial one. Most density estimation algo rithms, if applied naively to the task of learning q, would construct an approximation that was more accurate in re gions where q had high value. For example, if we gener ated samples from q, we would end up with many more samples, and thereby a much more refined estimate of the density, in regions where q has high mass. We have ex plored several different heuristics for this task, all of which follow roughly the same scheme: generate a density esti mate for p, and then modify it to fit q. The approach which worked best in our experiments is quite simple. We gener ate samples from p (which in our case is ?j,J (Si,J) ), thereby generating more samples in the \"right\" regions. We then weight the samples by qfp, making them estimates to the desired distribution. Finally, we apply density estimation to the resulting weighted samples.\nOur solution above estimated 'Tii-+ i using the approximate potential ?j,J for Ci. However, when we are computing\nApproximate Inference in Hybrid Bayes Nets 327\nT/i-+J\u2022 we do not yet have ?j,J; indeed, we are computing 7Ji-+ i for the express purpose of using it to compute ?j, i. There are two ways to resolve this problem. The first is to use our current best approximation to the potential in C i. While this approach might seem plausible, it is misguided. We should be sending a message from C; to Ci only if C; has information not available in C i. Thus, any approxima tion we might have in C i is known to be flawed, and we should not use it to guide our message approximation. The second solution is based on the observation that we are only interested in the marginal of ?j,i over S;,j. We have another approximation to this marginal - ?j,;(S;,j). As we men tioned, the fact that we need to send a message from C; to Ci indicates that C; is more informed (in some sense) than Ci. Thus, we use ?j,;(S;,j) to guide our approxima tion to the message 7];-+ j. Of course, this intuition is only partially valid: there may be other ways in which C J is more informed than C;. In general, we note that the choice of function to guide our approximation is only a heuristic, and does not influence the \"correctness\" of the message. This function is used only to derive the sampling distribu tion; the weights on the samples guarantee that the actual function being approximated is ?Ji-+i.\nThis observation immediately leads to the final major im provement to our basic algorithm: the iterative improve ment of the messages. When we send a mess\ufffdge from C; to Cj. we rely on our current approximation 1/J;. Later on, C; may get a message from CJ or from some other clique, which leads to a more accurate approximation ?j,;. If C; sends a message to Ci using this new improved approxi mation as the basis for approximating T/i-+ J, the resulting approximate message iJH J will almost certainly be more reliable. If fji-+ i is more reliable, then outgoing messages from C i will also be more reliable. Thus, our algorithm is an iterative improvement algorithm. It continues to ill} prove its current best estimate for each clique potential1f;; to produce more accurate message. These more accurate messages are, in turn, used to compute more accurate ap proximate potentials in the destination cliques.\nWe are now ready to present our general algorithm. At this point we leave many issues open to different implementa tions. We later show how several existing algorithms are instances of this general scheme, and present one new in stantiation of it in detail.\nThe first phase is virtually the same as Algorithm I, except that an approximate computation is used in place of an ex act one. We omit details. In the second phase, the algorithm iterates over the cliques, trying to improve its approxima tion of the potentials and the messages:\nAlgorithm 2: Iteration phase for approximate propagation 01: repeat 02: choose some clique C; 03: approximate {1; = TI(j,i)EC f/j-+i x <Pi\n328 Koller, Lerner, and Angelov\n04: set ,j,, = ,f,; 05: for some or all ( i, j) E [ 06: generate an estimate /Ji\ufffdJ to L:oom(c,,i)\n,J,; 07: reweigh! J.Li\ufffdi by ([11,#1 TJJ'\ufffdi x \u00a2i)j,f,, 08: until convergence\nIntuitively, the algorithm repeatedly selects a clique for im provement (using some criterion). It estimates the revised clique potential, and uses that as the basis for re-estimating some or all of the messages. As described above, each mes sage is first estimated to match the current potential. It is then reweighted to make it represent the correct function that ci should send to c j. Clearly, there are many instantiations to this general schema. For example, the algorithm can select which clique potential to update in a variety of ways. The simplest and cheapest approach, which is the one we used, is to exe cute repeated upward and downward passes, mirroring the computation in standard clique tree inference. Also, as we mentioned earlier, the approximation phase can be done in many ways. One approach is to use importance sampling, possibly followed by density estimation. In our particu lar instantiation of the algorithm, all approximations were done using this technique. In the initial calibration phase, we use an approximation to the prior distribution (before any evidence is inserted) as the sampling distribution. We obtain this approximation to the prior distribution by sam pling the original BN, using the simple top-down sampling algorithm. Our ability to do this effectively is due precisely to the fact that we are sampling from the prior. In the itera tion phase, we use our current posterior 1/Ji as the sampling distribution, as discussed above.\n4 Algorithm for hybrid BNs\nIn this section, we describe in detail one instantiation of the general approach described above, designed to perform effective inference in general hybrid BNs.\nAlgorithms for exact inference in hybrid BNs are applica ble only to very narrow families ofBNs (multivariate Gaus sians [ 18) or, in some sense, conditional Gaussians [ 15)). Our algorithm is very general in the sense it can deal with virtually any function for the CPO, as long as we can com pute the value of the function at a point, and sample a value for the node from the conditional density defined by a par ticular assignment to its parents. This flexibility allows our algorithm to deal with significantly more interesting mod els. In particular, our algorithm is capable of handling ar bitrary dependencies, including ones where a discrete node has continuous parents. Our initial implementation incor porates a few basic yet flexible CPOs that allow us to rep resent a fairly wide range of models.\nFor a discrete child with discrete parents, we implemented the standard conditional probability table model. For\na continuous node with discrete and continuous parents, we implemented the standard conditional linear Gaussian model [15]. In this model the child's mean is a linear func tion of the continuous parents, and its covariance is fixed. We have a separate linear Gaussian model for the child for every value of the discrete parents. We also allow uniform distributions.\nW hile these CPOs are fairly standard, we also defined a new class of CPOs for modeling the dependence of a dis crete node on discrete and continuous parents. This CPO is an interesting and useful generalization of the standard softmax density [I]. As for the conditional linear Gaussian CPO, our softmax CPO will have a separate component for each instantiation of the discrete parents. Therefore, it suf fices to describe the model for the case where the discrete node has only continuous parents. Intuitively, the softmax CPO defines a set of R regions (for some parameter R of our choice). The regions are defined by a set of R linear functions over the continuous variables. A region is char acterized as that part of the space where one particular lin ear function is higher than all the others. Each region is also associated with some distribution over the values of the discrete child; this distribution is the one used for the variable within this region. The actual CPO is a continuous version of this region-based idea, allowing for smooth tran sitions between the distributions in neighboring regions of the space.\nMore precisely, let C be a discrete variable, with contin uous parents Z = { Z1, \u2022 \u2022 . , Zm}. Assume that C has k possible values, { c1, c2, ... , ck}. Each of the R regions is defined via two vectors of parameters a r, pr. The vec tor ar is a vector of weights a(j, a[, ... , a:;, specifying the linear function associated with the region. The vec tor pi = {Pi, . . . , pk} is the probability distribution over c1, . . . , ck associated with the region (i.e., L:\ufffd=l pj = 1). The CPO is now defined as: P( C = Cj I Z) = L:\ufffd=l wrpj exp(a0+ L:= a; z,) where w\" = \"R \u00b7_.;= . In other words, the L.., q=l exp(a:6+ L.., i=l af Z;) distribution is a weighted average of the region distribu tions, where the weight of each \"region\" depends exponen tially on how high the value of its defining linear function is, relative to the rest.\nThe power to choose the number of regions R to be as large as we wish is the key to the rich expressive power of the generalized softmax CPO. Figure I demonstrates this ex pressivity. In Figure I (a), we present an example CPO for a binary variable with R = 4 regions. In Figure I (b), we show how this CPO can be used to represent a simple clas sifier. Here, C is a sensor with three values: low, medium and high. The probability of each of these values depends on the value of the continuous parent X. Note that we can easily accomodate a variety of noise models for the sen sor: we can make it less reliable in borderline situations by\nmaking the transitions between regions more moderate; we can make it inherently more noisy by having the probabili ties of the different values in each of the regions be farther away from 0 and I .\nPerhaps the most important decision in using our general algorithm is the decision on the actual representation of the potentials. In our case we needed a representation that en ables us to express hybrid density functions. Furthermore, we were looking for a representation from which samples can be generated easily, and which can, in turn, be easily estimated from a set of samples.\nWe chose to focus on Density Trees [13]. The structure of a density tree resembles that of a classification decision tree; however, rather than representing the conditional distribu tion of a class variable given a set of features, a density tree simply represents an unconditional density function over its set of random variables X. A density tree has two types of nodes: interior nodes and leaves. An interior node u de fines some set of mutually exclusive and exhaustive events Et, ... , Ei:. Each branch from u corresponds to one of the events. The definition allows for arbitrary events; for ex ample, we may have an interior node with three branches, corresponding to X2 < 3, 3 ::; X2 < 5 and X2 2 5. This definition generalizes that of [13]. The edge corresponding to the outcome Ei is labeled with the conditional probabil ity of Ei given all the events on the path from the root to node u. We define the probability of a path as the product of all the probabilities along the path, i.e., the probability of the conjunction of the events along the path.\nA leaf in the tree corresponds to some probability distribu tion consistent with events on the path leading to it (i.e., ev erything that is inconsistent with the path events has prob ability zero). To find the probability of some instantiation x, we traverse the tree from the root to a leaf on the unique path which is consistent with x. During this traversal, we compute the path probability. We then multiply the path probability by the probability assigned to x in the leaf.\nAs in [ 13], our implementation only uses events which are all the possible values of discrete variables (i.e., for every possible value we get one branch). This restriction simpli fies the learning algorithm. It also means that the value of any variable appearing in the path is determined at the leaf; thus, at each leaf, we simply use a a joint distribution over the remaining variables. We have chosen a fairly simply representation at the leaves. The discrete variables are as sumed to be independent, so we simply keep the marginal distribution of each one. (Dependency will be manifested as more splits in the tree.) The continuous variables are also independent of the discrete variables. The multivariate distribution over the discrete variables is represented as a mixture of Gaussians.\nThe basic operations which must be supported by density trees are computing the probability of some instantiation,\nApproximate Inference in Hybrid Bayes Nets 329\nmarginalization, introducing evidence into the tree (as the instantiation of the random variables in the tree) and sam pling. All these operations are fairly easy to implement. Marginalization and instantiation can be done in time lin ear in the size of the tree, while sampling and finding the probability of some instantiation can be done in time linear in the depth of the tree. Note that other possible represen tations of a joint density (e.g., as a BN) do not necessarily have these linear time guarantees.\nIt remains only to describe the process by which the den sity tree, with the Gaussian mixture at the leaves, is con structed from our weighted samples. To build the tree, we start recursively from the root. At each node u, we deter mine which discrete variable we want to split on. As dis cussed in [13], the relative entropy between the empirical distribution in u before and after the split is an appropriate error function. In the work of [13], uniform distributions were used at the leaf, leading to a very simple splitting cri terion. In our case, uniform leaf distributions are clearly less appropriate; our representation of the leaf as a prod uct of multinomials and a mixture of gaussians allows for much more accurate density learning. However, the asso ciated splitting rule (using the relative entropy error func tion) is now much more expensive to compute. Instead, we used a very simple heuristic rule: splitting on the variable which partitions the samples as equally as possible among the branches. Even with this simple heuristic, the density trees yield good results. In order to avoid overfitting, we stop splitting a node when it contains less than some mini mal number of samples.\nNote that the splitting criterion and the splitting rule are based on the samples themselves, rather than on the weight. This property is particularly helpful in tailoring the esti mate of the message to be accurate in areas where the clique potential is large. The samples are generated from the clique potential, so there will be more samples in re gions where the clique potential has high density; this leads to a more refined partition in those regions, even if the mes sage density there is low.\nWhen the leaves are reached, the marginals of the discrete variables are estimated using a simple Bayesian estimation algorithm with a Dirichlet prior for regularization. The density over the continuous variables is estimated as a mix ture of Gaussians, each with a diagonal covariance matrix. We execute this estimation using a variant of the standard EM algorithm [4] for Gaussian mixtures.\nUnfortunately, EM is not as well-behaved for Gaussian mixtures as it is in discrete settings. The problem is that the likelihood of the data can be arbitrarily large, if we al low the variance of the estimated Gaussians to go to zero. There are several techniques for preventing this situation. We experimented with two of them. One is a simple and commonly used technique, where we assume that all of the\n330 Koller, Lerner, and Angelov\nGaussians in the mixture have the same covariance matrix. The second, which turned out to work much better, is a version of EM that minimizes a regularized error function rather than the standard negative log-likelihood error func tion (this is analogous to the regularized error function for neural networks in [!]).\nSpecifically, let y[l], ... , y[M] represent our training in stances, each of which is an instantiation of the variables Y1, \u2022 . . , Yn. (For simplicity, we ignore the weights on the instances.) Assume that we are trying to estimate the dis tribution as a mixture of K Gaussians. The EM algorithm, in this setting, uses the current set of parameters 9 (means and variances for the K Gaussians and the weights of the mixture components) to estimate P(k I y[m], 9) for every Gaussian k = 1, . . . , K and every data instance m. It then uses the results to minimize the negative log-likelihood function -In\u00a3 = - L:m In P(y[m]) leading to the stan dard update rules for the means and covariances (see [I]). Instead, we try to minimize a regularized error function, which penalizes the algorithm for letting the variances get too small. Letting at denote the variance of Y; in the k th mixture component, we define our error function to be - In\u00a3 + >. L:k L:\ufffd=! 2=21 , where >. is a regularization co-\nu,d\nefficient that determines the extent of the penalty. Taking the derivative relative to a ki and setting to zero, we obtain that the setting of Oki that minimizes this function is\n2 _ L:m P(k I y[m], 8)(y;[m]- Yki)2 A 0ki - L:m P(k I y[m], 8) + L:m P(k I y[m], 8)'\nwhere fh; is the mean of Gaussian k in the i-th dimension. The first part of this expression is identical to the standard EM update rule for Oki\u00b7 The second part causes the covari ance to be larger than is warranted by the data. Note that the extent of the increase depends on the weight of samples assigned firmly to this mixture component: the more sam ples that are associated firmly with this Gaussian, the less effect the second term has on the variance. This is precisely the behavior we would like. Indeed, as we can see in the next section, the use of a regularization coefficient leads to significantly better results.\nIt is instructive to compare our algorithm to the simple pre-discretization approach, most often used in BNs. The main problem is that high-dimensional cliques over finely discretized variables are too large to fit in memory, mak ing exact inference impractical. But even if we ignore the memory constraints, there are many domains where pre discretization is impossible. For one, we may want to adapt the parameters as new data is obtained, requiring a re-discretization each time. Furthermore, in some cases, the function might be too expensive to evaluate more than a small number of times. One example of such a function comes up in the visual tracking domain, where we have a CPD defining the probability of an image given the state of the system. Computing this function involves a geometric projection and rendering, and is quite expensive.\n5 Experimental Results\nWe tested our algorithm using two networks. The first is a continuous version of the real-life BAT network of [5]. In most of our experiments we used three time slices of the BAT network, leading to 72 variables of which 23 are continuous. We also wanted to test a network with contin uous parents of a discrete node, which our version of BAT does not have. We constructed another small hybrid BN, shown in Figure I (c), which models a simple thermostat. The Thermostat Reading variable is a classifier node, as described above.\nTo evaluate our algorithm we needed to find a good ap proximation to the ground truth. To do so, we discretized the continuous variables in the two BNs into 100 discrete values each. We then computed the KL-distance between the result of the exact inference in the discrete network and a discretization of the result of approximate inference in the hybrid network. We refer to this measure as the KL-error. Note that obtaining such an accurate discrete estimator can not be done for general networks, as discussed before. In our experiments, we had to ensure that no clique in the tree contained more than four continuous variables.\nWe begin by investigating the influence of A, the regular-\nization coefficient used in EM. We first consider the pure density estimation problem, temporarily ignoring our al gorithm. Figure 2(a) shows the result of fitting 10 Gaus sians to a set of samples which was created during one of the runs (and is shown on the top right side) using three different values for A. one of the runs using three differ ent values for A. In this example, A = 0.001 overfits the data, A = 1000 does not capture correctly the area in which the samples are concentrated, but A = 10 seems to give a plausible result. Examining the KL-error after running our algorithm gives similar results. In this case, we averaged 5 runs over the thermostat network (querying the outside temprature at time 0, given the thermostat readings at both times). The graph shows the KL-errors after each iteration, where each iteration is defined as one pass of propagation in the clique tree (either up-stream or down-stream). When A is too small we get Gaussians with very small variance. As a result we get an estimation of almost 0 density in some areas where the true density is larger. This leads to a very big KL-error, as shown in the graph. On the other hand, when A is too big we get an estimation which is almost a uniform distribution. This gives a much smaller KL-error, but is not a useful estimation. Again, A = 10 seems to give good results.\nThe most important parameter which influences the run ning time of the algorithm is the number of samples drawn in every clique. The following table shows the time per it eration (on a Sun Ultra 2) on the BAT network as a function of the number of samples, and the average KL-error over 12 iterations. Here, there were 58 cliques in the join tree.\nThe results are hardly surprising. The running time of the algorithm grows linearly with the number of samples and the error decreases when we increase the number of sam ples. A natural improvement to the algorithm is to start with a relatively small number of samples in order to get some initial estimate of the potentials, and then increase the number of samples in later iterations.\nApproximate Inference in Hybrid Bayes Nets 331\nLike all sampling algorithms, our algorithm is sensitive to the likelihood of the evidence. However, we claim that the iterative nature of our algorithm solves this problem, at least partially. We tested our algorithm using the 3 time slice BAT network. In every time slice, BAT contains the continuous variables Xdot- the velocity of the car in the X axis (i.e., \\eft-right movement), and Xdot-sensed- the sensed value of Xdot. With probability 0.9999 the sensor is functional and the reading is Xdot plus some gaussian noise. With probability 0.0001 the sensor is broken and the reading is uniform, independent of Xdot.\nWe tested two scenarios. In both of them we instantiated Xdot at time 0 and Xdot-sensed at time 2 and queried Xdot sensed at time I. In the first case, we instantiated the vari ables to relatively close values, a likely situation. In the second, we used very different values, leading to a very un likely scenario; in fact, using our exact discrete inference, we found that the probability of the sensor being broken in this case went up to 0.3. As expected, our algorithm per formed much better in the first case. This is demonstrated in Figure 3. In (a) we see the density estimation of Xdot sensed at time I for the easy case. As expected the algo rithm converges quickly to the correct answer. In (b) we see the convergence in the second and more difficult case. This time the quality of the estimation is not as good and the convergence is slower. However, in some sense the sec ond scenario is even more encouraging than the first. Our algorithm seems to slowly improve the quality of the esti mation. The fact that the density does not go to zero far from the peak indicates that in later iterations the algorithm correctly identified the relatively high probability that the sensor is broken. Part (c) further demonstrates this point using the KL-error in the two cases.\nFinally, it is interesting to compare the performance of our algorithm and Likelihood Weighting. To do a fair compar ison, we gave each one of the algorithms the same CPU time and compared their KL-error. Since our algorithm takes advantage of the structure of the network to reduce to dimensionality of the samples drawn, we expected our algorithm to scale up much better when a lot of evidence is introduced to the network. To test this hypothesis we ran two experiments- in one we had only one evidence node while in the other we had 12 evidence nodes (note that we did not use unlikely evidence). In both cases we queried the same node (Xdot at time 1). The results (averaged over ten runs) are given in Figure 4. In (a), we see that LW provides a rough initial estimate after a very short time, whereas our algorithm requires some time to perform the initial clique estimation and the first iteration. After this startup cost, it seems that our algorithm outperforms LW even for just one evidence node. The difference becomes much more dramatic in the presence of more evidence. While the per formance of LW degrades severly, our algorithm is almost unaffected by the extra evidence.\n332 Koller, Lerner, and Angelov\n6 Existing instances of our approach\nSeveral known approximate inference algorithms turn out to be special cases of our general scheme. By viewing them from this perspective, we can understand their rela tionship to other inference algorithms. More importantly, we can sometimes point out ideas for possible improve ments based on our general approach. We briefly sketch the crucial properties of the mapping.\nConditional Gaussian (CG) networks [15]: In this algo rithm, the representation of the clique potentials is a table, with one entry for each combination of the discrete vari ables in the clique. In each entry, the table specifies a single multivariate Gaussian over the continuous variables in the clique. The approximate computation of messages is done using an \"exact\" algorithm, i.e., one that gets the best Gaus sian approximation to the factor. Lauritzen shows that this algorithm preserves the correct first and second moments throughout the propagation, so that the algorithm is \"ex act\" with respect to these. Thus, further iterations would not improve the quality of the result.\nHybrid Propagation [3, 6] and HUGS [12]: This fam ily of algorithms is quite closely related to ours, as it also uses sampling as a substitute for exact operations within a clique. However, it is restricted to messages that are vectors\nof weighted samples, and does not use any type of density estimation for smoothing. More importantly, the algorithm only samples once in a clique, and the variable is then re stricted to take on one of the sampled values. If the sam pled values are poor (due, for example, to an uninformed sampling distribution prior to message propagation), the re sulting value space for the variable can potentially badly skew the remainder of the computation. None of these al gorithms contain an iterative phase (such as ours); such a phase may help address this limitation.\nDynamic discretization [14]: This algorithm, which also works for hybrid BN s, is another instance of our general ap proach. It uses a piecewise-constant representation of the domain of the continuous variables in a clique. The repre sentation is structured hierarchically, with regions split into finer pieces further down the tree. Unlike most of the other instances, this algorithm has an iterative phase. However, its iterations are limited to complete upward and downward passes. Our algorithm is more flexible in its ability to con centrate the computational efforts on some specific areas of the clique tree where the approximation is inaccurate.\nLikelihood Weighting [19]: Roughly speaking, this algo rithm samples from the BN, weighting each sample based on the likelihood of their evidence relative to this sample. It can be viewed as a special case of our algorithm where the clique tree has a single clique, containing all of the net work variables. The representation of the densities is a set of samples, and only a single iteration is performed. If we introduce further iterations, the algorithm turns into a boot strap sampling algorithm, where one set of samples is used as the basis for further sampling. If we add a density esti mation step, the algorithm turns into a smoothed bootstrap algorithm.\nSurvival of the Fittest (SOF) [11] and its exten sions [13]: These algorithm performs monitoring in a dy namic Bayesian network (DBN). It maintains a belief state - a distribution over the current state given the evidence so far. SOF maintains the belief state at time t as a set of weighted samples. To get the time t + 1 samples, SOF\nsamples from the time t samples proportionately to their weight, stochastically propagates them to the next time slice, and weights them by the likelihood of the time t + 1 evidence. In terms of the general approach, the algorithm performs a single forward pass over the basic clique tree for the unrolled DBN: the one containing a clique for every pair of consecutive time slices. The message is generated using simple importance sampling. The extension of [ 13] can be viewed as augmenting the importance sampling at each clique with a density estimation phase.\n7 Conclusions\nIn this paper, we presented a general approximate inference algorithm for Bayesian Networks. Our algorithm can best be viewed as a general schema which can be instantiated in different ways based on the representation scheme and the different ways to manipulate it. Many well known infer ence algorithms turn out to be a special case of this general view. Our approach combines the best features of exact and approximate inference: like approximate inference al gorithms, it can deal with complex domains, including hy brid networks; like the clique tree algorithm, it exploits the locality structure of the Bayes net to reduce the dimension ality of the probability densities involved in the computa tion.\nWe described one particular instantiation of our algorithm that uses Monte Carlo Importance Sampling, combined with density estimation, in order to estimate the necessary functions. This particular instantiation is very general in the sense that all that is required from our factor represen tation is the ability to sample from factors. Hence, it allows us to provide a general-purpose approximate inference al gorithm for arbitrary hybrid BNs. We have presented em pirical results showing that our algorithm gives good results for nontrivial networks. We believe that our algorithm has the ability to scale up to significantly larger problems (such as visual tracking in complex environments), where exist ing inference algorithms are infeasible.\nAcknowledgments.\nWe would like to thank Ron Parr, Xavier Boyen and Si mon Tong for useful discussions. This research was sup ported by ARO under the MURI program, \"Integrated Ap proach to Intelligent Systems,\" grant number DAAH0496-I-0341, by DARPA contract DACA76-93-C-0025 un der subcontract to lET, Inc., and by the generosity of the Powell Foundation and the Sloan Foundation.\nReferences\n[I] C. M. Bishop. Neural networks for pattern recognition. Ox ford University Press, 1995.\nApproximate Inference in Hybrid Bayes Nets 333\n[2] T. Cover and J. Thomas. Elements of Information Theory. Wiley, 1991.\n[3] A.P. Dawid, U. Kjrerulff, and S.L. Lauritzen. Hybrid propa gation in junction trees. In Advances in Intelligent Comput ing, volume 945. Springer- Verlag, 1995.\n[4] A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum likelihood from incomplete data via the EM algorithm. J. Royal Statistical Society, B39:1-38, 1977.\n[5] J. Forbes, T. Huang, K. Kanazawa, and S.J. Russell. The BATmobile: Towards a Bayesian automated taxi. In Proc. IJCAI, 1995.\n[6] L. D. Hernandez and S. Moral. Mixing exact and importance sampling propagation algorithms in dependence graphs. International Journal of Intelligent Systems, 12:553-576, 1997.\n[7] T. Huang, D. Koller, J. Malik, G. Ogasawara, B. Rao, S.J. Russell, and J. Weber. Automatic symbolic traffic scene analysis using belief networks. In Proc. AAAI, 1994.\n[8] M. Isard and A. Blake. Contour tracking by stochastic prop agation of conditional density. In Proc. ECCV, volume I, 1996.\n[9] T. Jaakola and M. Jordan. Computing upper and lower bound on likelihoods in intractable networks. In Proceed ings of the Tweljh Annual Conference on Uncertainty in Ar tificial Intelligence (VAl '96), pages 340-348, 1996.\n[10] F.V. Jensen, S.L. Lauritzen, and K.G. Olesen. Bayesian up dating in recursive graphical models by local computations. Computational Statistical Quarterly, 4, 1990.\n[II] K. Kanazawa, D. Koller, and S.J. Russell. Stochastic sim ulation algorithms for dynamic probabilistic networks. In Proc. VAl, pages 346-351, 1995.\n[12] U. Kjrerulff. HUGS: combining exact inference and Gibbs sampling in junction trees. In Proc. VAl, 1995.\n[13] D. Koller and R. Fratkina. Using learning for approximation in stochastic processes. In Proc. ICML, 1998.\n[14] A. Kozlov and D. Koller. Nonuniform dynamic discretiza tion in hybrid networks. In Proc. VAl, pages 314-325, 1997.\n[15] S. L. Lauritzen. Propagation of probabilities, means, and variances in mixed graphical association models. Journal of American Statistical Association, 87: I 098-1108, 1992.\n[16] S.L. Lauritzen and D.J. Spiegelhalter. Local computations with probabilities on graphical structures and their applica tion to expert systems. J. Roy. Stat. Soc., B 50, 1988.\n[17] Radford M. Neal. Probabilistic inference using markov chain monte carlo methods. Technical Report CRG-T R-931, University of Toronto, 1993.\n[18] R. Shachter and C. Kenley. Gaussian influence diagrams. Management Science, 35:527-550, 1989.\n[19] R. D. Shachter and M. A. Peot. Simulation approaches to general probabilistic inference on belief networks. In Proc. VAl, 1989.\n[20] P.P. Shenoy and G.R. Shafer. Axioms for probability and belief-function propagation. In Proc. VAl, volume 4, pages 169-198, 1990."}], "references": [{"title": "Neural networks for pattern recognition", "author": ["C.M. Bishop"], "venue": "Ox\u00ad ford University Press,", "citeRegEx": "Bishop.,? \\Q1995\\E", "shortCiteRegEx": "Bishop.", "year": 1995}, {"title": "Hybrid propa\u00ad gation in junction trees", "author": ["A.P. Dawid", "U. Kjrerulff", "S.L. Lauritzen"], "venue": "In Advances in Intelligent Comput\u00ad ing,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1995}, {"title": "Maximum\u00ad likelihood from incomplete data via the EM algorithm", "author": ["A.P. Dempster", "N.M. Laird", "D.B. Rubin"], "venue": "J. Royal Statistical Society,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1977}, {"title": "The BATmobile: Towards a Bayesian automated taxi", "author": ["J. Forbes", "T. Huang", "K. Kanazawa", "S.J. Russell"], "venue": "In Proc. IJCAI,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1995}, {"title": "Mixing exact and importance sampling propagation algorithms in dependence graphs", "author": ["L.D. Hernandez", "S. Moral"], "venue": "International Journal of Intelligent Systems,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1997}, {"title": "Automatic symbolic traffic scene analysis using belief networks", "author": ["T. Huang", "D. Koller", "J. Malik", "G. Ogasawara", "B. Rao", "S.J. Russell", "J. Weber"], "venue": "In Proc. AAAI,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1994}, {"title": "Contour tracking by stochastic prop\u00ad agation of conditional density", "author": ["M. Isard", "A. Blake"], "venue": "In Proc. ECCV,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1996}, {"title": "Computing upper and lower bound on likelihoods in intractable networks", "author": ["T. Jaakola", "M. Jordan"], "venue": "In Proceed\u00ad ings of the Tweljh Annual Conference on Uncertainty in Ar\u00ad tificial Intelligence (VAl", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1996}, {"title": "Bayesian up\u00ad dating in recursive graphical models by local computations", "author": ["F.V. Jensen", "S.L. Lauritzen", "K.G. Olesen"], "venue": "Computational Statistical Quarterly,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1990}, {"title": "Stochastic sim\u00ad ulation algorithms for dynamic probabilistic networks", "author": ["K. Kanazawa", "D. Koller", "S.J. Russell"], "venue": "In Proc. VAl,", "citeRegEx": "Kanazawa et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Kanazawa et al\\.", "year": 1995}, {"title": "HUGS: combining exact inference and Gibbs sampling in junction trees", "author": ["U. Kjrerulff"], "venue": "In Proc. VAl,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1995}, {"title": "Using learning for approximation in stochastic processes", "author": ["D. Koller", "R. Fratkina"], "venue": "In Proc. ICML,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1998}, {"title": "Nonuniform dynamic discretiza\u00ad tion in hybrid networks", "author": ["A. Kozlov", "D. Koller"], "venue": "In Proc. VAl,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1997}, {"title": "Local computations with probabilities on graphical structures and their applica\u00ad tion to expert systems", "author": ["S.L. Lauritzen", "D.J. Spiegelhalter"], "venue": "J. Roy. Stat. Soc., B", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1988}, {"title": "Probabilistic inference using markov chain monte carlo methods", "author": ["Radford M. Neal"], "venue": "Technical Report CRG-T R-931,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1993}, {"title": "Gaussian influence diagrams", "author": ["R. Shachter", "C. Kenley"], "venue": "Management Science,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1989}, {"title": "Simulation approaches to general probabilistic inference on belief networks", "author": ["R.D. Shachter", "M.A. Peot"], "venue": "In Proc. VAl,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1989}, {"title": "Axioms for probability and belief-function propagation", "author": ["P.P. Shenoy", "G.R. Shafer"], "venue": "In Proc. VAl,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1990}], "referenceMentions": [], "year": 2011, "abstractText": "The clique tree algorithm is the standard method for doing inference in Bayesian networks. It works by ma\u00ad nipulating clique potentials distributions over the variables in a clique. While this approach works well for many networks, it is limited by the need to maintain an exact representation of the clique potentials. This paper presents a new unified approach that combines approximate inference and the clique tree algorithm, thereby circumventing this limitation. Many known approximate inference algorithms can be viewed as instances of this approach. The algorithm essentially does clique tree propagation, using approximate infer\u00ad ence to estimate the densities in each clique. In many settings, the computation of the approximate clique potential can be done easily using statistical impor\u00ad tance sampling. Iterations are used to gradually im\u00ad prove the quality of the estimation.", "creator": "pdftk 1.41 - www.pdftk.com"}}}