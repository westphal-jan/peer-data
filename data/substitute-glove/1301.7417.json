{"id": "1301.7417", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jan-2013", "title": "Planning with Partially Observable Markov Decision Processes: Advances in Exact Solution Method", "abstract": "There is making concern far specifically separated observable Markov answer computation (POMDPs) there a formal comparison for focused both inverse domains. This making is concerned each actually optimal encouraged another POMDPs. We drafting have productivity while incremental pruning, housed the have efficient circumstances optimisation there solving POMDPs.", "histories": [["v1", "Wed, 30 Jan 2013 15:07:12 GMT  (320kb)", "http://arxiv.org/abs/1301.7417v1", "Appears in Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence (UAI1998)"]], "COMMENTS": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence (UAI1998)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["nevin lianwen zhang", "stephen s lee"], "accepted": false, "id": "1301.7417"}, "pdf": {"name": "1301.7417.pdf", "metadata": {"source": "CRF", "title": "Planning with Partially Observable Markov Decision Processes: Advances in Exact Solution Method", "authors": ["Nevin L. Zhang", "Stephen S. Lee"], "emails": [], "sections": [{"heading": null, "text": "There is much interest in using par tially observable Markov decision processes (POMDPs) as a formal model for planning in stochastic domains. This paper is concerned with finding optimal policies for POMDPs. We propose several improvements to incre mental pruning, presently the most efficient exact algorithm for solving POMDPs.\n1 Introduction\nPartially ob servab le Mark ov decision pro cesses (POMDPs) model sequential decision making problems where effects of actions are nondeterministic and the state of the world is not known with certainty. A POMDP consists of (1) a set S of possible states of the world, which is assumed to be finite in this paper, (2) a finite set A of possible actions, (3) a finite set CJ of possible observations. At each point in time, the world is in one of the possible states. An agent receives an observation o according to an ob servation prob ab il ity P(ois, a_), which depends on the current states of the world and the action a_ just executed. The mi nus sign in the subscript indicates the previous time point. The agent also chooses and executes an action. After an action a is executed, the agent receives an im mediate reward r(s, a) and the world probabilistically moves into another state s+ according to a transition prob ab ility P(s+is, a). The plus sign in the subscript indicates the next time point.\nThe agent chooses actions based on its knowledge about the state of the world, which is summarized by a probability distribution over S. The proba bility distribution is sometimes called a b elief state. Let b be the current belief state. If the agent ob serves o+ after taking action a, then its next belief state b + is given by b +(s+) = c L:s P(s+, o+is, a)b(s) ,\nwhere P(s+, o+ls, a)=P(o+ls+, a)P(s+ls, a) and c is the renormalization constant.\nA policy maps each belief state to an action. A policy is optimal if it maximizes the expected long-term dis counted reward. Value iteration is a standard way for finding policies that are arbitrarily close to optimal. It begins with an arbitrary initial function V0* (b ) of belief states and iterates using the following equation\nl't*(b) = maxa[r(b, a)+ A L P(o+ib, a)1't\ufffd1 (b +) ], O+\nwhere P(o+lb,a)=l:s,s+P(o+,s+is,a)b(s) is the probability of observing o+ after executing action a in belief state b and where A (0<A<1) is a discount factor. Value iteration terminates when the Bellman residual maxbll't*(b) - 1't:._1 (b ) j, where the maximum is taken over all possible belief states, falls below a predetermined threshold t:. An policy is then obtained through one step lookahead (e.g. Cassandra 1994) .\nSince there are uncountably infinite many belief states, value iteration cannot be carried out explicitly. Fortu nately, it can be carried out implicitly. Sondik (1971) has shown that if there exists a finite set Vt of func tions of s, henceforth called vectors, that represents 1't* in the sense that for all belief states b\nl't*(b) = maxaEV, L a(s)b(s), 8\nthen there exists a finite of vectors that represents 1't+1. If one begins with a function V0*, say 0, that can be represented by a finite set of vectors, then ev ery 1't* can be represented by a finite set of vectors. Instead of computing 1't* explicitly, one can compute a set Vt of vectors that represents 1't*.\nThe process of obtaining a minimal set of vectors that represents 1't+1 from a minimal set of vectors that represents 1't* is called dynamic-programmin g update (Littman et al 1995 ) . It is of fundamental impor tance to POMDPs. Previous algorithms for dynamic programming updates include one-pass (Sondik 1971 ) ,\n524 Zhang and Lee\nexhaustive (Monahan 1982) , Lark (White 1991) , linear support (Cheng 1988) , witness (Littman et al 1995) , and incremental pruning (Zhang and Liu 1997) . Incre mental pruning is the simplest among all those algo rithms and preliminary experiments have shown that it is also the most efficient (Cassandra et al1997) .\nThis paper proposes a number of improvements to in cremental pruning. We will begin with a formal state ment of the dynamic-programming update problem (Section 2 ) and a brief review of incremental pruning (Section 3). We will then introduce the improvements (Sections 4 and 5) and discuss the pros and cons. Ex perimental results will be presented in Section 6 and conclusions provided in Section 7.\n2 Dynamic-programming updates\nTo formally state the dynamic-programming update problem, we need several operations on and concepts about sets of vectors. Suppose W and X are two sets of vectors over the state space. The cross sum of W and X is a new set of vectors given by\nWEfJX = {a+f3iaEW,/3EX}.\nIt is evident that the cross sum operation is com mutative and associative. Hence one can talk about the cross sum of more than two sets of vectors. Let f(s+, s) be a function of s+ and s. The matrix mul tiplication of W and f is a new set of vectors given by\nW*f = {,BI3aEW s.t.,B(s+)= L: a(s+)f(s+,s)Vs+} S+\nFor any number .X, define .XW = {Aaia E W}.\nA subset W' of W is a covering of W if for any belief state b, there exists a' EW' such that a'. b ;::: a. b for all aEW. Here a'.b and a.b are the inner products of a' and a with b. A covering of W is parsimonious if none of its proper subsets are coverings of W. If W is a parsimonious covering of itself, we say that W is parsimonious.\nLet B be the set of all belief states. The witness re gion R(a, W) and the closed witness region R(a, W) of a vector aEW w.r.t Ware subsets of B respectively given by\nR(a, W) = {bEBia. b>a'. b Va'EW\\{a}},\nR(a, W) = {bEBia. b;:::a'.b Va'EW\\{a}}. It can be proved (Littman et al1995) that W has a unique parsimonious covering and it is given by\nPC(W) = {aiR(a, W) f: 0}.\nA point in R(a, W) is called a witness point for a be cause it testifies to the fact that a is in the parsimo nious covering PC(W). A point in R(a, W)\\R(a, W) is called a b oundary point for a.\nGoing back to value iteration, suppose V is a set of vectors that represents the function \ufffd*. Given action a and observation o+, P(o+, s+is, a) is a function of s+ and s. Moreover r( s, a) is a function of s and hence can be viewed as a vector over the state space. Define\nVa,o+ = .\\V*P(o+, s+is, a), Va = EfJVa,o+' U = Ua[{r(s, a)} EfJ Va]\u00b7 (1)\n0+\nSondik (1971) has shown that the set U of vectors rep resents the function \ufffd\ufffd1-1. Consequently, the dynamic programming update problem can be formally stated as follows:\nGiven a parsimonious set V of vectors, find the parsimonious covering for the set U given by equation (1) .\n3 Incremental pruning\nThis section reviews the incremental pruning algo rithm. We begin by considering the parsimonious cov ering of the cross sum of two sets W and X of vec tors. For any aEW and any ,BE X, the vector a+,B appears in the parsimonious covering PC(WffiX) if and only if the witness region a intersects with that of ,8, i.e. when R(a, W)nR(,B, X)f:0. Consequently, the parsimonious covering PC(WEf)X) can be obtained using the following procedure. The name CSP stands for cross-sum-pruning.\nProcedure CSP(W, X): 1. y +- 0. 2. For each aEW and each ,BEW, 3. If R(a, W)nR(,B, X)f:0, Y +- {a+,B} u Y. 4. Return Y.\nWhether the two witness regions R(a, W) and R(/3, X) intersect can be determined by solving the following linear program.\nMaximize: x. Constraints:\na.b ;::: x+a' .b for all other a' EW ,B. b ;::: x+,B'.b for all other ,8' EX L:s b(s) = 1, b(s) 2: 0 for all sES\nThis linear program is always feasible; the first two groups of constraints are all satisfied for any belief\nstate b when x is small enough. The witness region of a intersects with that of j3 if and only if the solu tion for x is positive.\nNext consider the parsimonious covering of the cross sum of a list of sets of vectors W1, Wz, ... , Wm. For any k such that 1\ufffdk\ufffdm, PC(ffi\ufffd=l Wi)ffiWk+l is a covering of Ee\ufffd,!f Wi and hence its parsimonious cov ering is the same as that of the latter. This leads to the following procedure for computing PC(E9:,1 Wi):\nProcedure IP({Wi : i = 1, . . . , m}) : 1 . y +-- w1. 2. Fori = 2 tom, Y +-- CSP(Y, Wi)\u00b7 3. Return Y.\nThis procedure is named incremental pruning (IP) be cause pruning takes place while performing cross sums rather than after all the cross sums.\nSuppose there are m possible observations and enu merate them as 1, 2 , . . . , m. Applying IP to {Va,o+ lo+=1, 2, . . . , m} ), one obtains the \ufffdarsimonious covering PC(Va) of the set Va defined m (1) . The union Ua({r(s, a)}ffiPC(Va)] is a covering of U and hence its parsimonious covering is same as that of the latter. This leads to the following algorithm for dynamic-programming updates:\nProcedure DP-Update(V) : 1. For each a, Waf-- IP({Va,o+lo+ = 1, 2, ... ,m}). 2. Return PC(Ua[{r(s,a)}ffiWaD\u00b7\nWe also use the term incremental pruning to refer to the above algorithm for dynamic-programming up dates. It does not specify which method one should use at line 2 to find the parsimonious covering of Ua[{r(s, a)}ffiPC(Va)]. A popular choice is Lark's algorithm1 (White 1991) .\n4 Improvements to incremental pruning\nIn DP-Update, IP is called once for each possible ac tion to find the parsimonious covering of the cross sum of m sets of vectors, where m is the number of possi ble observations. In the process, CSP is called m-1 times. When calculating the parsimonious covering of two sets W and X of vectors, CSP solves I W II X I linear programs and each linear program has IWI+IXI+n-1 constraints, where n is the number of possible states.\n10ne can also apply Lark's algorithm directly to U. This is, however, very inefficient since the size of U is ex ponential in the number of observations.\nAdvances in POMDP Solution Method 525\nThe restricted region variation of incremental pruning (Cassandra et al 1997) reduces the numbers of con straints in some of the linear programs by incorporat ing the idea behind Lark's algorithm into CSP. A num ber of linear programs can also be saved by exploiting the following fact. Suppose we know a witness point b for a vector a in W. If b also happens to be a wit ness point for a vector /3EX, then the witness regions of a and j3 must intersect. This conclusion is reached without solving a linear program.\nThe section introduces four new improvements. The first reduces the number of calls to IP; the second and the third improvements reduces the number of linear programs and the numbers of constraints in the linear programs respectively; and the fourth improvement re formulates the linear programs so that they yield more information and uses the information to reduce the number of linear programs.\n4.1 Reducing the number of calls to IP\nActions can be classified into those that gather infor mation and those that achieve goals. In robot path planning, move-forward, turn-left, and turn-right are goal-achieving actions while looking-around is an information-gathering action. It is often the case that two different goal-achieving actions a1 and a2 have identical observation probabilities, i.e. P(o+is+,al)=P(o+is+,az). This fact can be ex ploited to reduce the number of calls to IP.\nFor any action a and any observation o+, define\nV\ufffd,o+ = {f313aEV s.t. j3(s+)=.Aa(s+)P(o+is+,a)\\is+},\nv\ufffd EBv\ufffd,o+. (2) 0+\nComparing these definitions with the ones given in (1) , one can easily see that Va=V\ufffd*P(s+ls,a). Moreover, PC(V\ufffd)*P(s+is, a) is a covering of Va\u00b7 We can hence modify DP-Update as follows: For each action a, ob tain the parsimonious covering of V\ufffd by applying IP to {V' lo+=1, 2, . . . , m} ). Then apply Lark's algorithm a,o+ to the union Ua({r(s, a)}ffi[PC(V\ufffd)*P(s+is, a)]]. The result is still the parsimonious covering of U.\nGiven a, P(s+ls, a) can be viewed as an nxn matrix. If the matrix is invertible, then PC(V\ufffd)*P(o+is+,a) is also the parsimonious covering of Va. If the matrix is not invertible, PC(V\ufffd)*P(o+is+, a) might be non-parsimonious. When this is the case, the above modification leaves more work to Lark's al gorithm. However, there is a big advantage. If P(o+is+,al)=P(o+is+,az), then V\ufffd1 =V\ufffd2\u2022 Conse quently, the computations for obtaining the parsimo nious coverings PC(Va1) and PC(VaJ can be shared. The number of calls to IP is thereby reduced.\n526 Zhang and Lee\n4.2 Reducing the number of linear programs in CSP\nWhen computing the parsimonious covering PC(WffiX), CSP solves a linear program for each pair (a, {3) of vectors aEW and {3EX to determine whether their witness regions intersect. This subsection explains how some of the linear pro grams can be saved if we know a witness or boundary point for each vector in W and the neighboring rela tionships among witness regions of vectors in both W and X. We will show later how such knowledge can be made available through proper book keeping and some additional computations.\nBecause of the constraint Z:::s b(s)=1, closed witness regions are polytops in the n-1 dimensional space. For any two vectors a and a' in W, the intersection of the closed witness regions R(a,W) and R(a' ,W) is a polytop of dimension less than n-1. If the polytop is of dimension n-2, we say that the closed witness regions are neighbors. When this is the case, we also say that the vectors a and a' are neighbors in W. It is easy to see that the set of all neighbors of a is the minimum subset W' of W such that R(a, W)=R(a, W').\nIf we know a witness or boundary point for each vector in W and the neighboring relationships among vectors in W and among vectors in X, then CSP can be modi fied as follows: To initialize, set Y=0. For each aEW,\n1. Find all vectors {3 in X that has maximum inner product with the witness or boundary point of a.\n2. For each such vector {3, determine whether the witness regions R(a, W) and R({3, X) intersect.\n3. If they do, add a+f3 to Y and repeat 2 for all the neighbors of {3 that have not been considered.\nIt can be proved that the set Y is PC(WffiX) when the procedure terminates.\nFor a given vector aEW, a vector {3EX is examined by the above procedure if and only if its witness region or that of one of its neighbors intersect with the witness region of a. The number of such {3's is much smaller than the total number of vectors in X when the sets W and X are large (which is usually the case) because then the witness regions are small.\n4.3 Reducing the number of constraints\nConsider the linear program in Section 3. Replace the first two groups of constraints by the following:\na.b > x+a' .b for all neighbors a' of a, {3.b \ufffd x+f3'.b for all neighbors {3' of {3.\nThe solution for x is positive in the modified linear program if and only if this is the case in the original linear program. However, the modified linear program is easier to solve because it contains fewer constraints.\n4.4 Reformulating linear programs\nThe linear program in Section 3 enables us to deter mine whether the two witness regions R( a, W) and R({3, X) intersect. When they do, the linear pro gram also gives us a witness point for the vector a+{3EPC(WffiX), which is the belief point b that allows x to take its maximum value. We will refer to this point as the maximum point of the linear pro gram. This subsection reformulates the linear program so that it gives us more information and hopefully helps us saving some linear programs.\nHere is the reformulated linear program:\nMaximize: x. Constraints:\na.b;:::: x+a' .b for all neighbors a' of a {3.b 2:: {3'.b for all neighbors {3' of {3 L:s b(s) = 1, b(s) 2:: 0 for all sES\nIn addition to the fact that it incorporates the im provement described in the previous subsection, the reformulated linear program differs from the original one only in the absence of x from the second group of constraints.\nThe reformulated linear program is infeasible if and only if the closed witness region of {3 is empty. In this case, {3 should be pruned from X. From now on, we assume the linear program is feasible.\nThe witness regions of a and {3 intersect if and only if the solution for x in the reformulated linear program is positive. When this is the case, the maximum point b is either a witness point or a boundary point for the vector a+{3EPC(WffiX). It is a boundary point of a+f3 if and only if there exist neighbors 'Y of {3 such that {3.b=\"f.b. When this is the case, the witness re gion of any such neighbor 'Y of {3, if not empty, must intersect with that of a. Thus, without solving addi tional linear programs, we know that the vector et+\"( is in PC(WffiX) and b is one of its boundary points.\nNow consider the case when the solution for x is not positive. Here the witness regions of a and {3 do not intersect. Define region Rx(a, W)={bEB\\ a.b ;:::: x+a' .b for all neighbors a' of a}. It grows as x decreases. Thus x achieves its maximum possible value when the region first touches the closed region R({3, X). Consequently, the maximum point b of the reformulated linear program must be a boundary point of {3 and there must exist neighbors 'Y of {3 such that\n{3.b=')'.b. Suppose b is a witness point for some o:'EW. If the witness region of {3 is not empty, then it inter sects with that of a'. Hence the vector a' +{3 is in PC(W$X) and b is one of its boundary point. Simi larly, for any neighbor 1' of {3 such that ')'.b = {3.b and R(')', X):r60, the vector a'+')' is in PC(W$X) and b is one of its boundary points. Again, we know all those without solving additional linear programs.\n5 Facilitating the improvements\nThe improvement described in Subsection 4.1 reduces the number of calls to IP. We shall refer to it as an IP-reduction technique. The improvements introduced in Subsections 4.2-4.4, on the other hand, reduce the number of linear programs that CSP has to solve and the numbers of constraints in those linear programs. We shall refer to them as LP-reduction techniques.\nThe IF-reduction technique calls for the computation of PC(V\ufffd) by applying IP to {V\ufffd,o+ io+=1, 2, . . . , m} ). In the process, CSP is called m-1 times. In the kth call (1Sksm-1) , the inputs to CSP are PC($\ufffd=1 V\ufffd,o+=i) and V\ufffd,o+=k+l\" To facilitate the LP-reduction tech niques, we need a witness or boundary point for each vector in the first set and the neighboring relation ships among vectors in both sets. This section show how those can be made available through proper book keeping and some additional computations.\n5.1 Inheritance of neighboring relationships\nAssume we know the exact neighboring relationships among vectors in the set V. This subsection shows how one can, through proper book keeping, identify most pairs of vectors in PC($\ufffd=1 V\ufffd,o+=i) and V\ufffd,o+=k+l that are not neighbors. A method for finding the exact neighboring relationships among vectors in V will be described later.\nPairs of vectors that are not identified as non neighbors will simply regarded as neighbors. Treat ing non-neighbors as neighbors increases the complexi ties of the LP-reduction techniques. Fortunately, those techniques yield the correct results as long as neigh bors are not mistaken as non-neighbors.\nConsider two vectors {3 and {3' in v\ufffd,O+. By the definition Of v\ufffd,O+ > there mUSt eXiSt VeCtOrS Q and a' in V such that {3s+=a(s+)P(o+is+,a) and {3'(s+)=o:'(s+)P(o+ls+, a) . Using the property of neighbors mentioned right after the concept was de fined in Subsection 4.2 , one can show that if a and a' are not neighbors in V, then {3 and {3' cannot be neighbOrS in v\ufffd,O+ \u2022 Next consider the parsimonious covering PC(W$X)\nAdvances in POMDP Solution Method 527\nof two sets W and X of vectors. Each member of the covering can be written as a+{3, where nEW and {3EX. The witness region of a+{3 w.r.t PC(W$X) is simply the intersection R(o:, W)nR({3, X) and hence is a subset of both R(a, W) and ({3, X). This fact implies that two vectors a+ {3 and a'+ {3' in the covering cannot be neighbors if a and a' are not neighbors in W or {3 and {3' are not neighbors in W.\nNow consider the case when a is a neighbor of a' and {3 is a neighbor of {3'. Suppose a+{3 and o:'+{3' are neighbors in PC(W$X). Then the intersec tion of their closed witness regions is an n-2 dimen sional polytop. Denote this polytop by A. Since the closed witness region of a+{3 is a subset of both R(a, W) and R({3, X) and that of a' +{3' is a sub set of both R( a', W) and R({3', X), the polytops R(a, W)nR(o:', W) and R({3, X)nR({3', X) must lie in the same n-2 dimensional space as the polytop A. Since the polytop R(a, W)nR(o:', W) lies in the space {bEB\\a.b=a' .b} while the polytop R({J, X)nR({3', X) lies in the space {bEX\\{3.b={3'.b}, it must be the case that a-a'=c({J-{3'), where cis some constant. When this is not the case, a+{3 and a' +{3' cannot be neigh bors.\n5.2 Witness and boundary points\nThis subsection discusses how the need for a wit ness or boundary point for each vector in the set PC(EB\ufffd=l v\ufffd,o+=i) can be facilitated. If k>1, the set is obtained by CSP from PC($\ufffd11V\ufffd,o+=i) and V\ufffd,o+=k\u00b7 Consider the linear programs that CSP solves. If they are of the form given in Section 3 , they produce witness points for vectors in PC( EB\ufffd=l v\ufffd,O+=i) as by-products. If they are of the form given in Subsection 4.4 , they yield witness or boundary points for each vector in PC($\ufffd=1 V\ufffd,o+=i) as by-products. The rest of this subsection deals with the case when k=l. Here we need to find a witness or boundary point, if exists, for each vector in V\ufffd,o+=l\u00b7 For nota tional simplicity, we consider the set V\ufffd,o+ for a general observation o+.\nAssume the set V is parsimonious and a witness or boundary point is known for each vector in V. We can make this assumption because, to solve a POMDP, DP-Update needs to be called iteratively until a cer tain stopping criterion is met. At the first iteration, V typically consists of only one vector. Any belief state is a witness point for the vector. At later iterations, V is the output of the previous call to DP-Update. If DP-Update uses Lark's algorithm at line 2 , witness or boundary points for vectors in V are computed as by products.\n528 Zhang and Lee\nIt is obviously desirable to take advantage of the known witness or boundary points for vectors in V when finding witness or boundary points for vector in Va,o+. Let b be the known witness or boundary point for a vector aEV. Define a new belief state b1 by set ting b1(s+)=cb(s+)f P(o+is+, a) when P(o+is+, a)>O and b1 ( s+) =0 otherwise, where c is the renormalization constant. If P(o+is+,a)>O for all possible values of s+, then b1 must be a witness or boundary point for the vector /3EV\ufffd,o+ such that f3(s+)=a(s+)P(o+is+,a).\nNow consider the case when P(o+ is+, a)=O for some possible values s+\u00b7 If there is a vector /3EV\ufffd,o+ such that f3. b1?:_{31. b1 for all other /31EV\ufffd,o+' then b1 is a wit ness or boundary point for {3. This fact allows us to find witness or boundary points for some of the vec tors. For vectors {3EV\ufffd,o+ whose witness or boundary points are not found this way, we solve the following linear program:\nMaximize: x. Constraints:\n{3.b?:. x+{31. b for all neighbors {31 of {3 2 b( s+) =0 for all s+ such that\nP(o+is+, a)=O Ls b(s+) = 1, b(s+)?:. 0 for all s+ES\nWhen the solution for x is positive, the maximum point of the linear program is a witness point of {3. When the solution for x is not positive, the witness region of f3 is empty. Hence f3 can be pruned from Va,o+\u00b7\n5.3 Identifying neighboring relationships\nThis subsection shows how to find the neighboring re lationships among vectors in V. As mentioned earlier, V typically consists of only one vector the first time when DP-Update is called. The neighboring relation ships are trivial in this case. At later calls, Vis the out put of the previous call to DP-Update. Consequently, it suffices to show how the neighboring relationships among vectors in the output PC(U) of DP-Update can be found.\nUse Wa to denote {r(s, a)}ffi[PC(V\ufffd)*P(s+is, a)]. Then PC(U)=PC(Ua Wa)\u00b7 As discussed in Sub section 5.1, certain pairs of vectors in PC(V\ufffd) are known to be non-neighbors due to neighbor ing relationship inheritance. Those known rela tionships are in turn inherited by Wa. Consider any two vectors f3 and /31 in Wa. They can\n2(Non-)neighboring relationships among vectors in v\ufffd 0 inherit from those among vectors in v in the way de\ufffdctibed in the previous section. Pairs of vectors that are not identified as non-neighbors are simply treated as neighbors.\nbe written as f3(s)=r(s, a)+ Ls+ a(s+)P(s+is, a) and /31(s)=r(s,a)+ I:s+ d(s+)P(s+is,a), where a and a1 are vectors in PC(V\ufffd). It can be proved that f3 and {31 cannot be neighbors in Wa if a and a1 are not neigh bors in PC(V\ufffd).\nConsider a vector aEPC(U). We find all its neigh bors in two steps: first detect vectors that might be neighbors of a and then examine each of the potential neighbors to determine whether it is indeed a neighbor. There must exist action a such that aEWa\u00b7 The first step takes advantage of the known non-neighboring re lationships among vectors in Wa. It relies on the fol lowing fact. Suppose Na is a list of vectors in Wa that potentially are neighbors of a in Wa and suppose N is a list of vectors in PC(U) that potentially are neigh bors of a in PC(U). Then a vector f3 in PC(U)\\N can be a neighbor of a only if the following linear program has a positive solution for its objective function:\nMaximize: x. Constraints:\na. b = f3. b a. b?:. x+a1.b for all dENaUN. I:s b(s) = 1, b(s) ?:. 0 for all sES\nTo find all potential neighbors of a, initialize N to the empty set. Examine each vector f3 in PC(U)\\{a} using the above linear program. The linear program is skipped if a and f3 are already known to be neighbors or non-neighbors. The vector f3 is added to N once it is detected as a potential neighbor. After examing all the vectors, none of the vectors outside N can be neighbors of a.\nThe second step first makes use of the belief points found when solving instances of the above linear pro gram. Suppose b is the belief point found when a vector f3 is detected as a potential neighbor of a. If {3. b>/31.b for any other potential neighbor /31, then f3 must be a neighbor. If this is not the case, another lin ear program needs to be solved to determine whether {3 is a neighbor of a. This new linear program is the same as the one above except with the phrase \"for all at EN a UN\" replaced by \"for all a1 EN\" . The vector f3 is a neighbor of a if and only if the solution for x in the new linear program is positive 3. A potential neighbor is removed from the list N once it is found not to be a neighbor.\nA couple of facts can be used to reduce the number of linear programs. First if two vectors in PC(U) are from the same Wa and they are not neighbors in Wa,\n8 One might suggest to avoid the first step by regarding all other vectors as potential neighbors of a. The problem with this alternative is that the resulting linear programs contain a large number of constraints.\nthen they cannot be neighbors in PC(U) either. This is true because the witness region of a vector in PC(U) must be a subset of its witness region in Wa.\nSecond if PC(U) is obtained from UaWa using Lark's algorithm, then we have a witness or boundary point for each vector in PC(U). If a belief point b is a witness point for a vector aEPC(U), then any vec tor ,BEPC(U)\\ {a} such that ,B.b?:_,B'.b for all other ,B'EPC(U)\\{a} must be a neighbor of a.\n6 Discussions\nThe IF-reduction technique has no overhead while the LP-reduction techniques do. Our experiences indicate that the main overhead is the need to identify neigh bors for vectors in PC(U). In the neighbor detection method presented in Subsection 5.3, the second step does not take much time at all. The number of linear programs solved at the first step is upper bounded by n(n-1)/2, where n is the number of vectors in PC(U). The numbers of constraints in those linear programs are much smaller than n when n is large.\nAt the next time when DF-Update is called, new sets of vectors are constructed for various combinations of o+ and a by multiplying each vector in PC(U) with P(o+ls+, a). If P(o+ls+, a)>O for all s+, the corre sponding new set of vectors is parsimonious. To com pute the parsimonious covering of the cross sum of two such sets, the original CSP solves n2 linear pro grams and each of them has 2(n -1) constraints. The overhead of the LP-reduction techniques at each call to DP-Update is hence upper bounded by the com plexity of one call to CSF in the original incremental pruning algorithm. The LP-reduction techniques can significantly speed up dynamic-programming update because they drastically reduce the number of linear programs CSF has to solve and the numbers of con straints in those linear programs.\nThere are two cases where the incorporation of the LP reduction techniques can be counter-productive. The first case is when the number of cross sums needed at each call to DF-Update is very small (e.g. no more than 3). As an extreme example, suppose there are only two possible observations and the observation probabilities for all actions are equal. Then one needs to perform only one cross sum at each call to DP-Update provided the IF-reduction technique is incorporated. Savings due to the LP-reduction techniques in this only cross sum cannot offset the costs of those techniques.\nThe second case is when the observations are very in formative so that P(o+ls+, a)>O only for a small num ber of possible states s+. In this case, the sizes of the new sets mentioned above can be greatly reduced, be-\nAdvances in POMDP Solution Method 529\n70\n60\n50\n40\n30\n20\n10\nnum of vectors \u00b7\u00b7)(\u00b7\u00b7\u00b7\u00b7\u00b7 restricted Region \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7\nIP+LPreduction ----\u00b7 IP+LPreduction1 -\nFigure 1: Comparisons between two variations of in cremental pruning: restricted region and one that in corporates LP-reduction techniques.\nfore the sets are fed to CSP, by pruning vectors that are pointwise dominated by others 4. As a consequence, the cost incurred when identifying neighbors for vec tors in PC(U) might not be compensated by savings in the cross sums.\nThe issue of exploiting informative observations is studied in detail in Zhang and Liu (1997). The LP reduction techniques can be incorporated into the method.\n7 Experiments\nPreliminary experiments have been conducted to de termine the effectiveness of the improvements. Due to time constraints, we have so far implemented only the two LP reduction techniques described in Subsections 4.2 and 4.3. Cassandra et al (1997) have shown that the restricted region variation of incremental pruning is significantly more efficient than plain incremental pruning. This section reports empirical comparisons between restricted region and a new variation of in cremental pruning that incorporates the above two LP reduction techniques.\nThe tiger problem (Cassandra 1994) was used in the experiments. Figure 1 shows the times that the two algorithms took at the first twenty iterations. The number of vectors at the beginning of each iteration is also shown. We cut off at iteration twenty because thereafter the two algorithms, due to machine preci sion, produce different numbers of vectors.\n4Pointwise pruning is computationally very cheap.\n530 Zhang and Lee\nThe curve IP+LPreduction depicts the total time, in CPU seconds, that the new variation of incre mental pruning took, while IP+LPreduction1 de picts the total time minus the time spent in find ing neighboring relationships. The difference between restrictedRegion and IP+LPreduction1 represent the gains of the LP reduction techniques, while that between IP+LPreduction and IP+LPreduction1 rep resent the overhead. We see that the gains are signifi cant.\nOn the other hand, the overhead is also large. For tunately, neighboring relationships need to be com puted only once for each iteration. As a conse quence, the overhead does not increase with the num bers of possible actions and observations, while the gains do. In the tiger problem, there are three possible actions and two possible observations and hence three cross sums are performed at each iter ation. The net gains, i.e. the difference between restrictedRegion and IP+LPreduction, are not very significant in this case. If there were a large number of possible actions and observations, the net gains would be close to the difference between restrictedRegion and IP-LPreduction1.\nIt should be noted that the tiger problem has only two possible states. One implication is that the vectors that incremental pruning deals with are two dimen sional and each vector can have at most two neighbors. Experiments are under way to determine the effective ness of the two LP reductions techniques, as well as the other two improvements, on problems with larger state spaces.\n8 Conclusions\nIncremental pruning is presently the most efficient exact algorithm for finding optimal policies for POMDPs. It solves many linear programs. This paper proposes four improvements to incremental pruning. The first improvement reduces the number of linear programs by taking advantage of the fact that .differ ent actions sometimes have equal observation proba bilities. The second and third improvements further reduce the number of linear programs and the num bers of {;Onstraints in the linear programs by exploiting neighboring relationships among witness regions. The fourth improvement reformulates the linear programs so that they provide us with more information and hence hopefully reduces the number of linear program even further. Preliminary experiments haves shown that the improvements can significantly speed up in cremental pruning.\nIt is unlikely that exact algorithms by themselves can solve large POMDPs. A obvious future direction is to\nincorporate the ideas behind the exact methods into approximate algorithms. The techniques introduced in this paper can be easily incorporated into the ap proximate method proposed by Zhang and Liu (1997).\nAcknowledgements\nThe authors would like thank Anthony R. Cassandra, Robert Givan, and Michael Littman for valuable dis cussions and Weihong Zhang for comments on earlier versions of this paper.\nReferences\nCassandra, A. R. (1994). Optimal polices for partially observable Markov decision processes. TR CS-94-14, Department of Computer Sci ence, Brown University, Providence, Rhode Island 02912, USA.\nCassandra, A. R., Littman, M. L., & Zhang, N. L. (1997). Incremental pruning: A simple, fast, ex act method for partially observable Markov deci sion processes. In Proceedings of Thirteenth Con ference on Uncertainty in Artificial Intelligence, 54-61.\nCheng, H. T. (1988). Algorithms for partially ob servable Markov decision processes. PhD thesis, University of British Columbia, Vancouver, BC, Canada.\nLittman, M. L., Cassandra, A. R., & Kaelbling, L. P. (1995). Efficient dynamic-programming up dates in partially observable Markov decision pro cesses. TR CS-95-19, Department of Computer Science, Brown University, Providence, Rhode Is land 02912, USA.\nG. E. Monahan (1982), A survey of partially observ able Markov decision processes: theory, models, and algorithms, Management Science, 28 (1), pp. 1-16.\nSondik, E. J. (1971). The optimal control of partially observable Markov processes. PhD thesis, Stan ford University, Stanford, California, USA.\nWhite III, C. C. (1991). Partially observed Markov decision processes: A survey. Annals of Opera tions Research, 32.\nN. L. Zhang and W. Liu (1997), A model approxima tion scheme for planning in stochastic domains, Journal of Artificial Intelligence Research, 7, pp. 199-230. ."}], "references": [{"title": "Optimal polices for partially observable Markov decision processes", "author": ["A.R. Cassandra"], "venue": "TR CS-94-14,", "citeRegEx": "Cassandra,? \\Q1994\\E", "shortCiteRegEx": "Cassandra", "year": 1994}, {"title": "Incremental pruning: A simple, fast, ex\u00ad act method for partially observable Markov deci\u00ad sion processes", "author": ["A.R. Cassandra", "M.L. Littman", "N.L. Zhang"], "venue": "In Proceedings of Thirteenth Con\u00ad ference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Cassandra et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Cassandra et al\\.", "year": 1997}, {"title": "Algorithms for partially ob\u00ad servable Markov decision processes", "author": ["H.T. Cheng"], "venue": "PhD thesis,", "citeRegEx": "Cheng,? \\Q1988\\E", "shortCiteRegEx": "Cheng", "year": 1988}, {"title": "Efficient dynamic-programming up\u00ad dates in partially observable Markov decision pro\u00ad cesses", "author": ["M.L. Littman", "A.R. Cassandra", "L.P. Kaelbling"], "venue": "TR CS-95-19,", "citeRegEx": "Littman et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Littman et al\\.", "year": 1995}, {"title": "A survey of partially observ\u00ad able Markov decision processes: theory, models, and algorithms", "author": ["G.E. Monahan"], "venue": "Management Science,", "citeRegEx": "Monahan,? \\Q1982\\E", "shortCiteRegEx": "Monahan", "year": 1982}, {"title": "The optimal control of partially observable Markov processes", "author": ["E.J. Sondik"], "venue": "PhD thesis, Stan\u00ad ford University,", "citeRegEx": "Sondik,? \\Q1971\\E", "shortCiteRegEx": "Sondik", "year": 1971}, {"title": "Partially observed Markov decision processes: A survey", "author": ["III C.C. White"], "venue": "Annals of Opera\u00ad tions Research,", "citeRegEx": "White,? \\Q1991\\E", "shortCiteRegEx": "White", "year": 1991}, {"title": "A model approxima\u00ad tion scheme for planning in stochastic domains", "author": ["N.L. Zhang", "W. Liu"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Zhang and Liu,? \\Q1997\\E", "shortCiteRegEx": "Zhang and Liu", "year": 1997}], "referenceMentions": [{"referenceID": 5, "context": "Sondik (1971) has shown that if there exists a finite set Vt of func\u00ad tions of s, henceforth called vectors, that represents 1't* in the sense that for all belief states b", "startOffset": 0, "endOffset": 14}, {"referenceID": 4, "context": "exhaustive (Monahan 1982) , Lark (White 1991) , linear support (Cheng 1988) , witness (Littman et al 1995) , and incremental pruning (Zhang and Liu 1997) .", "startOffset": 11, "endOffset": 25}, {"referenceID": 6, "context": "exhaustive (Monahan 1982) , Lark (White 1991) , linear support (Cheng 1988) , witness (Littman et al 1995) , and incremental pruning (Zhang and Liu 1997) .", "startOffset": 33, "endOffset": 45}, {"referenceID": 2, "context": "exhaustive (Monahan 1982) , Lark (White 1991) , linear support (Cheng 1988) , witness (Littman et al 1995) , and incremental pruning (Zhang and Liu 1997) .", "startOffset": 63, "endOffset": 75}, {"referenceID": 7, "context": "exhaustive (Monahan 1982) , Lark (White 1991) , linear support (Cheng 1988) , witness (Littman et al 1995) , and incremental pruning (Zhang and Liu 1997) .", "startOffset": 133, "endOffset": 153}, {"referenceID": 6, "context": "A popular choice is Lark's algorithm1 (White 1991) .", "startOffset": 38, "endOffset": 50}, {"referenceID": 7, "context": "The issue of exploiting informative observations is studied in detail in Zhang and Liu (1997). The LP\u00ad reduction techniques can be incorporated into the method.", "startOffset": 73, "endOffset": 94}, {"referenceID": 0, "context": "Cassandra et al (1997) have shown that the restricted region variation of incremental pruning is significantly more efficient than plain incremental pruning.", "startOffset": 0, "endOffset": 23}, {"referenceID": 0, "context": "The tiger problem (Cassandra 1994) was used in the experiments.", "startOffset": 18, "endOffset": 34}, {"referenceID": 7, "context": "The techniques introduced in this paper can be easily incorporated into the ap\u00ad proximate method proposed by Zhang and Liu (1997).", "startOffset": 109, "endOffset": 130}], "year": 2011, "abstractText": "There is much interest in using par\u00ad tially observable Markov decision processes (POMDPs) as a formal model for planning in stochastic domains. This paper is concerned with finding optimal policies for POMDPs. We propose several improvements to incre\u00ad mental pruning, presently the most efficient exact algorithm for solving POMDPs.", "creator": "pdftk 1.41 - www.pdftk.com"}}}