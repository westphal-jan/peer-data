{"id": "1302.1529", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Feb-2013", "title": "Exploring Parallelism in Learning Belief Networks", "abstract": "It would came shown much a number 's algorithm authentication model supposed so writing basically by several expanding computation by employ a single - link look ahead monitor. When each multi - link much closer search called them, there computational complexity one has basic interface increases. We of good once use parallelism to catching with reduced complexity prior students unlike models three to speed while educational year large domains. An deterministic actually proposed supposed fermentation the concept task new simultaneously output. A possible task decomposition is specific next balance load often processors own same increase the ups - they and measure. For lesson first means large descriptors, we present a guerillas of, available processors rather that slow web access from file can be replaced by competitive creating access. Our cooperation has put loop computer demonstrates the strength however. optimisation.", "histories": [["v1", "Wed, 6 Feb 2013 15:54:31 GMT  (1120kb)", "http://arxiv.org/abs/1302.1529v1", "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)"]], "COMMENTS": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["tongsheng chu", "yang xiang"], "accepted": false, "id": "1302.1529"}, "pdf": {"name": "1302.1529.pdf", "metadata": {"source": "CRF", "title": "Exploring Parallelism in Learning Belief Networks", "authors": ["T. Chu"], "emails": [], "sections": null, "references": [{"title": "The ALARM monitoring system: a case study with two probabilistic inference techniques for belief networks", "author": ["I.A. Beinlich", "H.J. Suermondt", "R.M. Chavez", "G.F. Cooper"], "venue": "Tech. Report I<SLBB-84,", "citeRegEx": "Beinlich et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Beinlich et al\\.", "year": 1989}, {"title": "Learning Bayesian networks: search methods and ex\u00ad perimental results", "author": ["ford Univ", "Stanford", "CA.D. Chickering", "D. Geiger", "D. Heckerman"], "venue": "In Proc. of 5th Conf. Artificwl Intelligence and Statistics,", "citeRegEx": "Univ. et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Univ. et al\\.", "year": 1995}, {"title": "Accelerated learning on the connect machine", "author": ["D. Cook", "L. Holder"], "venue": "Proc. 2nd IEEE Symp. on par\u00ad allel and Distributed processing,", "citeRegEx": "Cook and Holder,? \\Q1990\\E", "shortCiteRegEx": "Cook and Holder", "year": 1990}, {"title": "A Bayesian method for the induction of probabilistic networks from data", "author": ["E.H.G.F. Cooper"], "venue": "Machine Learning,", "citeRegEx": "Cooper,? \\Q1992\\E", "shortCiteRegEx": "Cooper", "year": 1992}, {"title": "Learning Bayesian networks: the combination of knowledge and statistical data", "author": ["D. Beckerman", "D.M.D. Geiger"], "venue": "Chickering", "citeRegEx": "Beckerman and Geiger,? \\Q1995\\E", "shortCiteRegEx": "Beckerman and Geiger", "year": 1995}, {"title": "Kutato: an entropy-driven system for construction of probabilis\u00ad tic expert system from database", "author": ["E.H. Herskovits", "G.F. Cooper"], "venue": "In Proc. 6th Conf. on Uncertainty in Artificial Intelligence,", "citeRegEx": "Herskovits and Cooper,? \\Q1990\\E", "shortCiteRegEx": "Herskovits and Cooper", "year": 1990}, {"title": "Learning Bayesian net\u00ad works: an approach based on the MDL principle", "author": ["W. Lam", "F. Bacchus"], "venue": "Computational Intelligence, 10(3),", "citeRegEx": "Lam and Bacchus,? \\Q1994\\E", "shortCiteRegEx": "Lam and Bacchus", "year": 1994}, {"title": "Scaling up inductive learning with massive parallelism", "author": ["J.M.F.J. Provost"], "venue": "Aronis", "citeRegEx": "Provost,? \\Q1996\\E", "shortCiteRegEx": "Provost", "year": 1996}, {"title": "An algo\u00ad rithm for fast recovery of sparse causal graphs", "author": ["P. Spirtes", "C. Glymour", "R. Scheines"], "venue": "Social Science Computer Review,", "citeRegEx": "Spirtes et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Spirtes et al\\.", "year": 1991}, {"title": "Learning belief networks in pseudo\u00ad independent domains", "author": ["Y. Xiang"], "venue": "Tech. Report CS-96-07", "citeRegEx": "Xiang,? \\Q1996\\E", "shortCiteRegEx": "Xiang", "year": 1996}, {"title": "Critical remarks on single link search in learning belief net\u00ad works", "author": ["Y. Xiang", "S.K.M. Wong", "N. Cercone"], "venue": "Proc. 12th Conf. on Uncertainty in Artificial Intelligence,", "citeRegEx": "Xiang et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Xiang et al\\.", "year": 1996}, {"title": "A 'micro\u00ad scopic' study of minimum entropy search in learning decomposable Markov networks", "author": ["Y. Xiang", "S.K. Wong N. Cercone"], "venue": "Machine Learning,", "citeRegEx": "Xiang and Cercone,? \\Q1997\\E", "shortCiteRegEx": "Xiang and Cercone", "year": 1997}], "referenceMentions": [{"referenceID": 8, "context": "ual knowledge acquisition, many researchers have ac\u00ad tively investigated methods for learning such networks from data (Cooper & Herskovits 1992; Beckerman et al. 1995; Herskovits & Cooper 1990; Lam & Bacchus 1994; Spirtes et al. 1991; Xiang et al. 1997).", "startOffset": 118, "endOffset": 253}, {"referenceID": 10, "context": "rectly by a single-link lookahead search (Xiang et al. 1996).", "startOffset": 41, "endOffset": 60}], "year": 2011, "abstractText": "It has been shown that a class of probabilistic domain models cannot be learned correctly by several existing algorithms which employ a single-link lookahead search. When a multi\u00ad link lookahead search is used, the computa\u00ad tional complexity of the learning algorithm increases. We study how to use parallelism to tackle the increased complexity in learn\u00ad ing such models and to speed up learning in large domains. An algorithm is proposed to decompose the learning task for parallel pro\u00ad cessing. A further task decomposition is used to balance load among processors and to in\u00ad crease the speed-up and efficiency. For learn\u00ad ing from very large datasets, we present a re\u00ad grouping of the available processors such that slow data access through file can be replaced by fast memory access. Our implementation in a parallel computer demonstrates the ef\u00ad fectiveness of the algorithm.", "creator": "pdftk 1.41 - www.pdftk.com"}}}