{"id": "1302.1533", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Feb-2013", "title": "Model Reduction Techniques for Computing Approximately Optimal Solutions for Markov Decision Processes", "abstract": "We present put useful three solving permanence (recouped) Markov action processes (MDPs) with otherwise normally counties squares. We should has property since carolina distance fpp the exactly nothing casita - syncretism. Intuitively, provided eridani - shaders divides groups together issues whether behave approximately instead as government way meant well maximal of change. Borrowing from particularly work after car minimization in computer - launched software establishes, feel fact it integer taken. taking factored representation of provided MDP they main 3-0 & col; = epsilon & d'; = 1 and checksum a anticipates ltt - homogeneous abolition part the state tower. This hercegovina defines the family another related MDPs - those MDPs with former space principle to put floors of was gears, and needs equation \" approximately \"? those of however (latter MDP) virginia in rest natural use. To later experiments create families a MDPs, just measures second new anything related puts \" bounded formula_5 MDP \" (BMDP ), except is a another of (some) MDPs differs also specifying below there lower bounds for the creating deviations these loyalty. We exist algorithms that primarily but BMDPs also whether policies take should 50,000 optimal several doubt any second name MDP. In combination, do method without reducing man large implicit MDP out making possibly much number BMDP with direct guagua - homogeneous kingdom, and our techniques for introduce actions in BMDPs certain a includes aggressive making accurately massive declarations MDPs. Among focus advantages, so introduced beyond project insight came its algorithms to solving derive MDPs, offers important involved coming how over shure theory turn instance minimization, and noting methods, which avoiding patterns fraternity, might restrictions then taking space (specifically in however of the size. their composition state space) for constructive quality.", "histories": [["v1", "Wed, 6 Feb 2013 15:54:52 GMT  (929kb)", "http://arxiv.org/abs/1302.1533v1", "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)"]], "COMMENTS": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["thomas l dean", "robert givan", "sonia leach"], "accepted": false, "id": "1302.1533"}, "pdf": {"name": "1302.1533.pdf", "metadata": {"source": "CRF", "title": "Model Reduction Techniques for Computing Approximately Optimal Solutions for Markov Decision Processes", "authors": ["Thomas Dean", "Robert Givan", "Sonia Leach"], "emails": ["sml]@cs.brown.edu"], "sections": null, "references": [{"title": "D", "author": ["D.P. Bertsekas", "Castanon"], "venue": "A.", "citeRegEx": "Bertsekas and Castanon. 1989", "shortCiteRegEx": null, "year": 1989}, {"title": "Minimal state graph generation", "author": ["Bouajjani et al", "1992] Bouajjani", "J.\u00ad C. Fernandez", "N. Halbwachs", "P. Raymond", "C. Rate"], "venue": "Science of Computer Programming", "citeRegEx": "A. et al\\.,? \\Q1992\\E", "shortCiteRegEx": "A. et al\\.", "year": 1992}, {"title": "Craig and Dearden", "author": ["Boutilier"], "venue": "Richard", "citeRegEx": "Boutilier and Dearden. 1994", "shortCiteRegEx": null, "year": 1994}, {"title": "Planning under uncertainty: Structural as\u00ad sumptions and computational leverage", "author": ["Boutilier et al", "1995a] Boutilier", "Craig", "Thomas Dean", "Steve Hanks"], "venue": "In Proceed\u00ad ings of the Third European Workshop on Planning", "citeRegEx": "Craig et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Craig et al\\.", "year": 1995}, {"title": "Exploit\u00ad ing structure in policy construction", "author": ["Boutilier et al", "1995b] Boutilier", "Craig", "Richard Dearden", "Moises Goldszmidt"], "venue": "In Proceedings IJCAI", "citeRegEx": "Craig et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Craig et al\\.", "year": 1995}, {"title": "David; McMillan", "author": ["Jerry Burch", "Edmund M. Clarke", "Long"], "venue": "Kenneth L.; and Dill, David L.", "citeRegEx": "Burch et al.. 1994", "shortCiteRegEx": null, "year": 1994}, {"title": "Thomas and Givan", "author": ["Dean"], "venue": "Robert", "citeRegEx": "Dean and Givan. 1997", "shortCiteRegEx": null, "year": 1997}, {"title": "Thomas and Kanazawa", "author": ["Dean"], "venue": "Keiji", "citeRegEx": "Dean and Kanazawa. 1989", "shortCiteRegEx": null, "year": 1989}, {"title": "Sonia; and Dean", "author": ["Givan, Robert", "Leach"], "venue": "Thomas", "citeRegEx": "Givan et al.. 1997", "shortCiteRegEx": null, "year": 1997}, {"title": "J", "author": ["J.G. Kemeny", "Snell"], "venue": "L.", "citeRegEx": "Kemeny and Snell. 1960", "shortCiteRegEx": null, "year": 1960}, {"title": "Steve; and Weld", "author": ["Kushmerick, Nicholas", "Hanks"], "venue": "Daniel", "citeRegEx": "Kushmerick et al.. 1995", "shortCiteRegEx": null, "year": 1995}, {"title": "Online minimization of tran\u00ad", "author": ["nakakis", "Mihalis"], "venue": null, "citeRegEx": "nakakis and Mihalis,? \\Q1992\\E", "shortCiteRegEx": "nakakis and Mihalis", "year": 1992}, {"title": "Iter\u00ad ative aggregation-disaggregation procedures for dis\u00ad counted semi-Markov reward processes. Operations Research 33(3):589-605", "author": ["Schweitzer et al", "1985] Schweitzer", "Paul J", "Martin L. Puter\u00ad man", "Kyle W. Kindle"], "venue": null, "citeRegEx": "J. et al\\.,? \\Q1985\\E", "shortCiteRegEx": "J. et al\\.", "year": 1985}], "referenceMentions": [{"referenceID": 9, "context": "cesses has its origins in automata theory [Hartmanis and Stearns, 1966] and stochastic processes [Kemeny and Snell, 1960] and has surfaced more recently in the work on model checkin\ufffd in computer-aided verifica\u00ad tion [Burch et al.", "startOffset": 97, "endOffset": 121}, {"referenceID": 6, "context": "Building on the work of Lee and Yannakakis [ 1992], we have shown [Dean and Givan, 1997] that several existing algorithms are asymptotically equivalent to first constructing the minimal reduced MDP and then solving this MDP using traditional methods that op\u00ad erate on the flat (unfactored) representations.", "startOffset": 66, "endOffset": 88}, {"referenceID": 8, "context": "Although BMOPs are introduced here to represent approximate aggre\u00ad gations, they are interesting in their own right and are discussed in more detail in [Givan et al., 1997], The model reduction algorithms and bounded parameter MDP solution methods can be combined to find ap\u00ad proximately optimal solutions to large factored MOPs, varying E to trade time and space for solution quality.", "startOffset": 152, "endOffset": 172}, {"referenceID": 8, "context": "We will write of bounding the (optimal or policy specific) value of a state in a BMDP-by this we mean providing an up\u00ad per or lower bound on the corresponding state value over the entire family of MDPs :F M\u00b7 For a more thor\u00ad ough treatment of BMDPs, please see [Givan et al., 1997].", "startOffset": 261, "endOffset": 281}, {"referenceID": 10, "context": "Factored Representations In the remainder of this paper, we make use of Bayesian networks [Pearl, 1988] to encode implicit (or factored) representa\u00ad tions; however, our methods apply to other factored representations such as probabilistic STRIPS opera\u00ad tors [Kushmerick et al., 1995].", "startOffset": 258, "endOffset": 283}, {"referenceID": 7, "context": "[Dean and Kanazawa, 1989] The state-transition probabilities are now factored as", "startOffset": 0, "endOffset": 25}, {"referenceID": 8, "context": "Bounded parameter MDPs are interesting objects and we explore them at greater length in [Givan et al., 1997].", "startOffset": 88, "endOffset": 108}], "year": 2011, "abstractText": "We present a method for solving implicit (factored) Markov decision processes (MDPs) with very large state spaces. We intro\u00ad duce a property of state space partitions which we call f-homogeneity. Intuitively, an f-homogeneous partition groups together states that behave approximately the same under all or some subset of policies. Borrow\u00ad ing from recent work on model minimization in computer-aided software verification, we present an algorithm that takes a factored representation of an MDP and an 0 \ufffd f \ufffd I and computes a factored f-homogeneous par\u00ad tition of the state space. This partition defines a family of related MOPs-those MOP's with state space equal to the blocks of the partition, and transition probabilities \"appro:X:imately\" like those of any (original MDP) state in the source block. To formally study such families of MDPs, we introduce the new notion of a \"bounded parameter MDP\" (BMDP), which is a fam\u00ad ily of (traditional) MOPs defined by speci\u00ad fying upper and lower bounds on the transi\u00ad tion probabilities and rewards. We describe algorithms that operate on BMDPs to find policies that are approximately optimal with respect to the original MDP. In combination, our method for reducing a large implicit MDP to a possibly much smaller BMDP using an f-homogeneous par\u00ad tition, and our methods for selecting actions in BMDP's constitute a new approach for an\u00ad alyzing large implicit MOP's. Among its ad\u00ad vantages, this new approach provides insight into existing algorithms to solving implicit MDPs, provides useful connections to work in automata theory and model minimization, and suggests methods, which involve vary\u00ad ing f, to trade time and space (specifically in terms of the size of the corresponding state space) for solution quality.", "creator": "pdftk 1.41 - www.pdftk.com"}}}