{"id": "1302.4489", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Feb-2013", "title": "Termhood-based Comparability Metrics of Comparable Corpus in Special Domain", "abstract": "Cross - Language Information Retrieval (CLIR) one pipe wrote (MT) resources, making as guidebooks same boundaries corpora, each quality brought make to put although but will sh3. Besides, common industry are while limited directly a yet swahili, most being English, French, are Spanish and sure however. So, determining most pacu automatically for particular transcription could be fact indeed return on rather effectively. Comparable yokuts, we the subcorpora were now contemporary of having other, used that both obtaining when desktop. Therefore, building then using comparable limbus this instead in more easiest option in polyglot information processing. Comparability metrics it five example other issues was the pitch in building included using quality redlands. Currently, there is fact widely accepted expression take proquest method particular watauga comparability. In simply, Different definitions instead metrics physical both comparability might although given both suit activities tasks probably growing voice suppliers. A similar retentions, interests, termhood - is metrics, urban actually made task most ticino lexicon dependency, is financing into kind paper. In always combining, few ones 9th called termhood not waveform, and then the comparator startling, calculated same on into ranking identify such word termhood, is small also nonlegal. Experiments results watch put termhood - based qualitative drum 've least means brightness - inc. metrics.", "histories": [["v1", "Tue, 19 Feb 2013 00:30:57 GMT  (171kb)", "http://arxiv.org/abs/1302.4489v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["sa liu", "chengzhi zhang"], "accepted": false, "id": "1302.4489"}, "pdf": {"name": "1302.4489.pdf", "metadata": {"source": "CRF", "title": "Termhood-based Comparability Metrics of Comparable Corpus in Special Domain", "authors": ["Sa Liu", "Chengzhi Zhang"], "emails": ["liusa321@163.com,", "zhangchz@istic.ac.cn"], "sections": [{"heading": null, "text": "Comparability metrics is one of key issues in the field of building and using comparable corpus. Currently, there is no widely accepted definition or metrics method of corpus comparability. In fact, Different definitions or metrics methods of comparability might be given to suit various tasks about natural language processing. A new comparability, namely, termhood-based metrics, oriented to the task of bilingual terminology extraction, is proposed in this paper. In this method, words are ranked by termhood not frequency, and then the cosine similarities, calculated based on the ranking lists of word termhood, is used as comparability. Experiments results show that termhood-based metrics performs better than traditional frequency-based metrics.\nKeywords: Termhood-based Comparability, Comparable Corpus, Frequencybased Metrics, Terminology Extraction"}, {"heading": "1 Introduction", "text": "Parallel corpus which contains source documents and their translations plays an important role in multilingual information service [1], such as Cross-Language Information Retrieval (CLIR), and machine translation (MT). However, parallel corpus is scarce resources and not easy to be obtained in some under-resourced languages or special domains. Due to these shortcomings, building and using comparable corpora is often a more feasible option. It is obviously easier to find document collections with similar topics in multiple languages than to find parallel corpus [2]. The Web, with its vast volumes of data, offers a natural source for this. For example, bilingual website, and online Wikipedia, are very good resources for collecting and obtaining\ncomparable data. Meanwhile, comparable data extracted from these resources can update with the increasing of the source data, and then more new words can be extracted easily and accurately. Therefore, building and using comparable corpora is becoming more and more important and urgent.\nComparability is the key concept in the research of comparable corpus. However, so far there has been no widely accepted definition of comparability. Different definitions or metrics methods of comparability might be given to suit various NLP tasks. In the task of machine translation, comparability is focused on distribution and quality of translated knowledge [3]. In multilingual terminology extraction, comparability is focused on distribution and quality of the vocabulary of translated forms [4].\nSo far, method of based word frequency list has been always used to measure corpus homogeneity and similarity between corpora [5]. This method is useful for measure corpus similarity in the respect of comparing the different language styles, however, this method perform badly in the task of bilingual term extraction. In our previous experiments, we verify this point.\nA new comparability, namely, termhood-based metrics, especially used for comparability metrics of comparable corpus in special domain, is proposed in this paper. Experiments results show that this method performs better than traditional frequencybased metrics in the task of bilingual term extraction. The remainder of this paper is organized as follows. In section 2, related works are introduced. Then the termhoodbased metrics is described in Section 3. Section 4 presents the experiment results and the proposed method is evaluated according to the task of bilingual terminology extraction in section 5. The paper is concluded with a summary and directions for future works."}, {"heading": "2 Related Works", "text": "In this section, we review related works relevant to our research, including a brief review of building comparable corpus and comparability metrics of comparable corpus."}, {"heading": "2.1 Building comparable corpus", "text": "Generally, comparable corpus is generated from news agencies or by crawling certain sites [2]. Talvensaari et al. built comparable corpora based on focused crawling [6]. Leturia et al. (2009) used search engine queries for collecting comparable corpora from the Internet [7]. Otero and L\u00b4opez exploited Wikipedia for collecting domain comparable corpora by using categories as topic restrictions [8].\nIn our previous experiments, we used three different Internet data source for collecting comparable corpus: querying bilingual domain keywords in search engine, exploiting the online encyclopedia-Wikipedia, and searching academic databases. At last, we choose data from academic databases as our experiment corpus for its suitable size and quality."}, {"heading": "2.2 Comparability metrics of comparable corpus", "text": "In order to evaluate the quality of comparable corpus, we need some way to measure the degree of comparability of the comparable corpus. The most used metrics of comparable corpus are Chi-square statistics and word similarity. Leturia et al. used these two methods to measure the comparability of domain-specific comparable corpora obtained from the Internet by using search engine [2]. One method is calculating the cosine value between the vectors containing all the keywords of each corpus; the other is calculating Chi-square statistics for the most N frequent keywords (Top-N keywords). The ACCURAT (Analysis and evaluation of Comparable Corpora for Under Resourced Areas of Machine Translation) project used asymmetric Chi-square statistics to measure comparability [9]. The TTC (Terminology Extraction, Translation Tools and Comparable Corpora) project concentrate on two dimensions for comparability calculation: one is similarity between anchor texts in its own language; the other is dissimilarity between anchor points texts in two corpora [10].\nThe aforementioned works are based on word frequency lists. This kind of method is simple and effective for measure language style. However, this method performs poor between different domain corpora. In our previous investigation, we find this method can\u2019t distinguish different domain-specific corpus efficiently.\nLi and Gaussier purposed a metrics of comparable corpus for bilingual lexicon extraction [11]. Given a comparable corpus P consisting of an English part Pe, and a French part Pf , the degree of comparability of P is defined as the expectation of finding the translation of any given source/target word in the target/source corpus vocabulary. This method needs a bilingual dictionary for mapping between two corpora. Thus the size and quality of dictionary may heavily affect the result of comparability measure.\nIn this paper, we propose termhood-based comparability metrics, according to bilingual terminology extraction task. It is noted that our method is oriented to bilingual terminology. It is in this point that our method is different to Li et al [11], which is oriented to bilingual lexicon. As for comparability of domain-specific comparable corpora, our method, based on termhood calculating, is more suitable to highlight terminology."}, {"heading": "3 Termhood-based comparability metrics of comparable corpus", "text": "As for terminology extraction based on comparable corpus, comparability should concern the distribution and quality of terminology. Termhood is defined as degree of terminolgy to be term in a specific field. Quality of term can be measured by termhood and distribution of words be measured by ranking list of word weighting. So, we proposed termhood-based comparability metrics. In this method, words are ranked by termhood not frequency, and then the cosine similarities are calculated based on the ranking lists of word termhood. The similarity obtained is used as comparability of comparable corpus."}, {"heading": "3.1 The Basic Idea", "text": "For calculating termhood-based comparability, the whole process we used is described as follows.\n(1) Chinese-English domain comparable corpus collecting: comparable corpus we exploit in the experiment from two online academic databases (Chinese corpus from CNKI [12], English corpus from EBSCO[13]);\n(2) Preprocessing: Chinese corpus is preprocessing and word lists from keywords (come from the abovementioned academic databases) and full-text words (come from full-text of document) are both obtained;\n(3) Translating and processing: English corpus is translated into Chinese through Google translate [14]. Then the translated corpus is segmentated by ICTClAS[15], and finally word lists from keywords and full-text words are acquired;\n(4) Termhood measure: Termhood of words is computed by using the method of corpus comparison after acquiring word frequency;\n(5) Similarity calculating: Ranking the word list again based on termhood and calculating cosine similarity between vectors."}, {"heading": "3.2 Key technology in the proposed method", "text": "In this section, key technology used in our proposed method is described in detail, including termhood measure and comparability of termhood-based metrics.\n(1) Termhood measure by corpus comparison It is observed that a true term is more outstanding (or peculiar) to its own subject domain than to a general domain or another field. Kit and Liu proposed a measure for mono-word termhood in terminology of such peculiarity and quantify it in terms of a word\u2019s ranking difference in a domain and background corpus [16]. We use this method to measure the termhood of terminology. We use People\u2019s Daily corpus of 1998 from January to June as background corpus and Library and information (LIS) corpus as domain corpus. Given a domain corpus D (with a vocabulary VD) and a background corpus B (with a vocabulary VB), the termhood of a word w is defined as formula (1).\nWhere r (w) is the ranking number of word w in a corpus in question, |VD|,| VB | is the size of domain and background corpus respectively. A word rank is normalized by the vocabulary size of its corpus in order to make the word ranks in two corpora comparable.\nB\nB\nD\nD\nV (w)rV (w)r)Termhood(w = (1)\n(2) Comparability of termhood-based metrics in comparable corpus According to the termhood, word lists are ranked in descending order. Then we calculate similarity of the new word list by vector space model [17]. The similarity obtained is used to be comparability of comparable corpus."}, {"heading": "4 Experiments and Result Analysis", "text": "In this section, we first introduce experiments data used for comparability metrics. Then two different way of data processing are described in detail. At last, the experiment results are given and analyzed."}, {"heading": "4.1 Data", "text": "The maximum and minimum of comparability is comparability of parallel corpus and comparability of non-comparable corpus respectively. In the experiments, we select three kinds of comparable corpus with different comparability, i.e. parallel corpus, comparable corpus, and non-comparable corpus. It is assumed that comparability of comparable corpus lies between parallel and non-comparable corpus. In our experiments, the domain of parallel corpus is Library and Information Science (LIS), obtained from abstracts of records from CNKI database; comparable corpus is also LIS domain, collected from two aforementioned academic databases. We build noncomparable corpus through combining Chinese corpus in domain of law and English corpus in domain of LIS. Table 1 describes basic information of corpus."}, {"heading": "4.2 Data processing", "text": "In order to verify the effectiveness of the proposed method, we compute the comparability of three kinds of comparable corpus, i.e. parallel corpus, comparable corpus and non-comparable corpus respectively. In the experiments, the comparability of each kind of comparable corpus is computed based on termhood-based and traditional frequency-based metrics respectively.\n(1) Frequency-based metrics Word was ranked based on their frequency in the corpus, and then comparability was calculated by cosine value between two vectors represented by words and their frequency. In the experiment, word frequency is normalized because there is some difference between size of Chinese corpus and English corpus. Experiments were carried out for six different corpus sizes, i.e. Top100, Top200, Top500, Top1000, Top2000 and Top5000 respectively.\n(2) Termhood-based metrics\nThe comparability metrics based on termhood computes word termhood by corpus comparison method after word frequency statistic. Then words vectors are generated based on their termhood. Finally comparability was calculated by cosine value between two vectors represented by words and their termhood. In this method we also compute comparability metrics in six different corpus sizes, i.e. Top100, Top200, Top500, Top1000, Top2000, and Top5000.\nBesides, keywords and all words were both used in our experiments for comparison. It should be noted that keywords come from the abovementioned academic database and all of words come from full-text of document after segment."}, {"heading": "4.3 Experiments and Results", "text": "Fig.1 and Fig.2 are results of comparability based on keywords according to the two measurement methods.\nNotice that both methods reflect the fact that comparability of parallel corpus > comparability of comparable corpus> comparability of non-comparable corpus. However, it is assumed that comparability of comparable corpus should be in the middle of the two; parallel, comparable, non-comparable, comparability of three kinds of corpus should present an even decreasing trends. In comparison, termhood-based approach reflects this point more obviously.\nThe performance of frequency-based method for all word is presented in Fig.3. As a whole, it reflects the fact that comparability of parallel corpus > comparability of non-comparable corpus> comparability of comparable corpus. This is against with our hypothesis. Moreover, this result is inconsistent with frequency-based method using keywords. Furthermore, we can also find that comparability of these kinds of corpus\nis very close to each other, all above 0.9. It is likely that there are so many noisy words that results are affected, further cause incorrect or incredible results.\nThe performance of termhood-based method for all word is presented in Fig.4. Notice that comparability of parallel corpus > comparability of comparable corpus> comparability of non-comparable corpus; comparability of three kinds of corpus present an even decreasing trends. Furthermore, these results using all words are consistent with using only keywords.\nAccording to the above analysis, we can conclude that: according to reflecting the real comparable degree between corpora, termhood-based method is better than frequency-based method. Meanwhile, the results of termhood-based method using keywords are consistent with the situation of using full-text words. It also shows that termhood-based method is more stable and reliable than frequency-based method. Therefore, we can conclude that the performance of termhood-based metric method is better than frequency-based approach."}, {"heading": "5 Evaluation", "text": "Furthermore, we verify the validity of the comparability measure of termhood-based metrics by the task of bilingual term extraction.\nIn this section, we need to learn whether comparable corpus with high comparability can generate bilingual terminology with high quality. Therefore, our experiment is designed to extract bilingual terminology from three corpora with different comparability. These corpora are parallel corpus, comparable corpus and non-comparable corpus respectively. Again, it is assumed that comparability of comparable corpus lies between parallel and non-comparable corpus. We expect that the higher corpus comparability is, the higher quality bilingual terminology we can obtain."}, {"heading": "5.1 Methods of Bilingual Term Extraction and Evaluation", "text": "The method of terminology extraction in our experiment is one of the most popular methods, namely, context vector-based method [18], which includes the following steps.\n1) Preprocessing. For Chinese corpus: segmentation and part of speech. For English: stemming and part of speech;\n2) Generating candidate monolingual terminology; 3) Creating context vector of monolingual terminology based on co-occurrence statistics; 4) Translating Chinese context vector to Eng-lish through bilingual dictionary from LDC [19]; 5) Computing similarity of context vector in singular space of English language. 6) Extracting terminology pairs of which similarity larger than the given threshold. 7) Evaluation of terminology quality. We use Top@N method to evaluate the result of bilingual terminology extraction. That is, for every Top@N English terminology together with N candidate Chinese terms, if there is one is the right translation, we consider the result is correct. Here we take 10 for N. In the evaluation criteria of human judgments, if translation relation is completely correct, the score of matching will be 1; partly correct, score will be calculated by dice coefficient [20]; completely incorrect, score will be zero.\ntokensofnumber ofsum\n*2Dice overlaps= (2)"}, {"heading": "5.2 Results and Analysis", "text": "We use two indicators for overall analysis, the overall similarity of terminology pairs and the overall degree of matching. Table 2 is the result of evaluation. Notice that the overall similarity of term pairs is increasing with the growth of comparability.\nAccording to table 2, the overall degree of matching obtained by machine discrimination is not always increasing with the growth of comparability. In fact, machine discrimination is carried out with the help of dictionary of LDC. As far as we know, LDC\u2019s dictionary is a general dictionary which only includes about 80, 000 pairs bilingual lexicons, but the corpus in our experiments is corpus in special domain. So it is inevitable that there is some deviation because of limited size of bilingual dictionary. Therefore, human evaluation is very necessary. Notice that the overall degree of matching obtained by human judgments is increasing with the growth of comparability.\nWe can also find out that the overall degree of matching, no matter machine or human, is very low. This could well be due to the limited size and quality of bilingual dictionary, small size of our experimental corpus, or the bias caused by parameter settings in terminology extraction based on context vector method. At the same time, the overall similarity of terminology pairs is only related to terminology frequency. It is not affected by other factors. Therefore the result should be more reliable than the overall degree of matching.\nIn summary, we can conclude that the overall similarity of term pairs and the overall degree of matching is increasing with the growth of comparability. Accordingly, we can learn that high comparability of corpus generate high quality bilingual terminology. This also shows that our termhood-based method of comparability is effective in the application of bilingual terminology extraction."}, {"heading": "6 Conclusions and Future Works", "text": "In this paper, we proposed termhood-based method to measure comparability of comparable corpus. Experiment results showed that this method performs better than traditional frequency-based method. It is likely to be that the candidate terms are ranked more reasonable because of constrain of termhood. It is possible that this method is less affected by common words, and it considers quality of term in special domain, so its performance is more stable and better in the task of terminology Extraction.\nExperiments also show that results of comparability are more reliable when using keywords not full-text in the frequency-based method. This is because when using full-text data after preprocessing, there are so many common words that they influence the rank lists, further causing inaccurate results. Regardless of keywords or fulltext data, the results are consistent in the termhood-based method. This again shows that termhood method has a better stability than frequency method.\nAlong the direction of our current work there are some directions for future works. One is to measure the effectiveness of termhood-base method in a more fine-grained comparable level. Another piece of work is to filter out the stop and common words after calculating word frequency, and then calculates the similarity of two words sequence; and finally we can make a comparison between this improved frequencybased method and termhood-based approach."}, {"heading": "Acknowledgement", "text": "This work is supported by National Natural Science Foundation of China under Grant No. 70903032."}], "references": [{"title": "Parallel and comparable corpora: What are they up to", "author": ["A.M. McEnery", "R.Z. Xiao"], "venue": "Proceedings of Incorporating Corpora: Translation and the Linguist Translating Europe Multilingual Matters, Clevedon, UK.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2007}, {"title": "Creating and Exploiting a Comparable Corpus in Cross - Language Information Retrieval", "author": ["T. Talvensaari", "Laurikkala J", "K. J\u00e4rvelin", "M. Juhola", "H. Keskustalo"], "venue": "J.ACM Transactions on Information Systems (TOIS)", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "Bilingual terminology extraction: an approach based on multilingual thesaurus applicable to comparable corpora", "author": ["H. Dejean", "E. Gaussier", "F. Sadat"], "venue": "Proceedings of COLING2002,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2002}, {"title": "Using word frequency lists to measure corpus homogeneity and similarity between corpora", "author": ["A. Kilgarriff"], "venue": "Proceedings of the Fifth Workshop on Very Large Corpora,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1997}, {"title": "Focused web crawling in the acquisition of comparable corpora", "author": ["T. Talvensaari", "A. Pirkola", "K. J\u00e4rvelin", "M. Juhola", "J. Laurikkala"], "venue": "J.Information Retrieval. 11(5), 427-445", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "Search engine based approaches for collecting domain-specific Basque-English comparable corpora from the Internet", "author": ["I. Leturia", "I.S. Vicente", "X. Saralegi"], "venue": "In Proceedings of the Fifth Web as Corpus Workshop (WAC5), pp.53-61.Basque Country, Spain", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "\u0301opez, I.G.: Wikipedia as Multilingual Source of Comparable Corpora", "author": ["P.G. Otero"], "venue": "In Proceedings of the 3rd Workshop on Building and Using Comparable Corpora, LREC2010,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "ACCURAT: Metrics for the evaluation of comparability of multilingual corpora", "author": ["A. Vasi\u013cjevs"], "venue": "Proceedings of the Workshop on Methods for the Automatic Acquisition of Language Resources and their Evaluation Methods, LREC2010.Malta", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Improving Corpus Comparability for Bilingual Lexicon Extraction from Comparable Corpora", "author": ["B. Li", "E. Gaussier"], "venue": "Proceedings of the 23rd International Conference on Computational Linguistics", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2010}, {"title": "Measuring mono-word termhood by rank difference via corpus comparison", "author": ["C.Y. Kit", "X.Y. Liu"], "venue": "J. Terminology", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2008}, {"title": "A Vector Space Model for Automatic Indexing", "author": ["G. Salton", "A. Wong", "C.S. Yang"], "venue": "Communications of the ACM. Malta", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1975}, {"title": "A Statistical view on Bilingual lexicon extraction: From Parallel Corpora to nonparallel corpora", "author": ["P. Fung"], "venue": "Proceedings of Jean Veronis. Parallel Text", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2000}, {"title": "Cognates Can Improve Statistical Translation Models", "author": ["G. Kondrak", "D. Marcu", "K. Knight"], "venue": "In Proceedings of HLT-NAACL 2003: Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2003}], "referenceMentions": [{"referenceID": 0, "context": "Parallel corpus which contains source documents and their translations plays an important role in multilingual information service [1], such as Cross-Language Information Retrieval (CLIR), and machine translation (MT).", "startOffset": 131, "endOffset": 134}, {"referenceID": 1, "context": "It is obviously easier to find document collections with similar topics in multiple languages than to find parallel corpus [2].", "startOffset": 123, "endOffset": 126}, {"referenceID": 2, "context": "In multilingual terminology extraction, comparability is focused on distribution and quality of the vocabulary of translated forms [4].", "startOffset": 131, "endOffset": 134}, {"referenceID": 3, "context": "So far, method of based word frequency list has been always used to measure corpus homogeneity and similarity between corpora [5].", "startOffset": 126, "endOffset": 129}, {"referenceID": 1, "context": "Generally, comparable corpus is generated from news agencies or by crawling certain sites [2].", "startOffset": 90, "endOffset": 93}, {"referenceID": 4, "context": "built comparable corpora based on focused crawling [6].", "startOffset": 51, "endOffset": 54}, {"referenceID": 5, "context": "(2009) used search engine queries for collecting comparable corpora from the Internet [7].", "startOffset": 86, "endOffset": 89}, {"referenceID": 6, "context": "Otero and L \u0301opez exploited Wikipedia for collecting domain comparable corpora by using categories as topic restrictions [8].", "startOffset": 121, "endOffset": 124}, {"referenceID": 1, "context": "used these two methods to measure the comparability of domain-specific comparable corpora obtained from the Internet by using search engine [2].", "startOffset": 140, "endOffset": 143}, {"referenceID": 7, "context": "The ACCURAT (Analysis and evaluation of Comparable Corpora for Under Resourced Areas of Machine Translation) project used asymmetric Chi-square statistics to measure comparability [9].", "startOffset": 180, "endOffset": 183}, {"referenceID": 8, "context": "Li and Gaussier purposed a metrics of comparable corpus for bilingual lexicon extraction [11].", "startOffset": 89, "endOffset": 93}, {"referenceID": 8, "context": "It is in this point that our method is different to Li et al [11], which is oriented to bilingual lexicon.", "startOffset": 61, "endOffset": 65}, {"referenceID": 9, "context": "Kit and Liu proposed a measure for mono-word termhood in terminology of such peculiarity and quantify it in terms of a word\u2019s ranking difference in a domain and background corpus [16].", "startOffset": 179, "endOffset": 183}, {"referenceID": 10, "context": "Then we calculate similarity of the new word list by vector space model [17].", "startOffset": 72, "endOffset": 76}, {"referenceID": 11, "context": "The method of terminology extraction in our experiment is one of the most popular methods, namely, context vector-based method [18], which includes the following steps.", "startOffset": 127, "endOffset": 131}, {"referenceID": 12, "context": "In the evaluation criteria of human judgments, if translation relation is completely correct, the score of matching will be 1; partly correct, score will be calculated by dice coefficient [20]; completely incorrect, score will be zero.", "startOffset": 188, "endOffset": 192}], "year": 2012, "abstractText": "Cross-Language Information Retrieval (CLIR) and machine translation (MT) resources, such as dictionaries and parallel corpora, are scarce and hard to come by for special domains. Besides, these resources are just limited to a few languages, such as English, French, and Spanish and so on. So, obtaining comparable corpora automatically for such domains could be an answer to this problem effectively. Comparable corpora, that the subcorpora are not translations of each other, can be easily obtained from web. Therefore, building and using comparable corpora is often a more feasible option in multilingual information processing. Comparability metrics is one of key issues in the field of building and using comparable corpus. Currently, there is no widely accepted definition or metrics method of corpus comparability. In fact, Different definitions or metrics methods of comparability might be given to suit various tasks about natural language processing. A new comparability, namely, termhood-based metrics, oriented to the task of bilingual terminology extraction, is proposed in this paper. In this method, words are ranked by termhood not frequency, and then the cosine similarities, calculated based on the ranking lists of word termhood, is used as comparability. Experiments results show that termhood-based metrics performs better than traditional frequency-based metrics.", "creator": "PScript5.dll Version 5.2"}}}