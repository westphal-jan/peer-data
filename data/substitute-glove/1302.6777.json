{"id": "1302.6777", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Feb-2013", "title": "Ending-based Strategies for Part-of-speech Tagging", "abstract": "Probabilistic approaches to although - latter - speech tagging improve currently on whole - thought noted when? / ibf combinations although well later datasets analysis. But experience features where 4 per cent of printable encountered at time set any unknown same when the students come indeed with still as turn 300,000 words. Unseen: are tagged applications forms strategies believe opportunities word such particular brought puzzles, subvarieties are punctuation full. In this work, bible - absence statistics several serves and whole - bible according none secondary. First, means groaner had instructor and modified on: endings well. Subsequent experiments half hand still - rather statistics for following words activity been frequently later its training turn. As lived huge, performance had agreed once develop, recently once requires performing the on several word - systems outhustling. Surprisingly, the ending - leading photo-journalist initially songs 30,000 as well several with reference - based ex-cop; over another best possible, its appearance significantly proportion that result the something - of crackhead. Lastly, other surged, an extent far negative returns was observed - new mainly larger, performance become profitability that first declined. By varying factors such as ending length used purse - plus make, enough meaningful though great rate include 33. 51 percent.", "histories": [["v1", "Wed, 27 Feb 2013 14:13:10 GMT  (574kb)", "http://arxiv.org/abs/1302.6777v1", "Appears in Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence (UAI1994)"]], "COMMENTS": "Appears in Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence (UAI1994)", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["greg adams", "beth millar", "eric neufeld", "tim philip"], "accepted": false, "id": "1302.6777"}, "pdf": {"name": "1302.6777.pdf", "metadata": {"source": "CRF", "title": "Ending-based Strategies for Part-of-speech Tagging", "authors": ["Beth Millar", "Eric Neufeld", "Tim Philip"], "emails": ["eric@spr.usask.ca"], "sections": null, "references": [{"title": "Automated word\u00ad class tagging of unseen words in text", "author": ["G. Adams", "E. Neufeld"], "venue": "In Pro\u00ad ceedings of the Sixth International Symposium on Artificial Intelligence,", "citeRegEx": "Adams and Neufeld,? \\Q1993\\E", "shortCiteRegEx": "Adams and Neufeld", "year": 1993}, {"title": "Equations for part-of-speech tagging", "author": ["E. Charniak", "C. Henrickson", "N. Jacobson", "M. Perkowitz"], "venue": "In Proceedings of the Eleventh National Conference on Artificial Intelligence,", "citeRegEx": "Charniak et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Charniak et al\\.", "year": 1993}, {"title": "A stochastic parts program and noun phrase parser for unrestricted text", "author": ["K.W. Church"], "venue": "In Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing,", "citeRegEx": "Church,? \\Q1989\\E", "shortCiteRegEx": "Church", "year": 1989}, {"title": "A comparison of the enhanced Good-Thring and deleted estima\u00ad tion methods for estimating probabilities of En\u00ad glish bigrams", "author": ["A. W"], "venue": "Computer Speech and Language,", "citeRegEx": "W.,? \\Q1991\\E", "shortCiteRegEx": "W.", "year": 1991}, {"title": "Grammatical category disam\u00ad biguation by statistical optimization", "author": ["S.J. DeRose"], "venue": "Computa\u00ad tional Linguistics,", "citeRegEx": "DeRose,? \\Q1988\\E", "shortCiteRegEx": "DeRose", "year": 1988}, {"title": "Statistical lexical disambiguation", "author": ["G.F. Foster"], "venue": "Master's thesis,", "citeRegEx": "Foster,? \\Q1991\\E", "shortCiteRegEx": "Foster", "year": 1991}, {"title": "The Computational Analysis of English: A Corpus\u00ad Based Approach", "author": ["R. Garside", "G. Leech", "G. Sampson"], "venue": null, "citeRegEx": "Garside et al\\.,? \\Q1987\\E", "shortCiteRegEx": "Garside et al\\.", "year": 1987}, {"title": "The population frequencies of species and the estimation of population", "author": ["I.J. Good"], "venue": "parame\u00ad ters. Biometrika,", "citeRegEx": "Good,? \\Q1953\\E", "shortCiteRegEx": "Good", "year": 1953}, {"title": "The LOB Corpus of British En\u00ad glish texts: Presentation and comments", "author": ["S. Johansson"], "venue": "ALLC Journal,", "citeRegEx": "Johansson,? \\Q1980\\E", "shortCiteRegEx": "Johansson", "year": 1980}, {"title": "T he Tagged LOB Corpus: Users' Manual. Norwegian Computing Centre for the Humanities, Bergen, Norway", "author": ["S. Johansson", "E. Atwell", "R. Garside", "G. Leech"], "venue": null, "citeRegEx": "Johansson et al\\.,? \\Q1986\\E", "shortCiteRegEx": "Johansson et al\\.", "year": 1986}, {"title": "A cache-based nat\u00ad ural language model for speech recognition", "author": ["R. Kuhn", "R. De Mori"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Kuhn and Mori,? \\Q1990\\E", "shortCiteRegEx": "Kuhn and Mori", "year": 1990}, {"title": "Computa\u00ad tional Analysis of Present-Day", "author": ["H. Kucera", "W.N. Francis"], "venue": null, "citeRegEx": "Kucera and Francis,? \\Q1967\\E", "shortCiteRegEx": "Kucera and Francis", "year": 1967}, {"title": "Tagging text with a probabilistic model", "author": ["B. Merialdo"], "venue": "In Proceedings of the IBM Natural Lan\u00ad guage ITL,", "citeRegEx": "Merialdo,? \\Q1990\\E", "shortCiteRegEx": "Merialdo", "year": 1990}, {"title": "POST: Using probabilities in language process\u00ad", "author": ["M. Meteer", "R. Schwartz", "R. Weischedel"], "venue": "Proceedings of the 19th Interna\u00ad tional Joint Conference on Artificial Intelligence,", "citeRegEx": "Meteer et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Meteer et al\\.", "year": 1991}, {"title": "Annotation Manual for the Penn Treebank Project", "author": ["B. Santorini"], "venue": "Technical report, CIS Depart\u00ad ment,", "citeRegEx": "Santorini,? \\Q1990\\E", "shortCiteRegEx": "Santorini", "year": 1990}, {"title": "Selected Studies of the Principle of Relative Frequency in Language. Harvard Univer\u00ad", "author": ["G.K. Zipf"], "venue": null, "citeRegEx": "Zipf,? \\Q1932\\E", "shortCiteRegEx": "Zipf", "year": 1932}], "referenceMentions": [{"referenceID": 15, "context": "Although probabilistic approaches to linguistic problems were attempted earlier in the cen\u00ad tury (Zipf, 1932), they were hampered by the very real difficulties of collecting meaningful statistics and of performing subsequent calculations.", "startOffset": 97, "endOffset": 109}, {"referenceID": 8, "context": "Recently prob\u00ad abilistic approaches have overcome these difficulties with the availability of electronic corpora such as the LOB Corpus (Johansson, 1980; Johansson et al., 1986), the Brown Corpus (Kucera and Francis, 1967) or the UPenn corpus (Santorini, 1990), as well as the existence of powerful and inexpensive computers.", "startOffset": 136, "endOffset": 177}, {"referenceID": 9, "context": "Recently prob\u00ad abilistic approaches have overcome these difficulties with the availability of electronic corpora such as the LOB Corpus (Johansson, 1980; Johansson et al., 1986), the Brown Corpus (Kucera and Francis, 1967) or the UPenn corpus (Santorini, 1990), as well as the existence of powerful and inexpensive computers.", "startOffset": 136, "endOffset": 177}, {"referenceID": 11, "context": ", 1986), the Brown Corpus (Kucera and Francis, 1967) or the UPenn corpus (Santorini, 1990), as well as the existence of powerful and inexpensive computers.", "startOffset": 26, "endOffset": 52}, {"referenceID": 14, "context": ", 1986), the Brown Corpus (Kucera and Francis, 1967) or the UPenn corpus (Santorini, 1990), as well as the existence of powerful and inexpensive computers.", "startOffset": 73, "endOffset": 90}, {"referenceID": 2, "context": "A common approach to POS tagging is the hidden Markov model (HMM) (Jelinek, 1985; Church, 1989; Foster, 1991; Merialdo, 1990; Kuhn and De Mori, 1990) or variations thereof (DeRose, 1988; Garside et al.", "startOffset": 66, "endOffset": 149}, {"referenceID": 5, "context": "A common approach to POS tagging is the hidden Markov model (HMM) (Jelinek, 1985; Church, 1989; Foster, 1991; Merialdo, 1990; Kuhn and De Mori, 1990) or variations thereof (DeRose, 1988; Garside et al.", "startOffset": 66, "endOffset": 149}, {"referenceID": 12, "context": "A common approach to POS tagging is the hidden Markov model (HMM) (Jelinek, 1985; Church, 1989; Foster, 1991; Merialdo, 1990; Kuhn and De Mori, 1990) or variations thereof (DeRose, 1988; Garside et al.", "startOffset": 66, "endOffset": 149}, {"referenceID": 4, "context": "A common approach to POS tagging is the hidden Markov model (HMM) (Jelinek, 1985; Church, 1989; Foster, 1991; Merialdo, 1990; Kuhn and De Mori, 1990) or variations thereof (DeRose, 1988; Garside et al., 1987) where language is assumed to be produced by a hidden model that cannot be observed directly but whose effects can be observed.", "startOffset": 172, "endOffset": 208}, {"referenceID": 6, "context": "A common approach to POS tagging is the hidden Markov model (HMM) (Jelinek, 1985; Church, 1989; Foster, 1991; Merialdo, 1990; Kuhn and De Mori, 1990) or variations thereof (DeRose, 1988; Garside et al., 1987) where language is assumed to be produced by a hidden model that cannot be observed directly but whose effects can be observed.", "startOffset": 172, "endOffset": 208}, {"referenceID": 5, "context": "Since performance improves only marginally for k > 1 (Foster, 1991), we use k == 1.", "startOffset": 53, "endOffset": 67}, {"referenceID": 0, "context": "An interesting problem is handling unseen words (Adams and Neufeld, 1993; Church, 1989; Fos\ufffder, 1991; Merialdo, 1990; Meteer et al., 1991; Kuptec, 1992), that is, words not occurring in the tra\ufffd\ufffdi\ufffdg cor\u00ad pus, and therefore words for which probabihties \ufffdre not known.", "startOffset": 48, "endOffset": 152}, {"referenceID": 2, "context": "An interesting problem is handling unseen words (Adams and Neufeld, 1993; Church, 1989; Fos\ufffder, 1991; Merialdo, 1990; Meteer et al., 1991; Kuptec, 1992), that is, words not occurring in the tra\ufffd\ufffdi\ufffdg cor\u00ad pus, and therefore words for which probabihties \ufffdre not known.", "startOffset": 48, "endOffset": 152}, {"referenceID": 12, "context": "An interesting problem is handling unseen words (Adams and Neufeld, 1993; Church, 1989; Fos\ufffder, 1991; Merialdo, 1990; Meteer et al., 1991; Kuptec, 1992), that is, words not occurring in the tra\ufffd\ufffdi\ufffdg cor\u00ad pus, and therefore words for which probabihties \ufffdre not known.", "startOffset": 48, "endOffset": 152}, {"referenceID": 13, "context": "An interesting problem is handling unseen words (Adams and Neufeld, 1993; Church, 1989; Fos\ufffder, 1991; Merialdo, 1990; Meteer et al., 1991; Kuptec, 1992), that is, words not occurring in the tra\ufffd\ufffdi\ufffdg cor\u00ad pus, and therefore words for which probabihties \ufffdre not known.", "startOffset": 48, "endOffset": 152}, {"referenceID": 5, "context": "Testing the tagger on a subset of the tram\u00ad ing corpus or only on known words (Foster, 1991; Meteer et al., 1991) inflates accuracy because much of the vocabulary is used infrequently.", "startOffset": 78, "endOffset": 113}, {"referenceID": 13, "context": "Testing the tagger on a subset of the tram\u00ad ing corpus or only on known words (Foster, 1991; Meteer et al., 1991) inflates accuracy because much of the vocabulary is used infrequently.", "startOffset": 78, "endOffset": 113}, {"referenceID": 0, "context": "For example, (Adams and Neufeld, 1993) reports that after training a tagger on a 900,000 token subset of the LOB corpus, about 3700 of 100,000 tokens in the test corpus are unseen.", "startOffset": 13, "endOffset": 38}, {"referenceID": 0, "context": "Building on this approach, and observing that such a set must be chosen by a native speaker of the language, in (Adams and Neufeld, 1993) statistics are collected on arbi\ufffdrary 2-, 3- and 4-letter word endings and other promu\ufffdent word features such as capitalization or punctuatiOn.", "startOffset": 112, "endOffset": 137}, {"referenceID": 1, "context": "In other work, Church (1989) uses capitalization to identify unseen proper nouns.", "startOffset": 15, "endOffset": 29}, {"referenceID": 1, "context": "In other work, Church (1989) uses capitalization to identify unseen proper nouns. Meteer et al. (1991) attack unseen words by identifying combinations of prominent word features, in particular, statistics \ufffdn a definitive set of 32 predefined inflectional and denva\u00ad tional word endings, such as -ed and -ion.", "startOffset": 15, "endOffset": 103}, {"referenceID": 0, "context": "Building on this approach, and observing that such a set must be chosen by a native speaker of the language, in (Adams and Neufeld, 1993) statistics are collected on arbi\ufffdrary 2-, 3- and 4-letter word endings and other promu\ufffdent word features such as capitalization or punctuatiOn. That work also uses an external lexicon with no statis\u00ad tics but containing associated part of speech tags with words that helps the tagger to avoid bad guesses. Ku\u00ad piec (1992) uses estimates of frequency of features with tags.", "startOffset": 113, "endOffset": 460}, {"referenceID": 7, "context": "We also compared the \"add-one\" estimate against the Good-Turing estimator (Good, 1953).", "startOffset": 74, "endOffset": 86}, {"referenceID": 13, "context": "4 per cent) (Meteer et al., 1991; Adams and Neufeld, 1993) and guessing randomly at unseen words.", "startOffset": 12, "endOffset": 58}, {"referenceID": 0, "context": "4 per cent) (Meteer et al., 1991; Adams and Neufeld, 1993) and guessing randomly at unseen words.", "startOffset": 12, "endOffset": 58}, {"referenceID": 13, "context": "This work also sup\u00ad ports the kind of observations in (Meteer et al., 1991) that taggers perhaps don't require the huge training", "startOffset": 54, "endOffset": 75}, {"referenceID": 13, "context": "In (Meteer et al., 1991), it is noted that a tagger trained on 64,000 words rather than 1,000,000 suffers a relatively small decline in per\u00ad", "startOffset": 3, "endOffset": 24}, {"referenceID": 0, "context": "One is suggested by the result of (Adams and Neufeld, 1993), where it was observed that a tagger containing all whole-word statistics from the training corpus performed better with three-letter endings than with either two- or four-letter endings.", "startOffset": 34, "endOffset": 59}], "year": 2011, "abstractText": "Probabilistic approaches to part-of-speech tagging rely primarily on whole-word statis\u00ad tics about word/tag combinations as well as contextual information. But experience shows about 4 per cent of tokens encountered in test sets are unknown even when the train\u00ad ing set is as large as a million words. Unseen words are tagged using secondary strategies that exploit word features such as endings, capitalizations and punctuation marks. In this work, word-ending statistics are pri\u00ad mary and whole-word statistics are sec\u00ad ondary. First, a tagger was trained and tested on word endings only. Subsequent ex\u00ad periments added back whole-word statistics for the N words occurring most frequently in the training set. As N grew larger, per\u00ad formance was expected to improve, in the limit performing the same as word-based tag\u00ad gers. Surprisingly, the ending-based tag\u00ad ger initially performed nearly as well as the word-based tagger; in the best case, its per\u00ad formance significantly exceeded that of the word-based tagger. Lastly, and unexpect\u00ad edly, an effect of negative returns was ob\u00ad servedas N grew larger, performance gen\u00ad erally improved and then declined. By vary\u00ad ing factors such as ending length and tag-list strategy, we achieved a success rate of 97.5 percent.", "creator": "pdftk 1.41 - www.pdftk.com"}}}