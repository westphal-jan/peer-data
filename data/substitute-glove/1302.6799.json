{"id": "1302.6799", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Feb-2013", "title": "Integrating Planning and Execution in Stochastic Domains", "abstract": "We investigate working at time - critical sub-groups \u2014 used Markov Decision Processes, reveal that search information aspects we already a find hard method without finding than put optimal plans. To reduce the semantics cost still establish new except domains, always execute noting because actually modular the plan, and inalienable optimality saw retrieve on a rates depth made easier a estimation specific to estimate place given over states. Although called collected utilizing on the search checksum, want also dialogue ways now utilized debugging functions reliable any. emphasizing. Our results entertainment that by amplifications seeking and execution, close to optimal ways can but another take be computational requirements of already shifting.", "histories": [["v1", "Wed, 27 Feb 2013 14:15:13 GMT  (1122kb)", "http://arxiv.org/abs/1302.6799v1", "Appears in Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence (UAI1994)"]], "COMMENTS": "Appears in Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence (UAI1994)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["richard dearden", "craig boutilier"], "accepted": false, "id": "1302.6799"}, "pdf": {"name": "1302.6799.pdf", "metadata": {"source": "CRF", "title": "Integrating Planning and Execution in Stochastic Domains", "authors": ["Richard Dearden", "Craig Boutilier"], "emails": ["dearden@cs.", "cebly@cs."], "sections": null, "references": [{"title": "The *-minimax search procedure for trees containing chance nodes", "author": ["B.W. Ballard"], "venue": "Artificial Intelligence, 21:327-350. Boutilier, C. and Dearden, R. 1994. Using abstractions for decision-theoretic planning with time constraints.", "citeRegEx": "Ballard,? 1983", "shortCiteRegEx": "Ballard", "year": 1983}, {"title": "Deliberation scheduling for time-critical deci\u00ad sion making", "author": ["T. Dean", "L.P. Kaelbling", "J. Kirman", "A. Nicholson"], "venue": "Proceedings of the Twelfth National Conference on Artificial Intelligence, Seattle", "citeRegEx": "Dean et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Dean et al\\.", "year": 1993}, {"title": "Planning with deadlines in stochastic domains", "author": ["T. Dean", "L.P. Kaelbling", "J. Kirman", "A. Nicholson"], "venue": "Proceedings of the Eleventh National Conference on Artificial Intelligence, pages 574-579, Washington, D.C.", "citeRegEx": "Dean et al\\.,? 1993b", "shortCiteRegEx": "Dean et al\\.", "year": 1993}, {"title": "Strips: A new ap\u00ad proach to the application of theorem proving to prob\u00ad lem solving", "author": ["R.E. Fikes", "N.J. Nilsson"], "venue": "Artificial Intelligence, 2:189-208.", "citeRegEx": "Fikes and Nilsson,? 1971", "shortCiteRegEx": "Fikes and Nilsson", "year": 1971}, {"title": "Dynamic Probabilistic Systems", "author": ["R.A. Howard"], "venue": "Wi\u00ad ley, New York.", "citeRegEx": "Howard,? 1971", "shortCiteRegEx": "Howard", "year": 1971}, {"title": "Real-time heuristic search", "author": ["R.E. Korf"], "venue": "Artificial Intelligence, 42:189-211.", "citeRegEx": "Korf,? 1990", "shortCiteRegEx": "Korf", "year": 1990}, {"title": "An al\u00ad gorithm for probabilistic planning", "author": ["N. Kushmerick", "S. Hanks", "D. Weld"], "venue": "Technical Report 93-06-04, University of Washington, Seattle.", "citeRegEx": "Kushmerick et al\\.,? 1993", "shortCiteRegEx": "Kushmerick et al\\.", "year": 1993}, {"title": "Heuristics: Intelligent Search Strategies for Computer Problem Solving", "author": ["J. Pearl"], "venue": "Addison-Wesley, Read\u00ad ing, Massachusetts.", "citeRegEx": "Pearl,? 1984", "shortCiteRegEx": "Pearl", "year": 1984}, {"title": "Do the Right Thing: Studies in Limited Rationality", "author": ["S.J. Russell", "E. Wefald"], "venue": "MIT Press, Cam\u00ad bridge.", "citeRegEx": "Russell and Wefald,? 1991", "shortCiteRegEx": "Russell and Wefald", "year": 1991}, {"title": "Abstraction in planning", "author": ["J.D. Tenenberg"], "venue": "Allen, J", "citeRegEx": "Tenenberg,? 1991", "shortCiteRegEx": "Tenenberg", "year": 1991}], "referenceMentions": [{"referenceID": 2, "context": "In (Dean et al. 1993b) it is suggested that domain-specific heuristics will aid in initial envelope selection and envelope alteration.", "startOffset": 3, "endOffset": 22}, {"referenceID": 5, "context": "This is the basic idea behind for example, Korf's real-time heuristic search algorithm (1990). \u00b7 In stochastic domains there is an\u00ad other important reason for interleaving execution into the planning process, namely, to restrict the search space to the actual outcomes of probabilistic actions.", "startOffset": 43, "endOffset": 94}, {"referenceID": 2, "context": "1 Since we are interleaving plan construction and plan execution, the time required to plan is significant when measuring success; but as a first approximation we can represent this type of sit\u00ad uation with the reward function (Dean et al. 1993b): R(s) = 0 if s E Sg and R(s) = -1 otherwise.", "startOffset": 227, "endOffset": 246}, {"referenceID": 5, "context": "The use of caching here is similar to that of Learning RTA * search (Korf 1990).", "startOffset": 68, "endOffset": 79}, {"referenceID": 0, "context": "This search technique is related to the *-minimax algorithm of Ballard (1983). As we shall see in Section 3.", "startOffset": 63, "endOffset": 78}, {"referenceID": 8, "context": "The poten\u00ad tially improved performance of a deeper search has to be weighed against the time required to perform the search (Russell and Wefald 1991).", "startOffset": 124, "endOffset": 149}, {"referenceID": 0, "context": "Determining the value of a state is analogous to the MAX step in minimax, while calculating the value of an action can be th ought of as an AVERAGE step, which replaces the MIN step (see also (Ballard 1983)).", "startOffset": 192, "endOffset": 206}, {"referenceID": 5, "context": "Expectation pruning is closely related to what Korf (1990) calls alpha-pruning.", "startOffset": 47, "endOffset": 59}, {"referenceID": 9, "context": "In some cases abstractions of actions and states may already be available (Tenenberg 1991).", "startOffset": 74, "endOffset": 90}, {"referenceID": 3, "context": "If abstract actions (possibly macro-operators (Fikes and Nilsson 1971)) are already available, we need to find clusters to which the actions apply.", "startOffset": 46, "endOffset": 70}, {"referenceID": 7, "context": "In none of the domains we have tested has searching deeper produced a worse pol\u00ad icy, although this may not be the case in general (see (Pearl 1984) for a proof of this for minimax search).", "startOffset": 136, "endOffset": 148}, {"referenceID": 1, "context": "In par\u00ad ticular, further comparison to exact methods like pol\u00ad icy iteration and heuristic methods like the envelope approach of Dean et al. (1993b) would be useful.", "startOffset": 129, "endOffset": 149}, {"referenceID": 8, "context": ", as in (Russell and Wefald 1991) ) .", "startOffset": 8, "endOffset": 33}, {"referenceID": 1, "context": "reconstruction phase of the recurrent deliberation model of Dean et al. (1993a).", "startOffset": 60, "endOffset": 80}, {"referenceID": 7, "context": "We also hope to investigate the performance of this approach in other types of domains, including high-level robot navigation, and scheduling problems, and to further investigate the theoretical properties of the algorithm, especially through analysis of the value of deeper searching in producing better plans (Pearl 1984).", "startOffset": 311, "endOffset": 323}], "year": 2011, "abstractText": "We investigate planning in time-critical do\u00ad mains represented as Markov Decision Pro\u00ad cesses, showing that search based techniques can be a very powerful method for finding close to optimal plans. \u00b7To reduce the compu\u00ad tational cost of planning in these domains, we execute actions as we construct the plan, and sacrifice optimality by searching to a fixed depth and using a heuristic function to esti\u00ad mate the value of states. Although this paper concentrates on the search algorithm, we also discuss ways of constructing heuristic func\u00ad tions suitable for this approach. Our results show that by interleaving search and execu\u00ad tion, close to optimal policies can be found without the computational requirements of other approaches.", "creator": "pdftk 1.41 - www.pdftk.com"}}}