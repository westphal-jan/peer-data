{"id": "1311.6425", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Nov-2013", "title": "Robust Multimodal Graph Matching: Sparse Coding Meets Graph Matching", "abstract": "Graph matching is a debate mean have better major requiring in a wide range of of, early image and screen analysis as biological and lab problems. We devise a unusually graph blue computations 1950s in sparsity - those incorporating. We cast first problem, shaped separate for collaborative re-installation nonstandard, there though institutions - smooth convex regression problem being are be efficiently imagined direct augmented Lagrangian techniques. The method see issue with average sometimes unweighted manifolds, from better as client-server data, then different stochastic represent other various of numbers. The scheme approach as also simply integrated past collaborative graph inference experiments, daunting general internet hypothesis problems leaving. visible variables, possibly coming 30 than programmatic, other same following correspondence. The convolution one study out accounted before control - although - the - art graph stripe applying in as synthetic and what graphs. We others there overall immediately multimodal graphs example applied if focused syllogism only researchers connectivity from alignment - calls structure dipole telescopes techniques (fMRI) analyzed. The registration, referring available.", "histories": [["v1", "Mon, 25 Nov 2013 19:57:49 GMT  (57kb,D)", "http://arxiv.org/abs/1311.6425v1", "NIPS 2013"]], "COMMENTS": "NIPS 2013", "reviews": [], "SUBJECTS": "math.OC cs.LG stat.ML", "authors": ["marcelo fiori", "pablo sprechmann", "joshua t vogelstein", "pablo mus\u00e9", "guillermo sapiro"], "accepted": true, "id": "1311.6425"}, "pdf": {"name": "1311.6425.pdf", "metadata": {"source": "CRF", "title": "Robust Multimodal Graph Matching: Sparse Coding Meets Graph Matching", "authors": ["Marcelo Fiori", "Pablo Sprechmann"], "emails": ["mfiori@fing.edu.uy", "pablo.sprechmann@duke.edu", "jovo@math.duke.edu", "pmuse@fing.edu.uy", "guillermo.sapiro@duke.edu"], "sections": [{"heading": "1 Introduction", "text": "Problems related to graph isomorphisms have been an important and enjoyable challenge for the scientific community for a long time. The graph isomorphism problem itself consists in determining whether two given graphs are isomorphic or not, that is, if there exists an edge preserving bijection between the vertex sets of the graphs. This problem is also very interesting from the computational complexity point of view, since its complexity level is still unsolved: it is one of the few problems in NP not yet classified as P nor NP-complete (Conte et al., 2004). The graph isomorphism problem is contained in the (harder) graph matching problem, which consists in finding the exact isomorphism between two graphs. Graph matching is therefore a very challenging problem which has several applications, e.g., in the pattern recognition and computer vision areas. In this paper we address the problem of (potentially multimodal) graph matching when the graphs are not exactly isomorphic. This is by far the most common scenario in real applications, since the graphs to be compared are the result of a measuring or description process, which is naturally affected by noise.\nGiven two graphs GA and GB with p vertices, which we will characterize in terms of their p \u00d7 p adjacency matrices A and B, the graph matching problem consists in finding a correspondence between the nodes of GA and GB minimizing some matching error. In terms of the adjacency matrices, this corresponds to finding a matrix P in the set of permutation matrices P , such that it minimizes some distance between A and PBPT. A common choice is the Frobenius norm ||A\u2212PBPT||2F , where ||M||2F = \u2211 ij M 2 ij . The graph matching problem can be then stated as\nmin P\u2208P ||A\u2212PBPT||2F = min P\u2208P ||AP\u2212PB||2F . (1)\nar X\niv :1\n31 1.\n64 25\nv1 [\nm at\nh. O\nC ]\nThe combinatorial nature of the permutation search makes this problem NP in general, although polynomial algorithms have been developed for a few special types of graphs, like trees or planar graphs for example (Conte et al., 2004).\nThere are several and diverse techniques addressing the graph matching problem, including spectral methods (Umeyama, 1988) and problem relaxations (Zaslavskiy et al., 2009; Vogelstein et al., 2012; Almohamad & Duffuaa, 1993). A good review of the most common approaches can be found in Conte et al. (2004). In this paper we focus on the relaxation techniques for solving an approximate version of the problem. Maybe the simplest one is to relax the feasible set (the permutation matrices) to its convex hull, the set of doubly stochastic matrices D, which consist of the matrices with nonnegative entries such that each row and column sum up one: D = {M \u2208 Rp\u00d7p : Mij \u2265 0,M1 = 1,MT1 = 1}, 1 being the p-dimensional vector of ones. The relaxed version of the problem is\nP\u0302 = arg min P\u2208D ||AP\u2212PB||2F ,\nwhich is a convex problem, though the result is a doubly stochastic matrix instead of a permutation. The final node correspondence is obtained as the closest permutation matrix to P\u0302: P\u2217 = arg minP\u2208P ||P\u2212 P\u0302||2F , which is a linear assignment problem that can be solved inO(p3) by the Hungarian algorithm (Kuhn, 1955). However, this last step lacks any guarantee about the graph matching problem itself. This approach will be referred to as QCP for quadratic convex problem.\nOne of the newest approximate methods is the PATH algorithm by Zaslavskiy et al. (2009), which combines this convex relaxation with a concave relaxation. Another new technique is the FAQ method by Vogelstein et al. (2012), which solves a relaxed version of the Quadratic Assignment Problem. We compare the method here proposed to all these techniques in the experimental section.\nThe main contributions of this work are two-fold. Firstly, we propose a new and versatile formulation for the graph matching problem which is more robust to noise and can naturally manage multimodal data. The technique, which we call GLAG for Group lasso graph matching, is inspired by the recent works on sparse modeling, and in particular group and collaborative sparse coding. We present several experimental evaluations to back up these claims. Secondly, this proposed formulation fits very naturally into the alignment-free collaborative network inference problem, where we collaborative exploit non-aligned (possibly multimodal) data to infer the underlying common network, making this application never addressed before to the best of our knowledge. We assess this with experiments using real fMRI data.\nThe rest of this paper is organized as follows. In Section 2 we present the proposed graph matching formulation, and we show how to solve the optimization problem in Section 3. The joint collaborative network and permutation learning application is described in Section 4. Experimental results are presented in Section 5, and we conclude in Section 6."}, {"heading": "2 Graph matching formulation", "text": "We consider the problem of matching two graphs that are not necessarily perfectly isomorphic. We will assume the following model: Assume that we have a noise free graph characterized by an adjacency matrix T. Then we want to match two graphs with adjacency matrices A = T + OA and B = PTo TPo + OB, where OA and OB have a sparse number of non-zero elements of arbitrary magnitude. This realistic model is often used in experimental settings, e.g., (Zaslavskiy et al., 2009).\nIn this context, the QCP formulation tends to find a doubly stochastic matrix P which minimizes the \u201caverage error\u201d between AP and PB. However, these spurious mismatching edges can be thought of as outliers, so we would want a metric promoting that AP and PB share the same active set (non zero entries representing edges), with the exception of some sparse entries. This can be formulated in terms of the group Lasso penalization (Yuan & Lin, 2006). In short, the group Lasso takes a set of groups of coefficients and promotes that only some of these groups are active, while the others remain zero. Moreover, the usual behavior is that when a group is active, all the coefficients in the group are non-zero. In this particular graph matching application, we form p2 groups, one per matrix entry (i, j), each one consisting of the 2-dimensional vector ( (AP)ij , (PB)ij ) . The proposed cost function is then the sum of the l2 norms of the groups:\nf(P ) = \u2211 i,j \u2223\u2223\u2223\u2223((AP)ij , (PB)ij)\u2223\u2223\u2223\u22232 . (2)\nIdeally we would like to solve the graph matching problem by finding the minimum of f over the set of permutation matrices P . Of course this formulation is still computationally intractable, so we solve the relaxed version, changing P by its convex hull D, resulting in the convex problem\nP\u0303 = arg min P\u2208D f(P). (3)\nAs with the Frobenius formulation, the final step simply finds the closest permutation matrix to P\u0303.\nLet us analyze the case when A and B are the adjacency matrices of two isomorphic undirected unweighted graphs with e edges and no self-loops. Since the graphs are isomorphic, there exist a permutation matrix Po such that A = PoBPTo .\nLemma 1 Under the conditions stated above, the minimum value of the optimization problem (3) is 2 \u221a\n2e and it is reached by Po, although the solution is not unique in general. Moreover, any solution P of problem (3) satisfies AP = PB.\nProof: Let (a)k denote all the p2 entries of AP, and (b)k all the entries of PB. Then f(P) can be re-written as f(P) = \u2211 k \u221a a2k + b 2 k . Observing that \u221a a2 + b2 \u2265 \u221a 2 2 (a+ b), we have\nf(P ) = \u2211 k \u221a a2k + b 2 k \u2265 \u2211 k \u221a 2 2 (ak + bk) . (4)\nNow, since P is doubly stochastic, the sum of all the entries of AP is equal to the sum of all the entries of A, which is two times the number of edges. Therefore \u2211 k ak = \u2211 k bk = 2e and\nf(P) \u2265 2 \u221a 2e.\nThe equality in (4) holds if and only if ak = bk for all k, which means that AP = PB. In particular, this is true for the permutation Po, which completes the proof of all the statements.\nThis Lemma shows that the fact that the weights in A and B are not compared in magnitude does not affect the matching performance when the two graphs are isomorphic and have equal weights. On the other hand, this property places a fundamental role when moving away from this setting. Indeed, since the group lasso tends to set complete groups to zero, and the actual value of the non-zero coefficients is less important, this allows to group very dissimilar coefficients together, if that would result in fewer active groups. This is even more evident when using the l\u221e norm instead of the l2 norm of the groups, and the optimization remains very similar to the one presented below. Moreover, the formulation remains valid when both graphs come from different modalities, a fundamental property when for example addressing alignment-free collaborative graph inference as presented in Section 4 (the elegance with which this graph matching formulation fits into such problem will be further stressed there). In contrast, the Frobenious-based approaches mentioned in the introduction are very susceptible to differences in edge magnitudes and not appropriate for multimodal matching1."}, {"heading": "3 Optimization", "text": "The proposed minimization problem (3) is convex but non-differentiable. Here we use an efficient variant of the Alternating Direction Method of Multipliers (ADMM) (Bertsekas & Tsitsiklis, 1989). The idea is to write the optimization problem as an equivalent artificially constrained problem, using two new variables \u03b1,\u03b2 \u2208 Rp\u00d7p:\nmin P\u2208D \u2211 i,j || ( \u03b1ij ,\u03b2ij ) ||2 s.t. \u03b1 = AP, \u03b2 = PB. (5)\nThe ADMOM method generates a sequence which converges to the minimum of the augmented Lagrangian of the problem:\nL(P,\u03b1,\u03b2,U,V) = \u2211 i,j || ( \u03b1ij ,\u03b2ij ) ||2 + c 2 ||\u03b1\u2212AP + U||2 + c 2 ||\u03b2 \u2212PB + V||2 ,\n1If both graphs are binary and we limit to permutation matrices (for which there are no algorithms known to find the solution in polynomial time), then the minimizers of (2) and (1) are the same (Vince Lyzinski, personal communication).\nwhere U and V are related to the Lagrange multipliers and c is a fixed constant.\nThe decoupling produced by the new artificial variables allows to update their values one at a time, minimizing the augmented Lagrangian L. We first update the pair (\u03b1,\u03b2) while keeping fixed (P,U,V); then we minimize for P; and finally update U and V, as described next in Algorithm 1.\nInput : Adjacency matrices A,B, c > 0. Output: Permutation matrix P\u2217 Initialize U = 0, V = 0, P = 1\np 1T1\nwhile stopping criterion is not satisfied do (\u03b1t+1,\u03b2t+1) = argmin\u03b1,\u03b2 \u2211 i,j || ( \u03b1ij ,\u03b2ij ) ||2 + c2 ||\u03b1\u2212AP t + Ut||2F + c2 ||\u03b2 \u2212P tB + Vt||2F\nPt+1 = argminP\u2208D 1 2 ||\u03b1t+1 \u2212AP + Ut||2F + 12 ||\u03b2 t+1 \u2212PB + Vt||2F Ut+1 = Ut +\u03b1t+1 \u2212APt+1 Vt+1 = Vt + \u03b2t+1 \u2212Pt+1B\nend P\u2217 = argminQ\u2208P ||Q\u2212P||2F Algorithm 1: Robust graph matching algorithm. See text for implementation details of each step.\nThe first subproblem is decomposable into p2 scalar problems (one for each matrix entry),\nmin \u03b1ij ,\u03b2ij\n|| ( \u03b1ij ,\u03b2ij ) ||2 + c\n2 (\u03b1ij \u2212 (APt)ij + Utij)2 +\nc 2 (\u03b2ij \u2212 (P tB)ij + V t ij) 2.\nFrom the optimality conditions on the subgradient of this subproblem, it can be seen that this can be solved in closed form by means of the well know vector soft-thresholding operator (Yuan & Lin, 2006): Sv(b, \u03bb) = [ 1\u2212 \u03bb||b||2 ] + b .\nThe second subproblem is a minimization of a convex differentiable function over a convex set, so general solvers can be chosen for this task. For instance, a projected gradient descent method can be used. However, this would require to compute several projections onto D per iteration, which is one of the computationally most expensive steps. Nevertheless, we can choose to solve a linearized version of the problem while keeping the convergence guarantees of the algorithm (Lin et al., 2011). In this case, the linear approximation of the first term is:\n1 2 ||\u03b1t+1 \u2212AP + Ut||2F \u2248 1 2 ||\u03b1t+1 \u2212APk + Ut||2F + \u3008gk,P\u2212P k\u3009+ 1 2\u03c4 ||P\u2212Pk||2F ,\nwhere gk = \u2212AT(\u03b1t+1 + Ut\u2212APk) is the gradient of the linearized term, \u3008\u00b7, \u00b7\u3009 is the usual inner product of matrices, and \u03c4 is any constant such that \u03c4 < 1\n\u03c1(ATA) , with \u03c1(\u00b7) being the spectral norm.\nThe second term can be linearized analogously, so the minimization of the second step becomes\nmin P\u2208D\n1 2 ||P\u2212\n( Pk + \u03c4AT(\u03b1t+1 + Ut \u2212APk) )\ufe38 \ufe37\ufe37 \ufe38 fixed matrix C ||2F+ 1 2 ||P\u2212 ( Pk + \u03c4(\u03b2t+1 + Vt \u2212PkB)BT )\ufe38 \ufe37\ufe37 \ufe38 fixed matrix D ||2F\nwhich is simply the projection of the matrix 12 (C + D) over D.\nSummarizing, each iteration consists of p2 vector thresholdings when solving for (\u03b1,\u03b2), one projection over D when solving for P, and two matrix multiplications for the update of U and V. The code is publicly available at www.fing.edu.uy/\u02dcmfiori."}, {"heading": "4 Application to joint graph inference of not pre-aligned data", "text": "Estimating the inverse covariance matrix is a very active field of research. In particular the inference of the support of this matrix, since the non-zero entries have information about the conditional dependence between variables. In numerous applications, this matrix is known to be sparse, and in this regard the graphical Lasso has proven to be a good estimator for the inverse covariance matrix (Yuan & Lin, 2007; Fiori et al., 2012) (also for non-Gaussian data (Loh & Wainwright, 2012)). Assume that we have a p-dimensional multivariate normal distributed variable X \u223c N (0,\u03a3); let X \u2208 Rk\u00d7p be a data matrix containing k independent observations of X , and S its empirical covariance matrix. The graphical Lasso estimator for \u03a3\u22121 is the matrix \u0398 which solves the optimization problem\nmin \u0398 0 tr(S\u0398)\u2212 log det \u0398 + \u03bb \u2211 i,j |\u0398ij | , (6)\nwhich corresponds to the maximum likelihood estimator for \u03a3\u22121 with an l1 regularization.\nCollaborative network inference has gained a lot of attention in the last years (Chiquet et al., 2011), specially with fMRI data, e.g., (Varoquaux et al., 2010). This problem consist of estimating two (or more) matrices \u03a3\u22121A and \u03a3 \u22121 B from data matrices XA and XB as above, with the additional prior information that the inverse covariance matrices share the same support. The joint estimation of \u0398A and \u0398B is performed by solving\nmin \u0398A 0,\u0398B 0 tr(SA\u0398A)\u2212 log det \u0398A + tr(SB\u0398B)\u2212 log det \u0398B + \u03bb \u2211 i,j \u2223\u2223\u2223\u2223(\u0398Aij ,\u0398Bij)||2 , (7) where the first four terms correspond to the maximum likelihood estimators for \u0398A,\u0398B , and the last term is the group Lasso penalty which promotes that \u0398A and \u0398B have the same active set.\nThis formulation relies on the limiting underlying assumption that the variables in both datasets (the columns of XA and XB) are in correspondence, i.e., the graphs determined by the adjacency matrices \u0398A and \u0398B are aligned. However, this is in general not the case in practice. Motivated by the formulation presented in Section 2, we propose to overcome this limitation by incorporating a permutation matrix into the optimization problem, and jointly learn it on the estimation process. The proposed optimization problem is then given by\nmin \u0398A,\u0398B 0\nP\u2208P\ntr(SA\u0398A)\u2212 log det \u0398A + tr(SB\u0398B)\u2212 log det \u0398B + \u03bb \u2211 i,j \u2223\u2223\u2223\u2223((\u0398AP)ij , (P\u0398B)ij)||2. (8)\nEven after the relaxation of the constraint P \u2208 P to P \u2208 D, the joint minimization of (8) over (\u0398A,\u0398B) and P is a non-convex problem. However it is convex when minimized only over (\u0398A,\u0398B) or P leaving the other fixed. Problem (8) can be then minimized using a block-coordinate descent type of approach, iteratively minimizing over (\u0398A,\u0398B) and P.\nThe first subproblem (solving (8) with P fixed) is a very simple variant of (7), which can be solved very efficiently by means of iterative thresholding algorithms (Fiori et al., 2013). In the second subproblem, since (\u0398A,\u0398B) are fixed, the only term to minimize is the last one, which corresponds to the graph matching formulation presented in Section 2."}, {"heading": "5 Experimental results", "text": "We now present the performance of our algorithm and compare it with the most recent techniques in several scenarios including synthetic and real graphs, multimodal data, and fMRI experiments. In the cases where there is a \u201cground truth,\u201d the performance is measured in terms of the matching error, defined as ||Ao \u2212PBoPT||2F , where P is the obtained permutation matrix and (Ao,Bo) are the original adjacency matrices."}, {"heading": "5.1 Graph matching: Synthetic graphs", "text": "We focus here in the traditional graph matching problem of undirected weighted graphs, both with and without noise. More precisely, let Ao be the adjacency matrix of a random weighted graph and Bo a permuted version of it, generated with a random permutation matrix Po, i.e., Bo = PTo AoPo. We then add a certain number N of random edges to Ao with the same weight distribution as the original weights, and anotherN random edges to Bo, and from these noisy versions we try to recover the original matching (or any matching between Ao and Bo, since it may not be unique).\nWe show the results using three different techniques for the generation of the graphs: the Erdo\u030bsRe\u0301nyi model (Erdo\u030bs & Re\u0301nyi, 1959), the model by Baraba\u0301si & Albert (1999) for scale-free graphs, and graphs with a given degree distribution generated with the BTER algorithm (Seshadhri et al., 2012). These models are representative of a wide range of real-world graphs (Newman, 2010). In the case of the BTER algorithm, the degree distribution was generated according to a geometric law, that is: Prob(degree = t) = (1\u2212 e\u2212\u00b5)e\u00b5t. We compared the performance of our algorithm with the technique by Zaslavskiy et al. (2009) (referred to as PATH), the FAQ method described in Vogelstein et al. (2012), and the QCP approach.\nFigure 1 shows the matching error as a function of the noise level for graphs with p = 100 nodes (top row), and for p = 150 nodes (bottom row). The number of edges varies between 200 and 400 for graphs with 100 nodes, and between 300 and 600 for graphs with 150 nodes, depending on the model. The performance is averaged over 100 runs. This figure shows that our method is more stable, and consistently outperforms the other methods (considered state-of-the-art), specially for noise levels in the low range (for large noise levels, is not clear what a \u201ctrue\u201d matching is, and in addition the sparsity hypothesis is no longer valid)."}, {"heading": "5.2 Graph matching: Real graphs", "text": "We now present similar experiments to those in the previous section but with real graphs. We use the C. elegans connectome. Caenorhabditis elegans is an extensively studied roundworm, whose somatic nervous system consists of 279 neurons that make synapses with other neurons. The two types of connections (chemical and electrical) between these 279 neurons have been mapped (Varshney et al., 2011), and their corresponding adjacency matrices, Ac and Ae, are publicly available.\nWe match both the chemical and the electrical connection graphs against noisy artificially permuted versions of them. The permuted graphs are constructed following the same procedure used in Section 5.1 for synthetic graphs. The weights of the added noise follow the same distribution as the original weights. The results are shown in Figure 2. These results suggest that from the prior art, the PATH algorithm is more suitable for the electrical connection network, while the FAQ algorithm works better for the chemical one. Our method outperforms both of them for both types of connections."}, {"heading": "5.3 Multimodal graph matching", "text": "One of the advantages of the proposed approach is its capability to deal with multimodal data. As discussed in Section 2, the group Lasso type of penalty promotes the supports of AP and PB to be identical, almost independently of the actual values of the entries. This allows to match weighted graphs where the weights may follow completely different probability distributions. This is commonly the case when dealing with multimodal data: when a network is measured using significantly different modalities, one expects the underlying connections to be the same but no relation can be assumed between the actual weights of these connections. This is even the case for example for fMRI data when measured with different instruments. In what follows, we evaluate the performance of the proposed method in two examples of multimodal graph matching.\nWe first generate an auxiliary binary random graph Ab and a permuted version Bb = PTo AbPo. Then, we assign weights to the graphs according to distributions pA and pB (that will be specified for each experiment), thus obtaining the weighted graphs A and B. We then add noise consisting of spurious weighted edges following the same distribution as the original graphs (i.e., pA for A and pB for B). Finally, we run all four graph matching methods to recover the permutation. The matching error is measured in the unweighted graphs as ||Ab \u2212 PBbPT ||F . Note that while this metric might not be appropriate for the optimization stage when considering multimodal data, it is appropriate for the actual error evaluation, measuring mismatches. Comparing with the original permutation matrix may not be very informative since there is no guarantee that the matrix is unique, even for the original noise-free data.\nFigures 3(a) and 3(b) show the comparison when the weights in both graphs are Gaussian distributed, but with different means and variances. Figures 3(c) and 3(d) show the performances when the weights of A are Gaussian distributed, and the ones of B follow a uniform distribution. See captions for details. These results confirm the intuition described above, showing that our method is more suitable for multimodal graphs, specially in the low range of noise."}, {"heading": "5.4 Collaborative inference", "text": "In this last experiment, we illustrate the application of the permuted collaborative graph inference presented in Section 4 with real resting-state fMRI data, publicly available (Nooner, 2012). We consider here test-retest studies, that is, the same subject undergoing resting-state fMRI in two different sessions separated by a break. Each session consists of almost 10 minutes of data, acquired with a sampling period of 0.645s, producing about 900 samples per study. The CC200 atlas (Craddock et al., 2012) was used to extract the time-series for the \u2248 200 regions of interest (ROIs), resulting in two data matrices XA,XB \u2208 R900\u00d7200, corresponding to test and retest respectively. To illustrate the potential of the proposed framework, we show that using only part of the data in XA and part of the data in a permuted version of XB , we are able to infer a connectivity matrix almost as accurately as using the whole data. Working with permuted data is very important in this application in order to handle possible miss-alignments to the atlas.\nSince there is no ground truth for the connectivity, and as mentioned before the collaborative setting (7) has already been proven successful, we take as ground truth the result of the collaborative inference using the empirical covariance matrices of XA and XB , denoted by SA and SB . The result of this collaborative inference procedure are the two inverse covariance matrices \u0398AGT and \u0398 B GT . In short, the gold standard built for this experiment are found by solving (obtained with the entire data)\nmin \u0398A 0,\u0398B 0 tr(SA\u0398A)\u2212 log det \u0398A + tr(SB\u0398B)\u2212 log det \u0398B + \u03bb \u2211 i,j \u2223\u2223\u2223\u2223(\u0398Aij ,\u0398Bij)||2 . Now, let XAH be the first 550 samples of X A, and XBH the first 550 samples of X B , which correspond to a little less than 6 minutes of study. We compute the empirical covariance matrices SAH and S B H of these data matrices, and we artificially permute the second one: S\u0303 B\nH = P T o S B HPo. With these two\nmatrices SAH and S\u0303 B\nH we run the algorithm described in Section 4, which alternately computes the inverse covariance matrices \u0398AH and \u0398 B H and the matching P between them.\nWe compare this approach against the computation of the inverse covariance matrix using only one of the studies. Let \u0398As and \u0398 B s be the results of the graphical Lasso (6) using S A and SB :\n\u0398Ks = argmin \u0398 0 tr(SK\u0398)\u2212 log det \u0398 + \u03bb \u2211 i,j |\u0398ij | , for K = {A,B}.\nThis experiment is repeated for 5 subjects in the database. The errors ||\u0398AGT \u2212\u0398 A s ||F and ||\u0398 A GT \u2212 \u0398AH ||F are shown in Figure 4. The errors for \u0398 B are very similar. Using less than 6 minutes of each study, with the variables not pre-aligned, the permuted collaborative inference procedure proposed in Section 4 outperforms the classical graphical Lasso using the full 10 minutes of study."}, {"heading": "6 Conclusions", "text": "We have presented a new formulation for the graph matching problem, and proposed an optimization algorithm for minimizing the corresponding cost function. The reported results show its suitability for the graph matching problem of weighted graphs, outperforming previous state-of-the-art methods, both in synthetic and real graphs. Since in the problem formulation the weights of the graphs are not compared explicitly, the method can deal with multimodal data, outperforming the other compared methods. In addition, the proposed formulation naturally fits into the pre-alignment-free collaborative network inference framework, where the permutation is estimated together with the underlying common network, with promising preliminary results in applications with real data.\nAcknowledgements: Work partially supported by ONR, NGA, NSF, ARO, AFOSR, and ANII."}], "references": [{"title": "A linear programming approach for the weighted graph matching problem", "author": ["H. Almohamad", "S. Duffuaa"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Almohamad and Duffuaa,? \\Q1993\\E", "shortCiteRegEx": "Almohamad and Duffuaa", "year": 1993}, {"title": "Emergence of scaling in random networks", "author": ["A. Barab\u00e1si", "R. Albert"], "venue": "Science, 286(5439):509\u2013512,", "citeRegEx": "Barab\u00e1si and Albert,? \\Q1999\\E", "shortCiteRegEx": "Barab\u00e1si and Albert", "year": 1999}, {"title": "Parallel and Distributed Computation: Numerical Methods", "author": ["D. Bertsekas", "J. Tsitsiklis"], "venue": null, "citeRegEx": "Bertsekas and Tsitsiklis,? \\Q1989\\E", "shortCiteRegEx": "Bertsekas and Tsitsiklis", "year": 1989}, {"title": "Inferring multiple graphical structures", "author": ["J. Chiquet", "Y. Grandvalet", "C. Ambroise"], "venue": "Statistics and Computing,", "citeRegEx": "Chiquet et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chiquet et al\\.", "year": 2011}, {"title": "Thirty years of graph matching in pattern recognition", "author": ["D. Conte", "P. Foggia", "C. Sansone", "M. Vento"], "venue": "International Journal of Pattern Recognition and Artificial Intelligence,", "citeRegEx": "Conte et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Conte et al\\.", "year": 2004}, {"title": "A whole brain fMRI atlas generated via spatially constrained spectral clustering", "author": ["R.C. Craddock", "G.A. James", "P.E. Holtzheimer", "X.P. Hu", "H.S. Mayberg"], "venue": "Human Brain Mapping,", "citeRegEx": "Craddock et al\\.,? \\Q1928\\E", "shortCiteRegEx": "Craddock et al\\.", "year": 1928}, {"title": "On random graphs, I", "author": ["P. Erd\u0151s", "A. R\u00e9nyi"], "venue": "Publicationes Mathematicae,", "citeRegEx": "Erd\u0151s and R\u00e9nyi,? \\Q1959\\E", "shortCiteRegEx": "Erd\u0151s and R\u00e9nyi", "year": 1959}, {"title": "Topology constraints in graphical models", "author": ["Fiori", "Marcelo", "Mus\u00e9", "Pablo", "Sapiro", "Guillermo"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Fiori et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Fiori et al\\.", "year": 2012}, {"title": "Multimodal graphical models via group lasso", "author": ["Fiori", "Marcelo", "Mus\u00e9", "Pablo", "Hariri", "Ahamd", "Sapiro", "Guillermo"], "venue": "Signal Processing with Adaptive Sparse Structured Representations,", "citeRegEx": "Fiori et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Fiori et al\\.", "year": 2013}, {"title": "The Hungarian method for the assignment problem", "author": ["H.W. Kuhn"], "venue": "Naval Research Logistic Quarterly,", "citeRegEx": "Kuhn,? \\Q1955\\E", "shortCiteRegEx": "Kuhn", "year": 1955}, {"title": "Linearized alternating direction method with adaptive penalty for lowrank representation", "author": ["Z. Lin", "R. Liu", "Z. Su"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Lin et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2011}, {"title": "Structure estimation for discrete graphical models: Generalized covariance matrices and their inverses", "author": ["P. Loh", "M. Wainwright"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Loh and Wainwright,? \\Q2012\\E", "shortCiteRegEx": "Loh and Wainwright", "year": 2012}, {"title": "Networks: An Introduction", "author": ["M. Newman"], "venue": null, "citeRegEx": "Newman,? \\Q2010\\E", "shortCiteRegEx": "Newman", "year": 2010}, {"title": "The NKI-Rockland sample: A model for accelerating the pace of discovery science in psychiatry", "author": ["K Nooner"], "venue": "Frontiers in Neuroscience,", "citeRegEx": "Nooner,? \\Q2012\\E", "shortCiteRegEx": "Nooner", "year": 2012}, {"title": "Community structure and scale-free collections of Erd\u0151sR\u00e9nyi graphs", "author": ["C. Seshadhri", "T.G. Kolda", "A. Pinar"], "venue": "Physical Review E,", "citeRegEx": "Seshadhri et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Seshadhri et al\\.", "year": 2012}, {"title": "An eigendecomposition approach to weighted graph matching problems", "author": ["S. Umeyama"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Umeyama,? \\Q1988\\E", "shortCiteRegEx": "Umeyama", "year": 1988}, {"title": "Brain covariance selection: better individual functional connectivity models using population prior", "author": ["G. Varoquaux", "A. Gramfort", "J.B. Poline", "Bertrand"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Varoquaux et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Varoquaux et al\\.", "year": 2010}, {"title": "Structural properties of the caenorhabditis elegans neuronal network", "author": ["L. Varshney", "B. Chen", "E. Paniagua", "D. Hall", "D. Chklovskii"], "venue": "PLoS Computational Biology,", "citeRegEx": "Varshney et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Varshney et al\\.", "year": 2011}, {"title": "Fast approximate quadratic programming for large (brain) graph matching", "author": ["J.T. Vogelstein", "J.M. Conroy", "L.J. Podrazik", "S.G. Kratzer", "E.T. Harley", "D.E. Fishkind", "R.J. Vogelstein", "C.E. Priebe"], "venue": null, "citeRegEx": "Vogelstein et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Vogelstein et al\\.", "year": 2012}, {"title": "Model selection and estimation in regression with grouped variables", "author": ["M. Yuan", "Y. Lin"], "venue": "Journal of the Royal Statistical Society: Series B,", "citeRegEx": "Yuan and Lin,? \\Q2006\\E", "shortCiteRegEx": "Yuan and Lin", "year": 2006}, {"title": "Model selection and estimation in the Gaussian graphical model", "author": ["M. Yuan", "Y. Lin"], "venue": null, "citeRegEx": "Yuan and Lin,? \\Q2007\\E", "shortCiteRegEx": "Yuan and Lin", "year": 2007}, {"title": "A path following algorithm for the graph matching problem", "author": ["M. Zaslavskiy", "F. Bach", "J.P. Vert"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Zaslavskiy et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Zaslavskiy et al\\.", "year": 2009}], "referenceMentions": [{"referenceID": 4, "context": "This problem is also very interesting from the computational complexity point of view, since its complexity level is still unsolved: it is one of the few problems in NP not yet classified as P nor NP-complete (Conte et al., 2004).", "startOffset": 209, "endOffset": 229}, {"referenceID": 4, "context": "The combinatorial nature of the permutation search makes this problem NP in general, although polynomial algorithms have been developed for a few special types of graphs, like trees or planar graphs for example (Conte et al., 2004).", "startOffset": 211, "endOffset": 231}, {"referenceID": 15, "context": "There are several and diverse techniques addressing the graph matching problem, including spectral methods (Umeyama, 1988) and problem relaxations (Zaslavskiy et al.", "startOffset": 107, "endOffset": 122}, {"referenceID": 21, "context": "There are several and diverse techniques addressing the graph matching problem, including spectral methods (Umeyama, 1988) and problem relaxations (Zaslavskiy et al., 2009; Vogelstein et al., 2012; Almohamad & Duffuaa, 1993).", "startOffset": 147, "endOffset": 224}, {"referenceID": 18, "context": "There are several and diverse techniques addressing the graph matching problem, including spectral methods (Umeyama, 1988) and problem relaxations (Zaslavskiy et al., 2009; Vogelstein et al., 2012; Almohamad & Duffuaa, 1993).", "startOffset": 147, "endOffset": 224}, {"referenceID": 4, "context": "A good review of the most common approaches can be found in Conte et al. (2004). In this paper we focus on the relaxation techniques for solving an approximate version of the problem.", "startOffset": 60, "endOffset": 80}, {"referenceID": 9, "context": "The final node correspondence is obtained as the closest permutation matrix to P\u0302: P\u2217 = arg minP\u2208P ||P\u2212 P\u0302||F , which is a linear assignment problem that can be solved inO(p) by the Hungarian algorithm (Kuhn, 1955).", "startOffset": 202, "endOffset": 214}, {"referenceID": 9, "context": "The final node correspondence is obtained as the closest permutation matrix to P\u0302: P\u2217 = arg minP\u2208P ||P\u2212 P\u0302||F , which is a linear assignment problem that can be solved inO(p) by the Hungarian algorithm (Kuhn, 1955). However, this last step lacks any guarantee about the graph matching problem itself. This approach will be referred to as QCP for quadratic convex problem. One of the newest approximate methods is the PATH algorithm by Zaslavskiy et al. (2009), which combines this convex relaxation with a concave relaxation.", "startOffset": 203, "endOffset": 460}, {"referenceID": 9, "context": "The final node correspondence is obtained as the closest permutation matrix to P\u0302: P\u2217 = arg minP\u2208P ||P\u2212 P\u0302||F , which is a linear assignment problem that can be solved inO(p) by the Hungarian algorithm (Kuhn, 1955). However, this last step lacks any guarantee about the graph matching problem itself. This approach will be referred to as QCP for quadratic convex problem. One of the newest approximate methods is the PATH algorithm by Zaslavskiy et al. (2009), which combines this convex relaxation with a concave relaxation. Another new technique is the FAQ method by Vogelstein et al. (2012), which solves a relaxed version of the Quadratic Assignment Problem.", "startOffset": 203, "endOffset": 594}, {"referenceID": 21, "context": ", (Zaslavskiy et al., 2009).", "startOffset": 2, "endOffset": 27}, {"referenceID": 10, "context": "Nevertheless, we can choose to solve a linearized version of the problem while keeping the convergence guarantees of the algorithm (Lin et al., 2011).", "startOffset": 131, "endOffset": 149}, {"referenceID": 7, "context": "In numerous applications, this matrix is known to be sparse, and in this regard the graphical Lasso has proven to be a good estimator for the inverse covariance matrix (Yuan & Lin, 2007; Fiori et al., 2012) (also for non-Gaussian data (Loh & Wainwright, 2012)).", "startOffset": 168, "endOffset": 206}, {"referenceID": 3, "context": "Collaborative network inference has gained a lot of attention in the last years (Chiquet et al., 2011), specially with fMRI data, e.", "startOffset": 80, "endOffset": 102}, {"referenceID": 16, "context": ", (Varoquaux et al., 2010).", "startOffset": 2, "endOffset": 26}, {"referenceID": 8, "context": "The first subproblem (solving (8) with P fixed) is a very simple variant of (7), which can be solved very efficiently by means of iterative thresholding algorithms (Fiori et al., 2013).", "startOffset": 164, "endOffset": 184}, {"referenceID": 14, "context": "We show the results using three different techniques for the generation of the graphs: the Erd\u0151sR\u00e9nyi model (Erd\u0151s & R\u00e9nyi, 1959), the model by Barab\u00e1si & Albert (1999) for scale-free graphs, and graphs with a given degree distribution generated with the BTER algorithm (Seshadhri et al., 2012).", "startOffset": 270, "endOffset": 294}, {"referenceID": 12, "context": "These models are representative of a wide range of real-world graphs (Newman, 2010).", "startOffset": 69, "endOffset": 83}, {"referenceID": 20, "context": "We compared the performance of our algorithm with the technique by Zaslavskiy et al. (2009) (referred to as PATH), the FAQ method described in Vogelstein et al.", "startOffset": 67, "endOffset": 92}, {"referenceID": 18, "context": "(2009) (referred to as PATH), the FAQ method described in Vogelstein et al. (2012), and the QCP approach.", "startOffset": 58, "endOffset": 83}, {"referenceID": 17, "context": "The two types of connections (chemical and electrical) between these 279 neurons have been mapped (Varshney et al., 2011), and their corresponding adjacency matrices, Ac and Ae, are publicly available.", "startOffset": 98, "endOffset": 121}, {"referenceID": 13, "context": "4 Collaborative inference In this last experiment, we illustrate the application of the permuted collaborative graph inference presented in Section 4 with real resting-state fMRI data, publicly available (Nooner, 2012).", "startOffset": 204, "endOffset": 218}], "year": 2013, "abstractText": "Graph matching is a challenging problem with very important applications in a wide range of fields, from image and video analysis to biological and biomedical problems. We propose a robust graph matching algorithm inspired in sparsityrelated techniques. We cast the problem, resembling group or collaborative sparsity formulations, as a non-smooth convex optimization problem that can be efficiently solved using augmented Lagrangian techniques. The method can deal with weighted or unweighted graphs, as well as multimodal data, where different graphs represent different types of data. The proposed approach is also naturally integrated with collaborative graph inference techniques, solving general network inference problems where the observed variables, possibly coming from different modalities, are not in correspondence. The algorithm is tested and compared with state-of-the-art graph matching techniques in both synthetic and real graphs. We also present results on multimodal graphs and applications to collaborative inference of brain connectivity from alignment-free functional magnetic resonance imaging (fMRI) data. The code is publicly available.", "creator": "LaTeX with hyperref package"}}}