{"id": "1401.3458", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2014", "title": "Solving #SAT and Bayesian Inference with Backtracking Search", "abstract": "Inference 2002 Bayes Nets (BAYES) becomes was important something with references allows in probabilistic logically. Counting before seven given infinitely budgets of called formulae knock-out (# SAT) is with sensitive besides how known scope theorists importance. Both actually problems, include could, are participate of however other far equal - of - foods (SUMPROD) problems. In this paper lot pictures make model characterizing mission next augmented with an describe memoization scheme (attachments) it possibilities need account - of - products problem with rest aspects but is home least still opportunity any other counties - of - still - taught calculation kernel, used nor thought unlike will accelerate the best commonly same - creating tradeoff. Furthermore, backtracking ' s ensure keep utilize fact modifying equation orderings allows us now prove that fact must achieve kind graphs speedup ago represent standard processes for SUMPROD on to complaints.", "histories": [["v1", "Wed, 15 Jan 2014 05:17:49 GMT  (474kb)", "http://arxiv.org/abs/1401.3458v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["fahiem bacchus", "shannon dalmao", "toniann pitassi"], "accepted": false, "id": "1401.3458"}, "pdf": {"name": "1401.3458.pdf", "metadata": {"source": "CRF", "title": "Solving #SAT and Bayesian Inference with Backtracking Search", "authors": ["Fahiem Bacchus", "Shannon Dalmao", "Toniann Pitassi"], "emails": ["FBACCHUS@CS.TORONTO.EDU", "TONI@CS.TORONTO.EDU"], "sections": [{"heading": null, "text": "abilistic reasoning. Counting the number of satisfying assignments of a propositional formula (#SAT) is a closely related problem of fundamental theoretical importance. Both these problems, and others, are members of the class of sum-of-products (SUMPROD) problems. In this paper we show that standard backtracking search when augmented with a simple memoization scheme (caching) can solve any sum-of-products problem with time complexity that is at least as good any other state-of-the-art exact algorithm, and that it can also achieve the best known time-space tradeoff. Furthermore, backtracking\u2019s ability to utilize more flexible variable orderings allows us to prove that it can achieve an exponential speedup over other standard algorithms for SUMPROD on some instances.\nThe ideas presented here have been utilized in a number of solvers that have been applied to various types of sum-of-product problems. These system\u2019s have exploited the fact that backtracking can naturally exploit more of the problem\u2019s structure to achieve improved performance on a range of problem instances. Empirical evidence of this performance gain has appeared in published works describing these solvers, and we provide references to these works."}, {"heading": "1. Introduction", "text": "Probabilistic inference in Bayesian Networks (BAYES) is an important and well-studied problem with numerous practical applications in probabilistic reasoning (Pearl, 1988). Counting the number of satisfying assignments of a propositional formula (#SAT) is also a well-studied problem that is of fundamental theoretical importance. These two problems are known to be closely related. In particular, the decision versions of both #SAT and BAYES are #P-complete (Valiant, 1979b, 1979a; Roth, 1996), and there are natural polynomial-time reductions from each problem to the other (Darwiche, 2002; Sang, Beame, & Kautz, 2005b; Chavira, Darwiche, & Jaeger, 2006).\nA more direct relationship between these two problems arises from the observation that they are both instances of the more general \u201csum of products\u201d problem (SUMPROD). Perhaps the most fundamental algorithm for SUMPROD (developed in a general way by Dechter 1999) is based on the idea of eliminating the variables of the problem one by one following some fixed order. This algorithm is called variable elimination (VE), and it is the core notion in many state-of-the-art exact algorithms for SUMPROD (and BAYES).\nSAT, the problem of determining whether or not a propositional formula has any satisfying assignments, is also an instance of SUMPROD, and the original Davis-Putnam algorithm (DP) for determining satisfiability (Davis & Putnam, 1960) which uses ordered resolution is a version of\nc\u00a92009 AI Access Foundation. All rights reserved.\nvariable elimination. However, DP is never used in practice as its performance is far inferior to modern versions of the backtracking search based DPLL algorithm (Davis, Logemann, & Loveland, 1962). In fact DP is provably less powerful than modern versions of DPLL equipped with clause learning (Hertel, Bacchus, Pitassi, & van Gelder, 2008).\nThis performance gap naturally raises the question of whether or not backtracking search could be used to solve other types of SUMPROD problems more efficiently than variable elimination. In this paper, we present a general algorithmic framework for using backtrack search methods (specifically DPLL) to solve SUMPROD and related problems.1 We first show that a straightforward adaptation of backtracking for solving SUMPROD is insufficient. However, by examining the sources of inefficiency we are able to develop some simple caching schemes that allow our backtracking algorithm, #DPLL-Cache, to achieve the same performance guarantees as state-of-the-art exact algorithms for SUMPROD, in terms of both time and space. Furthermore, we prove that backtracking\u2019s natural additional flexibility allows it to sometimes achieve an exponential speedup over other existing algorithms. Specifically, we present a family of SUMPROD instances where #DPLL-Cache achieves an exponential speedup over the original versions of three prominent algorithms for SUMPROD.\nBesides these theoretical results, there are also good reasons to believe that backtracking based algorithms have the potential to perform much better than their worst case guarantees on problems that arise from real domains. In fact, subsequent work has investigated the practical application of the ideas presented here to the problem of counting satisfying assignments, BAYES, and constraint optimization with very successful results (Sang, Bacchus, Beame, Kautz, & Pitassi, 2004; Sang et al., 2005b; Sang, Beame, & Kautz, 2005a, 2007; Davies & Bacchus, 2007; Kitching & Bacchus, 2008).\nAn outline of the paper follows. In Section 2, we define SUMPROD; demonstrate that #SAT, BAYES, and other important problems are instances of this class of problems; discuss various graphtheoretic notions of width that can be used to characterize the complexity of algorithms for SUMPROD; and review some core state-of-the-art exact algorithms for SUMPROD. In Section 3, we discuss DPLL-based algorithms with caching for solving #SAT and SUMPROD and provide worst case complexity bounds for these algorithms. These bounds are the same as the best time and space guarantees achieved by currently known algorithms. In Section 4, we provide a framework for comparing our algorithms with other algorithms for SUMPROD and prove that with caching DPLL can efficiently simulate known exact algorithms while sometimes achieving super-polynomially superior performance. In Section 5 we discuss some of the work that has used our algorithmic ideas to build practical solvers for various problems. Finally, we provide some closing remarks in Section 6."}, {"heading": "2. Background", "text": "In this section, we first define the sum-of-products (SUMPROD) class of problems, and then illustrate how BAYES, #SAT, and some other important problems are instances of SUMPROD. As we will show in the rest of the paper, backtracking search equipped with different caching schemes is\n1. The notion of \u201cbacktracking\u201d over a previous set of commitments can be utilized in other contexts, including in other algorithms for SUMPROD. However, here we are referring to the standard algorithmic paradigm of backtracking search that explores a single tree of partial variable assignments in a depth-first manner. This algorithm has an extensive history that stretches back over a hundred years (Bitner & Reingold, 1975).\nwell suited for solving SUMPROD. The key computational structure that is exploited by all algorithms for SUMPROD is then explained and the graph theoretic notion of width that captures this structure is identified. Different notions of \u201cwidth\u201d exist, and we present three different definitions and show that they all yield essentially equivalent measures of complexity. The different definitions are however very useful in that different algorithms are most easily analyzed using different definitions of width. Finally, we briefly review some of the most important exact algorithms for solving SUMPROD and related problems."}, {"heading": "2.1 Sum-of-Products", "text": "Dechter (1999) has been shown that BAYES and many other problems are instances of a more general problem called SUMPROD (sum-of-products). An instance of SUMPROD is defined by the tuple \u3008V,F ,\u2295,\u2297\u3009, where V is a set of discrete valued variables {X1, . . . ,Xn}, F is a set of functions {f1, . . . , fm} with each fi defined over some set of variables Ei \u2286 V , \u2295 is an addition operator, and \u2297 is a multiplication operator. The range of the functions in F depends on the problem, with \u2295 and \u2297 being operators over that range such that both are commutative, associative, and \u2297 distributes over \u2295. Typical examples involve functions that range over the boolean domain, with \u2295 being disjunction \u2228 and \u2297 being conjunction \u2227, or over the reals, with \u2295 and \u2297 being ordinary addition and multiplication.\nDefinition 1 (SUMPROD) Given \u3008V,F ,\u2295,\u2297\u3009 the SUMPROD problem is to compute\n\u2295\nX1\n\u2295\nX2\n\u00b7 \u00b7 \u00b7 \u2295\nXn\nm \u2297\ni=1\nfi(Ei),\ni.e., the sum (\u2295) over all values (assignments) of the variables V of the product (\u2297) of the functions F evaluated at those assignments.\nA number of well known problems are instances of SUMPROD. We describe some of them below."}, {"heading": "2.1.1 BAYES:", "text": "BAYES is the problem of computing probabilities in a Bayesian Network (BN). Developed by Pearl (1988), a Bayesian network is a triple (V, E,P) where (V, E) describes a directed acyclic graph, in which the nodes V = {X1, . . . ,Xn} represent discrete random variables, edges represent direct correlations between the variables, and associated with each random variable Xi is a conditional probability table CPT (or function), fi(Xi, \u03c0(Xi)) \u2208 P, that specifies the conditional distribution of Xi given assignments of values to its parents \u03c0(Xi) in (V, E). A BN represents a joint distribution over the random variables V in which the probability of any assignment (x1, . . . , xn) to the variables is given by the equation Pr(x1, . . . , xn) = \u220fn i=1 fi(xi, \u03c0(xi)), where fi(xi, \u03c0(xi)) is fi evaluated at this particular assignment. The generic BAYES problem is to compute the posterior distribution of a variable Xi given a particular assignment to some of the other variables \u03b1: i.e., Pr(Xi|\u03b1). Since Xi has only a finite set of k values, this problem can be further reduced to that of computing the k values Pr(Xi = dj \u2227\u03b1), j = 1, . . . , k and then normalizing them so that they sum to 1. The values Pr(Xi = dj \u2227 \u03b1) can be computed by making all of the assignments in \u03b1 as well as Xi = dj , and then summing out the\nother variables from the joint distribution Pr(x1, . . . , xn). Given the above product decomposition of Pr(x1, . . . , xn), this is equivalent to reducing the functions fi \u2208 P by setting the variables assigned in \u03b1 and Xi = dj , and then summing their product over the remaining variables; i.e., it is an instance of SUMPROD.\nComputing all Marginals It is common when solving BAYES to want to compute all marginals. That is, instead of wanting to compute just the marginal Pr(Xi|\u03b1) for one particular variable Xi, we want to compute the marginal for all variables not instantiated by \u03b1."}, {"heading": "2.1.2 MARKOV RANDOM FIELDS", "text": "Markov Random Fields or Markov Networks (MN) (Preston, 1974; Spitzer, 1971) are similar to Bayesian Networks in that they also define a joint probability distribution over a set of discrete random variables V = {X1, . . . ,Xn} using a set of functions fi, called potentials, each over some set of variables Ei \u2286 V . In particular, the probability of any assignment (x1, . . . , xn) to the variables is given by the normalized product of the fi evaluated at the values specified by the assignment: \u220f\ni fi(Ei[x1, . . . , xn]). The difficulty is to compute the partition function, or normalizing constant:\nZ = \u2211\nX1\n\u00b7 \u00b7 \u00b7 \u2211\nXn\nm \u220f\ni=1\nfi(Ei).\nComputing the partition function is thus an instance of SUMPROD."}, {"heading": "2.1.3 MOST PROBABLE EXPLANATION", "text": "Most Probable Explanation (MPE) is the problem of finding the most probable complete assignment to the variables in a Bayes net (or Markov net) that agrees with a fixed assignment to a subset of the variables (the evidence). If the evidence, \u03b1, is an instantiation of the variables in E \u2282 V , then MPE is the problem of computing\nmax V\u2212E\nm \u220f\ni=1\nfi|\u03b1(Ei \u2212 E),\nwhere fi|\u03b1 is the reduction of the function fi by the instantiations \u03b1 to the variables in E (yielding a function over the variables Ei \u2212 E)."}, {"heading": "2.1.4 SAT", "text": "Let V = {X1,X2, . . . ,Xn} be a collection of n Boolean variables, and let \u03c6(V) be a k-CNF Boolean formula on these variables with m clauses {c1, . . . , cm}. An assignment \u03b1 to the Boolean variables V is satisfying if it makes the formula True (i.e., \u03c6(\u03b1) = 1). SAT asks, given a Boolean formula \u03c6(V) in k-CNF, does it have a satisfying assignment? By viewing each clause ci as being a function of its variables Ei (i.e., it maps an assignment to these variables to TRUE if that assignment satisfies the clause and to FALSE otherwise), we can see that SAT is equivalent to the instance of SUMPROD \u3008V, {c1, . . . , cm},\u2228,\u2227\u3009:\n\u2228\nX1\n\u00b7 \u00b7 \u00b7 \u2228\nXn\nm \u2227\ni=1\nci(Ei)."}, {"heading": "2.1.5 #SAT", "text": "Given a k-CNF formula \u03c6(V) on the boolean variables V = {X1, . . . ,Xn}, as above, #SAT is the problem of determining the number of satisfying assignments for \u03c6. By viewing each clause ci as being a function from its variables Ei to {0, 1} (i.e., it maps satisfying assignments to 1 and falsifying assignments to 0), we can see that #SAT is equivalent to the instance of SUMPROD \u3008V, {c1, . . . , cm},+,\u00d7\u3009:\n\u2211\nX1\n\u00b7 \u00b7 \u00b7 \u2211\nXn\nm \u220f\ni=1\nci(Ei)."}, {"heading": "2.1.6 OPTIMIZATION WITH DECOMPOSED OBJECTIVE FUNCTIONS", "text": "Let V = {X1, . . . ,Xn} be a collection of finite valued variables, the optimization task is to find an assignment of values to these variables that maximizes some objective function O(V) (i.e., a function that maps every complete assignment to the variables to a real value). In many problems O can be decomposed into a sum of sub-objective functions {f1, . . . , fm} with each fi being a function of some subset of the variables Ei. This problem can then be cast as the SUMPROD instance \u3008V, {f1, . . . , fm},max,+\u3009\nmax X1 \u00b7 \u00b7 \u00b7max Xn\nm \u2211\ni=1\nfi(Ei)."}, {"heading": "2.2 The Computational Complexity of SUMPROD", "text": "SUMPROD is a computationally difficult problem. For example, #SAT is known to be complete for the complexity class #P (Valiant, 1979b, 1979a) as is BAYES (Roth, 1996). Many special cases that are easy for SAT remain hard for #SAT, e.g., Valiant showed that the decision version of #SAT is #P hard even when the clause size, k, is 2, and Roth (1996) showed that the problem is hard to even approximate in many cases where SAT is easy, e.g., when \u03c6(V) is monotone, or Horn, or 2-CNF.\nDespite this worst case intractability, algorithms for SUMPROD, e.g., the variable elimination algorithm presented by Dechter (1999), can be successful in practice. The key structure exploited by this algorithm, and by most algorithms, is that the functions fi of many SUMPROD problems are often relatively local and fairly independent. That is, it is often the case that the sets of variables Ei that each function fi depends on are small, so that each function is dependent only on a small \u201clocal\u201d set of the variables, and that these sets share only a few variables with each other, so that the functions fi are fairly independent of each other. The graph theoretic notion of Tree Width is used to make these intuitions precise."}, {"heading": "2.3 Complexity Measures and Tree width", "text": "There is a natural hypergraph, H = (V,E), corresponding to any instance \u3008V,F ,\u2295,\u2297\u3009 of SUMPROD. In the hypergraph, V corresponds to the set V of variables, and for every function fi with domain set Ei, there is a corresponding hyperedge, Ei.\nThe \u201cwidth\u201d of this hypergraph is the critical measure of complexity for essentially all state-ofthe-art algorithms for #SAT, BAYES, and SUMPROD. There are three different (and well known) notions of width that we will define in this section. We will also show that these different notions of width are basically equivalent. These equivalences are known, although we need to state them and\nprove some basic properties, in order to analyze our new algorithms, and to relate them to standard algorithms.\nDefinition 2 (Branch width) Let H = (V,E) be a hypergraph. A branch decomposition of H is a binary tree T such that each node of T is labelled with a subset of V . There are |E| many leaves of T , and their labels are in one-to-one correspondence with the hyperedges E. For any other node n in T , let A denote the union of the leaf labeling of the subtree rooted at n, and let B denote the union of the labelings of the rest of the leaves. Then the label for n is the set of all vertices v that are in the intersection of A and B. The branch width of a branch decomposition T for H is the maximum size of any labeling in T . The branch width of H is the minimum branch width over all branch decompositions of H.\nExample 1 Figure 1 shows a particular branch decomposition Tbd for the hypergraph H = (V,E) where V = {1, 2, 3, 4, 5} and E = {{1, 2, 3}, {1, 4}, {2, 5}, {3, 5}, {4, 5}}. Tbd has branch width 3.\nDefinition 3 (Elimination width) Let H = (V,E) be a hypergraph, and let \u03c0 = v\u03c01 , . . . , v \u03c0 n be an ordering of the vertices in V , where v\u03c0i is the i th element in the ordering. This induces a sequence of hypergraphs Hn,Hn\u22121, . . . ,H1 where H = Hn and Hi\u22121 is obtained from Hi as follows. All edges in Hi containing v\u03c0i are merged into one edge and then v \u03c0 i is removed. Thus the underlying vertices of Hi are v\u03c01 , . . . v \u03c0 i\u22121. The induced width of H under \u03c0 is the size of the largest edge in all the hypergraphs Hn, . . . ,H1. The elimination width of H is the minimum induced width over all orderings \u03c0.\nExample 2 Under the ordering \u03c0 = \u30081, 2, 3, 4, 5\u3009 the hypergraph H of Example 1 produces the following sequence of hypergraphs:\nH5 = {(1, 2, 3), (1, 4), (2, 5), (3, 5), (4, 5)}\nH4 = {(2, 3, 4), (2, 5), (3, 5), (4, 5)}\nH3 = {(3, 4, 5), (3, 5), (4, 5)}\nH2 = {(4, 5), (4, 5)}\nH1 = {(5)}\nThe induced width of H under \u03c0 is 3\u2014the edges (1, 2, 3) \u2208 H1, (2, 3, 4) \u2208 H2 and (3, 4, 5) \u2208 H3 all achieve this size.\nTree width is the third notion of width.\nDefinition 4 (Tree width) Let H = (V,E) be a hypergraph. A tree decomposition of H is a binary tree T such that each node of T is labelled with a subset of V in the following way. First, for every hyperedge e \u2208 E, some leaf node in T must have a label that contains e. Secondly, given labels for the leaf nodes every internal node n contains v \u2208 V in its label if and only if n is on a path between two leaf nodes l1 and l2 whose labels contain v.2 The tree width of a tree decomposition T for H is the maximum size of any labeling in T minus 1, and the tree width of H is the minimum tree width over all tree decompositions of H.\nExample 3 Figure 2 shows Ttd a tree decomposition for H of Example 1. Ttd has tree width 3.\nThe next three lemmas show that these three notions are basically equivalent. The proofs of Lemmas 2 and 3 are given in the appendix.\nLemma 1 (Robertson & Seymour, 1991) Let H be a hypergraph. Then the branch width of H is at most the tree width of H plus 1, and the tree width of H is at most 2 times the branch width of H.\nLemma 2 Let H = (V,E) be a hypergraph with a tree decomposition of width w. Then there is an elimination ordering \u03c0 of the vertices V such that the induced width of H under \u03c0 is at most w.\nLemma 3 Let H be a hypergraph with elimination width at most w. Then H has a tree decomposition of tree width at most w.\nLetting TW (H), BW (H), and EW (H) represent the tree width, branch width and elimination width of the hypergraph H, the above lemmas give the following relationship between these three notions of width: for all hypergraphs H\nBW (H)\u2212 1 \u2264 TW (H) = EW (H) \u2264 2BW (H).\n2. Since the labels of internal nodes are determined by the labels of the leaf nodes in this way, it can be seen that for any pair of nodes n1 and n2 in the tree decomposition every node lying on the path between them must contain v in its label if v appears in both n1\u2019s and n2\u2019s labels. This is commonly known as the running intersection property of tree decompositions.\nExample 4 The tree decomposition Ttd of H = {(1, 2, 3), (1, 4), (2, 5), (3, 5), (4, 5)} given in Figure 2 has the property that it has tree width no more than twice the branch width of the branch decomposition Tbd of H given in Figure 1. From Ttd we can obtain the ordering \u03c0 = \u30081, 2, 3, 4, 5\u3009 that was used in Example 2. (The proof of Lemma 2, given in the appendix, shows how a elimination ordering can be constructed from a tree-decomposition.) As shown in Example 2, \u03c0 has induced width 3, equal to the tree width of tree decomposition Ttd from which it was constructed. Finally, from the ordering \u03c0 we can construct a new tree decomposition for H shown in Figure 3. (The proof of Lemma 3 shows how a tree decomposition can be constructed from an elimination ordering). \u03c0 has induced width 3 and, as indicated by Lemma 3 the tree decomposition constructed from it has equal tree width of 3.\nIt can be noted that our definition of tree decompositions varies slightly from other definitions that appear in the literature, e.g., (Bodlaender, 1993). Following Robertson and Seymour (1991) we have defined tree decompositions over hypergraphs, rather than over graphs, and we have made two extra restrictions so as to simplify the proofs of our results. First, we have restricted tree decompositions to be binary trees, and second we have required that each hyperedge be contained in the label of some leaf node of the tree decomposition. Usually tree decompositions are not restricted to be binary trees, and only require that each hyperedge be contained in some node\u2019s label (not necessarily a leaf node).\nIt is not difficult to show that any tree decomposition that fails to satisfy our two restrictions can be converted to a tree decomposition satisfying these restrictions without changing its width. However, it is more straight forward to observe that with or without these two restrictions tree width is equal to elimination width. Hence, our restrictions do not change the tree width."}, {"heading": "2.4 Exact Algorithms for SUMPROD", "text": "Next we briefly review three prominent exact algorithms for BAYES. These algorithms solve the more general problem SUMPROD. All of these algorithms are in fact nondeterministic algorithms that should be considered to be families of procedures, each member of which is a particular deterministic realization."}, {"heading": "2.4.1 VARIABLE ELIMINATION:", "text": "Variable or bucket elimination (VE) (Dechter, 1999) is a fundamental algorithm for SUMPROD. Variable elimination begins by choosing an elimination ordering, \u03c0 for the variables V = {X1, . . ., Xn}: X\u03c0(1), . . ., X\u03c0(n). (This is the nondeterministic part of the computation). In the first phase, all functions involving X\u03c0(1), are collected together in the set FX\u03c0(1) , and a new function, F1 is computed by \u201csumming out\u201d X\u03c0(1). The new function sums the product of all the functions in FX\u03c0(1) over all of X\u03c0(1)\u2019s values. Specifically, F1 is a function of all of the variables of the functions in FX\u03c0(1) except for X\u03c0(1), and its value on any assignment \u03b1 to these variables is\nF1(\u03b1) = \u2211\nd\u2208vals(X\u03c0(1))\n\u220f\nf\u2208FX\u03c0(1)\nf(\u03b1,X\u03c0(1) = d).\nSumming out X\u03c0(1) induces a new hypergraph, H1, where the hyperedges corresponding to the set of functions FX\u03c0(1) are replaced by a single hyperedge corresponding to the new function F1. The process then continues to sum out X\u03c0(2) from H1 and so on until all n variables are summed out. Note that the sequence of hypergraphs generated by summing out the variables according to \u03c0 is the same the sequence of hypergraphs that defines the induced width of \u03c0 (Definition 3).\nThe original Davis-Putnam algorithm (Davis & Putnam, 1960) based on ordered resolution is an instance of variable elimination. Consider applying variable elimination to the formulation of SAT given above. For SAT, the new functions Fi computed at each stage need only preserve whether or not the product of the functions in FX\u03c0(i) is 0 or 1, the exact number of satisfying assignments need not remembered. This can be accomplished by representing the Fi symbolically as a set of clauses. Furthermore, this set of clauses can be computed by generating all clauses that can be obtained by resolving on X\u03c0(i), and then discarding all old clauses containing X\u03c0(i). This resolution step corresponds to the summing out operation, and yields precisely the Davis-Putnam (DP) algorithm for satisfiability.3"}, {"heading": "2.4.2 RECURSIVE CONDITIONING:", "text": "Recursive conditioning (RC) (Darwiche, 2001) is another type of algorithm for SUMPROD. Let S = \u3008V,F ,\u2295,\u2297\u3009 be an instance of SUMPROD and H be its underlying hypergraph. RC is a divide and conquer algorithm that instantiates the variables of V so as to break the problem into disjoint components. It then proceeds to solve these components independently. The original spaceefficient version of recursive conditioning, as specified by Darwiche (2001), begins with a branch decomposition T of H of width w and depth d, and an initially empty set of instantiated variables \u03c1. (Choosing T is the nondeterministic part of the computation.) We call this algorithm RC-Space and show it in Algorithm 1.\nThe branch decomposition T specifies a recursive decomposition of the problem and is used by RC-Space as follows. Let label(n) be the label of a node in T , and let ST be the SUMPROD problem defined by the variables and functions contained in T . (In the initial call T is the complete branch decomposition containing all variables and functions of S , so that initially ST = S). Starting at r, the root of T , RC-Space solves the reduced SUMPROD ST |\u03c1\u222a\u03b1 for all assignments \u03b1 to the variables\n3. Rish and Dechter (2000) have previously made a connection between DP and variable elimination. They were thus able to show, that DP runs in time nO(1)2O(w), where w is the branch width of the underlying hypergraph of the SAT instance.\nin label(left(r)) \u2229 label(right(r)) not yet instantiated by \u03c1, where left(r) and right(r) are the left and right children of r. The sum over all such \u03b1 is the solution to the inputed instance ST |\u03c1.\nEach \u03b1 renders the set of functions in the subtree below leftChild(r) (i.e., the leaf labels) disjoint from the functions below rightChild(r). Thus for each \u03b1, RC-Space can independently solve the subproblems specified by leftChild(r)|\u03c1\u222a\u03b1 and rightChild(r)|\u03c1\u222a\u03b1 (i.e., the sum of the products of all of the functions below the left/right subtree conditioned on the instantiations in \u03c1 \u222a \u03b1) and multiply their answers to obtain the solution to ST |\u03c1\u222a\u03b1. At the leaf nodes, the function fi associated with that node has had all of its variables instantiated, so the algorithm can simply \u201cLOOKUP\u201d fi\u2019s current value.\nAlgorithm 1: RC-Space\u2014Linear Space Recursive Conditioning\nRC-Space (T, \u03c1)1 begin2 if T is a leaf node then3 return LOOKUP(value of function labeling the leaf node)4 p = 0; r = root(T )5 ~x = variables in label (left(r)) \u2229 label(right(r)) uninstantiated by \u03c16 forall \u03b1 \u2208 {instantiations of ~x} do7\np = p+ RC-Space (leftChild(T ), \u03c1 \u222a \u03b1) \u00d7 RC-Space (rightChild(T ), \u03c1 \u222a \u03b1)8 end9 return p10\nend11\nA less space-efficient but more time-efficient version of recursive conditioning, called RCCache, caches intermediate values that can be reused to reduce the computation. Algorithm 2 shows the RC-Cache algorithm. Like RC-Space, each invocation of RC-Cache solves the subproblem specified by the variables and functions contained in the passed subtree T . Since the functions below T only share the variables in label(root(T )) with variables outside of T , only the instantiations in the subset, y, of \u03c1 intersecting label(root(T )) can affect the form of this subproblem. Hence, RC-Cache will return the same answer if invoked with the same T and same y, even if other assignments in \u03c1 have changed. RC-Cache, can thus use T and y to index a cache, storing the computed result in the cache (line 13) and returning immediately if the answer is already in the cache (line 7).\nPropagation Since RC instantiates the problem\u2019s variables, propagation can be employed. That is, RC can perform additional inference to compute some of the implicit effects each assignment has on the remaining problem ST |\u03c1\u222a\u03b1. For example, if the functions of the SUMPROD problem are all clauses (e.g., when solving #SAT) unit propagation can be performed. Propagation can make recursive conditioning more effective. For example, if one of the remaining clauses becomes falsified through unit propagation, recursive conditioning can immediately move on to the next instantiation of the variables ~x. Similarly, unit propagation can force the value of variables that will be encountered in subsequent recursive calls, thus reducing the number of different instantiations \u03b1 that must be attempted in that recursive call. It can be noted that propagation does not reduce the worst case complexity of the algorithm, as on some SUMPROD problems propagation is ineffective. It can however improve the algorithm\u2019s efficiency on some families of problems.\nAlgorithm 2: RC-Cache\u2014Recursive Conditioning with caching\nRC-Cache (T, \u03c1)1 begin2 if T is a leaf node then3 return LOOKUP(value of function labeling the leaf node)4\ny = \u03c1 \u2229 label (root(T ))5 if InCache(T,y) then6\nreturn GetValue(T,y)7 p = 0; r = root(T )8 ~x = variables in label (left(r)) \u2229 label(right(r)) uninstantiated by \u03c19 forall \u03b1 \u2208 {instantiations of ~x} do10 p = p+ RC-Cache (leftChild(T ), \u03c1 \u222a \u03b1) \u00d7 RC-Cache (rightChild(T ), \u03c1 \u222a \u03b1)11 end12 AddToCache((T ,y), p)13 return p14\nend15\nRC-Cache+ A simple extension of RC that is used in practice is to set the variables ~x \u2286 label(left(r) \u2229 label(right(r)) (line 10 of Algorithm 2) iteratively rather than all at once. That is, rather than iterate over all complete assignments \u03b1 to ~x we can instantiate these variables one at a time, performing propagation after each assignment. This can make propagation more effective, since, e.g., an empty clause might be detected after instantiating only a subset of the variables in ~x and thus the number of iterations of the for loop might be reduced.\nOnce the variables of ~x are being set iteratively the order in which they are assigned can vary. Furthermore, the order of assignment can vary dynamically. That is, depending on how the values assigned to the first k variables of ~x, the algorithm can make different choices as to which unassigned variable of ~x to assign next.\nWe call the extension of RC-Cache that uses incremental assignments and dynamic variable ordering within set ~x, RC-Cache+ . That is RC-Cache+ uses the same caching scheme as RC-Cache, but has more flexibility in its variable ordering. It should be noted however, that RC-Cache+ does not have complete freedom in its variable ordering. It must still follow the inputed branch decomposition T . That is, the variable chosen must come from the set ~x \u2286 label(left(r)) \u2229 label(right(r)). This is in contrast with the DPLL based algorithms we present in the next section, which are always free to choose any remaining unassigned variable as the next variable to assign.\nSpace-Time Tradeoff RC has the attractive feature that it can achieve a non-trivial space-time tradeoff, taking less time if it caches its recursively computed values (RC-Cache), or taking less space without caching (RC-Space). In fact, Darwiche and Allen (2002) show that there is a smooth tradeoff that can be achieved, with RC-Space and RC-Cache at the two extremes.\nThe DPLL based algorithms presented here share a number of features with RC; they also reduce and decompose the input problem by making instantiations, gain efficiency by caching, and achieve a similar space-time tradeoff. However, our algorithms are based on the paradigm of backtracking, rather than divide and conquer. In particular, they explore a single backtracking tree in which the decomposed subproblems are not solved separately but rather can be solved in any interleaved\nfashion. As a result, they are not limited to following the decomposition scheme specified by a fixed branch decomposition. As we will see, the limitation of a static decomposition scheme means that RC-Space and RC-Cache must perform exponentially worse than our algorithms on some instances."}, {"heading": "2.4.3 AND/OR SEARCH:", "text": "In more recent work Dechter and Mateescu (2007) have shown that the notion of AND/OR search spaces (Nilsson, 1980) can be applied to formalize the divide and conquer approach to SUMPROD problems utilized by RC. In this formulation the structure that guides the AND/OR search algorithm is a pseudo tree. (Choosing the pseudo tree is the nondeterministic part of the computation.)\nDefinition 5 (Primal Graph) The primal graph of a hypergraph H is an undirected graph G that has the same vertices as H and has an edge connecting two vertices if and only if those two vertices appear together in some hyperedge of H.\nDefinition 6 (Pseudo Tree) Given an undirected graph G with vertices and edges (V,EG), a pseudo tree for G is a directed rooted tree T with vertices and edges (V,ET ) (i.e., the same set of vertices as G), such that any edge e that is in G but not in T must connect a vertex in T to one of its ancestors. That is, e = (v1, v2) \u2227 e \u2208 EG \u2227 e 6\u2208 ET implies that either v1 is an ancestor of v2 in T or v2 is an ancestor of v1 in T .\nThis implies that there is no edge of G connecting vertices lying in different subtrees of T . Given a SUMPROD problem S = \u3008V,F ,\u2295,\u2297\u3009 with underlying hypergraph H, we can form G, the primal graph of H. The vertices of G are the variables of the problem V and any pair of variables that appear together in some function of F will be connected by an edge in G. A pseudo tree T for G will then have the property that two vertices of T (variables of S) can only appear in functions of F with their ancestors or their descendants, they cannot appear in functions with their siblings nor with their ancestor\u2019s siblings nor with the descendants of such siblings.\nThis implies that once a variable v and all of its ancestors in T have been instantiated, the variables contained in its children subtrees become disconnected. That is, the variables in these subtrees no longer appear in functions together, and the resulting subproblems can be solved independently. The AND/OR search algorithm utilizes this fact to solve these subproblems independently, just like recursive conditioning.\nExample 5 Given the hypergraph H = (V,E) where V = {1, 2, 3, 4, 5} and E = {{1, 2, 3}, {1, 4},{2, 5}, {3, 5}}, the primal graph of H is G = (V,EG) where EG = {(1, 2), (1, 3), (2, 3), (1, 4), (2, 5), (3, 5)}. H, its primal graph G, and a pseudo tree for G are shown in Figure 4. The dotted lines shown on the pseudo tree are the edges of G that are not in the pseudo tree. As can be seen from the diagram these edges connect nodes only with their ancestors.\nThe space efficient version of the AND/OR-Space search algorithm (Dechter & Mateescu, 2007) is shown in Algorithm 3. It solves the SUMPROD instance S = \u3008V,F ,\u2295,\u2297\u3009, taking as input a pseudo tree for the problem T (i.e., the hypergraph for S is converted to a primal graph G, and T is a pseudo tree for G), and an initially empty set of instantiated variables \u03c1. The algorithm solves a sub-problem of the original instance S reduced by the instantiations \u03c1, S|\u03c1. The sub-problem being solved is defined by the functions of S|\u03c1 that are over the variables contained in the passed sub-tree T . Initially, with \u03c1 being empty and T being the original pseudo tree containing all variables, the algorithm solves the original problem S .\nThe nodes of the pseudo tree T are variables of the problem S , and we also attach to each node n of T a set of functions fns(n). A function f of F is in fns(n) if and only if (a) n is in the scope of f and (b) all other variables in the scope of f are ancestors of n in T . This means that f will have a fully instantiated set of arguments when AND/OR search instantiates the node (variable) n.\nAlgorithm 3: AND/OR-Space\u2014Linear Space AND/OR search\nAND/OR-Space (T, \u03c1)1 begin2 p = 0; r = root(T )3 STr = set of subtrees below r4 forall d \u2208 {instantiations of r} do5\n\u03b1 = \u220f\nf\u2208fns(r) LOOKUP(value of f on \u03c1 \u222a {r = d})6 p = p+ \u03b1\u00d7 \u220f\nT \u2032\u2208STr AND/OR-Space (T \u2032, \u03c1 \u222a {r = d})7 end8 return p9\nend10\nThe algorithm operates on the variable r that is the root of the pseudo tree T . For each instantiation of r the algorithm computes \u03b1, the product of the functions in F that have now become fully instantiated by the assignment to r, i.e., those in fns(r). It then invokes a separate recursion for each child of r passing the subtree rooted by that child to the recursive call. AND/OR search exploits decomposition through these separate recursions. If r has only one child, then the problem is not decomposed\u2014there is only the single reduced subproblem that has resulted from instantiating r.\nLike RC, AND/OR search can be made more time efficient at the expense of using more space. Algorithm 4 shows the caching version AND/OR-Cache (called AND/OR graph search by Dechter and Mateescu (2007)). Let label (n) for any node n in the pseudo tree T be the set of ancestors of n that appear in some function with n or with some descendant of n in T . It is only the instantiations to label (n) that can affect the functions over the variables in the subtree rooted by n. Hence, label (n) plays the same role as the root label of the passed branch decomposition in RCCache: only instantiations to these variables can affect the subproblem currently being computed.\nHence, like RC-Cache, AND/OR-Cache can use the instantiations in the subset, y, of \u03c1 intersecting label(root(T )) along with T to index a cache.\nFinally, as with RC-Cache+, propagation can be used to decrease the number of branches that AND/OR search needs to explore. For example, the recursive calls over the children of r can be terminated when one of these calls returns the value zero.\nAlgorithm 4: AND/OR-Cache\u2014AND/OR search with caching\nAND/OR-Cache (T, \u03c1)1 begin2 p = 0; r = root(T )3 y = \u03c1 \u2229 label (root (T ))4 if InCache(T,y) then5 return GetValue(T,y)6 STr = set of subtrees below r7 forall d \u2208 {instantiations of r} do8\n\u03b1 = \u220f\nf\u2208fns(r) LOOKUP(value of f on \u03c1 \u222a {r = d})9 p = p+ \u03b1\u00d7 \u220f\nT \u2032\u2208STr AND/OR-Cache (T \u2032, \u03c1 \u222a {r = d})10 end11 return p12\nend13\nAND/OR-Cache+ Some variable order dynamism can be employed during AND/OR search. In particular, the variables along any chain in the pseudo tree T can be reordered without affecting the decompositions specified by T . A chain is a sub-path of T such that none of its nodes, except perhaps the last, have more than one child. In Figure 4 nodes 2, 3, and 5 form a chain. The resultant extension, AND/OR-Cache+, can dynamically chose to next instantiate any of the variables in the chain that starts at the root of its passed pseudo tree T . (Marinescu and Dechter (2006) refer to AND/OR-Cache+ as \u201cAND/OR with partial variable ordering\u201d. However they did not utilize caching in their version of the algorithm.)\nIt will then pass the rest of the chain (and the nodes below) to its next recursive call, or if the chosen variable was the last in the chain it will invoke a separate recursive call for each child. Like RC-Cache+, AND/OR-Cache+ does not have complete freedom in its choice of variable\u2014it must chose a variable from the top most chain. Furthermore, AND/OR-Cache+ can only use its caching scheme at the bottom of each chain (i.e., after all variables in the chain have been instantiated) since its cache requires that the same set of variables be instantiated. This makes AND/OR-Cache+ very similar to RC-Cache+."}, {"heading": "2.4.4 OTHER EXACT ALGORITHMS", "text": "The algorithm most commonly used for BAYES is the join tree algorithm (Lauritzen & Spiegelhalter, 1988), which can also be adapted to solve other kinds of SUMPROD problems. The join-tree algorithm first organizes the primal graph of the SUMPROD problem into a tree by clustering the variables, and it then performs message passing on the tree where the messages are computed by a variable elimination process. In the context of BAYES the main advantage of join-tree algorithms is\nthat they compute all marginals. That is they compute the posterior probability of all of the variables given some evidence.\nIn contrast, the default version of variable elimination computes only the posterior distribution for a single variable. However, Kask et al. (2005) show how the join-tree algorithm can be reduced to a version of VE that remembers some of its intermediate results and runs in the same time and space as VE. Hence, all of the results we state here comparing VE with our new backtracking based algorithms also hold for the join tree algorithm.\nComputing all Marginals All of the algorithms described above, i.e., VE, RC, and AND/OR search, can be modified to compute all marginals when solving BAYES without any change to their worst case complexity. In particular, besides the results of Kask et al. (2005), Darwiche (2001) has shown that RC can compute all marginals on BAYES problems with an extra bottom up traversal of its search tree\u2014at most doubling its run time. The same technique can be applied to AND/OR search algorithms. For the DPLL algorithms we present here, Sang et al. (2005b) have given an even simpler scheme for modifying them so that they can computing all marginals. Sang et al.\u2019s scheme involves maintaining some extra information during search and does not require an extra traversal of the search tree.\nAnother algorithm that has now been mostly superseded is cut-set conditioning (Pearl, 1988). Here the idea is to identify a subset of variables which when set reduce the underlying hypergraph of the SUMPROD into a tree. The reduced SUMPROD can then be easily solved. However, the approach requires trying all possible instantiations of the cut-set yielding a runtime that is usually worse than RC-Cache. Nevertheless, cutset conditioning can potentially be applied in conjunction with other exact algorithms (Mateescu & Dechter, 2005).\nFinally, an important early algorithm called DDP was presented by Bayardo and Pehoushek (2000). This was a version of DPLL that utilized dynamic decomposition for solving #SAT. In terms of the algorithms discussed above, AND/OR-Space can be viewed as being an version of DDP that utilizes a pseudo tree to guide its variable ordering. In the original presentation of DDP, any variable ordering could be used including dynamic variable orderings. The search continued until the problem was decomposed into independent components (tested for during search) at which point a separate recursion was used to solve each component. Hence, the DDP explored an AND/OR search tree, however this tree need not correspond to any pseudo tree over the original problem. (The DVO and DSO AND/OR search schemes presented by Mateescu and Dechter (2005) are also versions of DDP run with particular variable ordering heuristics). In comparison with the algorithms we present in the next section, Bayardo and Pehoushek (2000) did not provide a complexity analysis of DDP, DDP did not use caching to enhance its performance, and DDP still has less flexibility in its variable ordering. In particular, once the problem has been split into independent components the search must solve these components sequentially in separate recursions. Inside each recursion the search can only branch on the variables of the current component. That is, DDP cannot interleave the solution of these components like the DPLL algorithms we present here."}, {"heading": "2.5 Complexity Analysis", "text": "All known algorithms for BAYES, #SAT and SUMPROD run in exponential-time in the worst case. However, when the branch width of the underlying hypergraph of the instance, w, is small, the some of the above algorithms are much more efficient. It can be shown that the algorithms VE, RCCache and AND/OR-Cache discussed above run in time and space nO(1)2O(w). We note that the\ncomplexity of these algorithms is usually given in terms of tree width or elimination width, and not branch width. However, by Lemmas 1, 2, and 3, these concepts are equivalent to within a factor of 2, and therefore the asymptotic complexity can equivalently be stated in terms of any of these three notions of width (tree width, branch width, or elimination width). For analyzing our backtracking algorithms, branch width is be somewhat more natural, and for this reason we have chosen to state all complexity results in terms of branch width.\nThe runtime of the variable elimination algorithm is easily seen to be at most nO(1)2O(w). To see this, notice that the algorithm proceeds in n stages, removing one variable at each stage. Suppose that the algorithm is run on some variable ordering that has elimination width v. The algorithm removes the ith variable during the ith stage. At the ith stage, all functions involving this variable are merged to obtain a new function. As indicated in Section 2.4.1, computing the new function involves iterating overall possible instantiations of its variables. The runtime of this stage is therefore exponential in the number of underlying variables of the new function, which is bounded by v. Thus, the runtime of the algorithm is bounded by nO(1)2O(v). Now by Lemmas 1 and 2 and 3, if the elimination width is v, then the branch width is at most v + 1, and therefore the overall runtime is as claimed. It can also be noted that since the new function must be stored, the space complexity of variable elimination is the same as its time complexity, i.e., nO(1)2O(w).\nIt has also been shown that the run times of RC-Cache and RC-Cache+ are bounded by nO(1)2O(w)\n(Darwiche, 2001). Further, there is a nice time-space tradeoff. That is, the space-efficient implementation of RC, RC-Space, runs in time 2O(w logn) but needs only space linear in the size of the input, where as RC-Cache has space complexity equal to its time complexity, nO(1)2O(w). We will present proofs showing that our DPLL based algorithms can achieve the same time and time/space bounds; our proofs give the bounds for RC-Space, RC-Cache, and RC-Cache+ as special cases.\nFinally, it has been shown that AND/OR-Space runs in time 2O(w logn) (Dechter & Mateescu, 2007). Specifically, Dechter and Mateescu show that AND/OR-Space runs in time exponential in the height of its inputed pseudo tree, and Bayardo and Miranker (1995) show that this height is bounded w log n. Lemma 1 then shows that the bound also holds for branch width. Similarly, Dechter and Mateescu (2007) show that AND/OR-Cache runs in time and space bounded by nO(1)2O(w) by exploiting the very close relationship between pseudo trees and elimination orders.\nMaking the algorithms deterministic. As stated above, all of these algorithms are in fact nondeterministic algorithms each requiring a different nondeterministically determined input. Hence, the stated complexity bounds mean that there exists some choice of nondeterministic input (i.e., some variable ordering for VE, some branch decomposition for RC, and some pseudo tree for AND/OR search) with which the algorithm can achieve the stated complexity bound.\nHowever, to achieve this runtime in practice, we will need to be able to find such a good branch decomposition (variable ordering, pseudo tree) efficiently. Unfortunately, the general problem of computing an optimal branch decomposition (i.e., one that has width equal to the branch width of H) is NP-complete. However, Robertson and Seymour (1995) present an algorithm for computing a branch decomposition with branch width that is within a factor of 2 of optimal and that runs in time nO(1)2O(w), where w is the branch width of H. By first running this deterministic algorithm to compute a good branch decomposition, one can obtain deterministic versions of RC-Cache and RC-Cache+ that run in time and space nO(1)2O(w), as well as a deterministic version of RC-Space that runs in linear space and time 2O(w logn). These deterministic versions no longer require access to a nondeterministically determined choice to achieve their stated runtimes.\nAlgorithm 5: DPLL for SAT\nDPLL (\u03c6)1 begin2 if \u03c6 has no clauses then3 return TRUE4 else if \u03c6 contains an empty clause then5 return FALSE6 else7 choose a variable x that appears in \u03c68 return (DPLL(\u03c6|x=0) \u2228 DPLL(\u03c6|x=1))9\nend10\nSimilarly with a nearly optimal branch decomposition, we can use Lemmas 1-3 to find a nearly optimal elimination ordering, and thus can obtain a deterministic version of the variable elimination algorithm that runs in time and space nO(1)2O(w). And finally, from that nearly optimal elimination ordering the bucket-tree construction of Dechter and Mateescu (2007) can be used to construct a nearly optimal pseudo tree, and thus we can obtain a deterministic version of AND/OR-Space that runs in linear space and time 2O(w logn), and a deterministic version of AND/OR-Cache that runs in time and space nO(1)2O(w)."}, {"heading": "3. Using DPLL for #SAT and SUMPROD", "text": "Now we present our methods for augmenting backtracking search with different caching schemes so that it can solve SUMPROD with time and space guarantees at least as good as the other exact algorithm for SUMPROD. For ease in presentation we present DPLL-based algorithms for solving #SAT, and derive complexity results for these algorithms. Later we will discuss how the algorithms and complexity results can be applied to other instances of SUMPROD (like BAYES)."}, {"heading": "3.1 DPLL and #DPLL:", "text": "DPLL is a nondeterministic algorithm for SAT, that has also been used to solve various generalizations of SAT, including #SAT (Dubois, 1991; Zhang, 1996; Birnbaum & Lozinskii, 1999; Littman, Majercik, & Pitassi, 2001). DPLL solves SAT by performing a depth-first search in the space of partial instantiations (i.e., it is a standard backtracking search algorithm). The nondeterministic part of the computation is lies in the choice of which variable to query (i.e., instantiate) next during its search. It operates on SAT problems encoded in clause form (CNF).\nThe standard DPLL algorithm for solving SAT is given in Algorithm 5. We use the notation \u03c6|x=0 or \u03c6|x=1 to denote the new CNF formula obtained from reducing \u03c6 by setting the variable x to 0 or 1. Reducing \u03c6 by x = 1 (x = 0) involves removing from \u03c6 all clauses containing x (\u00acx) and removing the falsified \u00acx (x) from all remaining clauses.\nDPLL is a nondeterministic procedure that generates a decision tree representing the underlying CNF formula. For solving SAT, the decision tree is traversed in a depth-first manner until either a satisfying path is encountered, or until the whole tree is traversed (and all paths falsify the formula). The nondeterminism of the algorithm occurs in the choice of variable on line 8. In practice this\nAlgorithm 6: #DPLL for #SAT (no caching)\n#DPLL (\u03c6)1 // Returns the probability of \u03c6 begin2 if \u03c6 has no clauses then3 return 14 else if \u03c6 contains an empty clause then5 return 06 else7 choose a variable x that appears in \u03c68 return (12#DPLL(\u03c6|x=0) + 1 2#DPLL(\u03c6|x=1))9\nend10\nnondeterminism is typically resolved via some heuristic choice. Also, the algorithm utilizes early termination of the disjunctive test on line 9; i.e., if the first test returns TRUE the second recursive call is not made. Thus, the algorithm stops on finding the first satisfying path.\nNote that we do not require that DPLL perform unit propagation. In particular, unit propagation can always be realized through the choice of variable at line 8. In particular, if we force DPLL to always chose a variable that appears in a unit clause of \u03c6 whenever one exists, this will have the same effect as forcing DPLL to perform unit propagation after every variable instantiation. That is, after a variable is chosen, and instantiated to one of its values, the input CNF \u03c6 will be reduced. The reduced formula, \u03c6|x=0 or \u03c6|x=1, passed to the next recursive call may contain unit clauses. With unit propagation, the variables in these clauses would be instantiated so as to satisfy the unit clauses. If instead, we force one of these variable to be chosen next, one instantiation would immediately fail due to the generation of an empty clause, while the other would instantiate the variable to the same value as unit propagation. Hence, since we analyze DPLL as a nondeterministic algorithm, this includes those deterministic realizations that perform unit propagation.\nA simple modification of DPLL allows it to count all satisfying assignments. Algorithm 6 gives the #DPLL algorithm for counting. The algorithm actually computes the probability of the set of satisfying assignments under the uniform distribution. Hence, the number of satisfying assignments can be obtained by multiplying this probability by 2n, where n is the number of variables in \u03c6. The alternative would be to return 2 raised to the number of unset variables whenever \u03c6 has no clauses (line 4) and not multiply the recursively computed counts by 12 (line 9).\nKnown exponential worst-case time bounds for DPLL also apply to #DPLL: for unsatisfiable formulas, both algorithms have to traverse an entire decision tree before terminating. Although this decision tree can be small (e.g., when an immediate contradiction is detected), for some families of formulas the decision tree must be large. In particular, it is implicit in the results of Haken (1985) that any decision tree for the formulas encoding the (negation of the) propositional pigeonhole principle has exponential size, and thus DPLL and #DPLL must take exponential-time on these examples. This lower bound does not, however, help us discriminate between algorithms since all known algorithms for #SAT and BAYES take exponential-time in the worst-case. Nevertheless, #DPLL requires exponential time even on instances that can be efficiently solved by competing algorithms for SUMPROD. To see this, consider a 3CNF formula over 3n variables consisting of\nn clauses that share no variables. Any complete decision tree has exponential size, and therefore #DPLL will require exponential time. In contrast, since this formula has low tree width it can be solved in polynomial time by VE, RC, or AND/OR search."}, {"heading": "3.2 DPLL with Caching:", "text": "Given that the obvious application of DPLL to solve SUMPROD can give exponentially worse performance than the standard algorithms, we now examine ways of modifying DPLL so that it can solve #SAT (and thus BAYES and SUMPROD) more efficiently. To understand the source of #DPLL\u2019s inefficiency consider the following example.\nExample 6 The following diagram shows a run of #DPLL on \u03c6 = {(w \u2228 x)(y \u2228 z)}. Each node shows the variable to be branched on, and the current formula #DPLL is working on. The left hand branches correspond to setting the branch variable to FALSE, while on the right the variable is set to TRUE. The empty formula is indicated by {}, while a formula containing the empty clause is indicated by {()}. The diagram shows that #DPLL encounters and solves the subproblem {(y \u2228 z)} twice: once along the path (w = 0, x = 1) and again along the path (w = 1). Note that in this example unit propagation is realized by the choice of variable ordering\u2014after w is set to FALSE, #DPLL chooses to instantiate the variable x since that variable appears in a unit clause.\nw:{(x \u2228 w))(y \u2228 z)}\nH H\nH H\nH H\nH\nx:{(x)(y \u2228 z)}\nH H\nH H\n0:{()} y:{(y \u2228 z)}\nH HH\nz:{(z)}\nH H\n0:{()} 1:{}\n1:{}\ny:{(y \u2228 z)}\nH HH\nz:{(z)}\nH H\n0:{()} 1:{}\n1:{}\nIf one considers the above example of applying #DPLL to disjoint sets of clauses, it becomes clear that in some formulas #DPLL can encounter the same subproblem an exponential number of times."}, {"heading": "3.2.1 DPLL WITH SIMPLE CACHING (#DPLL-SIMPLECACHE)", "text": "One way to prevent this duplication is to apply memoization. As indicated in Example 6, associated with every node in the DPLL tree is a formula f such that the subtree rooted at this node is trying to compute the number of satisfying assignments to f . When performing a depth-first search of the tree, we can keep a cache that contains all formulas f that have already been solved, and upon reaching a new node of the tree we can avoid traversing its subtree if the value of its corresponding formula is already stored in the cache.\nIn Example 6 we would cache {(y \u2228 z)}, when we solve it along the path (w = 0, x = 1) thereby avoid traversing the subtree below (w = 1).\nAlgorithm 7: #DPLL algorithm with simple caching (#DPLL-SimpleCache)\n#DPLL-SimpleCache (\u03c6)1 // Returns the probability of \u03c6 begin2 if InCache(\u03c6) then3 // Also detects obvious formulas. return GetValue(\u03c6)4\nelse5 choose a variable x that appears in \u03c66 val = 12#DPLL-SimpleCache (\u03c6|x=0) + 1 2#DPLL-SimpleCache (\u03c6|x=1)7 AddToCache(\u03c6,val )8 return val9\nend10\nThe above form of caching, which we will call simple caching (#DPLL-SimpleCache) can be easily implemented as shown in Algorithm 7.4 As with #DPLL, #DPLL-SimpleCache returns the probability of its input formula \u03c6; multiplying this by 2n gives the number of satisfying assignments.\nIn addition to formulas stored in the cache there are also the following obvious formulas whose value is easy to compute. (1) The empty formula {} containing no clauses has value 1. (2) Any formula containing the empty clause has value 0. Obvious formulas can be treated as if they are implicitly stored in the cache (they need not be explicitly stored in the cache, rather their values can be computed as required).\nThe following (low complexity) subroutines are used to access the cache. (1) AddToCache(\u03c6, r): adds to the cache the fact that formula \u03c6 has value r. (2) InCache(\u03c6): takes as input a formula \u03c6 and returns true if \u03c6 is in the cache. (3) GetValue(\u03c6): takes as input a formula \u03c6 known to be in the cache and returns its stored value. There are various ways of computing a cache key from \u03c6. For example, \u03c6 can be maintained as a sorted set of sorted clauses, and then cached as if it was a text string. Such a caching scheme has nO(1) complexity.\nSurprisingly, simple caching, does reasonably well. The following theorem shows that simple caching achieves runtime bounded by 2O(w logn), where w is the underlying branch width. As with our complexity analysis of earlier algorithms presented in Section 2.5, the simple caching algorithm can also be made deterministic by first computing a branch decomposition that is within a factor of 2 of optimal (using the Robertson-Seymour algorithm), and then running #DPLL-SimpleCache with a variable ordering determined by this branch decomposition.\nTheorem 1 For solving #SAT with n variables, there is an execution of #DPLL-SimpleCache that runs in time bounded by 2O(w logn) where w is the underlying branch width of the instance. Furthermore, the algorithm can be made deterministic with the same time guarantees.\nAlthough the theorem shows that #DPLL-SimpleCache does fairly well, its performance is not quite as good as the best SUMPROD algorithms (which run in time nO(1)2O(w)).\n4. Simple caching has been utilized before (Majercik & Littman, 1998), but without theoretical analysis.\nAlgorithm 8: #DPLL algorithm with component caching (#DPLL-Cache)\n#DPLL-Cache (\u03a6)1 // Returns the probability of the set of disjoint formulas \u03a6 begin2 if InCache(\u03a6) then3 // Also detects obvious formulas. return GetValue(\u03a6)4\nelse5 \u03a8 = RemoveCachedComponents(\u03a6)6 choose a variable x that appears in some component \u03c6 \u2208 \u03a87 \u03a8\u2212 = ToComponents(\u03c6|v=0)8 #DPLL-Cache (\u03a8\u2212 {\u03c6} \u222a\u03a8\u2212)9 \u03a8+ = ToComponents(\u03c6|v=1)10 #DPLL-Cache (\u03a8\u2212 {\u03c6} \u222a\u03a8+)11 AddToCache(\u03c6, 12GetValue(\u03a8 \u2212) + 12GetValue(\u03a8 +))12 if #DPLL-Space then13 RemoveFromCache(\u03a8\u2212 \u222a\u03a8+)14 return GetValue(\u03a6)15 end16"}, {"heading": "3.2.2 DPLL WITH COMPONENT CACHING (#DPLL-CACHE)", "text": "Now we show that a more sophisticated caching scheme allows #DPLL to perform as well as the best known algorithms. We call the new algorithm #DPLL-Cache, and its implementation is given in Algorithm 8.\nIn the algorithm we generalize the cache to deal with sets of formulas. First, we say that a (single) formula \u03c6 is known if its value is stored in the cache or it is an obvious formula (and its value is implicitly stored in the cache). Given a set of formulas \u03a6 we say that the set is known if either every \u03c6 \u2208 \u03a6 is known, or there is some \u03c6 \u2208 \u03a6 whose value is known to be zero. In both cases we say that \u03a6\u2019s value is equal to the product of the values of the \u03c6 \u2208 \u03a6.\nNow we generalize some of the cache access subroutines. (1) InCache(\u03a6) is generalized so that it can take as input a set of formulas \u03a6. It returns true if \u03a6 is known as just defined. (2) Similarly GetValue(\u03a6) is generalized to take sets of formulas as input. It returns the product of the cached values of the formulas \u03c6 \u2208 \u03a6.\nThe intuition behind #DPLL-Cache is to recognize that as variables are set the input formula may become broken up into disjoint components, i.e., sets of clauses that share no variables with each other. Since these components share no variables we can compute the number of solutions to each component and multiply the answers to obtain the total solution count. Thus, it is intended that GetValue be called with a set of disjoint components \u03a6. In that case it will correctly return the solution count for \u03a6\u2014i.e., the product of the solution counts for each \u03c6 \u2208 \u03a6.\nThe algorithm creates a standard DPLL tree, however it caches component formulas as their values are computed. It keeps its input in decomposed form as a set of disjoint components, and if any of these components are already in the cache (and thus their value is known) it can remove\nthese parts of the input\u2014reducing the size of the problem it still has to solve and avoiding having to resolve these components.\nThe new algorithm uses the previously defined cache access subroutines along with two additional (low complexity) subroutines. (1) ToComponents(\u03c6): takes as input a formula \u03c6, breaks it up into a set of minimal sized disjoint components, and returns this set. (2) RemoveCachedComponents(\u03a6): returns the input set of formulas \u03a6 with all known formulas removed. The input to #DPLL-Cache is always set of disjoint formulas. Hence, to run #DPLL-Cache on the input formula \u03c6 we initially make the call #DPLL-Cache (ToComponents(\u03c6)).\nToComponents simply computes the connected components of the primal graph generated by \u03c6. That is, in this graph all of the variables of \u03c6 are nodes, and two nodes are connected if and only if the corresponding variables appear together (in any polarity) in a clause of \u03c6. Each connected component of this primal graph (which can be computed with a simple depth-first traversal of the graph Cormen, Leiserson, Rivest, & Stein, 2001), defines a set of variables whose clauses form an independent component of \u03c6.\nEach call of #DPLL-Cache completes with the solution of the unknown components from the set of inputed components \u03a6. If all components of \u03a6 are known the product of the values of these components will be returned at line 4. Otherwise the input set of components is reduced by removing all known components (line 6), which must leave at least one unknown component and potentially reduces the size of the remaining problem to be solved. Then a variable from some unsolved component is chosen and is branched on. Since the variable only appears in the component \u03c6 its assignment can only affect \u03c6. In particular, its assignment might break \u03c6 into smaller components (line 8 and 11). The recursive call will solve all components it is passed, so after the two recursive calls the value of \u03c6 can be computed and cached (line 12). Finally, since all components in the inputed set \u03a6 are now solved its value can be retrieved from the cache and returned.\nExample 7 Figure 5 illustrates the behavior of #DPLL-Cache on the formula \u03c6 = {(a, b, c, x), (\u00aca, b, c), (a,\u00acb, c), (d, e, f, x), (\u00acd, e, f), (d,\u00ace, f)}. Although the problem could be solved with a simpler search tree, we use a variable ordering that generates a more interesting behavior.\nEach node shows the variable to be branched on, and the current set of components #DPLLCache is working on. The known components (i.e., those already in the cache) are marked with an asterisk (\u2217). The branch variables are set to FALSE on the left branch and TRUE on the right branch. The empty formula is indicated by {}, while a formula containing the empty clause is indicated by {()}. To simply the diagram we use unit propagation to simplify the formula after the branch variable is set. This avoids the insertion into the diagram of nodes where unit clause variables are branched on. Finally, note that known formulas are removed before a recursive call is made, as per line 6 of Algorithm 8).\nAt the root, once x has been set to false, \u03c6 is broken up into two components \u03c6a,b,c = {(a, b, c), (\u00aca, b, c), (a,\u00acb, c)}, and \u03c6d,e,f = {(d, e, f), (\u00acd, e, f), (d,\u00ace, f)}. The search tree demonstrates that it does not matter how the search interleaves branching on variables from different components, the components will still be solved independently. We see that the leftmost node in the tree that branches on f succeeds in solving the component {(e, f), (\u00ace, f)}. This component is then added to the cache. Similarly, the parent node that branches on b solves the component {(b, c), (\u00acb, c)}. (The subcomponents \u03a8\u2212 and \u03a8+ generated by setting b, lines 8 and 11 of Algorithm 8, and performing unit propagation are equal to the empty formula, {}, and thus are known). On backtrack to d, the alternate value for d does not affect the component {(b, c), (\u00acb, c)}, so its value can be retrieved from the cache leaving only the component {(e, f)} to be solved. Branching on e solves\nthis component. Backtracking to d we have that both {(e, f)} and {(e, f), (\u00ace, f)} are solved, so \u03c6d,e,f \u2019s value can be computed and placed in the cache. On backtracking to a, the alternate value for a does not affect the component \u03c6d,e,f , so its value can be retrieved from the cache leaving only the component {(b, c)} to be solved. Branching on b solves this component, after which both {(b, c)} and {(b, c), (\u00acb, c)} are solved so \u03c6a,b,c\u2019s value can be computed and placed in the cache. The search can then backtrack to try setting x to TRUE.\nWe can obtain the following upper bound on the runtime of #DPLL-Cache.\nTheorem 2 For solving #SAT on n variables, there exists an execution of #DPLL-Cache that runs in time bounded by nO(1)2O(w) where w is the underlying branch width of the instance. Furthermore, the algorithm can be made deterministic with the same time guarantees (as discussed in Section 2.5).\nSo we see that #DPLL-Cache can achieve the same level of performance as the best SUMPROD algorithms.\nFinally, there is a third variant of #DPLL with caching, #DPLL-Space , that achieves a nontrivial time-space tradeoff. This algorithm is the natural variant of #DPLL-Cache, modified to remove cached values so that only linear space is consumed. The algorithm utilizes one additional subroutine. (6) RemoveFromCache(\u03a6): takes as input a set of formulas (a set of components) and removes all of them from the cache. After splitting a component with a variable instantiation and computing the value of each part, #DPLL-Space cleans up the cache by removing all of these sub-components, so that only the value of the whole component is retained. Specifically, #DPLL-Space is exactly like #DPLL-Cache, except that it calls RemoveFromCache(\u03a8\u2212 \u222a\u03a8+) just before returning (line 14).\nTheorem 3 For solving #SAT on n variables, there is an execution of #DPLL-Space that uses only space linear in the instance size and runs in time bounded by 2O(w logn) where w is the underlying branch width of the instance. Furthermore, the algorithm can be made deterministic with the same time and space guarantees.\nThe proofs of Theorems 1\u20133 are given in the appendix."}, {"heading": "3.3 Using DPLL Algorithms for Other Instances of SUMPROD:", "text": "The DPLL algorithms described in this section can be easily modified to solve other instances of SUMPROD. However, since #SAT is #P complete many instances of SUMPROD can also be solved by simply encoding them in #SAT. For example, this approach is readily applicable to BAYES and has proved to be empirically successful (Sang et al., 2005b). Furthermore, the encoding provided by Sang et al. (2005b) achieves the same complexity guarantees as standard algorithms for BAYES. (That is, the CNF encoding has tree width no greater than the original Bayes Net). Note that this encoding assigns non-uniform probabilities to values of the variables. That is, for variable x the probability of x = 0 might not be equal to the probability of x = 1. This is easily accommodated in our algorithms: instead of multiplying the value returned by each recursive call by 12 we simply multiply it by the probability of the corresponding variable value (i.e., by Pr(x = 0) or Pr(x = 1)).\nOn the other hand, if conversion to #SAT is inapplicable or undesirable the algorithms can be modified to solve other instances of SUMPROD directly. For SUMPROD, we want to compute \u2295\nX1 . . .\n\u2295\nXn\n\u2297m j=1 fj(Ej). DPLL chooses a variable, Xi, and for each value d of Xi it recursively\nsolves the reduced problem F|Xi=d. (Hence, instead of a binary decision tree it builds a k-ary tree). The reduced problem F|Xi=d is to compute\n\u2295\nX1\n. . . \u2295\nXi\u22121\n\u2295\nXi+1\n. . . \u2295\nXm\nm \u2297\nj=1\nfj(Ej)|Xi=d,\nwhere fj(Ej)|Xi=d is fj reduced by setting Xi = d. #DPLL-SimpleCache caches the solution to the reduced problem to avoid recomputing it. For example, it can remember the reduced problem by remembering which of the original functions in F remain (i.e., have not been reduced to a constant value) and the set of assignments that reduced these remaining functions. #DPLL-Cache caches the solution to components of the reduced problem. For example, it can remember a component by remembering the set of original functions that form the component along with the set of assignments that reduced these functions. It can compute the current components by finding the connected components of the primal graph generated from the hypergraph of the SUMPROD instance with all instantiated variables removed. It is a straightforward adaptation to show that the above three theorems continue to hold for #DPLL, #DPLL-Cache, and #DPLL-Space so modified to solve SUMPROD.\nAlgorithm 9 shows how #DPLL-Cache, for example, can be modified to solve general SUMPROD problems. The algorithm takes as input a set of components \u03a6, just like #DPLL-Cache, initially containing the components of the original problem. In the algorithm fns(x) denotes the set of functions of the original problem that (a) contain x in their scope, and (b) are fully instantiated by the instantiation of x.\nAlgorithm 9: SUMPROD-DPLL-Cache algorithm for arbitrary SUMPROD problems\nSUMPROD-DPLL-Cache (\u03a6)1 begin2 if InCache(\u03a6) then3 return GetValue(\u03a6)4 else5 \u03a8 = RemoveCachedComponents(\u03a6)6 choose a variable x that appears in some component \u03c6 \u2208 \u03a87 p = 08 foreach d \u2208 domain of x do9\n\u03a6d = ToComponents(\u03c6|x=d)10 \u03b1 = \u220f\nf\u2208fns(x) LOOKUP(value of f on \u03c1 \u222a {x = d})11 p = p+ \u03b1\u00d7 SUMPROD-DPLL-Cache(\u03a6\u2212 {\u03c6} \u222a\u03a6d)12\nend13 AddToCache(\u03c6, p)14\nreturn GetValue(\u03a6)15 end16"}, {"heading": "4. Comparing Algorithms for BAYES and #SAT", "text": "In this section, we will prove that our DPLL based algorithms are at least as powerful as the standard complete algorithms for solving #SAT, and that they are provable more powerful than many of them on some instances. This last feature is important as it means that solving SUMPROD using DPLL augmented with caching can in some cases solve problems that are beyond the reach of many standard complete algorithms.\nAs mentioned earlier, the algorithms for SUMPROD as well as our new DPLL-based algorithms, are actually nondeterministic algorithms that require some nondeterministically chosen input. (This input can be viewed as being a sequence of bits). For VE, the nondeterministic bits encode an elimination ordering; for RC, the nondeterministic bits encode a branch decomposition; for AND/OR search the nondeterministic bits encode a pseudo tree; and for our DPLL based algorithms, the nondeterministic bits encode the underlying decision tree indicating which variable will be queried next in the backtracking process. Thus when comparing the \u201cpower\u201d of these algorithms we must be careful about how the nondeterminism is resolved. For example, VE operating with a very bad elimination ordering cannot be expected to run as efficiently as #DPLL-Cache operating with a very good branching strategy. First we present some definitions which allow us to state our results precisely.\nDefinition 7 Let f be a CNF formula. Define Time[VE](f) to be the minimal runtime of any variable elimination algorithm for solving #SAT for f , over all choices of elimination orderings for f . Similarly define Time[A](f), for A equal to RC-Cache, RC-Space, RC-Cache+, AND/OR-Space, AND/OR-Cache, AND/OR-Cache+, #DPLL-Cache, and #DPLL-Space. (For example, Time[RCCache](f) is the minimal runtime of the RC-Cache algorithm solving #SAT for f , over all possible branch decompositions of f .)\nDefinition 8 Let A and B be two nondeterministic algorithms for #SAT. Then we will say that A polynomial-time simulates B if there is a fixed polynomial p such that for every CNF formula f Time[A](f) \u2264 p(Time[B](f)).\nThe following theorem shows that RC-Cache and RC-Cache+ polynomially simulate VE. The proof of this theorem is implicit in the results of Darwiche (2001).\nTheorem 4 Both RC-Cache and RC-Cache+ polynomially simulate VE.\nNow we prove that DPLL with caching is as powerful as previous algorithms.\nTheorem 5 #DPLL-Cache polynomially simulates RC-Cache, RC-Cache+, AND/OR-Cache, AND/OR-Cache+, and VE. #DPLL-Space polynomially simulates RC-Space, AND/OR-Space and DDP.5\nThe proof of this theorem is given in the appendix. It should be noted that the proof also implies that there is a deterministic version of #DPLL-Cache that has time (and space) complexity that is at least as good as any deterministic realization of RC-Cache, RC-Cache+, AND/ORCache, AND/OR-Cache+, or VE. Similarly, there is a deterministic version of #DPLL-Space that has time (and space) complexity that is at least as good as any deterministic realization of RC-Space, AND/OR-Space and DDP.\nNow we prove that DPLL with caching can in some cases run super-polynomially faster than previous algorithms. The proof is given in the appendix.\nTheorem 6 None of RC-Space, RC-Cache, AND/OR-Cache, AND/OR-Space or VE can polynomially simulate #DPLL-Cache, #DPLL-Space, or #DPLL.\nThis theorem shows that #DPLL-Cache/Space has a basic advantage over the other standard algorithms for SUMPROD. That is, on some problems RC, AND/OR search, and VE will all require time super-polynomially greater than #DPLL-Cache no matter what branch decomposition, pseudo tree, or variable ordering they are supplied with, even when caching is utilized. The proof of this theorem shows that the advantage of #DPLL-Cache arises from its ability to utilize dynamic variable orderings, where each branch can order the variables differently. The flexibility of a dynamic variable ordering for these instances gives rise to increased opportunities for contradictions thereby significantly decreasing the overall runtime.\nWe note that Theorem 6 does not cover those algorithms that have more flexibility in their variable ordering, i.e., AND/OR-Cache+, RC-Cache+, and DDP. It is an open problem whether or not #DPLL-Cache is superpolynomially faster than these algorithms on some instances, although we conjecture that Theorem 6 is also true for these algorithms.\nIn particular, note that #DPLL-Cache still has greater flexibility in its variable ordering than any of these algorithms. None of these algorithms have complete flexibility in their variable ordering. AND/OR-Cache+ must select an uninstantiated variable from the chain that starts at the root of its passed pseudo tree; RC-Cache+ must select an uninstantiated variable from the intersection of the labels of the left and right children of the root of its passed branch decomposition; and DDP must select an uninstantiated variable from the component it is currently solving. In contrast #DPLLCache can select any uninstantiated variable.\n5. DDP is the algorithm presented by Bayardo and Pehoushek (2000).\nThe difficulty with proving Theorem 6 for these other algorithms is that all of them can tradeoff flexibility in their variable ordering with their ability to decompose the problem. The clearest example of this occurs with AND/OR-Cache+. If AND/OR-Cache+ is passed a pseudo tree that is simply a single chain of variables, it will have complete flexibility in its variable ordering, but at the same time it will never decompose the problem. Similarly, if RC-Cache+ is provided with a branch decomposition that has large labels it will have more flexibility in its variable ordering, but will be less effective in decomposing the problem. For the family of problems used to prove Theorem 6 only flexibility in the variable ordering is needed to achieve a superpolynomial speedup, and thus for example AND/OR-Cache+ can achieve this speedup by completely sacrificing decomposition.\n#DPLL-Cache can manage the tradeoff between flexibility in variable ordering and decomposing the problem in more sophisticated ways. For example, it has the ability to use a variable ordering that encourages decomposition in some parts of its search tree while using a different variable orderings in other parts of its search tree. For instance, the Cachet system, which is based on #DPLL-Cache, employs a heuristic that dynamically trades off a variable\u2019s ability to decompose the problem with its ability to refute the current subtree (Sang et al., 2005a). (It employs a weighted average of the number of clauses the variable will satisfy and the variable\u2019s VSID score Moskewicz, Madigan, Zhao, Zhang, & Malik, 2001). #DPLL-Cache also has the ability to interleave the solving of its current set of components by successively choosing variables from different components. To extend Theorem 6 to cover AND/OR-Cache+, RC-Cache+ and DDP a family of problems exploiting these features of #DPLL-Cache would have to be developed."}, {"heading": "5. Impact on Practice", "text": "Some of the results of this paper were first presented in a conference paper (Bacchus, Dalmao, & Pitassi, 2003), and since that time a number of works have been influenced by the algorithmic ideas presented here.\nThe Cachet system (Sang et al., 2004, 2005a) is a state of the art #SAT solver directly based on the results presented here. Cachet like our #DPLL-Cache algorithm, is based on the ideas of dynamic decomposition into components and caching of component solutions. It was an advance over previous #SAT solvers in its use of caching to remember previously solved components and in its integration of clause learning. The previous best #SAT solver, the DDP solver (Bayardo & Pehoushek, 2000), also performed dynamic component detection but had neither component caching nor clause learning. Our results highlighted the importance of component caching and the possibility of basing a #SAT solver on a standard DPLL implementation thus making the integration of clause learning feasible.\nCachet resolved a number of issues in making the algorithms we presented here practical. This included practical ways of implementing the caching of components including a method for efficiently computing a key that could be used for cache lookup. (This method was subsequently improved by Thurley, 2006). The Cachet system has also been used to solve BAYES, most probable explanation (MPE), and weighted MAX-SAT problems by encoding these problems as weighted #SAT problems (Sang et al., 2005b, 2007). This approach has proved to be very successful, especially for BAYES where it is often much superior to standard BAYES algorithms. The applications of #SAT and the Cachet system for BAYES has been further advanced by Li et al. (2006, 2008).\nIt should also be noted that practical #SAT solving and its applications to other problems like BAYES has also been advanced during this period by work on the RC algorithm and its application\nto compiling CNF into representations on which model counting is tractable, e.g., (Darwiche, 2004; Chavira & Darwiche, 2006, 2008). This work has also illustrated the value of converting various problems into weighted #SAT instances, and the utilization of techniques like clause learning (in this case integrated into a RC style algorithm). There has also been considerable work advancing AND/OR search, e.g., (Dechter & Mateescu, 2004; Marinescu & Dechter, 2006; Dechter & Mateescu, 2007).\nOne difference between the Cachet system and the RC and AND/OR search based systems mentioned above is that Cachet utilized a dynamic decomposition scheme. In particular, Cachet used a dynamic variable ordering heuristic that attempts to trade off a variable\u2019s ability to decompose the problem with its ability to refute the current subtree. Because the variable ordering was dynamically determined during search, Cachet cannot predict what components will be generated during search. Hence it has to examine the current component (i.e., the component containing the variable just instantiated) to discover the new components generated. Thus Cachet utilized an approach like that specified in Algorithm 8 where a function like ToComponents is invoked on newly reduced component (see line 8). ToComponents must do a linear computation to find the new components (e.g., a depth-first search or a union-find algorithm). In addition, for each component it must examine the clauses contained in the component to compute a cache key.\nIn contrast, RC and AND/OR search take as input a static or precomputed decomposition scheme (i.e., a branch decomposition or a pseudo tree). Hence, they are able to find components without doing any extra work during search, and are able to more efficiently compute cache keys for these components. For example, with AND/OR search, the algorithm simply follows the supplied pseudo tree. When the variable V along with all variables on the path from the root to V have been instantiated, AND/OR search knows that the variables in each subtree rooted by a child of V forms an independent component. Hence, it can \u201cdetect\u201d these components during search in constant time. Similarly, it need not examine the clauses over the variables in these new components to compute a cache key. Instead it can compute a cache key from the node of the pseudo tree that roots the component and the set of instantiations of the parents of that root that appear in clauses with the variables of the component. Note that, the set of parents whose instantiations are relevant can be computed before search so that all that has to be done during search is to look up their current values.\nThus, by using a static decomposition scheme RC and AND/OR search can gain efficiency over Cachet. However, these statically computed decompositions are not always as effective as the dynamic scheme employed by Cachet. First, it can be useful to override the precomputed decomposition scheme so as to drive the search towards contradictions. This is the gist of Theorem 6 which shows that more dynamic flexibility in variable ordering can provide superpolynomial reductions in the size of the explored search tree by better exploiting such contradictions. Second, static decompositions cannot account for the different values of the variables. That is, the formula that arises after instantiating a variable V to 0 can be quite different from the formula that arises after instantiating V to 1. This difference can negatively affect the performance of RC and AND/OR search in at least a couple of ways: components might be generated that are not predicted by the static decomposition scheme and thus the static scheme might not fully exploit decomposition; and due to the specific changes to the formula generated by particular instantiations, the static decomposition scheme might be inappropriate for much of the search space.\nIn practice, Cachet displays a performance that is at least as good as systems built using the RC algorithm, and in some cases its performance is superior (see the empirical results presented\nby Sang et al., 2004, 2005a). It should also be noted that #DPLL-Cache can easily utilize a static decomposition scheme and gain all of the efficiencies of such schemes. For example, if provided with a pseudo tree #DPLL-Cache can follow any ordering of the variables in that pseudo tree under which parents are always instantiated before their children. Like AND/OR search it will know that the children of any node in the pseudo tree each root an independent component, so it also will be able to detect these components in constant time. Furthermore, it would be able to utilize the more efficient caching scheme of AND/OR search. In this case its advantage over AND/OR search would be that it would have the freedom to interleave the solving of its components.6\nIn more recent work our algorithms have also been applied to optimization problems (Kitching & Bacchus, 2008). This work involved adding branch and bound techniques to the decomposition and component caching described in #DPLL-Cache. During branch and bound dynamic variable ordering can be very effective. In particular, one wants to branch on variables that will drive the value of the current path towards a better value as this can generate a global bound that can be more effective in pruning the rest of the search space. The empirical results of Kitching and Bacchus (2008) show that the added flexibility of #DPLL-Cache can sometimes yield significant performance improvements over AND/OR search even when the extra flexibility of AND/OR-Cache+ is exploited."}, {"heading": "6. Final Remarks", "text": "In this paper we have studied DPLL with caching, analyzing the performance of various types of caching for #SAT. Our results apply immediately to a number of instances of the SUMPROD problem including BAYES, since #SAT is complete for the class #P. However, our proofs can also be modified without much difficulty so that our complexity results apply directly to any problem in SUMPROD.\nMore sophisticated caching methods have also been explored for solving SAT by Beame et al. (2003) who showed that some of these methods can considerably increase the power of DPLL. However, these more sophisticated caching methods are currently not practical due to their large overheads. In other related work, one of the results of Aleknovich and Razborov (2002) showed that SAT could be solved in time nO(1)2O(w). Our results extend this to any problem in SUMPROD\u2014as shown in Section 2.1 SAT is an instance of SUMPROD.\nWe have proved that from a theoretical point of view, #DPLL-Cache is just as efficient in terms of time and space as other state-of-the-art exact algorithms for SUMPROD. Moreover, we have shown that on specific instances, #DPLL-Cache substantially outperforms the basic versions of these other algorithms. The empirical results presented in the works described in Section 5 indicate that these advantages can often be realized in practice and that on some problems our DPLL based algorithms can yield significant performance improvements.\nThere are a number of reasons why our DPLL based algorithms can outperform traditional algorithms for SUMPROD. Algorithms like VE and the join tree algorithm (which is used in many BAYES inference systems), take advantage of the global structure of interconnections between the functions as characterized by the tree width or branch width of the instance. Our DPLL algorithms however, can also naturally exploit the internal or local structure within the functions. This is accomplished by instantiating variables and reducing the functions accordingly. This can lead to\n6. Marinescu and Dechter (2007) present a method for searching an AND/OR tree in a best-first manner. This method can also interleave the solving of components, but in general best-first search has exponential space overheads.\nimprovements especially when the functions are encoded in a way to expose more of the function\u2019s internal structure, such as an encoding by sets of clauses (e.g., see Li et al., 2008). There are two prominent examples of structure that can be exploited by DPLL.\nFirst, some of the subproblems might contain zero valued functions. In this case our algorithms need not recurse further\u2014the reduced subproblem must have value 0.7 In VE the corresponding situation occurs when one of the intermediate functions, Fi, produced by summing out some of the variables, has value 0 for some setting of its inputs. In VE there is no obvious way of fully exploiting this situation. VE can achieve some gains by ignoring those parts of Fi\u2019s domain that map to 0 when Fi appears in a product with other functions. However, it can still expend considerable effort computing some other intermediate function Fj many of whose non-zero values might in fact be irrelevant because they will eventually be multiplied by zero values from Fi.\nSecond, it can be that some of the input functions become constant prior to all of their variables being set (e.g., a clause might become equivalent to TRUE because one of its literals has become true), or they might become independent of some of their remaining variables. This means the subproblems f |xi=1 and f |xi=0 might have quite different underlying hypergraphs. Our DPLL-based algorithms can take advantage of this fact, since they work on these reduced problems separately. For example, our algorithms are free to use dynamic variable orderings, where a different variable ordering is used solving each subproblem. VE, on the other hand, does not decompose the problem in this way, and hence cannot take advantage of this structure.\nIn BAYES this situation corresponds to context-specific independence where the random variable X might be dependent on the set of variables W,Y,Z when considering all possible assignments to these variables (so f(X,W,Y,Z) is one of the input functions), but when W = True it might be that X becomes independent of Y (i.e., f(X,W,Y,Z)|W=1 might be a function F (X,Z) rather than F (X,Y,Z)). Previously only ad-hoc methods have been proposed (Boutilier, Friedman, Goldszmidt, & Koller, 1996) to take advantage of this kind of structure.\nIt should be noted however, that when the problem\u2019s functions have little or internal structure VE can be significantly more efficient than any of the other algorithms (RC, AND/OR search and our DPLL algorithms). VE only uses simple multiplication and summation operations and does have any of the overheads involved with instantiating variables and exploring an AND/OR search tree or backtracking tree.\nRC and AND/OR search share some of the same advantages over VE. However, they do not have as much flexibility as our DPLL algorithms. We have shown in Theorem 6 that fully exploiting the zero valued functions can in some instances require dynamic variable orderings that lie outside of the range of the basic versions of RC and AND/OR search. Although our proof does not cover the enhanced versions of RC and AND/OR (RC-Cache+ and AND/OR-Cache+), we have pointed out that even these versions do not have the same flexibility as our DPLL algorithms. In practice, the empirical evidence provided by the Cachet system (Sang et al., 2004, 2005a) and by the branch and bound system described by Kitching and Bacchus (2008) support our belief that this added flexibility can be important in practice.\nThe exploitation of context-specific independence also poses some problems for RC and AND/OR search algorithms. In particular, the static decomposition schemes they employ are incapable of fully exploiting this structure\u2014as pointed out above the underlying hypergraphs of the subproblems arising from different instantiations can be radically different. However, although our DPLL\n7. For #SAT this corresponds to the situation where a clause becomes empty.\nalgorithms are in principle able to exploit such structure, it remains an open problem to find practical ways to accomplishing this. Specifically, when a decomposition scheme is computed prior to search sophisticated (and computationally complex) algorithms can be utilized. It is difficult to overcome the overhead of such methods when they are used dynamically during search (although see Li and van Beek 2004 for some work in this direction). The development of methods that are light weight enough to use during search and are still effective for selecting decomposition promoting variables remains an open problem.\nFinally, as shown in the proof of Theorem 5, RC and AND/OR search possess no intrinsic advantages over our DPLL algorithms except perhaps conceptually simplicity. The proof shows that our DPLL algorithms can simulate RC and AND/OR search in such a way that no additional computation is required. Furthermore, as pointed out in the Section 5 our algorithms are also able to utilize static decomposition schemes obtaining the same efficiency gains as RC and AND/OR search.\nRecently, several papers (Sanner & McAllester, 2005; Mateescu & Dechter, 2007) have made significant progress on developing more compact representations for functions (rather than tabular form), thereby potentially enhancing all of the algorithms discussed in this paper (VE, RC, etc.) by allowing them to exploit additional local structure within the functions. An interesting future step would be to combine the unique dynamic features of #DPLL-Cache with one of these promising compact function representations to try to further improve SUMPROD algorithms.\nAcknowledgments This research funded by governments of Ontario and Canada through their NSERC and PREA programs. Some of the results of this paper were presented in an earlier conference paper (Bacchus et al., 2003). We thank Michael Littman for valuable conversations."}, {"heading": "Appendix A. Proofs", "text": "A.1 Lemmas Relating Branch Width, Tree Width, and Elimination Width\nLemma 2 Let H = (V,E) be a hypergraph with a tree-decomposition of width w. Then there is an ordering \u03c0 of the vertices V such that the induced width of H under \u03c0 is at most w.\nProof: Let H = (V,E) be a hypergraph of tree width w and let Ttd be a tree decomposition that achieves width w. That is, the maximum sized label of Ttd is of size w + 1. We can assume without loss of generality that the labels of the leaves of Ttd are in a one-to-one correspondence with the edges of H. For an arbitrary node m in Ttd, let label(m) be the set of vertices in the label of m, Am be the tree rooted at m, vertices(m) be the union of the labels of the leaf nodes in Am (i.e., the hyperedges of H appearing below Am), and depth(m) be the distance from m to the root. Let x be any vertex of H, and let leaves(x) be the set of leaves of Ttd that contain x in their label. We define node(x) to be the deepest common ancestor in Ttd of all the nodes in leaves(x), and the depth of a vertex, depth(x), to be depth(node(x)). Note that x \u2208 label(node(x)), since the path from the left-most leaf in leaves(x) to the right-most leaf must pass through node(x); and that x does not appear in the label of any node outside of the subtree rooted at node(x), since no leaf outside of this subtree contains x.\nFinally let \u03c0 = x1, . . . , xn be any ordering of the vertices such that if depth(y) < depth(x), then y must precede x in the ordering. We use the notation y <\u03c0 x to indicate that y precedes x in\nthe ordering \u03c0 (and thus y will be eliminated after x). We claim that the induced width of \u03c0 is at most the width of Ttd, i.e., w.\nConsider Anode(x), the subtree rooted at node(x), and vertices(node(x)), the union of the labels of the leaves of Anode(x). We make the following observations about these vertices.\n1. If y \u2208 vertices(node(x)) and y <\u03c0 x, then y labels node(x) and node(y) must be ancestor of node(x) (or equal). y <\u03c0 x implies that depth(y) \u2264 depth(x). There must be a path from the leaf in Anode(x) containing y to node(y), and since node(y) is at least as high as node(x) the path must go through node(x) (or we must have node(x) = node(y)). In either case y \u2208 label (node(x)).\n2. If y \u2208 vertices(node(x)) and y >\u03c0 x then node(y) must lie inside Anode(x) and node(y) must be a descendant of node(x) (or equal). y >\u03c0 x implies that depth(y) \u2265 depth(x). There must be a path from the leaf in A containing y to node(y), and since node(y) is at least as deep at node(x) there must either be a further path from node(y) to node(x), or node(y) = node(x).\nNote further that condition 2 implies that if y >\u03c0 x and y appears in the subtree below node(x), then all hyperedges in the original hypergraph H containing y must also be in the subtree below node(x).\nWe claim that the hyperedge produced at stage i in the elimination process when xi is eliminated is contained in label(node(xi)). Since the size of this set is bounded by w + 1, we thus verify that the induced width of \u03c0 is bounded by w (note that the hyperedge produced in elimination does not contain xi where as label (node(xi)) does).\nThe base case is when x1 is eliminated. All hyperedges containing x1 are contained in the subtree below node(x1), thus the hyperedge created when x1 is eliminated is contained in vertices(node(x1)). All other vertices in vertices(node(x1)) follow x1 in the ordering so by the above they must label node(x1) and vertices(node(x1)) \u2286 label(node(x1)).\nWhen xi is eliminated there are two types of hyperedges that might be unioned together: (a) those hyperedges containing xi that were part of the original hypergraph H, and (b) those hyperedges containing xi that were produced as x1, . . . , xi\u22121 were eliminated. For the original hyperedges, all these are among the leaves below node(xi), and thus are contained in vertices(node(xi)). For a new hyperedge produced by eliminating one of the previous variables, say the variable y, the hyperedge it produced is contained in label(node(y)) by induction, which in turn is contained in vertices(node(y)). If y is in the subtree below node(x) we get that this hyperedge is contained in vertices(node(x)) since this is a superset of vertices(node(y)). Otherwise, node(y) lies in another part of the tree, and its label cannot contain x (no node outside the subtree below node(x) has x in its label). Thus the hyperedge created when it is eliminated also cannot contain xi.\nIn sum the hyperedge created when xi is eliminated is contained in vertices(node(xi)), since all of the hyperedges containing xi at this stage are in this set. Furthermore, all vertices x1, . . . , xi\u22121 are removed from this hyperedge, thus it contains only variables following xi in the ordering. Hence, by (1) above this hyperedge is contained in label (node(xi)). 2\nLemma 3 LetH be a hypergraph with elimination width at most w. Then H has a tree-decomposition of tree width at most w.\nProof: (Proof of Lemma 3) Let \u03c0 = x1, . . . xn be an elimination ordering for H. Then we will construct a tree decomposition for H using \u03c0 as follows. Initially, we have |E| trees, each of size 1, one corresponding to each edge e \u2208 E. We first merge the trees containing xn into a bigger tree, Tn, leaving us with a new, smaller set of trees. Then we merge the trees containing xn\u22121 into a bigger tree, Tn\u22121. We continue in this way until we have formed a single tree, T . Now fill in the labels for all intermediate vertices of T so that the tree is a tree-decomposition. That is, if m and n are two leaves of T and they both contain some vertex v, then every node along the path from m to n must also contain v in its label. It is not too hard to see that for each xi, the tree Ti (created when merging the trees containing xi) has the property that the label of its root (which connects it with the rest of T ) is contained in ei \u222a xi, where ei is the hyperedge created when xi is eliminated. Basically, all nodes with xj , j > i, are already contained in Ti so xi does not need to label Ti\u2019s root. Furthermore, if xj j < i is contained in Ti\u2019s root label, then xj must have been in some original hyperedge with a variable xk k \u2265 i: thus xj would have appeared in the hyperedge ei generated when xi was eliminated.\nHence the tree width of the final tree T can be no larger than the induced width of \u03c0. 2\nA.2 Complexity Results for Caching Versions of DPLL\nFor the proof of theorems 1 and 2 we will need some common notation and definitions. Let f be k-CNF formula with n variables and m clauses, let H be the underlying hypergraph associated with f with branch width w. By the results of Darwiche (2001), there is a branch decomposition of H of depth O(logm) and width O(w). Also by the results of Robertson and Seymour (1995), it is possible to find a branch decomposition, Tbd, such that Tbd has branch width O(w) and depth O(logm), in time nO(1)2O(w). Thus our main goal for each of the three theorems will be to prove the stated time and space bounds for our DPLL-based procedures, when they are run on a static ordering that is easily obtainable from Tbd.\nRecall that the leaves of Tbd are in one-to-one correspondence with the clauses of f . We will number the vertices of Tbd according to a depth-first preorder traversal of Tbd. For a vertex numbered i, let fi denote the subformula of f consisting of the conjunction of all clauses corresponding to the leaves of the tree rooted at i. Let Vars(fi) be the set of variables in the (sub)formula fi. Recall that in a branch decomposition the label of each vertex i, label (i), is the set of variables in the intersection of Vars(fi) and Vars(f\u2212fi). Each node i in Tbd partitions the clauses of f into three sets of clauses: fi, fLi , and f R i , where f L i is the conjunction of clauses at the leaves of Tbd to the left of fi, and fRi is the conjunction of clauses at the leaves to the right of fi.\nAll of our DPLL caching algorithms achieve the stated run time bounds by querying the variables in a specific, static variable ordering. That is, down any branch of the DPLL decision tree, DT , the same variables are instantiated in the same order. (In contrast a dynamic variable ordering allows DPLL to decide which variable to query next based on the assignments that have been made before. Thus different branches can query the variables in a different order.). The variable ordering used in DT is determined by the depth-first pre-ordering of the vertices in the branch decomposition Tbd and by the labeling of these vertices. Let (i, 1), . . . , (i, ji) denote the variables in label(i) that do not appear in the label of an earlier vertex of Tbd. Note that since the width of Tbd is w, ji \u2264 w for all i. Let 1, . . . , z be the sequence of vertex numbers of Tbd. Then our DPLL algorithm will query the variables underlying f in the following static order: \u03c0 = \u3008(i1, 1), (i1, 2), . . . , (i1, j1), (i2, 1), . . . , (i2, j2), . . . , (is, 1), . . . , (is, js)\u3009 i1 < i2 < . . . < is \u2264 z, and j1, . . . , js \u2264 w.\nNote that for some vertices i of Tbd, nothing will be queried since all of the variables in its label may have occurred in the labels of earlier vertices. Our notation allows for these vertices to be skipped. The underlying complete decision tree, DT , created by our DPLL algorithms on input f is thus a tree with j1 + j2 + . . . + js = n levels. The levels are grouped into s layers, with the ith layer consisting of ji levels. Note that there are 2l nodes at level l in DT , and we will identify a particular node at level l by (l, \u03c1) where \u03c1 is a particular assignment to the first l variables in the ordering, or by ((q, r), \u03c1), where (q, r) is the lth pair in the ordering \u03c0, and \u03c1 is as before.\nThe DPLL algorithms carry out a depth-first traversal of DT , keeping formulas in the cache that have already been solved along the way. (For #DPLL-SimpleCache, the formulas stored in the cache are of the form f |\u03c1, and for #DPLL-Cache and #DPLL-Space, the formulas stored are various components of ToComponents(f |\u03c1).) If the algorithm ever hits a node where the formula to be computed has already been solved, it can avoid that computation, and thus it does not do a complete depth-first search of DT but rather it does a depth-first search of a pruned version of DT . For our theorems, we want to get an upper bound on the size of the pruned tree actually searched by the algorithm.\nTheorem 1 For solving #SAT with n variables, there is an execution of #DPLL-SimpleCache that runs in time bounded by 2O(w logn) where w is the underlying branch width of the instance. Furthermore, the algorithm can be made deterministic with the same time guarantees.\nProof: We want to show that the size of the subtree of DT searched by #DPLL-SimpleCache is at most 2O(w logn). When backtracking from a particular node (l, \u03c1) = ((q, r), \u03c1) at level l in DT , the formula put in the cache, if it is not already known, is of the form f |\u03c1. (Recall \u03c1 is a setting to the first l variables.) However, we will see that although there are 2l different ways to set \u03c1, the number of distinct formulas of this form is actually much smaller than 2l. Consider a partial assignment, \u03c1, where we have set all variables up to and including (q, r), for some q \u2264 is and some r \u2264 jq. The number of variables set by \u03c1 (the length of \u03c1) is j1 + j2 + . . . + jq\u22121 + r.\nLet \u03c1\u2212 denote the partial assignment that is consistent with \u03c1 where only the variables in \u03c1 that came from the labels of the vertices on the path from the root of Tbd up to and including vertex q are set. The idea is that \u03c1\u2212 is a reduction of \u03c1, where \u03c1\u2212 has removed the assignments of \u03c1 that are irrelevant to fq and fRq .\nConsider what happens when the DPLL algorithm reaches a particular node ((q, r), \u03c1) at level l of DT . At that point the algorithm is solving the subproblem f |\u03c1, and thus, once we backtrack to this node, f |\u03c1 = fLq |\u03c1 \u2227 fq|\u03c1 \u2227 f R q |\u03c1 is placed in the cache, if it is not already known. Note that all variables in the subformula fLq are set by \u03c1, and thus either f L q |\u03c1 = 0, in which case nothing new is put in the cache, or fLq |\u03c1 = 1 in which case f |\u03c1 = fq|\u03c1 \u2227 f R q |\u03c1 = fq|\u03c1\u2212 \u2227 f R q |\u03c1\u2212 is put in the cache. Thus, the set of distinct subformulas placed in the cache at level l = (q, r) is at most the set of all subformulas of the form fq|\u03c1\u2212 \u2227 f R q |\u03c1\u2212 , where \u03c1\n\u2212 is a setting to all variables in the labels from the root to vertex q, plus the variables (q, 1), ..., (q, r). There are at most d \u00b7 w such variables, where q has depth d in Tbd (each label has at most w variables since this is the width of Tbd). Hence the total number of such \u03c1\u2212\u2019s is at most 2(w\u00b7d). This implies that the number of subtrees in DT at level l + 1 that are actually traversed by #DPLL-SimpleCache is at most 2 \u00b7 2w\u00b7d = 2O(w\u00b7d), where d is the depth of node q in Tbd. Let t be the number of nodes in DT that are actually traversed by #DPLL-SimpleCache. Then, t is at most n2O(w\u00b7logn), since t is the sum of the number of nodes visited at every level of DT and for each node q in Tbd d \u2208 O(logm) = O(log n).\nAccounting for the time to search the cache, the overall runtime of #DPLL-SimpleCache is at most t2, where again t is the number of nodes in DT that are traversed by the algorithm. Thus, #DPLL-SimpleCache runs in time (n2O(w\u00b7logn))2 = 2O(w\u00b7logn). 2\nTheorem 2 For solving #SAT on n variables, there exists an execution of #DPLL-Cache that runs in time bounded by nO(1)2O(w) where w is the underlying branch width of the instance. Furthermore, the algorithm can be made deterministic with the same time guarantees.\nProof: We prove the theorem by placing a bound on the number of times #DPLL-Cache can branch on any variable xl. Using the notation specified above, xl corresponds to some pair (q, r) in the ordering \u03c0 used by #DPLL-Cache. That is, xl is the r\u2019th new variable in the label of vertex q of the branch decomposition Tbd.\nWhen #DPLL-Cache utilizes the static ordering \u03c0, it branches on, or queries, the variables according to that order, always reducing the component containing the variable xi that is currently due to be queried. However, since previously cached components are always removed (by RemoveCachedComponents in the algorithm), it can be that when it is variable xi\u2019s turn to be queried, there is no component among the active components that contains xi. In this case, #DPLLCache simply moves on to the next variable in the ordering, continuing to advance until it finds the first variable that does appear in some active component. It will then branch on that variable reducing the component it appears in, leaving the other components unaltered.\nThis implies that at any time when #DPLL-Cache selects xl as the variable to next branch on it must be the case that (1) xl appears in an active component. In particular the value of this component is not already in the cache. And (2) no variable prior to xl in the ordering \u03c0 appears in an active component. All of these variables have either been assigned a particular value by previous recursive invocations, or the component they appeared in has been removed because its value was already in the cache.\nIn the branch decomposition Tbd let p be q\u2019s parent (q must have a parent since the root has an empty label). We claim that whenever #DPLL-Cache selects xl as the next variable to branch on, the active component containing xl must be a component in the reduction of fp whose form is determined solely by the settings of the variables in p and the r variables of q that have already been set. If this is the case, then there can be at most 2(w+r) = 2O(w) different components that xl can appear in, and hence #DPLL-Cache can branch on xl at most 2O(w) times as each time one more of these components gets stored in the cache.\nNow we prove the claim. The label of q consists of variables appearing in p\u2019s label and variables appearing in the label of q\u2019s sibling. Since all of the variables in label(p) have been set, q and its sibling must now have an identical set of unqueried variables in their labels. Hence, q must be the left child of p as by the time the right child is visited in the ordering, xl will have already been queried. Thus, at the time xl is queried, fp will have been affected only by the current setting of label(p) (as these are the only variables it shares with the rest of the formula) and the first r queried variables from label (q). That is, fp can be in at most 2(w+r) different configurations, and thus the component containing xl can also be in at most this many different configurations.\nThus with n variables we obtain a bound on the number of branches in the decision tree explored by #DPLL-Cache of n2O(w). As in the proof of the previous theorem, the overall runtime is at most quadratic in the number of branches traversed, to give the claimed bound of nO(1)2O(w). 2\nTheorem 3 For solving #SAT on n variables, there is an execution of #DPLL-Space that uses only space linear in the instance size and runs in time bounded by 2O(w logn) where w is the underlying branch width of the instance. Furthermore, the algorithm can be made deterministic with the same time and space guarantees.\nProof: For this proof, it will be more natural to work with a tree decomposition rather than a branch decomposition.\nLet f be a k-CNF formula with n variables and m clauses and let H be the underlying hypergraph associated with f . We begin with a tree decomposition Ttd of depth O(logm) and width O(w) (computable in time nO(1)2O(w)). We can assume without loss of generality that the leaves of Ttd are in one-to-one correspondence with the clauses of f . Each node i in Ttd partitions f into three disjoint sets of clauses: fi, the conjunction of clauses at the leaves of the subtree of Ttd rooted at i, fLi , the conjunction of clauses of the leaves of Ttd to the left of fi, and f R i , the conjunction of clauses of the leaves of Ttd to the right of fi. #DPLL-Space will query the variables associated with the labels of Ttd according to the depth-first preorder traversal. Let the variables in label (i) not appearing in an earlier label on the path from the root to node i be denoted by S(i) = (i, 1), . . . , (i, ji). If i is a non-leaf node with j and k being its left and right children, then the variables in S(i) are exactly the variables that occur in both fj and fk but that do not occur outside of fi. If we let c be the total number of nodes in Ttd, then #DPLL-Space will query the variables underlying f in the following static order: S(1), S(2), . . . , S(c), where some S(i) may be empty. The underlying decision tree, DT , created by #DPLL-Space is a complete tree with n levels. As before we will identify a particular node s at level l of DT by s = (l, \u03c1) where \u03c1 is a particular assignment to the first l variables in the ordering, or by s = ((q, r), \u03c1) (the rth variable in S(q)).\n#DPLL-Space carries out a depth-first traversal of DT , storing the components of formulas in the cache as they are solved. However, now components of formulas are also popped from the cache so that the total space ever utilized is linear. If the algorithm hits a node where all of the components of the formula to be computed are known, it can avoid traversing the subtree rooted at that node. Thus it searches a pruned version of DT .\nDuring the (pruned) depth-first traversal of DT , each edge that is traversed is traversed twice, once in each direction. At a given time t in the traversal, let E = E1 \u222a E2 be the set of edges that have been traversed, where E1 are the edges that have only been traversed in the forward direction, and E2 are the edges that have been traversed in both directions. The edges in E1 constitute a partial path p starting at the root of DT . Each edge in p is labeled by either 0 or 1. Let p1, . . . , pk be the set of all subpaths of p (beginning at the root) that end in a 1-edge. Let \u03c11, . . . , \u03c1k be subrestrictions corresponding to p1, . . . , pk except that the last variable that was originally assigned a 1 is now assigned a 0. For example, if p is (x1 = 0, x3 = 1, x4 = 0, x5 = 1, x6 = 0, x2 = 0), then \u03c11 = (x1 = 0, x3 = 0), and \u03c12 = (x1 = 0, x3 = 1, x4 = 0, x5 = 0). Then the information that is in the cache at time t contains ToComponents(f |\u03c1i), i \u2264 k.\nFor a node q of Ttd and corresponding subformula fq, the context of fq is a set of variables defined as follows. Let (q1, . . . , qd) denote the vertices in Ttd on the path from the root to q (excluding q itself). Then the context of fq is the set Context(fq) = S(q1) \u222a S(q2) \u222a . . . \u222a S(qd). Intuitively, the context of fq is the set of all variables that are queried at nodes that lie along the path to q. Note that when we reach level l = (q, 1) in DT , where the first variable of S(q) is queried, we have already queried many variables, including all the variables in Context(fq). Thus the set of all variables queried up to level l = (q, 1) can be partitioned into two groups relative to fq: the\nirrelevant variables, and the set Context(fq) of relevant variables. We claim that at an arbitrary level l = (q, r) in DT , the only nodes at level l that are actually traversed are those nodes ((q, r), \u03c1) where all irrelevant variables in \u03c1 (with respect to fq) are set to 0. The total number of such nodes at level l = (q, r) is at most 2|Context(fq)|+r which is at most 2w logn. Since this will be true for all levels, the total number of nodes in DT that are traversed is bounded by n2w logn. Thus, all that remains is to prove our claim.\nConsider some node s = ((q, r), \u03b1) in DT . That is, \u03b1 = \u03b11\u03b12 . . . \u03b1q\u22121b1 . . . br\u22121, where for each i, \u03b1i is an assignment to the variables in S(i), and b1 . . . br\u22121 is an assignment to the first r\u22121 variables in S(q). Let the context of fq be S(q1) \u222a . . . \u222a S(qd), d \u2264 log n. Now suppose that \u03b1 assigns a 1 to some non-context (irrelevant) variable, and say the first such assignment occurs at \u03b1ut , the tth variable in \u03b1u, u \u2264 q \u2212 1. We want to show that the algorithm never traverses s.\nAssociated with \u03b1 is a partial path in DT ; we will also call this partial path \u03b1. Consider the subpath/subassignment p of \u03b1 up to and including \u03b1ut = 1. If \u03b1 is traversed, then we start by traversing p. Since the last bit of p is 1 (i.e., \u03b1ut = 1) when we get to this point, we have stored in the cache ToComponents(f |\u03c1) where \u03c1 is exactly like p except that the last bit, \u03b1ut , is zero. Let j be the first node in q1, q2, . . . qd with the property that the set of variables S(j) are not queried in p. (On the path to q in Ttd, j is the first node along this path such that the variables in S(j) are not queried in p.) Then ToComponents(f |\u03c1) consists of three parts: (a) ToComponents(fLj |\u03c1), (b) ToComponents(fj |\u03c1), and (c) ToComponents(fRj |\u03c1).\nNow consider the path p\u2032 that extends p on the way to s in DT , where p\u2032 is the shortest subpath of \u03b1 where all of the variables S(i) for i < j have been queried. The restriction corresponding to p\u2032 is a refinement of p where all variables in S(1)\u222aS(2)\u222a. . . S(j\u22121) are set. Since we have already set everything that occurs before j, we will only go beyond p\u2032 if some component of ToComponents(f |p\u2032) is not already in the cache. ToComponents(f |p\u2032) consists of three parts: (a) ToComponents(fLj |p\u2032), (b) ToComponents(fj |p\u2032), and (c) ToComponents(fRj |p\u2032). Because we have set everything that occurs before j, all formulas in (a) will be known. Since p\u2032 and \u03c1 agree on all variables that are relevant to fj , ToComponents(fj|p\u2032) = ToComponents(fj|\u03c1) and hence these formulas in (b) in the cache. Similarly all formulas in (c) are in the cache since ToComponents(fRj |p\u2032) = ToComponents(f R j |\u03c1). Thus all components of ToComponents(f |p\u2032) are in the cache, and hence we have shown that we never traverse beyond p\u2032 and hence never traverse s. Therefore the total number of nodes traversed at any level l = (q, r) is at most 2wd, where d is the depth of q in Ttd, as desired. This yields an overall runtime of 2O(w logn).\nIt is left to argue that the space used is linear in the instance size. The total number of formulas that are ever stored in the cache simultaneously is linear in the depth of the tree decomposition, which is O(logm). Since we store each restricted formula f |\u03c1 by storing the associated restriction \u03c1, the total space ever used is O(n logm), which is linear in the input size. 2\nA.3 Comparing Algorithms for BAYES and #SAT\nBefore proving the next theorem, we first discuss in more detail the structure of the search space explored by various versions of RC, AND/OR search and DDP. All of these algorithms operate in the same way. They instantiate variables and when the problem decomposes into independent components they solve these components in separate recursions. Hence, when solving any CNF formula f they all generate some AND/OR search tree (Dechter & Mateescu, 2007).\nThe AND/OR search tree AO generated when one of the above algorithms solves the #SAT instance f (a CNF formula), is a rooted tree. Each node n of AO is labeled by a formula n.f and the subtree below n is generated when solving n.f . The root of A0 is labeled by the original formula f . There are four different types of nodes in AO:\nQuery nodes. Each query node q has an associated variable q.var and two children corresponding to the two possible instantiations of q.var . That is, its children are labeled by the formulas q.f |q.var=0 and q.f |q.var=1. A query node q is generated by the search algorithm whenever it chooses to instantiate q.var and then executes recursive calls on the two resultant reduced formulas.\nAND nodes. Each AND node, a, has a query node as its parent, and has one or more children all of which are query nodes. An AND node is generated by the search algorithm when it decomposes the current formula into two or more independent components following the instantiation of the parent query node\u2019s variable. Each of these components will then be solved in one of the subtrees rooted by the AND node\u2019s children. If a.f splits into the components fi, i = 1, . . . , k, then a.f = \u2227\ni fi, and the i\u2019th child of a is labeled by fi. Note that the fi share no variables. Hence, the set of query node variables that appear in the subtree below the i-th child of a are disjoint from the set of query node variables appearing below the j-th child of a for all j 6= i.\nFailure nodes. These are leaf nodes of the tree that are labeled with a formula containing the empty clause. If caching is being used, failure nodes might also be labeled by a formula in the cache that has already been shown to be unsatisfiable.\nSatisfying nodes. These are leaf nodes of the tree that are labeled with a formula containing no clauses. If caching is being used, satisfying nodes might also be labeled by a satisfiable formula in the cache whose model count is already know.\nFigure 6 shows an example AND/OR search tree. Each node n of the AO also has a value, n.value, computed by the algorithm that generates it. Here we only need to distinguish between zero values n.value = 0, and non-zero values denoted by n.value = 1. Every satisfying node has value 1, and every failure node has value 0. A query node has value 1 if and only if at least one of its children has value 1, and an AND node has value 1 if and only if all of its children have value 1. For example, in Figure 6 AND node D has value 0, while query node 2 has value 1. Note that all of the children of an AND node in AO must have value 1 except possibly the right most child. The algorithms generating AO all terminate the search below an AND node as soon as they discover a value 0 child\u2014this implies that the AND node has value 0. It can be seen that n.value = 0 if n.f is unsatisfiable and n.value = 1 if n.f is satisfiable.\nGiven any node n of AO, let AO(n) be the AND/OR subtree of AO rooted by n. Each satisfying assignment \u03c1 of n\u2019s formula n.f defines a solution subtree S(n) of AO(n). In particular, S(n) is a connected subtree of AO(n) rooted by n such that (1) if q is a query node in S(n) then S(n) also contains the child of q corresponding to the assignment made by \u03c1 (i.e., if \u03c1[q.var ] is the value assigned to q.var in \u03c1, then S(n) will contain the child labeled by the formula q.f |q.var=\u03c1[q.var]), (2) if a is an AND node in S(n) then S(n) contains all children of a, and (3) S contains no failure nodes. For example, a solution subtree of the AND/OR tree shown in Figure 6 (i.e., a solution subtree of the root node) is formed by the leaf nodes b, c, f, and l; the query nodes 1, 2, 3, 4, 5, 6,\n7, and 8; and the AND nodes A, and B. In particular, the left value of query nodes 1, 2, 3, 5, 6, 7 and 8, along with the right value of query node 4 satisfy all clauses of the formula 1.f . A solution subtree of AO(n) exists if and only if n.value = 1.\nFinally, in an AND/OR search tree we say that a query node whose parent is an AND node is a component root. We also classify the root node as a component root. In Figure 6 query nodes 1 (the root node), 3, 6, 8, 4, 5, 9, 10, 12, 13, 17, and 19 are component roots.\nTheorem 5 #DPLL-Cache polynomially simulates RC-Cache, RC-Cache+, AND/OR-Cache, AND/OR-Cache+, and VE. #DPLL-Space polynomially simulates RC-Space, AND/OR-Space and DDP.\nProof: Since RC-Cache polynomially simulates VE we can ignore VE in our proof: showing that #DPLL-Cache polynomially simulates RC-Cache also shows that it polynomially simulates VE. Also we assume in our proof that if any of these algorithms use unit propagation, then so does #DPLL-Cache/Space. As explained in Section 3.1, #DPLL-Cache/Space without unit propagation can polynomially simulate versions of #DPLL-Cache/Space using unit propagation.\nEach of the stated algorithms will generate an AND/OR search tree when solving a CNF formula f . To prove the theorem we first show how any AND/OR search tree solving f can be converted into a partial DPLL decision tree, DT , that is no bigger. Then we show that our DPLL algorithms can solve f using DT to guide its variable ordering. Thus, we obtain the result that the minimal runtime for any of the stated algorithms, which must result in the generation of some AND/OR search tree AOmin, can also be achieved by our DPLL algorithms. In particular, when run on the partial decision tree constructed from AOmin, our DPLL algorithms will achieve a polynomially similar runtime. (This suffices to prove the theorem, as we need only show the existence of an execution of our DPLL algorithms achieving this run time.)\nTo make the distinction between the AND/OR search tree and the constructed partial decision tree clear, we will use the suffixes ao and dt to indicate elements of the AND/OR tree and decision tree respectively.\nDPLL decision trees contain only query variables, satisfying nodes, and failure nodes, where satisfying and failure nodes are both leaf nodes. We construct a partial decision tree DT from an AND/OR tree AO by expanding the left most solution subtree S(nao) below every node nao \u2208 AO with nao.value = 1 into a linear sequence of query variables in DT using a depth-first ordering of the query variables in S(nao). For nodes nao \u2208 AO with nao.value = 0 the same expansion is attempted, but in this case it will result in a sequence of query nodes that terminate at failure nodes.\nEvery node qdt in DT has a pointer, dt\u2192ao(qdt) to a node qao in AO, at the end of the construction these pointers establish a map between the nodes in DT and the nodes in AO. Initially, the root of DT has a pointer to the root of AO. Then, for any node qdt \u2208 DT :\n1. If dt\u2192ao(qdt) is a query node qao in AO, then make qdt a query node and create a left and right child, ldt and rdt, for qdt in DT . We make qdt query the same variable as qao (i.e., qdt.var = qao.var ), and set its children to point to the children of qao (i.e., dt\u2192ao(ldt) and dt\u2192ao(rdt) are set to the left and right children of qao in AO).\n2. If dt\u2192ao(qdt) is an AND node aao in AO, then we reset dt\u2192ao(qdt) to be the left most child of aao in AO. We then apply the first rule above, and continue.\n3. If dt\u2192ao(qdt) is a failure node in AO then we set qdt to be a failure node. In this case qdt has no children.\n4. If dt\u2192ao(qdt) is a satisfying node in AO then we examine the path \u03c1ao in AO from the root to dt\u2192ao(qdt). Let rao be the last component root on \u03c1ao that has a right sibling.\n(a) If such an rao exists, and no node on the path from rao to dt\u2192ao(qdt) in AO is the right child of a query node whose left child has value 1, then we reset dt\u2192ao(qdt) to be the leftmost right sibling of rao. This node is also a component root, and hence it is a query node in AO. We then apply the first rule above, and continue.\n(b) Otherwise (either rao does not exist or there is some node on the path from rao that is the right child of a query node whose left child has value 1), we make qdt a satisfying node. In this case qdt has no children.\nRule 4 of the construction is where we convert the leftmost solution subtree below each node nao in AO into a sequence of query nodes in DT by performing a depth-first traversal of this solution subtree. In particular, in this solution subtree the leftmost right sibling of the deepest component\nroot is the depth-first successor of the satisfying leaf node. The condition that no node on route to that sibling is the right child of a query node whose left child has value 1 ensures that we only perform a depth-first traversal along the leftmost solution subtree and not along subsequent solution subtrees. Figure 7 shows the partial decision tree that would be constructed from the AND/OR search tree of Figure 6.\nIn the diagram, satisfying nodes whose pointers are reset to the next component root using rule 4a, are numbered with the corresponding query node in the AND/OR tree followed by the leaf label of the corresponding satisfying node. For example, node 5b in the Figure 7 represents satisfying child b of node 4 in Figure 6 that has been redirected to its depth-first successor node 5 (the leftmost right sibling of the deepest component root 4).\nAs another example, in the AND/OR tree, the right child of node 6 is the AND node C. Hence, in the decision tree, the right child of the corresponding query node 6, becomes query node 9 which is the leftmost child of node C (rule 2). Furthermore, when we reach satisfying node j in the AND/OR tree, we can proceed no further and hence the left child of query node 10 in the decision tree becomes a terminal satisfying node (rule 3). In particular, although the path from the root to node 10 in the AND/OR tree contains a component root with a right sibling, namely node 6, this path also contains the node C that is the right child of a query node (node 6) whose left child (node 7) has value 1.\nThere are two things to note. First, at any node ndt of DT all variables instantiated on the path \u03c1ao in A0 from the root to dt\u2192ao(n) have been instantiated to the same values on the path \u03c1dt in DT from the root to ndt. Since Rules 3 and 4b terminate paths, all nodes on \u03c1dt are inserted only by Rules 1, 2, and 4b. Rules 1 and 2 only insert nodes on \u03c1dt whose parents are already on \u03c1dt, and Rule 1 ensures that the values assigned are the same as those in AO. Finally, Rule 4a only inserts a node adt on \u03c1dt if one of dt\u2192ao(adt)\u2019s siblings is already on \u03c1dt, and hence that sibling\u2019s (and a\u2019s) parent must already be on \u03c1dt.\nSecond, no variable is queried twice along any path of DT . That is, no node ndt in DT has an ancestor n\u2032dt with ndt.var = n \u2032 dt.var . Again any path \u03c1dt in DT is grown only by applications of Rules 1, 2, and 4a. Since no path in AO queries the same variable twice, Rules 1 and 2 must preserve this condition. Similarly Rule 4a moves to a new component root aao, and the set of query variables at and below aao in AO is disjoint with the set of query variables already appearing in \u03c1dt.\nUsing the above, from the AND/OR search tree AO generated by any of the algorithms RCSpace, AND/OR-Space or DDP when solving the formula f , we can construct a corresponding partial decision tree DT . Now we show that #DPLL-Space can solve f by exploring a search tree that is no larger than DT . Note that DT is itself no larger than AO, hence this will show that #DPLL-Space can solve f with a polynomially similar run time, proving that it can polynomially simulate RC-Space, AND/OR-Space and DDP. (Note that the run time of all of these algorithms is polynomially related to the size of the search trees they explore.)\nWe execute #DPLL-Space using the variable ordering specified in DT . That is, starting at the root rdt of DT , #DPLL-Space will always query the variable of the current node of DT , ndt.var , and then descend to ndt\u2019s left child. When it backtracks to ndt it will then descend to the right child. Hence, we only need to show that #DPLL-Space must backtrack if it reaches a leaf of DT . That is, it explores a search tree that is no larger than DT .\nFirst, if #DPLL-Space reaches a failure node of DT it must detect an empty clause and backtrack. By Rule 3 of the construction any failure node fdt of DT must correspond to a failure node dt\u2192ao(fdt) in AO. Since all variables instantiated on the path in AO from the root to dt\u2192ao(fdt) are instantiated to the same values on the path in DT from the root to fdt, we see that if an empty clause was detected in AO at dt\u2192ao(fdt) then #DPLL-Space must also detect an empty clause at fdt. (Note that if the algorithm that generated AO used unit propagation, then we assume that #DPLL-Space does as well).\nSecond, if #DPLL-Space reaches a satisfying node sdt of DT it must detect that all of its current set of components are solved and backtrack (line 4 of Algorithm 8). Let \u03c1dt be the path in DT from the root to sdt, \u03c1ao be the path in AO from dt\u2192ao(sdt) to the root, and crdt be a node on \u03c1dt such that dt\u2192ao(crdt) is a component root in AO (we say that crdt is a component root on \u03c1dt). We claim that (a) if lao is a left sibling of dt\u2192ao(crdt) in AO, then there exists a node ldt on \u03c1dt such that dt\u2192ao(ldt) = lao, and lao.f is satisfied by \u03c1dt; (b) if rao is a right sibling of dt\u2192ao(crdt) in AO then rao.f is in #DPLL-Space\u2019s cache.\nGiven claim (a) the only clauses of the original formula not yet satisfied by \u03c1dt are clauses from rao.f for those nodes rao in AO that are right siblings of some component root crdt on \u03c1dt (i.e., rao is a right sibling of component root dt\u2192ao(crdt) in AO). When #DPLL-Space arrived at crdt, prior to reaching sdt, all variables in AO on the path from the root to dt\u2192ao(crdt) have already been instantiated to the same values on \u03c1dt. Thus, if pao is dt\u2192ao(crdt)\u2019s parent in AO, #DPLLSpace would have recognized that rao.f was a separate component once it instantiated pao.var , and it would have added rao.f to its list of components (at line 8 or 11 of Algorithm 8). Note that,\nonce solved rao.f would not be removed from #DPLL-Space\u2019s cache until it backtracks to undo the instantiation of pao.var . (At which point the solution all of pao\u2019s children would be combined to yield a solution to pao.f ).\nFurthermore, following the variable ordering specified in DT , #DPLL-Space would not instantiate any of the variables in r.f along the path \u03c1dt. Hence, any component that is on #DPLL-Space\u2019s list of components when it reaches ns must be equal to rao.f for some right sibling rao of a component root on \u03c1dt, and by claim (b) will be removed by the call to RemoveCachedComponents(\u03a6) (line 6). This will leave #DPLL-Space with an empty list of components to solve, and hence it must backtrack at sdt.\nNow we prove the claims. For (a) we see that DT will always visit the children of an AND node in AO in a left to right order. That is, before inserting a component root crdt on its path, it must first visit all left siblings lao of dt\u2192ao(crdt). After inserting ldt on its path (with dt\u2192ao(ldt) = lao), it will instantiate ldt and then start to query the nodes under lao searching alternate instantiations to these variables until it is able to traverse a leftmost solution subtree of AO(lao). This traversal results in the insertion into the path of a solution to lao.f , after which DT inserts crdt on its path using Rule 4a.\nFor (b) we observe that sdt is a satisfying node in DT only through the application of Rule 4b. Hence there are two possible cases. First, it can be that none of the component roots on \u03c1dt have a right sibling. In this case every clause of the original formula is satisfied and #DPLL-Space must backtrack. For example, in Figure 7 this occurs at leaf nodes l and y.\nOtherwise, let crdt be a component root on \u03c1dt such that dt\u2192ao(crdt) has a right sibling in AO, and let ndt be the first node on \u03c1dt following crdt such that (i) ndt\u2019s successor on \u03c1dt is its right child, and (ii) dt\u2192ao(ndt) has a left child in AO with value 1. Such a node ndt must exist, else sdt would not have been a leaf node of DT by Rule 4a. When #DPLL-Space arrived at node crdt it would have rao.f on its list of components for all right siblings rao of dt\u2192ao(crdt). There might also be other unsolved components on this list. All of these components, however, must be equal to rao.f for some right sibling rao of a component root on \u03c1dt preceding crdt, and must have been placed on the list of components prior to #DPLL-Space reaching crdt. Then, when #DPLL-Space arrived at ndt it would have taken the left branch first. Thus it would have previously been invoked with all of these right sibling components on its component list.\nWhen #DPLL-Space is invoked with a list of components it either solves every component, placing them in its cache and keeping them there until it backtracks to the node where they were first placed on its list, or it discovers that one of these components is unsatisfiable. If one of the components is unsatisfiable, it will immediately backtrack to the point where that component was first placed on its list. In particular, all recursive calls where the list of components contains a known unsatisfiable component will return immediately since the call to InCache(\u03a6) will detect that the list of components has product equal to zero.\nHence, on taking the left branch at ndt, #DPLL-Space, will have on its list of components, components of the form rao.f for right siblings of component roots above ndt on \u03c1dt, and also lao.f where lao is the left child of dt\u2192ao(ndt) in AO. Since lao has value 1, lao.f is satisfiable, and either #DPLL-Space will solve all its components, placing their value in its cache, or it will discover that one of the components rao.f is unsatisfiable and will backtrack without visiting sdt. Therefore, if it does visit sdt it would have solved all components that could potentially be on its list of components, and these components would still be in is cache since they were placed on the list before arriving at sdt.\nThis shows that #DPLL-Space polynomially simulates RC-Space, AND/OR-Space and DDP. RC-Cache and AND/OR-Cache gain over RC-Space and AND/OR-Space by not having to solve some components more than once. That is, when they arrive at a node nao in their generated AND/OR tree AO, if nao.f has been solved before they can immediately backtrack.\n#DPLL-Cache gains the same efficiency over #DPLL-Space. In particular, it need never solve the same component more than once. Using caching to removing previously solved components from its list of components gives rise to the same savings that are realized by adding caching to AND/OR or RC. Formally, the same construction of a partial decision tree DT can be used. In AO we mark all nodes where search is terminated by a cache hit as a satisfying node (if the cached formula is satisfiable) or as a failure node (if the cached formula is unsatisfiable). Now, for example, AND nodes can have satisfying or failure nodes as children when those components have been solved before. Applying our construction to AO gives rise to a partial decision tree DT , and it can then be shown that #DPLL-Cache using DT to guide its variable choices will explore a search tree that is about the same size as DT . This proves that #DPLL-Cache polynomially simulates RC-Cache and AND/OR-Cache.\nThe only subtle point is that #DPLL-Cache might not solve a component at the same point in its search. In particular, if a component \u03c6 first appears on #DPLL-Cache\u2019s list of components with a previously added unsatisfiable component, #DPLL-Cache will backtrack without solving \u03c6. Following DT , #DPLL-Cache will only do enough work to find \u03c6\u2019s first solution, after which it will proceed to the other components on its list. During its search for \u03c6\u2019s first solution, it will cache all unsatisfiable reductions of \u03c6 found during this search. Thus, the next time it encounters \u03c6 it can follow the same variable ordering and not do any extra work: the cached unsatisfiable reductions will immediately prune all paths leading to failure and it can proceed directly to the first solution to \u03c6. If the other components on its list are all satisfiable, it will eventually backtrack to this first solution and then continue to solve \u03c6. Hence, although #DPLL-Cache might encounter \u03c6 many times before solving it, each such encounter, except for the first, require adding to its search tree only a number of nodes linear in the number of variables in \u03c6. The number of nodes added by the first encounter, where the \u03c6\u2019s first solution is found, and the encounter where it finally solves \u03c6, together equal the number of nodes required in AO to solve \u03c6. Hence, the \u201cencounters without solving\u201d do not increase the size of #DPLL-Cache\u2019s search tree by more than a polynomial.\nFinally, we note that the construction given accommodates the use of dynamic variable orderings where the order of variables varies from branch to branch in the AND/OR search tree. (Varying the value assigned along the left and right branch of each query variable is also accommodated). That is, the proof also shows that #DPLL-Cache polynomially simulates AND/OR-Cache+ and RC-Cache+. 2\nTheorem 6 None of RC-Space, RC-Cache, AND/OR-Cache, AND/OR-Space or VE can polynomially simulate #DPLL-Cache, #DPLL-Space, or #DPLL.\nTo prove this theorem we first observe that from a result of Johannsen (Johannsen, 2001), #DPLL-Cache, #DPLL-Space, and #DPLL can all solve the negation of the propositional stringof-pearls principle (Bonet, Esteban, Galesi, & Johannsen, 1998) in time nO(logn), when run with a dynamic variable ordering. Then we prove (in Theorem 7) that all of the other algorithms require time exponential in n on this problem. Hence, none of these algorithms can polynomially simulate #DPLL (or the stronger #DPLL-Space or #DPLL-Cache).\nThe string-of-pearls principle, introduced in a different form by Clote and Setzer (1998) and explicitly by Bonet et al. (1998) is as follows. From a bag of m pearls, which are colored red and blue, n pearls are chosen and placed on a string. The string-of-pearls principle says that if the first pearl in the string is red and the last one is blue, then there must be a red-blue or blue-red pair of pearls side-by-side somewhere on the string. The negation of the principle, Sm,n, is expressed with variables pi,j and pj for i \u2208 [n] and j \u2208 [m] where pi,j represents whether pearl j is mapped to vertex i on the string, and pj represents whether pearl j is colored blue (pj = 0) or red (pj = 1). The clauses of SPm,n are as follows.\n(1) Each hole gets at least one pearl: \u2228mj=1pi,j , i \u2208 [n].\n(2) Each hole gets at most one pearl: (\u00acpi,j \u2228 \u00acpi,j\u2032), i \u2208 [n] j \u2208 [m] ,j\u2032 \u2208 [m], j 6= j\u2032.\n(3) A pearl goes to at most one hole: (\u00acpi,j \u2228 \u00acpi\u2032,j), i \u2208 [n], i\u2032 \u2208 [n], i 6= i\u2032, j \u2208 [m].\n(4) The leftmost hole gets assigned a red pearl and the rightmost hole gets assigned a blue pearl: (\u00acp1,j \u2228 pj) and (\u00acpn,j \u2228 \u00acpj), j \u2208 [m].\n(5) Any two adjacent holes get assigned pearls of the same color: (\u00acpi,j \u2228\u00acpi+1,j\u2032 \u2228\u00acpj \u2228 pj\u2032), 1 \u2264 i < n, j \u2208 [m], j\u2032 \u2208 [m], j 6= j\u2032, and (\u00acpi,j \u2228\u00acpi+1,j\u2032 \u2228 pj \u2228\u00acpj\u2032), 1 \u2264 i < n, j \u2208 [m], j\u2032 \u2208 [m], j 6= j\u2032.\nJohannsen (Johannsen, 2001) shows that SPn,n has quasipolynomial size tree resolution proofs. It follows that #DPLL, #DPLL-Space and #DPLL-Cache can solve SPn,n in quasipolynomial time.\nLemma 4 (Johannsen, 2001) SPn,n can be solved in time nO(logn) by #DPLL, #DPLL-Space, and #DPLL-Cache.\nTheorem 7 Let \u01eb = 1/5. Any of the algorithms RC-Space, RC-Cache, AND/OR-Cache, AND/ORSpace, VE, or #DPLL-Cache using a static variable ordering, require time 2n \u01eb to solve SPn,n.\nProof: It can be seen from the proof of Theorem 5 that #DPLL-Cache using a static variable ordering can polynomially simulate all of the stated algorithms.\nHence, it suffices to prove that #DPLL-Cache under any static ordering requires time 2n \u01eb\nfor SPm,n, m = n. By a static ordering, we mean that the variables are queried according to this ordering as long as they are mentioned in the current formula. That is, we allow a variable to be skipped over if it is irrelevant to the formula currently under consideration. We will visualize SPn,n as a bipartite graph, with n vertices on the left, and n pearls on the right. There is a pearl variable pj corresponding to each of the n pearls, and an edge variable pi,j for every vertex-pearl pair. (Note that there are no variables corresponding to the vertices but we will still refer to them.)\nFix a particular total ordering of the underlying n2 + n variables, \u03b81, \u03b82, . . . , \u03b8l. For a pearl j, let fanint(j) equal the number of edge variables pk,j incident with pearl j that are one of the first t variables queried. Similarly, for a vertex i, let fanint(i) equal the number of edge variables pi,k incident with vertex i that are one of the first t variables queried. For a set of pearls S, let fanin t(S) equal the number of edge variables pk,j incident with some pearl j \u2208 S that are one of the first t variables queried. Similarly for a set of vertices S, fanin t(S) equals the number of edge variables pi,k incident with some vertex i \u2208 S that are one of the first t variables queried. Let edgest(j) and\nedgest(S) be defined similarly although now it is the set of such edges rather than the number of such edges. It should be clear from the context whether the domain objects are pearls or vertices.\nWe use a simple procedure, based on the particular ordering of the variables, for marking each pearl with either a C or with an F as follows. In this procedure, a pearl may at some point be marked with a C and then later overwritten with an F; however, once a pearl is marked with an F, it remains an F for the duration of the procedure. If a pearl j is marked with a C at some particular point in time, t, this means that at this point, the color of the pearl has already been queried, and fanint(j) is less than n\u03b4, \u03b4 = 2/5. If a pearl j is marked with an F at some particular point in time t, it means that at this point fanint(j) is at least n\n\u03b4. (The color of j may or may not have been queried.) If a pearl j is unmarked at time t, this means that its color has not yet been queried, and fanint(j) is less than n\u03b4.\nFor l from 1 to n2+n, we do the following. If the lth variable queried is a pearl variable (\u03b8l = pj for some j), and less than n\u03b4 edges pi,j incident to j have been queried so far, then mark pj with a C. Otherwise, if the lth variable queried is an edge variable (\u03b8l = pi,j) and fanin l(j) \u2265 n\n\u03b4, then mark pearl j with an F (if not already marked with an F). Otherwise, leave pearl j unmarked.\nEventually every pearl will become marked F. Consider the first time t\u2217 where we have either a lot of C\u2019s, or a lot of F\u2019s. More precisely, let t\u2217 be the first time where either there are exactly n\u01eb C\u2019s (and less than this many F\u2019s) or where there are exactly n\u01eb F\u2019s (and less than this many C\u2019s.) If exactly n\u01eb C\u2019s occurs first, then we will call this case (a). Extend t\u2217 to t\u2217a as follows. Let \u03b8t\u2217+1, . . . , \u03b8t\u2217+c be the largest segment of variables that are all pearl variables pj such that j is already marked with an F. Then t\u2217a = t\n\u2217 + c. Notice that the query immediately following \u03b8t\u2217a is either a pearl variable pj that is currently unmarked, or an edge variable. On the other hand, if exactly n\u01eb F\u2019s occurs first, then we will call this case (b). Again, extend t\u2217 to t\u2217b to ensure that the query immediately following \u03b8t\u2217\nb is either a pearl variable pj that is currently unmarked, or is an\nedge variable. The intuition is that in case (a) (a lot of C\u2019s), a lot of pearls are colored prematurely\u2013that is, before we know what position they are mapped to\u2013and hence a lot of queries must be asked. For case (b) (a lot of F\u2019s), a lot of edge variables are queried thus again a lot of queries will be asked. We now proceed to prove this formally.\nWe begin with some notation and definitions. Let f = SPn,n, and let Vars(f) denote the set of all variables underlying f . A restriction \u03c1 is a partial assignment of some of the variables underlying f to either 0 or to 1. If a variable x is unassigned by \u03c1, we denote this by \u03c1(x) = \u2217. Let T be the DPLL tree based on the variable ordering \u03b8. That is, T is a decision tree where variable \u03b8i is queried at level i of T . Recall that corresponding to each node v of T is a formula f |\u03c1 where \u03c1 is the restriction corresponding to the partial path from the root of T to v. The tree T is traversed by a depth-first search. For each vertex v with corresponding path p that is traversed, we check to see if f |p is already in the cache. If it is, then there is no need to traverse the subtree rooted below v. If it is not yet in the cache, then we traverse the left subtree of v, followed by the right subtree of v. After both subtrees have been traversed, we then pop back up to v, and store f |p in the cache. This induces an ordering on the vertices (and corresponding paths) of T that are traversed\u2014whenever we pop back up to a vertex v (and thus, we can store its value in the cache), we put v (p) at the end of the current order.\nLemma 5 Let f be SPn,n and let \u03c0 be a static ordering of the variables. Let \u03c1 be a partial restriction of the variables. Then the runtime of #DPLL-Cache on (f, \u03c1) is not less than the runtime of #DPLLCache on (f |\u03c1, \u03c0\u2032), where \u03c0\u2032 is the ordering of the unassigned variables consistent with \u03c0.\nLemma 6 For any restriction \u03c1, if f |\u03c1 6= 0 and \u03c1(pi,j) = \u2217, then pi,j occurs in f |\u03c1.\nProof: Consider the clause Ci = (pi,1 \u2228 . . . \u2228 pi,m) in f . Since pi,j is in this clause, if pi,j does not occur in f |\u03c1, then Ci|\u03c1 must equal 1. Thus there exists j\u2032 6= j such that \u03c1(pi,j\u2032) = 1. But then the clause (\u00acpi,j \u2228 \u00acpi,j\u2032)|\u03c1 = \u00acpi,j and thus pi,j does not disappear from f |\u03c1. 2\nCorollary 1 Let \u03b8 be a total ordering of Vars(f). Let \u03c1, \u03c1\u2032 be partial restrictions such that \u03c1 sets exactly \u03b81, . . . , \u03b8q and \u03c1\u2032 sets exactly \u03b81, . . . , \u03b8q\u2032 , q\u2032 < q. Suppose that there exists \u03b8k = pi,j such that \u03c1 sets \u03b8k but \u03c1\u2032(\u03b8k) = \u2217. Then either f |\u03c1 = 0 or f |\u03c1\u2032 = 0 or f |\u03c1 6= f |\u03c1\u2032 .\nCase (a). Let \u03b8 be a total ordering to Vars(f) such that case (a) holds. Let PC denote the set of exactly n\u01eb pearls that are marked C and let PF denote the set of less than n\u01eb pearls (disjoint from PC) that are marked F. Note that (the color of) all pearls in PC have been queried by time t\u2217a; the color of the pearls in PF may be queried by time t\u2217a, and the color of all pearls in P \u2212 P C \u2212 PF have not been queried by time t\u2217a. Note further that the total number of edges pi,j that have been queried is at most n\u01eb+\u03b4 + n1+\u01eb \u2264 2n1+\u01eb.\nWe will define a partial restriction, Ma, to all but 2n \u01eb\nof the variables in \u03b81, . . . , \u03b8t\u2217a as follows. For each j \u2208 PF , fix a one-to-one mapping from PF to [n] such that range(j) \u2208 edgest\u2217a(j) for each j. For each j \u2208 PC , for any variable pi,j queried in \u03b81, . . . \u03b8t\u2217a , set pi,j to 0. For any vertex i such that all variables pi,j have been queried in \u03b81, . . . , \u03b8t\u2217a , map i to exactly one pearl j such that pj \u2208 P \u2212 P\nC \u2212 PF . There are at most 2n\u01eb such i. (This can be arbitrary as long as it is consistent with the one-to-one mapping already defined on PF .) For all remaining pj \u2208 P \u2212 PC \u2212 PF that have not yet been mapped to, set all queried variables pi,j to 0. For all pearls pj in PF that have been queried in \u03b81, . . . , \u03b8t\u2217a , assign a fixed color to each such pearl (all Red or all Blue) so that the smallest Red/Blue gap is as large as possible. Note that the gap will be of size at least n1\u2212\u01eb. Ma sets all variables in \u03b81, . . . \u03b8t\u2217a except for the variables pj , j \u2208 P\nC . Since there are n\u01eb such variables, the number of restrictions \u03c1 to \u03b81, . . . , \u03b8t\u2217a consistent with Ma is exactly 2\nn\u01eb . Let S denote this set of restrictions.\nLet f \u2032 = f |Ma and let \u03b8 \u2032 be be the ordering on the unassigned variables consistent with \u03b8. (The set of unassigned variables is: pj , for j \u2208 PC , plus all variables in \u03b8k, k > t\u2217a.) Let T \u2032 be the DPLL tree corresponding to \u03b8\u2032 for solving f \u2032. By Lemma 5, it suffices to show that #DPLL-Cache when run on inputs f \u2032 and T \u2032, takes time at least 2n \u01eb .\nNote that the first n\u01eb variables queried in T \u2032 are the pearl variables in PC , and thus the set of all 2n \u01eb\npaths of height exactly n\u01eb in T \u2032 correspond to the set S of all possible settings to these variables. We want to show that for each vertex v of height n\u01eb in T \u2032 (corresponding to each of the 2n \u01eb\nsettings of all variables in PC), that v must be traversed by #DPLL-Cache, and thus the runtime is at least 2n \u01eb\n. Fix such a vertex v, and corresponding path \u03c1 \u2208 S. If v is not traversed, then there is some \u03c1\u2032 \u2286 \u03c1 and some \u03c3 such that \u03c3 occurs before \u03c1\u2032 in the ordering, and such that f \u2032|\u03c3 = f \u2032|\u03c1\u2032 . We want to show that this cannot happen. There are several cases to consider.\n1a. Suppose that |\u03c3| \u2264 n\u01eb and \u03c3 6= \u03c1\u2032. Then both \u03c1\u2032 and \u03c3 are partial assignments to some of the variables in PC that are inconsistent with one another. It is easy to check that in this case, f \u2032|\u03c1\u2032 6= f \u2032|\u03c3.\n2a. Suppose that |\u03c3| > n\u01eb, and the (n\u01eb + 1)st variable set by \u03c3 is an edge variable pi,j . Because |\u03c1\u2032| \u2264 n\u01eb, \u03c1\u2032(pi,j) = \u2217. By Corollary 1, it follows that f \u2032|\u03c1\u2032 6= f \u2032|\u03c3.\n3a. Suppose that |\u03c3| > n\u01eb and the (n\u01eb + 1)st variable set by \u03c3 is a pearl variable pj . (Again, we know that pj is unset by \u03c1\u2032.) Since this is case (a), we can assume that pj \u2208 P \u2212 PC \u2212 PF . Call a vertex i bad if P \u2212 PF \u2212 PC \u2282 edgest\u2217a(i). If i is bad, then fanint\u2217a(i) is greater than n \u2212 2n\u01eb \u2265 n/2. Since the total number of edges queried is at most 2n1+\u01eb, if follows that the number of bad vertices is at most 4n\u01eb. This implies that we can find a pair i, i + 1 of vertices and a pearl j\u2032 such that: (1) pi,j is not queried in \u03b81, . . . , \u03b8t\u2217a ; (2) pi+1,j\u2032 is not queried in \u03b81, . . . , \u03b8t\u2217a ; (3) pj\u2032 is in P \u2212 P\nC \u2212 PF and thus pj\u2032 is also not queried. Thus the clause (\u00acpi,j \u2228 \u00acpj \u2228 \u00acpi+1,j\u2032 \u2228 pj\u2032)|\u03c1\u2032 does not disappear or shrink in f \u2032|\u03c1\u2032 , and thus f \u2032|\u03c1\u2032 6= f \u2032|\u03c3 .\nCase (b). Let \u03b8 be a total ordering to Vars(f) such that case (b) holds. Now let PC denote the set of less than n\u01eb pearls marked C and let PF denote the set of exactly n\u01eb pearls marked F.\nWe define a partial restriction Mb to all but 2n \u01eb\nof the variables in \u03b81, . . . , \u03b8t\u2217 as follows. Call a vertex i full if all variables pi,j have been queried in \u03b81, . . . , \u03b8t\u2217\nb . There are at most n\u01eb full vertices.\nFor each j \u2208 PF , we will fix a pair of vertices Fj = (ij , i\u2032j) in [n]. Let the union of all n \u01eb sets Fj be denoted by F . F has the following properties. (1) For each j, no element of Fj is full; (2) For each j \u2208 PF , Fj \u2208 edgest\u2217\nb (j); and (3) every two distinct elements in F are at least distance 4 apart.\nSince fanint\u2217 b (j) \u2265 n\u03b4, and \u03b4 = 2/5 > \u01eb, it is possible to find such sets Fj satisfying these criteria.\nFor each pi,j queried in \u03b81, . . . \u03b8t\u2217 b , where j \u2208 PF and i 6\u2208 Fj , Mb will set pi,j to 0. For each j \u2208 PC , and for any variable pi,j queried in \u03b81, . . . \u03b8t\u2217 b , set pi,j to 0. For any full vertex i , map i to exactly one pearl j such that pj \u2208 P \u2212 PC \u2212 PF . (Again this can be arbitrary as long as it is consistent with a one-to-one mapping.) For the remaining pj \u2208 P \u2212 PC \u2212 PF that have not yet been mapped to, set all queried variables pi,j to 0. For all pearls pj in PC , color them Red. For all pearls pj in PF that have been queried, assign a fixed color to each pearl.\nThe only variables that were queried in \u03b81, . . . \u03b8t\u2217 b and that are not set by Mb are the edge\nvariables, pi,j , where j \u2208 PF , and i \u2208 Fj . Let S denote the set of all 2n \u01eb\nsettings of these edge variables such that each j \u2208 PF is mapped to exactly one element in Fj . Let f \u2032 = f |Mb and let T \u2032 be the DPLL tree corresponding to \u03b8\u2032 for solving f \u2032, where \u03b8\u2032 is the ordering on the unassigned variables consistent with \u03b8. By Lemma 5, it suffices to show that #DPLL-Cache on f \u2032 and T \u2032 takes time at least 2n \u01eb\n. Note that the first 2n\u01eb variables queried in T \u2032 are the variables Pij ,j , Pi\u2032j ,j , j \u2208 P F . The only nontrivial paths of height 2n\u01eb in T \u2032 are those were each j \u2208 PF is mapped to exactly one vertex in Fj , since otherwise the formula f \u2032 is set to 0. Thus, the nontrivial paths in T \u2032 of height 2n\u01eb correspond to S. We want to show that for each such nontrivial vertex v of height 2n\u01eb in T \u2032 (corresponding to each of the restrictions in S), that v must be traversed by #DPLL-Cache, and thus the runtime is at least 2n \u01eb .\nFix a vertex v and corresponding path \u03c1 \u2208 S. Again we want to show that for any \u03c1\u2032 \u2286 \u03c1, and \u03c3 where \u03c3 occurs before \u03c1\u2032 in the ordering, that f \u2032|\u03c1\u2032 6= f \u2032|\u03c3. There are three cases to consider.\n1b. Suppose that |\u03c3| \u2264 2n\u01eb. If \u03c3 is nontrivial, then both \u03c1\u2032 and \u03c3 are partial mappings of the pearls j in PF to Fj , that are inconsistent with one another. It is easy to check that in this case f \u2032|\u03c3 6= f \u2032|\u03c1\u2032 .\n2b. Suppose that |\u03c3| > 2n\u01eb and the (2n\u01eb + 1)st variable set by \u03c3 is an edge variable pi,j . Because |\u03c1\u2032| \u2264 2n\u01eb, \u03c1\u2032(pi,j) = \u2217. By Corollary 1, it follows that f \u2032|\u03c3 6= f \u2032|\u03c1\u2032 .\n3b. Suppose that |\u03c3| > 2n\u01eb and the (2n\u01eb + 1)st variable set by \u03c3 is a pearl variable pj . By the definition of t\u2217b , we can assume that pj \u2208 P \u2212P\nC \u2212PF . By reasoning similar to case 3a, can find vertices i, i+1, and pearl j\u2032 \u2208 P\u2212PC\u2212PF such that none of the variable pi,j, pi+1,j, pj\u2032 are queried in \u03b81, . . . , \u03b8t\u2217\nb . Thus the clause (\u00acpi,j \u2228\u00acpj \u2228\u00acpi+1,j\u2032 \u2228pj\u2032)|\u03c1\u2032 does not disappear\nto shrink in f \u2032|\u03c1\u20321, and therefore f \u2032|\u03c1\u2032 6= f \u2032|\u03c3.\nThus for each of the two cases, #DPLL-Cache on f \u2032 and T \u2032 takes time at least 2n \u01eb\nand thus #DPLL-Cache on f and T takes time at least 2n \u01eb . 2"}], "references": [{"title": "Satisfiability, Branch-width and Tseitin Tautologies", "author": ["A. Aleknovich", "A. Razborov"], "venue": "In Annual IEEE Symposium on Foundations of Computer Science (FOCS),", "citeRegEx": "Aleknovich and Razborov,? \\Q2002\\E", "shortCiteRegEx": "Aleknovich and Razborov", "year": 2002}, {"title": "Algorithms and Complexity Results for #SAT and Bayesian Inference", "author": ["F. Bacchus", "S. Dalmao", "T. Pitassi"], "venue": "In Annual IEEE Symposium on Foundations of Computer Science (FOCS),", "citeRegEx": "Bacchus et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Bacchus et al\\.", "year": 2003}, {"title": "Counting Models using Connected Components", "author": ["R.J. Bayardo", "J.D. Pehoushek"], "venue": "In Proceedings of the AAAI National Conference (AAAI),", "citeRegEx": "Bayardo and Pehoushek,? \\Q2000\\E", "shortCiteRegEx": "Bayardo and Pehoushek", "year": 2000}, {"title": "On the space-time trade-off in solving Constraint Satisfaction Problems", "author": ["R.J. Bayardo", "D.P. Miranker"], "venue": "In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "Bayardo and Miranker,? \\Q1995\\E", "shortCiteRegEx": "Bayardo and Miranker", "year": 1995}, {"title": "Memoization and DPLL: Formula Caching Proof Systems", "author": ["P. Beame", "R. Impagliazzo", "T. Pitassi", "N. Segerlind"], "venue": "In IEEE Conference on Computational Complexity,", "citeRegEx": "Beame et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Beame et al\\.", "year": 2003}, {"title": "The good old Davis Putnam procedure helps counting models", "author": ["E. Birnbaum", "E.L. Lozinskii"], "venue": "J. Artif. Intell. Research (JAIR),", "citeRegEx": "Birnbaum and Lozinskii,? \\Q1999\\E", "shortCiteRegEx": "Birnbaum and Lozinskii", "year": 1999}, {"title": "Backtracking programming techniques", "author": ["J.R. Bitner", "E. Reingold"], "venue": "Communications of the ACM,", "citeRegEx": "Bitner and Reingold,? \\Q1975\\E", "shortCiteRegEx": "Bitner and Reingold", "year": 1975}, {"title": "A tourist guide through Treewidth", "author": ["H.L. Bodlaender"], "venue": "Acta Cybernetica, 11(1\u20132), 1\u201321.", "citeRegEx": "Bodlaender,? 1993", "shortCiteRegEx": "Bodlaender", "year": 1993}, {"title": "Exponential separations between restricted resolution and cutting planes proof systems", "author": ["M. Bonet", "J.L. Esteban", "N. Galesi", "J. Johannsen"], "venue": "In Annual IEEE Symposium on Foundations of Computer Science (FOCS),", "citeRegEx": "Bonet et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Bonet et al\\.", "year": 1998}, {"title": "Context-specific independence in Bayesian Networks", "author": ["C. Boutilier", "N. Friedman", "M. Goldszmidt", "D. Koller"], "venue": "In Uncertainty in Artificial Intelligence, Proceedings of Annual Conference (UAI),", "citeRegEx": "Boutilier et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Boutilier et al\\.", "year": 1996}, {"title": "Encoding CNFs to empower component analysis", "author": ["M. Chavira", "A. Darwiche"], "venue": "In Theory and Applications of Satisfiability Testing (SAT),", "citeRegEx": "Chavira and Darwiche,? \\Q2006\\E", "shortCiteRegEx": "Chavira and Darwiche", "year": 2006}, {"title": "On probabilistic inference by weighted model counting", "author": ["M. Chavira", "A. Darwiche"], "venue": "Artificial Intelligence,", "citeRegEx": "Chavira and Darwiche,? \\Q2008\\E", "shortCiteRegEx": "Chavira and Darwiche", "year": 2008}, {"title": "Compiling relational bayesian networks for exact inference", "author": ["M. Chavira", "A. Darwiche", "M. Jaeger"], "venue": "Int. J. Approx. Reasoning,", "citeRegEx": "Chavira et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Chavira et al\\.", "year": 2006}, {"title": "On PHP, st-connectivity and odd charged graphs", "author": ["P. Clote", "A. Setzer"], "venue": "In Proof Complexity and Feasible Arithmetics,", "citeRegEx": "Clote and Setzer,? \\Q1998\\E", "shortCiteRegEx": "Clote and Setzer", "year": 1998}, {"title": "Introduction to Algorithms. 2nd Edition", "author": ["T.H. Cormen", "C.E. Leiserson", "R.L. Rivest", "C. Stein"], "venue": null, "citeRegEx": "Cormen et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Cormen et al\\.", "year": 2001}, {"title": "Optimal time-space tradeoff in probabilistic inference", "author": ["A. Darwiche", "D. Allen"], "venue": "In European Workshop on Probabilistic Graphical Models. Available at www.cs.ucla.edu/ \u0303darwiche. Darwiche, A", "citeRegEx": "Darwiche and Allen,? \\Q2002\\E", "shortCiteRegEx": "Darwiche and Allen", "year": 2002}, {"title": "A logical approach to factoring belief networks", "author": ["A. Darwiche"], "venue": "Proceedings of the International Conference on Principles of Knowledge Representation and Reasoning, pp. 409\u2013420.", "citeRegEx": "Darwiche,? 2002", "shortCiteRegEx": "Darwiche", "year": 2002}, {"title": "New advances in compiling CNF into decomposable negation normal form", "author": ["A. Darwiche"], "venue": "Proceedings of the European Conference on Artificial Intelligence (ECAI), pp. 328\u2013332.", "citeRegEx": "Darwiche,? 2004", "shortCiteRegEx": "Darwiche", "year": 2004}, {"title": "Using more reasoning to improve #SAT solving", "author": ["J. Davies", "F. Bacchus"], "venue": "In Proceedings of the AAAI National Conference (AAAI),", "citeRegEx": "Davies and Bacchus,? \\Q2007\\E", "shortCiteRegEx": "Davies and Bacchus", "year": 2007}, {"title": "A machine program for theorem-proving", "author": ["M. Davis", "G. Logemann", "D. Loveland"], "venue": "Communications of the ACM,", "citeRegEx": "Davis et al\\.,? \\Q1962\\E", "shortCiteRegEx": "Davis et al\\.", "year": 1962}, {"title": "A computing procedure for quantification theory", "author": ["M. Davis", "H. Putnam"], "venue": "Journal of the ACM,", "citeRegEx": "Davis and Putnam,? \\Q1960\\E", "shortCiteRegEx": "Davis and Putnam", "year": 1960}, {"title": "Bucket elimination: A unifying framework for reasoning", "author": ["R. Dechter"], "venue": "Artificial Intelligence, 113, 41\u201385.", "citeRegEx": "Dechter,? 1999", "shortCiteRegEx": "Dechter", "year": 1999}, {"title": "Mixtures of deterministic-probabilistic networks and their AND/OR search space", "author": ["R. Dechter", "R. Mateescu"], "venue": "In Uncertainty in Artificial Intelligence, Proceedings of Annual Conference (UAI),", "citeRegEx": "Dechter and Mateescu,? \\Q2004\\E", "shortCiteRegEx": "Dechter and Mateescu", "year": 2004}, {"title": "AND/OR search spaces for graphical models", "author": ["R. Dechter", "R. Mateescu"], "venue": "Artificial Intelligence,", "citeRegEx": "Dechter and Mateescu,? \\Q2007\\E", "shortCiteRegEx": "Dechter and Mateescu", "year": 2007}, {"title": "Counting the number of solutions for instances of satisfiability", "author": ["O. Dubois"], "venue": "Theoretical Computer Science, 81, 49\u201364.", "citeRegEx": "Dubois,? 1991", "shortCiteRegEx": "Dubois", "year": 1991}, {"title": "The intractability of resolution", "author": ["A. Haken"], "venue": "Theoretical Computer Science, 39, 297\u2013305.", "citeRegEx": "Haken,? 1985", "shortCiteRegEx": "Haken", "year": 1985}, {"title": "Clause learning can effectively psimulate general propositional resolution", "author": ["P. Hertel", "F. Bacchus", "T. Pitassi", "A. van Gelder"], "venue": "In Proceedings of the AAAI National Conference (AAAI)", "citeRegEx": "Hertel et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Hertel et al\\.", "year": 2008}, {"title": "Exponential incomparability of tree-like and ordered resolution", "author": ["J. Johannsen"], "venue": "Unpublished manuscript, available at http://www.tcs.informatik.uni-muenchen. de/ \u0303jjohanns/notes.html. Kask, K., Dechter, R., Larrosa, J., & Dechter, A. (2005). Unifying tree decompositions for reasoning in graphical models. Artificial Intelligence, 166(1-2), 165\u2013193.", "citeRegEx": "Johannsen,? 2001", "shortCiteRegEx": "Johannsen", "year": 2001}, {"title": "Exploiting decomposition in constraint optimization problems", "author": ["M. Kitching", "F. Bacchus"], "venue": "In Proceedings of Principles and Practice of Constraint Programming (CP),", "citeRegEx": "Kitching and Bacchus,? \\Q2008\\E", "shortCiteRegEx": "Kitching and Bacchus", "year": 2008}, {"title": "Local computation with probabilities on graphical structures and their application to expert systems", "author": ["S. Lauritzen", "D. Spiegelhalter"], "venue": "Journal of the Royal Statistical Society Series B,", "citeRegEx": "Lauritzen and Spiegelhalter,? \\Q1988\\E", "shortCiteRegEx": "Lauritzen and Spiegelhalter", "year": 1988}, {"title": "Guiding real-world sat solving with dynamic hypergraph separator decomposition", "author": ["W. Li", "P. van Beek"], "venue": "In Proceedings of the International Conference on Tools with Artificial Intelligence (ICTAI),", "citeRegEx": "Li and Beek,? \\Q2004\\E", "shortCiteRegEx": "Li and Beek", "year": 2004}, {"title": "Performing incremental Bayesian Inference by dynamic model counting", "author": ["W. Li", "P. van Beek", "P. Poupart"], "venue": "In Proceedings of the AAAI National Conference (AAAI),", "citeRegEx": "Li et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Li et al\\.", "year": 2006}, {"title": "Exploiting causal independence using weighted model counting", "author": ["W. Li", "P. van Beek", "P. Poupart"], "venue": "In Proceedings of the AAAI National Conference (AAAI)", "citeRegEx": "Li et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Li et al\\.", "year": 2008}, {"title": "Stochastic boolean satisfiability", "author": ["M.L. Littman", "S.M. Majercik", "T. Pitassi"], "venue": "J. Automated Reasoning,", "citeRegEx": "Littman et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Littman et al\\.", "year": 2001}, {"title": "Maxplan: A new approach to probabilistic planning", "author": ["S.M. Majercik", "M.L. Littman"], "venue": "In Proceedings of the International Conference on Artificial Intelligence Planning and Scheduling (AIPS),", "citeRegEx": "Majercik and Littman,? \\Q1998\\E", "shortCiteRegEx": "Majercik and Littman", "year": 1998}, {"title": "Dynamic orderings for AND/OR branch-and-bound search in graphical models", "author": ["R. Marinescu", "R. Dechter"], "venue": "In Proceedings of the European Conference on Artificial Intelligence (ECAI),", "citeRegEx": "Marinescu and Dechter,? \\Q2006\\E", "shortCiteRegEx": "Marinescu and Dechter", "year": 2006}, {"title": "Best-first AND/OR search for graphical models", "author": ["R. Marinescu", "R. Dechter"], "venue": "In Proceedings of the AAAI National Conference (AAAI),", "citeRegEx": "Marinescu and Dechter,? \\Q2007\\E", "shortCiteRegEx": "Marinescu and Dechter", "year": 2007}, {"title": "AND/OR multi-valued decision diagrams for weighted graphical models", "author": ["R. Mateescu", "R. Dechter"], "venue": "In Uncertainty in Artificial Intelligence, Proceedings of Annual Conference (UAI)", "citeRegEx": "Mateescu and Dechter,? \\Q2007\\E", "shortCiteRegEx": "Mateescu and Dechter", "year": 2007}, {"title": "AND/OR cutset conditioning", "author": ["R. Mateescu", "R. Dechter"], "venue": "In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "Mateescu and Dechter,? \\Q2005\\E", "shortCiteRegEx": "Mateescu and Dechter", "year": 2005}, {"title": "Chaff: Engineering an efficient sat solver", "author": ["E. Moskewicz", "C. Madigan", "M. Zhao", "L. Zhang", "S. Malik"], "venue": "In Proc. of the Design Automation Conference (DAC)", "citeRegEx": "Moskewicz et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Moskewicz et al\\.", "year": 2001}, {"title": "Principles of Artificial Intelligence", "author": ["N.J. Nilsson"], "venue": "Tioga.", "citeRegEx": "Nilsson,? 1980", "shortCiteRegEx": "Nilsson", "year": 1980}, {"title": "Probabilistic Reasoning in Intelligent Systems (2nd edition)", "author": ["J. Pearl"], "venue": "Morgan Kaufmann, San Mateo, CA.", "citeRegEx": "Pearl,? 1988", "shortCiteRegEx": "Pearl", "year": 1988}, {"title": "Gibbs States on Countable Sets", "author": ["C. Preston"], "venue": "Cambridge University Press.", "citeRegEx": "Preston,? 1974", "shortCiteRegEx": "Preston", "year": 1974}, {"title": "Resolution versus search: Two strategies for SAT", "author": ["I. Rish", "R. Dechter"], "venue": "Journal of Automated Reasoning,", "citeRegEx": "Rish and Dechter,? \\Q2000\\E", "shortCiteRegEx": "Rish and Dechter", "year": 2000}, {"title": "Graph minors X. obstructions to tree-decomposition", "author": ["N. Robertson", "P. Seymour"], "venue": "Journal of Combinatorial Theory, Series B,", "citeRegEx": "Robertson and Seymour,? \\Q1991\\E", "shortCiteRegEx": "Robertson and Seymour", "year": 1991}, {"title": "Graph minors XIII. the disjoint paths problem", "author": ["N. Robertson", "P. Seymour"], "venue": "Journal of Combinatorial Theory, Series B,", "citeRegEx": "Robertson and Seymour,? \\Q1995\\E", "shortCiteRegEx": "Robertson and Seymour", "year": 1995}, {"title": "On the hardness of approximate reasoning", "author": ["D. Roth"], "venue": "Artificial Intelligence, 82(1\u20132), 273\u2013 302.", "citeRegEx": "Roth,? 1996", "shortCiteRegEx": "Roth", "year": 1996}, {"title": "Combining component caching and clause learning for effective model counting", "author": ["T. Sang", "F. Bacchus", "P. Beame", "H.A. Kautz", "T. Pitassi"], "venue": "In Theory and Applications of Satisfiability Testing (SAT)", "citeRegEx": "Sang et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Sang et al\\.", "year": 2004}, {"title": "Heuristics for fast exact model counting", "author": ["T. Sang", "P. Beame", "H.A. Kautz"], "venue": "In Theory and Applications of Satisfiability Testing (SAT),", "citeRegEx": "Sang et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Sang et al\\.", "year": 2005}, {"title": "Performing Bayesian Inference by weighted model counting", "author": ["T. Sang", "P. Beame", "H.A. Kautz"], "venue": "In Proceedings of the AAAI National Conference (AAAI),", "citeRegEx": "Sang et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Sang et al\\.", "year": 2005}, {"title": "A dynamic approach for MPE and weighted MAXSAT", "author": ["T. Sang", "P. Beame", "H.A. Kautz"], "venue": "In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "Sang et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Sang et al\\.", "year": 2007}, {"title": "Affine algebraic decision diagrams (aadds) and their applications to structured probabilistic inference", "author": ["P. Sanner", "D. McAllester"], "venue": "In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "Sanner and McAllester,? \\Q2005\\E", "shortCiteRegEx": "Sanner and McAllester", "year": 2005}, {"title": "Markov random fields and Gibbs ensembles", "author": ["F.L. Spitzer"], "venue": "American Mathematical Monthly, 78, 142\u201354.", "citeRegEx": "Spitzer,? 1971", "shortCiteRegEx": "Spitzer", "year": 1971}, {"title": "sharpSAT\u2014Counting models with advanced component caching and implicit BCP", "author": ["M. Thurley"], "venue": "Theory and Applications of Satisfiability Testing (SAT), pp. 424\u2013429.", "citeRegEx": "Thurley,? 2006", "shortCiteRegEx": "Thurley", "year": 2006}, {"title": "The complexity of enumeration and reliability problems", "author": ["L.G. Valiant"], "venue": "SIAM Journal of Computing, 9, 410\u2013421.", "citeRegEx": "Valiant,? 1979a", "shortCiteRegEx": "Valiant", "year": 1979}, {"title": "The Complexity of Computing the Permanent", "author": ["L.G. Valiant"], "venue": "Theoretical Computer Science, 8, 189\u2013201.", "citeRegEx": "Valiant,? 1979b", "shortCiteRegEx": "Valiant", "year": 1979}, {"title": "Number of models and satisfiability of sets of clauses", "author": ["W. Zhang"], "venue": "Theoretical Computer Science, 155, 277\u2013288.", "citeRegEx": "Zhang,? 1996", "shortCiteRegEx": "Zhang", "year": 1996}], "referenceMentions": [{"referenceID": 41, "context": "Probabilistic inference in Bayesian Networks (BAYES) is an important and well-studied problem with numerous practical applications in probabilistic reasoning (Pearl, 1988).", "startOffset": 158, "endOffset": 171}, {"referenceID": 46, "context": "In particular, the decision versions of both #SAT and BAYES are #P-complete (Valiant, 1979b, 1979a; Roth, 1996), and there are natural polynomial-time reductions from each problem to the other (Darwiche, 2002; Sang, Beame, & Kautz, 2005b; Chavira, Darwiche, & Jaeger, 2006).", "startOffset": 76, "endOffset": 111}, {"referenceID": 16, "context": "In particular, the decision versions of both #SAT and BAYES are #P-complete (Valiant, 1979b, 1979a; Roth, 1996), and there are natural polynomial-time reductions from each problem to the other (Darwiche, 2002; Sang, Beame, & Kautz, 2005b; Chavira, Darwiche, & Jaeger, 2006).", "startOffset": 193, "endOffset": 273}, {"referenceID": 41, "context": "Developed by Pearl (1988), a Bayesian network is a triple (V, E,P) where (V, E) describes a directed acyclic graph, in which the nodes V = {X1, .", "startOffset": 13, "endOffset": 26}, {"referenceID": 42, "context": "Markov Random Fields or Markov Networks (MN) (Preston, 1974; Spitzer, 1971) are similar to Bayesian Networks in that they also define a joint probability distribution over a set of discrete random variables V = {X1, .", "startOffset": 45, "endOffset": 75}, {"referenceID": 52, "context": "Markov Random Fields or Markov Networks (MN) (Preston, 1974; Spitzer, 1971) are similar to Bayesian Networks in that they also define a joint probability distribution over a set of discrete random variables V = {X1, .", "startOffset": 45, "endOffset": 75}, {"referenceID": 46, "context": "For example, #SAT is known to be complete for the complexity class #P (Valiant, 1979b, 1979a) as is BAYES (Roth, 1996).", "startOffset": 106, "endOffset": 118}, {"referenceID": 45, "context": "For example, #SAT is known to be complete for the complexity class #P (Valiant, 1979b, 1979a) as is BAYES (Roth, 1996). Many special cases that are easy for SAT remain hard for #SAT, e.g., Valiant showed that the decision version of #SAT is #P hard even when the clause size, k, is 2, and Roth (1996) showed that the problem is hard to even approximate in many cases where SAT is easy, e.", "startOffset": 107, "endOffset": 301}, {"referenceID": 21, "context": ", the variable elimination algorithm presented by Dechter (1999), can be successful in practice.", "startOffset": 50, "endOffset": 65}, {"referenceID": 7, "context": ", (Bodlaender, 1993).", "startOffset": 2, "endOffset": 20}, {"referenceID": 7, "context": ", (Bodlaender, 1993). Following Robertson and Seymour (1991) we have defined tree decompositions over hypergraphs, rather than over graphs, and we have made two extra restrictions so as to simplify the proofs of our results.", "startOffset": 3, "endOffset": 61}, {"referenceID": 21, "context": "Variable or bucket elimination (VE) (Dechter, 1999) is a fundamental algorithm for SUMPROD.", "startOffset": 36, "endOffset": 51}, {"referenceID": 16, "context": "Recursive conditioning (RC) (Darwiche, 2001) is another type of algorithm for SUMPROD. Let S = \u3008V,F ,\u2295,\u2297\u3009 be an instance of SUMPROD and H be its underlying hypergraph. RC is a divide and conquer algorithm that instantiates the variables of V so as to break the problem into disjoint components. It then proceeds to solve these components independently. The original spaceefficient version of recursive conditioning, as specified by Darwiche (2001), begins with a branch decomposition T of H of width w and depth d, and an initially empty set of instantiated variables \u03c1.", "startOffset": 29, "endOffset": 448}, {"referenceID": 21, "context": "Rish and Dechter (2000) have previously made a connection between DP and variable elimination.", "startOffset": 9, "endOffset": 24}, {"referenceID": 15, "context": "In fact, Darwiche and Allen (2002) show that there is a smooth tradeoff that can be achieved, with RC-Space and RC-Cache at the two extremes.", "startOffset": 9, "endOffset": 35}, {"referenceID": 40, "context": "In more recent work Dechter and Mateescu (2007) have shown that the notion of AND/OR search spaces (Nilsson, 1980) can be applied to formalize the divide and conquer approach to SUMPROD problems utilized by RC.", "startOffset": 99, "endOffset": 114}, {"referenceID": 21, "context": "In more recent work Dechter and Mateescu (2007) have shown that the notion of AND/OR search spaces (Nilsson, 1980) can be applied to formalize the divide and conquer approach to SUMPROD problems utilized by RC.", "startOffset": 20, "endOffset": 48}, {"referenceID": 21, "context": "Algorithm 4 shows the caching version AND/OR-Cache (called AND/OR graph search by Dechter and Mateescu (2007)).", "startOffset": 82, "endOffset": 110}, {"referenceID": 21, "context": "(Marinescu and Dechter (2006) refer to AND/OR-Cache+ as \u201cAND/OR with partial variable ordering\u201d.", "startOffset": 15, "endOffset": 30}, {"referenceID": 41, "context": "Another algorithm that has now been mostly superseded is cut-set conditioning (Pearl, 1988).", "startOffset": 78, "endOffset": 91}, {"referenceID": 15, "context": "(2005), Darwiche (2001) has shown that RC can compute all marginals on BAYES problems with an extra bottom up traversal of its search tree\u2014at most doubling its run time.", "startOffset": 8, "endOffset": 24}, {"referenceID": 15, "context": "(2005), Darwiche (2001) has shown that RC can compute all marginals on BAYES problems with an extra bottom up traversal of its search tree\u2014at most doubling its run time. The same technique can be applied to AND/OR search algorithms. For the DPLL algorithms we present here, Sang et al. (2005b) have given an even simpler scheme for modifying them so that they can computing all marginals.", "startOffset": 8, "endOffset": 294}, {"referenceID": 2, "context": "Finally, an important early algorithm called DDP was presented by Bayardo and Pehoushek (2000). This was a version of DPLL that utilized dynamic decomposition for solving #SAT.", "startOffset": 66, "endOffset": 95}, {"referenceID": 2, "context": "Finally, an important early algorithm called DDP was presented by Bayardo and Pehoushek (2000). This was a version of DPLL that utilized dynamic decomposition for solving #SAT. In terms of the algorithms discussed above, AND/OR-Space can be viewed as being an version of DDP that utilizes a pseudo tree to guide its variable ordering. In the original presentation of DDP, any variable ordering could be used including dynamic variable orderings. The search continued until the problem was decomposed into independent components (tested for during search) at which point a separate recursion was used to solve each component. Hence, the DDP explored an AND/OR search tree, however this tree need not correspond to any pseudo tree over the original problem. (The DVO and DSO AND/OR search schemes presented by Mateescu and Dechter (2005) are also versions of DDP run with particular variable ordering heuristics).", "startOffset": 66, "endOffset": 836}, {"referenceID": 2, "context": "Finally, an important early algorithm called DDP was presented by Bayardo and Pehoushek (2000). This was a version of DPLL that utilized dynamic decomposition for solving #SAT. In terms of the algorithms discussed above, AND/OR-Space can be viewed as being an version of DDP that utilizes a pseudo tree to guide its variable ordering. In the original presentation of DDP, any variable ordering could be used including dynamic variable orderings. The search continued until the problem was decomposed into independent components (tested for during search) at which point a separate recursion was used to solve each component. Hence, the DDP explored an AND/OR search tree, however this tree need not correspond to any pseudo tree over the original problem. (The DVO and DSO AND/OR search schemes presented by Mateescu and Dechter (2005) are also versions of DDP run with particular variable ordering heuristics). In comparison with the algorithms we present in the next section, Bayardo and Pehoushek (2000) did not provide a complexity analysis of DDP, DDP did not use caching to enhance its performance, and DDP still has less flexibility in its variable ordering.", "startOffset": 66, "endOffset": 1007}, {"referenceID": 3, "context": "Specifically, Dechter and Mateescu show that AND/OR-Space runs in time exponential in the height of its inputed pseudo tree, and Bayardo and Miranker (1995) show that this height is bounded w log n.", "startOffset": 129, "endOffset": 157}, {"referenceID": 3, "context": "Specifically, Dechter and Mateescu show that AND/OR-Space runs in time exponential in the height of its inputed pseudo tree, and Bayardo and Miranker (1995) show that this height is bounded w log n. Lemma 1 then shows that the bound also holds for branch width. Similarly, Dechter and Mateescu (2007) show that AND/OR-Cache runs in time and space bounded by nO(1)2O(w) by exploiting the very close relationship between pseudo trees and elimination orders.", "startOffset": 129, "endOffset": 301}, {"referenceID": 44, "context": "However, Robertson and Seymour (1995) present an algorithm for computing a branch decomposition with branch width that is within a factor of 2 of optimal and that runs in time nO(1)2O(w), where w is the branch width of H.", "startOffset": 9, "endOffset": 38}, {"referenceID": 21, "context": "And finally, from that nearly optimal elimination ordering the bucket-tree construction of Dechter and Mateescu (2007) can be used to construct a nearly optimal pseudo tree, and thus we can obtain a deterministic version of AND/OR-Space that runs in linear space and time 2O(w logn), and a deterministic version of AND/OR-Cache that runs in time and space nO(1)2O(w).", "startOffset": 91, "endOffset": 119}, {"referenceID": 24, "context": "DPLL is a nondeterministic algorithm for SAT, that has also been used to solve various generalizations of SAT, including #SAT (Dubois, 1991; Zhang, 1996; Birnbaum & Lozinskii, 1999; Littman, Majercik, & Pitassi, 2001).", "startOffset": 126, "endOffset": 217}, {"referenceID": 56, "context": "DPLL is a nondeterministic algorithm for SAT, that has also been used to solve various generalizations of SAT, including #SAT (Dubois, 1991; Zhang, 1996; Birnbaum & Lozinskii, 1999; Littman, Majercik, & Pitassi, 2001).", "startOffset": 126, "endOffset": 217}, {"referenceID": 25, "context": "In particular, it is implicit in the results of Haken (1985) that any decision tree for the formulas encoding the (negation of the) propositional pigeonhole principle has exponential size, and thus DPLL and #DPLL must take exponential-time on these examples.", "startOffset": 48, "endOffset": 61}, {"referenceID": 47, "context": "For example, this approach is readily applicable to BAYES and has proved to be empirically successful (Sang et al., 2005b). Furthermore, the encoding provided by Sang et al. (2005b) achieves the same complexity guarantees as standard algorithms for BAYES.", "startOffset": 103, "endOffset": 182}, {"referenceID": 16, "context": "The proof of this theorem is implicit in the results of Darwiche (2001).", "startOffset": 56, "endOffset": 72}, {"referenceID": 2, "context": "DDP is the algorithm presented by Bayardo and Pehoushek (2000).", "startOffset": 34, "endOffset": 63}, {"referenceID": 17, "context": ", (Darwiche, 2004; Chavira & Darwiche, 2006, 2008).", "startOffset": 2, "endOffset": 50}, {"referenceID": 28, "context": "The empirical results of Kitching and Bacchus (2008) show that the added flexibility of #DPLL-Cache can sometimes yield significant performance improvements over AND/OR search even when the extra flexibility of AND/OR-Cache+ is exploited.", "startOffset": 25, "endOffset": 53}, {"referenceID": 3, "context": "More sophisticated caching methods have also been explored for solving SAT by Beame et al. (2003) who showed that some of these methods can considerably increase the power of DPLL.", "startOffset": 78, "endOffset": 98}, {"referenceID": 0, "context": "In other related work, one of the results of Aleknovich and Razborov (2002) showed that SAT could be solved in time nO(1)2O(w).", "startOffset": 45, "endOffset": 76}, {"referenceID": 21, "context": "Marinescu and Dechter (2007) present a method for searching an AND/OR tree in a best-first manner.", "startOffset": 14, "endOffset": 29}, {"referenceID": 28, "context": ", 2004, 2005a) and by the branch and bound system described by Kitching and Bacchus (2008) support our belief that this added flexibility can be important in practice.", "startOffset": 63, "endOffset": 91}, {"referenceID": 1, "context": "Some of the results of this paper were presented in an earlier conference paper (Bacchus et al., 2003).", "startOffset": 80, "endOffset": 102}, {"referenceID": 16, "context": "By the results of Darwiche (2001), there is a branch decomposition of H of depth O(logm) and width O(w).", "startOffset": 18, "endOffset": 34}, {"referenceID": 16, "context": "By the results of Darwiche (2001), there is a branch decomposition of H of depth O(logm) and width O(w). Also by the results of Robertson and Seymour (1995), it is possible to find a branch decomposition, Tbd, such that Tbd has branch width O(w) and depth O(logm), in time nO(1)2O(w).", "startOffset": 18, "endOffset": 157}, {"referenceID": 27, "context": "To prove this theorem we first observe that from a result of Johannsen (Johannsen, 2001), #DPLL-Cache, #DPLL-Space, and #DPLL can all solve the negation of the propositional stringof-pearls principle (Bonet, Esteban, Galesi, & Johannsen, 1998) in time nO(logn), when run with a dynamic variable ordering.", "startOffset": 71, "endOffset": 88}, {"referenceID": 12, "context": "The string-of-pearls principle, introduced in a different form by Clote and Setzer (1998) and explicitly by Bonet et al.", "startOffset": 66, "endOffset": 90}, {"referenceID": 8, "context": "The string-of-pearls principle, introduced in a different form by Clote and Setzer (1998) and explicitly by Bonet et al. (1998) is as follows.", "startOffset": 108, "endOffset": 128}, {"referenceID": 27, "context": "Johannsen (Johannsen, 2001) shows that SPn,n has quasipolynomial size tree resolution proofs.", "startOffset": 10, "endOffset": 27}, {"referenceID": 27, "context": "Lemma 4 (Johannsen, 2001) SPn,n can be solved in time nO(logn) by #DPLL, #DPLL-Space, and #DPLL-Cache.", "startOffset": 8, "endOffset": 25}], "year": 2009, "abstractText": "Inference in Bayes Nets (BAYES) is an important problem with numerous applications in probabilistic reasoning. Counting the number of satisfying assignments of a propositional formula (#SAT) is a closely related problem of fundamental theoretical importance. Both these problems, and others, are members of the class of sum-of-products (SUMPROD) problems. In this paper we show that standard backtracking search when augmented with a simple memoization scheme (caching) can solve any sum-of-products problem with time complexity that is at least as good any other state-of-the-art exact algorithm, and that it can also achieve the best known time-space tradeoff. Furthermore, backtracking\u2019s ability to utilize more flexible variable orderings allows us to prove that it can achieve an exponential speedup over other standard algorithms for SUMPROD on some instances. The ideas presented here have been utilized in a number of solvers that have been applied to various types of sum-of-product problems. These system\u2019s have exploited the fact that backtracking can naturally exploit more of the problem\u2019s structure to achieve improved performance on a range of problem instances. Empirical evidence of this performance gain has appeared in published works describing these solvers, and we provide references to these works.", "creator": "dvips(k) 5.96dev Copyright 2007 Radical Eye Software"}}}