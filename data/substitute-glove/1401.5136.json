{"id": "1401.5136", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Jan-2014", "title": "A Unifying Framework for Typical Multi-Task Multiple Kernel Learning Problems", "abstract": "Over although last come years, Multi - Kernel Learning (MKL) to accepted direct experience often calculations - far collection selection perfected in though sense has os - the learning. MKL nonprescription have been crafting and resolve new a form spectrum of processor focusing still, combined Multi - Task Learning (MTL ). Solving as MKL remedies usually scale collection algebraic to none tailored to when change at pulling, given way, form, making equal - variables impressive.", "histories": [["v1", "Tue, 21 Jan 2014 01:16:44 GMT  (51kb,D)", "http://arxiv.org/abs/1401.5136v1", "17 pages, 1 figure. Accepted by IEEE Transactions on Neural Networks and Learning Systems; currently published as Early Access Article"]], "COMMENTS": "17 pages, 1 figure. Accepted by IEEE Transactions on Neural Networks and Learning Systems; currently published as Early Access Article", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["cong li", "michael georgiopoulos", "georgios c anagnostopoulos"], "accepted": false, "id": "1401.5136"}, "pdf": {"name": "1401.5136.pdf", "metadata": {"source": "META", "title": "A Unifying Framework for Typical Multi-Task Multiple Kernel Learning Problems", "authors": ["Cong Li", "Michael Georgiopoulos", "Georgios C. Anagnostopoulos"], "emails": ["congli@eecs.ucf.edu,", "michaelg@ucf.edu", "georgio@fit.edu"], "sections": [{"heading": null, "text": "In this paper we present a general Multi-Task Multi-Kernel Learning (Multi-Task MKL) framework that subsumes well-known Multi-Task MKL formulations, as well as several important MKL approaches on single-task problems. We then derive a simple algorithm that can solve the unifying framework. To demonstrate the flexibility of the proposed framework, we formulate a new learning problem, namely Partially-Shared Common Space (PSCS) Multi-Task MKL, and demonstrate its merits through experimentation.\nKeywords: Multiple Kernel Learning, Multi-task Learning, Support Vector Machines"}, {"heading": "1 Introduction", "text": "Kernel methods play an important role in machine learning due to their elegant property of implicitly mapping samples from the original space into a potentially infinite-dimensional feature space, in which inner products can be calculated directly via a kernel function. It is desired that samples are appropriately distributed in the feature space, such that kernel-based models, like Support Vector Machines (SVMs)[4] [20], could perform better in the feature space than in the original space. Since the feature space is implicitly defined via the kernel function, it is important to choose the kernel appropriately for a given task. In recent years, substantial effort has been devoted on how to learn such kernel function (or equivalently, kernel matrix) from the available data. According to the Multi-Kernel Learning (MKL) approach [13], which is one of the most popular strategies for learning kernels, multiple predetermined kernels are, most commonly, linearly combined. Subsequently, in lieu of tuning kernel parameters via some validation scheme, the combination coefficients are adapted to yield the optimal kernel in a data-driven manner. A thorough review of MKL methods and associated algorithms is provided in [7].\nSo far, several MKL formulations, along with their optimization algorithms, have been proposed. The earlier work in [13] suggests a MKL formulation with trace constraints over the linearly combined kernels, which is further transformed into a solvable Semi-Definite Programming problem. Also, Simple-MKL [14] relies on a MKL formulation with L1-norm constrained coefficients. In each iteration of the algorithm, a SVM problem is solved by taking advantage of an existing efficient SVM solver and the coefficients are updated via a gradient-based scheme. A similar algorithm is also applied in [23]. In [11], an L2-norm constraint is applied to the linear combination coefficients and the proposed min-max formulation is transformed into a Semi-Infinite Programming (SIP) problem, which is then solved via a cutting plane algorithm. Moreover, two algorithms are proposed in [12] to solve the Lp-MKL formulation, where the coefficient constraint is generalized to an Lp-norm constraint. The relationship between the latter Lp-MKL formulation and one\nar X\niv :1\n40 1.\n51 36\nv1 [\ncs .L\nG ]\n2 1\nJa n\n20 14\nthat entails a Group-Lasso regularizer is pointed out in [24], which utilizes a block coordinate descent algorithm to solve the problem in the primal domain. Besides MKL-based SVM models, a MKL formulation for Kernel Ridge Regression (KRR)[16] has been proposed in [3]. Cast as a min-max problem, it is solved via an interpolated iterative algorithm, which takes advantage of the closed-form solution for the KRR kernel coefficients.\nFurthermore, MKL has been applied to Multi-Task Learning (MTL) giving rise to Multi-Task MultiKernel Learning (Multi-Task MKL) approaches, where several tasks with shared feature representations are simultaneously learned. As was the case with single-task MKL approaches mentioned in the previous paragraph, most Multi-Task MKL formulations that have appeared in the literature are accompanied by an algorithm tailored to their particular formulation. For example, a framework is formulated in [18], where individual tasks utilize their own task-specific space in conjunction with a shared space component, while the balance between these two components is controlled through weights. Subsequently, an exchange algorithm is proposed to solve the resulting min-max problem. Additionally, in [1], a Group-Lasso regularizer on SVM weights is considered that yields coefficient sparsity within a group of tasks and non-sparse regularization across groups. The resulting problem is solved in the dual domain via a mirror descent-based algorithm. Also, in [15], the Group-Lasso regularizer is generalized to Lp \u2212 Lq regularization and two optimization problems are addressed, one being convex and the other non-convex. Next, for each of these two formulations, a specialized algorithm is proposed. Furthermore, in [22], Multi-Task MKL is formulated in the primal domain by penalizing the SVM weight of each task to be close to a shared common weight. Finally, maximum entropy discrimination is employed in [9] to construct a Multi-Task MKL framework.\nProposing useful MKL formulations and devising effective algorithms specifically tailored to solving them is, in most cases, a non-trivial task; such an endeavor requires fair amounts of insight and ingenuity. This is even more so true, when one considers applying MKL to MTL problems. In this paper, we present a general kernel-based Multi-Task MKL framework that subsumes well-known Multi-Task MKL formulations, as well as several important MKL approaches on single-task machine learning problems. Its unifying character stems from its applicability to prominent kernel-based tasks, such as SVM-based binary classification, KRRbased regression and outlier detection based on One-Class SVM [17] and Support Vector Domain Description (SVDD) [19], to name a few important ones. Also, it accommodates various feature space sharing approaches that may be encountered in a Multi-Task MKL setting, as well as single-task MKL settings with different constraints. For example, it subsumes L2-MKL and Lp-MKL considered in [11] and [12], the KRR-based MKL in [3] and the Multi-Task MKL formulations in [18] and [15]. We introduce our framework in Section 2.\nIn Section 3 we state an equivalency between solving SIP problems and Exact Penalty Function (EPF) optimization, which may be viewed as a useful result on its own. As the new framework can be cast as a SIP problem, the previous equivalency allows us in Section 4 to eventually derive a straightforward and easy to implement algorithm for solving the new EPF-based formulation. For a given Multi-Task MKL problem that is a special case of our framework, the availability of our algorithm eliminates the need of using an existing, potentially complicated, algorithm or deriving a new algorithm that is tailored to the problem at hand. A further major advantage of the algorithm is that it can leverage from already existing efficient kernel machine solvers (e.g., SVM solvers) or closed-form solutions (e.g., KRR solution) for given problems.\nIn Section 5, we present a new specialization of our framework, called Partially-Shared Common Space (PSCS) Multi-Task MKL. It permits some tasks to share a common feature space, while other tasks are allowed to utilize their own feature space. This approach follows the spirit of recent MTL research, which allows tasks to be grouped, while tasks belonging to the same group can share information with each other. Some examples include the works in [25], [8], [10] and [26], to name a few. This is a generalization of the traditional MTL setting, according to which all tasks are considered as one group and are learned concurrently. Our PSCS Multi-Task MKL formulation is a combination of the grouped MTL setting and MKL, which appreciably differs from previously cited works. The new formulation concretely showcases the generality of the proposed Multi-Task MKL framework, the flexibility in choosing a suitable Multi-Task MKL feature sharing strategy, as well as the usefulness of the derived algorithm. The merits of PSCS are illustrated in Section 6, where we compare its performance on classification benchmark data sets against the commonspace (CS) and independent-space (IS) alternatives. Proofs of our analytical work are given in the appendices."}, {"heading": "2 Problem Formulation", "text": "Consider a supervised learning task with parameter \u03b1, which can be expressed in the form\nmax \u03b1\u2208\u2126(\u03b1) g\u0304(\u03b1,K) (1)\nwhere K is the kernel matrix of the training data set, i.e., its (i, j) entry is K(xi,xj) , \u3008\u03c6(xi), \u03c6(xj)\u3009H, and H is the Hilbert space reproduced by the kernel function k. Here, \u03c6 is the feature mapping that is implied by the kernel function k(\u00b7, \u00b7) and xi,xj \u2208 X , where X is an input set. Also, suppose g\u0304 has a finite maximum, a finite number of local maxima with respect to \u03b1 in the feasible set \u2126(\u03b1) \u2282 Rn and is affine with respect to the individual entries of K. Some well-known supervised learning tasks that feature these characteristics are considered in SVM, KRR, SVDD and One-Class SVM. Their dual-domain objective functions g\u0304 for n training samples are given in Equation (2) through Equation (5) respectively.\ng\u0304SV M(\u03b1,K) , \u03b1 \u20321\u2212 1\n2 \u03b1\u2032Y KY \u03b1, (2)\nwith \u2126(\u03b1) , {\u03b1 \u2208 Rn : 0 \u03b1 C1,\u03b1\u2032y = 0}\ng\u0304KRR(\u03b1,K) , 2\u03b1 \u2032y \u2212\u03b1\u2032(\u03bbI +K)\u03b1, (3)\nwith \u2126(\u03b1) , Rn\ng\u0304SV DD(\u03b1,K) , \u03b1 \u2032k \u2212\u03b1\u2032K\u03b1, (4) with \u2126(\u03b1) , {\u03b1 \u2208 Rn : 0 \u03b1 C1,\u03b1\u20321 = 1}\ng\u0304OCSV M(\u03b1,K) , \u2212\u03b1\u2032K\u03b1, (5)\nwith \u2126(\u03b1) , {\u03b1 \u2208 Rn : 0 \u03b1 1 \u03bdl 1,\u03b1\u20321 = 1}\nIn the above examples, \u00b7\u2032 signifies transposition vector/matrix , y , [y1, \u00b7 \u00b7 \u00b7 , yn]\u2032 is the target vector, k , [k(x1,x1), \u00b7 \u00b7 \u00b7 , k(xn,xn)]\u2032 and Y , diag(y), where diag(\u00b7) is an operator yielding a diagonal matrix, whose diagonal is formed by the operand\u2019s vector argument. Additionally, C, \u03bb, \u03bd, l are scalar non-negative regularization parameters for the corresponding learning problems and 1 is the all-ones vector of appropriate dimension.\nAssume, now, that we have T such tasks and let {xti, yti}, i = 1, \u00b7 \u00b7 \u00b7 , Nt, be the training data for task t, where t = 1, \u00b7 \u00b7 \u00b7 , T . Let km(xti,xtj) , \u3008\u03c6m(xti), \u03c6m(xtj)\u3009Hm , where m = 1, \u00b7 \u00b7 \u00b7M , be the m-th pre-specified kernel function and \u03c6m be the m-th associated feature mapping. Also, let K t m be the Nt\u00d7Nt kernel matrix of the training data corresponding to the t-th task and calculated using the m-th kernel function, i.e. Ktm has elements km(x t i,x t j), where i, j = 1, \u00b7 \u00b7 \u00b7 , Nt. In this paper we consider the Multi-Task MKL framework that is formulated as follows:\nmin \u03b8\u2208\u03a8(\u03b8) max a\u2208\u2126(a) T\u2211 t=1 g\u0304(\u03b1t, M\u2211 m=1 \u03b8tmK t m) (6)\nwhere a , [\u03b11 \u2032 , \u00b7 \u00b7 \u00b7 ,\u03b1T \u2032 ]\u2032 \u2208 RN , N = \u2211T t=1Nt, and \u03b1\nt\u2032 denotes the transpose of \u03b1t \u2208 RNt , t = 1, \u00b7 \u00b7 \u00b7 , T . Similarly, \u03b8 stands for the vector with elements \u03b8tm.\nThe framework is able to incorporate various feature space sharing approaches by appropriately specifying the feasible region of the kernel combination coefficients \u03b8. For example, for T = 1 it can specialize to Lpnorm MKL [12], where p \u2265 1, by using \u03a8(\u03b8) = {\u03b8 : \u2016\u03b8\u2016p \u2264 1,\u03b8 0}. Obviously, the L2-norm MKL [11] is also covered by our framework. Additionally, it can express the Multi-Task MKL model in [18] that allows individual tasks to utilize their own task-specific space in conjunction with a shared space component. This\nis achieved by specifying \u03a8(\u03b8) = {\u03b8 : \u03b8tm = \u03b6m + \u03b3tm, \u03b6m \u2265 0, \u03b3tm \u2265 0, \u2211M m=1 \u03b8 t m = 1, \u2211M m=1 \u2211T t=1 \u03b3 t m \u2264 \u03b2}. Hence, our framework also subsumes the Common Space (CS) and Independent Space (IS) Multi-Task MKL models as special cases. The former is obtained by letting \u03b8tm = \u03b6m,\u2200t,m. In this case, all tasks share a common kernel function determined by the coefficients \u03b6m\u2019s. Appropriate constraints can be added on \u03b6, such as the Lp-norm constraint. On the other hand, if we let \u03b8\nt , [\u03b8t1, \u00b7 \u00b7 \u00b7 , \u03b8tM ]\u2032 and add independent constraints on each \u03b8t, then we obtain the IS model, where each task occupies its own feature space.\nTo mention a final example, a Group-Lasso type regularizer is employed on the SVM primal-domain weights in [1], which leads to intricate optimization problems and algorithms. Our framework specializes to\nthis problem by specifying \u03a8(\u03b8) = {\u03b8 : \u03b8 0, ( \u2211T t=1 \u2016\u03b8\nt\u2016qp)1/q \u2264 a, p \u2265 1, q \u2265 1}. By appropriately choosing the values of p and q, different level of group-wise and intra-group sparsity can be obtained. In this case too, using our framework leads to an easier formulation that can be solved in a much more straightforward fashion via our algorithm.\nIn the next section, we first transform Problem (6) to an equivalent SIP problem. Subsequently, we demonstrate the equivalency between general SIP problems and EPF-based problems. The latter result will allow us to cast Problem (6) as an EPF-based problem, which, as it turns out, can be easily solved."}, {"heading": "3 Exact Penalty Function Method", "text": "In general, the min-max Problem (6) is not easy to solve. However, it can be transformed to an equivalent epigraph problem in the following SIP form:\nmin \u03c9\u2208R,\u03b8\u2208\u03a8(\u03b8) \u03c9\ns.t. T\u2211 t=1 g\u0304(\u03b1t, M\u2211 m=1 \u03b8tmK t m) \u2264 \u03c9, \u2200a \u2208 \u2126(a).\n(7)\nBefore solving Problem (7), we first show an equivalence between EPF-based problems [21] and general SIP problems. This will eventually facilitate the development of an algorithm for solving Problem (7). General SIP problem\nConsider the general SIP problem\nmin x\u2208Rn f(x) s.t. g(a,x) \u2264 0, \u2200a \u2208 \u2126(a); lu(x) = 0, u = 1, \u00b7 \u00b7 \u00b7 , U ; rv(x) \u2264 0, v = 1, \u00b7 \u00b7 \u00b7 , V.\n(8)\nwith U equality and V inequality constraints. Now, suppose f , g, the lu\u2019s and rv\u2019s are continuously differentiable. The feasible region of x is determined by both the SIP constraint involving g and the regular equality (lu\u2019s) and inequality (rv\u2019s) constraints. It is not difficult to see that Problem (7) is a special case of Problem (8) by defining x , [\u03c9,\u03b8\u2032]\u2032, a , [\u03b11 \u2032 , \u00b7 \u00b7 \u00b7 ,\u03b1T \u2032 ]\u2032, f(x) , \u03c9, g(a,x) , \u2211T t=1 g\u0304(\u03b1 t, \u2211M m=1 \u03b8 t mK t m)\u2212\u03c9, and letting the constraints lu\u2019s and rv\u2019s define \u03a8(\u03b8). EPF-based problem\nFor fixed x, assume that there are N(x) local maxima a\u2217i \u2208 \u2126(a) of g(a,x) that satisfy g(a\u2217i ,x) \u2265 \u2212\u03b7 for some \u03b7 > 0 and g(a\u2217i ,x) 6= g(a\u2217j ,x),\u2200a\u2217i ,a\u2217j \u2208 \u2126(a). Denote this set of local maxima as E(x) , {a\u2217i } N(x) i=1 , and let I(x) , {1, 2, . . . , N(x)}. Obviously, each a\u2217i depends implicitly on x. Thus, if the Implicit Function Theorem conditions hold, there is a function ai of x, such that a \u2217 i = ai(x) and we can define hi(x) , g(ai(x),x). Then, the EPF P (x) introduced in [21] is defined in a neighborhood of x as:\nP (x) , f(x) + \u03bd \u2211 i\u2208I(x) hi(x)+ (9)\nwhere \u03bd > 0 and hi(x)+ , max{0, hi(x)}. We refer the interested reader to [21] for more details about EPFs. Now, consider the EPF-based optimization problem:\nmin x\u2208Rn P (x) s.t. lu(x) = 0,\u2200u; rv(x) \u2264 0,\u2200v. (10)\nIn the next theorem, we state that the general SIP Problem (8) can be solved by solving the EPF-based Problem (10).\nTheorem 1. Let f , g, lu\u2019s and rv\u2019s in Problem (8) and Problem (10) be continuously differentiable, and let the EPF function P (x) be defined as in Equation (9). Suppose for fixed x, there are finite number of as \u2208 \u2126(a), s = 1, \u00b7 \u00b7 \u00b7 , S, such that g(as,x) = 0. If x\u0302 is in the feasible region of Problem (8) and solves Problem (10), then x\u0302 is a Karush-Kuhn-Tucker (KKT) point of Problem (8).\nThe proof of the above theorem is given in Section .1 of the Appendix. The EPF optimization provides a way to solve the proposed general SIP-type Problem (8); in addition, it also avoids involving the SIP constraint. Obviously, since our framework of Problem (7) is a general SIP problem, we can solve its equivalent EPF-based problem instead. In the next section we introduce a simple and easy to implement algorithm to solve the EPF optimization problem for our framework."}, {"heading": "4 Algorithm", "text": "In this section, we focus on solving the EPF-based Problem (10) for our framework. Consider Problem (10), for which we define x , [\u03c9,\u03b8\u2032]\u2032, a , [\u03b11 \u2032 , \u00b7 \u00b7 \u00b7 ,\u03b1T \u2032 ]\u2032, f(x) , \u03c9, g(a,x) , \u2211T t=1 g\u0304(\u03b1 t, \u2211M m=1 \u03b8 t mK t m) \u2212 \u03c9, and let the constraints lu\u2019s and rv\u2019s define \u03a8(\u03b8). In order to solve Problem (10), a descent algorithm is suggested in [21]. During iteration k and given xk, E(xk) is calculated, a descent direction dk is found, and the variables are updated as xk+1 = xk + dk. We remind the reader that the set E(x) contains a \u2217 i \u2019s, which satisfy g(a\u2217i ,x) \u2265 \u2212\u03b7. In [21] it is proven that, for sufficiently large \u03bd and sufficiently small step length > 0, the limit point of {xk} is a KKT point of Problem (8), if the sequence {dk} is bounded and the sequence {xk} remains in a bounded region, in which f and g are doubly-differentiable functions with bounded second-order derivatives. In the next theorem, we show how to find the descent direction dk for our framework given xk at the k-th iteration.\nTheorem 2. Let g\u0304(\u03b1,K) be affine with respect to the individual entries of K. Suppose it has a finite maximum and a finite number of local maxima with respect to \u03b1 in the feasible set \u2126(\u03b1). Let lu\u2019s and rv\u2019s be continuous and differentiable. Let E(x) and I(x) be as defined in Section 3, and ai,k , [\u03b11 \u2032 i,k, \u00b7 \u00b7 \u00b7 ,\u03b1T \u2032 i,k] \u2032 \u2208 E(xk), i \u2208 I(xk) = {1, \u00b7 \u00b7 \u00b7 , N(xk)}. Consider the following N(xk) problems, \u2200 i \u2208 I(xk):\nmin \u03b8 T\u2211 t=1 g\u0304(\u03b1ti,k, M\u2211 m=1 \u03b8tmK t m) s.t. lu(x) = 0,\u2200u; rv(x) \u2264 0,\u2200v.\n(11)\nLet \u03b8\u0302i, consisting of all elements \u03b8\u0302 t m,i\u2019s, be the solution to the i-th problem. Also, let i0 = arg mini\u2208I(xk) maxj\u2208I(xk){ \u2211T t=1 g\u0304(\u03b1 t j,k, \u2211M m=1 \u03b8\u0302 t m,iK t m)} and \u03c9\u0302 = mini\u2208I(xk) maxj\u2208I(xk){ \u2211T t=1 g\u0304(\u03b1 t j,k, \u2211M m=1 \u03b8\u0302 t m,iK t m}. Finally, let x\u0302 = [\u03c9\u0302, \u03b8\u0302 \u2032 i0 ] \u2032. Then, dk = x\u0302 \u2212 xk is a descent direction for the EPF-based Problem (10) when \u03bd > 1.\nThe proof of the above theorem is provided in Section .2 of the appendix. Note that, if g\u0304 is concave with respect to \u03b1, then N(xk) = 1. Thus, we have the following corollary.\nCorollary 1. Let g\u0304(\u03b1,K) be affine with respect to the individual entries of K and concave with respect to \u03b1. Let the lu\u2019s and rv\u2019s be continuous and differentiable. Also, let E(x) and I(x) be defined as in Section 3 and ak , [\u03b11 \u2032 k , \u00b7 \u00b7 \u00b7 ,\u03b1T \u2032 k ] \u2032 \u2208 E(xk). Consider the problem\nmin \u03b8 T\u2211 t=1 g\u0304(\u03b1tk, M\u2211 m=1 \u03b8tmK t m) s.t. lu(x) = 0,\u2200u; rv(x) \u2264 0,\u2200v.\n(12)\nwith solution \u03b8\u0302. Let \u03c9\u0302 , \u2211T t=1 g\u0304(\u03b1 t k, \u2211M m=1 \u03b8\u0302 t mK t m) and x\u0302 , [\u03c9\u0302, \u03b8\u0302 \u2032 ]\u2032. Then, dk = x\u0302 \u2212 xk is a descent direction for the EPF-based Problem (10) when \u03bd > 1.\nBased on the above discussion, we provide Algorithm 1. Note that we focus on the case, where g\u0304 is concave, since it is the most common one in the context of kernel machines.\nAlgorithm 1 Algorithm for solving Problem (10)\nChoose M kernel functions. Calculate the kernel matrices Ktm for the T tasks and the M kernels. Choose g\u0304 and \u03a8 (\u03b8) based on the characteristics of the problem at hand. Randomly initialize \u03b80 0. Initialize \u03b7 and 0 to small positive values. k \u2190 0. while not converged do ak \u2190 arg maxa\u2208\u2126(a) \u2211 t g\u0304(\u03b1 t, \u2211 m \u03b8 t m,kK t m)\n\u03b8\u0302k \u2190 solve Problem (12) given ak \u03c9\u0302k \u2190 \u2211 t g\u0304(\u03b1 t k, \u2211 m \u03b8\u0302 t m,kK t m) \u03b8k+1 \u2190 \u03b8k + k(\u03b8\u0302k \u2212 \u03b8k) \u03c9k+1 \u2190 \u03c9k + k(\u03c9\u0302k \u2212 \u03c9k) k \u2190 k + 1\nend while\nThere are several ways to choose the step length k in each step k. As suggested in [21], one possibility is to choose k as the largest element of the set {1, \u03b2, \u03b22, \u00b7 \u00b7 \u00b7 }, for some \u03b2, 0 < \u03b2 < 1, such that\n[P (xk + kdk)\u2212 P (xk)]/ kGk \u2265 \u03c3 (13) where P is the EPF given in Problem (10), \u03c3 is some constant that satisfies 0 < \u03c3 < 1, and Gk is the directional derivative of P with respect to x at the k-th step. It is not difficult to show that\nGk = f(x\u0302k) + \u03bd g(ak, x\u0302k)+ \u2212 f(xk)\u2212 \u03bd g(ak,xk)+ (14)\nwhere x\u0302k = [\u03c9\u0302k, \u03b8\u0302 \u2032 k] \u2032 and xk = [\u03c9k,\u03b8 \u2032 k]. For details of Gk\u2019s calculation, when g\u0304 is not concave with respect to \u03b1, we refer the reader to Section .2 of the Appendix."}, {"heading": "4.1 Analysis", "text": "The advantages of our algorithm are multifold. First, the framework hinges on relatively few mild constraints that are typically met in practice. Specifically, we only assumed that g\u0304 is continuous and doubly differentiable with respect to \u03b1 with bounded second-order derivatives and finite number of local maxima, whose value are also finite, and g\u0304 is affine with respect to the elements of K. There is no need for g\u0304 to be concave with respect to \u03b1. Note also that all these constraints are met for the 4 examples given in Problems 2 through 5. Therefore, the framework and its associated algorithm may enjoy wide applicability.\nSecondly, the maximization problem with respect to a in the first step of the algorithm can be separated into T independent problems under the commonly-encountered setting, where the feasible regions of the \u03b1t\u2019s are mutually independent, such as in the formulations of [18] and [15]. Furthermore, in most situations, solving each of the T problems can be addressed via readily-available efficient optimizers; for example, in the case of SVM problems, one could use LIBSVM [2]. In some other cases, a closed-form solution could be used instead, whenever available, such as in the case of KRR.\nThirdly, the minimization problem (12) is easy to solve. Since g\u0304 is affine with respect to the individual entries of the kernel matrix, it is also affine in the entries of \u03b8, which leads to the following optimization problem:\nmin \u03b8 c\u2032\u03b8 s.t. lu(x) = 0,\u2200u; rv(x) \u2264 0,\u2200v. (15)\nwhere c is a coefficient vector. For many practical models, the feasible regions of Problem (15) are such that a closed-form solution can be found. For example, in the case of an Lp-norm constrained (single-task) MKL\nmodel, the feasible region is defined by the constraints \u2016\u03b8\u2016p \u2264 1,\u03b8 0, for which a closed-form solution can be found. Another example is the setting considered in [18], which is of the form of Problem (12) and becomes\nmin \u03b8 c\u2032\u03b8 s.t. \u03b8tm = \u03b6m + \u03b3 t m, \u03b6m \u2265 0, \u03b3tm \u2265 0,\u2200m, t;\nM\u2211 m=1 \u03b8tm = 1, \u2200t; M\u2211 m=1 T\u2211 t=1 \u03b3tm \u2264 \u03b2.\n(16)\nRegarding the just-stated problem, a block coordinate descent algorithm can be employed to optimize \u03b6 = [\u03b61, \u00b7 \u00b7 \u00b7 , \u03b6M ] and \u03b3 = [\u03b31 \u2032 , \u00b7 \u00b7 \u00b7 ,\u03b3T \u2032]\u2032. Each sub-problem features a linear objective function with an L1-norm constraint, and, hence, a closed-form solution can be found. Obviously, doing so is much simpler than relying on cutting-plane algorithms employed by the authors. Finally, a closed-form solution can be obtained for an Lp \u2212 Lq-norm constraint as well. Proposition 1 offers closed-form solutions for problems featuring a linear objective with a Lp-norm or a Lp \u2212 Lq-norm constraint.\nProposition 1. Let c , [c1, \u00b7 \u00b7 \u00b7 , cn]\u2032 \u2208 Rn be the concatenation of T vectors c1 \u2208 Rn1 , \u00b7 \u00b7 \u00b7 , cT \u2208 RnT with \u2211T t=1 nt = n. Suppose that, for t = 1, \u00b7 \u00b7 \u00b7 , T , each ct has at least one negative element. Similarly, let \u03b8 , [\u03b81, \u00b7 \u00b7 \u00b7 , \u03b8n] \u2208 Rn be the concatenation of \u03b81 \u2208 Rn1 , \u00b7 \u00b7 \u00b7 ,\u03b8T \u2208 RnT . The optimization problem\nmin \u03b8\u2208Rn\nc\u2032\u03b8\ns.t. \u03b8 0, ( T\u2211 t=1 \u2016\u03b8t\u2016qp)1/q \u2264 a (17)\nhas closed-form solution  \u03b8\u0302 t = \u03c3 t(c\u0303t)r \u2016c\u0303t\u2016rr+1 , \u2200t, p > 1, q > 1 \u03b8\u0302 t = a(c\u0303 t)r \u2016c\u0303t\u2016rr+1 [t = t0], \u2200t, p > 1, q = 1 \u03b8\u0302 = a(c\u2217) s \u2016c\u2217\u2016ss+1 , p = 1, q > 1\n\u03b8\u0302 = aej , p = 1, q = 1\n(18)\nwhere \u03c3t , a\u2016c\u0303t\u2016sr+1 ( \u2211T\nt=1 \u2016c\u0303t\u2016 s+1 r+1)\n1/q , [t = t0] = 1, if t = t0, and equals 0, if otherwise, t0 , arg mint {\u2016c\u0303t\u2016r+1}, r ,\n1 p\u22121 , s , 1 q\u22121 , c\u0303 t is a vector with elements [max{\u2212ctm, 0}]Mm=1 and (c\u0303t)r denotes element-wise exponentiation of vectors. Also, c\u2217 represents the concatenation of ct\u2217 , c\nt \u25e6 etit , t = 1, \u00b7 \u00b7 \u00b7 , T , where \u25e6 is element-wise multiplication of vectors and etit \u2208 R nt is a vector, whose it-th entry is 1, while the remaining are 0, and it , arg mini{cti}. Moreover, ej is an all-0 vector except that its j-th entry equals 1, where j , arg mini{ci}. Finally, if \u2203 t such that ct 0, then \u03b8\u0302 t = 0.\nThe proof of the above proposition is given in Section .3 of the Appendix. It is worth mentioning that, based on Proposition 1, true within-task sparsity is only achieved, when p = 1. Similarly, true sparsity across tasks is only obtained, when q = 1. Therefore, depending on the desired type of sparsity, different parameter settings should be applied. For example, if within-task sparsity is desired, an L1 \u2212 L2 norm with p = 1 and q = 2 can be utilized, as discussed in [6].\nFor a non-concave g\u0304, but one that has a finite number of local maxima with respect to \u03b1 given xk, based on Theorem 2, we only need to solve N(xk) problems that are similar to Problem (12), which in most cases have closed-form solutions, as stated earlier.\nBased on the above analysis, it is not difficult to see that, when a closed-form solution can be found in the second step, the complexity of our algorithm in each iteration is dominated by the complexity of the solver of the first step, such as the SVM, SVDD solver, etc. The time complexity of LIBSVM for solving a SVM or SVDD problem is given in [2]. A KRR-based model, as stated earlier, can be solved in constant time. Therefore, if the second step has a closed-form solution, then the complexity of each iteration for\nsuch model is O(1). Unsurprisingly, we observed in practice that our algorithm is usually slower than the special algorithms that are tailored to each specific problem type. For example, for single-task MKL with an Lp-norm constraint as discussed in [24], a block coordinate descent algorithm is used, which is equivalent to our algorithm with step length equal to 1, when our algorithm is adapted to solve this model. Thus, since our algorithm initializes the step length to be a small value, it is not a surprise that our algorithm is slower. However, if the step length of our algorithm is initialized to 1, both of the two methods are exactly the same. Additionally, for solving the model that is proposed in [18], when 500 samples from the USPS data set are used for training, our algorithm takes on average 9 seconds to train the model, while the algorithm proposed in [18] takes 7 seconds. As expected, the advantages of our algorithm, namely its simplicity in terms of implementation and its generality are offset by a somewhat reduced computational efficiency, when compared to highly specialized algorithms that are designed to solve very specific problems."}, {"heading": "5 The Partially Shared Common Space Model", "text": "To demonstrate the flexibility of our framework and the capability of the associated algorithm, in this section we propose a Partially-Shared Common Space (PSCS) model for Multi-Task MKL as a novel concrete instance of our framework. As stated earlier, in MTL, several tasks sharing a common feature representation are trained simultaneously. For Multi-Task MKL, it is a natural choice to let all tasks share a common kernel function by letting \u03b8tm = \u03b6m,\u2200 t (see Section 2). However, in practice, there may be some problems, for which sharing a common space is not the optimal choice. For example, an MTL problem may include a few complex tasks, but also some much simpler ones. In this situation, it may be difficult to find a common feature mapping so that all tasks perform well. Therefore, it is meaningful to let complex tasks to use their own task-specific space, while allowing the remaining tasks to share a common space. Motivated by this consideration, we introduce the PSCS problem formulation shown below:\nmin \u03b8,\u03b6,\u03b3 max a\u2208\u2126(a) T\u2211 t=1 g\u0304(\u03b1t, M\u2211 m=1 \u03b8tmK t m) s.t. \u03b8tm = \u03b6m + \u03b3 t m, \u2200m, t; \u03b6 0, \u2016\u03b6\u2016p \u2264 1, p \u2265 1; \u03b3 0, ( T\u2211 t=1 \u2016\u03b3t\u2016qp)1/q \u2264 1, p \u2265 1, q \u2265 1.\n(19)\nThe feasible region of \u03b8 is chosen to meet our objectives: the Lp-norm constraint controls the sparsity of the common-space coefficients \u03b6, while the Lp\u2212Lq-norm constraint controls the within-group and group-wise sparsity. Choosing q = 1 induces sparcity on \u03b3 (group-wise sparsity), which will force most tasks to share a common feature space.\nDue to the complicated nature of the constraints, it is far from straightforward to devise a simple, tailored algorithm to solve the PSCS model. However, Algorithm 1 can be readily applied. In each iteration, T kernel machines are first trained. Next, the minimization with respect to \u03b8 can be accomplished via block coordinate descent to optimize \u03b6 as a block and \u03b3 as another block. In addition, the closed-form solution for \u03b8 and \u03b3 can be easily determined by Proposition 1."}, {"heading": "6 Experimental Results", "text": "In the following subsections, we experimentally evaluate our PSCS model on classification tasks. To apply our framework for classification tasks, the objective function g\u0304 is specified as the dual-domain objective function for SVM training:\nT\u2211 t=1 g\u0304(\u03b1t, M\u2211 m=1 \u03b8tmK t m) = T\u2211 t=1 (\u03b1t \u2032 1\u2212\u03b1t\u2032Y t( M\u2211 m=1 \u03b8tmK t m)Y t\u03b1t) (20)\nNote that all kernel functions in our experiments are used in their normalized form as k(x,y)\u221a k(x,x)k(y,y) ."}, {"heading": "6.1 A qualitative case study", "text": "To qualitatively illustrate the potential of our framework, in this subsection we apply our approach to the well-known Iris Flower classification problem, which we will recast as a MTL problem. The associated data set includes 150 patterns, each of which comes from one of three Iris flower classes: Setosa, Versicolour and Virginica (respectively, class 1, 2 and 3). Each of these 3 classes is represented by 50 samples and every sample has 4 attributes corresponding to the width and length of the flower\u2019s sepal and pedal. We chose only two attributes, namely the sepal width and length, to form a 2-dimensional data set, such that the distribution of patterns and the resulting decision boundaries can be visualized. Note that each attribute is normalized to [0, 1]. We split the three-class problem into three binary classification tasks by employing a one-against-one strategy. Specifically, these are: task 1 (class 1 vs. class 2), task 2 (class 1 vs. class 3), task 3 (class 2 vs. class 3). The data sets of task 1 and 2 are linearly separable, so it is desirable to obtain classifiers which will produce linear or almost-linear decision boundaries. On the other hand, the data set of task 3 is not linearly separable. Intuitively, one would expect a reasonable solution to have tasks 1 and 2 share a common feature space, while allowing task 3 to be mapped into an alternative, task-specific feature space.\nFor the purpose of this experiment, we employed Linear kernels, Polynomial kernels of degree 2, and Gaussian kernels using a spread parameter value of 5. All 150 patterns were used for training. The p parameter was set to 2 for non-sparse kernel combination, because we want to see how different tasks affect the weights of each kernel function. Additionally, q is set to 1, because we want to achieve inter-task sparsity for \u03b3, i.e. some tasks share a common space specified by \u03b6. The experimental results are shown in Table 1 and Figure 1.\nTable 1: Learned coefficients for the Iris classification multi-task problem\nKernel \u03b6 \u03b31 \u03b32 \u03b33\nLinear 0.1828 0 0 0.0295 Polynomial 0.9421 0 0 0.1976 Gaussian 0.2812 0 0 0.9333\nSepal Length\nS ep\nal W\nid th\n0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nTask 1 Task 2 Task 3 Class 1 Class 2 Class 3\nFigure 1: Decision boundaries of Iris classification multi-task problem.\nIt can be seen in Table 1 that all three elements in \u03b31 and \u03b32 are zero. This means that task 1 and 2 share a common space, which is specified by \u03b6 = [0.1828, 0.9421, 0.2812]. Obviously, in the common space, the combination of Linear and Polynomial kernels has a large weight, while the Gaussian kernel plays an insignificant role. The reason behind this is that the data for tasks 1 and 2 are both linearly separable,\nso the SVM can easily find effective boundaries in the original space and the feature space implied by the Polynomial kernel. Also, we can observe that the polynomial kernel has larger weight than the linear kernel. This is because the data in the feature space induced by the polynomial kernel offers a larger margin than in the case of the original space. Note that, even though the polynomial kernel does not imply a linear feature map, the decision boundary is almost a straight line. This implies that the mapping corresponding to the polynomial kernel is almost linear in this particular case. Unlike tasks 1 and 2, we can see from the table that the task-specific feature space for task 3 has a large weight corresponding to the Gaussian kernel. This is because the data for task 3 are not linearly separable, and therefore it is difficult for the associated SVM to find a good decision boundary in the original space and the feature space implied by the Polynomial kernel. A large weight corresponding to the Gaussian kernel implies that the classifier was able to find a better decision boundary in its associated infinite-dimensional feature space. The relevant decision boundaries can be seen in Figure 1. As expected, the decision boundaries for tasks 1 and 2 are almost linear, while task 3 features a non-linear decision boundary."}, {"heading": "6.2 Quantitative Analysis on Benchmark Problems", "text": "In this subsection we first evaluate our SVM-based PSCS method using 6 benchmark multi-class data sets obtained from the UCI repository [5]. Each associated recognition problem was cast as a multi-task classification problem by using the one-against-all approach. This is an effective method to test multi-task models; for example, refer to [9] and [26]. More specifically, we used the USPS Handwritten Digit (USPS ), MNIST Handwritten Digit (MNIST ), Wall-Following Robot Navigation (Robot), Statlog Shuttle (Shuttle), Statlog Vehicle Silhouettes (Vehicle), and Letter Recognition (Letter) data sets. For each data set, each class is represented by an equal number of samples. An exception is the original Shuttle data set that has seven classes, four of which are very poorly represented; for this data set we only chose data from the other three classes. Finally, for the Letter data set, we only chose the first 10 classes to avoid handling a large number tasks.\nFor all experiments, the kernel and algorithm parameter settings were held fixed. Twenty experiments were conducted for each setting and the average correct classification accuracy was recorded. Linear, Polynomial, and Gaussian kernels with spread parameter values { 20, 21, 22, 23, 24, 25, 26, 27 } were used. Regarding p, we held it fixed to 1.1, as we were not concerned with obtaining within-group sparsity. Cross-validation was employed to choose values for parameters C and q. We allowed C to vary over {1/27, 1/9, 1/3, 1, 3, 9, 27} and q ranged from 1.0 to 2.0 with a step size of 0.1. We did not consider the case, where q > 2, since these values would yield a non-sparse group-wise \u03b3 vector, which was not deemed desirable.\nThe PSCS model was compared to the CS and IS methods, which have been described in Section 2. The experimental settings for the CS and IS methods were exactly the same as the settings used for PSCS, except that there was no parameter q to be tuned for them. We considered training set sizes of 2%, 5%, 20% and 50% of the original data set to study the effect of training set size on classification accuracy. The rest of the data were split in half to form validation and test sets.\nWe report the experimental results (average classification accuracy of 20 runs over randomly sampled training set) in Table 2, where the best performance is highlighted in boldface. To test the statistical significance of the differences between the best performing method and the rest, we employed a t-test to compare mean accuracies using a significance level of \u03b1 = 0.05. Furthermore, we use two superscripts for each PSCS-related result to convey information about statistically significant differences in performance. The first sign refers to the comparison of PSCS to CS and the second one to the comparison to IS. A \u2018+\u2019 sign means that the PSCS performance is significantly better, and a \u2018=\u2019 sign indicates that there is no statistically significant difference.\nIt can be seen from Table 2 that, for small training set sizes (2% and 5%), the PSCS method is almost always better in terms of classification accuracy compared to the CS and IS approaches and that most of the differences are statistically significant. In other words, there are learning tasks that, in practice, may benefit from partially sharing a common feature space. Additionally, for all three methods considered, as the training set size increases to 20% or higher, their performance tends to be similar for most data sets; PSCS seems to perform significantly better only for the Vehicle data set. It appears that, when the training set is large enough, each task independently can be trained well, while sharing a common space among tasks helps little to further enhance performance.\nIn what follows we compare the PSCS method to the CS and IS approaches on two widely-used multi-task classification data sets, namely the Letter and Landmine data sets. The Letter data set1 is a collection of handwritten words compiled by Rob Kassel of the MIT Spoken Language Systems Group. The associated MTL problem involves 8 tasks, each of which is a binary classification problem. The 8 tasks are: \u2018C\u2019 vs. \u2018E\u2019, \u2018G\u2019 vs. \u2018Y\u2019, \u2018M\u2019 vs. \u2018N\u2019, \u2018A\u2019 vs. \u2018G\u2019, \u2018I\u2019 vs. \u2018J\u2019, \u2018A\u2019 vs. \u2018O\u2019, \u2018F\u2019 vs. \u2018T\u2019 and \u2018H\u2019 vs. \u2018N\u2019. Each letter is represented by a 8\u00d7 16 pixel image, hence by a 128 dimensional feature vector. The goal for this problem is to correctly recognize the letters in each task. For this data set, our intention was to compare the performance of the three models on large data sizes. Therefore, we chose 1000 samples from each class, so that each task had 2000 training samples. Note that, due to insufficient data for classes \u2018J\u2019, \u2018H\u2019 and \u2018F\u2019, our multi-task recognition problem considered only five of the eight tasks.\nOn the other hand, the Landmine data set2 consists of 29 binary classification tasks. Each datum is a 9-dimensional feature vector extracted from radar images that capture a single region, which may contain a landmine field. The 9 features include four moment-based features, three correlation-based features, one energy ration feature and one spatial variance feature [25]. Tasks 1\u221215 correspond to regions with relatively high foliage, while the other 14 tasks correspond to regions that are bare earth or desert. The tasks entail different amounts of data, varying from 30 to 96 samples. The goal is to classify regions as ones containing landmine fields or not.\nThe experimental setting for these two problems were the same as previous experiments, except that we did not use 2% and 5% of the Landmine data set for training, due to the small size of the data set. Instead, we started from 20% and increased the training set size in steps of 10%. Also, for the Letter data set, in order to show results for a wider range of training set sizes, we chose 0.2%, 0.5%, 5% and 50% of the data set for training.\nThe experimental results are displayed in Table 3, from which it can be observed that the experimental results are consistent with the ones obtained in the previous subsection. The PSCS method can improve the classification accuracy significantly, when the training set size is relatively small, while in the case of large training sets, the improvements are not statistically significant. In the latter situation, all three methods perform similarly.\nIt is also worth mentioning that, by using our proposed algorithm, all three models have the same asymptotic computation complexity. Obviously, in each iteration, all three models solve the same T SVM problems followed by solving Problem (12). Obviously, the former step differs for each method; Problem (12) has a closed-form solution based on Proposition 1 for each of the models. Therefore, the computational complexity per iteration is common among them and is dominated by the complexity of solving the T SVM problems.\nOn balance, since PSCS has no worse asymptotic runtime complexity, when compared to the IS and CS approaches, and since it offers a performance advantage in cases of sample scarcity, the use of PSCS seems much preferable over the IS and CS formulations.\n1Available at: http://multitask.cs.berkeley.edu/ 2Available at: http://people.ee.duke.edu/~lcarin/LandmineData.zip"}, {"heading": "7 Conclusions", "text": "In this paper, we proposed a Multi-Task Multi-Kernel Learning (Multi-Task MKL) framework, which is formulated as a min-max problem and which subsumes a broad class of kernel-based learning problems. We showed that our formulation can be optimized by solving an Exact Penalty Function (EPF) optimization problem. Subsequently, we derived a simple algorithm to solve it, which, for some frequently-used learning tasks, is able to leverage from existing efficient solvers or from closed-form solutions. The availability of this algorithm eliminates the need of using existing, potentially much sophisticated, algorithms or devising algorithms that are specifically tailored to the problem at hand.\nIn order to illustrate the utility of this novel framework and associated algorithm, we devised the PartiallyShared Common Space (PSCS) Multi-Task MKL model as a special case of our framework, which allows some tasks to share a common feature space, while other tasks are allowed to be appropriately associated to their own task-specific feature spaces. Results obtained from experimenting with a collection of classification tasks demonstrated performance advantages of the PSCS formulation, especially in the case, where the amount of training data is limited."}, {"heading": "Acknowledgements", "text": "C. Li acknowledges partial support from National Science Foundation (NSF) grant No. 0806931 and No. 0963146. Moreover, M. Georgiopoulos acknowledges partial support from NSF grants No. 0525429, No. 0963146, No. 1200566 and No. 1161228. Finally, G. C. Anagnostopoulos acknowledges partial support from NSF grant No. 0647018. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the NSF. Finally, the authors would like to thank the anonymous reviewers of this manuscript for their time and helpful comments."}], "references": [{"title": "Variable sparsity kernel learning", "author": ["Jonathan Aflalo", "Aharon Ben-Tal", "Chiranjib Bhattacharyya", "Jagarlapudi Saketha Nath", "Sankaran Raman"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2011}, {"title": "LIBSVM: A library for support vector machines", "author": ["Chih-Chung Chang", "Chih-Jen Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "l2 regularization for learning kernels", "author": ["Corinna Cortes", "Mehryar Mohri", "Afshin Rostamizadeh"], "venue": "In UAI,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "A note on the group lasso and a sparse group lasso", "author": ["J. Friedman", "T. Hastie", "R. Tibshirani"], "venue": "ArXiv e-prints,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "Multiple kernel learning algorithms", "author": ["Mehmet Gonen", "Ethem Alpaydin"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "Clustered multi-task learning: a convex formulation", "author": ["Laurent Jacob", "Francis Bach", "Jean-Philippe Vert"], "venue": "In NIPS,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "Multitask sparsity via maximum entropy discrimination", "author": ["Tony Jebara"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "Learning with whom to share in multi-task feature learning", "author": ["Zhuoliang Kang", "Kristen Grauman", "Fei Sha"], "venue": "In ICML,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Non-sparse multiple kernel learning", "author": ["Marius Kloft", "Ulf Brefeld", "Pavel Laskov", "Soren Sonnenburg"], "venue": "In NIPS Workshop on Kernel Learning: Automatic Selection of Optimal Kernels,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "Efficient and accurate lp-norm multiple kernel learning", "author": ["Marius Kloft", "Ulf Brefeld", "Soren Sonnenburg", "Pavel Laskov", "Klaus-Robert Muller", "Alexander Zien"], "venue": "In NIPS,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Learning the kernel matrix with semidefinite programming", "author": ["Gert R.G. Lanckriet", "Nello Cristianini", "Peter Bartlett", "Laurent El Ghaoui", "Michael I. Jordan"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2004}, {"title": "lp\u2212lq penalty for sparse linear and sparse multiple kernel multitask learning", "author": ["Alain Rakotomamonjy", "Remi Flamary", "Gilles Gasso", "Stephane Canu"], "venue": "IEEE Transactions on Neural Networks,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2011}, {"title": "Ridge regression learning algorithm in dual variables", "author": ["Craig Saunders", "Alexander Gammerman", "Volodya Vovk"], "venue": "In ICML,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1998}, {"title": "Estimating the support of a high-dimensional distribution", "author": ["Bernhard Sch\u00f6lkopf", "John C. Platt", "John Shawe-Taylor", "Alex J. Smola"], "venue": "Neural Computation,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2001}, {"title": "On multiple kernel learning with multiple labels", "author": ["Lei Tang", "Jianhui Chen", "Jieping Ye"], "venue": "In IJCAI,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "Support vector domain description", "author": ["David M.J. Tax", "Robert P.W. Duin"], "venue": "Pattern Recognition Letters,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1999}, {"title": "Globally convergent methods for semi-infinite programming", "author": ["G.A. Watson"], "venue": "BIT Numerical Mathematics,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1981}, {"title": "Multi-task multiple kernel learning (MT-MKL)", "author": ["Christian Widmer", "Nora C. Toussaint", "Yasemin Altun", "Gunnar Ratsch"], "venue": "In NIPS 2010 Workshop: New Directions in Multiple Kernel Learning,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2010}, {"title": "Soft margin multiple kernel learning", "author": ["Xinxing Xu", "I.W. Tsang", "Dong Xu"], "venue": "IEEE Transactions on Neural Networks and Learning Systems,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2013}, {"title": "Simple and efficient multiple kernel learning by group lasso", "author": ["Zenglin Xu", "Rong Jin", "Haiqin Yang", "Irwin King", "Michael R. Lyu"], "venue": "In ICML,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2010}, {"title": "Multi-task learning for classification with dirichlet process priors", "author": ["Ya Xue", "Xuejun Liao", "Laurence Carin", "Balaji Krishnapuram"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2007}], "referenceMentions": [{"referenceID": 10, "context": "According to the Multi-Kernel Learning (MKL) approach [13], which is one of the most popular strategies for learning kernels, multiple predetermined kernels are, most commonly, linearly combined.", "startOffset": 54, "endOffset": 58}, {"referenceID": 4, "context": "A thorough review of MKL methods and associated algorithms is provided in [7].", "startOffset": 74, "endOffset": 77}, {"referenceID": 10, "context": "The earlier work in [13] suggests a MKL formulation with trace constraints over the linearly combined kernels, which is further transformed into a solvable Semi-Definite Programming problem.", "startOffset": 20, "endOffset": 24}, {"referenceID": 18, "context": "A similar algorithm is also applied in [23].", "startOffset": 39, "endOffset": 43}, {"referenceID": 8, "context": "In [11], an L2-norm constraint is applied to the linear combination coefficients and the proposed min-max formulation is transformed into a Semi-Infinite Programming (SIP) problem, which is then solved via a cutting plane algorithm.", "startOffset": 3, "endOffset": 7}, {"referenceID": 9, "context": "Moreover, two algorithms are proposed in [12] to solve the Lp-MKL formulation, where the coefficient constraint is generalized to an Lp-norm constraint.", "startOffset": 41, "endOffset": 45}, {"referenceID": 19, "context": "that entails a Group-Lasso regularizer is pointed out in [24], which utilizes a block coordinate descent algorithm to solve the problem in the primal domain.", "startOffset": 57, "endOffset": 61}, {"referenceID": 12, "context": "Besides MKL-based SVM models, a MKL formulation for Kernel Ridge Regression (KRR)[16] has been proposed in [3].", "startOffset": 81, "endOffset": 85}, {"referenceID": 2, "context": "Besides MKL-based SVM models, a MKL formulation for Kernel Ridge Regression (KRR)[16] has been proposed in [3].", "startOffset": 107, "endOffset": 110}, {"referenceID": 14, "context": "For example, a framework is formulated in [18], where individual tasks utilize their own task-specific space in conjunction with a shared space component, while the balance between these two components is controlled through weights.", "startOffset": 42, "endOffset": 46}, {"referenceID": 0, "context": "Additionally, in [1], a Group-Lasso regularizer on SVM weights is considered that yields coefficient sparsity within a group of tasks and non-sparse regularization across groups.", "startOffset": 17, "endOffset": 20}, {"referenceID": 11, "context": "Also, in [15], the Group-Lasso regularizer is generalized to Lp \u2212 Lq regularization and two optimization problems are addressed, one being convex and the other non-convex.", "startOffset": 9, "endOffset": 13}, {"referenceID": 17, "context": "Furthermore, in [22], Multi-Task MKL is formulated in the primal domain by penalizing the SVM weight of each task to be close to a shared common weight.", "startOffset": 16, "endOffset": 20}, {"referenceID": 6, "context": "Finally, maximum entropy discrimination is employed in [9] to construct a Multi-Task MKL framework.", "startOffset": 55, "endOffset": 58}, {"referenceID": 13, "context": "Its unifying character stems from its applicability to prominent kernel-based tasks, such as SVM-based binary classification, KRRbased regression and outlier detection based on One-Class SVM [17] and Support Vector Domain Description (SVDD) [19], to name a few important ones.", "startOffset": 191, "endOffset": 195}, {"referenceID": 15, "context": "Its unifying character stems from its applicability to prominent kernel-based tasks, such as SVM-based binary classification, KRRbased regression and outlier detection based on One-Class SVM [17] and Support Vector Domain Description (SVDD) [19], to name a few important ones.", "startOffset": 241, "endOffset": 245}, {"referenceID": 8, "context": "For example, it subsumes L2-MKL and Lp-MKL considered in [11] and [12], the KRR-based MKL in [3] and the Multi-Task MKL formulations in [18] and [15].", "startOffset": 57, "endOffset": 61}, {"referenceID": 9, "context": "For example, it subsumes L2-MKL and Lp-MKL considered in [11] and [12], the KRR-based MKL in [3] and the Multi-Task MKL formulations in [18] and [15].", "startOffset": 66, "endOffset": 70}, {"referenceID": 2, "context": "For example, it subsumes L2-MKL and Lp-MKL considered in [11] and [12], the KRR-based MKL in [3] and the Multi-Task MKL formulations in [18] and [15].", "startOffset": 93, "endOffset": 96}, {"referenceID": 14, "context": "For example, it subsumes L2-MKL and Lp-MKL considered in [11] and [12], the KRR-based MKL in [3] and the Multi-Task MKL formulations in [18] and [15].", "startOffset": 136, "endOffset": 140}, {"referenceID": 11, "context": "For example, it subsumes L2-MKL and Lp-MKL considered in [11] and [12], the KRR-based MKL in [3] and the Multi-Task MKL formulations in [18] and [15].", "startOffset": 145, "endOffset": 149}, {"referenceID": 20, "context": "Some examples include the works in [25], [8], [10] and [26], to name a few.", "startOffset": 35, "endOffset": 39}, {"referenceID": 5, "context": "Some examples include the works in [25], [8], [10] and [26], to name a few.", "startOffset": 41, "endOffset": 44}, {"referenceID": 7, "context": "Some examples include the works in [25], [8], [10] and [26], to name a few.", "startOffset": 46, "endOffset": 50}, {"referenceID": 9, "context": "For example, for T = 1 it can specialize to Lpnorm MKL [12], where p \u2265 1, by using \u03a8(\u03b8) = {\u03b8 : \u2016\u03b8\u2016p \u2264 1,\u03b8 0}.", "startOffset": 55, "endOffset": 59}, {"referenceID": 8, "context": "Obviously, the L2-norm MKL [11] is also covered by our framework.", "startOffset": 27, "endOffset": 31}, {"referenceID": 14, "context": "Additionally, it can express the Multi-Task MKL model in [18] that allows individual tasks to utilize their own task-specific space in conjunction with a shared space component.", "startOffset": 57, "endOffset": 61}, {"referenceID": 0, "context": "To mention a final example, a Group-Lasso type regularizer is employed on the SVM primal-domain weights in [1], which leads to intricate optimization problems and algorithms.", "startOffset": 107, "endOffset": 110}, {"referenceID": 16, "context": "Before solving Problem (7), we first show an equivalence between EPF-based problems [21] and general SIP problems.", "startOffset": 84, "endOffset": 88}, {"referenceID": 16, "context": "Then, the EPF P (x) introduced in [21] is defined in a neighborhood of x as:", "startOffset": 34, "endOffset": 38}, {"referenceID": 16, "context": "We refer the interested reader to [21] for more details about EPFs.", "startOffset": 34, "endOffset": 38}, {"referenceID": 16, "context": "In order to solve Problem (10), a descent algorithm is suggested in [21].", "startOffset": 68, "endOffset": 72}, {"referenceID": 16, "context": "In [21] it is proven that, for sufficiently large \u03bd and sufficiently small step length > 0, the limit point of {xk} is a KKT point of Problem (8), if the sequence {dk} is bounded and the sequence {xk} remains in a bounded region, in which f and g are doubly-differentiable functions with bounded second-order derivatives.", "startOffset": 3, "endOffset": 7}, {"referenceID": 16, "context": "As suggested in [21], one possibility is to choose k as the largest element of the set {1, \u03b2, \u03b2, \u00b7 \u00b7 \u00b7 }, for some \u03b2, 0 < \u03b2 < 1, such that [P (xk + kdk)\u2212 P (xk)]/ kGk \u2265 \u03c3 (13) where P is the EPF given in Problem (10), \u03c3 is some constant that satisfies 0 < \u03c3 < 1, and Gk is the directional derivative of P with respect to x at the k-th step.", "startOffset": 16, "endOffset": 20}, {"referenceID": 14, "context": "Secondly, the maximization problem with respect to a in the first step of the algorithm can be separated into T independent problems under the commonly-encountered setting, where the feasible regions of the \u03b1\u2019s are mutually independent, such as in the formulations of [18] and [15].", "startOffset": 268, "endOffset": 272}, {"referenceID": 11, "context": "Secondly, the maximization problem with respect to a in the first step of the algorithm can be separated into T independent problems under the commonly-encountered setting, where the feasible regions of the \u03b1\u2019s are mutually independent, such as in the formulations of [18] and [15].", "startOffset": 277, "endOffset": 281}, {"referenceID": 1, "context": "Furthermore, in most situations, solving each of the T problems can be addressed via readily-available efficient optimizers; for example, in the case of SVM problems, one could use LIBSVM [2].", "startOffset": 188, "endOffset": 191}, {"referenceID": 14, "context": "Another example is the setting considered in [18], which is of the form of Problem (12) and becomes", "startOffset": 45, "endOffset": 49}, {"referenceID": 3, "context": "For example, if within-task sparsity is desired, an L1 \u2212 L2 norm with p = 1 and q = 2 can be utilized, as discussed in [6].", "startOffset": 119, "endOffset": 122}, {"referenceID": 1, "context": "The time complexity of LIBSVM for solving a SVM or SVDD problem is given in [2].", "startOffset": 76, "endOffset": 79}, {"referenceID": 19, "context": "For example, for single-task MKL with an Lp-norm constraint as discussed in [24], a block coordinate descent algorithm is used, which is equivalent to our algorithm with step length equal to 1, when our algorithm is adapted to solve this model.", "startOffset": 76, "endOffset": 80}, {"referenceID": 14, "context": "Additionally, for solving the model that is proposed in [18], when 500 samples from the USPS data set are used for training, our algorithm takes on average 9 seconds to train the model, while the algorithm proposed in [18] takes 7 seconds.", "startOffset": 56, "endOffset": 60}, {"referenceID": 14, "context": "Additionally, for solving the model that is proposed in [18], when 500 samples from the USPS data set are used for training, our algorithm takes on average 9 seconds to train the model, while the algorithm proposed in [18] takes 7 seconds.", "startOffset": 218, "endOffset": 222}, {"referenceID": 0, "context": "Note that each attribute is normalized to [0, 1].", "startOffset": 42, "endOffset": 48}, {"referenceID": 6, "context": "This is an effective method to test multi-task models; for example, refer to [9] and [26].", "startOffset": 77, "endOffset": 80}, {"referenceID": 20, "context": "The 9 features include four moment-based features, three correlation-based features, one energy ration feature and one spatial variance feature [25].", "startOffset": 144, "endOffset": 148}], "year": 2014, "abstractText": "Over the past few years, Multi-Kernel Learning (MKL) has received significant attention among data-driven feature selection techniques in the context of kernel-based learning. MKL formulations have been devised and solved for a broad spectrum of machine learning problems, including Multi-Task Learning (MTL). Solving different MKL formulations usually involves designing algorithms that are tailored to the problem at hand, which is, typically, a non-trivial accomplishment. In this paper we present a general Multi-Task Multi-Kernel Learning (Multi-Task MKL) framework that subsumes well-known Multi-Task MKL formulations, as well as several important MKL approaches on single-task problems. We then derive a simple algorithm that can solve the unifying framework. To demonstrate the flexibility of the proposed framework, we formulate a new learning problem, namely Partially-Shared Common Space (PSCS) Multi-Task MKL, and demonstrate its merits through experimentation.", "creator": "LaTeX with hyperref package"}}}