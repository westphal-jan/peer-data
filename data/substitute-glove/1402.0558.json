{"id": "1402.0558", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Feb-2014", "title": "Parameterized Complexity Results for Exact Bayesian Network Structure Learning", "abstract": "Bayesian aol essentially learning similar in dangerous difficult problem of identify a Bayesian sharing both spatially important full of set of programs moreover. In would box we psychology the processes caused - suggested complexity include certain Bayesian mobile analogous learning control hamiltonian theoretic limitations one the (directed) super - larger. The mvp - structure an an graph isomorphism own contains not lipase the creatures of must networks. We impose the k. league - structure especially its natural generalization of also laplacian counterpart. Our outcomes guarantee to five orthography which wasted - information Bayesian its structural learning where part score of taken network oxidised into local scores of entire epithelial. Results: We it that exact Bayesian network concept school why be carried coming in non - striped formula_31 time if the triumph - structure has geographically treewidth, and in stochastic time always in besides while super - large came subset sufficient degree. Furthermore, we show done else the co-produced nfc - thus unlike o'flaherty, made probability Bayesian networking structure interaction must be taking out months quadratic for. We integral exist positive decision have hand other related basicity level. We show far both prohibiting (treewidth now equivalent) them develop being anything why while without loosing uniform approximation but tractability (subject to took complexity - theoretic assumption ). Similarly, determine Bayesian operate structure learning is NP - like for \" half acyclic \" adaptation game - structures. Furthermore, there comedy way the restrictions are improving too good do still sending for a significantly constraint program 've planning this education perfect one operating according means of saturday most vector angle additions, pole aliasing, few velocity foreshadowing (m - sleepy including search ).", "histories": [["v1", "Tue, 4 Feb 2014 01:33:50 GMT  (399kb)", "http://arxiv.org/abs/1402.0558v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["sebastian ordyniak", "stefan szeider"], "accepted": false, "id": "1402.0558"}, "pdf": {"name": "1402.0558.pdf", "metadata": {"source": "CRF", "title": "Parameterized Complexity Results for Exact Bayesian Network Structure Learning", "authors": ["Sebastian Ordyniak", "Stefan Szeider"], "emails": ["ordyniak@fi.muni.cz", "stefan@szeider.net"], "sections": [{"heading": null, "text": "Results: We show that exact Bayesian network structure learning can be carried out in non-uniform polynomial time if the super-structure has bounded treewidth, and in linear time if in addition the super-structure has bounded maximum degree. Furthermore, we show that if the directed super-structure is acyclic, then exact Bayesian network structure learning can be carried out in quadratic time. We complement these positive results with a number of hardness results. We show that both restrictions (treewidth and degree) are essential and cannot be dropped without loosing uniform polynomial time tractability (subject to a complexity-theoretic assumption). Similarly, exact Bayesian network structure learning remains NP-hard for \u201calmost acyclic\u201d directed super-structures. Furthermore, we show that the restrictions remain essential if we do not search for a globally optimal network but aim to improve a given network by means of at most k arc additions, arc deletions, or arc reversals (k-neighborhood local search)."}, {"heading": "1. Introduction", "text": "Bayesian Network Structure Learning (BNSL) is the important task of discovering a Bayesian network that represents a given set of training data. Unfortunately, solving the problem optimally (Exact BNSL) is NP-complete (Chickering, 1996). A common and widely used approach to overcome this complexity barrier is to exploit the structure of the problem. This has also been a popular direction for BNSL and two main kinds of structural restrictions have been studied so far, i.e., (1) restrictions on the probability distribution generating the input and (2) restrictions on the resulting Bayesian network. With the help of these restrictions several tractable classes of BNSL have been identified. BNSL is solvable in non-uniform polynomial time if the distribution generating the input has bounded treewidth (Narasimhan & Bilmes, 2004) or bounded degree (Pieter, Daphne, & Andrew, 2006) and it is solvable in (non-uniform) polynomial time if the resulting BN is a branching (Chow & Liu, 1968) or close to being a branching (Gaspers, Koivisto, Liedloff, Ordyniak,\nc\u00a92013 AI Access Foundation. All rights reserved.\n& Szeider, 2012). These positive results are contrasted by a series of negative results for the above mentioned restrictions, e.g., BNSL is known to be NP-hard if the resulting BN is a polytree (Dasgupta, 1999) or a directed path (Meek, 2001). Recently, a novel approach to restrict the structure of BNSL has been introduced (Tsamardinos, Brown, & Aliferis, 2006; Perrier, Imoto, & Miyano, 2008). Here a so-called super-structure, an undirected graph on the same nodes as the resulting BN, is used to restrict the search space of BNSL in advance. After the super-structure has been obtained, usually using an IT-based approach (Tsamardinos et al., 2006), one looks for solution networks whose skeletons are contained in the super-structure. It hence becomes important that the super-structure is sound, i.e., contains at least one optimal solution.\nThere are two main questions concerning the super-structure: First, how can a suitable and sound super-structure be obtained efficiently? And secondly, once such a superstructure is obtained, how can it be used to guide the search for an optimal solution? The goal of this paper is to provide a theoretical analysis of the latter question, considering super-structures that arise from a given local score function adapting the model of Parviainen and Koivisto (2010). We consider various combinations of restrictions in a systematic way that allows us draw a broader picture of the complexity landscape of BNSL. We hope that our analysis can help to understand the boundaries between tractable and intractable cases of this important problem. Furthermore, we think that our results provide new insights that can help the search for more efficient and accurate heuristics. For our analysis, we use the theoretical framework of parameterized complexity (Downey & Fellows, 1999) which seems to be well suited for investigating the complexity of BNSL as it allows to take structural properties (in terms of parameters) into account. To the best of our knowledge parameterized complexity theory has not been employed in this context before."}, {"heading": "1.1 Results", "text": "In this section we give a brief overview of our results."}, {"heading": "1.1.1 Exact BNSL Using the Super-structure", "text": "In the first part of our paper we study the worst-case complexity of Exact BNSL under graph-theoretic restrictions on the super-structure. One of the most prominent restrictions on the super-structure that we consider is treewidth. Treewidth is an important and widely used parameter that measures the similarity of a graph to a tree (Bodlaender, 1993, 1997, 2005; Greco & Scarcello, 2010). Similarly as for trees, many otherwise intractable problems become tractable on graphs of bounded treewidth. More importantly, treewidth has already been successfully applied in the context of Bayesian Reasoning (Darwiche, 2001; Dechter, 1999; Kwisthout, Bodlaender, & van der Gaag, 2010). It hence seems only natural to apply treewidth to (Exact) BNSL. Our results are as follows:\n(1) Exact BNSL is solvable in non-uniform polynomial time if the treewidth of the superstructure is bounded by an arbitrary constant.\n(2) Exact BNSL is solvable in linear time if both treewidth and maximum degree of the super-structure are bounded by arbitrary constants.\nBy \u201cnon-uniform\u201d we mean that the order of the polynomial depends on the treewidth. We obtain results (1) and (2) by means of a dynamic programming algorithm along a decomposition tree of the super-structure. We show that\u2014in a certain sense\u2014both results are optimal:\n(3) Exact BNSL for instances with super-structures of maximum degree 4 (but unbounded treewidth) is not solvable in polynomial time unless P = NP. Thus, in (1) and (2) we cannot drop the bound on the treewidth.\n(4) Exact BNSL for instances with super-structures of bounded treewidth (but unbounded maximum degree) is not solvable in uniform polynomial time unless FPT = W[1]. Thus, in (2) we cannot drop the bound on the degree.\nFPT 6= W[1] is a widely accepted complexity theoretic assumption (Downey & Fellows, 1999) that is often considered as the parameterized analog to P 6= NP. We will provide necessary background on parameterized complexity and fpt-reductions in Section 2.2."}, {"heading": "1.1.2 Local Search BNSL Using the Super-structure", "text": "Since learning an optimal Bayesian network is computationally hard heuristic methods are used in practice. A popular heuristic for BNSL is the so-called hill climbing procedure, or local search. In particular, a highly competitive algorithm for learning large Bayesian networks (MMHC) uses local search to find an optimal solution inside a previously constructed super-structure (Tsamardinos et al., 2006). We study the worst case complexity of a wellknown generalization of local search, the k-Neighborhood Local Search (or k-Local Search for short). In this variant of local search one is allowed to modify not one but up to k arcs in every step of the search. Hence by adjusting k, one is able to balance speed and accuracy. However, because the k-local search space is of order nO(k), applying k-local search is especially desirable for problems where the running time does only increase modestly with respect to k. Similarly to result (2) we are able to show the following:\n(5) k-Local Search BNSL is solvable in linear time if both the treewidth and the maximum degree of the super-structure are bounded by arbitrary constants.\nClearly, this result is only of minor interest because we can already solve the Exact BNSL problem under the same restrictions on the super-structure (see result (2)). However, in contrast to the Exact BNSL problem one might be able to drop one of these restrictions without losing uniform polynomial-time tractability. We show that this is again unlikely.\n(6) k-Local Search BNSL for instances with super-structures that have either bounded treewidth or bounded maximum degree is not solvable in uniform polynomial time unless FPT = W[1]."}, {"heading": "1.1.3 Exact BNSL Using the Directed Super-structure", "text": "So far, one has only considered the super-structure as an undirected graph. We introduce the directed super-structure as a more expressive way to restrict the search space of solutions, i.e., once the directed super-structure has been fixed we restrict our search to solutions whose\nnetworks are contained in the directed super-structure. Again, we study the complexity of Exact BNSL with respect to certain restrictions on the directed super-structure and obtain the following result.\n(7) Exact BNSL is solvable in quadratic time if the directed super-structure is acyclic.\nThe question arises whether we can extend this result by using a more general form of acyclicity. We show, however, that this is not the case.\n(8) Exact BNSL is NP-hard for directed super-structures that can be made acyclic by deleting one node. Hardness even holds if the maximum in-degree and the maximum out-degree of the directed super-structure are both bounded by 3.\nA systematic overview of our results (1)\u2013(8) is given in Figure 1."}, {"heading": "1.2 Related Work", "text": "In this section we present relevant related work on BNSL. Further related work can be found in the respective sections, i.e., we present related work on parameterized complexity in Section 2.2, related work on treewidth and tree decompositions in Sections 2.3 and 3.1, and in Section 7 we present related work on k-neighborhood local search."}, {"heading": "1.2.1 Algorithms for Exact BNSL", "text": "To this date only a handful of exact algorithms for BNSL have been proposed. These can be split into three groups: (A) exact algorithms that do not employ any restrictions (Parviainen & Koivisto, 2010; Koivisto, 2006; Yuan, Malone, & Wu, 2011; Ott, Imoto, & Miyano, 2004; Silander & Myllyma\u0308ki, 2006; Yuan et al., 2011), (B) exact algorithms using restrictions on the generating or target distribution (Pieter et al., 2006; Chechetka & Guestrin, 2007; Friedman, Nachman, & Pe\u2019er, 1999; Chow & Liu, 1968; Gaspers, Koivisto et al., 2012), and (C) exact algorithms that use restrictions on the undirected super-structure (Friedman et al., 1999; Kojima, Perrier, Imoto, & Miyano, 2010). Algorithms falling into group (A) are only suited for small to medium sized Bayesian networks because they do not restrict the search space in any way. On the other hand, the restrictions used by algorithms in group (B) are more general than restrictions coming from the undirected super-structure and up to now only non-uniform polynomial-time algorithms could be obtained using these restrictions. To the best of our knowledge this paper is the first to employ an in-depth theoretical analysis of the parameterized complexity of BNSL using restrictions on the undirected super-structure. We obtain the first algorithm for exact BNSL with a uniform polynomial running-time with respect to structural restriction on the undirected superstructure. A similar approach has been taken by Kojima et al. (2010), where the authors propose an algorithm for exact BNSL that uses a \u201ccluster-decomposition\u201d of the undirected super-structure. Even though their practical results are quite promising the authors provide no theoretical analysis of the worst-case complexity of their algorithm beyond the trivial bound that also applies to exact algorithms in group (A). Apart from exact algorithms there also exists a variety of approximation algorithms using tree decomposition or degree-based techniques (Pieter et al., 2006; Elidan & Gould, 2008; Karger & Srebro, 2001)."}, {"heading": "1.2.2 Hardness Results for Exact BNSL", "text": "There are also a number of hardness results for BNSL under restrictions of the resulting Bayesian network. In particular, BNSL remains NP-hard if the in-degree of the resulting Bayesian network is bounded by 2 (Chickering, 1996), and if the resulting Bayesian network is a poly tree (Dasgupta, 1999), or a directed path (Meek, 2001). However, to the best of our knowledge, no negative results for BNSL under restrictions of the (directed) super-structure have been obtained."}, {"heading": "1.3 Organization and Prior Work", "text": "This paper is organized as follows: In Section 2 we introduce the basic concepts and notions that we use throughout the paper. We introduce the main object of our study (BNSL) in Section 3. Section 4 shows how to use a dynamic programming algorithm on a tree decomposition in order to show results (1) and (2). We provide a refined complexity analysis of our algorithm in Section 5. In Section 6 we show the complexity boundaries for Exact BNSL using a super-structure, i.e., we obtain results (3) and (4). We introduce k-Local Search BNSL in Section 7 where we establish results (5) and (6). We introduce the directed super-structure in Section 8 and show results (7) and (8). We conclude in Section 9. An appendix contains the proofs of some technical claims.\nA preliminary and shortened version of this paper appeared in the proceedings of UAI 2010. Apart from providing a higher level of detail and readability by giving more examples and detailed proofs, the paper extends its previous version in four ways: by adding a section on related work (Section 1.2), by providing a refined complexity analysis of our main algorithmic result (Section 5), by providing a novel proof of Theorem 6 that allows us to decrease the upper bound on the maximum degree of the super-structure from 5 to 3, and by introducing the directed super-structure (Section 8)."}, {"heading": "2. Preliminaries", "text": "In this section we will introduce the basic concepts and notions that we will use throughout the paper."}, {"heading": "2.1 Basic Graph Theory", "text": "We will assume that the reader is familiar with basic graph theory (see, e.g., Diestel, 2000; Bang-Jensen & Gutin, 2009). We consider undirected graphs and directed graphs (digraphs). A dag is a directed acyclic graph. We write V (G) = V and E(G) = E for the sets of nodes and edges of a (directed or undirected) graph G = (V,E), respectively. We denote an undirected edge between nodes u and v as {u, v} and a directed edge (or arc), directed from u to v as (u, v). We write NG(v) for the set of neighbors of a node v \u2208 V in G, i.e., NG(v) = {u : (v, u) \u2208 E or (u, v) \u2208 E } if G is directed and NG(v) = {u : {u, v} \u2208 E } if G is undirected. For a subset V \u2032 \u2286 V we write G[V \u2032] to denote the induced subgraph G\u2032 = (V \u2032, E\u2032) where E\u2032 = { e \u2286 V \u2032 : e \u2208 E } if G is undirected and E\u2032 = { e \u2208 V \u2032 \u00d7 V \u2032 : e \u2208 E } if G is directed. If G is a digraph we define PG(v) = {u \u2208 V (G) : (u, v) \u2208 E(G) } as the set of parents of v in G. Furthermore, for two directed graphs D1 and D2 we define D1\u222aD2 as the\nunion of D1 and D2, i.e., V (D1\u222aD2) = V (D1)\u222aV (D2) and E(D1\u222aD2) = E(D1)\u222aE(D2). Let G be a (directed or undirected) graph and e \u2208 E(G) a directed or undirected edge in G. We denote by G\u2212 e the (undirected or directed) graph, where G\u2212 e = (V (G), E(G) \\ {e}). Furthermore, for a subset X \u2286 V (G) we denote by G\u2212X the graph induced by the nodes in V \\X. If X contains only one node v we also write G \u2212 v instead of G \u2212 {v}. We call an undirected graph G\u2032 = (V \u2032, E\u2032) the skeleton of a directed graph G if V \u2032 = V (G) and E\u2032 = { {u, v} : (u, v) \u2208 E(G) }."}, {"heading": "2.2 Parameterized Complexity", "text": "Parameterized complexity provides a theoretical framework to distinguish between uniform and non-uniform polynomial-time tractability with respect to a parameter. It has been introduced and pioneered by Downey and Fellows (1999) and is receiving growing interest as reflected by the recent publication of two further monographs (Flum & Grohe, 2006; Niedermeier, 2006) and hundreds of research papers (see references in the above mentioned monographs). In 2008 the Computer Journal has devoted two special issues on parameterized complexity in order to make the key methods and ideas known to a wide range of computer scientists (Downey, Fellows, & Langston, 2008).\nAn instance of a parameterized problem is a pair (I, k) where I is the main part and k is the parameter ; the latter is usually a non-negative integer. A parameterized problem is fixed-parameter tractable if there exist a computable function f and a constant c such that instances (I, k) of size n can be solved in time O(f(k)nc). FPT is the class of all fixed-parameter tractable decision problems. Fixed-parameter tractable problems are also called uniform polynomial-time tractable because if k is considered constant, then instances with parameter k can be solved in polynomial time where the order of the polynomial is independent of k (in contrast to non-uniform polynomial-time running times such as nk).\nParameterized complexity offers a completeness theory similar to the theory of NPcompleteness. One uses fpt-reductions which are many-one reductions where the parameter for one problem maps into the parameter for the other. More specifically, problem L reduces to problem L\u2032 if there is a mapping R from instances of L to instances of L\u2032 such that (i) (I, k) is a yes-instance of L if and only if (I \u2032, k\u2032) = R(I, k) is a yes-instance of L\u2032, (ii) k\u2032 \u2264 g(k) for a computable function g, and (iii) R can be computed in time O(f(k)nc) where f is a computable function, c is a constant, and n denotes the size of (I, k). The parameterized complexity class W[1] is considered as the parameterized analog to NP. In particular, FPT = W[1] implies the (unlikely) existence of a 2o(n) algorithm for n-variable 3SAT (Impagliazzo, Paturi, & Zane, 2001; Flum & Grohe, 2006). An example, for a parameterized problem that is W[1]-complete under fpt-reductions is the parameterized Maximum Clique problem (given a graph G and a parameter k \u2265 0, does G contain a complete subgraph on k nodes?). Note that there exists a trivial non-uniform polynomialtime nk algorithm for the Maximum Clique problems that checks all sets of k nodes."}, {"heading": "2.3 Tree Decompositions", "text": "Treewidth is an important graph parameter that indicates in a certain sense the \u201ctreelikeness\u201d of an undirected graph (Bodlaender, 1993, 1997, 2005). On graphs of treewidth bounded by a constant many otherwise intractable problems become tractable. Bucket\nElimination (Dechter, 1999) and Recursive Conditioning (Darwiche, 2001) are two important algorithmic concepts that apply to instances of bounded treewidth.\nThe treewidth of a graph G = (V,E) is defined via the following notion of decomposition: a tree decomposition of G is a pair (T, \u03c7) where T is a tree and \u03c7 is a labeling function with \u03c7(t) \u2286 V for every tree node t such that the following conditions hold:\n1. Every node of G occurs in \u03c7(t) for some tree node t.\n2. For every edge {u, v} of G there is a tree node t such that u, v \u2208 \u03c7(t).\n3. For every node v of G, let Tv be the subgraph of T induced by all nodes t such that v \u2208 \u03c7(t). Then Tv is a (connected) subtree of T (\u201cConnectedness Condition\u201d).\nThe width of a tree decomposition (T, \u03c7) is the size of a largest set \u03c7(t) minus 1 among all nodes t of T . A tree decomposition of smallest width is optimal. The treewidth of a graph G, denoted tw(G), is the width of an optimal tree decomposition of G. It is known that if (T, \u03c7) is a tree decomposition of a graph G, then every clique of G is contained in \u03c7(t) for some tree node t \u2208 V (T ) (Kloks, 1994, Lemma 2.2.2).\nThe following proposition will be useful to retrieve an upper bound on the treewidth of a graph.\nProposition 1. Let G be an undirected graph and X \u2286 V (G). If the graph G\u2212X contains no edge, i.e., all the nodes in G\u2212X are isolated, then tw(G) \u2264 |X|.\nProof. Let V (G) \\ X contain the nodes v1, . . . , vn and let T be the tree with node set {t, t1, . . . , tn} and edge set { {t, ti} : 1 \u2264 i \u2264 n }. Then T together with the function \u03c7 such that \u03c7(t) = X and \u03c7(ti) = X \u222a {vi} for every 1 \u2264 i \u2264 n is a tree decomposition for G of width |X|.\nThe main property of tree decompositions that allows for efficient bottom-up dynamic programming algorithms for a wide spectrum of otherwise intractable problems is its wellknown separation property which is made precise in the following proposition.\nProposition 2. Let G be a graph, (T, \u03c7) a tree decomposition for G, {t\u2032, t\u2032\u2032} be an edge in T , and let T \u2032 and T \u2032\u2032 be the subtrees of T obtained from T after deleting the edge {t\u2032, t\u2032\u2032} such that T \u2032 contains t\u2032 and T \u2032\u2032 contains t\u2032\u2032. Furthermore, define S = \u03c7(t\u2032) \u2229 \u03c7(t\u2032\u2032), A =\u22c3 t\u2208V (T \u2032) \u03c7(t) and B = \u22c3 t\u2208V (T \u2032\u2032) \u03c7(t). Then the following two statements hold:\n1. A \u2229B = S;\n2. S separates the nodes in A from the nodes in B, i.e., there is no edge between a node in A \\ S and a node in B \\ S.\nProof. The first statement follows immediately from Property (3) of a tree decomposition, since the subtree containing a node v \u2208 (A\u2229B) has to make use of the edge {t\u2032, t\u2032\u2032} in order to be connected and hence v has to be contained in S.\nTo see the second statement, suppose for a contradiction that there is an edge between a node a \u2208 A \\S and a node b \u2208 B \\S. It follows from the first statement of this proposition that Ta and Tb are disjoint, i.e.,otherwise either a \u2208 S or b \u2208 S. But this contradicts property (2) of a tree decomposition since {a, b} is an edge of G.\nGiven a graph G with n nodes and a constant w, it is possible to decide whether G has treewidth at most w, and if so, to compute an optimal tree decomposition of G in time O(n) (Bodlaender, 1996). Furthermore there exist powerful heuristics to compute tree decompositions of small width in a practically feasible way (Koster, Bodlaender, & van Hoesel, 2001; Gogate & Dechter, 2004; Dow & Korf, 2007). Recently, new randomized heuristics have been studied in the context of Bayesian reasoning (Kask, Gelfand, Otten, & Dechter, 2011; Gelfand, Kask, & Dechter, 2011)."}, {"heading": "3. Bayesian Network Structure Learning", "text": "In this section we define the theoretical framework for BNSL that we shall use for our considerations. We closely follow the abstract framework used by Parviainen and Koivisto (2010) which encloses a wide range of score-based approaches to structure learning. We assume that the input data specifies a set N of nodes (representing random variables) and a local score function f that assigns to each v \u2208 N and each subset P \u2286 N \\ {v} a nonnegative real number f(v, P ). Given the local score function f and a set N of nodes, the problem is to find a dag D on N such that the score of D under f\nf(D) := \u2211 v\u2208N f(v,PD(v))\nis as large as possible (the dag D together with certain local probability distributions forms a Bayesian network). This setting accommodates several popular scores like BDe, BIC and AIC (Parviainen & Koivisto, 2010; Chickering, 1995).\nWe consider the following decision problem:\nExact Bayesian Network Structure Learning\nInput: A local score function f defined on a set N of nodes, a real number s > 0. Question: Is there a dag D on N such that f(D) \u2265 s?\nFor the following complexity results we need to fix how the score function is represented in the problem input. We cannot list the values f(v, P ) for all nodes v \u2208 N and all subsets P \u2286 N \\{v}, as this requires \u2126(2|N |) space. Therefore, we assume that f(v, P ) is only given if it is different from 0; we call this the non-zero representation. This representation is also used in other fields, for instance in constraint satisfaction, where only allowed tuples of constraints are listed in the input (Tsang, 1993). An alternative representation of the score function would be to list in the input all values f(v, P ) where |P | \u2264 c for some constant c. Let us call this the arity-c representation. This representation requires only polynomial space if every node has at most c parents, for a small constant c, which is a reasonable assumption. Given an arity-c representation of a score function, we can clearly compute in linear time the corresponding non-zero representation. Hence the non-zero representation is more general, and therefore we will base our complexity results on this encoding. All tractability results also carry over to the arity-c representation.\nThe size of f (given in the non-zero representation) is the number of bits needed to represent the tuples with f(v, P ) > 0 in a reasonable data structure, e.g., as a list of these\ntuples where each tuple stores the node, the set of parents, and the value of the score function. Clearly, the size of f exceeds the total number of all such tuples. We define Pf (v) := {P \u2286 N : f(v, P ) > 0} \u222a {\u2205} to be the set of all potential parent sets of v. We also define\n\u03b4f := max v\u2208N |Pf (v)|;\nwhich will be an important measurement for our worst-case analysis of running times. In particular, the above assumption on how f is represented implies the following:\n(*) Let I = (N, f, s) be an instance of Exact Bayesian Network Structure Learning. Then \u03b4f is bounded by the size of f .\nLet f be a local score function defined on a set N of nodes. The directed super-structure of f is the directed graph S\u2192f = (N,Ef ) where Ef contains an arc (u, v) if and only if u is a potential parent of v, i.e., if u \u2208 P for some P \u2208 Pf (v). The (undirected) super-structure of f , denoted Sf = (N,Ef ), is the skeleton of the directed super-structure.\nExample 1. Figure 2 shows an example for a local-score function f defined on the set N = {a, b, c, d, e, f, g} of nodes. The function f is given as a table containing all tuples (v, P, f(v, P )) with v \u2208 N and P \u2286 N \\ {v} such that f(v, P ) > 0. Note that since f is non-negative it holds that f(v, P ) = 0 for all the remaining pairs (v, P ), i.e., the pairs that are not contained in the table. The figure also shows the directed super-structure S\u2192f and the unique super-structure Sf of f .\nWe say that a dag D on a set N of nodes is admissible for f if the skeleton of D is a subgraph of the super-structure Sf . Furthermore, we say that a dag D on N is strictly admissible for f if for every node v \u2208 N we have PD(v) \u2208 Pf (v). Note that every strictly admissible dag is also admissible. Furthermore, there always exists a (strictly) admissible dag with the highest score as shown by the following lemma.\nLemma 1. Let f be a local score function defined on a set N of nodes and let D be a dag on N . Then there is a strictly admissible dag D\u2032 on N with the same score as D.\nProof. If D is not (strictly) admissible, i.e., if there is a v \u2208 N such that f(v,PD(v)) = 0, we can delete all arcs (w, v) such that w \u2208 PD(v). This does not decrease the score since f(v, \u2205) \u2265 f(v,PD(v)) = 0 for every such a v.\nExample 2. Figure 3 shows four examples of dags on the the nodes a, b, c, d, e, f, g. Using the local-score function f as defined in Example 1, we make the following observations:\na) Da is not admissible, because the super-structure Sf does not contain the edge {c, b}. The score for Da is f(Da) = 4.\nb) Db is admissible but not strictly admissible, because the node a has parents c and d but f(a, {c, d}) = 0. The score for Db is f(Db) = 5.\nc) Dc is the strictly admissible dag obtained from Db as described in the proof of Lemma 1. We have f(Dc) = f(Db) = 5.\nd) Dd is strictly admissible and is also an optimal dag for f . The score for Dd is f(Dd) = 7."}, {"heading": "3.1 Tree Decompositions", "text": "When presenting algorithms for graphs of bounded treewidth it is convenient to consider tree decompositions in the following normal form (Kloks, 1994): A triple (T, \u03c7, r) is a nice tree decomposition of a graph G if (T, \u03c7) is a tree decomposition of G, the tree T is rooted at node r, and each node of T is of one of the following four types:\n1. a leaf node: a node having no children;\n2. a join node: a node t having exactly two children t1, t2, and \u03c7(t) = \u03c7(t1) = \u03c7(t2);\n3. an introduce node: a node t having exactly one child t\u2032, and \u03c7(t) = \u03c7(t\u2032) \u222a {v} for a node v of G;\n4. a forget node: a node t having exactly one child t\u2032, and \u03c7(t) = \u03c7(t\u2032) \\ {v} for a node v of G.\nFor convenience we will also assume that \u03c7(r) = \u2205 for the root r of T . This can always be achieved by adding forget nodes on top of the root (see Figure 4 for an example). For a nice tree decomposition (T, \u03c7, r) we define \u03c7\u2217(t) to be the union of all the sets \u03c7(t\u2032) where t\u2032 is contained in the subtree of T rooted at t. Furthermore, we denote by Ft the set of nodes that have already been \u201cforgotten\u201d at node t, i.e.,\nFt = \u03c7 \u2217(t) \\ \u03c7(t).\nAs stated in Section 2.3 one of the main properties of tree decompositions that allows for efficient algorithms is the well-known separator property made precise in Proposition 2. The following propositions provide different versions of this separator property of tree decompositions for each of the node types of a nice tree decomposition. Because these propositions are well-known (Kloks, 1994) and are immediate consequences of the separator property of tree decompositions we state them without proofs. The propositions summarize the algorithmic properties of nice tree decompositions that we will use for the design of our algorithm in Section 4.\nProposition 3. Let t be a join node with children t1 and t2. Then Ft1 \u2229 Ft2 = \u2205 and there is no edge between a node u \u2208 Ft1 and a node v \u2208 Ft2 in G. Proposition 4. Let t be an introduce node with child t\u2032 such that \u03c7(t) = \u03c7(t\u2032)\u222a{v0}. Then there is no edge from v0 to a node v \u2208 Ft in G. Furthermore, v0 /\u2208 Ft\u2032.\nProposition 5. Let t be a forget node with child t\u2032 such that \u03c7(t) = \u03c7(t\u2032) \\ {v0}. Then there is no edge from v0 to a node v \u2208 V (G) \\ \u03c7\u2217(t) in G.\nGiven a tree decomposition of a graph G of width w, one can effectively obtain in time O(|V (G)|) a nice tree decomposition of G with O(|V (G)|) nodes and of width at most w (Kloks, 1994).\nExample 3. Figure 4 shows a tree decomposition and a corresponding nice tree decomposition of the super-structure of Example 1."}, {"heading": "4. A Dynamic Programming Algorithm for Exact Bayesian Network", "text": "Structure Learning\nIn this section we present the dynamic programming algorithm and establish our tractability results. For the remainder of this section w denotes an arbitrary but fixed constant. Recall from the previous section that \u03b4f is the maximum number of potential parent sets of a node.\nTheorem 1. Given a set N of nodes and a local score function f on N whose superstructure Sf = (N,Ef ) has treewidth bounded by an arbitrary constant w. Then we can find in time O(\u03b4 2(w+1) f \u00b7 |N |) a dag D on N with maximal score f(D).\nBefore we devise an algorithm to show Theorem 1 we state and prove a direct consequence of the theorem.\nCorollary 1. Exact Bayesian Network Structure Learning can be decided in polynomial time for instances where the super-structure has bounded treewidth. The problem can be decided in linear time if additionally the super-structure has bounded maximum degree.\nProof. The first statement follows immediately from the theorem since \u03b4f is bounded by the total input size of the instance and w is a constant. Recall from Section 3 that the local score function f is given as the list of all tuples for which f is non-zero and hence \u03b4f is bounded by the total input size of the instance. The second statement follows since \u03b4f is bounded whenever the maximum degree d of the super-structure is bounded as clearly \u03b4f \u2264 2d.\nIn the following we will assume that we are given a set of nodes N and a local score function f on N together with a nice tree decomposition (T, \u03c7, r) for Sf of width at most w. We are going to establish Theorem 1 by means of a dynamic programming algorithm along a nice tree decomposition for Sf , computing local information at the nodes of the tree decomposition that can then be put together to form an optimal dag. Our algorithm closely follows the general approach used by algorithms on graphs (or structures) of bounded treewidth (Bodlaender & Koster, 2008).\nA partial solution for a tree node t \u2208 V (T ) is a dag that can be obtained as the induced subdigraph D[\u03c7\u2217(t)] of a strictly admissible dag D for f . For a tree node t let D(t) denote the set of all partial solutions for t. For a partial solution D \u2208 D(t) we set\nft(D) = \u2211 v\u2208Ft f(v,PD(v)),\ni.e., ft(D) is the sum of the scores of the nodes in Ft. Recall from the previous section that Ft is the set of forgotten nodes at t.\nThe main idea underlying our algorithm is to reduce the space required to store a partial solution with the help of a so-called record. This becomes possible because of the properties of a tree decomposition manifested by Propositions 3, 4 and 5.\nA record of a tree node t \u2208 V (T ) is a triple R = (a, p, s) such that:\n1. a is a mapping \u03c7(t)\u2192 Pf (v), i.e., for every v \u2208 \u03c7(t) we have a(v) \u2208 Pf (v);\n2. p is a transitive binary relation on \u03c7(t);\n3. s is a non-negative real number.\nInformally, for a tree node t \u2208 V (T ) and a record R = (a, p, s), the mapping a fixes the parent set of every node in \u03c7(t), p is a compact representation of the reachability relation between the nodes in \u03c7(t) (using directed paths between nodes in \u03c7\u2217(t)), and s is the sum of the scores of the nodes that have been forgotten for t, i.e., the nodes in Ft.\nWe say that a record represents a partial solution D \u2208 D(t) if it satisfies the following conditions:\n1. a(v) \u2229 V (D) = PD(v) for every v \u2208 \u03c7(t).\n2. For every pair of nodes v1, v2 \u2208 \u03c7(t) it holds that (v1, v2) \u2208 p if and only if D contains a directed path from v1 to v2.\nWe say that a record R = (a, p, s) of a tree node t \u2208 V (T ) is valid if it represents some dag D \u2208 D(t) and s is the maximum score ft(D) over all dags in D(t) represented by R. We say a partial solution D that is represented by R is maximal with respect to R if R is valid and ft(D) = s. With each tree node t \u2208 V (T ) we associate the set R(t) of all valid records representing partial solutions in D(t).\nIn a certain sense, R(t) is a succinct representation of the optimal elements of D(t), using space that only depends on w and \u03b4f , but not on |N |.\nExample 4. Figure 5 shows two partial solutions Da and Db for the node t of the nice tree decomposition Example 3. Da and Db are represented by all records R = (a, p, s) with\na(b) = {a, f}, a(c) = {e}, a(d) = \u2205 and p = {(b, c), (d, b), (d, c)}. We have ft(Da) = 3 > ft(Db) = 2 and it is easy to see that 3 is the maximum score over all partial solutions represented by R. Hence the record R = (a, p, 3) is a valid record for t and Da is maximal with respect to R, thus R \u2208 R(t).\nOur dynamic programming algorithm computes the set of all valid records in a bottom up manner, i.e., starting from the leave nodes of the nice tree decomposition the algorithm proceeds to the root node. The next three lemmas show how to compute the set of all valid records for the introduce, forget and join nodes of the nice tree decomposition from the valid records of its children. Informally, if t is an introduce node with child t\u2032 such that \u03c7(t) = \u03c7(t\u2032) \u222a {v0} then we compute the set R(t) of all valid records for t by checking for each potential parent set P \u2208 P(v0) for v0 and each valid record R \u2208 R(t\u2032) for t\u2032 whether the combination of P and R constitutes a valid record for t.\nLemma 2 (introduce node). Let t be an introduce node with child t\u2032. Then R(t) can be computed from R(t\u2032) in time O(\u03b4w+1f ).\nProof. In the following we denote by v0 the node introduced by t, i.e., \u03c7(t) = \u03c7(t \u2032) \u222a {v0}. We are going to establish the lemma with the help of the following claim whose proof can be found in the appendix.\nClaim 1. R(t) is the set of all records R = (a, p, s) such that there is a set P \u2208 Pf (v0) and a record R\u2032 = (a\u2032, p\u2032, s\u2032) \u2208 R(t\u2032) with:\n1. a(v0) = P .\n2. For every v \u2208 \u03c7(t\u2032) it holds that a(v) = a\u2032(v).\n3. s = s\u2032.\n4. p is the transitive closure of the relation p\u2032 \u222a { (u, v0) : u \u2208 P } \u222a { (v0, u) : u \u2208 \u03c7(t\u2032) such that v0 \u2208 a\u2032(u) }.\n5. p is irreflexive.\nIt follows that R(t) can be computed by checking for every pair (P,R\u2032), with P \u2208 Pf (v0) and R\u2032 \u2208 R(t\u2032), whether it satisfies the conditions (1)\u2013(5). Since there are at most \u03b4f possible sets P and at most O(\u03b4wf ) possible valid records for t\n\u2032 (observe that |\u03c7(t\u2032)| \u2264 w) the lemma follows from the fact that for every pair (P ,R\u2032) the conditions can be checked in time that only depends on w.\nInformally, if t is a forget node with child t\u2032 such that \u03c7(t) = \u03c7(t\u2032)\\{v0} then we compute the set R(t) of all valid records for t by \u201cprojecting\u201d the set R(t\u2032) of valid records for t\u2032 to \u03c7(t).\nLemma 3 (forget node). Let t be a forget node with child t\u2032. Then R(t) can be computed from R(t\u2032) in time O(\u03b4w+1f ).\nProof. In the following we denote by v0 the forgotten node, i.e. \u03c7(t) = \u03c7(t \u2032) \\ {v0}. We will show that R(t) can be obtained as the \u201cprojection\u201d of R(t\u2032) to \u03c7(t). Before doing so we need some additional notation. Let R\u2032 = (a\u2032, p\u2032, s\u2032) \u2208 R(t\u2032). We define the projection of R\u2032 to t, denoted R\u2032[t] as the record R = (a, p, s) such that:\n1. a is the restriction of a\u2032 to \u03c7(t).\n2. p = { (v, w) \u2208 p\u2032 : v, w \u2208 \u03c7(t) }.\n3. s = s\u2032 + f(v0, a \u2032(v0)).\nFurthermore, we define the projection of R(t\u2032) to t, denoted R(t\u2032)[t], as the set of all records R\u2032[t] for R\u2032 \u2208 R(t\u2032). We say that a record R = (a, p, s) \u2208 R(t\u2032)[t] is maximal if there is no s\u2032 with s\u2032 > s such that (a, p, s\u2032) \u2208 R(t\u2032)[t].\nAgain, we are going to establish the lemma with the help of the following claim whose proof can be found in the appendix.\nClaim 2. R(t) is the set of all maximal records in R(t\u2032)[t].\nSince R(t\u2032) contains at most O(\u03b4w+1f ) records it is easy to see that R(t) can be computed in time O(\u03b4w+1f ).\nInformally, if t is a join node with children t1 and t2 then we compute the set R(t) of all valid records for t by checking for each record R1 \u2208 R(t1) and each record R2 \u2208 R(t2) whether the combination of R1 and R2 constitutes a valid record for t.\nLemma 4 (join node). Let t1, t2 be the children of t in T . Then R(t) can be computed from R(t1) and R(t2) in time O(\u03b42(w+1)f ).\nProof. We are going to establish the lemma with the help of the following claim (the rather technical proof of this claim can be found in the appendix).\nClaim 3. R(t) is the set of all records R = (a, p, s) such that there are records R1 = (a1, p1, s1) \u2208 R(t1) and R2 = (a2, p2, s2) \u2208 R(t2) with:\n1. a = a1 = a2.\n2. s = s1 + s2.\n3. p is the transitive closure of p1 \u222a p2.\n4. p is irreflexive, i.e., there is no v \u2208 \u03c7(t) such that (v, v) \u2208 p.\nIt follows that R(t) can be computed by considering all pairs of records R1 \u2208 R(t1) and R2 \u2208 R(t2) and checking conditions (1)\u2013(4). Since there are at most O(\u03b4w+1f ) valid records for every t \u2208 V (T ) and for every such pair of records the time required to check the conditions (1)\u2013(4) does only depend on w, it follows that the running time of this procedure is at most O(\u03b4 2(w+1) f ).\nWe are now ready to establish Theorem 1.\nProof of Theorem 1. Let N be a set of nodes, f a local score function on N where the super-structure Sf has treewidth w (a constant) and |N | = n. We compute a nice tree decomposition (T, \u03c7, r) of Sf of width w and with O(n) nodes. This can be accomplished in time O(n) (see the discussion in Section 2.3).\nNext we compute the sets R(t) via a bottom-up traversal of T . For a leaf node t we can compute R(t) just by considering all strictly admissible dags on the at most w + 1 nodes in \u03c7(t). This can clearly be done in time O(\u03b4w+1f ) and we can then use Lemmas 4, 2 and 3 to compute the sets R(t) for all other O(n) tree nodes in time O(\u03b42(w+1)f \u00b7 n). Since \u03c7(r) = \u2205, the partial solutions for the root r of T are exactly the strictly admissible dags for f , and we have fr(D) = f(D) for each such dag D. After the computation of the sets R(t) for all tree nodes t, the set R(r) contains exactly one record R = (\u2205, \u2205, s). By the above considerations, it follows that s is the largest score of all strictly admissible dags for f , and, as noted in Section 3, this is also the largest score of any dag whose nodes belong to N . It is now easy to compute a dag D with score f(D) = s via a top-down traversal of T starting from r and using the information previously stored at each node in T . This can also be accomplished in time O(\u03b4 2(w+1) f \u00b7 n).\nWe close this section with a remark concerning the relationship between the treewidth of a Bayesian network and the treewidth of its super-structure. For Bayesian reasoning one usually associates with the dag D of a Bayesian network its moral graph M(D) which is the skeleton of D plus edges joining nodes that have a common child in D. The treewidth of a Bayesian network is the treewidth of its moral graph (Darwiche, 2001; Dechter, 1999). We observe that for every Bayesian network of bounded treewidth there is a super-structure of bounded treewidth that contains the Bayesian network. Hence, such a Bayesian network can be learned considering only super-structures of bounded treewidth. On the other hand if a Bayesian network is contained in a super-structure of bounded treewidth then the Bayesian network has bounded treewidth under the reasonable assumption that each of its nodes has a bounded number of parents. Consequently, if a Bayesian network is learned from a super-structure of bounded treewidth it is reasonable to assume that the Bayesian network has bounded treewidth as well."}, {"heading": "5. Refined Complexity Analysis", "text": "When presenting our algorithm in Section 4 we focused on a broad evaluation of its complexity. In this Section we provide a more fine-grained analysis of its running time.\nIn the following we assume that N is a set of nodes, f is a local score function on N , and (T, \u03c7, r) is a nice tree decomposition of Sf of width at most w. We can improve on the running time of our algorithm by using the following five ideas.\nI1 By keeping the records for each node in the tree decomposition in some fixed order we\ncan improve the time needed at a join node of the tree decomposition from O(\u03b4 2(w+1) f ) to O(\u03b4w+1f ) without any additional cost for sorting. We achieve this by generating new records in an ordered manner and keeping track of that order when the records are stored.\nI2 Parent sets that are supersets of parent sets with a higher score can be disregarded (de Campos, Zeng, & Ji, 2009). This simple preprocessing rule usually allows us to consider fewer than the potentially 2d potential parent sets. In the sequel we will denote the preprocessed score function by f \u2032. Clearly, |Pf (v)| \u2264 |Pf \u2032(v)| for every v \u2208 N .\nI3 If the maximum in-degree of the resulting BN is bounded in advance one can use this fact to further preprocess the score function in the natural way. In the following we denote the resulting score function by f \u2032\u2032. Clearly, |Pf \u2032\u2032(v)| \u2264 |Pf \u2032(v)| for every v \u2208 N .\nI4 Every node of the network might have a different number of potential parent sets. Consequently, instead of using one upper bound for the number \u03b4f \u2032\u2032 of potential parent sets it is more realistic to consider the actual number |Pf \u2032\u2032(v)| of potential parent sets for each node v \u2208 N .\nI5 Only valid records need to be stored by our algorithm, i.e., records that represent acyclic networks.\nConsidering the ideas I1\u2013I4 the worst-case complexity of our algorithm can be refined as follows: \u2211\nt\u2208V (T ) O(w2 \u00b7 \u220f v\u2208\u03c7(t) |Pf \u2032\u2032(v)|)\nObserve that w2 \u00b7 \u220f v\u2208\u03c7(t) |Pf \u2032\u2032(v)| is the number of potential records for the tree node t. Because of idea I5 in general not all of these records need to be stored by our algorithm. This refined analysis suggests that the running time of our algorithm is dominated by the maximum number of records that need to be stored for a tree node t \u2208 V (T )."}, {"heading": "6. Hardness Results for Exact Bayesian Network Structure Learning", "text": "The following result follows by a reduction due to Chickering (1996).\nTheorem 2. Exact Bayesian Network Structure Learning is NP-hard for instances with super-structures of maximum degree 4.\nProof. Since we use a well-known reduction from Chickering, we will only sketch the argument. The reduction is from Feedback Arc Set (FAS). The problem asks whether a digraph D = (V,E) can be made acyclic by deleting at most k arcs (the deleted arcs form a feedback arc set of D). The problem is NP-hard for digraphs with skeletons of maximum degree 4 (Karp, 1972). Given an instance (D, k) of FAS, where the skeleton of D has maximum degree 4, we construct a set V \u2032 = V (D)\u222aE(D) of nodes and a local score function f on V \u2032 by setting f((u, v), {u}) = 1 for all (u, v) \u2208 E(D), f(v, { (u, v) : u \u2208 PD(v) }) = |PD(v)| for all v \u2208 V (D), and f(v, P ) = 0 in all other cases. Clearly, the super-structure Sf (recall the definition of Sf in Section 3) is isomorphic to the undirected graph obtained from the skeleton of D after subdividing every edge once, hence the maximum degree of Sf is at most the maximum degree of D which is 4. It is easy to see that D has a feedback arc set of size \u2264 k if and only if there exists a dag D\u2032 whose skeleton is a spanning subgraph of Sf with f(D\u2032) \u2265 2 \u00b7 |E| \u2212 k.\nTheorem 3. Exact Bayesian Network Structure Learning parameterized by the treewidth of the super-structure is W[1]-hard.\nProof. We devise an fpt-reduction from the following problem, which is well-known to be W[1]-complete (Pietrzak, 2003).\nPartitioned Clique\nInput: A k-partite graph G = (V,E) with partition V1, . . . , Vk such that |Vi| = |Vj | = n for 1 \u2264 i < j \u2264 k. Parameter: The integer k. Question: Are there nodes v1, . . . , vk such that vi \u2208 Vi for 1 \u2264 i \u2264 k\nand {vi, vj} \u2208 E for 1 \u2264 i < j \u2264 k? (The graph K = ({v1, . . . , vk}, { {vi, vj} : 1 \u2264 i < j \u2264 k }) is a k-clique of G.)\nLet G = (V,E) be an instance of this problem with partition V1, . . . , Vk, |V1| = \u00b7 \u00b7 \u00b7 = |Vk| = n and parameter k. Informally, we encode the given instance of Partitioned Clique as an instance (N, f, s) of Exact Bayesian Structure Learning such that G has a k-clique if and only if there is a Bayesian network D with f(D) \u2265 s. To achieve this we introduce a node nv for every node v of G and one node aij for every 1 \u2264 i 6= j \u2264 k. Then a node that corresponds to a node in Vi achieves its maximum score for the parent set that contains all nodes aij for 1 \u2264 j \u2264 k. A node aij achieves its maximum score if its parent set corresponds to an edge of G between a node in Vi and a node in Vj . Hence, the edges of G are encoded in the local score function of the nodes aij for 1 \u2264 i 6= j \u2264 k. By choosing the proper scores for these nodes and the right threshold s we can assure that in any Bayesian network whose score is higher than s every node aij has to attain its maximum score, and all but at most k nodes that correspond to nodes of G do not achieve their maximum score. It follows that the parent sets chosen for the nodes aij correspond to the edges of a k-clique of G.\nIn order to make later calculations easier we will assume that k > 2 for the remainder of this proof. Let \u03b1 = k2 \u2212 k \u2212 1, \u03b5 = 2k and s = nk\u03b1+ 1. We construct a set N of nodes and a local score function f on N satisfying the following claims.\nClaim 4. tw(Sf ) \u2264 k(k \u2212 1)/2\nClaim 5. G has a k-clique if and only if there is a dag D such that f(D) \u2265 s.\nWe will have shown the theorem after establishing the two claims. We set A = { aij : 1 \u2264 i < j \u2264 k }, N = V (G) \u222a A, and Ai = { alk \u2208 A : l = i or k = i } for every 1 \u2264 i \u2264 k. We are now ready to define f . We set f(v,Ai) = \u03b1 for every v \u2208 Vi, and f(aij , {u,w}) = \u03b5 for every 1 \u2264 i < j \u2264 k, u \u2208 Vi, w \u2208 Vj , and {u,w} \u2208 E(G). Furthermore, we set f(v, P ) = 0 for all the remaining combinations of v and P . See Figure 6 for an illustration. Now, Claim 4 follows from Proposition 1 with X = A. Hence, it remains to show Claim 5.\nBefore we go on to show Claim 5 we give some further notation and explanation. Let E\u2032 \u2286 E(G). We denote by V (E\u2032) the set of all nodes incident to edges in E\u2032, i.e., the set \u22c3 e\u2208E\u2032 e. We say that E\n\u2032 is representable if for every 1 \u2264 i < j \u2264 k it contains at most one edge between a node in Vi and a node in Vj . We define eij(E\n\u2032) = {vi, vj} if E\u2032 contains the edge between vi \u2208 Vi and vj \u2208 Vj and eij = \u2205 otherwise. We define D(E\u2032) to\nbe the directed graph with node set N and arc set { (v, aij) : v \u2208 eij(E\u2032) and 1 \u2264 i < j \u2264 k } \u222a { (aij , v) : v /\u2208 eij(E\u2032) and 1 \u2264 i < j \u2264 k }. Figure 7 shows D(E\u2032) for a representable edge set of the example graph G from Figure 6.\nThe main idea to show Claim 5 is that f(D) \u2265 s if and only if D has the form D(E\u2032) for a representable edge set E\u2032 that corresponds to a k-clique in G. This is formally expressed by the following claim whose proof can be found in the appendix.\nClaim 6. The following statements are equivalent:\n1. G has a k-clique.\n2. There is a dag D with f(D) \u2265 s.\n3. There is a representable edge set E\u2032 \u2286 E(G) such that f(D(E\u2032)) \u2265 s.\nNote that in contrast to Theorem 2, it is essential for Theorem 3 that the super-structure has unbounded degree: if both degree and treewidth are bounded then the problem is fixed-parameter tractable by Corollary 1 and so unlikely to be W[1]-hard.\n7. k-Neighborhood Local Search\nImportant and widely used algorithms for BNSL are based on local search methods (Heckerman, Geiger, & Chickering, 1995). Usually the local search algorithm tries to improve the score of a given dag by transforming it into a new dag by adding, deleting, or reversing one arc at a time (in symbols: add, del, and rev, respectively). The main obstacle for local search methods is the danger of getting stuck at a poor local optimum. A possibility for decreasing this danger is to perform k > 1 elementary changes in one step, known as kNeighborhood Local Search or k-Local Search for short. For BNSL, when we try to improve the score of a dag on n nodes, the k-local search space is of order nO(k). Therefore, if carried out by brute-force, k-local search is too costly even for small values of k. It is therefore not surprising that most practical local search algorithms for BNSL consider 1-neighborhoods only.\nThe study of the parameterized complexity of k-local search was initiated by Fellows (2003). To date a collection of positive and negative results on the parameterized complexity of k-local search for various combinatorial optimization problems are known. For instance, k-local search has already been investigated for combinatorial problems on graphs (Khuller, Bhatia, & Pless, 2003; Marx, 2008; Fellows, Rosamond, Fomin, Lokshtanov, Saurabh, & Villanger, 2009; Gaspers, Kim, Ordyniak, Saurabh, & Szeider, 2012), for the problem of finding a minimum weight assignment for a Boolean constraint satisfaction instance (Krokhin & Marx, 2012), for the stable marriage problem with ties (Marx & Schlotter, 2011), and for the satisfiability problem (Szeider, 2011).\nIn this section we show that k-local search for BNSL can be solved in linear time if the super-structure has bounded treewidth and bounded maximum degree. This result is in good agreement with Theorem 1. However, in contrast to Exact BNSL it might still be possible to drop one of these restrictions without losing uniform polynomial-time tractability, but we show that this is not the case. We also investigate k-Local Search BNSL for different combinations of allowed operations such as reversal, addition and deletion of an arc. Our results are mostly negative. In fact, somewhat surprisingly, k-Local Search BNSL remains hard even if edge reversal is the only allowed operation.\nBefore we state and show our results we define k-Local Search BNSL more formally. Let k \u2265 0 and O \u2286 {add,del,rev}. Consider a dag D = (V,E). A directed graph D\u2032 = (V \u2032, E\u2032) is a k-O-neighbor of D if\n1. D\u2032 is a dag,\n2. V = V \u2032,\n3. E\u2032 can be obtained from E by performing at most k operations from the set O.\nFor O \u2286 {add, del, rev} we consider the following parameterized decision problem.\nk-O-Local Search Bayesian Network Structure Learning Input: A local score function f , a dag D that is admissible for f , and\nan integer k. Question: Is there a k-O-neighbor D\u2032 of D with a higher score than D?\nNote that the problem does not change if we require D\u2032 to be admissible, as we can always avoid the addition of an inadmissible arc.\nExample 5. Figure 8 shows two dags D and D\u2032 such that D\u2032 can be obtained from D by either reversing or by deleting and adding the reverse of the bold arcs in D. It follows that D\u2032 is a 3-{rev}-neighbor and a 6-{add,del}-neighbor of D. The directed graph obtained from D after only reversing the arc (a, d) contains a cycle (on the nodes {a, b, f, d}) but D\u2032 does not. The score of D\u2032 is larger than the score of D, since f(D) = 3 and f(D\u2032) = 7 (using the score function f as depicted in Figure 2).\nProposition 6. k-Local Search Bayesian Network Structure Learning can be decided in linear time for instances where the super-structure has bounded treewidth and bounded maximum degree.\nProof. As the proof uses the same arguments as the proof of Theorem 1 we only sketch the proof of this proposition.\nIn the following we will assume that we are given an instance I = (D, f, k) of k-OLocal Search Bayesian Network Structure Learning together with a nice tree decomposition (T, \u03c7, r) for Sf of width at most w and let d be the maximum degree of Sf . As before we assume that w and d are constants. For a set S we denote by [S] the set of all subsets of S.\nThe main difference to the proof of Theorem 1 is that we are now only interested in solutions which are k-O-neighbors of D. To take this into account we need to slightly extend the concept of a record for a tree node t \u2208 V (T ). We include an integer c to reflect the \u201ccost\u201d of a partial solution that is the smallest number of operations from O needed to obtain D. For technical reasons we also include a mapping b that assigns the set of forgotten children to every node contained in \u03c7(t). This allows us to compute the value of c for a forget node.\nA record of a tree node t \u2208 V (T ) is a quintuple R = (a, b, p, c, s) such that:\n1. a is a mapping \u03c7(t)\u2192 Pf (v);\n2. b is a mapping \u03c7(t)\u2192 [Ft];\n3. p is a transitive binary relation on \u03c7(t);\n4. c is a non-negative integer;\n5. s is a non-negative real number.\nWe say that a record represents a partial solution Dp \u2208 D(t) if it satisfies the following conditions:\n1. a(v) \u2229 V (Dp) = PDp(v) for every v \u2208 \u03c7(t).\n2. b(v) = {u \u2208 Ft : (v, u) \u2208 E(Dp) } for every v \u2208 \u03c7(t).\n3. For every pair of nodes v1, v2 \u2208 \u03c7(t) it holds that (v1, v2) \u2208 p if and only if Dp contains a directed path from v1 to v2.\n4. c \u2264 k is the smallest integer such that Dp[Ft] is a c-O-neighbor of D[Ft].\nWe say that a record R = (a, b, p, c, s) of a tree node t \u2208 V (T ) is valid if it represents some dag Dp \u2208 D(t) and s is the maximum score ft(D) over all dags in D(t) represented by R. We say a partial solution D that is represented by R is maximal with respect to R if R is valid and ft(D) = s. With each tree node t \u2208 V (T ) we associate the set R(t) of all valid records representing partial solutions in D(t).\nIt is now straightforward to adapt the dynamic programming algorithm of Section 4 to the new setting. Observe that there are at most k + 1 possible values for c. Furthermore, because every considered partial solution Dp is admissible, the number of possible values for b(v) for every v \u2208 \u03c7(t) is bounded by 2d. It follows that the space requirement to store such a record is at most (k+ 1) \u00b7 2d(w+1) times the space requirement needed to store a record as defined in Section 4. Using the same argumentation as in Section 4 this leads to an overall running time of O((\u03b4w+1f \u00b7 (k+1) \u00b72\nd(w+1))2 \u00b7 |V (D)|) \u2264 O((dw+1 \u00b7 (k+1) \u00b72d(w+1))2 \u00b7 |V (D)|). Since w and d are constants, this constitutes a linear running time.\nTheorem 4. If O = {add} or O = {del}, then k-O-Local Search Bayesian Network Structure Learning is solvable in polynomial time.\nProof. We only consider O = {add} as the proof for O = {del} is analogous. Let I = (D, f, k) be the given instance of k-{add}-Local Search Bayesian Network Structure Learning. Since we are only allowed to add arcs to D every step must leave D acyclic. It follows that there is a k-{add}-neighbor D\u2032 of D with f(D\u2032) > f(D) if and only if there is a node v \u2208 V (D) such that the addition of at most k incoming arcs increases the score of v and the resulting digraph remains acyclic. Now, for every P \u2286 V (D) \\ {v} one can easily check whether f(v, P ) > f(v,PD(v)) and whether P can be obtained from PD(v) via the addition of at most k incoming arcs and whether the resulting digraph is acyclic.\nIn view of Theorem 4 let us define a set O \u2286 {add, del, rev} to be non-trivial if O /\u2208 {\u2205, {add}, {del}}.\nTheorem 5. Let O \u2286 {add,del,rev} be non-trivial. Then k-O-Local Search Bayesian Network Structure Learning is W[1]-hard for parameter tw(Sf ) + k.\nProof. We slightly modify the reduction given in the proof of Theorem 3. Let I = (G, k) be the given instance of Partioned Clique and let N , f and s be defined in correspondence to I and the proof of Theorem 3. We will distinguish two cases depending on whether it is allowed to reverse an arc or not, i.e., depending on whether rev \u2208 O.\nFor the case that rev \u2208 O we claim that I \u2032 = (f,D, k\u2032) where D = D(\u2205) and k\u2032 = ( k 2 ) is an instance of k\u2032-O-Local Search Bayesian Network Structure Learning such that G contains a k-clique if and only if there is a k\u2032-O-neighbor D\u2032 of D with f(D\u2032) > f(D). To see this let K be a k-clique in G. It follows from Claim 6 that there is a representable edge set E\u2032 with f(D(E\u2032)) \u2265 s > f(D) = s \u2212 1 and since E\u2032 is representable it is easy to see that D(E\u2032) can be obtained from D by the reversal of at most k\u2032 arcs in D. Hence D\u2032 = D(E\u2032) is a k\u2032-O-neighbor of D with f(D\u2032) > f(D). To see the reverse let D\u2032 be a k\u2032-O-neighbor of D with f(D\u2032) > f(D) = s\u22121. Hence D\u2032 is a dag and since f(D\u2032) is integer it follows that f(D\u2032) \u2265 s. Again, using Claim 6, we have that there is a k-clique in G.\nNow, for the only remaining case, i.e., the case that O = {add,del} we claim that I \u2032\u2032 = (f,D, k\u2032\u2032) where k\u2032\u2032 = 2k\u2032 is an instance of k\u2032-O-Local Search Bayesian Network Structure Learning such that G contains a k-clique if and only if there is a k\u2032\u2032-Oneighbor D\u2032 of D with f(D\u2032) > f(D). The proof uses the same arguments as in the case that rev \u2208 O only that we now need twice as many operations. That is, we have to replace the reversal of an arc (u, v) with the deletion of the arc (u, v) followed by the addition of the arc (v, u).\nIn the preliminary version of this paper (Ordyniak & Szeider, 2010) we showed the following theorem by a parametrized reduction from Red/Blue Non-Blocker, which had been claimed to be W[1]-complete for graphs of bounded degree (Downey & Fellows, 1995). However, recently we found out that this problem is in fact fixed-parameter tractable and that the proof published in the work of Downey and Fellows (1995) contained a mistake (Fellows, 2012). We therefore use a reduction from Independent Set that does not require the original instance to have bounded degree. This even allows us to strengthen our result by decreasing the upper bound on the maximum degree of the super-structure from 5 to 3.\nTheorem 6. Let O \u2286 {add,del,rev} be non-trivial. Then k-O-Local Search Bayesian Network Structure Learning is W[1]-hard for parameter k. Hardness even holds if the super-structure Sf has maximum degree 3.\nProof. We devise an fpt-reduction from the following problem which is known to be W[1]complete (Downey & Fellows, 1999).\nIndependent Set\nInput: An undirected graph G = (V,E) and an integer k. Parameter: The integer k. Question: Does G have an independent set of size at least k, i.e., is there\na set S \u2286 V with |S| \u2265 k such that {u, v} /\u2208 E for every pair of nodes u, v \u2208 S.\nTo simplify the initial construction we first prove the theorem for the case that the maximum degree of the super-structure is at most 5. We later show how to refine the proof for superstructures with maximum degree at most 3.\nLet (G = (V,E), k) be an instance of this problem and k\u2032 = 2k + 1 if rev \u2208 O and k\u2032 = 2(2k + 1) otherwise. We construct a dag D and a local score function f such that G has an independent set of size at least k if and only if D has a k\u2032-O-neighbor D\u2032 with a higher score than D.\nThe dag D is obtained from G by applying the following steps (see Figure 9 for an illustration):\n1. We replace every node v \u2208 V with the two nodes v1 and v2 and an arc (v1, v2).\n2. For every node v \u2208 V we add a binary tree Tv1 with exactly |NG(v)| leaves. The root of Tv1 is v 1 and all arcs of Tv1 are directed away from v 1. Furthermore, we define lv1\nto be a bijective mapping from NG(v) to the leaves of Tv1 .\n3. For every node v \u2208 V we add a binary tree Tv2 with exactly |NG(v)| leaves. The root of Tv2 is v 2 and all arcs of Tv2 are directed towards v 2. Furthermore, we define lv2 to\nbe a bijective mapping from NG(v) to the leaves of Tv2 .\n4. For every edge {u, v} \u2208 E, we add the arcs (lu1(v), lv2(u)) and (lv1(u), lu2(v)) to D.\n5. We add a binary tree T1 with root r1 with exactly |V | leaves, whose edges are directed away from r1. We define lT1 to be a bijective mapping from V to the leaves of T1.\n6. We add a binary tree T2 with root r2 with exactly |V | leaves, whose edges are directed towards r2. We define lT2 to be a bijective mapping from V to the leaves of T2.\n7. For every v \u2208 V (G), we add the arcs (v1, lT1(v)) and (v1, lT2(v)) to D.\n8. We add the arc (r2, r1) to D.\nThis completes the construction of D. Next we define the local score function f on V (D). Let \u03b1 = k \u2212 1, \u03b2 = |V (G)| and \u03b5 = 1.\n1. For every n \u2208 V (D) \\ { v1 : v \u2208 V (G) } \u222a {r1} we set f(n,PD(n)) = \u03b2.\n2. For every v \u2208 V (G) we set f(v1, {v2, lT1(v)}) = \u03b5, f(v2,PD(v2) \\ {v1}) = \u03b2, and f(lT1(v),PD(lT1(v)) \\ {v1}) = \u03b2.\n3. We set f(r1,PD(r1)) = \u03b1 and f(r2,PD(r2) \u222a {r1}) = \u03b2.\n4. For all the remaining combinations of n \u2208 V (D) and P \u2286 V (D) we set f(n, P ) = 0.\na b c7\u2192\nEvidently D is acyclic and both D and f can be constructed from G in polynomial time. Observe that the super-structure Sf is exactly the skeleton of D. Hence, by construction, the nodes v1 for v \u2208 V (D) have degree at most 5 while all other nodes of Sf have degree at most 3 showing that the maximum degree of Sf is at most 5. Consequently, we can establish the theorem with the help of the following claim whose proof can be found in the appendix.\nClaim 7. G has an independent set of size at least k if and only if D has a k\u2032-O-neighbor D\u2032 with a higher score than D where k\u2032 = 2k + 1 if rev \u2208 O and k\u2032 = 2(2k + 1) otherwise.\nWe now show how to alter the above construction to obtain the result for maximum degree 3. The only nodes in Sf whose degree may exceed 3 are the nodes in { v1 : v \u2208 V (G) }. The main idea to reduce the degree of these nodes is to further split their sets of neighbors using binary trees. For our new construction we define a DAG D\u2032 and a local score function f \u2032 as follows. The DAG D\u2032 is obtained from D by applying the following actions:\n1. For every v \u2208 V (G), we delete all nodes of Tv1 and all arcs incident with these nodes.\n2. For every v \u2208 V (G), we add the nodes v1a and v1b and the arcs (v1a, v1b) and (v1b, v2).\n3. For every v \u2208 V (G) we add a binary tree Tv1a with exactly |NG(v)| + 1 leaves. The root of Tv1a is v 1a and all arcs of Tv1a are directed away from v 1a. Furthermore, we\ndefine lv1a to be a bijective mapping from NG(v) \u222a {lT2(v)} to the leaves of Tv1a .\n4. For every v \u2208 V (G) we add the arcs (v1b, lT1(v)) and (lv1a(lT2(v)), lT2(v)).\nThis completes the construction of D\u2032. Next we define the local score function f \u2032 as follows:\n1. For every n \u2208 V (D\u2032) \\ { v1a : v \u2208 V (G) } \u222a {r1} we set f \u2032(n,PD\u2032(n)) = \u03b2.\n2. For every v \u2208 V (G) we set f \u2032(v1a, {v1b}) = \u03b5, f \u2032(v1b, {v2, lT1(v)}) = \u03b2, f \u2032(v2,PD\u2032(v2)\\ {v1b}) = \u03b2, and f \u2032(lT1(v),PD\u2032(lT1(v)) \\ {v1b}) = \u03b2.\n3. We set f \u2032(r1,PD\u2032(r1)) = \u03b1 and f \u2032(r2,PD\u2032(r2) \u222a {r1}) = \u03b2.\n4. For all the remaining combinations of n \u2208 V (D\u2032) and P \u2286 V (D\u2032) we set f \u2032(n, P ) = 0.\nIt is easy to see that Sf \u2032 has maximum degree 3. Furthermore, using the same arguments as in the proof of Claim 7 one can show that the graph G has an independent set of size k if and only if the DAG D\u2032 has a k\u2032-O-neighbor D\u2032\u2032 with a higher score than D\u2032 (with respect to f \u2032) where k\u2032 = 3k + 1 if rev \u2208 O and k\u2032 = 2(3k + 1) otherwise.\nTheorem 6 provides a surprising contrast to a similar study of k-local search for MAX-SAT where the problem is fixed-parameter tractable for instances of bounded degree (Szeider, 2011). A possible explanation for the surprising hardness of k-O-Local Search Bayesian Structure Learning could be that, in contrast to MAX-SAT, a global property of the entire instance (acyclicity) must be checked."}, {"heading": "8. The Directed Super-structure", "text": "In the previous sections we considered the problem of Exact BNSL and k-Local Search BNSL under certain restrictions of the undirected super-structure. However, every strictly admissible solution to Exact BNSL is actually contained in the more restrictive directed super-structure. It is a natural question whether the additional information entailed in the directed super-structure can be used to find new structural restrictions under which Exact BNSL becomes tractable. It is well-known that Exact BNSL becomes significantly easier if an ordering of the variables is given in advance. For instance, given an ordering of the variables of a BN, Exact BNSL becomes solvable in polynomial time if the input is given in the arity-c representation (Teyssier & Koller, 2005). Fixing an ordering of the variables in a BN corresponds to restricting the search space to acyclic directed super-structures. Our first observation of this section is that Exact BNSL is solvable in polynomial time if the directed super-structure is a dag and the input to the problem is given in the more general non-zero representation. It is important to note that there is no corresponding restriction of the undirected super-structure, because restricting the directed super-structure to be acyclic does not impose any restrictions on the undirected super-structure. Considering this promising result it becomes natural to ask whether it is possible to gradually generalize the class of acyclic directed super-structures. A natural approach would be to consider only directed super-structures that can be made acyclic by deleting a small number k of nodes. Such an approach looks promising as it is known that for every fixed k the directed superstructures that can be made acyclic by deleting at most k nodes can be recognized efficiently (Chen, Liu, Lu, O\u2019Sullivan, & Razgon, 2008). However, we show that this approach is unlikely to work for Exact BNSL. Furthermore, in correspondence to the results in the previous sections, NP-hardness even holds if we additionally bound the maximum in-degree and out-degree of S\u2192f .\nTheorem 7. Let N be a set of nodes and f a local score function on N such that S\u2192f is acyclic. Then we can find in time O(|N |\u03b4f ) a dag D with maximal score f(D).\nProof. Because S\u2192f is acyclic, it follows that every strictly admissible directed graph D is also acyclic. Hence in order to compute a dag D with the highest score, it is sufficient to\ncompute for every n \u2208 N a parent set with the highest score. This can clearly be done in time O(|N |\u03b4f ) and so the result follows.\nCorollary 2. Exact Bayesian Network Structure Learning is solvable in quadratic time for acyclic directed super-structures.\nProof. This follows immediately from Theorem 7 because both N and \u03b4f are bounded by the total input size of the problem. Recall from Section 3 that the local score function f is given as the list of all tuples for which f is non-zero and hence \u03b4f is bounded by the total input size of the instance.\nTheorem 8. Exact Bayesian Network Structure Learning is NP-hard for instances where S\u2192f can be made acyclic by deleting one node. Hardness even holds if we additionally bound the maximum in-degree and the maximum out-degree of S\u2192f by 3.\nProof. We devise a polynomial reduction from the restricted version of 3-SAT where every literal is contained in at most two clauses. This version of 3-SAT is still NP-complete (Garey & Johnson, 1979). Let \u03c6 be a 3-CNF formula with variables x1, . . . , xn and clauses C1, . . . , Cm where Cj = lj,1\u2228 lj,2\u2228 lj,3, for every 1 \u2264 j \u2264 m. We construct a set N of nodes, a local score function f and a real number s > 0.\nN contains the nodes d0, . . . , dn and t0, . . . , tn+m and additionally:\n\u2022 For every 1 \u2264 i \u2264 n the nodes xi, xi, ai, bi.\n\u2022 For every 1 \u2264 j \u2264 m the nodes lj,1, lj,2, lj,3, Cj .\nLet \u03b1 = n+ 1 and \u03b5 = 1. We define f as follows:\n\u2022 We set f(d0, {t0}) = f(t0, t1) = \u03b1.\n\u2022 For every 1 \u2264 i \u2264 n we set:\n\u2013 f(di, {di\u22121}) = \u03b1. \u2013 f(ai, {di}) = \u03b1 and f(xi, {ai}) = f(xi, {ai}) = \u03b5. \u2013 f(bi, {xi}) = f(bi, {xi}) = \u03b1. \u2013 f(ti, {ti+1, bi}) = \u03b1.\n\u2022 For every 1 \u2264 j \u2264 m we set:\n\u2013 f(Cj , {lj,1}) = f(Cj , {lj,2}) = f(Cj , {lj,3}) = \u03b1. \u2013 f(tn+j , {tn+j+1, Cj}) = \u03b1 if j < m and f(tn+j , {Cj}) = \u03b1 if j = m.\n\u2022 For every 1 \u2264 i \u2264 n, 1 \u2264 j \u2264 m and 1 \u2264 l \u2264 3 we set f(lj,l, {xi}) = \u03b1 if lj,l = xi and f(lj,l, {xi}) = \u03b1 if lj,l = xi.\nFor all other combinations of v \u2208 N and P \u2286 N we set f(v, P ) = 0. Furthermore, we set s = (4n + 5m + 2)\u03b1 + n\u03b5. An example of the directed super-structure constructed from a 3-CNF formula is shown in Figure 11. We establish the theorem by showing the following claims.\nClaim 8. S\u2192f can be made acyclic by deleting at most one node. Claim 9. S\u2192f has maximum in-degree and maximum out-degree 3.\nClaim 10. \u03c6 is satisfiable if and only if there is a dag D with score f(D) \u2265 s.\nIt is easy to see that S\u2192f \u2212 d0 is acyclic and hence Claim 8 holds. Since every literal occurs in at most two clauses it is also easy to verify Claim 9. The proof of Claim 10 is straightforward and can be found in the appendix."}, {"heading": "9. Conclusion", "text": "We have studied the computational complexity of Bayesian Structure Learning (BNSL) under various restrictions on the (directed) super-structure, considering both Exact BNSL and k-Local Search BNSL. We have obtained positive and negative results for the theoretical worst-case complexities of the problems. Our main positive result states that Exact BNSL is linear-time tractable if the super-structure has bounded treewidth and bounded maximum degree. We have contrasted out positive results with negative results, using techniques and concepts from Parameterized Complexity. This theoretical framework is particularly well-suited for such an investigation as it allows a fined-grained investigation that takes structural aspects of problem instances into account. Our results point out which combinations of structural restrictions make the problems tractable and which restrictions cannot be dropped without loosing tractability. Considering various combinations of restrictions in a systematic way allows us draw a broader picture of the complexity landscape (see the table in Section 1). We hope that our results provide a better understanding of the principles\nof BNSL and contribute to its foundations. We hope that this understanding will also be useful for the development of heuristic methods for practical BNSL systems."}, {"heading": "Acknowledgments", "text": "A shorter and preliminary version of this paper appeared in UAI 2010. Research supported by the European Research Council, grant reference 239962."}, {"heading": "Appendix A", "text": "Proof of Claim 1 (Lemma 2). Let us first assume that R = (a, p, s) is a valid record of t and let P = a(v0). Since R is valid it follows that it represents some partial solution D \u2208 D(t) such that D is maximal with respect to R. Now, D\u2032 = D[\u03c7\u2217(t\u2032)] is a partial solution for t\u2032 and it follows from Proposition 4 that D\u2032 = D \u2212 v0 and furthermore ft\u2032(D\u2032) = s. Hence, D\u2032 can be represented by some record R\u2032 = (a\u2032, p\u2032, s\u2032) such that R, R\u2032 and P satisfy the conditions of this claim. Furthermore, since R is valid and ft(D) = ft\u2032(D\n\u2032) the maximality of ft\u2032(D\n\u2032) with respect to R\u2032 follows from the maximality of ft(D) with respect to R and hence R\u2032 is a valid record of t\u2032.\nTo see the converse let P \u2208 Pf (v0) and a valid record R\u2032 = (a\u2032, p\u2032, s\u2032) \u2208 R(t\u2032) be given. Let R = (a, p, s) be the triple as defined via the conditions (1)-(4). Since R\u2032 is a valid record it represents some partial solution D\u2032 such that D\u2032 is maximal with respect to R\u2032. It is easy to see that the digraph D with node set V (D\u2032) \u222a {v0} and arc set E(D\u2032) \u222a { (u, v0) : u \u2208 P } \u222a { (v0, u) : u \u2208 \u03c7(t\u2032) such that v0 \u2208 a\u2032(u) } is acyclic if and only if p satisfies condition (5), i.e., p is irreflexive. It follows that R represents D if and only if p satisfies condition (5) and furthermore the maximality of D with respect to R follows from the maximality of D\u2032 with respect to R\u2032. Hence, R is a valid record for t if and only if it satisfies the conditions (1)\u2013(5).\nProof of Claim 2 (Lemma 3). Let us first assume that R = (a, p, s) is a valid record of t. Since R is a valid record it represents some solution D \u2208 D(t) such that D is maximal with respect to R. Now, let R\u2032 = (a\u2032, p\u2032, s\u2032) be such that a\u2032(v0) = PD(v0), a\n\u2032(v) = PD(v) for every v \u2208 \u03c7(t), p\u2032 is the union of p and all tuples (v0, v) and (v, v0) where v \u2208 \u03c7(t) such that there is a directed path from v0 to v respectively from v to v0 in D and s\n\u2032 = s \u2212 f(v0, PD(v0)). Note that because of Proposition 5 we can assume that PD(v0) \u2208 Pf (v0) and hence D is also represented by R\u2032. It follows from the maximality of D with respect to R that R\u2032 is a maximal element in R(t\u2032)[t].\nTo see the converse let R = (a, p, s) be a maximal element in R(t\u2032)[t]. Since R \u2208 R(t\u2032)[t] it follows that there is a record R\u2032 = (a\u2032, p\u2032, s\u2032) \u2208 R(t\u2032) such that R = R\u2032[t]. Hence, there is a partial solution D represented by R\u2032 such that ft\u2032(D) = s\n\u2032 is maximal with respect to all partial solutions represented by R\u2032. Clearly, D is also represented by R and the maximality of D with respect to R follows from the fact that R is a maximal element in R(t\u2032)[t].\nProof of Claim 3 (Lemma 4). Let us first assume that R = (a, p, s) is a valid record for t. Since R is valid it follows that it represents a partial solution D \u2208 D(t) such that D is maximal with respect to R. Let D1 = D[\u03c7 \u2217(t1)] and D2 = D[\u03c7 \u2217(t2)], i.e., D1 and D2 are the two subdigraphs of D induced by the nodes contained in the nodes of the subtrees\nrooted at t1 and t2, respectively. It follows from Proposition 3 that D = D1 \u222a D2 and V (D1) \u2229 V (D2) = \u03c7(t). Hence, D1 and D2 are partial solutions for t1 and t2, respectively. For i \u2208 {1, 2}, let Ri = (ai, pi, si) be such that a = ai, (v, w) \u2208 pi if and only if there is a directed path from v to w in Di and si = fti(Di). It follows directly from the definition that R1 and R2 represent D1 and D2, respectively, and since ft(D) = ft1(D1) + ft2(D2) the maximality of D with respect to R implies the maximality of D1 and D2 with respect to R1 and R2, respectively. Hence, R1 and R2 are valid records for t1 and t2, respectively, and it is easy to see that R, R1 and R2 satisfy the conditions of the claim.\nTo see the converse let us assume that we are given R1 = (a1, p1, s1) \u2208 R(t1) and R2 = (a2, p2, s2) \u2208 R(t2) and that the triple R = (a, p, s) as defined by the conditions (1)\u2013 (3) satisfies condition (4). Since R1 and R2 are valid it follows that both represent some partial solutions D1 and D2 such that D1 and D2 are maximal with respect to R1 and R2, respectively. Furthermore, using Proposition 3 it follows that V (D1) \u2229 V (D2) = \u03c7(t) and hence it follows from condition (4) that D = D1\u222aD2 is a partial solution represented by R. Now, ft(D) = ft1(D1) + ft2(D2) = s1 + s2 = s and the maximality of D with respect to R follows from the maximality of D1 and D2 with respect to R1 and R2, respectively. It follows that R is a valid record for t.\nProof of Claim 6 (Theorem 3). (1)\u21d2(2) SupposeG has a k-cliqueK. Then f(D(E(K))) = nk\u03b1\u2212 |V (K)|\u03b1+ |E(K)|\u03b5 = nk\u03b1+ k \u2265 s and it remains to show that D(E(K)) is acyclic. To see this note that every cycle in D(E(K)) has to use at least one node from V , because D(E(K)) does not contain an arc between two nodes in A. But since K is a clique, every node v \u2208 V is either a sink, i.e., v has only incoming arcs, or a source, i.e., v has only outgoing arcs and hence no cycle can use a node from V .\n(2)\u21d2(3) Suppose D is a dag with f(D) \u2265 s. Let A\u2032 be the set of nodes in A with f(a, PD(a)) = \u03b5 for every a \u2208 A\u2032. It follows from the definition of f that for every aij \u2208 A\u2032 there is a unique edge e between a node in Vi and a node in Vj in G with PD(aij) = e. Let E\u2032 \u2286 E(G) be the set of all edges in G that correspond to a node in A\u2032. It follows that E\u2032 is representable and we claim that every node v \u2208 N has at least the local score in D(E\u2032) as it has in D. By construction of D(E\u2032) the claim is trivially satisfied for every node a \u2208 A. Similarly, for every v \u2208 V \\ V (E\u2032) it holds that f(v, PD(E\u2032)(v)) = \u03b1 and hence f(v, PD(E\u2032)(v)) \u2265 f(v, PD(v)). Furthermore, for every v \u2208 V (E\u2032) it holds that f(v, PD(v)) = 0 and hence again f(v, PD(E\u2032)(v)) \u2265 f(v, PD(v)). It follows that f(D(E\u2032)) \u2265 f(D) \u2265 s.\n(3)\u21d2(1) Suppose that E\u2032 \u2286 E(G) is a representable edge set of G with f(D(E\u2032)) \u2265 s. We will show that |V (E\u2032)| = k and |E\u2032| = ( k 2 ) which implies that E\u2032 is the edge set of a k-clique in G.\nBecause E\u2032 is an edge set, it holds that |E\u2032| \u2264 (|V (E\u2032)|\n2\n) and hence:\nf(D(E\u2032))\u2212 nk\u03b1 = \u2212|V (E\u2032)|\u03b1+ |E\u2032|\u03b5 \u2264 \u2212|V (E\u2032)|\u03b1+ ( |V (E\u2032)|\n2\n) \u03b5\n= \u2212|V (E\u2032)|(k2 \u2212 k \u2212 1) + ( |V (E\u2032)|\n2\n) 2k\n= \u2212|V (E\u2032)|(k2 \u2212 k \u2212 1) + (|V (E\u2032)|2 \u2212 |V (E\u2032)|)k = \u2212|V (E\u2032)|k2 + |V (E\u2032)|2k + |V (E\u2032)|k \u2212 |V (E\u2032)|k + |V (E\u2032)| = \u2212|V (E\u2032)|k2 + |V (E\u2032)|2k + |V (E\u2032)|\nBecause f(D(E\u2032)) \u2265 s, it follows that \u2212|V (E\u2032)|k2 + |V (E\u2032)|2k + |V (E\u2032)| \u2265 1 and hence:\n\u2212|V (E\u2032)|k2 + |V (E\u2032)|2k + |V (E\u2032)| \u2265 1\n\u2212k2 + |V (E\u2032)|k + 1 \u2265 1 |V (E\u2032)|\n|V (E\u2032)| \u2265 1 |V (E\u2032)| + k 2 \u2212 1\nk\n|V (E\u2032)| \u2265 k \u2212 1 k + 1 |V (E\u2032)|k\nSince |V (E\u2032)| is an integer and k > 2, we have that |V (E\u2032)| \u2265 k. Furthermore, since E\u2032 is representable it can contain at most ( k 2 ) edges and hence\nf(D(E\u2032))\u2212nk\u03b1 \u2264 \u2212|V (E\u2032)|\u03b1+ ( k 2 ) \u03b5. Again, it follows from f(D(E\u2032)) \u2265 s that \u2212|V (E\u2032)|\u03b1+(\nk 2\n) \u03b5 \u2265 1 and:\n\u2212|V (E\u2032)|\u03b1+ ( k\n2\n) \u03b5 \u2265 1\n\u2212|V (E\u2032)|(k2 \u2212 k \u2212 1) + k3 \u2212 k2 \u2265 1 \u2212|V (E\u2032)|(k2 \u2212 k \u2212 1) \u2265 \u2212k3 + k2 + 1\n\u2212|V (E\u2032)| \u2265 \u2212k 3 + k2 + 1\nk2 \u2212 k \u2212 1\n|V (E\u2032)| \u2264 k + k + 1 k2 \u2212 k \u2212 1\nSince |V (E\u2032)| is an integer and k > 2, it follows that |V (E\u2032)| \u2264 k and hence |V (E\u2032)| = k. Using this in f(D(E\u2032))\u2212 nk\u03b1 \u2265 1 we get:\n\u2212k\u03b1+ |E\u2032|\u03b5 \u2265 1 \u2212(k3 \u2212 k2 \u2212 k) + |E\u2032|2k \u2265 1\n|E\u2032| \u2265 k 3 \u2212 k2 \u2212 k + 1\n2k\n|E\u2032| \u2265 k2 \u2212 k \u2212 1 + 1k\n2 |E\u2032| \u2265 ( k\n2\n) \u2212\n1\u2212 1k 2\nBecause |E\u2032| is an integer and k > 2, it follows that |E\u2032| \u2265 ( k 2 ) . Putting everything together\nwe have that f(D(E\u2032)) \u2265 s implies |V (E\u2032)| = k and |E\u2032| = ( k 2 ) . Hence E\u2032 is the edge set of a k-clique in G.\nProof of Claim 7 (Theorem 6). We first show the claim for the case that rev \u2208 O and k\u2032 = 2k + 1.\nLet us first assume that G has an independent set S \u2286 V (G) of size at least k. We obtain D\u2032 from D by reversing the k\u2032 arcs in { (v1, v2), (v1, lT1(v)) : v \u2208 S } \u222a {(r2, r1)}. This decreases the score for r1 by \u03b1 and increases the score for the nodes in { v1 : v \u2208 S } by \u03b5 while the score of all the other nodes of D remains unchanged. Hence, f(D\u2032) = f(D) \u2212 \u03b1 + |S|\u03b5 \u2265 \u03b1 + k\u03b5 = f(D) + 1 > f(D) and it remains to show that D\u2032 is acyclic. To see this assume that D\u2032 contains a cycle C. Because D is acyclic C must contain at least one of the newly created arcs in D\u2032, i.e., C must contain either an arc (v2, v1), an arc (lT1(v), v\n1) for some v \u2208 S or the arc (r1, r2). Because r2 is a sink in D\u2032, i.e., r2 has no outgoing arcs, the cycle C cannot contain the arc (r1, r2). Similarly, because D\n\u2032 does not contain a directed path from v1 to lT1(v) the cycle C cannot contain an arc (lT1(v), v\n1) for any v \u2208 S. Hence the cycle C must contain an arc (v2, v1) for some v \u2208 S. So suppose that C contains the arc (v2, v1) for some v \u2208 S. Because D\u2032 contains no directed paths from a node of T2 to a node of T1 it follows that C cannot leave the node v\n1 using the arc (v1, lT2(v)). Consequently, the cycle C must leave the node v\n1 towards w2 for some neighbor w of v in G. Because S is an independent set in G it follows that w /\u2208 S and hence the node w2 is a sink in D\u2032 contradicting the existence of the cycle C.\nTo see the reverse direction assume that D\u2032 is a dag obtained from D by reversing at most k\u2032 arcs. Note that the nodes in { v1 : v \u2208 V (G) } are the only nodes of D whose scores are not yet maximum. Hence, in order for D\u2032 to have a higher score than D the score for at least one of these nodes has to be increased. Now, the score for such a node v1 for some v \u2208 V (G) can only be increased by reversing the arcs (v1, v2) and (v1, lT1(v)). It is easy to see that reversing the arc (v1, lT1(v)) introduces a cycle C in D that uses only nodes in V (T1) \u222a V (T2) \u222a {v1}. However, because every such cycle C contains the arc (r2, r1) we can destroy all of these cycles by additionally reversing the arc (r2, r1). Because reversing (r2, r1) does only decrease the score of r1 by \u03b1 this is also the cheapest way to destroy these cycles. Now, \u03b1 = (k \u2212 1)\u03b5 and it follows that in order to increase the score of D the scores of at least k nodes in { v1 : v \u2208 V (G) } have to be increased to \u03b5. Let S be the set of nodes in V (G) such that the score of the nodes in { v1 : v \u2208 S } has been increased in this manner. As mentioned above |S| \u2265 k and it remains to show that S is an independent set in G. Suppose S is not an independent set and let u, v \u2208 S be such that {u, v} \u2208 E(G). Then the arcs (v2, v1) and (u2, u1) together with the directed path from v1 to u2 (using the arcs in Tv1 and Tu2) and the directed path from u\n1 to v2 (using the arcs in Tu1 and Tv2) form a cycle in D\u2032 contradicting the acyclicity of D\u2032. It follows that S is an independent set in G of size at least k.\nHence, we have shown the theorem for the case rev \u2208 O. It remains to show the theorem for the only remaining non-trivial set with rev /\u2208 O, i.e., the set O = {add,del}. Now k\u2032 = 2(2k + 1) and the idea is to replace every reversal of an arc (u, v) by a deletion (of (u, v)) and an addition (of (v, u)).\nProof of Claim 10 (Theorem 8). We will prove Claim 10 with the help of the following claim.\nClaim 11. f(D) \u2265 s and D is acyclic if and only if D satisfies the following conditions:\n1 D contains at least the following arcs:\n\u2013 The arc (t0, d0).\n\u2013 For every 1 \u2264 i \u2264 n, the arcs (di\u22121, di), (di, ai), (bi, ti) and (ti, ti\u22121). \u2013 For every 1 \u2264 i \u2264 n, 1 \u2264 j \u2264 m and 1 \u2264 l \u2264 3 the arc (xi, lj,l) if lj,l = xi and\nsimilarly the arc (xi, lj,l) if lj,l = xi.\n\u2013 For every 1 \u2264 j \u2264 m, the arcs (Cj , tn+j) and (tn+j , tn+j\u22121) and exactly one of the arcs (lj,1, Cj), (lj,2, Cj) and (lj,3, Cj).\n2 For every 1 \u2264 i \u2264 n the digraph D contains the arcs (ai, xi) and (xi, bi) but not the arcs (ai, xi) and (xi, bi) or D contains the arcs (ai, xi) and (xi, bi) but not the arcs (ai, xi) and (xi, bi).\n3 For 1 \u2264 i \u2264 n, 1 \u2264 j \u2264 m and 1 \u2264 l \u2264 3, the following holds:\n\u2013 If lj,l = xi and D contains the arc (lj,l, Cj) then D does not contain the arc (ai, xi).\n\u2013 If lj,l = xi and D contains the arc (lj,l, Cj) then D does not contain the arc (ai, xi).\nWe will first show how the previous claim can be used to prove Claim 10. Suppose \u03c6 is satisfiable and let \u03b2 be a satisfying assignment for \u03c6. Let D be the digraph that satisfies condition 1 and additionally:\n\u2022 For every 1 \u2264 i \u2264 n if \u03b2(xi) = true then D contains the arcs (ai, xi) and (xi, bi), otherwise D contains the arcs (ai, xi) and (xi, bi).\n\u2022 For every 1 \u2264 j \u2264 m let lj,l any literal in the clause Cj that is satisfied by \u03b2; since \u03b2 is a satisfying assignment every clause Cj contains such a literal. Then D contains the arc (lj,l, Cj).\nIt follows that D satisfies the conditions 2 and 3 and hence (using Claim 11) f(D) \u2265 s and D is acyclic.\nTo see the reverse let D be a dag with f(D) \u2265 s. It follows from Claim 11 that D satisfies the conditions 1 \u20133. We claim that the assignment \u03b2 with \u03b2(xi) = true if and only if D does not contain the arc (ai, xi) is a satisfying assignment for \u03c6. It follows from condition 1 that for every 1 \u2264 j \u2264 m the digraph D contains an arc (lj,l, Cj) for some 1 \u2264 l \u2264 3. W.l.o.g., we can assume that lj,l = xi for some 1 \u2264 i \u2264 n (the case that lj,l = xi is analog). Again using condition 1 it follows that D contains the arc (xi, lj,l). Because of condition 3 the digraph D does not contain the arc (ai, xi) and hence \u03b2(lj,l) = true.\nHence it only remains to show Claim 11. Let us first show that every dag D with f(D) \u2265 s satisfies conditions 1 \u20133. To see this observe that every node in V = {x1, x1, . . . , xn, xn}\nhas either score 0 or \u03b5. Similarly, every node in V \u2032 = N \\ V has either score 0 or \u03b1. It follows that in every directed graph there are at most 4n + 5m + 2 nodes with score \u03b1 and at most 2n nodes with score \u03b5. Hence, the maximum score for every directed graph is (4n + 5m + 2)\u03b1 + 2n\u03b5. Because \u03b1 > n\u03b5 and f(D) \u2265 s it follows that in D every node from V \u2032 must have score \u03b1 and similarly at least n of the 2n nodes in V must have score \u03b5. Hence D satisfies condition 1.\nTo show condition 2 observe that because for every 1 \u2264 i \u2264 n the node bi must have score \u03b1 in D it holds that exactly one of the arcs (xi, bi) and (xi, bi) is in D. Now, if D contains the arc (xi, bi) for some 1 \u2264 i \u2264 n then D cannot contain the arc (ai, xi) because otherwise D would contain the cycle (d, ai, xi, bi, t, d). Similarly, if D contains the arc (xi, bi) for some 1 \u2264 i \u2264 n then D cannot contain the arc (ai, xi). It follows that for every 1 \u2264 i \u2264 n at least one of the arcs (ai, xi) and (ai, xi) is missing in D. Since there are at most n nodes in V with score 0 it follows that for every 1 \u2264 i \u2264 n exactly one of the arcs (ai, xi) and (ai, xi) must be in D. It follows that D satisfies condition 2.\nTo see condition 3 suppose for some 1 \u2264 i \u2264 n, 1 \u2264 j \u2264 m and 1 \u2264 l \u2264 3 with lj,l = xi the digraph D contains both arcs (lj,l, Cj) and (ai, xi). It follows that D would contain the cycle (d, ai, xi, lj,l, Cj , t, d), a contradiction. The case that lj,l = xi is analog and hence D satisfies condition 3.\nTo see the reverse implication of the claim suppose that D is a digraph that satisfies the conditions 1 \u20133. It is easy to see that f(D) = s and it hence only remains to show that D is acyclic. Because S\u2192f \u2212 (t0, d0) is acyclic it follows that every cycle in D has to use the arc (t0, d0). Hence D contains a cycle if and only if there is a directed path P from d0 to t0 in D. It follows from condition 2 that there is no directed path from d0 to some bi in D, for 1 \u2264 i \u2264 3, and hence P cannot contain a node bi. Since the only other nodes in D with arcs to {t0, . . . , tn+m} are the nodes C1, . . . , Cm it follows that P has to use a node Cj for some 1 \u2264 j \u2264 m. Because of condition 1 the node Cj has exactly one incoming neighbor (one of lj,1, lj,2, lj,3) say lj,l. Again using condition 1 the node lj,l has exactly one incoming neighbor xi or xi if lj,l = xi or lj,l = xi, respectively. W.l.o.g. let us assume that lj,l = xi. It follows from condition 3 that xi has no incoming neighbor and hence D contains no directed path P from d0 to t0."}], "references": [{"title": "Digraphs (Second edition)", "author": ["J. Bang-Jensen", "G. Gutin"], "venue": null, "citeRegEx": "Bang.Jensen and Gutin,? \\Q2009\\E", "shortCiteRegEx": "Bang.Jensen and Gutin", "year": 2009}, {"title": "A tourist guide through treewidth", "author": ["H.L. Bodlaender"], "venue": "Acta Cybernetica,", "citeRegEx": "Bodlaender,? \\Q1993\\E", "shortCiteRegEx": "Bodlaender", "year": 1993}, {"title": "Discovering treewidth", "author": ["H.L. Bodlaender"], "venue": "In Proceedings of the 31st Conference on Current Trends in Theory and Practice of Computer Science (SOFSEM\u201905),", "citeRegEx": "Bodlaender,? \\Q2005\\E", "shortCiteRegEx": "Bodlaender", "year": 2005}, {"title": "A linear-time algorithm for finding tree-decompositions of small treewidth", "author": ["H.L. Bodlaender"], "venue": "SIAM J. Comput.,", "citeRegEx": "Bodlaender,? \\Q1996\\E", "shortCiteRegEx": "Bodlaender", "year": 1996}, {"title": "Treewidth: algorithmic techniques and results", "author": ["H.L. Bodlaender"], "venue": "In Mathematical foundations of computer science 1997 (Bratislava),", "citeRegEx": "Bodlaender,? \\Q1997\\E", "shortCiteRegEx": "Bodlaender", "year": 1997}, {"title": "Combinatorial optimization on graphs of bounded treewidth", "author": ["H.L. Bodlaender", "Koster", "A.M.C. A"], "venue": "Comput. J.,", "citeRegEx": "Bodlaender et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bodlaender et al\\.", "year": 2008}, {"title": "Efficient principled learning of thin junction trees", "author": ["A. Chechetka", "C. Guestrin"], "venue": "Advances in Neural Information Processing Systems 20, Proceedings of the Twenty-First Annual Conference on Neural Information Processing Systems,", "citeRegEx": "Chechetka and Guestrin,? \\Q2007\\E", "shortCiteRegEx": "Chechetka and Guestrin", "year": 2007}, {"title": "A fixed-parameter algorithm for the directed feedback vertex set problem", "author": ["J. Chen", "Y. Liu", "S. Lu", "B. O\u2019Sullivan", "I. Razgon"], "venue": "J. ACM,", "citeRegEx": "Chen et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2008}, {"title": "A transformational characterization of equivalent Bayesian network structures", "author": ["D.M. Chickering"], "venue": "In Uncertainty in artificial intelligence (Montreal, PQ,", "citeRegEx": "Chickering,? \\Q1995\\E", "shortCiteRegEx": "Chickering", "year": 1995}, {"title": "Learning Bayesian networks is NP-complete. In Learning from data (Fort", "author": ["D.M. Chickering"], "venue": "Vol. 112 of Lecture Notes in Statist.,", "citeRegEx": "Chickering,? \\Q1996\\E", "shortCiteRegEx": "Chickering", "year": 1996}, {"title": "Approximating discrete probability distributions with dependence trees", "author": ["C.I. Chow", "C.N. Liu"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Chow and Liu,? \\Q1968\\E", "shortCiteRegEx": "Chow and Liu", "year": 1968}, {"title": "Recursive conditioning", "author": ["A. Darwiche"], "venue": "Artificial Intelligence,", "citeRegEx": "Darwiche,? \\Q2001\\E", "shortCiteRegEx": "Darwiche", "year": 2001}, {"title": "Learning polytrees", "author": ["S. Dasgupta"], "venue": "UAI \u201999: Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence, Stockholm, Sweden, July 30-August", "citeRegEx": "Dasgupta,? \\Q1999\\E", "shortCiteRegEx": "Dasgupta", "year": 1999}, {"title": "Structure learning of Bayesian networks using constraints", "author": ["C.P. de Campos", "Z. Zeng", "Q. Ji"], "venue": "Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "Campos et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Campos et al\\.", "year": 2009}, {"title": "Bucket elimination: a unifying framework for reasoning", "author": ["R. Dechter"], "venue": "Artificial Intelligence,", "citeRegEx": "Dechter,? \\Q1999\\E", "shortCiteRegEx": "Dechter", "year": 1999}, {"title": "Graph Theory (2nd edition)., Vol. 173 of Graduate Texts in Mathematics", "author": ["R. Diestel"], "venue": null, "citeRegEx": "Diestel,? \\Q2000\\E", "shortCiteRegEx": "Diestel", "year": 2000}, {"title": "Best-first search for treewidth", "author": ["P.A. Dow", "R.E. Korf"], "venue": "In Proceedings of the Twenty-Second AAAI Conference on Artificial Intelligence, July 22-26,", "citeRegEx": "Dow and Korf,? \\Q2007\\E", "shortCiteRegEx": "Dow and Korf", "year": 2007}, {"title": "Parameterized Complexity. Monographs in Computer Science", "author": ["R.G. Downey", "M.R. Fellows"], "venue": null, "citeRegEx": "Downey and Fellows,? \\Q1999\\E", "shortCiteRegEx": "Downey and Fellows", "year": 1999}, {"title": "Fixed-parameter tractability and completeness", "author": ["R.G. Downey", "M.R. Fellows"], "venue": "II. On completeness for W [1]. Theoret. Comput. Sci.,", "citeRegEx": "Downey and Fellows,? \\Q1995\\E", "shortCiteRegEx": "Downey and Fellows", "year": 1995}, {"title": "The computer journal special issue on parameterized complexity: Foreword by the guest editors", "author": ["R.G. Downey", "M.R. Fellows", "M.A. Langston"], "venue": "The Computer Journal,", "citeRegEx": "Downey et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Downey et al\\.", "year": 2008}, {"title": "Learning bounded treewidth Bayesian networks", "author": ["G. Elidan", "S. Gould"], "venue": "Advances in Neural Information Processing Systems 21, Proceedings of the Twenty-Second Annual Conference on Neural Information Processing Systems,", "citeRegEx": "Elidan and Gould,? \\Q2008\\E", "shortCiteRegEx": "Elidan and Gould", "year": 2008}, {"title": "Blow-ups, win/win\u2019s, and crown rules: Some new directions in FPT", "author": ["M.R. Fellows"], "venue": "Graph-Theoretic Concepts in Computer Science (WG 2003),", "citeRegEx": "Fellows,? \\Q2003\\E", "shortCiteRegEx": "Fellows", "year": 2003}, {"title": "Local search: Is brute-force avoidable", "author": ["M.R. Fellows", "F.A. Rosamond", "F.V. Fomin", "D. Lokshtanov", "S. Saurabh", "Y. Villanger"], "venue": "Proceedings of the 21st International Joint Conference on Artificial Intelligence,", "citeRegEx": "Fellows et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Fellows et al\\.", "year": 2009}, {"title": "Parameterized Complexity Theory, Vol. XIV of Texts in Theoretical Computer Science. An EATCS Series", "author": ["J. Flum", "M. Grohe"], "venue": null, "citeRegEx": "Flum and Grohe,? \\Q2006\\E", "shortCiteRegEx": "Flum and Grohe", "year": 2006}, {"title": "Learning Bayesian network structure from massive datasets: The \u201dsparse candidate", "author": ["N. Friedman", "I. Nachman", "D. Pe\u2019er"], "venue": "UAI \u201999: Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Friedman et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Friedman et al\\.", "year": 1999}, {"title": "Computers and Intractability", "author": ["M.R. Garey", "D.R. Johnson"], "venue": null, "citeRegEx": "Garey and Johnson,? \\Q1979\\E", "shortCiteRegEx": "Garey and Johnson", "year": 1979}, {"title": "Don\u2019t be strict in local search", "author": ["S. Gaspers", "E.J. Kim", "S. Ordyniak", "S. Saurabh", "S. Szeider"], "venue": "In Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence,", "citeRegEx": "Gaspers et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gaspers et al\\.", "year": 2012}, {"title": "On finding optimal polytrees", "author": ["S. Gaspers", "M. Koivisto", "M. Liedloff", "S. Ordyniak", "S. Szeider"], "venue": null, "citeRegEx": "Gaspers et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gaspers et al\\.", "year": 2012}, {"title": "Stopping rules for randomized greedy triangulation schemes", "author": ["A. Gelfand", "K. Kask", "R. Dechter"], "venue": "Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence,", "citeRegEx": "Gelfand et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gelfand et al\\.", "year": 2011}, {"title": "A complete anytime algorithm for treewidth", "author": ["V. Gogate", "R. Dechter"], "venue": "In Proceedings of the Proceedings of the Twentieth Conference Annual Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "Gogate and Dechter,? \\Q2004\\E", "shortCiteRegEx": "Gogate and Dechter", "year": 2004}, {"title": "On the power of structural decompositions of graph-based representations of constraint problems", "author": ["G. Greco", "F. Scarcello"], "venue": "Artificial Intelligence,", "citeRegEx": "Greco and Scarcello,? \\Q2010\\E", "shortCiteRegEx": "Greco and Scarcello", "year": 2010}, {"title": "Learning Bayesian networks: The combination of knowledge and statistical data", "author": ["D. Heckerman", "D. Geiger", "D.M. Chickering"], "venue": "Machine Learning,", "citeRegEx": "Heckerman et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Heckerman et al\\.", "year": 1995}, {"title": "Which problems have strongly exponential complexity", "author": ["R. Impagliazzo", "R. Paturi", "F. Zane"], "venue": "J. of Computer and System Sciences,", "citeRegEx": "Impagliazzo et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Impagliazzo et al\\.", "year": 2001}, {"title": "Learning markov networks: maximum bounded treewidth graphs", "author": ["D.R. Karger", "N. Srebro"], "venue": "In SODA,", "citeRegEx": "Karger and Srebro,? \\Q2001\\E", "shortCiteRegEx": "Karger and Srebro", "year": 2001}, {"title": "Reducibility among combinatorial problems", "author": ["R.M. Karp"], "venue": "In Complexity of computer computations (Proc. Sympos., IBM Thomas J. Watson Res", "citeRegEx": "Karp,? \\Q1972\\E", "shortCiteRegEx": "Karp", "year": 1972}, {"title": "Pushing the power of stochastic greedy ordering schemes for inference in graphical models", "author": ["K. Kask", "A. Gelfand", "L. Otten", "R. Dechter"], "venue": "Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence,", "citeRegEx": "Kask et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kask et al\\.", "year": 2011}, {"title": "On local search and placement of meters in networks", "author": ["S. Khuller", "R. Bhatia", "R. Pless"], "venue": "SIAM J. Comput.,", "citeRegEx": "Khuller et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Khuller et al\\.", "year": 2003}, {"title": "Treewidth: Computations and Approximations", "author": ["T. Kloks"], "venue": null, "citeRegEx": "Kloks,? \\Q1994\\E", "shortCiteRegEx": "Kloks", "year": 1994}, {"title": "Advances in exact Bayesian structure discovery in Bayesian networks", "author": ["M. Koivisto"], "venue": "Proceedings of the 22nd Conference in Uncertainty in Artificial Intelligence,", "citeRegEx": "Koivisto,? \\Q2006\\E", "shortCiteRegEx": "Koivisto", "year": 2006}, {"title": "Optimal search on clustered structural constraint for learning Bayesian network structure", "author": ["K. Kojima", "E. Perrier", "S. Imoto", "S. Miyano"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Kojima et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kojima et al\\.", "year": 2010}, {"title": "Treewidth: Computational experiments", "author": ["Koster", "A.M.C. A", "H.L. Bodlaender", "S.P.M. van Hoesel"], "venue": "Electronic Notes in Discrete Mathematics,", "citeRegEx": "Koster et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Koster et al\\.", "year": 2001}, {"title": "On the hardness of losing weight", "author": ["A.A. Krokhin", "D. Marx"], "venue": "ACM Transactions on Algorithms,", "citeRegEx": "Krokhin and Marx,? \\Q2012\\E", "shortCiteRegEx": "Krokhin and Marx", "year": 2012}, {"title": "The necessity of bounded treewidth for efficient inference in Bayesian networks", "author": ["J. Kwisthout", "H.L. Bodlaender", "L.C. van der Gaag"], "venue": "In ECAI,", "citeRegEx": "Kwisthout et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kwisthout et al\\.", "year": 2010}, {"title": "Searching the k-change neighborhood for TSP is W[1]-hard", "author": ["D. Marx"], "venue": "Oper. Res. Lett.,", "citeRegEx": "Marx,? \\Q2008\\E", "shortCiteRegEx": "Marx", "year": 2008}, {"title": "Stable assignment with couples: Parameterized complexity and local search", "author": ["D. Marx", "I. Schlotter"], "venue": "Discrete Optimization,", "citeRegEx": "Marx and Schlotter,? \\Q2011\\E", "shortCiteRegEx": "Marx and Schlotter", "year": 2011}, {"title": "Finding a path is harder than finding a tree", "author": ["C. Meek"], "venue": "J. Artif. Intell. Res.,", "citeRegEx": "Meek,? \\Q2001\\E", "shortCiteRegEx": "Meek", "year": 2001}, {"title": "PAC-learning bounded tree-width graphical models", "author": ["M. Narasimhan", "J.A. Bilmes"], "venue": "UAI \u201904, Proceedings of the 20th Conference in Uncertainty in Artificial Intelligence,", "citeRegEx": "Narasimhan and Bilmes,? \\Q2004\\E", "shortCiteRegEx": "Narasimhan and Bilmes", "year": 2004}, {"title": "Invitation to Fixed-Parameter Algorithms. Oxford Lecture Series in Mathematics and its Applications", "author": ["R. Niedermeier"], "venue": null, "citeRegEx": "Niedermeier,? \\Q2006\\E", "shortCiteRegEx": "Niedermeier", "year": 2006}, {"title": "Algorithms and complexity results for exact Bayesian structure learning", "author": ["S. Ordyniak", "S. Szeider"], "venue": "Proceedings of UAI 2010, The 26th Conference on Uncertainty in Artificial Intelligence, Catalina", "citeRegEx": "Ordyniak and Szeider,? \\Q2010\\E", "shortCiteRegEx": "Ordyniak and Szeider", "year": 2010}, {"title": "Finding optimal models for small gene", "author": ["S. Ott", "S. Imoto", "S. Miyano"], "venue": "Proceedings of the Pacific Symposium, Hawaii,", "citeRegEx": "Ott et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Ott et al\\.", "year": 2004}, {"title": "Bayesian structure discovery in Bayesian networks with less space", "author": ["P. Parviainen", "M. Koivisto"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Parviainen and Koivisto,? \\Q2010\\E", "shortCiteRegEx": "Parviainen and Koivisto", "year": 2010}, {"title": "Finding optimal Bayesian network given a super-structure", "author": ["E. Perrier", "S. Imoto", "S. Miyano"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Perrier et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Perrier et al\\.", "year": 2008}, {"title": "Learning factor graphs in polynomial time and sample complexity", "author": ["A. Pieter", "K. Daphne", "Y.N. Andrew"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Pieter et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Pieter et al\\.", "year": 2006}, {"title": "On the parameterized complexity of the fixed alphabet shortest common supersequence and longest common subsequence problems", "author": ["K. Pietrzak"], "venue": "J. of Computer and System Sciences,", "citeRegEx": "Pietrzak,? \\Q2003\\E", "shortCiteRegEx": "Pietrzak", "year": 2003}, {"title": "A simple approach for finding the globally optimal Bayesian network structure", "author": ["T. Silander", "P. Myllym\u00e4ki"], "venue": "Proceedings of the 22nd Conference in Uncertainty in Artificial Intelligence,", "citeRegEx": "Silander and Myllym\u00e4ki,? \\Q2006\\E", "shortCiteRegEx": "Silander and Myllym\u00e4ki", "year": 2006}, {"title": "The parameterized complexity of k-flip local search for SAT and MAX SAT", "author": ["S. Szeider"], "venue": "Discrete Optimization,", "citeRegEx": "Szeider,? \\Q2011\\E", "shortCiteRegEx": "Szeider", "year": 2011}, {"title": "Ordering-based search: A simple and effective algorithm for learning bayesian networks", "author": ["M. Teyssier", "D. Koller"], "venue": "Proceedings of the 21st Conference in Uncertainty in Artificial Intelligence,", "citeRegEx": "Teyssier and Koller,? \\Q2005\\E", "shortCiteRegEx": "Teyssier and Koller", "year": 2005}, {"title": "The max-min hill-climbing Bayesian network structure learning algorithm", "author": ["I. Tsamardinos", "L. Brown", "C. Aliferis"], "venue": "Machine Learning,", "citeRegEx": "Tsamardinos et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Tsamardinos et al\\.", "year": 2006}, {"title": "Foundations of Constraint Satisfaction", "author": ["E.P.K. Tsang"], "venue": null, "citeRegEx": "Tsang,? \\Q1993\\E", "shortCiteRegEx": "Tsang", "year": 1993}, {"title": "Learning optimal Bayesian networks using A* search", "author": ["C. Yuan", "B. Malone", "X. Wu"], "venue": "Proceedings of the 22nd International Joint Conference on Artificial Intelligence,", "citeRegEx": "Yuan et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Yuan et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 9, "context": "Unfortunately, solving the problem optimally (Exact BNSL) is NP-complete (Chickering, 1996).", "startOffset": 73, "endOffset": 91}, {"referenceID": 12, "context": ", BNSL is known to be NP-hard if the resulting BN is a polytree (Dasgupta, 1999) or a directed path (Meek, 2001).", "startOffset": 64, "endOffset": 80}, {"referenceID": 45, "context": ", BNSL is known to be NP-hard if the resulting BN is a polytree (Dasgupta, 1999) or a directed path (Meek, 2001).", "startOffset": 100, "endOffset": 112}, {"referenceID": 57, "context": "After the super-structure has been obtained, usually using an IT-based approach (Tsamardinos et al., 2006), one looks for solution networks whose skeletons are contained in the super-structure.", "startOffset": 80, "endOffset": 106}, {"referenceID": 12, "context": ", BNSL is known to be NP-hard if the resulting BN is a polytree (Dasgupta, 1999) or a directed path (Meek, 2001). Recently, a novel approach to restrict the structure of BNSL has been introduced (Tsamardinos, Brown, & Aliferis, 2006; Perrier, Imoto, & Miyano, 2008). Here a so-called super-structure, an undirected graph on the same nodes as the resulting BN, is used to restrict the search space of BNSL in advance. After the super-structure has been obtained, usually using an IT-based approach (Tsamardinos et al., 2006), one looks for solution networks whose skeletons are contained in the super-structure. It hence becomes important that the super-structure is sound, i.e., contains at least one optimal solution. There are two main questions concerning the super-structure: First, how can a suitable and sound super-structure be obtained efficiently? And secondly, once such a superstructure is obtained, how can it be used to guide the search for an optimal solution? The goal of this paper is to provide a theoretical analysis of the latter question, considering super-structures that arise from a given local score function adapting the model of Parviainen and Koivisto (2010). We consider various combinations of restrictions in a systematic way that allows us draw a broader picture of the complexity landscape of BNSL.", "startOffset": 65, "endOffset": 1186}, {"referenceID": 11, "context": "More importantly, treewidth has already been successfully applied in the context of Bayesian Reasoning (Darwiche, 2001; Dechter, 1999; Kwisthout, Bodlaender, & van der Gaag, 2010).", "startOffset": 103, "endOffset": 179}, {"referenceID": 14, "context": "More importantly, treewidth has already been successfully applied in the context of Bayesian Reasoning (Darwiche, 2001; Dechter, 1999; Kwisthout, Bodlaender, & van der Gaag, 2010).", "startOffset": 103, "endOffset": 179}, {"referenceID": 57, "context": "In particular, a highly competitive algorithm for learning large Bayesian networks (MMHC) uses local search to find an optimal solution inside a previously constructed super-structure (Tsamardinos et al., 2006).", "startOffset": 184, "endOffset": 210}, {"referenceID": 38, "context": "These can be split into three groups: (A) exact algorithms that do not employ any restrictions (Parviainen & Koivisto, 2010; Koivisto, 2006; Yuan, Malone, & Wu, 2011; Ott, Imoto, & Miyano, 2004; Silander & Myllym\u00e4ki, 2006; Yuan et al., 2011), (B) exact algorithms using restrictions on the generating or target distribution (Pieter et al.", "startOffset": 95, "endOffset": 241}, {"referenceID": 59, "context": "These can be split into three groups: (A) exact algorithms that do not employ any restrictions (Parviainen & Koivisto, 2010; Koivisto, 2006; Yuan, Malone, & Wu, 2011; Ott, Imoto, & Miyano, 2004; Silander & Myllym\u00e4ki, 2006; Yuan et al., 2011), (B) exact algorithms using restrictions on the generating or target distribution (Pieter et al.", "startOffset": 95, "endOffset": 241}, {"referenceID": 52, "context": ", 2011), (B) exact algorithms using restrictions on the generating or target distribution (Pieter et al., 2006; Chechetka & Guestrin, 2007; Friedman, Nachman, & Pe\u2019er, 1999; Chow & Liu, 1968; Gaspers, Koivisto et al., 2012), and (C) exact algorithms that use restrictions on the undirected super-structure (Friedman et al.", "startOffset": 90, "endOffset": 223}, {"referenceID": 24, "context": ", 2012), and (C) exact algorithms that use restrictions on the undirected super-structure (Friedman et al., 1999; Kojima, Perrier, Imoto, & Miyano, 2010).", "startOffset": 90, "endOffset": 153}, {"referenceID": 52, "context": "Apart from exact algorithms there also exists a variety of approximation algorithms using tree decomposition or degree-based techniques (Pieter et al., 2006; Elidan & Gould, 2008; Karger & Srebro, 2001).", "startOffset": 136, "endOffset": 202}, {"referenceID": 24, "context": ", 2012), and (C) exact algorithms that use restrictions on the undirected super-structure (Friedman et al., 1999; Kojima, Perrier, Imoto, & Miyano, 2010). Algorithms falling into group (A) are only suited for small to medium sized Bayesian networks because they do not restrict the search space in any way. On the other hand, the restrictions used by algorithms in group (B) are more general than restrictions coming from the undirected super-structure and up to now only non-uniform polynomial-time algorithms could be obtained using these restrictions. To the best of our knowledge this paper is the first to employ an in-depth theoretical analysis of the parameterized complexity of BNSL using restrictions on the undirected super-structure. We obtain the first algorithm for exact BNSL with a uniform polynomial running-time with respect to structural restriction on the undirected superstructure. A similar approach has been taken by Kojima et al. (2010), where the authors propose an algorithm for exact BNSL that uses a \u201ccluster-decomposition\u201d of the undirected super-structure.", "startOffset": 91, "endOffset": 960}, {"referenceID": 9, "context": "In particular, BNSL remains NP-hard if the in-degree of the resulting Bayesian network is bounded by 2 (Chickering, 1996), and if the resulting Bayesian network is a poly tree (Dasgupta, 1999), or a directed path (Meek, 2001).", "startOffset": 103, "endOffset": 121}, {"referenceID": 12, "context": "In particular, BNSL remains NP-hard if the in-degree of the resulting Bayesian network is bounded by 2 (Chickering, 1996), and if the resulting Bayesian network is a poly tree (Dasgupta, 1999), or a directed path (Meek, 2001).", "startOffset": 176, "endOffset": 192}, {"referenceID": 45, "context": "In particular, BNSL remains NP-hard if the in-degree of the resulting Bayesian network is bounded by 2 (Chickering, 1996), and if the resulting Bayesian network is a poly tree (Dasgupta, 1999), or a directed path (Meek, 2001).", "startOffset": 213, "endOffset": 225}, {"referenceID": 47, "context": "It has been introduced and pioneered by Downey and Fellows (1999) and is receiving growing interest as reflected by the recent publication of two further monographs (Flum & Grohe, 2006; Niedermeier, 2006) and hundreds of research papers (see references in the above mentioned monographs).", "startOffset": 165, "endOffset": 204}, {"referenceID": 17, "context": "It has been introduced and pioneered by Downey and Fellows (1999) and is receiving growing interest as reflected by the recent publication of two further monographs (Flum & Grohe, 2006; Niedermeier, 2006) and hundreds of research papers (see references in the above mentioned monographs).", "startOffset": 40, "endOffset": 66}, {"referenceID": 14, "context": "Elimination (Dechter, 1999) and Recursive Conditioning (Darwiche, 2001) are two important algorithmic concepts that apply to instances of bounded treewidth.", "startOffset": 12, "endOffset": 27}, {"referenceID": 11, "context": "Elimination (Dechter, 1999) and Recursive Conditioning (Darwiche, 2001) are two important algorithmic concepts that apply to instances of bounded treewidth.", "startOffset": 55, "endOffset": 71}, {"referenceID": 3, "context": "Given a graph G with n nodes and a constant w, it is possible to decide whether G has treewidth at most w, and if so, to compute an optimal tree decomposition of G in time O(n) (Bodlaender, 1996).", "startOffset": 177, "endOffset": 195}, {"referenceID": 38, "context": "We closely follow the abstract framework used by Parviainen and Koivisto (2010) which encloses a wide range of score-based approaches to structure learning.", "startOffset": 64, "endOffset": 80}, {"referenceID": 8, "context": "This setting accommodates several popular scores like BDe, BIC and AIC (Parviainen & Koivisto, 2010; Chickering, 1995).", "startOffset": 71, "endOffset": 118}, {"referenceID": 58, "context": "This representation is also used in other fields, for instance in constraint satisfaction, where only allowed tuples of constraints are listed in the input (Tsang, 1993).", "startOffset": 156, "endOffset": 169}, {"referenceID": 37, "context": "When presenting algorithms for graphs of bounded treewidth it is convenient to consider tree decompositions in the following normal form (Kloks, 1994): A triple (T, \u03c7, r) is a nice tree decomposition of a graph G if (T, \u03c7) is a tree decomposition of G, the tree T is rooted at node r, and each node of T is of one of the following four types:", "startOffset": 137, "endOffset": 150}, {"referenceID": 37, "context": "Because these propositions are well-known (Kloks, 1994) and are immediate consequences of the separator property of tree decompositions we state them without proofs.", "startOffset": 42, "endOffset": 55}, {"referenceID": 37, "context": "Given a tree decomposition of a graph G of width w, one can effectively obtain in time O(|V (G)|) a nice tree decomposition of G with O(|V (G)|) nodes and of width at most w (Kloks, 1994).", "startOffset": 174, "endOffset": 187}, {"referenceID": 11, "context": "The treewidth of a Bayesian network is the treewidth of its moral graph (Darwiche, 2001; Dechter, 1999).", "startOffset": 72, "endOffset": 103}, {"referenceID": 14, "context": "The treewidth of a Bayesian network is the treewidth of its moral graph (Darwiche, 2001; Dechter, 1999).", "startOffset": 72, "endOffset": 103}, {"referenceID": 8, "context": "The following result follows by a reduction due to Chickering (1996).", "startOffset": 51, "endOffset": 69}, {"referenceID": 34, "context": "The problem is NP-hard for digraphs with skeletons of maximum degree 4 (Karp, 1972).", "startOffset": 71, "endOffset": 83}, {"referenceID": 53, "context": "We devise an fpt-reduction from the following problem, which is well-known to be W[1]-complete (Pietrzak, 2003).", "startOffset": 95, "endOffset": 111}, {"referenceID": 43, "context": "For instance, k-local search has already been investigated for combinatorial problems on graphs (Khuller, Bhatia, & Pless, 2003; Marx, 2008; Fellows, Rosamond, Fomin, Lokshtanov, Saurabh, & Villanger, 2009; Gaspers, Kim, Ordyniak, Saurabh, & Szeider, 2012), for the problem of finding a minimum weight assignment for a Boolean constraint satisfaction instance (Krokhin & Marx, 2012), for the stable marriage problem with ties (Marx & Schlotter, 2011), and for the satisfiability problem (Szeider, 2011).", "startOffset": 96, "endOffset": 256}, {"referenceID": 55, "context": "For instance, k-local search has already been investigated for combinatorial problems on graphs (Khuller, Bhatia, & Pless, 2003; Marx, 2008; Fellows, Rosamond, Fomin, Lokshtanov, Saurabh, & Villanger, 2009; Gaspers, Kim, Ordyniak, Saurabh, & Szeider, 2012), for the problem of finding a minimum weight assignment for a Boolean constraint satisfaction instance (Krokhin & Marx, 2012), for the stable marriage problem with ties (Marx & Schlotter, 2011), and for the satisfiability problem (Szeider, 2011).", "startOffset": 487, "endOffset": 502}, {"referenceID": 8, "context": "Important and widely used algorithms for BNSL are based on local search methods (Heckerman, Geiger, & Chickering, 1995). Usually the local search algorithm tries to improve the score of a given dag by transforming it into a new dag by adding, deleting, or reversing one arc at a time (in symbols: add, del, and rev, respectively). The main obstacle for local search methods is the danger of getting stuck at a poor local optimum. A possibility for decreasing this danger is to perform k > 1 elementary changes in one step, known as kNeighborhood Local Search or k-Local Search for short. For BNSL, when we try to improve the score of a dag on n nodes, the k-local search space is of order nO(k). Therefore, if carried out by brute-force, k-local search is too costly even for small values of k. It is therefore not surprising that most practical local search algorithms for BNSL consider 1-neighborhoods only. The study of the parameterized complexity of k-local search was initiated by Fellows (2003). To date a collection of positive and negative results on the parameterized complexity of k-local search for various combinatorial optimization problems are known.", "startOffset": 102, "endOffset": 1002}, {"referenceID": 17, "context": "However, recently we found out that this problem is in fact fixed-parameter tractable and that the proof published in the work of Downey and Fellows (1995) contained a mistake (Fellows, 2012).", "startOffset": 130, "endOffset": 156}, {"referenceID": 55, "context": "Theorem 6 provides a surprising contrast to a similar study of k-local search for MAX-SAT where the problem is fixed-parameter tractable for instances of bounded degree (Szeider, 2011).", "startOffset": 169, "endOffset": 184}], "year": 2013, "abstractText": "Bayesian network structure learning is the notoriously difficult problem of discovering a Bayesian network that optimally represents a given set of training data. In this paper we study the computational worst-case complexity of exact Bayesian network structure learning under graph theoretic restrictions on the (directed) super-structure. The super-structure is an undirected graph that contains as subgraphs the skeletons of solution networks. We introduce the directed super-structure as a natural generalization of its undirected counterpart. Our results apply to several variants of score-based Bayesian network structure learning where the score of a network decomposes into local scores of its nodes. Results: We show that exact Bayesian network structure learning can be carried out in non-uniform polynomial time if the super-structure has bounded treewidth, and in linear time if in addition the super-structure has bounded maximum degree. Furthermore, we show that if the directed super-structure is acyclic, then exact Bayesian network structure learning can be carried out in quadratic time. We complement these positive results with a number of hardness results. We show that both restrictions (treewidth and degree) are essential and cannot be dropped without loosing uniform polynomial time tractability (subject to a complexity-theoretic assumption). Similarly, exact Bayesian network structure learning remains NP-hard for \u201calmost acyclic\u201d directed super-structures. Furthermore, we show that the restrictions remain essential if we do not search for a globally optimal network but aim to improve a given network by means of at most k arc additions, arc deletions, or arc reversals (k-neighborhood local search).", "creator": "TeX"}}}