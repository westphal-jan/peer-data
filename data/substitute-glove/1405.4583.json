{"id": "1405.4583", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-May-2014", "title": "ESSP: An Efficient Approach to Minimizing Dense and Nonsubmodular Energy Functions", "abstract": "Many recent 5-1 while advanced personal have demonstrated a magnificent powerful. dense their nonsubmodular energy constraint followed processes sound statutes problems. However, minimizing many sithe the fairly. None of existing processes (all as s -? notation cut, QPBO, BP and TRW - S) see individually definitely there come. In this articles, 've as an efficient method, besides ESSP, coming optimize corresponding MRFs up explicit pairwise inhibition, new what always nonsubmodular all and dense tcp. We also programs a comparative study of not approach often including criticism choice basic. From really suggested, keep make still any committee for combining build methods as learn be set in different everyday some this challenging does. Experimental positive validate that included low-lying and nonsubmodular energy components, it direct approach reason usually whereby lower photon less the fun involves significant separate rigorous using comparably requirement did.", "histories": [["v1", "Mon, 19 May 2014 03:06:14 GMT  (432kb)", "http://arxiv.org/abs/1405.4583v1", "9 pages, 11 figures"]], "COMMENTS": "9 pages, 11 figures", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["wei feng", "jiaya jia", "zhi-qiang liu"], "accepted": false, "id": "1405.4583"}, "pdf": {"name": "1405.4583.pdf", "metadata": {"source": "CRF", "title": "ESSP: An Efficient Approach to Minimizing Dense and Nonsubmodular Energy Functions", "authors": ["Wei Feng", "Zhi-Qiang Liu"], "emails": ["wfeng@ieee.org"], "sections": [{"heading": null, "text": "ar X\niv :1\n40 5.\n45 83\nv1 [\ncs .C\nV ]\n1 9\nM ay\n2 01\n4 1\nIndex Terms\u2014ESSP, dense and nonsubmodular energy minimization, MRF, image restoration.\n\u2726"}, {"heading": "1 INTRODUCTION", "text": "Algorithms for discrete energy minimization play a fundamental role in computer vision and image analysis. Many early vision problems can be formulated as minimizing an energy function of the following form\nE(x) = \u03b8const + \u2211\nu\u2208N\n\u03b8u(xu) + \u2211\n(u,v)\u2208M\n\u03b8uv(xuxv). (1)\nwhere N is the set of pixels, xu \u2208 L denotes the label of pixel u, and neighborhood system M defines the pairwise dependency between pixels. Sets N and M jointly compose a graph, on which the energy function Eq. (1) is defined. The exact meaning of label space L = {0, 1, \u00b7 \u00b7 \u00b7 , L} depends on the specific problems, e.g., in image segmentation the labels are segment indices, while for stereo they represent disparities. In this paper, we focus on binary labeling problems, i.e., we consider only binary label set L = {0, 1}. For most early vision problems, the energy function of Eq. (1) is derived from the ubiquitous MRF model [1]. Last decade has witnessed the great success of efficient energy minimization techniques in computer vision. Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14]. These methods have triggered a significant progress in the state-of-the-art of many early vision problems,\n\u2022 W. Feng is with School of Computer Science and Technology, Tianjin University, China. E-mail: wfeng@ieee.org (Correspondence author). \u2022 J. Jia is with Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China. Z.-Q. Liu is with School of Creative Media, City University of Hong Kong, Hong Kong, China.\nsuch as image segmentation [15], [16], stereo [2], [17] and restoration [2], [4]. Recently, the performance of these techniques in minimizing energy functions defined on 4- connected grid graphs has been extensively studied [1], [17], [18]. These studies consistently conclude that for some visual labeling problems, such as stereo, existing methods are able to obtain a near global minimum solution efficiently. However, it has also been shown that the optimal labeling proposed by global minimum energy has larger error statistics than other suboptimal solutions for benchmark stereo pairs [18]. This indeed reflects the deficiency of the energy model itself, and suggests that further improvements can only be achieved by using more complicated and powerful models. Most recently, some sophisticated models, such as random fields with higher connectivity [19], [20] and with higher-order cliques [21], [22], [23], [24], have shown their impressive potentials in handling difficult visual labeling problems. Despite the very different formulations of these models, they usually rely on minimizing some dense and nonsubmodular energy functions [21], [25]. However, minimizing such energy functions is challenging for existing techniques [1], [19]. In this paper, we present a new method to optimize general MRFs with arbitrary pairwise potentials. Since the energy function of a binary MRF is a quadratic Pseudo-boolean function (QPBF). Our algorithm can also be viewed as a general approximate solution to dense and nonsubmodular QPBF minimization [26]. The core of our algorithm is an extended submodularsupermodular procedure (ESSP) that expands the classical submodular-supermodular procedure (SSP) [27] to minimize QPBFs of any type. Specifically, we present an undirected graph characterization of QPBF that has two desirable properties: (1) it enables automatic submodular-supermodular decomposition for a QPBF;\n2 and (2) it transforms a QPBF to a symmetric set function, thus providing an efficient way to suppress the supermodular part of the QPBF and to apply more efficient graph cut solutions [28], [29]. The first property extends the application scope of SSP to general QPBF minimization; and the second property enables us to control the accuracy of our optimization and to balance the accuracy and complexity. We provide a thorough comparative study on the performance of existing methods for dense and nonsubmodular QPBF minimization. We evaluated three important factors, i.e., connectivity, supermodularity ratio and unary guidance, that closely affect the hardness of the problem from different aspects. From our study, we figure out several hardness situations of the problem, and make a reasonable recommendation of combining existing methods in each situation that performs the best. Experimental results also validate that for dense and nonsubmodular energy functions, the proposed ESSP algorithm can always be used to improve the results of the best combinations of existing methods with reasonable time."}, {"heading": "2 RELATED WORK", "text": "Function f(x) : {0, 1}n 7\u2192 R is a QPBF if it contains only unary and pairwise items, i.e., f(x) = \u2211\ni u(xi) + \u2211\ni,j p(xi, xj). QPBF is a general energy functional for many problems in computer vision and machine learning. For instance, some combinatorial problems such as graph matching can be formulated as QPBF minimization. QPBF minimization has been studied in discrete optimization for decades [26]. We know that if a QPBF is submodular, it can be exactly minimized in polynomial time. However, minimizing nonsubmodular QPBFs is NPhard. Only approximate methods exist for this general problem. One of such methods is SSP that is designed to minimize the difference of two submodular functions [27]. In this paper, we show that SSP can be generalized to minimize any QPBF based on an undirected graph characterization. QPBF is also a general form of the energy functions of binary MRFs. State-of-the-art methods for binary MRF labeling include BP [6], TRW [9], [10] and graph cuts [3]. An important conclusion is that any submodular QPBF can be exactly minimized by solving an st-mincut problem on a directed graph [3]. For nonsubmodular QPBFs, the roof duality [26] is used to find an optimal partial labeling, which is called QPBO and two variants P and I [4], [5]. Our algorithm is in contrast to the directed graph formulation [3] and QPBO(P,I) [5]. First, the undirected graph characterization maps a QPBF to a symmetric set function, thus making us easily suppress the supermodular part, which is important for the optimality of our algorithm. Second, we use extended SSP to handle nonsubmodular terms. As a result, our algorithm solves a minimum cut problem of an undirected graph, which needs only half the number of nodes of QPBO(P,I)."}, {"heading": "3 THE ESSP ALGORITHM", "text": "We now introduce the proposed ESSP algorithm in detail. The major idea is to convert QPBF minimization to a minimum cut problem on an undirected graph."}, {"heading": "3.1 Undirected Graph Characterization", "text": "We first consider QPBFs of the following form\nE(x) = \u2211\nu\u2208N\n\u03b8uxu + \u2211\n(u,v)\u2208M\n\u03b8uvxuxv, (2)\nwhere N denotes the set of variables need to be optimized, M represents the pairwise correlations between variables. For briefness, we use n = \u2016N\u2016 and m = \u2016M\u2016 denote the number of variables and the number of pairwise terms in E(x), respectively. We show how to effectively characterize Eq. (2) by an undirected graph. Then, we will extend the method to represent general QPBFs as defined in Eq. (1).\nDefinition 1 (Graph characterization). We say a function f(x) is characterized by a graph Gf(x), iff for any particular labeling of x, the function value of f(x) (as induced by x) is equal to the cut value of graph Gf(x) plus a constant.\nProposition 1. For any QPBF with the form of Eq. (2), we have the following conclusions:\n1) Linear monomial \u03b1xu can be characterized by an undirected graph G\u03b1xu (see Fig. 1(a)). 2) Quadratic monomial \u03b2xuxv can be characterized by an undirected graph G\u03b2xuxv (see Fig. 1(b)). 3) Any QPBF E(x) with the form of Eq. (2) can be characterized by an undirected graph GE(x).\nProof: Referring to Fig. 1, it is easy to check the correctness of Conclusion 1 and 2. Conclusion 3 directly results from 1 and 2 due to the additivity property of graph characterization [3], [4].1\nProposition 2. A general QPBF E(x) can be characterized by an undirected graph GE(x). So, argminxE(x) can be computed by solving a minimum cut problem on GE(x).\nProof: A general QPBF E(x) = \u2211\nu\u2208N \u03b8u(xu) + \u2211\n(u,v)\u2208M \u03b8uv(xu, xv) can be transformed to the form of\nEq. (2), in that E(x) = \u2211\nu\u2208N\n[\n\u03b80u(1 \u2212 xu) + \u03b8 1 uxu\n]\n+ \u2211\n(u,v)\u2208M\n[\n\u03b800uv(1\u2212xu)(1\u2212xv)+\u03b8 01 uv(1\u2212xu)xv+\u03b8 10 uvxu(1\u2212\nxv) + \u03b8 11 uvxuxv\n]\n. Then, the conclusion follows directly from Proposition 1. Note that, for briefness, we use \u03b8xuu to represent \u03b8u(xu) and use \u03b8 xuxv uv to represent \u03b8uv(xu, xv), e.g., \u03b80u = \u03b8u(xu = 0) and \u03b8 01 uv = \u03b8uv(xu = 0, xv = 1).\nProposition 2 shows that our algorithm (as introduced in next section) is a general solution to QPBF minimization. Fig. 1(c) and (d) show graph G\u03b8u(xu) and G\u03b8uv(xu,xv) that characterize general unary function \u03b8u(xu) and general quadratic function \u03b8uv(xu, xv) respectively, of which\n1. Note that the undirected graph characterization has also been used in exact inference of planar graphs [30]. In this paper, we use it to extend the classical SSP [27] to optimize QPBFs of any type.\n3\nthe edge capacities are defined as\ncu = \u03b8 1 u \u2212 \u03b8 0 u, (3)\n\n\n\ncu = 1 2 (\u03b8 10 uv + \u03b8 11 uv \u2212 \u03b8 01 uv \u2212 \u03b8 00 uv), cv = 1 2 (\u03b8 01 uv + \u03b8 11 uv \u2212 \u03b8 00 uv \u2212 \u03b8 10 uv), cuv = 1 2 (\u03b8 01 uv + \u03b8 10 uv \u2212 \u03b8 00 uv \u2212 \u03b8 11 uv).\n(4)\nBesides, if denoting the value of indicator node o as xo, the undirected graph characterization implies that any QPBF E(x) can be converted to a symmetric set function F (x, xo) that represents the cut value of GE(x) [28],\nF (x, xo) = \u2211\n(u,v)\u2208{o,1,\u00b7\u00b7\u00b7 ,n}2\ncuv(xu + xv \u2212 2xuxv), (5)\nwhere (u, v) is an edge of GE(x), cuv is its capacity."}, {"heading": "3.2 Flipping Transformation", "text": "For a QPBF E(x), we construct its graph characterization GE(x). Then, minimizing E(x) is transformed to a minimum cut problem on graph GE(x). We already know that E(x) can be exactly minimized if it is submodular [3], [26]. In practice, however, some recent powerful energy functions of real problems are usually nonsubmodular [21], [25]. Minimizing nonsubmodular functions is generally NP-hard, thus approximate solutions are required. Before going to the details of our algorithm, we first introduce an important observation on nonsubmodular functions and an equivalent transformation on the undirected graph characterization. Flipping Variable. For a QPBF E(x) with x = [x1, x2, \u00b7 \u00b7 \u00b7 , xn]\nT , flipping variable x\u0304i is defined as x\u0304i = 1 \u2212 xi. Flipping variable has already been studied and\nused in the literature [4], [26]. In this paper, we mainly use flipping variables to denote a new equivalent transformation. We observe that some nonsubmodular functions can be converted to submodular functions when flipping some original variables. For instance, \u2212x1x2 + x2x3 is nonsubmodular, but it can be transformed to \u2212x1x2 + x2(1 \u2212 x\u03043) = \u2212x1x2 \u2212 x2x\u03043 + x2 that is a submodular function with variables (x1, x2, x\u03043). Unfortunately, not all nonsubmodular functions can be transformed to be submodular by this means, e.g., \u2212x1x2 \u2212 x1x3 + x2x3. But, we will see in next section the benefits of flipping variables in our algorithm.\nEquivalent Transformation. Equivalent transformation refers to reparameterizing the original energy function E(x) to E\u2032(x) that does not change the optimality of E(x) [4]. That is, for any two labelings x1 and x2, E\u2032(x1) \u2264 E\u2032(x2) \u21d4 E(x1) \u2264 E(x2). Since there are two kinds of nodes, i.e., indicator node o and variable node xu, in the undirected graph characterization, we have two types of flipping equivalent transformations.\nThe first type is about flipping the indicator node. As shown in Fig. 2, we can switch the meaning of indicator node from o (denoting label 0) to o\u0304 (denoting label 1) by negativing the capacities of all edges of o. This operation can also be conducted on only a subset of variable nodes. That is, we can use two indicator nodes, o and o\u0304, in graph Gf(x) to characterize f(x). Generally, for an undirected graph Gf(x) characterizing function f(x), flipping o to o\u0304 (or o\u0304 to o) for variable nodes xi \u2208 X makes the graph exactly represent function f(x)\u2212\u00b5, where \u00b5 is the sum of edges capacities linking indicator node to variable nodes in X , where X is the set of all variables in E(x).\nThe second type is about flipping original variable xu to x\u0304u. As shown in Fig. 3, this can also be done by negativing the capacities of all edges of xu. Flipping xu to x\u0304u can be viewed as locally switching the meaning of label 0 and label 1. Specifically, for a QPBF \u03b8uv(xu, xv), its graph characterization can be constructed by setting the edge capacities as Eq. (4). If flipping xu to x\u0304u, then: (1) indicator node o become o\u0304 with the capacity cu for x\u0304u, which can be reparameterized to o with capacity\n4\n\u2212cu; (2) the capacity of edge (x\u0304u, xv) is changed to 1 2 (\u03b8 00 uv + \u03b8 11 uv \u2212 \u03b8 01 uv \u2212 \u03b8 10 uv) = \u2212cuv .\nWe will show in next that flipping transformation can be used to flip original variables in the energy function E(x) to make the submodular part of E(x) as large as possible, which is important for the optimality of our algorithm for QPBF minimization."}, {"heading": "3.3 Submodular-Supermodular Decomposition", "text": "General QPBF minimization is challenging due to the existence of nonsubmodularity. But, there exist effective approximate solutions for some particular form of nonsubmodular functions. SSP is one of such methods and is designed to minimize the sum of a submodular function and a supermodular function [27]. We now extend SSP to minimize general QPBFs based on the undirected graph characterization, which provides us an convenient way to decompose any QPBF E(x) to the sum of a submodular part sub(E(x)) and a supermodular part sup(E(x)). It is known that the cut function of an undirected graph is symmetric, and submodular if all edge capacities are nonnegative. This means that for a QPBF E(x) we can automatically decompose E(x) to sub(E(x))+sup(E(x)) by simply checking the positivity of edge capacities in GE(x)."}, {"heading": "3.4 Supermodular Suppression", "text": "The optimality and efficacy of SSP is highly dependent on the modular approximation of the supermodular function [27]. Therefore, it would be desirable it we could suppress the influence of supermodular part sup(E(x)) as much as possible when minimizing a QPBF E(x) in our process. After submodular-supermodular decomposition, the influence of supermodular function sup(E(x)) can be naturally measured by the sum of all negative edge capacities in GE(x). Consequently, according to the definition of flipping transformation (see Fig. 2 and 3), to minimize the influence of sup(E(x)) equals to minimize the following energy function E\u2032(y) = yT C\u0304y, where y = [y1, \u00b7 \u00b7 \u00b7 , yn]\nT , yi \u2208 {\u22121, 1} indicates whether flipping the ith variable (yi = \u22121) or not (yi = 1) in supermodular\nsuppression, C\u0304 = \u2212C and C is the edge capacity matrix of graph GE(x). Clearly, minimizing E\n\u2032(y) is equivalent to minimize E\u2032\u2032(z) = zT C\u0304z+zT C\u03041with z = [z1, \u00b7 \u00b7 \u00b7 , zn]T and zi = yi+1 2 \u2208 {0, 1}, which is another dense and nonsubmodular energy function.\nFor simplicity and efficiency, instead of optimizing E\u2032\u2032(z) that is equally difficult as minimizing the original QPBF E(x), in this paper, we present an efficient greedy process to suppress the supermodular part of GE(x). Note that, we need only consider the edges linking two variable nodes, i.e., the variable edges, in supermodular suppression. We first derive a descending order \u03c0 of all variable nodes according to the ratio of \u03a3neg\u03a3all , where \u03a3neg and \u03a3all are the sum of absolute values of all negative capacities and all edge capacities, for each variable node, respectively. We then maintain a list t that records the variable nodes and their ratios of negative variable edges in the order of \u03c0. Then, we sequentially check node x\u03c0i in t. If the ratio is larger than 0.5, we flip x\u03c0i to x\u0304\u03c0i and update t accordingly. We repeat this process until no variable node need to be flipped. This can be done for any undirected graph, since in each iteration we decrease the overall influence of negative variable edges in GE(x), and stop when no variable node can be flipped. Fig. 4 shows an example of this process. Note that, there may exist multiple ways for supermodular suppression using different orders. However, the complexity of exhaustive search for the optimal flipping sequence is 2n. Besides, note that the above greedy process guarantees, in linear time, the influence of supermodular part sup(E(x)) is smaller than that of submodular part sub(E(x)). We also tested to use QPBO(P) to suppress supermodular part, since labeled nodes are guaranteed to be globally optimal. But, we found that it could barely produce better labeling. This reflects that for QPBFs with low supermodular ratios, ESSP with the proposed greedy suppression works as well as QPBO(P). Since for larger supermodular ratios few nodes will be labeled by\n5 QPBO(P), QPBO(P) cannot provide better suppression than the proposed greedy process. In the above, we consider only negative variable edges in GE(x). For negative edges (o, xu) linking indicator node o and variable nodes xu, which is called indicate edges, we can equivalently replace them by edges (o\u0304, xu) with positive capacities. As a result, after supermodular suppression, graph GE(x) contains two indicator nodes o and o\u0304."}, {"heading": "3.5 The Algorithm", "text": "We now present our algorithm for general QPBF minimization in Algorithm 1. The proposed ESSP algorithm is an iterative refinement process. The initial labeling x(0) can be the output of other methods or randomly generated. The performance of different initialization is compared in the experiments section. Each iteration of the ESSP algorithm consists of three major steps: (1) modular approximation,2 (2) maxflow computation, and (3) repermutation. The process iteratively refine the initial labeling according to the random permutation \u03c0(i). Each permutation actually corresponds to a set of labelings. Different permutations may lead to different local minima. To avoid being trapped to a poor local minimum, for each iteration of ESSP, we try K = 5 random permutations in our experiments.\nGraph Simplification. Some methods, such as QPBO(P) may produce partial labelings [4], [5]. Those labeled variables is guaranteed to be globally optimal. In this situations, we can simplify the graph and only focus on minimizing those unlabeled variables. Fig. 5 shows how to simplify a graph given a partial labeling. Efficient Implementation. If the modular approximation generates the same m(i)(x) as the last iteration, we need not run the maxflow algorithm. Furthermore, if the difference between m(i)(x) and m(i\u22121)(x) is only related to a small number of variables, the maxflow computation of last iteration can be efficiently reused [31]. For a QPBF of large size, we can improve the efficiency by locally refining the initial labeling using our ESSP algorithm. Specifically, we need just simplify the graph energy by fixing some variables to their initial labels and refine other variables.\n2. Refer to [27] for more details about modApproximation(\u00b7) in Algorithm 1.\nAlgorithm 1 The ESSP Algorithm\nInput: QPBF E(x) and an initial labeling x(0) Output: approximate minimizer x\u2217 of E(x)\nConstruct graph characterization GE(x) for E(x) Supermodular suppression of GE(x) Decompose GE(x) to Gsub(E(x)) and Gsup(E(x)) if isNotEmpty(Gsup(E(x))) then\n\u03c0(0) \u2190 randomPermutation(x(0)) repeat\nm(i)(x)\u2190 modApproximation(sup(E(x)), \u03c0(i\u22121)) x (i) \u2190 argminx [ sub(E(x)) +m(i)(x) ]\n\u03c0(i) \u2190 randPermutation(x(i)) until isEqual(x(i),x(i\u22121)) is true\nelse Solving an st-mincut on graph Gsub(E(x)) end if Converting flipping variables to original forms in x\u2217\nOptimality and Complexity. General QPBF minimization is NP-hard, thus we can only obtain a suboptimal labeling by ESSP. In each iteration, ESSP actually minimizes an upper bound of the objective function. Given an initial permutation, ESSP iteratively generates a refined labeling with smaller energy. According to the convergence of SSP [27], ESSP is also guaranteed to converge to a local optimum. Besides, automatic submodular-supermodular decomposition also enables us to tell whether the solution is a global optimum or not. Except for maxflow computation, all other steps of ESSP algorithm are of linear complexity. Thus, the complexity of ESSP algorithm is O(TM), where T is the number of iterations and M is the state-of-theart complexity of maxflow computation on undirected graphs [26], [28], [29]. Compared to the directed graph formulation and QPBO [4], [5], ESSP has half number of vertices in the undirected graph characterization. From our experiments, we find that ESSP usually converges within a small number of iterations when fed by a proper initialization."}, {"heading": "4 EXPERIMENTAL RESULTS", "text": "We now evaluate the performance of our ESSP algorithm and several state-of-the-art methods, i.e., BP [6], TRW-S [10] and QPBO(P,I) [4], [5], on minimizing dense and nonsubmodular energy functions.3 Synthetic Comparison. Our first evaluation was based on synthetic QPBFs. We did synthetic comparison due to two reasons. First, unlike the classical energies defined in 4-connected grid graphs, dense and nonsubmodular QPBFs have only been studied and applied in computer vision recently. Both its potential and difficulty may not necessarily limited in the range of real energies currently available in computer vision. Instead, it would be much more useful if we could figure out what factors\n3. For QPBO, we used the authors\u2019 original implementation. For BP and TRW-S, we used the speed-up implementation introduced in [19]. All source codes used in our experiments, including the proposed ESSP, are publicly available online.\n6 000 50 100 150 200 250 300 350 4 -4000 -3500 -3000 -2500 -2000 -1500 -1000 -500\nTime (s)\nE n\ne rg\ny\nQPBO(P) 100% unlabel\nTRW-S BP rand + QPBO-I rand + ESSP BP + QPBO-I BP + ESSP\n(a)\n0 5 10 15 20 25 30 35 40\n4000\n-3500\n-3000\n-2500\n-2000\n-1500\n-1000\nTest cases\nE n\ne rg\ny\nQPBO(P) 100% unlabel\n- (b)\nFig. 6. Comparison results of six algorithms for dense and nonsubmodular QPBF minimization: (a) average energy vs. running time curves for 20 QPBFs of 500 variables with Cr = 50%, Sr = 50% and Ug = 0.1; (b) the obtained energies for 40 random QPBFs under the same configuration. Each algorithm was forced to run at most 60 seconds in (b).\nof the energy function primarily affect the optimization hardness. Different combinations of these factors define several hardness situations of the problem. We are more interested in finding out the best combination of existing techniques in minimizing dense and nonsubmodular energies at each hardness situation. This will provide a useful guidance for future study and application of such energies in practice. Using synthetic energies, we can easily control the degree of these factors and systematically compare the performance of existing methods, while current real energies may not cover a large spectrum of these factors yet. Second, as stated in [18], [19], the performance of different methods for real energies depends on both the power of energy models and the efficacy of energy minimization methods. Using synthetic energies, we can rule out the influence of energy models and purely focus on evaluating the performance of optimization methods only.\nWe generated synthetic binary energy functions with the form of Eq. (2), of which the coefficients \u03b8u and \u03b8uv were randomly generated from a uniform distribution U(0, 10). Proposition 2 guarantees that, by this means, we can produce any QPBF with random coefficients. We empirically find three major factors that impact the hardness of the problem: (1) connectivity Cr = 2eV\nn2 (n\nis the number of variable nodes, eV is the number of variable edges, i.e., edges linking variable nodes), (2) supermodular ratio Sr = eV\u2212 eV (eV\u2212 and eV+ is the number of variable edges of negative and positive capacities, respectively, and eV = eV\u2212+eV+), and (3) unary guidance Ug = meanu(|cuo|,|cuo\u0304|)\nmeanuv |cuv| (cuo, cuo\u0304 and cuv is the capacity of\nedge uo, uo\u0304 and uv, respectively).\nFig. 6(a) plots the average energy vs. time curves of six combinations of existing methods in minimizing 20 random QPBFs with 500 variables and Cr = 50%, Sr = 50% and Ug = 0.1. The tested methods include BP and TRW-S (both were run for 5000 iterations), QPBO-I and ESSP with random initialization, QPBO-I and ESSP initialized by BP (50 iterations). We do not show the results of QPBO and QPBO-P since under this configuration almost all variables were unlabeled by QPBO(P). We can see that for those optimization methods based on solving LP relaxation, such as TRW-S and QPBO, minimizing dense and nonsubmodular energy functions is extremely difficult. In contrast, other methods such as BP, ESSP and QPBO-I can obtain a relatively lower energy. Note that BP+ESSP clearly outperforms other methods in this test. This is due to the good initialization provided by BP (as compared to other methods) and the fast convergence speed of ESSP. As discussed later, the appealing performance of BP in this test is mainly attributed to the strong unary guidance. Fig 6(b) shows the produced energy of the six solvers for 40 QPBFs generated using the same configuration. This time, we adjusted the maximal iterations of each solver to make them produce results within 60 seconds. We can see that using comparable time, QPBO-I with random initialization generated the highest energies. But, using the same random initialization, ESSP obtained much lower energy.\nThen, we evaluate the influence of supermodularity to the performance of different methods. Fig. 7 shows the comparison results. Note that if the supermodular ratio Cr is close to zero, then QPBO(P) is able to label all variables thus we can efficiently obtain a global optimum labeling. Note that although all tested methods produced the same energy to QPBO(P) in the first figure, only QPBO(P) and the algorithms initialized by QPBO(P) are theoretically guaranteed to obtain the global minimum energy.\nThen, to make a thorough comparison, we randomly generated 2880 QPBFs of 600 variables that covered a large range of connectivity Cr \u2208 {0.1, 0.2, 0.3, 0.4, 0.5, 0.6}, supermodularity ratio Sr \u2208 {0.1, 0.2, 0.3, 0.4, 0.5, 0.6} and unary guidance Ug \u2208 {0, 0.03, 0.1, 0.15}. For each configuration of Cr , Sr and Ug, we tested 20 QPBFs. We plotted the performance curves of different methods for each factor value by marginalizing all its energy vs. time curves under this factor value. Fig. 8, 9 and 10 show the performance curves of six testing methods under different situations of connectivity, supermodularity and unary guidance.\nSince the performance and tradeoff of existing tech-\nE n\ne rg\ny\nE n\ne rg\ny\nE n\ne rg\ny\nE n\ne rg\ny\nniques on minimizing sparse energies defined in 4- connected grid graphs is well-understood in computer vision [1], [17], as shown in Fig. 8, our study focused on minimizing dense energy functions. We can see that the convergence speed of ESSP clearly outperforms QPBOI using the same initialization as the connectivity increases. It is worth to note that the initialization of BP is usually better than QPBO(P). This is mainly because for dense and nonsubmodular energies, most variables cannot be certainly labeled by QPBO(P). Thus, in this situation, initialization by QPBO(P) is very close to random initialization. Fig. 9 tells us that lower Sr implies less hardness of the problem. All methods, except for TRW-S, can obtain a comparable low energy for Sr < 20%. ESSP and QPBO-I provided by a good initialization can always obtain the lowest energy. But, QPBO-I still needs much more time to converge than ESSP. We also tested the performance of different methods when supermodular ratio Sr is very small. Under this configuration, QPBO(P) is able to label almost all variables, thus we can certainly obtain a global optimum labeling. It is also worth to\n8 BP TRW-S rand+ESSPQPBONoisy image\nBP+ESSP BP+QPBO-I TRW-S+QPBO-ITRW-S+ESSPClean image\n(2606.7/0.5s) (-443.1/1.7s) (-425.3/1.8s) (-864.5/4.9s)\n(-940.6/54.0s)(-943.1/53.8s)(-922.8/4.1s)(-943.5/3.2s)\nFig. 11. Binary image restoration of different methods. The energy and time for each method are shown in the format of \u2018energy/time(s)\u2019. The lower bound of the energy function is \u2212980.0.\nnote that for energy functions with low Sr, we can use the partial labeling generated by QPBO(P) to simplify the graph of ESSP and run ESSP to seek a suboptimal labeling for other variables. In our tests, however, we found that this is equivalent to initializing ESSP by the output of QPBO(P). The optimality of the partial labeling generated by QPBO(P) can also be preserved by ESSP.\nFrom Fig. 10, we can see that if the energy function provides weak unary guidance, i.e., Ug \u2248 0, BP and TRW-S equally perform worse than ESSP and QPBO-I with random initialization. However, when the unary guidance is strong enough, BP can usually obtain a relatively low energy. The unary guidance actually reflects the consistency of unary and pairwise potentials. For an energy function in computer vision, Ug = 0 means that the unary terms caused by data likelihood fully contradict the unary terms contributed by pairwise potentials, thus may apparently increase the hardness of the problem.\nImage Restoration. We also tested different methods on binary image restoration based on the KAIST Chinese character database. Specifically, we 50 images to train a dense pairwise prior function for a particular character \u03c8(x) = \u2211\n(u,v)\u2208N 2 fuv(xu, xv), where N is the set of pixels, fuv(xu, xv) is the appearance frequency of labeling (xu, xv) for pixel u and v in the training data. As we consider every pixel pair and the desired labeling can be either 00, 01, 10 or 11, the prior function is certainly dense and nonsubmodular. In our experiments, the average Cr is above 70%, and average Sr is about 20%. To avoid over-fitting, we omit those labelings whose appearance frequency in the training data is less than 10%. Using the trained dense prior function \u03c8(x), we restore a noisy image by minimizing the energy function E(x) = \u03b1 \u2211\nu \u22121 1+|Yu\u2212xu| + \u03b2\u03c8(x), where Yu is\nthe appearance of noisy image for pixel u, xu is its label. Fig. 11 shows the restoration results for one character.\nDiscussion. In our experiments, we found that TRWS consistently performs worse than other methods. This is in contrast to their performances for sparse energy functions [1], [18]. The difficulty of TRW-S on solving dense energy functions was also found and analyzed in [19]. It seems that dense connectivity has much more\nnegative influence to the performance of LP relaxation based methods, e.g., QPBO and TRW-S, than other techniques, e.g., BP, QPBO-I and ESSP. The experiments show that ESSP has much faster convergence speed than QPBO-I given the same initialization. Note that we did not make any speed optimization in our implementation. As shown in Fig. 8, 9 and 10, QPBO-I is able to produce a lower energy than ESSP if given enough long time. Both the performance of ESSP and QPBO-I depends on the goodness of initialization. For ESSP, bad initialization leads to a poor local minimum, while good initialization leads to a much lower energy (see Fig. 6). In contrast, for QPBO-I, bad initialization means much slower convergence speed than good initialization. Our comparative study helps to understand the hardness of dense and nonsubmodular energy minimization. More importantly, from our study, we can make some promising recommendations of existing methods in different situations that performs the best to minimize such challenging energies, as summarized in Table 1. Generally, no existing methods are able to handle all situations. But, the proposed ESSP algorithm can always be used to efficiently improve the labeling obtained by existing methods for dense and nonsubmodular binary MRF energy functions. Note that, Ug \u2248 0 corresponds to the most difficult case, since both ESSP and QPBO-I cannot be initialized properly."}, {"heading": "5 CONCLUSIONS", "text": "We have proposed a new algorithm, namely ESSP, to minimize dense and nonsubmodular energy functions. Such kind of energies has recently shown great potentials in computer vision. Our approach is based on an undirected graph characterization of QPBFs, which enables us to extend the classical submodular-supermodular procedure [27] to a general solver for generic binary labeling problems. Experiments show that for dense and nonsubmodular energy functions, our ESSP algorithm can usually improve the results of existing methods with reasonable time. We have also provided a thorough comparative study on minimizing dense and nonsubmodular QPBFs by existing techniques. We empirically find out three important factors, i.e., connectivity, supermodularity and unary guidance, that closely relate to the hardness of the problem. Based on our study, we finally make several reasonable recommendations of combining existing methods in different situations to minimize such challenging energies. We believe our study presents a positive guidance for future modeling and applications of general energy functions in computer vision. There are several open questions about the ESSP algorithm. Like SSP, ESSP is also an iterative refinement process. It would be desirable if we could analyze the bound on the maximal number of iterations. From our experiments, we observe that ESSP usually converges\n9\nto a local minimum after a small number of iterations. Besides, combining ESSP with other recent optimization methods, such as [29], [32], is an interesting direction for future work."}, {"heading": "ACKNOWLEDGMENTS", "text": "This work is supported by the Program for New Century Excellent Talents in University (NCET-11-0365), National Nature Science Foundation of China (61100121), and National Science and Technology Support Project (2013BAK01B01)."}], "references": [{"title": "A comparative study of energy minimization methods for Markov random fields with smoothness-based priors", "author": ["R. Szeliski", "R. Zabih", "D. Scharstein", "O. Veksler", "V. Kolmogorov", "A. Agarwala", "M. Tappen", "R. Rother"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 30, no. 6, pp. 1068\u20131080, 2008.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2008}, {"title": "Fast approximate energy minimization via graph cuts", "author": ["Y. Boykov", "O. Veksler", "R. Zabih"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 23, no. 11, pp. 1222\u20131239, 2001.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2001}, {"title": "What energy functions can be minimized via graph cuts?", "author": ["V. Kolmogorov", "R. Zabih"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2004}, {"title": "Minimizing non-submodular functions with graph cuts \u2013 a review", "author": ["V. Kolmogorov", "C. Rother"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 29, no. 7, pp. 1274\u20131279, 2007.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2007}, {"title": "Optimizing binary MRFs via extended roof duality", "author": ["C. Rother", "V. Kolmogorov", "V. Lempitsky", "M. Szummer"], "venue": "CVPR, 2007.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "On the optimality of solutions of the max-product belief-propagation algorithm in arbitrary graphs", "author": ["Y. Weiss", "W. Freeman"], "venue": "IEEE Trans. Inf. Theory, vol. 47, no. 2, pp. 736\u2013744, 2001.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2001}, {"title": "Generalized belief propagation", "author": ["J. Yedidia", "W. Freeman", "Y. Weiss"], "venue": "NIPS, 2000.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2000}, {"title": "Efficient belief propagation for early vision", "author": ["P. Felzenszwalb", "D. Huttenlocher"], "venue": "Int\u2019l J. Computer Vision, vol. 70, no. 1, p. 4154, 2006.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2006}, {"title": "MAP estimation via agreement on trees: Message-passing and linear-programming approaches", "author": ["M. Wainwright", "T. Jaakkola", "A. Willsky"], "venue": "IEEE Trans. Inf. Theory, vol. 51, no. 11, pp. 3697\u20133717, 2005.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2005}, {"title": "A linear programming approach to max-sum problem: A review", "author": ["T. Werner"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 29, no. 7, pp. 1165\u20131179, 2007.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "Exact optimization for Markov random fields with convex priors", "author": ["H. Ishikawa"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 25, no. 10, pp. 1333\u20131336, 2003.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2003}, {"title": "Efficiently solving convex relaxations for MAP estimation", "author": ["M. Kumar", "P. Torr"], "venue": "ICML, 2008.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2008}, {"title": "An analysis of convex relaxations for MAP estimation", "author": ["M. Kumar", "V. Kolmorgorov", "P. Torr"], "venue": "NIPS, 2007.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2007}, {"title": "Self-validated labeling of Markov random fields for image segmentation", "author": ["W. Feng", "J. Jia", "Z.-Q. Liu"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 32, no. 10, pp. 1871\u20131887, 2010.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1871}, {"title": "Region-level image authentication using Bayesian structural content abstraction", "author": ["W. Feng", "Z.-Q. Liu"], "venue": "IEEE Trans. Image Process., vol. 17, no. 12, pp. 2413\u20132424, 2008.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2008}, {"title": "Comparison of graph cuts with belief propagation for stereo using identical mrf parameters", "author": ["M. Tappen", "W. Freeman"], "venue": "ICCV, 2003.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2003}, {"title": "Globally optimal solutions for energy minimization in stereo vision using reweighted belief propagation", "author": ["T. Meltzer", "C. Yanover", "Y. Weiss"], "venue": "ICCV, 2005.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2005}, {"title": "Comparison of energy minimization algorithms for highly connected graphs", "author": ["V. Kolmogorov", "C. Rother"], "venue": "ECCV, 2006.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2006}, {"title": "Fields of experts: A framework for learning image priors", "author": ["S. Roth", "M.J. Black"], "venue": "CVPR, 2005.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2005}, {"title": "Minimizing sparse higher order energy functions of discrete variables", "author": ["C. Rother", "P. Kohli", "W. Feng", "J. Jia"], "venue": "CVPR, 2009.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2009}, {"title": "Global stereo reconstruction under second order smoothness priors", "author": ["O. Woodford", "P. Torr", "I. Reid", "A. Fitzgibbon"], "venue": "CVPR, 2008.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2008}, {"title": "Efficient belief propagation with learned higher-order Markov random fields", "author": ["X. Lan", "S. Roth", "D. Huttenlocher", "M.J. Black"], "venue": "ECCV, 2006.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2006}, {"title": "Inference for order reduction in Markov random fields", "author": ["A.C. Gallagher", "D. Batra", "D. Parikh"], "venue": "CVPR, 2012.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2012}, {"title": "A graph cut algorithm for higher-order Markov random fields", "author": ["A. Fix", "A. Gruber", "E. Boros", "R. Zabih"], "venue": "ICCV, 2011.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2011}, {"title": "Pseudo-boolean optimization", "author": ["E. Boros", "P. Hammer"], "venue": "Discrete Applied Mathematics, vol. 123, pp. 155\u2013225, 2002.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2002}, {"title": "A submodular-supermodular procedure with applications to discriminative structure learning", "author": ["M. Narasimhan", "J. Bilmes"], "venue": "UAI, 2005.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2005}, {"title": "Minimizing symmetric submodular functions", "author": ["M. Queyranne"], "venue": "Math. Programming, vol. 82, pp. 3\u201312, 1998.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1998}, {"title": "Max flows in O(nm) time, or better", "author": ["J.B. Orlin"], "venue": "2012.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2012}, {"title": "Efficient exact inference in planar Ising models", "author": ["N. Schraudolph", "D. Kamenetsky"], "venue": "NIPS, 2006.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2006}, {"title": "Dynamic graph cuts for efficient inference in Markov random fields", "author": ["P. Kohli", "P. Torr"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 29, no. 12, pp. 2079\u20132088, 2007.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2007}, {"title": "Beyond loose LP-relaxations: Optimizing MRFs by repairing cycles", "author": ["N. Komodakis", "N. Paragios"], "venue": "ECCV, 2008.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "(1) is derived from the ubiquitous MRF model [1].", "startOffset": 45, "endOffset": 48}, {"referenceID": 1, "context": "Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14].", "startOffset": 49, "endOffset": 52}, {"referenceID": 2, "context": "Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14].", "startOffset": 54, "endOffset": 57}, {"referenceID": 3, "context": "Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14].", "startOffset": 59, "endOffset": 62}, {"referenceID": 4, "context": "Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14].", "startOffset": 64, "endOffset": 67}, {"referenceID": 5, "context": "Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14].", "startOffset": 93, "endOffset": 96}, {"referenceID": 6, "context": "Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14].", "startOffset": 98, "endOffset": 101}, {"referenceID": 7, "context": "Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14].", "startOffset": 103, "endOffset": 106}, {"referenceID": 8, "context": "Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14].", "startOffset": 145, "endOffset": 148}, {"referenceID": 9, "context": "Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14].", "startOffset": 175, "endOffset": 179}, {"referenceID": 10, "context": "Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14].", "startOffset": 211, "endOffset": 215}, {"referenceID": 11, "context": "Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14].", "startOffset": 217, "endOffset": 221}, {"referenceID": 12, "context": "Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14].", "startOffset": 223, "endOffset": 227}, {"referenceID": 13, "context": "such as image segmentation [15], [16], stereo [2], [17] and restoration [2], [4].", "startOffset": 27, "endOffset": 31}, {"referenceID": 14, "context": "such as image segmentation [15], [16], stereo [2], [17] and restoration [2], [4].", "startOffset": 33, "endOffset": 37}, {"referenceID": 1, "context": "such as image segmentation [15], [16], stereo [2], [17] and restoration [2], [4].", "startOffset": 46, "endOffset": 49}, {"referenceID": 15, "context": "such as image segmentation [15], [16], stereo [2], [17] and restoration [2], [4].", "startOffset": 51, "endOffset": 55}, {"referenceID": 1, "context": "such as image segmentation [15], [16], stereo [2], [17] and restoration [2], [4].", "startOffset": 72, "endOffset": 75}, {"referenceID": 3, "context": "such as image segmentation [15], [16], stereo [2], [17] and restoration [2], [4].", "startOffset": 77, "endOffset": 80}, {"referenceID": 0, "context": "Recently, the performance of these techniques in minimizing energy functions defined on 4connected grid graphs has been extensively studied [1], [17], [18].", "startOffset": 140, "endOffset": 143}, {"referenceID": 15, "context": "Recently, the performance of these techniques in minimizing energy functions defined on 4connected grid graphs has been extensively studied [1], [17], [18].", "startOffset": 145, "endOffset": 149}, {"referenceID": 16, "context": "Recently, the performance of these techniques in minimizing energy functions defined on 4connected grid graphs has been extensively studied [1], [17], [18].", "startOffset": 151, "endOffset": 155}, {"referenceID": 16, "context": "However, it has also been shown that the optimal labeling proposed by global minimum energy has larger error statistics than other suboptimal solutions for benchmark stereo pairs [18].", "startOffset": 179, "endOffset": 183}, {"referenceID": 17, "context": "Most recently, some sophisticated models, such as random fields with higher connectivity [19], [20] and with higher-order cliques [21], [22], [23], [24], have shown their impressive potentials in handling difficult visual labeling problems.", "startOffset": 89, "endOffset": 93}, {"referenceID": 18, "context": "Most recently, some sophisticated models, such as random fields with higher connectivity [19], [20] and with higher-order cliques [21], [22], [23], [24], have shown their impressive potentials in handling difficult visual labeling problems.", "startOffset": 95, "endOffset": 99}, {"referenceID": 19, "context": "Most recently, some sophisticated models, such as random fields with higher connectivity [19], [20] and with higher-order cliques [21], [22], [23], [24], have shown their impressive potentials in handling difficult visual labeling problems.", "startOffset": 130, "endOffset": 134}, {"referenceID": 20, "context": "Most recently, some sophisticated models, such as random fields with higher connectivity [19], [20] and with higher-order cliques [21], [22], [23], [24], have shown their impressive potentials in handling difficult visual labeling problems.", "startOffset": 136, "endOffset": 140}, {"referenceID": 21, "context": "Most recently, some sophisticated models, such as random fields with higher connectivity [19], [20] and with higher-order cliques [21], [22], [23], [24], have shown their impressive potentials in handling difficult visual labeling problems.", "startOffset": 142, "endOffset": 146}, {"referenceID": 22, "context": "Most recently, some sophisticated models, such as random fields with higher connectivity [19], [20] and with higher-order cliques [21], [22], [23], [24], have shown their impressive potentials in handling difficult visual labeling problems.", "startOffset": 148, "endOffset": 152}, {"referenceID": 19, "context": "Despite the very different formulations of these models, they usually rely on minimizing some dense and nonsubmodular energy functions [21], [25].", "startOffset": 135, "endOffset": 139}, {"referenceID": 23, "context": "Despite the very different formulations of these models, they usually rely on minimizing some dense and nonsubmodular energy functions [21], [25].", "startOffset": 141, "endOffset": 145}, {"referenceID": 0, "context": "However, minimizing such energy functions is challenging for existing techniques [1], [19].", "startOffset": 81, "endOffset": 84}, {"referenceID": 17, "context": "However, minimizing such energy functions is challenging for existing techniques [1], [19].", "startOffset": 86, "endOffset": 90}, {"referenceID": 24, "context": "Our algorithm can also be viewed as a general approximate solution to dense and nonsubmodular QPBF minimization [26].", "startOffset": 112, "endOffset": 116}, {"referenceID": 25, "context": "The core of our algorithm is an extended submodularsupermodular procedure (ESSP) that expands the classical submodular-supermodular procedure (SSP) [27] to minimize QPBFs of any type.", "startOffset": 148, "endOffset": 152}, {"referenceID": 26, "context": "and (2) it transforms a QPBF to a symmetric set function, thus providing an efficient way to suppress the supermodular part of the QPBF and to apply more efficient graph cut solutions [28], [29].", "startOffset": 184, "endOffset": 188}, {"referenceID": 27, "context": "and (2) it transforms a QPBF to a symmetric set function, thus providing an efficient way to suppress the supermodular part of the QPBF and to apply more efficient graph cut solutions [28], [29].", "startOffset": 190, "endOffset": 194}, {"referenceID": 24, "context": "QPBF minimization has been studied in discrete optimization for decades [26].", "startOffset": 72, "endOffset": 76}, {"referenceID": 25, "context": "One of such methods is SSP that is designed to minimize the difference of two submodular functions [27].", "startOffset": 99, "endOffset": 103}, {"referenceID": 5, "context": "State-of-the-art methods for binary MRF labeling include BP [6], TRW [9], [10] and graph cuts [3].", "startOffset": 60, "endOffset": 63}, {"referenceID": 8, "context": "State-of-the-art methods for binary MRF labeling include BP [6], TRW [9], [10] and graph cuts [3].", "startOffset": 69, "endOffset": 72}, {"referenceID": 2, "context": "State-of-the-art methods for binary MRF labeling include BP [6], TRW [9], [10] and graph cuts [3].", "startOffset": 94, "endOffset": 97}, {"referenceID": 2, "context": "An important conclusion is that any submodular QPBF can be exactly minimized by solving an st-mincut problem on a directed graph [3].", "startOffset": 129, "endOffset": 132}, {"referenceID": 24, "context": "For nonsubmodular QPBFs, the roof duality [26] is used to find an optimal partial labeling, which is called QPBO and two variants P and I [4], [5].", "startOffset": 42, "endOffset": 46}, {"referenceID": 3, "context": "For nonsubmodular QPBFs, the roof duality [26] is used to find an optimal partial labeling, which is called QPBO and two variants P and I [4], [5].", "startOffset": 138, "endOffset": 141}, {"referenceID": 4, "context": "For nonsubmodular QPBFs, the roof duality [26] is used to find an optimal partial labeling, which is called QPBO and two variants P and I [4], [5].", "startOffset": 143, "endOffset": 146}, {"referenceID": 2, "context": "Our algorithm is in contrast to the directed graph formulation [3] and QPBO(P,I) [5].", "startOffset": 63, "endOffset": 66}, {"referenceID": 4, "context": "Our algorithm is in contrast to the directed graph formulation [3] and QPBO(P,I) [5].", "startOffset": 81, "endOffset": 84}, {"referenceID": 2, "context": "Conclusion 3 directly results from 1 and 2 due to the additivity property of graph characterization [3], [4].", "startOffset": 100, "endOffset": 103}, {"referenceID": 3, "context": "Conclusion 3 directly results from 1 and 2 due to the additivity property of graph characterization [3], [4].", "startOffset": 105, "endOffset": 108}, {"referenceID": 28, "context": "Note that the undirected graph characterization has also been used in exact inference of planar graphs [30].", "startOffset": 103, "endOffset": 107}, {"referenceID": 25, "context": "In this paper, we use it to extend the classical SSP [27] to optimize QPBFs of any type.", "startOffset": 53, "endOffset": 57}, {"referenceID": 26, "context": "Besides, if denoting the value of indicator node o as xo, the undirected graph characterization implies that any QPBF E(x) can be converted to a symmetric set function F (x, xo) that represents the cut value of GE(x) [28],", "startOffset": 217, "endOffset": 221}, {"referenceID": 2, "context": "We already know that E(x) can be exactly minimized if it is submodular [3], [26].", "startOffset": 71, "endOffset": 74}, {"referenceID": 24, "context": "We already know that E(x) can be exactly minimized if it is submodular [3], [26].", "startOffset": 76, "endOffset": 80}, {"referenceID": 19, "context": "In practice, however, some recent powerful energy functions of real problems are usually nonsubmodular [21], [25].", "startOffset": 103, "endOffset": 107}, {"referenceID": 23, "context": "In practice, however, some recent powerful energy functions of real problems are usually nonsubmodular [21], [25].", "startOffset": 109, "endOffset": 113}, {"referenceID": 3, "context": "used in the literature [4], [26].", "startOffset": 23, "endOffset": 26}, {"referenceID": 24, "context": "used in the literature [4], [26].", "startOffset": 28, "endOffset": 32}, {"referenceID": 3, "context": "refers to reparameterizing the original energy function E(x) to E(x) that does not change the optimality of E(x) [4].", "startOffset": 113, "endOffset": 116}, {"referenceID": 25, "context": "SSP is one of such methods and is designed to minimize the sum of a submodular function and a supermodular function [27].", "startOffset": 116, "endOffset": 120}, {"referenceID": 25, "context": "The optimality and efficacy of SSP is highly dependent on the modular approximation of the supermodular function [27].", "startOffset": 113, "endOffset": 117}, {"referenceID": 3, "context": "Some methods, such as QPBO(P) may produce partial labelings [4], [5].", "startOffset": 60, "endOffset": 63}, {"referenceID": 4, "context": "Some methods, such as QPBO(P) may produce partial labelings [4], [5].", "startOffset": 65, "endOffset": 68}, {"referenceID": 29, "context": "Furthermore, if the difference between m(x) and m(x) is only related to a small number of variables, the maxflow computation of last iteration can be efficiently reused [31].", "startOffset": 169, "endOffset": 173}, {"referenceID": 25, "context": "Refer to [27] for more details about modApproximation(\u00b7) in Algorithm 1.", "startOffset": 9, "endOffset": 13}, {"referenceID": 25, "context": "According to the convergence of SSP [27], ESSP is also guaranteed to converge to a local optimum.", "startOffset": 36, "endOffset": 40}, {"referenceID": 24, "context": "Thus, the complexity of ESSP algorithm is O(TM), where T is the number of iterations and M is the state-of-theart complexity of maxflow computation on undirected graphs [26], [28], [29].", "startOffset": 169, "endOffset": 173}, {"referenceID": 26, "context": "Thus, the complexity of ESSP algorithm is O(TM), where T is the number of iterations and M is the state-of-theart complexity of maxflow computation on undirected graphs [26], [28], [29].", "startOffset": 175, "endOffset": 179}, {"referenceID": 27, "context": "Thus, the complexity of ESSP algorithm is O(TM), where T is the number of iterations and M is the state-of-theart complexity of maxflow computation on undirected graphs [26], [28], [29].", "startOffset": 181, "endOffset": 185}, {"referenceID": 3, "context": "Compared to the directed graph formulation and QPBO [4], [5], ESSP has half number of vertices in the undirected graph characterization.", "startOffset": 52, "endOffset": 55}, {"referenceID": 4, "context": "Compared to the directed graph formulation and QPBO [4], [5], ESSP has half number of vertices in the undirected graph characterization.", "startOffset": 57, "endOffset": 60}, {"referenceID": 5, "context": ", BP [6], TRW-S [10] and QPBO(P,I) [4], [5], on minimizing dense and nonsubmodular energy functions.", "startOffset": 5, "endOffset": 8}, {"referenceID": 3, "context": ", BP [6], TRW-S [10] and QPBO(P,I) [4], [5], on minimizing dense and nonsubmodular energy functions.", "startOffset": 35, "endOffset": 38}, {"referenceID": 4, "context": ", BP [6], TRW-S [10] and QPBO(P,I) [4], [5], on minimizing dense and nonsubmodular energy functions.", "startOffset": 40, "endOffset": 43}, {"referenceID": 17, "context": "For BP and TRW-S, we used the speed-up implementation introduced in [19].", "startOffset": 68, "endOffset": 72}, {"referenceID": 16, "context": "Second, as stated in [18], [19], the performance of different methods for real energies depends on both the power of energy models and the efficacy of energy minimization methods.", "startOffset": 21, "endOffset": 25}, {"referenceID": 17, "context": "Second, as stated in [18], [19], the performance of different methods for real energies depends on both the power of energy models and the efficacy of energy minimization methods.", "startOffset": 27, "endOffset": 31}, {"referenceID": 0, "context": "niques on minimizing sparse energies defined in 4connected grid graphs is well-understood in computer vision [1], [17], as shown in Fig.", "startOffset": 109, "endOffset": 112}, {"referenceID": 15, "context": "niques on minimizing sparse energies defined in 4connected grid graphs is well-understood in computer vision [1], [17], as shown in Fig.", "startOffset": 114, "endOffset": 118}, {"referenceID": 0, "context": "This is in contrast to their performances for sparse energy functions [1], [18].", "startOffset": 70, "endOffset": 73}, {"referenceID": 16, "context": "This is in contrast to their performances for sparse energy functions [1], [18].", "startOffset": 75, "endOffset": 79}, {"referenceID": 17, "context": "The difficulty of TRW-S on solving dense energy functions was also found and analyzed in [19].", "startOffset": 89, "endOffset": 93}, {"referenceID": 25, "context": "Our approach is based on an undirected graph characterization of QPBFs, which enables us to extend the classical submodular-supermodular procedure [27] to a general solver for generic binary labeling problems.", "startOffset": 147, "endOffset": 151}, {"referenceID": 0, "context": "Refer to [1], [17] Lower supermodularity Sr \u2248 0 Higher supermodularity Sr > 10%", "startOffset": 9, "endOffset": 12}, {"referenceID": 15, "context": "Refer to [1], [17] Lower supermodularity Sr \u2248 0 Higher supermodularity Sr > 10%", "startOffset": 14, "endOffset": 18}, {"referenceID": 27, "context": "Besides, combining ESSP with other recent optimization methods, such as [29], [32], is an interesting direction for future work.", "startOffset": 72, "endOffset": 76}, {"referenceID": 30, "context": "Besides, combining ESSP with other recent optimization methods, such as [29], [32], is an interesting direction for future work.", "startOffset": 78, "endOffset": 82}], "year": 2014, "abstractText": "Many recent advances in computer vision have demonstrated the impressive power of dense and nonsubmodular energy functions in solving visual labeling problems. However, minimizing such energies is challenging. None of existing techniques (such as s-t graph cut, QPBO, BP and TRW-S) can individually do this well. In this paper, we present an efficient method, namely ESSP, to optimize binary MRFs with arbitrary pairwise potentials, which could be nonsubmodular and with dense connectivity. We also provide a comparative study of our approach and several recent promising methods. From our study, we make some reasonable recommendations of combining existing methods that perform the best in different situations for this challenging problem. Experimental results validate that for dense and nonsubmodular energy functions, the proposed approach can usually obtain lower energies than the best combination of other techniques using comparably reasonable time.", "creator": "LaTeX with hyperref package"}}}