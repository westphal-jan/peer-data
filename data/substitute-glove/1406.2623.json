{"id": "1406.2623", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jun-2014", "title": "Maximum Likelihood-based Online Adaptation of Hyper-parameters in CMA-ES", "abstract": "The Covariance Matrix Adaptation Evolution Strategy (CMA - ES) is frequently demanded that kind robust non-standard - free intervals multi-dimensional algorithm before voluntary - formula_7 and adding - subset discrete conflicts. CMA - ES comes ones primarily rest given than parameterless, meaning if only and annoyingly - parameter, later roughly size, this recommended to still headsets once 's user. In so paper, everything blueprint called principled alternative main life - CMA - ES, enhance same mobile epic is CMA - ES shockingly - variables in means to expand its better made. Experimental unlikely entertainment some put produce - than - defaulting population only, set default routines a unpredictable - calculations of CMA - ES far far down since calculate, there now way - CMA - ES give for dynamically rising processes settings.", "histories": [["v1", "Tue, 10 Jun 2014 16:44:32 GMT  (578kb)", "https://arxiv.org/abs/1406.2623v1", "13th International Conference on Parallel Problem Solving from Nature (PPSN 2014) (2014)"], ["v2", "Wed, 11 Jun 2014 09:54:27 GMT  (1304kb)", "http://arxiv.org/abs/1406.2623v2", "13th International Conference on Parallel Problem Solving from Nature (PPSN 2014) (2014)"]], "COMMENTS": "13th International Conference on Parallel Problem Solving from Nature (PPSN 2014) (2014)", "reviews": [], "SUBJECTS": "cs.NE cs.AI", "authors": ["ilya loshchilov", "marc schoenauer", "mich\\`ele sebag", "nikolaus hansen"], "accepted": false, "id": "1406.2623"}, "pdf": {"name": "1406.2623.pdf", "metadata": {"source": "CRF", "title": "Maximum Likelihood-based Online Adaptation of Hyper-parameters in CMA-ES", "authors": ["Ilya Loshchilov", "Marc Schoenauer", "Mich\u00e8le Sebag", "Nikolaus Hansen"], "emails": ["Ilya.Loshchilov@epfl.ch", "FirstName.LastName@inria.fr"], "sections": [{"heading": null, "text": "ar X\niv :1\n40 6.\n26 23\nv2 [\ncs .N\nE ]\n1 1"}, {"heading": "1 Introduction", "text": "The Covariance Matrix Adaptation Evolution Strategy (CMA-ES [5]) is a continuous optimizer which only exploits the ranking of estimated candidate solutions to approach the optimum of an objective function f : Rn \u2192 R. CMA-ES is also invariant w.r.t. affine transformations of the decision space, explaining the known robustness of the algorithm. An important practical advantage of CMAES is that all hyper-parameters thereof are defined by default with respect to the problem dimension n. Practically, only the population size \u03bb is suggested to be tuned by the user, e.g. when a parallelization of the algorithm is considered or the problem at hand is known to be multi-modal and/or noisy [1,8]. Other hyperparameters have been provided robust default settings (depending on n and \u03bb), in the sense that their offline tuning allegedly hardly improves the CMA-ES performance for unimodal functions. In the meanwhile, for multi-modal functions it is suggested that the overall performance can be significantly improved by offline tuning of \u03bb and multiple stopping criteria [16,11]. Additionally, it is shown that CMA-ES can be improved by a factor up to 5-10 by the use of surrogate models on unimodal ill-conditioned functions [14]. This suggests that the CMA-ES performance can be improved by better exploiting the information in the evaluated samples (x, f(x)).\nThis paper focuses on the automatic online adjustment of the CMA-ES hyper-parameters. The proposed approach, called self-CMA-ES, relies on a second CMA-ES instance operating on the hyper-parameter space of the first CMAES, and aimed at increasing the likelihood of generating the most successful samples x in the current generation. The paper is organized as follows. Section 2 describes the original (\u00b5/\u00b5w, \u03bb)-CMA-ES. self-CMA-ES is described in Section 3 and its experimental validation is discussed in Section 4 comparatively to related work. Section 5 concludes the paper."}, {"heading": "2 Covariance Matrix Adaptation Evolution Strategy", "text": "The Covariance Matrix Adaptation Evolution Strategy [6,7,5] is acknowledgedly the most popular and the most efficient Evolution Strategy algorithm.\nThe original (\u00b5/\u00b5w, \u03bb)-CMA-ES (Algorithm 1) proceeds as follows. At the\nt-th iteration, a Gaussian distribution N ( mt, \u03c3t 2 C t ) is used to generate \u03bb candidate solution xk \u2208 Rn, for k = 1 . . . \u03bb (line 5):\nxtk = N ( mt, \u03c3t 2 C t ) = mt + \u03c3tN ( 0,C t ) , (1)\nwhere the mean mt \u2208 Rn of the distribution can be interpreted as the current estimate of the optimum of function f , C t \u2208 Rn\u00d7n is a (positive definite) covariance matrix and \u03c3t is a mutation step-size. These \u03bb solutions are evaluated according to f (line 6). The new mean mt+1 of the distribution is computed as a weighted sum of the best \u00b5 individuals out of the \u03bb ones (line 7). Weights w1 . . . w\u00b5 are used to control the impact of selected individuals, with usually higher weights for top ranked individuals (line 1).\nThe adaptation of the step-size \u03c3t, inherited from the Cumulative Step-Size Adaptation Evolution Strategy (CSA-ES [6]), is controlled by the evolution path pt+1\u03c3 . Successful mutation steps mt+1\u2212mt \u03c3t (line 8) are tracked in the sampling space, i.e., in the isotropic coordinate system defined by the eigenvectors of the covariance matrix C t. To update the evolution path pt+1\u03c3 , i) a decay/relaxation factor c\u03c3 is used to decrease the importance of previous steps; ii) the stepsize is increased if the length of the evolution path pt+1\u03c3 is longer than the expected length of the evolution path under random selection E \u2016N (0, I )\u2016; iii) otherwise it is decreased (line 13). Expectation of \u2016N (0, I )\u2016 is approximated by\u221a n(1\u2212 1\n4n + 1 21n2 ). A damping parameter d\u03c3 controls the change of the step-size. The covariance matrix update consists of two parts (line 12): a rank-one update [7] and a rank-\u00b5 update [5]. The rank-one update computes the evolution path pt+1c of successful moves of the mean mt+1\u2212mt \u03c3t of the mutation distribution in the given coordinate system (line 10), along the same lines as the evolution path pt+1\u03c3 of the step-size. To stall the update of p t+1 c when \u03c3 increases rapidly, a h\u03c3 trigger is used (line 9). The rank-\u00b5 update computes a covariance matrix C\u00b5 as a weighted sum of the covariances of successful steps of the best \u00b5 individuals (line 11). Covariance\nAlgorithm 1 The (\u00b5/\u00b5w, \u03bb)-CMA-ES\n1: given n \u2208 N+, \u03bb = 4 + \u230a3lnn\u230b, \u00b5 = \u230a\u03bb/2\u230b, wi = ln(\u00b5+ 1 2 )\u2212ln i\n\u2211\u00b5 j=1(ln(\u00b5+ 1 2 )\u2212ln j) for i = 1 . . . \u00b5,\n\u00b5w = 1\u2211\u00b5\ni=1 w2 i\n, c\u03c3 = \u00b5w+2\nn+\u00b5w+3 , d\u03c3 = 1 + c\u03c3 + 2max(0, \u221a \u00b5w\u22121 n+1\n\u2212 1), cc = 4n+4 , c1 =\n2 (n+1.3)2+\u00b5w , c\u00b5 = 2 (\u00b5w\u22122+1/\u00b5w) (n+2)2+\u00b5w\n2: initialize mt=0 \u2208 Rn, \u03c3t=0 > 0, pt=0\u03c3 = 0, pt=0c = 0,C t=0 = I, t \u2190 0 3: repeat 4: for k = 1, . . . , \u03bb do 5: xk = m t + \u03c3tN ( 0,C t ) 6: fk = f(xk) 7: mt+1 =\n\u2211\u00b5 i=1 wixi:\u03bb // the symbol i : \u03bb denotes i-th best individual on f\n8: pt+1\u03c3 = (1\u2212 c\u03c3)pt\u03c3 + \u221a c\u03c3(2\u2212 c\u03c3)\u221a\u00b5wC t\u2212 1 2 m t+1\u2212mt\n\u03c3t\n9: h\u03c3 = 1 \u2016pt+1\u03c3 \u2016< \u221a 1\u2212(1\u2212c\u03c3)2(t+1)(1.4+ 2\nn+1 ) E\u2016N(0,I )\u2016\n10: pt+1c = (1\u2212 cc)ptc + h\u03c3 \u221a cc(2\u2212 cc)\u221a\u00b5w m t+1\u2212mt\n\u03c3t\n11: C\u00b5 = \u2211\u00b5 i=1 wi xi:\u03bb\u2212m t \u03c3t \u00d7 (xi:\u03bb\u2212mt)T \u03c3t 12: C t+1 = (1\u2212 c1 \u2212 c\u00b5)C t + c1 pt+1c pt+1c T\n\ufe38 \ufe37\ufe37 \ufe38\nrank\u2212one update\n+c\u00b5C \u00b5 \ufe38\ufe37\ufe37\ufe38 rank\u2212\u00b5 update\n13: \u03c3t+1 = \u03c3texp( c\u03c3 d\u03c3\n( \u2016pt+1\u03c3 \u2016\nE\u2016N(0,I )\u2016 \u2212 1))\n14: t = t+ 1 15: until stopping criterion is met\nmatrix C itself is replaced by a weighted sum of the rank-one (weight c1 [7]) and rank-\u00b5 (weight c\u00b5 [5]) updates, with c1 and c\u00b5 positive and c1 + c\u00b5 \u2264 1.\nWhile the optimal parameterization of CMA-ES remains an open problem, the default parameterization is found quite robust on noiseless unimodal functions [5], which explains the popularity of CMA-ES."}, {"heading": "3 The self-CMA-ES", "text": "The proposed self-CMA-ES approach is based on the intuition that the optimal hyper-parameters of CMA-ES at time t should favor the generation of the best individuals at time t, under the (strong) assumption that an optimal parameterization and performance of CMA-ES in each time t will lead to the overall optimal performance.\nFormally, this intuition leads to the following procedure. Let \u03b8tf denote the hyper-parameter vector used for the optimization of objective f at time t (CMAES stores its state variables and internal parameters of iteration t in \u03b8t and the \u2019.\u2019-notation is used to access them). At time t+1, the best individuals generated according to \u03b8tf are known to be the top-ranked individuals x t 1:\u03bb . . . x t \u00b5:\u03bb, where xti:\u03bb stands for the i-th best individual w.r.t. f . Hyper-parameter vector \u03b8 t f would thus have been all the better, if it had maximized the probability of generating these top individuals.\nAlong this line, the optimization of \u03b8tf is conducted using a second CMA-ES algorithm, referred to as auxiliary CMA-ES as opposed to the one concerned with the optimization of f , referred to as primary CMA-ES. The objective of the auxiliary CMA-ES is specified as follows:\nGiven: hyper-parameter vector \u03b8if and points (x i 1:\u03bb, f(x i 1:\u03bb)) evaluated by\nprimary CMA-ES at steps i = 1, . . . , t (noted as \u03b8i+1f .f(x1:\u03bb) in Algorithm 2),\nFind: \u03b8t,\u2217f such that i) backtracking the primary CMA-ES to its state at time t\u22121; ii) replacing \u03b8tf by \u03b8t,\u2217f , would maximize the likelihood of xti:\u03bb for i = 1 . . . \u00b5. The auxiliary CMA-ES might thus tackle the maximization of gt(\u03b8) computed as the weighed log-likelihood of the top-ranked \u00b5sel individuals at time t:\ngt(\u03b8) =\n\u00b5sel \u2211\ni=1\nwsel,i log ( P (xti:\u03bb|\u03b8tf = \u03b8 ) ), (2)\nwhere wsel,i \u2265 0, i = 1 . . . \u00b5sel, \u2211\u00b5sel i=1 wsel,i = 1, and by construction\nP (xi|mt,Ct) = 1 \u221a\n(2\u03c0)n|Ct| exp (\u22120.5(mt \u2212 xti)Ct \u22121 (mt \u2212 xti)), (3)\nwhere Ct is the covariance matrix multiplied by \u03c3t 2 and |Ct| is its determinant.\nWhile the objective function for the auxiliary CMA-ES defined by Eq. (2) is mathematically sound, it yields a difficult optimization problem; firstly the probabilities are scale-sensitive; secondly and overall, in a worst case scenario, a single good but unlikely solution may lead the optimization of \u03b8tf astray.\nTherefore, another optimization objective ht(\u03b8) is defined for the auxiliary CMA-ES, where ht(\u03b8) measures the agreement on x t i:\u03bb for i = 1 . . . \u00b5 between i) the order defined from f ; ii) the order defined from their likelihood conditioned by \u03b8tf = \u03b8 (Algorithm 3). Procedure ReproduceGenerationCMA in Algorithm 3 updates the strategy parameters described from line 7 to line 14 in Algorithm 1 using already evaluated solutions stored in \u03b8tf .xi:\u03bb. Line 4 computes the Mahalanobis distance, division by step-size is not needed since only ranking will be considered in line 5 (decreasing order of Mahalanobis distances corresponds to increasing order of log-likelihoods). Line 6 computes a weighted sum of ranks of likelihoods of best individuals.\nFinally, the overall scheme of self-CMA-ES (Algorithm 2) involves two interdependent CMA-ES optimization algorithms, where the primary CMA-ES is concerned with optimizing objective f , and the auxiliary CMA-ES is concerned with optimizing objective ht, that is, optimizing the hyper-parameters of the primary CMA-ES4. Note that self-CMA-ES is not per se a \u201cmore parameterless\u201c algorithm than CMA-ES, in the sense that the user is still invited to modify the population size \u03bb. The main purpose of self-CMA-ES is to achieve the online adaptation of the other CMA-ES hyper-parameters.\n4 This scheme is actually inspired from the one proposed for surrogate-assisted optimization [13], where the auxiliary CMA-ES was in charge of optimizing the surrogate learning hyper-parameters.\nAlgorithm 2 The self-CMA-ES 1: t \u2190 1 2: \u03b8tf \u2190 InitializationCMA() { primary CMA-ES aimed at optimizing f } 3: \u03b8th \u2190 InitializationCMA() { auxiliary CMA-ES aimed at optimizing ht } 4: fill \u03b8tf with corresponding parameters stored in mean of distribution \u03b8 t h.m\n5: \u03b8t+1f \u2190 GenerationCMA(f , \u03b8tf ) 6: t \u2190 t+ 1 7: repeat 8: \u03b8t+1f \u2190GenerationCMA(f, \u03b8tf ) 9: \u03b8t+1h \u2190GenerationCMA(ht, \u03b8th) 10: fill \u03b8t+1f with corresponding parameters stored in mean of distribution \u03b8 t+1 h .m 11: t \u2190 t+ 1 12: until stopping criterion is met\nSpecifically, while the primary CMA-ES optimizes f(x) (line 8), the auxiliary CMA-ES maximizes ht(\u03b8) (line 9) by sampling and evaluating \u03bbh variants of \u03b8 t f . The updated mean of the auxiliary CMA-ES in the hyper-parameter space is used as a local estimate of the optimal hyper-parameter vector for the primary CMA-ES. Note that the auxiliary CMA-ES achieves a single iteration in the hyper-parameter space of the primary CMA-ES, with two motivations: limiting the computational cost of self-CMA-ES (which scales as \u03bbh times the time complexity of the CMA-ES), and preventing \u03b8tf from overfitting the current sample xti:\u03bb, i = 1 . . . \u00b5.\nAlgorithm 3 Objective function ht(\u03b8)\n1: Input: \u03b8, \u03b8t+1f ,\u03b8 t\u22121 f , \u03b8 t f , \u00b5, wsel,i for i = 1, . . . , \u00b5 2: \u03b8 \u2032t\u22121 f \u2190 \u03b8 3: \u03b8 \u2032t f \u2190ReproduceGenerationCMA(f, \u03b8 \u2032t\u22121 f ) using already evaluated \u03b8 t f .xi:\u03bb 4: di \u2190 \u2225 \u2225 \u2225\u03b8 \u2032t f . \u221a C\u22121 \u00b7 (\u03b8t+1f .xti \u2212 \u03b8 \u2032t f .m) \u2225 \u2225 \u2225 ; for i = 1, . . . , \u03b8t+1f .\u03bb 5: pi \u2190 rank of di, i = 1 . . . \u03bb sorted in decreasing order 6: h(\u03b8) \u2190 \u2211\u00b5i=1 wsel,ipi:\u03bb { i : \u03bb denotes the rank of \u03b8t+1.xi } 7: Output: h(\u03b8)"}, {"heading": "4 Experimental Validation", "text": "The experimental validation of self-CMA-ES investigates the performance of the algorithm comparatively to CMA-ES on the BBOB noiseless problems [4]. Both algorithms are launched in IPOP scenario of restarts when the CMA-ES is restarted with doubled population size once stopping criteria [3] are met5.\n5 For the sake of reproducibility, the source code is available at https://sites.google.com/site/selfcmappsn/\nThe population size \u03bb is chosen to be 100 for both CMA-ES and self-CMAES. We choose this value (about 10 times larger than the default one, see the default parameters of CMA-ES in Algorithm 1) to investigate how sub-optimal the other CMA-ES hyper-parameters, derived from \u03bb, are in such a case, and whether self-CMA-ES can recover from this sub-optimality.\nThe auxiliary CMA-ES is concerned with optimizing hyper-parameters c1, c\u00b5 and cc (Algorithm 1), responsible for the adaptation of the covariance matrix of the primary CMA-ES. These parameters range in [0, .9] subject to 0 \u2264 c1+ c\u00b5 \u2264 0.9; the constraint is meant to enforce a feasible C update for the primary CMA-ES (the decay factor of C should be in [0, 1]). Infeasible hyper-parameter solutions get a very large penalty, multiplied by the sum of distances of infeasible hyper-parameters to the range of feasibility.\nWe set wsel,i = 1/\u00b5 for i = 1, . . . , \u00b5 and \u00b5 = \u230a\u03bb/2\u230b to 50. The internal computational complexity of self-CMA-ES thus is \u03bbh = 20 times larger than the one of CMA-ES without lazy update (being reminded that the internal time complexity is usually negligible compared to the cost per objective function evaluation)."}, {"heading": "4.1 Results", "text": "Figures 1 and 2 display the comparative performances of CMA-ES (left) and self-CMA-ES (right) on 10 and 20-dimensional Sphere, Rosenbrock, Rotated Ellipsoid and Sharp ridge functions from the noiseless BBOB testbed [4] (medians out of 15 runs). Each plot shows the value of the hyper-parameters (left y-axis) together with the objective function (in logarithmic scale, right y-axis). Hyperparameters c1, c\u00b5 and cc are constant and set to their default values for CMA-ES while they are adapted along evolution for self-CMA-ES.\nIn self-CMA-ES, the hyper-parameters are uniformly initialized in [0, 0.9] (therefore the medians are close to 0.45) and they gradually converge to values which are estimated to provide the best update of the covariance matrix w.r.t. the ability to generate the current best individuals. It is seen that these values are problem and dimension-dependent. The values of c1 are always much smaller than c\u00b5 but are comparable to the default c1. The values of c\u00b5 and cc and c1 are almost always larger than the default ones; this is not a surprise for c1 and c\u00b5, as their original default values are chosen in a rather conservative way to prevent degeneration of the covariance matrix.\nSeveral interesting observations can be made about the dynamics of the parameter values. The value of c\u00b5 is high most of the times on the Rosenbrock functions, but it decreases toward values similar to those of the Sphere functions, when close to the optimum. This effect is observed on most problems; indeed, on most problems fast adaptation of the covariance matrix will improve the performance in the beginning, while the distribution shape should remain stable when the covariance matrix is learned close to the optimum.\nThe overall performance of self-CMA-ES on the considered problems is comparable to that of CMA-ES, with a speed-up of a factor up to 1.5 on Sharp Ridge functions. The main result is the ability of self-CMA-ES to achieve the\nonline adaptation of the hyper-parameters depending on the problem at hand, side-stepping the use of long calibrated default settings6."}, {"heading": "4.2 Discussion", "text": "self-CMA-ES offers a proof of concept for the online adaptation of three CMA-ES hyper-parameters in terms of feasibility and usefulness. Previous studies on parameter settings for CMA-ES mostly considered offline tuning (see, e.g., [16,11]) and theoretical analysis dated back to the first papers on Evolution Strategies. The main limitation of these studies is that the suggested hyper-parameter values are usually specific to the (class of) analyzed problems. Furthermore, the suggested values are fixed, assuming that optimal parameter values remain constant along evolution. However, when optimizing a function whose landscape gradually changes when approaching the optimum, one may expect optimal hyperparameter values to reflect this change as well.\nStudies on the online adaptation of hyper-parameters (apart from \u03c3, m and C) usually consider population size in noisy [2], multi-modal [1,12] or expensive [9] optimization. A more closely related approach was proposed in [15] where the learning rate for step-size adaptation is adapted in a stochastic way similarly to Rprop-updates [10]."}, {"heading": "5 Conclusion and Perspectives", "text": "This paper proposes a principled approach for the self-adaptation of CMA-ES hyper-parameters, tackled as an auxiliary optimization problem: maximizing the likelihood of generating the best sampled solutions. The experimental validation of self-CMA-ES shows that the learning rates involved in the covariance matrix adaptation can be efficiently adapted on-line, with comparable or better results than CMA-ES. It is worth emphasizing that matching the performance of CMA-ES, the default setting of which represent a historical consensus between theoretical analysis and offline tuning, is nothing easy.\nThe main novelty of the paper is to offer an intrinsic assessment of the algorithm internal state, based on retrospective reasoning (given the best current solutions, how could the generation of these solutions have been made easier) and on one assumption (the optimal hyper-parameter values at time t are \u201dsufficiently good\u201c at time t + 1). Further work will investigate how this intrinsic assessment can support the self-adaptation of other continuous and discrete hyper-parameters used to deal with noisy, multi-modal and constrained optimization problems.\nAcknowledgments We acknowledge anonymous reviewers for their constructive comments. This work was supported by the grant ANR-2010-COSI-002 (SIMINOLE) of the French National Research Agency.\n6 cc = 4\nn+4 , c1 = 2 (n+1.3)2+\u00b5w , c\u00b5 = 2 (\u00b5w\u22122+1/\u00b5w) (n+2)2+\u00b5w ."}], "references": [{"title": "A Restart CMA Evolution Strategy With Increasing Population Size", "author": ["A. Auger", "N. Hansen"], "venue": "In IEEE Congress on Evolutionary Computation, pages 1769\u2013 1776. IEEE Press,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2005}, {"title": "Controlling population size and mutation strength by meta-es under fitness noise", "author": ["H.-G. Beyer", "M. Hellwig"], "venue": "In Proceedings of the Twelfth Workshop on Foundations of Genetic Algorithms XII, FOGA XII \u201913, pages 11\u201324. ACM,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Benchmarking a BI-population CMA-ES on the BBOB-2009 function testbed", "author": ["N. Hansen"], "venue": "In GECCO Companion, pages 2389\u20132396,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Real-Parameter Black-Box Optimization Benchmarking 2010: Experimental Setup", "author": ["N. Hansen", "A. Auger", "S. Finck", "R. Ros"], "venue": "Technical report, INRIA,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Reducing the time complexity of the derandomized evolution strategy with covariance matrix adaptation (CMA-ES)", "author": ["N. Hansen", "S. M\u00fcller", "P. Koumoutsakos"], "venue": "Evolutionary Computation, 11(1):1\u201318,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2003}, {"title": "Adapting Arbitrary Normal Mutation Distributions in Evolution Strategies: The Covariance Matrix Adaptation", "author": ["N. Hansen", "A. Ostermeier"], "venue": "In International Conference on Evolutionary Computation, pages 312\u2013317,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1996}, {"title": "Completely Derandomized Self-Adaptation in Evolution Strategies", "author": ["N. Hansen", "A. Ostermeier"], "venue": "Evolutionary Computation, 9(2):159\u2013195, June", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2001}, {"title": "Benchmarking a weighted negative covariance matrix update on the BBOB-2010 noisy testbed", "author": ["N. Hansen", "R. Ros"], "venue": "In GECCO \u201910: Proceedings of the 12th annual conference comp on Genetic and evolutionary computation, pages 1681\u2013 1688, New York, NY, USA,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Controlled Model Assisted Evolution Strategy with Adaptive Preselection", "author": ["F. Hoffmann", "S. Holemann"], "venue": "In International Symposium on Evolving Fuzzy Systems, pages 182\u2013187. IEEE,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2006}, {"title": "Empirical evaluation of the improved rprop learning algorithms", "author": ["C. Igel", "M. H\u00fcsken"], "venue": "Neurocomputing, 50:105\u2013123,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2003}, {"title": "Benchmark results for a simple hybrid algorithm on the CEC 2013 benchmark set for real-parameter optimization", "author": ["T. Liao", "T. St\u00fctzle"], "venue": "In IEEE Congress on Evolutionary Computation (CEC), pages 1938\u20131944. IEEE press,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Alternative Restart Strategies for CMA-ES", "author": ["I. Loshchilov", "M. Schoenauer", "M. Sebag"], "venue": "In V. C. et al., editor, Parallel Problem Solving from Nature (PPSN XII), LNCS, pages 296\u2013305. Springer, September", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Self-Adaptive Surrogate-Assisted Covariance Matrix Adaptation Evolution Strategy", "author": ["I. Loshchilov", "M. Schoenauer", "M. Sebag"], "venue": "In Genetic and Evolutionary Computation Conference (GECCO), pages 321\u2013328. ACM Press, July", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Intensive Surrogate Model Exploitation in Self-adaptive Surrogate-assisted CMA-ES (saACM-ES)", "author": ["I. Loshchilov", "M. Schoenauer", "M. Sebag"], "venue": "In Genetic and evolutionary computation conference, pages 439\u2013446. ACM,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Comparing natural evolution strategies to bipop-cma-es on noiseless and noisy black-box optimization testbeds", "author": ["T. Schaul"], "venue": "In Genetic and evolutionary computation conference companion, pages 237\u2013244. ACM,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Beating the \u2018world champion\u2019 Evolutionary Algorithm via REVAC Tuning", "author": ["S. Smit", "A. Eiben"], "venue": "In IEEE Congress on Evolutionary Computation, pages 1\u20138,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 4, "context": "1 Introduction The Covariance Matrix Adaptation Evolution Strategy (CMA-ES [5]) is a continuous optimizer which only exploits the ranking of estimated candidate solutions to approach the optimum of an objective function f : R \u2192 R.", "startOffset": 75, "endOffset": 78}, {"referenceID": 0, "context": "when a parallelization of the algorithm is considered or the problem at hand is known to be multi-modal and/or noisy [1,8].", "startOffset": 117, "endOffset": 122}, {"referenceID": 7, "context": "when a parallelization of the algorithm is considered or the problem at hand is known to be multi-modal and/or noisy [1,8].", "startOffset": 117, "endOffset": 122}, {"referenceID": 15, "context": "In the meanwhile, for multi-modal functions it is suggested that the overall performance can be significantly improved by offline tuning of \u03bb and multiple stopping criteria [16,11].", "startOffset": 173, "endOffset": 180}, {"referenceID": 10, "context": "In the meanwhile, for multi-modal functions it is suggested that the overall performance can be significantly improved by offline tuning of \u03bb and multiple stopping criteria [16,11].", "startOffset": 173, "endOffset": 180}, {"referenceID": 13, "context": "Additionally, it is shown that CMA-ES can be improved by a factor up to 5-10 by the use of surrogate models on unimodal ill-conditioned functions [14].", "startOffset": 146, "endOffset": 150}, {"referenceID": 5, "context": "The Covariance Matrix Adaptation Evolution Strategy [6,7,5] is acknowledgedly the most popular and the most efficient Evolution Strategy algorithm.", "startOffset": 52, "endOffset": 59}, {"referenceID": 6, "context": "The Covariance Matrix Adaptation Evolution Strategy [6,7,5] is acknowledgedly the most popular and the most efficient Evolution Strategy algorithm.", "startOffset": 52, "endOffset": 59}, {"referenceID": 4, "context": "The Covariance Matrix Adaptation Evolution Strategy [6,7,5] is acknowledgedly the most popular and the most efficient Evolution Strategy algorithm.", "startOffset": 52, "endOffset": 59}, {"referenceID": 5, "context": "The adaptation of the step-size \u03c3, inherited from the Cumulative Step-Size Adaptation Evolution Strategy (CSA-ES [6]), is controlled by the evolution path p \u03c3 .", "startOffset": 113, "endOffset": 116}, {"referenceID": 6, "context": "The covariance matrix update consists of two parts (line 12): a rank-one update [7] and a rank-\u03bc update [5].", "startOffset": 80, "endOffset": 83}, {"referenceID": 4, "context": "The covariance matrix update consists of two parts (line 12): a rank-one update [7] and a rank-\u03bc update [5].", "startOffset": 104, "endOffset": 107}, {"referenceID": 6, "context": "matrix C itself is replaced by a weighted sum of the rank-one (weight c1 [7]) and rank-\u03bc (weight c\u03bc [5]) updates, with c1 and c\u03bc positive and c1 + c\u03bc \u2264 1.", "startOffset": 73, "endOffset": 76}, {"referenceID": 4, "context": "matrix C itself is replaced by a weighted sum of the rank-one (weight c1 [7]) and rank-\u03bc (weight c\u03bc [5]) updates, with c1 and c\u03bc positive and c1 + c\u03bc \u2264 1.", "startOffset": 100, "endOffset": 103}, {"referenceID": 4, "context": "While the optimal parameterization of CMA-ES remains an open problem, the default parameterization is found quite robust on noiseless unimodal functions [5], which explains the popularity of CMA-ES.", "startOffset": 153, "endOffset": 156}, {"referenceID": 12, "context": "4 This scheme is actually inspired from the one proposed for surrogate-assisted optimization [13], where the auxiliary CMA-ES was in charge of optimizing the surrogate learning hyper-parameters.", "startOffset": 93, "endOffset": 97}, {"referenceID": 3, "context": "4 Experimental Validation The experimental validation of self-CMA-ES investigates the performance of the algorithm comparatively to CMA-ES on the BBOB noiseless problems [4].", "startOffset": 170, "endOffset": 173}, {"referenceID": 2, "context": "Both algorithms are launched in IPOP scenario of restarts when the CMA-ES is restarted with doubled population size once stopping criteria [3] are met.", "startOffset": 139, "endOffset": 142}, {"referenceID": 3, "context": "Evolution of learning rates c1, c\u03bc, cc (lines with markers, left y-axis) and log10(objective function) (plain line, right y-axis) of CMA-ES (left column) and selfCMA-ES (right column) on 10- and 20-dimensional Sphere and Rosenbrock functions from [4].", "startOffset": 247, "endOffset": 250}, {"referenceID": 3, "context": "Evolution of learning rates c1, c\u03bc, cc (lines with markers, left y-axis) and log10(objective function) (plain line, right y-axis) of CMA-ES (left column) and selfCMA-ES (right column) on 10- and 20-dimensional Rotated Ellipsoid and Sharp Ridge functions from [4].", "startOffset": 259, "endOffset": 262}, {"referenceID": 0, "context": "9; the constraint is meant to enforce a feasible C update for the primary CMA-ES (the decay factor of C should be in [0, 1]).", "startOffset": 117, "endOffset": 123}, {"referenceID": 3, "context": "1 Results Figures 1 and 2 display the comparative performances of CMA-ES (left) and self-CMA-ES (right) on 10 and 20-dimensional Sphere, Rosenbrock, Rotated Ellipsoid and Sharp ridge functions from the noiseless BBOB testbed [4] (medians out of 15 runs).", "startOffset": 225, "endOffset": 228}, {"referenceID": 15, "context": ", [16,11]) and theoretical analysis dated back to the first papers on Evolution Strategies.", "startOffset": 2, "endOffset": 9}, {"referenceID": 10, "context": ", [16,11]) and theoretical analysis dated back to the first papers on Evolution Strategies.", "startOffset": 2, "endOffset": 9}, {"referenceID": 1, "context": "Studies on the online adaptation of hyper-parameters (apart from \u03c3, m and C) usually consider population size in noisy [2], multi-modal [1,12] or expensive [9] optimization.", "startOffset": 119, "endOffset": 122}, {"referenceID": 0, "context": "Studies on the online adaptation of hyper-parameters (apart from \u03c3, m and C) usually consider population size in noisy [2], multi-modal [1,12] or expensive [9] optimization.", "startOffset": 136, "endOffset": 142}, {"referenceID": 11, "context": "Studies on the online adaptation of hyper-parameters (apart from \u03c3, m and C) usually consider population size in noisy [2], multi-modal [1,12] or expensive [9] optimization.", "startOffset": 136, "endOffset": 142}, {"referenceID": 8, "context": "Studies on the online adaptation of hyper-parameters (apart from \u03c3, m and C) usually consider population size in noisy [2], multi-modal [1,12] or expensive [9] optimization.", "startOffset": 156, "endOffset": 159}, {"referenceID": 14, "context": "A more closely related approach was proposed in [15] where the learning rate for step-size adaptation is adapted in a stochastic way similarly to Rprop-updates [10].", "startOffset": 48, "endOffset": 52}, {"referenceID": 9, "context": "A more closely related approach was proposed in [15] where the learning rate for step-size adaptation is adapted in a stochastic way similarly to Rprop-updates [10].", "startOffset": 160, "endOffset": 164}], "year": 2014, "abstractText": "The Covariance Matrix Adaptation Evolution Strategy (CMAES) is widely accepted as a robust derivative-free continuous optimization algorithm for non-linear and non-convex optimization problems. CMA-ES is well known to be almost parameterless, meaning that only one hyper-parameter, the population size, is proposed to be tuned by the user. In this paper, we propose a principled approach called selfCMA-ES to achieve the online adaptation of CMA-ES hyper-parameters in order to improve its overall performance. Experimental results show that for larger-than-default population size, the default settings of hyperparameters of CMA-ES are far from being optimal, and that self-CMAES allows for dynamically approaching optimal settings.", "creator": "LaTeX with hyperref package"}}}