{"id": "1406.4619", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2014", "title": "A Generalized Markov-Chain Modelling Approach to $(1,\\lambda)$-ES Linear Optimization: Technical Report", "abstract": "Several followed publications investigate Markov - manufacturing prototyping of equivalently dft of one $ ((, \\ sorority) $ - ES, direct both unconstrained being linearly constricted optimization, out not duration and factors instead size. All of them assume bleakest of now dealing random steps, and far still if maintained to a purple - pieces unsettling, useful on the consequently to be optimized (e. g. anglomania) indeed likely reputations had the use of third transmission. The logical than things contribute is same complement previously studies wonder with moving steps, two to needed balance slow on the resource than the random steps have both role of this constant step - identical $ (. , \\ nu) $ - ES well end same should this a analogous generalized a a deterministic constraint. The formula_10 more good multidimensional processes into meant subparts and along mistranslation complement still much applied eventually with new murkiness troubling, example particularly later paid time variances his Archimedean copulas.", "histories": [["v1", "Wed, 18 Jun 2014 06:58:38 GMT  (124kb)", "http://arxiv.org/abs/1406.4619v1", null]], "reviews": [], "SUBJECTS": "cs.NA cs.LG cs.NE", "authors": ["alexandre chotard", "martin holena"], "accepted": false, "id": "1406.4619"}, "pdf": {"name": "1406.4619.pdf", "metadata": {"source": "CRF", "title": "A Generalized Markov-Chain Modelling Approach to (1, \u03bb)-ES Linear Optimization: Technical Report", "authors": ["Alexandre Chotard"], "emails": ["alexandre.chotard@lri.fr", "martin@cs.cas.cz"], "sections": [{"heading": null, "text": "ar X\niv :1\n40 6.\n46 19\nv1 [\ncs .N\nA ]\n1 8\nJu n\nKeywords: evolution strategies, continuous optimization, linear optimization, linear constraint, linear function, Markov chain models, Archimedean copulas"}, {"heading": "1 Introduction", "text": "Evolution Strategies (ES) are Derivative Free Optimization (DFO) methods, and as such are suited for the optimization of numerical problems in a black-box context, where the algorithm has no information on the function f it optimizes (e.g. existence of gradient) and can only query the function\u2019s values. In such a context, it is natural to assume normality of the random steps, as the normal distribution has maximum entropy for given mean and variance, meaning that it is the most general assumption one can make without the use of additional information on f . However such additional information may be available, and then using normal steps may not be optimal. Cases where different distributions have been studied include so-called Fast Evolution Strategies [1] or SNES [2,3] which exploits the separability of f , or heavy-tail distributions on multimodal problems [4,3].\nIn several recent publications [5,6,7,8], attention has been paid to Markovchain modelling of linear optimization by a (1, \u03bb)-ES, i.e. by an evolution strategy in which \u03bb children are generated from a single parent X \u2208 Rn by adding normally distributed n-dimensional random steps M ,\nX \u2190X + \u03c3C 1 2 M , where M \u223c N (0, In). (1)\nHere, \u03c3 is called step size, C is a covariance matrix, and N (0, In) denotes the ndimensional standard normal distribution with zero mean and covariance matrix identity. The best among the \u03bb children, i.e. the one with the highest fitness, becomes the parent of the next generation, and the step-size \u03c3 and the covariance matrix C may then be adapted to increase the probability of sampling better children. In this paper we relax the normality assumption of the movement M to a more general distribution H .\nThe linear function models a situation where the step-size is relatively small compared to the distance towards a local optimum. This is a simple problem that must be solved by any effective evolution strategy by diverging with positive increments of \u2207f.M . This unconstrained case was studied in [7] for normal steps with cumulative step-size adaptation (the step-size adaptation mechanism in CMA-ES [9]).\nLinear constraints naturally arise in real-world problems (e.g. need for positive values, box constraints) and also model a step-size relatively small compared to the curvature of the constraint. Many techniques to handle constraints in randomised algorithms have been proposed (see [10]). In this paper we focus on the resampling method, which consists in resampling any unfeasible candidate until a feasible one is sampled. We chose this method as it makes the algorithm easier to study, and is consistent with the previous studies assuming normal steps [11,5,6,8], studying constant step-size, self adaptation and cumulative step-size adaptation mechanisms (with fixed covariance matrix).\nOur aim is to study the (1, \u03bb)-ES with constant step-size, constant covariance matrix and random steps with a general absolutely continuous distribution H optimizing a linear function under a linear constraint handled through resampling. We want to extend the results obtained in [5,8] using the theory of Markov chains. It is our hope that such results will help in designing new algorithms using information on the objective function to make non-normal steps. We pay a special attention to distributions with Archimedean copulas, which are a particularly well transparent alternative to the normal distribution. Such distributions have been recently considered in the Estimation of Distribution Algorithms [12,13], continuing the trend of using copulas in that kind of evolutionary optimization algorithms [14].\nIn the next section, the basic setting for modelling the considered evolutionary optimization task is formally defined. In Section 3, the distributions of the feasible steps and of the selected steps are linked to the distribution of the random steps, and another way to sample them is provided. In Section 4, it is shown that, under some conditions on the distribution of the random steps, the normalized distance to the constraint is a ergodic Markov chain, and a law of large numbers for Markov chains is applied. Finally, Section 5 gives properties\non the distribution of the random steps under which some of the aforementioned conditions are verified.\nNotations\nFor (a, b) \u2208 N2 with a < b, [a..b] denotes the set of integers i such that a \u2264 i \u2264 b. For X and Y two random vectors, X (d) = Y denotes that these variables are equal in distribution, X a.s.\u2192 Y and X P\u2192 Y denote, respectively, almost sure convergence and convergence in probability. For (x,y) \u2208 Rn, x.y denotes the scalar product between the vectors x and y, and for i \u2208 [1..n], [x]i denotes the ith coordinate of x. For A a subset of Rn, 1A denotes the indicator function of A. For X a topological set, B(X ) denotes the Borel algebra on X ."}, {"heading": "2 Problem setting and algorithm definition", "text": "Throughout this paper, we study a (1, \u03bb)-ES optimizing a linear function f : R\nn \u2192 R where \u03bb \u2265 2 and n \u2265 2, with a linear constraint g : Rn \u2192 R, handling the constraint by resampling unfeasible solutions until a feasible solution is sampled.\nTake (ek)k\u2208[1..n] a orthonormal basis of R n. We may assume \u2207f to be normalized as the behaviour of an ES is invariant to the composition of the objective function by a strictly increasing function (e.g. h : x 7\u2192 x/\u2016\u2207f\u2016), and the same holds for\u2207g since our constraint handling method depends only on the inequality g(x) \u2264 0 which is invariant to the composition of g by a homothetic transformation. Hence w.l.o.g. we assume that \u2207f = e1 and \u2207g = cos \u03b8e1 + sin \u03b8e2 with the set of feasible solutions Xfeasible := {x \u2208 Rn|g(x) \u2264 0}. We restrict our study to \u03b8 \u2208 (0, \u03c0/2). Overall the problem reads\nmaximize f(x) = [x]1 subject to\ng(x) = [x]1 cos \u03b8 + [x]2 sin \u03b8 \u2264 0 . (2)\nAt iteration t \u2208 N, from a so-called parent point Xt \u2208 Xfeasible and with step-size \u03c3t \u2208 R\u2217+ we sample new candidate solutions by adding to Xt a random vector \u03c3tM i,j t where M i,j t is called a random step and (M i,j t )i\u2208[1..\u03bb],j\u2208N,t\u2208N is a i.i.d. sequence of random vectors with distribution H . The i index stands for the \u03bb new samples to be generated, and the j index stands for the unbounded number of samples used by the resampling. We denote M it a feasible step, that is the first element of (M i,jt )j\u2208N such that Xt + \u03c3tM i t \u2208 Xfeasible (random steps are sampled until a suitable candidate is found). The ith feasible solution Y it is then\nY it := Xt + \u03c3tM i t . (3)\nThen we denote \u22c6 := argmaxi\u2208[1..\u03bb] f(Y i t) the index of the feasible solution maximizing the function f , and update the parent point\nXt+1 := Y \u22c6 t = Xt + \u03c3tM \u22c6 t , (4)\nwhere M\u22c6t is called the selected step. Then the step-size \u03c3t, the distribution of the random steps H or other internal parameters may be adapted.\nFollowing [5,6,11,8] we define \u03b4t as\n\u03b4t := \u2212 g(Xt)\n\u03c3t . (5)"}, {"heading": "3 Distribution of the feasible and selected steps", "text": "In this section we link the distributions of the random vectors M it and M \u22c6 t to the distribution of the random steps M i,jt , and give another way to sample M i t and M\u22c6t not requiring an unbounded number of samples.\nLemma 1. Let a (1, \u03bb)-ES optimize the problem defined in (2) handling constraint through resampling. Take H the distribution of the random step M i,jt , and for \u03b4 \u2208 R\u2217+ denote L\u03b4 := {x \u2208 Rn|g(x) \u2264 \u03b4}. Providing that H is absolutely continuous and that H(L\u03b4) > 0 for all \u03b4 \u2208 R+, the distribution H\u0303\u03b4 of the feasible step and H\u0303\u22c6\u03b4 the distribution of the selected step when \u03b4t = \u03b4 are absolutely continuous, and denoting h, h\u0303\u03b4 and h\u0303 \u22c6 \u03b4 the probability density functions of, respectively, the random step, the feasible step M it and the selected step M \u22c6 t when \u03b4t = \u03b4\nh\u0303\u03b4(x) = h(x)1L\u03b4(x)\nH(L\u03b4) , (6)\nand\nh\u0303\u22c6\u03b4(x) = \u03bbh\u0303\u03b4(x)H\u0303\u03b4((\u2212\u221e, [x]1)\u00d7 Rn\u22121)\u03bb\u22121\n= \u03bb h(x)1L\u03b4 (x)H((\u2212\u221e, [x]1)\u00d7 Rn\u22121 \u2229 L\u03b4)\u03bb\u22121\nH(L\u03b4)\u03bb . (7)\nProof. Let \u03b4 > 0, A \u2208 B(Rn). Then for t \u2208 N, i = 1 . . . \u03bb, using the the fact that (M i,jt )j\u2208N is a i.i.d. sequence\nH\u0303\u03b4(A) = Pr(M i t \u2208 A|\u03b4t = \u03b4)\n= \u2211\nj\u2208N\nPr(M i,jt \u2208 A \u2229 L\u03b4 and \u2200k < j,M i,kt \u2208 Lc\u03b4|\u03b4t = \u03b4)\n= \u2211\nj\u2208N\nPr(M i,jt \u2208 A \u2229 L\u03b4|\u03b4t = \u03b4) Pr(\u2200k < j,M i,kt \u2208 Lc\u03b4|\u03b4t = \u03b4)\n= \u2211\nj\u2208N\nH(A \u2229 L\u03b4)(1 \u2212H(L\u03b4))j\n= H(A \u2229 L\u03b4) H(L\u03b4) = \u222b\nA\nh(x)1L\u03b4 (x)dx\nH(L\u03b4) ,\nwhich yield Eq. (6) and that H\u0303\u03b4 admits a density h\u0303\u03b4 and is therefore absolutely continuous.\nSince ((M i,jt )j\u2208N)i\u2208[1..\u03bb] is i.i.d., (M i t)i\u2208[1..\u03bb] is i.i.d. and\nH\u0303\u22c6\u03b4 (A) = Pr(M \u22c6 t \u2208 A|\u03b4t = \u03b4)\n=\n\u03bb \u2211\ni=1\nPr(M it \u2208 A and \u2200j \u2208 [1..\u03bb]\\{i}, [M it]1 > [M jt ]1|\u03b4t = \u03b4)\n= \u03bbPr(M1t \u2208 A and \u2200j \u2208 [2..\u03bb], [M1t ]1 > [M jt ]1|\u03b4t = \u03b4)\n= \u03bb\n\u222b\nA\nh\u0303\u03b4(x) Pr(\u2200j \u2208 [2..\u03bb], [M jt ]1 < [x]1|\u03b4t = \u03b4)dx\n=\n\u222b\nA\n\u03bbh\u0303\u03b4(x)H\u0303\u03b4((\u2212\u221e, [x]1)\u00d7 Rn\u22121)\u03bb\u22121dx ,\nwhich shows that H\u0303\u22c6\u03b4 possess a density, and with (6) yield Eq. (7). \u2293\u2294\nThe vectors (M it)i\u2208[1..\u03bb] andM \u22c6 t are functions of the vectors (M i,j t )i\u2208[1..\u03bb],j\u2208N\nand of \u03b4t. In the following Lemma an equivalent way to sample M i t and M \u22c6 t is given which uses a finite number of samples. This method is useful if one wants to avoid dealing with the infinite dimension space implied by the sequence (M i,jt )i\u2208[1..\u03bb,j\u2208N.\nLemma 2. Let a (1, \u03bb)-ES optimize problem (2), handling the constraint through resampling, and take \u03b4t as defined in (5). Let H denote the distribution of M i,j t that we assume absolutely continuous, \u2207g\u22a5 := \u2212 sin \u03b8e1 + cos \u03b8e2, Q the rotation matrix of angle \u03b8 changing (e1, e2, . . . , en) into (\u2207g,\u2207g\u22a5, . . . , en). Take F1,\u03b4(x) := Pr(M i t.\u2207g \u2264 x|\u03b4t = \u03b4), F2,\u03b4(x) := Pr(M it.\u2207g\u22a5 \u2264 x|\u03b4t = \u03b4) and Fk,\u03b4(x) := Pr([M i t]k \u2264 x|\u03b4t = \u03b4) for k \u2208 [3..n], the marginal cumulative distribution functions when \u03b4t = \u03b4, and C\u03b4 the copula of (M i t.\u2207g,M it.\u2207g\u22a5, . . . ,M it.en).\nWe define\nG : (\u03b4, (ui)i\u2208[1..n]) \u2208 R+ \u00d7 [0, 1]n 7\u2192 Q\n\n  F\u221211,\u03b4 (u1) ...\nF\u22121n,\u03b4 (un)\n\n  , (8)\nG\u22c6 : (\u03b4, (vi)i\u2208[1..\u03bb]) \u2208 R+ \u00d7 [0, 1]n\u03bb 7\u2192 argmax G\u2208{G(\u03b4,vi)|i\u2208[1..\u03bb]} f(G) . (9)\nThen, if the copula C\u03b4 is constant in regard to \u03b4, for Wt = (V i,t)i\u2208[1..\u03bb] a i.i.d. sequence with V i,t \u223c C\u03b4\nG(\u03b4t,V i,t) (d) = M it , (10)\nG\u22c6(\u03b4t,Wt) (d) = M\u22c6t . (11)\nProof. Since V i,t \u223c C\u03b4\n(M it.\u2207g,M it.\u2207g\u22a5, . . . ,M it.en) (d) = (F\u221211,\u03b4 (V 1,t), F \u22121 2,\u03b4 (V 2,t), . . . , F \u22121 n,\u03b4 (V n,t)) ,\nand if the function \u03b4 \u2208 R+ 7\u2192 C\u03b4 is constant, then the sequence of random vectors (V i,t)i\u2208[1..\u03bb],t\u2208N is i.i.d.. Finally by definitionQ \u22121M it = (M i t.\u2207g,M it.\u2207g\u22a5, . . . ,M it.en), which shows Eq. (10). Eq. (11) is a direct consequence of Eq. (10) and the fact that M\u22c6t = argmax\nG\u2208{G(\u03b4,vi)|i\u2208[1..\u03bb]}\nf(G) (which holds as f is linear). \u2293\u2294\nWe may now use these results to show the divergence of the algorithm when the step-size is constant, using the theory of Markov chains [15].\n4 Divergence of the (1, \u03bb)-ES with constant step-size\nFollowing the first part of [8], we restrict our attention to the constant step size in the remainder of the paper, that is for all t \u2208 N we take \u03c3t = \u03c3 \u2208 R\u2217+.\nFrom Eq. (4), by recurrence and dividing by t, we see that\n[Xt \u2212X0]1 t = \u03c3 t\nt\u22121 \u2211\ni=0\nM\u22c6i . (12)\nThe latter term suggests the use of a Law of Large Numbers to show the convergence of the LHS (Left Hand Side) to a constant that we call the divergence rate. The random vectors (M\u22c6t )t\u2208N are not i.i.d. so in order to apply a Law of Large Numbers on the RHS (Right Hand Side) of the previous equation we use Markov chain theory, more precisely the fact that (M\u22c6t )t\u2208N is a function of a (\u03b4t, (M i,j t )i\u2208[1..\u03bb],j\u2208N)t\u2208N which is a geometrically ergodic Markov chain. As (M i,jt )i\u2208[1..\u03bb],j\u2208N,t\u2208N is a i.i.d. sequence, it is a Markov chain, and the sequence (\u03b4t)t\u2208N is also a Markov chain as stated in the following proposition.\nProposition 1. Let a (1, \u03bb)-ES with constant step-size optimize problem (2), handling the constraint through resampling, and take \u03b4t as defined in (5). Then no matter what distribution the i.i.d. sequence (M i,jt )i\u2208[1..\u03bb],(j,t)\u2208N2 have, (\u03b4t)t\u2208N is a homogeneous Markov chain and\n\u03b4t+1 = \u03b4t \u2212 g(M\u22c6t ) = \u03b4t \u2212 cos \u03b8[M\u22c6t ]1 \u2212 sin \u03b8[M\u22c6t ]2 . (13)\nProof. By definition in (5) and since for all t, \u03c3t = \u03c3,\n\u03b4t+1 = \u2212 g(Xt+1)\n\u03c3t+1\n= \u2212g(Xt) + \u03c3g(M \u22c6 t ) \u03c3 = \u03b4t \u2212 g(M\u22c6t ) ,\nand as shown in (7) the density of M\u22c6t is determined by \u03b4t. So the distribution of \u03b4t+1 is determined by \u03b4t, hence (\u03b4t)t\u2208N is a time-homogeneous Markov chain. \u2293\u2294\nWe now show ergodicity of the Markov chain (\u03b4t)t\u2208N, which implies that the t-steps transition kernel (the function A 7\u2192 Pr(\u03b4t \u2208 A|\u03b40 = \u03b4) for A \u2208 B(R+)) converges towards a stationary measure \u03c0, generalizing Propositions 3 and 4 of [8].\nProposition 2. Let a (1, \u03bb)-ES with constant step-size optimize problem (2), handling the constraint through resampling. We assume that the distribution of M\ni,j t is absolutely continuous with probability density function h, and that h is continuous and strictly positive on Rn. Denote \u00b5+ the Lebesgue measure on (R+,B(R+)), and for \u03b1 > 0 take the functions V : \u03b4 7\u2192 \u03b4, V\u03b1 : \u03b4 7\u2192 exp(\u03b1\u03b4) and r1 : \u03b4 7\u2192 1. Then (\u03b4t)t\u2208N is \u00b5+-irreducible, aperiodic and compact sets are small sets for the Markov chain.\nIf the following two additional conditions are fulfilled\nE(|g(M i,jt )| | \u03b4t = \u03b4) < \u221e for all \u03b4 \u2208 R+ , and (14)\nlim \u03b4\u2192+\u221e\nE(g(M\u22c6t )|\u03b4t = \u03b4) \u2208 R\u2217+ , (15)\nthen (\u03b4t)t\u2208N is r1-ergodic and positive Harris recurrent with some invariant measure \u03c0.\nFurthermore, if\nE(exp(g(M i,jt ))|\u03b4t = \u03b4) < \u221e for all \u03b4 \u2208 R+ , (16)\nthen for \u03b1 > 0 small enough, (\u03b4t)t\u2208N is also V\u03b1\u2212geometrically ergodic.\nProof. The probability transition kernel of (\u03b4t)t\u2208N writes\nP (\u03b4, A) =\n\u222b\nRn\n1A(\u03b4 \u2212 g(x))h\u0303\u22c6\u03b4(x)dx\n=\n\u222b\nRn\n1A(\u03b4 \u2212 g(x))\u03bb h(x)1L\u03b4 (x)H((\u2212\u221e, [x]1)\u00d7 Rn\u22121 \u2229 L\u03b4)\u03bb\u22121\nH(L\u03b4)\u03bb\n= \u03bb\nH(L\u03b4)\u03bb\n\u222b\ng\u22121(A)\nh\n\n   \n\u03b4 \u2212 [u]1 \u2212[u]2\n... \u2212[u]n\n\n    H((\u2212\u221e, \u03b4 \u2212 [u]1)\u00d7 Rn\u22121 \u2229 L\u03b4)\u03bb\u22121du ,\nwith the substitution of variables [u]1 = \u03b4 \u2212 [x]1 and [u]i = \u2212[x]i for i \u2208 [2..n]. Denote L\u22c6\u03b4,v := (\u2212\u221e, v) \u00d7 Rn\u22121 \u2229 L\u03b4 and t\u03b4 : u 7\u2192 (\u03b4 \u2212 [u]1,\u2212[u]2, . . . ,\u2212[u]n), take C a compact of R+, and define \u03bdC such that for A \u2208 B(R+)\n\u03bdC(A) := \u03bb\n\u222b\ng\u22121(A)\ninf \u03b4\u2208C\nh(t\u03b4(u))H(L \u22c6 \u03b4,[u]1 )\u03bb\u22121\nH(L\u03b4)\u03bb du .\nAs the density h is supposed to be strictly positive on Rn, for all \u03b4 \u2208 R+ we have H(L\u03b4) \u2265 H(L0) > 0. Using the fact that H is a finite measure, and is absolutely continuous, applying the dominated convergence theorem shows that the functions \u03b4 7\u2192 H(L\u03b4) and \u03b4 7\u2192 H((\u2212\u221e, \u03b4\u2212 [u]1)\u00d7Rn\u22121\u2229L\u03b4) are continuous. Therefore the function \u03b4 7\u2192 h(t\u03b4(u))H(L\u22c6\u03b4,[u]1) \u03bb\u22121/H(L\u03b4) \u03bb is continuous and C being a compact, the infimum of this function is reached on C is reached on C. Since this function is strictly positive, if g\u22121(A) has strictly positive Lebesgue measure then \u03bdC(A) > 0 which proves that this measure is not trivial. By construction P (\u03b4, A) \u2265 \u03bdC(A) for all \u03b4 \u2208 C, so C is a small set which shows that compact sets are small. Since if \u00b5+(A) > 0 we have P (\u03b4, A) \u2265 \u03bdC(A) > 0, the Markov chain (\u03b4t)t\u2208N is \u00b5+-irreducible. Finally, if we take C a compact set of R+ with strictly positive Lebesgue measure, then it is a small set and \u03bdC(C) > 0 which means the Markov chain (\u03b4t)t\u2208N is strongly aperiodic.\nThe function \u2206V is defined as \u03b4mapstoE(V (\u03b4t+1)|\u03b4t = \u03b4) \u2212 V (\u03b4). We want to show a drift condition (see [15]) on V . Using Eq. (13)\n\u2206V (\u03b4) = E(\u03b4 \u2212 g(M\u22c6t )|\u03b4t = \u03b4)\u2212 \u03b4) = \u2212E(g(M\u22c6t )) .\nTherefore using the condition (15), we have that there exists a \u01eb > 0 and a M \u2208 R+ such that \u2200\u03b4 \u2208 (M,+\u221e), \u2206V (\u03b4) \u2264 \u2212\u01eb. With condtion (14) implies that the function \u2206V + \u01eb is bounded on the compact [0,M ] by a constant b \u2208 R. Hence for all \u03b4 \u2208 R+\n\u2206V (\u03b4) \u01eb \u2264 \u22121 + b \u01eb 1[0,M ](\u03b4) . (17)\nFor all x \u2208 R the level set CV,x of the function V , {y \u2208 R+|V (y) \u2264 x}, is equal to [0, x] which is a compact set, hence a small set according to what we proved\nearlier (and hence petite [15, Proposition 5.5.3]). Therefore V is unbounded off small sets and with (17) and Theorem 9.1.8 of [15], the Markov chain (\u03b4t)t\u2208N is Harris recurrent. The set [0,M ] is compact and therefore small and petite, so with (17), if we denote r1 the constant function \u03b4 \u2208 R+ 7\u2192 1 then with Theorem 14.0.1 of [15] the Markov chain (\u03b4t)t\u2208N is positive and is r1-ergodic.\nWe now want to show a drift condition (see [15]) on V\u03b1.\n\u2206V\u03b1(\u03b4) = E (exp (\u03b1\u03b4 \u2212 \u03b1g (M\u22c6t )) |\u03b4t = \u03b4)\u2212 exp (\u03b1\u03b4) \u2206V\u03b1 V\u03b1 (\u03b4) = E (exp (\u2212\u03b1g (M\u22c6t )) |\u03b4t = \u03b4)\u2212 1\n=\n\u222b\nRn\nlim t\u2192+\u221e\nt \u2211\nk=0\n(\u2212\u03b1g(x))k k! h\u0303\u22c6\u03b4(x)dx\u2212 1 .\nWith Eq. (7) we see that h\u0303\u22c6\u03b4(x) \u2264 \u03bbh(x)/H(L0)\u03bb, so with our assumption that E(exp\u03b1|g(M i,jt )||\u03b4t = \u03b4) < \u221e for \u03b1 > 0 small enough we have that the function \u03b4 7\u2192 E(exp(\u03b1|g(M\u22c6t )||\u03b4t = \u03b4) is bounded for the same \u03b1. As \u2211t\nk=0(\u2212\u03b1g(x))k/k!h\u0303\u22c6\u03b4(x) \u2264 exp(\u03b1|g(x)|)h\u0303\u22c6\u03b4(x) which, with condition (16), is integrable so we may apply the theorem of dominated convergence to invert limit and integral:\n\u2206V\u03b1 V\u03b1 (\u03b4) = lim t\u2192+\u221e\nt \u2211\nk=0\n\u222b\nRn\n(\u2212\u03b1g(x))k k! h\u0303\u22c6\u03b4(x)dx\u2212 1\n= \u2211\nk\u2208N\n(\u2212\u03b1)k E ( g (M\u22c6t ) k|\u03b4t = \u03b4 )\nk! \u2212 1\nSince h\u0303\u22c6\u03b4(x) \u2264 \u03bbh(x)/H(L0)2, (\u2212\u03b1)kE(g(M\u22c6t ) k|\u03b4t = \u03b4)/k! \u2264 (\u2212\u03b1)kE(g(M i,jt ) k )/k! which is integrable with respect to the counting measure so we may apply the dominated convergence theorem with the counting measure to invert limit and serie.\nlim \u03b4\u2192+\u221e \u2206V\u03b1 V\u03b1 (\u03b4) = \u2211\nk\u2208N\nlim \u03b4\u2192+\u221e\n(\u2212\u03b1)k E ( g (M\u22c6t ) k|\u03b4t = \u03b4 )\nk! \u2212 1\n= \u2212\u03b1 lim \u03b4\u2192+\u221e E (g (M\u22c6t ) |\u03b4t = \u03b4) + o (\u03b1) .\nWith condition (17) we supposed that lim\u03b4\u2192+\u221eE(g(M \u22c6 t )|\u03b4t = \u03b4) > 0 this implies that for \u03b1 > 0 and small enough, lim\u03b4\u2192+\u221e\u2206V\u03b1(\u03b4)/V\u03b1(\u03b4) < 0, hence there exists M \u2208 R+ and epsilon > 0 such that \u2200\u03b4 > M , \u2206V\u03b1(\u03b4) < \u2212\u01ebV\u03b1(\u03b4). Finally as \u2206V\u03b1 \u2212 V\u03b1 is bounded on [0,M ] there exists b \u2208 R such that\n\u2206V\u03b1(\u03b4) \u2264 \u2212\u01ebV\u03b1(\u03b4) + b1[0,M ](\u03b4) .\nAccording to what we did before in this proof, the compact set [0,M ] is small, and hence is petite ([15, Proposition 5.5.3]). So the \u00b5+-irreducible Markov chain\n(\u03b4t)t\u2208N satisfies the conditions of Theorem 15.0.1 of [15] which with Theorem 14.0.1 of [15] proves that the Markov chain (\u03b4t)t\u2208N is V\u03b1-geometrically ergodic.\n\u2293\u2294\nWe now use a law of large numbers ([15] Theorem 17.0.1) on the Markov chain (\u03b4t, (M i,j t )i\u2208[1..\u03bb],j\u2208N)t\u2208N to obtain an almost sure divergence of the algorithm.\nProposition 3. Let a (1, \u03bb)-ES optimize problem (2), handling the constraint through resampling. Assume that the distribution H of the random step M i,jt is absolutely continuous with continuous and strictly positive density h, that conditions (16) and (15) of Proposition 2 hold, and denote \u03c0 and \u00b5M the stationary distribution of respectively (\u03b4t)t\u2208N and (M i,j t )i\u2208[1..\u03bb],(j,t)\u2208N2 . Then\n[Xt \u2212X0]1 t a.s.\u2212\u2192 t\u2192+\u221e \u03c3E\u03c0\u00d7\u00b5M ([M \u22c6 t ]1) . (18)\nFurthermore if E([M\u22c6t ]2) < 0, then the right hand side of Eq. (18) is strictly positive.\nProof. According to Proposition 2 the sequence (\u03b4t)t\u2208N is a Harris recurrent positive Markov chain with invariant measure \u03c0. As (M i,jt )i\u2208[1..\u03bb],(j,t)\u2208N2 is a i.i.d. sequence with distribution \u00b5M , (\u03b4t, (M i,j t )i\u2208[1..\u03bb],j\u2208N)t\u2208N is also a Harris recurrent positive Markov chain. As [M\u22c6t ]1 is a function of \u03b4t and (M i,j t )i\u2208[1..\u03bb],j\u2208N, if E\u03c0\u00d7\u00b5M (|[M\u22c6t ]1|) < \u221e, according to Theorem 17.0.1 of [15], we may apply a law of large numbers on the right hand side of Eq. (12) to obtain (18).\nUsing Fubini-Tonelli\u2019s theorem E\u03c0\u00d7\u00b5M (|[M\u22c6t ]1|) = E\u03c0(E\u00b5M (|[M\u22c6t ]1||\u03b4t = \u03b4)). From Eq. (7) for all x \u2208 Rn, h\u0303\u22c6\u03b4(x) \u2264 \u03bbh(x)/H(L0)2, so the condition in (16) implies that for all \u03b4 \u2208 R+, E\u00b5M (|[M\u22c6t ]1||\u03b4t = \u03b4) is finite. Furthermore, with condition (15), the function \u03b4 \u2208 R+ 7\u2192 E\u00b5M (|[M\u22c6t ]1||\u03b4t = \u03b4) is bounded by some M \u2208 R. Therefore as \u03c0 is a probability measure, E\u03c0(E\u00b5M (|[M\u22c6t ]1||\u03b4t = \u03b4)) \u2264 M < \u221e so we may apply the law of large numbers of Theorem 17.0.1 of [15].\nUsing the fact that \u03c0 is an invariant measure, we have E\u03c0(\u03b4t) = E\u03c0(\u03b4t+1), so E\u03c0(\u03b4t) = E\u03c0(\u03b4t \u2212 \u03c3g(M\u22c6t )) and hence cos \u03b8E\u03c0([M\u22c6t ]1) = \u2212 sin \u03b8E\u03c0([M\u22c6t ]2). So using the assumption that E([M i,jt ]2) \u2264 0 then we get the strict positivity of E\u03c0\u00d7\u00b5M ([M i,j t ]1). \u2293\u2294"}, {"heading": "5 Application to More Specific Distributions", "text": "Throughout this section we give cases where the assumptions on the distribution of the random steps H used in Proposition 2 or Proposition 3 are verified.\nThe following lemma shows an equivalence between a non-identity covariance matrix for H and a different norm and constraint angle \u03b8.\nLemma 3. Let a (1, \u03bb)-ES optimize problem (2), handling the constraint with resampling. Assume that the distribution H of the random step M i,jt has positive definite covariance matrix C with eigenvalues (\u03b12i )i\u2208[1..n] and take B =\n(bi,j)(i,j)\u2208[1..n]2 such that BCB \u22121 is diagonal. Denote AH,g,X0 the sequence of parent points (Xt)t\u2208N of the algorithm with distribution H for the random steps M\ni,j t , constraint angle \u03b8 and initial parent X0. Then for all k \u2208 [1..n]\n\u03b2k [AH,\u03b8,X0 ]k (d) =\n[\nAC\u22121/2H,\u03b8\u2032,X\u2032 0\n]\nk , (19)\nwhere \u03b2k =\n\u221a\n\u2211n j=1 b2j,i \u03b12i , \u03b8\u2032 = arccos(\u03b21cos\u03b8\u03b2g ) with \u03b2g = \u221a \u03b221 cos 2 \u03b8 + \u03b222 sin 2 \u03b8,\nand [X \u20320]k = \u03b2k[X0]k for all k \u2208 [1..n].\nProof. Take (e\u0304k)k\u2208[1..n] the image of (ek)k\u2208[1..n] by B \u22121. We define a new norm \u2016 \u00b7 \u2016\u2212 such that \u2016e\u0304k\u2016\u2212 = 1/\u03b1k. We define two orthonormal basis (e\u2032k)k\u2208[1..n] and (e\u0304\u2032k)k\u2208[1..n] for (R\nn, \u2016\u00b7\u2016\u2212) by taking e\u2032k = ek/\u2016ek\u2016\u2212 and e\u0304\u2032k = e\u0304k/\u2016e\u0304k\u2016\u2212 = \u03b1ke\u0304k. As Var(M i,jt .e\u0304k) = \u03b1 2 k, Var(M i,j t .e\u0304 \u2032 k) = 1 so in (R\nn, \u2016\u00b7\u2016\u2212) the covariance matrix of M i,jt is the identity.\nTake h the function that to x \u2208 Rn maps its image in the new orthonormal basis (e\u2032k)k\u2208[1..n]. As e \u2032 k = ek/\u2016ek\u2016\u2212, h(x) = (\u2016ek\u2016\u2212[x]k)k\u2208[1..n], where \u2016ek\u2016\u2212 = \u2016 \u2211n i=1 bi,ke\u0304k\u2016\u2212 = \u221a \u2211n i=1 b 2 i,k/\u03b1 2 k = \u03b2k. As we changed the norm, the angle between \u2207f and \u2207g is also different in the new space. Indeed cos \u03b8\u2032 = h(\u2207g).h(\u2207f)/(\u2016h(\u2207g)\u2016\u2212\u2016h(\u2207f)\u2016\u2212) = \u03b221 cos \u03b8/( \u221a \u03b221 cos 2 \u03b8 + \u03b222 sin 2 \u03b8\u03b21) = \u03b21 cos \u03b8/\u03b2g.\nIf we take N i,jt \u223c C\u22121/2H then it has the same distribution as h(M i,jt ). Take X \u2032t = h(Xt) then for a constraint angle \u03b8\n\u2032 = arccos(\u03b21 cos \u03b8/\u03b2g) and a normalized distance to the constraint \u03b4t = X \u2032 t.h(\u2207g)/\u03c3t the ressampling is the same for N i,jt and h(M i,j t ) so N i t (d) = h(M it). Finally the rankings induced by \u2207f or h(\u2207f) are the same so the selection in the same, hence N\u22c6t (d) = h(M\u22c6t ), and therefore X \u2032t+1 (d) = h(Xt+1). \u2293\u2294\nAlthough Eq. (18) shows divergence of the algorithm, it is important that it diverges in the right direction, i.e. that the right hand side of Eq. (18) has a positive sign. This is achieved when the distribution of the random steps is isotropic, as stated in the following proposition.\nProposition 4. Let a (1, \u03bb)-ES optimize problem (2) with constant step-size, handling the constraint with resampling. Suppose that the Markov chain (\u03b4t)t\u2208N is positive Harris, that the distribution H of the random step M i,jt is absolutely continuous with strictly positive density h, and take C its covariance matrix. If the distribution C\u22121/2H is isotropic then E\u03c0\u00d7\u00b5M ([M \u22c6 t ]1) > 0.\nProof. First if C = In, using the same method than in the proof of Lemma 1\nh\u22c6\u03b4,2(y) = \u03bb\n\u222b\nR\n. . .\n\u222b\nR\nh\u0303\u03b4(u1, y, u3, . . . , un) Pr(u1 \u2265 [M it]1)\u03bb\u22121du1 n \u220f\nk=3\nduk .\nUsing Eq.(6) and the fact that the condition x \u2208 L\u03b4 is equivalent to [x]1 \u2264 (\u03b4 \u2212 [x]2 sin \u03b8)/ cos \u03b8 we obtain\nh\u22c6\u03b4,2(y) = \u03bb\n\u222b\nR\n. . .\n\u222b \u03b4\u2212y sin \u03b8\ncos \u03b8\n\u2212\u221e\nh(u1, y, u3, . . . , un)\nH(L\u03b4) Pr(u1 \u2265 [M it]1)\u03bb\u22121du1\nn \u220f\nk=3\nduk .\nIf the distribution of the random steps steps is isotropic then h(u1, y, u3, . . . , un) = h(u1,\u2212y, u3, . . . , un), and as the density h is supposed strictly positive, for y > 0 and all \u03b4 \u2208, h\u22c6\u03b4,2(y)\u2212 h\u22c6\u03b4,2(\u2212y) < 0 so E([M\u22c6t ]2|\u03b4t = \u03b4) < 0. If the Markov chain is Harris recurrent and positive then this imply that E\u03c0([M \u22c6 t ]2) < 0 and using the reasoning in the proof of Proposition 3 E\u03c0([M \u22c6 t ]1) > 0.\nFor any covariance matrixC this result is generalized with the use of Lemma 3. \u2293\u2294\nLemma 3 and Proposition 4 imply the following result to hold for multivariate normal distributions.\nProposition 5. Let a (1, \u03bb)-ES optimize problem (2) with constant step-size, handling the constraint with resampling. If H is a multivariate normal distribution with mean 0, then (\u03b4t)t\u2208N is a geometrically ergodic positive Harris Markov chain, Eq. (18) holds and its right hand side is strictly positive.\nProof. Suppose M i,jt \u223c N (0, In). Then H is absolutely continuous and h is strictly positive. The function x 7\u2192 exp(g(x)) exp(\u2212\u2016x\u20162/2)/ \u221a 2\u03c0 is integrable, so Eq. (16) is satisfied. Furthermore, when \u03b4 \u2192 +\u221e the constraint disappear so M i,jt behaves like (N\u03bb:\u03bb,N (0, 1), . . . ,N (0, 1)) where N\u03bb:\u03bb is the last order statistic of \u03bb i.i.d. standard normal variables, so using that E(N\u03bb:\u03bb) > 0 and E(N (0, 1)) = 0, with multiple uses of the dominated convergence theorem we obtain condition (15) so with Proposition 2 the Markov chain (\u03b4t)t\u2208N is geometrically ergodic and positive Harris.\nFinally H being isotropic the conditions of Proposition 4 are fulfilled, and therefore so are every condition of Proposition 3 which shows what we wanted.\n\u2293\u2294\nTo obtain sufficient conditions for the density of the random steps to be strictly positive, it is advantageous to decompose that distribution into its marginals and the copula combining them. We pay a particular attention to Archimedean copulas, i.e., copulas defined\n(\u2200u \u2208 [0, 1]n) C\u03c8(u) = \u03c8(\u03c8\u22121([u]1) + \u00b7 \u00b7 \u00b7+ \u03c8\u22121([u]n)), (20)\nwhere \u03c8 : [0,+\u221e] \u2192 [0, 1] is an Archimedean generator, i.e., \u03c8(0) = 1, \u03c8(+\u221e) = limt\u2192+\u221e \u03c8(t) = 0, \u03c8 is continuous and strictly decreasing on [0, inf{t : \u03c8(t) = 0}), and \u03c8\u22121 denotes the generalized inverse of \u03c8,\n(\u2200u \u2208 [0, 1]) \u03c8\u22121(u) = inf{t \u2208 [0,+\u221e] : \u03c8(t) = u}. (21)\nThe reason for our interest is that Archimedean copulas are invariant with respect to permutations of variables, i.e.,\n(\u2200u \u2208 [0, 1]n) C\u03c8(Qu) = C\u03c8(u). (22)\nholds for any permutation matrix Q \u2208 Rn,n. This can be seen as a weak form of isotropy because in the case of isotropy, (20) holds for any rotation matrix, and a permutation matrix is a specific rotation matrix.\nProposition 6. Let H be the distribution of the two first dimensions of the random step M i,jt , H1 and H2 be its marginals, and C be the copula relating H to H1 and H2. Then the following holds:\n1. Sufficient for H to have a continuous strictly positive density is the simultaneous validity of the following two conditions. (i) H1 and H2 have continuous strictly positive densities h1 and h2, respec-\ntively. (ii) C has a continuous strictly positive density c. Moreover, if (i) and (ii) are valid, then\n(\u2200x \u2208 R2) h(x) = c(H1([x]1), H2([x]2))h1([x]1)h2([x]2). (23)\n2. If C is Archimedean with generator \u03c8, then it is sufficient to replace (ii) with (ii\u2019) \u03c8 is at least 4-monotone, i.e., \u03c8 is continuous on [0,+\u221e], \u03c8\u2032\u2032 is decreas-\ning and convex on R+, and (\u2200t \u2208 R+) (\u22121)k\u03c8(k)(t) \u2265 0, k = 0, 1, 2. In this case, if (i) and (ii\u2019) are valid, then\n(\u2200x \u2208 R2) h(x) = \u03c8 \u2032\u2032(\u03c8\u22121(H1([x]1)) + \u03c8 \u22121(H2([x]2)))\n\u03c8\u2032(\u03c8\u22121(H1([x]1)) + \u03c8\u22121(H2([x]2))) h1([x]1)h2([x]2).\n(24)"}, {"heading": "6 Discussion", "text": "The paper presents a generalization of recent results of the first author [8] concerning linear optimization by a (1, \u03bb)-ES in the constant step size case. The generalization consists in replacing the assumption of normality of random steps involved in the evolution strategy by substantially more general distributional assumptions. This generalization shows that isotropic distributions solve the linear problem. Also, although the conditions for the ergodicity of the studied Markov chain accept some heavy-tail distributions, an expnentially vanishing tail allow for geometric ergodicity, which imply a faster convergence to its stationary distribution, and faster convergence of Monte Carlo simulations. In our opinion, these conditions increase the insight into the role that different kinds of distributions play in evolutionary computation, and enlarges the spectrum of possibilities for designing evolutionary algorithms with solid theoretical fundamentals. At the same time, applying the decomposition of a multidimensional distribution into its marginals and the copula combining them, the paper attempts to bring a\nsmall contribution to the research into applicability of copulas in evolutionary computation, complementing the more common application of copulas to the Estimation of Distribution Algorithms [12,14,13].\nNeedless to say, more realistic than the constant step size case, but also more difficult to investigate, is the varying step size case. The most important results in [8] actually concern that case. A generalization of those results for non-Gaussian distributions of random steps for cumulative step-size adaptation ([9]) is especially difficult as the evolution path is tailored for Gaussian steps, and some careful tweaking would have to be applied. The \u03c3 self-adaptation evolution strategy ([16]), studied in [6] for the same problem, appears easier, and would be our direction for future research.\nAcknowledgment\nThe research reported in this paper has been supported by grant ANR-2010COSI-002 (SIMINOLE) of the French National Research Agency, and Czech Science Foundation (GAC\u030cR) grant 13-17187S."}, {"heading": "10. C. A. Coello Coello, \u201cConstraint-handling techniques used with evolutionary al-", "text": "gorithms,\u201d in Proceedings of the 2008 GECCO conference companion on Genetic and evolutionary computation, GECCO \u201908, (New York, NY, USA), pp. 2445\u20132466, ACM, 2008. 11. D. Arnold and D. Brauer, \u201cOn the behaviour of the (1 + 1)-ES for a simple constrained problem,\u201d in Parallel Problem Solving from Nature - PPSN X (I. G. R. et al., ed.), pp. 1\u201310, Springer, 2008. 12. A. Cuesta-Infante, R. Santana, J. Hidalgo, C. Bielza, and P. Larran\u0303aga, \u201cBivariate empirical and n-variate archimedean copulas in estimation of distribution algorithms,\u201d in IEEE Congress on Evolutionary Computation, pp. 1\u20138, 2010. 13. L. Wang, X. Guo, J. Zeng, and Y. Hong, \u201cCopula estimation of distribution algorithms based on exchangeable archimedean copula,\u201d International Journal of Computer Applications in Technology, vol. 43, pp. 13\u201320, 2012. 14. R. Salinas-Gutierrez, A. Herna\u0301ndez Aguirre, and E. Villa Diharce, \u201cUsing copulas in estimation of distribution algorithms,\u201d in MICAI 2009: Advances in Artificial Intelligence, pp. 658\u2013668, 2009. 15. S. P. Meyn and R. L. Tweedie, Markov chains and stochastic stability. Cambridge University Press, second ed., 1993. 16. H.-G. Beyer, \u201cToward a theory of evolution strategies: Self-adaptation,\u201d Evolutionary Computation, vol. 3, no. 3, pp. 311\u2013347, 1995."}], "references": [{"title": "Fast evolution strategies,", "author": ["X. Yao", "Y. Liu"], "venue": "Evolutionary Programming VI,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1997}, {"title": "Benchmarking Separable Natural Evolution Strategies on the Noiseless and Noisy Black-box Optimization Testbeds,\u201d in Black-box Optimization Benchmarking Workshop, Genetic and Evolutionary Computation", "author": ["T. Schaul"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "High dimensions and heavy tails for natural evolution strategies,", "author": ["T. Schaul", "T. Glasmachers", "J. Schmidhuber"], "venue": "Genetic and Evolutionary Computation Conference (GECCO),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "When do heavy-tail distributions help?,", "author": ["N. Hansen", "F. Gemperle", "A. Auger", "P. Koumoutsakos"], "venue": "P. Runarsson et al., eds.),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2006}, {"title": "On the behaviour of the (1,\u03bb)-ES for a simple constrained problem,", "author": ["D. Arnold"], "venue": "in Foundations of Genetic Algorithms - FOGA", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "On the behaviour of the (1, \u03bb)-\u03c3SA-ES for a constrained linear problem,\u201d in Parallel Problem Solving from Nature ", "author": ["D. Arnold"], "venue": "PPSN XII,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Cumulative step-size adaptation on linear functions,\u201d in Parallel Problem Solving from Nature - PPSN XII", "author": ["A. Chotard", "A. Auger", "N. Hansen"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Markov chain analysis of evolution strategies on a linear constraint optimization problem,", "author": ["A. Chotard", "A. Auger", "N. Hansen"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Completely derandomized self-adaptation in evolution strategies,", "author": ["N. Hansen", "A. Ostermeier"], "venue": "Evolutionary Computation,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2001}, {"title": "Constraint-handling techniques used with evolutionary algorithms,", "author": ["C.A. Coello Coello"], "venue": "Proceedings of the 2008 GECCO conference companion on Genetic and evolutionary computation,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2008}, {"title": "On the behaviour of the (1 + 1)-ES for a simple constrained problem,\u201d in Parallel Problem Solving from Nature ", "author": ["D. Arnold", "D. Brauer"], "venue": "PPSN X (I. G. R. et al.,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "Copula estimation of distribution algorithms based on exchangeable archimedean copula,", "author": ["L. Wang", "X. Guo", "J. Zeng", "Y. Hong"], "venue": "International Journal of Computer Applications in Technology,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Using copulas in estimation of distribution algorithms,", "author": ["R. Salinas-Gutierrez", "A. Hern\u00e1ndez Aguirre", "E. Villa Diharce"], "venue": "MICAI", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Markov chains and stochastic stability", "author": ["S.P. Meyn", "R.L. Tweedie"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1993}, {"title": "Toward a theory of evolution strategies: Self-adaptation,", "author": ["H.-G. Beyer"], "venue": "Evolutionary Computation,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1995}], "referenceMentions": [{"referenceID": 0, "context": "Cases where different distributions have been studied include so-called Fast Evolution Strategies [1] or SNES [2,3] which exploits the separability of f , or heavy-tail distributions on multimodal problems [4,3].", "startOffset": 98, "endOffset": 101}, {"referenceID": 1, "context": "Cases where different distributions have been studied include so-called Fast Evolution Strategies [1] or SNES [2,3] which exploits the separability of f , or heavy-tail distributions on multimodal problems [4,3].", "startOffset": 110, "endOffset": 115}, {"referenceID": 2, "context": "Cases where different distributions have been studied include so-called Fast Evolution Strategies [1] or SNES [2,3] which exploits the separability of f , or heavy-tail distributions on multimodal problems [4,3].", "startOffset": 110, "endOffset": 115}, {"referenceID": 3, "context": "Cases where different distributions have been studied include so-called Fast Evolution Strategies [1] or SNES [2,3] which exploits the separability of f , or heavy-tail distributions on multimodal problems [4,3].", "startOffset": 206, "endOffset": 211}, {"referenceID": 2, "context": "Cases where different distributions have been studied include so-called Fast Evolution Strategies [1] or SNES [2,3] which exploits the separability of f , or heavy-tail distributions on multimodal problems [4,3].", "startOffset": 206, "endOffset": 211}, {"referenceID": 4, "context": "In several recent publications [5,6,7,8], attention has been paid to Markovchain modelling of linear optimization by a (1, \u03bb)-ES, i.", "startOffset": 31, "endOffset": 40}, {"referenceID": 5, "context": "In several recent publications [5,6,7,8], attention has been paid to Markovchain modelling of linear optimization by a (1, \u03bb)-ES, i.", "startOffset": 31, "endOffset": 40}, {"referenceID": 6, "context": "In several recent publications [5,6,7,8], attention has been paid to Markovchain modelling of linear optimization by a (1, \u03bb)-ES, i.", "startOffset": 31, "endOffset": 40}, {"referenceID": 7, "context": "In several recent publications [5,6,7,8], attention has been paid to Markovchain modelling of linear optimization by a (1, \u03bb)-ES, i.", "startOffset": 31, "endOffset": 40}, {"referenceID": 6, "context": "This unconstrained case was studied in [7] for normal steps with cumulative step-size adaptation (the step-size adaptation mechanism in CMA-ES [9]).", "startOffset": 39, "endOffset": 42}, {"referenceID": 8, "context": "This unconstrained case was studied in [7] for normal steps with cumulative step-size adaptation (the step-size adaptation mechanism in CMA-ES [9]).", "startOffset": 143, "endOffset": 146}, {"referenceID": 9, "context": "Many techniques to handle constraints in randomised algorithms have been proposed (see [10]).", "startOffset": 87, "endOffset": 91}, {"referenceID": 10, "context": "We chose this method as it makes the algorithm easier to study, and is consistent with the previous studies assuming normal steps [11,5,6,8], studying constant step-size, self adaptation and cumulative step-size adaptation mechanisms (with fixed covariance matrix).", "startOffset": 130, "endOffset": 140}, {"referenceID": 4, "context": "We chose this method as it makes the algorithm easier to study, and is consistent with the previous studies assuming normal steps [11,5,6,8], studying constant step-size, self adaptation and cumulative step-size adaptation mechanisms (with fixed covariance matrix).", "startOffset": 130, "endOffset": 140}, {"referenceID": 5, "context": "We chose this method as it makes the algorithm easier to study, and is consistent with the previous studies assuming normal steps [11,5,6,8], studying constant step-size, self adaptation and cumulative step-size adaptation mechanisms (with fixed covariance matrix).", "startOffset": 130, "endOffset": 140}, {"referenceID": 7, "context": "We chose this method as it makes the algorithm easier to study, and is consistent with the previous studies assuming normal steps [11,5,6,8], studying constant step-size, self adaptation and cumulative step-size adaptation mechanisms (with fixed covariance matrix).", "startOffset": 130, "endOffset": 140}, {"referenceID": 4, "context": "We want to extend the results obtained in [5,8] using the theory of Markov chains.", "startOffset": 42, "endOffset": 47}, {"referenceID": 7, "context": "We want to extend the results obtained in [5,8] using the theory of Markov chains.", "startOffset": 42, "endOffset": 47}, {"referenceID": 11, "context": "Such distributions have been recently considered in the Estimation of Distribution Algorithms [12,13], continuing the trend of using copulas in that kind of evolutionary optimization algorithms [14].", "startOffset": 94, "endOffset": 101}, {"referenceID": 12, "context": "Such distributions have been recently considered in the Estimation of Distribution Algorithms [12,13], continuing the trend of using copulas in that kind of evolutionary optimization algorithms [14].", "startOffset": 194, "endOffset": 198}, {"referenceID": 4, "context": "Following [5,6,11,8] we define \u03b4t as \u03b4t := \u2212 g(Xt) \u03c3t .", "startOffset": 10, "endOffset": 20}, {"referenceID": 5, "context": "Following [5,6,11,8] we define \u03b4t as \u03b4t := \u2212 g(Xt) \u03c3t .", "startOffset": 10, "endOffset": 20}, {"referenceID": 10, "context": "Following [5,6,11,8] we define \u03b4t as \u03b4t := \u2212 g(Xt) \u03c3t .", "startOffset": 10, "endOffset": 20}, {"referenceID": 7, "context": "Following [5,6,11,8] we define \u03b4t as \u03b4t := \u2212 g(Xt) \u03c3t .", "startOffset": 10, "endOffset": 20}, {"referenceID": 0, "context": "n]) \u2208 R+ \u00d7 [0, 1] 7\u2192 Q \uf8eb", "startOffset": 11, "endOffset": 17}, {"referenceID": 0, "context": "\u03bb]) \u2208 R+ \u00d7 [0, 1] 7\u2192 argmax G\u2208{G(\u03b4,vi)|i\u2208[1.", "startOffset": 11, "endOffset": 17}, {"referenceID": 13, "context": "We may now use these results to show the divergence of the algorithm when the step-size is constant, using the theory of Markov chains [15].", "startOffset": 135, "endOffset": 139}, {"referenceID": 7, "context": "Following the first part of [8], we restrict our attention to the constant step size in the remainder of the paper, that is for all t \u2208 N we take \u03c3t = \u03c3 \u2208 R+.", "startOffset": 28, "endOffset": 31}, {"referenceID": 7, "context": "We now show ergodicity of the Markov chain (\u03b4t)t\u2208N, which implies that the t-steps transition kernel (the function A 7\u2192 Pr(\u03b4t \u2208 A|\u03b40 = \u03b4) for A \u2208 B(R+)) converges towards a stationary measure \u03c0, generalizing Propositions 3 and 4 of [8].", "startOffset": 232, "endOffset": 235}, {"referenceID": 13, "context": "We want to show a drift condition (see [15]) on V .", "startOffset": 39, "endOffset": 43}, {"referenceID": 13, "context": "8 of [15], the Markov chain (\u03b4t)t\u2208N is Harris recurrent.", "startOffset": 5, "endOffset": 9}, {"referenceID": 13, "context": "1 of [15] the Markov chain (\u03b4t)t\u2208N is positive and is r1-ergodic.", "startOffset": 5, "endOffset": 9}, {"referenceID": 13, "context": "We now want to show a drift condition (see [15]) on V\u03b1.", "startOffset": 43, "endOffset": 47}, {"referenceID": 13, "context": "1 of [15] which with Theorem 14.", "startOffset": 5, "endOffset": 9}, {"referenceID": 13, "context": "1 of [15] proves that the Markov chain (\u03b4t)t\u2208N is V\u03b1-geometrically ergodic.", "startOffset": 5, "endOffset": 9}, {"referenceID": 13, "context": "\u2293\u2294 We now use a law of large numbers ([15] Theorem 17.", "startOffset": 38, "endOffset": 42}, {"referenceID": 13, "context": "1 of [15], we may apply a law of large numbers on the right hand side of Eq.", "startOffset": 5, "endOffset": 9}, {"referenceID": 13, "context": "1 of [15].", "startOffset": 5, "endOffset": 9}, {"referenceID": 0, "context": ", copulas defined (\u2200u \u2208 [0, 1]) C\u03c8(u) = \u03c8(\u03c8([u]1) + \u00b7 \u00b7 \u00b7+ \u03c8([u]n)), (20) where \u03c8 : [0,+\u221e] \u2192 [0, 1] is an Archimedean generator, i.", "startOffset": 24, "endOffset": 30}, {"referenceID": 0, "context": ", copulas defined (\u2200u \u2208 [0, 1]) C\u03c8(u) = \u03c8(\u03c8([u]1) + \u00b7 \u00b7 \u00b7+ \u03c8([u]n)), (20) where \u03c8 : [0,+\u221e] \u2192 [0, 1] is an Archimedean generator, i.", "startOffset": 93, "endOffset": 99}, {"referenceID": 0, "context": ", \u03c8(0) = 1, \u03c8(+\u221e) = limt\u2192+\u221e \u03c8(t) = 0, \u03c8 is continuous and strictly decreasing on [0, inf{t : \u03c8(t) = 0}), and \u03c8 denotes the generalized inverse of \u03c8, (\u2200u \u2208 [0, 1]) \u03c8(u) = inf{t \u2208 [0,+\u221e] : \u03c8(t) = u}.", "startOffset": 155, "endOffset": 161}, {"referenceID": 0, "context": ", (\u2200u \u2208 [0, 1]) C\u03c8(Qu) = C\u03c8(u).", "startOffset": 8, "endOffset": 14}, {"referenceID": 7, "context": "The paper presents a generalization of recent results of the first author [8] concerning linear optimization by a (1, \u03bb)-ES in the constant step size case.", "startOffset": 74, "endOffset": 77}, {"referenceID": 12, "context": "small contribution to the research into applicability of copulas in evolutionary computation, complementing the more common application of copulas to the Estimation of Distribution Algorithms [12,14,13].", "startOffset": 192, "endOffset": 202}, {"referenceID": 11, "context": "small contribution to the research into applicability of copulas in evolutionary computation, complementing the more common application of copulas to the Estimation of Distribution Algorithms [12,14,13].", "startOffset": 192, "endOffset": 202}, {"referenceID": 7, "context": "The most important results in [8] actually concern that case.", "startOffset": 30, "endOffset": 33}, {"referenceID": 8, "context": "A generalization of those results for non-Gaussian distributions of random steps for cumulative step-size adaptation ([9]) is especially difficult as the evolution path is tailored for Gaussian steps, and some careful tweaking would have to be applied.", "startOffset": 118, "endOffset": 121}, {"referenceID": 14, "context": "The \u03c3 self-adaptation evolution strategy ([16]), studied in [6] for the same problem, appears easier, and would be our direction for future research.", "startOffset": 42, "endOffset": 46}, {"referenceID": 5, "context": "The \u03c3 self-adaptation evolution strategy ([16]), studied in [6] for the same problem, appears easier, and would be our direction for future research.", "startOffset": 60, "endOffset": 63}], "year": 2014, "abstractText": "Several recent publications investigated Markov-chain modelling of linear optimization by a (1, \u03bb)-ES, considering both unconstrained and linearly constrained optimization, and both constant and varying step size. All of them assume normality of the involved random steps, and while this is consistent with a black-box scenario, information on the function to be optimized (e.g. separability) may be exploited by the use of another distribution. The objective of our contribution is to complement previous studies realized with normal steps, and to give sufficient conditions on the distribution of the random steps for the success of a constant step-size (1, \u03bb)-ES on the simple problem of a linear function with a linear constraint. The decomposition of a multidimensional distribution into its marginals and the copula combining them is applied to the new distributional assumptions, particular attention being paid to distributions with Archimedean copulas.", "creator": "LaTeX with hyperref package"}}}