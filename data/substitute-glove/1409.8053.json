{"id": "1409.8053", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Sep-2014", "title": "Medical diagnosis as pattern recognition in a framework of information compression by multiple alignment, unification and search", "abstract": "This paper analysis a portrays approach leave medical undergone its put the SP discourse of simulation they cognition. The this landmarks of meant view are: a interactive but representing diagnosing that is simple addition unorthodox; an ability up cope they errors they underlying in anatomical information; the qualities of storing multivariate providing as measurements included adverse one diseases; new method a satisfactory alternative placement inferences that dividends truth pre-test; and is framework that think involve chaperoning learning include medical expertise much the integration of medical doctors while each AI applications.", "histories": [["v1", "Mon, 29 Sep 2014 10:11:31 GMT  (52kb,D)", "http://arxiv.org/abs/1409.8053v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["j gerard wolff"], "accepted": false, "id": "1409.8053"}, "pdf": {"name": "1409.8053.pdf", "metadata": {"source": "CRF", "title": "Medical diagnosis as pattern recognition in a framework of information compression by multiple alignment, unification and search", "authors": ["J Gerard Wolff"], "emails": ["jgw@cognitionresearch.org;"], "sections": [{"heading": null, "text": "Keywords: medical diagnosis, information compression, multiple alignment, SP theory, pattern recognition, causal reasoning."}, {"heading": "1 Introduction", "text": "The problem of providing computational support for medical diagnosis has been approached from many directions including logical reasoning, fuzzy logic, set theory, rough set theory, if-then rules, Bayesian networks, classical parametric and non-parametric statistics, artificial neural networks, case-based reasoning, support vector machines, perceptrons, possibility theory, and more, as well as various aggregations or combinations of methods [1].\nThis paper describes a novel approach to diagnosis based on the SP theory of computing and cognition (described below). The main attractions of this approach are:\n\u2022 A format for representing diseases that is simple and intuitive.\n\u2022 An ability to cope with errors and uncertainties in diagnostic information. \u2217Dr Gerry Wolff, BA (Cantab), PhD (Wales), CEng, MBCS (CITP); CognitionResearch.org, Menai Bridge, UK; jgw@cognitionresearch.org; +44 (0) 1248 712962; +44 (0) 7746 290775; Skype: gerry.wolff; Web: www.cognitionresearch.org.\nar X\niv :1\n40 9.\n80 53\nv1 [\ncs .A\nI] 2\n9 Se\n\u2022 The simplicity of storing statistical information as frequencies rather than conditional probabilities.\n\u2022 A method for evaluating alternative diagnostic hypotheses that yields true probabilities.\n\u2022 A framework that should facilitate unsupervised learning of medical knowledge and the integration of medical diagnosis with other AI applications.\nIt must be stressed that the primary purpose of this paper is conceptual: to describe an approach to medical diagnosis that is significantly different from the main alternatives and with potential advantages compared with those alternatives. Although a prototype of the proposed new system exists, it is not yet a shrink-wrapped software system that is ready for immediate application. Like any other diagnostic system, the SP system must be equipped with a body of relevant knowledge and the creation of such a body of knowledge (by automatic learning or by \u2018knowledge elicitation\u2019 from experts) is a major undertaking in its own right.\nKey elements of the SP theory are first described, just sufficient for present purposes. Section 3 describes how the theory may be applied to medical diagnosis, viewed as a process of pattern recognition. This section also discusses how the SP system relates to several aspects of the diagnostic process, including causal reasoning and the process of acquiring the knowledge that is needed for accurate diagnosis. Section 4 compares this new approach to medical diagnosis with some of the alternatives. The paper concludes with an outline of what still needs to be done in this programme of research and with a review of the main points that have been made."}, {"heading": "2 The SP theory", "text": "The SP theory grew out of a long tradition in psychology that many aspects of brain function may be understood as information compression (see, for example, [2, 3, 4, 5]). It is based on principles of minimum length encoding1 pioneered by Solomonoff [6], Wallace and Boulton [7], Rissanen [8] and others (see also [9]). An overview of the theory is presented in [10] and more detail may be found in other papers cited there (see also [11]).\nThe SP theory has been developed as an abstract model of any system for processing information, either natural or artificial. In broad terms, the system receives \u2018New\u2019 information from its environment and transfers it to a repository of \u2018Old\u2019 information. At the same time, it tries to compress the information as much as possible by finding patterns that match each other and merging or \u2018unifying\u2019 patterns that are the same.2 An important part of this process is the\n1An umbrella term for \u2018minimum message length encoding\u2019 and \u2018minimum description length encoding\u2019.\n2The term \u2018unification\u2019 in the SP theory means a simple merging of two or more identical patterns to make one. This meaning is different from but related to the meaning of the term in logic.\nbuilding of \u2018multiple alignments\u2019 as described below. The SP framework is Turing-equivalent in the sense that it can model a universal Turing machine [12] but it has much more to say about the nature of \u2018intelligence\u2019 than the Turing model of computing (or equivalent models such as lamda calculus [13] or the Post canonical system [14]).\nTo date, the main areas in which the SP framework has been applied are probabilistic reasoning, pattern recognition and information retrieval [15], parsing and production of natural language [16], modelling concepts in logic and mathematics [17], and unsupervised learning [18, 19]."}, {"heading": "2.1 Computer models", "text": "Two computer models of the SP system have been developed:\n\u2022 SP62 is a partial realisation of the theory that does not transfer any information from New to Old. This model tries to compress the New information in terms of the Old information by building multiple alignments of the kind that will be seen below. SP62 also contains procedures for calculating the probabilities of inferences that may be drawn from alignments. A slightly earlier version of this model (SP61) is described quite fully in [16]. Both versions are relatively robust and mature.\n\u2022 SP70 realises all the main elements of the theory, including the transfer of information from New to Old. In addition to building multiple alignments like SP62, the model compiles one or more alternative \u2018grammars\u2019 for the information in New, using principles of minimum length encoding. This model, and its application to unsupervised learning, is described quite fully in [18, 19]. More work is required to realise the full potential of this model."}, {"heading": "2.2 Representation of knowledge", "text": "In the SP system, all kinds of knowledge are stored as arrays of atomic symbols in one or two dimensions called patterns. In work to date, the main focus has been on one-dimensional patterns (i.e., sequences of symbols) but it is envisaged that, at some stage, the concepts will be generalised to patterns in two dimensions.\nFor present purposes, we may define patterns and symbols as follows:\n\u2022 A pattern is a sequence of symbols bounded by end-of-pattern characters such as \u2018(\u2019 and \u2018)\u2019, not shown in the examples in this paper.\n\u2022 A symbol is a string of non-space characters bounded by white space (space characters, line-feed characters and the like).\n\u2022 Any symbol can be matched with any other symbol and, for any one pair of symbols, the two symbols are either \u2018the same\u2019 or \u2018different\u2019. No other result is permitted.\n\u2022 Symbols have no intrinsic meaning such as \u2018add\u2019 for the symbol \u2018+\u2019 in arithmetic or \u2018multiply\u2019 for the symbol \u2018\u00d7\u2019. Any meaning attaching to an SP symbol takes the form of one or more other symbols with which it is associated in a given set of patterns.\n\u2022 Each pattern has an associated integer value representing the absolute or relative frequency of occurrence of that pattern in some domain.\nDespite the extraordinary simplicity of this format for representing knowledge, the way in which SP patterns are processed within the system means that they can model a wide variety of established representational schemes, including context-free and context-sensitive grammars, class-inclusion hierarchies, part-whole hierarchies, discrimination networks and trees, if-then rules, and others."}, {"heading": "2.3 Processing knowledge", "text": "A key part of the process of matching patterns is the building of \u2018multiple alignments\u2019, described and illustrated here. The process of building multiple alignments in the SP system provides a unified model for a variety of computational effects including fuzzy pattern recognition, best-match information retrieval, probabilistic and exact styles of reasoning, unsupervised learning, planning, problem solving and others, as described in [10]."}, {"heading": "2.3.1 Multiple alignments", "text": "This subsection and the ones that follow describe the main elements of the multiple alignment concept as it has been developed in the SP theory and explains how multiple alignments are created and evaluated in the SP system.\nIn bioinformatics, a multiple alignment is an arrangement of two or more DNA sequences or sequences of amino acid residues so that matching symbols are aligned. Fig. 1 shows a typical example. The general idea is that, by judicious \u2018stretching\u2019 of sequences, as many symbols as possible are aligned with each other. A variety of measures of the \u2018goodness\u2019 of alignments are used but they all tend to favour alignments where the number of aligned symbols is high and the gaps between them are relatively few and relatively small.\nIn the SP framework, the concept of multiple alignment has been modified as follows:\n\u2022 One or more of the sequences (termed patterns, as described in Section 2.2) are classified as \u2018New\u2019 and the rest are \u2018Old\u2019.\n\u2022 A \u2018good\u2019 alignment is one where the New patterns can be encoded economically in terms of the Old patterns in the alignment, as will be explained.\n\u2022 Any one pattern may appear more than once in one alignment, not as two or more copies but as two or more appearances of a single pattern. This has implications for the way alignments are formed and for the representation\nof recursive structures. These aspects of the multiple alignment concept are not relevant to the main proposals here and will not be considered further in this paper. Readers who wish to know more may consult the sources cited earlier.\nNormally, the SP62 model is run with relatively few New patterns and a relatively large \u2018database\u2019 or \u2018dictionary\u2019 of Old patterns. The system typically forms a set of alternative alignments, each one of which represents a possible encoding of the New pattern or patterns in terms of one or more of the Old patterns.\nFig. 2 shows a simple example, with one New pattern (in row 0, representing a badly-spelled version of the word \u2018experimentation\u2019) and one Old pattern (in row 1, representing the correctly-spelled version of the word).3 This is the best alignment produced by SP62 with the New pattern as shown and a dictionary of Old patterns, each one of which represents one word in its correctly-spelled form.\nFig. 3 is a slightly more complicated example, the best alignment produced by SP62 when it is supplied with one New pattern (\u2018j o h n r u n s\u2019) and a set of Old patterns, each one of which represents a grammatical rule. This alignment shows how the sentence \u2018j o h n r u n s\u2019 (in row 0) may be analysed (\u2018parsed\u2019)\n3By convention, the New pattern or patterns are always shown in row 0 of alignments like those shown in Figs. 2 and 3, and the Old patterns are shown in the other rows, one pattern per row and in an order that is entirely arbitrary, without special significance. As we shall see, alignments can sometimes fit better on the page if they are rotated by 90\u25e6 and in this case the New pattern or patterns are shown in column 0 with the Old patterns in the other columns, one pattern per column.\ninto its parts. The Old patterns in rows 1 to 3 represent grammatical rules: \u2018< S < N > < V > >\u2019 in row 3 means that a (simple) sentence is composed of a noun (\u2018N\u2019) followed by a verb (\u2018V\u2019), \u2018< N 0 j o h n >\u2019 in row 2 means that \u2018j o h n\u2019 is a noun, and \u2018< V 1 r u n s >\u2019 in row 1 means that \u2018r u n s\u2019 is a verb."}, {"heading": "2.3.2 Evaluation of alignments", "text": "As previously mentioned, a \u2018good\u2019 multiple alignment is one where the New pattern or patterns can be encoded economically in terms of the Old patterns in the alignment. How is this evaluation done?\nEvery symbol has an associated \u2018weight\u2019 which is the number of bits needed to encode that symbol. And the weight is derived from the frequency of occurrence of the symbol using the Shannon-Fano-Elias method (see [20]) (a method that is similar to the well-known Huffman method). The frequency value for any symbol is derived from the frequency value of the pattern (or patterns) in which that symbol appears (as described in Section 2.2). In the context of medical diagnoses, the frequency associated with any given pattern is the frequency of occurrence of the disease that is represented by that pattern (see Section 3.1, below).\nA few of the symbols (normally one or two) near the beginning of each Old pattern are classified as identification symbols or \u2018ID-symbols\u2019. For example, the ID-symbol in the pattern \u2018< E3 e x p e r i m e n t a t i o n >\u2019 in Fig. 2 is \u2018E3\u2019, and the ID-symbols in the pattern \u2018< N 0 j o h n >\u2019 in Fig. 3 are \u2018N\u2019 and \u20180\u2019.\nA \u2018code\u2019 for any alignment may be derived quite simply by scanning the alignment from left to right looking for columns in the alignment that contain one code symbol, not matched with any other identical symbol. The code for the alignment is the sequence of symbols that have been found, in the given order. For example, the code derived in this way from the alignment in Fig. 2 is \u2018E3\u2019 and the code derived from the alignment in Fig. 3 is \u2018S 0 1\u2019.\nThe next step in the evaluation of a given alignment is the calculation of a \u2018compression score\u2019 or \u2018compression difference\u2019 as:\nCD = Bn \u2212Be, (1)\nwhere Bn is the total size (in bits) of those symbols within the New pattern that have been matched to Old symbols within the alignment, and Be is the total size (in bits) of the symbols in the code that has been derived as just explained. Adjustments to this score are made to take account of gaps in the alignment like those that may be seen in Fig. 2. The details of these calculations and adjustments are explained in [16]."}, {"heading": "2.3.3 The building of multiple alignments", "text": "In bioinformatics, it is generally understood that the abstract \u2018space\u2019 of alternative possible alignments between two or more sequences is, with few exceptions, astronomically large\u2014which means that it cannot be searched exhaustively. All practical methods for finding \u2018good\u2019 alignments amongst two or more sequences use heuristic methods such as \u2018hill climbing (or \u2018descent\u2019), \u2018beam search\u2019, \u2018genetic algorithms\u2019 or the like that search selectively and exclude large parts of the search space. With methods like these, one can find good approximate solutions in a reasonable time but one can never be sure of finding the best possible solution (unless the sequences are very short and very few). Finding good multiple alignments in the SP system is no different.\nAt the heart of the SP system for building multiple alignments is an improved version of \u2018dynamic programming\u2019 for finding full matches and good partial matches between two patterns (see, for example, [21]). Unlike standard versions of dynamic programming, the procedure used in the SP models:\n\u2022 Can find good matches between patterns without restrictions on the lengths of the patterns.\n\u2022 Can normally find several alternative alignments between two patterns, not just one.\n\u2022 It allows the \u2018depth\u2019 or thoroughness of searching to be varied according to need.\nGiven one New pattern and a database of Old patterns, SP62 first builds a set of alignments, each one of which is between the New pattern and one of the Old patterns. From this set, it selects the best few alignments, using the measure described in Section 2.3.2. Each of these alignments can itself be treated as if it was a single pattern. So, in the next stage, SP62 builds larger alignments, each one of which is between one of the selected alignments and one of the Old patterns or between one of the selected alignments and another of those alignments. As before, the program selects the best of the alignments that have been formed.\nThe process is repeated in this way until no more alignments can be found. The process for building alignments containing two or more New patterns is a generalisation of what has been described here."}, {"heading": "2.3.4 Unsupervised learning", "text": "At its most abstract level (Section 2), the SP model is conceived as a system that learns by transferring New information to its repository of Old information and compressing it at the same time. This abstract conception has now been realised more concretely in the form of the SP70 computer model [18, 19] that is capable of learning simple grammars from raw data. However, further development of the model is needed to realise its full potential.\nThe current model has two stages:\n1. From partial alignments between patterns, the model creates new patterns that are added to the repository of Old patterns as explained below.\n2. Amongst the patterns that are generated in this way, some are \u2018good\u2019 in terms the principles of minimum length encoding and others are \u2018bad\u2019. In the second stage of processing, the model measures the frequency with which each pattern may be recognised in the raw data and then it uses this information in a hill-climbing search amongst subsets of the Old patterns to find one or more sets of patterns that are good in terms of the principles of minimum length encoding. The remaining patterns may be discarded.\nIt is envisaged that, when the model is more fully developed, these two stages will be repeated so that the system can progressively bootstrap a set of patterns that are good in terms of the principles of minimum length encoding, and thus represent a distillation of the patterns of redundancy in the original data.\nSP70 is currently targeted at the learning of syntax in natural languages. Given a partial alignment like this:\n0 t h e g i r l r u n s 0\n| | | | | | |\n1 < %1 t h e b o y r u n s > 1\nthe program creates patterns like these:\n< %2 t h e > < %3 r u n s > < %4 0 b o y > < %4 1 g i r l > < %5 < %2 > < %4 > < %3 > >\nThe first four are derived from coherent sequences of matched symbols and coherent sequences of unmatched symbols in the alignment and they correspond to what we would normally recognise as words. Each one has a grammatical category represented by ID-symbols such as \u2018%2\u2019, \u2018%3\u2019 and \u2018%4\u2019. Notice that \u2018b o y\u2019 and \u2018g i r l\u2019 belong to the same disjunctive category {\u2018b o y\u2019, \u2018g i r l\u2019} because they are alternatives at the same point in the original alignment and they both share the ID-symbol \u2018%4\u2019. The ID-symbols \u20180\u2019 and \u20181\u2019 serve to distinguish the two alternatives in that category.\nThe last pattern in this example ties everything together by listing the sequence of categories in the original alignment. It is an \u2018abstract\u2019 pattern describing the overall structure of the two original sentences.\nFor an application like medical diagnosis, the style of learning just described is probably not entirely appropriate. Section 3.11.2 describes how similar principles may be applied to medical data. If the potential of these ideas can be realised, the SP system should facilitate the automatic or semi-automatic construction of knowledge bases from raw medical data."}, {"heading": "2.3.5 Computational complexity", "text": "The time complexity of the SP62 model in a serial processing environment is approximately O(log2n\u00d7nm), where n is the size of the New pattern or patterns (in bits) and m is the total size of the patterns in Old (in bits). In a parallel processing environment, the time complexity may approach O(log2 n \u00d7 n), depending on how well the parallel processing is applied. The space complexity in serial or parallel environments is O(m). Further details may be found in [16].\nIn medical diagnosis, it seems reasonable to suppose that there will normally be a fairly small maximum for the number of signs and symptoms (abbreviated hereinafter as \u2018symptoms\u2019) exhibited by any one patient. Correspondingly, there should be a maximum size for the size of the set of New patterns that are used to represent the patient\u2019s symptoms. If we take this to be a constant value for n, then in a serial processing environment the time complexity is approximately O(m) and in a parallel processing environment it may approach O(1)."}, {"heading": "3 Application of the SP system to medical di-", "text": "agnosis\nTo a large extent, medical diagnosis may be viewed as a problem of (fuzzy) pattern recognition: finding the best fit between a given set of symptoms for an individual patient and the symptoms associated with one or more diseases. However, causal reasoning also has a part to play when, for example, it is understood that a given disease is caused by a bacterial or virus infection.\nThis section presents an example showing how the SP system may be applied to medical diagnosis, viewed as a process of pattern recognition. The system may also support causal reasoning about medical problems and this is discussed briefly in Section 3.9, below.\nOther aspects of the proposals are discussed in other subsections."}, {"heading": "3.1 Describing diseases using SP patterns", "text": "In the SP scheme, knowledge about diseases may be stored as patterns in a repository of Old information, and the symptoms for an individual patient may be represented as a set of one or more New patterns.\nA pattern in the store of Old information may represent one disease and its associated symptoms, or a combination of diseases (see Section 3.7.2, below), or it may represent a cluster of symptoms that tend to occur together in two or more different diseases (see Section 3.5, below). In addition, Old may include patterns that play supporting ro\u0302les (see Section 3.6, below).\nThe frequency value of each pattern may be used to represent the absolute or relative frequency with which a given disease or cluster of symptoms is found in a given population. These figures may be derived from epidemiological surveys or they may be estimated by medical experts.\nBy way of illustration, Fig. 4 shows five examples of such patterns, one describing the symptoms of chicken pox, another describing the symptoms of smallpox, the third describing the cluster of symptoms which is described as \u2018fever\u2019 and two more describing the class of \u2018high\u2019 temperatures (38\u201339oC and 40+oC). The number in brackets after each pattern is a very rough estimate of the relative frequencies of occurrence of the corresponding disease or condition.4\nEach of the first three patterns begins and ends with a pair of symbols \u2018<disease> ... </disease>\u2019 which indicate that the pattern describes a disease or a cluster of disease symptoms. Within each pattern, there are similar pairs of symbols, each one marking the beginning and end of a \u2018field\u2019 which describes some aspect of the disease or cluster. For example, \u2018<dname> Chicken Pox </dname>\u2019 provides the name of the chicken pox disease, \u2018<skin> rash </skin>\u2019 describes one of its symptoms, \u2018<causative agent> chicken pox virus </causative agent>\u2019 describes what causes the disease, and \u2018<treatment> chicken pox treatment </treatment>\u2019 is a remarkably unhelpful description of how to treat the disease which would, of course, be much more detailed in a fully developed knowledge base.\nWithin the pattern for chicken pox, the field \u2018<R2> fever </R2>\u2019 indicates that \u2018fever\u2019 is one of the symptoms of the disease. However, by contrast with other fields like those just mentioned, the symbol \u2018fever\u2019 is, in effect, a reference or pointer to a cluster of symptoms such as rapid breathing, flushed face and high temperature described in the third pattern in the same figure. In a similar way, \u2018<R1> flu symptoms </R1>\u2019 in the pattern for smallpox is a reference or pointer to another pattern, not shown in the figure, that describes a cluster of symptoms associated with influenza and flu-like diseases. The way in which pointers like these are dereferenced in the SP system will be seen in the next section.\nReaders who are familiar with XML [22] will notice that pairs of symbols like \u2018<disease> ... </disease>\u2019 or \u2018<dname> ... </dname>\u2019 are rather like the start and end tags used to mark the elements of an XML document. However, by contrast with XML and related languages such as HTML, symbols of that kind have no formal status in the SP system and the styles of symbols are not defined within the system. Any convenient style may be used such as \u2018disease ... #disease\u2019 or \u2018disease ... %disease\u2019 and in some applications it is not necessary\n4The figure for smallpox is clearly too high in the world today but it will serve for the purpose of illustration.\nto provide any distinctive markers for the beginnings and ends of patterns or fields. The concept of \u2018field\u2019 has no formal status in the SP system either."}, {"heading": "3.2 Multiple alignment and medical diagnosis", "text": "The process of diagnosis may be modelled by the building of one or more multiple alignments. Fig. 6 shows the best alignment created by SP62 with a set of New patterns shown in Fig. 5 that describe \u2018John Smith\u2019 and his symptoms and a set of Old patterns like those shown in Fig. 4 that represent diseases or aspects of diseases.5\nAn alignment like this may be interpreted as the result of a process of recognition. In this case, the symptoms that have been recognised are those of influenza, as shown in column 2. The following subsections discuss aspects of the alignment and of this interpretation."}, {"heading": "3.3 A \u2018framework\u2019 pattern", "text": "In an application like this, it is convenient but not essential to include amongst the Old patterns a \u2018framework\u2019 pattern like the one shown in column 1. This is a generalised pattern for diseases of all kinds that lists the main categories associated with diseases such as \u2018<dname> </dname>\u2019 (the name of the disease), \u2018<breathing> </breathing>\u2019 (the state of the patient\u2019s breathing) and \u2018<temperature> </temperature>\u2019 (the patient\u2019s temperature), but it does not specify specific values for any category.\nThis framework pattern serves as an anchor point for symbols in other patterns and facilitates the formation of multiple alignments in accordance with the rules described in [10] and earlier publications.\n5Compared with the alignments shown in Figs. 2 and 3, the alignment in Fig. 6 has been rotated by 90o to allow the alignment to fit better on the page. As previously noted, the New patterns are shown in column 0 and the Old patterns are shown in the other columns, one pattern per column in an order that is arbitrary and without special significance."}, {"heading": "3.4 The ordering of descriptors", "text": "In an application like medical diagnosis, it is not obvious that there is any intrinsic order to the symptoms of a disease or associated descriptors such as the name of the patient. In describing a patient\u2019s symptoms, it should make no difference whether \u2018high temperature\u2019 is mentioned before \u2018runny nose\u2019 or the other way round.\nIn the SP framework, each pattern that describes a disease or a cluster of symptoms necessarily imposes an order in which categories of descriptors are specified. However, users of the system may specify the patient\u2019s symptoms in any order that is convenient. This is because symptoms are described using a set of New patterns and there is no intrinsic order amongst the New patterns supplied to the system. In our example, New patterns were supplied to the SP62 model in the order shown in Fig. 5 but in the alignment shown in Fig. 6 they appear in a completely different order.\nNotice that this freedom in the ordering of descriptors only applies to whole patterns. When two or more symbols in one pattern are matched to two or more symbols in another, the order of the symbols in one pattern must be the same as the order of the matching symbols in the other pattern."}, {"heading": "3.5 Dereferencing of pointers", "text": "As already noted, a symbol like \u2018fever\u2019 or \u2018flu symptoms\u2019 in one pattern may serve as a reference or pointer to another pattern that describes a cluster of symptoms that may be found in two or more different diseases.\nIn Fig. 6, we can see how such pointers are \u2018de-referenced\u2019 in the SP system. The symbol \u2018flu symptoms\u2019 in column 2 is matched to the same symbol in column 3 where flu-like symptoms are listed. Likewise, the symbol \u2018fever\u2019 in column 3 is matched to the same symbol in column 4 where the symptoms of fever or listed. Fever is itself part of the cluster of flu-like symptoms.\nThe provision of named clusters like these saves the need to specify the corresponding symptoms redundantly in each of the diseases where such clusters appear."}, {"heading": "3.6 Uncertainties in diagnosis", "text": "Diagnosis is not an exact process:\n\u2022 Most diseases are \u2018family resemblance\u2019 or \u2018polythetic\u2019 concepts because the majority of symptoms associated with any given disease are neither necessary nor sufficient for the diagnosis of the disease: they are \u2018characteristic\u2019 of the disease in the sense that any one such symptom need not be present in every case and any of them may be associated with other diseases.\n\u2022 There may be and frequently are errors in the observation or recording of symptoms.\nSP62 can accommodate these kinds of uncertainty in diagnosis in two distinct ways:\n\u2022 Because it looks for a global best match amongst patterns, it does not depend on the presence or absence of any particular symptom. Notice how SP62 has succeeded in constructing the alignment shown in Fig. 6 despite there being no match for \u2018poor\u2019 in the New pattern \u2018<appetite> poor </appetite>\u2019 and \u2018yes\u2019 in the New pattern \u2018<fatigue> yes </fatigue>\u2019 and no match for many of the symbols in the Old patterns.\nAlthough the system does not depend on the presence or absence of any one symptom, particular symptoms can have a major impact on diagnosis, as described in Section 3.7.1, below.\n\u2022 Within the SP framework, it is not necessary for every symptom of a disease to be recorded as a specific value. For example, in column 4 of the alignment in Fig. 6, the pair of symbols \u2018<t1> </t1>\u2019 represents a set of alternative values for the temperature associated with fever. In this case, there are just two values, represented in Old by the patterns \u2018<t1> 38-39 </t1>\u2019 (high temperature) and \u2018<t1> 40+ </t1>\u2019 (very high temperature), as shown at the bottom of Fig. 4. The first of these patterns is shown in column 5 of the alignment, matched to the temperature of the patient shown in column 0.\nBeing able to specify symptoms as sets of alternative values allows the system to accommodate the kind of variability which is so prominent in many diseases."}, {"heading": "3.7 Weighing alternative hypotheses and the calculation of probabilities", "text": "In medical diagnosis, it is quite usual for the physician to consider alternative hypotheses about what disease or diseases the patient may be suffering from. The SP framework provides a model for this process in the way the system builds alternative alignments for any given pattern or set of patterns in New. Alignments\u2014and the corresponding diagnoses\u2014may be evaluated as follows.\nAs previously noted (Section 2.3.2), a \u2018compression difference\u2019 is calculated for each alignment as shown in Equation 1. The value Be that is used in that equation may be translated into an absolute probability for the given alignment:\nP = 2\u2212Be . (2)\nFor any one alignment (the jth alignment) in a set of alternative alignments, a1...an, that encode the same symbols from New, a relative probability may be calculated as:\npj = Pj/ i=n\u2211 i=1 Pi. (3)\nA fuller account of the way probabilities are calculated may be found in [15]. Given that the New patterns represent the symptoms of one patient at a particular time and given that each pattern in Old describes a single disease or a single cluster of symptoms that may form part of the description of one or more diseases, then each alignment formed by SP62 represents an hypothesis about any one disease that the patient may have.\nWhere alternative alignments encode different subsets of the symbols in New, it is possible that the patient may be suffering from two or more diseases at the same time. This possibility is discussed in Section 3.7.2, below. However, where two or more of the best alignments encode exactly the same symbols from New, then they represent alternative diagnostic hypotheses and they may be compared using values for relative probability (p).\nWhen SP62 formed the alignment shown in Fig. 6, it also formed a similar alignment, matching exactly the same symbols in New, in which column 2 contained a pattern representing the symptoms of smallpox, instead of the pattern for influenza. The relative probability values calculated in this case were 0.99950 for influenza and 0.00049 for smallpox, reflecting the prevalence of those two diseases in the world today.6"}, {"heading": "3.7.1 \u2018Explaining away\u2019", "text": "The symptoms of influenza and smallpox are quite similar, except for the very distinctive rash and blisters that occur in smallpox. The example shown in Fig. 6 is silent about whether John Smith had a rash and blisters or not. If a rash and blisters had been seen to be absent, this would have been represented as \u2018<skin> normal </skin>\u2019. Given this lack of information about the state of the patient\u2019s skin, he may have either influenza or smallpox but he is very much more likely to have the former than the latter, as indicated by the calculated probabilities.\nIf \u2018<skin> rash with blisters </skin>\u2019 is added to the symptoms recorded in New, and if SP62 is run again with the augmented set of symptoms, the best alignment found by the system is similar to that shown in Fig. 6 but with the pattern for smallpox (the second pattern in Fig. 4) instead of the pattern for influenza in column 2 and with a match shown between \u2018<skin> rash with blisters </skin>\u2019 in the set of New patterns and the same symbols in the pattern that describes smallpox. However, in this case there is no other alignment that matches the same symbols in New. Consequently, the relative probability of the best alignment is 1.0. In short, the addition of one distinctive symptom to the list of symptoms has a dramatic effect on the relative probabilities calculated by the system. Instead of a vanishingly small probability for smallpox (0.00049), the system now assigns it a probability of 1.0, in accordance with our intuitions.\n6There are, of course, other factors that may be relevant\u2014such as the possibility that someone might release the smallpox virus deliberately\u2014but in this example, knowledge of such other factors has been excluded.\nFrom this result, we may conclude that the patient certainly has smallpox and that his aching muscles and runny nose are due to smallpox, not influenza. This is the phenomenon of \u2018explaining away\u2019: \u201cIf A implies B, C implies B, and B is true, then finding that C is true makes A less credible. In other words, finding a second explanation for an item of data makes the first explanation less credible.\u201d ([23, p. 7], with the emphasis as in the original)."}, {"heading": "3.7.2 A patient may suffer from two or more diseases at the same time", "text": "As noted above, it is possible for a patient to suffer from two or more diseases at the same time. Given that the Old patterns in the system describe single diseases, then the system would create two or more \u2018good\u2019 alignments, each one corresponding to one of the diseases that the patient is suffering from.\nIf we want the system to calculate probabilities for combinations of diseases, then the repository of Old patterns must contain patterns that represent combinations of that kind. Each such pattern may be constructed economically using references to the component diseases, in much the same way that clusters of symptoms may be referenced, as described in Section 3.5.\nAs with single diseases, frequency values for a combinations of diseases may be obtained from population surveys or by the judgement of medical experts. In the absence of any direct evidence of a statistical association between two or more diseases, it seems reasonable to assume that they are statistically independent. In such cases, frequency values may be derived straightforwardly via normalised values for the frequencies of occurrence of individual diseases. Whether the frequency values for combinations of diseases are measured, estimated or derived, they can be used for the calculation of CD values and probabilities in exactly the same way as for single diseases.\nOf course, there are so many possible combinations of diseases that it would be impossible to store information about them all. A more practical option may be to store information in Old about individual diseases and combinations of diseases that are known to have a statistical association with each other. One may assume that all other combinations of diseases are statistically independent."}, {"heading": "3.8 Inferences and the diagnostic cycle", "text": "In a multiple alignment like the one shown in Fig. 6, any symbol within an Old pattern that is not matched to a symbol in New represents an inference that may be drawn from the alignment. In this example, we may infer from the alignment inter alia that the patient is likely to have a cough and a headache and that the standard treatment for influenza is required. Probabilities of these inferences can be calculated as described in [15].\nIf a \u2018good\u2019 alignment makes a prediction about some marker that may be found in the patient\u2019s blood or something that may be observed in an X-ray, this may be interpreted as a suggestion to the physician that he or she should order an appropriate blood test or X-ray. If tests of that kind or other kinds\nof investigation are instigated as a result of the inferences drawn from preliminary alignments, the results of those investigations, together with the original symptoms, may be fed back into the system as New information. The system may then be run again and the alignments that are created may suggest a final diagnosis or the need for further investigation\u2014and so on."}, {"heading": "3.9 Causal reasoning", "text": "Apart from the kinds of inference just described, medical diagnosis often seems to involve a \u2018deeper\u2019 kind of reasoning about the causes of symptoms and diseases, using knowledge of bacteria, viruses, anatomy, physiology and so on.\nThe SP framework supports a variety of styles of reasoning, including probabilistic \u2018deductive\u2019 reasoning, abductive reasoning, nonmonotonic reasoning and (as we saw in Section 3.7.1) \u2018explaining away\u2019 (see [15]). So there are reasons to believe that, within the SP framework, it may be possible to extend the pattern recognition analysis described above to incorporate causal styles of reasoning.\nRecent investigation has confirmed this expectation. The input-output relations of each subsystem within a larger system can be modelled in the SP framework as a set of patterns, and causal connections can be established by matching outputs to inputs. As with the analysis described above, a \u2018framework\u2019 pattern is also needed to ensure that alignments can be formed in an appropriate manner. These potential applications of the system need further exploration and development."}, {"heading": "3.10 Classes and subclasses of diseases", "text": "One of the attractions of the SP system is that it allows concepts to be represented at multiple levels of abstraction (e.g., \u2018cat\u2019, \u2018mammal\u2019, \u2018vertebrate\u2019, \u2018animal\u2019) in the manner of object-oriented design and, via the building of multiple alignments, it allows a specific entity (such as \u201cmy cat Tibs\u201d) to be recognised at several different levels of abstraction [10, 15].\nTo some extent, this idea is already illustrated by the example shown in Fig. 6. The concept of \u2018fever\u2019, represented by the pattern in column 4 of the figure, may be seen as a superclass comprising all the diseases where the patient may be feverish. Likewise, the pattern for flu symptoms (column 3 in the figure) may be seen as a superclass of the diseases in which such symptoms may be seen.\nBy contrast with the classification of animals and plants, the hierarchy of diseases tends to be relatively flat. However, there is scope for the recognition of classes and subclasses in the variants of diseases such as influenza and diabetes. With the SP system, each variant of a given disease may be recorded as a pattern that specifies the symptoms that are characteristic of the variant. Provided that pattern contains a symbolic link to another pattern describing the main symptoms of the disease, there is no need to repeat those symptoms redundantly in each of the variants."}, {"heading": "3.11 Acquisition of knowledge", "text": "Broadly speaking, the knowledge that is required in any artificial system for medical diagnosis can be obtained \u2018manually\u2019 from experts or written sources, or it may be obtained by the automatic or semi-automatic abstraction of knowledge from raw medical data, or some combination of the two. The SP system has potential to facilitate any or all of these processes."}, {"heading": "3.11.1 Elicitation of expert knowledge", "text": "It should be apparent from the example described above that the SP system provides a means of representing medical knowledge in a form that is simple and intuitive. The simplicity of representing all knowledge as patterns is, perhaps, less important than the fact that this system allows computer-based knowledge to be expressed in a form that apparently reflects the natural structure of the original concepts.\nThis feature of the system should facilitate traditional kinds of knowledge elicitation from experts or written sources. Medical experts should have little difficulty in expressing their knowledge directly in the form of SP patterns. Given that such experts are often busy and their time is, in any case, expensive, there are advantages if at least some of the process of building computer-based knowledge bases can be undertaken by knowledge engineers without specialised medical training. It should be possible for such people to derive a good deal of the necessary knowledge from medical text books and other written sources."}, {"heading": "3.11.2 Automatic or semi-automatic learning", "text": "Section 2.3.4 presented an outline description of how the SP70 model learns the kinds of structures found in the syntax of natural languages. As was indicated in that section, that style of learning is probably not entirely appropriate for medical data but the same general principles should apply. This subsection describes in outline how the SP system may be applied to the learning of medical knowledge.\nThe simplest kind of \u2018learning\u2019 is simply to keep a record of the symptoms of each specific patient and the corresponding diagnosis. This is the principle of \u2018case-based learning\u2019 and, in conjunction with a system that kind find good partial matches between the description of a new patient and stored knowledge of old patients, it can be quite practical and useful in making new diagnoses. Since the SP system is capable of finding good partial matches between patterns, it could well be used in this way, as suggested in Section 4.5, below.\nHowever, medical practitioners normally recognise a degree of abstraction in medical knowledge as described in Section 3.10: a concept like \u2018fever\u2019 describes a cluster of symptoms that is found in two or more different diseases; diseases like influenza often come in several variants or subclasses; and symptoms may be described in terms of ranges rather than specific values as in our example of temperature (Section 3.6).\nAs an illustration of the way in which the SP system may create these kinds of abstraction, consider two imaginary patients with two different diseases and symptoms represented by the patterns \u2018X A B Y C D E Z F\u2019 and \u2018A P Q B C R D S E F T\u2019. With these two patterns, the SP system would create an alignment like this:\n0 X A B Y C D E Z F 0\n| | | | | |\n1 A P Q B C R D S E F T 1,\nand from the matched symbols in this alignment it may derive the pattern \u2018A B C D E F\u2019. With the addition of some appropriate ID-symbols, this pattern may serve like the pattern for \u2018fever\u2019 in Figs. 4 and 6: it represents a cluster of symptoms that appears in two or more different diseases. Alternatively, this pattern may represent the symptoms of a general class of diseases with two variants represented by the two original patterns, modified so that the shared cluster of symptoms are replaced by a pointer to the general class.\nWith regard to categories like the set of two alternative temperatures represented by the patterns \u2018<t1> 38-39 </t1>\u2019 and \u2018<t1> 40+ </t1>\u2019 in Fig. 4, the SP system may derive this kind of disjunctive category in much the same manner as the disjunctive class {\u2018b o y\u2019, \u2018g i r l\u2019} in the example in Section 2.3.4."}, {"heading": "3.12 Integration", "text": "The very simple format for representing knowledge described in Section 2.2 is intended to be as nearly \u2018universal\u2019 as possible in the sense that it is designed to represent a wide range of different kinds of knowledge. This should be much more nearly true when the concept of pattern has been generalised to two dimensions.\nIn a similar way, the concept of multiple alignment described in Section 2.3 is intended to be a \u2018universal\u2019 model for a wide range of different kinds of processing: pattern recognition, information retrieval, various kinds of reasoning, and so on.\nTo the extent that these two objectives can be realised, they should facilitate the seamless integration of different kinds of application, including medical diagnosis. It should, for example, be relatively easy to apply a natural language interface to an SP system for medical diagnosis or to integrate the kind of visual pattern recognition needed in the diagnosis of different kinds of skin cancer with other kinds of medical expertise."}, {"heading": "4 Comparison with alternatives", "text": "As mentioned in the introduction, a wide variety of philosophies and systems have been applied to the problem of medical diagnosis. In this section, I briefly review some of the more prominent of these approaches and compare them with the SP approach, as described in this paper."}, {"heading": "4.1 Rule-based systems", "text": "Rule-based systems (like the well-known MYCIN system [24]) contain if-then rules where the \u2018if\u2019 side of any rule is a collection of one or more conditions for the rule to fire connected by logical operators such as \u2018AND\u2019, \u2018OR\u2019 (which may be inclusive or exclusive) and \u2018NOT\u2019. By contrast, the SP system expresses all knowledge in the form of patterns.\nAt first sight, SP patterns lack the expressive power of if-then rules. But the effect of such rules can be modelled within the SP system if that is required [12, 17]. And if medical diagnosis is viewed as a process of pattern recognition (as in this paper), then SP patterns and the SP framework are, arguably, a more natural and flexible medium for the representation and processing of knowledge than are if-then rules.\nTo illustrate this last point, we can express the distinctive features of influenza by a rule such as:\nIF chills AND cough AND headache AND aching muscles AND runny nose AND sore throat\nTHEN influenza (probability = 0.9)\nAlthough there may be a probability associated with the rule (as shown), the rule has an intrinsic logic which, if strictly applied, means that the rule will only fire if all the conditions are satisfied. By contrast, a pattern like the one shown in column 3 of Fig. 6 may appear in the best alignment when any reasonably large subset of its symbols have been matched.\nIf one attempted to achieve this kind of flexibility with an if-then rule using combinations of AND, OR and NOT, the rule would become very complex. Alternatively, one might split up the rule into a number of smaller rules, one for each symptom or combination of two or three symptoms\u2014but again the result would be relatively complex."}, {"heading": "4.1.1 Probabilities", "text": "In systems like MYCIN and some of its successors, the \u2018probabilities\u2019 that the system calculates are really measures of confidence without the theoretical underpinnings of probability theory. In other systems, \u201c... formal approaches based on probability theory are precise but can be awkward and non-intuitive to use.\u201d [25, p. 272]. By contrast, the SP framework allows true probabilities to be calculated quite simply (see Section 3.7 and [15]) and strictly in accordance with established theory (as described in sources such as [20])."}, {"heading": "4.2 Neural networks", "text": "One of the attractions of artificial neural networks for the support of medical diagnosis is that they can be trained with appropriate data, thus by-passing the need for the manual compilation of knowledge by medical experts or knowledge engineers. However, \u201cA major drawback is that \u2018knowledge\u2019 embedded [in the neural network] is cryptically coded as a large number of weights and activation\nvalues. As a consequence, the lack of neural network validation tools is often one of the reasons limiting their use in practice, especially in the context of medical diagnosis where physicians cannot trust a system without explanation of its decisions.\u201d [26, pp. 141\u2013142].\nWhile there may be scope for extracting rules from a trained neural network (ibid.), this adds complexity and uncertainty to the technology and defeats the other main attraction of a neural network: as a classifier of specific cases in terms of the learned knowledge.\nAs a system for unsupervised learning of knowledge structures from raw data, the SP system is not yet a rival to existing neural network systems. However, the system has clear potential for unsupervised learning and, if that potential can be realised, the system has the advantage that its knowledge is stored in a form that can be read and understood by people. Meanwhile, if it is supplied with knowledge about diseases derived from experts or text books, it can be used for diagnostic classification of individual patients."}, {"heading": "4.3 Fuzzy logic and fuzzy set theory", "text": "Given the variability of diseases and other uncertainties associated with medical diagnosis (Section 3.6), the field of fuzzy logic (and fuzzy set theory) has the obvious attraction that it has been designed with the explicit intention of providing a model for \u2018fuzzy\u2019 concepts and \u2018fuzzy\u2019 operations on them (see, for example, [27, 28]).\nIn purely theoretical terms, the field of fuzzy logic may be criticised because it introduces a fairly elaborate conceptual framework to accommodate the undoubtedly fuzzy nature of many human concepts but this conceptual framework is poorly integrated with other ideas about the nature of human cognition. By contrast, the SP theory grew out of research in psychology and it provides a unified model for several aspects of human perception and cognition [10].\nConsiderations of that kind may be discounted as not relevant to the practicalities of medical diagnosis. But in that connection fuzzy logic has the drawback that it introduces another layer of complexity to the already difficult process of eliciting knowledge from medical experts [29]. There seems to be some scope for ameliorating this problem by the provision of appropriate tools (ibid.) but the basic problem remains. By contrast, the SP system allows concepts to be expressed in a simple, intuitive manner and, at the same time, it accommodates much, perhaps all, of the fuzziness of medical diagnosis."}, {"heading": "4.4 Bayesian networks", "text": "Two of the main differences between Bayesian networks (see, for example, [23]) and the SP system are:\n\u2022 Bayesian networks focus on the binary relationship between any given node in the network and each of its parent nodes (if any). In this respect, they inherit some of the thinking behind if-then rules. By contrast,\nthe SP system is oriented towards the representation and processing of associations (expressed as patterns) that may contain arbitrarily many elements.\n\u2022 Correspondingly, any given Bayesian network stores its statistical knowledge in the form of tables of conditional probabilities, one for each node in the network. By contrast, the SP system stores its statistical knowledge in the form of integers, one for each pattern, representing the absolute or relative frequency of that pattern in some domain.\nThese and related differences seem to underlie some of the apparent drawbacks of Bayesian networks compared with the SP framework:\n\u2022 The directional nature of Bayesian networks does not sit easily with the non-directional nature of medical syndromes.\n\u2022 The process of calculating probabilities of inferences in a Bayesian network is substantially more complicated than the calculation of probabilities for alignments and inferences in the SP framework.\n\u2022 The tables of conditional probabilities required for Bayesian networks are significantly more complex than simple measures of frequency that are used in the SP system. Notwithstanding the development of special methods for eliciting conditional probabilities from experts [30], the process of building up the necessary tables of conditional probabilities is likely to be much harder than measuring or estimating an integer value for each disease, reflecting its absolute or relative frequency in a given domain."}, {"heading": "4.5 Case-based reasoning", "text": "A major attraction of case-based reasoning in medical diagnosis (see, for example, [31, 32]) is that, compared with many of the alternatives, it can considerably simplify the process of acquiring the necessary knowledge. In its simplest form, a case-based system merely requires a description of one or more specific examples of each disease and a search algorithm that can find exact matches or good partial matches between the symptoms of a given patient and one or more of the stored records.\nIn some respects, the SP system is like a case-based system and it could indeed be used like a case-based system. To use it in this way, each of the Old patterns should represent a specific case (including its diagnosis) and the New pattern or patterns should represent the symptoms of a patient for whom a diagnosis is required. The capabilities of the system for finding exact matches and good partial matches between patterns will allow it to retrieve patterns for previously-diagnosed cases that are similar to any given current case.\nThe main advantages of the SP system compared with the case-based approach to diagnosis are:\n\u2022 It facilitates the description of diseases in generalised terms without the need to specify exact values for every category of symptom. In our main example, we saw how the temperature of a patient with a disease like influenza may be specified as a range of alternative values (Section 3.6). Any other category of symptom may be treated in the same way.\n\u2022 It allows one to specify clusters of symptoms that are found in two or more different diseases and it allows one to describe diseases at two or more levels of abstraction (Section 3.10). Both of these things facilitate the description of diseases without the need to repeat information unnecessarily where similar patterns are found in different diseases or varieties of disease."}, {"heading": "5 Conclusion", "text": "As we have seen, the SP system accommodates the main elements of medical diagnosis, viewed as a problem of pattern recognition, and there are reasons to believe that it may also provide support for causal reasoning in medical diagnosis. However, the SP62 model is only a prototype that serves for research and demonstration. It is not yet a system with \u2018industrial strength\u2019. The main developments that are needed to reach that goal are:\n\u2022 The provision of a well-designed graphical user interface.\n\u2022 There is probably scope for improvements in the search methods that are used within the system.\n\u2022 There is scope for the application of parallel processing both to improve the scaling properties of the system (Section 2.3.5) and to increase absolute speeds of processing.\n\u2022 Naturally, the system needs to be provided with appropriate knowledge. For each area of application, a set of patterns needs to be developed that describes the diseases and symptom clusters in that domain.\n\u2022 At some stage after the development of a realistic knowledge base, the performance of the system must be validated against the judgement of human medical experts.\nThe potential payoff from these developments is a system that allows knowledge about diseases to be expressed in a simple, intuitive manner, that can cope with errors and uncertainties in knowledge about diseases and knowledge about individual patients, that simplifies the acquisition and storage of statistical information, that calculates true probabilities of diagnoses, that smooths the path to the automatic or semi-automatic abstraction of medical knowledge in the future, and should facilitate the integration of medical diagnosis with other kinds of application."}], "references": [{"title": "Rampal, Model selection for medical diagnosis, Decision Support Systems, Decision Support Systems", "author": ["P. Mangiameli", "R.D. West"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2004}, {"title": "Some informational aspects of visual perception", "author": ["F. Attneave"], "venue": "Psychological Review", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1954}, {"title": "Trigger features, adaptation and economy of impulses", "author": ["H.B. Barlow"], "venue": "Information Processes in the Nervous System (Springer, New York,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1969}, {"title": "Learning syntax and meanings through optimization and distributional analysis", "author": ["J.G. Wolff"], "venue": "Categories and Processes in Language Acquisition (Lawrence Erlbaum,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1988}, {"title": "Reconciling simplicity and likelihood principles in perceptual organisation", "author": ["N. Chater"], "venue": "Psychological Review 103, No", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1996}, {"title": "Solomonoff, A Formal theory of inductive inference", "author": ["J. R"], "venue": "Parts I and II, Information and Control", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1964}, {"title": "An information measure for classification", "author": ["C.S. Wallace", "D.M. Boulton"], "venue": "Computer Journal 11,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1968}, {"title": "Modelling by the shortest data description, Automatica-J IFAC", "author": ["J. Rissanen"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1978}, {"title": "An Introduction to Kolmogorov Complexity and Its Applications (Springer-Verlag", "author": ["M. Li", "P. Vit\u00e1nyi"], "venue": "New York,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1997}, {"title": "Information compression by multiple alignment, unification and search as a unifying principle in computing and cognition", "author": ["J.G. Wolff"], "venue": "Artificial Intelligence Review 19,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2003}, {"title": "Information compression by multiple alignment, unification and search as a framework for human-like reasoning, Logic", "author": ["J.G. Wolff"], "venue": "Journal of the IGPL 9,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2001}, {"title": "Computing\u2019 as information compression by multiple alignment, unification and search", "author": ["J.G. Wolff"], "venue": "Journal of Universal Computer Science", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1999}, {"title": "Formal reductions of the general combinatorial decision problem", "author": ["E.L. Post"], "venue": "American Journal of Mathematics", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1943}, {"title": "Probabilistic reasoning as information compression by multiple alignment, unification and search: an introduction and overview", "author": ["J.G. Wolff"], "venue": "Journal of Universal Computer Science 5, No", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1999}, {"title": "Syntax, parsing and production of natural language in a framework of information compression by multiple alignment, unification and search", "author": ["J.G. Wolff"], "venue": "Journal of Universal Computer Science 6, No", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2000}, {"title": "Mathematics and logic as information compression by multiple alignment, unification and search, Technical Report, CognitionResearch.org.uk", "author": ["J.G. Wolff"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2002}, {"title": "Unsupervised grammar induction in a framework of information compression by multiple alignment, unification and search", "author": ["J.G. Wolff"], "venue": "Proceedings of the Workshop and Tutorial on Learning Context-Free Grammars,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2003}, {"title": "Unsupervised learning in a framework of information compression by multiple alignment, unification and search, Technical Report, CognitionResearch.org.uk", "author": ["J.G. Wolff"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2002}, {"title": "Extensible markup language (XML) 1.0 (second edition)", "author": ["T. Bray", "J. Paoli", "C.M. Sperberg-McQueen", "E. Maler"], "venue": "Technical Report, World Wide Web Consortium, W3C Recommendation,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2000}, {"title": "Probabilistic Reasoning in Intelligent Systems, Revised Second Printing Edition", "author": ["J. Pearl"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1997}, {"title": "Computer-Based Medical Consultations: MYCIN (Elsevier/North", "author": ["E.H. Shortliffe"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1976}, {"title": "Quantitative and qualitative approaches to reasoning under uncertainty in medical decision making", "author": ["J. Fox", "D. Glasspool", "J. Bury"], "venue": "Proceedings of the 8th Conference on Artificial Intelligence in Medicine in Europe, AIME 2001,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2001}, {"title": "A model for single and multiple knowledge based networks", "author": ["G. Bologna"], "venue": "Artificial Intelligence in Medicine", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2003}, {"title": "Fuzzy Sets and Fuzzy Logic: Theory and Applications (Prentic Hall PTR", "author": ["G.J. Klir", "B. Yuan"], "venue": "Upper Saddle River, NJ,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1995}, {"title": "A weighted fuzzy reasoning algorithm for medical diagnosis, Decision Support Systems", "author": ["S.-M. Chen"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1994}, {"title": "Probabilities for a probabilistic network: a case study in oesophageal cancer", "author": ["L.C. van der Gaag", "S. Renooij", "C. Witteman", "B. Aleman", "B. Taal"], "venue": "Artificial Intelligence in Medicine", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2002}, {"title": "Case-based reasoning for antibiotics therapy advice: an investigation of retrieval algorithms and prototypes", "author": ["R. Schmidt", "L. Gierl"], "venue": "Artificial Intelligence in Medicine", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2001}], "referenceMentions": [{"referenceID": 0, "context": "The problem of providing computational support for medical diagnosis has been approached from many directions including logical reasoning, fuzzy logic, set theory, rough set theory, if-then rules, Bayesian networks, classical parametric and non-parametric statistics, artificial neural networks, case-based reasoning, support vector machines, perceptrons, possibility theory, and more, as well as various aggregations or combinations of methods [1].", "startOffset": 445, "endOffset": 448}, {"referenceID": 1, "context": "The SP theory grew out of a long tradition in psychology that many aspects of brain function may be understood as information compression (see, for example, [2, 3, 4, 5]).", "startOffset": 157, "endOffset": 169}, {"referenceID": 2, "context": "The SP theory grew out of a long tradition in psychology that many aspects of brain function may be understood as information compression (see, for example, [2, 3, 4, 5]).", "startOffset": 157, "endOffset": 169}, {"referenceID": 3, "context": "The SP theory grew out of a long tradition in psychology that many aspects of brain function may be understood as information compression (see, for example, [2, 3, 4, 5]).", "startOffset": 157, "endOffset": 169}, {"referenceID": 4, "context": "The SP theory grew out of a long tradition in psychology that many aspects of brain function may be understood as information compression (see, for example, [2, 3, 4, 5]).", "startOffset": 157, "endOffset": 169}, {"referenceID": 5, "context": "It is based on principles of minimum length encoding pioneered by Solomonoff [6], Wallace and Boulton [7], Rissanen [8] and others (see also [9]).", "startOffset": 77, "endOffset": 80}, {"referenceID": 6, "context": "It is based on principles of minimum length encoding pioneered by Solomonoff [6], Wallace and Boulton [7], Rissanen [8] and others (see also [9]).", "startOffset": 102, "endOffset": 105}, {"referenceID": 7, "context": "It is based on principles of minimum length encoding pioneered by Solomonoff [6], Wallace and Boulton [7], Rissanen [8] and others (see also [9]).", "startOffset": 116, "endOffset": 119}, {"referenceID": 8, "context": "It is based on principles of minimum length encoding pioneered by Solomonoff [6], Wallace and Boulton [7], Rissanen [8] and others (see also [9]).", "startOffset": 141, "endOffset": 144}, {"referenceID": 9, "context": "An overview of the theory is presented in [10] and more detail may be found in other papers cited there (see also [11]).", "startOffset": 42, "endOffset": 46}, {"referenceID": 10, "context": "An overview of the theory is presented in [10] and more detail may be found in other papers cited there (see also [11]).", "startOffset": 114, "endOffset": 118}, {"referenceID": 11, "context": "The SP framework is Turing-equivalent in the sense that it can model a universal Turing machine [12] but it has much more to say about the nature of \u2018intelligence\u2019 than the Turing model of computing (or equivalent models such as lamda calculus [13] or the Post canonical system [14]).", "startOffset": 96, "endOffset": 100}, {"referenceID": 12, "context": "The SP framework is Turing-equivalent in the sense that it can model a universal Turing machine [12] but it has much more to say about the nature of \u2018intelligence\u2019 than the Turing model of computing (or equivalent models such as lamda calculus [13] or the Post canonical system [14]).", "startOffset": 278, "endOffset": 282}, {"referenceID": 13, "context": "To date, the main areas in which the SP framework has been applied are probabilistic reasoning, pattern recognition and information retrieval [15], parsing and production of natural language [16], modelling concepts in logic and mathematics [17], and unsupervised learning [18, 19].", "startOffset": 142, "endOffset": 146}, {"referenceID": 14, "context": "To date, the main areas in which the SP framework has been applied are probabilistic reasoning, pattern recognition and information retrieval [15], parsing and production of natural language [16], modelling concepts in logic and mathematics [17], and unsupervised learning [18, 19].", "startOffset": 191, "endOffset": 195}, {"referenceID": 15, "context": "To date, the main areas in which the SP framework has been applied are probabilistic reasoning, pattern recognition and information retrieval [15], parsing and production of natural language [16], modelling concepts in logic and mathematics [17], and unsupervised learning [18, 19].", "startOffset": 241, "endOffset": 245}, {"referenceID": 16, "context": "To date, the main areas in which the SP framework has been applied are probabilistic reasoning, pattern recognition and information retrieval [15], parsing and production of natural language [16], modelling concepts in logic and mathematics [17], and unsupervised learning [18, 19].", "startOffset": 273, "endOffset": 281}, {"referenceID": 17, "context": "To date, the main areas in which the SP framework has been applied are probabilistic reasoning, pattern recognition and information retrieval [15], parsing and production of natural language [16], modelling concepts in logic and mathematics [17], and unsupervised learning [18, 19].", "startOffset": 273, "endOffset": 281}, {"referenceID": 14, "context": "A slightly earlier version of this model (SP61) is described quite fully in [16].", "startOffset": 76, "endOffset": 80}, {"referenceID": 16, "context": "This model, and its application to unsupervised learning, is described quite fully in [18, 19].", "startOffset": 86, "endOffset": 94}, {"referenceID": 17, "context": "This model, and its application to unsupervised learning, is described quite fully in [18, 19].", "startOffset": 86, "endOffset": 94}, {"referenceID": 9, "context": "The process of building multiple alignments in the SP system provides a unified model for a variety of computational effects including fuzzy pattern recognition, best-match information retrieval, probabilistic and exact styles of reasoning, unsupervised learning, planning, problem solving and others, as described in [10].", "startOffset": 318, "endOffset": 322}, {"referenceID": 14, "context": "The details of these calculations and adjustments are explained in [16].", "startOffset": 67, "endOffset": 71}, {"referenceID": 16, "context": "This abstract conception has now been realised more concretely in the form of the SP70 computer model [18, 19] that is capable of learning simple grammars from raw data.", "startOffset": 102, "endOffset": 110}, {"referenceID": 17, "context": "This abstract conception has now been realised more concretely in the form of the SP70 computer model [18, 19] that is capable of learning simple grammars from raw data.", "startOffset": 102, "endOffset": 110}, {"referenceID": 14, "context": "Further details may be found in [16].", "startOffset": 32, "endOffset": 36}, {"referenceID": 18, "context": "Readers who are familiar with XML [22] will notice that pairs of symbols like \u2018<disease> .", "startOffset": 34, "endOffset": 38}, {"referenceID": 9, "context": "This framework pattern serves as an anchor point for symbols in other patterns and facilitates the formation of multiple alignments in accordance with the rules described in [10] and earlier publications.", "startOffset": 174, "endOffset": 178}, {"referenceID": 13, "context": "A fuller account of the way probabilities are calculated may be found in [15].", "startOffset": 73, "endOffset": 77}, {"referenceID": 13, "context": "Probabilities of these inferences can be calculated as described in [15].", "startOffset": 68, "endOffset": 72}, {"referenceID": 13, "context": "1) \u2018explaining away\u2019 (see [15]).", "startOffset": 26, "endOffset": 30}, {"referenceID": 9, "context": ", \u2018cat\u2019, \u2018mammal\u2019, \u2018vertebrate\u2019, \u2018animal\u2019) in the manner of object-oriented design and, via the building of multiple alignments, it allows a specific entity (such as \u201cmy cat Tibs\u201d) to be recognised at several different levels of abstraction [10, 15].", "startOffset": 241, "endOffset": 249}, {"referenceID": 13, "context": ", \u2018cat\u2019, \u2018mammal\u2019, \u2018vertebrate\u2019, \u2018animal\u2019) in the manner of object-oriented design and, via the building of multiple alignments, it allows a specific entity (such as \u201cmy cat Tibs\u201d) to be recognised at several different levels of abstraction [10, 15].", "startOffset": 241, "endOffset": 249}, {"referenceID": 20, "context": "Rule-based systems (like the well-known MYCIN system [24]) contain if-then rules where the \u2018if\u2019 side of any rule is a collection of one or more conditions for the rule to fire connected by logical operators such as \u2018AND\u2019, \u2018OR\u2019 (which may be inclusive or exclusive) and \u2018NOT\u2019.", "startOffset": 53, "endOffset": 57}, {"referenceID": 11, "context": "But the effect of such rules can be modelled within the SP system if that is required [12, 17].", "startOffset": 86, "endOffset": 94}, {"referenceID": 15, "context": "But the effect of such rules can be modelled within the SP system if that is required [12, 17].", "startOffset": 86, "endOffset": 94}, {"referenceID": 13, "context": "7 and [15]) and strictly in accordance with established theory (as described in sources such as [20]).", "startOffset": 6, "endOffset": 10}, {"referenceID": 23, "context": "6), the field of fuzzy logic (and fuzzy set theory) has the obvious attraction that it has been designed with the explicit intention of providing a model for \u2018fuzzy\u2019 concepts and \u2018fuzzy\u2019 operations on them (see, for example, [27, 28]).", "startOffset": 225, "endOffset": 233}, {"referenceID": 24, "context": "6), the field of fuzzy logic (and fuzzy set theory) has the obvious attraction that it has been designed with the explicit intention of providing a model for \u2018fuzzy\u2019 concepts and \u2018fuzzy\u2019 operations on them (see, for example, [27, 28]).", "startOffset": 225, "endOffset": 233}, {"referenceID": 9, "context": "By contrast, the SP theory grew out of research in psychology and it provides a unified model for several aspects of human perception and cognition [10].", "startOffset": 148, "endOffset": 152}, {"referenceID": 19, "context": "Two of the main differences between Bayesian networks (see, for example, [23]) and the SP system are:", "startOffset": 73, "endOffset": 77}, {"referenceID": 25, "context": "Notwithstanding the development of special methods for eliciting conditional probabilities from experts [30], the process of building up the necessary tables of conditional probabilities is likely to be much harder than measuring or estimating an integer value for each disease, reflecting its absolute or relative frequency in a given domain.", "startOffset": 104, "endOffset": 108}, {"referenceID": 26, "context": "A major attraction of case-based reasoning in medical diagnosis (see, for example, [31, 32]) is that, compared with many of the alternatives, it can considerably simplify the process of acquiring the necessary knowledge.", "startOffset": 83, "endOffset": 91}], "year": 2014, "abstractText": "This paper describes a novel approach to medical diagnosis based on the SP theory of computing and cognition. The main attractions of this approach are: a format for representing diseases that is simple and intuitive; an ability to cope with errors and uncertainties in diagnostic information; the simplicity of storing statistical information as frequencies of occurrence of diseases; a method for evaluating alternative diagnostic hypotheses that yields true probabilities; and a framework that should facilitate unsupervised learning of medical knowledge and the integration of medical diagnosis with other AI applications.", "creator": "LaTeX with hyperref package"}}}