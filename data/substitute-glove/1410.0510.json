{"id": "1410.0510", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Oct-2014", "title": "Deep Sequential Neural Network", "abstract": "Neural Networks sequentially upgrade high - increasing features all their successive layers. We amending here taken include excitability network integrated where each layer because associated taking just set of candidate mappings. When any output now processed, at each layer, one mapping among these candidates. selected according because first sequential must pressing. The resulting formula is pricing statement the also DAG those abstract, so that a realization being. using to turned wood binary defines a bits of integral. Instead example considering key nonlinear, why in modernism multilayer companies, still redesigned without raise first well this set latter local analytic. It thought thus able to plan available though well these leaving suggest phases although such according iterative, productivity that voice power of this model z. rep.. ups long modernism improvisatory affiliates. The learning multiplication \u201d inspired several stance flow techniques coming first taken movements learning domain and is made here get of on genres back - activation based probability british study. Experiments on different datasets presents on moral of would toward.", "histories": [["v1", "Thu, 2 Oct 2014 10:58:17 GMT  (448kb,D)", "http://arxiv.org/abs/1410.0510v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["ludovic denoyer", "patrick gallinari"], "accepted": false, "id": "1410.0510"}, "pdf": {"name": "1410.0510.pdf", "metadata": {"source": "CRF", "title": "Deep Sequential Neural Network", "authors": ["Ludovic Denoyer", "Patrick Gallinari"], "emails": ["ludovic.denoyer@lip6.fr", "patrick.gallinari@lip6.fr"], "sections": [{"heading": null, "text": "Neural Networks sequentially build high-level features through their successive layers. We propose here a new neural network model where each layer is associated with a set of candidate mappings. When an input is processed, at each layer, one mapping among these candidates is selected according to a sequential decision process. The resulting model is structured according to a DAG like architecture, so that a path from the root to a leaf node defines a sequence of transformations. Instead of considering global transformations, like in classical multilayer networks, this model allows us for learning a set of local transformations. It is thus able to process data with different characteristics through specific sequences of such local transformations, increasing the expression power of this model w.r.t a classical multilayered network. The learning algorithm is inspired from policy gradient techniques coming from the reinforcement learning domain and is used here instead of the classical back-propagation based gradient descent techniques. Experiments on different datasets show the relevance of this approach."}, {"heading": "1 Introduction", "text": "Reinforcement Learning (RL) techniques which are usually devoted to problems in dynamic environments have been recently used for classical machine learning tasks like classification [5, 2]. In that case, the prediction process is seen as a sequential process, and this sequential process can take different forms. For example [3] and [12] consider that the sequential process is an acquisition process able to focus on relevant parts of the input data; [9] for example focuses on the sequential prediction process with a cascade approach. RL opens now some interesting research directions for classical ML tasks and allows one to imagine solutions to complex problems like budgeted classification [4] or anytime prediction [6].\nIn parallel, Neural Networks (NNs) have recently given rise to a large amount of research motivated by the development of deep architectures - or Deep Neural Networks (DNNs). The use of deep architectures have shown impressive results for many different tasks, from image classification [10, 14], speech recognition [7] to machine translation [19] or even for natural language processing [16]. These great successes mainly come from the ability of DNNs to compute high-level features over data. Many variants of learning algorithms have been proposed, from complex gradient computations [11], to dropout methods [1], but the baseline learning algorithm still consists in recursively computing the gradient by using the back-propagation algorithm and performing (stochastic) gradient descent.\nar X\niv :1\n41 0.\n05 10\nv1 [\ncs .L\nG ]\n2 O\nThis paper is motivated by the idea of using sequential learning algorithms - mainly coming from the reinforcement learning community - in the context of Deep Neural Networks. More precisely, we consider that inference in a NN is a sequential decision process which selects at each layer of a deep architecture one mapping among a set of candidate mappings. This process is repeated layerwise until the final layer is reached. The resulting NN is then a DAG like architecture, where each layer is composed of a set of candidate mappings. Only one of these candidates will be selected at each layer, for processing an input pattern. When an input is presented to the NN, it will then follow a set of successive transformations which corresponds to a trajectory in the NN DAG, until the final output is computed. The decision on which trajectory to follow is computed at each layer through additional components called here selection functions. The latter are trained using a policy gradient technique like algorithm while the NN weights are trained using back propagation. This model called Deep Sequential Neural Networks (DNNs) process an input through successive local transformations insetad of using a global transformation in a classical deep NN architecture. It can be considered as an extension of the classical deep NN architecture since when the number of potential candidate mapping at each layer is reduced to 1, one recovers a classical NN architecture. DSNNs are thus based on the following inference process:\n\u2022 Given an input x, the model chooses between different possible mappings1\n\u2022 Then x is mapped to a new representation space. \u2022 Given the new representation, another mapping is chosen between a set of different possible\nmappings, and so on to the prediction.\nNote that the way mappings are chosen, and the mappings themselves are learned together on a training set. Instead of just computing representations in successive representation spaces, DSNNs are able to choose the best representation spaces depending on the input and to process differently data coming from different distributions.\nThis idea of choosing a different sequence of computations depending on the input share many common points with existing models (see Section 5) but our model has some interesting properties:\n\u2022 It is able to simultaneously learn successive representations of an input, and also which representations spaces are the most relevant for this particular input.\n\u2022 Learning is made by extending policy gradient methods which as far as we know have never been used in this context; moreover, we show that, when the DNNs is in its simplest shape, this algorithm is equivalent to the gradient descent technique used in NNs.\nThe paper is organized as follows: in Section 2, we describe the DSNN formalisms and the underlying sequential inference process. By deriving a policy gradient algorithm, we propose a learning algorithm in Section 3 based on gradient descent techniques. We present in Section 4 experimental results on different datasets and a qualitative study showing the ability of the model to solve complex classification problems. The related work is presented in Section 5."}, {"heading": "2 Deep Sequential Neural Networks", "text": "Let us consider X = RX the input space, and Y = RY the output space, X and Y being respectively the dimension of the input and output spaces. We denote {(x1, y1), ..., (x`, y`)} the set of labeled training instances such that xi \u2208 X and yi \u2208 Y . {(x`+1, y`+1), ..., (xT , yT )} will denote the set of testing examples.\nThe DSNN model has a DAG-structure defined as follow:\n\u2022 Each node n is in {n1, ..., nN} where N is the total number of nodes of the DAG \u2022 The root node is n1, n1 does not have any parent node. \u2022 cn,i corresponds to the i-th child of node n and #n is the number of children of n so, in\nthat case, i is a value be between 1 and #n. 1We call a mapping the base transformation made between two layers of a neural network i.e a projection\nfrom Rn to Rm.\n\u2022 leaf(n) is true if node n is a leaf of the DAG - i.e a node without children. \u2022 Each node is associated to a particular representation space Rdim(n) where dim(n) is the\ndimension associated to this space. Nodes play the same role than layers in classical neural networks.\n\u2013 dim(n1) = X i.e the dimension of the root node is the dimension of the input of the model.\n\u2013 For any node n, dim(n) = Y if leaf(n) = true i.e the dimension of the leaf nodes is the output space dimension.\n\u2022 We consider mapping functions fn,n\u2032 : Rdim(n) \u2192 Rdim(n \u2032) which are functions asso-\nciated with edge (n, n\u2032). fn,n\u2032 computes a new representation of the input x in node n\u2032 given the representation of x in node n. The output produced by the model is a sequence of f -transformation applied to the input like in a neural network.\n\u2022 In addition, each node is also associated with a selection function denoted pn : Rdim(n) \u2192 R#n able, given an input in Rdim(n), to compute a score for each child of node n. This function defines a probability distribution over the children nodes of n such as, given a vector z \u2208 Rdim(n)\nP (cn,i|z) = ep\ni n(z)\n#n\u2211 j=1 ep j n(z)\nSelection functions aim at selecting which f -functions to use by choosing a path in the DAG from the root node to a leaf node."}, {"heading": "2.1 Inference in DSNN", "text": "Given such a DAG structure G, the inference process is the following:\n1. At first, an input x \u2208 X is presented at the root node n(1) = n1 of the DAG2. 2n(t) is used to denote the node selected at time t\nAlgorithm 1 DSNN Inference Procedure 1: procedure INFERENCE(x) . x is the input vector 2: z(1) \u2190 x 3: n(1) \u2190 n1 4: t\u2190 1 5: while not leaf(n(t)) do . Inference finished 6: a(t) \u223c pn(t)(z(t)) . Sampling using the distribution over children nodes 7: n(t+1) \u2190 cn(t),a(t) 8: z(t+1) \u2190 fn(t),n(t+1)(z(t)) 9: t\u2190 t+ 1 10: end while 11: return z(t) 12: end procedure\n2. Then, based on x, a child node n(2) is sampled using the P (c(1),.|x) distribution computed through the pn1 function.\n3. The model computes a new representation at node n(2) using fn(1),n(2)(x). A child node of n(2) is sampled following P (c(2),.|x), .....\n4. The same process is repeated until a leaf node. The vector computed at the leaf node level is the output of the model.\nDetails of the inference procedure are given in Algorithm 1. The algorithm is a discrete-time sequential process starting at time t = 1 and finishing when the input has reached a leaf node. Given an input x, we denote:\n\u2022 n(t) the node reached by the input x at time t such that n(1) = n1. \u2022 a(t) the child node chosen at time t, a(t) \u2208 [1..#n(t)]\n\u2022 z(t) the mapping of x at time t such that z(t) \u2208 Rdim(n(t))\nThe inference process generates a trajectory T which is a sequence (n(1), ..., n(D)) of nodes starting from the root node n(1) = n1 to a leaf of the node n(D) such that leaf(n(D)) = True; D is the size of the chosen branch of the tree. This sequence is obtained by sequentially choosing a sequence of children (or actions) H = (a(1), ..., a(D\u22121)). In the following H will denote a sequence of actions sampled w.r.t the p functions."}, {"heading": "3 Learning DSNN with gradient-based approaches", "text": "The training procedure we propose aims at simultaneously learning both the mapping functions fi,j and the selection functions pi in order to minimize a given learning loss denoted \u2206. Our learning algorithm is based on an extension of policy gradient techniques inspired from the Reinforcement Learning literature. More precisely, our learning method is close to the methods proposed in [18] and [12] with the difference that, instead of considering a reward signal which is usual in reinforcement learning, we consider a loss function \u2206 computing the quality of the system.\nLet us denote \u03b8 the parameters of the f functions and \u03b3 the parameters of the p functions.\nThe performance of our system is denoted J(\u03b8, \u03b3):\nJ(\u03b8, \u03b3) = EP (x,H,y)[\u2206(F (x,H), y)] (1)\nwhere both H - i.e the sequence of children nodes chosen by the p-functions - and F - the final decision given a particular path in the DSNN - depends on both \u03b3 and \u03b8. The optimization of J can be made by gradient-descent techniques and we need to compute the gradient of J :\n\u2207\u03b8,\u03b3J(\u03b8, \u03b3) = \u222b \u2207\u03b8,\u03b3 (P (H|x)\u2206(F (x,H), y))P (x, y)dHdxdy (2)\nThis gradient can be simplified such that: \u2207\u03b8,\u03b3J(\u03b8, \u03b3) = \u222b \u2207\u03b8,\u03b3 (P (H|x)) \u2206(F (x,H), y)P (x, y)dHdxdy + \u222b P (H|x)\u2207\u03b8,\u03b3\u2206(F (x,H), y)P (x, y)dHdxdy\n= \u222b P (H|x) P (H|x) \u2207\u03b8,\u03b3 (P (H|x)) \u2206(F (x,H), y)P (x, y)dHdxdy\n+ \u222b P (H|x)\u2207\u03b8,\u03b3\u2206(F (x,H), y)P (x, y)dHdxdy\n= \u222b P (H|x)\u2207\u03b8,\u03b3 (logP (H|x)) \u2206(F (x,H), y)P (x, y)dHdxdy\n+ \u222b P (H|x)\u2207\u03b8,\u03b3\u2206(F (x,H), y)P (x, y)dHdxdy\n(3)\nUsing the Monte Carlo approximation of this expectation by takingM trail histories over the training examples, we can write:\n\u2207\u03b8,\u03b3J(\u03b8, \u03b3) = 1\n` \u2211\u0300 i=1\n[ 1\nM M\u2211 k=1 \u2207\u03b8,\u03b3 (logP (H|xi)) \u2206(F (xi, H), y) +\u2207\u03b8,\u03b3\u2206(F (xi, H), y)\n] (4)\nIntuitively, the gradient is composed of two terms:\n\u2022 The first term aims at penalizing trajectories with high loss - and thus encouraging to find trajectories with low loss. When the loss is 0, the resulting gradient is null and the system will thus continue to choose the same paths.\n\u2022 The second term is the gradient computed over the branch of the tree that has been sampled. It encourages the f functions to perform better the next time the same path will be chosen for a particular input.\nWhile the second term can be easily computed by back-propagation techniques over the sequence of f functions that compose the branch of the tree, the computation of\u2207\u03b8,\u03b3 logP (H|xi) can be written:\n\u2207\u03b8,\u03b3 logP (H|xi) = \u2207\u03b8,\u03b3 D\u2211 t=1 logP (a(t)|z(t)) (5)\nThe term \u2207\u03b8,\u03b3 logP (a(t)|z(t)) depends on z(t) which is the projection of the input x at node n(t). This projection involves the sequence of transformation fn(1),n(2) , ..., fn(t\u22121),n(t) and the selection function pn(t) . It can also be computed by back-propagation techniques over the functions fn(1),n(2) , ..., fn(t\u22121),n(t) , pn(t) .\nVariance reduction: Note that equation provides us an estimate of the gradient which can have a high variance. Instead of using this estimate, we replace \u2206(F (xi, H), y) by \u2206(F (xi, H), y) \u2212 b where b = Ep(x,H,y)[\u2206(F (xi, H), y)] which can be easily estimated on the training set [18].\nNNs and DSNNs: It is easy to show that DSNN is a generalization of NN and is equivalent to NN in its simple shape, where the structure is not a DAG but only a sequence of nodes as presented in Figure 2 (left). In other words, learning a DSNN with only one possible action at each timestep is equivalent to learning a neural network."}, {"heading": "4 Experiment", "text": "We have performed experiments comparing two different models: (i) NN corresponds to a simple neural network (ii) DSNN-k corresponds to the sequential model presented above where k is the number of possible actions. The model corresponding to DSNN-2 5 (tanh) is presented in Figure 2 (right). It corresponds to the extension of a NN with a 5-dimensionnal hidden layer (with hyperbolic tangent activation function) where now the system is able to choose at each timestep between 2\nactions. nhl will denote a model without hidden layer. DSNN-3 10-10 (rl) corresponds to the extension of a NN with two hidden layers of size 10 (with rectified linear units) with 3 possible actions. The f functions are thus linear transformations followed by a non linear function. The p. functions are simple linear functions3.\nThe experiments have been made on three families of datasets. The first set of experiments has been made on 5 UCI datasets which are datasets composed of about 1,000 training examples in lowdimensional space. The second set of experiments has been made on a variation of MNIST where the distribution of the inputs has been pertubated to measure the ability of the system to computes different features depending on the inputs. At last, the third set of experiments on simple 2-dimensionnal datasets based on checkerboard distributions and is used to better analyze the behavior of the model. The experiments have been performed with many different values of the hyper-parameters following a grid search algorithm. For each value of hyper-parameters and each dataset, we have performed 5 runs, we have averaged the performance over the 5 runs.\n3More complex p functions could be used but have not been investigated in the paper\nUCI datasets: The results obtained on UCI datasets are presented in Table 2 where 50 % of the examples have been used for training. First, one can see that, for some datasets (diabetes,heart), a simple linear model is sufficient for computing a high accuracy and using more complex architectures does not help in increasing the performance of the models. In that case, using DSNN does not seem really useful since a simple model is enough. For the other datasets, the DSNN outperforms the NN approach, particularly when the number of children for each node is low. Indeed, when this number becomes high, the number of parameters to learn can be very large, and the system is not able to learn these parameters, or needs at least much more iterations to converge.\nMNIST datasets: We have performed experiments on both the classical MNIST dataset4 where digits have been re-sampled to 14 \u00d7 14 images, and to a variation of this dataset called MNISTNegative where half of the digits have been negated - i.e for half of the digits, the value of a pixel is\n4The training set is composed of 12,000 examples, and the testing set is composed of 50,000 digits.\nequal to one minus its original value. In that case, one can consider that digits have been sampled following two different distributions a simple model will not be able to capture. Table 3 reports the results we have obtained with different architectures. First, one can see that, for the MNIST dataset, the performance of NN and DSNN are quite similar showing that DSNN is not relevant when the input distribution is simple. On the MNIST-Inverse dataset, first, the NN without hidden layer is unable to well classify since the inputs are too much disparate. In that case, DSNN is able to capture the two inputs distributions and performs quite well. Adding some small hidden layers allows us to increase the accuracy. When using large hidden layers, a single NN is capable of capturing the data distribution and thus perform as well as DSNN.\nCheckerboard datasets: For that set of experiments, we have generated checkerboard of points in two different categories (see Figure 1). The checkerboards sizes vary from 3\u00d73 to 11\u00d711 and each case of the checkerboard is composed of 100 training points, and 100 testing points. Performances are presented in Table 4 showing that the DSNN model is able to capture this distribution. Figure 1 show the decision frontiers obtained by different architectures. One can see that the NN model is not able to capture this distribution. DSNN-3 with a 10-dim hidden layer is almost perfect while DSNN models with a more complex architectures and a higher number of actions are not able to learn since they have too many parameters."}, {"heading": "5 Related Work", "text": "Different models are related to DSNNs. The first family of models are neural networks. The idea of processing input data by different functions is not new and have been proposed for example in Neural Tree Networks [17, 15], with Hierarchical Mixture of Experts [8] where the idea is to compute different transformations of data and to aggregate these transformations. The difference with our approach is both in the inference process, and in the way the model is learned. They also share the idea of processing different inputs with different computations which is the a major idea underlying decision trees [13] and also more recent classification techniques like [3].\nAt last, some links have already be done between classification and reinforcement learning algorithms [4, 2]. Particularly, the use of recurrent neural networks from modelling Markov Decision Processes learned by Policy gradient techniques has been deeply explored in [18] and in a recent work that proposes the use of such models for image classification [12]."}, {"heading": "6 Conclusion and Perspectives", "text": "We have proposed a new family of model called Deep Sequential Neural Networks which differ from neural networks since, instead of always applying the same set of transformations, they are able to choose which transformation to apply depending on the input. The learning algorithm is based on the computation of the gradient which is obtained by an extension of policy-gradient techniques. In its simplest shape, DSNNs are equivalent to DNNs. Experiments on different datasets have shown the effectiveness of these models."}], "references": [{"title": "The dropout learning algorithm", "author": ["Pierre Baldi", "Peter J. Sadowski"], "venue": "Artif. Intell.,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Fast classification using sparse decision dags", "author": ["R\u00f3bert Busa-Fekete", "Djalel Benbouzid", "Bal\u00e1zs K\u00e9gl"], "venue": "In Proceedings of the 29th International Conference on Machine Learning,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Text classification: A sequential reading approach", "author": ["Gabriel Dulac-Arnold", "Ludovic Denoyer", "Patrick Gallinari"], "venue": "In Advances in Information Retrieval - 33rd European Conference on IR Research,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Sequential approaches for learning datum-wise sparse representations", "author": ["Gabriel Dulac-Arnold", "Ludovic Denoyer", "Philippe Preux", "Patrick Gallinari"], "venue": "Machine Learning,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Sequentially generated instance-dependent image representations for classification", "author": ["Gabriel Dulac-Arnold", "Ludovic Denoyer", "Nicolas Thome", "Matthieu Cord", "Patrick Gallinari"], "venue": "Internation Conference on Learning Representations - ICLR 2014,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Learning to segment from a few well-selected training images", "author": ["Alireza Farhangfar", "Russell Greiner", "Csaba Szepesv\u00e1ri"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Speech recognition with deep recurrent neural networks", "author": ["Alex Graves", "Abdel-rahman Mohamed", "Geoffrey E. Hinton"], "venue": "In IEEE International Conference on Acoustics, Speech and Signal Processing,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Hierarchical mixtures of experts and the em algorithm", "author": ["Michael I. Jordan", "Robert A. Jacobs"], "venue": "Neural Comput.,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1994}, {"title": "Timely object recognition", "author": ["Sergey Karayev", "Tobias Baumgartner", "Mario Fritz", "Trevor Darrell"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E. Hinton"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Training deep and recurrent networks with hessian-free optimization", "author": ["James Martens", "Ilya Sutskever"], "venue": "In Neural Networks: Tricks of the Trade - Second Edition,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Recurrent models of visual attention", "author": ["Volodymyr Mnih", "Nicolas Heess", "Alex Graves", "Koray Kavukcuoglu"], "venue": "CoRR, abs/1406.6247,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Induction of decision trees", "author": ["J. Ross Quinlan"], "venue": "Machine Learning,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1986}, {"title": "Multi-column deep neural networks for image classification", "author": ["Jurgen Schmidhuber"], "venue": "In Proceedings of the 2012 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "Neural trees: a new tool for classification", "author": ["J A Sirat", "J-P Nadal"], "venue": "Network: Computation in Neural Systems,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1990}, {"title": "Deep learning for NLP (without magic)", "author": ["Richard Socher", "Christopher D. Manning"], "venue": "In Human Language Technologies,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Perceptron trees: A case study in hybrid concept representations", "author": ["Paul E. Utgoff"], "venue": "In Proceedings of the 7th National Conference on Artificial Intelligence. St. Paul,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1988}, {"title": "Solving deep memory pomdps with recurrent policy gradients", "author": ["Daan Wierstra", "Alexander F\u00f6rster", "Jan Peters", "J\u00fcrgen Schmidhuber"], "venue": "In Artificial Neural Networks - ICANN", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}, {"title": "Bilingual word embeddings for phrase-based machine translation", "author": ["Will Y. Zou", "Richard Socher", "Daniel M. Cer", "Christopher D. Manning"], "venue": "In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2013}], "referenceMentions": [{"referenceID": 4, "context": "Reinforcement Learning (RL) techniques which are usually devoted to problems in dynamic environments have been recently used for classical machine learning tasks like classification [5, 2].", "startOffset": 182, "endOffset": 188}, {"referenceID": 1, "context": "Reinforcement Learning (RL) techniques which are usually devoted to problems in dynamic environments have been recently used for classical machine learning tasks like classification [5, 2].", "startOffset": 182, "endOffset": 188}, {"referenceID": 2, "context": "For example [3] and [12] consider that the sequential process is an acquisition process able to focus on relevant parts of the input data; [9] for example focuses on the sequential prediction process with a cascade approach.", "startOffset": 12, "endOffset": 15}, {"referenceID": 11, "context": "For example [3] and [12] consider that the sequential process is an acquisition process able to focus on relevant parts of the input data; [9] for example focuses on the sequential prediction process with a cascade approach.", "startOffset": 20, "endOffset": 24}, {"referenceID": 8, "context": "For example [3] and [12] consider that the sequential process is an acquisition process able to focus on relevant parts of the input data; [9] for example focuses on the sequential prediction process with a cascade approach.", "startOffset": 139, "endOffset": 142}, {"referenceID": 3, "context": "RL opens now some interesting research directions for classical ML tasks and allows one to imagine solutions to complex problems like budgeted classification [4] or anytime prediction [6].", "startOffset": 158, "endOffset": 161}, {"referenceID": 5, "context": "RL opens now some interesting research directions for classical ML tasks and allows one to imagine solutions to complex problems like budgeted classification [4] or anytime prediction [6].", "startOffset": 184, "endOffset": 187}, {"referenceID": 9, "context": "The use of deep architectures have shown impressive results for many different tasks, from image classification [10, 14], speech recognition [7] to machine translation [19] or even for natural language processing [16].", "startOffset": 112, "endOffset": 120}, {"referenceID": 13, "context": "The use of deep architectures have shown impressive results for many different tasks, from image classification [10, 14], speech recognition [7] to machine translation [19] or even for natural language processing [16].", "startOffset": 112, "endOffset": 120}, {"referenceID": 6, "context": "The use of deep architectures have shown impressive results for many different tasks, from image classification [10, 14], speech recognition [7] to machine translation [19] or even for natural language processing [16].", "startOffset": 141, "endOffset": 144}, {"referenceID": 18, "context": "The use of deep architectures have shown impressive results for many different tasks, from image classification [10, 14], speech recognition [7] to machine translation [19] or even for natural language processing [16].", "startOffset": 168, "endOffset": 172}, {"referenceID": 15, "context": "The use of deep architectures have shown impressive results for many different tasks, from image classification [10, 14], speech recognition [7] to machine translation [19] or even for natural language processing [16].", "startOffset": 213, "endOffset": 217}, {"referenceID": 10, "context": "Many variants of learning algorithms have been proposed, from complex gradient computations [11], to dropout methods [1], but the baseline learning algorithm still consists in recursively computing the gradient by using the back-propagation algorithm and performing (stochastic) gradient descent.", "startOffset": 92, "endOffset": 96}, {"referenceID": 0, "context": "Many variants of learning algorithms have been proposed, from complex gradient computations [11], to dropout methods [1], but the baseline learning algorithm still consists in recursively computing the gradient by using the back-propagation algorithm and performing (stochastic) gradient descent.", "startOffset": 117, "endOffset": 120}, {"referenceID": 17, "context": "More precisely, our learning method is close to the methods proposed in [18] and [12] with the difference that, instead of considering a reward signal which is usual in reinforcement learning, we consider a loss function \u2206 computing the quality of the system.", "startOffset": 72, "endOffset": 76}, {"referenceID": 11, "context": "More precisely, our learning method is close to the methods proposed in [18] and [12] with the difference that, instead of considering a reward signal which is usual in reinforcement learning, we consider a loss function \u2206 computing the quality of the system.", "startOffset": 81, "endOffset": 85}, {"referenceID": 17, "context": "Instead of using this estimate, we replace \u2206(F (xi, H), y) by \u2206(F (xi, H), y) \u2212 b where b = Ep(x,H,y)[\u2206(F (xi, H), y)] which can be easily estimated on the training set [18].", "startOffset": 169, "endOffset": 173}, {"referenceID": 16, "context": "The idea of processing input data by different functions is not new and have been proposed for example in Neural Tree Networks [17, 15], with Hierarchical Mixture of Experts [8] where the idea is to compute different transformations of data and to aggregate these transformations.", "startOffset": 127, "endOffset": 135}, {"referenceID": 14, "context": "The idea of processing input data by different functions is not new and have been proposed for example in Neural Tree Networks [17, 15], with Hierarchical Mixture of Experts [8] where the idea is to compute different transformations of data and to aggregate these transformations.", "startOffset": 127, "endOffset": 135}, {"referenceID": 7, "context": "The idea of processing input data by different functions is not new and have been proposed for example in Neural Tree Networks [17, 15], with Hierarchical Mixture of Experts [8] where the idea is to compute different transformations of data and to aggregate these transformations.", "startOffset": 174, "endOffset": 177}, {"referenceID": 12, "context": "They also share the idea of processing different inputs with different computations which is the a major idea underlying decision trees [13] and also more recent classification techniques like [3].", "startOffset": 136, "endOffset": 140}, {"referenceID": 2, "context": "They also share the idea of processing different inputs with different computations which is the a major idea underlying decision trees [13] and also more recent classification techniques like [3].", "startOffset": 193, "endOffset": 196}, {"referenceID": 3, "context": "At last, some links have already be done between classification and reinforcement learning algorithms [4, 2].", "startOffset": 102, "endOffset": 108}, {"referenceID": 1, "context": "At last, some links have already be done between classification and reinforcement learning algorithms [4, 2].", "startOffset": 102, "endOffset": 108}, {"referenceID": 17, "context": "Particularly, the use of recurrent neural networks from modelling Markov Decision Processes learned by Policy gradient techniques has been deeply explored in [18] and in a recent work that proposes the use of such models for image classification [12].", "startOffset": 158, "endOffset": 162}, {"referenceID": 11, "context": "Particularly, the use of recurrent neural networks from modelling Markov Decision Processes learned by Policy gradient techniques has been deeply explored in [18] and in a recent work that proposes the use of such models for image classification [12].", "startOffset": 246, "endOffset": 250}], "year": 2014, "abstractText": "Neural Networks sequentially build high-level features through their successive layers. We propose here a new neural network model where each layer is associated with a set of candidate mappings. When an input is processed, at each layer, one mapping among these candidates is selected according to a sequential decision process. The resulting model is structured according to a DAG like architecture, so that a path from the root to a leaf node defines a sequence of transformations. Instead of considering global transformations, like in classical multilayer networks, this model allows us for learning a set of local transformations. It is thus able to process data with different characteristics through specific sequences of such local transformations, increasing the expression power of this model w.r.t a classical multilayered network. The learning algorithm is inspired from policy gradient techniques coming from the reinforcement learning domain and is used here instead of the classical back-propagation based gradient descent techniques. Experiments on different datasets show the relevance of this approach.", "creator": "LaTeX with hyperref package"}}}