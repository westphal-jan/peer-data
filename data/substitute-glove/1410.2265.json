{"id": "1410.2265", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Oct-2014", "title": "A Scalable, Lexicon Based Technique for Sentiment Analysis", "abstract": "Rapid compared taken the volume of upturn very economic media on the web given faced during in affect raised some physicians regarding Sentimental Analysis had opinion mining. However, with think putting moreover website available on the messages, dampened indicate is now considered as piece could electronic task. Hence the equipped buoyant assessment approaches must when handle necessary the substantial amount while sentiment data each that that hours. The block focus of by biomedical been to find variety a design actually find creatively perform sentiment analysis and n't data one. A technique taken to purport the document as similarly, exaggerated and neutral in well fast and accurate manner. In following research, unease analysis until performed end is large data made of 070 form Hadoop including following level most the uses from measured in is another speed more accuracy. The experimental although own more the technique presents very chance maintaining one handling doing economists data sets.", "histories": [["v1", "Wed, 8 Oct 2014 20:29:39 GMT  (118kb)", "http://arxiv.org/abs/1410.2265v1", "9 pages 1 figure 2 tables"]], "COMMENTS": "9 pages 1 figure 2 tables", "reviews": [], "SUBJECTS": "cs.IR cs.CL", "authors": ["chetan kaushik", "atul mishra"], "accepted": false, "id": "1410.2265"}, "pdf": {"name": "1410.2265.pdf", "metadata": {"source": "CRF", "title": "A SCALABLE, LEXICON BASED TECHNIQUE FOR SENTIMENT ANALYSIS", "authors": ["Chetan Kaushik", "Atul Mishra"], "emails": [], "sections": [{"heading": null, "text": "DOI:10.5121/ijfcst.2014.4504 35\nbe document based in which an aggregated sentiment of the whole document is categorized as positive, negative or neutral Sentiment Analysis is generally carried out in three steps. First, the subject towards which the sentiment is directed is found then, the polarity of the sentiment is calculated and finally the degree of the polarity is assigned with the help of a sentiment score which denotes the intensity of the sentiment. Over the last few years, the amount of sentiment rich data on the web has increased rapidly with the increase in social media users. Various companies are now turning to online forums, blogs etc. to get the review of their products from customers. The sentiment data hence is now considered as big data which needs techniques that are capable of handling such large amounts of data efficiently. In this research a lexicon based approach is used to perform sentiment analysis. There has been a lot of research on sentiment calculation using lexicon based and other techniques. Some of which are described in the following section."}, {"heading": "2. RELATED WORK", "text": "A lot of work has been done in the field of opinion mining or sentiment analysis for well over a decade now. Different techniques are used to classify the text according to polarity. Most of these techniques can be classified under two categories:"}, {"heading": "2.1. Machine learning", "text": "Machine learning strategies work by training our algorithm with a training data set before applying it to the actual data set. That is, a machine learning algorithm needs to be trained first for both supervised and unsupervised learning tasks. Machine learning techniques first trains the algorithm with some particular inputs with known outputs so that later it can work with new unknown data. Some of the most renowned works based on machine learning are as follows: Melville [2], Rui [3], Ziqiong [4], Songho [5], Qiang [6] and Smeureanu [7] used na\u00efve bayes for classification of text. Na\u00efve bayes is one of the most popular method in text classification. It is considered as one of the most simple and efficient approaches in NLP. It works by calculating the probability of an element being in a category. First the prior probability is calculated which is afterwards multiplied with the likelihood to calculate the final probability. The method assumes every word in the sentence to be independent which makes it easier to implement but less accurate. That\u2019s why the method is given the name \u2018na\u00efve\u2019. Rui [3], Ziqiong [4], Songho [5], and Rudy [8] used SVM (Support Vector Machines) in their approach. The sentiment classification was done using discriminative classifier. This approach is based on structural risk minimization in which support vectors are used to classify the training data sets into two different classes based on a predefined criteria. Multiclass SVM can also be used for text classification [9]. Songho [5] used centroid classifier which assign a centroid vector to different training classes and then uses this vector to calculate the similarity values of each element with a class. If the similarity value exceeds a defined threshold then the element is assigned to that class (polarity in this case).\nSongho [5] also used K-Nearest Neighbor (KNN) approach which finds \u2018K\u2019 nearest neighbours of a text document among the documents in the training data set. Then classification is performed on the basis of similarity score of a class with respect to a neighbour. Some approaches use prediction method. Winnow first predicts a class for an entity and then feedback is used to check for mistakes. The weight vectors are changed according to the feedback and the process is repeated over a large training data set. A combined approach was proposed based on included rule classification, machine learning and supervised learning [8]. Each training set was subjected to a 10 fold cross validation process. Several classifiers were used in series. Whenever a classifier failed, the text was passed on to the next classifier until all the texts are classified or there are no remaining classifiers Rui [3] used Ensemble technique which combines the output of several classification methods into a single integrated output. Another approach based on artificial neural networks was used to divide the document into positive, negative and fuzzy tone [10]. The approach was based on recursive least squares back propagation training algorithm. Long-Sheng [11] used a neural network based approach to combine the advantages of machine learning and information retrieval techniques."}, {"heading": "2.2. Lexicon Based", "text": "Lexicon Based techniques work on an assumption that the collective polarity of a document or sentence is the sum of polarities of the individual words or phrases. Some of the significant works done using this technique are: Kamps [12] used a simple technique based on lexical relations to perform classification of text. Andrea [13] used word net to classify the text using an assumption that words with similar polarity have similar orientation. Ting-Chun [14] used an algorithm based on pos (part of speech) patter. A text phrase was used as a query for a search engine and the results were used to classify the text. Prabhu [15] which used a simple lexicon based technique to extract sentiments from twitter data Turney [19] used semantic orientation on user reviews to identify the underlying sentiments. Taboada [20] used lexicon based approach to extract sentiments from microblogs. Sentiment analysis for microblogs is more challenging because of problems like use of short length status message, informal words, word shortening, spelling variation and emoticons. Twitter data was used for sentiment analysis by [21]. Negation word can reverse the polarity of any sentence. Taboada [20] performed sentiment analysis while handling negation and intensifying words. Role of negation was surveyed by [25]. Minquing [26] classified the text using a simple lexicon based approach with feature detection. It was observed that most of these existing techniques doesn\u2019t scale to big data sets efficiently. While various machine learning methodologies exhibits better accuracy than lexicon based techniques, they take more time in training the algorithm and hence are not suitable for big data sets. In this paper, lexicon based approach is used to classify the text according to polarity."}, {"heading": "3. PROPOSED APPROACH", "text": "As explained earlier the focus of this research was to device an approach that can perform sentiment analysis quicker because vast amount of data needed to be analyzed. Also, it had to be made sure that accuracy is not compromised too much while focusing on speed. The proposed approach is a lexicon based technique i.e. a dictionary of sentiment bearing words along with their polarities was used to classify the text into positive, negative or neutral opinion. Machine learning techniques are not used because although they are more accurate than the lexicon based approaches, they take far too much time performing sentiment analysis as they have to be trained first and hence are not efficient in handling big sentiment data. The main component of this approach is the sentiment lexicon or dictionary."}, {"heading": "3.1. Sentiment Lexicon", "text": "Unlike the small sized dictionaries which are used in other approaches, which are build up from a small set of words using a training data set, the dictionary used in this technique contains a large set of sentiment bearing words along with their polarity. The dictionary is domain specific i.e. the polarities of the words in the dictionary are set according to a specific domain e.g. book reviews, political blogs etc. Same word in different domains can have different meanings, the dictionary used in this approach is made for movie review domain. The dictionary contains all forms of a word i.e. every word is stored along with its various verb forms e.g. applause, applauding, applauded, applauds. Hence eliminating the need for stemming each word which saves more time. Emoticons are generally used by people to depict emotions. Hence it is obvious that they contain very useful sentiment information in them. The dictionary used in the approach contains more than 30 different emoticons along with their polarities. The Dictionary also contains the strength of the polarity of every word. Some word depicts stronger emotions than others. For example good and great are both positive words but great depicts a much stronger emotion. Negation and blind negation are very important in identifying the sentiments, as their presence can reverse the polarity of the sentence. The dictionary used here also contains various negation and blind negation words so that they can be identified in the sentence. The dictionary contains several different adjectives, nouns, negation words, emoticons etc. Some of these words are shown as an example in table 1.\nstrongsubj require verb n blindnegation\nstrongsubj not advb n negation strongsubj neither conj n negation strongsubj nor conj n negation strongsubj :) emoti n positive\nstrongsubj :( emoti n negative"}, {"heading": "3.2. Feature detection using Twitter hashtags", "text": "A hashtag is a word or an unspaced phrase prefixed with the number sign (\"#\"). It is a form of metadata tag. Words in messages on microblogging and social networking services such as Twitter, Facebook, Google+ or Instagram may be tagged by putting \"#\" before them, either as they appear in a sentence or they are appended to it. In this research, twitter data is categorized according to polarity. Detecting the subject towards which the sentiment is directed is a tedious task to perform, but as twitter is used as data source hashtags can be used to easily identify the subject hence eliminating the need for using a complex mechanism for feature detection thereby saving time and effort."}, {"heading": "3.3. Handling negation and blind negation", "text": "Negation words are the words which reverse the polarity of the sentiment involved in the text. For example \u2018the movie was not good\u2019. Although the word \u2018good\u2019 depicts a positive sentiment the negation \u2013 \u2018not\u2019 reverses its polarity. In the proposed approach whenever a negation word is encountered in a tweet, its polarity is reversed. Blind negation words are the words which operates on the sentence level and points out a feature that is desired in a product or service. For example in the sentence \u2018the acting needed to be better\u2019, \u2018better\u2019 depicts a positive sentiment but the presence of the blind negation word- \u2018needed\u2019 suggests that this sentence is actually depicting negative sentiment. In the proposed approach whenever a blind negation word occurs in a sentence its polarity is immediately labelled as negative."}, {"heading": "3.4. Sentiment Calculation", "text": "Sentiment calculation is done for every tweet and a polarity score is given to it. If the score is greater than 0 then it is considered to be positive sentiment on behalf of the user, if less than 0 then negative else neutral. The polarity score is calculated by using algorithm 1. Algorithm 1: ALGO_SENTICAL\nInput: Tweets, SentiWord_Dictionary Output: Sentiment (positive, negative or neutral) 1) BEGIN 2) For each tweet Ti 3) { 4) SentiScore = 0; 5) For each word Wj in Ti that exists in Sentiword_Dictionary 6) { 7) If polarity[Wj] = blindnegation\n8) { 9) Return negative; 10) } 11) Else 12) { 13) If polarity[Wj] = positive && strength[Wj] = Strongsubj 14) { 15) SentiScore = SentiScore + 1; 16) } 17) Else If polarity[Wj] = positive && strength[Wj] = Weaksubj 18) { 19) SentiScore = SentiScore + 0.5; 20) } 21) Else If polarity[Wj] = negative && strength[Wj] = Strongsubj 22) { 23) SentiScore = SentiScore \u2013 1; 24) } 25) Else If polarity[Wj] = negative && strength[Wj] = Weaksubj 26) { 27) SentiScore = SentiScore \u2013 0.5; 28) } 29) } 30) If polarity[Wj] = negation 31) { 32) Sentiscore = Sentiscore * -1 33) } 34) } 35) If Sentiscore of Ti >0 36) { 37) Sentiment = positive 38) } 39) Else If Sentiscore of TI<0 40) { 41) Sentiment = negative 42) } 43) Else 44) { 45) Sentiment = neutral 46) } 47) Return Sentiment 48) } 49) END"}, {"heading": "4. PERFORMANCE EVALUATION", "text": "In this section, description of the tools which were used to perform sentiment analysis is given along with the performance of the approach and its comparison with existing approaches."}, {"heading": "4.1. Experimental Setup", "text": "The proposed algorithm was implemented using a sandboxed version of Hadoop. Hadoop is designed to work in a huge multimode environment consisting of thousands of servers situated at\ndifferent locations. But for research purposes often a single node virtual environment is used that creates an illusion of several nodes which are situated at different locations and are working together. An Intel Core i5-3210M CPU@2.50GHz processor with 6 GB memory was used to simulate the Hadoop Environment. Data was imported from Twitter using Flume, a distributed, reliable, and available service for efficiently collecting, aggregating, and moving large amounts of streaming data into the Hadoop Distributed File System (HDFS). Then the data is refined and the algorithm described in the previous section is implemented upon it with the help of HiveQL. HiveQL is an SQL like language which is used in hadoop for interacting and manipulating huge databases."}, {"heading": "4.2. Results and Evaluation", "text": "As explained earlier the purpose of this research was to device a method that can quickly compute the sentiments of huge data sets without compromising too much with accuracy. The proposed approach has performed very well in terms of speed. It took 14.8 Seconds to analyse the sentiments behind 6,74,412 tweets. Table 1 shows the performance of the algorithm. Moreover the speed can be substantially improved by using an actual multimode hadoop environment instead of a single node sandboxed configuration. The algorithm also performed very well in terms of accuracy. Tweets were analyzed with an accuracy of 73.5 %. As expected it is not as high as the machine learning methodologies but it shows a fairly good accuracy when compared with other lexicon based approaches. Figure 1 shows a comparison between average accuracies of machine learning and lexicon based techniques discussed in section II and the accuracy of the proposed approach.\nTable 2 Performance of the proposed approach\nNumber of Tweets Time Taken Accuracy\n6,74,412 14.8 seconds 73.5 %\nFigure 1. Comparison of the proposed approach with other methodologies"}, {"heading": "5. CONCLUSION AND FUTURE WORK", "text": "Sentiment analysis is being used for different applications and can be used for several others in future. It is evident that its applications will definitely expand to more areas and will continue to encourage more and more researches in the field. We have done an overview of some state-ofthe-art solutions applied to sentiment classification and provided a new approach that scales to big data sets efficiently. A scalable and practical lexicon based approach for extracting sentiments using emoticons and hashtags is introduced. Hadoop was used to classify Twitter data without need for any kind of training. Our approach performed extremely well in terms of both speed and accuracy while showing signs that it can be further scaled to much bigger data sets with similar, in fact better performance. In this research, main focus was on performing sentiment analysis quickly so that big data sets can be handled efficiently. The work can be further expanded by introducing techniques that increase the accuracy by tackling problems like thwarted expressions and implicit sentiments which still needs to be resolved properly. Also as explained earlier, this work was implemented on a single node sandboxed configuration and although it is expected that it will perform much better in a multimode enterprise level configuration, it is desirable to check its performance in such environment in future."}], "references": [{"title": "Sentiment Analysis and Subjectivity", "author": ["B. Liu"], "venue": "Handbook of Natural Language Processing, Second Edition, (editors: N. Indurkhya and F. J. Damerau),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "Gryc, \u201cSentiment Analysis of Blogs by Combining Lexical Knowledge with Text Classification\u201d, KDD\u201f09", "author": ["Melville", "Wojciech"], "venue": "June 28\u2013July", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Ensemble of feature sets and classification algorithms for sentiment classification", "author": ["Rui Xia", "Chengqing Zong", "Shoushan Li"], "venue": "Information Sciences", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Sentiment classification of Internet restaurant reviews written in Cantonese\u201d, Expert Systems with Applications xxx (2011) xxx\u2013xxx", "author": ["Ziqiong Zhang", "Qiang Ye", "Zili Zhang", "Yijun Li"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "An empirical study of sentiment analysis for chinese documents", "author": ["Songbo Tan", "Jin Zhang"], "venue": "Expert Systems with Applications", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "BUCUR, \u201cApplying Supervised Opinion Mining Techniques on Online User Reviews", "author": ["Ion SMEUREANU", "Cristian"], "venue": "Informatica Economica\u0306 vol. 16,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Sentiment analysis: A combined approach.", "author": ["Rudy Prabowo", "Mike Thelwall"], "venue": "Journal of Informetrics", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2009}, {"title": "Mining comparative opinions from customer reviews for Competitive Intelligence", "author": ["Kaiquan Xu", "Stephen Shaoyi Liao", "Jiexun Li", "Yuxia Song"], "venue": "Decision Support Systems", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "Sentiment classification using the theory of ANNs", "author": ["ZHU Jian", "XU Chen", "WANG Han-shi"], "venue": "The Journal of China Universities of Posts and Telecommunications,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "A neural network based approach for sentiment classification in the blogosphere", "author": ["Long-Sheng Chen", "Cheng-Hsiang Liu", "Hui-Ju Chiu"], "venue": "Journal of Informetrics", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Using wordnet to measure semantic orientation of adjectives", "author": ["Kamps", "Maarten Marx", "Robert J. Mokken", "Maarten De Rijke"], "venue": "Proceedings of 4th International Conference on Language Resources and Evaluation,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2004}, {"title": "Determining the semantic orientation of terms through gloss classification", "author": ["Andrea Esuli", "Fabrizio Sebastiani"], "venue": "Proceedings of 14th ACM International Conference on Information and Knowledge", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2005}, {"title": "Serendio: Simple and Practical lexicon based approach to Sentiment Analysis", "author": ["Prabu Palanisamy", "Vineet Yadav", "Harsha Elchuri"], "venue": "Serendio Software Pvt Ltd,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "Discriminative learning for differing training and test distributions", "author": ["Bickel", "S.Bruckner", "M. Scheffer"], "venue": "International Conference on Machine Learning,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2007}, {"title": "Sentiment analysis: Adjectives and adverbs are better than adjectives alone", "author": ["Benamara", "Farah", "Carmine Cesarano", "Antonio Picariello", "Diego Reforgiato", "VS Subrahmanian"], "venue": "International Conference on Weblogs and Social Media,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}, {"title": "Measuring praise and criticism: Inference of semantic orientationfrom association", "author": ["Peter Turney", "Michael Littman"], "venue": "ACM Transactions on Information Systems", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2003}, {"title": "Lexiconbased methods for sentiment analysis", "author": ["Maite Taboada", "Julian Brooke", "Milan Tofiloski", "Kimberly Voll", "Manfred Stede"], "venue": "Computational linguistics,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Sentiment knowledge discovery in twitter streaming data, DiscoveryScience", "author": ["Albert Bifet", "Eibe Frank"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2010}, {"title": "Lexical normalisation of short text messages: Makn sens a# twitter.Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language", "author": ["Bo Han", "Timothy Baldwin"], "venue": "Technologies Volume", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "Syntactic normalization of Twitter messages", "author": ["Max Kaufmann", "Jugal Kalita"], "venue": "International Conference on Natural Language Processing", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2010}, {"title": "Enhanced sentiment learning using twitter hashtagsand smileys", "author": ["Dmitry Davidov", "Oren Tsur", "Ari Rappoport"], "venue": "Proceedings of the 23rd International Conference on Computational Linguistics", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2010}, {"title": "A survey on the role of negation in sentiment analysis. Proceedings of the workshop on negation and speculation in natural language processing 60\u201368, Association for Computational Linguistics", "author": ["Michael Wiegand", "Alexandra Balahur", "Benjamin Roth", "Dietrich Klakow", "Andr \u0301es Montoyo"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "Liu [1] defined a sentiment as a quintuple \u201c<oj, fjk, soijkl, hi, tl >, where oj is a target object, fjk is a feature of the object oj, soijkl is the sentiment value of the opinion of the opinion holder hi on feature fjk of object oj at time tl, soijkl is +ve, -ve, or neutral, or a more granular rating, hi is an opinion holder, tl is the time when the opinion is expressed.", "startOffset": 4, "endOffset": 7}, {"referenceID": 1, "context": "Melville [2], Rui [3], Ziqiong [4], Songho [5], Qiang [6] and Smeureanu [7] used na\u00efve bayes for classification of text.", "startOffset": 9, "endOffset": 12}, {"referenceID": 2, "context": "Melville [2], Rui [3], Ziqiong [4], Songho [5], Qiang [6] and Smeureanu [7] used na\u00efve bayes for classification of text.", "startOffset": 18, "endOffset": 21}, {"referenceID": 3, "context": "Melville [2], Rui [3], Ziqiong [4], Songho [5], Qiang [6] and Smeureanu [7] used na\u00efve bayes for classification of text.", "startOffset": 31, "endOffset": 34}, {"referenceID": 4, "context": "Melville [2], Rui [3], Ziqiong [4], Songho [5], Qiang [6] and Smeureanu [7] used na\u00efve bayes for classification of text.", "startOffset": 43, "endOffset": 46}, {"referenceID": 5, "context": "Melville [2], Rui [3], Ziqiong [4], Songho [5], Qiang [6] and Smeureanu [7] used na\u00efve bayes for classification of text.", "startOffset": 72, "endOffset": 75}, {"referenceID": 2, "context": "Rui [3], Ziqiong [4], Songho [5], and Rudy [8] used SVM (Support Vector Machines) in their approach.", "startOffset": 4, "endOffset": 7}, {"referenceID": 3, "context": "Rui [3], Ziqiong [4], Songho [5], and Rudy [8] used SVM (Support Vector Machines) in their approach.", "startOffset": 17, "endOffset": 20}, {"referenceID": 4, "context": "Rui [3], Ziqiong [4], Songho [5], and Rudy [8] used SVM (Support Vector Machines) in their approach.", "startOffset": 29, "endOffset": 32}, {"referenceID": 6, "context": "Rui [3], Ziqiong [4], Songho [5], and Rudy [8] used SVM (Support Vector Machines) in their approach.", "startOffset": 43, "endOffset": 46}, {"referenceID": 7, "context": "Multiclass SVM can also be used for text classification [9].", "startOffset": 56, "endOffset": 59}, {"referenceID": 4, "context": "Songho [5] used centroid classifier which assign a centroid vector to different training classes and then uses this vector to calculate the similarity values of each element with a class.", "startOffset": 7, "endOffset": 10}, {"referenceID": 4, "context": "37 Songho [5] also used K-Nearest Neighbor (KNN) approach which finds \u2018K\u2019 nearest neighbours of a text document among the documents in the training data set.", "startOffset": 10, "endOffset": 13}, {"referenceID": 6, "context": "A combined approach was proposed based on included rule classification, machine learning and supervised learning [8].", "startOffset": 113, "endOffset": 116}, {"referenceID": 2, "context": "Whenever a classifier failed, the text was passed on to the next classifier until all the texts are classified or there are no remaining classifiers Rui [3] used Ensemble technique which combines the output of several classification methods into a single integrated output.", "startOffset": 153, "endOffset": 156}, {"referenceID": 8, "context": "Another approach based on artificial neural networks was used to divide the document into positive, negative and fuzzy tone [10].", "startOffset": 124, "endOffset": 128}, {"referenceID": 9, "context": "Long-Sheng [11] used a neural network based approach to combine the advantages of machine learning and information retrieval techniques.", "startOffset": 11, "endOffset": 15}, {"referenceID": 10, "context": "Kamps [12] used a simple technique based on lexical relations to perform classification of text.", "startOffset": 6, "endOffset": 10}, {"referenceID": 11, "context": "Andrea [13] used word net to classify the text using an assumption that words with similar polarity have similar orientation.", "startOffset": 7, "endOffset": 11}, {"referenceID": 12, "context": "Prabhu [15] which used a simple lexicon based technique to extract sentiments from twitter data Turney [19] used semantic orientation on user reviews to identify the underlying sentiments.", "startOffset": 7, "endOffset": 11}, {"referenceID": 15, "context": "Prabhu [15] which used a simple lexicon based technique to extract sentiments from twitter data Turney [19] used semantic orientation on user reviews to identify the underlying sentiments.", "startOffset": 103, "endOffset": 107}, {"referenceID": 16, "context": "Taboada [20] used lexicon based approach to extract sentiments from microblogs.", "startOffset": 8, "endOffset": 12}, {"referenceID": 17, "context": "Twitter data was used for sentiment analysis by [21].", "startOffset": 48, "endOffset": 52}, {"referenceID": 16, "context": "Taboada [20] performed sentiment analysis while handling negation and intensifying words.", "startOffset": 8, "endOffset": 12}, {"referenceID": 21, "context": "Role of negation was surveyed by [25].", "startOffset": 33, "endOffset": 37}], "year": 2014, "abstractText": "Rapid increase in the volume of sentiment rich social media on the web has resulted in an increased interest among researchers regarding Sentimental Analysis and opinion mining. However, with so much social media available on the web, sentiment analysis is now considered as a big data task. Hence the conventional sentiment analysis approaches fails to efficiently handle the vast amount of sentiment data available now a days. The main focus of the research was to find such a technique that can efficiently perform sentiment analysis on big data sets. A technique that can categorize the text as positive, negative and neutral in a fast and accurate manner. In the research, sentiment analysis was performed on a large data set of tweets using Hadoop and the performance of the technique was measured in form of speed and accuracy. The experimental results shows that the technique exhibits very good efficiency in handling big sentiment data sets.", "creator": null}}}