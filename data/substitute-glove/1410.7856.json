{"id": "1410.7856", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Oct-2014", "title": "A Statistical Decision-Theoretic Framework for Social Choice", "abstract": "In. making, does does giving epidemiological give - pre-defined contradiction opened ideas choice, putting similar focus where the will they be up on claim between a systems especially smugglers. In means framework, not often given a department ranking model, a decision space, and in loss wherein distinction off (formula_37, decision) pairs, such formulate context but inhibit as consider subject did vulnerability planned loss. This instance puts general solution not one design only examining part house social choice protocols. We surely Bayesian covariance, which minimize Bayesian reach combined, for the Mallows model still now Condorcet concept respectively, such the Kemeny passed. We consider various heterodox properties, in addition with computational complexity both asymptotic physical. In particular, we theme made where Bayesian estimator for is Condorcet conventional probability some desired types primarily another comment, safeguarding, same shelvock, if be decomposition throughout formula_45 came, often is similis typically half it mainly two stringent during the data are generates which several Condorcet design for all ground true parameter.", "histories": [["v1", "Wed, 29 Oct 2014 01:46:50 GMT  (166kb,D)", "https://arxiv.org/abs/1410.7856v1", "Full version of a NIPS-14 paper under the same title"], ["v2", "Sat, 12 Mar 2016 05:11:50 GMT  (166kb,D)", "http://arxiv.org/abs/1410.7856v2", "Full version of a NIPS-14 paper under the same title, fixed a typo in Theorem 1"]], "COMMENTS": "Full version of a NIPS-14 paper under the same title", "reviews": [], "SUBJECTS": "cs.AI cs.MA", "authors": ["hossein azari soufiani", "david c parkes", "lirong xia"], "accepted": true, "id": "1410.7856"}, "pdf": {"name": "1410.7856.pdf", "metadata": {"source": "CRF", "title": "A Statistical Decision-Theoretic Framework for Social Choice", "authors": ["Hossein Azari Soufiani", "David C. Parkes", "Lirong Xia"], "emails": ["azari@google.com,", "parkes@eecs.harvard.edu,"], "sections": [{"heading": "1 Introduction", "text": "Social choice studies the design and evaluation of voting rules (or rank aggregation rules). There have been two main perspectives: reach a compromise among subjective preferences of agents, or make an objectively correct decision. The former has been extensively studied in classical social choice in the context of political elections, while the latter is relatively less developed, even though it can be dated back to the Condorcet Jury Theorem in the 18th century [9].\nIn many multi-agent and social choice scenarios the main consideration is to achieve the second objective, and make an objectively correct decision. Meanwhile, we also want to respect agents\u2019 preferences and opinions, and require the voting rule to satisfy well-established normative properties in social choice. For example, when a group of friends vote to choose a restaurant for dinner, perhaps the most important goal is to find an objectively good restaurant, but it is also important to use a good voting rule in the social choice sense. Even for applications with less societal context, e.g. using voting rules to aggregate rankings in meta-search engines [12], recommender systems [15], crowdsourcing [23], semantic webs [27], some social choice normative properties are still desired. For example, monotonicity may be desired, which requires that raising the position of an alternative in any vote does not hurt the alternative in the outcome of the voting rule. In addition, we require voting rules to be efficiently computable.\nSuch scenarios propose the following new challenge: How can we design new voting rules with good statistical properties as well as social choice normative properties?\nTo tackle this challenge, we develop a general framework that adopts statistical decision theory [3]. Our approach couples a statistical ranking model with an explicit decision space and loss function. \u2217azari@google.com, Google Research, New York, NY 10011, USA. The work was done when the author was at Harvard University. \u2020parkes@eecs.harvard.edu, Harvard University, Cambridge, MA 02138, USA. \u2021xial@cs.rpi.edu, Rensselaer Polytechnic Institute, Troy, NY 12180, USA.\nar X\niv :1\n41 0.\n78 56\nv2 [\ncs .A\nI] 1\n2 M\nar 2\n01 6\nGiven these, we can adopt Bayesian estimators as social choice mechanisms, which make decisions to minimize the expected loss w.r.t. the posterior distribution on the parameters (called the Bayesian risk). This provides a principled methodology for the design and analysis of new voting rules.\nTo show the viability of the framework, we focus on selecting multiple alternatives (the alternatives that can be thought of as being \u201ctied\u201d for the first place) under a natural extension of the 0-1 loss function for two models: letM1\u03d5 denote the Mallows model with fixed dispersion [22], and letM2\u03d5 denote the Condorcet model proposed by Condorcet in the 18th century [9, 34]. In both models the dispersion parameter, denoted \u03d5, is taken as a fixed parameter. The difference is that in the Mallows model the parameter space is composed of all linear orders over alternatives, while in the Condorcet model the parameter space is composed of all possibly cyclic rankings over alternatives (irreflexive, antisymmetric, and total binary relations).M2\u03d5 is a natural model that captures real-world scenarios where the ground truth may contain cycles, or agents\u2019 preferences are cyclic, but they have to report a linear order due to the protocol. More importantly, as we will show later, a Bayesian estimator on M2\u03d5 is superior from a computational viewpoint. Through this approach, we obtain two voting rules as Bayesian estimators and then evaluate them with respect to various normative properties, including anonymity, neutrality, monotonicity, the majority criterion, the Condorcet criterion and consistency. Both rules satisfy anonymity, neutrality, and monotonicity, but fail the majority criterion, Condorcet criterion,1 and consistency. Admittedly, the two rules do not enjoy outstanding normative properties, but they are not bad either. We also investigate the computational complexity of the two rules. Strikingly, despite the similarity of the two models, the Bayesian estimator forM2\u03d5 can be computed in polynomial time, while computing the Bayesian estimator forM1\u03d5 is P NP || -hard, which means that it is at least NP-hard. Our results are summarized in Table 1.\nWe also compare the asymptotic outcomes of the two rules with the Kemeny rule for winners, which is a natural extension of the maximum likelihood estimator of M1\u03d5 proposed by Fishburn [14]. It turns out that when n votes are generated underM1\u03d5, all three rules select the same winner asymptotically almost surely (a.a.s.) as n \u2192 \u221e. When the votes are generated according toM2\u03d5, the rule forM1\u03d5 still selects the same winner as Kemeny a.a.s.; however, for some parameters, the winner selected by the rule forM2\u03d5 is different with non-negligible probability. These are confirmed by experiments on synthetic datasets.\nRelated work. Along the second perspective in social choice (to make an objectively correct decision), in addition to Condorcet\u2019s statistical approach to social choice [9, 34], most previous work in economics, political science, and statistics focused on extending the theorem to heterogeneous, correlated, or strategic agents for two alternatives, see [25, 1] among many others. Recent work in computer science views agents\u2019 votes as i.i.d. samples from a statistical model, and computes the MLE to estimate the parameters that maximize the likelihood [10, 11, 33, 32, 2, 29, 7]. A limitation of these approaches is that they estimate the parameters of the model, but may not directly inform the right decision to make in the multi-agent context. The main approach has been to return the modal rank order implied by the estimated parameters, or the alternative with the highest, predicted marginal probability of being ranked in the top position.\nThere have also been some proposals to go beyond MLE in social choice. In fact, Young [34] proposed to select a winning alternative that is \u201cmost likely to be the best (i.e., top-ranked in the true ranking)\u201d and provided formulas to compute it for three alternatives. This idea has been formalized\n1The new voting rule forM1\u03d5 fails them for all \u03d5 < 1/ \u221a 2.\nand extended by Procaccia et al. [29] to choose a given number of alternatives with highest marginal probability under the Mallows model. More recently, independent to our work, Elkind and Shah [13] investigated a similar question for choosing multiple winners under the Condorcet model. We will see that these are special cases of our proposed framework in Example 2. Pivato [26] conducted a similar study to Conitzer and Sandholm [10], examining voting rules that can be interpreted as expect-utility maximizers.\nWe are not aware of previous work that frames the problem of social choice from the viewpoint of statistical decision theory, which is our main conceptual contribution. Technically, the approach taken in this paper advocates a general paradigm of \u201cdesign by statistics, evaluation by social choice and computer science\u201d. We are not aware of a previous work following this paradigm to design and evaluate new rules. Moreover, the normative properties for the two voting rules investigated in this paper are novel, even though these rules are not really novel. Our result on the computational complexity of the first rule strengthens the NP-hardness result by Procaccia et al. [29], and the complexity for the second rule (Theorem 5) was independently discovered by Elkind and Shah [13].\nThe statistical decision-theoretic framework is quite general, allowing considerations such as estimators that minimize the maximum expected loss, or the maximum expected regret [3]. In a different context, focused on uncertainty about the availability of alternatives, Lu and Boutilier [20] adopt a decision-theoretic view of the design of an optimal voting rule. Caragiannis et al. [8] studied the robustness of social choice mechanisms w.r.t. model uncertainty, and characterized a unique social choice mechanism that is consistent w.r.t. a large class of ranking models.\nA number of recent papers in computational social choice take utilitarian and decision-theoretical approaches towards social choice [28, 6, 4, 5]. Most of them evaluate the joint decision w.r.t. agents\u2019 subjective preferences, for example the sum of agents\u2019 subjective utilities (i.e. the social welfare). We don\u2019t view this as fitting into the classical approach to statistical decision theory as formulated by Wald [30]. In our framework, the joint decision is evaluated objectively w.r.t. the ground truth in the statistical model. Several papers in machine learning developed algorithms to compute MLE or Bayesian estimators for popular ranking models [18, 19, 21], but without considering the normative properties of the estimators."}, {"heading": "2 Preliminaries", "text": "In social choice, we have a set of m alternatives C = {c1, . . . , cm} and a set of n agents. Let L(C) denote the set of all linear orders over C. For any alternative c, let Lc(C) denote the set of linear orders over C where c is ranked at the top. Agent j uses a linear order Vj \u2208 L(C) to represent her preferences, called her vote. The collection of agents votes is called a profile, denoted by P = {V1, . . . , Vn}. A (irresolute) voting rule r : L(C)n \u2192 (2C \\ \u2205) selects a set of winners that are \u201ctied\u201d for the first place for every profile of n votes.\nFor any pair of linear orders V,W , let Kendall(V,W ) denote the Kendall-tau distance between V and W , that is, the number of different pairwise comparisons in V and W . The Kemeny rule (a.k.a. Kemeny-Young method) [17, 35] selects all linear orders with the minimum Kendall-tau distance from the preference profile P , that is, Kemeny(P ) = arg minW Kendall(P,W ). The most well-known variant of Kemeny to select winning alternatives, denoted by KemenyC , is due to Fishburn [14], who defined it as a voting rule that selects all alternatives that are ranked in the top position of some winning linear orders under the Kemeny rule. That is, KemenyC(P ) = {top(V ) : V \u2208 Kemeny(P )}, where top(V ) is the top-ranked alternative in V . Voting rules are often evaluated by the following normative properties. An irresolute rule r satisfies:\n\u2022 anonymity, if r is insensitive to permutations over agents; \u2022 neutrality, if r is insensitive to permutations over alternatives; \u2022 monotonicity, if for any P , c \u2208 r(P ), and any P \u2032 that is obtained from P by only raising the positions of c in one or multiple votes, then c \u2208 r(P \u2032); \u2022 Condorcet criterion, if for any profile P where a Condorcet winner exists, it must be the unique winner. A Condorcet winner is the alternative that beats every other alternative in pair-wise elections.\n\u2022 majority criterion, if for any profile P where an alternative c is ranked in the top positions for more than half of the votes, then r(P ) = {c}. If r satisfies Condorcet criterion then it also satisfies the majority criterion.\n\u2022 consistency, if for any pair of profiles P1, P2 with r(P1)\u2229r(P2) 6= \u2205, r(P1\u222aP2) = r(P1)\u2229r(P2). For any profile P , its weighted majority graph (WMG), denoted by WMG(P ), is a weighted directed graph whose vertices are C, and there is an edge between any pair of alternatives (a, b) with weight wP (a, b) = #{V \u2208 P : a V b} \u2212#{V \u2208 P : b V a}. A parametric modelM = (\u0398,S,Pr) is composed of three parts: a parameter space \u0398, a sample space S composing of all datasets, and a set of probability distributions over S indexed by elements of \u0398: for each \u03b8 \u2208 \u0398, the distribution indexed by \u03b8 is denoted by Pr(\u00b7|\u03b8).2\nGiven a parametric modelM, a maximum likelihood estimator (MLE) is a function fMLE : S \u2192 \u0398 such that for any data P \u2208 S, fMLE(P ) is a parameter that maximizes the likelihood of the data. That is, fMLE(P ) \u2208 arg max\u03b8\u2208\u0398 Pr(P |\u03b8). In this paper we focus on parametric ranking models. Given C, a parametric ranking modelMC = (\u0398,Pr) is composed of a parameter space \u0398 and a distribution Pr(\u00b7|\u03b8) over L(C) for each \u03b8 \u2208 \u0398, such that for any number of voters n, the sample space is Sn = L(C)n, where each vote is generated i.i.d. from Pr(\u00b7|\u03b8). Hence, for any profile P \u2208 Sn and any \u03b8 \u2208 \u0398, we have Pr(P |\u03b8) =\u220f V \u2208P Pr(V |\u03b8). We omit the sample space because it is determined by C and n. Definition 1 In the Mallows model [22], a parameter is composed of a linear order W \u2208 L(C) and a dispersion parameter \u03d5 with 0 < \u03d5 < 1. For any profile P and \u03b8 = (W,\u03d5), Pr(P |\u03b8) =\u220f V \u2208P 1 Z\u03d5 Kendall(V,W ), where Z is the normalization factor with Z = \u2211 V \u2208L(C) \u03d5 Kendall(V,W ).\nStatistical decision theory [30, 3] studies scenarios where the decision maker must make a decision d \u2208 D based on the data P generated from a parametric model, generallyM = (\u0398,S,Pr). The quality of the decision is evaluated by a loss functionL : \u0398\u00d7D \u2192 R, which takes the true parameter and the decision as inputs.\nIn this paper, we focus on the Bayesian principle of statistical decision theory to design social choice mechanisms as choice functions that minimize the Bayesian risk under a prior distribution over \u0398. More precisely, the Bayesian risk, RB(P, d), is the expected loss of the decision d when the parameter is generated according to the posterior distribution given data P . That is, RB(P, d) = E\u03b8|PL(\u03b8, d). Given a parametric model M, a loss function L, and a prior distribution over \u0398, a (deterministic) Bayesian estimator fB is a decision rule that makes a deterministic decision in D to minimize the Bayesian risk, that is, for any P \u2208 S , fB(P ) \u2208 arg mindRB(P, d). We focus on deterministic estimators in this work and leave randomized estimators for future research. Example 1 When \u0398 is discrete, an MLE of a parametric modelM is a Bayesian estimator of the statistical decision problem (M,D = \u0398, L0-1) under the uniform prior distribution, where L0-1 is the 0-1 loss function such that L0-1(\u03b8, d) = 0 if \u03b8 = d, otherwise L0-1(\u03b8, d) = 1.\nIn this sense, all previous MLE approaches in social choice can be viewed as the Bayesian estimators of a statistical decision-theoretic framework for social choice whereD = \u0398, a 0-1 loss function, and the uniform prior."}, {"heading": "3 Our Framework", "text": "Our framework is quite general and flexible because we can choose any parametric ranking model, any decision space, any loss function, and any prior to use the Bayesian estimators social choice mechanisms. Common choices of both \u0398 and D are L(C), C, and (2C \\ \u2205). Definition 2 A statistical decision-theoretic framework for social choice is a tuple F = (MC ,D, L), where C is the set of alternatives, MC = (\u0398,Pr) is a parametric ranking model, D is the decision space, and L : \u0398\u00d7D \u2192 R is a loss function.\nLet B(C) denote the set of all irreflexive, antisymmetric, and total binary relations over C. For any c \u2208 C, let Bc(C) denote the relations in B(C) where c a for all a \u2208 C \u2212 {c}. It follows\n2This notation should not be taken to mean a conditional distribution over S unless we are taking a Bayesian point of view.\nthat L(C) \u2286 B(C), and moreover, the Kendall-tau distance can be defined to count the number of pairwise disagreements between elements of B(C). In the rest of the paper, we focus on the following two parametric ranking models, where the dispersion is a fixed parameter. Definition 3 (Mallows model with fixed dispersion, and the Condorcet model) Let M1\u03d5 denote the Mallows model with fixed dispersion, where the parameter space is \u0398 = L(C) and given any W \u2208 \u0398, Pr(\u00b7|W ) is Pr(\u00b7|(W,\u03d5)) in the Mallows model, where \u03d5 is fixed. In the Condorcet model,M2\u03d5, the parameter space is \u0398 = B(C). For any W \u2208 \u0398 and any profile P , we have Pr(P |W ) = \u220f V \u2208P ( 1 Z\u03d5 Kendall(V,W ) ) , where Z is the normalization factor such that\nZ = \u2211 V \u2208B(C) \u03d5 Kendall(V,W ), and parameter \u03d5 is fixed.3\nM1\u03d5 and M2\u03d5 degenerate to the Condorcet model for two alternatives [9]. The Kemeny rule that selects a linear order is an MLE ofM1\u03d5 for any \u03d5.\nWe now formally define two statistical decision-theoretic frameworks associated withM1\u03d5 andM2\u03d5, which are the focus of the rest of our paper. Definition 4 For \u0398 = L(C) or B(C), any \u03b8 \u2208 \u0398, and any c \u2208 C, we define a loss function Ltop(\u03b8, c) such that Ltop(\u03b8, c) = 0 if for all b \u2208 C, c b in \u03b8; otherwise Ltop(\u03b8, c) = 1. Let F1\u03d5 = (M1\u03d5, 2C \\ \u2205, Ltop) and F2\u03d5 = (M2\u03d5, 2C \\ \u2205, Ltop), where for any C \u2286 C, Ltop(\u03b8, C) =\u2211 c\u2208C Ltop(\u03b8, c)/|C|. Let f1B (respectively, f2B) denote the Bayesian estimators of F1\u03d5 (respectively, F2\u03d5) under the uniform prior.\nWe note that Ltop in the above definition takes a parameter and a decision in 2C \\ \u2205 as inputs, which makes it different from the 0-1 loss function L0-1 that takes a pair of parameters as inputs, as the one in Example 1. Hence, f1B and f 2 B are not the MLEs of their respective models, as was the case in Example 1. We focus on voting rules obtained by our framework with Ltop. Certainly our framework is not limited to this loss function. Example 2 Bayesian estimators f1B and f2B coincide with Young [34]\u2019s idea of selecting the alternative that is \u201cmost likely to be the best (i.e., top-ranked in the true ranking)\u201d, under F1\u03d5 and F2\u03d5 respectively. This gives a theoretical justification of Young\u2019s idea and other followups under our framework. Specifically, f1B is similar to rule studied by Procaccia et al. [29] and f 2 B was independently studied by Elkind and Shah [13].\nThe following lemma provides a convenient way to compute the likelihood inM1\u03d5 andM2\u03d5 from the WMG. Lemma 1 InM1\u03d5 (respectively,M2\u03d5), for any W \u2208 L(C) (respectively, W \u2208 B(C)) and any profile P , Pr(P |W ) \u221d \u220f c W b \u03d5 \u2212wP (c,b)/2.\nProof: For any c W b, the number of times b c in P is (n \u2212 wP (c, b))/2, which means that Pr(P |W ) = \u03d5n2(n\u22121)/4 \u220f c W b \u03d5 \u2212wP (c,b)/2."}, {"heading": "4 Normative Properties of Bayesian Estimators", "text": "In this section, we compare f1B , f 2 B , and the Kemeny rule (for alternatives) w.r.t. various normative properties. We will frequently use the following lemma, whose proof follows directly from Bayes\u2019 rule. We recall that Lc(C) is the set of all linear orders where c is ranked in the top, and Bc(C) is the set of binary relations in B(C) where c is ranked in the top. Lemma 2 In F1\u03d5 under the uniform prior, for any profile P and any c, b \u2208 C, RB(P, c) \u2264 RB(P, b) if and only if \u2211 V \u2208Lc(C) Pr(P |V ) \u2265 \u2211 V \u2208Lb(C) Pr(P |V ). In F2\u03d5 under the uniform prior, for any profile P and any c, b \u2208 C, RB(P, c) \u2264 RB(P, b) if and only if \u2211 V \u2208Bc(C) Pr(P |V ) \u2265 \u2211 V \u2208Bb(C) Pr(P |V ).\n3In the Condorcet model the sample space is B(C)n [31]. We study a variant with sample space L(C)n.\nTheorem 1 For any \u03d5, f1B satisfies anonymity, neutrality, and monotonicity. It does not satisfy majority or the Condorcet criterion for all \u03d5 > 1\u221a\n2 ,4 and it does not satisfy consistency.\nProof: Anonymity and neutrality are obviously satisfied.\nMonotonicity. Suppose c \u2208 f1B(P ). To prove that f1B satisfies monotonicity, it suffices to prove that for any profile P \u2032 obtained from P by raising the position of c in one vote, c \u2208 f1B(P \u2032). We first prove the following lemma. Lemma 3 For any c \u2208 C, let P \u2032 denote a profile obtained from P by raising the position of c in one vote. For any W \u2208 Lc(C), Pr(P \u2032|W ) = Pr(P |W )/\u03d5; for any b \u2208 C and any V \u2208 Lb(C), Pr(P \u2032|V ) \u2264 Pr(P |V )/\u03d5. For any W \u2032 \u2208 Bc(L), Pr(P \u2032|W \u2032) \u2264 Pr(P |W \u2032)/\u03d5; for any b \u2208 C and any V \u2032 \u2208 Bb(C), Pr(P \u2032|V \u2032) \u2264 Pr(P |V \u2032)/\u03d5.\nProof: For W \u2208 Lc(C), the lemma holds because Kendall(P \u2032,W ) = Kendall(P,W ) \u2212 1, and for V \u2208 Lb(C), the lemma holds because Kendall(P \u2032, V ) \u2265 Kendall(P, V ) \u2212 1. The proof for Bc and Bb is similar. Therefore, for any b 6= c, by Lemma 3, we have \u2211 W\u2208Lc(C) Pr(P\n\u2032|W ) =\u2211 W\u2208Lc(C) Pr(P |W )/\u03d5 \u2265 \u2211 V \u2208Lb(C) Pr(P |V )/\u03d5 \u2265 \u2211 V \u2208Lb(C) Pr(P\n\u2032|V ), which proves that c \u2208 f1B(P \u2032) following Lemma 2. Majority and the Condorcet criterion. Let C = {c, b, c3, . . . , cm}. We construct a profile P \u2217 where c is ranked in the top positions for more than half of the votes, which means that c is the Condorcet winner, but c 6\u2208 f1B(P ). For any k, let P \u2217 denote a profile composed of k + 1 copies of [c b c3 \u00b7 \u00b7 \u00b7 cm] and k \u2212 1 copies of [b c3 \u00b7 \u00b7 \u00b7 cm c]. It is not hard to verify that the WMG of P \u2217 is as in Figure 1.\nLemma 4 \u2211 V\u2208Lc(C) Pr(P \u2217|V )\u2211\nW\u2208Lb(C) Pr(P\u2217|W ) =\n1+\u03d52k+\u00b7\u00b7\u00b7+\u03d52k(m\u22122) 1+\u03d52+\u00b7\u00b7\u00b7+\u03d52(m\u22122) \u00b7 1 \u03d52\nProof: Let L\u2212c = L \u2212 {c} and let P |\u2212c denote the profile where c is removed from all rankings.\u2211 V \u2208Lc(C) Pr(P \u2217|V ) \u221d\u03d5\u2212m+1 \u2211 V \u2032\u2208L(C\u2212c) \u03d5Kendall(P |\u2212c,V \u2032)\n\u221d\u03d5\u2212m+1 \u2211\nV \u2032\u2208L(C\u2212c) \u220f a,d\u2208C\u2212{c}:a V \u2032d \u03d5\u2212wP\u2217 (a,d)/2\n\u221d\u03d5\u2212m+1 m\u22122\u2211 t=0 ( m\u2212 2 t ) t!(m\u2212 2\u2212 t)!\u03d5kt\u03d5\u2212k(m\u22122\u2212t) (1)\n\u221d\u03d5\u2212(m\u22122)k\u2212m+1 m\u22122\u2211 t=0 \u03d52kt\nIn (1), t is the number of alternatives in {c3, . . . , cm} ranked above b in V \u2032. There are ( m\u22122 t ) such combinations, for each of which there are t! rankings among alternatives ranked above b and (m \u2212 2 \u2212 t)! rankings among alternatives ranked below t. Notice that there are no edges between alternatives in C \u2212 {c, b} in the WMG, which means that for any V \u2032 where exactly t alternatives are ranked above b, the probability is proportional to \u03d5kt\u03d5\u2212k(m\u22122\u2212t) by Lemma 1. Similarly,\u2211 V \u2208Lb(C) Pr(P \u2217|V ) \u221d \u03d5\u2212k(m\u22122)+1\u2212(m\u22122) \u2211m\u22122 t=0 \u03d5 2t.\n4Whether f1B satisfies majority and Condorcet criterion for \u03d5 \u2264 1\u221a2 is an open question.\nSince limm\u2192\u221e limk\u2192\u221e 1+\u03d5 2k+\u00b7\u00b7\u00b7+\u03d52k(m\u22122)\n1+\u03d52+\u00b7\u00b7\u00b7+\u03d52(m\u22122) \u00b7 1 \u03d52 = 1\u2212\u03d52 \u03d52 , for any \u03d5 > 1\u221a 2 , we can choose m and\nk so that \u2211\nV\u2208Lc(C) Pr(P |V )\u2211 W\u2208Lb(C) Pr(P |W ) < 1. By Lemma 4, c is the Condorcet winner in P \u2217 but it does not\nminimize the Bayesian risk underM1\u03d5, which means that it is not a winner under f1B .\nConsistency. We construct an example to show that f1B does not satisfy consistency. In our construction m and n are even, and C = {c, b, c3, c4}. Let P1 and P2 denote profiles whose WMGs are as shown in Figure 2, respectively.\nWe provide the following lemma to compare the Bayesian risk of c and d. The proof is similar to the proof of Lemma 4.\nLemma 5 Let P \u2208 {P1, P2}, \u2211\nV\u2208Lc(C) Pr(P |V )\u2211 W\u2208Lb(C) Pr(P |W ) = 3(1+\u03d54k) 2(1+\u03d52k+\u03d54k)\nProof: Let P = P1 or P2.\u2211 V \u2208Lc(C) Pr(P |V ) \u221d\u03d5\u22122k \u2211 V \u2032\u2208L(C\u2212c) \u03d5Kendall(P |C\u2212c ,V \u2032)\n\u221d\u03d5\u22122k3(\u03d5\u22122k + \u03d52k) Similarly \u2211 V \u2208Lb(C) Pr(P |V ) \u221d \u03d5 \u22122k2(\u03d5\u22122k + 1 + \u03d52k).\nFor any 0 < \u03d5 < 1, 3(1+\u03d5 4k)\n2(1+\u03d52k+\u03d54k) > 1 for all k. It is not hard to verify that f1B(P1) = f 1 B(P2) =\n{c}. However, it is not hard to verify that f1B(P1 \u222a P2) = {c, b}, which means that f1B is not consistent. This completes the proof of the theorem. Theorem 2 For any \u03d5, f2B satisfies anonymity, neutrality, and monotonicity. It does not satisfy majority, the Condorcet criterion, or consistency.\nProof: Anonymity and neutrality are obvious. The proof for monotonicity is similar to the proof for f1B and uses the second part of Lemma 3.\nMajority and Condorcet criterion. We prove that f2B does not satisfy majority or the Condorcet criterion for the same profile P \u2217 as used in the proof of Theorem 1. By Theorem 5 in the next section, we have:\u2211\nV \u2208Bc(C) Pr(P \u2217|V )\u2211\nW\u2208Bb(C) Pr(P \u2217|W )\n= ( 11+\u03d52 )\nm\u22121\n( 1 1+\u03d52k )m\u22122( 11+\u03d5\u22122 ) = (\n1 + \u03d52k\n1 + \u03d52 )m\u22122 \u00b7 1 + \u03d5\n\u22122\n1 + \u03d52 (2)\nFor any k \u2265 2, there exits m such that (2)< 1, which means that the Condorcet winner c is not in f2B(P \u2217).\nConsistency. We use the same profiles P1 and P2 as in the proof of Theorem 1 (see Figure 2). For P = P1 or P2, we have:\u2211\nV \u2208Bc(C) Pr(P |V )\u2211 W\u2208Bb(C) Pr(P |W ) = ( 11+1 )( 1 1+\u03d52k )2 ( 11+1 ) 2( 1 1+\u03d54k ) = 2(1 + \u03d54k) (1 + \u03d52k)2 (3)\nFor any k and m, we have that the value of (3) is strictly greater than 1. It is not hard to verify that f2B(P1) = f 2 B(P2) = {c} and f2B(P1 \u222a P2) = {c, d}, which means that f2B is not consistent.\nBy Theorem 1 and 2, f1B and f 2 B do not satisfy as many desired normative properties as the Kemeny rule (for winners). On the other hand, they minimize Bayesian risk under F1\u03d5 and F2\u03d5, respectively, for which Kemeny does neither. In addition, neither f1B nor f 2 B satisfy consistency, which means that they are not positional scoring rules."}, {"heading": "5 Computational Complexity", "text": "We consider the following two types of decision problems. Definition 5 In the BETTER BAYESIAN DECISION problem for a statistical decision-theoretic framework (MC ,D, L) under a prior distribution, we are given d1, d2 \u2208 D, and a profile P . We are asked whether RB(P, d1) \u2264 RB(P, d2).\nWe are also interested in checking whether a given alternative is the optimal decision. Definition 6 In the OPTIMAL BAYESIAN DECISION problem for a statistical decision-theoretic framework (MC ,D, L) under a prior distribution, we are given d \u2208 D and a profile P . We are asked whether d minimizes the Bayesian risk RB(P, \u00b7).\nPNP|| is the class of decision problems that can be computed by a P oracle machine with polynomial number of parallel calls to an NP oracle. A decision problem A is PNP|| -hard, if for any P NP || problem B, there exists a polynomial-time many-one reduction from B to A. It is known that PNP|| -hard problems are NP-hard. Theorem 3 For any \u03d5, BETTER BAYESIAN DECISION and OPTIMAL BAYESIAN DECISION for F1\u03d5 under uniform prior are PNP|| -hard.\nProof: The hardness of both problems is proved by a unified polynomial-time many-one reduction from the KEMENY WINNER problem, which was proved to be PNP|| -complete by Hemaspaandra et al. [16]. In a KEMENY WINNER instance, we are given a profile and an alternative c, and we are asked if c is ranked in the top of at least one V \u2208 L(C) that minimizes Kendall(P, V ). For any alternative c, the Kemeny score of c underM1\u03d5 is the smallest distance between the profile P and any linear order where c is ranked in the top. We prove that when \u03d5 < 1m! , the Bayesian risk of c is largely determined by the Kemeny score of c: Lemma 6 For any \u03d5 < 1m! and c, b \u2208 C, if the Kemeny score of c is strictly smaller than the Kemeny score of b, then RB(P, c) < RB(P, b) forM1\u03d5. Proof: Let kc and kb denote the Kemeny scores of c and b, respectively. We have\u2211 V \u2208Lc(C) Pr(P |V ) > 1 Zn\u03d5 kc > 1Znm!\u03d5 kc\u22121 \u2265 \u2211 V \u2208Lb(C) Pr(P |V ), which means that RB(P, c) < RB(P, b) by Lemma 2.\nWe note that \u03d5 may be larger than 1m! . In our reduction, we will duplicate the input profile so that effectively we are computing the problems for a small \u03d5. Let t be any natural number such that \u03d5t < 1m! . For any KEMENY WINNER instance (P, c) for alternatives C\n\u2032, we add two more alternatives {a, b} and define a profile P \u2032 whose WMG is as shown in Figure 3 using McGarvey\u2019s trick [24]. The WMG of P \u2032 contains the WMG(P ) as a subgraph, where the weights are 6 times of the weights of WMG(P ); for all c\u2032 \u2208 C\u2032, the weight of a\u2192 c\u2032 is 6; for all c\u2032 \u2208 C\u2032 \u2212 {c}, the weight of b\u2192 c\u2032 is 6; the weight of c\u2192 b is 4 and the weight of b\u2192 a is 2.\nThen, we let P \u2217 = tP , which is t copies of P . It follows that for any V \u2208 L(C), Pr(P \u2217|V, \u03d5) = Pr(P \u2032|V, \u03d5t). By Lemma 6, if an alternative e has the strictly lowest Kemeny score for profile P \u2032, then it the unique alternative that minimizes the Bayesian risk for P \u2032 and dispersion parameter \u03d5t, which means that e minimizes the Bayesian risk for P \u2217 and dispersion parameter \u03d5.\nLet O denote the set of linear orders over C\u2032 that minimizes the Kendall tau distance from P and let k denote this minimum distance. Choose an arbitrary V \u2032 \u2208 O. Let V = [b a V \u2032]. It follows that Kendall(P \u2032, V ) = 4 + 6k. If there exists W \u2032 \u2208 O where c is ranked in the top position, then\nwe let W = [a c b (V \u2032 \u2212 {c})]. We have Kendall(P \u2032,W ) = 2 + 6k. If c is not a Kemeny winner in P , then for any W where b is not ranked in the top position, Kendall(P \u2032,W ) \u2265 6 + 6k. Therefore, a minimizes the Bayesian risk if and only if c is a Kemeny winner in P , and if c does not minimizes the Bayesian risk, then b does. Hence BETTER DECISION (checking if a is better than b) and OPTIMAL BAYESIAN DECISION (checking if a is the optimal alternative) are PNP|| -hard.\nWe note that the OPTIMAL BAYESIAN DECISION for the framework in Theorem 3 is equivalent to checking whether a given alternative c is in f1B(P ). We do not know whether these problems are PNP|| -complete.\nTheorem 4 For any rational number \u03d5,5 BETTER BAYESIAN DECISION and OPTIMAL BAYESIAN DECISION for F2\u03d5 under uniform prior are in P.\nThe theorem is a corollary of the following stronger theorem that provides a closed-form formula for Bayesian loss for F2\u03d5.6 We recall that for any profile P and any pair of alternatives c, b, wP (c, b) is the weight on c\u2192 b in the weighted majority graph of P .\nTheorem 5 For F2\u03d5 under uniform prior, for any c \u2208 C, RB(P, c) = 1\u2212 \u220f b 6=c\n1\n1 + \u03d5wP (c,b) .\nProof: Given a profile P , for any c, b \u2208 C, we let P (c b) denote the number of times c is preferred to b in P . For any c, b \u2208 C, let K{c,b} = \u03d5P (c b) + \u03d5P (b c). The theorem is equivalent to proving\nthat \u2211 V \u2208Bc(C) Pr(V |P ) = \u220f b 6=c \u03d5P (b c)\nK{c,b} . We first calculate Pr(P ).\nPr(P ) = \u2211\nW\u2208Bc(C)\nPr(P |W ) \u00b7 Pr(W )\n=Pr(W ) \u00b7 1 Zn \u00b7 \u220f {c,b} (\u03d5P (c b) + \u03d5P (b c))\n=Pr(W ) \u00b7 1 Zn \u00b7 \u220f {c,b} K{c,b}\nFor any c \u2208 C, we have:\u2211 W\u2208Bc(C) Pr(W |P ) = \u2211 W\u2208Bc(C) Pr(P |W ) \u00b7 Pr(W ) Pr(P )\n= Pr(W ) Pr(P ) \u00b7 1 Zn \u00b7 \u220f b6=c \u03d5P (b c) \u2211 V \u2032\u2208B(C\u2212{c}) \u03d5Kendall(P |C\u2212c ,V \u2032)\n= Pr(W ) Pr(P ) \u00b7 1 Zn \u00b7 \u220f b6=c \u03d5P (b c) \u220f b,e6=c (\u03d5P (e b) + \u03d5P (b e)) = \u220f b 6=c \u03d5P (b c) K{c,b}\nThe comparisons of Kemeny, f1B , and f 2 B are summarized in Table 1. According to the criteria we considered, none of the three outperforms the others. Kemeny does well in normative properties, but does not minimize Bayesian risk under either F1\u03d5 or F2\u03d5, and is hard to compute. f1B minimizes the Bayesian risk under F1\u03d5, but is hard to compute. We would like to highlight f2B , which minimizes the Bayesian risk under F2\u03d5, and more importantly, can be computed in polynomial time despite the similarity between F1\u03d5 and F2\u03d5. This makes f2B a practical voting rule that is also justified by Condorcet\u2019s model.\n5We require \u03d5 to be rational to avoid representational issues. 6The formula resembles Young\u2019s calculation for three alternatives [34], where it was not clear whether the\ncalculation was done for F2\u03d5. Recently it was clarified by Xia [31] that this is indeed the case."}, {"heading": "6 Asymptotic Comparisons", "text": "In this section, we ask the following question: as the number of voters, n \u2192 \u221e, what is the probability that Kemeny, f1B , and f 2 B choose different winners?\nWe show that when the data is generated from M1\u03d5, all three methods are equal asymptotically almost surely (a.a.s.), that is, they are equal with probability 1 as n\u2192\u221e. Theorem 6 Let Pn denote a profile of n votes generated i.i.d. fromM1\u03d5 given W \u2208 Lc(C). Then, Prn\u2192\u221e(Kemeny(Pn) = f1B(Pn) = f 2 B(Pn) = c) = 1.\nProof sketch: It is not hard to see that asymptotically almost surely, for any pair of alternatives a, b \u2208 C, the number of times a b in Pn is (1 + o(1))nPr(a b|W ). As a corollary of a stronger theorem by [7], as n \u2192 \u221e, c is the Condorcet winner, which means that Prn\u2192\u221e(Kemeny(Pn) = c) = 1.\nWe now prove a lemma that will be useful for f1B and f 2 B . Lemma 7 For any W \u2208 Lc(C), any alternatives a, b that are different from c, Pr(c b|W ) > Pr(a b|W ).\nProof: We have Pr(c b|W )\u2212 Pr(a b|W ) = Pr(c b a|W )\u2212 Pr(a b c|W ). For any linear order Vc b a where c b a, we let Va b c denote the linear order obtained from Vc b a by switching the positions of c and a. It follows that Kendall(Vc b a,W ) < Kendall(Va b c,W ), which means that Pr(c b|W ) > Pr(a b|W ). To prove the theorem for f1B , it suffices to prove that for any b 6= c and any 0 < \u03d5 < 1, asymptotically almost surely, we have \u2211 V \u2208Lc(C) \u03d5 Kendall(Pn,V ) > \u2211 V \u2208Lb(C) \u03d5\nKendall(Pn,V ). For any Vc \u2208 Lc(C), we let Vb denote the linear order obtained from Vc by exchanging the positions of c and b, which means that Vb \u2208 Lb(C). Lemma 8 Prn\u2192\u221e(Kendall(Pn, Vc) < Kendall(Pn, Vb)) = 1.\nProof: Given Vc, let C\u2032 denote the set of alternatives between c and b in Vc. We have Kendall(Pn, Vb) \u2212 Kendall(Pn, Vc) = \u2211 a\u2208C\u2032 [wPn(a, b) \u2212 wPn(a, c)] + wPn(c, b) =\u2211\na\u2208C\u2032 2n[Pr(a b|W ) \u2212 Pr(a c|W )] + n(2 Pr(c b|W ) \u2212 1) + o(n), where we recall that wPn(a b) = Pn(a b) \u2212 Pn(b a). By Lemma 7, for all a that is different from b and c, Pr(c a|W ) > Pr(b a|W ), which means Pr(a b|W ) \u2212 Pr(a c|W ) > 0. Since c is the Condorcet winner asymptotically almost sure, Pr(c b|W ) > 1/2. This proofs the claim. By Lemma 8, Prn\u2192\u221e(\u2200Vc \u2208 Lc(C),Kendall(Pn, Vc) < Kendall(Pn, Vd)) = 1, which means that\nPr n\u2192\u221e\n( \u2200Vc \u2208 Lc(C), \u03d5Kendall(Pn,Vc) < \u03d5Kendall(Pn,Vd) ) = 1\nHence, Prn\u2192\u221e( \u2211 V \u2208Lc(C) \u03d5 Kendall(Pn,V ) > \u2211 V \u2208Ld(C) \u03d5\nKendall(Pn,V )) = 1. This proves the theorem for f1B .\nWe use Theorem 5 and Lemma 7 to prove the theorem for f2B . We note that \u03d5Pn(b c)\nK{c,b} =\n1 1+\u03d5Pn(c b)\u2212Pn(b c) = 1 1+\u03d52Pn(c b)\u2212n . By Lemma 7, Pr(c b|W ) > Pr(a b|W ), which means that asymptotically almost surely, we have the following steps of reasoning:\n(1) Pn(c b) > Pn(a b) for all a, b. (2) 1\n1+\u03d52Pn(c b)\u2212n > 1 1+\u03d52Pn(a b)\u2212n for all a and b.\n(3) \u03d5 Pn(b c)\nK{c,b} > \u03d5\nPn(b a) K{a,b} .\n(4) For any a 6= c, \u220f b 6=c \u03d5Pn(b c) K{c,b} > \u220f b 6=a \u03d5Pn(b a) K{a,b} .\nFinally, applying Theorem 5 to (4), c is the unique winner asymptotically almost surely. This completes the proof of the theorem. Theorem 7 For any W \u2208 B(C) and any \u03d5, f1B(Pn) = Kemeny(Pn) a.a.s. as n \u2192 \u221e and votes in Pn are generated i.i.d. fromM2\u03d5 given W .\nFor any m \u2265 5, there exists W \u2208 B(C) such that for any \u03d5, there exists > 0 such that with probability at least , f1B(Pn) 6= f2B(Pn) and Kemeny(Pn) 6= f2B(Pn) as n \u2192 \u221e and votes in Pn are generated i.i.d. fromM2\u03d5 given W .\nProof sketch: Due to the Central Limit Theorem, for any V,W \u2208 B(C), |Kendall(Pn, V ) \u2212 Kendall(Pn,W )| = \u2126( \u221a n) a.a.s. By Lemma 1 and Lemma 2, any f1B winner c maximizes\u2211\nVc\u2208Lc(C) \u03d5 Kendall(Pn,Vc) \u2248 maxVc\u2208Lc(C) \u03d5Kendall(Pn,Vc) a.a.s. This means that c is the Kemeny\nwinner a.a.s.\nFor the second part, we sketch a proof for m = 5. Other cases can be proved similarly. Let W denote the binary relation as shown in Figure 4.\nIt can be verified that for all i \u2264 5, Pr(ci ci+1|W ) (we let c1 = c6) are the same and are larger than 1/2, denoted by p1; for all i \u2264 5, Pr(ci ci+2|W ) are the same and are larger than 1/2, denoted by p2. We define a random variable Xc b for any c W b such that for any V \u2208 L(C), if c V b then Xc b = 1 otherwise Xc b = \u22121.\nLemma 9 {Xc b : c W b} are not linearly correlated.\nProof: Suppose for the sake of contradiction {Xc b : c W b} are linearly correlated. For anyXc b whose coefficient is non-zero, there exists a linear order V where c and b are ranked adjacently. Let V \u2032 denote the linear order obtained from V by switching the positions of c and b. We note thta Xc b(V ) = \u2212Xc b(V \u2032), and other random variables in {Xc b : c W b} take the same values at V and V \u2032, this leads to a contradiction.\nThen, it follows from the multivariate Lindeberg-Le\u0301vy Central Limit Theorem (CLT) [? , Theorem D.18A] that {( \u2211n j=1Xc b \u2212 pn)/ \u221a n : c W b} converges in distribution to a multivariate normal distribution N (0,\u03a3), where \u03a3 is the covariance matrix, and is non-singular by Lemma 9. We note that \u2211n j=1Xc b = Pn(c b).\nHence, with positive probability the following hold at the same time in WMG(Pn): \u2022 0 < wPn(c5, c1)\u2212 (2p1 \u2212 1)n < \u221a n; 0 < wPn(c4, c1)\u2212 (2p2 \u2212 1)n < \u221a n. \u2022 \u221a n < wPn(c1, c2) \u2212 (2p1 \u2212 1)n < 2 \u221a n; \u221a n < wPn(c5, c2) \u2212 (2p2 \u2212 1)n < 2 \u221a n; 0 <\nwPn(c1, c3)\u2212 (2p2 \u2212 1)n < \u221a n. \u2022 For any other ci W cj not mentioned above, 5 \u221a n < wPn(ci, cj)\u2212 (2 Pr(ci cj |W )\u2212 1)n.\nIf Pn satisfies all above conditions, then by Theorem 5 f2B(Pn) = {c1}. Meanwhile, Kemeny(Pn) = f1B(Pn) = {c2} with [c2 c3 c4 c5 c1] minimizing the total Kendall-tau distance. This shows that f2B(Pn) 6= Kemeny(Pn) with non-negligible probability as n \u2192 \u221e, and completes the proof of the theorem.\nTheorem 6 suggests that, when n is large and the votes are generated fromM1\u03d5, all of f1B , f2B , and Kemeny will choose the alternative ranked in the top of the ground truth as the winner. Similar observations have been made for other voting rules by [7]. On the other hand, Theorem 7 tells us that when the votes are generated from M2\u03d5, interestingly, for some ground truth parameter f2B is different from the other two with non-negligible probability, and as we will see in the next subsection, we are very confident that such probability is quite large (about 30% for given W shown in Figure 4)."}, {"heading": "6.1 Experiments", "text": "By Theorem 6 and 7, Kemeny and f1B are asymptotically equal when the data are generated from M1\u03d5 orM2\u03d5. Hence, we focus on the comparison between rule f2B and Kemeny using synthetic data generated fromM2\u03d5 given the binary relation W illustrated in Figure 4.\nBy Theorem 5, the exact computation of Bayesian risk involves computing \u03d5\u2126(n), which is exponentially small for large n since \u03d5 < 1. Hence, we need a special data structure to handle the computation of f2B , because a straightforward implementation easily loses precision. In our experiments, we use the following approximation for f2B :\nDefinition 7 For any c \u2208 C and profile P , let s(c, P ) = \u2211 b:wP (b,c)>0\nwP (b, c). Let g be the voting rule such that for any profile P , g(P ) = arg minc s(c, P ).\nIn words, g selects the alternative c with the minimum total weight on the incoming edges in the WMG. By Theorem 5, a f2B winner c maximizes \u220f b6=c \u03d5P (b c) K{c,b} = \u220f b 6=c 1 1+\u03d5wP (c,b) ,\nwhich means that c minimizes \u220f b 6=c(1 + \u03d5 wP (c,b)). In our experiments, \u220f b 6=c(1 + \u03d5 wP (c,b)) is\n(1 + o(1))\u03d5 \u2211\nb:wP (b,c)>0 wP (b,c) for reasonably large n. Therefore, g is a good approximation of f2B\nwith reasonably large n. Formally, this is stated in the following theorem.\nTheorem 8 For any W \u2208 B(C) and any \u03d5, f2B(Pn) = g(Pn) a.a.s. as n\u2192\u221e and votes in Pn are generated i.i.d. fromM2\u03d5 given W .\nIn our experiments, data are generated by M2\u03d5 given W in Figure 4 for m = 5, n \u2208 {100, 200, . . . , 2000}, and \u03d5 \u2208 {0.1, 0.5, 0.9}. For each setting we generate 1500 profiles, and calculate the percentage for g and Kemeny to be different. The results are shown in Figuire 5. We observe that for \u03d5 = 0.1 and 0.5, the probability for g(Pn) 6= Kemeny(Pn) is about 30% for most n in our experiments; when \u03d5 = 0.9, the probability is about 10%. In light of Theorem 8, these results confirm Theorem 7. We have also conducted similar experiments forM1\u03d5, and found that the g winner is the same as the Kemeny winner in all 10000 randomly generated profiles with m = 5, n = 100. This provides a sanity check for Theorem 6."}, {"heading": "7 Conclusions", "text": "There are some immediate open questions for future work, including the characterization of the exact computational complexity of f1B , and the normative properties of g. More generally, it is interesting to study the design and analysis of new voting rules using the proposed statistical decision-theoretic framework under alternative probabilistic models, e.g. random utility models, other loss functions, e.g. a smoother loss function, and other sample spaces including partial orders of a fixed set of k alternatives. We also plan to design and evaluate randomized estimators, and estimators that minimizes the maximum expected loss or the maximum expected regret [3]."}, {"heading": "8 Acknowledgments", "text": "We thank Shivani Agarwal, Craig Boutilier, Yiling Chen, Vincent Conitzer, Edith Elkind, Ariel Procaccia, and anonymous reviewers of AAAI-14 and NIPS-14 for helpful suggestions and discussions. Azari Soufiani acknowledges Siebel foundation for the scholarship in his last year of PhD studies. Parkes was supported in part by NSF grant CCF #1301976 and the SEAS TomKat fund. Xia acknowledges an RPI startup fund for support."}], "references": [{"title": "Information Aggregation, Rationality, and the Condorcet Jury Theorem", "author": ["David Austen-Smith", "Jeffrey S. Banks"], "venue": "The American Political Science Review,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1996}, {"title": "Random utility theory for social choice", "author": ["Hossein Azari Soufiani", "David C. Parkes", "Lirong Xia"], "venue": "In Proc. NIPS,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Statistical Decision Theory and Bayesian Analysis", "author": ["James O. Berger"], "venue": "Springer, 2nd edition,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1985}, {"title": "Probabilistic and Utility-theoretic Models in Social Choice: Challenges for Learning, Elicitation, and Manipulation", "author": ["Craig Boutilier", "Tyler Lu"], "venue": "Workshop on Social Choice and AI,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Optimal social choice functions: A utilitarian view", "author": ["Craig Boutilier", "Ioannis Caragiannis", "Simi Haber", "Tyler Lu", "Ariel D. Procaccia", "Or Sheffet"], "venue": "In Proc. EC,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Voting Almost Maximizes Social Welfare Despite Limited Communication", "author": ["Ioannis Caragiannis", "Ariel D. Procaccia"], "venue": "Artificial Intelligence,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "When do noisy votes reveal the truth", "author": ["Ioannis Caragiannis", "Ariel Procaccia", "Nisarg Shah"], "venue": "In Proc. EC,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Modal Ranking: A Uniquely Robust Voting Rule", "author": ["Ioannis Caragiannis", "Ariel D. Procaccia", "Nisarg Shah"], "venue": "In Proc. AAAI,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Common voting rules as maximum likelihood estimators", "author": ["Vincent Conitzer", "Tuomas Sandholm"], "venue": "In Proc. UAI,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2005}, {"title": "Preference functions that score rankings and maximum likelihood estimation", "author": ["Vincent Conitzer", "Matthew Rognlie", "Lirong Xia"], "venue": "In Proc. IJCAI,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "Rank aggregation methods for the web", "author": ["Cynthia Dwork", "Ravi Kumar", "Moni Naor", "D. Sivakumar"], "venue": "In Proc. WWW,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2001}, {"title": "How to Pick the Best Alternative Given Noisy Cyclic Preferences", "author": ["Edith Elkind", "Nisarg Shah"], "venue": "In Proc. UAI,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Condorcet social choice functions", "author": ["Peter C. Fishburn"], "venue": "SIAM Journal on Applied Mathematics,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1977}, {"title": "Voting for movies: the anatomy of a recommender system", "author": ["Sumit Ghosh", "Manisha Mundhe", "Karina Hernandez", "Sandip Sen"], "venue": "In Proc. AAMAS,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1999}, {"title": "The complexity of Kemeny elections", "author": ["Edith Hemaspaandra", "Holger Spakowski", "J\u00f6rg Vogel"], "venue": "Theoretical Computer Science,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2005}, {"title": "Learning to Rank from Bayesian Decision Inference", "author": ["Jen-Wei Kuo", "Pu-Jen Cheng", "Hsin-Min Wang"], "venue": "In Proc. CIKM,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "Active Learning for Ranking Through Expected Loss Optimization", "author": ["Bo Long", "Olivier Chapelle", "Ya Zhang", "Yi Chang", "Zhaohui Zheng", "Belle Tseng"], "venue": "In Proc. SIGIR,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}, {"title": "The Unavailable Candidate Model: A Decision-theoretic View of Social Choice", "author": ["Tyler Lu", "Craig Boutilier"], "venue": "In Proc. EC,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2010}, {"title": "Learning mallows models with pairwise preferences", "author": ["Tyler Lu", "Craig Boutilier"], "venue": "In Proc. ICML,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}, {"title": "Non-null ranking model", "author": ["Colin L. Mallows"], "venue": "Biometrika, 44(1/2):114\u2013130,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1957}, {"title": "Better human computation through principled voting", "author": ["Andrew Mao", "Ariel D. Procaccia", "Yiling Chen"], "venue": "In Proc. AAAI,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2013}, {"title": "A theorem on the construction of voting", "author": ["David C. McGarvey"], "venue": "paradoxes. Econometrica,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1953}, {"title": "The significance of independent decisions in uncertain dichotomous choice situations", "author": ["Shmuel Nitzan", "Jacob Paroush"], "venue": "Theory and Decision,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1984}, {"title": "Voting rules as statistical estimators", "author": ["Marcus Pivato"], "venue": "Social Choice and Welfare,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2013}, {"title": "Ontology Merging as Social Choice: Judgment Aggregation under the Open World Assumption", "author": ["Daniele Porello", "Ulle Endriss"], "venue": "Journal of Logic and Computation,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2013}, {"title": "The Distortion of Cardinal Preferences in Voting", "author": ["Ariel D. Procaccia", "Jeffrey S. Rosenschein"], "venue": "In Proc. CIA,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2006}, {"title": "A maximum likelihood approach for selecting sets of alternatives", "author": ["Ariel D. Procaccia", "Sashank J. Reddi", "Nisarg Shah"], "venue": "In Proc. UAI,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2012}, {"title": "Statistical Decision Function", "author": ["Abraham Wald"], "venue": "New York: Wiley,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1950}, {"title": "Deciphering young\u2019s interpretation of condorcet\u2019s model", "author": ["Lirong Xia"], "venue": "ArXiv,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2014}, {"title": "A maximum likelihood approach towards aggregating partial orders", "author": ["Lirong Xia", "Vincent Conitzer"], "venue": "In Proc. IJCAI,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2011}, {"title": "Aggregating preferences in multi-issue domains by using maximum likelihood estimators", "author": ["Lirong Xia", "Vincent Conitzer", "J\u00e9r\u00f4me Lang"], "venue": "In Proc. AAMAS,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2010}, {"title": "Condorcet\u2019s theory of voting", "author": ["H. Peyton Young"], "venue": "American Political Science Review,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 1988}, {"title": "A consistent extension of Condorcet\u2019s election principle", "author": ["H. Peyton Young", "Arthur Levenglick"], "venue": "SIAM Journal of Applied Mathematics,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 1978}], "referenceMentions": [{"referenceID": 10, "context": "using voting rules to aggregate rankings in meta-search engines [12], recommender systems [15], crowdsourcing [23], semantic webs [27], some social choice normative properties are still desired.", "startOffset": 64, "endOffset": 68}, {"referenceID": 13, "context": "using voting rules to aggregate rankings in meta-search engines [12], recommender systems [15], crowdsourcing [23], semantic webs [27], some social choice normative properties are still desired.", "startOffset": 90, "endOffset": 94}, {"referenceID": 20, "context": "using voting rules to aggregate rankings in meta-search engines [12], recommender systems [15], crowdsourcing [23], semantic webs [27], some social choice normative properties are still desired.", "startOffset": 110, "endOffset": 114}, {"referenceID": 24, "context": "using voting rules to aggregate rankings in meta-search engines [12], recommender systems [15], crowdsourcing [23], semantic webs [27], some social choice normative properties are still desired.", "startOffset": 130, "endOffset": 134}, {"referenceID": 2, "context": "To tackle this challenge, we develop a general framework that adopts statistical decision theory [3].", "startOffset": 97, "endOffset": 100}, {"referenceID": 19, "context": "To show the viability of the framework, we focus on selecting multiple alternatives (the alternatives that can be thought of as being \u201ctied\u201d for the first place) under a natural extension of the 0-1 loss function for two models: letM\u03c6 denote the Mallows model with fixed dispersion [22], and letM\u03c6 denote the Condorcet model proposed by Condorcet in the 18th century [9, 34].", "startOffset": 282, "endOffset": 286}, {"referenceID": 31, "context": "To show the viability of the framework, we focus on selecting multiple alternatives (the alternatives that can be thought of as being \u201ctied\u201d for the first place) under a natural extension of the 0-1 loss function for two models: letM\u03c6 denote the Mallows model with fixed dispersion [22], and letM\u03c6 denote the Condorcet model proposed by Condorcet in the 18th century [9, 34].", "startOffset": 367, "endOffset": 374}, {"referenceID": 12, "context": "We also compare the asymptotic outcomes of the two rules with the Kemeny rule for winners, which is a natural extension of the maximum likelihood estimator of M\u03c6 proposed by Fishburn [14].", "startOffset": 183, "endOffset": 187}, {"referenceID": 31, "context": "Along the second perspective in social choice (to make an objectively correct decision), in addition to Condorcet\u2019s statistical approach to social choice [9, 34], most previous work in economics, political science, and statistics focused on extending the theorem to heterogeneous, correlated, or strategic agents for two alternatives, see [25, 1] among many others.", "startOffset": 154, "endOffset": 161}, {"referenceID": 22, "context": "Along the second perspective in social choice (to make an objectively correct decision), in addition to Condorcet\u2019s statistical approach to social choice [9, 34], most previous work in economics, political science, and statistics focused on extending the theorem to heterogeneous, correlated, or strategic agents for two alternatives, see [25, 1] among many others.", "startOffset": 339, "endOffset": 346}, {"referenceID": 0, "context": "Along the second perspective in social choice (to make an objectively correct decision), in addition to Condorcet\u2019s statistical approach to social choice [9, 34], most previous work in economics, political science, and statistics focused on extending the theorem to heterogeneous, correlated, or strategic agents for two alternatives, see [25, 1] among many others.", "startOffset": 339, "endOffset": 346}, {"referenceID": 8, "context": "samples from a statistical model, and computes the MLE to estimate the parameters that maximize the likelihood [10, 11, 33, 32, 2, 29, 7].", "startOffset": 111, "endOffset": 137}, {"referenceID": 9, "context": "samples from a statistical model, and computes the MLE to estimate the parameters that maximize the likelihood [10, 11, 33, 32, 2, 29, 7].", "startOffset": 111, "endOffset": 137}, {"referenceID": 30, "context": "samples from a statistical model, and computes the MLE to estimate the parameters that maximize the likelihood [10, 11, 33, 32, 2, 29, 7].", "startOffset": 111, "endOffset": 137}, {"referenceID": 29, "context": "samples from a statistical model, and computes the MLE to estimate the parameters that maximize the likelihood [10, 11, 33, 32, 2, 29, 7].", "startOffset": 111, "endOffset": 137}, {"referenceID": 1, "context": "samples from a statistical model, and computes the MLE to estimate the parameters that maximize the likelihood [10, 11, 33, 32, 2, 29, 7].", "startOffset": 111, "endOffset": 137}, {"referenceID": 26, "context": "samples from a statistical model, and computes the MLE to estimate the parameters that maximize the likelihood [10, 11, 33, 32, 2, 29, 7].", "startOffset": 111, "endOffset": 137}, {"referenceID": 6, "context": "samples from a statistical model, and computes the MLE to estimate the parameters that maximize the likelihood [10, 11, 33, 32, 2, 29, 7].", "startOffset": 111, "endOffset": 137}, {"referenceID": 31, "context": "In fact, Young [34] proposed to select a winning alternative that is \u201cmost likely to be the best (i.", "startOffset": 15, "endOffset": 19}, {"referenceID": 26, "context": "[29] to choose a given number of alternatives with highest marginal probability under the Mallows model.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "More recently, independent to our work, Elkind and Shah [13] investigated a similar question for choosing multiple winners under the Condorcet model.", "startOffset": 56, "endOffset": 60}, {"referenceID": 23, "context": "Pivato [26] conducted a similar study to Conitzer and Sandholm [10], examining voting rules that can be interpreted as expect-utility maximizers.", "startOffset": 7, "endOffset": 11}, {"referenceID": 8, "context": "Pivato [26] conducted a similar study to Conitzer and Sandholm [10], examining voting rules that can be interpreted as expect-utility maximizers.", "startOffset": 63, "endOffset": 67}, {"referenceID": 26, "context": "[29], and the complexity for the second rule (Theorem 5) was independently discovered by Elkind and Shah [13].", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[29], and the complexity for the second rule (Theorem 5) was independently discovered by Elkind and Shah [13].", "startOffset": 105, "endOffset": 109}, {"referenceID": 2, "context": "The statistical decision-theoretic framework is quite general, allowing considerations such as estimators that minimize the maximum expected loss, or the maximum expected regret [3].", "startOffset": 178, "endOffset": 181}, {"referenceID": 17, "context": "In a different context, focused on uncertainty about the availability of alternatives, Lu and Boutilier [20] adopt a decision-theoretic view of the design of an optimal voting rule.", "startOffset": 104, "endOffset": 108}, {"referenceID": 7, "context": "[8] studied the robustness of social choice mechanisms w.", "startOffset": 0, "endOffset": 3}, {"referenceID": 25, "context": "A number of recent papers in computational social choice take utilitarian and decision-theoretical approaches towards social choice [28, 6, 4, 5].", "startOffset": 132, "endOffset": 145}, {"referenceID": 5, "context": "A number of recent papers in computational social choice take utilitarian and decision-theoretical approaches towards social choice [28, 6, 4, 5].", "startOffset": 132, "endOffset": 145}, {"referenceID": 3, "context": "A number of recent papers in computational social choice take utilitarian and decision-theoretical approaches towards social choice [28, 6, 4, 5].", "startOffset": 132, "endOffset": 145}, {"referenceID": 4, "context": "A number of recent papers in computational social choice take utilitarian and decision-theoretical approaches towards social choice [28, 6, 4, 5].", "startOffset": 132, "endOffset": 145}, {"referenceID": 27, "context": "We don\u2019t view this as fitting into the classical approach to statistical decision theory as formulated by Wald [30].", "startOffset": 111, "endOffset": 115}, {"referenceID": 15, "context": "Several papers in machine learning developed algorithms to compute MLE or Bayesian estimators for popular ranking models [18, 19, 21], but without considering the normative properties of the estimators.", "startOffset": 121, "endOffset": 133}, {"referenceID": 16, "context": "Several papers in machine learning developed algorithms to compute MLE or Bayesian estimators for popular ranking models [18, 19, 21], but without considering the normative properties of the estimators.", "startOffset": 121, "endOffset": 133}, {"referenceID": 18, "context": "Several papers in machine learning developed algorithms to compute MLE or Bayesian estimators for popular ranking models [18, 19, 21], but without considering the normative properties of the estimators.", "startOffset": 121, "endOffset": 133}, {"referenceID": 32, "context": "Kemeny-Young method) [17, 35] selects all linear orders with the minimum Kendall-tau distance from the preference profile P , that is, Kemeny(P ) = arg minW Kendall(P,W ).", "startOffset": 21, "endOffset": 29}, {"referenceID": 12, "context": "The most well-known variant of Kemeny to select winning alternatives, denoted by KemenyC , is due to Fishburn [14], who defined it as a voting rule that selects all alternatives that are ranked in the top position of some winning linear orders under the Kemeny rule.", "startOffset": 110, "endOffset": 114}, {"referenceID": 19, "context": "Definition 1 In the Mallows model [22], a parameter is composed of a linear order W \u2208 L(C) and a dispersion parameter \u03c6 with 0 < \u03c6 < 1.", "startOffset": 34, "endOffset": 38}, {"referenceID": 27, "context": "Statistical decision theory [30, 3] studies scenarios where the decision maker must make a decision d \u2208 D based on the data P generated from a parametric model, generallyM = (\u0398,S,Pr).", "startOffset": 28, "endOffset": 35}, {"referenceID": 2, "context": "Statistical decision theory [30, 3] studies scenarios where the decision maker must make a decision d \u2208 D based on the data P generated from a parametric model, generallyM = (\u0398,S,Pr).", "startOffset": 28, "endOffset": 35}, {"referenceID": 31, "context": "Example 2 Bayesian estimators f B and f B coincide with Young [34]\u2019s idea of selecting the alternative that is \u201cmost likely to be the best (i.", "startOffset": 62, "endOffset": 66}, {"referenceID": 26, "context": "[29] and f 2 B was independently studied by Elkind and Shah [13].", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[29] and f 2 B was independently studied by Elkind and Shah [13].", "startOffset": 60, "endOffset": 64}, {"referenceID": 28, "context": "In the Condorcet model the sample space is B(C) [31].", "startOffset": 48, "endOffset": 52}, {"referenceID": 14, "context": "[16].", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "For any KEMENY WINNER instance (P, c) for alternatives C \u2032, we add two more alternatives {a, b} and define a profile P \u2032 whose WMG is as shown in Figure 3 using McGarvey\u2019s trick [24].", "startOffset": 178, "endOffset": 182}, {"referenceID": 31, "context": "The formula resembles Young\u2019s calculation for three alternatives [34], where it was not clear whether the calculation was done for F \u03c6.", "startOffset": 65, "endOffset": 69}, {"referenceID": 28, "context": "Recently it was clarified by Xia [31] that this is indeed the case.", "startOffset": 33, "endOffset": 37}, {"referenceID": 6, "context": "As a corollary of a stronger theorem by [7], as n \u2192 \u221e, c is the Condorcet winner, which means that Prn\u2192\u221e(Kemeny(Pn) = c) = 1.", "startOffset": 40, "endOffset": 43}, {"referenceID": 6, "context": "Similar observations have been made for other voting rules by [7].", "startOffset": 62, "endOffset": 65}, {"referenceID": 2, "context": "We also plan to design and evaluate randomized estimators, and estimators that minimizes the maximum expected loss or the maximum expected regret [3].", "startOffset": 146, "endOffset": 149}], "year": 2016, "abstractText": "In this paper, we take a statistical decision-theoretic viewpoint on social choice, putting a focus on the decision to be made on behalf of a system of agents. In our framework, we are given a statistical ranking model, a decision space, and a loss function defined on (parameter, decision) pairs, and formulate social choice mechanisms as decision rules that minimize expected loss. This suggests a general framework for the design and analysis of new social choice mechanisms. We compare Bayesian estimators, which minimize Bayesian expected loss, for the Mallows model and the Condorcet model respectively, and the Kemeny rule. We consider various normative properties, in addition to computational complexity and asymptotic behavior. In particular, we show that the Bayesian estimator for the Condorcet model satisfies some desired properties such as anonymity, neutrality, and monotonicity, can be computed in polynomial time, and is asymptotically different from the other two rules when the data are generated from the Condorcet model for some ground truth parameter.", "creator": "LaTeX with hyperref package"}}}