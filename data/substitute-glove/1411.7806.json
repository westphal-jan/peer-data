{"id": "1411.7806", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Nov-2014", "title": "Two Gaussian Approaches to Black-Box Optomization", "abstract": "Outline now several strategies no simultaneously Gaussian mechanisms soon marriages models for put invertible adjacency produced cognition action (CMA - ES ).", "histories": [["v1", "Fri, 28 Nov 2014 10:39:24 GMT  (10kb)", "http://arxiv.org/abs/1411.7806v1", "9 pages"]], "COMMENTS": "9 pages", "reviews": [], "SUBJECTS": "cs.NE cs.AI", "authors": ["luk\\'a\\v{s} bajer", "martin hole\\v{n}a"], "accepted": false, "id": "1411.7806"}, "pdf": {"name": "1411.7806.pdf", "metadata": {"source": "CRF", "title": "Two Gaussian Approaches to Black-Box Optomization", "authors": ["Luk\u00e1\u0161 Bajer", "Martin Hole\u0148a"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n41 1.\n78 06\nv1 [\ncs .N\nE ]\n2 8\nN ov\n2 01\n4\nTwo Gaussian Approaches to Black-Box Optomization\nLuka\u0301s\u030c Bajer Martin Holen\u030ca"}, {"heading": "1 CMA Evolution Strategy", "text": "CMA-ES [7, 8] is the state-of-the-art evolutionary optimization method, at least in the area of continuous black-box optimization. Basically, it consists in generating new search points by sampling from a multidimensional normal distribtion, the mean and variance of which are updated from generation to generation. In particular, the population x (g+1) 1 , . . . , x (g+1) \u03bb \u2208 R\nd of the g + 1-st generation, g \u2265 1, follows the normal distribution with mean m(g) \u2208 Rd and variance (\u03c3(g))2C(g) \u2208 Rd,d resulting from the update in the g-th generation,\nx (g+1) i \u223c N ( m(g), (\u03c3(g))2C(g) ) . (1)\nHere, \u03c3(g) is the step size in the g-th generation. C(g) \u2208 Rd,d and \u03c3(g) > 0 are updated separately, C(g) being in the most simple case obtained as the unbiased empirical estimate based on the g-th generation:\nC(g)emp = 1\n\u03bb\u2212 1\n\u03bb \u2211\ni=1\n(\nx (g) i \u2212\n1\n\u03bb\n\u03bb \u2211\nj=1\nx (g) j\n)(\nx (g) i \u2212\n1\n\u03bb\n\u03bb \u2211\nj=1\nx (g) j\n)\u22a4\n. (2)\nThe positive semidefinite matrix C(g) can be diagonalised in the basis formed by its eigenvectors b\n(g) 1 , . . . , b (g) d ,\nC(g) = B(g)D(g)B(g)\u22a4, (3)\nwhere B(g) = (b (g) 1 \u00b7 \u00b7 \u00b7 b (g) d ) andD (g) is a diagonal matrix such that its k-th diagonal element is the eigenvalue corresponding to the eigenvector b (g) k . Consequently, the coordinates of points generated according to (1) in that basis, {x (g+1) i } B(g) , are uncorrelated:\n{x (g+1) i } B(g) = B(g)\u22a4x (g+1) i \u223c N ( B(g)\u22a4m(g), (\u03c3(g))2B(g)\u22a4C(g)B(g) ) . (4)"}, {"heading": "2 Optimization Based on Gaussian Processes", "text": "A Gaussian process (GP) on a d-dimensional Euclidean space X is a collection of random variables, GPX= (f(x))x\u2208X, such that the joint distribution of any finite number of them is a multidimensional normal distribtion. Following [4], we differentiate two ways of using GPs in black-box optimization:\n(i) As a surrogate model to be optimized instead of the black box objective function. On the found optimum or optima, the original black-box objective function is then evaluated. This use of GPs has been introduced in the popular Efficient Global Optimization (EGO) algorithm [14]. As the optimization method, also evolutionary optimization can be used, in particular CMA-ES [4], but this is not the only possibility: For example, traditional low-degree polynomial models, aka response surface models [20], are much more efficiently optimized using traditional smooth optimization methods. (ii) For the evolution control of the evolutionary optimization of the original objective function, i.e., for controlling the composition of its population [5, 6, 9, 23].\nIrrespective of the way in which a GP is used, its construction is always based on a sequence (x1, y1), . . . , (xn, yn) \u2208 X \u00d7 R of training pairs and is subsequently employed to compute the random variable f(x) for x 6\u2208 {x1, . . . , xn}. Since the distribution of (f(x), f(x1), . . . , f(xn)) is multidimensional normal, also the conditional distribution of f(x) conditioned on f(x1), . . . , f(xn) is normal,\nf(x)|f(x1), . . . , f(xn) \u223c N(\u00b5(x;X, Y ),\u03a3(x;X, Y )), (5)\nwhere X = (x1, . . . , xn), Y = (y1, . . . , yn), \u00b5(\u00b7;X, Y ) : X \u2192 X,\u03a3(\u00b7;X, Y ) : X \u2192 X 2. There are two commonly encountered possibilities how define the functions \u00b5(\u00b7;X, Y ), describing the conditional GP mean, and \u03a3(\u00b7;X, Y ), describing the conditional GP variance:\n1. A GP is the superposition of a deterministic function f\u0304 : X \u2192 R and a GP with zero mean. For the latter, it can be shown [21] that the function describing its mean fulfils\n(\u2200x \u2208 X) \u00b50(x;X, Y ) = K(x,X)(K(X,X) + \u03c3 2 noiseIn) \u22121Y \u22a4, (6)\nwhereas the function describing its variance fulfills\n(\u2200x \u2208 X) \u03a30(x;X, Y ) = K(x, x)\u2212K(x,X)(K(X,X) + \u03c3 2 noiseIn) \u22121K(X, x). (7)\nHere, an i.i.d. Gaussian noise is assumed, In is the n-dimensional identity matrix, K : X\u00d7 X \u2192 R is a symmetric function, and\nK(x,X) = (K(x, x1), . . . , K(x, xn)), K(X, x) = K(x,X) \u22a4,\nK(X,X) = (K(x1, X) \u22a4, . . . , K(xn, X) \u22a4)\u22a4. (8)\nThe resulting superposition then fulfils\n(\u2200x \u2208 X) \u00b5(x;X, Y ) = f\u0304(x) +K(x,X)(K(X,X) + \u03c32noiseIn) \u22121(Y \u2212 (f\u0304(x1), . . . , f\u0304(xn))) \u22a4,\n(9)\nwhereas \u03a3 = \u03a30.\n2. A GP is the superposition of a Bayesian mean assuming the multiplicative form wf\u0304 and a GP with zero mean, where w is a random variable with w \u223c N(1, \u03c32w), \u03c3w > 0,\nand f\u0304 has the same meaning as above. In that case, it can be shown [21] that for x \u2208 X,\n\u00b5(x;X, Y ) = K(x,X)(K(X,X) + \u03c32noiseIn) \u22121Y \u22a4+\n+ (f\u0304(x)\u2212 (f\u0304(x1), . . . , f\u0304(xn))(K(X,X) + \u03c3 2 noiseIn) \u22121K(X, x))w\u0302, (10)\n\u03a3(x;X, Y ) = K(x, x)\u2212K(x,X)(K(X,X) + \u03c32noiseIn) \u22121K(X, x)+\n+ \u03c32w(K(X,X) + \u03c3 2 noiseIn) \u22121Y \u22a4 + \u03ba\u03022\n1 + \u03c32w(f\u0304(x1), . . . , f\u0304(xn))(K(X,X) + \u03c3 2 noiseIn) \u22121(f\u0304(x1), . . . , f\u0304(xn))\u22a4 , (11)\nwhere\nw\u0302 = 1 + \u03c32w(f\u0304(x1), . . . , f\u0304(xn))(K(X,X) + \u03c3 2 noiseIn) \u22121(f\u0304(x1), . . . , f\u0304(xn)) \u22a4\n1 + \u03c32w(f\u0304(x1), . . . , f\u0304(xn))(K(X,X) + \u03c3 2 noiseIn)\n\u22121Y \u22a4 , (12)\n\u03ba\u0302 = (f\u0304(x)\u2212 (f\u0304(x1), . . . , f\u0304(xn))(K(X,X) + \u03c3 2 noiseIn) \u22121K(X, x)) (13)\nSimple, but frequently used examples of the function K occurring in (6)\u2013(7) and (10)\u2013 (11) include:\n\u2022 Squared exponential,\n(\u2200x, x\u2032 \u2208 X) K(x, x\u2032) = e\u2212 \u2016x\u2212x\u2032\u20162 2\u21132 , \u2113 > 0. (14)\nHere, \u2113 is a parameter called characteristic length-scale. It is a parameter of the function KSE, not of the Gaussian process, the process is nonparametric. Therefore \u2113 is referred to as a hyperparameter.\n\u2022 \u03b3-Exponential,\n(\u2200x, x\u2032 \u2208 X) K(x, x\u2032) = e \u2212\n( \u2016x\u2212x\u2032\u2016 \u2113\n)\u03b3\n, \u2113 > 0, 0 < \u03b3 \u2264 2, (15)\nwhich has 2 hyperparameters, \u03bb and \u03b3.\n\u2022 Dot product,\n(\u2200x, x\u2032 \u2208 X) K(x, x\u2032) = (\u03c32 + x\u22a4x\u2032)p, \u03c3 \u2265 0, p \u2208 N, (16)\nwhich has 2 hyperparameters, \u03c3 and p, or in its generalized version,\n(\u2200x, x\u2032 \u2208 X) K(x, x\u2032) = (\u03c32 + x\u22a4\u03a3x\u2032)p,\u03a3 \u2208 Rd,d positive definite, (17)\nwhich has, in addition, the matrix of hyperparameters \u03a3, defining a dot product in general coordinates."}, {"heading": "2.1 GP-based criteria to choose the points for evaluation", "text": "Whereas traditional response surface and surrogate models employ basically only one criterion for the choice of points in which the black box objective function should be evaluated, namely the global or at least local minimum of the model (if the optimization objective is minimization), GPs offer several additional criteria:\n(i) Minimum of a prescribed quantile (Q\u03b1) of the distribution of f(x)|f(x1), . . . , f(xn), \u03b1 \u2208 (0, 1).\nx\u2217\u03b1 = argmin x\u2208X q\u03b1(N(\u00b5(x;X, Y ),\u03a3(x;X, Y ))). (18)\nUsually, (18) is expressed using quantiles of the standard normal distribution, u\u03b1 = q\u03b1(N(0, 1)),\nx\u2217\u03b1 = argmin x\u2208X\n\u00b5(x;X, Y ) + \u221a\n\u03a3(x;X, Y )u\u03b1 = argmin x\u2208X\n\u00b5(x;X, Y )\u2212 \u221a\n\u03a3(x;X, Y )u1\u2212\u03b1.\n(19)\nFor \u03b1 = 0.5, (19) turns to the traditional global minimum criterion, applied to \u00b5(\u00b7;X, Y ).\n(ii) Probability of improvement (PoI),\nx\u2217PI = argmax x\u2208X P (f(x) < fmin|f(x1), . . . , f(xn)) = \u03c6\n(\nfmin \u2212 \u00b5(x;X, Y ) \u221a\n\u03a3(x;X, Y )\n)\n, (20)\nwhere \u03c6 denotes the distribution function of N(0, 1), fmin is the minimum value found so far. More generally, probability of improvement with respect to a given T \u2264 fmin,\nx\u2217PI\u2014T = argmax x\u2208X P (f(x) < T |f(x1), . . . , f(xn)) = \u03c6\n(\nT \u2212 \u00b5(x;X, Y ) \u221a\n\u03a3(x;X, Y )\n)\n. (21)\n(iii) Expected improvement (EI),\nx\u2217EI = argmax x\u2208X E((fmin \u2212 f(x))I(f(x) < fmin)|f(x1), . . . , f(xn)),\nwhere I(f(x) < fmin) =\n{\n1 f(x) < fmin, 0 f(x) \u2265 fmin. (22)\nIntroducing the normalized mean improvement \u03bd : X \u2192 R,\n(\u2200x \u2208 X) \u03bd(x) = fmin \u2212 \u00b5(x;X, Y ) \u221a\n\u03a3(x;X, Y ) , (23)\nand the notation \u03d5 for the density of N(0, 1), (22) can be expressed as [13]\nx\u2217EI = argmax x\u2208X\n\u221a\n\u03a3(x;X, Y )(\u03bd(x)\u03c6(\u03bd(x)) + \u03d5(\u03bd(x)))). (24)"}, {"heading": "3 Possible Synergy", "text": "Directly connecting both considered Gaussian approaches is not possible because the normal distribution in CMA-ES is a distribution on the input space of the objective function (fitness), whereas the normal distribution in GPs is on the space of its function values. Nevertheless, it is still possible to achieve some synergy through using information from CMA-ES for the GP, and/or using information from the GP for CMA-ES. According to whoat was recalled at the beginning of Section 2, the latter possibility corresponds to using GP for the evolution control of CMA-ES."}, {"heading": "3.1 Using Information from CMA-ES for the GP", "text": "We see 2 straightforward possibilities where some information from CMA-ES can be used in the GP.\n1. The function f\u0304 occurring in (9), (10) and (11) can be constructed using the fit-\nness values f(x (g) 1 ), . . . . . . , f(x (g) \u03bb ) of individuals from some particular generation or several generations of CMA-ES. Its construction can be as simple as setting f\u0304 to a constant aggregating the considered fitness values, e.g., their mean or weighted mean, but it can also consist in training, with those values, a response surface model, principally of any kind.\n2. Kruisselbrink et al. [16], who combine CMA-ES with a GP using the \u03b3-exponential function K, propose to employ in (15) the Mahalanobis distance of vectors x and x\u2032 given by the covariance matrix obtained in the g-th generation of CMA-ES, (\u03c3(g))2C(g), instead of their Euclidean distance. This is actually a specific consequence of another possibility of using information from CMA-ES for the GP \u2013 replacing the original space of d-dimensional vectors, Rd, by the space of their principal components with respect to C(g). In this context, it is worth recalling that in [2, 3, 15], Mahalanobis instead of Euclidean distance was used when combining CMA-ES with quadratic response surface models in [2, 3, 15]. In the approach presented there, the space of the principal components with respect to C(g) is used, together with an estimate of density, to locally weight the model predictions with respect to the considered input. In this way, a connection to the other kind of synergy is established, i.e., to the evolution control of CMA-ES, giving us the possibility to use both kinds in combination."}, {"heading": "3.2 GP-Based Evolution Control of CMA-ES", "text": "We intend to test the following approaches to using GP for the evolution control of CMAES.\n(i) Basic approach. In the (g+1)-th generation, \u03bb\u2032 points x\u03031, . . . , x\u0303\u03bb\u2032 \u2208 R d are sampled\nfrom the distribution N(m(g), (\u03c3(g))2C(g)), where \u03bb\u2032 is several to many times larger then \u03bb. For all of them, a selected criterion from among those introduced in 2.1\nis computed. Based on the value of that criterion, the \u03bb points x (g+1) 1 , . . . , x (g+1) \u03bb for the evaluation by the original black-box fitness are chosen. This can be done according to various strategies, we intend to use the one described in Algorithm 1, with which we have a good experience from using radial basis function networks for the evolution control in the evolutionary optimization of catalytic materials [10]. The linear ordering \u227ac stands in the cases c =PoI and c =EI for \u2264, in the case c = Q\u03b1 for \u2265. The use of a linear ordering relates the proposed approach to ranking-based evolution control of CMA-ES [2, 3, 15, 23], as well as to surrogate modelling of CMA-ES by ordinal regression [17, 18, 19, 22]. Most similar is the approach by Ulmer et al. [23], the difference being that they don\u2019t use clustering.\n(ii) GP on low-dimensional projections attempts to improve the basic approach in view of the experience reported in the literature [15] and obtained also in our earlier experiments [1] that GPs are actually advantageous only in low dimensional spaces. Instead of the sampled points x\u03031, . . . , x\u0303\u03bb\u2032 , the GP is trained only with their first \u2113 < d principal components with respect to C(g), x\u0303\n[\u2113] 1 , . . . , x\u0303 [\u2113] \u03bb\u2032 , i.e., with the projec-\ntions of x\u03031, . . . , x\u0303\u03bb\u2032 to the \u2113-dimensional space X\u2113 = span(b (g) 1 , . . . , b (g) \u2113 ), provided the orthonormal eigenvectors b (g) i are enumerated according to decreasing eigenvalues.\n(iii) GP on low-dimensional projections within restricted distance attempts to decreaase the deterioration of the GP on low-dimensional projections with respect to the GP on the original sampled points x\u03031, . . . , x\u0303\u03bb\u2032 by using only points x\u0303i within a prescribed small distance \u01eb from their respective projections x\u0303\n[\u2113] i . To this end, points from\nthe distribution N(m(g), (\u03c3(g))2C(g)) are resampled until \u03bb\u2032 points x\u0303i are obtained fulfilling\n\u2016x\u0303i \u2212 x\u0303 [\u2113] 1 \u2016 < \u01eb, or equivalently, \u2016x\u0303i\u2016 2 \u2212 \u2016x\u0303 [\u2113] 1 \u2016 2 < \u01eb2. (25)\n(iv) Two-stage sampling. Trainig the GP for the (g + 1)-th generation can easily suffer from the lack of training data in a part of the search space where a substantial proportion of the points x\u03031, . . . , x\u0303\u03bb\u2032 will be sampled. To alleviate it, the points x (g+1) 1 , . . . , x (g+1) \u03bb to be evaluated by the original fitness can be sampled in two stages:\n1. First, points x (g+1) 1 , . . . , x (g+1) \u03bb\u2032\u2032 , where \u03bb\n\u2032\u2032 < \u03bb, are sampled from the distribution N(m(g), (\u03c3(g))2C(g)), evaluated by the original fitness, and included into training the GP.\n2. Then, \u03bb\u2032 points x\u03031, . . . , x\u0303\u03bb\u2032 are sampled from the same distribution, and for them, a selected criterion from among those introduced in 2.1 is computed, based on which the points x\n(g+1) \u03bb\u2032\u2032+1 , . . . , x (g+1) \u03bb for the evaluation by the original\nblack-box fitness are chosen. To this end, again Algorithm 1 can be used, with the following changes:\n\u2022 In the input, the numbers \u03bb\u2032 and k have now to fulfill\n\u03bb\u2212 \u03bb\u2032\u2032 < card{x\u03031, . . . , x\u0303\u03bb\u2032}, k \u2208 {1, . . . , \u03bb\u2212 \u03bb \u2032\u2032}. (26)\n\u2022 In Step 3, x (g+1) j = max\u227ac S \\ {x (g+1) i : i = 1, j \u2212 1} is chosen only for\nj = k + 1, . . . , \u03bb\u2212 \u03bb\u2032\u2032.\n\u2022 The output contains only the points x (g+1) \u03bb\u2032\u2032+1 , . . . , x (g+1) \u03bb .\nNeedless to say, this approach has to be combined with some of the approaches (i)\u2013(iii) and can be combined with any of them.\n(v) Generation-based evolution control. Whereas the previous four approaches represent, in terms of [11, 12], individual-based evolution control, we want to test also one approach that is generation-based, in the sense that the desired number \u03bb of points is evaluated by the original black-box fitness function only in selected generations. Similarly to the evolution strategy in [18, 19], our approach selects those generations adaptively, according to the agreement between the ranking of considered points by the surrogate model and by the black-box fitness. Differently to that strategy, however, we want to base the estimation if that agreement not on the generations in which \u03bb points have been evaluated by the black-box fitness, but on evaluating a small and evolvable number \u03bb\u2032\u2032\u2032 of additional points in each generation. In this context, it is important that in situations when the fitness is evaluated empirically, using some measurement or testing, the evaluation hardware causes the evaluation costs to increase step-wise, and to remain subsequently constant for some \u03bbhw evaluated points (e.g. in the optimization of catalyst preformance described in [10], \u03bbhw is the number of channels in the chemical reactor in which the catalysts are tested). In such a situation, the costs of evaluation are the lowest if \u03bb is a multiple of \u03bbhw, and if the evaluation of the \u03bb\n\u2032\u2032\u2032 additional points in each generation is cumulated for nhw generations such that\nnhw = max n\u2208N\nn\u03bb\u2032\u2032\u2032 \u2264 \u03bbhw. (27)\nSetting nhw = 1 covers the case when such a situation does not occur and the evaluation costs increase linearly with the number of points. If glast is the last generation in which \u03bb points have been evaluated by the black-box fitness, then for g = glast, . . . , glast +nhw \u2212 1, points x\u0303 g+1 1 , . . . , x\u0303 g+1 \u03bb\u2032 \u2208 R d are sampled from the distribution N(m(g), (\u03c3(g))2C(g)), from which the points x (g+1) 1 , . . . , x (g+1) \u03bb\u2032\u2032\u2032 are selected by Algorithm 1, in which the input \u03bb is replaced with \u03bb\u2032\u2032\u2032. Subsequently, all the points x (glast+1) 1 , . . . , x (glast+nhw) \u03bb\u2032\u2032\u2032 are evaluated by the black-box fitness, and for each generation g = glast + 1, . . . , glast + nhw, the agreement between the ranking of x g 1, . . . , x g \u03bb\u2032\u2032\u2032 by the current Gaussian process, GPcurrent, and the black-box fitness is estimated. If the agreement is sufficient in all considered generations, then the procedure is repeated using glast + nhw instead of glast and unchanged \u03bb \u2032\u2032\u2032. Otherwise, additional\npoints xg\u03bb\u2032\u2032\u2032+1, . . . , x g \u03bb\u2032\u2032\u2032+\u03bb are selected from x\u0303 g 1, . . . , x\u0303 g\n\u03bb\u2032 for the first generation g in which the agreement was not sufficient. Then a new Gaussian process, GPnew, is trained using the training set\nTnew =\ng \u22c3\ng\u2032=1\n{xg \u2032 1 , . . . , x g\u2032 \u03bb\u2032\u2032\u2032} \u222a {x g \u03bb\u2032\u2032\u2032+1, . . . , x g \u03bb\u2032\u2032\u2032+\u03bb}, (28)\noptionally including also some or all points from the set Tcurrent used for training GPcurrent. At that occasion, aslo the value of \u03bb\n\u2032\u2032\u2032 can be changed. Provided the conditions 1 \u2264 \u03bb\u2032\u2032\u2032 < \u03bb and \u03bb\u2032\u2032\u2032 + \u03bb \u2264 \u03bb\u2032 are fulfilled, the value of \u03bb\u2032\u2032\u2032 can be arbitrary. Needless to say, the smaller \u03bb\u2032\u2032\u2032, the larger will be the proportion of points from the generation in which the GP was trained in its training set, and the more similar the obtained GP will normally be to a GP trained only with data from that generation, which is the usual way of using surrogate models in traditional generation-based strategies [11, 12, 18, 19]. It is also worth pointing out that our generation-based evolution control was explained here as a counterpart to the basic individual-based approach (i), but counterparts to the approaches (ii) and (iii) are possible as well."}], "references": [{"title": "Model guided sampling optimization with Gaussian processes for expensive black-box optimization", "author": ["L. Bajer", "V. Charypar", "M. Hole\u0148a"], "venue": "GECCO 2013, pages 1715\u20131716", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "Investigating the local-meta-model cmaes for large population sizes", "author": ["Z. Bouzarkouna", "A. Auger", "D.Y. Ding"], "venue": "EvoApplications 2010, pages 402\u2013411", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "Local-meta-model cma-es for partially separable functions", "author": ["Z. Bouzarkouna", "A. Auger", "D.Y. Ding"], "venue": "GECCO 2011, pages 869\u2013876", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Accelerating evolutionary algorithms with Gaussian process fitness function models", "author": ["D. B\u00fcche", "N.N. Schraudolph", "P. Koumoutsakos"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews, 35:183\u2013194", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2005}, {"title": "Evolutionary optimization for computationally expensive problems using Gaussian processes", "author": ["M.A. El-Beltagy", "A.J. Keane"], "venue": "International Conference on Artificial Intelligence, pages 708\u2013714", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2001}, {"title": "Metamodelassisted evolution strategies", "author": ["M. Emmerich", "A. Giotis", "M. \u00d6zdemir", "T. B\u00e4ck", "K. Giannakoglou"], "venue": "PPSN VII, pages 361\u2013370", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2002}, {"title": "The CMA evolution strategy: A comparing review", "author": ["N. Hansen"], "venue": "Towards a New Evolutionary Computation, pages 75\u2013102. Springer Verlag, Berlin", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2006}, {"title": "Completely derandomized self-adaptation in evolution strategies", "author": ["N. Hansen", "A. Ostermaier"], "venue": "Evolutionary Computation, 9:159\u2013195", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2001}, {"title": "Controlled model assisted evolution strategy with adaptive preselection", "author": ["E. Hoffman", "S. Holemann"], "venue": "International IEEE Symposium on Evolving Fuzzy Systems, pages 182\u2013187", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2006}, {"title": "Surrogate modeling in the evolutionary optimization of catalytic materials", "author": ["M. Hole\u0148a", "D. Linke", "L. Bajer"], "venue": "GECCO 2012, pages 1095\u20131102", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "A comprehensive survery of fitness approximation in evolutionary computation", "author": ["Y. Jin"], "venue": "Soft Computing, 9:3\u201312", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2005}, {"title": "Managing approximate models in evolutionary aerodynamic design optimization", "author": ["Y. Jin", "M. Olhofer", "B. Sendhoff"], "venue": "CEC 2001, pages 592\u2013599", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2001}, {"title": "A taxonomy of global optimization methods based on response surfaces", "author": ["D.R. Jones"], "venue": "Journal of Global Optimization, 21:345\u2013383", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2001}, {"title": "Efficient global optimization of expensive black-box functions", "author": ["D.R. Jones", "M. Schonlau", "W.J. Welch"], "venue": "Journal of Global Optimization, 13:455\u2013492", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1998}, {"title": "Local metamodels for optimization using evolution strategies", "author": ["S. Kern", "N. Hansen", "P. Koumoutsakos"], "venue": "PPSN IX, pages 939\u2013948", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "A robust optimization approach using kriging metamodels for robustness approximation in the CMA-ES", "author": ["J.W. Kruisselbrink", "M.T.M. Emmerich", "A.H. Deutz", "T. B\u00e4ck"], "venue": "CEC 2010, pages 1\u20138", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "Comparison-based optimizers need comparison-based surrogates", "author": ["I. Loshchilov", "M. Schoenauer", "M. Seba"], "venue": "PPSN XI, pages 364\u2013373", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}, {"title": "Self-adaptive surrogate-assisted covariance matrix adaptation evolution strategy", "author": ["I. Loshchilov", "M. Schoenauer", "M. Seba"], "venue": "GECCO 2012, pages 321\u2013328", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2012}, {"title": "Intensive surrogate model exploitation in self-adaptive surrogate-assisted CMA-ES (saACM-ES)", "author": ["I. Loshchilov", "M. Schoenauer", "M. Seba"], "venue": "GECCO 2013, pages 439\u2013446", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "Response Surface Methodology: Proces and Product Optimization Using Designed Experiments", "author": ["R.H. Myers", "D.C. Montgomery", "C.M. Anderson-Cook"], "venue": "John Wiley and Sons, Hoboken", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2009}, {"title": "Gaussian Process for Machine Learning", "author": ["E. Rasmussen", "C. Williams"], "venue": "MIT Press, Cambridge", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2006}, {"title": "Ordinal regression in evolutionary computation", "author": ["T.P. Runarsson"], "venue": "PPSN IX, pages 1048\u20131057", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2006}, {"title": "Evolution strategies assisted by Gaussian processes with improved pre-selection criterion", "author": ["H. Ulmer", "F. Streichert", "A. Zell"], "venue": "IEEE Congress on Evolutionary Computation, pages 692\u2013699", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2003}], "referenceMentions": [{"referenceID": 6, "context": "CMA-ES [7, 8] is the state-of-the-art evolutionary optimization method, at least in the area of continuous black-box optimization.", "startOffset": 7, "endOffset": 13}, {"referenceID": 7, "context": "CMA-ES [7, 8] is the state-of-the-art evolutionary optimization method, at least in the area of continuous black-box optimization.", "startOffset": 7, "endOffset": 13}, {"referenceID": 3, "context": "Following [4], we differentiate two ways of using GPs in black-box optimization:", "startOffset": 10, "endOffset": 13}, {"referenceID": 13, "context": "This use of GPs has been introduced in the popular Efficient Global Optimization (EGO) algorithm [14].", "startOffset": 97, "endOffset": 101}, {"referenceID": 3, "context": "As the optimization method, also evolutionary optimization can be used, in particular CMA-ES [4], but this is not the only possibility: For example, traditional low-degree polynomial models, aka response surface models [20], are much more efficiently optimized using traditional smooth optimization methods.", "startOffset": 93, "endOffset": 96}, {"referenceID": 19, "context": "As the optimization method, also evolutionary optimization can be used, in particular CMA-ES [4], but this is not the only possibility: For example, traditional low-degree polynomial models, aka response surface models [20], are much more efficiently optimized using traditional smooth optimization methods.", "startOffset": 219, "endOffset": 223}, {"referenceID": 4, "context": ", for controlling the composition of its population [5, 6, 9, 23].", "startOffset": 52, "endOffset": 65}, {"referenceID": 5, "context": ", for controlling the composition of its population [5, 6, 9, 23].", "startOffset": 52, "endOffset": 65}, {"referenceID": 8, "context": ", for controlling the composition of its population [5, 6, 9, 23].", "startOffset": 52, "endOffset": 65}, {"referenceID": 22, "context": ", for controlling the composition of its population [5, 6, 9, 23].", "startOffset": 52, "endOffset": 65}, {"referenceID": 20, "context": "For the latter, it can be shown [21] that the function describing its mean fulfils (\u2200x \u2208 X) \u03bc0(x;X, Y ) = K(x,X)(K(X,X) + \u03c3 2 noiseIn) Y , (6)", "startOffset": 32, "endOffset": 36}, {"referenceID": 20, "context": "In that case, it can be shown [21] that for x \u2208 X,", "startOffset": 30, "endOffset": 34}, {"referenceID": 12, "context": "and the notation \u03c6 for the density of N(0, 1), (22) can be expressed as [13] x\u2217EI = argmax x\u2208X \u221a", "startOffset": 72, "endOffset": 76}, {"referenceID": 15, "context": "[16], who combine CMA-ES with a GP using the \u03b3-exponential function K, propose to employ in (15) the Mahalanobis distance of vectors x and x given by the covariance matrix obtained in the g-th generation of CMA-ES, (\u03c3)C, instead of their Euclidean distance.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "In this context, it is worth recalling that in [2, 3, 15], Mahalanobis instead of Euclidean distance was used when combining CMA-ES with quadratic response surface models in [2, 3, 15].", "startOffset": 47, "endOffset": 57}, {"referenceID": 2, "context": "In this context, it is worth recalling that in [2, 3, 15], Mahalanobis instead of Euclidean distance was used when combining CMA-ES with quadratic response surface models in [2, 3, 15].", "startOffset": 47, "endOffset": 57}, {"referenceID": 14, "context": "In this context, it is worth recalling that in [2, 3, 15], Mahalanobis instead of Euclidean distance was used when combining CMA-ES with quadratic response surface models in [2, 3, 15].", "startOffset": 47, "endOffset": 57}, {"referenceID": 1, "context": "In this context, it is worth recalling that in [2, 3, 15], Mahalanobis instead of Euclidean distance was used when combining CMA-ES with quadratic response surface models in [2, 3, 15].", "startOffset": 174, "endOffset": 184}, {"referenceID": 2, "context": "In this context, it is worth recalling that in [2, 3, 15], Mahalanobis instead of Euclidean distance was used when combining CMA-ES with quadratic response surface models in [2, 3, 15].", "startOffset": 174, "endOffset": 184}, {"referenceID": 14, "context": "In this context, it is worth recalling that in [2, 3, 15], Mahalanobis instead of Euclidean distance was used when combining CMA-ES with quadratic response surface models in [2, 3, 15].", "startOffset": 174, "endOffset": 184}, {"referenceID": 9, "context": "This can be done according to various strategies, we intend to use the one described in Algorithm 1, with which we have a good experience from using radial basis function networks for the evolution control in the evolutionary optimization of catalytic materials [10].", "startOffset": 262, "endOffset": 266}, {"referenceID": 1, "context": "The use of a linear ordering relates the proposed approach to ranking-based evolution control of CMA-ES [2, 3, 15, 23], as well as to surrogate modelling of CMA-ES by ordinal regression [17, 18, 19, 22].", "startOffset": 104, "endOffset": 118}, {"referenceID": 2, "context": "The use of a linear ordering relates the proposed approach to ranking-based evolution control of CMA-ES [2, 3, 15, 23], as well as to surrogate modelling of CMA-ES by ordinal regression [17, 18, 19, 22].", "startOffset": 104, "endOffset": 118}, {"referenceID": 14, "context": "The use of a linear ordering relates the proposed approach to ranking-based evolution control of CMA-ES [2, 3, 15, 23], as well as to surrogate modelling of CMA-ES by ordinal regression [17, 18, 19, 22].", "startOffset": 104, "endOffset": 118}, {"referenceID": 22, "context": "The use of a linear ordering relates the proposed approach to ranking-based evolution control of CMA-ES [2, 3, 15, 23], as well as to surrogate modelling of CMA-ES by ordinal regression [17, 18, 19, 22].", "startOffset": 104, "endOffset": 118}, {"referenceID": 16, "context": "The use of a linear ordering relates the proposed approach to ranking-based evolution control of CMA-ES [2, 3, 15, 23], as well as to surrogate modelling of CMA-ES by ordinal regression [17, 18, 19, 22].", "startOffset": 186, "endOffset": 202}, {"referenceID": 17, "context": "The use of a linear ordering relates the proposed approach to ranking-based evolution control of CMA-ES [2, 3, 15, 23], as well as to surrogate modelling of CMA-ES by ordinal regression [17, 18, 19, 22].", "startOffset": 186, "endOffset": 202}, {"referenceID": 18, "context": "The use of a linear ordering relates the proposed approach to ranking-based evolution control of CMA-ES [2, 3, 15, 23], as well as to surrogate modelling of CMA-ES by ordinal regression [17, 18, 19, 22].", "startOffset": 186, "endOffset": 202}, {"referenceID": 21, "context": "The use of a linear ordering relates the proposed approach to ranking-based evolution control of CMA-ES [2, 3, 15, 23], as well as to surrogate modelling of CMA-ES by ordinal regression [17, 18, 19, 22].", "startOffset": 186, "endOffset": 202}, {"referenceID": 22, "context": "[23], the difference being that they don\u2019t use clustering.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "(ii) GP on low-dimensional projections attempts to improve the basic approach in view of the experience reported in the literature [15] and obtained also in our earlier experiments [1] that GPs are actually advantageous only in low dimensional spaces.", "startOffset": 131, "endOffset": 135}, {"referenceID": 0, "context": "(ii) GP on low-dimensional projections attempts to improve the basic approach in view of the experience reported in the literature [15] and obtained also in our earlier experiments [1] that GPs are actually advantageous only in low dimensional spaces.", "startOffset": 181, "endOffset": 184}, {"referenceID": 10, "context": "Whereas the previous four approaches represent, in terms of [11, 12], individual-based evolution control, we want to test also one approach that is generation-based, in the sense that the desired number \u03bb of points is evaluated by the original black-box fitness function only in selected generations.", "startOffset": 60, "endOffset": 68}, {"referenceID": 11, "context": "Whereas the previous four approaches represent, in terms of [11, 12], individual-based evolution control, we want to test also one approach that is generation-based, in the sense that the desired number \u03bb of points is evaluated by the original black-box fitness function only in selected generations.", "startOffset": 60, "endOffset": 68}, {"referenceID": 17, "context": "Similarly to the evolution strategy in [18, 19], our approach selects those generations adaptively, according to the agreement between the ranking of considered points by the surrogate model and by the black-box fitness.", "startOffset": 39, "endOffset": 47}, {"referenceID": 18, "context": "Similarly to the evolution strategy in [18, 19], our approach selects those generations adaptively, according to the agreement between the ranking of considered points by the surrogate model and by the black-box fitness.", "startOffset": 39, "endOffset": 47}, {"referenceID": 9, "context": "in the optimization of catalyst preformance described in [10], \u03bbhw is the number of channels in the chemical reactor in which the catalysts are tested).", "startOffset": 57, "endOffset": 61}, {"referenceID": 10, "context": "Needless to say, the smaller \u03bb, the larger will be the proportion of points from the generation in which the GP was trained in its training set, and the more similar the obtained GP will normally be to a GP trained only with data from that generation, which is the usual way of using surrogate models in traditional generation-based strategies [11, 12, 18, 19].", "startOffset": 344, "endOffset": 360}, {"referenceID": 11, "context": "Needless to say, the smaller \u03bb, the larger will be the proportion of points from the generation in which the GP was trained in its training set, and the more similar the obtained GP will normally be to a GP trained only with data from that generation, which is the usual way of using surrogate models in traditional generation-based strategies [11, 12, 18, 19].", "startOffset": 344, "endOffset": 360}, {"referenceID": 17, "context": "Needless to say, the smaller \u03bb, the larger will be the proportion of points from the generation in which the GP was trained in its training set, and the more similar the obtained GP will normally be to a GP trained only with data from that generation, which is the usual way of using surrogate models in traditional generation-based strategies [11, 12, 18, 19].", "startOffset": 344, "endOffset": 360}, {"referenceID": 18, "context": "Needless to say, the smaller \u03bb, the larger will be the proportion of points from the generation in which the GP was trained in its training set, and the more similar the obtained GP will normally be to a GP trained only with data from that generation, which is the usual way of using surrogate models in traditional generation-based strategies [11, 12, 18, 19].", "startOffset": 344, "endOffset": 360}], "year": 2014, "abstractText": "CMA-ES [7, 8] is the state-of-the-art evolutionary optimization method, at least in the area of continuous black-box optimization. Basically, it consists in generating new search points by sampling from a multidimensional normal distribtion, the mean and variance of which are updated from generation to generation. In particular, the population x (g+1) 1 , . . . , x (g+1) \u03bb \u2208 R d of the g + 1-st generation, g \u2265 1, follows the normal distribution with mean m \u2208 R and variance (\u03c3)C \u2208 R resulting from the update in the g-th generation,", "creator": "LaTeX with hyperref package"}}}