{"id": "1412.0439", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Dec-2014", "title": "Fuzzy human motion analysis: A review", "abstract": "Human Motion Analysis (HMA) name primarily more common instead highly b\u0101l\u0101 generally biomedical bind been other greater research interests are violent once though except as makes challenge requiring instead most video air, leagues techniques, healthcare requires also so recently. However, well of these real history applications serious central levels other downturns that might affect the operations of such applications. Hence, the fuzzy well object has previously applied especially signs the yet until the recent have. In this paper, take strengthen where reviewing first fuzzy and mainstream transition for HMA, individuating they in wuzzy fourth any improve under HMA, envisioning along hilar the continues perspectives. To but just important our furthermore, because goes come other. making nationally as the in literature say could administration and excerpts mimics approaches towards under HMA. For mounting important harmony, everybody conceptually assimilate the biological requires into set focus maximum: Low - Level (LoL ), Mid - Level (MiL ), those High - Level (HiL) HMA.", "histories": [["v1", "Mon, 1 Dec 2014 11:42:51 GMT  (6703kb)", "https://arxiv.org/abs/1412.0439v1", "Accepted in Pattern Recognition, first survey paper that discusses and reviews fuzzy approaches towards HMA"], ["v2", "Tue, 2 Dec 2014 18:19:13 GMT  (5727kb)", "http://arxiv.org/abs/1412.0439v2", "Accepted in Pattern Recognition, first survey paper that discusses and reviews fuzzy approaches towards HMA"]], "COMMENTS": "Accepted in Pattern Recognition, first survey paper that discusses and reviews fuzzy approaches towards HMA", "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["chern hong lim", "ekta vats", "chee seng chan"], "accepted": false, "id": "1412.0439"}, "pdf": {"name": "1412.0439.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Chee Seng Chan"], "emails": ["ektavats_2608}@siswa.um.edu.my;"], "sections": [{"heading": null, "text": "ar X\niv :1\n41 2.\n04 39\nv2 [\ncs .C\nV ]\n2 D\nec 2\n01 4\nHuman Motion Analysis (HMA) is currently one of the most popularly active research domains as such significant research interests are motivated by a number of real world applications such as video surveillance, sports analysis, healthcare monitoring and so on. However, most of these real world applications face high levels of uncertainties that can affect the operations of such applications. Hence, the fuzzy set theory has been applied and showed great success in the recent past. In this paper, we aim at reviewing the fuzzy set oriented approaches for HMA, individuating how the fuzzy set may improve the HMA, envisaging and delineating the future perspectives. To the best of our knowledge, there is not found a single survey in the current literature that has discussed and reviewed fuzzy approaches towards the HMA. For ease of understanding, we conceptually classify the human motion into three broad levels: Low-Level (LoL), Mid-Level (MiL), and High-Level (HiL) HMA.\nKeywords: Human motion analysis, fuzzy set theory, action recognition"}, {"heading": "1. Introduction", "text": "Human motion analysis (HMA) refers to the analysis and interpretation of human movements over time. For decades, it has been a popular research topic that crossovers many domains such as biology [1, 2], psychology [3, 4], multimedia [5] and so on. In the computer vision domain, HMA has been emerging actively over the years due to the advancement of video camera technologies and the availability of more sophisticated computer vision algorithms in the public domain. Here, the HMA concerns the detection, tracking and recognition of human, and more generally the understanding of human behaviors, from image sequences involving humans. Amongst all, video surveillance is one of the most important real-time applications [6, 7, 8, 9, 10]. For instance, as illustrated in Figure 1, the Madrid, London and Boston marathon bombing tragedies, happened in 2004, 2005 and 2013 respectively, would not have been worse if an intelligent video surveillance system that capable of automatically detecting abnormal human behavior was installed in the public areas. Apart from that, HMA also contributed in video retrieval [11], sports analysis [12, 13, 14], healthcare monitoring [15, 16], human-computer interaction [17] and so on.\nThe importance and popularity of the HMA system has led to several surveys in the literature, as indicated in Table 1. One of the earliest surveys was [18], focused on various methods employed in the analysis of the human body motion, which is in non-rigid form. [19] gave an overview on the motion extraction methods using the motion capture systems and focused on action recognition, individual body parts recognition, and body configuration estimation. [20] used the same taxonomy as in [19], but engaging different labels for the three classes, that is further dividing the classes into subclasses yielding a more comprehensive taxonomy. [21] gave an overview on the applications of visual analysis of human movements, and their taxonomy covered the 2D and 3D approaches with and without the explicit shape models.\nAs the works in this area prosper, public datasets start to gain importance in the vision community to meet different research challenges. The KTH [38] and the Weizmann [39, 40] datasets were the most popular human actions\n*Chern Hong Lim and Ekta Vats contributed equally to this paper. **Corresponding author.\nPreprint submitted to Elsevier December 3, 2014\ndatasets introduced in the early stages. However, neither of the datasets represent the human actions in a real world environment. In general, each action is performed in a simple manner with just a single actor, static background and fixed view point. KTH however considered a few complex situations such as different lighting conditions, but it is still far away from the real world complex scenarios. Therefore, other datasets were created such as the CAVIAR, ETISEO, CASIA Action, MSR Action, HOLLYWOOD, UCF datasets, Olympic Sports and HMDB51, BEHAVE, TV Human Interaction, UT-Tower, UT-Interaction, etc. Please refer to [37] for a complete list of the currently available datasets in HMA.\nDue to the advancement of the technology, using networks of multiple cameras for monitoring public places such as airports, shopping malls, etc. were emerged. [7, 20, 21, 24, 25, 28, 29, 32, 33] moved ahead to survey on the representation and recognition of the human actions in multiple-views aspect. Various new datasets were created exclusively for this purpose such as the IXMAS, i3DPost, MuHAVi, VideoWeb and CASIA Action. Last but not the least, [7, 21, 23, 24, 27, 31, 36] surveyed on the various applications of HMA such as the smart surveillance and advanced user interface for human-computer interaction. For the convenience of the readers, we summarize in Table 1 and 2 the available survey papers and their respective focuses."}, {"heading": "1.1. Motivation and contributions", "text": "Fuzzy set theory since its inception in 1965, has played an important role in a variety of applications, for example the subway system in Sendai, Japan; washing machine; digital camera and so on. The research works on the fuzzy set theory in real world problems are abounded. In this paper, we will focus primarily on the solutions that utilize the fuzzy approaches towards HMA. Particularly, our main aim and contribution is to review the early years of the fuzzy set oriented approaches for HMA, individuating how the fuzzy set may improve the HMA, envisaging and delineating the future perspectives. This is in contrast to the past surveys as listed in Table 1 and 2 where stochastic solutions were the predominant discussions.\nTo the best of our knowledge, there is not found a single survey in the literature that has discussed and reviewed the fuzzy approaches towards HMA. The nearest studies to ours are [41, 42, 43]. [41] was the earliest survey that discussed the uncertainties in computer vision using the fuzzy sets. Specifically, it addressed the uncertainty in three levels: image segmentation, edge detection and shape representation. Later, [42] gave a broad overview of the fuzzy set theory towards computer vision with applications in the areas of image modeling, preprocessing, segmentation, boundary detection, object/region recognition, and rule-based scene interpretation. The involved tasks were noise removal, smoothing, and sharpening of the contrast (low-level vision); segmentation of images to isolate the objects and the regions followed by the description and recognition of the segmented regions (intermediate-level vision); and finally the interpretation of the scene (high-level vision). Finally, [43] addressed various aspects of image processing and analysis problems where the theory of fuzzy set was applied.\nFor ease of understanding, we conceptually classify the human motion into three broad levels: Low-Level (LoL), Mid-Level (MiL), and High-Level (HiL) HMA, as depicted in Figure 2. The LoL HMA is the background/foreground subtraction which contributes in the pre-processing of the raw images to discover the areas of interest such as the human region. MiL HMA is the object tracking. In this level, it serves as the means to prepare data for pose estimation and activity recognition. HiL HMA is the behavior understanding where the objective is to correctly classify the human motion patterns into activity categories; for example, walking, running, wave hands and so on.\nThe remainder of this paper is organized as follows. Section 2 reviews the works on LoL HMA including the motion segmentation and the moving object classification. Section 3 covers the MiL HMA in terms of model-based and non-model based human tracking. The paper then extends the discussion to the HiL HMA that recognizes the human behavior in the image sequences in Section 4. Section 5 provides a detailed discussion on some advantages of the fuzzy approaches and presents some possible directions for the future research at length. Section 6 concludes the paper."}, {"heading": "2. Low-level HMA", "text": "Human detection is the enabling step in almost every low-level vision-based HMA system before the higher level of processing steps such as tracking and behavior understanding can be performed. Technically, human detection aims at locating and segmenting the regions bounding the people from the rest of the image. This process usually involves first of all, the motion segmentation, and followed by the object classification."}, {"heading": "2.1. Motion segmentation", "text": "Motion segmentation aims at separating the moving objects from the natural scenes. The extracted motion regions are vital for the next level of processing, e.g. it relaxes the tracking complexity as only the pixels with changes are considered in the process. However, some critical situations in the real world environment such as the illumination\nchanges, dynamic scene movements (e.g. rainy weather, waving tree, rippling water and so on), camera jittering, and shadow effects make it a daunting task. In this section, we will mainly review fuzzy approaches that had addressed the background subtraction problems.\nBackground subtraction is one of the popular motion segmentation algorithms that has received much attention in the HMA system. This is due to the usefulness of its output that is capable of preserving the shape information, as well as helps in extracting motion and contour information [44, 45, 46]. In general, background subtraction is to differentiate between the image regions which have significantly different characteristics from the background image (normally denoted as the background model). A good background subtraction algorithm comprises of a background model that is robust to the environmental changes, but sensitive to identify all the moving objects of interest. There are some fuzzy approaches that endowed this capability in the background subtraction which will be discussed as follows."}, {"heading": "2.1.1. Fuzzy integral", "text": "Information fusion from a variety of sources is the most straightforward and effective approach to increase the classification confidence, as well as removing the ambiguity and resolving the conflicts in different decisions. Rationally in background modeling, the combination of several measuring criteria (also known as the features or attributes) can strengthen the pixel\u2019s classification as background or foreground. However the basic mathematical operators used for aggregation such as the minimum, maximum, average, median, \u2018AND\u2019, and \u2018OR\u2019 operators provide crisp decisions and utilize only a single feature that tends to result in false positive [47]. In contrast, the fuzzy integrals take into account the importance of the coalition of any subset of the criteria [48].\nIn general, the fuzzy integral is a non-linear function that is defined with respect to the fuzzy measure such as a belief or a plausibility measure [49], and is employed in the aggregation step. As the fuzzy measure in the fuzzy integral is defined on a set of criteria, it provides precious information about the importance and relevance of the criteria to the discriminative classes. Thus it achieves feature selection with better classification results. [47] proposed to use the Sugeno integral [50] to fuse color and texture features in their works for better classification of the pixel that\nbelongs to either background or foreground, while [48, 51, 52] improved [47] by replacing the Sugeno integral with the Choquet integral [53]. The main reason is that the Choquet integral which was adapted for cardinal aggregation, was found to be more suitable than the Sugeno integral that assumed the measurement scale to be ordinal [54, 55]. The corresponding results for the comparison between the Sugeno integral and the Choquet integral are shown in Figure 3. The background modeling process using the fusion of color and texture features have shown to achieve better detection of the moving targets against cluttered backgrounds, backgrounds with little movements, shadow effects as well as illumination changes."}, {"heading": "2.1.2. Type-2 Gaussian mixture model", "text": "The studies on the background subtraction [56, 57] have shown that the Gaussian Mixture Model (GMM) is one of the popular approaches used in modeling the dynamic background scene. It solves the limitation in the unimodal model (single Gaussian) which is unable to handle the dynamic backgrounds such as waving tree and water rippling. The expectation-maximization algorithm is normally used in the initialization step of the GMM to estimate the parameters from a training sequence using the Maximum-likelihood (ML) criterion. However, due to insufficient or noisy training data, the GMM may not be able to accurately reflect the underlying distribution of the observations. This is because exact numbers must be used in the likelihood computation and unfortunately, these parameters are bounded by uncertainty. In order to take into account the uncertainty, the fuzzy set theory was explored.\nHowever, there has been an argument that type-1 fuzzy set, which is an ordinary fuzzy set [59], has limited capability in modeling the uncertainty. This is because the membership function for the type-1 fuzzy set is not associated with uncertainty. Therefore, type-2 fuzzy sets [60] emerged from the type-1 fuzzy set by generalizing it to handle more uncertainty in the underlying fuzzy membership function. As a whole, the type-2 fuzzy membership function is itself a fuzzy set and referring to Figure 4, it can be noticed that the uncertainty in the fuzzy membership function is represented in the shaded area known as the Footprint of Uncertainty (FOU). With the capability of type-2 fuzzy set to handle higher dimensions of uncertainty, it was adopted in [58] to represent the multivariate Gaussian with an uncertain mean vector or a covariance matrix. In more detail, it was assumed that the mean and the standard deviation vary within the intervals with uniform possibilities (Figure 4), instead of crisp values as in the conventional GMM.\nSeveral works [61, 62, 63] have been reported that utilized the type-2 fuzzy GMM to deal with insufficient or noisy data, and resulted in better background subtraction model. In the later stage, [64] made an improvement on these works with the inclusion of spatial-temporal constraints into the type-2 fuzzy GMM by using the Markov Random Field."}, {"heading": "2.1.3. Hybrid technique", "text": "Although the fuzzy approaches provide superior performance in background subtraction, most of these approaches have a common problem, that is how to optimize the parameters in their algorithms. These parameters can be the intrinsic parameters such as the interval values of the membership function, or the threshold value for the inference step. Optimizing these parameters usually increases the overall system performance. However, such steps require human intervention [47, 51, 48]. For example, the trial and error process to determine a classification threshold value is a tedious job, computationally expensive and subjective [65].\nFortunately, such limitations can be handled by using hybrid techniques, i.e. the combination of fuzzy approaches with machine learning methods. [66] applied neural fuzzy framework to estimate the image motion. The backpropagation learning rule from a five-layered neural fuzzy network was used to choose the best membership functions so that the system is able to adapt to different environments involving occlusions, specularity, shadowing, transparency and so on. Besides that, [67] introduced a spatial coherence variant incorporated with the self-organizing neural network to formulate a fuzzy model to enhance the robustness against false detection in the background subtraction algorithm. [68] used both the particle swarm optimization and the kernel least mean square to update the system parameters of a fuzzy model, and [69] employed a tuning process using the Marquardt-Levenberg algorithm within a fuzzy system to fine-tune the membership function. In order to determine the appropriate threshold value for the classification task, [70] proposed a novel fuzzy-cellular method that helps in dynamically learning the optimal threshold value."}, {"heading": "2.2. Object classification", "text": "The outcome from the motion segmentation usually results in a rough estimation of the moving targets in a natural scene. These moving targets in a natural scene can be shadow, vehicle, flying bird and so on. Before the region is further processed at the next level, it is very important to verify and refine the interest object by eliminating the unintended objects. In this section, we discuss some fuzzy approaches that are beneficial in the human object classification."}, {"heading": "2.2.1. Type-1 fuzzy inference system", "text": "The Type-1 Fuzzy Inference System (FIS) [72] is a complete fuzzy decision making system that utilizes the fuzzy set theory. It has been successfully applied in numerous applications for commercial and research purposes. Its popularity is due to the capability to model the uncertainty and the sophisticated inference mechanism that greatly compromises the vague, noisy, missing, and ill-defined data in the data acquisition step. Figure 5 shows the overall\nframework of a typical Type-1 FIS, where it includes three important steps: fuzzification, inference, and defuzzification. The fuzzification step maps the crisp input data from a set of sensors (features or attributes) to the membership functions to generate the fuzzy input sets with linguistic support [73]. Then, the fuzzy input sets go through the inference steps with the support from a set of fuzzy rules to infer the fuzzy output sets. Finally, the fuzzy output sets are defuzzified into the crisp outputs.\nIn human detection, the FIS is an effective and direct approach to distinguish between the human and non-human with different features [75, 74, 76]. As an example, [74] extracted three features from the contours of the segmented region, such as the distance to the centroid, angle, and cord to arc ratio, and input them into the FIS. The corresponding fuzzy membership function and a set of fuzzy rules were used to infer the fuzzy output as depicted in Figure 6. The fuzzy outputs (VL, L, M, H, VH) were then defuzzified into the crisp outputs, and used to perform human classification. For example, if the crisp output is found to be less than the threshold value, then it is recognized as a human and vice versa.\nBesides that, [77, 78] studied in depth about the problems encountered in the human classification tasks, such as the situations where the unintended objects are attached to the classified human region. This problem often occurs in the silhouette based classification output. In general, silhouette is the binary representation of the segmented regions from the background subtraction techniques, where in HMA, human silhouette has proved its sufficiency to describe the activities captured by the video [44, 45, 46]. For example. a chair that is being moved by a person can be misclassified as a part of the segmented region, and included as part of the silhouette image. In order to solve this, [77, 78] applied the FIS to perform an adaptive silhouette extraction in the complex and dynamic environments. In their works, they used multiple features such as the sum of absolute difference (SAD), fraction of neighbor blocks, and distance between blocks and human body centroid. A set of fuzzy rules were generated, for instance, \u201cIF SAD is SMALL, AND the fraction of neighboring silhouette blocks belong to the human body is LARGE, AND the distance from the centroid is SMALL, THEN the new block is more likely to be a human silhouette block\u201d. Depending upon the application, the FIS is capable of modeling different sources of features by generating the appropriate fuzzy membership functions and the fuzzy rules."}, {"heading": "2.2.2. Type-2 fuzzy inference system", "text": "To a certain extent, the overall performance of the system from [77, 78] may be degraded due to the misclassification of the objects in the proposed type-1 FIS. Taking this into account, [79] employed the interval type-2 FIS [80] which is capable of handling higher uncertainty levels present in the real world dynamic environments.\nIn general, as aforementioned, the type-2 FIS differs from the type-1 FIS in terms of the type-2 FIS offers the capability to support higher dimensions of uncertainty. The main focus in the type-2 FIS is the membership function that is used to represent the input data, where the membership function itself is a fuzzy set with FOU bounded in an ordinary membership function. In consequences, the input data is first fuzzified into type-2 input fuzzy sets, and then go through the inference process where the rules can be similar as the type-1 FIS. Before the defuzzification step takes place, the type-2 output fuzzy sets must be reduced from type-2 to type-1 output fuzzy set. This is processed by using a type-reducer, as depicted in Figure 7.\nUsing the same features as [77, 78], [79] proposed to fuzzify the input feature values into the type-2 fuzzy sets using the singleton fuzzification method [81]. Consequently, it produces the interval type-2 membership functions for the inference process. Their approach was tested on a set of images captured from the real world environment that contains single person, multi-person and the crowded scenes, respectively. The ground truth data was captured from the cameras deployed around their laboratory (i.e. a smart living room) to analyze people\u2019s regular activities. Their proposed work showed that the type-2 FIS provides much better results as compared to the type-1 FIS (Figure 8). For ease of understanding of the readers, the problems of the works in LoL HMA with the intuition of using fuzzy approaches as the resolution are summarized in Table 3."}, {"heading": "3. Mid-level HMA", "text": "After we have successfully located the human in the frame, the next step is to track the human movements over time for the higher level interpretation. Tracking is a crucial step in HMA as it forms the basis for data preparation for HiL HMA tasks such as action recognition, anomaly event detection and so on. The aim of tracking algorithm is to reliably track the interest objects such as the human body from a sequence of images, and it can be categorized as model based and non-model based motion tracking."}, {"heading": "3.1. Model based tracking", "text": "In the model based human motion tracking, the human body models such as the stick figures, 2D and 3D motion description models are adopted to model the complex, non-rigid structure of the human body [82, 83, 84, 85, 86, 87, 88, 89, 90, 91]. Readers can refer to [20, 21, 24, 92] for the detailed reviews. The stick figure model represents the human body as a combination of sticks or line segments connected by the joints [82, 83, 84, 85], while the 2D models represents the human body using 2D ribbons or blobs [83, 86, 87]. 3D models are used to depict the human body structure in a more detailed manner using cones, cylinders, spheres, ellipses etc. [88, 89, 90, 91].\nHowever, tracking human in video sequences is not an easy task. The human body has a complex non-rigid structure consisting of a number of joints (e.g. the leg is connected to the foot by the ankle joint) and each body part can therefore move in a high degree of freedom around its corresponding joints. This often results in self-occlusions of the body parts. 3D models are able to handle such scenarios, but there are other factors that can affect the tracking performance such as the monotone clothes, cluttered background and changing brightness [93]. Therefore, the fuzzy approaches such as the fuzzy qualitative kinematics, the fuzzy voxel person, and the fuzzy shape estimation are explored in the model based human motion tracking algorithms to handle the uncertainties."}, {"heading": "3.1.1. Fuzzy qualitative kinematics", "text": "A variety of works in the model based human motion tracking have employed the kinematic chain [82, 83, 84, 85, 86, 87, 88, 89, 90, 91]. Bregler et al. [94] demonstrated a comprehensive visual motion estimation technique using the kinematic chain in a complex video sequence, as depicted in Figure 9. However, the crisp representation of the kinematic chain has a limitation. It suffers from the precision problem [95] and the cumulative errors can directly affect the performance of the higher level tasks. Therefore, a better strategy is required to model the kinematic chain, and to this end, the fuzzy qualitative kinematics has been proposed.\nTo begin with, the fuzzy qualitative reasoning [97, 98] is a form of approximate reasoning that can be defined as the fusion between the fuzzy set theory [59] and the qualitative reasoning [99]. The qualitative reasoning operates with the symbolic \u2018quantities\u2019, while the fuzzy reasoning reasons with the fuzzy intervals of varying precisions, providing a means to handle the uncertainty in a natural way. Therefore, the fuzzy qualitative reasoning incorporates the advantages of both the approaches to alleviate the hard boundary or the crisp values of the ordinary measurement\nspace. For instance, [100] applied this in the Fuzzy Qualitative Trigonometry (Figure 10) where the ordinary Cartesian space and the unit circle are substituted with the combination of membership functions yielding the fuzzy qualitative coordinate and the fuzzy qualitative unit circle. Extension from this, a fuzzy qualitative representation of the robot kinematics [95, 101] was proposed. The work presented a derivative extension to the Fuzzy Qualitative Trigonometry [100]. Motivated by these approaches, [102] proposed a data quantization process based on the Fuzzy Qualitative Trigonometry to model the uncertainties during the kinematic chain tracking process; and subsequently constructed a generic activity representation model."}, {"heading": "3.1.2. Fuzzy voxel person", "text": "As aforementioned, the 3D models provide more useful information than the 2D models as the features (height, centroid, orientation, etc.) in the 3D space are camera-view independent. Inspired by this, [16, 104] demonstrated a method to construct a 3D human model in voxel (volume element) space using the human silhouette images called the voxel person (Figure 11). However, due to the location of the cameras and the object\u2019s positions, the gathered information using the crisp voxel person model can be sometimes imprecise and inaccurate. The crisp technique works well if and only if there are sufficient number of cameras. But unfortunately, it is hard to find more than a couple of cameras in the same area due to the high cost involved and the limited space area.\nTherefore, fuzzy voxel person was utilized in [103] by employing only a few cameras and a minimal prior knowledge about the object. The FIS was used to determine the membership degree of the voxel person, reflecting how likely it belongs to the actual object. Extreme body joints viewing conditions were taken into account and it was observed that the fuzzy acquired results were much better than the crisp approach, both qualitatively (as shown in Figure 12) as well as quantitatively [103]. This concept of the fuzzy voxel person was incorporated in a number of works [16, 104]."}, {"heading": "3.1.3. Fuzzy shape estimation", "text": "The regions of interest extracted from the background subtraction algorithm are normally represented using different shape models, such as ribbons and blobs for 2D images, while cones, cylinders, spheres, ellipses etc. for the 3D images. Here, we will concentrate mainly on the blob representation. For a tracking system with reliance on the shape estimation, problems arise due to imperfect image segmentation techniques. This is because of the image irregularities, shadows, occlusions, etc. that results in multiple blobs generation for a single object. Besides that, in the multiple objects tracking, recovering from the overlapping regions is a big challenge. In order to solve this, [105, 106] applied FIS to update both the trajectories and the shape estimated for the targets with a set of image regions. These image regions are represented using the blobs extracted from each frame. Following the general steps of the FIS, heuristic\nfeatures were extracted from the detected blobs, and used as inputs to the FIS to assess the confidence values assigned to each blob to update the estimators describing the targets\u2019 shape and the tracks. With this, the tracking can be locked if the confidence of the target shape is low. This is to prevent the tracking to deviate from the real path caused by the cumulated errors such as the uncertain shape. The tracking resumes once the confidence of the object shape is high."}, {"heading": "3.2. Non-model based tracking", "text": "In non-model based tracking, the objects detected are represented using the random dispersed points instead of the rigid shape models (e.g. stick figure, blob, cylinder, etc.). The association amongst the points that contribute to the motion tracking are based on the hypothesis which takes into account the object\u2019s characteristics and behavior. This is a complex problem to be formulated because of the presence of occlusions, misdetections, new object entries etc. that may lead to permanent tracking error. The fuzzy approaches such as the fuzzy Kalman filter, fuzzy particle filter, fuzzy optical flow and fuzzy clustering are widely employed in the non-model based object tracking, where they explicitly take into account the uncertainties to establish the point correspondence between the object motions."}, {"heading": "3.2.1. Fuzzy Kalman filter", "text": "Kalman filter, the popular optimal estimator capable of operating recursively on the streams of noisy input data [107], is a popular choice for tracking a moving object. It has been successfully applied in several previous works on the human motion tracking [91, 108, 109, 110, 111, 112]. There are three basic steps involved in the Kalman filtering for human motion tracking: initialization, prediction and correction [113]. Often the complex dynamic trajectories due to the changes in the acceleration of human motion are not feasible to be modeled by the linear systems. Therefore, instead of the basic Kalman filters, the Extended Kalman filters are used which are capable of modeling the non-linear states. However, all these Kalman filtering algorithms suffer from the divergence problem if the theoretical behavior of a filter and its actual behavior do not agree. The divergence due to modeling errors is a critical issue in the Kalman filtering process.\nIn order to solve this, the FIS was adopted in the Kalman filtering [114, 115, 116, 117, 118, 119] to detect the bias of measurements and prevent the divergence. The new Kalman filter is called as the fuzzy adaptive Kalman filter. Takagi-Sugeno fuzzy model is used to detect the divergence and the uncertainty of the parameters in the Kalman filter such as the covariance and the mean value are modeled as membership function with the corresponding fuzzy rules for inference. To this extent, [120] proposed the evolving Takagi-Sugeno fuzzy model [121, 122] which can be seen as the fuzzy weighted mixture of the Kalman filter for object tracking in the video streams, and the performance is better than the ordinary Kalman Filter."}, {"heading": "3.2.2. Fuzzy particle filter", "text": "Similar to the Kalman filters, the particle filters offer a good way to track the state of a dynamic HMA system. In general, if one has a model of how the system changes with time, and possible observations made in particular\nstates, the particle filters can be employed for tracking. However, as compared to the Kalman filters, the particle filters offer a better tracking mechanism as it provides multiple predictions or hypothesis (i.e. as many as hypothesis as the number of particles) to recover from the lost tracks, which helps to overcome the problems related to the complex human motion. One must note that there is a tradeoff between system precision and computational cost in the particle filter framework, i.e. more number of particles improves the system precision, but also increases the computational cost and vice versa.\nAs a remedy to the above mentioned problems, a new sequential fuzzy simulation based particle filter was proposed in [123] to estimate the state of a dynamic system with noises described as fuzzy variables using the possibility theory. In most of the current particle filtering algorithms, the uncertainty of the tracking process and the measurement of noises are expressed by the probability distributions, which are sometimes hard to construct due to the lack of statistical data. Therefore, it is more suitable to compute the possibility measure using the fuzzy set theory for modeling the uncertain variables with imprecise knowledge. [123] found that their proposed fuzzy logic based particle filter outperforms the traditional particle filter even when the number of particles is small. Another variant of this work is [124], where an adaptive model is implemented in the fuzzy particle filter with the capability to adjust the number of particles by using the result from the measurement step, and improve the speed of an object tracking algorithm. Apart from that, [96, 102] handled the tradeoff between the system precision and the computational cost by employing data quantization process that utilizes the Fuzzy Quantity Space [100]. In general, the work quantize the particles into finite fuzzy qualitative states. As such, the system able to model the offset of the tracking errors, while retaining the precision when relatively low number of particles are selected to perform the tracking task. Last but not the least, the FIS has also contributed in the particle filters [125, 126] and achieved better accuracy with lower computational cost."}, {"heading": "3.2.3. Fuzzy optical flow", "text": "Optical flow [127, 128] is another popular motion tracking algorithm. It is an efficient technique for approximating the object motion in two consecutive video frames by computing the intensity variations between them. However, the removal of the incoherent optical flow field is still a great challenge. This is because the incoherent regions can be treated as random noises in the optical flow field due to the sources of disturbances in a natural scene (e.g. dynamic background). Fuzzy hostility index was introduced in [129, 130] to overcome this issue and thus improving the time efficiency of the flow computation. The fuzzy hostility index [131] measures the amount of homogeneity or heterogeneity of the neighborhood pixel in the optical flow field. The more homogeneous is the neighborhood of a pixel, the less is the pixel hostile to its neighbor. This implies that a denser neighborhood indicates a more coherent optical flow neighborhood region. To deal with the uncertain conditions, soft computing is applied where the hostility index computed from the neighborhood pixels is represented as a fuzzy set, where the membership values lie between 0 and 1. This method has shown the capability to track fast moving objects from the video sequences efficiently."}, {"heading": "3.2.4. Fuzzy clustering", "text": "Clustering is an unsupervised machine learning solution that learns the unlabeled data by grouping the similar ones into the corresponding groups autonomously. Inspired from this, multi-object cluster trackings [133, 134] were introduced with the belief that the moving targets always produce a particular cluster of pixels with similar characteristics in the feature space, and the distribution of these clusters changes only little between the consecutive frames. [132] proposed a fast fuzzy c-means (FCM) clustering tracking method which offers a solution towards the high complexity and the computational cost involved in the conventional methods on multi-object tracking, and also the hard clustering algorithms such as the k-means that causes failure in the case of severe occlusions and pervasive disturbances. FCM is also recognized as the soft clustering algorithm where it applies data partition to allocate each sample data into more than one clusters with the corresponding membership values which is more meaningful and stable than the hard clustering algorithms. In [132], the component quantization filtering was incorporated with FCM to provide faster processing speed. Table 4 summarizes the intuition of using the fuzzy approaches in MiL HMA."}, {"heading": "4. High-level HMA", "text": "The final aim of the HMA system is to perform human behavior understanding. In this section, we study the feasibility of the fuzzy approaches to achieve this with emphasis on: (a) hand gesture recognition, (b) activity recognition, (c) style invariant action recognition, (d) multi-view action recognition, and (e) anomaly event detection."}, {"heading": "4.1. Hand gesture recognition", "text": "Gesture recognition aims at recognizing meaningful expressions of the human motion, involving the hands, arms, face, head, or body. The applications of gesture recognition are manifold [135], ranging from the sign language to medical rehabilitation and virtual reality. The importance of gesture recognition lies in building efficient and intelligent human-computer interaction applications [136] where one can control the system from a distance for a specific task, i.e. without any cursor movements or screen touching. Besides that, nowadays, there exists successful commercialized gesture recognition devices such as the Kinect: a vision-based motion sensing device, capable of inferring the human activities. Unfortunately, in a gesture recognition system, the complex backgrounds, dynamic lighting conditions and sometimes the deformable human limb shapes can lead to high level of uncertainties and ambiguities in recognizing the human gestures. Also, \u201cpure\u201d gestures are seldom elicited, as people typically demonstrate \u201cblends\u201d of these gestures [137]. Among all the solutions, the fuzzy clustering algorithms and the integration of fuzzy approaches with machine learning methods are often incorporated to deal with such difficult situations and achieve better system performance. In this section, we review the relevant works with emphasis on the hand gesture recognition."}, {"heading": "4.1.1. Fuzzy clustering", "text": "Among the well-known clustering techniques are K-means, GMM, hierarchical model, and FCM. However, in the probabilistic based clustering algorithms (e.g. K-means, GMM, and hierarchical model), the data allocation to\neach cluster is done in a crisp manner, that is each data element can belong to exactly one cluster. In contrast, the fuzzy clustering algorithm (e.g. FCM), soft computing is applied in the sense that the data partition alleviates the data allocation where each data can belong to more than one clusters and associated with a set of membership values. This solution works better in the challenging environments such as the complex backgrounds, dynamic lighting conditions, and the deformable hand shapes with real-time computational speeds [138, 139, 140, 141].\nUsing the FCM, [138, 139] worked on a fast respond telerobotic gesture-based user interface system. The nature of FCM in relaxing the hard decision allowed the use of smaller portions of the training set and thus shorter training time was required. Empirically, it has proved to be sufficiently reliable and efficient in the recognition tasks with the achievement on high accuracy and real-time performance. [140] further improved the work [138] in the skin segmentation problem using the color space to solve the skin color variation. Besides spatial information, temporal information is also important in the gesture inference process. In [141], the spatial information of hand gesture using the FCM was trained in order to determine the partitioning of the trajectory points into a number of clusters with the fuzzy pseudo-boundaries. In general, each trajectory point belongs to each cluster specified by a membership degree. Then, the temporal data is obtained through the transitions between the states (cluster of trajectory points) of a series of finite state machines to recognize the gesture motion."}, {"heading": "4.1.2. Hybrid technique", "text": "A few works [142, 143, 144] on fusing the fuzzy approaches with machine learning solutions have been reported in the gesture recognition. [142] used the adaptive neuro-fuzzy inference system to recognize the gestures in Arabic sign language. This work was motivated by the transformation of human knowledge into a FIS, but does not produce the exact desired response due to the heuristic or non-sophisticated membership functions and the fuzzy rules generation. Thus, there was a need to fine-tune the parameters in the FIS to enhance its performance, and the adaptive neuro-fuzzy inference system provided this flexibility by applying a learning procedure using a set of training data.\n[143] introduced a new approach towards gesture recognition based on the idea of incorporating the fuzzy ARTMAP [145] in the feature recognition neural network [146]. The proposed method reduced the system complexity and performed in real-time manner. Nonetheless, [144] presented an approach with several novelties and advantages as compared to other hybrid solutions. They introduced a new fuzzy hand-posture model using a modified circular fuzzy neural network architecture to efficiently recognize the hand posture. As a result, the robustness and reliability of the hand-gesture identification was improved, and the complexity and training time involved in the neural networks was significantly reduced."}, {"heading": "4.2. Activity recognition", "text": "Activity recognition is an important task in the HiL HMA systems. The goal of activity recognition is to autonomously analyze and interpret the ongoing human activities and their context from the video data. For example, in the surveillance systems for detecting suspicious actions, or in sports analysis for monitoring the correctness of the athletes\u2019 postures. In recent times, the fuzzy approaches such as type-1 FIS, fuzzy HMM, and hybrid techniques have proved to be beneficial in the human activity recognition, with capability of modeling the uncertainty in the feature data. Nonetheless, Fuzzy Vector Quantization (FVQ) and Qualitative Normalized Template (QNT) provide the capability to handle the complex human activities occurring in our daily life such as walking followed by running, then running followed by jumping, or a hugging activity where two or more people are involved. In this section, we will discuss on the applications of these fuzzy approaches in the activity recognition."}, {"heading": "4.2.1. Type-1 fuzzy inference system", "text": "The FIS can be efficiently used to distinguish the human motion patterns and recognize the human activities with its capability of modeling the uncertainty and the fusion of different features in the classification process. In the literature of activity recognition, there exists some works [147, 148] that employed the FIS to classify different human activities.\nBoth [147, 148] took into account the uncertainties in both the spatial and temporal features for efficient human behavior recognition. Their method aims at handling high uncertainty levels and the complexities occurring in the real world applications. [147] used the spatial and temporal geometry features to study the importance of the spatiotemporal relations such as \u2018IsMoving\u2019, \u2018IsComingCloseTo\u2019, \u2018IsGoingAway\u2019, \u2018IsGoingAlong\u2019 with the objective to\nprovide a qualitative interpretation of the behavior of an entity (e.g. a human) in real-time. Another work [148] adopted the spatio-temporal features such as the silhouette slices and the movement speed in video sequences as the inputs to the FIS. Extra merit in this work is that they learn the membership functions of the FIS using the FCM which prevents the intervention of human in generating the fuzzy membership function heuristically."}, {"heading": "4.2.2. Hybrid technique", "text": "Owing to the demands of the development of enhanced video surveillance systems that can automatically understand the human behaviors and identify dangerous activities, [149] introduced a semantic human behavioral analysis system based on the hybridization of the neuro-fuzzy approach. In their method, the kinematic data obtained from the tracking algorithm is translated into several semantic labels that characterizes the behaviors of various actors in a scene. To achieve this, the behavioral semantic rules were defined using the theory of time delay neural networks and the fuzzy logic, to identify a human behavior analyzing both the temporal and the contextual features. This means that they analyze how a human activity changes with respect to time along with how it is related to the contexts surrounding the human. Their hybrid method outperformed other approaches and showed high level of scalability and robustness.\nAnother work [150] presented a fuzzy rule-based reasoning approach for event detection and annotation of broadcast soccer video, integrating the Decision Tree and the FIS. A flexible system was designed using the fuzzy rules, that can be used with least reliance on the predefined feature sequences and domain knowledge. The FIS was designed as a classifier taking into account the information from a set of audio-visual features as its crisp inputs and generate the semantic concepts corresponding to the events occurred. From the fuzzification of the feature vectors derived from the training data, a set of tuples were created, and using the Decision Tree, the hidden knowledge among these tuples as well as the correlation between the features and the related events were extracted. Then, traversing each path from the root to the leaf nodes of the Decision Tree, a set of fuzzy rules were generated which were inserted in the knowledge base of the FIS and the occurred events were predicted from the input video (i.e. soccer video) with good accuracy."}, {"heading": "4.2.3. Fuzzy vector quantization", "text": "In order to learn the complex actions, [151] represented the human movements as a combination of the smallest constructive unit of human motion patterns called the dyneme (Figure 13). It is the basic movement patterns of a continuous action. In the bottom of action hierarchy, dyneme is defined as the smallest constructive unit of human motion; while one level above is the movement which is perceived as a sequence of dynemes with clearly defined temporal boundaries and conceptual meaning. Dyneme can be learned in an unsupervised manner and in [151], the FCM was chosen. Then, fuzzy vector quantization (FVQ) [152] as a function that regulates the transition between the crisp and the soft decisions was employed to map an input posture vector into the dyneme space. Finally, each\nmovement was represented as a fuzzy motion model by computing the arithmetic mean of the comprising postures of a movement in the dyneme space. Their algorithm provides good classification rates and exhibits adequate robustness against partial occlusions, different styles of movement execution, viewpoint changes, gentle clothing conditions and other challenging factors."}, {"heading": "4.2.4. Qualitative normalized template", "text": "Utilizing the concept of fuzzy qualitative robot kinematics [95, 101], Chan and Liu [96, 102] built a generative action template, called the Qualitative normalized template (QNT) to perform the human action recognition. First of all, the training data that represents a typical activity is acquired by tracking the human anatomical landmarks in the image sequences. In their work, a data quantization process was employed to handle the tradeoffs between the tracking precision and the computational cost. Then, the QNT as illustrated in Figure 14 was constructed according to the fuzzy qualitative robot kinematics framework [95, 101]. An empirical comparison with the conventional hidden Markov model (HMM) and fuzzy HMM using both the KTH and the Weizmannn datasets has shown the effectiveness of the proposed solution [96]."}, {"heading": "4.2.5. Fuzzy Hidden Markov Model", "text": "Hidden Markov model (HMM) [153] is the statistical Markov model with the state being not directly visible, but the output that is dependent on the state is visible. HMM have been widely employed in the human action recognition [154, 155, 156, 157, 158]. These papers have well demonstrated the modeling and recognition of the complex human activities using HMM. In the training stage of HMM, expectation maximization algorithm is adopted. However, in the conventional HMM, each observation vector is assigned only to one cluster. [159] pointed out that assigning different observation vectors to the same cluster is possible and if their observation probabilities become the same, consequently, the classification performance may decrease. Therefore, HMM was extended to fuzzy HMM where in the training stage, the distance from each observation vector to each cluster center is computed and the inverse of the distance is considered as the membership degree of the observation vector to the cluster. [159] utilized this concept for human action recognition and the experiment results demonstrate the effectiveness of the fuzzy HMM in human action recognition, with good recognition accuracy for the similar actions such as \u201cwalk\u201d and \u201crun\u201d."}, {"heading": "4.3. Style invariant action recognition", "text": "A robust action recognition algorithm must be capable of recognizing the actions performed by different person in different styles. Commonly, different person have different styles of executing the same action which can be categorized according to the physical differences (such as human appearances, sizes, postures, etc.) and the dynamic\ndifferences (speed, motion pattern, etc.) [160]. In order to model such variations, several notable works have been reported incorporating the fuzzy approaches."}, {"heading": "4.3.1. Fuzzy vector quantization", "text": "[161] adopted the concept of FVQ and the dyneme, and proposed a novel person specific activity recognition framework to cope with the style invariant problem. The method is mainly divided into two parts: firstly, the ID of the person is identified, and secondly, the activity is inferred from the person specific fuzzy motion model [151]. It was found that the different styles in action execution endowed the capability to distinguish one person from the another. Therefore, [162] developed an activity-related biometric authentication system by utilizing the information of different styles by different people. Improvement was made in the computation of the cumulative fuzzy distances between the vectors and the dynemes that outperforms L1, L2, and Mahalanobis distances which were used previously in [151]."}, {"heading": "4.3.2. Fuzzy descriptor action model", "text": "There is a limitation in [161, 162] where a large storage space is required to store the ID of different person and this makes the system impractical. An alternative approach was proposed in [160], where a fuzzy descriptor vector was used to represent the human actions of different styles in a single underlying fuzzy action descriptor. Theoretically, the ordinary descriptor vector was allowed to contain only a single value in each dimension of the vector. In contrast, fuzzy descriptor allows accommodation of a set of possible values where these values hold the different measurements of the feature data obtained from the training data, comprising of an action performed by different person in different styles."}, {"heading": "4.4. Multi-view action recognition", "text": "The capability of multi-view action recognition is emerging as an important aspect for advanced HMA systems. In the real world environment, human are free to perform an action at any angle with no restriction of being frontal parallel to the camera and most of the previous works treat it as a constraint or limitation in their system. This problem has received increasing attention in the HMA research and some of the notable works have been reported [28, 45, 46]. Besides that, fuzzy approaches such as the FVQ, and fuzzy qualitative reasoning are also applied in the study of multi-view action recognition which will be discussed in the following subsections."}, {"heading": "4.4.1. Fuzzy vector quantization", "text": "[162, 163, 164] extended [151] to support multi-view action recognition. The motion patterns obtained from different cameras, as in Figure 15, were clustered to determine the number of multi-view posture primitives called the multi-view dynemes. Similar to [151], FVQ was utilized to map every multi-view posture pattern to create the multi-view dyneme space. This new multi-view fuzzy movement representation is motion speed and duration invariant which generalizes over variations within one class and distinguishes between the actions of different classes. In\nthe recognition step, Fourier view invariant posture representation was used to solve the camera viewpoint identification problem before the action classification was performed. Nonetheless, they tackled the problem of interaction recognition i.e. human action recognition involving two persons [165]."}, {"heading": "4.4.2. Fuzzy qualitative single camera framework", "text": "In most of the multi-view action recognition works, there is an argument that performing view invariant human action recognition using multi-camera approach is not practical in real environment [33, 46]. The reasons are: firstly, such systems must be deployed in a close environment that has many overlapping regions which is very rare in the open public space. Secondly, the implementation and the maintenance cost is very high due to the usage of multiple cameras. In order to solve this, [160] proposed a fuzzy action recognition framework for multi-view within a single camera. Their work introduced the concept of learning the action in three predefined viewpoints which are horizontal, diagonal, and verticle view, as depicted in Figure 16. The learning is done by mapping the features extracted from the human silhouette onto the fuzzy quantity space. The dominant features are then identified from the fuzzy qualitative states and represented as a fuzzy descriptor [160]. In the action recognition step, the viewpoint of the person is first estimated and then proceeded with the action recognition by utilizing the viewpoint specific fuzzy descriptor action models [160]."}, {"heading": "4.5. Anomaly event detection", "text": "Anomaly detection refers to the problem of finding patterns in the input data that do not conform to the expected behavior. In our daily life, anomaly detection is important to infer the abnormal behavior of a person, such as an action or an activity that is not following the routine or deviated from the normal behavior [7, 166, 167]. For example, in the healthcare domain to prevent unfavorable events from occurring such as the risk of falling down of the patients, and in the surveillance systems, to automatically detect the crime activities."}, {"heading": "4.5.1. Type-1 fuzzy inference system", "text": "As humans gain more knowledge, they are able to make better decisions; similarly if the FIS is provided with sophisticated knowledge (i.e. fuzzy rules), it can deal with the real world problems in a better manner. FIS has been employed in various works for anomaly event detection such as the elderly fall detection in [15, 16, 104], to address the deficiencies and the inherent uncertainty related to modeling and inferring the human activities. The works emphasized that the non-interpretable likelihood value or the ad-hoc training of the activity models in the conventional approaches is impractical in the area of human action recognition. Therefore, a confidence value (fuzzy membership degree) that can be reliably used to reject unknown activities is more convenient.\n[16] proposed a novel fuzzy rule based method for monitoring the wellness of the elderly people from the video. In this paper, the knowledge base (fuzzy rules as depicted in Figure 17) was designed under the supervision of nurses for the recognition of falls of the elderly people. Under this framework, the rules can be easily modified, added or deleted, based on the knowledge about the cognitive and functional abilities of the patients. This work was an extension of [104] where the linguistic summarizations of the human states (three states: upright, on-the-ground and in-between) based on the voxel person and the FIS were extracted, extended using a hierarchy of the FIS and the linguistic summarization for the inference of the patients\u2019 activities. Their technique works well for fall detection, but the question is if this framework can be extended to different activities. The answer is yes where, [168] extended the work to support the additional common elderly activities such as standing, walking, motionless-on-the-chair, and lying-motionless-on-the-couch, with the inclusion of the knowledge about the real world for the identification of the voxels that corresponds to the wall, floor, ceiling, or other static objects or surfaces. Two new states were included to recognize these activities i.e. on-the-chair and on-the couch. These states were different from the previous three states (upright, on-the-ground and in-between) as they were based on the voxel person interacting with a static object in the scene. Further, the fuzzy rules were extended to six new fuzzy rules designed for identifying on-the-chair and on-the-couch activities."}, {"heading": "4.5.2. Fuzzy one class support vector machine", "text": "The fuzzy one class support vector machine (FOCSVM) is an efficient algorithm often used in fall detection systems to distinguish a falling from other activities such as walking, bending, sitting or lying. [169] proposed a robust fall detection system using FOCSVM with novel 3D features. In their method, a voxel person was first computed, then the video features obtained from the variation of a persons\u2019 3D angle and centroid information were extracted from the sequences of voxel persons which were used to train the FOCSVM classifier. As compared to the traditional one class support vector machine, FOCSVM obtained more accurate fall detection result with tight decision boundaries under a training dataset with outliers. The success of the proposed method is evident from the experiments on the real video sequences, with less non-fall samples being misclassified as falls by the classifier with imperfect training data."}, {"heading": "4.5.3. Fuzzy clustering", "text": "In order to perform fall detection in multiple camera framework, fuzzy clustering algorithms (e.g. FCM, Gustafson and Kessel Clustering, or Gath and Geva Clustering) along with the fuzzy K-nearest neighbor algorithms were employed in [170]. In particular, Hu moment invariant features were computed from the 2D silhouette images and principal component analysis was utilized to select the principal components. The fuzzy clustering algorithms were used to generate the multi-prototype that represent the action classes such as standing or walking, sitting or bending, lying and lying forward. Fuzzy K-nearest neighbor was then used to deduce the corresponding action classes. For example, if the detected action was \u201clying\u201d or \u201clying forward\u201d, it was considered as the falling activity."}, {"heading": "4.5.4. Hybrid technique", "text": "A hybrid model of the FIS and the Fuzzy Associative Memory (FAM) was incorporated in [172], which basically receives an input and assigns a degree of belongingness to a set of rules. [172] considered the angles of human limbs as the inputs to the FAM with three rules defining the abnormal movement types. FAM then assigns a degree of membership to each rule and determines the anomalous or normal events based on a specific threshold. [173] also used the neural fuzzy network hybrid model, compensating the lacking of the learning ability of the fuzzy approaches to recognize human poses (e.g. standing, bending, sitting, and lying). Their system with simple fuzzy rules is capable of detecting the emergencies caused by the accidental falls or when a person remains in the lying posture for a period of time. The works evidently show the flexibility of the fuzzy approaches in the alteration or extension of its knowledge base to adapt to newly encountered real world problems.\nAnother paper [174] proposed fuzzy self-organizing neural network (fuzzy SOM) to learn the activity patterns for anomaly detection in visual surveillance. Their method aims at automatically constructing the activity patterns by self-organizing learning instead of predefining them manually. Traditionally, individual flow vectors were used as inputs to the neural networks. In the proposed method, whole trajectory was taken as an input, simplifying the structure of the neural networks to a great extent. Fuzzy SOM further improved the learning speed and accuracy of the anomaly detection problem, as demonstrated with the support of experimental results. To understand better, a summary of research works in HiL HMA using the fuzzy approaches is shown in Table 5."}, {"heading": "5. Discussion", "text": "After reviewing a number of works using the fuzzy approaches in HMA, we identified some important factors that make fuzzy approaches successful in improving the overall system performance and these will be discussed in this section along with the potential future works."}, {"heading": "5.1. Soft boundary", "text": "Human reasoning is a mysterious phenomenon that scientists trying to simulate with machines in the past few decades. With the knowledge that \u201csoft\u201d boundaries exist in concepts formation of human beings [175], fuzzy set theory has emerged to become one of the most important methodology in capturing notions. In general, fuzzy approach assigns a \u201csoft\u201d boundaries, or in other words performing \u201csoft labeling\u201d where one subject can be associated with many possible classes with a certain degree of confidence. As such, the fuzzy representation is more beneficial than the ordinary (crisp) representations, as it can represent not only the information stated by a well-determined real interval, but also the knowledge embedded in the soft boundaries of the interval. Thus, it removes, or largely weakens the boundary interpretation problem achieved through the description of a gradual rather than an abrupt change in the degree of membership, closer to how humans make decisions and interpret things in the real world.\nThis is also supported by a few notable literatures. For example, [176] in their review on computing with uncertainties emphasized on the fact that the integration of fuzzy models always improves the computer performance in pattern recognition problems. Similarly, [41, 177] presented a survey on how to effectively represent the uncertainty using the FIS. Nevertheless, there are a few studies on the type-2 FIS that have been reported in this regards. [178, 179] explained on how to design an interval type-2 FIS using the uncertainty bounds and introduced the measurement of uncertainty for interval type-2 fuzzy sets using the information such as centroid, cardinality, fuzziness, variance and skewness. A comprehensive review on handling the uncertainty in pattern recognition using the type-2 fuzzy approach was provided by [180]."}, {"heading": "5.2. Linguistic support", "text": "Another worth highlighting aspect of human behavior is the way they interpret things in the natural scenarios. Human beings mostly employ words in reasoning, arriving at conclusions expressed as words from premises in natural language or having the form of mental perceptions. As used by humans, words have fuzzy denotations. Therefore, modeling the uncertainties in a natural format for humans (i.e. linguistic summarizations) can yield more succinct description of human activities. Inspired from this, HMA can be modeled efficiently by representing an activity in linguistic terms. This concept was initiated in [181] where words can be used in place of numbers for computing and reasoning (like done by humans), commonly known as computing with words (CWW).\nIn CWW, a word is viewed as a fuzzy set of points drawn together by similarity, with the fuzzy set playing the role of a fuzzy constraint on a variable. There are two major imperatives for CWW [181]. Firstly, CWW is a necessity when the available information is too imprecise to justify by the use of numbers. Secondly, when there is a tolerance for imprecision which can be exploited to achieve tractability, robustness, low solution cost, and better rapport with reality. This concept of using CWW i.e. linguistic support to represent the measurement boundaries can be well applied in the real world scenarios. For example, consider the human activities: walking and running, which can be inferred using simple cue i.e. the speed of a person. Different levels of running speeds of a person can be modeled using the linguistic terms such as \u2018very slow\u2019, \u2018slow\u2019, \u2018moderate\u2019, \u2018fast\u2019, and \u2018very fast\u2019, instead of representing speed in numerical terms. The use of linguistic terms provide the capability to perform human like reasoning such as the feasibility of defining rules for the inference process. With the integration of the linguistic support in the FIS, the computational complexity of the numeric labeling and the imprecision problem in the interpretation stage are also suppressed. Furthermore, the linguistic terms are more understandable where it mimics how humans interpret things and make decisions.\nThe concept of linguistic support is rooted in several papers starting with [182] in which the concepts of a linguistic variable and the granulation were introduced. [181] threw light on the role played by the fuzzy logic in CWW and vice-versa. An interesting piece of work on CWW can be found in [183] where the author defined CWW as a symbolic generalization of the fuzzy logic. In the recent years, several papers have been published that utilizes the concept of linguistic summarization in the fuzzy system that are successfully applied in the real world applications [104, 184, 185, 186, 187, 188]. In these works, a complete sentence instead of numerical data or a crisp answer in a conventional decision making systems is preferable as an output; for example, \u201cthe resident has fallen in the living room and is down for a long time\u201d. Such succinct linguistic summarization output is more understandable and closest to the natural answer."}, {"heading": "5.3. Flexibility of the fuzzy system", "text": "Another advantage of the fuzzy approaches, especially those that utilized the knowledge-based system (fuzzy rules) such as the FIS, is that they possess the flexibility and feasibility to adapt to various system designs. The conventional approaches designed their algorithms to be well-fitted to solve solely some specific problems with low or no extendibility. The world is changing rapidly with the headway of technologies, the flexibility to adapt to such changes is one of the major concerns for a good and long lasting system. Fortunately, the fuzzy approaches allow the alterations to serve the purpose. In addition, the alterations can be made easily on the knowledge base by designing the fuzzy rules.\nThe knowledge base that comprises of all the rules is considered as the most crucial part of a decision making system where it functions as the \u201cbrain\u201d of the overall system. As human growth together with knowledge is capable of making better decisions, similarly if a decision making system is provided with sophisticated knowledge, it can deal with the problems in a better manner. The FIS consists of a knowledge base where it can store a number of conditional \u201cIF-THEN\u201d rules that are used for the reasoning process in a specific problem domain. These rules are easy to write and as many rules as necessary can be supplied to describe the problem adequately. For example, consider the problem of identifying different human activities e.g. running. Rules can be designed to infer the running activity using a simple cue (speed) as following:\nRule 1: IF (speed is FAST) THEN (person is RUNNING) Rule 2: IF (speed is MODERATE) THEN (person is NOT RUNNING) However, in the real world scenarios, various factors can affect the speed of a person such as the height, body size, etc. Therefore, in order to make the system closer to natural solution, these rules are needed to be modified\naccordingly. Intuitively, if one may observe the styles of running of a tall person and a shorter person, due to difference in the step size of their feet, the taller person tends to run with a faster speed due to larger step size as compared to the shorter person, running with moderate speed. However, both are performing the running activity, but with different rules. This situation can be modeled by modifying the \u201cRule 2\u201d as follows:\nRule 2.1: IF (HEIGHT is TALL) & (SPEED is MODERATE) THEN (person is NOT RUNNING) Rule 2.2: IF (HEIGHT is SHORT) & (SPEED is MODERATE) THEN (person is RUNNING)\nSimilarly, the body size can also affect the speed of a person, and can be modeled using flexible fuzzy rules that can be easily added, modified or deleted according to the objective of the system.\nIn a conventional FIS, most of these rules are built with the help of human expert knowledge. For example, in our case, such experts can be doctor, police, forensic expert or researcher, etc. The information that they provide is considered to be the most reliable one as they build it based on their real life experiences and historical analysis. However, human intervention in an intelligent system is becoming a threat due to the heuristic and subjectivity of human decisions. Therefore, automated learning systems have emerged and widely employed in the research society, encouraging learning and generation of fuzzy rules automatically. Several works in the literature have reported efficient methods for the automatic generation of the fuzzy rules such as [189, 190, 191, 192, 193].\nFor example, [189] proposed a method of generating the fuzzy rules by learning from examples, more specifically by the numerical data. Similarly, [190] presented an alternative method to generate the fuzzy rules automatically from the training data with their rules defined in the form of possibility, certainty, gradual, and unless rules. A new approach called the fuzzy extension matrix was proposed in [191] which incorporated the fuzzy entropy to search for the paths and generalized the concept of the crisp extension matrix. Their method was capable of handling the fuzzy representation and tolerating the noisy or missing data. FCM and its variants (e.g. multi-stage random sampling) with its fast performance have also been adopted in the fuzzy rule generation such as the work by [192]. Apart from that, there are works reported in the fuzzy rule generation incorporated with other machine learning techniques. [194] provided an exhaustive survey on the neuro-fuzzy rule generation algorithms, while [193] presented an approach to automatically learn the fuzzy rules by incorporating the genetic algorithm."}, {"heading": "5.4. Potential future works in fuzzy HMA", "text": "Datasets: In the research society nowadays, public datasets play a very important role in order to show the effectiveness of a proposed algorithm. Even so, from our findings in Table 6, there were not much works from the fuzzy community that had explored these public datasets. Only a handful works in the fuzzy HMA (as referred in Table 6) had employed those datasets and compared their works with other algorithms. In order to justify and improve the competency of the fuzzy approaches in HMA, it is believed that one way forward is to start employing these datasets as the baseline study.\nOn the other hand, the datasets listed in Table 6 undeniably has met the objectives as a baseline evaluation. However, [238, 239, 240] raised an argument that many situations in the real life are ambiguous, especially the human behavior with varied perceptions of the masses. The current datasets, at this stage might be too ideal to reflect the real world scenarios, i.e. the current datasets are mutually exclusive, allowing a data to belong to one class (action) only at a time. Therefore, another potential area which can be explored as future works is having an appropriate psycho-physical dataset with fuzzy ground truths, or in a simpler sense: fuzzy datasets. To the best of our knowledge, there do not exist any fuzzy datasets modeling the human activities and their behavior till date.\nEarly event detection: Apart from that, fuzzy approaches being successful in handling the uncertainties in various real-time applications as highlighted in this survey, can be very well explored to be potentially applied in highly complex HMA applications such as human activity forecasting [241] and early detection of crimes [242, 243]. There do not exist literature on the fuzzy capability in handling the uncertainties arising in such scenarios, which have high quotient of importance as they are focusing on forecasting an event or early detecting crimes from happening. Therefore, even the minutest level of uncertainty is required to be taken care of for reliable decision making. Fuzzy approaches with its capability in handling the uncertain situations can substantially benefit in performing these complex tasks, and can be explored by the researchers working in this domain as a potential future work.\nHuman activity recognition in still images: Another interesting area to be explored as part of the future works is the recognition of human activities using still image. The work has has received much attention in the recent past in the\ncomputer vision community [244, 245, 246, 247, 248, 249, 250], but as to our very best knowledge, none was found in the fuzzy domain. In this research topic, most of the works considered it to be same as an image classification problem. Lately, several researchers are trying to obtain a thorough understanding of the human poses, the objects, and the interactions between them in a still images to infer the activities. For example, [251] proposed a method to recognize the human-object interactions in still images by explicitly modeling the mutual context between the human poses and the objects, so that each can facilitate the recognition of the other. Their mutual context model outperform the state-of-the-art in object detection, human pose estimation, as well as the recognition of human-object interaction activities. However limited information that can be extracted from the still image and the random noises in the image are two major problems that exists in this area. This can be a potential area to explore by the fuzzy community, providing useful solutions in handling the uncertainties, incomplete data or vague information in regards with the human-object interactions, or human-scene context in still images."}, {"heading": "6. Conclusion", "text": "Fuzzy set theory has been effectively applied in many ways that revealed a number of fuzzy approaches such as FIS, FCM, Fuzzy qualitative reasoning, etc. This paper takes the initiative to review the works that employed these fuzzy approaches in the HMA system which has not been done previously. From the studies, one can notice that the fuzzy approaches are capable of handling the uncertainty that abounded in each level of the HMA system (LoL, MiL, and HiL). The fundamental factors that endowed such capability to the fuzzy approaches include the ability to perform soft labeling and the flexibility to adapt to different uncertainties. However, most of the reported works herein did not utilize the standard HMA datasets as their baseline. Anyway, the current datasets are mostly too ideal to reflect the real world scenarios that is full of uncertainties. The generation of the fuzzy dataset for HMA could be one of the potential future works other than the early event detection and the still image action recognition."}, {"heading": "Acknowledgment", "text": "This research is supported by the High Impact Research MoE Grant UM.C/625/1/HIR/MoE/FCSIT/08, H-2200100-B0008 from the Ministry of Education Malaysia."}], "references": [{"title": "Movement", "author": ["A.F. Bobick"], "venue": "activity and action: the role of knowledge in the perception of motion, Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences 352 (1358) ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1997}, {"title": "Decomposing biological motion: A framework for analysis and synthesis of human gait patterns", "author": ["N.F. Troje"], "venue": "Journal of Vision 2 (5) ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2002}, {"title": "Temporal and spatial factors in gait perception that influence gender recognition", "author": ["C.D. Barclay", "J.E. Cutting", "L.T. Kozlowski"], "venue": "Perception & Psychophysics 23 (2) ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1978}, {"title": "Perception of human motion", "author": ["R. Blake", "M. Shiffrar"], "venue": "Annu. Rev. Psychol. 58 ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2007}, {"title": "Application of multimedia to the study of human movement", "author": ["C. Kirtley", "R. Smith"], "venue": "Multimedia Tools and Applications 14 (3) ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2001}, {"title": "The evolution of video surveillance: an overview", "author": ["N. Haering", "P.L. Venetianer", "A. Lipton"], "venue": "Machine Vision and Applications 19 (5-6) ", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "A survey on visual surveillance of object motion and behaviors", "author": ["W. Hu", "T. Tan", "L. Wang", "S. Maybank"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews 34 (3) ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2004}, {"title": "Intelligent visual surveillance: A survey", "author": ["I.S. Kim", "H.S. Choi", "K.M. Yi", "J.Y. Choi", "S.G. Kong"], "venue": "International Journal of Control, Automation and Systems 8 (5) ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "A survey on behavior analysis in video surveillance for homeland security applications", "author": ["T. Ko"], "venue": "in: 37th Applied Imagery Pattern Recognition Workshop", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2008}, {"title": "Video-based abnormal human behavior recognition - a review", "author": ["O.P. Popoola", "K. Wang"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews 42 (6) ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "A survey of content-based video retrieval", "author": ["P. Geetha", "V. Narayanan"], "venue": "Journal of Computer Science 4 (6) ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2008}, {"title": "Recognizing action at a distance", "author": ["A.A. Efros", "A.C. Berg", "G. Mori", "J. Malik"], "venue": "in: Proceedings. Ninth IEEE International Conference on Computer Vision (ICCV)", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2003}, {"title": "Monocular 3d reconstruction of human motion in long action sequences", "author": ["G. Loy", "M. Eriksson", "J. Sullivan", "S. Carlsson"], "venue": "in: European Conference on Computer Vision (ECCV), Springer", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2004}, {"title": "Action mach: Maximum average correlation height filter for action recognition", "author": ["M. Sullivan", "M. Shah"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2008}, {"title": "Recognizing falls from silhouettes", "author": ["D. Anderson", "J.M. Keller", "M. Skubic", "X. Chen", "Z. He"], "venue": "in: 28th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBS)", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "Modeling human activity from voxel person using fuzzy logic", "author": ["D. Anderson", "R.H. Luke", "J.M. Keller", "M. Skubic", "M.J. Rantz", "M.A. Aud"], "venue": "IEEE Transactions on Fuzzy Systems 17 (1) ", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "Multimodal human\u2013computer interaction: A survey", "author": ["A. Jaimes", "N. Sebe"], "venue": "Computer Vision and Image Understanding 108 (1) ", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2007}, {"title": "Articulated and elastic non-rigid motion: A review", "author": ["J.K. Aggarwal", "Q. Cai", "W. Liao", "B. Sabata"], "venue": "in: Proceedings of the IEEE Workshop on Motion of Non-Rigid and Articulated Objects", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1994}, {"title": "Motion-based recognition a survey", "author": ["C. C\u00e9dras", "M. Shah"], "venue": "Image and Vision Computing 13 (2) ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1995}, {"title": "Human motion analysis: A review", "author": ["J.K. Aggarwal", "Q. Cai"], "venue": "in: Proceedings of the IEEE Nonrigid and Articulated Motion Workshop", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1997}, {"title": "The visual analysis of human movement: A survey", "author": ["D.M. Gavrila"], "venue": "Computer Vision and Image Understanding 73 (1) ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1999}, {"title": "Looking at people: Sensing for ubiquitous and wearable computing", "author": ["A. Pentland"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 22 (1) ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2000}, {"title": "A survey of computer vision-based human motion capture", "author": ["T.B. Moeslund", "E. Granum"], "venue": "Computer Vision and Image Understanding 81 (3) ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2001}, {"title": "Recent developments in human motion analysis", "author": ["L. Wang", "W. Hu", "T. Tan"], "venue": "Pattern Recognition 36 (3) ", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2003}, {"title": "A survey of advances in vision-based human motion capture and analysis", "author": ["T.B. Moeslund", "A. Hilton", "V. Kr\u00fcger"], "venue": "Computer Vision and Image Understanding 104 (2) ", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2006}, {"title": "Vision-based human motion analysis: An overview", "author": ["R. Poppe"], "venue": "Computer Vision and Image Understanding 108 (1) ", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2007}, {"title": "Machine recognition of human activities: A survey", "author": ["P. Turaga", "R. Chellappa", "V.S. Subrahmanian", "O. Udrea"], "venue": "IEEE Transactions on Circuits and Systems for Video Technology 18 (11) ", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2008}, {"title": "Advances in view-invariant human motion analysis: a review", "author": ["X. Ji", "H. Liu"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews 40 (1) ", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2010}, {"title": "A survey on vision-based human action recognition", "author": ["R. Poppe"], "venue": "Image and Vision Computing 28 (6) ", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2010}, {"title": "Understanding transit scenes: A survey on human behavior-recognition algorithms", "author": ["J. Candamo", "M. Shreve", "D.B. Goldgof", "D.B. Sapper", "R. Kasturi"], "venue": "IEEE Transactions on Intelligent Transportation Systems 11 (1) ", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2010}, {"title": "Human activity analysis: A review", "author": ["J. Aggarwal", "M.S. Ryoo"], "venue": "ACM Computing Surveys 43 (3) ", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2011}, {"title": "A survey of vision-based methods for action representation", "author": ["D. Weinland", "R. Ronfard", "E. Boyer"], "venue": "segmentation and recognition, Computer Vision and Image Understanding 115 (2) ", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2011}, {"title": "Human action recognition using multiple views: a comparative perspective on recent developments", "author": ["M.B. Holte", "C. Tran", "M.M. Trivedi", "T.B. Moeslund"], "venue": "in: Proceedings of the Joint ACM Workshop on Human Gesture and Behavior Understanding", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2011}, {"title": "A survey on human activity recognition using wearable sensors", "author": ["O.D. Lara", "M.A. Labrador"], "venue": "IEEE Communications Surveys & Tutorials 15 (3) ", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2013}, {"title": "A survey of human motion analysis using depth imagery", "author": ["L. Chen", "H. Wei", "J. Ferryman"], "venue": "Pattern Recognition Letters 34 (15) ", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2013}, {"title": "Human behavior analysis in video surveillance: A social signal processing perspective", "author": ["M. Cristani", "R. Raghavendra", "A. Del Bue", "V. Murino"], "venue": "Neurocomputing 100 ", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2013}, {"title": "A survey of video datasets for human action and activity recognition", "author": ["J.M. Chaquet", "E.J. Carmona", "A. Fern\u00e1ndez-Caballero"], "venue": "Computer Vision and Image Understanding 117 (6) ", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2013}, {"title": "Recognizing human actions: a local svm approach", "author": ["C. Schuldt", "I. Laptev", "B. Caputo"], "venue": "in: Proceedings of the International Conference on Pattern Recognition (ICPR), Vol. 3", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2004}, {"title": "Event-based analysis of video", "author": ["L. Zelnik-Manor", "M. Irani"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Vol. 2", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2001}, {"title": "Actions as space-time shapes", "author": ["M. Blank", "L. Gorelick", "E. Shechtman", "M. Irani", "R. Basri"], "venue": "in: IEEE International Conference on Computer Vision (ICCV), Vol. 2", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2005}, {"title": "Representation of uncertainty in computer vision using fuzzy sets", "author": ["T.L. Huntsberger", "C. Rangarajan", "S.N. Jayaramamurthy"], "venue": "IEEE Transactions on Computers 100 (2) ", "citeRegEx": "41", "shortCiteRegEx": null, "year": 1986}, {"title": "Fuzzy set theoretic approach to computer vision: An overview", "author": ["R. Krishnapuram", "J.M. Keller"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "42", "shortCiteRegEx": null, "year": 1992}, {"title": "Fuzzy sets in computer vision: An overview", "author": ["P. Sobrevilla", "E. Montseny"], "venue": "Mathware & Soft Computing 10 (3) ", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2008}, {"title": "The recognition of human movement using temporal templates", "author": ["A.F. Bobick", "J.W. Davis"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 23 (3) ", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2001}, {"title": "Free viewpoint action recognition using motion history volumes", "author": ["D. Weinland", "R. Ronfard", "E. Boyer"], "venue": "Computer Vision and Image Understanding 104 (2) ", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2006}, {"title": "View and style-independent action manifolds for human activity recognition", "author": ["M. Lewandowski", "D. Makris", "J.-C. Nebel"], "venue": "in: European Conference on Computer Vision (ECCV)", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2010}, {"title": "Fusing color and texture features for background model", "author": ["H. Zhang", "D. Xu"], "venue": "in: Proceedings of the International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2006}, {"title": "Fuzzy integral for moving object detection", "author": ["F. El Baf", "T. Bouwmans", "B. Vachon"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2008}, {"title": "Information fusion in computer vision using the fuzzy integral", "author": ["H. Tahani", "J.M. Keller"], "venue": "Systems, Man and Cybernetics, IEEE Transactions on 20 (3) ", "citeRegEx": "49", "shortCiteRegEx": null, "year": 1990}, {"title": "On sugeno integral as an aggregation function", "author": ["J.-L. Marichal"], "venue": "Fuzzy Sets and Systems 114 (3) ", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2000}, {"title": "A fuzzy approach for background subtraction", "author": ["F. El Baf", "T. Bouwmans", "B. Vachon"], "venue": "in: IEEE International Conference on Image Processing 29  (ICIP)", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2008}, {"title": "Region based fuzzy background subtraction using choquet integral", "author": ["M. Balcilar", "A.C. Sonmez"], "venue": "in: Adaptive and Natural Computing Algorithms, Springer", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2013}, {"title": "An interpretation of fuzzy measures and the choquet integral as an integral with respect to a fuzzy measure", "author": ["T. Murofushi", "M. Sugeno"], "venue": "Fuzzy Sets and Systems 29 (2) ", "citeRegEx": "53", "shortCiteRegEx": null, "year": 1989}, {"title": "A new approach to time series modeling with fuzzy measures and the choquet integral", "author": ["M. Sugeno", "S.-H. Kwon"], "venue": "in: Proceedings of IEEE International Joint Conference of the Fourth IEEE International Conference on Fuzzy Systems and The Second International Fuzzy Engineering Symposium, Vol. 2", "citeRegEx": "54", "shortCiteRegEx": null, "year": 1995}, {"title": "Decision modelling using the choquet integral", "author": ["Y. Narukawa", "T. Murofushi"], "venue": "in: Modeling Decisions for Artificial Intelligence, Springer", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2004}, {"title": "Background subtraction techniques: a review", "author": ["M. Piccardi"], "venue": "in: IEEE International Conference on Systems, Man and Cybernetics (SMC), Vol. 4", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2004}, {"title": "Robust techniques for background subtraction in urban traffic video", "author": ["S.-C.S. Cheung", "C. Kamath"], "venue": "in: Proceedings of SPIE, Vol. 5308", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2004}, {"title": "Type-2 fuzzy gaussian mixture models", "author": ["J. Zeng", "L. Xie", "Z.-Q. Liu"], "venue": "Pattern Recognition 41 (12) ", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2008}, {"title": "Fuzzy sets", "author": ["L. Zadeh"], "venue": "Information and Control 8 (3) ", "citeRegEx": "59", "shortCiteRegEx": null, "year": 1965}, {"title": "Type-2 fuzzy sets made simple", "author": ["J.M. Mendel", "R.B. John"], "venue": "IEEE Transactions on Fuzzy Systems 10 (2) ", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2002}, {"title": "Type-2 fuzzy mixture of gaussians model: application to background modeling", "author": ["F. El Baf", "T. Bouwmans", "B. Vachon"], "venue": "in: Advances in Visual Computing, Springer", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2008}, {"title": "Fuzzy statistical modeling of dynamic backgrounds for moving object detection in infrared videos", "author": ["F. El Baf", "T. Bouwmans", "B. Vachon"], "venue": "in: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPRW)", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2009}, {"title": "F", "author": ["T. Bouwmans"], "venue": "El Baf, et al., Modeling of dynamic backgrounds by type-2 fuzzy gaussians mixture models, MASAUM Journal of of Basic and Applied Sciences 1 (2) ", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2009}, {"title": "A fuzzy background modeling approach for motion detection in dynamic backgrounds", "author": ["Z. Zhao", "T. Bouwmans", "X. Zhang", "Y. Fang"], "venue": "in: Multimedia and Signal Processing, Springer", "citeRegEx": "64", "shortCiteRegEx": null, "year": 2012}, {"title": "Fuzzy running average and fuzzy background subtraction: concepts and application", "author": ["M.H. Sigari", "N. Mozayani", "H.R. Pourreza"], "venue": "International Journal of Computer Science and Network Security 8 (2) ", "citeRegEx": "65", "shortCiteRegEx": null, "year": 2008}, {"title": "A neural fuzzy system for image motion estimation", "author": ["C. Lin", "I. Chung", "L. Sheu"], "venue": "Fuzzy Sets and Systems 114 (2) ", "citeRegEx": "66", "shortCiteRegEx": null, "year": 2000}, {"title": "A fuzzy spatial coherence-based approach to background/foreground separation for moving object detection", "author": ["L. Maddalena", "A. Petrosino"], "venue": "Neural Computing and Applications 19 (2) ", "citeRegEx": "67", "shortCiteRegEx": null, "year": 2010}, {"title": "Adaptive fuzzy apporach to background modeling using pso and klms", "author": ["Z. Li", "W. Liu", "Y. Zhang"], "venue": "in: 10th World Congress on Intelligent Control and Automation (WCICA)", "citeRegEx": "68", "shortCiteRegEx": null, "year": 2012}, {"title": "A fuzzy system for background modeling in video sequences", "author": ["E. Calvo-Gallego", "P. Brox", "S. S\u00e1nchez-Solano"], "venue": "in: Fuzzy Logic and Applications, Springer", "citeRegEx": "69", "shortCiteRegEx": null, "year": 2013}, {"title": "A novel fuzzy background subtraction method based on cellular automata for urban traffic applications", "author": ["M. Shakeri", "H. Deldari", "H. Foroughi", "A. Saberi", "A. Naseri"], "venue": "in: International Conference on Signal Processing (ICSP)", "citeRegEx": "70", "shortCiteRegEx": null, "year": 2008}, {"title": "Interval type-2 fuzzy logic systems made simple", "author": ["J.M. Mendel", "R.I. John", "F. Liu"], "venue": "IEEE Transactions on Fuzzy Systems 14 (6) ", "citeRegEx": "71", "shortCiteRegEx": null, "year": 2006}, {"title": "An introduction to fuzzy logic applications in intelligent systems", "author": ["R.R. Yager", "L. Zadeh"], "venue": "Springer", "citeRegEx": "72", "shortCiteRegEx": null, "year": 1992}, {"title": "Fuzzy logic", "author": ["L. Zadeh"], "venue": "Computer 21 (4) ", "citeRegEx": "73", "shortCiteRegEx": null, "year": 1988}, {"title": "Background subtraction and human detection in outdoor videos using fuzzy logic", "author": ["A. Mahapatra", "T.K. Mishra", "P.K. Sa", "B. Majhi"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "74", "shortCiteRegEx": null, "year": 2013}, {"title": "Human motion detection using fuzzy rule-base classification of moving blob regions", "author": ["J. See", "S. Lee", "M. Hanmandlu"], "venue": "in: Proc. Int. Conf. on Robotics, Vision, Information and Signal Processing 2005", "citeRegEx": "75", "shortCiteRegEx": null, "year": 2005}, {"title": "Detection of human presence in a surveillance video using fuzzy approach", "author": ["A. Chowdhury", "S.S. Tripathy"], "venue": "in: International Conference on Signal Processing and Integrated Networks (SPIN)", "citeRegEx": "76", "shortCiteRegEx": null, "year": 2014}, {"title": "Adaptive silouette extraction and human tracking in complex and dynamic environments", "author": ["X. Chen", "Z. He", "D. Anderson", "J. Keller", "M. Skubic"], "venue": "in: IEEE International Conference on Image Processing (ICIP)", "citeRegEx": "77", "shortCiteRegEx": null, "year": 2006}, {"title": "Adaptive silhouette extraction in dynamic environments using fuzzy logic", "author": ["X. Chen", "Z. He", "J.M. Keller", "D. Anderson", "M. Skubic"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "78", "shortCiteRegEx": null, "year": 2006}, {"title": "An interval type-2 fuzzy logic system for human silhouette extraction in dynamic environments", "author": ["B. Yao", "H. Hagras", "D. Al Ghazzawi", "M.J. Alhaddad"], "venue": "in: Autonomous and Intelligent Systems, Springer", "citeRegEx": "79", "shortCiteRegEx": null, "year": 2012}, {"title": "Interval type-2 fuzzy logic systems: theory and design", "author": ["Q. Liang", "J.M. Mendel"], "venue": "IEEE Transactions on Fuzzy Systems 8 (5) ", "citeRegEx": "80", "shortCiteRegEx": null, "year": 2000}, {"title": "Type-2 fuzzy logic systems: type-reduction", "author": ["N.N. Karnik", "J.M. Mendel"], "venue": "in: IEEE International Conference on Systems, Man, and Cybernetics (SMC), Vol. 2", "citeRegEx": "81", "shortCiteRegEx": null, "year": 1998}, {"title": "Tracking human body motion based on a stick figure model", "author": ["Y. Guo", "G. Xu", "S. Tsuji"], "venue": "Journal of Visual Communication and Image Representation 5 (1) ", "citeRegEx": "82", "shortCiteRegEx": null, "year": 1994}, {"title": "First sight: A human body outline labeling system", "author": ["M.K. Leung", "Y.-H. Yang"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 17 (4) ", "citeRegEx": "83", "shortCiteRegEx": null, "year": 1995}, {"title": "Posture estimation using structure and motion models", "author": ["Y. Iwai", "K. Ogaki", "M. Yachida"], "venue": "in: IEEE International Conference on Computer Vision (ICCV), Vol. 1", "citeRegEx": "84", "shortCiteRegEx": null, "year": 1999}, {"title": "Local and global skeleton fitting techniques for optical motion capture", "author": ["M.-C. Silaghi", "R. Pl\u00e4nkers", "R. Boulic", "P. Fua", "D. Thalmann"], "venue": "in: Modelling and Motion Capture Techniques for Virtual Environments, Springer", "citeRegEx": "85", "shortCiteRegEx": null, "year": 1998}, {"title": "Analyzing and recognizing walking figures in xyt", "author": ["S.A. Niyogi", "E.H. Adelson"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "86", "shortCiteRegEx": null, "year": 1994}, {"title": "Cardboard people: A parameterized model of articulated image motion", "author": ["S.X. Ju", "M.J. Black", "Y. Yacoob"], "venue": "in: Proceedings of the Second International Conference on Automatic Face and Gesture Recognition (FG)", "citeRegEx": "87", "shortCiteRegEx": null, "year": 1996}, {"title": "Towards model-based recognition of human movements in image sequences", "author": ["K. Rohr"], "venue": "CVGIP: Image understanding 59 (1) ", "citeRegEx": "88", "shortCiteRegEx": null, "year": 1994}, {"title": "Tracking of persons in monocular image sequences", "author": ["S. Wachter", "H.-H. Nagel"], "venue": "in: Proceedings of IEEE Nonrigid and Articulated Motion Workshop", "citeRegEx": "89", "shortCiteRegEx": null, "year": 1997}, {"title": "Model-based tracking of self-occluding articulated objects", "author": ["J.M. Rehg", "T. Kanade"], "venue": "in: Proceedings of International Conference on Computer Vision (ICCV)", "citeRegEx": "90", "shortCiteRegEx": null, "year": 1995}, {"title": "Model-based estimation of 3d human motion with occlusion based on active multi-viewpoint selection", "author": ["I.A. Kakadiaris", "D. Metaxas"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR), IEEE", "citeRegEx": "91", "shortCiteRegEx": null, "year": 1996}, {"title": "A survey of computer vision-based human motion capture", "author": ["T.B. Moeslund", "E. Granum"], "venue": "Computer Vision and Image Understanding 81 (3) ", "citeRegEx": "92", "shortCiteRegEx": null, "year": 2001}, {"title": "Kinematics-based tracking of human walking in monocular video sequences", "author": ["H. Ning", "T. Tan", "L. Wang", "W. Hu"], "venue": "Image and Vision Computing 22 (5) ", "citeRegEx": "93", "shortCiteRegEx": null, "year": 2004}, {"title": "Twist based acquisition and tracking of animal and human kinematics", "author": ["C. Bregler", "J. Malik", "K. Pullen"], "venue": "International Journal of Computer Vision 56 (3) ", "citeRegEx": "94", "shortCiteRegEx": null, "year": 2004}, {"title": "Fuzzy qualitative robot kinematics", "author": ["H. Liu"], "venue": "IEEE Transactions on Fuzzy Systems 16 (6) ", "citeRegEx": "95", "shortCiteRegEx": null, "year": 2008}, {"title": "Fuzzy qualitative human motion analysis", "author": ["C.S. Chan", "H. Liu"], "venue": "IEEE Transactions on Fuzzy Systems 17 (4) ", "citeRegEx": "96", "shortCiteRegEx": null, "year": 2009}, {"title": "Fuzzy qualitative simulation", "author": ["Q. Shen", "R. Leitch"], "venue": "IEEE Transactions on Systems, Man and Cybernetics 23 (4) ", "citeRegEx": "97", "shortCiteRegEx": null, "year": 1993}, {"title": "Recent advances in fuzzy qualitative reasoning", "author": ["C.S. Chan", "G.M. Coghill", "H. Liu"], "venue": "International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems 19 (03) ", "citeRegEx": "98", "shortCiteRegEx": null, "year": 2011}, {"title": "Qualitative simulation", "author": ["B. Kuipers"], "venue": "Artificial Intelligence 29 (3) ", "citeRegEx": "99", "shortCiteRegEx": null, "year": 1986}, {"title": "Fuzzy qualitative trigonometry", "author": ["H. Liu", "G.M. Coghill", "D.P. Barnes"], "venue": "International Journal of Approximate Reasoning 51 (1) ", "citeRegEx": "100", "shortCiteRegEx": null, "year": 2009}, {"title": "A fuzzy qualitative framework for connecting robot qualitative and quantitative representations", "author": ["H. Liu", "D.J. Brown", "G.M. Coghill"], "venue": "IEEE Transactions on Fuzzy Systems 16 (3) ", "citeRegEx": "101", "shortCiteRegEx": null, "year": 2008}, {"title": "A fuzzy qualitative approach to human motion recognition", "author": ["C.S. Chan", "H. Liu", "D. Brown", "N. Kubota"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "102", "shortCiteRegEx": null, "year": 2008}, {"title": "J", "author": ["D. Anderson", "R.H. Luke III", "E.E. Stone"], "venue": "M. Keller, Fuzzy voxel object., in: IFSA/EUSFLAT Conf.", "citeRegEx": "103", "shortCiteRegEx": null, "year": 2009}, {"title": "Linguistic summarization of video for fall detection using voxel person and fuzzy logic", "author": ["D. Anderson", "R.H. Luke", "J.M. Keller", "M. Skubic", "M. Rantz", "M. Aud"], "venue": "Computer Vision and Image Understanding 113 (1) ", "citeRegEx": "104", "shortCiteRegEx": null, "year": 2009}, {"title": "Robust object tracking with fuzzy shape estimation", "author": ["J. Garc\u00eda", "J.M. Molina", "J.A. Besada", "J.I. Portillo", "J.R. Casar"], "venue": "in: Proceedings of the International Conference on Information Fusion, Vol. 1", "citeRegEx": "105", "shortCiteRegEx": null, "year": 2002}, {"title": "Fuzzy region assignment for visual tracking", "author": ["J. Garcia", "M.A. Patricio", "A. Berlanga", "J.M. Molina"], "venue": "Soft Computing 15 (9) ", "citeRegEx": "106", "shortCiteRegEx": null, "year": 2011}, {"title": "A new approach to linear filtering and prediction problems", "author": ["R.E. Kalman"], "venue": "Journal of Basic Engineering 82 (1) ", "citeRegEx": "107", "shortCiteRegEx": null, "year": 1960}, {"title": "Using the Kalman filter to track human interactive motion: modelling and initialization of the Kalman filter for translational motion", "author": ["M. Kohler"], "venue": "Citeseer", "citeRegEx": "108", "shortCiteRegEx": null, "year": 1997}, {"title": "Implementation and experimental results of a quaternion-based kalman filter for human body motion tracking", "author": ["X. Yun", "C. Aparicio", "E.R. Bachmann", "R.B. McGhee"], "venue": "in: Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)", "citeRegEx": "109", "shortCiteRegEx": null, "year": 2005}, {"title": "Design", "author": ["X. Yun", "E.R. Bachmann"], "venue": "implementation, and experimental results of a quaternion-based kalman filter for human body motion tracking, IEEE Transactions on Robotics 22 (6) ", "citeRegEx": "110", "shortCiteRegEx": null, "year": 2006}, {"title": "An extended kalman filter for quaternion-based orientation estimation using marg sensors", "author": ["J.L. Marins", "X. Yun", "E.R. Bachmann", "R.B. McGhee", "M.J. Zyda"], "venue": "in: Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems, Vol. 4", "citeRegEx": "111", "shortCiteRegEx": null, "year": 2001}, {"title": "History: The use of the kalman filter for human motion tracking in virtual reality", "author": ["G.F. Welch"], "venue": "Presence: Teleoperators and Virtual Environments 18 (1) ", "citeRegEx": "112", "shortCiteRegEx": null, "year": 2009}, {"title": "G", "author": ["G. Welch"], "venue": "Bishop, An introduction to the kalman filter ", "citeRegEx": "113", "shortCiteRegEx": null, "year": 1995}, {"title": "Fuzzy kalman filtering", "author": ["G. Chen", "Q. Xie", "L.S. Shieh"], "venue": "Information Sciences 109 (1) ", "citeRegEx": "114", "shortCiteRegEx": null, "year": 1998}, {"title": "Accurate differential global positioning system via fuzzy logic kalman filter sensor fusion technique", "author": ["K. Kobayashi", "K.C. Cheok", "K. Watanabe", "F. Munekata"], "venue": "IEEE Transactions on Industrial Electronics 45 (3) ", "citeRegEx": "115", "shortCiteRegEx": null, "year": 1998}, {"title": "Sensor fusion based on fuzzy kalman filtering for autonomous robot vehicle", "author": ["J. Sasiadek", "Q. Wang"], "venue": "in: Proceedings of the International Conference on Robotics and Automation (ICRA), Vol. 4", "citeRegEx": "116", "shortCiteRegEx": null, "year": 1999}, {"title": "Fuzzy adaptive kalman filtering for ins/gps data fusion", "author": ["J. Sasiadek", "Q. Wang", "M. Zeremba"], "venue": "in: Proceedings of the IEEE International Symposium on Intelligent Control", "citeRegEx": "117", "shortCiteRegEx": null, "year": 2000}, {"title": "Sensor fusion based on fuzzy kalman filter", "author": ["J. Sasiadek", "J. Khe"], "venue": "in: Proceedings of the Second International Workshop on Robot Motion and Control", "citeRegEx": "118", "shortCiteRegEx": null, "year": 2001}, {"title": "Nonlinear state estimation using fuzzy kalman filter", "author": ["R. Senthil", "K. Janarthanan", "J. Prakash"], "venue": "Industrial & Engineering Chemistry Research 45 (25) ", "citeRegEx": "119", "shortCiteRegEx": null, "year": 2006}, {"title": "Autonomous novelty detection and object tracking in video streams using evolving clustering and takagi-sugeno type neuro-fuzzy system", "author": ["P. Angelov", "R. Ramezani", "X. Zhou"], "venue": "in: IEEE International Joint Conference on Neural Networks (IJCNN)", "citeRegEx": "120", "shortCiteRegEx": null, "year": 2008}, {"title": "An approach to online identification of takagi-sugeno fuzzy models", "author": ["P.P. Angelov", "D.P. Filev"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics 34 (1) ", "citeRegEx": "121", "shortCiteRegEx": null, "year": 2004}, {"title": "Simpl_ets: a simplified method for learning evolving takagi-sugeno fuzzy models", "author": ["P. Angelov", "D. Filev"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "122", "shortCiteRegEx": null, "year": 2005}, {"title": "Fuzzy particle filtering for uncertain systems", "author": ["H. Wu", "F. Sun", "H. Liu"], "venue": "IEEE Transactions on Fuzzy Systems 16 (5) ", "citeRegEx": "123", "shortCiteRegEx": null, "year": 2008}, {"title": "Object tracking from image sequences using adaptive models in fuzzy particle filter", "author": ["C. Yoon", "M. Cheon", "M. Park"], "venue": "Information Sciences 253 ", "citeRegEx": "124", "shortCiteRegEx": null, "year": 2013}, {"title": "Fuzzy logic based particle filter for tracking a maneuverable target", "author": ["H. Kamel", "W. Badawy"], "venue": "in: 48th Midwest Symposium on Circuits and Systems", "citeRegEx": "125", "shortCiteRegEx": null, "year": 2005}, {"title": "Fuzzy adaptive particle filter for localization of a mobile robot", "author": ["Y.-J. Kim", "C.-H. Won", "J.-M. Pak", "M.-T. Lim"], "venue": "in: Knowledge-Based Intelligent Information and Engineering Systems, Springer", "citeRegEx": "126", "shortCiteRegEx": null, "year": 2007}, {"title": "Determining optical flow", "author": ["B.K. Horn", "B.G. Schunck"], "venue": "in: 1981 Technical Symposium East, International Society for Optics and Photonics", "citeRegEx": "127", "shortCiteRegEx": null, "year": 1981}, {"title": "The computation of optical flow", "author": ["S. Beauchemin", "J.L. Barron"], "venue": "ACM Computing Surveys 27 (3) ", "citeRegEx": "128", "shortCiteRegEx": null, "year": 1995}, {"title": "High-speed target tracking by fuzzy hostility-induced segmentation of optical flow field", "author": ["S. Bhattacharyya", "U. Maulik", "P. Dutta"], "venue": "Applied Soft Computing 9 (1) ", "citeRegEx": "129", "shortCiteRegEx": null, "year": 2009}, {"title": "Target tracking using fuzzy hostility induced segmentation of optical flow field", "author": ["S. Bhattacharyya", "U. Maulik"], "venue": "in: Soft Computing for Image and Multimedia Data Processing, Springer", "citeRegEx": "130", "shortCiteRegEx": null, "year": 2013}, {"title": "Binary object extraction using bi-directional self-organizing neural network (bdsonn) architecture with fuzzy context sensitive thresholding", "author": ["S. Bhattacharyya", "P. Dutta", "U. Maulik"], "venue": "Pattern Analysis and Applications 10 (4) ", "citeRegEx": "131", "shortCiteRegEx": null, "year": 2007}, {"title": "A multi-object tracking system for surveillance video analysis", "author": ["D. Xie", "W. Hu", "T. Tan", "J. Peng"], "venue": "in: Proceedings of the 17th International Conference on Pattern Recognition (ICPR), Vol. 4", "citeRegEx": "132", "shortCiteRegEx": null, "year": 2004}, {"title": "Tracking non-rigid", "author": ["B. Heisele", "U. Kressel", "W. Ritter"], "venue": "moving objects based on color cluster flow, in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "133", "shortCiteRegEx": null, "year": 1997}, {"title": "From cluster tracking to people counting", "author": ["A.E. Pece"], "venue": "in: IEEE Workshop on Performance Evaluation of Tracking and Surveillance (PETS)", "citeRegEx": "134", "shortCiteRegEx": null, "year": 2002}, {"title": "Automatic classification of single facial images", "author": ["M.J. Lyons", "J. Budynek", "S. Akamatsu"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 21 (12) ", "citeRegEx": "135", "shortCiteRegEx": null, "year": 1999}, {"title": "Vision-based gesture recognition: A review", "author": ["Y. Wu", "T.S. Huang"], "venue": "in: Gesture-based communication in human-computer interaction, Springer", "citeRegEx": "136", "shortCiteRegEx": null, "year": 1999}, {"title": "Gesture recognition: A survey", "author": ["S. Mitra", "T. Acharya"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews 37 (3) ", "citeRegEx": "137", "shortCiteRegEx": null, "year": 2007}, {"title": "Real-time hand gesture telerobotic system using fuzzy c-means clustering", "author": ["J. Wachs", "U. Kartoun", "H. Stern", "Y. Edan"], "venue": "in: Proceedings of the 5th Biannual World Automation Congress, Vol. 13", "citeRegEx": "138", "shortCiteRegEx": null, "year": 2002}, {"title": "Cluster labeling and parameter estimation for the automated setup of a hand-gesture recognition system", "author": ["J.P. Wachs", "H. Stern", "Y. Edan"], "venue": "IEEE Transactions on Systems, Man and Cybernetics, Part A: Systems and Humans 35 (6) ", "citeRegEx": "139", "shortCiteRegEx": null, "year": 2005}, {"title": "Vision based hand gesture recognition using finite state machines and fuzzy logic", "author": ["R. Verma", "A. Dev"], "venue": "in: International Conference on Ultra Modern Telecommunications & Workshops (ICUMT)", "citeRegEx": "141", "shortCiteRegEx": null, "year": 2009}, {"title": "Recognition of gestures in arabic sign language using neuro-fuzzy systems", "author": ["O. Al-Jarrah", "A. Halawani"], "venue": "Artificial Intelligence 133 (1) ", "citeRegEx": "142", "shortCiteRegEx": null, "year": 2001}, {"title": "Hand gesture recognition using fuzzy neural network", "author": ["N.D. Binh", "T. Ejima"], "venue": "in: Proc. ICGST Conf. Graphics, Vision and Image Proces", "citeRegEx": "143", "shortCiteRegEx": null, "year": 2005}, {"title": "Human\u2013computer interaction for smart environment applications using fuzzy hand posture and gesture models", "author": ["A.R. V\u00e1rkonyi-K\u00f3czy", "B. Tusor"], "venue": "IEEE Transactions on Instrumentation and Measurement 60 (5) ", "citeRegEx": "144", "shortCiteRegEx": null, "year": 2011}, {"title": "Fuzzy artmap: A neural network architecture for incremental supervised learning of analog multidimensional maps", "author": ["G.A. Carpenter", "S. Grossberg", "N. Markuzon", "J.H. Reynolds", "D.B. Rosen"], "venue": "IEEE Transactions on Neural Networks 3 (5) ", "citeRegEx": "145", "shortCiteRegEx": null, "year": 1992}, {"title": "A novel feature recognition neural network and its application to character recognition", "author": ["B. Hussain", "M.R. Kabuka"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 16 (1) ", "citeRegEx": "146", "shortCiteRegEx": null, "year": 1994}, {"title": "A fuzzy spatio-temporal-based approach for activity recognition", "author": ["J.-M. Le Yaouanc", "J.-P. Poli"], "venue": "in: Advances in Conceptual Modeling, Springer", "citeRegEx": "147", "shortCiteRegEx": null, "year": 2012}, {"title": "A fuzzy logic-based system for the automation of human behavior recognition using machine vision in intelligent environments", "author": ["B. Yao", "H. Hagras", "M.J. Alhaddad", "D. Alghazzawi"], "venue": "Soft Computing ", "citeRegEx": "148", "shortCiteRegEx": null, "year": 2014}, {"title": "Combining neural networks and fuzzy systems for human behavior understanding", "author": ["G. Acampora", "P. Foggia", "A. Saggese", "M. Vento"], "venue": "in: IEEE Ninth International Conference on Advanced Video and Signal-Based Surveillance (AVSS)", "citeRegEx": "149", "shortCiteRegEx": null, "year": 2012}, {"title": "Fuzzy rule-based reasoning approach for event detection and annotation of broadcast soccer video", "author": ["M.-S. Hosseini", "A.-M. Eftekhari-Moghadam"], "venue": "Applied Soft Computing 13 (2) ", "citeRegEx": "150", "shortCiteRegEx": null, "year": 2013}, {"title": "Combining fuzzy vector quantization with linear discriminant analysis for continuous human movement recognition", "author": ["N. Gkalelis", "A. Tefas", "I. Pitas"], "venue": "IEEE Transactions on Circuits and Systems for Video Technology 18 (11) ", "citeRegEx": "151", "shortCiteRegEx": null, "year": 2008}, {"title": "Fuzzy vector quantization algorithms and their application in image compression", "author": ["N.B. Karayiannis", "P.-I. Pai"], "venue": "IEEE Transactions on Image Processing 4 (9) ", "citeRegEx": "152", "shortCiteRegEx": null, "year": 1995}, {"title": "Hidden Markov Models", "author": ["R.J. Elliott", "L. Aggoun", "J.B. Moore"], "venue": "Springer", "citeRegEx": "153", "shortCiteRegEx": null, "year": 1995}, {"title": "A state-based technique for the summarization and recognition of gesture", "author": ["A.F. Bobick", "A.D. Wilson"], "venue": "in: International Conference on Computer Vision (ICCV)", "citeRegEx": "154", "shortCiteRegEx": null, "year": 1995}, {"title": "Recognition of human body motion using phase space constraints", "author": ["L.W. Campbell", "A.F. Bobick"], "venue": "in: International Conference on Computer Vision (ICCV)", "citeRegEx": "155", "shortCiteRegEx": null, "year": 1995}, {"title": "A bayesian computer vision system for modeling human interactions", "author": ["N.M. Oliver", "B. Rosario", "A.P. Pentland"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 22 (8) ", "citeRegEx": "156", "shortCiteRegEx": null, "year": 2000}, {"title": "Parametric hidden markov models for gesture recognition", "author": ["A.D. Wilson", "A.F. Bobick"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 21 (9) ", "citeRegEx": "157", "shortCiteRegEx": null, "year": 1999}, {"title": "Recognizing human action in time-sequential images using hidden markov model", "author": ["J. Yamato", "J. Ohya", "K. Ishii"], "venue": "in: IEEE Conference on 32  Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "158", "shortCiteRegEx": null, "year": 1992}, {"title": "A novel fuzzy hmm approach for human action recognition in video", "author": ["K. Mozafari", "N.M. Charkari", "H.S. Boroujeni", "M. Behrouzifar"], "venue": "in: Knowledge Technology, Springer", "citeRegEx": "159", "shortCiteRegEx": null, "year": 2012}, {"title": "Fuzzy action recognition for multiple views within single camera", "author": ["C.H. Lim", "C.S. Chan"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "160", "shortCiteRegEx": null, "year": 2013}, {"title": "Person specific activity recognition using fuzzy learning and discriminant analysis", "author": ["A. Iosifidis", "A. Tefas", "I. Pitas"], "venue": "in: Proceedings of the 19th European Signal Processing Conference (EUSIPCO)", "citeRegEx": "161", "shortCiteRegEx": null, "year": 2011}, {"title": "Activity-based person identification using fuzzy representation and discriminant learning", "author": ["A. Iosifidis", "A. Tefas", "I. Pitas"], "venue": "IEEE Transactions on Information Forensics and Security 7 (2) ", "citeRegEx": "162", "shortCiteRegEx": null, "year": 2012}, {"title": "Multi-view human movement recognition based on fuzzy distances and linear discriminant analysis", "author": ["A. Iosifidis", "A. Tefas", "N. Nikolaidis", "I. Pitas"], "venue": "Computer Vision and Image Understanding 116 (3) ", "citeRegEx": "163", "shortCiteRegEx": null, "year": 2012}, {"title": "Minimum class variance extreme learning machine for human action recognition", "author": ["A. Iosifidis", "A. Tefas", "I. Pitas"], "venue": "IEEE Transactions on Circuits and Systems for Video Technology 23 (11) ", "citeRegEx": "164", "shortCiteRegEx": null, "year": 2013}, {"title": "Multi-view action recognition based on action volumes", "author": ["A. Iosifidis", "A. Tefas", "I. Pitas"], "venue": "fuzzy distances and cluster discriminant analysis, Signal Processing 93 (6) ", "citeRegEx": "165", "shortCiteRegEx": null, "year": 2012}, {"title": "Anomaly detection in extremely crowded scenes using spatio-temporal motion pattern models", "author": ["L. Kratz", "K. Nishino"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "166", "shortCiteRegEx": null, "year": 2009}, {"title": "Chaotic invariants of lagrangian particle trajectories for anomaly detection in crowded scenes", "author": ["S. Wu", "B.E. Moore", "M. Shah"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "167", "shortCiteRegEx": null, "year": 2010}, {"title": "Extension of a soft-computing framework for activity analysis from linguistic summarizations of video", "author": ["D. Anderson", "R.H. Luke", "J.M. Keller", "M. Skubic"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "168", "shortCiteRegEx": null, "year": 2008}, {"title": "Fall detection in a smart room by using a fuzzy one class support vector machine and imperfect training data", "author": ["M. Yu", "S.M. Naqvi", "A. Rhuma", "J. Chambers"], "venue": "in: IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)", "citeRegEx": "169", "shortCiteRegEx": null, "year": 2011}, {"title": "Multi-prototype fuzzy clustering with fuzzy k-nearest neighbor for off-line human action recognition", "author": ["R. Wongkhuenkaew", "S. Auephanwiriyakul", "N. Theera-Umpon"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "170", "shortCiteRegEx": null, "year": 2013}, {"title": "Fuzzy qualitative complex actions recognition", "author": ["C.S. Chan", "H. Liu", "W.K. Lai"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "171", "shortCiteRegEx": null, "year": 2010}, {"title": "Detecting pedestrian abnormal behavior based on fuzzy associative memory", "author": ["Z. Wang", "J. Zhang"], "venue": "in: Fourth International Conference on Natural Computation (ICNC), Vol. 6", "citeRegEx": "172", "shortCiteRegEx": null, "year": 2008}, {"title": "Human body posture classification by a neural fuzzy network and home care system application", "author": ["C.-F. Juang", "C.-M. Chang"], "venue": "EEE Transactions on Systems, Man and Cybernetics, Part A: Systems and Humans 37 (6) ", "citeRegEx": "173", "shortCiteRegEx": null, "year": 2007}, {"title": "Learning activity patterns using fuzzy self-organizing neural network", "author": ["W. Hu", "D. Xie", "T. Tan", "S. Maybank"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics 34 (3) ", "citeRegEx": "174", "shortCiteRegEx": null, "year": 2004}, {"title": "Toward a theory of fuzzy information granulation and its centrality in human reasoning and fuzzy logic", "author": ["L.A. Zadeh"], "venue": "Fuzzy Sets and Systems 90 (2) ", "citeRegEx": "175", "shortCiteRegEx": null, "year": 1997}, {"title": "Computing with uncertainty", "author": ["J.C. Bezdek"], "venue": "IEEE Communications Magazine 30 (9) ", "citeRegEx": "176", "shortCiteRegEx": null, "year": 1992}, {"title": "Uncertainty representation using fuzzy measures", "author": ["R.R. Yager"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics 32 (1) ", "citeRegEx": "177", "shortCiteRegEx": null, "year": 2002}, {"title": "Uncertainty bounds and their use in the design of interval type-2 fuzzy logic systems", "author": ["H. Wu", "J.M. Mendel"], "venue": "IEEE Transactions on Fuzzy Systems 10 (5) ", "citeRegEx": "178", "shortCiteRegEx": null, "year": 2002}, {"title": "Uncertainty measures for interval type-2 fuzzy sets", "author": ["D. Wu", "J.M. Mendel"], "venue": "Information Sciences 177 (23) ", "citeRegEx": "179", "shortCiteRegEx": null, "year": 2007}, {"title": "Type-2 fuzzy sets for handling uncertainty in pattern recognition", "author": ["J. Zeng", "Z.-Q. Liu"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "180", "shortCiteRegEx": null, "year": 2006}, {"title": "Fuzzy logic= computing with words", "author": ["L. Zadeh"], "venue": "IEEE Transactions on Fuzzy Systems 4 (2) ", "citeRegEx": "181", "shortCiteRegEx": null, "year": 1996}, {"title": "Outline of a new approach to the analysis of complex systems and decision processes", "author": ["L. Zadeh"], "venue": "IEEE Transactions on Systems, Man and Cybernetics (1) ", "citeRegEx": "182", "shortCiteRegEx": null, "year": 1973}, {"title": "Computing with words", "author": ["S.H. Rubin"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics 29 (4) ", "citeRegEx": "183", "shortCiteRegEx": null, "year": 1999}, {"title": "A", "author": ["G. Trivino"], "venue": "van der Heide, Linguistic summarization of the human activity using skin conductivity and accelerometers, in: Proc. 12th Int. Conf. on Information Processing and Management of Uncertainty in Knowledge-based Systems (IPMU)", "citeRegEx": "184", "shortCiteRegEx": null, "year": 2008}, {"title": "Linguistic summaries of data using fuzzy logic", "author": ["J. Kacprzyk", "R.R. Yager"], "venue": "International Journal of General System 30 (2) ", "citeRegEx": "185", "shortCiteRegEx": null, "year": 2001}, {"title": "Linguistic description of adult skeletal age-at-death estimations from fuzzy integral acquired fuzzy sets", "author": ["D.T. Anderson", "J.M. Keller", "M. Anderson", "D.J. Wescott"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "186", "shortCiteRegEx": null, "year": 2011}, {"title": "Linguistic summarization of sensor data for eldercare", "author": ["A. Wilbik", "J.M. Keller", "G.L. Alexander"], "venue": "in: IEEE International Conference on Systems, Man, and Cybernetics (SMC)", "citeRegEx": "187", "shortCiteRegEx": null, "year": 2011}, {"title": "A fuzzy measure similarity between sets of linguistic summaries", "author": ["A. Wilbik", "J. Keller"], "venue": "IEEE Transactions on Fuzzy Systems 21 (1) ", "citeRegEx": "188", "shortCiteRegEx": null, "year": 2013}, {"title": "Generating fuzzy rules by learning from examples", "author": ["L.-X. Wang", "J.M. Mendel"], "venue": "IEEE Transactions on Systems, Man and Cybernetics 22 (6) ", "citeRegEx": "189", "shortCiteRegEx": null, "year": 1992}, {"title": "Fuzzy rule generation methods for high-level computer vision", "author": ["F.C.-H. Rhee", "R. Krishnapuram"], "venue": "Fuzzy Sets and Systems 60 (3) ", "citeRegEx": "190", "shortCiteRegEx": null, "year": 1993}, {"title": "A new approach to fuzzy rule generation: fuzzy extension matrix", "author": ["X. Wang", "Y. Wang", "X. Xu", "W. Ling", "D.S. Yeung"], "venue": "Fuzzy Sets and Systems 123 (3) ", "citeRegEx": "191", "shortCiteRegEx": null, "year": 2001}, {"title": "Fast clustering with application to fuzzy rule generation", "author": ["T.W. Cheng", "D. Goldgof", "L. Hall"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ), Vol. 4", "citeRegEx": "192", "shortCiteRegEx": null, "year": 1995}, {"title": "Generating the knowledge base of a fuzzy rule-based system by the genetic learning of the data base", "author": ["O. Cord\u00f3n", "F. Herrera", "P. Villar"], "venue": "IEEE 33  Transactions on Fuzzy Systems 9 (4) ", "citeRegEx": "193", "shortCiteRegEx": null, "year": 2001}, {"title": "Neuro-fuzzy rule generation: survey in soft computing framework", "author": ["S. Mitra", "Y. Hayashi"], "venue": "IEEE Transactions on Neural Networks 11 (3) ", "citeRegEx": "194", "shortCiteRegEx": null, "year": 2000}, {"title": "Learning discriminative space\u2013time action parts from weakly labelled videos", "author": ["M. Sapienza", "F. Cuzzolin", "P.H. Torr"], "venue": "International Journal of Computer Vision ", "citeRegEx": "195", "shortCiteRegEx": null, "year": 2014}, {"title": "The pets04 surveillance ground-truth data sets", "author": ["R.B. Fisher"], "venue": "in: Proc. 6th IEEE International Workshop on Performance Evaluation of Tracking and Surveillance (PETS)", "citeRegEx": "196", "shortCiteRegEx": null, "year": 2004}, {"title": "Single/cross-camera multiple-person tracking by graph matching", "author": ["W. Nie", "A. Liu", "Y. Su", "H. Luan", "Z. Yang", "L. Cao", "R. Ji"], "venue": "Neurocomputing 139 ", "citeRegEx": "197", "shortCiteRegEx": null, "year": 2014}, {"title": "Recognizing human action from a far field of view", "author": ["C.-C. Chen", "J. Aggarwal"], "venue": "in: Workshop on Motion and Video Computing", "citeRegEx": "198", "shortCiteRegEx": null, "year": 2009}, {"title": "Multi-max-margin support vector machine for multi-source human action recognition", "author": ["D. Wu", "L. Shao"], "venue": "Neurocomputing 127 ", "citeRegEx": "199", "shortCiteRegEx": null, "year": 2014}, {"title": "Human activity recognition based on r transform", "author": ["Y. Wang", "K. Huang", "T. Tan"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "200", "shortCiteRegEx": null, "year": 2007}, {"title": "Application of an incremental svm algorithm for on-line human recognition from video surveillance using texture and color features", "author": ["Y. Lu", "K. Boukharouba", "J. Boon\u00e6rt", "A. Fleury", "S. Lec\u0153uche"], "venue": "Neurocomputing 126 ", "citeRegEx": "201", "shortCiteRegEx": null, "year": 2014}, {"title": "Etiseo", "author": ["A.T. Nghiem", "F. Bremond", "M. Thonnat", "V. Valentin"], "venue": "performance evaluation for video surveillance systems, in: IEEE Conference on Advanced Video and Signal Based Surveillance (AVSS)", "citeRegEx": "202", "shortCiteRegEx": null, "year": 2007}, {"title": "F", "author": ["S.M. Simha", "D.P. Chau"], "venue": "Bremond, et al., Feature matching using co-inertia analysis for people tracking, in: The 9th International Conference on Computer Vision Theory and Applications (VISAPP)", "citeRegEx": "203", "shortCiteRegEx": null, "year": 2014}, {"title": "Human action recognition using distribution of oriented rectangular patches", "author": ["N. Ikizler", "P. Duygulu"], "venue": "in: Human Motion\u2013Understanding, Modeling, Capture and Animation, Springer", "citeRegEx": "204", "shortCiteRegEx": null, "year": 2007}, {"title": "Human activity recognition with metric learning", "author": ["D. Tran", "A. Sorokin"], "venue": "in: European Conference on Computer Vision (ECCV), Springer", "citeRegEx": "205", "shortCiteRegEx": null, "year": 2008}, {"title": "The complex action recognition via the correlated topic model, The Scientific World", "author": ["H.-b. Tu", "L.-m. Xia", "Z.-w. Wang"], "venue": null, "citeRegEx": "206", "shortCiteRegEx": "206", "year": 2014}, {"title": "Charting-based subspace learning for video-based human action classification", "author": ["V. John", "E. Trucco"], "venue": "Machine Vision and Applications 25 (1) ", "citeRegEx": "208", "shortCiteRegEx": null, "year": 2014}, {"title": "Vihasi: virtual human action silhouette data for the performance evaluation of silhouettebased action recognition methods", "author": ["H. Ragheb", "S. Velastin", "P. Remagnino", "T. Ellis"], "venue": "in: Second ACM/IEEE International Conference on Distributed Smart Cameras (ICDSC)", "citeRegEx": "209", "shortCiteRegEx": null, "year": 2008}, {"title": "Grassmann multimodal implicit feature selection", "author": ["L. Zhang", "D. Tao", "X. Liu", "L. Sun", "M. Song", "C. Chen"], "venue": "Multimedia Systems ", "citeRegEx": "210", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning realistic human actions from movies", "author": ["I. Laptev", "M. Marszalek", "C. Schmid", "B. Rozenfeld"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "211", "shortCiteRegEx": null, "year": 2008}, {"title": "Recognizing complex events in real movies by combining audio and video features", "author": ["J.-X. Du", "C.-M. Zhai", "Y.-L. Guo", "Y.-Y. Tang", "P.C. Chun Lung"], "venue": "Neurocomputing 137 ", "citeRegEx": "212", "shortCiteRegEx": null, "year": 2014}, {"title": "Actions in context", "author": ["M. Marszalek", "I. Laptev", "C. Schmid"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "213", "shortCiteRegEx": null, "year": 2009}, {"title": "Action recognition with improved trajectories", "author": ["H. Wang", "C. Schmid"], "venue": "in: International Conference on Computer Vision (ICCV)", "citeRegEx": "214", "shortCiteRegEx": null, "year": 2013}, {"title": "Action mach: Maximum average correlation height filter for action recognition", "author": ["M. Rodriguez", "J. Ahmed", "M. Shah"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "215", "shortCiteRegEx": null, "year": 2008}, {"title": "Action recognition in videos acquired by a moving camera using motion decomposition of lagrangian particle trajectories", "author": ["S. Wu", "O. Oreifej", "M. Shah"], "venue": "in: IEEE International Conference on Computer Vision (ICCV)", "citeRegEx": "216", "shortCiteRegEx": null, "year": 2011}, {"title": "Recognizing realistic actions from videos in the wild", "author": ["J. Liu", "J. Luo", "M. Shah"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "217", "shortCiteRegEx": null, "year": 2009}, {"title": "The i3dpost multi-view and 3d human action/interaction database", "author": ["N. Gkalelis", "H. Kim", "A. Hilton", "N. Nikolaidis", "I. Pitas"], "venue": "in: Conference for Visual Media Production (CVMP)", "citeRegEx": "218", "shortCiteRegEx": null, "year": 2009}, {"title": "A local 3-d motion descriptor for multi-view human action recognition from 4-d spatio-temporal interest points", "author": ["M.B. Holte", "B. Chakraborty", "J. Gonzalez", "T.B. Moeslund"], "venue": "IEEE Journal of Selected Topics in Signal Processing 6 (5) ", "citeRegEx": "219", "shortCiteRegEx": null, "year": 2012}, {"title": "Spatio-temporal relationship match: Video structure comparison for recognition of complex human activities", "author": ["M.S. Ryoo", "J.K. Aggarwal"], "venue": "in: IEEE International Conference on Computer Vision (ICCV)", "citeRegEx": "220", "shortCiteRegEx": null, "year": 2009}, {"title": "Discriminative subvolume search for efficient action detection", "author": ["J. Yuan", "Z. Liu", "Y. Wu"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "222", "shortCiteRegEx": null, "year": 2009}, {"title": "Action recognition based on a bag of 3d points", "author": ["W. Li", "Z. Zhang", "Z. Liu"], "venue": "in: 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)", "citeRegEx": "223", "shortCiteRegEx": null, "year": 2010}, {"title": "Effective 3d action recognition using eigenjoints", "author": ["X. Yang", "Y. Tian"], "venue": "Journal of Visual Communication and Image Representation 25 (1) ", "citeRegEx": "224", "shortCiteRegEx": null, "year": 2014}, {"title": "The behave video dataset: ground truthed video for multi-person behavior classification", "author": ["S. Blunsden", "R. Fisher"], "venue": "Annals of the BMVA 2010 (4) ", "citeRegEx": "225", "shortCiteRegEx": null, "year": 2010}, {"title": "Recognizing human group action by layered model with multiple cues", "author": ["Z. Cheng", "L. Qin", "Q. Huang", "S. Yan", "Q. Tian"], "venue": "Neurocomputing 136 ", "citeRegEx": "226", "shortCiteRegEx": null, "year": 2014}, {"title": "Muhavi: A multicamera human action video dataset for the evaluation of action recognition methods", "author": ["S. Singh", "S.A. Velastin", "H. Ragheb"], "venue": "in: 2010 Seventh IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)", "citeRegEx": "227", "shortCiteRegEx": null, "year": 2010}, {"title": "Optimizing human action recognition based on a cooperative coevolutionary algorithm", "author": ["A.A. Chaaraoui", "F. Fl\u00f3rez-Revuelta"], "venue": "Engineering Applications of Artificial Intelligence 31 ", "citeRegEx": "228", "shortCiteRegEx": null, "year": 2013}, {"title": "Modeling temporal structure of decomposable motion segments for activity classification", "author": ["J.C. Niebles", "C.-W. Chen", "L. Fei-Fei"], "venue": "in: European Conference on Computer Vision (ECCV), Springer", "citeRegEx": "229", "shortCiteRegEx": null, "year": 2010}, {"title": "High five: Recognising human interactions in tv shows", "author": ["A. Patron-Perez", "M. Marszalek", "A. Zisserman", "I. Reid"], "venue": "in: Proceedings of the British Machine Vision Conference (BMVC)", "citeRegEx": "230", "shortCiteRegEx": null, "year": 2010}, {"title": "N", "author": ["M. Mar\u00edn-Jim\u00e9nez", "R. Mu\u00f1oz-Salinas", "E. Yeguas-Bolivar"], "venue": "P. de la Blanca, Human interaction categorization by using audio-visual cues, Machine Vision and Applications 25 (1) ", "citeRegEx": "231", "shortCiteRegEx": null, "year": 2014}, {"title": "Hmdb: a large video database for human motion recognition", "author": ["H. Kuehne", "H. Jhuang", "E. Garrote", "T. Poggio", "T. Serre"], "venue": "in: IEEE International Conference on Computer Vision (ICCV)", "citeRegEx": "232", "shortCiteRegEx": null, "year": 2011}, {"title": "Videoweb dataset for multi-camera activities and non-verbal communication", "author": ["G. Denina", "B. Bhanu", "H.T. Nguyen", "C. Ding", "A. Kamal", "C. Ravishankar", "A. Roy-Chowdhury", "A. Ivers", "B. Varda"], "venue": "in: Distributed Video Sensor Networks, Springer", "citeRegEx": "233", "shortCiteRegEx": null, "year": 2011}, {"title": "Detecting group activities with multi-camera context", "author": ["Z.-J. Zha", "H. Zhang", "M. Wang", "H. Luan", "T.-S. Chua"], "venue": "IEEE Transactions on Circuits and Systems for Video Technology 23 (5) ", "citeRegEx": "234", "shortCiteRegEx": null, "year": 2013}, {"title": "Ucf101: A dataset of 101 human actions classes from videos in the wild", "author": ["K. Soomro", "A.R. Zamir", "M. Shah"], "venue": "Tech. Rep. CRCV-TR-12-01, CRCV, University of Central Florida ", "citeRegEx": "235", "shortCiteRegEx": null, "year": 2012}, {"title": "Multi-view super vector for action recognition", "author": ["Z. Cai", "L. Wang", "X. Peng", "Y. Qiao"], "venue": "in: IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "236", "shortCiteRegEx": null, "year": 2014}, {"title": "Recognizing 50 human action categories of web videos", "author": ["K.K. Reddy", "M. Shah"], "venue": "Machine Vision and Applications 24 (5) ", "citeRegEx": "237", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning multi-label scene classification", "author": ["M.R. Boutell", "J. Luo", "X. Shen", "C.M. Brown"], "venue": "Pattern recognition 37 (9) ", "citeRegEx": "238", "shortCiteRegEx": null, "year": 2004}, {"title": "Relative attributes", "author": ["D. Parikh", "K. Grauman"], "venue": "in: IEEE International Conference on Computer Vision (ICCV)", "citeRegEx": "239", "shortCiteRegEx": null, "year": 2011}, {"title": "A fuzzy qualitative approach for scene classification", "author": ["C.H. Lim", "C.S. Chan"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "240", "shortCiteRegEx": null, "year": 2012}, {"title": "Activity forecasting", "author": ["K.M. Kitani", "B.D. Ziebart", "J.A. Bagnell", "M. Hebert"], "venue": "in: European Conference on Computer Vision (ECCV), Springer", "citeRegEx": "241", "shortCiteRegEx": null, "year": 2012}, {"title": "Human activity prediction: Early recognition of ongoing activities from streaming videos", "author": ["M. Ryoo"], "venue": "in: IEEE International Conference on Computer Vision (ICCV)", "citeRegEx": "242", "shortCiteRegEx": null, "year": 2011}, {"title": "F", "author": ["M. Hoai"], "venue": "De la Torre, Max-margin early event detectors, in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "243", "shortCiteRegEx": null, "year": 2012}, {"title": "Observing human-object interactions: Using spatial and functional compatibility for recognition", "author": ["A. Gupta", "A. Kembhavi", "L.S. Davis"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 31 (10) ", "citeRegEx": "244", "shortCiteRegEx": null, "year": 2009}, {"title": "Grouplet: A structured image representation for recognizing human and object interactions", "author": ["B. Yao", "L. Fei-Fei"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "245", "shortCiteRegEx": null, "year": 2010}, {"title": "Discriminative models for static human-object interactions", "author": ["C. Desai", "D. Ramanan", "C. Fowlkes"], "venue": "in: IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)", "citeRegEx": "246", "shortCiteRegEx": null, "year": 2010}, {"title": "Recognizing human actions from still images with latent poses", "author": ["W. Yang", "Y. Wang", "G. Mori"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "247", "shortCiteRegEx": null, "year": 2010}, {"title": "Recognizing human actions in still images: a study of bag-of-features and part-based representations", "author": ["V. Delaitre", "I. Laptev", "J. Sivic"], "venue": "in: Proceedings of the British Machine Vision Conference (BMVC)", "citeRegEx": "248", "shortCiteRegEx": null, "year": 2010}, {"title": "Action recognition from a distributed representation of pose and appearance", "author": ["S. Maji", "L. Bourdev", "J. Malik"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "249", "shortCiteRegEx": null, "year": 2011}, {"title": "Weakly supervised learning of interactions between humans and objects", "author": ["A. Prest", "C. Schmid", "V. Ferrari"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 34 (3) ", "citeRegEx": "250", "shortCiteRegEx": null, "year": 2012}, {"title": "Recognizing human-object interactions in still images by modeling the mutual context of objects and human poses", "author": ["B. Yao", "L. Fei-Fei"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 34 (9) ", "citeRegEx": "251", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "For decades, it has been a popular research topic that crossovers many domains such as biology [1, 2], psychology [3, 4], multimedia [5] and so on.", "startOffset": 95, "endOffset": 101}, {"referenceID": 1, "context": "For decades, it has been a popular research topic that crossovers many domains such as biology [1, 2], psychology [3, 4], multimedia [5] and so on.", "startOffset": 95, "endOffset": 101}, {"referenceID": 2, "context": "For decades, it has been a popular research topic that crossovers many domains such as biology [1, 2], psychology [3, 4], multimedia [5] and so on.", "startOffset": 114, "endOffset": 120}, {"referenceID": 3, "context": "For decades, it has been a popular research topic that crossovers many domains such as biology [1, 2], psychology [3, 4], multimedia [5] and so on.", "startOffset": 114, "endOffset": 120}, {"referenceID": 4, "context": "For decades, it has been a popular research topic that crossovers many domains such as biology [1, 2], psychology [3, 4], multimedia [5] and so on.", "startOffset": 133, "endOffset": 136}, {"referenceID": 5, "context": "Amongst all, video surveillance is one of the most important real-time applications [6, 7, 8, 9, 10].", "startOffset": 84, "endOffset": 100}, {"referenceID": 6, "context": "Amongst all, video surveillance is one of the most important real-time applications [6, 7, 8, 9, 10].", "startOffset": 84, "endOffset": 100}, {"referenceID": 7, "context": "Amongst all, video surveillance is one of the most important real-time applications [6, 7, 8, 9, 10].", "startOffset": 84, "endOffset": 100}, {"referenceID": 8, "context": "Amongst all, video surveillance is one of the most important real-time applications [6, 7, 8, 9, 10].", "startOffset": 84, "endOffset": 100}, {"referenceID": 9, "context": "Amongst all, video surveillance is one of the most important real-time applications [6, 7, 8, 9, 10].", "startOffset": 84, "endOffset": 100}, {"referenceID": 10, "context": "Apart from that, HMA also contributed in video retrieval [11], sports analysis [12, 13, 14], healthcare monitoring [15, 16], human-computer interaction [17] and so on.", "startOffset": 57, "endOffset": 61}, {"referenceID": 11, "context": "Apart from that, HMA also contributed in video retrieval [11], sports analysis [12, 13, 14], healthcare monitoring [15, 16], human-computer interaction [17] and so on.", "startOffset": 79, "endOffset": 91}, {"referenceID": 12, "context": "Apart from that, HMA also contributed in video retrieval [11], sports analysis [12, 13, 14], healthcare monitoring [15, 16], human-computer interaction [17] and so on.", "startOffset": 79, "endOffset": 91}, {"referenceID": 13, "context": "Apart from that, HMA also contributed in video retrieval [11], sports analysis [12, 13, 14], healthcare monitoring [15, 16], human-computer interaction [17] and so on.", "startOffset": 79, "endOffset": 91}, {"referenceID": 14, "context": "Apart from that, HMA also contributed in video retrieval [11], sports analysis [12, 13, 14], healthcare monitoring [15, 16], human-computer interaction [17] and so on.", "startOffset": 115, "endOffset": 123}, {"referenceID": 15, "context": "Apart from that, HMA also contributed in video retrieval [11], sports analysis [12, 13, 14], healthcare monitoring [15, 16], human-computer interaction [17] and so on.", "startOffset": 115, "endOffset": 123}, {"referenceID": 16, "context": "Apart from that, HMA also contributed in video retrieval [11], sports analysis [12, 13, 14], healthcare monitoring [15, 16], human-computer interaction [17] and so on.", "startOffset": 152, "endOffset": 156}, {"referenceID": 17, "context": "One of the earliest surveys was [18], focused on various methods employed in the analysis of the human body motion, which is in non-rigid form.", "startOffset": 32, "endOffset": 36}, {"referenceID": 18, "context": "[19] gave an overview on the motion extraction methods using the motion capture systems and focused on action recognition, individual body parts recognition, and body configuration estimation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] used the same taxonomy as in [19], but engaging different labels for the three classes, that is further dividing the classes into subclasses yielding a more comprehensive taxonomy.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[20] used the same taxonomy as in [19], but engaging different labels for the three classes, that is further dividing the classes into subclasses yielding a more comprehensive taxonomy.", "startOffset": 34, "endOffset": 38}, {"referenceID": 20, "context": "[21] gave an overview on the applications of visual analysis of human movements, and their taxonomy covered the 2D and 3D approaches with and without the explicit shape models.", "startOffset": 0, "endOffset": 4}, {"referenceID": 37, "context": "The KTH [38] and the Weizmann [39, 40] datasets were the most popular human actions", "startOffset": 8, "endOffset": 12}, {"referenceID": 38, "context": "The KTH [38] and the Weizmann [39, 40] datasets were the most popular human actions", "startOffset": 30, "endOffset": 38}, {"referenceID": 39, "context": "The KTH [38] and the Weizmann [39, 40] datasets were the most popular human actions", "startOffset": 30, "endOffset": 38}, {"referenceID": 17, "context": "[18] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19] C.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[21] D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[22] Alex Pentland Looking at people: sensing for ubiquitous and wearable computing Reviewed the state-of-the-art of \"looking at people\" focusing on person identification and surveillance monitoring.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[23] T.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] H.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "[7] W.", "startOffset": 0, "endOffset": 3}, {"referenceID": 24, "context": "[25] T.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[26] R.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[27] P.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[28] X.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[29] R.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[30] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[31] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "[32] D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "[33] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "[34] O.", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "[35] L.", "startOffset": 0, "endOffset": 4}, {"referenceID": 35, "context": "[36] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 36, "context": "[37] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "1994 [18] X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 18, "context": "1995 [19] X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 19, "context": "1997 [20] X X X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 20, "context": "1999 [21] X X X X X X", "startOffset": 5, "endOffset": 9}, {"referenceID": 21, "context": "2000 [22] X X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 22, "context": "2001 [23] X X X X X", "startOffset": 5, "endOffset": 9}, {"referenceID": 23, "context": "2003 [24] X X X X X", "startOffset": 5, "endOffset": 9}, {"referenceID": 6, "context": "2004 [7] X X X X X", "startOffset": 5, "endOffset": 8}, {"referenceID": 24, "context": "2006 [25] X X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 25, "context": "2007 [26] X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 26, "context": "2008 [27] X X X X", "startOffset": 5, "endOffset": 9}, {"referenceID": 27, "context": "2010 [28] X X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 28, "context": "2010 [29] X X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 29, "context": "2010 [30] X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 30, "context": "2011 [31] X X X X", "startOffset": 5, "endOffset": 9}, {"referenceID": 31, "context": "2011 [32] X X X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 32, "context": "2011 [33] X X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 33, "context": "2013 [34] X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 34, "context": "2013 [35] X X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 35, "context": "2013 [36] X X X X", "startOffset": 5, "endOffset": 9}, {"referenceID": 36, "context": "2013 [37] X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 36, "context": "Please refer to [37] for a complete list of the currently available datasets in HMA.", "startOffset": 16, "endOffset": 20}, {"referenceID": 6, "context": "[7, 20, 21, 24, 25, 28, 29, 32, 33] moved ahead to survey on the representation and recognition of the human actions in multiple-views aspect.", "startOffset": 0, "endOffset": 35}, {"referenceID": 19, "context": "[7, 20, 21, 24, 25, 28, 29, 32, 33] moved ahead to survey on the representation and recognition of the human actions in multiple-views aspect.", "startOffset": 0, "endOffset": 35}, {"referenceID": 20, "context": "[7, 20, 21, 24, 25, 28, 29, 32, 33] moved ahead to survey on the representation and recognition of the human actions in multiple-views aspect.", "startOffset": 0, "endOffset": 35}, {"referenceID": 23, "context": "[7, 20, 21, 24, 25, 28, 29, 32, 33] moved ahead to survey on the representation and recognition of the human actions in multiple-views aspect.", "startOffset": 0, "endOffset": 35}, {"referenceID": 24, "context": "[7, 20, 21, 24, 25, 28, 29, 32, 33] moved ahead to survey on the representation and recognition of the human actions in multiple-views aspect.", "startOffset": 0, "endOffset": 35}, {"referenceID": 27, "context": "[7, 20, 21, 24, 25, 28, 29, 32, 33] moved ahead to survey on the representation and recognition of the human actions in multiple-views aspect.", "startOffset": 0, "endOffset": 35}, {"referenceID": 28, "context": "[7, 20, 21, 24, 25, 28, 29, 32, 33] moved ahead to survey on the representation and recognition of the human actions in multiple-views aspect.", "startOffset": 0, "endOffset": 35}, {"referenceID": 31, "context": "[7, 20, 21, 24, 25, 28, 29, 32, 33] moved ahead to survey on the representation and recognition of the human actions in multiple-views aspect.", "startOffset": 0, "endOffset": 35}, {"referenceID": 32, "context": "[7, 20, 21, 24, 25, 28, 29, 32, 33] moved ahead to survey on the representation and recognition of the human actions in multiple-views aspect.", "startOffset": 0, "endOffset": 35}, {"referenceID": 6, "context": "Last but not the least, [7, 21, 23, 24, 27, 31, 36] surveyed on the various applications of HMA such as the smart surveillance and advanced user interface for human-computer interaction.", "startOffset": 24, "endOffset": 51}, {"referenceID": 20, "context": "Last but not the least, [7, 21, 23, 24, 27, 31, 36] surveyed on the various applications of HMA such as the smart surveillance and advanced user interface for human-computer interaction.", "startOffset": 24, "endOffset": 51}, {"referenceID": 22, "context": "Last but not the least, [7, 21, 23, 24, 27, 31, 36] surveyed on the various applications of HMA such as the smart surveillance and advanced user interface for human-computer interaction.", "startOffset": 24, "endOffset": 51}, {"referenceID": 23, "context": "Last but not the least, [7, 21, 23, 24, 27, 31, 36] surveyed on the various applications of HMA such as the smart surveillance and advanced user interface for human-computer interaction.", "startOffset": 24, "endOffset": 51}, {"referenceID": 26, "context": "Last but not the least, [7, 21, 23, 24, 27, 31, 36] surveyed on the various applications of HMA such as the smart surveillance and advanced user interface for human-computer interaction.", "startOffset": 24, "endOffset": 51}, {"referenceID": 30, "context": "Last but not the least, [7, 21, 23, 24, 27, 31, 36] surveyed on the various applications of HMA such as the smart surveillance and advanced user interface for human-computer interaction.", "startOffset": 24, "endOffset": 51}, {"referenceID": 35, "context": "Last but not the least, [7, 21, 23, 24, 27, 31, 36] surveyed on the various applications of HMA such as the smart surveillance and advanced user interface for human-computer interaction.", "startOffset": 24, "endOffset": 51}, {"referenceID": 40, "context": "The nearest studies to ours are [41, 42, 43].", "startOffset": 32, "endOffset": 44}, {"referenceID": 41, "context": "The nearest studies to ours are [41, 42, 43].", "startOffset": 32, "endOffset": 44}, {"referenceID": 42, "context": "The nearest studies to ours are [41, 42, 43].", "startOffset": 32, "endOffset": 44}, {"referenceID": 40, "context": "[41] was the earliest survey that discussed the uncertainties in computer vision using the fuzzy sets.", "startOffset": 0, "endOffset": 4}, {"referenceID": 41, "context": "Later, [42] gave a broad overview of the fuzzy set theory towards computer vision with applications in the areas of image modeling, preprocessing, segmentation, boundary detection, object/region recognition, and rule-based scene interpretation.", "startOffset": 7, "endOffset": 11}, {"referenceID": 42, "context": "Finally, [43] addressed various aspects of image processing and analysis problems where the theory of fuzzy set was applied.", "startOffset": 9, "endOffset": 13}, {"referenceID": 43, "context": "This is due to the usefulness of its output that is capable of preserving the shape information, as well as helps in extracting motion and contour information [44, 45, 46].", "startOffset": 159, "endOffset": 171}, {"referenceID": 44, "context": "This is due to the usefulness of its output that is capable of preserving the shape information, as well as helps in extracting motion and contour information [44, 45, 46].", "startOffset": 159, "endOffset": 171}, {"referenceID": 45, "context": "This is due to the usefulness of its output that is capable of preserving the shape information, as well as helps in extracting motion and contour information [44, 45, 46].", "startOffset": 159, "endOffset": 171}, {"referenceID": 46, "context": "However the basic mathematical operators used for aggregation such as the minimum, maximum, average, median, \u2018AND\u2019, and \u2018OR\u2019 operators provide crisp decisions and utilize only a single feature that tends to result in false positive [47].", "startOffset": 232, "endOffset": 236}, {"referenceID": 47, "context": "In contrast, the fuzzy integrals take into account the importance of the coalition of any subset of the criteria [48].", "startOffset": 113, "endOffset": 117}, {"referenceID": 47, "context": "Figure 3: Comparison between the Sugeno and the Choquet fuzzy integral methods for background subtraction [48].", "startOffset": 106, "endOffset": 110}, {"referenceID": 48, "context": "In general, the fuzzy integral is a non-linear function that is defined with respect to the fuzzy measure such as a belief or a plausibility measure [49], and is employed in the aggregation step.", "startOffset": 149, "endOffset": 153}, {"referenceID": 46, "context": "[47] proposed to use the Sugeno integral [50] to fuse color and texture features in their works for better classification of the pixel that", "startOffset": 0, "endOffset": 4}, {"referenceID": 49, "context": "[47] proposed to use the Sugeno integral [50] to fuse color and texture features in their works for better classification of the pixel that", "startOffset": 41, "endOffset": 45}, {"referenceID": 47, "context": "belongs to either background or foreground, while [48, 51, 52] improved [47] by replacing the Sugeno integral with the Choquet integral [53].", "startOffset": 50, "endOffset": 62}, {"referenceID": 50, "context": "belongs to either background or foreground, while [48, 51, 52] improved [47] by replacing the Sugeno integral with the Choquet integral [53].", "startOffset": 50, "endOffset": 62}, {"referenceID": 51, "context": "belongs to either background or foreground, while [48, 51, 52] improved [47] by replacing the Sugeno integral with the Choquet integral [53].", "startOffset": 50, "endOffset": 62}, {"referenceID": 46, "context": "belongs to either background or foreground, while [48, 51, 52] improved [47] by replacing the Sugeno integral with the Choquet integral [53].", "startOffset": 72, "endOffset": 76}, {"referenceID": 52, "context": "belongs to either background or foreground, while [48, 51, 52] improved [47] by replacing the Sugeno integral with the Choquet integral [53].", "startOffset": 136, "endOffset": 140}, {"referenceID": 53, "context": "The main reason is that the Choquet integral which was adapted for cardinal aggregation, was found to be more suitable than the Sugeno integral that assumed the measurement scale to be ordinal [54, 55].", "startOffset": 193, "endOffset": 201}, {"referenceID": 54, "context": "The main reason is that the Choquet integral which was adapted for cardinal aggregation, was found to be more suitable than the Sugeno integral that assumed the measurement scale to be ordinal [54, 55].", "startOffset": 193, "endOffset": 201}, {"referenceID": 55, "context": "The studies on the background subtraction [56, 57] have shown that the Gaussian Mixture Model (GMM) is one of the popular approaches used in modeling the dynamic background scene.", "startOffset": 42, "endOffset": 50}, {"referenceID": 56, "context": "The studies on the background subtraction [56, 57] have shown that the Gaussian Mixture Model (GMM) is one of the popular approaches used in modeling the dynamic background scene.", "startOffset": 42, "endOffset": 50}, {"referenceID": 57, "context": "The thick solid and dashed lines denote the lower and upper membership functions [58].", "startOffset": 81, "endOffset": 85}, {"referenceID": 58, "context": "However, there has been an argument that type-1 fuzzy set, which is an ordinary fuzzy set [59], has limited capability in modeling the uncertainty.", "startOffset": 90, "endOffset": 94}, {"referenceID": 59, "context": "Therefore, type-2 fuzzy sets [60] emerged from the type-1 fuzzy set by generalizing it to handle more uncertainty in the underlying fuzzy membership function.", "startOffset": 29, "endOffset": 33}, {"referenceID": 57, "context": "With the capability of type-2 fuzzy set to handle higher dimensions of uncertainty, it was adopted in [58] to represent the multivariate Gaussian with an uncertain mean vector or a covariance matrix.", "startOffset": 102, "endOffset": 106}, {"referenceID": 60, "context": "Several works [61, 62, 63] have been reported that utilized the type-2 fuzzy GMM to deal with insufficient or noisy data, and resulted in better background subtraction model.", "startOffset": 14, "endOffset": 26}, {"referenceID": 61, "context": "Several works [61, 62, 63] have been reported that utilized the type-2 fuzzy GMM to deal with insufficient or noisy data, and resulted in better background subtraction model.", "startOffset": 14, "endOffset": 26}, {"referenceID": 62, "context": "Several works [61, 62, 63] have been reported that utilized the type-2 fuzzy GMM to deal with insufficient or noisy data, and resulted in better background subtraction model.", "startOffset": 14, "endOffset": 26}, {"referenceID": 63, "context": "In the later stage, [64] made an improvement on these works with the inclusion of spatial-temporal constraints into the type-2 fuzzy GMM by using the Markov Random Field.", "startOffset": 20, "endOffset": 24}, {"referenceID": 46, "context": "However, such steps require human intervention [47, 51, 48].", "startOffset": 47, "endOffset": 59}, {"referenceID": 50, "context": "However, such steps require human intervention [47, 51, 48].", "startOffset": 47, "endOffset": 59}, {"referenceID": 47, "context": "However, such steps require human intervention [47, 51, 48].", "startOffset": 47, "endOffset": 59}, {"referenceID": 64, "context": "For example, the trial and error process to determine a classification threshold value is a tedious job, computationally expensive and subjective [65].", "startOffset": 146, "endOffset": 150}, {"referenceID": 65, "context": "[66] applied neural fuzzy framework to estimate the image motion.", "startOffset": 0, "endOffset": 4}, {"referenceID": 66, "context": "Besides that, [67] introduced a spatial coherence variant incorporated with the self-organizing neural network to formulate a fuzzy model to enhance the robustness against false detection in the background subtraction algorithm.", "startOffset": 14, "endOffset": 18}, {"referenceID": 67, "context": "[68] used both the particle swarm optimization and the kernel least mean square to update the system parameters of a fuzzy model, and [69] employed a tuning process using the Marquardt-Levenberg algorithm within a fuzzy system to fine-tune the membership function.", "startOffset": 0, "endOffset": 4}, {"referenceID": 68, "context": "[68] used both the particle swarm optimization and the kernel least mean square to update the system parameters of a fuzzy model, and [69] employed a tuning process using the Marquardt-Levenberg algorithm within a fuzzy system to fine-tune the membership function.", "startOffset": 134, "endOffset": 138}, {"referenceID": 69, "context": "In order to determine the appropriate threshold value for the classification task, [70] proposed a novel fuzzy-cellular method that helps in dynamically learning the optimal threshold value.", "startOffset": 83, "endOffset": 87}, {"referenceID": 70, "context": "Figure 5: Type-1 Fuzzy Inference System [71].", "startOffset": 40, "endOffset": 44}, {"referenceID": 71, "context": "The Type-1 Fuzzy Inference System (FIS) [72] is a complete fuzzy decision making system that utilizes the fuzzy set theory.", "startOffset": 40, "endOffset": 44}, {"referenceID": 72, "context": "The fuzzification step maps the crisp input data from a set of sensors (features or attributes) to the membership functions to generate the fuzzy input sets with linguistic support [73].", "startOffset": 181, "endOffset": 185}, {"referenceID": 73, "context": "(b) The fuzzy rules for the fuzzy input for three features (Distance, \u03c1; Angle, \u0398 and Cord to Arc Ratio, \u03b6), and its corresponding fuzzy output (VL=Very low, L=Low, M=Med, H=High, VH=Very High) [74].", "startOffset": 194, "endOffset": 198}, {"referenceID": 74, "context": "In human detection, the FIS is an effective and direct approach to distinguish between the human and non-human with different features [75, 74, 76].", "startOffset": 135, "endOffset": 147}, {"referenceID": 73, "context": "In human detection, the FIS is an effective and direct approach to distinguish between the human and non-human with different features [75, 74, 76].", "startOffset": 135, "endOffset": 147}, {"referenceID": 75, "context": "In human detection, the FIS is an effective and direct approach to distinguish between the human and non-human with different features [75, 74, 76].", "startOffset": 135, "endOffset": 147}, {"referenceID": 73, "context": "As an example, [74] extracted three features from the contours of the segmented region, such as the distance to the centroid, angle, and cord to arc ratio, and input them into the FIS.", "startOffset": 15, "endOffset": 19}, {"referenceID": 76, "context": "Besides that, [77, 78] studied in depth about the problems encountered in the human classification tasks, such as the situations where the unintended objects are attached to the classified human region.", "startOffset": 14, "endOffset": 22}, {"referenceID": 77, "context": "Besides that, [77, 78] studied in depth about the problems encountered in the human classification tasks, such as the situations where the unintended objects are attached to the classified human region.", "startOffset": 14, "endOffset": 22}, {"referenceID": 43, "context": "In general, silhouette is the binary representation of the segmented regions from the background subtraction techniques, where in HMA, human silhouette has proved its sufficiency to describe the activities captured by the video [44, 45, 46].", "startOffset": 228, "endOffset": 240}, {"referenceID": 44, "context": "In general, silhouette is the binary representation of the segmented regions from the background subtraction techniques, where in HMA, human silhouette has proved its sufficiency to describe the activities captured by the video [44, 45, 46].", "startOffset": 228, "endOffset": 240}, {"referenceID": 45, "context": "In general, silhouette is the binary representation of the segmented regions from the background subtraction techniques, where in HMA, human silhouette has proved its sufficiency to describe the activities captured by the video [44, 45, 46].", "startOffset": 228, "endOffset": 240}, {"referenceID": 76, "context": "In order to solve this, [77, 78] applied the FIS to perform an adaptive silhouette extraction in the complex and dynamic environments.", "startOffset": 24, "endOffset": 32}, {"referenceID": 77, "context": "In order to solve this, [77, 78] applied the FIS to perform an adaptive silhouette extraction in the complex and dynamic environments.", "startOffset": 24, "endOffset": 32}, {"referenceID": 76, "context": "To a certain extent, the overall performance of the system from [77, 78] may be degraded due to the misclassification of the objects in the proposed type-1 FIS.", "startOffset": 64, "endOffset": 72}, {"referenceID": 77, "context": "To a certain extent, the overall performance of the system from [77, 78] may be degraded due to the misclassification of the objects in the proposed type-1 FIS.", "startOffset": 64, "endOffset": 72}, {"referenceID": 78, "context": "Taking this into account, [79] employed the interval type-2 FIS [80] which is capable of handling higher uncertainty levels present in the real world dynamic environments.", "startOffset": 26, "endOffset": 30}, {"referenceID": 79, "context": "Taking this into account, [79] employed the interval type-2 FIS [80] which is capable of handling higher uncertainty levels present in the real world dynamic environments.", "startOffset": 64, "endOffset": 68}, {"referenceID": 70, "context": "Figure 7: Type-2 Fuzzy Inference System [71].", "startOffset": 40, "endOffset": 44}, {"referenceID": 77, "context": "(b) Extracted silhouette after using type-1 FIS to detach the book from the human, but degraded as a result [78, 77].", "startOffset": 108, "endOffset": 116}, {"referenceID": 76, "context": "(b) Extracted silhouette after using type-1 FIS to detach the book from the human, but degraded as a result [78, 77].", "startOffset": 108, "endOffset": 116}, {"referenceID": 76, "context": "Using the same features as [77, 78], [79] proposed to fuzzify the input feature values into the type-2 fuzzy sets using the singleton fuzzification method [81].", "startOffset": 27, "endOffset": 35}, {"referenceID": 77, "context": "Using the same features as [77, 78], [79] proposed to fuzzify the input feature values into the type-2 fuzzy sets using the singleton fuzzification method [81].", "startOffset": 27, "endOffset": 35}, {"referenceID": 78, "context": "Using the same features as [77, 78], [79] proposed to fuzzify the input feature values into the type-2 fuzzy sets using the singleton fuzzification method [81].", "startOffset": 37, "endOffset": 41}, {"referenceID": 80, "context": "Using the same features as [77, 78], [79] proposed to fuzzify the input feature values into the type-2 fuzzy sets using the singleton fuzzification method [81].", "startOffset": 155, "endOffset": 159}, {"referenceID": 46, "context": "[47, 48, 51, 52] Information fusion from a variety of sources us-", "startOffset": 0, "endOffset": 16}, {"referenceID": 47, "context": "[47, 48, 51, 52] Information fusion from a variety of sources us-", "startOffset": 0, "endOffset": 16}, {"referenceID": 50, "context": "[47, 48, 51, 52] Information fusion from a variety of sources us-", "startOffset": 0, "endOffset": 16}, {"referenceID": 51, "context": "[47, 48, 51, 52] Information fusion from a variety of sources us-", "startOffset": 0, "endOffset": 16}, {"referenceID": 60, "context": "[61, 62, 63, 64] The uncertainty in GMM is bounded with interval mean and standard deviation instead of the", "startOffset": 0, "endOffset": 16}, {"referenceID": 61, "context": "[61, 62, 63, 64] The uncertainty in GMM is bounded with interval mean and standard deviation instead of the", "startOffset": 0, "endOffset": 16}, {"referenceID": 62, "context": "[61, 62, 63, 64] The uncertainty in GMM is bounded with interval mean and standard deviation instead of the", "startOffset": 0, "endOffset": 16}, {"referenceID": 63, "context": "[61, 62, 63, 64] The uncertainty in GMM is bounded with interval mean and standard deviation instead of the", "startOffset": 0, "endOffset": 16}, {"referenceID": 65, "context": "[66, 67, 68, 69, 70] Integration of the machine learning techniques", "startOffset": 0, "endOffset": 20}, {"referenceID": 66, "context": "[66, 67, 68, 69, 70] Integration of the machine learning techniques", "startOffset": 0, "endOffset": 20}, {"referenceID": 67, "context": "[66, 67, 68, 69, 70] Integration of the machine learning techniques", "startOffset": 0, "endOffset": 20}, {"referenceID": 68, "context": "[66, 67, 68, 69, 70] Integration of the machine learning techniques", "startOffset": 0, "endOffset": 20}, {"referenceID": 69, "context": "[66, 67, 68, 69, 70] Integration of the machine learning techniques", "startOffset": 0, "endOffset": 20}, {"referenceID": 73, "context": "[74, 75, 76, 77, 78] Type-1 FIS is able to model the uncertainty in the features data as the membership function, and per-", "startOffset": 0, "endOffset": 20}, {"referenceID": 74, "context": "[74, 75, 76, 77, 78] Type-1 FIS is able to model the uncertainty in the features data as the membership function, and per-", "startOffset": 0, "endOffset": 20}, {"referenceID": 75, "context": "[74, 75, 76, 77, 78] Type-1 FIS is able to model the uncertainty in the features data as the membership function, and per-", "startOffset": 0, "endOffset": 20}, {"referenceID": 76, "context": "[74, 75, 76, 77, 78] Type-1 FIS is able to model the uncertainty in the features data as the membership function, and per-", "startOffset": 0, "endOffset": 20}, {"referenceID": 77, "context": "[74, 75, 76, 77, 78] Type-1 FIS is able to model the uncertainty in the features data as the membership function, and per-", "startOffset": 0, "endOffset": 20}, {"referenceID": 78, "context": "[79] Type-2 fuzzy set offers the capability to support", "startOffset": 0, "endOffset": 4}, {"referenceID": 81, "context": "In the model based human motion tracking, the human body models such as the stick figures, 2D and 3D motion description models are adopted to model the complex, non-rigid structure of the human body [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 199, "endOffset": 239}, {"referenceID": 82, "context": "In the model based human motion tracking, the human body models such as the stick figures, 2D and 3D motion description models are adopted to model the complex, non-rigid structure of the human body [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 199, "endOffset": 239}, {"referenceID": 83, "context": "In the model based human motion tracking, the human body models such as the stick figures, 2D and 3D motion description models are adopted to model the complex, non-rigid structure of the human body [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 199, "endOffset": 239}, {"referenceID": 84, "context": "In the model based human motion tracking, the human body models such as the stick figures, 2D and 3D motion description models are adopted to model the complex, non-rigid structure of the human body [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 199, "endOffset": 239}, {"referenceID": 85, "context": "In the model based human motion tracking, the human body models such as the stick figures, 2D and 3D motion description models are adopted to model the complex, non-rigid structure of the human body [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 199, "endOffset": 239}, {"referenceID": 86, "context": "In the model based human motion tracking, the human body models such as the stick figures, 2D and 3D motion description models are adopted to model the complex, non-rigid structure of the human body [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 199, "endOffset": 239}, {"referenceID": 87, "context": "In the model based human motion tracking, the human body models such as the stick figures, 2D and 3D motion description models are adopted to model the complex, non-rigid structure of the human body [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 199, "endOffset": 239}, {"referenceID": 88, "context": "In the model based human motion tracking, the human body models such as the stick figures, 2D and 3D motion description models are adopted to model the complex, non-rigid structure of the human body [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 199, "endOffset": 239}, {"referenceID": 89, "context": "In the model based human motion tracking, the human body models such as the stick figures, 2D and 3D motion description models are adopted to model the complex, non-rigid structure of the human body [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 199, "endOffset": 239}, {"referenceID": 90, "context": "In the model based human motion tracking, the human body models such as the stick figures, 2D and 3D motion description models are adopted to model the complex, non-rigid structure of the human body [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 199, "endOffset": 239}, {"referenceID": 19, "context": "Readers can refer to [20, 21, 24, 92] for the detailed reviews.", "startOffset": 21, "endOffset": 37}, {"referenceID": 20, "context": "Readers can refer to [20, 21, 24, 92] for the detailed reviews.", "startOffset": 21, "endOffset": 37}, {"referenceID": 23, "context": "Readers can refer to [20, 21, 24, 92] for the detailed reviews.", "startOffset": 21, "endOffset": 37}, {"referenceID": 91, "context": "Readers can refer to [20, 21, 24, 92] for the detailed reviews.", "startOffset": 21, "endOffset": 37}, {"referenceID": 81, "context": "The stick figure model represents the human body as a combination of sticks or line segments connected by the joints [82, 83, 84, 85], while the 2D models represents the human body using 2D ribbons or blobs [83, 86, 87].", "startOffset": 117, "endOffset": 133}, {"referenceID": 82, "context": "The stick figure model represents the human body as a combination of sticks or line segments connected by the joints [82, 83, 84, 85], while the 2D models represents the human body using 2D ribbons or blobs [83, 86, 87].", "startOffset": 117, "endOffset": 133}, {"referenceID": 83, "context": "The stick figure model represents the human body as a combination of sticks or line segments connected by the joints [82, 83, 84, 85], while the 2D models represents the human body using 2D ribbons or blobs [83, 86, 87].", "startOffset": 117, "endOffset": 133}, {"referenceID": 84, "context": "The stick figure model represents the human body as a combination of sticks or line segments connected by the joints [82, 83, 84, 85], while the 2D models represents the human body using 2D ribbons or blobs [83, 86, 87].", "startOffset": 117, "endOffset": 133}, {"referenceID": 82, "context": "The stick figure model represents the human body as a combination of sticks or line segments connected by the joints [82, 83, 84, 85], while the 2D models represents the human body using 2D ribbons or blobs [83, 86, 87].", "startOffset": 207, "endOffset": 219}, {"referenceID": 85, "context": "The stick figure model represents the human body as a combination of sticks or line segments connected by the joints [82, 83, 84, 85], while the 2D models represents the human body using 2D ribbons or blobs [83, 86, 87].", "startOffset": 207, "endOffset": 219}, {"referenceID": 86, "context": "The stick figure model represents the human body as a combination of sticks or line segments connected by the joints [82, 83, 84, 85], while the 2D models represents the human body using 2D ribbons or blobs [83, 86, 87].", "startOffset": 207, "endOffset": 219}, {"referenceID": 87, "context": "[88, 89, 90, 91].", "startOffset": 0, "endOffset": 16}, {"referenceID": 88, "context": "[88, 89, 90, 91].", "startOffset": 0, "endOffset": 16}, {"referenceID": 89, "context": "[88, 89, 90, 91].", "startOffset": 0, "endOffset": 16}, {"referenceID": 90, "context": "[88, 89, 90, 91].", "startOffset": 0, "endOffset": 16}, {"referenceID": 92, "context": "3D models are able to handle such scenarios, but there are other factors that can affect the tracking performance such as the monotone clothes, cluttered background and changing brightness [93].", "startOffset": 189, "endOffset": 193}, {"referenceID": 81, "context": "A variety of works in the model based human motion tracking have employed the kinematic chain [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 94, "endOffset": 134}, {"referenceID": 82, "context": "A variety of works in the model based human motion tracking have employed the kinematic chain [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 94, "endOffset": 134}, {"referenceID": 83, "context": "A variety of works in the model based human motion tracking have employed the kinematic chain [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 94, "endOffset": 134}, {"referenceID": 84, "context": "A variety of works in the model based human motion tracking have employed the kinematic chain [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 94, "endOffset": 134}, {"referenceID": 85, "context": "A variety of works in the model based human motion tracking have employed the kinematic chain [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 94, "endOffset": 134}, {"referenceID": 86, "context": "A variety of works in the model based human motion tracking have employed the kinematic chain [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 94, "endOffset": 134}, {"referenceID": 87, "context": "A variety of works in the model based human motion tracking have employed the kinematic chain [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 94, "endOffset": 134}, {"referenceID": 88, "context": "A variety of works in the model based human motion tracking have employed the kinematic chain [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 94, "endOffset": 134}, {"referenceID": 89, "context": "A variety of works in the model based human motion tracking have employed the kinematic chain [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 94, "endOffset": 134}, {"referenceID": 90, "context": "A variety of works in the model based human motion tracking have employed the kinematic chain [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 94, "endOffset": 134}, {"referenceID": 93, "context": "[94] demonstrated a comprehensive visual motion estimation technique using the kinematic chain in a complex video sequence, as depicted in Figure 9.", "startOffset": 0, "endOffset": 4}, {"referenceID": 94, "context": "It suffers from the precision problem [95] and the cumulative errors can directly affect the performance of the higher level tasks.", "startOffset": 38, "endOffset": 42}, {"referenceID": 96, "context": "To begin with, the fuzzy qualitative reasoning [97, 98] is a form of approximate reasoning that can be defined as the fusion between the fuzzy set theory [59] and the qualitative reasoning [99].", "startOffset": 47, "endOffset": 55}, {"referenceID": 97, "context": "To begin with, the fuzzy qualitative reasoning [97, 98] is a form of approximate reasoning that can be defined as the fusion between the fuzzy set theory [59] and the qualitative reasoning [99].", "startOffset": 47, "endOffset": 55}, {"referenceID": 58, "context": "To begin with, the fuzzy qualitative reasoning [97, 98] is a form of approximate reasoning that can be defined as the fusion between the fuzzy set theory [59] and the qualitative reasoning [99].", "startOffset": 154, "endOffset": 158}, {"referenceID": 98, "context": "To begin with, the fuzzy qualitative reasoning [97, 98] is a form of approximate reasoning that can be defined as the fusion between the fuzzy set theory [59] and the qualitative reasoning [99].", "startOffset": 189, "endOffset": 193}, {"referenceID": 93, "context": "Figure 9: (a) Kinematic chain defined by twist [94], and (b) The estimated kinematic chain on the human body while performing the walking action.", "startOffset": 47, "endOffset": 51}, {"referenceID": 95, "context": "(b) Element of the fuzzy quantity space for every variable (translation (X, Y), and orientation \u03b8) in the fuzzy qualitative unit circle is a finite and convex discretization of the real number line [96].", "startOffset": 198, "endOffset": 202}, {"referenceID": 99, "context": "For instance, [100] applied this in the Fuzzy Qualitative Trigonometry (Figure 10) where the ordinary Cartesian space and the unit circle are substituted with the combination of membership functions yielding the fuzzy qualitative coordinate and the fuzzy qualitative unit circle.", "startOffset": 14, "endOffset": 19}, {"referenceID": 94, "context": "Extension from this, a fuzzy qualitative representation of the robot kinematics [95, 101] was proposed.", "startOffset": 80, "endOffset": 89}, {"referenceID": 100, "context": "Extension from this, a fuzzy qualitative representation of the robot kinematics [95, 101] was proposed.", "startOffset": 80, "endOffset": 89}, {"referenceID": 99, "context": "The work presented a derivative extension to the Fuzzy Qualitative Trigonometry [100].", "startOffset": 80, "endOffset": 85}, {"referenceID": 101, "context": "Motivated by these approaches, [102] proposed a data quantization process based on the Fuzzy Qualitative Trigonometry to model the uncertainties during the kinematic chain tracking process; and subsequently constructed a generic activity representation model.", "startOffset": 31, "endOffset": 36}, {"referenceID": 102, "context": "Therefore, the fuzzy voxel person representation was proposed [103].", "startOffset": 62, "endOffset": 67}, {"referenceID": 15, "context": "Inspired by this, [16, 104] demonstrated a method to construct a 3D human model in voxel (volume element) space using the human silhouette images called the voxel person (Figure 11).", "startOffset": 18, "endOffset": 27}, {"referenceID": 103, "context": "Inspired by this, [16, 104] demonstrated a method to construct a 3D human model in voxel (volume element) space using the human silhouette images called the voxel person (Figure 11).", "startOffset": 18, "endOffset": 27}, {"referenceID": 102, "context": "Therefore, fuzzy voxel person was utilized in [103] by employing only a few cameras and a minimal prior knowledge about the object.", "startOffset": 46, "endOffset": 51}, {"referenceID": 102, "context": "Extreme body joints viewing conditions were taken into account and it was observed that the fuzzy acquired results were much better than the crisp approach, both qualitatively (as shown in Figure 12) as well as quantitatively [103].", "startOffset": 226, "endOffset": 231}, {"referenceID": 15, "context": "This concept of the fuzzy voxel person was incorporated in a number of works [16, 104].", "startOffset": 77, "endOffset": 86}, {"referenceID": 103, "context": "This concept of the fuzzy voxel person was incorporated in a number of works [16, 104].", "startOffset": 77, "endOffset": 86}, {"referenceID": 104, "context": "In order to solve this, [105, 106] applied FIS to update both the trajectories and the shape estimated for the targets with a set of image regions.", "startOffset": 24, "endOffset": 34}, {"referenceID": 105, "context": "In order to solve this, [105, 106] applied FIS to update both the trajectories and the shape estimated for the targets with a set of image regions.", "startOffset": 24, "endOffset": 34}, {"referenceID": 102, "context": "Red areas are the improved voxel person and the blue areas are the rest of the original crisp voxel person [103].", "startOffset": 107, "endOffset": 112}, {"referenceID": 106, "context": "Kalman filter, the popular optimal estimator capable of operating recursively on the streams of noisy input data [107], is a popular choice for tracking a moving object.", "startOffset": 113, "endOffset": 118}, {"referenceID": 90, "context": "It has been successfully applied in several previous works on the human motion tracking [91, 108, 109, 110, 111, 112].", "startOffset": 88, "endOffset": 117}, {"referenceID": 107, "context": "It has been successfully applied in several previous works on the human motion tracking [91, 108, 109, 110, 111, 112].", "startOffset": 88, "endOffset": 117}, {"referenceID": 108, "context": "It has been successfully applied in several previous works on the human motion tracking [91, 108, 109, 110, 111, 112].", "startOffset": 88, "endOffset": 117}, {"referenceID": 109, "context": "It has been successfully applied in several previous works on the human motion tracking [91, 108, 109, 110, 111, 112].", "startOffset": 88, "endOffset": 117}, {"referenceID": 110, "context": "It has been successfully applied in several previous works on the human motion tracking [91, 108, 109, 110, 111, 112].", "startOffset": 88, "endOffset": 117}, {"referenceID": 111, "context": "It has been successfully applied in several previous works on the human motion tracking [91, 108, 109, 110, 111, 112].", "startOffset": 88, "endOffset": 117}, {"referenceID": 112, "context": "There are three basic steps involved in the Kalman filtering for human motion tracking: initialization, prediction and correction [113].", "startOffset": 130, "endOffset": 135}, {"referenceID": 113, "context": "In order to solve this, the FIS was adopted in the Kalman filtering [114, 115, 116, 117, 118, 119] to detect the bias of measurements and prevent the divergence.", "startOffset": 68, "endOffset": 98}, {"referenceID": 114, "context": "In order to solve this, the FIS was adopted in the Kalman filtering [114, 115, 116, 117, 118, 119] to detect the bias of measurements and prevent the divergence.", "startOffset": 68, "endOffset": 98}, {"referenceID": 115, "context": "In order to solve this, the FIS was adopted in the Kalman filtering [114, 115, 116, 117, 118, 119] to detect the bias of measurements and prevent the divergence.", "startOffset": 68, "endOffset": 98}, {"referenceID": 116, "context": "In order to solve this, the FIS was adopted in the Kalman filtering [114, 115, 116, 117, 118, 119] to detect the bias of measurements and prevent the divergence.", "startOffset": 68, "endOffset": 98}, {"referenceID": 117, "context": "In order to solve this, the FIS was adopted in the Kalman filtering [114, 115, 116, 117, 118, 119] to detect the bias of measurements and prevent the divergence.", "startOffset": 68, "endOffset": 98}, {"referenceID": 118, "context": "In order to solve this, the FIS was adopted in the Kalman filtering [114, 115, 116, 117, 118, 119] to detect the bias of measurements and prevent the divergence.", "startOffset": 68, "endOffset": 98}, {"referenceID": 119, "context": "To this extent, [120] proposed the evolving Takagi-Sugeno fuzzy model [121, 122] which can be seen as the fuzzy weighted mixture of the Kalman filter for object tracking in the video streams, and the performance is better than the ordinary Kalman Filter.", "startOffset": 16, "endOffset": 21}, {"referenceID": 120, "context": "To this extent, [120] proposed the evolving Takagi-Sugeno fuzzy model [121, 122] which can be seen as the fuzzy weighted mixture of the Kalman filter for object tracking in the video streams, and the performance is better than the ordinary Kalman Filter.", "startOffset": 70, "endOffset": 80}, {"referenceID": 121, "context": "To this extent, [120] proposed the evolving Takagi-Sugeno fuzzy model [121, 122] which can be seen as the fuzzy weighted mixture of the Kalman filter for object tracking in the video streams, and the performance is better than the ordinary Kalman Filter.", "startOffset": 70, "endOffset": 80}, {"referenceID": 122, "context": "As a remedy to the above mentioned problems, a new sequential fuzzy simulation based particle filter was proposed in [123] to estimate the state of a dynamic system with noises described as fuzzy variables using the possibility theory.", "startOffset": 117, "endOffset": 122}, {"referenceID": 122, "context": "[123] found that their proposed fuzzy logic based particle filter outperforms the traditional particle filter even when the number of particles is small.", "startOffset": 0, "endOffset": 5}, {"referenceID": 123, "context": "Another variant of this work is [124], where an adaptive model is implemented in the fuzzy particle filter with the capability to adjust the number of particles by using the result from the measurement step, and improve the speed of an object tracking algorithm.", "startOffset": 32, "endOffset": 37}, {"referenceID": 95, "context": "Apart from that, [96, 102] handled the tradeoff between the system precision and the computational cost by employing data quantization process that utilizes the Fuzzy Quantity Space [100].", "startOffset": 17, "endOffset": 26}, {"referenceID": 101, "context": "Apart from that, [96, 102] handled the tradeoff between the system precision and the computational cost by employing data quantization process that utilizes the Fuzzy Quantity Space [100].", "startOffset": 17, "endOffset": 26}, {"referenceID": 99, "context": "Apart from that, [96, 102] handled the tradeoff between the system precision and the computational cost by employing data quantization process that utilizes the Fuzzy Quantity Space [100].", "startOffset": 182, "endOffset": 187}, {"referenceID": 124, "context": "Last but not the least, the FIS has also contributed in the particle filters [125, 126] and achieved better accuracy with lower computational cost.", "startOffset": 77, "endOffset": 87}, {"referenceID": 125, "context": "Last but not the least, the FIS has also contributed in the particle filters [125, 126] and achieved better accuracy with lower computational cost.", "startOffset": 77, "endOffset": 87}, {"referenceID": 126, "context": "Optical flow [127, 128] is another popular motion tracking algorithm.", "startOffset": 13, "endOffset": 23}, {"referenceID": 127, "context": "Optical flow [127, 128] is another popular motion tracking algorithm.", "startOffset": 13, "endOffset": 23}, {"referenceID": 128, "context": "Fuzzy hostility index was introduced in [129, 130] to overcome this issue and thus improving the time efficiency of the flow computation.", "startOffset": 40, "endOffset": 50}, {"referenceID": 129, "context": "Fuzzy hostility index was introduced in [129, 130] to overcome this issue and thus improving the time efficiency of the flow computation.", "startOffset": 40, "endOffset": 50}, {"referenceID": 130, "context": "The fuzzy hostility index [131] measures the amount of homogeneity or heterogeneity of the neighborhood pixel in the optical flow field.", "startOffset": 26, "endOffset": 31}, {"referenceID": 132, "context": "Inspired from this, multi-object cluster trackings [133, 134] were introduced with the belief that the moving targets always produce a particular cluster of pixels with similar characteristics in the feature space, and the distribution of these clusters changes only little between the consecutive frames.", "startOffset": 51, "endOffset": 61}, {"referenceID": 133, "context": "Inspired from this, multi-object cluster trackings [133, 134] were introduced with the belief that the moving targets always produce a particular cluster of pixels with similar characteristics in the feature space, and the distribution of these clusters changes only little between the consecutive frames.", "startOffset": 51, "endOffset": 61}, {"referenceID": 131, "context": "[132] proposed a fast fuzzy c-means (FCM) clustering tracking method which offers a solution towards the high complexity and the computational cost involved in the conventional methods on multi-object tracking, and also the hard clustering algorithms such as the k-means that causes failure in the case of severe occlusions and pervasive disturbances.", "startOffset": 0, "endOffset": 5}, {"referenceID": 131, "context": "In [132], the component quantization filtering was incorporated with FCM to provide faster processing speed.", "startOffset": 3, "endOffset": 8}, {"referenceID": 94, "context": "[95, 96, 100, 101, 102] Integration of the fuzzy set theory and the fuzzy qualitative reasoning in the kinematic chain representation provides a means of handling the uncertainty in a natural way.", "startOffset": 0, "endOffset": 23}, {"referenceID": 95, "context": "[95, 96, 100, 101, 102] Integration of the fuzzy set theory and the fuzzy qualitative reasoning in the kinematic chain representation provides a means of handling the uncertainty in a natural way.", "startOffset": 0, "endOffset": 23}, {"referenceID": 99, "context": "[95, 96, 100, 101, 102] Integration of the fuzzy set theory and the fuzzy qualitative reasoning in the kinematic chain representation provides a means of handling the uncertainty in a natural way.", "startOffset": 0, "endOffset": 23}, {"referenceID": 100, "context": "[95, 96, 100, 101, 102] Integration of the fuzzy set theory and the fuzzy qualitative reasoning in the kinematic chain representation provides a means of handling the uncertainty in a natural way.", "startOffset": 0, "endOffset": 23}, {"referenceID": 101, "context": "[95, 96, 100, 101, 102] Integration of the fuzzy set theory and the fuzzy qualitative reasoning in the kinematic chain representation provides a means of handling the uncertainty in a natural way.", "startOffset": 0, "endOffset": 23}, {"referenceID": 15, "context": "[16, 103, 104] Fuzzy voxel person is able to model different types of uncertainties associated with the construction of the voxel person by using the membership functions, employing only a few cameras and a minimal prior knowledge about the object.", "startOffset": 0, "endOffset": 14}, {"referenceID": 102, "context": "[16, 103, 104] Fuzzy voxel person is able to model different types of uncertainties associated with the construction of the voxel person by using the membership functions, employing only a few cameras and a minimal prior knowledge about the object.", "startOffset": 0, "endOffset": 14}, {"referenceID": 103, "context": "[16, 103, 104] Fuzzy voxel person is able to model different types of uncertainties associated with the construction of the voxel person by using the membership functions, employing only a few cameras and a minimal prior knowledge about the object.", "startOffset": 0, "endOffset": 14}, {"referenceID": 104, "context": "[105, 106] FIS is applied to perform the fuzzy shape estimation to achieve a better tracking performance by taking into account the uncertainty in shape estimation.", "startOffset": 0, "endOffset": 10}, {"referenceID": 105, "context": "[105, 106] FIS is applied to perform the fuzzy shape estimation to achieve a better tracking performance by taking into account the uncertainty in shape estimation.", "startOffset": 0, "endOffset": 10}, {"referenceID": 6, "context": "[7, 8, 9, 20, 21, 114, 115] Fuzzy Kalman filters are capable of solving the divergence problem by incorporating the FIS, and are more robust against the streams of random noisy data inputs.", "startOffset": 0, "endOffset": 27}, {"referenceID": 7, "context": "[7, 8, 9, 20, 21, 114, 115] Fuzzy Kalman filters are capable of solving the divergence problem by incorporating the FIS, and are more robust against the streams of random noisy data inputs.", "startOffset": 0, "endOffset": 27}, {"referenceID": 8, "context": "[7, 8, 9, 20, 21, 114, 115] Fuzzy Kalman filters are capable of solving the divergence problem by incorporating the FIS, and are more robust against the streams of random noisy data inputs.", "startOffset": 0, "endOffset": 27}, {"referenceID": 19, "context": "[7, 8, 9, 20, 21, 114, 115] Fuzzy Kalman filters are capable of solving the divergence problem by incorporating the FIS, and are more robust against the streams of random noisy data inputs.", "startOffset": 0, "endOffset": 27}, {"referenceID": 20, "context": "[7, 8, 9, 20, 21, 114, 115] Fuzzy Kalman filters are capable of solving the divergence problem by incorporating the FIS, and are more robust against the streams of random noisy data inputs.", "startOffset": 0, "endOffset": 27}, {"referenceID": 113, "context": "[7, 8, 9, 20, 21, 114, 115] Fuzzy Kalman filters are capable of solving the divergence problem by incorporating the FIS, and are more robust against the streams of random noisy data inputs.", "startOffset": 0, "endOffset": 27}, {"referenceID": 114, "context": "[7, 8, 9, 20, 21, 114, 115] Fuzzy Kalman filters are capable of solving the divergence problem by incorporating the FIS, and are more robust against the streams of random noisy data inputs.", "startOffset": 0, "endOffset": 27}, {"referenceID": 95, "context": "[96, 102, 123, 124, 125, 126] The fuzzy particle filter effectively handles the system complexity by compromising the low number of particles that were used while retaining the tracking performance.", "startOffset": 0, "endOffset": 29}, {"referenceID": 101, "context": "[96, 102, 123, 124, 125, 126] The fuzzy particle filter effectively handles the system complexity by compromising the low number of particles that were used while retaining the tracking performance.", "startOffset": 0, "endOffset": 29}, {"referenceID": 122, "context": "[96, 102, 123, 124, 125, 126] The fuzzy particle filter effectively handles the system complexity by compromising the low number of particles that were used while retaining the tracking performance.", "startOffset": 0, "endOffset": 29}, {"referenceID": 123, "context": "[96, 102, 123, 124, 125, 126] The fuzzy particle filter effectively handles the system complexity by compromising the low number of particles that were used while retaining the tracking performance.", "startOffset": 0, "endOffset": 29}, {"referenceID": 124, "context": "[96, 102, 123, 124, 125, 126] The fuzzy particle filter effectively handles the system complexity by compromising the low number of particles that were used while retaining the tracking performance.", "startOffset": 0, "endOffset": 29}, {"referenceID": 125, "context": "[96, 102, 123, 124, 125, 126] The fuzzy particle filter effectively handles the system complexity by compromising the low number of particles that were used while retaining the tracking performance.", "startOffset": 0, "endOffset": 29}, {"referenceID": 128, "context": "[129, 130] Fuzzy hostility index is used in the optical flow to filter the incoherent optical flow field containing", "startOffset": 0, "endOffset": 10}, {"referenceID": 129, "context": "[129, 130] Fuzzy hostility index is used in the optical flow to filter the incoherent optical flow field containing", "startOffset": 0, "endOffset": 10}, {"referenceID": 131, "context": "[132] FCM tracking algorithm offers more meaningful", "startOffset": 0, "endOffset": 5}, {"referenceID": 134, "context": "The applications of gesture recognition are manifold [135], ranging from the sign language to medical rehabilitation and virtual reality.", "startOffset": 53, "endOffset": 58}, {"referenceID": 135, "context": "The importance of gesture recognition lies in building efficient and intelligent human-computer interaction applications [136] where one can control the system from a distance for a specific task, i.", "startOffset": 121, "endOffset": 126}, {"referenceID": 136, "context": "Also, \u201cpure\u201d gestures are seldom elicited, as people typically demonstrate \u201cblends\u201d of these gestures [137].", "startOffset": 102, "endOffset": 107}, {"referenceID": 137, "context": "This solution works better in the challenging environments such as the complex backgrounds, dynamic lighting conditions, and the deformable hand shapes with real-time computational speeds [138, 139, 140, 141].", "startOffset": 188, "endOffset": 208}, {"referenceID": 138, "context": "This solution works better in the challenging environments such as the complex backgrounds, dynamic lighting conditions, and the deformable hand shapes with real-time computational speeds [138, 139, 140, 141].", "startOffset": 188, "endOffset": 208}, {"referenceID": 139, "context": "This solution works better in the challenging environments such as the complex backgrounds, dynamic lighting conditions, and the deformable hand shapes with real-time computational speeds [138, 139, 140, 141].", "startOffset": 188, "endOffset": 208}, {"referenceID": 137, "context": "Using the FCM, [138, 139] worked on a fast respond telerobotic gesture-based user interface system.", "startOffset": 15, "endOffset": 25}, {"referenceID": 138, "context": "Using the FCM, [138, 139] worked on a fast respond telerobotic gesture-based user interface system.", "startOffset": 15, "endOffset": 25}, {"referenceID": 137, "context": "[140] further improved the work [138] in the skin segmentation problem using the color space to solve the skin color variation.", "startOffset": 32, "endOffset": 37}, {"referenceID": 139, "context": "In [141], the spatial information of hand gesture using the FCM was trained in order to determine the partitioning of the trajectory points into a number of clusters with the fuzzy pseudo-boundaries.", "startOffset": 3, "endOffset": 8}, {"referenceID": 140, "context": "A few works [142, 143, 144] on fusing the fuzzy approaches with machine learning solutions have been reported in the gesture recognition.", "startOffset": 12, "endOffset": 27}, {"referenceID": 141, "context": "A few works [142, 143, 144] on fusing the fuzzy approaches with machine learning solutions have been reported in the gesture recognition.", "startOffset": 12, "endOffset": 27}, {"referenceID": 142, "context": "A few works [142, 143, 144] on fusing the fuzzy approaches with machine learning solutions have been reported in the gesture recognition.", "startOffset": 12, "endOffset": 27}, {"referenceID": 140, "context": "[142] used the adaptive neuro-fuzzy inference system to recognize the gestures in Arabic sign language.", "startOffset": 0, "endOffset": 5}, {"referenceID": 141, "context": "[143] introduced a new approach towards gesture recognition based on the idea of incorporating the fuzzy ARTMAP [145] in the feature recognition neural network [146].", "startOffset": 0, "endOffset": 5}, {"referenceID": 143, "context": "[143] introduced a new approach towards gesture recognition based on the idea of incorporating the fuzzy ARTMAP [145] in the feature recognition neural network [146].", "startOffset": 112, "endOffset": 117}, {"referenceID": 144, "context": "[143] introduced a new approach towards gesture recognition based on the idea of incorporating the fuzzy ARTMAP [145] in the feature recognition neural network [146].", "startOffset": 160, "endOffset": 165}, {"referenceID": 142, "context": "Nonetheless, [144] presented an approach with several novelties and advantages as compared to other hybrid solutions.", "startOffset": 13, "endOffset": 18}, {"referenceID": 145, "context": "In the literature of activity recognition, there exists some works [147, 148] that employed the FIS to classify different human activities.", "startOffset": 67, "endOffset": 77}, {"referenceID": 146, "context": "In the literature of activity recognition, there exists some works [147, 148] that employed the FIS to classify different human activities.", "startOffset": 67, "endOffset": 77}, {"referenceID": 145, "context": "Both [147, 148] took into account the uncertainties in both the spatial and temporal features for efficient human behavior recognition.", "startOffset": 5, "endOffset": 15}, {"referenceID": 146, "context": "Both [147, 148] took into account the uncertainties in both the spatial and temporal features for efficient human behavior recognition.", "startOffset": 5, "endOffset": 15}, {"referenceID": 145, "context": "[147] used the spatial and temporal geometry features to study the importance of the spatiotemporal relations such as \u2018IsMoving\u2019, \u2018IsComingCloseTo\u2019, \u2018IsGoingAway\u2019, \u2018IsGoingAlong\u2019 with the objective to", "startOffset": 0, "endOffset": 5}, {"referenceID": 146, "context": "Another work [148] adopted the spatio-temporal features such as the silhouette slices and the movement speed in video sequences as the inputs to the FIS.", "startOffset": 13, "endOffset": 18}, {"referenceID": 147, "context": "Owing to the demands of the development of enhanced video surveillance systems that can automatically understand the human behaviors and identify dangerous activities, [149] introduced a semantic human behavioral analysis system based on the hybridization of the neuro-fuzzy approach.", "startOffset": 168, "endOffset": 173}, {"referenceID": 148, "context": "Another work [150] presented a fuzzy rule-based reasoning approach for event detection and annotation of broadcast soccer video, integrating the Decision Tree and the FIS.", "startOffset": 13, "endOffset": 18}, {"referenceID": 149, "context": "Figure 13: Movements of running (top) and walking (bottom) activities, as well as the associated dynemes which are learned from the FCM [151].", "startOffset": 136, "endOffset": 141}, {"referenceID": 149, "context": "In order to learn the complex actions, [151] represented the human movements as a combination of the smallest constructive unit of human motion patterns called the dyneme (Figure 13).", "startOffset": 39, "endOffset": 44}, {"referenceID": 149, "context": "Dyneme can be learned in an unsupervised manner and in [151], the FCM was chosen.", "startOffset": 55, "endOffset": 60}, {"referenceID": 150, "context": "Then, fuzzy vector quantization (FVQ) [152] as a function that regulates the transition between the crisp and the soft decisions was employed to map an input posture vector into the dyneme space.", "startOffset": 38, "endOffset": 43}, {"referenceID": 95, "context": "Figure 14: Visualization of the QNT model: each of the five activities (walking, running, jogging, one-hand waving (wave1) and two-hands waving(wave2)) from eight subjects (a)-(h) in the quantity space [96].", "startOffset": 202, "endOffset": 206}, {"referenceID": 94, "context": "Utilizing the concept of fuzzy qualitative robot kinematics [95, 101], Chan and Liu [96, 102] built a generative action template, called the Qualitative normalized template (QNT) to perform the human action recognition.", "startOffset": 60, "endOffset": 69}, {"referenceID": 100, "context": "Utilizing the concept of fuzzy qualitative robot kinematics [95, 101], Chan and Liu [96, 102] built a generative action template, called the Qualitative normalized template (QNT) to perform the human action recognition.", "startOffset": 60, "endOffset": 69}, {"referenceID": 95, "context": "Utilizing the concept of fuzzy qualitative robot kinematics [95, 101], Chan and Liu [96, 102] built a generative action template, called the Qualitative normalized template (QNT) to perform the human action recognition.", "startOffset": 84, "endOffset": 93}, {"referenceID": 101, "context": "Utilizing the concept of fuzzy qualitative robot kinematics [95, 101], Chan and Liu [96, 102] built a generative action template, called the Qualitative normalized template (QNT) to perform the human action recognition.", "startOffset": 84, "endOffset": 93}, {"referenceID": 94, "context": "Then, the QNT as illustrated in Figure 14 was constructed according to the fuzzy qualitative robot kinematics framework [95, 101].", "startOffset": 120, "endOffset": 129}, {"referenceID": 100, "context": "Then, the QNT as illustrated in Figure 14 was constructed according to the fuzzy qualitative robot kinematics framework [95, 101].", "startOffset": 120, "endOffset": 129}, {"referenceID": 95, "context": "An empirical comparison with the conventional hidden Markov model (HMM) and fuzzy HMM using both the KTH and the Weizmannn datasets has shown the effectiveness of the proposed solution [96].", "startOffset": 185, "endOffset": 189}, {"referenceID": 151, "context": "Hidden Markov model (HMM) [153] is the statistical Markov model with the state being not directly visible, but the output that is dependent on the state is visible.", "startOffset": 26, "endOffset": 31}, {"referenceID": 152, "context": "HMM have been widely employed in the human action recognition [154, 155, 156, 157, 158].", "startOffset": 62, "endOffset": 87}, {"referenceID": 153, "context": "HMM have been widely employed in the human action recognition [154, 155, 156, 157, 158].", "startOffset": 62, "endOffset": 87}, {"referenceID": 154, "context": "HMM have been widely employed in the human action recognition [154, 155, 156, 157, 158].", "startOffset": 62, "endOffset": 87}, {"referenceID": 155, "context": "HMM have been widely employed in the human action recognition [154, 155, 156, 157, 158].", "startOffset": 62, "endOffset": 87}, {"referenceID": 156, "context": "HMM have been widely employed in the human action recognition [154, 155, 156, 157, 158].", "startOffset": 62, "endOffset": 87}, {"referenceID": 157, "context": "[159] pointed out that assigning different observation vectors to the same cluster is possible and if their observation probabilities become the same, consequently, the classification performance may decrease.", "startOffset": 0, "endOffset": 5}, {"referenceID": 157, "context": "[159] utilized this concept for human action recognition and the experiment results demonstrate the effectiveness of the fuzzy HMM in human action recognition, with good recognition accuracy for the similar actions such as \u201cwalk\u201d and \u201crun\u201d.", "startOffset": 0, "endOffset": 5}, {"referenceID": 158, "context": ") [160].", "startOffset": 2, "endOffset": 7}, {"referenceID": 159, "context": "[161] adopted the concept of FVQ and the dyneme, and proposed a novel person specific activity recognition framework to cope with the style invariant problem.", "startOffset": 0, "endOffset": 5}, {"referenceID": 149, "context": "The method is mainly divided into two parts: firstly, the ID of the person is identified, and secondly, the activity is inferred from the person specific fuzzy motion model [151].", "startOffset": 173, "endOffset": 178}, {"referenceID": 160, "context": "Therefore, [162] developed an activity-related biometric authentication system by utilizing the information of different styles by different people.", "startOffset": 11, "endOffset": 16}, {"referenceID": 149, "context": "Improvement was made in the computation of the cumulative fuzzy distances between the vectors and the dynemes that outperforms L1, L2, and Mahalanobis distances which were used previously in [151].", "startOffset": 191, "endOffset": 196}, {"referenceID": 159, "context": "There is a limitation in [161, 162] where a large storage space is required to store the ID of different person and this makes the system impractical.", "startOffset": 25, "endOffset": 35}, {"referenceID": 160, "context": "There is a limitation in [161, 162] where a large storage space is required to store the ID of different person and this makes the system impractical.", "startOffset": 25, "endOffset": 35}, {"referenceID": 158, "context": "An alternative approach was proposed in [160], where a fuzzy descriptor vector was used to represent the human actions of different styles in a single underlying fuzzy action descriptor.", "startOffset": 40, "endOffset": 45}, {"referenceID": 27, "context": "This problem has received increasing attention in the HMA research and some of the notable works have been reported [28, 45, 46].", "startOffset": 116, "endOffset": 128}, {"referenceID": 44, "context": "This problem has received increasing attention in the HMA research and some of the notable works have been reported [28, 45, 46].", "startOffset": 116, "endOffset": 128}, {"referenceID": 45, "context": "This problem has received increasing attention in the HMA research and some of the notable works have been reported [28, 45, 46].", "startOffset": 116, "endOffset": 128}, {"referenceID": 161, "context": "Figure 15: (a) A converging eight-view camera setup and its capture volume, and (b) an eight-view video frame [163].", "startOffset": 110, "endOffset": 115}, {"referenceID": 160, "context": "[162, 163, 164] extended [151] to support multi-view action recognition.", "startOffset": 0, "endOffset": 15}, {"referenceID": 161, "context": "[162, 163, 164] extended [151] to support multi-view action recognition.", "startOffset": 0, "endOffset": 15}, {"referenceID": 162, "context": "[162, 163, 164] extended [151] to support multi-view action recognition.", "startOffset": 0, "endOffset": 15}, {"referenceID": 149, "context": "[162, 163, 164] extended [151] to support multi-view action recognition.", "startOffset": 25, "endOffset": 30}, {"referenceID": 149, "context": "Similar to [151], FVQ was utilized to map every multi-view posture pattern to create the multi-view dyneme space.", "startOffset": 11, "endOffset": 16}, {"referenceID": 163, "context": "human action recognition involving two persons [165].", "startOffset": 47, "endOffset": 52}, {"referenceID": 32, "context": "In most of the multi-view action recognition works, there is an argument that performing view invariant human action recognition using multi-camera approach is not practical in real environment [33, 46].", "startOffset": 194, "endOffset": 202}, {"referenceID": 45, "context": "In most of the multi-view action recognition works, there is an argument that performing view invariant human action recognition using multi-camera approach is not practical in real environment [33, 46].", "startOffset": 194, "endOffset": 202}, {"referenceID": 158, "context": "In order to solve this, [160] proposed a fuzzy action recognition framework for multi-view within a single camera.", "startOffset": 24, "endOffset": 29}, {"referenceID": 158, "context": "The dominant features are then identified from the fuzzy qualitative states and represented as a fuzzy descriptor [160].", "startOffset": 114, "endOffset": 119}, {"referenceID": 158, "context": "In the action recognition step, the viewpoint of the person is first estimated and then proceeded with the action recognition by utilizing the viewpoint specific fuzzy descriptor action models [160].", "startOffset": 193, "endOffset": 198}, {"referenceID": 158, "context": "Figure 16: Predefined viewpoints from left to right: \u2018horizontal view\u2019, \u2018diagonal view\u2019 and \u2018vertical view\u2019 [160].", "startOffset": 108, "endOffset": 113}, {"referenceID": 6, "context": "In our daily life, anomaly detection is important to infer the abnormal behavior of a person, such as an action or an activity that is not following the routine or deviated from the normal behavior [7, 166, 167].", "startOffset": 198, "endOffset": 211}, {"referenceID": 164, "context": "In our daily life, anomaly detection is important to infer the abnormal behavior of a person, such as an action or an activity that is not following the routine or deviated from the normal behavior [7, 166, 167].", "startOffset": 198, "endOffset": 211}, {"referenceID": 165, "context": "In our daily life, anomaly detection is important to infer the abnormal behavior of a person, such as an action or an activity that is not following the routine or deviated from the normal behavior [7, 166, 167].", "startOffset": 198, "endOffset": 211}, {"referenceID": 14, "context": "FIS has been employed in various works for anomaly event detection such as the elderly fall detection in [15, 16, 104], to address the deficiencies and the inherent uncertainty related to modeling and inferring the human activities.", "startOffset": 105, "endOffset": 118}, {"referenceID": 15, "context": "FIS has been employed in various works for anomaly event detection such as the elderly fall detection in [15, 16, 104], to address the deficiencies and the inherent uncertainty related to modeling and inferring the human activities.", "startOffset": 105, "endOffset": 118}, {"referenceID": 103, "context": "FIS has been employed in various works for anomaly event detection such as the elderly fall detection in [15, 16, 104], to address the deficiencies and the inherent uncertainty related to modeling and inferring the human activities.", "startOffset": 105, "endOffset": 118}, {"referenceID": 15, "context": "[16] proposed a novel fuzzy rule based method for monitoring the wellness of the elderly people from the video.", "startOffset": 0, "endOffset": 4}, {"referenceID": 103, "context": "This work was an extension of [104] where the linguistic summarizations of the human states (three states: upright, on-the-ground and in-between) based on the voxel person and the FIS were extracted, extended using a hierarchy of the FIS and the linguistic summarization for the inference of the patients\u2019 activities.", "startOffset": 30, "endOffset": 35}, {"referenceID": 166, "context": "The answer is yes where, [168] extended the work to support the additional common elderly activities such as standing, walking, motionless-on-the-chair, and lying-motionless-on-the-couch, with the inclusion of the knowledge about the real world for the identification of the voxels that corresponds to the wall, floor, ceiling, or other static objects or surfaces.", "startOffset": 25, "endOffset": 30}, {"referenceID": 15, "context": "Figure 17: Rule table of the human states (Upright, In Between, On the Ground) with V=Very low, L=Low, M=Medium, and H=high which are used to infer the human activities [16].", "startOffset": 169, "endOffset": 173}, {"referenceID": 167, "context": "[169] proposed a robust fall detection system using FOCSVM with novel 3D features.", "startOffset": 0, "endOffset": 5}, {"referenceID": 168, "context": "FCM, Gustafson and Kessel Clustering, or Gath and Geva Clustering) along with the fuzzy K-nearest neighbor algorithms were employed in [170].", "startOffset": 135, "endOffset": 140}, {"referenceID": 170, "context": "A hybrid model of the FIS and the Fuzzy Associative Memory (FAM) was incorporated in [172], which basically receives an input and assigns a degree of belongingness to a set of rules.", "startOffset": 85, "endOffset": 90}, {"referenceID": 170, "context": "[172] considered the angles of human limbs as the inputs to the FAM with three rules defining the abnormal movement types.", "startOffset": 0, "endOffset": 5}, {"referenceID": 171, "context": "[173] also used the neural fuzzy network hybrid model, compensating the lacking of the learning ability of the fuzzy approaches to recognize human poses (e.", "startOffset": 0, "endOffset": 5}, {"referenceID": 172, "context": "Another paper [174] proposed fuzzy self-organizing neural network (fuzzy SOM) to learn the activity patterns for anomaly detection in visual surveillance.", "startOffset": 14, "endOffset": 19}, {"referenceID": 173, "context": "With the knowledge that \u201csoft\u201d boundaries exist in concepts formation of human beings [175], fuzzy set theory has emerged to become one of the most important methodology in capturing notions.", "startOffset": 86, "endOffset": 91}, {"referenceID": 174, "context": "For example, [176] in their review on computing with uncertainties emphasized on the fact that the integration of fuzzy models always improves the computer performance in pattern recognition problems.", "startOffset": 13, "endOffset": 18}, {"referenceID": 40, "context": "Similarly, [41, 177] presented a survey on how to effectively represent the uncertainty using the FIS.", "startOffset": 11, "endOffset": 20}, {"referenceID": 175, "context": "Similarly, [41, 177] presented a survey on how to effectively represent the uncertainty using the FIS.", "startOffset": 11, "endOffset": 20}, {"referenceID": 176, "context": "[178, 179] explained on how to design an interval type-2 FIS using the uncertainty bounds and introduced the measurement of uncertainty for interval type-2 fuzzy sets using the information such as centroid, cardinality, fuzziness, variance and skewness.", "startOffset": 0, "endOffset": 10}, {"referenceID": 177, "context": "[178, 179] explained on how to design an interval type-2 FIS using the uncertainty bounds and introduced the measurement of uncertainty for interval type-2 fuzzy sets using the information such as centroid, cardinality, fuzziness, variance and skewness.", "startOffset": 0, "endOffset": 10}, {"referenceID": 178, "context": "A comprehensive review on handling the uncertainty in pattern recognition using the type-2 fuzzy approach was provided by [180].", "startOffset": 122, "endOffset": 127}, {"referenceID": 137, "context": "[138, 139, 140, 141] FCM relaxes the learning and recognition of gesture by using soft computing technique.", "startOffset": 0, "endOffset": 20}, {"referenceID": 138, "context": "[138, 139, 140, 141] FCM relaxes the learning and recognition of gesture by using soft computing technique.", "startOffset": 0, "endOffset": 20}, {"referenceID": 139, "context": "[138, 139, 140, 141] FCM relaxes the learning and recognition of gesture by using soft computing technique.", "startOffset": 0, "endOffset": 20}, {"referenceID": 140, "context": "[142, 143, 144] Integration of the fuzzy approaches with machine learning algorithms help in learning the important", "startOffset": 0, "endOffset": 15}, {"referenceID": 141, "context": "[142, 143, 144] Integration of the fuzzy approaches with machine learning algorithms help in learning the important", "startOffset": 0, "endOffset": 15}, {"referenceID": 142, "context": "[142, 143, 144] Integration of the fuzzy approaches with machine learning algorithms help in learning the important", "startOffset": 0, "endOffset": 15}, {"referenceID": 145, "context": "[147, 148] FIS effectively distinguishes the human motion patterns and activity recognition with its flexibil-", "startOffset": 0, "endOffset": 10}, {"referenceID": 146, "context": "[147, 148] FIS effectively distinguishes the human motion patterns and activity recognition with its flexibil-", "startOffset": 0, "endOffset": 10}, {"referenceID": 147, "context": "[149, 150] Integration of fuzzy logic with machine learning techniques allows the generation of the optimum membership function and fuzzy rules to infer the human behavior.", "startOffset": 0, "endOffset": 10}, {"referenceID": 148, "context": "[149, 150] Integration of fuzzy logic with machine learning techniques allows the generation of the optimum membership function and fuzzy rules to infer the human behavior.", "startOffset": 0, "endOffset": 10}, {"referenceID": 149, "context": "[151] FVQ incorporated with FCM is used to model the human movements and provides the flexibility to support complex continuous actions.", "startOffset": 0, "endOffset": 5}, {"referenceID": 95, "context": "[96, 102, 171] QNT fuzzy motion template relaxes the complex-", "startOffset": 0, "endOffset": 14}, {"referenceID": 101, "context": "[96, 102, 171] QNT fuzzy motion template relaxes the complex-", "startOffset": 0, "endOffset": 14}, {"referenceID": 169, "context": "[96, 102, 171] QNT fuzzy motion template relaxes the complex-", "startOffset": 0, "endOffset": 14}, {"referenceID": 157, "context": "[159] Fuzzy HMM models apply soft computing in the training stage which effectively increases the per-", "startOffset": 0, "endOffset": 5}, {"referenceID": 159, "context": "[161, 162] Style invariant action recognition can be achieved by using person specific fuzzy movement model", "startOffset": 0, "endOffset": 10}, {"referenceID": 160, "context": "[161, 162] Style invariant action recognition can be achieved by using person specific fuzzy movement model", "startOffset": 0, "endOffset": 10}, {"referenceID": 158, "context": "[160] Fuzzy descriptor vector allows to accommodate a set of possible descriptor values in each vector di-", "startOffset": 0, "endOffset": 5}, {"referenceID": 160, "context": "[162, 163, 164, 165] Multi-view posture patterns are generated by uti-", "startOffset": 0, "endOffset": 20}, {"referenceID": 161, "context": "[162, 163, 164, 165] Multi-view posture patterns are generated by uti-", "startOffset": 0, "endOffset": 20}, {"referenceID": 162, "context": "[162, 163, 164, 165] Multi-view posture patterns are generated by uti-", "startOffset": 0, "endOffset": 20}, {"referenceID": 163, "context": "[162, 163, 164, 165] Multi-view posture patterns are generated by uti-", "startOffset": 0, "endOffset": 20}, {"referenceID": 158, "context": "[160] Using fuzzy qualitative framework, action recog-", "startOffset": 0, "endOffset": 5}, {"referenceID": 14, "context": "[15, 16, 104, 168] FIS is flexible in customization where the knowl-", "startOffset": 0, "endOffset": 18}, {"referenceID": 15, "context": "[15, 16, 104, 168] FIS is flexible in customization where the knowl-", "startOffset": 0, "endOffset": 18}, {"referenceID": 103, "context": "[15, 16, 104, 168] FIS is flexible in customization where the knowl-", "startOffset": 0, "endOffset": 18}, {"referenceID": 166, "context": "[15, 16, 104, 168] FIS is flexible in customization where the knowl-", "startOffset": 0, "endOffset": 18}, {"referenceID": 167, "context": "[169] FOCSVM is used to reflect the importance of ev-", "startOffset": 0, "endOffset": 5}, {"referenceID": 168, "context": "[170] Fuzzy clustering algorithms (e.", "startOffset": 0, "endOffset": 5}, {"referenceID": 170, "context": "[172, 173, 174] Integration of the fuzzy approaches with machine learning algorithms allows the learning of optimum fuzzy membership functions and fuzzy rules that can adapt to newly encountered problems.", "startOffset": 0, "endOffset": 15}, {"referenceID": 171, "context": "[172, 173, 174] Integration of the fuzzy approaches with machine learning algorithms allows the learning of optimum fuzzy membership functions and fuzzy rules that can adapt to newly encountered problems.", "startOffset": 0, "endOffset": 15}, {"referenceID": 172, "context": "[172, 173, 174] Integration of the fuzzy approaches with machine learning algorithms allows the learning of optimum fuzzy membership functions and fuzzy rules that can adapt to newly encountered problems.", "startOffset": 0, "endOffset": 15}, {"referenceID": 179, "context": "This concept was initiated in [181] where words can be used in place of numbers for computing and reasoning (like done by humans), commonly known as computing with words (CWW).", "startOffset": 30, "endOffset": 35}, {"referenceID": 179, "context": "There are two major imperatives for CWW [181].", "startOffset": 40, "endOffset": 45}, {"referenceID": 180, "context": "The concept of linguistic support is rooted in several papers starting with [182] in which the concepts of a linguistic variable and the granulation were introduced.", "startOffset": 76, "endOffset": 81}, {"referenceID": 179, "context": "[181] threw light on the role played by the fuzzy logic in CWW and vice-versa.", "startOffset": 0, "endOffset": 5}, {"referenceID": 181, "context": "An interesting piece of work on CWW can be found in [183] where the author defined CWW as a symbolic generalization of the fuzzy logic.", "startOffset": 52, "endOffset": 57}, {"referenceID": 103, "context": "In the recent years, several papers have been published that utilizes the concept of linguistic summarization in the fuzzy system that are successfully applied in the real world applications [104, 184, 185, 186, 187, 188].", "startOffset": 191, "endOffset": 221}, {"referenceID": 182, "context": "In the recent years, several papers have been published that utilizes the concept of linguistic summarization in the fuzzy system that are successfully applied in the real world applications [104, 184, 185, 186, 187, 188].", "startOffset": 191, "endOffset": 221}, {"referenceID": 183, "context": "In the recent years, several papers have been published that utilizes the concept of linguistic summarization in the fuzzy system that are successfully applied in the real world applications [104, 184, 185, 186, 187, 188].", "startOffset": 191, "endOffset": 221}, {"referenceID": 184, "context": "In the recent years, several papers have been published that utilizes the concept of linguistic summarization in the fuzzy system that are successfully applied in the real world applications [104, 184, 185, 186, 187, 188].", "startOffset": 191, "endOffset": 221}, {"referenceID": 185, "context": "In the recent years, several papers have been published that utilizes the concept of linguistic summarization in the fuzzy system that are successfully applied in the real world applications [104, 184, 185, 186, 187, 188].", "startOffset": 191, "endOffset": 221}, {"referenceID": 186, "context": "In the recent years, several papers have been published that utilizes the concept of linguistic summarization in the fuzzy system that are successfully applied in the real world applications [104, 184, 185, 186, 187, 188].", "startOffset": 191, "endOffset": 221}, {"referenceID": 187, "context": "Several works in the literature have reported efficient methods for the automatic generation of the fuzzy rules such as [189, 190, 191, 192, 193].", "startOffset": 120, "endOffset": 145}, {"referenceID": 188, "context": "Several works in the literature have reported efficient methods for the automatic generation of the fuzzy rules such as [189, 190, 191, 192, 193].", "startOffset": 120, "endOffset": 145}, {"referenceID": 189, "context": "Several works in the literature have reported efficient methods for the automatic generation of the fuzzy rules such as [189, 190, 191, 192, 193].", "startOffset": 120, "endOffset": 145}, {"referenceID": 190, "context": "Several works in the literature have reported efficient methods for the automatic generation of the fuzzy rules such as [189, 190, 191, 192, 193].", "startOffset": 120, "endOffset": 145}, {"referenceID": 191, "context": "Several works in the literature have reported efficient methods for the automatic generation of the fuzzy rules such as [189, 190, 191, 192, 193].", "startOffset": 120, "endOffset": 145}, {"referenceID": 187, "context": "For example, [189] proposed a method of generating the fuzzy rules by learning from examples, more specifically by the numerical data.", "startOffset": 13, "endOffset": 18}, {"referenceID": 188, "context": "Similarly, [190] presented an alternative method to generate the fuzzy rules automatically from the training data with their rules defined in the form of possibility, certainty, gradual, and unless rules.", "startOffset": 11, "endOffset": 16}, {"referenceID": 189, "context": "A new approach called the fuzzy extension matrix was proposed in [191] which incorporated the fuzzy entropy to search for the paths and generalized the concept of the crisp extension matrix.", "startOffset": 65, "endOffset": 70}, {"referenceID": 190, "context": "multi-stage random sampling) with its fast performance have also been adopted in the fuzzy rule generation such as the work by [192].", "startOffset": 127, "endOffset": 132}, {"referenceID": 192, "context": "[194] provided an exhaustive survey on the neuro-fuzzy rule generation algorithms, while [193] presented an approach to automatically learn the fuzzy rules by incorporating the genetic algorithm.", "startOffset": 0, "endOffset": 5}, {"referenceID": 191, "context": "[194] provided an exhaustive survey on the neuro-fuzzy rule generation algorithms, while [193] presented an approach to automatically learn the fuzzy rules by incorporating the genetic algorithm.", "startOffset": 89, "endOffset": 94}, {"referenceID": 234, "context": "However, [238, 239, 240] raised an argument that many situations in the real life are ambiguous, especially the human behavior with varied perceptions of the masses.", "startOffset": 9, "endOffset": 24}, {"referenceID": 235, "context": "However, [238, 239, 240] raised an argument that many situations in the real life are ambiguous, especially the human behavior with varied perceptions of the masses.", "startOffset": 9, "endOffset": 24}, {"referenceID": 236, "context": "However, [238, 239, 240] raised an argument that many situations in the real life are ambiguous, especially the human behavior with varied perceptions of the masses.", "startOffset": 9, "endOffset": 24}, {"referenceID": 237, "context": "Early event detection: Apart from that, fuzzy approaches being successful in handling the uncertainties in various real-time applications as highlighted in this survey, can be very well explored to be potentially applied in highly complex HMA applications such as human activity forecasting [241] and early detection of crimes [242, 243].", "startOffset": 291, "endOffset": 296}, {"referenceID": 238, "context": "Early event detection: Apart from that, fuzzy approaches being successful in handling the uncertainties in various real-time applications as highlighted in this survey, can be very well explored to be potentially applied in highly complex HMA applications such as human activity forecasting [241] and early detection of crimes [242, 243].", "startOffset": 327, "endOffset": 337}, {"referenceID": 239, "context": "Early event detection: Apart from that, fuzzy approaches being successful in handling the uncertainties in various real-time applications as highlighted in this survey, can be very well explored to be potentially applied in highly complex HMA applications such as human activity forecasting [241] and early detection of crimes [242, 243].", "startOffset": 327, "endOffset": 337}, {"referenceID": 37, "context": "KTH 2004 [38] [102, 96, 164] RA = 93.", "startOffset": 9, "endOffset": 13}, {"referenceID": 101, "context": "KTH 2004 [38] [102, 96, 164] RA = 93.", "startOffset": 14, "endOffset": 28}, {"referenceID": 95, "context": "KTH 2004 [38] [102, 96, 164] RA = 93.", "startOffset": 14, "endOffset": 28}, {"referenceID": 162, "context": "KTH 2004 [38] [102, 96, 164] RA = 93.", "startOffset": 14, "endOffset": 28}, {"referenceID": 162, "context": "52 [164] RA = 96.", "startOffset": 3, "endOffset": 8}, {"referenceID": 193, "context": "76 [195]", "startOffset": 3, "endOffset": 8}, {"referenceID": 194, "context": "CAVIAR 2004 [196] TP = 91.", "startOffset": 12, "endOffset": 17}, {"referenceID": 195, "context": "90 [197]", "startOffset": 3, "endOffset": 8}, {"referenceID": 39, "context": "WEIZMANN Actions 2005 [40] [148, 159, 151, 102, 96] RA = 100.", "startOffset": 22, "endOffset": 26}, {"referenceID": 146, "context": "WEIZMANN Actions 2005 [40] [148, 159, 151, 102, 96] RA = 100.", "startOffset": 27, "endOffset": 51}, {"referenceID": 157, "context": "WEIZMANN Actions 2005 [40] [148, 159, 151, 102, 96] RA = 100.", "startOffset": 27, "endOffset": 51}, {"referenceID": 149, "context": "WEIZMANN Actions 2005 [40] [148, 159, 151, 102, 96] RA = 100.", "startOffset": 27, "endOffset": 51}, {"referenceID": 101, "context": "WEIZMANN Actions 2005 [40] [148, 159, 151, 102, 96] RA = 100.", "startOffset": 27, "endOffset": 51}, {"referenceID": 95, "context": "WEIZMANN Actions 2005 [40] [148, 159, 151, 102, 96] RA = 100.", "startOffset": 27, "endOffset": 51}, {"referenceID": 95, "context": "00 [96] RA = 100.", "startOffset": 3, "endOffset": 7}, {"referenceID": 196, "context": "00 [198]", "startOffset": 3, "endOffset": 8}, {"referenceID": 44, "context": "IXMAS 2006 [45] [163, 160] RA = 83.", "startOffset": 11, "endOffset": 15}, {"referenceID": 161, "context": "IXMAS 2006 [45] [163, 160] RA = 83.", "startOffset": 16, "endOffset": 26}, {"referenceID": 158, "context": "IXMAS 2006 [45] [163, 160] RA = 83.", "startOffset": 16, "endOffset": 26}, {"referenceID": 161, "context": "47 [163] RA = 95.", "startOffset": 3, "endOffset": 8}, {"referenceID": 197, "context": "54 [199]", "startOffset": 3, "endOffset": 8}, {"referenceID": 198, "context": "CASIA Action 2007 [200] RA = 99.", "startOffset": 18, "endOffset": 23}, {"referenceID": 199, "context": "90 [201]", "startOffset": 3, "endOffset": 8}, {"referenceID": 200, "context": "ETISEO 2007 [202] TP = 100.", "startOffset": 12, "endOffset": 17}, {"referenceID": 201, "context": "00 [203]", "startOffset": 3, "endOffset": 8}, {"referenceID": 202, "context": "UIUC - Complex action 2007 [204] [171] RA > 80.", "startOffset": 27, "endOffset": 32}, {"referenceID": 169, "context": "UIUC - Complex action 2007 [204] [171] RA > 80.", "startOffset": 33, "endOffset": 38}, {"referenceID": 169, "context": "00 [171] UIUC 2008 [205] RA = 93.", "startOffset": 3, "endOffset": 8}, {"referenceID": 203, "context": "00 [171] UIUC 2008 [205] RA = 93.", "startOffset": 19, "endOffset": 24}, {"referenceID": 204, "context": "30 [206]", "startOffset": 3, "endOffset": 8}, {"referenceID": 149, "context": "CMU MoCap 2008 [207] [151] RA = 98.", "startOffset": 21, "endOffset": 26}, {"referenceID": 149, "context": "90 [151] RA = 98.", "startOffset": 3, "endOffset": 8}, {"referenceID": 205, "context": "30 [208]", "startOffset": 3, "endOffset": 8}, {"referenceID": 206, "context": "ViHASi 2008 [209] RA = 72.", "startOffset": 12, "endOffset": 17}, {"referenceID": 207, "context": "00 [210]", "startOffset": 3, "endOffset": 8}, {"referenceID": 208, "context": "HOLLYWOOD 2008 [211] RA = 61.", "startOffset": 15, "endOffset": 20}, {"referenceID": 209, "context": "50 [212]", "startOffset": 3, "endOffset": 8}, {"referenceID": 210, "context": "HOLLYWOOD-2 2009 [213] RA = 64.", "startOffset": 17, "endOffset": 22}, {"referenceID": 211, "context": "30 [214]", "startOffset": 3, "endOffset": 8}, {"referenceID": 212, "context": "UCF-Sports 2008 [215] [164] RA = 85.", "startOffset": 16, "endOffset": 21}, {"referenceID": 162, "context": "UCF-Sports 2008 [215] [164] RA = 85.", "startOffset": 22, "endOffset": 27}, {"referenceID": 162, "context": "77 [164] RA = 89.", "startOffset": 3, "endOffset": 8}, {"referenceID": 213, "context": "70 [216]", "startOffset": 3, "endOffset": 8}, {"referenceID": 214, "context": "UCF-11 Youtube 2009 [217] RA = 89.", "startOffset": 20, "endOffset": 25}, {"referenceID": 193, "context": "79 [195]", "startOffset": 3, "endOffset": 8}, {"referenceID": 215, "context": "i3DPost 2009 [218] [163, 165, 164] RA = 100.", "startOffset": 13, "endOffset": 18}, {"referenceID": 161, "context": "i3DPost 2009 [218] [163, 165, 164] RA = 100.", "startOffset": 19, "endOffset": 34}, {"referenceID": 163, "context": "i3DPost 2009 [218] [163, 165, 164] RA = 100.", "startOffset": 19, "endOffset": 34}, {"referenceID": 162, "context": "i3DPost 2009 [218] [163, 165, 164] RA = 100.", "startOffset": 19, "endOffset": 34}, {"referenceID": 162, "context": "00 [164] RA = 98.", "startOffset": 3, "endOffset": 8}, {"referenceID": 216, "context": "44 [219]", "startOffset": 3, "endOffset": 8}, {"referenceID": 217, "context": "UT-Interaction 2009 [220] RA = 91.", "startOffset": 20, "endOffset": 25}, {"referenceID": 196, "context": "67 [221] UT-Tower 2009 [198] -", "startOffset": 23, "endOffset": 28}, {"referenceID": 218, "context": "MSR Action 2009 [222] MSR 3D Action 2010 [223] RA = 97.", "startOffset": 16, "endOffset": 21}, {"referenceID": 219, "context": "MSR Action 2009 [222] MSR 3D Action 2010 [223] RA = 97.", "startOffset": 41, "endOffset": 46}, {"referenceID": 220, "context": "80 [224]", "startOffset": 3, "endOffset": 8}, {"referenceID": 221, "context": "BEHAVE 2010 [225] RA = 65.", "startOffset": 12, "endOffset": 17}, {"referenceID": 222, "context": "50 [226]", "startOffset": 3, "endOffset": 8}, {"referenceID": 223, "context": "MuHAVi 2010 [227] RA = 100.", "startOffset": 12, "endOffset": 17}, {"referenceID": 224, "context": "00 [228]", "startOffset": 3, "endOffset": 8}, {"referenceID": 225, "context": "Olympic Sports 2010 [229] RA = 91.", "startOffset": 20, "endOffset": 25}, {"referenceID": 211, "context": "10 [214]", "startOffset": 3, "endOffset": 8}, {"referenceID": 226, "context": "TV Human Interaction 2010 [230] RA = 46.", "startOffset": 26, "endOffset": 31}, {"referenceID": 227, "context": "00 [231]", "startOffset": 3, "endOffset": 8}, {"referenceID": 228, "context": "HMDB51 2011 [232] RA = 57.", "startOffset": 12, "endOffset": 17}, {"referenceID": 211, "context": "20 [214]", "startOffset": 3, "endOffset": 8}, {"referenceID": 229, "context": "VideoWeb 2011 [233] RA = 72.", "startOffset": 14, "endOffset": 19}, {"referenceID": 230, "context": "00 [234]", "startOffset": 3, "endOffset": 8}, {"referenceID": 231, "context": "UCF-101 2012 [235] RA = 83.", "startOffset": 13, "endOffset": 18}, {"referenceID": 232, "context": "50 [236]", "startOffset": 3, "endOffset": 8}, {"referenceID": 233, "context": "UCF-50 2013 [237] RA = 91.", "startOffset": 12, "endOffset": 17}, {"referenceID": 211, "context": "20 [214]", "startOffset": 3, "endOffset": 8}, {"referenceID": 240, "context": "computer vision community [244, 245, 246, 247, 248, 249, 250], but as to our very best knowledge, none was found in the fuzzy domain.", "startOffset": 26, "endOffset": 61}, {"referenceID": 241, "context": "computer vision community [244, 245, 246, 247, 248, 249, 250], but as to our very best knowledge, none was found in the fuzzy domain.", "startOffset": 26, "endOffset": 61}, {"referenceID": 242, "context": "computer vision community [244, 245, 246, 247, 248, 249, 250], but as to our very best knowledge, none was found in the fuzzy domain.", "startOffset": 26, "endOffset": 61}, {"referenceID": 243, "context": "computer vision community [244, 245, 246, 247, 248, 249, 250], but as to our very best knowledge, none was found in the fuzzy domain.", "startOffset": 26, "endOffset": 61}, {"referenceID": 244, "context": "computer vision community [244, 245, 246, 247, 248, 249, 250], but as to our very best knowledge, none was found in the fuzzy domain.", "startOffset": 26, "endOffset": 61}, {"referenceID": 245, "context": "computer vision community [244, 245, 246, 247, 248, 249, 250], but as to our very best knowledge, none was found in the fuzzy domain.", "startOffset": 26, "endOffset": 61}, {"referenceID": 246, "context": "computer vision community [244, 245, 246, 247, 248, 249, 250], but as to our very best knowledge, none was found in the fuzzy domain.", "startOffset": 26, "endOffset": 61}, {"referenceID": 247, "context": "For example, [251] proposed a method to recognize the human-object interactions in still images by explicitly modeling the mutual context between the human poses and the objects, so that each can facilitate the recognition of the other.", "startOffset": 13, "endOffset": 18}], "year": 2014, "abstractText": "Human Motion Analysis (HMA) is currently one of the most popularly active research domains as such significant research interests are motivated by a number of real world applications such as video surveillance, sports analysis, healthcare monitoring and so on. However, most of these real world applications face high levels of uncertainties that can affect the operations of such applications. Hence, the fuzzy set theory has been applied and showed great success in the recent past. In this paper, we aim at reviewing the fuzzy set oriented approaches for HMA, individuating how the fuzzy set may improve the HMA, envisaging and delineating the future perspectives. To the best of our knowledge, there is not found a single survey in the current literature that has discussed and reviewed fuzzy approaches towards the HMA. For ease of understanding, we conceptually classify the human motion into three broad levels: Low-Level (LoL), Mid-Level (MiL), and High-Level (HiL) HMA.", "creator": "LaTeX with hyperref package"}}}