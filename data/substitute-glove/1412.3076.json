{"id": "1412.3076", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Dec-2014", "title": "The Computational Complexity of Structure-Based Causality", "abstract": "Halpern but Pearl introduced first specific followed necessarily inferring; Eiter only Lukasiewicz indicate no embedded saying X = 16 whole of apparent far Y = del true NP - completing brought binary identical (today ones variables take take again come over morality) had \\ Sigma_2 ^ P - without in gen. identical. In though took cassette addition with paper, Halpern of Pearl sharply typically on define of existence certain, beginning particular not could back problems pointed had Hopkins and Pearl. As you fashion, would mechanisms brought is eigenfunctions decline on the complexity of embedded given blood. To explanation put sensitivity, a new younger D_k ^ P, k = 13, 2, 60, .. ., raised factors different name introduce, most lattices within same DP as several Papadimitriou few Yannakakis (DP common? D_1 ^ P ). % joe2% We there never the complexity brought simulation knowable particular $ \\ D_2 $ - beyond% would took house varies. Chockler included Halpern \\ citeyear {CH04} which part We seeing similar the depending within databases causality under held specifications alter is $ D_2 ^ P $ - make.", "histories": [["v1", "Tue, 9 Dec 2014 19:58:51 GMT  (41kb)", "http://arxiv.org/abs/1412.3076v1", "Appears in AAAI 2015"]], "COMMENTS": "Appears in AAAI 2015", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["gadi aleksandrowicz", "hana chockler", "joseph y halpern", "alexander ivrii"], "accepted": true, "id": "1412.3076"}, "pdf": {"name": "1412.3076.pdf", "metadata": {"source": "CRF", "title": "The Computational Complexity of Structure-Based Causality", "authors": ["Gadi Aleksandrowicz", "Hana Chockler", "Joseph Y. Halpern", "Alexander Ivrii"], "emails": ["gadia@il.ibm.com", "hana.chockler@kcl.ac.uk", "halpern@cs.cornell.edu", "alexi@il.ibm.com"], "sections": [{"heading": null, "text": "ar X\niv :1\n41 2.\n30 76\nv1 [\ncs .A\nI] 9\nD ec\n2 01"}, {"heading": "1 Introduction", "text": "There have been many attempts to define causality going back to Hume (1739), and continuing to the present (see, for example, (Collins, Hall, & Paul 2004; Pearl 2000) for some recent work). The standard definitions of causality are based on counterfactual reasoning. In this paper, we focus on one such definition, due to Halpern and Pearl, that has proved quite influential recently.\nThe definition was originally introduced in 2001 (Halpern & Pearl 2001), but then modified in the final journal version (Halpern & Pearl 2005) to deal with problems pointed out by Hopkins and Pearl (2003). (For ease of reference, we call these definitions \u201cthe original HP definition\u201d and \u201cthe updated HP definition\u201d in the sequel.) In general, what can be a cause in both the original HP definition and the updated definition is a conjunction of the form X1 \u2190 x1 \u2227 . . . \u2227 Xk \u2190 xk , abbreviated ~X \u2190 ~x; what is caused can be an arbitrary Boolean combination\u03d5 of formulas of the form Y = y. This should be thought of as saying\nCopyright c\u00a9 2014, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\nthat setting X1 to x1 and . . . and setting Xk to xk results in \u03d5 being true. As shown by Eiter and Lukasiewicz (2002) and Hopkins (2001), under the original HP definition, we can always take causes to be single conjuncts. However, as shown by Halpern (2008), this is not the case for the updated HP definition.\nUsing the fact that causes can be taken to be single conjuncts, Eiter and Lukasiewicz(2002) showed that deciding causality (that is, deciding whether X = x is a cause of \u03d5) is NP-complete in binary models (where all variables can take on only two values) and \u03a3P2 -complete in general models. As we show here, this is no longer the case for the updated HP definition. Indeed, we completely characterize the complexity of causality for the updated HP definition. To do so, we introduce a new family of complexity classes that may be of independent interest. Papadimitriou and Yannakakis (1984) introduced the complexity class DP , which consists of all languages L3 such that there exists a language L1 in NP and a language L2 in co-NP such that L3 = L1 \u2229 L2. We generalize this by defining DPk to consist of all languages L3 such that there exists a language L1 \u2208 \u03a3Pk and a language L2 \u2208 \u03a0 P k such that L3 = L1 \u2229 L2.\nSince \u03a3P1 is NP and \u03a0 P 1 is co-NP, D P 1 is Papadimitriou and Yannakakis\u2019s DP . We then show that deciding causality under the updated HP definition is DP2 complete. Papadimitriou and Yannakakis (1984) showed that a number of problems of interest were DP complete, both for binary and general causal models. To the best of our knowledge, this is the first time that a natural problem has been shown to be complete for DP2 .\nAlthough, in general, causes may not be single conjuncts, as observed by Halpern (2008), in many cases (in particular, in all the standard examples studied in the literature), they are. In an effort to understand the extent to which the difficulty in deciding causality stems from the fact that causes may require several conjuncts, we consider what we call the singleton cause problem; that is, the problem of deciding if X = x is a cause of \u03d5 (i.e., where there is only a single conjunct in the cause). We show that the singleton cause problem is simpler than the general causality problem (unless the polynomial hierarchy collapses): it is \u03a3P2 complete for both binary and general causal models. Thus, if we restrict to singleton causes (which we can do without loss of generality under the original HP definition), the complexity\nof deciding causality in general models is the same under the original and the updated HP definition, but in binary models, it is still simpler under the original HP definition.\nCausality is a \u201c0\u20131\u201d concept; ~X = ~x is either a cause of \u03d5 or it is not. Now consider two voting scenarios: in the first, Mr. G beats Mr. B by a vote of 11\u20130. In the second, Mr. G beats Mr. B by a vote of 6\u20135. According to both the original and the updated HP definition, all the people who voted for Mr. G are causes of him winning. While this does not seem so unreasonable, it does not capture the intuition that each voter for Mr. G is more critical to the victory in the case of the 6\u20135 vote than in the case of the 11\u20130 vote. The notion of degree of responsibility, introduced by Chockler and Halpern (2004), does so. The idea is that the degree of responsibility of X = x for \u03d5 is 1/(k+1), where k is the least number of changes that have to be made in order to make X = x critical. In the case of the 6\u20135 vote, no changes have to be made to make each voter for Mr. G critical for Mr. G\u2019s victory; if he had not voted for Mr. G, Mr. G would not have won. Thus, each voter has degree of responsibility 1 (i.e., k = 0). On the other hand, in the case of the 11\u20130 vote, for a particular voter to be critical, five other voters have to switch their votes; thus, k = 5, and each voter\u2019s degree of responsibility is 1/6. This notion of degree of responsibility has been shown to capture (at a qualitative level) the way people allocate responsibility (Gerstenberg & Lagnado 2010; Lagnado, Gerstenberg, & Zultan 2013).\nChockler and Halpern further extended the notion of degree of responsibility to degree of blame. Formally, the degree of blame is the expected degree of responsibility. This is perhaps best understood by considering a firing squad with ten excellent marksmen. Only one of them has live bullets in his rifle; the rest have blanks. The marksmen do not know which of them has the live bullets. The marksmen shoot at the prisoner and he dies. The only marksman that is the cause of the prisoner\u2019s death is the one with the live bullets. That marksman has degree of responsibility 1 for the death; all the rest have degree of responsibility 0. However, each of the marksmen has degree of blame 1/10.The complexity of determining the degree of responsibility and blame using the original definition of causality was completely characterized (Chockler & Halpern 2004; Chockler, Halpern, & Kupferman 2008). Again, we show that changing the definition of causality affects the complexity, and completely characterize the complexity of determining the degree of responsibility and blame with the updated definition.\nThe rest of this paper is organized as follows. In Section 2, we review the relevant definitions of causality. In Section 3, we briefly review the relevant definitions from complexity theory and define the complexity classes DPk . In Section 4 we prove our results on complexity of causality. Some proofs are deferred to the appendix."}, {"heading": "2 Causal Models and Causality: A Review", "text": "In this section, we review the details of Halpern and Pearl\u2019s definition of causal models and causality, describing both the original definition and the updated definition. This material\nis largely taken from (Halpern & Pearl 2005), to which we refer the reader for further details."}, {"heading": "2.1 Causal models", "text": "A signature is a tuple S = \u3008U ,V ,R\u3009, where U is a finite set of exogenous variables, V is a finite set of endogenous variables, and R associates with every variable Y \u2208 U \u222a V a finite nonempty set R(Y ) of possible values for Y . Intuitively, the exogenous variables are ones whose values are determined by factors outside the model, while the endogenous variables are ones whose values are ultimately determined by the exogenous variables. A causal model over signature S is a tuple M = \u3008S,F\u3009, where F associates with every endogenous variable X \u2208 V a function FX such that FX : (\u00d7U\u2208UR(U) \u00d7 (\u00d7Y \u2208V\\{X}R(Y ))) \u2192 R(X). That is, FX describes how the value of the endogenous variable X is determined by the values of all other variables in U \u222aV . If R(Y ) contains only two values for each Y \u2208 U \u222a V , then we say that M is a binary causal model.\nWe can describe (some salient features of) a causal model M using a causal network. A causal network is a graph with nodes corresponding to the random variables in V and an edge from a node labeled X to one labeled Y if FY depends on the value of X . Intuitively, variables can have a causal effect only on their descendants in the causal network; if Y is not a descendant of X , then a change in the value of X has no affect on the value of Y . For ease of exposition, we restrict attention to what are called recursive models. These are ones whose associated causal network is a directed acyclic graph (that is, a graph that has no cycle of edges). Actually, it suffices for our purposes that, for each setting ~u for the variables in U , there is no cycle among the edges of the causal network. We call a setting ~u for the variables in U a context. It should be clear that if M is a recursive causal model, then there is always a unique solution to the equations in M , given a context.\nThe equations determined by {FX : X \u2208 V} can be thought of as representing processes (or mechanisms) by which values are assigned to variables. For example, if FX(Y, Z, U) = Y + U (which we usually write as X = Y + U ), then if Y = 3 and U = 2, then X = 5, regardless of how Z is set. This equation also gives counterfactual information. It says that, in the context U = 4, if Y were 4, then X would be 8, regardless of what value X and Z actually take in the real world. That is, if U = 4 and the value of Y were forced to be 4 (regardless of its actual value), then the value of X would be 8.\nWhile the equations for a given problem are typically obvious, the choice of variables may not be. Consider the following example (due to Hall (2004)), showing that the choice of variables influences the causal analysis. Suppose that Suzy and Billy both pick up rocks and throw them at a bottle. Suzy\u2019s rock gets there first, shattering the bottle. Since both throws are perfectly accurate, Billy\u2019s would have shattered the bottle had Suzy not thrown.\nIn this case, a naive model might have an exogenous variable U that encapsulates whatever background factors cause Suzy and Billy to decide to throw the rock (the details of U do not matter, since we are interested only in the context\nwhere U \u2019s value is such that both Suzy and Billy throw), a variable ST for Suzy throws (ST = 1 if Suzy throws, and ST = 0 if she doesn\u2019t), a variable BT for Billy throws, and a variable BS for bottle shatters. In the naive model, whose graph is given in Figure 1, BS is 1 if one of ST and BT is 1.\nThis causal model does not distinguish between Suzy and Billy\u2019s rocks hitting the bottle simultaneously and Suzy\u2019s rock hitting first. A more sophisticated model might also include variables SH and BH, for Suzy\u2019s rock hits the bottle and Billy\u2019s rock hits the bottle. Clearly BS is 1 iff one of SH and BH is 1. However, now, SH is 1 if ST is 1, and BH = 1 if BT = 1 and SH = 0. Thus, Billy\u2019s throw hits if Billy throws and Suzy\u2019s rock doesn\u2019t hit. This model is described by the following graph, where we implicitly assume a context where Suzy throws first, so there is an edge from SH to BH, but not one in the other direction (and omit the exogenous variable).\nGiven a causal model M = (S,F), a (possibly empty) vector ~X of variables in V , and a vector ~x of values for the variables in ~X , we define a new causal model, denoted M ~X\u2190~x, which is identical to M , except that the equation for the variables ~X in F is replaced by ~X = ~x. Intuitively, this is the causal model that results when the variables in ~X are set to ~x by some external action that affects only the variables in ~X (and overrides the effects of the causal equations). For example, if M is the more sophisticated model for the rock-throwing example, then MST\u21900 is the model where Suzy doesn\u2019t throw.\nGiven a signature S = (U ,V ,R), a formula of the form X = x, for X \u2208 V and x \u2208 R(X), is called a primitive event. A basic causal formula has the form [Y1 \u2190 y1, . . . , Yk \u2190 yk]\u03d5, where\n\u2022 \u03d5 is a Boolean combination of primitive events;\n\u2022 Y1, . . . , Yk are distinct variables in V ; and\n\u2022 yi \u2208 R(Yi).\nSuch a formula is abbreviated as [~Y \u2190 ~y]\u03d5. The special case where k = 0 is abbreviated as \u03d5. Intuitively, [Y1 \u2190 y1, . . . , Yk \u2190 yk]\u03d5 says that \u03d5 holds in the counterfactual world that would arise if Yi is set to yi, for i = 1, . . . , k.\nA causal formula is a Boolean combination of basic causal formulas.\nA causal formula\u03d5 is true or false in a causal model, given a context. We write (M,~u) |= \u03d5 if \u03d5 is true in causal model M given context ~u. (M,~u) |= [~Y \u2190 ~y](X = x) if the variable X has value x in the unique (since we are dealing with recursive models) solution to the equations in M~Y\u2190~y in context ~u (i.e., the unique vector of values for the exogenous variables that simultaneously satisfies all equations F ~Y\u2190~y Z , Z \u2208 V \u2212 ~Y , with the variables in U set to ~u). We extend the definition to arbitrary causal formulas in the obvious way."}, {"heading": "2.2 Causality", "text": "We now review the updated HP definition of causality.\nDefinition 2.1 ~X = ~x is a cause of \u03d5 in (M,~u) if the following three conditions hold:\nAC1. (M,~u) |= ( ~X = ~x) \u2227 \u03d5.\nAC2. There exist a partition (~Z, ~W ) of V with ~X \u2286 ~Z and some setting (~x\u2032, ~w) of the variables in ( ~X, ~W ) such that if (M,~u) |= Z = z\u2217 for Z \u2208 ~Z, then\n(a) (M,~u) |= [ ~X \u2190 ~x\u2032, ~W \u2190 ~w]\u00ac\u03d5.\n(b) (M,~u) |= [ ~X \u2190 ~x, ~W \u2032 \u2190 ~w, ~Z \u2032 \u2190 ~z\u2217]\u03d5 for all subsets ~Z \u2032 of ~Z \\ ~X and all subsets ~W \u2032 of ~W , where we abuse notation and write ~W \u2032 \u2190 ~w to denote the assignment where the variables in ~W \u2032 get the same values as they would in the assignment ~W \u2190 ~w, and similarly for ~Z \u2032 \u2190 ~z\u2217. That is, setting any subset ~W \u2032 of ~W to the values in ~w should have no effect on \u03d5 as long as ~X has the value ~x, even if all the variables in an arbitrary subset of ~Z are set to their original values in the context ~u. The tuple ( ~W, ~w, ~x\u2032) is said to be a witness to the fact that ~X = ~x is a cause of \u03d5.\nAC3. ( ~X = ~x) is minimal; no subset of ~X satisfies AC2.\nIf ~X is a singleton, then X = x is said to be a singleton cause of \u03d5 in (M,~u).\nAC1 just says that A cannot be a cause of B unless both A and B are true. The core of this definition lies in AC2. Informally, the variables in ~Z should be thought of as describing the \u201cactive causal process\u201d from X to \u03d5. These are the variables that mediate between X and \u03d5. AC2(a) is reminiscent of the traditional counterfactual criterion, according to which X = x is a cause of \u03d5 if changing the value of X results in \u03d5 being false. However, AC2(a) is more permissive than the traditional criterion; it allows the dependence of \u03d5 on X to be tested under special structural contingencies, in which the variables ~W are held constant at some setting ~w. AC2(b) is an attempt to counteract the \u201cpermissiveness\u201d of AC2(a) with regard to structural contingencies. Essentially, it ensures that X alone suffices to bring about the change from \u03d5 to \u00ac\u03d5; setting ~W to ~w merely eliminates spurious side effects that tend to mask the action of X .\nTo understand the role of AC2(b), consider the rockthrowing example again. Let M be the model in Figure 1,\nand let ~u be the context where both Suzy and Billy throw. It is easy to see that both Suzy and Billy are causes of the bottle shattering in (M,~u): Let ~Z = {ST, BS}, and consider the structural contingency where Billy doesn\u2019t throw (BT = 0). Clearly (M,U) |= [ST \u2190 0,BT \u2190 0](BS = 0) and (M,u) |= [ST \u2190 1,BT \u2190 0](BS = 1), so Suzy is a cause of the bottle shattering. A symmetric argument shows that Billy is also a cause.\nBut now consider the model M \u2032 described in Figure 2; again, u is the context where both Suzy and Billy throw. It is still the case that Suzy is a cause of the bottle shattering in (M \u2032, u). We can take ~W = {BT} and again consider the contingency where Billy doesn\u2019t throw. However, Billy is not a cause of the bottle shattering in (M \u2032, u). For suppose that we now take ~W = {ST} and consider the contingency where Suzy doesn\u2019t throw. Clearly AC2(a) holds, since if Billy doesn\u2019t throw (under this contingency), then the bottle doesn\u2019t shatter. However, AC2(b) does not hold. Since BH \u2208 ~Z, if we set BH to 0 (its original value), then AC2(b) would require that (M \u2032, u) |= [BT \u2190 1, ST \u2190 0,BH \u2190 0](BS = 1), but this is not the case. Similar arguments show that no other choice of (~Z, ~W ) makes Billy\u2019s throw a cause of the bottle shattering in (M \u2032, u).\nThe original HP definition differs from the updated definition in only one respect. Rather than requiring that (M,~u) |= [ ~X \u2190 ~x, ~W \u2032 \u2190 ~w, ~Z \u2032 \u2190 ~z\u2217]\u03d5 for all subsets ~W \u2032 of ~W , it was required to hold only for ~W . That is, the following condition was used instead of AC2(b).\nAC2(b\u2032) (M,~u) |= [ ~X \u2190 ~x, ~W \u2190 ~w, ~Z \u2032 \u2190 ~z\u2217]\u03d5 for all subsets ~Z \u2032 of ~Z .\nThe requirement for AC2(b) to hold for all subsets of W in the updated definition prevents situations where W \u201cconceals other causes for\u03d5\u201d. The role of this requirement is perhaps best understood by considering the following example, due to Hopkins and Pearl (2003) (the description is taken from (Halpern & Pearl 2005)): Suppose that a prisoner dies either if A loads B\u2019s gun and B shoots, or if C loads and shoots his gun. Taking D to represent the prisoner\u2019s death and making the obvious assumptions about the meaning of the variables, we have that D = (A \u2227B) \u2228C. Suppose that in the actual context u, A loads B\u2019s gun, B does not shoot, but C does load and shoot his gun, so that the prisoner dies. That is, A = 1, B = 0, and C = 1. Clearly C = 1 is a cause of D = 1. We would not want to say that A = 1 is a cause of D = 1, given that B did not shoot (i.e., given that B = 0). However, with AC2(b\u2032), A = 1 is a cause of D = 1. For we can take ~W = {B,C} and consider the contingency where B = 1 and C = 0. It is easy to check that AC2(a) and AC2(b\u2032) hold for this contingency, so under the original HP definition, A = 1 is a cause of D = 1. However, AC2(b) fails in this case, since (M,u) |= [A \u2190 1, C \u2190 0](D = 0). The key point is that AC2(b) says that for A = 1 to be a cause of D = 1, it must be the case that D = 0 if only some of the values in ~W are set to ~w. That means that the other variables get the same value as they do in the actual context; in this case, by setting only A to 1 and leaving B unset,\nB takes on its original value of 0, in which case D = 0. AC2(b\u2032) does not consider this case.\nUsing AC2(b) rather than AC2(b\u2032) has been shown to have a significant benefit (and to lead to more intuitive results) when causality is applied to program verification, with the goal of understanding what in the code is the cause of a program not satisfying its specification (Beer et al. 2012)."}, {"heading": "3 Relevant Complexity Classes", "text": "In this section, we briefly recall the definitions of the complexity classes that we need for our results, and define the complexity class Dk2 .\nRecall that the polynomial hierarchy is a hierarchy of complexity classes that generalize the classes NP and coNP. Let \u03a3P1 = NP and \u03a0 P 1 = co-NP. For i > 1, define \u03a3Pi = NP \u03a3P i\u22121 and \u03a0Pi = (co-NP) \u03a3P\ni\u22121 , where, in general, XY denotes the class of problems solvable by a Turing machine in class A augmented with an oracle for a problem complete for class B. (See (Meyer & Stockmeyer 1972; Stockmeyer 1977) for more details and intuition.)\nWe now define the classes DPk as follows.\nDefinition 3.1 For k = 1, 2, . . .,\nDPk = {L : \u2203L1, L2 : L1 \u2208 \u03a3 P k , L2 \u2208 \u03a0 P k , L = L1 \u2229 L2}.\nFor k = 1, the class DP1 is the well-known complexity class DP , defined by Papadimitriou and Yannakakis (1984). It contains exact problems such as the language of pairs \u3008G, k\u3009, where G is a graph that has a maximal clique of size exactly k. As usual, we say that a language L is DPk complete if it is in DPk and is the \u201chardest\u201d language in D P k , in the sense that there is a polynomial time reduction from any language L\u2032 \u2208 DPk to L.\nRecall that a quantified Boolean formula (QBF) is a generalization of a propositional formula, where some propositional variables are quantified. Thus, for example, \u2203x\u2200y(x\u2228 y) is a QBF. A closed QBF (CQBF) is one where there are no free propositional variables. A CQBF is either true or false, independent of the truth assignment. The \u201ccanonical\u201d languages complete for \u03a3k2 and \u03a0 k 2 consist of the CQBFs with k alternations of quantifiers starting with \u2203 (resp., \u2200) that are true. In particular, let\n\u03a3P2 (SAT) = {\u2203 ~X\u2200~Y \u03d5 | \u2203 ~X\u2200~Y \u03d5 is a CQBF, \u2203 ~X\u2200~Y \u03d5 = true} \u03a0P2 (SAT) = {\u2200 ~X\u2203~Y \u03d5 | \u2200 ~X\u2203~Y \u03d5 is a CQBF, \u2200 ~X\u2203~Y \u03d5 = true}.\n\u03a3P2 (SAT) is complete for \u03a3 P 2 and \u03a0 P 2 (SAT) is complete for \u03a0P2 (Wrathall 1976). The following lemma provides a useful condition sufficient for a language to be DPk -complete.\nLemma 3.2 If L1 is \u03a3Pk -complete and L2 is \u03a0 P k -complete, then L3 = L1 \u2229 L2 is DPk -complete.\nProof: The fact that L3 is in DPk is immediate from the definition of DPk . For hardness, let L \u2032 3 be a language in D P k . Then there exist L\u20321 and L \u2032 2 such that L \u2032 1 \u2208 \u03a3 P k , L \u2032 2 \u2208 \u03a0 P k ,\nand L\u2032 = L\u20321 \u2229 L \u2032 2. Let f be a polynomial-time reduction from L\u20321 to L1, and let g be a polynomial-time reduction from L\u20322 to L2 (the existence of such reductions f and g follows from the fact that L1 and L2 are \u03a3Pk -complete and \u03a0Pk -complete, respectively). Then, \u3008f, g\u3009 is a polynomialtime reduction from L\u20323 to L3, as required.\nEssentially the same argument shows that if L1 is \u03a3Pk -hard and L2 is \u03a0Pk -hard, then L3 = L1 \u2229 L2 is D P k -hard.\nDetermining whether ~X = ~x is a cause of \u03d5 in (M,u) is a decision problem: we define a language and try to determine whether a particular tuple is in that language. (See Section 4 for the formal definition.) Determining degree of responsibility and blame is a different type of problem, since we are determining which number represents the degree of responsibility (resp., blame). Formally, these are function problems. For ease of exposition, we restrict attention to functions from some strings over some fixed language \u03a3 to strings over \u03a3 (i.e., we are considering functions from \u03a3\u2217 to \u03a3\u2217). For a complexity class A in the polynomial hierarchy, FPA[logn] consists of all functions that can be computed by a polynomial-time Turing machine with an A-oracle which on input x asks a total of O(log |x|) queries (Papadimitriou 1984). A function f(x) is FPA[logn]hard iff for every function g(x) in FPA[logn] there exist polynomially computable functions R,S : \u03a3\u2217 \u2192 \u03a3\u2217 such that g(x) = S(f(R(x))). A function f(x) is complete in FPA[logn] iff it is in FPA[logn] and is FPA[logn]-hard.\nFinally, for a complexity class A in polynomial hierarchy, FPA|| is the class of functions that can be computed by a polynomial-time Turing machine with parallel (i.e., non-adaptive) queries to an A-oracle. (For background on these complexity classes, see (Jenner & Toran 1995; Johnson 1990).)"}, {"heading": "4 Complexity for the Updated HP Definition", "text": "In this section, we prove our results on the complexity of deciding causality. We start by defining the problem formally. In the definitions, M stands for a causal model, ~u is a context, ~X is a subset of variables of M , and ~x is the set of values of ~X in (M,~u):\nLcause = {\u3008M,~u, \u03d5, ~X, ~x\u3009 : ( ~X = ~x) is a cause of \u03d5 in (M,~u)}.\nOne of our goals is to understand the cause of the complexity of computing causality. Towards this end, it is useful to define two related languages:\nLAC2 = {\u3008M,~u, \u03d5, ~X, ~x\u3009 : ( ~X = ~x) satisfies conditions AC1 and AC2 of Def. 2.1 for \u03d5 in (M,~u)}, LAC3 = {\u3008M,~u, \u03d5,\n~X, ~x\u3009 : ( ~X = ~x) satisfies conditions AC1 and AC3 of Def. 2.1 for \u03d5 in (M,~u)}.\nIt is easy to see that Lcause = LAC2 \u2229 LAC3. Let L1cause be the subset of Lcause where ~X and ~x are singletons; this is the singleton causality problem. We can similarly define L1AC2 and L 1 AC3. Again, we have L 1 cause =\nL1AC2 \u2229 L 1 AC3, but, in fact, we have L 1 cause = L 1 AC2, since L1AC2 \u2286 L 1 AC3; for singleton causality, the minimality condition AC3 trivially holds. We denote by LBcause the language of causality for binary causal models (i.e., where the models M in the tuple are binary models), and by LBAC2 and L B AC3 the languages LAC2 and LAC3 restricted to binary causal models. Again we have that LBcause = L B AC2 \u2229 L B AC3. And again, we can define LB,1cause, L B,1 AC2, and L B,1 AC3, and we have L B,1 cause = L B,1\nAC2. We start by considering singleton causality. As we observed, Eiter and Lukasiewicz (2002) and Hopkins (2001) showed that, with the original HP definition, singleton causality and causality coincide. However, for the updated definition, Halpern (2008) showed that it is in fact possible to have minimal causes that are not singletons. Thus, we consider singleton causality and general causality separately. We can clarify where the complexity lies by considering LAC2 (and its sublanguages) and LAC3 (and its sublanguages) separately.\nTheorem 4.1 The languages LAC2, L 1 AC2, L\nB,1 AC2, and\nL1AC2 are \u03a3 P 2 -complete.\nProof outline: To show all these languages are in \u03a3P , given a tuple \u3008M,~u, \u03d5, ~X, ~x\u3009, checking that AC1 holds, that is, checking that (M,~u) |= ~X = ~x \u2227 \u03d5, can be done in time polynomial in the size of M , | ~X|, and |\u03d5| (the length of \u03d5 as a string of symbols). For AC2, we need only guess the set ~W and the assignment ~w. The check that assigning ~w to ~W and x\u2032 to X indeed falsifies \u03d5 is polynomial, and we use an NP oracle to check that for all subsets of ~W and all subsets of ~Z , condition AC2(b) holds. (The argument is quite similar to Eiter and Lukasiewicz\u2019s argument that causality is in \u03a3P2 for general models with the original HP definition.)\nFor hardness, it clearly suffices to show that LB,1AC2 is \u03a3 P 2 -\nhard. We do this by reducing \u03a3P2 (SAT) to L B,1 AC2. Given a CQBF formula \u2203 ~X\u2200~Y \u03d5, we show that we can efficiently construct a causal formula \u03c8, model M , and context u such that \u2203 ~X\u2200~Y \u03d5 = true iff (M,u, \u03c8,A, 0) \u2208 LB,1AC2. We leave details to the appendix.\nSince, as we have observed, AC3 is vacuous in the case of singleton causality, it follows that singleton causality is \u03a3P2 -complete.\nCorollary 4.2 L1cause and L B,1 cause are \u03a32-complete.\nWe now show that things are harder if we do not restrict to binary causal models (unless the polynomial hierarchy collapses). As a first step, we consider the complexity of LAC3 and LBAC3.\nTheorem 4.3 LAC3 and L B AC3 are \u03a0 P 2 -complete.\nProof outline: The fact that LAC3 and L B AC3 are in \u03a0 P 2 is straightforward. Again, given a tuple \u3008M,~u, \u03d5, ~X, ~x\u3009, we can check that AC1 holds in polynomial time. For AC3, we need to check that for all strict subsets ~X \u2032 of ~X , AC2 fails.\nSince checking AC2 is in \u03a3P2 , checking that it fails is in \u03a0 P 2 . Checking that it fails for all strict subsets ~X \u2032 keeps it in \u03a0P2 (since it just adds one more universal quantifier).\nTo prove that these languages are \u03a0P2 -hard, we show that we can reduce \u03a0P2 (SAT) to L B AC3. The proof is similar in spirit to the proof of Theorem 4.1; we leave details to the appendix.\nWe are now ready to prove our main result. Theorem 4.4 Lcause and LBcause are D P 2 -complete.\nProof: Membership of Lcause (and hence also LBcause) in DP2 follows from the fact that Lcause = LAC2 \u2229 LAC3, LAC2 \u2208 \u03a3 P 2 , and LAC3 \u2208 \u03a0 P 2 . The fact that L B cause (and hence also Lcause) are DP2 -hard follows from Lemma 3.2 and Theorems 4.1 and 4.3.\nThe fact that there may be more than one conjunct in a cause using the updated HP definition means that checking AC3 becomes nontrivial, and causes the increase in complexity for \u03a3P2 to D P 2 . But why is there no dropoff with the updated HP definition when we restrict to binary models, although there is a dropoff from \u03a3P2 to NP for the original HP definition? To prove their NP-completeness result, Eiter and Lukasiewicz (2002) showed that for binary models, with the original HP definition, the set ~Z and its subsets can be omitted from the definition of cause. That is, we can replace AC2(b\u2032) by\nAC2(b\u2032\u2032) (M,~u) |= [ ~X \u2190 ~x, ~W \u2190 ~w]\u03d5 to get an equivalent definition. The example that a cause may require more than one conjunct given by Halpern (2008) shows that removing ~Z and its subsets from AC2(b) does not result in an equivalent definition in binary models. But even if it did, the fact that we need to quantify over all subset ~W \u2032 of ~W in AC2(b) would be enough to ensure that there is no dropoff in complexity in binary models."}, {"heading": "5 Responsibility and Blame", "text": "In this section, we review the definitions of responsibility and blame and characterize their complexity. See Chockler and Halpern (2004) for more intuition and details."}, {"heading": "5.1 Responsibility", "text": "The definition of responsibility given by Chockler and Halpern (2004) was given based on the original HP definition of causality, and thus assumed that causes were always single conjuncts. It is straightforward to extend it to allow causes to have arbitrarily many conjuncts.\nDefinition 5.1 The degree of responsibility of ~X = ~x for \u03d5 in (M,~u), denoted dr((M,~u), ( ~X = ~x), \u03d5), is 0 if ~X = ~x is not a cause of \u03d5 in (M,~u); it is 1/(k + 1) if ~X = ~x is a cause of \u03d5 in (M,~u) and there exists a partition (~Z, ~W ) and setting (~x\u2032, ~w) for which AC2 holds such that (a) k variables in ~W have different values in ~w than they do in the context ~u and (b) there is no partition (~Z \u2032, ~W \u2032) and setting (~x\u2032\u2032, ~w\u2032) satisfying AC2 such that only k\u2032 < k variables have different values in ~w\u2032 than they do the context ~u.\nIntuitively, dr((M,~u), ( ~X = ~x), \u03d5) measures the minimal number of changes that have to be made in ~u in order to make \u03d5 counterfactually depend on ~X , provided the conditions on the subsets of ~W and ~Z are satisfied (see also the voting example from the introduction). If there is no partition of V to (~Z, ~W ) that satisfies AC2, or ( ~X = ~x) does not satisfy AC3 for \u03d5 in (M,~u), then the minimal number of changes in ~u in Definition 5.1 is taken to have cardinality \u221e, and thus the degree of responsibility of ( ~X = ~x) is 0 (and hence it is not a cause).\nIn the original HP model, it was shown that computing responsibility is FPNP[logn]-complete in binary causal models (Chockler, Halpern, & Kupferman 2008) and FP\u03a3 P 2 [logn]-complete in general causal models (Chockler & Halpern 2004). We now characterize the complexity of computing responsibility in the updated HP definition.\nTheorem 5.2 Computing the degree of responsibility is FP\u03a3 P 2 [logn]-complete for singleton causes in binary and general causal models.\nProof outline: The proof is quite similar to the proof in (Chockler & Halpern 2004). We prove membership by describing an algorithm in FP\u03a3 P 2 [logn]for computing the degree of responsibility. Roughly speaking, the algorithm queries an oracle for the language R = {(\u3008(M,~u), (X = x), \u03d5, i\u3009 such that \u3008(M,~u), (X = x), \u03d5\u3009 \u2208 Lcause and the degree of responsibility of (X = x) for \u03d5 is at least i}. It is easy to see that R is in \u03a3P2 by using Corollary 4.2. The algorithm for computing the degree of responsibility performs a binary search on the value of dr((M,~u), (X = x), \u03d5), each time dividing the range of possible values for the degree of responsibility by 2 according to the answer of R. The number of possible candidates for the degree of responsibility is bounded by the size of the input n, and thus the number of queries is at most \u2308logn\u2309.\nFor hardness in binary causal models (which implies hardness in general causal models), we provide a reduction from the \u03a3P2 -complete problem MINQSAT2 (Chockler & Halpern 2004) to the degree of responsibility, where MINQSAT2(\u2203 ~X\u2200~Y \u03c8) is the minimum number of 1\u2019s in the satisfying assignment to ~X for \u2203 ~X\u2200~Y \u03c8 if such an assignment exists, and | ~X|+ 1 otherwise.\nTheorem 5.3 Computing the degree of responsibility is FPD2[logn]-complete in binary and general causal models.\nProof outline: Membership in FPD2[logn]is shown in quite a similar way to Theorem 5.2. For hardness, as there are no known natural problems complete in FPD2[logn], the proof proceeds by constructing a generic reduction from a problem in FPD2[logn] to the degree of responsibility."}, {"heading": "5.2 Blame", "text": "The definition of blame addresses the situation where there is uncertainty about the true situation or \u201chow the world\nworks\u201d. Blame, introduced in (Chockler & Halpern 2004), considers the \u201ctrue situation\u201d to be determined by the context, and \u201chow the world works\u201d to be determined by the structural equations. An agent\u2019s uncertainty is modeled by a pair (K,Pr), where K is a set of pairs of the form (M,~u), where M is a causal model and ~u is a context, and Pr is a probability distribution over K. A pair (M,~u) is called a situation. We think of K as describing the situations that the agent considers possible before ~X is set to ~x. The degree of blame that setting ~X to ~x has for \u03d5 is then the expected degree of responsibility of ~X = ~x for \u03d5 in (M ~X\u2190~x, ~u), taken over the situations (M,~u) \u2208 K. Note that the situation (M ~X\u2190~x, ~u) for (M,~u) \u2208 K are those that the agent considers possible after ~X is set to ~x.\nDefinition 5.4 The degree of blame of setting ~X to ~x for \u03d5 relative to epistemic state (K,Pr), denoted db(K,Pr, ~X \u2190 ~x, \u03d5), is\n\u2211\n(M,~u)\u2208K\ndr((M ~X\u2190~x, ~u), ~X = ~x, \u03d5) Pr((M,~u)).\nFor the original HP definition of cause, Chockler and Halpern (2004) show that computing the degree of blame is complete in FP\u03a3 P 2\n|| for general and in FP NP || for binary causal\nmodels. Again, with the updated HP definition, the complexity changes.\nTheorem 5.5 The problem of computing blame in recursive causal models is FP\u03a3 P 2\n|| -complete for singleton causes and\nFPD2|| -complete for (general) causes, in binary and general causal models."}, {"heading": "A Proof of Theorem 4.1", "text": "As we oberved in the main part of the paper, membership is straightforward, so we focus here on hardness. For hardness, we describe a reduction from the language \u03a32(SAT) to LB,1AC2. In the process, we work with both propositional formulas with propositional variables, and causal formulas, that use formulas like X = 1 and X = 0. We can think of X as a propositional variable here, where X = 1 denotes that X is true, and X = 0 denotes that x is false. If \u03d5 is a propositional formula, let \u03d5 be the causal formula that results by replacing each occurrence of a propositional variable X by X = 1.\nGiven a CQBF \u2203 ~X\u2200~Y \u03d5, consider the tuple (M,u, \u03c8,A, 0) where M = (U ,V ,R) is a binary causal model and\n\u2022 U = {U};\n\u2022 V = {X0 | X \u2208 ~X} \u222a {X1 | X \u2208 ~X} \u222a {Y | Y \u2208 ~Y }\u222a{A}, where A is a fresh variable that does not appear in ~X or ~Y ;\n\u2022 for all variables V \u2208 ~V , the structural equation is V = U (i.e. all the variables in V are set to the value of U );\n\u2022 u = 0;\n\u2022 \u03c8 = \u03c81 \u2228 (\u03c82 \u2227 \u03c83) where \u03c81, \u03c82, \u03c83 are the following causal formulas:\n\u2013 \u03c81 = \u00ac ( \u2227 X\u2208 ~X(X 0 6= X1) ) ;1 \u2013 \u03c82 = \u00ac(A = 1 \u2227 ~Y = ~1); \u2013 \u03c83 = A = 1\u2228\u03d5[ ~X/ ~X1], where \u03d5[ ~X/ ~X1] is the result of replacing each occurrence of a variable X \u2208 ~X by X1).\nWe prove that \u2203 ~X\u2200~Y \u03d5 = true iff A = 0 is a cause of \u03c8 in (M,u) (which is the case iff (M,u, \u03c8,A, 0) \u2208 LB,1AC2, since AC3 is vacuous for binary models).\nFirst suppose that \u2203 ~X\u2200~Y \u03d5 = true. To show that A = 0 is a cause of \u03c8 in (M,u), we prove that AC1 and AC2 hold.\nClearly AC1 holds: (M,u) |= A = 0 by the definition of FA, and (M,u) |= \u03c8 since (M,u) |= \u03c81, again by the definition of F .\nFor AC2, let ~W = V \u2212{A}. and define ~w as follows. Let \u03c4 be an assignment to the variables in ~X for which \u2200~Y \u03d5 = true. Using ~w(X) to denote the value of X according to ~w, we require that\n\u2022 ~w(X\u03c4(X)) = 1;\n\u2022 ~w(X1\u2212\u03c4(X)) = 0; and\n\u2022 ~w(Y ) = 1.\nFor AC2(a), note that (M,u) |= [A \u2190 1, ~W \u2190 ~w]\u00ac\u03c81 (since ~w assigns different values to X0 and X1 for all X \u2208 ~X) and, since ~w(Y ) = 1 for all Y \u2208 ~Y , we have that (M,u) |= [A \u2190 1, ~W \u2190 ~w]\u00ac\u03c82, so (M,u) |= [ ~A \u2190 1,W \u2190 ~w]\u00ac\u03c8. Thus, AC2(a) holds.\nIt now remains to show that AC2(b) holds. Fix ~W \u2032 \u2286 ~W . We must show that (M,u) |= [A \u2190 0, ~W \u2032 \u2190 ~w]\u03c8. (The condition \u201cfor all ~Z \u2032 \u2286 ~Z \u2212 {A}\u201d is vacuous in this case, since ~Z = {A}.) Since the definition of M guarantees that (M,u) |= [A \u2190 0, ~W \u2032 \u2190 ~w]\u03c8 iff (M,u) |= [ ~W \u2032 \u2190 ~w]\u03c8, we focus on the latter from here on in.\nIf (M,u) |= [ ~W \u2032 \u2190 ~w]\u03c81 , we are done. So suppose that (M,u) |= [ ~W \u2032 \u2190 ~w]\u00ac\u03c81; that is,\n(M,u) |= [ ~W \u2032 \u2190 ~w]\n\n\n\u2227\nX\u2208 ~X\n(X0 6= X1)\n\n . (1)\nIt follows that, for each variable X \u2208 ~X , we have that (M,u) |= [ ~W \u2032 \u2190 ~w](X1 = \u03c4(X)). To see this, note that if \u03c4(X) = 1, then we must have X1 \u2208 ~W \u2032; otherwise, we would have (M,u) |= [ ~W \u2032 \u2190 ~w](X1 = 0 \u2227 X0 = 0), contradicting (1). And if \u03c4(X) = 0, then since ~w(X1) = 0, we must have (M,u) |= [ ~W \u2032 \u2190 ~w](X1 = 0), whether or not X1 \u2208 ~W \u2032, so (M,u) |= [ ~W \u2032 \u2190 ~w]\u03c83. It follows that (M,u) |= [ ~W \u2032 \u2190 ~w]\u03c8, showing that AC2(b) holds.\nFinally, we must show that if A = 0 is a cause of \u03c8 in (M,u) then \u2203 ~X\u2200~Y \u03d5 = true.\n1As usual, we take X0 6= X1 to be an abbreviation for the causal formula (X0 = 1 \u2227X1 = 0) \u2228 (X0 = 0 \u2227X1 = 1).\nSo suppose that A = 0 is a cause of \u03c8 in (M,u). Then there exists a witness ( ~W, ~w, a). Since we are considering binary models, we must have a = 1, so we have\n(M,u) |= [A \u2190 1, ~W \u2190 ~w]\u00ac\u03c8. (2)\nThis implies that (M,u)[A \u2190 1, ~W \u2190 ~w] |= \u00ac\u03c81, so\n(M,u) |= [A \u2190 1, ~W \u2190 ~w]\n\n\n\u2227\nX\u2208 ~X\n(X0 6= X1)\n\n .\nDefine \u03c4 so that \u03c4(X) = b, where b \u2208 {0, 1} is the unique value for which (M,u)[A \u2190 1, ~W \u2190 ~w] |= Xb = 1.\nIt also follows from (2) that\n(M,u) |= [A \u2190 1, ~W \u2190 ~w]\u00ac(\u03c82 \u2227 \u03c83).\nSince clearly (M,u) |= [A \u2190 1, ~W \u2190 ~w]\u03c82, we must have (M,u) |= [A \u2190 1, ~W \u2190 ~w]\u00ac\u03c83. Indeed, we must have\n(M,u) |= [A \u2190 1, ~W \u2190 ~w](~Y = ~1).\nIt follows that Y \u2208 ~W and ~w(Y ) = 1 for all y \u2208 ~Y . Now let \u03bd be an assignment to ~X and ~Y such that \u03bd| ~X = \u03c4 . It cleary suffices to show that \u03d5 is true under assignment \u03c4 . Let ~W \u2032 = ~W\u2212{Y \u2208 ~Y | \u03bd(Y ) = 0}; that is, ~W \u2032 contains all the variables Xb that are in ~W , and all the variables Y \u2208 ~Y for which \u03bd(Y ) = 1. By AC2(b), it follows that (M,u) |= [ ~W \u2032 \u2190 ~w]\u03c8. Since ~W \u2032 contains all the variables Xb in ~W , we have that (M,u) |= [ ~W \u2032 \u2190 ~w]\u00ac\u03c81. Thus, we must have that (M,u) |= [ ~W \u2032 \u2190 ~w]\u03c83. Since (M,u) |= [ ~W \u2032 \u2190 ~w](A = 0), it follows that (M,u) |= [ ~W \u2032 \u2190 ~w]\u03d5[ ~X/ ~X1].\nNote that, for Y \u2208 ~Y ~w(Y ) = 1 iff \u03bd(Y ) = 1; moreover, ~w(X1) = 1 iff \u03c4(X) = 1 iff \u03bd(X) = 1. Thus, the fact that (M,u) |= [ ~W \u2032 \u2190 ~w]\u03c83 implies that \u03d5 is satisfied by \u03bd, so we are done.\nThis completes the proof of the theorem."}, {"heading": "B Proof of Theorem 4.3", "text": "Again, as we oberved in the main part of the paper, membership is straightforward, so we focus on hardness. We describe a reduction from the language \u03a02(SAT) to LBAC3, which suffices to prove the result. The argument is similar in spirit to that for Theorem 4.1.\nGiven a CQBF \u2200~Y \u2203 ~X\u03d5, consider the tuple (M,u, \u03c8, \u3008A1, A2\u3009, \u30080, 0\u3009) where M = (U ,V ,R) is a binary causal model and\n\u2022 U = {U};\n\u2022 V = ~X \u222a {Y 0 | Y \u2208 ~Y } \u222a {Y 1 | Y \u2208 ~Y } \u222a {A1, A2, S}, where A1, A2, and S are fresh variables;\n\u2022 the structural equations for A1 and A2 are A1 = S and A2 = S, and, for all other variables V \u2208 V , the equation is V = U ;\n\u2022 u = 0;\n\u2022 \u03c8 = \u03c81 \u2228 (\u03c82 \u2227 \u03c83) \u2228 (S = 0) where\n\u2013 \u03c81 = \u00ac ( \u2227 Y \u2208~Y (Y 0 6= Y 1) ) ; \u2013 \u03c82 = \u00ac( ~A = 1 \u2227 ~X = 1);\n\u2013 \u03c83 = (A1 = A2) \u2228 \u00ac\u03d5[~Y /~Y 1].\nWe prove that \u2200~Y \u2203 ~X\u03d5 = true iff (M,u, \u03c8, ~A,~0) is in LBAC3.\nFirst suppose that \u2200~Y \u2203 ~X\u03d5 = true. To show that (M,u, \u03c8, ~A,~0) is in LBAC3, we must prove that AC1 and AC3 hold.\nFor AC1, since (M,u) |= ~Y 0 = ~Y 1 = ~0, we clearly have (M,u) |= \u03c81, so (M,u) |= ( ~A = ~0) \u2227 \u03c8.\nTo show that AC3 holds, we need to show that neither A1 = 0 nor A2 = 0 is a cause of \u03c8 in (M,u). We prove that A1 = 0 is not a cause of \u03c8 in (M,u); the argument for A2 = 0 not being a cause is identical.\nIt suffices to prove that AC2 does not hold. So suppose by way of contradiction that ( ~W, ~w, 1) is a witness for A1 being a cause of \u03c8 in (M,u). Since AC2(a) holds, we must have\n(M,u) |= [A1 \u2190 1, ~W \u2190 ~w](\u00ac\u03c81\u2227(\u00ac\u03c82\u2228\u00ac\u03c83)\u2227(S = 1)). (3) Thus, S \u2208 ~W and ~w(S) = 1 (for otherwise (M,u) |= [A1 \u2190 1, ~W \u2190 ~w](S = 0)). Moreover, since (M,u) |= [A1 \u2190 1, ~W \u2190 ~w]\u00ac\u03c81, for all Y \u2208 ~Y , either Y 0 \u2208 ~W and ~w(Y 0) = 1 or Y 1 \u2208 ~W and ~w(Y 1) = 1, and it is not the case that both Y 0 and Y 1 are in ~W and ~w(Y 0) = ~w(Y 1).\nNow consider A2. There are three possibilities:\n(a) A2 \u2208 ~W and ~w(A2) = 0;\n(b) A2 \u2208 ~W and ~w(A2) = 1;\n(c) A2 /\u2208 ~W .\nWe show that we get a contradiction in each case. If (a) holds, note that since\n(M,u) |= [A1 \u2190 1, ~W \u2190 ~w](A2 = 0),\nit follows that (M,u) |= [A1 \u2190 1, ~W \u2190 ~w]\u03c82, so by (3), (M,u) |= [A1 \u2190 1, ~W \u2190 ~w]\u00ac\u03c83. Moreover, since (M,u) |= [A1 \u2190 1, ~W \u2190 ~w](A1 6= A2) \u2227 \u00ac\u03c83, it follows that (M,u) |= [A1 \u2190 1, ~W \u2190 ~w]\u03d5[~Y /~Y 1].\nLet Z \u2032 = \u2205 and let ~W \u2032 = ~W \u2212 {A2}. We show that (M,u) |= [A1 \u2190 0, ~W\n\u2032 \u2190 ~w]\u00ac\u03c8, so that AC2(b) does not hold. First observe that (M,u) |= [ ~W \u2032 \u2190 ~w](A1 6= A2). Since S and all the variables in ~X , ~Y 0, and ~Y 1 are in both ~W \u2032 and ~W , it follows from (3) that\n(M,u) |= [A1 \u2190 0, ~W \u2032 \u2190 ~w](\u00ac\u03c81\u2227\u03d5[~Y /~Y 1]\u2227 (S = 1)).\nThus, (M,u) |= [A1 \u2190 0, ~W \u2032 \u2190 ~w]\u00ac\u03c8, and AC2(b) does not hold.\nIf (b) or (c) hold, define an assignment \u03bd to the variables in ~Y by taking \u03bd(Y ) = 1 if Y 1 \u2208 ~W and ~w(Y 1) = 1 and \u03bd(Y ) = 0 if Y 0 \u2208 ~W and ~w(Y 0) = 1. (As we observed above, exactly one of these two cases occurs, so \u03bd is well\ndefined.) By assumption, \u2200~Y \u2203 ~X\u03d5 = true, so there exists an assignment \u03c4 to ~X that makes \u03d5 true if the assignment to ~Y is determined by \u03bd.\nWe again show that AC2(b) does not hold. Let Z \u2032 = \u2205 and let ~W \u2032 = ~W \u2212 {X : \u03c4(X) = 0}. Since S \u2208 ~W \u2032 and ~w(S) = 1, it is easy to see that in both case (b) and (c), we have (M,u) |= [A1 \u2190 0, ~W \u2032 \u2190 ~w](A1 6= A2). (In case (b), this is becaause ~w(A2) = 1; in case (c), this is because we have the equation A2 = S and ~w(S) = 1). The definition of ~W \u2032 ensures that\n(M,u) |= [A1 \u2190 0, ~W \u2032 \u2190 ~w]\u03d5[~Y /~Y 1],\nso that (M,u) |= [A1 \u2190 0, ~W \u2032 \u2190 ~w]\u00ac\u03c83, and hence also (M,u) |= [A1 \u2190 0, ~W \u2032 \u2190 ~w]\u00ac\u03c8, again showing that AC2(b) does not hold. We conclude that AC3 holds for ~A.\nNow suppose that (M,u, \u03c8, ~A,~0) is in LBAC3. We must show that \u2200~Y \u2203 ~X\u03d5( ~X, ~Y ) = true. Let \u03bd be some assignment to ~Y . Let ~W = {S} \u222a ~X \u222a ~Y 0 \u222a ~Y 1 and define ~w as follows:\n\u2022 ~w(S) = 1;\n\u2022 ~w(X) = 1 for all X \u2208 ~X;\n\u2022 ~w(Y \u03bd(y)) = 1 and ~w(Y 1\u2212\u03bd(y)) = 0 for all Y \u2208 ~Y .\nSince AC3 holds, A1 \u2190 0 cannot be a cause of \u03c8 in (M,u) with witness ( ~W , ~w, 1). It is straightforward to check that (M,u) |= [A1 \u2190 1, ~W \u2190 ~w]\u00ac\u03c8, using the fact that ~w(S) = 1. Hence, AC2(a) holds for A1 \u2190 0. AC3 holds trivially, and we have already observed that A1 holds. Thus, AC2(b) cannot hold for A2 \u2190 0, that is, there exist ~W \u2032 \u2286 ~W and ~Z \u2032 \u2286 {A2} such that (M,u) |= [A1 \u2190 0, ~W \u2032 \u2190 ~w, ~Z \u2032 \u2190 ~z\u2217]\u00ac\u03c8. It follows that\n\u2022 S \u2208 ~W \u2032 and ~w(S) = 1; and\n\u2022 either Y 0 \u2208 ~W \u2032 and ~w(Y 0) = 1 or Y 1 \u2208 ~W \u2032 and ~w(Y 1) = 1, and it is not the case that both Y 0 and Y 1\nare in ~W \u2032 and ~w(Y 0) = ~w(Y 1).\nSince (M,u) |= [A1 \u2190 0, ~W \u2032 \u2190 ~w, ~Z \u2032 \u2190 ~z\u2217]\u03c82, it must be the case that (M,u) |= [A1 \u2190 0, ~W \u2032 \u2190 ~w, ~Z \u2032 \u2190 ~z\u2217]\u00ac\u03c83. This, in turn, implies that (M,u) |= [A1 \u2190 0, ~W \u2032 \u2190 ~w, ~Z \u2032 \u2190 ~z\u2217]\u03d5[~Y /~Y 1]. Now (M,u) |= [ ~A\u2032 \u2190 ~a\u2032, ~W \u2032 \u2190 ~w, ~Z \u2032 \u2190 ~z\u2217]\u03c82. Thus, we must have (M,u) |= [ ~A\u2032 \u2190 ~a\u2032, ~W \u2032 \u2190 ~w, ~Z \u2032 \u2190 ~z\u2217]\u00ac\u03c83; thus, (M,u) |= [ ~A\u2032 \u2190 ~a\u2032, ~W \u2032 \u2190 ~w, ~Z \u2032 \u2190 ~z\u2217]\u03d5[~Y /~Y 1]. Now define \u03c4(X) = 1 iff X \u2208 ~W \u2032. It is immediate that \u03c4 satisfies \u03d5 if the values of Y are assigned according to \u03bd. It follows that \u2200~Y \u2203 ~X\u03d5( ~X, ~Y ) = true, as desired.\nAcknowledgements: Joseph Halpern was supported in part by NSF grants IIS-0911036 and CCF-1214844, AFOSR grant FA9550-08-1-0438, ARO grant W911NF-14-1-0017, and by the DoD Multidisciplinary University Research Initiative (MURI) program administered by AFOSR under grant FA9550-12-1-0040."}], "references": [], "referenceMentions": [], "year": 2014, "abstractText": "Halpern and Pearl introduced a definition of actual causality; Eiter and Lukasiewicz showed that computing whether X = x is a cause of Y = y is NP-complete in binary models (where all variables can take on only two values) and \u03a3P2 complete in general models. In the final version of their paper, Halpern and Pearl slightly modified the definition of actual cause, in order to deal with problems pointed by Hopkins and Pearl. As we show, this modification has a nontrivial impact on the complexity of computing actual cause. To characterize the complexity, a new family D k , k = 1, 2, 3, . . ., of complexity classes is introduced, which generalizes the class D introduced by Papadimitriou and Yannakakis (D is just D 1 ). We show that the complexity of computing causality under the updated definition is D 2 -complete. Chockler and Halpern extended the definition of causality by introducing notions of responsibility and blame. The complexity of determining the degree of responsibility and blame using the original definition of causality was completely characterized. Again, we show that changing the definition of causality affects the complexity, and completely characterize it using the updated definition.", "creator": "LaTeX with hyperref package"}}}