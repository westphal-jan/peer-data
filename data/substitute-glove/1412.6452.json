{"id": "1412.6452", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Dec-2014", "title": "Algorithmic Robustness for Learning via $(\\epsilon, \\gamma, \\tau)$-Good Similarity Functions", "abstract": "The importance addition optimize in engine learning that primarily turned growing continue that loop part similarity emphasizes, others especially the Mahalanobis stretching. However, to meaning worth emphasized they this research field lacks methodology mandate that supposed be come new the dynamical fully seen while classifier associated to a worked metric. The phenomenological framework a $ (\\ pilipino, \\ excitation, \\ tau) $ - much distinct functions has been one of present 1995 attempts also draw a to end followed are main each context formula_4 used those from a discrete talian coming use since far. In as ink, we return this abstract over for new outside form metric such it separator smaller jointly know in from set - supervised that. We understood enabling a generalization bound for the press classifier based next own algorithmic meaningfulness framework. The behavior known everyone parameters is illustrated via without biology failure.", "histories": [["v1", "Fri, 19 Dec 2014 17:43:26 GMT  (106kb,D)", "http://arxiv.org/abs/1412.6452v1", "ICLR 2015 conference submission - under review"], ["v2", "Fri, 27 Feb 2015 15:36:14 GMT  (196kb,D)", "http://arxiv.org/abs/1412.6452v2", "ICLR 2015 conference submission - under review"], ["v3", "Tue, 31 Mar 2015 11:10:43 GMT  (27kb)", "http://arxiv.org/abs/1412.6452v3", "ICLR 2015 Workshop - accepted"]], "COMMENTS": "ICLR 2015 conference submission - under review", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["maria-irina nicolae", "marc sebban", "amaury habrard", "\\'eric gaussier", "massih-reza amini"], "accepted": false, "id": "1412.6452"}, "pdf": {"name": "1412.6452.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Amaury Habrard", "Hubert Curien"], "emails": ["Maria.Irina.Nicolae@univ-st-etienne.fr", "Marc.Sebban@univ-st-etienne.fr", "Amaury.Habrard@univ-st-etienne.fr", "Eric.Gaussier@imag.fr", "Massih-Reza.Amini@imag.fr"], "sections": [{"heading": "1 INTRODUCTION", "text": "Many researchers have used the underlying geometry of the data to improve classification algorithms, e.g. by learning Mahanalobis distances instead of the standard Euclidean distance, thus paving the way for a new research area termed metric learning (Bellet et al., 2013). Most of these studies have based their approaches on distance learning (Baoli et al., 2004; Davis et al., 2007; Diligenti et al., 2003; Shalev-Shwartz et al., 2004; Weinberger & Saul, 2009), even though similarity learning has also attracted a growing interest (Bao et al. (2003); Grabowski & Sza\u0142as (2005); Hust (2004); Qamar & Gaussier (2009)), the rationale being that the cosine similarity should in some cases be preferred over the Euclidean distance. More recently, Balcan et al. (2008) have proposed the first framework that allows one to relate similarities with a classification algorithm making use of them. This framework, that is very general as it can be used with any bounded similarity function (potentially derived from a distance), provides generalization guarantees on a linear classifier learned from the similarity. Their algorithm, whose formulation is equivalent to a relaxed L1-norm SVM (Zhu et al., 2003), does not enforce the positive definiteness constraint of the similarity. However, to enjoy such generalization guarantees, the similarity function is assumed to be known beforehand and to satisfy ( , \u03b3, \u03c4)-goodness properties. Unfortunately, Balcan et al. (2008) do not provide any algorithm for learning such similarities.\nIn order to overcome these limitations, Bellet et al. (2012) have explored the possibility of independently learning an ( , \u03b3, \u03c4)-good similarity that they plug into the initial algorithm (Balcan et al., 2008) to learn the linear separator. Generalization bounds for the learned similarity (a bilinear similarity) were derived via uniform stability arguments (Bousquet & Elisseeff, 2002). However, despite good results in practice, one limitation of this framework is that it imposes to deal with strongly convex objective functions. More importantly, the similarity learning step is done in a completely supervised way while Balcan et al. (2008)\u2019s framework opens the door to the use of unlabeled data.\nar X\niv :1\n41 2.\n64 52\nv1 [\ncs .L\nG ]\n1 9\nD ec\nIn this paper, we aim at better exploiting the semi-supervised setting underlying the theoretical framework of Balcan et al. (2008), which is based on similarities between labeled data and unlabeled reasonable points (roughly speaking, the reasonable points play the same role as that of support vectors in SVMs). Furthermore, and unlike Bellet et al. (2012), we propose here to jointly learn the metric and the classifier, so that both the metric and the separator are learned in a semisupervised way. Enforcing ( , \u03b3, \u03c4)-goodness allows us to preserve (Balcan et al., 2008)\u2019s theoretical guarantees. Lastly, proving the algorithmic robustness (Xu & Mannor, 2010; 2012) of our method leads to consistency bounds for different kinds of similarity functions.\nThe remainder of this paper is organized as follows: Section 2 reviews some previous results in metric and similarity learning and presents the theory of ( , \u03b3, \u03c4)-good similarities. Section 3 introduces our method that jointly learns the metric and the linear classifier, followed by generalization guarantees for our formulation. We show how to integrate different similarity functions in our setting. Finally, Section 4 features an experimental study on various standard datasets."}, {"heading": "2 NOTATIONS AND RELATED WORK", "text": "We denote vectors by lower-case bold symbols (x) and matrices by upper-case bold symbols (A). Consider the following learning problem: we are given access to labeled examples z = (x, l(x)) drawn from some unknown distribution P over X \u00d7 Y , where X \u2286 Rd and Y = {\u22121, 1} are respectively the instance and the output spaces. A pairwise similarity function over X is defined as K : X \u00d7 X \u2192 [\u22121, 1], and the hinge loss as [c]+ = max(0, 1 \u2212 c). We denote the L1 norm by || \u00b7 ||1, the L2 norm by || \u00b7 ||2 and the Frobenius norm by || \u00b7 ||F . Metric learning aims at finding the parameters of a distance or similarity function that best satisfy the underlying geometry of the data. This information is usually expressed as pair-based (x and x\u2032 should be (dis)similar) or triplet-based constraints (x should be more similar to x\u2032 than to x\u2032\u2032). Typically, the learned metric takes the form of a matrix and is the result of solving an optimization problem.\nThe approaches that have received the most attention in this field involve learning a Mahalanobis distance, defined as dA(x,x\u2032) = \u221a (x\u2212 x\u2032)TA(x\u2212 x\u2032). The distance is parameterized by the symmetric and positive semi-definite (PSD) matrix A \u2208 Rd\u00d7d. This method has attracted a lot of interest due to its interpretability: the Mahalanobis distance implicitly corresponds to computing the Euclidean distance after linearly projecting the data to a different (possibly lower) feature space. The PSD constraint on A ensures dA is a proper metric. Note that setting A as the identity matrix gives the Euclidean distance. In this context, Large Margin Nearest Neighbors (LMNN) (Weinberger & Saul, 2008; 2009) is one of the most widely-used Mahalanobis distance learning methods. The constraints they use are pair- and triplet-based, derived from each instance\u2019s nearest neighbors. The optimization problem they solve is convex and has a special-purpose solver. The algorithm works well in practice, but is sometimes prone to overfitting due to the absence of regularization, especially when dealing with high dimensional data. Another limitation is that enforcing the PSD constraint on A is computationally expensive. One can partly get around this latter shortcoming by making use of specific solvers or using information-theoretic approaches, such as ITML (Davis et al., 2007). This work was the first one to use LogDet divergence for regularization, and thus provides an easy and cheap way for ensuring that A is a PSD matrix. However, the learned metric A strongly depends on the initial value A0, which is an important shortcoming, as A0 is handpicked.\nMore generally, Mahalanobis distance learning faces two main limitations. The first one is that enforcing the PSD and symmetry constraints on A, beyond the cost it induces, often rules out natural similarity functions for the problem at hand. Secondly, although one can experimentally notice that state of the art Mahalanobis distance learning methods give better accuracy than using the Euclidean distance, no theoretical guarantees are provided to establish a link between the quality of the metric and the behavior of the classifier that makes use of it. In this context, Balcan et al. (2008) introduced a theory for learning with so called ( , \u03b3, \u03c4)-good similarity functions based on non PSD matrices. This was the first stone to establish generalization guarantees for a linear classifier that would be learned by making use of such similarities. They derived all their results based on the following definition of a good metric.\nDefinition 1. (Balcan et al., 2008) K is a ( , \u03b3, \u03c4)-good similarity function in hinge loss for a learning problem P if there exists a random indicator function R(x) defining a probabilistic set of \u201dreasonable points\u201d such that the following conditions hold:\n1. We have E(x,l(x))\u223cP [ [1\u2212 l(x)g(x)/\u03b3]+ ] \u2264 , (1)\nwhere g(x) = E(x\u2032,l(x\u2032),R(x\u2032)) [l(x\u2032)K(x,x\u2032)|R(x\u2032)].\n2. Prx\u2032(R(x\u2032)) \u2265 \u03c4 .\nThis definition imposes a constraint on the mass of reasonable points one must consider (greater than \u03c4 ). It also expresses the tolerated margin violations in an averaged way: a (1 \u2212 ) proportion of examples x are on average 2\u03b3 more similar to random reasonable examples x\u2032 of their own label than to random reasonable examples x\u2032 of the other label. This allows for more flexibility than pair- or triplet-based constraints. Notice that no constraint is imposed on the form of the similarity function. Definition 1 can then be used to learn well: Theorem 1. (Balcan et al., 2008) Let K be an ( , \u03b3, \u03c4)-good similarity function in hinge loss for a learning problem P. For any 1 > 0 and < \u03b4 < \u03b3 1/4 let S = {x\u20321,x\u20322, . . . ,x\u2032du} be a sample of du = 2 \u03c4 ( log(2/\u03b4) + 16 log(2/\u03b4)( 1\u03b3)2 ) landmarks drawn from P. Consider the mapping \u03c6S : X \u2192 Rdu defined as follows: \u03c6Si (x) = K(x,x \u2032 i), i \u2208 {1, . . . , du}. With probability 1 \u2212 \u03b4 over the random sample S, the induced distribution \u03c6S(P ) in Rdu , has a separator achieving hinge loss at most + 1 at margin \u03b3.\nIn other words, ifK is ( , \u03b3, \u03c4)-good according to Definition 1 and enough points are available, there exists a linear separator \u03b1 with error arbitrarily close to in the space \u03c6S . The procedure for finding the separator involves two steps: first using du potentially unlabeled examples as landmarks to construct the feature space, then using a new labeled set of size dl to estimate \u03b1 \u2208 Rdu . This is done by solving the following optimization problem:\nmin \u03b1 dl\u2211 i=1 1\u2212 du\u2211 j=1 \u03b1j l(xi)K(xi,xj)  +\n(2)\ns.t. du\u2211 j=1 |\u03b1j | \u2264 1/\u03b3.\nNote that this problem can be solved efficiently by linear programming. Also, as the problem is L1-constrained, tuning the value of \u03b3 will produce a sparse solution. The main limitation of this approach is that the similarity function K is predefined and Balcan et al. (2008) did not provide any learning algorithm to design ( , \u03b3, \u03c4)-good similarities.\nThis problem has been fixed by Bellet et al. (2012) who optimized the ( , \u03b3, \u03c4)-goodness of a bilinear similarity function under Frobenius norm regularization. The learned metric is then used to build a global linear classifier for which Theorem 1 holds. Moreover, their algorithm comes with a uniform stability proof which allows them to derive a bound on the generalization error of the associated classifier. Their formulation is strongly convex w.r.t. the metric and takes the following form:\nmin A\n1\ndl dl\u2211 i=1\n[ 1\u2212 1\n\u03b3dr dr\u2211 k=1 l(xi)l(xk)KA(xi,xk) ] + + \u03b2||A||2F , (3)\nwhere KA(x,x\u2032) = xTAx\u2032 is the bilinear similarity.\nIt is worth noticing that Equation (3) optimizes an empirical version of the notion of ( , \u03b3, \u03c4)goodness of Balcan et al. (2008). Moreover, since the random indicator function R(x) defining the probabilistic set of reasonable points (as defined in Equation (1)) is unknown, Bellet et al. (2012) resort to an additional set of dr labeled points that are also used during the classifier learning step.\nSaid differently, they do not exploit the unsupervised setting offered by Problem (2) that does not require to have access to the labels of the du landmarks.\nMore recently, Guo & Ying (2013) extended the theoretical results of Bellet et al. (2012). Using the Rademacher complexity (instead of the uniform stability) and Khinchin-type inequalities, they derive generalization bounds for similarity learning formulations that are regularized w.r.t. more general matrix-norms including the L1 and the mixed L(2,1)-norms. Moreover, they show that such bounds for the learned similarities can be used to upper bound the true risk of a linear SVM. There are three main distinctions between this approach and our work. Firstly, we propose a method that jointly learns the metric and the linear separator at the same time. This allows us to make use of the semi-supervised setting presented by Balcan et al. (2008) to learn well with only a small amount of labeled data. Secondly, our setting uses the algorithmic robustness to establish bounds. This way to proceed enables us to characterize some properties of our algorithm by exploiting the geometry of the (possibly unlabeled) data that is not the case with the Rademacher complexity. Lastly, our setting does not regularize the metric for reasons that will be explained in the following sections. We thus obtain a simpler formulation with less hyper-parameters."}, {"heading": "3 LEARNING CONSISTENT GOOD SIMILARITY FUNCTIONS", "text": "In this section, we present our semi-supervised framework for jointly learning a similarity function and a linear separator from data. We also provide a generalization bound for our approach based on the recent algorithmic robustness framework proposed by Xu & Mannor (2010; 2012). We end this section by presenting some particular similarity functions that can be used in our setting."}, {"heading": "3.1 OPTIMIZATION PROBLEM", "text": "Let S be a sample set of dl labeled examples (x, l(x)) \u2208 Z = X \u00d7 Y and du \u2208 X unlabeled examples. We assume that ||x||2 \u2264 1. All the unlabeled samples are considered reasonable (\u03c4 = 1). Let KA(x,x\u2032) be a generic ( , \u03b3, \u03c4)-good similarity function, parameterized by the matrix A \u2208 Rd\u00d7d. We want to optimize the goodness of KA w.r.t. the empirical loss of a finite sample. To this end, we must find the matrix A and the global separator \u03b1 \u2208 Rdu that minimize the loss function (in our case, the hinge loss) over the training set S. Our learning algorithm takes the form of the following constrained optimization problem.\nmin \u03b1,A\n1\ndl dl\u2211 i=1 1\u2212 du\u2211 j=1 \u03b1j l(xi)KA(xi,xj)  +\n(4)\ns.t. du\u2211 j=1 |\u03b1j | \u2264 1/\u03b3 (5)\nA diagonal (6) |Akk| \u2264 1, 1 \u2264 k \u2264 d (7)\nThe novelty of this algorithm is the joint optimization over A and \u03b1: by solving problem (4), we are learning the metric and the separator at the same time. A significant advantage of this formulation is that it extends the semi-supervised setting from the separator learning step to the metric learning, and the two problems are solved using the same data. This method can naturally be used in situations where one has access to few labeled examples and many unlabeled ones: the labeled examples are used in this case to select the unlabeled examples that will serve to classify new points. Another important advantage of our technique is that the constraints on the pair of points do not need to be satisfied entirely, as the loss is averaged on all the reasonable points. In other words, this formulation is less restrictive than pair or triplet-based settings.\nConstraint (5) takes into account the desired margin \u03b3 and is the same as in Balcan et al. (2008). Constraints (6) and (7) come to restrict the similarity KA, as it is a generic form and its bounds are not known. This setting allows to preserve the ( , \u03b3, \u03c4)-goodness of KA. Constraining the values in the matrix A limits the risk of overfitting, and thus plays a similar role to regularization.\nAnother argument in favor of this formulation is that regularizing the metric through standard L1 or L(1,2) norms would slowly push the values in the matrix towards zero, while sparsity is not necessarily a wanted feature. Indeed, let f(x) = \u2211du j=1 \u03b1jKA(x,xj) be the output of the linear separator w.r.t. x. For some linear similarities KA(x, x\u2032), such as the bilinear form KA(x,x\u2032) = xTAx\u2032, computing f(x) boils down to calculating the similarity between x and the barycenter of the (weighted) unlabeled points, making sparsity superfluous."}, {"heading": "3.2 CONSISTENCY GUARANTEES", "text": "We now present a theoretical analysis of our approach. For the purpose of discussing the algorithmic robustness of the method, let us rewrite the minimization problem (4) with a more generalized notation of the loss function:\nmin 1\ndl dl\u2211 i=1 `(A,\u03b1, zi = (xi, l(xi))),\nwhere\n`(A,\u03b1, zi = (xi, l(xi))) = 1\u2212 du\u2211 j=1 \u03b1j l(xi)KA(xi,xj)  +\nis the instantaneous loss estimated at point (xi, l(xi)). Therefore, the optimization problem (4) under constraints (5), (6) and (7) reduces to minimizing the empirical loss R\u0302` = 1dl \u2211dl i=1 `(A,\u03b1, zi) over the training set S. To begin with, let us recall the notion of robustness of an algorithm A. Definition 2 (Algorithmic Robustness (Xu & Mannor, 2010; 2012)). Algorithm A is (M, (\u00b7))- robust, for M \u2208 N and (\u00b7) : Zdl \u2192 R, if Z can be partitioned into M disjoint sets, denoted by {Ci}Mi=1, such that the following holds for all S \u2208 Zdl :\n\u2200z = (x, l(x)) \u2208 S,\u2200z\u2032 = (x\u2032, l(x\u2032)) \u2208 Z,\u2200i \u2208 [M ] : if z, z\u2032 \u2208 Ci, then |`(A,\u03b1, z)\u2212 `(A,\u03b1, z\u2032)| \u2264 (S).\nThis notion is a desired property of a learning algorithm, as it implies a lack of sensitivity to small perturbations in the training data in the same sense as robust optimization.\nRoughly speaking, an algorithm is robust if for any example z\u2032 falling in the same subset as a training example z, the gap between the losses associated with z and z\u2032 is bounded (see Figure 1). In other words, robustness characterizes the capability of an algorithm to perform similarly on close train and test instances. The closeness of the instances is based on a partitionning of Z in the sense that two examples are close if they belong to the same region. In general, the partition is based on the notion of covering number (Kolmogorov & Tikhomirov, 1961) allowing one to cover Z by regions where the distance/norm between two elements in the same region are no more than a fixed quantity \u03c1. The covering is built as follows: first we consider a \u03c1-cover over the instance X , then we partition Z by considering one \u03c1-cover over X for the positive instances and another \u03c1-cover over X for the negative instances ensuring that two examples in the same region belong to the same class and the distance between them is no more than \u03c1 (Xu & Mannor (2010; 2012) for details). Note that with this construction the \u03c1-covers verify the cluster assumption used in semi-supervised learning (Chapelle et al., 2006).\nNow we can state the first theoretical contribution of this paper. Theorem 2. Given a partition of Z into M subsets {Ci} such that z = (x, l(x)) and z\u2032 = (x\u2032, l(x\u2032)) \u2208 Ci and l(x) = l(x\u2032), and provided thatKA(x,x\u2032) is l-lipschitz w.r.t. its first argument, the optimization problem (4) with constraints (5), (6) and (7) is (M, (S))-robust with (S) = 1\u03b3 l\u03c1, where \u03c1 = supx,x\u2032\u2208Ci ||x\u2212 x \u2032||.\nProof of Theorem 2.\n|`(A,\u03b1, z)\u2212 `(A,\u03b1, z\u2032)| \u2264 \u2223\u2223\u2223\u2223\u2223\u2223 du\u2211 j=1 \u03b1j l(x \u2032)KA(x \u2032,xj)\u2212 du\u2211 j=1 \u03b1j l(x)KA(x,xj) \u2223\u2223\u2223\u2223\u2223\u2223 (8)\n= \u2223\u2223\u2223\u2223\u2223\u2223 du\u2211 j=1 \u03b1j(KA(x \u2032,xj)\u2212KA(x,xj)) \u2223\u2223\u2223\u2223\u2223\u2223 \u2264\ndu\u2211 j=1 |\u03b1j | \u00b7 |KA(x\u2032,xj)\u2212KA(x,xj)| (9)\n\u2264 du\u2211 j=1 |\u03b1j | \u00b7 l||x\u2212 x\u2032|| \u2264 1 \u03b3 l\u03c1 (10)\nSetting \u03c1 = supx,x\u2032\u2208Ci ||x \u2212 x \u2032||1, we get the Theorem. We get Inequality (8) from the 1- lipschitzness of the hinge loss; Inequality (9) comes from the classical triangle inequality; The first inequality on line (10) is due to the l-lipschitzness of KA(x,xj) w.r.t. its first argument, and the result follows from Condition (5).\nWe now give a PAC generalization bound on the true loss making use of the previous robustness result. Let R` = Ez\u223cZ`(A,\u03b1, z) be the true loss w.r.t. the unknown distribution Z and R\u0302` = 1dl \u2211dl i=1 `(A,\u03b1, zi) be the empirical loss over the training set S. Based on the results of Xu & Mannor (2010; 2012), the proof requires the use of the following concentration inequality over multinomial random variables allowing one to capture statistical information coming from the different regions of the partition of Z . Proposition 3. (van der Vaart & Wellner, 1996) Let (|N1|, . . . , |NM |) an i.i.d. multinomial random variable with parameters dl =\u2211M i=1 |Ni| and (p(C1), . . . , p(CM )). By the Bretagnolle-Huber-Carol inequality we have:\nPr {\u2211M\ni=1 \u2223\u2223\u2223 |Ni|dl \u2212 p(Ci)\u2223\u2223\u2223 \u2265 \u03bb} \u2264 2M exp(\u2212dl\u03bb22 ), hence with probability at least 1\u2212 \u03b4, M\u2211 i=1 \u2223\u2223\u2223\u2223Nidl \u2212 p(Ci) \u2223\u2223\u2223\u2223 \u2264 \u221a 2M ln 2 + 2 ln(1/\u03b4) dl . (11)\nWe are now able to present our generalization bound thanks to the following theorem.\nTheorem 4. Considering that problem (4) is (M, (S))-robust, and that KA is l-lipschitz w.r.t. to its first argument, for any \u03b4 > 0 with probability at least 1\u2212 \u03b4, we have:\n|R` \u2212 R\u0302`| \u2264 1 \u03b3 l\u03c1+B\n\u221a 2M ln 2 + 2 ln(1/\u03b4)\ndl ,\nwhere B = 1 + 1\u03b3 is an upper bound of the loss `.\nThe proof of Theorem 4 follows the one described in Xu & Mannor (2010; 2012) and is given in the Appendix. Note that in robustness bounds, the cover radius \u03c1 can be made arbitrarily small at the expense of larger values of M . As M appears in the second term, which decreases to 0 when dl tends to infinity, this bound provides a standard O(1/ \u221a dl) asymptotic convergence."}, {"heading": "3.3 ROBUSTNESS ANALYSIS FOR DIFFERENT SIMILARITY FUNCTIONS", "text": "Our main theorems strongly depend on the l-lipschitzness of the similarity function. In this section, we focus on some particular similarities that can be used in our setting. The proofs for the following functions are detailed in the Appendix. Similarity function 1. Let K1A be the bilinear form K1A(x,x\u2032) = xTAx\u2032. K1A(x,x\u2032) is 1-lipschitz w.r.t. its first argument. Similarity function 2. We define K2A(x,x\u2032) = 1\u2212 (x\u2212 x\u2032)TA(x\u2212 x\u2032), a similarity derived from the Mahalanobis distance. K2A(x,x \u2032) is 4-lipschitz w.r.t. its first argument.\nSimilarity function 3. Let K3A(x,x\u2032) = exp ( \u2212 (x\u2212x \u2032)TA(x\u2212x\u2032) 2\u03c32 ) . K3A(x,x \u2032) is l-lipschitz w.r.t.\nits first argument with l = 2\u03c32 ( exp ( 1 2\u03c32 ) \u2212 exp ( \u22121 2\u03c32 )) .\nAs both K1A and K 2 A are linear w.r.t. their arguments, they have the main advantage to keep problem (4) convex. K3A is also based on the Mahalanobis distance, but this time it is a non linear function, ressembling more a gaussian kernel. Plugging l = 1 (resp. l = 4 and l = 2 \u03c32 ( exp ( 1 2\u03c32 ) \u2212 exp ( \u22121 2\u03c32 )) ) in Theorem 4, we obtain consistency results for problem (4) using K1A(x,x \u2032) (resp. K2A(x,x \u2032) and K3A(x,x \u2032)). As the gap between empirical and true loss presented in Theorem 4 is proportional with l for the l-lipschitzness of each similarity function, we would like to keep this parameter as small as possible. We notice that the generalization bound is tighter for K1A than for K 2 A. The bound for K 3 A depends on the additional parameter \u03c3, that adjusts the influence of the similarty value w.r.t. the distance to the landmarks. The value of l goes to 0 as \u03c3 augments, so larger values of \u03c3 are preferable in order to obtain a tight bound for the generalization error. However, note that when \u03c3 is large, the exponential behaves almost linearly, i.e. the projection loses its non-linear power."}, {"heading": "4 EXPERIMENTS", "text": "The state of the art in metric learning is dominated by algorithms designed to work in a purely supervised setting. Furthermore, most of them optimize a metric adapted to k-NN classification (e.g. LMNN, ITML), while our work is designed for finding a global linear separator. It is for these reasons that it is difficult to propose a fair comparative study. Therefore, we propose to compare our method to Balcan et al. (2008)\u2019s algorithm which will play the role of a baseline. We conduct the experimental study on 7 classic datasets taken from the UCI Machine Learning Repository, both binary and multi-class. Their characteristics are presented in Table 1. These datasets are widely used for metric learning evaluation."}, {"heading": "4.1 EXPERIMENTAL SETUP", "text": "We compare the following methods: the algorithm from Balcan et al. (2008) as a baseline (referred to as BBS from now on) and problem (4) with constraints (5), (6) and (7), that we will name JSL (for Joint Similarity Learning). We plug into these methods the three similarity functions studied previously (see Section 3.3), thus obtaining six settings. As BBS\u2019s setting contains no metric learning step, the metric A is set to the identity matrix, which is equivalent to using standard, non parametered similarity functions. All attributes are centered around zero and scaled to ensure ||x||2 \u2264 1, as this constraint is necessary for both algorithms. We randomly choose 15% of the data for validation purposes, and another 15% as a test set. The training set and the unlabeled data are chosen from the remaining 70% of examples not employed in the previous sets. In order to illustrate the classification using a restricted quantity of labeled data, the number of labeled points is limited to 5\nexamples per class, as this is usually considered a reasonable minimum amount of annotation to rely on. The number of landmarks is either equal to the size of the training set, either set to 15 points, to parallel the fact that we consider 5 labeled points per class. In the former case, the unlabeled data is chosen from the data as the points closest to the centroids determined by applying k-means++ clustering. When all the available data is used as landmarks, the L1 constraint on \u03b1 forces the algorithm to choose the most valuable of them by adapting their respective weights. All of the experimental results are averaged over 10 runs, for which we compute a 95% confidence interval. We deal with multiclass classification in a one-vs-all fashion. For both methods, we tune the following parameters by cross-validation: \u03b3 \u2208 {10\u22124, 10\u22123, 10\u22122, 10\u22121}, \u03c3 \u2208 {10\u22122, 10\u22121, 1, 10} (for K3A), choosing the value yielding the best accuracy. All the experiments are done using projected gradient descent, with the maximum number of iterations set to 350 (the value of the objective becomes stable before). We solve the joint learning problem by alternating the optimization variable from \u03b1 to A."}, {"heading": "4.2 RESULTS", "text": "We report the results obtained for linear classification in Tables 2 and 3. The best result for the pairwise comparison between the two methods using the same similarity function is marked in bold. When using all the available data as (unlabeled) landmarks (Table 2), our method achieves the best results on 15 out of 21 settings, and a tie on one configuration. Table 3 summarizes the results obtained when the unlabeled dataset contains only 15 points. In this case, our technique yields the best accuracy on 11 out of the 21 settings, and similar results in two other cases. Should one wish to compare the similarity functions in the same settings, we notice that K2A is the one yielding the best results in most of the cases for both tables. This is surprising, considering that the cosine similarity K1A is 1-lipschitz, thus resulting in a tighter generalization bound, as K 2 A is 4-lipschitz. We explain this fact by the geometric characteristics of the involved datasets, which makes the Mahalanobis distance more suitable for classification than the generalized cosine. When comparing Tables 2 and 3, we notice that there are only a few cases when the best accuracy is attained with less unlabeled points, but that when this happens the improvement is significant. This phenomenon is due to the fact that the 15 unlabeled points are not chosen randomly, but contain relevant information w.r.t. data topology. In the case of K3A, there is a trade-off between the tightness of the bound in Theorem 4 and the stability of the results. Large values of \u03c3 will lead to tighter bounds (as l is smaller), but the resulting similarity function becomes linear and less discriminative. As a consequence, the results vary more for this similarity function, leading to larger confidence intervals, as can be seen in Tables 2 and 3 on almost all the collections."}, {"heading": "5 CONCLUSIONS", "text": "In this paper, we present a semi-supervised framework for learning an ( , \u03b3, \u03c4)-good similarity function and a classifier at the same time. We show that our joint approach is theoretically founded using results from Balcan et al. (2008) and new results based on algorithmic robustness. This setting is designed to learn well with a limited amount of labeled data and performs well in practice on various UCI datasets. Future work could cover a kernelized version of our technique to learn more efficient similarities and classifiers in a non-linear feature space, as well as learning local metrics and a combination of them in a coherent framework."}], "references": [{"title": "Improved guarantees for learning via similarity functions", "author": ["Balcan", "M.-F", "A. Blum", "N. Srebro"], "venue": "Omnipress,", "citeRegEx": "Balcan et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Balcan et al\\.", "year": 2008}, {"title": "Quick asymmetric text similarity measures", "author": ["Bao", "J.-P", "Shen", "J.-Y", "Liu", "X.-D", "H.-Y"], "venue": "ICMLC,", "citeRegEx": "Bao et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Bao et al\\.", "year": 2003}, {"title": "An adaptive k-nearest neighbor text categorization strategy", "author": ["L. Baoli", "L. Qin", "Y. Shiwen"], "venue": "ACM TALIP,", "citeRegEx": "Baoli et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Baoli et al\\.", "year": 2004}, {"title": "Similarity learning for provably accurate sparse linear classification", "author": ["A. Bellet", "A. Habrard", "M. Sebban"], "venue": "In ICML, pp", "citeRegEx": "Bellet et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bellet et al\\.", "year": 2012}, {"title": "A survey on metric learning for feature vectors and structured data", "author": ["A. Bellet", "A. Habrard", "M. Sebban"], "venue": "arXiv preprint arXiv:1306.6709,", "citeRegEx": "Bellet et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bellet et al\\.", "year": 2013}, {"title": "Semi-Supervised Learning", "author": ["O. Chapelle", "B. Sch\u00f6lkopf", "Zien", "A. (eds"], "venue": null, "citeRegEx": "Chapelle et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Chapelle et al\\.", "year": 2006}, {"title": "Information-theoretic metric learning", "author": ["J.V. Davis", "B. Kulis", "P. Jain", "S. Sra", "I.S. Dhillon"], "venue": "In ICML,", "citeRegEx": "Davis et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Davis et al\\.", "year": 2007}, {"title": "Learning similarities for text documents using neural networks", "author": ["M. Diligenti", "M. Maggini", "L. Rigutini"], "venue": "In ANNPR,", "citeRegEx": "Diligenti et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Diligenti et al\\.", "year": 2003}, {"title": "A technique for learning similarities on complex structures with applications to extracting ontologies. In AWIC, LNAI", "author": ["M. Grabowski", "A. Sza\u0142as"], "venue": null, "citeRegEx": "Grabowski and Sza\u0142as,? \\Q2005\\E", "shortCiteRegEx": "Grabowski and Sza\u0142as", "year": 2005}, {"title": "Guaranteed classification via regularized similarity learning", "author": ["Guo", "Z.-C", "Y. Ying"], "venue": "CoRR, abs/1306.3108,", "citeRegEx": "Guo et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Guo et al\\.", "year": 2013}, {"title": "Learning Similarities for Collaborative Information Retrieval", "author": ["A. Hust"], "venue": "In Proceedings of KI 2004 workshop \u201dMachine Learning and Interaction for Text-Based Information Retrieval\u201d,", "citeRegEx": "Hust,? \\Q2004\\E", "shortCiteRegEx": "Hust", "year": 2004}, {"title": "entropy and -capacity of sets in functional spaces", "author": ["A. Kolmogorov", "V. Tikhomirov"], "venue": "American Mathematical Society Translations,", "citeRegEx": "Kolmogorov and Tikhomirov,? \\Q1961\\E", "shortCiteRegEx": "Kolmogorov and Tikhomirov", "year": 1961}, {"title": "Online and batch learning of generalized cosine similarities", "author": ["A.M. Qamar", "\u00c9. Gaussier"], "venue": "In ICDM, pp", "citeRegEx": "Qamar and Gaussier,? \\Q2009\\E", "shortCiteRegEx": "Qamar and Gaussier", "year": 2009}, {"title": "Online and batch learning of pseudo-metrics", "author": ["S. Shalev-Shwartz", "Y. Singer", "A.Y. Ng"], "venue": null, "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2004}, {"title": "Weak Convergence and Empirical Processes", "author": ["A. van der Vaart", "J. Wellner"], "venue": null, "citeRegEx": "Vaart and Wellner,? \\Q1996\\E", "shortCiteRegEx": "Vaart and Wellner", "year": 1996}, {"title": "Fast solvers and efficient implementations for distance metric learning", "author": ["K. Weinberger", "L. Saul"], "venue": "In ICML,", "citeRegEx": "Weinberger and Saul,? \\Q2008\\E", "shortCiteRegEx": "Weinberger and Saul", "year": 2008}, {"title": "Distance metric learning for large margin nearest neighbor classification", "author": ["K. Weinberger", "L. Saul"], "venue": "JMLR, 10:207\u2013244,", "citeRegEx": "Weinberger and Saul,? \\Q2009\\E", "shortCiteRegEx": "Weinberger and Saul", "year": 2009}, {"title": "Robustness and generalization", "author": ["H. Xu", "S. Mannor"], "venue": "In COLT, pp", "citeRegEx": "Xu and Mannor,? \\Q2010\\E", "shortCiteRegEx": "Xu and Mannor", "year": 2010}, {"title": "Robustness and generalization", "author": ["H. Xu", "S. Mannor"], "venue": "Machine Learning,", "citeRegEx": "Xu and Mannor,? \\Q2012\\E", "shortCiteRegEx": "Xu and Mannor", "year": 2012}, {"title": "1-norm support vector machines", "author": ["J. Zhu", "S. Rosset", "T. Hastie", "R. Tibshirani"], "venue": "In NIPS, pp", "citeRegEx": "Zhu et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Zhu et al\\.", "year": 2003}], "referenceMentions": [{"referenceID": 0, "context": "The theoretical framework of ( , \u03b3, \u03c4)-good similarity functions (Balcan et al., 2008) has been one of the first attempts to draw a link between the properties of a similarity function and those of a linear classifier making use of it.", "startOffset": 65, "endOffset": 86}, {"referenceID": 4, "context": "by learning Mahanalobis distances instead of the standard Euclidean distance, thus paving the way for a new research area termed metric learning (Bellet et al., 2013).", "startOffset": 145, "endOffset": 166}, {"referenceID": 2, "context": "Most of these studies have based their approaches on distance learning (Baoli et al., 2004; Davis et al., 2007; Diligenti et al., 2003; Shalev-Shwartz et al., 2004; Weinberger & Saul, 2009), even though similarity learning has also attracted a growing interest (Bao et al.", "startOffset": 71, "endOffset": 189}, {"referenceID": 6, "context": "Most of these studies have based their approaches on distance learning (Baoli et al., 2004; Davis et al., 2007; Diligenti et al., 2003; Shalev-Shwartz et al., 2004; Weinberger & Saul, 2009), even though similarity learning has also attracted a growing interest (Bao et al.", "startOffset": 71, "endOffset": 189}, {"referenceID": 7, "context": "Most of these studies have based their approaches on distance learning (Baoli et al., 2004; Davis et al., 2007; Diligenti et al., 2003; Shalev-Shwartz et al., 2004; Weinberger & Saul, 2009), even though similarity learning has also attracted a growing interest (Bao et al.", "startOffset": 71, "endOffset": 189}, {"referenceID": 13, "context": "Most of these studies have based their approaches on distance learning (Baoli et al., 2004; Davis et al., 2007; Diligenti et al., 2003; Shalev-Shwartz et al., 2004; Weinberger & Saul, 2009), even though similarity learning has also attracted a growing interest (Bao et al.", "startOffset": 71, "endOffset": 189}, {"referenceID": 19, "context": "Their algorithm, whose formulation is equivalent to a relaxed L1-norm SVM (Zhu et al., 2003), does not enforce the positive definiteness constraint of the similarity.", "startOffset": 74, "endOffset": 92}, {"referenceID": 0, "context": "(2012) have explored the possibility of independently learning an ( , \u03b3, \u03c4)-good similarity that they plug into the initial algorithm (Balcan et al., 2008) to learn the linear separator.", "startOffset": 134, "endOffset": 155}, {"referenceID": 0, "context": ", 2004; Weinberger & Saul, 2009), even though similarity learning has also attracted a growing interest (Bao et al. (2003); Grabowski & Sza\u0142as (2005); Hust (2004); Qamar & Gaussier (2009)), the rationale being that the cosine similarity should in some cases be preferred over the Euclidean distance.", "startOffset": 105, "endOffset": 123}, {"referenceID": 0, "context": ", 2004; Weinberger & Saul, 2009), even though similarity learning has also attracted a growing interest (Bao et al. (2003); Grabowski & Sza\u0142as (2005); Hust (2004); Qamar & Gaussier (2009)), the rationale being that the cosine similarity should in some cases be preferred over the Euclidean distance.", "startOffset": 105, "endOffset": 150}, {"referenceID": 0, "context": ", 2004; Weinberger & Saul, 2009), even though similarity learning has also attracted a growing interest (Bao et al. (2003); Grabowski & Sza\u0142as (2005); Hust (2004); Qamar & Gaussier (2009)), the rationale being that the cosine similarity should in some cases be preferred over the Euclidean distance.", "startOffset": 105, "endOffset": 163}, {"referenceID": 0, "context": ", 2004; Weinberger & Saul, 2009), even though similarity learning has also attracted a growing interest (Bao et al. (2003); Grabowski & Sza\u0142as (2005); Hust (2004); Qamar & Gaussier (2009)), the rationale being that the cosine similarity should in some cases be preferred over the Euclidean distance.", "startOffset": 105, "endOffset": 188}, {"referenceID": 0, "context": "More recently, Balcan et al. (2008) have proposed the first framework that allows one to relate similarities with a classification algorithm making use of them.", "startOffset": 15, "endOffset": 36}, {"referenceID": 0, "context": "More recently, Balcan et al. (2008) have proposed the first framework that allows one to relate similarities with a classification algorithm making use of them. This framework, that is very general as it can be used with any bounded similarity function (potentially derived from a distance), provides generalization guarantees on a linear classifier learned from the similarity. Their algorithm, whose formulation is equivalent to a relaxed L1-norm SVM (Zhu et al., 2003), does not enforce the positive definiteness constraint of the similarity. However, to enjoy such generalization guarantees, the similarity function is assumed to be known beforehand and to satisfy ( , \u03b3, \u03c4)-goodness properties. Unfortunately, Balcan et al. (2008) do not provide any algorithm for learning such similarities.", "startOffset": 15, "endOffset": 736}, {"referenceID": 0, "context": "More recently, Balcan et al. (2008) have proposed the first framework that allows one to relate similarities with a classification algorithm making use of them. This framework, that is very general as it can be used with any bounded similarity function (potentially derived from a distance), provides generalization guarantees on a linear classifier learned from the similarity. Their algorithm, whose formulation is equivalent to a relaxed L1-norm SVM (Zhu et al., 2003), does not enforce the positive definiteness constraint of the similarity. However, to enjoy such generalization guarantees, the similarity function is assumed to be known beforehand and to satisfy ( , \u03b3, \u03c4)-goodness properties. Unfortunately, Balcan et al. (2008) do not provide any algorithm for learning such similarities. In order to overcome these limitations, Bellet et al. (2012) have explored the possibility of independently learning an ( , \u03b3, \u03c4)-good similarity that they plug into the initial algorithm (Balcan et al.", "startOffset": 15, "endOffset": 858}, {"referenceID": 0, "context": "More recently, Balcan et al. (2008) have proposed the first framework that allows one to relate similarities with a classification algorithm making use of them. This framework, that is very general as it can be used with any bounded similarity function (potentially derived from a distance), provides generalization guarantees on a linear classifier learned from the similarity. Their algorithm, whose formulation is equivalent to a relaxed L1-norm SVM (Zhu et al., 2003), does not enforce the positive definiteness constraint of the similarity. However, to enjoy such generalization guarantees, the similarity function is assumed to be known beforehand and to satisfy ( , \u03b3, \u03c4)-goodness properties. Unfortunately, Balcan et al. (2008) do not provide any algorithm for learning such similarities. In order to overcome these limitations, Bellet et al. (2012) have explored the possibility of independently learning an ( , \u03b3, \u03c4)-good similarity that they plug into the initial algorithm (Balcan et al., 2008) to learn the linear separator. Generalization bounds for the learned similarity (a bilinear similarity) were derived via uniform stability arguments (Bousquet & Elisseeff, 2002). However, despite good results in practice, one limitation of this framework is that it imposes to deal with strongly convex objective functions. More importantly, the similarity learning step is done in a completely supervised way while Balcan et al. (2008)\u2019s framework opens the door to the use of unlabeled data.", "startOffset": 15, "endOffset": 1444}, {"referenceID": 0, "context": "Enforcing ( , \u03b3, \u03c4)-goodness allows us to preserve (Balcan et al., 2008)\u2019s theoretical guarantees.", "startOffset": 51, "endOffset": 72}, {"referenceID": 0, "context": "In this paper, we aim at better exploiting the semi-supervised setting underlying the theoretical framework of Balcan et al. (2008), which is based on similarities between labeled data and unlabeled reasonable points (roughly speaking, the reasonable points play the same role as that of support vectors in SVMs).", "startOffset": 111, "endOffset": 132}, {"referenceID": 0, "context": "In this paper, we aim at better exploiting the semi-supervised setting underlying the theoretical framework of Balcan et al. (2008), which is based on similarities between labeled data and unlabeled reasonable points (roughly speaking, the reasonable points play the same role as that of support vectors in SVMs). Furthermore, and unlike Bellet et al. (2012), we propose here to jointly learn the metric and the classifier, so that both the metric and the separator are learned in a semisupervised way.", "startOffset": 111, "endOffset": 359}, {"referenceID": 6, "context": "One can partly get around this latter shortcoming by making use of specific solvers or using information-theoretic approaches, such as ITML (Davis et al., 2007).", "startOffset": 140, "endOffset": 160}, {"referenceID": 0, "context": "In this context, Balcan et al. (2008) introduced a theory for learning with so called ( , \u03b3, \u03c4)-good similarity functions based on non PSD matrices.", "startOffset": 17, "endOffset": 38}, {"referenceID": 0, "context": "(Balcan et al., 2008) K is a ( , \u03b3, \u03c4)-good similarity function in hinge loss for a learning problem P if there exists a random indicator function R(x) defining a probabilistic set of \u201dreasonable points\u201d such that the following conditions hold:", "startOffset": 0, "endOffset": 21}, {"referenceID": 0, "context": "(Balcan et al., 2008) Let K be an ( , \u03b3, \u03c4)-good similarity function in hinge loss for a learning problem P.", "startOffset": 0, "endOffset": 21}, {"referenceID": 0, "context": "The main limitation of this approach is that the similarity function K is predefined and Balcan et al. (2008) did not provide any learning algorithm to design ( , \u03b3, \u03c4)-good similarities.", "startOffset": 89, "endOffset": 110}, {"referenceID": 0, "context": "The main limitation of this approach is that the similarity function K is predefined and Balcan et al. (2008) did not provide any learning algorithm to design ( , \u03b3, \u03c4)-good similarities. This problem has been fixed by Bellet et al. (2012) who optimized the ( , \u03b3, \u03c4)-goodness of a bilinear similarity function under Frobenius norm regularization.", "startOffset": 89, "endOffset": 240}, {"referenceID": 0, "context": "It is worth noticing that Equation (3) optimizes an empirical version of the notion of ( , \u03b3, \u03c4)goodness of Balcan et al. (2008). Moreover, since the random indicator function R(x) defining the probabilistic set of reasonable points (as defined in Equation (1)) is unknown, Bellet et al.", "startOffset": 108, "endOffset": 129}, {"referenceID": 0, "context": "It is worth noticing that Equation (3) optimizes an empirical version of the notion of ( , \u03b3, \u03c4)goodness of Balcan et al. (2008). Moreover, since the random indicator function R(x) defining the probabilistic set of reasonable points (as defined in Equation (1)) is unknown, Bellet et al. (2012) resort to an additional set of dr labeled points that are also used during the classifier learning step.", "startOffset": 108, "endOffset": 295}, {"referenceID": 2, "context": "More recently, Guo & Ying (2013) extended the theoretical results of Bellet et al. (2012). Using the Rademacher complexity (instead of the uniform stability) and Khinchin-type inequalities, they derive generalization bounds for similarity learning formulations that are regularized w.", "startOffset": 69, "endOffset": 90}, {"referenceID": 0, "context": "This allows us to make use of the semi-supervised setting presented by Balcan et al. (2008) to learn well with only a small amount of labeled data.", "startOffset": 71, "endOffset": 92}, {"referenceID": 0, "context": "Constraint (5) takes into account the desired margin \u03b3 and is the same as in Balcan et al. (2008). Constraints (6) and (7) come to restrict the similarity KA, as it is a generic form and its bounds are not known.", "startOffset": 77, "endOffset": 98}, {"referenceID": 5, "context": "Note that with this construction the \u03c1-covers verify the cluster assumption used in semi-supervised learning (Chapelle et al., 2006).", "startOffset": 109, "endOffset": 132}, {"referenceID": 0, "context": "Therefore, we propose to compare our method to Balcan et al. (2008)\u2019s algorithm which will play the role of a baseline.", "startOffset": 47, "endOffset": 68}, {"referenceID": 0, "context": "We compare the following methods: the algorithm from Balcan et al. (2008) as a baseline (referred to as BBS from now on) and problem (4) with constraints (5), (6) and (7), that we will name JSL (for Joint Similarity Learning).", "startOffset": 53, "endOffset": 74}], "year": 2017, "abstractText": "The importance of metrics in machine learning has attracted a growing interest for distance and similarity learning, and especially the Mahalanobis distance. However, it is worth noting that this research field lacks theoretical guarantees that can be expected on the generalization capacity of the classifier associated to a learned metric. The theoretical framework of ( , \u03b3, \u03c4)-good similarity functions (Balcan et al., 2008) has been one of the first attempts to draw a link between the properties of a similarity function and those of a linear classifier making use of it. In this paper, we extend this theory to a setting where the metric and the separator are jointly learned in a semi-supervised way. We furthermore provide a generalization bound for the associated classifier based on the algorithmic robustness framework. The behavior of our method is illustrated via some experimental results.", "creator": "LaTeX with hyperref package"}}}