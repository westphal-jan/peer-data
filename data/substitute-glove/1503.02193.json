{"id": "1503.02193", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Mar-2015", "title": "Label optimal regret bounds for online local learning", "abstract": "We resolve neither open reason he (Christiano, 2014b) exposing 2003 COLT ' 3 specifically an optimal fertility under brought conveyed attain to online citizens focus friday itself size of called billboard give. In however implement way simplest well revealed no top most antique coming and wants, chosen it an rest some $ n $ items. The validation then 2025 a label in while item, while now label close of smallest $ L $ used granted every even valued payoff. This this next create framework which frightening are interesting perplexing not although incorporating archiving, online lucrative, besides phone max while some others. (Christiano, 2014a) craft without designing page classroom graphs meant how cannot progress set regret of $ O (\\ sqrt {nL ^ 3T} ) $, every $ T $ is form different in lasted. Information conversely, just can promise set gesture beyond $ O (\\ sqrt {formula_1 \\ accessible L T} ) $. One of another creating open questions left only reason establishes concerns weekend the metres gap.", "histories": [["v1", "Sat, 7 Mar 2015 17:36:08 GMT  (19kb)", "https://arxiv.org/abs/1503.02193v1", "17 pages"], ["v2", "Mon, 24 Aug 2015 19:56:12 GMT  (19kb)", "http://arxiv.org/abs/1503.02193v2", "13 pages; Changes from previous version: small changes to proofs of Theorems 1 &amp; 2, a small rewrite of introduction as well (this version is the same as camera-ready copy in COLT '15)"]], "COMMENTS": "17 pages", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["pranjal awasthi", "moses charikar", "kevin a lai", "rej risteski"], "accepted": false, "id": "1503.02193"}, "pdf": {"name": "1503.02193.pdf", "metadata": {"source": "CRF", "title": "Label optimal regret bounds for online local learning", "authors": ["Pranjal Awasthi", "Moses Charikar", "Kevin A. Lai", "Andrej Risteski"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n50 3.\n02 19\n3v 2\n[ cs\n.L G\n] 2\n4 A\nug 2\n01 5\n\u221a\nnL3T ), where T is the number of rounds. Information theoretically, one can achieve a regret of O( \u221a\nn logLT ). One of the main open questions left in this framework concerns closing the above gap.\nIn this work, we provide a complete answer to the question above via two main results. We show, via a tighter analysis, that the semi-definite programming based algorithm of (Christiano, 2014a) in fact achieves a regret of O( \u221a\nnLT ). Second, we show a matching computational lower bound. Namely, we show that a polynomial time algorithm for online local learning with lower regret would imply a polynomial time algorithm for the planted clique problem which is widely believed to be hard. We prove a similar hardness result under a related conjecture concerning planted dense subgraphs that we put forth. Unlike planted clique, the planted dense subgraph problem does not have any known quasi-polynomial time algorithms.\nComputational lower bounds for online learning are relatively rare, and we hope that the ideas developed in this work will lead to lower bounds for other online learning scenarios as well."}, {"heading": "1 Introduction", "text": "Online learning is a classic area of machine learning starting from the seminal work of (Littlestone and Warmuth, 1994), (DeSantis et al., 1988) and (Vavock, 1990). In this framework, also known as \u201cprediction from expert advice\u201d, the learning algorithm has to predict label information about an item or a set of items at each stage. It then earns a real valued payoff which is a function of the predicted labels. The aim is to achieve a total payoff in T rounds comparable to the best expert, i.e., the best fixed labeling of the items. The difference from the best possible payoff is known as the regret of the algorithm.\nThe weighted majority algorithm (Littlestone and Warmuth, 1994) achieves the optimal regret of O( \u221a T logN) for the above mentioned problem (T is the number of rounds, N is the total number of experts) but is computationally efficient only when the number of experts is small. In many scenarios, one is competing with a set of exponentially many experts. Hence, there has been a significant effort in designing polynomial time algorithms with optimal regret bounds for various such problems such as collaborative filtering, online gambling, and online max cut ((Kalai and Vempala, 2005), (Hazan et al., 2012), (Kakade et al., 2009), (Hazan, 2009))\n\u2217Princeton University, Computer Science Department. Email: pawashti@cs.princeton.edu. Supported by NSF grant CCF-1302518. \u2020Princeton University, Computer Science Department. Email: moses@cs.princeton.edu. Partially supported by NSF grants CCF-1218687 and CCF-1302518, a Simons Investigator Award, and a Simons Collaboration Grant. \u2021Princeton University, Computer Science Department. Email: kalai@cs.princeton.edu \u00a7Princeton University, Computer Science Department. Email: risteski@cs.princeton.edu. Partially supported by NSF grants CCF-0832797, CCF-1117309, CCF-1302518, DMS-1317308, Sanjeev Arora\u2019s Simons Investigator Award, and a Simons Collaboration Grant.\nA common aspect of many online learning scenarios mentioned above, is that at each time step, the learner is asked to predict local information about items. For instance, in the online max cut problem, the learner has to predict whether any two nodes are on the same side of the cut or on opposite sides. Recently, (Christiano, 2014a) proposed an elegant unifying framework called online local learning to capture such problems.\nIn this framework, one is given a set of n items, numbered 1 to n. In each round t \u2208 [T ], the learner gets a pair of items (it, jt) as input and has to reply with a pair of labels (ait , bjt), where the possible labels are in [L]. Then, an adversary picks a payoff function Pt : [L]2 \u2192 [\u22121, 1]. The goal is to compete with the best fixed labeling. More precisely, if we denote\nOPT = maxl\u2208[L]n T \u2211\nt=1\nPt (l(it), l(jt))\nand the algorithm achieves expected payoff OPT \u2212 r, the algorithm has regret r, where the expectation is over the algorithm\u2019s randomness.\nThe main result of (Christiano, 2014a) is that the well known \u201cFollow-the-regularized-leader\u201d algorithm with an appropriate regularizer achieves regret O( \u221a nL3T ) for the online local learning problem. This, in particular, leads to optimal regret bounds1 for the online max cut problem. Notice that as mentioned before, one can get the optimal regret of O( \u221a n logL T ) via an inefficient algorithm which runs the weighted majority algorithm over the space of all possible labelings. One of the main questions left open in this framework was to close the gap between the regret that can be achieved by an efficient algorithm and the information theoretically optimal regret. We close this gap by proving the following results (formal statements appear later). On the lower bound side, we prove:\nTheorem 1 (Informal). For every \u01eb > 0, if there exists an algorithm for online local learning achieving regret O( \u221a nL1\u2212\u03b2(\u01eb)T ), and running in time polynomial in n, L, T , then in polynomial time, one can distinguish an instance of a random graph G(n, 1/2) from an instance of G(n, 1/2) with a randomly planted clique of size n1/2\u2212\u01eb. Here, \u03b2(\u01eb) is a function such that lim\u01eb\u21920 \u03b2(\u01eb) = 0.\nWe also prove a similar lower bound under a more robust conjecture concerning planting dense subgraphs which we introduce, which has no known quasipolynomial time algorithms, unlike planted clique. We show:\nTheorem 2 (Informal). For every \u01eb, \u01eb\u2032 > 0, if there exists an algorithm for online local learning achieving regret O( \u221a nL1\u2212\u03b2(\u01eb,\u01eb\u2032)T ), and running in time polynomial in n, L, T , then in polynomial time, one can distinguish between an instance of G(n, p) and an instance of G(n, p) with a randomly planted instance of G(k, q). Here, k, q depend on \u01eb, \u01eb\u2032, and \u03b2(\u01eb, \u01eb\u2032) is a function such that lim\u01eb,\u01eb\u2032\u21920 \u03b2(\u01eb, \u01eb\u2032) = 0.\nWe match the above lower bounds with the following theorem:\nTheorem 3 (Informal). For the online local learning problem, follow the regularized leader with an appropriate regularizer achieves regret O( \u221a nLT ).\nJointly these results are meaningful for multiple reasons. First and foremost, online local learning is the most natural generalization of constraint satisfaction problems (CSPs) to the online setting. The semidefinite relaxation upon which Theorem 3 is based is the same one considered in (Raghavendra, 2008), who proves that under the Unique Games Conjecture, it actually achieves the best approximation factor among all polynomial-time algorithms. Our result can be viewed as an extension of (Raghavendra, 2008): for the online version of CSPs, follow-the-regularized leader on the same semidefinite relaxation along with a log determinantal regularizer is the \u201coptimal\u201d algorithm, under widely believed conjectures. Furthermore, while our hardness reduction is specific to the setting of online local learning, given the paucity of lower bounds in the setting of online learning, our result is a significant contribution and we hope it will find applications in other settings as well. Finally, a labeling of the items with k labels can be also viewed as a k-partitioning of the items. So, all the above results can be viewed through the lens of online settings for k-partitioning.\n1Up to constant factors"}, {"heading": "1.1 Techniques", "text": "We obtain the above mentioned upper bound on the regret by showing that \u201cFollow-the-regularized-leader\u201d using the same regularizer as (Christiano, 2014a) achieves the regret bound we are claiming, but with a completely different analysis. There, the idea is to express the entropy of a multivariate Gaussian in terms of the log-determinant of its covariance matrix, and that two multivariate Gaussian distributions that differ by a small amount in their covariance matrices cannot be too far in total variation distance as well. The main reason for this approach in (Christiano, 2014a) is that the Hessian of the log-determinantal regularizer is not diagonal, so it\u2019s difficult to argue about its inverse. We use the special structure of the regularizer to get explicit expressions for the inverse, which allows us then to use more standard tools from convex geometry for analyzing \u201cFollow-the-regularized-leader\u201d. To do this we use some matrix calculus identities, which we think might be useful in other machine learning applications, where one needs to perform regularized optimization over polytopes of pseudo-moments.\nOur lower bounds are based on two conjectures about detecting planted dense structures inside random graphs. The first one is planted clique, which states that detecting planted cliques of sufficiently small size in an Erdo\u0308s-Re\u0301nyi graph cannot be done in polynomial time. We introduce a more robust version of this conjecture, planted dense subgraph, which concerns detecting planted dense Erdo\u0308s-Re\u0301nyi graphs inside sparser ones. While our reductions are similar in both cases, the state of the art algorithms for this detection problem are much worse. This is an indicator that this problem is likely harder and gives even stronger evidence for the hardness of achieving low regret. The proof idea is to use the online learner as an estimator of the size of the largest clique or dense subgraph in a graph, and the regret as the rate of error in this estimator. We show that if the rate is low enough, then one can distinguish between the planted and non-planted case. See next section for further details."}, {"heading": "1.2 The planted dense subgraph and planted clique problems", "text": "We will review the planted clique conjecture and describe the dense subgraph conjecture, upon which we will be basing our lower bounds."}, {"heading": "1.2.1 Planted clique", "text": "In the planted clique problem, one is given a graph sampled from one of two possible random ensembles: an Erdo\u0308sRe\u0301nyi random graph G(n, 1/2), or an Erdo\u0308s-Re\u0301nyi random graph G(n, 1/2) along with a clique of size k placed between k randomly chosen vertices in the graph. (The usual notation for this random ensemble is G(n, 1/2, k).) The task is to distinguish whether one is presented with a graph from the G(n, 1/2) ensemble or the G(n, 1/2, k) ensemble.\nPrevious sequences of work (Feldman et al., 2013), (Meka et al., 2015), show that wide classes of natural polynomial time algorithms cannot efficiently distinguish between these two cases when the size of the planted clique is n 1 2\u2212\u01eb, and it is conjectured that in fact there is no polynomial time algorithm for this task. More precisely, the conjecture is the following:\nConjecture 1. Suppose that an algorithm A receives as input a graph G, which is either sampled from the ensemble G(n, 1/2) or G(n, 1/2, n\n1 2\u2212\u01eb), \u01eb = \u2126(1). Then, no A which runs in polynomial time can decide, with probability 45 2,\nwhich ensemble the input was sampled from."}, {"heading": "1.2.2 Planted dense subgraph", "text": "The planted dense subgraph problem is a natural generalization of planted clique, where one again wants to distinguish between a random and a planted instance. In the planted case, we plant a denser graph inside a sparser one. Formally, let G(n, p, k, q) be a random graph ensemble generated in the following manner. First, one picks a random subset S of k vertices. Then, for all pairs of vertices inside S, one connects them with an edge independently with probability q. For all other pairs of vertices, we connect them independently with probability p.\n2The constant is arbitrary. One could make the conjecture for any constant bounded away from 1 2\nThe sizes and densities of the planted and ambient graph in which we will be interested are p = n\u2212\u03b1, k = n 1 2\u2212\u01eb \u2032\n, q = k\u2212\u03b1\u2212\u01eb, for \u03b1 \u2264 12 . The main reason this scenario is interesting is that unlike planted clique, we do not know of quasi-polynomial time algorithms for it.\nTo be formal, we conjecture the following:\nConjecture 2. Suppose that an algorithm A receives as input a graph G, which is either sampled from the ensemble G(n, p) or G(n, p, k, q), where k = n 1 2\u2212\u01eb \u2032\nfor \u01eb\u2032 = \u2126(1) and k = n\u2126(1); p = n\u2212\u03b1 for \u03b1 = \u2126(1), \u03b1 \u2264 12 ; q = k\u2212\u03b1\u2212\u01eb for \u01eb = \u2126(1); and p = o(q). Then, no A which runs in polynomial time can decide with probability 45 which ensemble the input was sampled from.\nThere are few ways to justify this conjecture. First, the current best known algorithm for this distinguishing problem from (Bhaskara et al., 2010) runs in time nk \u0398(\u01eb) . This bound gives a running time of 2n \u0398(\u01eb)\nsince k is polynomial in n, which is significantly worse than quasi-polynomial. Second, it\u2019s possible to show (Bhaskara et al., 2010) that spectral methods do not work in this regime. It\u2019s also easy to check that simple algorithms like outputting the vertices with highest degree do not work either \u2013 since the variance of the degree in the sparser ambient graph dominates the degrees in the denser planted graph. Finally, similar conjectures to this have already been proposed in various contexts in theoretical computer science. ((Arora et al., 2010), (Applebaum et al., 2010))\nThe fact that state of the art algorithms have a much worse running time for this problem in comparison to planted clique is our motivation for putting forth this conjecture. Namely, our reduction of planted clique/planted dense subgraph to online local learning will produce an online learning instance in which the number of items n\u2032, the number of rounds T and the label set size L are all polynomial in the size of the input graph. Furthermore, the time to produce the inputs for the learning algorithm will be polynomial as well. Therefore, if N = max(T, L, n\u2032), and we have an algorithm of running time f(N) for online local learning, we get an algorithm for planted clique/planted dense subgraph of running time max (f (poly (n)) , poly (n)).\nThis means for instance, if our algorithm for online local learning has running time f(N) = No(logN), our reduction would give an algorithm for planted clique with running time no(logn). A similar statement holds in the planted dense subgraph case. If our algorithm for online local learning has running time even f(N) = 2N o(1)\n, the reduction would give an algorithm better than the state of the art for planted dense subgraph."}, {"heading": "2 Computational lower bounds on achievable regret", "text": "We will proceed with the lower bound first. The overall strategy will be as follows. We will produce an online learning instance from our input graph. In the planted case, there will be a fixed labeling which achieves a large payoff bp, and in the random case, we\u2019ll show that any algorithm (efficient or not) can achieve at most some small payoff br. The reduction will ensure that if we can get a sufficiently low regret r in polynomial time, we will get a payoff of at least bp\u2212 r in the planted case, such that bp\u2212 r \u226b br, with probability 45 . Then to distinguish between planted and random, we simply declare planted if the payoff is large enough, and random otherwise.\nFor both reductions, we will show a \u201crobust\u201d version of the bound first, e.g. for planted clique, we will show a lower bound of O( \u221a nL1\u2212\u03b2(\u01eb)T ) if planted clique is hard when the size of the planted portion is n1/2\u2212\u01eb, for some function \u03b2(\u01eb). Then we will take the limit \u01eb \u2192 0. The details of the reduction follow."}, {"heading": "2.1 Planted clique-based hardness", "text": "Let us proceed to the planted clique-based lower bound first. We will show:\nTheorem 1. Let \u01eb = \u2126(1). If regret \u221a nL\u03b2T for \u03b2 = ( 1\u2212 \u03c9 ( 1\nlogn\n))(\n1 1 2 + \u01eb\n)\n\u2212 1 is achievable in time\npolynomial in n, L, T , then one can distinguish between G(n, 1/2) and G ( n, 1/2, n1/2\u2212\u01eb ) with probability 45 3 in polynomial time.\n3Again, the choice of 4 5 is arbitary\nProof. We produce an instance for the online local learning problem, given an instance of the planted clique problem with size of the planted clique k in the following way.\nWe randomly partition the input graph into n\u2032 = n/l clusters, each containing l vertices, where l = 10nk . We associate each vertex with a unique label in {1, .., l}. We then use this as an instance for the online learning problem as follows. We run the online learning game for T = ( n\u2032\n2\n)\nsteps. In each step t, we query a pair of clusters (Cit , Cjt). Each pair is queried once, and the ordering is arbitrary. The algorithm responds with some labeling for the clusters (lit , ljt), and the payoff is 1 if the vertex for lit in Cit has an edge to the vertex for ljt in Cjt . Otherwise, the payoff is 0.\nThe distinguisher for the planted clique problem runs the online learning algorithm on the instance specified above R = n 4\nk3.7 number of times. This is to ensure that with constant probability, the average payoff of the algorithm over the\nruns is close to the expected payoff. If the average payoff from the R runs is at least (1+ 1100 ) 1 2\n(\nk/10 2\n)\n, the distinguisher replies with planted. Otherwise, it replies with random.\nLet\u2019s assume the original graph was sampled from G(n, 1/2). Then, we claim that any algorithm (regardless if\nefficient or not) will get an average payoff of at most T2 + 5 \u221a T 2 with probability at least 4 5 .\nThe above probability is with respect to the randomness in generating the graph from G(n, 1/2), the partitioning of the vertices, and any randomness in the algorithm. Let the pair of clusters queried at time step t be (Cit , Cjt). Let\u2019s denote the random variable for the payoff in round t on the r-th repetition of the online learning problem as Prit,jt . Let Ga,b be a random 0-1 indicator variable for whether there is an edge between vertices a, b.\nIf Pit,jt = \u2211R r=1 Prit,jt , then the total payoff of the algorithm is P = \u2211T t=1 Pit,jt . We claim that the variables Pit,jt are mutually independent. Indeed, this follows because the variables Ga,b, for any vertices a \u2208 Cit , b \u2208 Cjt are independent of the data shown to the online learner in the first t\u2212 1 rounds and the algorithm\u2019s randomness.\nBut, by linearity of expectation, E [ 1 RPit,jt ] = 12 , and 1 RPit,jt always is between 0 and 1. So, by Hoeffding\u2019s\ninequality,\nPr\n[\n1\nR\nT \u2211\nt=1\nPit,jt \u2265 T\n2 + 5\n\u221a T\n2\n]\n\u2264 e\u221250\nIn particular, with probability at least 45 , any algorithm gets average payoff of 1 2\n(\nk/10 2\n)\n+ o(k2). Let\u2019s proceed to the planted case. First, we claim that with probability at least 78 , there is a fixed labeling with payoff\nat least ( 2k/25 2 ) . Let Ii be an indicator random variable for the event that no vertex from the planted clique belongs to cluster i. The partitioning is done independently of the graph, so Pr[Ii = 1] = (\n1\u2212 10 k\n)k\n\u2264 e\u2212 10k k = e\u221210. Hence, if I is a random variable for the total number of clusters which contain no vertices from the planted clique, we know that E[I] = n\u2032 \u2211\ni=1\nE[Ii] \u2264 k\n10 e\u221210. By Markov\u2019s inequality, Pr\n[\nI \u2265 k 50\n]\n\u2264 E[I] k 50 \u2264 5e\u221210 \u2264 1 8 .\nSo, with probability at least 78 , the number of clusters with at least one vertex from the planted clique is at least k 10 \u2212 k50 = 2k25 . In this case, the labeling where we label each of the clusters with a vertex from the planted clique has a payoff of at least (\n2k/25 2\n) . In the online learning instance we constructed, the number of vertices is n\u2032, the\nnumber of rounds is T , and the label size is l. Let\u2019s assume that we can achieve regret of \u221a n\u2032l\u03b2T . According to the definition of regret, whenever the graph was a planted instance, and the partitioning resulted in a fixed labeling with payoff at least (\n2k/25 2\n)\n, the expected payoff of the algorithm (with respect to the randomness of the algorithm) is at\nleast\n(\n2k/25\n2\n) \u2212 \u221a n\u2032l\u03b2T . We claim that the average payoff over the R runs of the online learning algorithm will be\nclose to this.\nIf we denote by Pr = T \u2211\nt=1 Prit,jt the payoff of the algorithm in the r-th repetition, then we have that E[Pr] \u2265 (\n2k/25 2\n) \u2212 \u221a n\u2032l\u03b2T and all the variables Pr are mutually independent and between 0 and n2. So, by Hoeffding\u2019s\nbound, Pr\n[\n1\nR\nR \u2211\nr=1\nPr \u2264 E[Pr]\u2212 t ] \u2264 e\u2212 2R 2t2 Rn4 . Setting t = k1.9, lets us conclude that with probability 1 \u2212 o(1),\n1 R \u2211R r=1Pr \u2265 ( 2k/25 2 )\n\u2212 \u221a n\u2032l\u03b2T \u2212 o(k2). Putting everything together, in the planted case, the average payoff is at\nleast ( 2k/25 2 ) \u2212 \u221a n\u2032l\u03b2T \u2212 o(k2) with probability 45 .\nRecall that we also proved that in a random instance, we get a payoff at most 1\n2\n(\nk/10\n2\n)\n+o(k2) with probability at\nleast 45 . We claim that\n(\n2k/25\n2\n) \u2265 ( 1 + 1\n100\n)\n1\n2\n(\nk/10\n2\n)\n. Indeed, ( 2k/25 2 ) = 2k/25(2k/25\u22121)2 \u2265 (1 \u2212 1100 ) (2k/25)2 2 ,\nfor large enough k, and\n(\n1\u2212 1 100\n)\n(2k/25)2\n2 \u2265\n(\n1 + 1\n100\n)\n1\n2\n(k/10)2\n2 \u2265\n(\n1 + 1\n100\n)\n1\n2\n(\nk/10\n2\n)\nHence, if \u221a n\u2032l\u03b2T = o(k2), the distinguisher constructed outputs the correct answer with probability 45 . We will\nshow exactly that. First we claim that\nl\u03b2 = o (n\nl\n)\n(1)\nSince l = 10nk = 10n 1 2+\u01eb, after rearranging terms, 1 is equivalent to n(\u03b2+1)( 1 2+\u01eb) = o(n). Notice that n\u03c9( 1 log n ) = \u03c9(1), so for the above it is sufficient that (\u03b2 + 1) ( 1\n2 + \u01eb\n) = 1 \u2212 \u03c9 ( 1\nlogn\n)\n. But since\n\u03b2 =\n( 1\u2212 \u03c9 ( 1\nlogn\n))(\n1 1 2 + \u01eb\n)\n\u2212 1 the above is clearly satisfied. Hence,\n\u221a n\u2032l\u03b2T =\n\u221a\nn l l\u03b2 (n l 2 ) = o\n( \u221a\nl\u03b2 (n\nl\n)3 )\n= o\n(\n(n\nl\n)2 )\n= o(k2)\nwhich finishes the proof.\nThis quite easily will give the result that assuming Conjecture 1, achieving regret \u221a nL1\u2212\u03b4T , for any \u03b4 = \u2126(1) is\nhard. More precisely: Corollary 1. Let \u01eb = \u2126(1). If we can achieve regret \u221a nL1\u2212\u01ebT in time polynomial in n, L, T , we can distinguishing between G(n, 1/2) and G(n, 1/2, n1/2\u2212 \u01eb 6 ) with probability 45 in polynomial time. In particular, if Conjecture 1 is\ntrue, no polynomial time algorithm can achieve regret \u221a nL1\u2212\u03b4T , for any \u03b4 = \u2126(1).\nThe proof of this Corollary is straightforward and relegated to Appendix A. We note that a stronger form of Conjecture 1 is consistent with our current knowledge of planted clique. In particular, we can strengthten the claim to allow any k = o( \u221a n), or alternatively k = n\n1 2\u2212\u01eb, for any \u01eb = \u03c9( 1logn ). In this case, Corollary 1 will imply that\nachieving regret \u221a n o(L)T is impossible in polynomial time."}, {"heading": "2.2 Planted dense subgraph hardness", "text": "We next move on to the planted dense subgraph based hardness. The proofs in this section are essentially a generalization of the planted clique hardness, so are relegated to Appendix A. We formally show: Theorem 2. Let \u01eb, \u03b1, k satisfy the conditions of Conjecture 2. If regret \u221a nL\u03b2T for\n\u03b2 = 2\n1 2 \u2212\n( 1 2 \u2212 \u01eb\u2032 )\n(\u03b1+ \u01eb)\u2212 \u03c9 (\n1 logn\n)\n1 2 + \u01eb\n\u2032 \u2212 1\nis achievable in time polynomial in n, L, T , then one can distinguish between G(n, ps) and G(n, ps, k, pd), where ps = n \u2212\u03b1, k = n 1 2\u2212\u01eb \u2032 , pd = k \u2212\u03b1\u2212\u01eb with probability 45 in polynomial time.\nAnd again as before, assuming Conjecture 2, achieving regret \u221a nL1\u2212\u03b4T , for any \u03b4 = \u2126(1) is hard. More pre-\ncisely: Corollary 2. Let \u01eb\u2032, \u03b1, \u01eb = \u2126(1) and \u03b1 \u2265 \u01eb. If we can achieve regret \u221a nL1\u2212\u01eb\u2032\u2212\u03b1\u2212\u01ebT in time polynomial in n, L, T , we can distinguish between G(n, ps) and G(n, ps, k, pd) in polynomial time with probability 45 , where ps = n \u2212\u03b18 , k = n 1 2\u2212 \u01eb\u2032 4 , pd = k \u2212\u03b18 \u2212 \u01eb 8 . In particular, if Conjecture 2 is true, no polynomial time algorithm can\nachieve regret \u221a nL1\u2212\u03b4T , for any \u03b4 = \u2126(1).\nSimilarly, a stronger form of Conjecture 2 is plausible given our current knowledge. We can allow \u03b1 = \u03c9( 1logn ), \u01eb = \u03c9( 1log k ), and k = o( \u221a n). (These constraints are necessary in order to make sure that n\u2212\u03b1 = o(1), and k\u2212\u01eb = o(1), since unlike planted clique, we are thinking of p and q as asymptotic quantities, so we want to ensure that k\u2212\u03b1\u2212\u01eb = o(k\u2212\u03b1), and n\u2212\u03b1 = o(1).) In this case, Corollary 2 will imply that achieving regret \u221a\nn o(L)T is impossible in polynomial time."}, {"heading": "3 Improved regret bound analysis of log-determinantal regularizer", "text": "We now move to the other result in our paper: matching the lower bound from the previous section. We show that \u201cFollow-the-regularized-leader\u201d with the log-determinant-based regularizer from (Christiano, 2014a) achieves regret O( \u221a nLT ).\nWe will follow the (Hazan, 2009) framework for online convex optimization. The scenario is as follows: at each round t, the player chooses a point ~xt \u2208 K, where K is some convex body. A linear payoff function is revealed, and the player receives a payoff ~Pt \u00b7 ~xt, for some vector ~Pt. The goal is to compete with the \u201cbest decision in hindsight\u201d, i.e. to maximize\ninf ~P1, ~P2,..., ~PT\n{\nE\n[\nT \u2211\ni=1\n~Pi \u00b7 ~xi ]\n\u2212max ~x\u2208K\nT \u2211\ni=1\n~Pi \u00b7 ~x }\nwhere the expectation is over the randomness of the algorithm. Then, \u201cFollow-the-regularized-leader\u201d, with a convex regularizer R(~x), is the following algorithm:\nAlgorithm 1: Follow-the-regularized-leader\n1 ~x1 = argmax~xR(~x); 2 for t \u2190 1 to T do 3 Predict ~xt; 4 Observe the payoff function ~Pt; 5 Update ~xt+1 = argmax~x\u2208K [ \u03bd \u2211t s=1 ~Ps \u00b7 x\u2212R(~x) ] ;\nThe main theorem in (Hazan, 2009) is:\nTheorem. (Hazan, 2009) \u201cFollow-the-regularized-leader\u201d, with a convex regularizer R(x) and an appropriate choice of \u03bd, achieves regret O( \u221a D\u03b3T ), where\nD = max ~x\u2208K |R(~x)| , \u03b3 = max ~x\u2208K, ~Pt ~P\u22bat [\u22072R(~x)]\u22121 ~Pt\nSince we are following the same approach as in (Christiano, 2014a), for us the polytope K will be the convex polytope of pseudo-moments, i.e. positive semidefinite matrices M(i,a),(j,b) where 1 \u2264 i, j \u2264 n, 1 \u2264 a, b \u2264 L, such:\n\u2022 \u2200i, a, j, b, 1 \u2265 M(i,a),(j,b) \u2265 0\n\u2022 \u2200i, j, \u2211a,b M(i,a),(j,b) = 1.\nThen, ~Pt \u2208 [\u22121, 1](nL) 2 , indexed by all pairs ((i, a), (j, b)). Furthermore, for any t, there are nonzeros in ~Pt only over a single pair (it, jt) (the edge that round is played on), and in that case ~Pt((it, a), (jt, b)) is the payoff of playing label a on the it vertex, and label b on the jt vertex. The payoff at round t would be simply\n\u2211\na,b\n~Pt((it, a), (jt, b)) \u00b7M(it,a),(jt,b)\nThe regularizer we use is R(M) = log det(I + LM). In (Christiano, 2014a), it is shown that the diameter parameter D is at most nL, however an additional L2 factor in the analysis of the \u03b3 parameter is lost. (While not quite written in these terms there, the argument in the paper can be very easily cast this way.) Here, we improve that analysis to show that in fact \u03b3 \u2264 4.\nSo, we will simply prove:\nTheorem 3. For online local learning, \u201cfollow-the-regularized-leader\u201d with a regularizer R(~x) = log det(I +LM) achieves regret O( \u221a D\u03b3T ), where\nD = max ~x\u2208K |R(~x)| \u2264 nL , \u03b3 = max ~x\u2208K, ~Pt ~P\u22bat [\u22072R(~x)]\u22121 ~Pt \u2264 4"}, {"heading": "3.1 Calculating the inverse Hessian of the regularizer", "text": "We\u2019ll prove the following lemma first:\nLemma 1. If R(M) = log det(I + LM), then:\n(\u22072R(M))\u22121((i,a),(j,b)),((i\u2032,a\u2032),(j\u2032,b\u2032)) =\n1\nL2 (\u03b4 ((i\u2032, a\u2032), (j, b)) + L \u00b7M ((i\u2032, a\u2032), (j, b))) (\u03b4 ((i, a), (j\u2032, b\u2032)) + L \u00b7M ((i, a), (j\u2032, b\u2032)))\nProof. Let\u2019s proceed stepwise. First, let\u2019s calculate the gradient. For this, the following theorem from matrix calculus is very useful (where adj stands for the adjugate):\nTheorem. Jacobi\u2019s Formula (Magnus and Neudecker, 1995):\n\u2202 det(B)\n\u2202Bi,j = adj(B)\u22bai,j = adj(B)j,i = det(B)B \u22121 j,i\nWith this in mind, the gradient is a simple matter of applying the chain rule. To keep the notation clean, let w = (i, a), x = (j, b), and calculate the gradient of R(M) with respect to Mw,x. We get:\n\u2202R(M) \u2202Mw,x = 1 det(I + L \u00b7M) \u2202 det(I + L \u00b7M) \u2202Mw,x = (I + L \u00b7M)\u22121x,w \u2202(I + L \u00b7M)w,x \u2202Mw,x\n= L(I + L \u00b7M)\u22121x,w\nAgain, to keep the notation lighter, let y = (i\u2032, a\u2032), z = (j\u2032, b\u2032). We will use a little bit of matrix calculus to show:\nLemma 2. \u2202(I+L\u00b7M)\u22121x,w\n\u2202My,z = \u2212L(I + L \u00b7M)\u22121x,y(I + L \u00b7M)\u22121z,w\nProof. Let\u2019s denote by \u2202X\u2202t the matrix with entries \u2202Xi,j \u2202t . Then, we claim the following is true:\n\u2202(XY )\n\u2202t =\n\u2202X\n\u2202t Y + X\n\u2202Y\n\u2202t . This is not hard to check: it\u2019s just due to the fact that in the matrix product XY, the entry\n(XY )i,j is a sum of terms which multiplications of two entries in X and Y. An application of the chain rule gives the above quite easily.\nThen, we use the following trick: BB\u22121 = I , so by the above observation, \u2202B\u2202t B \u22121 + B \u2202B\n\u22121\n\u2202t = 0. Hence, \u2202B\u22121\n\u2202t = \u2212B\u22121 \u2202B\u2202t B\u22121. Let\u2019s apply this observation to B = (I + L \u00b7M) and t = My,z\n\u2202(I + L \u00b7M)\u22121x,w \u2202My,z = \u2212((I + L \u00b7M)\u22121 \u2202(I + L \u00b7M) \u2202My,z (I + L \u00b7M)\u22121)x,w (2)\n= \u2212 \u2211\np,q\n(I + L \u00b7M)\u22121x,p \u2202(I + L \u00b7M)p,q\n\u2202My,z (I + L \u00b7M)\u22121q,w (3)\nNow, the term \u2202(I+L\u00b7M)p,q\u2202My,z is non-zero only if p = y, q = z, in which case it is equal to L. Hence, we get:\n(3) = \u2212L(I + L \u00b7M)\u22121x,y(I + L \u00b7M)\u22121z,w as needed.\nWith this in mind, the Hessian is obvious:\n\u22022R(M) \u2202Mw,x\u2202My,z = \u2202 \u2202My,z L(I + L \u00b7M)\u22121x,w = \u2212L2(I + L \u00b7M)\u22121x,y(I + L \u00b7M)\u22121z,w\nLet\u2019s call the Hessian matrix H(w,x),(y,z). We claim that the inverse H\u0303 has the following explicit form:\nH\u0303(w,x),(y,z) = \u2212 1\nL2 (I + L \u00b7M)x,y(I + L \u00b7M)w,z\nTo show this, it\u2019s just a matter of verifying that (HH\u0303)(w,x),(y,z) = \u03b4((w, x), (y, z)). But this is easy enough:\n(HH\u0303)(w,x),(y,z) = \u2211\np,q\nH(w,x),(p,q)H\u0303(p,q),(y,z)\n= \u2211\np,q\n(\u2212L2(I + L \u00b7M)\u22121x,p(I + L \u00b7M)\u22121w,q)(\u22121/L2(I + L \u00b7M)q,y(I + L \u00b7M)p,z)\n= \u2211\np\n(I + L \u00b7M)\u22121x,p(I + L \u00b7M)p,z \u2211\nq\n(I + L \u00b7M)\u22121w,q(I + L \u00b7M)q,y\n= \u03b4(x, z)\u03b4(w, y) = \u03b4((w, x), (y, z))\nThis finishes the proof of Lemma 1."}, {"heading": "3.2 Bounding \u03b3", "text": "Finally, we want to estimate \u03b3 = max~x\u2208K, ~Pt ~P\u22bat [\u22072R(~x)]\u22121 ~Pt, which will be relatively easy. Given the form of ~Pt, we can write this as \u2211\na,b,c,d\nPa,bPc,d[\u22072R(~x)]\u22121((it,a),(jt,b)),((it,c),(jt,d)) where (it, jt) is the edge chosen at timestep t,\nand Pa,b is the payoff of playing label a on vertex it and label b on vertex jt. So, we want to bound \u2211\na,b,c,d\nPa,bPc,d[\u22072R(~x)]\u22121((it,a),(jt,b)),((it,c),(jt,d))\n= \u2211\na,b,c,d\n\u2212 1 L2 Pa,bPc,d(I + L \u00b7M)(it,c),(jt,b)(I + L \u00b7M)(it,a),(jt,d)\nHowever, since Pa,b,Pc,d \u2208 [\u22121, 1], it suffices to upper bound \u2211\na,b,c,d\n1\nL2 (I + L \u00b7M)(it,c),(jt,b)(I + L \u00b7M)(it,a),(jt,d) =\n1\nL2\n\u2211\nb,c\n(I + L \u00b7M)(it,c),(jt,b) \u2211\na,d\n(I + L \u00b7M)(it,a),(jt,d) = 1\nL2\n\n\n\u2211\ne,f\n(I + L \u00b7M)(it,e),(jt,f)\n\n\n2\nThen we note the following: \u2211\ne,f\n(I + L \u00b7M)(it,e),(jt,f) = \u2211\ne,f\nI(it,e),(jt,f) + L \u2211\ne,f\nM(it,e),(jt,f)\n= L+ L = 2L\nwhere we have used the marginalization property of M and the definition of the identity."}, {"heading": "4 Conclusion and open problems", "text": "In this paper, we studied the optimal regret achievable in polynomial time for online local learning. We showed that follow the regularized leader with a log-determinantal regularizer achieves regret \u221a nLT , and we proved a matching lower bound based both on planted clique and planted dense subgraph. An interesting open problem is to investigate whether the regret bound can be improved when allowing subexponential time algorithms, since both planted clique and planted dense subgraph admit sub-exponential time algorithms. A natural approach is to maintain higher order pseudo-moments, following similar approaches when using the Lasserre/Sum of Squares hierarchies. The key difficulty is the right choice of the regularizer. The log determinant regularizer is one particular approximation of the entropy of a distribution over the set of all possible labelings, matching the pseudo-moments that we maintain during the algorithm \u2013 it roughly corresponds to the entropy of a Gaussian with matching second moments. (Wainwright and Jordan, 2006) Even if we one has access to higher order moments, it is not clear if there is a better candidate than the log determinant.\nAnother open problem is basing the hardness of achieving regret \u221a nLT on more standard, worst case assumptions (e.g. NP-hardness, UGC-hardness). Indeed, it isn\u2019t obvious that randomness is required for proving hardness, but it does seem to help. This mirrors the current state of affairs in improper learning, where the only known hardness results are either based on cryptographic assumptions or very recently, refuting random DNF formulas (Daniely et al., 2014)."}, {"heading": "A Relegated proofs", "text": "Corollary 1. Let \u01eb = \u2126(1). If we can achieve regret \u221a nL1\u2212\u01ebT in time polynomial in n, L, T , we can distinguishing between G(n, 1/2) and G(n, 1/2, n1/2\u2212 \u01eb 6 ) with probability 45 in polynomial time. In particular, if Conjecture 1 is\ntrue, no polynomial time algorithm can achieve regret \u221a nL1\u2212\u03b4T , for any \u03b4 = \u2126(1).\nProof. For ease of notation, let\u2019s call \u01eb\u0303 := \u01eb6 . Since \u01eb\u0303 = \u03c9( 1 logn ), directly applying Theorem 1, to distinguish between G(n, 1/2) and G(n, 1/2, n1/2\u2212\u01eb\u0303), it\u2019s sufficient to achieve regret \u221a nL\u03b2T , for \u03b2 = (1\u2212 \u01eb\u0303) 2\n1 + 2\u01eb\u0303 \u22121. Since\n2 1+2\u01eb\u0303 = 2\u2212 4\u01eb\u03031+2\u01eb\u0303 ,\n(1\u2212 \u01eb\u0303) 2 1 + 2\u01eb\u0303 = (1\u2212 \u01eb\u0303) ( 2\u2212 4\u01eb\u0303 1 + 2\u01eb\u0303 ) = 2\u2212 ( 2 + 4 1 + 2\u01eb\u0303 ) \u01eb\u0303+ 2\u01eb\u03032 1 + 2\u01eb\u0303 \u2265 2\u2212 6\u01eb\u0303 = 2\u2212 \u01eb\nHence, if we can achieve regret \u221a nL1\u2212\u01ebT , we can distinguish between G(n, 1/2) and G(n, 1/2, n 1 2\u2212 \u01eb 6 ), as we needed.\nTheorem 2. Let \u01eb, \u03b1, k satisfy the conditions of Conjecture 2. If regret \u221a nL\u03b2T for\n\u03b2 = 2\n1 2 \u2212\n( 1 2 \u2212 \u01eb\u2032 )\n(\u03b1+ \u01eb)\u2212 \u03c9 (\n1 logn\n)\n1 2 + \u01eb\n\u2032 \u2212 1\nis achievable in polynomial time, then one can distinguish between G(n, ps) andG(n, ps, k, pd), where ps = n\u2212\u03b1, k = n 1 2\u2212\u01eb \u2032\n, pd = k \u2212\u03b1\u2212\u01eb with probability 45 in polynomial time.\nProof. We proceed in the same way as in the proof of Theorem 1. Namely, we will produce an instance for the online learning algorithm by partitioning our graph randomly into n\u2032 = nl clusters, each of size n l , where l = 10 n k . As before, we will query all T pairs of clusters, and the payoff will be 1 if there is an edge between the labels supplied by the learner, and 0 otherwise. Finally, we run the distinguisher R = n 4\nk3.7p2 d\ntimes, and we output planted if the average\npayoff from the R runs is at least 12 ( 2k/25 2 ) \u00b7 pd, and otherwise random. As before, we claim that in the case when the graph is G(n, ps), with probability at least 45 , any algorithm will\nachieve average payoff at most T \u00b7 ps + 10 \u221a T \u00b7 ps = ( k/10\n2\n) \u00b7 ps + 10 \u221a ( k/10\n2\n)\n\u00b7 ps.\nWe use the same notation as before: the pair of clusters queried at time step t is (Cit , Cjt), the random variable for the payoff in round t on the r-th repetition of the online learning problem is Prit,jt , and Ga,b is a random 0-1 indicator variable for whether there is an edge between vertices a, b.\nFor the same reasons as before, the variables Pit,jt = \u2211R r=1 Prit,jt are mutually independent. Furthermore,\nE [ 1 RPii,jt ] = ps, and 1RPit,jt always is between 0 and 1. So, by Chernoff, Pr [ T \u2211\nt=1\nPt \u2265 T \u00b7 ps ( 1 + 10\u221a Tps )\n]\n\u2264\ne\u2212100/3, i.e. Pr\n[\nT \u2211\nt=1\nPt \u2265 T \u00b7 ps + 10 \u221a Tps]\n]\n\u2264 e\u2212100/3. In particular, with probability at least 45 , any algorithm\ngets payoff at most T \u00b7 ps + 10 \u221a T \u00b7 ps.\nIn the planted case, completely the same as in Theorem 1, with probability 1 \u2212 5e\u221210 \u2265 1415 , there will be at least 2k 25 clusters which contain a vertex from the planted graph.\nConditioned on the above event happening, we claim that any labeling that chooses the vertex from the planted\ngraph in the clusters that contain one achieves a payoff of at least ( 2k/25 2 ) \u00b7pd\u221210 \u221a ( 2k/25 2 )\n\u00b7 pd with probability at least 15 16 . To show this, first notice that conditioned on belonging to two different clusters, the probability of an edge existing between two vertices in the planted graph is a Bernoulli 0\u22121 variable, which is 1 with probability pd. This is true since\nthe partitioning is done independently from the graph. But then, the payoff is at least ( 2k/25 2 ) \u00b7 pd \u2212 10 \u221a ( 2k/25 2 )\n\u00b7 pd with probability at least 1\u2212 e\u2212100/3 \u2265 78 by Chernoff.\nHence, in the planted case, again, with probability at least 78 , there is a fixed labeling with payoff at least ( 2k/25 2 ) \u00b7 pd \u2212 10 \u221a ( 2k/25 2 ) \u00b7 pd. If the regret is \u221a n\u2032l\u03b2T , and such a labeling exists, using a Hoeffding bound as before, with\nprobability at least 1 \u2212 o(1) the average payoff will be at least ( 2k/25 2 ) \u00b7 pd \u2212 10 \u221a ( 2k/25 2 )\n\u00b7 pd \u2212 o(k2pd). But since ps = o(pd) and k2pd = \u03c9(1), if the regret is \u221a n\u2032l\u03b2T , such that \u221a n\u2032l\u03b2T = o(k2 \u00b7 pd), the distinguisher constructed outputs the correct answer with probability at least 45 . Since nl = \u0398(k), it\u2019s sufficient to show:\n\u221a n\u2032l\u03b2T = o(( n\nl )2k\u2212\u03b1\u2212\u01eb) \u21d4\nl(\u03b2+1)/2 = o(n 1 2\u2212( 1 2\u2212\u01eb \u2032)(\u03b1\u2032+\u01eb)) (4)\nPlugging in l = 10nk = 10n 1 2+\u01eb \u2032 , 4 is equivalent n( \u03b2+1 2 )( 1 2+\u01eb \u2032) = o(n 1 2\u2212( 1 2\u2212\u01eb \u2032)(\u03b1\u2032+\u01eb)) As before, for this it\u2019s sufficient that,\n(\n\u03b2 + 1\n2\n)(\n1 2 + \u01eb\u2032\n)\n=\n(\n1 2 \u2212 ( 1 2 \u2212 \u01eb\u2032 ) (\u03b1+ \u01eb) ) \u2212 \u03c9 ( 1 logn )\nIt\u2019s easy to check for our choice of \u03b2 that this is satisfied, which finishes the proof.\nCorollary 2. Let \u01eb\u2032, \u03b1, \u01eb = \u2126(1) and \u03b1 \u2265 \u01eb. If we can achieve regret \u221a nL1\u2212\u01eb\u2032\u2212\u03b1\u2212\u01ebT in polynomial time, we can distinguish between G(n, ps) and G(n, ps, k, pd) in polynomial time with probability 45 , where ps = n \u2212\u03b18 , k = n 1 2 \u2212 \u01eb\u2032 4 , pd = k \u2212\u03b1 8 \u2212 \u01eb\n8 . In particular, if Conjecture 2 is true, no polynomial time algorithm can achieve regret\u221a nL1\u2212\u03b4T , for any \u03b4 = \u2126(1).\nProof. For notational ease, let \u03b1\u0303 = \u03b18 , \u01eb\u0303 = \u01eb 8 , \u01eb\u0303 \u2032 = \u01eb \u2032\n4 . First, notice that ps = o(pd). Indeed, since ps = n\u2212\u03b1\u0303 and pd = k\u2212\u03b1\u0303\u2212\u01eb\u0303,\nps = o(pd) \u21d4 n\u2212\u03b1\u0303 = o(n\u2212( 1 2\u2212\u01eb\u0303\u2032)(\u03b1\u0303+\u01eb\u0303))\nHowever, since \u03b1 \u2265 \u01eb,\n\u03b1\u0303 \u2265 1 2 (\u03b1\u0303+ \u01eb\u0303) = ( 1 2 \u2212 \u01eb\u0303\u2032)(\u03b1\u0303 + \u01eb\u0303) + \u01eb\u0303\u2032(\u03b1\u0303+ \u01eb\u0303)\nSince \u01eb\u0303\u2032, \u03b1\u0303, \u01eb\u0303 = \u2126(1), clearly this implies n\u2212\u03b1\u0303 = o(n\u2212( 1 2\u2212\u01eb\u0303\u2032)(\u03b1\u0303+\u01eb\u0303)) Since clearly \u01eb\u0303, \u01eb\u0303\u2032, \u03b1\u0303 = \u03c9( 1logn ), directly applying Theorem 2, to distinguish betweenG(n, ps) andG(n, ps, k, pd),\nwhere k = n 1 2\u2212\u01eb\u0303\u2032 , ps = n \u2212\u03b1\u0303 and pd = k\u2212\u03b1\u0303\u2212\u01eb\u0303, achieving regret \u221a nL\u03b2T is sufficient, for\n\u03b2 = 2 1 2 \u2212 2(12 + \u01eb\u0303\u2032)(\u03b1\u0303+ \u01eb\u0303)\n1 2 + \u01eb\u0303\n\u2032 \u2212 1 = 1\u2212 4( 1 2 + \u01eb\u0303 \u2032)(\u03b1\u0303 + \u01eb\u0303) 1 2 + \u01eb\u0303 \u2032 \u2212 1\n= 1\u2212 2\u01eb\u0303 \u2032 + 4(12 + \u01eb\u0303 \u2032)(\u03b1\u0303 + \u01eb\u0303) 1 2 + \u01eb\u0303 \u2032 \u2265 1\u2212 4\u01eb\u0303\u2032 \u2212 8(1 2 + \u01eb\u0303\u2032)(\u03b1\u0303+ \u01eb\u0303) \u2265 1\u2212 4\u01eb\u0303\u2032 \u2212 8\u03b1\u0303\u2212 8\u01eb\u0303\nwhere the next to last inequality holds since \u01eb\u0303\u2032 \u2265 0 and the last since \u01eb\u0303\u2032 \u2264 12 . So, if we can achieve regret\n\u221a nL1\u22124\u01eb\u0303\u2032\u22128\u03b1\u0303\u22128\u01eb\u0303T = \u221a nL1\u2212\u01eb\u2032\u2212\u03b1\u2212\u01eb\nwe can distinguish between G(n, ps) and G(n, ps, k, pd), as we needed."}], "references": [{"title": "Public-key cryptography from different assumptions", "author": ["Benny Applebaum", "Boaz Barak", "Avi Wigderson"], "venue": "In Proceedings of the forty-second ACM symposium on Theory of computing,", "citeRegEx": "Applebaum et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Applebaum et al\\.", "year": 2010}, {"title": "Computational complexity and information asymmetry in financial products", "author": ["Sanjeev Arora", "Boaz Barak", "Markus Brunnermeier", "Rong Ge"], "venue": "In ICS,", "citeRegEx": "Arora et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Arora et al\\.", "year": 2010}, {"title": "Detecting high logdensities: an o (n 1/4) approximation for densest k-subgraph", "author": ["Aditya Bhaskara", "Moses Charikar", "Eden Chlamtac", "Uriel Feige", "Aravindan Vijayaraghavan"], "venue": "In Proceedings of the forty-second ACM Symposium on Theory of Computing,", "citeRegEx": "Bhaskara et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Bhaskara et al\\.", "year": 2010}, {"title": "Polynomial integrality gaps for strong sdp relaxations of densest k-subgraph", "author": ["Aditya Bhaskara", "Moses Charikar", "Aravindan Vijayaraghavan", "Venkatesan Guruswami", "Yuan Zhou"], "venue": "In Proceedings of the twenty-third annual ACMSIAM Symposium on Discrete Algorithms,", "citeRegEx": "Bhaskara et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bhaskara et al\\.", "year": 2012}, {"title": "Online local learning via semidefinite programming", "author": ["Paul Christiano"], "venue": "In Proceedings of the 53rd Annual IEEE Symposium on Foundations of Computer Science (FOCS),", "citeRegEx": "Christiano.,? \\Q2014\\E", "shortCiteRegEx": "Christiano.", "year": 2014}, {"title": "Open problem: Online local learning", "author": ["Paul Christiano"], "venue": "In Proceedings of The 27th Conference on Learning Theory, pages 1290\u20131294,", "citeRegEx": "Christiano.,? \\Q2014\\E", "shortCiteRegEx": "Christiano.", "year": 2014}, {"title": "From average case complexity to improper learning complexity", "author": ["Amit Daniely", "Nati Linial", "Shai Shalev-Shwartz"], "venue": "In Proceedings of the 46th Annual ACM Symposium on Theory of Computing,", "citeRegEx": "Daniely et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Daniely et al\\.", "year": 2014}, {"title": "Learning probabilistic prediction functions", "author": ["Alfredo DeSantis", "George Markowsky", "Mark N Wegman"], "venue": "In Foundations of Computer Science,", "citeRegEx": "DeSantis et al\\.,? \\Q1988\\E", "shortCiteRegEx": "DeSantis et al\\.", "year": 1988}, {"title": "Statistical algorithms and a lower bound for detecting planted cliques", "author": ["Vitaly Feldman", "Elena Grigorescu", "Lev Reyzin", "Santosh Vempala", "Ying Xiao"], "venue": "In Proceedings of the forty-fifth annual ACM symposium on Theory of computing,", "citeRegEx": "Feldman et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Feldman et al\\.", "year": 2013}, {"title": "The convex optimization approach to regret minimization", "author": ["Elad Hazan"], "venue": "Technical report,", "citeRegEx": "Hazan.,? \\Q2009\\E", "shortCiteRegEx": "Hazan.", "year": 2009}, {"title": "Near-optimal algorithms for online matrix prediction", "author": ["Elad Hazan", "Satyen Kale", "Shai Shalev-Shwartz"], "venue": "In Proceedings of The 25th Conference on Learning Theory,", "citeRegEx": "Hazan et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hazan et al\\.", "year": 2012}, {"title": "Playing games with approximation algorithms", "author": ["Sham M Kakade", "Adam Tauman Kalai", "Katrina Ligett"], "venue": "SIAM Journal on Computing,", "citeRegEx": "Kakade et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Kakade et al\\.", "year": 2009}, {"title": "Efficient algorithms for online decision problems", "author": ["Adam Kalai", "Santosh Vempala"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Kalai and Vempala.,? \\Q2005\\E", "shortCiteRegEx": "Kalai and Vempala.", "year": 2005}, {"title": "Learning hurdles for sleeping experts", "author": ["Varun Kanade", "Thomas Steinke"], "venue": "ACM Transactions on Computation Theory (TOCT),", "citeRegEx": "Kanade and Steinke.,? \\Q2014\\E", "shortCiteRegEx": "Kanade and Steinke.", "year": 2014}, {"title": "The weighted majority algorithm", "author": ["Nick Littlestone", "Manfred K Warmuth"], "venue": "Information and computation,", "citeRegEx": "Littlestone and Warmuth.,? \\Q1994\\E", "shortCiteRegEx": "Littlestone and Warmuth.", "year": 1994}, {"title": "Matrix differential calculus with applications in statistics and econometrics", "author": ["Jan R Magnus", "Heinz Neudecker"], "venue": null, "citeRegEx": "Magnus and Neudecker.,? \\Q1995\\E", "shortCiteRegEx": "Magnus and Neudecker.", "year": 1995}, {"title": "Sum-of-squares lower bounds for the planted clique problem", "author": ["Raghu Meka", "Aaron Potechin", "Avi Wigderson"], "venue": "In Proceedings of the forty-seventh ACM Symposium on Theory of Computing,", "citeRegEx": "Meka et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Meka et al\\.", "year": 2015}, {"title": "Optimal algorithms and inapproximability results for every csp", "author": ["Prasad Raghavendra"], "venue": "In Proceedings of the fortieth annual ACM symposium on Theory of computing,", "citeRegEx": "Raghavendra.,? \\Q2008\\E", "shortCiteRegEx": "Raghavendra.", "year": 2008}, {"title": "Aggregating strategies", "author": ["V Vavock"], "venue": "In Conference on Computational Learning Theory,", "citeRegEx": "Vavock.,? \\Q1990\\E", "shortCiteRegEx": "Vavock.", "year": 1990}, {"title": "Log-determinant relaxation for approximate inference in discrete markov random fields", "author": ["Martin J Wainwright", "Michael I Jordan"], "venue": "Signal Processing, IEEE Transactions on,", "citeRegEx": "Wainwright and Jordan.,? \\Q2006\\E", "shortCiteRegEx": "Wainwright and Jordan.", "year": 2006}, {"title": "Understanding belief propagation and its generalizations", "author": ["Jonathan S Yedidia", "William T Freeman", "Yair Weiss"], "venue": "Exploring artificial intelligence in the new millennium,", "citeRegEx": "Yedidia et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Yedidia et al\\.", "year": 2003}], "referenceMentions": [{"referenceID": 14, "context": "1 Introduction Online learning is a classic area of machine learning starting from the seminal work of (Littlestone and Warmuth, 1994), (DeSantis et al.", "startOffset": 103, "endOffset": 134}, {"referenceID": 7, "context": "1 Introduction Online learning is a classic area of machine learning starting from the seminal work of (Littlestone and Warmuth, 1994), (DeSantis et al., 1988) and (Vavock, 1990).", "startOffset": 136, "endOffset": 159}, {"referenceID": 18, "context": ", 1988) and (Vavock, 1990).", "startOffset": 12, "endOffset": 26}, {"referenceID": 14, "context": "The weighted majority algorithm (Littlestone and Warmuth, 1994) achieves the optimal regret of O( \u221a T logN) for the above mentioned problem (T is the number of rounds, N is the total number of experts) but is computationally efficient only when the number of experts is small.", "startOffset": 32, "endOffset": 63}, {"referenceID": 12, "context": "Hence, there has been a significant effort in designing polynomial time algorithms with optimal regret bounds for various such problems such as collaborative filtering, online gambling, and online max cut ((Kalai and Vempala, 2005), (Hazan et al.", "startOffset": 206, "endOffset": 231}, {"referenceID": 10, "context": "Hence, there has been a significant effort in designing polynomial time algorithms with optimal regret bounds for various such problems such as collaborative filtering, online gambling, and online max cut ((Kalai and Vempala, 2005), (Hazan et al., 2012), (Kakade et al.", "startOffset": 233, "endOffset": 253}, {"referenceID": 11, "context": ", 2012), (Kakade et al., 2009), (Hazan, 2009)) Princeton University, Computer Science Department.", "startOffset": 9, "endOffset": 30}, {"referenceID": 9, "context": ", 2009), (Hazan, 2009)) Princeton University, Computer Science Department.", "startOffset": 9, "endOffset": 22}, {"referenceID": 17, "context": "The semidefinite relaxation upon which Theorem 3 is based is the same one considered in (Raghavendra, 2008), who proves that under the Unique Games Conjecture, it actually achieves the best approximation factor among all polynomial-time algorithms.", "startOffset": 88, "endOffset": 107}, {"referenceID": 17, "context": "Our result can be viewed as an extension of (Raghavendra, 2008): for the online version of CSPs, follow-the-regularized leader on the same semidefinite relaxation along with a log determinantal regularizer is the \u201coptimal\u201d algorithm, under widely believed conjectures.", "startOffset": 44, "endOffset": 63}, {"referenceID": 8, "context": "Previous sequences of work (Feldman et al., 2013), (Meka et al.", "startOffset": 27, "endOffset": 49}, {"referenceID": 16, "context": ", 2013), (Meka et al., 2015), show that wide classes of natural polynomial time algorithms cannot efficiently distinguish between these two cases when the size of the planted clique is n 1 2\u2212\u01eb, and it is conjectured that in fact there is no polynomial time algorithm for this task.", "startOffset": 9, "endOffset": 28}, {"referenceID": 2, "context": "First, the current best known algorithm for this distinguishing problem from (Bhaskara et al., 2010) runs in time n \u0398(\u01eb) .", "startOffset": 77, "endOffset": 100}, {"referenceID": 2, "context": "Second, it\u2019s possible to show (Bhaskara et al., 2010) that spectral methods do not work in this regime.", "startOffset": 30, "endOffset": 53}, {"referenceID": 1, "context": "((Arora et al., 2010), (Applebaum et al.", "startOffset": 1, "endOffset": 21}, {"referenceID": 0, "context": ", 2010), (Applebaum et al., 2010)) The fact that state of the art algorithms have a much worse running time for this problem in comparison to planted clique is our motivation for putting forth this conjecture.", "startOffset": 9, "endOffset": 33}, {"referenceID": 9, "context": "We will follow the (Hazan, 2009) framework for online convex optimization.", "startOffset": 19, "endOffset": 32}, {"referenceID": 9, "context": "The main theorem in (Hazan, 2009) is: Theorem.", "startOffset": 20, "endOffset": 33}, {"referenceID": 9, "context": "(Hazan, 2009) \u201cFollow-the-regularized-leader\u201d, with a convex regularizer R(x) and an appropriate choice of \u03bd, achieves regret O( \u221a D\u03b3T ), where D = max ~x\u2208K |R(~x)| , \u03b3 = max ~x\u2208K, ~ Pt ~ P t [\u22072R(~x)]\u22121 ~ Pt Since we are following the same approach as in (Christiano, 2014a), for us the polytope K will be the convex polytope of pseudo-moments, i.", "startOffset": 0, "endOffset": 13}, {"referenceID": 15, "context": "Jacobi\u2019s Formula (Magnus and Neudecker, 1995): \u2202 det(B) \u2202Bi,j = adj(B)\u22bai,j = adj(B)j,i = det(B)B \u22121 j,i", "startOffset": 17, "endOffset": 45}], "year": 2015, "abstractText": "We resolve an open question from (Christiano, 2014b) posed in COLT\u201914 regarding the optimal dependency of the regret achievable for online local learning on the size of the label set. In this framework, the algorithm is shown a pair of items at each step, chosen from a set of n items. The learner then predicts a label for each item, from a label set of size L and receives a real valued payoff. This is a natural framework which captures many interesting scenarios such as online gambling and online max cut. (Christiano, 2014a) designed an efficient online learning algorithm for this problem achieving a regret of O( \u221a nLT ), where T is the number of rounds. Information theoretically, one can achieve a regret of O( \u221a n logLT ). One of the main open questions left in this framework concerns closing the above gap. In this work, we provide a complete answer to the question above via two main results. We show, via a tighter analysis, that the semi-definite programming based algorithm of (Christiano, 2014a) in fact achieves a regret of O( \u221a nLT ). Second, we show a matching computational lower bound. Namely, we show that a polynomial time algorithm for online local learning with lower regret would imply a polynomial time algorithm for the planted clique problem which is widely believed to be hard. We prove a similar hardness result under a related conjecture concerning planted dense subgraphs that we put forth. Unlike planted clique, the planted dense subgraph problem does not have any known quasi-polynomial time algorithms. Computational lower bounds for online learning are relatively rare, and we hope that the ideas developed in this work will lead to lower bounds for other online learning scenarios as well.", "creator": "LaTeX with hyperref package"}}}