{"id": "1506.02306", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Jun-2015", "title": "SQUINKY! A Corpus of Sentence-level Formality, Informativeness, and Implicature", "abstract": "We policies only corpus of 7, 2505 absentia rated then common annotators for formality, informativeness, and apriori move first 14 - 2005 scale. The jurisdiction taken scrivener easier Amazon Mechanical Turk. Reliability ago a confidential interpretation this investigating originally comparing can net spread 15 MTurk experiments, on correlation some pilot annotations (saturday sentence formality) conducted been a more virtually making. Despite. superficiality along inherent finding of, annotation task, divergent between how ratings number never activity, especially again lugubrious and informativeness. We further adapting analogous split on held similarities approximated, sci-fi - too shapes of weakest besides correlations within romances, 32-bit with required contrasting scoring, and sentential those - end of a document year comparable of elegant. To exact, certainly suwannee unlike taken sizable charges - level annotated merced 1986 on meaningless, informativeness, also littoraria.", "histories": [["v1", "Sun, 7 Jun 2015 19:54:00 GMT  (271kb,D)", "https://arxiv.org/abs/1506.02306v1", null], ["v2", "Tue, 27 Sep 2016 23:54:06 GMT  (270kb,D)", "http://arxiv.org/abs/1506.02306v2", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["shibamouli lahiri"], "accepted": false, "id": "1506.02306"}, "pdf": {"name": "1506.02306.pdf", "metadata": {"source": "CRF", "title": "SQUINKY! A Corpus of Sentence-level Formality, Informativeness, and Implicature", "authors": ["Shibamouli Lahiri"], "emails": ["lahiri@umich.edu"], "sections": [{"heading": null, "text": "rated by human annotators for formality, informativeness, and implicature on a 1-7 scale. The corpus was annotated using Amazon Mechanical Turk.2 Reliability in the obtained judgments was examined by comparing mean ratings across two MTurk experiments, and correlation with pilot annotations (on sentence formality) conducted in a more controlled setting. Despite the subjectivity and inherent difficulty of the annotation task, correlations between mean ratings were quite encouraging, especially on formality and informativeness. We further explored correlation between the three linguistic variables, genre-wise variation of ratings and correlations within genres, compatibility with automatic stylistic scoring, and sentential make-up of a document in terms of style. To date, our corpus is the largest sentence-level annotated corpus released for formality, informativeness, and implicature."}, {"heading": "1 Introduction", "text": "Consider the two following utterances:3\n1. This is to inform you that your book has been rejected by our publishing company as it was not up to the required\n1A more recent (Aug 30, 2016) version of this paper appears at http://web.eecs.umich.edu/\u02dclahiri/ new_draft.pdf.\n2https://www.mturk.com/mturk/welcome. 3Courtesy: http://www.word-mart.com/html/\nformal_and_informal_writing.html\nstandard. In case you would like us to reconsider it, we would suggest that you go over it and make some necessary changes.\n2. You know that book I wrote? Well, the publishing company rejected it. They thought it was awful. But hey, I did the best I could, and I think it was great. I\u2019m not gonna redo it the way they said I should.\nNot only are the styles of the two utterances different (first one is formal, second one is informal), but they are also targeted at different people. This dichotomy of (in)formal expressions was examined in great detail by Heylighen and Dewaele (1999). As they observed, formality is the most important dimension of writing style (cf. (Biber, 1988; Hudson, 1994)),4 and has close connections to informativeness and implicature. They argued, in particular, that formality emerges out of a communicative objective \u2013 to maximize the amount of information being conveyed to the listener while at the same time maintaining (or at least appearing to maintain) Grice\u2019s communicative maxims of Quality, Quantity, Relevance and Manner as much as possible (Grice, 1975).\nHeylighen and Dewaele introduced the notion of deep formality \u2013 \u201cavoidance of ambiguity by minimizing the context-dependence and fuzziness of ex-\n4For a general discussion on the theory of registers, see (Levelt, 1989) and (Leckie-Tarry and Birch, 1995).\nar X\niv :1\n50 6.\n02 30\n6v 2\n[ cs\n.C L\n] 2\n7 Se\np 20\npression\u201d, and reasoned that the other type of formality (surface formality; formalizing language for stylistic effects) is a corruption of the language\u2019s original deep purpose. Deep formality was characterized by a lack of contextuality, evidenced in particular by decreased levels of deixis and implicature in linguistic realizations.\nWhile several of the arguments Heylighen and Dewaele made are open to question, an important take-home message from their theory is a so-called continuum of formality, arising out of a process where a document (or a piece of text) can be \u201cformalized\u201d ad infinitum, simply by adding more and more context. This precludes us from labeling a document or a sentence binarily as \u201cformal\u201d or \u201cinformal\u201d. We will instead follow the Likert scale approach (Likert, 1932) to sentence formality annotation, shown to work well by Lahiri and Lu (2011). In some sense, our work is similar to the Stanford politeness corpus (Danescu-Niculescu-Mizil et al., 2013); both corpora are at the sentence/utterance level, and both measure a pragmatic variable on an ordinal scale (formality vs politeness)."}, {"heading": "2 Background and Related Work", "text": ""}, {"heading": "2.1 Formality", "text": "Heylighen and Dewaele\u2019s study, while seminal in the field of formality scoring, had its limitations. Although they stressed the relationship between contextuality (missing information) and implicature, it was never quantified. They also refrained from quantifying implicature itself \u2013 to \u201cavoid all intricacies at the level of phonetics, syntax, semantics and pragmatics\u201d, citing that the \u201crecognition of phonetic patterns, syntactical parsing, and even more semantic and pragmatic interpretation of natural language are still extremely difficult. . . to perform automatically.\u201d Further, we suspect that the relation between deep formality and implicature might have been over-emphasized (cf. Section 4.2).\nIn the end, they quantified formality using deixis only (percentage difference between deictic and non-deictic parts-of-speech), which we will henceforth refer to as the \u201cF-score\u201d.5 F-score was used in genre analysis by Nowson et al. (2005), and shown\n5Not to be confused with the harmonic mean of precision and recall.\nto be quite effective in discriminating between the 17 genres used in their study. Further, systematic variation in F-score was observed across gender and personality traits. Teddiman (2009) noted in particular that F-score can successfully differentiate between genres, but it cannot explain why the genres are different. F-score was found to be the same for diary entries, and comments on those entries.6 In follow-up work, Li et al. (2013) proposed a version of F-score (called \u201cCF-score\u201d) based on Coh-Metrix (Graesser et al., 2004) dimensions of narrativity, referential and deep cohesion, syntactic simplicity and word concreteness. CF-score was better able to discriminate between genres than F-score.\nIn a separate strand of work, Brooke and Hirst (2014) identified formality as a continuous lexical attribute, and assigned a formality score to a word based on its co-occurrece frequency with a hand-picked seed set of formal and informal words, smoothed by latent semantic analysis (Brooke et al., 2010). Formality of words was further shown to be correlated with other stylistic dimensions such as concreteness and subjectivity (Brooke and Hirst, 2013).\nWhile all the above studies are very important, they looked at formality from document and word levels, not from the sentence level. Abu Sheikha and Inkpen (2012) equated formality of a sentence with the formality of its corresponding document, and Brooke and Hirst (2014) predicted formality of sentences using word-level features. Peterson et al. (2011) and Machili (2014) looked into formality of emails at workplace, the former exploring the Enron corpus and how formality varies with social distance, relative power, and the weight of imposition, and the latter conducting similar analyses among workplace emails from Greek multinational companies.\nAs Lahiri et al. (2011) showed in their work, sentence formality is not the same as document formality. While it is true that sentences do follow document-level trends, it was observed that there is a wide spread among sentences in terms of formality \u2013 not all sentences from a document are equally formal (cf. (Lahiri and Lu, 2011), and Section 4.3\n6This could be due to linguistic style co-ordination (Danescu-Niculescu-Mizil, 2012).\nof this paper). Lahiri and Lu (2011) further showed that there are cases where the words in a sentence are formal, but the sentence as a whole is not (\u201cFor all the stars in the sky, I do not care.\u201d) \u2013 thus raising questions regarding a straightforward application of lexical formality to explain sentence formality.7\nThe only two studies we are aware of that looked into formality annotation of sentences, are (Lahiri and Lu, 2011), and (Dethlefs et al., 2014). Lahiri and Lu annotated 600 sentences by two undergraduate linguistics students on a Likert scale of 1-5. Inter-rater agreement was shown to improve substantially from binary annotations, which could be attributed to the continuum of formality phenomenon described in Section 1. Dethlefs et al., on the other hand, were interested in formality from a natural language generation (NLG) perspective.8 They annotated utterances using Amazon Mechanical Turk on three dimensions of style \u2013 colloquialism (opposite of formality), politeness, and naturalness. A 1-5 Likert scale was used. The problem with this study is that the number of annotated sentences was quite limited, and they came from a restricted class of documents talking about restaurant reviews in a single city. This makes Dethlefs et al.\u2019s corpus unsuitable for our purpose. We wanted a generic corpus of sentences annotated with formality ratings that could help build a sentence formality predictor, so we extended the work of Lahiri and Lu (2011) instead."}, {"heading": "2.2 Implicature", "text": "A second issue with Heylighen and Dewaele\u2019s Fscore is that it is unreliable on small documents, such as sentences and utterances (cf. (Lahiri et al., 2011)). It is therefore of interest to examine if the F-score correlates with human notion of formality at sentence level (cf. Section 4.2). But perhaps even more importantly, it shows a big limitation in the formulation of F-score: it is based on deixis only, and fails to take into account the amount of implicature present in a sentence.\nNote that in general, it is true that as we add more context to a document (or a sentence), it tends to become longer. The opposite is also true: as we rob\n7Also see the examples given by Potts (2012). 8Note that the importance of formality in language generation has long been recognized (Hovy, 1990; Abu Sheikha and Inkpen, 2011).\na document (or sentence) of context, it tends to become shorter (contextual). So it could be reasoned that sentences by themselves have a lot of un-stated context (as compared to a document), which are resolved by looking at neighboring sentences.9 So if we could somehow estimate the amount of \u201cmissing\u201d context in a sentence, we would be one more step ahead in assessing its true formality.\nQuantifying the missing context is complicated by the fact that it depends on both deixis and implicature. While F-score gives a reasonable estimate of the amount of relative deixis present in a sentence, it does not give any estimate of the amount of implicature. This forced us to rate sentences for the amount of implicature they carry (on Likert scale, because implicature is a continuous attribute (Degen, 2015)). This annotation process not only gave us implicature ratings, but also allowed us to look into how subjective the concept of implicature is (cf. Section 3.2).\nNote that Degen (2015) had already conducted a similar study on implicature annotation using Mechanical Turk. However, the focus of her study was on one particular type of implicature (some but not all), and the annotation process was not tied to formality or any other stylistic attribute. Also to be noted is the fact that our annotated corpus of 7,032 sentences is much larger than Degen\u2019s corpus of 1,363 utterances.\nA general discussion of the vast literature on implicature (starting with Grice (1975), and expanded by Harnish (1976), among others) is beyond the scope of this paper. Interested readers are referred to the excellent book by Potts (2005) for a gentle introduction to the theory of conventional implicatures (CIs), and to (Levin and Prince, 1986; Benotti, 2010; Benotti and Blackburn, 2011) for a discussion on causal implicatures. Grice also introduced scalar implicatures \u2013 arguably the most prominent class of implicatures \u2013 that equate \u201csome\u201d with \u201cnot all\u201d for the sake of politeness. Papafragou and Musolino (2003) discussed the acquisition of scalar implicatures by children, and Carston (1998) related scalar implicatures with relevance and informativeness \u2013 a topic we will briefly visit in the next section.\nApart from Degen (2015), we are not aware of any\n9Much like resolving the meaning of a word by looking at neighboring words.\nwork that specifically looked into implicature rating at sentence/utterance level. Degen\u2019s work, as we already pointed out, is not tied to formality scoring, so we used our own dataset of 7,032 sentences to rate for both formality and implicature."}, {"heading": "2.3 Informativeness", "text": "We also rated sentences for informativeness \u2013 a trait Heylighen and Dewaele (1999) identified with deep formality, where language is formalized to communicate meaning more clearly and directly. We will test this hypothesis by checking if the formality of a sentence positively correlates with its informativeness (Section 4.2). Interestingly, Carston (1998) independently arrived at a similar conclusion: \u201cinformativeness principles. . . give rise to. . . a strengthening or narrowing down of the encoded meaning of the utterance.\u201d While Carston\u2019s specific argument was tied to scalar implicatures, it is not very farfetched to see that the same argument would, in effect, also apply to deep formality as evinced by Heylighen and Dewaele.\nIt is to be noted that the word informativeness has different connotations in different settings. In the machine translation community, for example, the word informativeness denotes a type of fidelity measure to be applied to the translated text \u2013 in order to verify how much content of the original text is preserved under the translation (Rajman and Hartley, 2001). Informativeness of words and phrases is an important parameter in problems ranging from named entity detection (Rennie and Jaakkola, 2005) to keyword extraction (Timonen et al., 2012). Under this setting, informativeness is known as term informativeness (Kireyev, 2009; Wu and Giles, 2013). Interestingly, Rennie and Jaakkola (2005) pointed out that their term informativeness estimation approach would be especially helpful in \u201cextracting information from informal, written communication\u201d (emphasis ours).\nWhile all the above studies are important in their own right, and ground-breaking in some cases, we found none that specifically looked into informativeness rating of sentences in the context of formality, and there is no publicly available annotated dataset for sentence informativeness. In this work, we will bridge the gap."}, {"heading": "3 Corpus Creation", "text": ""}, {"heading": "3.1 Data", "text": "Our data comes from the pioneering study of Lahiri et al. (2011). They compiled four different datasets \u2013 blog posts, news articles, academic papers, and online forum threads \u2013 each consisting of 100 documents. For the blog dataset, they collected most recent posts from the top 100 blogs listed by Technorati10 on October 31, 2009. For the news article dataset, they collected 100 news articles from 20 news sites (five from each). The articles were mostly from \u201cBreaking News\u201d, \u201cRecent News\u201d, and \u201cLocal News\u201d categories, with no specific preference attached to any particular category.11 For the academic paper dataset, they randomly sampled 100 papers from the CiteSeerX12 digital library. For the online forum dataset, they sampled 50 random documents crawled from the Ubuntu Forums,13 and 50 random documents crawled from the TripAdvisor New York forum.14 The blog, news, paper, and forum datasets had 2110, 3009, 161406 and 2569 sentences respectively.\nWe manually cleaned and sentence-segmented the blog, news, and forum datasets to come up with 7,032 unique sentences. The much larger and more complex paper dataset was discarded, because manual cleansing and sentence segmentation of text data extracted from PDF was prohibitively timeconsuming, and often unsuccessful because of spurious characters, words, and corrupted/missing segments of text.15"}, {"heading": "3.2 Annotation", "text": "With the 7,032 sentences, we conducted two Mechanical Turk annotation experiments. In our first\n10http://technorati.com/. 11The news sites were CNN, CBS News, ABC News, Reuters, BBC News Online, New York Times, Los Angeles Times, The Guardian (U.K.), Voice of America, Boston Globe, Chicago Tribune, San Francisco Chronicle, Times Online (U.K.), news.com.au, Xinhua, The Times of India, Seattle Post Intelligencer, Daily Mail, and Bloomberg L.P.\n12http://citeseerx.ist.psu.edu/. 13http://ubuntuforums.org/. 14http://www.tripadvisor.com/ShowForum-\ng60763-i5-New_York_City_New_York.html. 15Note that this manual cleaning was necessary for our annotation process, because we cannot expect our annotators to deal with corrupt/incomplete/inaccurate sentences.\nexperiment, Turkers were requested to rate sentences on a 1-7 scale for formality, informativeness, and implicature. Each sentence was a HIT (Human Intelligence Task), and we requested five assignments per HIT so that we could get five independent ratings for each sentence. We requested Turkers with English as first language in our HIT title16 and description,17 but there was no easy way to ensure that it was indeed the case. As a quick fix, we required \u201cTurkers from US\u201d as qualification, and hoped that the average across five independent ratings will paint a better picture than any individual rating alone. Our instructions were minimal \u2013 we started with the two examples given at the beginning of Section 1 to prime the Turkers with the notion of formality, and gave them a few more links to explore the concept on their own.18 Then we told them to rate sentences on how formal they are. Turkers were requested to be consistent in their ratings across sentences, and rate sentences independently\n16How formal is this sentence? English as first language required.\n17This is a formality survey HIT, where we have three stylistic questions on an English sentence. Please do not enter if you do not have English as first language.\n18http://www.engvid.com/englishresource/formal-informal-english/, http: //dictionary.cambridge.org/us/grammar/ british-grammar/formal-and-informallanguage, http://www.englishspark.com/ informal-language/, http://www.antimoon. com/how/formal-informal-english.htm.\nof each other. The order of presentation of the sentences was scrambled so as to remove any potential sequence effect. In total, 527 Turkers participated in our first experiment.\nNote, however, that assessing inter-rater agreement becomes difficult on Mechanical Turk because different Turkers work on different number of HITs. Furthermore, we had no quality control other than \u201cUS-based\u201d in our first experiment. This is why we conducted a second experiment, which was essentially identical to the first, except that now we added two more requirements \u2013 at least 1,000 HITs completed with at least 99% approval rate \u2013 on top of the US-based requirement. This resulted in 187 Turkers participating in our second experiment.\nCorrelations between the mean ratings obtained from these two experiments are shown in Table 1. Several things are to be noted from this table. First, note that even without quality control (and weak enforcement of the English-first-language policy), Turkers\u2019 mean ratings correlated pretty well (across two experiments) for both formality as well as informativeness, echoing previous findings by Lahiri and Lu (2011). Second, it shows that even without extensive and detailed instructions, Turkers were able to rate subjective concepts like \u201cformality\u201d and \u201cinformativeness\u201d quite well, again echoing the findings summarized by Lahiri and Lu. Note that we did not provide Turkers with extensive and detailed instructions because:\n\u2022 We did not want to bias them with our view of the English language (removing experimenter bias).\n\u2022 We wanted to see if Likert scale annotations were good enough (as claimed by Lahiri and Lu (2011)) to instil sufficient reliability and agreement in the annotation process, especially between mean ratings.\n\u2022 We wanted to see if mean ratings across multiple raters could effectively eliminate the idiosyncrasies of individual Turkers in a subjective annotation task like this.19\nHaving said that, note from Table 1 that the correlation values for implicature are rather low \u2013 across all genres (albeit positive). This is unsurprising, however, given that implicature is arguably the most subjective among the three pragmatic variables we investigated, and quite possibly, the least amenable to any straightforward syntactic, lexical, or semantic explanation.\n19Here are the three questions we asked: How formal do you think is the above sentence? How much information do you think the above sentence carries? How much do you think the above sentence implies/suggests, or leaves to possible interpretations? We also had optional comment boxes so that Turkers can leave us their thoughts on the annotation process.\nWe further compared our mean formality ratings from Mechanical Turk to the mean formality ratings reported by Lahiri and Lu (2011) in their \u201cactual\u201d annotation phase. Results are shown in Table 2. Note that the mean Turker ratings are highly positively correlated with the mean ratings from Lahiri and Lu\u2019s quality-controlled study \u2013 except the news genre, where correlations are weaker (also see Table 1). We plan to investigate the news genre in future work. But the overall patterns are strongly encouraging, and validate the idea that a formalityannotated corpus can indeed be built reliably with Likert-scale-style annotations.\nWe show some example high- and low- formality, informativeness and implicature sentences in Table 3.20 Note that they follow the usual intuitions about formality, informativeness, and implicature quite well; for example, sentences that are high in formality and informativeness, but low in implicature, are longer and more difficult to read. The opposite is also true; informal and uninformative sentences are much shorter, and are often laden with a lot of implicature.21 For the rest of the paper,\n20The full dataset is available at https://drive.google.com/file/d/ 0B2Mzhc7popBgdXZmRlg2RUdqdDA/view?usp= sharing. Examples in Table 3 are from our second MTurk experiment, which comprises better-qualified Turkers.\n21Interesting trivia: the title of this paper derives from a sentence in our corpus that is very low in formality and informa-\nwe only consider the mean ratings from our second MTurk experiment, which comprises better-qualified Turkers. For notational convenience, mean ratings will henceforth be referred to as Formality, Informativeness and Implicature, as appropriate."}, {"heading": "4 Experiments", "text": "We performed three separate experiments on the 7,032 annotated sentences to identify different aspects of the annotations. In our first experiment, we explored how sentence-level formality, implicature, and informativeness vary across three different online genres \u2013 news, blog, and forums (Section 4.1). In the second experiment, we investigated the correlation among these three variables, and correlation with stylistic scores (Section 4.2). Finally, in Section 4.3, we examined how documents varied in terms of sentential formality, informativeness, and implicature \u2013 on average."}, {"heading": "4.1 Genre-wise Variation", "text": "We plot five-bin histograms of formality, informativeness, and implicature in Figure 1. Note from Figure 1 that overall, our corpus is dominated by highinformativeness, mid-to-high-formality, and midimplicature sentences. Since our implicature rating is less reliable than the other two ratings (cf. Section 3.2), it is relatively unclear whether this midimplicature trend is a real phenomenon, or is more of a reflection of central tendency bias among the annotators \u2013 who, lacking a better choice and a better interpretation \u2013 chose middling values for the implicature rating. Central tendency in implicature is\ntiveness, and medium in implicature.\nalso observed for the three individual genres \u2013 news, blog, forums.\nThe news genre is dominated by highinformativeness, and mid-to-high-formality sentences; blogs, too, are mostly high-formality and mid-to-high-informativeness sentences; on the other hand, forums are dominated by mid-to-lowformality sentences, and are spread out almost evenly when it comes to informativeness. The general trends corroborate earlier studies (Lahiri et al., 2011; Lahiri and Lu, 2011).\nThe fact that forums are spread out in terms of (sentential) informativeness shows that there are all kinds of sentences in forums \u2013 some are very informative, some are somewhat informative, and some are uninformative (e.g., help-eliciting setences such as \u201chelp please!\u201d, sentences expressing gratitude such as \u201cThanks everybody!\u201d, and suggestive sentences such as \u201cgive it a shot.\u201d). Filtering forum sentences by informativeness may be a useful first step towards effective mining of forum data."}, {"heading": "4.2 Relationship with Others", "text": "We experimented with eight different sentential stylistic variables, as detailed below:\n1. Fo: Formality of the sentence, i.e., the mean formality rating assigned by Turkers in our second MTurk experiment.\n2. In: Informativeness of the sentence, i.e., the mean informativeness rating assigned by Turkers in our second MTurk experiment.\n3. Im: Implicature of the sentence, i.e., the mean implicature rating assigned by Turkers in our second MTurk experiment.\n4. Lw: Length of the sentence in words.\n5. Lc: Length of the sentence in characters.\n6. F: Formality score of the sentence, as proposed by Heylighen and Dewaele (1999).\n7. I: Informativeness score of the sentence.\n8. LD: Lexical density of the sentence (Ure, 1971).\nAmong these variables, Heylighen and Dewaele\u2019s formality score is given by:\nF = (noun frequency + adjective freq. + preposition freq. + article freq. - pronoun freq. - verb freq. - adverb freq. - interjection freq. + 100)/2\nwhere the frequencies are taken as percentages with respect to the total number of words in the sentence. The inspiration for this score comes from the fact that nouns, adjectives, prepositions, and articles are found to be non-deictic in word correlation studies, whereas pronouns, verbs, adverbs, and interjections are found to be deictic.22 F-score measures formality as the amount of relative non-deixis present in a sentence (cf. Section 2.1).\nUre\u2019s lexical density takes the form: LD = (Nlex/N) \u00d7 100 where Nlex is the number of lexical tokens (nouns, adjectives, verbs, adverbs) in the sentence, and N is the total number of words in the sentence.\nThe informativeness score (I) is a scoring formula we propose in this paper. The idea is as follows. Recall from Section 1 that contextuality \u2013 the opposite of deep formality \u2013 is affected by both deixis as well as implicature. Although implicature is very hard to quantify, a measure of \u201cambiguity\u201d in a given piece of text can be formulated by counting how many WordNet senses (Miller, 1995) the words in that text carry on average. The more senses words have, the more ambiguous the text is. The informativeness score (I) of a sentence is thus given by the average number of WordNet senses per word in the sentence.23\nCorrelations between the eight variables are given in Table 4. Note from Table 4 that formality and\n22Conjunctions are deixis-neutral. We used CRFTagger (Phan, 2006) to part-of-speech-tag our sentences.\n23More accurately, it should be called an ambiguity score.\ninformativeness are highly correlated in all cases, thereby validating Heylighen and Dewaele\u2019s hypothesis that the purpose of formality (deep formality in particular) is more informative communication. Note, however, that in most cases, there is very little correlation between formality and implicature (small positive/negative values). There are two possible reasons for this: (a) implicature is a poorlyunderstood phenomenon, and maybe formality and implicature are not as antagonistically related as argued by Heylighen and Dewaele; (b) our implicature annotation by Turkers showed a central tendency bias and poor agreement between two MTurk experiments, so maybe the mean implicature ratings we obtained are not truly reflective of the actual amount of implicature present in a sentence. Validating which of these two (or maybe both) is the correct reason, is a part of our future work.\nNote further from Table 4 that formality and informativeness are positively correlated (moderateto-good correlation) with length of the sentence \u2013 in words and characters. This corroborates the earlier finding by Lahiri et al. (2011) that as a piece of text gets more formal, it tends to become longer and more intricate. Formality and informativeness also correlate positively (moderate correlation) with Heylighen and Dewaele\u2019s F-score, except in the Forum genre. On the other hand, they do not have significant correlations with the informativeness (I) score except the Forum genre. Implicature has a significant, but small negative correlation with Fscore in all cases. Lexical density negatively correlates with length of the sentence (#words and #characters). Informativeness score correlates positively with length, but negatively with Heylighen and Dewaele\u2019s F-score, as expected. Implicature also correlates negatively with F-score in all cases. The two length scores have an almost perfect positive correlation among them, which is unsurprising.\nThe surprising part, however, is that formality and informativeness (as rated by humans) are not very highly correlated (either positively or negatively) with Heylighen and Dewaele\u2019s F-score or our informativeness (I) score. Maybe these two scores are measuring complementary aspects of the phenomenon of formality, and are not individually able to explain all the variations. Automated scoring/prediction of formality by modeling it on top of\nscores like these (perhaps as features) is our future plan. We would also like to investigate how to predict informativeness, and how to get a better handle on implicature scoring \u2013 both by humans as well as automated."}, {"heading": "4.3 Sentential Make-up of Documents", "text": "In our final experiment, we investigated how the sentences in a document vary in terms of formality, implicature, and informativeness \u2013 starting from the beginning sentences, then the middle ones, and finally the last ones. We divided the sentences into ten successive bins (deciles) based on their position in the document, and measured the mean formality, informativeness, and implicature per decile. The results \u2013 averaged across all documents in a particular genre (blog, forums, news, overall) \u2013 are shown in Figure 2. Figure 2 also shows the standard errors for each decile.\nNote from Figure 2 that news sentences are most formal and most informative, followed by blog sentences, followed by forum sentences. In terms of formality and informativeness trends, news sentences start with high formality and informativeness, then gradually diminish in both \u2013 perhaps reflecting the fact that in journalistic writing, first few sentences carry the most information (to catch the readers\u2019 attention), and the information/interesting-ness content decreases substantially thereafter. Forum sentences, on the other hand, maintain a low level of formality and informativeness throughout \u2013 with a few small peaks and valleys in-between. For blogs, the trend is first decreasing, then increasing, and then decreasing again \u2013 indicating that the most informative (and formal) sentences in blogs may be in the middle. All three genres taken together, both formality and informativeness show a decreasing trend. There is no clear trend in the implicature rating of sentences \u2013 it is mostly an assortment of peaks and valleys."}, {"heading": "5 Conclusion", "text": "In this paper, we introduced a dataset of 7,032 sentences rated for formality, informativeness, and implicature on a 1-7 scale by human annotators on Amazon Mechanical Turk. To the best of our knowledge, this is the first large-scale annotation effort\nthat ties together all three pragmatic variables at the sentence level. We measured reliability of our annotations by running two independent rounds of annotation on MTurk, and inspecting the correlation among mean ratings between the two rounds. We further examined correlation of our annotations with pilot sentence formality annotations done in a more controlled setting (Lahiri and Lu, 2011). It was observed that while formality and informativeness can be reliably annotated on a 1-7 scale, implicature poses a much more difficult challenge. We analyzed the distribution of formality, informativeness, and implicature across three genres (news, blogs, and forums), and found significant differences \u2013 both in terms of overall distribution, and also in terms of the documents\u2019 sentential make-up. Correlations between the human ratings and five other stylistic variables were carefully examined. Our future plans include an automatic sentence-level formality and informativeness predictor, in the same spirit as (Danescu-Niculescu-Mizil et al., 2013). We also plan to investigate implicature rating more thoroughly, and figure out a good way to improve reliability in implicature annotation.\nThe limitations of our study mostly stem from our lack of control on the MTurk experiments. Some of that is intentional, because we really wanted to observe what people think/feel as formal, informative, and implicative. However, previous studies have employed measures like background questionnaires, linguistic attentiveness surveys, and zscoring to weed out/smooth difficulties (DanescuNiculescu-Mizil et al., 2013). While these are indeed promising research directions to try, we opine that even without such stringent measures, we were able to obtain quite good annotations \u2013 except implicature, where the earlier approach of Degen (2015) may truly be very helpful."}, {"heading": "Acknowledgments", "text": "We gratefully acknowledge Rada Mihalcea for her support; MTurk annotators for their annotations; Eduard Hovy and Julian Brooke for valuable discussions; Haiying Li and Nina Dethlefs for inspiration and dataset; Francis Heylighen and Jean-Marc Dewaele for their kindness and brilliant ideas, including the I-score; and lastly but most importantly, Xi-\naofei Lu for his continuous encouragement, warm intellectual companionship, excellent advice and camaraderie, sound ideas in the early stages of the study, and great help with thought processing. This work would not have been possible without you. All results, discussions, and comments contained herein are the sole responsibility of the author, and in no way associated with any of the above-mentioned people. The errors and omissions, if any, should be addressed to the author, and will be thankfully received."}], "references": [{"title": "Generation of Formal and Informal Sentences", "author": ["Fadi Abu Sheikha", "Diana Inkpen."], "venue": "Proceedings of the 13th European Workshop on Natural Language Generation, pages 187\u2013193, Nancy, France, September. Association for Computational Linguistics.", "citeRegEx": "Sheikha and Inkpen.,? 2011", "shortCiteRegEx": "Sheikha and Inkpen.", "year": 2011}, {"title": "Learning to Classify Documents According to Formal and Informal Style", "author": ["Fadi Abu Sheikha", "Diana Inkpen."], "venue": "Submitted to Linguistic Issues in Language Technology (LiLT).", "citeRegEx": "Sheikha and Inkpen.,? 2012", "shortCiteRegEx": "Sheikha and Inkpen.", "year": 2012}, {"title": "Classical planning and causal implicatures", "author": ["Luciana Benotti", "Patrick Blackburn."], "venue": "Michael Beigl, Henning Christiansen, Thomas R. Roth-Berghofer, Anders Kofod-Petersen, Kenny R. Coventry, and Hedda R. Schmidtke, editors, Modeling and Using", "citeRegEx": "Benotti and Blackburn.,? 2011", "shortCiteRegEx": "Benotti and Blackburn.", "year": 2011}, {"title": "Implicature as an Interactive Process", "author": ["Luciana Benotti."], "venue": "Ph.D. thesis, Universit\u00e9 Henri Poincar\u00e9 Nancy I, January.", "citeRegEx": "Benotti.,? 2010", "shortCiteRegEx": "Benotti.", "year": 2010}, {"title": "Variation Across Speech and Writing", "author": ["Douglas Biber."], "venue": "Cambridge University Press.", "citeRegEx": "Biber.,? 1988", "shortCiteRegEx": "Biber.", "year": 1988}, {"title": "Hybrid Models for Lexical Acquisition of Correlated Styles", "author": ["Julian Brooke", "Graeme Hirst."], "venue": "Proceedings of the Sixth International Joint Conference on Natural Language Processing, pages 82\u201390, Nagoya, Japan, October. Asian Federation of Natural Language", "citeRegEx": "Brooke and Hirst.,? 2013", "shortCiteRegEx": "Brooke and Hirst.", "year": 2013}, {"title": "Supervised Ranking of Co-occurrence Profiles for Acquisition of Continuous Lexical Attributes", "author": ["Julian Brooke", "Graeme Hirst."], "venue": "Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, pages", "citeRegEx": "Brooke and Hirst.,? 2014", "shortCiteRegEx": "Brooke and Hirst.", "year": 2014}, {"title": "Automatic Acquisition of Lexical Formality", "author": ["Julian Brooke", "Tong Wang", "Graeme Hirst."], "venue": "Proceedings of the 23rd International Conference on Computational Linguistics: Posters, COLING \u201910, pages 90\u2013", "citeRegEx": "Brooke et al\\.,? 2010", "shortCiteRegEx": "Brooke et al\\.", "year": 2010}, {"title": "Informativeness, Relevance, and Scalar Implicature", "author": ["Robyn Carston."], "venue": "Robyn Carston and Seiji Uchida, editors, Relevance Theory: Applications and Implications, pages 179\u2013236. John Benjamins Publishing Co., Amsterdam.", "citeRegEx": "Carston.,? 1998", "shortCiteRegEx": "Carston.", "year": 1998}, {"title": "A computational approach to politeness with application to social factors", "author": ["Cristian Danescu-Niculescu-Mizil", "Moritz Sudhof", "Dan Jurafsky", "Jure Leskovec", "Christopher Potts."], "venue": "ACL (1), pages 250\u2013259. The Association for Computer Linguistics.", "citeRegEx": "Danescu.Niculescu.Mizil et al\\.,? 2013", "shortCiteRegEx": "Danescu.Niculescu.Mizil et al\\.", "year": 2013}, {"title": "A Computational Approach to Linguistic Style Coordination", "author": ["Cristian Danescu-Niculescu-Mizil."], "venue": "Ph.D. thesis, Cornell University.", "citeRegEx": "Danescu.Niculescu.Mizil.,? 2012", "shortCiteRegEx": "Danescu.Niculescu.Mizil.", "year": 2012}, {"title": "Investigating the distribution of some (but not all) implicatures using corpora and webbased methods", "author": ["Judith Degen."], "venue": "Semantics and Pragmatics (In Press).", "citeRegEx": "Degen.,? 2015", "shortCiteRegEx": "Degen.", "year": 2015}, {"title": "Cluster-based Prediction of User Ratings for Stylistic Surface Realisation", "author": ["Nina Dethlefs", "Heriberto Cuay\u00e1huitl", "Helen Hastie", "Verena Rieser", "Oliver Lemon."], "venue": "Proceedings of the 14th Conference of the European Chapter of the Association for Computa-", "citeRegEx": "Dethlefs et al\\.,? 2014", "shortCiteRegEx": "Dethlefs et al\\.", "year": 2014}, {"title": "Coh-Metrix: Analysis of text on cohesion and language", "author": ["Arthur C. Graesser", "Danielle S. McNamara", "Max M. Louwerse", "Zhiqiang Cai."], "venue": "Behavior Research Methods, Instruments, & Computers, 36(2):193\u2013202.", "citeRegEx": "Graesser et al\\.,? 2004", "shortCiteRegEx": "Graesser et al\\.", "year": 2004}, {"title": "Logic and Conversation", "author": ["Herbert Paul Grice."], "venue": "Peter Cole and Jerry L. Morgan, editors, Syntax and Semantics: Vol. 3: Speech Acts, pages 41\u201358. Academic Press, New York.", "citeRegEx": "Grice.,? 1975", "shortCiteRegEx": "Grice.", "year": 1975}, {"title": "Logical Form and Implicature", "author": ["Robert M. Harnish."], "venue": "Thomas G. Bever, Jerrold J. Katz, and D. Terence Langendoen, editors, An Integrated Theory of Linguistic Ability, pages 313\u2013392. Thomas Y. Crowell, New York.", "citeRegEx": "Harnish.,? 1976", "shortCiteRegEx": "Harnish.", "year": 1976}, {"title": "Formality of Language: definition, measurement and behavioral determinants", "author": ["Francis Heylighen", "Jean-Marc Dewaele."], "venue": "Technical report, Center \u201cLeo Apostel\u201d, Free University of Brussels.", "citeRegEx": "Heylighen and Dewaele.,? 1999", "shortCiteRegEx": "Heylighen and Dewaele.", "year": 1999}, {"title": "Pragmatics and Natural Language Generation", "author": ["Eduard H. Hovy."], "venue": "Artificial Intelligence, 43(2):153\u2013 197, May.", "citeRegEx": "Hovy.,? 1990", "shortCiteRegEx": "Hovy.", "year": 1990}, {"title": "About 37% of Word-Tokens are Nouns", "author": ["Richard Hudson."], "venue": "Language, 70(2):pp. 331\u2013339.", "citeRegEx": "Hudson.,? 1994", "shortCiteRegEx": "Hudson.", "year": 1994}, {"title": "Semantic-based Estimation of Term Informativeness", "author": ["Kirill Kireyev."], "venue": "Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 530\u2013538, Boulder,", "citeRegEx": "Kireyev.,? 2009", "shortCiteRegEx": "Kireyev.", "year": 2009}, {"title": "Interrater Agreement on Sentence Formality", "author": ["Shibamouli Lahiri", "Xiaofei Lu."], "venue": "CoRR, abs/1109.0069.", "citeRegEx": "Lahiri and Lu.,? 2011", "shortCiteRegEx": "Lahiri and Lu.", "year": 2011}, {"title": "Informality Judgment at Sentence Level and Experiments with Formality Score", "author": ["Shibamouli Lahiri", "Prasenjit Mitra", "Xiaofei Lu."], "venue": "Proceedings of the 12th International Conference on Computational Linguistics and Intelligent Text Processing - Volume", "citeRegEx": "Lahiri et al\\.,? 2011", "shortCiteRegEx": "Lahiri et al\\.", "year": 2011}, {"title": "Language and Context: A Functional Linguistic Theory of Register", "author": ["Helen Leckie-Tarry", "David Birch."], "venue": "Pinter Publishers.", "citeRegEx": "Leckie.Tarry and Birch.,? 1995", "shortCiteRegEx": "Leckie.Tarry and Birch.", "year": 1995}, {"title": "Speaking: From Intention to Articulation", "author": ["William J.M. Levelt."], "venue": "MIT Press, Cambridge, MA.", "citeRegEx": "Levelt.,? 1989", "shortCiteRegEx": "Levelt.", "year": 1989}, {"title": "Gapping and Causal Implicature", "author": ["Nancy S. Levin", "Ellen F. Prince."], "venue": "Paper in Linguistics, 19(3):351\u2013 364.", "citeRegEx": "Levin and Prince.,? 1986", "shortCiteRegEx": "Levin and Prince.", "year": 1986}, {"title": "Comparing Two Measures for Formality", "author": ["Haiying Li", "Zhiqiang Cai", "Arthur C. Graesser."], "venue": "Proceedings of the Florida Artificial Intelligence Research Society Conference.", "citeRegEx": "Li et al\\.,? 2013", "shortCiteRegEx": "Li et al\\.", "year": 2013}, {"title": "A Technique for the Measurement of Attitudes", "author": ["Rensis Likert."], "venue": "Archives of Psychology, 22(140):1\u201355.", "citeRegEx": "Likert.,? 1932", "shortCiteRegEx": "Likert.", "year": 1932}, {"title": "Writing in the workplace: Variation in the Writing Practices and Formality of Eight Multinational Companies in Greece", "author": ["Ifigeneia Machili."], "venue": "Ph.D. thesis, University of the West of England.", "citeRegEx": "Machili.,? 2014", "shortCiteRegEx": "Machili.", "year": 2014}, {"title": "WordNet: A Lexical Database for English", "author": ["George Armitage Miller."], "venue": "Commun. ACM, 38(11):39\u201341, November.", "citeRegEx": "Miller.,? 1995", "shortCiteRegEx": "Miller.", "year": 1995}, {"title": "Weblogs, Genres, and Individual Differences", "author": ["Scott Nowson", "Jon Oberlander", "Alastair J. Gill."], "venue": "Proceedings of the 27th Annual Conference of the Cognitive Science Society, pages 1666\u20131671.", "citeRegEx": "Nowson et al\\.,? 2005", "shortCiteRegEx": "Nowson et al\\.", "year": 2005}, {"title": "Scalar implicatures: experiments at the semantics-pragmatics interface", "author": ["Anna Papafragou", "Julien Musolino."], "venue": "Cognition, 86(3):253 \u2013 282.", "citeRegEx": "Papafragou and Musolino.,? 2003", "shortCiteRegEx": "Papafragou and Musolino.", "year": 2003}, {"title": "Email Formality in the Workplace: A Case Study on the Enron Corpus", "author": ["Kelly Peterson", "Matt Hohensee", "Fei Xia."], "venue": "Proceedings of the Workshop on Languages in Social Media, LSM \u201911, pages 86\u201395, Stroudsburg, PA, USA. Association for Computational", "citeRegEx": "Peterson et al\\.,? 2011", "shortCiteRegEx": "Peterson et al\\.", "year": 2011}, {"title": "CRFTagger: CRF English POS Tagger", "author": ["Xuan-Hieu Phan"], "venue": null, "citeRegEx": "Phan.,? \\Q2006\\E", "shortCiteRegEx": "Phan.", "year": 2006}, {"title": "The Logic of Conventional Implicatures", "author": ["Christopher Potts."], "venue": "Oxford Studies in Theoretical Linguistics. Oxford University Press, Oxford.", "citeRegEx": "Potts.,? 2005", "shortCiteRegEx": "Potts.", "year": 2005}, {"title": "Conventional implicature and expressive content", "author": ["Christopher Potts."], "venue": "Claudia Maienborn, Klaus von", "citeRegEx": "Potts.,? 2012", "shortCiteRegEx": "Potts.", "year": 2012}, {"title": "Automatically predicting MT systems rankings compatible with Fluency, Adequacy or Informativeness scores", "author": ["Martin Rajman", "Tony Hartley."], "venue": "Procs. 4th ISLE Workshop on MT Evaluation, MT Summit VIII, pages 29\u201334.", "citeRegEx": "Rajman and Hartley.,? 2001", "shortCiteRegEx": "Rajman and Hartley.", "year": 2001}, {"title": "Using Term Informativeness for Named Entity Detection", "author": ["Jason D.M. Rennie", "Tommi Jaakkola."], "venue": "Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR \u201905, pages 353\u2013360, New", "citeRegEx": "Rennie and Jaakkola.,? 2005", "shortCiteRegEx": "Rennie and Jaakkola.", "year": 2005}, {"title": "Contextuality and Beyond: Investigating an Online Diary Corpus", "author": ["Laura Teddiman."], "venue": "Eytan Adar, Matthew Hurst, Tim Finin, Natalie S. Glance, Nicolas Nicolov, and Belle L. Tseng, editors, ICWSM. The AAAI Press.", "citeRegEx": "Teddiman.,? 2009", "shortCiteRegEx": "Teddiman.", "year": 2009}, {"title": "Informativeness-based Keyword Extraction from Short Documents", "author": ["Mika Timonen", "Timo Toivanen", "Yue Teng", "Chao Cheng", "Liang He."], "venue": "Ana L. N. Fred, Joaquim Filipe, Ana L. N. Fred, and Joaquim Filipe, editors, KDIR, pages 411\u2013421. SciTePress.", "citeRegEx": "Timonen et al\\.,? 2012", "shortCiteRegEx": "Timonen et al\\.", "year": 2012}, {"title": "Lexical density and register differentiation", "author": ["Jean Ure."], "venue": "Applications of Linguistics, pages 443\u2013452.", "citeRegEx": "Ure.,? 1971", "shortCiteRegEx": "Ure.", "year": 1971}, {"title": "Measuring Term Informativeness in Context", "author": ["Zhaohui Wu", "Clyde Lee Giles."], "venue": "Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 259\u2013269, At-", "citeRegEx": "Wu and Giles.,? 2013", "shortCiteRegEx": "Wu and Giles.", "year": 2013}], "referenceMentions": [{"referenceID": 4, "context": "(Biber, 1988; Hudson, 1994)),4 and has close connections to informativeness and implicature.", "startOffset": 0, "endOffset": 27}, {"referenceID": 18, "context": "(Biber, 1988; Hudson, 1994)),4 and has close connections to informativeness and implicature.", "startOffset": 0, "endOffset": 27}, {"referenceID": 14, "context": "They argued, in particular, that formality emerges out of a communicative objective \u2013 to maximize the amount of information being conveyed to the listener while at the same time maintaining (or at least appearing to maintain) Grice\u2019s communicative maxims of Quality, Quantity, Relevance and Manner as much as possible (Grice, 1975).", "startOffset": 318, "endOffset": 331}, {"referenceID": 14, "context": "This dichotomy of (in)formal expressions was examined in great detail by Heylighen and Dewaele (1999). As they observed, formality is the most important dimension of writing style (cf.", "startOffset": 73, "endOffset": 102}, {"referenceID": 23, "context": "For a general discussion on the theory of registers, see (Levelt, 1989) and (Leckie-Tarry and Birch, 1995).", "startOffset": 57, "endOffset": 71}, {"referenceID": 22, "context": "For a general discussion on the theory of registers, see (Levelt, 1989) and (Leckie-Tarry and Birch, 1995).", "startOffset": 76, "endOffset": 106}, {"referenceID": 26, "context": "We will instead follow the Likert scale approach (Likert, 1932) to sentence formality annotation, shown to work well by Lahiri and Lu (2011).", "startOffset": 49, "endOffset": 63}, {"referenceID": 9, "context": "In some sense, our work is similar to the Stanford politeness corpus (Danescu-Niculescu-Mizil et al., 2013); both corpora are at the sentence/utterance level, and both measure a pragmatic variable on an ordinal scale (formality vs politeness).", "startOffset": 69, "endOffset": 107}, {"referenceID": 14, "context": "While several of the arguments Heylighen and Dewaele made are open to question, an important take-home message from their theory is a so-called continuum of formality, arising out of a process where a document (or a piece of text) can be \u201cformalized\u201d ad infinitum, simply by adding more and more context. This precludes us from labeling a document or a sentence binarily as \u201cformal\u201d or \u201cinformal\u201d. We will instead follow the Likert scale approach (Likert, 1932) to sentence formality annotation, shown to work well by Lahiri and Lu (2011). In some sense, our work is similar to the Stanford politeness corpus (Danescu-Niculescu-Mizil et al.", "startOffset": 31, "endOffset": 539}, {"referenceID": 29, "context": "5 F-score was used in genre analysis by Nowson et al. (2005), and shown", "startOffset": 40, "endOffset": 61}, {"referenceID": 13, "context": "(2013) proposed a version of F-score (called \u201cCF-score\u201d) based on Coh-Metrix (Graesser et al., 2004) dimensions of narrativity, referential and deep cohesion, syntactic simplicity and word concreteness.", "startOffset": 77, "endOffset": 100}, {"referenceID": 35, "context": "Teddiman (2009) noted in particular that F-score can successfully differentiate between genres, but it cannot explain why the genres are different.", "startOffset": 0, "endOffset": 16}, {"referenceID": 24, "context": "6 In follow-up work, Li et al. (2013) proposed a version of F-score (called \u201cCF-score\u201d) based on Coh-Metrix (Graesser et al.", "startOffset": 21, "endOffset": 38}, {"referenceID": 7, "context": "In a separate strand of work, Brooke and Hirst (2014) identified formality as a continuous lexical attribute, and assigned a formality score to a word based on its co-occurrece frequency with a hand-picked seed set of formal and informal words, smoothed by latent semantic analysis (Brooke et al., 2010).", "startOffset": 282, "endOffset": 303}, {"referenceID": 5, "context": "Formality of words was further shown to be correlated with other stylistic dimensions such as concreteness and subjectivity (Brooke and Hirst, 2013).", "startOffset": 124, "endOffset": 148}, {"referenceID": 5, "context": "In a separate strand of work, Brooke and Hirst (2014) identified formality as a continuous lexical attribute, and assigned a formality score to a word based on its co-occurrece frequency with a hand-picked seed set of formal and informal words, smoothed by latent semantic analysis (Brooke et al.", "startOffset": 30, "endOffset": 54}, {"referenceID": 0, "context": "Abu Sheikha and Inkpen (2012) equated formality of a sentence with the formality of its corresponding document, and Brooke and Hirst (2014) predicted formality of sentences using word-level features.", "startOffset": 4, "endOffset": 30}, {"referenceID": 0, "context": "Abu Sheikha and Inkpen (2012) equated formality of a sentence with the formality of its corresponding document, and Brooke and Hirst (2014) predicted formality of sentences using word-level features.", "startOffset": 4, "endOffset": 140}, {"referenceID": 0, "context": "Abu Sheikha and Inkpen (2012) equated formality of a sentence with the formality of its corresponding document, and Brooke and Hirst (2014) predicted formality of sentences using word-level features. Peterson et al. (2011) and Machili (2014) looked into formality of emails at workplace, the former exploring the Enron corpus and how formality varies with social distance, relative power, and the weight of imposition, and the latter conducting similar analyses among workplace emails from Greek multinational companies.", "startOffset": 4, "endOffset": 223}, {"referenceID": 0, "context": "Abu Sheikha and Inkpen (2012) equated formality of a sentence with the formality of its corresponding document, and Brooke and Hirst (2014) predicted formality of sentences using word-level features. Peterson et al. (2011) and Machili (2014) looked into formality of emails at workplace, the former exploring the Enron corpus and how formality varies with social distance, relative power, and the weight of imposition, and the latter conducting similar analyses among workplace emails from Greek multinational companies.", "startOffset": 4, "endOffset": 242}, {"referenceID": 20, "context": "(Lahiri and Lu, 2011), and Section 4.", "startOffset": 0, "endOffset": 21}, {"referenceID": 20, "context": "As Lahiri et al. (2011) showed in their work, sentence formality is not the same as document formality.", "startOffset": 3, "endOffset": 24}, {"referenceID": 10, "context": "This could be due to linguistic style co-ordination (Danescu-Niculescu-Mizil, 2012).", "startOffset": 52, "endOffset": 83}, {"referenceID": 20, "context": "Lahiri and Lu (2011) further showed that there are cases where the words in a sentence are formal, but the sentence as a whole is not (\u201cFor all the stars in the sky, I do not care.", "startOffset": 0, "endOffset": 21}, {"referenceID": 20, "context": "The only two studies we are aware of that looked into formality annotation of sentences, are (Lahiri and Lu, 2011), and (Dethlefs et al.", "startOffset": 93, "endOffset": 114}, {"referenceID": 12, "context": "The only two studies we are aware of that looked into formality annotation of sentences, are (Lahiri and Lu, 2011), and (Dethlefs et al., 2014).", "startOffset": 120, "endOffset": 143}, {"referenceID": 12, "context": "The only two studies we are aware of that looked into formality annotation of sentences, are (Lahiri and Lu, 2011), and (Dethlefs et al., 2014). Lahiri and Lu annotated 600 sentences by two undergraduate linguistics students on a Likert scale of 1-5. Inter-rater agreement was shown to improve substantially from binary annotations, which could be attributed to the continuum of formality phenomenon described in Section 1. Dethlefs et al., on the other hand, were interested in formality from a natural language generation (NLG) perspective.8 They annotated utterances using Amazon Mechanical Turk on three dimensions of style \u2013 colloquialism (opposite of formality), politeness, and naturalness. A 1-5 Likert scale was used. The problem with this study is that the number of annotated sentences was quite limited, and they came from a restricted class of documents talking about restaurant reviews in a single city. This makes Dethlefs et al.\u2019s corpus unsuitable for our purpose. We wanted a generic corpus of sentences annotated with formality ratings that could help build a sentence formality predictor, so we extended the work of Lahiri and Lu (2011) instead.", "startOffset": 121, "endOffset": 1157}, {"referenceID": 21, "context": "(Lahiri et al., 2011)).", "startOffset": 0, "endOffset": 21}, {"referenceID": 17, "context": "Note that the importance of formality in language generation has long been recognized (Hovy, 1990; Abu Sheikha and Inkpen, 2011).", "startOffset": 86, "endOffset": 128}, {"referenceID": 30, "context": "Also see the examples given by Potts (2012). Note that the importance of formality in language generation has long been recognized (Hovy, 1990; Abu Sheikha and Inkpen, 2011).", "startOffset": 31, "endOffset": 44}, {"referenceID": 11, "context": "This forced us to rate sentences for the amount of implicature they carry (on Likert scale, because implicature is a continuous attribute (Degen, 2015)).", "startOffset": 138, "endOffset": 151}, {"referenceID": 11, "context": "Note that Degen (2015) had already conducted a similar study on implicature annotation using Mechanical Turk.", "startOffset": 10, "endOffset": 23}, {"referenceID": 24, "context": "Interested readers are referred to the excellent book by Potts (2005) for a gentle introduction to the theory of conventional implicatures (CIs), and to (Levin and Prince, 1986; Benotti, 2010; Benotti and Blackburn, 2011) for a discussion on causal implicatures.", "startOffset": 153, "endOffset": 221}, {"referenceID": 3, "context": "Interested readers are referred to the excellent book by Potts (2005) for a gentle introduction to the theory of conventional implicatures (CIs), and to (Levin and Prince, 1986; Benotti, 2010; Benotti and Blackburn, 2011) for a discussion on causal implicatures.", "startOffset": 153, "endOffset": 221}, {"referenceID": 2, "context": "Interested readers are referred to the excellent book by Potts (2005) for a gentle introduction to the theory of conventional implicatures (CIs), and to (Levin and Prince, 1986; Benotti, 2010; Benotti and Blackburn, 2011) for a discussion on causal implicatures.", "startOffset": 153, "endOffset": 221}, {"referenceID": 11, "context": "A general discussion of the vast literature on implicature (starting with Grice (1975), and expanded by Harnish (1976), among others) is beyond the scope of this paper.", "startOffset": 74, "endOffset": 87}, {"referenceID": 11, "context": "A general discussion of the vast literature on implicature (starting with Grice (1975), and expanded by Harnish (1976), among others) is beyond the scope of this paper.", "startOffset": 74, "endOffset": 119}, {"referenceID": 11, "context": "A general discussion of the vast literature on implicature (starting with Grice (1975), and expanded by Harnish (1976), among others) is beyond the scope of this paper. Interested readers are referred to the excellent book by Potts (2005) for a gentle introduction to the theory of conventional implicatures (CIs), and to (Levin and Prince, 1986; Benotti, 2010; Benotti and Blackburn, 2011) for a discussion on causal implicatures.", "startOffset": 74, "endOffset": 239}, {"referenceID": 2, "context": "Interested readers are referred to the excellent book by Potts (2005) for a gentle introduction to the theory of conventional implicatures (CIs), and to (Levin and Prince, 1986; Benotti, 2010; Benotti and Blackburn, 2011) for a discussion on causal implicatures. Grice also introduced scalar implicatures \u2013 arguably the most prominent class of implicatures \u2013 that equate \u201csome\u201d with \u201cnot all\u201d for the sake of politeness. Papafragou and Musolino (2003) discussed the acquisition of scalar implicatures by children, and Carston (1998) related scalar implicatures with relevance and informativeness \u2013 a topic we will briefly visit in the next section.", "startOffset": 193, "endOffset": 452}, {"referenceID": 2, "context": "Interested readers are referred to the excellent book by Potts (2005) for a gentle introduction to the theory of conventional implicatures (CIs), and to (Levin and Prince, 1986; Benotti, 2010; Benotti and Blackburn, 2011) for a discussion on causal implicatures. Grice also introduced scalar implicatures \u2013 arguably the most prominent class of implicatures \u2013 that equate \u201csome\u201d with \u201cnot all\u201d for the sake of politeness. Papafragou and Musolino (2003) discussed the acquisition of scalar implicatures by children, and Carston (1998) related scalar implicatures with relevance and informativeness \u2013 a topic we will briefly visit in the next section.", "startOffset": 193, "endOffset": 533}, {"referenceID": 11, "context": "Apart from Degen (2015), we are not aware of any", "startOffset": 11, "endOffset": 24}, {"referenceID": 15, "context": "We also rated sentences for informativeness \u2013 a trait Heylighen and Dewaele (1999) identified with deep formality, where language is formalized to communicate meaning more clearly and directly.", "startOffset": 54, "endOffset": 83}, {"referenceID": 8, "context": "Interestingly, Carston (1998) independently arrived at a similar conclusion: \u201cinformativeness principles.", "startOffset": 15, "endOffset": 30}, {"referenceID": 35, "context": "In the machine translation community, for example, the word informativeness denotes a type of fidelity measure to be applied to the translated text \u2013 in order to verify how much content of the original text is preserved under the translation (Rajman and Hartley, 2001).", "startOffset": 242, "endOffset": 268}, {"referenceID": 36, "context": "Informativeness of words and phrases is an important parameter in problems ranging from named entity detection (Rennie and Jaakkola, 2005) to keyword extraction (Timonen et al.", "startOffset": 111, "endOffset": 138}, {"referenceID": 38, "context": "Informativeness of words and phrases is an important parameter in problems ranging from named entity detection (Rennie and Jaakkola, 2005) to keyword extraction (Timonen et al., 2012).", "startOffset": 161, "endOffset": 183}, {"referenceID": 19, "context": "Under this setting, informativeness is known as term informativeness (Kireyev, 2009; Wu and Giles, 2013).", "startOffset": 69, "endOffset": 104}, {"referenceID": 40, "context": "Under this setting, informativeness is known as term informativeness (Kireyev, 2009; Wu and Giles, 2013).", "startOffset": 69, "endOffset": 104}, {"referenceID": 19, "context": "Under this setting, informativeness is known as term informativeness (Kireyev, 2009; Wu and Giles, 2013). Interestingly, Rennie and Jaakkola (2005) pointed out that their term informativeness estimation approach would be especially helpful in \u201cextracting information from informal, written communication\u201d (emphasis ours).", "startOffset": 70, "endOffset": 148}, {"referenceID": 21, "context": "Our data comes from the pioneering study of Lahiri et al. (2011). They compiled four different datasets \u2013 blog posts, news articles, academic papers, and online forum threads \u2013 each consisting of 100 documents.", "startOffset": 44, "endOffset": 65}, {"referenceID": 20, "context": "Table 2: Spearman\u2019s \u03c1 between the mean formality ratings from Mechanical Turk, and mean formality ratings from Lahiri and Lu (2011). All results are statistically significantly different from zero, with p-value < 0.", "startOffset": 111, "endOffset": 132}, {"referenceID": 20, "context": "First, note that even without quality control (and weak enforcement of the English-first-language policy), Turkers\u2019 mean ratings correlated pretty well (across two experiments) for both formality as well as informativeness, echoing previous findings by Lahiri and Lu (2011). Second, it shows that even without extensive and detailed instructions, Turkers were able to rate subjective concepts like \u201cformality\u201d and \u201cinformativeness\u201d quite well, again echoing the findings summarized by Lahiri and Lu.", "startOffset": 253, "endOffset": 274}, {"referenceID": 20, "context": "\u2022 We wanted to see if Likert scale annotations were good enough (as claimed by Lahiri and Lu (2011)) to instil sufficient reliability and agreement in the annotation process, especially between mean ratings.", "startOffset": 79, "endOffset": 100}, {"referenceID": 20, "context": "We further compared our mean formality ratings from Mechanical Turk to the mean formality ratings reported by Lahiri and Lu (2011) in their \u201cactual\u201d annotation phase.", "startOffset": 110, "endOffset": 131}, {"referenceID": 21, "context": "The general trends corroborate earlier studies (Lahiri et al., 2011; Lahiri and Lu, 2011).", "startOffset": 47, "endOffset": 89}, {"referenceID": 20, "context": "The general trends corroborate earlier studies (Lahiri et al., 2011; Lahiri and Lu, 2011).", "startOffset": 47, "endOffset": 89}, {"referenceID": 16, "context": "F: Formality score of the sentence, as proposed by Heylighen and Dewaele (1999).", "startOffset": 51, "endOffset": 80}, {"referenceID": 39, "context": "LD: Lexical density of the sentence (Ure, 1971).", "startOffset": 36, "endOffset": 47}, {"referenceID": 28, "context": "Although implicature is very hard to quantify, a measure of \u201cambiguity\u201d in a given piece of text can be formulated by counting how many WordNet senses (Miller, 1995) the words in that text carry on average.", "startOffset": 151, "endOffset": 165}, {"referenceID": 32, "context": "We used CRFTagger (Phan, 2006) to part-of-speech-tag our sentences.", "startOffset": 18, "endOffset": 30}, {"referenceID": 20, "context": "This corroborates the earlier finding by Lahiri et al. (2011) that as a piece of text gets more formal, it tends to become longer and more intricate.", "startOffset": 41, "endOffset": 62}, {"referenceID": 20, "context": "We further examined correlation of our annotations with pilot sentence formality annotations done in a more controlled setting (Lahiri and Lu, 2011).", "startOffset": 127, "endOffset": 148}, {"referenceID": 9, "context": "Our future plans include an automatic sentence-level formality and informativeness predictor, in the same spirit as (Danescu-Niculescu-Mizil et al., 2013).", "startOffset": 116, "endOffset": 154}, {"referenceID": 11, "context": "While these are indeed promising research directions to try, we opine that even without such stringent measures, we were able to obtain quite good annotations \u2013 except implicature, where the earlier approach of Degen (2015) may truly be very helpful.", "startOffset": 211, "endOffset": 224}], "year": 2016, "abstractText": "We introduce a corpus of 7,032 sentences1 rated by human annotators for formality, informativeness, and implicature on a 1-7 scale. The corpus was annotated using Amazon Mechanical Turk.2 Reliability in the obtained judgments was examined by comparing mean ratings across two MTurk experiments, and correlation with pilot annotations (on sentence formality) conducted in a more controlled setting. Despite the subjectivity and inherent difficulty of the annotation task, correlations between mean ratings were quite encouraging, especially on formality and informativeness. We further explored correlation between the three linguistic variables, genre-wise variation of ratings and correlations within genres, compatibility with automatic stylistic scoring, and sentential make-up of a document in terms of style. To date, our corpus is the largest sentence-level annotated corpus released for formality, informativeness, and implicature.", "creator": "TeX"}}}