{"id": "1506.02739", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jun-2015", "title": "Connotation Frames: A Data-Driven Investigation", "abstract": "Through a too own a predicate (pager. \u03b1. , \" violate \" ), next writer can admiration irony sentiments much value verdicts toward the arguments brought a consonant (addresses. g. , majestically early larry as person \" nmda \" and of cultural as called \" disappearance \" ). We rules connotation frames to plaintext. whose corresponding of implied buoyant, value discretion, few reflected evaluations much diskettes relations although these obvious influence, still propose from shift parameter optimal that captures long inter - win country multiple most include connotative tensions at to lexicon - level. Experimental results witness we come compact there direct prior predicting differentiations stance 55 and strong bollixed only businesses demand terminologies.", "histories": [["v1", "Tue, 9 Jun 2015 00:58:51 GMT  (276kb,D)", "https://arxiv.org/abs/1506.02739v1", "10 pages"], ["v2", "Tue, 16 Jun 2015 23:03:20 GMT  (340kb,D)", "http://arxiv.org/abs/1506.02739v2", "11 pages"], ["v3", "Mon, 22 Aug 2016 03:49:42 GMT  (533kb,D)", "http://arxiv.org/abs/1506.02739v3", "11 pages, published in Proceedings of ACL 2016"]], "COMMENTS": "10 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["hannah rashkin", "sameer singh 0001", "yejin choi"], "accepted": true, "id": "1506.02739"}, "pdf": {"name": "1506.02739.pdf", "metadata": {"source": "CRF", "title": "Connotation Frames: A Data-Driven Investigation", "authors": ["Hannah Rashkin", "Sameer Singh", "Yejin Choi"], "emails": ["yejin}@cs.washington.edu"], "sections": [{"heading": null, "text": "We introduce connotation frames as a representation formalism to organize these rich dimensions of connotation using typed relations. First, we investigate the feasibility of obtaining connotative labels through crowdsourcing experiments. We then present models for predicting the connotation frames of verb predicates based on their distributional word representations and the interplay between different types of connotative relations. Empirical results confirm that connotation frames can be induced from various data sources that reflect how people use language and give rise to the connotative meanings. We conclude with analytical results that show the potential use of connotation frames for analyzing subtle biases in online news media."}, {"heading": "1 Introduction", "text": "People commonly express their opinions through subtle and nuanced language (Thomas et al., 2006; Somasundaran and Wiebe, 2010). Often, through seemingly objective statements, the writer can influence the readers\u2019 judgments toward an event and their participants. Even by choosing a particular predicate, the writer can indicate rich connotative information about the entities that interact through\nWriter: \u201cAgent violates theme.\u201d\nthe predicate. Specifically, through a simple statement such as \u201cx violated y\u201d, the writer can convey:\n(1) writer\u2019s perspective: the writer is projecting x as an \u201cantagonist\u201d and y as a \u201cvictim\u201d, eliciting negative perspective from readers toward x (i.e., blaming x) and positive perspective toward y (supportive or sympathetic to y). (2) entities\u2019 perspective: y most likely feels negatively toward x as a result of being violated. (3) effect: something bad happened to y. (4) value: y is something valuable, since it does\nnot make sense to violate something worthless. In other words, the writer is presupposing y\u2019s positive value as a fact.\n(5) mental state: y is most likely unhappy about the outcome.1\n1To be more precise, y is most likely in a negative mental state assuming it is an entity that can have a mental state.\nar X\niv :1\n50 6.\n02 73\n9v 3\n[ cs\n.C L\n] 2\n2 A\nug 2\n01 6\nEven though the writer might not explicitly state any of the interpretations [1-5] above, the readers will be able interpret these intentions as a part of their comprehension. In this paper, we present an empirical study of how to represent and induce the connotative interpretations that can be drawn from a verb predicate, as illustrated above.\nWe introduce connotation frames as a representation framework to organize the rich dimensions of the implied sentiment and presupposed facts. Figure 1 shows an example of a connotation frame for the predicate violate. We define four different typed relations: P(x \u2192 y) for perspective of x towards y, E(x) for effect on x, V(x) for value of x, and S(x) for mental state of x. These relationships can all be either positive (+), neutral (=), or negative (-).\nOur work is the first study to investigate frames as a representation formalism for connotative meanings. This contrasts with previous computational studies and resource development for frame semantics, where the primary focus was almost exclusively on denotational meanings of language (Baker et al., 1998; Palmer et al., 2005). Our formalism draws inspirations from the earlier work of frame semantics, however, in that we investigate the connection between a word and the related world knowledge associated with the word (Fillmore, 1976), which is essential for the readers to interpret many layers of the implied sentiment and presupposed value judgments.\nWe also build upon the extensive amount of literature in sentiment analysis (Pang and Lee, 2008; Liu and Zhang, 2012), especially the recent emerging efforts on implied sentiment analysis (Feng et al., 2013; Greene and Resnik, 2009), entityentity sentiment inference (Wiebe and Deng, 2014), opinion role induction (Wiegand and Ruppenhofer, 2015), and effect analysis (Choi and Wiebe, 2014).\nHowever, our work is the first to organize aspects of the connotative information into coherent frames.\nMore concretely, our contributions are threefold: (1) a new formalism, model, and annotated dataset for studying the connotation frames from largescale natural language data and statistics, (2) datadriven insights into the dynamics among different typed relations within each frame, and (3) an analytic study to show the potential use of connotation frames for analyzing subtle biases in journalism.\nThe rest of the paper is organized as follows: in \u00a72, we provide the definitions and data-driven insights for connotation frames. In \u00a73, we introduce models for inducing the connotation frames, followed by empirical results, annotation studies, and analysis on news media in \u00a74. We discuss related work in \u00a75 and conclude in \u00a76."}, {"heading": "2 Connotation Frame", "text": "Given a predicate v, we define a connotation frame F(v) as a collection of typed relations and their polarity assignments: (i) perspective Pv(xi \u2192 xj): whether the predicate v implies directed sentiment from the entity xi to the entity xj , (ii) value Vv(xi): whether xi is presupposed to be valuable by the predicate v, (iii) effect Ev(xi): whether the event denoted by the predicate v is good or bad for the entity xi, and (iv) mental state Sv(xi): the likely mental state of the entity xi as a result of the event. We assume that each typed relation can have one of the three connotative polarities \u2208 {+,\u2212,=}, i.e., positive, negative, or neutral. Our goal in this paper is to focus on the general connotation of the predicate considered out of context. We leave contextual interpretation of connotation as future work.\nTable 1 shows examples of connotation frame relations for the verbs suffer, guard, and uphold, along with example sentences. For instance, for the verb suffer, the writer is likely to have a positive\nperspective towards the agent (e.g., being supportive or sympathetic toward the \u201c17-year-old girl\u201d in the example shown on the right) and a negative perspective towards the theme (e.g., being negative towards \u2018botched abortion\u201d)."}, {"heading": "2.1 Data-driven Motivation", "text": "Since the meaning of language is ultimately contextual, the exact connotation will vary depending on the context of each utterance. Nonetheless, there still are common shifts or biases in the connotative polarities, as we found from two data-driven analyses.\nFirst, we looked at words from the Subjectivity Lexicon (Wilson et al., 2005) that are used in the argument positions of a small selection of predicates in Google Syntactic N-grams (Goldberg and Orwant, 2013). For this analysis, we assumed that the agent is the word in the subject position while the theme is the word in the object position. We found 64% of the words in the agent role of suffer are positive, and 94% of the words in the theme role are negative, which is consistent with the polarities of the writer\u2019s perspective towards these arguments, as shown in Table 1. For guard, 57% of the agents and 76% of the themes are positive, and in the case of uphold, 56% of the agents and 72% of the themes are positive.\nWe also investigated how media bias can potentially be analyzed through connotation frames. From the Stream Corpus 2014 dataset (KBA, 2014), we selected all articles from news outlets with known political biases,2 and compared how they use polarised words such as \u201caccuse\u201d, \u201cattack\u201d, and \u201ccriticize\u201d differently in light of P(w \u2192 agent) and P(w \u2192 theme) relations of the connotation frames. Table 2 shows interesting contrasts. Obama, for example, is frequently portrayed as\n2The articles come from 30 news sources indicated by others as exhibiting liberal or conservative leanings (Mitchell et al., 2014; Center for Media and Democracy, 2013; Center for Media and Democracy, 2012; HWC Library, 2011)\nsomeone who attacks or criticizes others according to the right-leaning sources, whereas the leftleaning sources portray Obama as the victim of harsh acts like \u201cattack\u201d or \u201ccriticize\u201d.3 Furthermore, by knowing the perspective relationships P(w \u2192 xi) associated with a predicate, we can make predictions about how the left-leaning and right-leaning sources feel about specific people or issues. For example, because left-leaning sources frequently use McCain, Trump, and Limbaugh in the agent position of attack, we might predict that these sources have a negative sentiment towards these entities."}, {"heading": "2.2 Dynamics between Typed Relations", "text": "Given a predicate, the polarity assignments of typed relations are interdependent. For example, if the writer feels positively towards the agent but negatively towards the theme, then it is likely that the agent and the theme do not feel positively towards each other. This insight is related to that of Wiebe and Deng (2014), but differs in that the polarities are predicate-specific and do not rely on knowledge of prior sentiment towards the arguments, themselves. This and other possible interdependencies are summarized in Table 3. These interdependencies serve as general guidelines of what properties we expect to depend on one another, especially in the case where the polarities are non-neutral. We will promote these internal consistencies in our factor graph model (\u00a73) as soft constraints.\nThere also exist other interdependencies that we will use to simplify our task. First, the directed sentiments between the agent and the theme are likely to be reciprocal, or at least do not directly conflict with + and \u2212 simultaneously. This intuition follows from a notion of balance derived by social theory (Heider, 1946). Therefore, we assume\n3That is, even if someone truly deserves criticism from Obama, left-learning sources would choose slightly different wordings to avoid a potentially harsh portrayal of Obama.\nthat P(xi \u2192 xj) = P(xj \u2192 xi) = P(xi \u2194 xj), and we only measure for these binary relationships going in one direction. In addition, we assume the predicted4 perspective from the reader r to an argument, P(r \u2192 x), is likely to be the same as the implied perspective from the writer w to the same argument, P(w \u2192 x). So, we only try to learn the perspective of the writer. Lifting these assumptions will be future work.\nFor simplicity, our work only explores verb predicates and focuses on the polarities involving the agent and the theme roles, which we will refer to as a and t. We will assume that these roles are correlated to the subject and object positions.\n4Surely different readers can and will form varying opinions after reading the same text. Here we concern with the most likely perspective of the general audience, as a result of reading the text."}, {"heading": "3 Modeling Connotation Frames", "text": "Our task is essentially that of lexicon induction (Akkaya et al., 2009; Feng et al., 2013) in that we want to induce the connotation frames of previously unseen verbs. For each verb predicate, we infer a connotation frame composed of 9 relationship aspects that represent: perspective {P(w \u2192 t), P(w \u2192 a), P(a\u2192 t)}, effect {E(t), E(a)}, value {V(t), V(a)}, and mental state {S(t), S(a)} polarities, where w, a, t denote the writer, the agent, and the theme, respectively.\nWe propose two models: an aspect-level model that makes the prediction for each typed relation independently based on the distributional representation of the context in which the predicate commonly appears (\u00a73.1), and a frame-level model that makes the prediction over the connotation frame collectively in consideration of the dynamics between typed relations (\u00a73.2)."}, {"heading": "3.1 Aspect-Level", "text": "Our aspect-level model predicts labels for each of these typed relations separately. As input, we use the 300-dimensional dependency-based word embeddings from Levy and Goldberg (2014). For each aspect, there is a separate MaxEnt (maximum entropy) classifier used to predict the label of that aspect on a given word-embedding, which is treated as a 300 dimensional input vector to the classifier. The MaxEnt classifiers learn their weights using LBFGS on the training data examples with re-weighting of samples to maximize for the best average F1 score."}, {"heading": "3.2 Frame-Level", "text": "Next we present a factor graph model (Figure 2) of the connotation frames that parameterizes the dynamics between typed relations. Specifically,\nfor each verb predicate, the factor graph contains 9 nodes representing the different aspects of the connotation frame involving the writer (w), the agent (a), and the theme (t). All these variables take polarity values from the set {\u2212,=,+}.\nWe define Yi := {Pwt,Pwa,Pat, Et, Ea,Vt,Va, St,Sa} as the set of relational aspects for the ith verb predicate. The factor graph for Yi, is illustrated in Figure 2, and we describe the factor potentials, \u03c8, in detail in the rest of this section. The probability of an assignment of polarities to the nodes in Yi is:\nP (Yi) \u221d \u03c8PV(Pwa,Va) \u03c8PV(Pwt,Vt) \u03c8PE(Pat, Ea) \u03c8PE(Pat, Et) \u03c8ES(Ea,Sa) \u03c8ES(Et,St) \u03c8PT(Pwt,Pwa,Pat)\n\u220f y\u2208Yi \u03c8emb(y)\nEmbedding Factors We include unary factors on all nodes to represent the results of the aspect-level classifier. Incorporating this knowledge as factors, as opposed to fixing the variables as observed, affords us the flexibility of representing noise in the labels as soft evidence. The potential function \u03c8emb is a log-linear function of a feature vector f, which is a one-hot feature vector representing the polarity of a node (+,\u2212,or =). For example, with the node representing the value of the theme (Vt):\n\u03c8emb(Vt) = e\u03b8Vt \u00b7f(Vt)\nThe potential \u03c8emb is defined similarly for the remaining eight nodes.\nWeights \u03b8 are learned in a piecewise likelihood manner (Sutton and McCallum, 2009) for each factor independently using stochastic gradient descent (SGD) over the training data.\nInterdependency Factors We include interdependency factors to promote the properties defined by the dynamics between relations (\u00a72.2). The potentials for Perspective Triad, Perspective-Value, Perspective-Effect, and Effect-State Relationships (\u03c8PT , \u03c8PV , \u03c8PE, \u03c8ES respectively) are all defined using log-linear functions of one-hot feature vectors that encode the combination of polarities of the neighboring nodes. Thus the potential \u03c8PT is:\n\u03c8PT(Pwt,Pwa,Pat) = e\u03b8PT \u00b7f(Pwt,Pwa,Pat)\nAnd we define the potentials for \u03c8PV , \u03c8PE, and \u03c8ES for nodes pertaining to the agent as:\n\u03c8PV(Pwa,Va) = e\u03b8PV,a\u00b7f(Pwa,Va)\n\u03c8PE(Pat, Ea) = e\u03b8PE,a\u00b7f(Pat,Ea)\n\u03c8ES(Ea,Sa) = e\u03b8ES,a\u00b7f(Ea,Sa)\nand we define the potentials for the theme nodes similarly. As with the unary seed factors, weights \u03b8 are learned using SGD over training data.\nBelief Propagation We use belief propagation to induce the connotation frames of previously unseen verbs. In the belief propagation algorithm, messages are iteratively passed between the nodes to their neighboring factors. Each message \u00b5, containing a scalar for each value x \u2208 {\u2212,=,+}, is defined from each node v to a neighboring factor f as follows:\n\u00b5v\u2192f (x) \u221d \u220f\nf\u2217\u2208N(v)\\a\n\u00b5f\u2217\u2192v(x)\nand from each factor a to a neighboring node v as: \u00b5f\u2192v \u221d \u2211\nx\u2032,x\u2032v=x\n\u03c8(x\u2032) \u220f\nv\u2217\u2208N(f)\\v\n\u00b5v\u2217\u2192f (x \u2032 v\u2217)\nOur factor graph does not contain any loops, so we are able to perform exact inference by choosing a root node and performing message passing from the leaves to the root and back to the leaves. At the conclusion of message passing, the probability of a specific polarity associated with node v being equal to x is proportional to \u220f f\u2208N(v) \u00b5f\u2192v(x)."}, {"heading": "4 Experiments", "text": "We first describe crowd-sourced annotations (\u00a74.1), then present the empirical results of predicting connotation frames (\u00a74.2), and conclude with qualitative analysis of a large corpus (\u00a74.3)."}, {"heading": "4.1 Data and Crowdsourcing", "text": "In order to understand how humans interpret connotation frames, we designed an Amazon Mechanical Turk (AMT) annotation study. We gathered a set of transitive verbs commonly used in the New York Times corpus (Sandhaus, 2008), selecting the 2400 verbs that are used more than 200 times in the corpus. Of these, AMT workers annotated the 1000 most frequently used verbs. Annotation Design In a pilot annotation experiment, we found that annotators have difficulty thinking about subtle connotative polarities when shown predicates without any context. Therefore, we designed the AMT task to provide a generic context as follows. We first split each verb predicate into 5 separate tasks that each gave workers a\ndifferent generic sentence using the verb. To create generic sentences, we used Google Syntactic N-grams (Goldberg and Orwant, 2013) to come up with a frequently seen Subject-Verb-Object tuple which served as a simple three-word sentence with generic arguments.5 For each of the 5 sentences, we asked 3 annotators to answer questions like \u201cHow do you think the agent feels about the event described in this sentence?\u201d In total, each verb has 15 annotations aggregated over 5 different generic sentences containing the verb.\nIn order to help the annotators, some of the questions also allowed annotators to choose sentiment using additional classes for \u201cpositive or neutral\u201d or \u201cnegative or neutral\u201d for when they were less confident but still felt like a sentiment might exist. When taking inter-annotator agreement, we count \u201cpositive or neutral\u201d as agreeing with either \u201cpositive\u201d or \u201cneutral\u201d classes. Annotator agreement Table 4 shows agreements and data statistics. The non-conflicting (NC) agreement only counts opposite polarities as disagreement.6 From this study, we can see that non-expert annotators are able to see these sort of relationships based on their understanding of how language is used. From the NC agreement, we see that annotators do not frequently choose completely opposite polarities, indicating that even when they disagree, their disagreements are based on the degree of connotations rather than the polarity itself. The average Krippendorff alpha for all of the questions posed to the workers is 0.25, indicating stronger than random agreement. Considering the subtlety of the implicit sentiments that we are asking them to annotate, it is reasonable that some annotators will pick up on more nuances than others. Overall, the percent agreement is encouraging that the connotative relationships are visible to human annotators. Aggregating Annotations We aggregated over crowdsourced labels (fifteen annotations per verb) to create a polarity label for each aspect of a verb.7\nFinal distributions of the aggregated labels are included in the right-hand columns of Table 4. No-\n5Because Google Syntactic N-grams only provide dependency types and do not provide semantic roles, we approximate the agent and theme as the subject and the object respectively.\n6Annotators were asked yes/no questions related to Value, so this does not have a corresponding NC agreement score.\n7 We take the average to obtain scalar value between [\u22121., 1.] for each aspect of a verb\u2019s connotation frame. For simplicity, we cutoff the ranges of negative, neutral and positive polarities as [\u22121,\u22120.25), [\u22120.25, 0.25] and (0.25, 1], respectively.\ntably, the distributions are skewed toward positive and neutral labels. The most skewed connotation frame aspect is the value V(x) which tends to be positive, especially for the agent argument. This makes some intuitive sense since, as the agent actively causes the predicate event to occur, they most likely have some intrinsic potential to be valuable. An example of a verb where the agent was labelled with negative value is \u201ccontaminate\u201d. In the most generic case, the writer is using \u201ccontaminate\u201d to frame the agent as being worthless (and even harmful) with regards to the other event participants. For example, in the sentence \u201chis touch contaminated the food,\u201d it is clear that the writer presupposes \u201chis touch\u201d to be of negative value in how it impacts the rest of the event."}, {"heading": "4.2 Connotation Frame Prediction", "text": "Using the crowdsourced labels, we randomly divide the annotated verbs into training, dev, and held-out test sets of equal size (300 verbs each). For evaluation we measure average accuracy and F1 score of induced labels for the 9 different connotation frame relationship types for which we have annotations: P(w \u2192 t), P(w \u2192 a), P(a \u2192 t), V(t), V(a), E(t), E(a), S(t), and S(a), where w refers to the writer, a to the agent, and t to the theme. Baselines To show the non-trivial challenge of learning Connotation Frames, we include a simple majority-class baselines. The MAJORITY classifier assigns each of the 9 relationships the label of the majority of that relationship type found in the training data. Some of these relationships (in\nparticular, the Value of agent/theme) have skewed distributions, so we expect this classifier to achieve a much higher accuracy than random but a much lower overall F1 score.\nAdditionally, we add a GRAPH PROP baseline that is comparable to algorithms like graph propagation or label propagation which are often used for (sentiment) lexicon induction (Velikovich et al., 2010a). We use a factor graph with nodes representing the polarity of each typed relation for each verb. Binary factors connect nodes representing a particular type of relation for two similar verbs (e.g. P(w \u2192 t) for verbs persuade and convince). These binary factors have hand-tuned potentials that are proportional to the cosine similarity of the verbs\u2019 embeddings, encouraging similar verbs to have the same polarity for the various relational aspects. We use words in the training data as the seed set and use loopy belief propagation to propagate polarities from known nodes to the unknown relationships.\nFinally, we use a 3-NEAREST NEIGHBOR baseline that labels relationships for a verb based on the predicate\u2019s 300-dimensional word embedding representation, using the same embeddings as in our aspect-level. 3-NEAREST NEIGHBOR labels each verb using the polarities of the three closest verbs found in the training set. The most similar verbs are determined using the cosine similarity between word embeddings.\nResults As shown in Table 5, aspect-level and frame-level models consistently outperform all three baselines \u2014 MAJORITY, 3-NN, GRAPH PROP in the development set across the different types of relationships. In particular, the improved F1 scores show that these models are able to perform better across all three classes of labels even in the most skewed cases. The frame-level model also frequently improves the F1 scores of the labels from what they were in the aspect-level model. The summarized comparison of the classifiers\u2019 performance test set is shown in Table 6. As with the development set, aspect-level and frame-level are both able to outperform the baselines. Furthermore, the frame-level formulation is able to make improvement over the results of the aspectlevel classification, indicating that the modelling of inter-dependencies between relationships did help correct some of the mistakes made.\nOne point of interest about the frame-level results is whether the learned weights over the consis-\ntency factors match our initial intuitions about interdependencies between relationships. The weights learned in our algorithm do tell us something interesting about the degree to which these interdependencies are actually found in our data.\nWe show the heat maps for some of the learned weights in Figure 3. In 3a, we show the weights of one of the embedding factors, and how the node\u2019s polarities are more strongly weighted when they match the aspect-level output. In the rest of the figure, we show the weights for the other perspective relationships when P(w \u2192 t) is negative (3b), neutral (3c), and positive (3d), respectively. Based on the expected interdependencies, when P(w \u2192 t) : \u2212, the model should favor P(w \u2192 a) 6= P(a\u2192 t) and when P(w \u2192 t) : +, the model should favor P(w \u2192 a) = P(a \u2192 t). Our model does, in fact, learn a similar trend, with slightly higher weights along these two diagonals in the maps 3b and 3d. Interestingly, when P(w \u2192 t) is neutral, weights slightly prefer for the other two perspectives to resemble one another, but with highest weights being when other perspectives are also neutral."}, {"heading": "4.3 Analysis of a Large News Corpus", "text": "Using the connotation frame, we present measured implied sentiment in online journalism.\nData From the Stream Corpus (KBA, 2014), we select 70 million news articles. We extract subject-verb-object relations for this subset us-\n1.0 0.5 0.0 0.5 1.0\nDemocrat\n1.0\n0.5\n0.0\n0.5\n1.0\nlawsuits\nfunding\nbudget deal\ntax proposal\nabortion\nelephant mccain\nnancy pelosi\ndelaying tactics\nbacklash\nbias\nmitt romney\nnra\nthe proposal\njudicial nominees\nstate department\nbill clinton\ntheir principles\naid\nbig business\nobamacare\nmarket\nrenomination\ngay marriage\ntradition\nhealth care bill\nbusiness the pipeline\ntax cuts\nprinciples\nsmall businesses\nveto threat\nboehner\nthe dream act\ngeorge w. bush\nidea\nbusinesses\nbudget proposal\ntax increases\npropositions\npalin\nbarack obama\nthe allegations\nenvironment\nconstitution\nkerrytax deal\njobs bills medicare\ngop leadership\nhealth\nfloor vote\nunions\nbudget cuts\ngun control\nFigure 4: Average sentiment of Democrats and Republicans (as agents) to selected nouns (as their themes), aggregated over a large corpus using the learned lexicon (\u00a74.2). The line indicates identical sentiments, i.e. Republicans are more positive towards the nouns that are above the line.\ning the direct dependencies between noun phrases and verbs as identified by the BBN Serif system, obtaining 1.2 billion unique tuples of the form (url,subject,verb,object,count). We also extract tuples from news articles from the Annotated English Gigaword Corpus (Napoles et al., 2012), which contains nearly 10 million articles, resulting in an additional 120 million unique tuples.\nEstimating Entity Polarities Using connotation frames, we can also measure entity-to-entity sentiment at a large scale. Figure 4, for example, presents the polarity of entities \u201cDemocrats\u201d and \u201cRepublicans\u201d towards a selected set of nouns, by computing the average estimated P(a\u2192 t) polarity (using our frame-level output) over triples where one of these entities appears as part of the phrase in the agent role (e.g. \u201cDemocrats\u201d or \u201cRepublican party\u201d). Apart from nouns that both entities are positive (\u201cbusiness\u201d, \u201cconstitution\u201d) or negative (\u201cthe allegations\u201d,\u201cveto threat\u201d) towards, we can also see interesting examples in which Democrats feel more positively (below the line: \u201cnancy pelosi\u201d, \u201cunions\u201d, \u201cgun control\u201d, etc.) and ones where Republicans feel more positive (\u201cthe pipeline\u201d, \u201cgop leadership\u201d, \u201cbudget cuts\u201d, etc.). Also, both entities are neutral towards \u201cidea\u201d and \u201cthe proposal\u201d, which probably owes to the fact that ideas or proposals can be good or bad for either entity depending on the context."}, {"heading": "5 Related Work", "text": "Most prior work on sentiment lexicons focused on the overall polarity of words without taking into account their semantic arguments (Wilson et al., 2005; Baccianella et al., 2010; Wiebe et al., 2005; Velikovich et al., 2010b; Kaji and Kitsuregawa, 2007; Kamps et al., 2004; Takamura et al., 2005; Adreevskaia and Bergler, 2006). Several recent studies began exploring more specific and nuanced aspects of sentiment such as connotation (Feng et al., 2013), good and bad effects (Choi and Wiebe, 2014), and evoked sentiment (Mohammad and Turney, 2010). Drawing inspirations from them, we present connotation frames as a unifying representation framework to encode the rich dimensions of implied sentiment, presupposed value judgements, and effect evaluation, and propose a factor graph formulation that captures the interplay among different types of connotation relations.\nGoyal et al. (2010a; 2010b) investigated how characters (protagonists, villains, victims) in children\u2019s stories are affected by certain predicates, which is related to the effect relations studied in this work. While Klenner et al. (2014) similarly investigated the relation between the polarity of the verbs and arguments, our work introduces new perspective types and proposes a unified representation and inference model. Wiegand and Ruppenhofer (2015) also looked at perspective-based relationships induced by verb predicates with a focus on opinion roles. Building on this concept, our framework also incorporates information about the perspectives\u2019 polarities as well as information about other typed relations. There have been growing interests for modeling framing (Greene and Resnik, 2009; Hasan and Ng, 2013), biased language (Recasens et al., 2013) and ideology detection (Yano et al., 2010). All these tasks are relatively less studied, and we hope our connotation frame lexicon will be useful for them.\nSentiment inference rules have been explored by the recent work of Wiebe and Deng (2014) and Deng and Wiebe (2014). The focus of their work was on general inference rules that are not predicate-specific. In contrast, our work focuses on the notion that connotative polarities can be determined directly from the predicate, rather than partial knowledge of the arguments or the context in which it is being used. In brief, we make a novel conceptual connection between inferred sentiments and frame semantics, organized as conno-\ntation frames, and present a unified model that integrates different aspects of the connotation frames.\nFinally, in a broader sense, what we study as connotation frames draws a connection to schema and script theory (Schank and Abelson, 1975). Unlike prior work that focused on directly observable actions (Chambers and Jurafsky, 2009; Frermann et al., 2014; Bethard et al., 2008), we focus on implied sentiments that are framed by predicate verbs."}, {"heading": "6 Conclusion", "text": "In this paper, we presented a novel system of connotative frames that define a set of implied sentiment and presupposed facts for a predicate. Our work also empirically explores different methods of inducing and modelling these connotation frames, incorporating the interplay between relations within frames. Our work suggests new research avenues on learning connotation frames, and their applications to deeper understanding of social and political discourse. All the learned connotation frames and annotations are available at http://homes.cs.washington.edu/ \u02dchrashkin/connframe.html."}, {"heading": "Acknowledgements", "text": "We thank the anonymous reviewers for many insightful comments. We also thank members of UW NLP for discussions and support. This material is based upon work supported by the National Science Foundation Graduate Research Fellowship Program under Grant No. DGE-1256082, in part by NSF grants IIS-1408287, IIS-1524371, and gifts by Google and Facebook."}], "references": [{"title": "Mining wordnet for fuzzy sentiment: Sentiment tag extraction from wordnet glosses", "author": ["Alina Adreevskaia", "Sabine Bergler."], "venue": "11th Conference of the European Chapter of the Association for Computational Linguistics, pages 209\u2013216.", "citeRegEx": "Adreevskaia and Bergler.,? 2006", "shortCiteRegEx": "Adreevskaia and Bergler.", "year": 2006}, {"title": "Subjectivity word sense disambiguation", "author": ["Cem Akkaya", "Janyce Wiebe", "Rada Mihalcea."], "venue": "Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, volume 2, pages 190\u2013199.", "citeRegEx": "Akkaya et al\\.,? 2009", "shortCiteRegEx": "Akkaya et al\\.", "year": 2009}, {"title": "Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining", "author": ["Stefano Baccianella", "Andrea Esuli", "Fabrizio Sebastiani"], "venue": "In Proceedings of the Seventh conference on", "citeRegEx": "Baccianella et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Baccianella et al\\.", "year": 2010}, {"title": "The berkeley framenet project", "author": ["Collin F Baker", "Charles J Fillmore", "John B Lowe."], "venue": "Proceedings of the 17th international conference on Computational linguistics, volume 1, pages 86\u201390.", "citeRegEx": "Baker et al\\.,? 1998", "shortCiteRegEx": "Baker et al\\.", "year": 1998}, {"title": "Building a corpus of temporal-causal structure", "author": ["Steven Bethard", "William J Corvey", "Sara Klingenstein", "James H Martin."], "venue": "Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC\u201908).", "citeRegEx": "Bethard et al\\.,? 2008", "shortCiteRegEx": "Bethard et al\\.", "year": 2008}, {"title": "Sourcewatch: Conservative news outlets", "author": ["Center for Media", "Democracy."], "venue": "http://www.sourcewatch.org/index. php/Conservative_news_outlets.", "citeRegEx": "Media and Democracy.,? 2012", "shortCiteRegEx": "Media and Democracy.", "year": 2012}, {"title": "Sourcewatch: Liberal news outlets", "author": ["Center for Media", "Democracy."], "venue": "http: //www.sourcewatch.org/index.php/ Liberal_news_outlets.", "citeRegEx": "Media and Democracy.,? 2013", "shortCiteRegEx": "Media and Democracy.", "year": 2013}, {"title": "Unsupervised learning of narrative schemas and their participants", "author": ["Nathanael Chambers", "Dan Jurafsky."], "venue": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language", "citeRegEx": "Chambers and Jurafsky.,? 2009", "shortCiteRegEx": "Chambers and Jurafsky.", "year": 2009}, {"title": "+/effectwordnet: Sense-level lexicon acquisition for opinion inference", "author": ["Yoonjung Choi", "Janyce Wiebe."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1181\u20131191. Associa-", "citeRegEx": "Choi and Wiebe.,? 2014", "shortCiteRegEx": "Choi and Wiebe.", "year": 2014}, {"title": "Sentiment propagation via implicature constraints", "author": ["Lingjia Deng", "Janyce Wiebe."], "venue": "Proceedings of the Conference of the European Chapter of the Association for Computational Linguistics (EACL).", "citeRegEx": "Deng and Wiebe.,? 2014", "shortCiteRegEx": "Deng and Wiebe.", "year": 2014}, {"title": "Connotation lexicon: A dash of sentiment beneath the surface meaning", "author": ["Song Feng", "Jun Seok Kang", "Polina Kuznetsova", "Yejin Choi."], "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL), vol-", "citeRegEx": "Feng et al\\.,? 2013", "shortCiteRegEx": "Feng et al\\.", "year": 2013}, {"title": "Frame semantics and the nature of language", "author": ["Charles J. Fillmore."], "venue": "In Annals of the New York Academy of Sciences: Conference on the Origin and Development of Language and Speech, volume 280, pages 2032.", "citeRegEx": "Fillmore.,? 1976", "shortCiteRegEx": "Fillmore.", "year": 1976}, {"title": "A hierarchical bayesian model for unsupervised induction of script knowledge", "author": ["Lea Frermann", "Ivan Titov", "Manfred Pinkal."], "venue": "Proceedings of the Conference of the European Chapter of the Association for Computational Linguistics.", "citeRegEx": "Frermann et al\\.,? 2014", "shortCiteRegEx": "Frermann et al\\.", "year": 2014}, {"title": "A dataset of syntactic-ngrams over time from a very large corpus of english books", "author": ["Yoav Goldberg", "Jon Orwant."], "venue": "Second Joint Conference on Lexical and Computational Semantics (*SEM), volume 1, pages 241\u2013247, June.", "citeRegEx": "Goldberg and Orwant.,? 2013", "shortCiteRegEx": "Goldberg and Orwant.", "year": 2013}, {"title": "Automatically producing plot unit representations for narrative text", "author": ["Amit Goyal", "Ellen Riloff", "Hal Daum\u00e9", "III."], "venue": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, Proceedings of the 2010 Conference on", "citeRegEx": "Goyal et al\\.,? 2010a", "shortCiteRegEx": "Goyal et al\\.", "year": 2010}, {"title": "Toward plot units: Automatic affect state analysis", "author": ["Amit Goyal", "Ellen Riloff", "Hal Daum\u00e9 III", "Nathan Gilbert."], "venue": "Proceedings of HLT/NAACL Workshop on Computational Approaches to Analysis and Generation of Emotion in Text (CAET).", "citeRegEx": "Goyal et al\\.,? 2010b", "shortCiteRegEx": "Goyal et al\\.", "year": 2010}, {"title": "More than words: Syntactic packaging and implicit sentiment", "author": ["Stephan Greene", "Philip Resnik."], "venue": "Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Lin-", "citeRegEx": "Greene and Resnik.,? 2009", "shortCiteRegEx": "Greene and Resnik.", "year": 2009}, {"title": "Frame semantics for stance classification", "author": ["Kazi Saidul Hasan", "Vincent Ng."], "venue": "Proceedings of the Seventeenth Conference on Computational Natural Language Learning (CONLL), pages 124\u2013132.", "citeRegEx": "Hasan and Ng.,? 2013", "shortCiteRegEx": "Hasan and Ng.", "year": 2013}, {"title": "Attitudes and cognitive organization", "author": ["Fritz Heider."], "venue": "The Journal of psychology, 21(1):107\u2013112.", "citeRegEx": "Heider.,? 1946", "shortCiteRegEx": "Heider.", "year": 1946}, {"title": "Building lexicon for sentiment analysis from massive collection of html documents", "author": ["Nobuhiro Kaji", "Masaru Kitsuregawa."], "venue": "Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Nat-", "citeRegEx": "Kaji and Kitsuregawa.,? 2007", "shortCiteRegEx": "Kaji and Kitsuregawa.", "year": 2007}, {"title": "Using wordnet to measure semantic orientations of adjectives", "author": ["Jaap Kamps", "Maarten Marx", "Robert J Mokken", "Maarten De Rijke."], "venue": "Proceedings of the Fourth International Conference on Language Resources and Evaluation(LREC\u201904), vol-", "citeRegEx": "Kamps et al\\.,? 2004", "shortCiteRegEx": "Kamps et al\\.", "year": 2004}, {"title": "Knowledge Base Acceleration Stream Corpus", "author": ["TREC KBA."], "venue": "http://trec-kba.org/ kba-stream-corpus-2014.shtml.", "citeRegEx": "KBA.,? 2014", "shortCiteRegEx": "KBA.", "year": 2014}, {"title": "Verb polarity frames: a new resource and its application in target-specific polarity classification", "author": ["Manfred Klenner", "Michael Amsler", "Nora Hollenstein."], "venue": "Proceedings of KONVENS 2014, pages 106\u2013115.", "citeRegEx": "Klenner et al\\.,? 2014", "shortCiteRegEx": "Klenner et al\\.", "year": 2014}, {"title": "Dependencybased word embeddings", "author": ["Omer Levy", "Yoav Goldberg."], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL), pages 302\u2013308.", "citeRegEx": "Levy and Goldberg.,? 2014", "shortCiteRegEx": "Levy and Goldberg.", "year": 2014}, {"title": "A survey of opinion mining and sentiment analysis", "author": ["Bing Liu", "Lei Zhang."], "venue": "Mining text data, pages 415\u2013463. Springer.", "citeRegEx": "Liu and Zhang.,? 2012", "shortCiteRegEx": "Liu and Zhang.", "year": 2012}, {"title": "Political Polarization & Media Habits", "author": ["Amy Mitchell", "Jeffrey Gottfried", "Jocelyn Kiley", "Katerina Eva Matsa."], "venue": "www.journalism.org/2014/10/21/ political-polarization-media-habits/.", "citeRegEx": "Mitchell et al\\.,? 2014", "shortCiteRegEx": "Mitchell et al\\.", "year": 2014}, {"title": "Emotions evoked by common words and phrases: Using mechanical turk to create an emotion lexicon", "author": ["Saif M Mohammad", "Peter D Turney."], "venue": "Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Gener-", "citeRegEx": "Mohammad and Turney.,? 2010", "shortCiteRegEx": "Mohammad and Turney.", "year": 2010}, {"title": "Annotated gigaword", "author": ["Courtney Napoles", "Matthew Gormley", "Benjamin Van Durme."], "venue": "Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction, pages 95\u2013100. Association for Computa-", "citeRegEx": "Napoles et al\\.,? 2012", "shortCiteRegEx": "Napoles et al\\.", "year": 2012}, {"title": "The proposition bank: An annotated corpus of semantic roles", "author": ["Martha Palmer", "Daniel Gildea", "Paul Kingsbury."], "venue": "Computational linguistics, 31(1):71\u2013106.", "citeRegEx": "Palmer et al\\.,? 2005", "shortCiteRegEx": "Palmer et al\\.", "year": 2005}, {"title": "Opinion mining and sentiment analysis", "author": ["Bo Pang", "Lillian Lee."], "venue": "Foundations and trends in information retrieval, 2(1-2):1\u2013135.", "citeRegEx": "Pang and Lee.,? 2008", "shortCiteRegEx": "Pang and Lee.", "year": 2008}, {"title": "Linguistic models for analyzing and detecting biased language", "author": ["Marta Recasens", "Cristian Danescu-Niculescu-Mizil", "Dan Jurafsky."], "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL), pages 1650\u2013", "citeRegEx": "Recasens et al\\.,? 2013", "shortCiteRegEx": "Recasens et al\\.", "year": 2013}, {"title": "The new york times annotated corpus", "author": ["Evan Sandhaus."], "venue": "Linguistic Data Consortium, Philadelphia, 6(12):e26752.", "citeRegEx": "Sandhaus.,? 2008", "shortCiteRegEx": "Sandhaus.", "year": 2008}, {"title": "Scripts, plans, and knowledge", "author": ["Roger C Schank", "Robert P Abelson."], "venue": "Yale University.", "citeRegEx": "Schank and Abelson.,? 1975", "shortCiteRegEx": "Schank and Abelson.", "year": 1975}, {"title": "Recognizing stances in ideological on-line debates", "author": ["Swapna Somasundaran", "Janyce Wiebe."], "venue": "Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 116\u2013124. Association", "citeRegEx": "Somasundaran and Wiebe.,? 2010", "shortCiteRegEx": "Somasundaran and Wiebe.", "year": 2010}, {"title": "Piecewise training for structured prediction", "author": ["Charles Sutton", "Andrew McCallum."], "venue": "Machine Learning, 77(2):165\u2013194.", "citeRegEx": "Sutton and McCallum.,? 2009", "shortCiteRegEx": "Sutton and McCallum.", "year": 2009}, {"title": "Extracting semantic orientations of words using spin model", "author": ["Hiroya Takamura", "Takashi Inui", "Manabu Okumura."], "venue": "Proceedings of 43rd Annual Meeting of the Association for Computational Linguistics (ACL).", "citeRegEx": "Takamura et al\\.,? 2005", "shortCiteRegEx": "Takamura et al\\.", "year": 2005}, {"title": "Get out the vote: Determining support or opposition from Congressional floor-debate transcripts", "author": ["Matt Thomas", "Bo Pang", "Lillian Lee."], "venue": "Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages", "citeRegEx": "Thomas et al\\.,? 2006", "shortCiteRegEx": "Thomas et al\\.", "year": 2006}, {"title": "The viability of web-derived polarity lexicons", "author": ["Leonid Velikovich", "Sasha Blair-Goldensohn", "Kerry Hannan", "Ryan McDonald."], "venue": "Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association", "citeRegEx": "Velikovich et al\\.,? 2010a", "shortCiteRegEx": "Velikovich et al\\.", "year": 2010}, {"title": "The viability of web-derived polarity lexicons", "author": ["Leonid Velikovich", "Sasha Blair-Goldensohn", "Kerry Hannan", "Ryan McDonald."], "venue": "Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association", "citeRegEx": "Velikovich et al\\.,? 2010b", "shortCiteRegEx": "Velikovich et al\\.", "year": 2010}, {"title": "An account of opinion implicatures", "author": ["Janyce Wiebe", "Lingjia Deng."], "venue": "CoRR, abs/1404.6491.", "citeRegEx": "Wiebe and Deng.,? 2014", "shortCiteRegEx": "Wiebe and Deng.", "year": 2014}, {"title": "Annotating expressions of opinions and emotions in language", "author": ["Janyce Wiebe", "Theresa Wilson", "Claire Cardie."], "venue": "Language resources and evaluation, 39(2-3):165\u2013210.", "citeRegEx": "Wiebe et al\\.,? 2005", "shortCiteRegEx": "Wiebe et al\\.", "year": 2005}, {"title": "Opinion holder and target extraction based on the induction of verbal categories", "author": ["Michael Wiegand", "Josef Ruppenhofer."], "venue": "Proceedings of the 2015 Conference on Computational Natural Language Learning (CoNLL), page 215.", "citeRegEx": "Wiegand and Ruppenhofer.,? 2015", "shortCiteRegEx": "Wiegand and Ruppenhofer.", "year": 2015}, {"title": "Recognizing contextual polarity in phraselevel sentiment analysis", "author": ["Theresa Wilson", "Janyce Wiebe", "Paul Hoffmann."], "venue": "Proceedings of the conference on human language technology and empirical methods in natural language processing, pages", "citeRegEx": "Wilson et al\\.,? 2005", "shortCiteRegEx": "Wilson et al\\.", "year": 2005}, {"title": "Shedding (a thousand points of) light on biased language", "author": ["Tae Yano", "Philip Resnik", "Noah A. Smith."], "venue": "Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon\u2019s Mechanical Turk, CSLDAMT \u201910,", "citeRegEx": "Yano et al\\.,? 2010", "shortCiteRegEx": "Yano et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 36, "context": "People commonly express their opinions through subtle and nuanced language (Thomas et al., 2006; Somasundaran and Wiebe, 2010).", "startOffset": 75, "endOffset": 126}, {"referenceID": 33, "context": "People commonly express their opinions through subtle and nuanced language (Thomas et al., 2006; Somasundaran and Wiebe, 2010).", "startOffset": 75, "endOffset": 126}, {"referenceID": 3, "context": "This contrasts with previous computational studies and resource development for frame semantics, where the primary focus was almost exclusively on denotational meanings of language (Baker et al., 1998; Palmer et al., 2005).", "startOffset": 181, "endOffset": 222}, {"referenceID": 28, "context": "This contrasts with previous computational studies and resource development for frame semantics, where the primary focus was almost exclusively on denotational meanings of language (Baker et al., 1998; Palmer et al., 2005).", "startOffset": 181, "endOffset": 222}, {"referenceID": 11, "context": "Our formalism draws inspirations from the earlier work of frame semantics, however, in that we investigate the connection between a word and the related world knowledge associated with the word (Fillmore, 1976), which is essential for the readers to interpret many layers of the implied sentiment and presupposed value judgments.", "startOffset": 194, "endOffset": 210}, {"referenceID": 29, "context": "We also build upon the extensive amount of literature in sentiment analysis (Pang and Lee, 2008; Liu and Zhang, 2012), especially the recent emerging efforts on implied sentiment analysis (Feng et al.", "startOffset": 76, "endOffset": 117}, {"referenceID": 24, "context": "We also build upon the extensive amount of literature in sentiment analysis (Pang and Lee, 2008; Liu and Zhang, 2012), especially the recent emerging efforts on implied sentiment analysis (Feng et al.", "startOffset": 76, "endOffset": 117}, {"referenceID": 10, "context": "We also build upon the extensive amount of literature in sentiment analysis (Pang and Lee, 2008; Liu and Zhang, 2012), especially the recent emerging efforts on implied sentiment analysis (Feng et al., 2013; Greene and Resnik, 2009), entityentity sentiment inference (Wiebe and Deng, 2014), opinion role induction (Wiegand and Ruppenhofer, 2015), and effect analysis (Choi and Wiebe, 2014).", "startOffset": 188, "endOffset": 232}, {"referenceID": 16, "context": "We also build upon the extensive amount of literature in sentiment analysis (Pang and Lee, 2008; Liu and Zhang, 2012), especially the recent emerging efforts on implied sentiment analysis (Feng et al., 2013; Greene and Resnik, 2009), entityentity sentiment inference (Wiebe and Deng, 2014), opinion role induction (Wiegand and Ruppenhofer, 2015), and effect analysis (Choi and Wiebe, 2014).", "startOffset": 188, "endOffset": 232}, {"referenceID": 39, "context": ", 2013; Greene and Resnik, 2009), entityentity sentiment inference (Wiebe and Deng, 2014), opinion role induction (Wiegand and Ruppenhofer, 2015), and effect analysis (Choi and Wiebe, 2014).", "startOffset": 67, "endOffset": 89}, {"referenceID": 41, "context": ", 2013; Greene and Resnik, 2009), entityentity sentiment inference (Wiebe and Deng, 2014), opinion role induction (Wiegand and Ruppenhofer, 2015), and effect analysis (Choi and Wiebe, 2014).", "startOffset": 114, "endOffset": 145}, {"referenceID": 8, "context": ", 2013; Greene and Resnik, 2009), entityentity sentiment inference (Wiebe and Deng, 2014), opinion role induction (Wiegand and Ruppenhofer, 2015), and effect analysis (Choi and Wiebe, 2014).", "startOffset": 167, "endOffset": 189}, {"referenceID": 42, "context": "First, we looked at words from the Subjectivity Lexicon (Wilson et al., 2005) that are used in the", "startOffset": 56, "endOffset": 77}, {"referenceID": 13, "context": "argument positions of a small selection of predicates in Google Syntactic N-grams (Goldberg and Orwant, 2013).", "startOffset": 82, "endOffset": 109}, {"referenceID": 21, "context": "From the Stream Corpus 2014 dataset (KBA, 2014), we selected all articles from news outlets with known political biases,2 and compared how they use polarised words such as \u201caccuse\u201d, \u201cattack\u201d, and \u201ccriticize\u201d differently in light of P(w \u2192 agent) and P(w \u2192 theme) relations of the connotation frames.", "startOffset": 36, "endOffset": 47}, {"referenceID": 25, "context": "The articles come from 30 news sources indicated by others as exhibiting liberal or conservative leanings (Mitchell et al., 2014; Center for Media and Democracy, 2013; Center for Media and Democracy, 2012; HWC Library, 2011) someone who attacks or criticizes others according to the right-leaning sources, whereas the leftleaning sources portray Obama as the victim of harsh acts like \u201cattack\u201d or \u201ccriticize\u201d.", "startOffset": 106, "endOffset": 224}, {"referenceID": 39, "context": "This insight is related to that of Wiebe and Deng (2014), but differs in that the polarities are predicate-specific and do not rely on knowledge of prior sentiment towards the arguments, themselves.", "startOffset": 35, "endOffset": 57}, {"referenceID": 18, "context": "This intuition follows from a notion of balance derived by social theory (Heider, 1946).", "startOffset": 73, "endOffset": 87}, {"referenceID": 1, "context": "Our task is essentially that of lexicon induction (Akkaya et al., 2009; Feng et al., 2013) in that we want to induce the connotation frames of previously unseen verbs.", "startOffset": 50, "endOffset": 90}, {"referenceID": 10, "context": "Our task is essentially that of lexicon induction (Akkaya et al., 2009; Feng et al., 2013) in that we want to induce the connotation frames of previously unseen verbs.", "startOffset": 50, "endOffset": 90}, {"referenceID": 23, "context": "As input, we use the 300-dimensional dependency-based word embeddings from Levy and Goldberg (2014). For each aspect, there is a separate MaxEnt (maximum entropy) classifier used to predict the label of that aspect on a given word-embedding, which is treated as a 300 dimensional input vector to the classifier.", "startOffset": 75, "endOffset": 100}, {"referenceID": 34, "context": "Weights \u03b8 are learned in a piecewise likelihood manner (Sutton and McCallum, 2009) for each factor independently using stochastic gradient descent (SGD) over the training data.", "startOffset": 55, "endOffset": 82}, {"referenceID": 31, "context": "We gathered a set of transitive verbs commonly used in the New York Times corpus (Sandhaus, 2008), selecting the 2400 verbs that are used more than 200 times in the corpus.", "startOffset": 81, "endOffset": 97}, {"referenceID": 13, "context": "To create generic sentences, we used Google Syntactic N-grams (Goldberg and Orwant, 2013) to come up with a frequently seen Subject-Verb-Object tuple which served as a simple three-word sentence with generic arguments.", "startOffset": 62, "endOffset": 89}, {"referenceID": 37, "context": "Additionally, we add a GRAPH PROP baseline that is comparable to algorithms like graph propagation or label propagation which are often used for (sentiment) lexicon induction (Velikovich et al., 2010a).", "startOffset": 175, "endOffset": 201}, {"referenceID": 21, "context": "Data From the Stream Corpus (KBA, 2014), we select 70 million news articles.", "startOffset": 28, "endOffset": 39}, {"referenceID": 27, "context": "Gigaword Corpus (Napoles et al., 2012), which contains nearly 10 million articles, resulting in an additional 120 million unique tuples.", "startOffset": 16, "endOffset": 38}, {"referenceID": 42, "context": "Most prior work on sentiment lexicons focused on the overall polarity of words without taking into account their semantic arguments (Wilson et al., 2005; Baccianella et al., 2010; Wiebe et al., 2005; Velikovich et al., 2010b; Kaji and Kitsuregawa, 2007; Kamps et al., 2004; Takamura et al., 2005; Adreevskaia and Bergler, 2006).", "startOffset": 132, "endOffset": 327}, {"referenceID": 2, "context": "Most prior work on sentiment lexicons focused on the overall polarity of words without taking into account their semantic arguments (Wilson et al., 2005; Baccianella et al., 2010; Wiebe et al., 2005; Velikovich et al., 2010b; Kaji and Kitsuregawa, 2007; Kamps et al., 2004; Takamura et al., 2005; Adreevskaia and Bergler, 2006).", "startOffset": 132, "endOffset": 327}, {"referenceID": 40, "context": "Most prior work on sentiment lexicons focused on the overall polarity of words without taking into account their semantic arguments (Wilson et al., 2005; Baccianella et al., 2010; Wiebe et al., 2005; Velikovich et al., 2010b; Kaji and Kitsuregawa, 2007; Kamps et al., 2004; Takamura et al., 2005; Adreevskaia and Bergler, 2006).", "startOffset": 132, "endOffset": 327}, {"referenceID": 38, "context": "Most prior work on sentiment lexicons focused on the overall polarity of words without taking into account their semantic arguments (Wilson et al., 2005; Baccianella et al., 2010; Wiebe et al., 2005; Velikovich et al., 2010b; Kaji and Kitsuregawa, 2007; Kamps et al., 2004; Takamura et al., 2005; Adreevskaia and Bergler, 2006).", "startOffset": 132, "endOffset": 327}, {"referenceID": 19, "context": "Most prior work on sentiment lexicons focused on the overall polarity of words without taking into account their semantic arguments (Wilson et al., 2005; Baccianella et al., 2010; Wiebe et al., 2005; Velikovich et al., 2010b; Kaji and Kitsuregawa, 2007; Kamps et al., 2004; Takamura et al., 2005; Adreevskaia and Bergler, 2006).", "startOffset": 132, "endOffset": 327}, {"referenceID": 20, "context": "Most prior work on sentiment lexicons focused on the overall polarity of words without taking into account their semantic arguments (Wilson et al., 2005; Baccianella et al., 2010; Wiebe et al., 2005; Velikovich et al., 2010b; Kaji and Kitsuregawa, 2007; Kamps et al., 2004; Takamura et al., 2005; Adreevskaia and Bergler, 2006).", "startOffset": 132, "endOffset": 327}, {"referenceID": 35, "context": "Most prior work on sentiment lexicons focused on the overall polarity of words without taking into account their semantic arguments (Wilson et al., 2005; Baccianella et al., 2010; Wiebe et al., 2005; Velikovich et al., 2010b; Kaji and Kitsuregawa, 2007; Kamps et al., 2004; Takamura et al., 2005; Adreevskaia and Bergler, 2006).", "startOffset": 132, "endOffset": 327}, {"referenceID": 0, "context": "Most prior work on sentiment lexicons focused on the overall polarity of words without taking into account their semantic arguments (Wilson et al., 2005; Baccianella et al., 2010; Wiebe et al., 2005; Velikovich et al., 2010b; Kaji and Kitsuregawa, 2007; Kamps et al., 2004; Takamura et al., 2005; Adreevskaia and Bergler, 2006).", "startOffset": 132, "endOffset": 327}, {"referenceID": 10, "context": "Several recent studies began exploring more specific and nuanced aspects of sentiment such as connotation (Feng et al., 2013), good and bad effects (Choi and Wiebe, 2014), and evoked sentiment (Mohammad and Turney, 2010).", "startOffset": 106, "endOffset": 125}, {"referenceID": 8, "context": ", 2013), good and bad effects (Choi and Wiebe, 2014), and evoked sentiment (Mohammad and Turney, 2010).", "startOffset": 30, "endOffset": 52}, {"referenceID": 26, "context": ", 2013), good and bad effects (Choi and Wiebe, 2014), and evoked sentiment (Mohammad and Turney, 2010).", "startOffset": 75, "endOffset": 102}, {"referenceID": 16, "context": "There have been growing interests for modeling framing (Greene and Resnik, 2009; Hasan and Ng, 2013), biased language (Recasens et al.", "startOffset": 55, "endOffset": 100}, {"referenceID": 17, "context": "There have been growing interests for modeling framing (Greene and Resnik, 2009; Hasan and Ng, 2013), biased language (Recasens et al.", "startOffset": 55, "endOffset": 100}, {"referenceID": 30, "context": "There have been growing interests for modeling framing (Greene and Resnik, 2009; Hasan and Ng, 2013), biased language (Recasens et al., 2013) and ideology detection (Yano et al.", "startOffset": 118, "endOffset": 141}, {"referenceID": 43, "context": ", 2013) and ideology detection (Yano et al., 2010).", "startOffset": 31, "endOffset": 50}, {"referenceID": 32, "context": "Finally, in a broader sense, what we study as connotation frames draws a connection to schema and script theory (Schank and Abelson, 1975).", "startOffset": 112, "endOffset": 138}, {"referenceID": 7, "context": "Unlike prior work that focused on directly observable actions (Chambers and Jurafsky, 2009; Frermann et al., 2014; Bethard et al., 2008), we focus on implied sentiments that are framed by predicate verbs.", "startOffset": 62, "endOffset": 136}, {"referenceID": 12, "context": "Unlike prior work that focused on directly observable actions (Chambers and Jurafsky, 2009; Frermann et al., 2014; Bethard et al., 2008), we focus on implied sentiments that are framed by predicate verbs.", "startOffset": 62, "endOffset": 136}, {"referenceID": 4, "context": "Unlike prior work that focused on directly observable actions (Chambers and Jurafsky, 2009; Frermann et al., 2014; Bethard et al., 2008), we focus on implied sentiments that are framed by predicate verbs.", "startOffset": 62, "endOffset": 136}, {"referenceID": 0, "context": ", 2005; Adreevskaia and Bergler, 2006). Several recent studies began exploring more specific and nuanced aspects of sentiment such as connotation (Feng et al., 2013), good and bad effects (Choi and Wiebe, 2014), and evoked sentiment (Mohammad and Turney, 2010). Drawing inspirations from them, we present connotation frames as a unifying representation framework to encode the rich dimensions of implied sentiment, presupposed value judgements, and effect evaluation, and propose a factor graph formulation that captures the interplay among different types of connotation relations. Goyal et al. (2010a; 2010b) investigated how characters (protagonists, villains, victims) in children\u2019s stories are affected by certain predicates, which is related to the effect relations studied in this work. While Klenner et al. (2014) similarly investigated the relation between the polarity of the verbs and arguments, our work introduces new perspective types and proposes a unified representation and inference model.", "startOffset": 8, "endOffset": 822}, {"referenceID": 0, "context": ", 2005; Adreevskaia and Bergler, 2006). Several recent studies began exploring more specific and nuanced aspects of sentiment such as connotation (Feng et al., 2013), good and bad effects (Choi and Wiebe, 2014), and evoked sentiment (Mohammad and Turney, 2010). Drawing inspirations from them, we present connotation frames as a unifying representation framework to encode the rich dimensions of implied sentiment, presupposed value judgements, and effect evaluation, and propose a factor graph formulation that captures the interplay among different types of connotation relations. Goyal et al. (2010a; 2010b) investigated how characters (protagonists, villains, victims) in children\u2019s stories are affected by certain predicates, which is related to the effect relations studied in this work. While Klenner et al. (2014) similarly investigated the relation between the polarity of the verbs and arguments, our work introduces new perspective types and proposes a unified representation and inference model. Wiegand and Ruppenhofer (2015) also looked at perspective-based relationships induced by verb predicates with a focus on opinion roles.", "startOffset": 8, "endOffset": 1039}, {"referenceID": 0, "context": ", 2005; Adreevskaia and Bergler, 2006). Several recent studies began exploring more specific and nuanced aspects of sentiment such as connotation (Feng et al., 2013), good and bad effects (Choi and Wiebe, 2014), and evoked sentiment (Mohammad and Turney, 2010). Drawing inspirations from them, we present connotation frames as a unifying representation framework to encode the rich dimensions of implied sentiment, presupposed value judgements, and effect evaluation, and propose a factor graph formulation that captures the interplay among different types of connotation relations. Goyal et al. (2010a; 2010b) investigated how characters (protagonists, villains, victims) in children\u2019s stories are affected by certain predicates, which is related to the effect relations studied in this work. While Klenner et al. (2014) similarly investigated the relation between the polarity of the verbs and arguments, our work introduces new perspective types and proposes a unified representation and inference model. Wiegand and Ruppenhofer (2015) also looked at perspective-based relationships induced by verb predicates with a focus on opinion roles. Building on this concept, our framework also incorporates information about the perspectives\u2019 polarities as well as information about other typed relations. There have been growing interests for modeling framing (Greene and Resnik, 2009; Hasan and Ng, 2013), biased language (Recasens et al., 2013) and ideology detection (Yano et al., 2010). All these tasks are relatively less studied, and we hope our connotation frame lexicon will be useful for them. Sentiment inference rules have been explored by the recent work of Wiebe and Deng (2014) and Deng and Wiebe (2014).", "startOffset": 8, "endOffset": 1688}, {"referenceID": 0, "context": ", 2005; Adreevskaia and Bergler, 2006). Several recent studies began exploring more specific and nuanced aspects of sentiment such as connotation (Feng et al., 2013), good and bad effects (Choi and Wiebe, 2014), and evoked sentiment (Mohammad and Turney, 2010). Drawing inspirations from them, we present connotation frames as a unifying representation framework to encode the rich dimensions of implied sentiment, presupposed value judgements, and effect evaluation, and propose a factor graph formulation that captures the interplay among different types of connotation relations. Goyal et al. (2010a; 2010b) investigated how characters (protagonists, villains, victims) in children\u2019s stories are affected by certain predicates, which is related to the effect relations studied in this work. While Klenner et al. (2014) similarly investigated the relation between the polarity of the verbs and arguments, our work introduces new perspective types and proposes a unified representation and inference model. Wiegand and Ruppenhofer (2015) also looked at perspective-based relationships induced by verb predicates with a focus on opinion roles. Building on this concept, our framework also incorporates information about the perspectives\u2019 polarities as well as information about other typed relations. There have been growing interests for modeling framing (Greene and Resnik, 2009; Hasan and Ng, 2013), biased language (Recasens et al., 2013) and ideology detection (Yano et al., 2010). All these tasks are relatively less studied, and we hope our connotation frame lexicon will be useful for them. Sentiment inference rules have been explored by the recent work of Wiebe and Deng (2014) and Deng and Wiebe (2014). The focus of their work was on general inference rules that are not predicate-specific.", "startOffset": 8, "endOffset": 1714}], "year": 2016, "abstractText": "Through a particular choice of a predicate (e.g., \u201cx violated y\u201d), a writer can subtly connote a range of implied sentiments and presupposed facts about the entities x and y: (1) writer\u2019s perspective: projecting x as an \u201cantagonist\u201d and y as a \u201cvictim\u201d, (2) entities\u2019 perspective: y probably dislikes x, (3) effect: something bad happened to y, (4) value: y is something valuable, and (5) mental state: y is distressed by the event. We introduce connotation frames as a representation formalism to organize these rich dimensions of connotation using typed relations. First, we investigate the feasibility of obtaining connotative labels through crowdsourcing experiments. We then present models for predicting the connotation frames of verb predicates based on their distributional word representations and the interplay between different types of connotative relations. Empirical results confirm that connotation frames can be induced from various data sources that reflect how people use language and give rise to the connotative meanings. We conclude with analytical results that show the potential use of connotation frames for analyzing subtle biases in online news media.", "creator": "LaTeX with hyperref package"}}}