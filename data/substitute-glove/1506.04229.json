{"id": "1506.04229", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jun-2015", "title": "Evaluation of the Accuracy of the BGLemmatizer", "abstract": "This paper reveals the 2008 some is accuracy thus only accuracy including instance solutions took automatic lemmatization on a Bulgarian language. This lemmatization software is originally indeed began Java well is distributed when making GATE client-server. Certain indicate theories handful used move define the difficulty other given software. The results own set particular show 66% lemmatization durability.", "histories": [["v1", "Sat, 13 Jun 2015 05:53:57 GMT  (219kb)", "http://arxiv.org/abs/1506.04229v1", "5 pages, Sixth International Scientific Conference - FMNS2015"]], "COMMENTS": "5 pages, Sixth International Scientific Conference - FMNS2015", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["elena karashtranova", "grigor iliev", "nadezhda borisova", "yana chankova", "irena atanasova"], "accepted": false, "id": "1506.04229"}, "pdf": {"name": "1506.04229.pdf", "metadata": {"source": "CRF", "title": "Evaluation of the Accuracy of the BGLemmatizer", "authors": ["Elena Karashtranova", "Grigor Iliev", "Nadezhda Borisova", "Yana Chankova", "Irena Atanasova"], "emails": [], "sections": [{"heading": null, "text": "Keywords: Bulgarian grammar, NLP, GATE"}, {"heading": "1. INTRODUCTION", "text": "The entry for \u201clemmatize\u201d in the Collins English Dictionary states that lemmatization is the process of grouping together the different inflected forms of a word so that they can be analyzed as a single term (Collins English Dictionary1). Lemmatization is a fundamental natural language processing (NLP) task which automates the process of word normalization. The correct identification of the normalized form of a word is of significance for NLP tasks such as information extraction and information retrieval. It becomes of particular interest when applied to highly inflectional languages such as Bulgarian, which is a South Slavic language.\nThe total amount of relevant information in a sample is controlled by two factors:\n\u2022 The sampling plan or experimental design which represents the procedure for collecting the information;\n\u2022 The sample size n or the amount of information one collects [4].\nThe corpus we have investigated consists of 273933 tokens [1]. Every token is manually annotated with part-of-speech tags [5]. The aim of our study is to evaluate the lemmatizer\u2019s performance regarding three parts of speech, namely the noun, the adjective and the verb. In order to improve the accuracy of analysis results we have investigated only these parts of speech as a population with size 149061. We have conducted the survey in two stages (i.e. we have examined a two-phase sampling). Our discussion begins with an analysis of the results of a pilot study as such an approach has two\n1 http://www.collinsdictionary.com\nMathematics and Informatics\nadvantages. First, the pilot study will be used to provide estimates of the individual stratum variances and second, the results of the pilot study can be used to estimate the number of observations needed to obtain estimators of the population parameters with a specified level of precision.\nOn the basis of the results obtained from the samples, the traditional evaluation metrics have been applied, namely, Precision, Recall and Fmeasure [2].\nPrecision, as is well-known, measures the number of the items that have been correctly identified as a percentage of the number of the identified items. The higher the Precision is, the better the system is at ensuring what has been identified as being correct.\nRecall measures the number of the items that have been correctly identified as a percentage of the total number of items. The higher the Recall rate is, the better the system is at not missing correct items.\nThe F\u03b2-measure is used together with Precision and Recall, as a weighted average of both Precision and Recall."}, {"heading": "2. SURVEY", "text": "As mentioned above, we have conducted a pilot study, sampling 40 observations from each district, whereby the numbers in the three stratum district are [4]:\nN1=80509 /for the nouns/ N2=23159 /for the adjectives/ N3=45393 /for the verbs/ The numbers n1, n2, n3 have been sampled in the three strata as follows:\n(1) K = \u00b1 \" \u2211 \u00b1 \" # \u00a1p \u2219 K (j=1,2,3), where \u03c3i marks the stratum population standard deviations. The sample stratum standard deviations obtained are \u03c31=0,243, \u03c32=0,352, \u03c33=0,195. By substituting our sample estimates in place of quantities (1), we have found out that: n1=0,534.n; n2=0,224.n; n3=0,242.n We have now specified the proportions of the total sample to be allocated to each stratum under the optimal scheme. By means of (2) we can find the total number of the sample:\n(2) K = p%D\u2211 \u00b1 # \u00a1p \" Gq\u00b1\"&'q+ p% \u2211 \u00b1 \" q\u0327\u00a1p where N=149061 is the total number of the population members and \u03c3)'\nis the variance of the estimator of the population proportion.\nIn order that the 95% confidence interval for the population proportion be achieved we extend the error margin by 0,02 on each side of the sample estimate (\u03c3)' =0,02).\nHence, we can conclude that the needed total number of sample observations is 597.\nGiven that it is easy to make a random sample, the total number of sample observations amounted to 1373. These have then been allocated among the three strata as follows:\nn1=0,534.1373=732 n2=0,224.1373=308 n3=0,242.1373=333\nSince 40 observations have already been sampled in each stratum, the numbers sampled in the second phase are 692, 268, 293 respectively.\nWe have estimated the sample proportion by means of (3):\n(3) #'=\u2211 I .\u00e0 #p\u2211 I #p , where pi marks the proportions of the investigated parameters in each stratum and ni marks the numbers of the sampled stratum [3].\nIn view of Precision we resave * = 0,97 and 95% confidence interval for the population Precision is:\n0,97 \u2013 0,02 < P < 0,97 + 0,02\nConcerning Recall we resave R, = 0,93 and 95% confidence interval for the population Recall is:\n0,93 \u2013 0,02 < R < 0,93 + 0,02\nIn our study the F-measure is used as a weighted average of both Precision and Recall which are considered as equally important, so that: \u00a7 = \u00e4.-*, \u00e4+- =0,95\nSuch results are highly satisfactory and bear out the high accuracy and precision of the developed lemmatizater.\nFor the purpose of the following analyses, we have designed the frequency distribution on the basis of the specific features of each part of speech.\nIn order to achieve greater objectivity of verification of the sample observations, the parts of speech are retrieved with context. The specifics of our study design facilitate the procedure of eliciting extensive information on the structure of the different parts of speech included in the corpus. In view of\nMathematics and Informatics\nthe above, we have built the necessary frequency distributions which are demonstrated in the following tables.\nTable 1. Frequency distribution of the Nouns\nTable 2. Frequency distribution of the Adjectives\nBTB-TS tag Frequency BTB-TS tag Frequency\nN-msi 18667 Amsi 3256 N-msh 4918 Amsh 2062 N-msf 2560 Amsf 1099 N-mpi 5004 Afsi 3287 N-mpd 3136 Afsd 2785 N-mt 1966 Ansi 2074 N-fsi 15816 Ansd 1492 N-fsd 6127 A-pi 4172 N-fpi 4992 A-pd 2811 N-fpd 1836 N-nsi 7398 N-nsd 4288 N-npi 1992\nN-npd 986"}, {"heading": "3. CONCLUSION", "text": "The above frequency distribution tables can be used in performing analysis of the errors and detecting the types of errors in view of their elimination which will contribute to increasing the precision and efficiency of the developed software and enhance the possibilities for its application in different NLP tasks, such as information extraction and information retrieval.\nWe suggest that the samples should be made randomly in keeping with the proportions presented in the frequency distributions. The proposed method of choosing the sample size can be used in performing the estimation procedure for the three cases listed above. The parameters that are to be estimated as well as the standard error margin are determined on the basis of their point estimator."}, {"heading": "4. ACKNOWLEDGEMENTS", "text": "This research was funded by the South-West University \"Neofit Rilski\" grant SRP-A18/15."}, {"heading": "5. REFERENCES", "text": "Iliev, G., et al. A Publicly Available Cross-Platform Lemmatizer for Bulgarian. International Scientific Conference \u2013 SWU, FMNS2015, Blagoevgrad, 10-14.06.2015 Maynard, D., et al. Metrics for Evaluation of Ontology-based Information Extraction, International world wide web conferens, 2006 Newbold, P.,Statistics for Buziness and Economics, Prentice-Hall, USA, 1984 Prodanova, K., Lecture Notices in Statistics, Technical University of Sofia, 2008 Simov, K., Osenova, P., Slavcheva, M. (2004) BTB-TR03: BulTreeBank Morphosyntactic Tagset. BulTreeBank Project Technical Report \u2116 03."}], "references": [{"title": "A Publicly Available Cross-Platform Lemmatizer for Bulgarian. International Scientific Conference \u2013 SWU, FMNS2015, Blagoevgrad", "author": ["G Iliev"], "venue": null, "citeRegEx": "Iliev,? \\Q2006\\E", "shortCiteRegEx": "Iliev", "year": 2006}], "referenceMentions": [], "year": 2015, "abstractText": "This paper reveals the results of an analysis of the accuracy of developed software for automatic lemmatization for the Bulgarian language. This lemmatization software is written entirely in Java and is distributed as a GATE plugin. Certain statistical methods are used to define the accuracy of this software. The results of the analysis show 95% lemmatization accuracy.", "creator": "PDFium"}}}