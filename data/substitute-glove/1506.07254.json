{"id": "1506.07254", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Jun-2015", "title": "Unconfused ultraconservative multiclass algorithms", "abstract": "We stopping through unfortunately significant learning stochastic hdac from spectacle datasets its close multiclass setting. The two - generation re-released of appears be was studied whose few 1989 ago although the proposed theory same combat the brakes dwell around a Per - ceptron perspective scheme slow however complicated such computed eventually place fluctuate percentage such down from second noisy preparation only. We outlined to build so ways techniques and way introduce setting new linear called UMA (only Unconfused Multiclass maltose Algorithm) may cannot. seen have a derivation this the multiclass setting by the early interaction. In should come arise created noise think supposed the evident planar as a self-medication extension of has classification noise studied in where aforemen - tioned sciences. Theoretically only - 1907, UMA cannot displays very feel theoretical breathing robustness, most evidenced by decimal cognitive conducted moving similar synthetic besides real statistics.", "histories": [["v1", "Wed, 24 Jun 2015 06:31:21 GMT  (126kb,D)", "http://arxiv.org/abs/1506.07254v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["ugo louche", "liva ralaivola"], "accepted": false, "id": "1506.07254"}, "pdf": {"name": "1506.07254.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Ugo Louche", "Liva Ralaivola"], "emails": ["ugo.louche@lif.univ-mrs.fr", "liva.ralaivola@lif.univ-mrs.fr"], "sections": [{"heading": null, "text": "Keywords Multiclass classification \u00b7 Perceptron \u00b7 Noisy labels \u00b7 Confusion Matrix \u00b7 Ultraconservative algorithms"}, {"heading": "1 Introduction", "text": "Context. This paper deals with linear multiclass classification problems defined on an input space X (e.g., X = Rd) and a set of classes\nQ .= {1, . . . , Q}.\nIn particular, we are interested in establishing the robustness of ultraconservative additive algorithms [10] to label noise classification in the multiclass setting\u2014in order to lighten notation, we will now refer to these algorithms as ultraconservative\nU. Louche Qarma, Lab. d\u2019Informatique Fondamentale de Marseille, CNRS, Universite\u0301 d\u2019Aix-Marseille E-mail: ugo.louche@lif.univ-mrs.fr\nL. Ralaivola Qarma, Lab. d\u2019Informatique Fondamentale de Marseille, CNRS, Universite\u0301 d\u2019Aix-Marseille E-mail: liva.ralaivola@lif.univ-mrs.fr\nar X\niv :1\n50 6.\n07 25\n4v 1\n[ cs\n.L G\n] 2\n4 Ju\nn 20\n15\nalgorithms. We study whether it is possible to learn a linear predictor from a training set made of independent realizations of a pair (X,Y ) of random variables:\nS .= {(xi, yi)}ni=1\nwhere yi \u2208 Q is a corrupted version of a true label, i.e. deterministically computed class, t(xi) \u2208 Q associated with xi, according to some concept t. The random noise process Y that corrupts the label to provide the yi\u2019s given the xi\u2019s is supposed uniform within each pair of classes, thus it is fully described by a confusion matrix C = (Cpq)p,q \u2208 RQ\u00d7Q so that\n\u2200x, Cpt(x) = PY (Y = p|x).\nThe goal that we would like to achieve is to provide a learning procedure able to deal with the confusion noise present in the training set S to give rise to a classifier h with small risk\nR(h) . = PX\u223cD(h(X) 6= t(X)),\nD being the distribution according to which the xi\u2019s are obtained. As we want to recover from the confusion noise, i.e., we want to achieve low risk on uncorrupted/nonnoisy data, we use the term unconfused to characterize the procedures we propose.\nUltraconservative learning procedures are online learning algorithms that output linear classifiers. They display nice theoretical properties regarding their convergence in the case of linearly separable datasets, provided a sufficient separation margin is guaranteed (as formalized in Assumption 1 below). In turn, these convergence-related properties yield generalization guarantees about the quality of the predictor learned. We build upon these nice convergence properties to show that ultraconservative algorithms are robust to a confusion noise process, provided that: i) C is invertible and can be accessed, ii) the original dataset {(xi, t(xi))}ni=1 is linearly separable. This paper is essentially devoted to proving how/why ultraconservative multiclass algorithms are indeed robust to such situations. To some extent, the results provided in the present contribution may be viewed as a generalization of the contributions on learning binary perceptrons under misclassification noise [6,7].\nBeside the theoretical questions raised by the learning setting considered, we may depict the following example of an actual learning scenario where learning from noisy data is relevant. This learning scenario will be further investigated from an empirical standpoint in the section devoted to numerical simulations (Section 4).\nExample 1 One situation where coping with mislabelled data is required arises in (partially supervised) scenarios where labelling data is very expensive. Imagine a task of text categorization from a training set S = S` \u222aSu, where S` = {(xi, yi)}ni=1 is a set of n labelled training examples and Su = {xn+i}mi=1 is a set of m unlabelled vectors; in order to fall back to realistic training scenarios where more labelled data cannot be acquired, we may assume that n m. A possible three-stage strategy to learn a predictor is as follows: first learn a predictor f` on S` and estimate its confusion error C via a cross-validation procedure\u2014f is assumed to make mistakes evenly over the class regions\u2014, second, use the learned predictor to label all the data in Su to produce the labelled traning set S\u0302 = {(xn+i, tn+i := f(xn+i))}mi=1 and finally, learn a classifier f from S\u0302 and the confusion information C.\nThis introductory example pertains to semi-supervised learning and this is only one possible learning scenario where the contribution we propose, UMA, might be of some use. Still, it is essential to understand right away that one key feature of UMA, which sets it apart from many contributions encountered in the realm of semi-supervised learning, is that we do provide theoretical bounds on the sample complexity and running time required by our algorithm to output an effective predictor.\nThe present paper is an extended version of [21]. Compared with the original paper, it provides a more detailed introduction of the tools used in the paper, a more thorough discussion on related work as well as more extensive numerical results (which confirm the relevance of our findings). A strategy to make use of kernels for nonlinear classification has also been added.\nContributions. Our main contribution is to show that it is both practically and theoretically possible to learn a multiclass classifier on noisy data if some information on the noise process is available. We propose a way to generate new points for which the true class is known. Hence we can iteratively populate a new unconfused dataset to learn from. This allows us to handle a massive amount of mislabelled data with only a very slight loss of accuracy. We embed our method into ultraconservative algorithms and provide a thorough analysis of it, in which we show that the strong theoretical guarantees that characterize the family of ultraconservative algorithms carry over to the noisy scenario.\nRelated Work. Learning from mislabelled data in an iterative manner has a longstanding history in the machine learning community. The first contributions on this topic, based on the Perceptron algorithm [22], are those of [7,6,8], which promoted the idea utilized here that a sample average may be used to construct update vectors relevant to a Perceptron learning procedure. These first contributions were focused on the binary classification case and, for [6,8], tackled the specific problem of strong-polynomiality of the learning procedure in the probably approximately correct (PAC) framework [20]. Later, [27] proposed a binary learning procedure making it possible to learn a kernel Perceptron in a noisy setting; an interesting feature of this work is the recourse to random projections in order to lower the capacity of the class of kernel-based classifiers. Meanwhile, many advances were witnessed in the realm of online multiclass learning procedures. In particular, [10] proposed families of learning procedures subsuming the Perceptron algorithm, dedicated to tackle multiclass prediction problems. A sibling family of algorithms, the passive-aggressive online learning algorithms [9], inspired both by the previous family and the idea of minimizing instantaneous losses, were designed to tackle various problems, among which multiclass linear classification. Sometimes, learning with partially labelled data might be viewed as a problem of learning with corrupted data (if, for example, all the unlabelled data are randomly or arbitrarily labelled) and it makes sense to mention the works [19] and [25] as distant relatives to the present work.\nOrganization of the paper. Section 2 formally states the setting we consider throughout this paper. Section 3 provides the details of our main contribution: the UMA algorithm and its detailed theoretical analysis. Section 4 presents numerical simulations that support the soundness of our approach."}, {"heading": "2 Setting and Problem", "text": "2.1 Noisy Labels with Underlying Linear Concept\nThe probabilistic setting we consider hinges on the existence of two components. On the one hand, we assume an unknown (but fixed) probability distribution D on the input space X .= Rd. On the other hand, we also assume the existence of a deterministic labelling function t : X \u2192 Q, where Q .= {1, . . . Q}, which associates a label t(x) to any input example x; in the Probably Approximately Correct (PAC) literature, t is sometimes referred to as a concept [20,29].\nIn the present paper, we focus on learning linear classifiers, defined as follows.\nDefinition 1 (Linear classifiers) The linear classifier fW : X \u2192 Q is a classifier that is associated with a set of vectors W = [w1 \u00b7 \u00b7 \u00b7wQ] \u2208 Rd\u00d7Q, which predicts the label fW (x) of any vector x \u2208 X as\nfW (x) = argmax q\u2208Q \u3008wq,x\u3009 . (1)\nAdditionally, without loss of generality, we suppose that\nPX\u223cD (\u2016X\u2016 = 1) = 1,\nwhere \u2016\u00b7\u2016 is the Euclidean norm. This allows us to introduce the notion of margin.\nDefinition 2 (Margin of a linear classifier) Let c : S \u2192 Q be some fixed concept. Let W = [w1 \u00b7 \u00b7 \u00b7wQ] \u2208 Rd\u00d7Q be a set of Q weight vectors. Linear classifier fW is said to have margin \u03b8 > 0 with respect to c (and distribution D) if the following holds:\nPX\u223cD { \u2203p 6= c(X) : \u2329 wc(X) \u2212wp, X \u232a \u2264 \u03b8 } = 0.\nNote that if fW has margin \u03b8 > 0 with respect to c then\nPX\u223cD(fW (X) 6= c(X)) = 0.\nEquipped with this definition, we shall consider that the following assumption of linear separability with margin \u03b8 of concept t holds throughout.\nAssumption 1 (Linear Separability of t with Margin \u03b8.) There exist \u03b8 \u2265 0 and W \u2217 = [w\u22171 \u00b7 \u00b7 \u00b7w\u2217Q] \u2208 Rd\u00d7Q, with \u2016W \u2217\u20162F = 1 (\u2016\u00b7\u2016F denotes the Frobenius norm) such that fW\u2217 has margin \u03b8 with respect to the concept t.\nIn a conventional setting, one would be asked to learn a classifier f from a training set\nStrue . = {(xi, t(xi))}ni=1\nmade of n labelled pairs from X \u00d7 Q such that the xi\u2019s are independent realizations of a random variable X distributed according to D, with the objective of minimizing the true risk or misclassification error Rerror(f) of f given by\nRerror(f) . = PX\u223cD(f(X) 6= t(X)). (2)\nIn other words, the objective is for f to have a prediction behavior as close as possible to that of t. As announced in the introduction, there is however a little\ntwist in the problem that we are going to tackle. Instead of having direct access to Strue, we assume that we only have access to a corrupted version\nS .= {(xi, yi)}ni=1 (3)\nwhere each yi is the realization of a random variable Y whose distribution agrees with the following assumption:\nAssumption 2 The law DY |X of Y is the same for all x \u2208 X and its conditional distribution PY\u223cDY |X=x(Y |X = x) is fully summarized into a known confusion matrix C given by\n\u2200x, Cpt(x) . = PY\u223cDY |X=x(Y = p|X = x) = PY\u223cDY |X=x(Y = p|t(x) = q). (4)\nAlternatively put, the noise process that corrupts the data is uniform within each class and its level does not depend on the precise location of x within the region that corresponds to class t(x). The noise process Y is both a) aggressive, as it does not only apply, as we may expect, to regions close to the class boundaries between classes and b) regular, as the mislabelling rate is piecewise constant. Nonetheless, this setting can account for many real-world problems as numerous noisy phenomena can be summarized by a simple confusion matrix. Moreover it has been proved [6] that robustness to classification noise generalizes robustness to monotonic noise where, for each class, the noise rate is a monotonically decreasing function of the distance to the class boundaries.\nRemark 1 The confusion matrix C should not be mistaken with the matrix C\u0303 of general term: C\u0303ij . = PX\u223cDX|Y =j (t(X) = i|Y = j) which is the class-conditional distribution of t(X) given Y . The problem of learning from a noisy training set and C\u0303 is a different problem than the one we aim to solve. In particular, C\u0303 can be used to define cost-sensitive losses rather directly whereas doing so with C is far less obvious. Anyhow, this second problem of learning from C\u0303 is far from trivial and very interesting, and it falls way beyond the scope of the present work.\nFinally, we assume the following from here on:\nAssumption 3 C is invertible.\nNote that this assumption is not as restrictive as it may appear. For instance, if we consider the learning setting depicted in Example 1 and implemented in the numerical simulations, then the confusion matrix obtained from the first predictor f` is often diagonally dominant, i.e. the magnitudes of the diagonal entries are larger than the sum of the magnitudes of the entries in their corresponding rows, and C is therefore invertible. Generally speaking, the problems that we are interested in (i.e. problems where the true classes seems to be recoverable) tend to have invertible confusion matrix. It is most likely that invertibility is merely a sufficient condition on C that allows us to establish learnability in the sequel. Identifying less stringent conditions on C, or conditions termed in a different way\u2014which would for instance be based on the condition number of C\u2014for learnability to remain, is a research issue of its own that we leave for future investigations.\nThe setting we have just presented allows us to view S = {(xi, yi)}ni=1 as the realization of a random sample {(Xi, Yi)}ni=1, where each pair (Xi, Yi) is an independent copy of the random pair (X,Y ) of law DXY . = DXDX|Y .\n2.2 Problem: Learning a Linear Classifier from Noisy Data\nThe problem we address is the learning of a classifier f from S and C so that the error rate\nRerror(f) = PX\u223cD(f(X) 6= t(X))\nof f is as small as possible: the usual goal of learning a classifier f with small risk is preserved, while now the training data is only made of corrupted labelled pairs.\nBuilding on Assumption 1, we may refine our learning objective by restricting ourselves to linear classifiers fW , for W = [w1 \u00b7 \u00b7 \u00b7wQ] \u2208 Rd\u00d7Q (see Definition 1). Our goal is thus to learn a relevant matrix W from S and the confusion matrix C. More precisely, we achieve risk minimization through classic additive methods and the core of this work is focused on computing noise-free update points such that the properties of said methods are unchanged.\n3 Uma: Unconfused Ultraconservative Multiclass Algorithm\nThis section presents the main result of the paper, that is, the UMA procedure, which is a response to the problem posed above: UMA makes it possible to learn a multiclass linear predictor from S and the confusion information C. In addition to the algorithm itself, this section provides theoretical results regarding the convergence and sample complexity of UMA.\nAs UMA is a generalization of the ultraconservative additive online algorithms proposed in [10] to the case of noisy labels, we first and foremost recall the essential features of this family of algorithms. The rest of the section is then devoted to the presentation and analysis of UMA.\n3.1 A Brief Reminder on Ultraconservative Additive Algorithms\nUltraconservative additive online algorithms were introduced by Crammer et al. in [10]. As already stated, these algorithms output multiclass linear predictors fW as in Definition 1 and their purpose is therefore to compute a set W = [w1 \u00b7 \u00b7 \u00b7wQ] \u2208 Rd\u00d7Q of Q weight vectors from some training sample Strue = {(xi, t(xi))}ni=1. To do so, they implement the procedure depicted in Algorithm 1, which centrally revolves around the identification of an error set and its simple update: when processing a training pair (x, y), they perform updates of the form\nwq \u2190 wq + \u03c4qx, q = 1, . . . Q,\nwhenever the error set E(x, y) defined as\nE(x, y) .= {r \u2208 Q\\{y} : \u3008wr,x\u3009 \u2212 \u3008wy,x\u3009 \u2265 0} (5)\nis not empty, with the constraint for the family {\u03c4q}q\u2208Q of step sizes to fulfill\uf8f1\uf8f2\uf8f3 \u03c4y = 1 \u03c4r \u2264 0, if r \u2208 E(x, y) \u03c4r = 0, otherwise and Q\u2211 r=1 \u03c4r = 0. (6)\nAlgorithm 1 Ultraconservative Additive algorithms [10].\nInput: Strue Output: W = [ w1, . . . ,wQ ] and associated classifier fW (\u00b7) = argmax q\u3008wq , \u00b7\u3009\nInitialization: wq \u2190 0, \u2200q \u2208 Q repeat\naccess training pair (xt, yt) compute the error set E(xt, yt) according to (5) if E(xt, yt) 6= \u2205 then\ncompute a set {\u03c4q}q\u2208Q of update steps that comply with (6) perform the updates\nwq \u2190 wq + \u03c4qxq , \u2200q \u2208 Q end if\nuntil some stopping criterion is met\nThe term ultraconservative refers to the fact that only those prototype vectors wr which achieve a larger inner product \u3008wr,x\u3009 than \u3008wy,x\u3009, that is, the vectors that can entail a prediction mistake when decision rule (1) is applied, may be affected by the update procedure. The term additive conveys the fact that the updates consist in modifying the weight vectors wr\u2019s by adding a portion of x to them (which is to be opposed to multiplicative update schemes). Again, as we only consider these additive types of updates in what follows, it will have to be implicitly understood even when not explicitly mentioned.\nOne of the main results regarding ultraconservative algorithms, which we extend in our learning scenario is the following.\nTheorem 1 (Mistake bound for ultraconservative algorithms [10].) Suppose that concept t is in accordance with Assumption 1. The number of mistakes/updates made by one pass over S by any ultraconservative procedure is upper-bounded by 2/\u03b82.\nThis result is essentially a generalization of the well-known Block-Novikoff theorem [5,23], which establishes a mistake bound for the Perceptron algorithm (an ultraconservative algorithm itself).\n3.2 Main Result and High Level Justification\nThis section presents our main contribution, UMA, a theoretically grounded noisetolerant multiclass algorithm depicted in Algorithm 2. UMA learns and outputs a matrix W = [w1 \u00b7 \u00b7 \u00b7wQ] \u2208 Rd\u00d7Q from a noisy training set S to produce the associated linear classifier\nfW (\u00b7) = argmax q \u3008wq, \u00b7\u3009 (7)\nby iteratively updating the wq\u2019s, whilst maintaining \u2211 qwq = 0 throughout the learning process. As a new member of multiclass additive algorithms, we may readily recognize in step 8 through step 10 of Algorithm 2 the generic step sizes {\u03c4q}q\u2208Q promoted by ultraconservative algorithms (see Algorithm 1). An important feature of UMA is that it only uses information provided by S and does not make assumption on the accessibility to the noise-free dataset Strue: the incurred pivotal difference with regular ultraconservative algorithms is that the update points used are now\nAlgorithm 2 UMA: Unconfused Ultraconservative Multiclass Algorithm.\nInput: S = {(xi, yi)}ni=1, confusion matrix C \u2208 RQ\u00d7Q, and \u03b1 > 0 Output: W = [w1, . . . ,wK ] and classifier fW (\u00b7) = argmax q\u3008wq , \u00b7\u3009\n1: wk \u2190 0, \u2200k \u2208 Q 2: repeat 3: select p and q 4: compute set A\u03b1p as\nA\u03b1p \u2190 {x|x \u2208 S, \u3008wp,x\u3009 \u2212 \u3008wk,x\u3009 \u2265 \u03b1, \u2200k 6= p}\n5: for k = 1, . . . , Q, compute \u03b3pk as\n\u03b3pk \u2190 1\nn n\u2211 i=1 I{yi = k}I { xi \u2208 A\u03b1p } x>i , \u2200k \u2208 Q\n6: form \u0393 p \u2208 RQ\u00d7d as \u0393 p \u2190 [ \u03b3p1 \u00b7 \u00b7 \u00b7 \u03b3 p Q ]> ,\n7: compute the update vector zpq according to ([M ]q refers to the qth row of matrix M)\nzpq \u2190 ([C\u22121\u0393 p]q)>,\n8: compute the error set E\u03b1(zpq , q) as\nE\u03b1(zpq , q)\u2190 {r \u2208 Q\\{q} : \u3008wr,zpq\u3009 \u2212 \u3008wq ,zpq\u3009 \u2265 \u03b1}\n9: if E\u03b1(zpq , q) 6= \u2205 then 10: compute some ultraconservative update steps \u03c41, . . . , \u03c4Q such that: \u03c4q = 1\u03c4r \u2264 0, \u2200r \u2208 E\u03b1(zpq , q)\u03c4r = 0, otherwise and Q\u2211 r=1 \u03c4r = 0\n11: perform the updates for r = 1, . . . , Q:\nwr \u2190 wr + \u03c4rzpq 12: end if 13: until \u2016zpq\u2016 is too small\nthe computed (line 4 through line 7) zpq vectors instead of the xi\u2019s. Establishing that under some conditions UMA stops and provides a classifier with small risk when those update points are used is the purpose of the following subsections; we will also discuss the unspecified step 3, dealing with the selection step.\nFor the impatient reader, we may already leak some of the ingredients we use to prove the relevance of our procedure. Theorem 1, which shows the convergence of ultraconservative algorithms, rests on the analysis of the updates made when training examples are misclassified by the current classifier. The conveyed message is therefore that examples that are erred upon are central to the convergence analysis. It turns out that steps 4 through 7 of UMA (cf. Algorithm 2) construct a point zpq that is, with high probabilty, mistaken on. More precisely, the true class\nt(zpq) of zpq is q and it is predicted to be of class p by the current classifier; at the same time, these update vectors are guaranteed to realize a positive margin condition with respect to W \u2217: \u3008w\u2217q ,zpq\u3009 > \u3008w\u2217k,zpq\u3009 for all k 6= q. The ultraconservative feature of the algorithm is carried by step 8 and step 10, which make it possible to update any prototype vector wr with r 6= q having an inner product \u3008wr, zpq\u3009 with zpq larger than \u3008wq, zpq\u3009 (which should be the largest if a correct prediction were made). The reason why we have results \u2018with high probability\u2019 is because the zpq\u2019s are sample-based estimates of update vectors known to be of class q but predicted as being of class p, with p 6= q; computing the accuracy of the sample estimates is one of the important exercises of what follows. A control on the accuracy makes it possible for us to then establish the convergence of the proposed algorithm.\n3.3 With High Probability, zpq is a Mistake with Positive Margin\nHere, we prove that the update vector zpq given in step 7 is, with high probability, a point on which the current classifier errs.\nProposition 1 Let W = [w1 \u00b7 \u00b7 \u00b7wQ] \u2208 Rd\u00d7Q and \u03b1 > 0 be fixed. Let A\u03b1p be defined as in step 4 of Algorithm 2, i.e:\nA\u03b1p . = {x|x \u2208 S, \u3008wp,x\u3009 \u2212 \u3008wk,x\u3009 \u2265 \u03b1, \u2200k 6= p} . (8)\nFor k \u2208 Q, p 6= k, consider the random variable \u03b3pk (\u03b3 p k in step 5 of Algorithm 2 is a realization of this variable, hence the overloading of notation \u03b3pk):\n\u03b3pk . = 1\nn \u2211 i I{Yi = k}I { Xi \u2208 A\u03b1p } X>i .\nThe following holds, for all k \u2208 Q:\nES { \u03b3pk } = E{(Xi,Yi)}ni=1 { \u03b3pk } = Q\u2211 q=1 Ckq\u00b5 p q , (9)\nwhere\n\u00b5pq . = EDX\n{ I{t(X) = q}I { X \u2208 A\u03b1p } X> } . (10)\nProof Let us compute EDXY {I{Y = k}I { X \u2208 A\u03b1p } X>}:\nEDXY {I{Y = k}I { X \u2208 A\u03b1p } X>}\n= \u222b X Q\u2211 q=1 I{q = k}I { x \u2208 A\u03b1p } x>PY (Y = q|X = x)dDX(x)\n= \u222b X I { x \u2208 A\u03b1p } x>PY (Y = k|X = x)dDX(x)\n= \u222b X I { x \u2208 A\u03b1p } x>Ckt(x)dDX(x) (cf. (4))\n= \u222b X Q\u2211 q=1 I{t(x) = q}I { x \u2208 A\u03b1p } x>CkqdDX(x) = Q\u2211 q=1 Ckq \u222b X I{t(x) = q}I { x \u2208 A\u03b1p } x>dDX(x) = Q\u2211 q=1 Ckq\u00b5 p q ,\nwhere the last line comes from the fact that the classes are non-overlapping. The n pairs (Xi, Yi) being identically and independently distributed gives the result. ut\nIntuitively, \u00b5pq must be seen as an example of class p which is erroneously predicted as being of class q. Such an example is precisely what we are looking for to update the current classifier; as expecations cannot be computed, the estimate zpq of \u00b5 p q is used instead of \u00b5 p q .\nProposition 2 Let W = [w1 \u00b7 \u00b7 \u00b7wQ] \u2208 Rd\u00d7Q and \u03b1 \u2265 0 be fixed. For p, q \u2208 Q, p 6= q, zpq \u2208 Rd is such that\nEDXY zpq = \u00b5 p q (11) \u3008w\u2217q , \u00b5pq\u3009 \u2212 \u3008w\u2217k, \u00b5 p q\u3009 \u2265 \u03b8, \u2200k 6= q, (12) \u3008wp, \u00b5pq\u3009 \u2212 \u3008wk, \u00b5pq\u3009 \u2265 \u03b1, \u2200k 6= p. (13)\n(Normally, we should consider the transpose of \u00b5pq , but since we deal with vectors of Rd\u2014and not matrices\u2014we abuse the notation and omit the transpose.) This means that\ni) t(\u00b5pq) = q, i.e. the \u2018true\u2019 class of \u00b5 p q is q;\nii) and fW (\u00b5 p q) = p; \u00b5 p q is therefore misclassified by the current classifier fW .\nProof According to Proposition 1,\nEDXY { \u0393 p } = EDXY   \u03b3p1 ... \u03b3pQ   =  EDXY { \u03b3p1 } ... EDXY { \u03b3pQ }  =  \u2211Q q=1 C1q\u00b5 p 1 ...\u2211Q q=1 CQq\u00b5 p Q  = C  \u00b5p1 ... \u00b5pQ  . Hence, inverting C and extracting the qth of the resulting matrix equality gives that E {zpq} = \u00b5pq . Equation (12) is obtained thanks to Assumption 1 combined with (10) and the linearity of the expectation. Equation (13) is obtained thanks to the definition (8) of A\u03b1p (made of points that are predicted to be of class p) and the linearity of the expectation. ut\nThe attentive reader may notice that Proposition 2 or, equivalently, step 7, is precisely the reason for requiring C to be invertible, as the computation of zpq hinges on the resolution of a system of equations based on C.\nProposition 3 Let \u03b5 > 0 and \u03b4 \u2208 (0; 1]. There exists a number\nn0(\u03b5, \u03b4, d,Q) = O ( 1\n\u03b52\n[ ln 1\n\u03b4 + lnQ+ d ln\n1\n\u03b5 ]) such that if the number of training samples is greater than n0 then, with high probability\n\u3008w\u2217q ,zpq\u3009 \u2212 \u3008w\u2217k,zpq\u3009 \u2265 \u03b8 \u2212 \u03b5 (14) \u3008wp,zpq\u3009 \u2212 \u3008wk,zpq\u3009 \u2265 0, \u2200k 6= p. (15)\nProof The existence of n0 relies on pseudo-dimension arguments. We defer this part of the proof to Appendix A and we will directly assume here that if n \u2265 n0, then, with probability 1\u2212 \u03b4 for any W , zpq.\u2223\u2223\u3008wp \u2212wq,zpq\u3009 \u2212 \u2329wp \u2212wq, \u00b5pq\u232a\u2223\u2223 \u2264 \u03b5. (16) Proving (14) then proceeds by observing that\u2329\nw\u2217q \u2212w\u2217k,zpq \u232a = \u2329 w\u2217q \u2212w\u2217k, \u00b5 p q \u232a + \u2329 w\u2217q \u2212w\u2217k,zpq \u2212 \u00b5 p q \u232a bounding the first part using Proposition 2:\u2329\nw\u2217q \u2212w\u2217k, \u00b5 p q \u232a \u2265 \u03b8\nand the second one with (16). A similar reasoning allows us to get (15) by setting \u03b1 . = \u03b5 in A\u03b1p . ut\nThis last proposition essentially says that the update vectors zpq that we compute are, with high probability, erred upon and realize a margin condition \u03b8 \u2212 \u03b5.\nNote that \u03b1 is needed to cope with the imprecision incurred by the use of empirical estimates. Indeed, we can only approximate \u3008wp,zpq\u3009\u2212 \u3008wk,zpq\u3009 in (15) up to a precision of \u03b5. Thus for the result to hold we need to have \u3008wp, \u00b5pq\u3009 \u2212 \u3008wk, \u00b5 p q\u3009 \u2265 \u03b5 which is obtained from (13) when \u03b1 = \u03b5. In practice, this just says that the points used in the computation of zpq are at a distance at least \u03b1 from any decision boundaries.\nRemark 2 It is important to understand that the parameter \u03b1 helps us derive sample complexity results by allowing us to retrieve a linearly separable training dataset with positive margin from the noisy dataset. The theoretical results we prove hold for any such \u03b1 > 0 parameter and the smaller this parameter, the larger the sample complexity, i.e., the harder it is for the algorithm to take advantage of a training samples that meets the sample complexity requirements. In other words, the smaller \u03b1, the less likely it is for UMA to succeed; yet, as shown in the experiments, where we use \u03b1 = 0, UMA continues to perform quite well.\n3.4 Convergence and Stopping Criterion\nWe arrive at our main result, which provides both convergence and a stopping criterion.\nProposition 4 Under Assumptions 1, 2 and 3 there exists a number n, polynomial in d, 1/\u03b8,Q, 1/\u03b4, such that if the training sample is of size at least n, then, with high probability (1\u2212 \u03b4), UMA makes at most O(1/\u03b82) updates.\nProof Let Sz the set of all the update vectors zpq generated during the execution of UMA and labeled with their true class q. Observe that, in this context, UMA (Alg. 2) behaves like a regular ultraconservative algorithm run on Sz . Namely: a) lines 4 through 7 compute a new point in Sz , and b) lines 8 through 10 perform an ultraconservative update step.\nFrom Proposition 3, we know that with high probability, w\u2217 is a classifier with positive margin \u03b8\u2212 \u03b5 on Sz and it comes from Theorem 1 that UMA does not make more than O(1/\u03b82) mistakes on such dataset.\nBecause, by construction, we have that with high probability each element of Sz is erred upon then |Sz | \u2208 O(1/\u03b82); that means that, with high probability, UMA does not make more than O(1/\u03b82) updates.\nAll in all, after O(1/\u03b82) updates, there is a high probability that we are not able to construct examples on which UMA makes a mistake or, equivalently, the conditional misclassification errors P(fW (X) = p|Y = q) are all small. ut\nEven though UMA operates in a batch setting, it \u2018internally\u2019 simulates the execution of an online algorithm that encounters a new training point (zpq \u2208 Sz) at each time step. To more precisely see how UMA can be seen as an online algorithm, it suffices to imagine it be run in a way where each vector update is made after a chunk of n (where n is as in Proposition 4) training data has been encountered and used to compute the next element of Sz . Repeating this process O(1/\u03b82) times then guarantees convergence with high probability. Note that, in this scenario, UMA requires n\u2032 = O(n/\u03b82) data to converge which might be far more than the sample complexity exhibited in Proposition 4. Nonetheless, n\u2032 still remains polynomial in d, 1/\u03b8, Q and 1/\u03b4. For more detail on this (online to batch conversion) approach, we refer the interested readers to [6].\n3.5 Selecting p and q\nSo far, the question of selecting good pairs of values p and q to perform updates has been left unanswered. Indeed, our results hold for any pair (p, q) and convergence is guaranteed even when p and q are arbitrarily selected as long as zpq is not 0. Nonetheless, it is reasonable to use heuristics for selecting p and q with the hope that it might improve the practical convergence speed.\nOn the one hand, we may focus on the pairs (p, q) for which the empirical misclassification rate\nP\u0302X\u223cS {fW (X) 6= t(X)} . = 1\nn n\u2211 i=1 I { fW (xi) 6= t(xj) } (17)\nis the highest (X \u223c S means that X is randomly drawn from the uniform distribution of law x 7\u2192 n\u22121 \u2211n i=1 I{x = xi} defined with respect to training set S = {(xi, yi)}ni=1). We want to favor those pairs (p, q) because, i) the induced update may lead to a greater reduction of the error and ii) more importantly, because zpq may be more reliable, as A\u03b1p will be bigger.\nOn the other hand, recent advances in the passive aggressive literature [24] have emphasized the importance of minimizing the empirical confusion rate, given for a pair (p, q) by the quantity\nP\u0302X\u223cS {fW (X) = p|t(X) = q} . = 1\nnq n\u2211 i=1 I{t(xi) = q, fW (xi) = p}, (18)\nwhere\nnq . = n\u2211 i=1 I{t(xi) = q}.\nThis approach is especially worthy when dealing with imbalanced classes and one might want to optimize the selection of (p, q) with respect to the confusion rate.\nObviously, since the true labels in the training data cannot be accessed, neither of the quantities defined in (17) and (18) can be computed. Using a result provided in [6], which states that the norm of an update vector computed as zpq directly provides an estimate of (17), we devise two possible strategies for selecting (p, q):\n(p, q)error . = argmax\n(p,q) \u2016zpq\u2016 (19)\n(p, q)conf . = argmax\n(p,q)\n\u2016zpq\u2016 \u03c0\u0302q , (20)\nwhere \u03c0\u0302q is the estimated proportion of examples of true class q in the training sample. In a way similar to the computation of zpq in Algorithm 2, \u03c0\u0302q may be estimated as follows:\n\u03c0\u0302q = 1 n [C\u22121y\u0302]q,\nwhere y\u0302 \u2208 RQ is the vector containing the number of examples from S having noisy labels 1, . . . , Q, respectively.\nThe second selection criterion is intended to normalize the number of errors with respect to the proportions of different classes and aims at being robust to imbalanced data. Our goal here is to provide a way to take into account the class distribution for the selection of (p, q). Note that this might be a first step towards transforming UMA into an algorithm for minimizing the confusion risk, even though additional (and significant) work is required to provably provide UMA with this feature.\nOn a final note, we remark that (p, q)conf requires additional precautions when used: when (p, q)error is implemented, zpq is guaranteed to be the update vector of maximum norm among all possible update vectors, whereas this no longer holds true when (p, q)conf is used and if zpq is close to 0 then there may exist another possibly more informative\u2014from the standpoint of convergence speed\u2014update vector zp\u2032q\u2032 for some (p \u2032, q\u2032) 6= (p, q).\n3.6 UMA and Kernels\nThus far, we have only considered the situation where linear classifiers are learned. There are however many learning problems that cannot be handled effectively without going beyond linear classification. A popular strategy to deal with such a situation is obviously to make use of kernels [26]. In this direction, there are (at least) two paths that can be taken. The first one is to revisit UMA and provide a kernelized algorithm based on a dual representation of the weight vectors, as is done with the kernel Perceptron (see [11]) or its close cousins (see, e.g. [18, 13,17]). Doing so would entail the question of finding sparse expansions of the weight vectors with respect to the training data in order to contain the prediction time and to derive generalization guarantees based on such sparsity: this is an interesting and ambitious research program on its own. A second strategy, which we make use of in the numerical simulations, is simply to build upon the idea of Kernel Projection Machines [4,28]: first, perform a Kernel Principal Component Analysis (shorthanded as kernel-PCA afterwards) with D principal axes, second, project the data onto the principal D-dimensional subspace and, finally, run UMA on the obtained data. The availability of numerous methods to efficiently extract the\nprincipal subspaces (or approximation thereof) [1,15,16,27,30] makes this path a viable strategy to render UMA usable for nonlinearly separable concepts. This explains why we decided to use this strategy in the present paper."}, {"heading": "4 Experiments", "text": "In this section, we present results from numerical simulations of our approach and we discuss different practical aspects of UMA. The ultraconservative step sizes retained are those corresponding to a regular Perceptron: \u03c4p = \u22121 and \u03c4q = +1, the other values of \u03c4r being equal to 0.\nSection 4.1 discusses robustness results, based on simulations conducted on synthetic data while Section 4.2 takes it a step further and evaluates our algorithm on real data, with a realistic noise process related to Example 1 (cf. Section 1).\nWe essentially use what we call the confusion rate as a performance measure, which is :\n1\u221a Q \u2016C\u0302\u2016F\nWhere \u2016C\u0302\u2016F is the Frobenius norm of the confusion matrix C\u0302 computed on a test set Stest (independent from the training set), i.e.:\n\u2016C\u0302\u20162F = \u2211 i,j C\u03022ij , with C\u0302pq . =  0 if p = q,\u2211 xi\u2208Stest I{y\u0302i = p and ti = q}\u2211 xi\u2208Stest I{ti = q} otherwise,\nwith y\u0302i the label predicted for the test instance xi by the learned predictor. C\u0302 is much akin to a recall matrix, and the 1/ \u221a Q factor ensure that the confusion rate is comprised within 0 and 1.\n4.1 Toy dataset\nWe use a 10-class dataset with a total of roughly 1, 000 2-dimensional examples uniformly distributed according to U , which is the uniform distribution over the unit circle centered at the origin. Labelling is achieved according to (1) given a set of 10 weight vectors w1, . . . ,w10, which are also randomly generated according to U ; all these weight vectors have therefore norm 1. A margin \u03b8 = 0.025 is enforced in the generated data by removing examples that are too close to the decision boundaries\u2014practically, with this value of \u03b8, the case where three classes are so close to each other that no training example from one of the classes remained after enforcing the margin never occurred.\nThe learned classifiers are tested against a dataset of 10, 000 points that are distributed according to the training distribution. The results reported in the tables and graphics are averaged over 10 runs.\nThe noise is generated from the sole confusion matrix. This situation can be tough to handle and is rarely met with real data but we stick with it as it is a good example of a worst-case scenario.\nRobustness to noise. We first (Fig. 1(a)) evaluate the robustness to noise of UMA by running our algorithm with various confusion matrices. We uniformly draw a reference nonnegative square matrix M , the rows of M are then normalized, i.e. each entry of M is divided by the sum of the elements of its row, so M is a stochastic matrix. If M is not invertible it is rejected and we draw a new matrix until we have an invertible one. Then, we define N such that N = (M \u2212 I)/10, where I is the identity matrix of order Q; typically N has nonpositive diagonal entries and nonnegative off-diagonal coefficients. We will use N to parametrize a family of confusion matrices that have their most dominant coefficient to move from their diagonal to their off-diagonal parts. Namely, we run UMA 20 times with confusion matrices C \u2208 {Ci . = \u2126(I + iN)}20i=1, where \u2126 is a matrix operator which outputs a (row-)stochastic matrix: when applied on matrix A, \u2126 replaces the negative elements of A by zeros and it normalizes the rows of the obtained matrix; note that i = 10 corresponds to the case where C = M . Equivalently, one can think of Ci as the weighted average between I and \u2126(N) where I has a constant weight of 1 and \u2126(N) is weighted by i. Note that, after some point, further increasing i has little effect on Ci as it eventually converges to \u2126(N). Figure 1(a) plots our results against the Frobenius norm of the diagonal-free confusion matrix C, that is: \u2016C \u2212 diag(C)\u2016F where diag(C) denotes the diagonal matrix with the same diagonal values as C. For the sake of comparison, we also have run UMA with a fixed confusion matrix C = I on the same data. This amounts to running a Perceptron through the data multiple times and it allows us to have a baseline for measuring the improvement induced by the use of the confusion matrix.\nRobustness to the incorrect estimation of the confusion matrix. The second experiment (Fig. 1(b)) evaluates the robustness of UMA to the use of a confusion matrix that is not exactly the confusion matrix that describes the noise process corrupting the data; this will allow us to measure the extent to which a confusion matrix (inaccurately) estimated from the training data can be dealt with by UMA. Using the same notation as before, and the same idea of generating a random stochastic reference matrix M , we proceed as follows: we use the given matrix M to corrupt the noise-free dataset and then, each confusion matrix from the family {Ci}20i=1 is fed to UMA as if it were the confusion matrix governing the noise process. We introduce the notion of approximation factor \u03c1 as \u03c1(i) . = 1 \u2212 i/10, so that \u03c1 takes values in the set {\u22121,\u22120.9, . . . , 0.9}. As reference, the limit case where \u03c1 = 1\u2014that is, i = 0\u2014corresponds to the case where UMA is fed with the identity matrix I, effectively being oblivious of any noise in the training set. More generally, the values of C are being shifted away from the diagonal as \u03c1 decreases, the equilibrium point being \u03c1 = 0 where C is equal to the true confusion matrix M . Consequently, a positive (resp. negative) approximation factor means that the noise is underestimated (resp. overestimated), in the sense that the noise process described by C would corrupt a lower (resp. higher) fraction of labels from each class than the true noise process applied on the training set, and corresponding to M . Figure 1(b) plots the confusion rate against this approximation factor.\nOn Figure 1(a) we observe that UMA clearly provides improvement over the Perceptron algorithm for every noise level tested, as it achieves lower confusion rates. Nonetheless, its performance degrades as the noise level increases, going from a confusion rate of 0.5 for small noise levels\u2014that is, when \u2016C \u2212 diag(C)\u2016F is small\u2014to roughly 2.25 when the noise is the strongest. Comparatively, the Per-\nceptron algorithm follows the same trend, but with higher confusion rate, ranging from 1.7 to 2.75.\nThe second simulation (Fig. 1(b)) points out that, in addition to being robust to the noise process itself, UMA is also robust to underestimated (approximation factor \u03c1 > 0) noise levels, but not to overestimated (approximation factor \u03c1 < 0) noise levels. Unsurprisingly, the best confusion rate corresponds to an approximation factor of 0, which means that UMA is using the true confusion matrix and can achieve a confusion rate as low as 1.8. There is a clear gap between positive and negative approximation factors, the former yielding confusion rates around 2.6 while the latter\u2019s are slightly lower, around 2.15. From these observations, it is clear that the approximation factor has a major influence on the performances of UMA.\n4.2 Real data"}, {"heading": "4.2.1 Experimental Protocol", "text": "In addition to the results on synthetic data, we also perform simulations in a realistic learning scenario. In this section we are going to assume that labelling examples is very expensive and we implement the strategy evoked in Example 1. More precisely, for a given dataset S, proceed as follows:\n1. Ask for a small number m of examples for each of the Q classes. 2. Learn a rough classifier1 g from these Q\u00d7m points. 3. Estimate the confusion C of g on a small labelled subset Sconf of S. 4. Predict the missing labels y of S using g; thus, y is a sequence of noisy labels. 5. Learn the final classifier fUMA from S, y, C and measure its error rate.\n1 For the sake of self-containedness, we use UMA for this task (with C being the identity matrix). Remind that, when used this way, UMA acts as a regular Perceptron algorithm\nOne might wonder why we do not simply sample a very small portion of S in the first step. The reason is that in the case of very uneven classes proportions some of the classes may be missing in this first sampling. This is problematic when estimating C as it leads to a non-invertible confusion matrix. Moreover, the purpose of g is only to provide a baseline for the computation of y, hence tweaking the class (im)balance in this step is not a problem.\nIn order to put our results into perspective, we compare them with results obtained from various algorithms. This allows us to give a precise idea of the benefits and limitations of UMA. Namely, we learn four additional classifiers: fy is a regular Perceptron learned on S labelled with noisy labels y, fconf and ffull are trained with the correctly labelled training sets Sconf and S respectively and, lastly, fS3VM is a classifier produced by a multiclass semi-supervised SVM algorithm (S3VM, [3]) run on S where only the labels of Sconf are provided. The performances achieved by fy and ffull provide bounds for UMA\u2019s error rates: on the one hand, fy corresponds to a worst-case situation, as we simply ignore the confusion matrix and use the regular Perceptron instead\u2014arguably, UMA should perform better than this\u2014; on the other hand, ffull represents the best-case scenario for learning, when all the correct labels are available\u2014the performance of ffull should always top that of UMA (and the performances of other classifiers). The last two classifiers, fconf and fS3VM, provide us with objective comparison measures. They are learned from the same data as UMA but use them differently: fconf is learned from the reduced training set Sconf and fS3VM is output by a semi-supervised learning strategy that infers both fS3VM and the missing labels of S and it totally ignores the predictions y made by g. Note that according to the learning scenario we implement, we assume C to be estimated from raw data. This might not always be the case with real-world problems and C might be easier and/or less expensive to get than raw data; for instance, it might be deduced from expert knowledge on the studied domain. In that case, fconf and fS3VM may suffer from not taking full advantage of the accurate information about the confusion."}, {"heading": "4.2.2 Datasets", "text": "Our simulations are conducted on three different datasets. Each one with different features. For the sake of reproducibility, we used datasets that can be easily found on the UCI Machine learning repository [2]. Moreover, these datasets correspond to tasks for which generating a complete, labelled, training set is typically costly because of the necessity of human supervision and subject to classification noise. The datasets used and their main features are as follows.\nOptical Recognition of Handwritten Digits. This well-known dataset is composed of 8 \u00d7 8 grey-level images of handwritten digits, ranging from 0 to 9. The dataset is composed of 3, 823 images of 64 features for training, and 1, 797 for the test phase. We set m to 10 for this dataset, which means that g is learned from 100 examples only. Sconf is a sampling of 5% of S. The classes are evenly distributed (see Figure 2(a)). We handle the nonlinearity through the use of a Gaussian kernelPCA (see section 3.6) to project the data onto a feature space of dimension 640.\nLetter Recognition. The Letter Recognition dataset is another well-known pattern recognition dataset. The images of the letters are summarized into a vector of\n16 attributes, which correspond to various primitives computed on the raw data. With 20, 000 examples, this dataset is much larger than the previous one. As for the Handwritten Digits dataset, the examples are evenly spread across the 26 classes (see Figure 2(b)). We uniformly select 15, 000 examples for training and the remaining 5, 000 are used for test. We set m to 50 as it seems that smaller values do not yield usable confusion matrices. We again sample 5% of the dataset to form Sconf and use, as before, a Gaussian kernel-based Kernel-PCA to (nonlinearly) expand the dimension of the data to 1, 600.\nReuters. The Reuters dataset is a nearly linearly-separable document categorization dataset of more than 300, 000 instances of nearly 47, 000 features each. For size reasons we restrict ourselves to roughly 15, 000 examples for training, and 15, 000 other for test. It occurs that some classes are so underrepresented that they are flooded by the noise process and/or do not appear in Sconf, which may lead to a non-invertible confusion matrix. We therefore restrict the dataset to the 9 largest classes. One might wonder whether doing so erases class imbalance. This is not the case as, even this way, the least represented class accounts for roughly 500 examples while this number reaches nearly 4, 000 for the most represented one (see Figure 2(c)). Actually, these 9 classes represent more than 70 percent of the dataset, reducing the training and test sets to approximately 11, 000 examples each. We do not use any kernel for this dataset, the data being already near to linearly-separable. Also, we sample Sconf on 5% of the training set and we set m = 20."}, {"heading": "4.2.3 Results", "text": "Table 1 presents the misclassification error rates averaged on 10 runs. Keep in mind that we have not conducted a very thorough optimization of the hyper-parameters as the point here is essentially to compare UMA with the other algorithms. Additionally, we also report the error rates of fS3VM when trained on the kernelized data with all dimensions, that is the kernelized data before we project them onto their D principal components. Because the projection step is indeed unbecessary with S3VM, this will give us insights on the error due to the Kernel-PCA step. Comparing the first and the last columns of Table 1, it appears that UMA always induces a slight performance gain, i.e. a decrease of the misclassification rate, with respect to fy.\nFrom the second and third columns of Table 1, it is clear that the reduced number of examples available to fconf induces a drastic increase in the misclassification rate with respect to ffull which is allowed to use the totality of the dataset during the training phase.\nComparing UMA and fconf in Table 1 (fifth and second columns), we observe that UMA achieves lower misclassification rates on the Handwritten Digits and Letter Recognition datasets but a higher misclassification rate on Reuters. Although this is likely related to the strong class imbalance in the dataset. Indeed, some classes are overly represented, accounting for the vast majority of the whole dataset (see Fig. 2(c)). Because Sconf is uniformly sampled from the main dataset, fconf is trained with a lot of examples from the overrepresented classes and therefore it is very effective, in the sense that it achieves a low misclassification rate, for these overrepresented classes; this, in turn, induces a (global) low misclassification rate, as possibly high misclassification rates on underrepresented classes are countervailed by theirs accounting for a small portion of the data. On the other hand, because of this disparity in class representation, the slightest error in the confusion matrix, granted it involves one of these overrepresented classes, may lead to a significant increase of the misclassification rate. In this regard, UMA is strongly disadvantaged with respect to fconf on the Reuters dataset and it is the cause of the reported results.\nThe error rates for the S3VM and UMA classifiers are close for the Reuters and Handwritten Digits datasets whereas UMA has a clear advantage on the Letter Recognition problem. On the other hand, note that we used the S3VM method in conjunction with a Kernel-PCA for the sake of comparison with UMA in its kernelized form. The last column of Table 1 tends to confirm that this projection strategy increase the error rate of fS3VM. Also, reminds that the value of m does not impact the performances of fS3VM but has a significant effect on UMA, even though UMA never uses these labelled data. For instance, on the Reuters datasets, increasing m from 20 to 70 reduces UMA\u2019s error rate by nearly 0.1 (see the error rates of Fig. 3 (m = 70) when the size of labelled data is close to 550, that is 5% of the whole dataset). Despite our efforts to keep m as small as possible, we could not go under m = 50 for the Letter Recognition dataset without compromising the invertibility of the confusion matrix. The simple fact that an unusually high number of examples are required to simply learn a rough classifier asserts the complexity of this dataset. Moreover, the fact that fy also outperforms fS3VM implies that the labels fed to UMA are already mostly correct, and, according to our working assumptions, this is the most favorable setting for UMA.\nNonetheless, the disparities between UMA and fconf deserve more attention. Indeed, the same data are being used by both algorithms, and one could expect more closeness in the results. To get a better insight on what is occurring, we have reported the evolution of the error rate of these two algorithms with respect to\nthe sampling size of Sconf in Figure 3. We can see that UMA is unaffected by the size of the sample, essentially ignoring the possible errors in the confusion matrix on small samples. This reinforces our previous results showing that UMA is robust to errors in the confusion matrix. On the other hand, with the addition of more samples, the refinement of the confusion matrix does not allow UMA to compete with the value of additional (correctly) labelled data and eventually, when the size of Sconf grows, fconf performs better than UMA. This points towards the idea that the aggregated nature of the confusion matrix incurs some loss of relevant information for the classification task at hand, and that a more accurate estimate of the confusion matrix, as induced by, e.g., the use of larger Sconf, may not compensate for the information provided by additional raw data.\nBuilding on this observation, we go a step further and replicate this experiment for all of the three datasets; only this time we track the performances of fS3VM instead. The results are plotted on Figure 4. For the three datasets, we observe the same behavior as before. Namely, UMA is able to maintain a low error rate even with a very small size of Sconf. On the other hand, UMA does not benefit as much as other methods from a large pool of labelled examples. In this case, UMA quickly stabilizes while, to the contrary, the S3VM method starts at a fairly high error rate and keeps improving as more labelled examples are available.\nBeyond this, it is important to recall that UMA never uses the labels of Sconf (those are only used to estimate the confusion matrix, not the classifier\u2014refer to Section 4.2.1 for the detailed learning protocol). While refining the estimation of C is undoubtedly useful, a direction toward substantial performance gains should revolve around the combination of both this refined estimation of C and the use of the correctly labelled training set Sconf. This is a research subject on its own that we leave for future work.\nAll in all, the reported results advise us to prefer UMA over other available methods when the amount of labelled data is particularly small, in addition, obviously, to the motivating case of the present work where the training data are corrupted and the confusion matrix is known. Also, another interesting finding we get is that even a rough estimation of the confusion matrix is sufficient for UMA to behave well.\nFinally, we investigate the impact of the selection strategy of (p, q) on the convergence speed of UMA (see Section 3.5). We use three variations of UMA with different strategies for selecting (p, q) (error, confusion, and random) and monitor each one along the learning process on the Reuters dataset. The error and confusion strategies are described in Section 3.5 and the random strategy simply selects p and q at random.\nFrom Figure 5, which reports the misclassification rate and the confusion rate along the iterations, we observe that both performance measures evolve similarly, attaining a stable state around the 30th iteration. The best strategy depends on the performance measure used, even though regardless of the performance measure used, we observe that the random selection strategy leads to a predictor that does not achieve the best performance measure (there is always a curve beneath that of the random selection procedure), which shows that it not an optimal selection strategy.\nAs one might expect, the confusion-based strategy performs better than the error-based strategy when the confusion rate is retained as a performance measure, while the converse holds when using the error rate. This observation motivates us to thoroughly study the confusion-based strategy in a near future as being able to propose methods robust to class imbalance is a particularly interesting challenge of multiclass classification.\nThe plateau reached around the 30th iteration may be puzzling, since the studied dataset presents no positive margin and convergence is therefore not guaranteed. One possible explanation for this is to see the Reuters dataset as linearly separable problem corrupted by the effect of a noise process, which we call the intrinsic noise process that has structural features \u2018compatible\u2019 with the classification noise. By this, we mean that there must be features of the intrinsic noise such that, when additional classification noise is added, the resulting noise that characterizes the data is similar to a classification noise, or at least, to a noise that can be naturally handled by UMA. Finding out the family of noise processes that can be combined with the classification noise\u2014or, more generally, the family of noise processes themselves\u2014without hindering the effectiveness of UMA is one research direction that we aim to explore in a near future."}, {"heading": "5 Conclusion", "text": "In this paper, we have proposed a new algorithm, UMA\u2014for Unconfused Multiclass Additive algorithm\u2014to cope with noisy training examples in multiclass linear problems. As its name indicates, it is a learning procedure that extends the (ultraconservative) additive multiclass algorithms proposed by [10]; to handle the noisy datasets, it only requires the information about the confusion matrix that characterizes the mislabelling process. This is, to the best of our knowledge, the first time the confusion matrix is used as a way to handle noisy label in multiclass problems.\nOne of the core ideas behind UMA, namely, the computation of the update vector zpq, is not tied to the additive update scheme. Thus, as long as the assumption of linear separability holds, the very same idea can be used to render a wide variety of algorithms robust to noise by iteratively generating a noise-free training set with the consecutive values of zpq. Although, every computation of a new zpq requires learning a new classifier to start with. This may eventually incur prohibitive computational costs when applied to batch methods (as opposed to online methods) which are designed to process the entirety of the dataset at once. 2\nUMA takes advantage of the online scheme of additive algorithms and avoids this problem completely. Moreover, additive algorithms are designed to directly handle multiclass problem rather than having recourse to a bi-class mapping. The end-results of this are tightened theoretical guarantees and a convergence rate that does not depend of Q, the number of classes. Besides, UMA can be directly used with any additive algorithms, allowing to handle noise with multiple methods without further computational burden.\n2 Nonetheless, from a purely theoretical point of view, UMA makes at most O(1/\u03b82) mistakes (see proposition 4) and computing zpq can be done in O(n) time. Therefore, polynomial batch methods do not suffer much from this as their overall execution time is still polynomial.\nWhile we provide sample complexity analysis, it should be noted that a tighter bound can be derived with specific multiclass tools, such as the Natarajan\u2019s dimension (see [12] for example), which allow to better specify the expressiveness of a multiclass classifier. However, this is not the main focus of this paper and our results are based on simpler tools.\nTo complement this work, we want to investigate a way to properly tackle near-linear problems (such as Reuters). As for now the algorithm already does a very good jobs due to its noise robustness. However more work has to be done to derive a proper way to handle cases where a perfect classifier does not exist. We think there are great avenues for interesting research in this domain with an algorithm like UMA and we are curious to see how this present work may carry over to more general problems.\nAcknowledgments. The authors would like to thank the reviewers for their feedback and invaluable comments. This work is partially supported by the Agence Nationale de la Recherche (ANR), project GRETA 12-BS02-004-01. We would like to thank the anonymous reviewers for their insightful and extremely valuable feedback on earlier versions of this paper."}, {"heading": "A Double sample theorem", "text": "Proof (Proposition 3)\nFor a fixed pair (p, q) \u2208 Y2, we consider the family of functions\nFpq . = {f : f(x) .= \u3008wq \u2212wp, x\u3009 : wp,wq \u2208 Bd}\nwhere Bd is a d-dimensional unit ball. For each f \u2208 Fpq define the corresponding \u201closs\u201d function\nlf (x) . = l(f(x)) . = 2\u2212 f(x).\nStrictly speaking, lf (x) is not a loss as it does not take y into account, nonetheless it does play the same role in the following proof than a regular loss in the regular double-sampling proof. One way to think of it is as the loss of a problem for which we do not care about the observed labels but instead we want to classify points into a predetermined class\u2014in this case q.\nClearly, Fpq is a subspace of affine functions, thus Pdim(Fpq) \u2264 (d+ 1), where Pdim(Fpq) is the pseudo-dimension of Fpq. Additionally, l is Lipschitz in its first\nargument with a Lipschitz factor of L . = 1. Indeed \u2200y, y1, y2,\u2208 Y : |l(y1, y) \u2212 l(y2, y)| = |y1 \u2212 y2|. Let Dpq be any distribution over X \u00d7Y and T \u2208 (X \u00d7Y)m such that T \u223c Dmpq, then define the empirical loss errlT [f ] . = 1m \u2211 xi\u2208T l(xi, yi) and the expected loss errlD[f ] . = ED [l(x, y)]\nThe goal here is to prove that\nPT\u223cDmpq ( sup f\u2208Fpq |errlD[f ]\u2212 err l T [f ]| \u2265 ) \u2208 O (( 8 )(d+1) em 2/128 ) (21)\nProof (Proof of (21)) We start by noting that l(y1, y2) \u2208 [0, 2] and then proceed with a classic 4-step double sampling proof. Namely:\nSymmetrization. We introduce a ghost sample T \u2032 \u2208 (X \u00d7 Y)m, T \u2032 \u223c Dmpq and show that for fbadT such that |err l Dpq [f bad T ]\u2212 err l T [f bad T ]| \u2265 then\nPT \u2032|T (\u2223\u2223\u2223errlT \u2032 [fbadT ]\u2212 errlDpq [fbadT ]\u2223\u2223\u2223 \u2264 2) \u2265 12 ,\nas long as m 2 \u2265 32. It follows that\nP(T,T \u2032)\u223cDmpq\u00d7Dmpq ( sup f\u2208Fpq |errlT [f ]\u2212 err l T \u2032 [f ]| \u2265 2 ) \u2265 PT\u223cDmpq ( |errlT [f bad T ]\u2212 err l Dpq [f bad T ]| \u2265 ) \u00d7 PT \u2032|T\n(\u2223\u2223\u2223errlT \u2032 [fbadT ]\u2212 errlDpq [fbadT ]\u2223\u2223\u2223 \u2264 2) \u2265 1\n2 PT\u223cDmpq\n( |errlT [f bad T ]\u2212 err l Dpq [f bad T ]| \u2265 ) = 1\n2 PT\u223cDmpq ( sup f\u2208Fpq |errlT [f ]\u2212 err l Dpq [f ]| \u2265 ) (By definition of fbadT )\nThus upper bounding the desired probability by\n2\u00d7 P(T,T \u2032)\u223cDmpq\u00d7Dmpq ( sup f\u2208Fpq |errlT [f ]\u2212 err l T \u2032 [f ]| \u2265 2 ) (22)\nSwapping Permutations. Let define \u0393m the set of all permutations that swap one or more elements of T with the corresponding element of T \u2032 (i.e. the ith element of T is swapped with the ith element of T \u2032). It is quite immediate that |\u0393m| = 2m. For each permutation \u03c3 \u2208 \u0393m we note \u03c3(T ) (resp. \u03c3(T \u2032)) the set originating from T (resp. T \u2032) from which the elements have been swapped with T \u2032 (resp. T ) according to \u03c3.\nThanks to \u0393m we will be able to provide an upper bound on (22). Our starting point is that (T, T \u2032) \u223c Dmpq \u00d7 Dmpq then for any \u03c3 \u2208 \u0393m, the random variable supf\u2208Fpq |err l T [f ]\u2212err l T \u2032 [f ]| follows the same distribution as supf\u2208Fpq |err l \u03c3(T )[f ]\u2212 errl\u03c3(T \u2032)[f ]|.\nTherefore:\nP(T,T \u2032)\u223cDmpq\u00d7Dmpq ( sup f\u2208Fpq |errlT [f ]\u2212 err l T \u2032 [f ]| \u2265 2 )\n= 1\n2m \u2211 \u03c3\u2208\u0393m PT,T \u2032\u223cDmpq\u00d7Dmpq ( sup f\u2208Fpq |errl\u03c3(T )[f ]\u2212 err l \u03c3(T \u2032)[f ]| \u2265 2 )\n= E(T,T \u2032)\u223cDmpq\u00d7Dmpq  1 2m \u2211 \u03c3\u2208\u0393m I { sup f\u2208Fpq |errl\u03c3(T )[f ]\u2212 err l \u03c3(T \u2032)[f ]| \u2265 2 } \u2264 sup\n(T,T \u2032)\u2208(X\u00d7Y)2m\n[ P\u03c3\u2208\u0393m ( sup f\u2208Fpq |errl\u03c3(T )[f ]\u2212 err l \u03c3(T \u2032)[f ]| \u2265 2 )] , (23)\nwhich concludes the second step.\nReduction to a finite class. The idea is to reduce Fpq in (23) to a finite class of functions. For the sake of conciseness, we will not enter into the details of the theory of covering numbers. Please refer to the corresponding literature for further details (e.g. [14]).\nIn the following, N ( /8,Fpq, 2m) will denote the uniform /8convering number of Fpq over a sample of size 2m.\nLet define Gpq \u2282 Fpq such that (lGpq )|(T,T \u2032) is an /8-cover of (lFpq )|(T,T \u2032). Thus, |Gpq| \u2264 N ( /8, lFpq , 2m) < \u221e Therefore, if \u2203f \u2208 Fpq such that |errl\u03c3(T )[f ] \u2212 errl\u03c3(T \u2032)[f ]| \u2265 2 then, \u2203g \u2208 Gpq such that |err l \u03c3(T )[g] \u2212 err l \u03c3(T \u2032)[g]| \u2265 4 and the following comes naturally\nP\u03c3\u2208\u0393m ( sup f\u2208Fpq |errl\u03c3(T )[f ]\u2212 err l \u03c3(T \u2032)[f ]| \u2265 2 )\n\u2264 P\u03c3\u2208\u0393m (\nmax g\u2208Gpq\n|errl\u03c3(T )[g]\u2212 err l \u03c3(T \u2032)[g]| \u2265\n4 ) \u2264 N ( /8, lFpq , 2m) max\ng\u2208Gpq P\u03c3\u2208\u0393m\n( |errl\u03c3(T )[g]\u2212 err l \u03c3(T \u2032)[g]| \u2265\n8\n) (union bound)\nHoeffding\u2019s inequality. Finally, consider |errl\u03c3(T )[g] \u2212 err l \u03c3(T \u2032)[g]| as the average of m realizations of the same random variable, with expectation equal to 0. Then by Hoeffding\u2019s inequality we have that3\nP\u03c3\u2208\u0393m ( |errl\u03c3(T )[g]\u2212 err l \u03c3(T \u2032)[g]| \u2265\n4\n) \u2264 2e\u2212m 2/128 (24)\nPutting everything together yields the result w.r.t. N ( /8, lFpq , 2m) for m 2 \u2265 32. For m 2 < 32 it holds trivially.\nRecall that lFpq is Lipschitz in its first argument with a Lipschitz constant L = 1 thus N ( /8, lFpq , 2m) \u2264 N ( /8,Fpq, 2m) = O (( 8 )Pdim(Fpq)) 3 Note that in some references the right-hand side of (24) might viewed as a probability measure over m independent Rademacher variables.\nThe last part of the proof comes from the observation that, for any fixed (p, q), we had never used any other specific information about Fpq other than the upper bound of d+ 1 over its pseudo dimension. In other words, equation (21) holds for slightly modified definition of Fpq as long as the pseudo dimension does not exceed d+ 1.\nLet us now consider :\nF\u0302pq . = {f : f(x) .= I{t(x) = q}I { x \u2208 A\u03b1p } \u3008wp \u2212wq, x\u3009 : wp,wq \u2208 Bd}\nClearly for each function in F\u0302pq there is at most one corresponding affine function, thus F\u0302pq and Fpq share the same upper bound of d+ 1 on their pseudodimension.\nConsequently, any covering number of Fpq is also a covering number of F\u0302pq. More precisely, this proof holds true for any wp and wq, independently of A\u03b1p which may itself be defined with respect to wp and wq.\nIt comes naturally that, fixing S as the training set, the following holds true:\n1\nm \u2211 m I{t(x) = q}I { x \u2208 A\u03b1p } x = zpq.\nThus \u2223\u2223\u2223errlT [f ]\u2212 errlD[f ]\u2223\u2223\u2223 = \u2223\u2223\u2223\u2223\u2329 wp \u2212wq\u2016wp \u2212wq\u2016 ,zpq \u232a \u2212 \u2329 wp \u2212wq \u2016wp \u2212wq\u2016 , \u00b5qp \u232a\u2223\u2223\u2223\u2223 . We can generalize this result for any couple (p, q) by a simple union bound, giving the desired inequality:\nP(X\u00d7Y)\u223cD\n( sup\nW\u2208Rd\u00d7Q\n\u2223\u2223\u2223\u2223\u2329 wp \u2212wq\u2016wp \u2212wq\u2016 ,zpq \u232a \u2212 \u2329 wp \u2212wq \u2016wp \u2212wq\u2016 , \u00b5qp \u232a\u2223\u2223\u2223\u2223 \u2265 )\n\u2264 O ( Q2 ( 8 )(n+1) em 2/128 )\nEquivalently, we have that\u2223\u2223\u2223\u2223\u2329 wp \u2212wq\u2016wp \u2212wq\u2016 ,zpq \u232a \u2212 \u2329 wp \u2212wq \u2016wp \u2212wq\u2016 , \u00b5qp \u232a\u2223\u2223\u2223\u2223 \u2265 with probability 1\u2212 \u03b4 for\nm \u2208 O ( 1\n2\n[ ln ( 1\n\u03b4\n) + ln(Q) + d ln ( 1 )]) ."}], "references": [{"title": "Kernel Independent Component Analysis", "author": ["F.R. Bach", "M.I. Jordan"], "venue": "Journal of Machine Learning Research 3, 1\u201348", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2002}, {"title": "Lichman, M.: UCI machine learning repository", "author": ["K. Bache"], "venue": "URL http://archive. ics.uci.edu/ml", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Semi-supervised support vector machines", "author": ["K.P. Bennett", "A. Demiriz"], "venue": "Advances in Neural Information Processing Systems, pp. 368\u2013374. MIT Press", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1998}, {"title": "Finite-dimensional projection for classification and statistical learning", "author": ["G. Blanchard", "L. Zwald"], "venue": "IEEE Transactions on Information Theory 54(9), 4169\u20134182", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "The perceptron: a model for brain functioning", "author": ["H. Block"], "venue": "Reviews of Modern Physics 34, 123\u2013135", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1962}, {"title": "A Polynomial-Time Algorithm for Learning Noisy Linear Threshold Functions", "author": ["A. Blum", "A.M. Frieze", "R. Kannan", "S. Vempala"], "venue": "Proc. of 37th IEEE Symposium on Foundations of Computer Science, pp. 330\u2013338", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1996}, {"title": "Learning Linear Threshold Functions in the Presence of Classification Noise", "author": ["T. Bylander"], "venue": "Proc. of 7th Annual Workshop on Computational Learning Theory, pp. 340\u2013347. ACM Press, New York, NY, 1994", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1994}, {"title": "Learning Noisy Perceptrons by a Perceptron in Polynomial Time", "author": ["E. Cohen"], "venue": "Proc. of 38th IEEE Symposium on Foundations of Computer Science, pp. 514\u2013523", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1997}, {"title": "Online passiveaggressive algorithms", "author": ["K. Crammer", "O. Dekel", "J. Keshet", "S. Shalev-Shwartz", "Y. Singer"], "venue": "JMLR 7, 551\u2013585", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2006}, {"title": "Ultraconservative online algorithms for multiclass problems", "author": ["K. Crammer", "Y. Singer"], "venue": "Journal of Machine Learning Research 3, 951\u2013991", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2003}, {"title": "An Introduction to Support Vector Machines and other Kernel-Based Learning Methods", "author": ["N. Cristianini", "J. Shawe-Taylor"], "venue": "Cambridge University Press", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2000}, {"title": "Multiclass learnability and the ERM principle", "author": ["A. Daniely", "S. Sabato", "S. Ben-David", "S. Shalev-Shwartz"], "venue": "Journal of Machine Learning Research - Proceedings Track 19, 207\u2013232", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "The forgetron: A kernel-based perceptron on a fixed budget", "author": ["O. Dekel", "S. Shalev-shwartz", "Y. Singer"], "venue": "In Advances in Neural Information Processing Systems 18, pp. 259\u2013266. MIT Press", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2005}, {"title": "A Probabilistic Theory of Pattern Recognition", "author": ["L. Devroye", "L. Gy\u00f6rfi", "G. Lugosi"], "venue": "Springer", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1996}, {"title": "Fast Monte Carlo algorithms for matrices ii: computing a low rank approximation to a matrix", "author": ["P. Drineas", "R. Kannan", "M.W. Mahoney"], "venue": "SIAM Journal on Computing 36(1), 158\u2013183", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "On the Nystr\u00f6m method for approximating a gram matrix for improved kernel-based learning", "author": ["P. Drineas", "M.W. Mahoney"], "venue": "Journal of Machine Learning Research 6(Dec), 2153\u2013 2175", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2005}, {"title": "Large Margin Classification Using the Perceptron Algorithm", "author": ["Y. Freund", "R.E. Schapire"], "venue": "Machine Learning 37(3), 277\u2013296", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1999}, {"title": "The Kernel-Adatron Algorithm: a Fast and Simple Learning Procedure for Support Vector Machines", "author": ["T. Friess", "N. Cristianini", "N. Campbell"], "venue": "J. Shavlik (ed.) Machine Learning: Proc. of the 15th Int. Conf. Morgan Kaufmann Publishers", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1998}, {"title": "Efficient bandit algorithms for online multiclass prediction", "author": ["S.M. Kakade", "S. Shalev-Shwartz", "A. Tewari"], "venue": "Proceedings of the 25th International Conference on Machine Learning, ICML \u201908, pp. 440\u2013447. ACM, New York, NY, USA", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2008}, {"title": "An Introduction to Computational Learning Theory", "author": ["M.J. Kearns", "U.V. Vazirani"], "venue": "MIT Press", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1994}, {"title": "Unconfused ultraconservative multiclass algorithms", "author": ["U. Louche", "L. Ralaivola"], "venue": "JMLR Workshop & Conference Proc. 29, (Proc. of ACML 13), pp. 309\u2013324", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "Perceptrons: an Introduction to Computational Geometry", "author": ["M. Minsky", "S. Papert"], "venue": "MIT Press", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1969}, {"title": "On convergence proofs for perceptrons", "author": ["A. Novikoff"], "venue": "Proc. of the Symposium on the Mathematical Theory of Automata, Vol. 12, pp. 615\u2013622", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1963}, {"title": "Confusion-based online learning and a passive-aggressive scheme", "author": ["L. Ralaivola"], "venue": "NIPS, pp. 3293\u20133301", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2012}, {"title": "Applying multiclass bandit algorithms to call-type classification", "author": ["L. Ralaivola", "B. Favre", "P. Gotab", "F. Bechet", "G. Damnati"], "venue": "ASRU, pp. 431\u2013436", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning with Kernels, Support Vector Machines, Regularization, Optimization and Beyond", "author": ["B. Sch\u00f6lkopf", "A.J. Smola"], "venue": "MIT University Press", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2002}, {"title": "Learning kernel perceptron on noisy data and random projections", "author": ["G. Stempfel", "L. Ralaivola"], "venue": "In Proc. of Algorithmic Learning Theory (ALT 07)", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2007}, {"title": "MKPM: a multiclass extension to the kernel projection machine", "author": ["S. Takerkart", "L. Ralaivola"], "venue": "CVPR, pp. 2785\u20132791", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2011}, {"title": "A theory of the learnable", "author": ["L. Valiant"], "venue": "Communications of the ACM 27, 1134\u20131142", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1984}, {"title": "Using the Nystr\u00f6m Method to Speed Up Kernel Machines", "author": ["C.K.I. Williams", "M. Seeger"], "venue": "Advances in Neural Information Processing Systems 13, pp. 682\u2013688. MIT Press", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2001}], "referenceMentions": [{"referenceID": 9, "context": "In particular, we are interested in establishing the robustness of ultraconservative additive algorithms [10] to label noise classification in the multiclass setting\u2014in order to lighten notation, we will now refer to these algorithms as ultraconservative", "startOffset": 105, "endOffset": 109}, {"referenceID": 5, "context": "To some extent, the results provided in the present contribution may be viewed as a generalization of the contributions on learning binary perceptrons under misclassification noise [6,7].", "startOffset": 181, "endOffset": 186}, {"referenceID": 6, "context": "To some extent, the results provided in the present contribution may be viewed as a generalization of the contributions on learning binary perceptrons under misclassification noise [6,7].", "startOffset": 181, "endOffset": 186}, {"referenceID": 20, "context": "The present paper is an extended version of [21].", "startOffset": 44, "endOffset": 48}, {"referenceID": 21, "context": "The first contributions on this topic, based on the Perceptron algorithm [22], are those of [7,6,8], which promoted the idea utilized here that a sample average may be used to construct update vectors relevant to a Perceptron learning procedure.", "startOffset": 73, "endOffset": 77}, {"referenceID": 6, "context": "The first contributions on this topic, based on the Perceptron algorithm [22], are those of [7,6,8], which promoted the idea utilized here that a sample average may be used to construct update vectors relevant to a Perceptron learning procedure.", "startOffset": 92, "endOffset": 99}, {"referenceID": 5, "context": "The first contributions on this topic, based on the Perceptron algorithm [22], are those of [7,6,8], which promoted the idea utilized here that a sample average may be used to construct update vectors relevant to a Perceptron learning procedure.", "startOffset": 92, "endOffset": 99}, {"referenceID": 7, "context": "The first contributions on this topic, based on the Perceptron algorithm [22], are those of [7,6,8], which promoted the idea utilized here that a sample average may be used to construct update vectors relevant to a Perceptron learning procedure.", "startOffset": 92, "endOffset": 99}, {"referenceID": 5, "context": "These first contributions were focused on the binary classification case and, for [6,8], tackled the specific problem of strong-polynomiality of the learning procedure in the probably approximately correct (PAC) framework [20].", "startOffset": 82, "endOffset": 87}, {"referenceID": 7, "context": "These first contributions were focused on the binary classification case and, for [6,8], tackled the specific problem of strong-polynomiality of the learning procedure in the probably approximately correct (PAC) framework [20].", "startOffset": 82, "endOffset": 87}, {"referenceID": 19, "context": "These first contributions were focused on the binary classification case and, for [6,8], tackled the specific problem of strong-polynomiality of the learning procedure in the probably approximately correct (PAC) framework [20].", "startOffset": 222, "endOffset": 226}, {"referenceID": 26, "context": "Later, [27] proposed a binary learning procedure making it possible to learn a kernel Perceptron in a noisy setting; an interesting feature of this work is the recourse to random projections in order to lower the capacity of the class of kernel-based classifiers.", "startOffset": 7, "endOffset": 11}, {"referenceID": 9, "context": "In particular, [10] proposed families of learning procedures subsuming the Perceptron algorithm, dedicated to tackle multiclass prediction problems.", "startOffset": 15, "endOffset": 19}, {"referenceID": 8, "context": "A sibling family of algorithms, the passive-aggressive online learning algorithms [9], inspired both by the previous family and the idea of minimizing instantaneous losses, were designed to tackle various problems, among which multiclass linear classification.", "startOffset": 82, "endOffset": 85}, {"referenceID": 18, "context": "Sometimes, learning with partially labelled data might be viewed as a problem of learning with corrupted data (if, for example, all the unlabelled data are randomly or arbitrarily labelled) and it makes sense to mention the works [19] and [25] as distant relatives to the present work.", "startOffset": 230, "endOffset": 234}, {"referenceID": 24, "context": "Sometimes, learning with partially labelled data might be viewed as a problem of learning with corrupted data (if, for example, all the unlabelled data are randomly or arbitrarily labelled) and it makes sense to mention the works [19] and [25] as distant relatives to the present work.", "startOffset": 239, "endOffset": 243}, {"referenceID": 19, "context": "Q}, which associates a label t(x) to any input example x; in the Probably Approximately Correct (PAC) literature, t is sometimes referred to as a concept [20,29].", "startOffset": 154, "endOffset": 161}, {"referenceID": 28, "context": "Q}, which associates a label t(x) to any input example x; in the Probably Approximately Correct (PAC) literature, t is sometimes referred to as a concept [20,29].", "startOffset": 154, "endOffset": 161}, {"referenceID": 5, "context": "Moreover it has been proved [6] that robustness to classification noise generalizes robustness to monotonic noise where, for each class, the noise rate is a monotonically decreasing function of the distance to the class boundaries.", "startOffset": 28, "endOffset": 31}, {"referenceID": 9, "context": "As UMA is a generalization of the ultraconservative additive online algorithms proposed in [10] to the case of noisy labels, we first and foremost recall the essential features of this family of algorithms.", "startOffset": 91, "endOffset": 95}, {"referenceID": 9, "context": "in [10].", "startOffset": 3, "endOffset": 7}, {"referenceID": 9, "context": "Algorithm 1 Ultraconservative Additive algorithms [10].", "startOffset": 50, "endOffset": 54}, {"referenceID": 9, "context": "Theorem 1 (Mistake bound for ultraconservative algorithms [10].", "startOffset": 58, "endOffset": 62}, {"referenceID": 4, "context": "This result is essentially a generalization of the well-known Block-Novikoff theorem [5,23], which establishes a mistake bound for the Perceptron algorithm (an ultraconservative algorithm itself).", "startOffset": 85, "endOffset": 91}, {"referenceID": 22, "context": "This result is essentially a generalization of the well-known Block-Novikoff theorem [5,23], which establishes a mistake bound for the Perceptron algorithm (an ultraconservative algorithm itself).", "startOffset": 85, "endOffset": 91}, {"referenceID": 5, "context": "For more detail on this (online to batch conversion) approach, we refer the interested readers to [6].", "startOffset": 98, "endOffset": 101}, {"referenceID": 23, "context": "On the other hand, recent advances in the passive aggressive literature [24] have emphasized the importance of minimizing the empirical confusion rate, given for a pair (p, q) by the quantity", "startOffset": 72, "endOffset": 76}, {"referenceID": 5, "context": "Using a result provided in [6], which states that the norm of an update vector computed as zpq directly provides an estimate of (17), we devise two possible strategies for selecting (p, q):", "startOffset": 27, "endOffset": 30}, {"referenceID": 25, "context": "A popular strategy to deal with such a situation is obviously to make use of kernels [26].", "startOffset": 85, "endOffset": 89}, {"referenceID": 10, "context": "The first one is to revisit UMA and provide a kernelized algorithm based on a dual representation of the weight vectors, as is done with the kernel Perceptron (see [11]) or its close cousins (see, e.", "startOffset": 164, "endOffset": 168}, {"referenceID": 17, "context": "[18, 13,17]).", "startOffset": 0, "endOffset": 11}, {"referenceID": 12, "context": "[18, 13,17]).", "startOffset": 0, "endOffset": 11}, {"referenceID": 16, "context": "[18, 13,17]).", "startOffset": 0, "endOffset": 11}, {"referenceID": 3, "context": "A second strategy, which we make use of in the numerical simulations, is simply to build upon the idea of Kernel Projection Machines [4,28]: first, perform a Kernel Principal Component Analysis (shorthanded as kernel-PCA afterwards) with D principal axes, second, project the data onto the principal D-dimensional subspace and, finally, run UMA on the obtained data.", "startOffset": 133, "endOffset": 139}, {"referenceID": 27, "context": "A second strategy, which we make use of in the numerical simulations, is simply to build upon the idea of Kernel Projection Machines [4,28]: first, perform a Kernel Principal Component Analysis (shorthanded as kernel-PCA afterwards) with D principal axes, second, project the data onto the principal D-dimensional subspace and, finally, run UMA on the obtained data.", "startOffset": 133, "endOffset": 139}, {"referenceID": 0, "context": "principal subspaces (or approximation thereof) [1,15,16,27,30] makes this path a viable strategy to render UMA usable for nonlinearly separable concepts.", "startOffset": 47, "endOffset": 62}, {"referenceID": 14, "context": "principal subspaces (or approximation thereof) [1,15,16,27,30] makes this path a viable strategy to render UMA usable for nonlinearly separable concepts.", "startOffset": 47, "endOffset": 62}, {"referenceID": 15, "context": "principal subspaces (or approximation thereof) [1,15,16,27,30] makes this path a viable strategy to render UMA usable for nonlinearly separable concepts.", "startOffset": 47, "endOffset": 62}, {"referenceID": 26, "context": "principal subspaces (or approximation thereof) [1,15,16,27,30] makes this path a viable strategy to render UMA usable for nonlinearly separable concepts.", "startOffset": 47, "endOffset": 62}, {"referenceID": 29, "context": "principal subspaces (or approximation thereof) [1,15,16,27,30] makes this path a viable strategy to render UMA usable for nonlinearly separable concepts.", "startOffset": 47, "endOffset": 62}, {"referenceID": 2, "context": "Namely, we learn four additional classifiers: fy is a regular Perceptron learned on S labelled with noisy labels y, fconf and ffull are trained with the correctly labelled training sets Sconf and S respectively and, lastly, fS3VM is a classifier produced by a multiclass semi-supervised SVM algorithm (S3VM, [3]) run on S where only the labels of Sconf are provided.", "startOffset": 308, "endOffset": 311}, {"referenceID": 1, "context": "For the sake of reproducibility, we used datasets that can be easily found on the UCI Machine learning repository [2].", "startOffset": 114, "endOffset": 117}, {"referenceID": 9, "context": "As its name indicates, it is a learning procedure that extends the (ultraconservative) additive multiclass algorithms proposed by [10]; to handle the noisy datasets, it only requires the information about the confusion matrix that characterizes the mislabelling process.", "startOffset": 130, "endOffset": 134}, {"referenceID": 11, "context": "While we provide sample complexity analysis, it should be noted that a tighter bound can be derived with specific multiclass tools, such as the Natarajan\u2019s dimension (see [12] for example), which allow to better specify the expressiveness of a multiclass classifier.", "startOffset": 171, "endOffset": 175}], "year": 2015, "abstractText": "We tackle the problem of learning linear classifiers from noisy datasets in a multiclass setting. The two-class version of this problem was studied a few years ago where the proposed approaches to combat the noise revolve around a Perceptron learning scheme fed with peculiar examples computed through a weighted average of points from the noisy training set. We propose to build upon these approaches and we introduce a new algorithm called UMA (for Unconfused Multiclass additive Algorithm) which may be seen as a generalization to the multiclass setting of the previous approaches. In order to characterize the noise we use the confusion matrix as a multiclass extension of the classification noise studied in the aforementioned literature. Theoretically well-founded, UMA furthermore displays very good empirical noise robustness, as evidenced by numerical simulations conducted on both synthetic and real data.", "creator": "LaTeX with hyperref package"}}}