{"id": "1506.08454", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Jun-2015", "title": "WYSIWYE: An Algebra for Expressing Spatial and Textual Rules for Visual Information Extraction", "abstract": "The animation layout by gives webpage typically provide valuable fingerprints for these types many Information Extraction (IE) tasks. In traditional authoritarian based IE frameworks, these layout cues could remapped they rules that operate same only HTML found present the webpages. In critical, something we developed a governance in itself has rules whenever one thereof not at when signage conditions. This fact numerous qualities, since the level low of stylization hopes alone cheaper extraction statutes one directly largely independent although the also allows thus the pages, and, defined, more efficient. It can included extend modifying of current types to limitations although mostly not certain potential. To set best large keep knowledge, and much could department framework that allows profane integrated of link layer rules based on generalized suite. Our framework becomes combining to used text management meant framework and typically a seamless given with function layout related exception with particular text american change. We describe been algebra that enables such a own and. efficient undertake using standard frameworks and text indexing acoustic of turn hierarchical xml. We necessarily to simplicity and accelerating also this requires for that command involving time derived of automated applied additional. database product photos.", "histories": [["v1", "Sun, 28 Jun 2015 21:17:26 GMT  (2863kb,D)", "http://arxiv.org/abs/1506.08454v1", null], ["v2", "Tue, 27 Sep 2016 19:49:41 GMT  (2838kb,D)", "http://arxiv.org/abs/1506.08454v2", null]], "reviews": [], "SUBJECTS": "cs.CL cs.DB cs.IR", "authors": ["vijil chenthamarakshan", "prasad m desphande", "raghu krishnapuram", "ramakrishna varadarajan", "knut stolze"], "accepted": false, "id": "1506.08454"}, "pdf": {"name": "1506.08454.pdf", "metadata": {"source": "CRF", "title": "WYSIWYE\u2217 : An Algebra for Expressing Spatial and Textual Rules for Information Extraction", "authors": ["Vijil Chenthamarakshan", "Prasad .M. Deshpande", "Raghu Krishnapuram", "Ramakrishna Varadarajan", "Knut Stolze"], "emails": ["ecvijil@us.ibm.com", "prasdesh@in.ibm.com", "kraghura@in.ibm.com", "ramkris@cs.wisc.edu", "ramkris@cs.wisc.edu"], "sections": [{"heading": "1 Introduction", "text": "Information in web pages is laid out in a way that aids human perception using specification languages that can be understood by a web browser, such as HTML, CSS, and Javascript. The visual layout of elements in a page contain valuable clues that can be used for extracting information from the page. Indeed, there have been several efforts to use layout information for specific tasks such as web page segmentation [3] and table extraction [6]. There are two ways to use layout information:\n\u2217What You See Is What You Extract \u2020ecvijil@us.ibm.com \u2021prasdesh@in.ibm.com \u00a7kraghura@in.ibm.com \u00b6ramkris@cs.wisc.edu \u2016ramkris@cs.wisc.edu\nar X\niv :1\n50 6.\n08 45\n4v 1\n[ cs\n.C L\n1. Source Based Approach: Map the layout rule to equivalent rules based on the source code (html) of the page. For example, alignment of elements can be achieved in HTML by using a list (<li>) or a table row (<tr>) tag.\n2. Layout Based Approach: Use the layout information (coordinates) of various elements obtained by rendering the page to extract relevant information.\nBoth these approaches achieve the same end result, but the implementations are different as illustrated in the example below.\nExample 1.1 Figure 1 shows the system requirements page for an IBM software product. The IE task is to extract the set of operating systems supported by the product (listed in a column in the table indicated by Q3). In the source based approach, the rules need to identify the table, its rows and columns, the row or column containing the word \u2018Operating Systems\u2019, and finally a list of entities, all based on the tags that can be used to implement them. In the layout based approach, the rule can be stated as: \u2018From each System Requirements page, extract a list of operating system names that appear strictly1\nto the south of the word \u2018Operating Systems\u2019 and are vertically aligned\u2019. The higher level layout based rule is simpler, and is more robust to future changes in these web pages.\nSource based rules have several serious limitations, as listed below:\n\u2022 An abstract visual pattern can be implemented in many different ways by the web designer. For example, a tabular structure can be implemented using any of <table>, <div> and <li> tags. Lerman et al [10] show that only a fraction of tables are implemented using the <table> tag. Source-based rules that use layout cues need to cover all possible ways in which the layout can be achieved. Our experience with large scale IE tasks suggest that rules that depend on HTML\n1See section 3.3 for a definition of strictness\ntags and DOM trees work reasonably well on template based machine\u2013generated pages, but become too complex and brittle to maintain when applied to manually authored web pages.\n\u2022 Proximity of two entities in the HTML source code does not necessarily imply visual proximity [9], and so it may not be possible to encode visual proximity cues using simple source based rules.\n\u2022 Specification languages are becoming more complex and difficult to analyze. Visualization logic is often embedded in CSS and Javascript, making the process of rule writing difficult.\n\u2022 Rules based on HTML tags and DOM trees are often sensitive to even minor modifications of the web page, and rule maintenance becomes messy.\nLayout based approaches overcome these limitations since they are at a higher level and independent of the page source code. Previous efforts at using layout based approaches were targeted at specific tasks such as page segmentation, wrapper extraction, table extraction, etc and are implemented using custom code. Existing rule based information extraction frameworks do not provide a mechanism to express rules based on the visual layout of a page. Our goal is to address this gap by augmenting a rule based information extraction framework to be able to express layout based rules. Rule based system can be either declarative [12, 14] or procedural [1]. It has been shown that expressing information extraction (IE) tasks using an algebra, rather than procedural rules or custom code, enables systematic optimizations making the extraction process very efficient [12, 14]. Hence, we focus on an algebraic information extraction framework described in [12] and extend its algebra with a visual operator algebra that can express rules based on spatial layout cues. One of the challenges is that not all rules can be expressed using layout cues alone. For some rules, it may be necessary to use traditional text\u2013based matching such as regular expressions and dictionaries, and combine them with spatial layout based rules. The framework thus needs to support rules that use both traditional textual matching and high\u2013level spatial layout cues. In summary, our contributions are as follows:\n\u2022 We have developed an algebraic framework for rule\u2013based information extraction that allows us to seamlessly combine traditional text\u2013based rules with high\u2013level rules based on the spatial layout of the page by extending an existing algebra for traditional text based information extraction [12], with a visual operator algebra. We would like to reiterate that our focus is not on developing spatial rules for a specific task, rather we want to develop an algebra using which spatial rules for many different tasks can be expressed.\n\u2022 We implement the system using a relational database and demonstrate how the algebra enables optimizations by systematically mapping the algebra expressions to SQL. Thus, the system can benefit from the indexing and optimization features provided by relational databases.\n\u2022 We demonstrate the simplicity of the visual rules compared to source based rules for the tasks we considered. We also conduct performance studies on a dataset with about 20 million regions and describe our experience with the optimizations using region and text indices."}, {"heading": "2 Related Work", "text": "Information Extraction(IE): IE is a mature area of research that has received widespread attention in the NLP, AI, web and database communities [13]. Both rule based and machine learning based approaches have been proposed and widely used in real life settings. In this paper, we extend the operator algebra of System T [12] to support rules based on spatial layout.\nFrameworks for Information Extraction: The NLP community has developed several software architectures for sharing annotators, such as GATE [4] and UIMA [5]. The motivation is to provide a reusable framework where annotators developed by different providers can be integrated and executed in a workflow.\nVisual Information Extraction: There is a lot of work on using visual information for specific tasks. We list some representative work below. The VIPS algorithm described in [3] segments a DOM tree based on visual cues retrieved from browser\u2019s rendering. The VIPS algorithm complements our work as it can act as a good preprocessing tool performing task-independent page structure analysis before the actual visual extraction takes place - thereby improving extraction accuracy. A top-down approach to segment a web page and detect its content structure by dividing and merging blocks is given in [7]. [8] use visual information to build up a \u201cM-tree\u201d, a concept similar to the DOM tree enhanced with screen coordinates. [6] describe a completely domain-independent method for IE from web tables, using visual information from Mozilla browser. All these approaches are implemented as monolithic programs that are meant for specific tasks. On the other hand, we are not targeting a specific task; rather our framework can be used for different tasks by allowing declarative specification of both textual and visual extraction rules.\nAnother body of work that is somewhat related is automatic and semi-automatic wrapper induction for information extraction [2]. These methods learn the a template expression for extracting information based on some training sets. The wrapper based methods work well on pages that have been generated using a template, but do not work well on human authored pages."}, {"heading": "3 Visual Algebra", "text": ""}, {"heading": "3.1 Overview of Algebraic Information Extraction", "text": "We start with a system proposed by Reiss et al [12] and extend it to support visual extraction rules. First, we give a quick summary of their algebra. For complete details, we request the reader to refer to the original paper."}, {"heading": "Data Model", "text": "A document is considered to be a sequence of characters ignoring its layout and other visual information. The fundamental concept in the algebra is that of a span, an ordered pair \u3008begin, end\u3009 that denotes a region or text within a document identified by its \u201cbegin\u201d and \u201cend\u201d positions. Each annotator finds regions of the document that satisfy a set of rules, and marks each region with an object called a span.\nThe algebra operates over a simple relational data model with three data types: span, tuple, and relation. A tuple is an finite sequence of w spans \u3008s1, ..., sw\u3009; where w is the width of the tuple. A relation is a multiset of tuples, with the constraint that every tuple in the relation must be of the same width. Each operator takes zero or more relations as input and produces a single output relation."}, {"heading": "Operator Algebra", "text": "The set of operators in the algebra can be categorized broadly into relational operators, span extraction operators, and span aggregation operators as shown in Table 1. Relational operators include the standard operators such as select, project, join, union, etc. The span extraction operators identify segments of text that match some pattern and produce spans corresponding to these matches. The two common span extraction operators are the regular expression matcher re and the dictionary matcher d. The regular expression matcher takes a regular expression r, matches it to the input text and outputs spans corresponding to these matches. The dictionary matcher takes a dictionary dict, consisting of a set of words/phrases, matches these to the input text and outputs spans corresponding to each occurence of a dictionary item in the input text.\nspans. The block aggregation operator (\u03b2) identifies spans of text enclosing a minimum number of input spans such that no two consecutive spans are more than a specified distance apart. It is useful in combining a set of consecutive input spans into bigger spans that represent aggregate concepts. The algebra also includes some new selection predicates that apply only to spans as shown in Table 1."}, {"heading": "3.2 Extensions for Visual Information Extraction", "text": "We extend the algebra described in order to support information extraction based on visual rules. In addition to the span, we add two new types in our model \u2013 Region and V isualSpan. A Region represents a visual box in the layout of the page and has the attributes: \u3008xl, yl, xh, yh\u3009. (xl, yl) and (xh, yh) denote the bounding box of the identified region in the visual layout of the document. We assume that the regions are rectangles, which applies to most markup languages such as HTML. A V isualSpan is a combination of a text based span and a visual region with the following attributes: \u3008s, r\u3009, where s is a text span having attributes begin and end as before and r is the region corresponding to the span.\nThe operators are also modified to work with visual spans. The relational operators are unchanged. The span extraction operators are modified to return visual spans rather than spans. For example, the regular expression operator re matches the regular expression r to the input text and for each matching text span s it returns its corresponding visual span. Similarly, the dictionary matcher d outputs visual spans corresponding to occurences of dictionary items in the input text. The behavior of the span aggregation operators (\u2126c and \u2126o) is also affected. Thus containment consolidation \u2126c will discard visual spans whose region and span are both contained in the region and span of some other visual span. Overlap consolidation (\u2126o) aggregates visual spans whose text spans overlap. It produces a new visual span whose text span is the merge of the overlapping text spans and bounding box is the region corresponding to the closest HTML element that contains the merged text span.\nThere are two flavors to the block aggregation operator (\u03b2). The text block operator (\u03b2s) is identical to the earlier \u03b2 operator. It identifies spans of text enclosing a minimum number of input spans such that no two consecutive spans are more than a specified distance apart. The region block operator (\u03b2v) takes as input a X distance x and Y distance y. It finds visual spans whose region contains a minimum number of input visual spans that can be ordered such that the X distance between two consecutive spans is less than x and the Y distance is less than y. The text span of the output visual spans is the actual span of the text corresponding to its region.\nThe predicates described in Table 1 can still be applied to the text span part of the visual spans. To compare the region part of the visual spans, we need many new predicates, which are described in the next section."}, {"heading": "3.3 Visual Operators", "text": "We introduce many new operators in the algebra to enable writing of rules based on visual regions. The operators can be classified as span generating, scalar or grouping operators and a subset has been listed in Table 2. Many of these operators are borrowed from spatial (GIS) databases. For example, the operators Contains, Touches and Intersects are available in a GIS database like DB2 Spatial Extender2. However, to our best knowledge this is the first application of using these constructs for Information Extraction.\n2http://www-01.ibm.com/software/data/spatial/db2spatial/"}, {"heading": "Span Generating Operators", "text": "These operators produce a set of visual spans as output and include the<(d), Ancestors and Descendents operators."}, {"heading": "Scalar Operators", "text": "The scalar operators take as input one or more values from a single tuple and return a single value. Boolean scalar operators can be used in predicates and are further classified as directional or containment operators. The directional operators allow visual spans to be compared based on their positions in the layout. Due to lack of space, we have listed only NorthOf , however we have similar predicates for other directions. Other scalar operators include the generalization/specialization operators and the geometric operators."}, {"heading": "Grouping Operators", "text": "The grouping operators are used to group multiple tuples based on some criteria and apply an aggregation function to each group, similar to the GROUP BY functionality in SQL."}, {"heading": "3.4 Comparison with Source Based Approach", "text": "If visual algebra is not supported, we would have to impelement a given task using only source based rules. The visual algebra is a superset of the existing source based algebra. Expressing a visual rule using existing algebra as a source based rule can be categorized into one of the following cases:\n1. Identical Semantics: Some of the visual operators can be mapped directly into source level rules keeping the semantics intact. For example, the operator V erticallyAligned can be mapped to an expression based on constructs in html that are used for alignment such as <tr>, <li> or <p>, depending on the exact task at hand.\n2. Approximate Semantics: Mapping a visual rule to a source based rule with identical semantics may lead to very complex rules since there are many ways to achieve the same visual layout. It may be possible to get approximately similar results by simplifing the rules if we know that the layout for the pages in the dataset is achieved in one particular way. For example, in a particular template, alignment may always be implemented using rows of a table (the <tr> tag), so the source based rule can cover only this case.\n3. Alternate Semantics: In some cases, it is not possible to obtain even similar semantics from the source based rules. For example, rules based on Area, Centroid, Contains, Touches and Intersects cannot be mapped to source based rules, since it is not possible to check these conditions without actually rendering of the page. In such cases, we have to use alternate source based rules for the same task."}, {"heading": "4 System Architecture and Implementation", "text": "This section describes the architecture and our implementation of the visual extraction system. There are two models typically used for information extraction \u2013 document\nlevel processing, in which rules are applied to one document at a time and collection level processing, in which the rules are matched against the entire document collection at once. The document at a time processing is suitable in the scenario where the document collection is dynamic and new documents are added over time. The collection level processing is useful when the document collection is static and the rules are dynamic, i.e. new rules are being developed on the same collection over time. Previous work has demonstrated an order of magnitude improvement in performance by collection level processing compared to document level processing with the use of indices for evaluating regular expression rules [11]. The visual algebra can be implemented using either a document level processing model or a collection level processing model. We implemented a collection level processing approach using a relational database with extensions for inverted indices on text for efficient query processing. Figure 2 depicts the overall system architecture. Collection level processing has two phases: (a) Preprocessing phase comprising computations that can be done offline and (b) Query phase that includes the online computations done during interactive query time."}, {"heading": "Preprocessing Phase", "text": "In the preprocessing phase, web pages from which information is to be extracted are crawled and a local repository of the web pages is created. Along with the HTML source of the web page, all components that are required to render the page accurately, such as embedded images and stylesheets, should also be downloaded and appropriately linked from the local copy of the page. We use an open source Firefox extension called WebPageDump3 specifically designed for this purpose. Each page is then rendered in a browser and for each node in the DOM tree, its visual region and text is extracted (using the Chickenfoot Firefox extension4) and stored in a relational database (IBM DB2 UDB). We also use the indexing and text search capabilities of DB2 Net Search Extender5 to speed up queries that can benefit from an inverted index.\n3http://www.dbai.tuwien.ac.at/user/pollak/webpagedump/ 4http://groups.csail.mit.edu/uid/chickenfoot/ 5http://www.ibm.com/software/data/db2/extenders/netsearch/"}, {"heading": "Query Phase", "text": "During the interactive query phase, the user expresses the information extraction task as operations in the visual algebra. The visual algebraic operations are then translated to standard SQL queries and executed on the database"}, {"heading": "4.1 Implementing Visual Algebra Queries using a Database", "text": ""}, {"heading": "Schema", "text": "The visual regions computed in the pre-processing stage are stored in table called Regions with the following schema: < Pageid,Regionid,xl, yl, xh, yh, TextStart, TextEnd, Text,HtmlTag,MinimalRegion,MaximalRegion >.\nThe Pageid uniquely identifies a page. The html DOM tree is a hierarchical structure where the higher level nodes comprise lower level nodes. For example, a <td> may be nested inside a <tr> tag, which is nested inside a <table>, and so on. The Regionid uniquely identifies a region in a page annd is a path expression that encodes the path to the corresponding node. This makes it easy to identify the parents and descendants of a region. For example, a node 1.2 indicates a node reached by following the second child of the first child of the root node. The xl, yl, xh, yh denote the coordinates of the region. The Text field stores the text content of the node with TextStart and TextEnd indicating the offsets of the text within the document. The text content of higher level nodes is the union of the text content of all its children. However, to avoid duplication, we associate only the innermost node with the text content while storing in the Regions table. The MinimalRegion and MaximalRegion fields are used to quickly identify a descendant or ancestor that has the identical text content as this node."}, {"heading": "Implementation of Operators", "text": "The visual algebra is implemented using a combination of standard SQL and User Defined Functions (UDFs). Due to space constraints, we mention the mapping of only some representative operators without going into complete detail in Table 3. For simplicity, we have shown the SQL for each operator separately. Applying these rules for a general algebra expression will produce a nested SQL statement that can be flattened out into a single SQL using the regular transformation rules for SQL sub-queries. We also experimented with using a spatial database to implement our algebra, but found that it was not very efficient. Spatial databases can handle complex geometries, but are not optimized for the simple rectangular geometries that the visual regions have. Conditions arising from simple rectangular geometries can be easily mapped to simple conditions on the region coordinate columns in a regular relational database.\nVisual span producing operators: The re and d operators are implemented using UDFs that implement regular expression and dictionary matching respectively. Anscestors(v) and Descendants(v) are implemented using the path expression in the region id of vs. Searching for all prefixes of the Regionid returns the ancestors and searching for all extensions of Regionid returns the descendants.\nSpan aggregation operators: The span aggregation operators (\u2126o, \u2126c and \u03b2v) cannot be easily mapped to existing operators in SQL. We implement these in Java, external to the database.\nOther Visual operators: The scalar visual operators include the directional predicates, containment predicates, generalization/specialization operators and geometric operators. The predicates map to expressions in the WHERE clause. The\ngeneralization/specialization predicates are implemented using the pre-computed values in the columns MinimalRegion and MaximalRegion. The grouping operators map to GROUPBY clause in SQL and the aggregate functions can be mapped to SQL aggregate functions in a straightforward way as shown for HorizontallyAligned and MinimalBoundingRegion."}, {"heading": "Use of Indices", "text": "Indices can be used to speed up the text and region predicates. Instead of the MatchesRegex UDF, we can use the CONTAINS operation provided by the text index. We also build indices on xl, xl, xh, yh columns to speed up visual operators. Once the visual algebra query is mapped to a SQL query, the optimizer performs the task of deciding what indices to use for the query based on cost implications. Example of a mapping is shown in Table 4."}, {"heading": "5 Experiments", "text": "The goal of the experiments is two fold - to demonstrate the simplicity of visual queries and to study the effectiveness of mapping the visual algebra queries to database queries. We describe the visual algebra queries for a representative set of tasks, map them to SQL queries in a database system and study the effect of indexing on the performance."}, {"heading": "5.1 Experimental Setup", "text": "The document corpus for our experiments consists of software product information pages from IBM web site 6. We crawled these pages resulting in a corpus of 44726 pages. Our goal was to extract the system requirements information for these products from their web pages (see Figure 1). Extracting the system requirements is a challenging task since the pages are manually created and don\u2019t have a standard format. This can be broken into sub-tasks that we use as representative queries for our experiments. The queries are listed below. The visual algebra expression and the equivalent SQL query over the spatial database are listed in Table 4. For ease of expression, the visual algebra queries are\n6http://www.ibm.com/software/products/us/en?pgel=lnav\nspecified using a SQL like syntax. The functions RegEx and Dict represent the operators r and d respectively. For each of these sub-tasks, it is possible to write more precise queries. However, our goal here is to show how visual queries can be used for a variety of extraction tasks without focusing too much on the precision and recall of these queries.\n\u2022 Filter the navigational bar at the left edge before extracting the system requirements. Q1: Retrieve vertically aligned regions with more than n regions such that the region bounding the group is contained within a virtual region A(xl, yl, xh, yh). For our domain, we found that a virtual region of A(0,90,500,\u221e) works well.\n\u2022 Identify whether a page is systems requirements page. We use the heuristic that system requirement pages have the term \u201csystem requirements\u201d mentioned near the top of the page. Q2: Retrieve the region in the page containing the term \u2019system requirements\u2019 contained in a region A. In this case, we use a virtual region, A(450,0,\u221e,500)\n\u2022 To identify various operating systems that are supported, the following query can be used. Q3: Find all regions R, such that R contains one of the operating systems mentioned in a dictionary T and are to the strict south or to the strict east of a region containing the term \u201cOperating Systems\u201d.\n\u2022 To find the actual system requirements for a particular operating system, the following query can be used. Q4: Find a region that contains the term \u201cWindows\u201d that occurs to the strict south of a region containing the term \u201cOperating Systems\u201d and extract a region to the strict right of such a region.\nDue to lack of space, we show the visual algebra expression and the equivalent SQL query (Section 4.1) for only query Q4 in Table 4. For ease of expression, the visual algebra queries are specified using a SQL like syntax."}, {"heading": "5.2 Accuracy of Spatial Rules", "text": "We measured the accuracy of our spatial rules using manually annotated data from a subset of pages in our corpus. The test set for Q2 and Q4 consists of 116 manually tagged pages. The test set for Q1 and Q3 contains 3310 regions from 10 pages with 525 positive examples for Q1 and 23 positive examples for Q3. Please note that for Q1 and Q3 we need to manually tag each region in a page. Since there are few hundred regions in a page, we manually tagged only 10 pages. The rules were developed by looking\nat different patterns that occur in a random sample of the entire corpus. The results are reported in Figure 4. Since our tasks were well suited for extraction using spatial rules, we were able to obtain a high level of accuracy using relatively simple rules."}, {"heading": "5.3 Performance", "text": "We measured the performance of these queries on the document collection. Since the queries have selection predicates on the text column and the coordinates (xl, yl, xh, yh), we build indices to speed them up. We also index the text column using DB2 Net search extender. The running time for the queries are shown in Figure 3. We compare various options of using no indices, using only text index and using both text index and indices on the region coordinates. For Q1, the text index does not make a difference since there is no text predicate. The region index leads to big improvement in the time. Q2, Q3 and Q4 have both text and region predicates and thus benefit from the text index as well as the region indices. The benefit of the text index is found to be compartively larger. In all the cases, we can see that using indices leads to a three to fifteen times improvement in the query execution times.\nQuery Q1 Q2 Q3 Q4 Recall 100 96 100 100 Precision 84 85 88 100\nFigure 4: Accuracy"}, {"heading": "6 Discussion", "text": "We have demonstrated an extension to the traditional rule based IE framework that allows the user to specify layout based rules. This framework can be used for many information extraction tasks that require spatial analysis without having to use custom code. The WYSIWYE algebra we propose allows the user to seamlessly combine traditional text based rules with high level rules based on spatial layout. The visual algebra can be systematically mapped to SQL statements, thus enabling optimization by the database. We have evaluated our system in terms of usability and performance for a task of extracting software system requirements from software web pages. The rules expressed using the visual algebra are much simpler than the corresponding source based rules and more robust to changes in the source code. The performance results show that by mapping the queries to SQL and using text and region indexes in the database, we can get significant improvement in the time required to apply the rules.\nLayout based rules are useful for certain types of pages, where the layout information provides cues on the information to extract. A significant source of variation in web pages (different source code, same visual layout) can be addressed by rule based\ninformation extraction systems based on a visual algebra, leading to simpler rules. Visual rules are not always a replacement for the text based rules, rather they are complementary. In our system, we can write rules that combine both text based and layout based rules in one general framework."}], "references": [{"title": "The common pattern specification language", "author": ["D.E. Appelt", "B. Onyshkevych"], "venue": "In Proceedings of a workshop on held at Baltimore, Maryland,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1996}, {"title": "Extracting structured data from web pages", "author": ["A. Arasu", "H. Garcia-Molina"], "venue": "In SIGMOD Conference,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2003}, {"title": "Vips: a vision-based page segmentation algorithm", "author": ["D. Cai", "S. Yu", "J.-R. Wen", "W.-Y. Ma"], "venue": "Technical report, Microsoft Research,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "Gate - a general architecture for text", "author": ["H. Cunningham", "Y. Wilks", "R.J. Gaizauskas"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1996}, {"title": "Uima: an architectural approach to unstructured information processing in the corporate research environment", "author": ["D. Ferrucci", "A. Lally"], "venue": "Nat. Lang. Eng.,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2004}, {"title": "Towards domain-independent information extraction from web tables", "author": ["W. Gatterbauer", "P. Bohunsky", "M. Herzog", "B. Krpl", "B. Pollak"], "venue": "In WWW", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Visual based content understanding towards web adaptation", "author": ["X.-D. Gu", "J. Chen", "W.-Y. Ma", "G.-L. Chen"], "venue": "In AH", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2002}, {"title": "Recognition of common areas in a web page using visual information: a possible application in a page classification", "author": ["M. Kovacevic", "M. Diligenti", "M. Gori", "V. Milutinovic"], "venue": "In ICDM", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2002}, {"title": "Using visual cues for extraction of tabular data from arbitrary html documents", "author": ["B. Krpl", "M. Herzog", "W. Gatterbauer"], "venue": "WWW \u201905,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2005}, {"title": "Using the structure of web sites for automatic segmentation of tables", "author": ["K. Lerman", "L. Getoor", "S. Minton", "C. Knoblock"], "venue": "In SIGMOD", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2004}, {"title": "Entity annotation based on inverse index operations", "author": ["G. Ramakrishnan", "S. Balakrishnan", "S. Joshi"], "venue": "In EMNLP\u2019", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2006}, {"title": "An algebraic approach to rule-based information extraction", "author": ["F. Reiss", "S. Raghavan", "R. Krishnamurthy", "H. Zhu", "S. Vaithyanathan"], "venue": "In ICDE", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "Information extraction", "author": ["S. Sarawagi"], "venue": "FnT Databases,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2008}, {"title": "Declarative information extraction using datalog with embedded extraction predicates", "author": ["W. Shen", "A. Doan", "J.F. Naughton", "R. Ramakrishnan"], "venue": "In VLDB", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}], "referenceMentions": [{"referenceID": 2, "context": "Indeed, there have been several efforts to use layout information for specific tasks such as web page segmentation [3] and table extraction [6].", "startOffset": 115, "endOffset": 118}, {"referenceID": 5, "context": "Indeed, there have been several efforts to use layout information for specific tasks such as web page segmentation [3] and table extraction [6].", "startOffset": 140, "endOffset": 143}, {"referenceID": 9, "context": "Lerman et al [10] show that only a fraction of tables are implemented using the <table> tag.", "startOffset": 13, "endOffset": 17}, {"referenceID": 8, "context": "\u2022 Proximity of two entities in the HTML source code does not necessarily imply visual proximity [9], and so it may not be possible to encode visual proximity cues using simple source based rules.", "startOffset": 96, "endOffset": 99}, {"referenceID": 11, "context": "Rule based system can be either declarative [12, 14] or procedural [1].", "startOffset": 44, "endOffset": 52}, {"referenceID": 13, "context": "Rule based system can be either declarative [12, 14] or procedural [1].", "startOffset": 44, "endOffset": 52}, {"referenceID": 0, "context": "Rule based system can be either declarative [12, 14] or procedural [1].", "startOffset": 67, "endOffset": 70}, {"referenceID": 11, "context": "It has been shown that expressing information extraction (IE) tasks using an algebra, rather than procedural rules or custom code, enables systematic optimizations making the extraction process very efficient [12, 14].", "startOffset": 209, "endOffset": 217}, {"referenceID": 13, "context": "It has been shown that expressing information extraction (IE) tasks using an algebra, rather than procedural rules or custom code, enables systematic optimizations making the extraction process very efficient [12, 14].", "startOffset": 209, "endOffset": 217}, {"referenceID": 11, "context": "Hence, we focus on an algebraic information extraction framework described in [12] and extend its algebra with a visual operator algebra that can express rules based on spatial layout cues.", "startOffset": 78, "endOffset": 82}, {"referenceID": 11, "context": "\u2022 We have developed an algebraic framework for rule\u2013based information extraction that allows us to seamlessly combine traditional text\u2013based rules with high\u2013level rules based on the spatial layout of the page by extending an existing algebra for traditional text based information extraction [12], with a visual operator algebra.", "startOffset": 292, "endOffset": 296}, {"referenceID": 12, "context": "Information Extraction(IE): IE is a mature area of research that has received widespread attention in the NLP, AI, web and database communities [13].", "startOffset": 144, "endOffset": 148}, {"referenceID": 11, "context": "In this paper, we extend the operator algebra of System T [12] to support rules based on spatial layout.", "startOffset": 58, "endOffset": 62}, {"referenceID": 3, "context": "Frameworks for Information Extraction: The NLP community has developed several software architectures for sharing annotators, such as GATE [4] and UIMA [5].", "startOffset": 139, "endOffset": 142}, {"referenceID": 4, "context": "Frameworks for Information Extraction: The NLP community has developed several software architectures for sharing annotators, such as GATE [4] and UIMA [5].", "startOffset": 152, "endOffset": 155}, {"referenceID": 2, "context": "The VIPS algorithm described in [3] segments a DOM tree based on visual cues retrieved from browser\u2019s rendering.", "startOffset": 32, "endOffset": 35}, {"referenceID": 6, "context": "A top-down approach to segment a web page and detect its content structure by dividing and merging blocks is given in [7].", "startOffset": 118, "endOffset": 121}, {"referenceID": 7, "context": "[8] use visual information to build up a \u201cM-tree\u201d, a concept similar to the DOM tree enhanced with screen coordinates.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] describe a completely domain-independent method for IE from web tables, using visual information from Mozilla browser.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "Another body of work that is somewhat related is automatic and semi-automatic wrapper induction for information extraction [2].", "startOffset": 123, "endOffset": 126}, {"referenceID": 11, "context": "We start with a system proposed by Reiss et al [12] and extend it to support visual extraction rules.", "startOffset": 47, "endOffset": 51}, {"referenceID": 10, "context": "Previous work has demonstrated an order of magnitude improvement in performance by collection level processing compared to document level processing with the use of indices for evaluating regular expression rules [11].", "startOffset": 213, "endOffset": 217}], "year": 2017, "abstractText": "The visual layout of a webpage can provide valuable clues for certain types of Information Extraction (IE) tasks. In traditional rule based IE frameworks, these layout cues are mapped to rules that operate on the HTML source of the webpages. In contrast, we have developed a framework in which the rules can be specified directly at the layout level. This has many advantages, since the higher level of abstraction leads to simpler extraction rules that are largely independent of the source code of the page, and, therefore, more robust. It can also enable specification of new types of rules that are not otherwise possible. To the best of our knowledge, there is no general framework that allows declarative specification of information extraction rules based on spatial layout. Our framework is complementary to traditional text based rules framework and allows a seamless combination of spatial layout based rules with traditional text based rules. We describe the algebra that enables such a system and its efficient implementation using standard relational and text indexing features of a relational database. We demonstrate the simplicity and efficiency of this system for a task involving the extraction of software system requirements from software product pages.", "creator": "LaTeX with hyperref package"}}}