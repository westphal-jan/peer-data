{"id": "1508.05804", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Aug-2015", "title": "A note on the complexity of the causal ordering problem", "abstract": "In making materials would quality single 725-word experts since following arises still instead etiology ordering this, once model before Simon although yet yet tangential leadership expression following contexts models. We show probably Simon ' l incorporating non-linear either suppose geometry barring whose NP - Hard - - - has truth-value due answered first Nayak there them always proven. We directly briefly into presentation share based recently Nayak ' comes referring quantifying fails (brought best access ), which whose minority addition web predicates settlement - - - alignment last time the $ O (| \\ mathcal S | ^ 18) $, now $ \\ mathcal S (\\ mathcal E, \\ mathcal V) $ always the user requires underlying choir of a come $ \\ mathcal E $ now formula_7 five a set $ \\ mathcal V $ according formula_20 with flux $ | \\ mathcal S | $. We given anonymity last came potential among generalized execute be economies technologies over large - scale hypothesis management together predictive sustainability.", "histories": [["v1", "Mon, 24 Aug 2015 13:56:32 GMT  (31kb)", "http://arxiv.org/abs/1508.05804v1", "17 pages, 4 figures"], ["v2", "Mon, 13 Jun 2016 02:54:54 GMT  (48kb)", "http://arxiv.org/abs/1508.05804v2", "25 pages, 4 figures"]], "COMMENTS": "17 pages, 4 figures", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["bernardo gon\\c{c}alves", "fabio porto"], "accepted": false, "id": "1508.05804"}, "pdf": {"name": "1508.05804.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["bgonc@lncc.br", "fporto@lncc.br"], "sections": [{"heading": null, "text": "ar X\niv :1\n50 8.\n05 80\n4v 1\n[ cs\n.A I]\n2 4\nA ug\nIn this paper we provide a concise report on the complexity of the causal ordering problem, originally introduced by Simon to reason about causal relations implicit in mathematical models. We show that Simon\u2019s classical algorithm to infer causal ordering is NP-Hard\u2014an intractability previously guessed by Nayak but not yet proven. We present then a detailed account based on Nayak\u2019s suggested algorithmic solution (the best available), which is dominated by computing transitive closure\u2014bounded in time by O(|S|3), where S(E ,V) is the input system structure composed of a set E of equations over a set V of variables with density |S|. We also comment on the potential of causal ordering for emerging applications in large-scale hypothesis management and predictive analytics.\nKeywords: Causal reasoning, Structural equations, Hypothesis management."}, {"heading": "1. Introduction", "text": "The causal ordering problem has long been introduced by Simon as a technique to infer the causal orientations implicit in a deterministic mathematical model [1]. Simon was motivated by studies in econometrics, and not very concerned with the algorithmic aspects of his vision\u2014which turned out to be quite influential in the artificial intelligence literature (cf. survey [3]).\nIn a recent study, Dash and Druzdzel revisit the problem and motivate it in light of modern applications [3]. They show that Simon\u2019s causal ordering algorithm (COA) is correct in the sense that any valid causal ordering extracted from a self-contained (well-posed) system of equations must be\nEmail addresses: bgonc@lncc.br (Bernardo Gonc\u0327alves), fporto@lncc.br (Fabio Porto)\nPreprint submitted to Artificial Intelligence August 25, 2015\ncompatible with the causal ordering output by Simon\u2019s COA [3]. Their aim has also been (sic.) to validate decades of research that has shown COA to be a powerful tool for operating on causal models. In addition to the result on the correctness of COA, their note also provides a convenient survey of related work that connects to Simon\u2019s early vision on causal reasoning.\nThere is a need, though, to distinguish COA from the causal ordering problem (COP) itself. Simon\u2019s COA still seems to be the main entry point to COP in the specialized literature. Yet there is no review on the computational properties of COA, which as we show in this note turns out to be NP-Hard. The interested reader who needs an efficient algorithmic approach to address COP in a real, large-scale application can only scarcely find some comments spread through Nayak [4, p. 287-91], and then Iwasaki and Simon [5, p. 149] and Pearl [2, p. 226] both pointing to the former. In fact Nayak only suggests in words (sic.) that it is a worst-case exponential time algorithm [12, p. 37].\nCOP is significant also in view of emerging applications in large-scale hypothesis management and predictive analytics [6]. The modeling of physical and socio-economical systems as a set of mathematical equations is a traditional approach in science and engineering and a very large bulk of models exist which are ever more available in machine-readable format. Simon\u2019s early vision on the automatic extraction of the causal mechanisms implicit in (large-scale) models for the sake of informed intervention finds nowadays new applications in the context of open simulation laboratories [7], large-scale model management [8] and online, shared model repositories [9, 10, 11].\nThe contributions of this paper are (\u00a72) to originally show that COA is in fact NP-Hard, confirming Nayak\u2019s earlier intuition; and then (\u00a73) to organize into a concise note his hints on a polynomial-time algorithm for COP.\n1.1. Informal Preliminaries\nGiven a system of mathematical equations involving a set of variables, to build a structural equation model (SEM) is, essentially, to establish a one-toone mapping between equations and variables [1]. That shall enable further detecting the hidden asymmetry between variables, i.e., their causal ordering. For instance, Einstein\u2019s famous equation E = mc2 states the equivalence of mass and energy, summarizing (in its scalar version) a theory that can be imposed two different asymmetries for different applications. Say, given a fixed amount of mass m = m0 (and recalling that c is a constant), predict\nthe particle\u2019s relativistic rest energy E; or given the particle\u2019s rest energy, predict its mass or potential for nuclear fission.\nFor really large systems, having structures say in the order of one million equations [13], the causal ordering problem is critical to provide more specific accountability on the predictive accuracy of a large-scale system\u2014which specific variables and subsystems account for possible inaccurate predictions (?). That is key for managing the uncertainty of alternative modeling variations systematically [7, 13].\n1.2. Related Work\nCOA. As mentioned, Dash and Druzdzel provide a formal description of how Simon\u2019s COA gives a summary of the causal dependencies implicit in a given SEM. That is, in clustering the strongly coupled variables into a causal graph, COA provides a condensed representation of the causal model implicit in the given SEM. They show then that any valid total causal mapping produced for a given SEM must be consistent with COA\u2019s partial causal mapping. They leave open, though, any observation regarding COA\u2019s computational properties. In this note we supplement their work in that sense.\nCOP. Inspired by Serrano and Gossard\u2019s work on constraint modeling and reasoning [14], Nayak describes in words an approach that is provably quite effective to process the causal ordering: extract a total causal mapping and then compute the transitive closure of the direct causal dependencies. We shall arrange his insights into a succinct description shortly."}, {"heading": "2. The Complexity of Causal Ordering", "text": "2.1. Notation and Basic Concepts\nDef. 1. A structure is a pair S(E ,V), where E is a set of equations over set V of variables, |E| \u2264 |V|, such that:\n(a) In any subset of k equations of the structure, at least k different variables appear;\n(b) In any subset of k equations in which r variables appear, k \u2264 r, if the values of any (r\u2212k) variables are chosen arbitrarily, then the values of the remaining k variables can be determined uniquely \u2014 finding these unique values is a matter of solving the equations.\nDef. 2. Let S(E ,V) be a structure. We say that S is self-contained or complete if |E| = |V|.\nIn short, the COP is concerned with systems of equations that are \u2018structural\u2019 (Def. 1) and \u2018complete\u2019 (Def. 2), viz., that has as many equations as variables and no subset of equations has fewer variables than equations.1\nDef. 3. Let S be a structure. We say that S is minimal if it is complete and there is no complete proper substructure S \u2032\u2282 S.\nExample 1. Consider structure S(E ,V), where E={ f1(x1), f2(x2), f3(x3), f4(x1, x2, x3, x4, x5), f5(x1, x3, x4, x5), f6(x4, x6), f7(x5, x7) }. Note that S is complete, as |E|= |V|=7, but not minimal. There are exactly three minimal substructures S1,S2,S3 \u2282 S, whose sets of equations are E1={f1(x1)}, E2= {f2(x2)}, E3={f3(x3)}.\nWe are now in a position to begin our study of COA and its complexity.\n2.2. Simon\u2019s Causal Ordering Algorithm\nSimon\u2019s COA is based on a data structure which is introduced in Def. 4.\nDef. 4. The structure matrix AS of a structure S(E ,V), with f1, f2, ..., fn \u2208 E and x1, x2, ..., xm \u2208 V, is a n\u00d7m matrix of 1\u2019s and 0\u2019s in which entry aij is non-zero if variable xj appears in equation fi, and zero otherwise.\nElementary row operations (e.g., row multiplication by a constant) on the structure matrix may hinder the structure\u2019s causal ordering and then are not valid in general [1]. This also emphasizes that the problem of causal ordering is not about solving the system of mathematical equations of a structure, but identifying its hidden asymmetries.\nExample 1. (continued). Fig. 1a shows the matrix of the structure S given above in this example. By eliminating the variables identified with the minimal substructures S1,S2,S3 \u2282 S, a smaller structure T \u2282 S is derived to be input at the next recursive step (see Fig. 1b). This is the main insight of Simon to arrive at his recursive algorithm COA we introduce next.\nDef. 5. Let S(E ,V) be a complete structure.Then a total causal mapping over S is a bijection \u03d5 : E \u2192 V such that, for all f \u2208 E , if \u03d5(f) = x then x\u2208 V ars(f).\nThe algorithm Simon has informally described in [1] is given a complete structure S(E ,V) and computes a partial causal mapping \u03d5p from partitions on the set of equations to same-cardinality partitions on the set of variables. The causal mapping returned by Simon\u2019s COA is not total when S has variables that are strongly coupled (because they can only be determined simultaneously), but any total mapping \u03d5 over S must be consistent with COA\u2019s partial mapping \u03d5p [3]. The latter may be made partial by design (merge strongly coupled variables into partitions or clusters) in order to force its induced causal graph G\u03d5p to be acyclic. Algorithm 1, COA, is a variant of Simon\u2019s COA that returns a total causal mapping \u03d5 instead of a partial causal mapping.2 We illustrate it through Example 1 and Fig. 1.\nExample 1. (continued). Let T \u2282 S be the structure returned by COA\u2019s first\n1Also, for inferring causal ordering the systems of equations given as input is expected to be \u2018independent\u2019 in the sense of Linear Algebra (can only have non-redundant equations).\n2This difference, though, only takes place in lines 7\u201310 in Algorithm 1 and is irrelevant to COA intractability, which is due to line 3.\nAlgorithm 1 COA, a slight variant of Simon\u2019s original algorithm.\n1: procedure COA(S : structure over E and V) Require: S given is complete, i.e., |E| = |V| Ensure: Returns total causal mapping \u03d5 : E \u2192 V 2: \u03d5 \u2190 \u2205, Sk \u2190 \u2205 3: identify all minimal substructures S \u2032 \u2286 S 4: for all S \u2032 \u2286 S do 5: Sk \u2190 Sk \u222a S \u2032 \u22b2 stores each minimal substructure scanned 6: V \u2032 \u2190 \u2205 7: for all f \u2208 S \u2032(E) do 8: x \u2190 any xa such that xa \u2208 V ars(f) and xa /\u2208 V \u2032 9: \u03d5 \u2190 \u03d5 \u222a \u3008f, x\u3009 \u22b2 maps to f some variable x \u2208 V ars(f) 10: V \u2032 \u2190 V \u2032 \u222a {x} 11: T \u2190 S \\ \u22c3\nS\u2032\u2208Sk S \u2032\n12: if T 6= \u2205 then 13: return \u03d5 \u222a COAt(T ) 14: return \u03d5\nrecursive step k = 0 for this example. Then a valid total causal mapping that can be returned at k = 1 is COA(T ) = {\u3008f4, x4\u3009, \u3008f5, x5\u3009, \u3008f6, x6\u3009, \u3008f7, x7\u3009}. Since x4 and x5 are strongly coupled (see Fig.1b), COA maps them arbitrarily (e.g., it could be f4 7\u2192 x5, f5 7\u2192 x4 instead). Such total mapping \u03d5 renders a cycle in the directed causal graph G\u03d5 induced by \u03d5 (see Fig.1c), which might not be desirable for some applications.\n2.3. COA\u2019s Hardness\nThe serious issue with COA is that finding the minimal structures in a given structure (line 3) is hard and could only be addressed heuristically as a specific problem of co-clustering (also called biclustering [15, 16]) in Boolean matrices.\nAny structure S(E ,V) satisfying Def. 1 can be represented as a bipartite graph G = (V1\u222aV2, E), where the set E of equations and the set V of variables are the disjoint vertex sets, i.e., V1 7\u2192 E , V2 7\u2192 V, and E 7\u2192 S is the edge set connecting equations to the variables appearing in them. Fig. 2 shows the\nbipartite graph G corresponding to the structure given in Example 1 \u2014 for a comprehensive text on graph concepts and its related algorithmic problems, cf. Even [17].\nA biclique (or complete bipartite graph) is a bipartite graph G = (V1 \u222a V2, E) such that for every two vertices s \u2208 V1, t \u2208 V2, we have (s, t) \u2208 E [17]. Note that for balanced bicliques, i.e., when |V1| = |V2| = K, the degree deg(u) of any vertex u \u2208 V1 \u222a V2 must be deg(u) = |V1| = |V2| = K. The total number of edges in a balanced biclique is then |E| = K2.\nRecent approaches to co-clustering problems (e.g., [18]) have been working with the notion of pseudo-biclique (also called \u2018quasi-biclique\u2019), which is a relaxation (extension) of the biclique concept for less than complete connectivity, say when some edges are missing so that the ratio of the number of edges |E| in comparison to the biclique (|E| = K2) is no less than a threshold.\nNow recall that COA needs to find, at each recursive step, all minimal substructures S \u2032 \u2286 S. There two special features of COA that we have to capture in our notion of pseudo-biclique: (1) the context is important\u2014we have to define it as a subgraph w.r.t. the bipartite graph given; and (2) we have to distinguish not only that there are two disjoint vertex sets, but also keep track of their labels specifically: for bipartite graph G = (V1 \u222a V2, E) we shall say that V1 is the primary vertex set. This is because COA operates asymmetrically w.r.t. equation vertices V1 7\u2192 E and variable vertices V2 7\u2192 V.\nWe shall then prove that finding the minimal substructures in a given complete structure at each COA\u2019s recursive step is equivalent to find the\nminimal-size \u2018pseudo-bicliques\u2019 in its corresponding bipartite graph\u2014for a specific notion of pseudo-biclique that suits our problem, cf. Def. 6.\nFig. 3 introduces another example of complete structure and its correspondence with a bipartite graph.\nDef. 6. Let G = (V1 \u222a V2, E) be a bipartite graph with primary vertex set V1. We say that G has a K-balanced pseudo-biclique G\n\u2032 = (V \u20321 \u222aV \u20322 , E \u2032), where G\u2032 \u2286 G, if |V \u20321 | = |V \u20322 | = K and \u2211\nu\u2208V1\ndeg(u) \u2264 \u2211\nv\u2208V \u2032 2\ndeg(v).\nObserve that the vertex degrees from the primary vertex set V1 are computed w.r.t. graph G, not subgraph G\u2032 (unless G = G\u2032). Moreover, it is easy to see that the case when deg(u) = K for all u \u2208 V1 \u222a V2, (K-balanced biclique) is a particular case of the K-balanced pseudo-biclique case.\nWe now originally state the balanced pseudo-biclique problem (BPBP) as a decision problem as follows.\n(BPBP). Given a bipartite graphG = (V1\u222aV2, E) with primary vertex set V1 and a positive integer K, does G have a K-balanced pseudo-biclique?\nLemma 1. The balanced pseudo-biclique problem (BPBP) is NP-Complete.\nProof 1. We show (by restriction [19, p. 63-5]) that the BPBP is a generalization of the balanced biclique problem (BBP), referred \u2018balanced complete\nbipartite subgraph\u2019 problem [19, GT24, p. 196], which is known to be NPComplete by means of a transformation from \u2018clique\u2019 [20, p. 446]. The restriction from BPBP to BBP (special case) is made by requiring deg(u) = K for all u \u2208 V1 \u222a V2, which enforces any K-balanced pseudo-biclique G\u2032 \u2286 G and G itself to be more specifically a K-balanced biclique.\nTheorem 1. Let S(E ,V) be a complete structure. The extraction of its causal ordering by Simon\u2019s COA(S) is NP-Hard.\nProof 2. We show that, at each recursive step k of COA, to find all minimal substructures S \u2032 \u2286 S is an optimization problem associated with the decision problem BPBP, which we know by Lemma 1 to be NP-Complete. We elaborate on the proof in Appendix A.\nNonetheless, the causal ordering problem (COP) can be solved efficiently by means of a different approach due to Nayak [4], which we introduce and build upon next."}, {"heading": "3. Nayak\u2019s Efficient Algorithm to COP", "text": "3.1. Total Causal Mappings\nThe problem of causal ordering can be solved in polynomial time by just (i) finding any total causal mapping \u03d5 : E \u2192 V over structure S given (cf. Def. 5); and then (ii) by computing the transitive closure C+\u03d5 of the set C\u03d5 of direct causal dependencies induced by \u03d5, see Eq. 1.\nC\u03d5= { (xa, xb) | there exists f \u2208 E such that \u03d5(f) = xb and xa \u2208 V ars(f) } (1)\nDef. 7. Let S(E ,V) be a structure with variables xa, xb \u2208 V, and \u03d5 a total causal mapping over S inducing set of direct causal dependencies C\u03d5 and indirectly a transitive closure C+\u03d5 . We say that (xa, xb) is a direct causal dependency in S if (xa, xb) \u2208 C\u03d5, and that (xa, xb) is a causal dependency in S if (xa, xb) \u2208 C+\u03d5 .\nIn other words, (xa, xb) is in C\u03d5 iff xb direct and causally depends on xa, given the causal asymmetries induced by \u03d5. Such notions shall enable us to extract the causal ordering by computing the transitive closure C+\u03d5 of C\u03d5\u2014which is known to be bounded by O(|S|3) [22, p. 633], where |S| is the number of edges in the bipartite graph associated with the structure. For this to be effective, though, if we have to ensure some properties of total causal mappings.\nFor a given structure S, there may be multiple total causal mappings over S (recall Example 1). But the causal ordering of S must be unique (see Fig. 1c). Therefore, a question that arises is whether the transitive closure C+\u03d5 is the same for any total causal mapping \u03d5 over S. Proposition 1, originally from Nayak [4], ensures that is the case.\nProposition 1. Let S(E ,V) be a structure, and \u03d51 : E \u2192 V and \u03d52 : E \u2192 V be any two total causal mappings over S. Then C+\u03d51 = C+\u03d52.\nProof 3. The proof is based on an argument from Nayak [4], which we present in a bit more of detail (see Appendix B). Intuitively, it shows that if \u03d51 and \u03d52 differ on the variable an equation f is mapped to, then such variables, viz., \u03d51(f) = xa and \u03d52(f) = xb, must be causally dependent on each other (strongly coupled).\nAnother issue is concerned with the precise conditions under which total causal mappings exist (i.e., whether or not all variables in the equations can be causally determined). In fact, by Proposition 2, based on Nayak [4] apud. Hall [17, p. 135-7], we know that the existence condition holds iff the given structure is complete.\nLet us refer to Even [17] to briefly introduce the additional graph-theoretic concepts which are necessary here. A matching in a graph is a subset of edges such that no two edges in the matching share a common node. A matching is said maximum if no edge can be added to the matching (without hindering the matching property). Finally, a matching in a graph is said \u2018perfect\u2019 if every vertex is an end-point of some edge in the matching \u2014 in a bipartite graph, a perfect matching is said a complete matching.\nProposition 2. Let S(E ,V) be a structure. Then a total causal mapping \u03d5 : E \u2192 V over S exists iff S is complete.\nProof 4. We observe that a total causal mapping \u03d5 : E \u2192 V over S corresponds exactly to a complete matching M in a bipartite graph B = (V1 \u222a V2, E), where V1 7\u2192 E , V2 7\u2192 V, and E 7\u2192 S. In fact, by Even apud. Hall\u2019s theorem (cf. [17, 135-7]), we know that B has a complete matching iff (a) for every subset of vertices F \u2286 V1, we have |F | \u2264 |E(F )|, where E(F ) is the set of all vertices connected to the vertices in F by edges in E; and (b) |V1| = |V2|. By Def. 1 (no subset of equations has fewer variables than equations), and Def. 2 (number of equations is the same as number of variables), it is easy to see that conditions (a) and (b) above hold iff S is a complete structure.\nThe problem of finding a maximum matching is a well-studied algorithmic problem. We adopt the Hopcroft-Karp algorithm [21], which is known to be polynomial-time bounded by O( \u221a\n|V1|+ |V2| |E|).3 That is, we handle the problem of total causal mapping by (see Alg. 2) translating it to the problem of maximum matching in a bipartite graph (in linear time) and then applying the Hopcroft-Karp algorithm to get the matching and finally translate it back to the total causal mapping, as suggested by the proof of Proposition 2.\n3The Hopcroft-Karp algorithm solves maximum matching in a bipartite graph efficiently as a problem of finding maximum flow in a network (cf. [17, p. 135-7], or [22, p. 664-9]).\nAlgorithm 2 Find a total causal mapping for a given structure.\n1: procedure TCM(S : structure over E and V) Require: S given is a complete structure, i.e., |E| = |V| Ensure: Returns a total causal mapping \u03d5 2: B(V1 \u222a V2, E) \u2190 \u2205 3: \u03d5 \u2190 \u2205 4: for all \u3008f,X\u3009 \u2208 S do \u22b2 translates structure S to a bipartite graph B 5: V1 \u2190 V1 \u222a {f} 6: for all x \u2208 X do 7: V2 \u2190 V2 \u222a {x} 8: E \u2190 E \u222a {(f, x)} 9: M \u2190 Hopcroft-Karp(B) \u22b2 solves the maximum matching problem 10: for all (f, x) \u2208 M do \u22b2 translates the matching to a total causal\nmapping 11: \u03d5 \u2190 \u03d5 \u222a {\u3008f, x\u3009} 12: return \u03d5\nFig. 4 shows the complete matching found by the Hopcroft-Karp algorithm for the structure given in Example 1.\nCorollary 1 summarizes the results we have so far.\nCorollary 1. Let S(E ,V) be a complete structure. Then a total causal mapping \u03d5 : E \u2192 V over S can be found by (Alg. 2) TCM in time that is bounded by O( \u221a |E| |S|).\nProof 5. Let B = (V1 \u222a V2, E) be the bipartite graph corresponding to complete structure S given to TCM, where V1 7\u2192 E , V2 7\u2192 V, and E 7\u2192 S. The translation of S into B is done by a scan over it. This scan is of length |S| = |E|. Note that number |E| of edges rendered is precisely the length |S| of structure, where the denser the structure, the greater |S| is. The retranslation of the matching computed by internal procedure Hopcroft-Karp, in turn, is done at expense of |E| = |V| \u2264 |S|. Thus, it is easy to see that TCM is dominated by the maximum matching algorithm Hopcroft-Karp, which is known to be O( \u221a |V1|+ |V2| |E|), i.e., O( \u221a\n|E|+ |V| |S|). Since S is assumed complete, we have |E| = |V| then \u221a |E|+ |V| = \u221a 2 \u221a\n|E|. Therefore, TCM must have running time at most O( \u221a |E| |S|).\nRemark 1. Let S(E ,V) be a complete structure. Then we know (cf. Proposition 2) that a total causal mapping over S exists. Let it be defined \u03d5 , TCM(S), which can be done in O( \u221a\n|E| |S|). Then the causal ordering implicit in S shall be correctly extracted (cf. Proposition 1) by computing the set C+\u03d5 causal dependencies induced by \u03d5 in time bounded by O(|S|3). That is, it is dominated by computing transitive closure (cf. [22, p. 663])."}, {"heading": "4. Conclusions", "text": "\u2022 By Theorem 1, we know (an original hardness result) that Simon\u2019s approach to process the causal ordering of a structure is NP-Hard;\n\u2022 By building upon the work of Simon [1] and Nayak [4] (cf. Propositions 1 and 2), we have conveyed an approach to efficiently extract the basic information (a total causal mapping) for processing the causal ordering implicit in a given system of mathematical equations;\n\u2022 By Corollary 1, we know how to process the complete structure of a set of mathematical equations into a total causal mapping in time that is bounded by O( \u221a |E| |S|).\n\u2022 By Remark 1, we know how to extract the causal ordering of a complete structure in time bounded by O(|S|3). This time bound can still be\ndecreased by means of optimized implementation [22, p. 663], and a careful handling of cycles in the directed graph. The machinery of causal ordering is then suitable for processing very large structures."}, {"heading": "Appendix A. Proof of Theorem 1", "text": "\u201cLet S(E ,V) be a complete structure. The extraction of its causal ordering by Simon\u2019s COA(S) is NP-Hard.\u201d\nProof 6. We show that, at each recursive step of COA, to find all minimal substructures S \u2032 \u2286 S translates into an optimization problem associated with the decision problem BPBP, which we know by Lemma 1 to be NP-Complete.\nFirst, we show that, for any bipartite graph G = (V1\u222aV2, E) with primary vertex set V1 and a positive integer K, BPBP corresponds to decide whether there is a complete substructure S \u2032 \u2286 S, for S \u2032(E \u2032,V \u2032) and |E \u2032| = |V \u2032| = K.\nLet us map vertex sets V1 7\u2192 E and V2 7\u2192 V (n.b., primary vertex set V1 is mapped to the equation vertex set). Now we show that any K-balanced pseudo-biclique G\u2032 \u2286 G, where G\u2032 = (V \u20321 \u222a V \u20322 , E \u2032) must correspond to a complete substructure S \u2032(E \u2032,V \u2032) where V \u20321 7\u2192 E \u2032 and V \u20322 7\u2192 V \u2032. In fact, by Def. 6 we have properties (i) |V \u20321 | = |V \u20322 | = K and (ii)\u2211\nu\u2208V1\ndeg(u) \u2264 \u2211\nv\u2208V \u2032 2\ndeg(v). By property (i) and Def. 2 we know that S \u2032 \u2286 S is\ncomplete, if it is a valid structure. But that is ensured by property (ii) and Def. 1.\nFinally, we expose the optimization problem associated with BPBP and COA. In fact, it is not enough to decide if G has a K-balanced pseudo-biclique but we have to always find the minimal K for so and only identify additional balanced pseudo-bicliques in the next recursive step k + 1 after eliminating the minimal substructures found in step k. For instance, note in Fig. 3b that the bipartite graph G associated with the complete structure S(E ,V) given is itself a K-balanced pseudo-biclique with K = |E| = |V| = 4. But it is not minimal\u2014note substructure S \u2032 \u2282 S highlighted in Fig. 3a, with E \u2032 = {f1(x1, x3), f2(x1, x2), f3(x2, x3)}. That is, the latter also satisfies the Kbalanced pseudo-biclique property but for a smaller K = 3."}, {"heading": "Appendix B. Proof of Proposition 1", "text": "\u201cLet S(E ,V) be a structure, and \u03d51 : E \u2192 V and \u03d52 : E \u2192 V be any two total causal mappings over S. Then C+1 = C+2 .\u201d\nProof 7. The proof is based on an argument from Nayak [4], which we present here in a bit more of detail. Intuitively, it shows that if \u03d51 and \u03d52 differ on the variable an equation f is mapped to, then such variables, viz., \u03d51(f) and \u03d52(f), must be causally dependent on each other (strongly coupled).\nTo show C+1 = C + 2 reduces to C + 1 \u2286 C+2 and C+2 \u2286 C+1 . We show the first containment, with the second being understood as following by symmetry.\nClosure operators are extensive, X \u2286 cl(X), and idempotent, cl(cl(X)) = cl(X). That is, if we have C1 \u2286 C+2 , then we shall have C+1 \u2286 (C+2 )+ and, by idempotence, C+1 \u2286 C+2 .\nThen it suffices to show that C1 \u2286 C+2 , i.e., for any (x\u2032, x) \u2208 C1, we must show that (x\u2032, x) \u2208 C+2 as well. Observe by Def. 5 that both \u03d51 and \u03d52 are bijections, then, invertible functions. If \u03d5\u221211 (x) = \u03d5 \u22121\n2 (x), then we have (x\u2032, x) \u2208 C2 and thus, trivially, (x\u2032, x) \u2208 C+2 . Else, \u03d51 and \u03d52 disagree in which equations they map onto x. But we show next, in any case, that we shall have (x\u2032, x) \u2208 C+2 .\nTake all equations g \u2208 E \u2032 \u2286 E such that \u03d51(g) 6= \u03d52(g), and let n \u2264 |E| be the number of such \u2018disagreed\u2019 equations. Now, let f \u2208 E \u2032 be such that its mapped variable is x = \u03d51(f). Construct a sequence of length 2n such that, s0 = \u03d51(f) = x and, for 1 \u2264 i \u2264 2n, element si is defined si = \u03d52(\u03d5 \u22121\n1 (si\u22121)). That is, we are defining the sequence such that, for each equation g \u2208 E \u2032, its disagreed mappings \u03d51(g) = xa and \u03d52(g) = xb are such that \u03d51(g) is immediately followed by \u03d52(g). As xa, xb \u2208 V ars(g), we have (xa, xb) \u2208 C2 and, symmetrically, (xb, xa) \u2208 C1. The sequence is of form s = \u3008x, xf\n\ufe38 \ufe37\ufe37 \ufe38\nf\n, . . . , xa, xb \ufe38 \ufe37\ufe37 \ufe38\ng\n, . . . , x2n\u22121, x2n \ufe38 \ufe37\ufe37 \ufe38\nh\n\u3009.\nSince x must be in the codomain of \u03d52, we must have a repetition of x at some point 2 \u2264 k \u2264 2n in the sequence index, with sk = x and sk\u22121 = x\u2032\u2032 such that (x\u2032\u2032, x) \u2208 C2. If x\u2032\u2032 = x\u2032, then (x\u2032, x) \u2208 C2 and obviously (x\u2032, x) \u2208 C+2 . Else, note that xf must also be in the codomain of \u03d51, while x\n\u2032\u2032 in the codomain of \u03d52. Let \u2113 be the point in the sequence, 3 \u2264 \u2113 \u2264 2n\u22121, at which s\u2113 = xf = xa and s\u2113+1 = xb for some xb such that (xf , xb) \u2208 C2. It is easy to see that, either we have xb = x\n\u2032\u2032 or xb 6= x\u2032\u2032 but (xb, x\u2032\u2032) \u2208 C+2 . Thus, by transitivity on such a causal chain, we must have (xf , x\n\u2032\u2032) \u2208 C+2 and eventually (xf , x) \u2208 C+2 . Finally, since x\u2032 \u2208 V ars(f) and \u03d52(f) = xf , we have (x\u2032, xf ) \u2208 C2 and, by transitivity, (x\u2032, x) \u2208 C+2 ."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "In this paper we provide a concise report on the complexity of the causal<lb>ordering problem, originally introduced by Simon to reason about causal<lb>relations implicit in mathematical models. We show that Simon\u2019s classical<lb>algorithm to infer causal ordering is NP-Hard\u2014an intractability previously<lb>guessed by Nayak but not yet proven. We present then a detailed account<lb>based on Nayak\u2019s suggested algorithmic solution (the best available), which<lb>is dominated by computing transitive closure\u2014bounded in time by O(|S|3),<lb>where S(E ,V) is the input system structure composed of a set E of equations<lb>over a set V of variables with density |S|. We also comment on the po-<lb>tential of causal ordering for emerging applications in large-scale hypothesis<lb>management and predictive analytics.", "creator": "LaTeX with hyperref package"}}}