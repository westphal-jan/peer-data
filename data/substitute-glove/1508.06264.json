{"id": "1508.06264", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Aug-2015", "title": "Multiple kernel multivariate performance learning using cutting plane algorithm", "abstract": "In this on, say propose he aiming - kernel classifier practice algorithm put productivity every given nonlinear especially nonsmoonth convolution classifier competition instance. Moreover, if possible is problem of finite characteristic selection it kernel parameter tuning, we proposed to scheme charge economical interpolation to declines embedding changes particular some gore kernels. The understanding including before classifier inverse and the kernel weight than unified but just cover objective function considering instead distract new upper portion known the present cauchy quite measure. The realistic mechanisms is 64-bit with likewise to reification parameter although kernel lack casually in based three-step initialization noted using eliminate plane estimation. The system derivation probably inconsistent on three rather pattern classification methods with regard immediately various graphs performance measure optimization problems. The observations previous show time proposed algorithm outperforms entire competing formulation.", "histories": [["v1", "Tue, 25 Aug 2015 19:45:06 GMT  (105kb)", "http://arxiv.org/abs/1508.06264v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["jingbin wang", "haoxiang wang", "yihua zhou", "nancy mcdonald"], "accepted": false, "id": "1508.06264"}, "pdf": {"name": "1508.06264.pdf", "metadata": {"source": "CRF", "title": "Multiple kernel multivariate performance learning using cutting plane algorithm", "authors": ["Jingbin Wang", "Haoxiang Wang", "Yihua Zhou", "Nancy McDonald"], "emails": ["jingbinwang1@outlook.com", "nancya.mcdonald@yahoo.com"], "sections": [{"heading": null, "text": "ar X\niv :1\n50 8.\n06 26\n4v 1\n[ cs\n.L G\n] 2\n5 A\nIndex Terms\u2014Pattern recognition, multiple kernel, multivariate performance measures, cutting plane algorithm\nI. INTRODUCTION\nIn different pattern classification problems, various performances are employed to evaluate the classifiers, including classification accuracy (ACC), F1 score , Matthews Correlation Coefficient (MCC), area under the receiver operating characteristic (ROC) Curve (AUC) and recall-precision break even point (RP-BEP) of recall-precision curve. Due to the nonlinear and nonsmooth nature of many performance measures, it is difficult to optimize them directly to learn an optimal classifier. To solve this problem, Joachims [1] proposed a support vector machine learning method for multivariate Performance measures (SVMPerf ). This other method has been applied to optimized some nonlinear multivariate performance measures to learn linear classifiers successfully. However, it is limited to the learning of linear classifiers. When data samples of different classes cannot be separated by a linear boundary, it is suggested to employ the kernel trick to map the data samples to a nonlinear high-dimensional data space so that a linear boundary could be learned [2], [3], [4]. Joachims and Yu [5] also extended the SVMPerf to its kernel version to handle the nonlinearly distributed data. One important shortage of this\nmethod lies on the choosing of an optimal kernel function with its corresponding parameter. In [5], the RBF-Kernel is used to classification problems on some data sets without any justification, but it is highly doubt if this kernel is suitable for other data sets. Moreover, how the optimal parameter of the kernel function possibly influences the results significantly. One possible way to solve this problem is to conduct an exhausting linear search or a cross validation in the kernel function and parameter space by using the training set, which is very time-consuming and also makes the learned classifier over-fitting to the training samples.\nTo solve this problem, we assume that the desired kernel can be obtained by the linear combination of some candidate kernel functions with different kernel parameters. The optimal kernel is parameterized by the linear combination weights associated with different kernels. This framework is called Multi-Kernel Learning (MKL) since we explore the nonlinear kernel spaces of multiple kernels [6]. To learn the kernel weights, we cast the MKL problem with the multivariate performance measures problem, and proposed an unified learning problem for both MKL and multivariate performance measures problems. For the first time, we propose the problem of learning an optimal kernel for multivariate performance measures, and a novel solution for this problem by learning kernel in multiple kernel spaces simultaneously with optimizing multivariate performance measures.\nThe rest parts of this paper are organized as follows: in section II, we introduce the novel method by formulating the problem first, optimizing it then, and developing an iterative algorithm finally, in section III, the proposed method is evaluated on some benchmark data sets, and in section IV, the paper is concluded."}, {"heading": "II. PROPOSED METHOD", "text": "A. Problem Formulation\nWe assume we have a training data set with n training samples, and the training samples are organized in an training\nmatrix X = [x1, \u00b7 \u00b7 \u00b7 , xn] \u2208 Rd\u00d7n, where the i-th column xi is the d-dimensional feature vector of the i-th training sample. Moreover, we also organize the class labels in a class label vector y = [y1, \u00b7 \u00b7 \u00b7 , yn]\u22a4 \u2208 {+1,\u22121}n, where yi \u2208 {+1,\u22121} is the binary class label of the i-th training sample. Under the framework of kernel learning [7], an sample vector can be mapped into a high dimensional nonlinear Hilbert Space, via a implicit mapping function \u03c6 : x \u2192 \u03c6(x) \u2208 Rd \u2032\n, where d\u2032 \u226b d is the dimension of the Hilbert Space. The mapping function is explored by a kernel function, which is defined as the dot-produce of the mapping of two samples xi and xj , as K(xi, xj) = \u03c6(xi)\u22a4\u03c6(xj). In the multi-kernel learning framework, we may have several such Hilbert Spaces available and there corresponding nonlinear mapping functions are denoted as {\u03c6m(x) \u2208 Rd \u2032\nm}Mm=1, where M is the number of Hilbert Spaces, \u03c6m(x) is the nonlinear mapping function of the m-th mapping function, and d\u2032m is the dimension of the m-th Hilbert Space. We also define the kernel function for the m-th Hilbert space as Km(xi, xj) = \u03c6(xi)\u22a4m\u03c6m(xj). We weight and concatenate the mapping function to form a longer vector in a more general Hilbert Space, \u03c6\u03c4 (x) = [\n\u03c41\u03c61(x)\u22a4, \u00b7 \u00b7 \u00b7 , \u03c4M\u03c6M (x)\u22a4 ]\u22a4 \u2208 Rd \u2032\nwhere \u03c4m \u2208 R+ is the nonnegative weight for the m-th Hilbert Space, \u03c4 = [\u03c41, \u00b7 \u00b7 \u00b7 , \u03c4M ] \u22a4 \u2208 RM+ is the weight vector, and d \u2032 = \u2211M m=1 d \u2032 m is the dimension of the general Hilbert Space. Its corresponding kernel function is given as\nK\u03c4 (xi, xj) = \u03c6\u03c4 (xi)\u22a4\u03c6\u03c4 (xj) = M \u2211\nm=1\n\u03c42mKm(xi, vj) (1)\nIt can be seen that the kernel function is also a weighted linear combination of the M kernel functions of the M Hilbert spaces. We map all the samples to the Hilbert spaces, and organize the mapping results in a d\u2032 \u00d7 n matrix as \u03c6\u03c4 (X) = [\u03c6\u03c4 (x1), \u00b7 \u00b7 \u00b7 , \u03c6\u03c4 (xn)] \u2208 Rd\n\u2032\u00d7n. We can also apply the kernel function to the matrix and obtain the n\u00d7 n kernel matrix K\u03c4 (X,X) = \u2211M m=1 \u03c4 2 mKm(X,X) \u2208 R\nn\u00d7n, where Km(X,X) = [Km(xi, xj)] \u2208 Rn\u00d7n is the kernel matrix of the m-th Hilbert space.\nWe consider the problem of learning a hypotheses function hw(X) which maps a tuple of n samples organized in a data matrix X to a label vector of n labels y. To this end, we first map the data matrix X to the general Hilbert space \u03c6\u03c4 (X), and then apply a linear discriminant function of the following form\nhw(X) = argmax y\u2032\u2208{+1,\u22121}n w\u22a4\u03c6\u03c4 (X)y\u2032 = argmax y\u2032\u2208{+1,\u22121}n\nn \u2211\ni=1\nw\u22a4\u03c6\u03c4 (xi)y\u2032i\n(2) where w \u2208 Rd \u2032\nis the parameter vector. Actually, it is equal to the following prediction results,\nhw(X) = sign ( w\u22a4\u03c6\u03c4 (X) )\n(3)\nwhere sign (\u00b7) is an element-wise sign operation function.\nTo avoid the over-fitting problem, we try to reduce the complexity of the hypotheses function parameter w by minimizing the squared \u21132 norm,\nmin w,\u03be,\u03c4\n{\n1 2 \u2016w\u201622 = 1 2 w\u22a4w\n}\n(4)\nWe also want to reduce the prediction error of the hypotheses function on the training set. To measure the prediction error, a loss function can be applied to compare the true class label tuple y against the output of the hypotheses function hw(X). The following optimization problem is obtained with a \u2206(y, hw(X)),\nmin w \u2206(y, hw(X)). (5)\nInstead of trying to optimize \u2206(y, hw(X)) directly, we try to find its upper boundary and then minimize its upper boundary. Given (2), we have the following inequalities,\nw\u22a4\u03c6\u03c4 (X)hw(X) \u2265 w\u22a4\u03c6\u03c4 (X)y\u2032, \u2200y\u2032 \u2208 {+1,\u22121}n\n\u21d2 \u2206(y, hw(X)) + w\u22a4\u03c6\u03c4 (X) (hw(X)\u2212 y) \u2265 \u2206(y, hw(X)) (6)\nThus we have the upper boundary of \u2206(y, hw(X)), and the optimization problem in (5) can be relaxed to\nmin w\n{ \u2206(y, hw(X)) + w\u22a4\u03c6\u03c4 (X) (hw(X)\u2212 y) } . (7)\nWe further relax the minimization of \u2206(y, hw(X)) + w\u22a4\u03c6\u03c4 (X) (hw(X)\u2212 y) to the minimization of its upper boundary, which could be obtained by exploring the class label tuple space excluding y, y\u2032l \u2208 Y/y,\n\u2206(y, hw(X)) + w\u22a4\u03c6\u03c4 (X) (hw(X)\u2212 y)\n\u2264 max l:y\u2032\nl \u2208Y/y\n[\n\u2206(y, y\u2032l) + w \u22a4\u03c6\u03c4 (X) (y\u2032l \u2212 y)\n]\n(8) Thus we can translate the problem in (7) to (9),\nmin w\n{\nmax l:y\u2032\nl \u2208Y/y\n[\n\u2206(y, y\u2032l) + w \u22a4\u03c6\u03c4 (X) (y\u2032l \u2212 y)\n]\n}\n. (9)\nIt could be further relaxed by introducing a nonnegative slack variable \u03be to represent the upper boundary, so that the problem could be rewritten as\nmin w,\u03be \u03be,\ns.t. \u2206(y, y\u2032l) + w \u22a4\u03c6\u03c4 (X)(y\u2032l \u2212 y) \u2264 \u03be, \u2200l : y \u2032 l \u2208 Y/y,\n\u03be \u2265 0.\n(10)\nCombining the problems in (2) and (10), and introducing constrains on \u03c4 to prevent negative kernel weights, the following overall optimization problem,\nmin w,\u03be,\u03c4\n1 2 w\u22a4w + C\u03be,\ns.t. \u2206(y, y\u2032l) + w \u22a4\u03c6\u03c4 (X)(y\u2032l \u2212 y) \u2264 \u03be, l : y \u2032 l \u2208 Y/y,\n\u03be \u2265 0, M \u2211\nm=1\n\u03c4m = 1, \u03c4m \u2265 0,m = 1, \u00b7 \u00b7 \u00b7 ,M.\n(11)\nwhere C is a tradeoff parameter.\nB. Optimization\nTo optimize this problem, we give the primal Lagrangian function as follows,\nL(w, \u03be, \u03c4 ,\u03b1, \u03b2, \u03b3, \u03b4) = 1\n2 w\u22a4w + C\u03be\n+ \u2211\nl:y\u2032 l \u2208Y/y\n\u03b1l ( \u2206(y, y\u2032l) + w \u22a4\u03c6\u03c4 (X)(y\u2032l \u2212 y)\u2212 \u03be )\n\u2212 \u03b2\u03be \u2212 \u03b3\n(\nM \u2211\nm=1\n\u03c4m \u2212 1\n)\n\u2212 M \u2211\nm=1\n\u03b4m\u03c4m\n(12)\nwhere \u03b1l \u2265 0, \u03b2 \u2265 0, \u03b3 \u2265 0 and \u03b4m \u2265 0 are the Lagrange multipliers. We argue the following dual optimization problem,\nmax \u03b1,\u03b2,\u03b3,\u03b4 min w,\u03be,\u03c4 L(w, \u03be, \u03c4 ,\u03b1, \u03b2, \u03b3, \u03b4)\ns.t. \u03b1l \u2265 0, l : y\u2032l \u2208 Y/y,\n\u03b2 \u2265 0, \u03b3 \u2265 0, \u03b4m \u2265 0,m = 1, \u00b7 \u00b7 \u00b7 ,M.\n(13)\nBy setting the digestives of the Lagrange function with regard to w and \u03be to zero, we have\n\u2202L \u2202w = 0 \u21d2w = \u2211\nl:y\u2032 l \u2208Y/y\n\u03b1l\u03c6\u03c4 (X)(y \u2212 y\u2032l)\n\u2202L \u2202\u03be = 0 \u21d2C \u2212 \u2211\nl:y\u2032 l \u2208Y/y\n\u03b1l \u2212 \u03b2 = 0 \u21d2 C \u2265 \u2211\nl:y\u2032 l \u2208Y/y\n\u03b1l.\n(14) By substituting these results and the kernel definition in (1) to (13), we obtain the dual Lagrangian function,\nP(\u03c4 ,\u03b1, \u03b3, \u03b4)\n= \u2212 1\n2\n\u2211\nl,k:y\u2032 l ,y\u2032 k \u2208Y/y\n\u03b1l\u03b1k\n(\n(y \u2212 y\u2032l) \u22a4\nM \u2211\nm=1\n\u03c42mKm(X,X)(y \u2212 y \u2032 k)\n)\n+ \u2211\nl:y\u2032 l \u2208Y/y\n\u03b1l\u2206(y, y\u2032l)\u2212 \u03b3\n(\nM \u2211\nm=1\n\u03c4m \u2212 1\n)\n\u2212 M \u2211\nm=1\n\u03b4m\u03c4m\n(15) This optimization problem is then transformed to\nmin \u03c4 min \u03b1,\u03b3,\u03b4 P(\u03c4 ,\u03b1, \u03b3, \u03b4)\ns.t. \u03b1l \u2265 0, l : y\u2032l \u2208 Y/y, C \u2265 \u2211\nl:y\u2032 l \u2208Y/y\n\u03b1l,\n\u03b3 \u2265 0, \u03b4m \u2265 0,m = 1, \u00b7 \u00b7 \u00b7 ,M.\n(16)\nTo solve this problem, we adopt an alternate optimization strategy. In an iterative algorithm, \u03b1 and \u03c4 with its Lagrange multipliers \u03b3 and \u03b4 are optimized alternately.\n\u2022 Optimizing \u03b1 By fixing \u03c4 with its Lagrange multipliers \u03b3 and \u03b4, and only considering \u03b1, the optimization problem in (16) is reduced to\nmax \u03b1\n\n\u2212 1\n2\n\u2211\nl,k:y\u2032 l ,y\u2032 k \u2208Y/y\n\u03b1l\u03b1k ( (y \u2212 y\u2032l) \u22a4K\u03c4 (X,X)(y \u2212 y\u2032k) )\n+ \u2211\nl:y\u2032 l \u2208Y/y\n\u03b1l\u2206(y, y\u2032l)\n\n\ns.t. \u2211\nl:y\u2032 l \u2208Y/y\n\u03b1l \u2264 C,\u03b1l \u2265 0, l : y\u2032l \u2208 Y/y.\n(17) This problem can be solved as a quadratic programming problem.\n\u2022 Solving \u03c4 By fixing \u03b1, and only considering \u03c4 and its Lagrange multipliers \u03b3 and \u03b4, we have the following problem,\nmin \u03c4 max \u03b3,\u03b4\n\n\n\n\u2212 1\n2\n\u2211\nl,k:y\u2032 l ,y\u2032 k \u2208Y/y\n(\n\u03b1l\u03b1k(y \u2212 y\u2032l) \u22a4\n\u00d7 M \u2211\nm=1\n\u03c42mKm(X,X)(y \u2212 y \u2032 k)\n)\n\u2212\u03b3\n(\nM \u2211\nm=1\n\u03c4m \u2212 1\n)\n\u2212 M \u2211\nm=1\n\u03b4m\u03c4m\n}\ns.t. \u03b3 \u2265 0, \u03b4m \u2265 0,m = 1, \u00b7 \u00b7 \u00b7 ,M.\n(18)\nThis is the dual form of a constrained quadratic programming problem, and we can solve it as a constrained quadratic programming problem.\n\u2022 Updating Y/y Moreover, it should be noted that the construction of set Y/y is also a problem. To this end, we propose to construct Y/y sequentially in the iterative algorithm. We propose to construct Y/y by adding one new class label tuple to Y/y in each iteration according to updated w and \u03c4 ,\ny\u2217 = argmax y\u2032\u2032\u2208{+1,\u22121}n,y\u2032\u2032 6=y,y\u2032\u2032 /\u2208Y/y\n\n\n\n\u2206(y, y\u2032\u2032) +\n\u2211\nl:y\u2032 l \u2208Y/y\n(\n\u03b1l(y \u2212 y\u2032l) \u22a4K\u03c4 (X, xi)y\u2032\u2032\n)\n\n\n\n.\n(19)\nwhere K\u03c4 (X, xi) = [K\u03c4 (x1, xi), \u00b7 \u00b7 \u00b7 ,K\u03c4 (xn, xi)]\u22a4 \u2208 R n\u00d71. Then we can update Y/y by adding y\u2217 to it,\nY/y \u2190 {y\u2217} \u222a Y/y. (20)\nC. Algorithm\nThe iterative multi-kernel learning algorithm to optimize multivariate performance measure is summarized in Algorithm 1.\nAlgorithm 1 Multi-Kernel Learning algorithm for optimize multivariate Performance measure Optimization (MKLPO).\nInput: Training sample feature matrix X , and corresponding class label tuple y; Initialize \u03b10 and \u03c4 0; Initialize Y/y = \u2205; for t = 1, \u00b7 \u00b7 \u00b7 , T do\nObtain a predicted class label tuple y\u2217 as in (19) by fixing \u03b1t\u22121 and \u03c4 t\u22121, and add it to Y/y as in (20); Update \u03b1t by solving (17) and fixing \u03c4 t\u22121; Update \u03c4 t by solving (18) and fixing \u03b1t;\nend for Output: Output the learned \u03b1T and \u03c4 T ."}, {"heading": "III. EXPERIMENTS", "text": "A. Experiment I: Allergen prediction\nIn the first experiment, we perform the proposed to the problem of allergen prediction to optimized various prediction performance measures [8].\n1) Dataset and protocol: In this experiment, we used a dataset constructed by Dang and Lawrence [8]. This dataset contains 42,977 protein sequences, 3,907 of them are allergens while the remaining 39,070 are non-allergens. To extract feature from each protein sequence, we used the bag-of-words method [9]. Firstly, the amino acid sequence of a protein is broken to some overlapping peptides with a small sliding window, and each peptides is treated as a word. To conduct the experiment, we perform the popular 10-fold cross validation. Various performance measures are considered in this experiment. The multivariate performance measures are optimized on the training set and tested on the test set, including AUC, RP-BEP, ACC, F score and MCC.\n2) Results: We compare the proposed multi-kernel learning based multivariate performance measures optimization algorithm agains the original kernel version of SVMPerf , cuttingplane subspace pursuit (CPSP) algorithm [5]. Moreover, three different variations of SVMPerf are also compared as the state-of-the-art multivariate performance measures optimization methods, including the performance measure optimization method by classifier adaptation (CAPO) [10], the feature selection method for multivariate performance measures optimization (FSPO) [11], and the non-decomposable loss functions optimization method (NDLO) [12]. We used these methods to optimize the multivariate performances of AUC of ROC, PR-BEP of recall-precision curve, ACC, F score, and MCC respectively on the training set, and the test them on the test set. The boxplots of the corresponding performance measures of 10-fold cross validations are given in Figure 1. From this figure, we can see clearly that the proposed multi-kernel\nbased multivariate performance measure optimization method achieves the best results with regard to different performance measures. Similar phenomenon can be observed in Figure 1(e), and MKLPO is the only algorithm which obtains a higher MCC median value than 0.900. For other performance measures, MKLPO also optimize them to achieve the best performances measures on the test sets. Among the compared algorithms, both CPSP and CAPO are improved by using kernel trickles. However, due to the limitation of single kernel, their performance are not necessarily superior to the linear models, FSPO and NDLO. In most cases, their performances are comparable to each other.\nB. Experiment II: Rehabilitative speech treatment assessment\nIn this experiment, we test the proposed algorithm for the automatic assessment of rehabilitative speech treatment.\n1) Dataset and protocol: In this experiment, we use the dataset provided by Tsanas et al. [13]. There are 126 phonations in the data set. A speech expert is employed to assess the phonations, and label them as \u201cacceptable\u201d or \u201cunacceptable\u201d. Among the 126 phonations, 42 is labeled as \u201cacceptable\u201d while the remaining 84 is labeled as \u201cunacceptable\u201d. Each phonation is defined as a data sample in the problem of pattern classification, and \u2018acceptable\u201d phonation is defined as positive sample, while \u201cunacceptable\u201d phonation as negative sample. For the purpose of pattern classification, we extract features from each of the phonations. To conduct the experiment,\nwe also use the 10-fold cross validation. The multivariate performance measures are optimized on the training set and tested on the test set, including AUC, RP-BEP, ACC, F score and MCC.\n2) Results: Fig. 2 shows the boxplots of optimized multivariate performance measures of 10-fold cross validations by using rehabilitative speech treatment assessment data set. As can be seen, our MKLPO algorithm significantly outperforms the other multivariate performance measures optimization algorithms in most cases. The performance difference is larger as the MCC is optimized as the desired multivariate performance measure. The CAPO algorithm outperforms other algorithms in most cases slightly besides the proposed MKLPO algorithm. This result is consistent with the experiment results given in the previous section."}, {"heading": "IV. CONCLUSIONS AND FUTURE WORKS", "text": "Recently a multivariate performance measures optimization method is proposed to estimate a given complex multivariate performance measure as a linear function. This method is based on kernel trick. However, it is difficult to choose a suitable kernel function with its corresponding parameter. To solve this problem, in this paper, we proposed the first multi-kernel learning based algorithm for the problem of optimization of multivariate performance measures. We build a unified objective function for the learning of both multiple kernel weight and classifier parameter for the purpose of multivariate performance measure. An iterative algorithm is\ndeveloped to optimize the objective function. The experiment results on two different pattern classification problems show that the proposed algorithm outperforms the state-of-the-art multivariate performance measure optimization methods. In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52]. Moreover, we will also improve the proposed method by regularizing the learning of classifier by graphs [53], [54], [55], [56], [57], [58], [59], [60], [61]."}], "references": [{"title": "A support vector method for multivariate performance measures", "author": ["T. Joachims"], "venue": "Proceedings of the 22nd international conference on Machine learning. ACM, 2005, pp. 377\u2013384.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2005}, {"title": "An introduction to kernel-based learning algorithms", "author": ["K.-R. Mller", "S. Mika", "G. Rtsch", "K. Tsuda", "B. Schlkopf"], "venue": "IEEE Transactions on Neural Networks, vol. 12, no. 2, pp. 181\u2013201, 2001.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2001}, {"title": "Trajectory planning for an unmanned ground vehicle group using augmented particle swarm optimization in a dynamic environment", "author": ["Y. Wang", "P. Chen", "Y. Jin"], "venue": "Systems, Man and Cybernetics, 2009. SMC 2009. IEEE International Conference on. IEEE, 2009, pp. 4341\u20134346.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Regularized maximum correntropy machine", "author": ["J.J.-Y. Wang", "Y. Wang", "B.-Y. Jing", "X. Gao"], "venue": "Neurocomputing, vol. 160, pp. 85\u201392, 2015.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Sparse kernel svms via cutting-plane training", "author": ["T. Joachims", "C.-N. Yu"], "venue": "Machine Learning, vol. 76, no. 2-3, pp. 179\u2013193, 2009.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Feature selection and multikernel learning for sparse representation on a manifold", "author": ["J.J.-Y. Wang", "H. Bensmail", "X. Gao"], "venue": "Neural Networks, vol. 51, pp. 9\u201316, 2014.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "An effective image representation method using kernel classification", "author": ["H. Wang", "J. Wang"], "venue": "2014 IEEE 26th International Conference on Tools with Artificial Intelligence (ICTAI 2014), 2014, pp. 853\u2013858.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Allerdictor: fast allergen prediction using text classification techniques", "author": ["H.X. Dang", "C.B. Lawrence"], "venue": "Bioinformatics, p. btu004, 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Joint learning and weighting of visual vocabulary for bag-of-feature based tissue classification", "author": ["J.J.-Y. Wang", "H. Bensmail", "X. Gao"], "venue": "Pattern Recognition, vol. 46, no. 12, pp. 3249\u20133255, 2013.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Efficient optimization of performance measures by classifier adaptation", "author": ["N. Li", "I. Tsang", "Z.-H. Zhou"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 35, no. 6, pp. 1370\u20131382, 2013.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "A feature selection method for multivariate performance measures", "author": ["Q. Mao", "I.-H. Tsang"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 35, no. 9, pp. 2051\u20132063, 2013.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Optimizing nondecomposable loss functions in structured prediction", "author": ["M. Ranjbar", "T. Lan", "Y. Wang", "S.N. Robinovitch", "Z.-N. Li", "G. Mori"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 35, no. 4, pp. 911\u2013924, 2013.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Objective automatic assessment of rehabilitative speech treatment in parkinson\u2019s disease", "author": ["A. Tsanas", "M.A. Little", "C. Fox", "L.O. Ramig"], "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering, vol. 22, no. 1, pp. 181 \u2013 190, 2014.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Formation and degradation of multicomponent multicore micelles: insights from dissipative particle dynamics simulations", "author": ["H. Chen", "E. Ruckenstein"], "venue": "Langmuir, vol. 29, no. 18, pp. 5428\u20135434, 2013.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Nanoparticle aggregation in the presence of a block copolymer", "author": ["\u2014\u2014"], "venue": "The Journal of chemical physics, vol. 131, no. 24, p. 244904, 2009.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "Proclusensem: predicting membrane protein types by fusing different modes of pseudo amino acid composition", "author": ["J. Wang", "Y. Li", "Q. Wang", "X. You", "J. Man", "C. Wang", "X. Gao"], "venue": "Computers in biology and medicine, vol. 42, no. 5, pp. 564\u2013574, 2012.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "Three-dimensional counting of morphologically normal human red blood cells via digital holographic microscopy", "author": ["F. Yi", "I. Moon", "Y.H. Lee"], "venue": "Journal of biomedical optics, vol. 20, no. 1, pp. 016 005\u2013 016 005, 2015.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "A conceptual cellular interaction model of left ventricular remodelling postmi: dynamic network with exit-entry competition strategy", "author": ["Y. Wang", "H.-C. Han", "J.Y. Yang", "M.L. Lindsey", "Y. Jin"], "venue": "BMC systems biology, vol. 4, no. Suppl 1, p. S5, 2010.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "Modeling nanoparticle targeting to a vascular surface in shear flow through diffusive particle dynamics", "author": ["B. Peng", "Y. Liu", "Y. Zhou", "L. Yang", "G. Zhang", "Y. Liu"], "venue": "Nanoscale Research Letters, vol. 10, no. 1, p. 235, 2015.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Structure design of vascular stents", "author": ["Y. Liu", "J. Yang", "Y. Zhou", "J. Hu"], "venue": "Multiscale simulations and mechanics of biological materials, pp. 301\u2013 317, 2013.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2013}, {"title": "Biomarker binding on an antibody-functionalized biosensor surface: the influence of surface properties, electric field, and coating density", "author": ["Y. Zhou", "W. Hu", "B. Peng", "Y. Liu"], "venue": "The Journal of Physical Chemistry C, vol. 118, no. 26, pp. 14 586\u201314 594, 2014.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Piecewise surface regression modeling in intelligent decision guidance system", "author": ["J. Luo", "A. Brodsky"], "venue": "Intelligent Decision Technologies, 2011, pp. 223\u2013235.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "Eot scaling of on germanium pmosfets and impact of gate metal selection", "author": ["L. Zhang", "M. Gunji", "S. Thombare", "P.C. McIntyre"], "venue": "Electron Device Letters, IEEE, vol. 34, no. 6, pp. 732\u2013734, 2013.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "New insights into oxide traps characterization in gate-all-around nanowire transistors with tin metal gates based on combined i g-i d rts technique", "author": ["L. Zhang", "J. Zhuge", "Y. Wang", "R. Huang", "C. Liu", "D. Wu", "Z. Kang", "D.- W. Kim", "D. Park"], "venue": "VLSI Technology, 2009 Symposium on. IEEE, 2009, pp. 46\u201347.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2009}, {"title": "Impacts of non-negligible electron trapping/detrapping on the nbti characteristics in silicon nanowire transistors with tin metal gates", "author": ["L. Zhang", "R. Wang", "J. Zhuge", "R. Huang", "D.-W. Kim", "D. Park", "Y. Wang"], "venue": "2008 IEEE International Electron Devices Meeting, 2008, pp. 1\u20134.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2008}, {"title": "Germanium channel pmosfet with tio2/al2o3 bilayer high-k gate stacks and solutions for metal/tio2 interface stability", "author": ["L. Zhang", "M. Gungi", "P.C. McIntyre"], "venue": "Silicon-Germanium Technology and Device Meeting (ISTDM), 2012 International. IEEE, 2012, pp. 1\u20132.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2012}, {"title": "A comprehensive study on schottky barrier nanowire transistors (sb-nwts): Principle, physical limits and parameter fluctuations", "author": ["L. Zhang", "Z. Kang", "R. Wang", "R. Huang"], "venue": "Solid-State and Integrated-Circuit Technology, 2008. ICSICT 2008. 9th International Conference on. IEEE, 2008, pp. 157\u2013160.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2008}, {"title": "Random telegraph signal noise in gate-all-around silicon nanowire transistors featuring coulomb-blockade characteristics", "author": ["J. Zhuge", "L. Zhang", "R. Wang", "R. Huang", "D.-W. Kim", "D. Park", "Y. Wang"], "venue": "Applied Physics Letters, vol. 94, no. 8, p. 083503, 2009.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2009}, {"title": "Investigations on the physical limitation and electrostatic improvement of a gate-all-around silicon nanowire transistor with schottky barrier source/drain", "author": ["Z. Kang", "L. Zhang", "R. Wang", "R. Huang"], "venue": "Semiconductor Science and Technology, vol. 24, no. 10, p. 105001, 2009.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2009}, {"title": "Experimental investigations on channel backscattering characteristics of gate-all-around silicon nanowire transistors from top-down approach", "author": ["R. Wang", "R. Huang", "L. Zhang", "H. Liu", "D.-W. Kim", "D. Park", "Y. Wang"], "venue": "Applied Physics Letters, vol. 93, no. 8, p. 083513, 2008.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2008}, {"title": "Accelerating frequent itemset mining on graphics processing units", "author": ["F. Zhang", "Y. Zhang", "J.D. Bakos"], "venue": "The Journal of Supercomputing, vol. 66, no. 1, pp. 94\u2013117, 2013.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2013}, {"title": "Sparse matrix-vector multiply on the keystone ii digital signal processor", "author": ["Y. Gao", "F. Zhang", "J.D. Bakos"], "venue": "High Performance Extreme Computing Conference (HPEC), 2014 IEEE, 2014, pp. 1\u20136.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2014}, {"title": "Supervised cross-modal factor analysis for multiple modal data classification", "author": ["J. Wang", "Y. Zhou", "K. Duan", "J.J.-Y. Wang", "H. Bensmail"], "venue": "Systems, Man and Cybernetics (SMC), 2015 IEEE International Conference on. IEEE, 2015.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2015}, {"title": "Zht: A light-weight reliable persistent dynamic scalable zero-hop distributed hash table", "author": ["T. Li", "X. Zhou", "K. Brandstatter", "D. Zhao", "K. Wang", "A. Rajendran", "Z. Zhang", "I. Raicu"], "venue": "Parallel & Distributed Processing (IPDPS), 2013 IEEE 27th International Symposium on. IEEE, 2013, pp. 775\u2013787.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2013}, {"title": "Distributed key-value store on hpc and cloud systems", "author": ["T. Li", "X. Zhou", "K. Brandstatter", "I. Raicu"], "venue": "2nd Greater Chicago Area System Research Workshop (GCASR). Citeseer, 2013.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2013}, {"title": "Using simulation to explore distributed key-value stores for exascale system services", "author": ["K. Wang", "A. Kulkarni", "X. Zhou", "M. Lang", "I. Raicu"], "venue": "2nd Greater Chicago Area System Research Workshop (GCASR), 2013.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2013}, {"title": "Towards scalable distributed workload manager with monitoring-based weakly consistent resource stealing", "author": ["K. Wang", "M. Lang", "X. Zhou", "B. McClelland", "K. Qiao", "I. Raicu"], "venue": "HPDC \u201915 Proceedings of the 24th International Symposium on High-Performance Parallel and Distributed Computing, 2015, pp. 219\u2013222.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2015}, {"title": "Next generation job management systems for extreme-scale ensemble computing", "author": ["K. Wang", "X. Zhou", "H. Chen", "M. Lang", "I. Raicu"], "venue": "Proceedings of the 23rd international symposium on High-performance parallel and distributed computing, 2014, pp. 111\u2013114.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2014}, {"title": "Optimizing load balancing and data-locality with data-aware scheduling", "author": ["K. Wang", "X. Zhou", "T. Li", "D. Zhao", "M. Lang", "I. Raicu"], "venue": "Big Data (Big Data), 2014 IEEE International Conference on, 2014, pp. 119\u2013128.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2014}, {"title": "Fusionfs: Toward supporting data-intensive scientific applications on extreme-scale high-performance computing systems", "author": ["D. Zhao", "Z. Zhang", "X. Zhou", "T. Li", "K. Wang", "D. Kimpe", "P. Carns", "R. Ross", "I. Raicu"], "venue": "Big Data (Big Data), 2014 IEEE International Conference on, 2014, pp. 61\u201370.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2014}, {"title": "Unsupervised multi-level non-negative matrix factorization model: Binary data case", "author": ["Q. Sun", "P. Wu", "Y. Wu", "M. Guo", "J. Lu"], "venue": "Journal of Information Security, vol. 3, no. 04, p. 245, 2012.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2012}, {"title": "A multi-agent-based intelligent sensor and actuator network design for smart house and home automation", "author": ["Q. Sun", "W. Yu", "N. Kochurov", "Q. Hao", "F. Hu"], "venue": "Journal of Sensor and Actuator Networks, vol. 2, no. 3, pp. 557\u2013588, 2013.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2013}, {"title": "Human movement modeling and activity perception based on fiber-optic sensing system", "author": ["Q. Sun", "F. Hu", "Q. Hao"], "venue": "Human-Machine Systems, IEEE Transactions on, vol. 44, no. 6, pp. 743\u2013754, 2014.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2014}, {"title": "Mobile target scenario recognition via low-cost pyroelectric sensing system: Toward a context-enhanced accurate identification", "author": ["\u2014\u2014"], "venue": "Systems, Man, and Cybernetics: Systems, IEEE Transactions on, vol. 44, no. 3, pp. 375\u2013384, 2014.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2014}, {"title": "A multispectral photon-counting double random phase encoding scheme for image authentication", "author": ["F. Yi", "I. Moon", "Y.H. Lee"], "venue": "Sensors, vol. 14, no. 5, pp. 8877\u20138894, 2014.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2014}, {"title": "An empirical study on using the national vulnerability database to predict software vulnerabilities", "author": ["S. Zhang", "D. Caragea", "X. Ou"], "venue": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), vol. 6860 LNCS, no. PART 1, pp. 217\u2013231, 2011.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2011}, {"title": "After we knew it: empirical study and modeling of cost-effectiveness of exploiting prevalent known vulnerabilities across iaas cloud", "author": ["S. Zhang", "X. Zhang", "X. Ou"], "venue": "Proceedings of the 9th ACM symposium on Information, computer and communications security, 2014, pp. 317\u2013328.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2014}, {"title": "Effective network vulnerability assessment through model abstraction", "author": ["S. Zhang", "X. Ou", "J. Homer"], "venue": "Detection of Intrusions and Malware, and Vulnerability Assessment. Springer, 2011, pp. 17\u201334.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2011}, {"title": "Distilling critical attack graph surface iteratively through minimum-cost sat solving", "author": ["H. Huang", "S. Zhang", "X. Ou", "A. Prakash", "K. Sakallah"], "venue": "Proceedings of the 27th Annual Computer Security Applications Conference. ACM, 2011, pp. 31\u201340.", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2011}, {"title": "Investigating the application of moving target defenses to network security", "author": ["R. Zhuang", "S. Zhang", "A. Bardas", "S.A. DeLoach", "X. Ou", "A. Singhal"], "venue": "Resilient Control Systems (ISRCS), 2013 6th International Symposium on, 2013, pp. 162\u2013169.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2013}, {"title": "Dc microgrids: Economic operation and enhancement of resilience by hierarchical control", "author": ["L. Che", "M. Shahidehpour"], "venue": "IEEE Transactions Smart Grid, vol. 5, no. 5, pp. 2517\u20132526, 2014.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2014}, {"title": "Only connect: Microgrids for distribution system restoration", "author": ["L. Che", "M. Khodayar", "M. Shahidehpour"], "venue": "IEEE Power and Energy Magazine, vol. 12, no. 1, pp. 70\u201381, 2014.", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2014}, {"title": "Adaptive graph regularized nonnegative matrix factorization via feature selection", "author": ["J.-Y. Wang", "I. Almasri", "X. Gao"], "venue": "Pattern Recognition (ICPR), 2012 21st International Conference on, 2012, pp. 963\u2013966.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2012}, {"title": "Multiple graph regularized protein domain ranking", "author": ["J.J.-Y. Wang", "H. Bensmail", "X. Gao"], "venue": "BMC bioinformatics, vol. 13, no. 1, p. 307, 2012.", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2012}, {"title": "Doubly regularized portfolio with risk minimization", "author": ["W. Shen", "J. Wang", "S. Ma"], "venue": "Proceedings of the National Conference on Artificial Intelligence, vol. 2, 2014, pp. 1286\u20131292.", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2014}, {"title": "Transaction costs-aware portfolio optimization via fast lowner-john ellipsoid approximation", "author": ["W. Shen", "J. Wang"], "venue": "Twenty-Ninth AAAI Conference on Artificial Intelligence, 2015, pp. 1854 \u2013 1860.", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2015}, {"title": "Nonlinear passive control of a wave energy converter subject to constraints in irregular waves", "author": ["L. Wang", "J. Isberg"], "venue": "Energies, vol. 8, no. 7, pp. 6528\u20136542, 2015.", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2015}, {"title": "Constrained optimal control of a point absorber wave energy converter with linear generator", "author": ["L. Wang", "J. Engstr\u00f6m", "M. G\u00f6teman", "J. Isberg"], "venue": "Journal of Renewable and Sustainable Energy, vol. 7, no. 4, p. 043127, 2015.", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2015}, {"title": "Supervised learning of sparse context reconstruction coefficients for data representation and classification", "author": ["X. Liu", "J. Wang", "M. Yin", "B. Edwards", "P. Xu"], "venue": "Neural Computing and Applications, 2015.", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2015}, {"title": "Representing data by sparse combination of contextual data points for classification", "author": ["J. Wang", "Y. Zhou", "M. Yin", "S. Chen", "B. Edwards"], "venue": "Advances in Neural Networks\u2013ISNN 2015. Springer, 2015.", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2015}, {"title": "Image tag completion by local learning", "author": ["J. Wang", "Y. Zhou", "H. Wang", "X. Yang", "F. Yang", "A. Peterson"], "venue": "Advances in Neural Networks\u2013ISNN 2015. Springer, 2015.", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "To solve this problem, Joachims [1] proposed a support vector machine learning method for multivariate Performance measures (SVM ).", "startOffset": 32, "endOffset": 35}, {"referenceID": 1, "context": "When data samples of different classes cannot be separated by a linear boundary, it is suggested to employ the kernel trick to map the data samples to a nonlinear high-dimensional data space so that a linear boundary could be learned [2], [3], [4].", "startOffset": 234, "endOffset": 237}, {"referenceID": 2, "context": "When data samples of different classes cannot be separated by a linear boundary, it is suggested to employ the kernel trick to map the data samples to a nonlinear high-dimensional data space so that a linear boundary could be learned [2], [3], [4].", "startOffset": 239, "endOffset": 242}, {"referenceID": 3, "context": "When data samples of different classes cannot be separated by a linear boundary, it is suggested to employ the kernel trick to map the data samples to a nonlinear high-dimensional data space so that a linear boundary could be learned [2], [3], [4].", "startOffset": 244, "endOffset": 247}, {"referenceID": 4, "context": "Joachims and Yu [5] also extended the SVM to its kernel version to handle the nonlinearly distributed data.", "startOffset": 16, "endOffset": 19}, {"referenceID": 4, "context": "In [5], the RBF-Kernel is used to classification problems on some data sets without any justification, but it is highly doubt if this kernel is suitable for other data sets.", "startOffset": 3, "endOffset": 6}, {"referenceID": 5, "context": "This framework is called Multi-Kernel Learning (MKL) since we explore the nonlinear kernel spaces of multiple kernels [6].", "startOffset": 118, "endOffset": 121}, {"referenceID": 6, "context": "Under the framework of kernel learning [7], an sample vector can be mapped into a high dimensional nonlinear Hilbert Space, via a implicit mapping function \u03c6 : x \u2192 \u03c6(x) \u2208 R \u2032 , where d \u226b d is the dimension of the Hilbert Space.", "startOffset": 39, "endOffset": 42}, {"referenceID": 7, "context": "Experiment I: Allergen prediction In the first experiment, we perform the proposed to the problem of allergen prediction to optimized various prediction performance measures [8].", "startOffset": 174, "endOffset": 177}, {"referenceID": 7, "context": "1) Dataset and protocol: In this experiment, we used a dataset constructed by Dang and Lawrence [8].", "startOffset": 96, "endOffset": 99}, {"referenceID": 8, "context": "To extract feature from each protein sequence, we used the bag-of-words method [9].", "startOffset": 79, "endOffset": 82}, {"referenceID": 4, "context": "2) Results: We compare the proposed multi-kernel learning based multivariate performance measures optimization algorithm agains the original kernel version of SVM , cuttingplane subspace pursuit (CPSP) algorithm [5].", "startOffset": 212, "endOffset": 215}, {"referenceID": 9, "context": "Moreover, three different variations of SVM are also compared as the state-of-the-art multivariate performance measures optimization methods, including the performance measure optimization method by classifier adaptation (CAPO) [10], the feature selection method for multivariate performance measures optimization (FSPO) [11], and the non-decomposable loss functions optimization method (NDLO) [12].", "startOffset": 228, "endOffset": 232}, {"referenceID": 10, "context": "Moreover, three different variations of SVM are also compared as the state-of-the-art multivariate performance measures optimization methods, including the performance measure optimization method by classifier adaptation (CAPO) [10], the feature selection method for multivariate performance measures optimization (FSPO) [11], and the non-decomposable loss functions optimization method (NDLO) [12].", "startOffset": 321, "endOffset": 325}, {"referenceID": 11, "context": "Moreover, three different variations of SVM are also compared as the state-of-the-art multivariate performance measures optimization methods, including the performance measure optimization method by classifier adaptation (CAPO) [10], the feature selection method for multivariate performance measures optimization (FSPO) [11], and the non-decomposable loss functions optimization method (NDLO) [12].", "startOffset": 394, "endOffset": 398}, {"referenceID": 12, "context": "[13].", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 107, "endOffset": 111}, {"referenceID": 14, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 113, "endOffset": 117}, {"referenceID": 15, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 119, "endOffset": 123}, {"referenceID": 16, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 125, "endOffset": 129}, {"referenceID": 17, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 131, "endOffset": 135}, {"referenceID": 18, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 137, "endOffset": 141}, {"referenceID": 19, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 143, "endOffset": 147}, {"referenceID": 20, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 149, "endOffset": 153}, {"referenceID": 21, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 155, "endOffset": 159}, {"referenceID": 22, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 187, "endOffset": 191}, {"referenceID": 23, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 193, "endOffset": 197}, {"referenceID": 24, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 199, "endOffset": 203}, {"referenceID": 25, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 205, "endOffset": 209}, {"referenceID": 26, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 211, "endOffset": 215}, {"referenceID": 27, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 217, "endOffset": 221}, {"referenceID": 28, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 223, "endOffset": 227}, {"referenceID": 29, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 229, "endOffset": 233}, {"referenceID": 30, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 235, "endOffset": 239}, {"referenceID": 31, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 241, "endOffset": 245}, {"referenceID": 32, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 280, "endOffset": 284}, {"referenceID": 33, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 286, "endOffset": 290}, {"referenceID": 34, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 292, "endOffset": 296}, {"referenceID": 35, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 298, "endOffset": 302}, {"referenceID": 36, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 304, "endOffset": 308}, {"referenceID": 37, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 310, "endOffset": 314}, {"referenceID": 38, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 316, "endOffset": 320}, {"referenceID": 39, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 322, "endOffset": 326}, {"referenceID": 40, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 358, "endOffset": 362}, {"referenceID": 41, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 364, "endOffset": 368}, {"referenceID": 42, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 370, "endOffset": 374}, {"referenceID": 43, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 376, "endOffset": 380}, {"referenceID": 44, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 382, "endOffset": 386}, {"referenceID": 45, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 388, "endOffset": 392}, {"referenceID": 46, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 394, "endOffset": 398}, {"referenceID": 47, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 400, "endOffset": 404}, {"referenceID": 48, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 406, "endOffset": 410}, {"referenceID": 49, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 412, "endOffset": 416}, {"referenceID": 50, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 449, "endOffset": 453}, {"referenceID": 51, "context": "In the future, we will also explore the potential of using the proposed methods to bioinformatics problems [14], [15], [16], [17], [18], [19], [20], [21], [22], integrated circuit design [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], multiple model big data analysis [33], [34], [35], [36], [37], [38], [39], [40], software and network security [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], and power systems optimization [51], [52].", "startOffset": 455, "endOffset": 459}, {"referenceID": 52, "context": "Moreover, we will also improve the proposed method by regularizing the learning of classifier by graphs [53], [54], [55], [56], [57], [58], [59], [60], [61].", "startOffset": 104, "endOffset": 108}, {"referenceID": 53, "context": "Moreover, we will also improve the proposed method by regularizing the learning of classifier by graphs [53], [54], [55], [56], [57], [58], [59], [60], [61].", "startOffset": 110, "endOffset": 114}, {"referenceID": 54, "context": "Moreover, we will also improve the proposed method by regularizing the learning of classifier by graphs [53], [54], [55], [56], [57], [58], [59], [60], [61].", "startOffset": 116, "endOffset": 120}, {"referenceID": 55, "context": "Moreover, we will also improve the proposed method by regularizing the learning of classifier by graphs [53], [54], [55], [56], [57], [58], [59], [60], [61].", "startOffset": 122, "endOffset": 126}, {"referenceID": 56, "context": "Moreover, we will also improve the proposed method by regularizing the learning of classifier by graphs [53], [54], [55], [56], [57], [58], [59], [60], [61].", "startOffset": 128, "endOffset": 132}, {"referenceID": 57, "context": "Moreover, we will also improve the proposed method by regularizing the learning of classifier by graphs [53], [54], [55], [56], [57], [58], [59], [60], [61].", "startOffset": 134, "endOffset": 138}, {"referenceID": 58, "context": "Moreover, we will also improve the proposed method by regularizing the learning of classifier by graphs [53], [54], [55], [56], [57], [58], [59], [60], [61].", "startOffset": 140, "endOffset": 144}, {"referenceID": 59, "context": "Moreover, we will also improve the proposed method by regularizing the learning of classifier by graphs [53], [54], [55], [56], [57], [58], [59], [60], [61].", "startOffset": 146, "endOffset": 150}, {"referenceID": 60, "context": "Moreover, we will also improve the proposed method by regularizing the learning of classifier by graphs [53], [54], [55], [56], [57], [58], [59], [60], [61].", "startOffset": 152, "endOffset": 156}], "year": 2015, "abstractText": "In this paper, we propose a multi-kernel classifier learning algorithm to optimize a given nonlinear and nonsmoonth multivariate classifier performance measure. Moreover, to solve the problem of kernel function selection and kernel parameter tuning, we proposed to construct an optimal kernel by weighted linear combination of some candidate kernels. The learning of the classifier parameter and the kernel weight are unified in a single objective function considering to minimize the upper boundary of the given multivariate performance measure. The objective function is optimized with regard to classifier parameter and kernel weight alternately in an iterative algorithm by using cutting plane algorithm. The developed algorithm is evaluated on two different pattern classification methods with regard to various multivariate performance measure optimization problems. The experiment results show the proposed algorithm outperforms the competing methods.", "creator": "LaTeX with hyperref package"}}}