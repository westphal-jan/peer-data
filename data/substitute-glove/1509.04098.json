{"id": "1509.04098", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Sep-2015", "title": "Fame for sale: efficient detection of fake Twitter followers", "abstract": "$ \\ textit {Fake adherents} $ are most Twitter accounts generally created both inflate the number of dissidents of a more account. Fake christianity but turning meant the public support and beyond, since they actually alter formulation like increasing and influence in the Twittersphere - hence impacting on weakening, politics, and established. In this paper, we substantial along different dimensions. First, thought review some of new as individually existing studio and rules (proposed whose Academia but Media) for transient Twitter value detection. Second, we any gave uphill barcode one verified finding as items pragmatist amounts. Such timed rescaling is asserting additionally still it assessment heritage. Then, still fear the tricky dataset with minibus whose set of pistol - writing camelcase transformed made then experts adopt once uses. Our likely show seen highly and second rules proposed took Media provide woefully performance to personal tags catholics, saw features policy between the past was Academia both skype method enable good doubt. Building on following and promising originally, no approve an classifiers fact into terms example reduction of cardiotoxicity on cost made participate the data because from template through features. The event result in a entitled $ \\ textit {Class A} $ respelling, general going take thwart overfitting, inter-continental improvement same once usage by within less costly numerous, instead say able still correctly classify more which 52% seen the billions a part includes training previous. We because addition but analysis jazz - also variability analysis, the assess well focused severity particular same country the visual personnel by the codice_44. The findings showed in part printed, as half most supported other a thorough therapies objective besides curious following their to, recently timetable present get another immediate investigation two while novel merely of fake Twitter dissidents.", "histories": [["v1", "Mon, 14 Sep 2015 13:59:11 GMT  (44kb)", "http://arxiv.org/abs/1509.04098v1", null], ["v2", "Tue, 10 Nov 2015 17:31:40 GMT  (44kb)", "http://arxiv.org/abs/1509.04098v2", null]], "reviews": [], "SUBJECTS": "cs.SI cs.CR cs.LG", "authors": ["stefano cresci", "roberto di pietro", "marinella petrocchi", "angelo spognardi", "maurizio tesconi"], "accepted": false, "id": "1509.04098"}, "pdf": {"name": "1509.04098.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Stefano Cresci", "Roberto Di Pietro", "Marinella Petrocchi", "Angelo Spognardi", "Maurizio Tesconi"], "emails": ["stefano.cresci@iit.cnr.it", "roberto.di_pietro@alcatel-lucent.com", "marinella.petrocchi@iit.cnr.it", "angelo.spognardi@iit.cnr.it", "maurizio.tesconi@iit.cnr.it"], "sections": [{"heading": null, "text": "ar X\niv :1\n50 9.\n04 09\n8v 1\n[ cs\n.S I]\n1 4\nSe p\n20 15\nFake followers are those Twitter accounts specifically created to inflate the number of followers of a target account. Fake followers are dangerous for the social platform and beyond, since they may alter concepts like popularity and influence in the Twittersphere\u2014hence impacting on economy, politics, and society. In this paper, we contribute along different dimensions. First, we review some of the most relevant existing features and rules (proposed by Academia and Media) for anomalous Twitter accounts detection. Second, we create a baseline dataset of verified human and fake follower accounts. Such baseline dataset is publicly available to the scientific community. Then, we exploit the baseline dataset to train a set of machine-learning classifiers built over the reviewed rules and features. Our results show that most of the rules proposed by Media provide unsatisfactory performance in revealing fake followers, while features proposed in the past by Academia for spam detection provide good results. Building on the most promising features, we revise the classifiers both in terms of reduction of overfitting and cost for gathering the data needed to compute the features. The final result is a novel Class A classifier, general enough to thwart overfitting, lightweight thanks to the usage of the less costly features, and still able to correctly classify more than 95% of the accounts of the original training set. We ultimately perform an information fusion-based sensitivity analysis, to assess the global sensitivity of each of the features employed by the classifier. The findings reported in this paper, other than being supported by a thorough experimental methodology and interesting on their own, also pave the way for further investigation on the novel issue of fake Twitter followers. Keywords: Twitter, fake followers, anomalous account detection, baseline dataset, machine learning\n\u2729An extended version of this preprint has been accepted for publication on Elsevier\u2019s journal Decision Support Systems (in press).\n\u2217Corresponding author Email addresses: stefano.cresci@iit.cnr.it (Stefano Cresci), roberto.di_pietro@alcatel-lucent.com (Roberto Di\nPietro), marinella.petrocchi@iit.cnr.it (Marinella Petrocchi), angelo.spognardi@iit.cnr.it (Angelo Spognardi), maurizio.tesconi@iit.cnr.it (Maurizio Tesconi)\n1Phone number: +39 050 315 3376\nPreprint submitted to Elsevier September 15, 2015"}, {"heading": "1. Introduction", "text": "Originally started as a personal microblogging site, Twitter has been transformed by common use to an information publishing venue. Statistics reported about a billion of Twitter subscribers, with 302 million monthly active users2. Twitter annual advertising revenue in 2014 has been estimated to around $480 million3. Popular public characters, such as actors and singers, as well as traditional mass media (radio, TV, and newspapers) use Twitter as a new media channel.\nSuch a versatility and spread of use have made Twitter the ideal arena for proliferation of anomalous accounts, that behave in unconventional ways. Academia has mostly focused its attention on spammers, those accounts actively putting their efforts in spreading malware, sending spam, and advertising activities of doubtful legality [1, 2, 3, 4]. To enhance their effectiveness, these malicious accounts are often armed with automated twitting programs, as stealthy as to mimic real users, known as bots. In the recent past, media have started reporting that the accounts of politicians, celebrities, and popular brands featured a suspicious inflation of followers4. So-called fake followers correspond to Twitter accounts specifically exploited to increase the number of followers of a target account. As an example, during the 2012 US election campaign, the Twitter account of challenger Romney experienced a sudden jump in the number of followers. The great majority of them has been later claimed to be fake5. Similarly, before the last general Italian elections (February 2013), online blogs and newspapers had reported statistical data over a supposed percentage of fake followers of major candidates6. At a first glance, acquiring fake followers could seem a practice limited to foster one\u2019s vanity\u2014a maybe questionable, but harmless practice. However, artificially inflating the number of followers can also be finalized to make an account more trustworthy and influential, in order to stand from the crowd and to attract other genuine followers [5]. Recently, banks and financial institutions in U.S. have started to analyze Twitter and Facebook accounts of loan applicants, before actually granting the loan7. Thus, to have a \u201cpopular\u201d profile can definitely help to augment the creditworthiness of the applicant. Similarly, if the practice of buying fake followers is adopted by malicious accounts, as spammers, it can act as a way to post more authoritative messages and launch more effective advertising campaigns [6]. Fake followers detection seems to be an easy task for many bloggers, that suggest their \u201cgolden rules\u201d and provide a series of criteria to be used as red flags to classify a Twitter account behavior. However, such rules are\n2C. Smith, By The Numbers: 150+ Amazing Twitter Statistics, http://goo.gl/o1lNi8 - June 2015. Last checked: July 23, 2015.\n3Statistic Brain, Twitter statistics, http://goo.gl/XEXB1 - March 2015. Last checked: July 23, 2015. 4Corriere Della Sera (online ed.), Academic Claims 54% of Grillo\u2019s Twitter Followers are Bogus, http://goo.gl/qi7Hq - July 2012. Last checked: July 23, 2015. 5New York Times (online ed.), Buying Their Way to Twitter Fame, http://goo.gl/VLrVK, - August 2012. Last checked: July 23, 2015. 6The Telegraph (online ed.), Human or bot? Doubts over Italian comic Beppe Grillo\u2019s Twitter followers, http://goo.gl/2yEgT - July 2012. Last checked: July 23, 2015. 7Le Monde (online ed.), Dis-moi combien d\u2019amis tu as sur Facebook, je te dirai si ta banque va t\u2019accorder un pre\u0302t, http://goo.gl/zN3PJX - Sept. 2013. Last checked: July 23, 2015.\nusually paired neither with analytic algorithms to aggregate them, nor with validation mechanisms. As for Academia, researchers have focused mainly on spam and bot detection, with brilliant results characterizing Twitter accounts based on their (non-)human features, mainly by means of machine-learning classifiers trained over manually annotated sets of accounts.\nTo the best of our knowledge, however, despite fake followers constitute a widespread phenomenon with\nboth economical and social impacts, in the literature the topic has not been deeply investigated yet.\nContributions\nThe goal of this work is to shed light on the phenomenon of fake Twitter followers, aiming at overcoming current limitations in their characterization and detection. In particular, we provide the following contributions. First, we build a baseline dataset of Twitter accounts where humans and fake followers are known a priori. Second, we test known methodologies for bot and spam detection on our baseline dataset. In particular, we test the Twitter accounts in our reference set against algorithms based on: (i) single classification rules proposed by bloggers, and (ii) feature sets proposed in the literature for detecting spammers. The results of the analysis suggest that fake followers detection deserves specialized mechanisms: specifically, algorithms based on classification rules do not succeed in detecting the fake followers in our baseline dataset. Instead, classifiers based on features sets for spambot detection work quite well also for fake followers detection. Third, we classify all the investigated rules and features based on the cost required for gathering the data needed to compute them. Building on theoretical calculations and empirical evaluations, we show how the best performing features are also the most costly ones. The novel results of our analysis show that data acquisition cost often poses a serious limitation to the practical applicability of such features. Finally, building on the crawling cost analysis, we design and implement lightweight classifiers that make use of the less costly features, while still being able to correctly classify more than 95% of the accounts of our training dataset. In addition, we also validated the detection performances of our classifiers over two other sets of human and fake follower accounts, disjoint from the original training dataset.\nRoad map\nThe remainder of this paper is structured as follows. Section 2 considers and compares related work in the area of Twitter spam and bot detection. Section 3 describes our baseline dataset. In Section 4, we evaluated a set of criteria for fake Twitter followers detection promoted by Social Media analysts using our baseline dataset. In Section 5, we examine features used in previous works for spam detection of Twitter accounts. In Section 6 we compute the cost for extracting the features our classifiers are based on. A lightweight and efficient classifier is also provided, attaining a good balance between fake followers detection capability and crawling cost. Finally, Section 7 concludes the paper."}, {"heading": "2. Related Work", "text": "Quoting from [7], \u201cA fake Twitter account is considered as one form of deception (i.e., deception in both the content and the personal information of the profiles as well as deception in having the profile follow others not because of personal interest but because they get paid to do so).\u201d The second characterization for deception is exactly the one we deal with in our paper. We specifically consider fake followers as those Twitter accounts appropriately created and sold to customers, which aim at magnifying their influence and engagement to the eyes of the world, with the illusion of a big number of followers.\nSo defined fake followers are only an example of anomalous accounts which are spreading over Twitter. Anomalies have been indeed identified in the literature as either spammers (i.e. accounts that advertise unsolicited and often harmful content, containing links to malicious pages [8]), or bots (i.e., computer programs that control social accounts, as stealthy as to mimic real users [9]), or cyborgs (i.e., accounts that interweave characteristics of both manual and automated behavior [10]). Finally, there are fake followers, accounts massively created to follow a target account and that can be bought from online accounts markets."}, {"heading": "2.1. Grey literature and Online Blogs", "text": "Before covering the academic literature, we briefly report on online documentation that presents a series of intuitive fake follower detection criteria, though not proved to be effective in a scientific way. The reason why we cite this work is twofold: on the one hand, online articles and posts testify the quest for a correct discrimination between genuine and fake Twitter followers; on the other hand, we aim at assessing in a scientific manner whether such criteria could actually be employed for fake followers detection.\nAs an example, a well-known blogger in [11] indicates as possible bots-like distinctive signals the fact that bots accounts: 1) have usually a huge amount of following and a small amount of followers; 2) tweet the same thing to everybody; and, 3) play the follow/unfollow game, i.e. they follow and then unfollow an account usually within 24 hours. Criteria advertised by online blogs are mainly based on common sense and the authors usually do not even suggest how to validate them.\nA series of reports published by the firm Digital evaluations [12] have attracted the attention of Italian and European newspapers and magazines, raising doubts on the Twitter popularity of politicians and leading international companies. A number of criteria, inspired by common sense and denoting human behavior, are listed in the reports and used to evaluate a sample of the followers of selected accounts. For each criterion satisfied by a follower, a human score is assigned. For each not fulfilled criterion, either a bot or neutral score is assigned. According to the total score, Twitter followers are classified either as humans, as bots or as neutral (in the latter case, there is not enough information to assess their nature), providing a quality score of the effective influence of the followed account. The results in [12], however, lack a validation phase.\nFinally, some companies specialized in social media analysis offer online services to estimate how much a Twitter account is genuine in terms of its followers [13, 14, 15]. However, the criteria used for the\nanalysis are not publicly disclosed and just partially deductible from information available on their web sites. Moreover, as demonstrated in our previous work [16], these analyses are affected by several biases like small and statistically unsound sampling strategies."}, {"heading": "2.2. Academic literature", "text": "In recent years, spam detection on Twitter has been the matter of many investigations, approaching the issue from several points of view. As an example, a branch of research focused on the textual content of tweets [4, 3, 17], studying the redirection of embedded URLs in tweets [18], and classifying the URLs landing pages [19]. Other works tackled the problem of deception on Twitter via epistemology. For instance, in [20] authors evaluate 4 epistemological features for the task of deception detection: authority, plausibility and support, independent corroboration, and presentation.\nWork in [21] overcomes the limitation of not being able to correctly label those tweets without URLs as spam tweets, by proposing a composite tool, able to match incoming tweets with underlying templates commonly used by spammers. Instead of considering the content of tweets, work in [7] tries to classify if an account can be trusted or not based on possibly inconsistent information originating from the profile of the account only.\nA series of works investigate spammers on microblogging platforms through a multi-feature approach, including features on the profile, the behavior, and the timeline of an account. Within this research line, we cite here [8], [2], and [22]. The work in [8] presents an analysis on how spammers operate on Facebook, Twitter, and MySpace, reporting that the suspicious accounts shared some common traits on specific features. Those served as input to a machine learning-based classifier [23] leading to the detection of more than 15,000 spam profiles, that Twitter promptly deleted. In [2], the authors propose a taxonomy of criteria for detecting Twitter spammers. A series of experiments show how the newly designed criteria have higher detection rates, when compared to the existing ones. In [22], the authors leverage a combination of behavioral features (such as tweeting and retweeting activities), network features (such as the number of an account\u2019s followers and friends), and content-based features to develop a hybrid mathematical model for spammer detection in Weibo, the Chinese microblogging site resembling Twitter.\nThe authors of [10] classify Twitter accounts in three classes: humans, bot, and cyborgs. The latter class represents either bot-assisted humans or human-assisted bots. The authors used a decision maker based on three specialized components that considered the content and timing of tweets and some account properties.\nThe algorithms proposed in [24, 4] aim at spotting groups of automated malicious Twitter accounts as quickly as possible, to avoid the accounts\u2019 owners from taking advantage of them.Thus, authors apply clustering algorithms to group accounts created within a short period of time, considering, among others, name- and content-based features.\nIn [25], the authors list several criteria to detect clients and victims of Twitter account markets, that are\nonline services offering their subscribers to provide followers in exchange for a fee, and to spread promotional tweets on their behalf. In another work [26], the same research team provides more details about the account markets, analyzing additional properties and characteristics of their customers (e.g., the dynamics of followers and friends and the ability of generating engagement), and providing a classifier for the detection of both markets and market customers. The authors of [27] monitor prices, availability, and fraud perpetrated by a set of merchants of Twitter accounts over the course of a ten-months period. Such a research is a spotlight on techniques and methodologies that accounts markets exploit to create and register fraudulent accounts, from CAPTCHA solving services, to deceitful email credentials and a diverse pool of IP addresses to evade blacklisting. In collaboration with Twitter itself, the authors developed a classifier to detect such fraudulent accounts, which were consequently suspended.\nIt is worth noting that the cited selection of academic works is not exhaustive. However, it considers a huge collection of criteria, which we further leverage for our approach to fake Twitter followers detection. There are other works for spam detection, not detailed here, like [1, 28, 29, 30, 31, 32], which base their results on subsets, or on slightly modified versions, of criteria considered by the selected set of related work."}, {"heading": "2.3. Differences and similarities with our approach", "text": "The goal of our research is the automatic detection of those Twitter accounts specifically created to inflate the number of followers of some target account (so called fake Twitter followers). A priori, both spammers, bots, and genuine users\u2019 accounts could fall in the macro-category of fake followers, and specific features already proved effective in the literature for spotting spammers and bots could work also in the case of fake followers. It was indeed this observation that initially drove the authors of this paper towards the direction of testing rules and features from past works on a reference dataset of genuine accounts and fake followers. This contributed to prune those rules and features that behaved worst in detecting fake followers, and leave the ones that well behave.\nFrom a technical point of view, in our experiments we rely on machine learning-based classifiers exploiting features of 1) profile, 2) activity, and 3) relationships of the accounts, similarly to [8, 2]. Instead, we do not rely on features inherent to specific contents of tweets, such as the presence of URLs and the semantics of the text [17, 19]. We move beyond the mere application of already tested features to a new dataset, since we revise our classifiers to reduce overfitting and cost for data gathering, as illustrated in Sections 5 and 6.\nFinally, similarly to [26], we bought fake Twitter followers from different markets available on the Web. We conducted such an exercise independently from [26] and, moreover, goals of the two works are quite different, ours focusing on accounts sold by these markets, while the other targeting their customers. As for the genuine part of our baseline dataset, we recruit accounts of people that have voluntarily adhered to our campaign, and leverage a dataset of annotated accounts, belonging to people active on Twitter within a particular period of time on a specific domain, and whose authenticity has been verified. However, willing\nto test our classifiers over a representative sample of the entire Twitter population, we also approach the construction of a test set by randomly picking: 1) a sample of Barack Obama\u2019s followers, and 2) a sample of the Twitter population."}, {"heading": "3. Baseline datasets", "text": "In this section we present the datasets of Twitter accounts used to conduct our empirical study throughout the paper. We detail how we collected each of them and how we verified if they were genuine humans or fake followers. Despite the final size of the baseline dataset, to perform our research, we altogether crawled 9 millions of Twitter accounts and about 3 millions of tweets. To foster investigation on the novel issue of fake Twitter followers, our baseline dataset has been made publicly available for research purposes [33]."}, {"heading": "3.1. The Fake Project", "text": "The Fake Project started its activities on December 12, 2012, with the creation of the Twitter account @TheFakeProject. Its profile reports the following motto: \u201cFollow me only if you are NOT a fake\u201d and explains that the initiative is linked with a research project owned by researchers at IIT-CNR, in Pisa-Italy. In a first phase, the owners contacted further researchers and journalists to advertise the initiative and also foreign journalists and bloggers supported the initiative in their countries. In a twelve days period (Dec 12-24, 2012), the account has been followed by 574 followers. Through the Twitter APIs, we crawled a series of public information about these followers together with that of their followers and followings. For this dataset, we crawled the 574 accounts, leading to the collection of 616,193 tweets and 971,649 relationships (namely, linked Twitter accounts).\nAll those followers voluntarily joined the project. To include them in our reference set of humans, we also launched a verification phase. Each follower received a direct message on Twitter from @TheFakeProject, containing an URL to a CAPTCHA, unique for each follower. We consider as \u201ccertified humans\u201d all the 469 accounts out of the 574 followers that successfully completed the CAPTCHA. In the remainder of this section this dataset is referred to as TFP ."}, {"heading": "3.2. #elezioni2013 dataset", "text": "The #elezioni2013 dataset, henceforth E13 , was born to support a research initiative for a sociological study carried out in collaboration with the University of Perugia and the Sapienza University of Rome. The study focused on the strategic changes in the Italian political panorama for the 3-year period 2013-2015. Researchers identified 84,033 unique Twitter accounts that used the hashtag #elezioni2013 in their tweets, during the period between January 9 and February 28, 2013. Identification of these accounts has been based on specific keyword-driven queries on the username and biography fields of the accounts\u2019 profiles. Keywords include blogger, journalist, social media strategist/analyst, and congressperson. Specific names of political parties have been also searched. In conclusion, all the accounts belonging to politicians and candidates,\nparties, journalists, bloggers, specific associations and groups, and whoever somehow was officially involved in politics, have been discarded. The remaining accounts (about 40k) have been classified as citizens. This last set has been sampled (with confidence level 95% and confidence interval 2.5), leading to a final set of 1488 accounts, that have been subject to a manual verification to determine the nature of their profiles and tweets. The manual verification process has been carried out by two sociologists from the University of Perugia, Italy. It involved the analysis of profile pictures, biographies, and timeline of the accounts under investigation. Accounts not having a biography or a profile picture have been discarded. URLs in biographies have also been manually checked to allow for a deeper analysis of the subject. Only accounts labeled as humans by both the sociologists have been included in the E13 dataset. Overall, the manual verification phase lasted roughly two months. As a result, 1481 accounts became part of dataset E13 ."}, {"heading": "3.3. Baseline dataset of human accounts", "text": "The above introduced datasets form our final set, labeled HUM , of 1950 verified human accounts. It is worth noting how the two subsets differ from each other. The TFP set consists of accounts that have been recruited on a volunteer base: people involved in the initiative aimed to be part of an academic study for discovering fake followers on Twitter, and are a mixture of researchers and social media experts and journalists, mostly from Italy, but also from US and other European countries. The E13 set consists of particularly active Italian Twitter users, with different professional background and belonging to diverse social classes, sharing a common interest for politics, but that do not belong to the following categories: politicians, parties, journalists, bloggers."}, {"heading": "3.4. Baseline dataset of fake followers", "text": "In April, 2013, we bought 3000 fake accounts from three different Twitter online markets. In particular, we bought 1000 fake accounts from http:// fastfollowerz.com , 1000 from http:// intertwitter.com , and 1000 fake accounts from http:// twittertechnology.com , at a price of $19, $14 and $13 respectively. Surprisingly, fastfollowerz and intertwitter gave us a few more accounts than what we paid for, respectively 1169 and 1337 instead of 1000. We crawled all these accounts to build a fastfollowerz dataset, labeled FSF , and an intertwitter dataset labeled INT . Instead, we were unable to crawl all the 1000 fake followers bought from twittertechnology since 155 of them got suspended almost immediately. The remaining 845 accounts constitute the twittertechnology dataset, which is labeled TWT .\nWe acknowledge that our fake followers dataset is just illustrative, and not exhaustive, of all the possible existing sets of fake followers. However, it is worth noting that we found the Twitter accounts marketplaces by simply Web searching them on the most common search engines. Thus, we can argue that our dataset represents what was easily possible to find on the Web at the time of searching."}, {"heading": "3.5. Baseline dataset of fake followers and human accounts", "text": "The final baseline dataset exploited in our experiments is composed of both fake and human profiles. In the following, we briefly discuss the distribution between fake and human accounts that has been chosen for this dataset. Many machine-learning techniques are affected by the imbalance of the natural distributions of the minority and majority classes. This is why, for example, works in the literature have studied how the decision tree-based techniques perform when varying the distribution of the training set. In particular, Weiss and Provost, in [34], considered the performances of decision-tree based classifiers to predict the samples of 26 different datasets, with different distributions between the minority and majority classes. The conclusions of their investigation have shown that the metric used to evaluate the performance of the different classifiers changes the optimal distribution of the classes for the training set. For example, after their empirical analysis, using accuracy as evaluation metric, 9 out of the 26 datasets have the optimal distribution very different from the natural one, while, when using the AUC as evaluation metric, this number grows to 14 out of the 26. Moreover, the optimal distribution has an oversampling of the minority class (there are also cases when the best classifier is obtained with an oversampling up to 90% of the minority class samples).\nHere, we face another fundamental issue: we do not precisely know the real (natural) distribution of fake followers and human accounts. In 2013, the Twitter staff conjectured that the number of \u201cfalse or spam accounts should represent less than 5% of our MAUs\u201d (where MAUs refer to monthly active users) [35]. However, MAUs can be assimilated neither to a random sample of Twitter accounts nor to the followers of a given account. Moreover, if an account has bought fake followers, then its distribution of fake followers and human followers can vary dramatically from the natural distribution that one can find, either among MAUs, or among all the Twitter accounts in the Twittersphere. In conclusion, the estimation of 5% as false or spam accounts, in the whole Twitter, can not be directly extended to the fake followers of a given account.\nAlthough Twitter has never disclosed the total number of registered users, unofficial sources claim that the Twitter accounts created up to date are many more than the MAUs. This is why we made a conservative assumption, considering a balanced distribution of fake followers and human followers as our baseline dataset.\nTo validate this assumption, we performed the experiments in [34] to our dataset. We progressively varied the class distribution of fake followers and human followers in the dataset, from 5%\u201395% to 95%\u20135% (respectively 100 humans\u20131900 fake followers, 1900 humans\u2013100 fake followers), and used the obtained dataset to train J48 classifiers, considering their performances with cross-validation. The trained classifiers obtained their best results on a balanced distribution of humans and fake followers. To obtain a balanced dataset, we randomly undersampled the total set of fake accounts (i.e., 3351) to match the size of the HUM dataset of verified human accounts. Thus, we built a baseline dataset of 1950 fake followers, labeled FAK . The final baseline dataset for this work includes both the HUM dataset and the FAK dataset for a total of 3900 Twitter accounts. This balanced dataset is labeled BAS in the remainder of the paper and has been exploited for all the experiments described in this work (where not otherwise specified). Table 1 shows the number of accounts, tweets and relationships contained in the datasets described in this section."}, {"heading": "4. Fake detection with algorithms based on classification rules", "text": "In this section, we detail three procedures, originally proposed by bloggers and social media analysts, explicitly conceived for fake followers and bot accounts detection. These proposals were introduced in [12, 11, 14]. The work we focus on in this section is not directly attributable to academic work. However, it is an example of the spreading interest on the phenomenon of fake Twitter followers by Media and Social Marketing companies. Although we do not expect these proposals to satisfactorily perform for the complex task of fake followers detection, we believe a thorough analysis of the proposed criteria could still provide some useful insights. Coincidentally, all the procedures are proposed as algorithms relying on a list of rules, or criteria: each account to be classified is checked against all the rules and the outputs of the checks must be combined together in order to obtain the final classification. Unfortunately in many cases, details on how to combine the criteria to obtain the final classification of an account is not publicly available. Details on how aggregation has been performed are provided in [12] only. Driven by the provided details, we implement the full algorithm described in [12] and we present its detection performances in Section 4.5. In addition, for each of the procedures, we report the criteria as indicated by the original sources and we further specify how we have implemented them into rules suitable to be applied over our datasets. We also detail the reasons for our implementation choices.\nIn this section, we mainly focus on the application of each single rule over our dataset to assess its strength (or weakness) in discriminating fake followers. In Section 6, we combine all the rules together with the features analyzed in Section 5, to assess their collective classification power. This is because a single rule \u2013 or feature \u2013 alone may not perform well in classifying fake and human accounts, but it may improve the detection if used in combination with other ones. Indeed, it is worth noting that some of the criteria analyzed in this section have been actually exploited by the classifiers built in Section 6.\nThroughout the sequel of the paper we use the term \u201cfriends\u201d to denote the users followed by an account\n(i.e., if A follows B, B is a friend of A)."}, {"heading": "4.1. Followers of political candidates", "text": "Camisani-Calzolari [12] carried out a series of tests over samples of Twitter followers of Romney and Obama, for the last US presidential elections, as well as for popular Italian politicians. In [12] it is detailed an algorithm to evaluate an account based on some of its public features. The cited algorithm has enough details to be reproducible: it assigns human/active and bot/inactive scores and classifies an account considering the gap between the sum of the two scores. In particular, the algorithm assigns to the examined accounts 1 (or more, where specified) human point for each of the criteria in Table 2. Moreover, the account receives 2 bot points if it only uses APIs. Finally, for each criterion that fails to be verified, the account receives 1 bot point, with the exception of criteria 8, 13, 14, 15, 16 and 17: in this cases, no bot points are assigned. To verify those rules, we referred to the source metadata of the tweets, that contains a different value representing the platform used to post a tweet. In particular, concerning the above rules, we considered the source metadata with the values iphone, android, foursquare, instagram and web, respectively, and we assigned 1 human point for each of the values found at least once within the collected tweets of the account. For the criterion 21, 2 bot points are assigned if no tweets of the account have been retweeted by other users. Considering rule 8, geo-localization is related to tweets. Consequently, we set this rule as satisfied when at least one tweet of the account has been geo-localized. For the rule 11, punctuation has been searched in both the profile biography and in its timeline."}, {"heading": "4.2. Stateofsearch.com", "text": "Among the several bloggers that propose their golden rules to identify suspicious Twitter accounts, we consider the \u201c7 signals to look out for recognizing Twitter bots\u201d, according to the founder of the social media website stateofsearch.com [11]. The \u201c7 signals to look out for\u201d to recognize Twitter bots are listed in Table 3.\nThe rule 3 has been implemented considering the tweet as a single unit. We consider the last 20 tweets of each timeline. For the rule 4, we consider the existence of a duplicate profile picture when at least 3 accounts within the dataset have the same profile picture. For the rule 5, we consider as tweets posted from API all those tweets not being posted from the website twitter.com. For rules 6 and 7, when looking for an account\u2019s friends or followers list, Twitter only gives information about the current list, with no details about past friends or followers. Moreover, Twitter does not disclose any temporal data related to the moment a user stared following, or got followed by, another user. This means that the only way to check a user\u2019s follow/unfollow behavior (rule 7) is to continuously monitor full friends and followers complete lists. The same applies with respect to the measurement of the delay experienced when a user follows (and replies to) other users (rule 6). As further detailed in Section 6, the Twitter rate limits in the use of the APIs makes it practically infeasible to monitor friends and followers lists of even a small group of users. Therefore, we did not apply rules 6 and 7 to our datasets, since that would require to continually monitor those accounts. This also means that those rules cannot be used to support an automatic detection process, since they require an interactive process to be evaluated."}, {"heading": "4.3. Socialbakers\u2019 FakeFollowerCheck", "text": "Several companies provide online tools to classify Twitter followers based on their fakeness degree. Here, we consider the \u201cFakeFollowerCheck tool\u201d, by Socialbakers [14]. While the company website provides eight criteria to evaluate the fakeness degree of the followers of a certain account, it omits details on how to combine such criteria to classify the accounts. We contacted their customer service, but we were answered that \u201chow the respective criteria are measured is rather an internal information\u201d. The FakeFollowerCheck tool analyzes the followers of an account and considers them likely fake when the criteria listed in Table 4 are satisfied.\nFor the rule 2, we consider as spam phrases expressions like \u201cdiet\u201d or \u201cmake money\u201d or \u201cwork from\nhome\u201d (both English and Italian translations), as suggested by the website of Socialbakers."}, {"heading": "4.4. Evaluation methodology", "text": "All the criteria detailed above have been applied to the 2 verified human accounts datasets (TFP and E13 ) as well as to all the 3351 fake followers accounts bought from the Twitter account markets (FSF \u222a\nINT \u222a TWT ), as described in Section 3.\nWe conducted one experiment for each rule, considering two classes of accounts, the fake followers and the human ones. To summarize the outcomes of each experiment, we considered some evaluation metrics based on four standard indicators, namely:\n\u2022 True Positive (TP): the number of those fake followers recognized by the rule as fake followers;\n\u2022 True Negative (TN): the number of those human followers recognized by the rule as human followers;\n\u2022 False Positive (FP): the number of those human followers recognized by the rule as fake followers;\n\u2022 False Negative (FN): the number of those fake followers recognized by the rule as human followers.\nThe meaning of each indicator is graphically highlighted by the matrix in Table 5 (called the confusion matrix ), where each column represents the instances in the predicted class, while each row represents the instances in the actual class [36]: In order to evaluate the application of each single rule to the accounts in\nthe baseline dataset, we consider the following standard evaluation metrics:\n\u2022 Accuracy: the proportion of predicted true results (both true positives and true negatives) in the\npopulation, that is TP+TNTP+TN+FP+FN ;\n\u2022 Precision: the proportion of predicted positive cases that are indeed real positive, that is TPTP+FP ; \u2022 Recall (or also Sensitivity): the proportion of real positive cases that are indeed predicted positive,\nthat is TPTP+FN ;\n\u2022 F-Measure: the harmonic mean of precision and recall, namely 2\u00b7precision\u00b7recallprecision+recall ;\n\u2022 Matthew Correlation Coefficient (MCC from now on) [37]: the estimator of the correlation between\nthe predicted class and the real class of the samples, defined as:\nTP \u00b7 TN - FP \u00b7 FN \u221a\n(TP+FN)(TP+FP)(TN+FP)(TN+FN)\nEach of the above measures captures a different aspect of the prediction quality of the samples that belong to the relevant class (the fake followers, in our dataset). Accuracy measures how many samples are correctly identified in both of the classes, but it does not express if the relevant class is better recognized than the other one. Moreover, there are situations where some predictive models perform better than others, even having a lower accuracy [38]. A high Precision indicates that many of the samples identified as relevant are correctly recognized, but it does not give any information about the relevant samples which have not been identified. This information is provided by the Recall metric, that expresses how many samples, in the whole set of relevant samples, have been correctly recognized: a low recall means that many relevant samples are left unidentified. F-Measure and MCC try to convey in one single value the quality of a prediction, combining the other metrics. Furthermore, MCC is considered the unbiased version of the F-Measure, since it uses all the four elements of the confusion matrix [38]. An MCC value close to 1 means that the prediction is really accurate; a value close to 0 means that the prediction is no better than random guess, and a value close to -1 means that the prediction is heavily in disagreement with the real class. Then, we consider as best rules those criteria whose application gives MCC \u2265 0.6, since such rules have the strongest correlation with the typology of the accounts. For completeness, when available, we also report the area-under-the-curve metric (AUC ), that is the area under the Receiver Operating Characteristic (ROC) curve [39]. The latter is the curve that depicts the performance of a classifier considering the percentage of true positive samples compared with the percentage of false positive samples. The AUC is used to summarize ROC curves in a single value: the more the area approaches to 1, the more capable is the classifier.\nFinally, we also report the Information Gain (I gain) and the Pearson Correlation Coefficient (Pcc). While the Pearson correlation coefficient can detect linear dependencies between a feature and the target class, the information gain considers a more general dependence, leveraging probability densities (or frequencies, in case of discrete variables). More precisely, the information gain is a measure about the informativeness of a feature with respect to the predicting class and it is typically adopted to train machine learning classifiers. It can be informally defined as the expected reduction in entropy caused by the knowledge of the value of a given attribute [40]. We compute two information gains: I gain about the outcome of the rule and I gain* about the attribute used by the rule. For I gain, a rule based on attribute A can only assume the values 0 (not satisfied) and 1 (satisfied), while for I gain*, the attribute A can assume much heterogeneous values. For example, when evaluating the information gain of the rule \u201cfollowers \u2265 30\u201d, a sample with 234 followers contributes with value 1 when we compute I gain, and with value 234 when we compute I gain\u2217. The Pearson correlation coefficient, instead, is a measure of the strength of the linear rela-\ntionship between two random variables X and Y [41, 42]. Again , we compute Pcc, considering the outcome of the satisfaction of the rule (namely: true=1 or false=0) and Pcc*, based on the value assumed by the attribute used to evaluate the rule. Our experiments in the following sections will show that, generally, a rule and the corresponding attribute assume very different values for the information gain and the Pearson correlation coefficient."}, {"heading": "4.5. Evaluation of Camisani-Calzolari algorithm", "text": "The detection algorithm in [12] aggregates the 22 criteria for identifying human and bot behavior, introduced in Section 4.1. The algorithm evaluates every single rule on the account under investigation, and it assigns a positive human score or a negative bot score, according to the output of the rule application. The final outcome depends on the global score obtained by the account: if the result is a score greater than 0, then the account is marked as human; if it is between 0 and -4, it is marked as neutral ; otherwise, it is marked as bot.\nTable 6 details the results of running the algorithm over the complete dataset, including the FAK set, namely all the bought fake followers accounts. Although obtaining very good results in detecting the real human accounts, the algorithm achieves a poor fake follower account detection. Most of the accounts have been erroneously tagged as humans too, mainly because the fake followers in our dataset have characteristics that easily make them achieve a human score higher than the bot one.\nThe above inability to detect the fake accounts is evident in the results of our second experiment. To evaluate the algorithm, we used it to predict the class of the accounts of our baseline dataset (BAS), reporting the evaluation of the final prediction in Table 7. As expected, the algorithm has a poor accuracy (very close to 0.5) and a high precision, meaning that the (few) accounts identified as fake are effectively fake. However, it also has a very low recall, meaning that many of the other fake accounts were unidentified as fake. This poor performance is also expressed by a F-Measure close to 0.1 and by the low MCC value."}, {"heading": "4.6. Single rule evaluation", "text": "In this section, we analyze the effectiveness of each single rule, as designed by the original authors, in order to evaluate which rule can be considered as a good criterion for the detection of fake Twitter followers.\nTable 8 summarizes the results obtained by the application of each rule introduced in Sections 4.1, 4.2, and 4.3 to our BAS dataset. In Table 8, we highlighted the rules achieving high MCC values. As shown, only three rules obtained a value higher than 0.6, namely: (1) the threshold of at least 30 followers, (2) the threshold of at least 50 tweets, and (3) the use of a userID in at least one tweet.\nAs expected by the definition of MCC, such rules also exhibit a combination of high accuracy, precision, and recall. However, it is worth observing the values for the information gain and the Pearson correlation coefficient. The information gain of the rules (I gain) is always lower than the evaluation of the related attribute I gain*, while this is not true for the Pearson correlation coefficient (Pcc and Pcc* ). Actually, this happens because Pcc evaluates the linear dependency between two variables that assume very similar values, namely the output of the rule and the class, while the Pcc* considers variables with more heterogeneous\nvalues. In the first case, indeed, both the variables class and the output can assume only the values 0 and 1: the class can be either 0 (human) or 1 (fake), the rules can output either 0 (false, for example, account does not have more than 50 tweets) or 1 (true, for example, account has more than 50 tweets). Instead, for the Pcc* , the attribute of a rule (in the example, the number of tweets) can assume much higher values (account has 234 tweets). This is clearly not linearly dependent on the class values, resulting in lower values for the Pcc* with respect to the Pcc [41].\nThus, for each rule listed in Section 4.1 (top part of Table 8), it is meaningless to compare the Pcc and Pcc\u2217 values. Instead, we need to focus only on the same type of metric, namely by column, to compare the linear dependency of the feature with the class. Then, directing our attention to the information gain, we notice that many of the rules take into account attributes that are effectively able to perform the discrimination between the two classes. If we consider as useful the rules and features that have an information gain value higher than 0.5, we observe that, even if many rules exhibit a very low I gain, their \u201cfeature\u201d version becomes much more interesting: for example, rules 18, 20, 21 and 22 have an evident increase in their information gain when used as features. Thus, we can derive that the rule is based on a right assumption (for example, the use of hashtags), but the rule definition is too simple to be effective: the algorithm proposed by [12] is simply too naive for the complex task of fake accounts detection in Twitter. Coincidentally, we have that the best performing rules also show the highest Pcc values, namely their satisfaction is more strongly related to the belonging class. Concerning the features underlying the rules, we find that the Pcc\u2217 is strongly reduced because, as above noticed, they can (and indeed do) assume very high values and this severely affects the linear correlation with the class.\nObserving the other rules of Table 8, we can notice how none of the criteria suggested by online blogs and by Socialbakers\u2019 FakeFollowerCheck are successful in detecting the fake followers in our dataset. As an example, all rules by Van Den Beld have accuracy and precision close to 0.5 or a very low recall. Also, we observe that \u201ctweet from API\u201d has an MCC of -0.779, meaning that it is strictly related to the class of the account, but by an inverse factor: in our dataset, fake followers accounts almost never tweet from API (instead, they use Twitter.com to tweet), whereas human accounts have posted at least once from outside the website. This is exactly the opposite behavior than that suggested by the blogger for bots, that (are supposed to) almost exclusively post tweets using API. The relevance to the prediction task is also confirmed by both the I gain/I gain\u2217 and the Pcc/Pcc\u2217 values.\nAnother interesting observation is that many rules proposed by Socialbakers have MCC values close to 0, meaning that their outcomes are almost unrelated with the class of the accounts. Indeed, the large majority of the accounts are recognized as humans, resulting in a high precision, accuracy around 0.5 and very low recall. The exception is rule 6, \u201c0 tweets\u201d: as a rule, it has an information gain value of 0.02, but when considered as a feature (i.e., number of tweets) it obtains 0.621. Similarly, rules 4 and 5 are much more useful for the detection process when considering their underlying features (namely, number of retweets and\nnumber of tweets with URLs). Summarizing, independently from the typology of the account, the rules are almost always satisfied, leading to a severe flaw when dealing with fake followers detection."}, {"heading": "5. Fake detection with algorithms based on feature sets", "text": "In this section, we examine works in [8, 2] that address spam account detection on Twitter. Both of them propose a list of features to be extracted from manually classified datasets of accounts. Such feature sets are then used to train and test machine learning classifiers in order to distinguish between humans and spammers. Even if the proposed features have been originally designed for spam detection, here, for the first time, we consider them to spot another category of Twitter accounts, i.e., the fake followers. Although many other works exist in literature focused on Twitter spam detection (see Section 2), many of them consider features that can be in some way assimilated to those analyzed in this and in the previous section.\nDifferently from the rule-based algorithms in Section 4, features are here presented as quantifications of properties of the considered samples. Therefore, they are introduced without any prior knowledge about the values for the features that will characterize the considered classes. Only after the training phase, it will be possible to observe which are the most frequent values for the features within the different classes.\nFor our analysis, we employ classifiers that produce both \u201cglass-box\u201d and \u201cblack-box\u201d models. In \u201cglassbox\u201d models, such as Decision Trees and Regression Models, the inner structure of the models can be understood by humans, also providing insights on how the classifiers identify fake accounts [39]. Instead, in \u201cblack-box\u201d models, such as Support Vector Machines, the inner structure of the model does not have a direct human-explicable correspondence."}, {"heading": "5.1. Detecting spammers in social networks", "text": "The study presented in [8] focuses on spambot detection. The authors exploit several characteristics that can be gathered crawling an account\u2019s details, both from its profile and timeline. For each investigated account, such characteristics are exploited in a Random Forest algorithm [23, 43], that outputs if the account is a spambot or not. The results of the analysis in [8] depicted some interesting features of the spambot accounts under investigation, as reported in Table 9.\nTo evaluate feature 3, we implement the notion of message similarity by checking the existence of at least two tweets, in the last 15 tweets of the account timeline, in which 4 consecutive words are equal. This notion has been given in a later work by the same authors [25].\nWithout the original training set, we were unable to reproduce the same classifier, but we picked the five features and used them to train a set of classifiers with our BAS dataset. The results are reported in Table 12 of Section 5.3."}, {"heading": "5.2. Fighting evolving Twitter spammers", "text": "The authors of [2] observed that Twitter spammers often modify their behavior in order to evade existing spam detection techniques. Thus, they suggested to consider some new features, making evasion more difficult for spammers. Beyond the features directly available from the account profile lookup, the authors propose some graph-, automation-, and timing-based features. In Table 10 we detail nine of them, together with the outcome of their analysis in [2].\nThe authors of [2] combine their features in four different machine learning classifiers and compare their implementation with other existing approaches. We were unable to completely reproduce the machine learning classifiers in [2], since we had a different dataset. Instead, here we evaluate how those features, which proved to be quite robust against evasion techniques adopted by spammers, perform in detecting fake Twitter followers. As in [2], the following rate (feature 9) has been approximated with the ratio friends/age, since a precise evaluation would require to know the evolution of the number of friends of an account, but this is, indeed, publicly unavailable.\nFinally, in [2] there are also other features in addition to those mentioned above. However, as claimed by the same authors, they are less robust with regards to evasion techniques and thus we decided not to include them in our evaluation."}, {"heading": "5.3. Evaluation", "text": "As done for the rule set in Section 4, we report in Table 11 the evaluation of the information gain and the Pearson correlation coefficient for all the features within the BAS dataset. Also in this case, since the Pcc evaluates the linear dependence between the considered feature and the class (that can only be 0 or 1), it produces results that are slightly different when compared to the information gain. Observing the results in Table 11, we can identify several promising features: \u201cnumber of tweets\u201d (already noticed in Section 4), \u201cratio between friends and followers\u02c62\u201d, \u201cbidirectional links ratio\u201d and \u201cAPI ratio\u201d. The beneficial effect of the bi-link ratio will be further confirmed by the experiments of Section 5.4.3.\nTo evaluate the combined effectiveness of the feature sets described in Sections 5.1 and 5.2 on detecting fake follower accounts, we employed 8 classifiers, obtained from different machine learning-based algorithms, namely: Decorate (D), Adaptive Boost (AB), Random Forest (RF), Decision Tree (J48), Bayesian Network (BN), k-Nearest Neighbors (kNN), Multinomial Ridge Logistic Regression (LR) and a Support Vector Machine (SVM). Our SVM classifier exploits a Radial Basis Function (RBF) kernel and has been trained using libSVM as the machine learning algorithm [44]. During the training phase of the SVM, the cost and gamma parameters have been optimized via a grid search algorithm. Similarly, the k parameter of the kNN classifier and the ridge penalizing parameter of the LR model have been optimized via a cross validation parameter selection algorithm. All the classifiers and the optimization algorithms employed in this work are implemented within the Weka framework [43].\nAmong these algorithms, RF was the only one used in [8]. Instead, authors of [2] employed D, RF, J48 and BN. We have decided to include AB in our work, since it is considered one of the most effective machine learning algorithms for classification tasks [39]. Furthermore, we also added other well-known and widely adopted classifiers, which are based on different classification techniques, such as SVM, kNN and LR,\nin order to perform a thorough evaluation of our detection system.We have built 8 classifiers adopting the features in Sections 5.1 and 5.2 and we have trained the models using our baseline (BAS ) dataset. Then, we have used a 10-fold cross validation [23] to estimate the performances of each obtained classifier. As for the rule-based algorithms in Section 4.4, we look at the MCC as the preferred metric to assess the classifiers\u2019 performances. Table 12 summarises the results. The highest values for each metric are shown in bold.\nWe can observe that all the classifiers have an excellent prediction capability. The ones built over the feature set of [2] achieve slightly better results. In particular, the RF, J48 and D classifiers haveMCC greater than 0.98. Similarly, precision and recall are around 0.99 for all of them. In addition, all the classifiers based on the feature set by [2] have a higher AUC, when compared with the ones built with the feature set by [8]. Anyway, the latter also obtain high detection levels: accuracy, precision, and recall are around 0.98 for RF, D and J48, with a MCC of around 0.96. The lower precision and recall with respect to the ones obtained using the set of Yang et al. [2] show that the features of Stringhini et al. [8] exhibit the tendency to consider as fake followers some human accounts. With both the [2] and [8] feature sets, BN, kNN and LR classifiers achieve, overall, worse performances. The SVM classifier, instead, achieves remarkable results, especially with the feature set of [2]. Indeed, in this experiment SVM scores only slightly worse than RF, D and J48, and better than AB. Whereas, AB achieves extremely high performances when evaluated with the AUC metric. Finally, among all the considered classifiers and evaluation metrics, RF and D are the ones that have been proved to be more consistent.\nOverall, even if some small differences can be observed in the evaluation metrics, all the classifiers almost correctly distinguish between human and fake follower accounts, for our baseline BAS dataset. The featurebased classifiers are indisputably more accurate for fake follower detection when compared with the CC\nalgorithm, that does not perform well within our dataset, as observed in Section 4.5 above."}, {"heading": "5.4. Discussion", "text": "By examining the internal structure of the classifiers, we get insights about the best features that contribute more to distinguish between human and fake followers. In the case of decision trees, the best features are the ones closer to the root and the classifier automatically finds the numeric thresholds characterizing, for a given feature, the borderline between human and fake followers. It is worth noting that also the Decorate, AdaBoost, and Random Forest algorithms exploit, ultimately, combinations of simple decision tree classifiers. Despite their very good performance, they have the disadvantage of being difficult to analyze, since they can consist in tens of individual trees that interact together. Then, we only focus on the J48 classifier (a single decision tree) to examine how the features are applied during the classification process."}, {"heading": "5.4.1. Differences between fake followers and spam accounts", "text": "Looking at the tree structure, we observe some interesting differences between the fake followers in our BAS dataset and the spam accounts characterized in [8] and [2]. For example, the feature URL ratio has been found to have a higher value for spammers than for legitimate users, as highlighted in [8] (Section 5.1). Observing the tree structure of our J48 classifier, instead, low values for this feature characterize fake followers, compared with higher values that indicate human accounts in our baseline dataset. More than 72% of the fake followers in our training dataset have a URL ratio lower than 0.05, oppositely to 14% of human accounts. Similarly, the API ratio feature has been found higher for spammers than for legitimate accounts ([2], see also Section 5.2). In our dataset, the API ratio is lower than 0.0001 for 78% of fake followers. A similar behavior has been observed for the average neighbor\u2019s tweets feature, that has been found to be lower for spammers in [2], but higher for our fake followers.\nThese initial observations highlight a behavioral difference between a spam account and a fake follower. In particular, fake followers appear to be more passive compared to spammers and they do not make use of automated mechanisms for posting their tweets, as spammers usually do."}, {"heading": "5.4.2. Reducing overfitting", "text": "It is well known that trained classifiers can be subject to \u201coverfitting\u201d, namely the problem of being too\nspecialized on the training dataset and unable to generalize the classification to new and unseen data [45].\nA simple way to avoid overfitting is to keep the classifier as simple as possible. In case of a decision tree algorithm, for example, one solution could be reducing the number of nodes and, possibly, the height of the tree. The decision tree obtained with the feature set of Stringhini et al. [8] has 22 leaves, 43 nodes, and a height of 7, whereas the best feature is the friends/(followers\u02c62) ratio that places at the root. The decision tree with the feature set of Yang et al. [2] has 17 leaves, 33 nodes and a height of 8, with the bi-directional link ratio as the root.\nA common practice to generalize the classifiers is the adoption of a more aggressive pruning strategy, e.g., by using the reduce-error pruning with small test sets [23, 43]. Adopting this strategy, we were able to obtain simpler trees with a lower number of nodes and a very reduced height. Such simpler trees generally use subsets of the feature set, still maintaining very good performance on our BAS dataset.\nTable 13 reports the characteristics and the performance of the experiments we have carried out, varying the pruning strategy. It is worth noting that the complexity of the tree is not always directly connected to an improvement in the detection capability: for example, for the feature set of Yang et al. [2], reducing the number of nodes from 33 to 11 decreases the accuracy of 0.007 and the MCC of 0.014, only. Similarly, the values for AUC remain almost the same between the pruned and the not pruned versions of the tree. Furthermore, we clearly observe that the pruned version of Stringhini et al. [8] reduces its recall of 0.017, while the one of Yang et al.[2] only drops of 0.004, meaning that the latter is able to miss fewer fakes than the former one after pruning. This is also evident from the higher reduction of both F-Measure and MCC. We think that this increased effectiveness is a direct consequence of the quality of the used features. Overall, the results of this experiment show that, even reducing the features, it is possible to have a detection rate higher than 0.95 (as in the last lines of Table 13, for [8] and [2], respectively). For instance, in those two experiments, the features used by the pruned tree were only bi-directional link ratio, the average neighbors\u2019 followers, the age, and the followings to median neighbors\u2019 followers as a subset of the original feature set of Yang et al. [2], and the friends/(followers\u02c62), URL ratio, and number of friends as the subset for the Stringhini et al. [8] original feature set."}, {"heading": "5.4.3. Bidirectional link ratio", "text": "In Section 5.3 we observed that the bidirectional link ratio had the highest information gain among all the considered features. In order to test if this is the decisive feature to distinguish between humans and fake followers and how much it influences the detection process, we compare the results of the previous\nexperiments with those of a new one. We build a decision tree classifier leaving out the bi-link ratio from the feature set of Yang et al. [2] and compare its effectiveness against the classifier built with the complete set. The results are reported in the last rows of Table 13.\nThis experiment is particularly interesting since, as detailed in next Section 6, this feature is the most expensive to evaluate. The results in Table 13 show an evident decrease in accuracy, precision and recall for the less pruned trees (subtree raising 0.25 and reduced error 3 folds), as well as for both F-Measure and AUC, and an even noticeable decrease of the MCC measure. The reduced error pruning with 50 folds produces a classifier that has MCC dropping from 0.966 to 0.866. Its detection level (accuracy) is still very good for all the three pruned trees (0.964, 0.982 and 0.933, respectively), but we can clearly observe a remarkable drop in both precision and recall, compared to the version with the whole feature set. This suggests that the highest effectiveness we noticed in the above experiments after pruning (Section 5.4.2) is considerably lost when we do not consider the bi-link ratio feature. The most interesting aspect is the increased complexity of the decision tree: without the bi-link ratio, the classifiers need to resort to a considerably larger number of nodes. For example, the tree that does not use that feature, pruned with subtree raising confidence of 0.25, requires 101 nodes, whereas the tree that uses it requires only 33 nodes.\nFrom the results shown in Table 13, we conclude that the bidirectional link ratio is an important feature for fake follower detection: even if not essential, it is extremely effective for the detection process. By capturing the nature of the social ties between an account and its neighbors, this feature is intrinsically harder to beat than those based on simpler characteristics, like, e.g., other information in the account\u2019s profile."}, {"heading": "6. An efficient and lightweight classifier", "text": "As previously shown in sections 4 and 5, the classifiers based on feature sets perform much better than those based on rules. Similarly, we have seen that the feature set proposed by Yang et al. [2] seems to be slightly more effective than the one proposed by Stringhini et al.[8], when used in feature-based classifiers aiming at fake followers detection. Here, we look for an efficient and lightweight classifier, exploiting the best features and the best rules, not only in terms of detection performance, but also considering their evaluation costs. In particular, we can distinguish between the computational cost and the crawling cost required to evaluate a feature (or a rule). Computational costs can be generally lowered with optimized algorithms and data representations and they are negligible when compared to the crawling costs. Thus, in this section we focus on the latter: we quantify the crawling cost of each feature and rule, and we build a set of lightweight classifiers that make use of the most efficient features and rules, in terms of crawling cost and fake followers detection capability. For the sake of readability, in the following section with the term \u201cfeature\u201d we include all the features presented in sections 4 and 5, namely also the features underlying the analyzed rules."}, {"heading": "6.1. Crawling cost analysis", "text": "Intuitively, some features require few data for their calculation, while others require the download of big\namounts of data. For the sake of this analysis, we divide the features in three categories:\nA) profile: features that require information present in the profile of the followers of the target account\n(like, e.g., profile has name);\nB) timeline: features that require the tweets posted in the timeline of the followers of the target account\n(like, e.g., tweet from API );\nC ) relationship: features that require information about the accounts that are in a relationship (i.e., that\nare a friend, or a follower, or both) with the followers of the target account (like, e.g., bidirectional link ratio).\nEach category, in turn, belongs to a crawling cost class directly related to the amount of data to be crawled from Twitter. Starting from the list of the followers of a target account, Class A features can be evaluated simply accessing to all the profiles of the followers; Class B features require to download all the tweets posted by each follower; Class C features need to crawl the friends and the followers of each follower of the target account. To evaluate the class of cost associated to each feature\u2019s category, we estimate the number of Twitter API calls needed to download data required for the calculation. Results are in Tables 15 and 14. The following parameters refer to the Twitter account for which the number of fake followers is being investigated:\nf : number of followers of the target account;\nti : number of tweets of the i-th follower of the target account;\n\u03d5i : number of friends of the i-th follower of the target account;\nfi : number of followers of the i-th follower of the target account.\nThe number of API calls for each category depends on the maximum number of accounts (100), tweets (200) and friends/followers (5000) that can be fetched from Twitter with a single API request. For example, for the profile category, a single API call can return 100 follower profiles, leading to \u2308\nf 100\n\u2309\nAPI calls in\ntotal. The detailed costs do not account for the initial download of the whole list of f followers of the target account, that requires \u2308\nf 5000\n\u2309\nAPI calls.\nTable 15 also shows the minimum (Best-case) and maximum (Worst-case) number of API calls that could possibly be required, that depend on the length of the timelines and the number of relationships of the followers. The Best-case is when one single API call is sufficient to get all the data for a single follower. For the Worst-case we can only precisely evaluate the number of API calls for the timeline category, since the number of tweets that can be accessed from a user timeline is limited to 3200, leading to a maximum of 16 calls for each follower. The number of friends and followers, instead, is not limited and, therefore, it is impossible to calculate a worst-case scenario for the relationship category. However, just to provide an estimation, we can consider the account with the highest number of followers on Twitter, which, at the time of writing, belongs to the pop star Katy Perry (@katyperry), with about 60 millions of followers. We can therefore consider as the worst-case scenario an account with 60 millions followers and 60 millions friends, which leads to a number of API calls equal to 22000 \u2217 f.\nObserving the values of Table 15, we have a clear idea of the order of magnitude of each class: features in Class B are 100 times more costly than features of Class A, while features of Class C could be several orders of magnitude more costly than features of Class A.\nFurthermore, to protect Twitter from abuse, the number of API calls allowed per minute is limited. In Table 15, we also report the maximum number of calls allowed per minute (Calls/min.), which directly impacts on the time needed to complete the data acquisition.\nSome further considerations follow. Firstly, data collected for a category can be used to evaluate all the features of that category. Secondly, Twitter limits the number of calls of the same API, but different APIs can be called in parallel. This means that data for all the three feature categories can be possibly acquired concurrently. The total time required to collect all data depends on the category that requires more time, i.e., the relationship one. In other words, to get the total time, one should not consider the sum of the time\nneeded for each of the three cost classes, but just the most costly one."}, {"heading": "6.2. The Class A classifier", "text": "All the rules and features considered in this study fall into one of the three aforementioned categories, as reported in Table 14. Therefore, their crawling cost impacts on the final cost of the whole feature set and, ultimately, to the class of the classifier: a classifier that uses a certain feature set belongs to the class of the more expensive feature. Then, all the classifiers of the previous sections are classifiers of Class B, with the exception of the classifier with the feature set of Yang et al. [2], that belongs to Class C.\nIn the following, we consider a lightweight classifier working only with features of Class A. We aim at verifying whether the Class A classifier reaches performances that are comparable to those of the most expensive Class B and Class C classifiers.\nTable 16 reports the results of the classifiers built on our BAS dataset, using two different feature sets: all the features (independently from their cost) and the Class A features. We start observing that the Class C classifiers, built over all the features considered in our study, perform better than all the other ones, including the classifiers using the feature sets of Yang et al. [2] and Stringhini et al. [8], as reported in Table 12. In particular, RF, D and AB achieve an AUC as high as 0.999. Class C classifier only slightly outperforms Class A classifier. Indeed, there is a difference of around 0.02 in MCC for RF, D and J48. The AUC reduction is even smaller, only 0.004 for RF, D, J48 and 0 for BN. It is worth noting that the Class A classifier with BN outperforms the Class C competitor, noticeably obtaining an increase in all the metrics, but the AUC. Instead, the Class A kNN, LR and SVM classifiers suffer from a significant drop in performances with respect to the Class C counterparts.\nConcerning the complexity of the two decision trees obtained with the J48 algorithm, they are comparable, since both of them are composed by 31 nodes and 16 leaves and they have a height of 7. A further interesting observation is that both the classifiers employ a set of features that includes both features proposed by the grey literature for fake detection, which we introduced in Section 4, and by Academia for spam and bot detection, as detailed in Section 5.\nThe analysis carried out in Section 6.1 highlights the effort and time needed to compute many of the features commonly proposed for the detection of spam and fake accounts. As shown by the Katy Perry example, crawling costs for some of the proposed features are totally infeasible for accounts with hundreds of thousands or millions of followers. For this reason, we trained and evaluated the proposed Class A classifiers, which achieve overall good performances, while only exploiting cost-efficient features. The Class A classifiers thus represent a feasible solution for the investigation of fake followers on a large scale.\nWe have to point out, however, that countermeasures could be taken to evade some of the simplest features our classifiers are built upon [2]. This would require to continually monitor and update the choice of such features, to keep pace with the fake follower generators. While contemporary fake Twitter followers are effectively and efficiently spotted by our Class A classifier, we can consider the use of the most expensive Class B or even Class C features to have stronger evidences about the more suspicious followers."}, {"heading": "6.3. Validation of the Class A classifier", "text": "In this section, we propose a validation of our Class A classifier, built with our baseline BAS dataset. In particular, we set up two different experiments based on a random sampling of Twitter accounts. For the first experiment, we built a set of 1000 Twitter accounts, randomly selecting numeric Twitter user IDs, ranging from user ID 12 (the very first valid Twitter account \u2013 @jack \u2013 belonging to Jack Dorsey, founder of Twitter) to the user ID representing the last Twitter account created at the time of our experiment. This represents an unbiased sample of all the currently available (i.e., not closed, banned or suspended) Twitter accounts. This test set therefore comprises a broad range of accounts created during the nine years since Twitter\u2019s advent. For the second experiment, instead, we consider a random sample of 1500 accounts among the followers of the US President Barack Obama \u2013 @BarackObama. This experiment resembles the practical application scenario of the proposed classifier, since it investigates a sample of a single account\u2019s followers, in this case a major politician.\nAll the accounts acquired with the two aforementioned approaches have been labeled as humans, following the same approach used in [26]. Twitter officially reports that fake and spam profiles together are less than 5% of all registered accounts [35], therefore we are confident that just a few among the accounts labeled as humans might actually be fake ones. Automatically labeling the sampled accounts as humans would result in an error of at most 5%, still allowing an overall correct validation of our classifiers. In addition, many of the accounts randomly acquired for the first and second experiment show few signs of activity on Twitter\n(more than 70% of them did not post a tweet in the 3 months prior to our data acquisition). Thus, more reliable checks like CAPTCHA-based verifications would result in very sparse answers. Furthermore, we believe that also including less active accounts in our test sets, allows to validate our classifiers with Twitter accounts having different characteristics than those of our baseline dataset of humans in Section 3.3 (e.g., showing fewer \u201chuman\u201d features). Together with the human accounts, the test set also includes the 1401 fake followers we bought, but not included in the BAS dataset that we used as training set (Section 3.5).\nIn Table 17, we report the results of the experiments on the test sets. Comparing results of Table 17 with those of Tables 12 and 16, we notice a broader range of performances. Indeed, while in Tables 12 and 16 almost all the considered classifiers achieved comparable performances, here we can see some major differences. This means that the increased difficulty of the detection task on the two considered test sets highlighted differences that were not visible in the previous experiments.\nFrom Table 17, we can observe that the validation against sampled Obama followers (bottom half of the table) proves to be more error prone than that against random sampled accounts. Indeed, almost all the classifiers achieve worse results in the former experiment, as deducible, for instance, from the AUC scores.\nObserving the validation against the random sampled accounts, we can see that the five Class A classifiers obtain an accuracy above 0.9, a precision close to (when not much higher than) 0.9 and a recall above 0.94: this means that they are able to spot almost all the fake followers of the test set. This is particularly true for the best performing classifier, RF, that reaches 0.975 for both accuracy and recall, with a precision of 0.982. The highest performances are also shown by both F-measure and MCC values, that are noticeably higher for RF when compared with the others. AB and BN obtain lower results for both accuracy and precision, but still a noticeably high recall, meaning that only few fake followers are left behind, but a\nconsiderably higher number of human accounts are classified as fake followers. Among all the classifiers, LR is the one achieving the worst performances, because of the low MCC values obtained with both the test sets: 0.299 and 0.278 respectively. For the validation against sampled Obama followers, also kNN achieves unsatisfactory performances, with MCC equal to 0.469. The SVM classifier, instead, proves to be extremely effective, being the second best classifier when validated against random sampled accounts, and still performing very well against sampled Obama followers.\nThe RF, D, and J48 classifiers obtain results that are comparable for the two test sets, with an accuracy greater than 0.9 and a precision close to 0.87, with a reduction of only 0.025 on average. This is also confirmed by both the F-measure and MCC that are very close to the results above. In the two validation experiments, AB and BN noticeably switch their performances: the Adaptive Boosting algorithm raises its accuracy of 0.1 and its precision of around 0.08, outperforming the Bayesian Network-based one. This latter looses 0.105 of accuracy, meaning that many of the accounts we labeled as humans were recognized as fake followers. Also the RF classifier looses 0.4 of accuracy and a considerable 0.1 in precision, meaning that it considers as fake followers many of the sampled Obama\u2019s followers. We can finally observe that the AUC metric is always very high and that does not consistently reflect the real performances obtained by the five classifiers, as the F-measure and the MCC actually do."}, {"heading": "6.4. Assessing the global importance of Class A features", "text": "Motivated by the results obtained by our Class A classifiers, we went further to asses the global importance of Class A features towards the detection of fake Twitter followers. In order to estimate the importance of the single features among all the 8 classifiers, we followed the information fusion-based sensitivity analysis technique adopted in [46]. Information fusion is a technique aimed at leveraging the predictive power of several different models in order to achieve a combined prediction accuracy which is better than the predictions of the single models [47]. Sensitivity analysis, instead, aims at assessing the relative importance of the different features used to build a classification model [48]. It is therefore possible to combine information fusion and sensitivity analysis to estimate the global importance of several features, used in different machine learning classifiers, towards a common classification task.\nTo reach this goal, we firstly re-train each of the 8 Class A classifiers with our baseline BAS dataset, by removing one feature at a time. This leads to 19\u00d78 different classifiers. Subsequently, each of those classifiers is evaluated against our test sets. The local sensitivity score for the i-th feature of the j-th classifier can be computed as Sj,i = MCCj,\u2212i MCCj , namely as the reduction in classification performance of j when used without the feature i with respect to the classification performance of j using all the 19 Class A features. Then, we can compute a global sensitivity score for the i-th feature via a weighted sum of the local sensitivities, Si = \u2211\nj\nwjSj,i. The weighting factor wj is proportional to the MCC of the j-th classifier, as reported in\nTable 17, so that the best performing classifiers are weighted more. Finally, we rank features and assess\ntheir relative importance by normalizing their global sensitivities, so that the best performing feature has a normalized score of 1.\nTable 18 shows the results of this information fusion-based sensitivity analysis. Notably, none of the features is clearly dominant: all the 19 Class A features give a significant contribution to the detection of fake Twitter followers. Results of this in-depth analysis also show a considerable agreement with our feature evaluation studies reported in Tables 8 and 11. Specifically, the most important feature of Table 18, namely friends/(followers\u02c62) ratio, is the second best feature in Table 11, outperformed only by the Class C feature bidirectional link ratio. Given the relevant contribution of other features such as number of friends and following rate, we believe that features aimed at evaluating the social ties between an account and its neighbors play a central role towards the detection of fake Twitter followers."}, {"heading": "7. Conclusions", "text": "In this paper, we focused on efficient techniques for fake Twitter followers detection. To reach the goal, we firstly created a baseline dataset of human and fake follower accounts, the latter being bought from available online markets. Then, we surveyed various proposals for spammer and bot detection, based on classification rules and feature sets. Such proposals come partly from Academia and partly from the grey literature. Such rules and features were eventually tested on our dataset to understand their effectiveness in detecting fake Twitter followers. A few features were selected and used by a set of classifiers that we have trained on the baseline dataset. Going further, we ranked the best performing features according to their crawling cost. This led us to identify three categories of features belonging to three different, increasing, cost classes. Finally, we built a series of classifiers that only leverage cost-effective\n(Class A) features. With this final outcome, we were able to achieve detection rates comparable with the best of breed classifiers, whereas these latter necessitate overhead-demanding features.\nAmong the results of this study, there is the construction of a baseline dataset of verified human and fake follower accounts. To foster research on the novel issue of fake Twitter followers, we have publicly released our dataset to the scientific community [33].\nFor our analysis, we considered 49 distinct features and 8 different \u201cglass-box\u201d and \u201cblack-box\u201d machine learning classifiers. So-called \u201cglass-box\u201d classifiers produce interpretable models and an analysis of their inner structure allows to get insights into the mechanisms exploited to perform the detection. In turn, this is useful to better understand the characteristics of Twitter accounts that can be leveraged to discriminate between fake and genuine followers. Nonetheless, \u201cblack-box\u201d classifiers have been recently employed in a broad range of diverse classification tasks, achieving excellent results. Therefore, for the sake of experimentation, we expanded the set of machine learning algorithms employed in previous works on fake and spam detection, with the adoption of powerful classifiers, such as Support Vector Machines (SVM). Indeed, the results of our analyses confirm that SVMs achieve results comparable to those of the best performing classifiers (such as Random Forest and Decorate). The adoption of other powerful classification techniques, such as Artificial Neural Networks (ANNs), could provide other interesting results and, therefore, we consider its adoption and evaluation promising ground for future work.\nAmong all the analyzed features, we have seen that those yielding the best results are the ones based on the friends and followers of the account under investigation, such as the bidirectional link ratio and the friends/(followers\u02c62) ratio. By evaluating the social ties between an account and its neighbors, these features are more effective than those based on simpler characteristics, like, e.g., other information in the account\u2019s profile. However, relationships-based (Class C ) features are more demanding in terms of data to be downloaded and, consequently, they require a significant analysis time, making them unsuitable for analyses on massive amounts of followers. Timeline-based (Class B) features have been shown to be less time-demanding, while still effective; hence, these might represent a promising trade-off between efficient and accurate detections. Anyway, as shown by the proposed Class A classifiers, the detection of currently available fake Twitter followers is possible even without leveraging resource-demanding features, by means of efficient algorithms and accurate selection and combination of less-demanding features. We also evaluated the global importance of the Class A features for the fake Twitter follower detection, using information fusion-based sensitivity analysis and showing that those based on social relations play a dominant role.\nAs future work, we aim at designing and testing other advanced features that could be added to our lightweight fake followers\u2019 classifier, leveraging additional characteristics of Twitter accounts. Data that could be further exploited for the classification task are the content of tweets and the accounts\u2019 behavior. In particular, bot development forums represent a fruitful source of information to know more about bot/fake/spam accounts design, in terms, e.g., of similarities and differences in their behavior. As high-\nlighted by our work, the difficulty of the detection task and the massive numbers of accounts to analyze ask for the adoption of features that are not only effective, but also efficient, with regard to their crawling costs. Therefore, we believe that future works along this line of research should consider the balance between the predictive power of new features and their cost. This would allow to improve the detection of fake Twitter followers, while still retaining a scalable approach, making en masse analysis practically feasible.\nIt is foreseeable that countermeasures will be taken to masquerade a fake account with respect to some of the simplest features which our classifiers are built upon. This would require to continually monitor and update the choice of such features, conceivably studying (or directly interacting with) the same generators of fakes, to keep their pace. Therefore, we believe that the features renovation process can be considered as another interesting direction for future research."}, {"heading": "Acknowledgements", "text": "The authors would like to thank the anonymous reviewers who helped improving the quality of the manuscript."}], "references": [{"title": "Detecting social spam campaigns on Twitter", "author": ["Z. Chu", "I. Widjaja", "H. Wang"], "venue": "in: Applied Cryptography and Network Security, Springer", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Empirical evaluation and new design for fighting evolving Twitter spammers", "author": ["C. Yang", "R. Harkreader", "G. Gu"], "venue": "Information Forensics and Security, IEEE Transactions on 8 (8) ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "A generic statistical approach for spam detection in online social networks", "author": ["F. Ahmed", "M. Abulaish"], "venue": "Computer Communications 36 (10) ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Twitter spammer detection using data stream clustering", "author": ["Z. Miller", "B. Dickinson", "W. Deitrick", "W. Hu", "A.H. Wang"], "venue": "Information Sciences 260 ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Measuring user influence in Twitter: The million follower fallacy", "author": ["M. Cha", "H. Haddadi", "F. Benevenuto", "P.K. Gummadi"], "venue": "ICWSM 10 (10-17) ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Information credibility on Twitter", "author": ["C. Castillo", "M. Mendoza", "B. Poblete"], "venue": "in: Proceedings of the 20th international conference on World Wide Web, ACM", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Detecting deception in online social networks", "author": ["J.S. Alowibdi", "U.A. Buy", "P.S. Yu", "L. Stenneth"], "venue": "in: Advances in Social Networks Analysis and Mining (ASONAM), 2014 IEEE/ACM International Conference on", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Detecting spammers on social networks", "author": ["G. Stringhini", "C. Kruegel", "G. Vigna"], "venue": "in: 26th Annual Computer Security Applications Conference, ACSAC \u201910, ACM", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "The socialbot network: When bots socialize for fame and money", "author": ["Y. Boshmaf", "I. Muslukhov", "K. Beznosov", "M. Ripeanu"], "venue": "in: 27th Annual Computer Security Applications Conference, ACSAC \u201911, ACM, New York, NY, USA", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Detecting automation of Twitter accounts: Are you a human", "author": ["Z. Chu", "S. Gianvecchio", "H. Wang", "S. Jajodia"], "venue": "bot, or cyborg?, IEEE Trans. Dependable Sec. Comput. 9 (6) ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "digitalevaluations), Analysis of Twitter followers of the US Presidential Election candidates", "author": ["M. Camisani-Calzolari"], "venue": "Barack Obama and Mitt Romney (August", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "A Criticism to Society (as seen by Twitter analytics)", "author": ["S. Cresci", "R. Di Pietro", "M. Petrocchi", "A. Spognardi", "M. Tesconi"], "venue": "in: 1st International Workshop on Big Data Analytics for Security, IEEE", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "Towards online spam filtering in social networks", "author": ["H. Gao", "Y. Chen", "K. Lee", "D. Palsetia", "A.N. Choudhary"], "venue": "in: 19th Annual Network and Distributed System Security Symposium, NDSS 2012, San Diego, California, USA, February 5-8, 2012", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "WarningBird: A near real-time detection system for suspicious URLs in Twitter stream", "author": ["S. Lee", "J. Kim"], "venue": "IEEE Trans. Dependable Secur. Comput. 10 (3) ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Design and evaluation of a real-time URL spam filtering service", "author": ["K. Thomas", "C. Grier", "J. Ma", "V. Paxson", "D. Song"], "venue": "in: 32nd IEEE Symposium on Security and Privacy, S&P 2011, 22-25 May 2011, Berkeley, California, USA", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2011}, {"title": "Tweet", "author": ["A. Zubiaga", "H. Ji"], "venue": "but verify: epistemic study of information verification on Twitter, Social Network Analysis and Mining 4 (1) ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Spam ain\u2019t as diverse as it seems: Throttling OSN spam with templates underneath", "author": ["H. Gao", "Y. Yang", "K. Bu", "Y. Chen", "D. Downey", "K. Lee", "A. Choudhary"], "venue": "in: Annual Computer Security Applications Conference, ACSAC", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "SDHM: A hybrid model for spammer detection in Weibo", "author": ["Y. Liu", "B. Wu", "B. Wang", "G. Li"], "venue": "in: Advances in Social Networks Analysis and Mining (ASONAM), 2014 IEEE/ACM International Conference on", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Data Mining: Practical Machine Learning Tools and Techniques", "author": ["M. Hall", "I. Witten", "E. Frank"], "venue": "3rd Edition, Morgan Kaufmann", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2011}, {"title": "Early filtering of ephemeral malicious accounts on Twitter", "author": ["S. Lee", "J. Kim"], "venue": "Computer Communications 54 ", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "Poultry markets: on the underground economy of Twitter followers", "author": ["G. Stringhini", "M. Egele", "C. Kruegel", "G. Vigna"], "venue": "in: Workshop on online social networks, WOSN \u201912, ACM", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Follow the Green: Growth and Dynamics in Twitter Follower Markets", "author": ["G. Stringhini", "G. Wang", "M. Egele", "C. Kruegel", "G. Vigna", "H. Zheng", "B.Y. Zhao"], "venue": "in: Internet Measurement Conference, IMC \u201913", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2013}, {"title": "Trafficking fraudulent accounts: The role of the underground market in Twitter spam and abuse", "author": ["K. Thomas", "D. McCoy", "C. Grier", "A. Kolcz", "V. Paxson"], "venue": "in: 22nd USENIX Security Symposium, USENIX, Washington, D.C.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "Uncovering social spammers: social honeypots + machine learning", "author": ["K. Lee", "J. Caverlee", "S. Webb"], "venue": "in: SIGIR Conference on Research and Development in Information Retrieval, ACM", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2010}, {"title": "Peri-Watchdog: Hunting for hidden botnets in the periphery of online social networks", "author": ["G. Yan"], "venue": "Computer Networks 57 (2) ", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2013}, {"title": "Spam detection on Twitter using traditional classifiers", "author": ["M. McCord", "M. Chuah"], "venue": "in: Autonomic and Trusted Computing, Vol. 6906 of LNCS, Springer Berlin Heidelberg", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2011}, {"title": "Using communities against deception in online social networks", "author": ["S.Y. Bhat", "M. Abulaish"], "venue": "Computer Fraud & Security 2014 (2) ", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning when training data are costly: the effect of class distribution on tree induction", "author": ["G.M. Weiss", "F. Provost"], "venue": "Journal of Artificial Intelligence Research 19 ", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2003}, {"title": "Glossary of terms", "author": ["R. Kohavi", "F. Provost"], "venue": "Machine Learning 30 (2-3) ", "citeRegEx": "36", "shortCiteRegEx": null, "year": 1998}, {"title": "Assessing the accuracy of prediction algorithms for classification: an overview", "author": ["P. Baldi", "S. Brunak", "Y. Chauvin", "C. Andersen", "H. Nielsen"], "venue": "Bioinformatics 16 (5) ", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2000}, {"title": "Evaluation: from precision", "author": ["D.M.W. Powers"], "venue": "recall and F-measure to ROC, informedness, markedness and correlation, International Journal of Machine Learning Technologies 2 (1) ", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2011}, {"title": "The elements of statistical learning", "author": ["J. Friedman", "T. Hastie", "R. Tibshirani"], "venue": "Vol. 1, Springer Series in Statistics", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2001}, {"title": "Machine Learning", "author": ["T.M. Mitchell"], "venue": "1st Edition, McGraw-Hill, Inc., New York, NY, USA", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1997}, {"title": "Mathematical statistics and data analysis", "author": ["J. Rice"], "venue": "Cengage Learning", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2006}, {"title": "An introduction to variable and feature selection", "author": ["I. Guyon", "A. Elisseeff"], "venue": "The Journal of Machine Learning Research 3 ", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2003}, {"title": "The WEKA data mining software: an update", "author": ["M. Hall", "E. Frank", "G. Holmes", "B. Pfahringer", "P. Reutemann", "I.H. Witten"], "venue": "ACM SIGKDD explorations newsletter 11 (1) ", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2009}, {"title": "LIBSVM: A library for Support Vector Machines", "author": ["C.-C. Chang", "C.-J. Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology (TIST) 2 (3) ", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2011}, {"title": "The problem of overfitting", "author": ["D.M. Hawkins"], "venue": "Journal of chemical information and computer sciences 44 (1) ", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2004}, {"title": "Developing an early warning system to predict currency crises", "author": ["C. Sevim", "A. Oztekin", "O. Bali", "S. Gumus", "E. Guresen"], "venue": "European Journal of Operational Research 237 (3) ", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2014}, {"title": "Composite forecasting: combining forecasts for improved accuracy", "author": ["C.W. Chase Jr"], "venue": "Journal of Business Forecasting Methods & Systems 19 (2) ", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2000}, {"title": "Making best use of model evaluations to compute sensitivity indices", "author": ["A. Saltelli"], "venue": "Computer Physics Communications 145 (2) ", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2002}], "referenceMentions": [{"referenceID": 0, "context": "Academia has mostly focused its attention on spammers, those accounts actively putting their efforts in spreading malware, sending spam, and advertising activities of doubtful legality [1, 2, 3, 4].", "startOffset": 185, "endOffset": 197}, {"referenceID": 1, "context": "Academia has mostly focused its attention on spammers, those accounts actively putting their efforts in spreading malware, sending spam, and advertising activities of doubtful legality [1, 2, 3, 4].", "startOffset": 185, "endOffset": 197}, {"referenceID": 2, "context": "Academia has mostly focused its attention on spammers, those accounts actively putting their efforts in spreading malware, sending spam, and advertising activities of doubtful legality [1, 2, 3, 4].", "startOffset": 185, "endOffset": 197}, {"referenceID": 3, "context": "Academia has mostly focused its attention on spammers, those accounts actively putting their efforts in spreading malware, sending spam, and advertising activities of doubtful legality [1, 2, 3, 4].", "startOffset": 185, "endOffset": 197}, {"referenceID": 4, "context": "However, artificially inflating the number of followers can also be finalized to make an account more trustworthy and influential, in order to stand from the crowd and to attract other genuine followers [5].", "startOffset": 203, "endOffset": 206}, {"referenceID": 5, "context": "Similarly, if the practice of buying fake followers is adopted by malicious accounts, as spammers, it can act as a way to post more authoritative messages and launch more effective advertising campaigns [6].", "startOffset": 203, "endOffset": 206}, {"referenceID": 6, "context": "Quoting from [7], \u201cA fake Twitter account is considered as one form of deception (i.", "startOffset": 13, "endOffset": 16}, {"referenceID": 7, "context": "accounts that advertise unsolicited and often harmful content, containing links to malicious pages [8]), or bots (i.", "startOffset": 99, "endOffset": 102}, {"referenceID": 8, "context": ", computer programs that control social accounts, as stealthy as to mimic real users [9]), or cyborgs (i.", "startOffset": 85, "endOffset": 88}, {"referenceID": 9, "context": ", accounts that interweave characteristics of both manual and automated behavior [10]).", "startOffset": 81, "endOffset": 85}, {"referenceID": 10, "context": "A series of reports published by the firm Digital evaluations [12] have attracted the attention of Italian and European newspapers and magazines, raising doubts on the Twitter popularity of politicians and leading international companies.", "startOffset": 62, "endOffset": 66}, {"referenceID": 10, "context": "The results in [12], however, lack a validation phase.", "startOffset": 15, "endOffset": 19}, {"referenceID": 11, "context": "Moreover, as demonstrated in our previous work [16], these analyses are affected by several biases like small and statistically unsound sampling strategies.", "startOffset": 47, "endOffset": 51}, {"referenceID": 3, "context": "As an example, a branch of research focused on the textual content of tweets [4, 3, 17], studying the redirection of embedded URLs in tweets [18], and classifying the URLs landing pages [19].", "startOffset": 77, "endOffset": 87}, {"referenceID": 2, "context": "As an example, a branch of research focused on the textual content of tweets [4, 3, 17], studying the redirection of embedded URLs in tweets [18], and classifying the URLs landing pages [19].", "startOffset": 77, "endOffset": 87}, {"referenceID": 12, "context": "As an example, a branch of research focused on the textual content of tweets [4, 3, 17], studying the redirection of embedded URLs in tweets [18], and classifying the URLs landing pages [19].", "startOffset": 77, "endOffset": 87}, {"referenceID": 13, "context": "As an example, a branch of research focused on the textual content of tweets [4, 3, 17], studying the redirection of embedded URLs in tweets [18], and classifying the URLs landing pages [19].", "startOffset": 141, "endOffset": 145}, {"referenceID": 14, "context": "As an example, a branch of research focused on the textual content of tweets [4, 3, 17], studying the redirection of embedded URLs in tweets [18], and classifying the URLs landing pages [19].", "startOffset": 186, "endOffset": 190}, {"referenceID": 15, "context": "For instance, in [20] authors evaluate 4 epistemological features for the task of deception detection: authority, plausibility and support, independent corroboration, and presentation.", "startOffset": 17, "endOffset": 21}, {"referenceID": 16, "context": "Work in [21] overcomes the limitation of not being able to correctly label those tweets without URLs as spam tweets, by proposing a composite tool, able to match incoming tweets with underlying templates commonly used by spammers.", "startOffset": 8, "endOffset": 12}, {"referenceID": 6, "context": "Instead of considering the content of tweets, work in [7] tries to classify if an account can be trusted or not based on possibly inconsistent information originating from the profile of the account only.", "startOffset": 54, "endOffset": 57}, {"referenceID": 7, "context": "Within this research line, we cite here [8], [2], and [22].", "startOffset": 40, "endOffset": 43}, {"referenceID": 1, "context": "Within this research line, we cite here [8], [2], and [22].", "startOffset": 45, "endOffset": 48}, {"referenceID": 17, "context": "Within this research line, we cite here [8], [2], and [22].", "startOffset": 54, "endOffset": 58}, {"referenceID": 7, "context": "The work in [8] presents an analysis on how spammers operate on Facebook, Twitter, and MySpace, reporting that the suspicious accounts shared some common traits on specific features.", "startOffset": 12, "endOffset": 15}, {"referenceID": 18, "context": "Those served as input to a machine learning-based classifier [23] leading to the detection of more than 15,000 spam profiles, that Twitter promptly deleted.", "startOffset": 61, "endOffset": 65}, {"referenceID": 1, "context": "In [2], the authors propose a taxonomy of criteria for detecting Twitter spammers.", "startOffset": 3, "endOffset": 6}, {"referenceID": 17, "context": "In [22], the authors leverage a combination of behavioral features (such as tweeting and retweeting activities), network features (such as the number of an account\u2019s followers and friends), and content-based features to develop a hybrid mathematical model for spammer detection in Weibo, the Chinese microblogging site resembling Twitter.", "startOffset": 3, "endOffset": 7}, {"referenceID": 9, "context": "The authors of [10] classify Twitter accounts in three classes: humans, bot, and cyborgs.", "startOffset": 15, "endOffset": 19}, {"referenceID": 19, "context": "The algorithms proposed in [24, 4] aim at spotting groups of automated malicious Twitter accounts as quickly as possible, to avoid the accounts\u2019 owners from taking advantage of them.", "startOffset": 27, "endOffset": 34}, {"referenceID": 3, "context": "The algorithms proposed in [24, 4] aim at spotting groups of automated malicious Twitter accounts as quickly as possible, to avoid the accounts\u2019 owners from taking advantage of them.", "startOffset": 27, "endOffset": 34}, {"referenceID": 20, "context": "In [25], the authors list several criteria to detect clients and victims of Twitter account markets, that are", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "In another work [26], the same research team provides more details about the account markets, analyzing additional properties and characteristics of their customers (e.", "startOffset": 16, "endOffset": 20}, {"referenceID": 22, "context": "The authors of [27] monitor prices, availability, and fraud perpetrated by a set of merchants of Twitter accounts over the course of a ten-months period.", "startOffset": 15, "endOffset": 19}, {"referenceID": 0, "context": "There are other works for spam detection, not detailed here, like [1, 28, 29, 30, 31, 32], which base their results on subsets, or on slightly modified versions, of criteria considered by the selected set of related work.", "startOffset": 66, "endOffset": 89}, {"referenceID": 23, "context": "There are other works for spam detection, not detailed here, like [1, 28, 29, 30, 31, 32], which base their results on subsets, or on slightly modified versions, of criteria considered by the selected set of related work.", "startOffset": 66, "endOffset": 89}, {"referenceID": 24, "context": "There are other works for spam detection, not detailed here, like [1, 28, 29, 30, 31, 32], which base their results on subsets, or on slightly modified versions, of criteria considered by the selected set of related work.", "startOffset": 66, "endOffset": 89}, {"referenceID": 25, "context": "There are other works for spam detection, not detailed here, like [1, 28, 29, 30, 31, 32], which base their results on subsets, or on slightly modified versions, of criteria considered by the selected set of related work.", "startOffset": 66, "endOffset": 89}, {"referenceID": 26, "context": "There are other works for spam detection, not detailed here, like [1, 28, 29, 30, 31, 32], which base their results on subsets, or on slightly modified versions, of criteria considered by the selected set of related work.", "startOffset": 66, "endOffset": 89}, {"referenceID": 7, "context": "From a technical point of view, in our experiments we rely on machine learning-based classifiers exploiting features of 1) profile, 2) activity, and 3) relationships of the accounts, similarly to [8, 2].", "startOffset": 196, "endOffset": 202}, {"referenceID": 1, "context": "From a technical point of view, in our experiments we rely on machine learning-based classifiers exploiting features of 1) profile, 2) activity, and 3) relationships of the accounts, similarly to [8, 2].", "startOffset": 196, "endOffset": 202}, {"referenceID": 12, "context": "Instead, we do not rely on features inherent to specific contents of tweets, such as the presence of URLs and the semantics of the text [17, 19].", "startOffset": 136, "endOffset": 144}, {"referenceID": 14, "context": "Instead, we do not rely on features inherent to specific contents of tweets, such as the presence of URLs and the semantics of the text [17, 19].", "startOffset": 136, "endOffset": 144}, {"referenceID": 21, "context": "Finally, similarly to [26], we bought fake Twitter followers from different markets available on the Web.", "startOffset": 22, "endOffset": 26}, {"referenceID": 21, "context": "We conducted such an exercise independently from [26] and, moreover, goals of the two works are quite different, ours focusing on accounts sold by these markets, while the other targeting their customers.", "startOffset": 49, "endOffset": 53}, {"referenceID": 27, "context": "In particular, Weiss and Provost, in [34], considered the performances of decision-tree based classifiers to predict the samples of 26 different datasets, with different distributions between the minority and majority classes.", "startOffset": 37, "endOffset": 41}, {"referenceID": 27, "context": "To validate this assumption, we performed the experiments in [34] to our dataset.", "startOffset": 61, "endOffset": 65}, {"referenceID": 10, "context": "These proposals were introduced in [12, 11, 14].", "startOffset": 35, "endOffset": 47}, {"referenceID": 10, "context": "Details on how aggregation has been performed are provided in [12] only.", "startOffset": 62, "endOffset": 66}, {"referenceID": 10, "context": "Driven by the provided details, we implement the full algorithm described in [12] and we present its detection performances in Section 4.", "startOffset": 77, "endOffset": 81}, {"referenceID": 10, "context": "Camisani-Calzolari [12] carried out a series of tests over samples of Twitter followers of Romney and Obama, for the last US presidential elections, as well as for popular Italian politicians.", "startOffset": 19, "endOffset": 23}, {"referenceID": 10, "context": "In [12] it is detailed an algorithm to evaluate an account based on some of its public features.", "startOffset": 3, "endOffset": 7}, {"referenceID": 28, "context": "The meaning of each indicator is graphically highlighted by the matrix in Table 5 (called the confusion matrix ), where each column represents the instances in the predicted class, while each row represents the instances in the actual class [36]: In order to evaluate the application of each single rule to the accounts in", "startOffset": 241, "endOffset": 245}, {"referenceID": 29, "context": "\u2022 Matthew Correlation Coefficient (MCC from now on) [37]: the estimator of the correlation between the predicted class and the real class of the samples, defined as:", "startOffset": 52, "endOffset": 56}, {"referenceID": 30, "context": "Moreover, there are situations where some predictive models perform better than others, even having a lower accuracy [38].", "startOffset": 117, "endOffset": 121}, {"referenceID": 30, "context": "Furthermore, MCC is considered the unbiased version of the F-Measure, since it uses all the four elements of the confusion matrix [38].", "startOffset": 130, "endOffset": 134}, {"referenceID": 31, "context": "For completeness, when available, we also report the area-under-the-curve metric (AUC ), that is the area under the Receiver Operating Characteristic (ROC) curve [39].", "startOffset": 162, "endOffset": 166}, {"referenceID": 32, "context": "It can be informally defined as the expected reduction in entropy caused by the knowledge of the value of a given attribute [40].", "startOffset": 124, "endOffset": 128}, {"referenceID": 10, "context": "Table 7: Evaluation of Camisani-Calzolari algorithm (CC algorithm) [12].", "startOffset": 67, "endOffset": 71}, {"referenceID": 33, "context": "tionship between two random variables X and Y [41, 42].", "startOffset": 46, "endOffset": 54}, {"referenceID": 34, "context": "tionship between two random variables X and Y [41, 42].", "startOffset": 46, "endOffset": 54}, {"referenceID": 10, "context": "The detection algorithm in [12] aggregates the 22 criteria for identifying human and bot behavior, introduced in Section 4.", "startOffset": 27, "endOffset": 31}, {"referenceID": 10, "context": "Camisani-Calzolari [12] (satisfaction of rules means human behavior) 1 profile has name 0.", "startOffset": 19, "endOffset": 23}, {"referenceID": 33, "context": "This is clearly not linearly dependent on the class values, resulting in lower values for the Pcc* with respect to the Pcc [41].", "startOffset": 123, "endOffset": 127}, {"referenceID": 10, "context": "Thus, we can derive that the rule is based on a right assumption (for example, the use of hashtags), but the rule definition is too simple to be effective: the algorithm proposed by [12] is simply too naive for the complex task of fake accounts detection in Twitter.", "startOffset": 182, "endOffset": 186}, {"referenceID": 7, "context": "In this section, we examine works in [8, 2] that address spam account detection on Twitter.", "startOffset": 37, "endOffset": 43}, {"referenceID": 1, "context": "In this section, we examine works in [8, 2] that address spam account detection on Twitter.", "startOffset": 37, "endOffset": 43}, {"referenceID": 31, "context": "In \u201cglassbox\u201d models, such as Decision Trees and Regression Models, the inner structure of the models can be understood by humans, also providing insights on how the classifiers identify fake accounts [39].", "startOffset": 201, "endOffset": 205}, {"referenceID": 7, "context": "The study presented in [8] focuses on spambot detection.", "startOffset": 23, "endOffset": 26}, {"referenceID": 18, "context": "For each investigated account, such characteristics are exploited in a Random Forest algorithm [23, 43], that outputs if the account is a spambot or not.", "startOffset": 95, "endOffset": 103}, {"referenceID": 35, "context": "For each investigated account, such characteristics are exploited in a Random Forest algorithm [23, 43], that outputs if the account is a spambot or not.", "startOffset": 95, "endOffset": 103}, {"referenceID": 7, "context": "The results of the analysis in [8] depicted some interesting features of the spambot accounts under investigation, as reported in Table 9.", "startOffset": 31, "endOffset": 34}, {"referenceID": 7, "context": "[8].", "startOffset": 0, "endOffset": 3}, {"referenceID": 20, "context": "This notion has been given in a later work by the same authors [25].", "startOffset": 63, "endOffset": 67}, {"referenceID": 1, "context": "The authors of [2] observed that Twitter spammers often modify their behavior in order to evade existing spam detection techniques.", "startOffset": 15, "endOffset": 18}, {"referenceID": 1, "context": "In Table 10 we detail nine of them, together with the outcome of their analysis in [2].", "startOffset": 83, "endOffset": 86}, {"referenceID": 23, "context": "age of the account (this feature also appears in [28]): the more an account is aged, the more it could be considered a good one; 6.", "startOffset": 49, "endOffset": 53}, {"referenceID": 1, "context": "[2].", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "The authors of [2] combine their features in four different machine learning classifiers and compare their implementation with other existing approaches.", "startOffset": 15, "endOffset": 18}, {"referenceID": 1, "context": "We were unable to completely reproduce the machine learning classifiers in [2], since we had a different dataset.", "startOffset": 75, "endOffset": 78}, {"referenceID": 1, "context": "As in [2], the following rate (feature 9) has been approximated with the ratio friends/age, since a precise evaluation would require to know the evolution of the number of friends of an account, but this is, indeed, publicly unavailable.", "startOffset": 6, "endOffset": 9}, {"referenceID": 1, "context": "Finally, in [2] there are also other features in addition to those mentioned above.", "startOffset": 12, "endOffset": 15}, {"referenceID": 7, "context": "[8] 1 number of friends 0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] 1 age 0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 36, "context": "Our SVM classifier exploits a Radial Basis Function (RBF) kernel and has been trained using libSVM as the machine learning algorithm [44].", "startOffset": 133, "endOffset": 137}, {"referenceID": 35, "context": "All the classifiers and the optimization algorithms employed in this work are implemented within the Weka framework [43].", "startOffset": 116, "endOffset": 120}, {"referenceID": 7, "context": "Among these algorithms, RF was the only one used in [8].", "startOffset": 52, "endOffset": 55}, {"referenceID": 1, "context": "Instead, authors of [2] employed D, RF, J48 and BN.", "startOffset": 20, "endOffset": 23}, {"referenceID": 31, "context": "We have decided to include AB in our work, since it is considered one of the most effective machine learning algorithms for classification tasks [39].", "startOffset": 145, "endOffset": 149}, {"referenceID": 1, "context": "[2] RF Random Forest 0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] RF Random Forest 0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "Then, we have used a 10-fold cross validation [23] to estimate the performances of each obtained classifier.", "startOffset": 46, "endOffset": 50}, {"referenceID": 1, "context": "The ones built over the feature set of [2] achieve slightly better results.", "startOffset": 39, "endOffset": 42}, {"referenceID": 1, "context": "In addition, all the classifiers based on the feature set by [2] have a higher AUC, when compared with the ones built with the feature set by [8].", "startOffset": 61, "endOffset": 64}, {"referenceID": 7, "context": "In addition, all the classifiers based on the feature set by [2] have a higher AUC, when compared with the ones built with the feature set by [8].", "startOffset": 142, "endOffset": 145}, {"referenceID": 1, "context": "[2] show that the features of Stringhini et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] exhibit the tendency to consider as fake followers some human accounts.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "With both the [2] and [8] feature sets, BN, kNN and LR classifiers achieve, overall, worse performances.", "startOffset": 14, "endOffset": 17}, {"referenceID": 7, "context": "With both the [2] and [8] feature sets, BN, kNN and LR classifiers achieve, overall, worse performances.", "startOffset": 22, "endOffset": 25}, {"referenceID": 1, "context": "The SVM classifier, instead, achieves remarkable results, especially with the feature set of [2].", "startOffset": 93, "endOffset": 96}, {"referenceID": 7, "context": "Looking at the tree structure, we observe some interesting differences between the fake followers in our BAS dataset and the spam accounts characterized in [8] and [2].", "startOffset": 156, "endOffset": 159}, {"referenceID": 1, "context": "Looking at the tree structure, we observe some interesting differences between the fake followers in our BAS dataset and the spam accounts characterized in [8] and [2].", "startOffset": 164, "endOffset": 167}, {"referenceID": 7, "context": "For example, the feature URL ratio has been found to have a higher value for spammers than for legitimate users, as highlighted in [8] (Section 5.", "startOffset": 131, "endOffset": 134}, {"referenceID": 1, "context": "Similarly, the API ratio feature has been found higher for spammers than for legitimate accounts ([2], see also Section 5.", "startOffset": 98, "endOffset": 101}, {"referenceID": 1, "context": "A similar behavior has been observed for the average neighbor\u2019s tweets feature, that has been found to be lower for spammers in [2], but higher for our fake followers.", "startOffset": 128, "endOffset": 131}, {"referenceID": 37, "context": "It is well known that trained classifiers can be subject to \u201coverfitting\u201d, namely the problem of being too specialized on the training dataset and unable to generalize the classification to new and unseen data [45].", "startOffset": 210, "endOffset": 214}, {"referenceID": 7, "context": "[8] has 22 leaves, 43 nodes, and a height of 7, whereas the best feature is the friends/(followers\u02c62) ratio that places at the root.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] has 17 leaves, 33 nodes and a height of 8, with the bi-directional link ratio as the root.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] subtree raising 0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] subtree raising 0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2], without the bi-link ratio feature subtree raising 0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": ", by using the reduce-error pruning with small test sets [23, 43].", "startOffset": 57, "endOffset": 65}, {"referenceID": 35, "context": ", by using the reduce-error pruning with small test sets [23, 43].", "startOffset": 57, "endOffset": 65}, {"referenceID": 1, "context": "[2], reducing the number of nodes from 33 to 11 decreases the accuracy of 0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] reduces its recall of 0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] only drops of 0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "95 (as in the last lines of Table 13, for [8] and [2], respectively).", "startOffset": 42, "endOffset": 45}, {"referenceID": 1, "context": "95 (as in the last lines of Table 13, for [8] and [2], respectively).", "startOffset": 50, "endOffset": 53}, {"referenceID": 1, "context": "[2], and the friends/(followers\u02c62), URL ratio, and number of friends as the subset for the Stringhini et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] original feature set.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] and compare its effectiveness against the classifier built with the complete set.", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "Camisani-Calzolari [12] has name, has image, has address, has biography, followers \u2265 30, belongs to a list, tweets \u2265 50, URL in profile, 2 \u00d7 followers \u2265 friends geo-localized, is favorite, uses punctuation, uses hashtag, uses iPhone, uses Android, uses Foursquare, uses Instagram, uses Twitter.", "startOffset": 19, "endOffset": 23}, {"referenceID": 7, "context": "[8] number of friends, number of tweets, friends (followers\u02c62) tweet similarity, URL ratio", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] age, following rate API ratio, API URL ratio, API tweet similarity bi-link ratio, average neighbors\u2019 followers, average neighbors\u2019 tweets, followings to median neighbor\u2019s followers", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] seems to be slightly more effective than the one proposed by Stringhini et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8], when used in feature-based classifiers aiming at fake followers detection.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2], that belongs to Class C.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] and Stringhini et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8], as reported in Table 12.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "We have to point out, however, that countermeasures could be taken to evade some of the simplest features our classifiers are built upon [2].", "startOffset": 137, "endOffset": 140}, {"referenceID": 21, "context": "All the accounts acquired with the two aforementioned approaches have been labeled as humans, following the same approach used in [26].", "startOffset": 130, "endOffset": 134}, {"referenceID": 38, "context": "In order to estimate the importance of the single features among all the 8 classifiers, we followed the information fusion-based sensitivity analysis technique adopted in [46].", "startOffset": 171, "endOffset": 175}, {"referenceID": 39, "context": "Information fusion is a technique aimed at leveraging the predictive power of several different models in order to achieve a combined prediction accuracy which is better than the predictions of the single models [47].", "startOffset": 212, "endOffset": 216}, {"referenceID": 40, "context": "Sensitivity analysis, instead, aims at assessing the relative importance of the different features used to build a classification model [48].", "startOffset": 136, "endOffset": 140}, {"referenceID": 7, "context": "1 friends/(followers\u02c62) ratio [8] 1.", "startOffset": 30, "endOffset": 33}, {"referenceID": 1, "context": "000 2 age [2, 28, 4, 1] 0.", "startOffset": 10, "endOffset": 23}, {"referenceID": 23, "context": "000 2 age [2, 28, 4, 1] 0.", "startOffset": 10, "endOffset": 23}, {"referenceID": 3, "context": "000 2 age [2, 28, 4, 1] 0.", "startOffset": 10, "endOffset": 23}, {"referenceID": 0, "context": "000 2 age [2, 28, 4, 1] 0.", "startOffset": 10, "endOffset": 23}, {"referenceID": 0, "context": "919 3 number of tweets [1, 4, 8, 12, 14] 0.", "startOffset": 23, "endOffset": 40}, {"referenceID": 3, "context": "919 3 number of tweets [1, 4, 8, 12, 14] 0.", "startOffset": 23, "endOffset": 40}, {"referenceID": 7, "context": "919 3 number of tweets [1, 4, 8, 12, 14] 0.", "startOffset": 23, "endOffset": 40}, {"referenceID": 10, "context": "919 3 number of tweets [1, 4, 8, 12, 14] 0.", "startOffset": 23, "endOffset": 40}, {"referenceID": 10, "context": "816 4 profile has name [12] 0.", "startOffset": 23, "endOffset": 27}, {"referenceID": 26, "context": "782 5 number of friends [32, 8, 14, 4] 0.", "startOffset": 24, "endOffset": 38}, {"referenceID": 7, "context": "782 5 number of friends [32, 8, 14, 4] 0.", "startOffset": 24, "endOffset": 38}, {"referenceID": 3, "context": "782 5 number of friends [32, 8, 14, 4] 0.", "startOffset": 24, "endOffset": 38}, {"referenceID": 10, "context": "781 6 has URL in profile [12] 0.", "startOffset": 25, "endOffset": 29}, {"referenceID": 1, "context": "768 7 following rate [2] 0.", "startOffset": 21, "endOffset": 24}, {"referenceID": 10, "context": "755 9 belongs to a list [12] 0.", "startOffset": 24, "endOffset": 28}, {"referenceID": 10, "context": "752 10 profile has image [12] 0.", "startOffset": 25, "endOffset": 29}, {"referenceID": 10, "context": "707 16 has address [12] 0.", "startOffset": 19, "endOffset": 23}, {"referenceID": 10, "context": "664 18 has biography [12] 0.", "startOffset": 21, "endOffset": 25}, {"referenceID": 10, "context": "602 19 number of followers [12, 4, 3] 0.", "startOffset": 27, "endOffset": 37}, {"referenceID": 3, "context": "602 19 number of followers [12, 4, 3] 0.", "startOffset": 27, "endOffset": 37}, {"referenceID": 2, "context": "602 19 number of followers [12, 4, 3] 0.", "startOffset": 27, "endOffset": 37}], "year": 2017, "abstractText": "Fake followers are those Twitter accounts specifically created to inflate the number of followers of a target account. Fake followers are dangerous for the social platform and beyond, since they may alter concepts like popularity and influence in the Twittersphere\u2014hence impacting on economy, politics, and society. In this paper, we contribute along different dimensions. First, we review some of the most relevant existing features and rules (proposed by Academia and Media) for anomalous Twitter accounts detection. Second, we create a baseline dataset of verified human and fake follower accounts. Such baseline dataset is publicly available to the scientific community. Then, we exploit the baseline dataset to train a set of machine-learning classifiers built over the reviewed rules and features. Our results show that most of the rules proposed by Media provide unsatisfactory performance in revealing fake followers, while features proposed in the past by Academia for spam detection provide good results. Building on the most promising features, we revise the classifiers both in terms of reduction of overfitting and cost for gathering the data needed to compute the features. The final result is a novel Class A classifier, general enough to thwart overfitting, lightweight thanks to the usage of the less costly features, and still able to correctly classify more than 95% of the accounts of the original training set. We ultimately perform an information fusion-based sensitivity analysis, to assess the global sensitivity of each of the features employed by the classifier. The findings reported in this paper, other than being supported by a thorough experimental methodology and interesting on their own, also pave the way for further investigation on the novel issue of fake Twitter followers.", "creator": "LaTeX with hyperref package"}}}