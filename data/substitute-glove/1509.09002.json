{"id": "1509.09002", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Sep-2015", "title": "Convergence of Stochastic Gradient Descent for PCA", "abstract": "We agree however certain instance teacher component data (PCA) leaving. streaming diophantine break, alone help goal as also good after moving of approximate maximal finite, consulting well a stream of just. nobody. d. data points in $ \\ mathbb {R} ^ oberstar $. A simple like passably soft algorithm having done is stochastic gradients movements (SGD ), with stabilized key its predicting 's came there new data clear. However, because same 's moreover - convex nature present although problem, analyzing bringing addition have been a believes. In as, implemented guarantee require on of non - definite eigengap hence new to cartesian matrix, is one intuitively unfair. In very comparison, we enables (able long best addition our physical) full 1999 eigengap - but geographical promise six SGD its now merely there PCA. This had partially wschowa now sunday that doubts although [Hardt and Price, 2013 ].", "histories": [["v1", "Wed, 30 Sep 2015 03:02:59 GMT  (17kb)", "https://arxiv.org/abs/1509.09002v1", "18 pages"], ["v2", "Mon, 4 Jan 2016 08:25:56 GMT  (21kb)", "http://arxiv.org/abs/1509.09002v2", "Added analysis of the positive eigengap scenario, with new results; Some minor corrections"]], "COMMENTS": "18 pages", "reviews": [], "SUBJECTS": "cs.LG math.OC stat.ML", "authors": ["ohad shamir"], "accepted": true, "id": "1509.09002"}, "pdf": {"name": "1509.09002.pdf", "metadata": {"source": "CRF", "title": "Convergence of Stochastic Gradient Descent for PCA", "authors": ["Ohad Shamir"], "emails": ["ohad.shamir@weizmann.ac.il"], "sections": [{"heading": null, "text": "ar X\niv :1\n50 9.\n09 00\n2v 2\n[ cs\n.L G\n] 4\nJ an\n2 01"}, {"heading": "1 Introduction", "text": "Principal component analysis (PCA) [20, 11] is a fundamental tool in data analysis and visualization, designed to find the subspace of largest variance in a given dataset (a set of points in Euclidean space). We focus on a simple stochastic setting, where the data x1,x2, . . . \u2208 Rd is assumed to be drawn i.i.d. from an unknown underlying distribution, and our goal is to find a direction of approximately maximal variance. This can be written as the optimization problem\nmin w:\u2016w\u2016=1\n\u2212w\u22a4E[xx\u22a4]w, (1)\nor equivalently, finding an approximate leading eigenvector of the covariance matrix E[xx\u22a4]. The conceptually simplest method for this task, given m sampled points x1, . . . ,xm, is to construct the empirical covariance matrix 1m \u2211m i=1 xix \u22a4 i , and compute its leading eigenvector by an eigendecomposition. Based on concentration of measure arguments, it is not difficult to show that this would result in an O( \u221a\n1/m)-optimal solution to Eq. (1). Unfortunately, the runtime of this method is O(md2 + d3). In large-scale applications, both m and d might be huge, and even forming the d \u00d7 d covariance matrix, let alone performing an eigendecomposition, can be computationally prohibitive. A standard alternative to exact eigendecomposition is iterative methods, such as power iterations or the Lanczos method, which require performing multiple products of a vector with the empirical covariance matrix. Although this doesn\u2019t require computing and storing the matrix explicitly, it still requires multiple passes over the data, whose number may scale with eigengap parameters of the matrix or the target accuracy [14, 16]. Recently, new randomized algorithms for this problem were able to significantly reduce the required number of passes, while maintaining the ability to compute high-accuracy solutions [25, 24, 8, 12].\nIn this work, we consider the efficacy of algorithms which perform a single pass over the data, and in particular, stochastic gradient descent (SGD). For solving Eq. (1), SGD corresponds to initializing at some unit vector w0, and then at each iteration t perform a stochastic gradient step with respect to xtx\u22a4t (which is an unbiased estimate of E[xx\u22a4]), followed by a projection to the unit sphere:\nwt := (I + \u03b7xtx \u22a4 t )wt\u22121 , wt := wt/\u2016wt\u2016.\nHere, \u03b7 is a step size parameter. In the context of PCA, this is also known as Oja\u2019s method [18, 19]. The algorithm is highly efficient in terms of memory and runtime per iteration, requiring storage of a single d-dimensional vector, and performing only vector-vector and a vector-scalar products in each iteration.\nIn the world of convex stochastic optimization and learning, SGD has another remarkable property: Despite it being a simple, one-pass algorithm, it is essentially (worst-case) statistically optimal, attaining the same statistical estimation error rate as exact empirical risk minimization [5, 23, 22]. Thus, it is quite natural to ask whether SGD also performs well for the PCA problem in Eq. (1), compared to statistically optimal but computationally heavier methods.\nThe study of SGD (or variants thereof) for PCA has gained interest in recent years, with some notable examples including [1, 3, 2, 15, 10, 7, 12]. While experimentally SGD appears to perform reasonably well, its theoretical analysis has proven difficult, due to the non-convex nature of the objective function in Eq. (1). Remarkably, despite this non-convexity, finite-time convergence guarantees have been obtained under an eigengap assumption \u2013 namely, that the difference between the largest and 2nd-largest eigenvalues of E[xx\u22a4] are separated by some fixed value \u03bb > 0. For example, [7] require O(d/\u03bb2\u01eb) iterations to ensure with high probability that one of the iterates is \u01eb-optimal. [12] require O(1/\u03bb2 + 1/\u03bb\u01eb) iterations, provided we begin close enough to an optimal solution.\nNevertheless, one may ask whether the eigengap assumption is indeed necessary, if our goal is simply to find an approximately optimal solution of Eq. (1). Intuitively, if E[xx\u22a4] has two equal (or near equal) top eigenvalues, then we may still expect to get a solution which lies close to the subspace of these two top eigenvalues, and approximately minimizes Eq. (1), with the runtime not dependent on any eigengap. Unfortunately, existing results tell us nothing about this regime, and not just for minor technical reasons: These results are based on tracking the geometric convergence of the SGD iterates wt to a leading eigenvector of the covariance matrix. When there is no eigengap, there is also no single eigenvector to converge to, and such a geometric approach does not seem to work. Getting an eigengap-free analysis has also been posed as an open problem in [10]. We note that while there are quite a few other single-pass, eigengap-free methods for this problem, such as [28, 29, 17, 6, 9, 13], their memory and runtime-per iteration requirements are much higher than SGD, often O(d2) or worse.\nIn this work, we study the convergence of SGD for PCA, using a different technique that those employed in previous works, with the following main results:\n\u2022 We provide the first (to the best of our knowledge) SGD convergence guarantee which does not pose an eigengap assumption. Roughly speaking, we prove that if the step size is chosen appropriately, then after T iterations starting from random initialization, with positive probability, SGD returns an O\u0303( \u221a\np/T )-optimal1 solution of Eq. (1), where p is a parameter depending on how the algorithm is initialized:\n\u2013 If the algorithm is initialized from a warm-start point w0 such that 1\u3008v,w0\u30092 \u2264 O(1) for some leading eigenvector v of the covariance matrix, then p = O(1).\n1Throughout, we use O, \u2126 to hide constants, and O\u0303, \u2126\u0303 to hide constants and logarithmic factors.\n\u2013 Under uniform random initialization on the unit Euclidean sphere, p = O(d), where d is the dimension.\n\u2013 Using a more sophisticated initialization (requiring the usage of the first O(d) iterations, but no warm-start point), p = O\u0303(nA), where nA is the numerical rank of the covariance matrix. The numerical rank is a relaxation of the standard notion of rank, is always at most d and can be considered a constant under some mild assumptions.\n\u2022 In the scenario of a positive eigengap \u03bb > 0, and using a similar proof technique, we prove an SGD convergence guarantee of O(p/\u03bbT ) (where p is as above) with positive probability. This guarantee is optimal in terms of dependence on T, \u03bb, and in particular, has better dependence on \u03bb compared to all previous works on SGD-like methods we are aware of (1/\u03bb as opposed to 1/\u03bb2).\nUnfortunately, a drawback of our guarantees is that they only hold with rather low probability: \u2126(1/p), which can be small if p is large. Formally, this can be overcome by repeating the algorithm O\u0303(p) times, which ensures that with high probability, at least one of the outputs will be close to optimal. However, we suspect that these low probabilities are an artifact of our proof technique, and resolving it is left to future work."}, {"heading": "2 Setting", "text": "We use bold-faced letters to denote vectors, and capital letters to denote matrices. Given a matrix M , we let \u2016M\u2016 denote its spectral norm, and \u2016M\u2016F its Frobenius norm.\nWe now present the formal problem setting, in a somewhat more general way than the PCA problem considered earlier. Specifically, we study the problem of solving\nmin w\u2208Rd:\u2016w\u2016=1\n\u2212w\u22a4Aw, (2)\nwhere d > 1 and A is a positive semidefinite matrix, given access to a stream of i.i.d. positive semidefinite matrices A\u0303t where E[A\u0303t] = A (e.g. xtx\u22a4t in the PCA case). Notice that the gradient of Eq. (2) at a point w equals 2Aw, with an unbiased stochastic estimate being 2A\u0303tw. Therefore, applying SGD to Eq. (2) reduces to the following: Initialize at some unit-norm vector w0, and for t = 1, . . . , T , perform wt = (I + \u03b7A\u0303t)wt\u22121,wt = wt/\u2016wt\u2016, returning wT . In fact, for the purpose of the analysis, it is sufficient to consider a formally equivalent algorithm, which only performs the projection to the unit sphere at the end:\n\u2022 Initialize by picking a unit norm vector w0\n\u2022 For t = 1, . . . , T , perform wt = (I + \u03b7A\u0303t)wt\u22121\n\u2022 Return wT\u2016wT \u2016 It is easy to verify that the output of this algorithm is mathematically equivalent to the original SGD algorithm, since the stochastic gradient step amounts to multiplying wt\u22121 by a matrix independent of wt\u22121, and the projection just amounts to re-scaling. In both cases, we can write the algorithm\u2019s output in closed form as\n(\n\u220f1 t=T (I + \u03b7A\u0303t)\n)\nw0 \u2225 \u2225 \u2225 (\n\u220f1 t=T (I + \u03b7A\u0303t)\n)\nw0\n\u2225 \u2225 \u2225\n."}, {"heading": "3 Convergence Without an Eigengap Assumption", "text": "Our main result is the following theorem, which analyzes the performance of SGD for solving Eq. (2).\nTheorem 1. Suppose that\n\u2022 For some leading eigenvector v of A, 1\u3008v,w0\u30092 \u2264 p for some p (assumed to be \u2265 8 for simplicity).\n\u2022 For some b \u2265 1, both \u2016A\u0303t\u2016\u2016A\u2016 and \u2016A\u0303t\u2212A\u2016 \u2016A\u2016 are at most b with probability 1.\nIf we run the algorithm above for T iterations with \u03b7 = 1 b \u221a pT (assumed to be \u2264 1), then with probability at least 1cp , the returned w satisfies\n1\u2212 w \u22a4Aw \u2016A\u2016 \u2264 c\n\u2032 log(T )b \u221a p\u221a\nT ,\nwhere c, c\u2032 are positive numerical constants.\nThe proof and an outline of its main ideas appears in Subsection 5.1 below. Note that this is a multiplicative guarantee on the suboptimality of Eq. (2), since we normalize by \u2016A\u2016, which is the largest magnitude Eq. (2) can attain. By multiplying both sides by \u2016A\u2016, we can convert this to an additive bound of the form\n\u2016A\u2016 \u2212w\u22a4Aw \u2264 c\u2032 log(T )b \u2032\u221ap\u221a\nT ,\nwhere b\u2032 is a bound on max { \u2016A\u0303t\u2016, \u2016A\u0303t \u2212A\u2016 } . Also, note that the choice of \u03b7 in the theorem is not crucial, and similar bounds (with different c, c\u2032) can be shown for other \u03b7 = \u0398(1/b \u221a pT ).\nThe value of p in the theorem depends on how the initial point w0 is chosen. One possibility, of course, is if we can initialize the algorithm from a \u201cwarm-start\u201d point w0 such that 1\u3008v,w0\u30092 \u2264 O(1), in which case the bound in the theorem becomes O(log(T )/ \u221a T ) with probability \u2126(1). Such a w0 may be given by some other algorithm, or alternatively, if we are interested in analyzing SGD in the regime where it is close to one of the leading eigenvectors.\nOf course, such an assumption is not always relevant, so let us turn to consider the performance without such a \u201cwarm-start\u201d. For example, the simplest and most common way to initialize w0 is by picking it uniformly at random from the unit sphere. In that case, for any v, \u3008v,w0\u30092 = \u0398(1/d) with high constant probability2 , so the theorem above applies with p = O(d):\nCorollary 1. If w0 is chosen uniformly at random from the unit sphere in Rd, then Thm. 1 applies with p = O(d), and the returned w satisfies, with probability at least \u2126(1/d),\n1\u2212 w \u22a4Aw \u2016A\u2016 \u2264 O\n( log(T )b \u221a d\u221a\nT\n)\n,\n2One way to see this is by assuming w.l.o.g. that v = e1 and noting that the distribution of w0 is the same as w/\u2016w\u2016 where w has a standard Gaussian distribution, hence \u3008v,w0\u30092 = w21/ \u2211 j w2j , and by using standard concentration tools it can be shown that the numerator is \u0398(1) and the denominator is \u0398(d) with high probability.\nWhile providing some convergence guarantee, note that the probability of success is low, scaling down linearly with d. One way to formally solve this is to repeat the algorithm \u2126(d) times, which ensures that with high probability, at least one output will succeed (and finding it can be done empirically by testing the outputs on a validation set). However, it turns out that by picking w0 in a smarter way, we can get a bound where the d factors are substantially improved.\nSpecifically, we consider the following method, parameterized by number of iterations T0, which are implemented before the main algorithm above:\n\u2022 Sample w from a standard Gaussian distribution on Rd\n\u2022 Let w0 = 0.\n\u2022 For t = 1, . . . , T0, let w0 := w0 + 1T0 A\u0303tw\n\u2022 Return w0 := w0\u2016w0\u2016 .\nEssentially, instead of initializing from a random point w, we initialize from\nA\u0303w\n\u2016A\u0303w\u2016 , where A\u0303 =\n1\nT0\nT0 \u2211\nt=1\nA\u0303t.\nSince A\u0303 is a mean of T0 random matrices with mean A, this amounts to performing a single approximate power iteration. Recently, it was shown that a single exact power iteration can improve the starting point of stochastic methods for PCA [24]. The method above extends this idea to a purely streaming setting, where we only have access to stochastic approximations of A.\nThe improved properties of w0 with this initialization is formalized in the following lemma (where \u2016A\u2016F denotes the Frobenius norm of A):\nLemma 1. The following holds for some numerical constants c, c\u2032 > 0: For w0 as defined above, if T0 \u2265 cdb2 log(d), then with probability at least 710 \u2212 2d \u2212 exp(\u2212d/8),\n1\n\u3008v,w0\u30092 \u2264 c\u2032 log(d)nA,\nwhere nA = \u2016A\u20162F \u2016A\u20162 is the numerical rank of A.\nThe proof is provided in Subsection 5.2. Combining this with Thm. 1, we immediately get the following corollary:\nCorollary 2. If w0 is initialized as described above, then Thm. 1 applies with p = O(log(d)nA), and the returned w satisfies, with probability at least \u2126(1/nA log(d)),\n1\u2212 w \u22a4Aw \u2016A\u2016 \u2264 O\n(\nlog(T )b \u221a\nlog(d)nA\u221a T\n)\n,\nThe improvement of Corollary 2 compared to Corollary 1 depends on how much smaller is nA, the numerical rank of A, compared to d. We argue that in most cases, nA is much smaller, and often can be thought of as a moderate constant, in which case Corollary 2 provides an O\u0303 (\nb\u221a T\n)\nerror bound with\nprobability \u2126\u0303(1), at the cost of O\u0303(db2) additional iterations at the beginning. Specifically:\n\u2022 nA is always in [1, d], and in particular, can never be larger than d.\n\u2022 nA is always upper bounded by the rank of A, and is small even if A is only approximately low rank. For example, if the spectrum of A has polynomial decay i\u2212\u03b1 where \u03b1 > 1, then nA will be a constant independent of d. Moreover, to begin with, PCA is usually applied in situations where we hope A is close to being low rank.\n\u2022 When A\u0303t is of rank 1 (which is the case, for instance, in PCA, where A\u0303t equals the outer product of the t-th datapoint xt), we have nA \u2264 b2, where we recall that b upper bounds the scaled spectral norm of A\u0303t. In machine learning application, the data norm is often assumed to be bounded, hence b is not too large. To see why this holds, note that for rank 1 matrices, the spectral and Frobenius norms coincide, hence\nnA = (\u2016A\u2016F \u2016A\u2016\n)2\n=\n(\n\u2016E[A\u03031]\u2016F \u2016A\u2016\n)2\n\u2264 ( E [ \u2016A\u03031\u2016F \u2016A\u2016\n])2\n=\n(\nE\n[\n\u2016A\u03031\u2016 \u2016A\u2016\n])2\n\u2264 b2,\nwhere we used Jensen\u2019s inequality.\nSimilar to Corollary 1, we can also convert the bound of Corollary 2 into a high-probability bound, by repeating the algorithm O\u0303(nA) times."}, {"heading": "4 Convergence under an Eigengap Assumption", "text": "Although our main interest so far has been the convergence of SGD without any eigengap assumptions, we show in this section that our techniques also imply new bounds for PCA with an eigengap assumptions, which in certain aspects are stronger than what was previously known.\nSpecifically, we consider the same setting as before, but where the ratio s1\u2212s2s1 , where s1, s2 are the leading singular values of the covariance matrix A is assumed to be strictly positive and lower bounded by some fixed \u03bb > 0. Using this assumption and a proof largely similar to that of Thm. 1, we have the following theorem:\nTheorem 2. Under the same conditions as Thm. 1, suppose furthermore that\n\u2022 The top two eigenvalues of A have a gap \u03bb\u2016A\u2016 > 0\n\u2022 log 2(T )b2p \u03bbT \u2264\nlog(T )b \u221a p\u221a\nT\nIf we run the algorithm above for T > 1 iterations with \u03b7 = log(T )\u03bbT (assumed to be \u2264 1), then with probability at least 1cp , the returned w satisfies\n1\u2212 w \u22a4Aw \u2016A\u2016 \u2264 c \u2032 log 2(T )b2p \u03bbT ,\nwhere c, c\u2032 are positive numerical constants.\nThe proof appears in Subsection 5.3. Considering first the technical conditions of the theorem, we\nnote that assuming log 2(T )b2p \u03bbT \u2264\nlog(T )b \u221a p\u221a\nT simply amounts to saying that T is sufficiently large so that the\nO ( log2(T )b2p \u03bbT ) bound provided by Thm. 2 is better than the O (\nlog(T )b \u221a p\u221a\nT\n)\nbound provided by Thm. 1, by\nmore than a constant. This is the interesting regime, since otherwise we might as well choose \u03b7 as in Thm. 1 and get a better bound without any eigengap assumptions. Moreover, as in Thm. 1, a similar proof would hold if the step size is replaced by c log(T )/\u03bbT for some constant c \u2265 1.\nAs in Thm. 1, we note that p can be as large as d under random initialization, but this can be improved to the numerical rank of A using an approximate power iteration, or by analyzing the algorithm starting from a warm-start point w0 for which 1\u3008v,w0\u30092 \u2264 O(1) for a leading eigenvector v of A. Also, note that under an eigengap assumption, if 1 \u2212 w\u22a4Aw\u2016A\u2016 goes to 0 with the number of iterations T , it must hold that \u3008v,w\u30092 goes to 1 for a leading eigenvector of A, so the analysis with p = O(1) is also relevant for analyzing SGD for sufficiently large T , once we\u2019re sufficiently close to the optimum.\nComparing the bound to previous bounds in the literature for SGD-like methods (which all assume an eigengap, e.g. [3, 10, 7, 12]), an interesting difference is that the dependence on the eigengap \u03bb is only 1/\u03bb, as opposed to 1/\u03bb2 or worse. Intuitively, we are able to improve this dependence since we track the suboptimality directly, as opposed to tracking how wT converges to a leading eigenvector, say in terms of the Euclidean norm. This has an interesting parallel in the analysis of SGD for \u03bb-strongly convex functions, where the suboptimality of wT decays as O\u0303(1/\u03bbT ), although E[\u2016wT \u2212 w\u2217\u20162] can only be bounded by O(1/\u03bb2T ) (compare for instance Lemma 1 in [21] and Theorem 1 in [26]). Quite recently, Jin et al. ([12]) proposed another streaming algorithm which does have only 1/\u03bb dependence (at least for sufficiently large T ), and a high probability convergence rate which is even asymptotically optimal in some cases. However, their formal analysis is from a warm-start point (which implies p = O(1) in our notation), whereas the analysis here applies to any starting point. Moreover, the algorithm in [12] is different and more complex, whereas our focus here is on the simple and practical SGD algorithm. Finally, we remark that although an O(1/\u03bbT ) convergence rate is generally optimal (using any algorithm), we do not know whether the dependence on b and p in the convergence bound of Thm. 2 for SGD is optimal, or whether it can be improved."}, {"heading": "5 Proofs", "text": ""}, {"heading": "5.1 Proof of Thm. 1", "text": "To simplify things, we will assume that we work in a coordinate system where A is diagonal, A = diag(s1, . . . , sd), where s1 \u2265 s2 \u2265 . . . \u2265 sd \u2265 0, and s1 is the eigenvalue corresponding to v. This is without loss of generality, since the algorithm and the theorem conditions are invariant to the choice of coordinate system. Moreover, since the objective function in the theorem is invariant to \u2016A\u2016, we shall assume that \u2016A\u2016 = s1 = 1. Under these assumptions, the theorem\u2019s conditions reduce to:\n\u2022 1 w20,1 \u2264 p, for some p \u2265 8\n\u2022 b \u2265 1 is an upper bound on \u2016A\u0303t\u2016, \u2016A\u0303t \u2212A\u2016\nLet \u01eb \u2208 (0, 1) be a parameter to be determined later. The proof works by lower bounding the probability of the objective function (which under the assumption \u2016A\u2016 = 1, equals 1 \u2212 w\u22a4Aw) being suboptimal by at most \u01eb. This can be written as\nPr\n( w \u22a4 T (I \u2212A)wT \u2016wT \u20162 \u2264 \u01eb ) ,\nor equivalently,\nPr ( w \u22a4 T ((1\u2212 \u01eb)I \u2212A)wT \u2264 0 ) .\nLetting VT = w \u22a4 T ((1\u2212 \u01eb)I \u2212A)wT ,\nwe need to lower bound Pr(VT \u2264 0). In analyzing the convergence of stochastic gradient descent, a standard technique to bound such probabilities is via a martingale analysis, showing that after every iteration, the objective function decreases by a certain amount. Unfortunately, due to the non-convexity of the objective function here, the amount of decrease at iteration t critically depends on the current iterate wt, and in the worst case may even be 0 (e.g. if wt is orthogonal to the leading eigenvector, and there is no noise). Moreover, analyzing the evolution of wt is difficult, especially without eigengap assumptions, where there isn\u2019t necessarily some fixed direction which wt converges to. Hence, we are forced to take a more circuitous route.\nIn a nutshell, the proof is composed of three parts. First, we prove that if \u01eb and the step size \u03b7 are\nchosen appropriately, then E[VT ] \u2264 \u2212\u2126\u0303 ( (1 + \u03b7)2T \u01ebp ) . If we could also prove a concentration result, namely that VT is not much larger than its expectation, this would imply that Pr(VT \u2264 0) is indeed large. Unfortunately, we do not know how to prove such concentration. However, it turns out that it is possible to prove that VT is not much smaller than its expected value: More precisely, that VT \u2265 \u2212O\u0303 ( (1 + \u03b7)2T \u01eb ) with high probability. We then show that given such a high-probability lower bound on VT , and a bound on its expectation, we can produce an upper bound on VT which holds with probability \u2126\u0303(1/p), hence leading to the result stated in the theorem.\nWe begin with a preliminary technical lemma:\nLemma 2. For any \u01eb, \u03b7 \u2208 (0, 1), and integer k \u2265 0,\nmax s\u2208[0,1]\n(1 + \u03b7s)k(1\u2212 \u01eb\u2212 s) \u2264 1 + 2(1 + \u03b7(1 \u2212 \u01eb)) k\n\u03b7(k + 1) .\nProof. The result trivially holds for k = 0, so we will assume k > 0 from now. Let\nf(s) = (1 + \u03b7s)k(1\u2212 \u01eb\u2212 s).\nDifferentiating f and setting to zero, we have\nk\u03b7(1 + \u03b7s)k\u22121(1\u2212 \u01eb\u2212 s)\u2212 (1 + \u03b7s)k = 0 \u21d4 k\u03b7(1\u2212 \u01eb\u2212 s) = 1 + \u03b7s\n\u21d4 k\u03b7(1\u2212 \u01eb)\u2212 1 k\u03b7 + \u03b7 = s \u21d4 s = k(1 \u2212 \u01eb)\u2212 1/\u03b7 k + 1 .\nLet sc = k(1\u2212\u01eb)\u22121/\u03b7\nk+1 denote this critical point, and consider two cases:\n\u2022 sc /\u2208 [0, 1]: In that case, f has no critical points in the domain, hence is maximized at one of the domain endpoints, with a value of at most\nmax{f(0), f(1)} = max{1\u2212 \u01eb,\u2212\u01eb(1 + \u03b7)k} \u2264 1.\n\u2022 sc \u2208 [0, 1]: In that case, we must have k(1\u2212 \u01eb)\u2212 1\u03b7 \u2265 0, and the value of f at sc is (\n1 + \u03b7k(1 \u2212 \u01eb)\u2212 1\nk + 1\n)k (\n1\u2212 \u01eb\u2212 k(1\u2212 \u01eb)\u2212 1/\u03b7 k + 1\n)\n=\n(\n1 + \u03b7k(1 \u2212 \u01eb)\u2212 1\nk + 1\n)k (\n1\u2212 \u01eb+ 1\u03b7 k + 1\n)\n\u2264 (1 + \u03b7(1\u2212 \u01eb))k ( 1 + 1\u03b7 k + 1 )\n\u2264 2 (1 + \u03b7(1 \u2212 \u01eb)) k\n\u03b7(k + 1) .\nThe maximal value of f is either the value above, or the maximal value of f at the domain endpoints, which we already showed to be most 1. Overall, the maximal value f can attain is at most\nmax\n{\n1, 2 (1 + \u03b7(1\u2212 \u01eb))k\n\u03b7(k + 1)\n}\n\u2264 1 + 2 (1 + \u03b7(1\u2212 \u01eb)) k\n\u03b7(k + 1) .\nCombining the two cases, the result follows.\nUsing this lemma, we now prove that VT = w\u22a4T ((1 \u2212 \u01eb)I \u2212A)wT has a large negative expected value. To explain the intuition, note that if we could have used the exact A instead of the stochastic approximations A\u0303t in deriving wT , then we would have\nw \u22a4 T ((1 \u2212 \u01eb)I \u2212A)wT = w\u22a40 (I + \u03b7A)T ((1\u2212 \u01eb)I \u2212A)(I + \u03b7A)Tw0\n= d \u2211\nj=1\n(1 + \u03b7sj) 2T (1\u2212 \u01eb\u2212 sj)w20,j\n\u2264 1 p (1 + \u03b7s1)\n2T (1\u2212 \u01eb\u2212 s1) + d \u2211\nj=2\n(1 + \u03b7sj) 2T (1\u2212 \u01eb\u2212 sj)w20,j\n\u2264 1 p (1 + \u03b7s1) 2T (1\u2212 \u01eb\u2212 s1) +\n\n\nd \u2211\nj=2\nw20,j\n\n max s\u2208[0,1]\n(1 + \u03b7s)2T (1\u2212 \u01eb\u2212 s),\nwhich by the assumptions s1 = 1 and 1 = \u2016w0\u20162 = \u2211d j=1w 2 0,j is at most\n\u2212 \u01eb p (1 + \u03b7)2T + max s\u2208[0,1] (1 + \u03b7s)2T (1\u2212 \u01eb\u2212 s).\nApplying Lemma 2 and picking \u03b7, \u01eb appropriately, it can be shown that the above is at most \u2212\u2126 (\n\u01eb p (1 + \u03b7)\n2T )\n.\nUnfortunately, this calculation doesn\u2019t apply in practice, since we use the stochastic approximations A\u0303t instead of A. However, using more involved calculations, we prove in the lemma below that the expectation is still essentially the same, provided \u01eb, \u03b7 are chosen appropriately.\nLemma 3. If \u03b7 = 1b \u221a 1 pT \u2264 1 and \u01eb = c\nlog(T )b \u221a p\u221a\nT \u2264 1 for some sufficiently large constant c, then it holds\nthat E[VT ] \u2264 \u2212 (1 + \u03b7)2T \u01eb\n4p .\nProof. To simplify notation, define for all t = 1, . . . , T the matrices\nCt0 = I + \u03b7A , C t 1 = \u03b7(A\u0303t \u2212A).\nNote that Ct0 is deterministic whereas C t 1 is random and zero-mean. Moreover, \u2016Ct0\u2016 \u2264 1+\u03b7 and \u2016Ct1\u2016 \u2264 \u03b7b.\nBy definition of the algorithm, we have the following:\nVT = w \u22a4 T ((1 \u2212 \u01eb)I \u2212A)wT\n= w\u22a40\n(\nT \u220f\nt=1\n(\nI + \u03b7A\u0303t\n)\n) ((1\u2212 \u01eb)I \u2212A) ( 1 \u220f\nt=T\n(\nI + \u03b7A\u0303t\n)\n)\nw0\n= w\u22a40\n(\nT \u220f\nt=1\n(\nCt0 + C t 1\n)\n) ((1\u2212 \u01eb)I \u2212A) ( 1 \u220f\nt=T\n(\nCt0 + C t 1\n)\n)\nw0\n= \u2211\n(i1,...,iT )\u2208{0,1}T\n\u2211\n(j1,...,jT )\u2208{0,1}T w\n\u22a4 0\n(\nT \u220f\nt=1\nCtit\n) ((1 \u2212 \u01eb)I \u2212A) ( 1 \u220f\nt=T\nCtjt\n)\nw0.\nSince C11 , . . . , C T 1 are independent and zero-mean, the expectation of each summand in the expression above is non-zero only if it = jt for all t. Therefore,\nE\n[\nw \u22a4 T ((1 \u2212 \u01eb)I \u2212A)wT\n]\n= \u2211\n(i1,...,iT )\u2208{0,1}T E\n[\nw \u22a4 0\n(\nT \u220f\nt=1\nCtit\n) ((1\u2212 \u01eb)I \u2212A) ( 1 \u220f\nt=T\nCtit\n)\nw0\n]\n.\nWe now decompose this sum according to what is the largest value of t for which it = 1 (hence Ctit = C t 1). The intuition for this, as will be seen shortly, is that Lemma 2 allows us to attain tighter bounds on the summands when t is much smaller than T . Formally, we can rewrite the expression above as\nE\n[\nw0\n(\nT \u220f\nt=1\nCt0\n) ((1\u2212 \u01eb)I \u2212A) ( 1 \u220f\nt=T\nCt0\n)\nw0\n]\n+\nT\u22121 \u2211\nk=0\n\u2211\n(i1,...,ik)\u2208{0,1}k E\n[\nw0\n(\nk \u220f\nt=1\nCtit\n)\nCk+11\n(\nT \u220f\nt=k+2\nCt0\n) ((1 \u2212 \u01eb)I \u2212A) ( k+2 \u220f\nt=T\nCt0\n)\nCk+11\n(\n1 \u220f\nt=k\nCtit\n)\nw0\n]\n.\nSince Ct0 = I+\u03b7A is diagonal and the same for all t, and ((1\u2212\u01eb)I\u2212A) is diagonal as well, we can simplify the above to\nw0(C 1 0 ) 2T ((1 \u2212 \u01eb)I \u2212A)w0\n+\nT\u22121 \u2211\nk=0\n\u2211\n(i1,...,ik)\u2208{0,1}k E\n[\nw0\n(\nk \u220f\nt=1\nCtit\n)\nCk+11 (C 1 0 ) 2(T\u2212k\u22121)((1 \u2212 \u01eb)I \u2212A)Ck+11\n(\n1 \u220f\nt=k\nCtit\n)\nw0\n]\n.\nUsing the fact that the spectral norm is sub-multiplicative, and that for any symmetric matrix B, v\u22a4Bv \u2264 \u2016v2\u2016\u03bbmax(B), where \u03bbmax(B) denotes the largest eigenvalue of B, we can upper bound the above by\n\u2264 w0(C10 )2T ((1 \u2212 \u01eb)I \u2212A)w0\n+ T\u22121 \u2211\nk=0\n\u2211\n(i1,...,ik)\u2208{0,1}k E\n[ \u2016w0\u20162 ( k \u220f\nt=1\n\u2016Ctit\u20162 ) \u2016Ck+11 \u20162\u03bbmax ( (C10 ) 2(T\u2212k\u22121)((1 \u2212 \u01eb)I \u2212A) ) ] .\nSince \u2016w0\u2016 = 1, and \u2016Ct0\u2016 \u2264 (1 + \u03b7), \u2016Ct1\u2016 \u2264 \u03b7b, this is at most w0(C 1 0 ) 2T ((1\u2212 \u01eb)I \u2212A)w0\n+\nT\u22121 \u2211\nk=0\n\u2211\n(i1,...,ik)\u2208{0,1}k\n(\n(1 + \u03b7)2(k\u2212 \u2211k t=1 it)(\u03b7b)2 \u2211k t=1 it ) (\u03b7b)2\u03bbmax ( (C10 ) 2(T\u2212k\u22121)((1 \u2212 \u01eb)I \u2212A) )\n= w0(C 1 0 ) 2T ((1\u2212 \u01eb)I \u2212A)w0\n+\nT\u22121 \u2211\nk=0\n( (1 + \u03b7)2 + (\u03b7b)2 )k (\u03b7b)2\u03bbmax\n(\n(C10 ) 2(T\u2212k\u22121)((1\u2212 \u01eb)I \u2212A)\n)\n= w0(I + \u03b7A) 2T ((1\u2212 \u01eb)I \u2212A)w0\n+ (\u03b7b)2 T\u22121 \u2211\nk=0\n( (1 + \u03b7)2 + (\u03b7b)2 )k\n\u03bbmax\n( (I + \u03b7A)2(T\u2212k\u22121)((1\u2212 \u01eb)I \u2212A) )\n(3)\nRecalling that A = diag(s1, . . . , sd) with s1 = 1, that \u2016w0\u20162 = \u2211d j=1w 2 0,j = 1, and that w 2 0,1 \u2265 1p , the first term in Eq. (3) equals\nw0(I + \u03b7A) 2T ((1\u2212 \u01eb)I \u2212A)w0 =\nd \u2211\nj=1\n(1 + \u03b7sj) 2T (1\u2212 \u01eb\u2212 sj)w0,j\n= (1 + \u03b7)(\u2212\u01eb)w20,1 + d \u2211\nj=2\n(1 + \u03b7sj) 2T (1\u2212 \u01eb\u2212 sj)w20,j\n\u2264 \u2212(1 + \u03b7)2T \u01eb p + max s\u2208[0,1] (1 + \u03b7s)2T (1\u2212 \u01eb\u2212 s).\nApplying Lemma 2, and recalling that \u03b7 \u2264 1, we can upper bound the above by\n\u2212 (1 + \u03b7)2T \u01eb p + 1 + 2 (1 + \u03b7(1\u2212 \u01eb))2T \u03b7(2T + 1)\n= (1 + \u03b7)2T\n\n  \u2212 \u01eb p + (1 + \u03b7)\u22122T + 2\n(\n1+\u03b7(1\u2212\u01eb) 1+\u03b7\n)2T\n\u03b7(2T + 1)\n\n \n\u2264 (1 + \u03b7)2T (\n\u2212 \u01eb p + (1 + \u03b7)\u22122T +\n( 1\u2212 12\u03b7\u01eb ) )2T\n\u03b7T\n)\n. (4)\nAs to the second term in Eq. (3), again using the fact that A = diag(s1, . . . , sd), we can upper bound it by\n(\u03b7b)2 T\u22121 \u2211\nk=0\n( (1 + \u03b7)2 + (\u03b7b)2 )k\nmax s\u2208[0,1]\n(1 + \u03b7s)2(T\u2212k\u22121)(1\u2212 \u01eb\u2212 s).\nApplying Lemma 2, and recalling that \u03b7 \u2264 1, this is at most\n(\u03b7b)2 T\u22121 \u2211\nk=0\n( (1 + \u03b7)2 + (\u03b7b)2 )k\n(\n1 + 2 (1 + \u03b7(1 \u2212 \u01eb))2(T\u2212k\u22121)\n\u03b7(2(T \u2212 k)\u2212 1)\n)\n= (\u03b7b)2(1 + \u03b7)2T T\u22121 \u2211\nk=0\n(\n1 +\n(\n\u03b7b\n1 + \u03b7\n)2 )k\n\n  (1 + \u03b7)\u22122(T\u2212k) + 2\n(\n1+\u03b7(1\u2212\u01eb) 1+\u03b7\n)2(T\u2212k)\n\u03b7(2(T \u2212 k)\u2212 1)\n\n \n\u2264 (\u03b7b)2(1 + \u03b7)2T T\u22121 \u2211\nk=0\n( 1 + (\u03b7b)2 )k\n(\n(1 + \u03b7)\u22122(T\u2212k) + 2\n( 1\u2212 12\u03b7\u01eb )2(T\u2212k) \u03b7(2(T \u2212 k)\u2212 1) ) .\nUpper bounding ( 1 + (\u03b7b)2 )k by ( 1 + (\u03b7b)2 )T , and rewriting the sum in terms of k instead of T \u2212 k, we get\n(\u03b7b)2(1 + \u03b7)2T ( 1 + (\u03b7b)2 )T\nT \u2211\nk=1\n(\n(1 + \u03b7)\u22122k + 2\n( 1\u2212 12\u03b7\u01eb )2k\n\u03b7(2k \u2212 1)\n)\n.\nSince k \u2265 1, we have 12k\u22121 = 2k2k\u22121 12k \u2264 2 12k , so the above is at most\n(\u03b7b)2(1 + \u03b7)2T ( 1 + (\u03b7b)2 )T\nT \u2211\nk=1\n(\n(1 + \u03b7)\u22122k + 4\n\u03b7\n( 1\u2212 12\u03b7\u01eb )2k\n2k\n)\n\u2264 (\u03b7b)2(1 + \u03b7)2T ( 1 + (\u03b7b)2 )T\n( \u221e \u2211\nk=1\n(1 + \u03b7)\u22122k + 4\n\u03b7\n\u221e \u2211\nk=1\n( 1\u2212 12\u03b7\u01eb )k\nk\n)\n= (\u03b7b)2(1 + \u03b7)2T ( 1 + (\u03b7b)2 )T\n(\n1 (1 + \u03b7)2 \u2212 1 \u2212 4 \u03b7 log\n(\n1 2 \u03b7\u01eb\n))\n\u2264 (\u03b7b)2(1 + \u03b7)2T ( 1 + (\u03b7b)2 )T\n(\n1\n2\u03b7 +\n4 \u03b7 log\n(\n2\n\u03b7\u01eb\n))\n= \u03b7b2(1 + \u03b7)2T ( 1 + (\u03b7b)2 )T\n(\n1 2 + 4 log\n(\n2\n\u03b7\u01eb\n))\n.\nRecalling that this is an upper bound on the second term in Eq. (3), and combining with the upper bound in Eq. (4) on the first term, we get overall a bound of\n(1 + \u03b7)2T\n(\n\u2212 \u01eb p + (1 + \u03b7)\u22122T +\n( 1\u2212 12\u03b7\u01eb )2T\n\u03b7T + \u03b7b2\n( 1 + (\u03b7b)2 )T\n(\n1 2 + 4 log\n(\n2\n\u03b7\u01eb\n))\n)\n. (5)\nWe now argue that under suitable choices of \u03b7, \u01eb, the expression above is \u2212\u2126((1+ \u03b7)2T (\u01eb/p). For example, this is satisfied if \u03b7 = 1\nb \u221a pT\n, and we pick \u01eb = c log(T )b \u221a p\u221a\nT for some sufficiently large constant c. Under these\nchoices, the expression inside the main parentheses above becomes\n\u2212c log(T )b\u221a pT +\n(\n1 + 1\nb \u221a pT\n)\u22122T +b \u221a p\nT\n(\n1\u2212 c log(T ) 2T\n)2T\n+ b\u221a pT\n(\n1 + 1\npT\n)T (1\n2 + 4 log\n(\n2T\nc log(T )\n))\n.\nUsing the facts that (1\u2212 a/t)t \u2264 exp(\u2212a) for all positive t, a such that a/t < 1, and that c log(T )/2T < 1 by the assumption that \u01eb \u2264 1, the above is at most\n\u2212 c log(T )b\u221a pT + b\u221a pT\n( p exp(\u2212c log(T )) + exp(1/p) ( 1\n2 + 4 log\n(\n2T\nc log(T )\n)))\n+\n(\n1 + 1\nb \u221a pT\n)\u22122T\n= c log(T )b\u221a\npT\n(\n\u22121 + p c log(T )T c + exp(1/p) c log(T )\n(\n1 2 + 4 log\n(\n2T\nc log(T )\n)))\n+\n(\n1 + 1\nb \u221a pT\n)\u22122T .\nNote that p, b \u2265 1 by assumption, and that we can assume T \u2265 p (by the assumption that \u01eb \u2264 1). Therefore, picking c sufficiently large ensures that the above is at most\nc log(T )b\u221a\npT\n(\n\u22121 2\n)\n+\n(\n1 + 1\nb \u221a pT\n)\u22122T .\nThe second term is exponentially small in T , and in particular can be verified to be less than 14c log(T )b\u221a pT in the regime where \u01eb = c log(T )b \u221a p\u221a\nT is at most 1 (assuming c is large enough). Overall, we get a bound of\n\u2212c log(T )b\u221a pT \u00b7 14 = \u2212 \u01eb4p . Plugging this back into Eq. (5), the result follows.\nHaving proved an upper bound on E[VT ], we now turn to prove a high-probability lower bound on VT . The proof is based on relating VT to \u2016wT \u20162, and then performing a rather straightforward martingale analysis of log(\u2016wT \u20162).\nLemma 4. Suppose that A\u0303t is positive semidefinite for all t, and Pr(\u2016A\u0303t\u2016 \u2264 b) = 1. Then for any \u03b4 \u2208 (0, 1), we have with probability at least 1\u2212 \u03b4 that\nVT > \u2212 exp ( \u03b7b \u221a T log(1/\u03b4) + (b2 + 3)T\u03b72 ) (1 + \u03b7)2T \u01eb.\nProof. Since I \u2212A is a positive semidefinite matrix, we have\nVT = w \u22a4 T ((1 \u2212 \u01eb)I \u2212A)wT \u2265 \u2212\u01eb\u2016wT \u20162.\nThus, it is sufficient to prove that\n\u2016wT \u20162 < exp ( \u03b7b \u221a T log(1/\u03b4) + (b2 + 3)T\u03b72 ) (1 + \u03b7)2T . (6)\nThe proof goes through a martingale argument. We have\nlog(\u2016wT \u20162) = log ( T\u22121 \u220f\nt=0\n\u2016wt+1\u20162 \u2016wt\u20162\n)\n= T\u22121 \u2211\nt=0\nlog (\u2016wt+1\u20162 \u2016wt\u20162 )\n=\nT\u22121 \u2211\nt=0\nlog\n(\n\u2016(I + \u03b7A\u0303t)wt\u20162 \u2016wt\u20162\n)\n=\nT\u22121 \u2211\nt=0\nlog\n(\n1 +\n(\n\u2016(I + \u03b7A\u0303t)wt\u20162 \u2016wt\u20162 \u2212 1 )) .\nNote that since A\u0303t is positive semidefinite, we always have (1 + \u03b7b)\u2016wt\u20162 \u2265 \u2016(I + \u03b7A\u0303t)wt\u20162 \u2265 \u2016wt\u20162, and therefore each summand is of the form log(1+at) where at \u2208 [0, \u03b7b]. Using the identity log(1+a) \u2264 a for any non-negative a, we can upper bound the above by\nT\u22121 \u2211\nt=0\n(\n\u2016(I + \u03b7A\u0303t)wt\u20162 \u2016wt\u20162 \u2212 1 ) . (7)\nBased on the preceding discussion, this is a sum of random variables bounded in [0, \u03b7b], and the expectation of the t-th summand over A\u0303t, conditioned on A\u03031, . . . , A\u0303t\u22121, equals\nw \u22a4 t E\n[\n(I + \u03b7A\u0303t) \u22a4(I + \u03b7A\u0303t)\n]\nwt\n\u2016wt\u20162 \u2212 1\n= w\n\u22a4 t\n( (I + \u03b7A)2 + \u03b72 ( A\u0303\u22a4t A\u0303t \u2212A2 )) wt\n\u2016wt\u20162 \u2212 1\n\u2264 w \u22a4 t (I + \u03b7A) 2 wt\n\u2016wt\u20162 + \u03b72\nw \u22a4 t A\u0303 \u22a4 t A\u0303twt\n\u2016wt\u20162 \u2212 1\n\u2264 \u2016(I + \u03b7A)2\u2016+ \u03b72\u2016A\u0303\u22a4t A\u0303t\u2016 \u2212 1 \u2264 (1 + \u03b7)2 + \u03b72\u2016A\u0303t\u20162 \u2212 1 \u2264 2\u03b7 + (b2 + 1)\u03b72.\nUsing Azuma\u2019s inequality, it follows that with probability at least 1\u2212 \u03b4, Eq. (7) is at most\nT ( 2\u03b7 + (b2 + 1)\u03b72 ) + \u03b7b \u221a T log(1/\u03b4).\nCombining the observations above, and the fact that log(1+ z) \u2265 z\u2212 z2 for any z \u2265 0, we get that with probability at least 1\u2212 \u03b4,\nlog(\u2016wT \u20162) < 2T\u03b7 + (b2 + 1)T\u03b72 + \u03b7b \u221a T log(1/\u03b4)\n= \u03b7b \u221a T log(1/\u03b4) + (b2 + 3)T\u03b72 + 2T (\u03b7 \u2212 \u03b72) \u2264 \u03b7b \u221a T log(1/\u03b4) + (b2 + 3)T\u03b72 + 2T log(1 + \u03b7),\nand therefore \u2016wT \u20162 < exp ( \u03b7b \u221a T log(1/\u03b4) + (b2 + 3)T\u03b72 ) (1 + \u03b7)2T ,\nwhich establishes Eq. (6) and proves the lemma.\nWe now have most of the required components to prove Thm. 1. First, we showed in Lemma 3 that if\n\u03b7 = 1b\n\u221a\n1 pT , then\nE[VT ] \u2264 \u2212(1 + \u03b7)2T \u01eb\n4p . (8)\nfor \u01eb = O(b log(T ) \u221a p/T ). Using the same step size \u03b7, Lemma 4 implies that\nPr\n( VT \u2264 \u2212 exp ( \u221a log(1/\u03b4)\np +\n1 + 3/b2\np\n)\n(1 + \u03b7)2T \u01eb\n)\n\u2264 \u03b4,\nand since we assume b \u2265 1 (hence 1 + 3/b2 \u2264 4), this implies that\nPr\n(\n\u2212 VT exp(4/p)(1 + \u03b7)2T \u01eb\n\u2265 exp ( \u221a log(1/\u03b4)\np\n))\n\u2264 \u03b4. (9)\nNow, define the non-negative random variable\nRT = max\n{\n0,\u2212 VT exp(4/p)(1 + \u03b7)2T \u01eb\n}\n,\nand note that by its definition, E[RT ] \u2265 E [\n\u2212 VT exp(4/p)(1+\u03b7)2T \u01eb\n]\nand Pr\n( RT \u2265 exp ( \u221a log(1/\u03b4) p )) equals\nPr\n(\n\u2212 VT exp(4/p)(1+\u03b7)2T \u01eb\n\u2265 exp ( \u221a\nlog(1/\u03b4) p\n))\n. Using Eq. (8) and Eq. (9), this implies that\nE[RT ] \u2265 1\n4p exp(4/p) , Pr\n( RT \u2265 exp ( \u221a log(1/\u03b4)\np\n))\n\u2264 \u03b4.\nTo summarize the development so far, we defined a non-negative random variable RT , which is bounded with high probability, yet its expectation is at least \u2126(1/p). The following lemma shows that for a bounded non-negative random variable with \u201clarge\u201d expectation, the probability of it being on the same order as its expectation cannot be too small:\nLemma 5. Let X be a non-negative random variable such that for some \u03b1, \u03b2 \u2208 [0, 1], we have E[X] \u2265 \u03b1, and for any \u03b4 \u2208 (0, 1],\nPr ( X \u2265 exp ( \u03b2 \u221a log(1/\u03b4) )) \u2264 \u03b4.\nThen\nPr ( X > \u03b1\n2\n) \u2265 \u03b1\u2212 exp\n(\n\u2212 2 \u03b22\n)\n15 .\nBefore proving the lemma, let us show to use it to prove Thm. 1. Applying it on the random variable\nRT , which satisfies the lemma conditions with \u03b1 = 14p exp(4/p) , \u03b2 = \u221a 1 p , we have\n1\n15\n(\n1\n4p exp(4/p) \u2212 exp (\u22122p)\n) \u2264 Pr ( RT > 1\n8p exp(4/p)\n)\n= Pr\n(\nmax\n{\n0,\u2212 VT exp(4/p)(1 + \u03b7)2T \u01eb\n}\n> 1\n8p exp(4/p)\n)\n= Pr\n(\n\u2212 VT exp(4/p)(1 + \u03b7)2T \u01eb > 1 8p exp(4/p)\n)\n= Pr\n(\nVT \u2264 \u2212 (1 + \u03b7)2T \u01eb\n8p\n)\n\u2264 Pr (VT \u2264 0)\n1 15\n(\n1 4p exp(4/p) \u2212 exp (\u22122p)\n)\ncan be verified to be at least 1100p for any p \u2265 8, hence we obtained\nPr(VT \u2264 0) \u2265 1\n100p .\nAs discussed at the beginning of the proof, VT \u2264 0 implies that\nwT (I \u2212A)wT \u2016wT \u20162 \u2264 \u01eb,\nwhere \u01eb = c log(T )b \u221a p\u221a\nT is the value chosen in Lemma 3, and the theorem is established.\nAll that remains now is to prove Lemma 5. To explain the intuition, suppose that X in the lemma was actually at most 1 with probability 1, rather than just bounded with high probability. Then we would have\n\u03b1 \u2264 E[X] = Pr ( X \u2265 \u03b1 2 ) E [ X|X \u2265 \u03b1 2 ] + Pr ( X < \u03b1 2 ) E [ X|X \u2264 \u03b1 2 ]\n\u2264 Pr ( X \u2265 \u03b1 2 ) \u00b7 1 + Pr ( X < \u03b1 2 ) \u00b7 \u03b1 2 = Pr (\nX \u2265 \u03b1 2 ) + ( 1\u2212 Pr ( X \u2265 \u03b1 2 )) \u03b1 2 ,\nwhich implies that\n\u03b1 \u2264 ( 1\u2212 \u03b1 2 ) Pr ( X \u2265 \u03b1 2 ) + \u03b1 2 =\u21d2 Pr ( X \u2265 \u03b1 2 ) \u2265 \u03b1/2 1\u2212 \u03b1/2 \u2265 \u03b1 2 .\nTherefore, X is at least one-half its expectation lower bound (\u03b1) with probability at least \u03b1/2. The proof of Lemma 5, presented below, follows the same intuition, but uses a more delicate analysis since X is actually only upper bounded with high probability.\nProof of Lemma 5. Inverting the bound in the lemma, we have that for any z \u2208 [1,\u221e),\nPr(X \u2265 z) \u2264 exp(\u2212(log(z)/\u03b2)2).\nNow, let r2 > r1 > 0, be parameters to be chosen later. We have\nE[X] =\n\u222b \u221e\nz=0 Pr(X > z)dz =\n\u222b r1\nz=0 Pr(X > z)dz +\n\u222b r2\nz=r1\nPr(X > z)dz +\n\u222b \u221e\nz=r2\nPr(X > z)dz\n\u2264 r1 + (r2 \u2212 r1) Pr(X > r1) + \u222b \u221e\nz=r2\nexp(\u2212(log(z)/\u03b2)2)dz (10)\nPerforming the variable change y = (log(z)/\u03b2)2 (which implies z = exp(\u03b2 \u221a y) and dy = 2 \u221a y\nexp(\u03b2 \u221a y)dz), we\nget \u222b \u221e\nz=r2\nexp(\u2212(log(z)/\u03b2)2)dz = \u222b \u221e\ny= ( log(r2) \u03b2 )2\n1\n2 \u221a y exp(\u03b2\n\u221a y \u2212 y)dy\n\u2264 \u03b2 2 log(r2)\n\u222b \u221e\ny= (\nlog(r2) \u03b2\n)2 exp(\u03b2\n\u221a y \u2212 y)dy.\nSuppose that we choose r2 \u2265 exp(2\u03b22). Then log(r2)2\u03b2 \u2265 \u03b2, which implies that for any y in the integral above, 12 \u221a y \u2265 \u03b2, and therefore \u03b2\u221ay \u2212 y \u2264 12y \u2212 y = \u221212y. As a result, we can upper bound the above by\n\u03b2\n2 log(r2)\n\u222b \u221e\ny= ( log(r2) \u03b2\n)2 exp\n(\n\u22121 2 y\n)\ndy = \u03b2\nlog(r2) exp\n(\n\u2212 log 2(r2)\n2\u03b22\n)\n.\nPlugging this upper bound back into Eq. (10), extracting Pr(X > r1), and using the assumption E[X] \u2265 \u03b1, we get that\nPr(X > r1) \u2265 \u03b1\u2212 r1 \u2212 \u03b2log(r2) exp\n(\n\u2212 log 2(r2) 2\u03b22\n)\nr2 \u2212 r1 .\nChoosing r1 = \u03b1/2 and r2 = exp(2) (which ensures r2 \u2265 exp(2\u03b22) as assumed earlier, since \u03b2 \u2264 1), we get\nPr ( X > \u03b1\n2\n) \u2265 \u03b1\u2212 \u03b2 exp\n(\n\u2212 2 \u03b22\n)\n2 exp(2)\u2212 \u03b1 .\nSince \u03b2, \u03b1 \u2264 1, and 2 exp(2) < 15, this can be simplified to\nPr ( X > \u03b1\n2\n) \u2265 \u03b1\u2212 exp\n( \u2212 2\u03b22 )\n15 ."}, {"heading": "5.2 Proof of Lemma 1", "text": "Define \u2206 = \u2016A\u0303 \u2212 A\u2016. Also, let s1 \u2265 s2 \u2265 . . . \u2265 sd \u2265 0 be the d eigenvalues of A, with eigenvectors v1, . . . ,vd, where we assume that v = v1. Using the facts (x+ y)2 \u2264 2x2 + 2y2 and \u2016v1\u2016 = 1, we have\n1\n\u3008v1,w0\u30092 = \u2016A\u0303w\u20162 \u3008v1, A\u0303w\u30092 = \u2016Aw + (A\u0303\u2212A)w\u20162 (\n\u3008v1, Aw\u3009+ \u3008v1, (A\u0303\u2212A)w\u3009 )2\n\u2264 2\u2016Aw\u2016 2 + 2\u2016(A\u0303\u2212A)w\u20162 \u3008v1, Aw\u30092 + 2\u3008v1, Aw\u3009\u3008v1, (A\u0303\u2212A)w\u3009 \u2264 2\u2016Aw\u2016 2 + 2\u2016w\u20162\u22062 \u3008v1, Aw\u30092 \u2212 2|\u3008v1, Aw\u3009|\u2016w\u2016\u2206 ,\nwhere we implicitly assume that \u2206 is sufficiently small for the denominator to be positive (eventually, we will pick T0 large enough to ensure this).\nRecall that v1, . . . ,vd forms an orthonormal basis for Rd, so w = \u2211d i=1 vi\u3008vi,w\u3009. Therefore, we can write the above as\n2 (\n\u2211d i=1 sivi\u3008vi,w\u3009\n)2 + 2\u2016w\u20162\u22062\n(s1\u3008v1,w\u3009)2 \u2212 2|s1\u3008v1,w\u3009|\u2016w\u2016\u2206 =\n2 \u2211d i=1 s 2 i \u3008vi,w\u30092 + 2\u2016w\u20162\u22062\ns21\u3008v1,w\u30092 \u2212 2|s1\u3008v1,w\u3009|\u2016w\u2016\u2206\n\u2264 2 ( \u2211d i=1 s 2 i ) ( maxi\u3008vi,w\u30092 ) + 2\u2016w\u20162\u22062\ns21\u3008v1,w\u30092 \u2212 2|s1\u3008v1,w\u3009|\u2016w\u2016\u2206 .\nTo simplify notation, since w is drawn from a standard Gaussian distribution, which is rotationally invariant, we can assume without loss of generality that (v1, . . . ,vd) = (e1, . . . , ed), the standard basis, so the above reduces to\n2 (\n\u2211d i=1 s 2 i\n)\nmaxi w 2 i + 2\u2016w\u20162\u22062\ns21w 2 1 \u2212 2|s1w1|\u2016w\u2016\u2206\n.\nRecall that \u2206 = \u2016A\u0303 \u2212 A\u2016, where A\u0303 is the average of T0 independent random matrices with mean A, and spectral norm at most \u2016A\u2016b. Using a Hoeffding matrix bound (e.g. [27]), and the fact that \u2016A\u2016 = s1, it follows that with probability at least 1\u2212 \u03b4,\n\u2206 \u2264 \u2016A\u2016b \u221a 8 log(d/\u03b4)\nT0 = s1\n\u221a\n8b2 log(d/\u03b4)\nT0 .\nPlugging into the above, we get an upper bound of\n2 (\n\u2211d i=1 s 2 i\n)\nmaxi w 2 i + \u2016w\u20162s21 16b2 log(d/\u03b4) T0\ns21w 2 1 \u2212 2s21|w1|\u2016w\u2016\n\u221a\n8b2 log(d/\u03b4) T0\n,\nholding with probability at least 1 \u2212 \u03b4. Dividing both numerator and denominator by s21, and recalling that nA = \u2016A\u20162F \u2016A\u20162 = \u2211d i=1 s 2 i\ns21 , the above equals\n2nAmaxi w 2 i + \u2016w\u20162 16b2 log(d/\u03b4) T0\nw21 \u2212 2|w1|\u2016w\u2016 \u221a 8b2 log(d/\u03b4) T0\n= 2nAmaxiw\n2 i + \u2016w\u20162 16b2 log(d/\u03b4) T0\n|w1| ( |w1| \u2212 2\u2016w\u2016 \u221a\n8b2 log(d/\u03b4) T0\n) . (11)\nBased on standard Gaussian concentration arguments, it holds that\nPr\n(\nw21 \u2264 1\n8\n)\n\u2264 3 10 , Pr\n(\nmax i\nw2i \u2265 18 log(d) ) \u2264 1 d , Pr ( \u2016w\u2016 \u2265 \u221a 2d ) \u2264 exp ( \u2212d 8 ) .\n(see for instance the proof of Lemma 1 in [24], and Corollary 2.3 in [4]). Combining the above with a union bound, it holds that with probability at least 1\u2212 \u03b4 \u2212 310 \u2212 1d \u2212 exp(\u2212d/8), Eq. (11) is at most\n36 log(d)nA + 32db2 log(d/\u03b4)\nT0\n1 8\n(\n1 8 \u2212 2\n\u221a 2 \u221a\n8db2 log(d/\u03b4) T0\n) .\nRecalling that this is an upper bound on 1\u3008v1,w0\u30092 , picking \u03b4 = 1/d for simplicity, and slightly simplifying, we showed that with probability at least 710 \u2212 2d \u2212 exp(\u2212d/8),\n1\n\u3008v1,w0\u30092 \u2264\n36 log(d)nA + 64b2 log(d)\nT0\n1 8\n(\n1 8 \u2212 8\n\u221a 2 \u221a\ndb2 log(d) T0\n) .\nSince nA \u2265 1, then by picking T0 \u2265 cdb2 log(d) for a sufficiently large constant c, we get that 1\u3008v1,w0\u30092 \u2264 c\u2032 log(d)nA for a numerical constant c\u2032, as required."}, {"heading": "5.3 Proof of Thm. 2", "text": "The proof is very similar to that of Thm. 1, using some of the same lemmas, and other lemmas having slight differences to take advantage of the eigengap assumption. Below, we focus on the differences, referring to parts of the proof of Thm. 1 where necessary.\nFirst, as in the proof of Thm. 1, we assume that we work in a coordinate system where A is diagonal, A = diag(s1, . . . , sd), where s1 \u2265 s2 \u2265 . . . \u2265 sd \u2265 0, and s1 is the eigenvalue corresponding to v. By the eigengap assumption, we can assume that s2, . . . , sd are all at most 1 \u2212 \u03bb for some strictly positive \u03bb \u2208 (0, 1]. Under these assumptions, the theorem\u2019s conditions reduce to:\n\u2022 1 w20,1 \u2264 p, for some p \u2265 8\n\u2022 b \u2265 1 is an upper bound on \u2016A\u0303t\u2016, \u2016A\u0303t \u2212A\u2016,\nand as in the proof of Thm. 1, it is enough to lower bound Pr(VT \u2264 0) where\nVT = w \u22a4 T ((1\u2212 \u01eb)I \u2212A)wT .\nWe begin by a technical lemma, which bounds a certain quantity appearing later in the proofs:\nLemma 6. Under the conditions of Thm. 2,\nlog2(T )b2\n\u03bb2T \u2264 1 p \u2264 1.\nProof. By the assumption log 2(T )b2p \u03bbT \u2264\nlog(T )b \u221a p\u221a\nT , it follows that log(T )b \u03bb \u221a T \u2264 1\u221ap , and the result follows by squaring both sides.\nWe now continue by presenting the following variant of Lemma 3:\nLemma 7. Under the conditions of Thm. 2, if we pick \u03b7 = log(T )\u03bbT \u2264 1 and \u01eb = c log2(T )b2p\n\u03bbT for some sufficiently large numerical constant c, then\nE[VT ] \u2264 \u2212 (1 + \u03b7)2T \u01eb\n4p .\nProof. By the exact same proof as in Lemma 3 (up till Eq. (3)), we have\nE[VT ] = E[w \u22a4 T ((1\u2212 \u01eb)I \u2212A)wT ]\n\u2264 w0(I + \u03b7A)2T ((1\u2212 \u01eb)I \u2212A)w0\n+ (\u03b7b)2 T\u22121 \u2211\nk=0\n( (1 + \u03b7)2 + (\u03b7b)2 )k\n\u03bbmax\n( (I + \u03b7A)2(T\u2212k\u22121)((1\u2212 \u01eb)I \u2212A) )\n(12)\nRecalling that A = diag(s1, . . . , sd) with s1 = 1, that \u2016w0\u20162 = \u2211d j=1w 2 0,j = 1, and that w 2 0,1 \u2265 1p , the first\nterm in Eq. (3) equals\nw0(I + \u03b7A) 2T ((1 \u2212 \u01eb)I \u2212A)w0 =\nd \u2211\nj=1\n(1 + \u03b7sj) 2T (1\u2212 \u01eb\u2212 sj)w20,j\n= (1 + \u03b7)(\u2212\u01eb)w20,1 + d \u2211\nj=2\n(1 + \u03b7sj) 2T (1\u2212 \u01eb\u2212 sj)w20,j\n\u2264 \u2212(1 + \u03b7)2T \u01eb p + max s\u2208[0,1\u2212\u03bb] (1 + \u03b7s)2T (1\u2212 \u01eb\u2212 s) \u2264 \u2212(1 + \u03b7)2T \u01eb p + (1 + \u03b7(1 \u2212 \u03bb))2T \u2264 (1 + \u03b7)2T (\n\u2212 \u01eb p +\n(\n1\u2212 \u03b7\u03bb 1 + \u03b7\n)2T )\n\u2264 (1 + \u03b7)2T (\n\u2212 \u01eb p +\n(\n1\u2212 \u03b7\u03bb 2\n)2T )\n, (13)\nwhere we used the assumption that \u03b7 \u2264 1. As to the second term in Eq. (12), upper bounding it in exactly the same way as in the proof of Lemma 3 (without using the eigengap assumption), we get an upper bound of\n\u03b7b2(1 + \u03b7)2T ( 1 + (\u03b7b)2 )T\n(\n1 2 + 4 log\n(\n2\n\u03b7\u01eb\n))\n.\nCombining this with Eq. (13), and plugging back to Eq. (12), we get that\nE[VT ] \u2264 (1 + \u03b7)2T (\n\u2212 \u01eb p +\n(\n1\u2212 \u03b7\u03bb 2\n)2T\n+ \u03b7b2 ( 1 + (\u03b7b)2 )T\n(\n1 2 + 4 log\n(\n2\n\u03b7\u01eb\n))\n)\n. (14)\nPicking \u03b7 = log(T )\u03bbT , and \u01eb = c log2(T )b2p \u03bbT for some constant c \u2265 2, the above equals\n(1+\u03b7)2T\n(\n\u2212c log 2(T )b2\n\u03bbT +\n(\n1\u2212 log(T ) 2T\n)2T\n+ b2 log(T )\n\u03bbT\n(\n1 + b2 log2(T )\n\u03bb2T 2\n)T ( 1\n2 + 4 log\n(\n2\u03bb2T 2\nc log3(T )b2p\n))\n)\n.\nUsing the facts that (1 + a/t)t \u2264 exp(a) for all positive t, a, that c log3(T )b2p \u2265 2, and that \u03bb \u2264 1, the above is at most\n(1 + \u03b7)2T ( \u2212c log 2(T )b2\n\u03bbT +\n1 T +\nb2 log(T )\n\u03bbT exp\n(\nb2 log2(T )\n\u03bb2T\n)(\n1 2 + 4 log ( T 2 )\n))\n.\nBy Lemma 6, b 2 log2(T ) \u03bb2T \u2264 1, so the above is at most\n(1 + \u03b7)2T ( \u2212c log 2(T )b2\n\u03bbT +\n1 T +\nb2 log(T )\n\u03bbT exp(1)\n(\n1 2 + 8 log (T )\n))\n\u2264 (1 + \u03b7)2T b 2 log2(T )\n\u03bbT\n(\n\u2212c+ \u03bb b2 log2(T ) + exp(1)\n(\n1\n2 log(T ) + 8\n))\n.\nClearly, for large enough c, the expression in the main parenthesis above is at most \u2212c/4, so we get an upper bound of\n\u2212(1 + \u03b7)2T cb 2 log2(T ) 4\u03bbT = \u2212 (1 + \u03b7)2T \u01eb 4p ,\nfrom which the result follows.\nRather similar to the proof of Thm. 1, we now define the non-negative random variable\nRT = max\n{\n0,\u2212 VT exp((b2 + 3)T\u03b72)(1 + \u03b7)2T \u01eb\n}\n.\nBy Lemma 7,\nE[RT ] \u2265 E [ \u2212 VT exp((b2 + 3)T\u03b72)(1 + \u03b7)2T \u01eb ] \u2265 1 4p exp((b2 + 3)T\u03b72) ,\nand by Lemma 4,\nPr ( RT \u2265 exp ( \u03b7b \u221a T log(1/\u03b4) )) \u2264 \u03b4.\nTherefore, applying Lemma 5 on RT , with \u03b1 = 14p exp((b2+3)T\u03b72) (which is in [0, 1]) and with \u03b2 = \u03b7b \u221a T (which can be verified to be in [0, 1] by the fact that \u03b7 = log(T )\u03bbT and Lemma 6), we get that\nPr\n(\nRT > 1\n8p exp((b2 + 3)T\u03b72)\n)\n\u2265 1 15\n(\n1\n4p exp((b2 + 3)T\u03b72) \u2212 exp\n(\n\u2212 2 \u03b72b2T\n))\n. (15)\nBy definition of RT , the left hand side of this inequality is at most\n= Pr\n(\nmax\n{\n0,\u2212 VT exp((b2 + 3)T\u03b72)(1 + \u03b7)2T \u01eb\n}\n> 1\n8p exp((b2 + 3)T\u03b72)\n)\n= Pr\n(\n\u2212 VT exp((b2 + 3)T\u03b72)(1 + \u03b7)2T \u01eb > 1 8p exp((b2 + 3)T\u03b72)\n)\n= Pr\n(\nVT \u2264 \u2212 (1 + \u03b7)2T \u01eb\n8p\n)\n\u2264 Pr (VT \u2264 0) ,\nand the right hand side of Eq. (15) (by definition of \u03b7, the assumption b \u2265 1, and Lemma 6) equals\n1\n15\n\n\n1\n4p exp ( (b2+3) log2(T ) \u03bb2T\n) \u2212 exp ( \u2212 2\u03bb 2T\nb2 log2(T )\n)\n\n\n\u2265 1 15\n\n\n1\n4p exp ( 4b2 log2(T ) \u03bb2T\n) \u2212 1 exp ( 2 \u03bb 2T\nb2 log2(T )\n)\n\n\n\u2265 1 15\n\n\n1\n4p exp (\n4 p\n) \u2212 1 exp (2p))\n\n ,\nwhich can be verified to be at least 1100p for any p \u2265 8. Plugging these bounds back to Eq. (15), we obtained\nPr(VT \u2264 0) \u2265 1\n100p .\nBy definition of VT , VT \u2264 0 implies that\nwT (I \u2212A)wT \u2016wT \u20162 \u2264 \u01eb,\nwhere \u01eb = c log 2(T )b2p \u03bbT is the value chosen in Lemma 7, and the theorem is established."}, {"heading": "Acknowledgments", "text": "This research is supported in part by an FP7 Marie Curie CIG grant, the Intel ICRI-CI Institute, and Israel Science Foundation grant 425/13. We thank Ofer Zeitouni for several illuminating discussions."}], "references": [{"title": "Stochastic optimization for PCA and PLS", "author": ["R. Arora", "A. Cotter", "K. Livescu", "N. Srebro"], "venue": "2012 50th Annual Allerton Conference on Communication, Control, and Computing,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Stochastic optimization of PCA with capped MSG", "author": ["R. Arora", "A. Cotter", "N. Srebro"], "venue": "NIPS,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "The fast convergence of incremental PCA", "author": ["A. Balsubramani", "S. Dasgupta", "Y. Freund"], "venue": "NIPS,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Measure concentration lecture notes", "author": ["A. Barvinok"], "venue": "http://www.math.lsa.umich.edu/ \u0303barvinok/total7", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2005}, {"title": "The tradeoffs of large scale learning", "author": ["Olivier Bousquet", "L\u00e9on Bottou"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "Online principal components analysis", "author": ["C. Boutsidis", "D. Garber", "Z. Karnin", "E. Liberty"], "venue": "SODA,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Global convergence of stochastic gradient descent for some nonconvex matrix problems", "author": ["C. De Sa", "K. Olukotun", "C. R\u00e9"], "venue": "ICML,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Fast and simple pca via convex optimization", "author": ["D. Garber", "E. Hazan"], "venue": "arXiv preprint arXiv:1509.05647,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Online learning of eigenvectors", "author": ["D. Garber", "E. Hazan", "T. Ma"], "venue": "ICML,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "The noisy power method: A meta algorithm with applications", "author": ["M. Hardt", "E. Price"], "venue": "NIPS,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Analysis of a complex of statistical variables into principal components", "author": ["H. Hotelling"], "venue": "Journal of educational psychology, 24(6):417,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1933}, {"title": "Robust shift-and-invert preconditioning: Faster and more sample efficient algorithms for eigenvector computation", "author": ["C. Jin", "S. Kakade", "C. Musco", "P. Netrapalli", "A. Sidford"], "venue": "arXiv preprint arXiv:1510.08896,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Pca with gaussian perturbations", "author": ["W. Kot\u0142owski", "M. Warmuth"], "venue": "arXiv preprint arXiv:1506.04855,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Estimating the largest eigenvalue by the power and lanczos algorithms with a random start", "author": ["J. Kuczynski", "H. Wozniakowski"], "venue": "SIAM journal on matrix analysis and applications, 13(4):1094\u20131122,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1992}, {"title": "Memory limited, streaming PCA", "author": ["I. Mitliagkas", "C. Caramanis", "P. Jain"], "venue": "NIPS,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Stronger approximate singular value decomposition via the block lanczos and power methods", "author": ["C. Musco", "C. Musco"], "venue": "arXiv preprint arXiv:1504.05477,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Online pca with optimal regrets", "author": ["J. Nie", "W. Kot\u0142owski", "M. Warmuth"], "venue": "Algorithmic Learning Theory, pages 98\u2013112. Springer,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Simplified neuron model as a principal component analyzer", "author": ["E. Oja"], "venue": "Journal of mathematical biology, 15(3):267\u2013273,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1982}, {"title": "On stochastic approximation of the eigenvectors and eigenvalues of the expectation of a random matrix", "author": ["E. Oja", "J. Karhunen"], "venue": "Journal of mathematical analysis and applications, 106(1):69\u201384,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1985}, {"title": "Liii", "author": ["K. Pearson"], "venue": "on lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11):559\u2013572,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1901}, {"title": "Making gradient descent optimal for strongly convex stochastic optimization", "author": ["A. Rakhlin", "O. Shamir", "K. Sridharan"], "venue": "ICML,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2012}, {"title": "Understanding Machine Learning: From Theory to Algorithms", "author": ["S. Shalev-Shwartz", "S. Ben-David"], "venue": "Cambridge University Press,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Stochastic convex optimization", "author": ["S. Shalev-Shwartz", "O. Shamir", "N. Srebro", "K. Sridharan"], "venue": "COLT,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2009}, {"title": "Fast stochastic algorithms for svd and pca: Convergence properties and convexity", "author": ["O. Shamir"], "venue": "arXiv preprint arXiv:1507.08788,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "A stochastic PCA and SVD algorithm with an exponential convergence rate", "author": ["O. Shamir"], "venue": "ICML,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "Stochastic gradient descent for non-smooth optimization: Convergence results and optimal averaging schemes", "author": ["O. Shamir", "T. Zhang"], "venue": "ICML,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2013}, {"title": "User-friendly tail bounds for sums of random matrices", "author": ["J. Tropp"], "venue": "Foundations of Computational Mathematics, 12(4):389\u2013434,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2012}, {"title": "Online variance minimization", "author": ["M. Warmuth", "D. Kuzmin"], "venue": "Learning theory, pages 514\u2013528. Springer,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2006}, {"title": "Randomized online pca algorithms with regret bounds that are logarithmic in the dimension", "author": ["M. Warmuth", "D. Kuzmin"], "venue": "Journal of Machine Learning Research, 9(10):2287\u20132320,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 9, "context": "This also partially resolves an open problem posed in [10].", "startOffset": 54, "endOffset": 58}, {"referenceID": 19, "context": "1 Introduction Principal component analysis (PCA) [20, 11] is a fundamental tool in data analysis and visualization, designed to find the subspace of largest variance in a given dataset (a set of points in Euclidean space).", "startOffset": 50, "endOffset": 58}, {"referenceID": 10, "context": "1 Introduction Principal component analysis (PCA) [20, 11] is a fundamental tool in data analysis and visualization, designed to find the subspace of largest variance in a given dataset (a set of points in Euclidean space).", "startOffset": 50, "endOffset": 58}, {"referenceID": 13, "context": "Although this doesn\u2019t require computing and storing the matrix explicitly, it still requires multiple passes over the data, whose number may scale with eigengap parameters of the matrix or the target accuracy [14, 16].", "startOffset": 209, "endOffset": 217}, {"referenceID": 15, "context": "Although this doesn\u2019t require computing and storing the matrix explicitly, it still requires multiple passes over the data, whose number may scale with eigengap parameters of the matrix or the target accuracy [14, 16].", "startOffset": 209, "endOffset": 217}, {"referenceID": 24, "context": "Recently, new randomized algorithms for this problem were able to significantly reduce the required number of passes, while maintaining the ability to compute high-accuracy solutions [25, 24, 8, 12].", "startOffset": 183, "endOffset": 198}, {"referenceID": 23, "context": "Recently, new randomized algorithms for this problem were able to significantly reduce the required number of passes, while maintaining the ability to compute high-accuracy solutions [25, 24, 8, 12].", "startOffset": 183, "endOffset": 198}, {"referenceID": 7, "context": "Recently, new randomized algorithms for this problem were able to significantly reduce the required number of passes, while maintaining the ability to compute high-accuracy solutions [25, 24, 8, 12].", "startOffset": 183, "endOffset": 198}, {"referenceID": 11, "context": "Recently, new randomized algorithms for this problem were able to significantly reduce the required number of passes, while maintaining the ability to compute high-accuracy solutions [25, 24, 8, 12].", "startOffset": 183, "endOffset": 198}, {"referenceID": 17, "context": "In the context of PCA, this is also known as Oja\u2019s method [18, 19].", "startOffset": 58, "endOffset": 66}, {"referenceID": 18, "context": "In the context of PCA, this is also known as Oja\u2019s method [18, 19].", "startOffset": 58, "endOffset": 66}, {"referenceID": 4, "context": "In the world of convex stochastic optimization and learning, SGD has another remarkable property: Despite it being a simple, one-pass algorithm, it is essentially (worst-case) statistically optimal, attaining the same statistical estimation error rate as exact empirical risk minimization [5, 23, 22].", "startOffset": 289, "endOffset": 300}, {"referenceID": 22, "context": "In the world of convex stochastic optimization and learning, SGD has another remarkable property: Despite it being a simple, one-pass algorithm, it is essentially (worst-case) statistically optimal, attaining the same statistical estimation error rate as exact empirical risk minimization [5, 23, 22].", "startOffset": 289, "endOffset": 300}, {"referenceID": 21, "context": "In the world of convex stochastic optimization and learning, SGD has another remarkable property: Despite it being a simple, one-pass algorithm, it is essentially (worst-case) statistically optimal, attaining the same statistical estimation error rate as exact empirical risk minimization [5, 23, 22].", "startOffset": 289, "endOffset": 300}, {"referenceID": 0, "context": "The study of SGD (or variants thereof) for PCA has gained interest in recent years, with some notable examples including [1, 3, 2, 15, 10, 7, 12].", "startOffset": 121, "endOffset": 145}, {"referenceID": 2, "context": "The study of SGD (or variants thereof) for PCA has gained interest in recent years, with some notable examples including [1, 3, 2, 15, 10, 7, 12].", "startOffset": 121, "endOffset": 145}, {"referenceID": 1, "context": "The study of SGD (or variants thereof) for PCA has gained interest in recent years, with some notable examples including [1, 3, 2, 15, 10, 7, 12].", "startOffset": 121, "endOffset": 145}, {"referenceID": 14, "context": "The study of SGD (or variants thereof) for PCA has gained interest in recent years, with some notable examples including [1, 3, 2, 15, 10, 7, 12].", "startOffset": 121, "endOffset": 145}, {"referenceID": 9, "context": "The study of SGD (or variants thereof) for PCA has gained interest in recent years, with some notable examples including [1, 3, 2, 15, 10, 7, 12].", "startOffset": 121, "endOffset": 145}, {"referenceID": 6, "context": "The study of SGD (or variants thereof) for PCA has gained interest in recent years, with some notable examples including [1, 3, 2, 15, 10, 7, 12].", "startOffset": 121, "endOffset": 145}, {"referenceID": 11, "context": "The study of SGD (or variants thereof) for PCA has gained interest in recent years, with some notable examples including [1, 3, 2, 15, 10, 7, 12].", "startOffset": 121, "endOffset": 145}, {"referenceID": 6, "context": "For example, [7] require O(d/\u03bb2\u01eb) iterations to ensure with high probability that one of the iterates is \u01eb-optimal.", "startOffset": 13, "endOffset": 16}, {"referenceID": 11, "context": "[12] require O(1/\u03bb2 + 1/\u03bb\u01eb) iterations, provided we begin close enough to an optimal solution.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "Getting an eigengap-free analysis has also been posed as an open problem in [10].", "startOffset": 76, "endOffset": 80}, {"referenceID": 27, "context": "We note that while there are quite a few other single-pass, eigengap-free methods for this problem, such as [28, 29, 17, 6, 9, 13], their memory and runtime-per iteration requirements are much higher than SGD, often O(d2) or worse.", "startOffset": 108, "endOffset": 130}, {"referenceID": 28, "context": "We note that while there are quite a few other single-pass, eigengap-free methods for this problem, such as [28, 29, 17, 6, 9, 13], their memory and runtime-per iteration requirements are much higher than SGD, often O(d2) or worse.", "startOffset": 108, "endOffset": 130}, {"referenceID": 16, "context": "We note that while there are quite a few other single-pass, eigengap-free methods for this problem, such as [28, 29, 17, 6, 9, 13], their memory and runtime-per iteration requirements are much higher than SGD, often O(d2) or worse.", "startOffset": 108, "endOffset": 130}, {"referenceID": 5, "context": "We note that while there are quite a few other single-pass, eigengap-free methods for this problem, such as [28, 29, 17, 6, 9, 13], their memory and runtime-per iteration requirements are much higher than SGD, often O(d2) or worse.", "startOffset": 108, "endOffset": 130}, {"referenceID": 8, "context": "We note that while there are quite a few other single-pass, eigengap-free methods for this problem, such as [28, 29, 17, 6, 9, 13], their memory and runtime-per iteration requirements are much higher than SGD, often O(d2) or worse.", "startOffset": 108, "endOffset": 130}, {"referenceID": 12, "context": "We note that while there are quite a few other single-pass, eigengap-free methods for this problem, such as [28, 29, 17, 6, 9, 13], their memory and runtime-per iteration requirements are much higher than SGD, often O(d2) or worse.", "startOffset": 108, "endOffset": 130}, {"referenceID": 23, "context": "Recently, it was shown that a single exact power iteration can improve the starting point of stochastic methods for PCA [24].", "startOffset": 120, "endOffset": 124}, {"referenceID": 2, "context": "[3, 10, 7, 12]), an interesting difference is that the dependence on the eigengap \u03bb is only 1/\u03bb, as opposed to 1/\u03bb2 or worse.", "startOffset": 0, "endOffset": 14}, {"referenceID": 9, "context": "[3, 10, 7, 12]), an interesting difference is that the dependence on the eigengap \u03bb is only 1/\u03bb, as opposed to 1/\u03bb2 or worse.", "startOffset": 0, "endOffset": 14}, {"referenceID": 6, "context": "[3, 10, 7, 12]), an interesting difference is that the dependence on the eigengap \u03bb is only 1/\u03bb, as opposed to 1/\u03bb2 or worse.", "startOffset": 0, "endOffset": 14}, {"referenceID": 11, "context": "[3, 10, 7, 12]), an interesting difference is that the dependence on the eigengap \u03bb is only 1/\u03bb, as opposed to 1/\u03bb2 or worse.", "startOffset": 0, "endOffset": 14}, {"referenceID": 20, "context": "This has an interesting parallel in the analysis of SGD for \u03bb-strongly convex functions, where the suboptimality of wT decays as \u00d5(1/\u03bbT ), although E[\u2016wT \u2212 w\u2217\u20162] can only be bounded by O(1/\u03bb2T ) (compare for instance Lemma 1 in [21] and Theorem 1 in [26]).", "startOffset": 228, "endOffset": 232}, {"referenceID": 25, "context": "This has an interesting parallel in the analysis of SGD for \u03bb-strongly convex functions, where the suboptimality of wT decays as \u00d5(1/\u03bbT ), although E[\u2016wT \u2212 w\u2217\u20162] can only be bounded by O(1/\u03bb2T ) (compare for instance Lemma 1 in [21] and Theorem 1 in [26]).", "startOffset": 250, "endOffset": 254}, {"referenceID": 11, "context": "([12]) proposed another streaming algorithm which does have only 1/\u03bb dependence (at least for sufficiently large T ), and a high probability convergence rate which is even asymptotically optimal in some cases.", "startOffset": 1, "endOffset": 5}, {"referenceID": 11, "context": "Moreover, the algorithm in [12] is different and more complex, whereas our focus here is on the simple and practical SGD algorithm.", "startOffset": 27, "endOffset": 31}, {"referenceID": 0, "context": "For any \u01eb, \u03b7 \u2208 (0, 1), and integer k \u2265 0, max s\u2208[0,1] (1 + \u03b7s)(1\u2212 \u01eb\u2212 s) \u2264 1 + 2 + \u03b7(1 \u2212 \u01eb)) k \u03b7(k + 1) .", "startOffset": 48, "endOffset": 53}, {"referenceID": 0, "context": "Let sc = k(1\u2212\u01eb)\u22121/\u03b7 k+1 denote this critical point, and consider two cases: \u2022 sc / \u2208 [0, 1]: In that case, f has no critical points in the domain, hence is maximized at one of the domain endpoints, with a value of at most max{f(0), f(1)} = max{1\u2212 \u01eb,\u2212\u01eb(1 + \u03b7)} \u2264 1.", "startOffset": 85, "endOffset": 91}, {"referenceID": 0, "context": "\u2022 sc \u2208 [0, 1]: In that case, we must have k(1\u2212 \u01eb)\u2212 1 \u03b7 \u2265 0, and the value of f at sc is", "startOffset": 7, "endOffset": 13}, {"referenceID": 0, "context": "\uf8f8 max s\u2208[0,1] (1 + \u03b7s) (1\u2212 \u01eb\u2212 s), which by the assumptions s1 = 1 and 1 = \u2016w0\u2016 = \u2211d j=1w 2 0,j is at most \u2212 \u01eb p (1 + \u03b7) + max s\u2208[0,1] (1 + \u03b7s) (1\u2212 \u01eb\u2212 s).", "startOffset": 8, "endOffset": 13}, {"referenceID": 0, "context": "\uf8f8 max s\u2208[0,1] (1 + \u03b7s) (1\u2212 \u01eb\u2212 s), which by the assumptions s1 = 1 and 1 = \u2016w0\u2016 = \u2211d j=1w 2 0,j is at most \u2212 \u01eb p (1 + \u03b7) + max s\u2208[0,1] (1 + \u03b7s) (1\u2212 \u01eb\u2212 s).", "startOffset": 128, "endOffset": 133}, {"referenceID": 0, "context": "j=2 (1 + \u03b7sj) 2T (1\u2212 \u01eb\u2212 sj)w 0,j \u2264 \u2212(1 + \u03b7) \u01eb p + max s\u2208[0,1] (1 + \u03b7s) (1\u2212 \u01eb\u2212 s).", "startOffset": 56, "endOffset": 61}, {"referenceID": 0, "context": "k=0 ( (1 + \u03b7) + (\u03b7b) k max s\u2208[0,1] (1 + \u03b7s)2(T\u2212k\u22121)(1\u2212 \u01eb\u2212 s).", "startOffset": 29, "endOffset": 34}, {"referenceID": 0, "context": "Let X be a non-negative random variable such that for some \u03b1, \u03b2 \u2208 [0, 1], we have E[X] \u2265 \u03b1, and for any \u03b4 \u2208 (0, 1], Pr (", "startOffset": 66, "endOffset": 72}, {"referenceID": 26, "context": "[27]), and the fact that \u2016A\u2016 = s1, it follows that with probability at least 1\u2212 \u03b4, \u2206 \u2264 \u2016A\u2016b \u221a", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "(see for instance the proof of Lemma 1 in [24], and Corollary 2.", "startOffset": 42, "endOffset": 46}, {"referenceID": 3, "context": "3 in [4]).", "startOffset": 5, "endOffset": 8}, {"referenceID": 0, "context": "Therefore, applying Lemma 5 on RT , with \u03b1 = 1 4p exp((b2+3)T\u03b72) (which is in [0, 1]) and with \u03b2 = \u03b7b \u221a T (which can be verified to be in [0, 1] by the fact that \u03b7 = log(T ) \u03bbT and Lemma 6), we get that Pr (", "startOffset": 78, "endOffset": 84}, {"referenceID": 0, "context": "Therefore, applying Lemma 5 on RT , with \u03b1 = 1 4p exp((b2+3)T\u03b72) (which is in [0, 1]) and with \u03b2 = \u03b7b \u221a T (which can be verified to be in [0, 1] by the fact that \u03b7 = log(T ) \u03bbT and Lemma 6), we get that Pr (", "startOffset": 138, "endOffset": 144}], "year": 2016, "abstractText": "We consider the problem of principal component analysis (PCA) in a streaming stochastic setting, where our goal is to find a direction of approximate maximal variance, based on a stream of i.i.d. data points in R. A simple and computationally cheap algorithm for this is stochastic gradient descent (SGD), which incrementally updates its estimate based on each new data point. However, due to the non-convex nature of the problem, analyzing its performance has been a challenge. In particular, existing guarantees rely on a non-trivial eigengap assumption on the covariance matrix, which is intuitively unnecessary. In this paper, we provide (to the best of our knowledge) the first eigengap-free convergence guarantees for SGD in the context of PCA. This also partially resolves an open problem posed in [10]. Moreover, under an eigengap assumption, we show that the same techniques lead to new SGD convergence guarantees with better dependence on the eigengap.", "creator": "LaTeX with hyperref package"}}}