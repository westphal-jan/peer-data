{"id": "1509.09093", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Sep-2015", "title": "A Sentence Meaning Based Alignment Method for Parallel Text Corpora Preparation", "abstract": "Text approaches considered crucial. through objective example Machine Translation (MT) enabled, some NLP basic and likely as text processing tasks temporary bilingual data. This specialists proposes followed language union judgment concurrent steps based taken Polish (however position - critical language) then English clinical. This axis means immediately product held the TED Talks upr, but use could from for otherwise text domain or language pair. The term yet scraps various heuristics for prison genuine. Some result meant costs synonyms made algorithms text structure organizational example a another of direct content. Minimization mainly product damage was opportunity. The method exception compares well their pleading carriageway 32-bit. Also an sustaining today MT system point with written processed each portrayed specialized is shown.", "histories": [["v1", "Wed, 30 Sep 2015 09:29:51 GMT  (302kb)", "http://arxiv.org/abs/1509.09093v1", "corpora filtration, text alignement, corpora improvement. arXiv admin note: text overlap witharXiv:1509.08881"]], "COMMENTS": "corpora filtration, text alignement, corpora improvement. arXiv admin note: text overlap witharXiv:1509.08881", "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["krzysztof wo{\\l}k", "krzysztof marasek"], "accepted": false, "id": "1509.09093"}, "pdf": {"name": "1509.09093.pdf", "metadata": {"source": "CRF", "title": "A Sentence Meaning Based Alignment Method for Parallel Text Corpora Preparation", "authors": ["Krzysztof Wo\u0142k", "Krzysztof Marasek"], "emails": ["kwolk@pjwstk.edu.pl"], "sections": [{"heading": "1 Introduction", "text": "Before a parallel corpus can be used for any processing, the sentences must be aligned. Sentences in the raw corpus are mostly misaligned, with translation lines whose placement does not correspond to the text lines in the source language. Moreover, some sentences may have no corresponding translation in the corpus at all. The corpus might also contain poor or indirect translations, making alignment difficult. Thus, alignment is crucial to many systems accuracy [1]. Sentence alignment must also be computationally feasible in order to be of practical use in various applications [2]. As a result, sentence alignment poses a significant challenge.\nThe Polish language is a particular challenge to such tools. It is a very complicated West-Slavic language with complex elements and grammatical rules. In addition, the Polish language has a large vocabulary due to many endings and prefixes changed by word declension. These characteristics have a significant effect on the requirements for the data and the data structure.\nIn addition, English is a position-sensitive language. The syntactic order (the order of words in a sentence) plays a very significant role, and the language has very limited inflection of words (e.g., due to the lack of declension endings). The word position in an English sentence is often the only indicator of the meaning. The sentence order follows the Subject-Verb-Object (SVO) schema, with the subject phrase preceding the predicate.\nOn the other hand, no specific word order is imposed in Polish, and the word order has little effect on the meaning of a sentence. The same thought can be expressed in several ways. For example, the sentence \u201cI bought myself a new car.\u201d can be written in Polish as one of the following: \u201cKupi\u0142em sobie nowy samoch\u00f3d\u201d;\u201d Nowy samoch\u00f3d sobie kupi\u0142em.\u201d; \u201dSobie kupi\u0142em nowy samoch\u00f3d.\u201d; \u201dSamoch\u00f3d nowy sobie kupi\u0142em.\u201d. It must be noted that such differences exist in many language pairs and need somehow to be dealt with, what is done in this research.\nThis paper proposes a language independent sentence alignment method that has been applied to Polish-English parallel corpora. First, the method is described. Next, an alignment metric is discussed. A quality comparison of this method to other alignment methods is then made using data from experiments. Lastly, conclusions are drawn.\nThe dataset used for this research was the Translanguage English Database (TED) [12], provided by Fondazione Bruno Kessler (FBK) [17]. Vocabulary sizes of the English and Polish texts in TED are disproportionate. There are 41,684 unique English words and 88,158 unique Polish words. This also presents a challenge for SMT systems."}, {"heading": "2 Literature Overview", "text": "Early attempts at automatically aligning sentences for parallel corpora were based on sentence lengths, together with vocabulary alignment [19]. Brown\u2019s method [20] was based on measuring sentence length by the number of words. Gale and Church [21] measured the number of characters in sentences. Other researchers continued exploring various methods of combining sentence length statistics with alignment of vocabularies [22, 23].\nSeveral text aligners implementing these methods are currently available, including Bleualign, which is an open source project developed by the University of Zurich. In addition to parallel texts, Bleualign requires a translation of one of the texts. It uses the length-based Bilingual Evaluation Understudy (BLEU) similarity metric to align the texts [11].\nThe Hunalign tool is another open source tool, developed by the Media Research Center. Based on Gale and Church\u2019s method, it uses sentence lengths and, optionally, a dictionary to align texts in two languages strictly on a sentence level. It does not address sentence-ordering issues [10].\nABBYY Aligner is a commercial product developed by the ABBYY Group. This product reportedly uses proprietary word databases to align text portions of sentences based on their meaning. [8]\nUnitex Aligner [9] is an open source project primarily developed by the University of Paris-Est Marne-la-Vall\u00e9e (France). It uses the XAlign tool [18], which uses character lengths at the paragraph and sentence level for text alignment [24]."}, {"heading": "3 Proposed Sentence Aligner", "text": "A sentence aligner was designed to find an English translation of each Polish line in a corpus and place it in the correct place in the English file. This aligner was implemented as a Python script. We assume that each line in a text file represents one full sentence.\nOur first concept is to use the Google Translator Application Programming Interface (API) for lines for which an English translation does not exist and also for comparison between the original and translated texts. The second concept is based on web crawling, using Google Translator, Bing Translator, and Babylon translator. These can work in a parallel manner to improve performance. In addition, each translator can work in many instances. Our approach can also accommodate a userprovided translation file in lieu of crowd sourcing.\nOur strategy is to find a correct translation of each Polish line aided by Google Translator or another translation engine. We translate all lines of the Polish file (src.pl) with Google Translator and put each line translation in an intermediate English translation file (src.trans). This intermediate translation helps us find the correct line in the English translation file (src.en) and put it in the correct position.\nIn reality, the actual solution is more complex. Suppose that we choose one of the English data lines as the most similar line to the specific translated line and that its similarity rate is high enough to be accepted as the translation. This line can be more similar to the next line of src.trans, so that the similarity rate of this selected line and the next line of src.trans is higher. For example, consider the sentences and their similarity rating in Table 1.\nIn this situation, we should select \u201cI do not go to school every day.\u201d from src.en instead of \u201cI don't go to school every day\u201d from src.trans, and not \u201cI go to school every day.\u201d. So, we should consider the similarity of a selected line with the next lines of src.trans to make the best possible selection in the alignment process.\nThere are additional complexities that must be addressed. Comparing the src.trans lines with the src.en lines is not easy, and it becomes harder when we want to use the similarity rate to choose the correct, real-world translation.\nThere are many strategies to compare two sentences. We can split each sentence into its words and find the number of words in both sentences. However, this approach has some problems. For example, let us compare \u201cIt is origami.\u201d to these sentences: \u201cThe common theme what makes it origami is folding is how we create the form.\u201d; \u201cThis is origami.\u201d\nWith this strategy, the first sentence is more similar because it contains all 3 words. However, it is clear that the second sentence is the correct choice. We can solve this problem by dividing the number of words in both sentences by the number of total words in the sentences. However, counting stop words in the intersection of sentences sometimes causes incorrect results. So, we remove these words before comparing two sentences.\nAnother problem is that sometimes we find stemmed words in sentences, for example \u201cboy\u201d and \u201cboys.\u201d Despite the fact that these two words should be counted as similarity of two sentences, with this strategy, these words are not counted.\nThe next comparison problem is the word order in sentences. In Python there are other ways for comparing strings that are better than counting intersection lengths. The Python \u201cdifflib\u201d library for string comparison contains a function that first finds matching blocks of two strings. For example, we can use difflib to find matching blocks in the strings \"abxcd\" and \"abcd\".\nDifflib\u2019s \u201cratio\u201d function divides the length of matching blocks by the length of two strings, and returns a measure of the sequences\u2019 similarity as a float value in the range [0, 1]. This measure is 2.0*M / T, where T is the total number of elements in both sequences, and M is the number of matches. Note that this measure is 1.0 if the sequences are identical, and 0.0 if they have nothing in common. Using this function to compare strings instead of counting similar words helps us to solve the problem of the similarity of \u201cboy\u201d and \u201cboys\u201d. It also solves the problem of considering the position of words in sentences.\nAnother problem in comparing lines is synonyms. For example, in these sentences: \u201cI will call you tomorrow.\u201d; \u201cI would call you tomorrow.\u201d\nIf we want to know if these sentences are the same, we should know that \u201cwill\u201d and \u201cwould\u201d can be used interchangeably.\nWe used the NLTK Python module and WordNet\u00ae to find synonyms for each word and to use these synonyms in comparing sentences. Using synonyms of each word, we created multiple sentences from each original sentence.\nFor example, suppose that the word \u201cgame\u201d has the synonyms: \u201cplay\u201d, \u201csport\u201d, \u201cfun\u201d, \u201cgaming\u201d, \u201caction\u201d, and \u201cskittle\u201d. If we use, for example, the sentence \u201cI do not like game.\u201d, we create the following sentences: \u201cI do not like play.\u201d; \u201cI do not like sport.\u201d; \u201cI do not like fun.\u201d; \u201cI do not like gaming.\u201d; \u201cI do not like action.\u201d; \u201cI do not like skittle.\u201d. We must do the same every word in a sencence.\nNext, we try to find the best score by comparing all these sentences instead of just comparing the main sentence. One issue is that this type of comparison takes too much time, because we need to do many comparisons for each selection.\nDifflib has other functions (in SequenceMatcher and Diff class) to compare strings that are faster than described solution, but their accuracy is worse. To overcome all\nthese problems and obtain the best results, we consider two criteria: the speed of the comparison function and the comparison acceptance rate.\nTo obtain the best results, our script provides users with the ability to have multiple functions with multiple acceptance rates. Fast functions with lower quality results are tested first. If they can find results with a very high acceptance rate, we accept their selection. If the acceptance rate is not sufficient, we can use slower but higher accuracy functions. The user can configure these rates manually and test the resulting quality to get the best results. All are well described in documentation [25].\nBecause we used the Google Translator API and comparison functions that are not specific to any language, the program should be able to align similarly structured languages that are supported by Google Translator with English. Alignment between a language pair not included in Google Translator or WordNet would require use of a different lexical library for synonyms or not using some comparison functions.\nInformation about each data domain would require adapting parameters in order to provide the best alignment. In general, texts is associated with a domain, i.e. a particular subject area and mode of writing, e.g., a political science essay [13]. As discussed in [14], texts from different domains are likely to use words with different meanings. If a domain is ignored, this can lead to translations that are misleading [26].\nThe proposed method automatically creates text corpora. Some other aligners work in only a semi-automatic or fully manual manner. If they are unable to align or there is no translation, they leave an empty line. Clearly, this result in problems and some information are lost in process, which does not occur in our solution."}, {"heading": "4 Sentence Alignment Metric", "text": "We developed a special metric to evaluate aligner quality and tuned its parameters during this research. Special metric was needed to evaluate sentences properly aligned but built from synonyms or with different phrase order. For an aligned sentence, we give 1 point. For a misaligned sentence, we give a -0.2 points penalty. For web service translations, we give 0.4 points. For translations due to disproportion between input files, we give 1 point (when one of two files included more sentences). The score is normalized to fit between 1 and 100. A higher value is better. A floor function can be used to round the score to an integer value. Point weights were determined by empirical research and can be easily adjusted if needed. The score S is defined as:\n(1)\nwhere A is the number of aligned sentences, M is the number of misaligned sentences, T is the number of translated sentences, D is the number of lines not found in both language files (one file can contain some sentences that do not exist in the other one), and L is the total number of output lines.\nSome additional scoring algorithms were also implemented. These are more suited for comparing language translation quality. We added the BLEU and native\nS = floor(20(5A\u2212M + 2T + 5|D| L )\nimplementations of Translation Edit Rate (TER) and Character Edit Rate (CER) by using pycdec and the Rank-based Intuitive Bilingual Evaluation Measure (RIBES). BLEU and TER are well-described in the literature [4-5]. RIBES is an automatic evaluation metric for machine translation, developed in NTT Communication Science Labs [6].\nThe pycdec module is a Python interface to the cdec decoding and alignment algorithms [15, 16]. The BLEU metric compares phrases from a source text with reference translations of the text, using weighted averages of the resulting matches. It has been shown that BLEU performs well in comparison to reference human translations. BLEU is defined in [3] in terms of the n-gram precision (using n-grams up to length N) \ud835\udc5d! and weights \ud835\udc64! (positive only) whose sum is one:\n\u2211 =\n= N\nn nnB pwPBLEU 0 )logexp( (2)\nHere, \ud835\udc43! is the brevity penalty, which is given by [3] as:\nPB = { 1,c > r\ne (1\u2212r c ) ,c \u2264 r\n(3)\nIn the equation above, c is the candidate phrase translation length, and r is the length of the reference translation phrase, e is Euler\u2019s constant. [3]. The TER metric is intended to capture the quality of essential meaning and fluency of SMT system translations. It measures human translator edits required for a machine translation to match a reference translation. TER accounts for word substitutions, word insertions and deletions, and phrase and word order modifications [5].\nWe use these algorithms to generate likelihood scores for two sentences, to choose the best one in the alignment process. For this purpose, we used cdec and pycdec. cdec is a decoder, aligner, and learning framework for statistical machine translation and similar structured prediction models. It provides translation and alignment modeling based on finite-state transducers and synchronous context-free grammars, as well as implementations of several parameter-learning algorithms [15, 16].\npycdec is a Python module for the cdec decoder. It enables Python coders to use cdec\u2019s fast C++ implementation of core finite-state and context-free inference algorithms for decoding and alignment. The high-level interface allows developers to build integrated MT applications that take advantage of the rich Python ecosystem without sacrificing computational performance. The modular architecture of pycdec separates search space construction, rescoring, and inference.\ncdec includes implementations of the basic evaluation metrics (BLEU, TER and CER), exposed in Python via the cdec.score module. For a given (reference, hypothesis) pair, sufficient statistics vectors (SufficientStats) can be computed. These vectors are then summed for all sentences in the corpus, and the final result is converted into a real-valued score.\nBefore aligning a big data file, it is important to determine the proper comparators and acceptance rates for each one. Files of 1000 \u2013 10,000 lines result in the best performance. We recommend first evaluating each comparison method separately, and then combining the best ones in a specific scenario. For this purpose, we recommend using the binary search method in order to determine the best threshold factor value."}, {"heading": "5 Comparison Experiments", "text": "Experiments were performed to compare the performance of the proposed method with several other sentence alignment implementations on the data found in [7], using the metric defined earlier. The Polish data in the Translanguage English Database (TED) lectures (approximately 15 MB) includes over 2 million words that are not tokenized.\nThe additional aligners, all created to develop parallel corpora, used in this experiment were: Bleualign, hunalign, ABBYY Aligner, Wordfast Aligner, and Unitex Aligner. The performance of the aligners was scored using the sentence alignment metric described in Section 3. Table 2 provides the results.\nClearly, the first three aligners scored well. The proposed method is fully automatic. It is important to note that Bleualign does not translate text and requires that it be done manually.\nAs discussed earlier, it is important not to lose lines of text in the alignment process. Table 3 shows the total lines resulting from the application of each alignment method.\nAll the aligners compared, other than the proposed method, lose lines of text as compared to a reference human translation. The proposed method lost no lines.\nIn purpose of showing the output quality with an independent metric we decided to compare results with BLEU, NIST, METEOR and TER (the lower the better), in a comparison with human B1aligned texts. Those results are presented in Table 4."}, {"heading": "6 Conclusions", "text": "In general, sentence alignment algorithms are very important for creating of parallel text corpora. Most aligners are not fully automatic, but the one proposed here is, which gives it a distinct advantage. It also allows creating a corpus when sentences exist just in a single language. The proposed approach is also language independent for ones with similar structure to PL or EN.\nThe results show that the proposed method performed very well in terms of the metric. It also lost no lines of text, unlike the other aligners. This is critical to the end goal of obtaining a translated text. Our alignment method also proved to provide better score when comparing with typical machine translation metrics, and would most likely improve MT systems output quality."}, {"heading": "6 Acknowledgements", "text": "This work is supported by the European Community from the European Social Fund within the Interkadra project UDA-POKL-04.01.01-00-014/10-00 and Eu-Bridge 7th FR EU project (grant agreement n\u00b0287658)."}, {"heading": "25. http://korpusy.s16874487.onlinehome-server.info/", "text": "26. Thorleuchter, D. and Van den Poel, D. \u201cWeb Mining based Extraction of Problem Solution\nIdeas\u201d, Expert Systems with Applications, 40(10), p. 3961-3969, 2013."}], "references": [{"title": "Segmentation and alignment of parallel text for statistical machine translation", "author": ["Y. Deng", "S. Kumar", "W. Byrne"], "venue": "Natural Language Engineering,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "Improved Unsupervised Sentence Alignment for Symmetrical and Asymmetrical Parallel Corpora", "author": ["F. Braune", "A. Fraser"], "venue": "Coling 2010: Poster Volume,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "BLEU: a Method for Automatic Evaluation of Machine Translation", "author": ["K. Papineni", "S. Rouskos", "T. Ward", "W.J. Zhu"], "venue": "Proc. of 40 Annual Meeting of the Assoc. for Computational Linguistics,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2002}, {"title": "A Study of Translation Edit Rate with Targeted Human Annotation", "author": ["M. Snover", "B. Dorr", "R. Schwartz", "L. Micciulla", "J. Makhoul"], "venue": "Proc. of 7 Conference of the Assoc. for Machine Translation in the Americas,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2006}, {"title": "Binary codes with correction for deletions and insertions of the symbol 1", "author": ["V.I. Levenshtein"], "venue": "Problemy Peredachi Informacii,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1965}, {"title": "TED Polish-to-English translation system for the IWSLT 2012", "author": ["K. Marasek"], "venue": "Proc. of International Workshop on Spoken Language Translation (IWSLT)", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2010}, {"title": "Statistical Machine Translation Between New Language Pairs Using Multiple Intermediaries (Doctoral dissertation, Thesis)", "author": ["A. Schmidt"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2007}, {"title": "Machine translation evaluate versus quality estimation", "author": ["L. Specia", "D. Raj", "M. Turchi"], "venue": "Machine Translation,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "pycdec: A Python Interface to cdec", "author": ["V. Chahuneau", "N.A. Smith", "C. Dyer"], "venue": "The Prague Bulletin of Mathematical Linguistics, No", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "cdec: A decoder, alignment, and learning framework for finite-state and context-free translation models", "author": ["Dyer", "C. et al"], "venue": "Proc. of ACL 2010 System Demonstrations (pp. 7-12)", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "Wit3: Web inventory of transcribed and translated talks", "author": ["M. Cettolo", "C. Girardi", "M. Federico"], "venue": "Proc. of 16th Conference of the European Association for Machine Translation (EAMT),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "UNITEX, a Corpus Processing System with Multi-Lingual Linguistic Resources", "author": ["S. Paumier", "T. Nakamura", "S. Voyatzi"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "A survey on parallel corpora alignment", "author": ["A. Santos"], "venue": "MI-STAR", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "Aligning sentences in parallel corpora", "author": ["P.F. Brown", "J.C. Lai", "R.L. Mercer"], "venue": "Proc. of 29th Annual Meeting of the ACL,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1991}, {"title": "Identifying word correspondences in parallel texts", "author": ["W.A. Gale", "K.W. Church"], "venue": "Proc. of DARPA Workshop on Speech and Natual Language,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1991}, {"title": "Parallel corpora for medium density languages", "author": ["D Varga"], "venue": "Proc. of the RANLP", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2005}, {"title": "Improved unsupervised sentence alignment for symmetrical and asymmetrical parallel corpora", "author": ["F. Braune", "A. Fraser"], "venue": "Proc. of 23rd COLING International Conference,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2010}, {"title": "The lingua parallel concordancing project: Managing multilingual texts for educational purpose", "author": ["P. Bonhomme", "L. Romary"], "venue": "Proc. of Quinzie\u0300mes Journe\u0301es Internationales IA 95,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1995}, {"title": "Web Mining based Extraction of Problem Solution Ideas", "author": ["D. Thorleuchter", "D. Van den Poel"], "venue": "Expert Systems with Applications,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "Thus, alignment is crucial to many systems accuracy [1].", "startOffset": 52, "endOffset": 55}, {"referenceID": 1, "context": "Sentence alignment must also be computationally feasible in order to be of practical use in various applications [2].", "startOffset": 113, "endOffset": 116}, {"referenceID": 5, "context": "The dataset used for this research was the Translanguage English Database (TED) [12], provided by Fondazione Bruno Kessler (FBK) [17].", "startOffset": 80, "endOffset": 84}, {"referenceID": 10, "context": "The dataset used for this research was the Translanguage English Database (TED) [12], provided by Fondazione Bruno Kessler (FBK) [17].", "startOffset": 129, "endOffset": 133}, {"referenceID": 12, "context": "Early attempts at automatically aligning sentences for parallel corpora were based on sentence lengths, together with vocabulary alignment [19].", "startOffset": 139, "endOffset": 143}, {"referenceID": 13, "context": "Brown\u2019s method [20] was", "startOffset": 15, "endOffset": 19}, {"referenceID": 14, "context": "Gale and Church [21] measured the number of characters in sentences.", "startOffset": 16, "endOffset": 20}, {"referenceID": 15, "context": "Other researchers continued exploring various methods of combining sentence length statistics with alignment of vocabularies [22, 23].", "startOffset": 125, "endOffset": 133}, {"referenceID": 16, "context": "Other researchers continued exploring various methods of combining sentence length statistics with alignment of vocabularies [22, 23].", "startOffset": 125, "endOffset": 133}, {"referenceID": 11, "context": "It uses the XAlign tool [18], which uses character lengths at the paragraph and sentence level for text alignment [24].", "startOffset": 24, "endOffset": 28}, {"referenceID": 17, "context": "It uses the XAlign tool [18], which uses character lengths at the paragraph and sentence level for text alignment [24].", "startOffset": 114, "endOffset": 118}, {"referenceID": 0, "context": "Difflib\u2019s \u201cratio\u201d function divides the length of matching blocks by the length of two strings, and returns a measure of the sequences\u2019 similarity as a float value in the range [0, 1].", "startOffset": 176, "endOffset": 182}, {"referenceID": 6, "context": ", a political science essay [13].", "startOffset": 28, "endOffset": 32}, {"referenceID": 7, "context": "As discussed in [14], texts from different domains are likely to use words with different meanings.", "startOffset": 16, "endOffset": 20}, {"referenceID": 18, "context": "If a domain is ignored, this can lead to translations that are misleading [26].", "startOffset": 74, "endOffset": 78}, {"referenceID": 3, "context": "BLEU and TER are well-described in the literature [4-5].", "startOffset": 50, "endOffset": 55}, {"referenceID": 4, "context": "BLEU and TER are well-described in the literature [4-5].", "startOffset": 50, "endOffset": 55}, {"referenceID": 8, "context": "The pycdec module is a Python interface to the cdec decoding and alignment algorithms [15, 16].", "startOffset": 86, "endOffset": 94}, {"referenceID": 9, "context": "The pycdec module is a Python interface to the cdec decoding and alignment algorithms [15, 16].", "startOffset": 86, "endOffset": 94}, {"referenceID": 2, "context": "BLEU is defined in [3] in terms of the n-gram precision (using n-grams", "startOffset": 19, "endOffset": 22}, {"referenceID": 2, "context": "Here, P! is the brevity penalty, which is given by [3] as:", "startOffset": 51, "endOffset": 54}, {"referenceID": 2, "context": "[3].", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "word insertions and deletions, and phrase and word order modifications [5].", "startOffset": 71, "endOffset": 74}, {"referenceID": 8, "context": "It provides translation and alignment modeling based on finite-state transducers and synchronous context-free grammars, as well as implementations of several parameter-learning algorithms [15, 16].", "startOffset": 188, "endOffset": 196}, {"referenceID": 9, "context": "It provides translation and alignment modeling based on finite-state transducers and synchronous context-free grammars, as well as implementations of several parameter-learning algorithms [15, 16].", "startOffset": 188, "endOffset": 196}], "year": 2014, "abstractText": "Text alignment is crucial to the accuracy of Machine Translation (MT) systems, some NLP tools or any other text processing tasks requiring bilingual data. This research proposes a language independent sentence alignment approach based on Polish (not position-sensitive language) to English experiments. This alignment approach was developed on the TED Talks corpus, but can be used for any text domain or language pair. The proposed approach implements various heuristics for sentence recognition. Some of them value synonyms and semantic text structure analysis as a part of additional information. Minimization of data loss was ensured. The solution is compared to other sentence alignment implementations. Also an improvement in MT system score with text processed with described tool is shown.", "creator": "Word"}}}