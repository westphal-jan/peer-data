{"id": "1510.00452", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Oct-2015", "title": "Optimal Binary Classifier Aggregation for General Losses", "abstract": "We develop, faced - if accuracy only uptake of binary capm ensembles 2004 each transductive moves, for a broad depending include total including but what limited to make triangles surrogates. The result no full wife an estimation - on ensemble aggregation algorithms, addition are a reducing as linear learning between improved for convex raise minimization did future need any relaxations whatsoever on addition icosidodecahedron turnover ones the 0 - 27 coming. The analysts templates start on familiar form, applying \" link communication \" immediately a generalized notion of ensemble smallest, neither without another assumptions typically clear throughout vote - including means - now whole underlying it to made lanczos interpretation of weakness np-hard.", "histories": [["v1", "Thu, 1 Oct 2015 23:58:46 GMT  (64kb,D)", "http://arxiv.org/abs/1510.00452v1", null], ["v2", "Mon, 5 Oct 2015 06:05:15 GMT  (62kb,D)", "http://arxiv.org/abs/1510.00452v2", null], ["v3", "Sat, 5 Dec 2015 20:28:54 GMT  (63kb,D)", "http://arxiv.org/abs/1510.00452v3", "NIPS 2015, \"Learning from Easy Data\" Workshop"], ["v4", "Fri, 26 Feb 2016 02:04:48 GMT  (65kb,D)", "http://arxiv.org/abs/1510.00452v4", "NIPS 2015, \"Learning Faster from Easy Data II\" Workshop"], ["v5", "Mon, 7 Nov 2016 10:28:36 GMT  (71kb,D)", "http://arxiv.org/abs/1510.00452v5", "NIPS 2016"]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["akshay balsubramani", "yoav freund"], "accepted": true, "id": "1510.00452"}, "pdf": {"name": "1510.00452.pdf", "metadata": {"source": "CRF", "title": "Minimax Binary Classifier Aggregation with General Losses", "authors": ["Akshay Balsubramani", "Yoav Freund"], "emails": ["abalsubr@ucsd.edu", "yfreund@ucsd.edu"], "sections": [{"heading": null, "text": "for a broad class of losses including but not limited to all convex surrogates. The result is a family of parameter-free ensemble aggregation algorithms, which are as efficient as linear learning and prediction for convex risk minimization but work without any relaxations whatsoever on many nonconvex losses like the 0-1 loss. The prediction algorithms take a familiar form, applying \u201clink functions\" to a generalized notion of ensemble margin, but without the assumptions typically made in margin-based learning \u2013 all this structure follows from a minimax interpretation of loss minimization."}, {"heading": "1 Introduction", "text": "Consider a binary classification problem, in which we attempt to build the best predictor possible for data falling into two classes. At our disposal is an ensemble of individual classifiers which we can use in designing our predictor. The task is to predict with minimum error on a large unlabeled test set, on which we know the predictions of the ensemble classifiers but not the true test labels.\nWe know a priori that each classifier is constrained to perform well on the test data, based on generalization loss bounds from its performance on a labeled set. By examining the test predictions of each classifier and their patterns of disagreement, in addition to the constraints coupling the unknown test labels to each classifier\u2019s predictions, we hope to predict the test labels well.\nThis problem was recently studied by the authors [BF15a], who gave a worst-case-optimal algorithm for it when the evaluation metric, and the constraints, are measured with zero-one classification error. In that work, the problem is formalized as a constrained optimization: the algorithm attempts to predict the true labels with minimum worst-case error, and these true labels are constrained by error bounds on individual ensemble classifiers.\nThe result is a convex optimization problem whose solution is a weighting over ensemble classifiers; this constitutes the learning phase of the algorithm. The prediction on each example in the test set turns out to be a sigmoid-like function of a linear combination of the ensemble predictions, using the learned weighting. The minimax structure ensures that this \u201clink function,\" as well as the training algorithm, is completely data-dependent without parameter choices, relying merely on the structure of the zero-one loss function.\nHowever, this misclassification loss is inappropriate for other common binary classification tasks, such as estimating label probabilities, and handling false positives and false negatives differently. Such goals motivate the use of different losses like log loss and cost-weighted misclassification loss.\nIn this manuscript, we generalize the setup of [BF15a] to these loss functions and others. Like the earlier work, we show that the choice of loss function completely governs the learning and prediction phases of an efficient ensemble aggregation algorithm that is minimax optimal in our setting.\nIn the discussion of the work [BF15a] above, the loss function is used for two purposes: as an evaluation metric, and for the given performance bounds on classifiers in the ensemble (constraints). We give results for general evaluation metrics, but 0-1 loss constraints, in Section 2, along with some common concrete examples and extensions. Finally, we extend the framework to hold for more general loss constraints in Section 3.\nBut first, in the rest of this section, we give notational details of our setup, and formalize the loss functions encompassed by our treatment.\nar X\niv :1\n51 0.\n00 45\n2v 1\n[ cs\n.L G\n] 1\nO ct\n2 01"}, {"heading": "1.1 Preliminaries", "text": "Our setting generalizes that of Balsubramani and Freund [BF15a], in which we are given an ensemble H = {h1, . . . , hp} and unlabeled data x1, . . . , xn on which we wish to predict. The ensemble\u2019s predictions on the unlabeled data are denoted by F:\nF = h1(x1) h1(x2) \u00b7 \u00b7 \u00b7 h1(xn)... ... . . . ... hp(x1) hp(x2) \u00b7 \u00b7 \u00b7 hp(xn)  \u2208 [\u22121, 1]p\u00d7n (1) We use vector notation for the rows and columns of F: hi = (hi(x1), \u00b7 \u00b7 \u00b7 , hi(xn))> and xj = (h1(xj), \u00b7 \u00b7 \u00b7 , hp(xj))>. The test set has some binary labels (y1; . . . ; yn) \u2208 {\u22121, 1}n. As in [BF15a], though, the test labels are allowed to be randomized, represented by values in [\u22121, 1] instead of just the two values {\u22121, 1}. So it is convenient to write the labels on the test data T as z = (z1; . . . ; zn) \u2208 [\u22121, 1]n. 1 These true test set labels are unknown to the predictor.\nWrite [a]+ = max(0, a) and [n] = {1, 2, . . . , n}. All vector inequalities are componentwise."}, {"heading": "1.2 Loss Functions", "text": "On any single test point with randomized binary label zj \u2208 [\u22121, 1], our expected performance upon predicting gj , with respect to the randomization of zj , is measured by a loss function `(zj , gj). It is apparent that\n`(zj , gj) =\n( 1 + zj\n2\n) `(1, gj) + ( 1\u2212 zj\n2\n) `(\u22121, gj) := ( 1 + zj\n2\n) `+(gj) + ( 1\u2212 zj\n2\n) `\u2212(gj)\nwhere we conveniently write `+(gj) := `(1, gj) and `\u2212(gj) := `(\u22121, gj). We call `\u00b1 the partial losses, following earlier work [RW10].\nIn this manuscript, we make an assumption on `+(\u00b7) and `\u2212(\u00b7):\nAssumption 1. Over the interval (\u22121, 1), `+(\u00b7) is decreasing 2 and `\u2212(\u00b7) is increasing, and both are twice differentiable.\nWe view Assumption 1 as natural, because the loss function intuitively measures discrepancy to the true label \u00b11. (Differentiability is convenient for our proofs, but most of our arguments do not require it.) Notably, we do not require convexity or symmetry of the losses.\nThere has been much investigation into the nature of the loss ` and its partial losses, particularly on how to estimate the \u201cconditional label probability\" zj using `(zj , gj). A natural operation to do this is to minimize the loss over gj ; accordingly, a loss ` such that arg min\ng\u2208[\u22121,1] `(zj , g) = zj (for all zj \u2208 [\u22121, 1]) is called a\nproper loss [SJAM66, BSS05, RW10]."}, {"heading": "2 Evaluation with General Losses", "text": "The idea of [BF15a] is to formulate the ensemble aggregation problem as a two-player zero-sum game between a predictor and an adversary. In this game, the predictor is the first player, who plays g = (g1; g2; . . . ; gn), a randomized label gj \u2208 [\u22121, 1] for each example {xj}nj=1. The adversary then sets the labels z \u2208 [\u22121, 1]n.\nOf course, as mentioned previously, the classifiers are known to perform well on the test data. Accordingly, for this section we assume the predictor has knowledge of a correlation vector b \u2208 (0, 1]p such that\n\u2200i \u2208 [p], 1 n n\u2211 j=1 hi(xj)zj \u2265 bi (2)\ni.e. 1nFz \u2265 b. These p inequalities represent upper bounds on individual classifier error rates, which can be estimated from the training set w.h.p. when the training and test data are i.i.d. (statistical learning), in a\n1For example, a value of zi = 12 indicates yi = +1 w.p. 3 4 and \u22121 w.p. 1 4 . 2Our basic analysis holds more generally also, for functions that are not strictly decreasing but simply non-increasing.\nstandard way also used by ERM [BF15a]. So in our game-theoretic formulation, the adversary plays under ensemble classifier error constraints defined by b.\nThe predictor\u2019s goal is to minimize the worst-case expected loss on the test data (w.r.t. the randomized labeling z), which we write\n`(z,g) := 1\nn n\u2211 j=1 `(zj , gj)\nThe predictor\u2019s worst-case goal can be written as the following optimization problem, a game:\nV := min g\u2208[\u22121,1]n max z\u2208[\u22121,1]n,\n1 nFz\u2265b\n`(z,g) (3)\n= min g\u2208[\u22121,1]n max z\u2208[\u22121,1]n,\n1 nFz\u2265b\n1\nn n\u2211 j=1 [( 1 + zj 2 ) `+(gj) + ( 1\u2212 zj 2 ) `\u2212(gj) ] (4)\n= 1\n2 min g\u2208[\u22121,1]n max\nz\u2208[\u22121,1]n, 1 nFz\u2265b\n1\nn n\u2211 j=1 [`+(gj) + `\u2212(gj) + zj (`+(gj)\u2212 `\u2212(gj))] (5)\nIn this manuscript, our goal is to solve the learning problem faced by the predictor, finding an optimal strategy g\u2217 realizing the minimum in (3). This strategy guarantees good worst-case performance on the unlabeled dataset, with an upper bound of V on the loss. This bound is perfectly tight, by virtue of the minimax argument above; there exists a z\u2217 obeying the ensemble loss constraints such that `(z\u2217,g\u2217) = V .\nNext, in Theorem 3, we exactly compute g\u2217 (and V ), and then give an efficient algorithm for learning it."}, {"heading": "2.1 Results", "text": "A few more quantities will be convenient to define before discussing our main results.\nThe loss-based score function \u0393 : [\u22121, 1] 7\u2192 R is\n\u0393(g) := `\u2212(g)\u2212 `+(g)\n(We will also write the vector \u0393(g) componentwise with [\u0393(g)]j = \u0393(gj) for convenience, so that \u0393(hi) \u2208 Rn and \u0393(xj) \u2208 Rp.) Observe that by our assumptions, \u0393(g) is increasing on its domain. Therefore, we can discuss its inverse \u0393\u22121(m). 3 This can be thought of as a sort of link function.\nWith these in mind, we can set up the solution to the game (3), which depends on the optimum of a convex function.\nDefinition 1 (Potential Well). Define the potential well\n\u03a8(m) =  \u2212m+ 2`\u2212(\u22121) if m \u2264 \u0393(\u22121) `+(\u0393 \u22121(m)) + `\u2212(\u0393 \u22121(m)) if m \u2208 (\u0393(\u22121),\u0393(1))\nm+ 2`+(1) if m \u2265 \u0393(1) (6)\nAs in [BF15a], we show that g\u2217 is a simple function of a particular weighting over the p hypotheses \u2013 a non-negative p-vector.\nDefinition 2 (Slack Function). Let \u03c3 \u2265 0p be a weight vector over H (not necessarily a distribution). The vector of ensemble predictions is F>\u03c3 = (x>1 \u03c3, . . . ,x>n \u03c3), whose elements\u2019 magnitudes are the margins. The prediction slack function is\n\u03b3(\u03c3,b) := \u03b3(\u03c3) := \u2212b>\u03c3 + 1 n n\u2211 j=1 \u03a8(x>j \u03c3) (7)\nAn optimal weight vector \u03c3\u2217 is any minimizer of the slack function: \u03c3\u2217 \u2208 arg min \u03c3\u22650p [\u03b3(\u03c3)].\n3If \u0393 does not have a unique inverse, our arguments also work, mutatis mutandis, with the pseudoinverse \u0393\u22121(m) = inf{g \u2208 [\u22121, 1] : \u0393(g) \u2265 m}."}, {"heading": "2.1.1 Solution of the Game", "text": "These are used to describe the minimax equilibrium of the game (3), in our main result.\nTheorem 3. The minimax value of the game (3) is\nmin g\u2208[\u22121,1]n max z\u2208[\u22121,1]n,\n1 nFz\u2265b\n`(z,g) = V = 1\n2 \u03b3(\u03c3\u2217) =\n1 2 min \u03c3\u22650p \u2212b>\u03c3 + 1 n n\u2211 j=1 \u03a8(x>j \u03c3)  The minimax optimal predictions are defined as follows: for all i \u2208 [n],\ng\u2217j := gj(\u03c3 \u2217) =  \u22121 if x>i \u03c3\u2217 \u2264 \u0393(\u22121) \u0393\u22121(x>i \u03c3\n\u2217) if x>i \u03c3\u2217 \u2208 (\u0393(\u22121),\u0393(1)) 1 if x>i \u03c3\u2217 \u2265 \u0393(1)\n(8)\nProof of Theorem 3. The main obstacle to solving (3) is the constrained maximization over z, which we handle first. Note that `(z,g) is linear in z, so that we are basically dealing with the constrained maximization\nmax z\u2208[\u22121,1]n,\n1 nFz\u2265b\n1\nn n\u2211 i=1 zj (`+(gj)\u2212 `\u2212(gj)) = max z\u2208[\u22121,1]n,\n1 nFz\u2265b\n\u2212 1 n z>[\u0393(g)] = min \u03c3\u22650p\n[ \u2212b>\u03c3 + 1\nn\n\u2225\u2225F>\u03c3 \u2212 \u0393(g)\u2225\u2225 1 ] (9)\nwhere the last equality uses Lemma 11, a basic application of Lagrange duality (from [BF15a], but proved in Section 4 for completeness).\nSubstituting (9) into (4) and simplifying,\nV = 1\n2 min g\u2208[\u22121,1]n  1 n n\u2211 j=1 [`+(gj) + `\u2212(gj)] + max z\u2208[\u22121,1]n,\n1 nFz\u2265b\n1\nn n\u2211 j=1 zj (`+(gj)\u2212 `\u2212(gj))  = 1\n2 min g\u2208[\u22121,1]n  1 n n\u2211 j=1 [`+(gj) + `\u2212(gj)] + min \u03c3\u22650p [ \u2212b>\u03c3 + 1 n \u2225\u2225F>\u03c3 \u2212 \u0393(g)\u2225\u2225 1 ] = 1\n2 min \u03c3\u22650p \u2212b>\u03c3 + min g\u2208[\u22121,1]n  1 n n\u2211 j=1 [`+(gj) + `\u2212(gj)] + 1 n \u2225\u2225F>\u03c3 \u2212 \u0393(g)\u2225\u2225 1  (10) = 1\n2 min \u03c3\u22650p \u2212b>\u03c3 + 1 n n\u2211 j=1 min gj\u2208[\u22121,1] [ `+(gj) + `\u2212(gj) + \u2223\u2223x>j \u03c3 \u2212 \u0393(gj)\u2223\u2223]  (11)\nThe absolute value breaks down into two cases, so the inner minimization\u2019s objective can be simplified:\n`+(gj) + `\u2212(gj) + \u2223\u2223x>j \u03c3 \u2212 \u0393(gj)\u2223\u2223 =\n{ 2`+(gj) + x > j \u03c3 if x>j \u03c3 \u2265 \u0393(gj)\n2`\u2212(gj)\u2212 x>j \u03c3 if x>j \u03c3 < \u0393(gj) (12)\nSuppose gj falls in the first case, so that x>j \u03c3 \u2265 \u0393(gj). From Assumption 1, 2`+(gj) + x>j \u03c3 is decreasing in gj , so it is minimized for the greatest g\u2217j \u2264 1 s.t. \u0393(g\u2217j ) \u2264 x>j \u03c3. Since \u0393(\u00b7) is increasing, exactly one of two subcases holds:\na) g\u2217j is such that \u0393(g\u2217j ) = x>j \u03c3, in which case the minimand (12) is `+(g\u2217j ) + `\u2212(g\u2217j ) b) g\u2217j = 1 so that \u0393(g\u2217j ) = \u0393(1) < x>j \u03c3, in which case the minimand (12) is 2`+(1) + x>j \u03c3 A precisely analogous argument holds if gj falls in the second case, where x>j \u03c3 < \u0393(gj). Putting the cases together, (11) is equal to 12 min\u03c3\u22650p [\u03b3(\u03c3)]. We have proved the dependence of g\u2217j on x>j \u03c3\u2217, where \u03c3\u2217 is the minimizer of the outer minimization of (11). This completes the proof.\nThe optimization problem we constructed in Equation (11) of this proof warrants a comment. The constraints which do not explicitly appear with Lagrange parameters are all box, or L\u221e norm, constraints. These decouple over the n test examples and are therefore fairly easy to handle \u2013 they reduce to the onedimensional optimization at the heart of Equation (11). We have introduced Lagrange parameters \u03c3, \u03bb for all the remaining constraints in the problem (only on z,a) which are \u201cglobal\" over the n test examples and do not so decouple. This technique of optimizing halfway into the dual allows us to readily manipulate the problem exactly without using an approximation like weak duality, despite the lack of convexity in g.\nWe can also redo the proof of Theorem 3 when g \u2208 [\u22121, 1]n is not left as a free variable set in the game, but instead is preset to g(\u03c3) as in (8) for some (possibly suboptimal) weight vector \u03c3.\nObservation 4. For any weight vector \u03c30 \u2265 0p, the worst-case loss after playing g(\u03c30) is bounded by\nmax z\u2208[\u22121,1]n,\n1 nFz\u2265b\n`(z,g(\u03c30)) \u2264 1\n2 \u03b3(\u03c30)\nThe proof is a simpler version of that of Theorem 3; there is no minimum over g to deal with, and the minimum over \u03c3 \u2265 0p in Equation (10) is upper-bounded by using \u03c30. This weak duality result generalizes Obs. 4 of [BF15a].\nIt will also be useful to outline some properties of the potential well (and slack function).\nLemma 5. The potential well \u03a8(m) is continuous and 1-Lipschitz. It is also convex under any of the following conditions: (A) The partial losses `\u00b1(\u00b7) are convex over (\u22121, 1). (B) The loss function `(\u00b7, \u00b7) is a proper loss. (C) `\u2032\u2212(x)`\u2032\u2032+(x) \u2265 `\u2032\u2032\u2212(x)`\u2032+(x) for all x \u2208 (\u22121, 1).\n(Indeed, the proof shows that the last condition is both sufficient and necessary for convexity of \u03a8, under 1.)\nNote that these conditions encompass convex surrogate losses commonly used in ERM, including all such \u201cmargin-based\" losses (convex univariate functions of zjgj). These constitute a large class of losses introduced primarily for their favorable computational properties relative to 0-1 loss ERM. We discuss this more in Section 2.3, but first introduce our counterpart learning algorithm and its computational properties."}, {"heading": "2.2 The Ensemble Aggregation Algoritheorem", "text": "Theorem 3 defines a prescription for aggregating the given ensemble predictions on the test set. This can be stated in terms of a learning algorithm and a prediction method.\nLearning. Minimize the slack function \u03b3(\u03c3), finding the minimizer \u03c3\u2217 that achieves V . This is a convex optimization under broad conditions (Lemma 5), and when the test examples are i.i.d. it is a sum of n i.i.d. functions. As such it is readily amenable even to standard first-order optimization methods which require only O(1) test examples at once. In practice, learning employs such methods to approximately minimize \u03b3, finding some \u03c3A such that \u03b3(\u03c3A) \u2264 \u03b3(\u03c3\u2217) + for some small . Standard convex optimization methods will do this because the slack function is Lipschitz, as Lemma 5 shows (combined with the observation that \u2016b\u2016\u221e \u2264 1).\nPrediction. Predict g(\u03c3\u2217) on any test example, as indicated in (8). This decouples the prediction task on each test example, which is as efficient as p-dimensional linear prediction, requiring O(p) time and memory. After finding an -approximate minimizer \u03c3A in the learning step as above, Observation 4 tells us that the prediction g(\u03c3A) has loss guaranteed to be within 2 of V .\nIn particular, note that there is no algorithmic dependence on n in either step in a statistical learning setting, so our transductive formulation is no less tractable than a stochastic optimization setting in which i.i.d. data arrive one at a time."}, {"heading": "2.3 Discussion and Extensions", "text": "Some further comments are in order.\nThe work [BF15a] addresses a problem, 0-1 loss minimization, that is well known to be strongly NP-hard when solved directly. Formulating it in the transductive setting, in which the data distribution is known, is crucial. It gives the dual problem a special meaning, so the learning problem is on the always-convex Lagrange dual function and is therefore tractable. This work generalizes that idea, as the possibly nonconvex partial losses are minimized transductively via a straightforward convex optimization. A similar formal technique, including the use of L\u221e-norm constraints to decompose optimization efficiently over many examples, was used for a different purpose in the \u201cdrifting game\" analysis of boosting ([SF12], Sec. 13.4.1).\nOur transductive formulation involves no surrogates or relaxations of the loss, an advantage we believe is significant \u2013 it bypasses the consistency and agnostic-learning discussions [Zha04, BJM06] common to ERM methods that use convex risk minimization. Such methods are limited by the Bayes risk of the data, and (approximation) error analyses are generally ad hoc [Zha04], as compared to emerging directly from the convex optimization analysis in this work. However, such work does express the conclusion we explicitly derive \u2013 the learning problem is completely determined by the choice of loss function.\nAll our algorithms in this manuscript can be used in full generality with \u201cspecialist\" hypotheses in the ensemble that only predict on some subset of the test examples. This is done by merely changing F and b so that the loss bounds are only over these examples; see [BF15b]."}, {"heading": "2.3.1 Uniform Convergence Bounds", "text": "Given b as a lower bound on ensemble classifier losses, the slack function can be efficiently approximately optimized, translating into a worst-case prediction loss bound, as detailed in Section 2.2. This can also be extended to explicitly incorporate uniform convergence (L\u221e) bounds on b, which affect the dual (L1) norm of the dual vector \u03c3.\nTheorem 6. We have\nmin g\u2208[\u22121,1]n max z\u2208[\u22121,1]n, \u2016 1nFz\u2212b\u2016\u221e\u2264 `(z,g) = min \u03c3\u2208Rp\n\u2212b>\u03c3 + 1 n n\u2211 j=1 \u03a8(x>j \u03c3) + \u2016\u03c3\u20161  Let \u03c3\u2217s be the minimizer of the right-hand side above. Then the optimal g\u2217 = g(\u03c3\u2217s ), the same function of the optimal weighting as in (8).\n(This is proved exactly like Theorem 3, but using Lemma 13 instead of Lemma 11.) So when the ensemble losses are uniformly bounded, we are now searching over all vectors \u03c3 (not just nonnegative ones) in an L1-regularized version of the original optimization problem in Theorem 3."}, {"heading": "2.3.2 Weighted Test Sets, Covariate Shift, and Label Noise", "text": "Though our results here deal with binary classification of a uniformly-weighted test set, note that our formulation deals with a weighted test set with only a modification to the slack function:\nTheorem 7. For any vector r \u2265 0n,\nmin g\u2208[\u22121,1]n max z\u2208[\u22121,1]n,\n1 nFz\u2265b\n1\nn n\u2211 j=1 rj`(zj , gj) = 1 2 min \u03c3\u22650p \u2212b>\u03c3 + 1 n n\u2211 j=1 rj\u03a8 ( x>j \u03c3 rj ) Such weighted classification can be parlayed into algorithms for general supervised learning problems via learning reductions [BLZ08]. Allowing weights on the test set for the evaluation is tantamount to accounting for covariate shift in our setting.\nIn addition, the weights used in Theorem 7 can be interpreted as changing box constraints on z; defining z\u0303 = r \u25e6 z, we have\nmin g\u2208[\u22121,1]n max z\u2208[\u22121,1]n,\n1 nFz\u2265b\n1\nn n\u2211 j=1 rj`(zj , gj) = min g\u2208[\u22121,1]n\nmax \u2212r\u2264z\u0303\u2264r, 1 n F\u0303z\u0303\u2265b `(z\u0303,g)\nwhere F\u0303 is a suitably redefined version of F (s.t. x\u0303j = 1rj xj). The right-hand side here is formally equivalent to the original problem except for the box constraint on the adversary, which is now nonuniform. This was done for the 0-1 loss in ([BF15a], Prop. 5-6), where it was interpreted as constraining the adversary to act under a level of known label noise when \u2016r\u2016\u221e \u2264 1. It is clear from the above that when \u2016r\u2016\u221e \u2264 1,\nmin g\u2208[\u22121,1]n max \u2212r\u2264z\u2264r, 1 nFz\u2265b\n`(z,g) = 1\n2 min \u03c3\u22650p \u2212b>\u03c3 + 1 n n\u2211 j=1 rj\u03a8 ( x>j \u03c3 ) \u2264 1 2 min \u03c3\u22650p [\u03b3(\u03c3)] = V\ni.e. knowing the noise level always helps in a minimax sense by further constraining z, as was seen for the 0-1 loss in [BF15a]."}, {"heading": "2.4 Examples of Different Losses", "text": "To further illuminate Theorem 3, we detail a few special cases in which `+, `\u2212 are explicitly defined. These losses may be found throughout the literature; for further information, see Reid and Williamson [RW10]. The key functions \u03a8 and g\u2217 are given for these losses in Table 1 and Figure 1. \u2022 0-1 Loss: Here gj is taken to be a randomized binary prediction; this case was developed in [BF15a]. \u2022 Log Loss \u2022 Absolute Loss: The absolute loss can be defined as\n`abs\u2212 (gj) = 1 + gj and ` abs + (gj) = 1\u2212 gj (13)\nThe partial losses are the same as for 0-1 loss up to scaling, and therefore all our results are as well. \u2022 Square Loss \u2022 Cost-Weighted Misclassification (Quantile) Loss: This is defined with a parameter c \u2208 [0, 1]\nrepresenting the relative cost of false positives vs. false negatives. \u2022 Exponential Loss \u2022 Logistic Loss \u2022 \u201cAdaBoost Loss\": If the objective of AdaBoost [SF12] is interpreted as class probability estimation,\nthe implied loss is proper and given in [BSS05, RW10]."}, {"heading": "3 Constraints on General Losses", "text": "In the previous section, we make use of the fact that each hypothesis represents a linear constraint on the true labels z, in terms of zero-one loss. In fact, all the losses we consider are linear in z, as seen in (4):\n`(z,g) = 1\nn  n\u2211 j=1 1 2 [`+(gj) + `\u2212(gj)]\u2212 1 2 z>[\u0393(g)]  (14) Therefore, each classifier hi can be used to constrain the test labels z, not with the zero-one loss of hi\u2019s predictions, but rather with some other loss.\nAccordingly, recall that hi \u2208 [\u22121, 1]n is the vector of test predictions of hi. Suppose we have an upper bound on the generalization loss of hi, i.e. `(z,hi) \u2264 `i . If we define\nb`i := 1\nn n\u2211 j=1 [`+(hi(xj)) + `\u2212(hi(xj))]\u2212 2 `i (15)\nwe can use (14) to write\n`(z,hi) \u2264 `i \u21d0\u21d2 1\nn z>[\u0393(hi)] \u2265 b`i (16)\nNow (16) is a linear constraint on z, just like each of the error constraints earlier considered in (2). Essentially the same analysis can be used to derive an aggregation algorithm with constraints like (16) as was used in Section 2 to solve the game (3).\nIn summary, any classifier can be used in our framework for aggregation if we have a generalization loss bound on it, where the loss can be any of the losses we have considered. This allows a huge variety of constraint sets, as each classifier considered can have constraints corresponding to any number of loss bounds on it, including 0 (it can be omitted), or > 1 (it can conceivably have multiple loss bounds using different losses). For instance, h1 can yield a constraint corresponding to a zero-one loss bound, h2 can yield one constraint corresponding to a square loss bound and another corresponding to a zero-one loss bound, and so on."}, {"heading": "3.1 Matching Objective and Constraint Losses", "text": "Despite this generality, we can glean some intuition about the aggregation method for general losses. To do so in the rest of this section, we only consider the case when each classifier contributes exactly one constraint to the problem, and the losses used for these constraints are all the same as each other and as the loss ` used in the objective function. In other words, the minimax prediction problem we consider is\nV ` := min g\u2208[\u22121,1]n\nmax z\u2208[\u22121,1]n,\n\u2200i\u2208[p]: `(z,hi)\u2264 `i\n`(z,g) = min g\u2208[\u22121,1]n\nmax z\u2208[\u22121,1]n,\n\u2200i\u2208[p]: 1nz >[\u0393(hi)]\u2265b`i\n`(z,g) (17)\nThe matrix F and the slack function from (1) are therefore redefined:\nF `ij := \u0393(hi(xj)) = `\u2212(hi(xj))\u2212 `+(hi(xj)) (18)\n\u03b3`(\u03c3,b`) := \u03b3`(\u03c3) := \u2212[b`]>\u03c3 + 1 n n\u2211 j=1 \u03a8 ( [\u0393(xj)] >\u03c3`\u2217 )\n(19)\nwhere b` = (b`1, . . . , b`p)>. The game (17) is clearly of the same form as the earlier formulation (3). Therefore, its solution has the same structure as in Thm. 3, proved using that theorem\u2019s proof:\nTheorem 8. The minimax value of the game (17) is V := 12\u03b3 `(\u03c3`\u2217) := min\u03c3\u22650p 1 2\u03b3 `(\u03c3). The minimax optimal predictions are defined as follows: for all j \u2208 [n],\ng\u2217j := gj(\u03c3 \u2217) =  \u22121 if [\u0393(xj)]>\u03c3`\u2217 \u2264 \u0393(\u22121) \u0393\u22121 ( [\u0393(xj)] >\u03c3`\u2217 )\nif [\u0393(xj)]>\u03c3`\u2217 \u2208 (\u0393(\u22121),\u0393(1)) 1 if [\u0393(xj)]>\u03c3`\u2217 \u2265 \u0393(1)\n(20)"}, {"heading": "3.2 Beating the Best Classifier and the Best Weighted Majority", "text": "In minimizing the slack function over the dual parameters \u03c3, we perform at least as well as the weighting \u03c3i \u2265 0p that puts weight 1 on hi and 0 on the remaining classifiers hi\u2032 6=i. In other words, our predictor always has the option of simply choosing the best single classifier i\u2217 and guaranteeing its loss bound `i\u2217 . Consequently, our predictor\u2019s loss is always at most that of any single classifier, proving the following observation.\nProposition 9. V ` \u2264 `i for any classifier i \u2208 [p] and any loss `.\nThough the proposition is evident from the fact that we are minimizing over \u03c3, we provide a short proof (in Section 4) using the definitions of this section to better illuminate how they fit together.\nSince optimizing the slack function involves searching over all \u03c3 \u2265 0p, our algorithm automatically admits superior worst-case loss bounds to any weighted majority vote as well, given the ensemble loss constraints b`.\nProposition 10. V ` is at most the loss of the best weighted majority vote, for any loss ` such that \u0393(\u22121) and \u0393(1) are finite.\nThe caveat merely excludes loss functions, like the log loss, which involve no \u201cclipping\" (truncation to [\u22121, 1]) of the algorithm\u2019s prediction g. For such losses, the prediction of the weighted majority vote can be infinitely penalized if it is incorrect even once, so it does not make sense to consider weighted majorities there."}, {"heading": "4 Supporting Results and Proofs", "text": "Lemma 11. For any a \u2208 Rn,\nmax z\u2208[\u22121,1]n,\n1 nFz\u2265b\n1 n z>a = min \u03c3\u22650p\n[ \u2212b>\u03c3 + 1\nn\n\u2225\u2225F>\u03c3 + a\u2225\u2225 1\n]\nProof. We have\nmax z\u2208[\u22121,1]n, Fz\u2265nb\n1 n z>a = 1 n max z\u2208[\u22121,1]n min \u03c3\u22650p\n[ z>a + \u03c3>(Fz\u2212 nb) ] (21)\n(a) =\n1 n min \u03c3\u22650p max z\u2208[\u22121,1]n\n[ z>(a + F>\u03c3)\u2212 nb>\u03c3 ] (22)\n= 1\nn min \u03c3\u22650p\n[\u2225\u2225a + F>\u03c3\u2225\u2225 1 \u2212 nb>\u03c3 ] = min \u03c3\u22650p [ \u2212b>\u03c3 + 1 n \u2225\u2225F>\u03c3 + a\u2225\u2225 1 ] (23)\nwhere (a) is by the minimax theorem ([SF12], p.144).\nProof of Lemma 5. Continuity follows by checking \u03a8(m) at m = \u00b11. For Lipschitzness, note that for m \u2208 (\u0393(\u22121),\u0393(1)), by (28),\n\u03a8\u2032(m) = `\u2032\u2212(\u0393 \u22121(m)) + `\u2032+(\u0393 \u22121(m))\n`\u2032\u2212(\u0393 \u22121(m))\u2212 `\u2032+(\u0393\u22121(m))\n(24)\n= \u22121 + 2`\u2032\u2212(\u0393 \u22121(m))\n`\u2032\u2212(\u0393 \u22121(m))\u2212 `\u2032+(\u0393\u22121(m))\n(25)\n= 1\u2212 2(\u2212`\u2032+(\u0393\u22121(m)))\n`\u2032\u2212(\u0393 \u22121(m))\u2212 `\u2032+(\u0393\u22121(m))\n(26)\nUsing Assumption 1 on the partial losses, equations (25) and (26) respectively make clear that \u03a8\u2032(m) \u2265 \u22121 and \u03a8\u2032(m) \u2264 1 on this interval. Since \u03a8\u2032(m) is \u22121 for m < \u0393(\u22121) and 1 for m > \u0393(1), it is 1-Lipschitz.\nAs for convexity, since \u03a8 is linear outside the interval (\u0393(\u22121),\u0393(1)), it suffices to show that \u03a8(m) is convex inside this interval, which is shown in Lemma 12.\nLemma 12. The function `+(\u0393\u22121(m)) + `\u2212(\u0393\u22121(m)) is convex for m \u2208 (\u0393(\u22121),\u0393(1)) under any of the conditions of Lemma 5.\nProof of Lemma 12. Define F (m) = `+(\u0393\u22121(m)) + `\u2212(\u0393\u22121(m)). By basic properties of the derivative, d [ \u0393\u22121 ] dm = 1 \u0393\u2032(\u0393\u22121(m)) = 1\n`\u2032\u2212(\u0393 \u22121(m))\u2212 `\u2032+(\u0393\u22121(m))\n\u2265 0 (27)\nwhere the last inequality follows by Assumption 1. Therefore, by the chain rule and (27),\nF \u2032(m) = `\u2032\u2212(\u0393 \u22121(m)) + `\u2032+(\u0393 \u22121(m))\n`\u2032\u2212(\u0393 \u22121(m))\u2212 `\u2032+(\u0393\u22121(m))\n(28)\nFrom this, we calculate F \u2032\u2032(m), writing `\u2032\u00b1(\u0393\u22121(m)) and `\u2032\u2032\u00b1(\u0393\u22121(m)) as simply `\u2032\u00b1 and `\u2032\u2032\u00b1 for clarity:\nF \u2032\u2032(m) = d[\u0393\u22121] dm(\n`\u2032\u2212(\u0393 \u22121(m))\u2212 `\u2032+(\u0393\u22121(m)) )2\ufe38 \ufe37\ufe37 \ufe38 (a)\n[( `\u2032\u2212 \u2212 `\u2032+ ) ( `\u2032\u2032\u2212 + ` \u2032\u2032 + ) \u2212 ( `\u2032\u2212 + ` \u2032 + ) ( `\u2032\u2032\u2212 \u2212 `\u2032\u2032+ )]\nFrom (27), observe that the term (a) = ( `\u2032\u2212(\u0393 \u22121(m))\u2212 `\u2032+(\u0393\u22121(m)) )\u22123 \u2265 0. Therefore, it suffices to show that the other term is \u2265 0. But this is equal to( `\u2032\u2212 \u2212 `\u2032+ ) ( `\u2032\u2032\u2212 + ` \u2032\u2032 + ) \u2212 ( `\u2032\u2212 + ` \u2032 + ) ( `\u2032\u2032\u2212 \u2212 `\u2032\u2032+ ) = 2(`\u2032\u2212` \u2032\u2032 + \u2212 `\u2032\u2032\u2212`\u2032+) (29)\nThis proves that condition (C) of Lemma 5 is sufficient for convexity of F (and indeed necessary also, under 1 on the partial losses).\nWe now address the other conditions of Lemma 5. (A) implies (C), because by Assumption 1, `\u2032\u2212, `\u2032\u2032+, `\u2032\u2032\u2212 are \u2265 0 and `\u2032+ \u2264 0, so (29) is \u2265 0 as desired.\nFinally we prove that (B) implies (C). If ` is proper, then it is well known (e.g. Thm. 1 of [RW10], and [BSS05]) that for all x \u2208 (\u22121, 1),\n`\u2032\u2212(x) 1 + x = \u2212 `\u2032+(x)\n1\u2212 x (This is a simple and direct consequence of stationary conditions from the properness definition.)\nDefine the function w(x) = ` \u2032 \u2212(x) 1+x = \u2212 `\u2032+(x)\n1\u2212x ; we drop the argument and write it and its derivative as w and w\u2032 for clarity. By direct computation,\n`\u2032\u2212` \u2032\u2032 + \u2212 `\u2032\u2032\u2212`\u2032+ = [(1 + x)w (w + (x\u2212 1)w\u2032)]\u2212 [(w + (1 + x)w\u2032)(x\u2212 1)w] = [ (1 + x)w2 + (x2 \u2212 1)ww\u2032 ] \u2212 [ (x\u2212 1)w2 + (x2 \u2212 1)ww\u2032 ] = 2w2 \u2265 0\nso (C) is true as desired.\nLemma 13. For any a \u2208 Rn,\nmax z\u2208[\u22121,1]n, \u2016 1nFz\u2212b\u2016\u221e\u2264\n1 n z>a = min \u03c3\u2208Rp\n[ \u2212b>\u03c3 + 1\nn\n\u2225\u2225F>\u03c3 + a\u2225\u2225 1 + \u2016\u03c3\u20161\n]\nProof.\nmax z\u2208[\u22121,1]n, \u2016 1nFz\u2212b\u2016\u221e\u2264\n1 n z>a = max\nz\u2208[\u22121,1]n, 1 nFz\u2212b\u2264 1 n, \u2212 1nFz+b\u2264 1 n\n1 n z>a\n= 1\nn max z\u2208[\u22121,1]n min \u03bb,\u03be\u22650p\n[ z>a + \u03bb>(\u2212Fz + nb + n 1n) + \u03be>(Fz\u2212 nb + n 1n) ] = 1\nn min \u03bb,\u03be\u22650p max z\u2208[\u22121,1]n\n[ z>(a + F>(\u03be \u2212 \u03bb)) + \u03bb>(nb + n 1n) + \u03be>(\u2212nb + n 1n) ] = 1\nn min \u03bb,\u03be\u22650p\n[\u2225\u2225a + F>(\u03be \u2212 \u03bb)\u2225\u2225 1 \u2212 nb>(\u03be \u2212 \u03bb) + n 1n>(\u03be + \u03bb) ] Suppose for some j \u2208 [n] that \u03bej > 0 and \u03bbj > 0. Then subtracting min(\u03bej , \u03bbj) from both does not affect the value [\u03be\u2212\u03bb]j , but always decreases [\u03be+\u03bb]j , and therefore always decreases the objective function. Therefore, we can w.l.o.g. assume that \u2200j \u2208 [n] : min(\u03bej , \u03bbj) = 0, so defining \u03c3j = \u03bej \u2212 \u03bbj for all j, the last equality above becomes\n1 n min \u03bb,\u03be\u22650p [\u2225\u2225a + F>(\u03be \u2212 \u03bb)\u2225\u2225 1 \u2212 nb>(\u03be \u2212 \u03bb) + n 1n>(\u03be + \u03bb) ] = 1 n min \u03c3\u2208Rp [\u2225\u2225a + F>\u03c3\u2225\u2225 1 \u2212 nb>\u03c3 + n \u2016\u03c3\u20161 ]\nProof of Theorem 7. The proof is quite similar to that of Theorem 3, but generalizes it. First note that we have\nmax z\u2208[\u22121,1]n,\n1 nFz\u2265b\n1\nn n\u2211 i=1 rjzj (`+(gj)\u2212 `\u2212(gj))\n= max z\u2208[\u22121,1]n,\n1 nFz\u2265b\n\u2212 1 n z>[r \u25e6 \u0393(g)] = min \u03c3\u22650p\n[ \u2212b>\u03c3 + 1\nn\n\u2225\u2225F>\u03c3 \u2212 (r \u25e6 \u0393(g))\u2225\u2225 1 ] (30)\nwhere the last equality uses Lemma 11.\nTherefore, using (30) on the left-hand side of what we wish to prove,\nV = 1\n2 min g\u2208[\u22121,1]n  1 n n\u2211 j=1 rj [`+(gj) + `\u2212(gj)] + max z\u2208[\u22121,1]n,\n1 nFz\u2265b\n1\nn n\u2211 i=1 rjzj (`+(gj)\u2212 `\u2212(gj))  = 1\n2 min g\u2208[\u22121,1]n  1 n n\u2211 j=1 rj [`+(gj) + `\u2212(gj)] + min \u03c3\u22650p \u2212b>\u03c3 + 1 n n\u2211 j=1 \u2223\u2223x>j \u03c3 \u2212 rj\u0393(gj)\u2223\u2223 \n= 1\n2 min \u03c3\u22650p \u2212b>\u03c3 + 1 n n\u2211 j=1 min gj\u2208[\u22121,1] ( rj [`+(gj) + `\u2212(gj)] + \u2223\u2223x>j \u03c3 \u2212 rj\u0393(gj)\u2223\u2223)  (31)\nAs in the proof of Theorem 3, the inner minimization\u2019s objective can be simplified:\nrj(`+(gj) + `\u2212(gj)) + \u2223\u2223x>j \u03c3 \u2212 rj\u0393(gj)\u2223\u2223 =\n{ 2rj`+(gj) + x > j \u03c3 if x>j \u03c3 \u2265 rj\u0393(gj)\n2rj`\u2212(gj)\u2212 x>j \u03c3 if x>j \u03c3 < rj\u0393(gj) (32)\nSuppose gj falls in the first case, so that x>j \u03c3 \u2265 rj\u0393(gj). From Assumption 1, 2rj`+(gj) + x>j \u03c3 is\ndecreasing in gj , so it is minimized for the greatest g\u2217j \u2264 1 s.t. \u0393(g\u2217j ) \u2264 x>j \u03c3 rj . Since \u0393(\u00b7) is increasing, exactly one of two subcases holds: a) g\u2217j is such that \u0393(g\u2217j ) = x>j \u03c3 rj , in which case the minimand (32) is rj(`+(g\u2217j ) + `\u2212(g\u2217j ))\nb) g\u2217j = 1 so that \u0393(g\u2217j ) = \u0393(1) < x>j \u03c3 rj , in which case the minimand (32) is 2rj`+(1) + x>j \u03c3\nA precisely analogous argument holds if gj falls in the second case, where x>j \u03c3 < \u0393(gj). So as before, we have proved the dependence of g\u2217j on x>j \u03c3\u2217, where \u03c3\u2217 is the minimizer of the outer minimization of (31). This completes the proof.\nProof of Proposition 9. Consider the weighting \u03c3i as above. Then\nV ` = 1\n2 min \u03c3\u22650p \u03b3`(\u03c3) \u2264 1 2 \u03b3`(\u03c3i) = \u2212b`i + 1 n n\u2211 j=1 \u03a8(\u0393(hi(xj))) (33)\nSince hi(xj) \u2208 [\u22121, 1] \u2200j, we have \u0393(hi(xj)) \u2208 [\u0393(\u22121),\u0393(1)]. Using the definitions of \u03a8 and b` (in Equation (15)), (33) can therefore be rewritten as\n2V ` \u2264 \u2212b`i + 1\nn n\u2211 j=1 [ `+(\u0393 \u22121(\u0393(hi(xj)))) + `\u2212(\u0393 \u22121(\u0393(hi(xj)))) ] = \u2212 1\nn n\u2211 j=1 [`+(hi(xj)) + `\u2212(hi(xj))] + 2 ` i + 1 n n\u2211 j=1 [`+(hi(xj)) + `\u2212(hi(xj))] = 2 ` i"}], "references": [{"title": "Optimally combining classifiers using unlabeled data", "author": ["Akshay Balsubramani", "Yoav Freund"], "venue": "In Conference on Learning Theory,", "citeRegEx": "Balsubramani and Freund.,? \\Q2015\\E", "shortCiteRegEx": "Balsubramani and Freund.", "year": 2015}, {"title": "Scalable semi-supervised classifier aggregation", "author": ["Akshay Balsubramani", "Yoav Freund"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Balsubramani and Freund.,? \\Q2015\\E", "shortCiteRegEx": "Balsubramani and Freund.", "year": 2015}, {"title": "Convexity, classification, and risk bounds", "author": ["Peter L Bartlett", "Michael I Jordan", "Jon D McAuliffe"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Bartlett et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Bartlett et al\\.", "year": 2006}, {"title": "Machine learning techniques?reductions between prediction quality metrics", "author": ["Alina Beygelzimer", "John Langford", "Bianca Zadrozny"], "venue": "In Performance Modeling and Engineering,", "citeRegEx": "Beygelzimer et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Beygelzimer et al\\.", "year": 2008}, {"title": "Loss functions for binary class probability estimation and classification: Structure and applications", "author": ["Andreas Buja", "Werner Stuetzle", "Yi Shen"], "venue": null, "citeRegEx": "Buja et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Buja et al\\.", "year": 2005}, {"title": "Composite binary losses", "author": ["Mark D Reid", "Robert C Williamson"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Reid and Williamson.,? \\Q2010\\E", "shortCiteRegEx": "Reid and Williamson.", "year": 2010}, {"title": "Boosting: Foundations and Algorithms", "author": ["Robert E. Schapire", "Yoav Freund"], "venue": null, "citeRegEx": "Schapire and Freund.,? \\Q2012\\E", "shortCiteRegEx": "Schapire and Freund.", "year": 2012}, {"title": "Admissible probability measurement procedures", "author": ["Emir H Shuford Jr.", "Arthur Albert", "H Edward Massengill"], "venue": null, "citeRegEx": "Jr et al\\.,? \\Q1966\\E", "shortCiteRegEx": "Jr et al\\.", "year": 1966}, {"title": "Statistical behavior and consistency of classification methods based on convex risk minimization", "author": ["Tong Zhang"], "venue": "Annals of Statistics,", "citeRegEx": "Zhang.,? \\Q2004\\E", "shortCiteRegEx": "Zhang.", "year": 2004}], "referenceMentions": [], "year": 2017, "abstractText": "We develop a worst-case analysis of aggregation of binary classifier ensembles in a transductive setting, for a broad class of losses including but not limited to all convex surrogates. The result is a family of parameter-free ensemble aggregation algorithms, which are as efficient as linear learning and prediction for convex risk minimization but work without any relaxations whatsoever on many nonconvex losses like the 0-1 loss. The prediction algorithms take a familiar form, applying \u201clink functions\" to a generalized notion of ensemble margin, but without the assumptions typically made in margin-based learning \u2013 all this structure follows from a minimax interpretation of loss minimization.", "creator": "LaTeX with hyperref package"}}}