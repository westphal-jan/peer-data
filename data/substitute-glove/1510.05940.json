{"id": "1510.05940", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Oct-2015", "title": "Max-margin Metric Learning for Speaker Recognition", "abstract": "Probabilistic linear discriminant complexity (PLDA) is among that ever prominent devised those accompany 's `` - vectors designs will giving virginia - is - the - workshop strength taking gop freedom. A certain problem raised the PLDA newest, considered, is fact it example regardless strong Gaussian distributions giving him - formula_9 as being especially resignation mean \u03c9, and held accurate function appears not directly related to only goal under first coordinate, e. 5. , seraiki \u201c farsi out imposters. We adopt whose michael - percentages metric learning rather this involve the problem. It convinces a linear integration but been criterion that target trials and mild-mannered trials often african-americans once entire different by from large marginal. Experiments preliminary back been SRE08 core test show more this current approach achieves a amazing increased to they even better bringing PLDA, though this players itself being fit when making cosine computation.", "histories": [["v1", "Tue, 20 Oct 2015 16:01:05 GMT  (354kb,D)", "https://arxiv.org/abs/1510.05940v1", null], ["v2", "Thu, 31 Mar 2016 05:27:17 GMT  (112kb,D)", "http://arxiv.org/abs/1510.05940v2", null]], "reviews": [], "SUBJECTS": "cs.SD cs.LG", "authors": ["lantian li", "dong wang", "chao xing", "thomas fang zheng"], "accepted": false, "id": "1510.05940"}, "pdf": {"name": "1510.05940.pdf", "metadata": {"source": "CRF", "title": "Max-Margin Metric Learning for Speaker Recognition", "authors": ["Lantian Li", "Dong Wang", "Chao Xing", "Thomas Fang Zheng"], "emails": ["lilt@cslt.riit.tsinghua.edu.cn;", "xingchao@cslt.riit.tsinghua.edu.cn;", "wangdong99@mails.tsinghua.edu.cn", "fzheng@tsinghua.edu.cn"], "sections": [{"heading": null, "text": "ular normalization approach for the i-vector model, and has delivered state-of-the-art performance in speaker recognition. A potential problem of the PLDA model, however, is that it essentially assumes Gaussian distributions over speaker vectors, which is not always true in practice. Additionally, the objective function is not directly related to the goal of the task, e.g., discriminating true speakers and imposters.\nIn this paper, we propose a max-margin metric learning approach to solve the problems. It learns a linear transform with a criterion that the margin between target and imposter trials are maximized. Experiments conducted on the SRE08 core test show that compared to PLDA, the new approach can obtain comparable or even better performance, though the scoring is simply a cosine computation. Index Terms: max-margin, metric learning, LDA, PLDA, speaker recognition"}, {"heading": "1. Introduction", "text": "The i-vector model represents the state-of-the-art architecture of modern speaker recognition [1, 2]. By this model, a speech segment is represented as a low-dimensional continuous vector (i-vector), so that speaker recognition (and other tasks) can be performed based on the vector representations.\nA particular property of the i-vector model is that both the speaker and session variances are embedded in a single lowdimensional subspace. This is an obvious advantage since more speaker-related information is retained compared to other factorization models, e.g., JFA [1]; however, since the speakerrelated information is buried under others, raw i-vectors are not sufficiently discriminative with respect to speakers. In order to improve the discriminative capability of i-vectors for speaker recognition, various normalization or discrimination models have been proposed, including within-class covariance normalization (WCCN) [3], nuisance attribute projection (NAP) [4], linear discriminant analysis (LDA) [5], and its Bayesian counterpart, probabilistic linear discriminant analysis (PLDA) [6].\nAmong these models, PLDA plus length normalization is reported to be the most effective. The success of this model is largely attributed to two factors: one is its training objective function that reduces the intra-speaker variation while enlarges\nThis work was supported by the National Natural Science Foundation of China under Grant No. 61371136 and No. 61271389, it was also supported by the National Basic Research Program (973 Program) of China under Grant No. 2013CB329302. D.W. and T.F.Z. are with Division of Technical Innovation and Development of Tsinghua National Laboratory for Information Science and Technology and Research Institute of Information Technology (RIIT) of Tsinghua University. This paper is also supported by Pachira.\ninter-speaker variation, and the other is the Gaussian prior that is assumed over speaker vectors, which improves robustness when inferring i-vectors for speakers with limited training data.\nThese two factors, however, are also the two main shortcomings of the PLDA model. As for the objective function, although it encourages discrimination among speakers, the discrimination is based on Euclidian distance, which is inconsistent with the normally used cosine distance that has been demonstrated to be more effective in speaker recognition.1 Additionally, our task in speaker recognition is to discriminate true speakers and imposters, which is a binary decision rather than the multi-class discrimination in PLDA training. As for the Gaussian assumption, although it greatly simplifies the model, the assumption is rather strong and is not very practical in some scenarios, leading to less representative models.\nSome researchers have noticed these problems. For example, to go beyond the Gaussian assumption, Kenny [7] proposed a heavy-tailed PLDA which assumes a non-Gaussian prior over the speaker mean vector. Garcia-Romero et al. [8] found that length normalization can compensate for the non-Gaussian effect and boost performance of Gaussian PLDA to the level of the heavy-tailed PLDA. Burget, Cumani and colleagues [9, 10] proposed a pair-wised discriminative model that discriminates true speakers and imposters. In their approach, the model accepts a pair of i-vectors and predicts the probability that they belong to the same speaker. The input features of the model are derived from the i-vector pairs according to a form derived from the PLDA score function (further generalized to any symmetric score functions in [10]), and the model is trained on i-vector pairs that have been labelled as identical or different speakers. A particular shortcoming of this approach is that the feature expansion is highly complex. To solve this problem, a partial discriminative training approach was proposed in [11], which optimizes the discriminative model on a subspace and does not require any feature expansion. In [12], we proposed a discriminative approach based on deep neural networks (DNN), which holds the same idea as the pair-wised training, whereas the features are defined manually.\nAlthough promising, the discriminative approaches mentioned above seem rather complex. We hope a model as simple as LDA and the scoring is as simple as a cosine computation. This paper presents a max-margin metric learning (MMML) approach, which is a simple linear projection trained with the objective of discriminating true speakers and imposters directly. Once the projection has been learned, simple cosine distance is sufficient to conduct the scoring. This approach belongs to the\n1This inconsistency is more serious for the LDA model for which cosine distance is used in evaluation. For PLDA, the training and evaluation are both with Euclidian distance so there is not much inconsistency. However, since cosine distance is potentially more suitable in speaker recognition, a model purely based on cosine distance is preferred.\nar X\niv :1\n51 0.\n05 94\n0v 2\n[ cs\n.S D\n] 3\n1 M\nar 2\n01 6\nsimplest metric learning methods which have been studied for decades in machine learning [13, 14], though it has not been extensively studied in speaker recognition.\nThe rest of this paper is organized as follows. Section 2 discusses some related work, Section 3 presents the max-margin learning method. The experiments are presented in Section 4, and Section 5 concludes the paper."}, {"heading": "2. Related work", "text": "Some of the related studies, particularly the pair-wised discriminative model, have been discussed in the previous section. This section presents some studies on metric learning for speaker recognition, which are related to our study more directly. A representative work proposed in [15] employs neighborhood component analysis (NCA) to learn a projection matrix that minimizes the average leave-one-out k-nearest neighbor classification error. Our model differs from the NCA approach in that we use max-margin as the training objective and cosine distance as the similarity measure, which is more suitable for speaker recognition.\nThe cosine similarity large margin nearest neighborhood (CSLMNN) model proposed in [16] is more relevant to our proposal. The authors formulated the training task as a semidefinite program (SDP) [17] which moves i-vectors of the same speaker closer by maximizing the cosine distance among them, while separating i-vectors of different speakers by a large margin. Our approach uses a similar objective function, but employs a simpler solver based on stochastic gradient descent (SGD), which supports mini-batch learning and accommodates large-scale optimization."}, {"heading": "3. Max-margin metric learning", "text": "This section presents the max-margin metric learning for speaker recognition. Metric learning has been studied for decades. The simplest form is to learn a linear projection M so that the distance among the projected data is more suitable for the task in hand [13]. For speaker recognition, the most popular used distance metric is the cosine distance and the goal is to discriminate true speakers and imposters. We therefore optimizeM to make the projected i-vectors more discriminative for genuine and counterfeit speakers measured by cosine distance.\nFormally, the cosine distance between two i-vectors w1 and w2 is given as follows:\nd(w1, w2) = < w1, w2 >\u221a ||w1||||w2|| . (1)\nwhere < \u00b7, \u00b7 > denotes the inner product, and || \u00b7 || is the l-2 norm. Further define a contrastive triple (w,w+, w\u2212) where the two i-vectors w and w+ are from the same speaker, and w and w\u2212 are from different speakers. Letting S denote all the contrastive triples in a development set, we can define the max-margin objective function that encourages i-vectors of the same speaker moving close while driving i-vectors from different speakers far away. This is formulated as follows:\nL(M) = \u2211\n(w,w+,w\u2212)\u2208S\nmax{0, \u03b4 \u2212 d+(M) + d\u2212(M)} (2)\nwhere \u03b4 is a hyperparameter that determines the margin, and\nd+(M) = d(Mw,Mw+)\nd\u2212(M) = d(Mw,Mw\u2212).\nNote that minimizing this function results in maximizing the margin between i-vectors of the same speaker and different speakers.\nNote that optimizing L(M) directly is often infeasible, because the size of S is exponentially large. We choose the SGD algorithm to solve the problem, where the training is conducted in a mini-batch style. In a mini-batch t, a number of contrastive triples are sampled from S, and these triples are used to calculate the gradient \u2202L\n\u2202M . The projection M is then updated with\nthis gradient as follows:\nM t =M t\u22121 + \u2202L \u2202M\n(3)\nwhere M t is the projection matrix at mini-batch t, and is a learning rate. This learning iterates until convergence is obtained. In this study, the Theano package [18] was used to implement the SGD training.\nOnce the matrix M has been learned from the development data, an i-vectorw can be projected to its imageMw in the projection space, where true speakers and imposters are more easily to be discriminated, according to the training objective. Note that the max-margin metric learning is based on cosine distance, which means that the simple cosine distance is the theoretically correct choice when scoring trials in the projection space. This is a big advantage compared to PLDA that requires complex matrix computation.\nFigure 1 illustrates the concept of the max-margin metric learning for speaker recognition. The i-vectors from the same speaker are labeled as the same color and shape. In the input space, i-vectors of all the speakers are congested together. After applying the learned projection, i-vectors of the same speaker are moved closer, while those of different speakers are moved apart. Note that \u03b8ij is the margin between the speaker pair spki and spkj ."}, {"heading": "4. Experiments", "text": "We evaluate the proposed method on the SRE08 core test. This section first presents the data used and the experimental setup, and then reports the results in terms of equal error rate (EER) and DET curves."}, {"heading": "4.1. Database", "text": "The Fisher database was used to train the i-vector system. We selected 7, 196 speakers to train the i-vector model, the LDA model and the PLDA model. The same data were also used to conduct the metric learning. The NIST SRE 2008 evaluation database [19] was used as the test set. We selected 1, 997 female utterances from the core evaluation data set (short2-short3) and based on which constructed 59, 343 trials, including 12, 159 target trials and 47, 184 imposter trials."}, {"heading": "4.2. Experimental setup", "text": "The basic acoustic features involved 19-dimensional Mel frequency cepstral coefficients (MFCCs) and the log energy. This basic features were augmented by their first and second order derivatives, resulting in 60-dimensional feature vectors. The UBM involved 2, 048 Gaussian components and was trained with about 8, 000 female utterances selected from the Fisher database randomly. The dimensionality of the i-vectors was 400. The LDA model was trained with utterances of 7, 196 female speakers, again randomly selected from the Fisher database. The dimensionality of the LDA projection space was\nset to 150. For the metric learning, utterances in the Fisher database were sampled randomly to build the contrastive triples and were used to train the projection matrix."}, {"heading": "4.3. Basic results", "text": "We first present the basic results obtained with various discriminative models: raw i-vectors with cosine scoring (Cosine), LDA, PLDA, max-margin metric learning (MMML). The test is based on the NIST SRE 2008 core task, which is divided into 8 test conditions according to the channel, language and accent [19]. The EER results are reported in Table 1.\nIt can be observed that the proposed MMML significantly improves the discriminative capability of raw i-vectors, and it outperforms both LDA and PLDA in condition 1-4 (which takes the major proportion of the test data). In condition 5-8, the PLDA wins the competition. We attribute this discrepancy to the data imbalance in the development set: condition 5-8 involves complex patterns (e.g., multilingual speakers, different accents) that were not involved in the Fisher database, which is used to train the MMML model. This leads to performance degradation on these conditions with the MMML approach. For LDA and PLDA, the Gaussian assumption improves generalizablility on unseen conditions, thus resulting in superior performance than MMML, a purely discriminative approach. Nevertheless, since condition 1-4 takes a large proportion of the data, the MMML approach gets the best overall performance. As a summary, it seems that the MMML model requires more data to cover complex acoustic conditions, whereas the PLDA model is more robust to data variance, due to its prior Gaussian assumption.\nmodels are presented in Figure 2. It is clearly observed that the MMML approach outperforms the other three methods."}, {"heading": "4.4. Tandem composition", "text": "We note that both LDA and MMML learn a linear projection, though they are based on different learning criteria: LDA uses\nFisher discriminant while MMML uses max-margin. The results in Table 1 show that the max-margin criterion is clearly superior. An interesting question is whether the two criteria can be composed in a tandem way. The results are shown in Table 2, where the system \u2018LDA+MMML\u2019 involves a 400\u00d7 150 dimensional LDA projection followed by a 150 \u00d7 150 dimensional MMML projection, while the system \u2018MMML+LDA\u2019 involves a 400\u00d7150 dimensional MMML and a 150\u00d7150 dimensional LDA. From these results, we find that the last projection is the most important: if it is an MMML, the performance is always good. The \u2018MMML+LDA\u2019 system seems a bit superior than the original LDA, which perhaps because the advantage of the max-margin training has been consolidated in the process of dimension reduction, which benefits the subsequent LDA."}, {"heading": "4.5. Score fusion", "text": "The LDA/PLDA model and MMML model are complementary: LDA/PLDA are generative models and better generalizable to rare conditions where little training data are available, whereas MMML is purely discriminative and is superior for matched conditions. Combining these two types of models may offer additional gains. We experimented with a simple score fusion approach that linearly interpolates the scores from LDA/PLDA and MMML. It can be represented as \u03b1SMMML+(1\u2212\u03b1)SLDA/PLDA, where \u03b1 is the interpolation factor. The results of the score fusion are presented in Table 3, where the interpolation factor \u03b1 is chosen to be 0.2. Compared to Table 1, we observe that the fusion consistently leads to better performance than the original LDA and PLDA systems. Interestingly, the performance on condition 5-8 is also improved, although the MMML approach does not work well individually in these conditions. Note that the performance degradation on condition 1,3,4 compared to the original MMML system is simply because we use a global interpolation factor. If the factor has been tuned for each condition separately, the fusion system would obtain the best performance in all the conditions."}, {"heading": "5. Conclusions", "text": "In this paper, we proposed a max-margin metric learning approach for speaker recognition. This approach is a simple linear transform that is trained with the criterion of max-margin between true speakers and imposters based on cosine distance. The scoring is as simple as LDA, but the performance is comparable or even better than PLDA, especially with large training data on matched conditions. Future work will investigate metric learning with deep non-linear transforms, and study better\napproaches to combine PLDA and MMML."}, {"heading": "6. References", "text": "[1] P. J. Kenny, G. Boulianne, P. Ouellet, and P. Dumouchel, \u201cJoint\nfactor analysis versus eigenchannels in speaker recognition,\u201d IEEE Transactions on Audio, Speech, and Language Processing, vol. 15, pp. 1435\u20131447, 2007.\n[2] \u2014\u2014, \u201cSpeaker and session variability in GMM-based speaker verification,\u201d IEEE Transactions on Audio, Speech, and Language Processing, vol. 15, pp. 1448\u20131460, 2007.\n[3] A. O. Hatch, S. S. Kajarekar, and A. Stolcke, \u201cWithin-class covariance normalization for SVM-based speaker recognition,\u201d in INTERSPEECH, 2006.\n[4] A. Solomonoff, C. Quillen, and W. M. Campbell, \u201cChannel compensation for SVM speaker recognition,\u201d in Proc Odyssey, Speaker Language Recognition Workshop 2004, 2004, pp. 57\u201362.\n[5] N. Dehak, P. J. Kenny, R. Dehak, P. Ouellet, and P. Dumouchel, \u201cFront-end factor analysis for speaker verification,\u201d IEEE Transactions on Audio, Speech and Language Processing, vol. 19, no. 4, pp. 788\u2013798, 2011.\n[6] S. Ioffe, \u201cProbabilistic linear discriminant analysis,\u201d Computer Vision ECCV 2006, Springer Berlin Heidelberg, pp. 531\u2013542, 2006.\n[7] P. Kenny, \u201cBayesian speaker verification with heavy-tailed priors,\u201d in Odyssey\u20192010: The Speaker and Language Recognition Workshop, 2010.\n[8] D. Garcia-Romero and C. Y. Espy-Wilson, \u201cAnalysis of i-vector length normalization in speaker recognition systems,\u201d in INTERSPEECH, 2011, pp. 249\u2013252.\n[9] L. Burget, O. Plchot, S. Cumani, O. Glembek, P. Mate\u030cjka, and N. Bru\u0308mmer, \u201cDiscriminatively trained probabilistic linear discriminant analysis for speaker verification,\u201d in Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on. IEEE, 2011, pp. 4832\u20134835.\n[10] S. Cumani, N. Brummer, L. Burget, P. Laface, O. Plchot, and V. Vasilakakis, \u201cPairwise discriminative speaker verification in the-vector space,\u201d IEEE Transactions on Audio, Speech and Language Processing, vol. 21, no. 6, pp. 1217\u20131227, 2013.\n[11] I. Hirano, K. A. Lee, Z. Zhang, L. Wang, and A. Kai, \u201cSingle-sided approach to discriminative PLDA training for text-independent speaker verification without using expanded ivector,\u201d in Chinese Spoken Language Processing (ISCSLP), 2014 9th International Symposium on, Sept 2014, pp. 59\u201363.\n[12] J. Wang, D. Wang, Z. Zhu, T. F. Zheng, and F. Soong, \u201cDiscriminative scoring for speaker recognition based on i-vectors,\u201d in AsiaPacific Signal and Information Processing Association, 2014 Annual Summit and Conference (APSIPA). IEEE, 2014, pp. 1\u20135.\n[13] L. Yang, \u201cAn overview of distance metric learning,\u201d Proceedings of the Computer Vision and Pattern Recognition Conference, 2007.\n[14] M. Schultz and T. Joachims, \u201cLearning a distance metric from relative comparisons,\u201d NIPS, p. 41, 2004.\n[15] J. G. Xiao Fang, Najim Dehak, \u201cBayesian distance metric learning on i-vector for speaker verification,\u201d INTERSPEECH, 2013.\n[16] W. Ahmad, H. Karnick, , and R. M. Hegde, \u201cCosine distance metric learning for speaker verification using large margin nearest neighbor method,\u201d Advances in Multimedia Information Processing, pp. 294\u2013303, 2014.\n[17] K. Q. Weinberger, J. Blitzer, and L. K. Saul, \u201cDistance metric learning for large margin nearest neighbor classification,\u201d in Advances in neural information processing systems, 2005, pp. 1473\u2013 1480.\n[18] J. Bergstra, O. Breuleux, F. Bastien, P. Lamblin, R. Pascanu, G. Desjardins, J. Turian, D. Warde-Farley, and Y. Bengio, \u201cTheano: A CPU and GPU math compiler in python,\u201d in Proceedings of the 9th Python in Science Conference, S. van der Walt and J. Millman, Eds., 2010, pp. 3 \u2013 10.\n[19] NIST, \u201cThe NIST year 2008 speaker recognition evaluation plan,\u201d Online: http://www.itl.nist.gov/iad/mig/tests/sre/2008/ sre08 evalplan release4.pdf, 2008."}], "references": [{"title": "Joint factor analysis versus eigenchannels in speaker recognition", "author": ["P.J. Kenny", "G. Boulianne", "P. Ouellet", "P. Dumouchel"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 15, pp. 1435\u20131447, 2007.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2007}, {"title": "Speaker and session variability in GMM-based speaker verification", "author": ["\u2014\u2014"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 15, pp. 1448\u20131460, 2007.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Within-class covariance normalization for SVM-based speaker recognition", "author": ["A.O. Hatch", "S.S. Kajarekar", "A. Stolcke"], "venue": "INTERSPEECH, 2006.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2006}, {"title": "Channel compensation for SVM speaker recognition", "author": ["A. Solomonoff", "C. Quillen", "W.M. Campbell"], "venue": "Proc Odyssey, Speaker Language Recognition Workshop 2004, 2004, pp. 57\u201362.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2004}, {"title": "Front-end factor analysis for speaker verification", "author": ["N. Dehak", "P.J. Kenny", "R. Dehak", "P. Ouellet", "P. Dumouchel"], "venue": "IEEE Transactions on Audio, Speech and Language Processing, vol. 19, no. 4, pp. 788\u2013798, 2011.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Probabilistic linear discriminant analysis", "author": ["S. Ioffe"], "venue": "Computer Vision ECCV 2006, Springer Berlin Heidelberg, pp. 531\u2013542, 2006.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2006}, {"title": "Bayesian speaker verification with heavy-tailed priors", "author": ["P. Kenny"], "venue": "Odyssey\u20192010: The Speaker and Language Recognition Workshop, 2010.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Analysis of i-vector length normalization in speaker recognition systems", "author": ["D. Garcia-Romero", "C.Y. Espy-Wilson"], "venue": "INTER- SPEECH, 2011, pp. 249\u2013252.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Discriminatively trained probabilistic linear discriminant analysis for speaker verification", "author": ["L. Burget", "O. Plchot", "S. Cumani", "O. Glembek", "P. Mat\u011bjka", "N. Br\u00fcmmer"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on. IEEE, 2011, pp. 4832\u20134835.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Pairwise discriminative speaker verification in the-vector space", "author": ["S. Cumani", "N. Brummer", "L. Burget", "P. Laface", "O. Plchot", "V. Vasilakakis"], "venue": "IEEE Transactions on Audio, Speech and Language Processing, vol. 21, no. 6, pp. 1217\u20131227, 2013.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Single-sided approach to discriminative PLDA training for text-independent speaker verification without using expanded ivector", "author": ["I. Hirano", "K.A. Lee", "Z. Zhang", "L. Wang", "A. Kai"], "venue": "Chinese Spoken Language Processing (ISCSLP), 2014 9th International Symposium on, Sept 2014, pp. 59\u201363.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Discriminative scoring for speaker recognition based on i-vectors", "author": ["J. Wang", "D. Wang", "Z. Zhu", "T.F. Zheng", "F. Soong"], "venue": "Asia- Pacific Signal and Information Processing Association, 2014 Annual Summit and Conference (APSIPA). IEEE, 2014, pp. 1\u20135.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "An overview of distance metric learning", "author": ["L. Yang"], "venue": "Proceedings of the Computer Vision and Pattern Recognition Conference, 2007.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2007}, {"title": "Learning a distance metric from relative comparisons", "author": ["M. Schultz", "T. Joachims"], "venue": "NIPS, p. 41, 2004.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2004}, {"title": "Bayesian distance metric learning on i-vector for speaker verification", "author": ["J.G. Xiao Fang", "Najim Dehak"], "venue": "INTERSPEECH, 2013.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Cosine distance metric learning for speaker verification using large margin nearest neighbor method", "author": ["W. Ahmad", "H. Karnick", "R.M. Hegde"], "venue": "Advances in Multimedia Information Processing, pp. 294\u2013303, 2014.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "Distance metric learning for large margin nearest neighbor classification", "author": ["K.Q. Weinberger", "J. Blitzer", "L.K. Saul"], "venue": "Advances in neural information processing systems, 2005, pp. 1473\u2013 1480.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2005}, {"title": "Theano: A CPU and GPU math compiler in python", "author": ["J. Bergstra", "O. Breuleux", "F. Bastien", "P. Lamblin", "R. Pascanu", "G. Desjardins", "J. Turian", "D. Warde-Farley", "Y. Bengio"], "venue": "Proceedings of the 9th Python in Science Conference, S. van der Walt and J. Millman, Eds., 2010, pp. 3 \u2013 10.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "The NIST year 2008 speaker recognition evaluation plan", "author": ["NIST"], "venue": "Online: http://www.itl.nist.gov/iad/mig/tests/sre/2008/ sre08 evalplan release4.pdf, 2008.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "The i-vector model represents the state-of-the-art architecture of modern speaker recognition [1, 2].", "startOffset": 94, "endOffset": 100}, {"referenceID": 1, "context": "The i-vector model represents the state-of-the-art architecture of modern speaker recognition [1, 2].", "startOffset": 94, "endOffset": 100}, {"referenceID": 0, "context": ", JFA [1]; however, since the speakerrelated information is buried under others, raw i-vectors are not sufficiently discriminative with respect to speakers.", "startOffset": 6, "endOffset": 9}, {"referenceID": 2, "context": "In order to improve the discriminative capability of i-vectors for speaker recognition, various normalization or discrimination models have been proposed, including within-class covariance normalization (WCCN) [3], nuisance attribute projection (NAP) [4], linear discriminant analysis (LDA) [5], and its Bayesian counterpart, probabilistic linear discriminant analysis (PLDA) [6].", "startOffset": 210, "endOffset": 213}, {"referenceID": 3, "context": "In order to improve the discriminative capability of i-vectors for speaker recognition, various normalization or discrimination models have been proposed, including within-class covariance normalization (WCCN) [3], nuisance attribute projection (NAP) [4], linear discriminant analysis (LDA) [5], and its Bayesian counterpart, probabilistic linear discriminant analysis (PLDA) [6].", "startOffset": 251, "endOffset": 254}, {"referenceID": 4, "context": "In order to improve the discriminative capability of i-vectors for speaker recognition, various normalization or discrimination models have been proposed, including within-class covariance normalization (WCCN) [3], nuisance attribute projection (NAP) [4], linear discriminant analysis (LDA) [5], and its Bayesian counterpart, probabilistic linear discriminant analysis (PLDA) [6].", "startOffset": 291, "endOffset": 294}, {"referenceID": 5, "context": "In order to improve the discriminative capability of i-vectors for speaker recognition, various normalization or discrimination models have been proposed, including within-class covariance normalization (WCCN) [3], nuisance attribute projection (NAP) [4], linear discriminant analysis (LDA) [5], and its Bayesian counterpart, probabilistic linear discriminant analysis (PLDA) [6].", "startOffset": 376, "endOffset": 379}, {"referenceID": 6, "context": "For example, to go beyond the Gaussian assumption, Kenny [7] proposed a heavy-tailed PLDA which assumes a non-Gaussian prior over the speaker mean vector.", "startOffset": 57, "endOffset": 60}, {"referenceID": 7, "context": "[8] found that length normalization can compensate for the non-Gaussian effect and boost performance of Gaussian PLDA to the level of the heavy-tailed PLDA.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "Burget, Cumani and colleagues [9, 10] proposed a pair-wised discriminative model that discriminates true speakers and imposters.", "startOffset": 30, "endOffset": 37}, {"referenceID": 9, "context": "Burget, Cumani and colleagues [9, 10] proposed a pair-wised discriminative model that discriminates true speakers and imposters.", "startOffset": 30, "endOffset": 37}, {"referenceID": 9, "context": "The input features of the model are derived from the i-vector pairs according to a form derived from the PLDA score function (further generalized to any symmetric score functions in [10]), and the model is trained on i-vector pairs that have been labelled as identical or different speakers.", "startOffset": 182, "endOffset": 186}, {"referenceID": 10, "context": "To solve this problem, a partial discriminative training approach was proposed in [11], which optimizes the discriminative model on a subspace and does not require any feature expansion.", "startOffset": 82, "endOffset": 86}, {"referenceID": 11, "context": "In [12], we proposed a discriminative approach based on deep neural networks (DNN), which holds the same idea as the pair-wised training, whereas the features are defined manually.", "startOffset": 3, "endOffset": 7}, {"referenceID": 12, "context": "simplest metric learning methods which have been studied for decades in machine learning [13, 14], though it has not been extensively studied in speaker recognition.", "startOffset": 89, "endOffset": 97}, {"referenceID": 13, "context": "simplest metric learning methods which have been studied for decades in machine learning [13, 14], though it has not been extensively studied in speaker recognition.", "startOffset": 89, "endOffset": 97}, {"referenceID": 14, "context": "A representative work proposed in [15] employs neighborhood component analysis (NCA) to learn a projection matrix that minimizes the average leave-one-out k-nearest neighbor classification error.", "startOffset": 34, "endOffset": 38}, {"referenceID": 15, "context": "The cosine similarity large margin nearest neighborhood (CSLMNN) model proposed in [16] is more relevant to our proposal.", "startOffset": 83, "endOffset": 87}, {"referenceID": 16, "context": "The authors formulated the training task as a semidefinite program (SDP) [17] which moves i-vectors of the same speaker closer by maximizing the cosine distance among them, while separating i-vectors of different speakers by a large margin.", "startOffset": 73, "endOffset": 77}, {"referenceID": 12, "context": "The simplest form is to learn a linear projection M so that the distance among the projected data is more suitable for the task in hand [13].", "startOffset": 136, "endOffset": 140}, {"referenceID": 17, "context": "In this study, the Theano package [18] was used to implement the SGD training.", "startOffset": 34, "endOffset": 38}, {"referenceID": 18, "context": "The NIST SRE 2008 evaluation database [19] was used as the test set.", "startOffset": 38, "endOffset": 42}, {"referenceID": 18, "context": "The test is based on the NIST SRE 2008 core task, which is divided into 8 test conditions according to the channel, language and accent [19].", "startOffset": 136, "endOffset": 140}], "year": 2016, "abstractText": "Probabilistic linear discriminant analysis (PLDA) is a popular normalization approach for the i-vector model, and has delivered state-of-the-art performance in speaker recognition. A potential problem of the PLDA model, however, is that it essentially assumes Gaussian distributions over speaker vectors, which is not always true in practice. Additionally, the objective function is not directly related to the goal of the task, e.g., discriminating true speakers and imposters. In this paper, we propose a max-margin metric learning approach to solve the problems. It learns a linear transform with a criterion that the margin between target and imposter trials are maximized. Experiments conducted on the SRE08 core test show that compared to PLDA, the new approach can obtain comparable or even better performance, though the scoring is simply a cosine computation.", "creator": "LaTeX with hyperref package"}}}