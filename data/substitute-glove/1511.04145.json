{"id": "1511.04145", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Nov-2015", "title": "A Continuous-time Mutually-Exciting Point Process Framework for Prioritizing Events in Social Media", "abstract": "The overwhelming total many comparison more material update into mailing creation media its same kind increasingly difficult from users to allocate their change and coming topics of interest, thus almost being gave particular they for laudable news roaming. The well-being including a post immediately has accessing lacks day work complex contextual they temporal numerous especially form post. For all, the contents of took put, that sharpness several similar straight user, and the 30 included however newspaper must all come risk. So being, especially static working utilizes consisting has consider even 1880 under. unified relevant decided linemen present post prioritization problem. In this paper, tell propose a novel done for prioritizing fixed based later a feature tones multi - sphere point process. Our core is cannot means few aided testament brought sentiment features, into inflection well creating as self - excitation, friendship - electromagnetic different inward-looking nature whose creation perception. As an evaluation, believe also co-organized with is - world diction benchmark dataset crawled with Facebook. In our theorized, we demonstrate another opportunity integer exists ca to necessarily the - state - instance - now - art amazing one beyond particular analyzing, predicting, and standardizing previous. In issue of interpretability large our mechanical, because supposed that features confirming individual files current and linguistic characteristics the the summer work opportunity should clearer although timeliness large new events.", "histories": [["v1", "Fri, 13 Nov 2015 02:56:32 GMT  (848kb,D)", "http://arxiv.org/abs/1511.04145v1", null]], "reviews": [], "SUBJECTS": "cs.SI cs.LG", "authors": ["mehrdad farajtabar", "safoora yousefi", "long q tran", "le song", "hongyuan zha"], "accepted": false, "id": "1511.04145"}, "pdf": {"name": "1511.04145.pdf", "metadata": {"source": "CRF", "title": "A Continuous-time Mutually-Exciting Point Process Framework for Prioritizing Events in Social Media", "authors": ["Mehrdad Farajtabar", "Safoora Yousefi", "Long Q. Tran", "Le Song", "Hongyuan Zha"], "emails": ["mehrdad@gatech.edu,", "lsong@cc.gatech.edu,", "zha@cc.gatech.edu", "safoora.yousefi@emory.edu", "tqlong@vnu.edu.vn"], "sections": [{"heading": null, "text": "In this paper, we propose a novel approach for prioritizing posts based on a feature modulated multi-dimensional point process. Our model is able to simultaneously capture textual and sentiment features, and temporal features such as self-excitation, mutual-excitation and bursty nature of social interaction. As an evaluation, we also curated a real-world conversational benchmark dataset crawled from Facebook. In our experiments, we demonstrate that our algorithm is able to achieve the-stateof-the-art performance in terms of analyzing, predicting, and prioritizing events. In terms of interpretability of our method, we observe that features indicating individual user profile and linguistic characteristics of the events work best for prediction and prioritization of new events.\nI. INTRODUCTION\nOnline social media (OSM) and communities turn to become an inseparable part of today\u2019s lifestyle. Users of OSM usually participate via a variety of ways, including but not limited to sharing text and photos, asking questions, publishing their status, finding friends, and favoring or disfavoring contents. Many of these are organized around discussion threads which are evolving continuously. A mechanism of publishing posts and commenting on posts is an essential part of many social networking websites, forums, and groups. Users tend to pay attention to posts and comments that are from their preferred connections, or that are of topical attractiveness. However, the rate at which such discussion threads (cascades) are generated and developed is extremely high, and as a consequence, the user has to spend considerable time to find events of interest, or they may miss many appealing discussions, especially when they have many connections in the network. On the other hand, the cluttered news feed of a social network user or the cramped homepage of an online community member makes them reluctant to continue using the service.\nThe news feed prioritization problem deals with sorting the events in the a user\u2019s news-feed in a way that her stories of interest end up in the top of her newsfeed. There is a\npressing need for algorithms and tools to prioritize the news feeds of online social media and discussion groups. Despite the significance of it from the customer satisfaction point of view, few solutions have been proposed for this problem. A detailed discussion of the previous work is given in Section 4.\nThe concept of an ideally sorted newsfeed is usually subjective, and varies greatly from user to user. That\u2019s why a data-driven solution emerges for this problem. Basically, the attractiveness of a discussion thread (cascade) to a user depends on many complex social, contextual and temporal features of the cascade, such as its age, its content, and the reactions of other users to it. So far, these static and dynamic features have not been incorporated in a unified framework to tackle the news feed prioritization problem.\nIn this paper, we will address this problem using a novel framework based on a feature modulated multi-dimensional point process which can simultaneously capture both static and dynamic features of social interactions. Recently, there has been a growing interest in the application of point processes to social media analysis [11], [10], [30], [28], [9], [7]. Hawkes Process [14] is a special form of point process which exhibits mutual excitation and is appropriate for modeling user interactions in social media. In this paper we use network data, and infer social influence among users of an OSM from their generated content and interaction history. However, to learn the quadratic number of parameters of the Hawkes process accurately, a large amount of interaction data in terms of both the number of sample cascades and cascade length is needed. To overcome this problem, we propose to model social influence as a combination of features extracted from the users\u2019 behavior and published content. Furthermore, our model is also easy to interpret: we can tell to what extent each feature contributes to social influence based on the parameters of the learned model.\nLast but not least, in order to test the efficacy of the proposed method we curated a first-of-the-kind benchmark dataset of multi-user conversations in Facebook. The dataset contains about 50,000 posts and about 1,000,000 comments made by almost 25,000 users naturally partitioned into 16 active Facebook groups, making it an ideal dataset for evaluating news feed prioritization algorithms. To summarize, the contributions of this paper are three-fold:\nnoitemsep\n\u2022 Inspired by real-world dynamics of conversational activities, including their self- and mutual-excitation\nar X\niv :1\n51 1.\n04 14\n5v 1\n[ cs\n.S I]\n1 3\nN ov\n2 01\n5\nproperties as well as temporal properties such as burstiness [3], we propose a novel framework based on multi-dimensional Hawkes process for conversation modeling and prioritization.\n\u2022 As a solution to data scarcity, we parametrize social influence as a weighted sum of features, enabling easy interpretation of the model and the study of the contribution of each feature to social influence.\n\u2022 We introduce a new compelling conversation dataset to evaluate the proposed approach, which has recently been crawled from Facebook and is publicly available as a benchmark dataset.\nThe rest of the paper will first explain the intuitive dynamics of conversations in Section 2. Section 3 is the key technical section of the paper where, after building sufficient background, we present our proposed prioritization algorithm and the features designed to derive social influence. We surveyed related work in section 4. Section 5 presents the evaluation and analysis of the proposed algorithm using a realworld dataset. At last, the paper is concluded in section 6."}, {"heading": "II. A MOTIVATING EXAMPLE", "text": "Figure 1 illustrates a detailed example by which we explain our observations on social interactions. Consider Jacob\u2019s newsfeed on the OSM. His three friends, Sophia, Emma, and Mason have recently posted status updates. As a result, three threads of conversation start. Jacob may comment on these threads\nwith different likelihoods. These likelihoods evolve with time due to a quality called the time subordination of events.\nThe initial likelihood may depend on the social influence of each of the three friends on Jacob. Sophia, for instance, is Jacob\u2019s best friend, and they have recently become involved in a relationship. Therefore, the likelihood of Jacob commenting on her post is normally high, as demonstrated in part a of figure 1. We call this property the post publisher influence. On the other hand, Jacob is a fan of Football, therefore, Emma\u2019s post is on a popular topic -Football- so it excites Jacob and increases his likelihood of commenting on her post to a value higher than it would be with regard to his relationship with Emma only. As you have noticed, the content of the post effectively induces Jacob to respond to it. We refer to this effect as post content influence. These two sources of influence are combined to form the overall post influence.\nPost influence decay is another important factor determining likelihood. As a post ages, it is drawn out of focus by the generation of new events. Jacob\u2019s feed is accumulated with recent scenarios that distract him from Sofia\u2019s post.\nLet us now track Sophia\u2019s post. The likelihood that Jacob pays attention to Sofia\u2019s post keeps decreasing until Ethan comments on it and brings it to the top of Jacob\u2019s news feed as a recent event. This is basically what is known as the mutualexcitation of events in OSM. Now, let\u2019s say Jacob finally comments on Sophia\u2019s post. Interestingly, after he comments on it, his likelihood of returning to Sophia\u2019s post and recontributing increases. This property is a special case of the\nprevious one, and we will refer to it as the self-excitation property.\nNow, let\u2019s consider Mason\u2019s post. It seems that neither Mason has much influence on Jacob nor does his post\u2019s content attract Jacob. Therefore, the likelihood starts with a relatively low value. The post remains idle for a while and the likelihood attenuates, until Mary and Isabella comment on it, and, loosely speaking, awaken the post. Once more, the post becomes idle for a relatively long time until when Emily comments on it. Surprisingly, the post becomes very attractive afterwards, and three other people comment on it. Mutualexcitation accumulates likelihood and makes this post a hot one. This scenario reflects the bursty nature of social events[3].\nThere still remains an unexplained point. Before Emily comments on Mason\u2019s post, she comments on Emma\u2019s post. However, it does not attract Jacob\u2019s attention very much. Therefore, some other factor besides influence is playing a role: the content of the comment. It can be seen that the comment content influence is another factor driving behavior in social networks. On the other hand, Isabella usually has little influence on Jacob since Jacob does not like her very much, irrespective of what she expresses in her comment. This final example indicates that comment publisher influence is another component of the comment influence.\nSimilar to posts, comments normally exhibit a comment influence decay due to the same reasons. As time passes, more attractive stories replace them. However, as it is apparent, the influence of posts will last longer. In other words, the influence decay happens faster for comments than for posts. Different rates of decay is due to the fact that posts are generally more observable and easier to follow.\nWe end our observation at some point in time. Jacob may or may not comment on Emma\u2019s and/or Mason\u2019s post at a later time. To put it in a nutshell, conversations exhibit the following properties which we want to capture in a unified model:\nTime Subordination: The likelihood of commenting evolves with time.\nPost Publisher Influence: The likelihood of commenting is proportional to the social influence of the publisher on the subject user.\nPost Content Influence: The likelihood of commenting is related to content of the post.\nPost Influence Decay: As time passes, the probability of commenting on the post decreases.\nComment Publisher Influence: It reflects the intrinsic influence of the commenter on the subject user\nComment Content Influence: The content of the comment is an important factor triggering other events.\nComment Influence Decay: As time goes on, the effect of the comment disappears gradually.\nDifferent Rate of Decay: Comment and post influences decay at different rates.\nMutual-excitation: When a third user comments on the post, the likelihood of the subject user commenting increases.\nSelf-excitation: When one comments on the post there is a relatively higher chance that he returns to the post and comment again.\nBursty Effect: The comments on a post exhibit a bursty nature; after a post is made, it may receive multiple comments, then become dormant for a relatively lone time after which it comes to life again by receiving new comments.\nReturning to our problem of interest, prioritization, we can sort Jacob\u2019s news feed based on his likelihood of commenting on posts. In our synthetic example, suppose we are at time t when Jacob refreshes his page (we have not seen the events after time t yet). Based on our notion of influence, Jacob is most likely to comment on Emma\u2019s post. The next attractive post to him is Sophia\u2019s post, and Mason\u2019s comes last. Therefore, we had better show the stories to Jacob in the mentioned order. As time goes on, new events are generated, and the likelihoods change. For example, later on, we see that after Ethan\u2019s comment on Sohpia\u2019s post, the likelihood of Jacob commenting on her post increases, and if we get Jacob\u2019s feed sorted according to the likelihood, he will hit his topic of interest at the top of his news feed. In the subsequent sections we elaborate on a model to capture these properties and then prioritize events based on the intensity."}, {"heading": "III. BACKGROUNDS ON TEMPORAL POINT PROCESSES", "text": "Our framework elaborates upon the theory of temporal point processes and event history analysis. Time is an important factor in the study of events in social networks. One might argue that any well-developed statistical method such as linear or ridge regression, probabilistic models, etc. can be used with waiting times of events to conduct an analysis of event dynamics on a sample of users. The reason these standard statistical methods do not suit time-dependent events is a fundamental problem one almost always meets when dealing with such problems: when the study of sample of users ends and the analysis begins, one is left with a set of both complete and incomplete observations. The event in question has happened for a subset of users and not for the rest, but one does not have the knowledge of whether in future the event is going to happen to the rest. [1].\nTemporal point processes model point patterns with stochastic processes and are suitable for dealing with incomplete observations [1], [6]. The term point refers to the conceptualization of an event as instantaneous and representable as a point on the time line. A (1-dimensional) point process is simply a list of points in time {t1, t2, ..., tN} at which events occur. Equivalently, a point process can be defined by the corresponding counting process denoted by N(t)-the number of occurrences up to time t. Conditional intensity function is the most convenient and intuitive way to characterize a point process. Defining the history of events up to but not including t as Ht, the intensity function is\n\u03bb(t|Ht) = lim \u2206t\u21920 E[N(t+ \u2206t)\u2212N(t)|Ht] \u2206t\n(1)\nAn intuitive interpretation of conditional intensity function is: \u03bb(t|Ht) \u2206t is the conditional probability of observing an event in a small window [t, t+ \u2206t) given the history Ht, i.e., \u03bb(t|Ht) \u2206t := P {event in [t, t+ dt)|Ht} = E[dN(t)|H(t)],\n(2)\nwhere dN(t) = N(t+ \u2206t)\u2212N(t) and one typically assumes that only one event can happen in a small window of size \u2206t, i.e., dN(t) \u2208 {0, 1}. From now on, for the sake of convenience, we will not explicitly denote the dependence on past history, Ht. Furthermore, we can express the loglikelihood of a list of events {t1, t2, . . . , tn} in an observation window [0, T ) as\nL = n\u2211 i=1 log \u03bb(ti)\u2212 \u222b T 0 \u03bb(\u03c4) d\u03c4, (3)\nThis simple log-likelihood will later enable us to learn the parameters of our model from observed data.\nThe functional form of the intensity \u03bb(t) is often designed to capture the phenomena of interests. For instance, in a homogeneous Poisson process, the intensity is assumed to be independent of the history T and constant over time, i.e., \u03bb(t) = \u03bb0 > 0. In an inhomogeneous Poisson process, the intensity is also assumed to be independent of the history T but it can be a function varying over time, i.e., \u03bb(t) = g(t) > 0.\nA one-dimensional Hawkes process [14] is:\n\u03bb(t) = \u00b5(t) + \u222b t \u2212\u221e \u03ba(t\u2212 s)dN(s) (4)\nHere, \u00b5(t) is the base intensity, and \u03ba is the decaying kernel. The process is well-known for its self-exciting nature; each time a new event happens, the intensity grows by \u03ba(0). Then, as time passes, it decreases exponentially to \u00b5(t). Hawkes process also exhibits a bursty nature, hence it is also referred to as time-cluster process [15].\nIn U -dimensional Hawkes process, there are U processes that are coupled with each other, and the interactions between processes are explicitly modeled. Formally, {Nu(t)|u = 1, . . . , U} is a U -dimensional Hawkes process where the\nconditional intensity for the u-th dimension is given by:\n\u03bbu(t) = \u00b5u(t) + U\u2211 u\u2032=1 \u222b t \u2212\u221e \u03bauu\u2032(t\u2212 s)dNu\u2032(s) (5)\nwhere the summation captures the mutual excitation of the processes; i.e., the effect of the occurrence of events in one dimension on the likelihood of future events in all dimensions."}, {"heading": "IV. PROPOSED METHOD", "text": "In this section we formally define the newsfeed prioritization problem, and present our point process model along with the feature that constitute the parameters of our model.\nHere, post and comment can be regarded as an abstraction of any activity in social networks such as likes, comments, photo or status updates, etc. They are intended to show the interaction between activities. One can easily extend the model to capture different types of actions in social networks."}, {"heading": "A. Problem Definition", "text": "In the newsfeed prioritization problem, we are given C cascades and intend to sort them in order to show them on user u\u2019s news feed in a way that more attractive cascades to the user end up at the top of his newsfeed. Each cascade c is represented as a set of events c = {e0, e1, . . . , enc} where e0 indicates the post that initiates the cascade, and e1, e2, . . . , enc are the nc comments this post has received so far. Each event (either post or comment) ei is represented as a triple ei = (ti, pi, di) where ti, pi, and di represent the time of the event, its publisher, and its content, respectively.\nAs explained in section III, the conditional intensity function 5 can be interpreted as the expected rate of event occurrence. A process with higher intensity at time t is more likely to bring about an event than a process with less intensity. Given that no two events occur at the exact same time, the intensity function will be proportional to the probability of the event occurrence. Therefore we use equation 5 as a measure\nof user\u2019s contribution likelihood to a cascade. This explains why we propose to personalize users newsfeeds according to the value of the intensity function."}, {"heading": "B. Point Process Model", "text": "In this section, we propose a point process model designed to capture the properties we listed in section II. Our goal is to find the post and comment influence parameters, and use them to find the likelihood of target user u\u2019s contribution to each of the C posts, and finally, sort u\u2019s newsfeed.\nThe likelihood user u comments on cascade c is given by:\n\u03bbuc(t) = \u00b5ue0 exp(\u2212\u03c9\u00b5(t\u2212 t0))\ufe38 \ufe37\ufe37 \ufe38 post influence + \u2211 ti<t\nauei exp(\u2212\u03c9a(t\u2212 ti))\ufe38 \ufe37\ufe37 \ufe38 comment influence\nwhere \u00b5ue0 is the initial influence of post e0 on user u, and auei is the initial influence of comment ei on user u for i \u2265 1. As time goes on, these influences decrease exponentially with rates \u03c9\u00b5 and \u03c9a, respectively.\nAs a reminder of our discussion in section II, the influence of an event on user u is a combination of the influence of the event publisher and the influence of the event content influence. As a result, we rewrite post and comment influences as follows:\n\u00b5ue0 = \u00b5up0 + \u00b5ud0 (6) auei = aupi + audi (7)\nwhere the subscript upi indicates the influence of the event publisher pi on user u, and udi indicates the attractiveness of the event content di over u. Table I provides a summery of notations used in this subsection. Moreover, Hawkes process, as a temporal point process, naturally respects the rest of the properties listed in section II, namely time subordination, self excitation, mutual excitation, and bursty nature of events.\nUp to now, the number of parameters to be learned is at least O(U2). Given that the fact that there is not always as much training data available as required, it is practically impossible to learn the model effectively. To address this problem, we introduce a set of features to derive the influence between users via a weighted sum of them. These features include the social profiles of both sides of an event, their interaction history, and linguistic and psychological features of the content of the event. The following is the feature-based representation of the model parameters:\n\u00b5up0 = \u03b1 >Fup0 \u00b5ud0 = \u03b2>Fd0 (8) aupi = \u03b3 >Fupi audi = \u03c3>Fdi (9)\nHere, Fup indicates the features extracted from the interaction history of u and p, and Fd indicates the content features. Vectors \u03b1, \u03b2, \u03b3, and \u03c3 are the feature coefficients, or weights,\nand are the only parameters to be learned. They act as a measure of the importance of each feature in building up the likelihood. As you see, our learning space is reduced to the number of feature coefficients, O(K) where K is usually much smaller than U . In the experiments section we show how this meaningful reduction of the parameters leads to better results."}, {"heading": "C. Efficient Parameter Estimation", "text": "Assuming we have previously observed C cascades first we need to learn the parameters and then use them in prioritization task. Without loss of generality we assume all posts arrive at time t0 = 0 to write a simpler form for likelihood function. Given the parameters, the cascades are independent, therefore, the log-likelihood can be written as L = \u2211C c=1 Lc, where,\nLc = nc\u2211 i=1 log \u03bbpic(ti)\u2212 U\u2211 u=1 \u222b T 0 \u03bbuc(t)dt\n= nc\u2211 i=1 log ( (\u03b1>Fpip0 + \u03b2>Fd0)e\u2212\u03c9\u00b5(ti\u2212t0)\n+ \u2211 j<i (\u03b3>Fpipj + \u03c3>Fdj )e\u2212\u03c9a(ti\u2212tj) )\n\u2212 U\u2211 u=1 (\u03b1>Fpip0 + \u03b2>Fd0)(1\u2212 e\u2212\u03c9\u00b5(ti\u2212t0))/\u03c9\u00b5\n\u2212 U\u2211 u=1 nc\u2211 j=1 (\u03b3>Fupj + \u03c3>Fdj )(1\u2212 e\u2212\u03c9a(ti\u2212tj))/\u03c9a\nPerhaps surprisingly, the log-likelihood is convex with respect to parameters \u03b1, \u03b2, \u03b3, and \u03c3, therefore these parameters can be estimated using any of the well-developed convex optimization method, maximizing the log-likelihood under the constraint of being element-wise positive.\nTo preserve convexity while prohibiting over-fitting, we use l1 norm to regularize the model.\nmin \u03b1,\u03b2,\u03b3,\u03c3\n\u2212L+ \u03b6\u03b1||\u03b1||1 + \u03b6\u03b2 ||\u03b2||1 + \u03b6\u03b3 ||\u03b3||1 + \u03b6\u03c3||\u03c3||1 (10)\nsubject to \u03b1u \u2265 0, \u03b2u \u2265 0, \u03b3u \u2265 0, and \u03c3u \u2265 0 for all u where \u03b6\u03b1, \u03b6\u03b2 , \u03b6\u03b3 , \u03b6\u03c3 are regularization parameters."}, {"heading": "D. Prioritization", "text": "Having learned the model parameters, we can now sort the events on the news feed of a target user u based on \u03bbuc(t) for all cascades c at every time t. According to equation 11 intensity is the average rate of commenting or equivalently proportional to the probability of commenting given the history. i.e.,\n\u03bb(t) \u221d P {event in [t, t+ dt)|Ht} (11)\nand that\u2019s why it is very suitable candidate to serve as a prioritization measure.\nIt is notable that we do not need to compute everything from scratch when a new event occurs. The summation on previous events can be updated on the fly from the quantity at the previous time thanks to ideas borrowed from dynamic programming. To elaborate, let us assume we have computed \u03bbuc(t) at some time t1 as the summation of two terms, i.e., \u03bbuc(t) = A(t) + B(t) where A(t) = \u00b5ue0 exp(\u2212\u03c9\u00b5(t \u2212 t0))\nand B(t) = \u2211 ti<t\nauei exp(\u2212\u03c9a(t \u2212 ti)). It can be easily seen that the intensity at some time t2 > t1 can be easily updated by setting A(t2) = A(t1)e\u2212\u03c9\u00b5(t2\u2212t1), and B(t2) = B(t1)e \u2212\u03c9a(t2\u2212t1)."}, {"heading": "E. Features", "text": "The proposed framework is general enough to work with any feature extracted from the users (or even without any feature in its simplest form), such as their profile information and interaction history. In this subsection, we briefly introduce the features we use to parametrize the influence. Remember we have different influence parameters for posts and comments, namely, publisher influence and content influence. We believe that the social influence of the publisher on the user is a function of the social status of both, as well as their history of interactions. Therefore, Character-based influence has to do with characteristics of the publisher and the user, for example, their popularity, knowledge, or level of activity; On the other hand, relationship-based influence is a measure of the history of interactions between the publisher and the user, such as shared interests and activities. Table II demonstrates the features we extracted for each of these two elements of influence. Note that we extract Relationship based features for the publisher and the users separately to respect the directed nature of social interactions.\nSimilarly, we divide the content influence into two elements: linguistic features, and emotional/psychological characteristics extracted from the content.\nWe make use of Linguistic Inquiry and Word Count (LIWC) to extract content features [21]. LIWC is a text analysis software that calculates the degree any text comprises different categories of words, and is used in several prior studies in conversation analysis [4], [16].\nAs given in Table 2, to parametrize the influence of the publisher on the user in a post/comment, we use 35 features categorized into the following sets:\nChrPub: Character-based features of publisher\nChrUser: Character-based features of user\nRltnPub: Relationship-based features of publisher\nRltnUser: Relationship-based features of user\nLng: Linguistic features of the post/comment\nPsy: Psychological features of the post/comment"}, {"heading": "V. RELATED WORKS", "text": "The problem of personalizing news feeds in online social media has been recently addressed in several ways. The approaches taken to this problem can be categorized by the ranking criteria they use:\nGlobal criteria (Publisher authority and global content attractiveness): Gabrilovich et al. [13] propose a framework for comparing text documents using language models, and sort users\u2019 newsfeed based on the novelty and relevance of the content items. Shmueli et al. [24] proposed a content-based collaborative filtering method based on co-commenting and textual tags to predict which stories a particular user is most likely to comment on. Yi et al. [29] integrate dwell times of\nusers on content items into collaborative filtering and machine learning-to-rank models.\nRelationship-based criteria (User-to-user relationship and content relevance): Authors in [2] pose the re-entry prediction problem for the first time and extract several social, temporal, and textual features of the post, poster, comments and commenter to address it. Authors in [5] also utilize a comprehensive collection of social, textual and content relevance features along with publisher authority in a collaborative filtering approach to Tweet recommendation. In [26], a similar set of features is used to filter tweets based on users\u2019 retweet likelihood. In [12], the authors measure the significance of a similar set of features in ranking feeds of IBM\u2019s SocialBlue and show that browsing history is a more accurate predictor of content relevance than communication history.\nPhelan et al.[23] use Tweets to propose a content-based recommendation system to rank news stories in RSS feeds by calculating TF-IDF scores to measure the co-occurrence of popular terms within the user\u2019s RSS and Twitter feeds.\nInspired by physical interactions, authors in [4] study the factors affecting user participation in the context of Twitter chats, however, their work is limited to the re-entry problem.\nOur work is similar to the above mentioned methods in that it also seeks to rank a set of content items based on a personalized measure of relevance. But this paper differs from this direction of related work in that these methods disregards many unique properties of social media such as publisher influence and self- and mutual-excitation, as well as the bursty behavior of individuals and the evolution of dynamics with time. We use a comprehensive set of global and user-specific features to model conversation dynamic and predict events.\nTo the best of out knowledge, no recent work has employed temporal point processes (or Hawkes Process) to model conver-\nsation dynamics on social networks. Our model captures self and mutual excitation of user behavior to predict events based on user profile, interaction history, and content popularity.\nThe use of Hawkes process has been reported in the study of the association of temporal events in various fields, for example, financial events [8], seismic events [19], crimes [25], civilian deaths in conflicts [17], and recently, causal militant conflict events [18], social media [30], [28], [9], and network evolution modeling [11]. Authors in [27] utilize inhomogeneous poisson processes to deal with the item adoption problem. Zhou et al. [30], exploit multi-dimensional Hawkes process with low-rank and sparse assumption to accurately infer the influence network of WWW merely via the timestamps of new links between websites. In [9], authors proposed a novel framework based on Hawkes process to capture the dynamics of product adoption in social networks. They introduced a variety of activity shaping problems that which are convex and scalable and can be used to actively manage social networks. Exact/approximate (non) parametric estimation algorithms for Hawkes process are also proposed by various authors [20], [30], [31]. These methods suffer from quadratic number of parameters and an inherent batch learning procedure."}, {"heading": "VI. EXPERIMENTS", "text": ""}, {"heading": "A. Dataset", "text": "We examine our model on discussion cascades crawled from Facebook groups. Facebook groups are online communities of people who share interests or concerns, such as coworkers, classmates, celebrity fans, parents, etc. People join Facebook groups to share updates, photos and documents and receive feedback on them. With hundreds of millions of online groups each with tens to thousands of members discussing topics ranging from pet care to philosophy, Facebook provides us with abundant ongoing conversations among a known set of people to alleviate the study of conversation dynamics in online social media. We have collected a corpus of around 50,000 conversations recently drawn from Facebook, with over 1 million comments involving about 25,000 people. To our knowledge, this is the only corpus of Facebook groups conversation data available for study so far. The groups selected for this study were 16 open groups (groups whose posts can be viewed by non-members) chosen to cover a range of topics and populations presented in Table III. From each group, we collected as many conversations from the group\u2019s newsfeed as possible for our headless browser. The resulting corpus consists of 1078238 comments, naturally partitioned into 58772 posts among 22628 users.\nIt is notable that there is a minor bias in our dataset. The training data is collected from Facebook groups feeds. Since Facebook applies its own ranking of events in group news feeds, the collected data is biased toward attractive events. However, we argue that this bias has no significance in model evaluation, as both the training and test datasets are affected by it. A model learned from a set of users in one OSM, say Facebook, may not work properly on test data from the same set of users on another OSM, say Twitter. This is minor problem as the models are usually trained and utilized on the same environment. A discussion of the effect of this bias on the descriptive power of our model is given in section VI-C."}, {"heading": "B. Prioritization", "text": "In this section, we test the proposed method and compare its effectiveness to a number of baselines each having a special property that makes them interesting to discuss.\n1) Experimental Setup: Pre-processing and initialization For each group, cascades are sorted according to their initiation times. Depending on the size of the group C, a fraction of cascades is used as training data. Test posts are then chosen from the remaining posts whose participants are among the participants in the training data. Table IV gives an overview of the data available after this preprocessing step. Time is measured in minutes. We set \u03c9\u00b5 = 0.001 and \u03c9a = 0.01 to reflect the decay rates of the post and comment influence, respectively. This choice of decay rates means that a post/comment will loose 65 % of their influence after 1000/100 minutes and is estimated according to the conversation progress rate of the group at study. The regularization parameter \u03b1 is set by cross validation to the best performance. The features are extracted from training data and are normalized to lie within [0, 1].\nEvaluation Metric. After we train our model on training data, we proceed with the test data one comment at a time, and sort the posts for every user using the algorithms in study. We assign a rank to the comment at hand, with regard to the rank of the post it concerns. For example, if the newly arrived comment concerns the top post in our sorted set, we assign 0 to the comment. If the comment concerns the second top post, we assign 1, and so on. Finally, we compute the average rank over all incoming comments. This equips us with a measure called AveRank of the algorithm, that, intuitively, is the average number of posts each user is bound to scroll down to find their topic of interest when their newsfeed is sorted according to the algorithm is study.\nNote that AveRank is a means of intra-group performance analysis. However, since some groups are more active and the user faces many more candidates when deciding to contribute to threads in these groups than others, it is essential to define a measure that enables us to conduct inter-group analysis. We introduce the normalized average rank:\nNAveRank = AveRank/Activityg (12)\nwhere Activityg of group g is its number of active cascades averaged over time. We define active cascades as those that received their last comment no more than 12 hours ago.\nMethods. We compare the proposed method to the following four methods:\nReverse Chronological baseline (RCHR). This method sorts cascades according to their most recent timestamp, whether it is the initiation timestamp or the last comment timestamp). There are still many online social networks and communities that use this baseline criterion to sort news feeds.\nNearest Neighbor (NN). In this baseline method, for each user, we compute the moving average of feature vectors of their past comments. We then rank the given posts according to their distances from the moving average. This method uses all 35 features.\nCox process (COX). In this method, we implement a Cox process in which the likelihoods of future comments on each cascade are used to rank the user\u2019s interests in the thread. The likelihood of an incoming comment by user u on cascade c is: \u03bbuc(t) = exp{\u03c1TFd(t)}. The weight vector \u03c1 can be estimated via the maximization of the Partial Likelihood [22] using any convex optimization method. Since character and relationship based features are not usable with Cox process we used linguistic and psychological feature sets to come up with two algorithms; COX-LNG and COX-PSY. This method represents temporal point processes lacking mutual excitation.\nHawkes (HWK). This method is the basic Hawkes process before incorporating features. The likelihood that cascade c receives a comment from user u is based only on past events, and the social influence of the post publisher and commenters on u, and is given by:\n\u03bbu(t) = \u00b5upg(t\u2212 t0) + \u2211\nt0<ti<t\naupig(t\u2212 ti),\nwhere \u00b5up is the influence of the post publisher p on u, and aupi is the influence of the commenter pi on u. The parameters \u00b5 and a can be estimated efficiently using EM [30]. This algorithm is implemented to show how parameterizing the influence benefits in cases of data scarcity.\nFeature-based Hawkes (FHWK). This is the method proposed in the current paper. We have utilized five different feature sets to introduce five versions to the method: character-based (ChrPub and ChrUser features), relationship-based (RltnPub and RltnUser features), linguistic (Lng features), and psychological (Psy features) versions, respectively referred to as HWK-CHR, HWK-RLTN, HWK-LNG, and HWK-PSY. We introduce the fifth version by utilizing all the four feature sets HWK-ALL.\n2) Analysis: Let\u2019s start with a visual analysis of the proposed method. Figure 3 shows the 35 learned parameters for all the datasets via HWK-ALL. One can evaluate the significance of each of the 35 features in comprising the influence using this figure. From 3, the following observations can be made:\n- The columns are mostly sparse as imposed by regularization. About half of the elements are close to 0.\n- A great weight is concentrated on the relationshipbased features, as in accordance with our expectation. These features correlate very well with the observed interactions in the training data. However, as we will see later, they do not guarantee high predictive ability.\n- There is a notable emphasis on the Publisher parameters compared to User parameters, revealing that the characteristics of the publisher are more influential than those of the user. In contrast, for relationshipbased features, it seems that both the publisher and the user contribute equally in the influence, suggesting a reciprocity in the group\u2019s interactions.\n- It seems that different groups share the same dynamics. Although they have different weights for some of the features, the majority of the features play a similar role in all groups.\n- The post and comment parameters within individual groups do not take on the same values, but are highly correlated. It implies that the same features derive post and comment influences, but not with the same strength, which is merely a difference in scale.\n- In small and low activity groups, influence is more dependent on characteristic features of publisher and user than on the rest of the features.\nFigure 4 demonstrates the directed pairwise influence among users in one of the groups. The influence is obtained by the dot product of the features and the corresponding coefficients learned by HWK-ALL. For clarity, we included the first 35 users only. Note the following observations:\n- Influence matrix is sparse as in accordance with our intuition of real-world networks, where each individual is connected to and influenced by a limited number of people only.\n- A correlation between post influence and comment influence is observed. If p\u2019s posts are attractive to u, so are her comments.\n- The influence of user 10 on others (column) and the influence she receives from others (row) are both remarkable. Examining the dataset reveals that she is a super-active user but she also is a late adopter: she\nusually comments after a post receives a sufficient number of comments. This explains why her input influence (row) is greater than her output influence (column).\n- Diagonal values of the matrix seem to mostly take on large values. These parameters reflect the selfexcitation of individual activities. If a person comments on a post, it is likely that they return to the post to recontribute.\n- Off-diagonal values such as the square in row 5 and column 10 in both matrices, indicate notable mutual excitation."}, {"heading": "C. Prediction", "text": "We continue by quantitatively evaluating the proposed method. Table IV shows NAveRank values obtained using the algorithms listed in subsection 5.2.1 on all 16 groups. To give a better insight into our results, the performance of the algorithms is also represented graphically in Figure 5 using AveRank measure because of its intuitive comprehensibility.\nNote in Table IV and Figure 5 that relationship-based features do not yield good prediction results while being assigned great weights in the model. We think that this is due to the fact that data limitation is part of the problem we are dealing with. To extract descriptive relationship-based features, we need sufficient interaction data. With little data, learning is prone to overfitting and yields poor results on unseen data. On the other hand, our training data is collected from Facebook group newsfeeds, meaning it is biased toward containing cascades with exaggerated cascade re-entry and relationship-based activity. We attribute this to the fact that Facebook sorts each user\u2019s newsfeed based on interaction history, and also highly ranks cascades in which the user has previously participated. As a result, our learning algorithm overfits by assigning high values to relationship-based features, features that do not contribute much to the prediction task.\nOn the contrary, character-based features seem to lead to the best results. Linguistic features are also successful, however, when combined with the rest of the features in HWK-ALL,\nthe result deteriorates due to the overlap of correlated features. When two features are correlated, then an increase (or decrease) in the objective function can be attributed to any of them, introducing noise to the model. Another factor contributing to this deterioration is addition of relationshipbased features causes overfitting.\nIn most cases, Hawkes-based algorithms, are superior to all others, and where this is not the case, the difference is very small. We attribute this success to the excitation properties of Hawkes process, and its temporal and bursty nature along with the parameterization of likelihood into features. Lets examine the behavior of the featureless Hawkes algorithm, HWK. In some cases it demonstrates superior performance (groups 15 and 16), and in others quite the contrary (groups 7, 8, 11, 12). Looking into the number of training posts and users of these cases reveals a very interesting result. Superior results are obtained in groups that contain a large number of cascades while maintaining a relatively small number of users. In contrast, inferior performance is obtained on groups with so many users that learning O(U2) becomes too much.\nNormalized average ranking enables further analysis to proceed from user-level to group-level properties. Consider, for example, the last column of the table IV in which results of HWK-ALL is presented. Some groups have higher NAveRank compared to others. The first issue is that these groups are less predictable. A subjective analysis of these groups reveals some\nTABLE IV: Prioritization results for all groups and algorithms in terms of normalized average rank\nID # train posts # test posts # users RCHR NN COX-LNG COX-PSY HWK HWK-CHR HWK-RLTN HWK-LNG HWK-PSY HWK-ALL\n1 500 675 243 7.19 3.35 3.68 3.53 3.12 0.90 1.20 1.14 1.54 1.05 2 600 460 872 1.16 0.82 1.99 2.18 5.00 0.29 0.51 0.30 0.36 0.40 3 500 500 392 3.98 2.63 2.95 4.08 4.60 0.88 1.51 1.29 1.21 1.20 4 200 52 186 0.51 0.87 5.07 5.25 3.67 0.45 0.57 0.56 0.56 0.51 5 1000 1000 514 0.22 0.14 0.30 0.46 0.21 0.14 0.19 0.29 0.10 0.20 6 500 337 558 1.44 0.36 4.66 7.54 2.47 0.38 0.39 0.50 0.42 0.38 7 800 1000 950 4.83 4.86 5.31 6.23 13.09 0.52 0.60 0.53 0.62 0.60 8 400 73 719 2.14 2.40 8.86 9.97 56.04 0.91 0.92 0.92 0.97 0.91 9 200 110 64 1.34 0.63 3.06 2.48 2.18 0.62 0.64 0.61 0.62 0.61 10 600 223 979 1.23 1.77 5.50 6.43 9.20 0.34 0.48 0.38 0.45 0.39 11 2000 1950 1791 7.84 5.87 3.88 5.55 15.60 0.56 0.58 0.55 0.59 0.54 12 600 600 764 1.19 0.34 0.35 0.24 3.01 0.37 0.85 0.30 0.30 0.75 13 70 75 213 0.90 1.71 12.56 11.71 11.68 0.50 0.56 0.56 0.53 0.50 14 1000 650 481 2.49 1.15 3.58 3.64 1.16 0.38 0.45 0.46 0.62 0.44 15 2000 1000 577 3.79 0.95 1.95 2.40 0.44 0.62 0.71 0.68 0.61 0.82 16 2000 2000 189 4.75 0.15 0.35 0.29 0.13 0.52 0.75 0.55 0.65 0.74 avg 3.71 2.16 4.46 4.93 8.61 0.63 0.83 0.74 0.82 0.75\nfundamental differences in them.\nWe roughly divide the groups into two contrasting categories: In the first category of groups, socially-oriented conversations take place in which participants know each other to some extent and this acquaintance influences their probability of engaging in a conversation. Groups 2, 4, and 11 fall in this category. The first two are groups of residents of specific areas, and the third is an informal community of bowling players.\nThe second category consists of groups oriented around specific topics of controversy or specialized discussions. In these groups, whether a user contributes to a thread depends mostly on the topic of the thread, not on the strength of his link with the poster. Participants mostly engage in one-time contributions to threads, although prolonged conversations may also take place. Groups 1 and 8, specialized communities of horse trainers and gamers, respectively, are examples of such groups. We have noticed that the predictive power of the proposed algorithm is higher when dealing with the first category. As seen in the last column of table IV, the normalized average rank of the first category of groups is lower than that of the second category."}, {"heading": "VII. DISCUSSION", "text": "Our model can easily be extended to capture different rates of decay for users or groups. Furthermore, we can utilize any engineered feature set or even no feature to learn the Hawkes model. It\u2019s notable that post and comment in this paper can be regarded as an abstraction of any activity in social networks such as likes, comments, photo, status sharing, etc. One can easily generalize the model to capture different types of actions in social networks and model their interaction via coupling their intensities. In our experiments we merely used the usual notion of posts and comments to establish the framework and show its effectiveness in conversation dynamic analysis.\nAs future work, we would like to explore other methods to tackle limited data , such as incorporating prior knowledge and hierarchical parameter learning. Learning other parameters of the Hawkes process such as \u03c9, and, more generally, learning the decay kernel is an interesting direction for future research."}], "references": [{"title": "Survival and event history analysis: a process point of view", "author": ["O. Aalen", "O. Borgan", "H. Gjessing"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2008}, {"title": "Characterizing and curating conversation threads: expansion, focus, volume, re-entry", "author": ["L. Backstrom", "J. Kleinberg", "L. Lee", "C. Danescu-Niculescu-Mizil"], "venue": "In Proceedings of the sixth ACM international conference on Web search and data mining,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "The origin of bursts and heavy tails in human", "author": ["A.-L. Barabasi"], "venue": "dynamics. Nature,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2005}, {"title": "On participation in group chats on twitter", "author": ["C. Budak", "R. Agrawal"], "venue": "In Proceedings of the 22nd international conference on World Wide Web,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Collaborative personalized tweet recommendation", "author": ["K. Chen", "T. Chen", "G. Zheng", "O. Jin", "E. Yao", "Y. Yu"], "venue": "In Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "An Introduction to the Theory of Point Processes: Volume I: Elementary Theory and Methods", "author": ["D. Daley", "D. Vere-Jones"], "venue": "Probability and Its Applications. Springer,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2002}, {"title": "Dirichlethawkes processes with applications to clustering continuous-time document streams", "author": ["N. Du", "M. Farajtabar", "A. Ahmed", "A.J. Smola", "L. Song"], "venue": "In KDD. ACM,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Multivariate hawkes processes: an application to financial data", "author": ["P. Embrechts", "T. Liniger", "L. Lin"], "venue": "Journal of Applied Probability,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Shaping social activity by incentivizing users", "author": ["M. Farajtabar", "N. Du", "M. Gomez-Rodriguez", "I. Valera", "H. Zha", "L. Song"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Back to the past: Source identification in diffusion networks from partially observed cascades", "author": ["M. Farajtabar", "M. Gomez-Rodriguez", "N. Du", "M. Zamani", "H. Zha", "L. Song"], "venue": "In Proceedings of the 18th International Conference on Artificial Intelligence and Statistics (AISTATS),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "Coevolve: A joint point process model for information diffusion and network co-evolution", "author": ["M. Farajtabar", "Y. Wang", "M. Gomez-Rodriguez", "S. Li", "H. Zha", "L. Song"], "venue": "In NIPS \u201915: Advances in Neural Information Processing Systems,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Social networking feeds: recommending items of interest", "author": ["J. Freyne", "S. Berkovsky", "E.M. Daly", "W. Geyer"], "venue": "In Proceedings of the fourth ACM conference on Recommender systems,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2010}, {"title": "Newsjunkie: providing personalized newsfeeds via analysis of information novelty", "author": ["E. Gabrilovich", "S. Dumais", "E. Horvitz"], "venue": "In Proceedings of the 13th international conference on World Wide Web,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2004}, {"title": "Spectra of some self-exciting and mutually exciting point processes", "author": ["A.G. Hawkes"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1971}, {"title": "A cluster process representation of a self-exciting process", "author": ["A.G. Hawkes", "D. Oakes"], "venue": "Journal of Applied Probability,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1974}, {"title": "Language style matching predicts relationship initiation and stability", "author": ["M.E. Ireland", "R.B. Slatcher", "P.W. Eastwick", "L.E. Scissors", "E.J. Finkel", "J.W. Pennebaker"], "venue": "Psychological Science,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Selfexciting point process models of civilian deaths in iraq", "author": ["E. Lewis", "G. Mohler", "P.J. Brantingham", "A.L. Bertozzi"], "venue": "Security Journal,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "Dyadic event attribution in social networks with mixtures of hawkes processes", "author": ["L. Li", "H. Zha"], "venue": "In Proceedings of the 22nd ACM international conference on Conference on information & knowledge management,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Extending earthquakes\u2019 reach through cascading", "author": ["D. Marsan", "O. Lengline"], "venue": "Science, 319(5866):1076\u20131079,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "Exact and approximate em estimation of mutually exciting hawkes processes", "author": ["J.F. Olson", "K.M. Carley"], "venue": "Statistical Inference for Stochastic Processes,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2013}, {"title": "Linguistic inquiry and word count", "author": ["J.W. Pennebaker", "M.E. Francis", "R.J. Booth"], "venue": "Liwc", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2001}, {"title": "Point process modelling for directed interaction networks", "author": ["P.O. Perry", "P.J. Wolfe"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "Using twitter to recommend real-time topical news", "author": ["O. Phelan", "K. McCarthy", "B. Smyth"], "venue": "In Proceedings of the third ACM conference on Recommender systems,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "Care to comment?: recommendations for commenting on news stories", "author": ["E. Shmueli", "A. Kagian", "Y. Koren", "R. Lempel"], "venue": "In Proceedings of the 21st international conference on World Wide Web,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "Reconstruction of missing data in social networks based on temporal patterns of interactions", "author": ["A. Stomakhin", "M.B. Short", "A.L. Bertozzi"], "venue": "Inverse Problems,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "User oriented tweet ranking: a filtering approach to microblogs", "author": ["I. Uysal", "W.B. Croft"], "venue": "In Proceedings of the 20th ACM international conference on Information and knowledge management,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2011}, {"title": "From user comments to on-line conversations", "author": ["C. Wang", "M. Ye", "B.A. Huberman"], "venue": "In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2012}, {"title": "Mixture of mutually exciting processes for viral diffusion", "author": ["S.-H. Yang", "H. Zha"], "venue": "In Proceedings of the 30th International Conference on Machine Learning", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2013}, {"title": "Beyond clicks: dwell time for personalization", "author": ["X. Yi", "L. Hong", "E. Zhong", "N.N. Liu", "S. Rajan"], "venue": "In Proceedings of the 8th ACM Conference on Recommender systems,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2014}, {"title": "Learning social infectivity in sparse low-rank networks using multi-dimensional hawkes processes", "author": ["K. Zhou", "H. Zha", "L. Song"], "venue": "Proceedings of the Sixteenth International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2013}, {"title": "Learning triggering kernels for multidimensional hawkes processes", "author": ["K. Zhou", "H. Zha", "L. Song"], "venue": "In Proceedings of the 30th International Conference on Machine Learning", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2013}], "referenceMentions": [{"referenceID": 10, "context": "Recently, there has been a growing interest in the application of point processes to social media analysis [11], [10], [30], [28], [9], [7].", "startOffset": 107, "endOffset": 111}, {"referenceID": 9, "context": "Recently, there has been a growing interest in the application of point processes to social media analysis [11], [10], [30], [28], [9], [7].", "startOffset": 113, "endOffset": 117}, {"referenceID": 29, "context": "Recently, there has been a growing interest in the application of point processes to social media analysis [11], [10], [30], [28], [9], [7].", "startOffset": 119, "endOffset": 123}, {"referenceID": 27, "context": "Recently, there has been a growing interest in the application of point processes to social media analysis [11], [10], [30], [28], [9], [7].", "startOffset": 125, "endOffset": 129}, {"referenceID": 8, "context": "Recently, there has been a growing interest in the application of point processes to social media analysis [11], [10], [30], [28], [9], [7].", "startOffset": 131, "endOffset": 134}, {"referenceID": 6, "context": "Recently, there has been a growing interest in the application of point processes to social media analysis [11], [10], [30], [28], [9], [7].", "startOffset": 136, "endOffset": 139}, {"referenceID": 13, "context": "Hawkes Process [14] is a special form of point process which exhibits mutual excitation and is appropriate for modeling user interactions in social media.", "startOffset": 15, "endOffset": 19}, {"referenceID": 2, "context": "properties as well as temporal properties such as burstiness [3], we propose a novel framework based on multi-dimensional Hawkes process for conversation modeling and prioritization.", "startOffset": 61, "endOffset": 64}, {"referenceID": 2, "context": "This scenario reflects the bursty nature of social events[3].", "startOffset": 57, "endOffset": 60}, {"referenceID": 0, "context": "[1].", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "Temporal point processes model point patterns with stochastic processes and are suitable for dealing with incomplete observations [1], [6].", "startOffset": 130, "endOffset": 133}, {"referenceID": 5, "context": "Temporal point processes model point patterns with stochastic processes and are suitable for dealing with incomplete observations [1], [6].", "startOffset": 135, "endOffset": 138}, {"referenceID": 13, "context": "A one-dimensional Hawkes process [14] is:", "startOffset": 33, "endOffset": 37}, {"referenceID": 14, "context": "Hawkes process also exhibits a bursty nature, hence it is also referred to as time-cluster process [15].", "startOffset": 99, "endOffset": 103}, {"referenceID": 20, "context": "We make use of Linguistic Inquiry and Word Count (LIWC) to extract content features [21].", "startOffset": 84, "endOffset": 88}, {"referenceID": 3, "context": "LIWC is a text analysis software that calculates the degree any text comprises different categories of words, and is used in several prior studies in conversation analysis [4], [16].", "startOffset": 172, "endOffset": 175}, {"referenceID": 15, "context": "LIWC is a text analysis software that calculates the degree any text comprises different categories of words, and is used in several prior studies in conversation analysis [4], [16].", "startOffset": 177, "endOffset": 181}, {"referenceID": 12, "context": "[13] propose a framework for comparing text documents using language models, and sort users\u2019 newsfeed based on the novelty and relevance of the content items.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] proposed a content-based collaborative filtering method based on co-commenting and textual tags to predict which stories a particular user is most likely to comment on.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[29] integrate dwell times of TABLE II: Features to parametrize the influence", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "Relationship-based criteria (User-to-user relationship and content relevance): Authors in [2] pose the re-entry prediction problem for the first time and extract several social, temporal, and textual features of the post, poster, comments and commenter to address it.", "startOffset": 90, "endOffset": 93}, {"referenceID": 4, "context": "Authors in [5] also utilize a comprehensive collection of social, textual and content relevance features along with publisher authority in a collaborative filtering approach to Tweet recommendation.", "startOffset": 11, "endOffset": 14}, {"referenceID": 25, "context": "In [26], a similar set of features is used to filter tweets based on users\u2019 retweet likelihood.", "startOffset": 3, "endOffset": 7}, {"referenceID": 11, "context": "In [12], the authors measure the significance of a similar set of features in ranking feeds of IBM\u2019s SocialBlue and show that browsing history is a more accurate predictor of content relevance than communication history.", "startOffset": 3, "endOffset": 7}, {"referenceID": 22, "context": "[23] use Tweets to propose a content-based recommendation system to rank news stories in RSS feeds by calculating TF-IDF scores to measure the co-occurrence of popular terms within the user\u2019s RSS and Twitter feeds.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "Inspired by physical interactions, authors in [4] study the factors affecting user participation in the context of Twitter chats, however, their work is limited to the re-entry problem.", "startOffset": 46, "endOffset": 49}, {"referenceID": 7, "context": "The use of Hawkes process has been reported in the study of the association of temporal events in various fields, for example, financial events [8], seismic events [19], crimes [25], civilian deaths in conflicts [17], and recently, causal militant conflict events [18], social media [30], [28], [9], and network evolution modeling [11].", "startOffset": 144, "endOffset": 147}, {"referenceID": 18, "context": "The use of Hawkes process has been reported in the study of the association of temporal events in various fields, for example, financial events [8], seismic events [19], crimes [25], civilian deaths in conflicts [17], and recently, causal militant conflict events [18], social media [30], [28], [9], and network evolution modeling [11].", "startOffset": 164, "endOffset": 168}, {"referenceID": 24, "context": "The use of Hawkes process has been reported in the study of the association of temporal events in various fields, for example, financial events [8], seismic events [19], crimes [25], civilian deaths in conflicts [17], and recently, causal militant conflict events [18], social media [30], [28], [9], and network evolution modeling [11].", "startOffset": 177, "endOffset": 181}, {"referenceID": 16, "context": "The use of Hawkes process has been reported in the study of the association of temporal events in various fields, for example, financial events [8], seismic events [19], crimes [25], civilian deaths in conflicts [17], and recently, causal militant conflict events [18], social media [30], [28], [9], and network evolution modeling [11].", "startOffset": 212, "endOffset": 216}, {"referenceID": 17, "context": "The use of Hawkes process has been reported in the study of the association of temporal events in various fields, for example, financial events [8], seismic events [19], crimes [25], civilian deaths in conflicts [17], and recently, causal militant conflict events [18], social media [30], [28], [9], and network evolution modeling [11].", "startOffset": 264, "endOffset": 268}, {"referenceID": 29, "context": "The use of Hawkes process has been reported in the study of the association of temporal events in various fields, for example, financial events [8], seismic events [19], crimes [25], civilian deaths in conflicts [17], and recently, causal militant conflict events [18], social media [30], [28], [9], and network evolution modeling [11].", "startOffset": 283, "endOffset": 287}, {"referenceID": 27, "context": "The use of Hawkes process has been reported in the study of the association of temporal events in various fields, for example, financial events [8], seismic events [19], crimes [25], civilian deaths in conflicts [17], and recently, causal militant conflict events [18], social media [30], [28], [9], and network evolution modeling [11].", "startOffset": 289, "endOffset": 293}, {"referenceID": 8, "context": "The use of Hawkes process has been reported in the study of the association of temporal events in various fields, for example, financial events [8], seismic events [19], crimes [25], civilian deaths in conflicts [17], and recently, causal militant conflict events [18], social media [30], [28], [9], and network evolution modeling [11].", "startOffset": 295, "endOffset": 298}, {"referenceID": 10, "context": "The use of Hawkes process has been reported in the study of the association of temporal events in various fields, for example, financial events [8], seismic events [19], crimes [25], civilian deaths in conflicts [17], and recently, causal militant conflict events [18], social media [30], [28], [9], and network evolution modeling [11].", "startOffset": 331, "endOffset": 335}, {"referenceID": 26, "context": "Authors in [27] utilize inhomogeneous poisson processes to deal with the item adoption problem.", "startOffset": 11, "endOffset": 15}, {"referenceID": 29, "context": "[30], exploit multi-dimensional Hawkes process with low-rank and sparse assumption to accurately infer the influence network of WWW merely via the timestamps of new links between websites.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "In [9], authors proposed a novel framework based on Hawkes process to capture the dynamics of product adoption in social networks.", "startOffset": 3, "endOffset": 6}, {"referenceID": 19, "context": "Exact/approximate (non) parametric estimation algorithms for Hawkes process are also proposed by various authors [20], [30], [31].", "startOffset": 113, "endOffset": 117}, {"referenceID": 29, "context": "Exact/approximate (non) parametric estimation algorithms for Hawkes process are also proposed by various authors [20], [30], [31].", "startOffset": 119, "endOffset": 123}, {"referenceID": 30, "context": "Exact/approximate (non) parametric estimation algorithms for Hawkes process are also proposed by various authors [20], [30], [31].", "startOffset": 125, "endOffset": 129}, {"referenceID": 0, "context": "The features are extracted from training data and are normalized to lie within [0, 1].", "startOffset": 79, "endOffset": 85}, {"referenceID": 21, "context": "The weight vector \u03c1 can be estimated via the maximization of the Partial Likelihood [22] using any convex optimization method.", "startOffset": 84, "endOffset": 88}, {"referenceID": 29, "context": "The parameters \u03bc and a can be estimated efficiently using EM [30].", "startOffset": 61, "endOffset": 65}], "year": 2015, "abstractText": "The overwhelming amount and rate of information update in online social media is making it increasingly difficult for users to allocate their attention to their topics of interest, thus there is a strong need for prioritizing news feeds. The attractiveness of a post to a user depends on many complex contextual and temporal features of the post. For instance, the contents of the post, the responsiveness of a third user, and the age of the post may all have impact. So far, these static and dynamic features has not been incorporated in a unified framework to tackle the post prioritization problem. In this paper, we propose a novel approach for prioritizing posts based on a feature modulated multi-dimensional point process. Our model is able to simultaneously capture textual and sentiment features, and temporal features such as self-excitation, mutual-excitation and bursty nature of social interaction. As an evaluation, we also curated a real-world conversational benchmark dataset crawled from Facebook. In our experiments, we demonstrate that our algorithm is able to achieve the-stateof-the-art performance in terms of analyzing, predicting, and prioritizing events. In terms of interpretability of our method, we observe that features indicating individual user profile and linguistic characteristics of the events work best for prediction and prioritization of new events.", "creator": "LaTeX with hyperref package"}}}