{"id": "1511.06833", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Nov-2015", "title": "Semi-supervised Bootstrapping approach for Named Entity Recognition", "abstract": "The attempts 's Named Entity Recognition (NER) whole to identify references of knight entities in unstructured prosecutors, while to cannot any into early - defined html aforementioned. NER typically obesity 20 also varied knowledge later the possibly same argandab. However using combination but collection neither means yet made name synonyms and easier tension ambiguities these end identifying the entities today context and disseminating them together subclasses categories. We however the semi - ostensibly NER pragmatic that again with illustrate representative entities with for or all created training data. Using through indicate an ownership, has literally others the topics include rather used now appropriate the pattern. This combination of each companion form greatest is used both one seed pattern to identify the knight entities in taken bowling set. Pattern play and tuple value playing helps the popular of through future phenomena to identified the refer domain variations. We have diagnostic the opposed effectively the English subjects their into dataset include tagging (IEER) and untagged (CoNLL 2003) named void corpus they although Tamil derived brought main documents when the FIRE mesa and yield one exceeding x - effect 's 62% should both after classical.", "histories": [["v1", "Sat, 21 Nov 2015 04:11:44 GMT  (410kb)", "http://arxiv.org/abs/1511.06833v1", "13 pages, 2 figures, 5 tables"]], "COMMENTS": "13 pages, 2 figures, 5 tables", "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["s thenmalar", "j balaji", "t v geetha"], "accepted": false, "id": "1511.06833"}, "pdf": {"name": "1511.06833.pdf", "metadata": {"source": "CRF", "title": "Semi-supervised Bootstrapping approach for Named Entity Recognition", "authors": ["S. Thenmalar"], "emails": [], "sections": [{"heading": null, "text": "knowledge in the form of gazetteers. However using such a collection does not deal with name variants and cannot resolve ambiguities associated in identifying the entities in context and associating them with predefined categories. We present a semi-supervised NER approach that starts with identifying named entities with a small set of training data. Using the identified named entities, the word and the context features are used to define the pattern. This pattern of each named entity category is used as a seed pattern to identify the named entities in the test set. Pattern scoring and tuple value score enables the generation of the new patterns to identify the named entity categories. We have evaluated the proposed system for English language with the dataset of tagged (IEER) and untagged (CoNLL 2003) named entity corpus and for Tamil language with the documents from the FIRE corpus and yield an average f-measure of 75% for both the languages.\nKeywords: Named entity recognition, semi-supervised, pattern based bootstrapping, Tamil natural language processing."}, {"heading": "1. Introduction", "text": "In general, proper nouns are considered as named entities. The NER task was introduced during the 6 th Message Understanding Conference (MUC) in 1996 [13], and in MUC- 7 [3] the initial\nclassification of named entities used the following categories and subcategories: Entity (ENAMEX):\nperson, organization, location, Time expression (TIMEX): date, time and Numeric expression\n(NUMEX): money, percent. However, named entity tasks often include as named entities expressions\nfor date and time, names of sports and adventure activities, terms for biological species and\nsubstances. The major challenge of named entity recognition is that of tagging sequences of words\nthat represent interesting entities, such as people, places, and organizations. NER is a two-step\nprocess, the first step being the identification of proper nouns which is the marking of the presence of\na word or phrase as named entity (NE) in a given sentence while the second step is its classification\nwhere the role of the identified NE is determined.\nNER was initially known as a significant component for Information Extraction (IE). NER has\nnow become vital for many other natural language processing based applications. The identification\nand the semantic categories of Named entities are necessary before recognizing relations between\nthese entities [10, 11, 36]. NE\u2019s play an important role in identifying ontological concepts for\npopulating ontologies [5, 12]. NEs convey the crucial information that drives Information Retrieval\n(IR) and Question Answering (QA) systems [23, 35]. In more recent times, important applications like\nnews aggregation are usually centred on entities.\nThere are several approaches for identifying NER. The rule-based approach uses a set of rules defined by human experts to extract entities. This model takes a set of patterns consisting of grammatical, syntactic and orthographic features in combination with dictionaries. However, manual creation of rules is labour intensive and costly and requires significant language as well as domain expertise [33]. Moreover systems developed for one domain cannot be ported to another domain.\nTherefore learning based approaches have been introduced for NER. Learning algorithms can be defined as methods that use the features of training data and automatically induce patterns for recognising similar information from unseen data. Learning algorithms can be generally classified into three types: supervised learning, semi-supervised learning and unsupervised learning. Supervised learning utilises only the labelled data to generate a model. Semi-supervised learning aims to combine both the labelled data as well unlabelled data in learning. Unsupervised learning aims to learn without any labelled data.\nWe present a semi-supervised pattern based bootstrapping approach to NER that automatically identifies and classifies the entities. Our approach starts with the small set of tagged training data. The tagged training data is used to identify the word and context features to define a five window context pattern for each named entity category. We explore the representation of features used for both English and Tamil languages to define the pattern. The identified patterns are used as seed patterns. These seed patterns are used to identify the entities as an exact match in the test set. The pattern scoring and the tuple value scoring decide the modification needed to generate new patterns. The pattern score identifies which set of patterns are used for the next iteration. The tuple value scoring of POS provides which set of tuple contributes to the named entity and decides the window movement that is shift to the left or to the right and masks one tuple thus generating of new patterns that is used to learn new context to identify Named entities.\nThe rest of the paper is organized as follows. Section 2 gives a brief description of related work especially in the area of machine learning approaches to NER. Section 3 deals with the bootstrapping approach to NER. Section 4 deals with evaluation and results while section 5 gives a conclusion and discusses future work."}, {"heading": "2. Related Work", "text": "In a supervised learning approach an NER system takes training data and their features as input to\ngenerate an extraction model, which is then used to identify similar objects in new data. Supervised\nlearning has been the most commonly used and the leading approach in the NER [28]. There are\nseveral widely used machine learning techniques for this task. Support Vector Machines (SVM) [15,\n7] a model is constructed that fits a hyperplane that best splits positive and negative examples in the\nlabelled data. The model characterizes the examples as points in space, represented so that the positive\nand negative examples are separated by a clear gap that is as wide as possible. New examples are\nrepresented into that same space during the application time and expected to belong to a category\nbased on which side of the gap they fall on.\nHidden Markov Model (HMM) [46, 44, 30] is a statistical Markov model in which the sequence of states are hidden but can be predicted from a sequence of observations conveyed as a probabilistic function of the states. The learning process in the context of NER concludes that an HMM is based on the observed features and tags present in the training data. The model generates a mapping with certain probability that can predict a sequence of states. Conditional Random Fields (CRF) [17, 1] is a probabilistic model which avoids certain assumptions about the input and output sequence distributions of HMM. The other broadly used machine learning techniques for detecting NER where Perceptron algorithms [18], Na\u00efve Bayes [27], Decision Trees [9] and Maximum Entropy model [2]. For Tamil language named entities are identified by using Expectation Maximisation and the CRF model [29, 41]. The identification for named entity using CRF for Tamil language [41] describes the characteristics feature and handles morphological inflections to represent the training model. In our approach, we consider the morphological suffices as an added feature to represent the pattern for the named entity categories. The supervised learning method depends on the large set of training data, which has to be annotated manually.\nUnsupervised learning methods recognize named entity based on unlabelled data. The unsupervised learning methods basically use clustering techniques, distribution statistics and\nsimilarity based functions. The recognition of various types of named entities in the open domain that could be useful in IE [8]. The sequence of capitalised words that are likely to be named entities are extracted and the search queries using the sequence of words are created with Hearst patterns [14]. The hypernyms were extracted and clustered. The entities are looked up in WordNet and are labelled by the top level concepts observed in the WordNet. The named entities are lexicalised as multi-word in which co-occuring terms occur more frequently [6]. They have identified possible n-grams entity from the corpus based on the mutual information measures and the frequency of words and grouped similar named entities using clustering algorithm. The complex named entities in the Web data is identified using clustering algorithm [45]. The named entities are labelled based on the similarity using vector similarity model [4]. In essence, the entity names and their types are described as vectors with the specified features. In Semantic Concept Mapping, with the known list of candidate entity names and labels are denoted as WordNet synsets [19]. The Lin\u2019s similarity function describes the type of entity name [25].\nWe explore the semi-supervised learning method for NER. The semi-supervised method uses the\nsmall number of labelled data to learn and tag a large set of unlabelled data. The self-training\nalgorithm is used for detecting named entity and voted co-training algorithm is used for classifying\nthe named entity [21]. The self-training algorithm that selects the unlabelled instances for the Na\u00efve\nBayes classifier [43]. The gene name is recognized by bootstrapping approach [42]. The abstract and\nthe list of genes are available for the set of articles. The gene mentions in the abstract were annotated\nwith the list of gene available for the article. The HMM-based tagger is trained with the annotated\ndata. The lists of entities stated in the document are not usually available in general named entity\nrecognition. In another approach the named entities having Heidelberg Named Entity Resource are\nclassified based on the Wikipedia category using bootstrapping [20]. The inconsistency in\nclassification might be undetermined by placing the articles to the specified category. The features of\nPOS and syntactic structure of the document are used for the semi-supervised learning algorithm; a\nSelf-Training algorithm is used to recognize the named entity [34]. The features used determine the\nentity boundary and pattern extraction. However in our approach we use the POS feature and the\ncontext information of the word to represent the pattern. The CRF with feature induction is used for\ndetecting Hindi NER [24]. The features induction includes word based features, character n-grams,\nword prefix and suffix and 24 gazetteers. However we explore detecting named entity without\ngazetteers.\nNER problem is considered to be solved for languages such as English but still remains a challenge for resource scarce languages. Moreover NER of informal texts such as tweets and blogs still remains a challenging problem [22]. The issues in handling NER tasks for Indian languages have been described in the survey of Named Entity Recognition [16]. The issues discussed are the major feature commonly followed by NER systems is the capitalization of words. However, the capitalization of word for the named entities is not represented in the Indian languages. The gazetteers of named entities are unavailable for Indian languages. Additionally, spelling variations are common\nin Indian languages. For example in Tamil language: (Rasa) - (Raja): Person named Raja, (puducherri) - (pudhuccherri) : Place named Puducherry. The lack of labelled data is the added issue to resource scarce and morphological rich languages. In this work, we use pattern representation of bootstrapping approach which requires only a small set of feature tagged seed samples to learn the context and the features that detect the named entity and its category."}, {"heading": "3. Bootstrapping process for Named Entity Recognition", "text": "Figure 1 shows the overall bootstrapping process for NER. The proposed approach starts with the\nsmall set of training examples. The training set of documents is manually annotated with the named\nentity categories. The annotated training set is pre-processed by identifying the features of the word.\nWe make use of the context of the word to define the pattern. The patterns associated with each\ncategory of named entity are identified and used as seed patterns. The test data is processed by\nmatching the features of the word with the pattern. If exact match occurs then the named entity\ncategory is identified. Up to this point we have identified and categorized named entities that have\nfeatures exactly similar to the seed set initially given. However we need to generate new patterns by\nlearning new contexts where these named entities can occur. For this purpose the patterns are scored\nto identify which patterns can be used for further iteration. The new patterns have also been designed\nto identify named entity chunks even though the initial seed patterns are associated with only a single\nword. The new pattern is generated by right or left shift of the window for each pattern depending on\nthe tuple value score. The new pattern is given as input to the tagged test documents and the\ninstances of the named entity categories are identified. The process of pattern scoring, tuple value\nscoring and window shifting to learn new patterns is continued until no new patterns are generated or\nall the test data is labelled. The feature set used is described in the next section."}, {"heading": "3.1 Feature set", "text": "A perceptron based recognizer for identifying named entities uses nonlocal dependencies and\nexternal information as features [31]. A supervised learning method with CRF for detecting NER uses\nlocal knowledge features, external knowledge features and the non-local dependencies [38]. They\nhave discussed that the system when using the local knowledge feature performs poorly when using\nthe single token and the maximum observation of named entities is shown when using the sliding\nwindow of 3 token. However, when considering a three window context, the ambiguity of the type of\nnamed entity occurs. The features used also depend on the language under consideration. In order to\novercome the above issue we go for a five window context (wi-2,wi-1,wi,wi+1,wi+2)\nThe commonly used features for NER systems were part-of speech tags, shallow parsing and\nthe gazetteers. Part-of-speech (POS) tags are commonly used feature in NER but this feature is not considered for NER Systems [31, 26]. In this work, we use POS tag and semantic constraints obtained from UNL KB [40] that are associated with each word along with the five window context as common feature for both English and Tamil languages. Thus each word is attached with POS tag and semantic constraint to form the feature set. Using these features we describe the patterns."}, {"heading": "3.2 Seed pattern Generation", "text": "Tagging the words in the English documents with POS tag is carried out using the Stanford parser and the POS tagging of the words in the Tamil documents is carried out using morphological analyser. We manually label the named entities in a small set of tagged data. This data is considered as training data and is used for identifying the patterns. The patterns capture both the sequence of tokens that identify a potential named entity and the information from the right & left context where it occurs. We consider the five window context (wi-2,wi-1,wi,wi+1,wi+2) to represent the pattern. We have defined two types of patterns, one type for English language where the POS tag and semantic constraint (SC) are the features associated with each word is given below. In the case the pattern type of Tamil language we also use morphological suffix (MS) which implicitly conveys case information for nouns as an additional feature is given below. This difference in the type of patterns essentially caters to two languages having different characteristics such as fixed word order of English language and partially free word order of Tamil language. The use of word based semantic constraint (SC) allows the context of the named entity is to be semantically described to enable proper classification. Thus each word in the context window (wi-2,wi-1,wi,wi+1,wi+2) consists two tuples in the case of English language and three tuples in the case of Tamil language.\nPattern Type for English language\nPOS,SC(wi-2);POS,SC(wi-1);POS(wi),SC@Named Entity Type; POS,SC(wi+1);POS,SC(wi+2)\nPattern Type for Tamil language\nPOS,MS& SC(wi-2);POS,MS&SC(wi-1);POS,MS & SC (wi) @Named Entity Type; POS,MS&SC(wi+1);POS,MS&SC(wi+2)\nThe Named Entity Types used here are defined in the the classification of MUC-7 namely\nperson, organization, location, date, time, money and percentage.\nExample Pattern Types for English language\nPerson VBG,icl>person; IN,aoj>thing; NNP,iof>person@person; IN,aoj>thing; PRP,icl>female person\nLocation TO,aoj>thing; VB,agt>thing,obj>thing; NP,iof>country@location; NN,icl>area; NNS,icl>action\nOrganization IN,obj>thing; IN,aoj>thing; nnp,icl>organization@organization; JJ,aoj>thing; NN,icl>facilities\nDate NN,icl>organization; IN,aoj>thing; NNP,icl<date; CD,None@date; VBD,obj>thing; NNS,aoj>thing\nTime NN,icl>action; VBD,None; NN,icl>time@time; IN,aoj>thing; DT,None\nMoney NN,icl>deal; IN,aoj>thing; $CD,icl>money@money; IN,aoj>thing; NN,icl>reduce\nPercent VB;agt>thing,obj>thing; PRP,None; CD,None;NN,icl>ratio@percent; NN,agt>thing; IN,aoj>thing\nExample Pattern Type for Tamil language\nPerson\nEntity,\u0b85,icl>region; Noun,None,icl>person; Entity,None,iof>person@person; Adjective,\u0baa\u0bcd,icl>help; Adjective,None,aoj>thing\nLocation\nNoun,\u0b87\u0ba9\u0bcd,icl<weather; Noun,\u0b86\u0b95,icl<abstract thing; Entity,None,iof>place@location; Noun,\u0b87\u0bb2\u0bcd,icl<area; Noun,None,icl>calculate(agt>thing,obj>thing)\nOrganization\nNoun,None,icl>person; Noun,\u0b89\u0b9f\u0ba9\u0bcd,icl>act; Noun,None,icl>organization@organization; Noun,\u0b95\u0bb3\u0bcd,icl>person; Verb,None,icl>action\nDate\nAdjective,None,mod<thing; DateTime,None,icl>period; DateTime,None,icl>month, charNumbers,\u0b86\u0bae\u0bcd@date; DateTime,None,aoj>thing; Noun,\u0b89\u0b95\u0bcd\u0b95\u0bc1+ ,icl>facilities\nMoney\nPronoun,None,icl>person; Noun,None,aoj>thing; charNumbers,None,Noun,\u0b90, icl>currency@money;Adverb,None,icl>action; Noun,\u0b86\u0bb0\u0bcd,aoj>thing\nTime\nNoun,None,icl>morning; charNumbers,None,Noun,\u0b95\u0bcd\u0b95\u0bc1,icl>time; Noun,None, icl>workship; Verb,\u0b89\u0bae\u0bcd,icl>action\nPercent\nNoun,\u0b95\u0bb3\u0bcd,icl>person; Noun,\u0b95\u0bcd + \u0b95\u0b95\u0baf\u0bbf\u0bb2\u0bcd,icl>action; charNumbers,None,Noun, icl>ratio @percent; Noun,\u0b86\u0b95,icl>change; Verb,None,agt>thing,gol>person,obj>thing"}, {"heading": "3.3 Matching", "text": "For a given test data we POS tag the words using Stanford parser in case of English language\nand use a morphological analyser [39] in the case of Tamil language for POS and Morphological suffix tagging. The root words are then used to obtain the corresponding semantic constraints from the UNL KB [40]. We check for the matching of seed patterns with the annotated sentences of the documents. Although the pattern consists of a five word window (wi-2,wi-1,wi,wi+1,wi+2), actual exact\nmatching is carried out with only the middle word wi of the pattern. If there is a match the corresponding classes are labelled for the exactly matched patterns. Named entities that are not handled by the exact match are processed through partial matching. Partial match is carried out after selecting the pattern to be modified during iteration in the next cycle. Once a pattern is identified, tuple scoring detects which tuple contributes the most to the particular entity type."}, {"heading": "3.4 Generation of new patterns", "text": "The first step in new pattern generation is to find the most frequently occurring pattern for each\nclass of named entity indicated by Pattern Score. The next step is to find alternate values for POS tags\nthat can occur at position k in the context window of pattern Pj keeping all other tuple values the same by finding the tuple value of POS tag with minimum score at position k which is then considered for\nmasking."}, {"heading": "3.4.1 Pattern Score", "text": "In this work we use the Basilisk algorithm for calculating the pattern scoring metric RlogF metric\n[32]. The extraction pattern is scored using the following formula:\n(1)\nWhere Fj is the number of identified named entities by pattern Pj corresponding to a particular type of named entity, nj is the total number of patterns identified. The pattern score identifies the pattern for the particular type of named entity to be chosen for modification to form the new pattern."}, {"heading": "3.4.2 Tuple value Score", "text": "The tuple scoring basically depends on the tuple corresponding to the POS tag of the words in\nthe context window. This scoring essentially evaluates which POS tag value of which word in the context window of the specific pattern is strongly associated with a particular pattern.\nLet us consider a pattern Pj corresponding to a particular type of Named entity. The pattern P\nassociated with Named entity has four words (wi-2,wi-1,wi,wi+1,wi+2)in the 5 word context window and each of these words is associated with a POS values (posi-2, posi-1, posi+1, posi+2). The maximum score of the POS value indicates that this POS value in this position contributes the most to the pattern Pj and is given as\nwhere k=i-2,i-1,i+1,i+2 (2)\nHere, tvPOSk corresponds to tuple value of POS tuple posk. f(tvPOSk, Pj) is the number of times this particular POS value at position k occurs with pattern Pj. f(Pj) is the frequency of pattern Pj and f(tvPOSk) is the total frequency of this tuple value at position k."}, {"heading": "3.4.3 Methods for New Pattern Generation", "text": "The first method of new pattern generation is the replacement of POS value in the appropriate\nposition k. The POS tuple value with minimum score at position k is masked. The new pattern is\ngenerated by replacing the tuple value of the original pattern by the new tuple value that occurs the\nmost frequently at position k in the test data.\nThe next method of new pattern generation is carried out by shifting the context window to the\nleft or right of the Wi depending on the frequency of occurrence of POS pair of wi, wi+1 or wi-1, wi. Depending on a higher POS pair frequency score a new 5 word pattern is generated where either wi-1 or w i+1 becomes the new wi. This method of new pattern generation is possible since Named Entities are often associated with POS tags that frequently tend to co-occur together.\nNew patterns are also generated by chunking words to form phrasal named entities. For this\npurpose again we use the POS pair frequency score as shown in Eq. 1, but in addition we check\nwhether each of the words associated with POS pair have the same semantic constraints. In case the\nPOS pair frequency is above a threshold and have same semantic constraints they are chunked as a\nsingle Named entity and considered as wi for the next iteration. This unique way of forming patterns for chunked words forming Named Entities is possible because these chunks are often associated with\nsimilar semantic properties. However the two languages we considered needed to be tackled\ndifferently during the chunking process.\nIn the case of English language, the POS pair frequency score and semantic constraints alone\ndecide chunking. However in the case of Tamil language, in addition to the above features, morphological suffix should not be associated with Wi in case of pair Wi, Wi+1 or Wi-1 in case pair Wi-1, Wi. In case such morphological suffixes exist chunking is not carried out even though the semantic constraints between the pair matches."}, {"heading": "4. Evaluation", "text": "We have tested the performance of the system on IEER dataset, the tagged corpus which contains the Newswire development test data for the NIST 1999 IE-ER Evaluation. There were totally 3174 named entities. We have taken two different seed patterns that commonly occur for each named entity class (MUC-7). Iterations are carried out until no changes occur in the patterns. The performance of the system is evaluated using precision, recall, and f-measure metrics. Here, recall is defined as\nPrecision is defined as\nF-measure is the weighted harmonic mean of precision and recall and is given as\nThe performance of NER system using IEER data set is given in Table 1, where the system\nidentifies the named entities with the average precision of 83% and recall of 92%.\nWe have tested the performance of the system by using the CoNLL 2003 [37] data RCV1\n(Reuters Corpus Volume 1). The Reuters corpus consists of news articles between August 1996 and August 1997. The training set was taken from the files representing the end of august 1996. For test set the files were from December 1996. There were totally 5648 Named Entities. The training data is processed and tagged with POS tags and semantic constraints. We extract two different seed patterns for each named entity class (MUC-7) from the training set. With the seed patterns, we used the test set to identify exact match and iterate the process to generate new patterns for the named entity class. The performance is shown in Table 2, where the system yields the average precision of 80% and recall of 89%.\nFor Tamil language we performed experiments on documents of the FIRE (Forum of Information Retrieval Evaluation) Tamil corpus extracted from newspapers such as BBC, Dinamani and Dinamalar. We have considered 50000 documents and tagged with the appropriate features such as POS, Morphological suffix and UNL Semantic constraint. We have taken 4000 tagged documents for training set and extracted the most frequently occurring two different example patterns for each named entity class (MUC-7). The performance is shown in Table 3, where the system produces the average precision of 79% and recall of 88%.\nWe also compared our bootstrapping with the baseline approach [34]. The Baseline system\nuses Reuters corpus and considers accident documents. The total number of named entities corresponding to the date and location are 246 and 596. The Baseline system uses 15 and 36 seed patterns for date and location entities and extracted 18 and 68 patterns. Our system uses 2 seed patterns for each named entities and we have learned 12 and 35 patterns of those named entities. The\ncomparison is shown in figure 2, the missing of syntactic structure information in the baseline system yields less F-measure whereas our approach makes use of the larger contextual window and word based semantic information to learn the patterns.\nWe also shown in the Table 4 and Table 5 the number of patterns that we have learnt in the\nEnglish corpus and Tamil corpus for each named entities using each method (replacement of POS and shifting window)."}, {"heading": "5. Conclusion", "text": "This paper describes a new pattern based semi-supervised bootstrapping for identifying and classifying Named Entities. The method does not use any Gazetteer but instead uses POS information and word based semantic constraints and gives an average f-measure of 75 % for both the languages. This essentially ensures that the patterns are feature based enabling tagging of hitherto unseen Named Entities. This method can be further enhanced by considering more domain specific corpora and by trying for domain specific Named Entity categories. Future work includes testing this method for other languages to study how the methodology needs to adapted. Pattern definition and chunking strategies are possible aspects that need to be modified."}], "references": [{"title": "Exploiting Feature Hierarchy for Transfer Learning in Named Entity", "author": ["Arnold", "R.A. Nallapati", "W. Cohen"], "venue": "Journal of Computational Linguistics,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2008}, {"title": "Named Entity Recognition with a Maximum Entropy Approach", "author": ["H. Chieu", "H. Ng"], "venue": "In Proceedings of the Seventh Conference on Natural Language Learning", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2003}, {"title": "MUC-7 Named Entity Task Definition Version 3.5", "author": ["N. Chinchor"], "venue": "In Proceedings of the 7th Message Understanding Conference (MUC-7)", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1998}, {"title": "Towards Large-scale, Open-domain and Ontology-based Named Entity Classification", "author": ["P. Cimiano", "J. V\u00f6lker"], "venue": "In Proceedings of the International Conference on Recent Advances in Natural Language Processing", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2005}, {"title": "Ontology Learning and Population from Text: Algorithms, Evaluation and Applications", "author": ["Cimiano", "Philipp"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2006}, {"title": "Extracting Named Entities: a Statistical Approach", "author": ["J. Da Silva", "Z. Kozareva", "V. Noncheva"], "venue": "In Proceedings of the XIe\u0300me Confe\u0301rence sur le Traitement des Langues Naturelles (TALN)", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2004}, {"title": "Named Entity Recognition using Support Vector Machine: a Language Independent Approach", "author": ["Ekbal", "Asif", "Bandyopadhyay", "Sivaji"], "venue": "International Journal of Electrical and Electronics Engineering", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "A Framework for Named Entity Recognition in the Open Domain", "author": ["R. Evans"], "venue": "In Proceedings of Recent Advances in Natural Language Processing", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2003}, {"title": "Nested Named Entity Recognition", "author": ["J. Finkel", "C. Manning"], "venue": "In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Exploiting Shallow Linguistic Information for Relation Extraction from Biomedical Literature", "author": ["C. Giuliano", "A. Lavelli", "L. Romano"], "venue": "In proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL)", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "Relation Extraction and the Influence of Automatic Named Entity Recognition", "author": ["C. Giuliano", "A. Lavelli", "L. Romano"], "venue": "ACM Transactions on Speech and Language Processing (TSLP)", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2007}, {"title": "Instance-Based Ontology Population Exploiting Named-Entity Substitution", "author": ["C. Giuliano", "A. Gliozzo"], "venue": "In Proceedings of the 22nd International Conference on Computational Linguistics", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "Message understanding conference-6: a brief history", "author": ["Grishman", "Ralph", "Sundheim", "Beth"], "venue": "In Proceedings of the 16th conference on Computational linguistics", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1996}, {"title": "Automatic Acquisition of Hyponyms from Large Text Corpora", "author": ["M. Hearst"], "venue": "In Proceedings of the 14th International Conference on Computational Linguistics", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1992}, {"title": "Efficient Support Vectors Classifiers for Named Entity Recognition", "author": ["H. Isozaki", "H. Kazawa"], "venue": "In Proceedings of the 19th International Conference on Computational Linguistics", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2002}, {"title": "A survey of Named Entity Recognition in English and other Indian Languages", "author": ["Kaur", "Darvinder", "Gupta", "Vishal"], "venue": "IJCSI International Journal of Computer Science Issues", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "Exploiting Wikipedia as External Knowledge for Named Entity Recognition", "author": ["J. Kazama", "K. Torisawa"], "venue": "In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2007}, {"title": "A New Perceptron Algorithm for Sequence Labeling with Non-local Features", "author": ["J. Kazama", "K. Torisawa"], "venue": "In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and ComputationalNatural Language Learning", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}, {"title": "Combining Image Captions and Visual Analysis for Image Concept Classification", "author": ["T. Kliegr", "K. Chandramouli", "J. Nemrava", "V. Svatek", "E. Izquierdo"], "venue": "In Proceedings of the 9th International Workshop on Multimedia Data Mining, at the 2008 International Conferenc on Knowledge Discovery and Data Mining", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "Extending a Multilingual Lexical Resource by Bootstrapping Named Entity Classification using Wikipedia\u2019s Category System", "author": ["J. Knopp"], "venue": "In Proceedings of the 5th International Workshop On Cross Lingual Information Access,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Self-training and Co-training Applied to Spanish Named Entity Recognition", "author": ["Kozareva", "Zornitsa. Bonev", "Boyan", "Montoyo", "Andres"], "venue": "MICAI", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2005}, {"title": "Named Entity Recognition on Turkish Tweets", "author": ["Kucuk", "Dilek. Jacquet", "Guillaume", "Steinberger", "Ralf"], "venue": "In Proceedings of the Ninth International Conference on Language Resources and Evaluation", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "Fine-grained Named Entity Recognition and Relation Extraction for Question Answering", "author": ["C. Lee", "Y. Hwang", "M. Jang"], "venue": "In Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2007}, {"title": "2004.Rapid Development of Hindi Named Entity Recognition using Conditional Random Fields and Feature Induction", "author": ["W. Li", "A. McCallum"], "venue": "ACM Transactions on Asian Language Information Processing,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2004}, {"title": "An Information-theoretic Definition of Similarity", "author": ["D. Lin"], "venue": "In Proceedings of the Fifteenth International Conference on Machine learning", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1998}, {"title": "Phrase Clustering for Discriminative Learning. In the Proceedings of the Joint Conference of the 47  th Annual Meeting of the ACL and the 4  th International", "author": ["Lin", "Dekang", "Wu", "Xiaoyun"], "venue": "Joint Conference on Natural Language Processing of the AFNLP", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2009}, {"title": "Syntax-based Semi-supervised Named Entity Tagging", "author": ["B. Mohit", "R. Hwa"], "venue": "In Proceedings of the ACL Interactive Poster and Demonstration", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2005}, {"title": "A Survey on Named Entity Recognition and Classification", "author": ["D. Nadeau"], "venue": "Linguisticae Investigationes", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2007}, {"title": "Named Entity Recognition in Tamil using Context-cues and the E-M Algorithm", "author": ["S. Pandian", "T.V. Geetha", "Krishna"], "venue": "In Proceedings of the International Joint Conference on Artificial Intelligence", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2007}, {"title": "Biomedical Named Entity Recognition: a Poor Knowledge HMM - based Approach", "author": ["N. Ponomareva", "F. Pla", "A. Molina", "P. Rosso"], "venue": "In Proceedings of the 12th international conference on Applications of Natural Language to Information Systems (NLDB)", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2007}, {"title": "Design Challenges and Misconceptions in Named Entity Recognition", "author": ["Ratinov", "Lev", "Roth", "Dan"], "venue": "In the Proceedings of the Thirteenth Conference on Computational Natural Language Learning", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2009}, {"title": "An Empirical Study of Automated Dictionary Construction for Information Extraction in Three Domains", "author": ["E. Rillof"], "venue": "Al Journal,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1996}, {"title": "Rule-based pattern extractor and named entity recognition: A hybrid approach", "author": ["Sari", "Yunita. Hassan", "Mohd F", "Zamin", "Norshuhani"], "venue": "In Proceedings of International Symposium on Information Technology,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2010}, {"title": "Named Entity Recognition for Improving Retrieval and Translation", "author": ["R. Srihari", "E. Peterson"], "venue": "In Proceedings of the 11th International Conference on Asian Digital Libraries", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2008}, {"title": "Discovering Relations between Noun Categories", "author": ["M. Thahir", "H. Estevam", "T. Mitchell"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2011}, {"title": "Introduction to the CoNLL-2003 Shared Task:Language-Independent Named Entity Recognition", "author": ["Tjong Kim Sang", "Erik F", "De Meulder", "Fien"], "venue": "In the Proceedings of CoNLL-2003", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2003}, {"title": "Named entity recognition: Exploring features", "author": ["Tkachenko", "Maksim", "Simanovsky", "Andrey"], "venue": "In the Proceedings of KONVENS", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2012}, {"title": "Enhancement of morphological analyzer with compound, numeral and colloquial word handler", "author": ["Umamaheswari E", "Karthika Ranganathan", "Geetha T.V", "Ranjani Parthasarathi", "Madhan K"], "venue": "In the Proceedings of International Conference on Natural Language Processing (ICON),", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2011}, {"title": "Domain focused named entity recognizer for tamil using conditional random fields", "author": ["R Vijayakrishna", "L. Sobha"], "venue": "In Proceedings of the IJCNLP-08 Workshop on NER for South and South East Asian Languages,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2008}, {"title": "Bootstrapping and Evaluating Named Entity Recognition in the Biomedical Domain", "author": ["A. Vlachos", "C. Gasperin"], "venue": "In Proceedings of the HLT-NAACL BioNLP Workshop on Linking Natural Language and Biology ", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2006}, {"title": "Semi-supervised Self-training for Sentence Subjectivity Classification", "author": ["Wang", "Bin. Spencer", "Bruce. Ling", "Charles X", "Zhang", "Harry"], "venue": "Advances in Artificial Intelligence", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2008}, {"title": "Exploring Deep Knowledge Resources in Biomedical Name Recognition", "author": ["G. Zhou", "J. Su"], "venue": "In Proceedings of the COLING2004 International Workshop on Natural Language Processing in Biomedicine and its Applications", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2004}, {"title": "Locating Complex Named Entities in Web Text", "author": ["D Downey", "M Broadhead", "O Etzioni"], "venue": "Proceedings of the 20  th International Joint Conference on Artificial Intelligence,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2007}, {"title": "Named Entity Recognition using Hidden Markov Model, International", "author": ["S Morwal", "N Jahan", "D Chopra"], "venue": "Journal on Natural Language Computing (IJNLC)", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2012}], "referenceMentions": [{"referenceID": 12, "context": "The NER task was introduced during the 6 th Message Understanding Conference (MUC) in 1996 [13], and in MUC- 7 [3] the initial classification of named entities used the following categories and subcategories: Entity (ENAMEX): person, organization, location, Time expression (TIMEX): date, time and Numeric expression (NUMEX): money, percent.", "startOffset": 91, "endOffset": 95}, {"referenceID": 2, "context": "The NER task was introduced during the 6 th Message Understanding Conference (MUC) in 1996 [13], and in MUC- 7 [3] the initial classification of named entities used the following categories and subcategories: Entity (ENAMEX): person, organization, location, Time expression (TIMEX): date, time and Numeric expression (NUMEX): money, percent.", "startOffset": 111, "endOffset": 114}, {"referenceID": 9, "context": "The identification and the semantic categories of Named entities are necessary before recognizing relations between these entities [10, 11, 36].", "startOffset": 131, "endOffset": 143}, {"referenceID": 10, "context": "The identification and the semantic categories of Named entities are necessary before recognizing relations between these entities [10, 11, 36].", "startOffset": 131, "endOffset": 143}, {"referenceID": 34, "context": "The identification and the semantic categories of Named entities are necessary before recognizing relations between these entities [10, 11, 36].", "startOffset": 131, "endOffset": 143}, {"referenceID": 4, "context": "NE\u2019s play an important role in identifying ontological concepts for populating ontologies [5, 12].", "startOffset": 90, "endOffset": 97}, {"referenceID": 11, "context": "NE\u2019s play an important role in identifying ontological concepts for populating ontologies [5, 12].", "startOffset": 90, "endOffset": 97}, {"referenceID": 22, "context": "NEs convey the crucial information that drives Information Retrieval (IR) and Question Answering (QA) systems [23, 35].", "startOffset": 110, "endOffset": 118}, {"referenceID": 33, "context": "NEs convey the crucial information that drives Information Retrieval (IR) and Question Answering (QA) systems [23, 35].", "startOffset": 110, "endOffset": 118}, {"referenceID": 27, "context": "Supervised learning has been the most commonly used and the leading approach in the NER [28].", "startOffset": 88, "endOffset": 92}, {"referenceID": 14, "context": "Support Vector Machines (SVM) [15, 7] a model is constructed that fits a hyperplane that best splits positive and negative examples in the labelled data.", "startOffset": 30, "endOffset": 37}, {"referenceID": 6, "context": "Support Vector Machines (SVM) [15, 7] a model is constructed that fits a hyperplane that best splits positive and negative examples in the labelled data.", "startOffset": 30, "endOffset": 37}, {"referenceID": 43, "context": "Hidden Markov Model (HMM) [46, 44, 30] is a statistical Markov model in which the sequence of states are hidden but can be predicted from a sequence of observations conveyed as a probabilistic function of the states.", "startOffset": 26, "endOffset": 38}, {"referenceID": 41, "context": "Hidden Markov Model (HMM) [46, 44, 30] is a statistical Markov model in which the sequence of states are hidden but can be predicted from a sequence of observations conveyed as a probabilistic function of the states.", "startOffset": 26, "endOffset": 38}, {"referenceID": 29, "context": "Hidden Markov Model (HMM) [46, 44, 30] is a statistical Markov model in which the sequence of states are hidden but can be predicted from a sequence of observations conveyed as a probabilistic function of the states.", "startOffset": 26, "endOffset": 38}, {"referenceID": 16, "context": "Conditional Random Fields (CRF) [17, 1] is a probabilistic model which avoids certain assumptions about the input and output sequence distributions of HMM.", "startOffset": 32, "endOffset": 39}, {"referenceID": 0, "context": "Conditional Random Fields (CRF) [17, 1] is a probabilistic model which avoids certain assumptions about the input and output sequence distributions of HMM.", "startOffset": 32, "endOffset": 39}, {"referenceID": 17, "context": "The other broadly used machine learning techniques for detecting NER where Perceptron algorithms [18], Na\u00efve Bayes [27], Decision Trees [9] and Maximum Entropy model [2].", "startOffset": 97, "endOffset": 101}, {"referenceID": 26, "context": "The other broadly used machine learning techniques for detecting NER where Perceptron algorithms [18], Na\u00efve Bayes [27], Decision Trees [9] and Maximum Entropy model [2].", "startOffset": 115, "endOffset": 119}, {"referenceID": 8, "context": "The other broadly used machine learning techniques for detecting NER where Perceptron algorithms [18], Na\u00efve Bayes [27], Decision Trees [9] and Maximum Entropy model [2].", "startOffset": 136, "endOffset": 139}, {"referenceID": 1, "context": "The other broadly used machine learning techniques for detecting NER where Perceptron algorithms [18], Na\u00efve Bayes [27], Decision Trees [9] and Maximum Entropy model [2].", "startOffset": 166, "endOffset": 169}, {"referenceID": 28, "context": "For Tamil language named entities are identified by using Expectation Maximisation and the CRF model [29, 41].", "startOffset": 101, "endOffset": 109}, {"referenceID": 38, "context": "For Tamil language named entities are identified by using Expectation Maximisation and the CRF model [29, 41].", "startOffset": 101, "endOffset": 109}, {"referenceID": 38, "context": "The identification for named entity using CRF for Tamil language [41] describes the characteristics feature and handles morphological inflections to represent the training model.", "startOffset": 65, "endOffset": 69}, {"referenceID": 7, "context": "The recognition of various types of named entities in the open domain that could be useful in IE [8].", "startOffset": 97, "endOffset": 100}, {"referenceID": 13, "context": "The sequence of capitalised words that are likely to be named entities are extracted and the search queries using the sequence of words are created with Hearst patterns [14].", "startOffset": 169, "endOffset": 173}, {"referenceID": 5, "context": "The named entities are lexicalised as multi-word in which co-occuring terms occur more frequently [6].", "startOffset": 98, "endOffset": 101}, {"referenceID": 42, "context": "The complex named entities in the Web data is identified using clustering algorithm [45].", "startOffset": 84, "endOffset": 88}, {"referenceID": 3, "context": "The named entities are labelled based on the similarity using vector similarity model [4].", "startOffset": 86, "endOffset": 89}, {"referenceID": 18, "context": "In Semantic Concept Mapping, with the known list of candidate entity names and labels are denoted as WordNet synsets [19].", "startOffset": 117, "endOffset": 121}, {"referenceID": 24, "context": "The Lin\u2019s similarity function describes the type of entity name [25].", "startOffset": 64, "endOffset": 68}, {"referenceID": 20, "context": "The self-training algorithm is used for detecting named entity and voted co-training algorithm is used for classifying the named entity [21].", "startOffset": 136, "endOffset": 140}, {"referenceID": 40, "context": "The self-training algorithm that selects the unlabelled instances for the Na\u00efve Bayes classifier [43].", "startOffset": 97, "endOffset": 101}, {"referenceID": 39, "context": "The gene name is recognized by bootstrapping approach [42].", "startOffset": 54, "endOffset": 58}, {"referenceID": 19, "context": "In another approach the named entities having Heidelberg Named Entity Resource are classified based on the Wikipedia category using bootstrapping [20].", "startOffset": 146, "endOffset": 150}, {"referenceID": 32, "context": "The features of POS and syntactic structure of the document are used for the semi-supervised learning algorithm; a Self-Training algorithm is used to recognize the named entity [34].", "startOffset": 177, "endOffset": 181}, {"referenceID": 23, "context": "The CRF with feature induction is used for detecting Hindi NER [24].", "startOffset": 63, "endOffset": 67}, {"referenceID": 21, "context": "Moreover NER of informal texts such as tweets and blogs still remains a challenging problem [22].", "startOffset": 92, "endOffset": 96}, {"referenceID": 15, "context": "The issues in handling NER tasks for Indian languages have been described in the survey of Named Entity Recognition [16].", "startOffset": 116, "endOffset": 120}, {"referenceID": 30, "context": "1 Feature set A perceptron based recognizer for identifying named entities uses nonlocal dependencies and external information as features [31].", "startOffset": 139, "endOffset": 143}, {"referenceID": 36, "context": "A supervised learning method with CRF for detecting NER uses local knowledge features, external knowledge features and the non-local dependencies [38].", "startOffset": 146, "endOffset": 150}, {"referenceID": 30, "context": "Part-of-speech (POS) tags are commonly used feature in NER but this feature is not considered for NER Systems [31, 26].", "startOffset": 110, "endOffset": 118}, {"referenceID": 25, "context": "Part-of-speech (POS) tags are commonly used feature in NER but this feature is not considered for NER Systems [31, 26].", "startOffset": 110, "endOffset": 118}, {"referenceID": 37, "context": "3 Matching For a given test data we POS tag the words using Stanford parser in case of English language and use a morphological analyser [39] in the case of Tamil language for POS and Morphological suffix tagging.", "startOffset": 137, "endOffset": 141}, {"referenceID": 31, "context": "1 Pattern Score In this work we use the Basilisk algorithm for calculating the pattern scoring metric RlogF metric [32].", "startOffset": 115, "endOffset": 119}, {"referenceID": 35, "context": "We have tested the performance of the system by using the CoNLL 2003 [37] data RCV1 (Reuters Corpus Volume 1).", "startOffset": 69, "endOffset": 73}, {"referenceID": 32, "context": "We also compared our bootstrapping with the baseline approach [34].", "startOffset": 62, "endOffset": 66}], "year": 2015, "abstractText": "The aim of Named Entity Recognition (NER) is to identify references of named entities in unstructured documents, and to classify them into pre-defined semantic categories. NER often aids from added background knowledge in the form of gazetteers. However using such a collection does not deal with name variants and cannot resolve ambiguities associated in identifying the entities in context and associating them with predefined categories. We present a semi-supervised NER approach that starts with identifying named entities with a small set of training data. Using the identified named entities, the word and the context features are used to define the pattern. This pattern of each named entity category is used as a seed pattern to identify the named entities in the test set. Pattern scoring and tuple value score enables the generation of the new patterns to identify the named entity categories. We have evaluated the proposed system for English language with the dataset of tagged (IEER) and untagged (CoNLL 2003) named entity corpus and for Tamil language with the documents from the FIRE corpus and yield an average f-measure of 75% for both the languages.", "creator": "Microsoft\u00ae Word 2010"}}}