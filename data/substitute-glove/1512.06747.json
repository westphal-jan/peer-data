{"id": "1512.06747", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Dec-2015", "title": "Multivariate Time Series Classification Using Dynamic Time Warping Template Selection for Human Activity Recognition", "abstract": "Accurate and computationally practical way this classifying human activities have were the subject form purposes research efforts. Most an biological emphasis on accumulating located feature to enhance contrast sizes useful. We repeal a compute selection approach example went Dynamic Time Warping, such that complex comic extracted way domain identity indeed trouble. We focus two predictive capability entire the inference week both simulated more good startac electronically.", "histories": [["v1", "Mon, 21 Dec 2015 18:36:53 GMT  (3193kb,D)", "http://arxiv.org/abs/1512.06747v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["skyler seto", "wenyu zhang", "yichen zhou"], "accepted": false, "id": "1512.06747"}, "pdf": {"name": "1512.06747.pdf", "metadata": {"source": "CRF", "title": "Multivariate Time Series Classification Using Dynamic Time Warping Template Selection for Human Activity Recognition", "authors": ["Skyler Seto", "Wenyu Zhang", "Yichen Zhou"], "emails": ["ss3349@cornell.edu", "wz258@cornell.edu", "yz793@cornell.edu"], "sections": [{"heading": null, "text": "I. INTRODUCTION\nWearable sensors have widespread applications in academic, industrial and medical fields. Examples of some current uses are fall detection in medical or home settings [1], and Human Activity Recognition (HAR) for smart health-monitoring systems [2].\nA substantial amount of research has been done with professional on-body wearable sensors. However, these devices are usually large, impractical or inconvenient for general commercial purposes. One viable alternative is smartphone sensors. Smartphones are equipped with accelerometers and gyroscopes, which provide rich motion data on their users. Although these sensors are less accurate than professional ones, the prevalence and convenience of smartphones suggests their potential for far-reaching applications. Possible benefits include a decreased need for human supervision in medical settings, more complex human-machine interaction, and complex activity recognition on smartphone applications.\nOur objective is an offline implementation of smartphone motion data classification that has comparable classification accuracy and computational efficiency with current techniques, and does not require domain knowledge of HAR.\nIn this paper, we propose a method based on Dynamic Time Warping (DTW). DTW has recently been widely used and integrated with other methods such as decision trees [3] in machine learning. Although DTW suffers from high computational costs and Dynamic Time Warping Distance (DTWD) is not a distance metric because it lacks the triangle inequality, DTW still has the potential to be a feasible answer to the above task by providing a flexible, easily interpretable time\n* All authors contributed equally in this work.\nseries similarity measure. By modifying DTW to improve on computational efficiency and similarity measure accuracy, we proceed to use it for motion data clustering, activity template construction and classification for our problem. Each template is the time series average representing a cluster. It has the benefit of providing visual representations of a human activity and does not require HAR knowledge for construction.\nAs such, the primary contributions of this paper are:\n1) Modification of DTW as a similarity measure for time series, 2) Procedure for template extraction in place of feature extraction.\nOur implementation enhances the quality of prediction, avoids high dimensionality, and is robust to noise. For demonstration, we use real human activity data, as well as synthetic data constructed from human activity data.\nIn Section II, we proceed by discussing existing methods for classifying human activities using feature extraction, hierarchical divide-and-conquer strategies, and multi-modalsequence classification. Section III formally defines Dynamic Time Warping and Section IV describes our proposed modifications to increase prediction accuracy. Section V discusses our template selection and classification approach which utilizes the modified DTW. In Sections VI and VII, we apply our algorithm to both real world data and synthetic data. Finally, in Section VIII and onwards, we compare the results of our algorithm with existing algorithms, and conclude."}, {"heading": "II. RELATED WORK", "text": "Considerable work has been done on classifying human activities. We consolidate works on both professional on-body sensors and smartphone sensors, while taking note that data from the latter may need different pre-processing steps due to higher noise tendencies. Furthermore, on-body sensors can be placed at more assigned locations on the body such as arms and ankles, and may include more components such as magnetometer [1].\nAn essential step in many papers is feature extraction. Popular features for such tasks include mean, standard deviation, maximum, peak-to-peak, root-mean-square, and correlation978-1-4799-7560-0/15/$31 c\u00a92015 IEEE\nar X\niv :1\n51 2.\n06 74\n7v 1\n[ cs\n.A I]\n2 1\nD ec\nbetween values of modality axes [4]. Another suggested option is using autoregressive modeling to form augmented-feature vectors [5].\nFollowing feature extraction, algorithms used for classification include Hidden Markov Models [2], Support Vector Machines [4], Multi-layer Perceptron, Naive Bayes, Bayesian Network, Decision Table, Best-First Tree, and K-star [6]. Although the strategy can increase classification accuracy, it requires manual grouping of the activities into meaningful categories. Comparative study across these algorithms has also been done [7].\nWhile feature extraction is quite popular in HAR for achieving high accuracy rates, there are a few problems with feature extraction. First, it is dependent on domain expertise as achieving high accuracy through feature extraction is only possible with the correct features. Second, feature extraction is prone to high dimensionality as a large number of features are needed. Finally computing some of these features such as autoregression coefficients can be computationally intensive.\nCurrent DTW methods on HAR involve aligning human behavior in video data [8]. These methods use a generalized time warping mechanism to extend DTW to aligning multimodal sequences [9]. While our proposed method discussed in Section IV uses DTW, we recognize that we cannot translate these methods directly for our approach since the data modality is different, and sequences extracted from video data may have different properties from raw sensor readings."}, {"heading": "III. DEFINITIONS", "text": "In this section, we state our definition and assumptions of time series. We also introduce DTW."}, {"heading": "A. Time Series", "text": "A p-dimensional multivariate time series Xi = {Xi(tl) \u2208 Rp; l = 1, . . . ,m} is a sequence of data points where:\n1) tl < tl\u2032 for l < l\u2032,\n2) tl \u2208 T = [a, b], \u2200l = 1, . . . ,m,\n3) Xi(t) \u2208 Rp,\u2200t \u2208 T .\nWe assume our training and test data are time series satisfying the assumptions above, with the additional condition that \u2206ti = ti\u2212ti\u22121 = b\u2212am\u22121 . We assume that all series have the same length as observed in most data sets, but the following DTW algorithms can be easily extended to the alternate case.\nIn the rest of this paper, we will refer to the length of a time series as m and the dimension of each point in the time series as p."}, {"heading": "B. Dynamic Time Warping (DTW)", "text": "DTW is an algorithm for computing the distance and alignment between two time series. It is used in applications such as speech recognition, and video activity recognition [8].\nDefinition 3.1: [10] A warping path is a sequence w = (w1, . . . , w|w|) where for k \u2208 {1, . . . , |w|}, wk = (pk, qk) with pk, qk \u2208 {1, . . .m}, satisfying the following conditions:\n1) Boundary condition: w1 = (1, 1), w|w| = (m,m) 2) Monotonicity condition: {pk}|w|k=1, {qk} |w| k=1 are monotonously non-decreasing sequences 3) Continuity condition:\nwk+1 \u2212 wk \u2208 {(1, 0), (0, 1), (1, 1)} for k \u2208 {1, . . . , |w| \u2212 1}\nFor simplicity, we write w = (p, q) as a path in accordance with Definition 3.1\nDefinition 3.2: For time series Xi and Xj with distance matrix D as calculated in Algorithm 1, for a path w = (p, q), we define the cost c as:\nc(w) = |w|\u2211 k=1 D[pk, qk]\nDefinition 3.3: The Dynamic Time Warping Distance (DTWD) is the sum of the pointwise distances along the optimal path w\u2217, for the cost function defined in Definition 3.2.\nw\u2217 = argmin w c(w), DTWD (Xi, Xj) = c(w\u2217) = D[m,m].\nDTW can be optimized through a bandwidth parameter bw, where it computes only values of the matrix close to the diagonal. This version of DTW is called FastDTW [11]. Algorithm 1 denotes the procedure to compute DTWD(Xi, Xj ; bw). A small bandwidth should be employed if the two time series demonstrate the same shape and frequency, since a smaller bandwidth brings the computational time closer to O(m).\nData: time series Xi, Xj , bandwidth bw Result: DTWD(Xi, Xj ; bw) Initialize distance matrix D = 0m\u00d7m D[1, 1] = |Xi(1)\u2212Xj(1)| for s \u2208 {2, . . . ,m} do\nD[s, 1] = D[1, s] =\u221e end for s \u2208 {2, . . . ,m} do\nfor t \u2208 {max(2, s\u2212 bw),min(m, s+ bw)} do cost=min (D[s\u2212 1, t], D[s, t\u2212 1], D[s\u2212 1, t\u2212 1])\nD[s, t] = |Xi (s)\u2212Xj (t)|+ cost\nend end return D[m,m]\nAlgorithm 1: Fast DTW\nOne time series Xj can be aligned to another Xi by using the optimal path defined in Definition 3.3. The basic concept of DTW alignment is illustrated in Figure 1. DTW first creates a matrix D of pointwise distances depicted as a black and white grid in the image on the right. The algorithm then runs through D from the first index (bottom left) to the last index (top right), enumerates all paths w, and finds an optimal warping path w\u2217 as specified in Definition 3.3. The optimal warping path is shown as the darkened line in the image on the right, and the\nalignment between the two series is shown in the image on the left. The algorithm also returns the sum of the pointwise distances along the optimal path [12].\nAlgorithm 2 is used to align two time series. The algorithm first computes all paths from the distance matrix D, obtains the optimal path, and updates Xj according to that path.\nData: time series Xi, Xj , distance matrix D Result: time series Xj aligned to Xi for s \u2208 {2, . . . ,m} do\nfor t \u2208 {max(2, s\u2212 bw),min(m, s+ bw)} do if D[s][t\u2212 1] \u2264 D[s\u2212 1][t] and D[s][t\u2212 1] \u2264 D[s\u2212 1][t\u2212 1] then\npath[s][t] = (s, t\u2212 1) end if D[s\u2212 1][t] \u2264 D[s\u2212 1][t\u2212 1] then\npath[s][t] = (s\u2212 1, t) else\npath[s][t] = (s\u2212 1, t\u2212 1) end end end w\u2217 = {} for s \u2208 {1, . . .m}, t \u2208 {1, . . .m} do\nw\u2217 = w\u2217 \u222a {\nargmin s,t\npath[s][t] }\nend for p \u2208 w\u2217 do\nXj (p[0]) = Xj (p[1]) end return Xj\nAlgorithm 2: Alignment Algorithm using DTWD"}, {"heading": "IV. SUBSEQUENCE DTW (DTWSUBSEQ)", "text": "An apparent drawback of DTWD is the overstatement of the dissimilarity between two copies of a time series when one copy is horizontally displaced. DTW cannot match the ends of the two copies without incurring a cost. For instance, a sine curve and cosine curve can be obtained from the same sinusoidal function due to sampling from a long series, but DTWD returns a positive value. This limits the functionality of DTWD as a similarity measure.\nTo alleviate this, we propose a modification to DTW based on subsequence matching [13]. We relax the boundary condition that the optimal path must start at the bottom left\nD[1, 1] and end at the top right D[m,m] of the distance matrix D.\nComputing all possible paths is computational expensive. To induce computational savings, we introduce a displacement window parameter dw, which is the maximum horizontal displacement of the samples. We restrict our search to paths that start and end within the window defined by dw. This parameter can be empirically estimated through the distribution of a common landmark in the data. For periodic data, the natural displacement window is the period.\nWe view similar time series as those having similar shape and frequency. Therefore, at each displacement k, we truncate both input series, Xi and Xj , to the same length. To obtain a distance with respect to the original length, for the truncated series, Xki and X k j , the resulting DTWD ( Xki , X k j ) is weighed proportionately to their length by\nDTWDk (Xi, Xj) = m\nm\u2212 k + 1 DTWD\n( Xki , X k j ) DTWsubseq, displayed below in Algorithm 3, is further\noptimized by imposing a bandwidth as in Fast DTW.\nData: time series Xi, Xj , displacement window dw, bandwidth bw Result: DTWsubseqD(Xi, Xj ; dw, bw) Initialize optD =\u221e for k \u2208 {1, . . . , dw} do\nXki = Xi[k : m] Xkj = Xj [1 : m\u2212 k + 1] Dk = DTWD\nk (Xi, Xj ; bw) if Dk < optD then\noptD = Dk end\nend return optD\nAlgorithm 3: Fast DTWsubseq"}, {"heading": "V. TEMPLATE SELECTION AND CLASSIFICATION", "text": ""}, {"heading": "A. Overview", "text": "As discussed in Section II, the standard approach to HAR classification first extracts features from the motion data time series, then classifies using these features with well-established algorithms. Working with the raw data in the time domain is preferable if it is sufficiently capable of capturing information about the data. We propose a method based on DTWsubseq and hierarchical clustering, which avoids intensive feature extraction, and can alleviate many of the problems with feature extraction discussed in Section II.\nOur approach to classification is to use the training data to build time series templates representing each activity, and subsequently classify the test data according to their similarity to these templates using DTWsubseqD. This type of templatebased method is robust to speed and style variations of the subjects\u2019 motions, and potentially requires less training data than feature-based methods [8].\nBefore giving details of how to construct templates, we present a general diagram of the full classification procedure illustrated in Figure 2."}, {"heading": "B. Cluster", "text": "For each activity, we use the training set to build clusters. There are two main parts of the clustering step:\n1) Computing the distance matrix by finding the DTWsubseqD between all pairs of points in each activity, 2) Forming clusters in hierarchical clustering by calculating distance between two clusters Ci and Cj is calculated as\nd(Ci, Cj) = max s\u2208Ci,t\u2208Cj DTWsubseqD(s, t),\nand removing flat clusters by restricting pairwise distances within a cluster to be below\ncut\u00d7 max Ci,Cj d(Ci, Cj).\nWe use hierarchical clustering as our clustering algorithm because of its flexibility in being able to perform with any similarity measure. Decreasing the parameter cut increases the number of clusters for each activity. We show results for different values of cut in Section VII."}, {"heading": "C. Build Templates", "text": "After computing clusters for each activity, we compute the average of a set of time series. We consider two methods for selecting templates: DTW Pointwise Averaging (DPA) and DTW Barycenter Averaging (DBA).\nWe provide the algorithm for DPA in Algorithm 4 and brief descriptions of DBA.\nDPA is a straightforward method for computing the average of a set of time series. The algorithm first finds the point with minimum distance to all other time series, aligns each time series to that point, and finally calculates a pointwise average.\nDBA is a global method that calculates an average series that minimizes the sum of squared DTW distances to all series in the cluster. In each iteration of the algorithm,\n1) Conduct DTW between the average series and each series in the cluster, and extract associations between the coordinates of the pair. 2) For each coordinate \u03b1 of the average series, update the corresponding value as the mean corresponding to all coordinates associated with \u03b1.\nData: Clusters C1, . . . , Cn Result: Templates T1, . . . , Tn for i \u2208 {1, . . . , n} do\nt\u2217 = min t \u2211 x\u2208Ci DTWsubseqD (x, t) for x \u2208 Ci do align(t\u2217, x) Ti = \u2016Ci\u2016\u22121\n\u2211 x\u2208Ci x\nend end return T1, . . . , Tn\nAlgorithm 4: DTW Pointwise Averaging\nDetails of the DBA algorithm can be found in [14]. DBA is more computationally intensive than DPA, but DBA has been shown to improve classification accuracy in centroidbased methods [15], and hence is included for comparison.\nIn the aligning and averaging portions of both algorithms, we used DTW instead of DTWsubseq because DTW would return similar warping paths while maintaining the length of the input series."}, {"heading": "D. Classify", "text": "For each training and test sample, we first compute DTWsubseqD to each template. This provides a vector of distances, which is the same size as the number of templates, for each sample. We treat this vector of distances as a feature vector, and proceed by running a dimensionality reduction algorithm (such as PCA) and a classifier (such as SVM) on the DTWsubseqD vectors."}, {"heading": "VI. REAL WORLD DATA AND SIMULATIONS", "text": ""}, {"heading": "A. UCI HAR Data", "text": "The dataset contains a total of 10,299 samples from 30 subjects conducting six activities in a lab: 3 dynamic activities (walking, walking upstairs, walking downstairs) and 3 static activities (sitting, standing, lying). We used 7,352 samples for training, and the remaining 2,947 samples for testing.\nEach reading (time series) is six dimensional with dimensions corresponding to acceleration (in ms\u22122), and angular velocity (in s\u22121) in the x-y-z axis. The range for the acceleration is [\u22121, 1] and the range for angular velocity is [\u22123, 3].\nThis data set is already preprocessed as provided by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window) [16]. Figure 3 depicts some curves after preprocessing.\nDue to the method of sampling, many of the resulting shortened curves in the static activity category are flat curves with no activity, and mis-informative for classification. Since these flat curves provide no additional information, we have removed them. A multidimensional time series will be considered as a flat curve if all of its dimensions are flat. A dimension of the time series is flat if its range (maximum value - minimal value) falls within the 5% quantile of all ranges of that dimension across all time series. Figure 4 depicts some curves which have been removed."}, {"heading": "B. Synthetic Data", "text": "This dataset is created to test the ability of our proposed method to classify time series belonging to new subjects, in the event of noise that may be present in this type of usage of smartphone sensors. In the simulation, we consider short bursts of noise in the observations, due to reasons such as jerky motions, sudden shifts of the sensor, and sensor noise.\nTraining data is generated from one dimension (Accx, Acceleration in the x-axis) of a random template, computed from the UCI HAR dataset, from each of the following activities: walking, walking upstairs, walking downstairs, sitting. This can be taken to represent the motion of one subject. Test data is generated from a different random template for each activity, to simulate motions from a different subject.\nThe training set has a total of 800 samples, 200 for each activity. The test set has 200 samples, 50 for each activity. Each sample is created from the template in the following manner:\n1) Accx of the template is extracted and normalized to zero mean and unit variance 2) Concatenate the template to length 256 3) Perform FFT on the resulting series 4) Generate a normally distributed N (0, 5) random vec-\ntor of length 10 and add it to a random location of the FFT\n5) Perform IFFT and retrieve the real part of the result 6) Sample a series of length 128\nFigure 5 contains two plots corresponding to training and test samples for the same activity. Two curves are plotted to show the effects of adding noise. Each reading (time series) is a one dimensional acceleration (in ms\u22122). The range for the acceleration is [\u22124, 4]."}, {"heading": "VII. RESULTS", "text": "In this section, we present the results on the UCI HAR dataset and synthetic data.\nWe examine templates generated by our method, and additionally study the benefit obtained from using different values of the cut parameter in the clustering stage. We plot templates corresponding to different clusters in the same activity to demonstrate the performance of our clustering and template construction methods. Templates are shown in Figure 6 and 7 for both DBA and DPA for the UCI dataset, and synthetic dataset.\nClassification accuracy is presented in Tables I and II. Each table shows the accuracy for all four combinations of distance method (DTW, DTWsubseq) and averaging method (DPA, DBA), and two different values of the cut parameter (0.25, 0.5)."}, {"heading": "VIII. DISCUSSION", "text": ""}, {"heading": "A. Comparison with Feature Extraction", "text": "We benchmark our procedure against standard feature extraction methods. We computed 568 features using mean,\nstandard deviation, correlation, RMSE from [4], Energy [17], average absolute difference [18], largest 5 FFT magnitudes, autocorrelation, kurtosis, skew from [7], autoregression coefficients [5], and number of zeros for the original time series, and first difference time series. We also computed the mean, standard deviation, kurtosis, and skew for the magnitudes of the FFT [16].\nWe performed standard classification on these features using PCA for dimensionality reduction and linear SVM as a classifier (same as in Section V-D). The results for classification on both synthetic data and the UCI dataset are shown in Table III.\nBefore comparing accuracy, we comment on a few advantages our method has over feature extraction. First, our methods have the natural advantage that no domain knowledge is required, compared to the importance of extracting the correct features. In order to achieve high accuracy using feature extraction, a large number of features need to be extracted (over 500). To achieve comparable accuracy, using DTW-DBA with cut = 0.25 our method builds around 220 templates, less than half the number of features. Second, some features such as autocorrelation increase with the length of the time series, and almost all features increase with p, the dimension of each point. The dimensionality of our method is only influenced by the number of templates, which can be fixed through the cut parameter. Third, our method has reduced computational complexity compared to feature extraction. Fast DTW has\ncomplexity O(m), whereas most features have computational complexity at least O(m), and some features such as autoregression coefficients have computational complexity \u2126 ( m2 ) ."}, {"heading": "B. UCI HAR Data", "text": "Figure 6 shows that our clustering scheme performs reasonably well in grouping differently-shaped curves. Both template methods are able to capture the shape of the data. In fact, the DPA and DBA templates appear very similar to one another.\nJudging from the classification accuracy results in Table I, for both cut = 0.5 and 0.25, DTW performs better with DBA, achieving 0.797 over 0.781 and 0.860 over 0.841 respectively. When cut = 0.25, DTWsubseq also does better with DBA, with accuracy 0.855 over 0.838. But when cut = 0.5, DTWsubseq performs better with DPA, achieving 0.789 over 0.777.\nOne possible reason why DBA did not consistently work better is that the starting average sequence in DPA is initialized using the same similarity measure (DTWD, DTWsubseqD) as is used for clustering. The starting average sequence in DBA is initialized with a random candidate in the cluster, as suggested in the original paper [14].\nIt\u2019s possible that with a few modifications, such as picking the right initializing series for DBA, DTWsubseq-DBA with cut = 0.5 could achieve higher accuracy as it performs well in distinguishing between static and dynamic activities. It makes only 22 classification errors between static and dynamic activities, comparable to DTWsubseq-DPA, and has comparable accuracy when considering 4 activities as shown in parentheses in Table I.\nThe effects of lowering the cut threshold are clear-cut. As expected, lowering the threshold (and increasing the number of clusters) increased accuracy . With original DTW we see an increase in accuracy from 0.781 to 0.841 with DPA, and subsequently up to 0.86 with DBA. Using DTWsubseq, we see an increase with DBA, and a smaller increase with DPA. This may primarily be due to overfitting. Decreasing cut from 0.5 to 0.25 increase the number of templates from around 50 to over 500.\nThe highest accuracy our method achieved was 0.860 using DTW-DBA with cut = 0.25, which is comparable to the feature extraction method which had a test accuracy of 0.890. One possibility is that the flat curves in static activities have not been sufficiently removed. The static activity curves usually have a spike, then remain flat. As some flat portions still remain in our training and test sets, all 3 static activities contain flat templates and hence induce high classification error within themselves. This is evidenced by the confusion matrix for DTW-DBA shown in Table IV where there are lots of misclassifications between activities 3-5, especially for activity 5.\nHowever, we find that our methods are capable of performing better than feature extraction when we circumvent the issue of the flat templates. Looking at the values in parenthesis in Table I where we perform a 4-category classification of walking, walking upstairs, walking downstairs and static activities, all our methods with cut = 0.25 outperforms feature extraction\u2019s 0.965 accuracy. DTW-DBA and DTWsubseq-DBA perform the best with 0.977.\nSummarizing the results of our method on the UCI HAR dataset, compared with benchmark feature extraction method, we see that our accuracy rates are similar for six activities and better for four activities. Within our template-based methods, we see that there is no clear improvement using DPA versus DBA, and there is a slight overall improvement using DTWsubseq over DTW. Finally, we see that in all cases decreasing the cut parameter increases accuracy."}, {"heading": "C. Synthetic Data", "text": "Our synthetic data experiments reflect the satisfactory performance of our methods in the event of noisy data and new test subjects not present in the training phase.\nComparing template construction, Figure 7 shows that templates created using DBA are significantly more robust to sporadic noise than those created by DPA. The samples in Figure 7 are created from a single time series and modified by adding noise at a small region of the curve. DBA successfully accounts for this, as its template is identical to all curves at points other than the noisy region, and its shape matches the noisy region fairly well. On the other hand, DPA fails to capture the identical shape of the curve as it underestimates the magnitudes of the peaks and troughs.\nHowever, because the test data is constructed from a different template (simulating a different person), DBA overfits to the training data. All methods with DPA perform similarly or better than with DBA. With DPA instead of DBA, DTWsubseq achieves 0.650 over 0.640 with cut = 0.5, and 0.700 over 0.655 with cut = 0.25. DTW performs similarly with DPA and DBA with 0.615 and 0.620 respectively, and better with DPA for cut = 0.25 obtaining 0.615 over 0.580.\nThe cut threshold follows similar trends as in the UCI dataset, except that cut = 0.25 for DTW-DBA achieves lower accuracy than cut = 0.5. This is likely due to overfitting as the number of templates created was around 400.\nOur method achieves the highest accuracy using DTWsubseq-DPA with cut = 0.25 (0.700), 3% higher than that of feature extraction (0.67). This gives good indication that our method is potentially suitable for realworld applications, since it is more robust to noise than feature extraction, and is better at generalizing to data from new test subjects.\nSummarizing the results of our method on the synthetic dataset, we see our method achieves higher accuracy than\nbenchmark feature extraction. Within the template-based methods, we again see that there is no clear improvement using DPA versus DBA, but there is an improvement using DTWsubseq over DTW. Finally, we see that in almost all cases, decreasing the cut parameter increases accuracy as expected."}, {"heading": "D. Summary of Results", "text": "We summarize the accuracy results obtained using our algorithm for clarity in Table V. We see that our algorithm\u2019s accuracy is comparable to feature extraction\u2019s, and performs better in most cases."}, {"heading": "IX. CONCLUSION", "text": "In this paper, we presented modifications to DTW as a more accurate time series similarity measure, as well as a template-based approach for Human Activity Recognition. Through experiments on both real data and synthetic data, we show that our approach gives comparable and sometimes even better classification accuracy than the most common method of feature extraction. As compared to feature extraction on real data, our approach has comparable overall test accuracy, and better accuracy within activities in the dynamic category. For the synthetic data, it achieved higher accuracy, indicating robustness to noise and the ability to classify data from new test subjects. This is an especially useful feature for real-life implementations of such classification algorithms, for instance on a smartphone app.\nFurthermore, the application of our approach extends beyond HAR, as long as the data set satisfies our definition of multi-dimensional time series. Since the template-based approach allows us to extract features without domain knowledge, it can be readily applied to these new datasets, unlike feature extraction methods which requires careful determination of useful features to achieve good accuracy."}, {"heading": "X. FUTURE WORK", "text": "We plan to improve our activity recognition and template usage in several ways. Potential directions include: modifying DTW to learn more complex activities, cross validating parameters in hierarchical clustering and DTW such as cut or bandwidth bw to increase prediction accuracy, removing redundant templates and limiting overfitting, and creating synthetic data from templates which can increase predictive power, or be used in place of real-world data.\nSince the work presented in this paper is not specific to HAR applications, we also plan to apply and evaluate our algorithm on sequential data in other domains of research."}], "references": [{"title": "Detecting falls with wearable sensors using machine learning techniques", "author": ["A.T. Ozdemir", "B. Barshan"], "venue": "Sensors, vol. 14, no. 6, pp. 10 691\u201310 708, 2014. [Online]. Available: http://www.mdpi.com/ 1424-8220/14/6/10691", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "Machine learning methods for classifying human physical activity from on-body accelerometers", "author": ["A. Mannini", "A.M. Sabatini"], "venue": "Sensors, vol. 10, no. 2, pp. 1154\u20131175, 2010.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "Interval and dynamic time warpingbased decision trees", "author": ["J.J. Rodr\u0131\u0301guez", "C.J. Alonso"], "venue": "Proceedings of the 2004 ACM symposium on Applied computing. ACM, 2004, pp. 548\u2013552.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2004}, {"title": "Human motion recognition using a wireless sensor-based wearable system", "author": ["J.P. Varkey", "D. Pompili", "T.A. Walls"], "venue": "Personal and Ubiquitous Computing, vol. 16, no. 7, pp. 897\u2013910, Oct. 2012. [Online]. Available: http://link.springer.com/article/10.1007/s00779-011-0455-4", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "A triaxial accelerometer-based physical-activity recognition via augmented-signal features and a hierarchical recognizer", "author": ["A.M. Khan", "Y.-K. Lee", "S.Y. Lee", "T.-S. Kim"], "venue": "Information Technology in Biomedicine, IEEE Transactions on, vol. 14, no. 5, pp. 1166\u20131172, 2010.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Simple and complex activity recognition through smart phones", "author": ["S. Dernbach", "B. Das", "N.C. Krishnan", "B.L. Thomas", "D.J. Cook"], "venue": "Intelligent Environments (IE), 2012 8th International Conference on. IEEE, 2012, pp. 214\u2013221.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Comparative study on classifying human activities with miniature inertial and magnetic sensors", "author": ["K. Altun", "B. Barshan", "O. Tun\u00e7el"], "venue": "Pattern Recognition, vol. 43, no. 10, pp. 3605\u20133620, 2010.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Human action recognition using dynamic time warping", "author": ["S. Sempena", "N. Maulidevi", "P. Aryan"], "venue": "Electrical Engineering and Informatics (ICEEI), 2011 International Conference on, July 2011, pp. 1\u20135.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Generalized time warping for multimodal alignment of human motion", "author": ["F. Zhou", "F. De la Torre"], "venue": "Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, June 2012, pp. 1282\u2013 1289.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Information Retrieval for Music and Motion", "author": ["M. M\u00fcller"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2007}, {"title": "Toward accurate dynamic time warping in linear time and space", "author": ["S. Salvador", "P. Chan"], "venue": "Intelligent Data Analysis, vol. 11, no. 5, pp. 561\u2013580, 2007.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "Multivariate time series classification with parametric derivative dynamic time warping", "author": ["T. G\u00f3recki", "M. Luczak"], "venue": "Expert Systems with Applications, vol. 42, no. 5, pp. 2305 \u2013 2312, 2015. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S0957417414006927", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Computing and visualizing dynamic time warping alignments in r: The dtw package", "author": ["T. Giorgino"], "venue": "Journal of Statistical Software, vol. 31, no. 7, pp. 1\u201324, 8 2009. [Online]. Available: http: //www.jstatsoft.org/v31/i07", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "A global averaging method for dynamic time warping, with applications to clustering", "author": ["F. Petitjean", "A. Ketterlin", "P. Ganarski"], "venue": "Pattern Recognition, vol. 44, no. 3, pp. 678 \u2013 693, 2011. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S003132031000453X", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Dynamic time warping averaging of time series allows faster and more accurate classification", "author": ["F. Petitjean", "G. Forestier", "G. Webb", "A. Nicholson", "Y. Chen", "E. Keogh"], "venue": "Data Mining (ICDM), 2014 IEEE International Conference on, Dec 2014, pp. 470\u2013479.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "A public domain dataset for human activity recognition using smartphones", "author": ["D. Anguita", "A. Ghio", "L. Oneto", "X. Parra", "J.L. Reyes-Ortiz"], "venue": "21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN, April 2013.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Activity recognition from accelerometer data", "author": ["N. Ravi", "N. Dandekar", "P. Mysore", "M.L. Littman"], "venue": "Proceedings of the 17th Conference on Innovative Applications of Artificial Intelligence - Volume 3, ser. IAAI\u201905. AAAI Press, 2005, pp. 1541\u20131546. [Online]. Available: http://dl.acm.org/citation.cfm?id=1620092.1620107", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2005}, {"title": "Activity recognition using cell phone accelerometers", "author": ["J.R. Kwapisz", "G.M. Weiss", "S.A. Moore"], "venue": "ACM SigKDD Explorations Newsletter, vol. 12, no. 2, pp. 74\u201382, 2011.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": "Examples of some current uses are fall detection in medical or home settings [1], and Human Activity Recognition (HAR) for smart health-monitoring systems [2].", "startOffset": 77, "endOffset": 80}, {"referenceID": 1, "context": "Examples of some current uses are fall detection in medical or home settings [1], and Human Activity Recognition (HAR) for smart health-monitoring systems [2].", "startOffset": 155, "endOffset": 158}, {"referenceID": 2, "context": "DTW has recently been widely used and integrated with other methods such as decision trees [3] in machine learning.", "startOffset": 91, "endOffset": 94}, {"referenceID": 0, "context": "Furthermore, on-body sensors can be placed at more assigned locations on the body such as arms and ankles, and may include more components such as magnetometer [1].", "startOffset": 160, "endOffset": 163}, {"referenceID": 3, "context": "between values of modality axes [4].", "startOffset": 32, "endOffset": 35}, {"referenceID": 4, "context": "Another suggested option is using autoregressive modeling to form augmented-feature vectors [5].", "startOffset": 92, "endOffset": 95}, {"referenceID": 1, "context": "Following feature extraction, algorithms used for classification include Hidden Markov Models [2], Support Vector Machines [4], Multi-layer Perceptron, Naive Bayes, Bayesian Network, Decision Table, Best-First Tree, and K-star [6].", "startOffset": 94, "endOffset": 97}, {"referenceID": 3, "context": "Following feature extraction, algorithms used for classification include Hidden Markov Models [2], Support Vector Machines [4], Multi-layer Perceptron, Naive Bayes, Bayesian Network, Decision Table, Best-First Tree, and K-star [6].", "startOffset": 123, "endOffset": 126}, {"referenceID": 5, "context": "Following feature extraction, algorithms used for classification include Hidden Markov Models [2], Support Vector Machines [4], Multi-layer Perceptron, Naive Bayes, Bayesian Network, Decision Table, Best-First Tree, and K-star [6].", "startOffset": 227, "endOffset": 230}, {"referenceID": 6, "context": "Comparative study across these algorithms has also been done [7].", "startOffset": 61, "endOffset": 64}, {"referenceID": 7, "context": "Current DTW methods on HAR involve aligning human behavior in video data [8].", "startOffset": 73, "endOffset": 76}, {"referenceID": 8, "context": "These methods use a generalized time warping mechanism to extend DTW to aligning multimodal sequences [9].", "startOffset": 102, "endOffset": 105}, {"referenceID": 7, "context": "It is used in applications such as speech recognition, and video activity recognition [8].", "startOffset": 86, "endOffset": 89}, {"referenceID": 9, "context": "1: [10] A warping path is a sequence w = (w1, .", "startOffset": 3, "endOffset": 7}, {"referenceID": 10, "context": "This version of DTW is called FastDTW [11].", "startOffset": 38, "endOffset": 42}, {"referenceID": 0, "context": "Data: time series Xi, Xj , bandwidth bw Result: DTWD(Xi, Xj ; bw) Initialize distance matrix D = 0m\u00d7m D[1, 1] = |Xi(1)\u2212Xj(1)| for s \u2208 {2, .", "startOffset": 103, "endOffset": 109}, {"referenceID": 0, "context": "Data: time series Xi, Xj , bandwidth bw Result: DTWD(Xi, Xj ; bw) Initialize distance matrix D = 0m\u00d7m D[1, 1] = |Xi(1)\u2212Xj(1)| for s \u2208 {2, .", "startOffset": 103, "endOffset": 109}, {"referenceID": 11, "context": "The algorithm also returns the sum of the pointwise distances along the optimal path [12].", "startOffset": 85, "endOffset": 89}, {"referenceID": 11, "context": "1: DTW image from [12] showing the alignment procedure.", "startOffset": 18, "endOffset": 22}, {"referenceID": 0, "context": "end for p \u2208 w\u2217 do Xj (p[0]) = Xj (p[1]) end return Xj", "startOffset": 35, "endOffset": 38}, {"referenceID": 12, "context": "To alleviate this, we propose a modification to DTW based on subsequence matching [13].", "startOffset": 82, "endOffset": 86}, {"referenceID": 0, "context": "We relax the boundary condition that the optimal path must start at the bottom left D[1, 1] and end at the top right D[m,m] of the distance matrix D.", "startOffset": 85, "endOffset": 91}, {"referenceID": 0, "context": "We relax the boundary condition that the optimal path must start at the bottom left D[1, 1] and end at the top right D[m,m] of the distance matrix D.", "startOffset": 85, "endOffset": 91}, {"referenceID": 7, "context": "This type of templatebased method is robust to speed and style variations of the subjects\u2019 motions, and potentially requires less training data than feature-based methods [8].", "startOffset": 171, "endOffset": 174}, {"referenceID": 13, "context": "Details of the DBA algorithm can be found in [14].", "startOffset": 45, "endOffset": 49}, {"referenceID": 14, "context": "DBA is more computationally intensive than DPA, but DBA has been shown to improve classification accuracy in centroidbased methods [15], and hence is included for comparison.", "startOffset": 131, "endOffset": 135}, {"referenceID": 15, "context": "56 sec and 50% overlap (128 readings/window) [16].", "startOffset": 45, "endOffset": 49}, {"referenceID": 3, "context": "standard deviation, correlation, RMSE from [4], Energy [17], average absolute difference [18], largest 5 FFT magnitudes, autocorrelation, kurtosis, skew from [7], autoregression coefficients [5], and number of zeros for the original time series, and first difference time series.", "startOffset": 43, "endOffset": 46}, {"referenceID": 16, "context": "standard deviation, correlation, RMSE from [4], Energy [17], average absolute difference [18], largest 5 FFT magnitudes, autocorrelation, kurtosis, skew from [7], autoregression coefficients [5], and number of zeros for the original time series, and first difference time series.", "startOffset": 55, "endOffset": 59}, {"referenceID": 17, "context": "standard deviation, correlation, RMSE from [4], Energy [17], average absolute difference [18], largest 5 FFT magnitudes, autocorrelation, kurtosis, skew from [7], autoregression coefficients [5], and number of zeros for the original time series, and first difference time series.", "startOffset": 89, "endOffset": 93}, {"referenceID": 6, "context": "standard deviation, correlation, RMSE from [4], Energy [17], average absolute difference [18], largest 5 FFT magnitudes, autocorrelation, kurtosis, skew from [7], autoregression coefficients [5], and number of zeros for the original time series, and first difference time series.", "startOffset": 158, "endOffset": 161}, {"referenceID": 4, "context": "standard deviation, correlation, RMSE from [4], Energy [17], average absolute difference [18], largest 5 FFT magnitudes, autocorrelation, kurtosis, skew from [7], autoregression coefficients [5], and number of zeros for the original time series, and first difference time series.", "startOffset": 191, "endOffset": 194}, {"referenceID": 15, "context": "We also computed the mean, standard deviation, kurtosis, and skew for the magnitudes of the FFT [16].", "startOffset": 96, "endOffset": 100}, {"referenceID": 13, "context": "The starting average sequence in DBA is initialized with a random candidate in the cluster, as suggested in the original paper [14].", "startOffset": 127, "endOffset": 131}], "year": 2015, "abstractText": "Accurate and computationally efficient means for classifying human activities have been the subject of extensive research efforts. Most current research focuses on extracting complex features to achieve high classification accuracy. We propose a template selection approach based on Dynamic Time Warping, such that complex feature extraction and domain knowledge is avoided. We demonstrate the predictive capability of the algorithm on both simulated and real smartphone data.", "creator": "TeX"}}}