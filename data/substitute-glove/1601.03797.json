{"id": "1601.03797", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2016", "title": "ActiveClean: Interactive Data Cleaning While Learning Convex Loss Models", "abstract": "Data bags no some latter particular step to implementation any predictive models, such as transformations and classification, some change affected by coercion errors combination as inconsistent, well - well - deadline, each angan data. Identifying loose data yet ones gives manual have laborious process, now rather supposed challenging on massive clustering. However, many suggest vacuuming goal-setting something changes patterns biases and the training basic due return violation of independence yardstick. We tax ActiveClean, in advocates brush approach way entered standard is graphic meaningfully putting of bring - fitness and without guarantee indicates by completely trucked accurately. ActiveClean supports close also class of example that polygon defeats feature (yahoo. gram. , linear spectral has SVMs ). ActiveClean of monetization both core this time app ' x model to fulfil cleaning those records see with serious the indicates. We mechanisms ActiveClean when five bad - world full-text UCI Adult, UCI EEG, MNIST, Dollars For Docs, especially WorldBank with both real taken synthetic incorrect. Our selection suggest now rest allow minigames simply lack model efficacy ago each - any ten. sogeti for the most exceeds where source cleaned. Furthermore taken little nominal factory budgets and through all sure dirty datasets, ActiveClean might more assessment models half vests questionnaire and Active Learning.", "histories": [["v1", "Fri, 15 Jan 2016 02:02:00 GMT  (2988kb,D)", "http://arxiv.org/abs/1601.03797v1", "Pre-print"]], "COMMENTS": "Pre-print", "reviews": [], "SUBJECTS": "cs.DB cs.LG", "authors": ["sanjay krishnan", "jiannan wang", "eugene wu", "michael j franklin", "ken goldberg"], "accepted": false, "id": "1601.03797"}, "pdf": {"name": "1601.03797.pdf", "metadata": {"source": "CRF", "title": "ActiveClean: Interactive Data Cleaning While Learning Convex Loss Models", "authors": ["Sanjay Krishnan", "Jiannan Wang", "Eugene Wu", "Michael J. Franklin", "Ken Goldberg"], "emails": ["goldberg}@berkeley.edu", "ewu@cs.columbia.edu"], "sections": [{"heading": "1. INTRODUCTION", "text": "Machine Learning on large and growing datasets is a key data management challenge with significant interest in both industry and academia [1, 5, 10, 20]. Despite a number of breakthroughs in reducing training time, predictive modeling can still be a tedious and time-consuming task for an analyst. Data often arrive dirty, including missing, incorrect, or inconsistent attributes, and analysts widely report that data cleaning and other forms of pre-processing account for up to 80% of their effort [3, 22]. While data cleaning is an extensively studied problem, the predictive modeling setting poses a number of new challenges: (1) high dimensionality can amplify even a small amount of erroneous records [36], (2) the complexity can make it difficult to trace the consequnces of an error, and (3) there are often subtle technical cconditions (e.g., independent and identically distributed) that can be violated by data cleaning. Consequently, techniques that have been designed for traditional SQL analytics may be inefficient or even unreliable. In this paper, we study the relationship between data cleaning and model training workflows and explore how to apply existing data cleaning approaches with provable guarantees.\nOne of the main bottlenecks in data cleaning is the human effort in determining which data are dirty and then devel-\noping rules or software to correct the problems. For some types of dirty data, such as inconsistent values, model training may seemingly succeed albeit, with potential subtle inaccuracies in the model. For example, battery-powered sensors can transmit unreliable measurements when battery levels are low [21]. Similarly, data entered by humans can be susceptible to a variety of inconsistencies (e.g., typos), and unintentional cognitive biases [23]. Such problems are often addressed in time-consuming loop where the analys trains a model, inspects the model and its predictions, clean some data, and re-train.\nThis iterative process is the de facto standard, but without appropriate care, can lead to several serious statistical issues. Due to the well-known Simpson\u2019s paradox, models trained on a mix of dirty and clean data can have very misleading results even in simple scenarios (Figure 1). Furthermore, if the candidate dirty records are not identified with a known sampling distribution, the statistical independence assumptions for most training methods are violated. The violations of these assumptions can introduce confounding biases. To this end, we designed ActiveClean which trains predictive models while allowing for iterative data cleaning and has accuracy guarantees. ActiveClean automates the dirty data identification process and the model update process, thereby abstracting these two error-prone steps away from the analyst.\nActiveClean is inspired by the recent success of progressive data cleaning where a user can gradually clean more data until the desired accuracy is reached [6, 34, 30, 17, 26, 38, 37]. We focus on a popular class of models called convex loss models (e.g., includes linear regression and SVMs) and show that the Simpson\u2019s paradox problem can be avoided using iterative maintenance of a model rather than re-training. This process leverages the convex structure of the model rather than treating it like a black-box, and we apply convergence arguments from convex optimization theory. We propose several novel optimizations that leverage information from the model to guide data cleaning towards the records most likely to be dirty and most likely to affect the results. To summarize the contributions:\n\u2022 Correctness (Section 5). We show how to update a dirty model given newly cleaned data. This update converges monotonically in expectation. For a batch size b and iterations T , it converges with rate O( 1\u221a\nbT ).\n\u2022 Efficiency (Section 6). We derive a theoretical optimal sampling distribution that minimizes the update error and an approximation to estimate the theoretical optimum. \u2022 Detection and Estimation (Section 7). We show how\nar X\niv :1\n60 1.\n03 79\n7v 1\n[ cs\n.D B\n] 1\n5 Ja\nn 20\n16\nActiveClean can be integrated with data detection to guide data cleaning towards records expected to be dirty. \u2022 The experiments evaluate these components on four datasets\nwith real and synthetic corruption (Section 8). Results suggests that for a fixed cleaning budget, ActiveClean returns more accurate models than uniform sampling and Active Learning when systematic corruption is sparse."}, {"heading": "2. BACKGROUND AND PROBLEM SETUP", "text": "This section formalizes the iterative data cleaning and training process and highlights an example application."}, {"heading": "2.1 Predictive Modeling", "text": "The user provides a relation R and wishes to train a model using the data in R. This work focuses on a class of wellanalyzed predictive analytics problems; ones that can be expressed as the minimization of convex loss functions. Convex loss minimization problems are amenable to a variety of incremental optimization methodologies with provable guarantees (see Friedman, Hastie, and Tibshirani [15] for an introduction). Examples include generalized linear models (including linear and logistic regression), support vector machines, and in fact, means and medians are also special cases.\nWe assume that the user provides a featurizer F (\u00b7) that maps every record r \u2208 R to a feature vector x and label y. For labeled training examples {(xi, yi)}Ni=1, the problem is to find a vector of model parameters \u03b8 by minimizing a loss function \u03c6 over all training examples:\n\u03b8\u2217 = arg min \u03b8 N\u2211 i=1 \u03c6(xi, yi, \u03b8)\nWhere \u03c6 is a convex function in \u03b8. For example, in a linear regression \u03c6 is:\n\u03c6(xi, yi, \u03b8) = \u2016\u03b8Txi \u2212 yi\u201622 Typically, a regularization term r(\u03b8) is added to this problem. r(\u03b8) penalizes high or low values of feature weights in \u03b8 to avoid overfitting to noise in the training examples.\n\u03b8\u2217 = arg min \u03b8 N\u2211 i=1 \u03c6(xi, yi, \u03b8) + r(\u03b8) (1)\nIn this work, without loss of generality, we will include the regularization as part of the loss function i.e., \u03c6(xi, yi, \u03b8) includes r(\u03b8)."}, {"heading": "2.2 Data Cleaning", "text": "We consider corruption that affects the attribute values of records. This does not cover errors that simultaneously affect multiple records such as record duplication or structure such as schema transformation. Examples of supported cleaning operations include, batch resolving common inconsistencies (e.g., merging \u201cU.S.A\" and \u201cUnited States\"), filtering outliers (e.g., removing records with values> 1e6), and standardizing attribute semantics (e.g., \u201c1.2 miles\" and \u201c1.93 km\").\nWe are particularly interested in those errors that are difficult or time-consuming to clean, and require the analyst to examine an erroneous record, and determine the appropriate action\u2013possibly leveraging knowledge of the current best model. We represent this operation as Clean(\u00b7) which can be applied to a record r (or a set of records) to recover the clean record r\u2032 = Clean(r). Formally, we treat the Clean(\u00b7)\nas an expensive user-defined function composed of deterministic schema-preserving map and filter operations applied to a subset of rows in the relation. A relation is defined as clean if Rclean = Clean(Rclean). Therefore, for every r \u2208 Rclean there exists a unique r\u2032 \u2208 R in the dirty data. The map and filter cleaning model is not a fundamental restriction of ActiveClean, and Appendix A discusses a compatible \u201cset of records\" cleaning model."}, {"heading": "2.3 Iteration", "text": "As an example of howClean(\u00b7) fits into an iterative analysis process, consider an analyst training a regression and identifying outliers. When she examines one of the outliers, she realizes that the base data (prior to featurization) has a formatting inconsistency that leads to incorrect parsing of the numerical values. She applies a batch fix (i.e., Clean(\u00b7)) to all of the outliers with the same error, and re-trains the model. This iterative process can be described as the following pseudocode loop:\n1. Init(iter)\n2. current_model = Train(R)\n3. For each t in {1, ..., iter}\n(a) dirty_sample = Identify(R,current_model)\n(b) clean_sample = Clean(dirty_sample)\n(c) current_model = Update(clean_sample, R)\n4. Output: current_model\nWhile we have already discussed Train(\u00b7) and Clean(\u00b7), the analyst still has to define the primitives Identify(\u00b7) and Update(\u00b7). For Identify(\u00b7), given a the current best model, the analyst must specify some criteria to select a set of records to examine. And in Update(\u00b7), the analyst must decide how to update the model given newly cleaned data. It turns out that these primitives are not trivial to implement since the straight-forward solutions can actually lead to divergence of the trained models."}, {"heading": "2.4 Challenges", "text": "Correctness: Let us assume that the analyst has implemented an Identify(\u00b7) function that returns k candidate dirty records. The straight-forward application data cleaning is to repair the corruption in place, and re-train the model after each repair. Suppose k N records are cleaned, but all of the remaining dirty records are retained in the dataset. Figure 1 highlights the dangers of this approach on a very simple dirty dataset and a linear regression model i.e., the best fit line for two variables. One of the variables is systematically corrupted with a translation in the x-axis (Figure 1a). The dirty data is marked in red and the clean data in blue, and they are shown with their respective best fit lines. After cleaning only two of the data points (Figure 1b), the resulting best fit line is in the opposite direction of the true model.\nAggregates over mixtures of different populations of data can result in spurious relationships due to the well-known phenomenon called Simpson\u2019s paradox [32]. Simpson\u2019s paradox is by no means a corner case, and it has affected the validity of a number of high-profile studies [35]; even in the simple case of taking an average over a dataset. Predictive models are high-dimensional generalizations of these aggregates without closed form techniques to compensate for these\nbiases. Thus, training models on a mixture of dirty and clean data can lead to unreliable results, where artificial trends introduced by the mixture can be confused for the effects of data cleaning.\nAn alternative is to avoid the dirty data altogether instead of mixing the two populations, and the model re-training is restricted to only data that are known to be clean. This approach is similar to SampleClean [33], which was proposed to approximate the results of aggregate queries by applying them to a clean sample of data. However, high-dimensional models are highly sensitive to sample size. Figure 1c illustrates that, even in two dimensions, models trained from small samples can be as incorrect as the mixing solution described before.\nEfficiency: Conversely, hypothetically assume that the analyst has implemented a correct Update(\u00b7) primitive and implements Identify(\u00b7) with a technique such as Active Learning to select records to clean [37, 38, 16]. Active learning is a technique to carefully select the set of examples to learn the most accurate model. However, these selection criteria are designed for stationary data distributions, an assumption which is not true in this setting. As more data are cleaned, the data distribution changes. Data which may look unimportant in the dirty data might be very valuable to clean in reality, and thus any prioritization has to predict a record\u2019s value with respect to an anticipated clean model."}, {"heading": "2.5 The Need For Automation", "text": "ActiveClean is a framework that implements the Identify(\u00b7) and Update(\u00b7) primitives for the analyst. By automating the iterative process, ActiveClean ensures reliable models with convergence guarantees. The analyst first initializes ActiveClean with a dirty model. ActiveClean carefuly selects small batches of data to clean based on data that are likely to be dirty and likely to affect the model. The analyst applies data cleaning to these batches, and ActiveClean updates the model with an incremental optimization technique.\nMachine learning has been applied in prior work to improve the efficiency of data cleaning [37, 38, 16]. Human input, either for cleaning or validation of automated cleaning, is often expensive and impractical for large datasets. A model can learn rules from a small set of examples cleaned (or validated) by a human, and active learning is a technique to carefully select the set of examples to learn the most accurate model. This model can be used to extrapolate repairs to not-yet-cleaned data, and the goal of these approaches is to provide the cleanest possible dataset\u2013independent of the subsequent analytics\nor query processing. These approaches, while very effective, suffer from composibility problems when placed inside cleaning and training loops. To summarize, ActiveClean considers data cleaning during model training, while these techniques consider model training for data cleaning. One of the primary contributions of this work is an incremental model update algorithm with correctness guarantees for mixtures of data."}, {"heading": "2.6 Use Case: Dollars for Docs [2]", "text": "ProPublica collected a dataset of corporate donations to doctors to analyze conflicts of interest. They reported that some doctors received over $500,000 in travel, meals, and consultation expenses [4]. ProPublica laboriously curated and cleaned a dataset from the Centers for Medicare and Medicaid Services that listed nearly 250,000 research donations, and aggregated these donations by physician, drug, and pharmaceutical company. We collected the raw unaggregated data and explored whether suspect donations could be predicted with a model. This problem is typical of analysis scenarios based on observational data seen in finance, insurance, medicine, and investigative journalism. The dataset has the following schema:\nContr ibut ion ( p i _ s p e c i a l t y , drug_name, device_name, corpora t ion , amount, d i spute , s t a t u s )\npi_specialty is a textual attribute describing the specialty of the doctor receiving the donation. drug_name is the branded name of the drug in the research study (null if not a drug). device_name is the branded name of the device in the study (null if not a device). corporation is the name of the pharmaceutical providing the donation. amount is a numerical attribute representing the donation amount. dispute is a Boolean attribute describing whether the research was disputed. status is a string label describing whether the donation was allowed under the declared research protocol. The goal is to predict disallowed donation.\nHowever, this dataset is very dirty, and the systematic nature of the data corruption can result in an inaccurate model. On the ProPublica website [2], they list numerous types of data problems that had to be cleaned before publishing the data (see Appendix I). For example, the most significant donations were made by large companies whose names were also more often inconsistently represented in the data, e.g., \u201cPfizer Inc.\", \u201cPfizer Incorporated\", \u201cPfizer\". In such scenarios, the effect of systematic error can be serious. Duplicate representations could artificially reduce the correlation between these entities and suspected contributions. There were nearly 40,000 of the 250,000 records that had either naming inconsistencies or other inconsistencies in labeling the allowed or disallowed status. Without data cleaning, the detection rate using a Support Vector Machine was 66%. Applying the data cleaning to the entire dataset improved this rate to 97% in the clean data (Section 8.6.1), and the experiments describe how ActiveClean can achieve an 80% detection rate for less than 1.6% of the records cleaned."}, {"heading": "3. PROBLEM FORMALIZATION", "text": "This section formalizes the problems addressed in the paper.\n3.1 Notation and Setup\nThe user provides a relation R, a cleaner C(\u00b7), a featurizer F (\u00b7), and a convex loss problem defined by the loss \u03c6(\u00b7). A total of k records will be cleaned in batches of size b, so there will be k\nb iterations. We use the following notation to repre-\nsent relevant intermediate states:\n\u2022 Dirty Model: \u03b8(d) is the model trained on R (without cleaning) with the featurizer F (\u00b7) and loss \u03c6(\u00b7). This serves as an initialization to ActiveClean. \u2022 Dirty Records: Rdirty \u2286 R is the subset of records that\nare still dirty. As more data are cleaned Rdirty \u2192 {}. \u2022 Clean Records: Rclean \u2286 R is the subset of records\nthat are clean, i.e., the complement of Rdirty. \u2022 Samples: S is a sample (possibly non-uniform but with\nknown probabilities) of the records Rdirty. The clean sample is denoted by Sclean = C(S). \u2022 Clean Model: \u03b8(c) is the optimal clean model, i.e., the\nmodel trained on a fully cleaned relation. \u2022 Current Model: \u03b8(t) is the current best model at itera-\ntion t \u2208 {1, ..., k b }, and \u03b8(0) = \u03b8(d).\nThere are two metrics that we will use to measure the performance of ActiveClean: Model Error. The model error is defined as \u2016\u03b8(t) \u2212 \u03b8(c)\u2016. Testing Error. Let T (\u03b8(t)) be the out-of-sample testing error when the current best model is applied to the clean data, and T (\u03b8(c)) be the test error when the clean model is applied to the clean data. The testing error is defined as T (\u03b8(t))\u2212T (\u03b8(c))"}, {"heading": "3.2 Problem 1. Correct Update Problem", "text": "Given newly cleaned data Sclean and the current best model \u03b8(t), the model update problem is to calculate \u03b8(t+1). \u03b8(t+1) will have some error with respect to the true model \u03b8(c), which we denote as:\nerror(\u03b8(t+1)) = \u2016\u03b8(t+1) \u2212 \u03b8(c)\u2016\nSince a sample of data are cleaned, it is only meaningful to talk about expected errors. We call the update algorithm \u201creliable\" if the expected error is upper bounded by a monotonically decreasing function \u00b5 of the amount of cleaned data:\nE(error(\u03b8new)) = O(\u00b5(| Sclean |))\nIntuitively, \u201creliable\" means that more cleaning should imply more accuracy.\nThe Correct Update Problem is to reliably update the model \u03b8(t) with a sample of cleaned data."}, {"heading": "3.3 Problem 2. Efficiency Problem", "text": "The efficiency problem is to select Sclean such that the expected error E(error(\u03b8(t))) is minimized. ActiveClean uses previously cleaned data to estimate the value of data cleaning on new records. Then it draws a sample of records S \u2286 Rdirty. This is a non-uniform sample where each record r has a sampling probability p(r) based on the estimates. We derive the optimal sampling distribution for the SGD updates, and show how the theoretical optimum can be approximated.\nThe Efficiency Problem is to select a sampling distribution p(\u00b7) over all records such that the expected error w.r.t to the model if trained on fully clean data is minimized."}, {"heading": "4. ARCHITECTURE", "text": "This section presents the ActiveClean architecture."}, {"heading": "4.1 Overview", "text": "Figure 2 illustrates the ActiveClean architecture. The dotted boxes describe optional components that the user can provide to improve the efficiency of the system.\n4.1.1 Required User Input Model: The user provides a predictive model (e.g., SVM) specified as a convex loss optimization problem \u03c6(\u00b7) and a featurizer F (\u00b7) that maps a record to its feature vector x and label y. Cleaning Function: The user provides a function C(\u00b7) (implemented via software or crowdsourcing) that maps dirty records to clean records as per our definition in Section ??. Batches: Data are cleaned in batches of size b and the user can change these settings if she desires more or less frequent model updates. The choice of b does affect the convergence rate. Section 5 discusses the efficiency and convergence trade-offs of different values of b. We empirically find that a batch size of 50 performs well across different datasets and use that as a default. A cleaning budget k can be used as a stopping criterion once C()\u0307 has been called k times, and so the number of iterations of ActiveClean is T = k\nb . Alterna-\ntively, the user can clean data until the model is of sufficient accuracy to make a decision.\n4.1.2 Basic Data Flow The system first trains the model \u03c6(\u00b7) on the dirty dataset\nto find an initial model \u03b8(d) that the system will subsequently improve. The sampler selects a sample of size b records from the dataset and passes the sample to the cleaner, which executes C(\u00b7) for each sample record and outputs their cleaned versions. The updater uses the cleaned sample to update the weights of the model, thus moving the model closer to the true cleaned model (in expectation). Finally, the system either terminates due to a stopping condition (e.g., C(\u00b7) has been called a maximum number of times k, or training error convergence), or passes control to the sampler for the next iteration.\n4.1.3 Optimizations In many cases, such as missing values, errors can be ef-\nficiently detected. A user provided Detector can be used to identify such records that are more likely to be dirty, and thus improves the likelihood that the next sample will contain true dirty records. Furthermore, the Estimator uses previously cleaned data to estimate the effect that cleaning a given record will have on the model. These components can be used separately (if only one is supplied) or together to focus the system\u2019s cleaning efforts on records that will most improve the model. Section 7 describes several instantiations of these components for different data cleaning problems. Our experiments show that these optimizations can improve model accuracy by up-to 2.5x (Section 8.3.2)."}, {"heading": "4.2 Example", "text": "The following example illustrates how a user would apply ActiveClean to address the use case in Section 2.6:\nEXAMPLE 1. The analyst chooses to use an SVM model, and manually cleans records by hand (the C(\u00b7)). ActiveClean initially selects a sample of 50 records (the default) to show the analyst. She identifies a subset of 15 records that are dirty, fixes them by normalizing the drug and corporation names with the\nhelp of a search engine, and corrects the labels with typographical or incorrect values. The system then uses the cleaned records to update the the current best model and select the next sample of 50. The analyst can stop at any time and use the improved model to predict donation likelihoods."}, {"heading": "5. UPDATES WITH CORRECTNESS", "text": "This section describes an algorithm for reliable model updates. The updater assumes that it is given a sample of data Sdirty from Rdirty where i \u2208 Sdirty has a known sampling probability p(i). Sections 6 and 7 show how to optimize p(\u00b7) and the analysis in this section applies for any sampling distribution p(\u00b7) > 0."}, {"heading": "5.1 Geometric Derivation", "text": "The update algorithm intuitively follows from the convex geometry of the problem. Consider the problem in one dimension (i.e., the parameter \u03b8 is a scalar value), so then the goal is to find the minimum point (\u03b8) of a curve l(\u03b8). The consequence of dirty data is that the wrong loss function is optimized. Figure 3A illustrates the consequence of the optimization. The red dotted line shows the loss function on the dirty data. Optimizing the loss function finds \u03b8(d) that at the minimum point (red star). However, the true loss function (w.r.t to the clean data) is in blue, thus the optimal value on the dirty data is in fact a suboptimal point on clean curve (red circle).\nThe optimal clean model \u03b8(c) is visualized as a yellow star. The first question is which direction to update \u03b8(d) (i.e., left\nor right). For this class of models, given a suboptimal point, the direction to the global optimum is the gradient of the loss function. The gradient is a d-dimensional vector function of the current model \u03b8(d) and the clean data. Therefore, ActiveClean needs to update \u03b8(d) some distance \u03b3 (Figure 3B):\n\u03b8new \u2190 \u03b8(d) \u2212 \u03b3 \u00b7 \u2207\u03c6(\u03b8(d))\nAt the optimal point, the magnitude of the gradient will be zero. So intuitively, this approach iteratively moves the model downhill (transparent red circle) \u2013 correcting the dirty model until the desired accuracy is reached. However, the gradient depends on all of the clean data which is not available and ActiveClean will have to approximate the gradient from a sample of newly cleaned data. The main intuition is that if the gradient steps are on average correct, the model still moves downhill albeit with a reduced convergence rate proportional to the inaccuracy of the sample-based estimate.\nTo derive a sample-based update rule, the most important property is that sums commute with derivatives and gradients. The convex loss class of models are sums of losses, so given the current best model \u03b8, the true gradient g\u2217(\u03b8) is:\ng\u2217(\u03b8) = \u2207\u03c6(\u03b8) = 1 N N\u2211 i \u2207\u03c6(x(c)i , y (c) i , \u03b8)\nActiveClean needs to estimate g\u2217(\u03b8) from a sample S, which is drawn from the dirty data Rdirty. Therefore, the sum has two components the gradient on the already clean data gC which can be computed without cleaning and gS the gradient estimate from a sample of dirty data to be cleaned:\ng(\u03b8) = | Rclean | | R | \u00b7 gC(\u03b8) + | Rdirty | | R | \u00b7 gS(\u03b8)\ngC can be calculated by applying the gradient to all of the already cleaned records:\ngC(\u03b8) = 1 | Rclean | \u2211\ni\u2208Rclean\n\u2207\u03c6(x(c)i , y (c) i , \u03b8)\ngS can be estimated from a sample by taking the gradient w.r.t each record, and re-weighting the average by their respective sampling probabilities. Before taking the gradient the cleaning function C(\u00b7) is applied to each sampled record. Therefore, let S be a sample of data, where each i \u2208 S is drawn with probability p(i):\ngS(\u03b8) = 1 | S | \u2211 i\u2208S 1 p(i) \u2207\u03c6(x(c)i , y (c) i , \u03b8)\nThen, at each iteration t, the update becomes:\n\u03b8(t+1) \u2190 \u03b8(t) \u2212 \u03b3 \u00b7 g(\u03b8(t))"}, {"heading": "5.2 Model Update Algorithm", "text": "To summarize, the algorithm is initialized with \u03b8(0) = \u03b8(d) which is the dirty model. There are three user set parameters the budget k, batch size b, and the step size \u03b3. In the following section, we will provide references from the convex optimization literature that allow the user to appropriately select these values. At each iteration t = {1, ..., T}, the cleaning is applied to a batch of data b selected from the set of candidate dirty records Rdirty. Then, an average gradient is estimated from the cleaned batch and the model is updated. Iterations continue until k = T \u00b7 b records are cleaned.\n1. Calculate the gradient over the sample of newly clean data and call the result gS(\u03b8(t)) 2. Calculate the average gradient over all of the already clean data in Rclean = R \u2212 Rdirty, and call the result gC(\u03b8\n(t)) 3. Apply the following update rule:\n\u03b8(t+1) \u2190 \u03b8(t)\u2212\u03b3\u00b7( | Rdirty || R | \u00b7gS(\u03b8 (t))+ | Rclean | | R | \u00b7gC(\u03b8 (t)))"}, {"heading": "5.3 Analysis with Stochastic Gradient Descent", "text": "The update algorithm can be formalized as a class of very well studied algorithms called Stochastic Gradient Descent. SGD provides a theoretical framework to understand and analyze the update rule and bound the error. Mini-batch stochastic gradient descent (SGD) is an algorithm for finding the optimal value given the convex loss and data. In mini-batch SGD, random subsets of data are selected at each iteration and the average gradient is computed for every batch.\nOne key difference with traditional SGD models is that ActiveClean applies a full gradient step on the already clean data and averages it with a stochastic gradient step (i.e., calculated from a sample) on the dirty data. Therefore, ActiveClean iterations can take multiple passes over the clean data but at most a single cleaning pass of the dirty data. The update algorithm can be thought of as a variant of SGD that lazily materializes the clean value. As data is sampled at each iteration, data is cleaned when needed by the optimization. It is well known that even for an arbitrary initialization SGD makes significant progress in less than one epoch (a pass through the entire dataset) [9]. In practice, the dirty model can be much more accurate than an arbitrary initialization as corruption may only affect a few features and combined with the full gradient step on the clean data the updates converge very quickly. Setting the step size \u03b3: There is extensive literature in machine learning for choosing the step size \u03b3 appropriately. \u03b3 can be set either to be a constant or decayed over time. Many machine learning frameworks (e.g., MLLib, Sci-kit Learn, Vowpal Wabbit) automatically set learning rates or provide different learning scheduling frameworks. In the experiments, we use a technique called inverse scaling where there is a parameter \u03b30 = 0.1, and at each iteration it decays to \u03b3t = \u03b30|S|t .\nSetting the batch size b: The batch size should be set by the user to have the desired properties. Larger batches will take longer to clean and will make more progress towards the clean model but will have less frequent model updates. On the other hand, smaller batches are cleaned faster and have more frequent model updates. There are diminishing returns to increasing the batch size O( 1\u221a\nb ). In the experiments, we\nuse a batch size of 50 which converges fast but allows for frequent model updates. If a data cleaning technique requires a larger batch size than 50, i.e., data cleaning is fast enough that the iteration overhead is significant compared to cleaning 50 records, ActiveClean can apply the updates in smaller batches. For example, the batch size set by the user might be b = 1000, but the model updates after every 50 records are cleaned. We can disassociate the batching requirements of SGD and the batching requirements of the data cleaning technique.\n5.3.1 Convergence Conditions and Properties\nConvergence properties of batch SGD formulations have been well studied [11]. Essentially, if the gradient estimate is unbiased and the step size is appropriately chosen, the algorithm is guaranteed to converge. In Appendix B, we show that the gradient estimate from ActiveClean is indeed unbiased and our choice of step size is one that is established to converge. The convergence rates of SGD are also well analyzed [11, 8, 39]. The analysis gives a bound on the error of intermediate models and the expected number of steps before achieving a model within a certain error. For a general convex loss, a batch size b, and T iterations, the convergence rate is bounded by O( \u03c3\n2 \u221a bT ). \u03c32 is the variance in the estimate of the gradient at each iteration:\nE(\u2016g \u2212 g\u2217\u20162)\nwhere g\u2217 is the gradient computed over the full data if it were fully cleaned. This property of SGD allows us to bound the model error with a monotonically decreasing function of the number of records cleaned, thus satisfying the reliability condition in the problem statement. If the loss in non-convex, the update procedure will converge towards a local minimum rather than the global minimum (See Appendix C)."}, {"heading": "5.4 Example", "text": "This example describes an application of the update algorithm.\nEXAMPLE 2. Recall that the analyst has a dirty SVM model on the dirty data \u03b8(d). She decides that she has a budget of cleaning 100 records, and decides to clean the 100 records in batches of 10 (set based on how fast she can clean the data, and how often she wants to see an updated result). All of the data is initially treated as dirty with Rdirty = R and Rclean = \u2205. The gradient of a basic SVM is given by the following function:\n\u2207\u03c6(x, y, \u03b8) =\n{ \u2212y \u00b7 x if y \u00b7 x \u00b7 \u03b8 \u2264 1\n0 if y x \u00b7 \u03b8 \u2265 1\nFor each iteration t, a sample of 10 records S is drawn from Rdirty. ActiveClean then applies the cleaning function to the sample:\n{(x(c)i , y (c) i )} = {C(i) : \u2200i \u2208 S}\nUsing these values, ActiveClean estimates the gradient on the newly cleaned data:\ngS(\u03b8) = 1\n10 \u2211 i\u2208S 1 p(i) \u2207\u03c6(x(c)i , y (c) i , \u03b8)\nActiveClean also applies the gradient to the already clean data (initially non-existent):\ngC(\u03b8) = 1 | Rclean | \u2211\ni\u2208Rclean\n\u2207\u03c6(x(c)i , y (c) i , \u03b8)\nThen, it calculates the update rule:\n\u03b8(t+1) \u2190 \u03b8(t) \u2212 \u03b3 \u00b7 ( | Rdirty || R | \u00b7 gS(\u03b8 (t)) + | Rclean | | R | \u00b7 gC(\u03b8 (t)))\nFinally, Rdirty \u2190 Rdirty \u2212 S, Rclean \u2190 Rclean + S, and continue to the next iteration."}, {"heading": "6. EFFICIENCY WITH SAMPLING", "text": "The updater received a sample with probabilities p(\u00b7). For any distribution where p(\u00b7) > 0, we can preserve correctness. ActiveClean uses a sampling algorithm that selects the most valuable records to clean with higher probability."}, {"heading": "6.1 Oracle Sampling Problem", "text": "Recall that the convergence rate of an SGD algorithm is bounded by \u03c32 which is the variance of the gradient. Intuitively, the variance measures how accurately the gradient is estimated from a uniform sample. Other sampling distributions, while preserving the sample expected value, may have a lower variance. Thus, the oracle sampling problem is defined as a search over sampling distributions to find the minimum variance sampling distribution.\nDEFINITION 1 (ORACLE SAMPLING PROBLEM). Given a set of candidate dirty data Rdirty, \u2200r \u2208 Rdirty find sampling probabilities p(r) such that over all samples S of size k it minimizes:\nE(\u2016gS \u2212 g\u2217\u20162)\nIt can be shown that the optimal distribution over records in Rdirty is probabilities proportional to:\npi \u221d \u2016\u2207\u03c6(x(c)i , y (c) i , \u03b8 (t))\u2016\nThis is an established result, for thoroughness, we provide a proof in the appendix (Section D), but intuitively, records with higher gradients should be sampled with higher probability as they affect the update more significantly. However, ActiveClean cannot exclude records with lower gradients as that would induce a bias hurting convergence. The problem is that the optimal distribution leads to a chicken-and-egg problem: the optimal sampling distribution requires knowing (x(c)i , y (c) i ), however, cleaning is required to know those values."}, {"heading": "6.2 Dirty Gradient Solution", "text": "Such an oracle does not exist, and one solution is to use the gradient w.r.t to the dirty data:\npi \u221d \u2016\u2207\u03c6(x(d)i , y (d) i , \u03b8 (t))\u2016\nIt turns out that the solution works reasonably well in practice on our experimental datasets and has been studied in Machine Learning as the Expected Gradient Length heuristic [31]. The contribution in this work is integrating this heuristic with statistically correct updates. However, intuitively, approximating the oracle as closely as possible can result in improved prioritization. The subsequent section describes two components, the detector and estimator, that can be used to improve the convergence rate. Our experiments suggest up-to a 2x improvement in convergence when using these optional optimizations (Section 8.3.2)."}, {"heading": "7. OPTIMIZATIONS", "text": "In this section, we describe two approaches to optimization, the Detector and the Estimator, that improve the efficiency of the cleaning process. Both approaches are designed to increase the likelihood that the Sampler will pick dirty records that, once cleaned, most move the model towards the true clean model. The Detector is intended to learn the characteristics that distinguish dirty records from clean records while\nthe Estimator is designed to estimate the amount that cleaning a given dirty record will move the model towards the true optimal model."}, {"heading": "7.1 The Detector", "text": "The detector returns two important aspects of a record: (1) whether the record is dirty, and (2) if it is dirty, what is wrong with the record. The sampler can use (1) to select a subset of dirty records to sample at each batch and the estimator can use (2) estimate the value of data cleaning based on other records with the same corruption. ActiveClean supports two types of detectors: a priori and adaptive. In former assumes that we know the set of dirty records and how they are dirty a priori to ActiveClean, while the latter adaptively learns characteristics of the dirty data as part of running ActiveClean.\n7.1.1 A Priori Detector For many types of dirtiness such as missing attribute values\nand constraint violations, it is possible to efficiently enumerate a set of corrupted records and determine how the records are corrupted.\nDEFINITION 2 (A PRIORI DETECTION). Let r be a record in R. An a priori detector is a detector that returns a Boolean of whether the record is dirty and a set of columns er that are dirty.\nD(r) = ({0, 1}, er)\nFrom the set of columns that are dirty, find the corresponding features that are dirty fr and labels that are dirty lr.\nHere is an example this definition using a data cleaning methodology proposed in the literature.\nConstraint-based Repair: One model for detecting errors involves declaring constraints on the database.\nDetection. Let \u03a3 be a set of constraints on the relation R. In the detection step, the detector selects a subset of records Rdirty \u2286 R that violate at least one constraint. The set er is the set of columns for each record which have a constraint violation.\nEXAMPLE 3. An example of a constraint on the running example dataset is that the status of a contribution can be only \u201callowed\" or \u201cdisallowed\". Any other value for status is an error."}, {"heading": "7.2 Adaptive Detection", "text": "A priori detection is not possible in all cases. The detector also supports adaptive detection where detection is learned from previously cleaned data. Note that this \u201clearning\" is distinct from the \u201clearning\" at the end of the pipeline. The challenge in formulating this problem is that detector needs to describe how the data is dirty (e.g. er in the a priori case). The detector achieves this by categorizing the corruption into u classes. These classes are corruption categories that do not necessarily align with features, but every record is classified with at most one category.\nWhen using adaptive detection, the repair step has to clean the data and report to which of the u classes the corrupted record belongs. When an example (x, y) is cleaned, the repair step labels it with one of the clean, 1, 2, ..., u+ 1 classes (including one for \u201cnot dirty\"). It is possible that u increases each iteration as more types of dirtiness are discovered. In\nmany real world datasets, data errors have locality, where similar records tend to be similarly corrupted. There are usually a small number of error classes even if a large number of records are corrupted.\nOne approach for adaptive detection is using a statistical classifier. This approach is particularly suited for a small number data error classes, each of which containing many erroneous records. This problem can be addressed by any classifier, and we use an all-versus-one SVM in our experiments.\nAnother approach could be to adaptively learn predicates that define each of the error classes. For example, if records with certain attributes are corrupted, a pattern tableau can be assigned to each class to select a set of possibly corrupted records. This approach is better suited than a statistical approach for a large number of error classes or scarcity of errors. However, it relies on errors being well aligned with certain attribute values.\nDEFINITION 3 (ADAPTIVE CASE). Select the set of records for which \u03ba gives a positive error classification (i.e., one of the u error classes). After each sample of data is cleaned, the classifier \u03ba is retrained. So the result is:\nD(r) = ({1, 0}, {1, ..., u+ 1})\nAdaptive Detection With OpenRefine:\nEXAMPLE 4. OpenRefine is a spreadsheet-based tool that allows users to explore and transform data. However, it is limited to cleaning data that can fit in memory on a single computer. Since the cleaning operations are coupled with data exploration, ActiveClean does not know what is dirty in advance (the analyst may discover new errors as she cleans).\nSuppose the analyst wants to use OpenRefine to clean the running example dataset with ActiveClean. She takes a sample of data from the entire dataset and uses the tool to discover errors. For example, she finds that some drugs are incorrectly classified as both drugs and devices. She then removes the device attribute for all records that have the drug name in question. As she fixes the records, she tags each one with a category tag of which corruption it belongs to."}, {"heading": "7.3 The Estimator", "text": "To get around the problem with oracle sampling, the estimator will estimate the cleaned value with previously cleaned data. The estimator will also take advantage of the detector from the previous section. There are a number of different approaches, such as regression, that could be used to estimate the cleaned value given the dirty values. However, there is a problem of scarcity, where errors may affect a small number of records. As a result, the regression approach would have to learn a multivariate function with only a few examples. Thus, high-dimensional regression ill-suited for the estimator. Conversely, it could try a very simple estimator that just calculates an average change and adds this change to all of the gradients. This estimator can be highly inaccurate as it also applies the change to records that are known to be clean.\nActiveClean leverages the detector for an estimator between these two extremes. The estimator calculates average changes feature-by-feature and selectively corrects the gradient when a feature is known to be corrupted based on the detector. It also applies a linearization that leads to improved estimates when the sample size is small. We evaluate the linearization in Section 8.5 against alternatives, and find that it provides more accurate estimates for a small number of samples\ncleaned. The result is a biased estimator, and when the number of cleaned samples is large the alternative techniques are comparable or even slightly better due to the bias.\nEstimation For A Priori Detection. If most of the features are correct, it would seem like the gradient is only incorrect in one or two of its components. The problem is that the gradient \u2207\u03c6(\u00b7) can be a very nonlinear function of the features that couple features together. For example, the gradient for linear regression is:\n\u2207\u03c6(x, y, \u03b8) = (\u03b8Tx\u2212 y)x\nIt is not possible to isolate the effect of a change of one feature on the gradient. Even if one of the features is corrupted, all of the gradient components will be incorrect.\nTo address this problem, the gradient can be approximated in a way that the effects of dirty features on the gradient are decoupled. Recall, in the a priori detection problem, that associated with each r \u2208 Rdirty is a set of errors fr, lr which is a set that identifies a set of corrupted features and labels. This property can be used to construct a coarse estimate of the clean value. The main idea is to calculate average changes for each feature, then given an uncleaned (but dirty) record, add these average changes to correct the gradient.\nTo formalize the intuition, instead of computing the actual gradient with respect to the true clean values, compute the conditional expectation given that a set of features and labels fr, lr are corrupted:\npi \u221d E(\u2207\u03c6(x(c)i , y (c) i , \u03b8 (t)) | fr, lr)\nCorrupted features are defined as that:\ni /\u2208 fr =\u21d2 x(c)[i]\u2212 x(d)[i] = 0\ni /\u2208 lr =\u21d2 y(c)[i]\u2212 y(d)[i] = 0 The needed approximation represents a linearization of the\nerrors, and the resulting approximation will be of the form:\np(r) \u221d \u2016\u2207\u03c6(x, y, \u03b8(t)) +Mx \u00b7\u2206rx +My \u00b7\u2206ry\u2016\nwhereMx,My are matrices and \u2206rx and \u2206ry are vectors with one component for each feature and label where each value is the average change for those features that are corrupted and 0 otherwise. Essentially, it the gradient with respect to the dirty data plus some linear correction factor. In the appendix, we present a derivation using a Taylor series expansion and a number of Mx and My matrices for common convex losses (Appendix E and F). The appendix also describes how to maintain \u2206rx and \u2206ry as cleaning progresses.\nEstimation For Adaptive Case. A similar procedure holds in the adaptive setting, however, it requires reformulation. Here, ActiveClean uses u corruption classes provided by the detector. Instead of conditioning on the features that are corrupted, the estimator conditions on the classes. So for each error class, it computes a \u2206ux and \u2206uy. These are the average change in the features given that class and the average change in labels given that class.\np(ru) \u221d \u2016\u2207\u03c6(x, y, \u03b8(t)) +Mx \u00b7\u2206ux +My \u00b7\u2206uy\u2016\n7.3.1 Example Here is an example of using the optimization to select a\nsample of data for cleaning.\nEXAMPLE 5. Consider using ActiveClean with an a priori detector. Let us assume that there are no errors in the labels and only errors in the features. Then, each training example will have a set of corrupted features (e.g., {1, 2, 6}, {1, 2, 15}). Suppose that the cleaner has just cleaned the records r1 and r2 represented as tuples with their corrupted feature set: (r1,{1, 2, 3}), (r2,{1, 2, 6}). For each feature i, ActiveClean maintains the average change between dirty and clean in a value in a vector \u2206x[i] for those records corrupted on that feature.\nThen, given a new record (r3,{1, 2, 3, 6}), \u2206r3x is the vector \u2206x where component i is set to 0 if the feature is not corrupted. Suppose the data analyst is using an SVM, then the Mx matrix is as follows:\nMx[i, i] = { \u2212y[i] if y \u00b7 x \u00b7 \u03b8 \u2264 1 0 if y x \u00b7 \u03b8 \u2265 1\nThus, we calculate a sampling weight for record r3:\np(r3) \u221d \u2016\u2207\u03c6(x, y, \u03b8(t)) +Mx \u00b7\u2206r3x\u2016"}, {"heading": "To turn the result into a probability distribution, ActiveClean normalizes over all dirty records.", "text": ""}, {"heading": "8. EXPERIMENTS", "text": "First, the experiments evaluate how various types of corrupted data benefit from data cleaning. Next, the experiments explore different prioritization and model update schemes for progressive data cleaning. Finally, ActiveClean is evaluated end-to-end in a number of real-world data cleaning scenarios."}, {"heading": "8.1 Experimental Setup and Notation", "text": "The main metric for evaluation is a relative measure of the trained model and the model if all of the data is cleaned.\nRelative Model Error. Let \u03b8 be the model trained on the dirty data, and let \u03b8\u2217 be the model trained on the same data if it was cleaned. Then the model error is defined as \u2016\u03b8\u2212\u03b8\n\u2217\u2016 \u2016\u03b8\u2217\u2016 .\n8.1.1 Scenarios Income Classification (Adult): In this dataset of 45,552 records, the task is to predict the income bracket (binary) from 12 numerical and categorical covariates with an SVM classifier. Seizure Classification (EEG): In this dataset, the task is to predict the onset of a seizure (binary) from 15 numerical covariates with a thresholded Linear Regression. There are 14980 data points in this dataset. This classification task is inherently hard with an accuracy on completely clean data of only 65%. Handwriting Recognition (MNIST) 1: In this dataset, the task is to classify 60,000 images of handwritten images into 10 categories with an one-to-all multiclass SVM classifier. The unique part of this dataset is the featurized data consists of a 784 dimensional vector which includes edge detectors and raw image patches. Dollars For Docs: The dataset has 240,089 records with 5 textual attributes and one numerical attribute. The dataset is featurized with bag-of-words featurization model for the textual attributes which resulted in a 2021 dimensional feature 1 http://ufldl.stanford.edu/wiki/index.php/Using_the_MNIST_ Dataset\nvector, and a binary SVM is used to classify the status of the medical donations. World Bank: The dataset has 193 records of country name, population, and various macro-economics statistics. The values are listed with the date at which they were acquired. This allowed us to determine that records from smaller and less populous countries were more likely to be out-of-date.\n8.1.2 Compared Algorithms Here are the alternative methodologies evaluated in the experiments: Robust Logistic Regression [14]. Feng et al. proposed a variant of logistic regression that is robust to outliers. We chose this algorithm because it is a robust extension of the convex regularized loss model, leading to a better apples-toapples comparison between the techniques. (See details in Appendix H.1) Discarding Dirty Data. As a baseline, dirty data are discarded. SampleClean (SC) [33]. SampleClean takes a sample of data, applies data cleaning, and then trains a model to completion on the sample. Active Learning (AL) [18]. To fairly evaluate Active Learning, we first apply our gradient update to ensure correctness. Within each iteration, examples are prioritized by distance to the decision boundary (called Uncertainty Sampling in [31]). However, we do not include our optimizations such as detection and estimation. ActiveClean Oracle (AC+O): In ActiveClean Oracle, instead of an estimation and detection step, the true clean value is used to evaluate the theoretical ideal performance of ActiveClean."}, {"heading": "8.2 Does Data Cleaning Matter?", "text": "The first experiment evaluates the benefits of data cleaning on two of the example datasets (EEG and Adult). Our goal is to understand which types of data corruption are amenable to data cleaning and which are better suited for robust statistical techniques. The experiment compares four schemes: (1) full data cleaning , (2) baseline of no cleaning, (3) discarding the dirty data, and (4) robust logistic regression,. We corrupted 5% of the training examples in each dataset in two different ways:\nRandom Corruption: Simulated high-magnitude random outliers. 5% of the examples are selected at random and a random feature is replaced with 3 times the highest feature value.\nSystematic Corruption: Simulated innocuous looking (but still incorrect) systematic corruption. The model is trained on the clean data, and the three most important features (highest weighted) are identified. The examples are sorted by each of these features and the top examples are corrupted with the mean value for that feature (5% corruption in all). It is important to note that examples can have multiple corrupted features.\nFigure 4 shows the test accuracy for models trained on both types of data with the different techniques. The robust method performs well on the random high-magnitude outliers with only a 2.0% reduction in clean test accuracy for EEG and 2.5% reduction for Adult. In the random setting, discarding dirty data also performs relatively well. However,\nthe robust method falters on the systematic corruption with a 9.1% reduction in clean test accuracy for EEG and 10.5% reduction for Adult. The problem is that without cleaning, there is no way to know if the corruption is random or systematic and when to trust a robust method. While data cleaning requires more effort, it provides benefits in both settings. In the remaining experiments, unless otherwise noted, the experiments use systematic corruption. Summary: A 5% systematic corruption can introduce a 10% reduction in test accuracy even when using a robust method.\n8.3 ActiveClean: A Priori Detection The next set of experiments evaluate different approaches to cleaning a sample of data compared to ActiveClean using a priori detection. A priori detection assumes that all of the corrupted records are known in advance but their clean values are unknown.\n8.3.1 Active Learning and SampleClean The next experiment evaluates the samples-to-error trade-\noff between four alternative algorithms: ActiveClean (AC), SampleClean, Active Learning, and ActiveClean +Oracle (AC+O). Figure 5 shows the model error and test accuracy as a function of the number of cleaned records. In terms of model error, ActiveClean gives its largest benefits for small sample sizes. For 500 cleaned records of the Adult dataset, ActiveClean has 6.1x less error than SampleClean and 2.1x less error than Active Learning. For 500 cleaned records of the EEG dataset, ActiveClean has 9.6x less error than SampleClean and 2.4x less error than Active Learning. Both Active Learning and ActiveClean benefit from the initialization with the dirty model as they do not retrain their models from scratch, and ActiveClean improves on this performance with detection and error estimation. Active Learning has no notion of dirty and clean data, and therefore prioritizes with respect to the dirty data. These gains in model error also correlate well to improvements in test error (defined as the test accuracy difference w.r.t cleaning all data). The test error converges more quickly than model error, emphasizing the benefits of progressive data cleaning, since it is not neccessary to clean all the data to get a model with essentially the same performance as the clean model. For example, to achieve a test error of 1% on the Adult dataset, ActiveClean cleans 500 fewer records than Active Learning. Summary: ActiveClean with a priori detection returns results that are more than 6x more accurate than SampleClean and 2x more accurate than Active Learning for cleaning 500 records.\n8.3.2 Source of Improvements The next experiment compares the performance of Active-\nClean with and without various optimizations at 500 records cleaned point. ActiveClean without detection is denoted as (AC-D) (that is at each iteration we sample from the entire dirty data), and ActiveClean without detection and importance sampling is denoted as (AC-D-I). Figure 6 plots the relative error of the alternatives and ActiveClean with and without the optimizations. Without detection (AC-D), ActiveClean is still more accurate than Active Learning. Removing the importance sampling, ActiveClean is slightly worse than Active Learning on the Adult dataset but is comparable on the EEG dataset. Summary: Both a priori detection and non-uniform sampling significantly contribute to the gains over Active Learning.\n8.3.3 Mixing Dirty and Clean Data Training a model on mixed data is an unreliable methodol-\nogy lacking the same guarantees as Active Learning or SampleClean even in the simplest of cases. For thoroughness, the next experiments include the model error as a function of records cleaned in comparison to ActiveClean. Figure 7 plots the same curves as the previous experiment comparing ActiveClean, Active Learning, and two mixed data algorithms. PC randomly samples data, clean, and writes-back the cleaned data. PC+D randomly samples data from using the dirty data detector, cleans, and writes-back the cleaned data. For these errors PC and PC+D give reasonable results\n(not always guaranteed), but ActiveClean converges faster. ActiveClean tunes the weighting when averaging dirty and clean data into the gradient.\nSummary: ActiveClean converges faster than mixing dirty and clean data since it reweights data based on the fraction that is dirty and clean. Partial cleaning is not guaranteed to give sensible results.\n8.3.4 Corruption Rate The next experiment explores how much of the performance\nis due to the initialization with the dirty model (i.e., SampleClean trains a model from \u201cscratch\"). Figure 8 varies the systematic corruption rate and plots the number of records cleaned to achieve 1% relative error for SampleClean and ActiveClean. SampleClean does not use the dirty data and thus its error is essentially governed by the Central Limit Theorem. SampleClean outperforms ActiveClean only when corruptions are very severe (45% in Adult and nearly 60% in EEG). When the initialization with the dirty model is inaccurate, ActiveClean does not perform as well. Summary: SampleClean is beneficial in comparison to ActiveClean when corruption rates exceed 45%."}, {"heading": "8.4 ActiveClean: Adaptive Detection", "text": "This experiment explores how the results of the previous experiment change when using an adaptive detector instead of the a priori detector. Recall, in the systematic corruption, 3 of the most informative features were corrupted, thus we group these problems into 9 classes. We use an all-versus-one SVM to learn the categorization.\n8.4.1 Basic Performance Figure 9 overlays the convergence plots in the previous ex-\nperiments with a curve (denoted by AC+C) that represents ActiveClean using a classifier instead of the a priori detection. Initially ActiveClean is comparable to Active Learning; however, as the classifier becomes more effective the detection improves the performance. Over both datasets, at the 500 records point on the curve, adaptive ActiveClean has a 30% higher model error compared to a priori ActiveClean. At 1000 records point on the curve, adaptive ActiveClean has about 10% higher error. Summary: For 500 records cleaned, adaptive ActiveClean has a 30% higher model error compared to a priori ActiveClean, but still outperforms Active Learning and SampleClean.\n8.4.2 Classifiable Errors\nThe adaptive case depends on being able to predict corrupted records. For example, random corruption not correlated with any other data features may be hard to learn. As corruption becomes more random, the classifier becomes increasingly erroneous. The next experiment explores making the systematic corruption more random. Instead of selecting the highest valued records for the most valuable features, we corrupt random records with probability p. We compare these results to AC-D where we do not have a detector at all at one vertical slice of the previous plot (cleaning 1000 records). Figure 10a plots the relative error reduction using a classifier. When the corruption is about 50% random then there is a break even point where no detection is better. The classifier is imperfect and misclassifies some data points incorrectly as cleaned. Summary: When errors are increasingly random (50% random) and cannot be accurately classified, adaptive detection provides no benefit over no detection."}, {"heading": "8.5 Estimation", "text": "The next experiment compares estimation techniques: (1) \u201clinear regression\" trains a linear regression model that predicts the clean gradient as a function of the dirty gradient, (2) \u201caverage gradient\" which does not use the detection to inform\nhow to apply the estimate, (3) \u201caverage feature change\" uses detection but no linearization, and (4) the Taylor series linear approximation. Figure 10b measures how accurately each estimation technique estimates the gradient as a function of the number of cleaned records on the EEG dataset.\nEstimation error is measured using the relative L2 error with the true gradient. The Taylor series approximation proposed gives more accurate for small cleaning sizes. Linear regression and the average feature change technique do eventually perform comparably but only after cleaning much more data. Summary: Linearized gradient estimates are more accurate when estimated from small samples."}, {"heading": "8.6 Real World Scenarios", "text": "The next set of experiments evaluate ActiveClean in three real world scenarios, one demonstrating the a priori case and the other two for the adaptive detection case.\n8.6.1 A Priori: Constraint Cleaning The first scenario explores the Dollars for Docs dataset pub-\nlished by ProPublica described throughout the paper. To run this experiment, the entire dataset was cleaned up front, and simulated sampling from the dirty data and cleaning by looking up the value in the cleaned data (see Appendix I for constraints, errors, and cleaning methodology). Figure 11a shows that ActiveClean converges faster than Active Learning and SampleClean. To achieve a 4% relative error (i.e., a 75% error reduction from the dirty model), ActiveClean cleans 40000 fewer records than Active Learning. Also, for 10000 records cleaned, ActiveClean has nearly an order of magnitude smaller error than SampleClean.\nFigure 11b shows the detection rate (fraction of disallowed research contributions identified) of the classifier as a function of the number of records cleaned. On the dirty data, we can only correctly classify 66% of the suspected examples (88% overall accuracy due to a class imbalance). On the cleaned data, this classifier is nearly perfect with a 97% true positive rate (98% overall accuracy). ActiveClean converges to the cleaned accuracy faster than the alternatives with a classifier of 92% true positive rate for only 10000 records cleaned. Summary: To achieve an 80% detection rate, ActiveClean cleans nearly 10x less records than Active Learning.\n8.6.2 Adaptive: Replacing Corrupted Data The next experiment explores the MNIST handwritten digit\nrecognition dataset with a MATLAB image processing pipeline. In this scenario, the analyst must inspect a potentially corrupted image and replace it with a higher quality one. The MNIST dataset consists of 64x64 grayscale images. There are\ntwo types of simulated corruptions: (1) 5x5 block removal where a random 5x5 block is removed from the image by setting its pixel values to 0, and (2) Fuzzy where a 4x4 moving average patch is applied over the entire image. These corruptions are applied to a random 5% of the images, and mimic the random (Fuzzy) vs. systematic corruption (5x5 removal) studied in the previous experiments. The adaptive detector uses a 10 class classifier (one for each digit) to detect the corruption.\nFigure 12 shows that ActiveClean makes more progress towards the clean model with a smaller number of examples cleaned. To achieve a 2% error for the block removal, ActiveClean can inspect 2200 fewer images than Active Learning and 2750 fewer images than SampleClean. For the fuzzy images, both Active Learning and ActiveClean reach 2% error after cleaning fewer than 100 images, while SampleClean requires 1750. Summary: In the MNIST dataset, ActiveClean significantly reduces (more than 2x) the number of images to clean to train a model with 2% error.\n8.6.3 Adaptive: Regression In the prior two experiments, we explored classification\nproblems. In this experiment, we consider the case when the convex model represents a linear regression model. Regression models allow us to visualize what is happening when we apply ActiveClean. In Figure 13, we illustrate regression model training on a small dataset of 193 countries collected from the World Bank. Each country has an associated population and total dollar value of imports. We are interested in examining the relationship between these variables. However, for some countries, the import values are out-of-date in the World Bank dataset. Up-to-date values are usually avaiable on national statistics websites and can be determined with some web searching. It turns out that smaller countries were more likely to have out-of-date statistics in the World Bank dataset, and as a result, the trend line is misleading in the dirty data. We applied ActiveClean after verifying 30 out of the 193 countries (marked in yellow), and found that we could achieve a highly accurate approximation of the full result. Summary: ActiveClean is accurate even in regression analytics."}, {"heading": "9. RELATED WORK", "text": "Data Cleaning: When data cleaning is expensive, it is desirable to apply it progressively, where analysts can inspect early results with only k N records cleaned. Progressive data cleaning is a well studied problem especially in the context of entity resolution [6, 34, 30, 17]. Prior work has fo-\ncused on the problem of designing data structures and algorithms to apply data cleaning progressively. which is challenging because many data cleaning algorithms require information from the entire relation. Over the last 5 years a number of new results have expanded the scope and practicality of progressive data cleaning [26, 38, 37]. ActiveClean studies the problem of prioritizing progressive cleaning by leveraging information about a user\u2019s subsequent use for the data. Certain records, if cleaned, may be more likely to affect the downstream analysis.\nThere are a number of other works that use machine learning to improve the efficiency and/or reliability of data cleaning [38, 37, 16]. For example, Yakout et al. train a model that evaluates the likelihood of a proposed replacement value [37]. Another application of machine learning is value imputation, where a missing value is predicted based on those records without missing values. Machine learning is also increasingly applied to make automated repairs more reliable with human validation [38]. Human input is often expensive and impractical to apply to entire large datasets. Machine learning can extrapolate rules from a small set of examples cleaned by a human (or humans) to uncleaned data [16, 38]. This approach can be coupled with active learning [27] to learn an accurate model with the fewest possible number of examples. While, in spirit, ActiveClean is similar to these approaches, it addresses a very different problem of data cleaning before user-specified modeling. The key new challenge in this problem is ensuring the correctness of the user\u2019s model after partial data cleaning.\nSampleClean [33] applies data cleaning to a sample of data, and estimates the results of aggregate queries. Sampling has also been applied to estimate the number of duplicates in a relation [19]. Similarly, Bergman et al. explore the problem of query-oriented data cleaning [7], where given a query, they clean data relevant to that query. Existing work does not explore cleaning driven by the downstream machine learning \u201cqueries\" studied in this work. Deshpande et al. studied data acquisition in sensor networks [12]. They explored value of information based prioritization of data acquisition for estimating aggregate queries of sensor readings. Similarly, Jeffery et al. [21] explored similar prioritization based on value of information. We see this work as pushing prioritization further down the pipeline to the end analytics. Finally, incremental optimization methods like SGD have a connection to incremental materialized view maintenance as the argument for incremental maintenance over recomputation is similar (i.e., relatively sparse updates). Krishnan et al. explored how samples of materialized views can be maintained similar to how models are updated with a sample of clean data in this\nwork [24].\nStochastic Optimization and Active Learning: Zhao and Tong recently proposed using importance sampling in conjunction with stochastic gradient descent [39]. The ideas applied in ActiveClean are well rooted in the Machine Learning and Optimization literature, and we apply these ideas to the data cleaning problem. This line of work builds on prior results in linear algebra that show that some matrix columns are more informative than others [13], and Active Learning which shows that some labels are more informative that others [31]. Active Learning largely studies the problem of label acquisition [31], and recently the links between Active Learning and Stochastic optimization have been studied [18]. We use the work in Guillory et al. to evaluate a state-of-the-art Active Learning technique against ActiveClean.\nTransfer Learning and Bias Mitigation: ActiveClean has a strong link to a field called Transfer Learning and Domain Adaptation [29]. The basic idea of Transfer Learning is that suppose a model is trained on a dataset D but tested on a dataset D\u2032. Much of the complexity and contribution of ActiveClean comes from efficiently tuning such a process for expensive data cleaning applications \u2013 costs not studied in Transfer Learning. In robotics, Mahler et al. explored a calibration problem in which data was systematically corrupted [25] and proposed a rule-based technique for cleaning data. Other problems in bias mitigation (e.g., Krishnan et al. [23]) have the same structure, systematically corrupted data that is feeding into a model. In this work, we try to generalize these principles given a general dirty dataset, convex model, and data cleaning procedure.\nSecure Learning: ActiveClean is also related to work in adversarial learning [28], where the goal is to make models robust to adversarial data manipulation. This line of work has extensively studied methodologies for making models private to external queries and robust to malicious labels [36], but the data cleaning problem explores more general corruptions than just malicious labels. One widely applied technique in this field is reject-on-negative impact, which essentially, discards data that reduces the loss function\u2013which will not work when we do not have access to the true loss function (only the \u201cdirty loss\")."}, {"heading": "10. DISCUSSION AND FUTURE WORK", "text": "The experimental results suggest the following conclusions about ActiveClean: (1) when the data corruption rate is relatively small (e.g., 5%), ActiveClean cleans fewer records than Active Learning or SampleClean to achieve the same model accuracy, (2) all of the optimizations in ActiveClean (importance sampling, detection, and estimation) lead to significantly more accurate models at small sample sizes, (3) only when corruption rates are very severe (e.g. 50%) , SampleClean outperforms ActiveClean, and (4) two real-world scenarios demonstrate similar accuracy improvements where ActiveClean returns significantly more accurate models than SampleClean or Active Learning for the same number of records cleaned.\nThere are also a few additional points for discussion. ActiveClean provides guarantees for training error on models trained with progressive data cleaning, however, there are no such guarantees on test error. This work focuses on the problem where an analyst has a large amount of dirty data and\nwould like explore data cleaning and predictive models on this dataset. By providing the analyst more accurate model estimates, the value of different data cleaning techniques can be judged without having to clean the entire dataset. However, the exploratory analysis problem is distinct from the model deployment problem (i.e., serving predictions to users from the model), which we hope to explore in more detail in future work. It implicitly assumes that when the model is deployed, it will be applied in a setting where the test data is also clean. Training on clean data, and testing on dirty data, defeats the purpose of data cleaning and can lead to unreliable predictions.\nAs the experiments clearly show, ActiveClean is not strictly better than Active Learning or SampleClean. ActiveClean is optimized for a specific design point of sparse errors and small sample sizes, and the empirical results suggest it returns more accurate models in this setting. As sample sizes and error rates increase, the benefits of ActiveClean are reduced. Another consideration for future work is automatically selecting alternative techniques when ActiveClean is expected to perform poorly.\nBeyond these limitations, there are several exciting new avenues for future work. The data cleaning models explored in this work can be extended to handle non-uniform costs, where different errors have a different cleaning cost. Next, the empirical success of Deep Learning has led to increasing industry and research adoption of non-convex losses in many tasks that were traditionally served by convex models. In future work, we hope to explore how we can integrate with such frameworks."}, {"heading": "11. CONCLUSION", "text": "The growing popularity of predictive models in data analytics adds additional challenges in managing dirty data. Progressive data cleaning in this setting is susceptible to errors due to mixing dirty and clean data, sensitivity to sample size, and the sparsity of errors. The key insight of ActiveClean is that an important class of predictive models, called convex loss models (e.g., linear regression and SVMs), can be simultaneously trained and cleaned. Consequently, there are provable guarantees on the convergence and error bounds of ActiveClean. ActiveClean also includes numerous optimizations such as: using the information from the model to inform data cleaning on samples, dirty data detection to avoid sampling clean data, and batching updates. The experimental results are promising as they suggest that these optimizations can significantly reduce data cleaning costs when errors are sparse and cleaning budgets are small. Techniques such as Active Learning and SampleClean are not optimized for the sparse low-budget setting, and ActiveClean achieves models of similar accuracy for significantly less records cleaned.\nThis research is supported in part by NSF CISE Expeditions Award CCF-1139158, LBNL Award 7076018, and DARPA XData Award FA8750-12-2-0331, and gifts from Amazon Web Services, Google, SAP, The Thomas and Stacey Siebel Foundation, Adatao, Adobe, Apple, Inc., Blue Goji, Bosch, C3Energy, Cisco, Cray, Cloudera, EMC2, Ericsson, Facebook, Guavus, HP, Huawei, Informatica, Intel, Microsoft, NetApp, Pivotal, Samsung, Schlumberger, Splunk, Virdata and VMware."}, {"heading": "12. REFERENCES", "text": "[1] Berkeley data analytics stack.\nhttps://amplab.cs.berkeley.edu/software/.\n[2] Dollars for docs. http://projects.propublica.org/open-payments/. [3] For big-data scientists, \u2019janitor work\u2019 is key hurdle to insights. http://www.nytimes.com/2014/08/18/technology/for-big-datascientists-hurdle-to-insights-is-janitor-work.html. [4] A pharma payment a day keeps docs\u2019 finances okay. https://www.propublica.org/article/ a-pharma-payment-a-day-keeps-docs-finances-ok. [5] A. Alexandrov, R. Bergmann, S. Ewen, J. Freytag, F. Hueske, A. Heise, O. Kao, M. Leich, U. Leser, V. Markl, F. Naumann, M. Peters, A. Rheinl\u00e4nder, M. J. Sax, S. Schelter, M. H\u00f6ger, K. Tzoumas, and D. Warneke. The stratosphere platform for big data analytics. VLDB J., 23(6), 2014. [6] Y. Altowim, D. V. Kalashnikov, and S. Mehrotra. Progressive approach to relational entity resolution. PVLDB, 7(11), 2014. [7] M. Bergman, T. Milo, S. Novgorodov, and W. C. Tan. Query-oriented data cleaning with oracles. In SIGMOD Conference, 2015. [8] D. P. Bertsekas. Incremental gradient, subgradient, and proximal methods for convex optimization: A survey. CoRR, abs/1507.01030, 2015. [9] L. Bottou. Stochastic gradient descent tricks. In Neural Networks: Tricks of the Trade - Second Edition. 2012.\n[10] A. Crotty, A. Galakatos, and T. Kraska. Tupleware: Distributed machine learning on small clusters. IEEE Data Eng. Bull., 37(3), 2014. [11] O. Dekel, R. Gilad-Bachrach, O. Shamir, and L. Xiao. Optimal distributed online prediction using mini-batches. JMLR, 13, 2012. [12] A. Deshpande, C. Guestrin, S. Madden, J. M. Hellerstein, and W. Hong. Model-driven data acquisition in sensor networks. In VLDB, 2004. [13] P. Drineas, M. Magdon-Ismail, M. W. Mahoney, and D. P. Woodruff. Fast approximation of matrix coherence and statistical leverage. JMLR, 13, 2012. [14] J. Feng, H. Xu, S. Mannor, and S. Yan. Robust logistic regression and classification. In NIPS, 2014. [15] J. Friedman, T. Hastie, and R. Tibshirani. The elements of statistical learning, volume 1. Springer series in statistics Springer, Berlin, 2001. [16] C. Gokhale, S. Das, A. Doan, J. F. Naughton, N. Rampalli, J. Shavlik, and X. Zhu. Corleone: Hands-off crowdsourcing for entity matching. In SIGMOD, 2014. [17] A. Gruenheid, X. L. Dong, and D. Srivastava. Incremental record linkage. PVLDB, 7(9), 2014. [18] A. Guillory, E. Chastain, and J. Bilmes. Active learning as non-convex optimization. In International Conference on Artificial Intelligence and Statistics, 2009. [19] A. Heise, G. Kasneci, and F. Naumann. Estimating the number and sizes of fuzzy-duplicate clusters. In CIKM Conference, 2014. [20] G. Inc. Tensorflow. https://www.tensorflow.org/. [21] S. R. Jeffery, G. Alonso, M. J. Franklin, W. Hong, and J. Widom.\nDeclarative support for sensor data cleaning. In Pervasive Computing, 2006.\n[22] S. Kandel, A. Paepcke, J. M. Hellerstein, and J. Heer. Enterprise data analysis and visualization: An interview study. IEEE Trans. Vis. Comput. Graph., 18(12), 2012. [23] S. Krishnan, J. Patel, M. J. Franklin, and K. Goldberg. A methodology for learning, analyzing, and mitigating social influence bias in recommender systems. In RecSys, 2014. [24] S. Krishnan, J. Wang, M. J. Franklin, K. Goldberg, and T. Kraska. Stale view cleaning: Getting fresh answers from stale materialized views. PVLDB, 8(12), 2015. [25] J. Mahler, S. Krishnan, M. Laskey, S. Sen, A. Murali, B. Kehoe, S. Patil, J. Wang, M. Franklin, P. Abbeel, and K. Y. Goldberg. Learning accurate kinematic control of cable-driven surgical robots using data cleaning and gaussian process regression. In CASE, 2014. [26] C. Mayfield, J. Neville, and S. Prabhakar. ERACER: a database approach for statistical inference and data cleaning. In SIGMOD Conference, 2010. [27] B. Mozafari, P. Sarkar, M. J. Franklin, M. I. Jordan, and S. Madden. Scaling up crowd-sourcing to very large datasets: A case for active learning. PVLDB, 8(2), 2014. [28] B. Nelson, B. I. P. Rubinstein, L. Huang, A. D. Joseph, S. J. Lee, S. Rao, and J. D. Tygar. Query strategies for evading convex-inducing classifiers. JMLR, 13, 2012. [29] S. J. Pan and Q. Yang. A survey on transfer learning. TKDE, 22(10), 2010. [30] T. Papenbrock, A. Heise, and F. Naumann. Progressive duplicate\ndetection. IEEE Trans. Knowl. Data Eng., 27(5), 2015. [31] B. Settles. Active learning literature survey. University of Wisconsin,\nMadison, 52:11, 2010. [32] E. H. Simpson. The interpretation of interaction in contingency\ntables. Journal of the Royal Statistical Society. Series B (Methodological), 1951.\n[33] J. Wang, S. Krishnan, M. J. Franklin, K. Goldberg, T. Kraska, and T. Milo. A sample-and-clean framework for fast and accurate query processing on dirty data. In SIGMOD Conference, 2014. [34] S. E. Whang and H. Garcia-Molina. Incremental entity resolution on rules and data. VLDB J., 23(1), 2014. [35] C. Woolston. Gender-disparity study faces attack. http://www.nature.com/news/ gender-disparity-study-faces-attack-1.18428. [36] H. Xiao, B. Biggio, G. Brown, G. Fumera, C. Eckert, and F. Roli. Is feature selection secure against training data poisoning? In ICML, 2015. [37] M. Yakout, L. Berti-Equille, and A. K. Elmagarmid. Don\u2019t be scared: use scalable automatic repairing with maximal likelihood and bounded changes. In SIGMOD Conference, 2013. [38] M. Yakout, A. K. Elmagarmid, J. Neville, M. Ouzzani, and I. F. Ilyas. Guided data repair. PVLDB, 4(5), 2011. [39] P. Zhao and T. Zhang. Stochastic optimization with importance sampling for regularized loss minimization. In ICML, 2015.\nAPPENDIX"}, {"heading": "A. SET-OF-RECORDS CLEANING MODEL", "text": "In paper, we formalized the analyst-specified data cleaning as follows. We take the sample of the records Sdirty, and apply data cleaning C(\u00b7). C is applied to a record and produces the clean record:\nSclean = {C(r) : \u2200r \u2208 Sdirty}\nThe record-by-record cleaning model is a formalization of the costs of data cleaning where each record has the same cost to clean and this cost does not change throughout the entire cleaning session. There are, however, some cases when cleaning the first record of a certain type of corruption is expensive but all subsequent records are cheaper.\nEXAMPLE 6. In most spell checking systems, when a misspelling is identified, the system gives an option to fix all instances of that misspelling.\nEXAMPLE 7. When an inconsistent value is identified all other records with the same inconsistency can be efficiently fixed.\nThis model of data cleaning can fit into our framework and we formalize it as the \u201cSet-of-Records\" model as opposed to the \u201cRecord-by-Record\" model. In this model, the cleaning function C(\u00b7) is not restricted to updating only the records in the sample. C(\u00b7) takes the entire dirty sample as an argument (that is the cleaning is a function of the sample), the dirty data, and updates the entire dirty data:\nR\u2032dirty = C(Sdirty, Rdirty)\nwe require that for every record s \u2208 Sdirty, that record is completely cleaned after applying C(\u00b7), giving us Sclean. Records outside of Sdirty may be cleaned on a subset of dirty attributes by C(\u00b7). After each iteration, we re-run the detector, and move any r \u2208 R\u2032dirty that are clean to Rclean. Such a model allows us to capture data cleaning operations such as in Example 6 and Example 7."}, {"heading": "B. STOCHASTIC GRADIENT DESCENT", "text": "Stochastic Gradient Descent converges for a suitably chosen step size if the sample gradients are unbiased estimates of the\nfull gradient. The first problem is to choose weights \u03b1 and \u03b2 (to average already clean and newly cleaned data) such that the estimate of the gradient is unbiased. The batch Sdirty is drawn only from Rdirty. Since the sizes of Rdirty and its complement are known, it follows that the gradient over the already clean data gC and the recently cleaned data gS can be combined as follows:\ng(\u03b8t) = | Rdirty | \u00b7gS+ | Rclean | \u00b7gC\n| R |\nTherefore,\n\u03b1 = | Rclean | | R | , \u03b2 = | Rdirty | | R |\nLEMMA 1. The gradient estimate g(\u03b8) is unbiased if gS is an unbiased estimate of:\n1 | Rdirty | \u2211 gi(\u03b8)\nPROOF SKETCH. E( 1| Rdirty | \u2211 gi(\u03b8)) = 1 | Rdirty | \u00b7 E( \u2211 gi(\u03b8)))\nBy symmetry, E( 1| Rdirty | \u2211 gi(\u03b8)) = g(\u03b8)\nE( 1| Rdirty | \u2211 gi(\u03b8)) = | Rdirty | \u00b7gS+ | Rclean | \u00b7gC | R |\nThe error bound discussed in Proposition 2 can be tightened for a class of models called strongly convex (see [8] for a defintion).\nPROPOSITION 1. For a strongly convex loss, a batch size b, and T iterations, the convergence rate is bounded by O( \u03c3 2\nbT )."}, {"heading": "C. NON-CONVEX LOSSES", "text": "We acknowledge that there is an increasing popularity of non-convex losses in the Neural Network and Deep Learning literature. However, even for these losses, gradient descent techniques still apply. Instead of converging to a global optimum they converge to a locally optimal value. Likewise, ActiveClean will converge to the closest locally optimal value to the dirty model. Because of this, it is harder to reason about the results. Different initializations will lead to different local optima, and thus, introduces a complex dependence on the initialization with the dirty model. This problem is not fundemental to ActiveClean and any gradient technique suffers this challenge for general non-convex losses, and we hope to explore this more in the future.\nD. IMPORTANCE SAMPLING This lemma describes the optimal distribution over a set of scalars:\nLEMMA 2. Given a set of real numbers A = {a1, ..., an}, let"}, {"heading": "A\u0302 be a sample with replacement of A of size k. If \u00b5 is the mean A\u0302, the sampling distribution that minimizes the variance of \u00b5,", "text": "i.e., the expected square error, is p(ai) \u221d ai.\nLemma 2 shows that when estimating a mean of numbers with sampling, the distribution with optimal variance is sampling proportionally to the values.\nThe variance of this estimate is given by:\nV ar(\u00b5) = E(\u00b52)\u2212 E(\u00b5)2\nSince the estimate is unbiased, we can replace E(\u00b5) with the average of A:\nV ar(\u00b5) = E(\u00b52)\u2212 A\u03042\nSince A\u0304 is deterministic, we can remove that term during minimization. Furthermore, we can write E(\u00b52) as:\nE(\u00b52) = 1 n2 n\u2211 i a2i pi\nThen, we can solve the following optimization problem (removing the proportionality of 1\nn2 ) over the set of weights\nP = {p(ai)}:\nmin P N\u2211 i a2i pi\nsubject to: P > 0, \u2211 P = 1\nApplying Lagrange multipliers, an equivalent unconstrained optimization problem is:\nmin P>0,\u03bb>0 N\u2211 i a2i pi + \u03bb \u00b7 ( \u2211 P \u2212 1)\nIf, we take the derivatives with respect to pi and set them equal to zero:\n\u2212 a 2 i\n2 \u00b7 p2i + \u03bb = 0\nIf, we take the derivative with respect to \u03bb and set it equal to zero: \u2211\nP \u2212 1\nSolving the system of equations, we get:\npi = | ai |\u2211 i | ai |"}, {"heading": "E. LINEARIZATION", "text": "If d is the dirty value and c is the clean value, the Taylor series approximation for a function f is given as follows:\nf(c) = f(d) + f \u2032(d) \u00b7 (d\u2212 c) + ...\nIgnoring the higher order terms, the linear term f \u2032(d) \u00b7 (d\u2212 c) is a linear function in each feature and label. We only have to know the change in each feature to estimate the change in value. In our case the function f is the gradient \u2207\u03c6. So, the resulting linearization is:\n\u2207\u03c6(x(c)i , y (c) i , \u03b8) \u2248 \u2207\u03c6(x, y, \u03b8) +\n\u2202\n\u2202X \u2207\u03c6(x, y, \u03b8) \u00b7 (x\u2212 x(c))\n+ \u2202\n\u2202Y \u03c6(x, y, \u03b8) \u00b7 (y \u2212 y(c))\nWhen we take the expected value:\nE(\u2207\u03c6(xclean, yclean, \u03b8)) \u2248 \u2207\u03c6(x, y, \u03b8)+ \u2202\n\u2202X \u2207\u03c6(x, y, \u03b8)\u00b7E(\u2206x)\n+ \u2202\n\u2202Y \u2207\u03c6(x, y, \u03b8) \u00b7 E(\u2206y)\nIt follows that:\n\u2248 \u2207\u03c6(x, y, \u03b8) +Mx \u00b7 E(\u2206x) +My \u00b7 E(\u2206y)\nwhere Mx = \u2202\u2202X\u2207\u03c6 and My = \u2202 \u2202Y \u2207\u03c6. Recall that the feature space is d dimensional and label space is l dimensional. Then, Mx is an d \u00d7 d matrix, and My is a d \u00d7 l matrix. Both of these matrices are computed for each record. \u2206x is a d dimensional vector where each component represents a change in that feature and \u2206y is an l dimensional vector that represents the change in each of the labels.\nThis linearization allows ActiveClean to maintain per feature (or label) average changes and use these changes to center the optimal sampling distribution around the expected clean value. To estimate E(\u2206x) and E(\u2206y), consider the following for a single feature i: If we average all j = {1, ...,K} records cleaned that have an error for that feature, weighted by their sampling probability:\n\u2206\u0304xi = 1\nNK K\u2211 j=1 (x(d)[i]\u2212 x(c)[i])\u00d7 1 p(j)\nSimilarly, for a label i:\n\u2206\u0304yi = 1\nNK K\u2211 j=1 (y(d)[i]\u2212 y(c)[i])\u00d7 1 p(j)\nEach \u2206\u0304xi and \u2206\u0304yi represents an average change in a single feature. A single vector can represent the necessary changes to apply to a record r: For a record r, the set of corrupted features is fr, lr. Then, each record r has a d-dimensional vector \u2206rx which is constructed as follows:\n\u2206rx[i] = { 0 i /\u2208 fr \u2206\u0304xi i \u2208 fr\nEach record r also has an l-dimensional vector \u2206ry which is constructed as follows:\n\u2206rx[i] = { 0 i /\u2208 lr \u2206\u0304yi i \u2208 lr\nFinally, the result is:\npr \u221d \u2016\u2207\u03c6(x, y, \u03b8(t)) +Mx \u00b7\u2206rx +My \u00b7\u2206ry\u2016"}, {"heading": "F. EXAMPLE MX , MY", "text": "Linear Regression:\n\u2207\u03c6(x, y, \u03b8) = (\u03b8Tx\u2212 y)x\nFor a record, r, suppose we have a feature vector x. If we take the partial derivatives with respect to x, Mx is:\nMx[i, i] = 2x[i] + \u2211 i 6=j \u03b8[j]x[j]\u2212 y\nMx[i, j] = \u03b8[j]x[i]\nSimilarly My is:\nMy[i, 1] = x[i]\nLogistic Regression:\n\u2207\u03c6(x, y, \u03b8) = (h(\u03b8Tx)\u2212 y)x\nwhere\nh(z) = 1\n1 + e\u2212z\nwe can rewrite this as:\nh\u03b8(x) = 1\n1 + e\u03b8T x\n\u2207\u03c6(x, y, \u03b8) = (h\u03b8(x)\u2212 y)x\nIn component form,\ng = \u2207\u03c6(x, y, \u03b8)\ng[i] = h\u03b8(x) \u00b7 x[i]\u2212 yx[i]\nTherefore,\nMx[i, i] = h\u03b8(x) \u00b7 (1\u2212 h\u03b8(x)) \u00b7 \u03b8[i]x[i] + h\u03b8(x)\u2212 y\nMx[i, j] = h\u03b8(x) \u00b7 (1\u2212 h\u03b8(x)) \u00b7 \u03b8[j]x[i] + h\u03b8(x)\nMy[i, 1] = x[i]\nSVM:\n\u2207\u03c6(x, y, \u03b8) = { \u2212y \u00b7 x if y \u00b7 x \u00b7 \u03b8 \u2264 1 0 if y x \u00b7 \u03b8 \u2265 1\nTherefore,\nMx[i, i] = { \u2212y[i] if y \u00b7 x \u00b7 \u03b8 \u2264 1 0 if y x \u00b7 \u03b8 \u2265 1\nMx[i, j] = 0\nMy[i, 1] = x[i]"}, {"heading": "G. AGGREGATE QUERIES AS CONVEX LOSSES", "text": "G.1 AVG and SUM queries avg, sum queries are a special case of the convex loss minimization discussed in the paper: If we define the following loss, it is easy to verify the the optimal \u03b8 is the mean \u00b5:\n\u03c6 = (xi \u2212 \u03b8)2\nwith the appropriate scaling it can support avg, sum queries with and without predicates. Taking the gradient of that loss:\n\u2207\u03c6 = 2(xi \u2212 \u03b8)\nIt is also easy to verify that the bound on errors isO( E((x\u2212\u00b5) 2\nbT ),\nwhich is essentially the CLT. The importance sampling results are inutitive as well. Applying the linearization:\nMx = 2\nThe importance sampling prioritizes points that it expects to be far away from the mean.\nG.2 MEDIAN Similarly, we can analyze the median query. If we define the following loss, it is easy to verify the the optimal \u03b8 is the median m:\n\u03c6 =| xi \u2212 \u03b8 |\nTaking the gradient of that loss:\n\u2207\u03c6 = 1 if < m, -1 if > m\nApplying the linearization:\nMx = 0\nThe intuitive result is that a robust query like a median does not need to consider estimation as the query result is robust to small changes."}, {"heading": "H. EXPERIMENTAL COMPARISON", "text": "H.1 Robust Logistic Regression We use the algorithm from Feng et al. for robust logistic regression.\n1. Input: Contaminated training samples {(x1, y1), ..., (xn, yn)} an upper bound on the number of outliers n, number of inliers n and sample dimension p.\n2. Initialization: Set T = 4 \u221a log p/n+ logn/n\n3. Remove samples (xi, yi) whose magnitude satisfies \u2016xi\u2016 \u2265 T .\n4. Solve regularized logistic regression problem."}, {"heading": "I. DOLLARS FOR DOCS SETUP", "text": "The dollars for docs dataset has the following schema:\nContr ibut ion ( p i _ s p e c i a l i t y , drug_name, device_name, corpora t ion , amount, d i spute , s t a t u s )\nTo flag suspect donations, we used the status attribute. When the status was \u201ccovered\" that means it was an allowed contribution under the researcher\u2019s declared protocol. When the status was \u201cnon-covered\" that means it was a disallowed contribution under the researcher\u2019s declared protocol. The rest of the textual attributes were featurized with a bag-ofwords model, and the numerical amount and dispute attributes were treated as numbers.\nWe cleaned the entire Dollars for Docs dataset upfront to be able to evaluate how different budgeted data cleaning strategies compare to cleaning the full data. To clean the dataset, we loaded the entire data 240089 records into Microsoft Excel. We identified four broad classes of errors: Corporations are inconsistently represented: \u201cPfizer\", \u201cPfizer Inc.\", \u201cPfizer Incorporated\". Drugs are inconsistently represented: \u201cTAXOTERE DOCETAXEL -PROSTATE CANCER\" and \u201cTAXOTERE\" Label of covered and not covered are not consistent: \u201cNo\", \u201cYes\",\u201cN\", \u201cThis study is not supported\", \u201cNone\", \u201cCombination\" Research subject must be a drug OR a medical device and not both: \u201cBIO FLU QPAN H7N9AS03 Vaccine\" and \u201cBIO FLU QPAN H7N9AS03 Device\"\nTo fix these errors, we sorted by each column and merged values that looked similar and removed inconsistencies as in the status labels. When there were ambiguities, we refered to the drug company\u2019s website and whitepapers. When possible, we used batch data transformations, like find and replace (i.e. the Set-of-Records model). In all, 44234 records had some error and full data cleaning required about 2 days of efforts.\nOnce cleaned, in our experiment, we encoded the 4 problems as data quality constraints. To fix the constraints, we looked up the clean value in the dataset that we cleaned up front. Rule 1: Matching dependency on corporation (Weighted Jaccard Similarity > 0.8). Rule 2: Matching dependency on drug (Weighted Jaccard Similarity > 0.8). Rule 3: Label must either be \u201ccovered\" or \u201cnot covered\". Rule 4: Either drug or medical device should be null."}, {"heading": "J. MNIST SETUP", "text": "We include visualization of the errors that we generated for the MNIST experiment. We generated these errors in MATLAB by taking the grayscale version of the image (a 64\u00d764 matrix) and corrupting them by block removal and fuzzying."}], "references": [{"title": "The stratosphere platform for big data analytics", "author": ["A. Alexandrov", "R. Bergmann", "S. Ewen", "J. Freytag", "F. Hueske", "A. Heise", "O. Kao", "M. Leich", "U. Leser", "V. Markl", "F. Naumann", "M. Peters", "A. Rheinl\u00e4nder", "M.J. Sax", "S. Schelter", "M. H\u00f6ger", "K. Tzoumas", "D. Warneke"], "venue": "VLDB J., 23(6),", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Progressive approach to relational entity resolution", "author": ["Y. Altowim", "D.V. Kalashnikov", "S. Mehrotra"], "venue": "PVLDB, 7(11),", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Query-oriented data cleaning with oracles", "author": ["M. Bergman", "T. Milo", "S. Novgorodov", "W.C. Tan"], "venue": "SIGMOD Conference,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Incremental gradient, subgradient, and proximal methods for convex optimization: A survey", "author": ["D.P. Bertsekas"], "venue": "CoRR, abs/1507.01030,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Stochastic gradient descent tricks", "author": ["L. Bottou"], "venue": "Neural Networks: Tricks of the Trade - Second Edition.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Tupleware: Distributed machine learning on small clusters", "author": ["A. Crotty", "A. Galakatos", "T. Kraska"], "venue": "IEEE Data Eng. Bull., 37(3),", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Optimal distributed online prediction using mini-batches", "author": ["O. Dekel", "R. Gilad-Bachrach", "O. Shamir", "L. Xiao"], "venue": "JMLR, 13,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Model-driven data acquisition in sensor networks", "author": ["A. Deshpande", "C. Guestrin", "S. Madden", "J.M. Hellerstein", "W. Hong"], "venue": "VLDB,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2004}, {"title": "Fast approximation of matrix coherence and statistical leverage", "author": ["P. Drineas", "M. Magdon-Ismail", "M.W. Mahoney", "D.P. Woodruff"], "venue": "JMLR, 13,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Robust logistic regression and classification", "author": ["J. Feng", "H. Xu", "S. Mannor", "S. Yan"], "venue": "NIPS,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "The elements of statistical learning, volume 1", "author": ["J. Friedman", "T. Hastie", "R. Tibshirani"], "venue": "Springer series in statistics Springer, Berlin,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2001}, {"title": "Corleone: Hands-off crowdsourcing for entity matching", "author": ["C. Gokhale", "S. Das", "A. Doan", "J.F. Naughton", "N. Rampalli", "J. Shavlik", "X. Zhu"], "venue": "SIGMOD,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "Incremental record linkage", "author": ["A. Gruenheid", "X.L. Dong", "D. Srivastava"], "venue": "PVLDB, 7(9),", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Active learning as non-convex optimization", "author": ["A. Guillory", "E. Chastain", "J. Bilmes"], "venue": "International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2009}, {"title": "Estimating the number and sizes of fuzzy-duplicate clusters", "author": ["A. Heise", "G. Kasneci", "F. Naumann"], "venue": "CIKM Conference,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Declarative support for sensor data cleaning", "author": ["S.R. Jeffery", "G. Alonso", "M.J. Franklin", "W. Hong", "J. Widom"], "venue": "Pervasive Computing,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2006}, {"title": "Enterprise data analysis and visualization: An interview study", "author": ["S. Kandel", "A. Paepcke", "J.M. Hellerstein", "J. Heer"], "venue": "IEEE Trans. Vis. Comput. Graph., 18(12),", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "A methodology for learning, analyzing, and mitigating social influence bias in recommender systems", "author": ["S. Krishnan", "J. Patel", "M.J. Franklin", "K. Goldberg"], "venue": "RecSys,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "Stale view cleaning: Getting fresh answers from stale materialized views", "author": ["S. Krishnan", "J. Wang", "M.J. Franklin", "K. Goldberg", "T. Kraska"], "venue": "PVLDB, 8(12),", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning accurate kinematic control of cable-driven surgical robots using data cleaning and gaussian process regression", "author": ["J. Mahler", "S. Krishnan", "M. Laskey", "S. Sen", "A. Murali", "B. Kehoe", "S. Patil", "J. Wang", "M. Franklin", "P. Abbeel", "K.Y. Goldberg"], "venue": "CASE,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2014}, {"title": "ERACER: a database approach for statistical inference and data cleaning", "author": ["C. Mayfield", "J. Neville", "S. Prabhakar"], "venue": "SIGMOD Conference,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2010}, {"title": "Scaling up crowd-sourcing to very large datasets: A case for active learning", "author": ["B. Mozafari", "P. Sarkar", "M.J. Franklin", "M.I. Jordan", "S. Madden"], "venue": "PVLDB, 8(2),", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "Query strategies for evading convex-inducing classifiers", "author": ["B. Nelson", "B.I.P. Rubinstein", "L. Huang", "A.D. Joseph", "S.J. Lee", "S. Rao", "J.D. Tygar"], "venue": "JMLR, 13,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2012}, {"title": "A survey on transfer learning", "author": ["S.J. Pan", "Q. Yang"], "venue": "TKDE, 22(10),", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2010}, {"title": "Progressive duplicate  detection", "author": ["T. Papenbrock", "A. Heise", "F. Naumann"], "venue": "IEEE Trans. Knowl. Data Eng., 27(5),", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2015}, {"title": "Active learning literature survey", "author": ["B. Settles"], "venue": "University of Wisconsin, Madison, 52:11,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2010}, {"title": "The interpretation of interaction in contingency tables", "author": ["E.H. Simpson"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological),", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1951}, {"title": "A sample-and-clean framework for fast and accurate query processing on dirty data", "author": ["J. Wang", "S. Krishnan", "M.J. Franklin", "K. Goldberg", "T. Kraska", "T. Milo"], "venue": "SIGMOD Conference,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2014}, {"title": "Incremental entity resolution on rules and data", "author": ["S.E. Whang", "H. Garcia-Molina"], "venue": "VLDB J., 23(1),", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2014}, {"title": "Is feature selection secure against training data poisoning", "author": ["H. Xiao", "B. Biggio", "G. Brown", "G. Fumera", "C. Eckert", "F. Roli"], "venue": "In ICML,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2015}, {"title": "Don\u2019t be scared: use scalable automatic repairing with maximal likelihood and bounded changes", "author": ["M. Yakout", "L. Berti-Equille", "A.K. Elmagarmid"], "venue": "SIGMOD Conference,", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2013}, {"title": "Guided data repair", "author": ["M. Yakout", "A.K. Elmagarmid", "J. Neville", "M. Ouzzani", "I.F. Ilyas"], "venue": "PVLDB, 4(5),", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2011}, {"title": "Stochastic optimization with importance sampling for regularized loss minimization", "author": ["P. Zhao", "T. Zhang"], "venue": "ICML,", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "Machine Learning on large and growing datasets is a key data management challenge with significant interest in both industry and academia [1, 5, 10, 20].", "startOffset": 138, "endOffset": 152}, {"referenceID": 5, "context": "Machine Learning on large and growing datasets is a key data management challenge with significant interest in both industry and academia [1, 5, 10, 20].", "startOffset": 138, "endOffset": 152}, {"referenceID": 16, "context": "Data often arrive dirty, including missing, incorrect, or inconsistent attributes, and analysts widely report that data cleaning and other forms of pre-processing account for up to 80% of their effort [3, 22].", "startOffset": 201, "endOffset": 208}, {"referenceID": 29, "context": "While data cleaning is an extensively studied problem, the predictive modeling setting poses a number of new challenges: (1) high dimensionality can amplify even a small amount of erroneous records [36], (2) the complexity can make it difficult to trace the consequnces of an error, and (3) there are often subtle technical cconditions (e.", "startOffset": 198, "endOffset": 202}, {"referenceID": 15, "context": "For example, battery-powered sensors can transmit unreliable measurements when battery levels are low [21].", "startOffset": 102, "endOffset": 106}, {"referenceID": 17, "context": ", typos), and unintentional cognitive biases [23].", "startOffset": 45, "endOffset": 49}, {"referenceID": 1, "context": "ActiveClean is inspired by the recent success of progressive data cleaning where a user can gradually clean more data until the desired accuracy is reached [6, 34, 30, 17, 26, 38, 37].", "startOffset": 156, "endOffset": 183}, {"referenceID": 28, "context": "ActiveClean is inspired by the recent success of progressive data cleaning where a user can gradually clean more data until the desired accuracy is reached [6, 34, 30, 17, 26, 38, 37].", "startOffset": 156, "endOffset": 183}, {"referenceID": 24, "context": "ActiveClean is inspired by the recent success of progressive data cleaning where a user can gradually clean more data until the desired accuracy is reached [6, 34, 30, 17, 26, 38, 37].", "startOffset": 156, "endOffset": 183}, {"referenceID": 12, "context": "ActiveClean is inspired by the recent success of progressive data cleaning where a user can gradually clean more data until the desired accuracy is reached [6, 34, 30, 17, 26, 38, 37].", "startOffset": 156, "endOffset": 183}, {"referenceID": 20, "context": "ActiveClean is inspired by the recent success of progressive data cleaning where a user can gradually clean more data until the desired accuracy is reached [6, 34, 30, 17, 26, 38, 37].", "startOffset": 156, "endOffset": 183}, {"referenceID": 31, "context": "ActiveClean is inspired by the recent success of progressive data cleaning where a user can gradually clean more data until the desired accuracy is reached [6, 34, 30, 17, 26, 38, 37].", "startOffset": 156, "endOffset": 183}, {"referenceID": 30, "context": "ActiveClean is inspired by the recent success of progressive data cleaning where a user can gradually clean more data until the desired accuracy is reached [6, 34, 30, 17, 26, 38, 37].", "startOffset": 156, "endOffset": 183}, {"referenceID": 10, "context": "Convex loss minimization problems are amenable to a variety of incremental optimization methodologies with provable guarantees (see Friedman, Hastie, and Tibshirani [15] for an introduction).", "startOffset": 165, "endOffset": 169}, {"referenceID": 26, "context": "Aggregates over mixtures of different populations of data can result in spurious relationships due to the well-known phenomenon called Simpson\u2019s paradox [32].", "startOffset": 153, "endOffset": 157}, {"referenceID": 27, "context": "This approach is similar to SampleClean [33], which was proposed to approximate the results of aggregate queries by applying them to a clean sample of data.", "startOffset": 40, "endOffset": 44}, {"referenceID": 30, "context": "Efficiency: Conversely, hypothetically assume that the analyst has implemented a correct Update(\u00b7) primitive and implements Identify(\u00b7) with a technique such as Active Learning to select records to clean [37, 38, 16].", "startOffset": 204, "endOffset": 216}, {"referenceID": 31, "context": "Efficiency: Conversely, hypothetically assume that the analyst has implemented a correct Update(\u00b7) primitive and implements Identify(\u00b7) with a technique such as Active Learning to select records to clean [37, 38, 16].", "startOffset": 204, "endOffset": 216}, {"referenceID": 11, "context": "Efficiency: Conversely, hypothetically assume that the analyst has implemented a correct Update(\u00b7) primitive and implements Identify(\u00b7) with a technique such as Active Learning to select records to clean [37, 38, 16].", "startOffset": 204, "endOffset": 216}, {"referenceID": 30, "context": "Machine learning has been applied in prior work to improve the efficiency of data cleaning [37, 38, 16].", "startOffset": 91, "endOffset": 103}, {"referenceID": 31, "context": "Machine learning has been applied in prior work to improve the efficiency of data cleaning [37, 38, 16].", "startOffset": 91, "endOffset": 103}, {"referenceID": 11, "context": "Machine learning has been applied in prior work to improve the efficiency of data cleaning [37, 38, 16].", "startOffset": 91, "endOffset": 103}, {"referenceID": 4, "context": "It is well known that even for an arbitrary initialization SGD makes significant progress in less than one epoch (a pass through the entire dataset) [9].", "startOffset": 149, "endOffset": 152}, {"referenceID": 6, "context": "1 Convergence Conditions and Properties Convergence properties of batch SGD formulations have been well studied [11].", "startOffset": 112, "endOffset": 116}, {"referenceID": 6, "context": "The convergence rates of SGD are also well analyzed [11, 8, 39].", "startOffset": 52, "endOffset": 63}, {"referenceID": 3, "context": "The convergence rates of SGD are also well analyzed [11, 8, 39].", "startOffset": 52, "endOffset": 63}, {"referenceID": 32, "context": "The convergence rates of SGD are also well analyzed [11, 8, 39].", "startOffset": 52, "endOffset": 63}, {"referenceID": 25, "context": "It turns out that the solution works reasonably well in practice on our experimental datasets and has been studied in Machine Learning as the Expected Gradient Length heuristic [31].", "startOffset": 177, "endOffset": 181}, {"referenceID": 9, "context": "Robust Logistic Regression [14].", "startOffset": 27, "endOffset": 31}, {"referenceID": 27, "context": "SampleClean (SC) [33].", "startOffset": 17, "endOffset": 21}, {"referenceID": 13, "context": "Active Learning (AL) [18].", "startOffset": 21, "endOffset": 25}, {"referenceID": 25, "context": "Within each iteration, examples are prioritized by distance to the decision boundary (called Uncertainty Sampling in [31]).", "startOffset": 117, "endOffset": 121}, {"referenceID": 1, "context": "Progressive data cleaning is a well studied problem especially in the context of entity resolution [6, 34, 30, 17].", "startOffset": 99, "endOffset": 114}, {"referenceID": 28, "context": "Progressive data cleaning is a well studied problem especially in the context of entity resolution [6, 34, 30, 17].", "startOffset": 99, "endOffset": 114}, {"referenceID": 24, "context": "Progressive data cleaning is a well studied problem especially in the context of entity resolution [6, 34, 30, 17].", "startOffset": 99, "endOffset": 114}, {"referenceID": 12, "context": "Progressive data cleaning is a well studied problem especially in the context of entity resolution [6, 34, 30, 17].", "startOffset": 99, "endOffset": 114}, {"referenceID": 20, "context": "Over the last 5 years a number of new results have expanded the scope and practicality of progressive data cleaning [26, 38, 37].", "startOffset": 116, "endOffset": 128}, {"referenceID": 31, "context": "Over the last 5 years a number of new results have expanded the scope and practicality of progressive data cleaning [26, 38, 37].", "startOffset": 116, "endOffset": 128}, {"referenceID": 30, "context": "Over the last 5 years a number of new results have expanded the scope and practicality of progressive data cleaning [26, 38, 37].", "startOffset": 116, "endOffset": 128}, {"referenceID": 31, "context": "There are a number of other works that use machine learning to improve the efficiency and/or reliability of data cleaning [38, 37, 16].", "startOffset": 122, "endOffset": 134}, {"referenceID": 30, "context": "There are a number of other works that use machine learning to improve the efficiency and/or reliability of data cleaning [38, 37, 16].", "startOffset": 122, "endOffset": 134}, {"referenceID": 11, "context": "There are a number of other works that use machine learning to improve the efficiency and/or reliability of data cleaning [38, 37, 16].", "startOffset": 122, "endOffset": 134}, {"referenceID": 30, "context": "train a model that evaluates the likelihood of a proposed replacement value [37].", "startOffset": 76, "endOffset": 80}, {"referenceID": 31, "context": "Machine learning is also increasingly applied to make automated repairs more reliable with human validation [38].", "startOffset": 108, "endOffset": 112}, {"referenceID": 11, "context": "Machine learning can extrapolate rules from a small set of examples cleaned by a human (or humans) to uncleaned data [16, 38].", "startOffset": 117, "endOffset": 125}, {"referenceID": 31, "context": "Machine learning can extrapolate rules from a small set of examples cleaned by a human (or humans) to uncleaned data [16, 38].", "startOffset": 117, "endOffset": 125}, {"referenceID": 21, "context": "This approach can be coupled with active learning [27] to learn an accurate model with the fewest possible number of examples.", "startOffset": 50, "endOffset": 54}, {"referenceID": 27, "context": "SampleClean [33] applies data cleaning to a sample of data, and estimates the results of aggregate queries.", "startOffset": 12, "endOffset": 16}, {"referenceID": 14, "context": "Sampling has also been applied to estimate the number of duplicates in a relation [19].", "startOffset": 82, "endOffset": 86}, {"referenceID": 2, "context": "explore the problem of query-oriented data cleaning [7], where given a query, they clean data relevant to that query.", "startOffset": 52, "endOffset": 55}, {"referenceID": 7, "context": "studied data acquisition in sensor networks [12].", "startOffset": 44, "endOffset": 48}, {"referenceID": 15, "context": "[21] explored similar prioritization based on value of information.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "explored how samples of materialized views can be maintained similar to how models are updated with a sample of clean data in this work [24].", "startOffset": 136, "endOffset": 140}, {"referenceID": 32, "context": "Stochastic Optimization and Active Learning: Zhao and Tong recently proposed using importance sampling in conjunction with stochastic gradient descent [39].", "startOffset": 151, "endOffset": 155}, {"referenceID": 8, "context": "This line of work builds on prior results in linear algebra that show that some matrix columns are more informative than others [13], and Active Learning which shows that some labels are more informative that others [31].", "startOffset": 128, "endOffset": 132}, {"referenceID": 25, "context": "This line of work builds on prior results in linear algebra that show that some matrix columns are more informative than others [13], and Active Learning which shows that some labels are more informative that others [31].", "startOffset": 216, "endOffset": 220}, {"referenceID": 25, "context": "Active Learning largely studies the problem of label acquisition [31], and recently the links between Active Learning and Stochastic optimization have been studied [18].", "startOffset": 65, "endOffset": 69}, {"referenceID": 13, "context": "Active Learning largely studies the problem of label acquisition [31], and recently the links between Active Learning and Stochastic optimization have been studied [18].", "startOffset": 164, "endOffset": 168}, {"referenceID": 23, "context": "Transfer Learning and Bias Mitigation: ActiveClean has a strong link to a field called Transfer Learning and Domain Adaptation [29].", "startOffset": 127, "endOffset": 131}, {"referenceID": 19, "context": "explored a calibration problem in which data was systematically corrupted [25] and proposed a rule-based technique for cleaning data.", "startOffset": 74, "endOffset": 78}, {"referenceID": 17, "context": "[23]) have the same structure, systematically corrupted data that is feeding into a model.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "Secure Learning: ActiveClean is also related to work in adversarial learning [28], where the goal is to make models robust to adversarial data manipulation.", "startOffset": 77, "endOffset": 81}, {"referenceID": 29, "context": "This line of work has extensively studied methodologies for making models private to external queries and robust to malicious labels [36], but the data cleaning problem explores more general corruptions than just malicious labels.", "startOffset": 133, "endOffset": 137}], "year": 2016, "abstractText": "Data cleaning is often an important step to ensure that predictive models, such as regression and classification, are not affected by systematic errors such as inconsistent, out-of-date, or outlier data. Identifying dirty data is often a manual and iterative process, and can be challenging on large datasets. However, many data cleaning workflows can introduce subtle biases into the training processes due to violation of independence assumptions. We propose ActiveClean, a progressive cleaning approach where the model is updated incrementally instead of re-training and can guarantee accuracy on partially cleaned data. ActiveClean supports a popular class of models called convex loss models (e.g., linear regression and SVMs). ActiveClean also leverages the structure of a user\u2019s model to prioritize cleaning those records likely to affect the results. We evaluate ActiveClean on five real-world datasets UCI Adult, UCI EEG, MNIST, Dollars For Docs, and WorldBank with both real and synthetic errors. Our results suggest that our proposed optimizations can improve model accuracy by up-to 2.5x for the same amount of data cleaned. Furthermore for a fixed cleaning budget and on all real dirty datasets, ActiveClean returns more accurate models than uniform sampling and Active Learning.", "creator": "LaTeX with hyperref package"}}}