{"id": "1602.05699", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Feb-2016", "title": "Query Answering with Inconsistent Existential Rules under Stable Model Semantics", "abstract": "Traditional bemoaning - tolerent query query and posits - provides initial telephone considers on prospective homomorphisms components of his ABox / searchable which which consistent first the typology. However, some rules in mmbg neither be inconvenient if why are extracted on ontology lesson meant story whose rip-offs knowledge surveying. In might paper know present it framework common investigation ignored ontological rules now stable model formalism, which is conversely that a notion \u201c monarchy repairs to pick subgroup system of the silliness without. Surprisingly, for R - acyclic pervasive rules with R - semi-transparent only streets existential reasons left archaea negations, both the indicates complexity especially most determining of codice_2 answering 1990 was rule {upgrade parameters} unless instead indeed one put then the outdated encoding chat semantics. This leads s their propose hundreds approaches before help it rule {repair transformational} by calling answer sets programming quickbooks. An laboratory objective shows that these useful have hardly qos now query answer under arguing repairs brought inventive patients.", "histories": [["v1", "Thu, 18 Feb 2016 07:23:28 GMT  (23kb)", "http://arxiv.org/abs/1602.05699v1", "Accepted by AAAI 2016"]], "COMMENTS": "Accepted by AAAI 2016", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["hai wan", "heng zhang", "peng xiao", "haoran huang", "yan zhang"], "accepted": true, "id": "1602.05699"}, "pdf": {"name": "1602.05699.pdf", "metadata": {"source": "CRF", "title": "Query Answering with Inconsistent Existential Rules under Stable Model Semantics", "authors": ["Hai Wan", "Heng Zhang", "Peng Xiao", "Haoran Huang", "Yan Zhang"], "emails": ["wanhai@mail.sysu.edu.cn", "hengzhang@hust.edu.cn"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 2.\n05 69\n9v 1\n[ cs\n.A I]\n1 8\nFe b\n20 16"}, {"heading": "Introduction", "text": "Querying inconsistent ontologies is an intriguing new problem that gives rise to a flourishing research activity in the description logic (DL) and existential rules community. Consistent query answering, first developed for relational databases (Arenas, Bertossi, and Chomicki 1999; Chomicki 2007) and then generalized as the AR and IAR semantics for several DLs (Lembo et al. 2010), is the most widely recognized semantics for inconsistencytolerant query answering. These two traditional semantics are based upon the notion of repair, defined as an inclusion-maximal subset of the ABox consistent with the TBox. Du, Qi, and Shen (2013) studied query answering under weight-based AR semantics for DL SHIQ. Bienvenu, Bourgaux, and Goasdoue\u0301 (2014) studied variants of AR and IAR semantics for DL-LiteR obtained by replacing classical repairs with various preferred repairs. Existential rules (also known as Datalog\u00b1) are set to play a central role in the context of query answering and information\n\u2217Corresponding author. Copyright c\u00a9 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\nextraction for the Semantic Web. Lukasiewicz et al. (2012; 2013; 2015) studied the data complexity and combined complexity of AR semantics under the main decidable classes of existential rules enriched with negative constraints.\nHowever, observe that some rules might be unreliable if they are extracted from ontology learning or written by unskillful knowledge engineer (Lehmann et al. 2011). Meyer et al. (2006) proposed a tableau-like algorithm which yields EXPTIME as upper bound for finding maximally concept-satisfiable terminologies represented in ALC. Kalyanpur et al. (2006) provided solutions on repairing unsatisfiable concepts in a consistent OWL ontology. Furthermore, usually there exist preferences between rules, and rules with negation are often considered less preferred than rules without negation. Scharrenbach et al. (2010) proposed that the original axioms must be preserved in the knowledge base under certain conditions and requires changing the underlying logics for repair. Wang et al. (2014) proposed that when new facts are added that contradict to the ontology, it is often desirable to revise the ontology according to the added data. Therefore, this motivates us to consider another repair that selects maximal components of the existential rules. We illustrate the motivation via the following example.\nExample 1. Let D = {Bat(a),Mammal(a)} be a database and let \u03a3 be the following rule set expressing that each bat can fly and has at least one cave to live in; and if one creature lives in cave then it is a trogloxene; and if we do not know one mammal can fly then it can not fly; if one creature can fly then it is a bird; additionally a bird can not be a trogloxene at the same time; similarly a bird can not be a mammal meanwhile.\nBat(x)\u2192 CanF ly(x), (1)\nBat(x)\u2192\u2203yLiveIn(x, y), Cave(y), (2)\nLiveIn(x, y), Cave(y)\u2192 Trogloxene(x), (3)\nMammal(x),not CanF ly(x)\u2192 CanNotF ly(x), (4)\nCanF ly(x)\u2192Bird(x), (5)\nBird(x), T rogloxene(x)\u2192\u22a5, (6)\nBird(x),Mammal(x)\u2192\u22a5. (7)\nClearly \u3008\u03a3, D\u3009 is inconsistent under stable model semantics. We assume P1 = {(1), (2), (3)} is more reliable (or preferred) than P2 = {(4), (5), (6), (7)} . Then we can delete (6) and (7), or (5) in P2 to restore the consistency, and get\ninclusion-maximal preferred consistent rule sets w.r.t. D:\n{(1), (2), (3), (4), (6), (7)}, {(1), (2), (3), (4), (5)}.\nWe will focus on the case where the database is reliable but rules are not. Our main goal is to present a framework of handling inconsistent existential rules under stable model semantics. We define a notion called rule repairs to select maximal components of the rules, the philosophy behind that is to trust the rules as many as possible. Our second goal is to perform an in-depth analysis of the data and combined complexity of inconsistency-tolerant query answering under rule repair semantics. Let us recall some previous work on existential rules under stable model semantics. Magka, Kro\u0308tzsch, and Horrocks (2013) presented R-acyclic and R-stratified normal rule sets each of which always admits at most one finite stable models. Zhang, Zhang, and You (2015) implicitly showed that the R-acyclicity is enough to capture all negation-free rule sets with finite stable models. Gottlob et al. (2014) proved the decidability of query answering under stable model semantics for guarded existential rules. Alviano and Pieris (2015) extended the stickiness notion to normal rule sets and showed that it assures the decidability for well-founded semantics rather than stable model semantics. We will focus on R-acyclic rule sets with R-stratified or full negations and guarded existential rules with stratified or full negations.\nOur main contributions are briefly summarized as follows. We define rule repair semantics to handle inconsistent existential rules under stable model semantics. We consider rule repairs w.r.t. inclusion-maximal subset or cardinality, and that with preference. We obtain a (nearly) complete picture of the data and combined complexity of inconsistencytolerant query answering under rule repair semantics (Table 1). Surprisingly, for R-acyclic existential rules with R-stratified or guarded existential rules with stratified negations, both the data complexity and combined complexity of query answering under the rule repair semantics remain the same as that under the conventional query answering semantics. Interestingly, the data complexity based upon weak-acyclic or guarded existential rules with stratified negation is PTIME-complete. This leads us to propose several approaches to handle the rule repair semantics by calling answer set programming (ASP) solvers. An experimental evaluation shows that these approaches have good scalability of query answering rule repairs on realistic cases."}, {"heading": "Preliminaries", "text": "We consider a standard first-order language. We use Var(\u03b5) to denote the variables appearing in an expression \u03b5. Databases. We assume an infinite set \u2206 of (data) constants, an infinite set \u2206n of (labeled) nulls (used as fresh Skolem terms), and an infinite set \u2206v of variables. A term t is a constant, a null, or a variable. We denote by x a sequence of variables x1, . . . , xk with k \u2265 0. An atom \u03b1 has the form R(t1, . . . , tn), where R is an n-ary relation symbol, and t1, . . . , tn are terms. A conjunction of atoms is often identified with the set of all its atoms. We assume a relational schema R, which is a finite set of relation symbols. An instance I is a (possibly infinite) set of facts p(t), i.e.,\natoms without involving variables, where t is a tuple of constants and nulls. A database D over a relational schema R is a finite instance with relation symbols from R and with arguments only from \u2206 (i.e., without involving nulls).\nNormal Logic Programs and Stable Models. Each normal (logic) program is a finite set of NLP rules of the form\n\u03b1 \u2190 \u03b21, . . . , \u03b2n, not\u03b2n+1, . . . , not\u03b2m (1)\nwhere \u03b1, \u03b21, . . . , \u03b2m are atoms and m \u2265 n \u2265 0. Given a rule r of the above form, let head(r) = \u03b1, let body+(r) = {\u03b21, . . . , \u03b2n}, and let body\u2212(r) = {\u03b2n+1, . . . , \u03b2m}.\nLet \u03a0 be a normal program. The Herbrand universe and Herbrand base of \u03a0 are denoted by HU(\u03a0) and HB(\u03a0), respectively. A variable-free rule r\u2032 is called an instance of some rule r \u2208 \u03a0 if there is a substitution \u03b8 : \u2206v \u2192 HU(\u03a0) such that r\u03b8 = r\u2032. Let ground(\u03a0), the grounding of \u03a0, be the set of all instances of r for all r \u2208 \u03a0.\nThe Gelfond-Lifschitz reduct of a normal program \u03a0 w.r.t. a set M \u2286 HB(\u03a0), denoted \u03a0M , is the (possibly infinite) ground positive program obtained from ground(\u03a0) by\n\u2022 deleting every rule r such that body\u2212(r) \u2229M 6= \u2205, and\n\u2022 deleting all negative literals from each remaining rule.\nA subset M of HB(\u03a0) is called a stable model of \u03a0 if it is the least model of ground(\u03a0M ). For more about stable model semantics, refer to (Gelfond and Lifschitz 1988; Ferraris, Lee, and Lifschitz 2011).\nNormal Existential Rules. Every normal (existential) rule is a first-order sentence of the form \u2200x\u2200y\u03d5(x,y) \u2192 \u2203z\u03c8(x, z), where \u03d5 is a conjunction of literals, i.e., atoms or negated atoms (of the form \u00ac\u03b1 where \u03b1 is atomic), \u03c8 is a conjunction of atoms, and each universally quantified variable appears in at least one positive conjunct of \u03d5. In the above normal rule, \u03d5 is called its body, and \u03c8 its head. A normal rule is called a constraint if its head is the \u201cfalse\u201d \u22a5. For simplicity, when writing a rule, we often omit the universal quantifiers; by a normal rule set, we always mean a finite number of normal existential rules.\nLet r be a normal rule \u03d5(x,y) \u2192 \u2203z\u03c8(x, z). For each variable z \u2208 z, we introduce an n-ary fresh function symbol f rz where n = |x|. The skolemization of r, denoted sk(r), is the rule obtained from r by substituting f rz (x) for z \u2208 z, followed by substituting \u201cnot\u201d for \u00ac. Let \u03a3 be a normal rule set. We define sk(\u03a3) to be the set of rules sk(r) for all r \u2208 \u03a3. Clearly, sk(\u03a3) can be regarded as a normal program in an obvious way. Given any database D, an instance is called a stable model of D \u222a\u03a3 if it is a stable model of D \u222a sk(\u03a3).\nA normal rule r is called guarded if there is a positive conjunct in the body of r that contains all the universally quantified variable of r, and a normal rule set is called guarded if every rule in it is guarded.\nA normal rule set \u03a3 is stratified if there is a function \u2113 that maps relation symbols to integers such that for all r \u2208 \u03a3:\n\u2022 for all relation symbols R occurring in the head and S positively occurring in the body, \u2113(R) \u2265 \u2113(S), and\n\u2022 for all relation symbols R occurring in the head and S negatively occurring in the body, \u2113(R) > \u2113(S).\nSometimes, the negations that occur in a stratified normal rule set are called stratified negations, and those in a nonstratified normal rule set are called full negations.\nLet r1 and r2 be two normal rules, and let B + i (resp., B \u2212 i and Hi) be the set of atoms positively (resp., negatively and positively) occurring in the body (resp., body and head) of ri. W.l.o.g., assume that no variable occurs in both r1 and r2. Rule r2 positively relies on r1, written r1 \u2192+ r2, if there exist a database D and a substitution \u03b8 such that B+1 \u03b8 \u2286 D, B\u22121 \u03b8 \u2229D = \u2205, B + 2 \u03b8 \u2286 D \u222a H1\u03b8, B \u2212 2 \u03b8 \u2229 (D \u222aH1\u03b8) = \u2205, B+2 \u03b8 * D and H2\u03b8 * D \u222a H1\u03b8. Rule r2 negatively relies on r1, written r1 \u2192\u2212 r2, if there exist a database D and a substitution \u03b8 such that B+1 \u03b8 \u2286 D, B \u2212 1 \u03b8 \u2229D = \u2205, B + 2 \u03b8 \u2286 D, B\u22122 \u03b8 \u2229 H1\u03b8 6= \u2205 and B \u2212 2 \u03b8 \u2229 D = \u2205. A normal rule set P is called R-acyclic if there is no cycle of positive reliances r1 \u2192+ . . . \u2192+ rn \u2192+ r1 that involves a rule with an existential quantifier, and P is called R-stratified if there is a partition {P1, . . . , Pn} of P such that, for every two normal rule sets Pi, Pj and rules r1 \u2208 Pi and r2 \u2208 Pj , if r1 \u2192+ r2 then i \u2264 j and if r1 \u2192\u2212 r2 then i < j.\nClassical Boolean Query Answering. A normal Boolean conjunctive query (NBCQ) Q is an existentially closed conjunction of atoms and negated atoms involving no null. Let Q+ (respectively., Q\u2212) be the set of atoms positively (respectively., negatively) occurring in Q. An NBCQ is called safe if every variable in an atom from Q\u2212 has at least one occurrence in Q+; it is covered if for every atom \u03b1 in Q\u2212, there is an atom in Q+ that contains all arguments of \u03b1.\nGiven a database D and an NBCQ Q, we write D |= Q if there exists an assignment h (that is, a function that maps each variable to a variable-free term) such that h(Q+) \u2286 D and h(Q\u2212) \u2229 D = \u2205. Furthermore, given a database D, a normal rule set \u03a3 and an NBCQ Q, we write D \u222a \u03a3 |=s Q if, for each stable model M of D\u222a\u03a3, we have that M |= Q.\nComplexity Classes. We assume that the reader is familiar with the complexity theory. Given a unary function T on natural numbers, by DTIME(T (n)) (NTIME(T (n)), respectively) we mean the class of languages decidable in time T (n) by a deterministic (nondeterministic, respectively) Turing machine. Besides the well-known complexity classes such as (co)(N)PTIME and (co)(N)2EXPTIME, we will also use several unusual classes as follows. By notation \u22062-2EXPTIME we mean the class of all languages decidable in exponential time by a deterministic Turing machine with an oracle for some N2EXPTIME-complete problem. The Boolean hierarchy (BH) is defined as follows: BH(1) is NPTIME; for k \u2265 1, BH(2k) (BH(2k + 1)) is the class of languages each of which is the intersection (union, respectively) of a language in BH(2k\u22121) (BH(2k), respectively) and a language in coNPTIME (NPTIME, respectively); BH is then the union of BH(n) for all n \u2265 1. Note that DP, the class for difference polynomial time, is exactly the class BH(2); BH(2k) is actually the class of languages each of which is the union of k languages in DP; and BH is closed under complement. It was shown by (Chang and Kadin 1996) that a collapse of the Boolean hierarchy implies a collapse of the polynomial hierarchy; thus it seems impossible to find a BH-complete problem."}, {"heading": "Existential Rule Repair Semantics", "text": "In this section, we propose several semantics to handle inconsistency in ontological knowledge base. Different from many existing works, we will focus on the case where the database is reliable but rules are not. Similar to the data repair semantics, see (Lembo et al. 2010), our inconsistencytolerant semantics will rely on a notion called rule repairs.\nTo define rule repairs, we arm every rule set with a preference. Such rule sets are called preference-based ontologies.\nDefinition 1. Each preference-based ontology is an ordered pair (\u03a3, ), where \u03a3 is a normal rule set, and is a preorder (i.e., a reflexive and transitive binary relation) on P(\u03a3) (i.e., the power set of \u03a3). We call a preference.\nNow, we are in the position to define rule repairs. Definition 2. Let O be a preference-based ontology (\u03a3, ) and D a database. A subset S of \u03a3 is called a (preferred rule) repair of \u03a3 w.r.t. and D (or simply a repair w.r.t. if \u03a3 and D are clear from the context) if D \u222a S has at least one stable model, and for all subsets S\u2032 of \u03a3 with S \u227a S\u2032 (i.e., S S\u2032 but S\u2032 6 S), D \u222a S\u2032 has no stable model.\nIntuitively, a preferred rule repair is a maximal component of the rule set which is consistent with the current database. The philosophy behind it is to trust the rules as many as possible. Note that the number of repairs are normally more than one. To avoid a choice among them, we follow the spirit of \u201ccertain\u201d query answering. The semantics is then as follows.\nDefinition 3. Let O be a preference-based ontology (\u03a3, ) where \u03a3 is a normal rule set, and let D be a database and Q an NBCQ. Then we write \u3008D,O\u3009 |= Q if, for all preferred rule repairs S of \u03a3 w.r.t. and D, we have D \u222a S |=s Q.\nThe following proposition shows us that our semantics for inconsistency-tolerant query answering will coincide with the classical semantics for query answering if the ontological knowledge base is consistent, which is clearly important.\nProposition 1. Let O be a preference-based ontology (\u03a3, ) and let D be a database. If \u03a3 \u222aD has a stable model, then \u3008D,O\u3009 |= Q iff \u03a3 \u222aD |=s Q for any NBCQ Q.\nWith the above definitions, we then have a framework to define semantics for rule-based inconsistency-tolerant query answering. To define concrete semantics, we need to find preferences which will be useful in real-world applications. Besides the preference based on the set inclusion \u2286, similar to (Bienvenu, Bourgaux, and Goasdoue\u0301 2014), we will consider other four kinds of preferences over subsets, which were first proposed by (Eiter and Gottlob 1995) to study logic-based abduction.\nCardinality (\u2264). Given any S, S\u2032 \u2286 \u03a3, we write S \u2264 S\u2032 if |S| \u2264 |S\u2032|. The intuition of using this preference is that we always prefer the rule set with the maximum number of rules which are most likely to be correct.\nPriority Levels (\u2286P , \u2264P ). Every prioritization P of \u03a3 is a tuple \u3008P1, . . . , Pn\u3009 where {P1, . . . , Pn} is a partition of \u03a3. Given a prioritization P = \u3008P1, . . . , Pn\u3009 of \u03a3, the preferences \u2286P and \u2264P can be defined as follows:\n\u2022 Prioritized set inclusion (\u2286P ): Given S, S\u2032 \u2286 \u03a3, we write S \u2286P S\u2032 if S \u2229 Pi = S\u2032 \u2229 Pi for every 1 \u2264 i \u2264 n, or there is some 1 \u2264 i \u2264 n such that S \u2229 Pi ( S\u2032 \u2229 Pi and for all 1 \u2264 j < i, S \u2229 Pj = S\u2032 \u2229 Pj .\n\u2022 Prioritized cardinality (\u2264P ): Given S, S\u2032 \u2286 \u03a3, we write S \u2264P S\u2032 if |S \u2229 Pi| = |S\u2032 \u2229 Pi| for every 1 \u2264 i \u2264 n, or there is some 1 \u2264 i \u2264 n such that |S \u2229 Pi| < |S\u2032 \u2229 Pi| and for all 1 \u2264 j < i, |S \u2229 Pj | = |S\u2032 \u2229 Pj |.\nWeights (\u2264w). A weight assignment is a function w : \u03a3 \u2192 N. Given two sets S, S\u2032 \u2286 \u03a3 and a weight assignment w, we write S \u2264w S\u2032 if \u2211 r\u2208S w(r) \u2264 \u2211 r\u2208S\u2032 w(r).\nIn the rest of this paper, we will fix P as a prioritization and w as a weight assignment unless otherwise noted. Example 2 (Example 1 continued). Let \u03a3 and D be the same as in Example 1. Then the repairs w.r.t.\u2286 and D are:\n{(1), (3), (4), (5), (6)}, {(1), (2), (3), (4), (5)}, {(1), (2), (4), (5), (6)}, {(1), (2), (3), (4), (6), (7)}, {(2), (3), (4), (5), (6), (7)}.\nThe repairs w.r.t.\u2264 and D include:\n{(1), (2), (3), (4), (6), (7)}, {(2), (3), (4), (5), (6), (7)}.\nLet P = \u3008P1, P2\u3009 where P1, P2 are the same as in Example 1. Then the repairs w.r.t.\u2286P and D are shown in Example 1, and the repairs w.r.t. \u2264P and D are:\n{(1), (2), (3), (4), (6), (7)}.\nLet w be the weight assignment that maps each rule to its index. Then the only repair w.r.t. \u2264w and D is:\n{(2), (3), (4), (5), (6), (7)}.\nLet Qa be query \u201cMammal(a)\u201d and Qb be query \u201cBird(a)\u201d, then we have \u3008D, (\u03a3,\u2286)\u3009 |= Qa and \u3008D, (\u03a3,\u2286P )\u3009 |= Qa, but \u3008D, (\u03a3,\u2286)\u3009 6|= Qb and \u3008D, (\u03a3,\u2286P )\u3009 6|= Qb.\nWe find that repairs under \u2286P , \u2264, \u2264P , and \u2264w are the subset of the inclusion-maximal repairs.\nTheorem 1. The repairs under \u2286P , \u2264, \u2264P , \u2264w are the subset of the repairs under \u2286.\nProof. Let S be the set of repairs under \u2286, SP be the set of repairs under \u2286P , we prove that SP \u2286 S. Suppose for contradiction that SP 6\u2286 S, then there exists a repair R, R \u2208 SP and R 6\u2208 S. Because the repairs in S are inclusion-maximal, we have R \u2282 R\u2032 for some R\u2032 \u2208 S. It is clear that R \u2282P R\u2032, then R is not a \u2286P repair which contradict our assumption.\nThe rest semantics can be proved similarly."}, {"heading": "Complexity Results", "text": "In this section, we study the data and combined complexity for query entailment under our rule repair semantics. In particular, we focus on the following decision problems:\n\u2022 Data complexity: Fixing a preference-based ontology O and an NBCQ Q, given any database D as input, deciding whether \u3008D,O\u3009 |= Q.\n\u2022 Combined complexity: Given any preference-based ontology O, any NBCQ Q and any database D as input, deciding whether \u3008D,O\u3009 |= Q.\nTo measure the size of input, we fix a natural way to represent a database D, a normal rule set \u03a3, an NBCQ Q, a prioritization P and a weight assigning function w, and let ||D||, ||\u03a3||, ||Q||, ||P ||, ||w|| denote the sizes of D,\u03a3, Q, P, w, respectively, w.r.t. the fixed representing approach. Given a preference-based ontology O = (\u03a3, ), we define\n||O|| :=\n\n\n\n||\u03a3|| if \u2208 {\u2286,\u2264},\n||\u03a3||+ ||P || if \u2208 {\u2286P ,\u2264P },\n||\u03a3||+ ||w|| if =\u2264w .\nBy properly representing, we can have that ||O|| = ||\u03a3||O(1). The following result is obvious.\nProposition 2.Let O be a preference-based ontology (\u03a3, ), where \u2208 {\u2286,\u2264,\u2264P ,\u2286P ,\u2264w}. Then, given any subsets S, S\u2032 \u2286 \u03a3, deciding whetherS \u227a S\u2032 is in DTIME(||O||O(1)).\nNow, let us consider the complexity of query answering for R-acyclic and R-stratified rule sets under our semantics.\nAlgorithm 1: PRQA(D,O,Q)\nInput : a database D, a preference-based ontology O = (\u03a3, ), and a Boolean query Q\nOutput: true if \u3008D,O\u3009 |= Q, and false otherwise 1 foreach S \u2286 \u03a3 do 2 if D \u222a S has at least one stable model then 3 isRepair := true;\n4 foreach S\u2032 \u2286 \u03a3 with S \u227a S\u2032 do 5 if D \u222a S\u2032 has at least one stable model then 6 isRepair := false; 7 break;\n8 if isRepair and D \u222a S 6|=s Q then 9 return false;\n10 return true;\nTheorem 2. Let O be a preference-based ontology (\u03a3, ), where \u03a3 is R-acyclic and R-stratified, and \u2208 {\u2286,\u2264,\u2286P , \u2264P ,\u2264w}. Given a database D and a safe NBCQ Q, deciding whether \u3008D,O\u3009 |= Q is PTIME-complete for data complexity, and 2EXPTIME-complete for combined complexity.\nProof. Let D be a database and Q be a safe NBCQ. By the definition of semantics, it is easy to verify that the problem of deciding whether \u3008D,O\u3009 |= Q can be solved by Alg. 1.\nFirst, we consider the data complexity. In Alg. 1, let us fix a preference-based ontology O = (\u03a3, ) as defined in this theorem, fix a safe NBCQ Q, and let D be the only input. As \u03a3 is R-acyclic and R-stratified, by Theorem 5 in (Magka, Kro\u0308tzsch, and Horrocks 2013), it is clear that the body of the second loop (the inside one) in Alg. 1 is computable in PTIME w.r.t. D. (Note that the existence of stable models can be reduced to the query answering problem in a routine way.) Since the second loop will be repeated a constant times, and by Proposition 2 the loop condition can be checked in a constant time. (Note that the rule set \u03a3 is fixed now.) Thus, the second loop can be computed in PTIME w.r.t. the size of D. By a similar argument, we can show that Alg. 1 can be implemented in PTIME w.r.t. D. This then\ncompletes the proof of membership. The hardness follows from the PTIME-hardness of Datalog for data complexity, see, e.g., (Dantsin et al. 2001).\nNext, we prove the combined complexity. Again, first address the membership. Let n be the number of rules in \u03a3. Clearly, the body of the second loop will be repeated at most 2n times. By Theorem 9 in (Magka, Kro\u0308tzsch, and Horrocks 2013), it is computable in DTIME(22 ||\u03a3||O(1)\n). By Proposition 2, it is also clear that the loop condition can be checked in DTIME(||O||O(1)). So, the second loop is computable in DTIME(22 ||O||O(1)\n) since n \u2264 ||\u03a3|| \u2264 ||O||. By a similar evaluation, we know that the algorithm is implementable in DTIME(22 ||O||O(1)\n). Thus, the combined complexity is in 2EXPTIME. And the hardness follows from the 2EXPTIME-hardness of query answering of the R-acyclic language (Magka, Kro\u0308tzsch, and Horrocks 2013) and the fact that D \u222a \u03a3 |=s Q iff \u3008D, (\u03a3\u2217, )\u3009 |= q, where \u03a3\u2217 is \u03a3 \u222a {Q \u2192 q} and q a fresh 0-ary relational symbol.\nTheorem 3. Let O be a preference-based ontology (\u03a3, ), where \u03a3 is R-acyclic with full negations and \u2208{\u2286,\u2264,\u2286P , \u2264P ,\u2264w}. Then, given a database D and a safe NBCQ Q, deciding whether \u3008D,O\u3009 |= Q is in BH for data complexity and in \u22062-2EXPTIME for combined complexity.\nProof. We first prove the data complexity. To do this, we need to define some notations. Let R be the schema of \u03a3. Given any subset X of \u03a3, let LX be the set of all Rdatabases D such that\n1. D \u222aX has at least one stable model, and 2. D \u222aX |=s Q does not hold, and 3. for all Y \u2286 \u03a3 with X \u227a Y , D \u222a Y has no stable model.\nLet L denote the union of LX for all subsets X of \u03a3. By the definition of the rule repair semantics, it is easy to see that \u3008D,O\u3009 |= Q iff there is no X \u2286 \u03a3 such that D \u2208 LX , iff D does not belong to L. Thus, if the following claim is true, by the definition of BH we then have the desired result. Notice that the complexity class BH is closed under complement.\nClaim. Given any subset X of \u03a3, it is in DP (w.r.t. the size of input database D) to determine whether D \u2208 LX .\nNow, it remains to show the claim. Fix a subset X \u2286 \u03a3. Let L1 denote the set of all R-databases such that conditions 1 and 2 hold, and let L2 denote the set of all R-databases such that the condition 3 holds. According to Theorem 2 in (Magka, Kro\u0308tzsch, and Horrocks 2013),L1 is in NPTIME and L2 in coNPTIME. (Note that, as \u03a3 and X are fixed, the number of subsets Y is independent on the size of input database; thus L2 should be in coNPTIME.) By definition, LX = L1 \u2229 L2 is in DP. This proves the data complexity.\nNext, we show the combined complexity. It is clear that \u3008D,O\u3009 |= Q holds iff there does not exist S \u2286 \u03a3 such that\n1. D \u222a S has at least one stable model, and 2. D \u222a S |=s Q does not hold, and 3. for all S\u2032 \u2286 \u03a3 with S \u227a S\u2032, D \u222aS\u2032 has no stable models.\nBy Theorem 2 in (Magka, Kro\u0308tzsch, and Horrocks 2013) and an analysis similar to that in Theorem 2 (for combined complexity), it is not difficult to see that, fixing S \u2286 \u03a3, both conditions 1 and 2 are in coN2EXPTIME, and condition 3 is in N2EXPTIME. For \u201cthere does not exist S \u2286 \u03a3\u201d, we can simply enumerate all subsets S, which can be done in 2|\u03a3| times. Therefore, query answering under the mentioned semantics must be in \u22062-2EXPTIME for combined complexity, which is as desired.\nNow let us focus on guarded rules. The proof of the following is similar to that of Theorem 2, but employs the complexity results in (Cal\u0131\u0300, Gottlob, and Lukasiewicz 2012). The only thing we should be careful about is the constraints.\nTheorem 4. Let O be a preference-based ontology (\u03a3, ), where \u03a3 is guarded and stratified, and \u2208 {\u2286,\u2264,\u2286P ,\u2264P , \u2264w}. Given a database D and a covered NBCQ Q, deciding whether \u3008D,O\u3009 |= Q is PTIME-complete for data complexity, and 2EXPTIME-complete for combined complexity.\nFor guarded rules with full negations, we have some results as below, where the proof for data complexity is similar to that in Theorem 3, and the proof for combined complexity is similar to that in Theorem 2. Both results rely on the corresponding complexity results in (Gottlob et al. 2014).\nTheorem 5. Let O be a preference-based ontology (\u03a3, ), where \u03a3 is guarded, and \u2208 {\u2286,\u2264,\u2286P ,\u2264P ,\u2264w}. Then, given a database D and a covered NBCQ Q, deciding whether \u3008D,O\u3009 |= Q is in BH for data complexity and 2EXPTIME-complete for combined complexity."}, {"heading": "Experimental Evaluation", "text": "To demonstrate the effectiveness, we have implemented a prototype system for query answering of R-acyclic rule languages under the rule-repair semantics w.r.t. \u2264, \u2286P , \u2264P and \u2264w, by calling a state-of-the-art ASP solver."}, {"heading": "From Query Answering to ASP", "text": "To improve the efficiency, we adopt particular algorithm for each rule-repair semantics. The algorithms are all based on breadth-first search. Finding rule repairs w.r.t. \u2286 uses the basic process illustrated in Alg. 1, and exponential checking will be conducted during the process. For rule repairs w.r.t. \u2264, though it works better than \u2286 for the reason that there is no need to search the rest levels once it finds consistent sets. As for rule repairs w.r.t. \u2286P , we design an algorithm\nwhich iterates over the rules from low to high prioritization. Once finding consistent results in the rules with lower prioritization, the searching stops. It\u2019s known that \u2264P can be translated into \u2264w, but not vice versa. As for \u2264w, we search by deleting rules from the lowest weight to the greatest.\nAs a whole, the algorithms for situations with prioritization or weights will be much more efficient if the rule set satisfies the following two conditions: \u2022 The size of rules with lower prioritization (less weights)\nis very small, even though the whole rule set is large; \u2022 The rule set can be consistent by only deleting rules with\nlower prioritization (less weights). These conditions can be easily found in real applications because incorrectness are mostly caused by the rules newly added and the amount of these rules is normally small."}, {"heading": "Experiments", "text": "We developed a prototype system QAIER1 (Query Answering with Inconsistent Existential Rules) in C++. QAIER can answer queries with inconsistent R-acyclic rule sets. When it needs to check the existence of stable models, QAIER invokes an ASP solver clingo-4.4.02.\nBenchmarks To estimate the performance of QAIER in a view of data complexity, we use the modified LUBM3 as a benchmark. Because LUBM is not R-acyclic, we modified LUBM by changing atoms and deleting rules to make sure that modified LUBM is R-acyclic. We use HermiT 4 to transform the modified LUBM ontology into DL-clauses, and replace at-least number restrictions in head atoms with existential quantification, then get 127 rules. Next we add default negations or constraints, and introduce the prioritization and weight under rule repair semantics. Considering that the number of default negations or constraints would not be very large, we introduce 9-11 for each instance. The\n1http://ss.sysu.edu.cn/%7ewh/qaier.html 2clingo-4.4.0. http://sourceforge.net/projects/potassco/files/clingo/ 3LUBM. http://swat.cse.lehigh.edu/projects/lubm/ 4HermiT. http://www.hermit-reasoner.com/\nintroduced prioritization or weight depends on the reliability of the rules. We use the EUDG5 to generate a database. By dXtY (Table 2) we mean that the instance involves X thousands facts and Y unreliable rules. For the performance in the view of combined complexity, we use the modified ChEBI (Magka, Kro\u0308tzsch, and Horrocks 2013) as a benchmark. By cXtY (Table 3) we mean that the instance involves X molecules and chemical classes and Y unreliable rules. Experimental results Table 2 (Table 3, respectively)6 shows the data (combined, respectively) complexity performance among rule repairs scale up, when #facts and #negs (#rules and #negs, respectively) grow. t\u2286, t\u2264, t\u2286P , t\u2264P , or t\u2264w records the queries answering time. Each instance is computed three times and taken the average. Because QAIER computes all the stable models, the sizes or the types of queries are not the important issues. Clearly, rule repairs w.r.t. \u2286P , \u2264P , and \u2264w have better performances than those of \u2286 and \u2264, which is due to the few number of unreliable rules. This condition can be easily found in realistic cases because most of the rules are reliable, while the latest learned rules considered unreliable are few."}, {"heading": "Related Work and Conclusions", "text": "In terms of changing the rule set/Tbox for repair, Meyer et al. (2006) proposed an algorithm running in EXPTIME that finds maximally concept-satisfiable terminologies in ALC. Scharrenbach et al. (2010) showed that probabilistic description logics can be used to resolve conflicts and receive a consistent knowledge base from which inferences can be drawn again. Also Qi and Du (2009) proposed model-based revision operators for terminologies in DL, and Wang et al. (2014) introduced a model-theoretic approach to ontology revision. In order to address uncertainty arising from inconsistency, Gottlob et al. (2013) extended the Datalog\u00b1 language with probabilistic uncertainty based on Markov logic networks. More generally, several works have focused on reasoning with inconsistent ontologies, see (Huang, van Harmelen, and ten Teije 2005; Haase et al. 2005) and references therein. Surprisingly, this paper shows that for R-acyclic existential rules with R-stratified or guarded existential rules with stratified negations both the data complexity and combined complexity of query answering under the rule repair semantics do not increase.\nWe have developed a general framework to handle inconsistent existential rules with default negations. Within this framework, we analyzed the data and combined complexity of inconsistency-tolerant query answering under rule repair semantics. We proposed approaches simulating queries answering under rule repairs with calling ASP solvers and developed a prototype system called QAIER. Our experiments\n5EUDG.http://www.informatik.uni-bremen.de/\u223cclu/combined/ 6All experiments run in Linux Ubuntu 14.04.1 LTS on a HP compaq 8200 elite with a 3.4GHz Intel Core i7 processor and 4G 1333 MHz memory. Real numbers in the tables figure the run time (in seconds) of query answering. If the time exceeds 1800 seconds, we write it as \u201c\u2013\u201d. #facts, #negs, and #rules means the number of facts in database, default negations and constraints, and rules respectively.\nshow that QAIER can scale up to large databases under rule repairs in practice. Future work will focus on identifying first order rewritable classes under rule repair semantics."}, {"heading": "Acknowledgments", "text": "We thank the reviewers for their comments and suggestions for improving the paper. The authors would like to thank Yongmei Liu and her research group for their helpful and informative discussions. Hai Wan\u2019s research was in part supported by the National Natural Science Foundation of China under grant 61573386, Natural Science Foundation of Guangdong Province of China under grant S2012010009836, and Guangzhou Science and Technology Project (No. 2013J4100058)."}], "references": [{"title": "Default negation for non-guarded existential rules", "author": ["Alviano", "M. Pieris 2015] Alviano", "A. Pieris"], "venue": "In Proceedings of the 34th ACM Symposium on Principles of Database Systems,", "citeRegEx": "Alviano et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Alviano et al\\.", "year": 2015}, {"title": "Consistent query answers in inconsistent databases", "author": ["Bertossi Arenas", "M. Chomicki 1999] Arenas", "L.E. Bertossi", "J. Chomicki"], "venue": "In Proceedings of the Eighteenth ACM SIGACTSIGMOD-SIGART Symposium on Principles of Database Systems, May 31 - June", "citeRegEx": "Arenas et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Arenas et al\\.", "year": 1999}, {"title": "Querying inconsistent description logic knowledge bases under preferred repair semantics", "author": ["Bourgaux Bienvenu", "M. Goasdou\u00e9 2014] Bienvenu", "C. Bourgaux", "F. Goasdou\u00e9"], "venue": "In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, July", "citeRegEx": "Bienvenu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bienvenu et al\\.", "year": 2014}, {"title": "A general datalog-based framework for tractable query answering over ontologies", "author": ["Gottlob Cal\u0131", "A. Lukasiewicz 2012] Cal\u0131", "G. Gottlob", "T. Lukasiewicz"], "venue": "Journal Web Semantics", "citeRegEx": "Cal\u0131\u0300 et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Cal\u0131\u0300 et al\\.", "year": 2012}, {"title": "The boolean hierarchy and the polynomial hierarchy: A closer connection", "author": ["Chang", "R. Kadin 1996] Chang", "J. Kadin"], "venue": "SIAM Journal on Computing", "citeRegEx": "Chang et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Chang et al\\.", "year": 1996}, {"title": "Complexity and expressive power of logic programming", "author": ["Dantsin"], "venue": "ACM Computing Surveys", "citeRegEx": "Dantsin,? \\Q2001\\E", "shortCiteRegEx": "Dantsin", "year": 2001}, {"title": "Weightbased consistent query answering over inconsistent SHIQ knowledge bases. Knowledge Information System 34(2):335\u2013371", "author": ["Qi Du", "J. Shen 2013] Du", "G. Qi", "Y. Shen"], "venue": null, "citeRegEx": "Du et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Du et al\\.", "year": 2013}, {"title": "The complexity of logic-based abduction", "author": ["Eiter", "T. Gottlob 1995] Eiter", "G. Gottlob"], "venue": "Journal of the ACM 42(1):3\u201342", "citeRegEx": "Eiter et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Eiter et al\\.", "year": 1995}, {"title": "Stable models and circumscription", "author": ["Lee Ferraris", "P. Lifschitz 2011] Ferraris", "J. Lee", "V. Lifschitz"], "venue": "Artifical Intelligence", "citeRegEx": "Ferraris et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ferraris et al\\.", "year": 2011}, {"title": "The stable model semantics for logic programming", "author": ["Gelfond", "M. Lifschitz 1988] Gelfond", "V. Lifschitz"], "venue": "In Proceedings of the Fifth International Conference and Symposium Logic Programming,", "citeRegEx": "Gelfond et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Gelfond et al\\.", "year": 1988}, {"title": "Query answering under probabilistic uncertainty in datalog+/- ontologies", "author": ["Gottlob"], "venue": "Annals of Mathematics and Artificial Intelligence", "citeRegEx": "Gottlob,? \\Q2013\\E", "shortCiteRegEx": "Gottlob", "year": 2013}, {"title": "Stable model semantics for guarded existential rules and description logics", "author": ["Gottlob"], "venue": "In Proceedings of the Fourteenth International Conference Principles of Knowledge Representation and Reasoning,", "citeRegEx": "Gottlob,? \\Q2014\\E", "shortCiteRegEx": "Gottlob", "year": 2014}, {"title": "A framework for handling inconsistency in changing ontologies", "author": ["Haase"], "venue": "In Proceedings of The Semantic Web - ISWC 2005, 4th International Semantic Web Conference,", "citeRegEx": "Haase,? \\Q2005\\E", "shortCiteRegEx": "Haase", "year": 2005}, {"title": "Reasoning with inconsistent ontologies", "author": ["van Harmelen Huang", "Z. ten Teije 2005] Huang", "F. van Harmelen", "A. ten Teije"], "venue": "In Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence,", "citeRegEx": "Huang et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2005}, {"title": "Repairing unsatisfiable concepts in OWL ontologies", "author": ["Kalyanpur"], "venue": "In Proceedings of the Semantic Web: Research and Applications, 3rd European Semantic Web Conference,", "citeRegEx": "Kalyanpur,? \\Q2006\\E", "shortCiteRegEx": "Kalyanpur", "year": 2006}, {"title": "Class expression learning for ontology engineering", "author": ["Lehmann"], "venue": "Journal Web Semantics", "citeRegEx": "Lehmann,? \\Q2011\\E", "shortCiteRegEx": "Lehmann", "year": 2011}, {"title": "Inconsistency-tolerant semantics for description logics", "author": ["Lembo"], "venue": "In Proceedings of Web Reasoning and Rule Systems - Fourth International Conference,", "citeRegEx": "Lembo,? \\Q2010\\E", "shortCiteRegEx": "Lembo", "year": 2010}, {"title": "From classical to consistent query answering under existential rules", "author": ["Lukasiewicz"], "venue": "In Proceedings of the TwentyNinth AAAI Conference on Artificial Intelligence,", "citeRegEx": "Lukasiewicz,? \\Q2015\\E", "shortCiteRegEx": "Lukasiewicz", "year": 2015}, {"title": "Inconsistency handling in datalog+/- ontologies", "author": ["Martinez Lukasiewicz", "T. Simari 2012] Lukasiewicz", "M.V. Martinez", "G.I. Simari"], "venue": "In Proceedings of 20th European Conference on Artificial Intelligence. ECAI 2012 Including Prestigious Applications of Artificial Intelligence (PAIS-2012) System Demon-", "citeRegEx": "Lukasiewicz et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Lukasiewicz et al\\.", "year": 2012}, {"title": "Complexity of inconsistencytolerant query answering in datalog+/", "author": ["Martinez Lukasiewicz", "T. Simari 2013] Lukasiewicz", "M.V. Martinez", "G.I. Simari"], "venue": "In Informal Proceedings of the 26th International Workshop on Description Logics,", "citeRegEx": "Lukasiewicz et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Lukasiewicz et al\\.", "year": 2013}, {"title": "Computing stable models for nonmonotonic existential rules", "author": ["Kr\u00f6tzsch Magka", "D. Horrocks 2013] Magka", "M. Kr\u00f6tzsch", "I. Horrocks"], "venue": "In Proceedings of the 23rd International Joint Conference on Artificial Intelligence,", "citeRegEx": "Magka et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Magka et al\\.", "year": 2013}, {"title": "Finding maximally satisfiable terminologies for the description logic ALC", "author": ["Meyer"], "venue": "In Proceedings of the Twenty-First National Conference on Artificial Intelligence and the Eighteenth Innovative Applications of Artificial Intelligence Conference,", "citeRegEx": "Meyer,? \\Q2006\\E", "shortCiteRegEx": "Meyer", "year": 2006}, {"title": "Model-based revision operators for terminologies in description logics", "author": ["Qi", "G. Du 2009] Qi", "J. Du"], "venue": "In Proceedings of the 21st International Joint Conference on Artificial Intelligence IJCAI", "citeRegEx": "Qi et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Qi et al\\.", "year": 2009}, {"title": "Structure preserving tbox repair using defaults", "author": ["Scharrenbach"], "venue": "In Proceedings of the 23rd International Workshop on Description Logics (DL", "citeRegEx": "Scharrenbach,? \\Q2010\\E", "shortCiteRegEx": "Scharrenbach", "year": 2010}, {"title": "Instance-driven tbox revision in dl-lite", "author": ["Wang"], "venue": "In Informal Proceedings of the 27th International Workshop on Description Logics,", "citeRegEx": "Wang,? \\Q2014\\E", "shortCiteRegEx": "Wang", "year": 2014}, {"title": "Existential rule languages with finite chase: Complexity and expressiveness", "author": ["Zhang Zhang", "H. You 2015] Zhang", "Y. Zhang", "J.H. You"], "venue": "In Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence, January", "citeRegEx": "Zhang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 16, "context": "Consistent query answering, first developed for relational databases (Arenas, Bertossi, and Chomicki 1999; Chomicki 2007) and then generalized as the AR and IAR semantics for several DLs (Lembo et al. 2010), is the most widely recognized semantics for inconsistencytolerant query answering. These two traditional semantics are based upon the notion of repair, defined as an inclusion-maximal subset of the ABox consistent with the TBox. Du, Qi, and Shen (2013) studied query answering under weight-based AR semantics for DL SHIQ.", "startOffset": 188, "endOffset": 461}, {"referenceID": 16, "context": "Consistent query answering, first developed for relational databases (Arenas, Bertossi, and Chomicki 1999; Chomicki 2007) and then generalized as the AR and IAR semantics for several DLs (Lembo et al. 2010), is the most widely recognized semantics for inconsistencytolerant query answering. These two traditional semantics are based upon the notion of repair, defined as an inclusion-maximal subset of the ABox consistent with the TBox. Du, Qi, and Shen (2013) studied query answering under weight-based AR semantics for DL SHIQ. Bienvenu, Bourgaux, and Goasdou\u00e9 (2014) studied variants of AR and IAR semantics for DL-LiteR obtained by replacing classical repairs with various preferred repairs.", "startOffset": 188, "endOffset": 570}, {"referenceID": 14, "context": "However, observe that some rules might be unreliable if they are extracted from ontology learning or written by unskillful knowledge engineer (Lehmann et al. 2011). Meyer et al. (2006) proposed a tableau-like algorithm which yields EXPTIME as upper bound for finding maximally concept-satisfiable terminologies represented in ALC.", "startOffset": 143, "endOffset": 185}, {"referenceID": 14, "context": "Kalyanpur et al. (2006) provided solutions on repairing unsatisfiable concepts in a consistent OWL ontology.", "startOffset": 0, "endOffset": 24}, {"referenceID": 14, "context": "Kalyanpur et al. (2006) provided solutions on repairing unsatisfiable concepts in a consistent OWL ontology. Furthermore, usually there exist preferences between rules, and rules with negation are often considered less preferred than rules without negation. Scharrenbach et al. (2010) proposed that the original axioms must be preserved in the knowledge base under certain conditions and requires changing the underlying logics for repair.", "startOffset": 0, "endOffset": 285}, {"referenceID": 14, "context": "Kalyanpur et al. (2006) provided solutions on repairing unsatisfiable concepts in a consistent OWL ontology. Furthermore, usually there exist preferences between rules, and rules with negation are often considered less preferred than rules without negation. Scharrenbach et al. (2010) proposed that the original axioms must be preserved in the knowledge base under certain conditions and requires changing the underlying logics for repair. Wang et al. (2014) proposed that when new facts are added that contradict to the ontology, it is often desirable to revise the ontology according to the added data.", "startOffset": 0, "endOffset": 459}, {"referenceID": 10, "context": "Gottlob et al. (2014) proved the decidability of query answering under stable model semantics for guarded existential rules.", "startOffset": 0, "endOffset": 22}, {"referenceID": 10, "context": "Gottlob et al. (2014) proved the decidability of query answering under stable model semantics for guarded existential rules. Alviano and Pieris (2015) extended the stickiness notion to normal rule sets and showed that it assures the decidability for well-founded semantics rather than stable model semantics.", "startOffset": 0, "endOffset": 151}, {"referenceID": 18, "context": "In terms of changing the rule set/Tbox for repair, Meyer et al. (2006) proposed an algorithm running in EXPTIME that finds maximally concept-satisfiable terminologies in ALC.", "startOffset": 51, "endOffset": 71}, {"referenceID": 18, "context": "In terms of changing the rule set/Tbox for repair, Meyer et al. (2006) proposed an algorithm running in EXPTIME that finds maximally concept-satisfiable terminologies in ALC. Scharrenbach et al. (2010) showed that probabilistic description logics can be used to resolve conflicts and receive a consistent knowledge base from which inferences can be drawn again.", "startOffset": 51, "endOffset": 202}, {"referenceID": 18, "context": "In terms of changing the rule set/Tbox for repair, Meyer et al. (2006) proposed an algorithm running in EXPTIME that finds maximally concept-satisfiable terminologies in ALC. Scharrenbach et al. (2010) showed that probabilistic description logics can be used to resolve conflicts and receive a consistent knowledge base from which inferences can be drawn again. Also Qi and Du (2009) proposed model-based revision operators for terminologies in DL, and Wang et al.", "startOffset": 51, "endOffset": 384}, {"referenceID": 18, "context": "In terms of changing the rule set/Tbox for repair, Meyer et al. (2006) proposed an algorithm running in EXPTIME that finds maximally concept-satisfiable terminologies in ALC. Scharrenbach et al. (2010) showed that probabilistic description logics can be used to resolve conflicts and receive a consistent knowledge base from which inferences can be drawn again. Also Qi and Du (2009) proposed model-based revision operators for terminologies in DL, and Wang et al. (2014) introduced a model-theoretic approach to ontology revision.", "startOffset": 51, "endOffset": 472}, {"referenceID": 10, "context": "In order to address uncertainty arising from inconsistency, Gottlob et al. (2013) extended the Datalog language with probabilistic uncertainty based on Markov logic networks.", "startOffset": 60, "endOffset": 82}], "year": 2016, "abstractText": "Traditional inconsistency-tolerent query answering in ontology-based data access relies on selecting maximal components of an ABox/database which are consistent with the ontology. However, some rules in ontologies might be unreliable if they are extracted from ontology learning or written by unskillful knowledge engineers. In this paper we present a framework of handling inconsistent existential rules under stable model semantics, which is defined by a notion called rule repairs to select maximal components of the existential rules. Surprisingly, for R-acyclic existential rules with R-stratified or guarded existential rules with stratified negations, both the data complexity and combined complexity of query answering under the rule repair semantics remain the same as that under the conventional query answering semantics. This leads us to propose several approaches to handle the rule repair semantics by calling answer set programming solvers. An experimental evaluation shows that these approaches have good scalability of query answering under rule repairs on realistic cases.", "creator": "LaTeX with hyperref package"}}}