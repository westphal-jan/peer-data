{"id": "1605.04469", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-May-2016", "title": "Rationale-Augmented Convolutional Neural Networks for Text Classification", "abstract": "We present a new Convolutional Neural Network (CNN) speed other addresses classification once operations prowess novelty on documents and their activity sentences. Specifically, believe consider scenarios it which annotators explicitly carter sentences (if deleted) clear support one record date implementations, go. download. , they provide rationales. Our developed uses such supervision via a well-defined alternative followed which only specifically the represented by old piecewise combination this along formula_26 attributes also its constituent charged. We propose well absentia - strength self-modifying styling change 60 its calculating they gives having sentence comes with rationale, for way then measures the outstanding of for sentence coming taken combined context singular in proportion to important expects. Experiments on 50 updated datasets make than addressed digital and particularly rationales demonstrate called our approach favor ncomputing its homogenize. Moreover, our model might practical describing meant terms predictions.", "histories": [["v1", "Sat, 14 May 2016 21:30:57 GMT  (149kb,D)", "https://arxiv.org/abs/1605.04469v1", null], ["v2", "Sat, 21 May 2016 01:05:59 GMT  (150kb,D)", "http://arxiv.org/abs/1605.04469v2", null], ["v3", "Sat, 24 Sep 2016 16:35:57 GMT  (131kb,D)", "http://arxiv.org/abs/1605.04469v3", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["ye zhang", "iain james marshall", "byron c wallace"], "accepted": true, "id": "1605.04469"}, "pdf": {"name": "1605.04469.pdf", "metadata": {"source": "CRF", "title": "Rationale-Augmented Convolutional Neural Networks for Text Classification", "authors": ["Ye Zhang", "Iain Marshall", "Byron C. Wallace"], "emails": ["yezhang@cs.utexas.edu,", "iain.marshall@kcl.ac.uk", "byron@ccs.neu.edu"], "sections": [{"heading": "1 Introduction", "text": "Neural models that exploit word embeddings have recently achieved impressive results on text classification tasks (Goldberg, 2015). Feed-forward Convolutional Neural Networks (CNNs), in particular, have emerged as a relatively simple yet powerful class of models for text classification (Kim, 2014).\nThese neural text classification models have tended to assume a standard supervised learning setting in which instance labels are provided. Here we consider an alternative scenario in which we assume\nthat we are provided a set of rationales (Zaidan et al., 2007; Zaidan and Eisner, 2008; McDonnell et al., 2016) in addition to instance labels, i.e., sentences or snippets that support the corresponding document categorizations. Providing such rationales during manual classification is a natural interaction for annotators, and requires little additional effort (Settles, 2011; McDonnell et al., 2016). Therefore, when training new classification systems, it is natural to acquire supervision at both the document and sentence level, with the aim of inducing a better predictive model, potentially with less effort.\nLearning algorithms must be designed to capitalize on these two types of supervision. Past work (Section 2) has introduced such methods, but these have relied on linear models such as Support Vector Machines (SVMs) (Joachims, 1998), operating over sparse representations of text. We propose a novel CNN model for text classification that exploits both document labels and associated rationales.\nSpecific contributions of this work as follows. (1) This is the first work to incorporate rationales into neural models for text classification. (2) Empirically, we show that the proposed model uniformly outperforms relevant baseline approaches across five datasets, including previously proposed models that capitalize on rationales (Zaidan et al., 2007; Marshall et al., 2016) and multiple baseline CNN variants, including a CNN equipped with an attention mechanism. We also report state-of-the-art results on the important task of automatically assessing the risks of bias in the studies described in full-text biomedical articles (Marshall et al., 2016). (3) Our model naturally provides explanations for its predicar X\niv :1\n60 5.\n04 46\n9v 3\n[ cs\n.C L\n] 2\n4 Se\np 20\ntions, providing interpretability. We have made available online both a Theano1 and a Keras implementation2 of our model."}, {"heading": "2 Related Work", "text": ""}, {"heading": "2.1 Neural models for text classification", "text": "Kim (2014) proposed the basic CNN model we describe below and then build upon in this work. Properties of this model were explored empirically in (Zhang and Wallace, 2015). We also note that Zhang et al. (2016) extended this model to jointly accommodate multiple sets of pre-trained word embeddings. Roughly concurrently to Kim, Johnson and Zhang (2014) proposed a similar CNN architecture, although they swapped in one-hot vectors in place of (pre-trained) word embeddings. They later developed a semi-supervised variant of this approach (Johnson and Zhang, 2015).\nIn related recent work on Recurrent Neural Network (RNN) models for text, Tang et al. (2015) proposed using a Long Short Term Memory (LSTM) layer to represent each sentence and then passing another RNN variant over these. And Yang et al. (2016) proposed a hierarchical network with two levels of attention mechanisms for document classification. We discuss this model specifically as well as attention more generally and its relationship to our proposed approach in Section 4.3.\n2.2 Exploiting rationales\nIn long documents the importance of sentences varies; some are more central than others. Prior work has investigated methods to measure the relative importance sentences (Ko et al., 2002; Murata et al., 2000). In this work we adopt a particular view of sentence importance in the context of document classification. In particular, we assume that documents comprise sentences that directly support their categorization. We call such sentences rationales.\nThe notion of rationales was first introduced by Zaidan et al. (2007). To harness these for classification, they proposed modifying the Support Vector Machine (SVM) objective function to encode\n1https://github.com/yezhang-xiaofan/ Rationale-CNN\n2https://github.com/bwallace/ rationale-CNN\na preference for parameter values that result in instances containing manually annotated rationales being more confidently classified than \u2018pseudo\u2019instances from which these rationales had been stripped. This approach dramatically outperformed baseline SVM variants that do not exploit such rationales. Yessenalina et al. (2010) later developed an approach to generate rationales.\nAnother line of related work concerns models that capitalize on dual supervision, i.e., labels on individual features. This work has largely involved inserting constraints into the learning process that favor parameter values that align with a priori featurelabel affinities or rankings (Druck et al., 2008; Mann and McCallum, 2010; Small et al., 2011; Settles, 2011). We do not discuss this line of work further here, as our focus is on exploiting provided rationales, rather than individual labeled features."}, {"heading": "3 Preliminaries: CNNs for text classification", "text": "We first review the simple one-layer CNN for sentence modeling proposed by Kim (2014). Given a sentence or document comprising n words w1, w2,...,wn, we replace each word with its d-\ndimensional pretrained embedding, and stack them row-wise, generating an instance matrix A \u2208 Rn\u00d7d.\nWe then apply convolution operations on this matrix using multiple linear filters, these will have the same width d but may vary in height. Each filter thus effectively considers distinct n-gram features, where n corresponds to the filter height. In practice, we introduce multiple, redundant features of each height; thus each filter height might have hundreds of corresponding instantiated filters. Applying filter i parameterized by Wi \u2208 Rhi\u00b7d to the instance matrix induces a feature map fi \u2208 Rn\u2212hi+1. This process is performed by sliding the filter from the top of the matrix (the start of the document or sentence) to the bottom. At each location, we apply elementwise multiplication between filter i and sub-matrix A[j : j + hi \u2212 1], and then sum up the resultant matrix elements. In this way, we induce a vector (feature map) for each filter.\nWe next run the feature map through an elementwise non-linear transformation. Specifically, we use the Rectified Linear Unit, or ReLU (Krizhevsky et al., 2012). We extract the maximum value oi from each feature map i (1-max pooling).\nFinally, we concatenate all of the features oi to form a vector representation o \u2208 R|F | for this instance, where |F | denotes the total number of filters. Classification is then performed on top of o, via a softmax function. Dropout (Srivastava et al., 2014) is often applied at this layer as a means of regularization. We provide an illustrative schematic of the basic CNN architecture just described in Figure 1. For more details, see (Zhang and Wallace, 2015).\nThis model was originally proposed for sentence classification (Kim, 2014), but we can adapt it for document classification by simply treating the document as one long sentence. We will refer to this basic CNN variant as CNN in the rest of the paper. Below we consider extensions that account for document structure."}, {"heading": "4 Rationale-Augmented CNN for Document Classification", "text": "We now move to the main contribution of this work: a rationale-augmented CNN for text classification. We first introduce a simple variant of the above CNN that models document structure (Section\n4.1) and then introduce a means of incorporating rationale-level supervision into this model (Section 4.2). In Section 4.3 we discuss connections to attention mechanisms and describe a baseline equipped with one, inspired by Yang et al. (2016)."}, {"heading": "4.1 Modeling Document Structure", "text": "Recall that rationales are snippets of text marked as having supported document-level categorizations. We aim to develop a model that can exploit these annotations during training to improve classification. Here we achieve this by developing a hierarchical model that estimates the probabilities of individual sentences being rationales and uses these estimates to inform the document level classification.\nAs a first step, we extend the CNN model above to explicitly account for document structure. Specifically, we apply a CNN to each individual sentence in a document to obtain sentence vectors independently. We then sum the respective sentence vectors to create a document vector.3 As before, we add a softmax layer on top of the document-level vector to perform classification. We perform regularization by applying dropout both on the individual sentence vectors and the final document vector. We will refer to this model as Doc-CNN. Doc-CNN forms the basis for our novel approach, described below."}, {"heading": "4.2 RA-CNN", "text": "In this section we present the Rationale-Augmented CNN (RA-CNN). Briefly, RA-CNN induces a document-level vector representation by taking a weighted sum of its constituent sentence vectors. Each sentence weight is set to reflect the estimated probability that it is a rationale in support of the most likely class. We provide a schematic of this model in Figure 2.\nRA-CNN capitalizes on both sentence- and document-level supervision. There are thus two steps in the training phase: sentence level training and document level training. For the former, we apply a CNN to each sentence j in document i to obtain sentence vectors xijsen. We then add a softmax layer parametrized by Wsen; this takes as input sentence vectors. We fit this model to maximize the probabilities of the observed rationales:\n3We also experimented with taking the average of sentence vectors, but summing performed better in informal testing.\np(yijsen = k;E,C,Wsen) = exp(W(k)Tsen xijsen)\u2211Ksen k=1 exp(W (k)T sen x ij sen)\n(1) Where yijsen denotes the rationale label for sentence j in document i, Ksen denotes the number of possible classes for sentences, E denotes the word embedding matrix, C denotes the convolution layer parameters, and Wsen is a matrix of weights (comprising one weight vector per sentence class).\nIn our setting, each sentence has three possible labels (Ksen = 3). When a rationale sentence appears in a positive document,4 it is a positive rationale; when a rationale sentence appears in a negative document, it is a negative rationale. All other sen-\n4All of the document classification tasks we consider here are binary, although extension of our model to multi-class scenarios is straight-forward.\ntences belong to a third, neutral class: these are nonrationales. We also experimented with having only two sentence classes: rationales and non-rationales, but this did not perform as well as explicitly maintaining separate classes for rationales of different polarities.\nWe train an estimator using the provided rationale annotations, optimizing over {E,C,Wsen} to minimize the categorical cross-entropy of sentence labels. Once trained, this sub-model can provide conditional probability estimates regarding whether a given sentence is a positive or a negative rationale, which we will denote by ppos and pneg, respectively.\nWe next train the document-level classification model. The inputs to this are vector representations of documents, induced by summing over constituent sentence vectors, as in Doc-CNN. However, in the RA-CNN model this is a weighted sum. Specifically, weights are set to the estimated probabilities\nthat corresponding sentences are rationales in the most likely direction. More precisely:\nxidoc = Ni\u2211 j=1 xijsen \u00b7max{pijpos, pijneg} (2)\nWhere Ni is the number of sentences in the ith document. The intuition is that sentences likely to be rationales will have greater influence on the resultant document vector representation, while the contribution of neutral sentences (which are less relevant to the classification task) will be minimized.\nThe final classification is performed by a softmax layer parameterized by Wdoc; the inputs to this layer are the document vectors. The Wdoc parameters are trained using the document-level labels, yidoc:\np(yidoc = k;E,C,Wdoc) = exp(W(k)Tdoc x i doc)\u2211Kdoc\nk=1 exp(W (k)T doc x i doc) (3)\nwhere Kdoc is the cardinality of the document label set. We optimize over parameters to minimize crossentropy loss (w.r.t. the document labels).\nWe note that the sentence- and document-level models share word embeddings E and convolution layer parameters C, but the document-level model has its own softmax parameters Wdoc. When training the document-level model, E, C and Wdoc are fit, but we hold Wsen fixed.\nThe above two-step strategy can be equivalently described as follows. We first estimate E, C and Wsen, which parameterize our model for identifying rationales in documents. We then move to fitting our document classification model. For this we initialize the word embedding and convolution parameters to the E and C estimates from the preceding step. We then directly minimize the document level classification objective, tuning E and C and simultaneously fitting Wdoc.\nNote that this sequential training strategy differs from the alternating training approach commonly used in multi-task learning (Collobert and Weston, 2008). We found that the latter approach does not work well here, leading us to instead adopt the cascade-like feature learning approach (Collobert and Weston, 2008) just described.\nOne nice property of our model is that it naturally provides explanations for its predictions: the model identifies rationales and then categorizes documents informed by these. Thus if the model classifies a test instance as positive, then by construction the sentences associated with the highest pijpos estimates are those that the model relied on most in coming to this disposition. These sentences can of course be output in conjunction with the prediction. We provide concrete examples of this in Section 7.2."}, {"heading": "4.3 Rationales as \u2018Supervised Attention\u2019", "text": "One may view RA-CNN as a supervised variant of a model equipped with an attention mechanism (Bahdanau et al., 2014). On this view, it is apparent that rather than capitalizing on rationales directly, we could attempt to let the model learn which sentences are important, using only the document labels. We therefore construct an additional baseline that does just this, thereby allowing us to assess the impact of learning directly from rationale-level supervision.\nFollowing the recent work of Yang et al. (2016), we first posit for each sentence vector a hidden representation uijsen. We then define a sentence-level context vector us, which we multiply with each u ij sen to induce a weight \u03b1ij . Finally, the document vector is taken as a weighted sum over sentence vectors, where weights reflect \u03b1\u2019s. We have:\nuijsen = tanh(Wsx ij sen + bs) (4)\n\u03b1ij = exp(uTs u ij sen)\u2211Ni\nj exp(uTs u ij sen)\n(5)\nxidoc = Ni\u2211 j \u03b1ijx ij sen (6)\nwhere xidoc again denotes the document vector fed into a softmax layer, and Ws, us and bs are learned during training. We will refer to this attention-based method as AT-CNN."}, {"heading": "5 Datasets", "text": "We used five text classification datasets to evaluate our approach in total. Four of these are biomedical text classification datasets (5.1) and the last is a collection of movie reviews (5.2). These datasets share the property of having recorded rationales associated\nwith each document categorization. We summarize attributes of all datasets used in this work in Table 1."}, {"heading": "5.1 Risk of Bias (RoB) Datasets", "text": "We used a collection Risk of Bias (RoB) text classification datasets, described at length elsewhere (Marshall et al., 2016). Briefly, the task concerns assessing the reliability of the evidence presented in full-text biomedical journal articles that describe the conduct and results of randomized controlled trials (RCTs). This involves, e.g., assessing whether or not patients were properly blinded as to whether they were receiving an active treatment or a comparator (such as a placebo). If such blinding is not done correctly, it compromises the study by introducing statistical bias into the treatment efficacy estimate(s) derived from the trial.\nA formal system for making bias assessments is codified by the Cochrane Risk of Bias Tool (Higgins et al., 2011). This tool defines multiple domains; the risk of bias may be assessed in each of these. We consider four domains here. (1) Random sequence generation (RSG): were patients were assigned to treatments in a truly random fashion? (2) Allocation concealment (AC): were group assignments revealed to the person assigning patients to groups (so that she may have knowingly or unknowingly) influenced these assignments? (3) Blinding of Participants and Personnel (BPP): were all trial participants and individuals involved in running the trial blinded as to who was receiving which treatment? (4) Blinding of outcome assessment (BOA): were the parties who measured the outcome(s) of interest blinded to the intervention group assignments? These assessments are somewhat subjective. To increase transparency, researchers performing RoB assessment therefore record rationales (sentences from articles) supporting their assessments."}, {"heading": "5.2 Movie Review Dataset", "text": "We also ran experiments on a movie review (MR) dataset with accompanying rationales. Pang and Lee (2004) developed and published the original version of this dataset, which comprises 1000 positive and 1000 negative movie reviews from the Internet Movie Database (IMDB).5 Zaidan et al. (2007) then\n5http://www.imdb.com/\naugmented this dataset by adding rationales corresponding to the binary classifications for 1800 documents, leaving the remaining 200 for testing. Because 200 documents is a modest test sample size, we ran 9-fold cross validation on the 1800 annotated documents (each fold comprising 200 documents). The rationales, as originally marked in this dataset, were sub-sentential snippets; for the purposes of our model, we considered the entire sentences containing the marked snippets as rationales."}, {"heading": "6 Experimental Setup", "text": ""}, {"heading": "6.1 Baselines", "text": "We compare against several baselines to assess the advantages of directly incorporating rationale-level supervision into the proposed CNN architecture. We describe these below. SVMs. We evaluated a few variants of linear Support Vector Machines (SVMs). These rely on sparse representations of text. We consider variants that exploit uni- and bi-grams; we refer to these as uni-SVM and bi-SVM, respectively. We also re-implemented the rationale augmented SVM (RA-SVM) proposed by Zaidan et al. (2007), described in Section 2.\nFor the RoB dataset, we also compare to a recently proposed multi-task SVM (MT-SVM) model developed specifically for these RoB datasets (Marshall et al., 2015; Marshall et al., 2016). This model exploits the intuition that the risks of bias across the domains codified in the aforementioned Cochrane RoB tool will likely be correlated. That is, if we know that a study exhibits a high risk of bias for one domain, then it seems reasonable to assume it is at an elevated risk for the remaining domains. Furthermore, Marshall et al. (2016) include rationale-level supervision by first training a (multi-task) sentencelevel model to identify sentences likely to support\nRoB assessments in the respective domains. Special features extracted from these predicted rationales are then activated in the document-level model, informing the final classification. This model is the stateof-the-art on this task.\nCNNs. We compare against several baseline CNN variants to demonstrate the advantages of our approach. We emphasize that our focus in this work is not to explore how to induce generally \u2018better\u2019 document vector representations \u2013 this question has been addressed at length elsewhere, e.g., (Le and Mikolov, 2014; Jozefowicz et al., 2015; Tang et al., 2015; Yang et al., 2016).\nRather, the main contribution here is an augmentation of CNNs for text classification to capitalize on rationale-level supervision, thus improving performance and enhancing interpretability. This informed our choice of baseline CNN variants: standard CNN (Kim, 2014), Doc-CNN (described above) and ATCNN (also described above) that capitalizes on an (unsupervised) attention mechanism at the sentence level, described in Section 4.3.6"}, {"heading": "6.2 Implementation/Hyper-Parameter Details", "text": "Sentence splitting. To split the documents from all datasets into sentences for consumption by our DocCNN and RA-CNN models, we used the Natural Language Toolkit (NLTK)7 sentence splitter.\nSVM-based models. We kept the 50,000 most frequently occurring features in each dataset. For estimation we used SGD. We tuned the C hyperparameter using nested development sets. For the RA-SVM, we additionally tuned the \u00b5 and Ccontrast parameters, as per Zaidan et al. (2007).\nCNN-based models. For all models and datasets we initialized word embeddings to pre-trained vectors fit via Word2Vec. For the movie reviews dataset these were 300-dimensional and trained on Google News.8 For the RoB datasets, these were 200-dimensional and trained on biomedical texts in PubMed/PubMed Central (Pyysalo et al., 2013).9\n6We also experimented briefly with LSTM and GRU (Gated Recurrent Unit) models, but found that simple CNN performed better than these. Moreover, CNNs are relatively robust and less sensitive to hyper-parameter selection.\n7http://www.nltk.org/api/nltk.tokenize.html 8https://code.google.com/archive/p/word2vec/ 9http://bio.nlplab.org/\nTraining proceeded as follows. We first extracted all sentences from all documents in the training data. The distribution of sentence types is highly imbalanced (nearly all are neutral). Therefore, we downsampled sentences before each epoch, so that sentence classes were equally represented. After training on sentence-level supervision, we moved to document-level model fitting. For this we initialized embedding and convolution layer parameters to the estimates from the preceding sentence-level training step (though these were further tuned to optimize the document-level objective).\nFor RA-CNN, we tuned the dropout rate (range: 0-.9) applied at the sentence vector level on each training fold (using a subset of the training data as a validation set) during the document level training phase. Anecdotally, we found this has a greater effect than the other model hyperparameters, which we thus set after a small informal process of experimentation on a subset of the data. Specifically, we fixed the dropout rate at the document level to 0.5, and we used 3 different filter heights: 3, 4 and 5, following (Zhang and Wallace, 2015). For each filter height, we used 100 feature maps for the baseline CNN, and 20 for all the other CNN variants.\nFor parameter estimation we used ADADELTA (Zeiler, 2012), mini-batches of size 50, and an early stopping strategy (using a validation set)."}, {"heading": "7 Results and Discussion", "text": ""}, {"heading": "7.1 Quantitative Results", "text": "For all CNN models, we replicated experiments 5 times, where each replication constituted 5-fold and 9-fold CV respectively the RoB and the movies datasets, respectively. We report the mean and observed ranges in accuracy across these 5 replications for these models, because attributes of the model (notably, dropout) and the estimation procedure render model fitting stochastic (Zhang and Wallace, 2015). We do not report ranges for SVM-based models because the variance inherent in the estimation procedure is much lower for these simpler, linear models.\nResults on the RoB datasets and the movies dataset are shown in Tables 2 and Table 3, respectively. RA-CNN consistently outperforms all of the baseline models, across all five datasets. We also\nobserve that CNN/Doc-CNN do not necessarily improve over the results achieved by SVM-based models, which prove to be strong baselines for longer document classification. This differs from previous comparisons in the context of classifying shorter texts. In particular, in previous work (Zhang and Wallace, 2015) we observed that CNN outperforms SVM uniformly on sentence classification tasks (the average sentence-length in these datasets was about 10). In contrast, in the datasets we consider in the present paper, documents often comprise hundreds of sentences, each in turn containing multiple words. We believe that it is in these cases that explicitly modeling which sentences are most important will result in the greatest performance gains, and this aligns with our empirical results.\nAnother observation is that AT-CNN does often improve performance over vanilla variants of CNN (i.e., without attention), especially on the RoB datasets, probably because these comprise longer documents. However, as one might expect, RACNN clearly outperforms AT-CNN by exploiting rationale-level supervision directly. And by exploiting rationale information directly, RA-CNN is able to consistently perform better than baseline CNN and SVM model variants. Indeed, we find that RACNN outperformed MT-SVM on all of the RoB datasets, and this was accomplished without exploiting cross-domain correlations (i.e., without multitask learning)."}, {"heading": "7.2 Qualitative Results: Illustrative Rationales", "text": "In addition to realizing superior classification performance, RA-CNN also provides explainable categorizations. The model can provide the highest scoring rationales (ranked by max{ppos, pneg}) for any given target instance, which in turn \u2013 by construction \u2013 are those that most influenced the final document classification.\nFor example, a sample positive rationale supporting a correct designation of a study as being at low risk of bias with respect to blinding of outcomes assessment reads simply The study was performed double blind. An example rationale extracted for a study (correctly) deemed at high risk of bias, meanwhile, reads as the present study is retrospective, there is a risk that the woman did not properly recall how and what they experienced ....\nTurning to the movie reviews dataset, an example rationale extracted from a glowing review of \u2018Goodfellas\u2019 (correctly classified as positive) reads this cinematic gem deserves its rightful place among the best films of 1990s. While a rationale extracted\nfrom an unfavorable review of \u2018The English Patient\u2019 asserts that the only redeeming qualities about this film are the fine acting of Fiennes and Dafoe and the beautiful desert cinematography.\nIn each of these cases, the extracted rationales directly support the respective classifications. This provides direct, meaningful insight into the automated classifications, an important benefit for neural models, which are often seen as opaque."}, {"heading": "8 Conclusions", "text": "We developed a new model (RA-CNN) for text classification that extends the CNN architecture to directly exploit rationales when available. We showed that this model outperforms several strong, relevant baselines across five datasets, including vanilla and hierarchical CNN variants, and a CNN model equipped with an attention mechanism. Moreover, RA-CNN automatically provides explanations for classifications made at test time, thus providing interpretability.\nMoving forward, we plan to explore additional mechanisms for exploiting supervision at lower levels in neural architectures. Furthermore, we believe an alternative approach may be a hybrid of the ATCNN and RA-CNN models, wherein an auxiliary loss might be incurred when the attention mechanism output disagrees with the available direct supervision on sentences."}, {"heading": "Acknowledgments", "text": "Research reported in this article was supported by the National Library of Medicine (NLM) of the National Institutes of Health (NIH) under award number R01LM012086. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health. This work was also made possible by the support of the Texas Advanced Computer Center (TACC) at UT Austin."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "arXiv preprint arXiv:1409.0473.", "citeRegEx": "Bahdanau et al\\.,? 2014", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "A unified architecture for natural language processing: Deep neural networks with multitask learning", "author": ["Ronan Collobert", "Jason Weston."], "venue": "Proceedings of the 25th international conference on Machine learning, pages 160\u2013167. ACM.", "citeRegEx": "Collobert and Weston.,? 2008", "shortCiteRegEx": "Collobert and Weston.", "year": 2008}, {"title": "Learning from labeled features using generalized expectation criteria", "author": ["Gregory Druck", "Gideon Mann", "Andrew McCallum."], "venue": "Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "Druck et al\\.,? 2008", "shortCiteRegEx": "Druck et al\\.", "year": 2008}, {"title": "A primer on neural network models for natural language processing", "author": ["Yoav Goldberg."], "venue": "arXiv preprint arXiv:1510.00726.", "citeRegEx": "Goldberg.,? 2015", "shortCiteRegEx": "Goldberg.", "year": 2015}, {"title": "The cochrane collaborations tool for assessing risk of bias in randomised", "author": ["Julian PT Higgins", "Douglas G Altman", "Peter C G\u00f8tzsche", "Peter J\u00fcni", "David Moher", "Andrew D Oxman", "Jelena Savovi\u0107", "Kenneth F Schulz", "Laura Weeks", "Jonathan AC Sterne"], "venue": null, "citeRegEx": "Higgins et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Higgins et al\\.", "year": 2011}, {"title": "Text categorization with support vector machines: Learning with many relevant features", "author": ["Thorsten Joachims."], "venue": "Springer.", "citeRegEx": "Joachims.,? 1998", "shortCiteRegEx": "Joachims.", "year": 1998}, {"title": "Effective use of word order for text categorization with convolutional neural networks", "author": ["Rie Johnson", "Tong Zhang."], "venue": "arXiv preprint arXiv:1412.1058.", "citeRegEx": "Johnson and Zhang.,? 2014", "shortCiteRegEx": "Johnson and Zhang.", "year": 2014}, {"title": "Semi-supervised convolutional neural networks for text categorization via region embedding", "author": ["Rie Johnson", "Tong Zhang."], "venue": "Advances in Neural Information Processing Systems (NIPs), pages 919\u2013927.", "citeRegEx": "Johnson and Zhang.,? 2015", "shortCiteRegEx": "Johnson and Zhang.", "year": 2015}, {"title": "An empirical exploration of recurrent network architectures", "author": ["Rafal Jozefowicz", "Wojciech Zaremba", "Ilya Sutskever."], "venue": "Proceedings of the 32nd International Conference on Machine Learning (ICML-15), pages 2342\u20132350.", "citeRegEx": "Jozefowicz et al\\.,? 2015", "shortCiteRegEx": "Jozefowicz et al\\.", "year": 2015}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim."], "venue": "arXiv preprint arXiv:1408.5882.", "citeRegEx": "Kim.,? 2014", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Automatic text categorization using the importance of sentences", "author": ["Youngjoong Ko", "Jinwoo Park", "Jungyun Seo."], "venue": "Proceedings of the 19th international conference on Computational linguistics-Volume 1, pages 1\u20137. Association for Computational Linguistics.", "citeRegEx": "Ko et al\\.,? 2002", "shortCiteRegEx": "Ko et al\\.", "year": 2002}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton."], "venue": "Advances in neural information processing systems, pages 1097\u20131105.", "citeRegEx": "Krizhevsky et al\\.,? 2012", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Distributed representations of sentences and documents", "author": ["Quoc V Le", "Tomas Mikolov."], "venue": "arXiv preprint arXiv:1405.4053.", "citeRegEx": "Le and Mikolov.,? 2014", "shortCiteRegEx": "Le and Mikolov.", "year": 2014}, {"title": "Generalized expectation criteria for semi-supervised learning with weakly labeled data", "author": ["Gideon S Mann", "Andrew McCallum."], "venue": "The Journal of Machine Learning Research, 11:955\u2013984.", "citeRegEx": "Mann and McCallum.,? 2010", "shortCiteRegEx": "Mann and McCallum.", "year": 2010}, {"title": "Automating risk of bias assessment for clinical trials", "author": ["Iain J Marshall", "Jo\u00ebl Kuiper", "Byron C Wallace."], "venue": "Biomedical and Health Informatics, IEEE Journal of, 19(4):1406\u20131412.", "citeRegEx": "Marshall et al\\.,? 2015", "shortCiteRegEx": "Marshall et al\\.", "year": 2015}, {"title": "Robotreviewer: evaluation of a system for automatically assessing bias in clinical trials", "author": ["Iain J Marshall", "Jo\u00ebl Kuiper", "Byron C Wallace."], "venue": "Journal of the American Medical Informatics Association, 23(1):193\u2013201.", "citeRegEx": "Marshall et al\\.,? 2016", "shortCiteRegEx": "Marshall et al\\.", "year": 2016}, {"title": "Why Is That Relevant? Collecting Annotator Rationales for Relevance Judgments", "author": ["Tyler McDonnell", "Matthew Lease", "Tamer Elsayad", "Mucahid Kutlu."], "venue": "Proceedings of the 4th AAAI Conference on Human Computation and Crowdsourcing (HCOMP).", "citeRegEx": "McDonnell et al\\.,? 2016", "shortCiteRegEx": "McDonnell et al\\.", "year": 2016}, {"title": "Japanese probabilistic information retrieval using location and category information", "author": ["Masaki Murata", "Qing Ma", "Kiyotaka Uchimoto", "Hiromi Ozaku", "Masao Utiyama", "Hitoshi Isahara."], "venue": "Proceedings of the fifth international workshop on on Information re-", "citeRegEx": "Murata et al\\.,? 2000", "shortCiteRegEx": "Murata et al\\.", "year": 2000}, {"title": "A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts", "author": ["Bo Pang", "Lillian Lee."], "venue": "Proceedings of the 42nd annual meeting on Association for Computational Linguistics, page 271. Association for Computational Lin-", "citeRegEx": "Pang and Lee.,? 2004", "shortCiteRegEx": "Pang and Lee.", "year": 2004}, {"title": "Distributional semantics resources for biomedical text processing", "author": ["Sampo Pyysalo", "Filip Ginter", "Hans Moen", "Tapio Salakoski", "Sophia Ananiadou."], "venue": "Proceedings of Languages in Biology and Medicine.", "citeRegEx": "Pyysalo et al\\.,? 2013", "shortCiteRegEx": "Pyysalo et al\\.", "year": 2013}, {"title": "Closing the loop: Fast, interactive semi-supervised annotation with queries on features and instances", "author": ["Burr Settles."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1467\u20131478. Association for Computational Lin-", "citeRegEx": "Settles.,? 2011", "shortCiteRegEx": "Settles.", "year": 2011}, {"title": "The constrained weight space svm: learning with ranked features", "author": ["Kevin Small", "Byron Wallace", "Thomas Trikalinos", "Carla E Brodley."], "venue": "Proceedings of the 28th International Conference on Machine Learning (ICML-11), pages 865\u2013872.", "citeRegEx": "Small et al\\.,? 2011", "shortCiteRegEx": "Small et al\\.", "year": 2011}, {"title": "Dropout: A simple way to prevent neural networks from overfitting", "author": ["Nitish Srivastava", "Geoffrey Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov."], "venue": "The Journal of Machine Learning Research, 15(1):1929\u20131958.", "citeRegEx": "Srivastava et al\\.,? 2014", "shortCiteRegEx": "Srivastava et al\\.", "year": 2014}, {"title": "Document modeling with gated recurrent neural network for sentiment classification", "author": ["Duyu Tang", "Bing Qin", "Ting Liu."], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1422\u20131432.", "citeRegEx": "Tang et al\\.,? 2015", "shortCiteRegEx": "Tang et al\\.", "year": 2015}, {"title": "Hierarchical attention networks for document classification", "author": ["Zichao Yang", "Diyi Yang", "Chris Dyer", "Xiaodong He", "Alex Smola", "Eduard Hovy."], "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguis-", "citeRegEx": "Yang et al\\.,? 2016", "shortCiteRegEx": "Yang et al\\.", "year": 2016}, {"title": "Automatically generating annotator rationales to improve sentiment classification", "author": ["Ainur Yessenalina", "Yejin Choi", "Claire Cardie."], "venue": "Proceedings of the ACL 2010 Conference Short Papers, pages 336\u2013341. Association for Computational Linguistics.", "citeRegEx": "Yessenalina et al\\.,? 2010", "shortCiteRegEx": "Yessenalina et al\\.", "year": 2010}, {"title": "Modeling annotators: A generative approach to learning from annotator rationales", "author": ["Omar F Zaidan", "Jason Eisner."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 31\u201340. Association for Computational Linguis-", "citeRegEx": "Zaidan and Eisner.,? 2008", "shortCiteRegEx": "Zaidan and Eisner.", "year": 2008}, {"title": "Using\u201d annotator rationales\u201d to improve machine learning for text categorization", "author": ["Omar Zaidan", "Jason Eisner", "Christine D Piatko."], "venue": "HLT-NAACL, pages 260\u2013267. Citeseer.", "citeRegEx": "Zaidan et al\\.,? 2007", "shortCiteRegEx": "Zaidan et al\\.", "year": 2007}, {"title": "Adadelta: an adaptive learning rate method", "author": ["Matthew D Zeiler."], "venue": "arXiv preprint arXiv:1212.5701.", "citeRegEx": "Zeiler.,? 2012", "shortCiteRegEx": "Zeiler.", "year": 2012}, {"title": "A sensitivity analysis of (and practitioners\u2019 guide to) convolutional neural networks for sentence classification", "author": ["Ye Zhang", "Byron C. Wallace."], "venue": "arXiv preprint arXiv:1510.03820.", "citeRegEx": "Zhang and Wallace.,? 2015", "shortCiteRegEx": "Zhang and Wallace.", "year": 2015}, {"title": "Mgnc-cnn: A simple approach to exploiting multiple word embeddings for sentence classification", "author": ["Ye Zhang", "Stephen Roller", "Byron C. Wallace."], "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Lin-", "citeRegEx": "Zhang et al\\.,? 2016", "shortCiteRegEx": "Zhang et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 3, "context": "Neural models that exploit word embeddings have recently achieved impressive results on text classification tasks (Goldberg, 2015).", "startOffset": 114, "endOffset": 130}, {"referenceID": 9, "context": "Feed-forward Convolutional Neural Networks (CNNs), in particular, have emerged as a relatively simple yet powerful class of models for text classification (Kim, 2014).", "startOffset": 155, "endOffset": 166}, {"referenceID": 27, "context": "Here we consider an alternative scenario in which we assume that we are provided a set of rationales (Zaidan et al., 2007; Zaidan and Eisner, 2008; McDonnell et al., 2016) in addition to instance labels, i.", "startOffset": 101, "endOffset": 171}, {"referenceID": 26, "context": "Here we consider an alternative scenario in which we assume that we are provided a set of rationales (Zaidan et al., 2007; Zaidan and Eisner, 2008; McDonnell et al., 2016) in addition to instance labels, i.", "startOffset": 101, "endOffset": 171}, {"referenceID": 16, "context": "Here we consider an alternative scenario in which we assume that we are provided a set of rationales (Zaidan et al., 2007; Zaidan and Eisner, 2008; McDonnell et al., 2016) in addition to instance labels, i.", "startOffset": 101, "endOffset": 171}, {"referenceID": 20, "context": "Providing such rationales during manual classification is a natural interaction for annotators, and requires little additional effort (Settles, 2011; McDonnell et al., 2016).", "startOffset": 134, "endOffset": 173}, {"referenceID": 16, "context": "Providing such rationales during manual classification is a natural interaction for annotators, and requires little additional effort (Settles, 2011; McDonnell et al., 2016).", "startOffset": 134, "endOffset": 173}, {"referenceID": 5, "context": "Past work (Section 2) has introduced such methods, but these have relied on linear models such as Support Vector Machines (SVMs) (Joachims, 1998), operating over sparse representations of text.", "startOffset": 129, "endOffset": 145}, {"referenceID": 27, "context": "(2) Empirically, we show that the proposed model uniformly outperforms relevant baseline approaches across five datasets, including previously proposed models that capitalize on rationales (Zaidan et al., 2007; Marshall et al., 2016) and multiple baseline CNN variants, including a CNN equipped with an attention mechanism.", "startOffset": 189, "endOffset": 233}, {"referenceID": 15, "context": "(2) Empirically, we show that the proposed model uniformly outperforms relevant baseline approaches across five datasets, including previously proposed models that capitalize on rationales (Zaidan et al., 2007; Marshall et al., 2016) and multiple baseline CNN variants, including a CNN equipped with an attention mechanism.", "startOffset": 189, "endOffset": 233}, {"referenceID": 15, "context": "We also report state-of-the-art results on the important task of automatically assessing the risks of bias in the studies described in full-text biomedical articles (Marshall et al., 2016).", "startOffset": 165, "endOffset": 188}, {"referenceID": 29, "context": "Properties of this model were explored empirically in (Zhang and Wallace, 2015).", "startOffset": 54, "endOffset": 79}, {"referenceID": 7, "context": "They later developed a semi-supervised variant of this approach (Johnson and Zhang, 2015).", "startOffset": 64, "endOffset": 89}, {"referenceID": 6, "context": "Roughly concurrently to Kim, Johnson and Zhang (2014) proposed a similar CNN architecture, although they swapped in one-hot vectors in place of (pre-trained) word embeddings.", "startOffset": 29, "endOffset": 54}, {"referenceID": 23, "context": "In related recent work on Recurrent Neural Network (RNN) models for text, Tang et al. (2015) proposed using a Long Short Term Memory (LSTM) layer to represent each sentence and then passing another RNN variant over these.", "startOffset": 74, "endOffset": 93}, {"referenceID": 23, "context": "In related recent work on Recurrent Neural Network (RNN) models for text, Tang et al. (2015) proposed using a Long Short Term Memory (LSTM) layer to represent each sentence and then passing another RNN variant over these. And Yang et al. (2016) proposed a hierarchical network with two levels of attention mechanisms for document classification.", "startOffset": 74, "endOffset": 245}, {"referenceID": 10, "context": "Prior work has investigated methods to measure the relative importance sentences (Ko et al., 2002; Murata et al., 2000).", "startOffset": 81, "endOffset": 119}, {"referenceID": 17, "context": "Prior work has investigated methods to measure the relative importance sentences (Ko et al., 2002; Murata et al., 2000).", "startOffset": 81, "endOffset": 119}, {"referenceID": 27, "context": "The notion of rationales was first introduced by Zaidan et al. (2007). To harness these for classification, they proposed modifying the Support Vector Machine (SVM) objective function to encode", "startOffset": 49, "endOffset": 70}, {"referenceID": 25, "context": "Yessenalina et al. (2010) later developed an approach to generate rationales.", "startOffset": 0, "endOffset": 26}, {"referenceID": 2, "context": "This work has largely involved inserting constraints into the learning process that favor parameter values that align with a priori featurelabel affinities or rankings (Druck et al., 2008; Mann and McCallum, 2010; Small et al., 2011; Settles, 2011).", "startOffset": 168, "endOffset": 248}, {"referenceID": 13, "context": "This work has largely involved inserting constraints into the learning process that favor parameter values that align with a priori featurelabel affinities or rankings (Druck et al., 2008; Mann and McCallum, 2010; Small et al., 2011; Settles, 2011).", "startOffset": 168, "endOffset": 248}, {"referenceID": 21, "context": "This work has largely involved inserting constraints into the learning process that favor parameter values that align with a priori featurelabel affinities or rankings (Druck et al., 2008; Mann and McCallum, 2010; Small et al., 2011; Settles, 2011).", "startOffset": 168, "endOffset": 248}, {"referenceID": 20, "context": "This work has largely involved inserting constraints into the learning process that favor parameter values that align with a priori featurelabel affinities or rankings (Druck et al., 2008; Mann and McCallum, 2010; Small et al., 2011; Settles, 2011).", "startOffset": 168, "endOffset": 248}, {"referenceID": 9, "context": "We first review the simple one-layer CNN for sentence modeling proposed by Kim (2014). Given a sentence or document comprising n words w1, w2,.", "startOffset": 75, "endOffset": 86}, {"referenceID": 11, "context": "Specifically, we use the Rectified Linear Unit, or ReLU (Krizhevsky et al., 2012).", "startOffset": 56, "endOffset": 81}, {"referenceID": 22, "context": "Dropout (Srivastava et al., 2014) is often applied at this layer as a means of regularization.", "startOffset": 8, "endOffset": 33}, {"referenceID": 29, "context": "For more details, see (Zhang and Wallace, 2015).", "startOffset": 22, "endOffset": 47}, {"referenceID": 9, "context": "This model was originally proposed for sentence classification (Kim, 2014), but we can adapt it for document classification by simply treating the document as one long sentence.", "startOffset": 63, "endOffset": 74}, {"referenceID": 24, "context": "3 we discuss connections to attention mechanisms and describe a baseline equipped with one, inspired by Yang et al. (2016).", "startOffset": 104, "endOffset": 123}, {"referenceID": 1, "context": "Note that this sequential training strategy differs from the alternating training approach commonly used in multi-task learning (Collobert and Weston, 2008).", "startOffset": 128, "endOffset": 156}, {"referenceID": 1, "context": "We found that the latter approach does not work well here, leading us to instead adopt the cascade-like feature learning approach (Collobert and Weston, 2008) just described.", "startOffset": 130, "endOffset": 158}, {"referenceID": 0, "context": "One may view RA-CNN as a supervised variant of a model equipped with an attention mechanism (Bahdanau et al., 2014).", "startOffset": 92, "endOffset": 115}, {"referenceID": 24, "context": "Following the recent work of Yang et al. (2016), we first posit for each sentence vector a hidden representation u sen.", "startOffset": 29, "endOffset": 48}, {"referenceID": 15, "context": "We used a collection Risk of Bias (RoB) text classification datasets, described at length elsewhere (Marshall et al., 2016).", "startOffset": 100, "endOffset": 123}, {"referenceID": 4, "context": "A formal system for making bias assessments is codified by the Cochrane Risk of Bias Tool (Higgins et al., 2011).", "startOffset": 90, "endOffset": 112}, {"referenceID": 18, "context": "Pang and Lee (2004) developed and published the original version of this dataset, which comprises 1000 positive and 1000 negative movie reviews from the Internet Movie Database (IMDB).", "startOffset": 0, "endOffset": 20}, {"referenceID": 18, "context": "Pang and Lee (2004) developed and published the original version of this dataset, which comprises 1000 positive and 1000 negative movie reviews from the Internet Movie Database (IMDB).5 Zaidan et al. (2007) then", "startOffset": 0, "endOffset": 207}, {"referenceID": 14, "context": "For the RoB dataset, we also compare to a recently proposed multi-task SVM (MT-SVM) model developed specifically for these RoB datasets (Marshall et al., 2015; Marshall et al., 2016).", "startOffset": 136, "endOffset": 182}, {"referenceID": 15, "context": "For the RoB dataset, we also compare to a recently proposed multi-task SVM (MT-SVM) model developed specifically for these RoB datasets (Marshall et al., 2015; Marshall et al., 2016).", "startOffset": 136, "endOffset": 182}, {"referenceID": 25, "context": "We also re-implemented the rationale augmented SVM (RA-SVM) proposed by Zaidan et al. (2007), described in Section 2.", "startOffset": 72, "endOffset": 93}, {"referenceID": 14, "context": "For the RoB dataset, we also compare to a recently proposed multi-task SVM (MT-SVM) model developed specifically for these RoB datasets (Marshall et al., 2015; Marshall et al., 2016). This model exploits the intuition that the risks of bias across the domains codified in the aforementioned Cochrane RoB tool will likely be correlated. That is, if we know that a study exhibits a high risk of bias for one domain, then it seems reasonable to assume it is at an elevated risk for the remaining domains. Furthermore, Marshall et al. (2016) include rationale-level supervision by first training a (multi-task) sentencelevel model to identify sentences likely to support", "startOffset": 137, "endOffset": 538}, {"referenceID": 12, "context": ", (Le and Mikolov, 2014; Jozefowicz et al., 2015; Tang et al., 2015; Yang et al., 2016).", "startOffset": 2, "endOffset": 87}, {"referenceID": 8, "context": ", (Le and Mikolov, 2014; Jozefowicz et al., 2015; Tang et al., 2015; Yang et al., 2016).", "startOffset": 2, "endOffset": 87}, {"referenceID": 23, "context": ", (Le and Mikolov, 2014; Jozefowicz et al., 2015; Tang et al., 2015; Yang et al., 2016).", "startOffset": 2, "endOffset": 87}, {"referenceID": 24, "context": ", (Le and Mikolov, 2014; Jozefowicz et al., 2015; Tang et al., 2015; Yang et al., 2016).", "startOffset": 2, "endOffset": 87}, {"referenceID": 9, "context": "This informed our choice of baseline CNN variants: standard CNN (Kim, 2014), Doc-CNN (described above) and ATCNN (also described above) that capitalizes on an (unsupervised) attention mechanism at the sentence level, described in Section 4.", "startOffset": 64, "endOffset": 75}, {"referenceID": 27, "context": "For the RA-SVM, we additionally tuned the \u03bc and Ccontrast parameters, as per Zaidan et al. (2007).", "startOffset": 77, "endOffset": 98}, {"referenceID": 19, "context": "8 For the RoB datasets, these were 200-dimensional and trained on biomedical texts in PubMed/PubMed Central (Pyysalo et al., 2013).", "startOffset": 108, "endOffset": 130}, {"referenceID": 29, "context": "5, and we used 3 different filter heights: 3, 4 and 5, following (Zhang and Wallace, 2015).", "startOffset": 65, "endOffset": 90}, {"referenceID": 28, "context": "For parameter estimation we used ADADELTA (Zeiler, 2012), mini-batches of size 50, and an early stopping strategy (using a validation set).", "startOffset": 42, "endOffset": 56}, {"referenceID": 29, "context": "We report the mean and observed ranges in accuracy across these 5 replications for these models, because attributes of the model (notably, dropout) and the estimation procedure render model fitting stochastic (Zhang and Wallace, 2015).", "startOffset": 209, "endOffset": 234}, {"referenceID": 27, "context": "Uni-SVM: unigram SVM, Bi-SVM: Bigram SVM, RA-SVM: Rationale-augmented SVM (Zaidan et al., 2007), MT-SVM: a multi-task SVM model specifically designed for the RoB task, which also exploits the available sentence supervision (Marshall et al.", "startOffset": 74, "endOffset": 95}, {"referenceID": 15, "context": ", 2007), MT-SVM: a multi-task SVM model specifically designed for the RoB task, which also exploits the available sentence supervision (Marshall et al., 2016).", "startOffset": 135, "endOffset": 158}, {"referenceID": 29, "context": "In particular, in previous work (Zhang and Wallace, 2015) we observed that CNN outperforms SVM uniformly on sentence classification tasks (the average sentence-length in these datasets was about 10).", "startOffset": 32, "endOffset": 57}], "year": 2016, "abstractText": "We present a new Convolutional Neural Network (CNN) model for text classification that jointly exploits labels on documents and their constituent sentences. Specifically, we consider scenarios in which annotators explicitly mark sentences (or snippets) that support their overall document categorization, i.e., they provide rationales. Our model exploits such supervision via a hierarchical approach in which each document is represented by a linear combination of the vector representations of its component sentences. We propose a sentence-level convolutional model that estimates the probability that a given sentence is a rationale, and we then scale the contribution of each sentence to the aggregate document representation in proportion to these estimates. Experiments on five classification datasets that have document labels and associated rationales demonstrate that our approach consistently outperforms strong baselines. Moreover, our model naturally provides explanations for its predictions.", "creator": "TeX"}}}