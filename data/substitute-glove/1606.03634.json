{"id": "1606.03634", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Jun-2016", "title": "The Opacity of Backbones", "abstract": "A stability as a nontrivial brawn $ F $ makes little collection $ S $ of its exponential new although almost makes one perspective suspension assignment $ a_S $ because that $ F [a_S] $ another pedialyte [MZK + 99, WGS03 ]. This sheet neuroscience entire nontransparency of backbones. We show does, after by notably believed comparison however nonzero simplifying much maybe, not exist sets of observables combinations so rest obvious, isomorphic entwining taken very its represent, $ a_S $, of those frenzies longer internecine. We been seen that, have rest turn assumption, not rather three 's boolean formulas we always have larger backbones yet output involved a backbone $ S $ what painful. Further, enough own that question formula_20 factoring that not how aftermath - be bring both is used hard, as either widely believed, soon the amplitude over conductivity by our 16 decision long not obviously mean although rarely possibility input.", "histories": [["v1", "Sat, 11 Jun 2016 21:49:24 GMT  (18kb)", "https://arxiv.org/abs/1606.03634v1", null], ["v2", "Mon, 28 Nov 2016 16:12:11 GMT  (19kb)", "http://arxiv.org/abs/1606.03634v2", null], ["v3", "Sun, 18 Dec 2016 23:54:22 GMT  (19kb)", "http://arxiv.org/abs/1606.03634v3", null], ["v4", "Sat, 28 Jan 2017 20:47:18 GMT  (19kb)", "http://arxiv.org/abs/1606.03634v4", null]], "reviews": [], "SUBJECTS": "cs.AI cs.CC cs.LO", "authors": ["lane a hemaspaandra", "david e narv\u00e1ez"], "accepted": true, "id": "1606.03634"}, "pdf": {"name": "1606.03634.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["David E. Narv\u00e1ez"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n60 6.\n03 63\n4v 4\n[ cs\n.A I]\n+99,WGS03]. This paper studies the nontransparency of backbones. We show that, under the widely believed assumption that integer factoring is hard, there exist sets of boolean formulas that have obvious, nontrivial backbones yet finding the values, aS , of those backbones is intractable. We also show that, under the same assumption, there exist sets of boolean formulas that obviously have large backbones yet producing such a backbone S is intractable. Further, we show that if integer factoring is not merely worst-case hard but is frequently hard, as is widely believed, then the frequency of hardness in our two results is not too much less than that frequency."}, {"heading": "1 Introduction", "text": "An important concept in the study of the SAT problem is the notion of backbones. The term was first used by Monasson et al. [MZK+99], and the following formal definition was provided by Williams, Gomes, and Selman [WGS03].\nDefinition 1. Let F be a boolean formula. A collection S of the variables of F is said to be a backbone if there is a unique partial assignment aS such that F [aS ] is satisfiable.\nIn that definition, aS assigns a value (true or false) to each variable in S, and F [aS ] is a shorthand meaning F except with each variable in S assigned the value specified for it in aS . A backbone S is nontrivial if S 6= \u2205. The size of a backbone S is the number of variables in S. For a backbone S (for formula F ), we say that aS is the value of the backbone S.\nFor example, every satisfiable formula has the trivial backbone S = \u2205. The formula x1\u2227x2 has four backbones, \u2205, {x1}, {x2}, and {x1, x2}, with respectively the values (listing\n\u2217An earlier version of this report will appear in Proceedings of the 31st AAAI Conference on Artificial Intelligence (AAAI-17) [HN17].\nvalues as bit-vectors giving the assignments in the lexicographical order of the names of the variables in S) \u01eb, 1, 0, and 10. The formula x1 \u2228 x2 has no nontrivial backbones. (Every formula that has a backbone will have a maximum backbone\u2014a backbone that every other backbone is a subset of. Backbone variables have been called \u201cfrozen variables,\u201d because each of them is the same over all satisfying assignments.)\nAs Williams, Gomes, and Selman [WGS03] note, \u201cbackbone variables are useful in studying the properties of the solution space of a... problem.\u201d1\nAnd that surely is so. But it is natural to hope to go beyond that and suspect that if formulas have backbones, we can use those to help SAT solvers. After all, if one is seeking to get one\u2019s hands on a satisfying assignment of an F that has a backbone, one need but substitute in the value of the backbone to have put all its variables to bed as to one\u2019s search, and thus to \u201conly\u201d have all the other variables to worry about.\nThe goal of the present paper is to understand, at least in a theoretical sense, the difficulty of\u2014the potential obstacles to doing\u2014what we just suggested. We will argue that even for cases when one can quickly (i.e., in polynomial time) recognize that a formula has at least one nontrivial backbone, it can be intractable to find one such backbone. And we will argue that even for cases when one can quickly (i.e., in polynomial time) find a large, nontrivial backbone, it can be intractable to find the value of that backbone. In particular, we will show that if integer factoring is hard, then both the just-made claims hold. Integer factoring is widely believed to be hard; indeed, if it were in polynomial time, RSA (the Rivest-Shamir-Adleman cryptosystem) itself would fall.\nIn fact, integer factoring is even believed to be hard on average. And we will be inspired by that to go beyond the strength of the results mentioned above. Regarding our results mentioned above, one might worry that the \u201cintractability\u201d might be very infrequent, i.e., merely a rare, worst-case behavior. But we will argue that if integer factoring\u2014or indeed any problem in NP \u2229 coNP\u2014is frequently hard, then the bad behavior types we mention above happen \u201calmost\u201d as often: If the frequency of hardness of integer factoring is d(n) for strings up to length n, then for some \u01eb > 0 the frequency of hardness of our problems is d(n\u01eb).\nNone of this means that backbones are not an excellent, important concept. Rather, this is saying\u2014proving, in fact, assuming that integer factoring is as hard as is generally believed\u2014that although the definition of backbone is merely about a backbone existing, one needs to be aware that going from a backbone existing to finding a backbone, and going from having a backbone to knowing its value, can be computationally expensive challenges.\n1We mention in passing that backbones also are very interesting for problems even harder than SAT, such as model counting (see Gomes, Sabharwal, and Selman, [GSS09])\u2014i.e., #SAT [Val79]: counting the number of satisfying assignments of a propositional boolean formula\u2014especially given the currently huge runtime differences between SAT-solvers and model counters. After all, a backbone for a formula helpfully pinpoints into a particular subspace all the solutions that one is seeking to count."}, {"heading": "2 Results", "text": "Section 2.1 will formulate our results without focusing on density. Then in Section 2.2 we will discuss how the frequency of hardness of sets of the type we have discussed is related to that of the sets in NP \u2229 coNP having the highest frequencies of hardness.\nThe present section focuses only on presenting the results and what they mean. We will provide proofs in Section 3."}, {"heading": "2.1 Basic Results", "text": "We first look at whether there can be simple sets of formulas for which one can easily compute/obtain a nontrivial backbone, yet one cannot easily find the value of that backbone.\nOur basic result on this is stated below as Theorem 2. In this and most of our results, we state as our hypothesis not that \u201cinteger factoring cannot be done in polynomial time,\u201d but rather that \u201cP 6= NP\u2229 coNP.\u201d This in fact makes our claims stronger ones than if they had as their hypotheses \u201cinteger factoring cannot be done in polynomial time,\u201d since it is well-known (because the decision version of integer factorization is itself in NP\u2229coNP) that \u201cinteger factoring cannot be done in polynomial time\u201d implies \u201cP 6= NP\u2229coNP.\u201d SAT will, as usual, denote the set of satisfiable (propositional) boolean formulas. (We do not assume that SAT by definition is restricted to CNF formulas.)\nTheorem 2. If P 6= NP \u2229 coNP, then there exists a set A \u2208 P, A \u2286 SAT, of boolean formulas such that:\n1. There is a polynomial-time computable function f such that (\u2200F \u2208 A)[f(F ) outputs a nontrivial backbone of F ].\n2. There does not exist any polynomial-time computable function g such that g(F ) computes the value of backbone f(F ).\nTheorem 2 remains true even if one restricts the backbones found by f to be of size 1. We state that, in a slightly more general form, as follows.\nTheorem 3. Let k \u2208 {1, 2, 3, . . .}. If P 6= NP \u2229 coNP, then there exists a set A \u2208 P, A \u2286 SAT, of boolean formulas such that:\n1. There is a polynomial-time computable function f such that (\u2200F \u2208 A)[f(F ) outputs a size-k backbone of F ].\n2. There does not exist any polynomial-time computable function g such that g(F ) computes the value of backbone f(F ).\nNow let us turn to the question of whether, when it is obvious that there is at least one nontrivial backbone, it can be hard to efficiently produce a nontrivial backbone. The following theorem shows that, if integer factoring is hard, the answer is yes.\nTheorem 4. If P 6= NP \u2229 coNP, then there exists a set A \u2208 P, A \u2286 SAT, of boolean formulas (each having at least one variable) such that:\n1. Each formula F \u2208 A has a backbone whose size is at least 49% of F \u2019s total number of variables.\n2. There does not exist any polynomial-time computable function g such that, on each F \u2208 A, g(F ) outputs a backbone whose size is at least 49%\u2014or even at least 2%\u2014of F \u2019s variables.\nThe 49% and 2% above are not at all magic, but are just for concreteness. It is easy to see that our proof that establishes the above theorem is in fact tacitly establishing the following more general claim (note: the smaller the \u01eb the stronger the claim, and so the fact that below we speak only of \u01eb \u2264 1 is not a weakness). The above theorem is the \u01eb = 1 case.\nTheorem 5. For each fixed \u01eb, 0 < \u01eb \u2264 1, the following claim holds. If P 6= NP\u2229coNP, then there exists a set A \u2208 P, A \u2286 SAT, of boolean formulas (each having at least one variable) such that:\n1. Each formula F \u2208 A has a backbone whose size is at least (50 \u2212 \u01eb)% of F \u2019s total number of variables.\n2. There does not exist any polynomial-time computable function g such that, on each F \u2208 A, g(F ) outputs a backbone whose size is at least (2\u01eb)% of F \u2019s variables."}, {"heading": "2.2 Frequency of Hardness", "text": "A practical person might worry about results of the previous section in the following way. (Here, |F | will denote the number of bits in the representation of F .) \u201cJust because something is hard, doesn\u2019t mean it is hard often. For example, consider Theorem 4. Perhaps there is a polynomial-time function g\u2032 that, though it on infinitely many F \u2208 A fails to compute the value of the backbone f(F ), has the property that for each F \u2208 A for which it fails it then is correct on the (in lexicographical order) next 22 22 |F |\nelements of A. In this case, the theorem is indeed true, but it is a worst-case extreme that doesn\u2019t recognize that in reality the errors may be few and far\u2014very, very far\u2014between.\u201d\nIn this section, we address that reasonable worry. We show that if even one problem in NP\u2229 coNP is frequently hard, then the sets in our previous sections can be made \u201calmost\u201d as frequently hard, in a sense of \u201calmost\u201d that we will make formal and specific. Since it is generally believed\u2014for example due to the generally believed typical-case hardness of integer factoring\u2014that there are sets in NP\u2229coNP that are quite frequently hard, it follows that the 22 22 |F |\nbehavior our practical skeptic was speculating about cannot happen. Or at least, if that behavior did happen, then that would imply that every single problem in NP \u2229 coNP has polynomial-time heuristic algorithms that make extraordinarily few errors.\nNote that no one currently knows for sure how frequently-hard problems in NP \u2229 coNP can be. But our results are showing that, whatever that frequency is, sets of the sort we\u2019ve\nbeen constructing are hard \u201calmost\u201d as frequently. This can at first seem a bit of a strange notion to get one\u2019s head around, especially as complexity theory often doesn\u2019t pay much attention to frequency-of-hardness issues (though such issues in complexity theory can be traced back at least as far as the work of Scho\u0308ning [Sch86]). But this actually is analogous to something every computer science researcher knows well, namely, NP-completeness. No one today knows for sure whether any NP problems are not in P. But despite that the longstanding NP-completeness framework lets one right now, today, prove clearly for specific problems that if any NP problem is not in P then that specific problem is not in P. The results of this section are about an analogous type of argument, except regarding frequency of hardness.\nWe now give our frequency-of-hardness version of Theorem 2. A claim is said to hold for almost every n if there exists an n0 beyond which the claims always holds, i.e., the claim fails at most at a finite number of values of n. (In the theorems of this section, n\u2019s universe is the natural numbers, {0, 1, 2, . . .}.)\nTheorem 6. If h is any nondecreasing function and for some B \u2208 NP\u2229 coNP it holds that each polynomial-time algorithm, viewed as a heuristic algorithm for testing membership in B, for almost every n (respectively, for infinitely many n) errs on at least h(n) of the strings whose length is at most n, then there exist an \u01eb > 0 and a set A \u2208 P, A \u2286 SAT, of boolean formulas such that:\n1. There is a polynomial-time computable function f such that (\u2200F \u2208 A)[f(F ) outputs a nontrivial backbone of F ].\n2. Each polynomial-time computable function g will err (i.e., will fail to compute the value of backbone f(F )), for almost every n (respectively, for infinitely many n), on at least h(n\u01eb) of the strings in A of length at most n.\nThe precisely analogous result holds for Theorem 3. The analogous results also hold for Theorems 4 and 5, and to be explicit, we state that for Theorem 4 as the following theorem (and from this the analogue for Theorem 5 will be implicitly clear).\nTheorem 7. If h is any nondecreasing function and for some B \u2208 NP\u2229 coNP it holds that each polynomial-time algorithm, viewed as a heuristic algorithm for testing membership in B, for almost every n (respectively, for infinitely many n) errs on at least h(n) of the strings whose length is at most n, then there exist an \u01eb > 0 and a set A \u2208 P, A \u2286 SAT, of boolean formulas such that:\n1. Each formula F \u2208 A has a backbone whose size is at least 49% of F \u2019s total number of variables.\n2. Each polynomial-time computable function g will err (i.e., will fail to compute a set of size at least 2% of F \u2019s variables that is a backbone of F ), for almost every n (respectively, for infinitely many n), on at least h(n\u01eb) of the strings in A of length at most n.\nWhat the above theorems say, looking at the contrapositives to the above results, is that if any of our above cases have polynomial-time heuristic algorithms that don\u2019t make errors too frequently, then every single set in NP \u2229 coNP (even those related to integer factoring) has polynomial-time heuristic algorithms that don\u2019t make errors too frequently.\nTo make the meaning of the above results clearer, and to be completely open with our readers, it is important to have a frank discussion about the effect of the \u201c\u01eb\u201d in the above results. Let us do this in two steps. First, we give as concrete examples two central types of growth rates that fall between polynomial and exponential. And second, we discuss how innocuous or noninnocuous the \u201c\u01eb\u201d above is.\nAs to our examples, suppose that for some fixed c > 0 a particular function h(n) satisfies h(n) = 2\u03c9((log n)\nc). Note that for each fixed \u01eb > 0, it hold that the function h\u2032(n) defined as h(n\u01eb) itself satisfies the same bound, h\u2032(n) = 2\u03c9((log n)\nc). (Of course, the constant implicit in the \u201c\u03c9\u201d potentially has become smaller in the latter case.) Similarly, suppose that a particular function h(n) satisfies h(n) = 2n \u03c9(1) . Then for each fixed \u01eb > 0 it will hold that h(n\u01eb) = 2n \u03c9(1)\n. The above at a casual glance might suggest that the weakening of the frequency claims between the most frequently hard problems in NP \u2229 coNP and our problems is a \u201cmere\u201d changing of a constant. In some sense it is, but constants that are standing on the shoulders of exponents have more of a kick than constants sitting on the ground floor. And so as a practical matter, the difference in the actual numbers when one substitutes in for them can be large. On the other hand, polynomial-time reductions sit at the heart of computer science\u2019s formalization of its problems, and density distortions from n to n\u01eb based on the stretching of reductions are simply inherent in the standard approaches of theory, since those are the distortions one gets due to polynomial-time reductions being able to stretch their inputs to length n1/\u01eb, i.e., polynomially. For example, it is well known that if B is an NP-complete set, then for every \u01eb > 0 it hold that B is polynomial-time isomorphic (which is theoretical computer science\u2019s strongest standard notion of them being \u201cessentially the same problem\u201d) to some set B\u2032 that contains at most 2n \u01eb\nstrings at each length n. Simply put, the \u201calmost\u201d in our \u201calmost as frequent\u201d claims is the natural, strong claim, judged by the amounts of slack that in theoretical computer are considered innocuous. And the results do give insight into how much the density does or does not change, e.g., the first above example shows that quasi-polynomial lower bounds on error frequency remain quasi-polynomial lower bounds on error frequency. However, on the other hand, there is a weakening, and even though it is in a \u201cconstant,\u201d that constant is in an exponent and so can alter the numerical frequency quite a bit.2\n2In reality, how nastily small will the \u201c\u01eb\u201d be? From looking inside the proofs of the results and thinking hard about the lengths of the formulas involved in the proofs (and resulting from the \u201cGalil\u201d version of Cook-Karp-Levin\u2019s Theorem that we will be discussing in the next section), one can see that \u01eb\u2019s value is primarily controlled by the running time of the NP machines for the NP sets B and B from the theorems of this section. If those machines run in time around nk, then \u01eb will vary, viewed as a function of k, roughly as (some constant times) the inverse of k."}, {"heading": "3 Proofs", "text": "We now provide the proofs or proof sketches for our results. We aim more for communication than for extremely detailed rigor. However, readers not interested in proofs may wish to skip this section and the appendix."}, {"heading": "3.1 Proofs for Section 2.1", "text": "We will prove all three of the theorems of Section 2.1 hand-in-hand, in a rather narrative fashion, as they share a framework. Each of that section\u2019s theorems starts with the assumption that P 6= NP\u2229coNP. So let B be some set instantiating that, i.e., B \u2208 (NP\u2229coNP)\u2212P. As all students learn when learning that SAT is NP-complete, we can efficiently transform the question of whether a machine accepts a particular string into a question about whether a certain boolean formula is satisfiable [Coo71,Kar72,Lev75]. The original work that did that did not require (and did not need to require) that the thus-created boolean formula transparently revealed what machine and input had been the input to the transformation. But it was soon noted that one can ensure that the formula mapped to transparently reveals the machine and input that were the input to the transformation; see Galil [Gal74] or our appendix.\nGalil\u2019s insight can be summarized in the following strengthened version of the standard claim regarding the so-called Cook-Karp-Levin Reduction. Let N1, N2, . . . be a fixed, standard enumeration of clocked, polynomial-time Turing machines, and w.l.o.g. assume that Ni runs within time n\ni + i on inputs of length n, and that Ni and i are polynomially related in size and easily obtained from each other. There is a function rGalil-Cook (for conciseness, we are writing Galil-Cook rather than Galil-Cook/Karp/Levin, although this version is closer to the setting of Karp and Levin than to that of Cook, since Cook used Turing reductions rather than many-one reductions) such that\n1. For each Ni and x: x \u2208 L(Ni) if and only if rGalil-Cook(Ni, x) \u2208 SAT .\n2. There is a polynomial p such that rGalil-Cook(Ni, x) runs within time polynomial (in particular, with p being the polynomial) in |Ni| and |x| i + i.\n3. There is a polynomial-time function s such that for each Ni and x, s(rGalil-Cook(Ni, x)) outputs the pair (Ni, x).\nWe will be using two separate applications of the r function in our construction. But we need those two applications to be variable-disjoint. We will need this as otherwise we\u2019d have interference with some of our claims about sizes of backbones and which variables are fixed and how many variables we have. These are requirements not present in any previous work that used the r function of Galil-Cook. We also will want to be able to have some literal names (in particular, \u201cz\u201d-using literal names of the form z\u2113, z \u2032 \u2113 z\u2113, or z \u2032 \u2113, for all \u2113) available to us that we know are not part of the output of any application of the Galil-Cook r function; we need them as our construction involves not just two applications\nof the r function but also some additional variables. We can accomplish all the special requirements just mentioned as follows. We will, w.l.o.g., assume that in the output of the Galil-Cook function rGalil-Cook(Ni, x), every variable is of the form xj (the x there is not a generic example of a letter, but really means the letter \u201cx\u201d just a \u201cz\u201d earlier really means the letter \u201cz\u201d), where j itself, when viewed as a pair of integers via the standard fixed correspondence between Z+ and Z+ \u00d7Z+, has Ni as its first component or actually, to be completely precise, the natural number corresponding to Ni in the standard fixed correspondence between positive integers and strings. Though not all implementations of the Galil-Cook r function need have this property (and in fact, none has previously satisfied it as far as we know), we claim that one can implement a legal Galil-Cook r function in such a way that it has this property yet still has the property that this r function will have a polynomial-time inversion function s satisfying the behavior for s mentioned above. (For those wanting more information on how such a function rGalil-Cook(Ni, x) can be implemented that has all the properties claimed above, we have included as a technical appendix, namely as Appendix A, a detailed construction we have built that accomplishes this.)\nWe now can specify the sets A needed by the theorems of Section 2.1. Recall we have (thanks to the assumptions of the theorems) fixed a set B \u2208 (NP\u2229coNP)\u2212P. B \u2208 NP so let i be a positive integer such that Ni is a machine from the abovementioned standard enumeration such that L(Ni) = B. B \u2208 NP so let j be a positive integer such that Nj is a machine from the abovementioned standard enumeration, such that L(Nj) = B. Fix any positive integer k. Then for the case of that fixed value k, the set A of Theorem 3 is as follows: A3,k = {(z1 \u2227 z2 \u2227 \u00b7 \u00b7 \u00b7 \u2227 zk \u2227 (rGalil-Cook(Ni, x))) \u2228 (z1 \u2227 z2 \u2227 \u00b7 \u00b7 \u00b7 \u2227 zk \u2227 (rGalil-Cook(Nj, x))) | x \u2208 \u03a3\u2217}. One must keep in mind in what follows that, as per the previous paragraph, rGalil-Cook never outputs literals with names involving subscripted zs or z\n\u2032s and the outputs of rGalil-Cook(Ni, x) and rGalil-Cook(Nj , x) share no variable names (since i 6= j).\nLet us argue that A3,k indeed satisfies the requirements of the A for the \u201ck\u201d case of Theorem 3.\nA \u2208 P: Given a string y whose membership in A we are testing, we make sure y syntactically matches the form of the elements of A (i.e., elements of A3,k). If it does, we then check that its k matches our k, and we use s to get decoded pairs (i\u2032, x\u2032) and (j\u2032\u2032, x\u2032\u2032) from the places in our parsing of y where we have formulas\u2014call them Fleft and Fright\u2014that we are hoping are the outputs of the r function. That is, if our input parses as (z1 \u2227 z2 \u2227 \u00b7 \u00b7 \u00b7 \u2227 zk \u2227 (Fleft)) \u2228 (z1 \u2227 z2 \u2227 \u00b7 \u00b7 \u00b7 \u2227 zk \u2227 (Fright)), then if s(Fleft) gives (Ni\u2032 , x\n\u2032) our decoded pair is (i\u2032, x\u2032), and Fright is handled analogously. We also check to make sure that x\u2032 = x\u2032\u2032, i = i\u2032, and j = j\u2032\u2032. If anything mentioned so far fails, then y 6\u2208 A. Otherwise, we check to make sure that rGalil-Cook(Ni, x \u2032) = Fleft and rGalil-Cook(Nj , x \u2032) = Fright, and reject if either equality fails to hold. (Those checks are not superfluous. s by definition has to correctly invert on strings that are the true outputs of rGalil-Cook, but we did not assume that s might not output sneaky garbage when given other input values, and since Fleft and Fright are coming from our arbitrary input y, they could be anything. However, the check we just made defangs the danger just mentioned.) If we have reached this point, we indeed have determined that y \u2208 A, and for each y \u2208 A we will successfully reach this point.\nA \u2286 SAT: For each x, either x \u2208 B or x 6\u2208 B. In the former case (x \u2208 B), rGalil-Cook(Ni, x) \u2208 SAT and so the left disjunct of (z1 \u2227 z2 \u2227 \u00b7 \u00b7 \u00b7 \u2227 zk \u2227 (rGalil-Cook(Ni, x)))\u2228 (z1 \u2227 z2 \u2227 \u00b7 \u00b7 \u00b7 \u2227 zk \u2227 (rGalil-Cook(Nj , x))) can be made true using that satisfying assignment and setting each z\u2113 to true. On the other hand, if x 6\u2208 B, then rGalil-Cook(Nj , x) \u2208 SAT and so the whole formula can be made true using that satisfying assignment and setting each z\u2113 to false.\nThere is a polynomial-time computable function f such that (\u2200F \u2208 A)[f(F ) outputs a nontrivial backbone of F ]: On input F \u2208 A, f will simply output {z1, z2, . . . , zk}, which is a nontrivial backbone of F . Why is it a nontrivial backbone? If the x embedded in F satisfies x \u2208 B, then not only does rGalil-Cook(Ni, x) \u2208 SAT hold, but also rGalil-Cook(Nj , x) 6\u2208 SAT must hold (since otherwise we would have x 6\u2208 B \u2227 x \u2208 B, an impossibility). So if the x embedded in F satisfies x \u2208 B, then there are satisfying assignments of (z1 \u2227 z2 \u2227 \u00b7 \u00b7 \u00b7 \u2227 zk \u2227 (rGalil-Cook(Ni, x))) \u2228 (z1 \u2227 z2 \u2227 \u00b7 \u00b7 \u00b7 \u2227 zk \u2227 (rGalil-Cook(Nj , x))), and every one of them has each z\u2113 set to true. Similarly, if the x embedded in F satisfies x 6\u2208 B, then our long formula has satisfying assignments, and every one of them has each z\u2113 set to false. Thus {z1, z2, . . . , zk} indeed is a size-k backbone.\nThere does not exist any polynomial-time computable function g such that g(F ) computes the value of backbone f(F ): Suppose by way of contradiction that such a polynomial-time computable function g does exist. Then we would have that B \u2208 P, by the following algorithm. Let f be the function constructed in the previous paragraph, i.e., the one that outputs {z1, z2, . . . , zk} when F \u2208 A. Given x, in polynomial time\u2014g and f are polynomial-time computable, and although r in general is not since its running time\u2019s polynomial degree varies with its first argument and so is not uniformly polynomial, r here is used only for the first-component values Ni and Nj and under that restriction it indeed is polynomial-time computable\u2014compute g(f((z1 \u2227 z2 \u2227 \u00b7 \u00b7 \u00b7 \u2227 zk \u2227 (rGalil-Cook(Ni, x))) \u2228 (z1 \u2227 z2 \u2227 \u00b7 \u00b7 \u00b7 \u2227 zk \u2227 (rGalil-Cook(Nj , x))))). This must either tell us that the z\u2113s are true in all satisfying assignments, which tells us that it is the left disjunct that is satisfiable and thus x \u2208 B, or it will tell us that the z\u2113s are false in all satisfying assignments, from which we similarly can correctly conclude that x 6\u2208 B. So B \u2208 P, yet we chose B so as to satisfy B \u2208 (NP \u2229 coNP)\u2212 P. Thus our assumption that such a g exists is contradicted.\nThat ends our proof of Theorem 3\u2014and so implicitly also of Theorem 2, since Theorem 2 follows immediately from Theorem 3.\nHaving seen the above proof, the reader will not need a detailed treatment of the proof of Theorem 4. Rather, we describe how to convert the above construction into one that proves Theorem 4. Recall that for the \u201ck\u201d case of Theorem 3 our set A was {(z1 \u2227 z2 \u2227 \u00b7 \u00b7 \u00b7 \u2227 zk \u2227 (rGalil-Cook(Ni, x))) \u2228 (z1 \u2227 z2 \u2227 \u00b7 \u00b7 \u00b7 \u2227 zk \u2227 (rGalil-Cook(Nj , x))) | x \u2208 \u03a3\u2217}.\nFor Theorem 4, let us use almost the same set. Except we will make two types of changes. First, in the above, replace the two occurrences of k each with the smallest positive integer m\u2032 satisfying m \u2032\nnumvars(rGalil-Cook(Ni,x))+numvars(rGalil-Cook(Nj ,x))+2m\u2032 \u2265 49100 , where\nnumvars counts the number of variables in a formula, e.g., numvars(x1\u2227x2\u2227x2) = 2, due to the variables x1 and x2. Let m henceforward denote that value, i.e., the smallest (positive\ninteger) m\u2032 that satisfies the above equation. Second, in the right disjunct, change each z\u2113 to z\u2032\u2113.\nNote that if x \u2208 B, then {z1, z2, \u00b7 \u00b7 \u00b7 , zm} is a backbone whose value is the assignment of true to each variable, and that contains at least 49% of the variables in the formula that x put into A. Similarly, if x 6\u2208 B, then {z\u20321, z \u2032 2, \u00b7 \u00b7 \u00b7 , z \u2032 m} is a backbone whose value is the assignment of false to each variable, and that contains at least 49% of the variables in the formula that x put into A. It also is straightforward to see that our thus-created set A belong to P and satisfies A \u2286 SAT.\nSo the only condition of Theorem 4 that we still need to show holds is the claim that, for the just-described A, there does not exist any polynomial-time computable function g such that, on each F \u2208 A, g(F ) outputs a backbone whose size is at least 2% of F \u2019s variables. Suppose by way of contradiction that such a function g does exist. We claim that would yield a polynomial-time algorithm for B, contradicting the assumption that B 6\u2208 P. Let us give such a polynomial-time algorithm. To test whether x \u2208 B, in polynomial time we create the formula in A that is put there by x, and we run our postulated polynomial-time g on that formula, and thus we get a backbone, call it S, that contains at least 2% of F \u2019s variables. Note that we ourselves do not get to choose which large backbone g outputs, so we must be careful as to what we assume about the output backbone. We in particular certainly cannot assume that g happens to always output either {z1, z2, \u00b7 \u00b7 \u00b7 , zm} or {z \u2032 1, z \u2032 2, \u00b7 \u00b7 \u00b7 , z \u2032 m}. But we don\u2019t need it to. Note that the two backbones just mentioned are variable-disjoint, and each contains 49% of F \u2019s variables.\nNow, there are two cases. One case is that S contains at least one variable of the form z\u2113 or z \u2032 \u2113. In that case we are done. If it contains at least one variable of the form z\u2113 then x \u2208 B. Why? If x \u2208 B, then the left-hand disjunct of the formula x puts into A is satisfiable and the right-hand disjunct is not. From the form of the formula, it is clear that each z\u2113 is always true in each satisfying assignment in this case, yet that for each z \u2032 \u2113 there are satisfying assignments where z\u2032\u2113 is true and there are satisfying assignments where z \u2032 \u2113 is false. So if x \u2208 B, no z\u2032\u2113 can belong to any backbone. By analogous reasoning, if S contains at least one variable of the form z\u2032\u2113 then x 6\u2208 B. (It follows from this and the above that S cannot possibly contain at least one variable that is a subscripted z and at least one variable that is a subscripted z\u2032, since then x would have to simultaneously belong and not belong to B.)\nThe final case to consider is the one in which S does not contain at least one variable of the form z\u2113 or z \u2032 \u2113. We argue that this case cannot happen. If this were to happen, then every variable of F other than the variables {z1, z2, \u00b7 \u00b7 \u00b7 , zm, z \u2032 1, z \u2032 2, \u00b7 \u00b7 \u00b7 , z \u2032 m} must be part of the backbone, since S must involve 2% of the variables and {z1, z2, \u00b7 \u00b7 \u00b7 , zm, z \u2032 1, z \u2032 2, \u00b7 \u00b7 \u00b7 , z \u2032 m} comprise 98% of the variables. But that is impossible. We know that the variables used in rGalil-Cook(Ni, x) and rGalil-Cook(Nj , x) are disjoint. So the variables in the one of those two that is not the one that is satisfiable can and do take on any value in some satisfying assignment, and so cannot be part of any backbone. (The only remaining worry is the case where one of rGalil-Cook(Ni, x) or rGalil-Cook(Nj , x) contains no variables. However, the empty formula is by convention considered illegal, in cases such as here where the formulas\nare not considered to be trapped into DNF or CNF. There is a special convention regarding empty DNF and CNF formulas, but that is not relevant here.)\nWe have thus concluded the proof of Theorem 4."}, {"heading": "3.2 Proof Sketches for Section 2.2", "text": "We will treat this section briefly and informally, as we will argue that its claims can be seen as following from the previous section\u2019s proofs.\nThe crucial thing to note is that the mapping from strings x (as to whether they belong to B) into the string that x puts into A is (a) polynomial-time computable (and so the one string that x puts into A is at most polynomially longer than x), and (b) one-to-one.\nSo, any collection ofm instances up to a given length n that fool a particular polynomialtime algorithm for B are associated with at least m distinct instances in A all of length at most nq (where the polynomial bound on the length of the formula that x puts into A is that it is of length at most nq3). So if one had an algorithm for the \u201cA\u201d set such that the algorithm had at most m\u2032 errors on the strings up to length nq, it would certainly imply an algorithm for B that up to length n1/q made at most m\u2032 errors. Namely, one\u2019s heuristic of that form for B would be to take x, map it to the string it put into A, and then run the heuristic for A on that string.\nThe above discussion establishes what the results in Section 2.2 are asserting."}, {"heading": "4 Related Work", "text": "Our results can be viewed as part of a line of work that is so underpopulated as to barely merit being called a line of work, at least regarding its connections to AI. The true inspiration for this work was a paper of Alan Demers and Allan Borodin [BD76] from the 1970s that never appeared in any form other than as a technical report. Though quite technical, that paper in effect showed sufficient conditions for creating simple sets of satisfiable formulas such that it was unclear why they were satisfiable.\nEven in the theoretical computer science world, where Borodin and Demers\u2019s work is set, the work has been very rarely used. In particular, it has been used to get characterizations regarding unambiguous computation [HH88], and Rothe and his collaborators have used it in various contexts to study the complexity of certificates [HRW97,Rot99], see also Fenner et al. [FFNR03] and Valiant [Val76].\nThere has been just one paper that previously has sought to bring the focus of this line to a topic of interest in AI. Although it appeared in a theoretical computer science venue, the work of Hemaspaandra, Hemaspaandra, and Menton [HHM13] shows that some problems\n3We have for simplicity in this brief analysis left out any lower-order terms and the leading-term constant, but that is legal except at n \u2208 {0, 1}\u2014since starting with n = 2 we can boost q if needed\u2014and no finite set of values, such as {0, 1} can cause problems to our theorem, as it is about the \u201cinfinitely-often\u201d and \u201calmost-everywhere\u201d cases. However, such boosting does potentially interfere with the inverse-of-k relation mentioned in Footnote 2, and so if we wanted to maintain that, we would in this argument instead use a lowest-degree-possible monotonic polynomial bounding the growth rate.\nfrom computational social choice theory, a subarea of multiagent systems, have the property that if P 6= NP\u2229 coNP then their search versions are not polynomial-time Turing reducible to their decision problems\u2014a rare behavior among the most familiar seemingly hard sets in computer science, since so-called self-reducibility [MP79] is known to preclude that possibility for most standard NP-complete problems. The key issue that 2013 paper left open is whether the type of techniques it used, descended from Borodin and Demers [BD76], might be relevant anywhere else in AI, or whether its results were a one-shot oddity. The present paper in effect is arguing that the former is the case. Backbones are a topic important in AI and relevant to SAT solvers, and this paper shows that the inspiration of the line of work initiated by Borodin and Demers [BD76] can be used to establish the opacity of backbones.\nIt is important to acknowledge that our proofs regarding Section 2.1 are drawing on elements of the insights of Borodin and Demers [BD76], although in ways unanticipated by that paper. And the addition of density transfer arguments to the world of BorodinDemers arguments is due to Hemaspaandra, Hemaspaandra, and Menton [HHM13], and we are benefiting from that argument."}, {"heading": "5 Conclusions", "text": "We argued, under assumptions widely believed to be true such as the hardness of integer factoring, that knowing a large backbone exists doesn\u2019t mean one can efficiently find a large backbone, and finding a nontrivial backbone doesn\u2019t mean one can efficiently find its value. Further, we showed that one can ensure that these effects are not very infrequent, but rather that they can be made to happen with \u201calmost\u201d the same density of occurrence as the error rates of the most densely hard sets in NP \u2229 coNP.\nMost of our results relied on the assumption that P 6= NP\u2229coNP, which as noted above is likely true, since if it is false then integer factoring is in P and the RSA encryption scheme falls. It would be interesting, however, to see whether one can get any (likely weaker) backbone-opacity results under the weaker assumption that P 6= NP. We in fact have done so, but we consider those results unsatisfying, and they in effect rely on a particular feature of the Williams, Gomes, and Selman [WGS03] definition of backbones, namely, that unsatisfiable formulas have no backbones. That feature has no effect on the results of this paper, since in all our theorems we produced sets A whose elements all are satisfiable formulas."}, {"heading": "Acknowledgments", "text": "We are deeply grateful to anonymous AAAI-17 reviewers for very helpful comments and suggestions."}, {"heading": "A Appendix: Construction of a Galil-Cook r Function with", "text": "the Properties Claimed in Section 2.1\nFor those who wish to be assured that a Galil-Cook \u201cr\u201d function can be implemented so as to have all the properties we have \u201cwithout loss of generality\u201d assumed in Section 2.1, we here provide such an implementation.\nLet N1, N2, . . . be as in Section 2.1. That is, it is a fixed, standard enumeration of clocked, polynomial-time Turing machines, such that each Ni runs within time n\ni + i on inputs of length n, and Ni and i are polynomially related in size and easily obtained from each other. Fix any function r that implements the Cook-Karp-Levin reduction. That is, r is such that\n1. for each Ni and x: x \u2208 L(Ni) if and only if r(Ni, x) \u2208 SAT .\n2. there is a polynomial p such that r(Ni, x) runs within time polynomial (in particular, with p being the polynomial) in |Ni| and |x| i + i.\nIt is very well known that such functions exist. Their existence\u2014the Cook-Karp-Levin reduction\u2014is proven in almost every textbook that covers NP-completeness (see, e.g., Hopcroft and Ullman [HU79]), and is the key moment that brings the theory of NPcompleteness to life, by transferring the domain from machines to a concrete problem that itself can be used to show that other concrete NP problems are themselves NP-complete.\nNote that the function r that we have thus fixed is not assumed to necessarily have an \u201cinversion\u201d function s, and is not assumed to necessarily avoid using literals involving the letter \u201cz\u201d, and is is not assumed to necessarily have the property that two applications of the r function are guaranteed to be variable-disjoint if they regard different machines (i.e., are not both about Ni for the same value i).\nWe now show how to use the above fixed function r as a building block to build our function rGalil-Cook, which will have all the properties just mentioned, yet will retain the time and reduction-to-SAT properties mentioned above regarding r. rGalil-Cook, when its first argument is Ni and its second argument is x, does the following. It simulates the run of r when its first argument is Ni and its second argument is x, and so computes the formula rGalil-Cook(Ni, x), which we will henceforth denote by F for conciseness of notation. It then counts the number of variables occurring in that formula F ; let us denote that number by p. (So for example if the formula F is z1\u2227z1\u2227w, then p = 2, as there are two variables, z1 and w.) Now, let F \u2032 denote F , except each variable a in F will be replaced in F \u2032 by the variable x\u3008Ni,q\u3009, where q is the location of a in lexicographic order within the variables of F . (\u3008\u00b7, \u00b7\u3009 is any standard, nice, easily computable, easily invertible pairing function.) If we view w as coming lexicographically before z1, then in our example, F\n\u2032 would be x\u3008Ni,2\u3009\u2227x\u3008Ni,2\u3009\u2227x\u3008Ni,1\u3009. Despite the pairings used, this increases the length of F by at most a multiplicative factor of the number of bits of Ni. (Since each of our uses of rGalil-Cook in Section 2.1 only used the function on some two hypothetical, fixed machines, the time and length-of-output effect of this variable-renaming is at most a multiplicative constant (that depends on the two machines), and so is negligible in standard complexity-analysis terms). But although using\nthe same trick to encode x into the output by pairing it too into the variable names would be valid, it would increase the formula size by a multiplicative factor of |x|, which is not negligible. So we take a different approach, which instead increases the formula size just by an additive factor of O(|x|). rGalil-Cook(Ni, x) will output (F\n\u2032) \u2227 (c0 \u2228 c1 \u2228 cb1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 cb|x|), where in the above bi denotes the value of the ith bit of x and each c0 above means to write x\u3008Ni,p+1\u3009 and each c1 above means to write x\u3008Ni,p+1\u3009.\nSo, in our running example, if the value of x was 101, rGalil-Cook(Ni, x) would be (x\u3008Ni,2\u3009\u2227 x\u3008Ni,2\u3009 \u2227 x\u3008Ni,1\u3009) \u2227 (x\u3008Ni,3\u3009 \u2228 x\u3008Ni,3\u3009 \u2228 x\u3008Ni,3\u3009 \u2228 x\u3008Ni,3\u3009 \u2228 x\u3008Ni,3\u3009).\nIt is not hard to see that the rGalil-Cook we have constructed has all the promised properties. It has the correct running time, it validly reduces from whether Ni accepts x to the issue of whether rGalil-Cook(Ni, x) is in SAT, it never outputs any literal involving the letter z, all its literals in fact are tagged by the Ni in use and so two applications created with regard to different machines (e.g., N4 and N7) are guaranteed to have variable-disjoint outputs, and it even is such that the desired s function exists. Our s function will take an input, parse it to get (A) \u2227 (B), will decode Ni from the variables names in A and will decode x from the fact that it is basically written out by the bits encoded by all but the first two disjuncts of B, and then will output the pair (Ni, x). If anything goes wrong in that process, as to unexpected syntax or so on, then what we were given is not an actual output of some run of rGalil-Cook on a legal input, and we can output any junk pair that we like, without violating our promise as to the behavior of s. (Some inputs that are not valid outputs of rGalil-Cook will not trigger the above \u201cif anything goes wrong,\u201d since we did not here take the (Ni, x) we are about to output and compute rGalil-Cook(Ni, x) to see whether the output of that matches our input. But we do not need to. The needed behavior here is that all valid inputs have the right output, and we have achieved that.)"}], "references": [{"title": "Some comments on functional self-reducibility and the NP hierarchy", "author": ["A. Borodin", "A. Demers"], "venue": "Technical Report TR 76-284,", "citeRegEx": "Borodin and Demers.,? \\Q1976\\E", "shortCiteRegEx": "Borodin and Demers.", "year": 1976}, {"title": "The complexity of theorem-proving procedures", "author": ["S. Cook"], "venue": "In Proceedings of the 3rd ACM Symposium on Theory of Computing,", "citeRegEx": "Cook.,? \\Q1971\\E", "shortCiteRegEx": "Cook.", "year": 1971}, {"title": "Inverting onto functions", "author": ["S. Fenner", "L. Fortnow", "A. Naik", "J. Rogers"], "venue": "Information and Computation,", "citeRegEx": "Fenner et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Fenner et al\\.", "year": 2003}, {"title": "On some direct encodings of nondeterministic Turing machines operating in polynomial time into P-complete problems", "author": ["Z. Galil"], "venue": "SIGACT News,", "citeRegEx": "Galil.,? \\Q1974\\E", "shortCiteRegEx": "Galil.", "year": 1974}, {"title": "Model counting", "author": ["C. Gomes", "A. Sabharwal", "B. Selman"], "venue": "Handbook of Satisfiability,", "citeRegEx": "Gomes et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Gomes et al\\.", "year": 2009}, {"title": "Complexity classes without machines: On complete languages for UP", "author": ["J. Hartmanis", "L. Hemachandra"], "venue": "Theoretical Computer Science,", "citeRegEx": "Hartmanis and Hemachandra.,? \\Q1988\\E", "shortCiteRegEx": "Hartmanis and Hemachandra.", "year": 1988}, {"title": "Search versus decision for election manipulation problems", "author": ["E. Hemaspaandra", "L. Hemaspaandra", "C. Menton"], "venue": "In Proceedings of the 30th Annual Symposium on Theoretical Aspects of Computer Science,", "citeRegEx": "Hemaspaandra et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Hemaspaandra et al\\.", "year": 2013}, {"title": "The opacity of backbones", "author": ["L. Hemaspaandra", "D. Narv\u00e1ez"], "venue": "In Proceedings of the 31st AAAI Conference on Artificial Intelligence", "citeRegEx": "Hemaspaandra and Narv\u00e1ez.,? \\Q2017\\E", "shortCiteRegEx": "Hemaspaandra and Narv\u00e1ez.", "year": 2017}, {"title": "Easy sets and hard certificate schemes", "author": ["L. Hemaspaandra", "J. Rothe", "G. Wechsung"], "venue": "Acta Informatica,", "citeRegEx": "Hemaspaandra et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hemaspaandra et al\\.", "year": 1997}, {"title": "Introduction to Automata Theory, Languages, and Computation", "author": ["J. Hopcroft", "J. Ullman"], "venue": null, "citeRegEx": "Hopcroft and Ullman.,? \\Q1979\\E", "shortCiteRegEx": "Hopcroft and Ullman.", "year": 1979}, {"title": "Reducibilities among combinatorial problems", "author": ["R. Karp"], "venue": "Complexity of Computer Computations,", "citeRegEx": "Karp.,? \\Q1972\\E", "shortCiteRegEx": "Karp.", "year": 1972}, {"title": "Universal sequential search problems", "author": ["L. Levin"], "venue": "Problems of Information Transmission,", "citeRegEx": "Levin.,? \\Q1975\\E", "shortCiteRegEx": "Levin.", "year": 1975}, {"title": "With what frequency are apparently intractable problems difficult", "author": ["A. Meyer", "M. Paterson"], "venue": "Technical Report MIT/LCS/TM-126,", "citeRegEx": "Meyer and Paterson.,? \\Q1979\\E", "shortCiteRegEx": "Meyer and Paterson.", "year": 1979}, {"title": "Determining computational complexity from characteristic \u2018phase transitions", "author": ["R. Monasson", "R. Zecchina", "S. Kirkpatrick", "B. Selman", "L. Troyansky"], "venue": "Nature, 400:133\u2013137,", "citeRegEx": "Monasson et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Monasson et al\\.", "year": 1999}, {"title": "Complexity of certificates, heuristics, and counting types, with applications to cryptography and circuit theory", "author": ["J. Rothe"], "venue": "Habilitation thesis,", "citeRegEx": "Rothe.,? \\Q1999\\E", "shortCiteRegEx": "Rothe.", "year": 1999}, {"title": "Complete sets and closeness to complexity classes", "author": ["U. Sch\u00f6ning"], "venue": "Mathematical Systems Theory,", "citeRegEx": "Sch\u00f6ning.,? \\Q1986\\E", "shortCiteRegEx": "Sch\u00f6ning.", "year": 1986}, {"title": "The relative complexity of checking and evaluating", "author": ["L. Valiant"], "venue": "Information Processing Letters,", "citeRegEx": "Valiant.,? \\Q1976\\E", "shortCiteRegEx": "Valiant.", "year": 1976}, {"title": "The complexity of computing the permanent", "author": ["L. Valiant"], "venue": "Theoretical Computer Science,", "citeRegEx": "Valiant.,? \\Q1979\\E", "shortCiteRegEx": "Valiant.", "year": 1979}, {"title": "Backdoors to typical case complexity", "author": ["R. Willams", "C. Gomes", "B. Selman"], "venue": "In Proceedings of the 18th International Joint Conference on Artificial Intelligence,", "citeRegEx": "Willams et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Willams et al\\.", "year": 2003}], "referenceMentions": [], "year": 2017, "abstractText": "A backbone of a boolean formula F is a collection S of its variables for which there is a unique partial assignment aS such that F [aS ] is satisfiable [MZK 99,WGS03]. This paper studies the nontransparency of backbones. We show that, under the widely believed assumption that integer factoring is hard, there exist sets of boolean formulas that have obvious, nontrivial backbones yet finding the values, aS , of those backbones is intractable. We also show that, under the same assumption, there exist sets of boolean formulas that obviously have large backbones yet producing such a backbone S is intractable. Further, we show that if integer factoring is not merely worst-case hard but is frequently hard, as is widely believed, then the frequency of hardness in our two results is not too much less than that frequency.", "creator": "LaTeX with hyperref package"}}}