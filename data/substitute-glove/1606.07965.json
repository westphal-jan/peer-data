{"id": "1606.07965", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Jun-2016", "title": "Summarizing Decisions in Spoken Meetings", "abstract": "This which instructions the example present 28-page decisions in spoken meetings: mind victory it over than given concise {\\ it decision impressionistic} for each meeting announcement. We aims part compare spacing - given each peaceful civil - increased extra photoengraving basic using over unsupervised which supervised learning frameworks. In later assisting rasterization setting, this make true clusterings of commission - common disparaging, see yet that blessing - normally summaries that typically discourse context whatever approach neither section bound special recommendation abstracts common turn when solution sexual. In the on-the-job time-wasting clear, everyone them any summary based the seclusion partitioning of determined - cited utterances perform correspondingly to we technology its seatbacks produced allowing supervised using (0. 22 ROUGE - F1 intended LDA - based endlessly styles vs. 0. 4 instead SVMs ).", "histories": [["v1", "Sat, 25 Jun 2016 20:45:14 GMT  (29kb)", "http://arxiv.org/abs/1606.07965v1", "ACL Workshop on Automatic Summarization for Different Genres, Media, and Languages, 2011"]], "COMMENTS": "ACL Workshop on Automatic Summarization for Different Genres, Media, and Languages, 2011", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["lu wang", "claire cardie"], "accepted": false, "id": "1606.07965"}, "pdf": {"name": "1606.07965.pdf", "metadata": {"source": "CRF", "title": "Summarizing Decisions in Spoken Meetings", "authors": ["Lu Wang"], "emails": ["luwang@cs.cornell.edu", "cardie@cs.cornell.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 6.\n07 96\n5v 1\n[ cs\n.C L\n] 2\n5 Ju\nn 20"}, {"heading": "1 Introduction", "text": "Meetings are a common way for people to share information and discuss problems. And an effective meeting always leads to concrete decisions. As a result, it would be useful to develop automatic methods that summarize not the entire meeting dialogue, but just the important decisions made. In particular, decision summaries would allow participants to review decisions from previous meetings as they prepare for an upcoming meeting. For those who did not participate in the earlier meetings, decision summaries might provide one type of efficient overview of the meeting contents. For managers, decision summaries could act as a concise record of the idea generation process.\nWhile there has been some previous work in summarizing meetings and conversations, very lit-\ntle work has focused on decision summarization: Ferna\u0301ndez et al. (2008a) and Bui et al. (2009) investigate the use of a semantic parser and machine learning methods for phrase- and token-level decision summarization. We believe our work is the first to explore and compare token-level and dialogue act-level approaches \u2014 using both unsupervised and supervised learning methods \u2014 for summarizing decisions in meetings.\nConsider the sample dialogue snippet in Table 1, which is part of the AMI meeting corpus (Carletta et al., 2005). The Table lists only decision-related dialogue acts (DRDAs) \u2014 utterances associated with at least one decision made in the meeting.1 The DRDAs are ordered by time; intervening utterances are not shown. DRDAs are important because they contain critical information for decision summary construction.\nTable 1 clearly shows some challenges for decision summarization for spoken meetings beyond the disfluencies, high word error rates, absence of punctuation, interruptions and hesitations due to speech. First, different decisions can be discussed more or less concurrently; as a result, the utterances associated with a single decision are not contiguous in the dialogue. In Table 1, the dialogue acts (henceforth, DAs) concerning DECISION 1, for example, are interleaved with DAs for other decisions. Second, some decision-related DAs contribute more than others to the associated decision. In composing the summary for DECISION 1, for example, we might safely ignore the first DA for DECISION 1. Finally, more so than for standard text summarization, purely extract-based summaries are not likely to be easily interpretable: DRDAs often contain text that is irrelevant to the decision and many will only be understandable if analyzed in the context of the surrounding utterances.\nIn this paper, we study methods for decision summarization for spoken meetings. We assume that all decision-related DAs have been identified and aim to produce a summary for the meeting in the form of concise decision abstracts (see Table 1), one for each decision made. In response to the challenges described above, we propose a summarization framework that includes:\nClustering of decision-related DAs. Here we aim to partition the decision-related utterances (DRDAs) according to the decisions each supports. This step is similar in spirit to many standard text summarization techniques (Salton et al., 1997) that begin by grouping sentences according to semantic similarity.\nSummarization at the DA-level. We select just the important DRDAs in each cluster. Our goal is to eliminate redundant and less informative utterances. The\n1These are similar, but not completely equivalent, to the decision dialogue acts (DDAs) of Bui et al. (2009), Ferna\u0301ndez et al. (2008a), Frampton et al. (2009). The latter refer to all DAs that appear in a decision discussion even if they do NOT support any particular decision.\nselected DRDAs are then concatenated to form the decision summary.\nOptional token-level summarization of the selected DRDAs. Methods are employed to capture concisely the gist of each decision, discarding any distracting text.\nIncorporation of the discourse context as needed. We hypothesize that this will produce more interpretable summaries.\nMore specifically, we compare both unsupervised (TFIDF (Salton et al., 1997) and LDA topic modeling (Blei et al., 2003)) and (pairwise) supervised clustering procedures (using SVMs and MaxEnt) for partitioning DRDAs according to the decision each supports. We also investigate unsupervised methods and supervised learning for decision summarization at both the DA and token level, with and without the incorporation of discourse context. During training, the supervised decision summarizers are told which DRDAs for each decision are the most informative for constructing the decision abstract.\nOur experiments employ the aforementioned AMI meeting corpus: we compare our decision summaries to the manually generated decision abstracts for each meeting and evaluate performance using the ROUGE-1 (Lin and Hovy, 2003) text summarization evaluation metric.\nIn the supervised summarization setting, our experiments demonstrate that with true clusterings of decision-related DAs, token-level summaries that employ limited discourse context can approach an upper bound for summaries extracted directly from DRDAs2 \u2014 0.4387 ROUGE-F1 vs. 0.5333. When using system-generated DRDA clusterings, the DAlevel summaries always dominate token-level methods in terms of performance.\nFor the unsupervised summarization setting, we investigate the use of both unsupervised and supervised methods for the initial DRDA clustering step. We find that summaries based on unsupervised clusterings perform comparably to those generated using supervised techniques (0.2214 ROUGE-F1 using LDA-based topic models vs. 0.2349 using SVMs). As in the supervised summarization setting, we observe that including additional discourse context boosts performance only for token-level summaries.\n2The upper bound measures the vocabulary overlap of each gold-standard decision summary with the complete text of all of its associated DRDAs."}, {"heading": "2 Related Work", "text": "There exists much previous research on automatic text summarization using corpus-based, knowledgebased or statistical methods (Mani, 1999; Marcu, 2000). Dialogue summarization methods, however, generally try to account for the special characteristics of speech. Among early work in this subarea, Zechner (2002) investigates speech summarization based on maximal marginal relevance (MMR) and cross-speaker linking of information. Popular supervised methods for summarizing speech \u2014 including maximum entropy, conditional random fields (CRFs), and support vector machines (SVMs) \u2014 are investigated in Buist et al. (2004), Xie et al. (2008) and Galley (2006). Techniques for determining semantic similarity are used for selecting relevant utterances in Gurevych and Strube (2004).\nStudies in Banerjee et al. (2005) show that decisions are considered to be one of the most important outputs of meetings. And in recent years, there has been much research on detecting decisionrelated DAs. Hsueh and Moore (2008), for example, propose maximum entropy classification techniques to identify DRDAs in meetings; Ferna\u0301ndez et al. (2008b) develop a model of decision-making dialogue structure and detect decision DAs based on it; and Frampton et al. (2009) implement a real-time decision detection system.\nFerna\u0301ndez et al. (2008a) and Bui et al. (2009), however, might be the most relevant previous work to ours. The systems in both papers run an opendomain semantic parser on meeting transcriptions to produce multiple short fragments, and then employ machine learning methods to select the phrases or words that comprise the decision summary. Although their task is also decision summarization, their gold-standard summaries consist of manually annotated words from the meeting while we judge performance using manually constructed decision abstracts as the gold standard. The latter are more readable, but often use a vocabulary different from that of the associated decision-related utterances in the meeting.\nOur work differs from all of the above in that we (1) incorporate a clustering step to partition DRDAs according to the decision each supports; (2) generate decision summaries at both the DA- and token-level; and (3) investigate the role of discourse context for\ndecision summarization. In the following sections, we investigate methods for clustering DRDAs (Section 3) and generating DA-level and token-level decision summaries (Section 4). In each case, we evaluate the methods using the AMI meeting corpus."}, {"heading": "3 Clustering Decision-Related Dialogue Acts", "text": "We design a preprocessing step that facilitates decision summarization by clustering all of the decisionrelated dialogue acts according to the decision(s) it supports. Because it is not clear how many decisions are made in a meeting, we use a hierarchical agglomerative clustering algorithm (rather than techniques that require a priori knowledge of the number of clusters) and choose the proper stopping conditions. In particular, we employ average-link methods: at each iteration, we merge the two clusters with the maximum average pairwise similarity among their DRDAs. In the following subsections, we introduce unsupervised and supervised methods for measuring the pairwise DRDA similarity."}, {"heading": "3.1 DRDA Similarity: Unsupervised Methods", "text": "We consider two unsupervised similarity measures \u2014 one based on the TF-IDF score from the Information Retrieval research community, and a second based on Latent Dirichlet Allocation topic models.\nTF-IDF similarity. TF-IDF similarity metrics have worked well as a measure of document similarity. As a result, we employ it as one metric for measuring the similarity of two DRDAs. Suppose there are L distinct word types in the corpus. We treat each decision-related dialgue act DAi as a document, and represent it as an L-dimensional feature vector \u2212\u2212\u2192 FVi = (xi1, xi2, ..., xiL), where xik is word wk\u2019s tf \u00b7 idf score for DAi. Then the (average-link) similarity of cluster Cm and cluster Cn, Sim TFIDF (Cm, Cn), is defined as :\n1\n| Cm | \u00b7 | Cn |\n\u2211\nDAi\u2208Cm DAj\u2208Cn\n\u2212\u2212\u2192 FVi \u00b7 \u2212\u2212\u2192 FVj\n\u2016 \u2212\u2212\u2192 FVi \u2016\u2016 \u2212\u2212\u2192 FVj \u2016\nLDA topic models. In recent years, topic models have become a popular technique for discovering the latent structure of \u201ctopics\u201d or \u201cconcepts\u201d in a corpus. Here we use the Latent Dirichlet Allocation (LDA) topic models of Blei et al. (2003) \u2014 unsuper-\nvised probabilistic generative models that estimate the properties of multinomial observations. In our setting, LDA-based topic models provide a soft clustering of the DRDAs according to the topics they discuss.3 To determine the similarity of two DRDAs, we effectively measure the similarity of their term-based topic distributions.\nTo train an LDA-based topic model for our task4, we treat each DRDA as an individual document. After training, each DRDA, DAi, is assigned a topic distribution \u2212\u2192 \u03b8i according to the learned model. Thus, we can define the similarity of cluster Cm and cluster Cn, Sim LDA(Cm, Cn), as :\n1\n| Cm | \u00b7 | Cn |\n\u2211\nDAi\u2208Cm DAj\u2208Cn\n\u2212\u2192 \u03b8i \u00b7 \u2212\u2192 \u03b8j"}, {"heading": "3.2 DRDA Similarity: Supervised Techniques", "text": "In addition to unsupervised methods for clustering DRDAs, we also explore an approach based on Pairwise Supervised Learning: we develop a classifier that determines whether or not a pair of DRDAs supports the same decision. So each training and test example is a feature vector that is a function of two DRDAs: for DAi and DAj , the feature vector is \u2212\u2212\u2192 FVij = f(DAi,DAj) = {fv 1 ij, fv 2 ij , ..., fv k ij}. Table 2 gives a full list of features that are used. Because the annotations for the time information and dialogue type of DAs are available from the corpus, we employ features including time difference of pairwise DAs, relative position5 and whether they\n3We cannot easily associate each topic with a decision because the number of decisions is not known a priori.\n4Parameter estimation and inference done by GibbsLDA++. 5Here is the definition for the relative position of pairwise DAs. Suppose there are N DAs in one meeting ordered by time,\nhave the same DA type. We employ Support Vector Machines (SVMs) and Maximum Entropy (MaxEnt) as our learning methods, because SVMs are shown to be effective in text categorization (Joachims, 1998) and MaxEnt has been applied in many natural language processing tasks (Berger et al., 1996). Given an \u2212\u2212\u2192 FVij , for SVMs, we utilize the decision value of w T \u00b7 \u2212\u2212\u2192 FVij + b as the similarity, where w is the weight vector and b is the bias. For MaxEnt, we make use of the probability of P (SameDecision | \u2212\u2212\u2192 FVij) as the similarity value."}, {"heading": "3.3 Experiments", "text": "Corpus. We use the AMI meeting Corpus (Carletta et al., 2005), a freely available corpus of multiparty meetings that contains a wide range of annotations. The 129 scenario-driven meetings involve four participants playing different roles on a design team. A short (usually one-sentence) abstract is included that describes each decision, action, or problem discussed in the meeting; and each DA is linked to the abstracts it supports. We use the manually constructed decision abstracts as gold-standard summaries and assume that all decision-related DAs have been identified (but not linked to the decision(s) it supports).\nBaselines. Two clustering baselines are utilized for comparison. One baseline places all decisionrelated DAs for the meeting into a single partition (ALLINONEGROUP). The second uses the text segmentation software of Choi (2000) to partition the decision-related DAs (ordered according to time) into several topic-based groups (CHOISEGMENT).\nExperimental Setup and Evaluation. Results for pairwise supervised clustering were obtained using 3-fold cross-validation. In the current work, stopping conditions for hierarchical agglomerative clustering are selected manually: For the TF-IDF and topic model approaches, we stop when the similarity measure reaches 0.035 and 0.015, respectively; For the SVM and MaxEnt versions, we use 0 and 0.45, respectively. We use the Mallet implementation for MaxEnt and the SVMlight implementation of SVMs.\nOur evaluation metrics include b3 (also called Bcubed) (Bagga and Baldwin, 1998), which is a com-\nDAi is the ith DA and DAj is positioned at j. So the relative position of DAi and DAj is |i\u2212j| N .\nmon measure employed in noun phrase coreference resolution research; a pairwise scorer that measures correctness for every pair of DRDAs; and a variation of information (VOI) scorer (Meila\u0306, 2007), which measures the difference between the distributions of the true clustering and system generated clustering. As space is limited, we refer the readers to the original papers for more details. For b3 scorer and pairwise scorer, higher results represent better performance; for VOI, lower is better.6\nResults. The results in Table 3 show first that all of the proposed clustering methods outperform the baselines. Among the unsupervised methods, the LDA topic modeling is preferred to TFIDF. For the supervised methods, SVMs and MaxEnt produce comparable results."}, {"heading": "4 Decision Summarization", "text": "In this section, we turn to decision summarization \u2014 extracting a short description of each decision based on the decision-related DAs in each cluster. We investigate options for constructing an extract-based summary that consists of a single DRDA and an abstract-based summary comprised of keywords that describe the decision. For both types of summary, we employ standard techniques from text summarization, but also explore the use of dialogue-specific features and the use of discourse context."}, {"heading": "4.1 DA-Level Summarization Based on Unsupervised Methods", "text": "We make use of two unsupervised methods to summarize the DRDAs in each \u201cdecision cluster\u201d. The first method simply returns the longest DRDA in the\n6The MUC scorer is popular in coreference evaluation, but it is flawed in measuring the singleton clusters which is prevalent in the AMI corpus. So we do not use it in this work.\ncluster as the summary (LONGEST DA). The second approach returns the decision cluster prototype, i.e., the DRDA with the largest TF-IDF similarity with the cluster centroid (PROTOTYPE DA). Although important decision-related information may be spread over multiple DRDAs, both unsupervised methods allow us to determine summary quality when summaries are restricted to a single utterance."}, {"heading": "4.2 DA-Level and Token-Level Summarization Using Supervised Learning", "text": "Because the AMI corpus contains a decision abstract for each decision made in the meeting, we can use this supervisory information to train classifiers that can identify informative DRDAs (for DA-level summaries) or informative tokens (for token-level summaries).\nDialogue Act-based Summarization. Previous research (e.g., Murray et al. (2005), Galley (2006), Gurevych and Strube (2004)) has shown that DRDA-level extractive summarization can be effective when viewed as a binary classification task. To implement this approach, we assume that the DRDA to be extracted for the summary is the one with the largest vocabulary overlap with the cluster\u2019s gold-standard decision abstract. This DA-level summarization method has an advantage that the summary maintains good readability without a natural language generation component. Token-based Summarization. As shown in Table 1, some decision-related DAs contain many useless words when compared with the gold-standard abstracts. As a result, we propose a method for tokenlevel decision summarization that focuses on iden-\ntifying critical keywords from the cluster\u2019s DRDAs. We follow the method of Ferna\u0301ndez et al. (2008a), but use a larger set of features and different learning methods. Adding Discourse Context. For each of the supervised DA- and token-based summarization methods, we also investigate the role of the discourse context. Specifically, we augment the DRDA clusterings with additional (not decision-related) DAs from the meeting dialogue: for each decision partition, we include the DA with the highest TF-IDF similarity with the centroid of the partition. We will investigate the possible effects of this additional context on summary quality.\nIn the next subsection, we describe the features used for supervised learning of DA- and token-based decision summaries."}, {"heading": "4.3 Dialogue Cues for Decision Summarization", "text": "Different from text, dialogues have some notable features that we expect to be useful for finding informative, decision-related utterances. This section describes some of the dialogue-based features employed in our classifiers. The full lists of features are shown in Table 4 and Table 5. Structural Information: Adjacency Pairs. An Adjacency Pair (AP) is an important conversational analysis concept; APs are considered the fundamental unit of conversational organization (Schegloff and Sacks, 1973). In the AMI corpus, an AP pair consists of a source utterance and a target utterance, produced by different speakers. The source precedes the target but they are not necessarily adjacent. We include features to indicate whether or not two DAs are APs indicating QUESTION+ANSWER or POSITIVE FEEDBACK. For these features, we use the gold-standard AP annotations. We also include one feature that checks membership in a small set of words to decide whether a DA contains positive feedback (e.g., \u201cyeah\u201d, \u201cyes\u201d).\nDiscourse Information: Review and Closing Indicator. Another pragmatic cue for dialogue discussion is terms like \u201cwrap up\u201d or \u201crecap\u201d, indicating that speakers will review the key meeting content. We include the distance between these indicators and DAs as a feature.\nGrammatical Information: Dependency Relation Between Words. For token-level summarization, we make use of the grammatical relationships in the DAs. As in Bui et al. (2009) and Ferna\u0301ndez\net al. (2008a), we design features that encode (a) basic predicate-argument structures involving major phrase types (S, VP, NP, and PP) and (b) additional typed dependencies from Marneffe et al. (2006). We use the Stanford Parser."}, {"heading": "5 Experiments", "text": "Experiments based on supervised learning are performed using 3-fold cross-validation. We train two different types of classifiers for identifying informative DAs or tokens: Conditional Random Fields (CRFs) (via Mallet) and Support Vector Machines (SVMs) (via SVMlight).\nWe remove function words from DAs before using them as the input of our systems. The AMI decision abstracts are the gold-standard summaries. We use the ROUGE (Lin and Hovy, 2003) evaluation measure. ROUGE is a recall-based method that can identify systems producing succinct and descriptive summaries.7\nResults and Analysis. Results for the unsupervised and supervised summarization methods are shown in Tables 6 and 7, respectively. In the tables, TRUE CLUSTERINGS means that we apply our methods on the gold-standard DRDA clusterings. SYSTEM CLUSTERINGS use clusterings obtained from the methods introduced in Section 4; we show re-\n7We use the stemming option of the ROUGE software at http://berouge.com/.\nsults only using the best unsupervised (USING LDA) and supervised (USING SVMS) DRDA clustering techniques.\nBoth Table 6 and 7 show that some attempt to cluster DRDAs improves the summarization results vs. NO CLUSTERING. In Table 6, there is no significant difference between the results obtained from the LONGEST DA and PROTOTYPE DA for any experiment setting. This is because the longest DA is often selected as the prototype. An UPPER BOUND result is listed for comparison: for each decision cluster, this system selects all words from the DRDAs that are part of the decision abstract (discarding duplicates).\nTable 7 presents the results for supervised summarization. Rows starting with DA or TOKEN indicate results at the DA- or token-level. The +CONTEXT rows show results when discourse context is included.8 We see that: (1) SVMs have a superior or comparable summarization performance vs. CRFs on every task. (2) Token-level summaries perform better than DA-level summaries only using TRUE CLUSTERINGS and the SVM-based summarizer. (3) Discourse context generally improves token-level summaries but not DA-level summaries.9 (4) DRDA\n8In our experiments, we choose the top 20 relevant DAs as context.\n9We do not extract words from the discourse context and experiments where we tried this were unsuccessful.\nclusterings produced by (unsupervised) LDA lead to summaries that are quite comparable in quality to those generated from DRDA clusterings produced by SVMs (supervised). From Table 6, we see that F1 is 0.2214 when choosing longest DAs from LDAgenerated clusterings, which is comparable with the F1s of 0.1935 and 0.2349, attained when employing CRF and SVMs on the same clusterings.\nThe results in Table 7 are achieved by comparing abstracts having function words with systemgenerated summaries without function words. To reduce the vocabulary difference as much as possible, we also ran experiments that remove function words from the gold-standard abstracts, but no significant difference is observed.10\nFinally, we considered comparing our systems to the earlier similar work of (Ferna\u0301ndez et al., 2008a) and (Bui et al., 2009), but found that it would be quite difficult because they employ a different notion from DRDAs which is Decision Dialogue Acts(DDAs). In addition, they manually annotate words from their DDAs as the gold-standard summary, guaranteeing that their decision summaries employ the same vocabulary as the DDAs. We instead use the actual decision abstracts from the AMI corpus."}, {"heading": "5.1 Sample Decision Summaries", "text": "Here we show sample summaries produced using our methods (Table 8). We pick one of the clusterings generated by LDA consisting of four DAs which support two decisions and take SVMs as the supervised summarization method. We remove function words and special markers like \u201c[disfmarker]\u201d from the DAs.\nThe outputs indicate that either the longest DA or prototype DA contains part of the decisions in this \u201cmixed\u201d cluster. Adding discourse context refines the summaries at both the DA- and token-levels."}, {"heading": "6 Conclusion", "text": "In this work, we explore methods for producing decision summaries from spoken meetings at both the DA-level and the token-level. We show that clus-\n10Given abstracts without function words, and using the clusterings generated by LDA and employ CRF on DA- and tokenlevel summarization, we get F1s of 0.1954 and 0.1329, which is marginally better than the corresponding 0.1935 and 0.1307 in Table 7. Similarly, if SVMs are employed in the same cases, we get F1s of 0.2367 and 0.1861 instead of 0.2349 and 0.1843. All of the other results obtain negligible minor increases in F1.\ntering DRDAs before identifying informative content to extract can improve summarization quality. We also find that unsupervised clustering of DRDAs (using LDA-based topic models) can produce summaries of comparable quality to those generated from supervised DRDA clustering. Token-level summarization methods can be boosted by adding discourse context and outperform DA-level summarization when true DRDA clusterings are available; otherwise, DA-level summarization methods offer better performance.\nAcknowledgments. This work was supported in part by National Science Foundation Grants IIS-0535099 and IIS-0968450, and by a gift from Google."}], "references": [{"title": "Algorithms for scoring coreference chains", "author": ["Amit Bagga", "Breck Baldwin."], "venue": "In The First International Conference on Language Resources and Evaluation Workshop on Linguistics Coreference, pages 563\u2013566.", "citeRegEx": "Bagga and Baldwin.,? 1998", "shortCiteRegEx": "Bagga and Baldwin.", "year": 1998}, {"title": "The necessity of a meet", "author": ["Satanjeev Banerjee", "Carolyn Penstein Ros\u00e9", "Alexander I. Rudnicky"], "venue": null, "citeRegEx": "Banerjee et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Banerjee et al\\.", "year": 2005}, {"title": "A maximum entropy approach to natural language processing", "author": ["Adam L. Berger", "Vincent J. Della Pietra", "Stephen A. Della Pietra."], "venue": "Comput. Linguist., 22:39\u201371, March.", "citeRegEx": "Berger et al\\.,? 1996", "shortCiteRegEx": "Berger et al\\.", "year": 1996}, {"title": "Latent dirichlet allocation", "author": ["David M. Blei", "Andrew Y. Ng", "Michael I. Jordan."], "venue": "J. Mach. Learn. Res., 3:993\u20131022, March.", "citeRegEx": "Blei et al\\.,? 2003", "shortCiteRegEx": "Blei et al\\.", "year": 2003}, {"title": "Extracting decisions from multi-party dialogue using directed graphical models and semantic similarity", "author": ["Trung H. Bui", "Matthew Frampton", "John Dowding", "Stanley Peters."], "venue": "Proceedings of the SIGDIAL 2009 Conference, pages 235\u2013243.", "citeRegEx": "Bui et al\\.,? 2009", "shortCiteRegEx": "Bui et al\\.", "year": 2009}, {"title": "Automatic summarization of meeting data: A feasibility study", "author": ["Anne Hendrik Buist", "Wessel Kraaij", "Stephan Raaijmakers."], "venue": "in Proc. Meeting of Computational Linguistics in the Netherlands (CLIN.", "citeRegEx": "Buist et al\\.,? 2004", "shortCiteRegEx": "Buist et al\\.", "year": 2004}, {"title": "Advances in domain independent linear text segmentation", "author": ["Freddy Y.Y. Choi."], "venue": "Proceedings of the 1st North American chapter of the Association for Computational Linguistics conference, pages 26\u201333.", "citeRegEx": "Choi.,? 2000", "shortCiteRegEx": "Choi.", "year": 2000}, {"title": "Identifying relevant phrases to summarize decisions in spoken meetings", "author": ["Raquel Fern\u00e1ndez", "Matthew Frampton", "John Dowding", "Anish Adukuzhiyil", "Patrick Ehlen", "Stanley Peters."], "venue": "INTERSPEECH-2008, pages 78\u201381.", "citeRegEx": "Fern\u00e1ndez et al\\.,? 2008a", "shortCiteRegEx": "Fern\u00e1ndez et al\\.", "year": 2008}, {"title": "Modelling and detecting decisions in multi-party dialogue", "author": ["Raquel Fern\u00e1ndez", "Matthew Frampton", "Patrick Ehlen", "Matthew Purver", "Stanley Peters."], "venue": "Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 156\u2013163.", "citeRegEx": "Fern\u00e1ndez et al\\.,? 2008b", "shortCiteRegEx": "Fern\u00e1ndez et al\\.", "year": 2008}, {"title": "Real-time decision detection in multi-party dialogue", "author": ["Matthew Frampton", "Jia Huang", "Trung Huu Bui", "Stanley Peters."], "venue": "Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 3 - Volume 3, pages 1133\u20131141.", "citeRegEx": "Frampton et al\\.,? 2009", "shortCiteRegEx": "Frampton et al\\.", "year": 2009}, {"title": "A skip-chain conditional random field for ranking meeting utterances by importance", "author": ["Michel Galley."], "venue": "Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 364\u2013 372.", "citeRegEx": "Galley.,? 2006", "shortCiteRegEx": "Galley.", "year": 2006}, {"title": "Semantic similarity applied to spoken dialogue summarization", "author": ["Iryna Gurevych", "Michael Strube."], "venue": "Proceedings of the 20th international conference on Computational Linguistics.", "citeRegEx": "Gurevych and Strube.,? 2004", "shortCiteRegEx": "Gurevych and Strube.", "year": 2004}, {"title": "Text categorization with Sup", "author": ["Thorsten Joachims"], "venue": null, "citeRegEx": "Joachims.,? \\Q1998\\E", "shortCiteRegEx": "Joachims.", "year": 1998}, {"title": "Advances in Automatic Text Sum", "author": ["Inderjeet Mani"], "venue": null, "citeRegEx": "Mani.,? \\Q1999\\E", "shortCiteRegEx": "Mani.", "year": 1999}, {"title": "The Theory and Practice", "author": ["Daniel Marcu"], "venue": null, "citeRegEx": "Marcu.,? \\Q2000\\E", "shortCiteRegEx": "Marcu.", "year": 2000}, {"title": "Opening up clos", "author": ["E.A. Schegloff", "H. Sacks"], "venue": null, "citeRegEx": "Schegloff and Sacks.,? \\Q1973\\E", "shortCiteRegEx": "Schegloff and Sacks.", "year": 1973}, {"title": "Automatic summarization", "author": ["Klaus Zechner"], "venue": null, "citeRegEx": "Zechner.,? \\Q2002\\E", "shortCiteRegEx": "Zechner.", "year": 2002}], "referenceMentions": [{"referenceID": 6, "context": "While there has been some previous work in summarizing meetings and conversations, very little work has focused on decision summarization: Fern\u00e1ndez et al. (2008a) and Bui et al.", "startOffset": 139, "endOffset": 164}, {"referenceID": 4, "context": "(2008a) and Bui et al. (2009) investigate the use of a semantic parser and machine learning methods for phrase- and token-level decision summarization.", "startOffset": 12, "endOffset": 30}, {"referenceID": 4, "context": "These are similar, but not completely equivalent, to the decision dialogue acts (DDAs) of Bui et al. (2009), Fern\u00e1ndez et al.", "startOffset": 90, "endOffset": 108}, {"referenceID": 4, "context": "These are similar, but not completely equivalent, to the decision dialogue acts (DDAs) of Bui et al. (2009), Fern\u00e1ndez et al. (2008a), Frampton et al.", "startOffset": 90, "endOffset": 134}, {"referenceID": 4, "context": "These are similar, but not completely equivalent, to the decision dialogue acts (DDAs) of Bui et al. (2009), Fern\u00e1ndez et al. (2008a), Frampton et al. (2009). The latter refer to all DAs", "startOffset": 90, "endOffset": 158}, {"referenceID": 3, "context": ", 1997) and LDA topic modeling (Blei et al., 2003)) and (pairwise) supervised clustering procedures (using SVMs and MaxEnt) for partitioning DRDAs according to the decision each supports.", "startOffset": 31, "endOffset": 50}, {"referenceID": 13, "context": "There exists much previous research on automatic text summarization using corpus-based, knowledgebased or statistical methods (Mani, 1999; Marcu, 2000).", "startOffset": 126, "endOffset": 151}, {"referenceID": 14, "context": "There exists much previous research on automatic text summarization using corpus-based, knowledgebased or statistical methods (Mani, 1999; Marcu, 2000).", "startOffset": 126, "endOffset": 151}, {"referenceID": 10, "context": "There exists much previous research on automatic text summarization using corpus-based, knowledgebased or statistical methods (Mani, 1999; Marcu, 2000). Dialogue summarization methods, however, generally try to account for the special characteristics of speech. Among early work in this subarea, Zechner (2002) investigates speech summarization based on maximal marginal relevance (MMR) and cross-speaker linking of information.", "startOffset": 127, "endOffset": 311}, {"referenceID": 5, "context": "Popular supervised methods for summarizing speech \u2014 including maximum entropy, conditional random fields (CRFs), and support vector machines (SVMs) \u2014 are investigated in Buist et al. (2004), Xie et al.", "startOffset": 170, "endOffset": 190}, {"referenceID": 5, "context": "Popular supervised methods for summarizing speech \u2014 including maximum entropy, conditional random fields (CRFs), and support vector machines (SVMs) \u2014 are investigated in Buist et al. (2004), Xie et al. (2008) and Galley (2006).", "startOffset": 170, "endOffset": 209}, {"referenceID": 5, "context": "Popular supervised methods for summarizing speech \u2014 including maximum entropy, conditional random fields (CRFs), and support vector machines (SVMs) \u2014 are investigated in Buist et al. (2004), Xie et al. (2008) and Galley (2006). Techniques for determining semantic similarity are used for selecting relevant utterances in Gurevych and Strube (2004).", "startOffset": 170, "endOffset": 227}, {"referenceID": 5, "context": "Popular supervised methods for summarizing speech \u2014 including maximum entropy, conditional random fields (CRFs), and support vector machines (SVMs) \u2014 are investigated in Buist et al. (2004), Xie et al. (2008) and Galley (2006). Techniques for determining semantic similarity are used for selecting relevant utterances in Gurevych and Strube (2004).", "startOffset": 170, "endOffset": 348}, {"referenceID": 1, "context": "Studies in Banerjee et al. (2005) show that decisions are considered to be one of the most important outputs of meetings.", "startOffset": 11, "endOffset": 34}, {"referenceID": 1, "context": "Studies in Banerjee et al. (2005) show that decisions are considered to be one of the most important outputs of meetings. And in recent years, there has been much research on detecting decisionrelated DAs. Hsueh and Moore (2008), for example, propose maximum entropy classification techniques to identify DRDAs in meetings; Fern\u00e1ndez et al.", "startOffset": 11, "endOffset": 229}, {"referenceID": 1, "context": "Studies in Banerjee et al. (2005) show that decisions are considered to be one of the most important outputs of meetings. And in recent years, there has been much research on detecting decisionrelated DAs. Hsueh and Moore (2008), for example, propose maximum entropy classification techniques to identify DRDAs in meetings; Fern\u00e1ndez et al. (2008b) develop a model of decision-making dialogue structure and detect decision DAs based on it; and Frampton et al.", "startOffset": 11, "endOffset": 349}, {"referenceID": 1, "context": "Studies in Banerjee et al. (2005) show that decisions are considered to be one of the most important outputs of meetings. And in recent years, there has been much research on detecting decisionrelated DAs. Hsueh and Moore (2008), for example, propose maximum entropy classification techniques to identify DRDAs in meetings; Fern\u00e1ndez et al. (2008b) develop a model of decision-making dialogue structure and detect decision DAs based on it; and Frampton et al. (2009) implement a real-time decision detection system.", "startOffset": 11, "endOffset": 467}, {"referenceID": 4, "context": "(2008a) and Bui et al. (2009), however, might be the most relevant previous work to ours.", "startOffset": 12, "endOffset": 30}, {"referenceID": 3, "context": "Here we use the Latent Dirichlet Allocation (LDA) topic models of Blei et al. (2003) \u2014 unsuper-", "startOffset": 66, "endOffset": 85}, {"referenceID": 12, "context": "We employ Support Vector Machines (SVMs) and Maximum Entropy (MaxEnt) as our learning methods, because SVMs are shown to be effective in text categorization (Joachims, 1998) and MaxEnt has been applied in many natural language processing tasks (Berger et al.", "startOffset": 157, "endOffset": 173}, {"referenceID": 2, "context": "We employ Support Vector Machines (SVMs) and Maximum Entropy (MaxEnt) as our learning methods, because SVMs are shown to be effective in text categorization (Joachims, 1998) and MaxEnt has been applied in many natural language processing tasks (Berger et al., 1996).", "startOffset": 244, "endOffset": 265}, {"referenceID": 6, "context": "The second uses the text segmentation software of Choi (2000) to partition the decision-related DAs (ordered according to time) into several topic-based groups (CHOISEGMENT).", "startOffset": 50, "endOffset": 62}, {"referenceID": 0, "context": "Our evaluation metrics include b (also called Bcubed) (Bagga and Baldwin, 1998), which is a com-", "startOffset": 54, "endOffset": 79}, {"referenceID": 8, "context": "(2005), Galley (2006), Gurevych and Strube (2004)) has shown that DRDA-level extractive summarization can be effective when viewed as a binary classification task.", "startOffset": 8, "endOffset": 22}, {"referenceID": 8, "context": "(2005), Galley (2006), Gurevych and Strube (2004)) has shown that DRDA-level extractive summarization can be effective when viewed as a binary classification task.", "startOffset": 8, "endOffset": 50}, {"referenceID": 7, "context": "We follow the method of Fern\u00e1ndez et al. (2008a), but use a larger set of features and different learning methods.", "startOffset": 24, "endOffset": 49}, {"referenceID": 15, "context": "An Adjacency Pair (AP) is an important conversational analysis concept; APs are considered the fundamental unit of conversational organization (Schegloff and Sacks, 1973).", "startOffset": 143, "endOffset": 170}, {"referenceID": 4, "context": "As in Bui et al. (2009) and Fern\u00e1ndez", "startOffset": 6, "endOffset": 24}, {"referenceID": 7, "context": "Finally, we considered comparing our systems to the earlier similar work of (Fern\u00e1ndez et al., 2008a) and (Bui et al.", "startOffset": 76, "endOffset": 101}, {"referenceID": 4, "context": ", 2008a) and (Bui et al., 2009), but found that it would be quite difficult because they employ a different notion from DRDAs which is Decision Dialogue Acts(DDAs).", "startOffset": 13, "endOffset": 31}], "year": 2016, "abstractText": "This paper addresses the problem of summarizing decisions in spoken meetings: our goal is to produce a concise decision abstract for each meeting decision. We explore and compare token-level and dialogue act-level automatic summarization methods using both unsupervised and supervised learning frameworks. In the supervised summarization setting, and given true clusterings of decisionrelated utterances, we find that token-level summaries that employ discourse context can approach an upper bound for decision abstracts derived directly from dialogue acts. In the unsupervised summarization setting,we find that summaries based on unsupervised partitioning of decision-related utterances perform comparably to those based on partitions generated using supervised techniques (0.22 ROUGE-F1 using LDA-based topic models vs. 0.23 using SVMs).", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}