{"id": "1606.09577", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jun-2016", "title": "Ordering as privileged information", "abstract": "We propose immediately accelerate the proportion of polarization own second same recognition oversee in directly propensity an variance accelerations significant such hypothesis planar, entire are public materials following fast - microeconomic given. We kind that it time-dependent girth what be the only bridging phenomenological enclosed into exporting balls companies on a although order total. This powers co2 makes be minimized as he preposition regression problem, leading either end LUPI (Learning Using Privileged Information) enabling inside keep if came privileged analysis there usually corresponding ordering, out additional own consumers - converging hypothesis space by empirically enforce some ones hypothesis space according came that ordering. We our a significant analysis of second conventional. We discuss put greatly with introducing selection and means an innovative technique all criteria certain uses parameters. Finally, even making some indicators observations.", "histories": [["v1", "Thu, 30 Jun 2016 17:06:30 GMT  (17kb)", "http://arxiv.org/abs/1606.09577v1", "10 pages, 1 table, 2 page appendix giving proofs"]], "COMMENTS": "10 pages, 1 table, 2 page appendix giving proofs", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["thomas vacek"], "accepted": false, "id": "1606.09577"}, "pdf": {"name": "1606.09577.pdf", "metadata": {"source": "CRF", "title": "Ordering as privileged information", "authors": ["Tom Vacek"], "emails": ["vacek@cs.umn.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 6.\n09 57\n7v 1\n[ cs\n.A I]\n3 0\nJu n"}, {"heading": "1 Introduction", "text": "Learning using Privileged Information (first proposed by Vapnik et. al. [1]) seeks to bring in privileged information to assist the learner. This information is privileged because the learner may use it choose a hypothesis, but the privileged information will be unavailable making decisions based on the hypothesis.\nThis paper proposes a LUPI method that directly minimizes the variance diameters of the hypothesis spaces under consideration, an essential quantity in fast-convergence literature [2, 3]. This approach applies to discriminant-based hypotheses spaces where predictions are derived from thresholding the the discriminant value, which should be totally orderable. We show that the discriminant ordering defines equivalence classes for the elements of the space, and these classes are directly related the the variance diameters we seek to control. If we could restrict the hypothesis space to just the good equivalence classes, we would reduce the variance diameters and improve the speed of convergence.\nSelecting a good equivalence class requires some external definition of desirable order. This is privileged information. This raises a natural question:What is a desirable order? If ordering information were provided by an oracle according to some true distribution, then any ordering would provide desirable variance diameters. However, since an empirical ordering is the best we can hope for, a good ordering is one which has favorable convergence properties in ordinal regression.1 Low ordinal loss is sufficient, while more general characterizations may be possible.\nFrom another perspective, orderings according to conditional probability P (Y |X) have great appeal, as models that provide good estimates of conditional probability allow broader application than ones that do\n1We would want the ordering to correspond to a good hypothesis for the pattern recognition problem, though this is irrelevant to the rate of convergence.\nnot. Moreover, confidence seems to be a sliver of common ground between human and machine learning. Thus, we consider orderings which seem to bear some relationship to conditional probability, though quite loose. While a total ordering is best for controlling variance diameters, two independent orderings for each class can be shown to be very nearly as good. This arrangement allows us to expand the scope of tasks where useful privileged information is available."}, {"heading": "2 What is order?", "text": "We can\u2019t hope to provide any kind of overview of the field of order statistics. Web search made this a lucrative and popular field. Nevertheless, we believe our starting point is novel:\nDefinition 1. Order is any property of a set of real numbers that is invariant under any invertible increasing transformation.\nOrdering naturally defines equivalence classes on hypotheses spaces. Suppose some distribution P generates feature vectors X \u2208 Rd, and suppose h1 and h2 are hypotheses in a space H : Rd \u2192 R. If an increasing function m exists so that for all X \u223c P , m(h1(X)) = h2(X),2 then h1 and h2 are in the same equivalence class.\nThe thread which connects order to the pattern recognition task is the growth function, which measures the number of possible labelings of a set of points of size n by a 0/1-hypothesis set H0/1. We assume that H0/1 is defined by characteristic functions of real-valued functions, as in H0/1 = {\u03be(h(X)\u2212 t) : h \u2208 H : R\nd \u2192 R, t \u2208 R}. We observe that if H\u0302 contains a restricted number of order equivalence classes, then the growth function of H is also restricted. We propose that the relationship can be made precise by the machinery of variance-based risk bounds.\nAs a thought experiment, consider the variance diameter of h1 and h2 when combined with an appropriate 0/1 loss function, and restricted to one class. More formally, suppose now that P generates feature vectors and labels Y \u2208 \u00b11 jointly.\nDefinition 2. Zero-one loss is:\nl01(y\u0302, y) =\n\n\n 1 y\u0302 > 0, y \u2264 0 1 y\u0302 \u2264 0, y > 0 0 otherwise\n(1)\n3\nThen for any h1 and h2 in the same order equivalence class for for any t1 and t2, it is easy to show that\nE P \u21beY =1\n|l01(h1(X)\u2212 t1, Y )\u2212 l 01(h2(X)\u2212 t2, Y )| (2)\n\u2264| E P \u21beY =1\nl01(h1(X)\u2212 t1, Y )\u2212 l 01(h2(X)\u2212 t2, Y )| (3)\n2We might relax this to holding on a set of full measure. 3 As a matter of boilerplate, we use loss functions as are commonly defined in machine learning literature: a loss function takes two arguments: a prediction and a label; however, we may omit those where obvious to avoid clutter. Loss functions are uniquely identified by a superscript, unless intended to be taken generally. The expectation of the loss EX,Y \u223cP [l(h(X), Y )] is depicted as L(h), and the empirical risk on a finite set of size n is depicted as Ln(h). There are numerous more measurability and existence assumptions that we will not cover here.\nExcept for the restriction to a single class, this is just the relationship for variance diameters4 that is needed for fast rates.\nThere are two tasks required to extend the thought experiment to a real learning formulation. First, the relationship needs to apply in both classes simultaneously. The complicating factor to just adding the two per-class relationships is that the absolute-value arguments in the two respective RHS\u2019s could have opposite signs and cancel out. This can happen when the decision threshold falls in very different places relative to the ordering. We fix this by requiring that the loss in the two classes be balanced as a constraint on valid solutions. In effect, this is a constraint on the location of the decision boundary in the equivalence class definition, preventing the situations where there is cancellation.\nMore significantly, there is no access to the equivalence classes based only on empirical information. This is the majority of the analysis in the remainder of the paper. In short, we relax the notion of the equivalence class to metric balls, and then we bound bound the deviation of empirical balls from their true diameter."}, {"heading": "2.1 Ordering metric", "text": "We define a metric on orderings so that two hypotheses are in the same equivalence class if their metric distance is 0. The metric, when shown to have favorable properties, allows us to create balls of restricted variance diameter based on a finite sample using ordinary empirical risk minimization.\nDefinition 3. Let M be the set of all increasing continuous functions.\nDefinition 4. Let P generate vectors X \u2208 Rd, and consider any two functions h1, h2 : Rd \u2192 R. Then the order distance between h1 and h2 is\nD(h1, h2) = sup t\u2208R inf m\u2208M E P [l01(m \u25e6 h1(X)\u2212 t, h2(X)\u2212 t)]\nThe metric axioms (up to equivalence class elements) are not hard to check; the invertability of m is indispensable here.\nWhile many definitions would satisfy the metric axioms, we chose this definition for two reasons. First, it is a direct extension of the result we saw for equivalence classes. If D(h1(X), h2(X)) \u2264 d, then (3) holds with d added to the right-hand side. Second, the fact that 0/1 loss is an underlying component allows us to borrow a great deal from the standard results in machine learning.\nSince we have no access to true probabilities in a statistical learning setting, to proceed we have to derive a way to get access to D. We accomplish this by extending D to measure the order distance of a function h to some ground truth ordering instead of another function. The key observation is that functions within D0 of the ground truth ordering are within 2D0 of each other by the triangle inequality\u2014an empirical version of the equivalence classes we set out to find. We will redefine this extension of D as Liso for clarity:\n4 Fast converging bounds require the following: Denote by h\u2032 \u2208 H the minimum of the true risk over H. The following must hold uniformly for all h \u2208 H:\nVar[l01(h(X), Y ) \u2212 l01(h\u2032(X), Y )]\n\u2264E[l01(h(X), Y )\u2212 l01(h\u2032(X), Y )] (4)\nOur presentation is slightly different because the variance can be upper bounded by the expectation of the absolute value and we have not specialized to h\u2032. Note that many presentations of fast convergence can lead an in-attentive reader to believe that h\u2032 must be the Bayes rule. This is true if one is using the Mammen-Tsybakov noise conditions to establish the desired variance relationship, but not necessary if the relationship can be established another way, as we do here.\nDefinition 5. Suppose P jointly generates feature vectors X and real-valued labels Y . Let H : Rd \u2192 R be some hypothesis space.\nLiso(h) = sup t\u2208R inf m\u2208M E P [l01(m \u25e6 h1(X)\u2212 t, Y \u2212 t)]\nThe task at hand is to analyze risk bounds for Liso that allows us, with high probability, to identify functions where Liso(h) \u2264 D0. based on a finite sample. The key observation is that the infimum (m \u2208 M) and supremum (t \u2208 R) in the definition of Liso can be handled by a uniform bound on the deviations of a loss function over the joint space H\u00d7M\u00d7 R. We define that loss function to be lthr:\nDefinition 6. lthr(y\u0302, y, t) = l01(y\u0302 \u2212 t, y \u2212 t)\nWe will show that if H has bounded level VC-dimension,5 then the loss class for lthr over H\u00d7M\u00d7 R also has bounded VC dimension, so we can derive uniform risk bounds for empirical risk minimization.\nWe observe that level VC-dimension already satisfies an order invariance. That is, the inclusion of M doesn\u2019t have any affect on the estimated growth function.\nLemma 1. Let MH = {m \u25e6 h : h \u2208 H,m \u2208 M}. Then the level VC dimension of MH is the same as for H.\nThe proof is a simple shattering argument. Obviously, MH \u2287 H, so the VC-dimension is not less. It is not more because any rule m \u25e6 h\u2212 t > 0 can be replicated by h\u2212 t\u2032 > 0 for an appropriately chosen t\u2032.\nThese two observations give the following theorem:\nTheorem 1. Suppose H has level VC-dimension V . There exists a universal constant C such that uniformly for all h \u2208 H the following holds with probability at least 1\u2212 \u03b4:\nLiso(h) \u2264 sup t\u2208R inf m\u2208M Lthrn (m \u25e6 h, t) + C\n\u221a\nV log(n) + log 1\u03b4 n\nThe bound is a straightforward application of uniform risk bounds, provided that the VC dimension of the loss class can be found. This is a straightforward shattering argument. Suppose H has level VC dimension V . Suppose there exists a set {(xi, yi)} 2V+1 i=1 and some t0 such that {l\nthr(h(xi), yi, t0)}h\u2208H can attain any labeling. Considering the two sets {i : yi > t0} and {i : yi \u2264 t0}, one of these has size at least V + 1 by the pigeonhole principle. Call the set S. Then {h(xi) \u2212 t0 > 0}h\u2208H,i\u2208S is shattered, which contradicts our assumption about the level VC dimension of H. Hence, the VC-dimension is at most 2V . Extending the argument to allow separate orderings in each class is similar; there are now four pigeonholes because we have to consider a separate threshold for each ordering, so 4V + 1 points will ensure a contradiction."}, {"heading": "3 Putting the pieces together", "text": "The ordinal regression bound is the substantial piece of the puzzle, but to make use of it have to enforce class balance. Suppose that the user provides some parameter w as a weight to favor or discourage loss in one class over another:\n5 Level VC-Dimension is an extension of VC-dimension to real-valued functions. It is the VC dimension of {h\u2212t : h \u2208 H, t \u2208 R}.\nDefinition 7. Loss balance, given a specified parameter w > 0, is measured by\nlB(y\u0302, y;w) =\n{\nmax(w, 1) y\u0302 \u2264 0, y > 0 \u2212max(1, 1w ) y\u0302 > 0, y \u2264 0\nThe VC dimension of this loss class can be analyzed in terms of the VC dimension for the underlying hypothesis space just like in the ordinal regression application, giving a similar bound. With this in hand, we are ready for the main theorem:\nTheorem 2. Suppose some predefined ordering is provided. Consider the subset of H that satisfies the predefined ordering up to loss d and assume that the user provides a loss balance parameter that is empirically satisfied:\nH\u0302d = {h \u2208 H : L iso n (h) \u2264 d, L B n (h;w) = 0}.\nAssume that this set is not empty. Let h\u0302n be the empirical minimizer (of L01n ) and h\u0302 \u2032 be the true minimizer (of L01) over H\u0302. Then there exists a constant C such that the following holds uniformly for all h \u2208 H\u0302 and for all \u03c6 \u2264 1 with probability at least 1\u2212 \u03b41 \u2212 \u03b42 \u2212 \u03b43:\nmax ( L01(hn)\u2212 L 01(h\u2032), L01n (h \u2032)\u2212 L01n (hn) )\n\u2264 8\nn\u03c6\n(\n4C2V logn+ (1 + 2\u03c6) log 1\n\u03b41\n)\n+ 128\u03c6\n\nd+ C\n\u221a\nV log(n) + log 1\u03b42 n\n\n\n+ 128\u03c6Cmax\n(\nw, 1\nw\n)\n\u221a\nV log(n) + log 1\u03b43 n\nThe key to interpreting this bound is to note that one tunes \u03c6 to optimize the value in n. While the first term on the RHS dominates, let \u03c6 = 1, but when this drops below subsequent terms, \u03c6 can be set like n\u22121/4, giving an overall convergence like n\u22123/4 down to a constant times d, and then \u03c6 would be set like n\u22121/2 thereafter. Obviously, a small d is important; that is to say, the privileged orderings should fit well to some h \u2208 H under Liso. However, d could be much smaller under favorable circumstances. We believe it would be possible to characterize these by extending the Mammen-Tsybakov noise conditions to Liso. A proof is given in the appendix.\n4 Optimizing Lison We now study methods to find infh\u2208H,m\u2208M Lison (m \u25e6 h), assuming a linear or RKHS hypothesis space with defined level VC-dimension. We note that for a fixed h, the optimal m can be found by means of a dynamic program. A method to construct real-valued functions with defined level VC-dimension was given by Vapnik [4, p. 359]. The technique requires the model to separate each successive example by a minimum margin. As common with zero-one loss, we relax it to hinge loss to make a convex model.\nAssume that examples are sorted increasing in yi and there are no duplicates (which require extra attention). Define\nyij =\n{\n\u22121 yj \u2264 yi 1 yj > yi\nIn the following formulation, C is a user-defined capacity control parameter and \u03c1 = 1 can be assumed:\nmin w,\u03be,\u03b6,l\n1 2 \u2016w\u20162 + Cmax i (li) (5)\ns.t.for i = 1 . . . n : (6)\nli = \u2211\nj\nmax (\u03c1\u2212 yij(w \u00b7 xj \u2212 \u03bei), 0) (7)\nfor i\u2212 2 . . . n : (8)\n\u03bei\u22121 + \u03c1 \u2264 \u03bei (9)\nThis is a convex quadratic programming problem, though regrettably requiring n2 (where n is the number of examples) dummy variables to compute the max in line 7. This makes the program intractable (by machine learning standards), at least without a special solver.\nThe regression problem can be made more tractable by relaxing it to alternative ordinal regression formulations, such as the one proposed by Sashua & Levin [5]. Their formulation penalizes uses optimization variables to define ordered slots according to the sort order of the targets yi, and a training example is penalized if it does not project into its slot. It can be shown that the relaxation loss is an upper bound on the unrelaxed loss. The relaxed formulation is a quadratic program with just n constraints."}, {"heading": "5 GO-SVM", "text": "The Global-Order SVM (GO-SVM) is the name for the formulation we propose. It is simply is the usual SVM hypothesis space (thick hyperplanes) and loss (hinge), but it is simultaneously optimized with the Sashua & Levin [5] ordinal regression relaxation, with the SVM discriminant w constrained to be the same as the ordering hypothesis w. This constraint implements the restriction from H (the SVM hypothesis space) to H\u0302 (hypotheses that satisfy an ordinal condition), as defined in Theorem 2. Loss and capacity control are traded off between the bi-objectives by means of user-selectable weights.\nCapacity control in both SVM and the ordinal regression formulations is attained by the relationship between the squared norm of the predictor w and the size of the margin. In either formulation by itself, one can fix the margin size and place all capacity control in the squared norm of w, trading it off with loss. However, w serves a two-fold role in this formulation; therefore implementing different capacities for the two learning objectives requires setting the margins. Noting that the \u03bd-SVM formulations [6] have the margin as an optimization variable, we extended the approach so that the usual tradeoff between loss and capacity is preserved.\nThe formulation is\nmin \u03be\u22650\nw,b,g,\u03be \u03b6,\u03c1b,\u03c1o\n1 2 wTw + \u03b1\n(\n\u2212\u03bdb\u03c1b + 1\nn\nn \u2211\ni=1\n\u03bei\n)\n+ (1\u2212 \u03b1)\n(\n\u2212\u03bdo\u03c1o + 1\nn\u2217\nn \u2211\ni=1\n|\u03b6i|\n)\n(10)\ns.t.\u2200i, yi(w \u00b7 xi + b) \u2265 \u03c1b \u2212 \u03bei (11)\n\u2200i, gI(i) + \u03c1o 2 \u2264 w \u00b7 xi + \u03b6i \u2264 gI(i)+1 \u2212 \u03c1o 2\n(12)\nHere, I is an index function that returns an in-order, unique index for each distinct oracle value for in each class, and g is a vector of interval boundaries. Ordering is enforced because there are no empty intervals. The within-class ordering variant in principle requires two ordinal regressions, but in practice it can be done with a trick using the index function I by creating an empty interval.\nVariable w is the linear predictor, b is a bias term, \u03be is the hinge loss for the classification problem, and |\u03b6| is hinge loss for the ordinal problem. Constant n\u2217 is defined to control the feasible range of \u03bdo. It is n2\u2212n/2 if there are not ties in the ordering.\nParameter \u03bdb controls the VC-dimension of the 0/1 loss class, \u03bdo controls the maximum VC-dimension of each subproblem in Lthr. Finally, parameter\u03b1 is related to choosing the size of d in Theorem 2, expressed in terms of the permissiveness of the ordinal loss compared to the 0/1 loss. We do not attempt to enforce loss balance, as theory tells we should; from any computed solution, we can still apply the bound for as if we had constrained it to the value achieved by the optimum; moreover, we have never known the uncontrained optimum to have unreasonable loss balance, and we have no reason to prefer otherwise.\nLike \u03bd-SVM [6], the optimization problem can be characterized in terms of \u03bdb and \u03bdo and training data. The It can be proved that the problem is primal and dual feasible for \u03bdo \u2208 [0, 1], \u03b1 \u2208 [0, 1], and \u03bdb \u2208 [0, 2min(# positive examples,# negative examples)/n; and primal unbounded/dual infeasible otherwise. The Representer Theorem [7] holds for GO-SVM, so the solution can be expressed in terms of the dual variables and kernels can be used. We used Matlab\u2019s interior-point convex quadratic programming solver. The baseline \u03bd-SVM formulation was also implemented using the same solver, so that differences in numerical accuracy could not arise."}, {"heading": "6 Evaluation", "text": "The goal of evaluation is to prove that the order oracle hypothesis space allows faster convergence than a learning formulation which considers only the labels. Since GO-SVM is an extension of standard SVM, it is a logical baseline, and we compare only to that. However, these experiments are similar to other common experiments in LUPI literature, and we will point these to the reader where appropriate. Moreover, because of the construction of the GO-SVM hypothesis spaces, it cannot outperform SVM by virtue of a richer hypothesis space. Faster convergence is the only alternative explanation. The evaluation is not intended to be a statement about the fitness of the hypothesis spaces for the learning task, but only about the ability of the learner to select the best element.\nThe experimental setup is to hold out a testing set and sample remaining examples for 12 random realizations of training and validation sets. The validation set is used for a set of model selection experiments, and results are reported on the test set, which is used for all experiments. Testing sets contained at least 1800 examples. The formulations have a fixed, auto-scaling parameter \u03bd, and we use structural risk minimization to choose from a fixed set of parameters \u03bd = [.1 : .1 : .9, .95].\nThe rbf kernel width (where used) is chosen from the [.1, .25, 5]-quantiles of the pairwise distance of training points. The kernel parameter was chosen by a hold-out validation on the SVM experiment and reused in the GO-SVM formulation to cut down the size of the model search. The \u03b1 parameter in the GO-SVM method was chosen from [.1, .25, .5].\nThe first evaluation is up/down prediction of the MacKey-Glass synthetic timeseries [8]. It was used in the LUPI setting (SVM+) in [1], where the authors used a 4-dimensional embedding (xt\u22123, xt\u22122, xt\u22121, xt) in order to predict xt+5 > xt. Privileged information was a 4-dimensional embedding around the target: (xt+3, xt+4, xt+6, xt+7). The authors compared SVM+ to SVM. We were not able to replicate their results for either SVM or SVM+, which we suspect arises from the parameters used to generate the timeseries. (We\nused an integration step size of .1, with points created every 10, delay constant \u03c4 = 17, and initial value .9.) We use |xt+5 \u2212 xt| as the order oracle. We use an RBF kernel for all experiments with this dataset.\nThe second evaluation is predicting binary survival at a fixed time from onset. We create synthetic datasets using the same procedure as Shiao & Cherkassky [9, personal communication], with noise level .1 and no censoring, which is given by an exponential distribution parameter 1/.01. While censored data are an inherent aspect of survival studies, we avoid it in this case because the ordinal model can be modified to accommodate the partial information that censored examples contain; thus, it is an experiment for another day. They compare SVM, SVM+, and the Cox proportional hazards model. Privileged information for SVM+ was related to the patient\u2019s overall survival time and whether the event time is right censored (only known to be greater than some value). We use the (absolute) difference in the fixed prediction horizon and the event time for the order oracle, and we ignore whether an example is censored. We consider only linear models.\nThe last evaluation is handwritten digit recognition, which was used by Vapnik and Vahist [1] for SVM+ and slightly adapted by Lapin et al. for their proposed LUPI method [10]. The task is to classify downsampled (10 \u00d7 10) MNIST images based on pixel values. Lapin added human-annotated confidence scores to training examples (available for download). We repeat the experiment using their data preparation and using their annotators\u2019 confidence scores as the order oracle. These experiments use an RBF kernel."}, {"heading": "6.1 Model selection", "text": "The Go-SVM formulation considers a model space of 3 dimensions: a parameter to control the complexity of the classification problem, a parameter to control the complexity of the ordinal regression problem, and a parameter that balances the loss between these two problems. All of the parameters are chosen from fixed lists, which were detailed supra. The most basic form of model selection requires choosing the best node of the grid.\nWe found that traditional hold-out model selection strategies are more difficult with GO-SVM. The trouble appears to be because the assumptions of structural risk minimization [4] no longer hold. In traditional SRM, the nested hypothesis spaces ensures that the loss expectation of the empirical risk minimizer (as a function of complexity) is coercive, making the selection of a minimum considerably more reliable than if it occurred at random. In our framework, there is no total ordering of hypothesis complexity. Some hypothesis spaces (defined by parameters) have good convergence, while others do not. The task is to differentiate them.\nWe analyzed loss surfaces with respect to various dimensions of the parameter selection grid. We used synthetic datasets where we could to generate a great number of examples. We observed that, although the surfaces were not coercive, they tended to be smooth. Since the parameters of the models have a direct interpretation, parameters that are similar should have similar performance in expectation when trained on the same set. Thus, we decided to try a Gaussian filter to smooth the validation results, and then select the minimum in a grid search. The filter was constructed apriori, and was used for all the datasets in the evaluation.\nIn each experiment, we computed the loss on the test set that would have been found by each of three methods:\n1. A standard holdout, with the held-out validation set the same size as the training set. One might use cross-validation in practice. This is called \u2018unsmooth.\u2019\n2. The Gaussian smoothing technique using the same holdout. This is called \u2018smoothed.\u2019\nThe Gaussian filter was of size 5x5x3, with the smallest dimension corresponding to the \u03b1 parameter. (In experiments using a kernel parameter, we used one found via the SVM model search, so this was not a grid search parameter.) It has the property that any projection along coordinate directions of the filter is Gaussian. This was convolved with the tensor of validation scores using zero-degree smooth extrapolation; that is, the tensor is padded out with constants which are the same as the nearest true element of the tensor. The convolution gives a new tensor that is the same dimension as the un-smoothed tensor.\nWe also considered two alternative validation scenarios: first, selecting a model based on the un-smoothed tensor, and second, investigating the effect of having a much larger validation set available. The large validation set is intended to point out the gap between the best hypothesis spaces that can be created using the ordinal constraint technique, and the one which can in practice be selected. We point out that many LUPI research papers require validation sets that would not ordinarily be a reasonable split between training and testing data (for example [11, 1]. Each row of the table gives the size of the training and test sets. The columns give the model selection procedure."}, {"heading": "6.2 Conclusions", "text": "A table of results is given at Table (6.1). As a reminder, sizes for training and testing are given in parenthesis with the experiment name. The std, non-smooth, and smoothed methods used a validation set the same size as the training set. We note first that the gap between the extended validation model selection and the performance of the typical technique is larger for GO-SVM than for standard SVM. This is a blessing in that we have the opportunity to find a better model, but also a curse in that the variance is higher. It appears that this strain of LUPI methods is bound by model selection issues. The Gaussian smoothing approach seems to have been effective on the Digits dataset, and certainly did not hinder performance significantly where the un-smoothed model selection turned out to be superior.\nThe MacKey-Glass dataset is the only one which has strongly significant results. Although the gains in other datasets are small, the fact that they are supported by theory implies they should not be overlooked. Moreover, they are consistent with results reported by other authors. There comparisons with other works for the MacKey-Glass and Digits experiments. The MacKey-Glass experiment appeared in the original SVM+ paper [1]. They report, based on a training set of 100 examples, that SVM had an error rate of .052, whereas\nthe best SVM+ formulation was at .048. Furthermore, this was based on a validation set of size 500. We have reached that level of performance with considerably less data. The Digits experiment is intended to replicate one in [11]. We specifically replicated the experiment in which conditional probability weights were created by humans with an intent to help a machine. This task is well-suited to the order invariance that GO-SVM is built on, as humans have a fundamentally ordinal notion of confidence. In that study at a sample size of 80, the difference between the best and worst methods under study was about .01\u2014.073 compared to .083 (approximately). The size of the validation set in use, would be comparable to our extended experiment. Their best method, however, did not use human weights. In their experiment, the human weights information improved over SVM by about .003, whereas our gain is .006.\nIn conclusion, the fact that the formulation can find faster-converging models than formulations which don\u2019t consider order information supports the underlying theory. It appears likely the order information is helpful in scenarios when the prediction task discretizes some continuous attribute, such as in the timeseries and survival prediction tasks."}, {"heading": "7 Previous work", "text": "The original SVM+ paper [1] touched off a fair amount of research in the area. Most research, with limited exceptions, has focused on developing and evaluating formulations [12, 13, 14, 15, 15] rather than attempting to develop theory to understand when and why such a technique might be useful.\nPechyony et. al. [16] analyze the SVM+ algorithm in terms of variance bounds. While it shares with this work a major emphasis on variance bounds, that work considers the SVM+ loss function as given and derives bounds for it, whereas this paper works the other way in attempting to derive a formulation based on the bound.\nLapin et. al. [11] propose weighting examples based on class conditional probability, and is most directly similar to the ideas proposed here. Intuitively, the method encourages a learner to prioritize performance on the easy examples over the hard examples. Unfortunately, the theoretical motivation for departing from empirical risk minimization takes a tenuous path through SVM+ [1, 16], namely that SVM+ is reducible to weighted learning. The heart of their method is based on a loss function based on weights interpreted as conditional probability; however, a theoretical analysis is not provided. Our is somewhat more general in allowing order in variances."}, {"heading": "8 Appendix", "text": "The first result is a bridge between the variance conditions and the metric balls of hypotheses we can actually define. This result shows that the uniform variance conditions can be relaxed by a small constant, depicted here as d(n), at the expense of the rate of convergence when the bound is small.\nTheorem 3. Suppose there is a loss class F = {l \u25e6 h : h \u2208 H} with VC-dimension V , and let f \u2032 attain inff\u2208F E[f ]. There is a uniform constant C such that if the following holds uniformly for all f \u2208 F ,\nVar[f \u2212 f \u2032] \u2264 1\nh E[f \u2212 f \u2032] + d(n)\nthen for any \u03c6 \u2264 h \u2264 1, the following holds uniformly with probability 1\u2212 \u03b4:\nmax ( E[fn \u2212 f \u2032],E\nn [f \u2032 \u2212 fn]\n)\n\u2264 8\nn\u03c6\n(\n4C2V logn+ (1 + 2\u03c6) log 1\n\u03b4\n)\n+ 32\u03c6d(n).\nProof. I follow the definitions and notation in Bucheron et al. [17, Theorem 5.5]. In their notation it is straightforward to show that w(r) \u2264 \u221a\nr \u03c6 + d. For VC-classes, it can be proved that \u03c8(x) \u2264 Cx\n\u221a\nV n logn\n[18]. The risk bound depends on the solution of a fixed-point equation. Let \u01eb\u2217 be the solution of r = \u03c8(w(r)). Let \u01eb\u2032 = C2 V log nn\u03c6 + \u03c6d. The following analysis shows that \u01eb \u2032 \u2265 \u03c8(w(\u01eb\u2032)), which implies \u01eb\u2217 \u2264 \u01eb\u2032.\n\u03c8(w(\u01eb\u2032)) = C\n(\nC2\n\u03c62 V logn n + 2d\n) 1\n2 (\nV logn\nn\n) 1\n2\n(13)\n\u2264 C\n(\n(\nC2\n\u03c62 V log n n\n) 1\n2 + 1\n2\n(\nC2\n\u03c62 V logn n\n)\u2212 1 2\n2d\n)\n(\nV logn\nn\n) 1\n2\n(14)\n= C2 V logn\nn\u03c6 + \u03c6d = \u01eb\u2032. (15)\nAt step 14 I used that the first-order approximation of the square root is an upper bound. The bound \u01eb\u2032 can be substituted wholesale into the bound given by Bucheron in the statement of the theorem, which gives the theorem.\nThe next step is to show that the combination of the ordinal constraint and the balance constraint are sufficient to bound the variance diameter of the subset of a hypothesis space that satisfies those conditions.\nLemma 2. Suppose that an ordering and loss balance parameter w are provided and and that f, g \u2208 H\u0302. That is, Liso(f) \u2264 D0, Liso(g) \u2264 D0, and LB(f) \u2264 B0 and LB(g) \u2264 B0. Finally, Suppose L01(g) \u2264 L01(f). Then E |(l01(f(X), Y )\u2212 l01(g(X), Y )| \u2264 E[l01(f(X), Y )\u2212 l01(g(X), Y )] + 4(b+ d).\nProof. For the purposes of the proof, we decompose the expectation by class. Let PP = P (X |Y = 1) and PN = P (X |Y = \u22121). Let pP = P (Y = 1) and pN = P (Y = \u22121). Similarly, let LP and LN be loss functions defined by conditional expectations. The outline of the argument is shown below. We will expand each line subsequently.\nE P |l01(f(X), Y )\u2212 l01(g(X), Y )| (16)\n= E PP |l01(f(X), 1)\u2212 l01(g(X), 1)|pP + E PN |l01(f(X),\u22121)\u2212 l01(g(X),\u22121)|pN (17)\n\u2264| E PP l01(f(X), 1)\u2212 l01(g(X), 1)|pP + | E PN l01(f(X),\u22121)\u2212 l01(g(X),\u22121)|pN + 4D0 (18)\n\u2264 E PP [l01(f(X), 1)\u2212 l01(g(X), 1)]pP + E PN [l01(f(X),\u22121)\u2212 l01(g(X),\u22121)]pN + 4(D0 +B0) (19)\n= L01(f)\u2212 L01(g) + 4(D0 +B0) (20)\nWe begin by proving the inequality at line 18. Consider only the positive class for a moment. Let \u03b4f be the decision (or margin, as a simple extension) boundary for f and \u03b4g the boundary for g. Then l01 is 1 for f(X) \u2264 \u03b4f and 0 otherwise.\nWe have noted the triangle inequality relationship between D and Liso. Suppose Liso(f) \u2264 D0 and Liso(g) \u2264 D0, then D(f, g) \u2264 2D0. Let mf and mg be monotone functions as defined (implicitly) in Liso. Then mfg = m \u22121 g mf is a continuous monotone function which makes the metric relationship true. We will first show\nE PP |1f(X)\u2264\u03b4f \u2212 1g(X)\u2264\u03b4g | \u2264 | EPP [1f(X)\u2264\u03b4f \u2212 1g(X)\u2264\u03b4g ]|+ 2D0 (21)\n\u21d4 E PP [1f(X)\u2264\u03b4f \u2227 g(X)>\u03b4g ] + EPP [1f(X)>\u03b4f \u2227 g(X)\u2264\u03b4g ] (22)\n\u2264 | E PP [1f(X)\u2264\u03b4f \u2227 g(X)>\u03b4g ]\u2212 EPP [1f(X)>\u03b4f \u2227 g(X)\u2264\u03b4g ]|+ 2D0 (23)\nRewriting concisely, we wish to show a + b \u2264 |a\u2212 b|+ 2D0. In fact, this holds because either a \u2264 D0 or b \u2264 D0, which can be proved in the following way: Expanding a we have:\nE[1f(X)\u2264\u03b4f \u2227 g(X)>\u03b4g ] =E[1f\u2264\u03b4f \u2227 g>\u03b4g \u2227 g>mfg (\u03b4f )] + E[1f\u2264\u03b4f \u2227 g>\u03b4g \u2227 g\u2264mfg (\u03b4f )] (24)\n\u2264D0 + E[1g>\u03b4g \u2227 g\u2264mfg (\u03b4f )] (25)\nThe expectation term in line 25 is 0 if mfg (\u03b4f ) \u2264 \u03b4g . Repeating the procedure for b shows that the corresponding term is 0 if mfg (\u03b4f ) \u2265 \u03b4g . Since one of those conditions must be true, at least one of a or b is bounded by d, which proves line 21. A bound for the negative class is identical. This proves inequality 18.\nTo prove inequality 19, the assumptions on class balance are needed. Since we assumed that L(f) > L(g), then either (or both) LP (f) > LP (g) or LN (f) > LN(g). If both are true, then the desired inequality (19) is trivial. Suppose that LP (f) > LP (g) and LN(f) \u2264 LN (g).\n|LP (f)\u2212 LP (g)|pP + |LN(f)\u2212 LN(g)|pN (26)\n=|a\u2212 b|+ |c\u2212 d| (27)\n=a\u2212 b+ d\u2212 c (28)\n=a\u2212 b+ c\u2212 d+ 2(d\u2212 c) (29)\n\u2264a\u2212 b+ c\u2212 d+ 2w(b\u2212 a) + 4B0 (30)\n\u2264(LP (f)\u2212 LP (g))pP + (LN (f)\u2212 LN (g))pN + 4B0 (31)\nwhere we used that b \u2212 a < 0 ,|wa \u2212 c| \u2264 B0, |wb \u2212 d| \u2264 B0, and w > 0. The proof if LN(f) > LN (g) and LP (f) \u2264 LP (g) uses that |a\u2212 1w c| \u2264 B0 and |b\u2212 1 wd| \u2264 B0."}], "references": [{"title": "2009 special issue: A new learning paradigm: Learning using privileged information", "author": ["Vladimir Vapnik", "Akshay Vashist"], "venue": "Neural Netw.,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Smooth discrimination analysis", "author": ["Enno Mammen", "Alexandre B. Tsybakov"], "venue": "Ann. Statist., 27(6):1808\u20131829,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1999}, {"title": "Optimal aggregation of classifiers in statistical learning", "author": ["Alexander B. Tsybakov"], "venue": "Ann. Statist., 32(1):135\u2013166,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2004}, {"title": "Statistical learning theory. Adaptive and learning systems for signal processing, communications, and control", "author": ["V.N. Vapnik"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1998}, {"title": "Ranking with large margin principle: Two approaches", "author": ["Amnon Shashua", "Anat Levin"], "venue": "In Advances in Neural Information Processing Systems 15 [Neural Information Processing Systems,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2002}, {"title": "New support vector algorithms", "author": ["Bernhard Sch\u00f6lkopf", "Alex J. Smola", "Robert C. Williamson", "Peter L. Bartlett"], "venue": "Neural Comput.,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2000}, {"title": "A generalized representer theorem", "author": ["Bernhard Sch olkopf", "Ralf Herbrich", "AlexJ. Smola"], "venue": "Computational Learning Theory,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2001}, {"title": "Nonlinear prediction of chaotic time series using support vector machines", "author": ["S. Mukherjee", "E. Osuna", "F. Girosi"], "venue": "In Neural Networks for Signal Processing", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1997}, {"title": "Learning using privileged information (LUPI) for modeling survival data", "author": ["Han-Tai Shiao", "Vladimir Cherkassky"], "venue": "In 2014 International Joint Conference on Neural Networks,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Learning using privileged information: SVM+ and weighted SVM", "author": ["Maksim Lapin", "Matthias Hein", "Bernt Schiele"], "venue": "Neural Networks,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Learning using privileged information: SVM+ and weighted SVM", "author": ["Maksim Lapin", "Matthias Hein", "Bernt Schiele"], "venue": "Neural Networks,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Boosting with side information", "author": ["Jixu Chen", "Xiaoming Liu", "Siwei Lyu"], "venue": "In Computer Vision - ACCV 2012 - 11th Asian Conference on Computer Vision, Daejeon,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "Learning with hidden information using a max-margin latent variable model", "author": ["Ziheng Wang", "Tian Gao", "Qiang Ji"], "venue": "In Pattern Recognition (ICPR),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Learning using privileged information in prototype based models", "author": ["Shereen Fouad", "Peter Tino", "Somak Raychaudhury", "Petra Schneider"], "venue": "Artificial Neural Networks and Machine Learning \u2013 ICANN 2012,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "Classifier learning with hidden information", "author": ["Ziheng Wang", "Qiang Ji"], "venue": "Computer Vision and Pattern Recognition, IEEE Conference on,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "On the theory of learning with privileged information", "author": ["D. Pechyony", "V. Vapnik"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "Theory of classification : a survey of some recent advances", "author": ["St\u00e9phane Boucheron", "Olivier Bousquet", "G\u00e1bor Lugosi"], "venue": "ESAIM: Probability and Statistics,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2005}, {"title": "Local rademacher complexities", "author": ["Peter L. Bartlett", "Olivier Bousquet", "Shahar Mendelson"], "venue": "Ann. Statist., 33(4):1497\u20131537,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": "[1]) seeks to bring in privileged information to assist the learner.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "This paper proposes a LUPI method that directly minimizes the variance diameters of the hypothesis spaces under consideration, an essential quantity in fast-convergence literature [2, 3].", "startOffset": 180, "endOffset": 186}, {"referenceID": 2, "context": "This paper proposes a LUPI method that directly minimizes the variance diameters of the hypothesis spaces under consideration, an essential quantity in fast-convergence literature [2, 3].", "startOffset": 180, "endOffset": 186}, {"referenceID": 4, "context": "The regression problem can be made more tractable by relaxing it to alternative ordinal regression formulations, such as the one proposed by Sashua & Levin [5].", "startOffset": 156, "endOffset": 159}, {"referenceID": 4, "context": "It is simply is the usual SVM hypothesis space (thick hyperplanes) and loss (hinge), but it is simultaneously optimized with the Sashua & Levin [5] ordinal regression relaxation, with the SVM discriminant w constrained to be the same as the ordering hypothesis w.", "startOffset": 144, "endOffset": 147}, {"referenceID": 5, "context": "Noting that the \u03bd-SVM formulations [6] have the margin as an optimization variable, we extended the approach so that the usual tradeoff between loss and capacity is preserved.", "startOffset": 35, "endOffset": 38}, {"referenceID": 5, "context": "Like \u03bd-SVM [6], the optimization problem can be characterized in terms of \u03bdb and \u03bdo and training data.", "startOffset": 11, "endOffset": 14}, {"referenceID": 0, "context": "The It can be proved that the problem is primal and dual feasible for \u03bdo \u2208 [0, 1], \u03b1 \u2208 [0, 1], and \u03bdb \u2208 [0, 2min(# positive examples,# negative examples)/n; and primal unbounded/dual infeasible otherwise.", "startOffset": 75, "endOffset": 81}, {"referenceID": 0, "context": "The It can be proved that the problem is primal and dual feasible for \u03bdo \u2208 [0, 1], \u03b1 \u2208 [0, 1], and \u03bdb \u2208 [0, 2min(# positive examples,# negative examples)/n; and primal unbounded/dual infeasible otherwise.", "startOffset": 87, "endOffset": 93}, {"referenceID": 6, "context": "The Representer Theorem [7] holds for GO-SVM, so the solution can be expressed in terms of the dual variables and kernels can be used.", "startOffset": 24, "endOffset": 27}, {"referenceID": 7, "context": "The first evaluation is up/down prediction of the MacKey-Glass synthetic timeseries [8].", "startOffset": 84, "endOffset": 87}, {"referenceID": 0, "context": "It was used in the LUPI setting (SVM+) in [1], where the authors used a 4-dimensional embedding (xt\u22123, xt\u22122, xt\u22121, xt) in order to predict xt+5 > xt.", "startOffset": 42, "endOffset": 45}, {"referenceID": 0, "context": "The last evaluation is handwritten digit recognition, which was used by Vapnik and Vahist [1] for SVM+ and slightly adapted by Lapin et al.", "startOffset": 90, "endOffset": 93}, {"referenceID": 9, "context": "for their proposed LUPI method [10].", "startOffset": 31, "endOffset": 35}, {"referenceID": 3, "context": "The trouble appears to be because the assumptions of structural risk minimization [4] no longer hold.", "startOffset": 82, "endOffset": 85}, {"referenceID": 10, "context": "We point out that many LUPI research papers require validation sets that would not ordinarily be a reasonable split between training and testing data (for example [11, 1].", "startOffset": 163, "endOffset": 170}, {"referenceID": 0, "context": "We point out that many LUPI research papers require validation sets that would not ordinarily be a reasonable split between training and testing data (for example [11, 1].", "startOffset": 163, "endOffset": 170}, {"referenceID": 0, "context": "The MacKey-Glass experiment appeared in the original SVM+ paper [1].", "startOffset": 64, "endOffset": 67}, {"referenceID": 10, "context": "The Digits experiment is intended to replicate one in [11].", "startOffset": 54, "endOffset": 58}, {"referenceID": 0, "context": "The original SVM+ paper [1] touched off a fair amount of research in the area.", "startOffset": 24, "endOffset": 27}, {"referenceID": 11, "context": "Most research, with limited exceptions, has focused on developing and evaluating formulations [12, 13, 14, 15, 15] rather than attempting to develop theory to understand when and why such a technique might be useful.", "startOffset": 94, "endOffset": 114}, {"referenceID": 12, "context": "Most research, with limited exceptions, has focused on developing and evaluating formulations [12, 13, 14, 15, 15] rather than attempting to develop theory to understand when and why such a technique might be useful.", "startOffset": 94, "endOffset": 114}, {"referenceID": 13, "context": "Most research, with limited exceptions, has focused on developing and evaluating formulations [12, 13, 14, 15, 15] rather than attempting to develop theory to understand when and why such a technique might be useful.", "startOffset": 94, "endOffset": 114}, {"referenceID": 14, "context": "Most research, with limited exceptions, has focused on developing and evaluating formulations [12, 13, 14, 15, 15] rather than attempting to develop theory to understand when and why such a technique might be useful.", "startOffset": 94, "endOffset": 114}, {"referenceID": 14, "context": "Most research, with limited exceptions, has focused on developing and evaluating formulations [12, 13, 14, 15, 15] rather than attempting to develop theory to understand when and why such a technique might be useful.", "startOffset": 94, "endOffset": 114}, {"referenceID": 15, "context": "[16] analyze the SVM+ algorithm in terms of variance bounds.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] propose weighting examples based on class conditional probability, and is most directly similar to the ideas proposed here.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "Unfortunately, the theoretical motivation for departing from empirical risk minimization takes a tenuous path through SVM+ [1, 16], namely that SVM+ is reducible to weighted learning.", "startOffset": 123, "endOffset": 130}, {"referenceID": 15, "context": "Unfortunately, the theoretical motivation for departing from empirical risk minimization takes a tenuous path through SVM+ [1, 16], namely that SVM+ is reducible to weighted learning.", "startOffset": 123, "endOffset": 130}], "year": 2016, "abstractText": "We propose to accelerate the rate of convergence of the pattern recognition task by directly minimizing the variance diameters of certain hypothesis spaces, which are critical quantities in fast-convergence results. We show that the variance diameters can be controlled by dividing hypothesis spaces into metric balls based on a new order metric. This order metric can be minimized as an ordinal regression problem, leading to a LUPI application where we take the privileged information as some desired ordering, and construct a faster-converging hypothesis space by empirically restricting some larger hypothesis space according to that ordering. We give a risk analysis of the approach. We discuss the difficulties with model selection and give an innovative technique for selecting multiple model parameters. Finally, we provide some data experiments.", "creator": "LaTeX with hyperref package"}}}