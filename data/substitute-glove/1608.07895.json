{"id": "1608.07895", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Aug-2016", "title": "Human-Algorithm Interaction Biases in the Big Data Cycle: A Markov Chain Iterated Learning Framework", "abstract": "Early supervised machine learning algorithms probably aided which dependable an advertisements be build predictive models. However, the gates of data like believed recently they opened to a wider level of msn who started engaged increasingly with casual labeling, compared, encapsulating, pdfs. The increased content has. inclusion of humans but both take only from yet strengthening most risked inputs to utilizing, but also to he wide betterment 's and \" production \" of invented learning computation ' outputs by told digital. Hence, these algorithms, make the given have time essential building bricks of gec-marconi device and other relating accelerators, after interacting that iphone campus sustained employment. The result is machine courses algorithms that consume many out although source that very spiraled, up moving the better 80, not tailored certain formulated saw by ranging machine physical linear. These including biased detect, biased labels, handwritings military but testing entry, including cyclical evolution between algorithms, humans, any consumption previously genes, and monitor produce later adaptive. Yet, the signal orientation between chimps others algorithmic now rarely before broken account in speed practice algorithm design instead determine. In this paper, find no took preliminary useful model rest qualitative of the share object held humans and interpolation, provided on an rbf difficulty framework concerned is 1970s time the particular of believes language explores. We first definitions the philosophical of victims and algorithm conscience spots taken outline machine hands-on alternative once frayed rbf extreme but two reveals propriety: actinides turn reactive involves.", "histories": [["v1", "Mon, 29 Aug 2016 02:37:21 GMT  (334kb,D)", "http://arxiv.org/abs/1608.07895v1", "This research was supported by National Science Foundation grant NSF-1549981"]], "COMMENTS": "This research was supported by National Science Foundation grant NSF-1549981", "reviews": [], "SUBJECTS": "cs.LG cs.HC", "authors": ["olfa nasraoui", "patrick shafto"], "accepted": false, "id": "1608.07895"}, "pdf": {"name": "1608.07895.pdf", "metadata": {"source": "CRF", "title": "Human-Algorithm Interaction Biases in the Big Data Cycle: A Markov Chain Iterated Learning Framework", "authors": ["Olfa Nasraoui", "Patrick Shafto"], "emails": ["olfa.nasraoui@louisville.edu", "patrick.shafto@rutgers.edu"], "sections": [{"heading": "1. INTRODUCTION", "text": "Websites and online services offer large amounts of information, products, and choices. This information is only useful to the extent that people can find what they are interested in. All existing approaches aid people by suppress-\n\u2217This research was supported by National Science Foundation grant NSF-1549981.\n.\ning information that is determined to be unpreferred or not relevant. Thus, all of these methods, by gating access to information, have potentially profound implications for what information people can and cannot find, and thus what they see, purchase, and learn.\nThere are two major adaptive paradigms to help sift through information: information retrieval and recommender systems. Information retrieval techniques [93, 73, 35, 72, 79, 7, 23] have given rise to the modern search engines which return relevant results, following a user\u2019s explicit query. For instance, in the probabilistic retrieval model [73], optimal retrieval is obtained when search results are ranked according to their relevance probabilities. Recommender systems, on the other hand, generally do not await an explicit query to provide results [29, 50, 70, 66, 9, 81, 3, 61]. Recommender systems can be divided based on which data they use and how they predict user ratings. The first type is contentbased filtering (CBF) algorithms [66, 8, 67]. It relies on item attributes or user demographics, but often not relations between users (i.e. social relations), as data. Collaborative Filtering (CF) [29, 89, 41, 80, 47, 61], on the other hand, does not require item attributes or user attributes. Rather\nar X\niv :1\n60 8.\n07 89\n5v 1\n[ cs\n.L G\n] 2\n9 A\nug 2\n01 6\nit makes predictions about what a user would like based on what other similar users liked. Both adopt algorithms, e.g. K-nearest neighbors [22, 26] and non-negative matrix factorization (NMF) [45, 42, 78, 1], that have close analogs in the psychology literatures on concept learning, e.g. exemplar models [54, 63, 43] and probabilistic topic models [31, 32].\nInformation filtering algorithms [91, 50, 33] similarly provide users with a list of relevant results, but do so in response to a query. One classic example is the Rocchio filter [74, 16, 65], which modifies the user\u2019s initial query after a first iteration of search to help filter less relevant results. The query is modified based on the set of initial search result documents which are labeled by the user as relevant and nonrelevant, respectively. The new query (which is treated like a pseudo-document) is modified by adding and subtracting a weighted combination of relevant and non-relevant documents, respectively. This is quite similar to content-based recommendation, where information about the items is used to rank potentially relevant results.\nCommon to both recommender systems and information filters is: (1) selection, of a subset of data about which people express their preference, by a process that is not random sampling, and (2) an iterative learning process in which people\u2019s responses to the selected subset are used to train the algorithm for subsequent iterations. The data used to train and optimize performance of these systems are based on human actions. Thus, data that are observed and omitted are not randomly selected, but are the consequences of people\u2019s choices. Recommendation systems suggest items predicted to be of interest to a user (e.g. movies, books, news) based on their user profile [70, 66, 41]. The prediction can be based on people\u2019s explicit (e.g. ratings) or implicit (e.g. their browsing or purchase history) data [60, 36, 37, 105], or even query patterns [102]. Research into human choice suggests that both explicit and implicit choices systematically vary based on context, especially the other options that are present when choosing [24, 97, 53].\nIn addition to the simple effects of the interaction between algorithms\u2019 recommendations and people\u2019s choices, people may reason about the processes that underlie the algorithms. Research in cognitive science has shown that people reason about evidence selected by other people. In [87], a computational framework was proposed for modeling how people\u2019s inferences may change as a consequence of reasoning about why data were selected. This framework has been formalized in learning from helpful and knowledgeable teachers [86, 11, 15, 88], deceptive informants [99], and epistemic trust [85, 28, 44]. People\u2019s reasoning about the intentional nature of the algorithms may exacerbate the effects of cyclic interaction between the algorithms\u2019 recommendations and people\u2019s choices.\nWe propose a framework for investigating the implications of interactions between human and algorithms, that draws on diverse literature to provide algorithmic, mathematical, computational, and behavioral tools for investigating human-algorithm interaction. Our approach draws on foundational algorithms for selecting and filtering of data from computer science, while also adapting mathematical methods from the study of cultural evolution [30, 39, 10] to formalize the implications of iterative interactions.\nKey to our approach is the focus on the sources and consequences of bias in data collected \u201cin the wild\u201d. The two primary sources of bias are from algorithms and from humans.\nAlgorithms, such as recommender systems, necessarily filter information with the goal of presenting humans with typically the most preferred content. Then, based on the labels provided by people, learning algorithms are trained to optimize future recommendations. This framework differs from standard learning theory in that the training data are not randomly sampled, which calls into question any guarantees about learning from such data. The second source of bias is people. In addition to receiving filtered information optimized to their preferences, people are also not required to provide labels for any of the presented data. Moreover, people\u2019s choices are highly non-random, and may reflect not only their opinions about the presented content, but also inferences about why the content was presented. Finally, bias introduced into the data at any point may be magnified by retraining of models and associated implications for recommendations, yielding algorithms whose performance is at variance with theoretical expectations. We argue that either of the individual sources of bias is in principle sufficient to yield instability, and that this suggests the need for new theories and methods for understanding performance of such systems in terms of human-algorithm interactions. We propose to characterize the conditions under which we would expect these to lead to systematic bias in the selection of information by algorithms, and identify conditions under which we can \u201cundo\u201d the effects of these biases to obtain accurate estimates from biased data. We expect the results to contribute insights back to the fundamental psychology of human reasoning, choice and learning and the fundamental computer science of learning, recommendation and information filtering."}, {"heading": "2. PRELIMINARY ANALYSIS", "text": ""}, {"heading": "2.1 Markov Chain Iterated Learning Analysis of Human-Algorithm Interaction", "text": "In order to capture the iterative interaction between people and machine learning algorithms \u201cin the wild\u201d, we could look into formal and empirical frameworks that have been developed in the behavioral sciences for analyzing the asymptotic effects of iterative interactions. For instance, we could consider the evolution of algorithms as a special case of cultural evolution of the sort observed in human language [38] and human knowledge more broadly [96, 10]. For this purpose, a formal framework is needed for analyzing the effects of local decisions on long-run behavior. One way to do this is using Markov chains to model iterative interactions with transmission between adjacent iterations as was done in [30]. While previous work concentrated on human behavior and learning, our focus here is on algorithm behavior and learning, namely in terms of the choice of data to present to people and the updated behavior in response to people\u2019s observed actions. More specifically, in the short term, we seek to identify the conditions under which we would expect algorithms\u2019 behavior to converge to more or less effective performance in the long run. In the longer term, we seek to understand and devise mechanisms that can compensate for these biases to ensure good performance.\nIn our preliminary research, we start with simple supervised machine learning where the goal is to learn to predict a discrete class label. Research on simple classifiers has historically paved the road for most formal analysis in machine learning and data mining, and had a significant impact on\nboth information retrieval [93] as well as recommender systems [9]. It also provides a point of contact with the psychology of category learning (which we will exploit in future experiments).\n2.1.1 Iterated learning with filter-bias dependency In the following, We extend the Markov Chain-based iter-\nated learning framework to provide a framework to analyze the evolution of the learned hypotheses while taking into account interactions between the user and the algorithm. One major extension from the original framework (see Fig 1(a)) is that we will explicitly take into account the dependency between the current hypothesis learned by the algorithm (learner) and the next input supplied by the human. This is because, in each iteration, the model or hypothesis that is learned by the algorithm can be considered to act as a filter or gateway to the types of data that will later be seen by the user. This modification of the original graphical model will thus allow a dependence between the current hypotheses h and the next inputs x (see Fig 1(b)).\nThe extent of the departure that we propose from a conventional machine learning framework toward a human - machine learning framework, can be measured by the contrast between the evolution of iterated learning without and with the added dependency. Without the dependency, the algorithm at step n+ 1 sees input xn+1 which is generated from a distribution p(x) that is independent of all other variables. Represent this independence with new notation q(x) (q instead of p), where q(x) represents an unbiased sample from the world, rather than a selection made by the algorithm. With the dependency, the algorithm at iteration n+1 sees input xn+1 which is generated from a mixture between the objective distribution q(x) and another distribution that captures the dependency upon the previous hypothesis hn which biases the future inputs seen by the user,\np(xn|hn) = (1\u2212 )pseen(xn|hn) + q(xn). In the case of a rating based recommender or an optimal probabilistic information filter [73], the probability of selecting the data is related to its rank. For a rating based recommender, the rank is based on the predicted rating, and for an optimal probabilistic information filter, the rank is based on the probability of relevance [73]. In each case, the selection of x is based on whether it is likely to be highly rated or relevant (i.e. its corresponding y value), given h. Assume that y = 1 denotes the relevant class (0 otherwise). If x is chosen based on the probability of relevance, p(yn = 1|xn, hn), then\npseen(xn|hn) = p(yn = 1|xn, hn)\u2211 xi p(yi = 1|xi, hn) . (1)\nthe selection of inputs depends on the hypothesis, p(x|hn) 6= p(x), and therefore information is not unbiased, p(x|hn) 6= q(x). The transition probabilities take into account (1), and will be\np(hn+1|hn) = \u2211 x\u2208X \u2211 y\u2208Y p(hn+1|x,y)p(y|x, hn)pseen(x|hn).\nThis can be used to derive the asymptotic behavior of the Markov chain with transition matrix T (hn+1, hn) = p(hn+1|hn),\np(hn+1) = p(hn+1) + (1\u2212 )Tbias (2)\nwhere,\nTbias = [\u2211 x\u2208X \u2211 y\u2208Y p(hn+1|x,y) \u2211 hn\u2208H p(y|x, hn)pseen(x|hn) ] p(hn). (3) Thus, iterated learning with a filter bias converges to a mixture of the prior and the bias induced by filtering. To illustrate the effects of the filter bias, we can analyze a simple and most extreme case where the filtering algorithm shows only the most relevant data in the next iteration (e.g. top-1 recommender). Hence\nxtop = arg max x (p(y|x, h)) , (4)\npseen(xn|hn) = { 1 for x = xtop = arg maxx (p(y = 1|x, h)) 0 otherwise,\nTbias = [\u2211 x\u2208X \u2211 y\u2208Y ( p(y|x, hn+1)p(hn+1) p(y|x) ) \u2211 hn\u2208H p(y|xtopn , hn) ] p(hn).\nThe fact that xtopn maximizes p(y|x, h) suggests limitations to the ability to learn from such data. Specifically, the selection of relevant data allows the possibility of learning that an input that is predicted to be relevant is not, but does not allow the possibility of learning that an input that is predicted to be irrelevant is actually relevant. In this sense, selection of evidence based on relevance is related to the confirmation bias in cognitive science, where learners have been observed to (arguably maladaptively) select data which they believe to be true (i.e. they fail to attempt to falsify their hypotheses) [40]. Put differently, recommendation algorithms may induce a blind spot where data that are potentially important for understanding relevance are never seen.\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n2.1.2 Iterated learning with active-bias dependency Active learning is a classical method in machine learning\n[20, 21, 83, 18, 14], used to reduce the number of labeled samples required for learning and thus accelerate learning versus training sample addition. Starting with a seed set of labeled instances, typically, future training inputs are selected and added to the training data based on hypotheses to improve learning. Consider the case of one classical approach in active learning [83], where data are selected to be presented to the user for labeling based on the uncertainty portended by its prediction using the current algorithm\u2019s hypothesis,\npactive(x|h) \u221d 1\u2212 p(y\u0302|x, h). (5)\nwhere y\u0302 = arg maxy (p(y|x, h)). That is, x values are selected to be least certain about y\u0302, the predicted y.\nConsidering a simplified algorithm where only the very best data are selected, we can investigate the limiting behavior of an algorithm with active learning bias. Assuming a mixture of random sampling and active learning, we obtain:\nxact = arg max x (1\u2212 p(y\u0302|x, h)) ,\np(hn+1) = p(hn+1) + (1\u2212 )Tactive, (6)\nTactive = [\u2211 x\u2208X \u2211 y\u2208Y p(hn+1|x,y) \u2211 hn\u2208H p(y|xactn , hn) ] p(hn).\n(7) The limiting behavior depends on the active learning bias, Tactive. When the active-bias algorithm is certain about the rating or relevance of an item, it will never select it. In contrast, the filtering algorithm is almost certain to pick items that it knows are relevant. Thus, the goals of active learning and filtering are in opposition; filtering tends to select items for which the prediction is certain (to be highly rated or relevant), whereas active learning selects items for which prediction is uncertain.\nThis is, of course, consistent with the different goals of recommendation and active learning. The analysis illustrates how the long-run implications of these different biases may be analyzed: By deriving the transition matrices implied by iterated application of data selection biases, we can see that both active learning and filtering have different goals, but focus on an ever more extreme (and therefore not representative) subset of data. Similar methods can be applied to more nuanced and interesting biases to shed light on the consequences of iterative interactions on the data."}, {"heading": "2.2 Iterated learning with human action bias", "text": "The above analysis assumes that people\u2019s response is always observed. In the following, we extend our analysis to the more realistic case where users have a choice of whether to act or not on a given input.\nAssume that people have some target hypothesis, h\u2217, which represents optimal performance for the algorithm. Data are composed of an input provided by the algorithm, x, an output, y, and an action, a. The indicator variable a takes a value of 1 when people have provided a response, and a value of 0 when people have not. When the value of y is not observed, it is notated as y = null. These form triples d = (x,y,a) = {(x1, y1, a1), ..., (xn, yn, an)}. The basic inference problem, from one iteration to the next, is then,\np(ht|d) \u221d p(d|ht\u22121, h\u2217)p(ht\u22121),\np(ht|d) \u221d p(y|x,a, h\u2217)p(a|y\u2217,x, h\u2217)p(x|ht\u22121)p(ht\u22121), (8)\nwhere y\u2217 represents the output that would be observed, if an action were taken. The main change is in people\u2019s choice of whether to respond, p(a|y\u2217,x, h\u2217). A missing at random assumption implies that p(a|y\u2217,x, h\u2217) does not depend on x, y\u2217, or h\u2217, thus p(a|y,x, h\u2217) = p(a). If variables are missing due to a person\u2019s choice, the probability of a missing value almost certainly depends on x, y\u2217, and/or h\u2217. We can formalize this choice using Luce choice [48], a special case of softmax [94], 1\np(a = 1|y\u2217,x, h\u2217) = U(a = 1|y \u2217,x, h\u2217)\nU(a = 0|y\u2217,x, h\u2217) + U(a = 1|y\u2217,x, h\u2217) ,\n(9)\n1Both softmax and Luce choice have known issues for modeling human choice [24, 71].\nwhere the choice of whether to act depends on the relative utility of acting as opposed to not acting. For example, if it is especially effortful to act, then people will be biased against acting. Alternatively, the utility of acting may depend on the value of y\u2217. For example, it may be that there is greater perceived utility in acting when the value of y\u2217 is very low, as in the case of an angry customer or disappointed user.\nIn principle, one might think that this is related to the problem of dealing with missing data that is common in statistics [76]. Indeed, in our analyses, we showed one special case that reduces to the missing at random typically assumed in statistical applications [76]. However, the framework proposed here is in fact more general; it proposes a theory of why data are missing, and formalizes the problem as one of understanding human behavior [87, 84, 27]."}, {"heading": "2.3 A Blind Spot to Learning and to Human Exploration", "text": "In the following, we present formal definitions that allow quantifying the extent and influence of interaction bias on humans and algorithms. We start with defining the concept of blind spot relative to a human interacting with an algorithm. \u03b4Hb \u2014 Human Blind Spot: This is the set of data items from a universe of existing items or data records, D, available to a relevance filter algorithm, for which the probability of being seen by the human interacting with the algorithm that has so far learned hypothesis h, is less than or equal to \u03b4Hb ,\nDB\u03b4H b = {x \u2208 D | pseen(x|h) \u2264 \u03b4Hb }. (10)\nAnalogous concepts and metrics can be defined from the perspective of the algorithm instead of the human, by replacing the probability that an item is seen or discoverable by the human, by the probability that it is observed, particularly along with a relevance label, by the algorithm. \u03b4Ab \u2014 Algorithm Blind Spot: The set of data available to a relevance filter algorithm, for which the probability of being seen along with a label provided by a human, by the algorithm that has so far learned hypothesis h, while interacting with that human, is less than or equal to \u03b4Ab ,\nDB\u03b4A b = {x \u2208 D | p(a = 1|y\u2217,x, h\u2217) \u2264 \u03b4Ab }. (11)\nDifferent learning biases may lead to different levels of blind spot prevalence relative to humans or to algorithms, as can be quantified below.\nBlind Spot Prevalence: is defined as the proportion of data in the blind spot, relative to the human:\n\u03c1Hb = \u2223\u2223\u2223DB\u03b4H\nb \u2223\u2223\u2223 / |D| , (12) or relative to the algorithm:\n\u03c1Ab = \u2223\u2223\u2223DB\u03b4A\nb \u2223\u2223\u2223 / |D| . (13) Metrics associated with the blind spot generated by a particular learning algorithm and bias generated, can help track the effect of human-algorithm interaction with more iterations under various conditions of data dependency, data selection, type of relevance filter algorithms, type of human choice of action, different initialization bias, etc.\n2.4 Undoing the effects of bias\nWe propose two possible approaches for undoing bias: Antidotes and Reactive learning. An antidote mends the bias after it has occurred, i.e. post-learning, for instance by adding tolerance to relevance boundaries. On the other hand, reactive learning is an extension of active learning, where learning is altered by reacting to the human or algorithm bias-induced selection strategies by intervening within the iterated learning process.\n2.4.1 Antidotes There are several ways we can pursue an antidote; for ex-\nample, by unbiasing the final predicted outputs or by using ensemble-based active learning such as [56]. Unbiasing can be performed post-learning by a reverse-Rocchio approach which works in the opposite way to traditional Rocchio personalization [74]. Here, we use selected data to change the set of relevant and non relevant instances. The tuning of the constant multiplier weights in Rocchio can affect the final status of filtering and severity of blind spots (\u03b4b). Also, personalized ensembles may be learned, such that they operate with different blind spots or blind spot levels to allow fast recovery and adaptation in filtering strength. One method is to block the data, treating nearby items as having a common parameter, and modeling the data generation process as a sequential process, using the inferred models for each block. This would allow us to simulate data from the different blocks of the process.\n2.4.2 Reactive Learning Reactive learning can be achieved by incorporating an un-\nbiasing strategy in each iteration of learning. Reactive bias can span the entire range of selection mechanisms ranging from active learning to filter-bias and inverse-filter bias, including inverse sampling (note however, that existing methods like [98] do not assume iterated learning). Reactive learning can leverage using models of human behavior that can allow us to explore, by simulation, how combinations of the previously explored algorithms may or may not lead to blind spots and bias. Some alternative strategies, such as reverse filter-bias, can also be simulated using a model of human behavior developed for filtering. Un-biasing an iterated human-machine learning mechanism can be approached by equalizing the selection bias in active learning. One way this has been explored in semi-supervised learning, where the availability of labels can be biased, is by inverse sampling which multiplies the sampling probability by the reciprocal of the probability of labels given data [98, 17]. However, care must be taken not to adversely affect the intended benefits of personalized information filters and recommender systems. To help unbias filters, we can explore adapting (into reactive learning) Active Collaborative Filtering strategies, such as [12] and Uncertainty Sampling with Diversity Maximization (USDM) [100]."}, {"heading": "2.5 Comparison with existing work and limitations", "text": "Researchers have been aware that data, fed to filters such as recommender systems, is biased by the mechanism by which users rate items [34]. Viewing the learning resulting from the interaction between an algorithm and a human as a dynamic process instead of a process that works on one static batch of data is reminiscent of dynamic machine learning, but the latter is a completely different concept which\nis more related to a paradigm for learning models under an evolving or dynamic data input. The way we consider dynamics here, however, is different. In fact, our analysis is not situated within a learning paradigm that is intended to learn a final predictive model while coping with dynamic data. Rather, we are in the context of analyzing the emergence of biases and related phenomena such as human and algorithm blind spots, when the learning algorithm receives data from humans while these humans receive predictions from the algorithm in an iterated cycle. We are also interested in studying the impacts of these biases and related phenomena on human and algorithm learning during the process of online machine learning.\nWithin the context of online machine learning from human activity data, dynamic usage patterns were studied in [60] and dynamic recommender systems were studied within a stream data mining framework in [59]. In [77], a Swarm Intelligence-based recommender system, inspired by the collaborative behavior of bird flocks and called FlockRecom, generated recommendations by iteratively adjusting the position and speed of dynamic flocks of agents in a virtual space. Even with taking previous work, including all the aforementioned work into account, no prior work has studied human-algorithm interaction via iterated learning mechanisms. Even common benchmark data sets used in recommender systems are rife with biases. In fact, most past recommenders worked with or collected sparse rating data and none has considered iterated learning-induced biases, but rather only corrected for simple models of user, item, or time based biases [42]. The latter type of bias, time based recommendation bias [42], is not related to algorithm biases, but rather to general temporal trends of movie preferences that are decoupled from the machine learning algorithm itself. Experiments with different methods to select the items to be rated before any recommendations [69] showed different bias in initial ratings resulting from different methods. These item selection methods, which at the time, were limited to selecting items based on their distribution in the accumulated rating data so far, included popularity, random, entropy or personalized. Finally, the experiments simulating the various item selection methods started with a full rating matrix from other users, which is likely biased and could not capture biases resulting from iterated interaction between human and machine learning. In addition to these biases, previous conventional recommender systems do not record the full set of recommendations made in each iteration. This has consequently created a gap in the current public data sets that are available for benchmarking new algorithms. To fill the experimental benchmarking gap that limits using public data to study iterated human-algorithm biases, it is necessary to record each recommendation, user response, and the order, alongside past user history.\nOur work may seem related to various aspects of active learning [20, 21, 83, 18, 14], semi-supervised learning [57, 62, 19, 103, 104, 2], label sampling bias in semi-supervised learning [75], and missing data theory [76, 82]. One type of active learning, known as Proactive Learning [25] attaches a cost to every sample before asking for labels and assumes that different oracles have different reliability. However, none of these approaches perform a formal iterated learning analysis, nor an interdisciplinary study based on both human and machine learning, let alone behavioral experiments which we plan to undertake in our ongoing work. In our research so\nfar, we have made formal preliminary analyses and simulations that already illustrate the differences between some of these related concepts and our questions. Specifically, none of the previous research has studied the iterated humanalgorithm interaction as we have proposed, through iterated learning between algorithms and humans for the special case of filtering models, whether they be content-based or collaborative. For instance some work tried to study the effect of missing data in CF [49, 52]; however no prior studies exist using an iterated model or measuring the impact of a machine learning algorithm itself on future data. Instead, the data is assumed to be available as one frozen batch, then analysis is performed based on that image.\nOur notion of a blind spot is related to the concept of a filter bubble. Filter bubbles have been a subject of attention lately [64, 13, 46], including work attempting to reverse or ameliorate such effects [55, 58]. Our formal definition of blind spot paves the way to formalize the definition of filter bubbles. Interestingly, filter bubbles can be thought of as the opposite of blind spots, where the information is nearly certain to be seen within some small number of recommendations. This is consistent with the idea that a filter bubble prevents mixing of ideas, and suggests that our Markov chain-based analyses may provide tools to analyze the implications of different recommendations on filter bubbles. Our approach differs in that we focus on developing a framework for understanding the emergence of biases and filter bubbles, dynamic changes, and long run behavior of algorithms. Beyond mending filter bubbles, we bring forward a combination of mathematical, algorithmic, computational and behavioral perspectives that promises to yield insight into when and why blind spots and filter bubbles emerge, and how different algorithms are likely to behave over iterations.\nResearch in psychology has investigated category learning [14, 90, 68, 54, 4], choice behavior [95, 48, 101, 97, 92], active learning [14, 6, 4, 5, 51], and social learning [86, 11, 15, 88]. Perhaps the nearest neighbor is the literature on the implications of other people for learning. This literature has shown that people reason about why other people select data, and use people\u2019s selection of data to update their beliefs about the data selection process [85, 28, 44]. Our approach builds from insights drawn from each of these works, and thus embodies an extension of traditional work in psychology to the theoretically interesting and practically important domain of human-algorithm interaction."}, {"heading": "3. CONCLUSION AND FUTURE OUTLOOK", "text": "There is a long tradition in machine learning of algorithms whose performance is guaranteed in the context of unbiased data. Similarly, there is a long tradition in the psychology of human learning of treating learning as inference from unbiased data. Increasingly, people and algorithms are engaged in interactive processes wherein neither the humans nor the algorithms receive unbiased data. What are the long-run consequences of these iterative interactions on algorithms\u2019 performance? On human knowledge? The unique contributions of this preliminary research arise from bringing together mathematical, algorithmic, behavioral, and computational perspectives from computer science and psychology to understand how algorithm performance and human behavior depend on one an other, and how those dependencies affect long run performance. Our ongoing work will pave the\nroad for a framework on which the study of human-algorithm interaction may progress."}, {"heading": "4. REFERENCES", "text": "[1] O. Abdollahi, B. ; Nasraoui. A cross-modal warm-up\nsolution for the cold-start problem in collaborative filtering recommender systems. In Proceedings of the ACM conference on Web science, pages 257\u2013258, 2014.\n[2] A. Abdullin and O. Nasraoui. A semi-supervised learning framework to cluster mixed data types. In KDIR, pages 45\u201354. Citeseer, 2012.\n[3] M. U. M. M. U. . T. A. Adomavicius, G. ; Carlson Sch. of Manage. Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions. IEEE Transactions on Knowledge and Data Engineering, 17(6):734 \u2013 749, 2005.\n[4] F. G. Ashby, L. A. Alfonso-Reese, and E. M. Waldron. a neuropsychological theory of multiple systems in category learning. Psychological Review, 105:442\u2013481, 1998.\n[5] F. G. Ashby, W. T. Maddox, and C. J. Bohil. Observational versus feedback training in rule-based and information-integration category learning. Memory & Cognition, 30:666\u2013677, 2002.\n[6] F. G. Ashby, S. Queller, and P. T. Berretty. On the dominance of unidimensional rules in unsupervised categorization. Perception and Psychophysics, 61:1178\u20131199, 1999.\n[7] R. Baeza-Yates and B. Ribeiro-Neto. Modern information retrieval. ACM Press, 463, 1999.\n[8] M. Balabanovi and Y. Shoham. Fab: content-based, collaborative recommendation. Communications of the ACM, 40(3):66\u201372, 1997.\n[9] C. Basu, H. Hirsh, W. Cohen, et al. Recommendation as classification: Using social and content-based information in recommendation. In AAAI/IAAI, pages 714\u2013720, 1998.\n[10] A. Beppu and T. L. Griffiths. Iterated learning and the cultural ratchet. In Proceedings of the 31st Annual Conference of the Cognitive Science Society, 2009.\n[11] E. B. Bonawitz, P. Shafto, H. Gweon, N. D. Goodman, E. Spelke, and L. Schulz. The double-edged sword of pedagogy: Teaching limits children\u2019s spontaneous exploration and discovery. Cognition, 120:322\u2013330, 2011.\n[12] C. Boutilier, R. S. Zemel, and B. Marlin. Active collaborative filtering. In Proceedings of the Nineteenth conference on Uncertainty in Artificial Intelligence, pages 98\u2013106. Morgan Kaufmann Publishers Inc., 2002.\n[13] S. D. A. Brossard, D. Science, new media, and the public. Science, 339(6115):40\u201341, 2013.\n[14] J. R. Bruner, J. J. Goodnow, and G. A. Austin. A study of thinking. Wiley, New York, 1956.\n[15] D. Buchbaum, T. L. Griffiths, A. Gopnik, and P. Shafto. Children\u2019s imitation of causal action sequences is influenced by statistical and pedagogical evidence. Cognition, 120:331\u2013340, 2011.\n[16] C. Buckley, G. Salton, J. Allan, and A. Singhal. Automatic query expansion using smart: Trec 3. NIST special publication sp, pages 69\u201369, 1995.\n[17] S. M. Cacoullos, T. An inverse sampling procedure for selecting the most probable event in a multinomial distribution. Multivariate Analysis, pages 423\u2013455, 1966.\n[18] V. Castelli and T. M. Cover. On the exponential value of labeled samples. Pattern Recognition Letters, 16(1):105\u2013111, 1995.\n[19] O. Chapelle, B. Scho\u0308lkopf, A. Zien, et al. Semi-supervised learning. 2006.\n[20] D. Cohn, L. Atlas, and R. Ladner. Improving generalization with active learning. Machine Learning, 15(2):201\u2013221, 1994.\n[21] D. A. Cohn, Z. Ghahramani, and M. I. Jordan. Active learning with statistical models. Journal of artificial intelligence research, 1996.\n[22] T. Cover and P. Hart. Nearest neighbor pattern classification. Information Theory, IEEE Transactions on, 13(1):21\u201327, January 1967.\n[23] S. T. Croft B., Metzler D. Information retrieval in practice. Pearson Education, 2009.\n[24] G. Debreu. Review of R. D. Luce, individual choice behavior: A theoretical analysis. American Economic Review, 50:186\u2013188, 1960.\n[25] P. Donmez and J. G. Carbonell. Proactive learning: cost-sensitive active learning with multiple imperfect oracles. In Proceedings of the 17th ACM conference on Information and knowledge management, pages 619\u2013628. ACM, 2008.\n[26] S. A. Dudani. The distance-weighted k-nearest-neighbor rule. IEEE Transactions on Systems, Man and Cybernetics, SMC-6(4):325\u2013327, April 1976.\n[27] K. Durkin, L. R. Calgar, E. Bonawitz, and P. Shafto. Explaining choice behavior: The intentional selection assumption. In Proceedings of the Thirty-Seventh Annual Conference of the Cognitive Science Society, 2015.\n[28] B. S. Eaves and P. Shafto. Unifying pedagogical reasoning and epistemic trust. In F. Xu and T. Kushnir, editors, Advances in Child Development and Behavior, Volume, 43, pages 295\u2013319. Elsevier, San Diego, 2012.\n[29] D. Goldberg, D. Nichols, B. M. Oki, and D. Terry. Using collaborative filtering to weave an information tapestry. Commun. ACM, 35(12):61\u201370, Dec. 1992.\n[30] T. L. Griffiths and M. L. Kalish. A Bayesian view of language evolution by iterated learning. Cognitive Science, 31:441\u2013480, 2007.\n[31] T. L. Griffiths and M. Steyvers. Finding scientific topics. Proceedings of the National Academy of Sciences, 101:5228\u20135235, 2004.\n[32] T. L. Griffiths, J. B. Tenenbaum, and M. Steyvers. Topics in semantic representation. Psychological Review, 114:2007, 2007.\n[33] S. B. Hanani, U. and P. Shoval. Information filtering: Overview of issues, research and systems. User Modeling and User-Adapted Interaction, 11(3):203\u2013259, August 2001.\n[34] J. L. Herlocker, J. A. Konstan, L. G. Terveen, and J. T. Riedl. Evaluating collaborative filtering recommender systems. ACM Transactions on Information Systems (TOIS), 22(1):5\u201353, 2004.\n[35] H. V. Jones, Ed. K.P. Artificial intelligence: what can it offer information retrieval. Proceedings of Informatics, 3:3\u201311, 1978.\n[36] M. K. Khribi, M. Jemni, and O. Nasraoui. Automatic recommendations for e-learning personalization based on web usage mining techniques and information retrieval. In Advanced Learning Technologies, 2008. ICALT\u201908. Eighth IEEE International Conference on, pages 241\u2013245. IEEE, 2008.\n[37] M. K. Khribi, M. Jemni, and O. Nasraoui. Automatic personalization in e-learning based on recommendation systems: An overview. S. Graf, F. Lin, Kinshuk & R. McGreal (Eds.), Intelligent and adaptive learning systems: Technology enhanced support for learners and teachers, pages 19\u201333, 2012.\n[38] S. Kirby. Spontaneous evolution of linguistic structure: An iterated learning model of the emergence of regularity and irregularity. IEEE Journal of Evolutionary Computation, 5:102\u2013110, 2001.\n[39] S. Kirby, M. Dowman, and T. L. Griffiths. Innateness and culture in the evolution of language. Proceedings of the National Academy of Sciences, 104:5241\u20135245, 2007.\n[40] J. Klayman and Y. Ha. Confirmation, disconfirmation, and information in hypothesis testing. Psychological Review, 94:211\u2013228, 1987.\n[41] J. A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon, and J. Riedl. Grouplens: applying collaborative filtering to usenet news. Communications of the ACM, 40(3):77\u201387, 1997.\n[42] B. R. Koren, Y. and C. Volinsky. Matrix factorization techniques for recommender systems. Computer, 42(8):30\u201337, August 2009.\n[43] J. K. Kruschke. Alcove: An exemplar-based connectionist model of category learning. Psychological Review, 99:22\u201344, 1992.\n[44] A. R. Landrum, B. S. Eaves, and P. Shafto. Trusting to learn and learning to trust: A theoretical framework. Trends in Cognitive Sciences, 19:2015, 2015.\n[45] H. S. Lee, D. D. & Seung. Learning the parts of objects by non-negative matrix factorization. Nature, 401(6755):788A\u0303s\u0301791, 1999.\n[46] Q. V. Liao and W.-T. Fu. Beyond the filter bubble: interactive effects of perceived threat and topic involvement on selective exposure to information. In Proceedings of the ACM SIGCHI conference on Human Factors in Computing Systems, pages 2359\u20132368, 2013.\n[47] S. B. Y. J. Linden, G. Amazon. com recommendations: Item-to-item collaborative filtering. Internet Computing, IEEE, 7(1):76\u201380, 2003.\n[48] R. D. Luce. Individual choice behavior. John Wiley, New York, 1959.\n[49] H. Ma, I. King, and M. R. Lyu. Effective missing data prediction for collaborative filtering. In\nProceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval, pages 39\u201346. ACM, 2007.\n[50] P. Maes et al. Agents that reduce work and information overload. Communications of the ACM, 37(7):30\u201340, 1994.\n[51] D. Markant and T. Gureckis. Is it better to select or to receive? Learning via active and passive hypothesis testing. Journal of Experimental Psychology: General, 143(1):94\u2013122, 2014.\n[52] B. M. Marlin and R. S. Zemel. Collaborative prediction and ranking with non-random missing data. In Proceedings of the third ACM conference on Recommender systems, pages 5\u201312. ACM, 2009.\n[53] D. McFadden. Quantal choice analysis: A survey. Annals of Economic and Social Measurement, 5:363\u2013390, 1977.\n[54] D. L. Medin and M. M. Schaffer. Context theory of classification learning. Psychological Review, 100:254\u2013278, 1978.\n[55] C. M. Melo, R. The design of horacle: inducing serendipity on the web. xCoAx, 2013.\n[56] M. R. J. Melville, P. Diverse ensembles for active learning. Proceedings of the Twenty-first International Conference on Machine Learning, page 74, 2004.\n[57] T. M. Mitchell. Learning from labeled and unlabeled data. Machine learning, 10:701, 2006.\n[58] R. P. Munson, S. A. Presenting diverse political opinions: how and how much. Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pages 1457\u20131466, 2010.\n[59] O. Nasraoui, J. Cerwinske, C. Rojas, and F. A. Gonza\u0301lez. Performance of recommendation systems in dynamic streaming environments. In SDM, pages 569\u2013574. SIAM, 2007.\n[60] O. Nasraoui, M. Soliman, E. Saka, A. Badia, and R. Germain. A web usage mining framework for mining evolving user profiles in dynamic web sites. Knowledge and Data Engineering, IEEE Transactions on, 20(2):202\u2013215, 2008.\n[61] P. M. Nasraoui, O. Complete this puzzle: A connectionist approach to accurate web recommendations based on a committee of predictors. Advances in Web Mining and Web Usage Analysis, 3932:56\u201372, 2006.\n[62] K. Nigam, A. McCallum, and T. Mitchell. Semi-supervised text classification using em. Semi-Supervised Learning, pages 33\u201356, 2006.\n[63] R. M. Nosofsky. Choice, similarity, and the context theory of classification. Journal of Experimental Psychology: Learning, memory, and cognition, 10:104\u2013114, 1984.\n[64] E. Pariser. The filter bubble: What the internet is hiding from you. Penguin Press, 2011.\n[65] B. D. Pazzani, M. J. Adaptive news access. The Adaptive Web, pages 550\u2013570, 2007.\n[66] D. Pazzani, M. & Billsus. Learning and revising user profiles: The identification of interesting web sites. Machine Learning, 27(3):313\u2013331, 1997.\n[67] M. J. Pazzani and D. Billsus. Content-based\nrecommendation systems. In The adaptive web, pages 325\u2013341. Springer, 2007.\n[68] M. I. Posner and S. W. Keele. On the genesis of abstract ideas. Journal of Experimental Psychology, 77:241\u2013248, 1968.\n[69] A. M. Rashid, I. Albert, D. Cosley, S. K. Lam, S. M. McNee, J. A. Konstan, and J. Riedl. Getting to know you: learning new user preferences in recommender systems. In Proceedings of the 7th international conference on Intelligent user interfaces, pages 127\u2013134. ACM, 2002.\n[70] P. Resnick and H. R. Varian. Recommender systems. Commun. ACM, 40(3):56\u201358, Mar. 1997.\n[71] J. Rieskamp, J. R. Busemeyer, and B. A. Mellers. Extending the bounds of rationality: Evidence and theories of preferential choice. Journalof Economic Literature, XLIV, pages 631\u2013661, 2006.\n[72] C. J. V. Rijsbergen. Information Retrieval. Butterworth-Heinemann, Newton, MA, USA, 2nd edition, 1979.\n[73] S. Robertson. The probability ranking principle in ir. Journal of Documentation, 33(4):294\u2013304, 1977.\n[74] J. J. Rocchio. Relevance feedback in information retrieval. In G. Salton, editor, The SMART Retrieval System: Experiments in Automatic Document Processing, Prentice-Hall Series in Automatic Computation, chapter 14, pages 313\u2013323. Prentice-Hall, Englewood Cliffs NJ, 1971.\n[75] S. Rosset, J. Zhu, H. Zou, and T. J. Hastie. A method for inferring label sampling mechanisms in semi-supervised learning. In Advances in neural information processing systems, pages 1161\u20131168, 2004.\n[76] D. B. Rubin. Inference and missing data. Biometrika, 63(3):581\u2013592, 1976.\n[77] E. Saka and O. Nasraoui. A recommender system based on the collaborative behavior of bird flocks. In Collaborative Computing: Networking, Applications and Worksharing (CollaborateCom), 2010 6th International Conference on, pages 1\u201310. IEEE, 2010.\n[78] A. Salakhutdinov, R. & Mnih. Probabilistic matrix factorization. Advances in Neural Information Processing Systems, 20:1257A\u0303s\u03011264, 2008.\n[79] G. Salton, E. A. Fox, and H. Wu. Extended boolean information retrieval. Communications of the ACM, 26(11):1022\u20131036, 1983.\n[80] K. G. K. J. R. J. Sarwar, B. Item-based collaborative filtering recommendation algorithms. Proceedings of the 10th international conference on World Wide Web, pages 285\u2013295, May 2001.\n[81] K. J. R. J. Schafer, J. B. Recommender systems in e-commerce. pages 158\u2013166, 1999.\n[82] J. Scheffer. Dealing with missing data. Research Letters in the Information and Mathematical Sciences, 3:153\u2013160, 2002.\n[83] B. Settles. Active learning literature survey. Computer Sciences Technical Report, (1648), January 2010. University of Wisconsin - Madison.\n[84] P. Shafto and E. Bonawitz. Choice from among intentionally selected options. In B. Ross, editor, The psychology of learning and motivation, Volume 63.\nElsevier, San Diego, 2015.\n[85] P. Shafto, B. Eaves, D. J. Navarro, and A. Perfors. Epistemic trust: Modeling children\u2019s reasoning about others\u2019 knowledge and intent. Developmental Science, 15:436\u2013447, 2012.\n[86] P. Shafto and N. D. Goodman. Teaching games: Statistical sampling assumptions for pedagogical situations. In Proceedings of the 30th annual conference of the Cognitive Science Society, 2008.\n[87] P. Shafto, N. D. Goodman, and M. C. Frank. Learning from others: The consequences of psychological reasoning for human learning. Perspectives on Psychological Science, 7:341\u2013351, 2012.\n[88] P. Shafto, N. D. Goodman, and T. L. Griffiths. A rational account of pedagogical reasoning: Teaching by, and learning from, examples. Cognitive Psychology, 71:55\u201389, 2014.\n[89] U. Shardanand and P. Maes. Social information filtering: algorithms for automating \u201cword of mouth\u201d. In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 210\u2013217. ACM Press/Addison-Wesley Publishing Co., 1995.\n[90] R. N. Shepard, C. I. Hovland, and H. M. Jenkins. Learning and memorization of classifications. Psychological Monographs, 75, 1961.\n[91] B. Sheth and P. Maes. Evolving agents for personalized information filtering. In Artificial Intelligence for Applications, 1993. Proceedings., Ninth Conference on, pages 345\u2013352. IEEE, 1993.\n[92] I. Simonson and A. Tversky. Choice in context: Tradeoff contrast and extremeness aversion. Journal of Marketing Research, 29:281\u2013295, 1992.\n[93] K. Sparck Jones. Some thoughts on classification for retrieval. Journal of Documentation, 26(2):89\u2013101, 1970.\n[94] R. S. Sutton and A. G. Barto. Reinforcement learning: An introduction. MIT Press, Cambridge, MA, 1998.\n[95] L. L. Thurstone. A law of comparative judgment. Psychological Review, 34(4):273\u2013286, 1927.\n[96] M. Tomasello. The Cultural Origins of Human Cognition. Harvard University Press, 1999.\n[97] A. Tversky. Elimination by aspects: A theory of choice. Psychological Review, 79:281\u2013299, 1972.\n[98] Y. Vardi. Empirical distributions in selection bias models. The Annals of Statistics, 13(1):178\u2013203, 03 1985.\n[99] R. Warner, T. Stoess, and P. Shafto. Reasoning about teaching and misleading. In Proceedings of the 33rd annual conference of the Cognitive Science Society, 2011.\n[100] Y. Yang, Z. Ma, F. Nie, X. Chang, and A. G. Hauptmann. Multi-class active learning by uncertainty sampling with diversity maximization. International Journal of Computer Vision.\n[101] J. I. Yellot. The relationship between luce\u2019s choice axiom, thurstone\u2019s theory of comparative judgement, and the double exponential distribution. Journal of Mathematical Psychology, 15:109\u2013144, 1977.\n[102] Z. Zhang and O. Nasraoui. Mining search engine\nquery logs for query recommendation. In Proceedings of the 15th international conference on World Wide Web, pages 1039\u20131040. ACM, 2006.\n[103] X. Zhu. Semi-supervised learning literature survey. Internationl Conference on Machine Learning, December 2007.\n[104] X. Zhu and A. B. Goldberg. Introduction to semi-supervised learning. Synthesis lectures on artificial intelligence and machine learning, 3(1):1\u2013130, 2009.\n[105] L. Zhuhadar and O. Nasraoui. A hybrid recommender system guided by semantic user profiles for search in the e-learning domain. Journal of Emerging Technologies in Web Intelligence, 2(4):272\u2013281, 2010."}], "references": [{"title": "B", "author": ["O. Abdollahi"], "venue": "; Nasraoui. A cross-modal warm-up solution for the cold-start problem in collaborative filtering recommender systems. In Proceedings of the ACM conference on Web science, pages 257\u2013258", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "A semi-supervised learning framework to cluster mixed data types", "author": ["A. Abdullin", "O. Nasraoui"], "venue": "KDIR, pages 45\u201354. Citeseer", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Sch. of Manage. Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions", "author": ["Carlson"], "venue": "IEEE Transactions on Knowledge and Data Engineering,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2005}, {"title": "a neuropsychological theory of multiple systems in category learning", "author": ["F.G. Ashby", "L.A. Alfonso-Reese", "E.M. Waldron"], "venue": "Psychological Review, 105:442\u2013481", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1998}, {"title": "Observational versus feedback training in rule-based and information-integration category learning", "author": ["F.G. Ashby", "W.T. Maddox", "C.J. Bohil"], "venue": "Memory & Cognition, 30:666\u2013677", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2002}, {"title": "On the dominance of unidimensional rules in unsupervised categorization", "author": ["F.G. Ashby", "S. Queller", "P.T. Berretty"], "venue": "Perception and Psychophysics, 61:1178\u20131199", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1999}, {"title": "Modern information retrieval", "author": ["R. Baeza-Yates", "B. Ribeiro-Neto"], "venue": "ACM Press, 463", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1999}, {"title": "Fab: content-based", "author": ["M. Balabanovi", "Y. Shoham"], "venue": "collaborative recommendation. Communications of the ACM, 40(3):66\u201372", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1997}, {"title": "et al", "author": ["C. Basu", "H. Hirsh", "W. Cohen"], "venue": "Recommendation as classification: Using social and content-based information in recommendation. In AAAI/IAAI, pages 714\u2013720", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1998}, {"title": "Iterated learning and the cultural ratchet", "author": ["A. Beppu", "T.L. Griffiths"], "venue": "Proceedings of the 31st Annual Conference of the Cognitive Science Society", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "The double-edged sword of pedagogy: Teaching limits children\u2019s spontaneous exploration and discovery", "author": ["E.B. Bonawitz", "P. Shafto", "H. Gweon", "N.D. Goodman", "E. Spelke", "L. Schulz"], "venue": "Cognition, 120:322\u2013330", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Active collaborative filtering", "author": ["C. Boutilier", "R.S. Zemel", "B. Marlin"], "venue": "Proceedings of the Nineteenth conference on Uncertainty in Artificial Intelligence, pages 98\u2013106. Morgan Kaufmann Publishers Inc.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2002}, {"title": "new media", "author": ["S.D.A. Brossard", "D. Science"], "venue": "and the public. Science, 339(6115):40\u201341", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "A study of thinking", "author": ["J.R. Bruner", "J.J. Goodnow", "G.A. Austin"], "venue": "Wiley, New York", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1956}, {"title": "Children\u2019s imitation of causal action sequences is influenced by statistical and pedagogical evidence", "author": ["D. Buchbaum", "T.L. Griffiths", "A. Gopnik", "P. Shafto"], "venue": "Cognition, 120:331\u2013340", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2011}, {"title": "Automatic query expansion using smart: Trec 3", "author": ["C. Buckley", "G. Salton", "J. Allan", "A. Singhal"], "venue": "NIST special publication sp, pages 69\u201369", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1995}, {"title": "T", "author": ["S.M. Cacoullos"], "venue": "An inverse sampling procedure for selecting the most probable event in a multinomial distribution. Multivariate Analysis, pages 423\u2013455", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1966}, {"title": "On the exponential value of labeled samples", "author": ["V. Castelli", "T.M. Cover"], "venue": "Pattern Recognition Letters, 16(1):105\u2013111", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1995}, {"title": "Improving generalization with active learning", "author": ["D. Cohn", "L. Atlas", "R. Ladner"], "venue": "Machine Learning, 15(2):201\u2013221", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1994}, {"title": "Active learning with statistical models", "author": ["D.A. Cohn", "Z. Ghahramani", "M.I. Jordan"], "venue": "Journal of artificial intelligence research", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1996}, {"title": "Nearest neighbor pattern classification", "author": ["T. Cover", "P. Hart"], "venue": "Information Theory, IEEE Transactions on,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1967}, {"title": "Information retrieval in practice", "author": ["B.S.T. Croft", "D. Metzler"], "venue": "Pearson Education,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "Review of R", "author": ["G. Debreu"], "venue": "D. Luce, individual choice behavior: A theoretical analysis. American Economic Review, 50:186\u2013188", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1960}, {"title": "Proactive learning: cost-sensitive active learning with multiple imperfect oracles", "author": ["P. Donmez", "J.G. Carbonell"], "venue": "Proceedings of the 17th ACM conference on Information and knowledge management, pages 619\u2013628. ACM", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2008}, {"title": "The distance-weighted k-nearest-neighbor rule", "author": ["S.A. Dudani"], "venue": "IEEE Transactions on Systems, Man and Cybernetics,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1976}, {"title": "Explaining choice behavior: The intentional selection assumption", "author": ["K. Durkin", "L.R. Calgar", "E. Bonawitz", "P. Shafto"], "venue": "Proceedings of the Thirty-Seventh Annual Conference of the Cognitive Science Society", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "Unifying pedagogical reasoning and epistemic trust", "author": ["B.S. Eaves", "P. Shafto"], "venue": "F. Xu and T. Kushnir, editors, Advances in Child Development and Behavior, Volume, 43, pages 295\u2013319. Elsevier, San Diego", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2012}, {"title": "Using collaborative filtering to weave an information tapestry", "author": ["D. Goldberg", "D. Nichols", "B.M. Oki", "D. Terry"], "venue": "Commun. ACM,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1992}, {"title": "A Bayesian view of language evolution by iterated learning", "author": ["T.L. Griffiths", "M.L. Kalish"], "venue": "Cognitive Science, 31:441\u2013480", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2007}, {"title": "Finding scientific topics", "author": ["T.L. Griffiths", "M. Steyvers"], "venue": "Proceedings of the National Academy of Sciences, 101:5228\u20135235", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2004}, {"title": "Topics in semantic representation", "author": ["T.L. Griffiths", "J.B. Tenenbaum", "M. Steyvers"], "venue": "Psychological Review, 114:2007", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2007}, {"title": "Information filtering: Overview of issues, research and systems", "author": ["U.S.B. Hanani", "P. Shoval"], "venue": "User Modeling and User-Adapted Interaction,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2001}, {"title": "Evaluating collaborative filtering recommender systems", "author": ["J.L. Herlocker", "J.A. Konstan", "L.G. Terveen", "J.T. Riedl"], "venue": "ACM Transactions on Information Systems (TOIS), 22(1):5\u201353", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2004}, {"title": "Ed", "author": ["H.V. Jones"], "venue": "K.P. Artificial intelligence: what can it offer information retrieval. Proceedings of Informatics, 3:3\u201311", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1978}, {"title": "Automatic recommendations for e-learning personalization based on web usage mining techniques and information retrieval", "author": ["M.K. Khribi", "M. Jemni", "O. Nasraoui"], "venue": "Advanced Learning Technologies, 2008. ICALT\u201908. Eighth IEEE International Conference on, pages 241\u2013245. IEEE", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2008}, {"title": "Automatic personalization in e-learning based on recommendation systems: An overview", "author": ["M.K. Khribi", "M. Jemni", "O. Nasraoui"], "venue": "S. Graf, F. Lin, Kinshuk & R. McGreal (Eds.), Intelligent and adaptive learning systems: Technology enhanced support for learners and teachers, pages 19\u201333", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2012}, {"title": "Spontaneous evolution of linguistic structure: An iterated learning model of the emergence of regularity and irregularity", "author": ["S. Kirby"], "venue": "IEEE Journal of Evolutionary Computation, 5:102\u2013110", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2001}, {"title": "Innateness and culture in the evolution of language", "author": ["S. Kirby", "M. Dowman", "T.L. Griffiths"], "venue": "Proceedings of the National Academy of Sciences, 104:5241\u20135245", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2007}, {"title": "Confirmation", "author": ["J. Klayman", "Y. Ha"], "venue": "disconfirmation, and information in hypothesis testing. Psychological Review, 94:211\u2013228", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1987}, {"title": "Grouplens: applying collaborative filtering to usenet news", "author": ["J.A. Konstan", "B.N. Miller", "D. Maltz", "J.L. Herlocker", "L.R. Gordon", "J. Riedl"], "venue": "Communications of the ACM, 40(3):77\u201387", "citeRegEx": "41", "shortCiteRegEx": null, "year": 1997}, {"title": "Matrix factorization techniques for recommender systems", "author": ["Y.B.R. Koren", "C. Volinsky"], "venue": null, "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2009}, {"title": "Alcove: An exemplar-based connectionist model of category learning", "author": ["J.K. Kruschke"], "venue": "Psychological Review, 99:22\u201344", "citeRegEx": "43", "shortCiteRegEx": null, "year": 1992}, {"title": "Trusting to learn and learning to trust: A theoretical framework", "author": ["A.R. Landrum", "B.S. Eaves", "P. Shafto"], "venue": "Trends in Cognitive Sciences, 19:2015", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2015}, {"title": "D", "author": ["H.S. Lee"], "venue": "D. & Seung. Learning the parts of objects by non-negative matrix factorization. Nature, 401(6755):788\u00c3\u015b791", "citeRegEx": "45", "shortCiteRegEx": null, "year": 1999}, {"title": "Beyond the filter bubble: interactive effects of perceived threat and topic involvement on selective exposure to information", "author": ["Q.V. Liao", "W.-T. Fu"], "venue": "Proceedings of the ACM SIGCHI conference on Human Factors in Computing Systems, pages 2359\u20132368", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2013}, {"title": "com recommendations: Item-to-item collaborative filtering", "author": ["S.B.Y.J. Linden", "G. Amazon"], "venue": "Internet Computing, IEEE, 7(1):76\u201380", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2003}, {"title": "Individual choice behavior", "author": ["R.D. Luce"], "venue": "John Wiley, New York", "citeRegEx": "48", "shortCiteRegEx": null, "year": 1959}, {"title": "Effective missing data prediction for collaborative filtering", "author": ["H. Ma", "I. King", "M.R. Lyu"], "venue": " Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval, pages 39\u201346. ACM", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2007}, {"title": "Agents that reduce work and information overload", "author": ["P. Maes"], "venue": "Communications of the ACM,", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 1994}, {"title": "Is it better to select or to receive? Learning via active and passive hypothesis testing", "author": ["D. Markant", "T. Gureckis"], "venue": "Journal of Experimental Psychology: General, 143(1):94\u2013122", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2014}, {"title": "Collaborative prediction and ranking with non-random missing data", "author": ["B.M. Marlin", "R.S. Zemel"], "venue": "Proceedings of the third ACM conference on Recommender systems, pages 5\u201312. ACM", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2009}, {"title": "Quantal choice analysis: A survey", "author": ["D. McFadden"], "venue": "Annals of Economic and Social Measurement, 5:363\u2013390", "citeRegEx": "53", "shortCiteRegEx": null, "year": 1977}, {"title": "Context theory of classification learning", "author": ["D.L. Medin", "M.M. Schaffer"], "venue": "Psychological Review, 100:254\u2013278", "citeRegEx": "54", "shortCiteRegEx": null, "year": 1978}, {"title": "R", "author": ["C.M. Melo"], "venue": "The design of horacle: inducing serendipity on the web. xCoAx", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2013}, {"title": "P", "author": ["M.R.J. Melville"], "venue": "Diverse ensembles for active learning. Proceedings of the Twenty-first International Conference on Machine Learning, page 74", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2004}, {"title": "Learning from labeled and unlabeled data", "author": ["T.M. Mitchell"], "venue": "Machine learning, 10:701", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2006}, {"title": "S", "author": ["R.P. Munson"], "venue": "A. Presenting diverse political opinions: how and how much. Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pages 1457\u20131466", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2010}, {"title": "Performance of recommendation systems in dynamic streaming environments", "author": ["O. Nasraoui", "J. Cerwinske", "C. Rojas", "F.A. Gonz\u00e1lez"], "venue": "SDM, pages 569\u2013574. SIAM", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2007}, {"title": "A web usage mining framework for mining evolving user profiles in dynamic web sites", "author": ["O. Nasraoui", "M. Soliman", "E. Saka", "A. Badia", "R. Germain"], "venue": "Knowledge and Data Engineering, IEEE Transactions on, 20(2):202\u2013215", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2008}, {"title": "O", "author": ["P.M. Nasraoui"], "venue": "Complete this puzzle: A connectionist approach to accurate web recommendations based on a committee of predictors. Advances in Web Mining and Web Usage Analysis, 3932:56\u201372", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2006}, {"title": "Semi-supervised text classification using em", "author": ["K. Nigam", "A. McCallum", "T. Mitchell"], "venue": "Semi-Supervised Learning, pages 33\u201356", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2006}, {"title": "Choice", "author": ["R.M. Nosofsky"], "venue": "similarity, and the context theory of classification. Journal of Experimental Psychology: Learning, memory, and cognition, 10:104\u2013114", "citeRegEx": "63", "shortCiteRegEx": null, "year": 1984}, {"title": "The filter bubble: What the internet is hiding from you", "author": ["E. Pariser"], "venue": "Penguin Press", "citeRegEx": "64", "shortCiteRegEx": null, "year": 2011}, {"title": "M", "author": ["B.D. Pazzani"], "venue": "J. Adaptive news access. The Adaptive Web, pages 550\u2013570", "citeRegEx": "65", "shortCiteRegEx": null, "year": 2007}, {"title": "M", "author": ["D. Pazzani"], "venue": "& Billsus. Learning and revising user profiles: The identification of interesting web sites. Machine Learning, 27(3):313\u2013331", "citeRegEx": "66", "shortCiteRegEx": null, "year": 1997}, {"title": "Content-based  recommendation systems", "author": ["M.J. Pazzani", "D. Billsus"], "venue": "The adaptive web, pages 325\u2013341. Springer", "citeRegEx": "67", "shortCiteRegEx": null, "year": 2007}, {"title": "On the genesis of abstract ideas", "author": ["M.I. Posner", "S.W. Keele"], "venue": "Journal of Experimental Psychology, 77:241\u2013248", "citeRegEx": "68", "shortCiteRegEx": null, "year": 1968}, {"title": "Getting to know you: learning new user preferences in recommender systems", "author": ["A.M. Rashid", "I. Albert", "D. Cosley", "S.K. Lam", "S.M. McNee", "J.A. Konstan", "J. Riedl"], "venue": "Proceedings of the 7th international conference on Intelligent user interfaces, pages 127\u2013134. ACM", "citeRegEx": "69", "shortCiteRegEx": null, "year": 2002}, {"title": "Extending the bounds of rationality: Evidence and theories of preferential choice", "author": ["J. Rieskamp", "J.R. Busemeyer", "B.A. Mellers"], "venue": "Journalof Economic Literature, XLIV, pages 631\u2013661", "citeRegEx": "71", "shortCiteRegEx": null, "year": 2006}, {"title": "Information Retrieval", "author": ["C.J.V. Rijsbergen"], "venue": "Butterworth-Heinemann, Newton, MA, USA, 2nd edition", "citeRegEx": "72", "shortCiteRegEx": null, "year": 1979}, {"title": "The probability ranking principle in ir", "author": ["S. Robertson"], "venue": "Journal of Documentation, 33(4):294\u2013304", "citeRegEx": "73", "shortCiteRegEx": null, "year": 1977}, {"title": "Relevance feedback in information retrieval", "author": ["J.J. Rocchio"], "venue": "G. Salton, editor, The SMART Retrieval System: Experiments in Automatic Document Processing, Prentice-Hall Series in Automatic Computation, chapter 14, pages 313\u2013323. Prentice-Hall, Englewood Cliffs NJ", "citeRegEx": "74", "shortCiteRegEx": null, "year": 1971}, {"title": "A method for inferring label sampling mechanisms in semi-supervised learning", "author": ["S. Rosset", "J. Zhu", "H. Zou", "T.J. Hastie"], "venue": "Advances in neural information processing systems, pages 1161\u20131168", "citeRegEx": "75", "shortCiteRegEx": null, "year": 2004}, {"title": "Inference and missing data", "author": ["D.B. Rubin"], "venue": "Biometrika, 63(3):581\u2013592", "citeRegEx": "76", "shortCiteRegEx": null, "year": 1976}, {"title": "A recommender system based on the collaborative behavior of bird flocks", "author": ["E. Saka", "O. Nasraoui"], "venue": "Collaborative Computing: Networking, Applications and Worksharing (CollaborateCom), 2010 6th International Conference on, pages 1\u201310. IEEE", "citeRegEx": "77", "shortCiteRegEx": null, "year": 2010}, {"title": "R", "author": ["A. Salakhutdinov"], "venue": "& Mnih. Probabilistic matrix factorization. Advances in Neural Information Processing Systems, 20:1257\u00c3\u015b1264", "citeRegEx": "78", "shortCiteRegEx": null, "year": 2008}, {"title": "Extended boolean information retrieval", "author": ["G. Salton", "E.A. Fox", "H. Wu"], "venue": "Communications of the ACM, 26(11):1022\u20131036", "citeRegEx": "79", "shortCiteRegEx": null, "year": 1983}, {"title": "Item-based collaborative filtering recommendation algorithms", "author": ["B.K.G.K.J.R.J. Sarwar"], "venue": "Proceedings of the 10th international conference on World Wide Web,", "citeRegEx": "80", "shortCiteRegEx": "80", "year": 2001}, {"title": "J", "author": ["K.J.R.J. Schafer"], "venue": "B. Recommender systems in e-commerce. pages 158\u2013166", "citeRegEx": "81", "shortCiteRegEx": null, "year": 1999}, {"title": "Dealing with missing data", "author": ["J. Scheffer"], "venue": "Research Letters in the Information and Mathematical Sciences, 3:153\u2013160", "citeRegEx": "82", "shortCiteRegEx": null, "year": 2002}, {"title": "Active learning literature survey", "author": ["B. Settles"], "venue": "Computer Sciences Technical Report, ", "citeRegEx": "83", "shortCiteRegEx": null, "year": 1648}, {"title": "Choice from among intentionally selected options", "author": ["P. Shafto", "E. Bonawitz"], "venue": "B. Ross, editor, The psychology of learning and motivation, Volume 63.  Elsevier, San Diego", "citeRegEx": "84", "shortCiteRegEx": null, "year": 2015}, {"title": "Epistemic trust: Modeling children\u2019s reasoning about others\u2019 knowledge and intent", "author": ["P. Shafto", "B. Eaves", "D.J. Navarro", "A. Perfors"], "venue": "Developmental Science, 15:436\u2013447", "citeRegEx": "85", "shortCiteRegEx": null, "year": 2012}, {"title": "Teaching games: Statistical sampling assumptions for pedagogical situations", "author": ["P. Shafto", "N.D. Goodman"], "venue": "Proceedings of the 30th annual conference of the Cognitive Science Society", "citeRegEx": "86", "shortCiteRegEx": null, "year": 2008}, {"title": "Learning from others: The consequences of psychological reasoning for human learning", "author": ["P. Shafto", "N.D. Goodman", "M.C. Frank"], "venue": "Perspectives on Psychological Science, 7:341\u2013351", "citeRegEx": "87", "shortCiteRegEx": null, "year": 2012}, {"title": "A rational account of pedagogical reasoning: Teaching by", "author": ["P. Shafto", "N.D. Goodman", "T.L. Griffiths"], "venue": "and learning from, examples. Cognitive Psychology, 71:55\u201389", "citeRegEx": "88", "shortCiteRegEx": null, "year": 2014}, {"title": "Social information filtering: algorithms for automating \u201cword of mouth", "author": ["U. Shardanand", "P. Maes"], "venue": "Proceedings of the SIGCHI conference on Human factors in computing systems, pages 210\u2013217. ACM Press/Addison-Wesley Publishing Co.", "citeRegEx": "89", "shortCiteRegEx": null, "year": 1995}, {"title": "Learning and memorization of classifications", "author": ["R.N. Shepard", "C.I. Hovland", "H.M. Jenkins"], "venue": "Psychological Monographs, 75", "citeRegEx": "90", "shortCiteRegEx": null, "year": 1961}, {"title": "Evolving agents for personalized information filtering", "author": ["B. Sheth", "P. Maes"], "venue": "Artificial Intelligence for Applications, 1993. Proceedings., Ninth Conference on, pages 345\u2013352. IEEE", "citeRegEx": "91", "shortCiteRegEx": null, "year": 1993}, {"title": "Choice in context: Tradeoff contrast and extremeness aversion", "author": ["I. Simonson", "A. Tversky"], "venue": "Journal of Marketing Research, 29:281\u2013295", "citeRegEx": "92", "shortCiteRegEx": null, "year": 1992}, {"title": "Some thoughts on classification for retrieval", "author": ["K. Sparck Jones"], "venue": "Journal of Documentation, 26(2):89\u2013101", "citeRegEx": "93", "shortCiteRegEx": null, "year": 1970}, {"title": "Reinforcement learning: An introduction", "author": ["R.S. Sutton", "A.G. Barto"], "venue": "MIT Press, Cambridge, MA", "citeRegEx": "94", "shortCiteRegEx": null, "year": 1998}, {"title": "A law of comparative judgment", "author": ["L.L. Thurstone"], "venue": "Psychological Review, 34(4):273\u2013286", "citeRegEx": "95", "shortCiteRegEx": null, "year": 1927}, {"title": "The Cultural Origins of Human Cognition", "author": ["M. Tomasello"], "venue": "Harvard University Press", "citeRegEx": "96", "shortCiteRegEx": null, "year": 1999}, {"title": "Elimination by aspects: A theory of choice", "author": ["A. Tversky"], "venue": "Psychological Review, 79:281\u2013299", "citeRegEx": "97", "shortCiteRegEx": null, "year": 1972}, {"title": "Empirical distributions in selection bias models", "author": ["Y. Vardi"], "venue": "The Annals of Statistics, 13(1):178\u2013203,", "citeRegEx": "98", "shortCiteRegEx": "98", "year": 1985}, {"title": "Reasoning about teaching and misleading", "author": ["R. Warner", "T. Stoess", "P. Shafto"], "venue": "Proceedings of the 33rd annual conference of the Cognitive Science Society", "citeRegEx": "99", "shortCiteRegEx": null, "year": 2011}, {"title": "The relationship between luce\u2019s choice axiom", "author": ["J.I. Yellot"], "venue": "thurstone\u2019s theory of comparative judgement, and the double exponential distribution. Journal of Mathematical Psychology, 15:109\u2013144", "citeRegEx": "101", "shortCiteRegEx": null, "year": 1977}, {"title": "Mining search engine  query logs for query recommendation", "author": ["Z. Zhang", "O. Nasraoui"], "venue": "Proceedings of the 15th international conference on World Wide Web, pages 1039\u20131040. ACM", "citeRegEx": "102", "shortCiteRegEx": null, "year": 2006}, {"title": "Semi-supervised learning literature survey", "author": ["X. Zhu"], "venue": "Internationl Conference on Machine Learning,", "citeRegEx": "103", "shortCiteRegEx": "103", "year": 2007}, {"title": "Introduction to semi-supervised learning", "author": ["X. Zhu", "A.B. Goldberg"], "venue": "Synthesis lectures on artificial intelligence and machine learning, 3(1):1\u2013130", "citeRegEx": "104", "shortCiteRegEx": null, "year": 2009}, {"title": "A hybrid recommender system guided by semantic user profiles for search in the e-learning domain", "author": ["L. Zhuhadar", "O. Nasraoui"], "venue": "Journal of Emerging Technologies in Web Intelligence, 2(4):272\u2013281", "citeRegEx": "105", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 90, "context": "Information retrieval techniques [93, 73, 35, 72, 79, 7, 23] have given rise to the modern search engines which return relevant results, following a user\u2019s explicit query.", "startOffset": 33, "endOffset": 60}, {"referenceID": 70, "context": "Information retrieval techniques [93, 73, 35, 72, 79, 7, 23] have given rise to the modern search engines which return relevant results, following a user\u2019s explicit query.", "startOffset": 33, "endOffset": 60}, {"referenceID": 33, "context": "Information retrieval techniques [93, 73, 35, 72, 79, 7, 23] have given rise to the modern search engines which return relevant results, following a user\u2019s explicit query.", "startOffset": 33, "endOffset": 60}, {"referenceID": 69, "context": "Information retrieval techniques [93, 73, 35, 72, 79, 7, 23] have given rise to the modern search engines which return relevant results, following a user\u2019s explicit query.", "startOffset": 33, "endOffset": 60}, {"referenceID": 76, "context": "Information retrieval techniques [93, 73, 35, 72, 79, 7, 23] have given rise to the modern search engines which return relevant results, following a user\u2019s explicit query.", "startOffset": 33, "endOffset": 60}, {"referenceID": 6, "context": "Information retrieval techniques [93, 73, 35, 72, 79, 7, 23] have given rise to the modern search engines which return relevant results, following a user\u2019s explicit query.", "startOffset": 33, "endOffset": 60}, {"referenceID": 21, "context": "Information retrieval techniques [93, 73, 35, 72, 79, 7, 23] have given rise to the modern search engines which return relevant results, following a user\u2019s explicit query.", "startOffset": 33, "endOffset": 60}, {"referenceID": 70, "context": "For instance, in the probabilistic retrieval model [73], optimal retrieval is obtained when search results are ranked according to their relevance probabilities.", "startOffset": 51, "endOffset": 55}, {"referenceID": 27, "context": "Recommender systems, on the other hand, generally do not await an explicit query to provide results [29, 50, 70, 66, 9, 81, 3, 61].", "startOffset": 100, "endOffset": 130}, {"referenceID": 48, "context": "Recommender systems, on the other hand, generally do not await an explicit query to provide results [29, 50, 70, 66, 9, 81, 3, 61].", "startOffset": 100, "endOffset": 130}, {"referenceID": 64, "context": "Recommender systems, on the other hand, generally do not await an explicit query to provide results [29, 50, 70, 66, 9, 81, 3, 61].", "startOffset": 100, "endOffset": 130}, {"referenceID": 8, "context": "Recommender systems, on the other hand, generally do not await an explicit query to provide results [29, 50, 70, 66, 9, 81, 3, 61].", "startOffset": 100, "endOffset": 130}, {"referenceID": 78, "context": "Recommender systems, on the other hand, generally do not await an explicit query to provide results [29, 50, 70, 66, 9, 81, 3, 61].", "startOffset": 100, "endOffset": 130}, {"referenceID": 2, "context": "Recommender systems, on the other hand, generally do not await an explicit query to provide results [29, 50, 70, 66, 9, 81, 3, 61].", "startOffset": 100, "endOffset": 130}, {"referenceID": 59, "context": "Recommender systems, on the other hand, generally do not await an explicit query to provide results [29, 50, 70, 66, 9, 81, 3, 61].", "startOffset": 100, "endOffset": 130}, {"referenceID": 64, "context": "The first type is contentbased filtering (CBF) algorithms [66, 8, 67].", "startOffset": 58, "endOffset": 69}, {"referenceID": 7, "context": "The first type is contentbased filtering (CBF) algorithms [66, 8, 67].", "startOffset": 58, "endOffset": 69}, {"referenceID": 65, "context": "The first type is contentbased filtering (CBF) algorithms [66, 8, 67].", "startOffset": 58, "endOffset": 69}, {"referenceID": 27, "context": "Collaborative Filtering (CF) [29, 89, 41, 80, 47, 61], on the other hand, does not require item attributes or user attributes.", "startOffset": 29, "endOffset": 53}, {"referenceID": 86, "context": "Collaborative Filtering (CF) [29, 89, 41, 80, 47, 61], on the other hand, does not require item attributes or user attributes.", "startOffset": 29, "endOffset": 53}, {"referenceID": 39, "context": "Collaborative Filtering (CF) [29, 89, 41, 80, 47, 61], on the other hand, does not require item attributes or user attributes.", "startOffset": 29, "endOffset": 53}, {"referenceID": 77, "context": "Collaborative Filtering (CF) [29, 89, 41, 80, 47, 61], on the other hand, does not require item attributes or user attributes.", "startOffset": 29, "endOffset": 53}, {"referenceID": 45, "context": "Collaborative Filtering (CF) [29, 89, 41, 80, 47, 61], on the other hand, does not require item attributes or user attributes.", "startOffset": 29, "endOffset": 53}, {"referenceID": 59, "context": "Collaborative Filtering (CF) [29, 89, 41, 80, 47, 61], on the other hand, does not require item attributes or user attributes.", "startOffset": 29, "endOffset": 53}, {"referenceID": 20, "context": "K-nearest neighbors [22, 26] and non-negative matrix factorization (NMF) [45, 42, 78, 1], that have close analogs in the psychology literatures on concept learning, e.", "startOffset": 20, "endOffset": 28}, {"referenceID": 24, "context": "K-nearest neighbors [22, 26] and non-negative matrix factorization (NMF) [45, 42, 78, 1], that have close analogs in the psychology literatures on concept learning, e.", "startOffset": 20, "endOffset": 28}, {"referenceID": 43, "context": "K-nearest neighbors [22, 26] and non-negative matrix factorization (NMF) [45, 42, 78, 1], that have close analogs in the psychology literatures on concept learning, e.", "startOffset": 73, "endOffset": 88}, {"referenceID": 40, "context": "K-nearest neighbors [22, 26] and non-negative matrix factorization (NMF) [45, 42, 78, 1], that have close analogs in the psychology literatures on concept learning, e.", "startOffset": 73, "endOffset": 88}, {"referenceID": 75, "context": "K-nearest neighbors [22, 26] and non-negative matrix factorization (NMF) [45, 42, 78, 1], that have close analogs in the psychology literatures on concept learning, e.", "startOffset": 73, "endOffset": 88}, {"referenceID": 0, "context": "K-nearest neighbors [22, 26] and non-negative matrix factorization (NMF) [45, 42, 78, 1], that have close analogs in the psychology literatures on concept learning, e.", "startOffset": 73, "endOffset": 88}, {"referenceID": 52, "context": "exemplar models [54, 63, 43] and probabilistic topic models [31, 32].", "startOffset": 16, "endOffset": 28}, {"referenceID": 61, "context": "exemplar models [54, 63, 43] and probabilistic topic models [31, 32].", "startOffset": 16, "endOffset": 28}, {"referenceID": 41, "context": "exemplar models [54, 63, 43] and probabilistic topic models [31, 32].", "startOffset": 16, "endOffset": 28}, {"referenceID": 29, "context": "exemplar models [54, 63, 43] and probabilistic topic models [31, 32].", "startOffset": 60, "endOffset": 68}, {"referenceID": 30, "context": "exemplar models [54, 63, 43] and probabilistic topic models [31, 32].", "startOffset": 60, "endOffset": 68}, {"referenceID": 88, "context": "Information filtering algorithms [91, 50, 33] similarly provide users with a list of relevant results, but do so in response to a query.", "startOffset": 33, "endOffset": 45}, {"referenceID": 48, "context": "Information filtering algorithms [91, 50, 33] similarly provide users with a list of relevant results, but do so in response to a query.", "startOffset": 33, "endOffset": 45}, {"referenceID": 31, "context": "Information filtering algorithms [91, 50, 33] similarly provide users with a list of relevant results, but do so in response to a query.", "startOffset": 33, "endOffset": 45}, {"referenceID": 71, "context": "One classic example is the Rocchio filter [74, 16, 65], which modifies the user\u2019s initial query after a first iteration of search to help filter less relevant results.", "startOffset": 42, "endOffset": 54}, {"referenceID": 15, "context": "One classic example is the Rocchio filter [74, 16, 65], which modifies the user\u2019s initial query after a first iteration of search to help filter less relevant results.", "startOffset": 42, "endOffset": 54}, {"referenceID": 63, "context": "One classic example is the Rocchio filter [74, 16, 65], which modifies the user\u2019s initial query after a first iteration of search to help filter less relevant results.", "startOffset": 42, "endOffset": 54}, {"referenceID": 64, "context": "movies, books, news) based on their user profile [70, 66, 41].", "startOffset": 49, "endOffset": 61}, {"referenceID": 39, "context": "movies, books, news) based on their user profile [70, 66, 41].", "startOffset": 49, "endOffset": 61}, {"referenceID": 58, "context": "their browsing or purchase history) data [60, 36, 37, 105], or even query patterns [102].", "startOffset": 41, "endOffset": 58}, {"referenceID": 34, "context": "their browsing or purchase history) data [60, 36, 37, 105], or even query patterns [102].", "startOffset": 41, "endOffset": 58}, {"referenceID": 35, "context": "their browsing or purchase history) data [60, 36, 37, 105], or even query patterns [102].", "startOffset": 41, "endOffset": 58}, {"referenceID": 101, "context": "their browsing or purchase history) data [60, 36, 37, 105], or even query patterns [102].", "startOffset": 41, "endOffset": 58}, {"referenceID": 98, "context": "their browsing or purchase history) data [60, 36, 37, 105], or even query patterns [102].", "startOffset": 83, "endOffset": 88}, {"referenceID": 22, "context": "Research into human choice suggests that both explicit and implicit choices systematically vary based on context, especially the other options that are present when choosing [24, 97, 53].", "startOffset": 174, "endOffset": 186}, {"referenceID": 94, "context": "Research into human choice suggests that both explicit and implicit choices systematically vary based on context, especially the other options that are present when choosing [24, 97, 53].", "startOffset": 174, "endOffset": 186}, {"referenceID": 51, "context": "Research into human choice suggests that both explicit and implicit choices systematically vary based on context, especially the other options that are present when choosing [24, 97, 53].", "startOffset": 174, "endOffset": 186}, {"referenceID": 84, "context": "In [87], a computational framework was proposed for modeling how people\u2019s inferences may change as a consequence of reasoning about why data were selected.", "startOffset": 3, "endOffset": 7}, {"referenceID": 83, "context": "This framework has been formalized in learning from helpful and knowledgeable teachers [86, 11, 15, 88], deceptive informants [99], and epistemic trust [85, 28, 44].", "startOffset": 87, "endOffset": 103}, {"referenceID": 10, "context": "This framework has been formalized in learning from helpful and knowledgeable teachers [86, 11, 15, 88], deceptive informants [99], and epistemic trust [85, 28, 44].", "startOffset": 87, "endOffset": 103}, {"referenceID": 14, "context": "This framework has been formalized in learning from helpful and knowledgeable teachers [86, 11, 15, 88], deceptive informants [99], and epistemic trust [85, 28, 44].", "startOffset": 87, "endOffset": 103}, {"referenceID": 85, "context": "This framework has been formalized in learning from helpful and knowledgeable teachers [86, 11, 15, 88], deceptive informants [99], and epistemic trust [85, 28, 44].", "startOffset": 87, "endOffset": 103}, {"referenceID": 96, "context": "This framework has been formalized in learning from helpful and knowledgeable teachers [86, 11, 15, 88], deceptive informants [99], and epistemic trust [85, 28, 44].", "startOffset": 126, "endOffset": 130}, {"referenceID": 82, "context": "This framework has been formalized in learning from helpful and knowledgeable teachers [86, 11, 15, 88], deceptive informants [99], and epistemic trust [85, 28, 44].", "startOffset": 152, "endOffset": 164}, {"referenceID": 26, "context": "This framework has been formalized in learning from helpful and knowledgeable teachers [86, 11, 15, 88], deceptive informants [99], and epistemic trust [85, 28, 44].", "startOffset": 152, "endOffset": 164}, {"referenceID": 42, "context": "This framework has been formalized in learning from helpful and knowledgeable teachers [86, 11, 15, 88], deceptive informants [99], and epistemic trust [85, 28, 44].", "startOffset": 152, "endOffset": 164}, {"referenceID": 28, "context": "Our approach draws on foundational algorithms for selecting and filtering of data from computer science, while also adapting mathematical methods from the study of cultural evolution [30, 39, 10] to formalize the implications of iterative interactions.", "startOffset": 183, "endOffset": 195}, {"referenceID": 37, "context": "Our approach draws on foundational algorithms for selecting and filtering of data from computer science, while also adapting mathematical methods from the study of cultural evolution [30, 39, 10] to formalize the implications of iterative interactions.", "startOffset": 183, "endOffset": 195}, {"referenceID": 9, "context": "Our approach draws on foundational algorithms for selecting and filtering of data from computer science, while also adapting mathematical methods from the study of cultural evolution [30, 39, 10] to formalize the implications of iterative interactions.", "startOffset": 183, "endOffset": 195}, {"referenceID": 36, "context": "For instance, we could consider the evolution of algorithms as a special case of cultural evolution of the sort observed in human language [38] and human knowledge more broadly [96, 10].", "startOffset": 139, "endOffset": 143}, {"referenceID": 93, "context": "For instance, we could consider the evolution of algorithms as a special case of cultural evolution of the sort observed in human language [38] and human knowledge more broadly [96, 10].", "startOffset": 177, "endOffset": 185}, {"referenceID": 9, "context": "For instance, we could consider the evolution of algorithms as a special case of cultural evolution of the sort observed in human language [38] and human knowledge more broadly [96, 10].", "startOffset": 177, "endOffset": 185}, {"referenceID": 28, "context": "One way to do this is using Markov chains to model iterative interactions with transmission between adjacent iterations as was done in [30].", "startOffset": 135, "endOffset": 139}, {"referenceID": 90, "context": "both information retrieval [93] as well as recommender systems [9].", "startOffset": 27, "endOffset": 31}, {"referenceID": 8, "context": "both information retrieval [93] as well as recommender systems [9].", "startOffset": 63, "endOffset": 66}, {"referenceID": 70, "context": "In the case of a rating based recommender or an optimal probabilistic information filter [73], the probability of selecting the data is related to its rank.", "startOffset": 89, "endOffset": 93}, {"referenceID": 70, "context": "For a rating based recommender, the rank is based on the predicted rating, and for an optimal probabilistic information filter, the rank is based on the probability of relevance [73].", "startOffset": 178, "endOffset": 182}, {"referenceID": 38, "context": "they fail to attempt to falsify their hypotheses) [40].", "startOffset": 50, "endOffset": 54}, {"referenceID": 18, "context": "Active learning is a classical method in machine learning [20, 21, 83, 18, 14], used to reduce the number of labeled samples required for learning and thus accelerate learning versus training sample addition.", "startOffset": 58, "endOffset": 78}, {"referenceID": 19, "context": "Active learning is a classical method in machine learning [20, 21, 83, 18, 14], used to reduce the number of labeled samples required for learning and thus accelerate learning versus training sample addition.", "startOffset": 58, "endOffset": 78}, {"referenceID": 80, "context": "Active learning is a classical method in machine learning [20, 21, 83, 18, 14], used to reduce the number of labeled samples required for learning and thus accelerate learning versus training sample addition.", "startOffset": 58, "endOffset": 78}, {"referenceID": 17, "context": "Active learning is a classical method in machine learning [20, 21, 83, 18, 14], used to reduce the number of labeled samples required for learning and thus accelerate learning versus training sample addition.", "startOffset": 58, "endOffset": 78}, {"referenceID": 13, "context": "Active learning is a classical method in machine learning [20, 21, 83, 18, 14], used to reduce the number of labeled samples required for learning and thus accelerate learning versus training sample addition.", "startOffset": 58, "endOffset": 78}, {"referenceID": 80, "context": "Consider the case of one classical approach in active learning [83], where data are selected to be presented to the user for labeling based on the uncertainty portended by its prediction using the current algorithm\u2019s hypothesis,", "startOffset": 63, "endOffset": 67}, {"referenceID": 46, "context": "We can formalize this choice using Luce choice [48], a special case of softmax [94], 1", "startOffset": 47, "endOffset": 51}, {"referenceID": 91, "context": "We can formalize this choice using Luce choice [48], a special case of softmax [94], 1", "startOffset": 79, "endOffset": 83}, {"referenceID": 22, "context": "Both softmax and Luce choice have known issues for modeling human choice [24, 71].", "startOffset": 73, "endOffset": 81}, {"referenceID": 68, "context": "Both softmax and Luce choice have known issues for modeling human choice [24, 71].", "startOffset": 73, "endOffset": 81}, {"referenceID": 73, "context": "In principle, one might think that this is related to the problem of dealing with missing data that is common in statistics [76].", "startOffset": 124, "endOffset": 128}, {"referenceID": 73, "context": "Indeed, in our analyses, we showed one special case that reduces to the missing at random typically assumed in statistical applications [76].", "startOffset": 136, "endOffset": 140}, {"referenceID": 84, "context": "However, the framework proposed here is in fact more general; it proposes a theory of why data are missing, and formalizes the problem as one of understanding human behavior [87, 84, 27].", "startOffset": 174, "endOffset": 186}, {"referenceID": 81, "context": "However, the framework proposed here is in fact more general; it proposes a theory of why data are missing, and formalizes the problem as one of understanding human behavior [87, 84, 27].", "startOffset": 174, "endOffset": 186}, {"referenceID": 25, "context": "However, the framework proposed here is in fact more general; it proposes a theory of why data are missing, and formalizes the problem as one of understanding human behavior [87, 84, 27].", "startOffset": 174, "endOffset": 186}, {"referenceID": 54, "context": "There are several ways we can pursue an antidote; for example, by unbiasing the final predicted outputs or by using ensemble-based active learning such as [56].", "startOffset": 155, "endOffset": 159}, {"referenceID": 71, "context": "Unbiasing can be performed post-learning by a reverse-Rocchio approach which works in the opposite way to traditional Rocchio personalization [74].", "startOffset": 142, "endOffset": 146}, {"referenceID": 95, "context": "Reactive bias can span the entire range of selection mechanisms ranging from active learning to filter-bias and inverse-filter bias, including inverse sampling (note however, that existing methods like [98] do not assume iterated learning).", "startOffset": 202, "endOffset": 206}, {"referenceID": 95, "context": "One way this has been explored in semi-supervised learning, where the availability of labels can be biased, is by inverse sampling which multiplies the sampling probability by the reciprocal of the probability of labels given data [98, 17].", "startOffset": 231, "endOffset": 239}, {"referenceID": 16, "context": "One way this has been explored in semi-supervised learning, where the availability of labels can be biased, is by inverse sampling which multiplies the sampling probability by the reciprocal of the probability of labels given data [98, 17].", "startOffset": 231, "endOffset": 239}, {"referenceID": 11, "context": "To help unbias filters, we can explore adapting (into reactive learning) Active Collaborative Filtering strategies, such as [12] and Uncertainty Sampling with Diversity Maximization (USDM) [100].", "startOffset": 124, "endOffset": 128}, {"referenceID": 32, "context": "Researchers have been aware that data, fed to filters such as recommender systems, is biased by the mechanism by which users rate items [34].", "startOffset": 136, "endOffset": 140}, {"referenceID": 58, "context": "Within the context of online machine learning from human activity data, dynamic usage patterns were studied in [60] and dynamic recommender systems were studied within a stream data mining framework in [59].", "startOffset": 111, "endOffset": 115}, {"referenceID": 57, "context": "Within the context of online machine learning from human activity data, dynamic usage patterns were studied in [60] and dynamic recommender systems were studied within a stream data mining framework in [59].", "startOffset": 202, "endOffset": 206}, {"referenceID": 74, "context": "In [77], a Swarm Intelligence-based recommender system, inspired by the collaborative behavior of bird flocks and called FlockRecom, generated recommendations by iteratively adjusting the position and speed of dynamic flocks of agents in a virtual space.", "startOffset": 3, "endOffset": 7}, {"referenceID": 40, "context": "In fact, most past recommenders worked with or collected sparse rating data and none has considered iterated learning-induced biases, but rather only corrected for simple models of user, item, or time based biases [42].", "startOffset": 214, "endOffset": 218}, {"referenceID": 40, "context": "The latter type of bias, time based recommendation bias [42], is not related to algorithm biases, but rather to general temporal trends of movie preferences that are decoupled from the machine learning algorithm itself.", "startOffset": 56, "endOffset": 60}, {"referenceID": 67, "context": "Experiments with different methods to select the items to be rated before any recommendations [69] showed different bias in initial ratings resulting from different methods.", "startOffset": 94, "endOffset": 98}, {"referenceID": 18, "context": "Our work may seem related to various aspects of active learning [20, 21, 83, 18, 14], semi-supervised learning [57, 62, 19, 103, 104, 2], label sampling bias in semi-supervised learning [75], and missing data theory [76, 82].", "startOffset": 64, "endOffset": 84}, {"referenceID": 19, "context": "Our work may seem related to various aspects of active learning [20, 21, 83, 18, 14], semi-supervised learning [57, 62, 19, 103, 104, 2], label sampling bias in semi-supervised learning [75], and missing data theory [76, 82].", "startOffset": 64, "endOffset": 84}, {"referenceID": 80, "context": "Our work may seem related to various aspects of active learning [20, 21, 83, 18, 14], semi-supervised learning [57, 62, 19, 103, 104, 2], label sampling bias in semi-supervised learning [75], and missing data theory [76, 82].", "startOffset": 64, "endOffset": 84}, {"referenceID": 17, "context": "Our work may seem related to various aspects of active learning [20, 21, 83, 18, 14], semi-supervised learning [57, 62, 19, 103, 104, 2], label sampling bias in semi-supervised learning [75], and missing data theory [76, 82].", "startOffset": 64, "endOffset": 84}, {"referenceID": 13, "context": "Our work may seem related to various aspects of active learning [20, 21, 83, 18, 14], semi-supervised learning [57, 62, 19, 103, 104, 2], label sampling bias in semi-supervised learning [75], and missing data theory [76, 82].", "startOffset": 64, "endOffset": 84}, {"referenceID": 55, "context": "Our work may seem related to various aspects of active learning [20, 21, 83, 18, 14], semi-supervised learning [57, 62, 19, 103, 104, 2], label sampling bias in semi-supervised learning [75], and missing data theory [76, 82].", "startOffset": 111, "endOffset": 136}, {"referenceID": 60, "context": "Our work may seem related to various aspects of active learning [20, 21, 83, 18, 14], semi-supervised learning [57, 62, 19, 103, 104, 2], label sampling bias in semi-supervised learning [75], and missing data theory [76, 82].", "startOffset": 111, "endOffset": 136}, {"referenceID": 99, "context": "Our work may seem related to various aspects of active learning [20, 21, 83, 18, 14], semi-supervised learning [57, 62, 19, 103, 104, 2], label sampling bias in semi-supervised learning [75], and missing data theory [76, 82].", "startOffset": 111, "endOffset": 136}, {"referenceID": 100, "context": "Our work may seem related to various aspects of active learning [20, 21, 83, 18, 14], semi-supervised learning [57, 62, 19, 103, 104, 2], label sampling bias in semi-supervised learning [75], and missing data theory [76, 82].", "startOffset": 111, "endOffset": 136}, {"referenceID": 1, "context": "Our work may seem related to various aspects of active learning [20, 21, 83, 18, 14], semi-supervised learning [57, 62, 19, 103, 104, 2], label sampling bias in semi-supervised learning [75], and missing data theory [76, 82].", "startOffset": 111, "endOffset": 136}, {"referenceID": 72, "context": "Our work may seem related to various aspects of active learning [20, 21, 83, 18, 14], semi-supervised learning [57, 62, 19, 103, 104, 2], label sampling bias in semi-supervised learning [75], and missing data theory [76, 82].", "startOffset": 186, "endOffset": 190}, {"referenceID": 73, "context": "Our work may seem related to various aspects of active learning [20, 21, 83, 18, 14], semi-supervised learning [57, 62, 19, 103, 104, 2], label sampling bias in semi-supervised learning [75], and missing data theory [76, 82].", "startOffset": 216, "endOffset": 224}, {"referenceID": 79, "context": "Our work may seem related to various aspects of active learning [20, 21, 83, 18, 14], semi-supervised learning [57, 62, 19, 103, 104, 2], label sampling bias in semi-supervised learning [75], and missing data theory [76, 82].", "startOffset": 216, "endOffset": 224}, {"referenceID": 23, "context": "One type of active learning, known as Proactive Learning [25] attaches a cost to every sample before asking for labels and assumes that different oracles have different reliability.", "startOffset": 57, "endOffset": 61}, {"referenceID": 47, "context": "For instance some work tried to study the effect of missing data in CF [49, 52]; however no prior studies exist using an iterated model or measuring the impact of a machine learning algorithm itself on future data.", "startOffset": 71, "endOffset": 79}, {"referenceID": 50, "context": "For instance some work tried to study the effect of missing data in CF [49, 52]; however no prior studies exist using an iterated model or measuring the impact of a machine learning algorithm itself on future data.", "startOffset": 71, "endOffset": 79}, {"referenceID": 62, "context": "Filter bubbles have been a subject of attention lately [64, 13, 46], including work attempting to reverse or ameliorate such effects [55, 58].", "startOffset": 55, "endOffset": 67}, {"referenceID": 12, "context": "Filter bubbles have been a subject of attention lately [64, 13, 46], including work attempting to reverse or ameliorate such effects [55, 58].", "startOffset": 55, "endOffset": 67}, {"referenceID": 44, "context": "Filter bubbles have been a subject of attention lately [64, 13, 46], including work attempting to reverse or ameliorate such effects [55, 58].", "startOffset": 55, "endOffset": 67}, {"referenceID": 53, "context": "Filter bubbles have been a subject of attention lately [64, 13, 46], including work attempting to reverse or ameliorate such effects [55, 58].", "startOffset": 133, "endOffset": 141}, {"referenceID": 56, "context": "Filter bubbles have been a subject of attention lately [64, 13, 46], including work attempting to reverse or ameliorate such effects [55, 58].", "startOffset": 133, "endOffset": 141}, {"referenceID": 13, "context": "Research in psychology has investigated category learning [14, 90, 68, 54, 4], choice behavior [95, 48, 101, 97, 92], active learning [14, 6, 4, 5, 51], and social learning [86, 11, 15, 88].", "startOffset": 58, "endOffset": 77}, {"referenceID": 87, "context": "Research in psychology has investigated category learning [14, 90, 68, 54, 4], choice behavior [95, 48, 101, 97, 92], active learning [14, 6, 4, 5, 51], and social learning [86, 11, 15, 88].", "startOffset": 58, "endOffset": 77}, {"referenceID": 66, "context": "Research in psychology has investigated category learning [14, 90, 68, 54, 4], choice behavior [95, 48, 101, 97, 92], active learning [14, 6, 4, 5, 51], and social learning [86, 11, 15, 88].", "startOffset": 58, "endOffset": 77}, {"referenceID": 52, "context": "Research in psychology has investigated category learning [14, 90, 68, 54, 4], choice behavior [95, 48, 101, 97, 92], active learning [14, 6, 4, 5, 51], and social learning [86, 11, 15, 88].", "startOffset": 58, "endOffset": 77}, {"referenceID": 3, "context": "Research in psychology has investigated category learning [14, 90, 68, 54, 4], choice behavior [95, 48, 101, 97, 92], active learning [14, 6, 4, 5, 51], and social learning [86, 11, 15, 88].", "startOffset": 58, "endOffset": 77}, {"referenceID": 92, "context": "Research in psychology has investigated category learning [14, 90, 68, 54, 4], choice behavior [95, 48, 101, 97, 92], active learning [14, 6, 4, 5, 51], and social learning [86, 11, 15, 88].", "startOffset": 95, "endOffset": 116}, {"referenceID": 46, "context": "Research in psychology has investigated category learning [14, 90, 68, 54, 4], choice behavior [95, 48, 101, 97, 92], active learning [14, 6, 4, 5, 51], and social learning [86, 11, 15, 88].", "startOffset": 95, "endOffset": 116}, {"referenceID": 97, "context": "Research in psychology has investigated category learning [14, 90, 68, 54, 4], choice behavior [95, 48, 101, 97, 92], active learning [14, 6, 4, 5, 51], and social learning [86, 11, 15, 88].", "startOffset": 95, "endOffset": 116}, {"referenceID": 94, "context": "Research in psychology has investigated category learning [14, 90, 68, 54, 4], choice behavior [95, 48, 101, 97, 92], active learning [14, 6, 4, 5, 51], and social learning [86, 11, 15, 88].", "startOffset": 95, "endOffset": 116}, {"referenceID": 89, "context": "Research in psychology has investigated category learning [14, 90, 68, 54, 4], choice behavior [95, 48, 101, 97, 92], active learning [14, 6, 4, 5, 51], and social learning [86, 11, 15, 88].", "startOffset": 95, "endOffset": 116}, {"referenceID": 13, "context": "Research in psychology has investigated category learning [14, 90, 68, 54, 4], choice behavior [95, 48, 101, 97, 92], active learning [14, 6, 4, 5, 51], and social learning [86, 11, 15, 88].", "startOffset": 134, "endOffset": 151}, {"referenceID": 5, "context": "Research in psychology has investigated category learning [14, 90, 68, 54, 4], choice behavior [95, 48, 101, 97, 92], active learning [14, 6, 4, 5, 51], and social learning [86, 11, 15, 88].", "startOffset": 134, "endOffset": 151}, {"referenceID": 3, "context": "Research in psychology has investigated category learning [14, 90, 68, 54, 4], choice behavior [95, 48, 101, 97, 92], active learning [14, 6, 4, 5, 51], and social learning [86, 11, 15, 88].", "startOffset": 134, "endOffset": 151}, {"referenceID": 4, "context": "Research in psychology has investigated category learning [14, 90, 68, 54, 4], choice behavior [95, 48, 101, 97, 92], active learning [14, 6, 4, 5, 51], and social learning [86, 11, 15, 88].", "startOffset": 134, "endOffset": 151}, {"referenceID": 49, "context": "Research in psychology has investigated category learning [14, 90, 68, 54, 4], choice behavior [95, 48, 101, 97, 92], active learning [14, 6, 4, 5, 51], and social learning [86, 11, 15, 88].", "startOffset": 134, "endOffset": 151}, {"referenceID": 83, "context": "Research in psychology has investigated category learning [14, 90, 68, 54, 4], choice behavior [95, 48, 101, 97, 92], active learning [14, 6, 4, 5, 51], and social learning [86, 11, 15, 88].", "startOffset": 173, "endOffset": 189}, {"referenceID": 10, "context": "Research in psychology has investigated category learning [14, 90, 68, 54, 4], choice behavior [95, 48, 101, 97, 92], active learning [14, 6, 4, 5, 51], and social learning [86, 11, 15, 88].", "startOffset": 173, "endOffset": 189}, {"referenceID": 14, "context": "Research in psychology has investigated category learning [14, 90, 68, 54, 4], choice behavior [95, 48, 101, 97, 92], active learning [14, 6, 4, 5, 51], and social learning [86, 11, 15, 88].", "startOffset": 173, "endOffset": 189}, {"referenceID": 85, "context": "Research in psychology has investigated category learning [14, 90, 68, 54, 4], choice behavior [95, 48, 101, 97, 92], active learning [14, 6, 4, 5, 51], and social learning [86, 11, 15, 88].", "startOffset": 173, "endOffset": 189}, {"referenceID": 82, "context": "This literature has shown that people reason about why other people select data, and use people\u2019s selection of data to update their beliefs about the data selection process [85, 28, 44].", "startOffset": 173, "endOffset": 185}, {"referenceID": 26, "context": "This literature has shown that people reason about why other people select data, and use people\u2019s selection of data to update their beliefs about the data selection process [85, 28, 44].", "startOffset": 173, "endOffset": 185}, {"referenceID": 42, "context": "This literature has shown that people reason about why other people select data, and use people\u2019s selection of data to update their beliefs about the data selection process [85, 28, 44].", "startOffset": 173, "endOffset": 185}], "year": 2016, "abstractText": "Early supervised machine learning algorithms have relied on reliable expert labels to build predictive models. However, the gates of data generation have recently been opened to a wider base of users who started participating increasingly with casual labeling, rating, annotating, etc. The increased online presence and participation of humans has led not only to a democratization of unchecked inputs to algorithms, but also to a wide democratization of the \u201cconsumption\u201d of machine learning algorithms\u2019 outputs by general users. Hence, these algorithms, many of which are becoming essential building blocks of recommender systems and other information filters, started interacting with users at unprecedented rates. The result is machine learning algorithms that consume more and more data that is unchecked, or at the very least, not fitting conventional assumptions made by various machine learning algorithms. These include biased samples, biased labels, diverging training and testing sets, and cyclical interaction between algorithms, humans, information consumed by humans, and data consumed by algorithms. Yet, the continuous interaction between humans and algorithms is rarely taken into account in machine learning algorithm design and analysis. In this paper, we present a preliminary theoretical model and analysis of the mutual interaction between humans and algorithms, based on an iterated learning framework that is inspired from the study of human language evolution. We also define the concepts of human and algorithm blind spots and outline machine learning approaches to mend iterated bias through two novel notions: antidotes and reactive learning.", "creator": "LaTeX with hyperref package"}}}