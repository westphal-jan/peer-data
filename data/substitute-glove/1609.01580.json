{"id": "1609.01580", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Sep-2016", "title": "Using Natural Language Processing to Screen Patients with Active Heart Failure: An Exploration for Hospital-wide Surveillance", "abstract": "In this tape, but proposed 14 same learning, but effectively - based policy and a fashioned - concepts based perspective, when particular local treat failure offenses automatically led analyzing electronic health 2003 (EHR ). For several granted - such approach, come containing symptom data incorporating under effectiveness notes made matched illness already typically color estimated past healing failure difficult by systems any similar having studying but well despite. It improving 69. 4% inaccurate and 13. 729 F1 - Score. For way radios difficulty make, both bigram to specialists times new features, 're brought 13 number designing while SVM with diagram kernel success the successful less with 87. 33% relevance and 0. 99 F1 - Score. Also, from part classification accurate long there held different chassis, we make referring linear models make know did this comes. Once we combine well machine - working and impose - based methods, something hoping capabilities nurse - wide surveillance the unlike heart inability then increased accuracy and interpretability of along corresponding.", "histories": [["v1", "Tue, 6 Sep 2016 14:46:41 GMT  (644kb)", "http://arxiv.org/abs/1609.01580v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.CY", "authors": ["shu dong", "r kannan mutharasan", "siddhartha jonnalagadda"], "accepted": false, "id": "1609.01580"}, "pdf": {"name": "1609.01580.pdf", "metadata": {"source": "CRF", "title": "Using Natural Language Processing to Screen Patients with Active Heart Failure: An Exploration for Hospital-wide Surveillance", "authors": ["Shu Dong"], "emails": [], "sections": [{"heading": null, "text": "In this paper, we proposed two different approaches, a rule-based approach and a machine-learning based approach, to identify active heart failure cases automatically by analyzing electronic health records (EHR). For the rule-based approach, we extracted cardiovascular data elements from clinical notes and matched patients to different colors according their heart failure condition by using rules provided by experts in heart failure. It achieved 69.4% accuracy and 0.729 F1-Score. For the machine learning approach, with bigram of clinical notes as features, we tried four different models while SVM with linear kernel achieved the best performance with 87.5% accuracy and 0.86 F1-Score. Also, from the classification comparison between the four different models, we believe that linear models fit better for this problem. Once we combine the machine-learning and rule-based algorithms, we will enable hospital-wide surveillance of active heart failure through increased accuracy and interpretability of the outputs."}, {"heading": "Introduction", "text": "Reducing heart failure readmissions remains a major target for improving quality of care and reducing healthcare costs.1 A major component of this is identification of heart failure cases upon hospitalization. Early identification of patients with heart failure allows for early deployment of clinical resources to improve quality of care, continuity of care, and potentially reduce readmissions. The traditional model of accessing specialist care in hospitals relies upon placing a consultation request. Drawing from the operations management literature, this can be termed a \"push\" model of care delivery.2 A hallmark of push operations is operational delay, and potential inaccuracies in identifying patients who could benefit from more advanced resources. These flaws reduce health care quality and patient experience.\nIn contrast, hospital-wide surveillance by a central heart failure-focused team enables a \"pull\" model of specialist care and multidisciplinary intervention delivery. In a disease surveillance model, a disease-focused team specifically screens hospital admissions for the presence of that disease state, and calls front-line providers to offer specialist care. A pull model of consultation and provision of multidisciplinary care may reduce time lags and increase accuracy, thereby improving quality of care.\nAutomating identification of patients with heart failure admissions is possible by querying electronic health records (EHR). The use of discrete data from EHR is well established as a strategy for identification of disease states.3 The use of only discrete data, however, circumscribes the efficacy of automated detection methods by neglecting the rich clinical information embedded in free text such as clinical notes, radiological reports, and nursing notes. Natural language processing (NLP) is a strategy whereby clinical data can be mined from free text and meaningfully parsed into a format tractable for further processing by computational algorithms that enable machine learning. NLP, or Information extraction (to be precise) is the discovery by computers of new, previously unfound information, by automatically extracting information from different written resources.4 Earlier attempts were predominantly dictionary- or rule-based systems; however, most modern systems use supervised machine learning where a system is trained to recognize mentions in text based on specific (and numerous) features associated with the mentions that the system learns from annotated corpora. Unstructured information occurs in a wide variety of formats such as \u201ccalculated biplane LV ejection fraction is 37%\u201d or \u201cleft ventricular function is severely reduced.\u201d At a fundamental\nlevel, a medical concept such as a disease, treatment, or diagnostic test could be mentioned as a noun phrase \u2013 an incomplete sentence (ex: dry mucous membranes and myotic pupils), a complete sentence (ex: The patient had patent carotids bilaterally on her neck MRA), or as a list (ex: Tylenol 650 mg p.o. q. 4-6h p.r.n. headache or pain; acyclovir 400 mg p.o. t.i.d;). Despite active interest from clinicians in its potential,5 clinical information extraction is an unsolved problem.\nHere, we propose a natural language processing-based strategy for automated detection of heart failure cases, with high sensitivity and specificity, sufficient to enable operational use in a clinical setting."}, {"heading": "Methods", "text": ""}, {"heading": "Problem", "text": "We identified 3867 patients admitted to Northwestern Memorial Hospital between August and September 2015 with a possible diagnosis of heart failure. This initial screen was accomplished with an enterprise data warehouse query to identify patients with possible acute heart failure exacerbation. This screen primarily detects patients on the basis of receiving intravenous diuretic medications (used to remove fluid from patients with congestion), or with blood tests suggestive of heart failure (brain naturetic peptide greater than 100 ng/dl). The results of this EDW query were manually classified by a cardiologist and a nurse clinician, both expert in identification of patients with possible heart failure. Depicted in Table 1 is the classification schema. Although we have five colors here, in our algorithm, we treat Grey, Red and Purple as one class \u201cOther\u201d. Our goal here is to classify different patients to these three classes automatically by analyzing the EHR data automatically retrieved from the Northwestern Medicine Enterprise Data Warehouse (NMEDW)."}, {"heading": "Color Description", "text": ""}, {"heading": "System Overview", "text": "To decouple the system into simpler parts, we split our classification system into four components \u2013 Profile Builder, Data Element Extractor, Patient Classifier and Metrics Calculator. The system architecture is as shown in Figure 1.\nWe implemented two different classifiers \u2013 a rule-based classifier and a machine learning-based classifier. For the two classifiers, we only needed to change the implementation of the second and third components in their pipelines. That is, for the rule-based approach, we extracted data elements first and performed the matching of patients to colors by specific rules. For the machine learning-based approach, we built features for all patients\u2019 notes to build a feature matrix and then trained several models against this feature matrix.\nThe overall workflow works could be described as follows:\n1. The Profile Builder parses the raw data to patient profile, which is an aggregated JSON containing all his/her information. With this profile, we will be able to do analysis against each patient. 2. For the rule-based approach, the Data Elements Extractor extracts data elements from patient profile and then Rule-Based Classifier performs the classification according to extracted data elements. 3. For the machine learning based approach, the Feature Matrix Builder builds the feature matrix from patient profile and then Machine Learning-Based Classifier is trained to perform the classification.\n4. The Metric Calculator computes the metrics, including accuracy, recall, precision and F1-score according to classification result."}, {"heading": "Profile Builder", "text": "The raw data retrieved from the NMEDW are clinical notes generated by various doctors, nurses, and allied health professionals caring for a patient during a given hospitalization. Since we are doing the analysis against each patient, we built a profile for each patient by aggregating all their information into a JSON file containing all clinical notes of the patient."}, {"heading": "Rule Based Approach", "text": "The rule-based performs the classification by extracting proper data elements from patients\u2019 notes and matching the data elements to given classes according some rules. The intuition of this approach is simulating clinicians to do the choices.\nData Elements. Deciding data elements to be extracted needs a lot of domain knowledge. Table 1 shows the data elements we extracted to feed into classifier, which are five Boolean variables and will be feed into the rule-based classifier. These data elements are all compiled by experts in heart failure. Notice that we first extract keywords listed in the table, and then generate the data elements according to the keywords. For example, if we extracted keywords \u201ccardiology\u201d or \u201ccardiologist\u201d, we set the variable \u201cCardiology Consulted\u201d to be \u201cTrue\u201d, otherwise \u201cFalse\u201d.\nFor extracting these keywords, we defined regular expressions6 to match these keywords in the free text clinical notes. However, it is possible that we include some negated keywords during extraction. E.g. \u201cHe denies any symptomatic precipitants\u201d. Simple regex will not work for this case. So, we used NegEX7 to detect and exclude keywords in such negated statements.\nClassification Rules. When we have the data elements in structured form, we feed them into the rule-based classifier as shown in Figure 2. The classification rules are also recommended by experts in heart failure. This flowchart aims to classify patients to different groups by imitating the thought process of clinicians."}, {"heading": "Machine Learning-Based Approach", "text": "Features. Feature selection8-10 is very important in machine learning. In this approach, we experimented with several features including n-grams and UMLS concepts derived from cTAKES,11 etc. for each of the clinical notes in addition to the structured fields for each patient. Before extracting the features, we also performed preprocessing steps such as removing stop words, removing short words with less than four characters and replacing all numbers with a placeholder \u201cNUM\u201d. Then, we build feature matrix for each patient against these features.\nModel Training. We used 10-fold cross validation to train and evaluate the classifiers at a patient-level. In this approach, we picked four machine learning models, including Na\u00efve Bayes,12 SVM with RBF Kernel, SVM with Linear Kernel,13 and Logistic Regression,14 to test their performance and then selected the first one. All the classifiers are implemented by scikit-learn,15 an open source machine learning library.\nThere are two problems that need attention in this part. First, the data for each class is not balanced. Figure 3 shows the distribution for each class in our whole data set. From the figure, we can see that 82.3% of the patients belong to \u201cOthers\u201d while the \u201cGreen\u201d ones only count for 6.1%. To fix this problem, when we were training the model, we set a class weight for each class according to this data distribution. This effectively is equivalent to the oversampling technique16 used in machine learning for unbalanced training data. Second, the SVM and Logistic Regression models are not capable of classifying multiple classes directly. In this paper, we use the One-vs-Rest strategy,17 training a single classifier per class, with the samples of that class as positive samples and all other samples as negatives."}, {"heading": "Results", "text": "Rule-based Classification: Table 2 shows the classification result for rule-based classifier. We ran our algorithm against all 3834 patients and achieved 69.4% accuracy. However, we believe that with more domain knowledge the rule-based classifier will significantly improve.\nHere[1], for each class, we compute the count of True Positive (TP), True Negative (TN), False Positive (FP) and False Negative (FN) patients for each color first, and then compute the metrics as follows:\nMachine Learning-based Classification: Among all text-based features, we found that bigrams of patients\u2019 notes with document frequency between 0.2 and 0.8 as data elements produce models with higher accuracy. The bigram with lesser frequency tend to be outliers or spelling mistakes and those with higher frequency tend to be phrases such as \u201cconsulting physician\u201d that appear in most notes and not have any predictive power. There are 1816 such bigrams in our feature-set.\nFigure 4 shows the comparison of classification result between four models. We compared Precision, Recall, F1Score and Accuracy. From the figure, we can see that SVM with Linear Kernel has the best performance in all four parameters, while logistic regression is the second one. We believe that linear models fit better for this problem.\nTable 3 shows the detailed classification result using SVM with linear kernel, which outperformed all other models for each of the four metrics.\n\ud835\udc43\ud835\udc5f\ud835\udc52\ud835\udc50\ud835\udc60\ud835\udc56\ud835\udc5c\ud835\udc5b = \ud835\udc47\ud835\udc43\n\ud835\udc47\ud835\udc43 + \ud835\udc39\ud835\udc43\n\ud835\udc45\ud835\udc52\ud835\udc50\ud835\udc4e\ud835\udc59\ud835\udc59 = \ud835\udc47\ud835\udc43 \ud835\udc47\ud835\udc43 + \ud835\udc39\ud835\udc41\n\ud835\udc391 \u2212 \ud835\udc46\ud835\udc5c\ud835\udc50\ud835\udc5f\ud835\udc52 = 2\u2981 \ud835\udc43\ud835\udc5f\ud835\udc52\ud835\udc50\ud835\udc56\ud835\udc60\ud835\udc56\ud835\udc5c\ud835\udc5b\u2981\ud835\udc45\ud835\udc52\ud835\udc50\ud835\udc4e\ud835\udc59\ud835\udc59 \ud835\udc43\ud835\udc5f\ud835\udc52\ud835\udc50\ud835\udc56\ud835\udc60\ud835\udc56\ud835\udc5c\ud835\udc5b + \ud835\udc45\ud835\udc52\ud835\udc50\ud835\udc4e\ud835\udc59\ud835\udc59\n\ud835\udc34\ud835\udc50\ud835\udc50\ud835\udc62\ud835\udc5f\ud835\udc4e\ud835\udc50\ud835\udc66 = \u2211 \ud835\udc47\ud835\udc43!\"#\"$\n\u2211 \ud835\udc47\ud835\udc43!\"#\"$ + \u2211 \ud835\udc47\ud835\udc41 +!\"#\"$ \u2211 \ud835\udc39\ud835\udc43 + \u2211 \ud835\udc39\ud835\udc41!\"#\"$!\"#\"$"}, {"heading": "Discussion", "text": "We can make several important observations from the classification results of rule-based approach and machine learning-based approach. For the rule-based approach, precision of green class (Patient has active heart failure, but no cardiology service is consulted) is low since a lot of gray color records (Patient does not have heart failure) are misclassified as green. This is intentional in the design of the algorithm because clinically it is more important to capture all the heart failure cases, even at the expense of misclassifying non heart failure cases as active heart failure. Accuracy can be improved by further work in identifying words in documentation that represent heart failure, as well as extraction of concepts that mark for acuity of the condition. Furthermore, prediction is likely to increase significantly with the improvement and better use of NLP algorithms for context detection in better identifying whether heart failure mentions in text is active, historical or hypothetical.18 General purpose algorithms such as Context18 are not accurate enough and need to be adapted for our clinical notes. We will also need to use temporal resolution algorithms19 to identify the order and timing of events to ascertain whether a heart failure mention is active or not. From Table 3, we can see that machine-learning based approach achieves a better performance than rules-based approach, achieving 85% accuracy and 0.86 as F1-Score. It is able to identify to the patients that do not need to be screened for active heart failure with a high precision (95%) and high recall (90%). That is, if we use this system across Northwestern Medicine from which this sample is drawn, based on Figure 3 which shows that 82.3% of patients are classified as not heart-failure related, it is reasonable to believe that we will be able to automatically weed out 90% * 82.3% = 74.1% of patients from having to screen for active heart failure. The risk that 5% of the patients screened as not having active heart failure might have active heart failure has operational implications, but we are working with clinicians to render the predictions interpretable and also remove the features that are unrelated and might be leading to overfitting. For example, Table 4 shows the bigrams that the system found to be more predictive. Several of these bigrams such as \u201chealth care\u201d are not relevant for the task and will be removed in this process."}, {"heading": "Conclusion", "text": "Based on our result, we conclude that machine learning based approach has a better performance than rule-based approach, with 87.5% accuracy compared to 69.4%. However, our implementation of rule-based approach is not\ncomplete. We believe that it could be enhanced by classification rules learnt from machine learning algorithms. When combined, both the algorithms together will not only improve the results to make sure the system will be useful for hospital-wide surveillance of active heart failure, but will also make the classifications interpretable."}, {"heading": "Acknowledgments", "text": "We acknowledge support from the National Library of Medicine (grant R00LM011389 ) and the Bluhm Cardiovascular Institute (BCVI). Several BCVI clinicians and staff funded by them including Kalpana Raja, Corrine Benacka, Robin Fortman, Daniel Navarro, Preeti Kansal, Lynne Goodreau, and Hannah Alphs Jackson have assisted with data preparation and interpretation.\nReferences\n1. Soundarraj D, Singh V, Satija V, Thakur RK. Containing the Cost of Heart Failure Management: A Focus on Reducing Readmissions. Cardiac electrophysiology clinics 2015;7:577-84. 2. Spearman ML, Zazanis MA. Push and pull production systems: issues and comparisons. Operations research 1992;40:521-32. 3. Broberg CS, Mitchell J, Rehel S, et al. Electronic medical record integration with a database for adult congenital heart disease: Early experience and progress in automating multicenter data collection. International journal of cardiology 2015;196:178-82. 4. Hearst MA. Untangling text data mining. Proceedings of the 37th annual meeting of the Association for Computational Linguistics. College Park, Maryland1999:3-10. 5. Maddox TM, Matheny MA. Natural Language Processing and the Promise of Big Data: Small Step Forward, but Many Miles to Go. Circulation: Cardiovascular Quality and Outcomes 2015. 6. McNaughton R, Yamada H. Regular expressions and state graphs for automata. IEEE Transactions on Electronic Computers 1960;1:39-47. 7. Chapman WW, Bridewell W, Hanbury P, Cooper GF, Buchanan BG. Evaluation of negation phrases in narrative clinical reports. Proc AMIA Symp 2001:105-9. 8. Hall MA. Correlation-based feature selection for machine learning. The University of Waikato; 1999. 9. Bejan CA, Xia F, Vanderwende L, Wurfel MM, Yetisgen-Yildiz M. Pneumonia identification using statistical feature selection. . Journal of the American Medical Informatics Association 2012.;19:817-23. 10. Emadzadeh E, Jonnalagadda S, Gonzalez G. Evaluating Distributional Semantic and Feature Selection for Extracting Relationships from Biological Text. 10th International Conference on Machine Learning and Applications and Workshops (ICMLA); 2011 18-21 Dec. 2011. p. 66-71. 11. Savova GK, Masanz JJ, Ogren PV, et al. Mayo clinical Text Analysis and Knowledge Extraction System (cTAKES): architecture, component evaluation and applications. Journal of the American Medical Informatics Association : JAMIA 2010;17:507-13. 12. McCallum A, Nigam K. A comparison of event models for naive bayes text classification1998. 13. Joachims T. Text categorization with Support Vector Machines: Learning with many relevant features. Machine Learning: ECML-98, Tenth European Conference on Machine Learning 1998:137-42. 14. Press SJ, Wilson S. Choosing between logistic regression and discriminant analysis. J Am Stat Assoc 1978;73:699-705. 15. Pedregosa F, Varoquaux G, Gramfort A, et al. Scikit-learn: Machine learning in Python. The Journal of Machine Learning Research 2011;12:2825-30. 16. Chawla NV, Bowyer KW, Hall LO, Kegelmeyer WP. SMOTE: synthetic minority over-sampling technique. Journal of artificial intelligence research 2002:321-57. 17. Hong J-H, Cho S-B. A probabilistic multi-class strategy of one-vs.-rest support vector machines for cancer classification. Neurocomputing 2008;71:3275-81. 18. Harkema H, Dowling JN, Thornblade T, Chapman WW. ConText: an algorithm for determining negation, experiencer, and temporal status from clinical reports. J Biomed Inform 2009;42:839-51. 19. Sohn S, Wagholikar KB, Li D, et al. Comprehensive temporal information detection from clinical text: medical events, time, and TLINK identification. J Am Med Inform Assoc 2013;20:836-42."}], "references": [{"title": "Containing the Cost of Heart Failure Management: A Focus on Reducing Readmissions. Cardiac electrophysiology clinics 2015;7:577-84", "author": ["D Soundarraj", "V Singh", "V Satija", "RK. Thakur"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Push and pull production systems: issues and comparisons. Operations research 1992;40:521-32", "author": ["Spearman ML", "Zazanis MA"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1992}, {"title": "Electronic medical record integration with a database for adult congenital heart disease: Early experience and progress in automating multicenter data collection. International journal of cardiology 2015;196:178-82", "author": ["CS Broberg", "J Mitchell", "S Rehel"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Untangling text data mining. Proceedings of the 37th annual meeting of the Association for Computational Linguistics", "author": ["Hearst MA"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1999}, {"title": "Natural Language Processing and the Promise of Big Data: Small Step Forward, but Many Miles to Go. Circulation: Cardiovascular Quality and Outcomes", "author": ["Maddox TM", "Matheny MA"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Regular expressions and state graphs for automata", "author": ["R McNaughton", "H. Yamada"], "venue": "IEEE Transactions on Electronic Computers", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1960}, {"title": "Evaluation of negation phrases in narrative clinical reports", "author": ["WW Chapman", "W Bridewell", "P Hanbury", "GF Cooper", "BG. Buchanan"], "venue": "Proc AMIA Symp 2001:105-9", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2001}, {"title": "Correlation-based feature selection for machine learning", "author": ["Hall MA"], "venue": "The University of Waikato;", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1999}, {"title": "Pneumonia identification using statistical feature selection", "author": ["CA Bejan", "F Xia", "L Vanderwende", "MM Wurfel", "M. Yetisgen-Yildiz"], "venue": "Journal of the American Medical Informatics Association", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Evaluating Distributional Semantic and Feature Selection for Extracting Relationships from Biological Text", "author": ["E Emadzadeh", "S Jonnalagadda", "G. Gonzalez"], "venue": "10th International Conference on Machine Learning and Applications and Workshops (ICMLA);", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Mayo clinical Text Analysis and Knowledge Extraction System (cTAKES): architecture, component evaluation and applications", "author": ["GK Savova", "JJ Masanz", "PV Ogren"], "venue": "Journal of the American Medical Informatics Association", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2010}, {"title": "A comparison of event models for naive bayes text classification1998", "author": ["A McCallum", "K. Nigam"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1998}, {"title": "Text categorization with Support Vector Machines: Learning with many relevant features. Machine Learning: ECML-98", "author": ["T. Joachims"], "venue": "Tenth European Conference on Machine Learning", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1998}, {"title": "Choosing between logistic regression and discriminant analysis", "author": ["SJ Press", "S. Wilson"], "venue": "J Am Stat Assoc 1978;73:699-705", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1978}, {"title": "Scikit-learn: Machine learning in Python. The Journal of Machine Learning Research 2011;12:2825-30", "author": ["F Pedregosa", "G Varoquaux", "A Gramfort"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2011}, {"title": "SMOTE: synthetic minority over-sampling technique", "author": ["NV Chawla", "KW Bowyer", "LO Hall", "WP. Kegelmeyer"], "venue": "Journal of artificial intelligence research 2002:321-57", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2002}, {"title": "A probabilistic multi-class strategy of one-vs.-rest support vector machines for cancer", "author": ["Hong J-H", "Cho S-B"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}, {"title": "ConText: an algorithm for determining negation, experiencer, and temporal status from clinical reports", "author": ["H Harkema", "JN Dowling", "T Thornblade", "WW. Chapman"], "venue": "J Biomed Inform 2009;42:839-51", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "Comprehensive temporal information detection from clinical text: medical events, time, and TLINK identification", "author": ["S Sohn", "KB Wagholikar", "D Li"], "venue": "J Am Med Inform Assoc 2013;20:836-42", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "Here[1], for each class, we compute the count of True Positive (TP), True Negative (TN), False Positive (FP) and False Negative (FN) patients for each color first, and then compute the metrics as follows:", "startOffset": 4, "endOffset": 7}], "year": 2016, "abstractText": "In this paper, we proposed two different approaches, a rule-based approach and a machine-learning based approach, to identify active heart failure cases automatically by analyzing electronic health records (EHR). For the rule-based approach, we extracted cardiovascular data elements from clinical notes and matched patients to different colors according their heart failure condition by using rules provided by experts in heart failure. It achieved 69.4% accuracy and 0.729 F1-Score. For the machine learning approach, with bigram of clinical notes as features, we tried four different models while SVM with linear kernel achieved the best performance with 87.5% accuracy and 0.86 F1-Score. Also, from the classification comparison between the four different models, we believe that linear models fit better for this problem. Once we combine the machine-learning and rule-based algorithms, we will enable hospital-wide surveillance of active heart failure through increased accuracy and interpretability of the outputs.", "creator": "Word"}}}