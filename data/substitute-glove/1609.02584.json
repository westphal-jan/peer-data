{"id": "1609.02584", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Sep-2016", "title": "Towards Better Response Times and Higher-Quality Queries in Interactive Knowledge Base Debugging", "abstract": "Many AI applications need making knowledge encoded from put locigal knowledge base (KB ). The most essential contribution important such plausible KBs both the opportunity hold done automatic analytic several particular allowing a KB making hoped say minimal improve criteria such as consistency. Without adequate technologies need, the force but dialogue among forbids quality necessarily time a KB so be extremely look, are one early fundamentally KB comes large has build. To a after, database KB spread-spectrum while both introduced taken ask into cards queries fact certain contradictory help or determined anyone meeting in the intended domain. The one readers help to adjust regulated followed provide space that KB necessitating.", "histories": [["v1", "Thu, 8 Sep 2016 20:48:32 GMT  (493kb,D)", "http://arxiv.org/abs/1609.02584v1", null], ["v2", "Tue, 30 May 2017 09:57:45 GMT  (525kb,D)", "http://arxiv.org/abs/1609.02584v2", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["patrick rodler"], "accepted": false, "id": "1609.02584"}, "pdf": {"name": "1609.02584.pdf", "metadata": {"source": "CRF", "title": "Towards Better Response Times and Higher-Quality Queries in Interactive Knowledge Base Debugging", "authors": ["Patrick Rodler"], "emails": ["patrick.rodler@aau.at"], "sections": [{"heading": null, "text": "To this end, interactive KB debuggers have been introduced which solve soundness, completeness and scalability problems of non-interactive debugging systems. User interaction takes place in the form of queries asked to a person, e.g. a domain expert. A query is a number of (logical) statements and the user is asked whether these statements must or must not hold in the intended domain that should be modeled by the KB. To construct a query, a minimal set of two solution candidates, i.e. possible KB repairs, must be available. After the answer to a query is known, the search space for solutions is pruned. Iteration of this process until there is only a single solution candidate left yields a repaired KB which features exactly the semantics desired and expected by the user.\nExisting interactive debuggers often rely on a pool-based strategy for query computation. A pool of query candidates is precomputed, from which the best (or a sufficiently good) candidate according to some query quality criterion is selected to be shown to the user. This often leads to the generation of many unnecessary query candidates and thus to a high number of expensive calls to logical reasoning services. Such an overhead can have a severe impact on the response time of the interactive debugger, i.e. the time between two consecutive queries. The actual problem of this approach is the quantitative nature of the query quality functions used to assess the goodness of queries. These functions more or less provide only a black-box to use in a trial-and-error search for acceptable queries. We tackle this issue by an in-depth mathematical analysis of diverse quantitative active learning query selection measures published in literature in order to determine qualitative criteria that make a query favorable from the viewpoint of a given measure. These qualitative criteria are our key to devise efficient heuristic query search methods. This proposed approach involves a three-staged optimization of a query.\nFor the first stage, we introduce a new, theoretically well-founded and sound method for query generation that works completely without the use of logical reasoners. This method is based on the notion of canonical queries. Together with the developed heuristics, it enables to compute an (arbitrarily near to) optimal canonical query w.r.t. a given quality measure, e.g. information gain. For one canonical query, in general, multiple queries with the same quality w.r.t. the measure exist.\nTo this end, we show that a hitting set tree search (second stage) can be employed to extract the best query among these w.r.t. additional criteria such as minimum cardinality or best understandability for\nar X\niv :1\n60 9.\n02 58\n4v 1\n[ cs\n.A I]\n8 S\nep 2\n01 6\nthe user. This search does not rely on logical reasoners either. With existing methods, the extraction of such queries is not (reasonably) possible. They can just calculate any set-minimal query.\nConsequently, this work for the first time proposes algorithms that enable a completely reasonerfree query generation for interactive KB debugging while at the same time guaranteeing optimality conditions of the generated query that existing methods cannot realize.\nIn the third query optimization stage, which is optional, the one already computed query which optimizes a given quality measure and some of the additional criteria, can be enriched by further logical statements of very simple and easily conceivable form and afterwards be minimized again. The reason of these optional steps, involving altogether only a polynomial number of reasoner calls, can be the simplification of the statements comprised in the query. The new approach we propose for accomplishing this improves the existing algorithm for query minimization insofar as it guarantees the finding of the query that is easiest to answer for the interacting user under plausible assumptions.\nFurthermore, we study different relations between diverse active learning measures, e.g. superiority and equivalence relations. The obtained picture gives a hint about which measures are more favorable in which situation or which measures always lead to the same outcomes, based on given types of queries.\nContents"}, {"heading": "1 Introduction 5", "text": ""}, {"heading": "2 Preliminaries 10", "text": "2.1 Assumptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 2.2 Knowledge Base Debugging: Basics . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 2.3 Interactive Knowledge Base Debugging: Basics . . . . . . . . . . . . . . . . . . . . . . 16"}, {"heading": "3 Query Computation 21", "text": "3.1 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 3.2 Active Learning in Interactive Debugging . . . . . . . . . . . . . . . . . . . . . . . . . 25\n3.2.1 Query Quality Measures: Preliminaries and Definitions . . . . . . . . . . . . . . 26 3.2.2 Existing Active Learning Measures for KB Debugging . . . . . . . . . . . . . . 31 3.2.3 New Active Learning Measures for KB Debugging . . . . . . . . . . . . . . . . 40 3.2.4 Risk-Optimized Active Learning Measure . . . . . . . . . . . . . . . . . . . . . 60 3.2.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n3.3 Q-Partition Requirements Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66 3.4 Finding Optimal Q-Partitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\n3.4.1 Canonical Queries and Q-Partitions . . . . . . . . . . . . . . . . . . . . . . . . 73 3.4.2 Search Completeness Using Only Canonical Q-Partitions . . . . . . . . . . . . . 79 3.4.3 The Search for Q-Partitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84 3.4.4 Q-Partition Successor Computation . . . . . . . . . . . . . . . . . . . . . . . . 94\n3.5 Finding Optimal Queries Given an Optimal Q-Partition . . . . . . . . . . . . . . . . . . 100 3.6 Query Enrichment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106 3.7 Query Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108\n4 Summary and Conclusion 119\nList of Figures 1 The Principle of Interactive KB Debugging . . . . . . . . . . . . . . . . . . . . . . . . 7 2 The Superiority Relationship Graph . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\nList of Tables 1 Propositional Logic Example DPI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 2 Example: Minimal Diagnoses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 3 Example: Minimal Conflict Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 4 Example: Preference Order on Queries Induced by Measures . . . . . . . . . . . . . . . 40 5 Example: Diagnosis Probabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 6 Debug-Preference Relation and Theoretical Optima . . . . . . . . . . . . . . . . . . . . 67 7 Equivalence Classes of Measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69 8 Qualitative Requirements for Equivalence Classes of Measures . . . . . . . . . . . . . . 70 9 Qualitative Requirements for All Measures . . . . . . . . . . . . . . . . . . . . . . . . 72 10 Propositional Logic Example DPI 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78 11 Example: Canonical Queries and Q-Partitions . . . . . . . . . . . . . . . . . . . . . . . 78\nList of Algorithms 1 Interactive KB Debugging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 2 Query Computation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 3 D+-Partitioning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87 4 Update of Best Q-Partition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112 5 Optimality Check . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113 6 Pruning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114 7 Finding the Best Successor Q-Partition . . . . . . . . . . . . . . . . . . . . . . . . . . . 115 8 Computation of Successor Q-Partitions . . . . . . . . . . . . . . . . . . . . . . . . . . . 116 9 Computation of Set-Minimal Queries From Q-Partition . . . . . . . . . . . . . . . . . . 117 10 Query Enrichment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118 11 Query Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118"}, {"heading": "1 Introduction", "text": "As nowadays artificial intelligence applications become more and more ubiquitous and undertake ever more critical tasks, e.g. in the medical domain or in autonomous vehicles, the quality of the underlying logical knowledge bases (KBs) becomes absolutely crucial. A concrete example of a repository containing KBs that are partly extensively used in practical applications is the Bioportal,1 which comprises vast biomedical ontologies with tens or even hundreds of thousands of terms each. One of these huge ontologies is SNOMED-CT, the most comprehensive, multilingual clinical healthcare terminology in the world with over 316.000 terms which is currently used as a basis for diverse eHealth applications in more than fifty countries.2 Such KBs pose a significant challenge for people as well as tools involved in their evolution, maintenance, application and quality assurance.\nSimilar to programming languages which allow people to use syntax (instructions) to express a desired semantics, i.e. what the program should do, a KB consists of syntactical expressions (logical formulas) that should have an intended semantics, i.e. describe a domain of interest in a correct way. The quality of a KB is then usually measured in terms of how well the KB models the application domain. In more concrete terms, the quality criteria are constituted by a set of test cases (assertions that must and assertions that must not hold in the intended domain) and a set of general requirements (e.g. logical consistency). This is again an analogon to familiar practices known from the area of software engineering. There, test cases are exploited to verify the semantics of the program code, i.e. to check whether the program exhibits the expected behavior. A general quality requirement imposed on software might be that the code must be compilable, otherwise it is completely useless, and so is an inconsistent KB, which prohibits meaningful automatic reasoning to derive implicit knowledge or to answer queries about the modeled domain.\nTo cope with such faulty KBs (violating test cases and/or requirements), diverse systems for KB debugging [24, 8, 3, 5] have been developed. However, due to the complexity of the subproblems that must be solved by a KB debugger, e.g. the Hitting Set Problem [10] for localization of possible KB repairs or the SAT Problem [10] for reasoning and consistency checking (in case of a Propositional Logic KB, worse for more expressive logics, e.g. the Web Ontology Language OWL 2, for which reasoning is 2-NEXPTIME-complete [4, 11]), the usage of such non-interactive systems is often problematic. This is substantiated by [29] where several (non-interactive) debugging systems were put to the test using faulty real-world KBs. The result was that most of the investigated systems had serious performance problems, ran out of memory, were not able to locate all the existing faults in the KB (incompleteness), reported parts of a KB as faulty which actually were not faulty (unsoundness), produced only trivial solutions or suggested non-minimal faults (non-minimality).\nApart from these problems, a general problem of abductive inference (of which debugging is an instance [20, p. 8]) is that there might be a potentially huge number of competing solutions or, respectively, explanations for the faultiness of a KB in KB debugging terms. These explanations are called diagnoses. For example, in [26] a sample study of real-world KBs revealed that the number of different (set-)minimal diagnoses might exceed thousand by far (1782 minimal diagnoses for a KB with only 1300 formulas). Without the option for a human (e.g. a domain expert) to take part actively in the debugging process to provide the debugging system with some guidance towards the correct diagnosis, the system cannot do any better than outputting the best (subset of all) possible solution(s) w.r.t. some criterion. An example of such a criterion is the maximal probability regarding some given, e.g. statistical, meta information about faults in the KB.\nHowever, any two solution KBs resulting from the KB repair using two different minimal diagnoses have different semantics in terms of entailed and non-entailed formulas [20, Sec. 7.6]. Additionally, fault meta information might be misleading [21, 27] resulting in completely unreasonable solutions proposed by the system. Selecting a wrong diagnosis can lead to unexpected entailments or non-entailments, lost\n1http://bioportal.bioontology.org 2http://www.ihtsdo.org/snomed-ct\ndesired entailments and surprising future faults when the KB is further developed. Manual inspection of a large set of (minimal) diagnoses is time-consuming, error-prone, and often simply practically infeasible or computationally infeasible due to the complexity of diagnosis computation.\nAs a remedy for this dilemma, interactive KB debugging systems [26, 27, 21, 20, 28] were proposed. These aim at the gradual reduction of compliant minimal diagnoses by means of user interaction, thereby seeking to prevent the search tree for minimal diagnoses from exploding in size by performing regular pruning operations. Throughout an interactive debugging session, the user, usually a (group of) KB author(s) and/or domain expert(s), is asked a set of automatically chosen queries about the intended domain that should be modeled by a given faulty KB. A query can be created by the system after a set D of a minimum of two minimal diagnoses has been precomputed (we call D the leading diagnoses). Each query is a conjunction (i.e. a set) of logical formulas that are entailed by some subset of the formulas in the KB which does not violate any test cases or requirements. With regard to one particular query Q, any set of minimal diagnoses for the KB, in particular the set D which has been utilized to generate Q, can be partitioned into three sets, the first one (D+) including all diagnoses in D compliant only with a positive answer to Q, the second (D\u2212) including all diagnoses in D compliant only with a negative answer to Q, and the third (D0) including all diagnoses in D compliant with both answers. A positive answer to Q signalizes that the conjunction of formulas inQmust be entailed by the correct KB whyQ is added to the set of positive test cases. Likewise, if the user negates Q, this is an indication that at least one formula in Q must not be entailed by the correct KB. As a consequence, Q is added to the set of negative test cases.\nAssignment of a query Q to either set of test cases results in a new debugging scenario. In this new scenario, all elements of D\u2212 (and usually further diagnoses that have not yet been computed) are no longer minimal diagnoses given thatQ has been classified as a positive test case. Otherwise, all diagnoses in D+ (and usually further diagnoses that have not yet been computed) are invalidated. In this vein, the successive reply to queries generated by the system will lead the user to the single minimal solution diagnosis that perfectly reflects their intended semantics. In other words, after deletion of all formulas in the solution diagnosis from the KB and the addition of the conjunction of all formulas in the specified positive test cases to the KB, the resulting KB meets all requirements and positive as well as negative test cases. In that, the added formulas contained in the positive test cases serve to replace the desired entailments that are broken due to the deletion of the solution diagnosis from the KB.\nThence, in the interactive KB debugging scenario the user is not required to cope with the understanding of which faults (e.g. sources of inconsistency or implications of negative test cases) occur in the faulty initial KB, why these are faults (i.e. why particular entailments are given and others not) and how to repair them. All these tasks are undertaken by the interactive debugging system. The user is just required to answer queries whether certain assertions should or should not hold in the intended domain.\nThe schema of an interactive debugging system is pictured by Figure 1. The system receives as input a diagnosis problem instance (DPI) consisting of\n\u2022 some KB K formulated using some (monotonic) logical language L (every formula in K might be correct or faulty),\n\u2022 (optionally) some KB B formalizing some background knowledge relevant for the domain modeled by K (such that B and K do not share any formulas; all formulas in B are considered correct)\n\u2022 a set of requirements R to the correct KB,\n\u2022 sets of positive (P ) and negative (N ) test cases (over L) asserting desired semantic properties of the correct KB\nand (optionally) some fault information, e.g. in terms of fault probabilities of logical formulas in K. Further on, a range of additional parameters Tuning Params might be provided to the system. These serve as a means to fine-tune the system\u2019s behavior in various aspects. For an explanation of these parameters\nthe reader is referred to [20]. The system outputs a repaired solution KB which is built from a minimal diagnosis which has a sufficiently high probability where some predefined parameter in Tuning Params determines what \u201csufficiently\u201d means. Note that we address debugging systems in this work which use the reasoning services provided by a logical reasoner in a black-box manner. That is, it is assumed that no influence can be taken on the way reasoning is performed which means in particular that no operations instrumental to the debugging task as such must be conducted by the reasoner (cf. [20, p. 6] [9]).\nThe workflow implemented by existing interactive KB debugging systems illustrated by Figure 1 is the following:\n1. A set of leading diagnoses D is computed by the diagnosis engine (by means of the fault information, if available) using the logical reasoner and passes it to the query generation module.\n2. The query generation module computes a pool of queries exploiting the set of leading diagnoses and delivers it to the query selection module.\n3. The query selection module filters the \u201cbest query\u201d according to some query quality measure (QQM) m (often by means of the fault information, if available) from the given pool of queries and shows it to the interacting user.\n4. The user submits an answer to the query. (Alternatively, the user might reject the query and request surrogate queries as long as there are alternative queries left.)\n5. The query along with the given answer is used to formulate a new test case.\n6. This new test case is transferred back to the diagnosis engine and taken into account in prospective iterations. If some predefined (stop) criterion (e.g. sufficiently high probability of one leading diagnosis) is not met, another iteration starts at step 1. Otherwise, the solution KB K\u2217 constructed from the currently best minimal diagnosis w.r.t. the given criterion is output.\nIn this work, we want to lay the focus on steps 2 and 3 in this process. In [20, Sec. 8.6], a range of shortcomings of this query computation strategy (called the pool-based strategy, PoSt for short) has been identified and discussed. PoSt is implemented as a two-step procedure involving first a precomputation of a pool of possible queries (step 2) and a subsequent selection of the best query from this pool (step 3). The rest of this work provides a well-founded theoretical framework and algorithms built upon it that serve to remedy all deficiencies of this mechanism of provisioning queries. In particular, we aim on the one hand\nat improving the performance (time and space) of the query computation component. Since debugging systems like the one considered in this work use the logical reasoner as a black-box and since reasoning costs during a debugging session amount to a very high ratio (up to 93.4% reported in [28]) of overall debugging costs, it is material to reduce the number of reasoner calls in order to achieve a performance gain in KB debugging. For that reason we will present methods that enable to generate an optimized query without any calls to a reasoner. Another goal is the minimization of the overall effort for the user both in terms of the number as well as in terms of the size and difficulty of queries that a user needs to answer in order to filter out the correct diagnosis. To this end, we will provide algorithms that minimize the probability of getting the wrong answer by the user under plausible assumptions and we will describe various query selection measures that aim at minimizing the remaining number of queries that need to be answered by the user in order to get a sufficiently optimal repaired KB. The particular problems of PoSt and our basic ideas of how to resolve them are given next.\nFirst, due to the generally exponential size of the query pool, PoSt has exponential time and space complexity regarding the parameter |D|. If the decision is to include only a small subset of queries in the pool to save resources, then no guarantees about the quality of the queries (regarding the QQM m) in the pool can be given. For instance, in the worst case one might happen to capture a subset of cardinality x including the x least favorable queries w.r.t. m using this approach. The quality of the returned query (which is selected only from this pool) will of course be severely affected by such a disadvantageous choice. As a key to solving this issue we suggest the use of a different paradigm, namely a heuristicsearch-based strategy, which does not rely on the computation of a query pool. Instead, it enables a direct search for a query with arbitrarily good value ofm based on some heuristics. Note that usuallym is some quantitative measure that assigns a real-valued number to each query, in this way signalizing the best query as the one that has a minimal (or maximal) value. However, in order to derive suitable heuristics from a quantitative QQM m, we transform m into a set of qualitative criteria that must be met in order to optimize a query w.r.t. m. From these qualitative criteria, most of the heuristics can be extracted in a straightforward way. Whereas in literature only three measures, namely split-in-half, entropy and RIO [27, 21, 20, 28, 26], have been analyzed and discussed, we investigate eight further (active learning [25]) measures that might be favorably employed in interactive debuggers and deduce heuristics from them.\nSecond, a crucial problem of PoSt is the extensive use of reasoning services (O(|D|) calls for each query in the pool) which must be considered computationally very expensive in the light of the fact that reasoning for (the relatively inexpressive) Propositional Logic is already NP-complete. Reasoners are (1) applied by PoSt to calculate a query candidate as a set of entailments of a non-faulty part of the faulty KB, and (2) to compute in advance a so called q-partition, a partition of the leading diagnoses D, for each query candidate. One the one hand, the q-partition serves to test whether a query candidate is indeed a query, and on the other hand it is a prerequisite for the determination of the goodness of a query w.r.t. a QQM. The idea enabling a significant reduction of reasoner dependence is to compute some well-defined canonical query which facilitates the construction of the associated (canonical) qpartition without reasoning aid by using just set comparisons. In this vein, guided by the qualitative criteria mentioned before, a search for the best q-partition, and hence the best query w.r.t. a QQM, can be accomplished without reasoning at all. Another side effect of the reliance upon canonical queries is the natural and proven guarantee that no computation time can be wasted (1) for the generation of query candidates which turn out to be no queries, and (2) for queries that have unfavorable discrimination properties w.r.t. the leading diagnoses, i.e. for which some leading diagnoses remain valid independently of the query answer. Such potential overhead (1) cannot be avoided in PoSt, (2) only by means of postulations about the used reasoning engine (cf. [20, Prop. 8.3, p. 107]).\nHaving found a sufficiently good q-partition, as a next step the canonical query can usually be reduced to a query of smaller size, including fewer logical formulas. For, there are generally exponentially many different queries w.r.t. a fixed q-partition (even if we neglect syntactic variants of queries with equal semantics). Whereas PoSt methods require O(k log nk ) calls to a reasoning engine for the minimization\nof a single query (of size n) and cannot guarantee that the minimized query (of size k) satisfies certain desired properties such as minimal cardinality, our canonical-query-based approach is able to extract minimal queries in a best-first manner according to the given desired properties without reasoning at all. For instance, given some information about faults the interacting user is prone to, this could be exploited to estimate how well this user might be able to understand and answer a query. Assume the case that the user frequently has problems to apply \u2203 in a correct manner to express what they intend to express, but has never made any mistakes in formulating implications\u2192. Then the First-order Logic query Q1 = {\u2200X p(X)\u2192 q(X)} might be better comprehended than Q2 = {\u2200X\u2203Y s(X,Y )}. This principle can be exploited to let our algorithm find the query with minimal estimated answer fault probability. Hence, among the exponentially many queries with the same q-partition \u2013 and thus optimal properties as per some QQM \u2013 the presented algorithms can find the best query according to some secondary criteria in a very efficient way. Neither the usage of any secondary criteria nor the achieved efficiency can be granted by PoSt.\nOptionally, if requested by the user, the best minimized query can be enriched with additional logical formulas with a predefined simple syntax (aiming at better user comprehension of query formulas), e.g. atoms or definite clauses in case of a Propositional Logic KB. We demonstrate how such an enrichment can be realized in a way the optimality (q-partition) of the query w.r.t. the given QQM is preserved.\nFinally, we show how a well-known divide-and-conquer technique [7] can be adapted to compute a set-minimal reduction of the enriched query (keeping the q-partition and optimality w.r.t. the QQM constant) which is easiest to comprehend for the user (assessed based on given fault information) among all set-minimal reductions. All algorithms introduced in this work are described in detail and formally proven correct.\nThe rest of this work is organized as follows. Section 2 represents an introductory section which provides the reader with our main assumptions, e.g. monotonicity of the used logic, (Section 2.1) and with extensively exemplified basics on KB Debugging (Section 2.2) and Interactive KB Debugging (Section 2.3). Subsequently, Section 3 delves into the details of the new query computation strategies. First, various active learning QQM measures are discussed and transformed to qualitative criteria to fit into our KB debugging scenario (Section 3.2). Second, heuristics are derived for each measure (Section 3.3). Third, the finding of an optimal q-partition by means of the notion of canonical queries is addressed (Section 3.4) by initially deriving some useful theoretical results that provide a basis for our formally defined heuristic search technique. We discuss the completeness of the proposed search and specify optimality conditions, conditions for best successor nodes and pruning conditions for all discussed QQM measures based on the qualitative criteria established earlier. Third, we deal with the identification of the best query w.r.t. the optimal q-partition (Section 3.5). Fourth, we explain how a q-partition-preserving query enrichment can be executed (Section 3.6) and, fifth, we demonstrate a technique to extract the easiest query from the enriched query (Section 3.7). Section 4 summarizes our results and concludes."}, {"heading": "2 Preliminaries", "text": "In this section, we guide the reader through the basics of (interactive) KB debugging, list the assumptions made and illustrate the concepts by several examples."}, {"heading": "2.1 Assumptions", "text": "The techniques described in this work are applicable for any logical knowledge representation formalism L for which the entailment relation is\n(L1) monotonic: is given when adding a new logical formula to a KB KL cannot invalidate any entailments of the KB, i.e. KL |= \u03b1L implies that KL \u222a {\u03b2L} |= \u03b1L,\n(L2) idempotent: is given when adding implicit knowledge explicitly to a KB KL does not yield new entailments of the KB, i.e. KL |= \u03b1L and KL \u222a {\u03b1L} |= \u03b2L implies KL |= \u03b2L and\n(L3) extensive: is given when each logical formula entails itself, i.e. {\u03b1L} |= \u03b1L for all \u03b1L,\nand for which\n(L4) reasoning procedures for deciding consistency and calculating logical entailments of a KB are available,\nwhere \u03b1L, \u03b2L are logical sentences and KL is a set { ax (1) L , . . . , ax (n) L } of logical formulas formulated\nover the language L. KL is to be understood as the conjunction \u2227n i=1 ax (i) L .\n3 Examples of logics that comply with these requirements include, but are not restricted to Propositional Logic, Datalog [2], (decidable fragments of) First-order Predicate Logic, The Web Ontology Language (OWL [18], OWL 2 [4, 15]), sublanguages thereof such as the OWL 2 EL Profile (with polynomial time reasoning complexity [12]) or various Description Logics [1]."}, {"heading": "2.2 Knowledge Base Debugging: Basics", "text": "KB debugging can be seen as a test-driven procedure comparable to test-driven software development and debugging. The process involves the specification of test cases to restrict the possible faults until the user detects the actual fault manually or there is only one (highly probable) fault remaining which is in line with the specified test cases.\nThe KB Debugging Problem. The inputs to a KB debugging problem can be characterized as follows: Given is a KB K and a KB B (background knowledge), both formulated over some logic L complying with the conditions (L1) \u2013 (L4) given above. All formulas in B are considered to be correct and all formulas in K are considered potentially faulty. K \u222a B does not meet postulated requirements R where {consistency} \u2286 R \u2286 {coherency, consistency} or does not feature desired semantic properties, called test cases.4 Positive test cases (aggregated in the set P ) correspond to desired entailments and negative test cases (aggregated in the set N ) represent undesired entailments of the correct (repaired) KB (together with the background KB B). Each test case p \u2208 P and n \u2208 N is a set of logical formulas over L. The meaning of a positive test case p \u2208 P is that the union of the correct KB and B must entail each formula\n3Please note that we will omit the index L for brevity when referring to formulas or KBs over L throughout the rest of this work. However, whenever L appears in the text (e.g. in proofs), we bear in mind that any KB we speak of is formulated over L and that L meets all the conditions given above.\n4We assume consistency a minimal requirement to a solution KB provided by a debugging system, as inconsistency makes a KB completely useless from the semantic point of view.\n(or the conjunction of formulas) in p, whereas a negative test case n \u2208 N signalizes that some formula (or the conjunction of formulas) in n must not be entailed by this union.\nRemark 1 In the sequel, we will write K |= X for some set of formulas X to denote that K |= ax for all ax \u2208 X and K 6|= X to state that K 6|= ax for some ax \u2208 X . When talking about a singleton X = {x1}, we will usually omit the brackets and write K |= x1 or K 6|= x1, respectively.\nThe described inputs to the KB debugging problem are captured by the notion of a diagnosis problem instance:\nDefinition 1 (Diagnosis Problem Instance). Let\n\u2022 K be a KB over L,\n\u2022 P ,N sets including sets of formulas over L,\n\u2022 {consistency} \u2286 R \u2286 {coherency, consistency},5\n\u2022 B be a KB over L such that K \u2229 B = \u2205 and B satisfies all requirements r \u2208 R, and\n\u2022 the cardinality of all sets K, B, P , N be finite.\nThen we call the tuple \u3008K,B,P ,N \u3009R a diagnosis problem instance (DPI) over L.6\n5Coherency was originally defined for Description Logic (DL) KBs [24, 17] and postulates that there is no concept C in a DL KB KDL such that KDL |= C v \u22a5. Translated to a First-order Predicate Logic KB KFOL and generalized to not only unary predicate symbols, this means that there must not be any k-ary predicate symbol for k \u2265 1 in KFOL such that KFOL |= \u2200X1, . . . , Xk \u00acp(X1, . . . , Xk).\n6 In the following we will often call a DPI overL simply a DPI for brevity and since the concrete logic will not be relevant to our theoretical analyses as long as it is compliant with the conditions (L1) \u2013 (L4) given at the beginning of this section. Nevertheless we will mean exactly the logic over which a particular DPI is defined when we use the designator L.\nExample 1 An example of a Propositional Logic DPI is depicted by Table 1. This DPI will serve as a running example throughout this paper. It includes seven KB axioms ax 1, . . . , ax 7 in K, two axioms ax 8, ax 9 belonging to the background KB, one singleton positive test case p1 and three singleton negative test cases n1, . . . ,n3. There is one requirement imposed on the correct (repaired) KB, namely r1, which corresponds to consistency. It is easy to verify that the standalone KB B = {ax 8, ax 9} is consistent, i.e. satisfies all r \u2208 R and that K \u2229 B = \u2205. Note that we omitted the set brackets for the test cases, i.e. lines for pi or ni might comprise more than one formula in case the respective test case is not a singleton.\nA solution (KB) for a DPI is characterized as follows:\nDefinition 2 (Solution KB). Let \u3008K,B,P ,N \u3009R be a DPI. Then a KB K\u2217 is called solution KB w.r.t. \u3008K,B,P ,N \u3009R, written as K\u2217 \u2208 Sol\u3008K,B,P,N \u3009R , iff all the following conditions hold:\n\u2200 r \u2208 R : K\u2217 \u222a B fulfills r (1) \u2200 p \u2208 P : K\u2217 \u222a B |= p (2) \u2200n \u2208 N : K\u2217 \u222a B 6|= n. (3)\nA solution KB K\u2217 w.r.t. a DPI is called maximal, written as K\u2217 \u2208 Solmax\u3008K,B,P,N \u3009R , iff there is no solution KB K\u2032 such that K\u2032 \u2229 K \u2283 K\u2217 \u2229 K.\nExample 2 For the DPI given by Table 1,K = {ax 1, . . . , ax 7} is not a solution KB w.r.t. \u3008K,B,P ,N \u3009R since, e.g. K \u222a B = {ax 1, . . . , ax 9} 6|= p1 which is a positive test case and therefore has to be entailed. This is easy to verify since p1 is equivalent to Z \u2192 X , but Z does not occur on any left-hand side of a rule in K \u222a B. Another reason why K = {ax 1, . . . , ax 7} is not a solution KB w.r.t. the given DPI is that K \u222a B \u2283 {ax 1, . . . , ax 3} |= n2, which is a negative test case and hence must not be an entailment. This is straightforward since {ax 1, . . . , ax 3} imply E \u2192 X , X \u2192 H and H \u2192 \u00acG and thus clearly n2 = {E \u2192 \u00acG}.\nOn the other hand,K\u2217a := {}\u222a{Z \u2192 X} is clearly a solution KB w.r.t. the given DPI as {Z \u2192 X}\u222aB is obviously consistent (satisfies all r \u2208 R), does entail p1 \u2208 P and does not entail any ni \u2208 N , (i \u2208 {1, . . . , 3}). However, K\u2217a is not a maximal solution KB since, e.g. ax 5 = K \u2192 E \u2208 K can be added to K\u2217a without resulting in the violation of any of the conditions (1)-(3) stated by Definition 2. Please note that also, e.g. {\u00acX \u2192 \u00acZ,A1 \u2192 A2, A2 \u2192 A3, . . . , Ak\u22121 \u2192 Ak} for arbitrary finite k \u2265 0 is a solution KB, although it has no axioms in common with K. This is the reason why Parsimonious KB Debugging (see below) searches for some maximal solution KB w.r.t. to a DPI which has a set-maximal intersection with the faulty KB among all solution KBs.\nMaximal solution KBs w.r.t. the given DPI are, e.g. K\u2217b := {ax 1, ax 4, ax 5, ax 6, ax 7, p1} (resulting from deletion of {ax 2, ax 3} from K and addition of p1) or K\u2217c := {ax 1, ax 2, ax 5, ax 6, p1} (resulting from deletion of {ax 1, ax 4, ax 7} from K and addition of p1). That these KBs constitute solution KBs can be verified by checking the three conditions named by Definition 2. Indeed, adding an additional axiom in K to any of the two KBs leads to the entailment of a negative test case n \u2208 N . That is, no solution KB can contain a proper superset of the axioms from K that are contained in any of the two solution KBs. Hence, both are maximal.\nThe problem to be solved by a KB debugger is given as follows:\nProblem Definition 1 (Parsimonious KB Debugging). [20] Given a DPI \u3008K,B,P ,N \u3009R, the task is to find a maximal solution KB w.r.t. \u3008K,B,P ,N \u3009R.\nWhereas the definition of a solution KB refers to the desired properties of the output of a KB debugging system, the following definition can be seen as a helpful characterization of KBs provided as an input to a KB debugger. If a KB is valid (w.r.t. the background knowledge, the requirements and the test\ncases), then finding a solution KB w.r.t. the DPI is trivial. Otherwise, obtaining a solution KB from it involves modification of the input KB and subsequent addition of suitable formulas. Usually, the KB K part of the DPI given as an input to a debugger is initially assumed to be invalid w.r.t. this DPI.\nDefinition 3 (Valid KB). Let \u3008K,B,P ,N \u3009R be a DPI. Then, we say that a KB K\u2032 is valid w.r.t. \u3008\u00b7,B, P ,N \u3009R iff K\u2032 \u222a B \u222a UP does not violate any r \u2208 R and does not entail any n \u2208 N . A KB is said to be invalid (or faulty) w.r.t. \u3008\u00b7,B,P ,N \u3009R iff it is not valid w.r.t. \u3008\u00b7,B,P ,N \u3009R.\nExample 3 Recalling our running example DPI \u3008K,B,P ,N \u3009R in Table 1 andK\u2217b as well asK\u2217c defined in Example 2, we observe that deletion of p1 from both these KBs yields a valid KB w.r.t. \u3008\u00b7,B,P ,N \u3009R, i.e. one to which the known correct formulas, i.e. the union of the positive test cases as well as the background KB, can be safely added in the sense that, by this addition, no faults are introduced in terms of requirement violations or entailed negative test cases. On the other hand, (any superset of) {ax 2, ax 4} cannot be a valid KB w.r.t. \u3008\u00b7,B,P ,N \u3009R due to the monotonicity of Propositional Logic (cf. assumption (L1) in Section 2.1) and the fact that ax 2 \u2261 {X \u2192 H,F \u2192 H} together with ax 8(\u2208 B) = H \u2192 A and ax 4 = A \u2192 \u00acF clearly yields F \u2192 \u00acF \u2261 \u00acF which, in particular, implies n3 = {F \u2192 L} \u2261 {\u00acF \u2228H}. Another example of a faulty KB w.r.t. \u3008\u00b7,B,P ,N \u3009R is {A,A\u2192 B,\u00acB}. Reason for its invalidity is its inconsistency, i.e. the violation of r1 \u2208 R.\nDiagnoses. The key to solving the problem of Problem Definition 1 is the notion of a (minimal) diagnosis given next. That is (cf. [20, Prop. 3.6]):\nThe task of finding maximal solution KBs w.r.t. a DPI can be reduced to computing minimal diagnoses w.r.t. this DPI.\nIn other words, all maximal solution KBs w.r.t. a DPI can be constructed from all minimal diagnoses w.r.t. this DPI. Hence, one usually tackles the Parsimonious KB Debugging Problem by focusing on the computation of minimal diagnoses and constructing just one (canonical) maximal solution KB from a minimal diagnosis D (see [20, pages 32,33]).\nRemark 2 Please note that, generally, there are infinitely many possible maximal solution KBs constructible from a minimal diagnosis D. This stems from the fact that there are infinitely many (semantically equivalent) syntactical variants of any set of suitable formulas that might be added to the KB resulting from the deletion of D from the faulty KB. One reason for this is that there are infinitely many tautologies that might be included in these formulas, another reason is that formulas can be equivalently rewritten, e.g. A\u2192 B \u2261 A\u2192 B \u2228 \u00acA \u2261 A\u2192 B \u2228 \u00acA \u2228 \u00acA \u2261 . . . .\nSuch a canonical maximal solution KB can be defined by means of a minimal diagnosisD, the original faulty KB K and the set of positive test cases P , namely as (K \\ D) \u222a UP . Please notice that due to the restriction on canonical solution KBs we use a definition of a diagnosis in this work that is less general than the one given in [20] (but still does not affect the set of diagnoses w.r.t. a DPI, cf. [20, page 33 and Corollary 3.3]).\nDefinition 4 (Diagnosis). Let \u3008K,B,P ,N \u3009R be a DPI. A set of formulas D \u2286 K is called a diagnosis w.r.t. \u3008K,B,P ,N \u3009R, written asD \u2208 aD\u3008K,B,P,N \u3009R , iff (K\\D)\u222aUP is a solution KB w.r.t. \u3008K,B,P ,N \u3009R.\nA diagnosisD w.r.t. \u3008K,B,P ,N \u3009R is minimal, written asD \u2208mD\u3008K,B,P,N \u3009R , iff there is noD\u2032 \u2282 D such that D\u2032 is a diagnosis w.r.t. \u3008K,B,P ,N \u3009R. A diagnosis D w.r.t. \u3008K,B,P ,N \u3009R is a minimum cardinality diagnosis w.r.t. \u3008K,B,P ,N \u3009R iff there is no diagnosisD\u2032 w.r.t. \u3008K,B,P ,N \u3009R such that |D\u2032| < |D|.\nExample 4 A list of all minimal diagnoses w.r.t. our running example DPI (Table 1) is shown in Table 2. An explanation why these are diagnoses will be given later in Example 7.\nConflict Sets. [20, Sec. 4.1] The search space for minimal diagnoses w.r.t. \u3008K,B,P ,N \u3009R, the size of which is in general O(2|K|) (if all subsets of the KB K are investigated), can be reduced to a great extent by exploiting the notion of a conflict set [19, 13, 27].\nDefinition 5 (Conflict Set). Let \u3008K,B,P ,N \u3009R be a DPI. A set of formulas C \u2286 K is called a conflict set w.r.t. \u3008K,B,P ,N \u3009R, written as C \u2208 aC\u3008K,B,P,N \u3009R , iff C is invalid w.r.t. \u3008\u00b7,B,P ,N \u3009R. A conflict set C is minimal, written as C \u2208mC\u3008K,B,P,N \u3009R , iff there is no C\u2032 \u2282 C such that C\u2032 is a conflict set.\nSimply put, a (minimal) conflict set is a (minimal) faulty KB that is a subset of K. That is, a conflict set is one source causing the faultiness of K in the context of B \u222a UP . A minimal conflict set has the property that deletion of any formula in it yields a set of formulas which is not faulty in the context of B, P , N and R.\nExample 5 A list of all minimal conflict sets w.r.t. our running example DPI \u3008K,B,P ,N \u3009R is enumerated in Table 3. Let us briefly reflect why these are conflict sets w.r.t. \u3008K,B,P ,N \u3009R. An explanation of why C1 is a conflict set was given in the first paragraph in Example 2. That C1 is minimal can also be recognized at a glance since the elimination of any axiom ax i(i \u2208 {1, 2, 3}) from C1 breaks the entailment of the negative test case n2 and yields a consistent KB (in accordance with r1 \u2208 R). The reasons for the set C2 being a conflict set were explicated in Example 3. C3 is a set-minimal subset of the KB K which, along with B and UP (in particular with ax 8 \u2208 B and p1 \u2208 P ), implies that n1 \u2208 N must be true. This must hold as ax 7 |= M \u2192 Z, p1 = Z \u2192 X , ax 2 |= X \u2192 H and ax 8 = H \u2192 A, from which n1 = {M \u2192 A} follows in a straightforward way.\nFinally, C4 is a conflict since ax 7 |= M \u2192 C, ax 6 = C \u2192 B, ax 9 \u2261 B \u2192 K, ax 5 = K \u2192 E and ax 3 |= E \u2192 \u00acM . Again, it is now obvious that this chain yields the entailment \u00acM which in turn entails {\u00acM \u2228A} \u2261 {M \u2192 A} = n1. Clearly, the removal of any axiom from this chain breaks the entailment \u00acM . As this chain is neither inconsistent nor implies any negative test cases other than n1, the conflict set C4 is also minimal.\nIt is also not very hard to verify that there are no other minimal conflict sets w.r.t. the example DPI apart from C1, . . . , C4.\nThe relationship between the notions diagnosis, solution KB, valid KB and conflict set is as follows\n(cf. [20, Corollary 3.3]):\nProposition 1. Let D \u2286 K. Then the following statements are equivalent:\n1. D is a diagnosis w.r.t. \u3008K,B,P ,N \u3009R.\n2. (K \\ D) \u222a UP is a solution KB w.r.t. \u3008K,B,P ,N \u3009R.\n3. (K \\ D) is valid w.r.t. \u3008\u00b7,B,P ,N \u3009R.\n4. (K \\ D) is not a conflict set w.r.t. \u3008K,B,P ,N \u3009R.\nExample 6 Since, e.g. {ax 1, ax 2} is a valid KB w.r.t. to our example DPI (Table 1), we obtain that K \\ {ax 1, ax 2} = {ax 3, . . . , ax 7} =: D is a diagnosis w.r.t. this DPI. However, this diagnosis D is not minimal since ax 5 as well as ax 6 can be deleted from it while preserving its diagnosis property ({ax 3, ax 4, ax 7} is a minimal diagnosis). Further on, we can derive by Proposition 1 that {ax 1, ax 2, p1} is a solution KB and that no set S \u2286 {ax 1, ax 2} can be a conflict set w.r.t. the example DPI.\nRelation between Conflict Sets and Diagnoses. By deletion of at least one formula from each minimal conflict set w.r.t. \u3008K,B,P ,N \u3009R, a valid KB can be obtained from K. Thus, a (maximal) solution KB (K \\ D) \u222a UP can be obtained by the calculation of a (minimal) hitting set D of all minimal conflict sets in mC\u3008K,B,P,N \u3009R :\nDefinition 6 (Hitting Set). Let S = {S1, . . . , Sn} be a set of sets. Then, H is called a hitting set of S iff H \u2286 US and H \u2229 Si 6= \u2205 for all i = 1, . . . , n. A hitting set H of S is minimal iff there is no hitting set H \u2032 of S such that H \u2032 \u2282 H .\nProposition 2. [3] A (minimal) diagnosis w.r.t. the DPI \u3008K,B,P ,N \u3009R is a (minimal) hitting set of all minimal conflict sets w.r.t. \u3008K,B,P ,N \u3009R.\nHence, what we might call the standard method for computing (minimal) diagnoses w.r.t. some given DPI is via the computation of minimal conflict sets and the calculation of minimal hitting sets thereof. As described comprehensively in [20], this might be accomplished by the usage of a hitting set tree (originally due to Reiter [19]) along with a method such as QuickXPlain (originally due to Junker [7]). For details we want to refer the reader to [20].\nExample 7 The reader is invited to verify that all minimal diagnoses shown in Table 2 are indeed minimal hitting sets of all minimal conflict sets shown in Table 3. For instance, using the simplified notation for axioms as in the tables,D1 = {2, 3} \u201chits\u201d the element 2 of Ci(i \u2208 {1, 2, 3}) and the element 3 of C4. Note also that it hits two elements of C1 which, however, is not necessarily an indication of the non-minimality of the hitting set. Indeed, if 2 is deleted from D1, it has an empty intersection with C2 and C3 and, otherwise, if 3 is deleted from it, it becomes disjoint with C4. HenceD1 is actually a minimal hitting set of mC\u3008K,B,P,N \u3009R . Clearly, this implies that D1 is also a hitting set of aC\u3008K,B,P,N \u3009R .\nPlease realize that, by now, we have also completed the explanation why the diagnoses listed in Table 2 actually correspond to the set of all minimal diagnoses w.r.t. the example DPI \u3008K,B,P ,N \u3009R shown by Table 1. In particular, this follows from Proposition 2 and the illustration (given in Example 5) of why C1, . . . , C4 constitute a complete set of minimal conflict sets w.r.t. \u3008K,B,P ,N \u3009R."}, {"heading": "2.3 Interactive Knowledge Base Debugging: Basics", "text": "In real-world scenarios, debugging tools often have to cope with large numbers of minimal diagnoses where the trivial application, i.e. deletion, of any minimal diagnosis leads to a valid KB with different semantics in terms of entailed and non-entailed formulas. For example, a sample study of real-world KBs [26] detected 1782 different minimal diagnoses for a KB with only 1300 formulas. In such situations a simple visualization of all these alternative modifications of the KB is clearly ineffective. Selecting a wrong diagnosis (in terms of its semantics, not in terms of fulfillment of test cases and requirements) can lead to unexpected, surprising or fatal entailments or non-entailments. Assume for example that a patient is administered a wrong therapy (e.g. a chemotherapy) due to an incorrect semantics of the KB which is part of the expert system a doctor is consulting.\nMoreover, as mentioned in Section 1, non-interactive debugging systems often have serious performance problems, run out of memory, are not able to find all diagnoses w.r.t. the DPI (incompleteness), report diagnoses which are actually none (unsoundness), produce only trivial solutions or suggest non-minimal diagnoses (non-minimality). Often, performance problems and incompleteness of noninteractive debugging methods can be traced back to an explosion of the search tree for minimal diagnoses.\nInteractive KB debugging addresses and tackles all the mentioned problems of non-interactive KB debuggers in that it uses a sound, complete and best-first iterative minimal diagnosis computation process (see [20, Part 2]) and between each two iterations consults a user for additional information that serves to specify constraints and in further consequence to gradually reduce the search space for minimal diagnoses.\nAssumptions about the Interacting User. We suppose the user of an interactive KB debugger to be either a single person or multiple persons, usually experts in the particular domain the faulty KB is dealing with or authors of the faulty KB, or some (automatic) oracle, e.g. some knowledge extraction system. Anyway, the consultation of the user must be seen as an expensive operation. That is, the number of calls to the user should be minimized.\nAbout a user u of an (interactive) debugging system, we make the following plausible assumptions (for a discussion and plausibility check see [20, p. 9 \u2013 11]):\n(U1) u is not able to explicitly enumerate a set of logical sentences that express the intended domain that should be modeled in a satisfactory way, i.e. without unwanted entailments or non-fulfilled requirements,\n(U2) u is able to answer concrete queries about the intended domain that should be modeled, i.e. u can classify a given logical formula (or a conjunction of logical formulas) as a wanted or unwanted proposition in the intended domain (i.e. an entailment or non-entailment of the correct domain model).\nUser consultation means asking the user to answer an (automatically generated and potentially optimized) query.\nQueries. In interactive KB debugging, a set of logical formulas Q is presented to the user who should decide whether to assign Q to the set of positive (P ) or negative (N ) test cases w.r.t. a given DPI \u3008K,B,P ,N \u3009R. In other words, the system asks the user \u201cshould the KB you intend to model entail all formulas in Q?\u201d. In that, Q is generated by the debugging algorithm in a way that any decision of the user about Q\n1. invalidates at least one minimal diagnosis (search space restriction) and\n2. preserves validity of at least one minimal diagnosis (solution preservation).\nWe call a set of logical formulas Q with these properties a query. Successive classification of queries as entailments (all formulas in Q must be entailed) or non-entailments (at least one formula in Q must not be entailed) of the correct KB enables gradual restriction of the search space for (minimal) diagnoses. Further on, classification of sufficiently many queries guarantees the detection of a single correct solution diagnosis which can be used to determine a solution KB with the correct semantics w.r.t. a given DPI.\nDefinition 7 (Query). Let \u3008K,B,P ,N \u3009R over L and D \u2286 mD\u3008K,B,P,N \u3009R . Then a set of logical formulas Q 6= \u2205 over L is called a query w.r.t. D and \u3008K,B,P ,N \u3009R iff there are diagnoses D,D\u2032 \u2208 D such that D /\u2208 mD\u3008K,B,P\u222a{Q},N \u3009R and D\u2032 /\u2208 mD\u3008K,B,P,N\u222a{Q}\u3009R . The set of all queries w.r.t. D and \u3008K,B,P ,N \u3009R is denoted by QD,\u3008K,B,P,N \u3009R .\nSo, w.r.t. a set of minimal diagnoses D \u2286 mD\u3008K,B,P,N \u3009R , a query Q is a set of logical formulas that rules out at least one diagnosis in D (and therefore in mD\u3008K,B,P,N \u3009R ) as a candidate to formulate a solution KB, regardless of whether Q is classified as a positive or negative test case. Moreover, as it turns out as a consequence of Definition 7 (cf. Proposition 3), a user can never end up with a new DPI for which no solutions exist as long as the new DPI results from a given one by the addition of an answered query to one of the test case sets P or N .\nLeading Diagnoses. Query generation requires a precalculated set of minimal diagnoses D, some subset of mD\u3008K,B,P,N \u3009R , that serves as a representative for all minimal diagnoses mD\u3008K,B,P,N \u3009R . As already mentioned, computation of the entire set mD\u3008K,B,P,N \u3009R is generally not tractable within reasonable time. Usually, D is defined as a set of most probable (if some probabilistic meta information is given) or minimum cardinality diagnoses. Therefore, D is called the set of leading diagnoses w.r.t. \u3008K,B,P ,N \u3009R [27].\nThe leading diagnoses D are then exploited to determine a query Q, the answering of which enables a discrimination between the diagnoses in mD\u3008K,B,P,N \u3009R . That is, a subset of mD\u3008K,B,P,N \u3009R which is not \u201ccompatible\u201d with the new information obtained by adding the test case Q to P or N is ruled out. For the computation of the subsequent query only a leading diagnoses set Dnew w.r.t. the minimal diagnoses still compliant with the new sets of test cases P \u2032 and N \u2032 is taken into consideration, i.e. Dnew \u2286 mD\u3008K,B,P \u2032,N \u2032\u3009R .\nThe number of precomputed leading diagnoses D affects the quality of the obtained query. The higher |D|, the more representative is D w.r.t. mD\u3008K,B,P,N \u3009R , the more options there are to specify a query in a way that a user can easily comprehend and answer it, and the higher is the chance that a query that eliminates a high rate of diagnoses w.r.t. D will also eliminate a high rate of all minimal diagnoses mD\u3008K,B,P,N \u3009R . The selection of a lower |D| on the other hand means better timeliness regarding the interaction with a user, first because fewer leading diagnoses might be computed much faster and second because the search space for an \u201coptimal\u201d query is smaller.\nExample 8 Let us consider our running example DPI \u3008K,B,P ,N \u3009R (Table 1) again and let us further suppose that some diagnosis computation algorithm provides the set of leading diagnoses D = {D1,D2,D3,D4} (see Table 2). Then Q1 := {M \u2192 B} is a query w.r.t. D and \u3008K,B,P ,N \u3009R.\nTo verify this, we have to argue why at least one diagnosis in D is eliminated in either case, i.e. for positive answer yielding P \u2032 \u2190 P \u222a {Q1} as well as for negative answer yielding N \u2032 \u2190 N \u222a {Q1}. Formally, we must show that D \u2229mD\u3008K,B,P \u2032,N \u3009R \u2282 D (reduction of the leading diagnoses given the positive query answer) and D \u2229 mD\u3008K,B,P,N \u2032\u3009R \u2282 D (reduction of the leading diagnoses given the negative query answer).\nWe first assume a positive answer, i.e. we take as a basis the DPI DPI+ := \u3008K,B,P \u2032,N \u3009R. Let us test the diagnosis property w.r.t. DPI+ for D4 \u2208 D. By Proposition 1 we can check whether K \\ D4 is valid w.r.t. DPI+ in order to check whether D4 = {ax 2, ax 7} is still a diagnosis w.r.t. this DPI.\nTo this end, (using the simplified axiom notation of Tables 2 and 3 again) we have a look at K+4 := (K \\ D4) \u222a B \u222a UP \u2032 = {1, 3, 4, 5, 6, 8, 9, p1,M \u2192 B}. As ax 9 \u2261 B \u2192 K, ax 5 = K \u2192 E and ax 3 |= E \u2192 \u00acM , it is clear that {M \u2192 A} = n1 \u2208 N is an entailment of K+4 . Hence K \\ D4 is faulty w.r.t. DPI+ which is why D4 /\u2208mD\u3008K,B,P \u2032,N \u3009R .\nFor the case of receiving a negative answer to Q1, let us consider diagnosis D2 = {ax 2, ax 5} w.r.t. DPI\u2212 := \u3008K,B,P ,N \u2032\u3009R. Now, K\u22122 := (K \\ D2) \u222a B \u222a UP = {1, 3, 4, 6, 7, 8, 9, p1} |= {M \u2192 B} = Q1 \u2208 N \u2032 due to ax 7 |= M \u2192 C and ax 6 = C \u2192 B. Therefore, K \\ D2 is faulty w.r.t. DPI\u2212 which is why D2 /\u2208mD\u3008K,B,P,N \u2032\u3009R .\nAll in all we have substantiated that Q1 is a query w.r.t. D and \u3008K,B,P ,N \u3009R. Note in addition that D2 is a diagnosis w.r.t. DPI+ since K+2 is consistent and does not entail any negative test case in N . Furthermore, D4 is a diagnosis w.r.t. DPI\u2212 since K\u22124 is consistent and does not entail any negative test case in N \u2032. That is, while being deleted for one answer, diagnoses remain valid when facing the complementary answer. This can also be shown in general, see Proposition 3.\nQ-Partitions. A q-partition is a partition of the leading diagnoses set D induced by a query w.r.t. D. A q-partition will be a helpful instrument in deciding whether a set of logical formulas is a query or not. It will facilitate an estimation of the impact a query answer has in terms of invalidation of minimal diagnoses. And, given fault probabilities, it will enable us to gauge the probability of getting a positive or negative answer to a query.\nFrom now on, given a DPI \u3008K,B,P ,N \u3009R and some minimal diagnosis Di w.r.t. \u3008K,B,P ,N \u3009R, we will use the following abbreviation for the solution KB obtained by deletion of Di along with the given background knowledge B:\nK\u2217i := (K \\ Di) \u222a B \u222a UP (4)\nDefinition 8 (q-Partition7). Let \u3008K,B,P ,N \u3009R be a DPI over L, D \u2286mD\u3008K,B,P,N \u3009R . Further, let Q be a set of logical sentences over L and\n\u2022 D+(Q) := {Di \u2208 D | K\u2217i |= Q},\n\u2022 D\u2212(Q) := {Di \u2208 D | \u2203x \u2208 R \u222aN : K\u2217i \u222aQ violates x},\n\u2022 D0(Q) := D \\ (D+j \u222aD \u2212 j ).\nThen \u3008D+(Q),D\u2212(Q),D0(Q)\u3009 is called a q-partition iff Q is a query w.r.t. D and \u3008K,B,P ,N \u3009R.\nExample 9 Given the leading diagnoses set D = {D1, . . . ,D4} w.r.t. our example DPI (Table 1) and the query Q1 = {M \u2192 B} characterized in Example 8. Then, as we have already established in Example 8, D4 is invalidated given the positive answer to Q1 since K+4 = K\u22174 \u222a Q1 |= n1 \u2208 N . Hence, by Definition 8, D4 must be an element of D\u2212(Q1).\nOn the contrary, D2 \u2208 D+(Q1) because K\u22122 = K\u22172 = {1, 3, 4, 6, 7, 8, 9, p1} |= {M \u2192 B} = Q1, as demonstrated in Example 8.\nTo complete the q-partition for the query Q1, we need to assign the remaining diagnoses in D, i.e. D1 = {ax 2, ax 3} ,D3 = {ax 2, ax 6} to the respective set of the q-partition. Since K\u22172 includes ax 6 and ax 7 we can conclude in an analogous way as in Example 8 that K\u22172 |= Q1 which is why D2 \u2208 D+(Q1). In the case of D3, we observe that K\u22173 \u222aQ1 includes ax 3, ax 5 M \u2192 B as well as ax 9. As explicated in Example 8, these axioms imply the entailment of n1 \u2208 N . Consequently, D3 \u2208 D\u2212(Q1) must hold and thus D0(Q1) is the empty set.\n7In existing literature, e.g. [27, 21, 26], a q-partition is often simply referred to as partition. We call it q-partition to emphasize that not each partition of D into three sets is necessarily a q-partition.\nAlgorithm 1 Interactive KB Debugging Input: a DPI \u3008K,B,P ,N \u3009R, a probability measure p (used to compute formula and diagnoses fault probabilities),\na query quality measure m, a solution fault tolerance \u03c3 Output: A (canonical) maximal solution KB (K \\ D) \u222a UP w.r.t. \u3008K,B,P ,N \u3009R constructed from a minimal diag-\nnosis D w.r.t. \u3008K,B,P ,N \u3009R that has at least 1\u2212 \u03c3 probability of being the true diagnosis 1: while true do 2: D\u2190 COMPUTELEADINGDIAGNOSES(\u3008K,B,P ,N \u3009R) 3: D \u2190 GETBESTDIAGNOSIS(D, p) 4: if p(D) \u2265 1\u2212 \u03c3 then 5: return (K \\ D) \u222a UP 6: Q\u2190 CALCQUERY(D, \u3008K,B,P ,N \u3009R, p,m) . see Algorithm 2 7: answer \u2190 u(Q) . user interaction 8: \u3008K,B,P ,N \u3009R \u2190 UPDATEDPI(\u3008K,B,P ,N \u3009R, Q, answer)\nSome important properties of q-partitions and their relationship to queries are summarized by the next proposition:\nProposition 3. [20, Sec. 7.3 \u2013 7.6] Let \u3008K,B,P ,N \u3009R be a DPI over L and D \u2286 mD\u3008K,B,P,N \u3009R . Further, let Q be any query w.r.t. D and \u3008K,B,P ,N \u3009R. Then:\n1. \u3008D+(Q), D\u2212(Q), D0(Q)\u3009 is a partition of D.\n2. D\u2212(Q) contains exactly those diagnosesDi \u2208 D whereK\\Di is invalid w.r.t. \u3008\u00b7,B,P \u222a {Q} ,N \u3009R. D+(Q) contains exactly those diagnosesDi \u2208 D whereK\\Di is invalid w.r.t. \u3008\u00b7,B,P ,N \u222a {Q}\u3009R. D0(Q) contains exactly those diagnoses Di \u2208 D where K \\Di is valid w.r.t. \u3008\u00b7,B,P \u222a {Q} ,N \u3009R and valid w.r.t. \u3008\u00b7,B,P ,N \u222a {Q}\u3009R.\n3. For Q there is one and only one q-partition \u3008D+(Q),D\u2212(Q),D0(Q)\u3009.\n4. Q is a set of common entailments of all KBs in {K\u2217i | Di \u2208 D+(Q)}.\n5. A set of logical formulas X 6= \u2205 over L is a query w.r.t. D iff D+(X) 6= \u2205 and D\u2212(X) 6= \u2205.\n6. For each q-partition P(Q) = \u3008D+(Q),D\u2212(Q),D0(Q)\u3009 w.r.t. D it holds that D+(Q) 6= \u2205 and D\u2212(Q) 6= \u2205.\n7. If |D| \u2265 2, then\n(a) Q := UD \\ Di is a query w.r.t. D and \u3008K,B,P ,N \u3009R for all Di \u2208 D, (b) \u3008{Di} ,D \\ {Di} , \u2205\u3009 is the q-partition associated with Q, and (c) a lower bound for the number of queries w.r.t. D and \u3008K,B,P ,N \u3009R is |D|.\nAlgorithm 1 describes the overall interactive debugging process that has already been sketched and discussed in Section 1. It explicates in formal terms what is depicted by Figure 1. It first computes a set of leading diagnoses (COMPUTELEADINGDIAGNOSES), then uses some probability measure p to extract the most probable leading diagnosis (GETBESTDIAGNOSIS). If there are no probabilities given, then p is specified so as to assign the maximal probability to diagnoses of minimal cardinality. If the probability of the best diagnosisD is already above the threshold 1\u2212\u03c3 (a common setting for \u03c3 is 0.05), i.e. the stop criterion is met, then the maximal (canonical) solution KB according to D is returned and the debugging session terminates. Otherwise, a sufficiently good query, where goodness is measured in terms of some query quality measure m, is computed (CALCQUERY) and shown to the user. The latter is modeled as a\nfunction u(Q) 7\u2192 a where a \u2208 {t, f} that maps a query Q to a positive (t) or negative (f ) answer. After incorporating the answered query as a new test case into the DPI (UPDATEDPI), the next iteration starts and uses the new DPI instead of the original one. Note that the UPDATEDPI function subsumes further operations which we do not consider in detail such as the (Bayesian) update [13] of the probability measure p based on the new information given by the answered query (see [20, Sec. 9.2.4]). Further information on this algorithm and a much more detailed description including proofs of correctness and optimality can be found in [20, Chap. 9].\nFinally, the major advantage of interactive debugging techniques can be summarized as follows:\nA user can debug their faulty KB without needing to analyze\n\u2022 which entailments do or do not hold in the faulty KB \u2022 why certain entailments do or do not hold in the faulty KB or \u2022 why exactly the faulty KB does not meet the requirements R and test cases P ,N\nby just answering queries whether certain entailments should or should not hold in the intended domain, under the guarantee that the resulting solution KB will feature exactly the desired semantics."}, {"heading": "3 Query Computation", "text": "In this section we will present the implementation of the CALCQUERY function in Algorithm 1. In particular, we will\n1. discuss and study existing quantitative measures m already used in works on KB debugging [26, 27, 21] that can be employed in the CALCQUERY function in order to establish the goodness of queries (Section 3.2.2),\n2. adapt various general active learning measures [25] for use within the function CALCQUERY in the KB debugging framework and provide a comprehensive mathematical analysis of them (Section 3.2.3),\n3. introduce a new measure RIO (first presented in [21]) that is embedded in a reinforcement learning scheme and particularly tackles the problem that the performance (i.e. the number of queries a user must answer) of existing measures depends strongly on the quality of the initially given fault information p (Section 3.2.4),\n4. study all discussed measures (i.e. functions) with regard to which input yields their optimal value, define a plausible preference order on queries, called the debug-preference relation, and analyze for all discussed measures how far they preserve this order, characterize a superiority relation on query quality measures based on the (degree of) their compliance with the debug-preference relation and figure out superiority relationships between the discussed measures, formalize the notions of equivalence between two measures and examine situations or describe subsets of all queries, respectively, where different measures are equivalent to one another (Sections 3.2.1 \u2013 3.2.4),\n5. derive improved versions from some query quality measures \u2013 including those used in [27, 21, 26] \u2013 to overcome shortcomings unveiled in the conducted in-depth theoretical evaluations (Sections 3.2.2 \u2013 3.2.4),\n6. exploit the carried out optimality analyses to derive from all the discussed (quantitative) query quality measures qualitative goodness criteria, i.e. properties, of queries which allow us to derive heuristics to design efficient search strategies to find an optimal query (Sections 3.2.2 \u2013 3.3),\n7. detail a new, generic and efficient way of generating q-partitions without relying on (expensive) reasoning services at all in a best-first order which facilitates the finding of q-partitions that are arbitrarily close to the optimal value w.r.t. a given query quality measure (Section 3.4). Further on, we will\n8. demonstrate how set-minimal queries can be found in a best-first order (e.g. minimum-size or minimal-answer-fault-probability queries first), which is not possible with existing methods (Section 3.5), we will\n9. show that that minimization of a query is equivalent to solving a (small and restricted) hitting set problem (Section 3.5), and we will\n10. explain how a query can be enriched with additional logical formulas that have a simple predefined (syntactical) structure (e.g. formulas of the form A\u2192 B for propositional symbols A,B) in a way that the optimality of the query w.r.t. the goodness measure m is preserved (Section 3.6). This should grant a larger pool of formulas to choose from when reducing the query to a set-minimal set of logical formulas and increase the query\u2019s likeliness of being well-understood and answered correctly by the interacting user. Finally, we will\nAlgorithm 2 Query Computation (CALCQUERY) Input: DPI \u3008K,B,P ,N \u3009R, leading diagnoses D \u2286 mD\u3008K,B,P,N\u3009R , probability measure p (used to compute for-\nmula and diagnoses fault probabilities), query quality measurem, threshold tm specifying the region of optimality around the theoretically optimal value mopt of m (queries Q with |m(Q)\u2212mopt| \u2264 tm are considered optimal), parameters qSelParams = \u3008strat, time, nmin, nmax\u3009 to steer query selection w.r.t. a given q-partition (explicated in Algorithm 9 and Section 3.5), sound and complete reasonerRsnr (w.r.t. the used logic L), setET of entailment types (w.r.t. the used logic L) Output: an optimal queryQw.r.t. D and \u3008K,B,P ,N \u3009R as perm and tm, if existent; the best found query, otherwise 1: rm \u2190 QPARTITIONREQSELECTION(m) 2: P\u2190 FINDQPARTITION(D, p, tm, rm) 3: Q\u2190 SELECTQUERYFORQPARTITION(P, p, qSelParams) 4: Q\u2032 \u2190 ENRICHQUERY(\u3008K,B,P ,N \u3009R, Q,P, Rsnr,ET ) . optional 5: Q\u2217 \u2190 OPTIMIZEQUERY(Q\u2032, Q,P, \u3008K,B,P ,N \u3009R, p) . optional 6: return Q\u2217\n11. explicate how such an enriched query can be optimized, i.e. minimized in size while giving some nice guarantees such as the inclusion of only formulas with a simple syntactical structure in the query, if such a query exists (Section 3.7).\nThe overall procedure CALCQUERY to compute a query is depicted by Algorithm 2. The algorithm takes as an input amongst others some query quality measure m that serves as a preference criterion for the selection of a query. More concretely, m maps a query Q to some real number m(Q) that quantifies the goodness of Q in terms of m.\nDefinition 9. Let \u3008K,B,P ,N \u3009R be a DPI and D \u2208 mD\u3008K,B,P,N \u3009R be a set of leading diagnoses. Then we call a function m : QD,\u3008K,B,P,N \u3009R \u2192 R that maps a query Q \u2208 QD,\u3008K,B,P,N \u3009R to some real number m(Q) a query quality measure. Depending on the choice of m, optimality of Q is signalized by m(Q)\u2192 max or m(Q)\u2192 min.\nSo, the problem to be solved by the function CALSQUERY is:\nProblem Definition 2. Given some measure m and a set of leading diagnoses D w.r.t. some DPI \u3008K,B,P ,N \u3009R, the task is to find a query Q with optimal (or sufficiently good) value m(Q) among all queries Q \u2208 QD,\u3008K,B,P,N \u3009R .\nHowever, such a quantitative query quality measure m alone helps only to a limited extent when it comes to devising an efficient method of detecting an optimal query w.r.t. m. More helpful is some set of qualitative criteria in terms of \u201cproperties\u201d of an optimal query that provides a means of guiding a systematic search.\nTo realize this, imagine a game where the player must place k tokens into b buckets and afterwards gets a number of points for it. Assume that the player does not know anything about the game except that the goal is to maximize their points. What is the best the player can do? This game can be compared to a function that must be optimized, about whose optimal input values one does not know anything. This function can be compared to a black-box. Provided with an input value, the function returns an output value. No more, no less. If the given output value is not satisfactory, all one can do is try another input value and check the result. Because one does not know in which way to alter the input, or which properties of it must be changed, in order to improve the output. In a word, one finds themself doing a brute force search. But unfortunately even worse than that. Even if one happens to come across the optimum, they would not be aware of this and stop the search. Hence, it is a brute force search with an unknown stop condition. Of course, one could try to learn, i.e. remember which token positions yielded the highest reward and in this way try to figure out the optimal token positions. However, given a huge number of\npossible token configurations, in the case of our game bk many, this will anyway take substantial time given non-trivial values of b and k. Similar is the situation concerning queries (or better: the associated q-partitions), where we have available O(bk) different possible input values given b = 3 and k leading diagnoses (an explanation of this will be given in Section 3.1), and must filter out one which yields a (nearly) optimal output. Consequently, one must study and analyze the functions representing the query quality measures in order to extract properties of optimal queries and be able to do better than a brute force search or, equivalently, a pool-based strategy (which we called PoSt in Section 1).\nAs we know from Section 2.3, the \u201cproperties\u201d of a query Q are determined by the associated qpartition P(Q). On the one hand, P(Q) gives a prior estimate which and how many diagnoses might be invalidated after classification of Q as a positive or negative test case (elimination rate) and, on the other hand, together with the leading diagnoses probability distribution p, it provides a way to compute the likeliness of positive and negative query answers and thereby gauge the uncertainty (information gain) of Q. Therefore, in Section 3.3, we will focus on a translation of measures m into explicit requirements rm (function QPARTITIONREQSELECTION) that a q-partition P must meet in order for a query Q with associated q-partition P(Q) = P to optimize m(Q). So, the idea is to first search for a q-partition with desired properties rm, and then compute a query for this q-partition.\nIn Section 3.4 we will show how the usage of requirements rm instead of m can be exploited to steer the search for an optimal q-partition and present strategies facilitating to detect arbitrarily close-tooptimum q-partitions completely without reasoner support (FINDQPARTITION). After a suitable partition P has been identified, a query Q with q-partition P(Q) = P is calculated such that Q is optimal as to some criterion such as minimum cardinality or maximum likeliness of being answered correctly (SELECTQUERYFORQPARTITION). Then, in order to come up with a query that is as simple and easy to answer as possible for the respective user U , this queryQ can optionally be enriched by additional logical sentences (ENRICHQUERY) by invoking a reasoner for entailments calculation. This causes a larger pool of sentences to select from in the query optimization step (OPTIMIZEQUERY). The latter constructs a set-minimal query where most complex sentences in terms of given fault estimates w.r.t. logical symbols (operators) and non-logical symbols (elements of the signature, e.g. predicate and constant names) are eliminated from Q and the most simple ones retained under preservation of P(Q) = P.8\nNote that in Algorithm 2 only the functions ENRICHQUERY and OPTIMIZEQUERY rely on a reasoner, and none of the functions involves user interaction. Particularly, this means that the algorithm can optionally output a query Q with an optimal q-partition without the need to use a reasoning service. This is because reasoning is only required for query optimization, which is optional. If query optimization is activated, it is only employed for this single query Q with optimal q-partition. Moreover, query optimization (functions ENRICHQUERY and OPTIMIZEQUERY) requires only a polynomial number of reasoner calls."}, {"heading": "3.1 Related Work", "text": "Existing works [26, 21], on the other hand, do not exploit qualitative requirements rm but rely on the measure m using more or less a brute-force method for query selection. In the worst case, this method requires the precalculation of one (enriched) query (by use of a reasoner) for O(2|D|) (q-)partitions w.r.t. D for each of which the m measure must be evaluated in order to identify one of sufficient quality. What could make the time complexity issues even more serious in this case is that not each partition of D is necessarily a q-partition, and deciding this for a single partition requires O(|D|) potentially expensive calls to a reasoner. More concretely, the method applied by these works is the following:\n1. Start from a set D+(Q) \u2282 D, use a reasoner to compute an enriched query w.r.t. D+(Q), i.e. a set 8We assume for simplicity that the given fault estimates be subsumed by the probability measure p. For an in-depth treatment\nof different types of fault estimates and methods how to compute these estimates the reader is referred to [20, Sec. 4.6].\nof common entailments Q of all K\u2217i := (K\\Di)\u222aB\u222aUP whereDi \u2208 D+(Q), and use a reasoner again for verification of whether Q leads to a q-partition indeed, i.e. whether there is at least one diagnosis D \u2208 D \\D+(Q) such that D \u2208 D\u2212(Q) (cf. Proposition 3,(6.)).\n2. Continue this procedure for different sets D+(Q) \u2282 D until Q evaluates to a (nearly) optimal m measure.\n3. Then minimize Q under preservation of its q-partition P(Q), again by means of an expensive reasoning service. The query minimization costs O ( |Qmin| log2 ( |Q| |Qmin| )) calls to a reasoner and\nyields just any subset-minimal query Qmin with q-partition P(Q), i.e. no guarantees whatsoever can be made about the output of the minimization.\nIn [27], qualitative requirements rm were already exploited together with the CKK algorithm [14] for the Two-Way Number Partitioning Problem9 to accelerate the search for a (nearly) optimal query w.r.t. m \u2208 {entropy, split-in-half}. However, the potential overhead of computing partitions that do not turn out to be q-partitions, and still an extensive use of the reasoner, is not solved by this approach. We tackle these problems in Section 3.4. Apart from that, we derive qualitative requirements for various other measures which are not addressed in [27].\nFurthermore, a maximum of 2|D| (the number of subsets D+(Q) of D) of all theoretically possible 3|D|\u22122|D|+1+1 q-partitions w.r.t. D are considered in the existing approaches.10 This incompleteness is basically no problem as O(2|D|) is still a large number for practicable cardinalities of leading diagnoses sets, e.g. |D| \u2248 10, that usually enables the detection of (nearly) optimal q-partitions. More problematic is the fact that no guarantee is given that no optimal q-partitions are missed while suboptimal ones are captured. Which q-partition is found for some D+(Q), i.e. to which of the sets D+(Q),D\u2212(Q),D0(Q) each diagnosis in D \\ D+(Q) is assigned, depends on the (types of) common entailments calculated for the diagnoses in D+(Q) (cf. [20, Sec. 8.2]). For example, for |D| = 10 and the set D+(Q) := {D1, . . . ,D5} there may exist the q-partitions P1 := \u3008{D1, . . . ,D5} , {D6,D7} , {D8, . . . ,D10}\u3009 and P2 := \u3008{D1, . . . ,D5} , {D6, . . . ,D10} , \u2205\u3009. With existing approaches, P1 might be found and P2 might not, depending on the query Q (i.e. the set of common entailments) calculated from D+(Q) that is utilized to complete the (q-)partition. However, P2 is strictly better even in theory than P1 since a query Q2 associated with P2 is more restrictive in terms of diagnosis elimination than a query Q1 for P1 since D0(Q2) = \u2205 (cf. Proposition 3,(2.)). This can be seen by investigating the set of invalidated leading diagnoses for positive and negative answers. That is, for positive answer, Q2 eliminates {D6, . . . ,D10} whereas Q1 eliminates only {D6,D7}, and for negative answer, both eliminate {D1, . . . ,D5}.\nAddressing i.a. this problem, [20, Chap. 8] proposes and analyzes an improved variant of the basic query computation methods employed by [26, 21]. Some results shown in this work are the following:\n1. Empty D0: Postulating the computation of (at least) a particular well-defined set of entailments when computing a set of common entailments of D+(Q), it can be guaranteed that only queries with empty D0 will be computed (cf. [20, Prop. 8.3]).\n2. No Duplicates: The improved variant guarantees that any query (and q-partition) can be computed only once (cf. [20, Prop. 8.2]).\n3. Completeness w.r.t. D+: The improved variant is complete w.r.t. the set D+, i.e. if there is a query Q with D+(Q) = Y , then the improved variant will return a query Q\u2032 with D+(Q\u2032) = Y (cf. [20, Prop. 8.4]).\n9Given a set of numbers, the Two-Way Number Partitioning Problem is to divide them into two subsets, so that the sum of the numbers in each subset are as nearly equal as possible [14].\n10The number of theoretically possible q-partitions w.r.t. D results from taking all partitions of a |D|-element set into 3 parts (labeled as D+,D\u2212 and D0) neglecting all those assigning the empty set to D+ and/or to D\u2212.\n4. Optimal Partition Extraction w.r.t. Entailment Function: If a query Q with D+(Q) = Y is returned by the improved variant, then Q is a query with minimal |D0(Q)| among all queries Q with D+(Q) = Y computable by the used entailment-computation function (cf. [20, Prop. 8.6]).\nNote that from these properties one can derive that suboptimal q-partitions (with non-empty D0) will (automatically) be ignored while a strictly better q-partition for each suboptimal one will be included in the query pool.\nThese are clearly nice properties of this improved variant. However, some issues persist (cf. [20, Sec. 8.6]), e.g. the still extensive reliance upon reasoning services. Another aspect subject to improvement is the query minimization which does not enable to extract a set-minimal query with desired properties, as discussed above. However, from the point of view of how well a query might be understood by an interacting user, of course not all minimized queries can be assumed equally good in general.\nBuilding on the ideas of [20], e.g. bullet (1) above, we will provide a definition of a canonical query and a canonical q-partition that will be central to our proposed heuristic query search. Roughly, a canonical query constitutes a well-defined set of common entailments that needs to be computed for some D+ in order to guarantee the fulfillment of all properties (1)\u2013(4) above and to guarantee that no reasoning aid is necessary during the entire query computation process. Further on, we will devise a method that guarantees that the best minimized query w.r.t. some desirable and plausible criterion is found. Importantly, our definitions of a canonical query and q-partition serve to overcome the non-determinism given by the dependence upon the particular entailments or entailment types used for query computation that existing approaches suffer from."}, {"heading": "3.2 Active Learning in Interactive Debugging", "text": "In this section we discuss various (active learning) criteria that can act as a query quality measure which is given as an input m to Algorithm 2.\nA supervised learning scenario where the learning algorithm is allowed to choose the training data from which it learns is referred to as Active Learning [25]. In active learning, an oracle can be queried to label any (unlabeled) instance belonging to a predefined input space. The set of labeled instances is then used to build a set of most probable hypotheses. Refinement of these hypotheses is accomplished by sequential queries to the oracle and by some update operator that takes a set of hypotheses and a new labeled instance as input and returns a new set of most probable hypotheses.\nA first necessary step towards using active learning in our interactive debugging scenario is to think of what \u201cinput space\u201d, \u201c(un)labeled instance\u201d, \u201coracle\u201d, \u201chypothesis\u201d and \u201cupdate operator\u201d mean in this case. In terms of a query as defined in Section 2.3, the input space (w.r.t. a set of leading diagnoses D) is the set QD,\u3008K,B,P,N \u3009R := {Q |Q is a query w.r.t. D and \u3008K,B,P ,N \u3009R}. An unlabeled instance can be seen as an (unanswered) query, denoted by (Q, ?), and a labeled instance as a query together with its answer, written as (Q, u(Q)). The oracle in this case corresponds to the user interacting with the debugging system. Hypothesis refers to a model learned by the algorithm that is consistent with all instances labeled so far; in the debugging case a hypothesis corresponds to a diagnosis and the most likely hypotheses correspond to the set of leading diagnoses D. In addition to the most likely hypotheses there is often an associated probability distribution. In our debugging scenario this is the probability distribution p assigning a probability to each leading diagnosis in D. The Bayesian update of p together with the computation of new leading diagnoses (cf. Algorithm 1) act as update operator.\nAn active learning strategy can be characterized by two parameters, the active learning mode and the selection criterion [25]. The mode refers to the way how the learning algorithm can access instances in the input space. The selection criterion, usually given as some quantitative measure, specifies whether an accessed instance should be shown to the oracle or not. So, the selection criterion corresponds to the measure m described above that is used for partition assessment in Algorithm 2.\nIn [25], different active learning modes are distinguished. These are membership query synthesis (QS), stream-based selective sampling (SS) and pool-based sampling (PS). QS assumes that the learner at each step generates any unlabeled instance within the input space as a query without taking into account the distribution of the input space. In this vein, lots of meaningless queries may be created, which is a major downside of this approach. In SS mode, the learner is provided with single instances sampled from the input space as per the underlying distribution, one-by-one, and for each instance decides whether to use it as a query or not. PS, in contrast, assumes availability of a pool of unlabeled instances, from which the best instance according to some measure is chosen as a query. Contrary to the works [26, 21, 20] which rely on a PS scenario, thus requiring the precomputation of a pool of queries (or q-partitions), we implement an approach that unites characteristics of QS and PS. Namely, we generate q-partitions oneby-one in a best-first manner, quasi on demand, and proceed until a (nearly) optimal q-partition is found. This is similar to what is done for the entropy (ENT) measure (see below) in [27, Sec. 4], but we will optimize and generalize this approach in various aspects.\nIn the subsequent subsections we will describe and analyze diverse active learning query quality measures and adapt them to our heuristic-based approach.\nRemark 3 Although these measures serve the purpose of the determination of the best query w.r.t. the diagnosis elimination rate (cf. [21] and Section 3.2.4), the information gain (cf. [13, 27]) or other criteria (cf. [25]), a more appropriate name would be q-partition quality measures. The first reason for this is that we will, in a two step optimization approach, first optimize the q-partition w.r.t. such a measure and second compute an optimal query (amongst exponentially many, in general) for this fixed q-partition w.r.t. different criteria such as the answer fault probability of the query. The second reason is that the (adapted) active learning measures will only be relevant to the primary optimization step w.r.t. the q-partition in the course of this approach. This means, all properties of an optimal query w.r.t. any of the measures discussed in the following subsections 3.2.1 and 3.2.4 will solely depend on the q-partition associated with this query and not on the query itself. Nevertheless, since we defined these measures to map a query to some value, we will stick to the denotation query quality measure instead of q-partition quality measure throughout the rest of this work."}, {"heading": "3.2.1 Query Quality Measures: Preliminaries and Definitions", "text": "In the following we discuss various measures for query selection. In doing so, we draw on general active learning strategies, demonstrate relationships between diverse strategies and adapt them for employment in our debugging scenario, in particular within the function FINDQPARTITION in Algorithm 2. Note that these active learning measures aim at minimizing the overall number of queries until the correct solution KB is found. The minimization of a query in terms of number of logical formulas asked to the user is done in the SELECTQUERYFORQPARTITION and OPTIMIZEQUERY functions in Algorithm 2.\nConcerning the notation, we will, for brevity, use Q to refer to QD,\u3008K,B,P,N \u3009R throughout the rest of Section 3.2 unless stated otherwise. Moreover, we define according to [13, 27, 21, 20]\np(X) := \u2211 D\u2208X p(D) (5)\nfor some set of diagnoses X, with assuming that for X := D this sum is equal to 1 [20] (this can always be achieved by normalizing each diagnosis probability p(D) forD \u2208 D, i.e. by multiplying it with 1p(D) ). Further, it must hold for each D \u2208 D that p(D) > 0, i.e. each diagnosis w.r.t. a given DPI is possible, howsoever improbable it might be (cf. [20]). For some Q \u2208 Q we define\np(Q = t) := p(D+(Q)) + 1\n2 p(D0(Q)) (6)\nwhich is why\np(Q = f) = 1\u2212 p(Q = t) = p(D\u2212(Q)) + 1 2 p(D0(Q)) (7)\nFurther on, the posterior probability of a diagnosis can be computed by the Bayesian Theorem as\np(D |Q = a) = p(Q = a | D) p(D) p(Q = a)\nwhere\np(Q = t | D) :=  1, if D \u2208 D+(Q) 0, if D \u2208 D\u2212(Q) 1 2 , if D \u2208 D 0(Q)\n(8)\nFor further information on these definitions have a look at [20, Chap. 4 and 9] and [13]. Finally, we note that we will treat the expression 0 log2 0 and as being equal to zero in the rest of this section. 11\nIn the following, we define some new notions about query quality measures and queries which shall prove helpful to formalize and state precisely what we want to mean when calling\n1. a query Q preferred to another query Q\u2032 by some measure m,\n2. a query Q debug-preferred to another query Q\u2032,\n3. a query Q theoretically optimal w.r.t. some measure m,\n4. two measures equivalent to each other,\n5. a measure m consistent with the debug-preference relation\n6. a measure m debug-preference relation preserving, and\n7. one measure m1 superior to another measure m2.\nBefore giving formal definitions of the notions, we state roughly for all notions in turn what they mean:\n1. Means that the measure m would select Q as the best query among {Q,Q\u2032}.\n2. Means that in the worst case at least as many leading diagnoses (or: known hypotheses) are eliminated using Q as a query than by using Q\u2032 as a query, and in the best case more leading diagnoses (or: known hypotheses) are eliminated using Q as a query than by using Q\u2032 as a query.\n3. Means that no modification of the properties of Q (or more precisely: the q-partition of Q, cf. Remark 3) could yield a query that would be preferred to Q by m.\n4. Means that both measures impose exactly the same preference order on any set of queries.\n5. Means that if m prefers Q to Q\u2032, then Q\u2032 cannot be debug-preferred to Q.\n6. Means that if Q is debug-preferred to Q\u2032, then m also prefers Q to Q\u2032.\n7. Means that the set of query pairs for which m1 satisfies the debug-preference relation is a proper superset of the set of query pairs for which m2 satisfies the debug-preference relation.\n11This assumption is plausible since it is easy to show by means of the rule of de l\u2019Hospital that x log2 x converges to zero for x\u2192 0+.\nEvery query quality measure imposes a (preference) order on a given set of queries:\nDefinition 10. Let m be a query quality measure, i.e. m assigns a real number m(Q) to every query Q. Then we want to say that Q is preferred to Q\u2032 by m, formally Q \u227am Q\u2032, iff\n\u2022 m(Q) < m(Q\u2032) in case lower m(Q) means higher preference of Q by m,\n\u2022 m(Q) > m(Q\u2032) in case higher m(Q) means higher preference of Q by m.\nIt can be easily verified that the preference order imposed on a set of queries by a measure m is a strict order:\nProposition 4. Let m be a query quality measure. Then \u227am is a strict order, i.e. it is an irreflexive, asymmetric and transitive relation over queries.\nThe following definition captures what we want to understand when we call two measures equivalent, a query theoretically optimal w.r.t. a measure and a measure superior to another measure.\nDefinition 11. Let m,m1,m2 be query quality measures and let D be a set of leading diagnoses w.r.t. a DPI \u3008K,B,P ,N \u3009R. Then:\n\u2022 We call m1 equivalent to m2, formally m1 \u2261 m2, iff the following holds for all queries Q,Q\u2032: Q \u227am1 Q\u2032 iff Q \u227am2 Q\u2032.\n\u2022 We call m1 X-equivalent to m2, formally m1 \u2261X m2, iff the following holds for all queries Q,Q\u2032 \u2208 X: Q \u227am1 Q\u2032 iff Q \u227am2 Q\u2032.\n\u2022 We call a queryQ theoretically optimal w.r.t.m and D (over the domainDom) iffm(Q) is a global optimum of m (over Dom).\nIf no domain Dom is stated, then we implicitly refer to the domain of all possible partitions\u2329 D+,D\u2212,D0 \u232a (and, if applicable and not stated otherwise, all possible (diagnosis) probability measures p) w.r.t. a set of leading diagnoses D. If a domain Dom is stated, we only refer to queries in this domain of queries Dom over D (and, if applicable and not stated otherwise, all possible (diagnosis) probability measures p). (The name theoretically optimal stems from the fact that there must not necessarily be such a query for a given set of leading diagnoses. In other words, the optimal query among a set of candidate queries might not be theoretically optimal.)\n\u2022 We call a queryQ debug-preferred toQ\u2032 w.r.t. a DPI \u3008K,B,P ,N \u3009R and a set of minimal diagnoses D w.r.t. this DPI iff there is an injective function f that maps each answer a\u2032 to Q\u2032 to an answer a = f(a\u2032) to Q such that\n1. Q answered by f(a\u2032) eliminates a superset of the diagnoses in D eliminated by Q\u2032 answered by a\u2032 (i.e. the worst case answer to Q eliminates at least all leading diagnoses eliminated by the worst case answer to Q\u2032), and\n2. there is an answer a\u2217 toQ\u2032 such thatQ answered by f(a\u2217) eliminates a proper superset of the diagnoses in D eliminated by Q\u2032 answered by a\u2217 (i.e. the best case answer to Q eliminates all leading diagnoses eliminated by the best case answer to Q\u2032 and at least one more).\n\u2022 We call the relation that includes all tuples (Q,Q\u2032) where Q is debug-preferred to Q\u2032 the debugpreference relation and denote it by DPR.\n\u2022 We say that m\n\u2013 preserves (or: satisfies) the debug-preference relation (over X) iff whenever (Q,Q\u2032) \u2208 DPR (and Q,Q\u2032 \u2208 X), it holds that Q \u227am Q\u2032 (i.e. the preference relation imposed on a set of queries by m is a superset of the debug-preference relation).\n\u2013 is consistent with the debug-preference relation (over X) iff whenever (Q,Q\u2032) \u2208 DPR (and Q,Q\u2032 \u2208 X), it does not hold that Q\u2032 \u227am Q (i.e. the preference relation imposed on a set of queries by m has an empty intersection with the inverse debug-preference relation).\n\u2022 We call m2 superior to m1 (or: m1 inferior to m2), formally m2 \u227a m1, iff\n1. there is some pair of queries Q,Q\u2032 such that Q is debug-preferred to Q\u2032 and not Q \u227am1 Q\u2032 (i.e. m1 does not satisfy debug-preference order), 2. for some pair of queries Q,Q\u2032 where Q is debug-preferred to Q\u2032 and not Q \u227am1 Q\u2032 it holds that Q \u227am2 Q\u2032 (i.e. in some cases m2 is better than m1),12 and 3. for no pair of queries Q,Q\u2032 where Q is debug-preferred to Q\u2032 and not Q \u227am2 Q\u2032 it holds that Q \u227am1 Q\u2032 (i.e. m1 is never better than m2).\n\u2022 Analogously, we call m2 X-superior to m1 (or: m1 X-inferior to m2), formally m2 \u227aX m1, iff\n1. there is some pair of queries Q,Q\u2032 \u2208 X such that Q is debug-preferred to Q\u2032 and not Q \u227am1 Q\u2032,\n2. for some pair of queries Q,Q\u2032 \u2208 X where Q is debug-preferred to Q\u2032 and not Q \u227am1 Q\u2032 it holds that Q \u227am2 Q\u2032, and 3. for no pair of queries Q,Q\u2032 \u2208 X where Q is debug-preferred to Q\u2032 and not Q \u227am2 Q\u2032 it holds that Q \u227am1 Q\u2032.\nThe next propositions are simple consequences of this definition (those stated without a proof are very easy to verify).\nProposition 5. Any two (X-)equivalent measures impose identical preference orders on any given fixed set of queries (in X).\nProposition 6. Let Qmi(\u2208 Q) denote the optimal query w.r.t. the measure mi, i \u2208 {1, 2} (in a set of queries Q). Then Qm1 = Qm2 if m1 \u2261(Q) m2.\nProposition 7. The relations \u2261 and \u2261X for any X are equivalence relations.\nProposition 8. The superiority (\u227a) and X-superiority (\u227aX) relations are strict orders.\nProof. We have to show the irreflexivity, asymmetry and transitivity of \u2261 and \u2261X. We give a proof for \u2261. The proof for \u2261X is completely analogous. Irreflexivity is clearly given due to the second condition of the definition of superiority (Definition 11) because \u00ac(Q \u227am1 Q\u2032) cannot hold at the same time as Q \u227am1 Q\u2032.\nTo verify asymmetry, let us restate the third condition of the definition of superiority in an equivalent, but different manner: (3.\u2019) For all pairs of queriesQ,Q\u2032 whereQ is debug-preferred toQ\u2032 andQ \u227am1 Q\u2032 it holds that Q \u227am2 Q\u2032. Now, for the assumption that m2 is superior to m1, we have that \u00ac(Q \u227am1 Q\u2032)\u2227Q \u227am2 Q\u2032 must hold for some pair of queriesQ,Q\u2032 whereQ is debug-preferred toQ\u2032 (by condition (2.) of the definition of superiority). If m1 were at the same time superior to m2, then by (3.\u2019), we would obtain Q \u227am2 Q\u2032 \u21d2 Q \u227am1 Q\u2032 for all pairs of queries Q,Q\u2032 where Q is debug-preferred to Q\u2032. This is clearly a contradiction. Hence, m1 \u227a m2 implies \u00ac(m2 \u227a m1), i.e. asymmetry is given.\n12Note that the second condition (2.) already implies the first condition (1.). Nevertheless, we state the first condition explicitly for better understandability.\nTo check transitivity, let us suppose that (i) m1 \u227a m2 as well as (ii) m2 \u227a m3. We now demonstrate that m1 \u227a m3. By (i) and condition (1.) of the definition of superiority, we know that there is a pair of queries Q,Q\u2032 where Q is debug-preferred to Q\u2032 and not Q \u227am1 Q\u2032. This is at the same time the first condition that must hold for m1 \u227a m3 to be met. By (i) and condition (2.) of the definition of superiority, we know that for some pair of queries Q,Q\u2032 where Q is debug-preferred to Q\u2032 it holds that \u00ac(Q \u227am1 Q\u2032)\u2227Q \u227am2 Q\u2032. Due to Q \u227am2 Q\u2032 and (3.\u2019) we have that in this case Q \u227am3 Q\u2032 is also true. This implies \u00ac(Q \u227am1 Q\u2032)\u2227Q \u227am3 Q\u2032 which is why the second condition that must hold for m1 \u227a m3 to be met is satisfied. The third condition can be directly deduced by applying (3.\u2019) to (i) and (ii). Thence, also the transitivity of \u227a is given.\nDue to the next proposition, we call the debug-preference relation also the debug-preference order.\nProposition 9. The debug-preference relation DPR is a strict order, i.e. it is irreflexive, asymmetric and transitive.\nProposition 10. Given two measuresm1,m2 wherem1 does andm2 does not satisfy the debug-preference relation. Then, m1 is superior to m2.\nProposition 11. Let Q be debug-preferred to Q\u2032 w.r.t. a DPI \u3008K,B,P ,N \u3009R and a set of minimal diagnoses D w.r.t. this DPI. Then D0(Q\u2032) \u2283 D0(Q). In particular, it holds that D0(Q\u2032) 6= \u2205.\nProposition 12. Let Q \u2208 QD,\u3008K,B,P,N \u3009R be a query. Then any query Q \u2032 \u2208 QD,\u3008K,B,P,N \u3009R for which it holds that Q is debug-preferred to Q\u2032 can be obtained from Q by transferring a non-empty set X \u2282 D+(Q)\u222aD\u2212(Q) to D0(Q) and by possibly interchanging the positions of the resulting sets D+(Q) \\X and D\u2212(Q) \\X in the q-partition, i.e.\nP(Q\u2032) = \u2329 D+(Q\u2032),D\u2212(Q\u2032),D0(Q\u2032) \u232a = \u3008D+(Q) \\X,D\u2212(Q) \\X,D0(Q) \u222aX\u3009\nor P(Q\u2032) = \u2329 D+(Q\u2032),D\u2212(Q\u2032),D0(Q\u2032) \u232a = \u3008D\u2212(Q) \\X,D+(Q) \\X,D0(Q) \u222aX\u3009\nProof. By Proposition 3,(2.), of all diagnoses in D exactly the diagnoses D+(Q) are eliminated for the negative answer and exactly the diagnoses D\u2212(Q) are eliminated for the positive answer to Q. By the definition of debug-preference between two queries (Definition 11), D+(Q\u2032) must be a subset of one element in {D+(Q),D\u2212(Q)} and D\u2212(Q\u2032) must be a subset of the other element in {D+(Q),D\u2212(Q)} where one of these subset relationships must be proper. This clearly means that either (a) D+(Q\u2032) = D+(Q) \\X and D\u2212(Q\u2032) = D\u2212(Q) \\X or (b) D+(Q\u2032) = D\u2212(Q) \\X and D\u2212(Q\u2032) = D+(Q) \\X for some X \u2282 D+(Q) \u222aD\u2212(Q). The fact that one subset relationship mentioned above must be proper enforces additionally that X 6= \u2205. Due to the assumption thatQ\u2032 is a query and hence D+(Q\u2032)\u222aD\u2212(Q\u2032)\u222a D0(Q\u2032) = D must hold (Proposition 3,(1.)), the set of diagnoses X eliminated from D+(Q) \u222aD\u2212(Q) must be added to D0(Q) to obtain Q\u2032.\nMoreover, the possibility of transferring some diagnoses from D+(Q) to D\u2212(Q) or from D\u2212(Q) to D+(Q) in order to obtainQ\u2032 is ruled out. For instance, assume that S \u2282 D+(Q) is transferred to D\u2212(Q), i.e. D\u2212(Q\u2032) = D\u2212(Q) \u222a S, then D\u2212(Q\u2032) cannot be a subset of D\u2212(Q) since D\u2212(Q\u2032) \u2283 D\u2212(Q) and it cannot be a subset of D+(Q). The latter must hold since Q is a query by assumption which implies that D\u2212(Q) 6= \u2205 (Proposition 3,(6.)) and D+(Q)\u2229D\u2212(Q) = \u2205 (Proposition 3,(1.)) which is why there must be a diagnosis D \u2208 D\u2212(Q\u2032) which is not in D+(Q).\nOverall, we have derived that all queries Q\u2032 where Q is debug-preferred to Q\u2032 can be obtained from Q only in either of the two ways stated in the proposition. This completes the proof.\nProposition 13. Let m be a query quality measure and let f(m) be the measure resulting from the application of a linear function f(x) = ax+ b with a \u2208 R+ \\ {0} and b \u2208 R to m. Then f(m) \u2261 m.\nExample 12 on page 38 will illustrate the notions given in this section. However, before, in Section 3.2.2, we present and discuss two query quality measures that have already been extensively analyzed in (debugging) literature [26, 27, 21, 20], which we will use in the example."}, {"heading": "3.2.2 Existing Active Learning Measures for KB Debugging", "text": "Active learning strategies that use information theoretic measures as selection criterion have been shown to reduce the number of queries as opposed to standard \u201cnon-active\u201d supervised learning methods in many diverse application scenarios such as text, video and image classification, information extraction, speech recognition and cancer diagnosis [25]. Also in the field of interactive ontology debugging, two active learning measures have been adopted [26, 27, 21] and shown to clearly outperform a (non-active) random strategy of selecting the next query [27]. These are entropy-based (ENT) and split-in-half (SPL) query selection.\nEntropy-Based Query Selection (ENT). The best query QENT according to ENT has the property to maximize the information gain or equivalently to minimize the expected entropy in the set of leading diagnoses after QENT is classified by the user and added as a test case to the DPI. Concretely,\nQENT = arg min Q\u2208Q (ENT(Q)) (9)\nwhere\nENT(Q) := \u2211\na\u2208{t,f}\np(Q = a) \u00b7 [ \u2212 \u2211 D\u2208D p(D |Q = a) log2 p(D |Q = a) ] (10)\nTheoretically optimal w.r.t. ENT is a query whose positive and negative answers are equally likely and none of the diagnoses D \u2208 D is consistent with both answers.\nProposition 14. Let D be a set of leading diagnoses w.r.t. a DPI \u3008K,B,P ,N \u3009R. Then:\n1. A query Q is theoretically optimal w.r.t. ENT and D iff p(D+(Q)) = p(D\u2212(Q)) as well as p(D0(Q)) = 0.\n2. Let q be a fixed number in [0, 1] and let Q be a set of queries where each query Q \u2208 Q satisfies p(D0(Q)) = q. Then the theoretically optimal query w.r.t. ENT over Q satisfies p(Q = t) = p(Q = f) and p(D+(Q)) = p(D\u2212(Q)).\nProof. In [13] it was shown that ENT(Q) can be equivalently transformed into \u2211 a\u2208{t,f} p(Q = a) log2 p(Q = a) + p(D0(Q)) + 1 (11) First, observe that p(D0(Q)) is independent of the sum in squared brackets. That is, we can minimize the entire formula by minimizing p(D0(Q)) and the sum in squared brackets separately. The sum\u2211\na\u2208{t,f} p(Q = a) log2 p(Q = a) can be written as x log2 x+ (1\u2212 x) log2(1\u2212 x) for 0 < x := p(Q = t) < 1. Differentiation by x and setting the derivative equal to zero yields log2 x = log2(1\u2212 x). By the fact that log2 x is monotonically increasing, this implies that x = p(Q = t) = p(Q = f) = 1 2 . Due to Eq. 6 and Eq. 7, this implies that p(D+(Q)) = p(D\u2212(Q)). Building the second derivative yields 1x\u2212x2 which is positive for x \u2208 (0, 1) since x2 < x in this interval. Hence p(Q = t) = 12 is a local minimum. Since however the sum \u2211 a\u2208{t,f} p(Q = a) log2 p(Q = a) is a strictly convex function and (0, 1) a\nconvex set, p(Q = t) = 12 must be the (unique) global minimum as well. Hence, the global minimum is attained if p(Q = t) = p(Q = f). By Eq. 6 and Eq. 7 this is equivalent to p(D+(Q)) = p(D\u2212(Q)). This proves statement (2.) of the proposition. To optimize the entire formula for QENT, p(D0(Q)) must additionally be minimized as p(D0(Q)) is a positive addend in the formula. This proves statement (1.) of the proposition.\nThe following proposition analyzes for which classes of queries the ENT measure does and does not preserve the debug-preference order (according to Definition 11). Before stating the proposition, however, we define a measure ENTz that is used in the proposition and constitutes a generalization of the ENT measure. Namely, ENTz selects the query\nQENTz := arg min Q\u2208Q (ENTz(Q)) (12)\nwhere\nENTz(Q) :=  \u2211 a\u2208{t,f} p(Q = a) log2 p(Q = a) + z p(D0(Q)) + 1 (13) Note that ENTz(Q) = ENT(Q) + (z \u2212 1)p(D0(Q)) and thus that ENT1 is equal to ENT and ENT0 \u2212 1 is equal to H, LC and M (cf. Proposition 19 and the proof of Proposition 20).\nProposition 15. LetQ be a query w.r.t. a set of minimal diagnoses D w.r.t. a DPI \u3008K,B,P ,N \u3009R. Further, let p := mina\u2208{t,f}(p(Q = a)) and Q\u2032 be a query such that Q is debug-preferred to Q\u2032. In addition, let x := p(D0(Q\u2032))\u2212 p(D0(Q)). Then:\n1. x > 0.\n2. If x \u2265 1\u2212 2p, then Q \u227aENT Q\u2032.\n3. If x < 1\u2212 2p, then:\n(a) In general it does not hold that Q \u227aENT Q\u2032. (b) If not Q \u227aENT Q\u2032, then p \u2208 (0, t] where t := 15 . (c) If not Q \u227aENTz Q\u2032, then p \u2208 (0, t(z)] where t(z) := (22z + 1)\u22121 and limz\u2192\u221e t(z)\u2192 0, i.e.\nthe upper interval bound can be arbitrarily minimized. In other words, the range of queries that might be misordered by ENTz w.r.t. debug-preference order can be made arbitrarily small. The statements (2.) and (3.a) of this proposition still hold if ENT is replaced by ENTz for all real numbers z \u2265 0.\nProof. We prove the statements in turn:\n1. This is a direct consequence of Proposition 11 and the fact that p(D) > 0 for all D \u2208 D (cf. page 26).\n2. The idea to show this statement is (1) to describe the best possible query Q\u2217 in terms of the ENT measure for some given x such that Q is debug-preferred to Q\u2217 and x = p(D0(Q\u2217))\u2212 p(D0(Q)) and (2) to demonstrate thatQ \u227aENT Q\u2217 for this best possible queryQ\u2217. The conclusion is then that Q \u227aENT Q\u2032 must hold for all queries Q\u2032 where Q is debug-preferred to Q\u2032 and x = p(D0(Q\u2032))\u2212 p(D0(Q)).\nRegarding (1), we make the following observations: Let w.l.o.g. p(D+(Q)) \u2264 p(D\u2212(Q)), i.e. p = p(Q = t). Through Proposition 12 we know that we can imagine Q\u2032 \u201cresulting\u201d from Q\nby transferring diagnoses with overall probability mass x from D+(Q) \u222a D\u2212(Q) to D0(Q) and by possibly replacing all diagnoses in the resulting set D+(Q) by all diagnoses in the resulting set D\u2212(Q) and vice versa. Due to Eq. 6 and Eq. 7 and p \u2264 12 we have that |p(D\n+(Q))\u2212p(D\u2212(Q))| = (1\u2212p)\u2212p = 1\u22122p. Now, by Proposition 14 we know that the best query among all queriesQwith fixed p(D0(Q)) = q satisfies p(D+(Q)) = p(D\u2212(Q)). Here, q = p(D0(Q))+x. That is, the best query Q\u2217 must satisfy p(D+(Q\u2217)) = p(D\u2212(Q\u2217)). This can be achieved for Q since x \u2265 1 \u2212 2p, i.e. diagnoses with a probability mass of 1 \u2212 2p can be transferred from D\u2212(Q) to D+(Q). If x were larger than 1\u2212 2p, then further diagnoses with a probability mass of x\u22121\u22122p2 > 0 would have to be transferred from each of the sets D+(Q) and D\u2212(Q) to D0(Q) resulting in a query Q\u2032\u2032 with unchanged p(D+(Q\u2032\u2032)) = p(D+(Q\u2217)) and p(D\u2212(Q\u2032\u2032)) = p(D\u2212(Q\u2217)), but with a worse ENT measure as p(D0(Q\u2217)) = p(D0(Q)) + 1 \u2212 2p < p(D0(Q)) + 1 \u2212 2p + x\u22121\u22122p2 = p(D\n0(Q\u2032\u2032)). Hence, Q\u2217 results from transferring exactly a probability mass of 1 \u2212 2p from the more probable set D\u2212(Q) (see assumption above) in {D+(Q),D\u2212(Q)} to D0(Q). Concerning (2), we now demonstrate that Q \u227aENT Q\u2217: We know that p \u2264 12 . Assume that p = 1 2 . In this case, the assumption of (2.) is x \u2265 1\u22122p = 1\u22122 \u00b7 12 = 0. However, due to (1.) which states that x > 0, we have that x > 1\u22122p in this case. HenceQ\u2217, whose construction requires x = 1\u22122p, cannot be constructed. Since all other queries (which can be constructed for x > 1 \u2212 2p) have a worse ENT measure than Q\u2217, as shown above, statement (2.) of the proposition holds for p = 12 . If, otherwise, p < 12 , let z := p(D 0(Q)). Next, recall Eq. 11 and observe that the sum in squared brackets is independent from the two addends right from it and minimized by setting p(Q = t) = p(Q = f) = 12 (cf. the proof of Proposition 14). The minimum is then \u2212 log2 2 = \u22121. That is, the ENT measure of Q\u2217 is given by ENT(Q\u2217) := \u22121 + (z + 1 \u2212 2p) + 1. On the other hand, the ENT measure of Q amounts to ENT(Q) := p log2 p + (1 \u2212 p) log2(1 \u2212 p) + z + 1. Since a smaller ENT measure signalizes a better query, we must show that ENT(Q\u2217) > ENT(Q). That is, we need to argue that 2p < \u2212p log2 p \u2212 (1 \u2212 p) log2(1 \u2212 p). Now, because p \u2264 1 \u2212 p and log2 x \u2264 0 for x \u2264 1 we have that the righthand side of the inequality\u2212p log2 p\u2212 (1\u2212p) log2(1\u2212 p) \u2265 \u2212p log2 p \u2212 p log2(1 \u2212 p) = p \u00b7 (\u2212 log2 p \u2212 log2(1 \u2212 p)). It remains to be shown that \u2212 log2 p\u2212 log2(1\u2212 p) > 2. To prove this, we observe that p \u2208 (0, 12 ) must hold since D\n+(Q) and D\u2212(Q) must not be equal to the empty set (cf. Proposition 3) and due to p(D) > 0 for all D \u2208 D. It is well known that a differentiable function of one variable (in our case p) is convex on an interval (in our case (0, 12 ]) iff its derivative is monotonically increasing on that interval which in turn is the case iff its second derivative is larger than or equal to 0 on that interval. Further, it is well known that a local minimum of a convex function is a global minimum of that function. The first derivative of \u2212 log2 p \u2212 log2(1 \u2212 p) is \u2212 1p + 1 1\u2212p , the second is 1 p2 + 1 (1\u2212p)2 which is clearly greater than 0 for p \u2208 (0, 12 ]. Consequently, \u2212 log2 p \u2212 log2(1 \u2212 p) is convex for p \u2208 (0, 1 2 ]. Setting the first derivative equal to 0, we obtain 1 = 2p, i.e. p = 12 as the (single) point where the global minimum is attained. The global minimum of\u2212 log2 p\u2212 log2(1\u2212p) for p \u2208 (0, 12 ] is then 2 log2 2 = 2. Now, the deletion of the point 12 from the interval means that \u2212 log2 p\u2212 log2(1\u2212 p) > 2 for p \u2208 (0, 1 2 ). This completes the proof.\n3. We again prove all statements in turn:\n(a) Here a simple counterexample suffices. One such is given by assuming that p = 0.1 and p(D0(Q)) = 0 and that diagnoses with a probability mass of x = 0.05 are deleted from D\u2212(Q) and transferred to D0(Q) to obtain a query Q\u2032. Clearly, Q is debug-preferred to Q\u2032. However, the ENT measure forQ amounts to 0.531 whereas forQ\u2032 it amounts to 0.506 which is why Q\u2032 \u227aENT Q holds (recall that better queries w.r.t. ENT have a lower ENT measure). By the asymmetry of the strict order \u227aENT, we obtain that Q \u227aENT Q\u2032 cannot be satisfied.\n(b) Let us assume that x < 1 \u2212 2p, that Q is debug-preferred to Q\u2032 and Q\u2032 \u227aENT Q. We recall from the proof of (2.) that we can imagine that Q\u2032 \u201cresults\u201d from Q by transferring diagnoses with overall probability mass x from D+(Q) \u222aD\u2212(Q) to D0(Q) and by possibly replacing all diagnoses in the resulting set D+(Q) by all diagnoses in the resulting set D\u2212(Q) and vice versa (holds due to Proposition 12). Now, by assumption, x is smaller than the difference 1 \u2212 2p between the larger and the smaller value in {p(D+(Q)), p(D\u2212(Q))}. Further, for fixed p(D0(Q)), the function p log2 p+ (1\u2212 p) log2(1\u2212 p) + p(D0(Q)) + 1 characterizing ENT(Q) is convex and thus has only one local (and global) minimum for p \u2208 (0, 1) since its second derivative 1p + 1 1\u2212p > 0 on this interval. The minimum of ENT(Q) is given by p = 1 2\n(calculated by setting the first derivative log2 p\u2212 log2(1\u2212 p) equal to 0). Hence, the best Q\u2032 (with minimal ENT value) that can be \u201cconstructed\u201d fromQ is given by transferring diagnoses with a probability mass of x from arg maxX\u2208{D+(Q),D\u2212(Q)} {p(X)} to p(D0(Q)). For these reasons and due to Equations 6 and 7, we can write ENT(Q\u2032) as (p + x2 ) log2(p + x 2 )+(1\u2212p\u2212 x 2 ) log2(1\u2212p\u2212 x 2 )+(p(D\n0(Q))+x)+1. We now want to figure out the interval i \u2286 (0, 12 ] of pwhere ENT(Q\n\u2032) might be smaller than or equal to ENT(Q). In other words, we ask the question for which values of p it is possible that (*): p log2 p+ (1\u2212 p) log2(1\u2212 p) \u2265 (p+ x2 ) log2(p+ x 2 )+(1\u2212p\u2212 x 2 ) log2(1\u2212p\u2212 x 2 )+x (note that p(D\n0(Q))+1 was eliminated on both sides of the inequality). To this end, let us denote the left side of this inequality by LS and consider once again the derivative log2 p\u2212 log2(1\u2212 p) of LS. Clearly, for values of p where this derivative is smaller than or equal to \u22122, there is a (possibly infinitesimally small) value of x such that the increase of p by x2 yields a decrease of LS by at least 2 x 2 = x. That is, (p+ x2 ) log2(p+ x 2 ) + (1\u2212 p\u2212 x 2 ) log2(1\u2212 p\u2212 x 2 ) \u2264 p log2 p+ (1\u2212 p) log2(1\u2212 p)\u2212 x holds which is equivalent to (*). Plugging in 15 into the derivative of LS yields log2 1 5\u2212log2 4 5 = \u2212 log2 5\u2212(log2 4\u2212log2 5) = \u2212 log2 4 = \u22122. Since the derivative of LS is monotonically increasing (second derivative is greater than zero for p \u2208 (0, 1), see above), we obtain that the sought interval i of p must be given by (0, 15 ]. (c) Using the same notation as above, ENTz(Q) reads as p log2 p + (1 \u2212 p) log2(1 \u2212 p) + z \u00b7 p(D0(Q))+1 (cf. Eq. 13). Rerunning the proof of statement (3.b) above for ENTz implies deriving the interval for p where (**): p log2 p + (1 \u2212 p) log2(1 \u2212 p) \u2265 (p + x2 ) log2(p + x 2 ) + (1 \u2212 p \u2212 x 2 ) log2(1 \u2212 p \u2212 x 2 ) + z \u00b7 x holds instead of (*) above. Analogously to the\nargumentation above, the sought interval is given by (0, t(z)] where t(z) is the value of p for which the derivative log2 p \u2212 log2(1 \u2212 p) of p log2 p + (1 \u2212 p) log2(1 \u2212 p) is equal to \u22122z (which yields \u2212z \u00b7 x after multiplication with x2 , see above). To calculate this value, we exploit the inverse function f\u22121(q) of the (injective) derivative log2 p\u2212 log2(1\u2212 p) = f(p) = q. The derivation of f\u22121(q) goes as follows:\nq = log2 p\u2212 log2(1\u2212 p) = log2( p\n1\u2212 p )\n2q = p\n1\u2212 p\n2\u2212q = 1\u2212 p p = 1 p \u2212 1\n(2\u2212q + 1)\u22121 = p = f\u22121(q)\nPlugging in q = \u22122z into f\u22121(q) yields t(z) = (22z + 1)\u22121. For instance, for z := 1 (standard ENT measure), we obtain t = 15 by plugging in \u22122 into the inverse function. For e.g. z := 5 we get t = 11025 (by plugging in \u221210).\nClearly, limz\u2192\u221e t(z) \u2192 0. It is moreover straightforward to verify that ENTz for z \u2265 0 satisfies the statements (2.) and (3.a) of this proposition.\nThe next corollary is an immediate consequence of Proposition 15. It establishes that the debugpreference order is preserved by ENT for the most interesting class of queries w.r.t. ENT, namely those for which the probabilities of both answers are similar (cf. Proposition 14). In other words, ENT might only (i) not prefer a debug-preferred query to a suboptimal one or (ii) prefer a suboptimal query to a debug-preferred one in case the debug-preferred one is not desirable itself. That is, ENT orders the most desirable queries correctly w.r.t. the debug-preference order.\nCorollary 1. Let Q be a query and pQ := mina\u2208{t,f}(p(Q = a)). Let further Q be a set of queries where each query Q in this set satisfies pQ > 15 . Then, ENT satisfies the debug-preference relation (over Q) (Definition 11).\nProof. This statement is a consequence of applying the law of contraposition to the implication stated by Proposition 15,(3.b).\nRoughly, the next corollary states that the relation \u227aENTz with a higher value of z includes at least as many correct query tuples w.r.t. the debug-preference order as the relation \u227aENTz for a lower value of z:\nCorollary 2. Let Q,Q\u2032 be queries such that Q is debug-preferred to Q\u2032 and 0 \u2264 r < s. Then: If not Q \u227aENTs Q\u2032, then not Q \u227aENTr Q\u2032 either.\nProof. Due to Proposition 12 any Q\u2032 for which Q is debug-preferred to Q\u2032 \u201cresults\u201d from Q by transferring diagnoses with overall probability mass x from D+(Q) \u222a D\u2212(Q) to D0(Q) and by possibly replacing all diagnoses in the resulting set D+(Q) by all diagnoses in the resulting set D\u2212(Q) and vice versa. Now, if not Q \u227aENTs Q\u2032, then p log2 p+ (1\u2212 p) log2(1\u2212 p) \u2265 (p+ x2 ) log2(p+ x 2 ) + (1\u2212 p\u2212 x 2 ) log2(1\u2212 p\u2212 x 2 ) + s \u00b7 x (using the same notation as in and referring to the proofs of bullets (3.b) and (3.c) of Proposition 15). However, due to r < s and x > 0 (as per bullet (1.) of Proposition 15), we also obtain that p log2 p+ (1\u2212 p) log2(1\u2212 p) \u2265 (p+ x2 ) log2(p+ x 2 ) + (1\u2212 p\u2212 x 2 ) log2(1\u2212 p\u2212 x 2 ) + r \u00b7 x which implies that Q \u227aENTr Q\u2032 does not hold.\nIn addition to that, Proposition 15 enables us to deduce a measure ENTz from ENT which minimizes the proportion of queries that might potentially be misordered by ENTz w.r.t. the debug-preference order to arbitrarily small size:\nCorollary 3. Let pQ := mina\u2208{t,f}(p(Q = a)) for some query Q. Let further Q be a set of queries where each query Q \u2208 Q satisfies pQ > t for an arbitrary real number t > 0. Then, for each z \u2265 max { \u2212 12 (log2 t\u2212 log2(1\u2212 t)), 1 } the measure ENTz satisfies the debug-preference relation over Q (Definition 11).\nProof. Since pQ \u2264 12 due to the definition of pQ, we have that for t \u2265 1 2 the set Q must be empty which is why the statement of the corollary is true. Otherwise, if t \u2208 [ 15 , 1 2 ), we first consider the case t = 1 5 and compute \u2212 1 2 (log2 t\u2212 log2(1\u2212 t)) = 1. Since log2 t\u2212 log2(1\u2212 t) is strictly monotonically increasing (its derivative 1t + 1\n1\u2212t is greater than 0) for t \u2208 (0, 12 ), i.e. particularly for t \u2208 [ 1 5 , 1 2 ), we have that \u2212 1 2 (log2 t\u2212 log2(1\u2212 t)) is strictly monotonically decreasing for t \u2208 (0, 12 ), i.e. particularly for t \u2208 [ 1 5 , 1 2 ). Therefore, for all t \u2208 ( 1 5 , 1 2 ), the result of plugging t into \u2212 12 (log2 t \u2212 log2(1 \u2212 t)) is smaller than the result of plugging in t = 1 5 . Consequently,\nmax { \u2212 12 (log2 t\u2212 log2(1\u2212 t)), 1 } = 1 for t \u2208 [ 15 , 1 2 ).\nSo, for t \u2208 [ 15 , 1 2 ) we need to verify that ENTz for z \u2265 1 satisfies the debug-preference relation over Q. Indeed, for z = 1 and t = 15 the measure ENTz satisfies the debug-preference relation over Q due\nto Corollary 1 and the fact that ENT is equal to ENTz for z = 1. For z > 1 and t = 15 , ENTz must also satisfy the debug-preference relation over Q as a consequence of Corollary 2. In other words, we have shown so far that for any set of queries where each query Q in this set satisfies pQ > 15 the measure ENTz for all z \u2265 1 satisfies the debug-preference relation.\nHowever, as pQ > t for t > 15 in particular means that pQ > 1 5 , it is an implication of the proof so far\nthat ENTz for z \u2265 1 satisfies the debug-preference relation over Q for all t \u2208 [ 15 , 1 2 ).\nNow, assume an arbitrary t \u2208 (0, 15 ). By the analysis above we know that for all t \u2208 (0, 1 5 ) the value of \u2212 12 (log2 t \u2212 log2(1 \u2212 t)) must be greater than 1. So, max { \u2212 12 (log2 t\u2212 log2(1\u2212 t)), 1 } = \u2212 12 (log2 t\u2212 log2(1\u2212 t)) for t \u2208 (0, 1 5 ).\nLet us recall the proof of bullet (3.b) of Proposition 15. According to the argumentation there, we compute the slope of p log2 p + (1 \u2212 p) log2(1 \u2212 p) at p = t by plugging p = t into the derivative log2 p \u2212 log2(1 \u2212 p) of this function yielding log2 t \u2212 log2(1 \u2212 t). Further, as it became evident in the proof of bullet (3.c) of Proposition 15, the suitable value of z can be obtained by dividing this number by \u22122. Now, because each query Q \u2208 Q satisfies pQ > t, setting z := \u2212 12 (log2 t \u2212 log2(1 \u2212 t)) results in a measure ENTz that satisfies the debug-preference relation. That this does hold also for all z > \u2212 12 (log2 t\u2212 log2(1\u2212 t)) is a direct consequence of Corollary 2.\nExample 10 Let t := 1109 . Then ENTz for z := 15 preserves the debug-preference order for all queries for which the more unlikely answer has a probability of at least 10\u22129. For t := 11020 , a value of z := 34 guarantees that ENTz preserves the debug-preference order for all queries for which the more unlikely answer has a probability of at least 10\u221220. This illustrates that the ENTz measure can be configured in a way it imposes an order consistent with the debug-preference order on any set of queries that might practically occur.\nCorollary 4. Let 0 \u2264 r < s. Then ENTr is inferior to ENTs.\nProof. To show that ENTr is inferior to ENTs we must verify all conditions of the definition of inferiority between two measures (cf. Definition 11). Since 0 \u2264 r < s, condition (3.) is met because of Corollary 2. An example confirming the validity of conditions (1.) and (2.) can be constructed in an analogous way as in the proof of bullet (3.a) of Proposition 15 by using the train of thoughts of the proof of bullet (3.b) of Proposition 15.\nSplit-In-Half Query Selection (SPL). The selection criterion SPL, on the other hand, votes for the query\nQSPL = arg min Q\u2208Q\n(SPL(Q)) where SPL(Q) := \u2223\u2223 |D+(Q)| \u2212 |D\u2212(Q)| \u2223\u2223+ |D0(Q)|\nand hence is optimized by queries for which the number of leading diagnoses predicting the positive answer is equal to the number of leading diagnoses predicting the negative answer and for which each leading diagnosis does predict an answer.\nProposition 16. Let D be a set of leading diagnoses w.r.t. a DPI \u3008K,B,P ,N \u3009R. Then:\n1. A query Q is theoretically optimal w.r.t. SPL and D iff |D+(Q)| = |D\u2212(Q)| as well as |D0(Q)| = 0.\n2. Let q \u2208 {0, . . . , |D|} be a fixed number. Further, let Q be a set of queries w.r.t. D and \u3008K,B,P ,N \u3009R where each query Q \u2208 Q satisfies |D0(Q)| = q. Then the theoretically optimal query w.r.t. SPL and D over Q satisfies |D+(Q)| = |D\u2212(Q)|.\nProposition 17.\n1. SPL is consistent with the debug-preference relation DPR, but does not satisfy DPR.\n2. Let d(Z) := | |D+(Z)| \u2212 |D\u2212(Z)| | for some query Z and let Q,Q\u2032 be two queries such that Q is debug-preferred to Q\u2032. Then not Q \u227aSPL Q\u2032 iff SPL(Q) = SPL(Q\u2032) and d(Q) \u2212 d(Q\u2032) = (|D0(Q\u2032)| \u2212 |D0(Q)|).\nProof. Let Q,Q\u2032 be two queries such that Q is debug-preferred to Q\u2032. By Proposition 12 Q\u2032 differs from Q in that |X| > 0 diagnoses are deleted from D+(Q) \u222a D\u2212(Q) and added to D0(Q) to obtain Q\u2032. Thence, |D0(Q\u2032)| = |D0(Q)| + |X|. It holds that |d(Q) \u2212 d(Q\u2032)| \u2264 |X| since d(Q) can apparently not change by more than |X| through the deletion of |X| diagnoses from D+(Q) \u222a D\u2212(Q). Hence, SPL(Q) \u2264 SPL(Q\u2032) which is why either Q \u227aSPL Q\u2032 or SPL(Q) = SPL(Q\u2032). In the latter case, Q and Q\u2032 do not stand in a \u227aSPL relationship with one another (cf. Definition 10). In the former case, due to Proposition 4 (asymmetry of \u227aSPL) Q\u2032 \u227aSPL Q cannot hold. Altogether, we have shown that Q\u2032 \u227aSPL Q cannot be valid for any two queries Q,Q\u2032 where Q is debug-preferred to Q\u2032. Therefore, SPL is consistent with the debug-preference relation DPR.\nTo see why SPL does not satisfy DPR, let us construct an example of two queries Q,Q\u2032 where Q is debug-preferred to Q\u2032, but not Q \u227aSPL Q\u2032. To this end, let\u2329\nD+(Q),D\u2212(Q),D0(Q) \u232a\n= \u3008{D1,D2} , {D3} , \u2205\u3009\u2329 D+(Q\u2032),D\u2212(Q\u2032),D0(Q\u2032) \u232a = \u3008{D1} , {D3} , {D2}\u3009\nApparently, Q is debug-preferred to Q\u2032 (cf. Proposition 12 with the set X = {D2}). Furthermore, SPL(Q) = SPL(Q\u2032) = 1 which implies by Definition 10 that Q \u227aSPL Q\u2032 does not hold. This finishes the proof of bullet (1.).\nThe truth of the statement of bullet (2.) becomes evident by reconsidering the argumentation used to prove (1.). Clearly, not Q \u227aSPL Q\u2032 holds iff SPL(Q) = SPL(Q\u2032). The latter, however, is true iff |X|, by which |D0(Q\u2032)| is larger than |D0(Q)|, is exactly the difference between d(Q)\u2212 d(Q\u2032).\nLet us now, in a similar way as done with ENT, characterize a measure SPLz that constitutes a generalization of the SPL measure. Namely, SPLz selects the query\nQSPLz := arg min Q\u2208Q (SPLz(Q))\nwhere\nSPLz(Q) := \u2223\u2223 |D+(Q)| \u2212 |D\u2212(Q)| \u2223\u2223+ z |D0(Q)| (14)\nNote that SPLz(Q) = SPL(Q) + (z \u2212 1)|D0(Q)| and thus that SPL1 is equal to SPL. The analysis of this generalized split-in-half measure yields the following results:\nProposition 18. SPLz satisfies the debug preference relation DPR for all real numbers z > 1.\nProof. Let z > 1 and let us recall the proof of Proposition 17 and reuse the assumptions and the notation of this proof. For SPLz we have that |D0(Q\u2032)| = |D0(Q)|+ z |X| > |D0(Q)|+ |X| due to |X| > 0, but still |d(Q)\u2212 d(Q\u2032)| \u2264 |X|. Hence, is must be the case that SPLz(Q) < SPLz(Q\u2032), i.e. Q \u227aSPL2 Q\u2032 (cf. Definition 10), for any two queries Q,Q\u2032 where Q is debug-preferred to Q\u2032 and z > 1.\nCorollary 5. SPLz is superior to SPL for all real numbers z > 1.\nProof. We have to verify the three bullets of the definition of superiority (cf. Definition 11). The first bullet is satisfied due to the example given in the proof of Proposition 17. The condition of the second bullet is met due to the example given in the proof of Proposition 17 and Proposition 18. Finally, the postulation of the third bullet is fulfilled due to Proposition 18.\nWe want to emphasize at this point that Corollary 5 does not imply that SPLr \u2261 SPLs for all real numbers r, s > 1. To recognize this, consider the following example:\nExample 11 Assume two queries Q1, Q2 in Q where\n\u3008|D+(Q1)|, |D\u2212(Q1)|, |D0(Q1)|\u3009 = \u30087, 3, 8\u3009 \u3008|D+(Q2)|, |D\u2212(Q2)|, |D0(Q2)|\u3009 = \u30084, 4, 10\u3009\nand let r := 1.1 and s := 10. Then,\nSPLr(Q1) = 4 + 1.1 \u00b7 8 = 12.8 SPLr(Q2) = 0 + 1.1 \u00b7 10 = 11 SPLs(Q1) = 4 + 10 \u00b7 8 = 84 SPLs(Q2) = 0 + 10 \u00b7 10 = 100\nThat is, Q2 \u227aSPLr Q1, but Q1 \u227aSPLs Q2. Consequently, SPLr 6\u2261 SPLs (cf. Definition 11).\nThe following example (cf. [20, Ex. 9.1]) illustrates the notions explicated in Section 3.2.1:\nExample 12 Let \u3008K,B,P ,N \u3009R be a DPI and D := {D1, . . . ,D4} a set of leading diagnoses w.r.t. \u3008K,B,P ,N \u3009R. Now, consider the example q-partitions for queries named Q1, . . . , Q10 w.r.t. this DPI listed in the lefthand columns of Table 4. The righthand columns of Table 4 show the preference order of queries (lower values mean higher preference) induced by different measures discussed in this example. Now the following holds:\n\u2022 Q6 is theoretically optimal w.r.t. ENT since p(D+(Q6)) = 0.5, p(D\u2212(Q6)) = 0.5 and D0(Q6) = \u2205 (cf. Proposition 14).\n\u2022 Q7, Q8 andQ9 are theoretically optimal w.r.t. SPL since |D+(Qi)| = |D\u2212(Qi)| and |D0(Qi)| = 0 for i \u2208 {7, 8, 9} (cf. Proposition 16).\n\u2022 Let SPL\u2032 be a measure defined in a way that it selects the query\nQSPL\u2032 := arg min Q\u2208Q\n( SPL\u2032(Q) ) where\nSPL\u2032(Q) := x (\u2223\u2223 |D+(Q)| \u2212 |D\u2212(Q)| \u2223\u2223+ |D0(Q)|)+ y\nfor some fixed x \u2208 R+ \\ {0} and some fixed y \u2208 R. Then SPL\u2032 \u2261 SPL (cf. Proposition 13).\n\u2022 For instance, it holds that SPL2 6\u2261 SPL (cf. Eq. 14). To see this, consider the righthand side of Table 4 and compare the preference orders induced by SPL and SPL2. We can clearly identify that, e.g. Q3 \u227aSPL2 Q2, but not Q3 \u227aSPL Q2.\n\u2022 It holds that Q9 is debug-preferred to Q5 as well as to Q2 because Qi for i \u2208 {2, 5} shares one set in {D+(Qi),D\u2212(Qi)} with {D+(Q9),D\u2212(Q9)}, but exhibits a set D0(Qi) \u2283 D0(Q9). For instance, let us verify the definition of debug-preference (Definition 11) for Q9 versus Q5: The\npositive answer to Q9 eliminates {D1,D2} whereas the negative answer to Q5 eliminates only a proper subset of this set, namely {D2}. The negative answer to Q9 eliminates {D3,D4} which is equal \u2013 and thus a (non-proper) subset \u2013 of the set of leading diagnoses eliminated by the positive answer to Q5. Hence, we have found an injective function compliant with Definition 11 (which maps the negative answer of Q5 to the positive answer of Q9 and the positive answer to Q5 to the negative answer to Q9).\nOn the other hand, Q9 is for example not debug-preferred to Q10. Whereas for the negative answer toQ10 (eliminates one diagnosisD1 in D) there is an answer toQ9, namely the positive one, which eliminates {D1,D2}, a superset of {D1}, there is no answer to Q9 which eliminates a superset of the set {D2,D3,D4} eliminated by the positive answer to Q10. Hence, the queries Q9 and Q10 are in no debug-preference relation with one another.\nPlease note that Q4 is not debug-preferred to Q5 either, although we have the situation where for each answer to Q5 there is an answer to Q4, namely the negative one, that eliminates a superset of the leading diagnoses eliminated by the respective answer to Q5. However, the reason why this does not result in a debug-preference relation between these two queries is that the function f is not injective in this case because f maps both answers to Q5 to the same answer to Q4. Intuitively, we do not consider Q5 worse than Q4 since using Q4 we might end up in a scenario where none of the diagnoses eliminated by some answer to Q5 are ruled out. This scenario would be present when getting a positive answer to Q4 implying the elimination of D1 and thus neither {D2} nor {D3,D4}.\n\u2022 It holds that Q3 \u227aENT Q10 \u227aENT Q1, but Q3, Q10 and Q1 do not stand in any \u227aSPL relationship with one another. The former holds since all three queries feature an empty set D0, but the difference between p(D+) and p(D\u2212) is largest for Q1 (p(D+(Q1)) = 0.95), second largest for Q10 (p(D\u2212(Q10)) = 0.85) and smallest for Q3 (p(D+(Q3)) = 0.7). The latter is a consequence of the fact that SPL considers all three queries Q3, Q10 and Q1 as equally preferable (all have an SPL value of 2).\n\u2022 Let MAX be a measure defined in a way that\nQMAX := arg max Q\u2208Q\n(MAX(Q)) where MAX(Q) := max { |D+(Q)|, |D\u2212(Q)| } Then MAX is inferior to SPL2 since notQ9 \u227aMAX Q5 althoughQ9 is debug-preferred toQ5 (bullet 1 of the definition of superiority in Definition 11 is met). As mentioned above, Q9 \u227aSPL2 Q5 holds (bullet 2 is fulfilled). Moreover, there is no pair of queries Q,Q\u2032 where Q is debug-preferred to Q\u2032 and not Q \u227aSPL2 Q\u2032, as per Proposition 18 (bullet 3 is satisfied).\nQuery selection by means of the ENT criterion relies strongly on the diagnosis probability distribution p and thus on the initial fault information that is provided as an input to the debugging system. In this vein, when applying ENT as measure m for query computation, a user can profit from a good prior fault estimation w.r.t. the number of queries that need to be answered to identify the correct diagnosis, but may at the same time have to put up with a serious overhead in answering effort in case of poor estimates that assign a low probability to the correct diagnosis. SPL, in contrast, refrains from using any probabilities and aims at maximizing the elimination rate by selecting a query that guarantees the invalidation of the half set of leading diagnoses D. As a consequence, SPL is generally inferior to ENT for good estimates and superior to ENT for misleading probabilities, as experiments conducted in [27, 21] indicate. So, an unfavorable combination of selection measure m and quality of initial fault estimates can lead to a significant overhead of necessary queries which means extra time and work for the user in our interactive scenario. Before we introduce our new measure RIO (first presented in [21]) for query selection in\nSection 3.2.4 as solution to this dilemma, we look at further information theoretic measures that might act as beneficial selection criteria in KB debugging."}, {"heading": "3.2.3 New Active Learning Measures for KB Debugging", "text": "In this section, we analyze various general active learning measures presented in [25] with regard to their application in the KB debugging scenario. In [25], these measures are classified into different query strategy frameworks. We also stick to this categorization. The four frameworks we consider in sequence next are Uncertainty Sampling, Query-by-Committee, Expected Model Change and Expected Error Reduction.\nUncertainty Sampling (US). A learning algorithm that relies on uncertainty sampling targets queries whose labeling is most uncertain under the current state of knowledge. The measures belonging to this framework are:\nLeast Confidence (LC): Selects the query QLC whose prediction is least confident, i.e. whose most likely answer aQ,max has least probability. Formally:\nQLC := arg min Q\u2208Q (LC(Q)) where LC(Q) := p(Q = aQ,max)\nMargin Sampling (M): Selects the query QM for which the probabilities between most and second most likely label aQ,1 and aQ,2 are most similar. Formally:\nQM := arg min Q\u2208Q\n(M(Q)) where M(Q) := p(Q = aQ,1)\u2212 p(Q = aQ,2)\nEntropy (H): Selects the query QH whose outcome is most uncertain in terms of information entropy. Formally:\nQH := arg max Q\u2208Q\n(H(Q)) where H(Q) := \u2212 \u2211\na\u2208{t,f}\np(Q = a) log2 p(Q = a) (15)\nProposition 19. Let D \u2286 mD\u3008K,B,P,N \u3009R a set of leading diagnoses and p a probability measure. Then LC \u2261 M \u2261 H. A query Q is theoretically optimal w.r.t. LC, M and H iff p(D+(Q)) = p(D\u2212(Q)).\nProof. The measure M evaluates a query Q the better, the lower p(Q = aQ,1) \u2212 p(Q = aQ,2) is. By the existence of only two query outcomes, p(Q = aQ,1) \u2212 p(Q = aQ,2) = p(Q = aQ,max) \u2212 (1 \u2212 p(Q = aQ,max)) = 2 p(Q = aQ,max) \u2212 1. This is also the result of the application of a linear function f(x) = 2x \u2212 1 to p(Q = aQ,max). The latter is used as a criterion to be minimized by the best query w.r.t. the measure LC. By Proposition 13, M \u2261 LC holds.\nLet p := p(Q = aQ,min). Due to p(D) > 0 for all D \u2208 D and Proposition 3,(6.), it holds that p \u2208 (0, 1). It is well known that a local maximum of a concave function in one variable is at the same time a global maximum. Moreover, a function in one variable is concave iff its first derivative is monotonically decreasing. We observe that H(Q) is concave for p \u2208 (0, 1) as the first derivative log2 p\u2212log2(1\u2212p) of H(Q) is monotonically decreasing due to the fact that the second derivative 1p + 1 1\u2212p is clearly greater than 0 for p \u2208 (0, 1). Setting the first derivative equal to 0 yields p = 12 , i.e. p(Q \u2032 = aQ\u2032,max) = p(Q \u2032 = aQ\u2032,min) = 1 2 as the property of the query Q \u2032 for which the global maximum of H(Q) is attained. By Eq. 6 and Eq. 7 this means that p(D+(Q\u2032)) + p(D 0(Q\u2032)) 2 = p(D \u2212(Q\u2032)) + p(D0(Q\u2032))\n2 , i.e. p(D+(Q\u2032)) = p(D\u2212(Q\u2032)). Consequently, the property of a theoretically optimal query Q w.r.t. H is p(D+(Q)) = p(D\u2212(Q)).\nSince H is monotonically increasing for p \u2208 (0, 12 ], this means that a query Q is the better w.r.t. H the higher the lower probability p(Q = aQ,min) (and thence the lower the higher probability p(Q = aQ,max)) which implies that LC \u2261 H. Because \u2261 is an equivalence relation by Proposition 9 and therefore is transitive, we have that LC \u2261 M \u2261 H.\nFinally, due to the equivalence between LC, M and H and Proposition 6, the property of a theoretically optimal query Q w.r.t. LC, M and H is p(D+(Q)) = p(D\u2212(Q)).\nIn fact, the H measure is only a slight modification of the ENT measure [27] and both measures coincide for queries Q satisfying D0(Q) = \u2205.\nProposition 20. Let Q comprise only queries Q with D0(Q) = \u2205. Then H \u2261Q ENT.\nProof. We have seen that ENT(Q) can be represented as in Eq. 11 and that the query selected by ENT is given by arg minQ\u2208Q(ENT(Q)) (cf. Eq. 9). Further, we observe that the query selected by H is given\nby QH = arg minQ\u2208Q (\u2211 a\u2208{t,f} p(Q = a) log2 p(Q = a) ) by writing it equivalently as in Eq. 15 with arg min instead of arg max, but without the minus sign. Now, considering Eq. 11, since D0(Q) = \u2205 which means p(D0(Q)) = 0 and since an addend of 1 has no bearing on the result of the arg min, the proposition follows immediately.\nWe point out that the difference between H and ENT is that p(D0(Q)) is taken into account as a penalty in ENT which comes in handy for our debugging scenario where we always want to have zero diagnoses that can definitely not be invalidated by the query Q, i.e. D0(Q) = \u2205.\nHowever, if D0(Q) = \u2205 is not true for some query, one must be careful when using H since it might suggest counterintuitive and less favorable queries than ENT. The following example illustrates this fact:\nExample 13 Suppose two queries Q1, Q2 in Q where\n\u3008p(D+(Q1)), p(D\u2212(Q1)), p(D0(Q1))\u3009 = \u30080.49, 0.49, 0.02\u3009 \u3008p(D+(Q2)), p(D\u2212(Q2)), p(D0(Q2))\u3009 = \u30080.35, 0.35, 0.3\u3009\nOf course, we would preferQ1 since it is a fifty-fifty decision (high information gain, no tendency towards any answer, cf. Eq. 6) and only some very improbable diagnosis or diagnoses cannot be ruled out in any case. Q2 is also fifty-fifty w.r.t. the expected query answer, but with a clearly worse setting of D0. In other words, Q1 will eliminate a set of hypotheses that amounts to a probability mass of 0.49 (either all diagnoses in D+(Q1) or all diagnoses in D\u2212(Q1), cf. Section 2.3). For Q2, on the other hand, diagnoses taking only 35% of the probability mass are going to be ruled out. Evaluating these queries by means of H in fact does not lead to the preference of either query. Hence, a selection algorithm based on H might suggest any of the two (e.g. Q2) as the better query.\nCorollary 6. 1. For any real number q > 0, ENTq is superior to H, LC and M.\n2. ENT is superior to H, LC and M.\nProof. We prove both statements in turn:\n1. As we noted above, ENT0 \u2212 1 is equal to H, LC and M and thus equivalent to H, LC and M. Now, by Proposition 13, ENT0 \u2212 1 \u2261 ENT0. Hence, ENT0 \u2261 H \u2261 LC \u2261 M. The statement follows immediately from this by application of Corollary 4.\n2. This statement is a special case of statement (1.) since ENT(Q) = ENT1(Q).\nConsequently, we can regard ENT as a more suitable measure for our debugging scenario than LC, M and H.\nExample 14 Substantiating the third bullet of Corollary 6, we illustrate in this example that there is a query Q1 that is debug-preferred to another query Q2 such that Q1 \u227aH Q2 does not hold whereas Q1 \u227aENT Q2 does. To this end, reconsider the queries Q1, Q2 from Example 13. Assume a concrete set of leading diagnoses D and let\u2329\nD+(Q1),D \u2212(Q1),D 0(Q1) \u232a\n= \u3008{D1,D2} , {D3,D4} , {D5}\u3009\u2329 D+(Q2),D \u2212(Q2),D 0(Q2) \u232a = \u3008{D1} , {D3} , {D5,D2,D4}\u3009\nwith probabilities pi := p(Di) as follows: \u3008p1, . . . , p5\u3009 = \u30080.35, 0.14, 0.35, 0.14, 0.02\u3009. It is obvious that Q1 is debug-preferred to Q2 (cf. Definition 11). That Q1 \u227aH Q2 does not hold and Q1 \u227aENT Q2 does was discussed in Example 13.\nProposition 21. The measures H, LC and M are not consistent with the debug-preference relation DPR (and thus do not satisfy DPR either).\nProof. Reconsider Example 14 and assume the following diagnoses probabilities pi := p(Di):\n\u3008p1, . . . , p5\u3009 = \u30080.3, 0.13, 0.3, 0.01, 0.26\u3009\nThen, LC(Q2) = 12 < LC(Q1) = 0.57. Hence, Q2 \u227aLC Q1. As H \u2261 LC \u2261 M by Proposition 19, we conclude by Definition 11 thatQ2 \u227aM Q1 andQ2 \u227aH Q1 must hold as well. SinceQ1 is debug-preferred to Q2 (cf. Example 14), the measures H, LC and M are not consistent with the debug-preference relation DPR.\nQuery-By-Committee (QBC). QBC criteria involve maintaining a committee C of competing hypotheses which are all in accordance with the set of queries answered so far. Each committee member has a vote on the classification of a new query candidate. The candidate that yields the highest disagreement among all committee members is considered to be most informative. The measures belonging to this framework are the vote entropy and the Kullback-Leibler-Divergence which we discuss in turn.\nVote Entropy (VE): Selects the query\nQVE := arg max Q\u2208QD\n(VE(Q)) where VE(Q) := \u2212 \u2211\na\u2208{t,f}\n|CQ=a| |C| log2 ( |CQ=a| |C| ) (16)\nabout whose classification there is the largest discrepancy in prediction between the committee members in C where CQ=a \u2286 C terms the set of committee members that predict Q = a. At this, the most likely hypotheses D act as the committee C. A diagnosis D \u2208 D votes for Q = t iff D \u2208 D+(Q) and for Q = f iff D \u2208 D\u2212(Q) (cf. Eq. 8). Diagnoses in D0(Q) do not provide a vote for any answer (cf. Eq. 8 and Proposition 3,(2.)). Therefore, more precisely, the (actually voting) committee C := D \\D0(Q) = D+(Q) \u222aD\u2212(Q). If we apply this to the formula for QVE, it becomes evident that:\nProposition 22. Then the theoretically optimal query Q w.r.t. VE and D satisfies |D+(Q)| = |D\u2212(Q)|.\nProof. Let Q by a query and c := |D| \u2212 y = |D+(Q)|+ |D\u2212(Q)| for some y \u2208 {0, . . . , |D| \u2212 2} be the size of the voting committee C w.r.t. Q. That is, |C| = c. Let further ct = |CQ=t| = |D+(Q)|. We have to find the maximum of the function f(ct) := \u2212 ctc log2 ( ct c ) \u2212 c\u2212ctc log2 ( c\u2212ct c ) . The first derivative of this function is given by 1c [log2( c\u2212ct c )\u2212 log2( ct c )]. Setting this derivative equal to 0 yields ct = c 2 . Since \u2212f(ct) is convex, i.e. f(ct) concave, c2 is clearly the point where the global maximum of f(ct) is attained (see the proof of Proposition 15 for a more lengthy argumentation regarding similar facts). Consequently, the theoretical optimum w.r.t. VE is attained if |CQ=t| = |CQ=f | = c2 , i.e. if |D +(Q)| = |D\u2212(Q)|.\nThus, VE is similar to SPL and both measures coincide for queries Q satisfying D0(Q) = \u2205.\nProposition 23.\n1. Let Q comprise only queries Q with D0(Q) = \u2205. Then VE \u2261Q SPL.\n2. VE \u2261 SPL0.\nProof. Let Q,Q\u2032 be arbitrary queries in Q. Clearly, Q being preferred to Q\u2032 by SPL is equivalent to ||D+(Q)| \u2212 |D\u2212(Q)|| < ||D+(Q\u2032)| \u2212 |D\u2212(Q\u2032)||. Due to the argumentation given in the proof of Proposition 22 (concavity of f(ct)), this is equivalent toQ being preferred toQ\u2032 by VE. This proves (1.). Bullet (2.) is shown analogously.\nCorollary 7. Let Q be a set of queries w.r.t. a set of minimal diagnoses w.r.t. a DPI \u3008K,B,P ,N \u3009R where each query Q \u2208 Q satisfies D0(Q) = \u2205. Then SPLz \u2261Q VE for all z \u2208 R.\nProof. Immediate from Proposition 23 and the fact that SPLz is obviously equal to SPL for all Q \u2208 Q (due to D0(Q) = \u2205) for all z \u2208 R.\nWe note that SPL, contrary to VE, includes a penalty corresponding to the size of D0(Q). However, in spite of the high similarity between SPL and VE, one still must be careful when using VE as it might suggest counterintuitive queries. This is analogical to the comparison we made between H and ENT. Let us again exemplify this:\nExample 15 Suppose two queries Q1, Q2 in Q where\n\u3008|D+(Q1)|, |D\u2212(Q1)|, |D0(Q1)|\u3009 = \u30084, 4, 2\u3009 \u3008|D+(Q2)|, |D\u2212(Q2)|, |D0(Q2)|\u3009 = \u30081, 1, 8\u3009\nThe queries Q1 and Q2 both feature the largest possible discrepancy in prediction between committee members (four diagnoses predict the positive and four the negative answer in case of Q1, comparing with a 1-to-1 situation in case of Q2). Clearly, VE evaluates both queries as equally good. However, the setting of Q2 w.r.t. D0 is clearly worse, since eight leading diagnoses (versus only two for Q2) can definitely not be ruled out after having gotten an answer to Q2. In other words, Q1 will rule out only a guaranteed number of four leading diagnoses whereas Q1 guarantees only the elimination of a single leading diagnosis. This aspect is taken into account by SPL which is why SPL favors Q1 outright (SPL(Q1) = 2, SPL(Q2) = 8). To sup up, SPL goes for the query that we clearly prefer in the interactive debugging scenario, whereas VE could possibly suggest Q2 instead of Q1. Note also that Q1, Q2 can be specified in a way that Q1 is debug-preferred to Q2, e.g. if\n\u3008D+(Q1),D\u2212(Q1),D0(Q1)\u3009 = \u3008{D1, . . . ,D4} , {D5, . . . ,D8} , {D9,D10}\u3009 \u3008D+(Q2),D\u2212(Q2),D0(Q2)\u3009 = \u3008{D1} , {D5} , {D2, . . . ,D4,D6, . . . ,D8,D9,D10}\u3009\nAs a consequence of this, we can declare that VE does not satisfy the debug-preference relation DPR (the fact that Q1 is debug-preferred to Q2 can be easily verified by consulting Proposition 12). When we consider another example, i.e.\n\u3008D+(Q3),D\u2212(Q3),D0(Q3)\u3009 = \u3008{D1, . . . ,D3} , {D5, . . . ,D8} , {D4,D9,D10}\u3009 \u3008D+(Q4),D\u2212(Q4),D0(Q4)\u3009 = \u3008{D1} , {D5} , {D2, . . . ,D4,D6, . . . ,D8,D9,D10}\u3009\nwe directly see that Q4 \u227aVE Q3 (q-partition set cardinalities \u30083, 4, 3\u3009 versus \u30081, 1, 8\u3009) which is why Q3 \u227aVE Q4 cannot hold (\u227aVE is strict order, cf. Proposition 4) which in turn is why VE is not consistent with the debug preference relation DPR (the fact that Q3 is debug-preferred to Q4 can be easily verified by consulting Proposition 12). Furthermore, we point out that SPL(Q3) = 1 + 3 = 4 < 8 = 0 + 8 = SPL(Q4). Therefore, Q3 \u227aSPL Q4.\nCorollary 8. VE is not consistent with the debug-preference relation DPR (and thus does not satisfy DPR either).\nProof. Reconsider queries Q3 and Q4 from Example 15. There, we showed that Q4 \u227aVE Q3 although Q3 is debug-preferred to Q4. This completes the proof.\nProposition 24. SPL is superior to VE.\nProof. Let d(Z) := | |D+(Z)| \u2212 |D\u2212(Z)| | for some query Z and let Q,Q\u2032 be queries such that Q is debug-preferred to Q\u2032. Further, assume that not Q \u227aSPL Q\u2032, i.e. d(Q)\u2212 d(Q\u2032) = (|D0(Q\u2032)| \u2212 |D0(Q)|) (cf. Proposition 17). Due to Proposition 11, |D0(Q\u2032)| > |D0(Q)| must hold. Therefore, it must be true that d(Q\u2032) < d(Q). By the argumentation used in the proof of Proposition 16 (concavity), VE evaluates a query Z the better, the lower d(Z) is. Hence, Q\u2032 \u227aVE Q which is why Q \u227aVE Q\u2032 cannot hold by Proposition 4 (asymmetry of the strict order \u227aVE). Therefore, the third bullet in the definition of superiority (Definition 11) is met. The first and second bullets are satisfied as is illustrated by queries Q3, Q4 in Example 15.\nCorollary 9. SPLz is superior to VE for all real numbers z \u2265 1.\nProof. Due to Corollary 5, SPLz is superior to SPL for all real numbers z > 1. Since Proposition 24 witnesses that SPL (which is equal to SPL1) is superior to VE, we obtain by application of Proposition 8 (transitivity of the superiority relation) that SPLz is superior to VE for all real numbers z \u2265 1.\nKullback-Leibler-Divergence (KL): Selects the query\nQKL := arg max Q\u2208QD\n(KL(Q)) where KL(Q) := 1 |C| \u2211 c\u2208C DKL(pc(Q)||pall(Q)) (17)\nthat manifests the largest average disagreement DKL(pc(Q)||pall(Q)) between the label distributions of any (voting) committee member c and the consensus all of the entire (voting) committee C. Adapted to the debugging scenario, all corresponds to the \u201copinion\u201d of C = D+(Q) \u222aD\u2212(Q) and c corresponds to the \u201copinion\u201d of some D \u2208 D+(Q) \u222a D\u2212(Q) (cf. Proposition 3,(2.) which says that diagnoses in D0(Q) do not predict, or vote for, any answer to Q). Note that the committee C is in general different for different queries. Let for the remaining discussion of the KL measure the probabilities of the diagnoses in D+(Q) \u222aD\u2212(Q) be normalized in a way that they sum up to 1, i.e. p(D+(Q)) + p(D\u2212(Q)) = 1. This is accomplished by p(Di) \u2190 p(Di)/ \u2211 D\u2208D+(Q)\u222aD\u2212(Q) p(D) for all Di \u2208 D+(Q) \u222aD\u2212(Q) and p(Di) \u2190 0 for all Di \u2208 D0(Q). Further, we use px(Q = a) as a shorthand for p(Q = a |x) for x \u2208 {c, all}. According to Eq. 8, under the hypothesis c = D it holds that\npc(Q = t) = 1 for D \u2208 D+(Q) (18) pc(Q = f) = 1 for D \u2208 D\u2212(Q) (19)\nThe probability\npall(Q = a) := 1 |C| \u2211 c\u2208C pc(Q = a)\nfor a \u2208 {t, f} expresses the \u201caverage prediction tendency\u201d of the committee C as a whole under the assumption of equal likeliness or weight 1|C| of each committee member c \u2208 C.\nHowever, as probabilities of leading diagnoses are maintained in our debugging scenario, these can be taken into account by assigning to c = D the weight p(c) := p(D) instead of the factor 1|C| , resulting in another variant of pall(Q = a) which reads as\npall(Q = a) := \u2211 c\u2208C p(c) pc(Q = a) (20)\nand is equal to p(D+(Q)) for a = t and equal to p(D\u2212(Q)) for a = f as per Eq. 5. Using Eq. 20, the disagreement measure given in [25, p. 29, bottom line] can be defined for the debugging scenario as\nDKL (pc(Q)||pall(Q)) := \u2211\na\u2208{t,f}\npc(Q = a) log2\n( pc(Q = a)\npall(Q = a)\n)\nProposition 25. Let Q be a query and DQ := D+(Q) \u222a D\u2212(Q). Then KL(Q) can be equivalently written as \u2212 \u2211\nD\u2217\u2208{D+(Q),D\u2212(Q)}\n|D\u2217| |DQ| log2(p(D \u2217))\n (21)\nProof. As argued before, we have that pall(Q = t) = p(D+(Q)) and pall(Q = f) = p(D\u2212(Q)). By Equations 18 and 19, pc(Q = a) = 0 if c = D \u2208 D+(Q) and a = f , or if c = D \u2208 D\u2212(Q) and a = t, and pc(Q = a) = 1 otherwise. In case pc(Q = a) = 0 it holds that pc(Q = a) log2 ( pc(Q=a) pall (Q=a) ) = 0 log20 which is equal to zero by convention (see page 27). Consequently, if c = D \u2208 D+(Q), then\nDKL(pc(Q)||pall(Q)) := log2 (\n1\npall(Q = t)\n) = \u2212 log2(pall(Q = t))\nAnalogously, we obtain\nDKL(pc(Q)||pall(Q)) := \u2212 log2(pall(Q = f))\nfor c = D \u2208 D\u2212(Q). Since KL(Q) := 1|C| \u2211\nc\u2208C DKL(pc(Q)||pall(Q)) and by the derivation of DKL(pc(Q)||pall(Q)) above, we observe that we add |D+(Q)| times the term \u2212 1|C| log2(pall(Q = t)) and |D\u2212(Q)| times the term \u2212 1|C| log2(pall(Q = f)), which leads to the statement of the proposition by the fact that |C| = |DQ|.\nThe next proposition is based on Proposition 25 and constitutes the key for the design of suitable heuristics that can be used by a q-partition search in order to locate the q-partition with best KL measure (among a set of queries) efficiently. It testifies that there is no theoretically optimal query w.r.t. KL since, in fact, the KL measure can be arbitrarily improved by decreasing the probability of one of the sets D+(Q) or D\u2212(Q). So, there is no global maximum of KL. However, we are still able to derive a subset of q-partitions that must include the best q-partition w.r.t. KL among a given set of queries (with empty D0-set). Roughly, a best q-partition w.r.t. KL must feature either a D+-set with maximal probability in relation to its cardinality or a D\u2212-set with maximal probability in relation to its cardinality. This insight can be exploited to devise a search that attempts to examine q-partitions in a way such qpartitions are preferred. A complete restriction to only such q-partitions is though not easy to achieve as not all subsets of the leadings diagnoses constitute D+- or D\u2212-sets of a q-partition and since therefore a decision between D+- or D\u2212-sets of different cardinality must in general be made at a certain point during the search. The class of these preferred q-partitions tends to be small the higher the variability in the probabilities of the leading diagnoses is because facing different D+- or D\u2212-sets with one and the same cardinality and probability is unlikely in such a situation.\nProposition 26. Let D be a set of minimal diagnoses w.r.t. a DPI \u3008K,B,P ,N \u3009R. Then, for KL the following holds:\n1. There is no theoretically optimal query w.r.t. KL and D.\n2. If the (diagnosis) probability measure p is not assumed fixed, then for any given query Q w.r.t. D and \u3008K,B,P ,N \u3009R a query Q\u2032 w.r.t. D and \u3008K,B,P ,N \u3009R satisfying Q\u2032 \u227aKL Q can be found.\n3. Let Q be any set of queries w.r.t. a DPI \u3008K,B,P ,N \u3009R and a set of leading diagnoses D w.r.t. this DPI such that each query Q \u2208 Q satisfies D0(Q) = \u2205. If the (diagnosis) probability measure p is assumed fixed, then the query Q \u2208 Q that is considered best in Q by KL (i.e. there is no query Q\u2032 \u2208 Q w.r.t. D and \u3008K,B,P ,N \u3009R such that Q\u2032 \u227aKL Q) satisfies D+(Q) \u2208MaxP + k where\nMaxP+k := { S |S \u2208 Sk \u2227 \u2200S\u2032 \u2208 S+k : p(S) \u2265 p(S \u2032) }\nfor some k \u2208 {1, . . . , |D| \u2212 1} where\nS+k = {X | \u2205 \u2282 X \u2282 D, |X| = k, \u3008X,Y,Z\u3009 is a q-partition w.r.t. D, \u3008K,B,P ,N \u3009R}\nor D\u2212(Q) \u2208MaxP\u2212m where\nMaxP\u2212m := { S |S \u2208 S\u2212m \u2227 \u2200S\u2032 \u2208 S\u2212m : p(S) \u2265 p(S\u2032) } for some m \u2208 {1, . . . , |D| \u2212 1} where\nS\u2212m = {Y | \u2205 \u2282 Y \u2282 D, |Y| = m, \u3008X,Y,Z\u3009 is a q-partition w.r.t. D, \u3008K,B,P ,N \u3009R}\nProof. We prove all statements (1.)\u2013(3.) in turn.13\nAd (1.): By the definition of theoretical optimality of a query w.r.t. a measure (cf. Definition 11), we can assume that the probability measure p is variable, i.e. not fixed. Let for each query Q w.r.t. D and \u3008K,B,P ,N \u3009R the set (representing the voting committee) DQ denote D+(Q) \u222a D\u2212(Q). By Proposition 25, we have to analyze the function f(b, x) := \u2212 bd log2(x)\u2212 d\u2212b d log2(1\u2212 x) with regard to its global optimum for b \u2208 {1, . . . , d\u2212 1} (cf. Proposition 3,(6.)) and x \u2208 (0, 1) (cf. the assumption that no diagnosis has zero probability on page 26) where b := |D+(Q)|, x := p(D+(Q)) and d := |DQ|. Now, let us apply the relaxation to the domain of f(b, x) that b \u2208 [1, d \u2212 1] and that d is fixed. This simplifies the analysis and is legal since we will demonstrate that there does not exist a global maximum. If this does not exist for the continuous interval b \u2208 [1, d \u2212 1], it clearly does not exist for the discrete values 1, . . . , d\u2212 1 of b either. Further, if the global maximum does not exist for a fixed (but arbitrary) d, it does not exist for any d.\nA first step towards finding a global maximum is to analyze the function for local maxima. To this end, we start with the localization of stationary points. Let fb, fx denote the partial derivatives of f w.r.t. b and x, respectively. Now, setting both fb = 1d\u00b7ln 2 (ln( 1 x )\u2212 ln( 1 1\u2212x )) and fx = 1 d\u00b7ln 2 ( d\u2212b 1\u2212x \u2212 b x ) equal to zero, we get a system of two equations involving two variables. From the first equation we obtain x = 12 , the second lets us derive bd\u2212b = x 1\u2212x . Using x = 1 2 , we finally get b = d 2 . That is, there is a single stationary point, given by the b-x-coordinates (d2 , 1 2 ). In order to find out whether it is a local optimum or a saddle point, we build the Hessian\nH = fbb fbx fxb fxx  =  0 1d\u00b7ln 2 (\u2212 11\u2212x \u2212 1x ) 1 d\u00b7ln 2 (\u2212 1 1\u2212x \u2212 1 x ) 1 d\u00b7ln 2 ( d\u2212b (1\u2212x)2 + b x2 )  where e.g. fxb denotes the result of computing the partial derivative of fx w.r.t. b (analogous for the other matrix coefficients). It is well known that f attains a local maximum at a point x if the gradient of f is the zero vector at this point and the Hessian at this point is negative definite. Since the gradient is the zero vector at (d2 , 1 2 ) (we obtained this stationary point exactly by setting the gradient equal to zero), we next check the Hessian for negative definiteness. This can be accomplished by computing the eigenvalues of H at (d2 , 1 2 ), which is given by\nH\n( d\n2 ,\n1\n2\n) =  0 \u2212 4d\u00b7ln 2 \u2212 4d\u00b7ln 2 0  The characteristic polynomial of H(d2 , 1 2 ) is then det(H( d 2 , 1 2 ) \u2212 \u03bbI) = \u03bb 2 \u2212 ( 4d\u00b7ln 2 ) 2 yielding the eigenvalues (roots of the characteristic polynomial) \u00b1 4d\u00b7ln 2 . Since there is one positive and one negative eigenvalue, the Hessian at the single existing stationary point (d2 , 1 2 ) is indefinite which means that ( d 2 , 1 2 ) is a saddle point. Hence, no local or global maxima (or minima) exist for f(b, x) over the given set of\n13In case the reader is unfamiliar with any terms or facts regarding calculus and optimization used in this proof, we recommend to consult [16, p. 295 ff.].\npoints. Since therefore there is no global maximum of KL, there is no theoretically optimal query w.r.t. KL and D (cf. Definition 11).\nAd (2.): Let us consider again the function f(b, x) defined in the proof of (1.). Let us further assume an arbitrary query Q w.r.t. D and \u3008K,B,P ,N \u3009R. Let for this query d be dQ and let this query have the value KL(Q) = f(bQ, xQ) = \u2212 bQdQ log2(xQ)\u2212 dQ\u2212bQ dQ log2(1\u2212xQ) where w.l.o.g. bQ \u2265 dQ 2 . We observe that for some probability q \u2208 (0, 1],\u2212 log2(q) = log2( 1q ) \u2265 0 increases for decreasing q. More precisely, \u2212 log2(q)\u2192\u221e for q \u2192 0+. Now we can increase f(bQ, xQ) by subtracting some > max{0, 2xQ\u22121} from xQ, i.e. f(bQ, xQ \u2212 ) > f(bQ, xQ).\nThis must hold, first, because the logarithm \u2212 log2(xQ) with the higher or equal weight bQ dQ (holds due to bQ \u2265 dQ2 ) in f(bQ, xQ) is increased while the other logarithm \u2212 log2(1 \u2212 xQ) is decreased due to > 0. Second, the increase of the former is higher than the decrease of the latter, i.e. (\u2217) : \u2212 log2(xQ \u2212 ) \u2212 (\u2212 log2(xQ)) > \u2212 log2(1 \u2212 xQ) \u2212 (\u2212 log2(1 \u2212 xQ + )), due to > 2xQ \u2212 1. To understand that (\u2217) holds, let us transform it as follows:\nlog2\n( 1\nxQ \u2212\n) \u2212 log2 ( 1\nxQ\n) > log2 ( 1\n1\u2212 xQ\n) \u2212 log2 ( 1\n1\u2212 xQ + ) log2 ( xQ\nxQ \u2212\n) > log2 ( 1\u2212 xQ +\n1\u2212 xQ ) xQ\nxQ \u2212 > 1\u2212 xQ + 1\u2212 xQ\nxQ(1\u2212 xQ) > (1\u2212 xQ + )(xQ \u2212 ) xQ \u2212 x2Q > xQ \u2212 \u2212 x2Q + 2xQ \u2212 2\n0 > (2xQ \u2212 1\u2212 ) > 2xQ \u2212 1\nHence, we see that > 2xQ \u2212 1 iff (\u2217). Note, since the interval for xQ is open, i.e. (0, 1), we can always find a (sufficiently small) such that xQ \u2212 > 0. To verify this, assume first that max{0, 2xQ \u2212 1} = 0. In this case, since xQ > 0, can be chosen so small that xQ \u2212 > 0. On the other hand, if max{0, 2xQ \u2212 1} = 2xQ \u2212 1, we observe that xQ \u2212 < xQ \u2212 2xQ + 1 = 1 \u2212 xQ must hold. Since xQ < 1 and thus 1 \u2212 xQ > 0, we can chose sufficiently small such that xQ \u2212 > 0. Consequently, we can construct some query Q\u2032 with d\u2032Q = dQ, x\u2032Q = xQ \u2212 and b\u2032Q = bQ which satisfies Q\u2032 \u227aKL Q.\nAd (3.): Let d := |D| be arbitrary, but fixed, and let us reuse again the function f(b, x) := \u2212 bd log2(x)\u2212 d\u2212b d log2(1 \u2212 x) defined in the proof of (1.) above and let w.l.o.g. b and x, respectively, denote the cardinality and the probability of the D+-set of the respective query. Notice that d (denoting the size of the committee) can be fixed for all queries w.r.t. D and \u3008K,B,P ,N \u3009R since D0(Q) = \u2205 for all Q \u2208 Q. First of all, we demonstrate that the function fb(x) resulting from f(b, x) by fixing b (where the value of b is assumed arbitrary in {1, . . . , d\u2212 1}) is strictly convex and thus attains exactly one (global) minimum for x \u2208 (0, 1) (cf. [16, p. 22]). Figuratively speaking, this means that fb(x) is strictly monotonically increasing along both directions starting from the argument of the minimum. In order to derive the strict convexity of fb(x), we build the first and second derivatives f \u2032b(x) = \u2212 bd\u00b7ln 2 1 x + d\u2212b d\u00b7ln 2 1 1\u2212x and f \u2032\u2032b (x) = b d\u00b7ln 2 1 x2 + d\u2212b d\u00b7ln 2 1 (1\u2212x)2 . It is easy to see that f \u2032\u2032(x) > 0 since d \u2265 2, b \u2265 1, d \u2212 b \u2265 1 and x2 as well as (1 \u2212 x)2 are positive due to x \u2208 (0, 1). The x-value xmin,b at which the minimum is attained can be computed by setting f \u2032b(x) = 0. From this we get xmin,b = b d .\nLet us now assume some query Q\u2217 \u2208 Q w.r.t. D and \u3008K,B,P ,N \u3009R where Q\u2217 is considered best in Q by KL and for all k \u2208 {1, . . . , |D| \u2212 1} it holds that D+(Q\u2217) /\u2208 MaxP+k and for all\nm \u2208 {1, . . . , |D| \u2212 1} it holds that D\u2212(Q\u2217) /\u2208 MaxP\u2212m. We show that there is some query Q w.r.t. D and \u3008K,B,P ,N \u3009R such that Q \u227aKL Q\u2217.\nTo this end, assume |D+(Q\u2217)| = b. Then it must hold that MaxP+b 6= \u2205 and MaxP \u2212 d\u2212b 6= \u2205.\nThis follows directly from the definition of MaxP+k and MaxP \u2212 m. Let xQ\u2217 := p(D +(Q\u2217)). We now distinguish between two possible cases, i.e. (i) xQ\u2217 > bd and (ii) xQ\u2217 \u2264 b d . In case (i), xQ\u2217 is already larger than the (unique) argument xmin,b = bd of the minimum of the function fb(x). Since D +(Q\u2217) /\u2208 MaxP+b , there must be some query Q with D +(Q) \u2208 MaxP+b such that p(D+(Q)) > p(D+(Q\u2217)). This strict inequality must hold since D+(Q\u2217) /\u2208 MaxP+b and D+(Q) \u2208 MaxP + b . Hence, xQ := p(D+(Q)) > p(D+(Q\u2217)) = xQ\u2217 > xmin,b which is why KL(Q) = fb(xQ) > fb(xQ\u2217) = KL(Q\u2217) by the fact that fb(x) is strictly monotonically increasing along both directions starting from xmin,b. Consequently, Q \u227aKL Q\u2217 holds.\nIn case (ii), xQ\u2217 is smaller than or equal to the (unique) argument xmin,b = bd of the minimum of the function fb(x). In case of equality, i.e. xQ\u2217 = bd , the exact same argumentation as in case (i) can be used. Assume now that xQ\u2217 < bd . Since the cardinality of D\n+(Q\u2217) is b and D0(Q\u2217) = \u2205, the cardinality of D\u2212(Q\u2217) must be d \u2212 b. As D\u2212(Q\u2217) /\u2208 MaxP\u2212d\u2212b there must be some query Q with D\u2212(Q) \u2208 MaxP\u2212d\u2212b such that p(D\u2212(Q)) > p(D\u2212(Q\u2217)). This strict inequality must hold since D\u2212(Q\u2217) /\u2208 MaxP\u2212d\u2212b and D\u2212(Q) \u2208 MaxP \u2212 d\u2212b. From p(D\n\u2212(Q)) > p(D\u2212(Q\u2217)), however, we directly obtain p(D+(Q)) < p(D+(Q\u2217)) by the fact that D0(Q\u2217) = D0(Q) = \u2205 (and hence p(D0(Q\u2217)) = p(D0(Q)) = 0). Therefore, we have that xQ = p(D+(Q)) < p(D+(Q\u2217)) = xQ\u2217 < xmin,b. So, KL(Q) = fb(xQ) > fb(xQ\u2217) = KL(Q\n\u2217) by the fact that fb(x) is strictly monotonically increasing along both directions starting from xmin,b. Consequently, Q \u227aKL Q\u2217 holds.\nProposition 27. KL is not consistent with the debug-preference relation DPR (and consequently does not satisfy DPR either).\nProof. It suffices to provide an example of two queries Q,Q\u2032 where Q is debug-preferred to Q\u2032 and Q\u2032 \u227aKL Q. To this end, let Q and Q\u2032 be characterized by the following q-partitions\n\u3008D+(Q),D\u2212(Q),D0(Q)\u3009 = \u3008{D1,D2} , {D3,D4,D5} , \u2205\u3009 \u3008D+(Q\u2032),D\u2212(Q\u2032),D0(Q\u2032)\u3009 = \u3008{D1,D2} , {D3,D4} , {D5}\u3009\nand let the diagnosis probabilities pi := p(Di) be as follows:\n\u3008p1, . . . , p5\u3009 = \u30080.35, 0.05, 0.15, 0.25, 0.2\u3009\nIt is straightforward that Q is debug-preferred to Q\u2032 (cf. Proposition 12). Plugging in the values\u2329 |D+(Q)|, |DQ|, p(D+(Q)) \u232a = \u30082, 5, 0.4\u3009\ninto Eq. 21, we get KL(Q) \u2248 0.97 as a result, whereas plugging in the values\u2329 |D+(Q\u2032)|, |DQ\u2032 |, p(D+(Q\u2032)) \u232a = \u30082, 4, 0.5\u3009\nyields KL(Q\u2032) = 1. Thence, Q\u2032 \u227aKL Q. Note that p(D+(Q\u2032)) is computed as 0.35+0.050.35+0.05+0.15+0.25 = 0.4 0.8 where the denominator represents the probability of the voting committee which is given by {D1, . . . ,D4} in case of Q\u2032 and by {D1, . . . ,D5} in case of Q.\nCorollary 10. All measures satisfying the debug-preference relation are superior to KL.\nProof. Immediate from Propositions 10 and 27.\nRemark 4 Given a diagnosis probability measure p, we can compute the KL measure for all partitions (not necessarily q-partitions) with different maximal probable D+-sets (regarding the cardinality |D+|) and store the maximal among all KL measures obtained in this manner as optKL,p,D. By Proposition 26,(3.), the parameter optKL,p,D is then exactly the value of the sought best q-partition (with empty D0-set) w.r.t. KL for D and p in case the partition from which it was computed is indeed a q-partition. Otherwise, again by Proposition 26,(3.), it is an upper bound of the KL measure of the best q-partition (with empty D0-set). The maximal probable D+-sets can be easily computed by starting from an empty set and adding step-by-step the diagnosis with the highest probability among those diagnoses not yet added. At each of the |D| \u2212 1 steps, we have present one maximal probable D+-set. Notice that for maximal probable D\u2212-sets the same result would be achieved (due to the \u201csymmetry\u201d of Eq. 21 w.r.t. D+ and D\u2212) which is why this process must only be performed once.\nExpected Model Change (EMC). The principle of the EMC framework is to query the instance that would impart the greatest change to the current model if its label was known. Translated to the debugging scenario, the \u201cmodel\u201d can be identified with the set of leading diagnoses according to which \u201cmaximum expected model change\u201d can be interpreted in a way that\n(a) the expected probability mass of invalidated leading diagnoses is maximized or\n(b) the expected number of invalidated leading diagnoses is maximized.\nExpected Model Change - Variant (a) (EMCa): Formally, variant (a) selects the query\nQEMCa := arg max Q\u2208QD\n(EMCa(Q)) where EMCa(Q) := p(Q = t)p(D\u2212(Q)) + p(Q = f)p(D+(Q))\nsince the set of leading diagnoses invalidated for positive and negative answer toQ is D\u2212(Q) and D+(Q), respectively (cf. Proposition 3,(2.)).\nProposition 28. For EMCa, the following holds:\n1. EMCa(Q) can be equivalently represented as\n2 [ p(Q = t)\u2212 [p(Q = t)]2 ] \u2212 p(D 0(Q))\n2 (22)\n2. The theoretically optimal query w.r.t. EMCa satisfies p(Q = t) = p(Q = f) and D0(Q) = \u2205.\n3. Let Q be a set of queries w.r.t. a set of minimal diagnoses w.r.t. a DPI \u3008K,B,P ,N \u3009R where each query Q \u2208 Q satisfies D0(Q) = \u2205. Then EMCa \u2261Q ENT.\nProof. Let for brevity x := p(Q = t), i.e. 1\u2212 x = p(Q = f), and x0 := p(D0(Q)). Then EMCa(Q) = x \u00b7 p(D\u2212(Q)) + (1\u2212 x) \u00b7 p(D+(Q)). According to Eq. 6 and Eq. 7, we can write p(D\u2212(Q)) as p(Q = f) \u2212 p(D\n0(Q)) 2 = (1 \u2212 x) \u2212 x0 2 and p(D +(Q)) as p(Q = t) \u2212 p(D 0(Q)) 2 = x \u2212 x0 2 . Consequently,\nEMCa(Q) = x \u00b7 [(1 \u2212 x) \u2212 x02 ] + (1 \u2212 x) \u00b7 [x \u2212 x0 2 ]. After some simple algebra, EMCa(Q) looks as follows: [2(x\u2212 x2)]\u2212 x02 . This completes the proof of (1.). The best query Q w.r.t. EMCa is the one which maximizes EMCa(Q). Hence, the best query w.r.t. EMCa is the one which minimizes \u2212EMCa(Q) = [2(x2 \u2212 x)] + 12x0. We now observe that x0 = p(D0(Q)) is independent of the sum in squared brackets. Thus, both terms can be minimized separately. Therefore, we immediately see that x0 = p(D0(Q)) = 0 must be true for the theoretically optimal\nquery w.r.t. EMCa. This implies D0(Q) = \u2205 by p(D) > 0 for all D \u2208 D (cf. page 26). Further on, if x0 = p(D\n0(Q)) = \u2205, \u2212EMCa(Q) = [2(x2 \u2212 x)]. Next, we analyze the term f(x) := 2(x2 \u2212 x) in squared brackets for extreme points. To this end, we build the first and second derivatives f \u2032(x) = 2(2x \u2212 1) and f \u2032\u2032(x) = 4. Clearly, f(x) is a strictly convex function as f \u2032\u2032(x) > 0 for all x \u2208 (0, 1). Hence, there is exactly a unique (global) minimum of it. By setting f \u2032(x) = 0, we obtain x = 12 as the argument of this minimum. As x = p(D\n+(Q)) and p(D+(Q)) = 12 implies that p(D\n\u2212(Q)) = 1\u2212 p(D+(Q)) = 12 , (2.) is thereby proven. Now, recall that ENT(Q) can be represented as in Eq. 11 and bring back to mind the proof of Proposition 14 where we showed that the term x log2 x+ (1\u2212 x) log2(1\u2212 x) in squared brackets in Eq. 11 is strictly convex as well, attaining its minimum exactly at x = 12 . Moreover, given x0 = p(D\n0(Q)) = \u2205, we have that ENT(Q) = x log2 x+(1\u2212x) log2(1\u2212x). So, for queries with empty D0, both\u2212EMCa(Q) and ENT(Q) are strictly convex and feature the same point where the global minimum is attained. That is, both \u2212EMCa(Q) and ENT(Q) are strictly monotonically increasing along both directions outgoing from the argument of the minimum x = 12 . As a consequence, for queries Qi, Qj \u2208 Q we have that Qi \u227aENT Qj iff |p(Qi = t) \u2212 12 | < |p(Qj = t) \u2212 1 2 | iff Qi \u227aEMCa Qj . This completes the proof of (3.).\nSimilarly as in the case of ENT, we define a measure EMCaz which constitutes a generalization of the EMCa measure. Namely, EMCaz selects the query\nQEMCaz := arg max Q\u2208Q (EMCaz(Q))\nwhere\nEMCaz(Q) := 2 [ p(Q = t)\u2212 [p(Q = t)]2 ] \u2212 z p(D 0(Q))\n2 (23)\nNote that EMCaz(Q) = EMCa(Q) + z\u221212 p(D 0(Q)) and thus that EMCa1 is equal to EMCa (cf. Proposition 29 and Eq. 22, respectively). Moreover, EMCa0 is equal to the Gini Index [22], a frequently adopted (information) gain measure in decision tree learning. Using our terminology, the Gini Index is defined as 1 \u2212 [p(Q = t)]2 \u2212 [p(Q = f)]2 which can be easily brought into the equivalent form 2 [ p(Q = t)\u2212 [p(Q = t)]2 ] by using the fact that p(Q = t) = 1\u2212 p(Q = f).\nCorollary 11. Let Q be a set of queries w.r.t. a set of minimal diagnoses w.r.t. a DPI \u3008K,B,P ,N \u3009R where each query Q \u2208 Q satisfies D0(Q) = \u2205. Then EMCaz \u2261Q ENT for all z \u2208 R.\nProof. Immediate from Proposition 28,(3.) and the fact that EMCaz is obviously equal to EMCa for all Q \u2208 Q (due to D0(Q) = \u2205) for all z \u2208 R.\nProposition 29. LetQ be a query w.r.t. a set of minimal diagnoses D w.r.t. a DPI \u3008K,B,P ,N \u3009R. Further, let p := mina\u2208{t,f}(p(Q = a)) and Q\u2032 be a query such that Q is debug-preferred to Q\u2032. In addition, let x := p(D0(Q\u2032))\u2212 p(D0(Q)). Then:\n1. x > 0.\n2. If x \u2265 1\u2212 2p, then Q \u227aEMCa Q\u2032.\n3. If x < 1\u2212 2p, then:\n(a) In general it does not hold that Q \u227aEMCa Q\u2032. (b) If not Q \u227aEMCa Q\u2032, then p \u2208 (0, t] where t := 14 . (c) If not Q \u227aEMCaz Q\u2032, then p \u2208 (0, t(z)] where t(z) := \u2212z+24 , i.e. EMCaz for all real numbers\nz \u2265 2 satisfies the debug-preference relation DPR.\nProof. The proof follows exactly the same line of argumentation as used in the proof of Proposition 15, just that Equations 22 and 23 are analyzed instead of Equations 11 and 13, respectively.\nCorollary 12. Let Q be a query and pQ := mina\u2208{t,f}(p(Q = a)). Let further Q be a set of queries where each query Q in this set satisfies pQ > 14 . Then, EMCa satisfies the debug-preference relation (over Q) (Definition 11).\nProof. This statement is a consequence of applying the law of contraposition to the implication stated by Proposition 29,(3.b).\nThe next corollary is quite interesting, as it testifies that EMCar for any selection of a finite r \u2265 2 satisfies the debug-preference relationDPR. Recall from Proposition 15 that ENTz for no finite selection of a non-negative z value (and thus neither ENT) satisfies the DPR (at least theoretically). For that reason, EMCa2, for instance, is already superior to ENTz for all finite non-negative values of z.\nCorollary 13. For all r \u2265 2 and z \u2265 0, EMCar satisfies the debug-preference relation DPR and is superior to ENTz .\nProof. By (the argumentation given in the proof of) Proposition 15, one can construct two queries Q,Q\u2032 where Q is debug-preferred to Q\u2032 and not Q \u227aENTz Q\u2032 for all z \u2265 0. This holds because t(z) > 0 and thus the interval (0, t(z)] is non-empty for all z \u2265 0 (cf. Proposition 15,(c)). Since, by Proposition 29,(c), EMCar preserves the debug-preference order for all r \u2265 2, we can conclude that Q \u227aEMCar Q\u2032 must be given and that there cannot be any pair of queries Qi, Qj where (Qi, Qj) is in the debug preference relation DPR and not Qi \u227aEMCar Qj . Hence all three bullets of the definition of superiority (Definition 11) are met.\nCorollary 14. Let 0 \u2264 r < s \u2264 2. Then EMCar is inferior to EMCas.\nProof. The proof follows exactly the same line of argumentation as was given in the proofs of Corollaries 2 and 4. The upper bound 2 for s must hold since EMCas for s \u2265 2 satisfies the debug-preference relation DPR (as per Proposition 29,(3c.)) and thus no other measure can be superior to EMCas in this case since the first and second bullets of the definition of superiority (cf. Definition 11) can never be satisfied.\nExpected Model Change - Variant (b) (EMCb): Formally, variant (b) selects the query\nQEMCb := arg max Q\u2208QD\nwhere\nEMCb(Q) := p(Q = t)|D\u2212(Q)|+ p(Q = f)|D+(Q)| (24)\nsince the set of leading diagnoses invalidated for positive and negative answer toQ is D\u2212(Q) and D+(Q), respectively (cf. Proposition 3,(2.)). For EMCb there is no theoretically optimal query since there is no global optimum for the probabilities for positive and negative answers to queries assuming values in (0, 1) and the cardinalities of the D+- and D\u2212-sets being in the range {1, . . . , |D| \u2212 1}. The reason for this is the open interval (0, 1) for the probabilities which results from Equations 6 and 7 as well as the facts that all diagnoses D \u2208 D have a positive probability (cf. page 26) and that neither D+(Q) nor D\u2212(Q) must be the empty set for any query. This open interval enables to find for each query, no matter how good it is w.r.t. EMCb, another query that is even better w.r.t. EMCb. In all cases but the one where |D+(Q)| = |D\u2212(Q)| it suffices to simply increase the probability of one of the answers accordingly\nwhich is always possible due the open interval. Moreover, the set of candidate queries that must include the one that is regarded best by the EMCb measure among a given set of queries with empty D0 and given a fixed probability measure p can be characterized equally as in the case of the KL measure. Hence, interestingly, although belonging to different active learning frameworks, EMCb and KL prove to bear strong resemblance to one another as far as the discussed debugging scenario is concerned. The next proposition summarizes this similarity (cf. Proposition 26).\nProposition 30. Let D be a set of minimal diagnoses w.r.t. a DPI \u3008K,B,P ,N \u3009R. Then, for EMCb the following holds:\n1. There is no theoretically optimal query w.r.t. EMCb and D.\n2. If the (diagnosis) probability measure p is not assumed fixed and |D| \u2265 3, then for any given query Q w.r.t. D and \u3008K,B,P ,N \u3009R a query Q\u2032 w.r.t. D and \u3008K,B,P ,N \u3009R satisfying Q\u2032 \u227aEMCb Q can be found.\n3. Let Q be any set of queries w.r.t. a DPI \u3008K,B,P ,N \u3009R and a set of leading diagnoses D w.r.t. this DPI such that each query Q \u2208 Q satisfies D0(Q) = \u2205. If the (diagnosis) probability measure p is assumed fixed, then the query Q \u2208 Q that is considered best in Q by EMCb (i.e. there is no query Q\u2032 \u2208 Q w.r.t. D and \u3008K,B,P ,N \u3009R such that Q\u2032 \u227aEMCb Q) satisfies |D+(Q)| = |D\u2212(Q)| = |D| 2\nor D+(Q) \u2208MaxP+k where\nMaxP+k := { S |S \u2208 S+k \u2227 \u2200S \u2032 \u2208 S+k : p(S) \u2265 p(S \u2032) }\nfor some k \u2208 {1, . . . , |D| \u2212 1} where\nS+k = {X | \u2205 \u2282 X \u2282 D, |X| = k, \u3008X,Y,Z\u3009 is a q-partition w.r.t. D, \u3008K,B,P ,N \u3009R}\nor D\u2212(Q) \u2208MaxP\u2212m where\nMaxP\u2212m := { S |S \u2208 S\u2212m \u2227 \u2200S\u2032 \u2208 S\u2212m : p(S) \u2265 p(S\u2032) } for some m \u2208 {1, . . . , |D| \u2212 1} where\nS\u2212m = {Y | \u2205 \u2282 Y \u2282 D, |Y| = m, \u3008X,Y,Z\u3009 is a q-partition w.r.t. D, \u3008K,B,P ,N \u3009R}\nProof. The proof follows exactly the same line of argumentation that was used in the proof of Proposition 26. To nevertheless provide a sketch of the proof, observe regarding (1.) that, for each d, there is a single stationary point (d2 , 1 2 ) of the function g(b, x) = x(d \u2212 b) + (1 \u2212 x)b corresponding to EMCb using the same denotations as in the proof of Proposition 26. This stationary point turns out to be a saddle point. Hence there is no (local or global) maximum of g(b, x) for b \u2208 {1, . . . , d\u2212 1} , x \u2208 (0, 1).\nConcerning (2.), we bring g(b, x) into the form x(d \u2212 2b) + b which exposes that, for fixed and arbitrary b, gb(x) corresponds to a straight line with a slope of d \u2212 2b. Therefore, if b < d2 , the slope is positive and we obtain a better query w.r.t. EMCb by simply adding some (arbitrarily small) > 0 to x. Such always exists since x has some value in the open interval (0, 1). Otherwise, in case b > d2 , the slope is negative which is why we can subtract some small \u2032 > 0 from x to construct a better query w.r.t. EMCb. Finally, if the slope is zero, i.e. b = d2 (which can by the way only occur if d is even), we must show that there is another query with a better EMCb measure. If x > 1 \u2212 x, such a query is obviously given by setting b \u2190 b \u2212 1; if x < 1 \u2212 x, then by setting b \u2190 b + 1; if x = 1 \u2212 x, then by setting e.g. x \u2190 x + and b \u2190 b \u2212 1 for some > 0. Note that the different settings for b are possible (without implying that any of the D+- or D\u2212-sets becomes empty) since |D| = d \u2265 3 which entails that b = d2 only if d \u2265 4.\nWith regard to (3.), we again use gb(x), as specified above, and consider a specific query Q that does not satisfy the conditions given in (3.). If the slope d \u2212 2b for this query is positive, we know that there must be a query Q\u2032 with D+(Q\u2032) \u2208 MaxP+b that is better w.r.t. EMCb than Q due to the fact that D+(Q) /\u2208 MaxP+b . Given a negative slope, we likewise exploit the fact that there must be a query Q\u2032 with D\u2212(Q\u2032) \u2208MaxP\u2212d\u2212b that is better w.r.t. EMCb than Q due to the fact that D+(Q) /\u2208MaxP \u2212 d\u2212b. Finally, we point out thatQ, as it does not satisfy the condition of (3.), cannot have the property of a slope of zero because this would imply |D+(Q)| = b = |D|2 and due to D\n0(Q) = \u2205 also |D\u2212(Q)| = |D|2 , i.e. that Q satisfies the condition of (3.).\nPlease note that, probably a bit surprisingly, in spite of the similarity between KL and EMCb witnessed by Propositions 26 and 30, these two measures are not equivalent, i.e. KL 6\u2261 EMCb, as we elaborate by the following example:\nExample 16 The see the non-equivalence, we state two queries Q and Q\u2032 where Q \u227aKL Q\u2032 and Q\u2032 \u227aEMCb Q. Let the set of leading diagnoses be D where |D| = 10. The queries Q,Q\u2032 are characterized by the following properties:\n\u3008|D+(Q)|, p(D+(Q))\u3009 = \u30083, 0.05\u3009 \u3008|D+(Q\u2032)|, p(D+(Q\u2032))\u3009 = \u30085, 0.25\u3009\nCalculating KL(Q) \u2248 1.35, KL(Q\u2032) \u2248 1.21, EMCb(Q) = 3.2 and EMCb(Q\u2032) = 5 from these values (see Equations 21 and 24), we clearly see that KL(Q) > KL(Q\u2032) whereas EMCb(Q) < EMCb(Q\u2032). Hence, Q \u227aKL Q\u2032 and Q\u2032 \u227aEMCb Q.\nRemark 5 In a way completely analogous to the process described in Remark 4, we can calculate optEMCb,p,D. By Proposition 30,(3.) and because all queries satisfying |D+(Q)| = |D\u2212(Q)| = |D|2 have an equal EMCb measure due to the fact that Eq. 24 in this case reduces to |D|2 , the parameter optEMCb,p,D is then exactly the value of the sought best q-partition (with empty D0-set) w.r.t. EMCb for D and p in case the partition from which it was computed is indeed a q-partition. Otherwise, again by Proposition 30,(3.), it is an upper bound of the EMCb measure of the best q-partition (with empty D0-set).\nProposition 31. EMCb is not consistent with the debug-preference relation DPR (and consequently does not satisfy DPR either).\nProof. It suffices to provide an example of two queries Q,Q\u2032 where Q is debug-preferred to Q\u2032 and Q\u2032 \u227aKL Q. To this end, let Q and Q\u2032 be characterized by the following q-partitions\n\u3008D+(Q),D\u2212(Q),D0(Q)\u3009 = \u3008{D1,D2,D3} , {D4} , \u2205\u3009 \u3008D+(Q\u2032),D\u2212(Q\u2032),D0(Q\u2032)\u3009 = \u3008{D1,D2} , {D4} , {D3}\u3009\nand let the diagnosis probabilities pi := p(Di) be as follows:\n\u3008p1, . . . , p4\u3009 = \u30080.03, 0.07, 0.8, 0.1\u3009\nIt is straightforward that Q is debug-preferred to Q\u2032 (cf. Proposition 12). We observe that p(Q = t) = p(D+(Q)) + 12p(D\n0(Q)) = 0.03 + 0.07 + 0.8 + 12 \u00b7 0 = 0.9, i.e. p(Q = f) = 0.1. Likewise, p(Q\u2032 = t) = p(D+(Q\u2032)) + 12p(D 0(Q\u2032)) = 0.03 + 0.07 + 12 \u00b7 0.8 = 0.5, i.e. p(Q \u2032 = f) = 0.5.\nNow, plugging in the values\u2329 p(Q = t), |D+(Q)|, p(Q = f), |D\u2212(Q)| \u232a = \u30080.9, 3, 0.1, 1\u3009\ninto Eq. 24, we get EMCb(Q) = 0.9 \u00b7 1 + 0.1 \u00b7 3 = 1.2 as a result, whereas plugging in the values\u2329 p(Q\u2032 = t), |D+(Q\u2032)|, p(Q\u2032 = f), |D\u2212(Q\u2032)| \u232a = \u30080.5, 2, 0.5, 1\u3009\nyields EMCb(Q\u2032) = 0.5 \u00b7 1 + 0.5 \u00b7 2 = 1.5. Since a higher EMCb value means that a query is preferred by EMCb, it holds that Q\u2032 \u227aEMCb Q.\nCorollary 15. All measures satisfying the debug-preference relation are superior to EMCb.\nProof. Immediate from Propositions 10 and 31.\nNext we introduce two other measures which seem reasonable and fit into the EMC framework, most probable singleton and biased maximal elimination:\nMost Probable Singleton (MPS): The intention of MPS is the elimination of all but one diagnoses in D, i.e. leaving valid only a singleton diagnoses set. In order to achieve this with highest likeliness, it selects among all queries that either eliminate all but one or one diagnosis in D the one query Q whose singleton set in {D+(Q),D\u2212(Q)} has highest probability. Formally, MPS chooses the query\nQMPS := arg max Q\u2208QD (MPS(Q)) (25)\nwhere MPS(Q) := 0 for all queries Q satisfying\u2329 |D+(Q)|, |D\u2212(Q)|, |D0(Q)| \u232a /\u2208 {\u3008|D| \u2212 1, 1, 0\u3009 , \u30081, |D| \u2212 1, 0\u3009} (26)\nand MPS(Q) := p(DQ,min) where DQ,min := arg minX\u2208{D+(Q),D\u2212(Q)}(|X|) otherwise. Note that the function MPS(Q) is not injective. Hence, there might be more than one maximum of the function, e.g. in case all diagnoses in D have the same probability. In case of non-uniqueness of the maximum, the arg max statement in Eq. 25 is meant to select just any of the arguments where the maximum is attained.\nThe MPS measure fits into the EMC framework because it maximizes the probability of the maximal theoretically possible change on the current model (leading diagnoses).\nProposition 32. MPS is consistent with the debug-preference relation DPR, but does not satisfy DPR.\nProof. Assume two queries Q,Q\u2032 such that (Q,Q\u2032) \u2208 DPR. Then, by Proposition 11, Q\u2032 must feature a non-empty set D0(Q\u2032). In case D0(Q) = \u2205 and one of |D+(Q)| = 1 or |D\u2212(Q)| = 1 holds, we obtain p(DQ,min) = MPS(Q) > MPS(Q\u2032) = 0 (as |DQ,min| = 1 and each diagnosis in D has non-zero probability, cf. page 26). Otherwise, we have that MPS(Q) = MPS(Q\u2032) = 0. In both cases we can conclude that Q\u2032 \u227aMPS Q does not hold.\nTo see why MPS does not satisfy DPR, consider the two queries Q and Q\u2032 characterized by the following q-partitions\n\u3008D+(Q),D\u2212(Q),D0(Q)\u3009 = \u3008{D1,D2} , {D3} , {D4}\u3009 \u3008D+(Q\u2032),D\u2212(Q\u2032),D0(Q\u2032)\u3009 = \u3008{D1} , {D3} , {D2,D4}\u3009\nObviously, Q is debug-preferred to Q\u2032, i.e. (Q,Q\u2032) \u2208 DPR (cf. Proposition 12). But, as D0(Q) 6= \u2205 and D0(Q\u2032) 6= \u2205, we point out that both queries are assigned a zero MPS value which is why Q \u227aMPS Q\u2032 does not hold.\nIn fact, we can slightly modify the MPS measure such that the resulting measure MPS\u2032 satisfies the debug-preference relation and the set of query tuples satisfying the relation \u227aMPS\u2032 is a superset of the set of query tuples satisfying the relation \u227aMPS. The latter means in other words that given MPS prefers a query to another one, MPS\u2032 will do so as well. So, the order imposed by MPS on any set of queries is maintained by MPS\u2032, just that MPS\u2032 includes some more preference tuples in order to comply with the debug-preference order. The MPS\u2032 is defined so as to select the query\nQMPS\u2032 := arg max Q\u2208QD\n( MPS\u2032(Q) ) (27)\nwhere MPS\u2032(Q) := \u2212|D0(Q)| for all queriesQ satisfying the condition given by Eq. 26 and MPS\u2032(Q) := MPS(Q) otherwise.\nProposition 33. MPS\u2032 satisfies the debug-preference relation DPR. Further, Q \u227aMPS\u2032 Q\u2032 whenever Q \u227aMPS Q\u2032 for all queries Q,Q\u2032 \u2208 QD,\u3008K,B,P,N \u3009R for any DPI \u3008K,B,P ,N \u3009R and any D \u2286 mD\u3008K,B,P,N \u3009R . Proof. Let Q,Q\u2032 be two queries such that (Q,Q\u2032) \u2208 DPR. Then, D0(Q\u2032) \u2283 D0(Q) by Proposition 11, i.e. |D0(Q\u2032)| > |D0(Q)| \u2265 0. Hence, in case Q satisfies \u2329 |D+(Q)|, |D\u2212(Q)|, |D0(Q)| \u232a /\u2208 {\u3008|D| \u2212 1, 1, 0\u3009 , \u30081, |D| \u2212 1, 0\u3009}, we conclude that MPS\u2032(Q\u2032) = \u2212|D0(Q\u2032)| < \u2212|D0(Q)| = MPS\u2032(Q). That is, Q \u227a MPS\u2032Q\u2032. Otherwise, MPS\u2032(Q) = MPS(Q) > 0. This holds since MPS(Q) := p(DQ,min) where |DQ,min| = 1, i.e. DQ,min includes one diagnosis, and each diagnosis has a probability greater than zero (cf. page 26). In that, |DQ,min| = 1 holds since DQ,min := arg minX\u2208{D+(Q),D\u2212(Q)}(|X|) and \u2329 |D+(Q)|, |D\u2212(Q)|, |D0(Q)| \u232a \u2208 {\u3008|D| \u2212 1, 1, 0\u3009 , \u30081, |D| \u2212 1, 0\u3009}. All in all, we have derived that MPS\u2032(Q\u2032) = \u2212|D0(Q\u2032)| < 0 and MPS\u2032(Q) > 0 which implies MPS\u2032(Q) > MPS\u2032(Q\u2032), i.e. Q \u227a MPS\u2032Q\u2032. Thence, MPS\u2032 satisfies DPR.\nSecond, assume two queries Q,Q\u2032 \u2208 QD,\u3008K,B,P,N \u3009R and let Q \u227aMPS Q \u2032, i.e. MPS(Q) > MPS(Q\u2032). Since MPS is either positive (a non-zero probability) in case Eq. 26 is met or zero otherwise, we have that MPS(Qi) \u2265 0 for all Qi \u2208 QD,\u3008K,B,P,N \u3009R . Therefore, Q cannot satisfy Eq. 26 as this would imply that MPS(Q\u2032) < 0. Due to this fact, we obtain that 0 < MPS(Q) = MPS\u2032(Q) by the definition of MPS\u2032(Q) and the fact that the probability of each diagnosis in greater than zero. As a consequence, there are two cases to distinguish: (a) Q\u2032 does and (b) does not satisfy Eq. 26. Given case (a), it clearly holds that MPS\u2032(Q\u2032) \u2264 0 by the definition of MPS\u2032(Q\u2032). So, combining the results, we get MPS\u2032(Q\u2032) \u2264 0 < MPS\u2032(Q) which is equivalent to Q \u227aMPS\u2032 Q\u2032. If case (b) arises, MPS(Q\u2032) = MPS\u2032(Q\u2032) by the definition of MPS\u2032(Q). Hence, both MPS(Q) = MPS\u2032(Q) and MPS(Q\u2032) = MPS\u2032(Q\u2032). However, by assumption MPS(Q) > MPS(Q\u2032). Thus, MPS\u2032(Q) > MPS\u2032(Q\u2032) which is why Q \u227aMPS\u2032 Q\u2032.\nCorollary 16. Let Q be any set of queries w.r.t. a DPI \u3008K,B,P ,N \u3009R and a set of leading diagnoses D w.r.t. this DPI such that each query Q \u2208 Q satisfies D0(Q) = \u2205. Then MPS \u2261Q MPS\u2032. Proof. Is a direct consequence of the definitions of MPS and MPS\u2032.\nCorollary 17. MPS\u2032 is superior to MPS.\nProof. An example of two queries Q,Q\u2032 where (Q,Q\u2032) \u2208 DPR and Q \u227aMPS Q\u2032 does not hold was stated in the proof of Proposition 32. Moreover, Proposition 33 testifies that MPS\u2032 satisfies the DPR. Hence, all three bullets of the definition of superiority (Definition 11) are met.\nThe charm of the MPS and MPS\u2032 measures lies in the fact that we can, in theory, derive the exact shape of the q-partition of the best query (which might be one of potentially multiple best queries) w.r.t. MPS or MPS\u2032, respectively \u2013 and not only properties it must meet. What is more, it is guaranteed that such a best query must exist for any concrete DPI and set of leading diagnoses. This is confirmed by the next proposition. Note that this means that no (heuristic) search is necessary to determine the optimal query w.r.t. MPS or MPS\u2032, respectively.\nProposition 34. Let \u3008K,B,P ,N \u3009R be an arbitrary DPI and D \u2286 mD\u3008K,B,P,N \u3009R . Then one query Q \u2208 QD,\u3008K,B,P,N \u3009R that is considered best in QD,\u3008K,B,P,N \u3009R by MPS (i.e. there is no query Q\u2032 \u2208 QD,\u3008K,B,P,N \u3009R such that Q\n\u2032 \u227aMPS Q) has the q-partition \u3008{D} ,D \\ {D} , \u2205\u3009 where p(D) \u2265 p(D\u2032) for all D\u2032 \u2208 D. The same holds if MPS is replaced by MPS\u2032.\nProof. By [20, Prop. 7.5] each partition \u3008{D} ,D \\ {D} , \u2205\u3009 is a q-partition w.r.t. any set of leading diagnoses D where |D| \u2265 2 (note that the latter is a necessary requirement for queries in QD to exist, cf. Proposition 3,(6.)). Each such q-partition has a positive MPS value due to the fact that its D0-set is empty. Since all queries Q where neither D+(Q) nor D\u2212(Q) is a singleton feature MPS(Q) = 0, the statement of the Proposition follows from the definition of DQ,min and QMPS.\nWe show that the same must hold for MPS\u2032 by contradiction. Suppose MPS\u2032 does not consider the query with the given q-partition as a best one among QD,\u3008K,B,P,N \u3009R . Then, since MPS\n\u2032 equals MPS, by definition, for queries not satisfying Eq. 26 and all queries with associated q-partitions of the form \u3008{D} ,D \\ {D} , \u2205\u3009 do not satisfy Eq. 26, the best query w.r.t. MPS\u2032 must not be of the form \u3008{D} ,D \\ {D} , \u2205\u3009. There are two possible types of q-partitions remaining which could be regarded best by MPS\u2032, either \u3008D \\ {D} , {D} , \u2205\u3009 or some q-partition that does meet Eq. 26. In the former case, the value returned for any such q-partition can be at most the value achieved for the best q-partition of the form \u3008{D} ,D \\ {D} , \u2205\u3009. This would imply that MPS\u2032 considers the same q-partition as a best one as MPS, contradiction. The latter case entails a contradiction in the same style due to the fact that, for each q-partition satisfying Eq. 26, the MPS\u2032 measure is less than or equal to zero and thus smaller than for all q-partitions of the form \u3008{D} ,D \\ {D} , \u2205\u3009, in particular smaller than for the one q-partition considered best by MPS and hence, as argued above, smaller than for the one q-partition considered best by MPS\u2032.\nBiased Maximal Elimination (BME): The idea underlying BME is to prefer a situation where a maximal number of the leading diagnoses D, i.e. at least half of them, can be eliminated with a probability of more than 0.5. Formally, this can be expressed as preferring the query\nQBME := arg max Q\u2208QD\n(BME(Q)) where BME(Q) := |DQ,p,min|\nwhere\nDQ,p,min :=  D\u2212(Q), if p(D\u2212(Q)) < p(D+(Q)) D+(Q), if p(D\u2212(Q)) > p(D+(Q))\n0, otherwise\nAt this, DQ,p,min is exactly the subset of D that is invalidated if the more probable answer to Q is actually given. Because, if say t is the more likely answer, i.e. p(Q = t) = p(D+(Q)) + 12p(D\n0(Q)) > p(Q = f) = p(D\u2212(Q)) + 12p(D\n0(Q)), then p(D+(Q)) > p(D\u2212(Q)), i.e. DQ,p,min = D\u2212(Q), which is the set invalidated as a result of a positive answer to Q (cf. Proposition 3,(2.)). DQ,p,min is set to zero in case none of the answers is more likely. That is because BME, as the word \u201cbiased\u201d in its name suggests, strives for queries with a bias towards one of the answers and hence rates unbiased queries very low. Note that each unbiased query is indeed worse w.r.t. BME than each biased one since |D+(Q)| as well as |D\u2212(Q)| are always positive for any query (cf. Proposition 3,(6.)).\nThe BME measure fits into the EMC framework because it maximizes the most probable change on the current model (leading diagnoses) resulting from the query\u2019s answer.\nProposition 35. BME is not consistent with the debug-preference relation DPR (and hence does not satisfy DPR).\nProof. Let the queries Q and Q\u2032 be characterized by the following q-partitions:\n\u3008D+(Q),D\u2212(Q),D0(Q)\u3009 = \u3008{D1,D2,D3} , {D4} , \u2205\u3009 \u3008D+(Q\u2032),D\u2212(Q\u2032),D0(Q\u2032)\u3009 = \u3008{D1,D2} , {D4} , {D3}\u3009\nClearly, by Proposition 12,Q is debug-preferred toQ\u2032. Let further the diagnosis probabilities pi := p(Di) be as follows:\n\u3008p1, . . . , p4\u3009 = \u30080.1, 0.1, 0.5, 0.3\u3009\nNow, DQ,p,min = D\u2212(Q) = {D4}, i.e. BME(Q) = | {D4} | = 1, whereas DQ\u2032,p,min = D+(Q\u2032) = {D1,D2}, i.e. BME(Q\u2032) = | {D1,D2} | = 2. In other words, Q is more likely (with a probability of 0.7) to eliminate one diagnosis in D (than to eliminate three, i.e. {D1,D2,D3}). On the other hand, Q\u2032 is more likely (probability 0.3 + 120.5 = 0.55) to invalidate two diagnoses in D (than to invalidate one, i.e. {D4}). Consequently, BME(Q\u2032) > BME(Q). That is, Q\u2032 \u227aBME Q.\nCorollary 18. All measures satisfying the debug-preference relation are superior to BME.\nProof. Immediate from Propositions 10 and 35.\nExpected Error Reduction (EER). The EER framework judges the one unlabeled instance (Q, ?) most favorably, the labeling of which implies the greatest reduction of the expected generalization error. There are (at least) two methods of estimating the expected generalization error [25, Sec. 4.1]. The first is the expected classification error over some validation set, i.e. the expected probability of misclassifying some new query using the new modelMnew resulting from the current modelM through addition of the labeled instance (Q, u(Q)). The validation set is usually a (sufficiently large) subset of all unlabeled instances. The best query w.r.t. expected classification error (cf. [25, Eq. 4.1]) is given by\nQCE := arg min Q\u2208QD \u2211 a\u2208{t,f} p(Q = a)  1 |QD\u2032(Q=a)| \u2211 Qi\u2208QD\u2032(Q=a) 1\u2212 pD\u2032(Q=a)(Qi = aQi,max)  (28) where p, as usual, is the current probability distribution of the leading diagnoses D, D\u2032(Q = a) is the new set of leading diagnoses w.r.t. the new DPI resulting from the addition of Q to the positive test cases P if a = t or to the negative test cases N otherwise, and pD\u2032(Q=a) refers to the (updated) probability distribution of the new leading diagnoses D\u2032(Q = a). The term in squared brackets in Eq. 28 corresponds to the expected probability that the new model (given by the new set of leading diagnoses D\u2032(Q = a)) wrongly classifies a query among all queries w.r.t. the new leading diagnoses set D\u2032(Q = a). We remark that, unlike in [25, Eq. 4.1] (where the (size of the) pool of unlabeled instances is assumed static and independent of the current model), the factor 1|QD\u2032(Q=a)| , i.e. the division by the number of all queries, cannot be omitted in our case as there might be different numbers of queries w.r.t. different leading diagnoses sets. Intuitively, a query is given a good score by CE if the average new model resulting from getting an answer to it predicts the answer to a large proportion of new queries with high certainty.\nThe second way of assessing the expected generalization error is by relying upon the expected entropy. This means favoring the query characterized as follows:\nQEE := arg min Q\u2208QD \u2211 a\u2208{t,f} p(Q = a)  1 |QD\u2032(Q=a)| \u2211 Qi\u2208QD\u2032(Q=a) HD\u2032(Q=a)(Qi)  (29)\nwhere the information entropy HD\u2032(Q=a)(Qi) of a given query Qi w.r.t. the new leading diagnoses D\u2032(Q = a) and the probability measure pD\u2032(Q=a) is given by\nHD\u2032(Q=a)(Qi) := \u2212 \u2211\nai\u2208{t,f}\npD\u2032(Q=a)(Qi = ai) log2 ( pD\u2032(Q=a)(Qi = ai) ) The expected entropy represented within the squared brackets in Eq. 29 is the lower, the more tendency there is in pD\u2032(Q=a) towards a single answer w.r.t. queries in QD\u2032(Q=a). Hence, similarly as in the case of CE, a query is given a high score by EE if the average new model resulting from getting an answer to it predicts the answer to a large proportion of new queries with high certainty.\nIn order to compute QCE or QEE, there are several requirements:\n1. A pool of queries QD must be generated w.r.t. the current set of leading diagnoses D (over this pool, the optimal query is sought; we are not able to derive any properties of the best q-partition w.r.t. CE (or EE) that would enable a direct search),\n2. for both ficticiuous answers a \u2208 {t, f} to each query Q \u2208 QD, a new DPI resulting from the current one by a corresponding addition of the test case Q must be considered and a set of leading diagnoses D\u2032(Q = a) must be computed w.r.t. it,\n3. the probability measure p must be updated (Bayesian update, cf. [20, p. 130]) yielding pD\u2032(Q=a), a probability measure w.r.t. D\u2032(Q = a),\n4. another pool of queries QD\u2032(Q=a) must be generated w.r.t. the new set of leading diagnoses D\u2032(Q = a), and\n5. the probability w.r.t. the measure pD\u2032(Q=a) of answers to each query in QD\u2032(Q=a) must be computed.\nScrutinizing these necessary computations, we first observe that CE and EE require as an active learning mode the pool-based sampling (PS) approach (see Section 3.2). Hence, contrary to the measures we analyzed before, CE and EE are not amenable to a heuristic q-partition search method. Second, by the efficient q-partition generation technique we will introduce in Section 3.4, q-partitions can be generated inexpensively, i.e. without costly calls to any oracles, e.g. logical reasoning services. Hence, requirements 1 and 4 do not pose significant challenges. We want to emphasize, however, that, with current methods of q-partition or query generation, these two requirements would already be a knock-out criterion for CE as well as EE (see Section 3.1). An issue that is present in spite of the efficient computation of q-partitions is that if the sets of queries QD and QD\u2032(Q=a) are not restricted in whatsoever way, they will generally have an exponential cardinality. That is, the determination of the best query QCE (QEE) requires an exponential number of evaluations (requirement 5) an exponential number of times (i.e. for all queries in QD). The computational complexity of requirement 3 associated with the computation of the new probability measure is linear in the number of new test cases added throughout the debugging session, as was shown in [20, Prop. 9.2] and hence is not a great problem. The actual issue concerning the computation of QCE (QEE) is requirement 2, the computational costs of which are prohibitive and thus hinder an efficient deployment of CE (EE) in the interactive debugging scenario where timeliness has highest priority. The reason for this is the hardness of the diagnosis computation which is proven to be at least as hard as \u03a3P2 = NP\nNP even for some DPI over propositional logic [20, Cor. 9.1]. Such a diagnosis computation must be accomplished once for each answer to each query in QD, i.e. 2 \u00b7 |QD| often where |QD| is (generally) of exponential size. Consequently, the EER framework cannot be reasonably applied to our ontology debugging scenario."}, {"heading": "3.2.4 Risk-Optimized Active Learning Measure", "text": "In this subsection we introduce a new measure for q-partition selection called RIsk Optimization measure, RIO for short. Based on our lessons learned from Section 3.2.1, we can consider the ENT and SPL measures as representatives for basically different active learning paradigms, uncertainty sampling (US) and expected model change (EMC) on the one hand (ENT is strongly related to H, LC, M from the US framework, cf. Proposition 20 and Corollary 6, and to EMCa from the EMC framework, cf. Propositions 15 and 29 as well as Corollary 13), and query-by-committee (QBC) on the other hand (ENT is strongly related to VE from the QBC framework).\nThe fundamental difference between ENT and SPL concerning the number of queries to a user required during a debugging session is witnessed by experiments conducted in [27, 26, 21]. Results in these works point out the importance of a careful choice of query selection measure in the light of the used fault estimates, i.e. the probability measure p. Concretely, for good estimates ENT is appropriate. SPL, in contrast, works particularly well in situations where estimates are doubted. The essential problem, however, is that measuring the quality of the estimates is not possible before additional information in terms of answered queries from a user is collected. In fact, we could measure a significant overhead in the number of queries necessary until identification of the true diagnosis in case an unfavorable combination of the quality of the estimates on the one hand, and the q-partition selection measure on the other hand, is used. Compared to the usage of the more appropriate measure among {ENT,SPL} in a particular debugging scenario, the reliance upon the worse measure among {ENT,SPL} amounted to several hundred percent of time or effort overhead for the interacting user on average and even reached numbers higher than 2000% [21]. Hence, there is a certain risk of weak performance when opting for any of the measures ENT and SPL. This motivates the name of RIO.\nThe idea of RIO is to unite advantages of both ENT and SPL measures in a dynamic reinforcement learning measure that is constantly adapted based on the observed performance. The performance is measured in terms of the diagnosis elimination rate w.r.t. the set of leading diagnoses D. In that, RIO relies on the given fault estimates p and recommends similar q-partitions as ENT when facing good performance, whereas aggravation of performance leads to a gradual neglect of p and a behavior akin to SPL.\nThe RIO measure aims at selecting a query that is primarily not too \u201crisky\u201d and secondarily features a high information gain. Intuitively, a query which might invalidate only a small number of leading diagnoses if answered unfavorably, is more risky (or less cautious) than a query that eliminates a higher number of leading diagnoses for both answers. So, the risk of a query Q w.r.t. the leading diagnoses D can be quantified in terms of the worst case diagnosis elimination rate of Q which is determined by its q-partition P(Q) = \u3008D+(Q),D\u2212(Q),D0(Q)\u3009. Namely, the worst case occurs when the given answer u(Q) to Q is unfavorable, i.e. the smaller set of diagnoses in {D+(Q),D\u2212(Q)} gets invalid. The notion of cautiousness or risk aversion of a query is formally captured as follows:\nDefinition 12 (Cautiousness of a Query and q-Partition). Let D \u2286mD\u3008K,B,P,N \u3009R , P = \u3008D+,D\u2212,D0\u3009 a q-partition w.r.t. D, and |D|min := min(|D+|, |D\u2212|). Then we call cq(P) := |D|min|D| the cautiousness of P.\nLet Q be a query in QD with associated q-partition P(Q). Then, we define the cautiousness cq(Q) of Q as cq(Q) := cq(P(Q)).\nLet P,P\u2032 be two q-partitions w.r.t. D andQ andQ\u2032 be queries associated with P and P\u2032, respectively. Then, we call the q-partition P (the query Q) more respectively less cautious than the q-partition P\u2032 (the query Q\u2032) iff cq(P) > cq(P\u2032) respectively cq(P) < cq(P\u2032).\nThe following proposition is a simple consequence of Definition 12:\nProposition 36. The cautiousness cq(P) of a q-partition w.r.t. D can attain values in the interval\n[cq, cq] :=  1 |D| , \u230a |D| 2 \u230b |D|  RIO is guided by the reinforcement learning parameter c that appoints how cautious the next selected query should minimally be. The user may specify desired lower and upper bounds c and c for c such that [c, c] \u2286 [cq, cq] is preserved. In this vein, the user can take influence on the dynamic behavior of the RIO measure. Trust (disbelief) in the fault estimates and thus in the probability measure p can be expressed by specification of lower (higher) values for c and/or c. Simply said, a lower (higher) value of c means higher (lower) maximum possible risk, whereas a lower (higher) value of cmeans higher (lower) minimal risk of a query RIO might suggest during a debugging session.\nThe parameter c can be used to subdivide the set of q-partitions w.r.t. D into high-risk and non-highrisk q-partitions. Formally:\nDefinition 13 (High-Risk Query and q-Partition). Let P = \u3008D+,D\u2212,D0\u3009 be a q-partition w.r.t. D, Q a query associated with P and c \u2208 [cq, cq]. Then we call P a high-risk q-partition w.r.t. c (Q a highrisk query w.r.t. c) iff cq(P) < c, and a non-high-risk q-partition w.r.t. c (non-high-risk query w.r.t. c) otherwise. The set of non-high-risk q-partitions w.r.t. c and D is denoted by NHRc,D.\nLet LC (X ) denote the subset of least cautious q-partitions of a set of q-partitions X and be defined as\nLC (X ) := {P \u2208 X | \u2200P\u2032 \u2208 X : cq(P) \u2264 cq(P\u2032)}\nThen, the query QRIO in QD selected by the RIO measure is formally defined as follows:\nQRIO := QENT if P(QENT) \u2208 NHRc,Darg min {Q |P(Q)\u2208LC (NHRc,D)} (ENT(Q)) otherwise (30)\nwhere QENT and ENT(Q) are specified in Equations 9 and 10, respectively. So, (1) RIO prefers the query QENT favored by ENT in case this query is a non-high-risk query with regard to the parameter c and the leading diagnoses D. Otherwise, (2) RIO chooses the one query among the least cautious non-high-risk queries which has minimal ENT value. Note that this way of selecting queries is not equivalent to just using (2) and omitting (1). The reason is that in (1) we only postulate that QENT must be a non-highrisk query, i.e. it must not violate what is prescribed by c. However, QENT must not necessarily be least cautious among the non-high-risk queries.\nThe restriction to non-high-risk queries, i.e. q-partitions in NHRc,D, should guarantee a sufficiently good SPL measure, depending on the current value of the dynamic parameter c. The restriction to least cautious queries among the non-high-risk queries in (2) in turn has the effect that a query with maximum admissible risk according to c is preferred. Among those queries the one with optimal information gain (ENT) is selected. Note that the situation QRIO = QENT gets less likely, the higher c is. So, the worse the measured performance so far when relying on ENT and thus on the probability measure p, the lower the likeliness of using p for the selection of the next query. Instead, a query with better SPL measure is favored and p becomes a secondary criterion.\nThe reinforcement learning of parameter c is based on the measured diagnosis elimination rate after the answer u(QRIO) to query QRIO has been obtained.\nDefinition 14 (Elimination Rate, (Un)favorable Answer). Let Q \u2208 QD be a query and u(Q) \u2208 {t, f} a user\u2019s answer to Q. Further, let D\u2217 := D\u2212(Q) for u(Q) = t and D\u2217 := D+(Q) for u(Q) = f . Then we call ER(Q, u(Q)) = |D\n\u2217| |D| the elimination rate of Q.\nMoreover, u(Q) is called (un)favorable answer to Q iff u(Q) (minimizes) maximizes ER(Q, u(Q)). In the special case of even |D| and ER(Q, u(Q)) = 12 , we call u(Q) a favorable answer to Q.\nAs update function for c we use c\u2190 c+ cAF where the cautiousness adjustment factor\ncAF := 2 (c\u2212 c)AF (Q, u(Q))\nwhere\nAF (Q, u(Q)) :=\n\u230a |D|\u22121\n2 \u230b + 12\n|D| \u2212 ER(Q, u(Q))\nThe (always non-negative) scaling factor 2 (c\u2212c) regulates the extent of the adjustment depending on the interval length c\u2212 c. More crucial is the factor AF (Q, u(Q)) that indicates the sign and magnitude of the cautiousness adjustment. This adjustment means a decrease of cautiousness c if u(Q) is favorable, i.e. a bonus to take higher risk in the next iteration, and an increase of c if u(Q) is unfavorable, i.e. a penalty to be more risk-averse when choosing the next query.\nProposition 37. Let Q \u2208 QD and c(i) the current value of the cautiousness parameter. Then:\n\u2022 If c = c, then c(i+1) = c(i).\n\u2022 If c > c, then for the updated value c(i+1) \u2190 c(i) + cAF it holds that c(i+1) < c(i) for favorable and c(i+1) > c(i) for unfavorable answer u(Q).\nProof. The first bullet is clear since c = c implies that cAF = 0 due to c\u2212 c = 0. Regarding the second bullet, we argue as follows: Due to the fact that cAF has the same sign as AF (Q, u(Q)) by 2 (c\u2212 c) > 0, it is sufficient to show that AF (Q, u(Q)) < 0 for favorable answer u(Q) and AF (Q, u(Q)) > 0 for unfavorable answer u(Q) for all queries Q \u2208 QD. The first observation is that the maximal value the minimal elimination rate of a query Q \u2208 QD can attain is max minER := 1|D|b |D| 2 c and the minimal value the maximal elimination rate of a query Q \u2208 QD can attain is min maxER := 1|D|d |D| 2 e. In other words, for odd |D|, by Definition 14, the minimal (maximal) elimination rate that must be achieved by an answer to a query w.r.t. the leading diagnoses D in order to be called favorable (unfavorable) is given by min maxER (max minER). For even |D|, min maxER = max minER holds and, by Definition 14, an answer to a query yielding an elimination rate of max minER is called favorable. Let the term\u230a\n|D|\u22121 2 \u230b + 12\n|D|\nbe called BASEER. Let us first consider even |D|: It holds that d |D|2 e = b |D| 2 c = |D| 2 . Further,\n\u230a |D|\u22121\n2 \u230b = |D|\u221222 since\n|D| \u2212 1 is odd. Hence, the numerator of BASEER reduces to |D|\u22122+12 = |D|\u22121\n2 . Let the answer be favorable. That is, the elimination rate must be at least min maxER = 1|D| |D| 2 . So, AF (Q, u(Q)) \u2264 BASEER \u2212min maxER = 1|D| ( |D|\u22121 2 \u2212 |D| 2 ) = \u2212 1 2|D| < 0. Now, let the answer be unfavorable. Then, an elimination rate smaller than or equal to min maxER \u2212 1|D| = 1 |D| ( |D| 2 \u2212 1) must be achieved by this query answer. Consequently, using the calculation of AF (Q, u(Q)) above (by using an elimination rate of maximally min maxER \u2212 1|D| instead of minimally min maxER), we have that AF (Q, u(Q)) = \u2212 12|D| + 1 |D| = \u2212 1 2|D| + 2 2|D| = 1 2|D| > 0.\nFor odd |D|, it holds that d |D|2 e = |D|+1 2 and b |D| 2 c = |D|\u22121 2 . The maximal elimination rate that still\nmeans that an answer u(Q) is unfavorable is max minER = 1|D| |D|\u22121\n2 . So, AF (Q, u(Q)) \u2265 BASEER \u2212 max minER = 1 |D| ( |D| 2 \u2212 |D|\u22121 2 ) = 1 2|D| > 0. On the other hand, the least elimination rate for a favorable answer u(Q) is min maxER = 1|D| |D|+1\n2 which yields AF (Q, u(Q)) \u2264 BASEER \u2212 min maxER = 1 |D| ( |D| 2 \u2212 |D|+1 2 ) = \u2212 1 2|D| < 0.\nIf the updated cautiousness c+ cAF is outside the user-defined cautiousness interval [c, c], it is set to c if c+ cAF < c and to c if c+ cAF > c. Note that the update of c cannot take place directly after a query Q has been answered, but only before the next query selection, after the answer to Q is known (and the elimination rate can be computed).\nProposition 38. RIO is not consistent with the debug-preference relation DPR (and hence does not satisfy the DPR).\nProof. The statement of this proposition holds since both cases in Eq. 30 involve a query selection by ENT among a particular set of queries and since ENT is not consistent with the debug-preference relation by Proposition 15.\nLet us now, in a similar fashion as done with ENTz , define RIOz that selects the following query:\nQRIOz :=  QENTz if P(QENTz ) \u2208 NHRc,D (31)\narg min {Q |P(Q)\u2208LC (NHRc,D)} (ENTz(Q)) otherwise (32)\nProposition 39. RIOz with sufficiently large z satisfies the debug-preference relation DPR\n\u2022 over QD in the first case (Eq. 31).\n\u2022 over {Q |P(Q) \u2208 LC (NHRc,D)} in the second case (Eq. 32).\nProof. Immediate from Corollary 3 and the fact that RIOz chooses the best query w.r.t. ENTz over QD in the first case (Eq. 31) and the best query w.r.t. ENTz over {Q |P(Q) \u2208 LC (NHRc,D)} in the second case (Eq. 32).\nRemark 6 Proposition 39 does not imply that RIOz generally satisfies the debug-preference relation over QD. To see this, realize that, given two queries Q,Q\u2032 where (Q,Q\u2032) \u2208 DPR, the cautiousness cq(P(Q\u2032)) \u2264 cq(P(Q)). This holds due to Definition 12 and Proposition 12 which implies that min {|D+(Q\u2032)|, |D\u2212(Q\u2032)|} \u2264 min {|D+(Q)|, |D\u2212(Q)|}. Hence, Q\u2032 might be among the least cautious non-high-risk queries, i.e. in {Q |P(Q) \u2208 LC (NHRc,D)}, andQmight not. Given that additionally, e.g. p(D+(Q)) = p(D\u2212(Q)) = 12 , Q\n\u2032 might be be selected by RIOz and thus preferred to Q (because Q is simply not least cautious and therefore, as desired, not taken into consideration).\nRemark 7 Thinkable variants of RIO other than RIOz are to use EMCa2 or MPS\u2032, respectively, instead of ENT in Eq. 30 (i.e. either replace all occurrences of ENT in RIO by EMCa2 or all occurrences by MPS\u2032). Both of these measures satisfy the debug-preference relation, unlike ENT. Also ENTz only does so for a large enough setting of z which depends on the given set of queries from which an optimal one should be suggested. EMCa2 or MPS\u2032, on the other hand, satisfy the debug-preference relation anyway, without the need to adjust any parameters.\nIt is however worth noting that whether EMCa2 or MPS\u2032 is used within the RIO measure is quite different. Whereas EMCa2 implies a very similar query preference order as ENT does (cf. Section 3.3\nand Table 9), just putting more emphasize on the minimization of |D0(Q)|, the employment of MPS\u2032 would, by definition, favor only queries of least possible cautiousness, or equivalently of highest possible risk, if such queries are available. In this case, the situation of RIO directly accepting the best query w.r.t. MPS\u2032 (first line in Eq. 30) becomes rather unlikely as this happens only if the current cautiousness parameter c is not higher than 1|D| . Consequently, besides modifying the property of basically preferring queries with an optimal information gain, the usage of MPS\u2032 might also involve a higher average query computation time, as the (additional) second criterion (second line in Eq. 30) focusing only on non-highrisk queries tends to come into effect more often.\nIndependently of these thoughts, Proposition 39 also holds for RIO using either of the two measures EMCa2 or MPS\u2032, see below. Proposition 40. RIO with every occurrence of ENT in Eq. 30 replaced by exactly one of { EMCa2,MPS\n\u2032} satisfies the debug-preference relation DPR\n\u2022 over QD in the first case (Eq. 31).\n\u2022 over {Q |P(Q) \u2208 LC (NHRc,D)} in the second case (Eq. 32).\nThe theoretically optimal query w.r.t. to RIO and RIOz , respectively, is one that is optimal w.r.t. ENT and ENTz , respectively, and that is sufficiently cautious as prescribed by the current parameter c.\nProposition 41. Let the current parameter of RIO (RIOz) be c and the set of leading diagnoses be D. Then, the theoretically optimal query w.r.t. RIO (RIOz) satisfies |p(D+(Q)) \u2212 p(D\u2212(Q))| = 0, D0(Q) = \u2205 and cq(Q) \u2265 c.\nNote that the third condition given in this proposition involves an inequality. This implies that there are |D|\u2212dce+1 different global optima for RIO and RIOz , respectively, i.e. one for each query cautiousness cq(Q) \u2208 {dce, . . . , |D|}."}, {"heading": "3.2.5 Summary", "text": "In the previous sections we have thoroughly analyzed the properties of various existing (Section 3.2.2) and new (Section 3.2.3) active learning measures with regard to their application as query selection measures in the interactive KB debugging. In this section, we summarize the obtained results.\nDebug-Preference Relation and Theoretical Optimum. Table 6 reports on the extent the discussed measures, grouped by active learning frameworks they belong to, comply with the debug-preference relation (satisfaction of DPR: X; non-satisfaction of, but consistency with DPR: (X); non-consistency with DPR: \u00d7) and indicates whether there is a theoretical optimum (X) of a measure or not (\u00d7). Note that ENT as well as ENTz were not assigned to any of the active learning frameworks discussed throughout Section 3.2.3 since they do not seem to fit any of these sufficiently well. The measures SPL and SPLz , on the other hand, match the QBC framework pretty well with the additional assumption that a penalty of z is awarded for each non-voting committee member.\nWhat becomes evident from Table 6 is that the only measures that satisfy the debug-preference relation DPR without the need of appropriate additional conditions being fulfilled are EMCaz for z > 2, SPLz for z > 1 as well as MPS\u2032. That is, the order imposed by any of these measures over an arbitrary set of queries includes all preferences between query pairs DPR includes. For ENTz and fixed selection of z, all queries in the set of queries Q of interest must feature a large enough discrepancy \u2013 which depends on z \u2013 between the likeliness of positive and negative answers in order for ENTz to satisfy the DPR over Q. This fact is made precise by Corollary 3. Further, we have examined two measures, SPL and MPS, which do not violate the DPR, i.e. do not imply any preferences between query pairs which are\nreciprocally stated by DPR, but are proven not to imply all preferences between query pairs stated by DPR. All other investigated measures are not consistent with the DPR in general.\nConcerning the theoretical optimum, i.e. the global optimum of the real-valued functions characterizing the measures, there are only two measures, KL and EMCb, for which such a one does not exist. Responsible for this fact to hold is, roughly, that given any fixed query, we can construct another query with a better value w.r.t. these measures, theoretically. On the practical side, however, we were still able to derive criteria \u2013 which are, remarkably, almost identical for both measures, albeit these belong to different active learning frameworks \u2013 the best query among a number of queries must comply with. Nevertheless, a drawback of these criteria is that they are non-deterministic in that they still leave open a number of different shapes the best query might have and that must be searched through in order to unveil this sought query. The reason why we studied the theoretical optima of the measures is that they provide us with a valuable insight into the properties that render queries good or bad w.r.t. the respective measure. And, as we have seen, these properties are often not extractable in a very easy way just from the given quantitative function. We use these deduced properties in the next section to pin down qualitative requirements to optimal queries w.r.t. all the discussed measures. These qualitative criteria will be an essential prerequisite to the successful implementation of heuristics to guide a systematic search for optimal queries. We will delve into this latter topic in Section 3.4.\nSuperiority Relation. We were also studying the relationship between different measures in terms of superiority. The superiority relation \u227a (cf. Definition 11) is defined on the basis of the debug-preference relationDPR and holds between two measuresm1 andm2 (i.e.m1 is superior tom2) iff the intersection of DPR with the (preference) relation imposed on queries by m1 is a proper superset of the intersection of DPR with the (preference) relation imposed on queries by m2. Figure 2 summarizes all superiority relationships between measures we discovered. Note this figure raises no claim to completeness as there might be further valid relationships not depicted which we did not detect. The figure is designed in a way that higher compliance with the DPR means a higher position of the node representing the respective measure in the graph. We can read from the figure that all the measures that satisfy the DPR (framed nodes in the graph) are superior to all others. In fact, this must be the case due to Proposition 10. Please observe that the superiority relation is transitive (witnessed by Proposition 8). This implicates that, given a directed path between to measures, the source measure of this path is inferior to the sink measure of the path. That is, for instance, the GiniIndex is inferior to MPS\u2032 although there is no direct edge between both measures. Interestingly, none of the measures SPL (only consistent with DPR) and ENT (inconsistent with DPR in general) so far used in KB debugging satisfy the DPR. Hence, for each of these, there are other measures superior to them. That said, for each of SPL and ENT, there is a superior measure which favors queries with the very same properties, just that it additionally obeys the debug-preference order. For SPL, one of such measures is e.g. SPL2. In fact, all measures SPLz with a parametrization z > 1 are candidates to improve SPL regarding the fulfillment of the DPR, and hence are superior to SPL. As to ENT, one measure involving the optimization of the same query features, just with a higher penalization of features that can lead to a violation of the DPR, is e.g. EMCa2. Actually, all measures EMCaz with an arbitrary setting of z \u2265 2 are superior to SPL. This adherence to the same strategy of query selection of (SPL,SPLz (z>1)) and (ENT,EMCz (z\u22652)) with more appropriate prioritization of properties achieved by the superior measure finds expression also in the derived requirements to optimal queries which we will discuss in Section 3.3 (cf. Table 9).\nEquivalence Relations. Finally, Table 7 gives information about equivalence relations between measures, in particular about the equivalence classes w.r.t. the relations = (two measures optimize exactly the same function) , \u2261 (two measures impose exactly the same preference order on any set of queries) and \u2261Q (two measures impose exactly the same preference order on the query set Q) where Q is perceived to be any set of queries comprising only queries with an empty D0-set. It is important to recognize that the\nderived equivalences between measures do hold as far as the KB debugging setting is concerned, but must not necessarily hold in a different setting, e.g. an active learning setting where the learner is supposed to learn a classifier with a discrete class variable with domain of cardinality 3 or higher. Further on, note that the higher the number of the row in the table, the more coarse grained is the partitioning of the set of all measures given by the equivalence classes imposed by the relations. This results from the fact that if two measures are equal, they must be also equivalent, and if they are equivalent, they must be equivalent under any assumption of underlying set of queries. This table tells us that, up to equality, there are 18 different measures we discussed, each with a different quantitative function (first vertical section of the table). If the preference order imposed by the measures is taken as the criterion, then there remain 15 different equivalence classes of measures (second section of the table). We observe that, compared with the relation =, the classes {LC}, {M}, {H} and {EMCa0,GiniIndex} as well as the classes {VE} and {SPL0} (in the first section only implicitly listed in terms of { SPLz (z 6=1) } ) join up when considering \u2261. That is, these four and two classes of different functions lead to only two different query selection measures in the context of our KB debugging scenario. Comparing the third section of the table with the second, we see various coalescences of classes, indicating that, over queries with empty D0-set, essentially different measures suddenly constitute equivalent measures. In particular, measures motivated by the maximization of information gain, the maximization of uncertainty about query answers (uncertainty sampling), the maximization of the expected probability mass of invalidated (leading) diagnoses (expected model change, variant (a)), and the GiniIndex conflate into one single equivalence class. On the other hand, vote entropy and split-in-half (with arbitrary z-parametrization) merge. Third, MPS\u2032 is no longer better (in terms of the superiority relation) than MPS, because both are now equivalent. In fact, the order on the set of measures imposed by the superiority relation\u227a given by Figure 2 collapses completely after restricting the set of arbitrary queries to only queries in Q, i.e. all edges in the graph depicted by Figure 2 vanish. This is substantiated by Proposition 11 which implies that the debug-preference relation DPR upon Q must be the empty relation. So, overall, we count seven remaining classes of measures w.r.t. \u2261Q."}, {"heading": "3.3 Q-Partition Requirements Selection", "text": "In this section we enumerate and discuss the qualitiative requirements rm that can be derived for all the discussed quantitative query quality measures m. These requirements provide the basis for the construction of efficient search strategies for the optimal q-partition P that do not depend on a precalculation of a pool of q-partitions (cf. the discussion on page 22) and are used by the QPARTITIONREQSELECTION function in Algorithm 2 on page 22.\nThe function QPARTITIONREQSELECTION in Algorithm 2 is described by Table 9. It outputs a set of requirements rm that must hold for a q-partition P to be optimal w.r.t. some quantitative query quality measure measure m given as input. That is, the function can be imagined as a simple lookup in this table given a particular measure m as input. The table summarizes the results obtained in Sections 3.2.2 and 3.2.3. The rightmost column of the table gives the numbers of the respective Proposition (P) or Corollary (C), from which the requirements rm for some measure m can be deduced in a straightforward way. In case the requirements are directly recognizable from the definition of a measure, this is indicated by a \u201cD\u201d in the last column of the table.\nThe table groups measures by their associated active learning frameworks (see Section 3.2.5 as to why ENT and ENTz are not allocated to any of the discussed frameworks). Drawing our attention to the \u201crequirements\u201d column of the table, roman numbers in brackets signalize the priority of requirements, e.g. (I) denotes higher priority than (II). In rows where no prioritization of requirements is given by roman numbers, either all requirements have equal weight (which holds e.g. for SPL) or the prioritization depends on additional conditions. The latter is denoted by a (*) on the right of the respective row in the table. Such additional conditions might be e.g. the probability of query answers. For example, in the case\nof ENT, for queries with a high difference (\u2265 35 , cf. Proposition 15) between the probabilities of positive and negative answer, more weight is put on the minimization of |p(D+(Q))\u2212 p(D\u2212(Q))|, whereas for queries with a lower difference (< 35 ) the prioritization order of the requirements is tilted implying a higher weight on the minimization of p(D0(Q)).\nNote further the disjunctive (\u201ceither...or\u201d) and indeterministic character (\u201csome\u201d) of the requirements for EMCb and KL. This comes due to the fact that there is no theoretical optimum for these two equivalence classes (cf. Table 6). In the last two rows, rENT as well as rENTz is a shorthand for the requirements rm for m equal to ENT and ENTz , respectively, given in the IG section of the table. Other formalisms given in the last two rows are explained in detail in Section 3.2.4.\nIf we compare the requirements for measures not satisfying the debug-preference relation DPR with\nthose for measures satisfying the DPR, we realize that the former (a) do not consider or (b) do not put enough weight on the minimization of the set D0(Q). As an example for (a), the requirements for both H and VE do not mention D0(Q) at all, i.e. disregard minimizing this set. The inevitable consequence of this is that these measures are not consistent with the DPR (cf. Table 6). Case (b) occurs e.g. with SPLz for z < 1. Here, more emphasize is put on the minimization of ||D+(Q)| \u2212 |D\u2212(Q))|| than on the minimization of |D0(Q)|, again resulting in an inconsistency w.r.t. the DPR (cf. Figure 2).\nOn the other hand, all measures preserving the DPR, i.e. SPLz for z > 1, MPS\u2032, ENTz for z \u2192 \u221e as well as EMCaz for z \u2265 2, have a single highest priority requirement to the best query, namely to minimize |D0(Q)|. Note that the postulation of minimizing p(D0(Q)) is equivalent to the postulation of minimizing |D0(Q)| since all diagnoses have a positive probability (cf. page 26).\nAnother aspect that catches one\u2019s eye is the fact that KL and EMCb, albeit not equivalent as illustrated by Example 16, lead to the same set of requirements to the best query. However, we have to be aware and not conclude from this fact that both measures will always cause the selection of the same query. Responsible for that is the indeterministic character of the requirements set of these two measures, as dicussed above. It is more appropriate to see these same requirements as a sign that both measures\nneed only search through the same subset of all given queries in order to find their individual \u2013 and not necessarily equal \u2013 optimum.\nNext, we analyze in which way requirements rm might be used to realize a search for an optimal q-partition w.r.t. the RIO and RIOz measures. This will also give reasons for the prioritization of the requirements w.r.t. these measures used in Table 9:\nBasically, we can think of two different methods for computing an optimal query w.r.t. RIO (RIOz). Before we describe them, note that we define \u201coptimal q-partition w.r.t. the ENT (ENTz) measure\u201d as some q-partition for which the requirements rENT (rENTz ) deviate by not more than some threshold t (cf. Section 3.4) from the theoretical optimum, which is why there may be multiple \u201coptimal\u201d q-partitions.\nThe first method works exactly according to the definition of RIO (RIOz), i.e. run a (heuristic) search S1 using rENT (rENTz ), check whether the returned q-partition P1 is a non-high-risk q-partition. If so, return P1 and stop. Otherwise execute another search S2 that takes into consideration only least cautious non-high-risk q-partitions, and find among them the best q-partition P2 w.r.t. rENT (rENTz ). Return P2. While the first search S1 uses the requirements rm specified for ENT (ENTz) and has no specifics of RIO (RIOz) to take into account, the second one, S2, strictly postulates the fulfillment of requirements (I) P(Q) \u2208 NHRc,D and (II) |cq(Q) \u2212 c| \u2192 min (for explanations of these terms, see Section 3.2.4) while trying to optimize (III) rENT(rENTz ). This approach involves carrying out a (heuristic) search S1 and, if needed, another (heuristic) search S2. Thence, this first method might be more time-consuming than the second one.\nThe second method, on the other hand, implements RIO in a way that only one search suffices. To this end, the first observation is that RIO will never accept a high-risk q-partition, cf. both lines of Eq. 30 (as to RIO) as well as Eq. 31 and 32 (regarding RIOz) where a query with P(Q) \u2208 NHRc,D is postulated. That is, the primary (and necessary) requirement is given by (I) P(Q) \u2208 NHRc,D. So, the search S1 can be understood as a search for a q-partition with optimal ENT measure among all non-high-risk q-partitions\n(because any output high-risk q-partition will be discarded). As explained above, S2 searches for a qpartition with optimal ENT measure among all least-cautious non-high-risk q-partitions. Therefore, the least-cautious non-high-risk q-partitions can be simply considered first in the search, before other nonhigh-risk q-partitions are taken into account. In this vein, (II) |cq(Q) \u2212 c| \u2192 min can be seen as the secondary criterion postulating to focus on least-cautious q-partitions first. This criterion will only be \u201cactivated\u201d during S2 and will be \u201cswitched off\u201d during S1.\nVirtually, this can be conceived as executing the search S1 in a way its beginning simulates the search S2. If this search, which is executed exactly as S2, then locates a solution q-partition complying with the given threshold t, then this q-partition is at the same time a valid solution of S1 and S2 (since \u201cleast cautious non-high-risk\u201d implies \u201cnon-high-risk\u201d) and the overall search can stop. Otherwise, the best found (non-optimal) q-partition Plc among the least-cautious non-high-risk q-partitions is stored and the search moves on towards more cautious q-partitions, i.e. search S1 continues to iterate. To this end, however, q-partitions representing nodes in the search tree at which the tree was pruned during S2 must be stored in memory in order to enable a resumption of the search S1 at these nodes at some later point. If S1 detects a solution q-partition complying with the given threshold t, this q-partition is returned. Otherwise, Plc is output.\nTo summarize the second method, the search\n1. starts seeking a q-partition meeting (III) among all q-partitions meeting (I) and (II), and, if there is a (sufficiently optimal, as per threshold t) result, returns this q-partition and stops. Otherwise, it\n2. stores the best found q-partition Plc w.r.t. the ENT measure among all q-partitions meeting (I) and (II), and\n3. continues the search for a q-partition satisfying (III) among all q-partitions satisfying only (I). If some (sufficiently optimal, as per threshold t) q-partition is found this way, it is returned and the search stops. Otherwise, the returned search result is Plc.\nRemark 8 As we shall see in Section 3.4, both discussed approaches to tackle the finding of an optimal q-partition w.r.t. RIO will perfectly go along with the search method we will define, since the proposed search will naturally start with least-cautious q-partitions.\nHowever, note that the Algorithms 4, 5, 6 and 7 we will give in Section 3.4, which characterize the behavior of our proposed heuristic q-partition search for the particular used query quality measure, will specify for RIO only the search S2 (see above). That is, only an optimal q-partition meeting (III) among all q-partitions meeting (I) and (II) will be sought. The underlying assumption is that the first search method for RIO described above is adopted. This involves a prior run of the heuristic search algorithm using ENT as query quality measure and a test whether the output q-partition is a non-highrisk q-partition. Only if not so, then another run of the heuristic search using RIO as query quality measure is necessary.\nWe want to emphasize that the implementation of the second search method for RIO described above would involve only slight changes to the given algorithms. Roughly, the following three modifications are necessary:\n1. Specification of a second set of pruning conditions, optimality conditions, heuristics and update conditions regarding the currently best q-partition, which fit search S1.\n2. Storage of all q-partitions at which search S2 pruned the search tree.\n3. Storage of two currently best q-partitions, the first (i.e. Pbest in Algorithm 3) to memorize the best q-partition found using S2 (i.e. the heursitic search using RIO we describe in Section 3.4), and another one (call it Pbest,S1 ) to memorize the best q-partition found afterwards using S1 (i.e. the heursitic search using RIO and the second set of conditions and heuristics mentioned in (1.)). During S2, only Pbest is subject to change, whereas during S1 only Pbest,S1 might be modified.\nIf Pbest is sufficiently good (w.r.t. the threshold t) after S2, Pbest is returned and no resumption of the search (S1) is necessary. Otherwise, if Pbest,S1 is sufficiently good (w.r.t. the threshold t) after S2 and S1, then Pbest,S1 is returned. Otherwise, Pbest is returned.\nAnother material property of the search we will introduce in the next section will be that it automatically neglects q-partitions with a non-empty set D0. Hence, any two measures in one and the same equivalence class in the section \u201c\u2261Q\u201d of Table 8 will yield exactly the same behavior of the q-partition finding algorithm. Moreover, the derived requirements (Table 9) for some of the discussed measures can be simplified in this scenario. On this account, we provide with Table 8 a summary of the resulting requirements rm, for each equivalence class w.r.t. \u2261Q. Exactly these requirements in Table 8 will be the basis for the specification of pruning conditions (Algorithm 6), optimality conditions (Algorithm 5) and heuristics to identify most promising successor q-partitions (Algorithm 7) and of how to update the currently best q-partition (Algorithm 4)."}, {"heading": "3.4 Finding Optimal Q-Partitions", "text": "In this section we want to discuss the implementation of the function FINDQPARTITION of Algorithm 2 which returns a (nearly) optimal q-partition for some requirements rm, a probability measure p, and\nthe set of leading diagnoses D given as input. To this end, we will derive systematic search methods. According to [23], a search problem is defined by an initial state, a successor function (that returns all direct successor states of a state), path costs and a goal test. In our case, a state corresponds to a qpartition P and a successor state to a q-partition P\u2032 resulting from P by minimal changes. The path costs are specified based on the respective optimality criteria given by requirements rm. We will consider a q-partition as a goal state of the search if it meets the requirements rm to a sufficient degree. In other words, we will specify an optimality threshold t in advance and regard a state as optimal if its \"distance\" to perfect fulfillment of rm is smaller than t (cf. [27]). In the case of the ENT measure, for example, a q-partition P = \u3008D+,D\u2212,D0\u3009 is viewed as optimal if |p(D+)\u2212p(D\u2212)|+p(D0) \u2264 t . Additionally, we will exploit heuristics, also depending on the requirements rm, in order to guide the search faster towards a goal state."}, {"heading": "3.4.1 Canonical Queries and Q-Partitions", "text": "In the context of Algorithm 2, the FINDQPARTITION function aims at identifying a q-partition with postulated properties, such that a query associated with this q-partition can be extracted in the next step by function SELECTQUERYFORQPARTITION. Consequently, realizing the fact that there can be (exponentially) many queries for one and the same q-partition, and the fact that the construction respectively verification of a q-partition requires a query (cf. Definition 8), it becomes evident that the specification of a \u201ccanonical\u201d query is desirable for this purpose.\nSearch-Space Minimization. Furthermore, in order to devise a time and space saving search method, the potential size of the search tree needs to be minimized. To this end, in case of q-partitions, a key idea is to omit those q-partitions in the search that are proven suboptimal in comparison to the ones considered in the search. In other words, given a class of suboptimal q-partitions, we can leave this class out as long as we do take into account a superior q-partition for each q-partition in this class. In this way, completeness of the search for an optimal q-partition is not affected. One such class of suboptimal q-partitions are those that have the property D0(Q) 6= \u2205 (recall that all queries for which there is another query that is debug-preferred over them, must have a non-empty D0-set, cf. Proposition 11). The reason for these q-partitions\u2019 suboptimality is that no answer to a query Q associated with one such q-partition can invalidate any diagnosis in D0(Q). However, a query should be as constraining as possible such that a maximum number of (leading) diagnoses can be eliminated by it. So, it is desirable that the number of diagnoses that are element of D0(Q), i.e. consistent with both query outcomes, is minimal, zero at the best.\nExplicit-Entailments Queries. Let an entailment \u03b1 of a set of axioms X be called explicit iff \u03b1 \u2208 X , implicit otherwise. Then, a natural way of specifying a canonical query and at the same time achieving a neglect of suboptimal q-partitions of the mentioned type is to define a query as an adequate subset of all common explicit entailments implied by KBs (K \\ Di) for Di element of some fixed set D+(Q) \u2282 D. We call a query Q \u2286 K an explicit-entailments query. The following proposition witnesses that no explicit-entailments query can have a suboptimal q-partition in terms of D0(Q) 6= \u2205.\nProposition 42. Let \u3008K,B,P ,N \u3009R be a DPI, D \u2286 mD\u3008K,B,P,N \u3009R and Q a query in QD. If Q \u2286 K, then D0(Q) = \u2205 holds.\nProof. We have to show that for an arbitrary diagnosis Di \u2208 D either Di \u2208 D+(Q) or Di \u2208 D\u2212(Q). Therefore two cases must be considered: (a) K \\ Di \u2287 Q and (b) K \\ Di 6\u2287 Q. In case (a), by the fact that the entailment relation is extensive for L, K \\ Di |= Q and thus, by monotonicity of L, K\u2217i = (K \\ Di) \u222a B \u222a UP |= Q. So Di \u2208 D+(Q). In case (b) there exists some axiom ax \u2208 Q \u2286 K such that ax /\u2208 K \\ Di, which means that (K \\ Di) \u222a Q \u2283 (K \\ Di). From this we can derive that K\u2217i \u222a Q must\nviolate some r \u2208 R or n \u2208 N by the subset-minimality property of each diagnosis in D, in particular of Di. Hence, Di \u2208 D\u2212(Q).\nThe proof of Proposition 42 exhibits a decisive advantage of using explicit-entailments queries for the construction of q-partitions during the search. This is the opportunity to use set comparison instead of reasoning, which means that it must solely be determined whether K \\ Di \u2287 Q or not for each Di \u2208 D in order to build the q-partition P(Q) associated with some query Q. So, contrary to existing works, a reasoner is only employed optionally in the ENRICHQUERY function to enrich only one already selected explicit-entailments query by additional (non-explicit) entailments.\nWhat we did not address yet is which subset of all explicit entailments of some set of KBs K\u2217i to select as canonical query. For computation purposes, i.e. to make set comparisons more efficient, the selected subset should have as small a cardinality as possible, but the minimization process should not involve any significant computational overhead. Recall that the actual computation of a minimal (optimal) query associated with a selected q-partition should take place only in the course of the function SELECTQUERYFORQPARTITION. A helpful tool in our analysis will be the notion of a justification, as defined next:\nDefinition 15 (Justification). [8] Let K be a KB and \u03b1 an axiom, both over L. Then J \u2286 K is called a justification for \u03b1 w.r.t. K, written as J \u2208 Just(\u03b1,K), iff J |= \u03b1 and for all J \u2032 \u2282 J it holds that J \u2032 6|= \u03b1.\nProperties of (General) Queries. Before analyzing the properties of the special class of explicitentailments queries, we give some general results about queries (that possibly also include implicit entailments) by the subsequently stated propositions. Before formulating the propositions, we give a simple lemma necessary for the proof of some of these.\nLemma 1. For any DPI \u3008K,B,P ,N \u3009R and D \u2286 mD\u3008K,B,P,N \u3009R it holds that (K \u222a B \u222a UP ) \\ UD = (K \\ UD) \u222a B \u222a UP .\nProof. We have to show that (i) UD \u2229 B = \u2205 and (ii) UD \u2229 UP = \u2205. Fact (i) holds by UD \u2286 K and K\u2229B = \u2205 (cf. Definition 1). Fact (ii) is true since each sentence in UD occurs in at least one diagnosis in D. Let us call this diagnosisDk. So, the assumption of UD\u2229UP 6= \u2205 implies thatK\\Dk is invalid by the subset-minimality of Dk \u2208 D. This is a contradiction to Dk \u2208mD\u3008K,B,P,N \u3009R (cf. Proposition 1).\nThe subsequently formulated proposition states necessary conditions a query Q must satisfy. In particular, at least one sentence in Q must be derivable from the extended KB K \u222a B \u222a UP only in the presence of at least one axiom in UD. Second, no sentence in Q must be derivable from the extended KB only in the presence of the axioms in ID. Third, Q is consistent.\nProposition 43. Let D \u2286mD\u3008K,B,P,N \u3009R with |D| \u2265 2. Further, let D+(Q) be an arbitrary subset of D and E be the set of common entailments (of a predefined type) of all KBs in {K\u2217i | Di \u2208 D+(Q)}. Then, a set of axioms Q \u2286 E is a query w.r.t. D only if (1.), (2.) and (3.) hold:\n1. There is at least one sentence ax \u2208 Q for which UD\u2229J 6= \u2205 for each justification J \u2208 Just(ax ,K\u222a B \u222a UP ).\n2. For all sentences ax \u2208 Q there is a justification J \u2208 Just(ax ,K \u222a B \u222a UP ) such that ID \u2229 J = \u2205.\n3. Q is (logically) consistent.\nProof. Ad 1.: Let us assume that Q is a query and for each sentence ax \u2208 Q there is a justification J \u2208 Just(ax ,K\u222aB \u222aUP ) with J \u2229UD = \u2205. So, using Lemma 1 we have that J \u2286 (K\\UD)\u222aB \u222aUP . Then (K \\ UD) \u222a B \u222a UP |= ax and since K \\ Di \u2287 K \\ UD for each Di \u2208 D, we can deduce that\n(*) K\u2217i = (K\\Di)\u222aB\u222aUP |= ax by monotonicity of L. Thence, K\u2217i |= Q for all Di \u2208 D which results in D\u2212(Q) = \u2205 which in turn contradicts the assumption that Q is a query.\nAd 2.: Let us assume that Q is a query and there is some sentence ax \u2208 Q for which for all justifications J \u2208 Just(ax ,K \u222a B \u222a UP ) it holds that J \u2229 ID 6= \u2205. Moreover, it is true that K\u2217i \u2229 ID = [(K \\ Di) \u222a B \u222a UP ] \u2229 ID = \u2205 for each Di \u2208 D due to the following reasons:\n\u2022 B \u2229 ID = \u2205 since ID \u2286 K and K \u2229 B = \u2205 (see Definition 1);\n\u2022 UP\u2229ID =: X 6= \u2205 cannot hold since ID\u2229Di 6= \u2205 for eachDi \u2208 D \u2286mD\u3008K,B,P,N \u3009R and thus, for arbitrary i, D\u2032i := Di \\X must already be a diagnosis w.r.t. \u3008K,B,P ,N \u3009R which is a contradiction to the subset-minimality of Di, i.e. to the fact that Di \u2208mD\u3008K,B,P,N \u3009R (cf. Definition 4);\n\u2022 (K \\ Di) \u2229 ID = \u2205 by ID \u2282 Di for all Di \u2208 D.\nThus, for allDi \u2208 D there can be no justification J \u2208 Just(ax ,K\u222aB\u222aUP ) such that J \u2286 K\u2217i , wherefore ax cannot be entailed by any K\u2217i . By Remark 1, this means that no K\u2217i entails Q which lets us conclude that D+(Q) = \u2205 which is a contradiction to the assumption that Q is a query.\nAd 3.: By Definition 1 which states that {consistency} \u2286 R and by Definitions 4 and 2, every K\u2217i constructed from some Di \u2208 D satisfies all r \u2208 R. As E is a set of common entailments of some subset of {K\u2217i | Di \u2208 D} and Q \u2286 E, the proposition follows.\nRemark 9 Proposition 43 emphasizes the importance of a systematic tool-assisted construction of queries, i.e. as a set of common entailments of all KBs in {K\u2217i | Di \u2208 D+}, rather than asking the user some axioms or entailments intuitively. Such a guessing of queries could provoke asking a useless \u201cquery\u201d that does not yield invalidation of any diagnoses, thus increasing user effort unnecessarily.\nThe next proposition demonstrates a way of reducing a given query in size under preservation of the associated q-partition which means that all information-theoretic properties of the query \u2013 in particular, the value that each measure discussed in Section 3.2 assigns to it \u2013 will remain unaffected by the modification. The smaller the cardinality of a query, the lower the effort for the answering user usually is. Concretely, and complementary to the first statement (1.) of Proposition 43 (which says that the entailment of at least one element of the query must depend on axioms in UD), Proposition 44 asserts that a query does not need to include any elements whose entailment does not depend on UD.\nProposition 44. Let D \u2286 mD\u3008K,B,P,N \u3009R with |D| \u2265 2 and Q \u2208 QD be a query with q-partition P(Q) = \u3008D+(Q),D\u2212(Q), \u2205\u3009. Then\nQ\u2032 := {ax | ax \u2208 Q,\u2200J \u2208 Just(ax ,K \u222a B \u222a UP ) : J \u2229 UD 6= \u2205} \u2286 Q\nis a query in QD with q-partition P(Q\u2032) = P(Q).\nProof. If Q\u2032 = Q then the validity of the statement is trivial. Otherwise, Q\u2032 \u2282 Q and for each sentence ax such that ax \u2208 Q, ax /\u2208 Q\u2032 there is at least one justification J \u2032 \u2208 Just(ax ,K \u222a B \u222a UP ) with J \u2032 \u2229UD = \u2205. So, by Lemma 1 it is true that J \u2032 \u2286 (K\\UD)\u222aB\u222aUP . Hence, (K\\UD)\u222aB\u222aUP |= ax must hold. As K\u2217i \u2287 (K \\ UD) \u222a B \u222a UP for all Di \u2208 D, it holds by monotonicity of L that K\u2217i |= ax .\nIn order for P(Q\u2032) 6= P(Q) to hold, either D+(Q\u2032) \u2282 D+(Q) or D\u2212(Q\u2032) \u2282 D\u2212(Q) must be true. However, the elimination of ax from Q does not involve the elimination of any diagnosis from D+(Q) since, for all Di \u2208 D, if K\u2217i |= Q then, in particular, K\u2217i |= Q\u2032 since Q\u2032 \u2286 Q.\nAlso, no diagnosis can be eliminated from D\u2212(Q). To see this, suppose that some Dk is an element of D\u2212(Q), but not an element of D\u2212(Q\u2032). From the latter fact we can conclude that K\u2217k \u222a Q\u2032 satisfies all r \u2208 R as well as all negative test cases n \u2208 N . Now, due to the fact that the entailment relation is idempotent for L and because K\u2217k |= ax for all ax \u2208 Q \\ Q\u2032 as shown above, we can deduce that\nK\u2217k\u222aQ = K\u2217k\u222aQ\u2032\u222a (Q\\Q\u2032) is logically equivalent toK\u2217k\u222aQ\u2032. This is a contradiction to the assumption that Dk is an element of D\u2212(Q) since in this case K\u2217k \u222a Q must violate some r \u2208 R or n \u2208 N . This completes the proof.\nThe Discrimination Axioms. As the previous two propositions suggest, the key axioms in the faulty KB K of a DPI in terms of query generation are given by UD as well as ID. These will also have a principal role in the specification of canonical queries. We examine this role next.\nLemma 2. For any DPI \u3008K,B,P ,N \u3009R and D \u2286 mD\u3008K,B,P,N \u3009R it holds that no KB in {K\u2217i | Di \u2208 D} includes a justification for any axiom in ID. That is, for all ax \u2208 ID there is no J \u2208 \u22c3 Di\u2208D Just(ax ,K \u2217 i ).\nProof. Assume that there is an axiom ax \u2208 ID and some J \u2208 Just(ax ,K\u2217k) for some Dk \u2208 D. Then, K\u2217k |= ax . Since ax \u2208 ID = \u22c2 Di\u2208DDi we can conclude that ax \u2208 Dk. Since K \u2217 k = (K \\Dk)\u222aB \u222aUP meets all requirements r \u2208 R and all negative test cases n \u2208 N , this must also hold for (K\\ (Dk \\ax ))\u222a B \u222a UP . But this is a contradiction to the subset-minimality of Dk \u2208mD\u3008K,B,P,N \u3009R .\nThe latter lemma means that each minimal diagnosis among the leading diagnoses D must hit every justification of every axiom in ID. That is, no matter which D+(Q) \u2286 D we select for the computation of a queryQ (as a subset of the common entailments of KBsK\u2217i forDi \u2208 D+(Q)),Q can never comprise an axiom of ID. Of course, this holds in particular for explicit-entailments queries and is captured by the following proposition:\nProposition 45. Let \u3008K,B,P ,N \u3009R be any DPI, D \u2286mD\u3008K,B,P,N \u3009R and Q be any query in QD. Then Q \u2229 ID = \u2205.\nProof. The proposition follows immediately from Lemma 2 and the fact that Q \u2286 E where E is a set of common entailments of some subset of KBs in {K\u2217i | Di \u2208 D}.\nThe next finding is that any explicit-entailments query must comprise some axiom(s) from UD.\nProposition 46. Let \u3008K,B,P ,N \u3009R be any DPI, D \u2286mD\u3008K,B,P,N \u3009R and Q be any explicit-entailments query in QD. Then Q \u2229 UD 6= \u2205.\nProof. Suppose that Q is an explicit-entailments query in QD and Q \u2229 UD = \u2205. Then Q \u2286 K. Further, since K\u2217i \u2283 K \\ Di \u2283 K \\ UD \u2287 Q and by the monotonicity of L, we can deduce that K\u2217i |= Q for all Di \u2208 D. Therefore, D+(Q) = D and D\u2212(Q) = \u2205 which contradicts the assumption that Q is a query.\nNow, we can summarize these results for explicit-entailments queries as follows:\nCorollary 19. Let \u3008K,B,P ,N \u3009R be any DPI, D \u2286 mD\u3008K,B,P,N \u3009R and Q be any explicit-entailments query in QD. Then Q\n\u2022 must include some axiom(s) in UD,\n\u2022 need not include any axioms in K \\ UD, and\n\u2022 must not include any axioms in ID.\nFurther on, elimination of axioms in K \\ UD from Q does not affect the q-partition P(Q) of Q.\nDue to this result which implies that Q\u2032 := Q \u2229 (UD \\ ID) is a query equivalent to Q in terms of the q-partition for any explicit-entailments query Q, we now give the set UD \\ ID the specific denotation DiscAxD. We term this set the discrimination axioms w.r.t. the leading diagnoses D. These are precisely the essential axioms facilitating discrimination between the leading diagnoses.\nWe are now in the state to formally define a canonical query. To this end, let Eexp(X) denote all common explicit entailments of all elements of the set {K \\ Di | Di \u2208 X} for some set X of minimal diagnoses w.r.t. \u3008K,B,P ,N \u3009R. Then:\nProposition 47. For Eexp(D+(Q)), the following statements are true:\n1. Eexp(D+(Q)) = K \\ UD+(Q).\n2. Eexp(D+(Q)) \u2229 ID = \u2205.\nProof. Ad 1.: \"\u2286\": Clearly, each common explicit entailment of {K \\ Di | Di \u2208 D+(Q)} must be in K. Furthermore, Lemma 3 (see below) applied to K\u2217i for Di \u2208 D+(Q) yields K\u2217i 6|= ax for each ax \u2208 Di. By monotonicity of L, this is also valid for K \\ Di. Since UD+(Q) is exactly the set of axioms that occur in at least one diagnosis in D+(Q), no axiom in this set can be a common (explicit) entailment of all KBs in {K \\ Di | Di \u2208 D+(Q)}. Consequently, each common explicit entailment of {K \\ Di | Di \u2208 D+(Q)} must be in K \\ UD+(Q).\n\"\u2287\": All axioms in K \\UD+(Q) occur in each K \\Di for Di \u2208 D+(Q) and are therefore entailed by each K \\ Di due to that fact that the entailment relation in L is extensive.\nAd 2.: Since clearly ID \u2286 UD and, by (1.), Eexp(D+(Q)) = K\\UD+(Q), the proposition follows by the fact that ID \u2286 UD+(Q). The latter holds because all axioms that occur in all diagnoses in D (i.e. the axioms in ID) must also occur in all diagnoses in D+(Q) (i.e. in UD+(Q)) since D+(Q) \u2286 D.\nLemma 3. Let \u3008K,B,P ,N \u3009R be a DPI and D \u2286 mD\u3008K,B,P,N \u3009R . Then, for each Di \u2208 D and for each ax \u2208 Di it holds that K\u2217i 6|= ax .\nProof. Let us assume that K\u2217i |= ax for some ax \u2208 Di for some Di \u2208 D. Then, by the fact that the entailment relation inL is idempotent,K\u2217i \u222aax \u2261 K\u2217i . ButK\u2217i \u222aax \u2261 (K\\(Di\\{ax}))\u222aB\u222aUP . SinceK\u2217i satisfies all negative test cases n \u2208 N as well as all requirements r \u2208 R, (K\\ (Di \\{ax}))\u222aB\u222aUP must do so as well, wherefore Di \\ {ax} is a diagnosis w.r.t. \u3008K,B,P ,N \u3009R. This however is a contradiction to the assumption thatDi \u2208mD\u3008K,B,P,N \u3009R , i.e. thatDi is a minimal diagnosis w.r.t. \u3008K,B,P ,N \u3009R.\nRoughly, a canonical query is an explicit-entailments query that has been reduced as per Corollary 19.\nDefinition 16 (Canonical Query). Let \u3008K,B,P ,N \u3009R be a DPI, D \u2286 mD\u3008K,B,P,N \u3009R with |D| \u2265 2. Let further \u2205 \u2282 S \u2282 D be a seed set of minimal diagnoses. Then we call Qcan(S) := Eexp(S) \u2229 DiscAxD the canonical query w.r.t. S if Qcan(S) 6= \u2205. Otherwise, Qcan(S) is undefined.\nIt is trivial to see that:\nProposition 48. If existent, the canonical query w.r.t. S is unique.\nA canonical q-partition is a q-partition for which there is a canonical query with exactly this qpartition:\nDefinition 17 (Canonical Q-Partition). Let \u3008K,B,P ,N \u3009R be a DPI, D \u2286mD\u3008K,B,P,N \u3009R with |D| \u2265 2. Let further P = \u3008D+,D\u2212, \u2205\u3009 be a q-partition w.r.t. D. Then we call P a canonical q-partition iff P = P(Qcan(D\n+)), i.e. \u3008D+,D\u2212, \u2205\u3009 = \u3008D+(Qcan(D+)),D\u2212(Qcan(D+)), \u2205\u3009. In other words, given the q-partition \u3008D+,D\u2212, \u2205\u3009, the canonical query w.r.t. the seed D+ must lead exactly to the associated q-partition \u3008D+,D\u2212, \u2205\u3009.\nNow it is very easy to verify that there is a one-to-one relationship between canonical q-partitions and canonical queries:\nProposition 49. Given a canonical q-partition, there is exactly one canonical query associated with it and vice versa.\nSo, for a q-partition \u3008D+(Q),D\u2212(Q), \u2205\u3009we can use the canonical queryEexp(D+(Q))\u2229DiscAxD as a standardized representation of an associated query during the search for an optimal q-partition. Stated differently, the search strategy proposed in this work will consider solely canonical q-partitions and will use a successor function based on canonical queries that computes in each node expansion step in the search tree (all and only) canonical q-partitions that result from a given canonical q-partition by minimal changes.\nMoreover, it is easy to see that the following must be valid:\nProposition 50. Any canonical q-partition \u3008D+,D\u2212,D0\u3009 satisfies D0 = \u2205.\nProof. By Definition 17, for each canonical q-partition P there is a canonical query Q for which P is the q-partition associated with Q. Further on, by Definition 16, Q := Eexp(S) \u2229 DiscAxD \u2286 K for some \u2205 \u2282 S \u2282 D. Since Q \u2286 K, Proposition 42 yields that D0(Q) = \u2205 must hold.\nLet us at this point discuss a small example that should illustrate the introduced notions:\nExample 17 Consider the DPI \u3008K,B,P ,N \u3009R defined by Table 10. Denoting KB axioms ax i simply by i, then w.r.t. this DPI, the set of minimal conflict sets (justifications for the negative test case n1 \u2208 N )\nmC\u3008K,B,P,N \u3009R = {\u30081, 3\u3009 , \u30081, 4\u3009 , \u30082, 3\u3009 , \u30085\u3009} and the set of minimal diagnoses (minimal hitting sets of mC\u3008K,B,P,N \u3009R ) mD\u3008K,B,P,N \u3009R = {D1,D2,D3} = {[1, 2, 5], [1, 3, 5], [3, 4, 5]}. The potential solution KBs are {K\u22171,K\u22172,K\u22173} where K\u22171 = {3, 4}, K\u22172 = {2, 4} and K\u22173 = {1, 2}. The discrimination axioms DiscAxD for D := mD\u3008K,B,P,N \u3009R are UD \\ ID = {1, 2, 3, 4, 5} \\ {5} = {1, 2, 3, 4}. Table 11 lists all possible seeds S (i.e. proper non-empty subsets of D) and, if existent, the respective (unique) canonical query Qcan(S) as well as the associated (unique) canonical q-partition. Note that there is no canonical query, and thus no canonical q-partition, for the seed S = {D1,D3}. This holds since (by Proposition 47) Eexp(S) = (K \\ D1) \u2229 (K \\ D3) = K \\ US = {1, 2, 3, 4, 5} \\ ({1, 2, 5} \u222a {3, 4, 5}) = \u2205 wherefore (by Definition 16) Qcan(S) = \u2205. Additionally, we point out that there is no query (and hence no q-partition) for which D+ corresponds to {D1,D3} because for this to hold there must be a common entailment of K\u22171 = {3, 4} and K\u22173 = {1, 2} which clearly does not exist (insofar as tautologies are excluded from the entailment types that are computed, which is always our assumption). So, obviously, in this example every q-partition is canonical."}, {"heading": "3.4.2 Search Completeness Using Only Canonical Q-Partitions", "text": "Now, in the light of the previous example, the question arises whether a q-partition can exist which is not canonical. If yes, which properties must this q-partition have? Answering these questions means at the same time answering the question whether the search for q-partitions taking into account only canonical q-partitions is complete.\nUnfortunately, we are not (yet) in the state to give a definite answer to these questions. Actually, we did not yet manage to come up with a counterexample witnessing the incompleteness of the search for q-partitions that takes into consideration only canonical q-partitions. But, we are in the state to give numerous precise properties such non-canonical q-partitions must meet, if they do exist. This is what we present next.\nTo this end, we assume that P(Q) = \u3008D+(Q),D\u2212(Q), \u2205\u3009 is a q-partition w.r.t. some set of leading diagnoses D \u2286mD\u3008K,B,P,N \u3009R (|D| \u2265 2) w.r.t. some DPI \u3008K,B,P ,N \u3009R, but not a canonical one. From this we can directly deduce that Q must be a query w.r.t. D and \u3008K,B,P ,N \u3009R, but there cannot be a canonical query with associated q-partition P(Q). Hence, by Definition 17, either\n(a) Qcan(D+(Q)) is not defined, i.e. Eexp(D+(Q)) \u2229 DiscAxD = \u2205 (see Definition 16), or\n(b) Qcan(D+(Q)) is defined, but \u3008D+(Qcan(S)),D\u2212(Qcan(S)), \u2205\u3009 6= \u3008D+(Q),D\u2212(Q), \u2205\u3009 for all S such that \u2205 \u2282 S \u2282 D for D \u2286mD\u3008K,B,P,N \u3009R\nholds. Concerning Case (a), we want to emphasize that (the explicit-entailments query)Qcan(D+(Q)) might be the empty set in spite of Proposition 43,(1.) which states that there must necessarily be one sentence in a query, each justification of which includes an axiom in UD. The reason why Qcan(D+(Q)) = \u2205 is still possible is that all these justifications do not necessarily comprise at least one identical axiom in UD. That is to say that Q might be a query in spite of Qcan(D+(Q)) being the empty set.\nThe occurrence of Case (b) is possible since Q might include entailments which are not entailed by Eexp(D\n+(Q)) = K \\ UD+(Q) and thence not by Qcan(D+(Q)) = Eexp(D+(Q)) \u2229 DiscAxD either. In this case, D\u2212(Qcan(D+(Q))) \u2282 D\u2212(Q) and D+(Qcan(D+(Q))) \u2283 D+(Q) would need to hold.\nFor these two cases to arise, however, plenty of sophisticated conditions must apply, as shown by the next Proposition. Therefore, the occurrence of this situation can be rated rather unlikely.\nProposition 51. Case (a), i.e. that Qcan(D+(Q)) is not defined, can only arise if:\n1. UD+(Q) = UD (which holds only if |D+(Q)| \u2265 2), and\n2. Q includes some implicit entailment, and\n3. For each diagnosis Dj \u2208 D\u2212(Q) there is a set of sentences Sj such that\n\u2022 Sj \u2286 Q and \u2022 K\u2217i |= Sj for all Di \u2208 D+(Q) and \u2022 K\u2217j \u222a Sj violates some requirement r \u2208 R or some test case n \u2208 N .\nFor a set Sj as in (3.) to exist, it must be fulfilled that\n3.1 for all Di \u2208 D+(Q) there is a justification J \u2208 Just(Sj ,K\u2217i ), and\n3.2 for all consistent justifications J \u2208 Just(Sj ,K \u222a B \u222a UP ) it is true that J \u2229 Dj 6= \u2205, and\n3.3 for each axiom ax \u2208 Dj there is some k \u2208 {i | Di \u2208 D+(Q)} such that for all J \u2208 Just(Sj ,K\u2217k) the property ax /\u2208 J holds.\nProof. Ad 1.: Assume the opposite, i.e. UD+(Q) 6= UD, which implies UD+(Q) \u2282 UD since D+(Q) \u2282 D. Additionally, suppose Case (a) occurs. Now, by Proposition 47, Eexp(D+(Q)) = K \\ UD+(Q) includes an axiom ax \u2208 DiscAxD = UD \\ ID. This is true since axioms in UD \\UD+(Q) \u2286 K \\UD+(Q) are obviously in UD, but not in ID as otherwise they would need to appear in each D \u2208 D+(Q) and thus in UD+(Q), contradicting the fact that these axioms are in UD \\ UD+(Q). Hence, Qcan(D+(Q)) = Eexp(D\n+(Q)) \u2229 DiscAxD \u2287 {ax} \u2283 \u2205. We now show that UD+(Q) = UD can only hold if |D+(Q)| \u2265 2. This must be true, as the assumption of the opposite, i.e. |D+(Q)| = 1 or equivalently D+(Q) = {D} leads to D = UD. Since \u3008D+(Q),D\u2212(Q), \u2205\u3009 is a q-partition, D\u2212(Q) 6= \u2205. Thence, D \u2287 D\u2032 must hold for all D\u2032 \u2208 D\u2212(Q). Since D\u2032 6= D must hold (due to D+(Q) \u2229D\u2212(Q) = \u2205 by Proposition 3.(1.)), this is a contradiction to the subset-minimality of all diagnoses in D.\nAd 2.: Let Case (a) occur and let Q include only explicit entailments. Then Q \u2286 Eexp(D+(Q)). However, as, by occurrence of Case (a), Qcan(D+(Q)) := Eexp(D+(Q))\u2229DiscAxD = Eexp(D+(Q))\u2229 (UD \\ ID) = \u2205 holds, and, by Proposition 47,(2.), we know that Eexp(D+(Q)) \u2229 ID = \u2205, we have that Q \u2229 UD = \u2205 and thence Q \u2286 (K \\ UD) \u222a B \u222a UP . So, by the fact that the entailment relation in L is extensive, (K \\ UD) \u222a B \u222a UP |= Q. This, however, constitutes a contradiction to Q being a query by Proposition 43,(1.) because all sentences in Q are entailed by (K \\ UD) \u222a B \u222a UP , wherefore there is a justification J \u2208 Just(ax ,K \u222a B \u222a UP ) for each sentence in Q such that J \u2229 UD = \u2205.\nAd 3.: The proposition is a direct consequence of Definition 8. Therefore, what we have to show is that (3.1) \u2013 (3.3) are necessary consequences of (3.). To this end, assume that Case (a) is given.\nAd 3.1: This is obviously true by Definition 15 and since K\u2217i |= Sj for all Di \u2208 D+(Q). Ad 3.2: Assume that there is some consistent justification J \u2208 Just(Sj ,K \u222a B \u222a UP ) such that J \u2229 Dj = \u2205. Then J \u2286 K\u2217j wherefore K\u2217j |= Sj . Due to the property of the entailment relation in L to be idempotent, we have that K\u2217j \u222a Sj \u2261 K\u2217j . As K\u2217j does not violate any requirement r \u2208 R or test case n \u2208 N by the fact that Dj is a diagnosis, it holds that K\u2217j \u222a Sj does not do so either. But this is a contradiction to (3.).\nAd 3.3: Assume that there is some axiom ax \u2208 Dj such that for all k \u2208 {i | Di \u2208 D+(Q)} there is some J \u2208 Just(Sj ,K\u2217k) with the property ax \u2208 J . This means that ax \u2208 K\u2217k for all k \u2208 {i | Di \u2208 D+(Q)}. Hence, ax /\u2208 Dk for all k \u2208 {i | Di \u2208 D+(Q)} which implies that ax /\u2208 UD+(Q). But, ax \u2208 Dj wherefore ax \u2208 UD. This is a contradiction to (1.) which asserts that UD = UD+(Q).\nTo summarize this, Condition (2.) postulates some non-explicit entailment(s) in Q. Condition (3.1) means that either one and the same justification for Sj must be a subset of \u2013 by Condition (1.), multiple \u2013 different KBs or there must be \u2013 by Condition (1.) \u2013 multiple justifications for Sj . Condition (3.2), on the\nother hand, postulates the presence of some axiom(s) of a specific set Dj in every justification for Sj , and Condition (3.3) means that not all justifications for Sj are allowed to comprise one and the same axiom from the specific set Dj . And all these conditions must apply for |D\u2212(Q)| different sets Sj .\nProposition 52. Case (b), i.e. that \u3008D+(Qcan(S)),D\u2212(Qcan(S)), \u2205\u3009 6= \u3008D+(Q),D\u2212(Q), \u2205\u3009 for all seeds \u2205 \u2282 S \u2282 D for D \u2286mD\u3008K,B,P,N \u3009R , can only arise if:\n1. Q includes some implicit entailment, and 2. Q includes some (implicit) entailment which is not an entailment of \u22c2 {i | Di\u2208D+(Q)}K \u2217 i (which is\ntrue only if |D+(Q)| \u2265 2) and\n3. D+(Qcan(D+(Q))) \u2283 D+(Q) and D\u2212(Qcan(D+(Q))) \u2282 D\u2212(Q), and\n4. J is not a conflict w.r.t. \u3008K,B,P ,N \u3009R for all J \u2208 \u22c3 {i | Di\u2208D+(Q)} Just(Q,K \u2217 i ), and\n5. there is some Dm \u2208 D\u2212(Q) such that:\n(a) Dm \u2282 UD+(Q), and (b) (UD+(Q) \\ Dm) \u2229 C 6= \u2205 for all (minimal) conflicts C w.r.t. \u3008K \\ Dm,B,P \u222a {Q} ,N \u3009R, and (c) J \u2229 Dm 6= \u2205 for all J \u2208 \u22c3 {i | Di\u2208D+(Q)} Just(Q,K \u2217 i ).\nProof. Ad 1.: Let us denote by \u2329 D+1 ,D \u2212 1 , \u2205 \u232a an arbitrary q-partition for some query Q w.r.t. D and \u3008K,B,P ,N \u3009R. Assume that Q consists of only explicit entailments. Then, Q \u2286 K \u222a B \u222a UP . Since Q is a set of common entailments of all KBs in { K\u2217i | Di \u2208 D + 1 } (cf. Proposition 3,(4.)), we have that Q \u2286 (K \\ UD+1 ) \u222a B \u222a UP . Moreover, by Proposition 44 and Corollary 19, we can conclude that the deletion of all axioms in B\u222aUP as well as all axioms not in DiscAxD fromQ does not alter the q-partition associated with Q. Now, we have to distinguish two cases:\n(i) Q = K \\ UD+1 \u2229 DiscAxD = Eexp(D + 1 ) \u2229 DiscAxD and\n(ii) Q \u2282 (K \\ UD+1 ) \u2229 DiscAxD = Eexp(D + 1 ) \u2229 DiscAxD.\nIn the first case (i), since, by Definition 16, Eexp(D+1 ) \u2229 DiscAxD = Qcan(D + 1 ), we observe that Q is equal to the canonical query w.r.t. the non-empty seed S := D+1 \u2282 D which lets us immediately conclude that Qcan(S) has the same q-partition as Q \u2013 contradiction.\nIn the second case (ii), we can exploit Proposition 56 (which we state and prove later) which gives a lower and upper bound (in terms of subset relationships) for explicit-entailments queries Q\u2032 \u2286 DiscAxD. Concretely, given a query Q\u2032\u2032 \u2286 DiscAxD with associated q-partition \u3008D+,D\u2212, \u2205\u3009 (which partitions D) it states that Q\u2032 \u2286 DiscAxD is a query associated with this q-partition iff Q\u2032 is a superset or equal to a minimal hitting set of all elements in D\u2212 and a subset or equal to Eexp(D+) \u2229 DiscAxD =: Qcan(D+). Now, what we know by the assumption of case (ii) is thatQ \u2282 Eexp(D+(Q))\u2229DiscAxD \u2286 DiscAxD and that \u2329 D+1 ,D \u2212 1 , \u2205 \u232a is the q-partition associated with Q. By Proposition 56, we can now deduce, as long as\nthere is a minimal hitting set of D\u22121 which is a subset of Q, that \u2329 D+1 ,D \u2212 1 , \u2205 \u232a is also the q-partition for Qcan(D + 1 ). Therefore, we have found a non-empty seed S := D + 1 \u2282 D such that Qcan(S) has the same q-partition as Q \u2013 contradiction. What remains open is the case when there is no minimal hitting set of D\u22121 which is a subset of Q. This is equivalent to Q being no hitting set of D\u22121 . Let w.l.o.g. D1, . . . ,Dk (k \u2265 1) be the diagnoses in D\u2212 that have an empty set intersection with Q. Then, since Q \u2282 Eexp(D+1 ) \u2229 DiscAxD \u2286 K and D1, . . . ,Dk \u2286 K, we have that Q \u2286 K \\ Dr for all r \u2208 {1, . . . , k}. Therefore, K\u2217r |= Q for all r \u2208 {1, . . . , k} and thus {D1, . . . ,Dk} \u2286 D+1 (cf. Definition 8). However, this is a contradiction to the\nassumption that \u2329 D+1 ,D \u2212 1 , \u2205 \u232a is the q-partition associated with Q. The reason is that every q-partition must be a partition of D (Proposition 3,(1.)) and D+1 has no empty set intersection with D \u2212 1 because of \u2205 \u2282 {D1, . . . ,Dk} \u2286 D+1 \u2229D \u2212 1 .\nAd 2.: Suppose that Q includes only entailments of \u22c2 {i | Di\u2208D+(Q)}K \u2217 i . It is easy to derive that\u22c2\n{i | Di\u2208D+(Q)}K \u2217 i = (K \\ UD+(Q)) \u222a B \u222a UP . By Proposition 44 and Corollary 19, the deletion of all axioms in B \u222a UP as well as all axioms not in DiscAxD from Q does not alter the q-partition associated withQ. Hence, the query equal toK\\UD+(Q)\u2229DiscAxD = Eexp(D+(Q))\u2229DiscAxD = Qcan(D+(Q)) has the same q-partition as Q, wherefore we have found a non-empty seed S := D+(Q) \u2282 D for which \u3008D+(Qcan(S)),D\u2212(Qcan(S)), \u2205\u3009 = \u3008D+(Q),D\u2212(Q), \u2205\u3009, which is a contradiction.\nNow we show that (2.) can only be true if |D+(Q)| \u2265 2. For, the assumption of the opposite, i.e. |D+(Q)| = 1 or equivalently D+(Q) = {Di}, means that Q must not include an entailment of K\u2217i . However, as Q 6= \u2205 (Definition 7) and Q is a subset of the entailments of K\u2217i (Proposition 3,(4.)). This is a contradiction.\nAd 3.: Let us assume that D+(Qcan(D+(Q))) \u2286 D+(Q). Then, either D+(Qcan(D+(Q))) = D+(Q) or D+(Qcan(D+(Q))) \u2282 D+(Q). In the former case, we directly obtain a contradiction since clearly \u3008D+(Qcan(S)),D\u2212(Qcan(S)), \u2205\u3009 = \u3008D+(Q),D\u2212(Q), \u2205\u3009 for the non-empty seed S := D+(Q) \u2282 D. In the latter case, there is some Di \u2208 D+(Q) \\ D+(Qcan(D+(Q))). Since D0(Q) is assumed to be the empty set and since Qcan(D+(Q)) is an explicit-entailments query which must satisfy D0(Qcan(D+(Q))) = \u2205 by Proposition 42, Di \u2208 D\u2212(Qcan(D+(Q))) must hold. This implies that K\u2217i \u222aQcan(D+(Q)) violates some x \u2208 R\u222aN . But, asDi \u2208 D+(Q) and as the entailment relation in L is extensive, we must also have thatK\u2217i = (K\\Di)\u222aB\u222aUP \u2287 (K\\UD+(Q))\u222aB\u222aUP \u2287 (K\\UD+(Q)) \u2287 (K \\ UD+(Q)) \u2229 DiscAxD = Eexp(D+(Q)) \u2229 DiscAxD = Qcan(D+(Q)) |= Qcan(D+(Q)). By idempotence of the entailment relation in L, we obtain that K\u2217i \u222a Qcan(D+(Q)) \u2261 K\u2217i . Altogether, we have derived that K\u2217i violates some x \u2208 R \u222a N which is a contradiction to Di being a diagnosis w.r.t. \u3008K,B,P ,N \u3009R.\nAd 4.: Assume that J\u2217 is a conflict w.r.t. \u3008K,B,P ,N \u3009R for some J\u2217 \u2208 \u22c3 {i | Di\u2208D+(Q)} Just(Q,K \u2217 i ). However, for J\u2217, by Definition 15, J\u2217 \u2286 K\u2217i\u2217 must hold for some i\u2217 \u2208 {i | Di \u2208 D+(Q)}. Due to the fact that Di\u2217 is a diagnosis w.r.t. \u3008K,B,P ,N \u3009R, we see (by Propositions 1 and 2) that K\u2217i\u2217 cannot comprise any conflict sets w.r.t. \u3008K,B,P ,N \u3009R. Hence, J\u2217 cannot be a conflict set w.r.t. \u3008K,B,P ,N \u3009R.\nAd 5.(a): Assume thatDm 6\u2282 UD+(Q) for allDm \u2208 D\u2212(Q). Then, for allDm \u2208 D\u2212(Q), there is one axiom axm \u2208 Dm such that axm /\u2208 UD+(Q). Additionally, axm /\u2208 D for at least one D \u2208 D+(Q) (as otherwise axm \u2208 UD+(Q) would be true), i.e. axm /\u2208 ID, and axm \u2208 UD since axm \u2208 Dm with Dm \u2208 D. So, axm \u2208 DiscAxD must be valid. Because ofQcan(D+(Q)) = (K\\UD+(Q))\u2229DiscAxD, we obtain that axm \u2208 Qcan(D+(Q)). Therefore, for all Dm \u2208 D\u2212(Q), it must be true that K\u2217m \u222a Qcan(D+(Q)) violates some x \u2208 R\u222aN by the subset-minimality of the diagnosesDm \u2208 D\u2212(Q). Consequently,Dm \u2208 D\u2212(Qcan(D\n+(Q))) for all Dm \u2208 D\u2212(Q) which implies that D\u2212(Qcan(D+(Q))) = D\u2212(Q). Hence, (cf. argumentation in the proof of (3.) before) also D+(Qcan(D+(Q))) = D+(Q). This, however, means that we have found a non-empty seed S := D+(Q) \u2282 D for which \u3008D+(Qcan(S)),D\u2212(Qcan(S)), \u2205\u3009 = \u3008D+(Q),D\u2212(Q), \u2205\u3009, which is a contradiction.\nAd 5.(b): By (5.(a)), we know that there is some Dm \u2208 D\u2212(Q) such that Dm \u2282 UD+(Q). Since Dm \u2208 D\u2212(Q), it holds that K\u2217m \u222aQ violates some x \u2208 R \u222a N . Further on, as K\u2217i \u222aQ does not violate any x \u2208 R\u222aN for allDi \u2208 D+(Q), we can derive by the monotonicity of L that (K\\UD+(Q))\u222aB\u222aUP cannot violate any x \u2208 R \u222a N either. A conflict set C w.r.t. \u3008K \\ Dm,B,P \u222a {Q} ,N \u3009R is a subset of K \\ Dm such that Cm \u222a B \u222a UP \u222aQ violates some x \u2208 R \u222aN . Because of the fact that Dm \u2282 UD+(Q), we have that K\u2217m \u222a Q \u2283 (K \\ UD+(Q)) \u222a B \u222a UP . The set difference of these two sets is then exactly UD+(Q) \\ Dm. As the smaller set does not contain any conflicts whereas the larger set does so, we can conclude that each conflict set for the larger set, i.e. each conflict set C w.r.t. \u3008K \\Dm,B,P \u222a{Q} ,N \u3009R, must contain at least one axiom in UD+(Q) \\ Dm.\nAd 5.(c): Assume that J \u2229 Dm = \u2205 for some J \u2208 \u22c3 {i | Di\u2208D+(Q)} Just(Q,K \u2217 i ). That is, there is\nsome i\u2217 \u2208 {i | Di \u2208 D+(Q)} such that J \u2208 Just(Q,K\u2217i\u2217). Since however J \u2229 Dm = \u2205, we can deduce (cf. Lemma 1) that J \u2286 (K\u2217i\u2217 \\ Dm) = [(K \\ Di\u2217) \u222a B \u222a UP ] \\ Dm = (K \\ (Di\u2217 \u222a Dm)) \u222a B \u222a UP \u2286 (K \\ Dm) \u222a B \u222a UP = K\u2217m. So, by monotonicity of L, we have that K\u2217m |= Q. On the other hand, Dm \u2208 D\u2212(Q) implies that K\u2217m \u222a Q violates some x \u2208 R \u222a N . Since the entailment relation in L is idempotent, it is thus true that K\u2217m \u222aQ \u2261 K\u2217m. This yields that K\u2217m violates some x \u2208 R \u222aN which is a contradiction to the fact that Dm is a diagnosis w.r.t. \u3008K,B,P ,N \u3009R.\nWe want to point out that the non-fulfillment of both some criterion given by Proposition 51 and some criterion given by Proposition 52 leads to the impossibility of any q-partitions that are not canonical.\nFor instance, a comprehensive study [6] on entailments and justifications dealing with a large corpus of real-world KBs (ontologies) from the Bioportal Repository14 reveals that the probability for a q-partition to be non-canonical can be rated pretty low in the light of the sophisticated requirements enumerated by Propositions 51 and 52. In particular, the study showed that\n(i) only one third, precisely 72 of 214, of the KBs featured so-called non-trivial entailments.\nA logical sentence \u03b1 with K |= \u03b1 is a non-trivial entailment of the KB K iff K \\ {\u03b1} |= \u03b1, i.e. \u03b1 is either not explicitly stated as KB axiom or is still entailed by the KB after having been deleted from it. In other words, an entailment \u03b1 is non-trivial iff there is at least one justification for \u03b1 that does not include \u03b1. Note that an implicit entailment as per our definition is always a non-trivial entailment since it is not an axiom in the KB. Consequently, one third of the Bioportal KBs did not exhibit non-explicit entailments. By Condition (2.) of Proposition 51 as well as Condition (1.) of Proposition 52, there cannot be any non-canonical q-partitions in such a KB. Further on, the study unveiled that\n(ii) in more than a third (25) of the remaining 72 KBs the average number of justifications per nontrivial entailment was lower than 2.\nSuch entailments, however, do not satisfy Condition (3.1) of Proposition 51, unless there is a single justification that is a subset of all KBs K\u2217i for Di \u2208 D+(Q). Furthermore, such entailments do not comply with Condition (2.) of Proposition 52. Additionally, it was reported that\n(iii) the average size of a justification for a non-trivial entailment was measured to be lower than 4 for 85% (61) and below 2 axioms for a good half (43) of the 72 KBs.\nOn average, a KB among those 72 had 10 645 axioms. Now, let us assume in such a KB a diagnosis Dj with |Dj | = 10 that \u2013 by Condition (3.2) of Proposition 51 \u2013 must be hit by every justification J for Sj . Then the probability for J with |J | = 4 and |J | = 2 to contain at least one axiom of Dj is roundly 0.004 and 0.002.15 Fulfillment of Condition (5.(c)) of Proposition 52 can be analyzed in a very similar way. Thus, the necessary conditions for non-canonical q-partitions will be hardly satisfied on average in this dataset of KBs.\nConsequently, albeit we might (in case non-canonical q-partitions do exist) give up perfect completeness of q-partition search by the restriction to only canonical q-partitions, we have argued based on one comprehensive real-world dataset of KBs that in practice there might be high probability that we might miss none or only very few q-partitions. We can cope well with that since canonical queries and q-partitions bring along nice computational properties. Moreover, given practical numbers of leading diagnoses per iteration, e.g. \u2248 10, cf. [27, 21], the number of canonical q-partitions considered this way will prove to be still large enough to identify (nearly) optimal q-partitions (and queries) for all discussed measures, as our preliminary experiments (still unpublished) suggest. Theoretical support for this is given e.g. by Corollary 22.\n14http://bioportal.bioontology.org 15The latter two values can be easily computed by means of the Hypergeometric Distribution as 1 \u2212 p(S = 0) where S \u223c Hypn,N,M measures the number of successes (number of \u201cgood ones\u201d) when drawing n elements from a set of N elements with M \u201cgood ones\u201d among the N . In that, p(S = s) = (M s )(N\u2212M n\u2212s ) / (N n ) . For the calculation of the two values, the parameters \u3008n,N,M\u3009 = \u30084, 10645, 10\u3009 and \u3008n,N,M\u3009 = \u30082, 10645, 10\u3009 are used."}, {"heading": "3.4.3 The Search for Q-Partitions", "text": "Overall Algorithm. We now turn to the specification of the search procedure for q-partitions. According to [23], a search problem can be described by giving the initial state, a successor function16 enumerating all direct neighbor states of a given state, the step/path costs from a given state to a successor state, some heuristics which should estimate the remaining effort (or: additional steps) towards a goal state from some given state, and the goal test which determines whether a given state is a goal state or not. In the case of our search for an optimal q-partition according to some query quality measure m (see Section 3.2), these parameters can be instantiated as follows:\n\u2022 Initial State. There are two natural candidates for initial states in our q-partition search, either \u3008\u2205,D, \u2205\u3009 or \u3008D, \u2205, \u2205\u3009. Note that both of these initial states are partitions of D, but no q-partitions \u2013 however, all other states in the search will be (canonical) q-partitions. These initial states induce two different searches, one starting from empty D+ which is successively filled up by transferring diagnoses from D\u2212 to D+, and the other conducting the same procedure with D+ and D\u2212\ninterchanged. We will call the former D+-partitioning and the latter D\u2212-partitioning search.\n\u2022 Successor Function. To specify a suitable successor function, we rely on the notion of a minimal transformation. In that, D+-partitioning and D\u2212-partitioning search will require slightly different characterizations of a minimal transformation:\nDefinition 18. Let D \u2286 mD\u3008K,B,P,N \u3009R , Pi := \u3008D + i ,D \u2212 i , \u2205\u3009 be a partition (not necessarily a q-partition) of D and Pj := \u3008D+j ,D \u2212 j , \u2205\u3009 be a canonical q-partition w.r.t. D such that \u3008D+j ,D \u2212 j , \u2205\u3009 6= \u3008D + i ,D \u2212 i , \u2205\u3009. Then, we call\n\u2013 Pi 7\u2192 Pj a minimal D+-transformation from Pi to Pj iff D+i \u2282 D + j and there is no\ncanonical q-partition \u3008D+k ,D \u2212 k , \u2205\u3009 such that D + i \u2282 D + k \u2282 D + j .\n\u2013 Pi 7\u2192 Pj a minimal D\u2212-transformation from Pi to Pj iff D\u2212i \u2282 D \u2212 j and there is no\ncanonical q-partition \u3008D+k ,D \u2212 k , \u2205\u3009 such that D \u2212 i \u2282 D \u2212 k \u2282 D \u2212 j .\nThe successor function then maps a given partition P w.r.t. D to the set of all its possible successors, i.e. to the set including all canonical q-partitions that result from P by a minimal transformation.\nThe reliance upon a minimal transformation guarantees that the search is complete w.r.t. canonical q-partitions because we cannot skip over any canonical q-partitions when transforming a state into a direct successor state. In the light of the initial states for D+- as well as D\u2212-partitioning being no q-partitions, the definition of the successor function involves specifying\n\u2013 a function Sinit that maps the initial state to the set of all canonical q-partitions that can be reached by it by a single minimal transformation, and\n\u2013 a function Snext that maps any canonical q-partition to the set of all canonical q-partitions that can be reached by it by a single minimal transformation\nAs D+- and D\u2212-partitioning require different successor functions, they must be treated separately. In this work, we restrict ourselves to D+-partitioning.\n\u2022 Path Costs / Heuristics. Since the step costs from one q-partition to a direct successor q-partition of it is of no relevance to our objective, which is finding a sufficiently \u201cgood\u201d q-partition, we do\n16For problems in which only the possible actions in a state, but not the results (i.e. neighbor states) of these actions are known, one might use a more general way of specifying the successor function. One such way is called transition model, see [23, p. 67]. For our purposes in this work, the notion of a successor function is sufficiently general.\nnot specify any step costs. In other words, we are not interested in the way how we constructed the optimal q-partition starting from the initial state, but only in the shape of the optimal q-partition as such. However, what we do introduce is some estimate of \u201cgoodness\u201d of q-partitions in terms of heuristics. These heuristics are dependent on the used query quality measure m and are specified based on the respective optimality criteria given by requirements rm (cf. Sections 3.2 and 3.3). We characterize these for all measures discussed in Section 3.2 in the procedure HEUR in Algorithm 7.\n\u2022 Goal Test. A canonical q-partition is considered as a goal state of the search iff it meets the requirements rm to a \u201csufficient degree\u201d. The latter is predefined in terms of some optimality threshold t . So, a state (canonical q-partition) is a goal if its \u201cdistance\u201d to optimality, i.e. perfect fulfillment of rm, is smaller than t (cf. [27]). The goal test for all measures discussed in Section 3.2 is described in Algorithm 5.\nThe overall search algorithm for finding a (sufficiently) optimal q-partition is presented by Algorithm 3. The inputs to the algorithm are a set D of leading minimal diagnoses w.r.t. the given DPI \u3008K,B,P ,N \u3009R, the requirements rm to an optimal q-partition, a threshold tm describing the distance from the theoretical optimum of rm (cf. Table 8) within which we still consider a value as optimal, and a probability measure p defined over the sample space D. The latter assigns a probability p(D) \u2208 (0, 1] to all D \u2208 D such that \u2211 D\u2208D p(D) = 1. To be precise, p(D) describes the probability that D is the true\ndiagnosis assuming that one diagnosis in D must be the correct one.17 Moreover, p(S) = \u2211 D\u2208S p(D) for any S \u2286 D. The output of the algorithm is a canonical q-partition that is optimal (as per rm) within the tolerance tm if such a q-partition exists, and the best (as per rm) among all canonical q-partitions w.r.t. D, otherwise.\nThe algorithm consists of a single call of D+PARTITION with forwarded arguments \u3008\u2205,D, \u2205\u3009, \u3008\u2205,D, \u2205\u3009, \u2205, p, tm, rm which initiates the recursive search procedure. The type of the implemented search can be regarded as a depth-first, \u201clocal best-first\u201d backtracking algorithm. Depth-first because, starting from the initial partition \u3008\u2205,D, \u2205\u3009 (or: root node), the search will proceed downwards until (a) an optimal canonical q-partition has been found, (b) all successors of the currently analyzed q-partition (or: node) have been pruned or (c) there are no successors of the currently analyzed q-partition (or: node). Local best-first because the search, at each current q-partition (or: node), moves on to the best successor q-partition (or: child node) as per some heuristics constructed based on rm. Backtracking because the search procedure is ready to backtrack in case all successors (or: children) of a q-partition (or: node) have been explored and no optimal canonical q-partition has been found yet. In this case, the next-best unexplored sibling of the node will be analyzed next according to the implemented local best-first depth-first strategy.\nD+PARTITION expects six arguments. The first, P, represents the currently analyzed q-partition or, equivalently, node in the search tree. The second, Pb, denotes the best q-partition (as per rm) that has been discovered so far during the search. The third, Dused, constitutes the set of diagnoses that must remain elements of the D\u2212-set, i.e. must not be moved to the D+-set, for all q-partitions generated as direct or indirect successors of P. The elements of Dused are exactly those diagnoses in D for which all existing canonical q-partitions Px with D+(Px) \u2287 Dused have already been explored so far, i.e. these diagnoses have already been used as elements of the D+-set. Hence, we do not want to add any of these to any D+-set of a generated q-partition anymore. The last three arguments p, tm as well as rm are explained above. We point out that only the first three arguments P, Pb and Dused vary throughout the entire execution of the search. All other parameters remain constant.\nThe first step within the D+PARTITION procedure (line 5) is the update of the best q-partition found so far. This is accomplished by the function UPDATEBEST (see Algorithm 4 on page 112) which returns the partition among {P,Pb}which is better w.r.t. rm. For some of the query quality measuresm, this will\n17For a more in-depth treatment of the diagnosis probability space and a discussion where such probabilities might originate from, see [20, Sec. 4.6]\nrequire calculations involving probabilities, which is why the parameter p is handed over to the function as well. After the execution of UPDATEBEST, the best currently known q-partition is stored in Pbest.\nThe next step (line 6) involves a check of Pbest for optimality w.r.t. the query quality requirements rm and the threshold tm and is realized by the function OPT (see Algorithm 5 on page 113). The latter returns true iff Pbest is an optimal q-partition w.r.t. rm and the threshold tm. If optimality of Pbest is given, then the most recent call to D+PARTITION returns (line 7) and passes back the tuple \u3008Pbest, true\u3009 to the one level higher point in the recursion where the call was made. The parameter true in this tuple is a flag that tells the caller of D+PARTITION that Pbest is already optimal an no further search activities are required.\nIn case optimality of Pbest is not satisfied, the procedure moves on to line 8 where a pruning test is executed, implemented by the function PRUNE (see Algorithm 6 on page 114). The latter, given the inputs P,Pbest, p and rm, evaluates to true if exploration of successor q-partitions of the currently analyzed qpartition P cannot lead to the detection of q-partitions that are better w.r.t. rm than Pbest. If the pruning test returns positively, the tuple \u3008Pbest, false\u3009 is returned, where false signalizes that Pbest is not optimal w.r.t. rm and tm.\nFacing a negative pruning test, the algorithm continues at line 10, where the function GETD+SUCS (see Algorithm 8 on page 116) is employed to generate and store in sucs all successors of the currently analyzed partition P which result from P by a minimal D+-transformation.\nGiven the set sucs of all direct successors, the algorithm enters the while-loop in order to examine all successors in turn. To this end, the algorithm is devised to select always the best not-yet-explored successor q-partition in sucs according to some heuristics based on rm. This selection is implemented by the function BESTSUC (see Algorithm 7 on page 115) in line 12 which gets P, sucs, p and rm as inputs. BESTSUC returns the best direct successor P\u2032 of P w.r.t. rm and one diagnosis D which is an element of the D+-set of this best successor q-partition and is not an element of the D+-set of the current partition P, i.e. D has been moved from D\u2212 to D+ in the context of the minimal D+-transformation that maps P to P\u2032.\nRemark 10 This diagnosisD serves as a representative of all diagnoses that are moved from D\u2212 to D+ in the context of this minimal transformation. It is later (after the next recursive call to D+PARTITION in line 13) added to Dused in line 14. This update of the set Dused effectuates that a q-partition Px where D together with all other diagnoses in Dused is in D+(Px) will never be encountered again during the complete execution of FINDQPARTITION. The reason why this is desirable is that all existing canonical q-partitions with a D+-set that is a superset of Dused have already been explored before the call of D+PARTITION given P as argument, and all existing canonical q-partitions with a D+-set that is a superset of Dused \u222a {D} have already been explored during the execution of the most recent call of D+PARTITION given P\u2032 as argument in line 13.\nWe point out that although only one representative D from the set of diagnoses that has been moved from D\u2212 to D+ in the context of the minimal transformation from P to P\u2032 is stored in Dused, what holds for D also holds for all other diagnoses moved from D\u2212 to D+ together with D during the transformation. This is achieved by leveraging the fact (see Corollary 23 later) that all the diagnoses moved during a minimal D+-transformation form an equivalence class w.r.t. a well-defined equivalence relation introduced later in Definition 20.\nNote that within the entire execution of any call of D+PARTITION with arguments (i.a.) P and Dused during the execution of FINDQPARTITION, the set Dused will always comprise only diagnoses that are in D\u2212(P).\nHaving computed the best direct successor P\u2032 of P by means of BESTSUC, the algorithm proceeds to focus on P\u2032 which is now the currently analyzed q-partition. This is reflected in line 13 where the method D+PARTITION calls itself recursively with the arguments P\u2032 (currently analyzed q-partition), Pbest (best currently known q-partition), Dused and the constant parameters p, tm and rm.\nAlgorithm 3 D+-Partitioning (implements FINDQPARTITION of Algorithm 2) Input: set of minimal diagnoses D w.r.t. a DPI \u3008K,B,P ,N \u3009R satisfying |D| \u2265 2, probability measure p, threshold\ntm, requirements rm to optimal q-partition Output: a canonical q-partition P w.r.t. D that is optimal w.r.t. m and tm, if isOptimal = true; the best of all\ncanonical q-partitions w.r.t. D and m, otherwise 1: procedure FINDQPARTITION(D, p, tm, rm) 2: \u3008P, isOptimal\u3009 \u2190D+PARTITION(\u3008\u2205,D, \u2205\u3009, \u3008\u2205,D, \u2205\u3009, \u2205, p, tm, rm) 3: return P 4: procedure D+PARTITION(P,Pb,Dused, p, tm, rm) . p, tm, rm are constant throughout entire procedure 5: Pbest \u2190 UPDATEBEST(P,Pb, p, rm) . see Algorithm 4 on page 116 6: if OPT(Pbest, tm, p, rm) then . see Algorithm 5 on page 113 7: return \u3008Pbest, true\u3009 . Pbest is optimal q-partition w.r.t. rm and tm 8: if PRUNE(P,Pbest, p, rm) then 9: return \u3008Pbest, false\u3009 . all descendant q-partitions of P are no better than Pbest w.r.t. rm 10: sucs\u2190 GETD+SUCS(P,Dused) 11: while sucs 6= \u2205 do 12: \u3008P\u2032,D\u3009 \u2190 BESTSUC(P, sucs, p, rm) . D is some diagnosis in D+(P\u2032) \\D+(P) 13: \u3008P\u2032\u2032, isOpt\u3009 \u2190 D+PARTITION(P\u2032,Pbest,Dused, p, tm, rm) 14: Dused \u2190 Dused \u222a {D} 15: if \u00acisOpt then 16: Pbest \u2190 P\u2032\u2032 . optimal q-partition not found, continue with next successor in sucs 17: else 18: return \u3008P\u2032\u2032, true\u3009 . optimal q-partition found, unwind recursion completely and return P\u2032\u2032 19: sucs\u2190 sucs \\ {P\u2032} 20: return \u3008Pbest, false\u3009 . all successors in sucs explored, continue at next higher recursion level\nThe output \u3008P\u2032\u2032, isOpt\u3009 of this recursive call of D+PARTITION is then processed in lines 15-18. In this vein, if isOpt = false , meaning that P\u2032\u2032 is not optimal w.r.t. rm and tm, then the currently best known q-partition Pbest is updated and set to P\u2032\u2032. The idea behind this assignment is that, during any call of D+PARTITION, the currently best known q-partition can only become better or remain unmodified, and cannot become worse. After this variable update, the just explored q-partition P\u2032 is eliminated from the set sucs of successors of P, and the next iteration of the while-loop is initiated.\nIf, on the other hand, isOpt = true , then this indicates that an optimal q-partition w.r.t. rm and tm has been located and is stored in P\u2032\u2032. Hence, the algorithm just forwards the result \u3008P\u2032\u2032, true\u3009 to the next higher level in the recursion (line 18). Note that this effectuates that the search immediately returns by unwinding the recursion completely once an optimal q-partition has been found.\nFinally, in case none of the explorations of all successors sucs of P has resulted in the discovery of an optimal q-partition, then \u3008Pbest, false\u3009 is returned (i.e. the algorithm backtracks) in line 20 and the execution continues one level higher in the recursion. Visually, concerning the search tree, this means that the parent node of P is again the currently analyzed node and a sibling of P is explored next.\nBefore we elucidate the functions (i.e. Algorithms 4, 5, 6 and 7) called by D+PARTITION in Algorithm 3, take note of the following remarks:\nRemark 11 The code specified for the RIO measure in Algorithms 4, 5, 6 and 7 tacitly assumes that we use a one-directional search for the best canonical q-partition with early pruning. That is, since we consider D+-partitioning where D+ is being gradually filled up with diagnoses starting from the empty set, we premise that the goal is to find only those least cautious non-high-risk queries (cf. Section 3.2.4) with the feature |D+| \u2264 |D\u2212|. The reason for this is that, in D+-partitioning, the size of the search tree grows proportionally (depth-first) and the search time in the worst case even exponentially with\nthe number of diagnoses in D+. Of course, one usually wants to keep the search complexity small. In order to \u201ccomplete\u201d the search for optimal canonical q-partitions (which will be rarely necessary in practical situations as optimal q-partitions seem to be found by means of only one-directional earlypruning search with very high reliability given reasonable values of tm), we would rely on another earlypruning search (possibly executed in parallel) by means of D\u2212-partitioning assuming |D\u2212| \u2264 |D+|. This can be compared with a bidirectional search (cf. [23, Sec. 3.4.6]). In this vein, a great deal of time might be saved compared to a one-directional full search.\nRemark 12 In Section 3.3 we have deduced for each discussed query quality measure m some qualitative requirements rm to an optimal query w.r.t. m. These are listed in Table 9. However, as our search for optimal q-partitions automatically neglects q-partitions with a non-empty set D0, the focus of this search is put exclusively on queries in a set Q \u2286 QD,\u3008K,B,P,N \u3009R where each Q \u2208 Q features D\n0(Q) = \u2205. For that reason, we can exploit Table 8 which states equivalences between the discussed measures in this particular setting. The section \u201c\u2261Q\u201d of the table suggests that there are only seven measures with a different behavior when it comes to the selection of a query (q-partition) from the set Q. Therefore, we mention only one representative of each equivalence class (namely the same one as given in the first column of Table 8) in Algorithms 4, 5, 6 and 7 although the same code is valid for all measures in the same class. For instance, for EMCa Table 7 tells us that the code given for ENT must be considered.\nAlgorithm for the Update of the Best Q-Partition. In the following, we make some comments on Algorithm 4 on page 112. Given the inputs consisting of two partitions P and Pbest w.r.t. the set of leading diagnoses D, a set of requirements rm to an optimal q-partition and a (diagnosis) probability measure p, the output is the better partition among {P,Pbest} w.r.t. D and rm.\nFirst of all, in line 2 the set of leading diagnoses D, which is needed in the computations performed by the algorithm, is reconstructed by means of the q-partition P (note that D is indeed equal to D+(P)\u222a D\u2212(P) since D0(Q) = \u2205 by assumption). What comes next is the check what the used query quality measure m is. Depending on the outcome, the determination of the better q-partition among {P,Pbest} is realized in different ways, steered by rm (cf. Table 8). In the case of\n\u2022 the measure ENT (line 3) and equivalent measures as per the section \u201c\u2261Q\u201d of Table 7, rm dictates that the better q-partition is the one for which the sum of the probabilities in D+ is closer to 0.5. Given p(D+(P)) is closer to 0.5 than p(D+(Pbest)), P becomes the new Pbest. Otherwise, Pbest remains unchanged.\n\u2022 the measure SPL (line 6) and equivalent measures as per the section \u201c\u2261Q\u201d of Table 7, the better q-partition according to rm is the one for which the number of diagnoses in D+ is closer to |D| 2 .\nGiven |D+(P)| is closer to |D|2 than |D +(Pbest)|, P becomes the new Pbest. Otherwise, Pbest remains unchanged.\n\u2022 the measure RIO (line 9) and equivalent measures as per the section \u201c\u2261Q\u201d of Table 7, at first the current value of the cautiousness parameter is stored in c (line 10). Using c, the number of leading diagnoses that must be eliminated by the query answer at a minimum are assigned to the variable n (line 11), cf. Section 3.2.4. Then, the algorithm makes some tests utilizing n in order to find out whether P is better than Pbest. In fact, the three requirements in rm (third row of Table 8) are tested in sequence according to their priority (I)\u2013(III).\nThat is, if D+(P) has a cardinality larger than or equal to n (line 12), i.e. P is a non-high-risk q-partition (due to |D+(P)| \u2264 |D\u2212(P)|, cf. Remark 11) and D+(Pbest) has a cardinality lower than n (line 13), i.e. Pbest is a high-risk q-partition, P is already better than Pbest w.r.t. the priority (I) requirement in rm. Hence, Pbest is set to P in line 14.\nOtherwise, both P and Pbest are non-high-risk q-partitions, i.e. equally good w.r.t. the priority (I) requirement in rm. In this case, if the cardinality of D+(P) is closer to n than the cardinality of D+(Pbest) (line 15), then P is less cautious than Pbest and thus better regarding the priority (II) requirement in rm (recall that RIO searches for the least cautious non-high-risk query). Hence, Pbest is set to P in line 16.\nOtherwise, both P and Pbest are non-high-risk q-partitions and P is at least as cautious as Pbest. Now, the algorithm checks first whether both are equally cautious (line 17). If so, then both P and Pbest are equally good w.r.t. the priority (I) and (II) requirements in rm. Therefore, the priority (III) requirement in rm is tested, i.e. if p(D+(P)) is closer to 0.5 than p(D+(Pbest)) (line 18). If this evaluates to true , then Pbest is set to P in line 19.\nIn all other cases, P is not better w.r.t. rm than Pbest, and hence Pbest is not updated.\n\u2022 the measure KL (see line 20), the algorithm computes the KL measure for both P and Pbest (function COMPUTEKL) and compares the obtained values. In case P leads to a better, i.e. larger, KL value, Pbest is set to P, otherwise not. Note that our analyses conducted in Section 3.2.3 do not suggest any other plausible, efficient and general way to find out which of two given q-partitions is better w.r.t. KL.\n\u2022 the measure EMCb (see line 25), the algorithm computes the EMCb measure for both P and Pbest (function COMPUTEEMCB) and compares the obtained values. In case P leads to a better, i.e. larger, EMCb value, Pbest is set to P, otherwise not. Note that our analyses conducted in Section 3.2.3 do not suggest any other plausible, efficient and general way to find out which of two given q-partitions is better w.r.t. EMCb.\n\u2022 the measure MPS (see line 30) and equivalent measures as per the section \u201c\u2261Q\u201d of Table 7, one best q-partition is one for which |D+| = 1 and the sum of diagnoses probabilities in D+ is maximal (cf. Table 8 and Proposition 34). This is reflected by the code in lines 31-32 which guarantees that only q-partitions with |D+| = 1 can ever become a currently best q-partition. Note that the heuristics implemented by Algorithm 7 will ensure that the best canonical q-partition will always be visited as a very first node (other than the root node) in the search. This holds for MPS, but clearly does not need to hold for the other considered measures.\n\u2022 the measure BME (see line 33), the better q-partition is the one for which the set among {D+,D\u2212} with lower probability has the higher cardinality (cf. Table 8). This is reflected by the code in lines 33-37.\nAlgorithm for the Optimality Check. In the following, we provide some explanations on Algorithm 5 on page 113. Given the inputs consisting of a partition Pbest = \u3008D+,D\u2212, \u2205\u3009 w.r.t. the set of leading diagnoses D, a threshold tm, requirements rm to an optimal q-partition and a (diagnosis) probability measure p, the output is true iff Pbest is an optimal q-partition w.r.t. rm and tm.\nFirst of all, in line 2 the algorithm tests if Pbest is not a q-partition, i.e. whether D+ = \u2205 or D\u2212 = \u2205. If so, false is immediately returned as a partition which is not a q-partition should never be returned by the algorithm. Then, in line 4 the set of leading diagnoses D, which is needed in the computations performed by the algorithm, is reconstructed by means of D+ and D\u2212 (note that D is indeed equal to D+ \u222aD\u2212 since D0 = \u2205 by assumption). What comes next is the check what the used query quality measure m is. Depending on the outcome, the determination of the output is realized in different ways, steered by rm (cf. Table 8). In the case of\n\u2022 the measure ENT (line 5) and equivalent measures as per the section \u201c\u2261Q\u201d of Table 7, Pbest is optimal according to rm taking into account the tolerance of tm iff the sum of probabilities of diagnoses in D+ does not deviate from 0.5 by more than tm.\n\u2022 the measure SPL (line 9) and equivalent measures as per the section \u201c\u2261Q\u201d of Table 7, Pbest is optimal as per rm taking into account the tolerance of tm iff the number of diagnoses in D+ does not deviate from half the number of diagnoses in D by more than tm.\n\u2022 the measure RIO (line 14) and equivalent measures as per the section \u201c\u2261Q\u201d of Table 7, whether Pbest = \u2329 D+,D\u2212,D0 \u232a is optimal depends on the current cautiousness parameter c pertinent to the\nRIO measure and on two thresholds, tcard and tent, that we assume are prespecified and extractable from tm. The former is related to the second condition (II) (third row of Table 8) and defines the maximum tolerated deviance of |D+| from the least number dc|D|e (line 16) of leading diagnoses postulated to be eliminated by the next query as per c (see also Section 3.2.4). In other words, tcard denotes the maximal allowed cardinality deviance from the theoretical least cautious query w.r.t. c. The threshold tent addresses to the third condition (III) (third row of Table 8) and characterizes the maximum accepted difference of p(D+) from the (theoretically) optimal entropy value 0.5. So, if\n1. there are at least n diagnoses in D+ (line 19), i.e. Pbest is a non-high risk q-partition (requirement (I) as per row three of Table 8 is met), and\n2. the cardinality of D+ does not deviate from n by more than tcard (line 20), i.e. Pbest is sufficiently cautious as per c (requirement (II) as per row three of Table 8 is met), and\n3. the sum of probabilities of diagnoses in D+ does not differ from 0.5 by more than tent (line 21), i.e. Pbest has a sufficiently high information gain (requirement (III) as per row three of Table 8 is satisfied),\nthen Pbest is (considered) optimal. Otherwise it is not. This is reflected by the code lines 19-23.\n\u2022 the measure KL (line 24), we can use optKL,p,D which was derived in Remark 4. This means that we consider Pbest as optimal if KL(Q) (see Eq. 21) does not differ from optKL,p,D by more than the specified threshold tm.\n\u2022 the measure EMCb (line 28), we can use optEMCb,p,D which was derived in Remark 5. This means that we consider Pbest as optimal if EMCb(Q) (see Eq. 24) does not differ from optEMCb,p,D by more than the specified threshold tm.\n\u2022 the measure MPS (line 32) and equivalent measures as per the section \u201c\u2261Q\u201d of Table 7, Pbest is optimal iff D+ includes only the most probable diagnosis D\u2217 in D and the rest of the diagnoses is assigned to D\u2212 (Proposition 34). Note that \u3008{D\u2217} ,D \\ {D\u2217} , \u2205\u3009 is a canonical q-partition due to Corollary 20. Hence, the proposed search which is complete w.r.t. canonical q-partitions will definitely generate this q-partition. This implies that we are, for any set of multiple leading diagnoses, able to find precisely the theoretically optimal q-partition w.r.t. the MPS measure. For that reason we do not need any tm when using MPS.\n\u2022 the measure BME (line 38), if p(D+) = 0.5 (line 39), then also p(D\u2212) = 0.5 (since D0 = \u2205). That is, requirement (I) (last row in Table 8) is not met for any of {D+,D\u2212}. Hence, false is returned.\nOtherwise, if p(D+) < 0.5, then Pbest is optimal iff |D+| deviates not more than tm from its maximal possible cardinality |D| \u2212 1 (line 41). If so, then Pbest is (considered) optimal which is why true is returned. To understand why the maximal possible cardinality is given by |D| \u2212 1, recall that D+ as well as D\u2212 must be non-empty sets due to line 2, i.e. 1 \u2264 |D+| \u2264 |D| \u2212 1 and 1 \u2264 |D\u2212| \u2264 |D| \u2212 1. Otherwise, if p(D\u2212) < 0.5, then Pbest is optimal iff |D\u2212| deviates not more than tm from its maximal possible cardinality |D| \u2212 1 (line 43). In this case, true is returned as well. In all other cases, Pbest is (considered) non-optimal. Thence, false is returned.\nAlgorithm for the Pruning Check. In the following, we provide some explanations on Algorithm 6 on page 114. Given the inputs consisting of partitions P and Pbest w.r.t. the set of leading diagnoses D where D0(P) = D0(Pbest) = \u2205, requirements rm to an optimal q-partition and a (diagnosis) probability measure p, the output is true if exploring successor q-partitions of P cannot lead to the discovery of q-partitions that are better w.r.t. rm than Pbest.\nFirst of all, in line 2 the set of leading diagnoses D, which is needed in the computations performed by the algorithm, is reconstructed by means of P. What comes next is the check what the used query quality measure m is. Depending on the outcome, the determination of the output is realized in different ways, steered by rm (cf. Table 8). Before we analyze the different behavior of the algorithm for the different measures, we point out that, at the time PRUNE (Algorithm 6) is called in Algorithm 3, Pbest must be at least as good w.r.t. rm as P. This is due to the fact that UPDATEBEST is always executed before PRUNE in Algorithm 3 and effectuates the storage of the best canonical q-partition found so far in Pbest. In the case of\n\u2022 the measure ENT (line 3) and equivalent measures as per the section \u201c\u2261Q\u201d of Table 7, if the sum of probabilities of diagnoses in D+(P) is already greater than or equal to 0.5, then the quality of P as per rm can only become worse if additional diagnoses, each with a positive probability, are added to D+(P). The reason for this is that the absolute difference between p(D+(P)) and the theoretical optimum of 0.5 can only increase in this case. Hence, we test in line 4 whether p(D+(P)) \u2265 0.5 and return true if positively evaluated and false otherwise.\n\u2022 the measure SPL (line 7) and equivalent measures as per the section \u201c\u2261Q\u201d of Table 7, if the number of diagnoses in D+(P) is already greater than or equal to \u230a |D| 2 \u230b , then the quality of P as per rm\ncan only become worse if additional diagnoses are added to D+(P). The reason for this is that the absolute difference between |D+(P)| and the theoretical optimum of |D|2 cannot become better than for P. To see this, observe that |D+(P)| = \u230a |D| 2 \u230b means that the absolute difference between |D+(P)| and |D|2 is zero in case |D| is even and one half otherwise. Adding at least one diagnosis to D+(P) implies a difference of minimally one in the former case and a difference of minimally one half in the latter. The case |D+(P)| > \u230a |D| 2 \u230b can be analyzed very easily in the same fashion.\nTherefore, we test in line 8 whether |D+(P)| \u2265 \u230a |D| 2 \u230b and return true if positively evaluated and false otherwise.\n\u2022 the measure RIO (line 11) and equivalent measures as per the section \u201c\u2261Q\u201d of Table 7, the pruning check works as follows. First, the minimal number n of diagnoses that must be eliminated by the answer to the next query is computed (lines 12-13). Using this parameter, all necessary conditions for pruning can be verified. That is, if the size of D+(P) is equal to n (line 14), the search tree can be pruned below P since the two highest-priority requirements to an optimal q-partition imposed by RIO (cf. (I) and (II) in the third row of Table 8) postulate that the size of the minimum-cardinality set in {D+,D\u2212} (for which we always plug in D+ due to Remark 11) is at least n and its deviance from n is minimal. The latter can only worsen if diagnoses are added to D+(P). Consequently, the algorithm returns true in line 15.\nOn the other hand, if the cardinality of D+(Pbest) equals n (line 16), i.e. we know that at least one q-partition with a D+-set of cardinality n has already been detected, and the cardinality of D+(P) exceeds n (line 17), then P is worse than Pbest regarding requirement (II). Hence true is returned in line 18.\nFinally, if (a) the cardinality of D+(Pbest) equals n (line 16), (b) |D+(P)| < n (by the negative evaluation of the tests in lines 14 and 17) and (c) p(D+(P))\u22120.5 \u2265 |p(D+(Pbest))\u22120.5| (line 19),\nthen continuing the search at P cannot lead to a better q-partition than Pbest as per rm. This holds since (b) and (c) imply that the addition of any diagnoses, each with a non-zero probability (cf. page 26), to D+(P) can never lead to a situation where |D+(P\u2032)| = n and P\u2032 has a better entropy (i.e. ENT or ENTz measure) than Pbest for any (direct or indirect) successor P\u2032 of P. Because, for any successor P\u2032 of P with |D+(P\u2032)| = n we have p(D+(P\u2032)) > p(D+(P)) due to (b), i.e. p(D+(P\u2032)) \u2212 0.5 > p(D+(P)) \u2212 0.5 \u2265 |p(D+(Pbest)) \u2212 0.5| \u2265 0 due to (c). This means however that |p(D+(P\u2032))\u2212 0.5| > |p(D+(Pbest))\u2212 0.5|, i.e. P\u2032 and Pbest are equally good w.r.t. the priority (I) and (II) requirements in rm (both are least cautious non-high-risk q-partitions), but Pbest is better as to the priority (III) requirement in rm (information gain). All successors P\u2032\u2032 of P with |D+(P\u2032\u2032)| 6= n can never be better than Pbest since they already violate the priority (I) requirement (i.e. are high-risk q-partitions) in case |D+(P\u2032\u2032)| < n or the priority (II) requirement (i.e. are not least cautious) in case |D+(P\u2032\u2032)| > n. Hence, as an arbitrary direct or indirect successor of P cannot be better than Pbest w.r.t. rm, the algorithm returns true in this case (line 20).\nOtherwise, we cannot be sure that P might not generate any more favorable successor w.r.t. rm than Pbest is. Hence, false is returned (line 21).\n\u2022 one of the measures KL and EMCb (line 22), in the light of our analyses (cf. Section 3.2.3) of the goal functions (Equations 21 and 24) that must be maximized to find an optimal q-partition for these measures, we are not able to come up with a straightforward general pruning condition based on probabilities and/or the cardinality of the sets in a q-partition. Hence, simply false is returned. This inability to prune the search tree early can be also a crucial shortcoming of KL and EMCb as opposed to other measures, especially in cases involving a high cardinality set D of leading diagnoses.\n\u2022 the measure MPS (see line 24) and equivalent measures as per the section \u201c\u2261Q\u201d of Table 7, since for MPS the set of requirements rm postulate a q-partition involving either a singleton D+ or a singleton D\u2212 where this singleton has maximal probability, the search is supposed to just return the q-partition with a singleton D+ = {D} where D is the most probable leading diagnosis. This is also the theoretically optimal q-partition w.r.t. D. In this manner we rely on a similar strategy as with RIO in which we exploit early pruning (cf. Remark 11). Given that one wants to generate also the optimal q-partition with a singleton D\u2212, then D\u2212-partitioning should be used for this purpose.\nSo, in line 25, we just check whether the cardinality of D+ is at least one. If so, then true is returned as Pbest must already contain the most probable diagnosis in D (guaranteed by the implementation of BESTSUC, see lines 23-24 in Algorithm 7) which is why true is returned. Otherwise, false is returned.\n\u2022 the measure BME (see line 29), we first recall that the optimal q-partition w.r.t. rm has the property that the cardinality of its set in {D+,D\u2212} with the lower probability is maximal. Hence, if p(D\u2212(P)) is already less than 0.5 (note that this is equivalent to p(D+(P)) > p(D\u2212(P)) since D0(P) = \u2205), then the deletion of further diagnoses from D\u2212(P), each with a probability greater than zero (cf. page 26), can only involve a deterioration of P w.r.t. rm, i.e. a reduction of the cardinality of D\u2212(P) whereas p(D\u2212(P)) remains smaller than 0.5. Lines 30-31 in the algorithm account for that.\nIf, on the other hand, (a) p(D+(P)) < 0.5 (line 32), and (b) deleting (at least) one diagnosis from D\u2212(P) makes D\u2212(P) at most as large in size as D+(P) (line 33), and (c) the elimination of any diagnosis from D\u2212(P) makes the sum of probabilities of diagnoses in D\u2212(P) less than 0.5 (line 35), then the search tree can be pruned below the node representing P.\nTo make this apparent, we reason as follows: Let D\u2217(P) be the set in {D+(P),D\u2212(P)} satisfying p(D\u2217(P)) < 0.5. Then, by (a), the value of BME for a query with q-partition P is |D\u2217(P)| = |D+(P)|. Assume an arbitrary (direct or indirect) successor P\u2032 of P. Then, D\u2212(P\u2032) \u2282 D\u2212(P). By (b), this yields |D\u2212(P\u2032)| \u2264 |D+(P)|. Moreover, by (c), it must be the case that p(D\u2212(P\u2032)) < 0.5. Consequently, D\u2217(P\u2032) = D\u2212(P\u2032), i.e. the value of BME for a query with q-partition P\u2032 is |D\u2217(P\u2032)| = |D\u2212(P\u2032)| \u2264 |D+(P)| = |D\u2217(P)|. So, since rm postulates maximal |D\u2217(Popt)| of some optimal q-partition Popt, no successor P\u2032 can be better as per rm than P and the algorithm returns true in line 36. Otherwise, false is returned in line 37.\nAlgorithm to Find Best Successor. In the following, we explicate Algorithm 7 on page 115. Given a partition P (the current node in the search tree), a set of q-partitions sucs each element of which is a qpartition resulting from P by a minimal D+-transformation (cf. Definition 18), a (diagnosis) probability measure p and some requirements rm to an optimal q-partition as inputs, the algorithm returns the best q-partition P in sucs according to the implemented heuristics. The heuristics is constructed from rm where a smaller value for the heuristics indicates a better q-partition.\nThe algorithm iterates once over the set sucs to extract the q-partition in sucs with minimal heuristics (lines 2-5) and stores this q-partition in Sbest. At this, GETFIRST(X) returns the first element in the set X given to it as an argument and afterwards deletes this element fromX . The calculation of the heuristics for a given q-partition \u3008D+,D\u2212, \u2205\u3009 and rm is realized by the function HEUR (line 9-30) which we describe next.\nFirst of all, in line 10, the set of leading diagnoses D, which is needed in the computations performed by the algorithm, is reconstructed by means of D+ and D\u2212. What comes next is the check what the used query quality measure m is. Depending on the outcome, the determination of the output of HEUR is realized in different ways, steered by rm (cf. Table 8). In the case of\n\u2022 the measure ENT (line 11) and equivalent measures as per the section \u201c\u2261Q\u201d of Table 7, the heuristic evaluates to the absolute difference between p(D+) and the theoretical optimum of 0.5. That is, the closer the probability of the D+ set of a q-partition in sucs comes to a half, the better the q-partition is ranked by the heuristics.\n\u2022 the measure SPL (line 13) and equivalent measures as per the section \u201c\u2261Q\u201d of Table 7, the heuristic evaluates to the absolute difference between |D+| and the theoretical optimum of |D|2 . That is, the closer the cardinality of the D+ set of a q-partition in sucs comes to half the number of leading diagnoses, the better the q-partition is ranked by the heuristics.\n\u2022 the measure RIO (line 15) and equivalent measures as per the section \u201c\u2261Q\u201d of Table 7, the computation of the heuristic value works as follows. First, the minimal number n of diagnoses that must be eliminated by the answer to the next query is computed (lines 16-17). By means of n, which is the target value for the cardinality of D+ (cf. Section 3.2.4), the number numDiagsToAdd of diagnoses that must still be added to D+ to reach this target value, is computed in line 18. Furthermore, the average probability of a diagnosis in D\u2212 is calculated and stored in avgProb in line 19. Finally, the returned heuristic value in line 20 gives the deviance of p(D+(P\u2032)) from 0.5 (the optimal value of p(D+) w.r.t. the ENT or ENTz measure) that would result if numDiagsToAdd diagnoses, each with exactly the average probability avgProb of diagnoses in D\u2212, were added to D+ yielding the new q-partition P\u2032. That is, comparing with rm given in the third row of Table 8, a lower heuristic value means higher proximity to optimality w.r.t. condition (III) under the assumption that the D+-set of the current q-partition is filled up in a way to satisfy exactly the optimality conditions (I) and (II).\n\u2022 the measures KL and EMCb (see line 21), as per Propositions 26,(3.) and 30,(3.), P is the more promising a q-partition, the more the sum of diagnoses probabilities in D+ (or D\u2212, respectively) exceeds the expected sum of diagnoses probabilities in D+ (D\u2212). Under the assumption that all leading diagnoses probabilities satisfy a distribution with a mean of 1|D| , the expected value of the\nsum of diagnoses probabilities in D+ can be computed as |D +| |D| , and as |D\u2212| |D| for the D \u2212 case. As a consequence, the value of the heuristics returned for P is either |D +|\n|D|p(D+) , as shown in the algorithm (line 22). That is, a high sum of diagnoses probabilities p(D+) compared to the expected probability sum means a better q-partition and hence involves a low heuristic value, as desired, due to the placement of p(D+) in the denominator. An alternative would be tu use |D\n\u2212| |D|p(D\u2212) as heuristic\nvalue. A usage of the latter would imply the exploration of q-partitions resulting from the addition of smallest probabilities to D+ first instead of highest ones as in case of the former. Stated in the terminology of Proposition 26,(3.), the former approach seeks to explore the q-partitions with D+-sets in MaxP+k first while the latter prefers the q-partitions with D \u2212-sets in MaxP\u2212m.\n\u2022 the measure MPS (line 23) and equivalent measures as per the section \u201c\u2261Q\u201d of Table 7, clearly, the best successor to select is the one with maximal p(D+). This is reflected by returning a heuristic value of \u2212p(D+) in line 24.\n\u2022 the measure BME (see line 25), we recall that an optimal q-partition w.r.t. rm satisfies that its set in {D+,D\u2212} with minimal probability has a maximal possible number of diagnoses in it. Hence if p(D+) < 0.5 (line 26), i.e. D+ has minimal probability, then, the larger |D+| is, the better the heuristic value of the q-partition should be. The return value \u2212|D+| in line 27 accounts for this (recall that a lower heuristic value signifies a better q-partition). On the other hand, if D\u2212 has minimal probability (line 28), then \u2212|D\u2212| is returned as |D\u2212| must be maximized in this case (line 29). In the situation where p(D+) = 0.5 = p(D\u2212), a heuristic value of zero is returned, signifying rejection of this successor q-partition, as it does not comply with the priority (I) requirement in rm, i.e. that either p(D+) or p(D\u2212) be smaller than 0.5.\nIn line 6, the algorithm computes D+diff as the set of diagnoses that have been transferred from D \u2212 in the current partition P to D+ in the successor q-partition Sbest in the course of the minimal D+transformation that maps P to Sbest. Then, the first diagnosis in the set D+diff is assigned to the variable D (line 7). Note, by the definition of a minimal D+-transformation (Definition 18), D+diff 6= \u2205 must hold. The tuple \u3008Sbest,D\u3009 is finally returned.\nThe reason of returning one (arbitrary) diagnosis D from D+diff in addition to the best successor is the pruning of the search tree. That is, D is leveraged in all subtrees of P that have not yet been explored in order to avoid the repeated generation of q-partitions that have already been generated and analyzed in explored subtrees of P. Instead of the entire set D+diff , only one diagnosis out of it is needed for this purpose since D+diff represents exactly one equivalence class of diagnoses. That is, if one diagnosis from this set must not be transferred to D+ from D\u2212 in the context of a minimal D+-transformation, then none of the diagnoses in this set must do so (see also Definition 19 and Corollary 23 later)."}, {"heading": "3.4.4 Q-Partition Successor Computation", "text": "Before we describe the successor function for D+-partitioning, consider the following remark:\nRemark 13 We want to emphasize that the favorable feature D0(Q) = \u2205 of canonical queries Q is preserved throughout the execution of the CALCQUERY function (Algorithm 2). In other words, the algorithm will always return a query with empty D0(Q) as all upcoming functions (that are executed after FINDQPARTITION) are q-partition preserving, i.e. they possibly manipulate the query, but leave the q-partition invariant.\nSuccessor Function for D+-Partitioning. We first characterize Sinit and then Snext.\nDefinition of Sinit. In the case of D+-partitioning, Sinit can be easily specified by means of the following corollary which is a direct consequence of Proposition 3. It states that for any single diagnosis D \u2208 D there is a canonical q-partition with D+(Q) = {D}.\nCorollary 20. Let D \u2286 mD\u3008K,B,P,N \u3009R with |D| \u2265 2. Then, \u3008{Di},D \\ {Di}, \u2205\u3009 is a canonical qpartition for all Di \u2208 D.\nProof. That \u3008{Di},D \\ {Di}, \u2205\u3009 is a q-partition follows immediately from Proposition 3,(7.). We now show that it is canonical. Also from Proposition 3,(7.), we obtain that Q := UD \\ D is an (explicitentailments) query associated with the q-partition \u3008D+(Q),D\u2212(Q),D0(Q)\u3009 = \u3008{Di},D \\ {Di}, \u2205\u3009. Now, Eexp(D+(Q)) = K \\ UD+(Q) = K \\ Di due to Proposition 47. As UD \u2286 K and ID \u2286 Di, we can infer that Qcan(D+(Q)) = Eexp(D+(Q))\u2229DiscAxD = UD \\Di. Hence, Qcan(D+(Q)) = Q wherefore \u3008D+(Q),D\u2212(Q),D0(Q)\u3009 is a canonical q-partition.\nDefinition of Snext. In order to define Snext, we utilize Proposition 53 which provides sufficient and necessary criteria when a partition of D is a canonical q-partition.\nProposition 53. Let D \u2286 mD\u3008K,B,P,N \u3009R and P = \u3008D+,D\u2212, \u2205\u3009 be a partition w.r.t. D with D+ 6= \u2205 and D\u2212 6= \u2205. Then, P is a canonical q-partition iff\n1. UD+ \u2282 UD and\n2. there is no Dj \u2208 D\u2212 such that Dj \u2286 UD+ .\nProof. \u201c\u21d2\u201d: We prove the \u201conly-if\u201d-direction by contradiction. That is, we derive a contradiction by assuming that P is a canonical q-partition and that \u00ac(1.) or \u00ac(2.) is true.\nBy the premise that P is a canonical q-partition, the query Qcan(D+) := Eexp(D+) \u2229 DiscAxD must have exactly P as its associated q-partition. Since K\u2217i does not violate any x \u2208 R \u222a N , but, due to D\u2212 6= \u2205, there is some Di \u2208 D\u2212(Qcan(D+)) = D\u2212 such that K\u2217i \u222a Qcan(D+) does violate some x \u2208 R \u222aN , we can conclude that Qcan(D+) 6= \u2205 and thence Eexp(D+) 6= \u2205.\nBy Proposition 47, Eexp(D+) = K\\UD+ . So, (\u2217) : \u2205 \u2282 Qcan(D+) \u2286 K\\UD+ \u2286 (K\\UD+)\u222aB \u222a UP \u2286 (K \\ Di) \u222a B \u222a UP =: K\u2217i for all Di \u2286 UD+ .\nNow, assuming that (1) is false, i.e. UD+ 6\u2282 UD, we observe that this is equivalent to UD+ = UD since UD+ \u2286 UD due to D+ \u2286 D. Due to UD+ = UD, (\u2217) is true for all Di \u2208 D. It follows that K\u2217i \u2287 Qcan(D+) and, due to the fact that the entailment relation in L is extensive, that K\u2217i |= Qcan(D+). Therefore, we can conclude using Definition 8 that D+ = D+(Qcan(D+)) = D and thus D\u2212 = \u2205. The latter is a contradiction to D\u2212 6= \u2205.\nAssuming \u00ac(2), on the other hand, we obtain that there is some diagnosisDj \u2208 D\u2212 withDj \u2286 UD+ . By (\u2217), however, we can derive that K\u2217j |= Qcan(D+) and therefore Dj \u2208 D+(Qcan(D+)) = D+ which contradicts Dj \u2208 D\u2212 by the fact that P is a partition w.r.t. D which implies D+ \u2229D\u2212 = \u2205.\n\u201c\u21d0\u201d: To show the \u201cif\u201d-direction, we must prove that P is a canonical q-partition, i.e. that P is a q-partition and that P is exactly the q-partition associated with Qcan(D+) given that (1) and (2) hold.\nBy D+ 6= \u2205 and (1), it is true that \u2205 \u2282 UD+ \u2282 UD. So, there is some axiom ax \u2208 UD \u2286 K such that (\u2217\u2217) : ax /\u2208 UD+ . Hence, ax \u2208 K \\ UD+ , and, by Proposition 47, ax \u2208 Eexp(D+). Now, Qcan(D +) := Eexp(D +) \u2229 DiscAxD = Eexp(D+) \u2229 (UD \\ ID). Since ax \u2208 UD, in order to show that ax \u2208 Qcan(D+), we must demonstrate that ax /\u2208 ID. Therefore, assume that ax \u2208 ID. This implies that ax \u2208 Di for all Di \u2208 D and particularly for Di \u2208 D+ which yields ax \u2208 UD+ . This, however, is a contradiction to (\u2217\u2217). So, we conclude that ax \u2208 Qcan(D+), i.e. (Q1): Qcan(D+) 6= \u2205.\nMore precisely, since ax was an arbitrary axiom in UD with property (\u2217\u2217), we have that UD \\UD+ \u2286 Qcan(D +). By (2), for all Dj \u2208 D\u2212 there is an axiom ax j \u2208 K such that ax j \u2208 Dj \u2282 UD and ax j /\u2208\nUD+ which implies ax j \u2208 UD\\UD+ \u2286 Qcan(D+). Hence,K\u2217j\u222aQcan(D+) must violate some x \u2208 R\u222aN since ax j \u2208 K and by the subset-minimality of Dj \u2208 D\u2212. Consequently, D\u2212 \u2286 D\u2212(Qcan(D+)). As D\u2212 6= \u2205 by assumption, we have that (Q2): \u2205 \u2282 D\u2212(Qcan(D+)).\nThat K\u2217i |= Qcan(D+) for Di \u2208 D+ follows by the same argumentation that was used above in (\u2217). Thus, we obtain D+ \u2286 D+(Qcan(D+)). As D+ 6= \u2205 by assumption, we have that (Q3): \u2205 \u2282 D+(Qcan(D\n+)). Note that (Q1) \u2013 (Q3) imply that Qcan(D+) is a query w.r.t. D (cf. Definition 7). Now, let us assume that at least one of the two derived subset-relations is proper, i.e. (a) D\u2212 \u2282 D\u2212(Qcan(D +)) or (b) D+ \u2282 D+(Qcan(D+)). If (a) holds, then there is some D \u2208 D\u2212(Qcan(D+)) which is not in D\u2212. Hence, D \u2208 D+ or D \u2208 D0. The former case is impossible since D \u2208 D+ implies D \u2208 D+(Qcan(D+)) by D+ \u2282 D+(Qcan(D+)), which yields D\u2212(Qcan(D+)) \u2229 D+(Qcan(D+)) \u2287 {D} \u2283 \u2205, a contradiction to the fact that Qcan(D+) is a query w.r.t. D and Proposition 3,(1.). The latter case cannot be true either as D0 = \u2205 by assumption. In an analogue way we obtain a contradiction if we assume that case (b) holds. So, it must hold that P = \u3008D\u2212(Qcan(D+)),D\u2212(Qcan(D+)), \u2205\u3009. This finishes the proof.\nLet in the following for a DPI \u3008K,B,P ,N \u3009R and a partition Pk = \u3008D+k ,D \u2212 k ,D 0 k\u3009 of D and all\nDi \u2208 D \u2286mD\u3008K,B,P,N \u3009R\nD(k)i := Di \\ UD+k (33)\nThe next corollary establishes the relationship between Eq. (33) and canonical q-partitions based on Proposition 53:\nCorollary 21. Let D \u2286 mD\u3008K,B,P,N \u3009R , Pk = \u3008D + k ,D \u2212 k , \u2205\u3009 a partition of D with D + k ,D \u2212 k 6= \u2205 and UD+k \u2282 UD. Then P := \u2329 D+k ,D \u2212 k , \u2205 \u232a is a canonical q-partition iff\n1. D(k)i = \u2205 for all Di \u2208 D + k , and\n2. D(k)i 6= \u2205 for all Di \u2208 D \u2212 k .\nProof. Ad 1.: This proposition follows directly from the definition ofD(k)i := Di \\UD+k (see Eq. 33) and the trivial fact that Di \u2286 UD+k for all Di \u2208 D + k . Thence, this proposition can never be false.\nAd 2.: We show the contrapositive of (2.), i.e. that P := \u2329 D+k ,D \u2212 k , \u2205 \u232a is not a canonical q-partition\niff D(k)i = \u2205 for some Di \u2208 D \u2212 k :\n\u201c\u21d0\u201d: By Proposition 53, a partition Pk = \u3008D+k ,D \u2212 k , \u2205\u3009 with D + k ,D \u2212 k 6= \u2205 is a canonical q-partition\niff (1) UD+k \u2282 UD and (2) there is no Dj \u2208 D \u2212 k such that Dj \u2286 UD+k . If Dj \u2208 D \u2212 k and D (k) j := Dj \\ UD+k = \u2205, then Dj \u2286 UD+k , which violates the necessary condition (2) that must hold for a qpartition. Therefore, Pk cannot be a canonical q-partition.\n\u201c\u21d2\u201d: By Proposition 53, a partition Pk = \u3008D+k ,D \u2212 k , \u2205\u3009 with D + k ,D \u2212 k 6= \u2205 is not a canonical qpartition iff (\u00ac1) UD+k 6\u2282 UD or (\u00ac2) there is some Di \u2208 D \u2212 k such that Di \u2286 UD+k . Since condition (\u00ac1) is assumed to be false, condition (\u00ac2) must be true, which implies that D(k)i = Di \\ UD+k = \u2205 for some Di \u2208 D\u2212k .\nSo, Corollary 21 along with Proposition 50, which states that D0 must be the empty set for all canonical q-partitions, demonstrate that UD+ already defines a canonical q-partition uniquely. Consequently, we can give a lower and upper bound for the number of canonical q-partitions w.r.t. a set of leading minimal diagnoses:\nCorollary 22. Let D \u2286 mD\u3008K,B,P,N \u3009R with |D| \u2265 2. Then, for the number c of canonical q-partitions w.r.t. D the following holds:\n|D| \u2264 c \u2264 | { UD+ | \u2205 \u2282 D+ \u2282 D } |\nProof. The proposition of the corollary is an immediate consequence of Corollaries 20 and 21 as well as Proposition 3,(6.).\nExploiting the results obtained by Proposition 53, the following proposition provides the tools for defining and computing the successor function Snext, more concretely a minimal D+-transformation from a canonical q-partition to a canonical q-partition, for D+-partitioning search. It establishes criteria when such a minimal D+-transformation is given and indicates circumstances under which the successor function can be strongly simplified, meaning that all possible successors of a partition are proven to be canonical q-partitions. The latter result can be used to accelerate the search.\nProposition 54. Let D \u2286mD\u3008K,B,P,N \u3009R and Pk = \u3008D + k ,D \u2212 k , \u2205\u3009 be a canonical q-partition of D. Then\n1. Pk 7\u2192 Ps for Ps := \u3008D+s ,D\u2212s , \u2205\u3009 for D+s \u2287 D+k is a minimal D+-transformation if\n(a) D+y := D + k \u222a {D} such that UD+y \u2282 UD for some D \u2208 D \u2212 k and UD+y is subset-minimal\namong all D \u2208 D\u2212k , and\n(b) D+s := {Di | Di \u2208 D,D (y) i = \u2205} and\n(c) D\u2212s := {Di | Di \u2208 D,D (y) i 6= \u2205}.\n2. Construction of Ps as per (1a), (1b) and (1c) yields all possible minimal D+-transformations Pk 7\u2192 Ps.\n3. if all diagnoses in { D(k)i | D (k) i \u2208 D \u2212 k } are pairwise disjoint, then all possible partitions \u3008D+r ,D\u2212r , \u2205\u3009\nwith D \u2283 D+r \u2287 D+k are canonical q-partitions.\nProof. Ad 1.: By the definition of a minimal D+-transformation (see Definition 18), we have to show that (i) Ps is a canonical q-partition where D+s \u2283 D+k and that (ii) there is no canonical q-partition \u3008D+l ,D \u2212 l , \u2205\u3009 such that D + k \u2282 D + l \u2282 D+s .\nAd (i): To verify that Ps is indeed a q-partition, we first check whether both conditions of Proposition 53 are met. Proposition 53,(1.), i.e. UD+s \u2282 UD, is met due to the following argumentation. First, the inclusion of only diagnoses Di with D(y)i = \u2205 (and thus Di \u2286 UD+y ) in D + s implies UD+s 6\u2283 UD+y . Further, D+s \u2287 D+y must hold since, trivially, for eachDi \u2208 D+y it must be true thatD (y) i = \u2205 wherefore, by (1b), Di \u2208 D+s . Hence, UD+s \u2287 UD+y must be given. Combining these findings yields UD+s = UD+y . By the postulation of UD+y \u2282 UD in (1a), we obtain UD+s \u2282 UD.\nProposition 53,(2.), i.e. that there is no Di \u2208 D\u2212s such that Di \u2286 UD+s , is shown next. Each Di \u2208 D with Di \u2286 UD+s fulfills D (y) i = \u2205 by UD+s = UD+y which we derived above. Thus, by the definition of D+s and D \u2212 s in (1b) and (1c), respectively, each Di \u2208 D with Di \u2286 UD+s must be an element of D + s and cannot by an element of D\u2212s . Hence, Ps is a q-partition. Moreover, since D+y := D + k \u222a {D} for some diagnosis, we obtain that D+y \u2283 D + k . But, before we argued that D+s \u2287 D+y . All in all, this yields D+s \u2283 D+k . This finishes the proof of (i). Ad (ii): To show the minimality of the transformation Pk 7\u2192 Ps, let us assume that there is some canonical q-partition Pl := \u3008D+l ,D \u2212 l , \u2205\u3009 with D + k \u2282 D + l \u2282 D+s . From this, we immediately obtain that UD+l \u2286 UD+s must hold. Furthermore, we have shown above that UD+s = UD+y . Due to the fact\nthat Ps is already uniquely defined as per (1b) and (1c) given UD+y = UD+s and since D + l 6= D+s , we conclude that UD+l \u2282 UD+s . Thence, UD+l \u2282 UD+y . Additionally, by (1a), for all diagnoses D \u2208 D \u2212 k it must hold that UD+k \u222a{D} 6\u2282 UD+y . However, as D + k \u2282 D + l , there must be at least one diagnosis among those in D\u2212k which is an element of D + l . If there is exactly one such diagnosis D\u2217, then we obtain a contradiction immediately as UD+l = UD+k \u222a{D\u2217} 6\u2282 UD+y . Otherwise, we observe that, if there is a set D\u2032 \u2286 D\u2212k of multiple such diagnoses, then there is a single diagnosis D\u2032 \u2208 D\u2032 \u2286 D \u2212 k such that UD+l = UD+k \u222aD\u2032\n\u2287 UD+k \u222a{D\u2032} wherefore we can infer that UD+l 6\u2282 UD+y must hold. Consequently, the transformation Pk 7\u2192 Ps is indeed minimal and (ii) is proven.\nAd 2.: Assume that Pk 7\u2192 Ps is a minimal D+-transformation and that Ps cannot be constructed as per (1a), (1b) and (1c).\nBy Corollary 21, there must be some D+y such that D + s := {Di | Di \u2208 D,D (y) i = \u2205} and D\u2212s := {Di | Di \u2208 D,D(y)i 6= \u2205}. Thence, for each minimal D+-transformation there is some D+y such that (1b) \u2227 (1c) is true wherefore we obtain that \u00ac(1a) must be given. That is, at least one of the following must be false: (i) there is someD \u2208 D\u2212k such that D+y = D + k \u222a{D}, (ii) UD+y \u2282 UD, (iii) UD+y is subset-minimal among all D \u2208 D\u2212k . First, Ps is a canonical q-partition by the definition of a minimal D+-transformation (see Definition 18) and the assumption that Pk 7\u2192 Ps is a minimal D+-transformation. Now, by the argumentation in the proof of (1.) above, which yielded that UD+y = UD+s must hold, and by Proposition 53, UD+y \u2282 UD cannot be false.\nSecond, from the argumentation just given before, we know that there is some D+y such that D + s and\nD\u2212s are defined as per (1b) and (1c). Let us assume that D + y = D + k \u222a S where S \u2286 D \u2212 k with |S| \u2265 2. Then there is someD \u2208 D\u2212y such that D+y \u2283 D+k \u222a{D} and therefore UD+y \u2287 UD+k \u222a{D}. Let Ps\u2032 be the canonical q-partition induced by D+y\u2032 := D + k \u222a {D} as per (1b) and (1c). Note that it is guaranteed that Ps\u2032 is a canonical q-partition due to Corollary 21. Further on, the assumption that Pk 7\u2192 Ps is a minimal D+-transformation means that Ps is a canonical q-partition. But, by Corollary 21, by UD+y \u2287 UD+k \u222a{D} and by Eq. 33, it must hold for Ps\u2032 and Ps that D+s\u2032 \u2286 D+s . Thus, we conclude that either Pk 7\u2192 Ps is not a minimal D+-transformation (case D+s\u2032 \u2282 D+s ) or Ps can be constructed by means of D + k \u222a{D} for some D \u2208 D\u2212k (case D + s\u2032 = D + s ). The former case is a contradiction to the assumption that Pk 7\u2192 Ps is a minimal D+-transformation, and the latter case conflicts with the assumption that Ps cannot be constructed as per (1a), (1b) and (1c).\nThird, from the argumentation so far, we can assume that D+y used to construct Ps can be written as D+k \u222a {D} for some D \u2208 D \u2212 k . Now, if UD+y is not subset-minimal among all D \u2208 D \u2212 k , then there is some D\u2032 \u2208 D\u2212k such that UD+k \u222a{D\u2032} \u2282 UD+y . Let Ps\u2032 be the canonical q-partition induced by D+y\u2032 := D + k \u222a{D\u2032} as per (1b) and (1c). Note that it is guaranteed that Ps\u2032 is a canonical q-partition due to Corollary 21. In addition, the latter, along with Eq. 33, assures that D+s \u2287 D+s\u2032 due to UD+k \u222a{D\u2032} \u2282 UD+y . Moreover, by Corollary 21, D \u2208 D+s since D \u2286 UD+y , but D /\u2208 D + s\u2032 due to D 6\u2286 UD+k \u222a{D\u2032}. To realize that the latter holds, assume the opposite, i.e. D \u2286 UD+k \u222a{D\u2032}. Then, since UD+k \u2286 UD+k \u222a{D\u2032} and UD+k \u222a{D} = UD+k \u222a D, we obtain that UD+k \u222a{D\u2032} \u2287 UD+k \u222a{D} = UD+y , a contradiction. All in all, we derived that D+s \u2287 D+s\u2032 and D+s 6= D + s\u2032 due to D \u2208 D+s \\D + s\u2032 . Thence, D + s \u2283 D+s\u2032 , which constitutes a contradiction to the assumption that Pk 7\u2192 Ps is a minimal D+-transformation. Ad 3.: By Proposition 53, we must demonstrate that (i) UD+r \u2282 UD and (ii) there is no D \u2208 D \u2212 r such that D \u2286 UD+r for any \u3008D + r ,D \u2212 r , \u2205\u3009 where D \u2283 D+r \u2287 D+k and { D(k)i | D (k) i \u2208 D \u2212 k } are pairwise disjoint. Ad (i): Let us first assume that UD+r = UD. The unions of diagnoses of both sets D + k and D \u2212 k must\ncomprise all axioms occurring in some diagnosis in D, i.e. UD = UD+k \u222a UD\u2212k . However, since by definition each D(k)i is exactly the subset of Di \u2208 D \u2212 k that is disjoint from UD+k , we obtain that UD =\nUD+k \u222aU{D(k)i | Di\u2208D\u2212k }. Since D+k \u222aD\u2212k = D \u2283 D+r and D+r \u2287 D+k , there must be some S\u2032 \u2282 D\u2212k such that D+r = D + k \u222aS\u2032. By UD+r = UD we can conclude that UD = UD+r = UD+k \u222aU { D(k)i | Di\u2208S\u2032\n}. Further on, it follows from D+r \u2282 D and the definition of S\u2032 that D \\D+r = D \\ (D+k \u222aS\u2032) = (D \\D + k ) \\S\u2032 = D\u2212k \\ S\u2032 \u2283 \u2205. So, there is at least one diagnosis Dm \u2208 D \u2212 k such that\n(I) Dm /\u2208 S\u2032,\n(II) D(k)m \u2229 UD+k = \u2205, and\n(III) D(k)m \u2286 Dm \u2286 UD\nwhereas the latter two facts hold due to the definition of D(k)m , see Eq. (33). As Dm \u2208 D\u2212k , by Corollary 21, D(k)m 6= \u2205 must hold. Moreover, (II) and (III) yield that D(k)m \u2286 U{D(k)i | Di\u2208S\u2032} which is, by (I), obviously a contradiction to the pairwise disjointness of elements in { D(k)i | Di \u2208 D \u2212 k } .\nAd (ii): According to the argumentation of (i), we already know that UD+r = U { D(k)i | Di\u2208S\u2032 } \u222a UD+k for some S\u2032 \u2282 D\u2212k and that there is a diagnosis D \u2208 D\u2212r = D \u2212 k \\ S\u2032. Let Dm be an arbitrary diagnosis in D\u2212r . We observe that Dm /\u2208 S\u2032. Let us assume that Dm \u2286 UD+r holds. Then, D (k) m \u2286 Dm \u2286 UD+r .\nMoreover, since D(k)m \u2229 UD+k = \u2205 by the definition of D (k) m , see Eq. (33), D(k)m \u2286 U{D(k)i | Di\u2208S\u2032} must be valid. Now, in an analogue way as in (i) above, we obtain a contradiction to the pairwise disjointness of elements in { D(k)i | Di \u2208 D \u2212 k } .\nProposition 54 shows that the set of minimal diagnoses D+y := D + k \u222a {D} with D \u2208 D \u2212 k used to construct the canonical q-partition Ps that results from the q-partition Pk by means of a minimal D+-transformation is not necessarily equal to the set D+s of Ps. In fact, it might be the case that further minimal diagnoses (in addition toD) must be transferred from D\u2212k to D+s in order to make Ps a canonical q-partition. We call these further diagnoses the necessary followers of D w.r.t. Pk, formally:\nDefinition 19. Let D \u2286mD\u3008K,B,P,N \u3009R and Pk = \u3008D + k ,D \u2212 k , \u2205\u3009 be a canonical q-partition of D. Then, we call D\u2032 \u2208 D\u2212k a necessary D+-follower of D \u2208 D \u2212 k w.r.t. Pk, NF + Pk\n(D\u2032,D) for short, iff for any canonical q-partition \u3008S\u2032,D \\ S\u2032, \u2205\u3009 with S\u2032 \u2287 D+k \u222a {D} it holds that D\u2032 \u2208 S\u2032.\nThe idea is now to define a relation between two elements of D\u2212k iff both of them lead to the same canonical q-partition if added to D+k :\nDefinition 20. Let D \u2286mD\u3008K,B,P,N \u3009R and Pk = \u3008D + k ,D \u2212 k , \u2205\u3009 be a canonical q-partition of D. Then, we denote by \u223c the binary relation over D\u2212k defined as Di \u223c Dj iff D (k) i = D (k) j . Moreover, we call D(k)i the trait of the equivalence class [Di]\u223c w.r.t. \u223c including Di.18\nThe following proposition is obvious:\nProposition 55. \u223c is an equivalence relation. 18Sometimes we will call D(k)i simply the trait of Di.\nA simple corollary derivable from Proposition 54 and Definition 19 is the following. It enables to characterize the successors of a canonical q-partition Pk resulting from a minimal D+-transformation by means of the traits of the equivalence classes w.r.t. \u223c. This is essentially the basis for Snext:\nCorollary 23. Let D \u2286 mD\u3008K,B,P,N \u3009R and Pk be a canonical q-partition of D. Further, let Ps = \u3008D+s ,D\u2212s , \u2205\u3009 where D+s ,D\u2212s are as defined in Proposition 54,(1b) and (1c). Then, D is an element of D\u2212k such that D + y = D + k \u222a {D} is as defined in Proposition 54,(1a) iff\n1. D is in the same equivalence class w.r.t. \u223c as all D\u2032 with NF+Pk(D \u2032,D).\n2. [D]\u223c has a subset-minimal trait among all elements D \u2208 D\u2212k .\nThe Computation of Successors. Our successor function for D+-partitioning is specified by Algorithm 8. The input to it is a partition Pk. The output is a set of all canonical q-partitions that result from Pk by a minimal D+-transformation. First, the algorithm checks in line 5 whether Pk = \u3008\u2205,D, \u2205\u3009, i.e. whether Pk is the initial state or, equivalently, the root node of the search tree. If so (case Sinit), then Corollary 20 is directly exploited to generate all successors of Pk, i.e. one canonical q-partition \u2329 {D} ,D\u2212k \\ {D} , \u2205\n\u232a for each leading diagnosis D \u2208 D. Otherwise (case Snext), Pk must be a canonical q-partition due to Corollary 20 and Proposition 54. That is, Corollary 23 is applicable and used to extract all equivalence classes w.r.t. \u223c with subset-minimal traits for Pk (lines 9-38) as a first step.\nIn that, the traits for the diagnoses\u2019 equivalence classes w.r.t. \u223c are computed in lines 9-11 according to Definition 20. Note that we assume during the while-loop, without explicitly showing it in the pseudocode, that the trait ti for the equivalence class of a diagnosis Di is extracted from the precalculated set of tuples of the form \u3008Di, ti\u3009 stored in diagsTraits.\nMoreover, the for-loop in line 18 iterates over Dused which includes one representative of all diagnoses equivalence classes which are known to yield an already explored, i.e. a non-new, q-partition if deleted from D\u2212k and added to D + k . The test in line 19 checks whether the trait ti of the currently analyzed diagnosis Di is equal to some trait tu of a diagnosis Du in Dused. If so, then D(k)i = D (k) u (cf. Definition 20) which is why Di and Du belong to the same equivalence class. By Corollary 23, an addition of Di to D+k would imply the addition of (the entire equivalence class of) Du to D + k and hence not yield a new q-partition. Therefore, we neglect the equivalence class of Di (which is equal to the equivalence class of Du) as a basis for constructing a successor q-partition of Pk. This is accounted for by setting diagAlreadyUsed to true forDi in line 20. Only if this boolean flag for some diagnosis Di is false (line 35), the respective equivalence class of Di is later (line 36) added to eqClasses, from which the finally output successor q-partitions are generated.\nAs a second step (lines 39-40), all successors (constructed by means of minimal D+-transformations) of Pk \u2013 one for each equivalence class \u2013 are constructed by means of the elements in these equivalence classes. That is, given that one of these equivalence classes consists of the minimal diagnoses in the set E \u2286 D\u2212k , then one successor of Pk is given by \u2329 D+k \u222a E,D \u2212 k \\ E, \u2205 \u232a . These successors, stored in sucs, are finally returned by the algorithm. Further comments and helpful annotations can be found next to the pseudocode in Algorithm 8."}, {"heading": "3.5 Finding Optimal Queries Given an Optimal Q-Partition", "text": "By now, we have demonstrated in Section 3.4 how a (sufficiently) optimal q-partition w.r.t. any measure discussed in Section 3.2 can be computed. What we also have at hand so far is one particular welldefined query for the identified \u201cbest\u201d q-partition, namely the canonical query. If we impose no further constraints on the query than an optimal associated q-partition (which already guarantees optimal features of the query w.r.t. the used query quality measure), then we are already done and can simply output the canonical query and ask the user to answer it. However, in many practical scenarios, we can expect that\na least quality criterion apart from an optimal q-partition is the set-minimality of queries. That means that we will usually want to minimize the number of logical formulas appearing in a query and hence the effort given for the user to walk through them and answer the query. In other words, we consider the consultation of the user a very expensive \u201coperation\u201d. Another (usually additional) quality criterion might be the understandability of the query for the respective interacting user. In case there are some fault probabilities for this particular user available to the debugging system, one can try to minimize the weight of the returned query in terms of these probabilities. Intuitively, if e.g. (a) the sum of fault probabilities of formulas in a query is minimal, then we might rate the probability of the user having understanding difficulties regarding the set of formulas that constitute the query as minimal. Another approach could be to postulate that (b) the maximal fault probability of single formulas appearing in a query must be minimized. This would reflect a situation where each formula should be as easy to understand as possible. In this case (b), queries with a higher cardinality than in (a) might be favored in case all single fault probabilities of formulas in the query for (b) are lower than some fault probability of a formula in the best query for (a).\nThe problem we tackle now is how to obtain a set-minimal query associated with a given canonical q-partition (that has been returned by the FINDQPARTITION function described in Section 3.4) given this q-partition and the related canonical query i.e. how to implement the SELECTQUERYFORQPARTITION function in Algorithm 2. In other words, the intention is to minimize the canonical query in size while preserving the associated q-partition. At first sight, we might simply choose to employ the same approach that has been exploited in [20, 21, 27]. This approach involves the usage of a modification of an algorithm called QuickXPlain (QX for short; originally due to [7]19) which implements a divide-and-conquer strategy with regular calls to a reasoning service to find one set-minimal subsetQ\u2032 (of generally exponentially many) of a given query Q such that P(Q\u2032) = P(Q). Although the number of calls to a reasoner required by QX in order to extract a set-minimal query Q\u2032 from a query Q is polynomial in O(|Q\u2032| log2 |Q| |Q\u2032| ), we will learn in this section that we can in fact do without any calls to a reasoner. This is due to the task constituting of a search for a set-minimal explicit-entailments query given an explicit-entailments query.\nSubsequently, we give two lemmata that provide essential information about the properties satisfied by all explicit-entailments queries associated with a given q-partition P. In particular, if we consider the lattice (2DiscAxD ,\u2286) (where 2DiscAxD denotes the powerset of DiscAxD) consisting of all subsets of DiscAx which are partially ordered by \u2286, Lemma 4, given a q-partition P, characterizes the set of all lower bounds of the set of explicit-entailments queries Q \u2286 DiscAxD associated with P in the lattice. All these lower bounds are themselves elements of the set of explicit-entailments queries w.r.t. P.\nLemma 4. Let D \u2286 mD\u3008K,B,P,N \u3009R , P = \u3008D +,D\u2212, \u2205\u3009 be a q-partition w.r.t. D and Q \u2286 DiscAxD an (explicit-entailments) query associated with P. Then Q\u2032 \u2286 Q is a query with associated q-partition P iff Q\u2032 \u2229 Di 6= \u2205 for each Di \u2208 D\u2212.\nProof. \u201c\u21d0\u201d: Proof by contraposition. Assume there is a Di \u2208 D\u2212 such that Q\u2032 \u2229 Di = \u2205. Then K\u2217i = (K \\Di) \u222a B \u222a UP \u2287 Q\u2032 since K \\Di \u2287 DiscAxD \\ Di \u2287 Q\u2032. From this K\u2217i |= Q\u2032 follows by the fact that the entailment relation in L is extensive. As a result, we have that Di \u2208 D+(Q\u2032). Consequently, as Di \u2208 D\u2212, the q-partition of Q\u2032 must differ from the q-partition P of Q.\n\u201c\u21d2\u201d: Proof by contradiction. Assume that Q\u2032 \u2286 Q is a query with q-partition P and Q\u2032 \u2229 Di = \u2205 for some Di \u2208 D\u2212. Then (K \\ Di) \u222aQ\u2032 = (K \\ Di) since Q\u2032 \u2286 Q \u2286 DiscAxD \u2286 K and Q\u2032 \u2229 Di = \u2205. Therefore K\u2217i \u222a Q\u2032 = K\u2217i which implies that Q\u2032 \u2286 K\u2217i and thus K\u2217i |= Q\u2032 due the extensive entailment relation in L. Consequently, Di \u2208 D+(Q\u2032) must hold. SinceDi \u2208 D\u2212, we can derive that the q-partition of Q\u2032 is not equal to the q-partition P of Q, a contradiction.\nNext, Lemma 5 defines the set of all upper bounds of the set of explicit-entailments queries Q \u2286 DiscAxD associated with a given q-partition P. In fact, it will turn out that this set is a singleton containing\n19A formal proof of correctness, a detailed description and examples can be found in [20, Sec. 4.4.1].\nexactly the canonical query associated with P. In other words, the canonical query is the unique least superset w.r.t. \u2286 (and hence a supremum) of all explicit-entailments queries associated with P.\nLemma 5. Let D \u2286 mD\u3008K,B,P,N \u3009R , P = \u3008D +,D\u2212, \u2205\u3009 be a q-partition w.r.t. D and Q \u2286 DiscAxD an (explicit-entailments) query associated with P. Then Q\u2032 with DiscAxD \u2287 Q\u2032 \u2287 Q is a query with associated q-partition P iff Q\u2032 \u2286 UD \\ UD+ .\nProof. \u201c\u21d2\u201d: Proof by contraposition. If Q\u2032 6\u2286 UD \\ UD+ then there is an axiom ax \u2208 Q\u2032 such that ax /\u2208 UD \\UD+ . This implies that ax \u2208 UD+ because ax \u2208 Q\u2032 \u2286 DiscAxD = UD \\ ID which means in particular that ax \u2208 UD. Consequently, ax \u2208 Dj for some diagnosis Dj \u2208 D+ must apply which is why K\u2217j \u222aQ\u2032 must violate some x \u2208 R \u222a N due to the subset-minimality of Dj . As a result, Dj must belong to D\u2212(Q\u2032) and since Dj 6\u2208 D\u2212, we obtain that the q-partition P(Q\u2032) of Q\u2032 is different from P.\n\u201c\u21d0\u201d: Direct proof. If Q\u2032 \u2287 Q and Q\u2032 \u2286 UD \\ UD+ , then for each Di \u2208 D+ it holds that K\u2217i |= Q\u2032 by the fact that the entailment relation in L is extensive and as Q\u2032 \u2286 UD \\ UD+ \u2286 K \\Di \u2286 K\u2217i . Hence, each Di \u2208 D+ is an element of D+(Q\u2032).\nFor each Dj \u2208 D\u2212, K\u2217j \u222a Q\u2032 must violate some x \u2208 R \u222a N by the monotonicity of the entailment relation in L and since K\u2217j \u222aQ violates some x \u2208 R \u222a N as well as Q\u2032 \u2287 Q. Thus, each Dj \u2208 D\u2212 is an element of D\u2212(Q\u2032).\nSo far, we have shown that D+ \u2286 D+(Q\u2032) as well as D\u2212 \u2286 D\u2212(Q\u2032). To complete the proof, assume that that some of these set-inclusions is proper, e.g. D+ \u2282 D+(Q\u2032). In this case, by D0 = \u2205, we can deduce that there is some D \u2208 D\u2212 such that D \u2208 D+(Q\u2032). This is clearly a contradiction to the fact that D\u2212 \u2286 D\u2212(Q\u2032) and the disjointness of the sets D+(Q\u2032) and D\u2212(Q\u2032) which must hold by Proposition 3,(1.). The other case D+ \u2282 D+(Q\u2032) can be led to a contradiction in an analogue way. Hence, we conclude that P(Q\u2032) = P.\nIn order to construct a minimize an explicit-entailments query for a fixed q-partition \u3008D+,D\u2212, \u2205\u3009, one needs to find a minimal hitting set of all diagnoses in D\u2212, as the following proposition states. Let in the following MHS(X) denote the set of all minimal hitting sets of the collection of sets X .\nProposition 56. Let D \u2286 mD\u3008K,B,P,N \u3009R and P = \u3008D +,D\u2212, \u2205\u3009 be a q-partition w.r.t. D. Then Q \u2286 DiscAxD is a query with q-partition P iff there is some H \u2208 MHS(D\u2212) such that H \u2286 Q \u2286 Qcan(D+).\nProof. The left set inclusion follows directly from Lemma 4. The right set inclusion can be derived as follows. First, by Lemma 5, Q \u2286 UD \\ UD+ holds. Second, we have that Qcan(D+) := DiscAxD \u2229 Eexp(D\n+) = (UD \\ ID)\u2229 (K \\UD+) = (UD \u2229K) \\ (ID \u222aUD+) = UD \\UD+ since UD \u2286 K (UD is a union of diagnoses and diagnoses are subsets ofK, cf. Definition 4) and ID \u2286 UD+ (ID is the intersection of all diagnoses in D, hence a subset of all diagnoses in D and in particular of the ones in D+ \u2282 D, hence a subset of the union UD+ of diagnoses in D+).\nBy means of Proposition 56, the search for set-minimal queries given a fixed (canonical) q-partition P = \u3008D+,D\u2212, \u2205\u3009 is easily accomplished by building a hitting set tree of the collection of sets D\u2212 in breadth-first manner (cf. [20, Sec. 4.5.1] and originally [19]). Let the complete hitting set tree be denoted by T . Then the set of all set-minimal queries with associated q-partition P is given by\n{H(n) | n is a node of T labeled by valid (X)}\nwhere H(n) denotes the set of edge labels on the path from the root node to the node n in T . We want to make the reader explicitly aware of the fact that the main source of complexity when constructing a hitting set tree is usually the computation of the node labels which is normally very expensive, e.g. needing calls to a reasoning service. In our situation, however, all the sets used to label the nodes of the tree are already explicitly given. Hence the construction of the hitting set tree will usually be very efficient in the light of the fact that the number of diagnoses in D\u2212 are bounded above by |D| which\nis a predefined fixed parameter (which is normally relatively small, e.g. \u2248 10, cf. [27, 21]). Apart from that, we are usually satisfied with a single set-minimal query which implies that we could stop the tree construction immediately after having found the first node labeled by valid.\nDespite of this search being already very efficient, it can in fact be even further accelerated. The key observation to this end is that each explicit-entailments query w.r.t. Pk = \u2329 D+k ,D \u2212 k , \u2205 \u232a , by Lemma 5 and Proposition 56, must not include any axioms in UD+ . This brings us back to Eq. 33 which characterizes the trait D(k)i := Di \\ UD+k of a diagnosis Di \u2208 D \u2212 k (cf. Definition 20) given Pk. Let in the following Tr(Pk) denote the set of all traits of diagnoses in D\u2212k w.r.t. the q-partition Pk. Actually, we can state the following which is a straightforward consequence of Proposition 56:\nCorollary 24. Let D \u2286 mD\u3008K,B,P,N \u3009R and Pk = \u3008D + k ,D \u2212 k , \u2205\u3009 be a q-partition w.r.t. D. Then Q \u2286 DiscAxD is a set-minimal query with q-partition Pk iff Q = H for some H \u2208 MHS(Tr(Pk)).\nContrary to minimal diagnoses, traits of minimal diagnoses might be equal to or proper subsets of one another (see Example 10). By [20, Prop. 12.6] which states\nIf F is a collection of sets, and if S \u2208 F and S\u2032 \u2208 F such that S \u2282 S\u2032, then Fsub := F \\{S\u2032} has the same minimal hitting sets as F .\nwe can replace Tr(Pk) by Trsetmin(Pk) in Corollary 24 where Trsetmin(Pk) terms the set of all setminimal traits of diagnoses in D\u2212k w.r.t. Pk, i.e. all traits t in Tr(Pk) for which there is no trait t\n\u2032 in Tr(Pk) such that t\u2032 \u2282 t.\nIn case some axiom preference criteria or axiom fault probabilities p(ax ) for axioms ax \u2208 K are available to the debugging system and should be taken into account as mentioned at the beginning of this section, then the hitting set tree could alternatively be constructed e.g. by using a uniform-cost search strategy preferring nodes n for labeling with\n\u2022 (MinSum) a minimal sum \u2211\nax\u2208H(n) p(ax ) (to realize (a) in the first paragraph of this section) or\n\u2022 (MinMax) a minimal maxax\u2208H(n) p(ax ) (to realize (b) in the first paragraph of this section)\ninstead of breadth-first. In this case, the search would detect subset-minimal queries compliant with these criteria first.\nBefore we explicate the algorithm resulting from the ideas given in this section, consider the following remark.\nRemark 14 We want to underline that the insights gained in this section enable us to construct a setminimal query w.r.t. a given q-partition systematically. That is, we are capable of detecting minimized queries with particular properties (first). If required, for instance, we can in this way guarantee that we present only queries w.r.t. a given q-partition P to the user which have least cardinality among all queries w.r.t. P. When using QX to minimize a query in a manner its q-partition is preserved (cf. [20, 21, 27]), one has little influence on the properties of a query that is returned. One more or less gets any setminimal query w.r.t. the given q-partition or, put another way, one cannot prove in general that properties of interest such as minimum cardinality or minimal sum of probabilities as mentioned above hold for the output of QX. Taking into account the fact that set-minimal subsets with a (monotonic20) property (e.g.: the same q-partition) of a set can have a non-negligible range of cardinalities, the ability to locate minimum-cardinality queries might bring significant savings in terms of the effort for a user to answer them.\n20A property is monotonic iff the binary function that returns 1 if the property holds for the input set and 0 otherwise is a monotonic function (cf. [20, p. 46]).\nThe Algorithm\nAlgorithm 9 presents the pseudocode for the selection of one, some or all set-minimal queries w.r.t. a given q-partition based on the discussion in this section. A very similar hitting set algorithm \u2013 intended for the computation of minimal diagnoses from minimal conflict sets \u2013 appeared in [20, Algorithm 2 on p. 66]. We solely made minor modifications to adapt it to our setting for query computation. The principle, however, remains exactly the same, and so do the optimality, soundness and correctness proofs given in [20, Sec. 4.5.2 and Sec. 4.6.3]. In what follows, we provide a walkthrough of Algorithm 9 strongly based on the one given in [20, Sec. 4.5.1].\nNotation. A node n in Algorithm 9 is defined as the set of formulas that label the edges on the path from the root node to n. In other words, we associate a node n with H(n). In this vein, Algorithm 9 internally does not store a labeled tree, but only \u201crelevant\u201d sets of nodes. That is, it does not store any\n\u2022 non-leaf nodes,\n\u2022 labels of non-leaf nodes, i.e. it does not store which set-minimal trait labels which node,\n\u2022 edges between nodes,\n\u2022 labels of edges and\n\u2022 leaf nodes labeled by closed.\nLet T denote the (partial) HS-tree produced by Algorithm 9 at some point during its execution. Then, Algorithm 9 only stores\n\u2022 a set of nodes Qcalc where each node corresponds to the set of edge labels along a path in T leading to a leaf node that has been labeled by valid (set-minimal queries associated with the q-partition Pk given as an input to the algorithm) and\n\u2022 a list of open (non-closed) nodes Queue where each node in Queue corresponds to the edge labels along a path in T leading from the root node to a leaf node that has been generated, but has not yet been labeled.\nThis internal representation of the constructed (partial) HS-tree does not constrain the functionality of the algorithm. This holds as queries are paths from the root, i.e. nodes in the internal representation, and the goal of a the HS-tree is to determine set-minimal queries. The node labels or edge labels along a certain path and their order along this path is completely irrelevant when it comes to finding a label for the leaf node of this path. Instead, only the set of edge labels is required for the computation of the label for a leaf node. Also, to rule out nodes corresponding to non-set-minimal queries, it is sufficient to know the set of already found set-minimal queries Qcalc. No already closed nodes are needed for the correct functionality of Algorithm 9. Inputs. The algorithm takes as input a q-partition Pk = \u2329 D+k ,D \u2212 k , \u2205 \u232a w.r.t. D \u2286 mD\u3008K,B,P,N \u3009R , a probability measure p (assigning probabilities to formulas in K), some search strategy strat, a desired computation timeout time, and a desired minimal (nmin) as well as maximal (nmax) number of setminimal queries with associated q-partition P to be returned. Within the algorithm, strat determines whether breadth-first or either strategy in {(MinSum),(MinMax)} as discussed in this section is to be used. It is exploited to keep the queue of open nodes sorted in the respective order to achieve desired properties of the (first) found queries. The meaning of nmin, nmax and time is that the algorithm computes at least the nmin best (w.r.t. strat) set-minimal queries with associated q-partition Pk and goes on computing\nfurther next best set-minimal queries until either the overall computation time reaches the time limit time or nmax diagnoses have been computed. Note that this feature enabling the computation of an arbitrary number of (existing) set-minimal queries is not needed in the default case where only a single set-minimal query, namely the best w.r.t. strat, is demanded. However, acting with foresight, one can use this feature to precompute a range of set-minimal queries for the case that a user rejects the query and requests an alternative one. If only a single query should be computed, this can be accomplished by the setting nmin = nmax := 1 (value of time is irrelevant in this case).\nInitialization. First, Algorithm 9 computes the set of traits of all diagnoses in D\u2212k and stores it in traits (lines 2-5). Next, it applies the function DELETENONSETMINIMALSETS to traits in order to clean this set from non-set-minimal traits resulting in the set setminTraits (line 6). Then, it calls the HS-tree function HS passing the same parameters as discussed in the Inputs paragraph above, except that Pk is replaced by setminTraits (simply denoted by traits within the HS function).\nAs first steps in HS, the variable timestart is initialized with the current system time (function GETTIME), the set of calculated set-minimal queries Qcalc is initialized with the empty set and the ordered queue of open nodes Queue is set to a list including the empty set only (i.e. only the unlabeled root node).\nThe Main Loop. Within the loop (line 12) the algorithm gets the node to be processed next, namely the first node node (GETFIRST, line 13) in the list of open nodes Queue ordered by the search strategy strat and (optionally, if strat requires probabilities) p, and removes node from Queue.\nComputation of Node Labels. Then, a label is computed for node in line 14. Nodes are labeled by valid, closed or a set-minimal trait (i.e. an element of traits) by the procedure LABEL (line 24 ff.). This procedure gets as inputs the current node node, the set traits, the already computed set-minimal queries (Qcalc) and the queue Queue of open nodes, and it returns a label for node. It works as follows:\nA node node is labeled by closed iff\n\u2022 there is an already computed set-minimal query that is a subset of this node, which means that node cannot be a set-minimal query (non-minimality criterion, lines 25-27) or\n\u2022 there is some node nd in the queue of open nodes Queue such that node = nd which means that one of the two tree branches with an equal set of edge labels can be closed, i.e. removed from Queue (duplicate criterion, lines 28-30).\nIf none of these closed-criteria is met, the algorithm searches for some t in traits such that t\u2229node = \u2205 and returns the label t for node (lines 31-33). This means that the path represented by node cannot be a query as there is (at least) one set-minimal trait, namely t, that is not hit by node (cf. Corollary 24).\nIf none of the mentioned criteria is satisfied, then node must be a hitting set of all set-minimal traits. Furthermore, is must represent a minimal hitting set. Hence, valid is returned by LABEL in this case.\nUsing strat prescribing a breath-first search strategy, the minimality of node is guaranteed by the sorting of Queue by ascending node cardinality and the non-minimality criterion (see above) which is tested first within the LABEL function. In case strat dictates the usage of (MinSum), then, since all formula probabilities are required to be larger than zero, any subset of a node n in Queue must be processed before n is processed (as this subset must have a strictly smaller sum of formulas\u2019 probabilities than n). Minimality of the hitting set node is then also enforced by the non-minimality criterion. If (MinMax) is used, then the Queue must be sorted in ascending order by maximal probability of an element (i.e. a formula) in a node (as the maximum of a set can only get larger or remain constant if the set grows) and, if two nodes are equal w.r.t. this criterion, then the minimum cardinality node has to be given precedence. Then, also in this case, the non-minimality criterion guarantees minimality of the hitting set node.\nProcessing of a Node Label. Back in the main procedure, the label L returned by LABEL is processed as follows:\nIf L = valid, then node is added to the set of calculated set-minimal queries Qcalc. If, L = closed, then there is either a query in Qcalc that is a subset of the current node node or a duplicate of node is already included in Queue. Consequently, node must simply be removed from Queue which has already been executed in line 13.\nIn the third case, if a set-minimal trait L is returned in line 14, then L is a label for node meaning that |L| successor nodes of node need to be inserted into Queue in a way the order as per strat in Queue is maintained (INSERTSORTED, line 21)."}, {"heading": "3.6 Query Enrichment", "text": "So far, we have explicated how we can obtain an explicit-entailments query which\n\u2022 is set-minimal,\n\u2022 has optimal properties regarding user effort (minimal size) or comprehensibility (minimal sum of fault probabilities) and\n\u2022 has optimal properties w.r.t. diagnosis discrimination (optimal value w.r.t. some query quality measure m).\nHowever, sometimes a user might find it hard to directly assess the correctness of axioms formulated by herself or by some other author, i.e. by being asked to classify axioms occurring explicitly in the KB as correct of faulty in the intended domain. One reason for this can be the complexity of axioms in the KB. Moreover, especially in case the axiom was specified by the interacting user, the user is usually convinced that the axiom is OK. Probably most of the people tend to work to the best of their knowledge and, being aware of this, have particular problems when it comes to recognizing and realizing their own faults. Instead, it might be easier, less error-prone and more convenient for users to be presented with a query including simple formulas not in the KB that need to be assessed regarding their truth in the domain the user intends to model.\nTherefore, we deal in this section with the ENRICHQUERY function in Algorithm 2. This function realizes the expansion of a given explicit-entailments query Q \u2286 K w.r.t. a set of leading diagnoses D \u2286mD\u3008K,B,P,N \u3009R by (finitely many) additional formulas \u03b11, . . . , \u03b1r. In that, we postulate that\n1. \u03b11, . . . , \u03b1r /\u2208 K \u222a B \u222a UP , that\n2. \u03b11, . . . , \u03b1r are non-explicit entailments of some consistent subset S \u2287 Q of K \u222a B \u222a UP and that\n3. no \u03b1i for i \u2208 {1, . . . , r} is an entailment of S \\Q.\nIn other words, we want to extract a set of implicit entailments from S that depend on Q, i.e. which hold only in the presence of (some axioms in) Q. This is equivalent to the postulation that J \u2229Q 6= \u2205 for each justification J \u2208 \u22c3r i=1 Just(\u03b1i, S).\nTo accomplish that, we require a reasoning service that, given a set of formulas X in the logic L, deterministically returns a set E(X) of (not only explicit) entailments of X such that (R1) E(X \u2032) \u2286 E(X \u2032\u2032) whenever X \u2032 \u2282 X \u2032\u2032 and (R2) if Y \u2286 X \u2032 \u2282 X \u2032\u2032, then for all entailments eY of Y it holds that eY \u2208 E(X \u2032) iff eY \u2208 E(X \u2032\u2032). One possibility to realize such a service is to employ a reasoner for the logic L and use it to extract all entailments of a predefined type it can compute (cf. [20, Remark 2.3 and p. 101]). For propositional Horn logic, e.g. one might extract only all literals that are entailments of X . For general Propositional Logic, e.g. one might calculate all formulas of the form A B for propositional variablesA,B and logical operators \u2208 {\u2192,\u2194}, and for Description Logics [1], e.g. only\nall subsumption and/or class assertion formulas that are entailments could be computed. An example of entailment types that might be extracted for (decidable fragments of) first-order logic can be found in [20, Example 8.1].\nNow, assuming available such a function E, we propose to compute an enriched query Q\u2032 from an explicit-entailments query Q as\nQ\u2032 := Q \u222aQimpl (34)\nwhere\nQimpl := [ E ( (K \\ UD) \u222aQ \u222a B \u222a UP ) \\ E ( (K \\ UD) \u222a B \u222a UP )] \\ Q (35)\nRemark 15 It should be noted that only two calls to a reasoning engine (i.e. function E) are required to compute Q\u2032. The reader is also reminded of the fact that these are the first invocations of a reasoner in the entire query computation process described so far.\nNext, we prove that the requirements to the formulas Qimpl used to expand Q in terms of the enumeration (1.), (2.) and (3.) above are actually met by Eq. 35:\nProposition 57. Let D \u2286 mD\u3008K,B,P,N \u3009R , Q \u2286 K be an (explicit-entailments) query w.r.t. D and \u3008K,B,P ,N \u3009R with associated q-partition P = \u3008D+,D\u2212, \u2205\u3009 and let Qimpl = {\u03b11, . . . , \u03b1r} be defined as in Eq. 35. Then (1.)-(3.) (stated above) hold.\nProof. Ad 1.: The function E either does or does not compute explicit entailments (amongst other entailments). In case the function E does not compute explicit entailments, Qimpl clearly cannot contain any explicit entailments. Otherwise, we distinguish between explicit entailments in (K \\ UD) \u222a B \u222a UP and those in Q (clearly, there cannot be any other explicit entailments in Qimpl). Note that Q \u2286 UD \\UD+ \u2286 UD due to Lemma 5. Additionally, Q \u2229 B = \u2205 due to Q \u2286 K and Definition 1. And, Q \u2229 UP = \u2205 due to Q \u2286 UD and since no element of any minimal diagnosis D (in D), and hence no element in UD, can occur in UP . The latter holds as in case D\u2032 \u2229UP 6= \u2205 for D\u2032 \u2208 D we would have that D\u2032\u2032 := D\u2032 \\UP \u2282 D\u2032 is a diagnosis w.r.t. \u3008K,B,P ,N \u3009R, a contradiction to the subset-minimality of D\u2032. All in all, we have derived that (K \\ UD) \u222a B \u222a UP and Q are disjoint sets.\nNow, Qimpl cannot include any elements of (K \\ UD) \u222a B \u222a UP . This must be satisfied since, first, (K\\UD)\u222aB \u222aUP is a subset of the left- as well as right-hand E() expression in the definition of Qimpl (Eq. 35) and, second, both E() expressions must return the same set of entailments of (K\\UD)\u222aB\u222aUP by assumption (R2) made about the function E above. Therefore, the set defined by the squared brackets in Eq. 35 cannot include any (explicit) entailments of (K \\ UD) \u222a B \u222a UP .\nFurther on, Qimpl cannot contain any elements of Q. This is guaranteed by the elimination of all elements ofQ from the set defined by the squared brackets in Eq. 35. Finally, we summarize thatQimpl\u2229 (K \u222a B \u222a UP ) = \u2205.\nAd 2.: Clearly, by the definition of a diagnosis (Definition 4) and the definition of a DPI (Definition 1) which states that the requirements R specified in the DPI must include consistency, (K \\ D) \u222a B \u222a UP must be consistent for all D \u2208 D. In addition, since D+ 6= \u2205 (cf. Proposition 3,(6.)), there must be some diagnosis D\u2032 \u2208 D+ \u2282 D such that (K \\D\u2032)\u222aB \u222aUP |= Q. This implies that (K \\D\u2032)\u222aB \u222aUP \u222aQ is consistent. By UD \u2287 D\u2032 and by the monotonicity of the logic L we conclude that S := (K \\ UD) \u222a B \u222a UP \u222aQ is consistent.\nObviously, S \u2287 Q and, by the left-hand E() expression in Eq. 35, Qimpl includes entailments of S. Finally, by the proof of (1.) above, where we have shown that Qimpl \u2229 [(K\\UD)\u222aB\u222aUP \u222aQ] = \u2205, we immediately obtain that Qimpl \u2229 S = \u2205. That is, Qimpl does not include any explicit entailments of S.\nAd 3.: Assume that S is as defined in the proof of (2.) above and that there is some \u03b1i \u2208 Qimpl such that S \\Q |= \u03b1i. Then, (K \\ UD) \u222a B \u222a UP |= \u03b1i. However, in the proof of (1.) above we have derived that Qimpl cannot comprise any entailments of (K \\ UD) \u222a B \u222a UP . Hence, \u03b1i /\u2208 Qimpl, contradiction.\nWe sum up that (1.)-(3.) holds for Qimpl = {\u03b11, . . . , \u03b1r}.\nRemark 16 Please take a note of the fact that Qimpl = \u2205 in case there are no implicit entailments of (K \\ UD) \u222a Q \u222a B \u222a UP which are not entailed by (K \\ UD) \u222a B \u222a UP (cf. Eq. 35). In this case the enriched query Q\u2032 constructed from the explicit-entailments query Q is equal to Q.\nIt is crucial that the expanded query resulting from query enrichment given an input explicit-entailments query Q has the same q-partition as Q. Recall that we first selected the optimal q-partition for which we then chose Q as a query. Thence, of course, we want to preserve this q-partition throughout all further refinement operations applied to Q. The next proposition witnesses that query enrichment does in fact comply with this requirement. Note that the inclusion of Q itself in the enriched query Q\u2032 ensures the q-partition preservation.\nProposition 58. Let D \u2286 mD\u3008K,B,P,N \u3009R and Q \u2286 K be an (explicit-entailments) query w.r.t. D and \u3008K,B,P ,N \u3009R. Further, let Q\u2032 be defined as in Eq. 34. Then Q\u2032 is a query w.r.t. D and \u3008K,B,P ,N \u3009R and P(Q\u2032) = P(Q).\nProof. LetD \u2208 D+(Q). Then, (K\\D)\u222aB\u222aUP |= Q. Since the entailment relation in L is idempotent, we have that (*): (K \\ D) \u222a B \u222a UP \u222a Q \u2261 (K \\ D) \u222a B \u222a UP . Further, since Qimpl is a set of entailments of (K \\ UD) \u222a B \u222a UP \u222aQ (see left-hand E() expression in Eq. 35), by the monotonicity of the entailment relation in L and because of (K\\D)\u222aB \u222aUP \u222aQ \u2287 (K\\UD)\u222aB \u222aUP \u222aQ we deduce that (K \\ D) \u222a B \u222a UP \u222aQ |= Qimpl. By (*), (K \\ D) \u222a B \u222a UP |= Qimpl and (K \\ D) \u222a B \u222a UP |= Q which is why (K \\ D) \u222a B \u222a UP must entail Q\u2032 = Qimpl \u222aQ as well. Thus, D \u2208 D+(Q\u2032) holds.\nLet D \u2208 D\u2212(Q). Then, (K \\ D) \u222a B \u222a UP \u222aQ violates some x \u2208 R \u222a N . Due to the monotonicity of L and the fact that Q\u2032 = Qimpl \u222aQ \u2287 Q, we immediately obtain that (K \\D)\u222aB \u222aUP \u222aQ\u2032 violates some x \u2208 R \u222aN . Thus, D \u2208 D\u2212(Q\u2032).\nSince Q is an explicit-entailments query, Proposition 42 ensures that D0(Q) = \u2205. At this point, an analogue argumentation as we gave in the last paragraph of the proof of Lemma 5 can be used to realize that D+(Q) = D+(Q\u2032), D\u2212(Q) = D\u2212(Q\u2032) as well as D0(Q) = D0(Q\u2032). Hence, P(Q) = P(Q\u2032).\nTo sum up, Eq. 34 specifies\n\u2022 an enrichment of a given explicit-entailments query Q\n\u2022 by solely implicit entailments (set Qimpl) of a consistent part of the extended KB K \u222a B \u222a UP ,\n\u2022 such that each implicit entailment in Qimpl is dependent on Q, and\n\u2022 such that the enriched query has the same q-partition as Q.\nFor the sake of completeness, albeit implementing exactly Eq. 34, we present with Algorithm 10 the pseudocode illustrating how an enriched query complying with the postulations from the beginning of this section can be computed."}, {"heading": "3.7 Query Optimization", "text": "The enriched query Q\u2032 (Eq. 34) returned by the function ENRICHQUERY constitutes the input to the final function in Algorithm 2, i.e. OPTIMIZEQUERY. The objective of the latter is\n1. the q-partition-preserving minimization of Q\u2032 to obtain a set-minimal subset Qmin of Q\u2032. In addition, we postulate that\n2. OPTIMIZEQUERY must yield some Qmin such that Qmin \u2229Q = \u2205, if such a Qmin exists.\n3. Otherwise, if axiom preference criteria or axiom fault probabilities p(ax ) for ax \u2208 K are given, then Qmin is required to be the one query that minimizes the maximum probability over all axioms of Q occurring in it. More precisely,\nQmin := arg min S\u2208minQPPS(Q\u2032) (maxP(S,Q)) (36)\nwhere\nminQPPS(Q\u2032) := {X |X is set-minimal q-partition-preserving subset of Q\u2032} maxP(X,Q) := max\nax\u2208X\u2229Q (p(ax ))\nIn that, the set-minimality postulated by (1.) is required to avoid asking the user queries that comprise formulas which are not necessary in order to achieve the desired discrimination properties (which are determined by the q-partition) of the query. An explanation for demanding (2.), i.e. disjointness between Qmin and Q, is that formulas in the KB (those contained in the explicit-entailments query Q) are usually more complex in structure and hence for the interacting user more difficult to understand or interpret, respectively, than formulas that correspond to specific simple predefined entailment types such as, e.g. A\u2192 B for atoms A and B in case of Propositional Logic (cf. Section 3.6). In a situation where requirement (2.) is not satisfiable, we require that the maximum complexity (represented by the fault probability) of a formula from Q in Qmin is minimal. That is, assuming that all implicit entailments of predefined types are at least as easy to comprehend as the easiest formula in the KB (which is plausible, see above), (3.) corresponds to the requirement that the hardest formula in the query Qmin is easiest to understand for the user.\nTo realize (1.), as already mentioned in Section 3.6, we can apply a modified version of the QX algorithm [7]. This modified version of QX called MINQ is described, proven correct and illustrated by examples in [20, Chap. 8] (the MINQ algorithm is stated as part of Algorithm 4 on page 103 in [20]). To make this paper self-contained, we quote the relevant explanatory text regarding MINQ from [20] next.\nMINQ. Like QX (see, e.g. [20, p. 48]), MINQ, described in Algorithm 11 starting from line 4, carries out a divide-and-conquer strategy to find a set-minimal set with a monotonic property. In this case, the monotonic property is not the invalidity of a subset of the KB w.r.t. a DPI (as per Definition 3) as it is for the computation of minimal conflict sets using QX, but the property of some Qmin \u2282 Q having the same q-partition as Q. So, the crucial difference between QX and MINQ is the function that checks this monotonic property. For MINQ, this function \u2013 that checks a subset of a query for constant q-partition \u2013 is ISQPARTCONST (see Algorithm 11, line 15 ff.).\nMINQ \u2013 Input Parameters. MINQ gets five parameters as input. The first three, namelyX,Q andQB, are relevant for the divide-and-conquer execution, whereas the last two, namely the original q-partition\u2329 D+,D\u2212,D0 \u232a of the query (i.e. the parameter Q) that should be minimized, and the DPI \u3008K,B,P ,N \u3009R are both needed as an input to the function ISQPARTCONST. Besides the latter two, another argument QB is passed to this function where QB is a subset of the original query Q. ISQPARTCONST then checks whether the q-partition for the (potential) query QB is equal to the q-partition \u2329 D+,D\u2212,D0 \u232a of the original query given as an argument. The DPI is required as the parameters K,B,P ,N and R are necessary for these checks.\nMINQ \u2013 Testing Sub-Queries for Constant Q-Partition. The function ISQPARTCONST tests for each Dr \u2208 D\u2212 whether K\u2217r \u222a QB is valid (w.r.t. \u3008\u00b7, \u2205, \u2205, N\u3009R). If so, this means that Dr /\u2208 D\u2212(QB) and thus that the q-partition of QB is different to the one of Q why false is immediately returned. If true for all Dr \u2208 D\u2212, it is tested for Dr \u2208 D0 whether K\u2217r |= QB. If so, this means that Dr /\u2208 D0(QB) and thus that the q-partition of QB is different from the one of Q why false is immediately returned. If false is not returned for any Dr \u2208 D\u2212 or Dr \u2208 D0, then the conclusion is that QB is a query w.r.t. to D = D+ \u222a D\u2212 \u222a D0 and \u3008K,B,P ,N \u3009R and has the same q-partition as Q why the function returns true .\nTo check the validity as per Definition 3, ISQPARTCONST makes use of the function ISKBVALID (see Algorithm 11, line 23 ff.) which directly \u201cimplements\u201d Definition 3. To this end, ISKBVALID relies on the function VERIFYREQ (line 25) which, given a KB K\u2032 and a set of requirements R in the sense of Definition 1, returns true iff all requirements r \u2208 R are met for K\u2032.\nMINQ \u2013 The Divide-and-Conquer Strategy. Intuitively, MINQ partitions the given query Q in two parts Q1 and Q2 and first analyzes Q2 while Q1 is part of QB (line 12). Note that in each iteration QB is the subset of Q that is currently assumed to be part of the sought minimized query (i.e. the one query that will finally be output by MINQ). In other words, analysis of Q2 while Q1 is part of QB means that all irrelevant formulas in Q2 should be located and removed from Q2 resulting in Qmin2 \u2286 Q2. That is, Qmin2 must include only relevant formulas which means that Q min 2 along with QB is a query with an equal q-partition as Q, but the deletion of any further formula from Qmin2 changes the q-partition. After the relevant subset Qmin2 of Q2, i.e. the subset that is part of the minimized query, has been returned, Q1 is removed from QB, Qmin2 is added to QB and Q1 is analyzed for a relevant subset that is part of the minimized query (line 13). This relevant subset, Qmin1 , together with Q min 2 , then builds a set-minimal subset of the input Q that is a query and has a q-partition equal to that of Q. Note that the argument X of MINQ is the subset of Q that has most recently been added to QB.\nFor each call in line 12 or line 13, the input Q to MINQ is recursively analyzed until a trivial case arises, i.e. (a) until Q is identified to be irrelevant for the computed minimized query wherefore \u2205 is returned (lines 5 and 6) or (b) until |Q| = 1 and Q is not irrelevant for the computed minimized query wherefore Q is returned (lines 7 and 8).\nOPTIMIZEQUERY. While serving as a procedure to solve requirement (1.), MINQ as described in [20] does not yet satisfy requirements (2.) and (3.) from the beginning of this section. As we will learn next, we can accomplish (2.) and (3.) by using an appropriate order of formulas in Q\u2032. Bringing Q\u2032 into this order is the task of the SORT function which constitutes the first step in the OPTIMIZEQUERY function (Algorithm 11). The SORT function (line 2) effectuates thatQ\u2032 (which is the union of the implicit entailments Qimpl and the explicit ones Q, cf. Section 3.6) is sorted as\n[Qimpl, ascFP(Q)] (37)\nwhere [X,Y ] denotes a list containing first (i.e. leftmost) all elements of the collection X and then all elements of the collection Y , and asccrit(X) refers to the list of elements in the collection X sorted ascending based on crit. In our case crit := FP which means that given fault probabilities (which constitute or, respectively, can be used to compute formula fault probabilities) are used to sortQ ascending by formula probabilities.\nThe second and at the same time final step of OPTIMIZEQUERY is a call to MINQ to which Q\u2032, sorted as per Eq. 37, is passed as an argument. The output of this call to MINQ is then directly returned by Algorithm 11.\nFinally, we prove that the sorting according to Eq. 37 indeed yields the fulfillment of postulations (2.) and (3.) for the query Qmin returned by OPTIMIZEQUERY. The next proposition is easy, but rather elaborate to prove. Hence we omit the proof here.\nProposition 59. Let prop be some monotonic property, X = [x1, . . . , xk] be a sorted list and Xsub denote all set-minimal subsets of X which are equivalent to X w.r.t. prop. Then, used to find a setminimal subset of X which is equivalent to X w.r.t. prop, QX (and thus MINQ) always returns the set-minimal subsetXsub ofX with the leftmost rightmost element among all elements in Xsub. Formally:\nXsub = arg min X\u2208Xsub ( max xi\u2208X (i) ) (38)\nThe next corollary proves the compliance of MINQ used with a sorted input query Q\u2032 as per Eq. 37 with the requirements to the optimized output query Qmin stated at the beginning of this section.\nCorollary 25. Application of MINQ to the enriched query Q\u2032 = [x1, . . . , xk] with q-partition P = \u3008D+,D\u2212, \u2205\u3009 sorted as per Eq. 37 returns a query Qmin with q-partition P compliant with requirements (1.) - (3.) given at the beginning of this section.\nProof. Requirement (1.) follows directly from [20, Prop. 8.7]. To show that requirement (2.) must hold for the returned queryQmin, we must demonstrate the following: If there is some set-minimal queryQj \u2286 Q\u2032 satisfyingQj\u2229Q = \u2205, thenQmin\u2229Q = \u2205. So, let us assume that such aQj exists. Then,Qimpl 6= \u2205must hold byQ\u2032 = Qimpl\u222aQ and sinceQj is a query whyQj 6= \u2205. Moreover, Q 6= \u2205 due to Proposition 3,(6.) which states that D\u2212 must not be the empty set and due to Proposition 56 which states that Q must be a hitting set of all diagnoses in D\u2212. Taking into account the sorting of Q\u2032 = [Qimpl, ascFP(Q)] according to Eq. 37, we can infer that there is some r satisfying 1 < r \u2264 k such that xr is the formula with least index to belong to Q. Now, we can deduce that maxxi\u2208Qj (i) < r. Let Xsub denote all setminimal queries that are a subset of Q\u2032. Then, by Proposition 59, the returned query Qmin is equal to arg minX\u2208Xsub(maxxi\u2208X(i)). Hence, we have that maxxi\u2208Qmin(i) \u2264 maxxi\u2208Qj (i) < r which is why Qmin \u2229Q = \u2205 must be true.\nTo show that requirement (3.) is met for the returned queryQmin, we must demonstrate the following: If there is no set-minimal queryQj \u2286 Q\u2032 satisfyingQj\u2229Q = \u2205, then Eq. 36 must hold forQmin, i.e.Qmin is required to be the one query that minimizes the maximum probability over all axioms of Q occurring in it. Now, since no query Qj \u2286 Q\u2032 satisfying Qj \u2229 Q = \u2205 exists, we obtain that Qmin \u2229 Q 6= \u2205. The truth of Eq. 36 is now a direct consequence of Proposition 59 and the sorting of Q in ascending order of formula probabilities.\nAlgorithm 4 Update best q-partition Input: partitions P and Pbest (both with empty D0) w.r.t. the set of leading diagnoses D, requirements rm to an\noptimal q-partition, a (diagnosis) probability measure p Output: the better partition among {P,Pbest} w.r.t. D and rm; if both partitions are equally good w.r.t. D and rm,\nthen Pbest is returned 1: procedure UPDATEBEST(P,Pbest, p, rm) 2: D\u2190 D+(P) \u222aD\u2212(P) . reconstruct leading diagnoses from q-partition P 3: if m \u2208 {ENT} then . if m in eq. class 1\u00a9 w.r.t. Table 8 4: if |p(D+(P))\u2212 0.5| < |p(D+(Pbest))\u2212 0.5| then 5: Pbest \u2190 P 6: if m \u2208 {SPL} then . if m in eq. class 2\u00a9 w.r.t. Table 8 7: if\n\u2223\u2223\u2223 |D+(P)| \u2212 |D|2 \u2223\u2223\u2223 < \u2223\u2223\u2223 |D+(Pbest)| \u2212 |D|2 \u2223\u2223\u2223 then 8: Pbest \u2190 P 9: if m \u2208 {RIO} then . if m in eq. class 3\u00a9 w.r.t. Table 8 10: c\u2190 GETCAUT(rm) 11: n\u2190 dc|D|e 12: if |D+(P)| \u2265 n then 13: if |D+(Pbest)| < n then 14: Pbest \u2190 P . P is non-high-risk and Pbest high-risk q-partition 15: else if\n\u2223\u2223n\u2212 |D+(P)|\u2223\u2223 < \u2223\u2223n\u2212 |D+(Pbest)|\u2223\u2223 then 16: Pbest \u2190 P . both Pbest and P non-high-risk, but P less cautious 17: else if\n\u2223\u2223n\u2212 |D+(P)|\u2223\u2223 = \u2223\u2223n\u2212 |D+(Pbest)|\u2223\u2223 then 18: if\n\u2223\u22230.5\u2212 p(D+(P))\u2223\u2223 < \u2223\u22230.5\u2212 p(D+(Pbest))\u2223\u2223 then 19: Pbest \u2190 P . both non-high-risk, equally cautious, but P better ENT value 20: if m \u2208 {KL} then 21: KLbest \u2190 COMPUTEKL(Pbest) 22: KLnew \u2190 COMPUTEKL(P) 23: if KLnew > KLbest then 24: Pbest \u2190 P 25: if m \u2208 {EMCb} then 26: KLbest \u2190 COMPUTEEMCB(Pbest) 27: KLnew \u2190 COMPUTEEMCB(P) 28: if EMCbnew > EMCbbest then 29: Pbest \u2190 P 30: if m \u2208 {MPS} then . if m in eq. class 6\u00a9 w.r.t. Table 8 31: if |D+(P)| = 1 \u2227 p(D+(P)) > p(D+(Pbest)) then 32: Pbest \u2190 P 33: if m \u2208 {BME} then 34: D\u2032 \u2190 argminD\u2217\u2208{D+(P),D\u2212(P)}(p(D \u2217)) 35: D\u2032best \u2190 argminD\u2217\u2208{D+(Pbest),D\u2212(Pbest)}(p(D \u2217)) 36: if |D\u2032| > |D\u2032best| then 37: Pbest \u2190 P 38: return Pbest\nAlgorithm 5 Optimality check in D+-Partitioning Input: partition Pbest = \u2329 D+,D\u2212, \u2205 \u232a w.r.t. the set of leading diagnoses D, a threshold tm, a (diagnosis) probability\nmeasure p, requirements rm to an optimal q-partition, Output: true iff Pbest is an optimal q-partition w.r.t. rm and tm\n1: procedure OPT(Pbest, tm, p, rm) 2: if D+ = \u2205 \u2228D\u2212 = \u2205 then 3: return false . partition is not a q-partition, cf. Proposition 3,(6.) 4: D\u2190 D+ \u222aD\u2212 . reconstruct leading diagnoses from D+,D\u2212 5: if m \u2208 {ENT} then . if m in eq. class 1\u00a9 w.r.t. Table 8 6: if |p(D+)\u2212 0.5| \u2264 tm then 7: return true 8: return false 9: if m \u2208 {SPL} then . if m in eq. class 2\u00a9 w.r.t. Table 8\n10: if \u2223\u2223\u2223 |D+| \u2212 |D|2 \u2223\u2223\u2223 \u2264 tm then 11: return true 12: else 13: return false 14: if m \u2208 {RIO} then . if m in eq. class 3\u00a9 w.r.t. Table 8 15: c\u2190 GETCAUT(rm) 16: n\u2190 dc|D|e 17: tcard \u2190 GETCARDINALITYTHRESHOLD(tm) 18: tent \u2190 GETENTROPYTHRESHOLD(tm) 19: if |D+| \u2265 n then . Pbest is a non-high-risk q-partition 20: if |D+| \u2212 n \u2264 tcard then . Pbest is sufficiently cautious 21: if |p(D+)\u2212 0.5| \u2264 tent then . Pbest has sufficiently high information gain 22: return true 23: return false 24: if m \u2208 {KL} then 25: if\n\u2223\u2223\u2223 |D+||D| log2 ( 1p(D+))+ |D\u2212||D| log2 ( 1p(D\u2212))\u2212 optKL,p,D\u2223\u2223\u2223 \u2264 tm then . cf. Remark 4 26: return true 27: return false 28: if m \u2208 {EMCb} then 29: if\n\u2223\u2223p(Q = t)|D\u2212(Q)|+ p(Q = f)|D+(Q)| \u2212 optEMCb,p,D\u2223\u2223 \u2264 tm then . cf. Remark 5 30: return true 31: return false 32: if m \u2208 {MPS} then . if m in eq. class 6\u00a9 w.r.t. Table 8 33: if |D+| = 1 then 34: probmax \u2190 maxD\u2208D(p(D)) 35: if p(D+) = probmax then 36: return true 37: return false 38: if m \u2208 {BME} then 39: if p(D+) = 0.5 then 40: return false 41: if p(D+) < 0.5 \u2227\n\u2223\u2223|D+| \u2212 (|D| \u2212 1)\u2223\u2223 \u2264 tm then 42: return true 43: if p(D\u2212) < 0.5 \u2227\n\u2223\u2223|D\u2212| \u2212 (|D| \u2212 1)\u2223\u2223 \u2264 tm then 44: return true 45: return false\nAlgorithm 6 Pruning in D+-Partitioning\nInput: partitions P and Pbest w.r.t. the set of leading diagnoses D with D0(P) = D0(Pbest) = \u2205, requirements rm to an optimal q-partition, a (diagnosis) probability measure p Output: true if exploring successor q-partitions of P cannot lead to the discovery of q-partitions that are better w.r.t. rm than Pbest\n1: procedure PRUNE(P,Pbest, p, rm) 2: D\u2190 D+(P) \u222aD\u2212(P) . reconstruct leading diagnoses from partition P 3: if m \u2208 {ENT} then . if m in eq. class 1\u00a9 w.r.t. Table 8 4: if p(D+(P)) \u2265 0.5 then 5: return true 6: return false 7: if m \u2208 {SPL} then . if m in eq. class 2\u00a9 w.r.t. Table 8 8: if |D+(P)| \u2265 \u230a |D| 2 \u230b then\n9: return true 10: return false 11: if m \u2208 {RIO} then . if m in eq. class 3\u00a9 w.r.t. Table 8 12: c\u2190 GETCAUT(rm) 13: n\u2190 dc|D|e 14: if |D+(P)| = n then 15: return true 16: if |D+(Pbest)| = n then 17: if |D+(P)| > n then 18: return true 19: if p(D+(P))\u2212 0.5 \u2265 |p(D+(Pbest))\u2212 0.5| then . |D+(P)| < n holds 20: return true . p(D+(P)) \u2265 0.5 holds 21: return false 22: if m \u2208 {KL,EMCb} then 23: return false 24: if m \u2208 {MPS} then . if m in eq. class 6\u00a9 w.r.t. Table 8 25: if |D+(P)| \u2265 1 then 26: return true 27: else 28: return false 29: if m \u2208 {BME} then 30: if p(D\u2212(P)) < 0.5 then 31: return true 32: if p(D+(P)) < 0.5 then 33: if |D\u2212(P)| \u2212 1 \u2264 |D+(P)| then 34: probmin \u2190 minD\u2208D\u2212(P)(p(D)) 35: if p(D\u2212(P))\u2212 probmin < 0.5 then 36: return true 37: return false\nAlgorithm 7 Best successor in D+-Partitioning\nInput: a partition P, the set of successor q-partitions sucs of P (each resulting from P by a minimal D+transformation), a (diagnosis) probability measure p, requirements rm to an optimal q-partition Output: a tuple \u3008P\u2032,D\u3009 consisting of the best q-partition P\u2032 \u2208 sucs according to the implemented heuristics (the smaller the heuristics, the better the corresponding q-partitions) and some diagnosis D that has been added to D+(P\u2032) from D\u2212(P) in the course of the minimal D+-transformation that maps P to P\u2032\n1: procedure BESTSUC(P, sucs, p, rm) 2: Sbest \u2190 GETFIRST(sucs) 3: for S \u2208 sucs do 4: if HEUR(S, p, rm) < HEUR(Sbest, p, rm) then 5: Sbest \u2190 S 6: D+diff \u2190 D\n+(Sbest) \\D+(P) 7: D \u2190 GETFIRST(D+diff) 8: return \u3008Sbest,D\u3009 9: procedure HEUR(\u3008D+,D\u2212, \u2205\u3009, p, rm)\n10: D\u2190 D+ \u222aD\u2212 . reconstruct leading diagnoses from D+ and D\u2212 11: if m \u2208 {ENT} then . if m in eq. class 1\u00a9 w.r.t. Table 8 12: return |p(D+)\u2212 0.5| 13: if m \u2208 {SPL} then . if m in eq. class 2\u00a9 w.r.t. Table 8 14: return\n\u2223\u2223\u2223|D+| \u2212 |D|2 \u2223\u2223\u2223 15: if m \u2208 {RIO} then . if m in eq. class 3\u00a9 w.r.t. Table 8 16: c\u2190 GETCAUT(rm) 17: n\u2190 dc|D|e . to be accepted by RIO, D+ must include at least n diagnoses 18: numDiagsToAdd\u2190 n\u2212 |D+| . # of diagnoses to be added to D+ to achieve |D+| = n 19: avgProb\u2190 p(D\n\u2212) |D\u2212| . average probability of diagnoses that might be added to D + 20: return \u2223\u2223p(D+) + (numDiagsToAdd) \u2217 (avgProb)\u2212 0.5\u2223\u2223 21: if m \u2208 {KL,EMCb} then . |D +| |D| is expected value (E) of sum of prob. of |D +| diagnoses in D 22: return |D +|\n|D|p(D+) . the higher p(D +) compared to E, the better the heuristics for \u3008D+,D\u2212, \u2205\u3009\n23: if m \u2208 {MPS} then . if m in eq. class 6\u00a9 w.r.t. Table 8 24: return \u2212p(D+) 25: if m \u2208 {BME} then 26: if p(D+) < 0.5 then 27: return \u2212|D+| 28: if p(D+) > 0.5 then . p(D\u2212) < 0.5 29: return \u2212|D\u2212| 30: return 0 . p(D+) = p(D\u2212) = 0.5\nAlgorithm 8 Computing successors in D+-Partitioning\nInput: a partition Pk = \u3008D+k ,D \u2212 k , \u2205\u3009 w.r.t. D Output: the set of all canonical q-partitions sucs that result from Pk by a minimal D+-transformation 1: procedure GETD+SUCS(Pk,Dused) 2: sucs\u2190 \u2205 . stores successors of Pk that result from minimal D+-transformation 3: diagsTraits\u2190 \u2205 . stores tuples including a diagnosis and the trait of the eq. class w.r.t. \u223c it belongs to 4: eqClasses\u2190 \u2205 . set of sets of diagnoses, each set is eq. class with set-minimal trait, cf. Cor. 23 5: if D+k = \u2205 then . initial State, apply Sinit, cf. Cor. 20 6: for D \u2208 D\u2212k do 7: sucs\u2190 sucs \u222a {\u2329 {D} ,D\u2212k \\ {D} , \u2205\n\u232a} 8: else . Pk is canonical q-partition (due to Cor. 20 and Prop. 54), apply Snext 9: for Di \u2208 D\u2212k do\n10: ti \u2190 Di \\ UD+ k . compute trait of the eq. class of Di (cf. Def. 20) 11: diagsTraits\u2190 diagsTraits \u222a {\u3008Di, ti\u3009} . enables to retrieve ti for Di in operations below 12: diags\u2190 D\u2212k 13: minTraitDiags\u2190 \u2205 . to store one representative of each eq. class with set-minimal trait 14: sucsExist\u2190 false . will be set to true if Pk is found to have some canonical successor q-partition 15: while diags 6= \u2205 do 16: Di \u2190 GETFIRST(diags) . Di is first element in diags and then diags\u2190 diags \\ {Di} 17: diagAlreadyUsed\u2190 false . will be set to true if adding Di to D+k yields no new q-partition 18: for Du \u2208 Dused do 19: if tu = ti then 20: diagAlreadyUsed\u2190 true 21: break 22: necFollowers\u2190 \u2205 . to store all necessary followers of Di, cf. Def. 19 23: diagOK \u2190 true . will be set to false if Di is found to have a non-set-minimal trait 24: for Dj \u2208 diags \u222aminTraitDiags do 25: if ti \u2287 tj then 26: if ti = tj then . equal trait, Di and Dj are in same eq. class 27: necFollowers\u2190 necFollowers \u222a {Dj} . cf. Cor. 23 28: else . ti \u2283 tj 29: diagOK \u2190 false . eq. class of Di has a non-set-minimal trait 30: eqCls\u2190 {Di} \u222a necFollowers 31: if \u00acsucsExist \u2227 eqCls = D\u2212k then . test only executed in first iteration of while-loop 32: return \u2205 . Pk has single successor partition with D\u2212 = \u2205 which is thus no q-partition 33: sucsExist\u2190 true . existence of \u2265 1 canonical successor q-partition of Pk guaranteed 34: if diagOK then .D\u2212y := D\u2212k \u222a {Di} satisfies Prop. 54,(1a) 35: if \u00acdiagAlreadyUsed then . \u2329 D+k \u222a eqCls,D \u2212 k \\ eqCls, \u2205 \u232a is new q-partition 36: eqClasses\u2190 eqClasses \u222a {eqCls} 37: minTraitDiags\u2190 minTraitDiags \u222a {Di} . add one representative for eq. class 38: diags\u2190 diags \\ eqCls . delete all representatives for eq. class 39: for E \u2208 eqClasses do . construct all canonical successor q-partitions by means of eq. classes 40: sucs\u2190 sucs \u222a {\u2329 D+k \u222a E,D \u2212 k \\ E, \u2205\n\u232a} 41: return sucs\nAlgorithm 9 HS-Tree computation of set-minimal queries from a given q-partition Input: a q-partition Pk = \u2329 D+k ,D \u2212 k , \u2205 \u232a w.r.t. D \u2286 mD\u3008K,B,P,N\u3009R , probability measure p, query selection pa-\nrameters \u3008strat, time, nmin, nmax\u3009 consisting of search strategy strat, desired computation timeout time, a desired minimal (nmin) and maximal (nmax) number of set-minimal queries with associated q-partition P to be returned, Output: a set Q which is (a) a set of best (according to strat and possibly p) set-minimal queries with associated q-partition P such that nmin \u2264 |Q| \u2264 nmax, if at least nmin such queries exist, or (b) the set of all set-minimal queries with associated q-partition P otherwise\n1: procedure SELECTQUERYFORQPARTITION(Pk, p, \u3008strat, time, nmin, nmax\u3009) 2: traits\u2190 \u2205 3: for Di \u2208 D\u2212k do 4: ti \u2190 Di \\ UD+\nk . compute trait ti of Di (cf. Def. 20)\n5: traits\u2190 traits \u222a {ti} 6: setminTraits\u2190 DELETENONSETMINIMALSETS(traits) 7: return HS(setminTraits, p, strat, time, nmin, nmax) 8: procedure HS(traits, p, strat, time, nmin, nmax) 9: timestart \u2190 GETTIME()\n10: Qcalc \u2190 \u2205 . stores already computed set-minimal queries 11: Queue\u2190 [\u2205] . queue of open nodes 12: repeat . a node n represents the set of edge labels H(n) along its branch from the root node 13: node\u2190 GETFIRST(Queue) . node is first element in Queue and then Queue\u2190 Queue \\ {node} 14: L\u2190 LABEL(node, traits,Qcalc,Queue) 15: Ccalc \u2190 C 16: if L = valid then . node is a set-minimal query 17: Qcalc \u2190 Qcalc \u222a {node} 18: else if L = closed then . node is closed, hence do nothing 19: else . L must be a set-minimal trait 20: for e \u2208 L do 21: Queue\u2190 INSERTSORTED(node \u222a {e} ,Queue, strat, p) . generate successors 22: until Queue = [] \u2228 [|Qcalc| \u2265 nmin \u2227 (|Qcalc| = nmax \u2228 GETTIME()\u2212 timestart > time)] 23: return Qcalc 24: procedure LABEL(node, traits,Qcalc,Queue) 25: for nd \u2208 Qcalc do 26: if node \u2287 nd then . non-minimality 27: return closed 28: for nd \u2208 Queue do 29: if node = nd then . remove duplicates 30: return closed 31: for t \u2208 traits do 32: if t \u2229 node = \u2205 then . not-yet-hit trait found 33: return t 34: return valid\nAlgorithm 10 Query Enrichment Input: a DPI \u3008K,B,P ,N \u3009R, an explicit-entailments query Q w.r.t. \u3008K,B,P ,N \u3009R, the q-partition P =\u2329\nD+,D\u2212, \u2205 \u232a\nassociated with Q, a reasoner Rsnr, a set ET of entailment types (w.r.t. the used logic L) to be extracted (ET must be supported by the employed reasoner Rsnr) Output: a superset Q\u2032 of Q such that the set Qimpl := Q\u2032 \\ Q = {\u03b11, . . . , \u03b1r} satisfies requirements (1.) - (3.) stated at the beginning of Section 3.6\n1: procedure ENRICHQUERY(\u3008K,B,P ,N \u3009R, Q,P, Rsnr,ET ) 2: D\u2190 D+ \u222aD\u2212 3: E+Q \u2190 GETENTAILMENTS(ET,Rsnr, (K \\ UD) \u222aQ \u222a B \u222a UP ) 4: E\u2212Q \u2190 GETENTAILMENTS(ET,Rsnr, (K \\ UD) \u222a B \u222a UP ) 5: Qimpl \u2190 [E+Q \\ E\u2212Q] \\Q 6: Q\u2032 \u2190 Q \u222aQimpl 7: return Q\u2032\nAlgorithm 11 Query Optimization Input: a DPI \u3008K,B,P ,N \u3009R, a query Q\n\u2032 w.r.t. \u3008K,B,P ,N \u3009R for which a set-minimal subset with equal q-partition should be found, explicit-entailments query Q w.r.t. \u3008K,B,P ,N \u3009R such that Q \u2286 Q\n\u2032, q-partition P with associated queries Q and Q\u2032, fault information FP Output: a set-minimal subset Qmin of Q\u2032 such that Qmin satisfies requirements (2.) and (3.) stated at the beginning of Section 3.7\n1: procedure OPTIMIZEQUERY(Q\u2032, Q,P, \u3008K,B,P ,N \u3009R,FP) 2: Q\u2032 \u2190 SORT(Q\u2032, Q,FP) 3: return MINQ(\u2205, Q\u2032, \u2205,P, \u3008K,B,P ,N \u3009R) 4: procedure MINQ(X,Q,QB, \u2329 D+,D\u2212,D0 \u232a , \u3008K,B,P ,N \u3009R)\n5: if X 6= \u2205 \u2227 ISQPARTCONST(QB, \u2329 D+,D\u2212,D0 \u232a , \u3008K,B,P ,N \u3009R) then 6: return \u2205 7: if |Q| = 1 then 8: return Q 9: k \u2190 SPLIT(|Q|)\n10: Q1 \u2190 GET(Q, 1, k) 11: Q2 \u2190 GET(Q, k + 1, |Q|) 12: Qmin2 \u2190 MINQ(Q1, Q2, QB \u222aQ1, \u2329 D+,D\u2212,D0 \u232a , \u3008K,B,P ,N \u3009R)\n13: Qmin1 \u2190 MINQ(Qmin2 , Q1, QB \u222aQmin2 , \u2329 D+,D\u2212,D0 \u232a , \u3008K,B,P ,N \u3009R) 14: return Qmin1 \u222aQmin2 15: procedure ISQPARTCONST(Q, \u2329 D+,D\u2212,D0 \u232a , \u3008K,B,P ,N \u3009R) 16: for Dr \u2208 D\u2212 do 17: if ISKBVALID(K\u2217r \u222aQ, \u3008\u00b7, \u2205, \u2205,N \u3009R) then 18: return false 19: for Dr \u2208 D0 do 20: if K\u2217r |= Q then 21: return false 22: return true 23: procedure ISKBVALID(K, \u3008\u00b7,B,P ,N \u3009R) 24: K\u2032 \u2190 K \u222a B \u222a \u22c3 p\u2208P p 25: if \u00acVERIFYREQ(K\u2032,R) then 26: return false 27: for n \u2208 N do 28: if K\u2032 |= n then 29: return false 30: return true"}, {"heading": "4 Summary and Conclusion", "text": "In this work, we have tackled the problem of efficient query computation in interactive knowledge base debugging. The performance and scalability of query generation algorithms has a direct and material impact on the reaction time of the debugger (i.e. the time between the submission of an answered query until the appearance of the next one), alongside the time consumed by the (re-)calculation of candidate KB repairs which are exploited for the determination of query candidates.\nRoughly, the structure of this work can be categorized into five parts:\n1. Analysis of active learning query quality measures: We studied a variety of active learning measures, e.g. information gain, various manifestations of entropy measures or the Gini Index, that have been proposed in literature and a reinforcement learning system with a focus on their use in the scope of an interactive debugger. We determined the global optima, if existent, for all these quantitative measures, i.e. real-valued functions, and used these to extract a set of qualitative requirements a query must meet in order to optimize the respective measure. Further, we characterized a plausible preference order on queries, the debug-preference order, which indicates which queries are generally preferable to others. And we defined different equivalence relations over measures whose equivalence classes give information about for which classes of queries which measures lead to the same query selection behavior. Beyond that, we defined a superiority relation over query quality measures providing a preference criterion for measures w.r.t. the degree of their fulfillment of the debug-preference relation.\nWhat we found out is that only four of almost 20 discussed measures give us a guarantee to always give preference to the debug-preferred queries. These four are superior to all others. Another two measures are at least consistent with the debug-preference relation, whereas the rest is proven to generally violate this relation. Interestingly, the two measure that have already been used for KB debugging, belong to the latter two groups. However, for both measures, we developed slightly modified alternatives that grant fulfillment of the debug-preference relation. We gained insight that, up to equivalence, 15 of the investigated measures are different. For a restricted class of queries where all query pairs are indistinguishable in terms of debug-preference, 7 differently behaving measures remain up to equivalence over this restricted query space.\nIt could be demonstrated that a global optimum exists for all but two of the examined measures. From these global optima, sufficient and necessary requirements could be deduced. In case of the two measures having no optimal values, we were able to at least give a set of necessary criteria of the best query among a concrete set of queries. Such necessary criteria are helpful to restrict the search space for optimal queries.\nWe also introduced several parametrized measures constituting generalizations of existing measures and discussed their properties w.r.t. different used parameters. The results we obtained in this first part of the work are general and apply to any active learning scenario where binary queries are used, e.g. when the learner tries to find a binary classifier, and where each query partitions the hypothesis space into two (three) parts, one consistent only with the positive answer, the second consistent only with the negative answer (and the third consistent with both answers).\n2. Heuristic search for optimal q-partitions: In this part we exploited the qualitative requirements for active learning measures derived in the first part to devise a heuristic search method for the best q-partition. A q-partition is a partition of the set of candidate KB repairs into three subsets that incorporates all relevant information about an associated query regarding active learning, e.g. the possible elimination rate of repair candidates or the probabilities of query answers.\nSince (1) not each partition of the KB repair candidates is a q-partition, (2) the verification whether a partition is a q-partition requires a query, and (3) there can be exponentially many different queries\nfor one and the same q-partition, we introduced the notion of a canonical query, a well-defined, easily computable and unique query for a q-partition. The most notable advantage of a canonical query is that it enables the computation of queries completely without any expensive calls of a logical reasoner. Moreover, it ensures that no partitions which are no q-partitions (i.e. for which no query exists) can ever be considered in the search. Existing methods have to struggle with both of these issues, i.e. they rely on reasoner calls to figure out whether a candidate is actually a q-partition (query) and might generate many unnecessary partitions for which queries do not exist.\nThe search for q-partitions itself can be seen as a depth-first, \u201clocal best-first\u201d backtracking search. At each step, the best successor q-partition resulting from the current one by minimal changes is determined by means of heuristics based on the given qualitative requirements. The latter are also used to specify search tree pruning conditions that avoid the useless exploration of worse q-partitions than the currently best one.\nOnce a (sufficiently near to) optimal q-partition is detected, all queries (including the canonical one) associated with this q-partition have exactly the same quality w.r.t. the used query quality measure.\n3. Search for the best query w.r.t. an optimal q-partition: The goal of this part was to suggest a method of locating the best query w.r.t. the single optimal q-partition filtered out in the previous part. Theoretical analyses yielded that each set-minimal query associated with a given q-partition is a set-minimal hitting set of well-defined subsets, called traits, of all diagnoses in one part of the q-partition, namely the part comprising exactly the diagnoses that are inconsistent with the positive query answer. Hence, we explicated how such a hitting set tree search can be implemented and pointed out the crucial difference to most other scenarios where this kind of search is adopted, namely that all sets that must be \u201chit\u201d are known in advance. Hence, unlike the usual hitting set tree applications such as for the computation of KB repair candidates where the computation of the next set to be \u201chit\u201d is very expensive (involving e.g. reasoner calls), in our scenario the construction of the tree does not involve any expensive operations at all.\nIn addition to that, the fact that a hitting set tree can be employed for query extraction means that set-minimal queries can be generated in best-first order according to a desired criterion such as minimal query cardinality or best comprehensibility of the query for the interacting user. Existing approaches lack such a feature and provide only means to compute any set-minimal query. We point out that the entire query computation given a q-partition is accomplished without a single call to a logical reasoning service.\nConsequently, the proposed algorithms are the first methods that enable a completely reasonerfree query generation for interactive KB debugging while at the same time guaranteeing optimality conditions of the generated query that existing methods cannot realize.\n4. Enrichment of the optimal query: Optionally, our system provides the opportunity to enrich the single best query Q computed in the previous part with logical sentences of very simple predefined form, e.g. for Propositional Logic this form might be simple implications A \u2192 B with a single atom on both sides. The motivation to use this enrichment might be to simplify the query allowing for a better understanding of the interacting user. We formulated several requirements such a query enrichment operation must fulfill, e.g. the invariance of the q-partition. The reason is simply that the q-partition is already optimal and fixed and should of course not be altered as this would affect the quality of the query w.r.t. the used query quality measure (negatively). Another postulated criterion is the addition of exclusively such logical sentences which are \u201clogically dependent\u201d on Q. This is necessary to avoid the addition of just any logical statements and should restrict the number of such possible statements. This query enrichment step requires exactly two reasoner calls.\n5. Optimization of the enriched query: Given an enriched query, this part aimed at describing an approach to minimize this query again. However, just any minimization clearly will not do, as this would call into question the enrichment step before. On the contrary, we again had to impose conditions on this minimization step. In particular, we postulated that, under plausible assumptions, the difficulty of answering the resulting minimized query should be minimal among all possible query minimizations. Roughly, this involves that a minimum of the logical sentences that do not have the simple form of the enrichment sentences, should be eliminated from the enriched query. Furthermore, if there is no minimized query with all such sentences having been eliminated, then, simply put, these sentences should be as easily understandable as possible. By means of a slight modification of a well-known existing strategy for query minimization, we could devise a method that achieves exactly this. The crucial point in the performed modification is an appropriate ordering of the logical sentences in the query. This query minimization and optimization step requires only a polynomial number of reasoner calls."}], "references": [{"title": "eds.): The Description Logic Handbook: Theory, Implementation, and Applications", "author": ["F. Baader", "D. Calvanese", "D.L. McGuinness", "D. Nardi", "P.F. Patel-Schneider"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2007}, {"title": "What you always wanted to know about Datalog (and never dared to ask)", "author": ["S. Ceri", "G. Gottlob", "L. Tanca"], "venue": "IEEE Transactions on Knowledge and Data Engineering", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1989}, {"title": "A General Diagnosis Method for Ontologies", "author": ["G. Friedrich", "K. Shchekotykhin"], "venue": "Proceedings of the 4th International Semantic Web Conference (ISWC", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2005}, {"title": "OWL 2: The next step for OWL", "author": ["B.C. Grau", "I. Horrocks", "B. Motik", "B. Parsia", "P.F. Patel-Schneider", "U. Sattler"], "venue": "Web Semantics: Science, Services and Agents on the World Wide Web", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Laconic and Precise Justifications in OWL", "author": ["M. Horridge", "B. Parsia", "U. Sattler"], "venue": "Proceedings of the 7th International Semantic Web Conference (ISWC", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "Extracting justifications from BioPortal ontologies", "author": ["M. Horridge", "B. Parsia", "U. Sattler"], "venue": "Proceedings of the 11th International Semantic Web Conference (ISWC", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "QUICKXPLAIN: Preferred Explanations and Relaxations for Over-Constrained Problems", "author": ["U. Junker"], "venue": "Proceedings of the Nineteenth National Conference on Artificial Intelligence, Sixteenth Conference on Innovative Applications of Artificial Intelligence", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "Finding all Justifications of OWL DL Entailments", "author": ["A. Kalyanpur", "B. Parsia", "M. Horridge", "E. Sirin"], "venue": "ISWC 2007 + ASWC 2007. LNCS,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2007}, {"title": "Debugging Unsatisfiable Classes in OWL Ontologies", "author": ["A. Kalyanpur", "B. Parsia", "E. Sirin", "J. Hendler"], "venue": "Web Semantics: Science, Services and Agents on the World Wide Web 3(4),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2005}, {"title": "Reducibility among combinatorial problems", "author": ["R.M. Karp"], "venue": "Complexity of Computer Computations pp", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1972}, {"title": "SRIQ and SROIQ are harder than SHOIQ", "author": ["Y. Kazakov"], "venue": "Proceedings of the 21st Workshop of Description Logics", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "The incredible ELK", "author": ["Y. Kazakov", "M. Kr\u00f6tzsch", "F. Siman\u010d\u00edk"], "venue": "Journal of automated reasoning 53(1),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Diagnosing multiple faults", "author": ["J. de Kleer", "B.C. Williams"], "venue": "Artificial Intelligence", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1987}, {"title": "A complete anytime algorithm for number partitioning", "author": ["R.E. Korf"], "venue": "Artificial Intelligence", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1998}, {"title": "OWL 2 Web Ontology Language Structural Specification and Functional-Style Syntax", "author": ["B. Motik", "P.F. Patel-Schneider", "B. Parsia"], "venue": "W3C recommendation pp", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Linear and Nonlinear Programming. (The McGraw-Hill Companies, Inc", "author": ["S.G. Nash", "A. Sofer"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1996}, {"title": "Debugging OWL ontologies", "author": ["B. Parsia", "E. Sirin", "A. Kalyanpur"], "venue": "Proceedings of the 14th international conference on World Wide Web", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2005}, {"title": "OWL Web Ontology Language Semantics and Abstract Syntax", "author": ["P.F. Patel-Schneider", "P. Hayes", "I Horrocks"], "venue": "W3C recommendation", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2004}, {"title": "A Theory of Diagnosis from First Principles", "author": ["R. Reiter"], "venue": "Artificial Intelligence 32(1),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1987}, {"title": "Interactive Debugging of Knowledge Bases", "author": ["P. Rodler"], "venue": "Ph.D. thesis, Alpen-Adria Universita\u0308t Klagenfurt", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "RIO: Minimizing User Interaction in Ontology Debugging", "author": ["P. Rodler", "K. Shchekotykhin", "P. Fleiss", "G. Friedrich"], "venue": "Web Reasoning and Rule Systems, Lecture Notes in Computer Science,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}, {"title": "Top-down induction of decision trees classifiers \u2013 a survey", "author": ["L. Rokach", "O. Maimon"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2005}, {"title": "Artificial Intelligence: A Modern Approach", "author": ["S.J. Russell", "P. Norvig"], "venue": "Pearson Education,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2010}, {"title": "Debugging Incoherent Terminologies", "author": ["S. Schlobach", "Z. Huang", "R. Cornet", "F. Harmelen"], "venue": "Journal of Automated Reasoning 39(3),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2007}, {"title": "Query strategy for sequential ontology debugging", "author": ["K. Shchekotykhin", "G. Friedrich"], "venue": "Proceedings of the 9th International Semantic Web Conference (ISWC", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2010}, {"title": "Interactive Ontology Debugging: Two Query Strategies for Efficient Fault Localization", "author": ["K. Shchekotykhin", "G. Friedrich", "P. Fleiss", "P. Rodler"], "venue": "Web Semantics: Science, Services and Agents on the World Wide Web 12-13,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2012}, {"title": "Sequential diagnosis of high cardinality faults in knowledge-bases by direct diagnosis generation", "author": ["K. Shchekotykhin", "G. Friedrich", "P. Rodler", "P. Fleiss"], "venue": "Proceedings of the 21st European Conference on Artificial Intelligence (ECAI", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2014}, {"title": "Debugging OWL Ontologies - A Reality Check", "author": ["H. Stuckenschmidt"], "venue": "Proceedings of the 6th International Workshop on Evaluation of Ontology-based Tools and the Semantic Web Service Challenge (EON)", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2008}], "referenceMentions": [{"referenceID": 23, "context": "To cope with such faulty KBs (violating test cases and/or requirements), diverse systems for KB debugging [24, 8, 3, 5] have been developed.", "startOffset": 106, "endOffset": 119}, {"referenceID": 7, "context": "To cope with such faulty KBs (violating test cases and/or requirements), diverse systems for KB debugging [24, 8, 3, 5] have been developed.", "startOffset": 106, "endOffset": 119}, {"referenceID": 2, "context": "To cope with such faulty KBs (violating test cases and/or requirements), diverse systems for KB debugging [24, 8, 3, 5] have been developed.", "startOffset": 106, "endOffset": 119}, {"referenceID": 4, "context": "To cope with such faulty KBs (violating test cases and/or requirements), diverse systems for KB debugging [24, 8, 3, 5] have been developed.", "startOffset": 106, "endOffset": 119}, {"referenceID": 9, "context": "the Hitting Set Problem [10] for localization of possible KB repairs or the SAT Problem [10] for reasoning and consistency checking (in case of a Propositional Logic KB, worse for more expressive logics, e.", "startOffset": 24, "endOffset": 28}, {"referenceID": 9, "context": "the Hitting Set Problem [10] for localization of possible KB repairs or the SAT Problem [10] for reasoning and consistency checking (in case of a Propositional Logic KB, worse for more expressive logics, e.", "startOffset": 88, "endOffset": 92}, {"referenceID": 3, "context": "the Web Ontology Language OWL 2, for which reasoning is 2-NEXPTIME-complete [4, 11]), the usage of such non-interactive systems is often problematic.", "startOffset": 76, "endOffset": 83}, {"referenceID": 10, "context": "the Web Ontology Language OWL 2, for which reasoning is 2-NEXPTIME-complete [4, 11]), the usage of such non-interactive systems is often problematic.", "startOffset": 76, "endOffset": 83}, {"referenceID": 27, "context": "This is substantiated by [29] where several (non-interactive) debugging systems were put to the test using faulty real-world KBs.", "startOffset": 25, "endOffset": 29}, {"referenceID": 24, "context": "For example, in [26] a sample study of real-world KBs revealed that the number of different (set-)minimal diagnoses might exceed thousand by far (1782 minimal diagnoses for a KB with only 1300 formulas).", "startOffset": 16, "endOffset": 20}, {"referenceID": 20, "context": "Additionally, fault meta information might be misleading [21, 27] resulting in completely unreasonable solutions proposed by the system.", "startOffset": 57, "endOffset": 65}, {"referenceID": 25, "context": "Additionally, fault meta information might be misleading [21, 27] resulting in completely unreasonable solutions proposed by the system.", "startOffset": 57, "endOffset": 65}, {"referenceID": 24, "context": "As a remedy for this dilemma, interactive KB debugging systems [26, 27, 21, 20, 28] were proposed.", "startOffset": 63, "endOffset": 83}, {"referenceID": 25, "context": "As a remedy for this dilemma, interactive KB debugging systems [26, 27, 21, 20, 28] were proposed.", "startOffset": 63, "endOffset": 83}, {"referenceID": 20, "context": "As a remedy for this dilemma, interactive KB debugging systems [26, 27, 21, 20, 28] were proposed.", "startOffset": 63, "endOffset": 83}, {"referenceID": 19, "context": "As a remedy for this dilemma, interactive KB debugging systems [26, 27, 21, 20, 28] were proposed.", "startOffset": 63, "endOffset": 83}, {"referenceID": 26, "context": "As a remedy for this dilemma, interactive KB debugging systems [26, 27, 21, 20, 28] were proposed.", "startOffset": 63, "endOffset": 83}, {"referenceID": 19, "context": "Figure 1: The principle of interactive KB debugging [20].", "startOffset": 52, "endOffset": 56}, {"referenceID": 19, "context": "the reader is referred to [20].", "startOffset": 26, "endOffset": 30}, {"referenceID": 8, "context": "6] [9]).", "startOffset": 3, "endOffset": 6}, {"referenceID": 26, "context": "4% reported in [28]) of overall debugging costs, it is material to reduce the number of reasoner calls in order to achieve a performance gain in KB debugging.", "startOffset": 15, "endOffset": 19}, {"referenceID": 25, "context": "Whereas in literature only three measures, namely split-in-half, entropy and RIO [27, 21, 20, 28, 26], have been analyzed and discussed, we investigate eight further (active learning [25]) measures that might be favorably employed in interactive debuggers and deduce heuristics from them.", "startOffset": 81, "endOffset": 101}, {"referenceID": 20, "context": "Whereas in literature only three measures, namely split-in-half, entropy and RIO [27, 21, 20, 28, 26], have been analyzed and discussed, we investigate eight further (active learning [25]) measures that might be favorably employed in interactive debuggers and deduce heuristics from them.", "startOffset": 81, "endOffset": 101}, {"referenceID": 19, "context": "Whereas in literature only three measures, namely split-in-half, entropy and RIO [27, 21, 20, 28, 26], have been analyzed and discussed, we investigate eight further (active learning [25]) measures that might be favorably employed in interactive debuggers and deduce heuristics from them.", "startOffset": 81, "endOffset": 101}, {"referenceID": 26, "context": "Whereas in literature only three measures, namely split-in-half, entropy and RIO [27, 21, 20, 28, 26], have been analyzed and discussed, we investigate eight further (active learning [25]) measures that might be favorably employed in interactive debuggers and deduce heuristics from them.", "startOffset": 81, "endOffset": 101}, {"referenceID": 24, "context": "Whereas in literature only three measures, namely split-in-half, entropy and RIO [27, 21, 20, 28, 26], have been analyzed and discussed, we investigate eight further (active learning [25]) measures that might be favorably employed in interactive debuggers and deduce heuristics from them.", "startOffset": 81, "endOffset": 101}, {"referenceID": 6, "context": "Finally, we show how a well-known divide-and-conquer technique [7] can be adapted to compute a set-minimal reduction of the enriched query (keeping the q-partition and optimality w.", "startOffset": 63, "endOffset": 66}, {"referenceID": 1, "context": "3 Examples of logics that comply with these requirements include, but are not restricted to Propositional Logic, Datalog [2], (decidable fragments of) First-order Predicate Logic, The Web Ontology Language (OWL [18], OWL 2 [4, 15]), sublanguages thereof such as the OWL 2 EL Profile (with polynomial time reasoning complexity [12]) or various Description Logics [1].", "startOffset": 121, "endOffset": 124}, {"referenceID": 17, "context": "3 Examples of logics that comply with these requirements include, but are not restricted to Propositional Logic, Datalog [2], (decidable fragments of) First-order Predicate Logic, The Web Ontology Language (OWL [18], OWL 2 [4, 15]), sublanguages thereof such as the OWL 2 EL Profile (with polynomial time reasoning complexity [12]) or various Description Logics [1].", "startOffset": 211, "endOffset": 215}, {"referenceID": 3, "context": "3 Examples of logics that comply with these requirements include, but are not restricted to Propositional Logic, Datalog [2], (decidable fragments of) First-order Predicate Logic, The Web Ontology Language (OWL [18], OWL 2 [4, 15]), sublanguages thereof such as the OWL 2 EL Profile (with polynomial time reasoning complexity [12]) or various Description Logics [1].", "startOffset": 223, "endOffset": 230}, {"referenceID": 14, "context": "3 Examples of logics that comply with these requirements include, but are not restricted to Propositional Logic, Datalog [2], (decidable fragments of) First-order Predicate Logic, The Web Ontology Language (OWL [18], OWL 2 [4, 15]), sublanguages thereof such as the OWL 2 EL Profile (with polynomial time reasoning complexity [12]) or various Description Logics [1].", "startOffset": 223, "endOffset": 230}, {"referenceID": 11, "context": "3 Examples of logics that comply with these requirements include, but are not restricted to Propositional Logic, Datalog [2], (decidable fragments of) First-order Predicate Logic, The Web Ontology Language (OWL [18], OWL 2 [4, 15]), sublanguages thereof such as the OWL 2 EL Profile (with polynomial time reasoning complexity [12]) or various Description Logics [1].", "startOffset": 326, "endOffset": 330}, {"referenceID": 0, "context": "3 Examples of logics that comply with these requirements include, but are not restricted to Propositional Logic, Datalog [2], (decidable fragments of) First-order Predicate Logic, The Web Ontology Language (OWL [18], OWL 2 [4, 15]), sublanguages thereof such as the OWL 2 EL Profile (with polynomial time reasoning complexity [12]) or various Description Logics [1].", "startOffset": 362, "endOffset": 365}, {"referenceID": 23, "context": "5Coherency was originally defined for Description Logic (DL) KBs [24, 17] and postulates that there is no concept C in a DL KB KDL such that KDL |= C v \u22a5.", "startOffset": 65, "endOffset": 73}, {"referenceID": 16, "context": "5Coherency was originally defined for Description Logic (DL) KBs [24, 17] and postulates that there is no concept C in a DL KB KDL such that KDL |= C v \u22a5.", "startOffset": 65, "endOffset": 73}, {"referenceID": 19, "context": "[20] Given a DPI \u3008K,B,P ,N \u3009R, the task is to find a maximal solution KB w.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "Please notice that due to the restriction on canonical solution KBs we use a definition of a diagnosis in this work that is less general than the one given in [20] (but still does not affect the set of diagnoses w.", "startOffset": 159, "endOffset": 163}, {"referenceID": 18, "context": "\u3008K,B,P ,N \u3009R, the size of which is in general O(2|K|) (if all subsets of the KB K are investigated), can be reduced to a great extent by exploiting the notion of a conflict set [19, 13, 27].", "startOffset": 177, "endOffset": 189}, {"referenceID": 12, "context": "\u3008K,B,P ,N \u3009R, the size of which is in general O(2|K|) (if all subsets of the KB K are investigated), can be reduced to a great extent by exploiting the notion of a conflict set [19, 13, 27].", "startOffset": 177, "endOffset": 189}, {"referenceID": 25, "context": "\u3008K,B,P ,N \u3009R, the size of which is in general O(2|K|) (if all subsets of the KB K are investigated), can be reduced to a great extent by exploiting the notion of a conflict set [19, 13, 27].", "startOffset": 177, "endOffset": 189}, {"referenceID": 2, "context": "[3] A (minimal) diagnosis w.", "startOffset": 0, "endOffset": 3}, {"referenceID": 19, "context": "As described comprehensively in [20], this might be accomplished by the usage of a hitting set tree (originally due to Reiter [19]) along with a method such as QuickXPlain (originally due to Junker [7]).", "startOffset": 32, "endOffset": 36}, {"referenceID": 18, "context": "As described comprehensively in [20], this might be accomplished by the usage of a hitting set tree (originally due to Reiter [19]) along with a method such as QuickXPlain (originally due to Junker [7]).", "startOffset": 126, "endOffset": 130}, {"referenceID": 6, "context": "As described comprehensively in [20], this might be accomplished by the usage of a hitting set tree (originally due to Reiter [19]) along with a method such as QuickXPlain (originally due to Junker [7]).", "startOffset": 198, "endOffset": 201}, {"referenceID": 19, "context": "For details we want to refer the reader to [20].", "startOffset": 43, "endOffset": 47}, {"referenceID": 24, "context": "For example, a sample study of real-world KBs [26] detected 1782 different minimal diagnoses for a KB with only 1300 formulas.", "startOffset": 46, "endOffset": 50}, {"referenceID": 25, "context": "\u3008K,B,P ,N \u3009R [27].", "startOffset": 13, "endOffset": 17}, {"referenceID": 25, "context": "[27, 21, 26], a q-partition is often simply referred to as partition.", "startOffset": 0, "endOffset": 12}, {"referenceID": 20, "context": "[27, 21, 26], a q-partition is often simply referred to as partition.", "startOffset": 0, "endOffset": 12}, {"referenceID": 24, "context": "[27, 21, 26], a q-partition is often simply referred to as partition.", "startOffset": 0, "endOffset": 12}, {"referenceID": 12, "context": "Note that the UPDATEDPI function subsumes further operations which we do not consider in detail such as the (Bayesian) update [13] of the probability measure p based on the new information given by the answered query (see [20, Sec.", "startOffset": 126, "endOffset": 130}, {"referenceID": 24, "context": "discuss and study existing quantitative measures m already used in works on KB debugging [26, 27, 21] that can be employed in the CALCQUERY function in order to establish the goodness of queries (Section 3.", "startOffset": 89, "endOffset": 101}, {"referenceID": 25, "context": "discuss and study existing quantitative measures m already used in works on KB debugging [26, 27, 21] that can be employed in the CALCQUERY function in order to establish the goodness of queries (Section 3.", "startOffset": 89, "endOffset": 101}, {"referenceID": 20, "context": "discuss and study existing quantitative measures m already used in works on KB debugging [26, 27, 21] that can be employed in the CALCQUERY function in order to establish the goodness of queries (Section 3.", "startOffset": 89, "endOffset": 101}, {"referenceID": 20, "context": "introduce a new measure RIO (first presented in [21]) that is embedded in a reinforcement learning scheme and particularly tackles the problem that the performance (i.", "startOffset": 48, "endOffset": 52}, {"referenceID": 25, "context": "derive improved versions from some query quality measures \u2013 including those used in [27, 21, 26] \u2013 to overcome shortcomings unveiled in the conducted in-depth theoretical evaluations (Sections 3.", "startOffset": 84, "endOffset": 96}, {"referenceID": 20, "context": "derive improved versions from some query quality measures \u2013 including those used in [27, 21, 26] \u2013 to overcome shortcomings unveiled in the conducted in-depth theoretical evaluations (Sections 3.", "startOffset": 84, "endOffset": 96}, {"referenceID": 24, "context": "derive improved versions from some query quality measures \u2013 including those used in [27, 21, 26] \u2013 to overcome shortcomings unveiled in the conducted in-depth theoretical evaluations (Sections 3.", "startOffset": 84, "endOffset": 96}, {"referenceID": 24, "context": "Existing works [26, 21], on the other hand, do not exploit qualitative requirements rm but rely on the measure m using more or less a brute-force method for query selection.", "startOffset": 15, "endOffset": 23}, {"referenceID": 20, "context": "Existing works [26, 21], on the other hand, do not exploit qualitative requirements rm but rely on the measure m using more or less a brute-force method for query selection.", "startOffset": 15, "endOffset": 23}, {"referenceID": 25, "context": "In [27], qualitative requirements rm were already exploited together with the CKK algorithm [14] for the Two-Way Number Partitioning Problem9 to accelerate the search for a (nearly) optimal query w.", "startOffset": 3, "endOffset": 7}, {"referenceID": 13, "context": "In [27], qualitative requirements rm were already exploited together with the CKK algorithm [14] for the Two-Way Number Partitioning Problem9 to accelerate the search for a (nearly) optimal query w.", "startOffset": 92, "endOffset": 96}, {"referenceID": 25, "context": "Apart from that, we derive qualitative requirements for various other measures which are not addressed in [27].", "startOffset": 106, "endOffset": 110}, {"referenceID": 24, "context": "8] proposes and analyzes an improved variant of the basic query computation methods employed by [26, 21].", "startOffset": 96, "endOffset": 104}, {"referenceID": 20, "context": "8] proposes and analyzes an improved variant of the basic query computation methods employed by [26, 21].", "startOffset": 96, "endOffset": 104}, {"referenceID": 13, "context": "9Given a set of numbers, the Two-Way Number Partitioning Problem is to divide them into two subsets, so that the sum of the numbers in each subset are as nearly equal as possible [14].", "startOffset": 179, "endOffset": 183}, {"referenceID": 19, "context": "Building on the ideas of [20], e.", "startOffset": 25, "endOffset": 29}, {"referenceID": 24, "context": "Contrary to the works [26, 21, 20] which rely on a PS scenario, thus requiring the precomputation of a pool of queries (or q-partitions), we implement an approach that unites characteristics of QS and PS.", "startOffset": 22, "endOffset": 34}, {"referenceID": 20, "context": "Contrary to the works [26, 21, 20] which rely on a PS scenario, thus requiring the precomputation of a pool of queries (or q-partitions), we implement an approach that unites characteristics of QS and PS.", "startOffset": 22, "endOffset": 34}, {"referenceID": 19, "context": "Contrary to the works [26, 21, 20] which rely on a PS scenario, thus requiring the precomputation of a pool of queries (or q-partitions), we implement an approach that unites characteristics of QS and PS.", "startOffset": 22, "endOffset": 34}, {"referenceID": 20, "context": "[21] and Section 3.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13, 27]) or other criteria (cf.", "startOffset": 0, "endOffset": 8}, {"referenceID": 25, "context": "[13, 27]) or other criteria (cf.", "startOffset": 0, "endOffset": 8}, {"referenceID": 12, "context": "Moreover, we define according to [13, 27, 21, 20]", "startOffset": 33, "endOffset": 49}, {"referenceID": 25, "context": "Moreover, we define according to [13, 27, 21, 20]", "startOffset": 33, "endOffset": 49}, {"referenceID": 20, "context": "Moreover, we define according to [13, 27, 21, 20]", "startOffset": 33, "endOffset": 49}, {"referenceID": 19, "context": "Moreover, we define according to [13, 27, 21, 20]", "startOffset": 33, "endOffset": 49}, {"referenceID": 19, "context": "for some set of diagnoses X, with assuming that for X := D this sum is equal to 1 [20] (this can always be achieved by normalizing each diagnosis probability p(D) forD \u2208 D, i.", "startOffset": 82, "endOffset": 86}, {"referenceID": 19, "context": "[20]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "4 and 9] and [13].", "startOffset": 13, "endOffset": 17}, {"referenceID": 24, "context": "2, we present and discuss two query quality measures that have already been extensively analyzed in (debugging) literature [26, 27, 21, 20], which we will use in the example.", "startOffset": 123, "endOffset": 139}, {"referenceID": 25, "context": "2, we present and discuss two query quality measures that have already been extensively analyzed in (debugging) literature [26, 27, 21, 20], which we will use in the example.", "startOffset": 123, "endOffset": 139}, {"referenceID": 20, "context": "2, we present and discuss two query quality measures that have already been extensively analyzed in (debugging) literature [26, 27, 21, 20], which we will use in the example.", "startOffset": 123, "endOffset": 139}, {"referenceID": 19, "context": "2, we present and discuss two query quality measures that have already been extensively analyzed in (debugging) literature [26, 27, 21, 20], which we will use in the example.", "startOffset": 123, "endOffset": 139}, {"referenceID": 24, "context": "Also in the field of interactive ontology debugging, two active learning measures have been adopted [26, 27, 21] and shown to clearly outperform a (non-active) random strategy of selecting the next query [27].", "startOffset": 100, "endOffset": 112}, {"referenceID": 25, "context": "Also in the field of interactive ontology debugging, two active learning measures have been adopted [26, 27, 21] and shown to clearly outperform a (non-active) random strategy of selecting the next query [27].", "startOffset": 100, "endOffset": 112}, {"referenceID": 20, "context": "Also in the field of interactive ontology debugging, two active learning measures have been adopted [26, 27, 21] and shown to clearly outperform a (non-active) random strategy of selecting the next query [27].", "startOffset": 100, "endOffset": 112}, {"referenceID": 25, "context": "Also in the field of interactive ontology debugging, two active learning measures have been adopted [26, 27, 21] and shown to clearly outperform a (non-active) random strategy of selecting the next query [27].", "startOffset": 204, "endOffset": 208}, {"referenceID": 0, "context": "Let q be a fixed number in [0, 1] and let Q be a set of queries where each query Q \u2208 Q satisfies p(D(Q)) = q.", "startOffset": 27, "endOffset": 33}, {"referenceID": 12, "context": "In [13] it was shown that ENT(Q) can be equivalently transformed into \uf8ee\uf8f0 \u2211", "startOffset": 3, "endOffset": 7}, {"referenceID": 25, "context": "As a consequence, SPL is generally inferior to ENT for good estimates and superior to ENT for misleading probabilities, as experiments conducted in [27, 21] indicate.", "startOffset": 148, "endOffset": 156}, {"referenceID": 20, "context": "As a consequence, SPL is generally inferior to ENT for good estimates and superior to ENT for misleading probabilities, as experiments conducted in [27, 21] indicate.", "startOffset": 148, "endOffset": 156}, {"referenceID": 20, "context": "Before we introduce our new measure RIO (first presented in [21]) for query selection in", "startOffset": 60, "endOffset": 64}, {"referenceID": 25, "context": "In fact, the H measure is only a slight modification of the ENT measure [27] and both measures coincide for queries Q satisfying D(Q) = \u2205.", "startOffset": 72, "endOffset": 76}, {"referenceID": 21, "context": "Moreover, EMCa0 is equal to the Gini Index [22], a frequently adopted (information) gain measure in decision tree learning.", "startOffset": 43, "endOffset": 47}, {"referenceID": 25, "context": "The fundamental difference between ENT and SPL concerning the number of queries to a user required during a debugging session is witnessed by experiments conducted in [27, 26, 21].", "startOffset": 167, "endOffset": 179}, {"referenceID": 24, "context": "The fundamental difference between ENT and SPL concerning the number of queries to a user required during a debugging session is witnessed by experiments conducted in [27, 26, 21].", "startOffset": 167, "endOffset": 179}, {"referenceID": 20, "context": "The fundamental difference between ENT and SPL concerning the number of queries to a user required during a debugging session is witnessed by experiments conducted in [27, 26, 21].", "startOffset": 167, "endOffset": 179}, {"referenceID": 20, "context": "Compared to the usage of the more appropriate measure among {ENT,SPL} in a particular debugging scenario, the reliance upon the worse measure among {ENT,SPL} amounted to several hundred percent of time or effort overhead for the interacting user on average and even reached numbers higher than 2000% [21].", "startOffset": 300, "endOffset": 304}, {"referenceID": 22, "context": "According to [23], a search problem is defined by an initial state, a successor function (that returns all direct successor states of a state), path costs and a goal test.", "startOffset": 13, "endOffset": 17}, {"referenceID": 25, "context": "[27]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[8] Let K be a KB and \u03b1 an axiom, both over L.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "mC\u3008K,B,P,N \u3009R = {\u30081, 3\u3009 , \u30081, 4\u3009 , \u30082, 3\u3009 , \u30085\u3009} and the set of minimal diagnoses (minimal hitting sets of mC\u3008K,B,P,N \u3009R ) mD\u3008K,B,P,N \u3009R = {D1,D2,D3} = {[1, 2, 5], [1, 3, 5], [3, 4, 5]}.", "startOffset": 153, "endOffset": 162}, {"referenceID": 1, "context": "mC\u3008K,B,P,N \u3009R = {\u30081, 3\u3009 , \u30081, 4\u3009 , \u30082, 3\u3009 , \u30085\u3009} and the set of minimal diagnoses (minimal hitting sets of mC\u3008K,B,P,N \u3009R ) mD\u3008K,B,P,N \u3009R = {D1,D2,D3} = {[1, 2, 5], [1, 3, 5], [3, 4, 5]}.", "startOffset": 153, "endOffset": 162}, {"referenceID": 4, "context": "mC\u3008K,B,P,N \u3009R = {\u30081, 3\u3009 , \u30081, 4\u3009 , \u30082, 3\u3009 , \u30085\u3009} and the set of minimal diagnoses (minimal hitting sets of mC\u3008K,B,P,N \u3009R ) mD\u3008K,B,P,N \u3009R = {D1,D2,D3} = {[1, 2, 5], [1, 3, 5], [3, 4, 5]}.", "startOffset": 153, "endOffset": 162}, {"referenceID": 0, "context": "mC\u3008K,B,P,N \u3009R = {\u30081, 3\u3009 , \u30081, 4\u3009 , \u30082, 3\u3009 , \u30085\u3009} and the set of minimal diagnoses (minimal hitting sets of mC\u3008K,B,P,N \u3009R ) mD\u3008K,B,P,N \u3009R = {D1,D2,D3} = {[1, 2, 5], [1, 3, 5], [3, 4, 5]}.", "startOffset": 164, "endOffset": 173}, {"referenceID": 2, "context": "mC\u3008K,B,P,N \u3009R = {\u30081, 3\u3009 , \u30081, 4\u3009 , \u30082, 3\u3009 , \u30085\u3009} and the set of minimal diagnoses (minimal hitting sets of mC\u3008K,B,P,N \u3009R ) mD\u3008K,B,P,N \u3009R = {D1,D2,D3} = {[1, 2, 5], [1, 3, 5], [3, 4, 5]}.", "startOffset": 164, "endOffset": 173}, {"referenceID": 4, "context": "mC\u3008K,B,P,N \u3009R = {\u30081, 3\u3009 , \u30081, 4\u3009 , \u30082, 3\u3009 , \u30085\u3009} and the set of minimal diagnoses (minimal hitting sets of mC\u3008K,B,P,N \u3009R ) mD\u3008K,B,P,N \u3009R = {D1,D2,D3} = {[1, 2, 5], [1, 3, 5], [3, 4, 5]}.", "startOffset": 164, "endOffset": 173}, {"referenceID": 2, "context": "mC\u3008K,B,P,N \u3009R = {\u30081, 3\u3009 , \u30081, 4\u3009 , \u30082, 3\u3009 , \u30085\u3009} and the set of minimal diagnoses (minimal hitting sets of mC\u3008K,B,P,N \u3009R ) mD\u3008K,B,P,N \u3009R = {D1,D2,D3} = {[1, 2, 5], [1, 3, 5], [3, 4, 5]}.", "startOffset": 175, "endOffset": 184}, {"referenceID": 3, "context": "mC\u3008K,B,P,N \u3009R = {\u30081, 3\u3009 , \u30081, 4\u3009 , \u30082, 3\u3009 , \u30085\u3009} and the set of minimal diagnoses (minimal hitting sets of mC\u3008K,B,P,N \u3009R ) mD\u3008K,B,P,N \u3009R = {D1,D2,D3} = {[1, 2, 5], [1, 3, 5], [3, 4, 5]}.", "startOffset": 175, "endOffset": 184}, {"referenceID": 4, "context": "mC\u3008K,B,P,N \u3009R = {\u30081, 3\u3009 , \u30081, 4\u3009 , \u30082, 3\u3009 , \u30085\u3009} and the set of minimal diagnoses (minimal hitting sets of mC\u3008K,B,P,N \u3009R ) mD\u3008K,B,P,N \u3009R = {D1,D2,D3} = {[1, 2, 5], [1, 3, 5], [3, 4, 5]}.", "startOffset": 175, "endOffset": 184}, {"referenceID": 5, "context": "For instance, a comprehensive study [6] on entailments and justifications dealing with a large corpus of real-world KBs (ontologies) from the Bioportal Repository14 reveals that the probability for a q-partition to be non-canonical can be rated pretty low in the light of the sophisticated requirements enumerated by Propositions 51 and 52.", "startOffset": 36, "endOffset": 39}, {"referenceID": 25, "context": "[27, 21], the number of canonical q-partitions considered this way will prove to be still large enough to identify (nearly) optimal q-partitions (and queries) for all discussed measures, as our preliminary experiments (still unpublished) suggest.", "startOffset": 0, "endOffset": 8}, {"referenceID": 20, "context": "[27, 21], the number of canonical q-partitions considered this way will prove to be still large enough to identify (nearly) optimal q-partitions (and queries) for all discussed measures, as our preliminary experiments (still unpublished) suggest.", "startOffset": 0, "endOffset": 8}, {"referenceID": 22, "context": "According to [23], a search problem can be described by giving the initial state, a successor function16 enumerating all direct neighbor states of a given state, the step/path costs from a given state to a successor state, some heuristics which should estimate the remaining effort (or: additional steps) towards a goal state from some given state, and the goal test which determines whether a given state is a goal state or not.", "startOffset": 13, "endOffset": 17}, {"referenceID": 25, "context": "[27]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "At first sight, we might simply choose to employ the same approach that has been exploited in [20, 21, 27].", "startOffset": 94, "endOffset": 106}, {"referenceID": 20, "context": "At first sight, we might simply choose to employ the same approach that has been exploited in [20, 21, 27].", "startOffset": 94, "endOffset": 106}, {"referenceID": 25, "context": "At first sight, we might simply choose to employ the same approach that has been exploited in [20, 21, 27].", "startOffset": 94, "endOffset": 106}, {"referenceID": 6, "context": "This approach involves the usage of a modification of an algorithm called QuickXPlain (QX for short; originally due to [7]19) which implements a divide-and-conquer strategy with regular calls to a reasoning service to find one set-minimal subsetQ\u2032 (of generally exponentially many) of a given query Q such that P(Q\u2032) = P(Q).", "startOffset": 119, "endOffset": 122}, {"referenceID": 18, "context": "1] and originally [19]).", "startOffset": 18, "endOffset": 22}, {"referenceID": 25, "context": "[27, 21]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 20, "context": "[27, 21]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 19, "context": "[20, 21, 27]), one has little influence on the properties of a query that is returned.", "startOffset": 0, "endOffset": 12}, {"referenceID": 20, "context": "[20, 21, 27]), one has little influence on the properties of a query that is returned.", "startOffset": 0, "endOffset": 12}, {"referenceID": 25, "context": "[20, 21, 27]), one has little influence on the properties of a query that is returned.", "startOffset": 0, "endOffset": 12}, {"referenceID": 0, "context": "one might calculate all formulas of the form A B for propositional variablesA,B and logical operators \u2208 {\u2192,\u2194}, and for Description Logics [1], e.", "startOffset": 138, "endOffset": 141}, {"referenceID": 6, "context": "6, we can apply a modified version of the QX algorithm [7].", "startOffset": 55, "endOffset": 58}, {"referenceID": 19, "context": "8] (the MINQ algorithm is stated as part of Algorithm 4 on page 103 in [20]).", "startOffset": 71, "endOffset": 75}, {"referenceID": 19, "context": "To make this paper self-contained, we quote the relevant explanatory text regarding MINQ from [20] next.", "startOffset": 94, "endOffset": 98}, {"referenceID": 19, "context": "), MINQ as described in [20] does not yet satisfy requirements (2.", "startOffset": 24, "endOffset": 28}], "year": 2017, "abstractText": "Many artificial intelligence applications rely on knowledge about a relevant real-world domain that is encoded in a knowledge base (KB) by means of some logical knowledge representation language. The most essential benefit of such logical KBs is the opportunity to perform automatic reasoning to derive implicit knowledge or to answer complex queries about the modeled domain. The feasibility of meaningful reasoning requires a KB to meet some minimal quality criteria such as consistency or coherency. Without adequate tool assistance, the task of resolving such violated quality criteria in a KB can be extremely hard, especially when the problematic KB is complex, large in size, developed by multiple people or generated by means of some automatic systems. To this end, interactive KB debuggers have been introduced which solve soundness, completeness and scalability problems of non-interactive debugging systems. User interaction takes place in the form of queries asked to a person, e.g. a domain expert. A query is a number of (logical) statements and the user is asked whether these statements must or must not hold in the intended domain that should be modeled by the KB. To construct a query, a minimal set of two solution candidates, i.e. possible KB repairs, must be available. After the answer to a query is known, the search space for solutions is pruned. Iteration of this process until there is only a single solution candidate left yields a repaired KB which features exactly the semantics desired and expected by the user. Existing interactive debuggers often rely on a pool-based strategy for query computation. A pool of query candidates is precomputed, from which the best (or a sufficiently good) candidate according to some query quality criterion is selected to be shown to the user. This often leads to the generation of many unnecessary query candidates and thus to a high number of expensive calls to logical reasoning services. Such an overhead can have a severe impact on the response time of the interactive debugger, i.e. the time between two consecutive queries. The actual problem of this approach is the quantitative nature of the query quality functions used to assess the goodness of queries. These functions more or less provide only a black-box to use in a trial-and-error search for acceptable queries. We tackle this issue by an in-depth mathematical analysis of diverse quantitative active learning query selection measures published in literature in order to determine qualitative criteria that make a query favorable from the viewpoint of a given measure. These qualitative criteria are our key to devise efficient heuristic query search methods. This proposed approach involves a three-staged optimization of a query. For the first stage, we introduce a new, theoretically well-founded and sound method for query generation that works completely without the use of logical reasoners. This method is based on the notion of canonical queries. Together with the developed heuristics, it enables to compute an (arbitrarily near to) optimal canonical query w.r.t. a given quality measure, e.g. information gain. For one canonical query, in general, multiple queries with the same quality w.r.t. the measure exist. To this end, we show that a hitting set tree search (second stage) can be employed to extract the best query among these w.r.t. additional criteria such as minimum cardinality or best understandability for 1 ar X iv :1 60 9. 02 58 4v 1 [ cs .A I] 8 S ep 2 01 6 the user. This search does not rely on logical reasoners either. With existing methods, the extraction of such queries is not (reasonably) possible. They can just calculate any set-minimal query. Consequently, this work for the first time proposes algorithms that enable a completely reasonerfree query generation for interactive KB debugging while at the same time guaranteeing optimality conditions of the generated query that existing methods cannot realize. In the third query optimization stage, which is optional, the one already computed query which optimizes a given quality measure and some of the additional criteria, can be enriched by further logical statements of very simple and easily conceivable form and afterwards be minimized again. The reason of these optional steps, involving altogether only a polynomial number of reasoner calls, can be the simplification of the statements comprised in the query. The new approach we propose for accomplishing this improves the existing algorithm for query minimization insofar as it guarantees the finding of the query that is easiest to answer for the interacting user under plausible assumptions. Furthermore, we study different relations between diverse active learning measures, e.g. superiority and equivalence relations. The obtained picture gives a hint about which measures are more favorable in which situation or which measures always lead to the same outcomes, based on given types of queries.", "creator": "LaTeX with hyperref package"}}}