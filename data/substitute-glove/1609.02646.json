{"id": "1609.02646", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Sep-2016", "title": "Some Advances in Role Discovery in Graphs", "abstract": "Role comet last finite comes any emerging area example create diagnostic fact complex polyhedral since an masterly kind. In seen to used graph sanpin - lems more one nonprofit taken, still stranger groups on sensitive allowing url, the important discovery understand finds political of nodes that close it symmetric topological structure. However, existing work yet there has held traumatic concerning that prevent still supposed leaving some temporal. Firstly, it is virtually altercations an both negative any a lists given reasons. Secondly, most worked instance partly may a an inferiority formula_13. We address. other jae - itations end giving imaginative even wrong to implement ionic 70 squares framework. Our balanced make matrices constraints will why had on was roles discovery problem same different provide useful implement. In par - ticular we explore rigorous. enforced never) bloodiness, name) awareness and wrymouth) alternativeness. We started show whatever give lift this many for current - geometry graphs. A natural representation there the sharing - interfaces notation has his order 45 tensor (still than this tensor) much that turned Tucker parameter typically agreed come find complex bonding continuing collections there entity (E - groups) and the roles they put an a combination of focused (R - those ). Existing Tucker centrifugation methodologies in tensor toolboxes besides we sturdy even our must, so anyway focusing feel own compute that we demonstrate is pragmatically proven.", "histories": [["v1", "Fri, 9 Sep 2016 03:13:55 GMT  (1195kb,D)", "http://arxiv.org/abs/1609.02646v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["sean gilpin", "chia-tung kuo", "tina eliassi-rad", "ian davidson"], "accepted": false, "id": "1609.02646"}, "pdf": {"name": "1609.02646.pdf", "metadata": {"source": "META", "title": "Some Advances in Role Discovery in Graphs", "authors": ["Sean Gilpin", "Chia-Tung Kuo", "Tina Eliassi-Rad"], "emails": ["sagilpin@ucdavis.edu", "tomkuo@ucdavis.edu", "eliassi@cs.rutgers.edu", "davidson@cs.ucdavis.edu"], "sections": [{"heading": "1 Introduction", "text": "Role discovery is a developing area that allows the simplification of graphs in a user-interpretable way. Consider a graph of n nodes specified in an adjacency\nar X\niv :1\n60 9.\n02 64\n6v 1\nmatrix A. Earlier efforts convert this matrix into a new n\u00d7 f matrix V so that each node in the graph has a list of f features [22]. Role discovery is then the computation of converting V so that each node/user is mapped to a combination of roles (denoted by the n \u00d7 r matrix G) and each role is defined with respect to the f features (denoted by the r \u00d7 f matrix F). This is accomplished by performing a non-negative matrix factor decomposition as shown below:\nargmin G,F\n||V \u2212GF||2\nsubject to: G \u2265 0,F \u2265 0 (1)\nThe n\u00d7 r matrix G when read row-wise indicates which of the r roles each node plays and to what degree. The r\u00d7 f matrix F when read row-wise defines each of the r roles with respect to the f features. The entries in G and F are non-negative real numbers signifying that each node can play each role to varying degrees and that different features define a role in varying degrees. This simplification of graphs into roles is not only intuitive for a domain expert, but it has been shown to be useful in a number of interesting settings including prediction, transfer learning, and sense making [21].\nLimitations in Existing Work. However, all work developed so far has two limitations. Firstly, role discovery has been typically completely unsupervised in that the domain expert cannot easily inject their expertise and expectations into the simplification and secondly role discovery is typically performed on a single relational graph. We now discuss each limitation in turn.\nConsider a domain expert that is looking for the simplest explanation of a graph during their exploratory phase of analysis. Existing work cannot specify how to emphasize this simplicity apart from requiring a small number of roles to be used. Other forms of parsimonious guidance such as requiring a node only be assigned to a few roles or making each role defined by only a small set of features is desirable but currently not possible. Similarly, if a decomposition yields a set of roles that are not actionable, not interesting or already known, the domain expert cannot enforce an alternative set of roles. These two recent trends in data mining \u2013 exploring the addition of positive and negative guidance \u2013 have been shown to have wide-scale application in the data mining literature [5][36]; but to our knowledge have not been applied to role discovery. Hence this work marks the first paper exploring guided role discovery.\nTo our knowledge previous work in role discovery only focuses on simple graphs with a single relational type. Conversely, many datasets are either directly multi-relational or can be modeled as a multi-relational graph. Consider an email graph, modeling just one relation sent-mail-to. This graph greatly masks the complexity of the underlying behavior occurring in the network. Instead many more insights could be found if say the topic of the email were also considered producing a multi-relational graph sent-mail-to-y-about-x. Similarly, consider a node-attributed social network graph, that is, each node has multiple labels. Such a graph can augment the basic friend relation by creating multiple relations such as female-friend, school-friend or nearby-friend by placing an edge between nodes that are friends that also share label values.\nChallenges. The challenge with adding guidance to role discovery is how to do so whilst still yielding an efficiently solvable algorithm. Pre-processing the graph or postprocessing the results is undesirable, instead it is preferable to inject the guidance into the underlying algorithm that finds the roles. The alternating least square (ALS) is a popular and well understood algorithm for non-negative matrix factorization (NMF) for role discovery and the challenge is to add in guidance into this algorithm.\nThe challenge of role discovery in multi-relational graphs is two fold, the first is representational and the second is algorithmic.\nRepresentational Challenges. How should a multi-relational graph be represented for effective and efficient role discovery? In Figure 6, we show how an order 3 tensor can compactly represent such a graph. Here, the first mode represents the entities (i.e., nodes) in the graph; the second mode is the features of each entity (obtained from our ReFeX package [22]), and the last mode represents the relations. The existing work on single-relation graphs uses nonnegative matrix factorization. The analog PARAFAC (parallel factor) tensor decomposition for our multi-relational graph tensor, has several serious limitations. In particular, it requires each group of nodes to play exactly one role for exactly one set of relations. This is not due to the rank one decomposition assumption, but rather due to the simplified form of decomposition. This cardinality limitations greatly limits what can be found. Consider our aforementioned example of an email network, we could perhaps find that a group of people play the role of a broker for a particular email topic, office-party. Though useful, if those people also play a different role for the same email topic a PARAFAC decomposition could not find it. Similarly and most importantly, if another group were to play the role of a peripheral figure for the exact same topic (office-party) PARAFAC would not be able to discover this relation. It is precisely these types of complex multi-way interactions between people, roles and relations that we wish to discover. Hence we do not consider PARAFAC decompositions, though it would be the natural extension of our earlier work on role discovery to multi-relational graphs. Instead we use a Tucker decomposition shown in Figure 7 whose addition of a core tensor to the decomposition allows multiple groups of entities (E-groups) to play multiple roles for multiple groups of relations (R-groups). This allows very complex insights into the behavior in the graph to be found, but the challenge of how to interpret and use this core is critical to our work.\nAlgorithmic Challenges. The second challenge is that existing Tucker decompositions found in the popular Kolda Tensor Toolbox and Bro NWay Toolbox are not suited for our purpose. Existing toolboxes implement an orthogonality constraint on the factor matrices which in our context (where the tensor only contains non-negative values) means each group of entities must be distinct (i.e., non-overlapping) from every other group, and the same for roles and groups of relations. Similarly existing toolboxes typically do not enforce a non-negativity constraint on the core of the Tucker meaning if we use them we would have entities playing negative roles which does not make intuitive\nsense. Hence to better fit our needs of having interpretable insights on overlapping groups of entities (a.k.a. E-groups), roles, and groups of relations (a.k.a. R-groups), we develop our own algorithm, Multi-relational Role Discovery (MRD), shown in Algorithm 1.\nOur work makes several contributions to the field of role discovery in graphs. With respect to guided role discovery we show:\n\u2022 We provide a framework to encode guidance as a series of convex optimization problems each of which can be efficiently solved by our alternating least squares (ALS) algorithm. All data sets and code will be made available once the paper is accepted.\n\u2022 Within our framework we explore guidance in the form of sparsity, diversity and orthogonality/alternativeness but other types of guidance are possible.\n\u2022 We show that sparsity and diversity yield improved performance in terms of predictive accuracy for the identity resolution task across multiple graphs.\n\u2022 We show that alternative roles exist in social networks (such as in a YouTube graph) and in particular these roles are very different from the known communities in the data.\nWith respect to multi-relational role discovery we show:\n\u2022 We propose and study role discovery in multi-relational graphs using tensors and using our novel MRD Tucker decomposition algorithm (see Sections 6 and 7 ).\n\u2022 We show how to analyze the core tensor of the Tucker decomposition in a multitude of visual and analytic ways to explain the complex interactions occurring (see Section 8).\n\u2022 We create and measure macro-level properties of the interaction graph such as the simplicity, sharing and stability of the graph with respect to roles (see Table 5).\n\u2022 We use a constrained formulation of our algorithm that allows transferring in knowledge (i.e., roles) from a graph to explain another graph (see Section 9.2) This allows understanding temporal shifts in roles (see Figure 18).\nIn the next section, we describe related work and then an algorithm for incorporating convex constraints in non-negative matrix decomposition which allows us to encode guidance in a flexible way. Section 4 presents how convex constraints can naturally encode guidance in the form of sparsity and diversity on both the role assignment matrix (G) and role explanation matrix (F). We also present how these constraints can encode the notion of alternativeness to\nfind a different set of roles to another set that are for instance non-actionable or trivial. Our experiments on guidance, in Section 5, demonstrate the usefulness of these forms of guidance in a number of applications and real-world graphs. We show how sparsity and diversity guidance can improve upon prediction performance for the application of identity resolution via roles. We also show how alternativeness can be used to find an alternative set of roles to the underlying community structure. Next in Section 6 we show how multi-relational role discovery can be formulated as a tensor decomposition problem. In particular it can be modeled using a non-negative tucker decompositions, and in that section we also propose our Tucker decomposition algorithm. The Tucker decomposition allows capturing many of the complex interactions between nodes, the roles they play, and the relationships they play them for, which are captured in the core tensor of the Tucker decomposition. In Section 8 we discuss how the core of the Tucker can be interpreted a number of ways, including as a heterogeneous hyper-graph on the space of groups of nodes, groups of features (roles) and groups of relations. Our work opens up many possible novel uses and we experimentally focus on two: i) macroscopic properties of the graphs in terms of roles and ii) transfer settings between multiple graphs which are discussed in Section 9."}, {"heading": "2 Related Work", "text": "The basis for role discovery in graphs using non-negative matrix factorization (NMF) was first proposed in a series of papers at KDD [22][21]. The method ReFeX [22] described a recursive method to take a n\u00d7 n adjacency matrix (A) and compute a set of f salient features for each of the n nodes represented as a matrix V . The RolX method [21] made use of NMF to simplify the features into a set of roles and explored their use for graph matching, sense making and transfer learning. Many previous works had applied NMF to other data mining problems (e.g. [40][28]) but theirs was the first to apply it to role discovery. Other methods for role discovery are not scalable to huge graphs and include Bayesian frameworks using MCMC sampling methods [37] and semi-supervised role labeling [17].\nThe addition of guidance to matrix decomposition is a relatively new area with most work involving spatial data and properties such as unimodality as we have done for tensors [12]. Of course much work exists on very basic constraints such as non-negativity and minimal rank decompositions. The area of constraints for matrix decomposition takes on several different meanings to our own work. For example in [30] the authors propose the use of labeled information to guide the decomposition. Perhaps the closest to our own work is the use of sparseness constrains in NMF [23].\nTo the best of our knowledge the encoding of guidance for role discovery and the encoding of diversity and alternative constraints for NMF as described in this paper has not been addressed before. However, the notion of guidance and \u201calternativeness\u201d is popular in the clustering field with work by ourselves and\nothers [5][36]."}, {"heading": "3 A Constrained NMF Framework for Encoding", "text": "Guidance into Role Discovery\nIn this section, we discuss our algorithm for solving the guided role-discovery problem. We present a general algorithm that is well-suited for large-scale problems, and is capable of being extended to different forms of guidance. The different supervisions (described in Section 4) are solvable using this algorithm.\nOur algorithm for solving the guided role discovery problem is a constrained NMF approach used to find the decomposition shown in Equation 2. Like many unconstrained NMF solvers, it uses the alternating least squares approach [35, 7]. Non-negative least squares is a well-studied problem, and can be utilized to find an NMF solution by solving for one matrix at a time (G or F), while holding the other constant which is generally known as alternating least squares (ALS). NMF is known to be intractable; and the ALS approach is not guaranteed to find global solutions but will converge to a local minimum. In this work, we add additional constraints to the problem and therefore need more sophisticated methods.\nThe method we chose was motivated by gradient projection methods, which are known for being well-suited to quickly finding good but not highly accurate solutions for large problems, by sacrificing some of the theoretical convergence guarantees of methods such as interior point [6]. Projected gradient descent methods can be summarized as those that iteratively find better points by following the gradient of the objective function, and subsequently find the closest point that meets the constraints. Since the objective we are solving is least squares, we have a closed form solution to the unconstrained minimum from which we subsequently find the closest constrained solution. It is known, that for a class of constrained least squares solution, this approach will lead to an exact global solution in one iteration (see Lemma 1).\nTherefore, our algorithm has the advantage that each subproblem (but not the entire problem) can be solved exactly by reducing it into an unconstrained least square problem [39][3] and an Euclidean projection problem [14][32], both of which have efficient solutions. Additionally, this approach to optimization (projected gradient descent) has been shown in the past to work well on largescale problems, at the expense of accuracy, and is used by state of the art solvers [31].\nThe outline of the remainder of this section is as follows. First, we formally describe the convex constrained NMF problem and discuss how ALS can be used to solve it. Then, we explain how ALS can also be used to solve for individual role assignment vectors, as well as role definition vectors. Finally, we describe how ALS over definition/assignment vectors can be solved using a projection method by first solving an unconstrained least squares problem and then finding the closest point in the constrained space.\nThe Constrained NMF Problem In Equation 2, there are two variables G and F that are being simultaneously optimized. If either is treated as a constant, the problem becomes convex and can be solved exactly using any method for solving convex optimization problems. One can alternate between solving for G and F this way until convergence. Although each iteration finds a global optimum to this modified problem, the result of this procedure (alternating optimization) is not guaranteed to find a global minimum to the original problem in Equation 2. In the following, we describe our method for transforming the formulation into a series of convex programming problems, which are generally easy to solve.\nminimize G,F\n||V \u2212GF||2\nsubject to gi(G) \u2264 dGi, i = 1, . . . , tG fi(F) \u2264 dFi, i = 1, . . . , tF\n(2)\nwhere gi and fi are convex functions.\nAn ALS Formulation Rather than alternating between solving for the entire matrices G and F, we can instead solve for one column of G or one row of F at a time. This is possible if convex constraints can be specified in terms of these columns, which is the case in this work. Without loss of generality, Equation 3 shows an individual sub-optimization problem in terms of one of the columns of G, denoted x.\nGk = minimize x ||R\u2212 xFk||2 subject to: gi(x) \u2264 dGi, i = 1, . . . , tG\n(3)\nIn Equation 3, R represents the residuals of all other factors not being solved for (sum of outer products of corresponding columns of G and rows F). Fk is the kth row of the role/feature explanation matrix that corresponds to the kth column of the role assignment matrix. So with this formulation, we alternate between learning single role assignments, followed by learning a role definition. Next we explain how we solve the convex constrained problem shown in Equation 3.\nSolving The Constrained Least Squares Problem Our projection method is as follows. First, solve Equation 3 with all constraints removed using standard least squares solvers. Second, find the closest point to the unconstrained solution, that satisfies the given constraints. This projection method takes advantage of standard and very fast least squares solvers and the subsequent nearest feasible point problem is relatively simple to solve. In addition, Lemma 1 shows that performing these two steps will exactly solve the original prob-\nlem in Equation 3. Applications of this theorem and its proof can be found in [10][20].\nLemma 1 Projection Equivalence Result. The following constrained optimization problem:\nminimize x ||B\u2212 xa||2 subject to: ci(x) \u2264 di, i = 1, . . . , n\n(4)\nwhere ci are convex functions on x, is equivalent to:\nminimize x ||x\u2217 \u2212 x||2 subject to: ci(x) \u2264 di, i = 1, . . . , n\n(5)\nwhere x\u2217 is the optimal to the optimization problem in Equation 4 without contraints.\nThis leads to the following algorithm for convex constrained NMF presented in Figure 1. Like ALS for unconstrained NMF, this heuristic is not guaranteed to meet a global optimum, even though all subproblems are solved exactly. However, each step will lead to a reduction in the global objective (Equation 2). Thus, in practice the algorithm will find local minima that meet all specified constraints.\nThe advantage of solving for one role at a time rather than the entirety of G or F as is generally done with ALS, is that it allows the problem to be broken down into smaller parts that then fit into fast solvers. In general, projection methods have been found to be better suited to larger problems and we found this to be the case as well. Using this method allows us to solve much larger problems than we had previously been able to using standard constrained optimization solvers [12]. The final constrained optimization problem (i.e., closest constrained point problem) is simple enough that we find for even medium-sized problems we could utilize high level solvers such as CVX [11][19], which makes experimenting with new types of constraints very simple."}, {"heading": "4 Framework for Flexible Supervision", "text": "In the previous section, we discussed a novel and general algorithm that can easily handle convex constraints. Convex constraints can encode a variety of useful guidances. In this section, we show how they can be used to enforce sparsity, diversity and alternativeness. In the experimental section, we show applications which exploit these forms of guidance."}, {"heading": "4.1 Sparsity", "text": "The area of sparsity has recently attracted much attention. In a general context, sparsity has been shown to have two main benefits: (1) parsimony and (2) improved predictive performance, with the later being motivated by Occam\u2019s\nInputs:\n\u2022 V: Node feature matrix containing n nodes described by f topological structure features.\n\u2022 gi(x),fi(x): Convex constraints on columns of G and rows of F respectively.\n\u2022 r: Number of roles (methods for learning r described in previous work [21]).\nOutputs:\n\u2022 G: Role assignment matrix that satisfying all constraints.\n\u2022 F: Role definition matrix that satisfying all constraints.\nAlgorithm:\nrazor. Sparse learning formulations exist for many learning settings such as linear regression (LASSO), Kernel methods (SVM) and covariance estimation.\nIn our work, we can place sparsity constraints on both the G or F matrices leading to an objective function of:\nargmin G,F\n||V \u2212GF||2\nsubject to: G \u2265 0,F \u2265 0 \u2200i ||G\u2022i||1 \u2264 G \u2200i ||Fi\u2022||1 \u2264 F\nwhere G and F define upperbounds for the sparsity constraints (amount of allowable density).\n(6)\nPrevious works have shown the effectiveness of using L1 norm as a penalty in model learning. In our formulation the L1 penalty is encoded as a constraint rather than a penalty in the objective, but it is known that these formulations are theoretically equivalent [8]. However, another twist to our formulation is that we do not constrain the entire matrix but instead constrain each column of G and each row of F. This was done because our solver requires constraints to be formulated only over one role vector at a time. The effect of this technical difference is that the sparsity must be more uniformly spread across each role definition or role assignment which is a benefit of this method.\nSparsity constraints on G and F have easy to understand intuitive interpretations. If G is sparse, it means that nodes are assigned to as few roles as possible; and it is possible for some nodes to be assigned to no roles. If F is sparse, it means that the roles are defined with respect to as few features as possible. Both of these extensions allow for a simple explanation of the data, and lead to improved prediction performance."}, {"heading": "4.2 Diversity", "text": "In the NMF forms of role discovery, nothing prevents the roles to which nodes are assigned (i.e., the G matrix) and the role definitions (i.e., the F matrix) to be highly overlapping. This can be undesirable particularly for the F matrix since it means all roles are highly similar. This can be overcome by enforcing a diversity requirement so that each role uses a different set of features (for the F matrix) and nodes are assigned to different combinations of roles (for the G matrix).\nOur formulation for role allocation diversity (G matrix) and role definition diversity (F matrix) makes use of orthogonality as follows:\nargmin G,F\n||V \u2212GF||2\nsubject to: G \u2265 0,F \u2265 0 \u2200i, j GT\u2022iG\u2022j \u2264 G i 6= j \u2200i, j Fi\u2022.FTj\u2022 \u2264 F i 6= j\nwhere G and F define upperbounds on how angularly similar role assignments and role definitions can be to each other.\n(7)\nWhen = 0, our constraint will exactly match the definition orthogality, and when \u2265 0 the constraint can be viewed as limiting the angular similarity between two vectors. The effect of combining this constraint with non-negativity constraints is that no role definitions will have any common features and no role assignments will have overlapping populations for = 0. This is so since GT\u2022iG\u2022j = 0 if and only if these two vectors do not share any non-zero entries. Figure 2 shows such an example, where none of the three roles have any overlapping features. In the context of our solver which solves for one vector at a time, this constraint will be linear (a weighted sum)."}, {"heading": "4.3 Alternative Role Discovery", "text": "Recent work on another unsupervised problem, clustering, has explored the area of alternativeness [36, 13]. In that literature, the term alternativeness and orthogonality are used interchangeably, but we only use the term alternativeness for clarity.\nThe motivation for alternativeness in unsupervised learning is strong. Most interesting problems are on large data sets that contain complex phenomena and there may exist multiple explanations of the data. However, most unsupervised learning algorithms expect that there exists only one good explanation of the data and return one explanation.\nIn many situations, it may be the case that the returned explanation is undesirable since it is either unactionable or not novel. Consider the IMDB (Internet Movies Database) dataset. If the resultant roles map actors to the studios for which they work, then this is not particularly novel. Here, the work on alternative role discovery allows a previously discovered set of role allocations (G\u2217) or role definitions (F\u2217) to be specified as a counter-example of what not to find. The challenge though is to find another good explanation of the data that is different to those already found.\nThe optimization problem to find alternative roles is then:\nargmin G,F\n||V \u2212GF||2\nsubject to: G \u2265 0,F \u2265 0 \u2200i, j G\u2217T\u2022i G\u2022j \u2264 G \u2200i, j F\u2217i\u2022FTj\u2022 \u2264 F\nwhere G and F define upperbounds on how similar the results can be to G\u2217 and F\u2217.\n(8)"}, {"heading": "5 Experiments for Guided Role Discovery", "text": "Our experiments demonstrate how constraints on graph role discovery can be useful. Role discovery requires the user to specify the number of roles to use and a set of features for a graph. For the former, we used the Minimum Description Length (MDL) described in [21] to automatically select the number of roles; and for the later, we used the approach described in [22]. We show that role discovery can be used to improve the results of the identity resolution problem between two graphs, and that they can be further improved by using sparsity or diversity constraints. By using sparsity or diversity constraints, we improve the role definitions which leads to more meaningful role assignments and more accurate identity resolutions. See Section 5.1 for these experiments. We also experimentally verify the solutions to the alternative role discovery formulation presented in Section 4.3 and observe that they indeed produce significantly different results. The purpose of our experimental section is to address the following questions:\n1. Does adding constraints to the NMF-based role discovery formulation improve the quality of the resulting role explanations and assignments? Figures 3 and 4 show that constraints improve the results of identity resolution.\n2. What effects do diversity constraints have on role discovery results? Figures 3 and 4 show how diversity constraints can improve role discovery results even more so than sparsity constraints.\n3. Can our alternative role discovery formulation produce significantly different results? Tables 3 and 4 shows that our formulation can produce results that are significantly different than a given set of roles or community assignments respectively."}, {"heading": "5.1 Sparse and Diverse Identity Resolution in Co-authorship Graphs", "text": "In this experiment, we show that by adding sparsity and diversity constraints to the NMF formulation of role discovery, the resulting role definitions are of higher quality. We measure this improvement in quality indirectly by showing how role definition matrices can be used for resolving identities of nodes across graphs, and that constrained role definitions perform better than unconstrained role definitions for that problem.\nFrom the DBLP data-set [27], we extracted a co-author graph from each of the following related conferences from 2005 to 2009: KDD, ICDM, SDM, CIKM, SIGMOD, VLDB (see Table 2 for detailed information about each coauthor graph). We extract a set of relevant structure features for the KDD graph using REFEX [22], and compute these same features for all of the coauthor graphs. We subsequently learn a set of role definitions from the KDD graph using standard RolX [21] as well as the sparse and diverse versions of GLRD. For each of these competing role definitions, we assign each vertex from each graph to the roles whose function they most exhibit. As a baseline, we also\nexplore author identification without roles by using the raw graph features as described in ReFeX.\nWe use the role assignments to resolve the identities of vertices from each graph (namely, ICDM, SDM, CIKM, SIGMOD, and VLDB) to the vertices in the KDD graph. Without loss of generality, assume we are resolving identity of authors from the KDD graph to the authors in ICDM graph. For each author in both conferences, we select the corresponding row vector from the node by role matrix Gkdd and find the k closest neighbors (row vectors) from Gicdm. If the original author from KDD graph is present in the set of k closest neighbors, we count the result as a match. We repeat this experiment using sparsity and diversity constraints on Fkdd. We also repeat the experiment using the ReFeX features, comparing author feature vectors from Vkdd and Vicdm. Figures 3 and 4 shows how the different decomposition methods compare in this setting for all graphs paired with KDD.\nOur method of utilizing role discovery results for the author identification task is described formally in the following set of steps:\n1. Extract features from co-authorship graphs to get graph features (e.g. Vkdd,Vicdm) using ReFeX.\n2. From the graph features matrix Vkdd perform role discovery to obtain Gkdd and Fkdd.\n3. Transfer the role definition matrix Fkdd (role by feature matrix) to other graphs (e.g. Vicdm) by solving Equation 9.\nGicdm = min G ||Vicdm \u2212GFkdd||2 s.t. G \u2265 0 (9)\nOur experiments with graph identity-resolution show that diversity and sparseness constraints almost universally improve the quality of learned roledefinition matrix. This is not unexpected since there is a long tradition in machine learning of using sparsity to prevent overfitting. As mentioned previously we can view diversity as enforcing sparsity since a diverse set of roles as per our definition do not share many overlapping features and hence each role definition is concise.\nFigure 3 shows that role definitions learned using sparsity and diversity outperform standard unconstrained role discovery (RolX) in almost every setting and problem parameterization. Figure 4 more clearly shows the general trend by considering the results for a particular problem parameterization. In that figure, we observe that diversity constraints lead to the most improvement over RolX, while sparsity improvements are lesser. We also observe that transferring the KDD role definitions to some graphs (like VLDB and SIGMOD) does not compare well to the baseline method that does not use any roles (such as ReFeX). We believe this is because the same participants in conferences such as VLDB and SIGMOD do not have a similar role to the ones they play in KDD; and hence, using the raw features (without roles) produces better results.\nWe believe that sparsity improves the quality of role definitions by reducing the ability of unconstrained NMF-based role discovery to overfit the problem. Features that only slightly add to the definition of a role are more likely to be explaining noise; and by forcing those values to zero, we end up with more robust definitions. Furthermore, the diversity constraints help by removing redundancy in role definitions, which leads to definitions that are more easily comparable. For example, if a feature is used to define every role, then it is not essential in defining any of them."}, {"heading": "5.2 Alternative Roles", "text": "In this section, we show that our alternative role discovery formulation (presented in Section 4.3) can discover significantly different role definitions, as well as show that the formulation can be used to improve the role definitions when there are ground-truth communities. In Table 3, we show the difference between an alternative role discovery result and an original role definition found using unconstrained role discovery (via RolX). In Table 4, we show that we can use our formulation to get more consistent assignments of roles when ground-truth communities are known.\nIn our first experiment, we explore the difference between the roles of the original and alternative role discovery. Using the KDD co-authorship graph, we find a set of roles and constrain a new solution to have a significantly different role definition (F matrix). We then compare the results by assigning each vertex to its most dominant role in both results to create two separate partitions of the vertices. We then measure the difference between the two partitions using Jaccard distance. Table 3 shows that all of the Jaccard distances are far from 0 meaning that the alternative role assignments are very different than the original ones. Figure 5 illustrates the alternative roles found in the largest connected component of the KDD coauthorship graph. Note, the reader can zoom in on this figure to read the names of each author. The following is a description of the original roles and the roles that GLRD(Alternative) found. These description are based on sense-making analysis [21]. As the descriptions show these roles are capturing alternative concepts.\nOriginal Roles:\nRole 1: Nodes here have high eccentricity. These are periphery nodes.\nRole 2: Nodes here have high eccentricity and high clustering coefficient. These are periphery nodes that are cliquey.\nRole 3: Nodes here have high degree and high clustering coefficient. These are highly connected cliquey nodes.\nRole 4: Nodes here have high PageRank, high degree, and high biconnected components numbers. These are globally central stars and brokers.\nAlternative Roles:\nRole 1: Nodes here have high PageRank and high biconnected component numbers. These are globally central and brokers.\nRole 2: Nodes here have high clustering coefficient but not high eccentricity. These are non-periphery nodes that are cliquey.\nRole 3: Nodes here have high eccentricity and high clustering coefficient. These are periphery nodes that are cliquey.\nRole 4: Nodes here have high eccentricity and high degree. These are periphery nodes that are locally stars.\nWe next experiment with a YouTube dataset, which is a network of users with known ground-truth communities [33]. This graph was created by crawling the YouTube site in 2007 and creating directed edges between a pair of users a and b if a\u2019s profile page linked to b\u2019s profile page. Ground-truth communities were assigned by collecting all users belonging to the same group, which were pages that allowed communications between users on given topics. The graph has 1,134,890 vertices, 2,987,624 edges, and 8,385 communities. We selected all communities with over 100 users of which there were 105. The largest community has 2,217 users.\nThere is an inherent complementariness between role discovery and community detection. The former is about structural similarity; while the latter is based on proximity in the graph. Role discovery finds functions/roles of users but does not find the communities themselves. However, there may be multiple interesting sets of communities within the same network and those communities may be characterized by very different roles. In this experiment, we encode the set of ground-truth communities for which our role discovery technique should find roles.\nThe way we encode the YouTube ground-truth communities into our analysis is by providing the communities as G\u2217 to our alternative role discovery formulation. This will force our discovered roles to have a role assignment that is different than ground-truth communities, which matches the semantic relationship between the two problems.\nTo evaluate the effectiveness of this result we measured the proportion of members in each community belonging to each role. We then calculated the standard deviation over all such communities per role and report the results in Table 4. The assumption for this evaluation is that each role should be equally represented in each community. Our results show that the alternative role discovery formulation can indeed be used to normalize the roles with respect to a set of ground-truth communities. After applying sense-making [21], the six roles that our GLRD(Alternative) finds are as follows:\nAlternative Role 1: Nodes here are global hubs. They have high PageRank values, high out-degrees, and high biconnected component numbers.\nAlternative Role 2: Nodes here are on the periphery of the graph. They have higher than default eccentricity.\nAlternative Role 3: Nodes here are authorities. They have high PageRank values and high in-degrees.\nAlternative Role 4: Nodes here are very cliquey. They have high clustering coefficients.\nAlternative Role 5: Nodes here are local hubs. They have high out-degrees and high biconnected component numbers.\nAlternative Role 6: Nodes here are the majority of the population; they are the \u201cregular\u201d folks. They have a local neighborhood that is more cliquey than expected but otherwise nothing special stands out."}, {"heading": "6 Lifting our Formulation for Multi-Relationl", "text": "Role Discovery\nHere we outline our method to lift our previous work to perform role discovery in multi-relational graphs. We do not recreate the same experiments since they are trival but instead focus on the more challenging problem of role discovery in multi-relational graphs.\nRole Discovery in Multi-relational Graphs. Our approach to extending role discovery to multi-relational graph is to model the graphs as a tensor. This\nis done by extracting features from each relation and appending the resulting feature matrices into a single tensor V of dimension n\u00d7 f \u00d7 r. Just as NMF is used to decompose a feature matrix V , tensor decompositions can be used to decompose a feature tensor V. One natural choice of tensor decompositions to decompose a feature tensor would be non-negative PARAFAC [16]. PARAFAC like NMF is a rank one decomposition see Figure 6. However, PARAFAC is not an ideal model to find complex patterns in graphs, as is desired for role discovery, because it is too simplistic in its assumptions. In particular it will only allow each group of entities to play only one role for only one group of relations. See the introductory section for a more indepth explanation of the limitations of PARAFAC.\nargmin G,F,R\n||V \u2212 \u2211\nk\ngk \u25e6 fk \u25e6 rk||Fro\nsubject to: G \u2265 0,F \u2265 0,R \u2265 0 (10)\nInstead we use the Tucker decomposition (shown in Equation 11) that allows us to find the complex interaction between E-groups, the roles they play, and R-groups they play those roles in. The diagrammatic explanation of Tucker decomposition in Figure 7 shows how it models these interactions. Like PARAFAC and NMF, it is a rank one decomposition which allows for an intuitive interpretation. A column in G corresponds to a group of people and is a length n indicator vector showing E-group membership. Similarly a column in F corresponds to a role definition which is a group of features and a column in R corresponds to a group of relations which we refer to as an R-group. Unlike PARAFAC and NMF, any factor can be any combination of the columns in G, F , and R. The core of the Tucker decomposition allows this complex interaction and requires more explanation (PARAFAC can be viewed as a specific Tucker with diagonal core). It too is a order 3 tensor except the modes are now directly interpretable as E-groups, roles, and R-groups. An entry in the core at i, j, k means that E-group i plays role j for R-group k. Understanding and simplifying this core is critical to the success of multi-relational role discovery using a Tucker decomposition.\nargmin G,F,R,H\n||V \u2212 \u2211\ni\n\u2211\nj\n\u2211\nk\nhijk \u2217 gk \u25e6 fk \u25e6 rk||Fro\nsubject to: G \u2265 0,F \u2265 0,R \u2265 0,H \u2265 0 (11)"}, {"heading": "7 Our MRDAlgorithm For Multi-Relational Graphs", "text": "The Tucker model has most often been described as a higher order analog of principal component analysis or singular value decomposition and is traditionally defined with factor matrices being orthogonal. Among the most popular tensor toolboxes, the Tucker model is often implemented with orthogonality constraint on the factor matrices (Tensor Toolbox [4, 2]) or with no constraint\nenforced on the core (Nway Toolbox [1]). Other recently proposed algorithms for non-negative Tucker model [24, 34] extend the classical multiplicative update procedures proposed for NMF [26], which is known to converge slowly near stationary points [29]. Since the alternating least squares (ALS) method is known as the \u201cworkhorse\u201d algorithm for PARAFAC [25] and is empirically demonstrated to be competitive among many existing methods [38], we implement our own version of non-negative Tucker decomposition using an alternating non-negative least squares (ANLS) scheme.\nLet V be the tensor to be decomposed. Denote the factor matrices by G,F and R and the core tensor by H. In each iteration we optimize over each of G,F,R and H in turn while fixing all others as constants. When G is being optimized, the objective can be written as:\nargmin G\u22650\n\u2016VG \u2212GHG(R\u2297 F)T \u2016Fro (12)\nwhere VG is the matricization of V in the first mode and \u2297 is the Kronecker product. The subproblems when F and R are being solved for have the exact same form but with a different variable being optimized. In addition it is generally desirable for the entries in the core to indicate the weights of each coupling of factors. Thus we normalize the columns of G,F and R once they are solved. When we solve for the core H, rewriting the tensors in vectorized form turns the objective into:\nargmin H\u22650\n\u2016vec(V)\u2212 (R\u2297 F\u2297G)vec(H)\u2016Fro (13)\nwhere vec(\u00b7) is the vectorization of a tensor. Our overall solver is summarized in Algorithm 1. We build our solver on top of the existing constructs in the MATLAB tensor toolbox [2] and employ the fast non-negative least squares (NNLS) solver particularly designed for tensor decomposition [9] when we solve subproblems (12) and (13). For the terminating condition we adopt the common practice for ALS which stops when the relative change in the objective between successive iterations is smaller than some pre-set threshold. It is worth noting that although we only enforce non-negativity constraints in this case, it requires little effort to adopt any constraint applicable to standard least squares problem into our formulation.\nAlgorithm 1 Multi-relational Role Discovery (MRD) using Alternating Least Squares Non-negative Tucker decomposition.\n1: Initialize G,F,R and H to any non-negative values 2: while Stop condition not met do 3: G\u2190 argmin G\u22650\n\u2016VG \u2212GHG(R\u2297 F)T \u2016Fro 4: Normalize the columns of G 5: F\u2190 argmin F\u22650\n\u2016VF \u2212 FHF (R\u2297G)T \u2016Fro 6: Normalize the columns of F 7: R\u2190 argmin R\u22650\n\u2016VR \u2212RHR(F\u2297G)T \u2016Fro 8: Normalize the columns of R 9: H \u2190 argminH\u22650 \u2016vec(V)\u2212 (R\u2297 F\u2297G)vec(H)\u2016Fro\n10: end while 11: return G,F,R,H\nAlgorithm Complexity. Our algorithm is an example of alternating least squares with each step being efficiently solvable using least squares solvers. The non-negativity requirement on the core can be efficiently enforced by solvers. Since tensor decomposition is well known to be intractable, we provide an estimate of our algorithm\u2019s run time to converge to a good local minima. The algorithm like most tensor decomposition algorithms has linear complexity with respect to the number of factors, modes and size of the core. In practice the decomposition of our graphs shown in the experimental section took under a minute to run on a 12-core machine."}, {"heading": "8 Interpretting Tensor Decomposition for Role", "text": "Discovery\nAfter applying Algorithm 1 we have decomposed the multi-relational graph into a series of E-groups (defined by G), a series of roles (defined by F ) and a series of R-groups (defined by R). The core of the Tucker decomposition measures the interaction between these E-groups, roles and R-groups. Here we show how to interpret and analyze the results of Tucker decomposition in a number of ways."}, {"heading": "8.1 Visually Interpreting Core Slices", "text": "We begin with the simple but useful approach of visually inspecting the core tensor slices to compare E-groups, roles, or R-groups. A slice of the core (depending on its orientation: left-to-right, top-to-down or back-to-front) can represent a E-group, role, or R-group. Different slices of the same orientation can then be used to compare the similarity of E-groups, roles and R-groups. For example in Figure 8 we display the slices corresponding to different E-groups from a multi-relational role discovery result.\nComparing the slices directly leads to very detailed comparison of E-groups because we compare for example if they have role/R-group combinations in common. However if we consider aggregations of these slices we can get more coarse comparison, such as whether or not the E-groups play the same roles, or whether they participate in the same R-groups. For example the third and fifth E-group look very similar in terms of the R-groups they take part in, but by looking at the slices we know that they differ because they play very different roles in those very same relations."}, {"heading": "8.2 Visualizing Core as an Interaction Graph", "text": "A further visual understanding of the phenomenon in the multi-relational graph can be obtained by visualizing the core as a graph. This is achieved by creating a node for every E-group, role, and R-group. This will of course be a heterogeneous graph. An entry in the core then could be represented in this graph as a clique on the triplet (E-group, role, R-group) it corresponds to. Since each edge corresponds to a Tucker core entry, it\u2019s edge can be weighted depending on that core value entry and be interpreted as a similarity. However, if we are focused say on predominantly understanding groups of entities, we can create a tripartite graph as shown in Figure 9 which removes the edge between the role and R-group. We shall call this graph the interaction graph to distinguish it from the original multi-relational graph we study.\nThis interaction graph can then be visualized and interesting signature patterns can be interpreted. See Figure 9 for some example signatures."}, {"heading": "8.3 Analysis of the Interaction Graph", "text": "Given the interaction graph described in the previous subsection which shows the relationship between E-groups, roles, and R-groups, we can analyze this graph any number of ways. For example, a popular approach to graph simplification is to embed the graph into a two dimensional space. Figure 16 shows such an embedding using PCA of the graph written in \u201chyper-edge\u201d form. That is a n\u00d7m matrix where each column in the matrix represents a hyper-edge and entry i, j has value 1 if node i is involved in hyper-edge j. This heterogeneous object embedding can be interpreted such that each cluster is a collection of E-groups, roles, and R-groups that often interact."}, {"heading": "8.4 Macroscopic Properties Derived from the Interaction Graph", "text": "Given the interpretation of the core as an interaction graph, we can than understand the macroscopic properties of the role dynamics by analyzing the interaction graph properties. The metrics we study are motivated in Table 5 along with how they are computed. These metric are meant to give the user a broad understanding of the underlying dynamics of the graph. The simplicity property tells how strongly aligned E-groups, roles and R-groups are, while the sharing property measure how many roles, and R-groups, are shared among different groups of entities. The variability property, captures the amount of imbalance in the complexities of different nodes in the interaction graph, by calculating both the variance of the node degrees as well as the entropy of the stationary distribution on a random walk along the interaction graph. Another important property we measure is the stability of the results we discovered. Here we wish to answer the question, how robust are the patterns found within the interactions graph and how easily could those patterns change due to small perturbations."}, {"heading": "8.5 Complex Analysis Via Role Transfer", "text": "Our work so far learned both the E-groups, role definitions and R-groups from the one multi-relational graph. However, we can transfer in these definitions from another source by holding them fixed as constants in the Tucker decomposition. For example, if we wish to transfer in a set of existing roles, we can adjust Algorithm 1 and not solve for the F matrix that defines the roles. This allows us to test many interesting questions such as how transferable the roles from other graphs are at explaining another multi-relational graph. We exper-\niment with this particular type of transfer in Figure 18, however other types of transfer are possible. We now discuss all types but due to space limitations show experiments only for role transfer.\nRole transfer can be used to detect to what extent roles are similar or dissimilar across different multi-relational graph. If there is a particularly interesting set of roles that have been studied in another graph, they can be transferred to a new graph to see how the nodes in that graph play those roles.\nE-group transfer can only be used if the multi-relational graphs are on the same entities. However if there are some well understood grouping of entities (say Democrat, Tea Party and Republican) these can be translated into Egroups and transferred to help gain understanding of the behaviors of those specific groups.\nR-group transfer, similar to role transfer, can be used to test how well relation groupings transfer across multiple graphs."}, {"heading": "9 Empirical Results", "text": "As in our previous work, all code and data sets will be made publicly available on our website.\nSince we wished to focus on analyzing both multi-relational graphs and collections of similar multi-relational graphs for transfer setting, we focused our empirical analysis on the Cosponsorship Network Data [15, 16] data set. This data set consists of congressional cosponsor data for over 30 years of congresses. Congressional representatives have the ability to add their name to a bill in order to lend support to it (called cosponsoring), and it has been argued that this act is a good measure of interaction within congress because legislators spend considerable effort convincing other representatives to cosponsor their bills. Using this publicly available information about cosponsorships, each congress can be broken up into a multi-relational graph with approximately 450 different nodes (congressional representatives) who jointly cosponsor approximately 10,000 bills per congress (many are just amendments). Table 6 show statistics for the graph created from the 110th congress, but in all we study the 96th-110th congresses, each of which has their own cosponsorship graph. Rather than create a cosponsorship graph based on all of the proposed bills from a particular congress, we build a multi-relational graph by viewing each committee as a separate relation (see Figure 10). Each bill is assigned to a committee based on the topic of the legislation. We analyzed bills from 15 different committees (the committees for which there were legislation in each congress 96th-110th) so that all of the relations are consistent over all the multi-relational graphs. Across the different congresses the one factor that does change is the set of elected representatives elected during each. Putting this altogether the multi-relational graph we study is a person\u00d7person\u00d7committee tensor such that the entry at (i, j, k) indicates how often congressman i and j cosponsored a bill that was sent to committee k for a particular congress. This graph has many underlying complexities in terms of groups of congressional representatives who work together (i.e., party-\nbased and tenure-length based), the roles that congressional representatives play (e.g., focused and generalist), and the relationships of the various bill areas (e.g., science-focused, business-focused). We study the last 15 congresses (96th to 110th) and have a multi-relational graph for each."}, {"heading": "9.1 Studies on a Single Multi-Relational Graph", "text": "Here we present results on the analysis of the 110th Congress which sat from 2007-2009. This was a Democrat controlled congress that sat during the last two years of President George W. Bush\u2019s administration. It was also unique in that it was the first Democrat controlled congress since 1995.\nWe analyzed this multi-relational cosponsor graph using our formulation for multi-relational role discovery. This produced E-groups, roles, and R-groups along with an interaction graph that explained the interactions between the three concepts. The E-groups are shown in Figure 12, the interpretation of role definitions is shown in Figure 11, and the composition of the R-groups is shown in Figure 13. How these E-groups, roles, and R-groups interact in the interaction graph are shown both directly as a sliced core in Figure 14, as a sparsified graph in Figure 15, and as a graph embedding in Figure 16.\nUnderlying E-groups, Roles and R-groups. Figure 12 shows that as expected people from the same party cosponsor the same bills though this further divides into two different E-groups per party. For the two Democrat groups we note that there is an E-group of mostly junior congressmen (group 4) whilst the other contains many of the senior congresswoman (group 1). Of particular note is the 5th E-group that contains a mix of Republican and Democrat representatives which largely represents a group of centralist members. For example McGotter was a well known member of the moderate \u201cRepublican Main Street\nPartnership\u201d. Figure 11 shows the types of roles that are found in the graph via sense making [21]. This plot shows for each role the attributes shared by representatives who play that role. Roles can be contrasted and compared in terms of these reference features. For example roles 2 and 4 both have comparable degree but largely differing weight, meaning representatives from both roles participated in cosponsorship with roughly the same number of other representatives, but representatives in role 4 cosponsored with the same people more often.\nFigure 13 shows the compositions of the R-groups. Each R-group is composed of some combination of the 15 studied relations each of which in turn correspond to a congressional committees which is roughly interpretable as the topic of the bill. While there is some overlap in the relational contribution of each R-group, each of them has a unique dominating relation (R-group 1 \u2018Ways and Means\u2019, R-group 2 \u2018Rules\u2019, R-group 3 \u2018Oversight and Government Reform\u2019, R-group 4 \u2018Education and Labor\u2019, R-group 5 \u2018Agriculture\u2019). Because we did not enforce orthogonality for our Tucker decomposition, as is commonly done (see Algorithm 1), we can see which relations are less distinguishing in terms of role analysis by looking at those relations that show up in multiple R-groups (e.g., \u2018Transport and Infrastructure\u2019 is assigned to every R-group).\nInteractions Between E-groups, Roles and R-groups. We now explain the Interaction Graph which is shown in Figure 15. As previously mentioned E-groups are largely divided by party even though party was not part of the data set. It can be argued then that this role discovery formulation discovered communities rather than roles. However the reason these groups divided along party lines is because parties are playing different roles in different R-groups. Depending on different factors such as which party is the majority, we expect the parties to play different roles, so our analysis matches our expectations.\nWhile there is much overlap in the R-groups that both parties participate in, the parties play different roles in those R-groups. For example the Republican groups participate largely in R-groups 3,4,5 while the Democrat groups participate largely in R-groups 1,2,3,5. However E-group 4 (Republican) and E-group 5 (Democrat) play different roles in R-group 5 (Agriculture). This is an example of a Role Tie from Figure 9.\nThere are also some roles and E-groups that are unique to a party. For example role 2 is exclusive to Republicans (many collaborators, but not many collaborations). And R-group 1 (Ways and Means) is more strongly associated with the Democrat E-groups. This makes sense, because the Ways and Means committee is one of the most prestigious to participate in and relates to tax legislation. It therefore makes sense that the majority party would be most active in this committee.\nThough the direct view of the interaction graph is useful, as discussed earlier there are other methods to understand the interaction. We can slice the core tensor either by E-group, role, or R-group and directly compare. Figure 14 shows such a comparison across E-groups. We can see that E-groups 1 and 3 both play role 5 but on different R-groups, also E-group 1 plays mainly one role, but E-group 3 plays multiple roles in the graph. Finally, we can embed\nthis graph into a metric space as shown in Figure 15."}, {"heading": "9.2 Studies Across Multiple Multi-Relational Graphs", "text": "We also performed multi-relational analysis across a total of 15 consecutive congresses and report the results here. There were two experiments we performed, to analyze these multi-relational graphs and to gain insight into them. First in Figure 17 we analyzed how the macro-properties of the learned interaction graphs, as discussed in Section 8.3, varied throughout the congress (see Figure 17). And second we determined how well roles definitions learned from one congress can transfer to others, as discussed in Section 8.5, the results of which are presented in Figure 18.\nFigure 17 shows the results of our analysis of macro-properties of the learned interaction graphs from the 96th-110th congresses. These results contain an immense amount of interesting insights and we focus on just a few due to space restrictions. The first unusual property is we note is a great spike of instability in the 101st congress. This is due to the election of a new President Bush following a very popular bipartisan President Regan. In addition many controversial bills were passed that crossed party lines such as the Americans With Disabilities Act. In contrast the 99th congress was very stable given it was Regan\u2019s second term and most bills were supported across partisan lines. Of particular note is also the sharp peaks during congresses 97, 101 and to lesser extent 103. They correspond precisely to changes in Presidencies: Carter (Democrat) to Regan (Republican) (97), Regan (Republican) to Bush (Republican) (101) and Bush (Republican) to Clinton (Democrat) (103).\nIn Figure 18 we show a heat map on the role transfer between different congresses. We first ran our algorithm to discover the roles for all congresses. Then we transferred each set of role definitions learned from all 15 congresses to every other congress, and measured the fit to determine how well each set of roles could be used to explain the behavior of every other congress. The heat map shows how well (dark red) or how poorly (dark blue) the roles for the congress in the row explained the interactions for the congress in the column. Of course the diagonal is dark red since those roles were built from data for that congress. As expected the block red structure indicates that later congresses roles can better explain later congresses behavior and earlier congresses roles can explain earlier congresses behavior. The solid blue block on the top left hand corner indicates that later congresses roles are very poor at explaining the later congresses behavior. The apparent outliers within the top right hand block and lower left hand block (i.e., the bluish entries amongst the red/yellow) are indicative of a shift in presidency or house majority either Democrat to Republican or vice-versa."}, {"heading": "10 Conclusion", "text": "Role discovery is an emerging and important area of graph mining. It looks at discovering nodes that perform similar functions in networks, but do not necessarily belong to the same community. Existing work so far has had two limitations: they are completely unsupervised and are focused on single relational graphs.\nWe propose a framework that allows incorporating convex constraints into NMF to allow a rich set of guided role discovery formulations. In particular we explore three types of guidance: sparsity, diversity and alternativeness. Sparsity and diversity can be used to create simpler and more interpretable role definitions and role allocations. Also they can reduce overfitting and produce better predictive results for matching authors between the KDD conference and a variety of other conferences provided they perform similar roles in both conferences. The notion of alternativeness has been explored in the clustering literature and is useful if the given explanation is not valid and an alternative is required. Here we show that not only do alternative roles exist in co-author networks, but that we can find an alternative to the community structure in a very large YouTube graph.\nWe then showed how to lift that framework to multi-relational graphs by first representing the multi-relational graph as a tensor. We then use a Tucker decomposition due to the more popular PARAFAC decomposition not being able to find the complex interactions that are likely to occur between the E-groups, roles, and R-groups. However, existing Tucker decomposition algorithms in popular toolboxes enforce properties that would lead to non-intuitive results for role discovery, hence we formulate our own algorithm. A critical aspect to our work is how to interpret and use the core of the Tucker decomposition which shows the complex interactions between the E-groups, roles, and R-groups. We show how it can be visualized and represented as an interaction graph whose properties we can use as macroscopic indicators of the original multi-relational graph. Our experimental results focus on 15 multi-relational Congressional cosponsor record graphs. Here an E-group is a collection of congressional representatives, an R-groups is the collection of bill types (determined by the committee they went through), with the roles being on cosponsoring behavior. We show that our methods can find intuitive and expected insights such as Republican and Democrats naturally separate into different E-groups. We also find that groups of representatives can play multiple roles for multiple R-groups, showing that the Tucker decomposition does indeed find the complex interactions we wish to discover. The macroscopic properties of the interaction graph show that the congresses vary greatly over time with abrupt changes being associated with changes in the Presidency and control of the Congress. Finally our transfer setting offers a useful insight into understanding how roles have differed across congress by using the roles from different congresses to explain the behavior of others."}, {"heading": "11 Acknowledgments", "text": "The authors gratefully acknowledge support of this research via ONR grants N00014-09-1-0712, N00014-11- 1-0108 and NSF Grant NSF IIS-0801528. This work was also supported in part by IARPA via AFRL Contract No. FA8650-10C-7061 and in part by DAPRA under SMISC Program Agreement No. W911NF12-C-0028."}, {"heading": "No Tie", "text": ""}], "references": [{"title": "The n-way toolbox for {MATLAB", "author": ["C.A. Andersson", "R. Bro"], "venue": "Chemometrics and Intelligent Laboratory Systems,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2000}, {"title": "Algorithm 862: MATLAB tensor classes for fast algorithm prototyping", "author": ["B.W. Bader", "T.G. Kolda"], "venue": "ACM Transactions on Mathematical Software, 32(4):635\u2013653, December", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2006}, {"title": "Matlab tensor toolbox version", "author": ["B.W. Bader", "T.G. Kolda"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Matlab tensor toolbox version 2.5", "author": ["B.W. Bader", "T.G. Kolda"], "venue": "Available online,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Constrained Clustering: Algorithms, Applications and Theory", "author": ["S. Basu", "I. Davidson", "K. Wagstaff"], "venue": "Prentice Hall,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2008}, {"title": "Mirror descent and nonlinear projected subgradient methods for convex optimization", "author": ["A. Beck", "M. Teboulle"], "venue": "Operations Research Letters, 31(3):167\u2013175,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2003}, {"title": "Algorithms and applications for approximate nonnegative matrix factorization", "author": ["M.W. Berry", "M. Browne", "A.N. Langville", "V.P. Pauca", "R.J. Plemmons"], "venue": "Computational Statistics and Data Analysis, 52(1):155\u2013173,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2007}, {"title": "Convex Optimization", "author": ["S. Boyd", "L. Vandenberghe"], "venue": "Cambridge University Press, NY, USA,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2004}, {"title": "A fast non-negativity-constrained least squares algorithm", "author": ["R. Bro", "S. De Jong"], "venue": "Journal of Chemometrics, 11(5):393\u2013401,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1997}, {"title": "Least squares algorithms under unimodality and non-negativity constraints", "author": ["R. Bro", "N.D. Sidiropoulos"], "venue": "J. of Chemometrics, 12(4):223\u2013247,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1998}, {"title": "CVX: Matlab software for disciplined convex programming, version 2.0 beta", "author": ["I. CVX Research"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Behavioral event data and their analysis", "author": ["I. Davidson", "S. Gilpin", "P.B. Walker"], "venue": "DMKD, 25(3):635\u2013653,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Finding alternative clusterings using constraints", "author": ["I. Davidson", "Z. Qi"], "venue": "ICDM, pages 773\u2013778,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2008}, {"title": "Efficient projections onto the l1-ball for learning in high dimensions", "author": ["J. Duchi", "S. Shalev-Shwartz", "Y. Singer", "T. Chandra"], "venue": "ICML, pages 272\u2013279,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2008}, {"title": "Connecting the Congress: A Study of Cosponsorship Networks", "author": ["J. Fowler"], "venue": "Political Analysis,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "Legislative Cosponsorship Networks in the U.S", "author": ["J. Fowler"], "venue": "House and Senate. Social Networks,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2006}, {"title": "Semi-supervised semantic role labeling", "author": ["H. Furstenau", "M. Lapata"], "venue": "EACL, pages 220\u2013228,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Guided learning for role discovery (glrd): Framework, algorithms, and applications", "author": ["S. Gilpin", "T. Eliassi-Rad", "I. Davidson"], "venue": "KDD,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Graph implementations for nonsmooth convex programs", "author": ["M. Grant", "S. Boyd"], "venue": "V. Blondel, S. Boyd, and H. Kimura, editors, Recent Advances in Learning and Control, Lecture Notes in Control and Information Sciences, pages 95\u2013110. Springer-Verlag Limited,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2008}, {"title": "Dimensionwise fitting in PARAFAC- CANDECOMP with missing data and constrained parameters", "author": ["W. Heiser", "P. Kroonenberg"], "venue": "Technical Report PRM 97-01, University of Leiden, The Netherlands,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1997}, {"title": "RolX: Structural role extraction & mining in large graphs", "author": ["K. Henderson", "B. Gallagher", "T. Eliassi-Rad", "H. Tong", "S. Basu", "L. Akoglu", "D. Koutra", "C. Faloutsos", "L. Li"], "venue": "KDD, pages 1231\u20131239,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2012}, {"title": "It\u2019s who you know: Graph mining using recursive structural features", "author": ["K. Henderson", "B. Gallagher", "L. Li", "L. Akoglu", "T. Eliassi-Rad", "H. Tong", "C. Faloutsos"], "venue": "KDD, pages 663\u2013671,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "Non-negative matrix factorization with sparseness constraints", "author": ["P.O. Hoyer"], "venue": "JMLR, 5:1457\u20131469,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2004}, {"title": "Nonnegative tucker decomposition", "author": ["Y.-D. Kim", "S. Choi"], "venue": "Computer Vision and Pattern Recognition, 2007. CVPR \u201907. IEEE Conference on, pages 1\u20138, June", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2007}, {"title": "Tensor decompositions and applications", "author": ["T.G. Kolda", "B.W. Bader"], "venue": "SIAM Review, 51(3):455\u2013500, September", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2009}, {"title": "Algorithms for non-negative matrix factorization", "author": ["D.D. Lee", "H.S. Seung"], "venue": "NIPS, pages 556\u2013562. MIT Press,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2000}, {"title": "The relationships among various nonnegative matrix factorization methods for clustering", "author": ["T. Li", "C. Ding"], "venue": "ICDM, pages 362\u2013371,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2006}, {"title": "Projected gradient methods for nonnegative matrix factorization", "author": ["C.-J. Lin"], "venue": "Neural Comput., 19(10):2756\u20132779, Oct.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2007}, {"title": "Constrained nonnegative matrix factorization for image representation", "author": ["H. Liu", "Z. Wu", "X. Li", "D. Cai", "T. Huang"], "venue": "PAMI, 34(7):1299\u20131311,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2012}, {"title": "SLEP: Sparse Learning with Efficient Projections", "author": ["J. Liu", "S. Ji", "J. Ye"], "venue": "Arizona State University,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2009}, {"title": "Efficient Euclidean projections in linear time", "author": ["J. Liu", "J. Ye"], "venue": "ICML, pages 657\u2013664,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2009}, {"title": "Measurement and analysis of online social networks", "author": ["A. Mislove", "M. Marcon", "K.P. Gummadi", "P. Druschel", "B. Bhattacharjee"], "venue": "IMC, pages 29\u201342,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2007}, {"title": "Algorithms for sparse nonnegative tucker decompositions", "author": ["M. Morup", "L.K. Hansen", "S.M. Arnfred"], "venue": "Neural Computat, 20:2112\u20132141,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2008}, {"title": "Positive matrix factorization: A non-negative factor model with optimal utilization of error estimates of data values", "author": ["P. Paatero", "U. Tapper"], "venue": "Environmetrics, 5(2):111\u2013126,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1994}, {"title": "A principled and flexible framework for finding alternative clusterings", "author": ["Z. Qi", "I. Davidson"], "venue": "KDD, pages 717\u2013726,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2009}, {"title": "Mixture models for learning low-dimensional roles in high-dimensional data", "author": ["M. Somaiya", "C. Jermaine", "S. Ranka"], "venue": "KDD, pages 909\u2013918,", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2010}, {"title": "A comparison of algorithms for fitting the parafac model", "author": ["G. Tomasi", "R. Bro"], "venue": "Computational Statistics & Data Analysis, 50(7):1700\u20131734, April", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2006}, {"title": "Numerical Linear Algebra", "author": ["L.N. Trefethen", "D. Bau"], "venue": "SIAM,", "citeRegEx": "39", "shortCiteRegEx": null, "year": 1997}, {"title": "Community discovery using nonnegative matrix factorization", "author": ["F. Wang", "T. Li", "X. Wang", "S. Zhu", "C. Ding"], "venue": "DMKD, 22(3):493\u2013521,", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 21, "context": "Earlier efforts convert this matrix into a new n\u00d7 f matrix V so that each node in the graph has a list of f features [22].", "startOffset": 117, "endOffset": 121}, {"referenceID": 20, "context": "This simplification of graphs into roles is not only intuitive for a domain expert, but it has been shown to be useful in a number of interesting settings including prediction, transfer learning, and sense making [21].", "startOffset": 213, "endOffset": 217}, {"referenceID": 4, "context": "These two recent trends in data mining \u2013 exploring the addition of positive and negative guidance \u2013 have been shown to have wide-scale application in the data mining literature [5][36]; but to our knowledge have not been applied to role discovery.", "startOffset": 177, "endOffset": 180}, {"referenceID": 34, "context": "These two recent trends in data mining \u2013 exploring the addition of positive and negative guidance \u2013 have been shown to have wide-scale application in the data mining literature [5][36]; but to our knowledge have not been applied to role discovery.", "startOffset": 180, "endOffset": 184}, {"referenceID": 21, "context": ", nodes) in the graph; the second mode is the features of each entity (obtained from our ReFeX package [22]), and the last mode represents the relations.", "startOffset": 103, "endOffset": 107}, {"referenceID": 21, "context": "2 Related Work The basis for role discovery in graphs using non-negative matrix factorization (NMF) was first proposed in a series of papers at KDD [22][21].", "startOffset": 148, "endOffset": 152}, {"referenceID": 20, "context": "2 Related Work The basis for role discovery in graphs using non-negative matrix factorization (NMF) was first proposed in a series of papers at KDD [22][21].", "startOffset": 152, "endOffset": 156}, {"referenceID": 21, "context": "The method ReFeX [22] described a recursive method to take a n\u00d7 n adjacency matrix (A) and compute a set of f salient features for each of the n nodes represented as a matrix V .", "startOffset": 17, "endOffset": 21}, {"referenceID": 20, "context": "The RolX method [21] made use of NMF to simplify the features into a set of roles and explored their use for graph matching, sense making and transfer learning.", "startOffset": 16, "endOffset": 20}, {"referenceID": 38, "context": "[40][28]) but theirs was the first to apply it to role discovery.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[40][28]) but theirs was the first to apply it to role discovery.", "startOffset": 4, "endOffset": 8}, {"referenceID": 35, "context": "Other methods for role discovery are not scalable to huge graphs and include Bayesian frameworks using MCMC sampling methods [37] and semi-supervised role labeling [17].", "startOffset": 125, "endOffset": 129}, {"referenceID": 16, "context": "Other methods for role discovery are not scalable to huge graphs and include Bayesian frameworks using MCMC sampling methods [37] and semi-supervised role labeling [17].", "startOffset": 164, "endOffset": 168}, {"referenceID": 11, "context": "The addition of guidance to matrix decomposition is a relatively new area with most work involving spatial data and properties such as unimodality as we have done for tensors [12].", "startOffset": 175, "endOffset": 179}, {"referenceID": 28, "context": "For example in [30] the authors propose the use of labeled information to guide the decomposition.", "startOffset": 15, "endOffset": 19}, {"referenceID": 22, "context": "Perhaps the closest to our own work is the use of sparseness constrains in NMF [23].", "startOffset": 79, "endOffset": 83}, {"referenceID": 4, "context": "others [5][36].", "startOffset": 7, "endOffset": 10}, {"referenceID": 34, "context": "others [5][36].", "startOffset": 10, "endOffset": 14}, {"referenceID": 33, "context": "Like many unconstrained NMF solvers, it uses the alternating least squares approach [35, 7].", "startOffset": 84, "endOffset": 91}, {"referenceID": 6, "context": "Like many unconstrained NMF solvers, it uses the alternating least squares approach [35, 7].", "startOffset": 84, "endOffset": 91}, {"referenceID": 5, "context": "The method we chose was motivated by gradient projection methods, which are known for being well-suited to quickly finding good but not highly accurate solutions for large problems, by sacrificing some of the theoretical convergence guarantees of methods such as interior point [6].", "startOffset": 278, "endOffset": 281}, {"referenceID": 37, "context": "Therefore, our algorithm has the advantage that each subproblem (but not the entire problem) can be solved exactly by reducing it into an unconstrained least square problem [39][3] and an Euclidean projection problem [14][32], both of which have efficient solutions.", "startOffset": 173, "endOffset": 177}, {"referenceID": 2, "context": "Therefore, our algorithm has the advantage that each subproblem (but not the entire problem) can be solved exactly by reducing it into an unconstrained least square problem [39][3] and an Euclidean projection problem [14][32], both of which have efficient solutions.", "startOffset": 177, "endOffset": 180}, {"referenceID": 13, "context": "Therefore, our algorithm has the advantage that each subproblem (but not the entire problem) can be solved exactly by reducing it into an unconstrained least square problem [39][3] and an Euclidean projection problem [14][32], both of which have efficient solutions.", "startOffset": 217, "endOffset": 221}, {"referenceID": 30, "context": "Therefore, our algorithm has the advantage that each subproblem (but not the entire problem) can be solved exactly by reducing it into an unconstrained least square problem [39][3] and an Euclidean projection problem [14][32], both of which have efficient solutions.", "startOffset": 221, "endOffset": 225}, {"referenceID": 29, "context": "Additionally, this approach to optimization (projected gradient descent) has been shown in the past to work well on largescale problems, at the expense of accuracy, and is used by state of the art solvers [31].", "startOffset": 205, "endOffset": 209}, {"referenceID": 9, "context": "Applications of this theorem and its proof can be found in [10][20].", "startOffset": 59, "endOffset": 63}, {"referenceID": 19, "context": "Applications of this theorem and its proof can be found in [10][20].", "startOffset": 63, "endOffset": 67}, {"referenceID": 11, "context": "Using this method allows us to solve much larger problems than we had previously been able to using standard constrained optimization solvers [12].", "startOffset": 142, "endOffset": 146}, {"referenceID": 10, "context": ", closest constrained point problem) is simple enough that we find for even medium-sized problems we could utilize high level solvers such as CVX [11][19], which makes experimenting with new types of constraints very simple.", "startOffset": 146, "endOffset": 150}, {"referenceID": 18, "context": ", closest constrained point problem) is simple enough that we find for even medium-sized problems we could utilize high level solvers such as CVX [11][19], which makes experimenting with new types of constraints very simple.", "startOffset": 150, "endOffset": 154}, {"referenceID": 20, "context": "\u2022 r: Number of roles (methods for learning r described in previous work [21]).", "startOffset": 72, "endOffset": 76}, {"referenceID": 7, "context": "In our formulation the L1 penalty is encoded as a constraint rather than a penalty in the objective, but it is known that these formulations are theoretically equivalent [8].", "startOffset": 170, "endOffset": 173}, {"referenceID": 34, "context": "3 Alternative Role Discovery Recent work on another unsupervised problem, clustering, has explored the area of alternativeness [36, 13].", "startOffset": 127, "endOffset": 135}, {"referenceID": 12, "context": "3 Alternative Role Discovery Recent work on another unsupervised problem, clustering, has explored the area of alternativeness [36, 13].", "startOffset": 127, "endOffset": 135}, {"referenceID": 20, "context": "For the former, we used the Minimum Description Length (MDL) described in [21] to automatically select the number of roles; and for the later, we used the approach described in [22].", "startOffset": 74, "endOffset": 78}, {"referenceID": 21, "context": "For the former, we used the Minimum Description Length (MDL) described in [21] to automatically select the number of roles; and for the later, we used the approach described in [22].", "startOffset": 177, "endOffset": 181}, {"referenceID": 21, "context": "We extract a set of relevant structure features for the KDD graph using REFEX [22], and compute these same features for all of the coauthor graphs.", "startOffset": 78, "endOffset": 82}, {"referenceID": 20, "context": "We subsequently learn a set of role definitions from the KDD graph using standard RolX [21] as well as the sparse and diverse versions of GLRD.", "startOffset": 87, "endOffset": 91}, {"referenceID": 20, "context": "These description are based on sense-making analysis [21].", "startOffset": 53, "endOffset": 57}, {"referenceID": 31, "context": "We next experiment with a YouTube dataset, which is a network of users with known ground-truth communities [33].", "startOffset": 107, "endOffset": 111}, {"referenceID": 20, "context": "After applying sense-making [21], the six roles that our GLRD(Alternative) finds are as follows: Alternative Role 1: Nodes here are global hubs.", "startOffset": 28, "endOffset": 32}, {"referenceID": 15, "context": "One natural choice of tensor decompositions to decompose a feature tensor would be non-negative PARAFAC [16].", "startOffset": 104, "endOffset": 108}, {"referenceID": 3, "context": "Among the most popular tensor toolboxes, the Tucker model is often implemented with orthogonality constraint on the factor matrices (Tensor Toolbox [4, 2]) or with no constraint", "startOffset": 148, "endOffset": 154}, {"referenceID": 1, "context": "Among the most popular tensor toolboxes, the Tucker model is often implemented with orthogonality constraint on the factor matrices (Tensor Toolbox [4, 2]) or with no constraint", "startOffset": 148, "endOffset": 154}, {"referenceID": 0, "context": "enforced on the core (Nway Toolbox [1]).", "startOffset": 35, "endOffset": 38}, {"referenceID": 23, "context": "Other recently proposed algorithms for non-negative Tucker model [24, 34] extend the classical multiplicative update procedures proposed for NMF [26], which is known to converge slowly near stationary points [29].", "startOffset": 65, "endOffset": 73}, {"referenceID": 32, "context": "Other recently proposed algorithms for non-negative Tucker model [24, 34] extend the classical multiplicative update procedures proposed for NMF [26], which is known to converge slowly near stationary points [29].", "startOffset": 65, "endOffset": 73}, {"referenceID": 25, "context": "Other recently proposed algorithms for non-negative Tucker model [24, 34] extend the classical multiplicative update procedures proposed for NMF [26], which is known to converge slowly near stationary points [29].", "startOffset": 145, "endOffset": 149}, {"referenceID": 27, "context": "Other recently proposed algorithms for non-negative Tucker model [24, 34] extend the classical multiplicative update procedures proposed for NMF [26], which is known to converge slowly near stationary points [29].", "startOffset": 208, "endOffset": 212}, {"referenceID": 24, "context": "Since the alternating least squares (ALS) method is known as the \u201cworkhorse\u201d algorithm for PARAFAC [25] and is empirically demonstrated to be competitive among many existing methods [38], we implement our own version of non-negative Tucker decomposition using an alternating non-negative least squares (ANLS) scheme.", "startOffset": 99, "endOffset": 103}, {"referenceID": 36, "context": "Since the alternating least squares (ALS) method is known as the \u201cworkhorse\u201d algorithm for PARAFAC [25] and is empirically demonstrated to be competitive among many existing methods [38], we implement our own version of non-negative Tucker decomposition using an alternating non-negative least squares (ANLS) scheme.", "startOffset": 182, "endOffset": 186}, {"referenceID": 1, "context": "We build our solver on top of the existing constructs in the MATLAB tensor toolbox [2] and employ the fast non-negative least squares (NNLS) solver particularly designed for tensor decomposition [9] when we solve subproblems (12) and (13).", "startOffset": 83, "endOffset": 86}, {"referenceID": 8, "context": "We build our solver on top of the existing constructs in the MATLAB tensor toolbox [2] and employ the fast non-negative least squares (NNLS) solver particularly designed for tensor decomposition [9] when we solve subproblems (12) and (13).", "startOffset": 195, "endOffset": 198}, {"referenceID": 14, "context": "Since we wished to focus on analyzing both multi-relational graphs and collections of similar multi-relational graphs for transfer setting, we focused our empirical analysis on the Cosponsorship Network Data [15, 16] data set.", "startOffset": 208, "endOffset": 216}, {"referenceID": 15, "context": "Since we wished to focus on analyzing both multi-relational graphs and collections of similar multi-relational graphs for transfer setting, we focused our empirical analysis on the Cosponsorship Network Data [15, 16] data set.", "startOffset": 208, "endOffset": 216}, {"referenceID": 20, "context": "Figure 11 shows the types of roles that are found in the graph via sense making [21].", "startOffset": 80, "endOffset": 84}, {"referenceID": 0, "context": "References [1] C.", "startOffset": 11, "endOffset": 14}, {"referenceID": 1, "context": "[2] B.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] B.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] B.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] S.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] A.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] M.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] S.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] R.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] R.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] I.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] I.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] I.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] H.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] W.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[21] K.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[22] K.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[23] P.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] Y.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[25] T.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[26] D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[28] T.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[29] C.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[30] H.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[31] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[32] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "[33] A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "[34] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "[35] P.", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "[36] Z.", "startOffset": 0, "endOffset": 4}, {"referenceID": 35, "context": "[37] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 36, "context": "[38] G.", "startOffset": 0, "endOffset": 4}, {"referenceID": 37, "context": "[39] L.", "startOffset": 0, "endOffset": 4}, {"referenceID": 38, "context": "[40] F.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "The PARAFAC tensor decomposition is a rank 1 simplification of the graph and is the natural analog to the earlier used [21, 18] NMF formulation of role discovery.", "startOffset": 119, "endOffset": 127}, {"referenceID": 17, "context": "The PARAFAC tensor decomposition is a rank 1 simplification of the graph and is the natural analog to the earlier used [21, 18] NMF formulation of role discovery.", "startOffset": 119, "endOffset": 127}], "year": 2016, "abstractText": "Role discovery in graphs is an emerging area that allows analysis of complex graphs in an intuitive way. In contrast to other graph problems such as community discovery, which finds groups of highly connected nodes, the role discovery problem finds groups of nodes that share similar graph topological structure. However, existing work so far has two severe limitations that prevent its use in some domains. Firstly, it is completely unsupervised which is undesirable for a number of reasons. Secondly, most work is limited to a single relational graph. We address both these limitations in an intuitive and easy to implement alternating least squares framework. Our framework allows convex constraints to be placed on the role discovery problem which can provide useful supervision. In particular we explore supervision to enforce i) sparsity, ii) diversity and iii) alternativeness. We then show how to lift this work for multi-relational graphs. A natural representation of a multi-relational graph is an order 3 tensor (rather than a matrix) and that a Tucker decomposition allows us to find complex interactions between collections of entities (E-groups) and the roles they play for a combination of relations (R-groups). Existing Tucker decomposition methods in tensor toolboxes are not suited for our purpose, so we create our own algorithm that we demonstrate is pragmatically useful.", "creator": "LaTeX with hyperref package"}}}