{"id": "1609.06578", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Sep-2016", "title": "Twitter Opinion Topic Model: Extracting Product Opinions from Tweets by Leveraging Hashtags and Sentiment Lexicon", "abstract": "Aspect - product opinion metallurgy not particularly established to compliance applications to aggregate or summarise philosophical of a sale, many along current state - especially - held - art becomes achieved with Latent Dirichlet Allocation (LDA) - enterprise model. Although integration as users well murids either carried some opinions, way \" guys \" nature (not natural lexicon) even hesitant diseases one permit LDA - regional statements generation both consumer review mining. Tweets represent otherwise informal, unstructured and conscious item data different they categories then quarterly, more very challenging for hardware indeed metallurgy. In may paper, things propose an LDA - based opinion comparison whose Twitter Opinion Topic Model (TOTM) for regarding venture have sentiment analysis. TOTM leverages utis, pliny, demonstratives already leading growing mentions still well important since messages until plans discovery meant. It depends opinion uncertain same evaluating brought charge - explain interaction they, thus uncover target specific opinion familiar, neglected in existing broader. Moreover, mean recommendations every week differs common curriculum sentiment upon search off little topic model, others utilizing fact such policies sentiment lexicon. This name adventure. that then daughter by updates all the data. We handling tests. 9 400 tweets full combining materials, and efforts next improvements focus other TOTM in way quantitative diligence making qualitative analysis. We show be understanding - based appeal accuracy on massive volume of tweets proper types discussion immediately products.", "histories": [["v1", "Wed, 21 Sep 2016 14:25:23 GMT  (551kb,D)", "http://arxiv.org/abs/1609.06578v1", "CIKM paper"]], "COMMENTS": "CIKM paper", "reviews": [], "SUBJECTS": "cs.CL cs.IR cs.LG", "authors": ["kar wai lim", "wray buntine"], "accepted": false, "id": "1609.06578"}, "pdf": {"name": "1609.06578.pdf", "metadata": {"source": "CRF", "title": "Twitter Opinion Topic Model: Extracting Product Opinions from Tweets by Leveraging Hashtags and Sentiment Lexicon", "authors": ["Kar Wai Lim", "Wray Buntine"], "emails": ["karwai.lim@anu.edu.au", "wray.buntine@monash.edu", "permissions@acm.org."], "sections": [{"heading": null, "text": "Categories and Subject Descriptors I.2.7 [Artificial Intelligence]: NLP\u2014Text analysis\nGeneral Terms Design, Experimentation\nKeywords Opinion mining, sentiment analysis, Twitter, topic modeling, product review, sentiment lexicon, emoticons"}, {"heading": "1. INTRODUCTION", "text": "When making a purchase decision, a key deciding factor can often be the reviews written by other consumers. These reviews are Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CIKM\u201914, November 3\u20137, 2014, Shanghai, China. Copyright is held by the owner/author(s). Publication rights licensed to ACM. ACM 978-1-4503-2598-1/14/11 ...$15.00. http://dx.doi.org/10.1145/2661829.2662005.\nfreely available online, however, one can rarely read all the reviews given their volume. This has led to various automated algorithms to mine the reviews, extracting a more digestible summary for a user. The task of analyzing opinions from text data such as reviews is known as opinion mining or opinion extraction [19, 33].\nAmong various approaches to opinion mining, aspect-based opinion mining has recently gained a lot of attention from the research community. Aspect-based opinion mining involves extracting the major aspects or facets from data for analysis. As an example, for a camera product, the aspects could be \u201cpicture quality\u201d, \u201cportability\u201d etc. Topic models are often used to determine the aspects through soft clustering. Topic models have been successfully applied to review data crawled from review websites such as Epinions.com, TripAdvisor etc. LDA-based models are considered to be state-of-the-art for aspect-based opinion mining [28].\nBesides reviews extracted from review websites, opinions from social media websites are also very useful, even though they are often overlooked as a source for reviews. Social media text is short and is regarded as \u201cdirty\u201d, and hence less useful for more sophisticated language analysis [47]. The same problem also leads to degradation when applying NLP tools [36]. Despite these limitations, large numbers of tweets containing opinions are generated every day and are very relevant for opinion mining. We argue that while tweets are generally unstructured, Twitter is a useful source of reviews since it provides a convenient platform for users to express their opinions. Twitter is also integrated to a person\u2019s social life, making it easier for users to express their opinions on products by tweeting instead of writing a review on review websites.\nIn this paper, we demonstrate the usefulness of Twitter as a source for aspect-based target-opinion mining. We propose a novel LDAbased opinion model that is designed for tweets, which we name Twitter Opinion Topic Model (TOTM). TOTM models the targetopinion interaction directly, which significantly improves opinion prediction, e.g. TOTM discovers \u2018grilled\u2019 is positive for sausage but not other targets. We note that while there are no explicit ratings and scores on tweets, tweets often contain emoticons and strong sentiment words, such as \u2018love\u2019 and \u2018hate\u2019. TOTM exploits this fact and uses the information to compensate for the lack of explicit ratings. Additionally, hashtags are strong indicators of topics for tweets [24]. TOTM makes use of the hashtags and mentions in tweets for tweet aggregation, which improves aspect clustering. Modeling with TOTM also allows us to acquire additional summaries on products, which are not obtainable with existing models.\nFurthermore, we incorporate a sentiment lexicon as prior information into TOTM. We propose a novel formulation of how the sentiment lexicon affects the priors in TOTM. Our approach facilitates automatic learning of the lexicon strength based on the data; while current existing methods are ad hoc or ruled-based. Our for-\nar X\niv :1\n60 9.\n06 57\n8v 1\n[ cs\n.C L\n] 2\n1 Se\np 20\n16\nmulation is shown to perform best for sentiment classification. Additionally, we propose a different target-opinion extraction procedure that works better for tweets, discussed in Subsection 8.1. We note that text preprocessing is important when dealing with tweets.\nWe apply TOTM to 3 tweets corpus, showing improved performance of TOTM in model fitting and sentiment analysis. Qualitatively, we demonstrate the usefulness of TOTM in extracting the opinions on products from tweets. As large volumes of tweets laden with opinions are generated daily, real-time aspect-based opinion analysis allows us to obtain first-hand opinions on new products, which might not be as readily available from review websites.\nThe rest of the paper is structured as follows. Section 2 reviews some related work, and Section 3 provides a summary of our task and major contributions. In Section 4, we present Interdependent LDA (ILDA) [27] which will be used as a baseline for comparison. We introduce TOTM in Section 5 and the method of incorporating a lexicon in Section 6. In Section 7, we discuss TOTM\u2019s model likelihood and inference procedure, as well as proposing a novel hyperparameter sampling procedure. We then describe the data used in this paper and report on the experiments in Sections 8 and 9. Finally, we conclude the paper in Section 10."}, {"heading": "2. RELATED WORK", "text": "Latent Dirichlet Allocation (LDA) is a topic model that has been extended by many for sentiment analysis. Notable examples based on LDA include the MaxEnt-LDA hybrid model [48], Joint Sentiment Topic (JST) model [18], Multi-grain LDA (MG-LDA) [43], Interdependent LDA (ILDA) [27], Aspect and Sentiment Unification Model (ASUM) [15] and Multi-Aspect Sentiment (MAS) model [42]. The Topic-Sentiment Mixture (TSM) model [25] performs sentiment analysis by utilizing the Multinomial distribution. These models perform aspect-based opinion analysis and they had been successfully applied to review data of different domains, such as electronic product, hotel and restaurant reviews. The task of summarizing the reviews is also known as opinion aggregation.\nTo the best of our knowledge, there is no existing LDA-based opinion aggregation method that has been successfully applied to social media data such as tweets. Current opinion mining methods that are used on tweets tend to be ad hoc or rule-based. We suspect this is because tweets are generally regarded as too noisy for modelbased methods to work, and also due to the fact that LDA works badly on short documents. Maynard et al. [22] studied the challenges in developing an opinion mining tool for social media and they advocated the use of shallow techniques in linguistic processing of tweets. Notable non-LDA-based methods for opinion analysis include OPINE [35], which uses relaxation labeling to classify sentiment, and Opinion Digger [26], an aspect-based review miner using k nearest neighbor. Hu and Liu [12] performed rule-based target-opinion extraction from online product reviews, while Li et al. [16] extracted opinions from reviews using Conditional Random Fields. On tweets, Pak and Paroubek [32] performed opinion analysis using a Naive Bayes classifier; while Liu et al. [20] performed sentiment classification using an adaptive co-training SVM. Go et al. [8] and Davidov et al. [4] made use of emoticons (smileys), which were found to provide improvement for sentiment classification on tweets. Since tweets are always short, existing work [8, 32, 4, 20] tends to assume a single polarity for each tweet. In contrast, Jiang et al. [14] performed target-dependent sentiment analysis, where the sentiments apply to a specific target.\nLexical information can be used to improve sentiment analysis. He [11] used a sentiment lexicon to modify the priors of LDA for sentiment classification, though with an approach with ad hoc constants. Li et al. [17] incorporated a lexical dictionary into a non-\nnegative matrix tri-factorization model, using a simple rule-based polarity assignment. Refer to Ding et al. [6] and Taboada et al. [37] for a detailed review on applying lexicon-based methods in sentiment analysis. Instead of a lexicon, Jagarlamudi et al. [13] used seeded words as lexical priors for semi-supervised topic modeling."}, {"heading": "3. OPINION MINING TASK ON TWEETS", "text": "In this section, we describe the opinion mining problem we are tackling and outline our major contributions in solving the problem."}, {"heading": "3.1 Problem Definition", "text": "Given a collection of documents (tweets), our first problem is to extract target-opinion pairs from each document. A target-opinion pair \u3008t, o\u3009 consists of two phrases: a target phrase t which is the object being described, and an opinion phrase o which is the description. Target phrases are usually nouns and opinion phrases are usually adjectives, examples include \u3008picture quality, good\u3009, \u3008iPhone app, expensive\u3009 etc. Note that a phrase can be either a collocation (multi-word phrase) or a single word. For simplicity, we will use \u2018word\u2019 to mean a single-word or a phrase in this paper.\nOur next problem is to group the target-opinion pairs into clusters and identify the associated sentiments. The produced clusters should depend on the tweet corpus, as they should represent different aspects of the corpus. For example, given a tweet corpus which consists of various electronic products, we would like different products to be grouped into different clusters. Each targetopinion pair is assigned 2 latent labels, the first being aspect a indicating which cluster the pair belongs, the second label being sentiment r. The sentiment of a target-opinion pair refers to the polarity of the opinion phrase, which can be negative, neutral or positive.\nFinally, we would like to display a summary (high level view) of the obtained quadruples \u3008t, o, a, r\u3009. There are many ways to do this, here we follow the standard topic modeling approach to display the top phrases. We inspect the target phrases given the aspects. We also examine the opinion phrases given the target phrases and sentiments. In brief, our task of opinion mining on tweets is to extract useful opinions and represent them in a format that is easy to digest. For example, with a tweet corpus on electronic products, we would like to discover the opinions of Twitter users on certain products, such as iPhones."}, {"heading": "3.2 Major Contributions", "text": "We make two major contributions as follows: Firstly, we design an LDA-based topic model (TOTM) for performing aspect-based target-opinion analysis on product reviews from tweets. TOTM is novel in that it directly models the target-opinion interaction, giving significant improvement in opinion prediction. Existing aspectbased methods only model the interaction between aspects and sentiments, leaving the targets and opinions to be weakly associated through aspects and sentiments. Without this explicit modeling, the existing models failed to sensibly assign opinions to targets. For example, from a restaurant review with friendly staff and delicious cake, existing LDA-based opinion model failed to recognize that friendly cannot be used to describe cake. Also, as mentioned in the introduction, TOTM makes use of available auxiliary variables in tweets (hashtags, mentions, emoticons and strong sentiment words) to improve aspect-based opinion analysis.\nSecondly, we propose a new formulation for incorporating a sentiment lexicon into our topic model. While existing methods adopt an ad hoc or ruled-based approach to incorporating sentiment prior, our formulation is novel in that it is learned automatically given the data. This is done robustly using a tuning hyperparameter that is optimized automatically. The sentiment information is used to adjust the opinion priors in order to improve sentiment analysis.\n4. BASELINE: INTERDEPENDENT LDA\nInterdependent LDA (ILDA) [27] is an extension of LDA that performs aspect-based opinion analysis. It jointly models the aspect (a) and sentiment1 (r) for each target-opinion pair \u3008t, o\u3009 that is present in a document. We note that the sentiment variable r is a categorical variable, and is not restricted to just 3 values. However, in this paper, we will assume that the sentiment r has only three labels {\u22121, 0, 1}, which correspond to negative, neutral and positive sentiment respectively.\nIn this paper, we treat ILDA as a baseline. It has the following generative process. For each document d, we sample a documentaspect distribution\n\u03b8d \u223c Dir(\u03b1\u03b8) .\nFor each aspect a, we sample an aspect-sentiment distribution \u03b7a and an aspect-target word distribution \u03c8a:\n\u03b7a \u223c Dir(\u03b1\u03b7) , \u03c8a \u223c Dir(\u03b1\u03c8) .\nGiven each sentiment r, we sample a sentiment-opinion phrase distribution\n\u03c6r \u223c Dir(\u03b1\u03c6) .\nFinally, we model each target-opinion pair \u3008tdn, odn\u3009 and their respective latent aspects and sentiments.\nadn \u223c Discrete(\u03b8d) , rdn \u223c Discrete(\u03b7adn) , tdn \u223c Discrete(\u03c8adn) , odn \u223c Discrete(\u03c6rdn) .\nWe note that the \u03b1\u2019s are the hyperparameters corresponding to the symmetric Dirichlet distributions.\nILDA models the sentiment conditionally on the aspect; and given the aspect and sentiment, the target word and opinion word are generated independently. Although such modeling is often adequate (since many of the opinion words can be applied generally to most target words), it fails to take into account that some opinion words are restricted to certain target words, and vice versa. For example, we can say a phone has short battery life but not short camera quality.\nIn this paper, we do not compare against other models such as MG-LDA and ASUM, since these models do not perform targetbased opinion analysis, and thus not directly comparable."}, {"heading": "5. TWITTER OPINION TOPIC MODEL", "text": "Here we present the Twitter Opinion Topic Model for aspectbased opinion analysis on tweets. The model is given in Figure 2. Contrary to ILDA, we do not model the aspect-sentiment distribution \u03b7. Instead, we model the target-opinion pairs directly. This allows us to better model the opinion words, and also provides us with a finer level of opinion analysis. For example, TOTM will be able to model that the word \u2018limited\u2019 can describe battery life but is unlikely to be used to describe charger.\n1Also known as rating in Moghaddam and Ester [27].\nTOTM uses the Griffiths-Engen-McCloskey (GEM) [34] distribution to generate probability vectors and the Pitman-Yor process (PYP) [39] to generate probability vector given another mean probability vector. Both GEM and PYP are parameterized by a discount parameter \u03b1 and a concentration parameter \u03b2; and PYP is additionally parameterized by a mean or base distribution H . The GEM distribution is equivalent to the PYP with a base distribution that generates an ordered integer label, H\u03b8 . The PYP is also known as the two-parameter Poisson-Dirichlet process.\nWe introduce a variable e named emotion indicator, which detects the existence of emoticons and/or strong sentiment words in the documents. The strong sentiment words are hand-selected and represent words that are associated with a person\u2019s positive or negative feeling. We present some examples of strong sentiment words in Table 2, and provide the full list in the supplementary material made available online on the author\u2019s website. We define e to be \u22121 when only a negative emotion is observed and e to be 1 when only a positive emotion is observed, otherwise we treat e as unobserved. Note that e = 0 would correspond to a neutral emotion, but we have no such observations so this is not considered.\nThe generative process of TOTM is as follows. First, we sample the document-aspect distribution \u03b8d for each document d,\n\u03b8d \u223c GEM(\u03b1\u03b8, \u03b2\u03b8) .\nSecond, for e = {\u22121, 1}, we model the emotion-sentiment distribution \u03b3e by a Dirichlet distribution with asymmetric prior:\n\u03b3e|e \u223c Dir(~qe) .\nThe prior qe is chosen such that ~q\u22121 = (0.9, 0.05, 0.05) and ~q1 = (0.05, 0.05, 0.9).\nNext, for the target words, we generate the aspect-target distribution \u03c8a for each aspect a:\n\u03c8a \u223c PYP(\u03b1\u03c8, \u03b2\u03c8, H\u03c8) .\nHere, H\u03c8 is a discrete uniform vector over the vocabulary of the target words (Vt).\nFor the opinion words, we propose a novel hierarchical modeling that allows an opinion word to describe two different targets differently (e.g. short for processing time is good but short for battery life is bad), while at the same time allows for sharing of the polarity of opinion words between targets. This is achieved by assigning common base distributions to the target-opinion distributions. So target-opinion distributions \u03c6\u2032tr for different targets t share a common mean \u03c6r which itself is unknown so we sample it from a uniform base \u03c6\u2217r . More specifically, for each r = {\u22121, 0, 1} and t = {1, . . . , |Vt|}, we generate \u03c6\u2032tr as follows:\n\u03c6\u2217r = ~1/|Vo| ,\n\u03c6r|\u03c6\u2217r \u223c PYP(\u03b1\u03c6, \u03b2\u03c6, \u03c6\u2217r) ,\n\u03c6\u2032tr|\u03c6r \u223c PYP(\u03b1\u03c6 \u2032 , \u03b2\u03c6 \u2032 , \u03c6r) ,\nwhere Vo is the vocabulary of the opinion words. Finally, for each target-opinion pair \u3008tdn, odn\u3009 (indexed by n) in document d, we sample the respective aspect adn, sentiment rdn and the target-opinion pair:\nadn|\u03b8d \u223c Discrete(\u03b8d) , rdn|ed, \u03b3 \u223c Discrete(\u03b3ed) , tdn|adn, \u03c8 \u223c Discrete(\u03c8adn) ,\nodn|tdn, rdn, \u03c6\u2032 \u223c Discrete(\u03c6\u2032tdn,rdn) .\nWe note that each PYP distribution is parameterized by its own set of hyperparameters, i.e. \u03b2\u03b8 differs for different document d, albeit not explicitly shown above for readability. We present a list of variables associated with TOTM in Table 1. Also note that by modeling the target-opinion distribution explicitly, we have to store the information of the distribution for each target in the data, which is very large. In our implementation, we adopt a sparse representation for storing the counts associated with the target-opinion distributions. We find that each target word is only described by a limited number of opinion words in the data, which is less than 1% of the words from the opinion word vocabulary.\nIn the next section, we propose a novel method to incorporate sentiment prior information for opinion analysis."}, {"heading": "6. INCORPORATING SENTIMENT PRIOR", "text": "He [11] proposed a simple yet effective way to incorporate sentiment prior information into LDA by directly modifying the Dirichlet prior based on available sentiment lexicons. Naming her model LDA-DP (LDA with Dirichlet Prior modified), He replaces the topics in LDA by latent sentiment labels and allows the word priors to be custom probability distributions. The generative process of LDA-DP is identical to LDA and hence omitted in this paper.\nIn LDA-DP, the word distribution \u03c6r is Dirichlet distributed with the parameter (~\u03bbr \u00d7 \u03b1r), where r = {\u22121, 0, 1} is the sentiment label corresponding to negative, neutral and positive sentiment, respectively2. The \u03bbrv is initialized to be 1/3, and subsequently updated if the sentiment lexicon contains word v. In this case, \u03bbrv\n2We redefined the original sentiment labels [11] for consistency.\ntakes the value of 0.9 if the sentiment of word v matches r, and takes the value of 0.05 otherwise:\n\u03bbrv =\n{ 0.9 if Sentiment(v) = r\n0.05 otherwise\nMotivated by this, but not wishing to be required to give the exact strength by which the dictionary affects probabilities, instead, we propose a novel formulation that automatically learns and updates itself. We assume that a sentiment lexicon is available and provides sentiment scores for opinion words. Additionally, we assume that the sentiment score Sv returned from the sentiment lexicon takes negative value when v has negative sentiment, positive value when v has positive sentiment, and 0 when v is neutral3.\nSentiment lexicons that are freely available online include SentiWordNet [1], SentiStrength [41], MPQA Subjectivity lexicon [45] and others. SentiStrength is developed from MySpace4 text data by a research group (Statistical Cybermetrics Research Group) from the University of Wolverhampton, UK. Since the SentiStrength lexicon is constructed for informal text, we use it to extract sentiment information for TOTM. The sentiment score Sv from SentiStrenth ranges from \u22125 to +5, which conforms to our assumption. We assume that Sv = 0 for unlisted words.\nAdditionally, we make use of the SentiWordNet 3.0 lexicon to evaluate TOTM. SentiWordNet is built on WordNet [7] by researchers from Italy. We note that SentiStrength and SentiWordNet are developed independently by different teams using different methods. Thus we claim it is fair and unbiased to use one lexicon for training and the other for evaluation.\nOur formulation is as follows, introducing a tunable parameter b that controls the strength of the prior, we replace the prior \u03c6\u2217r (in the context of TOTM) by the following:\n\u03c6\u2217rv \u221d (1 + b)Xrv , (1)\nwhere b > 0 and hence \u03c6\u2217rv > 0. Here, Xrv is the score of word v for sentiment r, which is defined as\nXrv =  Sv if r = 1 (positive)\n\u2212|Sv| if r = 0 (neutral) \u2212Sv if r = \u22121 (negative) .\nNote that although there are multiple ways to formulate the prior, we choose the above formulation due to its simplicity and intuitiveness. We can see that positiveXrv boosts the probability of word v while a negative Xrv diminishes it. Also, this formulation ensures the positivity of the prior, which can be difficult to achieve if we use other formulations such as a polynomial function.\nEven though b is a tunable parameter, we do not need to manually tune it. We propose a flexible way to learn the parameter b from its posterior distribution (detailed in Subsection 7.2), thus relieving us from choosing the value for b, which can be difficult (the value of b should depend on the sentiment score of the lexicon)."}, {"heading": "7. INFERENCE TECHNIQUE", "text": "In this section, we discuss the collapsed Gibbs sampler for TOTM, and then discuss the sampling of the hyperparameters."}, {"heading": "7.1 Collapsed Gibbs Sampling for TOTM", "text": "The key to Gibbs sampling with PYPs is to marginalize out the probability vectors (e.g. \u03b8) in the model and record various associated counts instead, thus yielding a collapsed sampler. While a 3We can simply normalize the score to conform to this assumption. 4MySpace is a social networking website similar to Facebook.\nAlgorithm 1 Collapsed Gibbs Sampling for TOTM\n1. Initialize the model by assigning a random aspect to each targetopinion pair, sampling the sentiment label, and building the relevant customer counts cNk and table counts c \u2032N k for all nodes.\n2. For each document d:\n(a) For each target phrase tdn: i. Decrement counts associated with tdn.\nii. Sample new aspect adn and corresponding parts of C from Equation 4.\niii. Increment associated counts for the new adn. (b) For each opinion phrase odn:\ni. Decrement counts associated with odn. ii. Sample new sentiment rdn and corresponding parts\nof C (like Equation 4). iii. Increment associated counts for the new rdn.\n3. Repeat step 2 until the model converges or when a fixed number of iterations is reached.\ncommon approach here is to use the Chinese Restaurant Process (CRP) representation of Teh and Jordan [40], we use another representation that requires no dynamic memory and has better inference efficiency [3]. We let g(N ) be the marginalized likelihood associated with the probability vectorN . The vector is marginalized out, thus the likelihood is in terms of \u2014 using the CRP terminology \u2014 the customer counts cN = (. . . , cNi , . . . ) and the total customer count CN (the sum of cNi ). For the PYP, we introduce the table counts c\u2032N = (. . . , c\u2032i N , . . . ) that represents the subset of cN that gets passed up the hierarchy (as customer for the parent probability vector ofN ), and C\u2032N , the total table count. For instance, looking at the sub-hierarchy in Figure 2 for \u03c6\u2032tr \u2190 \u03c6r \u2190 \u03c6\u2217r , the customer count c\u03c6 \u2032 tr v for opinion index v is associated with the table count c\u2032\u03c6 \u2032 tr v which are added to the customer count c\u03c6rv (\u03c6r is the parent of \u03c6\u2032tr). The table count of \u03c6r , c\u2032 \u03c6r v , is in turn added to the customer count c\u03c6 \u2217 r v . Note that table count is always smaller than customer count (c\u2032Ni \u2264 cNi ). These counts are latent, not observed, hence they are sampled during inference.\nBy using the above representation, we do not need to record the occupancy counts of each table, hence we do not need a dynamic storage. The marginalized likelihood is given by\ng(N ) = (\u03b2 N |\u03b1N )C\u2032N (\u03b2N )CN \u220f i S cNi c\u2032Ni ,\u03b1 N , (2)\nwhere Sxy,\u03b1 is the generalized Stirling number, whereas (x)C and (x|y)C denote the Pochhammer symbol [2].\nWe use bold face capital letters to denote the set of all relevant lower case variables, e.g. A = {~a1, \u00b7 \u00b7 \u00b7 ,~aD}, where each ~ai = {ai1, \u00b7 \u00b7 \u00b7 , ai,Nd}, denotes the set of all aspects. Variables R,T and O are defined similarly. In addition, we denote C to be the set of the customer counts and table counts for all probability vectors (c\u03c6 \u2032 tr , c\u03c6r , c\u03c6 \u2217 r , etc.) Also, we denote \u03b6 the set of all hyperparameters (such as the \u03b1\u2019s). Note all probability vectors are marginalized out. The likelihood of the model can then be written \u2014 in terms of g(\u00b7) \u2014 as p(A,R,T,O,C|\u03b6) \u221d ( D\u220f d=1 g(\u03b8d) )(\u220f e={\u22121,1} g(\u03b3e) )( A\u220f a=1 g(\u03c8a) )( 1\u220f r=\u22121 g(\u03c6r) (|Vt|\u220f t=1 g(\u03c6\u2032tr) )) .\n(3)\nWe use the collapsed Gibbs sampler from Chen et al. [3] for inference. The concept of the sampler is analogous to LDA, which consists of decrementing counts associated with a word, sampling the respective new latent values for the word, and incrementing the respective counts. In our case, the process is more complicated, albeit following the same general procedure. For the decrementing procedure, the table counts are represented as a sum of Bernoulli \u201cindicator\u201d variables u. Each data item (customer) corresponding to a +1 in cNi either has u = 0 or u = 1. When u = 1, the data item is passed up the hierarchy to the parent of N , and thus contributes a +1 to the table count c\u2032Ni . Note that the counts can only increase or decrease by one, since we are decrementing and incrementing a word at a time.\nWhen sampling a new aspect a or sentiment r, the modularized likelihood (Equation 3) allows the posterior to be computed quickly, since the conditional posterior simplifies to a ratio of likelihoods. This in turn allows for the ratio to simplify further since the counts can only change by 1. For instance, the ratio of the Pochhammer symbols, (x|y)C+1/(x|y)C , is reduced to a constant. While for the ratio of Stirling numbers, such as Sy+1x+1,\u03b1/S y x,\u03b1, can be computed quickly via caching [2]. For example, the conditional posterior for aspect adn is\np(adn,C|A\u2212dn,R,T,O,C\u2212dn, \u03b6)\n= p(A,R,T,O,C|\u03b6)\np(A\u2212dn,R,T,O,C\u2212dn|\u03b6) , (4)\nwhere the superscript 2\u2212dn indicates that the target-opinion pair \u3008tdn, adn\u3009 is removed from the respective sets. It is trivial to show that the conditional posterior simplifies to ratios of Pochhammer symbols and a ratio of Stirling numbers with Equation 2 and Equation 3. The conditional posterior probability for sampling the sentiment rdn can be similarly written.\nNote the change in associated counts C|C\u2212dn will be the full possible range of +1\u2019s propagated up the hierarchy. So sampling rdn = r will increment c \u03c6\u2032tdnr odn and may/may-not increment c \u2032\u03c6 \u2032 tdnr odn . If it does increment c\u2032 \u03c6\u2032tdnr odn then it also increments c \u03c6r odn , but then c\u2032 \u03c6r odn may or may-not be incremented. Sampling all these increments corresponds to sampling on a small tree of Booleans which can be done in closed form. Similarly, sampling a new adn = a will increment c\u03b8da , and if c\u2032 \u03b8d a is also incremented, a new aspect cluster is created for tdn. We summarize the collapsed Gibbs sampler in Algorithm 1, and refer the interested reader to the supplementary material for detail."}, {"heading": "7.2 Hyperparameters Sampling", "text": "During inference, we sample the hyperparameters of the PYP using an auxiliary variable sampler [38]. Moreover, we propose a novel method to update the hyperparameter b, which controls the strength of the sentiment prior. Instead of sampling the hyperparameter b (e.g. using the slice sampler [30]), we adopt an optimization approach since the posterior of b is highly concentrated in a small region (thin-tailed). The posterior density is given by the following equation, subject to a normalization constant.\np(b|~c) \u221d p(b) \u220f r \u220f v ( (1 + b)Xrv\u2211 i \u2211 j(1 + b) Xij )crv ,\nwhere crv is the number of times a word v is assigned a sentiment r, and p(b) is the hyperprior of b. We assume a weak hyperprior for b, b \u223c Gamma(1, 1).\nDuring inference, we update b to its maximum a posteriori probability (MAP) estimate using a gradient ascent algorithm. We opti-\nAlgorithm 2 Gradient Ascent Optimization for Hyperparameter b\n1. Given an initial value for b = b0, evaluate the gradient l\u2032(b0).\n2. Given a learning rate \u03c4 , update b to bi = bi\u22121+ \u03c4 \u00d7 l\u2032(bi\u22121), if the new log posterior l(bi) is lower than l(bi\u22121), we halve the learning rate: \u03c4 := \u03c4/2 .\n3. Repeat step 2 until b converges.\nmize the log posterior l(b) = log(p(b|~c)) since log is an increasing function. The gradient of the log posterior is derived as\nl\u2032(b) = 1\n(1 + b) \u2211 r \u2211 v crv (Xrv \u2212 E\u03c6r [Xr]) + \u03c1 \u2032(b) ,\nwhere E\u03c6r [Xr] is the expected value of Xr under the probability distribution \u03c6r , and \u03c1\u2032(b) is the derivative of log p(b). We summarize the gradient ascent algorithm in Algorithm 2. Additionally, in the supplementary material, we present the gradient derivation and a plot of the log posteriors of b given different statistics ~c."}, {"heading": "8. DATA", "text": "For experiments, we perform aspect-based opinion analysis on tweets, which are characterized by their limited 140 characters text. From the Twitter 7 dataset5 [46], we queried for tweets that are related to electronic products such as camera and mobile phones (see the list of our query words in the supplementary material). We then remove non-English tweets with langid.py [21]. Moreover, since most spam tweets contain a URL, we adopt a conservative approach to remove spam by discarding tweets containing URLs. This results in a dataset of about 9 million tweets, which we name as the electronic product dataset.\nDue to the lack of sentiment labels on the electronic product dataset, we make use of the Sentiment140 (Sent140) tweets6 [8] for sentiment classification evaluation. Each Sent140 tweet contains a sentiment label (positive or negative) that are determined by emoticons. The whole corpus contains 1.6 million tweets, with half of them labeled as positive and the other half as negative.\nIn addition, we also use the SemEval 2013 dataset7 [29] for evaluation. SemEval tweets are annotated on Mechanical Turk, which arguably provides better sentiment labels compared to Sent140. Since annotation is expensive, SemEval has only 6322 tweets."}, {"heading": "8.1 Data Preprocessing", "text": "Here, we describe the preprocessing steps that we apply to tweets. Firstly, we apply Twitter NLP [31], a state-of-the-art tool for partof-speech (POS) tagging on tweets. We then apply word normalization to clean up the tweets. We make use of the lexical normalization dictionary8 from Han et al. [9], but modify it such that proper nouns are not normalized. For instance, words like \u2018iphone\u2019 and \u2018xbox\u2019 are not normalized, since they are the targets we are interested in. We perform normalization after POS tagging since tweets normalization degrades the performance of Twitter NLP [10].\nNext, we proceed to extract target-opinion pairs from the data. Following Moghaddam and Ester [28], we apply the Stanford Dependency Parser [5] to extract dependency relations that will be used to form the target-opinion pairs. However, our approach is slightly different: we do not use the Direct Object (dobj) relation to obtain a target-opinion pair, for example, the sentence \u201cI 5http://snap.stanford.edu/data/twitter7.html 6http://help.sentiment140.com/home 7 http://www.cs.york.ac.uk/semeval-2013/task2/ 8http://ww2.cs.mu.oz.au/~tim/#resources\nlike the perfect picture quality\u201d gives \u2018dobj(like, picture quality)\u2019 and \u2018amod(picture quality, perfect)\u2019, resulting in two target-opinion pairs, \u3008picture quality, like\u3009 and \u3008picture quality, perfect\u3009. We drop the target-opinion pair associated with dobj and instead use the dobj relation for the emotion indicator variable. Note that we use the caseless English model in the Stanford Dependency Parser, which works better for tweets. Additionally, since standard NLP tools perform less optimally on tweets [36], we use the POS tagging from Twitter NLP to clean up the target-opinion pairs. We note that negations like \u2018not\u2019 are captured as dependency relations, the negated words are then treated as new words with the prefix \u2018not_\u2019.\nWe determine the emotion indicator variable via the existence of emoticons, strong sentiment words and/or the dobj relation in each tweet. We simply set the emotion indicator to \u22121 (negative) or 1 (positive) as long as the indicators agree with one another, and unobserved otherwise. The list of emoticons used is compiled from Wikipedia9. We present a subset of the emoticons and strong sentiment words in Table 2, while the full list is available in the supplementary material. For Sent140 and SemEval tweets, we replace the unobserved emotion indicator by their sentiment label.\nWe then perform tweet aggregation, which is found to give significant improvement for LDA [24]. We group tweets that contain the same hashtag (word prefixed with # symbol) or same mention (word prefixed with @ symbol) into a single document, this allows co-occurrence within the same tags (our abbreviation for hashtags and mention) to be used by topic models. Grouping tweets also allows us to summarize the results for each tag, giving us a better opinion overview (see Subsection 9.3 for example). Additionally, we discard tags that occur infrequently. We note that although tweets are merged to form a larger document, the emotion indicator (variable e) is observed and stored for each individual tweet (rather than the merged document), this prevents the emotion indicator from being lost through merging.\nFinally, we perform other standard preprocessing techniques to topic modeling, this consists of decapitalizing the words, removing stop words and discarding commonly occurred words and infrequent words. We define the common words as words that appear in at least 90% of the documents, and infrequent words as words that appear less than 50 times in the corpus. We randomly split the data into 90% training set and 10% test set for evaluation. We present a summary of the preprocessing pipeline in Figure 3."}, {"heading": "8.2 Corpus Statistics", "text": "On average, we found that there are 0.69 target-opinion pair extracted per electronic product tweet. Out of the electronic tweets that contain at least one target-opinion pair, 17.9% of them contain an emotion indicator. After preprocessing, the number of unique target word tokens in the electronic product tweets is 4402, while the number of unique opinion word tokens is 25188. We present a summary of the corpus statistics for all datasets in Table 3.\n9http://en.wikipedia.org/wiki/Kaomoji and http://en.wikipedia.org/wiki/List_of_emoticons\nFor the electronic product tweets, the top tags are #apple, #phone, #iphone, #computer and #laptop. We note that some tags are associated with products, brands or companies, for example, #playstation and #xbox are associated with gaming products, while #sony and #canon are associated with companies. In Subsection 9.3 below, we show that aggregating hashtags allow us to have a more focused view on certain products or companies, as well as facilitating comparison between these products or companies side-by-side."}, {"heading": "9. EXPERIMENTS AND RESULTS", "text": "In this section, we demonstrate the usefulness of TOTM for opinion mining. We evaluate TOTM quantitatively against ILDA and LDA-DP in terms of perplexity and sentiment classification. To compare the effectiveness of various sentiment lexicons, we propose a novel sentiment metric to evaluate the sentiment-opinion word distributions \u03c6\u2019s. Qualitatively, we utilize TOTM for the task of opinion mining from the electronic product tweets, and show that we are able to extract various useful opinions on technological products such as iPhone."}, {"heading": "9.1 Experiment Settings", "text": "For all the experiments, we initialize the hyperparameters of PYP to \u03b1 = \u03b2 = 0.1 and the sentiment hyperparameter to b = 10, noting that the hyperparameters are optimized automatically as discussed in Subsection 7.2.\nTo determine the optimal number of latent aspects (A) for ILDA, we set aside 5% of the training data as development set, and select A (tested in increment of 10) such that perplexity of the development set is minimized. For a fair comparison between TOTM and ILDA, we cap the maximum number of aspects of TOTM to be that of ILDA. Our experiment finds that the number of aspects in TOTM\nalways converges to the cap. We note that LDA-DP has only three fixed \u2018topics\u2019, which is the number of sentiments.\nDuring inference, we run the collapsed Gibbs algorithm until the convergence criteria is satisfied, defined by which the training log likelihood does not differ by more than 0.1% in ten consecutive iterations. Empirically, we find that all experiments converge within 200 iterations, indicating a good Gibbs sampling algorithm."}, {"heading": "9.2 Quantitative Evaluations", "text": "9.2.1 Perplexity We compute the perplexity of the test set to measure how well\nthe models fit to the data. The perplexity is negatively related to the likelihood of the test data. Since aspect-based opinion analysis deals with two types of vocabulary, we compute the perplexity for both target words and opinion words, in this case:\nperplexity(W) = exp ( \u2212 \u2211D d=1 logP (~wd)\u2211D\nd=1Nd\n) ,\nwhere W can be either target words T or opinion words O, Nd is the number of the target-opinion pairs in document d. We also compute the overall perplexity, which is given by\nperplexity(T,O) = exp ( \u2212 \u2211D d=1 logP (~td, ~od)\n2 \u2211D d=1Nd\n) .\nWe present the perplexity result (the lower the better) for the electronic product tweets in Table 4. We present the perplexity result of Sent140 tweets and SemEval tweets in the supplementary material, for which the same conclusion can be drawn. From the perplexity results, it is clear that modeling the target-opinion pairs directly leads to significant improvement of opinion words perplexity and hence the overall perplexity. Note that LDA-DP only models the opinion words, thus we can only compare the perplexity for opinion words, we can see that its result is comparable to that of ILDA, albeit slightly better.\n9.2.2 Sentiment Classification Here, we perform a classification task to predict the polarity of\nthe test data for Sent140 and SemEval data. We determine the polarity of a test document d by simply selecting the polarity r that gives higher likelihood in \u03c6r:\npolarity(d) = argmax r={\u22121,1} \u220f i \u03c6r,odi .\nFor simplicity, our evaluation is a binary classification task, as such, we do not include neutral tweets from SemEval data during evaluation. Note that Sent140 data does not have neutral tweets.\nWe present the classification accuracy, precision, recall and the F1 score in Table 5. We can see that TOTM outperforms LDADP and ILDA on both datasets, suggesting that our prior formulation is more appropriate than that of LDA-DP. We can also see that LDA-DP gives a better sentiment classification compared to ILDA, which does not incorporate any prior information. Note that the classification result for SemEval data is better than that of Sent140. We conjecture that this is because Sent140\u2019s sentiment labels are obtained from the emoticons, which are noisy in nature; while the sentiment labels for SemEval data is annotated.\n9.2.3 Evaluating the Sentiment Prior We propose a novel method to evaluate the learned sentiment-\nopinion phrase distributions \u03c6 by using another sentiment lexicon. We use the SentiWordNet lexicon for evaluation, noting that the lexicon used during training is the SentiStrength lexicon.\nUnlike SentiStrength, the SentiWordNet lexicon provides two values for each word. We name them the positive affinity Z+v and negative affinity Z\u2212v for a given word v, they ranged from 0 to 1. For example, the word \u2018active\u2019 has a positive affinity of 0.5 and a negative affinity of 0.125; while \u2018supreme\u2019 has a positive affinity or 0.75 and a negative affinity of 0.\nGiven the affinities, we propose the following sentiment score to evaluate an opinion word distribution \u03c6r:\nScore(\u03c6r, Z) = E\u03c6r [Z] = Vo\u2211 v=1 Zv\u03c6rv ,\nwhere Z is either Z+ or Z\u2212, the positive or negative affinity. The sentiment score is also the expected sentiment under the opinion word distribution.\nHere, we evaluate \u03c6\u22121 with negative affinity Z\u2212 and \u03c61 with positive affinity Z+. We compare the sentiment scores between the cases when a sentiment lexicon is used and when it is not. Additionally, we also make use of the MPQA Subjectivity lexicon for sentiment prior (during training) and compare the sentiment evaluation against the SentiStrength lexicon. We present the result in Table 6. As we can see, it is clear that incorporating prior information results in huge improvement in the sentiment score. Also, the priors for SentiStrength are slightly better than MPQA on average. We note that optimizing the hyperparameter b is very important, as it relieves us from tuning the hyperparameter manually. To illustrate, the optimized b converges to 2.59 on the electronic product\ntweets, while on Sent140 and SemEval dataset, the b converges to 1.85 and 0.71 respectively. We also find that, in our tests, an incorrectly chosen b can lead to a bad result."}, {"heading": "9.3 Qualitative Analysis and Applications", "text": "9.3.1 Analyzing Word Distributions First, we inspect the clustering of target words by TOTM and\nILDA, noting that LDA-DP does not model the target words. We calculate the pair-wise Hellinger distance between each documentaspect distribution and found that the aspects are distinctive. Hellinger distance is commonly used to measure the dissimilarity between two probability distributions. The Hellinger distances between all pairs of aspect distributions from TOTM is displayed as a heat map in Figure 4, we can see that the distances between the topics are high, indicating that there is no duplicated aspect. We note that the heat map for ILDA is similar and hence not presented here. We also display an extract of the top target words from TOTM in Table 7. Our empirical examination on the aspect-target word distributions suggest that both TOTM and ILDA perform well in clustering the target words.\nWe then look at the opinion phrase distributions \u03c6\u2019s. In ILDA and LDA-DP, the opinion words are generated conditioned on the latent sentiment labels, meaning that the opinion word is assumed to be independent to the target word given the sentiment; while in TOTM, the opinion word distributions are modeled given the senti-\nment and the observed target word. The advantage of TOTM over ILDA and LDA-DP in modeling the opinion words is that it allows us to analyze the opinions in a finer grained view. For instance, we can display a list of positive and negative opinions associated to a certain target word; an extract of this result is presented in Table 8, in which we pick a few distinctive target words to show their opinion words distribution. As we can see from Table 8, despite some opinion words can generally be applied to most target words (e.g. good, bad), the highlighted words are more descriptive (e.g. addictive, fried, grilled) and can only be applied to certain target words. Such a result cannot be achieved by ILDA or LDA-DP.\n9.3.2 Comparing Opinions on Brands with TOTM We present an application of comparing opinions on entities or\nproducts using TOTM. Since entities and products are frequently quoted with tags, we can compare them directly by looking at the opinions associated with each tag. We present an extract of the opinion comparison between three brands (Canon, Sony and Samsung) in Table 9. This table shows that we can have a high level comparison of the camera product between these three brands. For the phone product, there are only comparison between Sony and Samsung, since Canon does not manufacture phones (or no tweet on such topic is found). Note that the entries under the aspect \u2018printer\u2019 are lacking, we find that this is due to the low amount of opinion tweets on printers in the dataset."}, {"heading": "9.3.3 Extracting Contrastive Opinions on Products", "text": "Although the above comparison is useful for providing a high\nlevel summary, it is also important to inspect the original tweets as they provide opinions in greater details. We use TOTM to extract tweets containing people\u2019s opinions on iPhone. In Table 10, we display an extract of contrasting tweets containing the target \u2018iphone\u2019 with positive or negative sentiment (r = {\u22121, 1})."}, {"heading": "10. CONCLUSION", "text": "In this paper, we study the use of LDA-based models for opinion analysis on tweets queried with electronic product terms. This is motivated by the fact that Twitter is a popular platform for opinions and tweets are publicly available. Unlike reviews, tweets do not contain scores or ratings, they are more informal and usually accompanied by emoticons and strong sentiment words. Taking advantage of the informal nature of tweets, we designed a topic model named Twitter Opinion Topic Model (TOTM) for opinion analysis. TOTM is shown to greatly improve opinion prediction with the direct target-opinion modeling. In incorporating a sentiment lexicon into topic models, we proposed a new formulation for the topic\nmodel priors, which learns and updates given data. Our innovative formulation is shown to improve sentiment analysis significantly.\nOur qualitative analysis demonstrates that opinion mining on tweets provide useful opinions on electronic products. Note that although we can obtain a large quantity of product opinions on tweets, the opinions are usually much noisier than reviews. For instance, opinions can be incidental (e.g. the author was just frustrated with the product that time), since it is easy and effortless to produce a tweet. As with the reviews, the opinions on tweets may not always be true. Some tweets are laden with sarcasm, making them difficult to interpret, while some others are spam containing no useful information.\nWe emphasize the importance of preprocessing steps. For instance, word normalization allows misspellings and abbreviations to be captured for target-opinion analysis; tweet aggregation improves aspect clustering and lets us compare different products or brands. For practical applications, filtering sarcastic tweets and spam is also important. In this paper, we have attempted to filter spam by removing tweets containing URLs. We acknowledge that although there is existing work on removing sarcastic tweets and spam [44, 23], we did not incorporate them due to the lack of publicly available software. As future work, we are interested in utilizing other word lexicons such as synonym and antonym lexicons into an LDA-based model for sentiment analysis."}, {"heading": "11. ACKNOWLEDGMENTS", "text": "NICTA is funded by the Australian Government through the Department of Communications and the Australian Research Council through the ICT Centre of Excellence Program. We also like to thank Scott Sanner, Shamin Kinathil, Rishi Dua and the anonymous reviewers for their feedback and comments."}, {"heading": "12. REFERENCES", "text": "[1] S. Baccianella, A. Esuli, and F. Sebastiani. SentiWordNet\n3.0: An enhanced lexical resource for sentiment analysis and opinion mining. In LREC, pages 2200\u20132204, 2010.\n[2] W. Buntine and M. Hutter. A Bayesian review of the Poisson-Dirichlet process. arXiv:1007.0296v2, 2012.\n[3] C. Chen, L. Du, and W. Buntine. Sampling table configurations for the hierarchical Poisson-Dirichlet Process. In ECML, pages 296\u2013311, 2011.\n[4] D. Davidov, O. Tsur, and A. Rappoport. Enhanced sentiment learning using Twitter hashtags and smileys. In COLING, pages 241\u2013249, 2010.\n[5] M. De Marneffe, B. MacCartney, and C. Manning. Generating typed dependency parses from phrase structure parses. In LREC, pages 449\u2013454, 2006.\n[6] X. Ding, B. Liu, and P. Yu. A holistic lexicon-based approach to opinion mining. In WSDM. ACM, 2008.\n[7] C. Fellbaum. WordNet. Wiley Online Library, 1999. [8] A. Go, R. Bhayani, and L. Huang. Twitter sentiment\nclassification using distant supervision. CS224N Project Report, Stanford, pages 1\u201312, 2009.\n[9] B. Han, P. Cook, and T. Baldwin. Automatically constructing a normalisation dictionary for microblogs. In EMNLP-CoNLL, pages 421\u2013432. ACL, 2012.\n[10] B. Han, P. Cook, and T. Baldwin. Lexical normalization for social media text. ACM TIST, 4(1):5:1\u20135:27, Feb. 2013.\n[11] Y. He. Incorporating sentiment prior knowledge for weakly supervised sentiment analysis. ACM TALIP, 11(2):4, 2012.\n[12] M. Hu and B. Liu. Mining opinion features in customer reviews. In AAAI, volume 4, pages 755\u2013760, 2004.\n[13] J. Jagarlamudi, H. Daum\u00e9, III, and R. Udupa. Incorporating lexical priors into topic models. In EACL. ACM, 2012.\n[14] L. Jiang, M. Yu, M. Zhou, X. Liu, and T. Zhao. Target-dependent Twitter sentiment classification. In ACL, pages 151\u2013160, 2011.\n[15] Y. Jo and A. Oh. Aspect and sentiment unification model for online review analysis. In WSDM, pages 815\u2013824, 2011.\n[16] F. Li, C. Han, M. Huang, X. Zhu, Y.-J. Xia, S. Zhang, and H. Yu. Structure-aware review mining and summarization. In COLING, pages 653\u2013661. ACL, 2010.\n[17] T. Li, Y. Zhang, and V. Sindhwani. A non-negative matrix tri-factorization approach to sentiment classification with lexical prior knowledge. In AFNLP, pages 244\u2013252, 2009.\n[18] C. Lin and Y. He. Joint sentiment/topic model for sentiment analysis. In CIKM, pages 375\u2013384. ACM, 2009.\n[19] B. Liu. Sentiment analysis and opinion mining. Synthesis Lectures on HLT, 5(1):1\u2013167, 2012.\n[20] S. Liu, F. Li, F. Li, X. Cheng, and H. Shen. Adaptive co-training SVM for sentiment classification on tweets. In CIKM, pages 2079\u20132088. ACM, 2013.\n[21] M. Lui and T. Baldwin. langid.py: An off-the-shelf language identification tool. In ACL, pages 25\u201330, 2012.\n[22] D. Maynard, K. Bontcheva, and D. Rout. Challenges in developing opinion mining tools for social media. @NLP can u tag #usergeneratedcontent, 2012.\n[23] M. McCord and M. Chuah. Spam detection on Twitter using traditional classifiers. In Autonomic and Trusted Computing, pages 175\u2013186. Springer, 2011.\n[24] R. Mehrotra, S. Sanner, W. Buntine, and L. Xie. Improving LDA topic models for microblogs via Tweet pooling and automatic labeling. In SIGIR, pages 889\u2013892. ACM, 2013.\n[25] Q. Mei, X. Ling, M. Wondra, et al. Topic Sentiment Mixture: Modeling facets and opinions in weblogs. In WWW, 2007.\n[26] S. Moghaddam and M. Ester. Opinion Digger: An unsupervised opinion miner from unstructured product reviews. In CIKM, pages 1825\u20131828. ACM, 2010.\n[27] S. Moghaddam and M. Ester. ILDA: Interdependent LDA model for learning latent aspects and their ratings from online product reviews. In SIGIR, pages 665\u2013674, 2011.\n[28] S. Moghaddam and M. Ester. On the design of LDA models for aspect-based opinion mining. In CIKM. ACM, 2012.\n[29] P. Nakov, Z. Kozareva, A. Ritter, S. Rosenthal, V. Stoyanov, and T. Wilson. SemEval-2013 task 2: Sentiment analysis in Twitter. In Workshop on Semantic Evaluation, 2013.\n[30] R. Neal. Slice sampling. Ann. Statist., 31(3):705\u2013767, 2003. [31] O. Owoputi, B. O\u2019Connor, C. Dyer, et al. Improved\npart-of-speech tagging for online conversational text with word clusters. In NAACL-HLT, pages 380\u2013390, 2013.\n[32] A. Pak and P. Paroubek. Twitter as a corpus for sentiment analysis and opinion mining. In LREC, 2010.\n[33] B. Pang and L. Lee. Opinion Mining and Sentiment Analysis. Foundations and Trends in Information Retrieval, 2(1-2):1\u2013135, 2008.\n[34] J. Pitman. Some developments of the Blackwell-Macqueen urn scheme. Lecture Notes-Monograph Series, 1996.\n[35] A.-M. Popescu and O. Etzioni. Extracting product features and opinions from reviews. In Natural language processing and text mining, pages 9\u201328. Springer, 2007.\n[36] A. Ritter, S. Clark, Mausam, and O. Etzioni. Named entity recognition in Tweets: An experimental study. In EMNLP, pages 1524\u20131534, 2011.\n[37] M. Taboada, J. Brooke, M. Tofiloski, K. Voll, and M. Stede. Lexicon-based methods for sentiment analysis. Computational linguistics, 37(2):267\u2013307, 2011.\n[38] Y. W. Teh. A Bayesian interpretation of interpolated Kneser-Ney. Tech Report A2/06, NUS, 2006.\n[39] Y. W. Teh. A hierarchical Bayesian language model based on Pitman-Yor processes. In ACL, pages 985\u2013992. ACL, 2006.\n[40] Y. W. Teh and M. Jordan. Hierarchical Bayesian nonparametric models with applications. Bayesian Nonparametrics: Principles and Practice, pages 158\u2013207, 2010.\n[41] M. Thelwall, K. Buckley, G. Paltoglou, D. Cai, and A. Kappas. Sentiment strength detection in short informal text. JASIST, 61(12):2544\u20132558, 2010.\n[42] I. Titov and R. McDonald. A joint model of text and aspect ratings for sentiment summarization. In ACL08: HLT, 2008.\n[43] I. Titov and R. McDonald. Modeling online reviews with multi-grain topic models. In WWW, pages 111\u2013120, 2008.\n[44] O. Tsur, D. Davidov, and A. Rappoport. ICWSM-A great catchy name: Semi-supervised recognition of sarcastic sentences in online product reviews. In ICWSM, 2010.\n[45] T. Wilson, J. Wiebe, and P. Hoffmann. Recognizing contextual polarity in phrase-level sentiment analysis. In HLT-EMNLP, pages 347\u2013354, 2005.\n[46] J. Yang and J. Leskovec. Patterns of temporal variation in online media. In WSDM, pages 177\u2013186, 2011.\n[47] W. Zhao, J. Jiang, J. Weng, J. He, E.-P. Lim, H. Yan, and X. Li. Comparing Twitter and traditional media using topic models. In ECIR, pages 338\u2013349, 2011.\n[48] W. Zhao, J. Jiang, H. Yan, and X. Li. Jointly modeling aspects and opinions with a MaxEnt-LDA hybrid. In EMNLP, pages 56\u201365, 2010."}], "references": [{"title": "SentiWordNet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining", "author": ["S. Baccianella", "A. Esuli", "F. Sebastiani"], "venue": "In LREC,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "A Bayesian review of the Poisson-Dirichlet process", "author": ["W. Buntine", "M. Hutter"], "venue": "arXiv:1007.0296v2,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Sampling table configurations for the hierarchical Poisson-Dirichlet Process", "author": ["C. Chen", "L. Du", "W. Buntine"], "venue": "ECML, pages 296\u2013311,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Enhanced sentiment learning using Twitter hashtags and smileys", "author": ["D. Davidov", "O. Tsur", "A. Rappoport"], "venue": "COLING, pages 241\u2013249,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Generating typed dependency parses from phrase structure parses", "author": ["M. De Marneffe", "B. MacCartney", "C. Manning"], "venue": "LREC, pages 449\u2013454,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2006}, {"title": "A holistic lexicon-based approach to opinion mining", "author": ["X. Ding", "B. Liu", "P. Yu"], "venue": "WSDM. ACM,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "WordNet", "author": ["C. Fellbaum"], "venue": "Wiley Online Library,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1999}, {"title": "Twitter sentiment classification using distant supervision", "author": ["A. Go", "R. Bhayani", "L. Huang"], "venue": "CS224N Project Report, Stanford, pages 1\u201312,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "Automatically constructing a normalisation dictionary for microblogs", "author": ["B. Han", "P. Cook", "T. Baldwin"], "venue": "EMNLP-CoNLL, pages 421\u2013432. ACL,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Lexical normalization for social media text", "author": ["B. Han", "P. Cook", "T. Baldwin"], "venue": "ACM TIST, 4(1):5:1\u20135:27, Feb.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Incorporating sentiment prior knowledge for weakly supervised sentiment analysis", "author": ["Y. He"], "venue": "ACM TALIP, 11(2):4,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Mining opinion features in customer reviews", "author": ["M. Hu", "B. Liu"], "venue": "AAAI, volume 4, pages 755\u2013760,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2004}, {"title": "Incorporating lexical priors into topic models", "author": ["J. Jagarlamudi", "III H. Daum\u00e9", "R. Udupa"], "venue": "In EACL. ACM,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Target-dependent Twitter sentiment classification", "author": ["L. Jiang", "M. Yu", "M. Zhou", "X. Liu", "T. Zhao"], "venue": "ACL, pages 151\u2013160,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Aspect and sentiment unification model for online review analysis", "author": ["Y. Jo", "A. Oh"], "venue": "WSDM, pages 815\u2013824,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2011}, {"title": "Structure-aware review mining and summarization", "author": ["F. Li", "C. Han", "M. Huang", "X. Zhu", "Y.-J. Xia", "S. Zhang", "H. Yu"], "venue": "COLING, pages 653\u2013661. ACL,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "A non-negative matrix tri-factorization approach to sentiment classification with lexical prior knowledge", "author": ["T. Li", "Y. Zhang", "V. Sindhwani"], "venue": "AFNLP, pages 244\u2013252,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Joint sentiment/topic model for sentiment analysis", "author": ["C. Lin", "Y. He"], "venue": "CIKM, pages 375\u2013384. ACM,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2009}, {"title": "Sentiment analysis and opinion mining", "author": ["B. Liu"], "venue": "Synthesis Lectures on HLT, 5(1):1\u2013167,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Adaptive co-training SVM for sentiment classification on tweets", "author": ["S. Liu", "F. Li", "F. Li", "X. Cheng", "H. Shen"], "venue": "CIKM, pages 2079\u20132088. ACM,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2013}, {"title": "langid.py: An off-the-shelf language identification tool", "author": ["M. Lui", "T. Baldwin"], "venue": "In ACL,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "Challenges in developing opinion mining tools for social media", "author": ["D. Maynard", "K. Bontcheva", "D. Rout"], "venue": "@NLP can u tag #usergeneratedcontent,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "Spam detection on Twitter using traditional classifiers", "author": ["M. McCord", "M. Chuah"], "venue": "Autonomic and Trusted Computing, pages 175\u2013186. Springer,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2011}, {"title": "Improving LDA topic models for microblogs via Tweet pooling and automatic labeling", "author": ["R. Mehrotra", "S. Sanner", "W. Buntine", "L. Xie"], "venue": "SIGIR, pages 889\u2013892. ACM,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}, {"title": "Topic Sentiment Mixture: Modeling facets and opinions in weblogs", "author": ["Q. Mei", "X. Ling", "M. Wondra"], "venue": "In WWW,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2007}, {"title": "Opinion Digger: An unsupervised opinion miner from unstructured product reviews", "author": ["S. Moghaddam", "M. Ester"], "venue": "CIKM, pages 1825\u20131828. ACM,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2010}, {"title": "ILDA: Interdependent LDA model for learning latent aspects and their ratings from online product reviews", "author": ["S. Moghaddam", "M. Ester"], "venue": "SIGIR, pages 665\u2013674,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2011}, {"title": "On the design of LDA models for aspect-based opinion mining", "author": ["S. Moghaddam", "M. Ester"], "venue": "CIKM. ACM,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2012}, {"title": "SemEval-2013 task 2: Sentiment analysis in Twitter", "author": ["P. Nakov", "Z. Kozareva", "A. Ritter", "S. Rosenthal", "V. Stoyanov", "T. Wilson"], "venue": "Workshop on Semantic Evaluation,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2013}, {"title": "Slice sampling", "author": ["R. Neal"], "venue": "Ann. Statist., 31(3):705\u2013767,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2003}, {"title": "Improved part-of-speech tagging for online conversational text with word clusters", "author": ["O. Owoputi", "B. O\u2019Connor", "C. Dyer"], "venue": "In NAACL-HLT,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2013}, {"title": "Twitter as a corpus for sentiment analysis and opinion mining", "author": ["A. Pak", "P. Paroubek"], "venue": "LREC,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2010}, {"title": "Opinion Mining and Sentiment Analysis", "author": ["B. Pang", "L. Lee"], "venue": "Foundations and Trends in Information Retrieval, 2(1-2):1\u2013135,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2008}, {"title": "Some developments of the Blackwell-Macqueen urn scheme", "author": ["J. Pitman"], "venue": "Lecture Notes-Monograph Series,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1996}, {"title": "Extracting product features and opinions from reviews", "author": ["A.-M. Popescu", "O. Etzioni"], "venue": "Natural language processing and text mining, pages 9\u201328. Springer,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2007}, {"title": "Named entity recognition in Tweets: An experimental study", "author": ["A. Ritter", "S. Clark", "Mausam", "O. Etzioni"], "venue": "In EMNLP,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2011}, {"title": "Lexicon-based methods for sentiment analysis", "author": ["M. Taboada", "J. Brooke", "M. Tofiloski", "K. Voll", "M. Stede"], "venue": "Computational linguistics, 37(2):267\u2013307,", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2011}, {"title": "A Bayesian interpretation of interpolated Kneser-Ney", "author": ["Y.W. Teh"], "venue": "Tech Report A2/06, NUS,", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2006}, {"title": "A hierarchical Bayesian language model based on Pitman-Yor processes", "author": ["Y.W. Teh"], "venue": "ACL, pages 985\u2013992. ACL,", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2006}, {"title": "Hierarchical Bayesian nonparametric models with applications", "author": ["Y.W. Teh", "M. Jordan"], "venue": "Bayesian Nonparametrics: Principles and Practice, pages 158\u2013207,", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2010}, {"title": "Sentiment strength detection in short informal text", "author": ["M. Thelwall", "K. Buckley", "G. Paltoglou", "D. Cai", "A. Kappas"], "venue": "JASIST, 61(12):2544\u20132558,", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2010}, {"title": "A joint model of text and aspect ratings for sentiment summarization", "author": ["I. Titov", "R. McDonald"], "venue": "ACL08: HLT,", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2008}, {"title": "Modeling online reviews with multi-grain topic models", "author": ["I. Titov", "R. McDonald"], "venue": "WWW, pages 111\u2013120,", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2008}, {"title": "ICWSM-A great catchy name: Semi-supervised recognition of sarcastic sentences in online product reviews", "author": ["O. Tsur", "D. Davidov", "A. Rappoport"], "venue": "ICWSM,", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2010}, {"title": "Recognizing contextual polarity in phrase-level sentiment analysis", "author": ["T. Wilson", "J. Wiebe", "P. Hoffmann"], "venue": "HLT-EMNLP, pages 347\u2013354,", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2005}, {"title": "Patterns of temporal variation in online media", "author": ["J. Yang", "J. Leskovec"], "venue": "WSDM, pages 177\u2013186,", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2011}, {"title": "Comparing Twitter and traditional media using topic models", "author": ["W. Zhao", "J. Jiang", "J. Weng", "J. He", "E.-P. Lim", "H. Yan", "X. Li"], "venue": "ECIR, pages 338\u2013349,", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2011}, {"title": "Jointly modeling aspects and opinions with a MaxEnt-LDA hybrid", "author": ["W. Zhao", "J. Jiang", "H. Yan", "X. Li"], "venue": "EMNLP, pages 56\u201365,", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 18, "context": "The task of analyzing opinions from text data such as reviews is known as opinion mining or opinion extraction [19, 33].", "startOffset": 111, "endOffset": 119}, {"referenceID": 32, "context": "The task of analyzing opinions from text data such as reviews is known as opinion mining or opinion extraction [19, 33].", "startOffset": 111, "endOffset": 119}, {"referenceID": 27, "context": "LDA-based models are considered to be state-of-the-art for aspect-based opinion mining [28].", "startOffset": 87, "endOffset": 91}, {"referenceID": 46, "context": "Social media text is short and is regarded as \u201cdirty\u201d, and hence less useful for more sophisticated language analysis [47].", "startOffset": 118, "endOffset": 122}, {"referenceID": 35, "context": "The same problem also leads to degradation when applying NLP tools [36].", "startOffset": 67, "endOffset": 71}, {"referenceID": 23, "context": "Additionally, hashtags are strong indicators of topics for tweets [24].", "startOffset": 66, "endOffset": 70}, {"referenceID": 26, "context": "In Section 4, we present Interdependent LDA (ILDA) [27] which will be used as a baseline for comparison.", "startOffset": 51, "endOffset": 55}, {"referenceID": 47, "context": "Notable examples based on LDA include the MaxEnt-LDA hybrid model [48], Joint Sentiment Topic (JST) model [18], Multi-grain LDA (MG-LDA) [43], Interdependent LDA (ILDA) [27], Aspect and Sentiment Unification Model (ASUM) [15] and Multi-Aspect Sentiment (MAS) model [42].", "startOffset": 66, "endOffset": 70}, {"referenceID": 17, "context": "Notable examples based on LDA include the MaxEnt-LDA hybrid model [48], Joint Sentiment Topic (JST) model [18], Multi-grain LDA (MG-LDA) [43], Interdependent LDA (ILDA) [27], Aspect and Sentiment Unification Model (ASUM) [15] and Multi-Aspect Sentiment (MAS) model [42].", "startOffset": 106, "endOffset": 110}, {"referenceID": 42, "context": "Notable examples based on LDA include the MaxEnt-LDA hybrid model [48], Joint Sentiment Topic (JST) model [18], Multi-grain LDA (MG-LDA) [43], Interdependent LDA (ILDA) [27], Aspect and Sentiment Unification Model (ASUM) [15] and Multi-Aspect Sentiment (MAS) model [42].", "startOffset": 137, "endOffset": 141}, {"referenceID": 26, "context": "Notable examples based on LDA include the MaxEnt-LDA hybrid model [48], Joint Sentiment Topic (JST) model [18], Multi-grain LDA (MG-LDA) [43], Interdependent LDA (ILDA) [27], Aspect and Sentiment Unification Model (ASUM) [15] and Multi-Aspect Sentiment (MAS) model [42].", "startOffset": 169, "endOffset": 173}, {"referenceID": 14, "context": "Notable examples based on LDA include the MaxEnt-LDA hybrid model [48], Joint Sentiment Topic (JST) model [18], Multi-grain LDA (MG-LDA) [43], Interdependent LDA (ILDA) [27], Aspect and Sentiment Unification Model (ASUM) [15] and Multi-Aspect Sentiment (MAS) model [42].", "startOffset": 221, "endOffset": 225}, {"referenceID": 41, "context": "Notable examples based on LDA include the MaxEnt-LDA hybrid model [48], Joint Sentiment Topic (JST) model [18], Multi-grain LDA (MG-LDA) [43], Interdependent LDA (ILDA) [27], Aspect and Sentiment Unification Model (ASUM) [15] and Multi-Aspect Sentiment (MAS) model [42].", "startOffset": 265, "endOffset": 269}, {"referenceID": 24, "context": "The Topic-Sentiment Mixture (TSM) model [25] performs sentiment analysis by utilizing the Multinomial distribution.", "startOffset": 40, "endOffset": 44}, {"referenceID": 21, "context": "[22] studied the challenges in developing an opinion mining tool for social media and they advocated the use of shallow techniques in linguistic processing of tweets.", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "Notable non-LDA-based methods for opinion analysis include OPINE [35], which uses relaxation labeling to classify sentiment, and Opinion Digger [26], an aspect-based review miner using k nearest neighbor.", "startOffset": 65, "endOffset": 69}, {"referenceID": 25, "context": "Notable non-LDA-based methods for opinion analysis include OPINE [35], which uses relaxation labeling to classify sentiment, and Opinion Digger [26], an aspect-based review miner using k nearest neighbor.", "startOffset": 144, "endOffset": 148}, {"referenceID": 11, "context": "Hu and Liu [12] performed rule-based target-opinion extraction from online product reviews, while Li et al.", "startOffset": 11, "endOffset": 15}, {"referenceID": 15, "context": "[16] extracted opinions from reviews using Conditional Random Fields.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "On tweets, Pak and Paroubek [32] performed opinion analysis using a Naive Bayes classifier; while Liu et al.", "startOffset": 28, "endOffset": 32}, {"referenceID": 19, "context": "[20] performed sentiment classification using an adaptive co-training SVM.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[8] and Davidov et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] made use of emoticons (smileys), which were found to provide improvement for sentiment classification on tweets.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "Since tweets are always short, existing work [8, 32, 4, 20] tends to assume a single polarity for each tweet.", "startOffset": 45, "endOffset": 59}, {"referenceID": 31, "context": "Since tweets are always short, existing work [8, 32, 4, 20] tends to assume a single polarity for each tweet.", "startOffset": 45, "endOffset": 59}, {"referenceID": 3, "context": "Since tweets are always short, existing work [8, 32, 4, 20] tends to assume a single polarity for each tweet.", "startOffset": 45, "endOffset": 59}, {"referenceID": 19, "context": "Since tweets are always short, existing work [8, 32, 4, 20] tends to assume a single polarity for each tweet.", "startOffset": 45, "endOffset": 59}, {"referenceID": 13, "context": "[14] performed target-dependent sentiment analysis, where the sentiments apply to a specific target.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "He [11] used a sentiment lexicon to modify the priors of LDA for sentiment classification, though with an approach with ad hoc constants.", "startOffset": 3, "endOffset": 7}, {"referenceID": 16, "context": "[17] incorporated a lexical dictionary into a nonnegative matrix tri-factorization model, using a simple rule-based polarity assignment.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "[6] and Taboada et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 36, "context": "[37] for a detailed review on applying lexicon-based methods in sentiment analysis.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] used seeded words as lexical priors for semi-supervised topic modeling.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "Interdependent LDA (ILDA) [27] is an extension of LDA that performs aspect-based opinion analysis.", "startOffset": 26, "endOffset": 30}, {"referenceID": 26, "context": "Also known as rating in Moghaddam and Ester [27].", "startOffset": 44, "endOffset": 48}, {"referenceID": 33, "context": "TOTM uses the Griffiths-Engen-McCloskey (GEM) [34] distribution to generate probability vectors and the Pitman-Yor process (PYP) [39] to generate probability vector given another mean probability vector.", "startOffset": 46, "endOffset": 50}, {"referenceID": 38, "context": "TOTM uses the Griffiths-Engen-McCloskey (GEM) [34] distribution to generate probability vectors and the Pitman-Yor process (PYP) [39] to generate probability vector given another mean probability vector.", "startOffset": 129, "endOffset": 133}, {"referenceID": 10, "context": "He [11] proposed a simple yet effective way to incorporate sentiment prior information into LDA by directly modifying the Dirichlet prior based on available sentiment lexicons.", "startOffset": 3, "endOffset": 7}, {"referenceID": 10, "context": "We redefined the original sentiment labels [11] for consistency.", "startOffset": 43, "endOffset": 47}, {"referenceID": 0, "context": "Sentiment lexicons that are freely available online include SentiWordNet [1], SentiStrength [41], MPQA Subjectivity lexicon [45] and others.", "startOffset": 73, "endOffset": 76}, {"referenceID": 40, "context": "Sentiment lexicons that are freely available online include SentiWordNet [1], SentiStrength [41], MPQA Subjectivity lexicon [45] and others.", "startOffset": 92, "endOffset": 96}, {"referenceID": 44, "context": "Sentiment lexicons that are freely available online include SentiWordNet [1], SentiStrength [41], MPQA Subjectivity lexicon [45] and others.", "startOffset": 124, "endOffset": 128}, {"referenceID": 6, "context": "SentiWordNet is built on WordNet [7] by researchers from Italy.", "startOffset": 33, "endOffset": 36}, {"referenceID": 39, "context": "common approach here is to use the Chinese Restaurant Process (CRP) representation of Teh and Jordan [40], we use another representation that requires no dynamic memory and has better inference efficiency [3].", "startOffset": 101, "endOffset": 105}, {"referenceID": 2, "context": "common approach here is to use the Chinese Restaurant Process (CRP) representation of Teh and Jordan [40], we use another representation that requires no dynamic memory and has better inference efficiency [3].", "startOffset": 205, "endOffset": 208}, {"referenceID": 1, "context": "where S y,\u03b1 is the generalized Stirling number, whereas (x)C and (x|y)C denote the Pochhammer symbol [2].", "startOffset": 101, "endOffset": 104}, {"referenceID": 2, "context": "[3] for inference.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "While for the ratio of Stirling numbers, such as S x+1,\u03b1/S y x,\u03b1, can be computed quickly via caching [2].", "startOffset": 102, "endOffset": 105}, {"referenceID": 37, "context": "During inference, we sample the hyperparameters of the PYP using an auxiliary variable sampler [38].", "startOffset": 95, "endOffset": 99}, {"referenceID": 29, "context": "using the slice sampler [30]), we adopt an optimization approach since the posterior of b is highly concentrated in a small region (thin-tailed).", "startOffset": 24, "endOffset": 28}, {"referenceID": 45, "context": "From the Twitter 7 dataset [46], we queried for tweets that are related to electronic products such as camera and mobile phones (see the list of our query words in the supplementary material).", "startOffset": 27, "endOffset": 31}, {"referenceID": 20, "context": "py [21].", "startOffset": 3, "endOffset": 7}, {"referenceID": 7, "context": "Due to the lack of sentiment labels on the electronic product dataset, we make use of the Sentiment140 (Sent140) tweets [8] for sentiment classification evaluation.", "startOffset": 120, "endOffset": 123}, {"referenceID": 28, "context": "In addition, we also use the SemEval 2013 dataset [29] for evaluation.", "startOffset": 50, "endOffset": 54}, {"referenceID": 30, "context": "Firstly, we apply Twitter NLP [31], a state-of-the-art tool for partof-speech (POS) tagging on tweets.", "startOffset": 30, "endOffset": 34}, {"referenceID": 8, "context": "[9], but modify it such that proper nouns are not normalized.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "We perform normalization after POS tagging since tweets normalization degrades the performance of Twitter NLP [10].", "startOffset": 110, "endOffset": 114}, {"referenceID": 27, "context": "Following Moghaddam and Ester [28], we apply the Stanford Dependency Parser [5] to extract dependency relations that will be used to form the target-opinion pairs.", "startOffset": 30, "endOffset": 34}, {"referenceID": 4, "context": "Following Moghaddam and Ester [28], we apply the Stanford Dependency Parser [5] to extract dependency relations that will be used to form the target-opinion pairs.", "startOffset": 76, "endOffset": 79}, {"referenceID": 35, "context": "Additionally, since standard NLP tools perform less optimally on tweets [36], we use the POS tagging from Twitter NLP to clean up the target-opinion pairs.", "startOffset": 72, "endOffset": 76}, {"referenceID": 23, "context": "We then perform tweet aggregation, which is found to give significant improvement for LDA [24].", "startOffset": 90, "endOffset": 94}, {"referenceID": 43, "context": "We acknowledge that although there is existing work on removing sarcastic tweets and spam [44, 23], we did not incorporate them due to the lack of publicly available software.", "startOffset": 90, "endOffset": 98}, {"referenceID": 22, "context": "We acknowledge that although there is existing work on removing sarcastic tweets and spam [44, 23], we did not incorporate them due to the lack of publicly available software.", "startOffset": 90, "endOffset": 98}], "year": 2016, "abstractText": "Aspect-based opinion mining is widely applied to review data to aggregate or summarize opinions of a product, and the current stateof-the-art is achieved with Latent Dirichlet Allocation (LDA)-based model. Although social media data like tweets are laden with opinions, their \u201cdirty\u201d nature (as natural language) has discouraged researchers from applying LDA-based opinion model for product review mining. Tweets are often informal, unstructured and lacking labeled data such as categories and ratings, making it challenging for product opinion mining. In this paper, we propose an LDA-based opinion model named Twitter Opinion Topic Model (TOTM) for opinion mining and sentiment analysis. TOTM leverages hashtags, mentions, emoticons and strong sentiment words that are present in tweets in its discovery process. It improves opinion prediction by modeling the target-opinion interaction directly, thus discovering target specific opinion words, neglected in existing approaches. Moreover, we propose a new formulation of incorporating sentiment prior information into a topic model, by utilizing an existing public sentiment lexicon. This is novel in that it learns and updates with the data. We conduct experiments on 9 million tweets on electronic products, and demonstrate the improved performance of TOTM in both quantitative evaluations and qualitative analysis. We show that aspect-based opinion analysis on massive volume of tweets provides useful opinions on products.", "creator": "LaTeX with hyperref package"}}}