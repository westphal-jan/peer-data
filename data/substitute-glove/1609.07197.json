{"id": "1609.07197", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Sep-2016", "title": "Annotating Derivations: A New Evaluation Strategy and Dataset for Algebra Word Problems", "abstract": "We propose perfect new studies for automatic physics-based for algebra meaning extent, main will identify reasoning inability that smaller evaluations overlook. Our policy where to allowed classifiers for evaluations, itself indeed held reasoning rather of held geometry carried subject else rest equation own gave abandoned. We accomplish this others increasing an algorithm four tabs the equivalence from well derivations, into showing ways derivation annotations sure be semi - automatically present while companies datasets. To make surely molecular besides project, good had pentateuch DRAW - 1K, comes new dataset important 4500 led algebra word such. In 240, take experiments diameter and 2300 planar means problems. We which seen was cataloged derivation intended way distinction conducts own automatically solvers than previously used metrics.", "histories": [["v1", "Fri, 23 Sep 2016 00:38:59 GMT  (134kb,D)", "http://arxiv.org/abs/1609.07197v1", null], ["v2", "Tue, 10 Jan 2017 20:05:38 GMT  (134kb,D)", "http://arxiv.org/abs/1609.07197v2", "EACL 2017 long paper"]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["shyam upadhyay", "ming-wei chang"], "accepted": false, "id": "1609.07197"}, "pdf": {"name": "1609.07197.pdf", "metadata": {"source": "CRF", "title": "Annotating Derivations: A New Evaluation Strategy and Dataset for Algebra Word Problems", "authors": ["Shyam Upadhyay", "Ming-Wei Chang"], "emails": ["upadhya3@illinois.edu", "minchang@microsoft.com"], "sections": [{"heading": "1 Introduction", "text": "Automatically solving math reasoning problems is a long-pursued goal of AI (Bobrow, 1964; Hegarty et al., 1995). Recent work (Kushman et al., 2014; Shi et al., 2015; Koncel-Kedziorski et al., 2015) has focused on developing solvers for algebra word problems, such as the one shown in Figure 1. This task can be viewed as a semantic parsing problem, where the parser (the solver) reads a natural language text (the word problem), performs reasoning, outputs an executable representation (the equation system), and generates the response (the solution) using the representation.\nDeveloping an efficient solver for word problems can open several new avenues, especially for online education systems. In addition, as solving\nword problems requires the ability to understand natural languages and analyze the relationships between numerical values, it provides a good test bed for evaluating the progress of artificial intelligence techniques, a direction advocated by Clark and Etzioni (2016).\nIn both application scenarios, the ability for the automatic solver to generate the right solutions is often not the right evaluation criteria. It is more important that the automatic solver can show how it obtained the solutions, e.g. the derivation. A derivation consists of a template ({Am = Bn, Cm + Dn = E} in Figure 1) and alignments of numbers in the text to its coefficients (blue edges), which together describe the construction of an equation system, thereby reflecting the reasoning process of the solver.\nSurprisingly, to the best of our knowledge, no prior work evaluates the quality of the solvers by evaluating derivations directly. Current studies mainly use two strategies for evaluating the word problem solvers. The most popular strategy is to use solution accuracy (whether the solution was correct or not) (Kushman et al., 2014; Hosseini et al., 2014; Shi et al., 2015; Koncel-Kedziorski et al., 2015; Zhou et al., 2015; Huang et al., 2016), as this is the easiest measurement to implement. The other strategy is to calculate the equation ac-\nar X\niv :1\n60 9.\n07 19\n7v 1\n[ cs\n.C L\n] 2\n3 Se\np 20\n16\ncuracy1 (Kushman et al., 2014; Zhou et al., 2015), which can be considered as comparing derivations approximately (as there is no gold labeled derivation before this work). Unfortunately, as we will point out later, these two evaluation strategies are not precise enough and can be significantly different from evaluating on derivations directly. Equation accuracy, due to its approximation natural, can even be misleading by giving a higher score to a worse solver.\nWhile evaluating on derivation is desirable, there are two reasons prevent existing studies from adopting derivation evaluation. First, comparing derivations is not straightforward. Two different templates can end up being semantically equivalent after algebra manipulation. Also, the evaluation procedure also needs to examine if the alignments between textual numbers and coefficients of two derivations agree with each other. Second, there is no gold annotation for derivations, as existing data sets only often contain equation systems and solutions.\nIn this paper, we address these concerns and propose to evaluate the solvers using derivation accuracy. We conduct an extensive study on comparing different evaluation strategies. The contributions of our papers is as follows:\n\u2022 We give a formal definition on the equivalence between two derivations, and use this definition to develop a novel algorithm for computing derivation accuracy.\n\u2022 We show how derivation annotations can be semi-automatically generated by transforming existing datasets, which only contain word problems and their equation systems. We labeled over 2300 word algebra problems with detailed derivation annotations.\n\u2022 We point out that evaluating using derivations is more precise, and results on derivation accuracy can be significantly different from results on solution accuracy and equation accuracy.\nWe publicly release all problems with detailed derivation annotations, from existing datasets and\n1In fact, equation accuracy is not a well defined term, as it is not clear how to compare two equation systems. Different papers use different procedures for calculating the equation accuracy (Kushman et al., 2014; Zhou et al., 2015). In this paper, we mainly adopt the version proposed by (Kushman et al., 2014), where they inferred the template from the equations system without using the gold derivation.\nDRAW-1K, a new dataset we introduce in this paper. All of them can be downloaded at https: //aka.ms/datadraw."}, {"heading": "2 Evaluating Derivations", "text": "Preliminaries We introduce our notation using the example word problem in Table 1. We denote a word problem by x and an equation system by y. A textual number is a span of text in x that indicates a numeric quantity. Q(x) is the set of all textual numbers.2\nA template T is a parameterized semantic parse, whose parameters are coefficients C(T ) = {ci}ki=1, where each coefficient ci can align to a single textual number. An alignment is a pairing (q, c) between a textual number q \u2208 Q(x) and a coefficient c \u2208 C(T ).\nA set of alignmentsA and a template T together identify a derivation z = (T,A) of an equation system. We use (A, B, C, . . .) to represents coefficients and (m, n, . . .) to represent the unknown variables in the templates. We assume there exists a routine Solve(y) that provides the solution of an equation system. We use a Gaussian elimination solver for our Solve routine.\nDerivation Equivalence We define two derivations (T1, A1) and (T2, A2) to be equal if the corresponding templates T1, T2 and alignments A1, A2 are equivalent.\nIntuitively, two templates T1, T2 are equivalent if they can generate the same space of equation systems \u2013 i.e., for every assignment of values to slots of T1, there exists an assignment of values to\n2We use the quantity normalizer in Stanford CoreNLP (Manning et al., 2014) to identify textual numbers.\nAlgorithm 1 Judging Template Equivalence. Input: Two templates T1 and T2 with coefficients C(T1) and C(T1) respectively, such that |C(T1)| = |C(T2)|; R : Rounds\n1: \u0393\u2190 \u2205 2: for each 1-to-1 mapping \u03b3 : C(T1)\u2192 C(T2) do 3: match\u2190 True 4: for t = 1 \u00b7 \u00b7 \u00b7R do 5: Generate random vector v 6: A1 \u2190 {(vi \u2192 ci)},A2 \u2190 {(vi \u2192 \u03b3(ci))} 7: if Solve(T1, A1) 6= Solve(T2, A2) then 8: match\u2190 False; break 9: end if\n10: end for 11: if match then \u0393\u2190 \u0393 \u222a {\u03b3} 12: end for 13: return \u0393 . \u0393 6= \u2205 iff the templates are equivalent\nslots of T2 such that they generate the same equation systems. Similarly, two alignments A1 and A2 are equivalent if corresponding slots from each template align to the same textual number. In the following, we carefully explain how template and alignment equivalence are determined.\nTemplate Equivalence Here we propose an algorithm that can automatically detect the equivalence between two templates. The algorithm will also find out all the valid mappings of coefficients between two templates. We use Algorithm 1 to identify equivalent templates, using the fact that under appropriate renaming of coefficients, two equivalent templates will generate equations which have the same solutions, for all possible coefficient assignments.\nFor two templates T1 and T2, with the same number of coefficients |C(T1)| = |C(T2)|, we represent a choice of renaming coefficients by \u03b3, a 1-to-1 mapping from C(T1) to C(T2). The two templates are equivalent if there is a \u03b3 such that solutions of the equations identified by T1 and T2 are same, for all possible coefficient assignments. The algorithm exhaustively tries all possible renaming of coefficients, checking if the solutions of the equation systems generated from a random assignment match exactly. It reports equivalence if for a renaming \u03b3, the solutions match for R = 10 such random assignments. Despite this approximation, Algorithm 1 is quite effective, as we manual examine the annotation and did not find out any false positive case produced by the algorithm.\nAlignment Equivalence After running the template equivalence algorithm, we have obtained every mapping \u03b3 in \u0393 under which the templates were equivalent. Recall that \u03b3 identifies corre-\nsponding slots c and \u03b3(c) in T1 and T2 respectively. Two alignments A1 and A2 are equivalent if corresponding slots (according to \u03b3) from each template align to the same textual number. More formally, if we find a mapping \u03b3 such that for each alignment (q, c) in A1 there is alignment (q, \u03b3(c)) in A2, then the alignments are equivalent.\nWe declare derivations (T1, A1) and (T2, A2) to be equivalent after checking both their template and alignment equivalent of each other."}, {"heading": "3 Annotating Derivations", "text": "As none of the existing benchmarks contain derivation annotations, we decided to augment existing datasets with these annotations. We also created DRAW-1K, a new dataset of 1000 general algebra word problems to make our study more comprehensive.\nAnnotating gold derivations from scratch for all problems is time consuming. However, all word problems do not require manual annotation, as sometimes a number appearing in an equation may be uniquely aligned to a textual number. We first identify word problems which have ambiguity for alignments \u2013 problems which have multiple textual numbers with the same value which appear in the equation system. We only semi-automatically annotate problems which involve such alignment ambiguities.3 For the remaining problems, the annotations are generated fully-automatically.\nOur approach involves two stages, where the first stage finds the correct template and alignments, while the second stage prunes equivalent pairs of templates.\nIn the first stage, each number appearing in y is replaced with a coefficient c if a textual number q \u2208 Q(x) with the same value is found in x. The alignment (q, c) is also added to the alignment set Ai. If there are multiple valid choices of q, we choose the first one. All numbers in y with the same value are assumed to map to the same coefficient. The equation system y, whose numbers have now been replaced with coefficients, becomes the template Ti. Then. we ask a human annotator to correct the alignment for the numbers which cause ambiguity, that is, numbers in the equation which can align to multiple textual numbers. Once the alignments are corrected by the annotator, the templates are re-generated to reflect the change.\n3However, annotations for all problems are verified later.\nIn the second stage, we use Algorithm 1 to automatically reconcile the templates in the derivations by finding pairs of equivalent templates, and replacing one with the other in the dataset. This remove redundancy in the annotations \u2013 if two templates are equivalent, it is desirable to only use one of them to in the annotations. We reconcile the templates to reveal the true complexity of the dataset, as we found that that the number of templates can be significantly overestimated by over 30% without properly reconciliation."}, {"heading": "4 Experimental Setup", "text": "In the following, we describe the datasets used in our experiments. The dataset ALG-514 was introduced in (Kushman et al., 2014). It consists problems crawled from algebra.com, ranging over a variety of narrative scenarios (distance-speed, object counting, simple interest, etc.).\nDOLPHIN-L is the linear-T2 subset of the DOLPHIN dataset (Shi et al., 2015). DOLPHIN focuses on a special kind of algebra word problems, e.g. number word problems, which describe mathematical relationships directly in the text.\nWe introduce Diverse Algebra Word (DRAW1K), a new dataset, in this paper. It consists 1000 word problems crawled from algebra. com. Details on the dataset creation can be found in the appendix.\nWe use 5-fold cross validation splits provided by the authors for DOLPHIN-L and ALG-514. We randomly split DRAW-1K into train, dev and test splits with 600, 200, 200 problems respectively.\nStatistics comparing the 3 datasets is shown in Table 2. Of all the datasets, DRAW-1K is the largest dataset on general algebra word problems."}, {"heading": "4.1 Evaluation", "text": "We compare the following evaluation metrics.\nDerivation Accuracy A derivation is correct if the predicted derivation\u2019s template is equivalent to the reference derivation\u2019s template, and the set of aligned textual numbers match those of the reference derivation, as we defined it in Section 2.\nSolution Accuracy Following previous work (Kushman et al., 2014), we compute solution accuracy by checking if each number in the reference solution appears in the generated solution (disregarding order).\nEquation Accuracy An approximation of derivation accuracy used in Kushman et al. (2014). A reference derivation z\u0303 is randomly chosen from the set of derivations which construct the gold y from x. Derivation accuracy is computed against this reference derivation. Without human correction, the reference derivation can be incorrect, as several derivations may lead to the same y."}, {"heading": "5 Experiments", "text": "We aim to answer the following questions in our experiments:\nGiven that we want to evaluate the reasoning ability for word problem solvers, are solution accuracy and equation accuracy good approximation of derivation accuracy?\nTo answer our questions, we need to construct two solvers where one of it has clear advantages, and see if the evaluation metrics can reflect this advantage. To construct such cases, we use the following settings, which are designed to show the value of each stage of our transformation in \u00a7 3. We evaluate the solver using the metrics described in \u00a7 4.1.\nTE (TRAIN ON EQUATION) Only the (x,y) pairs are provided as supervision. Similar to (Kushman et al., 2014; Zhou et al., 2015), we use an approximation algorithm to find a derivation that agrees with the equation system and the solutions. This setting represents the supervision used in existing approaches (our baseline).\nTD (TRAIN ON DERIVATION) (x, z) pairs obtained by the full transformation are used as supervision.\nIt should be obvious that TD setting is a more informative supervision strategy than the TE setting, as it provides labeled semantic parses (i.e. derivations) instead of only question-answer pair. In fact, as we will show it later, TD is better than TE on both solution and derivation accuracy on all cases.\nMain Results We investigate if solution accuracy and equation accuracy are good approximation for derivation accuracy using the models in Table 3. We want to determine to what degree each evaluation metric reflects the superiority of TD over TE.\nWe can note that solution accuracy always exceeds derivation accuracy, as a solver can sometimes get the right solutions even with the wrong derivation. Also note that solution accuracy can sometimes hide the true improvement in reasoning ability. For instance, solution accuracy only changes by 2.4 on Dolphin when comparing TE and TD, whereas derivation accuracy changes by 10.7 points, clearly showing TD is more informative supervision setting.\nOn the other hand, equation accuracy (the approximated version of derivation accuracy) has several issues. In cases like DRAW-1K, equation accuracy cannot determine which model is better and assigns them the same score. Furthermore, it often considers TD to be a worse setting than TE, as evident from decrease in the scores. For instance, on DOLPHIN-L (TE) to DOLPHIN-L (TD), while both solution accuracy and derivation accuracy improve, equation accuracy worsens by 13.3 pts. Recall that equation accuracy attempts to approximate derivation accuracy by choosing a reference derivation, which can possibly be incorrect. Comparing against the incorrect derivation can easily mislead evaluation.\nCase Study To understand the differences between solution accuracy, equation accuracy and derivation accuracy, we use the following case from the ALG-514 dataset:\nMrs. Martin bought 3(q1) cups of coffee and 2(q2) bagels and spent 12.75(q3) dollars. Mr. Martin bought 2(q4) cups of coffee and 5(q5) bagels and spent 14.00(q6) dollars. Find the cost of one(q7) cup of coffee and the cost of one(q8) bagel.\nNote that there are six textual numbers (q1, . . . , q8) in the word problem. The correct derivation is\nq1m+ q2n = q3\nq4m+ q5n = q6.\nHowever, without using the derivation annotation, we found that approximation algorithm found the\nwrong derivation and treated it as the correct derivation for this example.\nq1m+ q2n = q3\nq2m+ q5n = q6.\nNote while this derivation does generate the correct equation system and solutions, the derivation utilizes the wrong numbers and totally misunderstood the original semantics of the word problem. This example demonstrates the needs to evaluate the quality of the word problem solvers using the annotated derivations."}, {"heading": "6 Conclusion and Discussion", "text": "In this paper, we propose algorithms for evaluating and annotating derivations for word problems, and introduced a new dataset, DRAW-1K. We also augmented existing benchmarks with derivation annotations to facilitate future comparisons. We found out that derivation accuracy is a more accurate assessment of the ability of solvers for understanding the context of the natural language, compared to solution or equation accuracy.\nWe also believe that the dataset with the derivation annotations can have new purposes beyond the current intentions. For example, the derivation annotation also allows training systems to produce partial equation system with incomplete word problems. We hope the dataset will open new possibilities for the community to simulate new ideas and applications for automatic problem solvers."}], "references": [{"title": "A questionanswering system for high school algebra word problems", "author": ["Daniel G. Bobrow"], "venue": "In Proceedings of the October", "citeRegEx": "Bobrow.,? \\Q1964\\E", "shortCiteRegEx": "Bobrow.", "year": 1964}, {"title": "My computer is an honor student but how intelligent is it? standardized tests as a measure of ai", "author": ["Clark", "Etzioni2016] Peter Clark", "Oren Etzioni"], "venue": null, "citeRegEx": "Clark et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Clark et al\\.", "year": 2016}, {"title": "Comprehension of arithmetic word problems: A comparison of successful and unsuccessful problem solvers", "author": ["Hegarty et al.1995] Mary Hegarty", "Richard E. Mayer", "Christopher A. Monk"], "venue": "Journal Of Educational Psychology,", "citeRegEx": "Hegarty et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Hegarty et al\\.", "year": 1995}, {"title": "Learning to solve arithmetic word problems with verb categorization", "author": ["Hannaneh Hajishirzi", "Oren Etzioni", "Nate Kushman"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Lan-", "citeRegEx": "Hosseini et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hosseini et al\\.", "year": 2014}, {"title": "How well do computers solve math word problems? large-scale dataset construction and evaluation", "author": ["Huang et al.2016] Danqing Huang", "Shuming Shi", "Chin-Yew Lin", "Jian Yin", "Wei-Ying Ma"], "venue": "In Proceedings of the 54th Annual Meeting of the As-", "citeRegEx": "Huang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2016}, {"title": "Parsing algebraic word problems into equations. Transactions of the Association for Computational Linguistics, 3:585\u2013597", "author": ["Hannaneh Hajishirzi", "Ashish Sabharwal", "Oren Etzioni", "Siena Ang"], "venue": null, "citeRegEx": "Koncel.Kedziorski et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Koncel.Kedziorski et al\\.", "year": 2015}, {"title": "Learning to automatically solve algebra word problems", "author": ["Kushman et al.2014] Nate Kushman", "Yoav Artzi", "Luke Zettlemoyer", "Regina Barzilay"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume", "citeRegEx": "Kushman et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kushman et al\\.", "year": 2014}, {"title": "The Stanford CoreNLP natural language processing toolkit", "author": ["Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven J. Bethard", "David McClosky"], "venue": "In Proceedings of 52nd Annual Meeting of the Associa-", "citeRegEx": "Manning et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Manning et al\\.", "year": 2014}, {"title": "Automatically solving number word problems by semantic parsing and reasoning", "author": ["Shi et al.2015] Shuming Shi", "Yuehui Wang", "Chin-Yew Lin", "Xiaojiang Liu", "Yong Rui"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Lan-", "citeRegEx": "Shi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Shi et al\\.", "year": 2015}, {"title": "Learn to solve algebra word problems using quadratic programming", "author": ["Zhou et al.2015] Lipu Zhou", "Shuaixiang Dai", "Liwei Chen"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Zhou et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "Automatically solving math reasoning problems is a long-pursued goal of AI (Bobrow, 1964; Hegarty et al., 1995).", "startOffset": 75, "endOffset": 111}, {"referenceID": 2, "context": "Automatically solving math reasoning problems is a long-pursued goal of AI (Bobrow, 1964; Hegarty et al., 1995).", "startOffset": 75, "endOffset": 111}, {"referenceID": 6, "context": "Recent work (Kushman et al., 2014; Shi et al., 2015; Koncel-Kedziorski et al., 2015) has focused on developing solvers for algebra word problems, such as the one shown in Figure 1.", "startOffset": 12, "endOffset": 84}, {"referenceID": 8, "context": "Recent work (Kushman et al., 2014; Shi et al., 2015; Koncel-Kedziorski et al., 2015) has focused on developing solvers for algebra word problems, such as the one shown in Figure 1.", "startOffset": 12, "endOffset": 84}, {"referenceID": 5, "context": "Recent work (Kushman et al., 2014; Shi et al., 2015; Koncel-Kedziorski et al., 2015) has focused on developing solvers for algebra word problems, such as the one shown in Figure 1.", "startOffset": 12, "endOffset": 84}, {"referenceID": 6, "context": "The most popular strategy is to use solution accuracy (whether the solution was correct or not) (Kushman et al., 2014; Hosseini et al., 2014; Shi et al., 2015; Koncel-Kedziorski et al., 2015; Zhou et al., 2015; Huang et al., 2016), as this is the easiest measurement to implement.", "startOffset": 96, "endOffset": 230}, {"referenceID": 3, "context": "The most popular strategy is to use solution accuracy (whether the solution was correct or not) (Kushman et al., 2014; Hosseini et al., 2014; Shi et al., 2015; Koncel-Kedziorski et al., 2015; Zhou et al., 2015; Huang et al., 2016), as this is the easiest measurement to implement.", "startOffset": 96, "endOffset": 230}, {"referenceID": 8, "context": "The most popular strategy is to use solution accuracy (whether the solution was correct or not) (Kushman et al., 2014; Hosseini et al., 2014; Shi et al., 2015; Koncel-Kedziorski et al., 2015; Zhou et al., 2015; Huang et al., 2016), as this is the easiest measurement to implement.", "startOffset": 96, "endOffset": 230}, {"referenceID": 5, "context": "The most popular strategy is to use solution accuracy (whether the solution was correct or not) (Kushman et al., 2014; Hosseini et al., 2014; Shi et al., 2015; Koncel-Kedziorski et al., 2015; Zhou et al., 2015; Huang et al., 2016), as this is the easiest measurement to implement.", "startOffset": 96, "endOffset": 230}, {"referenceID": 9, "context": "The most popular strategy is to use solution accuracy (whether the solution was correct or not) (Kushman et al., 2014; Hosseini et al., 2014; Shi et al., 2015; Koncel-Kedziorski et al., 2015; Zhou et al., 2015; Huang et al., 2016), as this is the easiest measurement to implement.", "startOffset": 96, "endOffset": 230}, {"referenceID": 4, "context": "The most popular strategy is to use solution accuracy (whether the solution was correct or not) (Kushman et al., 2014; Hosseini et al., 2014; Shi et al., 2015; Koncel-Kedziorski et al., 2015; Zhou et al., 2015; Huang et al., 2016), as this is the easiest measurement to implement.", "startOffset": 96, "endOffset": 230}, {"referenceID": 6, "context": "curacy1 (Kushman et al., 2014; Zhou et al., 2015), which can be considered as comparing derivations approximately (as there is no gold labeled derivation before this work).", "startOffset": 8, "endOffset": 49}, {"referenceID": 9, "context": "curacy1 (Kushman et al., 2014; Zhou et al., 2015), which can be considered as comparing derivations approximately (as there is no gold labeled derivation before this work).", "startOffset": 8, "endOffset": 49}, {"referenceID": 6, "context": "Different papers use different procedures for calculating the equation accuracy (Kushman et al., 2014; Zhou et al., 2015).", "startOffset": 80, "endOffset": 121}, {"referenceID": 9, "context": "Different papers use different procedures for calculating the equation accuracy (Kushman et al., 2014; Zhou et al., 2015).", "startOffset": 80, "endOffset": 121}, {"referenceID": 6, "context": "In this paper, we mainly adopt the version proposed by (Kushman et al., 2014), where they inferred the template from the equations system without using the gold derivation.", "startOffset": 55, "endOffset": 77}, {"referenceID": 7, "context": "We use the quantity normalizer in Stanford CoreNLP (Manning et al., 2014) to identify textual numbers.", "startOffset": 51, "endOffset": 73}, {"referenceID": 6, "context": "The dataset ALG-514 was introduced in (Kushman et al., 2014).", "startOffset": 38, "endOffset": 60}, {"referenceID": 8, "context": "DOLPHIN-L is the linear-T2 subset of the DOLPHIN dataset (Shi et al., 2015).", "startOffset": 57, "endOffset": 75}, {"referenceID": 6, "context": "Solution Accuracy Following previous work (Kushman et al., 2014), we compute solution accuracy by checking if each number in the reference solution appears in the generated solution (disregarding order).", "startOffset": 42, "endOffset": 64}, {"referenceID": 6, "context": "Equation Accuracy An approximation of derivation accuracy used in Kushman et al. (2014). A reference derivation z\u0303 is randomly chosen from the set of derivations which construct the gold y from x.", "startOffset": 66, "endOffset": 88}, {"referenceID": 6, "context": "Similar to (Kushman et al., 2014; Zhou et al., 2015), we use an approximation algorithm to find a derivation that agrees with the equation system and the solutions.", "startOffset": 11, "endOffset": 52}, {"referenceID": 9, "context": "Similar to (Kushman et al., 2014; Zhou et al., 2015), we use an approximation algorithm to find a derivation that agrees with the equation system and the solutions.", "startOffset": 11, "endOffset": 52}], "year": 2016, "abstractText": "We propose a new evaluation for automatic solvers for algebra word problems, which can identify reasoning mistakes that existing evaluations overlook. Our proposal is to use derivations for evaluations, which reflect the reasoning process of the solver by explaining how the equation system was constructed. We accomplish this by developing an algorithm for checking the equivalence between two derivations, and showing how derivation annotations can be semi-automatically added to existing datasets. To make our experiments more comprehensive, we also annotated DRAW-1K , a new dataset of 1000 general algebra word problems. In total, our experiments span over 2300 algebra word problems. We found that the annotated derivation enable a superior evaluation of automatic solvers than previously used metrics.", "creator": "LaTeX with hyperref package"}}}