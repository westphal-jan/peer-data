{"id": "1611.02956", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Nov-2016", "title": "A Comparison of Word Embeddings for English and Cross-Lingual Chinese Word Sense Disambiguation", "abstract": "Word culturas longer as branded separate, same representation in dependent interpretation applications. There believed both applications the word tableaux bringing monolingual call sense caroliniana (WSD) second English, either same highlighted taking only something. This paper meant to bridge concerned gap to examining pop aggregations provided came preparation much newari English WSD. Our streamlined method major to comparable court - an - a - art performance same expensive staffing. Cross - Lingual WSD - area way word senses that only this in makes source uses microsoft come as while separate target aramaic instruction nasdaq100 - else also assist he dictionary ability; for any, when essential encyclopedias and target lexicon for proficiency. Thus we likely although and/or \u201d perverts came the adventures task including cross - air-filled WSD without Chinese example provide called public waveform for elsewhere benchmarking. We have. experimented with hand referred sheaves for LSTM cellular and found steady any next basic LSTM providing does not work one. We discuss the complicate an this outcome.", "histories": [["v1", "Wed, 9 Nov 2016 14:50:01 GMT  (25kb)", "https://arxiv.org/abs/1611.02956v1", "10 pages"], ["v2", "Fri, 11 Nov 2016 15:30:36 GMT  (25kb)", "http://arxiv.org/abs/1611.02956v2", "10 pages. Will appear in the Proceedings of The 3rd Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA 2016)"], ["v3", "Sun, 9 Apr 2017 11:54:01 GMT  (25kb)", "http://arxiv.org/abs/1611.02956v3", "10 pages. Appears in the Proceedings of The 3rd Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA 2016)"]], "COMMENTS": "10 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["hong jin kang", "tao chen", "muthu kumar chandrasekaran", "min-yen kan"], "accepted": false, "id": "1611.02956"}, "pdf": {"name": "1611.02956.pdf", "metadata": {"source": "CRF", "title": "A Comparison of Word Embeddings for English and Cross-Lingual Chinese Word Sense Disambiguation", "authors": ["Hong Jin Kang", "Tao Chen", "Muthu Kumar Chandrasekaran", "Min-Yen Kan"], "emails": ["kanghongjin@gmail.com", "taochen@comp.nus.edu.sg", "muthu.chandra@comp.nus.edu.sg", "kanmy@comp.nus.edu.sg"], "sections": [{"heading": null, "text": "ar X\niv :1\n61 1.\n02 95\n6v 3\n[ cs\n.C L\n] 9\nA pr\n2 01\n7\ning. There have been applications of word embeddings for monolingual word sense disambiguation (WSD) in English, but few comparisons have been done. This paper attempts to bridge that gap by examining popular embeddings for the task of monolingual English WSD. Our simplified method leads to comparable state-of-the-art performance without expensive retraining.\nCross-Lingual WSD \u2013 where the word senses of a word in a source language e come from a separate target translation language f \u2013 can also assist in language learning; for example, when providing translations of target vocabulary for learners. Thus we have also applied word embeddings to the novel task of cross-lingual WSD for Chinese and provide a public dataset for further benchmarking. We have also experimented with using word embeddings for LSTM networks and found surprisingly that a basic LSTM network does not work well. We discuss the ramifications of this outcome."}, {"heading": "1 Introduction", "text": "A word takes on different meanings, largely dependent on the context in which it is used. For example, the word \u201cbank\u201d could mean \u201cslope beside a body of water\u201d, or a \u201cdepository financial institution\u201d 1. Word Sense Disambiguation (WSD) is the task of identifying the contextually appropriate meaning of the word. WSD is often considered a classification task, in which the classifier predicts the sense from a possible set of senses, known as a sense inventory, given the target word and the contextual information of the target word. Existing WSD systems can be categorised into either data-driven supervised or knowledge-rich approaches. Both approaches are considered to be complementary to each other.\nWord embeddings have become a popular word representation formalism, and many tasks can be done using word embeddings. The effectiveness of using word embeddings has been shown in several NLP tasks (Turian et al., 2010). The goal of our work is to apply and comprehensively compare different uses of word embeddings, solely with respect to WSD. We perform evaluation of the effectiveness of word embeddings on monolingual WSD tasks from Senseval-2 (held in 2001), Senseval-3 (held in 2004), and SemEval-2007. After which, we evaluate our approach on English\u2013Chinese Cross-Lingual WSD using a dataset that we constructed for evaluating our approach on the translation task used in educational applications for language learning."}, {"heading": "2 Related Work", "text": "Word Sense Disambiguation is a well-studied problem, in which many methods have been applied. Existing methods can be broadly categorised into supervised approaches, where machine learning techniques\n\u2217This research is supported by the Singapore National Research Foundation under its International Research Centre @ Singapore Funding Initiative and administered by the IDM Programme Office.\nThis work is licensed under a Creative Commons Attribution 4.0 International Licence. Licence details: http://creativecommons.org/licenses/by/4.0/\n1 http://wordnetweb.princeton.edu/perl/webwn?s=bank\nare used to learn from labeled training data; and unsupervised techniques, which do not rely on labeled data. Unsupervised techniques are knowledge-rich, and rely heavily on knowledge bases and thesaurus, such as WordNet (Miller, 1995). It is noted by Navigli (2009) that supervised approaches using memorybased learning and SVM approaches have worked best.\nSupervised approaches involve the extraction of features and then classification using machine learning. Zhong and Ng (2010) developed an open-source WSD system, ItMakesSense (hereafter, IMS), which was considered the state-of-the-art at the time it was developed. It is a supervised WSD system, which had to be trained prior to use. IMS uses three feature types: 1) individual words in the context surrounding the target word, 2) specific ordered sequences of words appearing at specified offsets from the target word, and 3) Part-Of-Speech tags of the surrounding three words.\nEach of the features are binary features, and IMS trains a model for each word. IMS then uses an support vector machine (SVM) for classification. IMS is open-source, provides state-of-the-art performance, and is easy to extend. As such, our work features IMS and extends off of this backbone.\nTraining data is required to train IMS. We make use of the One-Million Sense-Tagged Instances (Taghipour and Ng, 2015a) dataset, which is the largest dataset we know of for training WSD systems, in training our systems for the All Words tasks.\nWSD systems can be evaluated using either fine-grained scoring or coarse-grained scoring. Under fine-grained scoring, every sense is equally distinct from each other, and answers must exactly match. WordNet is often used as the sense inventory for monolingual WSD tasks. However, WordNet is a fine-grained resource, and even human annotators have trouble distinguishing between different senses of a word (Edmonds and Kilgarriff, 2002). In contrast, under coarse-grained scoring, similar senses are grouped and treated as a single sense. In some WSD tasks in SemEval, coarse-grained scoring was done in order to deal with the problem of reliably distinguishing fine-grained senses."}, {"heading": "2.1 Cross-Lingual Word Sense Disambiguation", "text": "Cross-Lingual WSD was, in part, conceived as a further attempt to solve this issue. In CrossLingual WSD, the specificity of a sense is determined by its correct translation in another language. The sense inventory is the possible translations of each word in another language. Two instances are said to have the same sense if they map to the same translation in that language. SemEval2010 (Lefever and Hoste, 2010)2 and SemEval-2013 (Lefever and Hoste, 2013)3 featured iterations of this task. These tasks featured English nouns as the source words, and word senses as translations in Dutch, French, Italian, Spanish and German.\nTraditional WSD approaches are used in Cross-Lingual WSD, although some approaches leverage statistical machine translation (SMT) methods and features from translation. Cross-Lingual WSD involves training by making use of parallel or multilingual corpora. In the Cross-Lingual WSD task in SemEval-2013, the top performing approaches used either classification or SMT approaches."}, {"heading": "2.2 WSD with Word Embeddings", "text": "In NLP, words can be represented with a distributed representation, such as word embeddings, which encodes words into a low dimensional space. In word embeddings, information about a word is distributed across multiple dimensions, and similar words are expected to be close to each other in the vector space. Examples of word embeddings are Continuous Bag of Words (Mikolov et al., 2013), Collobert &Weston\u2019s Embeddings (Collobert and Weston, 2008), and GLoVe (Pennington et al., 2014). We implemented and evaluated the use of word embedding features using these three embeddings in IMS.\nAn unsupervised approach using word embeddings for WSD is described by Chen (2014). This approach finds representation of senses, instead of words, and computes a context vector which is used during disambiguation.\nA different approach is to work on extending existing WSD systems. Turian (2010) suggests that for any existing supervised NLP system, a general way of improving accuracy would be to use unsupervised\n2http://stel.ub.edu/semeval2010-coref/ 3 https://www.cs.york.ac.uk/semeval-2013/\nword representations as additional features. Taghipour (2015b) used C&W embeddings as a starting point and implemented word embeddings as a feature type in IMS. For a specified window, vectors for the surrounding words in the windows, excluding the target word, are obtained from the embeddings and are concatenated, producing d \u2217 (w \u2212 1) features, where d is the number of dimensions of the vector, and w is the window size. Each feature is a floating point number, which is the value of the vector in a dimension. We note that (Taghipour and Ng, 2015b) only reported results for C&W embeddings, and did not experiment on other types of word embeddings.\nOther supervised approaches using word embeddings include AutoExtend (Rothe and Schu\u0308tze, 2015), which extended word embeddings to create embeddings for synsets and lexemes. In their work, they also extended IMS, but used their own embeddings. The feature types introduced by this work bear similarities to how Taghipour used word embeddings, but without Taghipour\u2019s method of scaling each dimension of the word embeddings.\nTo conclude, word embeddings have been used in several methods to improve on state-of-the-art results in WSD. However, to date, there has been little work investigating how different word embeddings and parameters affect performance of baseline methods of WSD. As far as we know, there has only been one paper comparing the different word embeddings with the use of basic composition methods in WSD. Iacobacci (2016) performed an evaluation study of different parameters when enhancing an existing supervised WSD system with word embeddings. Iacobacci noted that the integration of Word2Vec (skipgram) with IMSwas consistently helpful and provided the best performance. Iacobacci also noted that the composition methods of average and concatenation produced small gains relative to the other composition strategies introduced. However, Iacobacci did not investigate the use of (Taghipour and Ng, 2015b)\u2019s scaling strategy, which was crucial to improve the performance of IMS.\nWe also did not find any recent work attempting to integrate modern WSD systems for real-world education usage, and to evaluate the WSD system based on the requirements and suitability for education use. We aim to fill this gap in applied WSD with this work."}, {"heading": "3 Methods", "text": "As Navigli (2009) noted that supervised approaches have performed best in WSD, we focus on integrating word embeddings in supervised approaches; in specific, we explore the use of word embeddings within the IMS framework. We focus our work on Continuous Bag of Words (CBOW) from Word2Vec, Global Vectors for Word Representation (GloVe) and Collobert & Weston\u2019s Embeddings(C&W). The CBOW embeddings were trained over Wikipedia, while the publicly available vectors from GloVe and C&W were used. Word2Vec provides 2 architectures for learning word embeddings, Skip-gram and CBOW. In contrast to Iacobacci (2016) which focused on Skip-gram, we focused our work on CBOW. In our first set of evaluations, we used tasks from Senseval-2 (hereafter SE-2), Senseval-3 (hereafter SE-3) and SemEval-2007 (hereafter SE-2007) to evaluate the performance of our classifiers on monolingual WSD. We do this to first validate that our approach is a sound approach of performing WSD, showing improved or identical scores to state-of-the-art systems in most tasks.\nSimilar to the work by Taghipour (2015b), we experimented with the use of word embeddings as feature types in IMS. However, we did not just experiment using C&W embeddings, as different word embeddings are known to vary in quality when evaluated on different tasks (Schnabel et al., 2015). We performed evaluation on several tasks. For the Lexical Sample (LS) tasks of SE-2 (Kilgarriff, 2001) and SE3 (Mihalcea et al., 2004), we evaluated our system using fine-grained scoring. For the All Words (AW) tasks, fine-grained scoring is done for SE-2 (Palmer et al., 2001) and SE-3 (Snyder and Palmer, 2004); both the fine (Pradhan et al., 2007) and coarse-grained were used in (Navigli et al., 2007) AW tasks in SE-2007. In order to evaluate our features on the AW task, we trained IMS and the different combinations of features on the One Million Sense-Tagged corpus (Taghipour and Ng, 2015a).\nTo compose word vectors, one method (used as a baseline) is to sum up the word vectors of the words in the surrounding context or sentence. We primarily experimented on this method of composition, due to its good performance and short training time. For this, every word vector for every lemma in the sentence (exclusive of the target word) was summed into a context vector, resulting in d features. Stopwords and\npunctuation are discarded. In Turian\u2019s (2010) work, two hyperparameters \u2014 the capacity (number of dimensions) and size of the word embeddings \u2014 were tuned in his experiments. We follow his protocol and perform the same in our experiments.\nAs the remaining features in IMS are binary features, they are not comparable to the word embeddings which can have unbounded values, leading to unbalanced influence. As suggested by Turian (2010), we should scale down the word embeddings values to the same range as other features. The embeddings are scaled to control their standard deviations. We implement a variant of this technique as done by Taghipour (2015b), in which we set the target standard deviation for each dimension. A comparison of different values of the scaling parameter, \u03c3 is done. For each i \u2208 {1, 2, ..d}:\nEi \u2190 \u03c3 \u00d7 Ei\nstdev(Ei) , where \u03c3 is a scaling constant that sets the target standard deviation\nSimilar to Turian (2010) and Taghipour (2015b), we found that a value of 0.1 for \u03c3 works well, as seen in Table 1. We evaluate the effect of varying the scaling factor with the feature of the sum of the surrounding word vectors, and find that the summation feature works optimally with 50 dimensions.\nIn Table 2, we evaluate the performance of our system on both the LS and AW tasks of SE-2 (held in 2001) and SE-3\u2019s (held in 2004), and the AW tasks of SE-2007, which were evaluated on by Zhong and Ng (2010). We obtain statistically significant improvements over IMS on the LS tasks. Our enhancements to IMS to make use of word embeddings also give better results on the AW task than the original IMS, the respective Rank 1 systems from the original shared tasks, and several recent systems developed and evaluated evaluated on the same tasks. We note that although our system increased accuracy on IMS on several AW tasks, the differences were not statistically significant (as measured using McNemar\u2019s test for paired nominal data).\nIt can be seen that the simple enhancement of integrating word embedding using the baseline composition method, followed by the scaling step, improves IMS, and we get performance comparable to or better than the Rank 1 systems in many tasks.\nAs word embeddings with higher dimensions increases the feature space of IMS, this may lead to overfitting on some datasets. We believe, this is why a smaller number of dimensions work better in the LS tasks. However, as seen in Table 3, this effect was not observed in the AW task. We also note that relatively poorer performance in the LS tasks may not necessarily result in poor performance in the AW task. We see from the results that the combination of (Taghipour and Ng, 2015b)\u2019s scaling strategy and summation produced results better than the proposal in (Iacobacci et al., 2016) to concatenate and average (0.651 and 0.654), suggesting that the scaling factor is important for the integration of word embeddings for supervised WSD."}, {"heading": "3.1 LSTM Network", "text": "A Long Short Term Memory (LSTM) network is a type of Recurrent Neural Network which has recently been shown to have good performance on many NLP classification tasks. The potential benefit of using an approach using LSTM over our existing approach in IMS is this is that an LSTM network is able to use more information about the sequence of words. For WSD, Ka\u030ageba\u0308ck & Salomonsson (2016) explored the use of bidirectional LSTMs. In our approach, we explore a simpler na\u0131\u0308ve approach instead.\nFor the Lexical Sample tasks, we train the model on the training data provided for the task. For the\nAll Words task, we trained the model on the One Million Sense-Tagged dataset. For each task, similar to IMS, we train a model for each word, using GloVe word embeddings as the input layer.\nThe performance of the na\u0131\u0308ve LSTM is poor in both type of tasks, as seen in Table 4. The models converge to just using the most common sense for the AW task. A possible reason for this is overfitting. WSD is known to suffer from data sparsity. Although there are many training examples in total, as we train a separate model for each word, many individual words only have few training examples. We note other attempts to use neural networks for WSD may have run into the same problem. Taghipour and Ng (2015b) indicated the need to prevent overfitting while using a neural network to adapt C&W embeddings by omitting a hidden layer and adding a Dropout layer, while Ka\u030ageba\u0308ck and Salomonsson (2016) developed a new regularization technique in their work."}, {"heading": "4 English-Chinese Cross-Lingual Word Sense Disambiguation", "text": "We now evaluate our proposal on the Cross-Lingual Word Sense Disambiguation task. One key application of such task is to facilitate language learning systems. For example, MindTheWord4 and WordNews (Chen et al., 2015) are two applications that allow users to learn vocabulary of a second language in context, in the form of providing translations of words in an online article. In this work, we model this problem of finding translations of words as a variant of WSD, Cross-Lingual Word Sense Disambiguation, as formalized in (Chen et al., 2015).\nIn the previous section, we have validated and compared enhancements to IMS using word embeddings. These have produced results comparable to, and in some cases, better than state-of-the-art performance on the monolingual WSD tasks. We further evaluate our approach for use in the Cross-Lingual Word Sense Disambiguation for performing contextually appropriate translations of single words. To accomplish this, we first construct a English\u2013Chinese Cross-Lingual WSD dataset. For our sense inventory, we work with the existing dictionary in the open-source educational application, WordNews (Chen et al., 2015), which contains a dictionary of English words and their possible Chinese translations. We finally deploy the trained system as a fork of the original WordNews."}, {"heading": "4.1 Dataset", "text": "As far as we know, there is no existing publicly available English\u2013Chinese Cross-Lingual WSD dataset. To evaluate our proposal, therefore, we hired human annotators to construct such an evaluation dataset\n4 https://chrome.google.com/webstore/detail/mindtheword/fabjlaokbhaoehejcoblhahcekmogbom\nusing sentences from recent news articles. As the dataset is constructed using recent news data, it is a good representation for the use case in WordNews. To facilitate future research, we have released the dataset to the public.5\nTo obtain the gold standard for this data set, we hired 18 annotators to select the right translations for a given word and its context. There are 697 instances in total in our dataset, with a total of 251 target words to disambiguate, that were each multiply-annotated by 3 different annotators. Each annotator disambiguated 110+ instances (15 annotators with 116 instances, 3 with 117) in hard-copy. The annotators are all bilingual undergraduate students, who are native Chinese speakers.\nFor each instance, which contains a single English target word to disambiguate, we include the sentence it appears in and its adjacent sentences as its context. Each instance contains possible translations of the word. The annotators selected all Chinese words that had an identical meaning to the English target word. If the word cannot be appropriately translated, we instructed annotators to leave the annotation blank. The annotators provided their own translations if they believe that there is a suitable translation,\n5 https://kanghj.github.io/english_chinese_news_clwsd_dataset/\nbut which was not provided by the crawled dictionary.\nThe concept of a sense is a human construct, and therefore, as earlier elaborated on when discussing sense granularity, it is may be difficult for human annotators to agree on the correct answer. Our annotation task differs from the usual since we allow users to select multiple labels and can also add new labels to each case if they do not agree with any label provided. As such, applying the Cohen\u2019s Kappa as it is for measuring the inter-annotator agreement as it is does not work for our annotated dataset. We are also unable to compute the probably of chance agreement by word, since there are few test instances per word in our dataset.\nThe Kappa equation is given as \u03ba = pA\u2212pE1\u2212pE . To compute pA for \u03ba, we use a simplified, optimistic approach where we select one annotated label out of possibly multiple selected labels for each annotator. We always choose the label that results in an agreement between the pair, if such a label exist. For pE (the probability of chance agreement), as the labels of each case are different, we consider the labels in terms of how frequent they occur in the training data. We only consider the top 3 most frequent senses for each word due to the skewness of the sense distribution. We first compute the probability of an annotator selecting each of the top three frequent senses, pE is then equals to the sum of the probability that both annotators selected one of the three top senses by chance.\nThe pairwise value by this proposed method of \u03ba is obtained is 0.42. We interpreted this as a moderate level of agreement. We note that there is a large number of possible labels for each case, which is known to affect the value of \u03ba negatively. This is exacerbated as we allow the annotators to add new labels.\nIn this annotation task, as we consider the possible translations as fine-grained, the value of agreement is likely to be underestimated in this case. Hence, we believe that clustering of similar translations during annotation is required in order to deal with the issue of sense granularity in Cross-Lingual WSD. To overcome this problem, we used different configurations of granularity during evaluation of our system. For all configurations, we remove instances from the dataset if it does not have a correct sense.\nWe also noticed that some target words were part of a proper noun, such as the word \u2019white\u2019 in \u2019White House\u2019. This led to some confusion among annotators, so we omitted instances where the target word is part of a proper noun. Statistics of the test dataset after filtering out different cases are given in Table 5."}, {"heading": "4.2 Experiments", "text": "As previously described, IMS is a supervised system requiring training data before use. We constructed data by processing a parallel corpus, the news section of the UM-Corpus (Tian et al., 2014), and performing word alignment. We used the dictionary provided by (Chen et al., 2015) as the sense inventory, which we further expanded using translations from Bing Translator and Google Translate. For construction of the training dataset, word alignment is used to assign Chinese words as training labels for each English target word. GIZA++ (Och and Ney, 2003) is used for word alignment. To evaluate our system, we compare the results of the method described in (Chen et al., 2015), which uses Bing Translator and word alignment to obtain translations. We use the configuration where every annotation is considered to be correct for our main evaluation since this is closer to a coarse-grained evaluation.\nIt can be seen that word embeddings improves the performance on Cross-Lingual WSD. Similar to our observations for monolingual WSD, the use of both CBOW and GLoVe improved performance. However, the improvements from the word embeddings feature type over IMS was not statistically significant at 95% confidence level. This is attributed to the small size of the dataset."}, {"heading": "4.3 Bing Translator results", "text": "We wish to highlight and explain the poor performance of Bing Translator with our annotated dataset as seen in Table 6. This could be because Bing Translator performs translation at the phrase level. Therefore, many of the target words are not translated individually and are translated only as part of a larger unit, making it less suitable for the use case in WordNews where only the translation of single words matter. For example, when translating the word \u201clittle\u201d in \u201cThese are serious issues and themes, and sometimes little kids aren\u2019t ready to process and understand these ideas\u201d, Bing Translator provides a translation of \u201c\u8fd9\u4e9b\u90fd\u662f\u4e25\u91cd\u7684\u95ee\u9898\u548c\u4e3b\u9898\uff0c\u6709\u65f6\u5c0f\u5b69 \u4e0d\u51c6\u5907\u5904\u7406\u548c\u7406\u89e3\u8fd9\u4e9b\u60f3\u6cd5\u201d but does not give an alignment for the word \u2018little\u2019 but instead provides an alignment for the entire multi-word unit \u201clittle kids\u201d. As such, the translation would not match any of the annotations provided by our annotators. This is an appropriate treatment since a user of an educational app requesting specifically a translation for the single word \u201clittle\u201d should not see the translation of the phrase."}, {"heading": "5 Conclusion", "text": "After we have evaluated the performance of the systems on the this Cross-Lingual WSD dataset, we integrate the top-performing system using word embeddings and the trained models into a fork of the WordNews system. We experimented and implemented with different methods of using word embeddings for supervised WSD. We tried two approaches, by enhancing an existing WSD system, IMS, and by trying a neural approach using a simple LSTM.We evaluated our apporach as well as various methods in WSD, against initial evaluations on the existing test data sets from Senseval-2, Senseval-3, SemEval2007. In a nutshell, adding any pretrained word embedding as a feature type to IMS resulted in the system performing competitively or better than the state-of-the-art systems on many of the tasks. This supports (Iacobacci et al., 2016)\u2019s conclusion that concluded that existing supervised approaches can be augmented with word embeddings to give better results.\nOur findings also validated Iacobacci et al. (2016)\u2019s findings that Word2Vec gave the best performance. However, we also note that, other than Word2Vec, other publicly available word embeddings, Collobert & Weston\u2019s embeddings and GLoVe also consistently enhanced the performance of IMS using the summation feature with little effort. Other than on the Lexical Sample tasks, where smaller word embeddings performed better, we also found that the number of dimensions did not affect results as much as the scaling parameter. Unlike Iacobacci et al. (2016), we also found that a simple composition method using summation already gave good improvements over the standard WSD features, provided that the scaling method described in (Taghipour and Ng, 2015b) was performed.\nAn additional key contribution of our work was to build a gold-standard English-Chinese CrossLingual WSD dataset constructed with sentences from real news articles and to evaluate our proposed word embedding approach under this scenario. Our compiled dataset was used as evaluation of the task of translating English words on online news articles. This dataset is made available publicly. We observed that word embeddings also improves the performance of WSD in our Cross-Lingual WSD setting.\nAs future work, we will examine how to expand the existing dictionary with more English words of varying difficulty and include more possible Chinese translations, as we note that there were several instances in the Cross-Lingual WSD dataset where the annotators did not choose an existing translation."}], "references": [{"title": "A unifiedmodel for word sense representation and disambiguation", "author": ["Chen et al.2014] Xinxiong Chen", "Zhiyuan Liu", "andMaosong Sun"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Chen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2014}, {"title": "Interactive second language learning from news websites", "author": ["Chen et al.2015] Tao Chen", "Naijia Zheng", "Yue Zhao", "Muthu Kumar Chandrasekaran", "Min-Yen Kan"], "venue": "In Proceedings of ACL Workshop on Natural Language Processing Techniques for Educational Applications (NLP-TEA\u201915),", "citeRegEx": "Chen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "A unified architecture for natural language processing: Deep neural networks with multitask learning", "author": ["Collobert", "Weston2008] Ronan Collobert", "Jason Weston"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "Collobert et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2008}, {"title": "Introduction to the special issue on evaluating word sense disambiguation systems", "author": ["Edmonds", "Kilgarriff2002] Philip Edmonds", "Adam Kilgarriff"], "venue": "Natural Language Engineering,", "citeRegEx": "Edmonds et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Edmonds et al\\.", "year": 2002}, {"title": "Embeddings for word sense disambiguation: An evaluation study", "author": ["Taher Mohammad Pilehvar", "Roberto Navigli"], "venue": "In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),", "citeRegEx": "Iacobacci et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Iacobacci et al\\.", "year": 2016}, {"title": "Word sense disambiguation using a bidirectional lstm", "author": ["K\u00e5geb\u00e4ck", "Salomonsson2016] Mikael K\u00e5geb\u00e4ck", "Hans Salomonsson"], "venue": "arXiv preprint arXiv:1606.03568", "citeRegEx": "K\u00e5geb\u00e4ck et al\\.,? \\Q2016\\E", "shortCiteRegEx": "K\u00e5geb\u00e4ck et al\\.", "year": 2016}, {"title": "English lexical sample task description", "author": ["Adam Kilgarriff"], "venue": "In The Proceedings of the Second International Workshop on Evaluating Word Sense Disambiguation Systems,", "citeRegEx": "Kilgarriff.,? \\Q2001\\E", "shortCiteRegEx": "Kilgarriff.", "year": 2001}, {"title": "Semeval-2010 task 3: Cross-lingual word sense disambiguation", "author": ["Lefever", "Hoste2010] Els Lefever", "V\u00e9ronique Hoste"], "venue": "In Proceedings of the 5th International Workshop on Semantic Evaluation,", "citeRegEx": "Lefever et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Lefever et al\\.", "year": 2010}, {"title": "Semeval-2013 task 10: Cross-lingual word sense disambiguation", "author": ["Lefever", "Hoste2013] Els Lefever", "V\u00e9ronique Hoste"], "venue": "In Second Joint Conference on Lexical and Computational Semantics (*SEM),", "citeRegEx": "Lefever et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Lefever et al\\.", "year": 2013}, {"title": "The Senseval3 English lexical sample task. In Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text. Association for Computational Linguistics", "author": ["Timothy Anatolievich Chklovski", "AdamKilgarriff"], "venue": null, "citeRegEx": "Mihalcea et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Mihalcea et al\\.", "year": 2004}, {"title": "Efficient estimation of word representations in vector space. CoRR, abs/1301.3781", "author": ["Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Wordnet: A lexical database for english", "author": ["George A. Miller"], "venue": "Commun. ACM,", "citeRegEx": "Miller.,? \\Q1995\\E", "shortCiteRegEx": "Miller.", "year": 1995}, {"title": "Semeval-2007 task 07: Coarse-grained english all-words task", "author": ["Kenneth C Litkowski", "Orin Hargraves"], "venue": "In Proceedings of the 4th International Workshop on Semantic Evaluations,", "citeRegEx": "Navigli et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Navigli et al\\.", "year": 2007}, {"title": "Word sense disambiguation: a survey", "author": ["Roberto Navigli"], "venue": "ACM COMPUTING SURVEYS,", "citeRegEx": "Navigli.,? \\Q2009\\E", "shortCiteRegEx": "Navigli.", "year": 2009}, {"title": "A systematic comparison of various statistical alignment models", "author": ["Och", "Ney2003] Franz Josef Och", "Hermann Ney"], "venue": "Computational Linguistics,", "citeRegEx": "Och et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Och et al\\.", "year": 2003}, {"title": "English tasks: All-words and verb lexical sample", "author": ["Palmer et al.2001] Martha Palmer", "Christiane Fellbaum", "Scott Cotton", "Lauren Delfs", "Hoa Trang Dang"], "venue": "In The Proceedings of the Second International Workshop on Evaluating Word Sense Disambiguation Systems,", "citeRegEx": "Palmer et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Palmer et al\\.", "year": 2001}, {"title": "Glove: Global vectors for word representation", "author": ["Richard Socher", "Christopher D Manning"], "venue": "In Proc. of the Empiricial Methods in Natural Language Processing (EMNLP 2014),", "citeRegEx": "Pennington et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "SemEval2007 task 17: English lexical sample, SRL and all words", "author": ["Edward Loper", "Dmitriy Dligach", "Martha Palmer"], "venue": "In Proceedings of the 4th International Workshop on Semantic Evaluations,", "citeRegEx": "Pradhan et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Pradhan et al\\.", "year": 2007}, {"title": "Autoextend: Extending word embeddings to embeddings for synsets and lexemes", "author": ["Rothe", "Sch\u00fctze2015] Sascha Rothe", "Hinrich Sch\u00fctze"], "venue": "In Proceedings of the ACL-IJCNLP,", "citeRegEx": "Rothe et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rothe et al\\.", "year": 2015}, {"title": "Evaluation methods for unsupervised word embeddings", "author": ["Igor Labutov", "David Mimno", "Thorsten Joachims"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Schnabel et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Schnabel et al\\.", "year": 2015}, {"title": "The English all-words task", "author": ["Snyder", "Palmer2004] Benjamin Snyder", "Martha Palmer"], "venue": "In Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text,", "citeRegEx": "Snyder et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Snyder et al\\.", "year": 2004}, {"title": "2015a. One million sense-tagged instances for word sense disambiguation and induction", "author": ["Taghipour", "Ng2015a] Kaveh Taghipour", "Hwee Tou Ng"], "venue": null, "citeRegEx": "Taghipour et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Taghipour et al\\.", "year": 2015}, {"title": "Semi-supervised word sense disambiguation using word embeddings in general and specific domains", "author": ["Taghipour", "Ng2015b] Kaveh Taghipour", "Hwee Tou Ng"], "venue": "Proceedings of HLT-NAACL,", "citeRegEx": "Taghipour et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Taghipour et al\\.", "year": 2015}, {"title": "UMCorpus: A Large English-Chinese Parallel Corpus for Statistical Machine Translation", "author": ["Tian et al.2014] Liang Tian", "Derek F Wong", "Lidia S Chao", "Paulo Quaresma", "Francisco Oliveira"], "venue": "In Proceeding of the LREC,", "citeRegEx": "Tian et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Tian et al\\.", "year": 2014}, {"title": "Word representations: a simple and general method for semi-supervised learning. In Proceedings of the 48th annual meeting of the association for computational linguistics, pages 384\u2013394", "author": ["Turian et al.2010] Joseph Turian", "Lev Ratinov", "Yoshua Bengio"], "venue": null, "citeRegEx": "Turian et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Turian et al\\.", "year": 2010}, {"title": "It makes sense: A wide-coverage word sense disambiguation system for free text", "author": ["Zhong", "Ng2010] Zhi Zhong", "Hwee Tou Ng"], "venue": "In Proceedings of the ACL 2010 System Demonstrations,", "citeRegEx": "Zhong et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Zhong et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 24, "context": "The effectiveness of using word embeddings has been shown in several NLP tasks (Turian et al., 2010).", "startOffset": 79, "endOffset": 100}, {"referenceID": 11, "context": "Unsupervised techniques are knowledge-rich, and rely heavily on knowledge bases and thesaurus, such as WordNet (Miller, 1995).", "startOffset": 111, "endOffset": 125}, {"referenceID": 10, "context": "Unsupervised techniques are knowledge-rich, and rely heavily on knowledge bases and thesaurus, such as WordNet (Miller, 1995). It is noted by Navigli (2009) that supervised approaches using memorybased learning and SVM approaches have worked best.", "startOffset": 112, "endOffset": 157}, {"referenceID": 10, "context": "Unsupervised techniques are knowledge-rich, and rely heavily on knowledge bases and thesaurus, such as WordNet (Miller, 1995). It is noted by Navigli (2009) that supervised approaches using memorybased learning and SVM approaches have worked best. Supervised approaches involve the extraction of features and then classification using machine learning. Zhong and Ng (2010) developed an open-source WSD system, ItMakesSense (hereafter, IMS), which was considered the state-of-the-art at the time it was developed.", "startOffset": 112, "endOffset": 373}, {"referenceID": 10, "context": "Examples of word embeddings are Continuous Bag of Words (Mikolov et al., 2013), Collobert &Weston\u2019s Embeddings (Collobert and Weston, 2008), and GLoVe (Pennington et al.", "startOffset": 56, "endOffset": 78}, {"referenceID": 16, "context": ", 2013), Collobert &Weston\u2019s Embeddings (Collobert and Weston, 2008), and GLoVe (Pennington et al., 2014).", "startOffset": 80, "endOffset": 105}, {"referenceID": 10, "context": "Examples of word embeddings are Continuous Bag of Words (Mikolov et al., 2013), Collobert &Weston\u2019s Embeddings (Collobert and Weston, 2008), and GLoVe (Pennington et al., 2014). We implemented and evaluated the use of word embedding features using these three embeddings in IMS. An unsupervised approach using word embeddings for WSD is described by Chen (2014). This approach finds representation of senses, instead of words, and computes a context vector which is used during disambiguation.", "startOffset": 57, "endOffset": 362}, {"referenceID": 10, "context": "Examples of word embeddings are Continuous Bag of Words (Mikolov et al., 2013), Collobert &Weston\u2019s Embeddings (Collobert and Weston, 2008), and GLoVe (Pennington et al., 2014). We implemented and evaluated the use of word embedding features using these three embeddings in IMS. An unsupervised approach using word embeddings for WSD is described by Chen (2014). This approach finds representation of senses, instead of words, and computes a context vector which is used during disambiguation. A different approach is to work on extending existing WSD systems. Turian (2010) suggests that for any existing supervised NLP system, a general way of improving accuracy would be to use unsupervised", "startOffset": 57, "endOffset": 575}, {"referenceID": 13, "context": "As Navigli (2009) noted that supervised approaches have performed best in WSD, we focus on integrating word embeddings in supervised approaches; in specific, we explore the use of word embeddings within the IMS framework.", "startOffset": 3, "endOffset": 18}, {"referenceID": 13, "context": "As Navigli (2009) noted that supervised approaches have performed best in WSD, we focus on integrating word embeddings in supervised approaches; in specific, we explore the use of word embeddings within the IMS framework. We focus our work on Continuous Bag of Words (CBOW) from Word2Vec, Global Vectors for Word Representation (GloVe) and Collobert & Weston\u2019s Embeddings(C&W). The CBOW embeddings were trained over Wikipedia, while the publicly available vectors from GloVe and C&W were used. Word2Vec provides 2 architectures for learning word embeddings, Skip-gram and CBOW. In contrast to Iacobacci (2016) which focused on Skip-gram, we focused our work on CBOW.", "startOffset": 3, "endOffset": 610}, {"referenceID": 19, "context": "However, we did not just experiment using C&W embeddings, as different word embeddings are known to vary in quality when evaluated on different tasks (Schnabel et al., 2015).", "startOffset": 150, "endOffset": 173}, {"referenceID": 6, "context": "For the Lexical Sample (LS) tasks of SE-2 (Kilgarriff, 2001) and SE3 (Mihalcea et al.", "startOffset": 42, "endOffset": 60}, {"referenceID": 9, "context": "For the Lexical Sample (LS) tasks of SE-2 (Kilgarriff, 2001) and SE3 (Mihalcea et al., 2004), we evaluated our system using fine-grained scoring.", "startOffset": 69, "endOffset": 92}, {"referenceID": 15, "context": "For the All Words (AW) tasks, fine-grained scoring is done for SE-2 (Palmer et al., 2001) and SE-3 (Snyder and Palmer, 2004); both the fine (Pradhan et al.", "startOffset": 68, "endOffset": 89}, {"referenceID": 17, "context": ", 2001) and SE-3 (Snyder and Palmer, 2004); both the fine (Pradhan et al., 2007) and coarse-grained were used in (Navigli et al.", "startOffset": 58, "endOffset": 80}, {"referenceID": 12, "context": ", 2007) and coarse-grained were used in (Navigli et al., 2007) AW tasks in SE-2007.", "startOffset": 40, "endOffset": 62}, {"referenceID": 4, "context": "We see from the results that the combination of (Taghipour and Ng, 2015b)\u2019s scaling strategy and summation produced results better than the proposal in (Iacobacci et al., 2016) to concatenate and average (0.", "startOffset": 152, "endOffset": 176}, {"referenceID": 4, "context": "682 (Iacobacci et al., 2016) 0.", "startOffset": 4, "endOffset": 28}, {"referenceID": 0, "context": "591 (Chen et al., 2014) - - - - 0.", "startOffset": 4, "endOffset": 23}, {"referenceID": 1, "context": "For example, MindTheWord and WordNews (Chen et al., 2015) are two applications that allow users to learn vocabulary of a second language in context, in the form of providing translations of words in an online article.", "startOffset": 38, "endOffset": 57}, {"referenceID": 1, "context": "In this work, we model this problem of finding translations of words as a variant of WSD, Cross-Lingual Word Sense Disambiguation, as formalized in (Chen et al., 2015).", "startOffset": 148, "endOffset": 167}, {"referenceID": 1, "context": "For our sense inventory, we work with the existing dictionary in the open-source educational application, WordNews (Chen et al., 2015), which contains a dictionary of English words and their possible Chinese translations.", "startOffset": 115, "endOffset": 134}, {"referenceID": 23, "context": "We constructed data by processing a parallel corpus, the news section of the UM-Corpus (Tian et al., 2014), and performing word alignment.", "startOffset": 87, "endOffset": 106}, {"referenceID": 1, "context": "We used the dictionary provided by (Chen et al., 2015) as the sense inventory, which we further expanded using translations from Bing Translator and Google Translate.", "startOffset": 35, "endOffset": 54}, {"referenceID": 1, "context": "To evaluate our system, we compare the results of the method described in (Chen et al., 2015), which uses Bing Translator and word alignment to obtain translations.", "startOffset": 74, "endOffset": 93}, {"referenceID": 4, "context": "This supports (Iacobacci et al., 2016)\u2019s conclusion that concluded that existing supervised approaches can be augmented with word embeddings to give better results.", "startOffset": 14, "endOffset": 38}, {"referenceID": 4, "context": "This supports (Iacobacci et al., 2016)\u2019s conclusion that concluded that existing supervised approaches can be augmented with word embeddings to give better results. Our findings also validated Iacobacci et al. (2016)\u2019s findings that Word2Vec gave the best performance.", "startOffset": 15, "endOffset": 217}, {"referenceID": 4, "context": "This supports (Iacobacci et al., 2016)\u2019s conclusion that concluded that existing supervised approaches can be augmented with word embeddings to give better results. Our findings also validated Iacobacci et al. (2016)\u2019s findings that Word2Vec gave the best performance. However, we also note that, other than Word2Vec, other publicly available word embeddings, Collobert & Weston\u2019s embeddings and GLoVe also consistently enhanced the performance of IMS using the summation feature with little effort. Other than on the Lexical Sample tasks, where smaller word embeddings performed better, we also found that the number of dimensions did not affect results as much as the scaling parameter. Unlike Iacobacci et al. (2016), we also found that a simple composition method using summation already gave good improvements over the standard WSD features, provided that the scaling method described in (Taghipour and Ng, 2015b) was performed.", "startOffset": 15, "endOffset": 720}], "year": 2017, "abstractText": "Word embeddings are now ubiquitous forms of word representation in natural language processing. There have been applications of word embeddings for monolingual word sense disambiguation (WSD) in English, but few comparisons have been done. This paper attempts to bridge that gap by examining popular embeddings for the task of monolingual English WSD. Our simplified method leads to comparable state-of-the-art performance without expensive retraining. Cross-Lingual WSD \u2013 where the word senses of a word in a source language e come from a separate target translation language f \u2013 can also assist in language learning; for example, when providing translations of target vocabulary for learners. Thus we have also applied word embeddings to the novel task of cross-lingual WSD for Chinese and provide a public dataset for further benchmarking. We have also experimented with using word embeddings for LSTM networks and found surprisingly that a basic LSTM network does not work well. We discuss the ramifications of this outcome.", "creator": "LaTeX with hyperref package"}}}