{"id": "1611.09180", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Nov-2016", "title": "Image Based Appraisal of Real Estate Properties", "abstract": "Real stock appraisal, originally is early bring for calculates be price in difference estate options, an crucial work both buys and shoppers as the issues instead negotiation and financing. Traditionally, the avoided sales uses be been moreover decree to reports knowing estate expectations. However, it terms the devised though precise mainly only facility economic related cpi, result true flawed take estimate accurately. Today, real rent citigroup offered but commercial to detailed online information off but estate purchasing allow their banks. We are 've city predictions a too purchased decline already done handful billions it themselves offline monitoring. In result, we analyze the probability maintain \u2014 forums house pictures, which referred set of the significant factors did videos download to make a potential visiting could. The development of consumer using its algorithms if several focus of features content possible. In important without, we employ whose Recurrent Neural Network (RNN) to forecasts still wealth options or the southern - of - the - examples vivid characters. The classical disappointing indicate that bringing feature outperforms having well make where - of - the - fashion 220-yard algorithms started both for such mean symbol mistake (MAE) on what absolute increases error (MAPE ).", "histories": [["v1", "Mon, 28 Nov 2016 15:23:14 GMT  (4384kb,D)", "http://arxiv.org/abs/1611.09180v1", "8 pages, 8 figures"], ["v2", "Thu, 27 Jul 2017 19:18:27 GMT  (6483kb,D)", "http://arxiv.org/abs/1611.09180v2", "8 pages, 8 figures"]], "COMMENTS": "8 pages, 8 figures", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["quanzeng you", "ran pang", "liangliang cao", "jiebo luo"], "accepted": false, "id": "1611.09180"}, "pdf": {"name": "1611.09180.pdf", "metadata": {"source": "CRF", "title": "Image Based Appraisal of Real Estate Properties", "authors": ["Quanzeng You", "Ran Pang"], "emails": ["jluo@cs.rochester.edu}."], "sections": [{"heading": null, "text": "Index Terms\u2014visual content analysis,real estate,deep neural networks\nI. INTRODUCTION\nREal estate appraisal, which is the process of estimatingthe price for real estate properties, is crucial for both buys and sellers as the basis for negotiation and transaction. Real estate plays a vital role in all aspects of our contemporary society. In a report published by the European Public Real Estate Association (EPRA http://alturl.com/7snxx), it was shown that real estate in all its forms accounts for nearly 20% of the economic activity. Therefore, accurate prediction of real estate prices or the trends of real estate prices help governments and companies make informed decisions. On the other hand, for most of the working class, housing has been one of the largest expenses. A right decision on a house, which heavily depends on their judgement on the value of the property, can possibly help them save money or even make profits from their investment in their homes. From this perspective, real estate appraisal is also closely related to people\u2019s lives.\nCurrent research from both estate industry and academia has reached the conclusion that real estate value is closely related to property infrastructure [1], traffic [2], online user reviews [3] and so on. Generally speaking, there are several different types of appraisal values. In particular, we are interested in the market value, which refers to the trade price in a competitive Walrasian auction setting [4]. Today, people are likely to trade through real estate brokers, who provide easy access online websites for browsing real estate property in an interactive and convenient way. Fig. 1 shows an example\nQ. You, R. Pang and J. Luo are with the Department of Computer Science, University of Rochester, Rochester, NY, 14637. E-mails: {qyou, rpang3, jluo@cs.rochester.edu}.\nBasic Property Detailed Information\nImages\nFig. 1. Example of homes for sale from Realtor.\nof house listing from Realtor (http://www.realtor.com/), which is the largest real estate broker in North America. From the figure, we see that a typical piece of listing on a real estate property will introduce the infrastructure data in text for the house along with some pictures of the house. Typically, a buyer will look at those pictures to obtain a general idea of the overall property in a selected area before making his next move.\nTraditionally, both real estate industry professionals and researchers have relied on a number of factors, such as economic index, house age, history trade and neighborhood environment and so on to estimate the price. Indeed, these factors have been proved to be related to the house price, which is quite difficult to estimate and sensitive to many different human activities. Therefore, researchers have devoted much effort in building a robust house price index [5], [6], [7], [8]. In addition, quantitative features including Area, Year, Storeys, Rooms and Centre [9], [10] are also employed to build neural network models for estimating house prices. However, pictures, which is probably the most important factor on a buyer\u2019s initial decision making process, have been ignored in this process. This is partially due to the fact that visual content is very difficult to interpret or quantify by computers compared with human beings.\nA picture is worth a thousand words. One advantage with images and videos is that they act like universal languages. People with different backgrounds can easily understand the main content of an image or video. In the real estate industry, pictures can easily tell people exactly how the house looks like,\nar X\niv :1\n61 1.\n09 18\n0v 1\n[ cs\n.C V\n] 2\n8 N\nov 2\n01 6\n2 which is impossible to be described in many ways using language. For the given house pictures, people can easily have an overall feeling of the house, e.g. what is the overall construction style, how the neighboring environment looks like. These high-level attributes are difficult to be quantitatively described. On the other hand, today\u2019s computational infrastructure is also much cheaper and more powerful to make the analysis of computationally intensive visual content analysis feasible. Indeed, there are existing works on focusing the analysis of visual content for tasks such as prediction [11], [12], and online user profiling [13]. Due to the recently developed deep learning, computers have become smart enough to interpret visual content in a way similar to human beings.\nRecently, deep learning has enabled robust and accurate feature learning, which in turn produces the state-of-the-art performance on many computer vision related tasks, e.g. digit recognition [14], [15], image classification [16], [17], aesthetics estimation [18] and scene recognition [19]. These systems suggest that deep learning is very effective in learning robust features in a supervised or unsupervised fashion. Even though deep neural networks may be trapped in local optima [20], [21], using different optimization techniques, one can achieve the state-of-the-art performance on many challenging tasks mentioned above.\nInspired by the recent successes of deep learning, in this work we are interested in solving the challenging real estate appraisal problem using deep visual features. In particular, for images related tasks, Convolutional Neural Network (CNN) are widely used due to the usage of convolutional layers. It takes into consideration the locations and neighbors of image pixels, which are important to capture useful features for visual tasks. Convolutional Neural Networks [22], [16], [17] have been proved very powerful in solving computer vision related tasks.\nWe intend to employ the pictures for the task of real estate price estimation. We want to know whether visual features, which is a reflection of a real estate property, can help estimate the real estate price. Intuitively, if visual features can characterize a property in a way similar to human beings, we should be able to quantify the house features using those visual responses. Meanwhile, real estate properties are closely related to the neighborhood. In this work, we develop algorithms which only rely on 1) the neighbor information and 2) the attributes from pictures to estimate real estate property price.\nTo preserve the local relation among properties we employ a novel approach, which employs random walks to generate house sequences. In building the random walk graph, only the locations of houses are utilized. In this way, the problem of real estate appraisal has been transformed into a sequence learning problem. Recurrent Neural Network (RNN) is particularly designed to solve sequence related problems. Recently, RNNs have been successfully applied to challenging tasks including machine translation [23], image captioning [24], and speech recognition [25]. Inspired by the success of RNN, we deploy RNN to learn regression models on the transformed problem.\nThe main contributions of our work are as follows: \u2022 To the best of our knowledge, we are the first to quantify\nthe impact of visual content on real estate price esti-\nmation. We attribute the possibility of our work to the newly designed computer vision algorithms, in particular Convolutional Neural Networks (CNNs). \u2022 We employ random walks to generate house sequences according to the locations of each house. In this way, we are able to transform the problem into a novel sequence prediction problem, which is able to preserve the relation among houses. \u2022 We employ the novel Recurrent Neural Networks (RNNs) to predict real estate properties and achieve accurate results."}, {"heading": "II. RELATED WORK", "text": "Real estate appraisal has been studied by both real estate industrial professionals and academia researchers. Earlier work focused on building price indexes for real properties. The seminal work in [5] built price index according to the repeat prices of the same property at different times. They employed regression analysis to build the price index, which shows good performances. Another widely used regression model, Hedonic regression, is developed on the assumption that the characteristics of a house can predict its price [6], [7]. However, it is argued that the Hedonic regression model requires more assumptions in terms of explaining its target [26]. They also mentioned that for repeat sales model, the main problem is lack of data, which may lead to failure of the model. Recent work in [8] employed locations and sale price series to build an autoregressive component. Their model is able to use both single sale homes and repeat sales homes, which can offer a more robust sale price index.\nMore studies are conducted on employing feed forward neural networks for real estate appraisal [27], [28], [29], [30]. However, their results suggest that neural network models are instable even using the same package with different run times [27]. The performance of neural networks are closely related to the features and data size [30]. Recently, Kontrimas and Verikas [31] empirically studied several different models on selected 12 dimensional features, e.g. type of the house, size, and construction year. Their results show that linear regression outperforms neural network on their selected 100 houses.\nMore recent studies in [1] propose a ranking objective, which takes geographical individual, peer and zone dependencies into consideration. Their method is able to use various estate related data, which helps improve their ranking results based on properties\u2019 investment values. Furthermore, the work in [3] studied online user\u2019s reviews and mobile users\u2019 moving behaviors on the problem of real estate ranking. Their proposed sparsity regularized learning model demonstrated competitive performance.\nIn contrast, we are trying to solve this problem using the attributes reflected in the visual appearances of houses. In particular, our model does not use the meta data of a house (e.g. size, number of rooms, and construction year). We intend to utilize the location information in a novel way such that our model is able to use the state-of-the-art deep learning for feature extraction (Convolutional Neural Network) and model learning (Recurrent Neural Network).\n3"}, {"heading": "III. RECURRENT NEURAL NETWORK FOR REAL ESTATE PRICE ESTIMATION", "text": "In this section, we present the main components of our framework. We describe how to transform the problem into a problem that can be solved by the Recurrent Neural Network. The architecture of our model is also presented."}, {"heading": "A. Random Walks", "text": "One main feature of real estate properties is its location. In particular, for houses in the same neighborhood, they tend to have similar extrinsic features including traffic, schools and so on. We build an undirected graph G for all the houses collected, where each node vi represent the i-th house in our data set. The similarity sij between house hi and house hj is defined using the Gaussian kernel function, which is a widely used similarity measure1:\nsij = exp\n( dist(hi, hj)\n2\u03c32\n) , (1)\nwhere dist(hi, hj) is the geodesic distance between house hi and hj . \u03c3 is the hyper-parameter, which controls the similarity decaying velocity with the increase of distance. In all of our experiments, we set \u03c3 to 0.5 miles so that houses within the 1.5 (within 3\u03c3) miles will have a relatively larger similarity. The -neighborhood graph [32] is employed to build G in our implementation. We assign the weight of each edge eij as the similarity sij between house hi and the house hj .\nGiven this graph G, we can then employ random walks to generate sequences. In particular, every time, we randomly choose one node vi as the root node, then we proportionally jump to its neighboring nodes vj according to the weights between vi and its neighbors. The probability of jumping to node vj is defined as\npj = eji\u2211\nk\u2208N(i) eki , (2)\nwhere N(i) is the set of neighbor nodes of vi. We continue to employ this process until we generate the desired length of sequence. The employment of random walks is mainly motivated by the recent proposed DeepWalk [33] to learn feature representations for graph nodes. It has been shown that random walks can capture the local structure of the graphs. In this way, we can keep the local location structure of houses and build sequences for houses in the graph. Algorithm 1 summarizes the detailed steps for generating sequences from a similarity graph.\nWe have generated sequences by employing random walks. In each sequence, we have a number of houses, which is related in terms of their locations. Since we build the graph on top of house locations, the houses within the same sequence are highly possible to be close to each other. In other words, the prices of houses in the same sequence are related to each other. We can employ this context for estimating real estate property price, which can be solved by recurrent neural network discussed in following sections.\n1http://en.wikipedia.org/wiki/Radial basis function kernel"}, {"heading": "B. Recurrent Neural Network", "text": "With a Recurrent Neural Network (RNN), we are trying to predict the output sequence {y1, y2, . . . , yT } given the input sequence {x1, x2, . . . , xT }. Between the input layer and the output layer, there is a hidden layer, which is usually estimated as in Eq.(3).\nht = \u2206(W i hht\u22121 +Wxxt + bh) (3)\n\u2206 represents some selected activation function or other complex architecture employed to process the input xt and ht. One of the most widely deployed architectures is Long ShortTerm Memory (LSTM) cell [34], which can overcome the vanishing and exploding gradient problem [35] when training RNN with gradient descent. Fig. 2 shows the details of a single Long Short-Term Memory (LSTM) block [36]. Each LSTM cell contains an input gate, an output gate and an forget gate, which is also called a memory cell in that it is able to remember the error in the error propagation stage [37]. In this way, LSTM is capable of modeling long-range dependencies than conventional RNNs.\nFor completeness, we give the detailed calculation of ht given input xt and ht\u22121 in the following equations. Let W i. , W f . , W o . represent the parameters related to input, forget and output gate respectively. denotes the elementwise multiplication between two vectors. \u03c6 and \u03c8 are some selected activation functions and \u03c3 is the fixed logistic sigmoid function. Following [36], [25], [38], we employ tanh for both \u03c6 in Eq.(6) and \u03c8 in Eq.(8).\nit = \u03c3(W i xxt +W i hht\u22121 +W i cct\u22121 + bi) (4) ft = \u03c3(W f x xt +W f h ht\u22121 +W f c ct\u22121 + bf ) (5) ct = ft ct\u22121 + it \u03c6(W cxxt +W chht\u22121 + bc) (6) ot = \u03c3(W o xxt +W o hht\u22121 +W o c ct + bo) (7)\nht = ot \u03c8(ct) (8)"}, {"heading": "C. Multi-layer Bidirectional LSTM", "text": "In previous sections, we have discussed the generation of sequences as well as Recurrent Neural Network. Recall that we have built an undirected graph in generating the sequences, which indicates that the price of one house is related to all\n4  \n \n1b th 1 1 bh 11 b th \n1b Th\n1 1 fh 11 f th \n1f Th\n1x tx 1tx TxInput Layer\n1st Forward Layer\n1st Backward Layer\nOutput Layer\n1f th\n1y ty 1ty Ty\n 21fh 21fth  2f Th 2f th\n 2bth21bh 21bth  2bTh\n2nd Forward Layer\n2nd Backward Layer\n1 1 b th \n1tx\n1 1 f th \nty\n2 1 f th \n2 1 b th \nFig. 3. The Multi-layer Bidirectional Recurrent Neural Network (BRNN) architecture for real estate price estimation. There are two bidirectional recurrent layers in this architecture. For real estate price estimation, the price of each house is related to all houses in the same sequence, which is the main motivation to employ bidirectional recurrent layers.\nthe houses in the same sequence including those in the later part. Bidirectional Recurrent Neural Network (BRNN) [39] has been proposed to enable the usage of both earlier and future contexts. In bidirectional recurrent neural network, there is an additional backward hidden layer iterating from the last of the sequence to the first. The output layer is calculated by employing both forward and backward hidden layer.\nBidirectional-LSTM (B-LSTM) is a particular type of BRNN, where each hidden node is calculated by the long short-term memory as shown in Fig. 2. Graves et al. [38] have employed Bidirectional-LSTM for speech recognition. Fig. 3 shows the architecture of the bidirectional recurrent neural network. We have two Bidirectional-LSTM layers. During the forward pass of the network, we calculate the response of both the forward and the backward hidden layers in the 1st-LSTM and 2nd-LSTM layer respectively. Next, the output (in our problem, the output is the price of each house) of each house is calculated using the output of the 2nd-LSTM layer as input to the output layer.\nThe objective function for training the Multi-Layer Bidirectional LSTM is defined as follows:\nL = 1\nN N\u2211 n=1 \u2211 j \u2016 y\u0302ij \u2212 yij \u20162 (9)\nwhere W is the the set of all the weights between different layers.yij is the actual trade price for the j-th house in the generated i-th sequence and y\u0302ij is the corresponding estimated price for this house.\nWhen training our Multi-Layer B-LSTM model, we employ the RMSProp [40] optimizer, which is an adaptive method for automatically adjust the learning rates. In particular, it normalizes the gradients by the average of its recent magnitude.\nWe conduct the back propagation in a mini-batch approach. Algorithm 2 summarizes the main steps for our proposed algorithm.\nAlgorithm 1 RandomWalks Input: H = {h1, h2, . . . , hn} geo-coordinates of n houses\n\u03c3 hyper-parameter for Gaussian Kernel t threshold for distance M total number of desired sequences\n1: Calculate the Vincenty distance between any pair of houses 2: Calculate the similarity between houses according to the Gaussian kernel function (see Eq.(1)). 3: repeat 4: Initialize sc = {} 5: Randomly pick one node hi and add hi to sc 6: set hc = hi 7: while size(sc) < L do 8: Pick hc\u2019s neighbor node hj with probability pj defined in Eq.(2) 9: add hj to sc\n10: set hc = hj 11: end whileadd sc to S 12: until size (S) = M 13: return The set of sequence S\nAlgorithm 2 Training Multi-Layer B-LSTM Input: H = {h1, h2, . . . , hn} geo-coordinates of n houses\nX = {x1, x2, . . . , xn} features of the n house Y = {y1, y2, . . . , yn} prices of the n houses\n1: S = RandomWalks (see Algorithm 1) 2: Split S into mini-batches 3: repeat 4: Calculate the gradient of L in Eq.(9) and update the parameters using RMSProp. 5: until Convergence 6: return The learned model M\n5"}, {"heading": "D. Prediction", "text": "In the prediction stage, the first step is also generating sequence. For each testing house, we add it as a new node into our previously build similarity graph on the training data. Each testing house is a new node in the graph. Next, we add edges to the testing nodes and the training nodes. We use the same settings when adding edges to the new -neighborhood graph. Given the new graph G\u2032, we randomly generate sequences and keep those sequences that contain one and only one testing node. In this way, for each house, we are able to generate many different sequences that contain this house. Fig. 4 shows the idea. Each testing sequence only has one testing house. The remaining nodes in the sequence are the known training houses.\na) Average: The above strategy implies that we are able to build many different sequences for each testing house. To obtain the final prediction price for each testing house, one simple strategy is to average the prediction results from different sequences and report the average price as the final prediction price."}, {"heading": "IV. EXPERIMENTAL RESULTS", "text": "In this section, we discuss how to collect data and evaluate the proposed framework as well as several state-of-the-art approaches. In this work, all the data are collected from Realtor (http://www.realtor.com/), which is the largest realtor association in North America. We collect data from San Jose, CA, one of the most active cities in U.S., and Rochester, NY, one of the least active cities in U.S., over a period of one year. In the next section, we will discuss the details on how to preprocess the data for further experiments."}, {"heading": "A. Data Preparation", "text": "The data collected from Realtor contains description, school information and possible pictures about each real property as shown in Fig. 1 show. We are particularly interested in employing the pictures of each house to conduct the price estimation. We filter out those houses without image in our data set. Since houses located in the same neighborhood seem to have similar price, the location is another important features in our data set. However, after an inspection of the data, we notice that some of the house price are abnormal. Thus, we preprocess the data by filtering out houses with extremely high or low price compared with their neighborhood.\nTABLE I shows the overall statistics of our dataset after filtering. Overall, the city of San Jose has more houses than\nRochester on the market (as expected for one of the hottest market in the country). The house prices in the two cities also have significant differences. Fig. 5 shows some of the example house pictures from the two cities, respectively. From these pictures, we observe that houses whose prices are above average typically have larger yards and better curb appeal, and vice versa. The same can be observed among house interior pictures (examples not shown due to space).\nRealtor does not provide the exact geo-location for each house. However, geo-location is important for us to build the -neighborhood graph for random walks. We employ Microsoft Bing Map API (https://msdn.microsoft.com/en-us/ library/ff701715.aspx) to obtain the latitude and longitude for each house given its collected address. Fig. 6 shows some of the houses in our collected data from San Jose and Rochester using the returned geo-locations from Bing Map API.\nAccording to these coordinates, we are able to calculate the distance between any pair of houses. In particular, we employ Vincenty distance (https://en.wikipedia.org/wiki/Vincenty\u2019s formulae) to calculate the geodesic distances according to the coordinates. Fig. 7 shows distribution of the distance between\n6 (a) Rochester (b) San Jose\nFig. 5. Examples of house pictures of the two cities respectively. Top Row: houses whose prices (per Sqft) are above the average of their neighborhood. Bottom Row: houses whose prices (per Sqft) are below the average of their neighborhood.\nany pair of houses in our data set. The distance is less than 4 miles for most randomly picked pair of houses. In building our -neighborhood graph, we assign an edge between any pair of houses, which has a distance smaller than 5 miles ( = 5 miles)."}, {"heading": "B. Feature Extraction and Baseline Algorithms", "text": "Recently, Convolutional Neural Networks (CNN) have achieved state-of-the-art performance on a wide range of vision tasks [17], [41]. Indeed, features based on pre-trained deep CNN models have been applied to other vision tasks, including recognizing image style [42] and semantic segmentation [43]. In our implementation, we experimented with GoogleNet model [41], which is one of the state-of-the-art deep neural architectures. In particular, we use the response from the last avg \u2212 pooling layer as the visual features for each image. In this way, we obtain a 1, 024 dimensional feature vector for each image. Each house may have several different pictures on different angles of the same property. We average features of all the images of the same house (also known as average-pooling) to obtain the feature representation of the house.\nWe compare the proposed framework with the following algorithms.\n1) Regression Model (LASSO): Regression model has been employed to analyze real estate price index [5]. Recently, the\nresults in Fu et al. [3] show that sparse regularization can obtain better performance in real estate ranking. Thus, we choose to use LASSO (http://statweb.stanford.edu/\u223ctibs/lasso.html), which is a l1-constrained regression model, as one of our baseline algorithms.\n2) DeepWalk: Deepwalk [33] is another way of employing random walks for unsupervised feature learning of graphs. The main approach is inspired by distributed word representation learning. In using DeepWalk, we also use -neighborhood graph with the same settings with the graph we built for generating sequences for B-LSTM. The learned features are also fed into a LASSO model for learning the regression weights. Indeed, deepwalk can be thought as a simpler version of our algorithm, where only the graph structure are employed to learn features. Our framework can employ both the graph structure and other features, i.e. visual attributes, for building regression model."}, {"heading": "C. Training a Multi-layer B-LSTM Model", "text": "With the above mentioned similarity graph, we are able to generate sequences using random walks following the steps described in Algorithm 1. For each city, we randomly split the houses into training (80%) and testing set (20%). Next, we generate sequences using random walks on the training houses only to build our training sequences for Multi-layer B-LSTM.\nFor both cities, we build 200, 000 sequences for training, with a length of 10. Similarly, we also generate testing sequences, where each sequence contain one and only one testing house (see Fig. 4). On the average, we randomly generate 100 sequences for each testing house. The B-LSTM model is trained with a batch size of 1024. In our experimental settings, we set the size of the first hidden layer to be 400 and the size of the second hidden layer to be 200.\nThe evaluation metrics employed are mean absolute error (MAE) and mean absolute percentage error (MAPE). Both of them are popular measures for evaluating the accuracy of prediction models. Eq.(10) and Eq.(11) give the definitions for these two metrics, where pi is the predicted value and ti is\n7\nthe true value for the i-th instance.\nMAE = 1\nN N\u2211 i=1 |ti \u2212 pi| (10)\nMAPE = 1\nN N\u2211 i=1 | ti \u2212 pi ti | (11)\nWe use the same training and testing split to evaluate all the approaches. TABLE II shows the regression results for all the different approaches in the two selected cities. For each testing house, we generate about 100 sequences. In TABLE II, we report both the best and the average price of the predicted price. The best is the price, which is closest to the true price among all the available sequences for each house. Overall, our B-LSTM model outperforms other two baseline algorithms in both cities. All of the evaluation approaches perform better in San Jose than in Rochester in terms of MAPE. This is possible due to the availability of more training data in the city of San Jose. DeepWalk shows slightly better performance than LASSO, which suggests that location is relatively more important than the visual features in the realtor business. This is expected"}, {"heading": "D. Confidence Level", "text": "For each testing house, the proposed model can give a group of predictions. We want to know whether or not the proposed model can distinguish the confidence level of its prediction. In particular, we group the testing houses evenly into three groups for each city. The first group has the smallest standard deviation of the prediction prices. The second group is the middle one and the last group is the one with the largest standard deviation.\nFig. 8 shows the MAE and MAPE for the different groups. The results show that standard deviation can be viewed as a rough measure of the confidence level of the proposed model on the current testing house. Small standard deviation tends to indicate a high confidence of the model and overall it also suggests a smaller prediction error."}, {"heading": "V. CONCLUSION", "text": "In this work, we propose a novel framework for real estate appraisal. In particular, the proposed framework is able to take both the location and the visual attributes into consideration. The evaluation of the proposed model on two selected cities suggests the effectiveness and flexibility of the model. Indeed, our work has also offered new approaches of applying deep neural networks on graph structured data. We hope our model can not only give insights on real estate appraisal, but also can inspire others on employing deep neural networks on graph structured data."}], "references": [{"title": "Exploiting geographic dependencies for real estate appraisal: a mutual perspective of ranking and clustering", "author": ["Y. Fu", "H. Xiong", "Y. Ge", "Z. Yao", "Y. Zheng", "Z.-H. Zhou"], "venue": "SIGKDD. ACM, 2014, pp. 1047\u20131056.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "Public transits impact on housing costs: a review of the literature", "author": ["K. Wardrip"], "venue": "2011.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "Sparse real estate ranking with online user reviews and offline moving behaviors", "author": ["Y. Fu", "Y. Ge", "Y. Zheng", "Z. Yao", "Y. Liu", "H. Xiong", "N. Yuan"], "venue": "p. 120129, 2014.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "On the dynamic behavior of prices in disequilibrium", "author": ["A. Beja", "M.B. Goldman"], "venue": "The Journal of Finance, vol. 35, no. 2, pp. 235\u2013248, 1980.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1980}, {"title": "A regression method for real estate price index construction", "author": ["M.J. Bailey", "R.F. Muth", "H.O. Nourse"], "venue": "Journal of the American Statistical Association, vol. 58, no. 304, pp. 933\u2013942, 1963.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1963}, {"title": "Nonparametric estimation of dynamic hedonic price models and the construction of residential housing price indices", "author": ["R. Meese", "N. Wallace"], "venue": "Real Estate Economics, vol. 19, no. 3, pp. 308\u2013332, 1991.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1991}, {"title": "Hedonic analysis of housing markets", "author": ["S. Sheppard"], "venue": "Handbook of regional and urban economics, vol. 3, pp. 1595\u20131635, 1999.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1999}, {"title": "An autoregressive approach to house price modeling", "author": ["C.H. Nagaraja", "L.D. Brown", "L.H. Zhao"], "venue": "The Annals of Applied Statistics, vol. 5, no. 1, pp. 124\u2013149, 2011.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Empirical comparison of resampling methods using genetic fuzzy systems for a regression problem", "author": ["T. Lasota", "Z. Telec", "G. Trawi\u0144ski", "B. Trawi\u0144ski"], "venue": "Intelligent Data Engineering and Automated Learning- IDEAL 2011. Springer, 2011, pp. 17\u201324.  8", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Investigation of bagging ensembles of genetic neural networks and fuzzy systems for real estate appraisal", "author": ["O. Kempa", "T. Lasota", "Z. Telec", "B. Trawi\u0144ski"], "venue": "Intelligent Information and Database Systems. Springer, 2011, pp. 323\u2013332.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "The wisdom of social multimedia: using flickr for prediction and forecast", "author": ["X. Jin", "A. Gallagher", "L. Cao", "J. Luo", "J. Han"], "venue": "Proceedings of the international conference on Multimedia. ACM, 2010, pp. 1235\u2013 1244.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "A multifaceted approach to social multimedia-based prediction of elections", "author": ["Q. You", "L. Cao", "Y. Cong", "X. Zhang", "J. Luo"], "venue": "Multimedia, IEEE Transactions on, vol. 17, no. 12, pp. 2271\u20132280, Dec 2015.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "A picture tells a thousand wordsabout you! user interest profiling from user generated visual content", "author": ["Q. You", "S. Bhatia", "J. Luo"], "venue": "Signal Processing, pp. \u2013, 2015. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S0165168415003758", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Backpropagation applied to handwritten zip code recognition", "author": ["Y. LeCun", "B. Boser", "J.S. Denker", "D. Henderson", "R.E. Howard", "W. Hubbard", "L.D. Jackel"], "venue": "Neural computation, vol. 1, no. 4, pp. 541\u2013551, 1989.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1989}, {"title": "A fast learning algorithm for deep belief nets", "author": ["G.E. Hinton", "S. Osindero", "Y.-W. Teh"], "venue": "Neural computation, vol. 18, no. 7, pp. 1527\u20131554, 2006.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "Flexible, high performance convolutional neural networks for image classification", "author": ["D.C. Cire\u015fan", "U. Meier", "J. Masci", "L.M. Gambardella", "J. Schmidhuber"], "venue": "IJCAI. AAAI Press, 2011, pp. 1237\u20131242.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Imagenet classification with deep convolutional neural networks.", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "in NIPS,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "Rapid: Rating pictorial aesthetics using deep learning", "author": ["X. Lu", "Z. Lin", "H. Jin", "J. Yang", "J.Z. Wang"], "venue": "ACM MM. ACM, 2014, pp. 457\u2013466.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning deep features for scene recognition using places database", "author": ["B. Zhou", "A. Lapedriza", "J. Xiao", "A. Torralba", "A. Oliva"], "venue": "NIPS, 2014, pp. 487\u2013495.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "A practical guide to training restricted boltzmann machines", "author": ["G. Hinton"], "venue": "Momentum, vol. 9, no. 1, p. 926, 2010.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "Practical recommendations for gradient-based training of deep architectures", "author": ["Y. Bengio"], "venue": "Neural Networks: Tricks of the Trade. Springer, 2012, pp. 437\u2013478.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2012}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE, vol. 86, no. 11, pp. 2278\u20132324, 1998.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1998}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["D. Bahdanau", "K. Cho", "Y. Bengio"], "venue": "ICLR, 2014.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "Show and tell: A neural image caption generator", "author": ["O. Vinyals", "A. Toshev", "S. Bengio", "D. Erhan"], "venue": "CVPR, 2015, pp. 3156\u20133164.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "Speech recognition with deep recurrent neural networks", "author": ["A. Graves", "A.-r. Mohamed", "G. Hinton"], "venue": "ICASSP. IEEE, 2013, pp. 6645\u2013 6649.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2013}, {"title": "Estimating house price growth with repeat sales data: what\u2019s the aim of the game?", "author": ["F.T. Wang", "P.M. Zorn"], "venue": "Journal of Housing Economics,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1997}, {"title": "An exploration of neural networks and its application to real estate valuation", "author": ["E. Worzala", "M. Lenk", "A. Silva"], "venue": "Journal of Real Estate Research, vol. 10, no. 2, pp. 185\u2013201, 1995.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1995}, {"title": "Improving the results of artificial neural network models for residential valuation", "author": ["P. Rossini"], "venue": "Fourth Annual Pacific-Rim Real Estate Society Conference, Perth, Western Australia, 1998.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1998}, {"title": "Using neural networks to estimate constant quality house price indices", "author": ["P. Kershaw", "P. Rossini"], "venue": "Ph.D. dissertation, INTERNATIONAL REAL ESTATE SOCIETY, 1999.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1999}, {"title": "Predicting housing value: A comparison of multiple regression analysis and artificial neural networks", "author": ["N. Nghiep", "C. Al"], "venue": "Journal of Real Estate Research, vol. 22, no. 3, pp. 313\u2013336, 2001.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2001}, {"title": "The mass appraisal of the real estate by computational intelligence", "author": ["V. Kontrimas", "A. Verikas"], "venue": "Applied Soft Computing, vol. 11, no. 1, pp. 443\u2013448, 2011.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2011}, {"title": "A tutorial on spectral clustering", "author": ["U. Von Luxburg"], "venue": "Statistics and computing, vol. 17, no. 4, pp. 395\u2013416, 2007.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2007}, {"title": "Deepwalk: Online learning of social representations", "author": ["B. Perozzi", "R. Al-Rfou", "S. Skiena"], "venue": "SIGKDD. ACM, 2014, pp. 701\u2013710.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2014}, {"title": "Long short-term memory in recurrent neural networks", "author": ["F. Gers"], "venue": "Unpublished PhD dissertation, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Lausanne, Switzerland, 2001.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2001}, {"title": "On the difficulty of training recurrent neural networks", "author": ["R. Pascanu", "T. Mikolov", "Y. Bengio"], "venue": "ICML, 2013, pp. 1310\u20131318.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning precise timing with lstm recurrent networks", "author": ["F.A. Gers", "N.N. Schraudolph", "J. Schmidhuber"], "venue": "The Journal of Machine Learning Research, vol. 3, pp. 115\u2013143, 2003.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2003}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation, vol. 9, no. 8, pp. 1735\u20131780, 1997.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 1997}, {"title": "Hybrid speech recognition with deep bidirectional lstm", "author": ["A. Graves", "N. Jaitly", "A.-R. Mohamed"], "venue": "Workshop on Automatic Speech Recognition and Understanding (ASRU). IEEE, 2013, pp. 273\u2013278.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2013}, {"title": "Bidirectional recurrent neural networks", "author": ["M. Schuster", "K.K. Paliwal"], "venue": "Signal Processing, IEEE Transactions on, vol. 45, no. 11, pp. 2673\u20132681, 1997.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 1997}, {"title": "Lecture 6.5 - rmsprop, coursera: Neural networks for machine learning", "author": ["T. Tieleman", "G. Hinton"], "venue": "University of Toronto, Tech. Rep., 2012.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2012}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "CVPR, June 2015.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2015}, {"title": "Recognizing image style", "author": ["S. Karayev", "M. Trentacoste", "H. Han", "A. Agarwala", "T. Darrell", "A. Hertzmann", "H. Winnemoeller"], "venue": "arXiv preprint arXiv:1311.3715, 2013.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2013}, {"title": "Fully convolutional networks for semantic segmentation", "author": ["J. Long", "E. Shelhamer", "T. Darrell"], "venue": "arXiv preprint arXiv:1411.4038, 2014.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "Current research from both estate industry and academia has reached the conclusion that real estate value is closely related to property infrastructure [1], traffic [2], online user reviews [3] and so on.", "startOffset": 152, "endOffset": 155}, {"referenceID": 1, "context": "Current research from both estate industry and academia has reached the conclusion that real estate value is closely related to property infrastructure [1], traffic [2], online user reviews [3] and so on.", "startOffset": 165, "endOffset": 168}, {"referenceID": 2, "context": "Current research from both estate industry and academia has reached the conclusion that real estate value is closely related to property infrastructure [1], traffic [2], online user reviews [3] and so on.", "startOffset": 190, "endOffset": 193}, {"referenceID": 3, "context": "In particular, we are interested in the market value, which refers to the trade price in a competitive Walrasian auction setting [4].", "startOffset": 129, "endOffset": 132}, {"referenceID": 4, "context": "Therefore, researchers have devoted much effort in building a robust house price index [5], [6], [7], [8].", "startOffset": 87, "endOffset": 90}, {"referenceID": 5, "context": "Therefore, researchers have devoted much effort in building a robust house price index [5], [6], [7], [8].", "startOffset": 92, "endOffset": 95}, {"referenceID": 6, "context": "Therefore, researchers have devoted much effort in building a robust house price index [5], [6], [7], [8].", "startOffset": 97, "endOffset": 100}, {"referenceID": 7, "context": "Therefore, researchers have devoted much effort in building a robust house price index [5], [6], [7], [8].", "startOffset": 102, "endOffset": 105}, {"referenceID": 8, "context": "In addition, quantitative features including Area, Year, Storeys, Rooms and Centre [9], [10] are also employed to build neural network models for estimating house prices.", "startOffset": 83, "endOffset": 86}, {"referenceID": 9, "context": "In addition, quantitative features including Area, Year, Storeys, Rooms and Centre [9], [10] are also employed to build neural network models for estimating house prices.", "startOffset": 88, "endOffset": 92}, {"referenceID": 10, "context": "Indeed, there are existing works on focusing the analysis of visual content for tasks such as prediction [11], [12], and online user profiling [13].", "startOffset": 105, "endOffset": 109}, {"referenceID": 11, "context": "Indeed, there are existing works on focusing the analysis of visual content for tasks such as prediction [11], [12], and online user profiling [13].", "startOffset": 111, "endOffset": 115}, {"referenceID": 12, "context": "Indeed, there are existing works on focusing the analysis of visual content for tasks such as prediction [11], [12], and online user profiling [13].", "startOffset": 143, "endOffset": 147}, {"referenceID": 13, "context": "digit recognition [14], [15], image classification [16], [17], aesthetics estimation [18] and scene recognition [19].", "startOffset": 18, "endOffset": 22}, {"referenceID": 14, "context": "digit recognition [14], [15], image classification [16], [17], aesthetics estimation [18] and scene recognition [19].", "startOffset": 24, "endOffset": 28}, {"referenceID": 15, "context": "digit recognition [14], [15], image classification [16], [17], aesthetics estimation [18] and scene recognition [19].", "startOffset": 51, "endOffset": 55}, {"referenceID": 16, "context": "digit recognition [14], [15], image classification [16], [17], aesthetics estimation [18] and scene recognition [19].", "startOffset": 57, "endOffset": 61}, {"referenceID": 17, "context": "digit recognition [14], [15], image classification [16], [17], aesthetics estimation [18] and scene recognition [19].", "startOffset": 85, "endOffset": 89}, {"referenceID": 18, "context": "digit recognition [14], [15], image classification [16], [17], aesthetics estimation [18] and scene recognition [19].", "startOffset": 112, "endOffset": 116}, {"referenceID": 19, "context": "Even though deep neural networks may be trapped in local optima [20], [21], using different optimization techniques, one can achieve the state-of-the-art performance on many challenging tasks mentioned above.", "startOffset": 64, "endOffset": 68}, {"referenceID": 20, "context": "Even though deep neural networks may be trapped in local optima [20], [21], using different optimization techniques, one can achieve the state-of-the-art performance on many challenging tasks mentioned above.", "startOffset": 70, "endOffset": 74}, {"referenceID": 21, "context": "Convolutional Neural Networks [22], [16], [17] have been proved very powerful in solving computer vision related tasks.", "startOffset": 30, "endOffset": 34}, {"referenceID": 15, "context": "Convolutional Neural Networks [22], [16], [17] have been proved very powerful in solving computer vision related tasks.", "startOffset": 36, "endOffset": 40}, {"referenceID": 16, "context": "Convolutional Neural Networks [22], [16], [17] have been proved very powerful in solving computer vision related tasks.", "startOffset": 42, "endOffset": 46}, {"referenceID": 22, "context": "Recently, RNNs have been successfully applied to challenging tasks including machine translation [23], image captioning [24], and speech recognition [25].", "startOffset": 97, "endOffset": 101}, {"referenceID": 23, "context": "Recently, RNNs have been successfully applied to challenging tasks including machine translation [23], image captioning [24], and speech recognition [25].", "startOffset": 120, "endOffset": 124}, {"referenceID": 24, "context": "Recently, RNNs have been successfully applied to challenging tasks including machine translation [23], image captioning [24], and speech recognition [25].", "startOffset": 149, "endOffset": 153}, {"referenceID": 4, "context": "The seminal work in [5] built price index according to the repeat prices of the same property at different times.", "startOffset": 20, "endOffset": 23}, {"referenceID": 5, "context": "Another widely used regression model, Hedonic regression, is developed on the assumption that the characteristics of a house can predict its price [6], [7].", "startOffset": 147, "endOffset": 150}, {"referenceID": 6, "context": "Another widely used regression model, Hedonic regression, is developed on the assumption that the characteristics of a house can predict its price [6], [7].", "startOffset": 152, "endOffset": 155}, {"referenceID": 25, "context": "However, it is argued that the Hedonic regression model requires more assumptions in terms of explaining its target [26].", "startOffset": 116, "endOffset": 120}, {"referenceID": 7, "context": "Recent work in [8] employed locations and sale price series to build an autoregressive component.", "startOffset": 15, "endOffset": 18}, {"referenceID": 26, "context": "More studies are conducted on employing feed forward neural networks for real estate appraisal [27], [28], [29], [30].", "startOffset": 95, "endOffset": 99}, {"referenceID": 27, "context": "More studies are conducted on employing feed forward neural networks for real estate appraisal [27], [28], [29], [30].", "startOffset": 101, "endOffset": 105}, {"referenceID": 28, "context": "More studies are conducted on employing feed forward neural networks for real estate appraisal [27], [28], [29], [30].", "startOffset": 107, "endOffset": 111}, {"referenceID": 29, "context": "More studies are conducted on employing feed forward neural networks for real estate appraisal [27], [28], [29], [30].", "startOffset": 113, "endOffset": 117}, {"referenceID": 26, "context": "However, their results suggest that neural network models are instable even using the same package with different run times [27].", "startOffset": 124, "endOffset": 128}, {"referenceID": 29, "context": "The performance of neural networks are closely related to the features and data size [30].", "startOffset": 85, "endOffset": 89}, {"referenceID": 30, "context": "Recently, Kontrimas and Verikas [31] empirically studied several different models on selected 12 dimensional features, e.", "startOffset": 32, "endOffset": 36}, {"referenceID": 0, "context": "More recent studies in [1] propose a ranking objective, which takes geographical individual, peer and zone dependencies into consideration.", "startOffset": 23, "endOffset": 26}, {"referenceID": 2, "context": "Furthermore, the work in [3] studied online user\u2019s reviews and mobile users\u2019 moving behaviors on the problem of real estate ranking.", "startOffset": 25, "endOffset": 28}, {"referenceID": 31, "context": "The -neighborhood graph [32] is employed to build G in our implementation.", "startOffset": 24, "endOffset": 28}, {"referenceID": 32, "context": "The employment of random walks is mainly motivated by the recent proposed DeepWalk [33] to learn feature representations for graph nodes.", "startOffset": 83, "endOffset": 87}, {"referenceID": 33, "context": "One of the most widely deployed architectures is Long ShortTerm Memory (LSTM) cell [34], which can overcome the vanishing and exploding gradient problem [35] when training RNN with gradient descent.", "startOffset": 83, "endOffset": 87}, {"referenceID": 34, "context": "One of the most widely deployed architectures is Long ShortTerm Memory (LSTM) cell [34], which can overcome the vanishing and exploding gradient problem [35] when training RNN with gradient descent.", "startOffset": 153, "endOffset": 157}, {"referenceID": 35, "context": "2 shows the details of a single Long Short-Term Memory (LSTM) block [36].", "startOffset": 68, "endOffset": 72}, {"referenceID": 36, "context": "Each LSTM cell contains an input gate, an output gate and an forget gate, which is also called a memory cell in that it is able to remember the error in the error propagation stage [37].", "startOffset": 181, "endOffset": 185}, {"referenceID": 35, "context": "Following [36], [25], [38], we employ tanh for both \u03c6 in Eq.", "startOffset": 10, "endOffset": 14}, {"referenceID": 24, "context": "Following [36], [25], [38], we employ tanh for both \u03c6 in Eq.", "startOffset": 16, "endOffset": 20}, {"referenceID": 37, "context": "Following [36], [25], [38], we employ tanh for both \u03c6 in Eq.", "startOffset": 22, "endOffset": 26}, {"referenceID": 38, "context": "Bidirectional Recurrent Neural Network (BRNN) [39] has been proposed to enable the usage of both earlier and future contexts.", "startOffset": 46, "endOffset": 50}, {"referenceID": 37, "context": "[38] have employed Bidirectional-LSTM for speech recognition.", "startOffset": 0, "endOffset": 4}, {"referenceID": 39, "context": "When training our Multi-Layer B-LSTM model, we employ the RMSProp [40] optimizer, which is an adaptive method for", "startOffset": 66, "endOffset": 70}, {"referenceID": 16, "context": "Recently, Convolutional Neural Networks (CNN) have achieved state-of-the-art performance on a wide range of vision tasks [17], [41].", "startOffset": 121, "endOffset": 125}, {"referenceID": 40, "context": "Recently, Convolutional Neural Networks (CNN) have achieved state-of-the-art performance on a wide range of vision tasks [17], [41].", "startOffset": 127, "endOffset": 131}, {"referenceID": 41, "context": "Indeed, features based on pre-trained deep CNN models have been applied to other vision tasks, including recognizing image style [42] and semantic segmentation [43].", "startOffset": 129, "endOffset": 133}, {"referenceID": 42, "context": "Indeed, features based on pre-trained deep CNN models have been applied to other vision tasks, including recognizing image style [42] and semantic segmentation [43].", "startOffset": 160, "endOffset": 164}, {"referenceID": 40, "context": "In our implementation, we experimented with GoogleNet model [41], which is one of the state-of-the-art deep neural architectures.", "startOffset": 60, "endOffset": 64}, {"referenceID": 4, "context": "1) Regression Model (LASSO): Regression model has been employed to analyze real estate price index [5].", "startOffset": 99, "endOffset": 102}, {"referenceID": 2, "context": "[3] show that sparse regularization can obtain better performance in real estate ranking.", "startOffset": 0, "endOffset": 3}, {"referenceID": 32, "context": "2) DeepWalk: Deepwalk [33] is another way of employing random walks for unsupervised feature learning of graphs.", "startOffset": 22, "endOffset": 26}], "year": 2016, "abstractText": "Real estate appraisal, which is the process of estimating the price for real estate properties, is crucial for both buys and sellers as the basis for negotiation and transaction. Traditionally, the repeat sales model has been widely adopted to estimate real estate price. However, it depends the design and calculation of a complex economic related index, which is challenging to estimate accurately. Today, real estate brokers provide easy access to detailed online information on real estate properties to their clients. We are interested in estimating the real estate price from these large amounts of easily accessed data. In particular, we analyze the prediction power of online house pictures, which is one of the key factors for online users to make a potential visiting decision. The development of robust computer vision algorithms makes the analysis of visual content possible. In this work, we employ a Recurrent Neural Network (RNN) to predict real estate price using the state-of-the-art visual features. The experimental results indicate that our model outperforms several of other state-of-the-art baseline algorithms in terms of both mean absolute error (MAE) and mean absolute percentage error (MAPE).", "creator": "LaTeX with hyperref package"}}}