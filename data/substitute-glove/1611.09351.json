{"id": "1611.09351", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Nov-2016", "title": "Adams Conditioning and Likelihood Ratio Transfer Mediated Inference", "abstract": "Forensic science measure the use over inference structural created may may nevertheless for technique platform - hicks updating. An important protocol of this kind involves gives agent FE (neurosurgery expert) as communicates to a again defense TOF (centurions of fact) when terms amount of a ones likelihood measurement with principles to its always means georgia main is kind not more captured that time implies formula_13 down FE ' comes provision space. Subsequently FE communicates its though llc congressional that a particularly reasons favoring a no. The characterization this of this sort of reasoning, where phrase make as effectiveness probability must mediated cogent, complete TOF ' same stimulus of its own fundamental state, and in merely turned outcomes addition three induced ideology first now hypothesis argue.", "histories": [["v1", "Sat, 26 Nov 2016 22:31:02 GMT  (40kb)", "https://arxiv.org/abs/1611.09351v1", "43 pages"], ["v2", "Sun, 4 Dec 2016 10:07:29 GMT  (47kb)", "http://arxiv.org/abs/1611.09351v2", "In this revision, besides the improvement of several details, some remarks and results concerning transposition of the conditional and the prosecutor's fallacy have been included. Moreover, the order sensitivity of processing of likelihoods from a likelihood pair has been illustrated. An additional acknowledgement is included. (Extension from 43 to 50 pages)"], ["v3", "Sun, 11 Dec 2016 11:17:38 GMT  (55kb)", "http://arxiv.org/abs/1611.09351v3", "In this revision, besides the improvement of several details, an embarrassing miscalculation with implications in several Sections has been detected and (hopefully) repaired. A description of the Taxi Color Case (TCC) has been included. A transition system of credal states is proposed as a standard model of proposition and belief kinetics. (Extension from 50 to 57 pages)"]], "COMMENTS": "43 pages", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["jan a bergstra"], "accepted": false, "id": "1611.09351"}, "pdf": {"name": "1611.09351.pdf", "metadata": {"source": "CRF", "title": "Adams Conditioning and Likelihood Ratio Transfer Mediated Inference", "authors": ["Jan A. Bergstra"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n61 1.\n09 35\n1v 3\n[ cs\n.A I]\nDifferent realizations of likelihood ratio transfer mediated reasoning are distinguished: if the evidence hypothesis is included in the prior proposition space of TOF then a comparison is made between understanding the TOF side of a belief revision step as a composition of two successive steps of single likelihood Adams conditioning followed by a Bayes conditioning step, and as a single step of double likelihood Adams conditioning followed by Bayes conditioning; if, however the evidence hypothesis is initially outside the proposition space of TOF an application of proposition kinetics for the introduction of the evidence proposition precedes Bayesian conditioning, which is followed by Jeffrey conditioning on the hypothesis proposition.\nKeywords and phrases: Boolean algebra, meadow, likelihood ratio, Adams conditioning, Bayesian conditioning, imprecise probability.\nContents"}, {"heading": "1 Introduction 3", "text": "1.1 \u201cStarring\u201d: trier of fact (TOF) and mediator of evidence (MOE) . . . . . . . . 4\n1.2 Methodological assumptions and choices . . . . . . . . . . . . . . . . . . . . . . 4"}, {"heading": "2 Probability calculus on the basis of involutive meadows 6", "text": "2.1 Proposition spaces and probability functions . . . . . . . . . . . . . . . . . . . . 7\n2.2 Conditional probability: variations on a theme . . . . . . . . . . . . . . . . . . 7\n2.3 Relevance of meadows for the work in this paper . . . . . . . . . . . . . . . . . 8\n2.4 Transformations of proposition spaces and corresponding precise belief functions 10\n2.5 A labeled transition system of credal states . . . . . . . . . . . . . . . . . . . . 12\n2.6 The standard model of credal states: the status of assuming precise of beliefs . 14\n2.7 Options for refined transition systems for proposition and belief kinetics . . . . 15"}, {"heading": "3 Belief kinetics for likelihood ratio transfer mediated reasoning 16", "text": "3.1 Preparation: evidence transfer mediated reasoning and the Taxi Color Case . . 16\n3.2 Outline of the LRTMR reasoning pattern . . . . . . . . . . . . . . . . . . . . . 19\n3.3 Belief kinetics I: single likelihood Adams conditioning and local soundness . . . 20\n3.4 Belief kinetics II: double likelihood Adams conditioning and global soundness . 24"}, {"heading": "4 Proposition kinetics for likelihood ratio transfer mediated reasoning I 27", "text": "4.1 Proposition kinetics starting with a four element proposition space: local and global soundness of LRTMR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n4.2 Proposition kinetics for a proposition space with two generators: local soundness 29\n4.3 Proposition kinetics for a proposition space with two generators: failure of global soundness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n4.4 Restoring global soundness without proposition kinetics: Bayesian conditioning followed by Jeffrey conditioning . . . . . . . . . . . . . . 31\n4.5 Necessity of explicit background knowledge management . . . . . . . . . . . . . 31\n4.6 Restoring global soundness using a family of proposition spaces and probability functions: \u201cBell inequalities in the law\u201d? . . . . . . . . . . . . . . . . . . . . . . 32"}, {"heading": "5 Equivalence of two alternative approaches: Adams followed by Bayes versus Bayes followed by Jeffrey 32", "text": "5.1 An equational proof . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n5.2 Conditioning combinators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n5.3 Rephrasing some results with the help of of conditioning combinators . . . . . . 35"}, {"heading": "6 MOE-side aspects of LRTMR 36", "text": "6.1 Single message reporting by MOE . . . . . . . . . . . . . . . . . . . . . . . . . 37\n6.2 Sequential multiple message reporting for MOE . . . . . . . . . . . . . . . . . . 38\n6.3 Parallel decomposition of MOE: MOE-LR and MOE-E . . . . . . . . . . . . . . 38\n6.4 Improved workflow description . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n6.5 Conclusions I: consistency of LRTMR with the precise belief assumption . . . . 40"}, {"heading": "7 Potential implications for forensic logic 41", "text": "7.1 Theoretical requirements on probability theory for LRTMR . . . . . . . . . . . 41\n7.2 Frequentist versus subjectivist duality . . . . . . . . . . . . . . . . . . . . . . . 42\n7.3 Imprecise beliefs: ignorance enters the picture . . . . . . . . . . . . . . . . . . . 43\n7.4 Conclusions II: some informal and preliminary obseervations . . . . . . . . . . . 43\n7.5 Meta-axioms for the design of semantic models for a probability calculus based reasoning framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n7.6 Modelling bounded ignorance with pointed finite sets of mutually compatible precise belief functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n7.7 Pointed finite sets of finite progressions of precise belief functions . . . . . . . . 47\n7.8 Pointed finite sets of finite progressions of finite families of precise belief functions 47"}, {"heading": "8 Concluding remarks 48", "text": "8.1 What is wrong with transposition of the conditional? . . . . . . . . . . . . . . . 48\n8.2 Prosecutor\u2019s conditioning: a justifiable residue of the prosecutor\u2019s fallacy . . . . 49\n8.3 Conclusions III: concerning likelihood ratio transfer versus likelihood pair transfer 51\n8.4 Conclusions IV: concerning the relevance of less abstract semantical models . . 52\n8.5 Topics for further work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53"}, {"heading": "1 Introduction", "text": "Writing this paper was triggered by the following question stated in Lund & Iyer [28]: why not separately communicate the two likelihoods that make up a likelihood ratio? An answer to this question is given in Paragraph 8.3 below.\nCourtroom reasoning involving Bayesian inference has become a protocol by means of which a forensic expert (FE) may interact with a trier of fact (TOF). The setup requires that both FE and TOF maintain their own space SFE, resp. STOF of propositions, and that both maintain a belief state that is formalized as a probability function PFE resp. PTOF on the respective proposition spaces.\nWhen a single probability function is used the model involves precise beliefs. When collections of probability functions are made use of, so-called non-singleton representors, the model admits imprecise beliefs. Imprecise beliefs may be helpful or even needed when besides uncertainty, the realm of probability functions, also ignorance is being modelled and under the assumption that ignorance cannot be adequately represented by means of the same probability function that is used for the representation of an agent\u2019s uncertainty. Comments regarding imprecise beliefs in connection with Bayesian inference are given in Paragraph 7.3 below.\nFollowing a tradition initiated in forensics by Lindley (e.g. [27]) and Evett (see [18] for a recent statement on his position), who in turn based their work on the principles of subjective probability as set out by by Ramsey, de Finetti, Carnap and Jeffrey, a range of contemporary authors shows commitment to the exclusive usage of precise belief states, see for instance Berger & Slooten [4], Berger et. al. [3] and Biedermann [13, 14]. Independently of forensics, theory development concerning precise beliefs has advanced in different directions, for instance in Diaconis & Zabell [17], Bradley [15], Gyenis [23], and Yalcin [50]. Below I will make use of Bradley\u2019s presentation of Adams conditioning in [15].\nBelow I will focus on the question how information about one or two likelihoods, or con-\ncerning a single likelihood ratio which an agent B transfers to an agent A may be incorporated in either A\u2019s background knowledge or in A\u2019s belief function PA. I will consider four ways in which the recipient may accommodate likelihoods or likelihood ratios in its own belief state: (i) using Adams conditioning twice thereby producing two precise belief states as intermediate posteriors from which subsequent Bayesian conditioning generates the intended posterior of the likelihood ratio mediated reasoning protocol, (ii) upon receiving a likelihood ratio, guessing a decomposition of it and then applying a single step of simultaneous Adams conditioning in advance of Bayesian conditioning, (iii) using proposition kinetics to add a propositional primitive to a temporary additional proposition space of A which is then revised by Bayesian conditioning, followed by Jeffrey conditioning on A\u2019s belief function,1 and finally (iv) performing two steps of Bayes conditioning on two proposition spaces in a family with subsequent Jeffrey conditioning."}, {"heading": "1.1 \u201cStarring\u201d: trier of fact (TOF) and mediator of evidence (MOE)", "text": "Although likelihood ratio transfer mediated reasoning has become quite established in a forensic setting the principle is more generally applicable.2 In a forensic context the trier of fact (TOF) has the role of determinating the the truth of certain statements. Below such statements are referred to as hypothesis propositions. The TOF role may be played by a judge or by a jury. TOF may say \u201cguilty\u201d (or \u201cnot guilty\u201d). The TOF may be in need of a science backed interpretation of available evidence. Providing such information is delegated to the forensic expert. In order to obtain a more generally applicable presentation I will speak of a mediator of evidence (MOE) rather than of a forensic expert (FE). TOF and MOE are the two major roles in any account of likelihood ratio transfer mediated reasoning."}, {"heading": "1.2 Methodological assumptions and choices", "text": "This paper is written on the basis of certain assumptions which are worth mentioning.\n1. The paper is written as a contribution to the development of probability theory in the context of signed meadows, a joint project by Alban Ponse (University of Amsterdam) and myself, initiated in the spring of 2013. The technical work may be viewed in that light whereas an attempt made in Section 7 to derive conclusions with relevance for forensic science and forensic logic in particular is a separate theme, quite disconnected from the intended advancement of meadow theory by considering potential applications of it.\n2. The technical work is done having in mind, at least initially, the paradigm of subjective probability theory with precise probabilities quantifying the strength of an agent\u2019s belief.\n1Attention is limited to precise belief functions because I am convinced by the conventional argument in favour of the use of precise belief states, namely that using imprecise belief states would leave TOF with an unmanageable burden of proof methodology and technology. Nevertheless by using imprecise belief states as intermediate belief states proposition kinetics may just as well be described. After one or more steps of constraining (steps of belief kinetics which reduce imprecision using the terminology of Voorbraak [42]) the belief state may be turned back into a precise belief state ready for subsequent Bayesian conditioning with the required effect.\n2The central role of likelihood ratios in reporting in forensic science (which includes forensic science based forensic practice) is strongly emphasized in the ENFSI guidelines (Willis et al. [49]).\nThis is done for the simple reason that this paradigm provides ample motivation and justification for the use of a range of transformations of probability functions. A the same time an open mind is called for with respect to other paradigms that might provide a justification for the same or a similar body of theoretical developments.\n3. Reading (and understanding) the very extensive foundational literature on probability theory is a substantial challenge. I have no basis for the claim that the results in this paper are new except that I did not yet find these results in this form elsewhere. Unfortunately, absence of evidence implies no evidence of absence in this sort of case.\n4. More specifically I must be quite cautious with making any claims regarding the technical correctness, the philosophical and methodological adequacy, and of course the novelty and originality of the following methods, and notions which are defined and used in the paper: (i) the use of repeated single likelihood Adams conditioning for TOF side processing of transferred (incoming from MOE) likelihoods in advance of Bayes conditioning (for processing incoming evidence), (iii) the use of double likelihood Adams conditioning in advance of Bayes conditioning, (iii) the use of an additional (auxiliary and temporary) proposition space if the evidence proposition is not included in the proposition space of TOF, (iv) the use of Jeffrey conditioning as a follow up for Bayes conditioning, (vii) the distinction between likelihood pairs and likelihood ratios, (vi) the distinction between synchronous likelihood pairs and asynchronous likelihood pairs, (vi) the notion of single message reporting (by MOE), (vii) the suggestion of parallel decomposition of a MOE, (viii) the perception of precise belief functions as a semantic model for a calculus of revisions of probability functions, (ix) the successive stages for making the semantic model less abstract: finite sets of belief functions, finite sets of uniformly structured finite progressions of belief functions, and finite sets uniformly structured finite progressions of finite families of proposition spaces and corresponding belief functions.\n5. The role of documented representations of belief functions for TOF is to support TOF in the determination of its eventually internalized beliefs. Psychological research has shown that unsupported human agents are likely not to follow the rules of probability calculus and methodologically justified belief revision in the manner that probability theory would prescribe. Stated differently, if TOF consists of human agents a theory of belief revision for TOF is not meant describe the unsupported behaviour of TOF. Conversely this theory and its calculus are supposed to support TOF in achieving a reliable and defensible performance.\nTherefore any usable and explicit calculus or notation for belief states amounts to no more than a supportive tool for TOF, and the calculus is merely a toolkit. In agreement with Fenton, Neil & Berger[19] it is to be expected that in actual application TOF will make use of automated support, and that the calculation of actual beliefs and of belief state revisions will not become a task for human agents. However, at certain stages values of the current belief function are used by TOF and are incorporated in its own mental belief function.3\n6. It follows from the core of subjective belief theory that belief revisions (by TOF) must\n3By consequence there is no rationale for raising fundamental objections against using imprecise beliefs in the toolkit as long as doing so is supportive of the formation of precise beliefs in TOF\u2019s mind, and as long as these \u201ctrue beliefs\u201d play a proper role in TOF\u2019s decision taking.\nalways be applied on the entire belief function, thereby taking all elements of the TOF\u2019s proposition space into account.\nMore specifically, supposing that TOF\u2019s proposition space is generated by say four propositions: H (main hypothesis proposition), E (main evidence proposition), L,M (additional hypothesis or evidence propositions). Now a belief revision for TOF must specify all probabilities on the entire Boolean algebra of sentences over these four generators, which can be achieved by providing a specification of 16 values of the revised belief function."}, {"heading": "2 Probability calculus on the basis of involutive meadows", "text": "A meadow is a structure for numbers equipped with either a name/notation for the multiplicative inverse function (inversive notation) or with a name/notation for the division function (divisive notation). Given either name the other name can be introduced as an abbreviation.\nFrom the perspective of forensic science it is wholly immaterial whether or not there is a name in one\u2019s language for a mathematical function, in this case division. Only when formalizing the logic the presence or absence of names acquires relevance. From the perspective of formalizing the underlying logic, however, it is an important issue, and this observation applies to the case of forensic reasoning.\nOnce a name and notation (say division with notation x\ny given arguments x and y) has been\nintroduced the question \u201cwhat is x\n0 \u201d may be posed and is entitled to an answer. Assigning a\nvalue to x\n0 can be done in at least 6 different ways, each of which has been amply investigated\nin the mathematical and logical literature about how one may deal with the multiplicative inverse of zero. A very straightforward idea, which is adopted below, is to work under the assumption that x\n0 = 0. This convention must not be understood as expressing a non-trivial\ninsight about numbers and division, which has been overlooked by mainstream mathematics until now, so to say. This convention to set x\n0 = 0 merely represents a choice (and only\none choice out of a number of options) on how to base one\u2019s logic on a formalized version of arithmetic. Using x\n0 = 0 on top of the standard axioms for numbers (the axioms for a\ncommutative ring) leads to what is called an involutive meadow in [8].\nDeveloping precise logics for application in forensic science begins with the choice of a logic for arithmetic as a step towards having a logic for the values serving as probabilities. Mathematics does not provide such logics, however, which is rather the task of mathematical logic. Working with involutive meadows, a subclass (in fact variety) of the class of ring based meadows, is just one option for choosing a logic of numbers. The approach via meadows derives from the computer science tradition where rational numbers are viewed as an abstract datatype. My preference for working with involutive (ring based) meadows derives from a preference for working with equations and conditional equations over the explicit use of quantifiers which comes with the use of full first order logic.4\n4I notice a marked absence of quantified formulae (in particular \u2200x.\u03a6 and \u2203x.\u03a6 for a formula \u03a6) in the forensic science literature. In computer science quantifiers are used all over the place. This relative lack of prominence of quantifiers is at first sight at odds with the frequent use of the term logic in forensics. However,\nBelow decimal notation will used freely under the assumption that 2 abbreviates 1+ 1 and so on.5"}, {"heading": "2.1 Proposition spaces and probability functions", "text": "Formulae and equations below are to be understood in the context of the specification BA+ Md+ Sign+ PFP\n6 taken from Bergstra & Ponse [10] for a probability function with name P over an event space E, which takes form of a Boolean algebra of events and for which a finite collection C of constants is available.7 As is common in the forensic literature I will refer to events as propositions below. Formulae, however, involve sentences and syntax. I will write E for a sentence while reserving [[E]] for its interpretation, a notation I won\u2019t make use of however, and I apologise in advance for confusion that may be caused by a sometime rather imperfect (sloppy) application of these conventions. Besides a Boolean algebra of propositions there is a Boolean algebra of sentences, which need not be a free Boolean algebra either.\nThroughout the paper I will use Jeffrey\u2019s t(\u2022) notation for lambda abstraction with a single variable: given a context t[\u2212]: t(\u2022) = \u03bbx.t[x]."}, {"heading": "2.2 Conditional probability: variations on a theme", "text": "Following [10] P 0(x | y) is defined by\nP 0(x | y) = P (x \u2227 y)\nP (y)\nThe superscript 0 indicates that P 0(x|y) = 0 whenever P (y) = 0. In Bergstra & Ponse [10] several other options for defining conditional probabilities when taking the possibility of P (y) = 0 into account are discussed. For instance,\nP 1(x | y) = P (x \u2227 y)\u2212 P (y)\nP (y) + 1\nP 1(\u2212) satisfies: P (y) = 0 \u2192 P 1(x | y) = 1, which fits well with material implication for two-valued logic. When dealing with Bayesian conditionalization safe conditional probability,\nassuming that only universally quantified formulae are used, and taking into account the convention (which prevails both in logic and in mathematics) to omit explicit mention of quantifiers while having universal quantification as a default I entertain the view that the forensic science community implicitly shares my preference for working with a fragment (implicitly universally quantified formulae) of first order logic rather over working with full first order logic. This fragment, however, is more expressive than equational logic, which for instance does without negation. When working in equational logic the logical operators (negation, conjunction, disjunction, material implication) are dealt with as ordinary mathematical functions as well. This latter convention is by no means generally accepted and it undeniably comes with its own complications, but I will use it because it strongly facilitates the use of equations and conditional equations.\n5In Bergstra & Ponse [11] the formalization of decimal number notation by means of ground complete term rewriting systems, a useful shape of abstract datatype specification in preparation for prototyping implementations, is studied in detail.\n6For: Boolean algebra + meadows + sign function + a probability function named P . 7For this specification a completeness theorem that was proven in Bergstra, Bethke & Ponse [6] for Md+Sign is extended in [10]. The equational specification BA+Md+Sign+PFP is extended with so-called conditional values, playing the role of random variables, and expectation values in Bergstra [5].\nwritten as PS(x \u2227 y), may be helpful:\nPS(x | y) = P (x \u2227 y)\u2212 P (y) \u00b7 P (x)\nP (y) + P (x)\nThe advantage of safe conditional probability is that PS(\u2022 | y) = \u03bbx.PS(x | y) (using Jeffrey\u2019s PS(\u2022 | y) notation as a \u201cdedicated\u201d instance of lambda abstraction) is a probability function for all y, which is not the case for P 0(\u2022 | y) and for P 1(\u2022 | y). Denoting with \u2191 the \u201cundefined\u201d outcome of a function, the conventional notion of a conditional probability due to Kolmogorov reads as follows:\nP \u2191(x | y) = P (x \u2227 y)\nP (y) \u22b3 P (y)\u22b2 \u2191 .\nHere a\u22b3 b\u22b2c stands for if b 6= 0 then a else c. The conditional operator allows a straightforward definition in ring based involutive meadows:8\nx\u22b3 y \u22b2 z = y\ny \u00b7 x+ (1\u2212\ny y ) \u00b7 z\nNotwithstanding the fact that P \u2191(\u2212) corresponds best with what ordinary school mathematics has to say about division, properly formulating its logic is far more involved than developing the logic needed to work with P 0(\u2212|\u2212) or with P 1(\u2212|\u2212) or PS(\u2212|\u2212).9 Using the conditional operator the definitions of P 1(\u2212|\u2212) and PS(\u2212|\u2212) can be made more illuminating:\nP 1(x | y) = P (x \u2227 y)\nP (y) \u22b3 P (y)\u22b2 1 and PS(x | y) =\nP (x \u2227 y)\nP (y) \u22b3 P (y)\u22b2 P (x).\nThe literature on conditional probabilities taking probability zero for the condition into account is quite complex. Popper functions, nonstandard probabilities, Renyi\u2019s conditional probability, and De Finetti\u2019s coherent conditional probability come into play. Working with P 0(\u2212) excludes some of these options for dealing with conditional probability functions, but choosing to work with an involutive meadow does not by itself introduce such kind of bias. On the contrary by taking an involutive meadow as the point of departure one is well-placed to proceed with the formalization of each of the mentioned options (and more) for the definitions of conditional probability functions."}, {"heading": "2.3 Relevance of meadows for the work in this paper", "text": "The use of meadows specifically in this context of this particular paper is listed in the following items.\n\u2022 All equations are meant to be valid for all substitutions of values for variables. All conditions for equations to hold must be made explicit.10\n8In the presence of \u2191 weaker equations are needed: such as x\u22b3 0\u22b2 z = z, x\u22b3 1 \u22b2 z = x, x\u22b3 \u2191 \u22b2z =\u2191, and x\u22b3 y \u22b2 z = x\u22b3 y\ny \u22b2 z.\n9The choice made below for using P 0(\u2212|\u2212) rather than P 1(\u2212|\u2212) or PS(\u2212|\u2212) is merely a matter of taste. 10No attempt is made in the paper to work out these matters in full detail. In many cases instead of an assumption that say t 6= 0 it is assumed or derived that t t = 1, which given the theory of meadows nearly amounts to the same. The claimed advantage is that working with meadows allows to achieve 100% precision in these matters in principle. However, compared with a conventional style of mathematical writing, regarding matters of division by zero, working with meadows does not imply or induce any additional commitment to a formalistic and possibly overly detailed approach.\n\u2022 Various forms of Bayes\u2019 theorem take the form of derivable equations (see Bergstra and Ponse [10] and Bergstra [5]).\n\u2022 Proofs of equations can be given relative to the equational proof system BA+Md+Sign+ PFP (usually in combination with some equational and explicit operator definitions). No additional import of a theory of real numbers or of set theory is required.\n\u2022 A particular semantic problem that permeates conventional school mathematics is avoided. Suppose one insists that in the world of rational numbers the assertion\n\u03a6(x) \u2261 x 6= 0 \u2192 x\nx = 1\nholds in general. Many formulations of Bayes\u2019 theorem presuppose this assumption. Then the following logical complication arises: for \u2200x.\u03a6(x) to be true it is required that \u03a6(0) is true. Thus\n0 6= 0 \u2192 0\n0 = 1\nAssuming a classical two-valued logic 00 = 1 must be either true or false. But conventional mathematics is reluctant to commit to either option.\nThree-valued logics provide a solution, but the proof systems become unexpectedly complex.\nA computer science related perspective is to have a temporal interpretation of implication (\u2192), thus turning propositional calculus into a so-called short circuit logic. The idea is that if a condition to an implication fails the conclusion is left unevaluated. The logical details of the short-circuit perspective have been worked out in ample detail in Bergstra, Ponse & Staudt [12]. These details, however, are prohibitively complex for application in forensic logics.\nClose to conventional mathematical intuition is to work with partial functions and to formalize arithmetic using a logic of partial functions. Designing logics of partial functions constitutes an intricate subject, however, providing no easy solutions.\n\u2022 Writing about an expression P (x \u2227 y)\nP (y) in no way has the side effect of introducing the\nassumption that P (y) is non-zero.\nThe relevance of this matter may be clarified with an example: If in colloquial language and within informal mathematics A asks B for the conditional probability that some agent C has sold some object F under the assumption (condition) that C has stolen that object, A already implicitly states (requires, assumes) that the probability P (has-stolen-F) that C has stolen the object is non-zero.\n\u2022 The equational logic that comes with the meadow approach is not supportive of introducing constraints of the form P (H) 6= 0 or of the form P (H) > 0, because these assertions are not equations and are not equivalent to any equations. An assumption of the form P (H) 6= 0 by itself is also conceptually non-trivial, in spite of its very common occurrence in explanations of Bayes\u2019 theorem and of Bayes conditioning.\nTo appreciate this difficulty one may notice that the constraint P (H) > 0 cannot be conveniently expressed in the language of probability functions with precise beliefs. From\nthe perspective of subjective probability with beliefs represented by precise probability functions, either the assumption that P (has-stolen-F) > 0 must be considered not to qualify as information with relevance to an agent\u2019s belief (because otherwise the agent should be able, by definition of the concept of subjective probability, to encode the level of uncertainty resulting after learning that P (has-stolen-F) > 0 in a probability function with precise values), or the limitation to precise values must be lifted, a step of significant magnitude in the current (2016) state of affairs in forensic logic.\n\u2022 On the basis of meadows providing a formalization of aspects of probability calculus relevant for the discussion below is relatively simple; and providing such a formalization in terms of equational logic is feasible."}, {"heading": "2.4 Transformations of proposition spaces and corresponding precise belief functions", "text": "The work in this paper will be quite sensitive to the precise shape of proposition spaces and probability functions on proposition spaces. Rather than working out these matters by way of preparation to the sequel of the paper, in full detail, I will limit this presentation to the mentioning of scattered aspects, while giving definitions by way of representative examples rather than in a more general notational setting.\nThe proposition space of an agent, say A, will be denoted with SA. If it is known that the proposition space is generated by primitive propositions, say H,L,M,N , I will write SA = SA(H,L,M,N), if there are only two generators one has e.g. SA(L,M) or SA(H,L).\nA belief function (supposedly encoding beliefs of agent A) PA maps each proposition in a proposition space to a value in a meadow. I will only make use of the meadow of rational numbers below. More sophisticated work may call for reals (or even for complex numbers, as is the case in the non-commutative probability theory of quantum mechanics).\nA belief function is best thought of as a pair (SA, PA), though below the domain SA is often left implicit. A limited number of transformations on belief functions will play a role in this paper.\nBayes conditioning (without proposition kinetics). Let for example SA = SA(L,M,N).\nSuppose PA(M) = p with p > 0. Then P\u0302A is obtained by Bayes conditioning if it satisfies the following equation:\nP\u0302A = P 0 A(\u2022 |M)\nIt follows that P\u0302A(M) = 1 and the proposition space is left unaffected. 11\nBayes conditioning with proposition kinetics. Let once more SA = SA(L,M,N). Sup-\npose PA(M) = p with p > 0. Then (SA(L,N), P\u0302A) is obtained by Bayes conditioning if P\u0302A satisfies the following equation:\nP\u0302A = P 0 A(\u2022 |M)\n11Bayes conditioning comes under alternative names: Bays conditioning, Bayes\u2019 conditioning, Bayes conditionalization, Bayes\u2019 conditionalization, Bayesian conditioning, Bayesian conditionalization. In this paper only Bayes conditioning and Bayesian conditioning is used.\nBayes conditioning with proposition kinetics removes M from SA with the effect that after Bayes conditioning with respect to M the proposition space has been reduced to SA = SA(L,N).\nBayes conditioning on a non-primitive proposition. Let, again by way of example, the proposition space of A have three generators: SA = SA(L,M,N). Suppose \u03a6 is a closed propositional sentence making use of primitives L,N, and M . Suppose PA(\u03a6) = p with\np > 0. Then P\u0302A is obtained by Bayes conditioning on \u03a6 if it satisfies the following equation:\nP\u0302A = P 0 A(\u2022 | \u03a6)\nWhen conditioning on a non-primitive proposition kinetics does not apply, i.e. the proposition space is left as it was.\nJeffrey conditioning. Let for example SA = SA(L,M,N). Suppose PA(M) = p. Then P\u0302A is obtained by Jeffrey conditioning if it satisfies the following equation:\nP\u0302A = p \u00b7 P 0 A(\u2022 |M) + (1\u2212 p) \u00b7 P 0 A(\u2022 | \u00acM)\nJefrey conditioning involves no proposition kinetics. Bayesian condition may be understood as the version of Bayes conditioning without proposition kinetics.12\nProposition space reduction. Consider SA = SA(L,M,N), one may wish to forget about say N . Proposition kinetics now leads to a reduced proposition space SA(L,M) in which only the propositions generated by L, and M are left.\nProposition space reduction constitutes the simplest form of proposition kinetics.\nParametrized proposition space expansion. Let SA = SA(H). One may wish to expand SA to a proposition space by introducing M to it in such a manner that a subsequent reduct brings one back in SA.\nPA(H) is left unchanged but PA(H \u2227M) and PA(H \u2227M) must be fixed with definite values. A specification of the new probability function, say QA (with domain S(H,M) is: QA(H) = PA(H), PA(H\u2227M) = q1, PA(\u00acH\u2227M) = q2 with q1 and q2 appropriate rational number expressions. If one intends to extend SA = SA(L,M) to SA = SA(L,M,N) four additional values for the probability functions are needed and so on.\nSymmetric proposition space expansion. Let SA = SA(N,H). One may wish to expand SA to a proposition space by introducing M to it in such a manner that a subsequent reduct brings one back in SA but one may not wish to guess any parameters. Now it suffices to assert that for each closed propositional expression \u03a6 over the propositional primitives N and H . QA(M \u2227 \u03a6) = QA(M \u2227 \u00ac\u03a6), in other words all parameters are chosen with value 12 .\nBase rate inclusion. This is a special case of parametrized proposition space expansion, and a generalization of symmetric proposition space expansion. Let p be a closed value expression with p > 0, and assume that BRh is a new proposition name. BRh is introduced in order to include the base rate p (for some relevant type of event, named h) in the probability function.\n12Jeffrey conditioning has finite as well as infinitary versions. According to Diaconis & Zabell [17] only its infinitary versions are stronger than any Bayesian rules.\nThe probability function is extended as follows: QA(BRh \u2227 \u03a6) = p \u00b7 QA(\u03a6), for all sentences \u03a6 not involving BRh.\nSingle likelihood Adams conditioning. Let 0 < l \u2264 1 be a rational number, (given by a closed expression for it). Assume that H and E are among the generators of SA. Single likelihood Adams conditioning leaves the proposition space unchanged and transforms the probability function PA to Ql (leaving out the subscript A for ease of notation).\nQl = PA(H \u2227 E \u2227 \u2022) \u00b7 l\nP 0A(E |H) + PA(H \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\nP 0A(\u00acE |H) + PA(\u00acH \u2227 \u2022)\nDouble likelihood Adams conditioning. Let 0 < l, l\u2032 \u2264 1 be two rational numbers, (each given by a closed meadow expressions). Assume that H and E are among the generators of SA. Double likelihood Adams conditioning leaves the proposition space unchanged and transforms the probability function PA to Ql,l\u2032 .\nQl,l\u2032 = PA(H \u2227 E \u2227 \u2022) \u00b7 l\nP 0A(E |H) + PA(H \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\nP 0A(\u00acE |H) +\nPA(\u00acH \u2227 E \u2227 \u2022) \u00b7 l\u2032\nP 0A(E | \u00acH) + PA(\u00acH \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\u2032\nP 0A(\u00acE | \u00acH)"}, {"heading": "2.5 A labeled transition system of credal states", "text": "A pair (SA, PA) is the mathematical (if one prefers logical) counterpart of an agent A\u2019s state of beliefs. As a may have beliefs not captured in SA one often speaks of A\u2019s partial beliefs or of A\u2019s partial state of beliefs.\nThus (SA, PA) contains (as elements of SA) and quantifies (via PA) only some of the agent\u2019s beliefs. More generally (SA, QA) plays the role of a credal state in a model of the kinetics (dynamics) of A\u2019s credences. Two credal states (SA, PA) and (SA, QA) are called compatible if the same propositions (or rather sentences) of SA have probability 1 under PA as under QA.\nNow one may imagine the collection CSU of all credal states (assuming these are of the form of a probability function on a Boolean algebra which takes values in the signed meadow of rationals) over finite subsets W of a countable set U of propositional atoms.\nEach of the transformations as outlined above in Paragraph 2.4 may be viewed as a rule which generates so-called labeled transitions. Labels are derived from rules, and the label created from a rule contains information about the name of the transformation and possibly of parameters, while the transition itself is between the prior and posterior state of the transformation. There is significant freedom in the details of designing labels.\nFor instance Bayes conditioning without proposition kinetics has label [BC,E, p] with p > 0, it requires of the prior credal state (SA(W ), PA) that E \u2208 W and that PA(E) = p the posterior credal state is (SA(W ), P 0 A(\u2022 | E)). For Bayes conditioning with proposition kinetics the label can be chosen as [BC,E, p, PK], and for Bayes conditioning on a nonprimitive proposition the label [BC,H, p,NP ] may be used. In this manner all transformations of credal states can be understood as rules generating transitions from one credal state to the next and it turns out that a portfolio of transformations, for instance such as given in Paragraph 2.4, provides the definition of a labeled transition system.13\n13This is the way one often looks for an interpretation of a system of states and transformations in mathematical computer science.\nWith L the collection is denoted of all labels that come about when turning the portfolio of transformations listed in paragraph 2.4 into transition rules. Metavariables X and Y range over credal states, L : X \u2192 Y asserts that there is a transition from X to Y with label L. The labeled transitions system obtained from CSU is denoted CS lts U . The collection of credal states with proposition space generated by finite set W \u2286 U is denoted PCSW where PCS indicates that the states have precisely proposition space SA(W ).\nDefinition 2.5.1. A bisimulation on CSltsU is a family of relations RW on PCSW for all finite W \u2286 U which satisfies the following requirements:\n1. for all finite W \u2286 U and X \u2208 PCSW , (X,X) \u2208 RW , (RW is reflexive),\n2. for all finite W \u2286 U and X,Y \u2208 PCSW , if (X,Y ) \u2208 RW then (Y,X) \u2208 RW (RW is symmetric),\n3. for all finite W \u2286 U and X,Y, Z \u2208 PCSW , if (X,Y ) \u2208 RW , and (Y, Z) \u2208 RW then (Y, Z) \u2208 RW (RW is transitive),\n4. if\n(a) W,V are finite subsets of U ,\n(b) X \u2208 PCSW ,\n(c) Y \u2208 PCSV ,\n(d) l \u2208 L, (e) l : X \u2192 Y \u2208 CSltsU , and, (f) (X,X \u2032) \u2208 RW ,\nthen for some Y \u2032 \u2208 PCSV :\n(a) (Y, Y \u2032) \u2208 RV , and (b) l : X \u2032 \u2192 Y \u2032 \u2208 CSltsU ,\nBisimulation relations play a key role in computer science, as well as in modal logic. This definition has been spelled out in much detail because the notion may be unknown in forensic statistics. The following facts can be easily shown:\n\u2022 When taking RidW the identity relation for each finite W \u2286 U , a bisimulation relation is obtained.\n\u2022 If X = (SA(W ), PA) \u2208 PCSW and Y = (SA(W ), QA) \u2208 PCSW then if it is the case that (X,Y ) \u2208 RW for some bisimulation R, it must be the case that X and Y are compatible. Suppose otherwise, then say PA(H) = 1 and QA(H) < 1 for some sentence H in SA(W ). But then Y admits a Bayes conditioning step (perhaps on a non-primitive proposition) on \u00acH whereas X does not admits such a transition.\n\u2022 Let RmaxW contain all pairs of compatible credal states over SA(W ), then R max is a\nbisimulation relation, and moreover it is the maximal bisimulation relation.\nBoth Rid and Rmax are so-called trivial bisimulations. Of these Rid is proper while Rmax is degenerate. Using computer science terminology, Rid is called fully abstract if there is no non-trivial bisimulation on CSltsU which identifies more pairs of credal states than R\nid itself, that is if it is a maximal non-degenerate bisimulation.\nOpen question. The following question seems to be open: is Rid a fully abstract bisimulation on CSltsU ?\nIn the absence of an answer to this question one may easily check that any bisimulation between Rid and Rmax lacks any intuitive appeal. Thus I arrive at the (preliminary) conclusion that CSltsU , by default equipped with R\nmax may serve as a standard model of credal states. In view of the restriction to rational values for probabiliities this model is in fact the rational valued standards model of credal states, (CSltsrat,U ) whereas working with real values in full generality produces the real valued standard model (CSltsreal,U ) of credal states. Below I will focus on the rational model of credal states merely because that restriction provides a useful simplification."}, {"heading": "2.6 The standard model of credal states: the status of assuming precise of beliefs", "text": "Having portrayed CSltsU as the standard model of credal states several remarks can be made:\n\u2022 CSltsU represents the mathematical model behind the Lindley framework: subjective beliefs with beliefs represented as precise probabilities on a well-defined space of propositions.14\n\u2022 By viewing CSltsU as the standard model it is not expressed that it is the most useful model or the best model for applications inside or outside forensics. What it expresses is that in mathematical terms this model comes first and that other models, when contemplated at all, are preferably viewed as more sophisticated variations on the same theme.\n\u2022 The main chacteristic of the standard model is the adoption of the principle that beliefs must be precise. Although I am not convinced that the latter principle can be elevated to the status of an irrefutable \u201caxiom\u201d for forensic logic, I appreciate very much the pragmatic value of the restriction to precise beliefs for the development of theory, as indeed this single assumption provides so much structure.\n\u2022 My position concerning the principle that subjective beliefs must be precise is that theory of forensic logic is best developed under this very assumption, at least initially, while keeping an open mind for more inclusive perspectives on both the notion and the representation of beliefs. When it comes to the well-known fallacies there is no indication that the analysis of these forms of erroneous reasoning requires the contemplation of imprecise beliefs. In other words: the primary analysis of well-known fallacies is to be done within the setting of precise beliefs. Concerning transposition of the conditionals my proposal for an analysis of that particular fallacy is in given in Theorem 8.1.1 below.\n\u2022 Concerning the adoption of imprecise beliefs the observation can be made: there can be no objection against the use of imprecise beliefs if these serve the purpose of obtaining information regarding precise beliefs. The situation may be compared with the status\n14The Lindley framework produces a model for forensic reasoning based on subjective probability theory plus precise belief assumption. Ignoring variations on the theme I will write as if one may refer with \u201cLindley framework\u201d to a definite position which arose from the works of Ramsey, de Finetti, Carnap, Lindley, Evett, and which is now represented by authors including Berger, Biedermann, and Taroni.\nof negative numbers: one may dispute the status of negative numbers as numbers, but one may hardly dispute the status of negative numbers as a tool for the investigation of properties of natural (non-negative) numbers. In the setting of subjective belief theory an analogous argument indicates that the introduction of imprecise beliefs may be first of all conducted with the intent of providing a reasoning tool within a setting based on precise beliefs. Stated yet differently: when introducing sets of numbers as a tool for number theory one need not speak of a paradigm shift in the direction of imprecise numbers. On the contrary it is taken for granted that by introducing sets of numbers the concept of number is not affected. Similarly calculating with sets of belief functions (non-singleton representors) does not change the notion of a belief."}, {"heading": "2.7 Options for refined transition systems for proposition and belief kinetics", "text": "Instead of considering bismulations that identify more credal states than Rid it is meaningful to look for different models of credal states which have the property that the model CSltsU (that is the standard model) can be obtained from it by working modulo an appropriate bisimulation relation. Such models provide a less abstract picture of credal states from which the standard model may be obtained by further abstraction. At least three different patterns for refining the standard model of credal states can be distinguisghed.15\n\u2022 Pointed finite sets of probability functions for each proposition space. This refinement of the standard model allows to capture a restricted form of ignorance by providing zero or more alternatives to a belief function. This is option may be relevant for an expert witness (MOE) who, in addition to a belief wishes to express a perspective on the statistics of the process that led the witness to the reporting of that particular belief.\n\u2022 Finite progressions of probability functions, allowing to attach to a belief some account of how it came into existence by way of a sequence of preceding transformation. This option may be relevant for an expert agent (MOE) who wishes to report at the same time (single message reporting) on the development of its beliefs during some preceding episode.\n\u2022 Instead of having a fixed proposition space for a credal state, each credal sate may be based on a finite family of proposition spaces, each equipped with its own probability function. This refinement can deal with circumstances where no universal probability function can be defined on the probability space generated by the union of the generators of the respective proposition spaces in the family. This kind of generalisation plays a role in quantum mechanics. Whether or relevant applications of proposition space families can be found in the area of forensic logic remains to be seen.\n15In Section 7 below some additional comments on these different mechanisms for obtaining refined models of credal states from the standard model will be given."}, {"heading": "3 Belief kinetics for likelihood ratio transfer mediated", "text": "reasoning\nLikelihood ratio transfer mediated reasoning (LRTMR) is meant to refer to a spectrum of reasoning patterns used at the receiving side of probabilistic information.16 In order to emphasize the general nature of the protocols and methods for LRTMR, and in order to simplify the presentation of expressions and proofs, I will use A instead of TOF and B instead of MOE.\nIn this Section it is assumed that the proposition space of A is left unchanged during the reasoning process. In other words, there is only belief kinetics but no proposition kinetics.17\nIgnoring proposition kinetics while focusing on belief kinetics, constitutes a significant simplification, while it seems to be consistent with current practice in forensic reasoning. For these reasons the case involving belief kinetics only is considered the primary case in this paper.18 The following outline of LRTMR serves as a point of departure for some more technical work.19\nMOE is not expected to determine ready made posterior probabilities for (transferal to) TOF because MOE needs to be informed about its prior beliefs by TOF in order to compute suitable posteriors. The idea behind this restriction is that TOF should be under no pressure to disclose its priors to MOE because these priors are exclusively relevant (if at all) for intra TOF deliberation."}, {"heading": "3.1 Preparation: evidence transfer mediated reasoning and the Taxi Color Case", "text": "The simplest reasoning pattern involving A\u2019s reaction to (way of processing of) an input from B occurs if A maintains a proposition space SA(E,H) and a precise belief function PA defined on it for which PA(E) = p > 0. In these circumstances it may occur that B sends to A a message to the extent that according to B the proposition E is true (more precisely: the sentence E denotes a valid proposition), or in other words that PB(E) = 1. A trusts B and intends to adopt the belief that E is certainly valid. A reacts to the input from B by performing Bayesian conditioning on E, thereby revising its belief function to P\u0302A = P 0(\u2022 |E).\nA paradigmatic example of this reasoning pattern occurs in the so-called Taxi Color Case as specified in detail in Schweizer [35].20 I will decorate the the case description with some additional details. In a town (here TCCC, Taxi Color Case City), in total 1000 taxis circulate,\n16It is worth mentioning that logical aspects of courtroom proceedings related reasoning worth of formal scrutiny arise in quite different context as well. For instance the implicit proof rule for the probability of a conjunction as listed in Arguello [1] seems to be wrong. LRTMR is a container for Bayesian reasoning patterns. Fienberg & Finkelstein [20] provide a historic account of the use of Bayesian reasoning in US trials and propose the avoidance of fallacious reasoning as the primary objective for the promotion of Bayesian reasoning in the light of a substantial difficulty to get the content of Bayesian reasoning across to legal professionals and members of jury\u2019s.\n17In the literature on subjective probability theory instead of belief kinetics the phrase belief dynamics is used as an alternative, and instead of proposition kinetics the phrase proposition dynamics occurs.\n18The simplest examples of LRTMR initially involve only involve a single hypothesis proposition and might for that reason be qualified as involving proposition dynamics in addition to belief dynamics.\n19It is worth mentioning that in this paper no attempt is made to unify all or many reasoning patterns based on Bayesian conditioning. For instance the reasoning pattern discussed by Stephens in [38] lies outside the patterns considered below.\n20Schweizer [35] contains a detailed description of the taxi color case, together with a useful survey of\n150 of which are green and 850 of which are blue. A witness K stated that (s)he saw a defendant D leave with a green taxi from a specific location, in particular taking the first taxi in the taxi queue in front of restaurant R at 23.00 PM.\nI will simplify the case in comparison to Schweizer\u2019s description in Schweizer [35] by assuming that A includes the estimate of a base rate for the correctness of K\u2019s testimony. According to A\u2019s background knowledge it may be expected in general for a witness operating in the conditions of K at the time of the reported event that the witness (not just the actual witness K but also some average of test candidates) will report the color of the taxi correctly with a probability of 80%. In Schweizer\u2019s description, in contrast, B investigates the statement of the witness, including an investigation concerning K\u2019s ability to correctly report about the color of a taxi including for instance (my details) information regarding the position from where she claimed to have been standing at the alleged time of D\u2019s departure by taxi, and taking into account the overall illumination of the scene.\nA determines a proposition space with two propositions: H (hypothesis proposition asserting that D left with a green taxi), and E (evidence proposition asserting that according to K\u2019s testimony D left with a green taxi). A uses, lacking other data, the base rate on operational taxi\u2019s (irrespective of location and time) of 150/1000 to set PA(H) = 150/1000, and A uses the base rate of 80% valid reporting (for both colors) to set: P 0A(E |H) = 80% and P 0 A(E | \u00acH) = 100%\u2212 80% = 20%, so that PA(E \u2227H) = P 0A(E |H) \u00b7 PA(H) = 80/100 \u00b7 150/1000 = 12/100 and PA(E \u2227 \u00acH) = P 0A(E | \u00acH) \u00b7 PA(H) = 20/100 \u00b7 850/1000 = 17/100. It follows that PA(E) = 12/100 + 17/100 = 29/100. Thus (SA(E,H), PA) serves as a prior credal state for A.\nNow one assumes that A obtains evidence from B in the form of its assertion that K made a testimony which may be faithfully rendered at the relevant level of abstraction as E, so that A may now assume that E is true. Given the acquired additional information A may mitigate the consequences of its prior adoption of base rates, as a sources for its prior credal state, by applying Bayesian conditioning on E. P\u0302A = P 0(\u2022 | E) with in particular: P\u0302A(E) = 1 and\nP\u0302A(H) = P 0 A(H | E) =\nP 0A(E |H) \u00b7 PA(H)\nPA(E) =\n80/100 \u00b7 150/100\n29/100 =\n12/100 29/100 = 12/29\nThe example may be decorated with more detail by having for instance a proposition BRgreen as a base rate proposition included with p = 150/1000 (see the listing of transformations of propositions spaces and probability functions above), thus obtaining a proposition space SA(E,H,BRgreen) for A. 21\nThe example, as presented here and in contrast with Schweizer\u2019s presentation, makes no use of determination of a single likelihood or of the determination of a pair of likelihoods by B. For that reason there is no occurrence of a transfer from B to A of either a single likelihood, or of two subsequent likelihoods, or of a simultaneously transferred pair of likelihoods, or of the transfer of a ratio between two likelihoods. In subsequent paragraphs a variety of cases is considered where B determines a likelihood pair P 0B(E |H) and P 0 B(E | \u00acH) and subsequently\nprecise terminology in German about forensic reasoning patterns involving likelihood transfer and Bayesian conditioning. In Schweizer [36] the similar bus color scenario is mentioned in an exposition concerning the legal value of base rates.\n21Here the idea is not to indirectly involve (via base rate inclusion) the mechanism of proposition kinetics in the response of A on the information obtained from B but merely to make use of (or to suggest the use of) proposition kinetics in A\u2019s process of prior belief state construction.\nconveys these either in successive steps, or in a single step as a pair or in a single step while merely transferring the ratio of both, with the intent of overruling the respective likelihoods which are given by A\u2019s prior belief function. At this stage it must be emphasized that because proposition kinetics is ruled out (in this Section) the partial prior beliefs PA of A do provide prior values for both likelihoods and consequently for the likelihood ratio.\nTransposition of the conditional and the TCC. In the TCC example (without proposition kinetics) as outlined above, on finds P 0A(E |H) = 80% and P 0 A(H | E) = 12/29% from which it might be concluded that TCC (with these parameters) provides a counterexample to the so-called fallacy of transposing the conditional. However, in my view this conclusion would be mistaken. Presence of a case of the fallacy of transposing the conditional would suggest that P 0A(H | E) = 80% might be (erroneously) inferred from P 0 A(E |H) = 80%. The objection I raise against that position is that given the fact that one is dealing with a given credal state consisting of a single proposition space SA and its corresponding precise belief function PA, there is no sense in which P 0 A(E | H) = 80% is known (or might be known) in advance of having knowledge of the value of P 0A(H | E), let alone to infer P 0 A(H | E) = q for any particular q from P 0A(E |H) = 80%. In other words there is no form of inference going on.\nThe option to infer P 0A(H |E) = q for some closed value expression q from P 0 A(E |H) = 80% and possible other data definitely arises if one works with collections of probability functions as specified with equations in such a manner that some but not all values of the probability function at hand are specified so that a value for P 0A(H | E) might conceivably be unknown. However, such an interpretation is at odds with the principle that beliefs must be precise (see Paragraph 2.6 above for a discussion on the status of this principle). Concerning transposition of the conditionals an analysis of that particular fallacy within the setting of precise beliefs is given in Theorem 8.1.1 below.\nThe relevance of TCC. The occurrence of a single taxi departure in TCCC provides a remarkably nice case study for theoretical work as it allows an amazing range of further details and significant complications, to mention:\n1. the presence of multiple witnesses, potentially with different reliability and with conflicting assertions, thereby introducing issues of probabilistic independence,\n2. different methods for determining witness reliability ranging from potentially problematic guesswork reported in poor documentation to well documented, scientific research strength (and therefore evidence based) methods of investigation, of course taking into account that likelihoods may be color dependant;\n3. taking other colours into account, taking car model information into account, taking partial (unreliable) number plate information into account, taking taxi management scheduling and monitoring into account;\n4. observations concerning other taxis in the queue in front of restaurant R;\n5. observations on the order of events, was D waiting for a taxi, or did (s)he find one waiting upon arrival;\n6. improved base rate estimations, (possibly measuring the relative frequency of green taxis in that particular queue at that time of the day);\n7. a lying witness, withdrawal of a statement by a witness, a forgetful witness;\n8. suspicion of witness intimidation;\n9. conspiring witnesses;\n10. relations between witness reliability and time, method, and and process of interview;\n11. different mechanisms of background knowledge management for A, and finally item a range of different interaction scenarios for A, B, and other relevant agents (e.g. the prosecution or the defendant\u2019s attorney)."}, {"heading": "3.2 Outline of the LRTMR reasoning pattern", "text": "It is now assumed that both E and H are members of both proposition spaces SA and SB. Both A and B have prior belief states PA and PB with respective domains SA and SB. The reasoning protocol LRTMR involves the following steps:\n1. It is assumed that 0 < PB(H) < 1 and 0 < PB(E) < 1, otherwise the protocol aborts.\n2. B determines the value r of the likelihood ratio LR0B(E,H,\u00acH) = LB(E,H)\nLB(E,\u00acH) =\nP 0B(E |H)\nP 0B(E | \u00acH) with respect to its probability function PB.\n3. If LB(E,\u00acH) = 0 the protocol aborts.\n4. B communicates to A the value r and a description of LR0B(E,H,\u00acH), that is a description of what propositions r is an LR of.\n5. B communicates its newly acquired information to A that it now considers PB(E) = 1, i.e. E being true, to be an adequate representation of the state of affairs.\n6. A trusts B to the extent that A prefers those of B\u2019s quantitative values that B communicates during a run of the protocol over its own values for the same probabilities, likelihoods, and likelihood ratios.\n7. A takes all information into account and applies Bayesian conditioning to end up with its posterior belief function P\u0302A which satisfies:\nP\u0302A(H) = r \u00b7 PA(H)\n1 + (r \u2212 1) \u00b7 PA(H) (1)\nThe equation that specifies the posterior belief on H is equivalent in probability calculus to the more familiar odds form of Bayes\u2019 Theorem:\nP\u0302A(H)\nP\u0302A(\u00acH) = r \u00b7\nPA(H)\nPA(\u00acH) (2)\nThe description of LRTMR is a drastic abstraction used for the purposes of the paper and many aspects are left unspecified such as for instance: (i) has an invitation to B occurred for it to play a role in the protocol, (ii) what is done if the assumptions are not met, (iii)\nhow is an abort of the revision process performed when necessary, (iv) are any assumptions about the absence of background knowledge required for either A or for B, (v) making sure that checking various conditions does not involve information transfer between A and B which stands in the way of the properly performing the conditioning operations?"}, {"heading": "3.3 Belief kinetics I: single likelihood Adams conditioning and local soundness", "text": "I will first consider an adaptation of the protocol named LPTMR for likelihood pair transfer mediated reasoning. LPTMR results from LRTMR by modifying step 4 as follows:\nB determines l and l\u2032 such that l = L(E,H), l\u2032 = L(E,\u00acH), and r = l\nl\u2032 ;22\nB communicates both l and l\u2032 to A in addition to information concerning what sentences these values are likelihoods of.\nIn order to process the incoming information concerning l and l\u2032, A first applies the following transformation, thereby obtaining an intermediate (precise) belief function Ql:\nQl = PA(H \u2227 E \u2227 \u2022) \u00b7 l\nP 0A(E |H) + PA(H \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\nP 0A(\u00acE |H) + PA(\u00acH \u2227 \u2022) (3)\nFollowing the exposition of Bradley [15] this is the Adams transformation corresponding to an intended update of likelihood LA(E,H) = P 0 A(E |H) to value l.\nNext A applies Adams conditioning to P \u2032 in order to update its likelihood LA(E,\u00acH) = P 0A(E | \u00acH) to value l \u2032, thus obtaining a second intermediate belief function RA:\nRl,l\u2032 = Ql(\u00acH \u2227 E \u2227 \u2022) \u00b7 l\u2032\nQ0l (E | \u00acH) +Ql(\u00acH \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\u2032\nQ0l (\u00acE | \u00acH) +Ql(H \u2227 \u2022) (4)\nFinally A applies Bayesian conditioning to Rl.l\u2032 with respect to E:\nR\u0302l,l\u2032 = R 0 l.l\u2032(\u2022 |E) (5)\nThe following facts can be shown concerning this sequence of three conditioning steps:\nTheorem 3.3.1. Given the assumptions and definitions mentioned above, the following identities are true for l, l\u2032, r, PA, Ql, Rl,l\u2032 , and R\u0302l,l\u2032 :\n1. Q0l (E |H) = l\n2. R0l,l\u2032(E |H) = l\n3. R0l,l\u2032(E | \u00acH) = l \u2032\n22It is assumed that l and l\u2032 are known as closed expressions with non-zero and non-negative value not in excess of 1 for the meadow of rational numbers. This assumption is implicitly used many times below in order to be able to apply t\nt = 1 for various terms t. The same use is made of non-zero prior odds PA(H) and PH (E)\nwhich must as well be known in terms of such expression so as to guarantee P (H) P (H) = 1 and P (E) P (E) = 1.\n4. R 0l,l\u2032(E |H)\nR 0l,l\u2032(E | \u00acH) = r\n5. R\u0302l,l\u2032(H) = r \u00b7 PA(H)\n1 + (r \u2212 1) \u00b7 PA(H)\n6. Rl,l\u2032(x) = PA(\u00acH \u2227 E \u2227 x) \u00b7 l\u2032\nP 0A(E | \u00acH) + PA(\u00acH \u2227 \u00acE \u2227 x) \u00b7\n1\u2212 l\u2032\nP 0A(\u00acE | \u00acH) +\nPA(H \u2227 E \u2227 x) \u00b7 l\nP 0A(E |H) + PA(H \u2227 \u00acE \u2227 x) \u00b7\n1\u2212 l\nP 0A(\u00acE |H)\nFrom these facts the following conclusions can be drawn:\n\u2022 If the intention is to perform conditionalization on E then R\u0302l,l\u2032 is a plausible candidate\nfor the posterior P\u0302A of PA after execution of rule LRTMR.\n\u2022 The result of conditioning H on E does not depend on the way l and l\u2032 are chosen so that r = ll\u2032 .\n\u2022 Conditioning of H on E is independent from the way r is written as a fraction. This independence will be referred to as the local soundness of the LPTMR (likelihood pair transfer mediated reasoning) inference method.\n\u2022 If t2 t1 is nonzero the result of conditioning propositions other than H with respect to E\nmay depend on the particular choice of l and l\u2032.\n\u2022 A symmetry argument yields that performing both Adams conditioning steps in the other order leads to the same result.\n\u2022 Performing Adams conditioning for L(E |H) = l and for L(E | \u00acH) = l\u2032 in either order is equivalent to double likelihood Adams conditioning.\nProof. The proof of Theorem 3.3.1 is a matter of calculation on the basis of the available equational axioms and definitions.\n1. (a) Ql(H)\n= (PA(H \u2227 E \u2227 \u2022) \u00b7 l\nP 0A(E |H) + PA(H \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\nP 0A(\u00acE |H) + PA(\u00acH \u2227 \u2022))(H)\n= PA(H \u2227 E) \u00b7 l\nP 0A(E |H) + PA(H \u2227 \u00acE) \u00b7\n1\u2212 l\nP 0A(\u00acE |H) + PA(\u00acH \u2227H)\n= PA(H \u2227 E) \u00b7 l \u00b7 PA(H)\nPA(E \u2227H) + PA(H \u2227 \u00acE) \u00b7\n(1\u2212 l) \u00b7 PA(H)\nPA(\u00acE \u2227H)\n= l \u00b7 PA(H) + (1 \u2212 l) \u00b7 PA(H)\n= PA(H)\n(b) Ql(E \u2227H)\n= (PA(H \u2227 E \u2227 \u2022) \u00b7 l\nP 0A(E |H) + PA(H \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\nP 0A(\u00acE |H) + PA(\u00acH \u2227 \u2022))(H \u2227 E)\n= PA(H \u2227 E \u2227H \u2227 E) \u00b7 l\nP 0A(E |H) + PA(H \u2227 \u00acE \u2227H \u2227 E) \u00b7\n1\u2212 l\nP 0A(\u00acE |H) +\nPA(\u00acH \u2227H \u2227 E)\n= PA(H \u2227 E) \u00b7 l\nP 0A(E |H)\n= l \u00b7 PA(H)\n(c) Q0l (E |H) = Ql(E \u2227H)\nQl(H) =\nl \u00b7 PA(H)\nPA(H) = l\n2. R0l,l\u2032(E |H) = Rl,l\u2032(E \u2227H)\nRl,l\u2032(H) =\nQl(H \u2227E \u2227H)\nQl(H \u2227H) =\nQl(E \u2227H)\nQl(H) = Q0(E |H) = l\n3. (a) Rl,l\u2032(\u00acH)\n= (Ql(\u00acH \u2227 E \u2227 \u2022) \u00b7 l\u2032\nQ0l (E | \u00acH) +Ql(\u00acH \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\u2032\nQ0l (\u00acE | \u00acH) +Ql(H \u2227 \u2022))(\u00acH)\n= Ql(\u00acH \u2227 E \u2227 \u00acH) \u00b7 l\u2032\nQ0l (E | \u00acH) +Ql(\u00acH \u2227 \u00acE \u2227 \u00acH) \u00b7\n1\u2212 l\u2032\nQ0l (\u00acE | \u00acH) +Ql(H \u2227 \u00acH)\n= Ql(E \u2227 \u00acH) \u00b7 l\u2032\nQ0l (E | \u00acH) +Ql(\u00acE \u2227 \u00acH) \u00b7\n1\u2212 l\u2032\nQ0l (\u00acE | \u00acH)\n= l\u2032 \u00b7Ql(\u00acH) + (1\u2212 l \u2032) \u00b7Ql(\u00acH)\n= Ql(\u00acH)\n(b) Rl,l\u2032(E \u2227 \u00acH)\n= (Ql(\u00acH \u2227 E \u2227 \u2022) \u00b7 l\u2032\nQ0l (E | \u00acH) +Ql(\u00acH \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\u2032\nQ0l (\u00acE | \u00acH) +Ql(H \u2227 \u2022))(E \u2227 \u00acH)\n= Ql(\u00acH \u2227 \u00acE \u2227 \u00acH) \u00b7 l\u2032\nQ0l (\u00acE | \u00acH)\n= Ql(\u00acE \u2227 \u00acH) \u00b7 l\u2032\nQ0l (\u00acE | \u00acH)\n= Ql(\u00acE \u2227 \u00acH) \u00b7 l\u2032 \u00b7Ql(\u00acH)\nQl(\u00acE \u2227 \u00acH)\n= l\u2032 \u00b7Ql(\u00acH)\n(c) R0l,l\u2032(E | \u00acH) = Rl,l\u2032(E \u2227 \u00acH)\nRl,l\u2032(\u00acH) =\nl\u2032 \u00b7Ql(\u00acH)\nQl(\u00acH) = l\u2032\n4. Using the preceding items and by definition of r.\n5. (a) Ql(\u00acH) = 1\u2212Ql(H) = 1\u2212 PA(H)\n(b) Rl,l\u2032(E)\n= (Ql(\u00acH \u2227 E \u2227 \u2022) \u00b7 l\u2032\nQ0l (E | \u00acH) +Ql(\u00acH \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\u2032\nQ0l (\u00acE | \u00acH) +\nQl(H \u2227 \u2022))(E)\n= Ql(\u00acH \u2227E) \u00b7 l\u2032\nQ0l (E | \u00acH) +Ql(H \u2227 E)\n= l\u2032 \u00b7Ql(\u00acH) + l \u00b7 PA(H) = l\u2032 \u00b7 (1\u2212 PA(H)) + l \u00b7 PA(H)\n(c) R\u0302l,l\u2032(H) = R 0 l,l\u2032(H |E) =\nRl,l\u2032(E \u2227H)\nRl,l\u2032(E) =\nQl(E \u2227H)\nRl,l\u2032(E)\n= l \u00b7 PA(H)\nl\u2032 \u00b7 (1\u2212 PA(H)) + l \u00b7 PA(H) =\nl/l\u2032 \u00b7 PA(H)\n(1\u2212 PA(H)) + l/l\u2032 \u00b7 PA(H)\n= r \u00b7 PA(H)\n1 + (r \u2212 1) \u00b7 PA(H)\n6. (a) Q0l (E | \u00acH) = Ql(E \u2227 \u00acH)\nQl(\u00acH) =\nPA(E \u2227 \u00acH)\n1\u2212 PA(H) = P 0A(E | \u00acH)\n(b) Ql(\u00acH)\n= (PA(H \u2227 E \u2227 \u2022) \u00b7 l\nP 0A(E |H) + PA(H \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\nP 0A(\u00acE |H) + PA(\u00acH \u2227 \u2022))(\u00acH)\n= PA(\u00acH)\n(c) Ql(\u00acE \u2227 \u00acH)\n= (PA(H \u2227 E \u2227 \u2022) \u00b7 l\nP 0A(E |H) + PA(H \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\nP 0A(\u00acE |H) + PA(\u00acH \u2227 \u2022))(E \u2227 \u00acH)\n= PA(\u00acE \u2227 \u00acH)\n(d) Q0l (\u00acE | \u00acH) = Ql(\u00acE \u2227 \u00acH)\nQl(\u00acH) =\nPA(\u00acE \u2227 \u00acH)\nPA(\u00acH) = P 0A(\u00acE | \u00acH)\n(e) Rl,l\u2032(x)\n= Ql(\u00acH \u2227 E \u2227 x) \u00b7 l\u2032\nP 0A(E | \u00acH) +Ql(\u00acH \u2227 \u00acE \u2227 x) \u00b7\n(1\u2212 l\u2032)\nP 0A(\u00acE | \u00acH) +Ql(H \u2227 x)\n= PA(\u00acH \u2227 E \u2227 x) \u00b7 l\u2032\nP 0A(E | \u00acH) + PA(\u00acH \u2227 \u00acE \u2227 x) \u00b7\n1\u2212 l\u2032\nP 0A(\u00acE | \u00acH)\n+ PA(H \u2227 E \u2227 x) \u00b7 l\nP 0A(E |H) + PA(H \u2227 \u00acE \u2227 x) \u00b7\n1\u2212 l\nP 0A(\u00acE |H)"}, {"heading": "3.4 Belief kinetics II: double likelihood Adams conditioning and global soundness", "text": "In this paragraph the proporties of double likelihood Adams conditioning are considered in detail. This conditioning mechanism fits best with likelihood ratio transfer as it simultaneously incorporates two likelihoods l and l\u2032. The likelihoods l and l\u2032 may in turn have been obtained by choosing for a given likelihood ratio r (which A may have received from B) appropriate values such that r = ll\u2032 : Ql,l\u2032 = PA(H \u2227 E \u2227 \u2022) \u00b7 l\nP 0A(E |H) + PA(H \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\nP 0A(\u00acE |H) +\nPA(\u00acH \u2227 E \u2227 \u2022) \u00b7 l\u2032\nP 0A(E | \u00acH) + PA(\u00acH \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\u2032\nP 0A(\u00acE | \u00acH)\nSubsequent conditioning with respect to E is given by:\nQ\u0302l,l\u2032 = Q 0 l.l\u2032(\u2022 | E) (6)\nTheorem 3.4.1. Given the assumptions and definitions mentioned above, the following identities are true for l, l\u2032, r, PA, Ql,l\u2032 , and Q\u0302l,l\u2032 :\n1. Q0l,l\u2032(E |H) = l\n2. Q0l,l\u2032(E | \u00acH) = l \u2032\n3. Q 0l,l\u2032(E |H)\nQ 0l,l\u2032(E | \u00acH) = r\n4. Q\u0302l,l\u2032(x) = r \u00b7 P 0A(x |H \u2227 E) \u00b7 PA(H) + P 0 A(x | \u00acH \u2227 E) \u00b7 PA(\u00acH)\nr \u00b7 PA(H) + PA(\u00acH)\n5. Q\u0302l,l\u2032(H) = r \u00b7 PA(H)\n1 + (r \u2212 1) \u00b7 PA(H)\nFrom these facts the following conclusions can be drawn:\n\u2022 Double likelihood Adams conditioning23 for likelihoods l and l\u2032 transforms PA in to a probability function with the following properties: (i) the corresponding likelihoods are equal to l and l\u2032, (ii) after Bayesian conditioning of H with respect to E the correct values is obtained, (iii) the result of conditioning any proposition with respect to E depends on the ratio of l and l\u2032 only. of PA after execution of rule LRTMR, and for that reason also for the posterior P\u0302A.\n\u2022 Double likelihood Adams conditioning followed by Bayesian conditioning is globally sound.\n\u2022 In view of Theorem 3.3.1 the following answer to the question mentioned in the first lines of the paper is obtained: only by working with a likelihood ratio and by processing both ratios simultaneously global soundness is obtained.\n23Alternative names: simultaneous Adams conditioning, or likelihood pair Adams conditioning.\nProof. As double likelihood Adams conditioning may be considered the more important conditioning transformation the proofs have been worked out in full detail without making use of calculations for the single likelihood case.\n1. (a) Ql,l\u2032(E \u2227H)\n= (PA(H \u2227 E \u2227 \u2022) \u00b7 l\nP 0A(E |H) + PA(H \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\nP 0A(\u00acE |H) +\nPA(\u00acH \u2227 E \u2227 \u2022) \u00b7 l\u2032\nP 0A(E | \u00acH) + PA(\u00acH \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\u2032\nP 0A(\u00acE | \u00acH) )(E \u2227H)\n= PA(H \u2227E) \u00b7 l\nP 0A(E |H) = l \u00b7 PA(H)\n(b) Ql,l\u2032(H)\n= (PA(H \u2227 E \u2227 \u2022) \u00b7 l\nP 0A(E |H) + PA(H \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\nP 0A(\u00acE |H) +\nPA(\u00acH \u2227 E \u2227 \u2022) \u00b7 l\u2032\nP 0A(E | \u00acH) + PA(\u00acH \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\u2032\nP 0A(\u00acE | \u00acH) )(H)\n= (PA(H \u2227 E) \u00b7 l\nP 0A(E |H) + PA(H \u2227 \u00acE) \u00b7\n1\u2212 l\nP 0A(\u00acE |H)\n= l \u00b7 PA(H) + (1 \u2212 l) \u00b7 PA(H) = PA(H)\n(c) Q0l,l\u2032(E |H) = Ql,l\u2032(E \u2227H)\nQl,l\u2032(H) =\nl \u00b7 PA(H)\nPA(H) = l\n2. (a) Ql,l\u2032(E \u2227 \u00acH)\n= (PA(H \u2227 E \u2227 \u2022) \u00b7 l\nP 0A(E |H) + PA(H \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\nP 0A(\u00acE |H) +\nPA(\u00acH \u2227 E \u2227 \u2022) \u00b7 l\u2032\nP 0A(E | \u00acH) + PA(\u00acH \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\u2032\nP 0A(\u00acE | \u00acH) )(E \u2227 \u00acH)\n= PA(\u00acH \u2227 E) \u00b7 l\u2032\nP 0A(E | \u00acH) = l\u2032 \u00b7 PA(\u00acH)\n(b) Ql,l\u2032(\u00acH)\n= (PA(H \u2227 E \u2227 \u2022) \u00b7 l\nP 0A(E |H) + PA(H \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\nP 0A(\u00acE |H) +\nPA(\u00acH \u2227 E \u2227 \u2022) \u00b7 l\u2032\nP 0A(E | \u00acH) + PA(\u00acH \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\u2032\nP 0A(\u00acE | \u00acH) )(\u00acH)\n= (PA(\u00acH \u2227 E) \u00b7 l\u2032\nP 0A(E | \u00acH) + PA(\u00acH \u2227 \u00acE) \u00b7\n1\u2212 l\u2032\nP 0A(\u00acE | \u00acH)\n= l\u2032 \u00b7 PA(\u00acH) + (1 \u2212 l \u2032) \u00b7 PA(\u00acH) = PA(\u00acH)\n(c) Q0l,l\u2032(E | \u00acH) = Ql,l\u2032(E \u2227 \u00acH)\nQl,l\u2032(\u00acH) =\nl\u2032 \u00b7 PA(\u00acH)\nPA(\u00acH) = l\u2032\n3. Immediate.\n4. (a) Ql,l\u2032(E)\n= (PA(H \u2227 E \u2227 \u2022) \u00b7 l\nP 0A(E |H) + PA(H \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\nP 0A(\u00acE |H) +\nPA(\u00acH \u2227 E \u2227 \u2022) \u00b7 l\u2032\nP 0A(E | \u00acH) + PA(\u00acH \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\u2032\nP 0A(\u00acE | \u00acH) )(E)\n= PA(H \u2227E) \u00b7 l\nP 0A(E |H) + PA(\u00acH \u2227 E) \u00b7\nl\u2032\nP 0A(E | \u00acH)\n= l \u00b7 PA(H) + l \u2032 \u00b7 PA(\u00acH)\n(b) Ql,l\u2032(x \u2227 E)\n= (PA(H \u2227 E \u2227 \u2022) \u00b7 l\nP 0A(E |H) + PA(H \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\nP 0A(\u00acE |H) +\nPA(\u00acH \u2227 E \u2227 \u2022) \u00b7 l\u2032\nP 0A(E | \u00acH) + PA(\u00acH \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\u2032\nP 0A(\u00acE | \u00acH) )(x \u2227 E)\n= PA(x \u2227H \u2227E) \u00b7 l\nP 0A(E |H) + PA(x \u2227 \u00acH \u2227E) \u00b7\nl\u2032\nP 0A(E | \u00acH)\n= PA(x \u2227H \u2227E) \u00b7 l \u00b7 PA(H)\nPA(E \u2227H) + PA(x \u2227 \u00acH \u2227 E) \u00b7\nl\u2032 \u00b7 PA(\u00acH)\nPA(E \u2227 \u00acH)\n= l \u00b7 P 0A(x |H \u2227E) \u00b7 PA(H) + l \u2032 \u00b7 P 0A(x | \u00acH \u2227 E) \u00b7 PA(\u00acH)\n(c) Q\u0302l,l\u2032(x) = Ql,l\u2032(x \u2227 E)\nQl,l\u2032(E)\n= l \u00b7 P 0A(x |H \u2227 E) \u00b7 PA(H) + l \u2032 \u00b7 P 0A(x | \u00acH \u2227E) \u00b7 PA(\u00acH)\nl \u00b7 PA(H) + l\u2032 \u00b7 PA(\u00acH)\n= l\u2032 \u00b7 (l/l\u2032 \u00b7 P 0A(x |H \u2227 E) \u00b7 PA(H) + P 0 A(x | \u00acH \u2227 E) \u00b7 PA(\u00acH))\nl\u2032(l/l\u2032 \u00b7 PA(H) + PA(\u00acH))\n= r \u00b7 P 0A(x |H \u2227 E) \u00b7 PA(H) + P 0 A(x | \u00acH \u2227 E) \u00b7 PA(\u00acH)\nr \u00b7 PA(H) + PA(\u00acH)\n5. Q\u0302l,l\u2032(H) = ( r \u00b7 P 0A(\u2022 |H \u2227E) \u00b7 PA(H) + P 0 A(\u2022 | \u00acH \u2227E) \u00b7 PA(\u00acH)\nr \u00b7 PA(H) + PA(\u00acH) )(H)\n= r \u00b7 P 0A(H |H \u2227 E) \u00b7 PA(H) + P 0 A(H | \u00acH \u2227 E) \u00b7 PA(\u00acH)\nr \u00b7 PA(H) + PA(\u00acH)\n= r \u00b7 PA(H)\n1 + (r \u2212 1) \u00b7 PA(H)\nSummarizing the information obtained thus far lead leads to the following conclusions.\nAssessment of LRTMR in the absence of proposition kinetics Summarizing the conclusions of the discussion of belief kinetics and Adams conditioning, I arrive at the following assessment. For a likelihood L(E,H,\u00acH) as well as for a likelihood ratio LR0(E,H,\u00acH) I will refer to E as its evidence proposition and to H as its hypothesis proposition.\n1. If proposition kinetics plays no role then LRTMR is justified in the sense that no loss occurs by receiving only a likelihood ratio at the exclusion of both underlying likelihoods.\n2. If proposition kinetics plays no role and if A adopts subjective probability theory with precise probabilities (used for the representation of degrees of subjective belief) to the extent that upon receiving new information of relevance to its partial beliefs it must instantaneously incorporate such information in its probability function, then A can process the reception of a single likelihood update, by way of single likelihood Adams conditioning.\n3. If proposition kinetics plays no role and if after processing the likelihood ratio information and Bayesian conditioning on the evidence proposition A is interested in the whole spectrum of beliefs (global soundness), A may chose an arbitrary decomposition of the given likelihood ratio in two underlying ratios and should then apply double likelihood Adams conditioning on both likelihoods in advance of Bayesian conditioning on the evidence proposition."}, {"heading": "4 Proposition kinetics for likelihood ratio transfer medi-", "text": "ated reasoning I\nIn this Section it is assumed that initially E is not yet included in the proposition space SA of A. An argument why this assumption may be reasonable is the objective of the following listing of considerations:\n\u2022 A may ask B to provide evidence of relevance concerning proposition H without having a particular and technically specific form of such evidence in mind; for instance A may suggest B to consider \u201csomething with DNA\u201d instead of a more precise indication of what sort of technology is to be used.\n\u2022 A template proposition Et (merely a name) is agreed upon between A and B for expressing what B proposes that can be said about evidence for H that is available to B.\n\u2022 B may subsequently propose to A to make use of (to instantiate the template with) an evidence proposition \u201cof the type Te\u201d, merely in conceptual terms and A may agree upon this plan with B. In other words the template is assigned type Te.\n\u2022 B now chooses as its private proposed evidence proposition a specific instance Eb,e of the type Te.\n\u2022 B communicates an abstract form Ea of Ebe to A, which will serve as its public evidence proposition, meant for the interactive reasoning in cooperation with A.\n\u2022 A and B agree to use E as the name for Ea.\n\u2022 A confirms that E is sufficiently new given its background information (that is the current PA has not come about by conditioning or constraining (the most prominent alternative revision mechanism in the imprecise case) on any proposition comparable to E, if no confirmation along these lines can be obtained A terminates this thread of interaction with B.\n\u2022 A makes the plan to incorporate E in its proposition space (proposition space family) using proposition kinetics:\n\u2013 the plan is to be carried out once relevant probabilistic information is made available to A by B;\n\u2013 A need not become fully aware of the meaning of E (i.e. of Eb,e) at any stage during the reasoning process;\n\u2013 A must be able to embed so much information regarding Ea (i.e. the approximation to Eb,e which A has received from B) in its background knowledge base KB that in a forthcoming situation it may recognize a (high) degree of similarity with the contents of a new proposition say E\u2032 which may be proposed to A by the same or another forensic expert (in the same, or another (?) case) with the effect that A must refuse subsequent Bayesian conditioning on E\u2032.24\n\u2022 At this stage A is ready to receive information related to the development of B\u2019s beliefs in E and in E in relation to H . Preferably this is done by way of B first sending to A a likelihood ratio r = LR0B(E,H,\u00acH). A will use this information to expand its proposition space with E (or to add an additional proposition space generated by H and E to its family of proposition spaces), and (ii) to extend its (precise) belief function (or to add another belief function).\nHere it is assumed that B will report to A about E what it actually thinks (believes about) of Eb. In some circumstances B reports its past beliefs rather than current beliefs (indeed B may already have established that PB(E) = 1 before communicating a likelihood ratio r = LR0B(E,H,\u00acH) to A. But once PB(E) = 1, unavoidably (for B) LRB(E,H,\u00ac) = 1 just as well, a value not worth being communicated.\n\u2022 A may subsequently announce to B that it has become convinced that PB(E) = 1. This information is processed by A by way of performing Bayesian conditioning."}, {"heading": "4.1 Proposition kinetics starting with a four element proposition space: local and global soundness of LRTMR", "text": "It will be assumed that initially H is in the proposition space of A while E is not. The simplest nontrivial proposition space SA has a single generator H which is neither \u22a4 nor \u22a5 so that \u22a4,\u22a5, H , and \u00ac are the four elements of SA = SA(H). Initially it is assumed that 1 > PA(H) = p > 0.\nIt is then assumed that A receives from B the information that LR0B(E,H,\u00acH) = r with r > 0. Extending its proposition space SA with E leads to a proposition space with two generators H and E, and 16 elements:\n|SA(H,E)| = {\u22a4,\u22a5, H,\u00acH,E,\u00acE,H \u2227 E,H \u2227 \u00acE,\u00acH \u2227 E,\u00acH \u2227 \u00acE}\n24This refusal is essential only after a reasoning step involving conditioning on E has been performed.\nIn order to specify a belief function QA on this extende proposition space it satisfies to specify besides QA(H) = p (inherited from PA the values Q 0 A(E |H) = l and Q 0 A(E | \u00acH) = l \u2032.\nNow it is assumed that upon receiving the trusted information that LRB(E,H,\u00acH) = r, A guesses values l and l\u2032 for the underlying ratios (undisclosed by B) such that r = ll\u2032 . A applies proposition kinetics by simultaneously extending SA to SA(H,E) and by specifying QA so that QA(H) = p, Q 0 A(E |H) = l and Q 0 A(E |H) = l \u2032 (for the chosen values l and l\u2032).\nThe next phase in LRTMR is that A receives the information that PB(E) = 1 (the evidence proposition is found to hold true by trusted agent B) and A processes this information by applying Bayesian conditioning to the evidence proposition E, thereby obtaining its posterior belief function Q\u0302A = P \u20320(\u2022 |E). The only probability worth evaluating is Q\u0302A(H):\nQ\u0302A(H) = Q 0 A(\u2022 |E)(H) = Q 0 A(H |E)\n= Q0A(H | E) \u00b7QA(H)\nQ0A(E |H) \u00b7QA(H) +Q 0 A(E | \u00acH) \u00b7QA(\u00acH)\n= l \u00b7 PA(H)\nl \u00b7 PA(H) + l\u2032 \u00b7 PA(\u00acH) =\nl/l\u2032 \u00b7 PA(H)\nl/l\u2032 \u00b7 PA(H) + PA(\u00acH)\n= r \u00b7 PA(H)\nr \u00b7 PA(H) + 1\u2212 PA(H) =\nr \u00b7 PA(H)\n1 + (r \u2212 1) \u00b7 PA(H)\nEvaluating Q\u0302A(H) produces precisely the value as required in the outline description of LRTMR in Paragraph 3.2 above. This fact can be interpreted as a sufficient indication for the local soundness of LRTMR in the case of proposition kinetics with a prior proposition space generated by the hypothesis proposition. Under the constraint of a single proposition generated proposition space local soundness and global soundness are the same.\nIf chained reasoning is not applied by A,25 then this simple case suffices to validate the use of likelihood ratio transfer while abstracting from the underlying ratios."}, {"heading": "4.2 Proposition kinetics for a proposition space with two generators: local soundness", "text": "The situation may be reconsidered in the case of a proposition space SA which is generated by two propositions H and L, L now playing the role of the second hypothesis proposition. Upon receiving from B the information that LRB(E,H,\u00acH) = r with r > 0, A extends its proposition space to SA = SA(H,L) to SA(H,L,E). In order to have a belief function QA on this space extending the prior belief function PA on the prior proposition space SA, A must choose the following likelihoods: Q0A(E | H \u2227 L) = u, Q 0 A(E | H \u2227 \u00acL) = v, Q 0 A(E | \u00acH \u2227 L) = u\u2032, and Q0A(E | \u00acH \u2227 \u00acL) = v \u2032. These values must be chosen in such a manner that LRA(E,H,\u00acH) = r will hold. Therefore it is required that (with respect to QA):\n25Absence of chaining appears to be sufficient in many (though not all) forensic applications of LRTMR that have been documented to date.\nr = LRA(E,H,\u00acH) = LA(E,H)\nLA(E,\u00acH) =\nQ0A(E |H)\nQ0A(E | \u00acH)\n= QA(E \u2227H)\nQA(H) \u00b7\nQA(\u00acH)\nQA(E \u2227 \u00acH)\n= QA(E \u2227H \u2227 L) +QA(E \u2227H \u2227 \u00acL)\nQA(H) \u00b7\nQA(\u00acH)\nQA(E \u2227 \u00acH \u2227 L) +QA(E \u2227 \u00acH \u2227 \u00acL)\n= u \u00b7QA(H \u2227 L) + v \u00b7QA(H \u2227 \u00acL)\nQA(H) \u00b7\nQA(\u00acH)\nu\u2032 \u00b7QA(\u00acH \u2227 L) + v\u2032 \u00b7QA(\u00acH \u2227 \u00acL)\nThe following probabilities can be calculated: QA(E) = u \u00b7QA(H \u2227 L) + v \u00b7QA(H \u2227 \u00acL) + u\u2032 \u00b7QA(\u00acH \u2227 L) + v\u2032 \u00b7QA(\u00acH \u2227 \u00acL) and QA(E \u2227H) = u \u00b7QA(H \u2227 L) + v \u00b7QA(H \u2227 \u00acL).\nUpon receiving the information that (according to B) PB(E) = 1, A will perform Bayesian conditioning resulting in the posterior belief function Q\u0302A = Q 0 A(\u2022 | E). Calculating Q\u0302A(H) produces:\nQ\u0302A(H) = Q 0 A(\u2022 |E)(H) = Q 0 A(H |E) =\nQA(H \u2227E)\nQA(E)\n= u \u00b7QA(H \u2227 L) + v \u00b7QA(H \u2227 \u00acL)\nu \u00b7QA(H \u2227 L) + v \u00b7QA(H \u2227 \u00acL) + u\u2032 \u00b7QA(\u00acH \u2227 L) + v\u2032 \u00b7QA(\u00acH \u2227 \u00acL)\n= u \u00b7QA(H \u2227 L) + v \u00b7QA(H \u2227 \u00acL)\nu \u00b7QA(H \u2227 L) + v \u00b7QA(H \u2227 \u00acL) + u\u00b7QA(H\u2227L)+v\u00b7QA(H\u2227\u00acL) r \u00b7 QA(\u00acH) QA(H)\n= 1\n1 + 1r \u00b7 QA(\u00acH) QA(H)\n= r \u00b7QA(H)\n1 + (r \u2212 1) \u00b7QA(H)\n= r \u00b7 PA(H)\n1 + (r \u2212 1) \u00b7 PA(H)\nIt may be concluded that in the case of two generators for SA and an arbitrary guess for all new probabilities (upon introducing E as a new generator) local soundness (with respect to H) is obtained. Using a similar proof it can be shown that local soundness generalizes to an arbitrary number of generator for SA."}, {"heading": "4.3 Proposition kinetics for a proposition space with two generators: failure of global soundness", "text": "Global soundness is a different matter as will be found by considering an example. Calculating Q\u0302A(L) produces:\nQ\u0302A(L) = Q 0 A(\u2022 | E)(L) = Q 0 A(L | E) =\nQA(L \u2227E)\nQA(E) =\nu\u2032 \u00b7QA(H \u2227 L) + v \u00b7QA(\u00acH \u2227 L)\nu \u00b7QA(H \u2227 L) + v \u00b7QA(H \u2227 \u00acL) + u\u2032 \u00b7QA(\u00acH \u2227 L) + v\u2032 \u00b7QA(\u00acH \u2227 \u00acL)\nNow consider as an example the case that QA(H \u2227 L) = QA(H \u2227 \u00acL) = QA(\u00acH \u2227 L) =\nQA(\u00acH \u2227 \u00acL) = 1 4 . Then the requirement on u, v, u\n\u2032 and v\u2032 simplifies to: r = u+ v\nu\u2032 + v\u2032 , and\nQ\u0302A(L) simplifies as follows: Q\u0302A(L) = u\u2032 + v\nu+ v + u\u2032 + v\u2032 . Now choosing u\u2032 = v\u2032 = 13 and r = 3 2\nwe find u + v = 1, for instance u = 37 and v = 4 7 or alternatively u = 4 7 and v = 3 7 . In these two cases Q\u0302A(L) takes different values. In the first case Q\u0302A(L) = u\u2032 + v\nu+ v + u\u2032 + v\u2032 =\n1/3 + 4/7\n3/7 + 4/7 + 1/3 + 1/3 whereas in the second case: Q\u0302A(L) =\n1/3 + 3/7\n3/7 + 4/7 + 1/3 + 1/3 . It fol-\nlows that when SA has two or more generating propositions global soundness fails."}, {"heading": "4.4 Restoring global soundness without proposition kinetics: Bayesian conditioning followed by Jeffrey conditioning", "text": "The process specified in Paragraph 4.2 has two disadvantages: failure of global soundness, and pollution of the belief function with meaningless (guessed) values, due to the fact that the mere availability of a new likelihood ratio leaves open many degrees of freedom. The second disadvantage, however, is immaterial because the first issue stands in the way of chaining the reasoning pattern with subsequent reasoning steps taking the obtained posterior belief function as a prior.\nThe following process is plausible for A upon it receiving the information that trusted agent B\u2019s beliefs imply LR0B(E,H,\u00acH) = r. First use the new information on E in relation to H to compute a new (revised) belief p\u0302 in H according to the process as specified in Paragraph 4.1:\np\u0302 = r \u00b7 PA(H)\n1 + (r \u2212 1) \u00b7 PA(H)\nThis first step involves proposition kinetics. In the second step, however, the proposition space of A is not extended, instead merely a revision of the belief function is performed.\nRecall that Jeffrey conditioning (with parameter p on proposition H) works as follows\nP\u0302p,H = p \u00b7 P 0(\u2022 |H) + (1\u2212 p) \u00b7 P 0(\u2022 | \u00acH)\nThe revision of PA is found by the following application of Jeffrey conditioning:\nP\u0302A = P\u0302p\u0302,H = r \u00b7 PA(H)\n1 + (r \u2212 1) \u00b7 PA(H) \u00b7 P 0(\u2022 |H) + (1\u2212\nr \u00b7 PA(H)\n1 + (r \u2212 1) \u00b7 PA(H) ) \u00b7 P 0(\u2022 | \u00acH)\nThe two stage belief revision process just outlined produces a posterior belief state which may serve as a prior belief state for a subsequent reasoning step."}, {"heading": "4.5 Necessity of explicit background knowledge management", "text": "Assuming that only intermediate (auxiliary) proposition kinetics is applied and Jeffrey conditioning is used in order to integrate the newly found probability in A\u2019s belief function it turns out that the formalism allows a repetition of the same reasoning step. Therefore in addition to the two stage reasoning process an update of the background knowledge of A is needed which incorporates in A the fact that the beliefs of A have come about in part by making use of probabilistic information (quantified belief) regarding a proposition E which lies outside in the proposition space and the meaning of which is to be sufficiently specified as a part of\nA\u2019s background information as well. Assuming that the background database state is a set of information items the relevant update may be formalized as follows:\nK\u0302A = KA \u222a {(E,Ea)}\nHere (E,Ea) represents the information that a proposition named E, the content/meaning of which is specified as Ea, has been used during the development of the current belief function. The background information KA needs to be inspected (by A) whenever a new proposition E\u2032 may be considered for (possibly temporary) inclusion in the proposition space of A."}, {"heading": "4.6 Restoring global soundness using a family of proposition spaces and probability functions: \u201cBell inequalities in the law\u201d?", "text": "Instead of making use of a temporary extension of a reduct of the proposition space followed by Jeffrey conditioning, one may alternatively conceive of a generalization of the single proposition space with probability function representation of an agent\u2019s state of credences.\nQuantum mechanics makes use of precise probability functions while using families of proposition spaces (event spaces) and corresponding probability functions on the spaces. The Bell inequalities express by way of a mathematical criterion a property of such families which is met if integration into a single proposition space combined with a single probability function on it is possible. In case some Bell inequality is violated the family of event spaces and corresponding probability functions cannot be properly captured by a single proposition space/probability function combination.\nQuantum mechanics has given rise to many years of experience with a particular generalization of a model based on proposition spaces with precise probability functions on it. Whether or not that state of affairs is of any relevance for the foundations of forensic logic remains to be seen."}, {"heading": "5 Equivalence of two alternative approaches: Adams fol-", "text": "lowed by Bayes versus Bayes followed by Jeffrey\nAt first sight it seems that the case where E is contained in the proposition space of A is the more general case. Double likelihood Adams conditioning allows the independent processing, in terms of belief state revision by A, of an incoming likelihood ratio from B. If, however the subsequent phase of Bayes conditioning is included, the path involving proposition space kinetics turns out to be the more general one. Below it will be proven that both revision processes commute. I will first establish the equivalence of both approaches by way of direct calculation. Subsequently a concise manner of formulating this and other equivalences with the help of conditioning combinators is provided."}, {"heading": "5.1 An equational proof", "text": "Upon receiving a message LR0B(E,H,\u00acH) = r A may first create a second proposition space generated by H and E and proceed as in 4.1, thereby producing a posterior probability\np\u0302 = r \u00b7 PA(H)\n1 + (r \u2212 1) \u00b7 PA(H)\nfor H after Bayes conditioning in the auxiliary proposition space.\nNow SA containsE which allows Bayes conditioning on E, thus obtaining as an intermediate result Q = P 0(\u2022 |E). Subsequently Jeffrey conditioning with parameter p\u0302 and with respect to H may be applied to the intermediate probability function Q thus obtaining: Pp as follows:\nP\u0302 = p\u0302 \u00b7Q0(\u2022 |H) + (1\u2212 p\u0302) \u00b7Q0(\u2022 | \u00acH)\nP\u0302 is a plausible result of performing the combination of receiving a likelihood ratio r (for Ev\nand H) and a confirmation of E from the prior belief PA. We consider P\u0302 (x) for an arbitrary proposition x in SA:\nP\u0302 (x) = (p\u0302 \u00b7Q0(\u2022 |H) + (1\u2212 p\u0302) \u00b7Q0(\u2022 | \u00acH))(x)\n= (p\u0302 \u00b7 Q(\u2022 \u2227H)\nQ(H) + (1\u2212 p\u0302) \u00b7\nQ0(\u2022 \u2227 \u00acH)\nQ(\u00acH) )(x)\n= (p\u0302 \u00b7 P 0A(\u2022 \u2227H | E)\nP 0A(H | E) + (1 \u2212 p\u0302) \u00b7\nP 0A(\u2022 \u2227 \u00acH |E)\nP 0A(\u00acH | E) )(x)\n= (p\u0302 \u00b7 PA(\u2022 \u2227H \u2227 E) \u00b7 PA(E)\nPA(E) \u00b7 PA(H \u2227 E) + (1\u2212 p\u0302) \u00b7\nPA(\u2022 \u2227 \u00acH \u2227 E) \u00b7 PA(E)\nPA(E) \u00b7 PA(\u00acH \u2227 E) )(x)\n= (p\u0302 \u00b7 PA(\u2022 \u2227H \u2227 E)\nPA(H \u2227 E) + (1\u2212 p\u0302) \u00b7\nPA(\u2022 \u2227 \u00acH \u2227 E)\nPA(\u00acH \u2227 E) )(x)\n= (p\u0302 \u00b7 P 0A(\u2022 |H \u2227 E) + (1 \u2212 p\u0302) \u00b7 P 0 A(\u2022 \u2227 \u00acH \u2227E))(x) = p\u0302 \u00b7 P 0A(x |H \u2227 E) + (1\u2212 p\u0302) \u00b7 P 0 A(x \u2227 \u00acH \u2227 E) = r \u00b7 PA(H) \u00b7 P 0A(x |H \u2227 E)\n1 + (r \u2212 1) \u00b7 PA(H) + (1\u2212\nr \u00b7 PA(H)\n1 + (r \u2212 1) \u00b7 PA(H) ) \u00b7 P 0A(x \u2227 \u00acH \u2227 E)\n= r \u00b7 PA(H) \u00b7 P 0A(x |H \u2227 E)\n1 + (r \u2212 1) \u00b7 PA(H) + (\n1\u2212 PA(H)\n1 + (r \u2212 1) \u00b7 PA(H) ) \u00b7 P 0A(x \u2227 \u00acH \u2227 E)\n= r \u00b7 PA(H) \u00b7 P 0A(x |H \u2227 E) + PA(\u00acH) \u00b7 P 0 A(x \u2227 \u00acH \u2227E)\n1 + (r \u2212 1) \u00b7 PA(H)\nIt turns out that P\u0302 (x) is identical to Q\u0302l,l\u2032(x) as found in Theorem 3.4.1(4). This identity serves as confirmation of the validity each of both pathways which derive the same probability function on the same proposition space:\n\u2022 double Adams conditioning followed by Bayes conditioning and,\n\u2022 1. starting a new proposition space with generator H , the probability being taken from PA,\n2. proposition kinetics in the new proposition space adding E to it such that the acquired likelihood ratio fits,\n3. Bayes conditioning with proposition kinetics in the auxiliary workspace,\n4. extracting the posterior probability p\u0302 of H from the auxiliary proposition space (after Bayes conditioning),\n5. Bayes conditioning with proposition kinetics on the original (prior) proposition space of A,\n6. and finally Jeffrey conditioning (with respect to p\u0302 and H) on the result of the last step."}, {"heading": "5.2 Conditioning combinators", "text": "In order to better formulate the relation between different paths of application of conditioning operations the availability of a more explicit notation is useful. To that extent I will introduce combinators (function names) for various transformations on probability functions. It is assumed that proposition spaces are generated by a finite number of (names of) primitive propositions from a countable universal set \u03a3u of such names. In order to avoid speaking of pairs of a proposition space and a probability function it is assumed that the set of generators for the proposition space service as the domain of a probability function is encoded in it as follows: each probability function P is supposed to carry with it a finite set of proposition names \u03a3(P ) \u2282 \u03a3u. \u03a3(P ) is called the signature of P . For a sentence (i.e. propositional formula) \u03a6, \u03a3(\u03a6) denotes the set of proposition generators occurring in \u03a6, \u03a3(\u03a6) is the signature of Phi. Logically equivalent sentences may have different signatures, e.g. \u03a3(H \u2227 \u00acH) = {H} while \u03a3(\u22a5) = \u2205. E,H,M,N, and L are elements of \u03a3u.\n1. Id is the identity transformation,\n2. As an operator on probability functions Bayes conditioning without proposition kinetics relative to M is denoted with BCM . If M \u2208 \u03a3(P ) then BCM (P ) = PSA (\u2022 | M). Safe conditional probability PS(\u2212|\u2212) is used instead of P 0(\u2212|\u2212) in order to make sure that the result is a probability function in all cases.\n3. Signature extension combinators (that is combinators for proposition space expansion) are denoted PSE with additional parameters. Tho specific instances of parametrized proposition space expansion are named as well as symmetric proposition space expansion.\n(a) PSEM,1 extends the probability space with an additional generator M (while leaving it unchanged if M is present) and extends the probability function by setting P (M) = 1,\n(b) PSEM,0 extends the probability space with an additional generator M (while leaving it unchanged if M is present) and extends the probability function by setting P (M) = 0,\n(c) PSEM,1/2 extends the probability space with an additional generator M (while leaving it unchanged if M is present) and extends the probability function by way of symmetric extension.\n4. Proposition space reduction PSRM removes a generator M (when present leaving the proposition space and probability function unchanged otherwise), and transforms the probability function to its restriction to the reduced proposition space. Examples and illustrations:\n\u2022 PSRM \u25e6 PSEM,0 = PSRM \u25e6 PSEM,0 = PSRM \u25e6 PSEM,1/2 = Id,\n\u2022 If M \u2208 \u03a3(P ) then \u03a3(PSRM (P )) = \u03a3(P )\u2212 {M},\n\u2022 Bayes conditioning (relative to M) with proposition kinetics is denoted by: PSRM \u25e6 BCm \u25e6 PSEM,1.\n\u2022 Bayes conditioning relative to a sentence \u03a6 is denoted BC\u03a6. For defining BC\u03a6 special care must be taken if \u03a3(\u03a6) 6\u2282 \u03a3(P ). Suppose M \u2208 \u03a3(\u03a6) \u2212 \u03a3(P ), then BC\u03a6 = PSRM \u25e6 BC\u03a6 \u25e6 PSEM,1. Repeated application of this rewriting may be needed if more generators in \u03a3(\u03a6) are not in \u03a3(P ).\n5. Jeffrey conditioning with respect to p and M is denoted JCp,M . As a defining equation one may use: JCp,M = (\u03bbPs.t. H\u2208\u03a3(P ) p \u00b7 P S(\u2022 |M) + (1\u2212 p) \u00b7 PS(\u2022 | \u00acM)) \u25e6 PSEM,1/2.\nI will adapting the Jeffrey notation to second order arguments, by writing \u22c6 as a placeholder for a probability function, and using t(\u22c6) = \u03bbP.t(P ), while the appropriate signature of P is derived from the context. Using second order Jeffrey notation this equation may be rewritten, slightly informally as follows:\nJCp,M = (p \u00b7 \u22c6 S(\u2022 |M) + (1\u2212 p) \u00b7 \u22c6S(\u2022 | \u00acM)) \u25e6 PSEM,1/2\n6. Single likelihood Adams conditioning is written SLACl,E,H with the defining equation:\nSLACl,E,M (P ) = P (H \u2227E\u2227\u2022) \u00b7 l\nPS(E |H) +PA(H \u2227\u00acE\u2227\u2022) \u00b7\n1\u2212 l\nPS(\u00acE |H) +P (\u00acH \u2227\u2022)\n7. Double likelihood Adams conditioning is written DLACl,l\u2032,E,H,\u00acH with the defining equation:\nSLACl,E,M (P ) = P (H \u2227 E \u2227 \u2022) \u00b7 l\nPS(E |H) + P (H \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\nPS(\u00acE |H) +\nP (\u00acH \u2227 E \u2227 \u2022) \u00b7 l\u2032\nPS(E | \u00acH) + P (\u00acH \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\u2032\nP 0A(\u00acE | \u00acH)"}, {"heading": "5.3 Rephrasing some results with the help of of conditioning combinators", "text": "Assuming r = ll\u2032 and r > 0, Theorem 3.4.1 (5) can now be reformulated as follows:\nTheorem 5.3.1.\n(BCE \u25e6DLACl,l\u2032,E,H,\u00acH \u25e6 PSEE,1 \u25e6 PSEH,1)(\u22c6)(H) = r \u00b7 (\u22c6 \u25e6 PSEH,1)(H)\n1 + (r \u2212 1) \u00b7 (\u22c6 \u25e6 PSEH,1)(H)\nThe local consistency of repeated single likelihood Adams conditioning followed by Bayesian conditioning may be formulated as follows:\nTheorem 5.3.2.\nBCE \u25e6 SLACl\u2032,E,\u00acH \u25e6 SLACl,E,H \u25e6 PSEE,1 \u25e6 PSEH,1 = r \u00b7 (\u22c6 \u25e6 PSEH,1)(H)\n1 + (r \u2212 1) \u00b7 (\u22c6 \u25e6 PSEH,1)(H)\nThe equivalence of double likelihood Adams followed by Bayes and parallel Bayes followed by Jeffrey as calculated in Paragraph 5 above can be formulated thus:\nTheorem 5.3.3.\nPSRE \u25e6BCE \u25e6DLACl,l\u2032,E,H,\u00acH \u25e6 PSEE,1 \u25e6 PSEH,1 =\nPSRE \u25e6 JCBCE\u25e6DLACl,l\u2032,E,H,\u00acH (\u22c6))(H),H((BCE \u25e6 PSEE,1 \u25e6 PSEH,1)(\u22c6))"}, {"heading": "6 MOE-side aspects of LRTMR", "text": "In this section using the abstract presentation with A and B is instantiated with TOF for S and MOE for B in order to provide more intuitive guidance.\nMOE, the mediator of evidence is supposed to provide information to TOF which is helpful for TOF to converge towards a state of belief from which either subsequent reasoning is possible or from which binary conclusions can be drawn, the latter being best suited for export to agents external to the reasoning processes.\nMOE may contemplate the use of a repertoire of communications or messages to TOF. A listing op options is helpful. The messages will be tagged with a generic agent B, which may be instantiated with TOF.\n1. \u201cLB(E,H) = l\u201d (for a closed rational number expression l with 0 < l \u2264 1) is the message that the likelihood of evidence proposition E with respect to hypothesis proposition H is equal to l,\n2. \u201cLB(E,\u00acH) = l\u201d (for a closed rational number expression l with 0 < l \u2264 1) is the message that the likelihood of evidence proposition E with respect to negated hypothesis proposition H is equal to l,\n3. \u201c(LB(E,H) = l, LB(E,\u00acH) = l\u2032)\u201d (for closed rational number expressions l, l\u2032 with 0 < l, l\u2032 \u2264 1) is the message that the likelihood pair of evidence proposition E with respect to hypothesis proposition H is equal to (l, l\u2032),\n4. \u201cLR0B(E,H,\u00acH) = r\u201d (for a closed rational number expression r with 0 < r \u2264 1) is the message that the likelihood ratio of evidence proposition E with respect to hypothesis proposition H is equal to r,\n5. \u201cPB(E) = 1\u201d is the message that B considers evidence proposition E to be true.\n6. \u201cLR0B(E,H,\u00acH) = r & PB(E) = 1\u201d is the combined (simultaneous) message that includes both \u201cLR0B(E,H,\u00acH) = r\u201d and \u201cPB(E) = 1\u201d (which are supposed to reach A simultaneously).\nActions of the form sndB\u2192A(\u201cm\u201d) may performed by agent B resulting in the asynchronous 26 and eventually successful transfer of the message \u201cm\u201d to agent A (in the role of TOF). MOE has some internal actions, notably finding out likelihoods in advance of transferral. findB(L(E,H) = l) represents the action of B coming to the belief that P\n0(E | H) should be given value l. Similarly findB(LB(E,\u00acH) = l) represents the action of B coming to the understanding that P 0(E |\u00acH) should be given credence l. The action confirmB(E) represents B\u2019s becoming aware that E must be considered a fact.\nB can carry out its task in many ways and I will consider only two options for the behaviour of B, thereby limiting attention to the transfer of a likelihood ratio."}, {"heading": "6.1 Single message reporting by MOE", "text": "The simplest idea is that in a single message MOE reports to TOF.27 The report is transferred by a single asynchronous send action:28\nsndMOE\u2192TOF(\u201cLRMOE(E,H) = r\u201d & \u201cPMOE(E) = 1\u201d)\nThis behaviour of MOE is plausible in that an expert report may well be a single document (assuming that no subsequent interview is part of the process). Under these assumptions the following conclusions can be drawn:\n\u2022 MOE is not reporting its current (at the time op sending) beliefs. Indeed if PMOE(E) = 1 then according to the probability axioms also LRMOE(E,H) = 1. The case that r = 1 cannot be excluded, but if r = 1 it is whole interaction with TOF is redundant, and a modified protocol would raise an exception or interrupt so as to effect premature termination without making any attempt to make TOF revise its beliefs.\n\u2022 MOE is reporting a mix of current and past beliefs. The quality of the message improves if timing tags for the two items indicate in which order MOE has revised its beliefs. Here it is important that \u201cPMOE(E) = 1\u201d occurred after MOE becoming aware of the likelihoods that make up the likelihood ratio reported as r.\n\u2022 Subjective belief theory cannot explain the behaviour of MOE. Something else is required, be it lightweight use of temporal logic, or sequential ordering of the progression of belief revisions (of MOE).\n26An asynchronous message may arrive later than it was sent. A synchronous message arrives at the same time. The price paid for synchrony is that sending a message may be delayed until the intended recipient is able to receive the message. The process algebra ACP of Bergstra & Klop [7] provides synchronous messaging as the primary communication mechanism, with asynchronous messaging as a rather more complex derived feature. Synchronous messaging plays an role in computer science in spite of the fact that it is rather counterintuitive. In the context of this paper and for the specification of the interaction between TOF and MOE the use of synchronous messaging would be simpler. I have refrained from doing so because it is a somewhat unfamiliar mechanism outside computing.\n27It is assumed that a message may also contain explanatory text, but that part of the content is ignored at the level of abstraction envisaged in this paper.\n28In Willis et al. [49] (ENFSI guideline for evaluative reporting in forensic science) extensive mention is made of the imperative that a likelihood ratio must be included in the report of a forensic expert. Confusingly the term evidence is not used at all and its use is suggested to be a matter of lawyers only. It is suggested that evidence is not part of FE reporting. As a remarkable consequence (as far as I understand) FE should not speak of the weight of evidence either. It is unclear from this guideline if it advises (in the simplest case) MOE to make use of to what I am calling single message reporting.\n\u2022 Inclusion of temporal logic in the formalism, thereby moving from a model with single belief functions to a model accommodating progressions of belief functions, may be needed.29\n\u2022 Ignoring the controversy regarding whether or not it is plausible that MOE reports precise values for a likelihood ratio, it appears that an underlying theory for the behaviour of a (single statement reporting) MOE cannot straightforwardly be based on subjective probability theory with precise belief functions."}, {"heading": "6.2 Sequential multiple message reporting for MOE", "text": "Instead of issuing a single message the introduction of a sequential ordering in the behaviour of MOE is an option too. In the present setting MOE\u2019s issuing of two or three consecutive messages may be contemplated:\n\u2022 Two consecutive messages each containing a likelihood (both likelihoods forming a pair which is asynchronously transferred. (If this happens MOE may move through two consecutive Adams conditioning steps which serve to revise its beliefs in such a manner that its messages to TOF are in accordance with its beliefs at the moment of sending.)\n\u2022 two consecutive messages each containing a likelihood (both likelihoods forming a pair which is asynchronously transferred) followed by a message reporting the truth of the evidence proposition (evidence message). In this case too, MOE may successively revise its beliefs so that its reporting messages are in both cases in accordance with its beliefs.\n\u2022 a message containing a likelihood pair followed by an evidence message. MOE may in both cases report in accordance with its beliefs.\n\u2022 a message reporting a likelihood ratio followed by an evidence message. MOE may in both cases report in accordance with its beliefs.\nIn each of these cases compliance with the concept of subjective beliefs as encoded in precise probability functions can be obtained to the extent that MOE at each stage reports about its current beliefs at the time of reporting. Only if likelihood information is packaged with evidence information adherence to this principle is called in question.\nFor modelling the paralel composition of TOF, MOE, and other agents each of which are supposed to operate in a sequential fashion in a predetermined workflow, the thread algebra with strategic interleaving of Bergstra & Middelburg [9] may be used.30"}, {"heading": "6.3 Parallel decomposition of MOE: MOE-LR and MOE-E", "text": "An alternative to assuming sequential behaviour for MOE is to expect MOE to operate as if it effectuates a parallel composition of parts of the behaviour of MOE. The simplest workflow\n29The \u201ccosts\u201d of this extension, in terms of added complexity to the logic must not be underestimated. The temporal logic of beliefs in combination with conditionalization (e.g. Jeffrey conditionalization) is a strikingly difficult topic. Weisberg\u2019s paradox (Weisberg [48] and the analysis of it in Huber [24] provide an indication of the complications involved.\n30The computing literature offers a multitude of modelling techniques able to deal with such circumstances. Thread algebra ([9]) has been designed as a theoretical tool allowing being incorporated in other frameworks in a lightweight manner.\nfor these tasks places the sending of likelihoods or a likelihood ratio in parallel with the task of transferring an evidence proposition. A simple workflow assigns both tasks to independent agents, together realizing the functionality of MOE. I will use ACP style process algebra notation from Bergstra & Klop [7] for lightweight workflow description.\nThe architecture of MOE is as follows: MOE = MOE-LR \u2016 MOE-E. Further MOE-LR is the sequential compositions of three actions:\nMOE-LR = setMOE-LR(LMOE-LR(E,H) = l)\u00b7 setMOE-LR(LMOE-LR(E,\u00acH) = l\u2032)\u00b7 sndMOE-LR\u2192TOF(\u201cLRMOE-LR(E,H,\u00acH) = l/l\u2032\u201d).\nThe behaviour of MOE-E consists of two actions:\nMOE-E = confirmMOE-LR(E)\u00b7 sndMOE-LR(\u201cLRMOE-LR(E,H) = r\u201d).\nIt must also be explained how MOE-LR and MOE-E each (independently) revise or update the respective beliefs. For MOE-E it is assumed that its proposition space is generated by E. A prior belief PMOE-E(E) = p is assumed with p a rational number expression so that 0 < p \u2264 1. Upon performing confirmB(E), MOE-E performs Bayes conditioning thus reaching a belief state with PMOE-E(E) = 1.\nFor MOE-LR the situation is slightly more involved. Assuming that its proposition space is generated by H and E a prior belief needs to be installed which ensures that: PMOE-LR(\u00acH), PMOE-LR(H), and PMOE-LR(E) each are nonzero.\nUpon performing setMOE-LR(LB(E,H) = l) single likelihood Adams conditioning is applied (see Paragraph 3.3) and subsequently upon performing setB(LMOE-LR(E,\u00acH) = l\u2032) single likelihood Adams conditioning is applied once more. According to Theorem 3.3.1 (4) a belief state is reached in which LRMOE-LR(E,H,\u00acH) = l/l\u2032 = r.\nThe following conclusions can be drawn:\n\u2022 When reporting by MOE is split in two independent components (MOE-LR for transferring the likelihood ratio, and MOE-E for transferring the fact that the evidence proposition has been confirmed) each of the two components may communicate its current (at the time of sending) beliefs.\n\u2022 Moreover an explanation of the internal belief revision history of both components may be given by means of single likelihood Adams conditioning steps, and the correctness (compatibility with the component\u2019s current beliefs) of the transferred likelihood ratio can be shown.\n\u2022 The situation is about the same if instead of a likelihood ratio MOE-E transfers a likelihood pair (when packaged in a single message).31\n\u2022 Only under the assumption that MOE is decomposed into independent parallel subagents (each performing single message reporting) each of which will be maintaining private belief states, the entire LRTMR protocol can be understood in terms of subjective probabilities with precise values.\n31On the transfer of likelihood pairs: Robertson, Vignaux & Berger in [34] (p. 447) indicate that it has become standard (in paternity cases) that a likelihood ratio is conveyed in addition to the underlying likelihood pair. Morisson & Enzinger [30] suggest to distinguish between Bayes factor and likelihood ratio and both notions may have disparate relations with the respective underlying pairs.\n\u2022 If likelihoods pairs are transferred asynchronously by MOE so that TOF may receive these at different instants of time and so that two single likelihood Adams conditioning steps must be applied by TOF the situation depends on whether or not E is included in the proposition space of TOF.32 If so, then Bayesian conditioning by TOF (upon obtaining confirmation of the evidence proposition) will be locally sound but it may not be globally sound. In the case that the evidence proposition is not included in the (prior) proposition space of TOF, global soundness can be achieved if TOF first works with a (new and temporary additional) proposition space generated by H and E and then applies Jeffrey conditioning with the posterior probability found for the hypothesis proposition in the temporary proposition space. Together these observations imply that in all cases it suffices for MOE to communicate a likelihood ratio (or equivalently a synchronous likelihood pair) and that in some cases this is to be preferred over the successive (asynchronous) transferal to TOF of the two components of a likelihood pair."}, {"heading": "6.4 Improved workflow description", "text": "The workflow specified by MOE = MOE-LR \u2016 MOE-E features a significant weakness. It fails to guarantee that the LR is transferred before the evidence is conveyed. This fault can be repaired by introducing a notification message from MOE-LR to MOE-E, which tells MOE-E that the LR has been sent, such that MOE-E may delay sending its message until the notification from MOE-LR has been received. Such protocols may easily be specified in process algebra notation."}, {"heading": "6.5 Conclusions I: consistency of LRTMR with the precise belief assumption", "text": "At this stage three conclusions can be drawn from the work in this paper. To the best of my knowledge these conclusions are novel:\n1. Under the assumption that MOE may either sequentially or in parallel split its activities so that transferal of likelihoods (single likelihoods in succession, or likelihood pairs or likelihood ratio\u2019s) is either made independent of (parallel decomposition of MOE) or performed before sending information about the validity of the evidence assumption, then the interaction between TOF and MOE can be described in accordance with the assumption of precise beliefs.33\nThe novelty of this result lies in the fact (i) single message reporting by MOE is at odds with the idea that MOE always faithfully reports its current beliefs, while (ii) the\n32There is no need for TOF to disclose to MOE the size and/or content of its (TOF\u2019s) proposition space. 33\n2. Perhaps redundantly repeating the argument for this position: subjective belief theory with precise probabilities does not easily apply to how MOE (that is the forensic expert) is to deal with its own development and revision of beliefs, at least not in the case that MOE uses single message reporting including both likelihood information and evidence information. If MOE uses single message reporting, it follows from the account of MOE side reasoning in Paragraph 6.1 above that MOE is by necessity not reporting on its actual beliefs and not even on any of its past belief functions (whether precise or not). Instead (when performing single message reporting) MOE must be reporting on the timed development of its beliefs, taking different timestamps into account and including reporting beliefs which have become entirely outdated at the time of reporting.\ninteraction between TOF must be such that the reception of both likelihoods (pair or ratio) is performed (bay way of Adams conditioning) in advance of the processing of reception of the evidence proposition (by way of Bayes conditioning).\n3. In addition to the above first conclusion on the (conditional) consistency of the entire framework it may be stated that transferal of a likelihood pair (or equivalently of successive likelihoods) is preferable over transferral of a likelihood ratio for the following reasons. After transferal of a likelihood pair a unique posterior state can be found without the need to perform Bayesian conditioning, a step which may be postponed, moreover, by first processing the implications for TOF of receiving likelihood information from MOE the focus on revising the entire probability function (rather than merely revising its value on the hypothesis proposition on which the likelihoods have been based.\n4. If one insists that MOE performs single message reporting including both likelihood information and information confirming the validity of the evidence proposition then the mentioned consistency of the framework with the reasoning patterns at hand brakes down and a different semantic model must be sought, for instance by including progressions (histories with explanation) of belief functions as components of credal states, thus departing from the standard model by way of refinement."}, {"heading": "7 Potential implications for forensic logic", "text": "LRTMR came to prominence in forensic science where its role as a cornerstone of forensic logic is as yet undisputed. In this Section I intend to survey which implications the results obtained in the preceding Sections might have regarding forensic logic.\nIt is plausible that subjective probability has come to stay in the area of forensic reasoning. Under that assumption one may ask these two questions: (i) how close the form of subjective probability theory eventually applied in forensics will be to the views originally set out by de Finetti and Lindley, and (ii) to what extent other perspectives on probability will be eventually accommodated in a coherent picture.\nI will assume from the outset (but without proof) that some form of managed coexistence of disparate paradigms on probabilities constitutes a promising path forward."}, {"heading": "7.1 Theoretical requirements on probability theory for LRTMR", "text": "Extensive research has been devoted to the development of viewpoints regarding forensic logic(s). These views are not specific for forensics and may generalize to an arbitrary setting where LRTMR may be of use. Finding one\u2019s way in that area is made difficult in the light of the fact that quite fundamental differences of opinion turn out to matter in practice. Let\u2019s consider physics for a moment, in order to look for some possibly informative parallels. An appreciation of physics may be partially unachievable for a layman in view of his or her mere inability to understand wave particle duality or to understand how the big bang was itself the beginning of time and space, or to understand how and why the universe may be curved and may possibly even be finite, or to understand the (idea of) a (conceivable) distinction between matter and dark matter.\nIn the area of forensic logic a prominent counterpart to these conceptual complexities in physics stems from the seemingly unbridgeable discrepancy between physical probabilities34 and subjective probabilities. Apparently it is a generally accepted hypothesis that mathematically speaking these two mechanisms for measuring uncertainty are somehow the same. This remarkable hypothesis dominates the development of forensic logic.\nAs a counterpart to some of these famous issues in physics, the contrast between two understandings of probability may make a rather unglamorous impression. But once one has been confronted with a non-trivial application of courtroom reasoning including the modern practice of providing forensic evidence to the Court by way of Bayesian statistics reasoning, one will become convinced instantaneously that this particular contrast is very important in daily life, that it is conceptually fascinating, and that it is in no way less fundamental than the contrasts or dualities rooted in physics."}, {"heading": "7.2 Frequentist versus subjectivist duality", "text": "Probability has both subjective and frequentistic (physical) aspects. There is no reason to expect or to wish that one of these two views (or any of the views in between that have been developed thus far) would, on the basis of philosophical reflection alone, emerge as a victorious perspective on the concept of probability, thereby merely leaving for the other interpretation a highly praised role as an outdated stage in the history of science.\nThis position has an immediate bearing on some discussions in forensic science. I consider every argument which is based on the alleged superiority of one of these views as flawed beyond repair. Flawed arguments may lead to valid conclusions, however, and that very phenomenon seems to apply in some of the positions in current debates regarding the foundations of forensic logic.\nIn forensic logic, and more generally wherever LRTMR (or LPTMR) may apply, there appears to be room for both perspectives on probability. This position intentionally leaves room for worries such as formulated in Risinger [33] (p. 9) \u201cthat likelihood ratios would be guessed because of the permissiveness for substituting opinion for fact which subjectivism would allegedly grant a forensic expert\u201d. Distrust of the notion of subjective probability may promote the idea that a frequentist viewpoint provides a self-explanatory conceptual framework. That position, however, is an illusion, as is witnessed by the circumstance that even gaining an understanding of the fair binary coin leads to significant theoretical complexity (e.g. in Belot [2]).\nIn Paragraphs 7.6 and 7.8 below a specific instance for the duality between a frequentist view of probability and subjectivism is put forward: instead of single and precise belief functions the suggestion is made to work with finite sets of belief functions, leaving aside the feature of including progressions and families. Rather than to include in the value (or presentation) of a belief function information about the statistical aspects of observations and calculations which gave rise to the specific value (of the function) another way of providing additional information is sought. By allowing finite sets of belief functions to be produced and transferred by MOE to TOF, MOE may present a collection of information items which as whole allows statistical processing and which in total features some statistical properties that MOE deems essential\n34In Strevens [39] this terminology is discussed in some detail. Frequentistic probabilities are subsumed under the category of physical probabilities in [39].\nfor sound judgement of the case (by TOF) and which at the same time MOE finds impossible to express in a single belief function.35"}, {"heading": "7.3 Imprecise beliefs: ignorance enters the picture", "text": "Imprecise belief modeled by way of non-singleton representors can be traced back to Keynes (see Weatherson [44]), and features explicitly in Levi [26] with subsequent work in e.g. Voorbraak [42], Weatherson [45, 46] and Rens [32].36 Imprecise belief is supposed to enable the incorporation of ignorance into a framework primarily meant to deal with uncertainty. Biedermann [13] provides a recent exposition and justification of the by now classical viewpoint that ignorance is merely a variation on the theme of uncertainty, which for that reason is fully representable in a single and precise belief function, if not in general then at least in the context of forensic reasoning.\nLikelihood ratio transfer mediated inference for precise beliefs is a topic belonging to belief revision theory. It is remarkable that the central tenets of mainstream belief revision theory as incorporated in AGM style belief revision have not found a noticeable audience in forensics. Probabilistic AGM theory, an adaptation of AGM theory which contemplating its application in forensics would necessitate anyhow, has been developed in Voorbraak [42] and in Suzuki [40]. Replacing Bayesian conditioning by Jeffrey conditioning, so as to never set any probability to 0 as the effect of conditionalization, a state from which recovery via Bayesian conditioning is unfeasible, allows to simulate the options for backtracking that AGM style belief revision provides. This detour, however, seems to allow only an unnatural way to incorporate some of the results of the vast body of research on AGM style belief revision in forensic reasoning. AGM style belief revision makes use of sets in a way that renders it closer to dealing with ignorance than to dealing with the precise representation of quantified beliefs.\nThe restriction to precise belief states seems to be increasingly considered to constitute a source of practical problems by authors in forensic science. For instance in Morisson & Enzinger [30] and in Sjerps et al. [37] the case is made that a likelihood ratio ought to be reported by an MOE as a value equipped with resolution and precision. From the perspective of a theoretical account of beliefs a suggestion of this nature means no less than leaving the restricted area of precise probability functions and making the move towards significantly more complex semantic models of inference in the presence of ignorance in addition to uncertainty."}, {"heading": "7.4 Conclusions II: some informal and preliminary obseervations", "text": "In spite of the disclaimers mentioned in Paragraph 1.2, I have tried to draw some preliminary conclusions from the results of this paper.\n1. Is is reasonably clear (from the results obtained above) why likelihood ratios have a\n35In other words, although statistical processing at MOE side of a collection of belief functions may result in a valuable data reduction, the resulting outputs, such as values within an interval are not compatible with the probability calculus at hand. Instead of doing statistics before handing over the data to TOF, TOF is sent a representative sample of data so that TOF may itself perform statistical processing in a later stage of its activity. Maintaining finite sets of belief functions as a supportive tool for TOF undoubtedly requires that dedicated automated support is available.\n36Verbal likelihood ratio scales (see Marquis et al. [29]) seem to constitute an approach based on imprecise values, but the authors strongly insist that verbal scales must not be understood or used in that manner.\npreferred status in the communication from MOE to TOF, over synchronous or asynchronous likelihood pairs. Under all modes of interaction between TOF and MOE, which have been considered, the transferral of likelihood ratios suffices for achieving unambiguous reasoning. In particular, after TOF receives a likelihood ratio r = LR0(l, E,H,\u00acH) then TOF can apply double likelihood Adams conditioning in advance of subsequent Bayes conditioning. This ability to incorporate r into the belief function represents an important ability of precise belief functions to grasp incoming data.\n2. The tradition that seems to have evolved into forensic science of speaking of propositions instead of events makes sense in the light of \u201cproposition\u201d carrying with it a connotation of source level assertions while \u201cevent\u201d may come with the connotation of activity level assertions. During the initial phase when source level assertions were the main carrier of Bayesian reasoning in court this confusing bias of the notion of an event space might have been unhelpful indeed. However, to the effect that event spaces have become ignored in nearly all presentations of the subject, perhaps being considered a residue of overly formalistic approaches to probability theory, that is unhelpful for communication to an audience of legal practitioners. I conclude that the concept of a proposition space (or a space of sentences) must be taken on board as soon as event spaces are left unmentioned.\n3. Stating these matters differently: it seems to be the case that subjective probability theory with precise beliefs (as promoted in the Lindley framework) is biased towards providing a tool as well as an explanation of TOF side reasoning.\nThe conception that MOE side reasoning (when explaining single message reporting) is philosophically understood as an easy to define mix of dogmatic subjective probability with temporal logic is problematic in the light of the complications discovered by Weisberg in [48].\n4. Taking a specific philosophy of probabilities (beliefs) as a definite point of departure and subsequently providing an interpretation of current and forthcoming reasoning processes of relevance in certain areas (e.g. in forensics) in terms of that specific philosophy is not the most natural approach for someone (like me) coming from the theory of computer science. An alternative approach is to view the account made in this paper (or an alternative account for that matter) as a calculus which is in need of so-called semantics.\n5. Precise probability functions over a finite proposition space are very much the sort of mathematical entity of which semantical models in computing are construed. Computer science makes use of vastly more intricate models, however, mixing uncertainty with ignorance as well as incorporating explicit perspectives on time and causality. Introducing as a principled idea the perception that a single model would be the final end of the story, primarily justified by its perceived intrinsic intellectual strength, would constitute no less than a self-inflicted endpoint of the theory of computer science. For example computer science theory cannot possibly incorporate quantum computing unless it allows for the revision of its conceptual models, however much these models with roots in the thirties (just as formalized subjectivism) have become glorified as \u201cthe real story of computing\u201d.\n6. Finding a semantic model for a given and useful calculus (or for a computer program notation) may still be remarkably hard even if these so-called natural phenomena occur in every computing device known to date. If one understands the area of LRTMR reasoning\npatterns as a calculus in need of a semantic model, the computer science tradition does not suggest that the envisaged model will be easy to find, on the contrary.\n7. The Lindley framework is satisfactory for analysing TOF side reasoning but is felt as being too abstract by some (but not all) representatives at the side of MOE (i.e. FE), with authors including Morrison, Enzinger, Risinger, and Sjerps.\nHere it is assumed that (i) models based on imprecise beliefs are less abstract than models based on precise beliefs, (ii) reporting likelihood ratios with resolution and or precision (and viewing these as approximations) requires the provision of additional information to a single value (which makes the models more concrete, i.e. less abstract), (iii) working with (an thinking in terms of) approximations of likelihood ratios has the same effect of lowering the level of abstraction.\n8. Asking TOF to work on lower level of abstraction is not straightforward, working with intervals is not straightforward in calculational terms. Nevertheless: TOF side research might well focus on finding a model at the lowest level of abstraction (which still works) so as to maximise the options for mutual understanding with MOE side representatives.\n9. Theory of computer science has acquired important pieces of advise on this matter: (i) finding the one semantic model that works for each and every case has turned out to be wholly impossible, (ii) hybrid models which use different levels of abstraction for (the understanding and analysis) of different parts of a system are becoming a necessity, (iii) it takes many years for the best (most useful) semantic models to emerge, these are not always the most natural one\u2019s, (iv) theoretical models are judged on the basis of the engineering implications of adopting such models.\n10. There is as yet no proof of a necessity to analyze and explain TOF and MOE at the same level of abstraction. It is conceivable that the interaction between TOF is best understood with an account that uses a lower level of abstraction at MOE side than at TOF side. Such an account makes use of a heterogeneous semantic model."}, {"heading": "7.5 Meta-axioms for the design of semantic models for a probability calculus based reasoning framework", "text": "Restriction to homogeneous semantic models may be understood as a possible meta-axiom on semantic modelling: the homogeneity axiom (on semantic models for LRTMR style reasoning) requires that all agents can make use of the same conceptual (logical mathematical) modelling of their credal states.\nFor the development of theory it is plausible to assume semantic homogeneity until the point that it becomes provably unsustainable or clearly unattractive (if that point is reached at all). There are other meta-axioms which may be adopted: the timestamp axiom states that when agents report beliefs or quantities based on beliefs (such as likelihoods) such reporting must be faithful to the agents current beliefs at the time of reporting.\nA third useful meta-axiom is the instantaneous revision response axiom which states that upon receiving information that bears on its partial beliefs as encoded in the representor of its credal state (whatever form of representor is used) a belief revision must be performed by the receiving agent without delay and in advance of any subsequent communication with other agents.\nA fourth meta-axiom is adoption of Lewis\u2019 new principle (see e.g. Weatherson [47]. This assertion rephrases the older Lewis principal principle, which asserts that a chance (probability in the sense of a frequency) may be taken for a belief of equal degree."}, {"heading": "7.6 Modelling bounded ignorance with pointed finite sets of mutually compatible precise belief functions", "text": "An intermediate position between strict application of subjective probability theory with precise beliefs, and a quite liberal use of imprecise beliefs (which according to several authors is outright incompatible with subjective belief theory), may be found as follows.\n1. Instead of working with single precise belief functions TOF (and MOE) may as well work with finite sets of candidate (precise) belief functions. Such sets are finite representors. Given a finite representor each of its elements is a belief function on the same shared proposition space. Two belief functions are mutually compatible if the same propositions have probability zero.\nRevisions and transformations are in each step performed on all members of the set. For this to be possible it is required that alle members are mutually compatible. If MOE sends sets of information packages on its candidate belief functions to TOF this will give rise to a Cartesian product of options (and thereby risking a combinatorial explosion), as for each candidate belief function of TOF a set of revision options appears. There will be an exponential growth of the number of candidate belief functions in the number of sequential reasoning steps of a legal argument. With appropriate computer support for TOF this explosion of data creates no problem at all.\n2. In order to make sure that the model is less abstract than the model with precise beliefs it is assumed that the finite representors are pointed, i.e. that a designated element exists. When two such representors are combined it is the combination of both pointed elements that will become the ponited element of the resulting representor.\n3. Instead of determining a final verdict TOF may apply some for of majority voting: if a significant fraction, in excess of some threshold, of candidate belief functions indicates a certain verdict with a sufficiently high belief TOF may feel sufficient support for a verdict in that direction, even without selecting one of the candidate belief functions as the one it will finally adopt.\n4. Working with finite representors is a lightweight form of adding ignorance to uncertainty: no probability intervals are used, all revision rules are immediately taken from the case of precise probability functions, there is no shift from questions concerning the precision of values of a probability function to equally difficult questions about the precision and nature of interval bounds.\n5. Reporting a finite representor, however, allows MOE to work with a set of candidate information packages \u201cwhich has the right statistics\u201d. In spite of the potential presence of a combinatorial explosion I expect that there is no practical objection against the use of say 100 candidates per reasoning step."}, {"heading": "7.7 Pointed finite sets of finite progressions of precise belief functions", "text": "Allowing finite sets of belief functions will not solve the deeper problem that a single message reporting MOE cannot be reporting about its current or past (single) state of belief. MOE reports about the successive development stages of its belief function at least in two stages: having determined a likelihood ratio, and successively having confirmed the truth of the evidence proposition. In order to take this complication into account a state of belief must contain a set of candidate progressions of belief functions.\nLeaving the pointing out gives rise to a somewhat more abstract semantic model, for which the relation to the model with precise beliefs (singleton representors) is not immediately clear.\n1. A progression is a sequence of (successive) belief functions. A progression supposedly represents the development in time through successive revision steps of an agent\u2019s precise belief function. A limitation to finite progressions is plausible in this context.\n2. All progressions in a finite set of candidates must have the same \u201carchitecture\u201d, determined by the chain of reasoning patterns that has been used, that is the same steps are taken, though the priors, or the inputs from MOE side, may differ for different candidates. Different progressions only differ in the quantitative values of the belief functions involved.\n3. Allowing sets of candidate progressions with a uniform revision pattern as representors of states of belief (now including some aspect of ignorance) together with a prescript on how to extract information from a progression into a report from MOE and how TOF may make use of such reported information for effectuating revisions, seems to provide a semantic model for LRTMR that (ii) satisfies the needs of both TOF and MOE, (ii) technically complies with the ideas of PT+PBA, (iii) is philosophical defensible as (the foundations for) the design of a toolkit for supporting TOF in one ore more steps of TOF-MOE interaction as well as with a final stage of production of verdict.\n4. Undeniably the introduction of progressions, an some form of temporal reasoning along with it makes the setting vulnerable to problems as brought forward by Weisberg [48] and Huber [24].37"}, {"heading": "7.8 Pointed finite sets of finite progressions of finite families of precise belief functions", "text": "Belief states may be generalized further (while the resulting theory making use of belief states may become less abstract) by working with finite families of probability functions and corresponding finite families of proposition spaces. This generalization has emerged from quantum mechanics, a theory with a strong commitment to the use of precise probabilities. Below a very modest use is made of such families in the analysis of LRTMR in the absence of TOF side proposition kinetics.\nThat probability function (and space) families constitute a proper generalization of single probability functions is the essence of Bell\u2019s results in quantum mechanics, where Bell inequalities provide criteria on when it the case that a probability function family can be reduced to\n37One way to draw a conclusion from the Weisberg paradox in [48] is that MOE should refrain from making use of Jeffrey conditioning. This approach may be too much ad hoc, however.\na single probability function by way of providing a joint probability function from which each member of the family may be found via (repeated) Bayes conditioning.\nIn Bergstra & Ponse [10] a detailed account of probability function families is given including an equational version of the proof of a Bell inequality taken from de Muynck [31]."}, {"heading": "8 Concluding remarks", "text": "Instead of transferring a likelihood pair (simultaneously or in consecutive separate messages) or transferring a likelihood ratio, merely a single likelihood may be transferred by MOE to TOF. Typically in the literature on forensic reasoning the prosecution would expect MOE to provide such information to TOF.\nThe resulting inferences are often qualified as fallacies.38 Transposing the conditional and the prosecutor\u2019s fallacy may be considered failed examples of attempts to design and use methods for single likelihood transfer mediated reasoning (SLTMR). I will first focus on the so-called transposition of the conditional, a phrase attributed to Lindley by Fienberg & Finkelstein [20]."}, {"heading": "8.1 What is wrong with transposition of the conditional?", "text": "Transposing the conditional is often portrayed as making the mistake that P 0(H | E) = P 0(E |H) which is admittedly easily refuted unless one of three \u201cunlikely\u201d conditions holds: P (E) = 0, or P (H) = 0, or P (H) = P (E).\nI consider this way of looking at what is wrong with transposition of the conditional (TOC) rather implausible.39 In my view a more plausible way of looking at it takes into account the setting of new information and corresponding belief state revision. Instead of transposition of the conditional I will speak of transposition of the likelihood, which of course amounts to the same. Now assuming that agent A receives new information concerning the single likelihood P 0A(E |H), say P 0 A(E |H) = l. Is there a justification for A to infer that after performing an appropriate belief revision resulting in P\u0302A, the following identity may be correct:\nP\u0302A 0 (H | E) = P 0A(E |H)\nFollowing Paragraph 3.3 it may be assumed that P\u0302A is obtained from PA via single likelihood Adams conditioning.\nP\u0302A = PA(H \u2227 E \u2227 \u2022) \u00b7 l\nP 0A(E |H) + PA(H \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\nP 0A(\u00acE |H) + PA(\u00acH \u2227 \u2022)\nThe calculation of P\u0302A 0 (H | E) is packaged in a Theorem.\nTheorem 8.1.1. If P\u0302A is the posterior belief of A upon acquiring knowledge that P 0 A(E |H) = l then P\u0302A 0 (H |E) = P 0A(H | E).\n38For a philosophical discussion of fallacies in the context of Bayesian reasoning I refer to Korb [25] 39In Paragraph 3.1 the implausibility of TOC as an inference mechanism in the absence of belief revision\nhas already been argued in some detail.\nProof. P\u0302A 0 (H | E) = Q0l (H | E) = Ql(H \u2227 E)\nQl(E)\n= (PA(H \u2227 E \u2227 \u2022) \u00b7\nl P 0\nA (E | H)\n)(H \u2227E)\n(PA(H \u2227 E \u2227 \u2022) \u00b7 l\nP 0 A (E | H)\n+ PA(\u00acH \u2227 \u2022))(E)\n= PA(H \u2227 E) \u00b7\nl P 0\nA (E |H)\nPA(H \u2227E) \u00b7 l\nP 0 A (E | H)\n+ PA(\u00acH \u2227 E)\n= l \u00b7 PA(H)\nl \u00b7 PA(H) + PA(\u00acH \u2227 E)\n= P 0A(E |H) \u00b7 PA(H)\nP 0A(E |H) \u00b7 PA(H) + PA(\u00acH \u2227 E)\n=\nPA(E\u2227H) PA(H) \u00b7 PA(H)\nPA(E\u2227H) PA(H) \u00b7 PA(H) + PA(\u00acH \u2227 E)\n= PA(E \u2227H)\nPA(E \u2227H) + PA(\u00acH \u2227 E)\n= PA(E \u2227H)\nPA(E)\n= P 0A(H |E)\nThe conclusion which can be drawn from this Theorem transcends the mere rejection of TOC as a fallacious inference. It may be concluded, assuming the validity of the application of Adams conditioning for the belief revision problem at hand, that learning a new value for a likelihood provides no incentive at all to reconsider one\u2019s valuation of the corresponding transposed likelihood."}, {"heading": "8.2 Prosecutor\u2019s conditioning: a justifiable residue of the prosecutor\u2019s fallacy", "text": "It is sometimes claimed that reliable reasoning in forensics necessarily requires the balancing of at least two scenario\u2019s. Likelihood ratio transfer represents the communication of an evaluation some form of comparison between two scenario\u2019s. Transferring a single likelihood ratio from MOE to TOF might be considered as a communication concerning merely a single scenario, which may be considered problematic for that reason. I will show that there is no such problem, at least not in principle.\nThe grounds for rejecting one sided reporting of evidence reside in the fact that MOE is not supposed to know TOF\u2019s prior beliefs. For the prosecutor, however (below POC for pioneer of claims), it is acceptable to ask TOF about its prior beliefs and to seek common ground with TOF on that matter in advance of formulating a claim in the form of a strong belief in a hypothesis H , for instance asserting that a certain course of events took place in a certain manner. After having established common ground with TOF concerning shared beliefs. Here is an example.\nFor propositional atoms Di for i \u2208 n = {1, . . . , n} it is assumed that D1\u2228 . . .\u2228Dn = \u22a4 and Di \u2227Dj = \u22a5 for different i, j \u2208 n. Di expresses that focus is on individual i. Besides the D\u2019s The proposition space of TOF has generators E and H . E satisfies E = D1\u2228 . . .\u2228Dk for some k < n. H \u2227Di expresses that individual i is considered the unique person (and suspect) who carried out a certain action. Initially TOF and POC agree upon the following (shared) beliefs, the relative height of p being motivated by circumstantial evidence indicating individual 1 as a suspect:\nP (Di) = 1\nn , 1 \u2264 i \u2264 n\nP (H \u2227D1) = p\nn ,\n1 n < p \u2264 1\nP (H \u2227Di) = 1\u2212 p n\u2212 1 \u00b7 1 n , 1 < i \u2264 n\nP (E) = k\nn\nP (H) = 1\nn\nP (E \u2227H) = \u2211\ni\u2208n\nP 0(E \u2227H |Di) \u00b7 P (Di) = \u2211\ni\u2208n\nP (E \u2227H \u2227Di)\nP (Di) \u00b7 P (Di)\n= \u2211\ni\u2208n\nP (E \u2227H \u2227Di) = \u2211\ni\u2208n\nP (E \u2227H \u2227Di)\n= p\nn + (k \u2212 1) \u00b7\n1\u2212 p n\u2212 1 \u00b7 1 n = 1 n (p+ (1\u2212 p) \u00b7 k \u2212 1 n\u2212 1 )\nPOC calls MOE for advice and is informed by MOE way of a single likelihood transfer that P 0(E |H) = 1.\nUsing prosecutor\u2019s fallacy (see Thompson & Shumann [41]) as a reasoning pattern, POC and TOF may now infer P 0(H |E) = 1 and therefore P 0(H |D1) = 1, thereby finding a very high probability that the suspect is the perpetrator. Instead of transposing the conditional in this case, a reasoning step for which no justification exists, it is possible to use Adams conditioning in order to capture the belief revision which TOF and POC may justifiably adopt. I will refer to single likelihood Adams conditioning in the presence of a fixed prior probability function as prosecutor\u2019s conditioning.40\n40Prosecutor\u2019s conditioning is prone to yielding false positives while avoiding false negatives, a feature which may reflect negatively on the presumed ethical merits of prosecutor\u2019s conditioning rather than on its logical validity.\nApplication of single likelihood Adams conditioning works as follows in this case:\nP\u0302 = P (H \u2227 E \u2227 \u2022) \u00b7 l\nP 0(E |H) + P (H \u2227 \u00acE \u2227 \u2022) \u00b7\n1\u2212 l\nP 0(\u00acE |H) + P (\u00acH \u2227 \u2022)\n= P (H \u2227 E \u2227 \u2022) \u00b7 1\nP 0(E |H) + P (\u00acH \u2227 \u2022)\nP\u0302 (H \u2227D1) = (P (H \u2227 E \u2227 \u2022) \u00b7 1\nP 0(E |H) + P (\u00acH \u2227 \u2022)(H \u2227D1)\n= P (H \u2227 E \u2227D1) \u00b7 1\nP 0(E |H) + P (\u00acH \u2227 h \u2227D1)\n= P (H \u2227D1) \u00b7 P (H)\nP (E \u2227H)\n= p n \u00b7 1 n \u00b7 1 1 n \u00b7 (p+ (1 \u2212 p) \u00b7 k\u22121 n\u22121 ) = 1\nn \u00b7\np\np+ (1 \u2212 p) \u00b7 k\u22121n\u22121\n= P (H \u2227D1) \u00b7 1\np+ (1\u2212 p) \u00b7 k\u22121n\u22121\nThe practical value of this conditioning step appears only when looking at an example. With p = 1/10, k = 100, n = 100.000 one finds:\nP\u0302 (H \u2227D1) = P (H \u2227D1) \u00b7 1\n1/10 + 9/10 \u00b7 9999.999\n\u2265 P (H \u2227D1) \u00b7 1\n1/10 + 9/10 \u00b7 100100.000\n= P (H \u2227D1) \u00b7 1\n1/10 + 9/100\n= P (H \u2227D1) \u00b7 100\n19\nThis on the basis of a single likelihood obtained from MOE both TOF and POC have significantly increased the belief that the suspect (person 1) has been the perpetrator: P 0(H |D1) \u2248 P 0(H | D1) \u00b7 100\n19 . The use of approximation serves an expository purpose only. Adams\nconditioning provides precise values for all posterior probabilities."}, {"heading": "8.3 Conclusions III: concerning likelihood ratio transfer versus likelihood pair transfer", "text": "The following conclusions can be drawn regarding the pro\u2019s and con\u2019s of transferring likelihood ratios in comparison with simultaneous or asynchronous transferral of likelihood pairs.\n\u2022 Single likelihood Adams conditioning provides an adequate response for TOF upon receiving an update of a single likelihood.\n\u2022 If MOE sends a likelihood ratio LR(E,H,\u00acH) to TOF, this provides enough information for TOF to revise its beliefs, with or without conditioning on the evidence proposition.\n\u2022 TOF may split a likelihood ratio r it receives in an arbitrary manner into a fraction r = l/l\u2032 and revise its belief function in either order with respect to both likelihoods (in each case using single likelihood Adams conditioning). TOF may equivalently apply double likelihood Adams conditioning.\n\u2022 In the presence of proposition kinetics, in particular if the evidence proposition is new for TOF, guessing an arbitrary parametrized expansion of the prior belief which enjoys the property that it instals the intended likelihood ratio for the evidence proposition will not achieve global correctness after conditioning on the evidence proposition.\nThis problem may be remedied in various ways. The simplest is to perform a symmetric expansion with the evidence proposition and subsequently to proceed as in the case without belief kinetics. This minor complication is avoided when only likelihood ratios are transferred.\n\u2022 From the point of view of MOE there is not much difference between reporting a single likelihood ratio and reporting a likelihood pair or even subsequently communicating (to TOF) the likelihoods that make up a pair. In each case MOE is able to report on its current beliefs, and these beliefs may be revised in the same way as TOF\u2019s beliefs are."}, {"heading": "8.4 Conclusions IV: concerning the relevance of less abstract semantical models", "text": "While the conclusions of this paper regarding ratios versus pairs of likelihoods have fairly limited practical meaning, the situation might be different for the conclusions concerning what I prefer to call the choice of a semantic model. It seems to be the case that besides precise probability functions (singleton representors) on a Boolean algebra (the proposition space) a range of less abstract models for the calculus of LRMTR can be found.\n1. The consistency of the standard model of subjective probability and precise beliefs with LRMTR under the conditions mentioned in the first conclusion listed in Paragraph 6.5.\n2. The use of a model based on finite representors rather than singleton representors seems to be adequate from a semantic perspective. Using finite representors allows MOE to encode in its reports statistical information about the likelihoods and likelihood ratios which MOE wishes to convey.\n3. Using finite representors may solve a practical problem for some which is not felt by others, without introducing an unsurmountable philosophical obstacle which might deprive some participants of a workable framework. But it matters to those MOE\u2019s who would feel more confident about their outputs if reporting a non-singleton finite representor is an option.\nSomewhat Less abstract than finite representors is a mode made up of pointed finite representors. A pointed finite representor contains a single preferred (pointed to) element.\n4. If MOE is expected to use single message reporting thereby combining the transfer of likelihoods or likelihood ratios with the transfer of the assessed validity of the evidence proposition, the framework of subjective beliefs as precise probability functions on a proposition space brakes down, because time or temporal order must be included. Although it is technically easily feasible to design a model where different agents maintain progressions of proposition spaces and belief functions, the philosophical complications of this adaptation are potentially significant, (and perhaps more significant than the complications that come with the adoption of finite representors), a conclusion for which I refer to Weisberg [48] and Huber [24].\n5. Depending on MOE reporting standards adopting a framework persmissive of states as progressions of beliefs may constitute a philosophical necessity.\n6. The adoption of families of proposition spaces and belief functions as state descriptions opens up new perspectives but seems neither to solve an urgent theoretical problem, nor of a practical problem that is may be slowing down the advancement of LRTMR style reasoning in a forensic context."}, {"heading": "8.5 Topics for further work", "text": "I take it for granted that upon choosing precise belief functions on a finite proposition space as the point of departure it is both technically and philosophically feasible to find less abstract models, and thereby potentially more useful models, for the calculus of Bayesian reasoning in an LRTMR setting, along the lines set out in the preceding Sections. However, several complications stand in the way of a perspective of quick progress, each of which seem to merit independent further research:\n1. Is the standard model of a transition system of credal states fully abstract? (See Paragraph 2.5 above.)\n2. Single message reporting by a single MOE or parallel (single but more concise) message reporting by different MOE\u2019s provides an overly simplified picture of MOE side activity and of MOE\u2019s practice of reporting. A more sophisticated model for MOE side operation must be incorporated.\n3. At some stage a formalization of how TOF side reasoning is used in the phase of producing a final verdict comes into play. Lacking a clear description of that part of the reasoning process it is too difficult to make adequate sense of the interplay between uncertainty and bounded ignorance in preceding stages.\n4. Some perspective on the formalization of the maintenance and revision of (at least TOF side) background knowledge is needed. In chained reasoning processes, the soundness of LRMTR depends on adequate knowledge management, as well as on reliable use of the knowledge at hand.\n5. Some representation of the prosecution perspective is needed. The prosecutor may be generalized (that is incorporated in a terminology without a forensic bias) to a pioneer (proponent, provider, pursuer, promoter, producer) of claims (POC) who is playing a role besides TOF and MOE in the interactive reasoning process, for instance by producing a\nhypothesis and suggesting it for incorporation in TOF\u2019s proposition space. Unlike MOE it is plausible that POC tries to influence TOF\u2019s prior probabilities. Equally important is a defendant\u2019s perspective which may be laid in the hands of an agent in the role ROC (refuter of claims).\n6. Some perspective is needed on the role which non-quantitative information provided by MOE to TOF may play within TOF\u2019s reasoning process.\n7. If the principles of LRTMR are understood as a branch of logic, then besides soundness of LRTMR driven reasoning also completeness should be analyzed. The motivating question is: can all convincing arguments be captured by chaining in an appropriate order the steps from a given catalogue of sound reasoning patterns? The exposition of LRTMR given in in the above Sections sheds no light on this question, and solutions if available must be looked for elsewhere.\nAcknowledgement. Suggestions made by Kees Middelburg concerning the precise definition of various fallacies made me consider Adams conditioning which provides a key aspect of this work. Andrea Haker has been very helpful via our longstanding discussions regarding the relevance of a focus on forensic reasoning in the context of teaching forensic science.41 Huub Hardy has provided useful and supportive advice including the suggestion not to be worried about the vast distance between the cases dealt with by forensic science practitioners and the fairly theoretical considerations constituting the focus of my research. Alban Ponse has been very helpful via his contribution to our joint trial and error prone path towards finding a usable presentation of probability calculus in the context of ring based involutive meadows. Alban has also made many useful comments on previous drafts of this paper."}], "references": [{"title": "Bayesian Orgulity", "author": ["Gordon Belot"], "venue": "Philosophy of Science,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Expressing evaluative opinions: A position statement", "author": ["Charles E.H. Berger", "John Buckleton", "Christophe Champod", "Ian W. Evett", "Graham Jackson"], "venue": "http://charles-berger.com/docs/2011_SciJus-Expressing_evaluative_ opinions-A_position_statement-manuscript.pdf (accessed October", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "The LR does not exist", "author": ["Charles E.H. Berger", "Klaas Slooten"], "venue": "Science and Justice,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "Conditional Values in Signed Meadow Based Axiomatic Probability Calculus", "author": ["Jan A. Bergstra"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "Equations for formally real meadows", "author": ["J.A. Bergstra", "I. Bethke", "A. Ponse"], "venue": "Journal of Applied Logic,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Process Algebra for Synchronous Communication", "author": ["J.A. Bergstra", "J.W. Klop"], "venue": "Information and Control,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1984}, {"title": "Division by zero in involutive meadows", "author": ["J.A. Bergstra", "C.A. Middelburg"], "venue": "Journal of Applied Logic,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Thread algebra for strategic interleaving", "author": ["J.A. Bergstra", "C.A. Middelburg"], "venue": "Formal Aspects of Computing,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2007}, {"title": "Probability functions in the context of signed involutive meadows", "author": ["Jan A. Bergstra", "Alban Ponse"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "Datatype defining rewrite systems for the ring of integers, and for natural and integer arithmetic in unary view", "author": ["Jan A. Bergstra", "Alban Ponse"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "The role of the subjectivist position in the probabilization of forensic science", "author": ["Alex Biedermann"], "venue": "J. Forensic Sci Med,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Digital evidence, \u2018absence\u2019 of data and ambiguous patterns of reasoning", "author": ["Alex Biedermann", "Jo\u00eblle Vuille"], "venue": "Digital Investigation,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}, {"title": "Radical Probabilism and Bayesian Conditioning", "author": ["Richard Bradley"], "venue": "Philosophy of Science,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2005}, {"title": "There is no Fallacy of Arguing from Authority", "author": ["Edwin Coleman"], "venue": "Informal Logic,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1995}, {"title": "Updating Subjective Probability", "author": ["Persi Diaconis", "Sandy L. Zabell"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1982}, {"title": "The logical foundations of forensic science: towards reliable knowledge", "author": ["Ian Evett"], "venue": "Philosophical Transactions B,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}, {"title": "Bayesian statistics and the law", "author": ["Stephen E. Fienberg", "Michael O. Finkelstein"], "venue": "Bayesian Statistics,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1996}, {"title": "Objections to Bayesian Statistics", "author": ["Andrew Gelman"], "venue": "Bayesian Analysis,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2009}, {"title": "Intersubjective probability and economics", "author": ["Donald A. Gillies", "Grazia Letto Gillies"], "venue": "Review of Political Economy,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1991}, {"title": "Bayes rules all: On the equivalence of various forms of learning in a probabilistic setting", "author": ["Bal\u00e1sz Gyenis"], "venue": "PhilSci Archive http://philsci-archive.pitt.edu/11230/,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "For True Conditionalizers Weisberg\u2019s Paradox is a False Alarm. to appear in Symposion", "author": ["Franz Huber"], "venue": "http://philsci-archive.pitt.edu/10830/1/WeisbergJeffrey.pdf (last accessed November", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2016}, {"title": "Bayesian Informal Logic and Fallacy", "author": ["Kevin Korb"], "venue": "Informal Logic,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2004}, {"title": "On Indeterminate Probabilities", "author": ["Isaac Levi"], "venue": "The Journal of Philosophy,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1974}, {"title": "Probability and the Law", "author": ["D.V. Lindley"], "venue": "Journal of the Royal Statistical Society. Series D (The Statistician),", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1977}, {"title": "Use of Interval Quantifications for the Value of Forensic Evidence. Technical Colloquium: Quantifying the Weight of Evidence, NIST May 2016", "author": ["Steve Lund", "Hari Iyer"], "venue": "http://biometrics.nist.gov/cs_links/ibpc2016/tc/presentations/ Day2/2ndPanel_confidenceInterval_LR/06_Hari_LR_Interval_Panel.pdf, accessed October", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2016}, {"title": "Discussion on how to implement a verbal scale in a forensic laboratory: Benefits, pitfalls and suggestions to avoid misunderstandings", "author": ["Raymond Marquis", "Alex Biedermann", "Liv Cadola", "Christophe Champod", "Line Gueissaz", "Genevi\u00e8ve Massonnet", "Wiiliams David Mazella", "Franco Taroni", "Tacha Hicks"], "venue": "Science and Justice, doi: 10.1016/j.j.scijus.2016.05.009,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2016}, {"title": "What should a forensic practitioner\u2019s likelihood ratio be", "author": ["Geoffrey Stewart Morrison", "Ewald Enzinger"], "venue": "Science and Justice,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2016}, {"title": "Foundations of quantum mechanics, an empiricist approach", "author": ["W.M. de Muynck"], "venue": "Fundamental theories of physics,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2002}, {"title": "On Stochastic Belief Revision and Update and their Combination", "author": ["Gavin Rens"], "venue": "http: //arxiv.org/abs/1604.02126,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2016}, {"title": "Reservations about likelihood ratios (and some other aspects of forensic \u2018Bayesianism\u2019)", "author": ["D. Michael Risinger"], "venue": "Law, Probability and Risk,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2012}, {"title": "Extending the Confusion about Bayes", "author": ["Bernard Robertson", "G.A. Vignaux", "Charles E.H. Berger"], "venue": "Modern Law Review,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2011}, {"title": "Intuition, Statistik und Beweisw\u00fcrdigung. Justice-Justiz-Giustizia, 4 (http://www.decisions.ch/publikationen/intuition_statistik.html accessed", "author": ["Mark Schweizer"], "venue": null, "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2016}, {"title": "The law doesn\u2019t say much about base rates", "author": ["Mark Schweizer"], "venue": "Working paper (https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2329387,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2013}, {"title": "Uncertainty and LR: to integrate or not to integrate, that\u2019s the question", "author": ["M.J. Sjerps", "I. Alberink", "A. Bolck", "R.D. Stoe", "P. Vergeer", "J.H. van Zanten"], "venue": "Law, Probability and Risk,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2016}, {"title": "A Bayesian Approach to Absent Evidence Reasoning", "author": ["Cristopher Stephens"], "venue": "Informal Logic,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2011}, {"title": "The Old Evidence Problem and AGM Theory", "author": ["Saturo Suzuki"], "venue": "Annals of the Japanese Association for Philosophy of Science,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2005}, {"title": "Interpretation of Statistical Evidence in Criminal Trials: The Prosecutor\u2019s Fallacy and the Defense Attorney\u2019s Fallacy", "author": ["William C. Thompson", "Edward L. Shumann"], "venue": "Law and Human Behavior,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 1987}, {"title": "Probabilistic belief expansion and conditioning", "author": ["Frans Voorbraak"], "venue": "ILLC Research", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2016}, {"title": "The limitation of Bayesianism", "author": ["Pei Wang"], "venue": "Artificial Intelligence,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2004}, {"title": "Keynes, uncertainty and interest rates", "author": ["Brian Weatherson"], "venue": "Cambridge Journal of Economics,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2002}, {"title": "The Bayesian and the Dogmatist", "author": ["Brian Weatherson"], "venue": "Proceedings of the Aristotelian Society,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2007}, {"title": "Commutativity or Holism? A dilemma for Conditionalizers", "author": ["Jonathan Weisberg"], "venue": "Brittish Journal for the Philosophy of Science,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2009}, {"title": "ENSFI guideline for evaluative reporting in forensic science", "author": ["Sheila Willis"], "venue": "http://www.enfsi.eu/sites/default/files/documents/external_ publications/m1_guideline.pdf (accessed November", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2015}], "referenceMentions": [{"referenceID": 24, "context": "Writing this paper was triggered by the following question stated in Lund & Iyer [28]: why not separately communicate the two likelihoods that make up a likelihood ratio? An answer to this question is given in Paragraph 8.", "startOffset": 81, "endOffset": 85}, {"referenceID": 23, "context": "[27]) and Evett (see [18] for a recent statement on his position), who in turn based their work on the principles of subjective probability as set out by by Ramsey, de Finetti, Carnap and Jeffrey, a range of contemporary authors shows commitment to the exclusive usage of precise belief states, see for instance Berger & Slooten [4], Berger et.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[27]) and Evett (see [18] for a recent statement on his position), who in turn based their work on the principles of subjective probability as set out by by Ramsey, de Finetti, Carnap and Jeffrey, a range of contemporary authors shows commitment to the exclusive usage of precise belief states, see for instance Berger & Slooten [4], Berger et.", "startOffset": 21, "endOffset": 25}, {"referenceID": 2, "context": "[27]) and Evett (see [18] for a recent statement on his position), who in turn based their work on the principles of subjective probability as set out by by Ramsey, de Finetti, Carnap and Jeffrey, a range of contemporary authors shows commitment to the exclusive usage of precise belief states, see for instance Berger & Slooten [4], Berger et.", "startOffset": 329, "endOffset": 332}, {"referenceID": 1, "context": "[3] and Biedermann [13, 14].", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "[3] and Biedermann [13, 14].", "startOffset": 19, "endOffset": 27}, {"referenceID": 11, "context": "[3] and Biedermann [13, 14].", "startOffset": 19, "endOffset": 27}, {"referenceID": 14, "context": "Independently of forensics, theory development concerning precise beliefs has advanced in different directions, for instance in Diaconis & Zabell [17], Bradley [15], Gyenis [23], and Yalcin [50].", "startOffset": 146, "endOffset": 150}, {"referenceID": 12, "context": "Independently of forensics, theory development concerning precise beliefs has advanced in different directions, for instance in Diaconis & Zabell [17], Bradley [15], Gyenis [23], and Yalcin [50].", "startOffset": 160, "endOffset": 164}, {"referenceID": 19, "context": "Independently of forensics, theory development concerning precise beliefs has advanced in different directions, for instance in Diaconis & Zabell [17], Bradley [15], Gyenis [23], and Yalcin [50].", "startOffset": 173, "endOffset": 177}, {"referenceID": 12, "context": "Below I will make use of Bradley\u2019s presentation of Adams conditioning in [15].", "startOffset": 73, "endOffset": 77}, {"referenceID": 37, "context": "After one or more steps of constraining (steps of belief kinetics which reduce imprecision using the terminology of Voorbraak [42]) the belief state may be turned back into a precise belief state ready for subsequent Bayesian conditioning with the required effect.", "startOffset": 126, "endOffset": 130}, {"referenceID": 42, "context": "[49]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "Using x 0 = 0 on top of the standard axioms for numbers (the axioms for a commutative ring) leads to what is called an involutive meadow in [8].", "startOffset": 140, "endOffset": 143}, {"referenceID": 8, "context": "Formulae and equations below are to be understood in the context of the specification BA+ Md+ Sign+ PFP 6 taken from Bergstra & Ponse [10] for a probability function with name P over an event space E, which takes form of a Boolean algebra of events and for which a finite collection C of constants is available.", "startOffset": 134, "endOffset": 138}, {"referenceID": 8, "context": "2 Conditional probability: variations on a theme Following [10] P (x | y) is defined by", "startOffset": 59, "endOffset": 63}, {"referenceID": 8, "context": "In Bergstra & Ponse [10] several other options for defining conditional probabilities when taking the possibility of P (y) = 0 into account are discussed.", "startOffset": 20, "endOffset": 24}, {"referenceID": 9, "context": "5In Bergstra & Ponse [11] the formalization of decimal number notation by means of ground complete term rewriting systems, a useful shape of abstract datatype specification in preparation for prototyping implementations, is studied in detail.", "startOffset": 21, "endOffset": 25}, {"referenceID": 4, "context": "7For this specification a completeness theorem that was proven in Bergstra, Bethke & Ponse [6] for Md+Sign is extended in [10].", "startOffset": 91, "endOffset": 94}, {"referenceID": 8, "context": "7For this specification a completeness theorem that was proven in Bergstra, Bethke & Ponse [6] for Md+Sign is extended in [10].", "startOffset": 122, "endOffset": 126}, {"referenceID": 3, "context": "The equational specification BA+Md+Sign+PFP is extended with so-called conditional values, playing the role of random variables, and expectation values in Bergstra [5].", "startOffset": 164, "endOffset": 167}, {"referenceID": 8, "context": "\u2022 Various forms of Bayes\u2019 theorem take the form of derivable equations (see Bergstra and Ponse [10] and Bergstra [5]).", "startOffset": 95, "endOffset": 99}, {"referenceID": 3, "context": "\u2022 Various forms of Bayes\u2019 theorem take the form of derivable equations (see Bergstra and Ponse [10] and Bergstra [5]).", "startOffset": 113, "endOffset": 116}, {"referenceID": 14, "context": "According to Diaconis & Zabell [17] only its infinitary versions are stronger than any Bayesian rules.", "startOffset": 31, "endOffset": 35}, {"referenceID": 31, "context": "A paradigmatic example of this reasoning pattern occurs in the so-called Taxi Color Case as specified in detail in Schweizer [35].", "startOffset": 125, "endOffset": 129}, {"referenceID": 16, "context": "Fienberg & Finkelstein [20] provide a historic account of the use of Bayesian reasoning in US trials and propose the avoidance of fallacious reasoning as the primary objective for the promotion of Bayesian reasoning in the light of a substantial difficulty to get the content of Bayesian reasoning across to legal professionals and members of jury\u2019s.", "startOffset": 23, "endOffset": 27}, {"referenceID": 34, "context": "For instance the reasoning pattern discussed by Stephens in [38] lies outside the patterns considered below.", "startOffset": 60, "endOffset": 64}, {"referenceID": 31, "context": "20Schweizer [35] contains a detailed description of the taxi color case, together with a useful survey of", "startOffset": 12, "endOffset": 16}, {"referenceID": 31, "context": "I will simplify the case in comparison to Schweizer\u2019s description in Schweizer [35] by assuming that A includes the estimate of a base rate for the correctness of K\u2019s testimony.", "startOffset": 79, "endOffset": 83}, {"referenceID": 32, "context": "In Schweizer [36] the similar bus color scenario is mentioned in an exposition concerning the legal value of base rates.", "startOffset": 13, "endOffset": 17}, {"referenceID": 12, "context": "Following the exposition of Bradley [15] this is the Adams transformation corresponding to an intended update of likelihood LA(E,H) = P 0 A(E |H) to value l.", "startOffset": 36, "endOffset": 40}, {"referenceID": 5, "context": "The process algebra ACP of Bergstra & Klop [7] provides synchronous messaging as the primary communication mechanism, with asynchronous messaging as a rather more complex derived feature.", "startOffset": 43, "endOffset": 46}, {"referenceID": 42, "context": "[49] (ENFSI guideline for evaluative reporting in forensic science) extensive mention is made of the imperative that a likelihood ratio must be included in the report of a forensic expert.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "For modelling the paralel composition of TOF, MOE, and other agents each of which are supposed to operate in a sequential fashion in a predetermined workflow, the thread algebra with strategic interleaving of Bergstra & Middelburg [9] may be used.", "startOffset": 231, "endOffset": 234}, {"referenceID": 41, "context": "Weisberg\u2019s paradox (Weisberg [48] and the analysis of it in Huber [24] provide an indication of the complications involved.", "startOffset": 29, "endOffset": 33}, {"referenceID": 20, "context": "Weisberg\u2019s paradox (Weisberg [48] and the analysis of it in Huber [24] provide an indication of the complications involved.", "startOffset": 66, "endOffset": 70}, {"referenceID": 7, "context": "Thread algebra ([9]) has been designed as a theoretical tool allowing being incorporated in other frameworks in a lightweight manner.", "startOffset": 16, "endOffset": 19}, {"referenceID": 5, "context": "I will use ACP style process algebra notation from Bergstra & Klop [7] for lightweight workflow description.", "startOffset": 67, "endOffset": 70}, {"referenceID": 30, "context": "31On the transfer of likelihood pairs: Robertson, Vignaux & Berger in [34] (p.", "startOffset": 70, "endOffset": 74}, {"referenceID": 26, "context": "Morisson & Enzinger [30] suggest to distinguish between Bayes factor and likelihood ratio and both notions may have disparate relations with the respective underlying pairs.", "startOffset": 20, "endOffset": 24}, {"referenceID": 29, "context": "This position intentionally leaves room for worries such as formulated in Risinger [33] (p.", "startOffset": 83, "endOffset": 87}, {"referenceID": 0, "context": "in Belot [2]).", "startOffset": 9, "endOffset": 12}, {"referenceID": 39, "context": "Imprecise belief modeled by way of non-singleton representors can be traced back to Keynes (see Weatherson [44]), and features explicitly in Levi [26] with subsequent work in e.", "startOffset": 107, "endOffset": 111}, {"referenceID": 22, "context": "Imprecise belief modeled by way of non-singleton representors can be traced back to Keynes (see Weatherson [44]), and features explicitly in Levi [26] with subsequent work in e.", "startOffset": 146, "endOffset": 150}, {"referenceID": 37, "context": "Voorbraak [42], Weatherson [45, 46] and Rens [32].", "startOffset": 10, "endOffset": 14}, {"referenceID": 40, "context": "Voorbraak [42], Weatherson [45, 46] and Rens [32].", "startOffset": 27, "endOffset": 35}, {"referenceID": 28, "context": "Voorbraak [42], Weatherson [45, 46] and Rens [32].", "startOffset": 45, "endOffset": 49}, {"referenceID": 10, "context": "Biedermann [13] provides a recent exposition and justification of the by now classical viewpoint that ignorance is merely a variation on the theme of uncertainty, which for that reason is fully representable in a single and precise belief function, if not in general then at least in the context of forensic reasoning.", "startOffset": 11, "endOffset": 15}, {"referenceID": 37, "context": "Probabilistic AGM theory, an adaptation of AGM theory which contemplating its application in forensics would necessitate anyhow, has been developed in Voorbraak [42] and in Suzuki [40].", "startOffset": 161, "endOffset": 165}, {"referenceID": 35, "context": "Probabilistic AGM theory, an adaptation of AGM theory which contemplating its application in forensics would necessitate anyhow, has been developed in Voorbraak [42] and in Suzuki [40].", "startOffset": 180, "endOffset": 184}, {"referenceID": 26, "context": "For instance in Morisson & Enzinger [30] and in Sjerps et al.", "startOffset": 36, "endOffset": 40}, {"referenceID": 33, "context": "[37] the case is made that a likelihood ratio ought to be reported by an MOE as a value equipped with resolution and precision.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[29]) seem to constitute an approach based on imprecise values, but the authors strongly insist that verbal scales must not be understood or used in that manner.", "startOffset": 0, "endOffset": 4}, {"referenceID": 41, "context": "The conception that MOE side reasoning (when explaining single message reporting) is philosophically understood as an easy to define mix of dogmatic subjective probability with temporal logic is problematic in the light of the complications discovered by Weisberg in [48].", "startOffset": 267, "endOffset": 271}, {"referenceID": 41, "context": "Undeniably the introduction of progressions, an some form of temporal reasoning along with it makes the setting vulnerable to problems as brought forward by Weisberg [48] and Huber [24].", "startOffset": 166, "endOffset": 170}, {"referenceID": 20, "context": "Undeniably the introduction of progressions, an some form of temporal reasoning along with it makes the setting vulnerable to problems as brought forward by Weisberg [48] and Huber [24].", "startOffset": 181, "endOffset": 185}, {"referenceID": 41, "context": "That probability function (and space) families constitute a proper generalization of single probability functions is the essence of Bell\u2019s results in quantum mechanics, where Bell inequalities provide criteria on when it the case that a probability function family can be reduced to 37One way to draw a conclusion from the Weisberg paradox in [48] is that MOE should refrain from making use of Jeffrey conditioning.", "startOffset": 343, "endOffset": 347}, {"referenceID": 8, "context": "In Bergstra & Ponse [10] a detailed account of probability function families is given including an equational version of the proof of a Bell inequality taken from de Muynck [31].", "startOffset": 20, "endOffset": 24}, {"referenceID": 27, "context": "In Bergstra & Ponse [10] a detailed account of probability function families is given including an equational version of the proof of a Bell inequality taken from de Muynck [31].", "startOffset": 173, "endOffset": 177}, {"referenceID": 16, "context": "I will first focus on the so-called transposition of the conditional, a phrase attributed to Lindley by Fienberg & Finkelstein [20].", "startOffset": 127, "endOffset": 131}, {"referenceID": 21, "context": "38For a philosophical discussion of fallacies in the context of Bayesian reasoning I refer to Korb [25] 39In Paragraph 3.", "startOffset": 99, "endOffset": 103}, {"referenceID": 36, "context": "Using prosecutor\u2019s fallacy (see Thompson & Shumann [41]) as a reasoning pattern, POC and TOF may now infer P (H |E) = 1 and therefore P (H |D1) = 1, thereby finding a very high probability that the suspect is the perpetrator.", "startOffset": 51, "endOffset": 55}, {"referenceID": 41, "context": "Although it is technically easily feasible to design a model where different agents maintain progressions of proposition spaces and belief functions, the philosophical complications of this adaptation are potentially significant, (and perhaps more significant than the complications that come with the adoption of finite representors), a conclusion for which I refer to Weisberg [48] and Huber [24].", "startOffset": 379, "endOffset": 383}, {"referenceID": 20, "context": "Although it is technically easily feasible to design a model where different agents maintain progressions of proposition spaces and belief functions, the philosophical complications of this adaptation are potentially significant, (and perhaps more significant than the complications that come with the adoption of finite representors), a conclusion for which I refer to Weisberg [48] and Huber [24].", "startOffset": 394, "endOffset": 398}], "year": 2016, "abstractText": "Forensic science advocates the use of inference mechanisms which may be viewed as simple multi-agent protocols. An important protocol of this kind involves an agent FE (forensic expert) who communicates to a second agent TOF (trier of fact) first its value of a certain likelihood ratio with respect to its own belief state which is supposed to be captured by a probability function on FE\u2019s proposition space. Subsequently FE communicates its recently acquired confirmation that a certain evidence proposition is true. The inference part of this sort of reasoning, here referred to as likelihood ratio transfer mediated reasoning, involves TOF\u2019s revision of its own belief state, and in particular an evaluation of the resulting belief in the hypothesis proposition. Different realizations of likelihood ratio transfer mediated reasoning are distinguished: if the evidence hypothesis is included in the prior proposition space of TOF then a comparison is made between understanding the TOF side of a belief revision step as a composition of two successive steps of single likelihood Adams conditioning followed by a Bayes conditioning step, and as a single step of double likelihood Adams conditioning followed by Bayes conditioning; if, however the evidence hypothesis is initially outside the proposition space of TOF an application of proposition kinetics for the introduction of the evidence proposition precedes Bayesian conditioning, which is followed by Jeffrey conditioning on the hypothesis proposition.", "creator": "LaTeX with hyperref package"}}}