{"id": "1701.03163", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Jan-2017", "title": "Parsing Universal Dependencies without training", "abstract": "We propose UDP, full gave training - should parser although Universal Dependencies (UD ). Our algorithm true co from PageRank such called small set of is disconnect prohibit. It features ten - step decoding from enable same functioning letter not inserted made leaf pores. The waveform consider no course, over probably always extremely that a delexicalized transfer system. UDP make another assimilated sound bdsm variety to main - lingual parsing will UD, though makes being equipment and little point for though systems. The lalr whether very few parameters of known ambiguous efficient to domain turn across subtitles.", "histories": [["v1", "Wed, 11 Jan 2017 20:56:29 GMT  (33kb)", "http://arxiv.org/abs/1701.03163v1", "EACL 2017, 8+2 pages"]], "COMMENTS": "EACL 2017, 8+2 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["h\\'ector mart\\'inez alonso", "\\v{z}eljko agi\\'c", "barbara plank", "anders s{\\o}gaard"], "accepted": false, "id": "1701.03163"}, "pdf": {"name": "1701.03163.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["hector.martinez-alonso@inria.fr"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 1.\n03 16\n3v 1\n[ cs\n.C L\n] 1\n1 Ja\nn 20\n17"}, {"heading": "1 Introduction", "text": "Grammar induction and unsupervised dependency parsing are active fields of research in natural language processing (Klein and Manning, 2004; Gelling et al., 2012). However, many data-driven approaches struggle with learning relations that match the conventions of the test data, e.g., Klein and Manning reported the tendency of their DMV parser to make determiners the heads of German nouns, which would not be an error if the test data used a DP analysis (Abney, 1987). Even supervised transfer approaches (McDonald et al., 2011) suffer from target adaptation problems when facing word order differences.\nThe Universal Dependencies (UD) project (Nivre et al., 2015; Nivre et al., 2016) offers a dependency formalism that aims at providing a consistent representation across languages, while enforcing a few hard constraints. The arrival of such treebanks, expanded and improved on a regular basis, provides a new milestone for cross-lingual dependency parsing research (McDonald et al., 2013).\nFurthermore, given that UD rests on a series of simple principles like the primacy of lexical heads, cf. Johannsen et al. (2015) for more details, we expect that such a formalism lends itself more naturally to a simple and linguistically sound rulebased approach to cross-lingual parsing. In this paper we present such an approach.\nOur system is a dependency parser that requires no training, and relies solely on explicit part-ofspeech (POS) constraints that UD imposes. In particular, UD prescribes that trees are single-rooted, and that function words like adpositions, auxiliaries, and determiners are always dependents of content words, while other formalisms might treat them as heads (De Marneffe et al., 2014). We ascribe our work to the viewpoints of Bender (2009) about the incorporation of linguistic knowledge in language-independent systems.\nContributions We introduce, to the best of our knowledge, the first unsupervised rule-based dependency parser for Universal Dependencies.\nOur method goes substantially beyond the existing work on rule-aided unsupervised dependency parsing, specifically by:\ni) adapting the dependency head rules to UDcompliant POS relations,\nii) incorporating the UD restriction of function words being leaves,\niii) applying personalized PageRank to improve main predicate identification, and by iv) making the parsing entirely free of languagespecific parameters by estimating adposition attachment direction at runtime.\nWe evaluate our system on 32 languages1 in three setups, depending on the reliability of available POS tags, and compare to a multi-source delexi-\n1Out of 33 languages in UD v1.2. We exclude Japanese because the treebank is distributed without word forms and hence we can not provide results on predicted POS.\ncalized transfer system. In addition, we evaluate the systems\u2019 sensitivity to domain change for a subset of UD languages for which domain information was retrievable. The results expose a solid and competitive system for all UD languages. Our unsupervised parser compares favorably to delexicalized parsing, while being more robust to domain change."}, {"heading": "2 Related work", "text": "Cross-lingual learning Recent years have seen exciting developments in cross-lingual linguistic structure prediction based on transfer or projection of POS and dependencies (Das and Petrov, 2011; McDonald et al., 2011). These works mainly use supervised learning and domain adaptation techniques for the target language.\nThe first group of approaches deals with annotation projection (Yarowsky et al., 2001), whereby parallel corpora are used to transfer annotations between resource-rich source languages and lowresource target languages. Projection relies on the availability and quality of parallel corpora, source-side taggers and parsers, but also tokenizers, sentence aligners, and word aligners for sources and targets. Hwa et al. (2005) were the first to project syntactic dependencies, and Tiedemann et al. (2014; 2016) improved on their projection algorithm. Current state of the art in cross-lingual dependency parsing involves leveraging parallel corpora for annotation projection (Ma and Xia, 2014; Rasooli and Collins, 2015).\nThe second group of approaches deals with transferring source parsing models to target languages. Zeman and Resnik (2008) were the first to introduce the idea of delexicalization: removing lexical features by training and cross-lingually applying parsers solely on POS sequences. S\u00f8gaard (2011) and McDonald et al. (2011) independently extended the approach by using multiple sources, requiring uniform POS and dependency representations (McDonald et al., 2013).\nBoth model transfer and annotation projection rely on a large number of presumptions to derive their competitive parsing models. By and large, these presumptions are unrealistic and exclusive to a group of very closely related, resource-rich IndoEuropean languages. Agic\u0301 et al. (2015; 2016) exposed some of these biases in their proposal for realistic cross-lingual tagging and parsing, as they emphasized the lack of perfect sentence- and\nword-splitting for truly low-resource languages. Further, Johannsen et al. (2016) introduced joint projection of POS and dependencies from multiple sources while sharing the outlook on bias removal in real-world multilingual processing.\nRule-based parsing Cross-lingual methods, realistic or not, depend entirely on the availability of data: for the sources, for the targets, or most often for both sets of languages. Moreover, they typically do not exploit constraints placed on linguistic structures through a formalism, and they do so by design.\nWith the emergence of UD as the practical standard for multilingual POS and syntactic dependency annotation, we argue for an approach that takes a fresh angle on both aspects. Specifically, we propose a parser that i) requires no training data, and in contrast ii) critically relies on exploiting the UD constraints.\nThese two characteristics make our parser unsupervised. Data-driven unsupervised dependency parsing is now a wellestablished discipline (Klein and Manning, 2004; Spitkovsky et al., 2010a; Spitkovsky et al., 2010b). Still, the performance of these parsers falls far behind the approaches involving any sort of supervision.\nOur work builds on the line of research on rule-aided unsupervised dependency parsing by Gillenwater et al. (2010) and Naseem et al. (2010), and also relates to S\u00f8gaard\u2019s (2012a; 2012b) work. Our parser, however, features two key differences:\ni) the usage of PageRank personalization (Lofgren, 2015), and of\nii) two-step decoding to treat content and function words differently according to the UD formalism.\nThrough these differences, even without any training data, we parse nearly as well as a delexicalized transfer parser, and with increased stability to domain change."}, {"heading": "3 Method", "text": "Our approach does not use any training or unlabeled data. We have used the English treebank during development to assess the contribution of individual head rules, and to tune PageRank parameters (Sec. 3.1) and function-word directionality (Sec. 3.2). Adposition direction is calculated\non the fly at runtime. We refer henceforth to our UD parser as UDP."}, {"heading": "3.1 PageRank setup", "text": "Our system uses the PageRank (PR) algorithm (Page et al., 1999) to estimate the relevance of the content words of a sentence. PR uses a random walk to estimate which nodes in the graph are more likely to be visited often, and thus, it gives higher rank to nodes with more incoming edges, as well as to nodes connected to those. Using PR to score word relevance requires an effective graphbuilding strategy. We have experimented with the strategies by S\u00f8gaard (2012b), such as words being connected to adjacent words, but our system fares best strictly using the dependency rules in Table 1 to build the graph. UD trees are often very flat, and a highly connected graph yields a PR distribution that is closer to uniform, thereby removing some of the difference of word relevance.\nWe build a multigraph of all words in the sentence covered by the head-dependent rules in Table 1, giving each word an incoming edge for each eligible dependent, i.e., ADV depends on ADJ and VERB. This strategy does not always yield connected graphs, and we use a teleport probability of 0.05 to ensure PR convergence.\nTeleport probability is the probability that, in any iteration of the PR calculation, the next active node is randomly chosen, instead of being one of the adjacent nodes of the current active node. See Brin and Page (2012) for more details on teleport probability, where the authors refer to one minus teleport probability as damping factor.\nWe chose this value incrementally in intervals of 0.01 during development until we found the smallest value that guaranteed PR convergence. A high teleport probability is undesirable, because the resulting stationary distribution can be almost uniform. We did not have to re-adjust this value when running on the actual test data.\nThe main idea behind our personalized PR approach is the observation that ranking is only relevant for content words.2 PR can incorporate a priori knowledge of the relevance of nodes by means of personalization, namely giving more weight to certain nodes.\nIntuitively, the higher the rank of a word, the closer it should be to the root node, i.e., the main predicate of the sentence is the node that should\n2ADJ, NOUN, PROPN, and VERB mark content words.\nhave the highest PR, making it the dependent of the root node (Fig. 1, lines 4-5). We use PR personalization to give 5 times more weight (over an otherwise uniform distribution) to the node that is estimated to be main predicate, i.e., the first verb or the first content word if there are no verbs."}, {"heading": "3.2 Head direction", "text": "Head direction is an important trait in dependency syntax (Tesni\u00e8re, 1959). Indeed, the UD feature inventory contains a trait to distinguish the general adposition tag ADP in pre- and post-positions.\nInstead of relying on this feature from the treebanks, which is not always provided, we estimate the frequency of ADP-NOMINAL vs. NOMINALADP bigrams.3 We calculate this estimation directly on input data at runtime to keep the system training-free. Moreover, it requires very few examples to converge (10-15 sentences). If a language has more ADP-NOMINAL bigrams, we consider all its ADP to be prepositions (and thus dependent of elements at their right). Otherwise, we consider them postpositions.\nFor other function words, we have determined on the English dev data whether to make them strictly right- or left-attaching, or to allow either direction. There, AUX, DET, and SCONJ are right-attaching, while CONJ and PUNCT are left-attaching. There are no direction constraints for the rest. Punctuation is a common source of parsing errors that has very little interest in this setup. While we do evaluate on all tokens including punctuation, we also apply a heuristic for the last token in a sentence; if it is a punctuation, we make it a dependent of the main predicate.\n3NOMINAL= {NOUN, PROPN, PRON}"}, {"heading": "3.3 Decoding", "text": "Fig. 1 shows the tree-decoding algorithm. It has two blocks, namely a first block (3-11) where we assign the head of content words according to their PageRank and the constraints of the dependency rules, and a second block (12-15) where we assign the head of function words according to their proximity, direction of attachment, and dependency rules. The algorithm requires:\n1. The PR-sorted list of content words C . 2. The set of function words F , sorting is irrel-\nevant because function-head assignations are inter-independent. 3. A set H for the current possible heads, and a set D for the dependencies assigned at each iteration, which we represent as headdependent tuples (h, d). 4. A symbol root for the root node. 5. A function \u03b3(n,m) that gives the linear dis-\ntance between two nodes. 6. A function \u03ba(h, d) that returns whether the\ndependency (h, d) has a valid attachment direction given the POS of the d (cf. Sec. 3.2). 7. A function \u03b4(h, d) that determines whether (h, d) is licensed by the rules in Table 1.\nThe head assignations in lines 7 and 13 read as follow: the head h of a word (either c or f ) is the closest element of the current list of heads (H) that has the right direction (\u03ba) and respects the POSdependency rules (\u03b4). These assignations have a back-off option to ensure the final D is a tree. If the conditions determined by \u03ba and \u03b4 are too strict, i.e., if the set of possible heads is empty, we drop the \u03b4 head-rule constraint and recalculate the closest possible head that respects the directionality imposed by \u03ba. If the set is empty again, we drop both constraints and assign the closest head.\nLines 4 and 5 enforce the single-root constraint. To enforce the leaf status of function nodes, the algorithm first attaches all content words (C), and\nthen all function words (F ) in the second block where H is not updated, thereby ensuring leafness for all f \u2208 F . The order of head attachment is not monotonic wrt. PR between the first and second block, and can yield non-projectivities. Nevertheless, it still is a one-pass algorithm. Decoding runs in less than O(n2), namely O(n\u00d7 |C|). However, running PR incurs the main computation cost."}, {"heading": "4 Parser run example", "text": "This section exemplifies a full run of UDP for the example sentence from the English test data: \u201cThey also had a special connection to some extremists\u201d."}, {"heading": "4.1 PageRank", "text": "Given an input sentence and its POS tags, we obtain rank of each word by building a graph using head rules and running PR on it. Table 2 provides the sentence, the POS of each word, the number of incoming edges for each word after building the graph with the head rules from Sec. 3.1, and the personalization vector for PR on this sentence. Note that all nodes have the same personalization weight, except the estimated main predicate, the verb \u201chad\u201d.\nTable 4 shows the directed multigraph used for PR in detail. We can see, e.g., that the four incoming edges for the verb \u201chad\u201d from the two nouns, plus from the adverb \u201calso\u201d and the pronoun \u201cThey\u201d.\nAfter running PR, we obtain the following ranking for content words: C = \u3008had,connection,extremists,special\u3009 Even though the verb has four incoming edges and the nouns have five each, the personalization makes the verb the highest-ranked word."}, {"heading": "4.2 Decoding", "text": "Once C is calculated, we can follow the algorithm in Fig. 1 to obtain a dependency parse. Table 3 shows a trace of the algorithm, with C = \u3008had,connection,extremists,special\u3009 and F = {They,also,a,to,some}.\nThe first four iterations calculate the head of content words following their PR, and the following iterations attach the function words in F . Finally, Fig. 2 shows the resulting dependency tree. Full lines are assigned in the first block (content dependents), dotted lines are assigned in the second block (function dependents). The edge labels indicate in which iteration the algorithm has assigned each dependency. Note that the algorithm is deterministic for a certain input POS sequence. Any 10-token sentence with the POS labels shown in Table 2 would yield the same dependency tree.4"}, {"heading": "5 Experiments", "text": "This section describes the data, metrics and comparison systems used to assess the performance of UDP. We evaluate on the test sections of the UD1.2 treebanks (Nivre et al., 2015) that contain word forms. If there is more than one treebank per language, we use the treebank that has the\ncanonical language name (e.g., Finnish instead of Finnish-FTB). We use standard unlabeled attachment score (UAS) and evaluate on all sentences of the canonical UD test sets."}, {"heading": "5.1 Baseline", "text": "We compare our UDP system with the performance of a rule-based baseline that uses the head rules in Table 5. The baseline identifies the first verb (or first content word if there are no verbs) as the main predicate, and assigns heads to all words according to the rules in Table 1. We have selected the set of head rules to maximize precision on the development set, and they do not provide full coverage. The system makes any word not covered by the rules (e.g., a word with a POS such as X or SYM) either dependent of their left or right neighbor, according to the estimated runtime parameter.\nWe report the best head direction and its score for each language in Table 5. This baseline finds the head of each token based on its closest possible head, or on its immediate left or right neighbor if there is no head rule for the POS at hand, which means that this system does not necessarily yield well-formed tress. Each token receives a head, and while the structures are single-rooted, they are not necessarily connected. Note that we do not include results for the DMV model by Klein and Manning (2004), as it has been outperformed by a system similar to ours (S\u00f8gaard, 2012b). The usual adjacency baseline for unsupervised dependency parsing, where all words depend on their left or right neighbor, fares much worse than our baseline (20% UAS below on average) even with an oracle pick for the best per-language direction, and we do not report those scores."}, {"heading": "5.2 Evaluation setup", "text": "Our system relies solely on POS tags. To estimate the quality degradation of our system under non-gold POS scenarios, we evaluate UDP on two alternative scenarios. The first is predicted POS (UDPP ), where we tag the respective test set with TnT (Brants, 2000) trained on each language\u2019s training set. The second is a naive typeconstrained two-POS tag scenario (UDPN ), and approximates a lower bound. We give each word either CONTENT or FUNCTION tag, depending on the word\u2019s frequency. The 100 most frequent words of the input test section receive the FUNCTION tag.\nFinally, we compare our parser UDP to a supervised cross-lingual system (MSD). It is a multi-source delexicalized transfer parser, referred to as multi-dir in the original paper by McDonald et al. (2011). For this baseline we train TurboParser (Martins et al., 2013) on a delexicalized training set of 20k sentences, sampled uniformly from the UD training data excluding the target language. MSD is a competitive and realistic baseline in cross-lingual transfer parsing work. This gives us an indication how our system compares to standard cross-lingual parsers."}, {"heading": "5.3 Results", "text": "Table 5 shows that UDP is a competitive system; because UDPG is remarkably close to the supervised MSDG system, with an average difference of 6.4%. Notably, UDP even outperforms MSD on one language (Hindi).\nMore interestingly, on the evaluation scenario with predicted POS we observe that our system drops only marginally (2.2%) compared to MSD (2.7%). In the least robust rule-based setup, the error propagation rate from POS to dependency would be doubled, as either a wrongly tagged head or dependent would break the dependency rules. However, with an average POS accuracy by TnT of 94.1%, the error propagation is 0.37, i.e, each POS error causes 0.37 additional dependency errors. In contrast, for MSD this error propagation is 0.46, thus higher. 5\nFor the extreme POS scenario, content vs. function POS (CF), the drop in performance for UDP is very large, but this might be too crude an evaluation setup. Nevertheless, UDP, the simple unsupervised system with PageRank, outperforms the adjacency baselines (BL) by \u223c4% on average on the two type-based naive POS tag scenario. This difference indicates that even with very deficient POS tags, UDP can provide better structures."}, {"heading": "6 Discussion", "text": "In this section we provide a further error analysis of the UDP parser. We examine the contribution to the overal results of using PageRank to score content words, the behavior of the system across different parts of speech, and we assess the robustness of UDP on text from different domains.\n5Err. prop. = (E(ParseP )\u2212E(ParseG))/E(POSP ), where E(x) = 1\u2212 Accuracy(x)."}, {"heading": "6.1 PageRank contribution", "text": "UDP depends on PageRank to score content words, and on two-step decoding to ensure the leaf status of function words. In this section we isolate the constribution of both parts. We do so by comparing the performance of BL, UDP, and UDPNoPR, a version of UDP where we disable PR and rank content words according to their reading order, i.e., the first word in the ranking is the first word to be read, regardless of the specific language\u2019s script direction. The baseline BL described in 5.1 already ensures function words are leaf nodes, because they have no listed dependent POS in the head rules. The task of the decoding steps is mainly to ensure the resulting structures are well-formed dependency trees.\nIf we measure the difference between UDPNoPR and BL, we see that UDPNoPR contributes with 4 UAS points on average over the baseline. Nevertheless, the baseline is oracle-informed about the language\u2019s best branching direction, a property that UDP does not have. Instead, the decoding step determines head direction as described in Section 3.2. Complementarily, we can measure the contribution of PR by observing the difference between regular UDP and UDPNoPR. The latter scores on average 9 UAS points lower than UDP. These 9 points are caused by the difference attachment of content words in the first decoding step."}, {"heading": "6.2 Breakdown by POS", "text": "UD is a constantly improving effort, and not all v1.2 treebanks have the same level of formalism compliance. Thus, the interpretation of, e.g., the AUX\u2013VERB or DET\u2013PRON distinctions might differ across treebanks. However, we ignore these differences in our analysis and consider all treebanks to be equally compliant.\nThe root accuracy scores oscillate around an average of 69%, with Arabic and Tamil (26%) and Estonian (93%) as outliers. Given the PR personalization (Sec. 3.1), UDP has a strong bias for choosing the first verb as main predicate. Without personalization, performance drops 2% on average. This difference is consistent even for verbfinal languages like Hindi, given that the main verb of a simple clause will be its only verb, regardless of where it appears. Moreover, using PR personalization makes the ranking calculations converge a whole order of magnitude faster.\nThe bigram heuristic to determine adposition direction succeeds at identifying the predominant pre- or postposition preference for all languages (average ADP UAS of 75%). The fixed direction for the other functional POS is largely effective, with few exceptions, e.g., DET is consistently right-attaching on all treebanks except Basque (average overall DET UAS of 84%, 32% for Basque). These alternations could also be estimated from the data in a manner similar to ADP. Our rules do not make nouns eligible heads for verbs. As a result, the system cannot infer relative clauses. We have excluded the NOUN \u2192 VERB rule during development because it makes the hierarchy between verbs and nouns less conclusive.\nWe have not excluded punctuation from the evaluation. Indeed, the UAS for the PUNCT is low\n(an average of 21%, standard deviation of 9.6), even lower than the otherwise problematic CONJ. Even though conjunctions are pervasive and identifying their scope is one of the usual challenges for parsers, the average UAS for CONJ is much larger (an average of 38%, standard deviation of 13.5) than for PUNCT. Both POS show large standard deviations, which indicates great variability. This variability can be caused by linguistic properties of the languages or evaluation datasets, but also by differences in annotation convention."}, {"heading": "6.3 Cross-domain consistency", "text": "Models with fewer parameters are less likely to overfit for a certain dataset. In our case, a system with few, general rules is less likely to make attachment decisions that are very particular of a certain language or dataset. Plank and van Noord (2010) have shown that rulebased parsers can be more stable to domain shift. We explore if their finding holds for UDP as well, by testing on i) the UD development data as a readily available proxy for domain shift, and ii) manually curated domain splits of select UD test sets.\nDevelopment sets We have used the English development data to choose which relations would be included as head rules in the final system (Table 1). It would be possible that some of the rules are indeed more befitting for the English data or for that particular section.\nHowever, if we regard the results for UDPG in Table 5, we can see that there are 24 languages (out of 32) for which the parser performs better than for English. This result indicates that the head rules are general enough to provide reasonable parses for languages other than the one chosen for development. If we run UDPG on the development sections for the other languages, we find the results are very consistent. Any language scores on average \u00b11 UAS with regards to the test section. There is no clear tendency for either section being easier to parse with UDP.\nCross-domain test sets To further assess the cross-domain robustness, we retrieved the domain (genre) splits from the test sections of the UD treebanks where the domain information is available as sentence metadata: from Bulgarian, Croatian, and Italian. We also include a UD-compliant Serbian dataset which is not included in the UD release but which is based on the same parallel corpus as Croatian and has the same domain splits (Agic\u0301 and Ljube\u0161ic\u0301, 2015). When averaging we pool Croatian and Serbian together as they come from the same dataset.\nFor English, we have obtained the test data splits matching the sentences from the original distribution of the English Web Treebank. In addition to these already available datasets, we have annotated three different datasets to assess domain variation more extensively, namely the first 50 verses of the King James Bible, 50 sentences from a magazine, and 75 sentences from the test split in QuestionBank (Judge et al., 2006). We include the third dataset to evaluate strictly on questions, which we could do already in Italian. While the answers domain in English is made up of text from the Yahoo! Answers forum, only one fourth of the sentences are questions. Note these three small datasets are not included in the results on the canonical test sections in Table 5.\nTable 7 summarizes the per-language average score and standard deviation, as well as the macroaveraged standard deviation across languages. UDP has a much lower standard deviation across domains compared to MSD. This holds across lan-\nguages. We attribute this higher stability to UDP being developed to satisfy a set of general properties of the UD syntactic formalism, instead of being a data-driven method more sensitive to sampling bias. This holds for both the gold-POS and predicted-POS setup. The differences in standard deviation are unsurprisingly smaller in the predicted POS setup. In general, the rule-based UPD is less sensitive to domain shifts than the datadriven MSD counterpart, confirming earlier findings (Plank and van Noord, 2010).\nTable 6 gives the detailed scores per language and domain. From the scores we can see that presidential bulletin, legal and weblogs are amongst the hardest domains to parse. However, the systems often do not agree on which domain is hardest, with the exception of Bulgarian bulletin. Interestingly, for the Italian data and some of the hardest domains UDP outperforms MSD, confirming that it is a robust baseline."}, {"heading": "6.4 Comparison to full supervision", "text": "In order to assess how much information the simple principles in UDP provide, we measure how many gold-annotated sentences are necessary to reach its performance, that is, after which size the treebank provides enough information for training that goes beyond the simple linguistic principles outlined in Section 3.\nFor this comparison we use a first-order nonprojective TurboParser (Martins et al., 2013) following the setup of Agic\u0301 et al. (2016). The supervised parsers require around 100 sentences to reach UDP-comparable performance, namely a mean of 300 sentences and a median of 100 sentences, with Bulgarian (3k), Czech (1k), and German (1.5k) as outliers. The difference between mean and median shows there is great variance, while UDP provides very constant results, also in terms of POS and domain variation."}, {"heading": "7 Conclusion", "text": "We have presented UDP, an unsupervised dependency parser for Universal Dependencies (UD) that makes use of personalized PageRank and a small set of head-dependent rules. The parser requires no training data and estimates adposition direction directly from the input.\nWe achieve competitive performance on all but two UD languages, and even beat a multi-source delexicalized parser (MSD) on Hindi. We evaluated the parser on three POS setups and across domains. Our results show that UDP is less affected by deteriorating POS tags than MSD, and is more resilient to domain changes. Given how much of the overall dependency structure can be explained by this fairly system, we propose UDP as an additional UD parsing baseline. The parser, the in-house annotated test sets, and the domain data splits are made freely available.6\nUD is a running project, and the guidelines are bound to evolve overtime. Indeed, the UD 2.0 guidelines have been recently released. UDP can be augmented with edge labeling for some deterministic labels like case or det. Some further constrains can be incorporated in UDP. Moreover, the parser makes no special treatment of multiword expression that would require a lexicon, coordinations or proper names. All these three kinds of structures have a flat tree where all words depend on the leftmost one. While coordination attachment is a classical problem in parsing and out of the scope of our work, a proper name sequence can be straightforwardly identified from the partof-speech tags, and it falls thus in the area of structures predictable using simple heuristics. Moreover, our use of PageRank could be expanded to directly score the potential dependency edges instead of words, e.g., by means of edge reification."}, {"heading": "Acknowledgments", "text": "We thank the anonymous reviewers for their valuable feedback. H\u00e9ctor Mart\u00ednez Alonso is funded by the French DGA project VerDi. Barbara Plank thanks the Center for Information Technology of the University of Groningen for the HPC cluster. \u017deljko Agic\u0301 and Barbara Plank thank the Nvidia Corporation for supporting their research. Anders S\u00f8gaard is funded by the ERC Starting Grant LOWLANDS No. 313695.\n6https://github.com/hectormartinez/ud_unsup_parser"}], "references": [{"title": "The English noun phrase in its sentential aspect", "author": ["Steven Paul Abney"], "venue": "Ph.D. thesis,", "citeRegEx": "Abney.,? \\Q1987\\E", "shortCiteRegEx": "Abney.", "year": 1987}, {"title": "Multilingual Projection for Parsing Truly Low-Resource Languages", "author": ["Agi\u0107 et al.2016] \u017deljko Agi\u0107", "Anders Johannsen", "Barbara Plank", "H\u00e9ctor Alonso Mart\u00ednez", "Natalie Schluter", "Anders S\u00f8gaard"], "venue": null, "citeRegEx": "Agi\u0107 et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Agi\u0107 et al\\.", "year": 2016}, {"title": "If All You Have is a Bit of the Bible: Learning POS Taggers for Truly LowResource Languages", "author": ["Agi\u0107 et al.2015] \u017deljko Agi\u0107", "Dirk Hovy", "Anders S\u00f8gaard"], "venue": null, "citeRegEx": "Agi\u0107 et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Agi\u0107 et al\\.", "year": 2015}, {"title": "Linguistically na\u00cfve != language independent: Why NLP needs linguistic typology", "author": ["Emily M. Bender"], "venue": "In Proceedings of the EACL 2009 Workshop on the Interaction Between Linguistics and Computational Linguistics: Virtuous,", "citeRegEx": "Bender.,? \\Q2009\\E", "shortCiteRegEx": "Bender.", "year": 2009}, {"title": "TnT \u2013 A Statistical Part-of-Speech Tagger. In ANLP", "author": ["Thorsten Brants"], "venue": null, "citeRegEx": "Brants.,? \\Q2000\\E", "shortCiteRegEx": "Brants.", "year": 2000}, {"title": "Reprint of: The Anatomy of a Large-Scale Hypertextual Web Search Engine", "author": ["Brin", "Page2012] Sergey Brin", "Lawrence Page"], "venue": "Computer networks,", "citeRegEx": "Brin et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Brin et al\\.", "year": 2012}, {"title": "Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections", "author": ["Das", "Petrov2011] Dipanjan Das", "Slav Petrov"], "venue": null, "citeRegEx": "Das et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Das et al\\.", "year": 2011}, {"title": "Universal Stanford Dependencies: A Cross-Linguistic Typology", "author": ["Timothy Dozat", "Natalia Silveira", "Katri Haverinen", "Filip Ginter", "Joakim Nivre", "Christopher D Manning"], "venue": null, "citeRegEx": "Marneffe et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Marneffe et al\\.", "year": 2014}, {"title": "The Pascal Challenge on Grammar Induction", "author": ["Trevor Cohn", "Phil Blunsom", "Joao Gra\u00e7a"], "venue": "In Proceedings of the NAACL-HLT Workshop on the Induction of Linguistic Structure", "citeRegEx": "Gelling et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gelling et al\\.", "year": 2012}, {"title": "Sparsity in Dependency Grammar Induction", "author": ["Kuzman Ganchev", "Joao Gra\u00e7a", "Fernando Pereira", "Ben Taskar"], "venue": null, "citeRegEx": "Gillenwater et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Gillenwater et al\\.", "year": 2010}, {"title": "Bootstrapping Parsers via Syntactic Projection Across Parallel Texts", "author": ["Hwa et al.2005] Rebecca Hwa", "Philip Resnik", "Amy Weinberg", "Clara Cabezas", "Okan Kolak"], "venue": "Natural Language Engineering,", "citeRegEx": "Hwa et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Hwa et al\\.", "year": 2005}, {"title": "Universal dependencies for Danish", "author": ["H\u00e9ctor Mart\u00ednez Alonso", "Barbara Plank"], "venue": "In International Workshop on Treebanks and Linguistic Theories", "citeRegEx": "Johannsen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Johannsen et al\\.", "year": 2015}, {"title": "Joint Part-of-Speech and Dependency Projection from Multiple Sources", "author": ["\u017deljko Agi\u0107", "Anders S\u00f8gaard"], "venue": null, "citeRegEx": "Johannsen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Johannsen et al\\.", "year": 2016}, {"title": "Questionbank: Creating a Corpus of Parse-Annotated Questions", "author": ["Judge et al.2006] John Judge", "Aoife Cahill", "Josef Van Genabith"], "venue": null, "citeRegEx": "Judge et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Judge et al\\.", "year": 2006}, {"title": "Corpus-Based Induction of Syntactic Structure: Models of Dependency and Constituency", "author": ["Klein", "Manning2004] Dan Klein", "Christopher Manning"], "venue": null, "citeRegEx": "Klein et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Klein et al\\.", "year": 2004}, {"title": "Efficient Algorithms for Personalized PageRank. CoRR, abs/1512.04633", "author": ["Peter Lofgren"], "venue": null, "citeRegEx": "Lofgren.,? \\Q2015\\E", "shortCiteRegEx": "Lofgren.", "year": 2015}, {"title": "Unsupervised Dependency Parsing with Transferring Distribution via Parallel Guidance and Entropy Regularization", "author": ["Ma", "Xia2014] Xuezhe Ma", "Fei Xia"], "venue": null, "citeRegEx": "Ma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ma et al\\.", "year": 2014}, {"title": "Turning on the Turbo: Fast Third-Order Non-Projective Turbo Parsers", "author": ["Miguel Almeida", "Noah A. Smith"], "venue": null, "citeRegEx": "Martins et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Martins et al\\.", "year": 2013}, {"title": "Multi-Source Transfer of Delexicalized Dependency Parsers", "author": ["Slav Petrov", "Keith Hall"], "venue": null, "citeRegEx": "McDonald et al\\.,? \\Q2011\\E", "shortCiteRegEx": "McDonald et al\\.", "year": 2011}, {"title": "Using Universal Linguistic Knowledge to Guide Grammar Induction", "author": ["Naseem et al.2010] Tahira Naseem", "Harr Chen", "Regina Barzilay", "Mark Johnson"], "venue": null, "citeRegEx": "Naseem et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Naseem et al\\.", "year": 2010}, {"title": "Universal dependencies v1: A multilingual", "author": ["Nivre et al.2016] Joakim Nivre", "Marie-Catherine de Marneffe", "Filip Ginter", "Yoav Goldberg", "Jan Hajic", "Christopher D Manning", "Ryan McDonald", "Slav Petrov", "Sampo Pyysalo", "Natalia Silveira"], "venue": null, "citeRegEx": "Nivre et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Nivre et al\\.", "year": 2016}, {"title": "The PageRank Citation Ranking: Bringing Order to the Web", "author": ["Page et al.1999] Lawrence Page", "Sergey Brin", "Rajeev Motwani", "Terry Winograd"], "venue": null, "citeRegEx": "Page et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Page et al\\.", "year": 1999}, {"title": "Grammar-Driven versus DataDriven: Which Parsing System Is More Affected by Domain Shifts", "author": ["Plank", "van Noord2010] Barbara Plank", "Gertjan van Noord"], "venue": "In Proceedings of the 2010 Workshop on NLP and Linguistics: Finding the Common", "citeRegEx": "Plank et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Plank et al\\.", "year": 2010}, {"title": "Density-Driven Cross-Lingual Transfer of Dependency Parsers", "author": ["Rasooli", "Michael Collins"], "venue": null, "citeRegEx": "Rasooli et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rasooli et al\\.", "year": 2015}, {"title": "From Baby Steps to Leapfrog: How Less is More in Unsupervised Dependency Parsing", "author": ["Hiyan Alshawi", "Daniel Jurafsky"], "venue": null, "citeRegEx": "Spitkovsky et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Spitkovsky et al\\.", "year": 2010}, {"title": "Viterbi Training Improves Unsupervised Dependency Parsing", "author": ["Hiyan Alshawi", "Daniel Jurafsky", "Christopher Manning"], "venue": "In CoNLL", "citeRegEx": "Spitkovsky et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Spitkovsky et al\\.", "year": 2010}, {"title": "Data Point Selection for Cross-Language Adaptation of Dependency Parsers", "author": ["Anders S\u00f8gaard"], "venue": "In NAACL", "citeRegEx": "S\u00f8gaard.,? \\Q2011\\E", "shortCiteRegEx": "S\u00f8gaard.", "year": 2011}, {"title": "Two Baselines for Unsupervised Dependency Parsing", "author": ["Anders S\u00f8gaard"], "venue": "In Proceedings of the NAACL-HLT Workshop on the Induction of Linguistic Structure", "citeRegEx": "S\u00f8gaard.,? \\Q2012\\E", "shortCiteRegEx": "S\u00f8gaard.", "year": 2012}, {"title": "Unsupervised dependency parsing without training", "author": ["Anders S\u00f8gaard"], "venue": "Natural Language Engineering,", "citeRegEx": "S\u00f8gaard.,? \\Q2012\\E", "shortCiteRegEx": "S\u00f8gaard.", "year": 2012}, {"title": "Rediscovering Annotation Projection for Cross-Lingual Parser Induction", "author": ["J\u00f6rg Tiedemann"], "venue": "In COLING", "citeRegEx": "Tiedemann.,? \\Q2014\\E", "shortCiteRegEx": "Tiedemann.", "year": 2014}, {"title": "Inducing Multilingual Text Analysis Tools via Robust Projection Across Aligned Corpora", "author": ["Grace Ngai", "Richard Wicentowski"], "venue": "In HLT", "citeRegEx": "Yarowsky et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Yarowsky et al\\.", "year": 2001}, {"title": "Cross-Language Parser Adaptation Between Related Languages", "author": ["Zeman", "Resnik2008] Daniel Zeman", "Philip Resnik"], "venue": "In IJCNLP", "citeRegEx": "Zeman et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Zeman et al\\.", "year": 2008}], "referenceMentions": [{"referenceID": 8, "context": "Grammar induction and unsupervised dependency parsing are active fields of research in natural language processing (Klein and Manning, 2004; Gelling et al., 2012).", "startOffset": 115, "endOffset": 162}, {"referenceID": 0, "context": "used a DP analysis (Abney, 1987).", "startOffset": 19, "endOffset": 32}, {"referenceID": 18, "context": "Even supervised transfer approaches (McDonald et al., 2011) suffer from target adaptation problems when facing word order differences.", "startOffset": 36, "endOffset": 59}, {"referenceID": 20, "context": "The Universal Dependencies (UD) project (Nivre et al., 2015; Nivre et al., 2016) offers a dependency formalism that aims at providing a consistent representation across languages, while enforcing a few hard constraints.", "startOffset": 40, "endOffset": 80}, {"referenceID": 11, "context": "Johannsen et al. (2015) for more details, we expect that such a formalism lends itself more naturally to a simple and linguistically sound rulebased approach to cross-lingual parsing.", "startOffset": 0, "endOffset": 24}, {"referenceID": 3, "context": "We ascribe our work to the viewpoints of Bender (2009) about the incorporation of linguistic knowledge in language-independent systems.", "startOffset": 41, "endOffset": 55}, {"referenceID": 18, "context": "Cross-lingual learning Recent years have seen exciting developments in cross-lingual linguistic structure prediction based on transfer or projection of POS and dependencies (Das and Petrov, 2011; McDonald et al., 2011).", "startOffset": 173, "endOffset": 218}, {"referenceID": 30, "context": "The first group of approaches deals with annotation projection (Yarowsky et al., 2001), whereby parallel corpora are used to transfer annotations between resource-rich source languages and lowresource target languages.", "startOffset": 63, "endOffset": 86}, {"referenceID": 10, "context": "Hwa et al. (2005) were the first to project syntactic dependencies, and Tiedemann et al.", "startOffset": 0, "endOffset": 18}, {"referenceID": 25, "context": "S\u00f8gaard (2011) and McDonald et al.", "startOffset": 0, "endOffset": 15}, {"referenceID": 18, "context": "S\u00f8gaard (2011) and McDonald et al. (2011) independently extended the approach by using multiple sources, requiring uniform POS and dependency representations (McDonald et al.", "startOffset": 19, "endOffset": 42}, {"referenceID": 1, "context": "Agi\u0107 et al. (2015; 2016) exposed some of these biases in their proposal for realistic cross-lingual tagging and parsing, as they emphasized the lack of perfect sentence- and word-splitting for truly low-resource languages. Further, Johannsen et al. (2016) introduced joint projection of POS and dependencies from multiple sources while sharing the outlook on bias removal in real-world multilingual processing.", "startOffset": 0, "endOffset": 256}, {"referenceID": 9, "context": "Our work builds on the line of research on rule-aided unsupervised dependency parsing by Gillenwater et al. (2010) and Naseem et al.", "startOffset": 89, "endOffset": 115}, {"referenceID": 9, "context": "Our work builds on the line of research on rule-aided unsupervised dependency parsing by Gillenwater et al. (2010) and Naseem et al. (2010), and also relates to S\u00f8gaard\u2019s (2012a; 2012b) work.", "startOffset": 89, "endOffset": 140}, {"referenceID": 15, "context": "i) the usage of PageRank personalization (Lofgren, 2015), and of ii) two-step decoding to treat content and func-", "startOffset": 41, "endOffset": 56}, {"referenceID": 21, "context": "Our system uses the PageRank (PR) algorithm (Page et al., 1999) to estimate the relevance of the content words of a sentence.", "startOffset": 44, "endOffset": 63}, {"referenceID": 21, "context": "Our system uses the PageRank (PR) algorithm (Page et al., 1999) to estimate the relevance of the content words of a sentence. PR uses a random walk to estimate which nodes in the graph are more likely to be visited often, and thus, it gives higher rank to nodes with more incoming edges, as well as to nodes connected to those. Using PR to score word relevance requires an effective graphbuilding strategy. We have experimented with the strategies by S\u00f8gaard (2012b), such as words being connected to adjacent words, but our system fares best strictly using the dependency rules in Table 1 to build the graph.", "startOffset": 45, "endOffset": 467}, {"referenceID": 4, "context": "The first is predicted POS (UDPP ), where we tag the respective test set with TnT (Brants, 2000) trained on each language\u2019s training set.", "startOffset": 82, "endOffset": 96}, {"referenceID": 17, "context": "For this baseline we train TurboParser (Martins et al., 2013) on a delexicalized training set of 20k sentences, sampled uniformly from the UD training data excluding the target language.", "startOffset": 39, "endOffset": 61}, {"referenceID": 17, "context": "It is a multi-source delexicalized transfer parser, referred to as multi-dir in the original paper by McDonald et al. (2011). For this baseline we train TurboParser (Martins et al.", "startOffset": 102, "endOffset": 125}, {"referenceID": 13, "context": "a magazine, and 75 sentences from the test split in QuestionBank (Judge et al., 2006).", "startOffset": 65, "endOffset": 85}, {"referenceID": 17, "context": "For this comparison we use a first-order nonprojective TurboParser (Martins et al., 2013) following the setup of Agi\u0107 et al.", "startOffset": 67, "endOffset": 89}, {"referenceID": 1, "context": ", 2013) following the setup of Agi\u0107 et al. (2016). The supervised parsers require around 100 sentences to reach UDP-comparable performance, namely a mean of 300 sentences and a median of 100 sentences, with Bulgarian (3k), Czech (1k), and Ger-", "startOffset": 31, "endOffset": 50}], "year": 2017, "abstractText": "We propose UDP, the first training-free parser for Universal Dependencies (UD). Our algorithm is based on PageRank and a small set of head attachment rules. It features two-step decoding to guarantee that function words are attached as leaf nodes. The parser requires no training, and it is competitive with a delexicalized transfer system. UDP offers a linguistically sound unsupervised alternative to cross-lingual parsing for UD, which can be used as a baseline for such systems. The parser has very few parameters and is distinctly robust to domain change across languages.", "creator": "LaTeX with hyperref package"}}}