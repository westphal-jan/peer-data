{"id": "1701.04039", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2017", "title": "The Birth of Collective Memories: Analyzing Emerging Entities in Text Streams", "abstract": "We study doing sake legacy so forming web. We wanted you but computerized entities there overcome but personal naturalism, yet is, in online text areas those well politics website made broadcast gullies, when they they incorporated into Wikipedia, which, we explain, can be viewed came an publishers rest years collective memory. By operating very entities emerge in services allegory, little. e. , has temporal patterns its their same mention months online uses streams once subsequent forms brought collective images, does gain comparative into how the acts remembrance process tell online. Specifically, we analyze nearly 165, 000 businesses so quickly agree in computer word streams before they that formerly and Wikipedia. The ebay text spawning nothing use for supposed indicate consist following leadership that same news streams, and seven had 579 1,000 reviewed present a timespan taken 18 coming. We happens some main influences describe: overlapping believe re in a \" pagodula \" fit, else. servers. , that ones also policy didactic even a notion, ambush into activity each plan into collective ipod. Other entities designed no \" delayed \" pattern, outside what still in public socio-political, critical also last similar inactivity, include then hyperventilate again seamlessly and why cultural collective mental.", "histories": [["v1", "Sun, 15 Jan 2017 13:34:43 GMT  (1042kb,D)", "http://arxiv.org/abs/1701.04039v1", "37 pages, 10 figures"]], "COMMENTS": "37 pages, 10 figures", "reviews": [], "SUBJECTS": "cs.IR cs.CL", "authors": ["david graus", "daan odijk", "maarten de rijke"], "accepted": false, "id": "1701.04039"}, "pdf": {"name": "1701.04039.pdf", "metadata": {"source": "CRF", "title": "The Birth of Collective Memories: Analyzing Emerging Entities in Text Streams", "authors": ["David Graus", "Daan Odijk", "Maarten de Rijke"], "emails": ["dpgraus@gmail.com,", "daan@blendle.com,", "derijke@uva.nl"], "sections": [{"heading": null, "text": "We discover two main emergence patterns: entities that emerge in a \u201cbursty\u201d fashion, i.e., that appear in public discourse without a precedent, blast into activity and transition into collective memory. Other entities display a \u201cdelayed\u201d pattern, where they appear in public discourse, experience a period of inactivity, and then resurface before transitioning into our cultural collective memory."}, {"heading": "1 Introduction", "text": "Remembering is a social process [19]. Collective remembrance is the process in which information moves from public discourse into a shared collective memory. In the literature this process has been described as being similar to the remembrance process of an individual, whose memories or experiences transfer from short-term into long-term memory [1]. This comparison has\n\u2217Corresponding author.\nar X\niv :1\n70 1.\n04 03\n9v 1\n[ cs\n.I R\n] 1\nbeen formalized by mapping the collective\u2019s equivalent of the individual\u2019s long-term and shortterm memory to the collective\u2019s cultural and communicative memory, respectively.\nCultural collective memory (CM), the collective\u2019s equivalent of an individual\u2019s long-term memory, is characterized by being organized, specialized, formal, structured, and distanced from the immediate [1]. Wikipedia is known to \u201cdemocratize information,\u201d through its collaborative nature: its content is being produced by volunteer editors and authors from all over the world [49]. Wikipedia has been called an online place for cultural CM [31, 38]. We support this view, and argue that the aforementioned characteristics fit Wikipedia\u2019s nature. First, Wikipedia is organized, through its hierarchy of contributors, where authors are distinguished from admins. Wikipedia is specialized, since appropriately citing relevant and expert sources to support and back up newly added information is a requirement. These conventions, requirements, and policies around contributing new information to Wikipedia impose a level of formality and enable its coherent and consistent structure. Finally, the requirement for new articles to be collectively deemed \u201cimportant enough,\u201d ensures Wikipedia\u2019s distance from the immediate.\nCommunicative CM is in many aspects the opposite of cultural CM. Analogously to an individual\u2019s short-term memory, communicative CM is mainly orally negotiated, close to the everyday, disorganized, informal, and non-specialized [1]. The large volume of content that is produced continuously in online text streams fits this notion of orally negotiated memory: the highly interactive and reactive nature of the content, through the rapid pace and high volume at which it is created, means that\u2014as opposed to the carefully curated and edited nature of Wikipedia\u2014online text streams are close to the everyday: they not only record and reflect the actions of everyday life but also have a role in producing everyday life for a media-enabled public [44, p. 33]. With the advent of Web 2.0, and the ability for anyone to publish content and participate in public discourse on the web, online text streams became disorganized, informal, and non-specialized.\nIn this paper, we study the evolution of collective memory, by tracking additions to our online cultural collective memory, Wikipedia. Specifically, we study the link between what happens in the news and social media on the one hand and the addition of new Wikipedia articles on the other hand, by tracking real world entities as they emerge in the former (our communicative CM), before they are added to the latter (our cultural CM).1 Entities that emerge in communicative CM and that are deemed important enough to be incorporated into cultural CM are thereby deemed important enough to be collectively remembered. With Wikipedia as an online place for cultural CM, we are able to detail and study the collective remembrance process through the process of Wikipedia\u2019s expansion.\nEvery day, new content is being added to Wikipedia, with the knowledge base receiving over 6 million monthly edits at its peak [43]. Domain experts may find information missing on Wikipedia, and take up the task of contributing this new information. Alternatively, as events unfold in the real world, new, previously unknown, and unheard-of entities (people, organizations, products, etc.) emerge into public discourse. These new entities emerge online in news\n1By an \u201centity\u201d we follow standard practice and mean a thing with distinct and independent existence, e.g., a person or device (Oxford Dictionary, http://www.oxforddictionaries.com/definition/english/ entity).\narticles and social media postings that may describe or comment on events, e.g., the Olympics may introduce new athletes onto the world stage, a newly announced smartphone or video game console may generate a wave of activity on social media, or the opening of a new restaurant may be reported in local news media and pop up in social media.\nStudying our collective memory through studying the entities that emerge in public discourse gives us insights into how collective memory evolves\u2014for the first time, the online world allows us to make these sort of observations at a large scale. Furthermore, in today\u2019s digital world, with virtually unconstrained ways of digitally storing information, we can keep accumulating events in our communicative collective memory in great detail. Studying which entities transition to our cultural CM, their properties and emergence patterns, is a cornerstone for understanding what we, humans, find important to remember as a collective.\nIn this paper, we study \u201cemerging entities,\u201d which we consider to be the core unit for understanding the collective remembrance process. We analyze a sample of online social media and news text streams, spanning over 18 months and comprising over 579 million documents. We focus on the emergence patterns of these entities, i.e., how a new entity\u2019s exposure develops and evolves in the timespan between the entity\u2019s first mention in online text streams, and when an article devoted to the entity is subsequently added to Wikipedia. More precisely, we define an entity\u2019s emergence pattern to be its \u201cdocument mention time series,\u201d i.e., the time series that represents the number of documents that mention a specific entity over time, starting at the moment it is first mentioned, up to the moment it is incorporated into Wikipedia.\nAn example of one such emergence pattern is shown in Figure 1. The time series shows the number of documents that mention a given entity per day on the y-axis (i.e., the emergence volume), with the x-axis representing the time between the first mention of the entity in the online text stream and the day it is added to Wikipedia (i.e., the emergence duration).2 Since emergence durations naturally differ between entities, our time series are of variable length. As we are interested in broad attention patterns, we study document mention time series, as opposed to total mention volume. And because we want to study global, broad, and long-term patterns, our time series are at a granularity of days, not hours.\nThe main findings of this paper are as follows. By clustering time series of mentions of entities as these entities emerge in news and social media streams, we find broadly two different emergence patterns: entities that show a strong initial burst around the time of their introduction into public discourse, and late bursting entities that exhibit a more gradual emergence pattern. Furthermore, we find meaningful differences between how entities emerge in social media and news streams: entities that emerge in social media streams exhibit a slower transition from communicative CM to cultural CM than entities emerging in news streams. Finally, we show how different types of real world entities exhibit different emergence patterns; we find that the entities that emerge fastest are entity types that know shorter life-cycles such as devices (e.g., smartphones), and \u201ccultural artifacts\u201d (e.g., movies and music albums).\nIn Section 2 we describe related work for this study. In Section 3 we formulate our research questions. The data that we use in our study is described in Section 4. In Section 5 we detail\n2This is the English version of Wikipedia; see Section 4 for details on the data used in this paper.\nthe methods used to analyze the data. Results of our analysis are presented in Section 6. We conclude in Section 7."}, {"heading": "2 Related Work", "text": "Two types of work are related to this paper: work on collective memory and work on the growth and development of Wikipedia."}, {"heading": "2.1 Collective memory", "text": "The concept \u201ccollective memory\u201d was analyzed and advanced in the 1920s by Halbwachs [18]; see also [19]. The notion of a \u201cshared pool of knowledge and information in the memories of a social group,\u201d depends upon the framework of a group in a society. Since its introduction the concept has been studied in a wide variety of interdisciplinary fields, most notably in literature, history, and media [8, 37] but also in (experimental) psychology [20, 41, 51], e.g., by emperically studying the performance of remembering events of different members of a single social group [5].\nWikipedia was first dubbed a global memory place where collective memories are built by Pentzold [38], with follow-up studies by Keegan [25] and Ferron and Massa [11] shortly after that. As Ferron [10, p. 23] puts it, \u201cWikipedia\u2019s processes of discussion and article construction can be seen as the discursive formation of memory, or in other terms, as the transition from communicative memory, which is interactive, informal, nonspecialized, reciprocal, disorganized and unstable, to cultural memory, which is formal, well organized and objective\u201d (our italics).\nIn the context of online collective memory, studies have revolved around automated methods for analyzing texts, e.g., by extracting and studying temporal expressions from web documents it has been shown that we tend to remember the \u201cnear past\u201d online [2]. Other sources used for online collective memory studies include search engine query logs [6], and microblog services [23].\nOur work differs from previous work on collective memory in two important ways. We are the first to empirically study the transition from communicative CM to collective CM in terms of entities being mentioned in news and social text streams prior to being included in Wikipedia. And we are the first to empirically study this transition at scale and across text streams and entity types, signifying an important difference from the case studies that often involve dramatic or traumatizing events that are characteristic of the study of \u201ccollective memory\u201d [30, 36]."}, {"heading": "2.2 Growth and development of Wikipedia", "text": "Previous work on studying the expansion of Wikipedia through the addition of new pages studies the phenomenon from the perspective of Wikipedia itself, e.g., by analyzing how newly created articles fit in Wikipedia\u2019s semantic network, studying the relation between activity on talk pages and the addition of new content to articles, or by studying controversy and disagreement on new content through \u201cedit wars\u201d [24, 26, 52, 53].\nStudying emerging entities has received considerable attention from the natural language processing and information retrieval communities. Most notably, different methods and systems for identifying and linking unknown or emerging entities have been proposed [21, 29, 35, 48]. Graus et al. [16] study the problem of predicting new concepts in social streams. More recently, Fa\u0308rber et al. [9] formalize and analyze the specific challenges and aspects that come with linking emerging entities, while Reinanda et al. [42] study the problem of identifying relevant documents for known and emerging as as new information comes in and Graus et al. [17] present a method for updating representations based on newly identified information.\nOur work differs from the aforementioned studies in being largely observational in nature, focusing on temporal patterns of emerging entities, and studying it from the perspective of the \u201coutside world,\u201d not Wikipedia."}, {"heading": "3 Research Questions", "text": "In studying emergence patterns of entities, we apply different methods for grouping entities. Specifically, we apply three grouping strategies, representing alternative views on emerging entities. In Section 6.1 below, we apply a burst-based unsupervised hierarchical clustering method to cluster similar entity emergence patterns, so as to discover groups of entities with broadly\ncommon emergence patterns. That is, we group entity time series by similarities in the peaks of comparatively higher activity (i.e., peaks of exposure in public discourse). This type of analysis is meant to help us answer the following research question:\nRQ1 Are there common patterns in how entities emerge in online text streams?\nWe show that entities emerge in two distinct patterns: so-called early bursting (EB) entities, that show a strong initial burst around the time of their introduction into public discourse, or late bursting (LB) entities, that exhibit a more gradual emergence pattern. EB entities are shown to transition from communicative to cultural CM more quickly than LB entities.\nIn Section 6.2, we adopt an alternative view of emerging entities, and examine their emergence patterns in different types of text stream, comparing patterns between entities that emerge in news to social media streams. This view is motivated by perceived differences in the nature of the professionally curated, authoritative, and high impact, \u201cmainstream media\u201d versus the usergenerated, unedited, social media streams. We apply two grouping methods. First, we group the time series by type of text stream, and provide their descriptive statistics, hypothesizing that news streams will exhibit shorter emergence durations than social media streams, due to their reach and impact. We also analyze the cross-pollination between the two types of stream, i.e., we study whether entities appear first in either of the streams, or whether they appear in both at the same time, etc. These analyses help us answer the following research question:\nRQ2 Do news and social media text streams exhibit different emergence patterns?\nWe find that news and social media streams show broadly similar emergence patterns for entities. However, entities that first emerge in social media streams exhibit slower transitions from communicative to cultural CM than entities that first emerge in news streams.\nFinally, in Section 6.3, we study the similarities and differences between different types of entities as they emerge in public discourse. Specifically, we leverage DBpedia, the structured counterpart of Wikipedia, to group emerging entities by their underlying entity types, such as companies, athletes, and video games. This allows us to gain insights into whether different types of entities exhibit different emergence patterns. In addition, by considering entity types we study whether the news stream and the social stream exhibit different focal points, i.e., where professionally curated news streams exhibit a focus on the mainstream and user-generated social media streams surface more niche entities. This analysis helps us answer the following research question:\nRQ3 Do different types of entities exhibit different emergence patterns?\nWe find that different entity types exhibit substantially different emergence patterns. Furthermore, we find that specific entity types are more or less likely to emerge in either the news or social media streams, which can be largely attributed to the different nature of both streams, and their authors. Finally, we find that entity types that have shorter emergence durations remain popular over time. The findings suggest that the entity types that transition relatively fast from communicative to cultural CM, take a more central place in our cultural CM."}, {"heading": "4 Data", "text": "As described in the introduction, we study the emergence patterns of entities by looking at the lead time between the first mention of an entity, i.e., its first appearance in communicative CM, up to its subsequent incorporation into Wikipedia, i.e., its transition into cultural CM. To study these emergence patterns, we generate a custom dataset of timestamped documents that are annotated retrospectively with links to Wikipedia, including for each link (i) the creation date of the associated Wikipedia page, and (ii) whether the Wikipedia page existed at the time the document was created. Our dataset spans 7.3 million documents with 36.2 million references to 79,482 unique emerging entities. We create this dataset by extending an existing document-stream dataset (TREC KBA\u2019s StreamCorpus 20143) with an additional set of annotations to Freebase (FAKBA14). We enrich the dataset by including Wikipedia creation dates of the Freebase entities, and the relative age of the entity to the document. We subsequently reduce this dataset by filtering out documents that have \u201cfuture leaks\u201d, i.e., that contain references to entities whose Wikipedia pages were created after the dataset\u2019s timespan. Below, we describe our data acquisition and preparation processes in detail."}, {"heading": "4.1 Emerging entities in news and social media", "text": "Our dataset is derived from the TREC KBA StreamCorpus 2014, a dataset of roughly 1.2 billion timestamped documents from various sources, e.g., blog and forum posts and newswires. It spans 572 days (or roughly 18 months) from October 7th, 2011 to May 1st, 2013 (line 1 in Table 1). The StreamCorpus is composed of multiple subsets, with slightly different periods and volumes (i.e., numbers of documents). All documents in the corpus that were automatically classified as being written in English have been automatically tagged for named entities with the Serif tagger [4], yielding roughly 580M tagged documents. This annotated subset of documents was the official collection for the TREC Knowledge Base Acceleration (KBA) task in 2014 [14].\nDalton et al. [7] further annotated these 580M documents with Freebase entities, resulting in the Freebase Annotations of TREC KBA 2014 Stream Corpus, v1 (FAKBA1) dataset, which spans over 394M documents (line 2 in Table 1). It is essential to our study that the Freebase dump used for linking the entities is dated after the span of the StreamCorpus. Because of this, we can isolate entities that are mentioned (i.e., linked) in documents before their corresponding Wikipedia page was created.\nWe take an entity\u2019s Wikipedia page creation date to be the time at which the entity transitions from communicative to cultural CM. To extract Wikipedia page creation dates for the entities present in the TREC KBA StreamCorpus 2014, we first map the Freebase entities linked in the FAKBA1 collection to their corresponding Wikipedia pages, using the available mappings in Freebase. We extract Wikipedia page creation dates from a dump of Wikipedia with the full revision history of all pages (enwiki-latest-page-meta-history.xml). We append the Wikipedia page creation date or entity timestamp (denoted eT ) to each entity in FAKBA1. In\n3http://trec-kba.org/kba-stream-corpus-2014.shtml 4http://trec-kba.org/data/fakba1/"}, {"heading": "3. FAKBAT 2,254,177 (68.9%) 9,221,204,641 (97.8%) 394,051,027 (100%)", "text": ""}, {"heading": "4. OOKBAT 225,291 (10.0%) 94,929,292 (1.0%) 23,896,922 (6.1%)", "text": "addition, we include the entity\u2019s \u201cage\u201d relative to the document timestamp (docT ): the difference between the Wikipedia page creation date and the document timestamp, i.e., eage = eT \u2212 docT . The resulting dataset, FAKBA1, extended with the entity age and entity timestamp, is denoted FAKBAT (Freebase Annotations of TREC KBA 2014 Stream Corpus with Timestamps), see line 3 in Table 1.\nAs a next step, we filter to retain only documents that contain emerging entities. Emerging entities are entities with eage < 0, i.e., entities mentioned in documents dated before the entity\u2019s Wikipedia creation date. We denote the resulting subset of FAKBAT documents with emerging entities OOKBAT (Out of Knowledge Base Annotations (with) Timestamps). This yields a set of nearly 24M documents (line 4 in Table 1).\nTo be able to study an emerging entity\u2019s complete emergence pattern, we take two additional filtering steps. First, we prune entities with creation dates later than the last document in our stream, to ensure the entities emerged in the timespan of our document stream, i.e., we remove all entities whose Wikipedia page has a creation date later than May 1st, 2013. Next, we prune all entities that are mentioned in fewer than 5 documents, to be able to visualize and study their time series. This yields our final dataset, which comprises 79,482 emerging entities (line 5 in Table 1)."}, {"heading": "4.1.1 Entity types", "text": "In the analysis in Section 6.3, we leverage an entity\u2019s \u201cclass\u201d from the DBpedia ontology.5 Freebase provides mappings to Wikipedia and its structured counterpart DBpedia. In the DBpedia ontology, an entity is assigned to one or more classes in a tree-like class structure. We map each of our emerging entities to the classes assigned in DBpedia, e.g., the entity Barack Obama is\n5http://mappings.dbpedia.org/server/ontology/classes/\nmapped to the Person, Politician, Author, Award Winner classes. We extract these mappings by extracting all triples that have rdf:type property (e.g., Barack Obama <rdf:type> Person). Out of the 79,482 emerging entities in our dataset, we have 39,713 class-mappings (i.e., a coverage of 50.0%)."}, {"heading": "4.1.2 Entity popularity", "text": "Finally, as a proxy for an entity\u2019s popularity, which we use to study the composition of clusters and the different substreams in Section 6.3, we extract Wikipedia pageview statistics. More specifically, we extract the total number of pageviews each entity received during 2015. We choose to use the pageview counts of a year that falls outside of the timespan of our dataset so as to minimize the effects of timeliness (i.e., we want to separate the true \u201chead\u201d entities from the ones that have a shorter lifespan)."}, {"heading": "4.2 Timeseries of emerging entity mentions", "text": "We use the dataset that we have created, the annotated subset of documents in the TREC KBA StreamCorpus 2014 containing emerging entities, to generate time series that describe their emergence. Figure 2 shows the document volume over time of the different streams in our dataset. It shows a larger number of news documents compared to social media documents in the first half of the data, and a larger number of social media compared to news documents in the second half. In total, the news stream comprises 1,836,022 documents, making it substantially smaller\nthan the social media stream, at 5,357,014 documents. The news and social media streams themselves are composed of multiple datasets from different sources [13], which explains the gap seen around May 2012 up to somewhere in July 2012.\nWe note that 79,482 entities emerge during the 18+ month (572 days) timespan of the TREC KBA StreamCorpus 2014 dataset, i.e., on average over 138 new entities emerge per day. Looking at the distribution at which these entities emerge over time, we observe in Figure 3 that they do not emerge uniformly. In particular, Figure 3 shows a gradual increase of emerging entities between the start of our dataset and May 2012, at which it peaks. The subsequent gap can be explained by the absence of the news stream during that time (see also Figure 2).\nThe core unit in our analysis are so-called entity document mention time series, i.e., time series that represent the number of documents that mention an entity over time (see, e.g., Mars Curiosity\u2019s document mention time series in Figure 1). These time series are characterized by several properties. First, the time series are of variable length: each entity\u2019s time series starts at the first mention of the entity in our dataset, and ends at the day the Wikipedia page for that entity was created. For some entities, the time series may span several days, whereas others may span months. Second, the time series in our dataset are not temporally aligned. They exhibit different absolute timings, where the date of the first mention (i.e., the start of the time series) and last mention (i.e., the end of the time series) varies between emerging entities."}, {"heading": "5 Methods", "text": "Our first research question, Are there common patterns in how entities emerge in online text streams? (RQ1), revolves around discovering common emergence patterns. We apply a time series clustering method for discovering groups of entities with similar emergence patterns. In this section, we first describe our time series clustering method, explain and motivate the choices for representing the emerging entity\u2019s time series. After that, we describe the general time series analysis methods that we use."}, {"heading": "5.1 Time series clustering", "text": "Clustering time series consists of three steps: First, we need to normalize our timeseries as they might span very different periods of time. Next, we measure the similarity between time series by applying a similarity metric. And third, we apply a hierarchical agglomerative clustering method to group entities in groups with similar emergence patterns."}, {"heading": "5.1.1 Normalization", "text": "As described in Section 4.2, the timeseries in our dataset might span different periods and are not temporarily aligned. For these reasons we cannot rely on time series analysis and modeling methods that leverage aligned time series or seasonal patterns. Because of variable lengths, we cannot leverage similarity methods that assume a correspondence between the data points between two time series such as, e.g., Euclidean distance. Furthermore, to be able to visualize clusters and groups of similar time series, we linearly interpolate the time series to have equal length [40]. Finally, as we are interested in the similarity in emergence patterns, not in individual differences between popular and long-tail entities (i.e., absolute number of mentions), we standardize all time series by subtracting the mean and dividing by standard deviation to account for the differences in volume/popularity [46]."}, {"heading": "5.1.2 Burst similarity", "text": "Typically, time series similarity metrics rely on fixed-length time series, and leverage seasonal or repetitive patterns [28]. But as noted above, our time series are of variable length, and not temporally aligned. For this reason, common time series similarity metrics such as Dynamic Timewarping (DTW) are not applicable [3]. We are interested in the moments at which the attention or focus around an entity in public discourse increases, i.e., we are looking for periods with higher activity. These so-called time series \u201cbursts\u201d may be correlated to real-world activity and events around the entity.\nTo address the nature of our time series as well as our focus on bursts, we turn to BSim [46] (Burst Similarity) as the similarity metric we leverage to compare time series. It relies on detecting bursts, and using the overlap in bursts between time series as the notion of similarity.\nFor burst detection, we compute a moving average for each (raw) entity document mention time series (Te), denoted TMAe . We set our parameter w, indicating the size of the rolling window\nto 7 days. Bursts are the points in TMAe that surpass a cutoff value (c). We set c = 1.5 \u00b7 \u03c3MA, where \u03c3MA is the standard deviation of MA. These parameter choices for w and c are in line with previous work [46]. Figure 4 shows an example time series (Te), with the bursts detected for the emerging entity Curiosity (rover). The detected bursts correspond to the earlier described launch and landing of the Mars Rover."}, {"heading": "5.1.3 Hierarchical agglomerative clustering", "text": "Now that we can measure similarity between time series, we need to identify clusters of similar time series. To this end, we compute the Similarity Matrix (SM ) with all pair-wise burst similarities. More specifically, to cluster emerging entities, we first apply L2 normalization to SM , and then convert it to a distance matrix DM (DM = 1\u2212SM ). Next, we apply hierarchical agglomerative clustering (HAC) on DM using the fastcluster package [34] to discover groups of similar time series at different levels of granularity. We apply Ward\u2019s method as our linkage criterion. Ward\u2019s method is an iterative approach, where one starts with singleton clusters, and aims to merge the pair of samples that maximally decreases the within-cluster variance at each successive iteration [50]."}, {"heading": "5.2 Time series analysis", "text": "Throughout this paper we take an exploratory approach to analyzing, visualizing, and comparing patterns of groups of time series to discover meaningful clusterings [47]. We apply different grouping strategies, e.g., implicit groups, such as the clusters we find by using our clustering method, or explicit groups, e.g., entities that emerge either in social media or in news streams.\nWe apply two analysis methods to study different groups of time series: (i) visualization of group signatures that represent common emergence patterns within a group of time series, and (ii) analysis of descriptive statistics that reflect properties of the underlying time series."}, {"heading": "5.2.1 Visualization", "text": "To compare patterns and trends across different groups of emerging entities, we visualize and compare the so-called group signatures, i.e., the average of all time series that belong to a group. See Figure 6 below for an example of the group signature of all emerging entities in our dataset (n = 79,482).\nTwo challenges specific to the time series that we study in this paper arise when visualizing them. First, their duration. The time series we study in this paper (may) differ in length, as emergence durations differ between entities. Second, their alignment. The time series are not temporally aligned, as their start (i.e., x = 0) is marked when the entity is first mentioned in the online text stream, and end at the time at which the entity is incorporated into Wikipedia. For these reasons, we linearly interpolate the time series to the (overall) highest emergence duration, effectively \u201cstretching\u201d them to have equal length. Next, we align them in relative duration, i.e., the first and last mentions for each entity is set at the start and end of the x-axis, respectively. This allows us to visualize both the clusters themselves, and the corresponding cluster signatures."}, {"heading": "5.2.2 Descriptive statistics", "text": "While studying group signatures of time series allows us to discover similar patterns and study and compare broad patterns and trends, they do not paint the full picture. More fine-grained properties of emergence patterns, e.g., the average emergence duration (the time between a new entity\u2019s first mention in the text stream and its subsequent incorporation into Wikipedia) and the emergence volume (the total number of documents that mention the new entity before it is incorporated into Wikipedia) are difficult to convey through visualization alone. In order to study these aspects, we represent the groups of time series through different descriptive features that reflect the emergence and burst behavior of the time series that belong to a group. For an overview of the emergence and burst statistics that we consider, see Table 2."}, {"heading": "5.2.3 Chi-square goodness of fit test", "text": "In Section 6.3 we compare the distribution over entity classes per online text stream (i.e., comparing the entity classes in the social media stream to those in the news stream). To assess whether the differences in these class-distributions are statistically significantly different, we apply a chi-square goodness of fit test to both distributions. In addition, we rank the classes by their contribution to the difference, using chi-grams, i.e., we compute for each class: observed\u2212expected\u221a\nexpected ,\nwhere observed corresponds to the number of entities that belong to a particular class in one set (e.g., the entities that emerge in social media) and expected corresponds to the number of entities that belong to a particular class in the global population (i.e., all entities that emerge in our dataset)."}, {"heading": "6 Results", "text": "In this section we present the analyses that answer our three research questions. First, we study the time series clusters that result from our clustering method in Section 6.1. Next, in Section 6.2 we study similarities and differences between emergence patterns in social media and newswire streams. In Section 6.3 we study the underlying entity types, and their emergence patterns."}, {"heading": "6.1 RQ1: Emergence patterns", "text": "The first research question we aim to answer, Are there common patterns in how entities emerge in online text streams? (RQ1), is at the core of our study into how collective remembrance takes place in the online world. Finding similar patterns, and studying how an entity transitions from communicative CM (i.e., online text streams) into cultural CM (as represented by Wikipedia) allows us to gain insights into the mechanism of collective remembrance. Our unit of study are the entities that emerge in communicative CM before they become part of our cultural CM.\nFigure 5 shows a cluster tree that results from applying hierarchical clustering on the BSim similarity matrix computed for the time series of all entities under consideration, as explained in Section 5.1. The tree shows a clear subdivision into smaller clusters. At its highest level, the tree shows two distinct clusters, each of which is broken down in multiple smaller sub-clusters. The cluster tree in Figure 5 helps us to organize our analysis; in the following section, we look at different granularities of similarly emerging entities, by exploring three levels of this cluster tree: first, we study the global emergence patterns, by taking the time series that are at the root node of the tree (i.e., the first level of the tree, denoted Top level in Figure 5). Then we study the main two clusters, at the next level of the tree (denoted Level 1 in Figure 5). Finally, move down another level in the tree and study the set of six clusters at Level 2 in Figure 5."}, {"heading": "6.1.1 Global emergence pattern", "text": "First, we examine the emergence pattern of the global average, by taking the group at the root node of the cluster tree (i.e., all time series in our dataset, where n = 79,482). Figure 6 shows the global emergence signature, and Table 3 shows the associated descriptive statistics.\nFigure 6 shows how both the emerging entities\u2019 introduction into public discourse (the first mention at the left-most side of the plot) and subsequent incorporation into cultural CM (the right-most side of the plot) occur in bursts of documents, i.e., overall, the largest number of documents that mention a newly emerging entity are either at the start or at the end of their time series. This can be explained as follows. The entrance into public discourse represents the first emergence of an entity, whereas being added to cultural CM is likewise likely to happen in a period of increased attention, e.g., a real world event that puts the entity in public discourse. Between these two bursts, the number of documents that mention the entity seems to increase gradually as time progresses, suggesting that on average, the number of documents that mention a new entity, and thus the attention the entity receives in public discourse increases over time\nbefore it reaches \u201ccritical mass,\u201d i.e., when the entity is deemed important enough to transition into cultural CM.\nNext, we look at the global emergence pattern\u2019s descriptive statistics; see Table 3. Here, we see how on average it takes 245 days between an emerging entity\u2019s first mention and being incorporated into cultural CM. In these 245 days, an emerging entity is mentioned in 183 documents on average. However, both the emergence durations and emergence volumes show large standard deviations (of 153 days and 1,180 documents, respectively), indicating that they differ substantially between entities, further motivating our clustering approach to zoom into the different underlying patterns. The emergence velocity shows how, on average, an entity is mentioned in less than a document a day.\nTo better understand how the documents that mention an emerging entity are distributed over time, e.g., to gain insights into whether they are concentrated in a few bursts, or spread out more uniformly over the timeline, we turn to the burst statistics in Table 3. On average, an entity is associated with 3.8 bursts, indicating that entities are likely to resurface multiple times in public discourse before being deemed important enough to transition into cultural CM. The average burst durations span a mere 3% of an emerging entity\u2019s time series, indicating that emerging entities spend the majority of their time \u201cunder the radar.\u201d The heights of these bursts (i.e., burst values) show a comparatively large standard deviation, suggesting that the heights differ substantially between different entities and bursts.\nIn summary, globally, entities experience a long time span between surfacing in communicative CM (i.e., their first mention in an online text stream), and transitioning into cultural CM; they are associated with multiple bursts and thus display a resurfacing behavior. Finally, the large standard deviations seen at the descriptive statistics suggests the entities show large variations in terms of their emergence patterns. Below, we study whether grouping the time series of new entities by similar burst patterns allows us to find groups of broadly similarly emerging entities in terms of their group signatures, and emergence and burst-features."}, {"heading": "6.1.2 Clusters at level 1 in Figure 5: Early vs. late bursts", "text": "In our first attempt at uncovering distinct patterns in which collective remembrance happens, i.e., in which memories transition from communicative to cultural CM, we look at the first two main clusters that appear at Level 1 of the cluster tree in Figure 5. The resulting cluster signatures are shown in Figure 7.\nMuch like the global cluster signatures we studied in the previous section, the clusters at Level 1 show two main bursts: the initial burst around the first mention, and the final burst around the last mention before an entity is added to Wikipedia. However, as we will show, the left cluster, which we call early bursting (EB) entities, is characterized by a stronger initial burst, with the majority of the documents that mention the entity concentrated at the time around the first mention when the entity surfaces in communicative CM. This suggests that the cluster contains new entities that suddenly emerge and experience a (brief) period of lessened attention, before transitioning into the collective\u2019s CM. The right cluster, which we denote as late bursting (LB) entities, shows a more gradual pattern in activity towards the point at which the entity is incorporated into cultural CM, much like we saw in the global signature (Figure 6).\nLooking at Figure 7, we note two main differences between the group signatures of the early bursting and late bursting entities. First, the way documents are distributed between the initial and final burst. The EB entities cluster show a more \u201cabrupt\u201d final burst: the signature shows the majority of the documents in the wake of the initial burst, i.e., at the left-hand side of the plot. In the next phase, the volume of documents seems to gradually wind down into a relatively quiet period, which finally seems to abruptly transition into the final burst at the right hand-side of the plot. In contrast, the LB entities cluster shows a relatively subtle initial burst, which like the EB-cluster appears to quiet down, followed by a gradual increase of document volume that leads up to the final burst.\nA second difference is the height difference between the initial and final bursts. The EB cluster shows roughly equally high initial and final bursts. The LB cluster shows a substantially smaller initial burst, which suggests the introduction into public discourse is comparatively more subtle than its addition, i.e., these entities may emerge \u201csilently,\u201d suggesting the entities are less central, more niche, and less widely supported. In summary, the first split separates the entities that are associated with a strong \u201cinitial\u201d emergence in communicative CM from the entities that more gradually transition into cultural CM.\nNext, to better understand the different characteristics of the two clusters, we study the descriptive time series and burst statistics of the time series in the early bursting (EB) and late bursting (LB) entity clusters in Table 4.\nBefore we proceed, we determine whether the differences between the statistics of the two\nclusters are statistically significant. To do so, we perform a Kruskal-Wallis one-way analysis of variance test, also known as a non-parametric ANOVA. Following this omnibus test, we perform a post-hoc test using Dunn\u2019s multiple comparison test (with p-values corrected for family-wise errors using Holm-Bonferroni correction). Comparing all descriptive statistics from the two clusters, we find that all differences are statistically significant at the \u03b1 = 0.05 level.\nZooming into the statistics, we make the following observations. First, there are more LB than EB entities, at 60.3% vs. 39.7%. LB entities emerge more slowly than EB entities: the LB entities exist for a longer period in public discourse (with an emergence duration of 259 days, versus 224 for EB entities), and receive more attention (with an emergence volume of 225 documents, versus 118 documents for EB entities) before being deemed important enough to be incorporated into the collective\u2019s cultural memory. The EB entities\u2019 shorter emergence durations and lower emergence volumes suggest a higher \u201curgency\u201d or timeliness, suggesting this cluster may contain entities that represent sudden events, e.g., large-scale natural catastrophes or societal events, that will typically be incorporated in Wikipedia soon after they first emerge in public discourse. The descriptive statistics of the LB entities too may indicate they comprise less timely or urgent entities, e.g., recurring events, such as sports events that may appear in public discourse long before transitioning from communicative into cultural CM.\nThis view of the slower, less timely LB entities, and the more urgent, fast, and timely EB entities is supported by the burst statistics. First, the average burst heights of EB entities are higher (at 0.05 on average, versus 0.03 for LB entities), suggesting LB entities see a more evenly spread volume of documents that mention them. Next, EB entities show a lower number of bursts (3.22 on average, versus 4.12 for LB entities). Fewer and higher bursts, together with shorter emergence durations and lower emergence volumes supports the view of more urgent or timely EB entities, i.e., those that are more quickly (in terms of time and number of documents) incorporated into cultural CM, while exhibiting more bursty patterns. In the next section we show that entities that emerge in news likewise exhibit higher burst heights and fewer bursts on average, further exploring the notion of higher urgency or importance.\nIn summary, we find that the two clusters at Level 1 in Figure 5 differ substantially and significantly in terms of their emergence patterns and burst properties. Our visual inspection of the cluster signatures and the analysis of burst and emergence features suggests LB entities emerge more slowly, i.e., build up attention more slowly before transitioning from communicative into cultural CM, whereas EB entities are associated with more sudden and higher bursts of activity, prior to transitioning into cultural CM."}, {"heading": "6.1.3 Clusters at level 2 in Figure 5", "text": "In this section, we consider the clusters at Level 2 in Figure 5, i.e., the different clusters that make up the LB and EB entities clusters. For brevity we refer to these clusters as subclusters. See Figure 8 for the signatures of the six subclusters. In general, the broad distinction between faster and seemingly more urgent EB entities, and comparatively slow LB entities, remains in the subclusters.\nUsing the procedure described in the previous section, we test whether the differences between the subclusters are statistically significant. Overall, the properties of time series within each subcluster different significantly, except for early bursting 1 and late bursting 2a, which may not differ statistically significantly in terms of emergence volume. And in terms of burst statistics, some clusters show inconclusive differences. Specifically, early bursting 1 and 2a do not differ statistically significantly in terms of burst values, and early bursting 2a and late bursting 2b do not differ statistically significantly in terms of burst durations.\nThe cluster signatures in Figure 8 show that the entities that belong to the LB entities subclusters (the top three plots) exhibit an increase in document volume in the period leading up to the final burst before entering into cultural CM. This suggests that even when the entity first appears in communicative CM with a relatively big burst, its subsequent transition into cultural CM is not instantaneous. Consider, e.g., the previously shown example of the Mars Curiosity (in Figure 4); whereas its first burst happens around October 2011, its transition into cultural CM is after a relatively quiet period, 9 months later. Whereas the LB entities subclusters both differ in the \u201csteepness\u201d of the final burst and the relative moment of the increase of activity, the three EB entities subclusters (the bottom three plots) differ mainly in the moment of the increased activity, i.e., the \u201cbump\u201d in the plot.\nOne outlier exists in the LB entities cluster: late bursting 2a (second plot from the top). Its cluster signature shows a high and sudden burst of activity just before the entity is incorporated into Wikipedia, seemingly omitting the period of gradually increasing attention between the initial and final bursts seen at the other two subclusters. Its emergence features in Table 5 show that with an average duration of 146 days before an entity transitions into cultural CM, it is almost twice as fast as the global average. Both the cluster signature and the average number of bursts (1.6 on average) show that the entities exhibit a single, steep, high volume burst before being incorporated into cultural CM. Compared to the other two subclusters in the same LB group, the number of bursts is substantially lower, and the average burst values are substantially higher. This suggests that the entities in the LB 2a cluster comprise abruptly or suddenly emerging entities, like events, and indeed, upon closer inspection, events such as the World Music Festival Chicago, the 2013 British Grand Prix, the 2012 Volvo World Match Play Championship, and the 2012 Sundance Film Festival belong to this cluster.\nWith the exception of this outlier, the entities in the LB subclusters show longer emergence durations on average (i.e., are slower to transition into cultural CM), and substantially higher emergence volumes on average, further supporting our distinction of slowly emerging entities. In particular, late bursting 1 and late bursting 2b (the third and first plot from the top, respectively), with 242 and 227 documents on average, with relatively long emergence durations (255 and 294 days on average, respectively), suggest that these clusters contain slowly emerging niche\nentities, that are not as widely supported by \u201cthe masses\u201d as, e.g., the entities that are part of the LB 2a cluster. Manual inspection of the subclusters confirms this, revealing entities such as Summerland Secondary School, but also a long-tail of person entities (e.g., AFL athlete Rodney Filer, jazz musician Kjetil M\u00f8ster) in LB 1, whereas entities that represent more \u201csubstantive\u201d events are in LB 2a, e.g., the 2012 Benghazi attack, the Greek withdrawal from the eurozone, and the Incarceration of Daniel Chong."}, {"heading": "6.1.4 Summary", "text": "In this section, we answer our first research question: \u201cAre there common patterns in how entities emerge in online text streams?\u201d\nWe performed hierarchical clustering using a burst similarity-metric of the emerging entity time series. We discovered two distinct emergence patterns: early bursting entities and late bursting entities. Both the visual inspection of the cluster signatures, as the analysis of the descriptive statistics of the time series in the clusters support the same findings: the EB entities are characterized by fewer but higher bursts, with shorter emergence durations and lower emergence volumes. The LB entities on the other hand, seem to emerge more slowly, with a more gradual increase of exposure in the online text streams, before transitioning into cultural CM. This can be seen both in the cluster signature, as in the descriptive statistics, which show longer durations, higher volumes, and a larger number of bursts."}, {"heading": "6.2 RQ2: Entity emergence patterns in social media and news", "text": "In this section we answer our second research question: \u201cDo news and social media text streams exhibit different emergence patterns?\u201d The news or social media document streams represent content from different sources: the news stream consists of traditional online news sources, where the content is mostly written by professional journalists; the social media stream contains mostly user-generated content, and consists of, e.g., forums and blog posts, but also content that was shared through other social media platforms such as Twitter and Facebook (through the bit.ly URL-shortener service).\nIn the previous section we have shown that 79,482 entities emerge in the combined news and social media streams. Taking a closer look by splitting out these entities by stream, we find 51,095 of these entities emerge in the news stream (i.e., are mentioned in the news stream), similar to the number of entities that emerge in the social media stream, at 51,356. Finally, 30,148 of the emerging entities are mentioned in both streams before being incorporated into Wikipedia.\nIn order to answer our second research question, we consider (i) the emergence patterns of entities that emerge in social media and news streams, and (ii) entities that appear in both streams vs. (iii) entities that appear in only one of the two streams."}, {"heading": "6.2.1 Global: News vs. social", "text": "First, we compare the emergence patterns of entities in news and social streams. We apply the same hierarchical clustering method as we have done in Section 6.1 on the two subsets of entities that emerge in news and social media streams (where nnews = 51,095 and nsocial = 51,356).\nUnsurprisingly, the emergence patterns are largely the same in the two streams and highly similar to the global patterns studied in Section 6.1. Both the news and social streams exhibit the same general global emergence pattern, witnessed by the largely similar clusterings we yield. Both streams exhibit groups that are similar to the early bursting and late bursting entities discovered in the previous section (shown in Figure 7).\nFigure 9 first shows the global emergence patterns (top row, in green), and then the LB and EB entity clusters in the news (left) and social media (right) streams in the bottom two rows. Looking more closely at the global signatures of the news and social media streams, we note that entities that emerge in the news stream have slightly more of their emergence volume mass after the initial burst (i.e., the left-hand side of the plot), compared to the global pattern of the social media stream, which exhibits more of a gradual increase of emergence volume towards the final burst (i.e., the right-hand side of the plot). This may be attributed to the slightly higher proportion of early bursting entities in the news stream, which has 50.0% of its entities falling in this cluster, while the social media stream has 48.6%. The two main clusters (late bursting and early bursting) show broadly similar distributions and patterns, with the LB news cluster showing slightly more mass after the initial burst. This may be attributed to the \u201cblind spot\u201d of the news stream in our dataset (shown in Figure 2).\nTable 6 shows the emergence and burst descriptive statistics of the streams. Statistical testing (using the same Kruskal-Wallis test followed by Dunn\u2019s multiple comparison test with Holm-\nBonferroni adjusted p-values used in \u00a76.1.2) shows that the differences in the descriptive statistics between both streams is statistically significant at the \u03b1 \u2264 0.05 level. With 216 days on average, entities that emerge in news streams are more quickly incorporated into our cultural CM than entities in the social media stream. These shorter emergence durations are seen with higher emergence volumes on average: an entity that emerges in news is mentioned on average in 123 documents between their initial and final mention, nearly double the number of documents in social media (65). Recall that the total number of documents in the social media stream is larger, at 5.3M documents (versus 1.8M documents for the news stream\u2014see also Figure 2). The higher number of documents with comparatively shorter emergence durations further supports the observation that emerging entities in news are picked up quicker than those that emerge in social media.\nFurthermore, in the previous section we have seen how early bursting entities exhibit fewer but higher bursts, and reasoned they represent more \u201curgent\u201d or timely entities. The emergence features of entities emerging in news supports this notion of timeliness or urgency: they exhibit higher and fewer bursts on average.\nIn summary, we have shown that entities emerging in news and social media show broadly similar patterns, with both the cluster signatures and descriptive statistics being similar to the emergence patterns in the combined text streams in Section 6.1. We have also shown that news\nstreams seem to surface entities more quickly than social media streams, which we attribute to the different nature of the streams (professional and authoritative versus unedited and usergenerated). In Section 6.3 we revisit this hypothesis by studying how the types of emerging entities differ between streams."}, {"heading": "6.2.2 Who\u2019s first?", "text": "Of the 79,482 entities that emerge in the 18 month period our dataset spans, 30,148 appear in both the news and social media stream before they transition to cultural CM; 20,947 entities are mentioned exclusively in the news stream, never appearing in social media (news-only) between surfacing in communicative CM and transitioning into cultural CM. Finally, 21,208 appear only in the social media stream (social-only). See also Table 7.\nOf the 30,148 entities that emerge in both streams, the majority appears in the social media stream before they appear in the news stream. This may be explained by the nature of the publishing cycles of the two streams; whereas traditional newswire has a more thorough publishing cycle, where stories need to be checked and edited before being published, social media\u2014in particular forums and blog posts\u2014follows a more unedited and direct publishing cycle.\nThe entities that appear in a social media stream first, which we denote social-first, cover 62.9% (n = 18,967) of the entities that emerge in both streams. The opposite pattern, where entities appear in news before they appear in social media (news-first), comprises 29.1% of the entities that emerge in both streams (n = 8,794). Entities that emerge in news first, subsequently appear in social media streams faster than vice versa: it takes a news-first entity on average 66 days to appear in the social media stream after surfacing in the news stream, whereas the other way around takes 49 days. The remaining comparatively small number of entities are mentioned in both streams on the same day (same-time): 7.9% (n = 2,387). The latter group of entities are expected to transition more quickly into cultural CM, by virtue of appearing more widely in public discourse, and hence being more urgent and central.\nThe burst and emergence descriptive statistics, as recorded in Table 7, support this view: the same-time entities show comparatively short emergence durations. With an average 197 days between being first mentioned and being incorporated into our cultural CM, same-time entities emerge substantially quicker than entities that appear in both streams at different times (at 298 days and 281 days on average for news-first and social-first entities respectively).\nFurthermore, the same-time entities exhibit higher emergence volumes too, accounting for the highest overall velocity at 2.87 documents per day, further supporting the hypothesis that these entities are more urgent and central.\nEntities that emerge only in one of the two media streams show shorter emergence durations than those that appear in both but at different times (at 250 and 214 for news and social media respectively). These observations can be explained by the fact that longer duration means that it is more likely for an entity to cross from one stream to the other. Similarly, the longer average emergence durations of the news-first and social-first entities are paired with a larger number of bursts (around 4 on average, versus 3 on average for entities that emerge in either the news or social media stream). Much like what we saw in the previous section between late bursting and early bursting entities, the shorter durations and smaller number of bursts suggests that entities that emerge in a single stream are more central or important in public discourse."}, {"heading": "6.2.3 Summary", "text": "News and social media streams show broadly similar emergence patterns for entities. However, while the patterns may be similar, the population and the behavior of entities emerging in news and social differ significantly. More specifically, the social media stream seems to be slower on average in transitioning entities from communicative to cultural CM. Looking in more detail at the interactions between the two streams, we notice that entities that appear in both streams on\nthe same day are the fastest to transition to cultural CM. Furthermore, we find that entities that first emerge in social media are more quickly picked up in news streams than vice versa."}, {"heading": "6.3 RQ3: Emergence patterns of different entity types", "text": "In this section we answer our third research question: \u201cDo different types of entities exhibit different emergence patterns?\u201d First, we analyze the descriptive statistics of each entity type in our dataset, to assert whether different types of entities exhibit different behavior in terms of how they transition from communicative to cultural CM. Next, we study whether entity types are distributed differently over the news and social media text streams."}, {"heading": "6.3.1 Entity types: temporal patterns", "text": "First, we study each entity type in isolation, i.e., we study the descriptive statistics per entity type. Table 8 provides an overview of the most frequent entity types in our dataset (i.e., all entity types with a frequency of \u2265 400).\nWe find that the entity type signatures (i.e., the average over all time series for each entity type) are highly similar to the global pattern (visualized in Figure 6), suggesting that the time series of mentions are highly variable within an entity type. To illustrate this, see Figure 10 for an example of two common entity types (top row) and two less frequently emerging types (bottom row). Whereas the signature becomes smoother as the number of entities increase, the overall pattern is highly similar across the four types.\nIn contrast, the descriptive statistics per entity type does yield clear patterns, as we will describe next. First, the null class, i.e., the entities that are not assigned an entity type in DBpedia exhibit very low emergence volumes, with an average of 98 documents over 225 days. Which may be explained by their nature, as they are not assigned a class in the DBpedia ontology, they are likely to be very long-tail, or unpopular entities.\nSecond, we note a group of \u201cfast\u201d emerging entity types, i.e., those with short emergence durations and/or high emergence velocities, e.g., DesignedArtifact, CreativeWork, MusicalWork, and VideoGame. In particular, the DesignedArtifacts type shows high emergence velocities: it takes entities of this type on average 217 days to transition from communicative CM to cultural CM, with an average volume of over 7 documents a day (versus 0.87 for the global average). The DesignedArtifact type includes entities such as devices and products, e.g., smartphones, tablets, and laptops. The relatively fast transition of the entities of this type may be explained by their nature: they have short \u201clife-cycles\u201d and may be superseded\nor replaced at high frequencies. Consider, e.g., the release or announcement of a new smartphone: this event typically generates a lot of attention in a short timeframe, which may result in a fast transition into cultural CM. Similar to devices of the DesignedArtifact-type, creative works (CreativeWork, including MusicalWork, WrittenWork, Movie, etc.) share this characteristic: they play a central but short-lived role in public discourse.\nThird, the \u201cslower\u201d entities, i.e., those with longer emergence durations and lower emergence volumes, are largely person types such as writers (Writer), artists (Artist), and political figures (OfficeHolder), but also schools (School and EducationalInstitution), and geographical entities (e.g., Building, ArchitecturalStructure, Place, and PopulatedPlace). These entities by their nature may have longer life-cycles, with a more gradual \u201crise to fame\u201d (politicians, artists), and play a less central role in public discourse (schools, buildings). The opening of a new school may appear briefly in regional and local news sources, but is unlikely to be globally and widely reported. Politicians generally have a long and gradual career, surfacing e.g., in regional media, and do not suddenly \u201cburst\u201d into existence.\nTo better understand the difference between \u201cfast\u201d and \u201cslow\u201d entities, we examine the popularity of entities. Table 9 lists the average number of pageviews received per entity in 2015, grouped by type. Entity types that exhibit short emergence durations and high velocities are all in the top 10 (ranks 3, 4, and 9, for VideoGame, CreativeWork, and DesignedArtifact, respectively), whereas the slower entity types all reside towards the lower ranks of the table, e.g., rank 19, 22, and 24 for Building, EducationalInstitution and School, respectively. This suggests that entity types that transition faster from communicative to cultural CM remain more popular over time."}, {"heading": "6.3.2 Entity types per stream", "text": "To determine whether the entity types observed in news and social media streams differ significantly, we apply Pearson\u2019s chi-squared test. This allows us to identify entity types that are observed more than expected (w.r.t. the global distribution) in the news and social media streams. See Table 10.\nThe majority of the entity types observed more frequently in social media streams (right column of Table 10) are the ones we identified to be comparatively fast in transitioning from communicative to cultural CM in the previous section, e.g., DesignedArtifact, VideoGame, TelevisionShow, Software. The (average) popularity rankings from Table 9 show how 6 out of 10 of the entity types that are observed more frequently in social media are in the top 10 most popular entity types of Table 9. The average popularity rank of the social media entity types is 9.9. At the other end, the types of entities seen more frequently in news are both slower in transition on average (e.g., Person, Organization, and Company), and are characterized by being more \u201cgeneral\u201d or less niche types compared to the entity types seen more frequently in the social media stream. Videogame or smartphones are likely to see more exposure in social media streams in, e.g., blog and forum posts, but more general entity types such as people, places, and organizations are more natural subjects for (traditional) news media. Merely 2 entity types that are more often seen in news streams are in the top 10 most popular entity types in Table 9. The average popularity rank of news-specific entity types is 14.5. These observations\nsuggest that entities that remain popular over time are more likely to emerge in the social media stream."}, {"heading": "6.3.3 Summary", "text": "In summary, we have shown that different entity types exhibit substantially different emergence patterns, but entities that belong to a particular type show broadly similar emergence patterns. Furthermore, we have shown that different entity types are distributed distinctly over different online text streams, which can be intuitively explained by looking at both the nature of the entity types and the nature of the streams. Next, we have seen that entities with a fast transition from communicative to cultural CM, are more likely to remain popular over time. Finally, we have seen that in social media streams entities emerge faster, and more remain popular over time in comparison to news streams."}, {"heading": "7 Conclusion", "text": "We summarize the work we have done, list our main findings, the implications of this work, its limitations and identify potential future work."}, {"heading": "7.1 Summary", "text": "In this paper we studied entities as they transition from communicative into cultural collective memory. We did so by studying a large set of time series of mentions of entities in online news streams before transitioning into cultural CM (as represented by the creation of a Wikipedia page). We studied implicit groups of similarly emerging entities by applying a burst-based agglomerative hierarchical clustering method and explicit groups by isolating entities by whether they emerge in news or social media streams."}, {"heading": "7.2 Findings", "text": "In Section 6.1, we applied a clustering method to the time series of mentions of emerging entities to find implicit groups of similarly emerging entities. We found that, globally, entities have a long time span between surfacing in communicative CM (i.e., their first mention in an online text stream), and transitioning into cultural CM. During this time span, an emerging entity is associated with multiple bursts (i.e., resurfaces into public discourse), however both the emerging entities\u2019 introduction into public discourse and subsequent transitioning into cultural CM occur in the largest document bursts. Emergence durations and volumes show large standard deviations, indicating that they differ substantially between entities. For this reason, we turned to time series clustering to uncover distinct groups of entities. We discovered two distinct emergence patterns: early bursting (EB) entities and late bursting (LB) entities. Analysis suggests that EB entities comprise mostly \u201chead\u201d or popular entities; they exhibit fewer and higher bursts, with shorter emergence durations and lower emergence volumes. The LB entities emerge more\nslowly on average, and witness a more gradual increase of exposure in online text streams, before transitioning into cultural CM. The emergence patterns we visualized differ substantially from the global average and from, e.g., the type signatures studied in Section 6.3, suggesting that the entities in each of the underlying clusters exhibit substantially different and distinct emergence patterns from entities in the other clusters.\nIn Section 6.2, we showed that entities emerging in news and social media streams display very similar emergence patterns, but that on average, entities that emerge in social media have a longer period between surfacing and being incorporated into cultural CM. We hypothesize that this can be attributed to the nature of the underlying sources. Traditional news media is more mainstream and professional, with a larger audience and reach, and more authority than social media streams. Our findings are in line with those of Petrovic et al. [39], who compare breaking news on traditional media with that on social media. Their findings suggest reported events overlap largely between both media, however, social media exhibits in addition a long tail of minor events, which may explain the longer uptake on average. Leskovec et al. [27] find that the \u201cattention span\u201d for news events on social media both increases and decays at a slower rate than for traditional news sources, which may explain the comparatively slower uptake on social media.\nFinally, we studied entity types in Section 6.3. We showed that different entity types exhibit substantially different patterns, but entities of a similar type show similar patterns. Some entity types, e.g., devices or creative works, on average transition faster from communicative to cultural CM, than entities such as buildings, locations, and people. At the same time, the former \u201cfaster\u201d entity types remain more popular over time (as seen through their pageview counts). One aspect that distinguishes between \u201cfast\u201d and \u201cslow\u201d entity types, is that the former are more likely to appear in so-called \u201csoft news\u201d (i.e, news that covers sensational or human-interest events and topics, e.g., news related to celebrities and cultural artifacts), whereas the slower entity types are more likely to be associated with more substantive \u201chard news\u201d (i.e., news that encompasses more pressing or urgent events and topics, e.g., reports related to political elections) [45]. Granka [15] studied the differences in \u201cattention span\u201d of the public (as measured through search engine query volumes) and the traditional news media (as measured through coverage volume) for \u201chard\u201d and \u201csoft news,\u201d and found that, in line with the findings of Leskovec et al. [27], hard news is associated with a relatively short period of attention from the public (as measured by query volume). Soft news exhibits a slower decrease of the public\u2019s attention (as seen through slower declines in query volumes), which supports our finding that faster entity types\u2014entities more likely to be associated with soft news\u2014tend to remain more popular over time. Furthermore, the relatively longer attention for soft news may explain the quicker uptake of the \u201cfast\u201d entity types, e.g., \u201ccultural\u201d artifacts (e.g., movies, TV shows, artists) may transition more quickly into cultural CM, as they are more widely supported, followed, and more strongly represented in our online public discourse.\nFinally, we showed how entity types are distributed differently over news and social media streams. This difference in entity types may be explained by the nature of the streams. Partly because of the open, democratic, and user-generated nature of the Web 2.0, and blogging in particular [32], blogs no longer simply pick up news stories from the traditional media. The agenda setting power of traditional media is diluting [33]. Moreover, there are situations in\nwhich breaking news emerges on social media, e.g., the death of Osama Bin Laden [22]. And finally, as mentioned before, the events reported on social media and traditional news overlap, but social media has a long tail of its \u201cown\u201d events [39], which may account for the different distribution of emerging entity types in the social media stream.\nTaking a step back, our findings can be summarized to the observation that emerging entities are not \u201cborn equal,\u201d i.e., the patterns and features under which an entity transitions from communicative to cultural CM differ depending on source and type."}, {"heading": "7.3 Implications", "text": "The findings in this paper have implications for designing systems to detect emerging entities, and more generally for studying and understanding how collective memories are formed.\nFirst, we have shown that entities are likely to resurface multiple times in public discourse (i.e., online text streams) before transitioning into cultural CM. This means that, on average, it takes multiple moments of \u201cexposure\u201d for a cultural memory to be formed. In addition, this suggests that monitoring bursts of newly emerging entities could serve as an effective method for predicting when they transition into cultural CM, i.e., after observing the initial burst, it is not too late.\nFurthermore, we have shown that the type of stream in which entities emerge (i.e., news and social media) carries different signals that allow us to model the process of an entity\u2019s transition process. More specifically, we have shown how entities that emerge, e.g., in both streams at the same time transition more quickly from communicative to cultural CM than, e.g., those entities that never move from one stream to another. These findings suggest that taking different streams into account separately can be beneficial for detecting emerging entities, or predicting when an entity transitions from communicative to cultural CM. Furthermore, we have shown that the different types of online text streams also surface different types of entities. This provides insights into the difference between \u201cmainstream media\u201d and users of the world-wide web, in terms of preferences and interests through the \u201cagenda setting.\u201d"}, {"heading": "7.4 Limitations", "text": "There are several limitations to our study."}, {"heading": "7.4.1 Clustering", "text": "Part of our findings are derived from the clusters that serve as a starting point for discovering common patterns, similarities, and differences in emergence patterns. Clustering and studying cluster signatures is by design a subjective matter [47]. Applying unsupervised clustering, entailing different hyperparameters, is by definition a hard task to \u201cevaluate,\u201d i.e., to decide whether the resulting clusters show meaningful differences. The large (standard) deviations seen in the descriptive statistics within clusters may suggest there exists a wider variety of different entities. However, the linear interpolation step we took to cluster time series with variable lengths and different relative timespans (i.e., not temporally aligned) will result in varied time series. In our\ndefense, the cluster signatures that result from the clustering method yielded visually discernible and statistically different patterns between clusters, which was not the case for the signatures of the groups of time series from Sections 6.2 and 6.3 (see, e.g., Figure 10). Finally, the clustering\u2019s resulting dendrogram suggests there are distinct and meaningful groups of substantially different time series, as the structure of the dendrogram shows symmetry and clear separations."}, {"heading": "7.4.2 Data", "text": "Next, the fragmented nature of the TREC-KBA StreamCorpus 2014 means the coverage, and hence representativeness and comprehensiveness of the data cannot be guaranteed. As could be seen in Figure 2, the dataset contains a blind spot around May 2012, which may affect the time series of all emerging entities. To minimize the adverse effects, we normalize all entity document mention time series by the total document volume. Furthermore, the choice of underlying sources (that represent the social media and news streams) is limited, e.g., popular social media channels such as Tumblr, Twitter and Facebook are not part of the dataset. There may be sampling bias in the types of sources, resulting in a similar bias in the entities. That is to say, with another set of sources, we may have had different findings. This is unavoidable.\nThe entity annotations that represent the starting point of our study into emerging entities cannot be assumed to be 100% accurate. So-called \u201ccascading errors\u201d [12] cause the overall accuracy to suffer, by using imperfect tagging by SERIF as input for imperfect FAKBA1 annotations. The latter annotations are estimated (from manual inspection) to contain around 9% incorrectly linked Freebase entities, with around 8% of SERIF mentions being wrongfully not linked. Even more so, the \u201cdifficult\u201d entity links are long-tail entities, ones that are likely to be included in our filtered set, meaning the accuracy may be relatively worse in our subset of entities. However, manually correcting the annotations was beyond the scope of this study, and the large scale of the dataset makes it less likely that wrongfully linked entities are a major issue.\nFinally, there may be a cultural bias inherent in our choice of datasets: we used English language news sources and social media as well as the English version of Wikipedia. As an illustration to the cultural bias inherent to the data sources, see Table 11 for the top 10 most frequently mentioned entities in the FAKBA1 dataset. Hence, one could claim that we studied the birth of collective memories for English speaking part of the world, and that different datasets may also yield different findings. However, it is unfortunate that the English speaking part of the world is disproportionately represented in our field of research, as witnessed by the biggest constraint in conducting this study: dataset availability. We encourage the community to create suitable datasets in other languages and/or reflecting cultural practices in other parts of the planet so as to enable comparative studies."}, {"heading": "7.5 Future work", "text": "This paper is a starting point of studying collective memory formation. As a next step, we should take a closer look at the circumstances at which entities emerge, by not only considering in how many documents they appear over time, before transitioning into our collective CM, but rather at in which contexts, e.g., by looking at the content of the articles themselves. Furthermore, in\nthis paper we have chosen to restrict ourselves to the entities that transition into cultural CM and stay there. Another interesting aspect of CM that falls out of the scope of the present work, is the notion of \u201cconsensus.\u201d For example, one could study the emergence patterns of entities that are removed from cultural CM after transitioning. Finally, the observations made in this paper could be explored in a prediction task, where, e.g., given a partial entity time series, the task would be to predict the point at which the entity transitions from communicative to cultural CM."}, {"heading": "Acknowledgements", "text": "This research was supported by Ahold Delhaize, Amsterdam Data Science, Blendle, the Bloomberg Research Grant program, the Dutch national program COMMIT, Elsevier, the European Community\u2019s Seventh Framework Programme (FP7/2007-2013) under grant agreement nr 312827 (VOX-Pol), the ESF Research Network Program ELIAS, the Royal Dutch Academy of Sciences (KNAW) under the Elite Network Shifts project, the Microsoft Research Ph.D. program, the Netherlands eScience Center under project number 027.012.105, the Netherlands Institute for Sound and Vision, the Netherlands Organisation for Scientific Research (NWO) under project nrs 727.011.005, 612.001.116, HOR-11-10, CI-14-25, 652.002.001, 612.001.551, 652.001.003, 314-98-071, the Yahoo! Faculty Research and Engagement Program, and Yandex. All content represents the opinion of the authors, which is not necessarily shared or endorsed by their respective employers and/or sponsors."}], "references": [{"title": "Collective memory and cultural identity", "author": ["J. Assmann", "J. Czaplicka"], "venue": "New German Critique,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1995}, {"title": "Studying how the past is remembered: Towards computational history through large scale text mining", "author": ["Au Yeung", "C.-m", "A. Jatowt"], "venue": "In Proceedings of the 20th ACM International Conference on Information and Knowledge Management,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Using dynamic time warping to find patterns in time series", "author": ["D.J. Berndt", "J. Clifford"], "venue": "In Proceedings of the 3rd International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1994}, {"title": "Automatic information extraction", "author": ["E. Boschee", "R. Weischedel", "A. Zamanian"], "venue": "In Conference on Intelligence Analysis (IAC)", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2005}, {"title": "Organization of public events in long-term memory", "author": ["N.R. Brown"], "venue": "Journal of Experimental Psychology: General,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1990}, {"title": "What is the temporal value of web snippets", "author": ["R. Campos", "G. Dias", "A.M. Jorge"], "venue": "In WWW 2011 Workshop on Temporal Web Analytics,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Cultural Memory Studies", "author": ["A. Erll", "A. N\u00fcnning", "S. Young"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "On emerging entity detection", "author": ["M. F\u00e4rber", "A. Rettinger", "B. El Asmar"], "venue": "Knowledge Engineering and Knowledge Management: 20th International Conference,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2016}, {"title": "Collective Memories in Wikipedia. PhD thesis, Doctoral School in Cognitive and Brain Sciences, Universit\u00e0 degli Studi di Trento", "author": ["M. Ferron"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Collective memory building in Wikipedia: the case of North African uprisings", "author": ["M. Ferron", "P. Massa"], "venue": "In Proceedings of the 7th International Symposium on Wikis and Open", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Solving the problem of cascading errors: Approximate bayesian inference for linguistic annotation pipelines", "author": ["J.R. Finkel", "C.D. Manning", "A.Y. Ng"], "venue": "In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2006}, {"title": "Building an entity-centric stream filtering test collection for TREC", "author": ["J.R. Frank", "M. Kleiman-Weiner", "D.A. Roberts", "F. Niu", "C. Zhang", "C. Re", "I. Soboroff"], "venue": "In Proceedings of the Text REtrieval Conference (TREC)", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Evaluating stream filtering for entity profile updates in TREC", "author": ["J.R. Frank", "M. Kleiman-Weiner", "D.A. Roberts", "E.M. Voorhees", "I. Soboroff"], "venue": "In TREC", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Media agenda setting and online search traffic: Influences of online and traditional media", "author": ["L.A. Granka"], "venue": "In American Political Science Association", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Generating pseudo-ground truth for predicting new concepts in social streams", "author": ["D. Graus", "M. Tsagkias", "L. Buitinck", "M. de Rijke"], "venue": "In 36th European Conference on Information Retrieval (ECIR", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "Learning dynamic collective entity representations for entity ranking", "author": ["D. Graus", "M. Tsagkias", "W. Weerkamp", "E. Meij", "M. de Rijke"], "venue": "In WSDM 2016: The 9th International Conference on Web Search and Data Mining,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2016}, {"title": "La M\u00e9moire Collective", "author": ["M. Halbwachs"], "venue": "Albin Michel", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1950}, {"title": "Towards a psychology of collective memory. Memory, 16(3):183\u2013200", "author": ["W. Hirst", "D. Manier"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2008}, {"title": "Discovering emerging entities with ambiguous names", "author": ["J. Hoffart", "Y. Altun", "G. Weikum"], "venue": "In Proceedings of the 23rd International Conference on World Wide Web, WWW", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "Breaking news on twitter", "author": ["M. Hu", "S. Liu", "F. Wei", "Y. Wu", "J. Stasko", "Ma", "K.-L"], "venue": "In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2012}, {"title": "Mapping temporal horizons: Analysis of collective future and past related attention in twitter", "author": ["A. Jatowt", "E. Antoine", "Y. Kawai", "T. Akiyama"], "venue": "In Proceedings of the 24th International Conference on World Wide Web,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2015}, {"title": "The detection of emerging trends using Wikipedia traffic data and context networks", "author": ["M. K\u00e4mpf", "E. Tessenow", "D.Y. Kenett", "J.W. Kantelhardt"], "venue": "PLoS ONE,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2016}, {"title": "Breaking news, breaking planes, and breaking hearts: Psycholinguistics and sensemaking in collaborative accounts of catastrophe", "author": ["B. Keegan"], "venue": "In International Communication Association,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "Hot off the wiki: Structures and dynamics of wikipedia\u2019s coverage of breaking news events", "author": ["B. Keegan", "D. Gergle", "N. Contractor"], "venue": "American Behavioral Scientist,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2013}, {"title": "Meme-tracking and the dynamics of the news cycle", "author": ["J. Leskovec", "L. Backstrom", "J. Kleinberg"], "venue": "In Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2009}, {"title": "Clustering of time series data\u2014a survey", "author": ["T.W. Liao"], "venue": "Pattern Recognition,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2005}, {"title": "No noun phrase left behind: Detecting and typing unlinkable entities", "author": ["T. Lin", "Mausam", "O. Etzioni"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2012}, {"title": "Time Passages: Collective Memory and American Popular Culture", "author": ["G. Lipsitz"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2001}, {"title": "Wikipedia, collective memory, and the Vietnam war", "author": ["B. Luyt"], "venue": "Journal of the Association for Information Science and Technology,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2016}, {"title": "Is there an elite hold? traditional media to social media agenda setting influence in blog networks", "author": ["S. Meraz"], "venue": "Journal of Computer-Mediated Communication,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2009}, {"title": "Using time series analysis to measure intermedia agenda-setting influence in traditional media and political blog networks", "author": ["S. Meraz"], "venue": "Journalism & Mass Communication", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2011}, {"title": "fastcluster: Fast hierarchical, agglomerative clustering routines for r and python", "author": ["D. M\u00fcllner"], "venue": "Journal of Statistical Software,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2013}, {"title": "Fine-grained semantic typing of emerging entities", "author": ["N. Nakashole", "T. Tylenda", "G. Weikum"], "venue": "In Proceedings of the 51st Annual Meeting of the Association for Com- 36  putational Linguistics,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2013}, {"title": "National Trauma and Collective Memory: Major Events in the American Century. M.E", "author": ["A.G. Neal"], "venue": null, "citeRegEx": "36", "shortCiteRegEx": "36", "year": 1998}, {"title": "The Collective Memory Reader", "author": ["J.K. Olick", "V. Vinitzky-Seroussi", "D. Levy"], "venue": null, "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2011}, {"title": "Fixing the floating gap: The online encyclopaedia Wikipedia as a global memory place", "author": ["C. Pentzold"], "venue": "Memory Studies,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2009}, {"title": "Can twitter replace newswire for breaking news", "author": ["S. Petrovic", "M. Osborne", "R. Mccreadie", "C. Macdonald", "I. Ounis"], "venue": "In Proceedings of the Seventh International Conference on Weblogs and Social Media (ICWSM", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2013}, {"title": "Recent techniques of clustering of time series data: A survey", "author": ["S. Rani", "G. Sikka"], "venue": "International Journal of Computer Applications,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2012}, {"title": "The development of collective remembering. Memory, 16(3):201\u2013212", "author": ["E. Reese", "R. Fivush"], "venue": null, "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2008}, {"title": "Document filtering for long-tail entities", "author": ["R. Reinanda", "E. Meij", "M. de Rijke"], "venue": "In CIKM 2016: 25th ACM Conference on Information and Knowledge Management. ACM", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2016}, {"title": "The singularity is not near: Slowing growth of wikipedia", "author": ["B. Suh", "G. Convertino", "E.H. Chi", "P. Pirolli"], "venue": "In Proceedings of the 5th International Symposium on Wikis and Open Collaboration,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2009}, {"title": "The Public Space of Social Media: Connected Cultures of the Network Society. Routledge Studies in New Media and Cyberculture", "author": ["T. Tierney"], "venue": null, "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2013}, {"title": "Objectivity as strategic ritual: An examination of newsmen\u2019s notions of objectivity", "author": ["G. Tuchman"], "venue": "American Journal of Sociology,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 1972}, {"title": "Identifying similarities, periodicities and bursts for online search queries", "author": ["M. Vlachos", "C. Meek", "Z. Vagena", "D. Gunopulos"], "venue": "In Proceedings of the 2004 ACM SIGMOD International Conference on Management of Data,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2004}, {"title": "Clustering: Science or art", "author": ["U. Von Luxburg", "R.C. Williamson", "I. Guyon"], "venue": "In Unsupervised and Transfer Learning workshop,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2012}, {"title": "Querydependent contextualization of streaming data", "author": ["N. Voskarides", "D. Odijk", "M. Tsagkias", "W. Weerkamp", "M. de Rijke"], "venue": "In 26th European Conference on Information Retrieval (ECIR", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2014}, {"title": "From the editors: The democratization of information? Wikipedia as a reference resource", "author": ["D.P. Wallace", "C. Van Fleet"], "venue": "Reference & User Services Quarterly,", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2005}, {"title": "Hierarchical grouping to optimize an objective function", "author": ["J.H. Ward Jr."], "venue": "Journal of the American Statistical Association,", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 1963}, {"title": "Collective memory: A perspective from (experimental) clinical psychology. Memory, 16(3):288\u2013304", "author": ["I. Wessel", "M.L. Moulds"], "venue": null, "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2008}, {"title": "Circadian patterns of Wikipedia editorial activity: A demographic analysis", "author": ["T. Yasseri", "R. Sumi", "J. Kert\u00e9sz"], "venue": "PLoS ONE,", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2012}, {"title": "Dynamics of conflicts in Wikipedia", "author": ["T. Yasseri", "R. Sumi", "A. Rung", "A. Kornai", "J. Kert\u00e9sz"], "venue": "PLoS ONE,", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2012}], "referenceMentions": [{"referenceID": 16, "context": "Remembering is a social process [19].", "startOffset": 32, "endOffset": 36}, {"referenceID": 0, "context": "In the literature this process has been described as being similar to the remembrance process of an individual, whose memories or experiences transfer from short-term into long-term memory [1].", "startOffset": 189, "endOffset": 192}, {"referenceID": 0, "context": "Cultural collective memory (CM), the collective\u2019s equivalent of an individual\u2019s long-term memory, is characterized by being organized, specialized, formal, structured, and distanced from the immediate [1].", "startOffset": 201, "endOffset": 204}, {"referenceID": 46, "context": "Wikipedia is known to \u201cdemocratize information,\u201d through its collaborative nature: its content is being produced by volunteer editors and authors from all over the world [49].", "startOffset": 170, "endOffset": 174}, {"referenceID": 28, "context": "Wikipedia has been called an online place for cultural CM [31, 38].", "startOffset": 58, "endOffset": 66}, {"referenceID": 35, "context": "Wikipedia has been called an online place for cultural CM [31, 38].", "startOffset": 58, "endOffset": 66}, {"referenceID": 0, "context": "Analogously to an individual\u2019s short-term memory, communicative CM is mainly orally negotiated, close to the everyday, disorganized, informal, and non-specialized [1].", "startOffset": 163, "endOffset": 166}, {"referenceID": 40, "context": "Every day, new content is being added to Wikipedia, with the knowledge base receiving over 6 million monthly edits at its peak [43].", "startOffset": 127, "endOffset": 131}, {"referenceID": 16, "context": "The concept \u201ccollective memory\u201d was analyzed and advanced in the 1920s by Halbwachs [18]; see also [19].", "startOffset": 99, "endOffset": 103}, {"referenceID": 6, "context": "Since its introduction the concept has been studied in a wide variety of interdisciplinary fields, most notably in literature, history, and media [8, 37] but also in (experimental) psychology [20, 41, 51], e.", "startOffset": 146, "endOffset": 153}, {"referenceID": 34, "context": "Since its introduction the concept has been studied in a wide variety of interdisciplinary fields, most notably in literature, history, and media [8, 37] but also in (experimental) psychology [20, 41, 51], e.", "startOffset": 146, "endOffset": 153}, {"referenceID": 17, "context": "Since its introduction the concept has been studied in a wide variety of interdisciplinary fields, most notably in literature, history, and media [8, 37] but also in (experimental) psychology [20, 41, 51], e.", "startOffset": 192, "endOffset": 204}, {"referenceID": 38, "context": "Since its introduction the concept has been studied in a wide variety of interdisciplinary fields, most notably in literature, history, and media [8, 37] but also in (experimental) psychology [20, 41, 51], e.", "startOffset": 192, "endOffset": 204}, {"referenceID": 48, "context": "Since its introduction the concept has been studied in a wide variety of interdisciplinary fields, most notably in literature, history, and media [8, 37] but also in (experimental) psychology [20, 41, 51], e.", "startOffset": 192, "endOffset": 204}, {"referenceID": 4, "context": ", by emperically studying the performance of remembering events of different members of a single social group [5].", "startOffset": 110, "endOffset": 113}, {"referenceID": 35, "context": "Wikipedia was first dubbed a global memory place where collective memories are built by Pentzold [38], with follow-up studies by Keegan [25] and Ferron and Massa [11] shortly after that.", "startOffset": 97, "endOffset": 101}, {"referenceID": 22, "context": "Wikipedia was first dubbed a global memory place where collective memories are built by Pentzold [38], with follow-up studies by Keegan [25] and Ferron and Massa [11] shortly after that.", "startOffset": 136, "endOffset": 140}, {"referenceID": 9, "context": "Wikipedia was first dubbed a global memory place where collective memories are built by Pentzold [38], with follow-up studies by Keegan [25] and Ferron and Massa [11] shortly after that.", "startOffset": 162, "endOffset": 166}, {"referenceID": 1, "context": ", by extracting and studying temporal expressions from web documents it has been shown that we tend to remember the \u201cnear past\u201d online [2].", "startOffset": 135, "endOffset": 138}, {"referenceID": 5, "context": "Other sources used for online collective memory studies include search engine query logs [6], and microblog services [23].", "startOffset": 89, "endOffset": 92}, {"referenceID": 20, "context": "Other sources used for online collective memory studies include search engine query logs [6], and microblog services [23].", "startOffset": 117, "endOffset": 121}, {"referenceID": 27, "context": "And we are the first to empirically study this transition at scale and across text streams and entity types, signifying an important difference from the case studies that often involve dramatic or traumatizing events that are characteristic of the study of \u201ccollective memory\u201d [30, 36].", "startOffset": 277, "endOffset": 285}, {"referenceID": 33, "context": "And we are the first to empirically study this transition at scale and across text streams and entity types, signifying an important difference from the case studies that often involve dramatic or traumatizing events that are characteristic of the study of \u201ccollective memory\u201d [30, 36].", "startOffset": 277, "endOffset": 285}, {"referenceID": 21, "context": ", by analyzing how newly created articles fit in Wikipedia\u2019s semantic network, studying the relation between activity on talk pages and the addition of new content to articles, or by studying controversy and disagreement on new content through \u201cedit wars\u201d [24, 26, 52, 53].", "startOffset": 256, "endOffset": 272}, {"referenceID": 23, "context": ", by analyzing how newly created articles fit in Wikipedia\u2019s semantic network, studying the relation between activity on talk pages and the addition of new content to articles, or by studying controversy and disagreement on new content through \u201cedit wars\u201d [24, 26, 52, 53].", "startOffset": 256, "endOffset": 272}, {"referenceID": 49, "context": ", by analyzing how newly created articles fit in Wikipedia\u2019s semantic network, studying the relation between activity on talk pages and the addition of new content to articles, or by studying controversy and disagreement on new content through \u201cedit wars\u201d [24, 26, 52, 53].", "startOffset": 256, "endOffset": 272}, {"referenceID": 50, "context": ", by analyzing how newly created articles fit in Wikipedia\u2019s semantic network, studying the relation between activity on talk pages and the addition of new content to articles, or by studying controversy and disagreement on new content through \u201cedit wars\u201d [24, 26, 52, 53].", "startOffset": 256, "endOffset": 272}, {"referenceID": 18, "context": "Most notably, different methods and systems for identifying and linking unknown or emerging entities have been proposed [21, 29, 35, 48].", "startOffset": 120, "endOffset": 136}, {"referenceID": 26, "context": "Most notably, different methods and systems for identifying and linking unknown or emerging entities have been proposed [21, 29, 35, 48].", "startOffset": 120, "endOffset": 136}, {"referenceID": 32, "context": "Most notably, different methods and systems for identifying and linking unknown or emerging entities have been proposed [21, 29, 35, 48].", "startOffset": 120, "endOffset": 136}, {"referenceID": 45, "context": "Most notably, different methods and systems for identifying and linking unknown or emerging entities have been proposed [21, 29, 35, 48].", "startOffset": 120, "endOffset": 136}, {"referenceID": 14, "context": "[16] study the problem of predicting new concepts in social streams.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[9] formalize and analyze the specific challenges and aspects that come with linking emerging entities, while Reinanda et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 39, "context": "[42] study the problem of identifying relevant documents for known and emerging as as new information comes in and Graus et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[17] present a method for updating representations based on newly identified information.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "All documents in the corpus that were automatically classified as being written in English have been automatically tagged for named entities with the Serif tagger [4], yielding roughly 580M tagged documents.", "startOffset": 163, "endOffset": 166}, {"referenceID": 12, "context": "This annotated subset of documents was the official collection for the TREC Knowledge Base Acceleration (KBA) task in 2014 [14].", "startOffset": 123, "endOffset": 127}, {"referenceID": 12, "context": "TREC KBA [14] N/A N/A 579,838,246", "startOffset": 9, "endOffset": 13}, {"referenceID": 11, "context": "The news and social media streams themselves are composed of multiple datasets from different sources [13], which explains the gap seen around May 2012 up to somewhere in July 2012.", "startOffset": 102, "endOffset": 106}, {"referenceID": 37, "context": "Furthermore, to be able to visualize clusters and groups of similar time series, we linearly interpolate the time series to have equal length [40].", "startOffset": 142, "endOffset": 146}, {"referenceID": 43, "context": ", absolute number of mentions), we standardize all time series by subtracting the mean and dividing by standard deviation to account for the differences in volume/popularity [46].", "startOffset": 174, "endOffset": 178}, {"referenceID": 25, "context": "Typically, time series similarity metrics rely on fixed-length time series, and leverage seasonal or repetitive patterns [28].", "startOffset": 121, "endOffset": 125}, {"referenceID": 2, "context": "For this reason, common time series similarity metrics such as Dynamic Timewarping (DTW) are not applicable [3].", "startOffset": 108, "endOffset": 111}, {"referenceID": 43, "context": "To address the nature of our time series as well as our focus on bursts, we turn to BSim [46] (Burst Similarity) as the similarity metric we leverage to compare time series.", "startOffset": 89, "endOffset": 93}, {"referenceID": 43, "context": "These parameter choices for w and c are in line with previous work [46].", "startOffset": 67, "endOffset": 71}, {"referenceID": 31, "context": "Next, we apply hierarchical agglomerative clustering (HAC) on DM using the fastcluster package [34] to discover groups of similar time series at different levels of granularity.", "startOffset": 95, "endOffset": 99}, {"referenceID": 47, "context": "Ward\u2019s method is an iterative approach, where one starts with singleton clusters, and aims to merge the pair of samples that maximally decreases the within-cluster variance at each successive iteration [50].", "startOffset": 202, "endOffset": 206}, {"referenceID": 44, "context": "Throughout this paper we take an exploratory approach to analyzing, visualizing, and comparing patterns of groups of time series to discover meaningful clusterings [47].", "startOffset": 164, "endOffset": 168}, {"referenceID": 43, "context": "Figure 5: Dendrogram resulting from applying hierarchical agglomerative clustering using BSim [46] similarity, on our corpus of emerging entity time series (n = 79,482).", "startOffset": 94, "endOffset": 98}, {"referenceID": 36, "context": "[39], who compare breaking news on traditional media with that on social media.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[27] find that the \u201cattention span\u201d for news events on social media both increases and decays at a slower rate than for traditional news sources, which may explain the comparatively slower uptake on social media.", "startOffset": 0, "endOffset": 4}, {"referenceID": 42, "context": ", reports related to political elections) [45].", "startOffset": 42, "endOffset": 46}, {"referenceID": 13, "context": "Granka [15] studied the differences in \u201cattention span\u201d of the public (as measured through search engine query volumes) and the traditional news media (as measured through coverage volume) for \u201chard\u201d and \u201csoft news,\u201d and found that, in line with the findings of Leskovec et al.", "startOffset": 7, "endOffset": 11}, {"referenceID": 24, "context": "[27], hard news is associated with a relatively short period of attention from the public (as measured by query volume).", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "0, and blogging in particular [32], blogs no longer simply pick up news stories from the traditional media.", "startOffset": 30, "endOffset": 34}, {"referenceID": 30, "context": "The agenda setting power of traditional media is diluting [33].", "startOffset": 58, "endOffset": 62}, {"referenceID": 19, "context": ", the death of Osama Bin Laden [22].", "startOffset": 31, "endOffset": 35}, {"referenceID": 36, "context": "And finally, as mentioned before, the events reported on social media and traditional news overlap, but social media has a long tail of its \u201cown\u201d events [39], which may account for the different distribution of emerging entity types in the social media stream.", "startOffset": 153, "endOffset": 157}, {"referenceID": 44, "context": "Clustering and studying cluster signatures is by design a subjective matter [47].", "startOffset": 76, "endOffset": 80}, {"referenceID": 10, "context": "So-called \u201ccascading errors\u201d [12] cause the overall accuracy to suffer, by using imperfect tagging by SERIF as input for imperfect FAKBA1 annotations.", "startOffset": 29, "endOffset": 33}], "year": 2017, "abstractText": "We study how collective memories are formed online. We do so by tracking entities that emerge in public discourse, that is, in online text streams such as social media and news streams, before they are incorporated into Wikipedia, which, we argue, can be viewed as an online place for collective memory. By tracking how entities emerge in public discourse, i.e., the temporal patterns between their first mention in online text streams and subsequent incorporation into collective memory, we gain insights into how the collective remembrance process happens online. Specifically, we analyze nearly 80,000 entities as they emerge in online text streams before they are incorporated into Wikipedia. The online text streams we use for our analysis comprise of social media and news streams, and span over 579 million documents in a timespan of 18 months. We discover two main emergence patterns: entities that emerge in a \u201cbursty\u201d fashion, i.e., that appear in public discourse without a precedent, blast into activity and transition into collective memory. Other entities display a \u201cdelayed\u201d pattern, where they appear in public discourse, experience a period of inactivity, and then resurface before transitioning into our cultural collective memory.", "creator": "LaTeX with hyperref package"}}}