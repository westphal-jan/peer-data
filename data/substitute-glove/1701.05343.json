{"id": "1701.05343", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Jan-2017", "title": "A Joint Framework for Argumentative Text Analysis Incorporating Domain Knowledge", "abstract": "For argumentation mining, nothing places more country - designing change as gandhian similar types 4a, relation classification. Existing studying effect for solve such pickup3rdgraf - tasks separately, way ignore although down defining between cannot. In turn paper, we present another joint application works imply necessity two lowest - decisions from improve the performance whose argumentation structure makes. We design on aims function to medium the predictions from require different other each sub - focus or practical the problem with because responsibilities installed soon background knowledge. We examine our proposed model on 30 public corpora these place experiment results show change enough core they strategist given bending that derived only existing uses significantly making each countries - tasked. Our model one stories benefits from transformation - aspects economies - efficient 60 on right officials - is - the - literature joint model based thursday the evidence affine.", "histories": [["v1", "Thu, 19 Jan 2017 09:32:08 GMT  (806kb)", "http://arxiv.org/abs/1701.05343v1", "12 pages"]], "COMMENTS": "12 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["zhongyu wei", "chen li", "yang liu"], "accepted": false, "id": "1701.05343"}, "pdf": {"name": "1701.05343.pdf", "metadata": {"source": "CRF", "title": "A Joint Framework for Argumentative Text Analysis Incorporating Domain Knowledge", "authors": ["Zhongyu Wei", "Chen Li", "Yang Liu"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n70 1.\n05 34\n3v 1\n[ cs\n.C L\n] 1\n9 Ja\nn 20\n17"}, {"heading": "1 Introduction", "text": "Argumentation mining has attracted increasing attention from NLP research in recent years. It aims to automatically recognize the structure of argumentation in a text by identifying the type of argumentative discourse unit (ADU, e.g., claim, premises, etc.) and detecting relationships between each pair of such ADUs. A variety of applications can benefit from analyzing argumentative structure of text, including the retrieval of relevant court decisions from legal databases (Palau and Moens, 2009), automatic document summarization systems, analysis of scientific papers, and essay scoring (Beigman et al., 2014; Persing and Ng, 2015).\nThe full-fledged task of argumentation mining consists of several sub-tasks including segmentation, identification of ADUs, ADU type classification and relation identification (Peldszus and Stede, 2015b). Stab and Gurevych (2014b) aimed to classify text segments into four classes, namely major claim, claim, premise and non-argumentative for persuasive essays. Based on the same corpus and setting, Nguyen et al. (2015) explored a semi-supervised method for segment type classification. Peldszus and Stede (2015b) worked on a microtext corpus and aimed to identify the attachment relation between ADUs. Most of the existing research for argumentation mining either focuses on a single task or tackles sub-tasks separately without considering the relation between them.\nBased on the annotation schemes of the argumentative text and characteristics shown in a specific corpus, there can be strong relations between different argumentation sub-tasks. Take the corpus annotated by Peldszus and Stede (2015a) as an example (Figure 1 shows an example). There is only one central claim in each text unit and there is no attachment relation starting from the central claim. It is fair to assume that the result of central claim identification is bonded to that of relation identification. Stab and Gurevych (2014b) also showed that if perfect labels from ADU type classification can be added as extra features for relation classification, the performance can be improved significantly, and vice versa. Peldszus and Stede (2015b) thus proposed an evidence-graph based approach to jointly solve four argumentation mining sub-tasks. Experiments on a microtext corpus showed its effectiveness. However, their approach requires a tree argumentation structure as input thus is not applicable to many corpora. Especailly, the evaluation corpus is generated artificially, which benefits the joint-model in nature.\n\u2217*Corresponding Author: zywei@fudan.edu.cn\nIn this paper, we also propose to use a joint framework inspired by Roth and Yih (Roth and tau Yih, 2004) to combine the predictions of argumentation mining sub-tasks from separate models for argumentation structure prediction. We treat the problem as an optimization problem. Based on different annotation schemes, we generate corpus-specific constraints and solve the problem using Integer Linear Programming (ILP). With the flexibility of designing corpus-specific objective functions and constraints, our joint model can be applied to all kinds of datasets. We evaluate our model on two public corpora: an artificial generated corpus (microtext) and a real environment corpus (student essays). The experiment results on both corpora show that our joint model improves the performance of separate models significantly. In particular for component-based tasks, our approach can outperform the state-of-the-art joint model based on evidence graph in a large margin."}, {"heading": "2 Related Work", "text": "Previous research on argumentation mining focuses on several sub-tasks, including (1) splitting text into discourse units (DU) (Madnani et al., 2012; Du et al., 2014), (2) identification of ADUs from non-argumentative ones (Moens et al., 2007; Florou et al., 2013), (3) identification of ADU types (Biran and Rambow, 2011; Nguyen and Litman, 2015; Eckle-Kohler et al., 2015; Habernal and Gurevych, 2015) and (4) identification of relation between ADUs (Lawrence et al., 2014; Stab and Gurevych, 2014b; Peldszus and Stede, 2015b; Kirschner et al., 2015). We will concentrate on the latter two sub-tasks in this part and introduce some existing joint models.\nADU type classification: Stab and Gurevych (2014b) aimed to classify text segments into four classes, namely major claim, claim, premise and non-argumentative for persuasive essays. Based on the same corpus and setting, Nguyen et al. (2015) explored a semi-supervised method for segment type classification. They proposed to divide words into argument words and topic words; and deploy a semi-supervised method to generate argument words based on 10 seeding words, and then used them as additional features for classification. Habernal and Gurevych (2015) also focused on developing semi-supervised features. They exploited clustering of unlabeled data from debate portals based on word embeddings. Some research focused on specific types of ADU identification given its context. Park and Cardie (2014)\nproposed to identify the supporting situation for a given claim. Biran et al. (2011) aimed to identify justifications for claims.\nRelation identification: There is much less work for relation identification. Palau and Moens (2011) used a hand-written context-free grammar to predict argumentation trees on legal documents. Kirchner et al. (2015) presented an annotation study for fine-grained analysis of argumentation structures in scientific publications. For data-driven approaches, Lawrence et al. (2014) constructed tree structures on philosophical texts using unsupervised methods based on topical distance between segments. Stab and Gurevych (2014b) presented a supervised approach for student essays. Peldszus and Stede (2015b) aimed to identify the attachment relation between ADUs on a microtext corpus.\nJoint model for argumentation mining: Although there are several approaches for different subtasks in argumentation mining, researchers rarely consider to solve sub-tasks in unified way. Stab and Gurevych (2014b) explored to directly use the prediction results of ADU type classification as features for the task of relation classification, however, without considering logical relation between these two tasks, the effect was marginal. Peldszus and Stede (2015b) tackled four argumentation mining tasks including three ADU type classification tasks and the task of relation identification. They proposed to combine the prediction results for these sub-tasks as the edge weights of an evidence graph. They then applied a standard max spanning tree (MST) decoding algorithm and showed its effectiveness on a microtext corpus.\nIn our research, we also explore to identify argumentation structure in unified way. We propose to use integer linear programming (ILP) to combine predictions from sub-tasks and generate results jointly with argumentation structure related constraints. Compared to the evidence-graph-based approach that requires the tree-structure of argumentation as input, our model is more flexible and can be easily applied to different corpora with various characteristics."}, {"heading": "3 Framework of ILP-based Joint Model", "text": "The overall framework of our joint model for argumentation mining can be seen in Figure 2. For an input argumentative text unit, we first employ several separate models to predict results for each subtask. Our joint model then takes the probability scores from each separate model as input to form the objective function. Besides, we define constraints based on the annotation scheme of the target corpus."}, {"heading": "112 462 451 125 290 174 112 464 2,000", "text": "We solve the objective function by ILP with these constraints. Our joint model finally generates updated predictions for all the sub-tasks simultaneously.\nIn order to evaluate our proposed joint model, we use two public corpora, consisting of microtext (Peldszus and Stede, 2015a) and persuasive essays (Stab and Gurevych, 2014a) respectively. In the first corpus, all the texts are generated in a controlled environment for research purpose. It ensures the tree structure of argumentations in the input text unit. In the second corpus, all the documents are student essays collected from on online learning platform. It thus contains noise. With different annotation schemes, these two corpora have different sub-task settings. We will design objective functions and construct constraints for each corpus accordingly."}, {"heading": "4 Joint Model for Microtext", "text": ""}, {"heading": "4.1 Microtext Corpus", "text": "The corpus of \u201cmicrotexts\u201d is from Peldszus and Stede (2015a). The dataset contains 112 text units with 576 ADUs. 23 text units are written by the authors, while the rest are generated by instructed users in a controlled environment. The corpus is annotated according to a scheme representing segment-level argumentation structure (Freeman, 1991). The annotations include three ADU type labels, central claim (CC, if it is a central claim), role (RO, proponent or opponent), function (FU, support, attack and none) and one relation label, attachment (AT, if there is an attachment relation between a pair of ADUs). An example text unit in this corpus can be seen in Figure 1.\nThis corpus has the following properties: (1) The length of each text is about 5 ADUs. (2) One segment explicitly states the central claim. (3) Each segment is argumentatively relevant. (4) At least one objection to the central claim is considered. The basic statistics can be seen in Table 1. There are 2,464 possible pairs of relations between ADUs, in which 464 are annotated as attachment. The corpus contains both German and English version. We only use the English version in our paper."}, {"heading": "4.2 ILP-based Joint Model", "text": "There are four sub-tasks designed in this corpus based on its annotation scheme, including central claim identification (cc), role identification (ro), function classification (fu), and attachment relation classification (at). Our joint model takes the probability scores predicted by the individual classifiers for each sub-task as input and generates the final prediction jointly. In order to consider all the sub-tasks simultaneously, we aim to maximize the following objective function:\nw1 \u2211\ni\n{aiCCi}+ w2 \u2211\ni\n{biROi}+ w3 \u2211\ni\n{ciSUPi + eiATTi + giNONEi}+ w4 \u2211\nij\n{dijATij}\nwhere the four different components correspond to four sub-tasks respectively: CCi stands for the probability of segment i being central claim; ROi stands for the probability of i having proponent role; SUPi, ATTi, and NONEi denote the probability of the function type of i (support, attack and none); and ATij is the probability of i attaching to j. ai, bi, ci, ei and gi are binary variables indicating if segment i is predicted as true for different sub-tasks. dij is also a binary variable representing if segment i attaches j. w1, w2, w3 and w4 are introduced to balance the contributions of different sub-tasks.\nBased on the task definition and annotation scheme, we have the following constraints.\na) There is only one central claim. (Eq. 1)\nb) There is at least one opponent segment. (Eq. 2)\nperformance is statistically significantly better than separate baseline (p<0.05); Italic: the performance is significantly better than MST (p<0.05).)\nc) The function of i is one of support, attack and none. (Eq. 3).\nd) If i is the central claim, then its role is proponent (Eq. 4).\ne) If i is the central claim, then its function is none (Eq. 5).\nf) If i is the central claim, then it attaches to no other segments, otherwise, it attaches to one and only one other segment. (Eq. 6).\ng) If i is the central claim, it has at least one supporting segment. (Eq. 7).\nh) There can be no more than one relation between two segments. (Eq. 8).\ni) If i attaches j and the function of i is support, then the role of i and j are the same. (Eq. 9).\nj) If i attaches j and the function of i is attack, then the role of i and j are opposite. (Eq. 10).\n\u2211\ni\nai = 1 (1) \u2211\ni\n{1\u2212 bi} >= 1 (2)\n\u2200ici + ei + gi = 1 (3) \u2200iai <= bi (4)\n\u2200iai = gi (5) \u2200iai + \u2211\nj\ndij = 1 (6)\n\u2200jaj \u2264 \u2211\ni\ncij (7) \u2200ijdij + dji <= 1 (8)\n\u2200ij(dij \u2227 ci) \u2192 (bi = bj) (9) \u2200ij(dij \u2227 ei) \u2192 (bi + bj = 1) (10)"}, {"heading": "4.3 Results", "text": "We implemented the approach of (Peldszus and Stede, 2015b) for each sub-task1. For the sub-task cc, ro and at, we trained binary classifiers, while a three-way classifier was trained for fu. 10-fold crossvalidation is used. We report F-1 score for each sub-task and their macro-F1. We compared three approaches on this corpus.\n- separate: the baseline approach from (Peldszus and Stede, 2015b) that we re-implemented.\n- MST: we implemented the evidence-graph-based approach of (Peldszus and Stede, 2015b). In this approach, a fully connected multigraph over all the segments is first generated. Then, the prediction probabilities from different sub-tasks are combined as edge weights. Finally, MST is used to decode the graph and generate a tree structure as argumentation structure. The prediction results for each sub-task are generated from the resulting tree based on some rules.\n- ILP: this is our approach."}, {"heading": "4.3.1 Overall Experiment Results", "text": "Table 2 shows the results on the microtext corpus. MST and ILP use equal weighting2 for sub-task combination.\n1We obtained similar performance for all the sub-tasks except function classification. 2We also explored to tune the weighting for each sub-task based on the setting of 10-fold cross validation, however, the performance drops slightly for both joint approaches. The influence of different combination of weighting to the performance of each task will be given in next section.\nBoth joint models (MST and ILP) can improve performance over separate baseline for all the subtasks (except MST on fu) and the improvements are significant3 in terms of macro F1. This indicates that joint prediction of sub-tasks can improve the performance of each single task for argumentation mining.\nCompared to MST, our approach ILP achieves equal or better results for all the sub-tasks. In particular, ILP-based approach performs similarly as MST-based model for structure-based tasks (cc4 and at), but performs better for component-based tasks (ro and fu). For fu, ILP is significantly better than MST. For ro, ILP improve the performance significantly based on separate while the improvement obtained by MST is not significant. This is partly because we include the probability of function type none in the objective function, while the MST-based model could not encode this factor into the graph. Besides, we explicitly state that the number of opponent segments should be at least one, while the MST-based method is unable to set such a constraint. This shows that our ILP-based approach can better utilize joint information for argumentation mining than the MST-based method."}, {"heading": "4.3.2 Discussion", "text": "In order to show the contribution of each sub-task to the predictions of the other sub-tasks, we simulate better individual classification results and study their impact. We utilize the strategy proposed in (Peldszus and Stede, 2015b) for this experiment. We artificially improved the classification result of one sub-task by overwriting a percentage of its predictions with ground truth. The overwritten samples are chosen randomly and the choosing process is on top of the original base classifier, regardless of whether the base classifier already chose the correct label. The simulation result can be seen in Figure 3. The figure plots the F score on y-axis for all the sub-tasks when varying the improvement percentage on top of the base classifier for one task (x-axis). Each subfigure shows the simulation results when improving the corresponding task.\nAs we can see, function classification is improved when using better role classification due to the logical connection between them, whereas the other sub-tasks are unaffected. Similarly, the performance of role classification is affected by the artificial improvement of function as well. Since the task of central claim and function classification overlaps partially (segment with function none is central claim), their performance is bonded in this experiment. The performance of attachment classification is difficult to be affected by other sub-tasks, however, improving it results in improvement of other sub-tasks. This is because given a correct tree-structure, the result of other sub-tasks can be inferred to some extent.\nWe also evaluate the influence of different combination weights. We set a task as a target at a time, and use x for its weight and other three tasks as (1 \u2212 x) / 3. The higher x is, the more contribution the target task makes in the joint model. When x equals 0, the label for the target task is assigned randomly, restricted by the constraints only. When x equals 1, the labels for the other three tasks are assigned\n3The significance test is performed using paired two-tailed t-test. 4The prediction of major claim can be inferred using relation information.\nrandomly. We thus sampled x in the range of [0.1, 0.9]. The result can be seen in Figure. 4. In general the performance of the target task increases when its weight increases, although the improvement is not large. ro is the only task that is sensitive to different combinations of weight. When the target task is fu or at, the performance of ro drops along with its weight drops."}, {"heading": "5 Joint Model for Student Essays", "text": "The corpus of microtext (Peldszus and Stede, 2015b) shows the effectiveness of the joint models for argumentation mining, including the evidence-graph-based method as well as our ILP-based approach. However, the corpus is generated for research purpose and follows some restricted rules (e.g., one central claim, one out-arrow for non-central claim, etc.), which might benefit the joint models. In order to show the flexibility of our ILP-based approach for argumentation mining, we applied our ILP-based model on another corpus (Stab and Gurevych, 2014a) consisting of student essays."}, {"heading": "5.1 Student Essays Corpus", "text": "This corpus contains 90 persuasive essays in English. They were selected from the online learning platform essayforum5. It has segment-level annotations including ADU type annotations of major claim, claim and premises; relations of support and non-support between argumentative segments. The natural unit of this corpus is an entire student essay, however, there rarely exist cross-paragraph support relations. We thus treat each paragraph as a single unit following (Stab and Gurevych, 2014b). The original corpus contains 416 paragraphs.\nIn the original setting of the corpus, there are two sub-tasks, namely, component classification and relation identification. The former one aims to label a target component as major claim, claim, premise or non-argumentative. For a given pair of argumentative components, relation identification aims to classify the relation as support or non-support. To make the two tasks consistent, we made some modifications\n5http://www.essayforum.com\non the original corpus. First, we ignored non-argumentative components in the component classification task because only relations between argumentative components were considered in relation identification. Second, we combined two categories major claim and claim, because these two roles are similar when using paragraphs as units, considering there is no claim to claim relation. Third, we filtered those paragraphs with less than one argumentative component because there is no relation identified in such paragraphs. After the pre-selection, we obtained a version of corpus mod-1, including 351 paragraphs (versus 416 in the original one). For this modified version of the corpus, the component classification task thus becomes binary classification of claim and premise.\nIn theory, a complete argument should include one claim and its supporting premises. But some essays in the corpus were not written properly. They include isolated claims or premises. To simulate the perfect situation, we further constructed two other versions of the corpus, named mod-2 and mod-3. In mod-2, a premise should have at least one out-going arrow to support other components. Furthermore, a claim should have at least one support premise in mod-3. The basic statistics of the corpora are shown in Table 3. Based on the distribution of claim and premise, this corpus is different from the microtext one in that the number of central claims in each paragraph can be more than one and a premise can support more than one claim. Thus, the tree structure of argumentation is not always assured in this corpus."}, {"heading": "5.2 ILP-based Joint Model", "text": "There are two sub-tasks designed in this corpus based on its annotation scheme, including component classification (comp) and relation classification (rel). Our ILP model takes the output of the separate models for the two sub-tasks as input and aims to generate results for both tasks in a mutual-reinforcement way. Suppose there are N argumentative components in a target paragraph. For each component i, we have a probability distribution for being claim and premise, noted as Pi and Ci. For each pair of such components, the probability for component i to support j is SUPij . We aim to maximize the following objective function:\nv \u2211\ni\n{aiCi + biPi}+ (1\u2212 v) \u2211\ni,j\n{cijSUPij}\nwhere ai and bi are two binary variables to denote if the target component is claim or premise, cij is a binary variable to denote if the supporting relation between i and j exists or not. v6 is introduced to balance the contributions of the two tasks.\nThe following constraints are used in this corpus (constraints f and g are only used in the dataset of mod-2 or mod-3).\na) A component is either claim or premise. (Eq. 11) b) There is at most one relation between two segments. (Eq. 12) c) A relation only starts from a premise. (Eq. 13) d) There is at least one claim. (Eq. 14) e) To control the predicted number of support relations, we set the max number of relations in each\nparagraph as the number of components, comp num. (Eq. 15) f) A premise should support at least one claim. (Eq. 16, for mod-2 and mod-3)\ng) A claim should be supported by at least one premise. (Eq. 17, for mod-3)\n\u2200i{ai + bi} = 1 (11) \u2200i,j{cij + cji} <= 1 (12)\n\u2200jbi \u2265 cij (13) \u2211\nj {aj} >= 1 (14) \u2211\ni,j\n{cij} <= comp num (15) \u2200ibi \u2264 \u2211\nj\ncij (16)\n\u2200jaj \u2264 \u2211\ni\ncij (17)\n6Due to the length limit, we will not discuss the influence of v on the student essays corpus."}, {"heading": "5.3 Results", "text": "We implemented the approach from (Stab and Gurevych, 2014b) for each sub-task. For component classification, we used five categories of features including structural, lexical, syntactic, indicators and contextual. Instead of SVM, we employed MaxEntropy for classification because it shows better result in our implementation. For relation classification, we followed the original paper and employed MaxEntropy as well. 10-fold cross-validation is used. For both tasks, we trained binary classifiers. We take the probabilities predicted by the two classifiers as input to our ILP model. F-1 score is used as evaluation metric. We compared the following three approaches.\n- separate: the baseline approach from (Stab and Gurevych, 2014b) that we re-implemented.\n- MST: we implemented the evidence-graph-based approach for this corpus. Since the relation should always start from a premise, we compute the edge score eij from segment i to j as \u03b2Pi+(1\u2212\u03b2)SUPij , where \u03b1 is introduced to balance the contributions of two sub-tasks.\n- ILP: this is our approach.\nThe performance on the student essays can be seen in Table 4. In all the three versions of datasets, both joint models can improve the performance significantly compared to the separate baseline based on macro F1 score. Our approach ILP achieves better macro F1 score than MST on all the three datasets and generates significantly better results for component classification in both datasets mod-1 and mod2. This re-confirms that our ILP-based approach can better utilize joint information for argumentation mining compared to the MST-based methods for component-based task. The performance gain from the joint models over the separate baseline approach increases from dataset mod-1 to mod-3 when the argumentation structure is more strict. This is because the joint model can perform better when the structure information is more correct. The performance gain of our model over MST-based is larger in dataset mod-1 and mod-2 compared to mod-3. This shows the MST-based model is more sensitive to the quality of the argumentation structure. Our ILP model is more robust."}, {"heading": "5.3.1 Discussion", "text": "The result of the simulation experiment on this corpus can be seen in Figure 6. As we can see, the performance of component classification is greatly improved by a better relation classification. However, the effect of better component classification on relation identification is small. This is because given the correct relation structure of a text, the role of each component can be identified easily. In contrast, even the component classification is perfect, the identification of relation between them is still hard. In addition, the low performance of the base relation identification sub-task also matters.\nWe also evaluate the effect of different combination of weights in the same way as we did for microtext corpus. The result shows that for larger \u03b1, the performance for component classification is higher in general; the impact of \u03b1 on relation classification is smaller. This might be because the base performance for the relation classifier is low. Due to the length limit, we did not show figure here.\nThe result is shown in Figure 5. The higher v is, the more contribution component classification makes in the joint model. In general, for larger v, the performance for component classification is higher. The impact of v on relation classification is smaller. This might be because the base performance for the relation classifier is low."}, {"heading": "6 Summary and Future Work", "text": "We introduced a joint framework to argumentation mining based on ILP to combine prediction results from individual sub-tasks and encode argumentation structure related characteristics as constraints to generate updated predictions for all sub-tasks. Our ILP-based approach is superior to the existing graphbased model because it can work on all kinds of datasets without requirement for tree structure as input and it can utilize more joint information represented by constraints, especially for component-based tasks.\nThere are two interesting directions for future research. First, we will look into other kinds of argumentative texts with more noise and even more complicated argumentation structure, such as posts from online debate forum. Second, we will integrate our argumentation mining framework for automatic student essay scoring."}], "references": [{"title": "Applying argumentation schemes for essay scoring", "author": ["Beigman et al.2014] Beigman", "Song Yi", "Michael Heilman Beata", "Klebanov Paul Deane"], "venue": "ACL", "citeRegEx": "Beigman et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Beigman et al\\.", "year": 2014}, {"title": "Identifying justifications in written dialogs", "author": ["Biran", "Rambow2011] Or Biran", "Owen Rambow"], "venue": "In Semantic Computing (ICSC),", "citeRegEx": "Biran et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Biran et al\\.", "year": 2011}, {"title": "Shell miner: Mining organizational phrases in argumentative texts in social media", "author": ["Du et al.2014] Jianguang Du", "Jing Jiang", "Liu Yang", "Dandan Song", "Lejian Liao"], "venue": "In Data Mining (ICDM),", "citeRegEx": "Du et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Du et al\\.", "year": 2014}, {"title": "On the role of discourse markers for discriminating claims and premises in argumentative discourse", "author": ["Roland Kluge", "Iryna Gurevych"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Eckle.Kohler et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Eckle.Kohler et al\\.", "year": 2015}, {"title": "Argument extraction for supporting public policy formulation", "author": ["Florou et al.2013] Eirini Florou", "Stasinos Konstantopoulos", "Antonis Koukourikos", "Pythagoras Karampiperis"], "venue": "In Proceedings of the 7th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities,", "citeRegEx": "Florou et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Florou et al\\.", "year": 2013}, {"title": "Dialectics and the macrostructure of arguments: A theory of argument structure, volume 10", "author": ["James B Freeman"], "venue": null, "citeRegEx": "Freeman.,? \\Q1991\\E", "shortCiteRegEx": "Freeman.", "year": 1991}, {"title": "Exploiting debate portals for semisupervised argumentation mining in user-generated web discourse", "author": ["Habernal", "Gurevych2015] Ivan Habernal", "Iryna Gurevych"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Habernal et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Habernal et al\\.", "year": 2015}, {"title": "Linking the thoughts: Analysis of argumentation structures in scientific publications. In Proceedings of the 2nd Workshop on Argumentation Mining held in conjunction with the 2015 Conference of the North American Chapter of the Association for Computational Linguistics", "author": ["Judith Eckle-Kohler", "Iryna Gurevych"], "venue": "Human Language Technologies (NAACL HLT", "citeRegEx": "Kirschner et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kirschner et al\\.", "year": 2015}, {"title": "Mining arguments from 19th century philosophical texts using topic based modelling", "author": ["Chris Reed", "Colin Allen", "Simon McAlister", "Andrew Ravenscroft", "David Bourget"], "venue": "Proceedings of the First Workshop on Argumentation Mining,", "citeRegEx": "Lawrence et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lawrence et al\\.", "year": 2014}, {"title": "Identifying high-level organizational elements in argumentative discourse", "author": ["Michael Heilman", "Joel Tetreault", "Martin Chodorow"], "venue": "In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,", "citeRegEx": "Madnani et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Madnani et al\\.", "year": 2012}, {"title": "Automatic detection of arguments in legal texts", "author": ["Erik Boiy", "Raquel Mochales Palau", "Chris Reed"], "venue": "In Proceedings of the 11th international conference on Artificial intelligence and law,", "citeRegEx": "Moens et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Moens et al\\.", "year": 2007}, {"title": "Extracting argument and domain words for identifying argument components in texts", "author": ["Nguyen", "Litman2015] Huy V Nguyen", "Diane J Litman"], "venue": null, "citeRegEx": "Nguyen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2015}, {"title": "Argumentation mining: the detection, classification and structure of arguments in text", "author": ["Palau", "Moens2009] Raquel Mochales Palau", "Marie-Francine Moens"], "venue": "In Proceedings of the 12th international conference on artificial intelligence and law,", "citeRegEx": "Palau et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Palau et al\\.", "year": 2009}, {"title": "Identifying appropriate support for propositions in online user comments", "author": ["Park", "Cardie2014] Joonsuk Park", "Claire Cardie"], "venue": "ACL", "citeRegEx": "Park et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Park et al\\.", "year": 2014}, {"title": "2015a. An annotated corpus of argumentative microtexts", "author": ["Peldszus", "Stede2015a] Andreas Peldszus", "Manfred Stede"], "venue": "In Proceedings of the First Conference on Argumentation,", "citeRegEx": "Peldszus et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Peldszus et al\\.", "year": 2015}, {"title": "2015b. Joint prediction in mst-style discourse parsing for argumentation mining", "author": ["Peldszus", "Stede2015b] Andreas Peldszus", "Manfred Stede"], "venue": "In Proc. of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Peldszus et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Peldszus et al\\.", "year": 2015}, {"title": "Modeling argument strength in student essays", "author": ["Persing", "Ng2015] Isaac Persing", "Vincent Ng"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),", "citeRegEx": "Persing et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Persing et al\\.", "year": 2015}, {"title": "A linear programming formulation for global inference in natural language tasks", "author": ["Roth", "tau Yih2004] Dan Roth", "Wen tau Yih"], "venue": "In Proceedings of CoNLL-2004,", "citeRegEx": "Roth et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Roth et al\\.", "year": 2004}, {"title": "Annotating argument components and relations in persuasive essays", "author": ["Stab", "Gurevych2014a] Christian Stab", "Iryna Gurevych"], "venue": "In Proceedings of the 25th International Conference on Computational Linguistics (COLING", "citeRegEx": "Stab et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Stab et al\\.", "year": 2014}, {"title": "Identifying argumentative discourse structures in persuasive essays", "author": ["Stab", "Gurevych2014b] Christian Stab", "Iryna Gurevych"], "venue": "In Conference on Empirical Methods in Natural Language Processing (EMNLP 2014)(Oct", "citeRegEx": "Stab et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Stab et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "A variety of applications can benefit from analyzing argumentative structure of text, including the retrieval of relevant court decisions from legal databases (Palau and Moens, 2009), automatic document summarization systems, analysis of scientific papers, and essay scoring (Beigman et al., 2014; Persing and Ng, 2015).", "startOffset": 275, "endOffset": 319}, {"referenceID": 0, "context": "A variety of applications can benefit from analyzing argumentative structure of text, including the retrieval of relevant court decisions from legal databases (Palau and Moens, 2009), automatic document summarization systems, analysis of scientific papers, and essay scoring (Beigman et al., 2014; Persing and Ng, 2015). The full-fledged task of argumentation mining consists of several sub-tasks including segmentation, identification of ADUs, ADU type classification and relation identification (Peldszus and Stede, 2015b). Stab and Gurevych (2014b) aimed to classify text segments into four classes, namely major claim, claim, premise and non-argumentative for persuasive essays.", "startOffset": 276, "endOffset": 552}, {"referenceID": 0, "context": "A variety of applications can benefit from analyzing argumentative structure of text, including the retrieval of relevant court decisions from legal databases (Palau and Moens, 2009), automatic document summarization systems, analysis of scientific papers, and essay scoring (Beigman et al., 2014; Persing and Ng, 2015). The full-fledged task of argumentation mining consists of several sub-tasks including segmentation, identification of ADUs, ADU type classification and relation identification (Peldszus and Stede, 2015b). Stab and Gurevych (2014b) aimed to classify text segments into four classes, namely major claim, claim, premise and non-argumentative for persuasive essays. Based on the same corpus and setting, Nguyen et al. (2015) explored a semi-supervised method for segment type classification.", "startOffset": 276, "endOffset": 742}, {"referenceID": 0, "context": "A variety of applications can benefit from analyzing argumentative structure of text, including the retrieval of relevant court decisions from legal databases (Palau and Moens, 2009), automatic document summarization systems, analysis of scientific papers, and essay scoring (Beigman et al., 2014; Persing and Ng, 2015). The full-fledged task of argumentation mining consists of several sub-tasks including segmentation, identification of ADUs, ADU type classification and relation identification (Peldszus and Stede, 2015b). Stab and Gurevych (2014b) aimed to classify text segments into four classes, namely major claim, claim, premise and non-argumentative for persuasive essays. Based on the same corpus and setting, Nguyen et al. (2015) explored a semi-supervised method for segment type classification. Peldszus and Stede (2015b) worked on a microtext corpus and aimed to identify the attachment relation between ADUs.", "startOffset": 276, "endOffset": 836}, {"referenceID": 0, "context": "A variety of applications can benefit from analyzing argumentative structure of text, including the retrieval of relevant court decisions from legal databases (Palau and Moens, 2009), automatic document summarization systems, analysis of scientific papers, and essay scoring (Beigman et al., 2014; Persing and Ng, 2015). The full-fledged task of argumentation mining consists of several sub-tasks including segmentation, identification of ADUs, ADU type classification and relation identification (Peldszus and Stede, 2015b). Stab and Gurevych (2014b) aimed to classify text segments into four classes, namely major claim, claim, premise and non-argumentative for persuasive essays. Based on the same corpus and setting, Nguyen et al. (2015) explored a semi-supervised method for segment type classification. Peldszus and Stede (2015b) worked on a microtext corpus and aimed to identify the attachment relation between ADUs. Most of the existing research for argumentation mining either focuses on a single task or tackles sub-tasks separately without considering the relation between them. Based on the annotation schemes of the argumentative text and characteristics shown in a specific corpus, there can be strong relations between different argumentation sub-tasks. Take the corpus annotated by Peldszus and Stede (2015a) as an example (Figure 1 shows an example).", "startOffset": 276, "endOffset": 1326}, {"referenceID": 0, "context": "A variety of applications can benefit from analyzing argumentative structure of text, including the retrieval of relevant court decisions from legal databases (Palau and Moens, 2009), automatic document summarization systems, analysis of scientific papers, and essay scoring (Beigman et al., 2014; Persing and Ng, 2015). The full-fledged task of argumentation mining consists of several sub-tasks including segmentation, identification of ADUs, ADU type classification and relation identification (Peldszus and Stede, 2015b). Stab and Gurevych (2014b) aimed to classify text segments into four classes, namely major claim, claim, premise and non-argumentative for persuasive essays. Based on the same corpus and setting, Nguyen et al. (2015) explored a semi-supervised method for segment type classification. Peldszus and Stede (2015b) worked on a microtext corpus and aimed to identify the attachment relation between ADUs. Most of the existing research for argumentation mining either focuses on a single task or tackles sub-tasks separately without considering the relation between them. Based on the annotation schemes of the argumentative text and characteristics shown in a specific corpus, there can be strong relations between different argumentation sub-tasks. Take the corpus annotated by Peldszus and Stede (2015a) as an example (Figure 1 shows an example). There is only one central claim in each text unit and there is no attachment relation starting from the central claim. It is fair to assume that the result of central claim identification is bonded to that of relation identification. Stab and Gurevych (2014b) also showed that if perfect labels from ADU type classification can be added as extra features for relation classification, the performance can be improved significantly, and vice versa.", "startOffset": 276, "endOffset": 1629}, {"referenceID": 0, "context": "A variety of applications can benefit from analyzing argumentative structure of text, including the retrieval of relevant court decisions from legal databases (Palau and Moens, 2009), automatic document summarization systems, analysis of scientific papers, and essay scoring (Beigman et al., 2014; Persing and Ng, 2015). The full-fledged task of argumentation mining consists of several sub-tasks including segmentation, identification of ADUs, ADU type classification and relation identification (Peldszus and Stede, 2015b). Stab and Gurevych (2014b) aimed to classify text segments into four classes, namely major claim, claim, premise and non-argumentative for persuasive essays. Based on the same corpus and setting, Nguyen et al. (2015) explored a semi-supervised method for segment type classification. Peldszus and Stede (2015b) worked on a microtext corpus and aimed to identify the attachment relation between ADUs. Most of the existing research for argumentation mining either focuses on a single task or tackles sub-tasks separately without considering the relation between them. Based on the annotation schemes of the argumentative text and characteristics shown in a specific corpus, there can be strong relations between different argumentation sub-tasks. Take the corpus annotated by Peldszus and Stede (2015a) as an example (Figure 1 shows an example). There is only one central claim in each text unit and there is no attachment relation starting from the central claim. It is fair to assume that the result of central claim identification is bonded to that of relation identification. Stab and Gurevych (2014b) also showed that if perfect labels from ADU type classification can be added as extra features for relation classification, the performance can be improved significantly, and vice versa. Peldszus and Stede (2015b) thus proposed an evidence-graph based approach to jointly solve four argumentation mining sub-tasks.", "startOffset": 276, "endOffset": 1843}, {"referenceID": 9, "context": "Previous research on argumentation mining focuses on several sub-tasks, including (1) splitting text into discourse units (DU) (Madnani et al., 2012; Du et al., 2014), (2) identification of ADUs from non-argumentative ones (Moens et al.", "startOffset": 127, "endOffset": 166}, {"referenceID": 2, "context": "Previous research on argumentation mining focuses on several sub-tasks, including (1) splitting text into discourse units (DU) (Madnani et al., 2012; Du et al., 2014), (2) identification of ADUs from non-argumentative ones (Moens et al.", "startOffset": 127, "endOffset": 166}, {"referenceID": 10, "context": ", 2014), (2) identification of ADUs from non-argumentative ones (Moens et al., 2007; Florou et al., 2013), (3) identification of ADU types (Biran and Rambow, 2011; Nguyen and Litman, 2015; Eckle-Kohler et al.", "startOffset": 64, "endOffset": 105}, {"referenceID": 4, "context": ", 2014), (2) identification of ADUs from non-argumentative ones (Moens et al., 2007; Florou et al., 2013), (3) identification of ADU types (Biran and Rambow, 2011; Nguyen and Litman, 2015; Eckle-Kohler et al.", "startOffset": 64, "endOffset": 105}, {"referenceID": 3, "context": ", 2013), (3) identification of ADU types (Biran and Rambow, 2011; Nguyen and Litman, 2015; Eckle-Kohler et al., 2015; Habernal and Gurevych, 2015) and (4) identification of relation between ADUs (Lawrence et al.", "startOffset": 41, "endOffset": 146}, {"referenceID": 8, "context": ", 2015; Habernal and Gurevych, 2015) and (4) identification of relation between ADUs (Lawrence et al., 2014; Stab and Gurevych, 2014b; Peldszus and Stede, 2015b; Kirschner et al., 2015).", "startOffset": 85, "endOffset": 185}, {"referenceID": 7, "context": ", 2015; Habernal and Gurevych, 2015) and (4) identification of relation between ADUs (Lawrence et al., 2014; Stab and Gurevych, 2014b; Peldszus and Stede, 2015b; Kirschner et al., 2015).", "startOffset": 85, "endOffset": 185}, {"referenceID": 2, "context": ", 2012; Du et al., 2014), (2) identification of ADUs from non-argumentative ones (Moens et al., 2007; Florou et al., 2013), (3) identification of ADU types (Biran and Rambow, 2011; Nguyen and Litman, 2015; Eckle-Kohler et al., 2015; Habernal and Gurevych, 2015) and (4) identification of relation between ADUs (Lawrence et al., 2014; Stab and Gurevych, 2014b; Peldszus and Stede, 2015b; Kirschner et al., 2015). We will concentrate on the latter two sub-tasks in this part and introduce some existing joint models. ADU type classification: Stab and Gurevych (2014b) aimed to classify text segments into four classes, namely major claim, claim, premise and non-argumentative for persuasive essays.", "startOffset": 8, "endOffset": 566}, {"referenceID": 2, "context": ", 2012; Du et al., 2014), (2) identification of ADUs from non-argumentative ones (Moens et al., 2007; Florou et al., 2013), (3) identification of ADU types (Biran and Rambow, 2011; Nguyen and Litman, 2015; Eckle-Kohler et al., 2015; Habernal and Gurevych, 2015) and (4) identification of relation between ADUs (Lawrence et al., 2014; Stab and Gurevych, 2014b; Peldszus and Stede, 2015b; Kirschner et al., 2015). We will concentrate on the latter two sub-tasks in this part and introduce some existing joint models. ADU type classification: Stab and Gurevych (2014b) aimed to classify text segments into four classes, namely major claim, claim, premise and non-argumentative for persuasive essays. Based on the same corpus and setting, Nguyen et al. (2015) explored a semi-supervised method for segment type classification.", "startOffset": 8, "endOffset": 756}, {"referenceID": 2, "context": ", 2012; Du et al., 2014), (2) identification of ADUs from non-argumentative ones (Moens et al., 2007; Florou et al., 2013), (3) identification of ADU types (Biran and Rambow, 2011; Nguyen and Litman, 2015; Eckle-Kohler et al., 2015; Habernal and Gurevych, 2015) and (4) identification of relation between ADUs (Lawrence et al., 2014; Stab and Gurevych, 2014b; Peldszus and Stede, 2015b; Kirschner et al., 2015). We will concentrate on the latter two sub-tasks in this part and introduce some existing joint models. ADU type classification: Stab and Gurevych (2014b) aimed to classify text segments into four classes, namely major claim, claim, premise and non-argumentative for persuasive essays. Based on the same corpus and setting, Nguyen et al. (2015) explored a semi-supervised method for segment type classification. They proposed to divide words into argument words and topic words; and deploy a semi-supervised method to generate argument words based on 10 seeding words, and then used them as additional features for classification. Habernal and Gurevych (2015) also focused on developing semi-supervised features.", "startOffset": 8, "endOffset": 1071}, {"referenceID": 2, "context": ", 2012; Du et al., 2014), (2) identification of ADUs from non-argumentative ones (Moens et al., 2007; Florou et al., 2013), (3) identification of ADU types (Biran and Rambow, 2011; Nguyen and Litman, 2015; Eckle-Kohler et al., 2015; Habernal and Gurevych, 2015) and (4) identification of relation between ADUs (Lawrence et al., 2014; Stab and Gurevych, 2014b; Peldszus and Stede, 2015b; Kirschner et al., 2015). We will concentrate on the latter two sub-tasks in this part and introduce some existing joint models. ADU type classification: Stab and Gurevych (2014b) aimed to classify text segments into four classes, namely major claim, claim, premise and non-argumentative for persuasive essays. Based on the same corpus and setting, Nguyen et al. (2015) explored a semi-supervised method for segment type classification. They proposed to divide words into argument words and topic words; and deploy a semi-supervised method to generate argument words based on 10 seeding words, and then used them as additional features for classification. Habernal and Gurevych (2015) also focused on developing semi-supervised features. They exploited clustering of unlabeled data from debate portals based on word embeddings. Some research focused on specific types of ADU identification given its context. Park and Cardie (2014)", "startOffset": 8, "endOffset": 1318}, {"referenceID": 1, "context": "Biran et al. (2011) aimed to identify justifications for claims.", "startOffset": 0, "endOffset": 20}, {"referenceID": 1, "context": "Biran et al. (2011) aimed to identify justifications for claims. Relation identification: There is much less work for relation identification. Palau and Moens (2011) used a hand-written context-free grammar to predict argumentation trees on legal documents.", "startOffset": 0, "endOffset": 166}, {"referenceID": 1, "context": "Biran et al. (2011) aimed to identify justifications for claims. Relation identification: There is much less work for relation identification. Palau and Moens (2011) used a hand-written context-free grammar to predict argumentation trees on legal documents. Kirchner et al. (2015) presented an annotation study for fine-grained analysis of argumentation structures in scientific publications.", "startOffset": 0, "endOffset": 281}, {"referenceID": 1, "context": "Biran et al. (2011) aimed to identify justifications for claims. Relation identification: There is much less work for relation identification. Palau and Moens (2011) used a hand-written context-free grammar to predict argumentation trees on legal documents. Kirchner et al. (2015) presented an annotation study for fine-grained analysis of argumentation structures in scientific publications. For data-driven approaches, Lawrence et al. (2014) constructed tree structures on philosophical texts using unsupervised methods based on topical distance between segments.", "startOffset": 0, "endOffset": 444}, {"referenceID": 1, "context": "Biran et al. (2011) aimed to identify justifications for claims. Relation identification: There is much less work for relation identification. Palau and Moens (2011) used a hand-written context-free grammar to predict argumentation trees on legal documents. Kirchner et al. (2015) presented an annotation study for fine-grained analysis of argumentation structures in scientific publications. For data-driven approaches, Lawrence et al. (2014) constructed tree structures on philosophical texts using unsupervised methods based on topical distance between segments. Stab and Gurevych (2014b) presented a supervised approach for student essays.", "startOffset": 0, "endOffset": 592}, {"referenceID": 1, "context": "Biran et al. (2011) aimed to identify justifications for claims. Relation identification: There is much less work for relation identification. Palau and Moens (2011) used a hand-written context-free grammar to predict argumentation trees on legal documents. Kirchner et al. (2015) presented an annotation study for fine-grained analysis of argumentation structures in scientific publications. For data-driven approaches, Lawrence et al. (2014) constructed tree structures on philosophical texts using unsupervised methods based on topical distance between segments. Stab and Gurevych (2014b) presented a supervised approach for student essays. Peldszus and Stede (2015b) aimed to identify the attachment relation between ADUs on a microtext corpus.", "startOffset": 0, "endOffset": 671}, {"referenceID": 1, "context": "Biran et al. (2011) aimed to identify justifications for claims. Relation identification: There is much less work for relation identification. Palau and Moens (2011) used a hand-written context-free grammar to predict argumentation trees on legal documents. Kirchner et al. (2015) presented an annotation study for fine-grained analysis of argumentation structures in scientific publications. For data-driven approaches, Lawrence et al. (2014) constructed tree structures on philosophical texts using unsupervised methods based on topical distance between segments. Stab and Gurevych (2014b) presented a supervised approach for student essays. Peldszus and Stede (2015b) aimed to identify the attachment relation between ADUs on a microtext corpus. Joint model for argumentation mining: Although there are several approaches for different subtasks in argumentation mining, researchers rarely consider to solve sub-tasks in unified way. Stab and Gurevych (2014b) explored to directly use the prediction results of ADU type classification as features for the task of relation classification, however, without considering logical relation between these two tasks, the effect was marginal.", "startOffset": 0, "endOffset": 962}, {"referenceID": 1, "context": "Biran et al. (2011) aimed to identify justifications for claims. Relation identification: There is much less work for relation identification. Palau and Moens (2011) used a hand-written context-free grammar to predict argumentation trees on legal documents. Kirchner et al. (2015) presented an annotation study for fine-grained analysis of argumentation structures in scientific publications. For data-driven approaches, Lawrence et al. (2014) constructed tree structures on philosophical texts using unsupervised methods based on topical distance between segments. Stab and Gurevych (2014b) presented a supervised approach for student essays. Peldszus and Stede (2015b) aimed to identify the attachment relation between ADUs on a microtext corpus. Joint model for argumentation mining: Although there are several approaches for different subtasks in argumentation mining, researchers rarely consider to solve sub-tasks in unified way. Stab and Gurevych (2014b) explored to directly use the prediction results of ADU type classification as features for the task of relation classification, however, without considering logical relation between these two tasks, the effect was marginal. Peldszus and Stede (2015b) tackled four argumentation mining tasks including three ADU type classification tasks and the task of relation identification.", "startOffset": 0, "endOffset": 1213}, {"referenceID": 5, "context": "The corpus is annotated according to a scheme representing segment-level argumentation structure (Freeman, 1991).", "startOffset": 97, "endOffset": 112}], "year": 2017, "abstractText": "For argumentation mining, there are several sub-tasks such as argumentation component type classification, relation classification. Existing research tends to solve such sub-tasks separately, but ignore the close relation between them. In this paper, we present a joint framework incorporating logical relation between sub-tasks to improve the performance of argumentation structure generation. We design an objective function to combine the predictions from individual models for each sub-task and solve the problem with some constraints constructed from background knowledge. We evaluate our proposed model on two public corpora and the experiment results show that our model can outperform the baseline that uses a separate model significantly for each sub-task. Our model also shows advantages on component-related sub-tasks compared to a state-of-the-art joint model based on the evidence graph.", "creator": "LaTeX with hyperref package"}}}