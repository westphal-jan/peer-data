{"id": "1702.00539", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Feb-2017", "title": "Procedural Content Generation via Machine Learning (PCGML)", "abstract": "This survey relates Procedural Content Generation where Machine Learning (PCGML ), defined however there true now finished uses using laptop learning smaller training at existing generated. As same openness such PCG on finals development limit, researchers learning new piazzas be capacity high - quality content with. without believes involvement; possible covering references its otherwise it standpoint example using machine learning (while unusually also sites - institute, solver - largest, still relations application ). We programs on what actually most and considered three-dimensional game software can as masterful measured, midway accessed, interactive fiction names, taking pins in merchandise card start, most conservatives to specialty such though all sprites those sound generated. In same eventually certain PCG same autonomous generation, sam - advancement, contrast - pursue \u2019s, addition compression, PCGML although rather one repair, critique, with mix analysis none of its emphasize on conceptual companies context. We discuss throughout monitoring also especially identifiable that affect created affected generated content. Multiple PCGML particular or parts, years replication networks, cut through - exception memory (LSTM) wireless, autoencoders, or out convolutional segments; Markov models, $ \u03b3 $ - 70, instead main - dimensional Markov lining; failover; are corresponding divisors. Finally, we resolve at arise held one procedure important PCGML, involved experience from it multi-dimensional, lack with trainers data, holds - gauzy better, style - phase, matrices pythagorean, example PCG as a pitching homemaker.", "histories": [["v1", "Thu, 2 Feb 2017 04:49:22 GMT  (1406kb,D)", "http://arxiv.org/abs/1702.00539v1", null], ["v2", "Wed, 16 Aug 2017 11:50:28 GMT  (1785kb,D)", "http://arxiv.org/abs/1702.00539v2", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["adam summerville", "sam snodgrass", "matthew guzdial", "christoffer holmg{\\aa}rd", "amy k hoover", "aaron isaksen", "y nealen", "julian togelius"], "accepted": false, "id": "1702.00539"}, "pdf": {"name": "1702.00539.pdf", "metadata": {"source": "CRF", "title": "Procedural Content Generation via Machine Learning (PCGML)", "authors": ["Adam Summerville", "Sam Snodgrass", "Matthew Guzdial", "Christoffer Holmg\u00e5rd", "Amy K. Hoover", "Aaron Isaksen", "Andy Nealen", "Julian Togelius"], "emails": ["asummerv@ucsc.edu,", "sps74@drexel.edu,", "mguzdial3@gatech.edu,", "christoffer@holmgard.org,", "amy.hoover@gmail.com,", "aisaksen@appabove.com,", "nealen@nyu.edu,", "julian@togelius.com"], "sections": [{"heading": null, "text": "1 Procedural Content Generation via Machine Learning (PCGML)\nAdam Summerville1, Sam Snodgrass2, Matthew Guzdial3, Christoffer Holmg\u00e5rd4, Amy K. Hoover5, Aaron Isaksen6, Andy Nealen6, and Julian Togelius6,\n1Department of Computational Media, University of California, Santa Cruz, CA 95064, USA 2College of Computing and Informatics, Drexel University, Philadelpia, PA 19104, USA\n3School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA 30332, USA 4Duck and Cover Games ApS, 1311 Copenhagen K, Denmark\n5College of Arts, Media and Design, Northeastern University, Boston, MA 02115, USA 6Department of Computer Science and Engineering, New York University, Brooklyn, NY 11201, USA\nemails: asummerv@ucsc.edu, sps74@drexel.edu, mguzdial3@gatech.edu, christoffer@holmgard.org, amy.hoover@gmail.com, aisaksen@appabove.com, nealen@nyu.edu, julian@togelius.com\nThis survey explores Procedural Content Generation via Machine Learning (PCGML), defined as the generation of game content using machine learning models trained on existing content. As the importance of PCG for game development increases, researchers explore new avenues for generating high-quality content with or without human involvement; this paper addresses the relatively new paradigm of using machine learning (in contrast with search-based, solver-based, and constructive methods). We focus on what is most often considered functional game content such as platformer levels, game maps, interactive fiction stories, and cards in collectible card games, as opposed to cosmetic content such as sprites and sound effects. In addition to using PCG for autonomous generation, co-creativity, mixed-initiative design, and compression, PCGML is suited for repair, critique, and content analysis because of its focus on modeling existing content. We discuss various data sources and representations that affect the resulting generated content. Multiple PCGML methods are covered, including neural networks, long short-term memory (LSTM) networks, autoencoders, and deep convolutional networks; Markov models, n-grams, and multi-dimensional Markov chains; clustering; and matrix factorization. Finally, we discuss open problems in the application of PCGML, including learning from small datasets, lack of training data, multi-layered learning, style-transfer, parameter tuning, and PCG as a game mechanic.\nIndex Terms\u2014Computational and artificial intelligence, Machine learning, Procedural Content Generation, Knowledge representation, Pattern analysis, Electronic design methodology, Design tools\nI. INTRODUCTION\nProcedural content generation (PCG), the creation of game content through algorithmic means, has become increasingly prominent within both game development and technical games research. It is employed to increase replay value, reduce production cost and effort, to save storage space, or simply as an aesthetic in itself. Academic PCG research addresses these challenges, but also explores how PCG can enable new types of game experiences, including games that can adapt to the player. Researchers also addresses challenges in computational creativity and ways of increasing our understanding of game design through building formal models [1].\nIn the games industry, many applications of PCG are what could be called \u201cconstructive\u201d methods, using grammars or noise-based algorithms to create content in a pipeline without evaluation. Many techniques use either search-based methods [2] (for example using evolutionary algorithms) or solverbased methods [3] to generate content in settings that maximize objectives and/or preserve constraints.\nWhat these methods have in common is that the algorithms, parameters, constraints, and objectives that create the content are in general hand-crafted by designers or researchers. While common to examine existing game content for inspiration, so far machine learning methods have far less commonly been used to extract data from existing game content in order to create more content.\nConcurrently, there has been an explosion in the use of machine learning to train models based on datasets [4]. In particular, the resurgence of neural networks under the name deep learning has precipitated a massive increase in the capabilities and application of methods for learning models from big data [5], [6]. Deep learning has been used for a variety of tasks in machine learning, including the generation of content.\nFor example, generative adversarial networks have been applied to generating artifacts such as images, music, and speech [7]. But many other machine learning methods can also be utilized in a generative role, including n-grams, Markov\nar X\niv :1\n70 2.\n00 53\n9v 1\n[ cs\n.A I]\n2 F\neb 2\n01 7\n2 models, autoencoders, and others [8], [9], [10]. The basic idea is to train a model on instances sampled from some distribution, and then use this model to produce new samples.\nThis paper is about the nascent idea and practice of generating game content from machine-learned models. We define Procedural Content Generation via Machine Learning (abbreviated PCGML) as the generation of game content using models that have been trained on existing game content. These models could be of many different kinds and trained using very different training algorithms, including neural networks, probabilistic models, decision trees, and others. The generation could be partial or complete, autonomous, interactive, or guided. The content could be almost anything in a game, such as levels, maps, items, weapons, quests, characters, rules, etc.\nThis paper is focused on game content that is directly related to game mechanics. In other words, we focus on functional rather than cosmetic game content. We define functional content as artifacts that, if they were changed, could alter the in-game effects of a sequence of player actions. The main types of cosmetic game content that we exclude are textures and sound, as those do not directly impact the effects of in-game actions the way levels or rules do in most games, and there is already much research on the generation of such content outside of games [11], [12]. This not a value judgment, and cosmetic content is extremely important in games; however, it is not the focus of this paper.\nIt is important to note a key difference between game content generation and procedural generation in many other domains: most game content has strict structural constraints to ensure playability. These constraints differ from the structural constraints of text or music because of the need to play games in order to experience them. Where images, sounds, and in many ways also text can be consumed statically, games are dynamic and must be evaluated through interaction that requires non-trivial effort\u2014in Aarseth\u2019s terminology, games are ergodic media [13]. A level that structurally prevents players from finishing it is not a good level, even if it\u2019s visually attractive; a strategy game map with a strategy-breaking shortcut will not be played even if it has interesting features; a gamebreaking card in a collectible card game is merely a curiosity; and so on. Thus, the domain of game content generation poses different challenges from that of other generative domains. Of course, there are many other types of content in other domains which pose different, and in some sense more difficult challenges, such as lifelike and beautiful images or evocative musical pieces; however, in this paper we focus on the challenges posed by game content by virtue of its necessity for interaction.\nThe remainder of this paper is structured as fol-\nlows. Section II describes the various use cases for PCG via machine learning, including various types of generation and uses of the learned models for purposes that are not strictly generative. Section III discusses the key problem of data acquisition and the recurring problem of small datasets. Section IV includes a large number of examples of PCGML approaches. As we will see, there is already a large diversity of methodological approaches, but only a limited number of domains have been attempted. In Section V, we outline a number of important open problems in research and application of PCGML."}, {"heading": "II. USE CASES FOR PCGML", "text": "Procedural Content Generation via Machine Learning shares many uses with other forms of PCG: in particular, autonomous generation, cocreation/mixed initiative design, and data compression. However, because it has been trained on existing content, it can also extend into new use areas, such as repair and critique/analysis of new content.\nA. Autonomous Generation\nThe most straightforward application of PCGML is autonomous PCG: the generation of complete game artifacts without human input at the time of generation. Autonomous generation is particularly useful when online content generation is needed, such as in rogue-like games which require runtime level generation.\nPCGML is well-suited for autonomous generation because the input to the system can be examples of representative content specified in the content domain. With search-based PCG using a generateand-test framework, a programmer must specify an algorithm for generating the content and an evaluation function that can validate the fitness of the new artifact [14]. However, these are rarely coded in the same space as the output artifact, requiring the designer to use a different domain to express their ideas. With PCGML, a designer can create a set of representative artifacts in the target domain as a model for the generator, and then the algorithm can generate new content in this style. PCGML avoids the complicated step of experts having to design specific algorithms to create a particular type of content.\nB. Co-creative and Mixed-initiative Design\nA more compelling use case for PCGML is AIassisted design, where a human designer and an algorithm work together to create content. This approach has previously been explored with other methods such as constraint satisfaction algorithms and evolutionary algorithms [15], [16], [17].\n3 Again, because the designer can train the machinelearning algorithm by providing examples in the target domain, the designer is \u201cspeaking the same language\u201d the algorithm requires for input and output. This has the potential to reduce frustration, user error, user training time, and lower the barrier to entry because a programming language is not required to specify generation or acceptance criteria.\nBecause PCGML algorithms are provided with example data, they are suited to auto-complete game content that is partially specified by the designer. Within the image domain, we have seen work on image inpainting, where a neural network is trained to complete images where parts are missing [18]. Similarly, machine learning methods could be trained to complete game content with parts missing.\nC. Repair\nWith a library of existing representative content, PCGML algorithms can identify areas that are not playable (e.g. if an unplayable level or impossible rule set has been specified) and also offer suggestions for how to fix them. Summerville and Mateas [19] use a special tile that represents where an AI would choose to move the player in their training set, so that the algorithm only generates playable content; the system inherently has learned the difference between passable and impassable terrain. Jain et. al. [20] used a sliding window and an autoencoder to repair illegal level segments \u2013 because they did not appear in the training set, the autoencoder replaced them with a nearby window it had seen during training.\nD. Recognition, Critique, and Analysis\nA use case for PCGML that sets it apart from other PCG approaches is its capacity for recognition, analysis and critique of game content. Given the basic idea of PCGML is to train some kind of model on sets of existing game content, these models could be applied to analyzing other game content, whether created by an algorithm, players, or designers.\nFor example, by supervised training on sets of game content artifacts and player response data, machine learning models can be trained to classify game content into various types, such as broken or whole, underworld or overworld, etc. They can also be trained to predict quantities such as difficulty, completion time, or emotional tenor [21], [22]. They also have the potential to identify uniqueness, for example by noting how common a particular pattern appears in the training set, or judging how typical a complete content artifact (such as a level) is with regard to an existing set. Being able to identify which user-created levels are truly novel, and then enhance them further so as to fit with\nthe aesthetics of the game and repair broken parts, could be very useful. Such models could also be used to automatically evaluate game content, as is already done within many applications of searchbased PCG, and potentially be used together with other generative methods.\nE. Data Compression\nOne of the original motivations for PCG, particularly in early games such as Elite [23], was data compression. There was simply not enough space on disk for the whole game universe. The same is true for some of today\u2019s games such as No Man\u2019s Sky [24]. The compression of game data into fewer dimensions through machine learning could allow more efficient game content storage. By exploiting the regularities of a large number of content instances, we can store the distinctive features of each more cheaply. Unsupervised learning methods such as autoencoders might be particularly well suited to this.\nIII. DATA SOURCES AND REPRESENTATIONS\nIn this section we investigate how training data, varying in source, quality, and representation, can impact PCGML work.\nA. Data Sources\nA commonly held view in the machine learning community is that more data is better. Halevy, et al. [25] make the case that having access to more data, not better algorithms or better data, is the key difference between why some problems are able to be solved in an effective manner with machine learning while others are not (e.g., language translation is a much harder problem than document classification, but more data exists for the translation task). For some types of machine learning a surfeit of data exists enabling certain techniques, such as images for generative adversarial networks [26] or text for Long Short-Term Memory recurrent neural networks (LSTMs) [27]; However, video games do not have this luxury. While many games exist, they typically share no common data structures. Additionally, even if they do they typically do not share semantics (e.g., sprites in the NES share similarity in how they are displayed but sprite 0x01 is unlikely to have similar semantics between Super Mario Bros. [28] and Metroid [29], despite the fact that both are platformers). As such, data sources are often limited to within a game series [30], [19] and more commonly within individual games [31], [32], [33]. This in turn means that data scarcity is likely to plague PCGML for the foreseeable future, as there are a small, finite number of official maps for most games. However, for many games there are vibrant fan communities producing hundreds,\n4 thousands, and even millions of maps [34], which could conceivably provide much larger data sources.\nRecently, Summerville et al. created the video game level corpus (VGLC) [35], a collection of video game levels represented in several easily parseable formats. The corpus contains 428 levels from 12 games in 3 different file formats. This effort marks an initial step in creating a shared data source that can be used for commonality across PCGML research. That being said, the repository is limited in scale (12 games and 428 levels being small on the standard machine learning front) and the representations are lossy (e.g., in Mario, levels only contain a single Enemy type mapping for all Goombas, Koopa Troopas, etc.), so additional effort is needed to increase the scope and fidelity of the representations.\nAssuming bountiful data existed for video games, bigger questions abound: 1) How should the data be represented? 2) What is a training instance? For certain classes of PCGML, such as the aforementioned image generation, obvious data structures exist (e.g., RGB matrices), but there are no common structures for games. Games are a combination of some amount of content (levels, images, 3-D models, text, boards, pieces, etc.) and the rules that govern them (What happens when input x is held down in state y? What happens if z is clicked on? Can player \u03b1 move piece p? etc.). Furthermore, the content is often dynamic during playtime, so even if the content were to capture with perfect fidelity (e.g., a Goomba starts at tile X,Y ) how it will affect gameplay requires play (e.g., by the time the player can see the Goomba it has moved to tile X \u2032, Y \u2032). Thus, issues of representation serve as a second major challenge, after access to sufficient quantities of quality data.\nB. Data Representation Example: Mario Levels\nWe next look at Super Mario Bros. levels as a case study in the importance of data representation in PCGML. Super Mario Bros. levels have been one of the most successful venues for PCGML research, with many of these prior approaches having distinct representations, with individual affordances and limitations. These can be divided according to two features: how the units of the representation are arranged (one or two-dimensional representations) and the atomic unit of the representation (tiles, voices, shapes).\nTwo-dimensional representations of Super Mario Bros. levels parallel the two-dimensional spatial relationships in the game. However, a two-dimensional representation limits the types of machine learning techniques that can be applied. Therefore the majority of PCGML approaches structure levels as one-dimensional sequences, meaning that the\noriginal two-dimensional level must be transformed according to some function.\nMost simply this involves iterating over the data from left-to-right then top-to-bottom [20], however depending on the technique, this can obfuscate spatial relationships. This loss can be mitigated, for example [19] utilizes a \u201csnaking\u201d path while [36] represents vertical and horizontal relations by splitting two-dimensional maps into one-dimensional sequences of columns.\nSuper Mario Bros. stores its levels in a grid of \u201csprites,\u201d a predefined set of 16 pixel square images that can be tiled to create larger shapes. Many of these sprites represent the same in-game function such as \u201csolid blocks\u201d or \u201cenemies,\u201d which tilebased representations take advantage of. In a tilebased representation, the low-level sprites of the game are classified into a higher order representation based on gameplay function (e.g. all enemies classified as an \u201cenemy\" type). This improves learning by cutting down on variance, which is important in cases of PCGML due to the limited size of the training set. However this representation requires hand-authored rules to transform from higher order tiles to sprites after generation.\nWhile tile-based representations have been the most popular thus far, we highlight two alternatives. Voices-based representations as in [36] similarly separate sprites by function, with similar drawbacks, but rely on a musical metaphor to categorize sprites according to voices based on gameplay function. Shape-based representations as in [33] instead use the game\u2019s original sprites as their atomic unit, categorizing the various shapes they are arranged into, which therefore requires no processing after generation. However this representation limits the types of machine learning approaches that can be applied.\nPCGML has been largely limited to the representation of video game levels thus far, impacting the types of data source and representation approaches that we\u2019ve seen. However, we note that PCGML has promise to address many other elements of video games, along with entire games themselves. We expect that future PCGML approaches will still struggle with issues of data sources and data representations, which will in turn restrict the underlying machine learning approaches.\nC. Non-level Content\nThe majority of PCGML work thus far, and the majority covered in this paper, focuses on generating individual game levels. However, PCGML can apply to all types of game content, including mechanics, stories, quests, NPCS, and even full games. We note two examples covered in this paper: Magic/Hearthstone card generation [37] and interactive narrative/story generation [38]. The\n5 former shares a framework with much of the level generation work, relying on a fan-made corpus of game content. The latter relies on crowdsourcing its training data, given the lack of a general, formal story representation. We expect either of these strategies could find success in other types of PCGML content generation."}, {"heading": "IV. METHODS OF PCGML", "text": "We classify procedural content generation approaches that employ machine learning techniques (PCGML) using two axes: method, the machine learning approach that is used; and content, the type of content that is generated. In this section, we discuss various PCGML techniques, grouped by method. We start with neural networks, because of the recent uptake in PCGML approaches employing neural networks. We then discuss Markov models, which have been explored in the context of platformer game level generation. Next we cover clustering-based approaches that have been used to model and generate platformer levels as well as interactive stories. Afterwards, we discuss matrix factorization techniques for generating platformer and action role-playing game levels. We close the section with an explanation of a wave function collapse approach.\nA. Artificial Neural Networks\nRecently neural networks have been used in the context of generating images [40], [41] and learning to play games [42], [43], [44] with great success. Unsurprisingly, neural networks are also being explored in PCG for level and map generation as well as cooperative trading card generation.\n1) Function Scaffolding for Mario Levels Hoover et al. [36] generate levels for Super Mario Bros. by extending a representation called functional scaffolding for musical composition (FSMC) that was originally developed to compose music. The original FSMC representation posits 1) music can be represented as a function of time and 2) musical voices in a given piece are functionally related [45]. Through a method for evolving artificial neural networks (ANNs) called NeuroEvolution of Augmenting Topologies (NEAT) [39], additional musical voices are then evolved to be played simultaneously with an original human-composed voice.\nTo extend this musical metaphor and represent Super Mario Bros. levels as functions of time, each level is broken down into a sequence of columns with a tile-sized width. The height of each column extends the height of the screen. While FSMC represents a unit of time by the length of an eighthnote, a unit of time in this approach is width of each column.\nAt each unit of time, the system queries the ANN to decide at what height to place a tile. FSMC inputs\na musical note\u2019s pitch and duration to the ANNs, this approach translates pitch to the height at which a tile is placed and duration to the number of times a tile-type is repeated at that height. For a given tile-type or musical voice, this information is then input to an ANN that is trained on two-thirds of the existing human-authored levels to predict the value of a tile-type at each column (as shown in Figure 1). The idea is that the ANN will learn hidden relationships between the tile-types in the humanauthored levels that can then help humans construct entire levels from as little starting information as the layout of a single tile-type.\nLike in FSMC, this approach combines a minimal amount of human-authored content with the output from previous iterations. The output of the network is added to the newly created level and fed back as input into the generation of new tile layouts. By acknowledging and iterating on the relationships between design pieces inherent in a human-produced level, this method can generate maps that both adhere to some important aspects of level design while deviating from others in novel ways.\n2) LSTMs for Mario Levels Summerville and Mateas [19] used Long ShortTerm Memory Recurrent Neural Networks (LSTM RNNs) [46] to generate levels learned from a tile representation of Super Mario Bros. and Super Mario Bros. 2 (JP) [47] levels. LSTMs are a variant of RNNs that represent the current state-of-the-art for sequence based tasks, able to hold information for 100\u2019s and 1000\u2019s of time steps, unlike the 5-6 of standard of RNNs. Summerville and Matteas used a tile representation like the one used by Snodgrass and Onta\u00f1\u00f3n [48], but instead of representing levels as 2-D arrays they represent them as a linear string with 3 different representations used for experimentation. They also included simulated player path information in the input data, forcing the generator to generate exemplar paths in addition to the level geometry. Finally, they included information about how deep into the string the level geometry was, causing the generator to learn both level progression and when a level should end.\nSummerville et al. [49] extended this work to incorporate actual player paths extracted from 4 different YouTube playthroughs. The incorporation of a specific player\u2019s paths biased the generators to generate content suited to that player (e.g., the player that went out of their way to collect every coin and question-mark block had more coins and question-marks in their generated levels).\n3) Autoencoders for Mario Levels In [20] Jain, Isaksen, Holmg\u00e5rd and Togelius show how autoencoders [50] may be trained to reproduce levels from the original Super Mario Bros. game. The autoencoders are trained on series of vertical level windows and compress the typical\nfeatures of Mario levels into a more general representation. They experimented with the width of the level windows and found that four tiles seems to work best for Mario levels. They proceeded to use these networks to discriminate generated levels from original levels, and to generate new levels as transformation from noise. They also demonstrated how a trained autoencoder may be used to repair unplayable levels, changing tile-level features to make levels playable, by inputting a broken/unplayable level to the autoencoder and receiving a repaired one as output (see Figure 3).\n4) Deep Nets for StarCraft II Lee, Isaksen, Holmg\u00e5rd and Togelius [51] use convolutional neural networks to predict resource locations in maps for StarCraft II [52]. Resource\nlocations are sparsely represented in StarCraft II maps, but are decisive in shaping gameplay. They are usually placed to match the topology of maps. Exploiting this fact, they transform StarCraft II maps into heightmaps, downsample them, and train deep neural networks to predict resource locations. The neural networks are shown to perform well in some cases, but struggled in other cases, most likely due to overfitting owing to a small training dataset. By adding a number of postprocessing steps to the network, the authors created a tool that allows map designers to vary the amount of resource locations in an automatically decorated map, varying the frequency of mineral placements, shown in Figure 4.\n5) LSTM Generation of Magic Cards A rare example of game content generation that is not a level generator is Magic: The Gathering [53] card generation. The first to use a machine learning approach for this is Morgan Milewicz\n7\nwith @RoboRosewater [54] a twitter bot that uses LSTMs to generate cards. Trained on the entirety of the corpus of Magic cards it generates cards, represented as a sequence of text fields (e.g., Cost, Name, Type, etc.). A limitation of this representation and technique is that by treating cards as a sequence there is no way to condition generation of cards on fields that occur later in the sequence (e.g., Cost occurs near the end of the sequence and as such can not be used to condition the generation unless all previous fields are specified).\n6) Sequence-to-Sequence Magic Card Creation Building on the work of @RoboRosewater is Mystical Tutor by Summerville and Mateas [37]. Using sequence-to-sequence learning [55], wherein an encoding LSTM encodes an input sequence into a fixed length vector which is then decoded by a decoder LSTM, they trained on the corpus of Magic: The Gathering. They corrupted the input sequences by replacing lines of text with a MISSING token and then tried to reproduce the original cards as the output sequence. The corruption of the input along with the sequence-to-sequence architecture allows the generator to be conditioned on any\npiece of the card, addressing one of the limitations of @RoboRosewater. This work shows multiple different paradigms for PCGML, showing how it can be used on different game content and as a co-creative design assistant, as in Hoover et al.\u2019s [36] previously mentioned work.\nB. Markov Models\nMarkov models are stochastic models that model changes in a system over time, where the current state of the system depends on the previous state. This type of model lends itself easily to modeling levels for games that have a directional trend, such as Super Mario Bros. and Kid Icarus [56], where the \u201ctime\u201d of the system relates to the position in the level.\n1) n-grams for Mario Levels Perhaps the simplest possible Markov models are n-gram models. An n-gram model (or n-gram for short) is simply an n-dimensional array, where the probability of each character is determined by the n characters that precede it. Training an n-gram consists of scanning a set of strings and calculating the conditional probability of each character.\nDahlskog et al. trained n-gram models on the levels of the original Super Mario Bros. game, and used these models to generate new levels [31]. As n-gram models are fundamentally one-dimensional, these levels needed to be converted to strings in order for n-grams to be applicable. This was done through dividing the levels into vertical \u201cslices,\u201d where most slices recur many times throughout the level [57]. This representational trick is dependent on there being a large amount of redundancy in the level design, something that is true in many games. Models were trained using various levels of n, and it was observed that while n = 0 create essentially random structures and n = 1 create barely playable levels, n = 2 and n = 3 create rather well-shaped levels. See Figure 6 for examples of this.\n2) Multi-dimensional Markov Chains for Levels In [48] Snodgrass and Onta\u00f1\u00f3n present an approach to level generation using multi-dimensional Markov chains (MdMCs) [58]. An MdMC differs from a standard Markov chain in that it allows for dependencies in multiple directions and from multiple\n8 (a) n = 1\n(b) n = 2\n(c) n = 3\nFigure 6: Mario levels reconstructed by n-grams with n set to 1, 2, and 3 respectively.\nstates, whereas a standard Markov chain only allows for dependence on the previous state alone. In their work, Snodgrass and Onta\u00f1\u00f3n represent video game levels as 2-D arrays of tiles representing features in the levels. For example, in Super Mario Bros. they use tiles representing the ground, enemies, and ?-blocks, etc. These tile types are used as the states in the MdMC. That is, the type of the next tile is dependent upon the types of surrounding tiles, given the network structure of the MdMC (i.e., the states that the current state\u2019s value depends on).\nIn order to generate levels, first the model must be trained. They train an MdMC by building a probability table according to the frequency of the tiles in training data, given the network structure of the MdMC, the set of training levels, and the set of tile types. A new level is then sampled one tile at a time by probabilistically choosing the next tile based upon the types of the previous tiles and the learned probability table.\nIn addition to their standard MdMC approach, Snodgrass and Onta\u00f1\u00f3n have explored hierarchical [32] and constrained [59] extensions to MdMCs in order to capture higher level structures and ensure usability of the sampled levels, respectively. They have also developed a Markov random field approach (MRF) [60] that performed better than the standard MdMC model in Kid Icarus, a domain where platform placement is pivotal to playability.\nFigure 7 shows a section of a Super Mario Bros. level (top) and a section of a Kid Icarus level (bottom-left) sampled using a constrained MdMC approach, and a section of Kid Icarus level (bottomright) sampled using the MRF approach.\n3) Wave Function Collapse A recent approach by Gumin [61] leverages concepts from quantum mechanics in order to generate images and levels from a representative example tile set. Specifically, he created a wave function collapse algorithm that takes a set of representative level sections and generates new levels that are locally similar to the input. That is, each N\u00d7N window in the output appears in the\nFigure 7: Sections from a Super Mario Bros. level (top) and a Kid Icarus level (bottom left) generated using the constrained MdMC approach, and a Kid Icarus level generated using an MRF approach (bottom right).\ninput, and the distribution of each N\u00d7N window in the output is similar to the distribution in the input, where N is chosen prior to generation, typically based on the patterns present in the training data.\nThis wave function collapse algorithm is particularly exciting, because it is able to produce high-quality results with a single training example. The algorithm works by initializing a level to superpositions of possible N \u00d7 N windows from the input. It then chooses a position among those with the lowest entropy, and collapses it (i.e., sets it probabilistically according to the distribution of windows in the input and the possible windows for that position). The entropy for the rest of the level is updated accordingly. This process is repeated until all of the positions in the output have been collapsed. This approach is a variant of MdMC, except instead of sampling based on a geometric pattern (e.g. leftto-right, bottom-to-top), samples are chosen via the\n9 aforementioned entropy methodology. This approach was initially explored for bitmap generation, but has since been expanded for use with 3-D tile sets as well as for level generation [62], [63]. The source code and examples of the bitmap project can be found online [61].\nC. Clustering\nClustering is a category of machine learning approaches that attempt to group similar elements together in order to learn their relationships. Below we discuss an approach that uses clustering to learn grammars and graphs for level and story generation, respectively.\n1) Learning Mario Levels from Video In [33] Guzdial and Riedl utilized gameplay video of individuals playing through Super Mario Bros. to generate new levels. They accomplished this by parsing each Super Mario Bros. gameplay video frame-by-frame with OpenCV [64] and a fanauthored spritesheet, a collection of each image that appears in the game (referred to as sprites). Individual parsed frames could then combine to form chunks of level geometry, which served as the input to the model construction process. In total Guzdial and Riedl made use of nine gameplay videos for their work with Super Mario Bros., roughly 4 hours of gameplay in total.\nGuzdial and Riedl\u2019s model structure was adapted from [65], a graph structure meant to encode styles of shapes and their probabilistic relationships. The shapes in this case refer to collections of identical sprites tiled over space in different configurations. For further details please see [33], but it can be understood as a learned shape grammar, identifying individual shapes and probabilistic rules on how to combine them. To train this model Guzdial and Riedl used a hierarchical clustering approach utilizing K-means clustering with automatic K estimation. First the chunks of level geometry were clustered to derive styles of level chunks, then the shapes within that chunk were clustered again to derive styles of shapes, and lastly the styles of shapes were clustered to determine how they could be combined to form\nnovel chunks of level. After this point generating a new level requires generating novel level chunks in sequences derived from the gameplay videos. An example screen of generated content using this approach is shown in Figure 8.\n2) Scheherazade-IF: General Interactive Fiction PCGML has focused on graphical games, and particularly the levels of graphical games. However, there exists some work in the field of generating interactive fiction, text-based games like choose your own adventure stories. Guzdial et al. adapted Scheherazade [66], a system for automatically learning to generate stories, into Scheherazade-IF [38], which can derive entire interactive fiction games from a dataset of stories.\nBoth Scheherazades rely on exemplar stories crowdsourced from Amazon Mechanical Turk (AMT). The reliance on crowdsourcing rather than finding stories \"in the wild\" allows Scheherazade to collect linguistically simple stories and stories related to a particular genre or setting (e.g., a bank robbery, a movie date, etc).\nScheherazade-IF\u2019s structures its model in the form of plot graphs [67], directed graphs with events as vertices and sequentiality information encoded as edges. The system derives events from the individual sentences of the story, learning what events can occur via an adaption of the OPTICS clustering algorithm [68]. The ordering of these primitive events can then be derived from the exemplar stories, which then enables the construction of a plot graph for each type of story (e.g., bank robbery). Scheherazade-IF uses these learned plot graphs as the basis for an interactive narrative experience, allowing players to take the role of any of the characters in the plot graph (robber or bank teller in bank robbery) and making choices based on the possible sequences of learned events.\nD. Matrix Factorization\nMatrix factorization is a way of extracting latent features from high-dimensional data. These techniques have been explored (below) in the context of learning from level data and learning from other level generators.\n1) Bayes Nets and PCA for Zelda Levels While platformers, specifically Super Mario Bros., have dominated the field, Summerville et al. [30]\n10\n[69] have generated levels learned from The Legend of Zelda [70] series. Combining different approaches for the content, they split the generation process into two domains. The first is the dungeon level wherein the base topology of a dungeon is generated in a graph structure. The room-to-room structure of a dungeon is learned along with high level parameters such as dungeon size and length of the optimal player path using a Bayes Net [71], a graphical structure of the joint probability distribution.\nAfter generating the topological structure of a dungeon, they then use Principal Component Analysis (PCA) to generate the low-level tile representations of the individual rooms. PCA finds a compressed representation of the original 2-D room arrays by taking the eigenvectors of the original high dimensional space and only keeping the most informative, in this work only keeping the top 20 most informative accounting for 95% of all variation. These compressed representations are then represented as weight vectors that can be interpolated between to generate new room content as seen in Figure 10.\n2) Matrix Factorization for Level Generation Many generators (both machine and human) create in a particular identifiable style with a limited expressive range [72]. Shaker and Abou-Zleikha [73] use Non-Negative Matrix Factorization (NNMF) to learn patterns from 5 unique non-ML-based unique generators of Super Mario Bros. levels (Notch, Parameterized, Grammatical Evolution, Launchpad, and Hopper), to create a wider variety of content than any of the single methods. To their knowledge, this is the first time that NNMF has been used to generate content. Because NNMF requires only non-negative values in its matrix decomposition, the basis representations are localized and purely additive, and they are therefore more intuitive to analyze than PCA.\nTheir system begins by generating 1000 levels of length 200 with each of the G = 5 unique generators. These 5000 levels in the training set are represented as vectors recording the locations or amount of T = 5 content types at each level column: Platforms, Hills, Gaps, Items, and Enemies. These vectors are combined into T matrices, one for each level content type. The algorithm then uses a multiplicative update NNMF algorithm [74] to factor the data matrices into T approximate \u201cpart matrices\u201d which represent level patterns and T coefficient matrices corresponding to weights for each pattern that appear in the training set. The part matrices can be examined to see what types of patterns appear globally and uniquely in different generators, and multiplying these part matrices by novel coefficient vectors can be used to generate new levels. This allows the NNMF method to explore far outside the expressive range of the original generators."}, {"heading": "V. OPEN PROBLEMS AND OUTLOOK", "text": "In this section, we describe some of the major issues facing PCGML and open areas for active research. Because games as a ML research domain are considerably different from other ML domains, such as vision and audio learning, the problems that arise are commensurately different. In particular, game datasets are typically much smaller than other domains\u2019 datasets, they are dynamic systems that rely on interaction, and the availability of high-quality clean data is limited. In the following sections we discuss the issue of limited data as well as underexplored applications of PCGML for games includes style transfer, parameter tuning, and potential PCGML game mechanics.\nA. Learning from Small Datasets\nAs previously mentioned, it is a commonly held tenet that more data is better; However, games are likely to always be data-constrained. The English Gigaword corpus [75] which has been used in over 450 papers at the time of writing is approximately 27 GB. The entire library of games for the Nintendo Entertainment System is approximately 237 MB, over 2 orders of magnitude smaller. The most common genre, platformers, makes up approximately 14% of the NES library (and is the most common genre for PCG research) which is roughly another order of magnitude smaller. For specific series it is even worse, with the largest series (Mega Man [76]) making up 0.8% of the NES library, for 4 orders of magnitude smaller than a standard language corpus. Standard image corpora are even larger than the Gigaword corpus, such as the ImageNet corpus [77] at 155GB. All told, work in this area is always going to be constrained by the amount of data, even if more work is put into creating larger, better corpora.\nWhile most machine learning is focused on using large corpora, there is work in the field focused on One-Shot Learning/Generalization [78]. Humans have the ability to generalize very quickly after being shown a single (or very small set, e.g., n < 5) object to other objects of the same type, and OneShot Learning is similarly concerned with learning from a very small dataset. Most of the work has been focused on image classification, but games are a natural testbed for such techniques due to the paucity of data."}, {"heading": "B. Learning on Different Levels of Abstraction", "text": "As described above, one key challenge that sets PCGML for games apart from PCGML for domains such as images or sound is the fact that games are multi-modal dynamic systems. This means that content generated will have interactions: generated rules operate on generated levels which in turn change the consequences of those rules and so on.\n11\nA useful high-level formal model for understanding games as dynamic systems that create experiences is the Mechanics, Dynamics, Aesthetics (MDA) framework by Hunicke, LeBlanc and Zubek [79]. \u201cMechanics describes the particular components of the game, at the level of data representation and algorithms. Dynamics describes the run-time behavior of the mechanics acting on player inputs and each other\u2019s outputs over time. Aesthetics describes the desirable emotional responses evoked in the player, when she interacts with the game system.\u201d [79] If the end goal for PCGML for games is to generate content or even complete games and with good results at the aesthetic level, the problem is inherently a hierarchical one. It is possible that learning from data will need to happen at all of these three levels simultaneously in order to successfully generate content for games.\nC. Datasets and Benchmarks\nProcedural content generation, and specifically PCG via machine learning, is a developing field of research. As such, there are not many publicly available large datasets and no standardized evaluation benchmarks that are widely used.\nPublicly available, large datasets are important, as they will reduce the barrier for entry into PCGML, which will allow the community to grow more quickly. As previously mentioned, the VGLC [35] is an important step in creating widely available datasets for PCGML. However, it currently only provides level data. Other data sets exist for object models1 and gameplay mechanics2, but they have not been utilized by the PCGML community. By bringing these data sets to the attention of researchers, we hope to promote the exploration and development of approaches for generating those types of content. Additionally, creating, improving, and growing both new and existing data sets is necessary for refining and expanding the field.\nWidespread benchmarks allow for the comparison of various techniques in a standardized way. Previously, competitions have been used to compare various level generation approaches [80], [81]. However, many of the competitors in the Super Mario Bros. competition included hard coded rules, and the GVG-AI competition provides descriptions of\n1opengameart.org 2http://www.squidi.net/three/index.php\nthe games, but not the training data necessary for machine learning approaches.\nIn addition to competitions, there has been some work in developing metric-based benchmarks for comparing techniques. Horn et al. [72] proposed a benchmark for Super Mario Bros. level generators in a large comparative study of multiple generators, which provided several evaluation metrics that are commonly used now, but only for level generators for platforming games. In recent years, Canossa and Smith [82] presented several general evaluation metrics for procedurally generated levels, which could allow for cross-techniques comparisons. Again, however, these only apply to level generation and not other generatable content. Other machine learning domains, such as image processing, have benchmarks in place [83] for testing new techniques and comparing various techniques against each other. For the field of PCGML to grow, we need to be able to compare approaches in a meaningful way.\nD. Style Transfer\nStyle and concept transfer is the idea that information learned from one domain can enhance or supplement knowledge in another domain. Style transfer has most notably been explored for image modeling and generation [84], [85]. For example, in recent work Gatys et al. [41] used neural networks to transfer the style of an artist onto different images. Additionally, Deep Dream [40] trains neural networks on images, and then generates new images that excite particular layers or nodes of the network. This approach could be adapted to learn from game content (e.g., levels, play data, etc.) and used to generate content that excites layers associated with different elements from the training data. More traditional forms of blending domain knowledge have been applied sparingly to games, such as game creature blending [86] and interactive fiction blending [87]. However, until very recently no one has applied this machine learning-oriented style transfer to procedural content generation.\nRecently Snodgrass and Onta\u00f1\u00f3n [88] explored domain transfer in level generation across platforming games, and Guzdial et al. [89] used concept blending to meld different level designs from Super Mario Bros. together (e.g., castle, underwater, and overworld levels). These approaches transfer and blend level styles, but do not attempt to address the game mechanics explicitly; both approaches\n12\nensure playable levels, but do not attempt transfer or blending between different mechanics. Gow and Corneli [90] proposed a framework for blending two games together into a new game, including mechanics, but no implementation yet exists.\nThe above approaches are important first steps, but style transfer needs to be explored more fully in PCG. Specifically, approaches to transferring more than just aesthetics are needed, including game mechanic transfer. Additionally, the above approaches only apply transfer to game levels, and there are many other areas where style transfer can be applied. Character models, stories, and quests are a few such areas.\nE. Exposing and Exploring the Generative Space\nOne avenue that has yet to be deeply explored in PCGML is opening the systems up to allow for designer input. Most systems are trained on a source of data and the editorial control over what data is fed in is the main interaction for a designer, but it is easy to imagine that a designer would want to control things such as difficulty, complexity, or theming (e.g., the difference between an above ground level and below ground level in Super Mario Bros.). The generative approach of Summerville et al. [30] allows a designer to set some high-level design parameters (number of rooms in a dungeon, length of optimal player path), but this approach only works if all design factors are known at training time and a Bayes Net is a suitable technique. Similarly, Snodgrass and Onta\u00f1\u00f3n [59] allow the user to define constraints (e.g., number of enemies, distance of the longest gap, etc.), but require hand crafted constraint checkers for each constraint used, and for the domain to be able to be modeled with multidimensional Markov chains.\nThe nature of Generative Adversarial Networks has allowed for the discovery of latent factors that hold specific semantics (e.g., subtracting the latent space image of blank-faced person from a smiling one is the smile vector) [92]. Interpolating and extrapolating along these latent dimensions allows a user to generate content while freely tuning the parameters they see fit. We envision that this type of approach could lead to similar results in the PCG domain (e.g., subtract Mario 1-1 from Mario 1-2 for the underground dimension, subtract Mario 1-1 from Mario 8-3 for the difficulty dimension). Furthermore, if multiple games are used as training input, it is theoretically possible that one could interpolate between two games (e.g., find the half-way point between Mario and Sonic) or find other more esoteric combinations (Contra\u2212Mario+ Zelda =???).\nF. Using PCGML as a Game Mechanic\nMost current work in PCGML focuses on replicating designed content in order to provide the player infinite or novel variations on gameplay, informed by past examples. Another possibility is to use PCGML as the main mechanic of a game, presenting the PCGML system as an adversary or toy for the player to engage with. Designs could include enticing the player to, for example, generate content that is significantly similar to or different from the corpus the system was trained on, identify content examples that are outliers or typical examples of the system, or train PCGML systems to generate examples that possess certain qualities or fulfill certain objective functions, teaching the player to operate an opaque or transparent model by feeding it examples that shape its output in one direction or the other. This would allow a PCGML system to take on several design pattern roles, including AI as Role-Model, Trainee, Editable, Guided, Co-Creator, Adversary, and Spectacle [93]. Role-model: a PCGML system replicates content generated by players of various levels of skill or generates content suitable for players of certain skill levels. New players are trained by having them replicate the content or by playing the generated content in a form of generative tutorial. Trainee: the player needs to train a PCGML system to generate a piece of content necessary as part of a puzzle or a piece of level geometry to proceed in the game. Editable: rather than training the AI to generate the missing puzzle piece via examples, the player changes the internal model\u2019s values until acceptable content is generated. Guided: the player corrects PCG system output in order to fulfill increasingly difficult requirements. The AI, in turn, learns from the player\u2019s corrections, following the player\u2019s guidance. Co-creator: the player and a PCGML system take turns in creating content, moving toward some external requirement. The PCGML system learns from the player\u2019s examples. Adversary: the player produces content that the PCGML system must replicate by generation to survive or vice versa in a \u201ccall and response\u201d style battle. Spectacle: the PCGML system is trained to replicate patterns that are sensorically impressive or cognitively interesting.\nVI. CONCLUSION\nIn this survey paper, we give an overview of an emerging machine learning approach to Procedural Content Generation, including describing and contrasting the existing examples of work taking this approach and outlining a number of challenges and opportunities for future research. We intend\n13\nthe paper to play a similar role as the SearchBased Procedural Content Generation paper [2], which pointed out existing research as well as work that was yet to be done. Much research that was proposed in that paper was subsequently carried out by various authors. In Table I, we present a summary the Procedural Content Generation via Machine Learning papers discussed throughout this paper. As can be seen from this table, and indeed from the rest of the paper, there is much work left to do. The vast majority of work has so far concerned twodimensional levels, in particular Super Mario Bros. levels. Plenty of work remains in applying these methods to other domains, including rulesets, items, characters, and 3-D levels. There is also very rapid progress within machine learning in general in the moment, and in particular within the deep learning field and in methods with generative capabilities such as Generative Adversarial Networks. There is plenty of interesting and rewarding work to do in exploring how these new capabilities can be adapted to function with the particular constraints and affordances of game content.\nREFERENCES\n[1] N. Shaker, J. Togelius, and M. J. Nelson, Procedural Content Generation in Games: A Textbook and an Overview of Current Research. Springer, 2016. [2] J. Togelius, G. N. Yannakakis, K. O. Stanley, and C. Browne, \u201cSearch-based procedural content generation: A taxonomy and survey,\u201d Computational Intelligence and AI in Games, IEEE Transactions on, vol. 3, no. 3, pp. 172\u2013186, 2011. [3] A. M. Smith and M. Mateas, \u201cAnswer set programming for procedural content generation: A design space approach,\u201d Computational Intelligence and AI in Games, IEEE Transactions on, vol. 3, no. 3, pp. 187\u2013200, 2011. [4] J. Montgomery, \u201cMachine learning in 2016: what does nips2016 tell us about the field today?\u201d 2016, https://blogs.royalsociety.org/inverba/2016/12/22/machine-learning-in-2016-what-doesnips2016-tell-us-about-the-field-today/. [5] J. Schmidhuber, \u201cDeep learning in neural networks: An overview,\u201d Neural Networks, vol. 61, pp. 85\u2013117, 2015. [6] I. Goodfellow, Y. Bengio, and A. Courville, \u201cDeep learning,\u201d 2016, book in preparation for MIT Press. [Online]. Available: http://www.deeplearningbook.org [7] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, \u201cGenerative adversarial nets,\u201d in Advances in Neural Information Processing Systems, 2014, pp. 2672\u20132680. [8] N. Boulanger-Lewandowski, Y. Bengio, and P. Vincent, \u201cModeling temporal dependencies in high-dimensional\n14\nsequences: Application to polyphonic music generation and transcription,\u201d arXiv preprint arXiv:1206.6392, 2012. [9] S. Fine, Y. Singer, and N. Tishby, \u201cThe hierarchical hidden markov model: Analysis and applications,\u201d Machine learning, vol. 32, no. 1, pp. 41\u201362, 1998. [10] K. Gregor, I. Danihelka, A. Graves, D. J. Rezende, and D. Wierstra, \u201cDraw: A recurrent neural network for image generation,\u201d arXiv preprint arXiv:1502.04623, 2015. [11] L.-Y. Wei, S. Lefebvre, V. Kwatra, and G. Turk, \u201cState of the art in example-based texture synthesis,\u201d in Eurographics 2009, State of the Art Report, EG-STAR. Eurographics Association, 2009, pp. 93\u2013117. [12] Z. Ren, H. Yeh, and M. C. Lin, \u201cExample-guided physically based modal sound synthesis,\u201d ACM Transactions on Graphics (TOG), vol. 32, no. 1, p. 1, 2013. [13] E. J. Aarseth, Cybertext: Perspectives on ergodic literature. JHU Press, 1997. [14] J. Togelius, G. N. Yannakakis, K. O. Stanley, and C. Browne, \u201cSearch-Based Procedural Content Generation,\u201d in Applications of Evolutionary Computation. Springer, 2010, pp. 141\u2013150. [15] N. Shaker, M. Shaker, and J. Togelius, \u201cRopossum: An authoring tool for designing, optimizing and solving cut the rope levels.\u201d 2013. [16] A. Liapis, G. N. Yannakakis, and J. Togelius, \u201cSentient sketchbook: Computer-aided game level authoring.\u201d in FDG, 2013, pp. 213\u2013220. [17] G. Smith, J. Whitehead, and M. Mateas, \u201cTanagra: Reactive planning and constraint solving for mixed-initiative level design,\u201d IEEE Transactions on Computational Intelligence and AI in Games, no. 99, 2011. [18] C. Guillemot and O. Le Meur, \u201cImage inpainting: Overview and recent advances,\u201d IEEE signal processing magazine, vol. 31, no. 1, pp. 127\u2013144, 2014. [19] A. Summerville and M. Mateas, \u201cSuper Mario as a string: Platformer level generation via LSTMs,\u201d Proceedings of 1st International Joint Conference of DiGRA and FDG, 2016. [20] R. Jain, A. Isaksen, C. Holmg\u00e5rd, and J. Togelius, \u201cAutoencoders for Level Generation, Repair, and Recognition,\u201d in ICCC, 2016. [21] G. N. Yannakakis, P. Spronck, D. Loiacono, and E. Andr\u00e9, \u201cPlayer modeling,\u201d in Dagstuhl Follow-Ups, vol. 6. Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik, 2013. [22] M. Guzdial, N. Sturtevant, and B. Li, \u201cDeep static and dynamic level analysis: A study on infinite mario,\u201d in Third Experimental AI in Games Workshop, vol. 3, 2016. [23] D. Braben and I. Bell, \u201cElite,\u201d 1984. [24] Hello Games, \u201cNo Man\u2019s Sky,\u201d 2016. [25] F. Pereira, P. Norvig, and A. Halevy, \u201cThe unreasonable\neffectiveness of data,\u201d IEEE Intelligent Systems, vol. 24, no. undefined, pp. 8\u201312, 2009. [26] P. Isola, J.-Y. Zhu, T. Zhou, and A. A. Efros, \u201cImage-toimage translation with conditional adversarial networks,\u201d 2016. [27] A. Karpathy, \u201cThe unreasonable effectiveness of recurrent neural networks,\u201d 2015. [Online]. Available: http://karpathy. github.io/2015/05/21/rnn-effectiveness/ [28] S. Miyamoto and T. Tezuka, \u201cSuper Mario Bros.\u201d 1985. [29] G. Yokoi and Y. Sakamoto, \u201cMetroid,\u201d 1986. [30] A. Summerville and M. Mateas, \u201cSampling hyrule: Sam-\npling probabilistic machine learning for level generation,\u201d 2015. [31] S. Dahlskog, J. Togelius, and M. J. Nelson, \u201cLinear levels through n-grams,\u201d in Proceedings of the 18th International Academic MindTrek Conference, 2014. [32] S. Snodgrass and S. Onta\u00f1\u00f3n, \u201cA hierarchical MdMC approach to 2D video game map generation,\u201d in Eleventh Artificial Intelligence and Interactive Digital Entertainment Conference, 2015. [33] M. Guzdial and M. Riedl, \u201cGame level generation from gameplay videos,\u201d in Twelfth Artificial Intelligence and Interactive Digital Entertainment Conference, 2016. [34] D. McFerran, \u201cMore than a million super mario maker levels have been uploaded in a week,\u201d 2015. [Online]. Available: http://www.nintendolife.com/news/2015/09/\nmore_than_a_million_super_mario_maker_levels_have_ been_uploaded_in_a_week\n[35] A. J. Summerville, S. Snodgrass, M. Mateas, and Onta\u00f1\u00f3n, \u201cThe VGLC: The video game level corpus.\u201d [36] A. K. Hoover, J. Togelius, and G. N. Yannakis, \u201cComposing video game levels with music metaphors through functional scaffolding.\u201d [37] A. Summerville and M. Mateas, \u201cMystical tutor: A magic: The gathering design assistant via denoising sequence-tosequence learning,\u201d 2016. [Online]. Available: http://www. aaai.org/ocs/index.php/AIIDE/AIIDE16/paper/view/13980 [38] M. Guzdial, B. Harrison, B. Li, and M. O. Riedl, \u201cCrowdsourcing open interactive narrative,\u201d in the 10th International Conference on the Foundations of Digital Games. Pacific Grove, CA, 2015. [39] K. O. Stanley and R. Miikkulainen, \u201cEvolving neural networks through augmenting topologies,\u201d Evolutionary Computation, vol. 10, pp. 99\u2013127, 2002. [40] A. Mordvintsev, C. Olah, and M. Tyka, \u201cInceptionism: Going deeper into neural networks,\u201d Google Research Blog. Retrieved June, vol. 20, 2015. [41] L. A. Gatys, A. S. Ecker, and M. Bethge, \u201cA neural algorithm of artistic style,\u201d arXiv preprint arXiv:1508.06576, 2015. [42] V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G. Bellemare, A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski et al., \u201cHuman-level control through deep reinforcement learning,\u201d Nature, vol. 518, no. 7540, pp. 529\u2013533, 2015. [43] D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. Van Den Driessche, J. Schrittwieser, I. Antonoglou, V. Panneershelvam, M. Lanctot et al., \u201cMastering the game of go with deep neural networks and tree search,\u201d Nature, vol. 529, no. 7587, pp. 484\u2013489, 2016. [44] S. Samothrakis, D. Perez-Liebana, S. M. Lucas, and M. Fasli, \u201cNeuroevolution for general video game playing,\u201d in Computational Intelligence and Games (CIG), 2015 IEEE Conference on. IEEE, 2015, pp. 200\u2013207. [45] A. K. Hoover, P. A. Szerlip, and K. O. Stanley, \u201cFunctional scaffolding for composing additional musical voices,\u201d Computer Music Journal, vol. 38, no. 4, pp. 80\u201399, 2014. [46] S. Hochreiter and J. Schmidhuber, \u201cLong short-term memory,\u201d Neural Computing, 1997. [47] S. Miyamoto and T. Tezuka, \u201cSuper mario bros. 2,\u201d 1986. [48] S. Snodgrass and S. Onta\u00f1\u00f3n, \u201cExperiments in map\ngeneration using Markov chains,\u201d in Proceedings of the 9th International Conference on Foundations of Digital Games, ser. FDG, vol. 14, 2014. [49] A. Summerville, M. Guzdial, M. Mateas, and M. Riedl, \u201cLearning player tailored content from observation: Platformer level generation from video traces using lstms,\u201d in AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, 2016. [50] P. Vincent, H. Larochelle, Y. Bengio, and P.-A. Manzagol, \u201cExtracting and composing robust features with denoising autoencoders,\u201d in Intl. Conf. on Machine Learning. ACM, 2008, pp. 1096\u20131103. [51] S. Lee, A. Isaksen, C. Holmg\u00e5rd, and J. Togelius, \u201cPredicting Resource Locations in Game Maps Using Deep Convolutional Neural Networks,\u201d in The Twelfth Annual AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment. AAAI, 2016. [52] B. Entertainment, \u201cStarCraft II,\u201d 2010. [53] W. of the Coast, \u201cMagic: The Gathering,\u201d 1993. [54] M. Milewicz, RoboRosewater.\nhttps://twitter.com/roborosewater?lang=en, 2016. [55] I. Sutskever, O. Vinyals, and Q. V. Le, \u201cSequence to\nsequence learning with neural networks,\u201d in CoRR, 2014. [56] T. Osawa and Y. Sakamoto, \u201cKid icarus,\u201d 1986. [57] S. Dahlskog and J. Togelius, \u201cPatterns as objectives for\nlevel generation,\u201d in Proceedings of EvoApplications, 2013. [58] W. Ching, S. Zhang, and M. Ng, \u201cOn multi-dimensional\nmarkov chain models,\u201d Pacific Journal of Optimization, vol. 3, no. 2, 2007. [59] S. Snodgrass and S. Onta\u00f1\u00f3n, \u201cControllable procedural content generation via constrained multi-dimensional Markov chain sampling,\u201d in Proceedings of the Twenty-Fifth\n15\nInternational Joint Conference on Artificial Intelligence, IJCAI, 2016, pp. 780\u2013786. [60] S. Snodgrass and S. Ontanon, \u201cLearning to generate video game maps using Markov models,\u201d IEEE Transactions on Computational Intelligence and AI in Games, 2016. [61] M. Gumin, \u201cWavefunctioncollapse,\u201d GitHub repository, 2016. [62] Freehold Games, \u201cThe Caves of Qud,\u201d 2016. [63] Arcadia-Clojure, \u201cProc Skater 2016,\u201d 2016. [64] K. Pulli, A. Baksheev, K. Kornyakov, and V. Eruhimov,\n\u201cReal-time computer vision with opencv,\u201d Commun. ACM, vol. 55, no. 6, pp. 61\u201369, Jun. 2012. [65] E. Kalogerakis, S. Chaudhuri, D. Koller, and V. Koltun, \u201cA probabilistic model for component-based shape synthesis,\u201d ACM Transactions on Graphics, vol. 31, no. 4, pp. 55:1\u2013 55:11, Jul. 2014. [66] B. Li, \u201cLearning knowledge to support domain-independent narrative intelligence,\u201d Ph.D. dissertation, Georgia Institute of Technology, 2015. [67] P. Weyhrauch, \u201cGuiding interactive fiction,\u201d Ph.D. dissertation, Ph. D. Dissertation, Carnegie Mellon University, 1997. [68] M. Ankerst, M. M. Breunig, H.-P. Kriegel, and J. Sander, \u201cOptics: ordering points to identify the clustering structure,\u201d in ACM Sigmod Record, vol. 28, no. 2. ACM, 1999, pp. 49\u201360. [69] A. J. Summerville, M. Behrooz, M. Mateas, and A. Jhala, \u201cThe learning of zelda: Data-driven learning of level topology.\u201d [70] Nintendo, \u201cThe Legend of Zelda,\u201d 1986. [71] S. Wright, \u201cCorrelation and causation,\u201d 1921. [72] B. Horn, S. Dahlskog, N. Shaker, G. Smith, and J. Togelius,\n\u201cA comparative evaluation of procedural level generators in the mario ai framework,\u201d 2014. [73] N. Shaker and M. Abou-Zleikha, \u201cAlone we can do so little, together we can do so much: A combinatorial approach for generating game content.\u201d AIIDE, vol. 14, pp. 167\u2013173, 2014. [74] D. D. Lee and H. S. Seung, \u201cLearning the parts of objects by non-negative matrix factorization,\u201d Nature, vol. 401, no. 6755, pp. 788\u2013791, 1999. [75] D. Graff, J. Kong, K. Chen, and K. Maeda, \u201cEnglish gigaword,\u201d Linguistic Data Consortium, Philadelphia, 2003. [76] Capcom, \u201cMega Man,\u201d 1987. [77] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-\nFei, \u201cImagenet: A large-scale hierarchical image database,\u201d in Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on. IEEE, 2009, pp. 248\u2013255. [78] F.-F. Li, R. Fergus, and P. Perona, \u201cOne-shot learning of object categories,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 28, no. 4, pp. 594\u2013611, 2006. [79] R. Hunicke, M. LeBlanc, and R. Zubek, \u201cMda: A formal approach to game design and game research,\u201d in Proceedings of the AAAI Workshop on Challenges in Game AI, vol. 4, 2004, p. 1. [80] J. Togelius, N. Shaker, S. Karakovskiy, and G. N. Yannakakis, \u201cThe Mario AI Championship 2009-2012,\u201d AI Magazine, vol. 34, no. 3, pp. 89\u201392, 2013. [81] S. L. Ahmed Khalifa, Diego Perez-Liebana and J. Togelius, \u201cGeneral video game level generation,\u201d in Proceedings of the Genetic and Evolutionary Computation Conference, 2016. [82] A. Canossa and G. Smith, \u201cTowards a procedural evaluation technique: Metrics for level design,\u201d development, vol. 7, p. 8, 2015. [83] Y. LeCun, C. Cortes, and C. J. Burges, \u201cThe MNIST database of handwritten digits,\u201d 1998. [84] S. Bruckner and M. E. Gr\u00f6ller, \u201cStyle transfer functions for illustrative volume rendering,\u201d in Computer Graphics Forum, vol. 26, no. 3. Wiley Online Library, 2007, pp. 715\u2013724. [85] A. Hertzmann, C. E. Jacobs, N. Oliver, B. Curless, and D. H. Salesin, \u201cImage analogies,\u201d in Proceedings of the 28th annual conference on Computer graphics and interactive techniques. ACM, 2001, pp. 327\u2013340.\n[86] P. Ribeiro, F. C. Pereira, B. Marques, B. Leitao, and A. Cardoso, \u201cA model for creativity in creature generation.\u201d in Proceedings of the 4th GAME-ON Conference, 2003, p. 175. [87] J. Permar and B. Magerko, \u201cA conceptual blending approach to the generation of cognitive scripts for interactive narrative,\u201d in Proceedings of the 9th AIIDE Conference, 2013. [88] S. Snodgrass and S. Onta\u00f1\u00f3n, \u201cAn approach to domain transfer in procedural content generation of two-dimensional videogame levels,\u201d in Twelfth Artificial Intelligence and Interactive Digital Entertainment Conference, 2016. [89] M. Guzdial and M. Riedl, \u201cLearning to blend computer game levels,\u201d arXiv preprint arXiv:1603.02738, 2016. [90] J. Gow and J. Corneli, \u201cTowards generating novel games using conceptual blending,\u201d in Eleventh Artificial Intelligence and Interactive Digital Entertainment Conference, 2015. [91] A. J. Summerville, M. Behrooz, M. Mateas, and A. Jhala, \u201cThe learning of Zelda: Data-driven learning of level topology.\u201d [92] T. White, \u201cSampling generative networks: Notes on a few effective techniques,\u201d arXiv preprint arXiv:1609.04468, 2016. [93] M. Treanor, A. Zook, M. P. Eladhari, J. Togelius, G. Smith, M. Cook, T. Thompson, B. Magerko, J. Levine, and A. Smith, \u201cAI-based game design patterns,\u201d in Proceedings of the 10 International Conference on Foundations of Digital Games, FDG, 2015."}], "references": [{"title": "Procedural Content Generation in Games: A Textbook and an Overview of Current Research", "author": ["N. Shaker", "J. Togelius", "M.J. Nelson"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "Search-based procedural content generation: A taxonomy and survey", "author": ["J. Togelius", "G.N. Yannakakis", "K.O. Stanley", "C. Browne"], "venue": "Computational Intelligence and AI in Games, IEEE Transactions on, vol. 3, no. 3, pp. 172\u2013186, 2011.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "Answer set programming for procedural content generation: A design space approach", "author": ["A.M. Smith", "M. Mateas"], "venue": "Computational Intelligence and AI in Games, IEEE Transactions on, vol. 3, no. 3, pp. 187\u2013200, 2011.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Machine learning in 2016: what does nips2016 tell us about the field today?", "author": ["J. Montgomery"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "Deep learning in neural networks: An overview", "author": ["J. Schmidhuber"], "venue": "Neural Networks, vol. 61, pp. 85\u2013117, 2015.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep learning", "author": ["I. Goodfellow", "Y. Bengio", "A. Courville"], "venue": "2016, book in preparation for MIT Press. [Online]. Available: http://www.deeplearningbook.org", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2016}, {"title": "Generative adversarial nets", "author": ["I. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio"], "venue": "Advances in Neural Information Processing Systems, 2014, pp. 2672\u20132680.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Modeling temporal dependencies in high-dimensional  14 sequences: Application to polyphonic music generation and transcription", "author": ["N. Boulanger-Lewandowski", "Y. Bengio", "P. Vincent"], "venue": "arXiv preprint arXiv:1206.6392, 2012.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "The hierarchical hidden markov model: Analysis and applications", "author": ["S. Fine", "Y. Singer", "N. Tishby"], "venue": "Machine learning, vol. 32, no. 1, pp. 41\u201362, 1998.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1998}, {"title": "Draw: A recurrent neural network for image generation", "author": ["K. Gregor", "I. Danihelka", "A. Graves", "D.J. Rezende", "D. Wierstra"], "venue": "arXiv preprint arXiv:1502.04623, 2015.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "State of the art in example-based texture synthesis", "author": ["L.-Y. Wei", "S. Lefebvre", "V. Kwatra", "G. Turk"], "venue": "Eurographics 2009, State of the Art Report, EG-STAR. Eurographics Association, 2009, pp. 93\u2013117.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "Example-guided physically based modal sound synthesis", "author": ["Z. Ren", "H. Yeh", "M.C. Lin"], "venue": "ACM Transactions on Graphics (TOG), vol. 32, no. 1, p. 1, 2013.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Cybertext: Perspectives on ergodic literature", "author": ["E.J. Aarseth"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1997}, {"title": "Search-Based Procedural Content Generation", "author": ["J. Togelius", "G.N. Yannakakis", "K.O. Stanley", "C. Browne"], "venue": "Applications of Evolutionary Computation. Springer, 2010, pp. 141\u2013150.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2010}, {"title": "Ropossum: An authoring tool for designing, optimizing and solving cut the rope levels.", "author": ["N. Shaker", "M. Shaker", "J. Togelius"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "Sentient sketchbook: Computer-aided game level authoring.", "author": ["A. Liapis", "G.N. Yannakakis", "J. Togelius"], "venue": "in FDG,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Tanagra: Reactive planning and constraint solving for mixed-initiative level design", "author": ["G. Smith", "J. Whitehead", "M. Mateas"], "venue": "IEEE Transactions on Computational Intelligence and AI in Games, no. 99, 2011.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "Image inpainting: Overview and recent advances", "author": ["C. Guillemot", "O. Le Meur"], "venue": "IEEE signal processing magazine, vol. 31, no. 1, pp. 127\u2013144, 2014.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Super Mario as a string: Platformer level generation via LSTMs", "author": ["A. Summerville", "M. Mateas"], "venue": "Proceedings of 1st International Joint Conference of DiGRA and FDG, 2016.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2016}, {"title": "Autoencoders for Level Generation, Repair, and Recognition", "author": ["R. Jain", "A. Isaksen", "C. Holmg\u00e5rd", "J. Togelius"], "venue": "ICCC, 2016.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2016}, {"title": "Player modeling", "author": ["G.N. Yannakakis", "P. Spronck", "D. Loiacono", "E. Andr\u00e9"], "venue": "Dagstuhl Follow-Ups, vol. 6. Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik, 2013.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "Deep static and dynamic level analysis: A study on infinite mario", "author": ["M. Guzdial", "N. Sturtevant", "B. Li"], "venue": "Third Experimental AI in Games Workshop, vol. 3, 2016.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2016}, {"title": "Elite", "author": ["D. Braben", "I. Bell"], "venue": "1984.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1984}, {"title": "No Man\u2019s Sky", "author": ["Hello Games"], "venue": "2016.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2016}, {"title": "The unreasonable effectiveness of data", "author": ["F. Pereira", "P. Norvig", "A. Halevy"], "venue": "IEEE Intelligent Systems, vol. 24, no. undefined, pp. 8\u201312, 2009.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2009}, {"title": "Image-toimage translation with conditional adversarial networks", "author": ["P. Isola", "J.-Y. Zhu", "T. Zhou", "A.A. Efros"], "venue": "2016.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2016}, {"title": "The unreasonable effectiveness of recurrent neural networks", "author": ["A. Karpathy"], "venue": "2015. [Online]. Available: http://karpathy. github.io/2015/05/21/rnn-effectiveness/", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "Metroid", "author": ["G. Yokoi", "Y. Sakamoto"], "venue": "1986.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1986}, {"title": "Sampling hyrule: Sampling probabilistic machine learning for level generation", "author": ["A. Summerville", "M. Mateas"], "venue": "2015.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2015}, {"title": "Linear levels through n-grams", "author": ["S. Dahlskog", "J. Togelius", "M.J. Nelson"], "venue": "Proceedings of the 18th International Academic MindTrek Conference, 2014.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2014}, {"title": "A hierarchical MdMC approach to 2D video game map generation", "author": ["S. Snodgrass", "S. Onta\u00f1\u00f3n"], "venue": "Eleventh Artificial Intelligence and Interactive Digital Entertainment Conference, 2015.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2015}, {"title": "Game level generation from gameplay videos", "author": ["M. Guzdial", "M. Riedl"], "venue": "Twelfth Artificial Intelligence and Interactive Digital Entertainment Conference, 2016.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2016}, {"title": "More than a million super mario maker levels have been uploaded in a week", "author": ["D. McFerran"], "venue": "2015. [Online]. Available: http://www.nintendolife.com/news/2015/09/  more_than_a_million_super_mario_maker_levels_have_ been_uploaded_in_a_week", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2015}, {"title": "Mystical tutor: A magic: The gathering design assistant via denoising sequence-tosequence learning", "author": ["A. Summerville", "M. Mateas"], "venue": "2016. [Online]. Available: http://www. aaai.org/ocs/index.php/AIIDE/AIIDE16/paper/view/13980", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2016}, {"title": "Crowdsourcing open interactive narrative", "author": ["M. Guzdial", "B. Harrison", "B. Li", "M.O. Riedl"], "venue": "the 10th International Conference on the Foundations of Digital Games. Pacific Grove, CA, 2015.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2015}, {"title": "Evolving neural networks through augmenting topologies", "author": ["K.O. Stanley", "R. Miikkulainen"], "venue": "Evolutionary Computation, vol. 10, pp. 99\u2013127, 2002.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2002}, {"title": "Inceptionism: Going deeper into neural networks", "author": ["A. Mordvintsev", "C. Olah", "M. Tyka"], "venue": "Google Research Blog. Retrieved June, vol. 20, 2015.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2015}, {"title": "A neural algorithm of artistic style", "author": ["L.A. Gatys", "A.S. Ecker", "M. Bethge"], "venue": "arXiv preprint arXiv:1508.06576, 2015.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2015}, {"title": "Human-level control through deep reinforcement learning", "author": ["V. Mnih", "K. Kavukcuoglu", "D. Silver", "A.A. Rusu", "J. Veness", "M.G. Bellemare", "A. Graves", "M. Riedmiller", "A.K. Fidjeland", "G. Ostrovski"], "venue": "Nature, vol. 518, no. 7540, pp. 529\u2013533, 2015.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2015}, {"title": "Mastering the game of go with deep neural networks and tree search", "author": ["D. Silver", "A. Huang", "C.J. Maddison", "A. Guez", "L. Sifre", "G. Van Den Driessche", "J. Schrittwieser", "I. Antonoglou", "V. Panneershelvam", "M. Lanctot"], "venue": "Nature, vol. 529, no. 7587, pp. 484\u2013489, 2016.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2016}, {"title": "Neuroevolution for general video game playing", "author": ["S. Samothrakis", "D. Perez-Liebana", "S.M. Lucas", "M. Fasli"], "venue": "Computational Intelligence and Games (CIG), 2015 IEEE Conference on. IEEE, 2015, pp. 200\u2013207.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2015}, {"title": "Functional scaffolding for composing additional musical voices", "author": ["A.K. Hoover", "P.A. Szerlip", "K.O. Stanley"], "venue": "Computer Music Journal, vol. 38, no. 4, pp. 80\u201399, 2014.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2014}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural Computing, 1997.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 1997}, {"title": "Super mario bros. 2", "author": ["S. Miyamoto", "T. Tezuka"], "venue": "1986.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 1986}, {"title": "Experiments in map generation using Markov chains", "author": ["S. Snodgrass", "S. Onta\u00f1\u00f3n"], "venue": "Proceedings of the 9th International Conference on Foundations of Digital Games, ser. FDG, vol. 14, 2014.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning player tailored content from observation: Platformer level generation from video traces using lstms", "author": ["A. Summerville", "M. Guzdial", "M. Mateas", "M. Riedl"], "venue": "AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, 2016.", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2016}, {"title": "Extracting and composing robust features with denoising autoencoders", "author": ["P. Vincent", "H. Larochelle", "Y. Bengio", "P.-A. Manzagol"], "venue": "Intl. Conf. on Machine Learning. ACM, 2008, pp. 1096\u20131103.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2008}, {"title": "Predicting Resource Locations in Game Maps Using Deep Convolutional Neural Networks", "author": ["S. Lee", "A. Isaksen", "C. Holmg\u00e5rd", "J. Togelius"], "venue": "The Twelfth Annual AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment. AAAI, 2016.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2016}, {"title": "StarCraft II", "author": ["B. Entertainment"], "venue": "2010.", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2010}, {"title": "Magic: The Gathering", "author": ["W. of the Coast"], "venue": "1993.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 1993}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "CoRR, 2014.", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2014}, {"title": "Kid icarus", "author": ["T. Osawa", "Y. Sakamoto"], "venue": "1986.", "citeRegEx": "56", "shortCiteRegEx": null, "year": 1986}, {"title": "Patterns as objectives for level generation", "author": ["S. Dahlskog", "J. Togelius"], "venue": "Proceedings of EvoApplications, 2013.", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2013}, {"title": "On multi-dimensional markov chain models", "author": ["W. Ching", "S. Zhang", "M. Ng"], "venue": "Pacific Journal of Optimization, vol. 3, no. 2, 2007.", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2007}, {"title": "Controllable procedural content generation via constrained multi-dimensional Markov chain sampling", "author": ["S. Snodgrass", "S. Onta\u00f1\u00f3n"], "venue": "Proceedings of the Twenty-Fifth  15 International Joint Conference on Artificial Intelligence, IJCAI, 2016, pp. 780\u2013786.", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2016}, {"title": "Learning to generate video game maps using Markov models", "author": ["S. Snodgrass", "S. Ontanon"], "venue": "IEEE Transactions on Computational Intelligence and AI in Games, 2016.", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2016}, {"title": "Wavefunctioncollapse", "author": ["M. Gumin"], "venue": "GitHub repository, 2016.", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2016}, {"title": "The Caves of Qud", "author": ["Freehold Games"], "venue": "2016.", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2016}, {"title": "Proc Skater 2016", "author": ["Arcadia-Clojure"], "venue": "2016.", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2016}, {"title": "Real-time computer vision with opencv", "author": ["K. Pulli", "A. Baksheev", "K. Kornyakov", "V. Eruhimov"], "venue": "Commun. ACM, vol. 55, no. 6, pp. 61\u201369, Jun. 2012.", "citeRegEx": "64", "shortCiteRegEx": null, "year": 2012}, {"title": "A probabilistic model for component-based shape synthesis", "author": ["E. Kalogerakis", "S. Chaudhuri", "D. Koller", "V. Koltun"], "venue": "ACM Transactions on Graphics, vol. 31, no. 4, pp. 55:1\u2013 55:11, Jul. 2014.", "citeRegEx": "65", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning knowledge to support domain-independent narrative intelligence", "author": ["B. Li"], "venue": "Ph.D. dissertation, Georgia Institute of Technology, 2015.", "citeRegEx": "66", "shortCiteRegEx": null, "year": 2015}, {"title": "Guiding interactive fiction", "author": ["P. Weyhrauch"], "venue": "Ph.D. dissertation, Ph. D. Dissertation, Carnegie Mellon University, 1997.", "citeRegEx": "67", "shortCiteRegEx": null, "year": 1997}, {"title": "Optics: ordering points to identify the clustering structure", "author": ["M. Ankerst", "M.M. Breunig", "H.-P. Kriegel", "J. Sander"], "venue": "ACM Sigmod Record, vol. 28, no. 2. ACM, 1999, pp. 49\u201360.", "citeRegEx": "68", "shortCiteRegEx": null, "year": 1999}, {"title": "The Legend of Zelda", "author": ["Nintendo"], "venue": "1986.", "citeRegEx": "70", "shortCiteRegEx": null, "year": 1986}, {"title": "Correlation and causation", "author": ["S. Wright"], "venue": "1921.", "citeRegEx": "71", "shortCiteRegEx": null, "year": 1921}, {"title": "A comparative evaluation of procedural level generators in the mario ai framework", "author": ["B. Horn", "S. Dahlskog", "N. Shaker", "G. Smith", "J. Togelius"], "venue": "2014.", "citeRegEx": "72", "shortCiteRegEx": null, "year": 2014}, {"title": "Alone we can do so little, together we can do so much: A combinatorial approach for generating game content.", "author": ["N. Shaker", "M. Abou-Zleikha"], "venue": "AIIDE, vol", "citeRegEx": "73", "shortCiteRegEx": "73", "year": 2014}, {"title": "Learning the parts of objects by non-negative matrix factorization", "author": ["D.D. Lee", "H.S. Seung"], "venue": "Nature, vol. 401, no. 6755, pp. 788\u2013791, 1999.", "citeRegEx": "74", "shortCiteRegEx": null, "year": 1999}, {"title": "English gigaword", "author": ["D. Graff", "J. Kong", "K. Chen", "K. Maeda"], "venue": "Linguistic Data Consortium, Philadelphia, 2003.", "citeRegEx": "75", "shortCiteRegEx": null, "year": 2003}, {"title": "Mega Man", "author": ["Capcom"], "venue": "1987.", "citeRegEx": "76", "shortCiteRegEx": null, "year": 1987}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["J. Deng", "W. Dong", "R. Socher", "L.-J. Li", "K. Li", "L. Fei- Fei"], "venue": "Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on. IEEE, 2009, pp. 248\u2013255.", "citeRegEx": "77", "shortCiteRegEx": null, "year": 2009}, {"title": "One-shot learning of object categories", "author": ["F.-F. Li", "R. Fergus", "P. Perona"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 28, no. 4, pp. 594\u2013611, 2006.", "citeRegEx": "78", "shortCiteRegEx": null, "year": 2006}, {"title": "Mda: A formal approach to game design and game research", "author": ["R. Hunicke", "M. LeBlanc", "R. Zubek"], "venue": "Proceedings of the AAAI Workshop on Challenges in Game AI, vol. 4, 2004, p. 1.", "citeRegEx": "79", "shortCiteRegEx": null, "year": 2004}, {"title": "The Mario AI Championship 2009-2012", "author": ["J. Togelius", "N. Shaker", "S. Karakovskiy", "G.N. Yannakakis"], "venue": "AI Magazine, vol. 34, no. 3, pp. 89\u201392, 2013.", "citeRegEx": "80", "shortCiteRegEx": null, "year": 2013}, {"title": "General video game level generation", "author": ["S.L. Ahmed Khalifa", "Diego Perez-Liebana", "J. Togelius"], "venue": "Proceedings of the Genetic and Evolutionary Computation Conference, 2016.", "citeRegEx": "81", "shortCiteRegEx": null, "year": 2016}, {"title": "Towards a procedural evaluation technique: Metrics for level design", "author": ["A. Canossa", "G. Smith"], "venue": "development, vol. 7, p. 8, 2015.", "citeRegEx": "82", "shortCiteRegEx": null, "year": 2015}, {"title": "The MNIST database of handwritten digits", "author": ["Y. LeCun", "C. Cortes", "C.J. Burges"], "venue": "1998.", "citeRegEx": "83", "shortCiteRegEx": null, "year": 1998}, {"title": "Style transfer functions for illustrative volume rendering", "author": ["S. Bruckner", "M.E. Gr\u00f6ller"], "venue": "Computer Graphics Forum, vol. 26, no. 3. Wiley Online Library, 2007, pp. 715\u2013724.", "citeRegEx": "84", "shortCiteRegEx": null, "year": 2007}, {"title": "Image analogies", "author": ["A. Hertzmann", "C.E. Jacobs", "N. Oliver", "B. Curless", "D.H. Salesin"], "venue": "Proceedings of the 28th annual conference on Computer graphics and interactive techniques. ACM, 2001, pp. 327\u2013340.", "citeRegEx": "85", "shortCiteRegEx": null, "year": 2001}, {"title": "A model for creativity in creature generation.", "author": ["P. Ribeiro", "F.C. Pereira", "B. Marques", "B. Leitao", "A. Cardoso"], "venue": "Proceedings of the 4th GAME-ON Conference,", "citeRegEx": "86", "shortCiteRegEx": "86", "year": 2003}, {"title": "A conceptual blending approach to the generation of cognitive scripts for interactive narrative", "author": ["J. Permar", "B. Magerko"], "venue": "Proceedings of the 9th AIIDE Conference, 2013.", "citeRegEx": "87", "shortCiteRegEx": null, "year": 2013}, {"title": "An approach to domain transfer in procedural content generation of two-dimensional videogame levels", "author": ["S. Snodgrass", "S. Onta\u00f1\u00f3n"], "venue": "Twelfth Artificial Intelligence and Interactive Digital Entertainment Conference, 2016.", "citeRegEx": "88", "shortCiteRegEx": null, "year": 2016}, {"title": "Learning to blend computer game levels", "author": ["M. Guzdial", "M. Riedl"], "venue": "arXiv preprint arXiv:1603.02738, 2016.", "citeRegEx": "89", "shortCiteRegEx": null, "year": 2016}, {"title": "Towards generating novel games using conceptual blending", "author": ["J. Gow", "J. Corneli"], "venue": "Eleventh Artificial Intelligence and Interactive Digital Entertainment Conference, 2015.", "citeRegEx": "90", "shortCiteRegEx": null, "year": 2015}, {"title": "Sampling generative networks: Notes on a few effective techniques", "author": ["T. White"], "venue": "arXiv preprint arXiv:1609.04468, 2016.", "citeRegEx": "92", "shortCiteRegEx": null, "year": 2016}, {"title": "AI-based game design patterns", "author": ["M. Treanor", "A. Zook", "M.P. Eladhari", "J. Togelius", "G. Smith", "M. Cook", "T. Thompson", "B. Magerko", "J. Levine", "A. Smith"], "venue": "Proceedings of the 10 International Conference on Foundations of Digital Games, FDG, 2015.", "citeRegEx": "93", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "Researchers also addresses challenges in computational creativity and ways of increasing our understanding of game design through building formal models [1].", "startOffset": 153, "endOffset": 156}, {"referenceID": 1, "context": "techniques use either search-based methods [2] (for example using evolutionary algorithms) or solverbased methods [3] to generate content in settings that maximize objectives and/or preserve constraints.", "startOffset": 43, "endOffset": 46}, {"referenceID": 2, "context": "techniques use either search-based methods [2] (for example using evolutionary algorithms) or solverbased methods [3] to generate content in settings that maximize objectives and/or preserve constraints.", "startOffset": 114, "endOffset": 117}, {"referenceID": 3, "context": "Concurrently, there has been an explosion in the use of machine learning to train models based on datasets [4].", "startOffset": 107, "endOffset": 110}, {"referenceID": 4, "context": "neural networks under the name deep learning has precipitated a massive increase in the capabilities and application of methods for learning models from big data [5], [6].", "startOffset": 162, "endOffset": 165}, {"referenceID": 5, "context": "neural networks under the name deep learning has precipitated a massive increase in the capabilities and application of methods for learning models from big data [5], [6].", "startOffset": 167, "endOffset": 170}, {"referenceID": 6, "context": "have been applied to generating artifacts such as images, music, and speech [7].", "startOffset": 76, "endOffset": 79}, {"referenceID": 7, "context": "models, autoencoders, and others [8], [9], [10].", "startOffset": 33, "endOffset": 36}, {"referenceID": 8, "context": "models, autoencoders, and others [8], [9], [10].", "startOffset": 38, "endOffset": 41}, {"referenceID": 9, "context": "models, autoencoders, and others [8], [9], [10].", "startOffset": 43, "endOffset": 47}, {"referenceID": 10, "context": "The main types of cosmetic game content that we exclude are textures and sound, as those do not directly impact the effects of in-game actions the way levels or rules do in most games, and there is already much research on the generation of such content outside of games [11], [12].", "startOffset": 271, "endOffset": 275}, {"referenceID": 11, "context": "The main types of cosmetic game content that we exclude are textures and sound, as those do not directly impact the effects of in-game actions the way levels or rules do in most games, and there is already much research on the generation of such content outside of games [11], [12].", "startOffset": 277, "endOffset": 281}, {"referenceID": 12, "context": "be consumed statically, games are dynamic and must be evaluated through interaction that requires non-trivial effort\u2014in Aarseth\u2019s terminology, games are ergodic media [13].", "startOffset": 167, "endOffset": 171}, {"referenceID": 13, "context": "With search-based PCG using a generateand-test framework, a programmer must specify an algorithm for generating the content and an evaluation function that can validate the fitness of the new artifact [14].", "startOffset": 201, "endOffset": 205}, {"referenceID": 14, "context": "This approach has previously been explored with other methods such as constraint satisfaction algorithms and evolutionary algorithms [15], [16], [17].", "startOffset": 133, "endOffset": 137}, {"referenceID": 15, "context": "This approach has previously been explored with other methods such as constraint satisfaction algorithms and evolutionary algorithms [15], [16], [17].", "startOffset": 139, "endOffset": 143}, {"referenceID": 16, "context": "This approach has previously been explored with other methods such as constraint satisfaction algorithms and evolutionary algorithms [15], [16], [17].", "startOffset": 145, "endOffset": 149}, {"referenceID": 17, "context": "Within the image domain, we have seen work on image inpainting, where a neural network is trained to complete images where parts are missing [18].", "startOffset": 141, "endOffset": 145}, {"referenceID": 18, "context": "Summerville and Mateas [19] use a special tile that represents where an AI would choose to move the player in their training set, so that the algorithm only generates playable content; the system inherently has learned the difference between passable and impassable terrain.", "startOffset": 23, "endOffset": 27}, {"referenceID": 19, "context": "[20] used a sliding window and an autoencoder to repair illegal level segments \u2013 because they did not appear in the training set, the autoencoder replaced them with a nearby window it had seen during training.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "They can also be trained to predict quantities such as difficulty, completion time, or emotional tenor [21], [22].", "startOffset": 103, "endOffset": 107}, {"referenceID": 21, "context": "They can also be trained to predict quantities such as difficulty, completion time, or emotional tenor [21], [22].", "startOffset": 109, "endOffset": 113}, {"referenceID": 22, "context": "One of the original motivations for PCG, particularly in early games such as Elite [23], was data compression.", "startOffset": 83, "endOffset": 87}, {"referenceID": 23, "context": "The same is true for some of today\u2019s games such as No Man\u2019s Sky [24].", "startOffset": 64, "endOffset": 68}, {"referenceID": 24, "context": "[25] make the case that having access to more data, not better algorithms or better data, is the key difference between why some problems are able to be solved in an effective manner with machine learning while others are not (e.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "For some types of machine learning a surfeit of data exists enabling certain techniques, such as images for generative adversarial networks [26] or text for Long Short-Term Memory recurrent neural", "startOffset": 140, "endOffset": 144}, {"referenceID": 26, "context": "networks (LSTMs) [27]; However, video games do not have this luxury.", "startOffset": 17, "endOffset": 21}, {"referenceID": 27, "context": "[28] and Metroid [29], despite the fact that both are platformers).", "startOffset": 17, "endOffset": 21}, {"referenceID": 28, "context": "As such, data sources are often limited to within a game series [30], [19] and more commonly within individual games [31], [32], [33].", "startOffset": 64, "endOffset": 68}, {"referenceID": 18, "context": "As such, data sources are often limited to within a game series [30], [19] and more commonly within individual games [31], [32], [33].", "startOffset": 70, "endOffset": 74}, {"referenceID": 29, "context": "As such, data sources are often limited to within a game series [30], [19] and more commonly within individual games [31], [32], [33].", "startOffset": 117, "endOffset": 121}, {"referenceID": 30, "context": "As such, data sources are often limited to within a game series [30], [19] and more commonly within individual games [31], [32], [33].", "startOffset": 123, "endOffset": 127}, {"referenceID": 31, "context": "As such, data sources are often limited to within a game series [30], [19] and more commonly within individual games [31], [32], [33].", "startOffset": 129, "endOffset": 133}, {"referenceID": 32, "context": "thousands, and even millions of maps [34], which could conceivably provide much larger data sources.", "startOffset": 37, "endOffset": 41}, {"referenceID": 19, "context": "Most simply this involves iterating over the data from left-to-right then top-to-bottom [20], however depending on the technique, this can obfuscate spatial relationships.", "startOffset": 88, "endOffset": 92}, {"referenceID": 18, "context": "This loss can be mitigated, for example [19] utilizes a \u201csnaking\u201d path while [36] represents vertical and horizontal relations by split-", "startOffset": 40, "endOffset": 44}, {"referenceID": 31, "context": "Shape-based representations as in [33] instead use the game\u2019s original sprites as their atomic unit, categorizing the various shapes they are arranged into, which therefore requires no processing after generation.", "startOffset": 34, "endOffset": 38}, {"referenceID": 33, "context": "We note two examples covered in this paper: Magic/Hearthstone card generation [37] and interactive narrative/story generation [38].", "startOffset": 78, "endOffset": 82}, {"referenceID": 34, "context": "We note two examples covered in this paper: Magic/Hearthstone card generation [37] and interactive narrative/story generation [38].", "startOffset": 126, "endOffset": 130}, {"referenceID": 36, "context": "Recently neural networks have been used in the context of generating images [40], [41] and learning to play games [42], [43], [44] with great success.", "startOffset": 76, "endOffset": 80}, {"referenceID": 37, "context": "Recently neural networks have been used in the context of generating images [40], [41] and learning to play games [42], [43], [44] with great success.", "startOffset": 82, "endOffset": 86}, {"referenceID": 38, "context": "Recently neural networks have been used in the context of generating images [40], [41] and learning to play games [42], [43], [44] with great success.", "startOffset": 114, "endOffset": 118}, {"referenceID": 39, "context": "Recently neural networks have been used in the context of generating images [40], [41] and learning to play games [42], [43], [44] with great success.", "startOffset": 120, "endOffset": 124}, {"referenceID": 40, "context": "Recently neural networks have been used in the context of generating images [40], [41] and learning to play games [42], [43], [44] with great success.", "startOffset": 126, "endOffset": 130}, {"referenceID": 41, "context": "The original FSMC representation posits 1) music can be represented as a function of time and 2) musical voices in a given piece are functionally related [45].", "startOffset": 154, "endOffset": 158}, {"referenceID": 35, "context": "menting Topologies (NEAT) [39], additional musical voices are then evolved to be played simultaneously with an original human-composed voice.", "startOffset": 26, "endOffset": 30}, {"referenceID": 18, "context": "Summerville and Mateas [19] used Long ShortTerm Memory Recurrent Neural Networks (LSTM RNNs) [46] to generate levels learned from a tile representation of Super Mario Bros.", "startOffset": 23, "endOffset": 27}, {"referenceID": 42, "context": "Summerville and Mateas [19] used Long ShortTerm Memory Recurrent Neural Networks (LSTM RNNs) [46] to generate levels learned from a tile representation of Super Mario Bros.", "startOffset": 93, "endOffset": 97}, {"referenceID": 43, "context": "2 (JP) [47] levels.", "startOffset": 7, "endOffset": 11}, {"referenceID": 44, "context": "Summerville and Matteas used a tile representation like the one used by Snodgrass and Onta\u00f1\u00f3n [48], but instead of representing levels", "startOffset": 94, "endOffset": 98}, {"referenceID": 45, "context": "[49] extended this work to incorporate actual player paths extracted from 4", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "In [20] Jain, Isaksen, Holmg\u00e5rd and Togelius", "startOffset": 3, "endOffset": 7}, {"referenceID": 46, "context": "show how autoencoders [50] may be trained to reproduce levels from the original Super Mario Bros.", "startOffset": 22, "endOffset": 26}, {"referenceID": 35, "context": "This example figure shows ground tiles being input to the ANN while the brick tile placements are output from predictions made through NeuroEvolution of Augmenting Topologies [39].", "startOffset": 175, "endOffset": 179}, {"referenceID": 47, "context": "Lee, Isaksen, Holmg\u00e5rd and Togelius [51] use convolutional neural networks to predict resource locations in maps for StarCraft II [52].", "startOffset": 36, "endOffset": 40}, {"referenceID": 48, "context": "Lee, Isaksen, Holmg\u00e5rd and Togelius [51] use convolutional neural networks to predict resource locations in maps for StarCraft II [52].", "startOffset": 130, "endOffset": 134}, {"referenceID": 49, "context": "A rare example of game content generation that is not a level generator is Magic: The Gathering [53] card generation.", "startOffset": 96, "endOffset": 100}, {"referenceID": 33, "context": "Building on the work of @RoboRosewater is Mystical Tutor by Summerville and Mateas [37].", "startOffset": 83, "endOffset": 87}, {"referenceID": 50, "context": "Using sequence-to-sequence learning [55], wherein an encoding LSTM encodes an input sequence into a fixed length vector which is then decoded by a decoder LSTM, they trained on the corpus of Magic: The Gathering.", "startOffset": 36, "endOffset": 40}, {"referenceID": 51, "context": "and Kid Icarus [56], where the \u201ctime\u201d of the system relates to the position in the level.", "startOffset": 15, "endOffset": 19}, {"referenceID": 29, "context": "game, and used these models to generate new levels [31].", "startOffset": 51, "endOffset": 55}, {"referenceID": 52, "context": "This was done through dividing the levels into vertical \u201cslices,\u201d where most slices recur many times throughout the level [57].", "startOffset": 122, "endOffset": 126}, {"referenceID": 44, "context": "In [48] Snodgrass and Onta\u00f1\u00f3n present an ap-", "startOffset": 3, "endOffset": 7}, {"referenceID": 53, "context": "proach to level generation using multi-dimensional Markov chains (MdMCs) [58].", "startOffset": 73, "endOffset": 77}, {"referenceID": 30, "context": "[32] and constrained [59] extensions to MdMCs in order to capture higher level structures and ensure usability of the sampled levels, respectively.", "startOffset": 0, "endOffset": 4}, {"referenceID": 54, "context": "[32] and constrained [59] extensions to MdMCs in order to capture higher level structures and ensure usability of the sampled levels, respectively.", "startOffset": 21, "endOffset": 25}, {"referenceID": 55, "context": "They have also developed a Markov random field approach (MRF) [60] that performed better than the standard MdMC model in Kid Icarus, a domain", "startOffset": 62, "endOffset": 66}, {"referenceID": 56, "context": "A recent approach by Gumin [61] leverages concepts from quantum mechanics in order to generate images and levels from a representative example tile set.", "startOffset": 27, "endOffset": 31}, {"referenceID": 57, "context": "This approach was initially explored for bitmap generation, but has since been expanded for use with 3-D tile sets as well as for level generation [62], [63].", "startOffset": 147, "endOffset": 151}, {"referenceID": 58, "context": "This approach was initially explored for bitmap generation, but has since been expanded for use with 3-D tile sets as well as for level generation [62], [63].", "startOffset": 153, "endOffset": 157}, {"referenceID": 56, "context": "The source code and examples of the bitmap project can be found online [61].", "startOffset": 71, "endOffset": 75}, {"referenceID": 31, "context": "In [33] Guzdial and Riedl utilized gameplay video of individuals playing through Super Mario Bros.", "startOffset": 3, "endOffset": 7}, {"referenceID": 59, "context": "gameplay video frame-by-frame with OpenCV [64] and a fanauthored spritesheet, a collection of each image that appears in the game (referred to as sprites).", "startOffset": 42, "endOffset": 46}, {"referenceID": 60, "context": "Guzdial and Riedl\u2019s model structure was adapted from [65], a graph structure meant to encode styles of shapes and their probabilistic relationships.", "startOffset": 53, "endOffset": 57}, {"referenceID": 31, "context": "For further details please see [33], but it can be", "startOffset": 31, "endOffset": 35}, {"referenceID": 61, "context": "adapted Scheherazade [66], a system for automatically learning to generate stories, into Scheherazade-IF [38], which can derive entire interactive fiction games from a dataset of stories.", "startOffset": 21, "endOffset": 25}, {"referenceID": 34, "context": "adapted Scheherazade [66], a system for automatically learning to generate stories, into Scheherazade-IF [38], which can derive entire interactive fiction games from a dataset of stories.", "startOffset": 105, "endOffset": 109}, {"referenceID": 62, "context": "Scheherazade-IF\u2019s structures its model in the form of plot graphs [67], directed graphs with events as vertices and sequentiality information encoded as edges.", "startOffset": 66, "endOffset": 70}, {"referenceID": 63, "context": "occur via an adaption of the OPTICS clustering algorithm [68].", "startOffset": 57, "endOffset": 61}, {"referenceID": 28, "context": "[30]", "startOffset": 0, "endOffset": 4}, {"referenceID": 64, "context": "[69] have generated levels learned from The Legend of Zelda [70] series.", "startOffset": 60, "endOffset": 64}, {"referenceID": 65, "context": "The room-to-room structure of a dungeon is learned along with high level parameters such as dungeon size and length of the optimal player path using a Bayes Net [71], a graphical structure of the joint probability distribution.", "startOffset": 161, "endOffset": 165}, {"referenceID": 66, "context": "Many generators (both machine and human) create in a particular identifiable style with a limited expressive range [72].", "startOffset": 115, "endOffset": 119}, {"referenceID": 67, "context": "Shaker and Abou-Zleikha [73] use Non-Negative Matrix Factorization (NNMF) to learn patterns from 5 unique non-ML-based unique generators of Super Mario Bros.", "startOffset": 24, "endOffset": 28}, {"referenceID": 68, "context": "The algorithm then uses a multiplicative update NNMF algorithm [74] to factor", "startOffset": 63, "endOffset": 67}, {"referenceID": 69, "context": "The English Gigaword corpus [75] which has been used in over 450 papers at the time of writing is approximately 27 GB.", "startOffset": 28, "endOffset": 32}, {"referenceID": 70, "context": "For specific series it is even worse, with the largest series (Mega Man [76]) making up 0.", "startOffset": 72, "endOffset": 76}, {"referenceID": 71, "context": "Standard image corpora are even larger than the Gigaword corpus, such as the ImageNet corpus [77] at 155GB.", "startOffset": 93, "endOffset": 97}, {"referenceID": 72, "context": "While most machine learning is focused on using large corpora, there is work in the field focused on One-Shot Learning/Generalization [78].", "startOffset": 134, "endOffset": 138}, {"referenceID": 73, "context": "A useful high-level formal model for understanding games as dynamic systems that create experiences is the Mechanics, Dynamics, Aesthetics (MDA) framework by Hunicke, LeBlanc and Zubek [79].", "startOffset": 185, "endOffset": 189}, {"referenceID": 73, "context": "\u201d [79] If the end goal for PCGML for games is to generate content or even complete games and with good results at the aesthetic level, the problem is inherently a hierarchical one.", "startOffset": 2, "endOffset": 6}, {"referenceID": 74, "context": "various level generation approaches [80], [81].", "startOffset": 36, "endOffset": 40}, {"referenceID": 75, "context": "various level generation approaches [80], [81].", "startOffset": 42, "endOffset": 46}, {"referenceID": 66, "context": "[72] proposed a benchmark for Super Mario Bros.", "startOffset": 0, "endOffset": 4}, {"referenceID": 76, "context": "In recent years, Canossa and Smith [82] presented several general evaluation metrics for procedurally generated levels, which could allow for cross-techniques comparisons.", "startOffset": 35, "endOffset": 39}, {"referenceID": 77, "context": "Other machine learning domains, such as image processing, have benchmarks in place [83] for testing new techniques and comparing various techniques against each other.", "startOffset": 83, "endOffset": 87}, {"referenceID": 78, "context": "Style transfer has most notably been explored for image modeling and generation [84], [85].", "startOffset": 80, "endOffset": 84}, {"referenceID": 79, "context": "Style transfer has most notably been explored for image modeling and generation [84], [85].", "startOffset": 86, "endOffset": 90}, {"referenceID": 37, "context": "[41] used neural networks to transfer the style of an artist onto different images.", "startOffset": 0, "endOffset": 4}, {"referenceID": 36, "context": "Additionally, Deep Dream [40] trains neural networks on images, and then generates new images that excite particular layers or nodes of the network.", "startOffset": 25, "endOffset": 29}, {"referenceID": 80, "context": "More traditional forms of blending domain knowledge have been applied sparingly to games, such as game creature blending [86] and interactive fiction blending [87].", "startOffset": 121, "endOffset": 125}, {"referenceID": 81, "context": "More traditional forms of blending domain knowledge have been applied sparingly to games, such as game creature blending [86] and interactive fiction blending [87].", "startOffset": 159, "endOffset": 163}, {"referenceID": 82, "context": "Recently Snodgrass and Onta\u00f1\u00f3n [88] explored domain transfer in level generation across platforming games, and Guzdial et al.", "startOffset": 31, "endOffset": 35}, {"referenceID": 83, "context": "[89] used concept blending to meld different level designs from Super", "startOffset": 0, "endOffset": 4}, {"referenceID": 84, "context": "Gow and Corneli [90] proposed a framework for blending two games together into a new game, including mechanics, but no implementation yet exists.", "startOffset": 16, "endOffset": 20}, {"referenceID": 28, "context": "[30] allows a designer to set some high-level design parameters (number of rooms in a dungeon, length of optimal player path), but this approach only works if all design factors are known at training time and a Bayes Net is a suitable technique.", "startOffset": 0, "endOffset": 4}, {"referenceID": 54, "context": "Similarly, Snodgrass and Onta\u00f1\u00f3n [59] allow the user to define constraints (e.", "startOffset": 33, "endOffset": 37}, {"referenceID": 85, "context": ", subtracting the latent space image of blank-faced person from a smiling one is the smile vector) [92].", "startOffset": 99, "endOffset": 103}, {"referenceID": 86, "context": "This would allow a PCGML system to take on several design pattern roles, including AI as Role-Model, Trainee, Editable, Guided, Co-Creator, Adversary, and Spectacle [93].", "startOffset": 165, "endOffset": 169}, {"referenceID": 18, "context": "Summerville, Mateas [19]: Cat.", "startOffset": 20, "endOffset": 24}, {"referenceID": 19, "context": "[20]: Cat.", "startOffset": 0, "endOffset": 4}, {"referenceID": 47, "context": "[51]: Real Grid Starcraft II Maps Convolutional Neural Co-creative generation", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "Summerville, Mateas [37]: Cat.", "startOffset": 20, "endOffset": 24}, {"referenceID": 29, "context": "[31]: Cat.", "startOffset": 0, "endOffset": 4}, {"referenceID": 44, "context": "Snodgrass, Onta\u00f1\u00f3n [48]: Cat.", "startOffset": 19, "endOffset": 23}, {"referenceID": 30, "context": "Snodgrass, Onta\u00f1\u00f3n [32]: Cat.", "startOffset": 19, "endOffset": 23}, {"referenceID": 54, "context": "Snodgrass, Onta\u00f1\u00f3n [59]: Cat.", "startOffset": 19, "endOffset": 23}, {"referenceID": 55, "context": "Snodgrass, Onta\u00f1\u00f3n [60]: Cat.", "startOffset": 19, "endOffset": 23}, {"referenceID": 56, "context": "[61]: Cat.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "Guzdial and Riedl [33]: Cat.", "startOffset": 18, "endOffset": 22}, {"referenceID": 34, "context": "[38]: Cat.", "startOffset": 0, "endOffset": 4}, {"referenceID": 67, "context": "Shaker, Abou-Zleikha [73]: Real Seq.", "startOffset": 21, "endOffset": 25}, {"referenceID": 1, "context": "the paper to play a similar role as the SearchBased Procedural Content Generation paper [2], which pointed out existing research as well as work that was yet to be done.", "startOffset": 88, "endOffset": 91}], "year": 2017, "abstractText": "Adam Summerville1, Sam Snodgrass2, Matthew Guzdial3, Christoffer Holmg\u00e5rd4, Amy K. Hoover5, Aaron Isaksen6, Andy Nealen6, and Julian Togelius6, 1Department of Computational Media, University of California, Santa Cruz, CA 95064, USA 2College of Computing and Informatics, Drexel University, Philadelpia, PA 19104, USA 3School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA 30332, USA 4Duck and Cover Games ApS, 1311 Copenhagen K, Denmark 5College of Arts, Media and Design, Northeastern University, Boston, MA 02115, USA 6Department of Computer Science and Engineering, New York University, Brooklyn, NY 11201, USA emails: asummerv@ucsc.edu, sps74@drexel.edu, mguzdial3@gatech.edu, christoffer@holmgard.org, amy.hoover@gmail.com, aisaksen@appabove.com, nealen@nyu.edu, julian@togelius.com", "creator": "LaTeX with hyperref package"}}}