{"id": "1702.03447", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Feb-2017", "title": "A Collective, Probabilistic Approach to Schema Mapping: Appendix", "abstract": "In except deleted we making raise requiring related keep \" A Collective, Probabilistic Approach to Schema Mapping. \" We small came 1,000 previous example, earmarked devised concerning, others proof for its characteristics partly called in all main hand.", "histories": [["v1", "Sat, 11 Feb 2017 19:18:41 GMT  (66kb)", "http://arxiv.org/abs/1702.03447v1", "This is the appendix to the paper \"A Collective, Probabilistic Approach to Schema Mapping\" accepted to ICDE 2017"]], "COMMENTS": "This is the appendix to the paper \"A Collective, Probabilistic Approach to Schema Mapping\" accepted to ICDE 2017", "reviews": [], "SUBJECTS": "cs.DB cs.LG", "authors": ["angelika kimmig", "alex memory", "renee j miller", "lise getoor"], "accepted": false, "id": "1702.03447"}, "pdf": {"name": "1702.03447.pdf", "metadata": {"source": "CRF", "title": "A Collective, Probabilistic Approach to Schema Mapping: Appendix", "authors": ["Angelika Kimmig", "Ren\u00e9e J. Miller", "Lise Getoor"], "emails": ["angelika.kimmig@cs.kuleuven.be", "memory@cs.umd.edu", "miller@cs.toronto.edu", "getoor@ucsc.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 2.\n03 44\n7v 1\n[ cs\n.D B\n] 1\n1 Fe\nb 20\n17\nA Collective, Probabilistic Approach\nto Schema Mapping: Appendix\nAngelika Kimmig\nKU Leuven\nangelika.kimmig@cs.kuleuven.be\nAlex Memory\nUniversity of Maryland\nmemory@cs.umd.edu\nRene\u0301e J. Miller\nUniversity of Toronto\nmiller@cs.toronto.edu\nLise Getoor\nUC Santa Cruz\ngetoor@ucsc.edu\nIn this appendix we provide additional supplementary material to \u201cA Collective, Probabilistic Approach to Schema Mapping\u201d [1]. We include an additional extended example, supplementary experiment details, and proof for the complexity result stated in the main paper."}, {"heading": "I. EXAMPLE OF SELECTION OVER ST TGDS", "text": "We extend the running example from the main paper to illustrate objective Eq. (9) of [1]. We use a reduced candidate set C\u2032 = {\u03b81, \u03b83} (Figure 1(d) in [1]) and the data in\nFigure 1(b)-(c) in [1], but omit the leader relation. A universal solution K\u03b81 of I contains the task tuples (BigData, Bob, Null1) and (ML, Alice, Null2), while a K\u03b83 contains the task tuples (BigData, Bob, Null3) and (ML, Alice, Null4) and the org tuples (Null3, IBM) and (Null4, SAP).\nFor \u03b81, creates is 1 for tuple task(BigData, Bob, Null1), and 0 for all other tuples, and covers is 2/3 for task(ML, Alice, 111) and 0 otherwise. This is because task(ML, Alice, Null2) partially explains the latter via a homomorphismmapping Null2 to 111. Similarly, for \u03b83, creates is 1 for task(BigData, Bob, Null3) and org(Null3,IBM), but 0 for task(ML, Alice, Null4) and org(Null4,SAP), which partially explain task(ML, Alice, 111) and org(111, SAP) to degree 3/3 and 2/2 respectively, via a homomorphism mapping Null4 to 111, with corresponding values for covers. The different subsets of candidate st tgds thus obtain the following values for the individual parts and the total of objective function Eq. (9) of [1].\nM \u2211 1\u2212 explains \u2211\nerror size Eq. (9) of [1] {} 4 0 0 4 {\u03b81} 31/3 1 3 71/3 {\u03b83} 2 2 4 8\n{\u03b81, \u03b83} 2 3 7 12\nAs the data example is small compared to the mappings, the minimal value for the objective is that of the empty mapping, but we also see that {\u03b81} is preferred over {\u03b83}, which in turn is preferred over {\u03b81, \u03b83}. The reason is that while \u03b83 covers more tuples than \u03b81, it also produces more errors and is larger. The fact that the empty mapping has a better objective value is an important guard against overfitting on too little data; this is easily overcome by slightly larger data instances. If we add at least five more projects X of the same kind as the ML one, i.e., pairs of tuples proj(X,N,1) and task(X,Alice,111), the preferred mapping is {\u03b83}, as the empty mapping cannot explain the new target tuples, \u03b81 explains each to degree 2/3, and \u03b83 fully explains them (while no mapping introduces additional errors)."}, {"heading": "II. SCENARIO GENERATION", "text": "We provide additional details of the scenario generation process discussed in Section VI-A of [1].\niBench. We used seven iBench primitives [2], [3]: CP copies a source relation to the target, changing its name. ADD copies a source relation and adds attributes; DL does the same, but removes attributes instead; and ADL adds and removes attributes to the same relation. The number that are added or removed are controlled by range parameters, which we set to (2,4). ME copies two relations, after joining them, to form a target relation. VP copies a source relation to form two, joined, target relations. VNM is the same as VP but introduces an additional target relation to form a N-to-M relationship between the other target relations.\nModifying the metadata evidence through random correspondences. If \u03c0Corresp > 0 (cf. Table I of [1]), we introduce additional correspondences as follows. We randomly select \u03c0Corresp percent of the target relations. For every selected target relation T , we randomly select a source relation S from those of the iBench primitive invocations not involving T (so Clio [4] can generate MG as part of C). For each attribute of T , we introduce a correspondence to a randomly selected attribute of S.\nModifying the data instance. As certain errors and certain unexplained tuples can be removed prior to optimization (cf. Section III-C of [1]), we restrict data instance modifications to non-certain errors and non-certain unexplained tuples (with respect to MG). Note that in our scenarios, MG \u2286 C, and thusKG \u2286 KC. So each tuple in KC is either generated by both MG and C\u2212MG, only by MG (i.e., a non-certain error tuple if deleted from J), or only by C\u2212MG (i.e., a non-certain unexplained tuple if added to J). As tuples in KC may have nulls, we take into account homomorphisms when determining which of these cases applies to a given tuple. We randomly select \u03c0Unexplained% of the potential non-certain unexplained tuples, which we add to J , and \u03c0Errors% of the potential noncertain error tuples, which we delete from J ."}, {"heading": "III. MAPPING SELECTION IS NP-HARD", "text": "We provide a proof for the complexity result stated in Section III-C of the main paper.\nTheorem 1: The mapping selection problem for full st tgds as defined in Eq. (4) of [1] is NP-hard.\nProof: We use a reduction from SET COVER, which is well known to be NP-complete, and is defined as follows:\nGiven a finite set U , a finite collection R = {Ri | Ri \u2286 U, 1 \u2264 i \u2264 k} and a natural number n \u2264 k, is there a set R\u2032 \u2286 R consisting of at most n sets Ri such that \u22c3\nRi\u2208R \u2032 Ri = U?\nWe first consider the decision variant of mapping selection, which is defined as follows:\nGiven schemas S, T, a data example (I, J), a set C of candidate full st tgds, and a natural number m, is there a selection M \u2286 C with F (M) \u2264 m?\nwhere F (M) is the function minimized in Eq. (4) of [1], i.e.,\nF (M) = \u2211\nt\u2208J\n[1\u2212 explainsfull(M, t)]\n+ \u2211\nt\u2208KC\u2212J\n[errorfull(M, t)] + sizem(M) (1)\nWe construct a mapping selection decision instance from a SET COVER instance as follows. We set m = 2n, introduce an auxiliary domain D = {1, . . . ,m+ 1}, and define\nS = {Ri/2 | Ri \u2208 R}\nT = {U/2}\nC = {Ri(X,Y ) \u2192 U(X,Y ) | Ri \u2208 R}\nJ = {U(x, y) | (x, y) \u2208 U \u00d7D} I = \u22c3\nRi\u2208R\n{Ri(x, y) | (x, y) \u2208 Ri \u00d7D}\nIt is easily verified that this construction is polynomial in the size of the SET COVER instance. We next show that the answers to SET COVER and the constructed mapping selection problem coincide.\nFor each Ri, the candidate st tgd \u03b8i = Ri(X,Y ) \u2192 U(X,Y ) has size two, makes no errors (as Ri \u2286 U ), and for each x \u2208 Ri explains the tuples U(x, 1), . . . , U(x,m+1). We thus have\nF (M) = \u2211\nt\u2208J\n[1\u2212 explainsfull(M, t)] + 2 \u00b7 |M| (2)\n= (m+ 1) \u00b7\n(\n|U | \u2212 | \u22c3\n\u03b8i\u2208M\nRi|\n)\n+ 2 \u00b7 |M| (3)\nA mapping M \u2286 C with F (M) \u2264 m = 2n thus exists if and only if | \u22c3\n\u03b8i\u2208M Ri| = |U | and |M| \u2264 n, which is exactly the\ncase where M encodes a covering selection with at most n sets. Furthermore, if such mappings exist, the optimal mapping according to Eq. (4) of [1] is one of them, and a polynomial time solution for mapping selection with full st tgds can thus be used to find a candidate solution that can be verified or rejected in polynomial time to answer SET COVER.\nWe note that the mapping selection problem for arbitrary st tgds as defined in Eq. (9) of [1] coincides with the one in Eq. (4) of [1] if all candidates are full, and thus is NPhard as well. Furthermore, the reduction used in the proof directly generalizes to the following weighted version of the optimization criterion:\nF (M) =w1 \u00b7 \u2211\nt\u2208J\n[1\u2212 explainsfull(M, t)]\n+ w2 \u00b7 \u2211\nt\u2208KC\u2212J\n[errorfull(M, t)] + w3 \u00b7 \u2211\n\u03b8\u2208M\nsize(\u03b8)\nwith positive integer weights w1, w2, w3 and any size function that assigns equal size to the candidate mappings \u03b8i = Ri(X,Y ) \u2192 U(X,Y ). More precisely, setting m = size(\u03b81) \u00b7 w3 \u00b7 n in the proof above shows that this generalization is NP-hard as well."}], "references": [{"title": "A collective, probabilistic approach to schema mapping", "author": ["A. Kimmig", "A. Memory", "R.J. Miller", "L. Getoor"], "venue": "ICDE, (accepted) 2017.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2017}, {"title": "STBenchmark: towards a benchmark for mapping systems", "author": ["B. Alexe", "W.-C. Tan", "Y. Velegrakis"], "venue": "PVLDB, vol. 1, no. 1, pp. 230\u2013244, 2008.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "The iBench Integration Metadata Generator", "author": ["P.C. Arocena", "B. Glavic", "R. Ciucanu", "R.J. Miller"], "venue": "PVLDB, vol. 9, no. 3, pp. 108\u2013119, 2015.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Clio: Schema Mapping Creation and Data Exchange", "author": ["R. Fagin", "L.M. Haas", "M.A. Hern\u00e1ndez", "R.J. Miller", "L. Popa", "Y. Velegrakis"], "venue": "Conceptual Modeling: Foundations and Applications - Essays in Honor of John Mylopoulos, 2009, pp. 198\u2013236.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "In this appendix we provide additional supplementary material to \u201cA Collective, Probabilistic Approach to Schema Mapping\u201d [1].", "startOffset": 122, "endOffset": 125}, {"referenceID": 0, "context": "(9) of [1].", "startOffset": 7, "endOffset": 10}, {"referenceID": 0, "context": "We use a reduced candidate set C = {\u03b81, \u03b83} (Figure 1(d) in [1]) and the data in Figure 1(b)-(c) in [1], but omit the leader relation.", "startOffset": 60, "endOffset": 63}, {"referenceID": 0, "context": "We use a reduced candidate set C = {\u03b81, \u03b83} (Figure 1(d) in [1]) and the data in Figure 1(b)-(c) in [1], but omit the leader relation.", "startOffset": 100, "endOffset": 103}, {"referenceID": 0, "context": "(9) of [1].", "startOffset": 7, "endOffset": 10}, {"referenceID": 0, "context": "(9) of [1] {} 4 0 0 4 {\u03b81} 31/3 1 3 71/3 {\u03b83} 2 2 4 8 {\u03b81, \u03b83} 2 3 7 12", "startOffset": 7, "endOffset": 10}, {"referenceID": 0, "context": "We provide additional details of the scenario generation process discussed in Section VI-A of [1].", "startOffset": 94, "endOffset": 97}, {"referenceID": 1, "context": "We used seven iBench primitives [2], [3]: CP copies a source relation to the target, changing its name.", "startOffset": 32, "endOffset": 35}, {"referenceID": 2, "context": "We used seven iBench primitives [2], [3]: CP copies a source relation to the target, changing its name.", "startOffset": 37, "endOffset": 40}, {"referenceID": 0, "context": "Table I of [1]), we introduce additional correspondences as follows.", "startOffset": 11, "endOffset": 14}, {"referenceID": 3, "context": "For every selected target relation T , we randomly select a source relation S from those of the iBench primitive invocations not involving T (so Clio [4] can generate MG as part of C).", "startOffset": 150, "endOffset": 153}, {"referenceID": 0, "context": "Section III-C of [1]), we restrict data instance modifications to non-certain errors and non-certain unexplained tuples (with respect to MG).", "startOffset": 17, "endOffset": 20}, {"referenceID": 0, "context": "(4) of [1] is NP-hard.", "startOffset": 7, "endOffset": 10}, {"referenceID": 0, "context": "(4) of [1], i.", "startOffset": 7, "endOffset": 10}, {"referenceID": 0, "context": "(4) of [1] is one of them, and a polynomial time solution for mapping selection with full st tgds can thus be used to find a candidate solution that can be verified or rejected in polynomial time to answer SET COVER.", "startOffset": 7, "endOffset": 10}, {"referenceID": 0, "context": "(9) of [1] coincides with the one in Eq.", "startOffset": 7, "endOffset": 10}, {"referenceID": 0, "context": "(4) of [1] if all candidates are full, and thus is NPhard as well.", "startOffset": 7, "endOffset": 10}], "year": 2017, "abstractText": "We extend the running example from the main paper to illustrate objective Eq. (9) of [1]. We use a reduced candidate set C = {\u03b81, \u03b83} (Figure 1(d) in [1]) and the data in Figure 1(b)-(c) in [1], but omit the leader relation. A universal solution K\u03b81 of I contains the task tuples (BigData, Bob, Null1) and (ML, Alice, Null2), while a K\u03b83 contains the task tuples (BigData, Bob, Null3) and (ML, Alice, Null4) and the org tuples (Null3, IBM) and (Null4, SAP).", "creator": "dvips(k) 5.996 Copyright 2016 Radical Eye Software"}}}