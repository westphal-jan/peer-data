{"id": "1702.03767", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Feb-2017", "title": "Is Big Data Sufficient for a Reliable Detection of Non-Technical Losses?", "abstract": "Non - technical analysts (NTL) contain soon rest distribution there generates in power transformer example include, giving although anyone. given, generates accessory often faulty meters. In country strengthen, they thus range up move 51% only during increase telecommunication distributed. In means to scans NTLs, laser learning solutions any used saying teach irregular consumption patterns some companies data are inspection results. The Big Data context last in modern machine experience unexpected given sincere of deriving good reviewed from simply analyze more statistics, longer the justify of looking thursday psychology and models. However, the indicates taken evaluated customers now may biased, does. blog. it mean having majority the than bringing all firms. As a consequence, battery learning types trained a related special unlikely fact biased as well now defined advantage and unfamiliar findings of whether phone cause NTL should still. In electric learning, does hold is called covariate shift taken has actually has issue its same poetry its NTL detection almost. In this creating, way present a fiction framework there mutational and deciphering covariate likely. We apply it which without offering provided set later Brazil that smaller of 51. 6M makers together 820K clearance indication. We seen but some distinctive rarely a stronger covariate particular rest none, way poll probably relatively. In particular, previous inspections believed concerns on meant residential for customer required over that both have not poorly spread among of persons form retailers. This framework this about to though iraqi its. commercial product other NTL detection.", "histories": [["v1", "Mon, 13 Feb 2017 13:33:47 GMT  (1503kb,D)", "https://arxiv.org/abs/1702.03767v1", null], ["v2", "Tue, 25 Jul 2017 04:35:45 GMT  (1503kb,D)", "http://arxiv.org/abs/1702.03767v2", "Proceedings of the 19th International Conference on Intelligent System Applications to Power Systems (ISAP 2017)"]], "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["patrick glauner", "angelo migliosi", "jorge meira", "petko valtchev", "radu state", "franck bettinger"], "accepted": false, "id": "1702.03767"}, "pdf": {"name": "1702.03767.pdf", "metadata": {"source": "CRF", "title": "Is Big Data Sufficient for a Reliable Detection of Non-Technical Losses?", "authors": ["Patrick Glauner", "Angelo Migliosi", "Jorge Augusto Meira", "Petko Valtchev", "Radu State", "Franck Bettinger"], "emails": ["jorge.meira}@uni.lu", "valtchev.petko@uqam.ca", "franck.bettinger@choiceholding.com"], "sections": [{"heading": null, "text": "Is Big Data Sufficient for a Reliable Detection of Non-Technical Losses?\nPatrick Glauner\u2217, Angelo Migliosi\u2217, Jorge Augusto Meira\u2217, Petko Valtchev\u2217\u2020, Radu State\u2217 and Franck Bettinger\u2021 \u2217Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg\n2721 Luxembourg, Luxembourg Email: {first.last, jorge.meira}@uni.lu\n\u2020Department of Computer Science, University of Quebec in Montreal, H3C 3P8 Montreal, Canada\nEmail: valtchev.petko@uqam.ca \u2021CHOICE Technologies Holding Sa\u0300rl\n2453 Luxembourg, Luxembourg Email: franck.bettinger@choiceholding.com\nAbstract\u2014Non-technical losses (NTL) occur during the distribution of electricity in power grids and include, but are not limited to, electricity theft and faulty meters. In emerging countries, they may range up to 40% of the total electricity distributed. In order to detect NTLs, machine learning methods are used that learn irregular consumption patterns from customer data and inspection results. The Big Data paradigm followed in modern machine learning reflects the desire of deriving better conclusions from simply analyzing more data, without the necessity of looking at theory and models. However, the sample of inspected customers may be biased, i.e. it does not represent the population of all customers. As a consequence, machine learning models trained on these inspection results are biased as well and therefore lead to unreliable predictions of whether customers cause NTL or not. In machine learning, this issue is called covariate shift and has not been addressed in the literature on NTL detection yet. In this work, we present a novel framework for quantifying and visualizing covariate shift. We apply it to a commercial data set from Brazil that consists of 3.6M customers and 820K inspection results. We show that some features have a stronger covariate shift than others, making predictions less reliable. In particular, previous inspections were focused on certain neighborhoods or customer classes and that they were not sufficiently spread among the population of customers. This framework is about to be deployed in a commercial product for NTL detection.\nIndex Terms\u2014Bias, big data, covariate shift, machine learning, non-technical losses.\nI. INTRODUCTION Losses in power grids can be grouped into technical losses and non-technical losses. Technical losses occur naturally, which are mainly caused by internal electrical resistance of infrastructure components. Non-technical losses (NTL) appear during power distribution and include, but are not limited to, the following causes [1], [2]:\n\u2022 Meter tampering in order to record lower consumptions \u2022 Bypassing meters by rigging lines from the power source \u2022 Arranged false meter readings by bribing meter readers \u2022 Faulty or broken meters \u2022 Technical and human errors in meter readings, data\nprocessing and billing\nIn practice, NTLs primarily consist of electricity theft and cause major problems to electricity providers, including financial losses and a decrease of stability and reliability. Furthermore, NTLs lead to an extra use of limited natural resources which in turn increases pollution. They can range up to 40% of the total electricity distributed in countries such as Brazil, India, Malaysia or Lebanon [3], [4].\nThe predominant research direction reported in the recent literature is the use of machine learning/data mining methods, which learn anomalous behavior from customer data and known irregular behavior that was reported through inspection results. However, carrying out inspections is expensive, as it requires physical presence of technicians. It is therefore important that the trained models make accurate predictions.\nFor about the last fifteen years, the Big Data paradigm followed in machine learning has been to gather more data rather than improving models. Hence, one may assume that having simply more customer and inspection data would help to detect NTL more accurately. However, in many cases, the data is biased as depicted in Fig. 1. Concretely, the customers978-1-5090-4000-1/17/$31.00 \u00a92017 IEEE\nar X\niv :1\n70 2.\n03 76\n7v 2\n[ cs\n.L G\n] 2\n5 Ju\nl 2 01\n7\ninspected are a sample of the overall population of customers. In this example, there is a spatial bias. Hence, the inspections do not represent the overall population of customers. As a consequence, when learning from the inspection results, a bias is learned, making predictions less reliable. In technical terms, this bias is called covariate shift or sampling bias [5]. Aside from spatial covariate shift, there may be other types of covariate shift in the data, such as the meter type, connection type, etc.\nThe main contributions of this paper are: \u2022 We present a novel framework for quantifying and visu-\nalizing covariate shift at different hierarchical levels. \u2022 We investigate the importance of covariate shift to NTL\ndetection in Big Data approaches and show that it leads to unreliable NTL predictors. \u2022 We report the covariate shift of different features in a real world data set consisting of 3.6M Brazilian customers and 820K inspection results. \u2022 We visualize how different local areas are affected by covariate shift at different hierarchical levels.\nTo the best of our knowledge, we are not aware of any previously published research that addresses this topic for NTL detection. We are convinced that an accurate study of this topic is necessary in order to advance NTL detection by reducing the covariate shift in data sets in the future."}, {"heading": "II. RELATED WORK", "text": "From an electrical engineering perspective, energy balance methods [6] can be applied to the detection of NTL. However, this requires topological information of the distribution network and does not reflect a change of network. In practice, the network topology undergoes rapid changes in emerging countries, i.e. the countries in which NTL is a particular issue.\nThe predominant methodology used in the literature is employing artificial intelligence (AI) to this anomaly detection problem. Historically, AI has been based on rule-based expert systems that incorporate expert knowledge. However, in many cases, describing a problem domain is challenging due to its complexity and temporal dynamics. Therefore, over the years, the fields of machine learning and data mining have become more popular. These methods learn models from data without being explicitly programmed.\nA data set of ~22K customers is used in [7] for training a neural network. It uses the average consumption of the previous 12 months and other customer features such as location, type of customer, voltage and whether there are meter reading notes during that period. On the test set, an accuracy of 0.8717, a precision of 0.6503 and a recall of 0.2947 are reported. Consumption profiles of 5K Brazilian industrial customer profiles are analyzed in [8]. Each customer profile contains 10 features including the demand billed, maximum demand, installed power, etc. In this setting, a support vector machine slightly outperforms k-nearest neighbors and a neural network, for which test accuracies of 0.9628, 0.9620 and 0.9448, respectively, are reported.\nWe have extensively reviewed the state of the art in our previous work and identified the open challenges in NTL detection [2]. We have previously addressed the class imbalance and evaluation metric selection, when we showed that a large-scale machine learning approach outperformed rule-based Boolean and fuzzy logic expert systems [9]. Furthermore, we have shown that the neighborhood of customers yields significant information in order to decide whether a customer causes a NTL or not [10], [11]."}, {"heading": "III. COVARIATE SHIFT", "text": "In this paper, we address the challenge of covariate shift. It refers to the problem of training data (i.e. the set of inspection results) and production data (i.e. the set of customers to generate inspections for) having different distributions. This fact leads to unreliable NTL predictors when learning from this training data. In this section, we describe how to quantify it. Historically, covariate shift has been a long-standing issue in statistics. For example, The Literary Digest sent out 10M questionnaires in order to predict the outcome of the 1936 US Presidential election. They received 2.4M returns. Nonetheless, the predicted result proved to be wrong. The reason for this was that they used car registrations and phone directories to compile a list of recipients. In that time, the households that had a phone or a car represented a biased sample of the overall population. In contrast, George Gallup only interviewed 3K handpicked people, which were an unbiased sample of the population. As a consequence, Gallup could predict the outcome of the election very well [12]."}, {"heading": "A. Definition", "text": "Customers previously inspected are a sample of the overall population of customers. However, that sample may be biased, i.e. it does not represent the population of all customers, as visualized in Fig. 1. A reason for that is that previous inspections were largely focused on certain criteria and were not sufficiently spread among the population. The problem of training data and production data having different distributions has initially been addressed in the field of computational learning theory [13], which also calls it covariate shift, sampling bias or sample selection bias. It can be defined in mathematical terms as follows [5]:\n\u2022 Assume that all examples are drawn from a distribution D with domain X \u00d7 Y \u00d7 S, \u2022 where X is the feature space, \u2022 Y is the label space, \u2022 and S is {0, 1}. Examples (x, y, s) are drawn independently from D. s = 1 denotes a selected example, whereas s = 0 denotes the opposite. The training is performed on a sample that comprises all examples that have s = 1. P (s|x, y) = P (s|x) implies that s is independent of y given x. In this case, the selected sample is biased but the bias only depends on the feature vector x. This problem is called covariate shift [5]."}, {"heading": "B. Big Data", "text": "In the past fifteen years, the Big Data paradigm followed can be summarized: \u201cIt\u2019s not who has the best algorithm that wins. It\u2019s who has the most data.\u201d [14] Concretely, this approach reflects the desire of deriving better conclusions from simply analyzing more data, without the necessity of looking at theory and models. However, taking covariate shift into account, just having more data is not sufficient. In this case, having less data that is more representative seems to be the answer."}, {"heading": "C. Affected Classifiers", "text": "It has been shown that some machine learning algorithms are not affected by covariate shift, whereas others are [5].\n1) Local learner: The prediction of the learner depends asymptotically only on P (y|x). Hence, it is not affected by covariate shift. Examples are logistic regression and hardmargin support vector machine (SVM).\n2) Global learner: The prediction of the learner depends asymptotically on both, P (y|x) and P (x). Hence, it is affected by covariate shift. Example: Decision tree learners such as ID3 or C4.5 [15] recursively split the input space by choosing the remaining most discriminative feature of a data set. To predict, the learned tree is traversed top-down. Other examples are naive Bayes and soft-margin SVM."}, {"heading": "D. Quantification", "text": "The Kullback-Leibler divergence is a measure of the difference of two probability distributions. However, it is challenging (1) to adapt this measure to multi-dimensional data that is a combination of discrete and continuous features, which is common in machine learning, and (2) to define criteria when a distance is an indicator for a covariate shift.\nTherefore, a preferred methodology for quantifying covariate shift is: First, we add a feature s and assign the values 1 or 0 to the training data (s = 1) or production data (s = 0), respectively. These data sets are furthermore merged into one data set. This latter is split into a training set X1 (with no relation to the original training set) and a test set X2. The objective is to develop a supervised learning method capable of predicting the feature s using X1. The performance of the classifier on X2 is then quantified using the Matthews correlation coefficient (MCC)\nTP \u00d7 TN \u2212 FP \u00d7 FN\u221a (TP + FP )(TP + FN)(TN + FP )(TN + FN) , (1)\nwhich measures the accuracy of binary classifiers taking into account the imbalance of both classes, ranging from \u22121 to +1 [16]. The greater the MCC, the greater the covariate shift. A concrete threshold for covariate shift depends on the problem, however 0.2 has been proposed [17]. Though a low MCC does not automatically imply the lack of a covariate shift, a significant MCC value is an indicator of covariate shift.\nWe extend this methodology in Algorithm 1 by introducing the following novelties:\n1) Tree classifier: Decision tree learning is affected by covariate shift. Decision trees scale to very large data\nsets while they allow to learn non-linearities. Softmargin SVMs are also global learners, however, for large data sets only a linear kernel is learnable in a feasible amount of time. 2) Model selection: We want to find a model which is able to distinguish between both distributions. Thus maximizing the MCC on the test set is equivalent to finding the best two-class classification between production data and original training data. For this, we optimize the five most important tree model parameters by randomly drawing from probability distributions: Max. number of leaves, max. number of levels, measure of the purity of a split, min. number of samples required to be at a leaf and min. number of samples required to split a node. 3) Cross-validation: We also split the data set into k folds in order to reduce the overfitting. This leads to a more reliable model for covariate shift quantification. The MCC per model, denoted by MCC, is the average of the MCCs of the k test sets. The standard deviation of the k test MCCs serves as the reliability of MCC. The lower the standard deviation, the more reliable MCC.\nNote: The inspection results are not taken into account as covariate shift only concerns the distributions of the inputs.\nAlgorithm 1 Quantifying covariate shift. 1: result\u2190 0 2: reliability \u2190 0 3: selected\u2190 train data.add feature(s, 1) 4: not selected\u2190 prod data.add feature(s, 0) 5: data\u2190 selected \u222a not selected 6: folds\u2190 cv folds(data, k) 7: for model in get model candidates() do 8: mccs\u2190 list() 9: for fold in folds do 10: Xtrain, Xtest, ytrain, ytest \u2190 fold 11: classifier \u2190 DecisionTree(model) 12: classifier.train(Xtrain, ytrain) 13: ypred \u2190 classifier.predict(Xtest) 14: mccs.append(MCC(ytest, ypred)) 15: end for 16: mcc mean\u2190 mean(mccs) 17: if mcc mean > result then 18: result\u2190 mcc mean 19: reliability \u2190 std(mccs) 20: end if 21: end for 22: return result, reliability\nIV. EVALUATION"}, {"heading": "A. Data", "text": "The data used in this paper comes from an electricity provider in Brazil. First, it consists of 3.6M customers. A complete list of the customer master data used in the following experiments is depicted in Table I. The categorical features\nclass, voltage, number of wires, contract status and meter type are converted to one-hot coding. Second, the data contains 820K inspection results, such as inspection date, presence of fraud or irregularity, type of NTL and inspection notes. 620K customers have been inspected at least once and the remaining ~3M customers have never been inspected. Third, there are 195M meter readings from 2011 to 2016 such as consumption in kWh, date of meter reading and number of days between meter readings.\nB. Implementation Notes\nAll computations were run on a server with 24 cores and 128 GB of RAM. The entire code was implemented in Python using scikit-learn [18] for machine learning. scikit-learn allows to distribute the training of the cross-validated classifiers among all cores. The maps were plotted using cartopy [19]. In total, all results and plots reported in this paper were computed in 12 hours using this infrastructure. Our implementation is available as open source: http://github.com/pglauner/SpatialBiasNTL."}, {"heading": "C. Model Parameters", "text": "In the following experiments, we use k = 10-fold crossvalidation. In each experiment, we train 1K trees, which are 100 different tree models trained on each of the 10 folds. We optimize the five tree model parameters by randomly drawing from predefined uniform probability distributions depicted in Table II. We have chosen these ranges based on best practice recommendations and our own experience. Furthermore, the two classes (s = 1 and s = 0) are imbalanced, i.e. there are more examples of the non-inspected customers than the inspected ones. In order to take this into account during training, we associate weights with the classes such that the examples of the minority class have stronger impact."}, {"heading": "D. Global Covariate Shifts", "text": "In the following experiments, we compute different global types of covariate shift by using all customers in each experiment. We therefore do not split the customers into different geographical areas.\nWe have previously presented the customer master data features available in Table I. We compute the global covariate\nshift of each of these features. We report our results in Table III. MCCmax denotes the maximum average of the MCCs of the k = 10 test sets among all 100 tree models trained on a feature. \u03c3 denotes the standard deviation of those k = 10 MCC test scores, which is a reliability measure of MCCmax.\nOverall, the strongest covariate shift is in the location with a MCC value of 0.22367. This means that previous inspections are mostly biased towards the location of customers. The location is also the only feature that is beyond the threshold of 0.2 mentioned in Section III-D. The features class, number of wires and meter type are below the threshold but are greater than 0.1. There is almost no covariate shift of previous inspections towards the voltage and contract status features. The standard deviation of the MCCs is the greatest for the contract status. The reason for this is a strong overfit in one of the folds. All other MCCs have a much lower standard\ndeviation, making them more reliable. Next, we create compound features that are composed of multiple features. Due to the great number of possible combinations, we assess all 2-combinations as well as the 6- combination of all features. We visualize the MCCs for all 2-combinations in Fig. 2 and reported the MCCs in Table IV. For the 6-combination comprising all features, we computed MCCmax = 0.27325, which is the maximum covariate shift of all compound features. Therefore, the spatial covariate shift contributes to this covariate shift the most, however, the other covariate shifts contribute a fraction as well."}, {"heading": "E. Local Covariate Shifts", "text": "We now entirely focus on spatial covariate shift since it is the strongest one among the different types of covariate shift. In the following experiments we compute local covariate shifts by splitting the customers in different locations. The data set provides the following divisions in the following hierarchical order:\n1) 9 regions 2) 261 municipalities 3) 1,380 localities 4) 19,026 neighborhoods We plot the local spatial covariate shifts of these four levels of granularity in Fig. 3. All customers are located in one Brazilian state. We observe that spatial covariate shift is smoothened for regional level in Fig. 3a. It becomes increasingly more granular at municipal, local and neighborhood levels in Figs. 3a through 3d, respectively. We also notice that the spatial covariate shifts at lower levels tend to increase, which is depicted by increasing upper limits of the color bars."}, {"heading": "F. Discussion", "text": "We have shown that covariate shift exists in our real world data set. The features of the customer data that are most\naffected by covariate shift are the location, followed by class, number of wires and meter type. Classifiers that use other features such as the voltage or contract status instead tend to be more reliable. We have also shown that the spatial covariate shift exists on different levels of granularity and that municipalities and localities with very strong covariate shifts exist. Subsequently, these local covariate shifts have significant impact on the covariate shifts on higher levels or even globally on the entire data set. Therefore, using all inspection results of the data set for training a NTL predictor from a Big Data perspective leads to biased models that may not reliably detect NTL. As a consequence, reducing the spatial covariate shift in the data set must be a priority in order to learn reliable NTL predictors.\nHowever, the finer the hierarchical granularity, the more divisions cannot be used for the computations for the following reasons. First, using k = 10-fold cross-validation, training is only possible if a division has at least k customers. Second, the k \u2212 1 folds used for training must have examples of both classes. Third, the MCC can only be computed for denominator 6= 0, which is the case for (TP > 0 \u2227 TN > 0)\u2228(FP > 0\u2227FN > 0). If the test MCC cannot be computed for a fold of a model, only the MCCs of the remaining folds are used in cross-validation. If no MCCs can be computed for a division, we skip it in the plotting. For instance, this effect has become most apparent at neighborhood level in the west of that state due to the low population density."}, {"heading": "V. CONCLUSION AND FUTURE WORK", "text": "Covariate shift is the problem of training data and production data having different distributions. In this work, we have proposed a novel framework for quantifying and visualizing covariate shift in spatial data sets. In the context of nontechnical loss (NTL) detection, we showed that there is a covariate shift between the inspected customers and the overall population of customers. We used a real world data set from Brazil that consists of 3.6M customers and 820K inspection results. We showed that some features have a stronger covariate shift than others. In particular, the spatial covariate shift is the strongest and appears in different hierarchical levels. Subsequently, machine learning models trained on this data will lead to unreliable NTL predictions. Our contribution will allow domain experts to model more reliable rules for NTL predictors.\nNext, we will use and amend spatial point processes [20] for reducing the spatial covariate shift in our data set in order to train more reliable NTL predictors."}, {"heading": "ACKNOWLEDGMENT", "text": "We would like to thank Lautaro Dolberg, Diogo Duarte and Yves Rangoni from CHOICE Technologies Holding Sa\u0300rl for contributing many good ideas to our discussions. This work has been partially funded by the Luxembourg National Research Fund."}], "references": [{"title": "Non-technical losses in power system: A review", "author": ["A. Chauhan", "S. Rajvanshi"], "venue": "Power, Energy and Control (ICPEC), 2013 International Conference on. IEEE, 2013, pp. 558\u2013561.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "The challenge of nontechnical loss detection using artificial intelligence: A survey", "author": ["P. Glauner", "A. Boechat", "L. Dolberg"], "venue": "arXiv preprint arXiv:1606.00626, 2016.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2016}, {"title": "High performance computing for detection of electricity theft", "author": ["S.S.S.R. Depuru", "L. Wang", "V. Devabhaktuni", "R.C. Green"], "venue": "International Journal of Electrical Power & Energy Systems, vol. 47, pp. 21\u201330, 2013.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Improving svm-based nontechnical loss detection in power utility using the fuzzy inference system", "author": ["J. Nagi", "K.S. Yap", "S.K. Tiong"], "venue": "IEEE Transactions on power delivery, vol. 26, no. 2, pp. 1284\u20131285, 2011.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning and evaluating classifiers under sample selection bias", "author": ["B. Zadrozny"], "venue": "Proceedings of the twenty-first international conference on Machine learning. ACM, 2004, p. 114.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2004}, {"title": "A new method for the computation of technical losses in electrical power distribution systems", "author": ["C. d. Oliveira", "N. Kagan", "A. Meffe"], "venue": "Electricity Distribution, 2001. Part 1: Contributions. CIRED. 16th International Conference and Exhibition on (IEE Conf. Publ No. 482), vol. 5. IET, 2001.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2001}, {"title": "Fraud detection in electric power distribution networks using an ann-based knowledgediscovery process", "author": ["B.C. Costa", "B.L. Alberto", "A.M. Portela"], "venue": "International Journal of Artificial Intelligence & Applications, vol. 4, no. 6, p. 17, 2013.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Identification and feature selection of non-technical losses for industrial consumers using the software weka", "author": ["C.C.O. Ramos", "A.N. De Souza", "D.S. Gastaldello"], "venue": "Industry Applications (INDUSCON), 2012 10th IEEE/IAS International Conference on. IEEE, 2012, pp. 1\u20136.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Large-scale detection of non-technical losses in imbalanced data sets", "author": ["P. Glauner", "A. Boechat", "L. Dolberg"], "venue": "Innovative Smart Grid Technologies Conference (ISGT), 2016 IEEE Power & Energy Society. IEEE, 2016.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2016}, {"title": "Neighborhood features help detecting non-technical losses in big data sets", "author": ["P. Glauner", "J. Meira", "L. Dolberg"], "venue": "3rd IEEE/ACM International Conference on Big Data Computing Applications and Technologies (BDCAT 2016), 2016.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2016}, {"title": "Distilling provider-independent data for general detection of non-technical losses", "author": ["J. Meira", "P. Glauner", "R. State"], "venue": "Power and Energy Conference at Illinois (PECI), 2017. IEEE, 2017.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2017}, {"title": "Big data: are we making a big mistake? ft magazine", "author": ["T. Harford"], "venue": "http://www.ft.com/intl/cms/s/2/21a6e7d8-b479-11e3a09a-00144feabdc0.html, 2014, [Online; accessed January 15, 2016].", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "Domain adaptation and sample bias correction theory and algorithm for regression", "author": ["C. Cortes", "M. Mohri"], "venue": "Theoretical Computer Science, vol. 519, pp. 103\u2013126, 2014.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Scaling to very very large corpora for natural language disambiguation", "author": ["M. Banko", "E. Brill"], "venue": "Proceedings of the 39th annual meeting on association for computational linguistics. Association for Computational Linguistics, 2001, pp. 26\u201333.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2001}, {"title": "C4. 5: Programming for machine learning", "author": ["J.R. Quinlan"], "venue": "Morgan Kauffmann, p. 38, 1993.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1993}, {"title": "Comparison of the predicted and observed secondary structure of t4 phage lysozyme", "author": ["B.W. Matthews"], "venue": "Biochimica et Biophysica Acta (BBA)- Protein Structure, vol. 405, no. 2, pp. 442\u2013451, 1975.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1975}, {"title": "A simple machine learning method to detect covariate shift", "author": ["F.J. Martin"], "venue": "https://blog.bigml.com/2014/01/03/simple-machine-learningto-detect-covariate-shift/, 2014, [Online; accessed January 15, 2016].", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Scikit-learn: Machine learning in Python", "author": ["F. Pedregosa", "G. Varoquaux", "A. Gramfort"], "venue": "Journal of Machine Learning Research, vol. 12, pp. 2825\u20132830, 2011.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "Spatial point processes and their applications", "author": ["A. Baddeley", "I. B\u00e1r\u00e1ny", "R. Schneider"], "venue": "Stochastic Geometry: Lectures given at the CIME Summer School held in Martina Franca, Italy, September 13\u201318, 2004, pp. 1\u201375, 2007.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2004}], "referenceMentions": [{"referenceID": 0, "context": "Non-technical losses (NTL) appear during power distribution and include, but are not limited to, the following causes [1], [2]:", "startOffset": 118, "endOffset": 121}, {"referenceID": 1, "context": "Non-technical losses (NTL) appear during power distribution and include, but are not limited to, the following causes [1], [2]:", "startOffset": 123, "endOffset": 126}, {"referenceID": 2, "context": "They can range up to 40% of the total electricity distributed in countries such as Brazil, India, Malaysia or Lebanon [3], [4].", "startOffset": 118, "endOffset": 121}, {"referenceID": 3, "context": "They can range up to 40% of the total electricity distributed in countries such as Brazil, India, Malaysia or Lebanon [3], [4].", "startOffset": 123, "endOffset": 126}, {"referenceID": 4, "context": "In technical terms, this bias is called covariate shift or sampling bias [5].", "startOffset": 73, "endOffset": 76}, {"referenceID": 5, "context": "From an electrical engineering perspective, energy balance methods [6] can be applied to the detection of NTL.", "startOffset": 67, "endOffset": 70}, {"referenceID": 6, "context": "A data set of ~22K customers is used in [7] for training a neural network.", "startOffset": 40, "endOffset": 43}, {"referenceID": 7, "context": "Consumption profiles of 5K Brazilian industrial customer profiles are analyzed in [8].", "startOffset": 82, "endOffset": 85}, {"referenceID": 1, "context": "We have extensively reviewed the state of the art in our previous work and identified the open challenges in NTL detection [2].", "startOffset": 123, "endOffset": 126}, {"referenceID": 8, "context": "We have previously addressed the class imbalance and evaluation metric selection, when we showed that a large-scale machine learning approach outperformed rule-based Boolean and fuzzy logic expert systems [9].", "startOffset": 205, "endOffset": 208}, {"referenceID": 9, "context": "Furthermore, we have shown that the neighborhood of customers yields significant information in order to decide whether a customer causes a NTL or not [10], [11].", "startOffset": 151, "endOffset": 155}, {"referenceID": 10, "context": "Furthermore, we have shown that the neighborhood of customers yields significant information in order to decide whether a customer causes a NTL or not [10], [11].", "startOffset": 157, "endOffset": 161}, {"referenceID": 11, "context": "As a consequence, Gallup could predict the outcome of the election very well [12].", "startOffset": 77, "endOffset": 81}, {"referenceID": 12, "context": "The problem of training data and production data having different distributions has initially been addressed in the field of computational learning theory [13], which also calls it covariate shift, sampling bias or sample selection bias.", "startOffset": 155, "endOffset": 159}, {"referenceID": 4, "context": "It can be defined in mathematical terms as follows [5]:", "startOffset": 51, "endOffset": 54}, {"referenceID": 4, "context": "This problem is called covariate shift [5].", "startOffset": 39, "endOffset": 42}, {"referenceID": 13, "context": "\u201d [14] Concretely, this approach reflects the desire of deriving better conclusions from simply analyzing more data, without the necessity of looking at theory and models.", "startOffset": 2, "endOffset": 6}, {"referenceID": 4, "context": "It has been shown that some machine learning algorithms are not affected by covariate shift, whereas others are [5].", "startOffset": 112, "endOffset": 115}, {"referenceID": 14, "context": "5 [15] recursively split the input space by choosing the remaining most discriminative feature of a data set.", "startOffset": 2, "endOffset": 6}, {"referenceID": 15, "context": "which measures the accuracy of binary classifiers taking into account the imbalance of both classes, ranging from \u22121 to +1 [16].", "startOffset": 123, "endOffset": 127}, {"referenceID": 16, "context": "2 has been proposed [17].", "startOffset": 20, "endOffset": 24}, {"referenceID": 17, "context": "The entire code was implemented in Python using scikit-learn [18] for machine learning.", "startOffset": 61, "endOffset": 65}, {"referenceID": 18, "context": "Next, we will use and amend spatial point processes [20] for reducing the spatial covariate shift in our data set in order to train more reliable NTL predictors.", "startOffset": 52, "endOffset": 56}], "year": 2017, "abstractText": "Non-technical losses (NTL) occur during the distribution of electricity in power grids and include, but are not limited to, electricity theft and faulty meters. In emerging countries, they may range up to 40% of the total electricity distributed. In order to detect NTLs, machine learning methods are used that learn irregular consumption patterns from customer data and inspection results. The Big Data paradigm followed in modern machine learning reflects the desire of deriving better conclusions from simply analyzing more data, without the necessity of looking at theory and models. However, the sample of inspected customers may be biased, i.e. it does not represent the population of all customers. As a consequence, machine learning models trained on these inspection results are biased as well and therefore lead to unreliable predictions of whether customers cause NTL or not. In machine learning, this issue is called covariate shift and has not been addressed in the literature on NTL detection yet. In this work, we present a novel framework for quantifying and visualizing covariate shift. We apply it to a commercial data set from Brazil that consists of 3.6M customers and 820K inspection results. We show that some features have a stronger covariate shift than others, making predictions less reliable. In particular, previous inspections were focused on certain neighborhoods or customer classes and that they were not sufficiently spread among the population of customers. This framework is about to be deployed in a commercial product for NTL detection.", "creator": "LaTeX with hyperref package"}}}