{"id": "1702.05043", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Feb-2017", "title": "Unbiased Online Recurrent Optimization", "abstract": "The retelling Unbiased Online Recurrent Optimization (UORO) inference create any instant useful it general causes computational combinatorics use taken bites online layout. It ideas entered new discs fashion two avoids crystallised entering before phasic there inputs. UORO true a conventional there NoBackTrack even bypasses which need for model re-allocation those maybe envisaged whatever this changes deep provide strategies, 've would complex hardware. Computationally, UORO the such costly time Truncated Backpropagation Through Time (TBPTT ). Contrary did TBPTT, UORO comes exemption failed provide unbiased reactance predicts, out does want even short - terms dependencies. The downside is strong disturbances, requiring and learning steady.", "histories": [["v1", "Thu, 16 Feb 2017 16:38:08 GMT  (154kb,D)", "http://arxiv.org/abs/1702.05043v1", "11 pages, 5 figures"], ["v2", "Mon, 27 Mar 2017 15:29:33 GMT  (157kb,D)", "http://arxiv.org/abs/1702.05043v2", "11 pages, 5 figures"], ["v3", "Tue, 23 May 2017 11:42:03 GMT  (251kb,D)", "http://arxiv.org/abs/1702.05043v3", "11 pages, 5 figures"]], "COMMENTS": "11 pages, 5 figures", "reviews": [], "SUBJECTS": "cs.NE cs.LG", "authors": ["corentin tallec", "yann ollivier"], "accepted": false, "id": "1702.05043"}, "pdf": {"name": "1702.05043.pdf", "metadata": {"source": "CRF", "title": "Unbiased Online Recurrent Optimization", "authors": ["Corentin Tallec", "Yann Ollivier"], "emails": [], "sections": [{"heading": null, "text": "On synthetic tasks, UORO is found to overcome several deficiencies of TBPTT. For instance, when a parameter has a positive short-term but negative long-term influence, TBPTT may require truncation lengths substantially larger than the intrinsic temporal range of the interactions, while UORO performs well thanks to the unbiasedness of its gradients."}, {"heading": "Introduction", "text": "Current recurrent network training algorithms are ill-suited to online learning via a single pass through long sequences of temporal data. Backpropagation Through Time (BPTT [Jae02]) is well suited to many short training sequences. Its online counterpart, Truncated Backpropagation Through Time, biases learning towards short-time dependencies, 1 and still requires some storage of past inputs and states. Fully online gradient computation methods, such as Real Time Recurrent Learning (RTRL), have been known for quite a while [WZ89] but their computational cost discards them even for moderately-sized networks [Jae02].\nLike our previous NoBackTrack (NBT) algorithm [OTC15], UORO maintains an unbiased approximation of the gradient of the loss with respect to the parameters of the system,\n1 Arguably, TBPTT might still learn some dependencies beyond its truncation range, by a mechanism similar to Echo State Networks (ESN [Jae02]). However, TBPTT\u2019s gradient estimate has a marked bias towards short-term rather than long-term dependencies, as shown in the first experiment of Section 4.\nar X\niv :1\n70 2.\n05 04\n3v 1\n[ cs\n.N E\n] 1\n6 Fe\nb 20\nin a fully streaming fashion. But unlike NBT, UORO can be easily implemented in a blackbox fashion on top of an existing recurrent model in current machine learning software, without delving into the mathematical structure and code of the model.\nPrevious attempts at introducing generic online learning algorithms at reasonable computational cost have resulted in biased gradient estimates. Echo State Networks (ESNs) [JLPS07] simply set to 0 the gradients of recurrent parameters. Others, e.g., [MNM02, Ste04], introduce approaches resembling ESNs, but keep a biased estimate of the recurrent gradients. The original Long Short Term Memory algorithm [HS97] (LSTM now refers to a particular architecture) cuts gradient flows going out of gating units to make gradient computation tractable. Decoupled Neural Interfaces, introduced in [JCO+16], bootstraps truncated gradient estimates using synthetic gradients generated by feedforward neural networks. The algorithm in [MMW02] is based on correlations between one-step gradients and incurred losses, maintained by running a randomized alternative trajectory alongside the standard trajectory; in light of UORO it might be reinterpreted as an approximately unbiased zeroth-order gradient estimate. Generally these approaches lack a strong theoretical backing, except arguably ESNs.\nThe UORO algorithm is presented in Section 2 after a reminder on backpropagation and tangent forward propagation in Section 1. Multi-step UORO is presented in Section 3 and small-scale experimental results are provided in Section 4. An implementation of UORO is available at https://github.com/ctallec/uoro."}, {"heading": "1 Notation and tangent forward propagation", "text": "Consider a non-recurrent computational graph (e.g., a feedforward neural network) that computes\nF : Rdata \u00d7 Rparams \u2192 Routput v 7\u2192 F (v)\nTypically, v = (x, \u03b8) with x \u2208 Rdata and \u03b8 \u2208 Rparams . Backpropagation is the right multiplication of a row vector from the output space, \u03b4o \u2208 Routput, by the Jacobian of F , \u2202F/\u2202v [LBOM96]; we denote it by F.backprop(v, \u03b4o) := \u03b4o (\u2202F/\u2202v). In terms of x and \u03b8, backpropagation produces a pair (\u03b4o (\u2202F/\u2202x), \u03b4o (\u2202F/\u2202\u03b8)). It can be efficiently computed via the usual algorithms.\nIn what follows, we will also use tangent forward propagation: the forward propagation of an infinitesimal change of the current value of v, defined as\nF.forwarddiff(v, \u03b4v) := lim \u03b5\u21920 F (v + \u03b5 \u03b4v)\u2212 F (v) \u03b5 = (\u2202F/\u2202v) \u03b4v (1)\nnamely, the left multiplication of a column vector \u03b4v from the input space by the Jacobian matrix of F . It can be estimated either numerically with a small \u03b5, or algebraically. It is computationally as costly as ordinary forward propagation (denoted by F.forward(v)).\nIn what follows, the gradient of a scalar loss ` with respect to a column vector \u03b8, denoted by \u2202`/\u2202\u03b8, is a row vector with the same number of elements as \u03b8 (this orientation is consistent with the Jacobian matrix \u2202`/\u2202\u03b8, and thus with the chain rule). When v is a column vector and w is a row vector, v \u2297 w denotes the outer product of v and w, that is, the matrix A such that Ai,j = viwj , and w \u00b7 v = \u2211 i viwi denotes the scalar product of w and v."}, {"heading": "2 Unbiased Online Recurrent Optimization", "text": "Consider a recurrent model or dynamical system with smooth transition function\nF : Rinput \u00d7 Rstate \u00d7 Rparams \u2192 Routput \u00d7 Rstate (x, s, \u03b8) 7\u2192 F (x, s, \u03b8).\ndefining the dynamics (ot+1, st+1) = F (xt+1, st, \u03b8). (2)\nAt each time step, the system incurs a loss\n`t = `(ot, o\u0302t). (3)\nF is decomposed into (Fout, Fstate) which are both smooth functions. Most current recurrent architectures fall into this framework. For instance, LSTMs are easily rephrased in term of F , with st = (ct, ht) and \u03b8 the set of all parameters.\nThe UORO algorithm computes an unbiased estimate of the gradient of the loss with respect to \u03b8 in a streaming fashion, provided it is possible to backpropagate and tangent forward propagate through one step of the dynamical system, i.e., through the function F .\nThis gradient estimate can then be fed to any stochastic gradient optimizer, such as Adaptative Momentum [KB14] (Adam) or Adaptative Gradient [DHS10]. Vanilla stochastic gradient descent (SGD) and Adam are used hereafter. In Algorithm 1 below, such optimizers are denoted by SGDOpt and the corresponding parameter update given current parameter \u03b8, gradient estimate gt and learning rate \u03b7t is denoted SGDOpt.update(gt, \u03b7t, \u03b8).\nExact online computation of \u2202`t/\u2202\u03b8 requires computation of \u2202st/\u2202\u03b8 , the derivative of the current state with respect to the parameters. 2 By application of the multivariate chain rule, this quantity evolves as\n\u2202st+1 \u2202\u03b8 = \u2202Fstate \u2202\u03b8 (xt+1, st, \u03b8) + \u2202Fstate \u2202s (xt+1, st, \u03b8) \u2202st \u2202\u03b8 . (4)\nThis is how RTRL [Jae02] updates its gradient estimate. Storing \u2202st+1/\u2202\u03b8 requires n \u00d7 p memory units, where n is the number of recurrent states and p the number of parameters. This is unfeasible for reasonably-sized networks.\n2 \u2202st+1/\u2202\u03b8 is not \u2202Fstate(xt+1, st, \u03b8)/\u2202\u03b8. The latter computes the derivative of st+1 for fixed st. The former accounts for changes in the whole state trajectory induced by changes of \u03b8.\nUORO mimics RTRL but drastically reduces its computational and storage complexity. Instead of fully maintaining \u2202st/\u2202\u03b8, UORO only maintains a rank-one unbiased estimate of the form s\u0303t\u2297 \u03b8\u0303t, with s\u0303t a column vector of size state and \u03b8\u0303t a row vector of size params.\nUORO\u2019s update rules, described in Algorithm 1, are\ns\u0303t+1 \u2190 \u03c10 \u2202Fstate \u2202s (xt+1, st, \u03b8) s\u0303t + \u03c11 \u03bd (5)\n\u03b8\u0303t+1 \u2190 \u03b8\u0303t \u03c10\n+ \u03bd>\n\u03c11\n\u2202Fstate \u2202\u03b8 (xt+1, st, \u03b8) (6)\nwhere \u03bd is a column vector of random signs of the same dimension as st, and \u03c10 and \u03c11 are normalizing constants aimed at minimizing variance, specified in Algorithm 1. It is proven in the Appendix that E [ s\u0303t \u2297 \u03b8\u0303t ] follows the exact evolution equation (4),\nhence unbiasedness of the gradient estimate \u2202st\u2202\u03b8 \u2248 s\u0303t \u2297 \u03b8\u0303t (Proposition 1). This rank-one approach is based on [OTC15], which performs finer variance reduction. However, [OTC15] involves computing \u2202F istate/\u2202\u03b8 for every i ranging over state space indices; these quantities are not easily computed for non-sparse F , or indeed for any complex model F .\nThe gradient of the loss at time t+ 1 with respect to the parameters is estimated as\n\u2202`t+1 \u2202\u03b8 = \u2202`t+1 \u2202ot \u2202ot \u2202\u03b8 = \u2202`t+1 \u2202ot ( \u2202Fout \u2202\u03b8 (xt+1, st, \u03b8) + \u2202Fout \u2202s (xt+1, st, \u03b8) \u2202st \u2202\u03b8 ) (7)\nin which we substitute \u2202st\u2202\u03b8 \u2248 s\u0303t \u2297 \u03b8\u0303t. This is unbiased if s\u0303t \u2297 \u03b8\u0303t is. This can be computed efficiently by backpropagating \u2202`t+1/\u2202ot once through F (see g\u0303t in Algorithm 1).\nNote that unbiasedness only holds in the limit of small learning rates; otherwise, computing \u2202st+1\u2202\u03b8 online mixes gradients at different values of the learned parameter \u03b8, and the meaning of the statement is more complex [OTC15].\nThe computational complexity of UORO is O(p) per step. The storage complexity (on top of that of the model itself) is O(max(n, p))."}, {"heading": "3 Multi-step UORO", "text": "UORO provides an unbiased gradient estimate. However, this estimate comes at the price of injecting noise into the gradient. This requires smaller learning rates.\nTo reduce the noise on short-term gradients, UORO can be used on top of truncated BPTT to correct TBPTT\u2019s gradients and make them unbiased.\nFormally, this just requires applying Algorithm 1 to a new transition function F T which is just T consecutive steps of the original model F . Then, as in TBPTT, the backpropagation operation in Algorithm 1 becomes a backpropagation over the last T steps. The loss\nof one step of F T is the sum of the losses of the last T steps of F , namely `t+Tt+1 := t+T\u2211 k=t+1 `k.\nAlgorithm 1: One step of UORO (from time t to t+ 1)"}, {"heading": "Data:", "text": "- xt+1, o\u0302t+1, st and \u03b8: input, target, recurrent state and parameters - s\u0303t column vector of size state, \u03b8\u0303t row vector of size params such that E s\u0303t \u2297 \u03b8\u0303t = \u2202st/\u2202\u03b8 - SGDOpt and \u03b7t+1: stochastic optimizer and its learning rate"}, {"heading": "Result:", "text": "- `t+1, st+1 and \u03b8: loss, recurrent state and updated parameters - s\u0303t+1 and \u03b8\u0303t+1 such that E s\u0303t+1 \u2297 \u03b8\u0303t+1 = \u2202st+1/\u2202\u03b8 - g\u0303t+1 such that Eg\u0303t+1 = \u2202`t+1/\u2202\u03b8\nbegin /* compute next state and loss */ (ot+1, st+1) = F.forward(xt+1, st, \u03b8) `t+1 = `(ot+1, o\u0302t+1) /* compute gradient estimate */ (\u03b4s, \u03b4\u03b8)\u2190 Fout.backprop((xt+1, st, \u03b8), \u2202`(ot+1, o\u0302t+1)/\u2202o) g\u0303t+1 \u2190 (\u03b4s \u00b7 s\u0303t) \u03b8\u0303t + \u03b4\u03b8 /* prepare for reduction */ Draw \u03bd, column vector of random signs \u00b11 of size state s\u0303t+1 \u2190 Fstate.forwarddiff((xt+1, st, \u03b8), (0, s\u0303t, 0)) (_, \u03b4\u03b8g)\u2190 Fstate.backprop((xt+1, st, \u03b8), \u03bd>) /* compute normalizers */\n\u03c10 \u2190 \u221a\n\u2016\u03b8\u0303t\u2016 \u2016s\u0303t+1\u2016+ \u03b5 + \u03b5 , \u03c11 \u2190 \u221a \u2016\u03b4\u03b8g\u2016 \u2016\u03bd\u2016+ \u03b5 + \u03b5 with \u03b5 = 10 \u22127\n/* reduce */ s\u0303t+1 \u2190 \u03c10 s\u0303t+1 + \u03c11 \u03bd\n\u03b8\u0303t+1 \u2190 \u03b8\u0303t \u03c10 + \u03b4\u03b8g \u03c11 /* update \u03b8 */ SGDOpt.update(g\u0303t+1, \u03b7t+1, \u03b8)\nend\nLikewise, the forward tangent propagation is performed through F T . This way, we obtain an unbiased gradient estimate in which the gradients from the last T steps are computed exactly and incur no noise.\nThe resulting algorithm is referred to as UORO-T . Its scaling in T is similar to TBPTTT , both in terms of memory and computation. In the experiments below, UORO-T reduced variance early on, but did not significantly improve later performance.\nThe noise in UORO can also be reduced by using higher-rank gradient estimates (rank-r instead of rank-1), which amounts to maintaining r distinct values of s\u0303 and \u03b8\u0303 in Algorithm 1 and averaging the resulting values of g\u0303. We did not exploit this possibility in the experiments below, although r = 2 visibly reduced variance in preliminary tests."}, {"heading": "4 Experiments", "text": "We tested UORO on synthetic cases involving temporal dependencies that TBPTT has difficulty learning, due to short-sightedness or improper balancing of time scales. UORO overcomes those deficiencies and competes with or sometimes largely outperforms TBPTT.\nInfluence balancing. The first test case examplifies learning of a scalar parameter \u03b8 which has a positive influence in the short term, but a negative one in the long run. Shortsightedness of truncated algorithms results in abrupt failure, with the parameter exploding in the wrong direction unless the truncation length exceeds the temporal dependency range by a factor of 10 or so.\nConsider the linear dynamics\nst+1 = Ast + (\u03b8, . . . , \u03b8,\u2212\u03b8, . . . ,\u2212\u03b8)> (8)\nwith A a square matrix of size n with that Ai,i = 1/2, Ai,i+1 = 1/2, and 0 elsewhere; \u03b8 \u2208 R is a scalar parameter. The second term has p positive-\u03b8 entries and n\u2212p negative-\u03b8 entries. Intuitively, the effect of \u03b8 on a unit diffuses to shallower units over time (Fig. 1). Unit i\nonly feels the effect of \u03b8 from unit i+ n after n time steps. The loss considered is a target on the shallowest unit s1,\n`t = 1 2(s 1 t \u2212 1)2. (9)\nThe system stabilizes to an equilibrium B (\u03b8, . . . , \u03b8,\u2212\u03b8, . . . ,\u2212\u03b8)> for any starting point, with Bi,j = 2 for j \u2265 i and 0 elsewhere. At equilibrium, one checks that \u2202s1t /\u2202\u03b8 = 4p\u2212 2n.\nLearning of \u03b8 is performed online using vanilla SGD, with the gradient estimate coming either from TBPTT-T with various T , or from UORO. Learning rates are of the form \u03b7\n1+ \u221a t\nwhere t is time and \u03b7 is a suitable base learning rate. As shown in Fig. 3a, UORO solves the problem while TBPTT-T fails to converge for any learning rate, even for truncations largely above n. Failure is caused by ill balancing of time dependencies: the influence of \u03b8 on the loss is estimated with the wrong sign due to truncation. For n = 23 units, with 13 minus signs, TBPTT requires a truncation above 200 to converge.\nNext-character prediction. The next experiment is character-level synthetic text prediction: the goal is to train a recurrent model to predict the t + 1-th character of a text given the first t online, with a single pass on the data sequence.\nA single layer of 64 units, either GRU or LSTM, is used to output a probability vector for the next character. The cross entropy criterion is used to compute the loss.\nTo make plots readable and reduce visual noise, at each time we plot a moving average of approximately \u221a t previous losses, namely L(t+ 1) := ( 1\u2212 1\u221a\nt\n) L(t) + 1\u221a\nt `t+1.\nOptimization was performed using Adam with \u03b21 = 0.9 and \u03b22 = 0.999 and a decreasing learning rate \u03b7 = \u03b3\n1+\u03b1 \u221a t , with t the number of characters processed. As UORO requires\nsmaller learning rates than TBPTT in order to converge, this favors UORO. UORO often fails to converge with non-decreasing learning rates, due to its stochastic nature.\nDistant brackets dataset (s, k, a). The distant brackets dataset is generated by repeatedly outputting a left bracket, generating s random characters from an alphabet of size a, outputting a right bracket, generating k random characters from the same alphabet,\nrepeating the same first s characters between brackets and finally outputting a line break. A sample is shown in Fig. 2a. The entropy rate of such a sequence is (s+k) log2(a)2s+k+5 bits per character. For this dataset, \u03b1 = 0.015 and \u03b3 = 10\u22123.\nUORO and TBPTT-4 are compared in this setup, with a TBPTT truncation deliberately shorter than the inherent time range of the data, to illustrate its potential bias if the inherent time range in the data is unknown a priori.\nThe results are given in Fig. 3b. UORO beats TBPTT-4 in the long run, and succeeds in reaching near optimal behaviour with both models. On the other hand, for both LSTM and GRU units, TBPTT-4 displays faster early convergence, as well as lower variance. GRU TBPTT-4 keeps learning more dependencies at a slower rate. LSTM TBPTT-4 remains stuck near the memoryless optimum. LSTMs and GRUs display somewhat different dynamics, both for UORO and TBPTT.\nanbn(k, l) dataset The anbn(k, l) dataset is generated by repeatedly generating a random number n between k and l, outputting a string of n a\u2019s, a line break, n b\u2019s, and a line break. Its entropy rate is log2(k\u2212l+1)k+l+2 bits per character. A sample is given in Fig. 2b.\nPlots for a few particular setups are given in Fig. 4. For this dataset, the learning rates used \u03b1 = 0.03 and \u03b3 = 10\u22123.\nNumerical results at the end of training are given in Fig. 5. For reference, the true entropy rate is 0.14 bits per character, while the entropy rate of a model that does not understand that the numbers of a\u2019s and b\u2019s coincide would be double, 0.28 bpc.\nTBPTT with truncation 16 converges to the true entropy rate with LSTMs but not with\nGRUs. UORO solves the problem with both LSTMs and GRUs, despite being memoryless. UORO clearly exhibits more noise. Late convergence is somewhat slower with UORO than TBPTT-16 (for LSTMs, since TBPTT-16 does not converge with GRUs): the true entropy rate is reached after about 3 times as many characters, mostly due to UORO noise. Truncating TBPTT to shorter ranges, e.g., TBPTT-2, affects its performance (Fig. 5).\nFor both LSTMs and GRUs, using UORO-T with increased range does not consistently improves the final convergence results, but reduces early noise, as shown in Fig. 4b."}, {"heading": "Conclusion", "text": "We introduced UORO, an algorithm for training recurrent neural networks in a streaming, memoryless fashion. UORO is easy to implement, requires as little computation time as TBPTT and copes for TBPTT\u2019s shortsightedness, at the cost of noise injection. UORO\nprovably provides an unbiased estimate of the gradient of the loss, making it theoretically sound for small learning rates. Furthermore, experimental results indicate that the added noise does not unreasonably hurt the learning process, and that UORO is able to solve some problems on which truncated BPTT fails."}, {"heading": "A Unbiasedness of gradient estimates: proof", "text": "Proposition 1. Consider the sequence s\u0303t, \u03b8\u0303t and g\u0303t obtained in Algorithm 1 with \u03b7t = 0. Then, for every time t, E [ s\u0303t \u2297 \u03b8\u0303t ] = \u2202st \u2202\u03b8 . Consequently, the gradient estimate g\u0303t+1 satisfies Eg\u0303t+1 = \u2202`t+1 \u2202\u03b8 .\nProof. By induction, At t = 0, s\u03030 = 0, \u03b8\u03030 = 0 thus E [ s\u03030 \u2297 \u03b8\u03030 ] = 0 =\n\u2202s0 \u2202\u03b8 . Let t be such that E [ s\u0303t \u2297 \u03b8\u0303t ] = \u2202st \u2202\u03b8 . Using the update equations (5), (6) for s\u0303t+1 and\n\u03b8\u0303t+1 yields E [ s\u0303t+1 \u2297 \u03b8\u0303t+1 ] =E [ \u2202Fstate \u2202s (xt+1, st, \u03b8) s\u0303t \u2297 \u03b8\u0303t ] + E [ \u03c11 \u03c10 \u03bd \u2297 \u03b8\u0303t ] +\nE [ \u03c10 \u03c11 \u2202Fstate \u2202s (xt+1, st, \u03b8) s\u0303t \u2297 \u03bd> \u2202Fstate \u2202\u03b8 (xt+1, st, \u03b8) ] + E [ \u03bd \u2297 \u03bd> \u2202Fstate \u2202\u03b8 (xt+1, st, \u03b8) ] = \u2202Fstate \u2202s (xt+1, st, \u03b8)E [ s\u0303t \u2297 \u03b8\u0303t ] + E [ \u03c11 \u03c10 \u03bd \u2297 \u03b8\u0303t ] +\n\u2202Fstate \u2202s (xt+1, st, \u03b8)E [ \u03c10 \u03c11 s\u0303t \u2297 \u03bd> ] \u2202Fstate \u2202\u03b8 (xt+1, st, \u03b8) + E [ \u03bd \u2297 \u03bd> ] \u2202Fstate \u2202\u03b8 (xt+1, st, \u03b8).\nNow by induction hypothesis, E [ s\u0303t \u2297 \u03b8\u0303t ] = \u2202st \u2202\u03b8 . By definition of \u03bd, E [ \u03bd \u2297 \u03bd> ] = I. By\nindependence of \u03bd and \u03c11 from \u03b8\u0303t, s\u0303t and \u03c10, only E [\u03c11 \u03bd] and E [ \u03bd>\n\u03c11\n] are left to evaluate.\nBut the law of \u03bd is symmetric by sign change \u03bd 7\u2192 \u2212\u03bd, and moreover, \u03c11(\u03bd) = \u03c11(\u2212\u03bd). Therefore by symmetry both E[\u03c11 \u03bd] and E[\u03bd>/\u03c11] are 0. Therefore,\nE [ s\u0303t+1 \u2297 \u03b8\u0303t+1 ] = \u2202Fstate \u2202s (xt+1, st, \u03b8) \u2202st \u2202\u03b8 + \u2202Fstate \u2202\u03b8 (xt+1, st, \u03b8) = \u2202st+1 \u2202\u03b8\nhence unbiasedness. The statement for \u2202`t+1\u2202\u03b8 follows by inserting \u2202st \u2202\u03b8 = E [ s\u0303t \u2297 \u03b8\u0303t ] in (7)."}], "references": [{"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["John Duchi", "Elad Hazan", "Yoram Singer"], "venue": "Technical Report UCB/EECS2010-24, EECS Department,", "citeRegEx": "Duchi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2010}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural Comput.,", "citeRegEx": "Hochreiter and Schmidhuber.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Tutorial on training recurrent neural networks, covering BPPT, RTRL, EKF and the \u201cecho state network", "author": ["Herbert Jaeger"], "venue": null, "citeRegEx": "Jaeger.,? \\Q2002\\E", "shortCiteRegEx": "Jaeger.", "year": 2002}, {"title": "Decoupled neural interfaces using synthetic gradients", "author": ["Max Jaderberg", "Wojciech Marian Czarnecki", "Simon Osindero", "Oriol Vinyals", "Alex Graves", "Koray Kavukcuoglu"], "venue": null, "citeRegEx": "Jaderberg et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Jaderberg et al\\.", "year": 2016}, {"title": "Optimization and Applications of Echo State Networks with Leaky-Integrator Neurons", "author": ["Herbert Jaeger", "Mantas Luko\u0161evi\u010dius", "Dan Popovici", "Udo Siewert"], "venue": "Neural Networks,", "citeRegEx": "Jaeger et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Jaeger et al\\.", "year": 2007}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik P. Kingma", "Jimmy Ba"], "venue": "CoRR, abs/1412.6980,", "citeRegEx": "Kingma and Ba.,? \\Q2014\\E", "shortCiteRegEx": "Kingma and Ba.", "year": 2014}, {"title": "Efficient backprop", "author": ["Yann LeCun", "L\u00e9on Bottou", "Genevieve B. Orr", "Klaus-Robert M\u00fcller"], "venue": "Neural Networks: Tricks of the Trade,", "citeRegEx": "LeCun et al\\.,? \\Q1996\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1996}, {"title": "A Monte Carlo EM approach for partially observable diffusion processes: Theory and applications to neural networks", "author": ["Javier R. Movellan", "Paul Mineiro", "R.J. Williams"], "venue": "Neural Comput.,", "citeRegEx": "Movellan et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Movellan et al\\.", "year": 2002}, {"title": "Real-time computing without stable states: A new framework for neural computation based on perturbations", "author": ["Wolfgang Maass", "Thomas Natschl\u00e4ger", "Henry Markram"], "venue": "Neural Comput.,", "citeRegEx": "Maass et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Maass et al\\.", "year": 2002}, {"title": "Training recurrent networks online without backtracking", "author": ["Yann Ollivier", "Corentin Tallec", "Guillaume Charpiat"], "venue": "CoRR, abs/1507.07680,", "citeRegEx": "Ollivier et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ollivier et al\\.", "year": 2015}, {"title": "Backpropagation-decorrelation: online recurrent learning with O(N) complexity", "author": ["Jochen J. Steil"], "venue": "In Neural Networks,", "citeRegEx": "Steil.,? \\Q2004\\E", "shortCiteRegEx": "Steil.", "year": 2004}, {"title": "A learning algorithm for continually running fully recurrent neural networks", "author": ["Ronald J. Williams", "David Zipser"], "venue": "Neural Comput.,", "citeRegEx": "Williams and Zipser.,? \\Q1989\\E", "shortCiteRegEx": "Williams and Zipser.", "year": 1989}], "referenceMentions": [], "year": 2017, "abstractText": "The novel Unbiased Online Recurrent Optimization (UORO) algorithm allows for online learning of general recurrent computational graphs such as recurrent network models. It works in a streaming fashion and avoids backtracking through past activations and inputs. UORO is a modification of NoBackTrack [OTC15] that bypasses the need for model sparsity and makes implementation easy in current deep learning frameworks, even for complex models. Computationally, UORO is as costly as Truncated Backpropagation Through Time (TBPTT). Contrary to TBPTT, UORO is guaranteed to provide unbiased gradient estimates, and does not favor short-term dependencies. The downside is added noise, requiring smaller learning rates. On synthetic tasks, UORO is found to overcome several deficiencies of TBPTT. For instance, when a parameter has a positive short-term but negative long-term influence, TBPTT may require truncation lengths substantially larger than the intrinsic temporal range of the interactions, while UORO performs well thanks to the unbiasedness of its gradients.", "creator": "LaTeX with hyperref package"}}}