{"id": "1702.06733", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Feb-2017", "title": "Improving a Strong Neural Parser with Conjunction-Specific Features", "abstract": "While maternal parsers reach think current overall complexity, probably consumption relations are more harder than none. In particular, criminalization isopropanol musicians thoroughly its hand-eye sector (my. ip. , correctly regulating both \" conj \" similarity ). We accept own as - on - put - art concomitant parser when part - determine presents, technology at the similarity following took conjuncts head answer. Training their upon parser decline an steady followed \" conj \" lateral as well brought with overall lessening indexing lacking brought the Stanford dependency halting such before Penn TreeBank.", "histories": [["v1", "Wed, 22 Feb 2017 10:10:44 GMT  (224kb,D)", "http://arxiv.org/abs/1702.06733v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["jessica ficler", "yoav goldberg"], "accepted": false, "id": "1702.06733"}, "pdf": {"name": "1702.06733.pdf", "metadata": {"source": "CRF", "title": "Improving a Strong Neural Parser with Conjunction-Specific Features", "authors": ["Jessica Ficler"], "emails": ["jessica.ficler@gmail.com", "yoav.goldberg@gmail.com"], "sections": [{"heading": null, "text": "While dependency parsers reach very high overall accuracy, some dependency relations are much harder than others. In particular, dependency parsers perform poorly in coordination construction (i.e., correctly attaching the conj relation). We extend a state-of-the-art dependency parser with conjunction-specific features, focusing on the similarity between the conjuncts head words. Training the extended parser yields an improvement in conj attachment as well as in overall dependency parsing accuracy on the Stanford dependency conversion of the Penn TreeBank."}, {"heading": "1 Introduction", "text": "Advances in dependency parsing result in impressive overall parsing accuracy. For the most part, the advances are due to general improvements in parsing technology or feature representation, and do not explicitly target any specific language or syntactic construction. However, despite the high overall accuracy, parsers are still persistently wrong in attaching certain relations. In the attachments predicted by BIST-parser (Kiperwasser and Goldberg, 2016), the F1 score for the labels nn, nsubj, pobj, and others is 95% and above; while the F1 scores for advmod, conj and prep are 83.3%, 82.5% and 87.4% respectively. Conjunction holds the lowest F1 score, ignoring rare labels, dep and punct. Other parsers behave similarly. Conjunction mistakes occurs also in simple sentences such as:\n(1) \u201cThose machines are still considered novelties, with keyboards only a munchkin could love and screens to match.\u201d\n(2) \u201cIn the year-earlier period, CityFed had net income of $ 485,000, but no per-share earnings.\u201d\nBIST-parser (Kiperwasser and Goldberg, 2016) attaches screens and love instead screens and keyboards in (1); and earnings and had instead earnings and income in (2).\nThe parsers low performance on conjunction is disappointing given that conjunction is a common and important syntactic phenomena, appearing in almost 40% of the sentences in the Penn TreeBank (Marcus et al., 1993), as well constitutes 2.82% of the Stanford dependency conversion of the Penn TreeBank (De Marneffe and Manning, 2008) edges.\nIn this work we focus on improving conj attachment accuracy by extending a dependency parser with features that specifically target the coordinating conjunction structures. Similar efforts were done for constituency parsing in previous work (Hogan, 2007; Charniak and Johnson, 2005).\nAs previously explored, conjuncts tend to be semantically related and have a similar syntactic structure (Shimbo and Hara, 2007; Hara et al., 2009; Hogan, 2007; Ficler and Goldberg, 2016; Charniak and Johnson, 2005; Johnson et al., 1999). For example: \u201cfor China and for India\u201d, \u201c1.86 marks and 139.75 yen\u201d, \u201cowns 33 % of Moleculons stocks and holds 27.5 % of Datapoints shares\u201d. Such cases are common but still there are many cases where symmetry between conjuncts is less straightforward such as in (1), which includes the conjuncts \u201ckeyboards only a munchkin could love\u201d and \u201cscreens to match\u201d; and (2), which includes \u201cnet income of $ 485,000\u201d and \u201cno pershare earnings\u201d. For many cases of this type, the head words of the conjuncts are similar, e.g. (keyboards,screens) in (1) and (income,earnings) in (2).\nWe extend BIST-parser, the Bi-LSTM based\nar X\niv :1\n70 2.\n06 73\n3v 1\n[ cs\n.C L\n] 2\n2 Fe\nb 20\n17\nparser by Kipwasser and Goldberg (2016), by adding explicit features that target the conjunction relation and focus on various aspects of symmetry between the potential conjuncts\u2019 head words. We show improvement in dependency parsing scores and in conj attachment."}, {"heading": "2 Symmetry between Conjuncts", "text": "It is well known that conjuncts tend to be semantically related and often have a similar syntactic structure. This property of coordination was used as a guiding principle in previous work on coordination disambiguation (Hara et al., 2009; Hogan, 2007; Shimbo and Hara, 2007; Ficler and Goldberg, 2016). While these focus on symmetry between conjuncts in constituency structures, we use the symmetry assumption for the purpose of improving dependency parsing. Here is a simple example of dependency tree that include conjunction:\nThe bond fund will invest in high-grade or medium-grade bonds\ndet\nnn\nnsubj\naux prep\namod\ncc\nconj\npobj\nThe edge labeled with conj connects the first conjunct head to the heads of the other conjuncts. In more complex conjuncts, the subtrees under the nodes connected by conj are often similar such as the following examples:\nto a stock fund , an annuity and a money-market fund\npobj\ndet\nnn\nconj\ncc\ndet\nconj\ndet\nnn\nhandled four World Series teams and now handles the Gold Coast Suns\ndobj\ncc\nadvmod\nconj\nnum\nnn\nnn\ndobj\ndet\nnn\nnn\nHowever, there are also cases where the conjuncts structures are non-similar such as in:\nHani Zayadi was appointed president and chief executive officer of ...\nnn\nnsubjpass\nauxpass xcomp cc\nconj\nprep\namod\nnn\nYet, some form of symmetry (or anti-symmetry) usually holds between the conjuncts head words. Table 1 lists the most common coordinated words in the PTB."}, {"heading": "3 Conjunction Features", "text": "We suggest a set of features that are designed specifically for the conjunction relation, and target the symmetry aspect of the head words. The features look at a pair of head and modifier words, and are based on properties that appear frequently in conjunctions in the Stanford Dependencies version of the PTB. The features are summarized in Table 2, and are detailed below: CAP \u2013 The case where both conjuncts head words start with a capital letter is much more common (> 3\u00d7) than the case where only one of the head words starts with a capital letter. These cases are usually names of people, countries and organizations; and common phrases such as \u201cMac and Cheese\u201d. This property is rare in other labels except nn. We capture this property with a boolean feature that indicates whether both conjuncts head words start with a capital letter. SUF \u2013 In some of the conjunctions, the head words have a similar form, as in (codification, clarification), (demographic, geographic), (highgrade, medium-grade), (backwards, forwards). The cases where the longest common suffix between the words is at least 3 is 8% in the case of conj and much lower for the other labels. We capture this tendency using a numeric feature that indicated the length of the common suffix between the head words. LEM \u2013 Conjuncts heads often share the same lemma. These are usually different inflections of the same verb (e.g. sells,sold); or singular/plural forms of the same noun (e.g. table,tables). This is also a tendency that is more common in conj label than the other labels. We capture these, with a boolean feature indicating whether the lemmas of\nthe conjuncts head words are identical. Lemmas are obtained using the NLTK (Bird, 2006) interface to WordNet (Miller, 1995). SYM \u2013 The conjuncts head words usually have a strong semantic relation. For example (fund, annuity), (same, similar), (buy, sell), (dishes, glass). SYM is a numeric feature that scores the similarity between the conjuncts heads words. The score is computed as the cosine-similarity between word embeddings of the head words (these embeddings are initialized with pre-trained vector from Dyer et al. (2015)). SENT \u2013 In some cases, both conjunct\u2019s head words sentiments are not neutral. Here are some examples from the PTB where both words are with positive sentiments: (enjoyable,easy), (complementary,interesting), (calm,rational); where both words are with negative sentiments: (slow,dump), (insulting,demeaning), (injury,death); and where one word is positive and the other is negative: (winners,losers), (crush,recover), (succeeded,failed). Having non-neutral sentiment for both words is not very common for conj relation (2.3% of the cases), but it much less common for the other relations. Therefore we add features that indicate the sentiment (positive, negative or neutral) for each of the coordinated words. We use lists of positive and negative words from work on airline consumer sentiment (Breen, 2012)."}, {"heading": "4 Incorporating conjunction features", "text": "We incorporate the above features in the freely available BIST-parser (Kiperwasser and Goldberg, 2016). This parser is a greedy transitionbased parser, using the archybrid transition system (Kuhlmann et al., 2011). At each step of the parsing process, the parser chooses one of 2\u2217|labels|+ 1 possible transitions: SHIFT, RIGHT(rel) and LEFT(rel). The LEFT and RIGHT transitions add a dependency edge with the label rel. At each step, all transitions are scored, and the highest scoring transition is applied.\nThe Stanford Dependencies scheme specifies\nthat the conj relation appears as a right edge, and so it can only be produced by a RIGHT(conj) transition. We compute a score Sconj which is added to the score of the RIGHT(conj) transition that was produced by the parser. Sconj is computed by an MLP that receives a feature vector that is a concatenation of the original parser\u2019s features and the conjunction specific features. The scoring MLP and the parser are trained jointly."}, {"heading": "5 Experiments", "text": "We evaluate the extended parsing model on the Stanford Dependencies (De Marneffe and Manning, 2008) version of the Penn Treebank. We adapt BIST-parser code to run with the DyNet toolkit1 and add our changes. We follow the setup of Kiperwasser and Goldberg (2016): (1) A word is represented as the concatenation of randomly initialized vector and pre-trained vector (taken from Dyer et al. (2015)); (2) The word and POS embeddings are tuned during training; (3) Punctuation symbols are not considered in the evaluation; (4) The hyper-parameters values are as in Kiperwasser and Goldberg paper (2016), Table 2; (5) We use the same seed and do not perform hyper-parameter tuning. We train the parser with the conjunction features for up to 10 iterations, and choose the best model according to the LAS accuracy on the development set.\nGeneral Parsing Results Table 3 compares our results to the unmodified BIST parser. The extended parser achieves 0.1 points improvement in UAS and 0.2 points in LAS comparing to Kiperwasser and Goldberg (2016). This is a strong baseline, which so far held the highest results among greedy transition based parsers that were trained on the PTB only, including e.g. the parsers of Weiss et al (2015), Dyer et al (2015) and Ballesteros et al (2016). Stronger absolute parsing numbers are reported by Andor et al (2016) (using a beam); and Kuncoro et al (2016) and Dozat\n1https://github.com/clab/dynet\nand Manning (2016) (using an arc-factored global parsers). All those parsers rely on broadly the same kind of features, and while we did not test this, it is likely the conjunction features would benefit them as well.2\nParsing Results for conj Label We evaluate our model specifically for conj label, and compare to the results achieved by the parser without the conjunction features. We measure Rel (correctly identifying modifiers that participate in a conj relation, regardless of correctly attaching the parent) and Rel+Att (correctly identifying both the head and the modifier in a conj relation). The results are in Table 4. The improvement in Rel score is relatively small while there is an improvement of 1.1 points in Rel+Att F1 score, suggesting that the parser was already effective at identifying the modifiers in a conj relation and that our model\u2019s benefit is mainly on attaching the correct parent node.\nAnalysis We would like to examine to what extent the improvement we achieve over Kiperwasser and Goldberg (2016) on conj attachments corresponds to the coordination features we designed. To do that, we analyze the conj cases in the dev-set that were correctly predicted by our model and were not predicted by the original BIST-parser and vice versa. The following table shows the percentage of cases where conjunction features appear in each of these lists:\nFeatures +Our,\u2212K&G \u2212Our,+K&G LEM+CAP+SUF 7.5 0 LEM+SUF 3 0 SENTIMENT+SUF 1.5 0 LEM/CAP/SENTIMENT/SUF 29.9 24 Total 41.9 24\nThe percentage of cases that include conjunction features is much higher in the list of cases that were correctly predicted only by our model. More than that, there are no cases that include more than one conjunction feature in the list of cases that were correctly predicted only by BIST-parser (Kiperwasser and Goldberg, 2016).\n2A reviewer of this work suggested that our baseline model is oblivious to the word\u2019s morphology, and that a neural parsing architecture that explicitly models the words\u2019 morphology through character-based LSTMs, such as the model of (Ballesteros et al., 2015), could capture some of the information in our features automatically, and thus would be a better baseline. While we were skeptical, we tried this suggestion, and found that it indeed does not change the results in a meaningful way.\nThe above table does not include the SYM feature since unlike the other features there is no absolute way to determine whether the feature takes place on a specific example. To give a sense of the contribution of the SYM feature, we show some examples where our model attaches a conj label between similar words, while the unmodified BIST parser attaches conj parent which is clearly less similar to the modifier (The word in bold is the attached modifier; the word marked with continuous line is the node\u2019s parent in our prediction; the word marked with dashed line is the node\u2019s parent in BIST\u2019s prediction):\n\u2022 Koop, who rattled liberals and conservatives alike with his outspoken views on ... \u2022 ... dropped in response to gains in the stock\nmarket and losses in Treasury securities. \u2022 Died: Cornel Wilde, 74 ,actor and director\n,in Los Angeles ,of leukemia ... \u2022 ... investment firms advising clients to boost\ntheir stock holdings and reduce the ,,.\nIn the cases that were correctly predicted by BIST-parser only, we could not find examples where the words in the correct attachment are clearly more similar than the attachment predicted by our model. We could find a few examples where both models attached words that are similar, such as:\n\u2022 ML & Co.\u2019s net income dropped 37%, while BS Cos. posted a 7.5% gain in net, and PG Inc.\u2019s profit fell, but would have risen ... \u2022 The closely watched rate on federal funds, or\novernight loans between banks, slid to..."}, {"heading": "6 Conclusions", "text": "While most recent work in parsing attempt to improve results using \u201dgeneral\u201d architectures and feature sets, targeted feature engineering is still beneficial. We demonstrate that a linguistically motivated and data-driven feature-set for a specific syntactic relation (coordinating conjunction) improves a strong baseline parser.\nThe features we propose explicitly model the symmetry between the head words in coordination constructions. While we demonstrated their effectiveness in a greedy transition-based parser, the information our features capture is not currently captured also by other dependency parsing architectures (including first-order graph based parsers, higher-order graph-based parsers, beambased transition parsers). These features will be straightforward to integrate into such parsers, and we expect them to be effective for them as well."}, {"heading": "Acknowledgments", "text": "This work was supported by The Israeli Science Foundation (grant number 1555/15) as well as the German Research Foundation via the German-Israeli Project Cooperation (DIP, grant DA 1600/1-1)."}], "references": [{"title": "Globally normalized transition-based neural networks", "author": ["Andor et al.2016] Daniel Andor", "Chris Alberti", "David Weiss", "Aliaksei Severyn", "Alessandro Presta", "Kuzman Ganchev", "Slav Petrov", "Michael Collins"], "venue": "In Proc. of ACL", "citeRegEx": "Andor et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Andor et al\\.", "year": 2016}, {"title": "Improved transitionbased parsing by modeling characters instead of words with LSTMs", "author": ["Chris Dyer", "Noah A. Smith"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Lan-", "citeRegEx": "Ballesteros et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ballesteros et al\\.", "year": 2015}, {"title": "Training with exploration improves a greedy stack-LSTM parser", "author": ["Yoav Goldberg", "Chris Dyer", "Noah A Smith"], "venue": "In proceedings of Short Papers EMNLP", "citeRegEx": "Ballesteros et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ballesteros et al\\.", "year": 2016}, {"title": "NLTK: the natural language toolkit", "author": ["Steven Bird"], "venue": "In Proceedings of the COLING/ACL on Interactive presentation sessions,", "citeRegEx": "Bird.,? \\Q2006\\E", "shortCiteRegEx": "Bird.", "year": 2006}, {"title": "Mining twitter for airline consumer sentiment. Practical text", "author": ["Jeffrey Oliver Breen"], "venue": null, "citeRegEx": "Breen.,? \\Q2012\\E", "shortCiteRegEx": "Breen.", "year": 2012}, {"title": "Coarse-to-fine n-best parsing and maxent discriminative reranking", "author": ["Charniak", "Johnson2005] Eugene Charniak", "Mark Johnson"], "venue": "In Proc. of ACL,", "citeRegEx": "Charniak et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Charniak et al\\.", "year": 2005}, {"title": "Stanford typed dependencies manual", "author": ["De Marneffe", "Christopher D Manning"], "venue": "Technical report,", "citeRegEx": "Marneffe et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Marneffe et al\\.", "year": 2008}, {"title": "Deep biaffine attention for neural dependency parsing", "author": ["Dozat", "Manning2016] Timothy Dozat", "Christopher D Manning"], "venue": "In arXiv preprint arXiv:1611.01734", "citeRegEx": "Dozat et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Dozat et al\\.", "year": 2016}, {"title": "Transition-based dependency parsing with stack long short-term memory", "author": ["Dyer et al.2015] Chris Dyer", "Miguel Ballesteros", "Wang Ling", "Austin Matthews", "Noah A. Smith"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association", "citeRegEx": "Dyer et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dyer et al\\.", "year": 2015}, {"title": "A neural network for coordination boundary prediction", "author": ["Ficler", "Goldberg2016] Jessica Ficler", "Yoav Goldberg"], "venue": "In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Ficler et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ficler et al\\.", "year": 2016}, {"title": "Coordinate structure analysis with global structural constraints and alignment-based local features", "author": ["Hara et al.2009] Kazuo Hara", "Masashi Shimbo", "Hideharu Okuma", "Yuji Matsumoto"], "venue": "In Proceedings of the Joint Conference of the 47th Annual", "citeRegEx": "Hara et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hara et al\\.", "year": 2009}, {"title": "Coordinate noun phrase disambiguation in a generative parsing model", "author": ["Deirdre Hogan"], "venue": "In Proceedings of Association for Computational Linguistics,", "citeRegEx": "Hogan.,? \\Q2007\\E", "shortCiteRegEx": "Hogan.", "year": 2007}, {"title": "Estimators for stochastic \u201dunification-based", "author": ["Johnson et al.1999] Mark Johnson", "Stuart Geman", "Stephen Canon", "Zhiyi Chi", "Stefan Riezler"], "venue": "grammars. In Proc. of ACL,", "citeRegEx": "Johnson et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Johnson et al\\.", "year": 1999}, {"title": "Simple and accurate dependency parsing using bidirectional LSTM feature representations. Transactions of the Association for Computational Linguistics, 4:313\u2013327", "author": ["Kiperwasser", "Yoav Goldberg"], "venue": null, "citeRegEx": "Kiperwasser et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Kiperwasser et al\\.", "year": 2016}, {"title": "Dynamic programming algorithms for transitionbased dependency parsers", "author": ["Carlos G\u00f3mez-Rodr\u0131\u0301guez", "Giorgio Satta"], "venue": "In Proc. of ACL,", "citeRegEx": "Kuhlmann et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kuhlmann et al\\.", "year": 2011}, {"title": "Distilling an ensemble of greedy dependency parsers into one MST parser", "author": ["Miguel Ballesteros", "Lingpeng Kong", "Chris Dyer", "Noah A. Smith"], "venue": "In Proc. of EMNLP,", "citeRegEx": "Kuncoro et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Kuncoro et al\\.", "year": 2016}, {"title": "Building a large annotated corpus of english: The Penn Treebank", "author": ["Mary Ann Marcinkiewicz", "Beatrice Santorini"], "venue": null, "citeRegEx": "Marcus et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Marcus et al\\.", "year": 1993}, {"title": "WordNet: a lexical database for english", "author": ["George A Miller"], "venue": "Communications of the ACM,", "citeRegEx": "Miller.,? \\Q1995\\E", "shortCiteRegEx": "Miller.", "year": 1995}, {"title": "A discriminative learning model for coordinate conjunctions", "author": ["Shimbo", "Hara2007] Masashi Shimbo", "Kazuo Hara"], "venue": "In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural", "citeRegEx": "Shimbo et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Shimbo et al\\.", "year": 2007}, {"title": "Structured training for neural network transition-based parsing", "author": ["Weiss et al.2015] David Weiss", "Chris Alberti", "Michael Collins", "Slav Petrov"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th In-", "citeRegEx": "Weiss et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Weiss et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 16, "context": "The parsers low performance on conjunction is disappointing given that conjunction is a common and important syntactic phenomena, appearing in almost 40% of the sentences in the Penn TreeBank (Marcus et al., 1993), as well constitutes 2.", "startOffset": 192, "endOffset": 213}, {"referenceID": 11, "context": "Similar efforts were done for constituency parsing in previous work (Hogan, 2007; Charniak and Johnson, 2005).", "startOffset": 68, "endOffset": 109}, {"referenceID": 10, "context": "As previously explored, conjuncts tend to be semantically related and have a similar syntactic structure (Shimbo and Hara, 2007; Hara et al., 2009; Hogan, 2007; Ficler and Goldberg, 2016; Charniak and Johnson, 2005; Johnson et al., 1999).", "startOffset": 105, "endOffset": 237}, {"referenceID": 11, "context": "As previously explored, conjuncts tend to be semantically related and have a similar syntactic structure (Shimbo and Hara, 2007; Hara et al., 2009; Hogan, 2007; Ficler and Goldberg, 2016; Charniak and Johnson, 2005; Johnson et al., 1999).", "startOffset": 105, "endOffset": 237}, {"referenceID": 12, "context": "As previously explored, conjuncts tend to be semantically related and have a similar syntactic structure (Shimbo and Hara, 2007; Hara et al., 2009; Hogan, 2007; Ficler and Goldberg, 2016; Charniak and Johnson, 2005; Johnson et al., 1999).", "startOffset": 105, "endOffset": 237}, {"referenceID": 10, "context": "This property of coordination was used as a guiding principle in previous work on coordination disambiguation (Hara et al., 2009; Hogan, 2007; Shimbo and Hara, 2007; Ficler and Goldberg, 2016).", "startOffset": 110, "endOffset": 192}, {"referenceID": 11, "context": "This property of coordination was used as a guiding principle in previous work on coordination disambiguation (Hara et al., 2009; Hogan, 2007; Shimbo and Hara, 2007; Ficler and Goldberg, 2016).", "startOffset": 110, "endOffset": 192}, {"referenceID": 3, "context": "Lemmas are obtained using the NLTK (Bird, 2006) interface to WordNet (Miller, 1995).", "startOffset": 35, "endOffset": 47}, {"referenceID": 17, "context": "Lemmas are obtained using the NLTK (Bird, 2006) interface to WordNet (Miller, 1995).", "startOffset": 69, "endOffset": 83}, {"referenceID": 4, "context": "We use lists of positive and negative words from work on airline consumer sentiment (Breen, 2012).", "startOffset": 84, "endOffset": 97}, {"referenceID": 3, "context": "Lemmas are obtained using the NLTK (Bird, 2006) interface to WordNet (Miller, 1995). SYM \u2013 The conjuncts head words usually have a strong semantic relation. For example (fund, annuity), (same, similar), (buy, sell), (dishes, glass). SYM is a numeric feature that scores the similarity between the conjuncts heads words. The score is computed as the cosine-similarity between word embeddings of the head words (these embeddings are initialized with pre-trained vector from Dyer et al. (2015)).", "startOffset": 36, "endOffset": 491}, {"referenceID": 14, "context": "This parser is a greedy transitionbased parser, using the archybrid transition system (Kuhlmann et al., 2011).", "startOffset": 86, "endOffset": 109}, {"referenceID": 8, "context": "We follow the setup of Kiperwasser and Goldberg (2016): (1) A word is represented as the concatenation of randomly initialized vector and pre-trained vector (taken from Dyer et al. (2015)); (2) The word and POS embeddings are tuned during training; (3) Punctuation symbols are not considered in the evaluation; (4) The hyper-parameters values are as in Kiperwasser and Goldberg paper (2016), Table 2; (5) We use the same seed and do not perform hyper-parameter tuning.", "startOffset": 169, "endOffset": 188}, {"referenceID": 8, "context": "We follow the setup of Kiperwasser and Goldberg (2016): (1) A word is represented as the concatenation of randomly initialized vector and pre-trained vector (taken from Dyer et al. (2015)); (2) The word and POS embeddings are tuned during training; (3) Punctuation symbols are not considered in the evaluation; (4) The hyper-parameters values are as in Kiperwasser and Goldberg paper (2016), Table 2; (5) We use the same seed and do not perform hyper-parameter tuning.", "startOffset": 169, "endOffset": 391}, {"referenceID": 1, "context": "A reviewer of this work suggested that our baseline model is oblivious to the word\u2019s morphology, and that a neural parsing architecture that explicitly models the words\u2019 morphology through character-based LSTMs, such as the model of (Ballesteros et al., 2015), could capture some of the information in our features automatically, and thus would be a better baseline.", "startOffset": 233, "endOffset": 259}], "year": 2017, "abstractText": "While dependency parsers reach very high overall accuracy, some dependency relations are much harder than others. In particular, dependency parsers perform poorly in coordination construction (i.e., correctly attaching the conj relation). We extend a state-of-the-art dependency parser with conjunction-specific features, focusing on the similarity between the conjuncts head words. Training the extended parser yields an improvement in conj attachment as well as in overall dependency parsing accuracy on the Stanford dependency conversion of the Penn TreeBank.", "creator": "LaTeX with hyperref package"}}}