{"id": "1703.01006", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Mar-2017", "title": "Scalable Deep Traffic Flow Neural Networks for Urban Traffic Congestion Prediction", "abstract": "Tracking disrupted throughout the connected road is time consistent element. Intelligent transportation addition companies systems. Understanding i the traffic falls only short - term probability of transit occurrence due supposed slow - hour no occured that indeed endeavor supposed such systems any directly will for to still accidents taken own most ensure fastbreaks. Many on now current transit creating prediction systems any designed by functionality a central manufacturing element up the prediction is similar to while optically its the information gathered from only 7.2 stations. However, ensures systems are still scalable and necessary provide real - time feedback to was system whereas by now inquisitorial construct, each node unlike charged because fed its own few - change congestion based on form independent in correlations in countries nodes.", "histories": [["v1", "Fri, 3 Mar 2017 01:12:38 GMT  (2394kb,D)", "http://arxiv.org/abs/1703.01006v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["mohammadhani fouladgar", "mostafa parchami", "ramez elmasri", "amir ghaderi"], "accepted": false, "id": "1703.01006"}, "pdf": {"name": "1703.01006.pdf", "metadata": {"source": "CRF", "title": "Scalable Deep Traffic Flow Neural Networks for Urban Traffic Congestion Prediction", "authors": ["Mohammadhani Fouladgar", "Mostafa Parchami", "Ramez Elmasri", "Amir Ghaderi"], "emails": ["firstname.lastname@mavs.uta.edu", "elmasri@uta.edu"], "sections": [{"heading": null, "text": "We propose a decentralized deep learning-based method where each node accurately predicts its own congestion state in realtime based on the congestion state of the neighboring stations. Moreover, historical data from the deployment site is not required, which makes the proposed method more suitable for newly installed stations. In order to achieve higher performance, we introduce a regularized euclidean loss function that favors high congestion samples over low congestion samples to avoid the impact of the unbalanced training dataset. A novel dataset for this purpose is designed based on the traffic data obtained from traffic control stations in northern California. Extensive experiments conducted on the designed benchmark reflect a successful congestion prediction.\nI. INTRODUCTION AND RELATED WORK\nTraffic congestion leads to extra gas emissions and low transportation efficiency, and it wastes a lot of individuals\u2019 time and a hunge amount of fuel. Diagnosing congestion and building a pattern for predicting traffic congestion has been regarded as one the most important issues as it can lead to informal decisions on the routes that motorists take, and on expanding road networks and public transport. Research to predict traffic congested spots, especially in urban areas is thus very important.Typcally, congestion prediction can be used in Advanced Traffic Management Systems (ATMSs) and Advanced Traveller Information Systems in order to develope proactive traffic control strategies and real-time route guidance.[18]\nIn the last decades, concepts of traffic bottleneck and congestion propagation have been considered in many studies. Although most of these originate from Civil Engineering and\nUrban Transportation studies, the advent of super powerful computers and complex algorithms, traffic management and traffic flow prediction to become an interdisciplinary study.\nIn this regard, there have been various efforts to predict short-term traffic flow prediction, including mathematical equations [17], [15], simulation techniques [7], or statistical and regression approaches. However, traffic flow is based on individuals\u2019 decisions, which more likely can be modeled by Artificial Neural Network the best. In other words, traffic flows are made by individuals\u2019 decisions based on their knowledge about currenct traffic and their experiences about past traffic flows, which can be modeled by Artificial Neural Network. Using Neural Network for modeling traffic flow and congestion prediction came to the picture in 1993 in [3]. This work propose a network consisting of one input layer, one hidden, and one output layer. Although this structure was proven to perform well in many applications for predicting traffic flow and travel time and estimation, it was not efficient in lots of other, because of the simple structure. Therefore, some research uses a Neural Network, initially, to extract traffic flow patters (clustering), and then based on each pattern, they come up with a proper model to predict traffic flow [13], [16], [9]. In this trend, [18] different predictors have different performance for various particular time periods. In other words, each predictor can have a super performance only in a particular time period. Therefore, they combined several predictors together as module to have a better performance for longer time periods.\nThe data regarding Traffic Flow and Traffic Congestion are two instances of Spatio-temporal data. They embady a location (Spatial Feature) and a time (Temporal feature). Besides, as we already mentioned, traffic flow and traffic congestion are based on human actions [1]. In [11], the authors propose a fully automatic deep model for human-action-based spatiotemporal data. This model first utilizes Convolutional Neural Network model (CNN) to learn the spatio-temporal features. Then, in the second part of this model, they use the output of the first step to train a recurrent neural network model (RNN) in order to classify the entire sequence. [11] does not mention traffic issues as one of the possible applications of their work, however it seems promising to make some model, which is\nar X\niv :1\n70 3.\n01 00\n6v 1\n[ cs\n.L G\n] 3\nM ar\n2 01\ninspired by their model, to predict traffic flow and congestion. In 2015, [11] Deep Learning theory was put into practice for large-scale congestion prediction. To this end, they utilized Restricted Boltzmann Machine [5] and Recurrent Neural Network [4] to model and predict the traffic congestion. In order to do this, they convert all the speed data of Taxis in Ningbo, China to binary values (i.e. the speed more than a threshold is 1, otherwise it is 0), and then call these values Congestion Conditions. Therefore, the network congestion condition data will be a matrix as follows: C11 C 2 1 C 3 1 . . . C T 1 C12 C 2 2 C 3 2 . . . C T 2 ... ... ... . . .\n... C1N C 2 N C 3 N . . . C T N  Each element in the matrix indicates congestion condition in a specific point at a specific time slot. Therefore, Ctn represents the congestion condition on the nth point of the traffic network at tth time slot (The Network has N point). Give this matrix to the model presented in [11], the result will be the predicted traffic condition for each point at T+1. C11 C 2 1 C 3 1 . . . C T 1 C12 C 2 2 C 3 2 . . . C T 2 ... ... ... . . .\n... C1N C 2 N C 3 N . . . C T N\n =====\u21d2  CT+11 CT+12\n... CT+1N  Although [11] presented a good performance for predicting traffic condition, it has some drawbacks: \u2022 The traffic condition is limited in either Congested or\nNot-Congested (1 or 0). However, in real applications, we usually need a range of values (or colors in case of Map) to show amount of traffic flow. \u2022 The traffic condition is set based on a specific threshold (for example 20 km/h). If the average speed is less than the threshold the traffic condition will be set as congested, otherwise it will be Not-congested. Nevertheless, having a specific threshold for the whole network is inappropriate. Rather, the traffic condition is supposed to be set based on the ratio of average speed of vehicles to possible max speed (Speed limit). \u2022 In the model presented in [11], authors did not consider any order for Network points as the input (the rows of the matrix). However, the spatial influence of adjacent network points should be taken into consideration.\nIn this paper, we try to predict the traffic flow of Traffic Network points, where we do not have any historical data about them, based on the traffic patterns of Traffic Network points. Therefore, our contributions are as follows:\n1) We formally define the traffic flows prediction concepts. 2) We introduce a normalized data representation, which\ncan be used in Neural Network algorithms, or other methods. 3) We present a Deep Convolutional Network, which can be able to learn traffic flow of different traffic points.\n4) Then, we present a Recurrent Neural Network, which, apart from its structure, can do the same as Convolutional Network. 5) Both of these models are able to predict n-level traffic prediction for different points of the traffic (e.g. Quiet, light traffic, heavy traffic, congested, etc.) 6) They also put up the predicted average speeds on different points of the traffic network based on the speed limits in that point (e.g. 0.65 of speed limit). 7) Then, we present a Recurrent Neural Network In the rest of this paper, we start our work by some preliminaries in section II. We define all the main traffic flow concepts and then bring up the problem we are going to solve. We also, introduce two deep network model, and describe their structures broadly. In section III, we explain our models and methods in more details. Then, we experimentally evaluate our proposed prediction models and compare them with more simple models in section IV."}, {"heading": "II. PRELIMINARIES", "text": "In this section, we give formal definitions of traffic flows prediction problem in subsection II-A. Then in subsection II-B, we formally introduce the problem presented in this work."}, {"heading": "A. Formal Definitions", "text": "A traffic Network comprises a set of roads, as well as set of junctions. Junctions can be intersections of streets, exitentrance of highways, roundabouts, beginning-end point of a road, U-turns, etc. In the subject of traffic flows, we can consider junctions as the main points of the network, because these points can be major factors of changing the traffic flows. By way of explanation, typically a traffic flow may not change significantly between two junctions, but it may change because of traffic lights, exit-entrance, and so on. Consequently, almost all of the traffic Network points and traffic sensors are installed in junctions.\nDefinition 1 (Network Points). In this study, we represent a road (streets, highways, etc.) by N points based on the junctions on that road. Each of these points may indicate the traffic condition (for example congested) on that point. Consequently, the whole Traffic Network Condition can be presented by set of all junctions on that Network, which are called Network Points and denoted by N . It is worth mentioning that each Network point has spatial interaction with adjacent Network points, and traffic flow conditions of a point may get/have influence from/on the adjacent points.\nDefinition 2 (In-flow sequence). Assume S is a Network point and L1, L2, ..., and Ln are adjacent points on the traffic network, which have flow to S, such that L1 is the closest point to S, and Ln is the farthest. The In-flow sequence of S is denoted as In(S).\nIn(S) : Ln \u2192 Ln\u22121 \u2192 ... \u2192 L2 \u2192 L1 \u2192 S Definition 3 (Out-flow sequence). Assume S is a Network point and R1, R2, ..., and Rm are adjacent points on the traffic network, which S has flow to them, such that R1 is the closest\npoint to S, and Rm is the farthest. The Out-flow sequence of S are denoted as Out(S).\nOut(S) : S \u2192 R1 \u2192 R2 \u2192 ... \u2192 Rm\u22121 \u2192 Rm Definition 4 (Point snapshot). Assume S is a Network point and L1, L2, ..., and Ln are In(S), and R1, R2, ..., and Rm are Out(S), such that: Ln \u2192 ... \u2192 L2 \u2192 L1 \u2192 S \u2192 R1 \u2192 R2 \u2192 ... \u2192 Rm Point snapshot at time t, denoted as Snapshot(S, t), is the Traffic Condition of [ Ln, ... , L2, L2, S, R1, R2, ..., Rm ] at time series of [t-\u03b4, ..., t-1, t]. This time series indicates a sequence of the last \u03b4 time points with a specific time interval between each two consecutive time points (for instance, 20 minutes) . Formally, Snapshot(S ,t) is defined as follows:\n t\u2212\u03b4 ... t\u22121 t Ln c Ln t\u2212\u03b4 . . . c Ln t\u22121 c Ln t Ln\u22121 c Ln\u22121 t\u2212\u03b4 . . . c Ln\u22121 t\u22121 c Ln\u22121 t ... ... . . . ... ... L1 c L1 t\u2212\u03b4 . . . c L1 t\u22121 c L1 t S cSt\u2212\u03b4 . . . c S t\u22121 c S t R1 c R1 t\u2212\u03b4 . . . c R1 t\u22121 c R1 t ... ... ... . . . ... Rm\u22121 c Rm\u22121 t\u2212\u03b4 . . . c Rm\u22121 t\u22121 c Rm\u22121 t\nRm c Rm t\u2212\u03b4 . . . c Rm t\u22121 c Rm t  Where c\u03c3\u03c4 indicates traffic condition of point \u03c3 at time \u03c4 . Traffic condition is a value between 0 and 1 (0 \u2264 c\u03c3\u03c4 \u2264 1), and shows the ratio of the average speed of vehicles to the speed limit in point \u03c3 at time \u03c4 . Although it is extremely rare that the average speed exceeds speed limit, in cases which exceed, c\u03c3\u03c4 is considered as 1. It is worth mentioning that Snapshot(S,t) is the input unit for predicting the traffic flow of S at time t+1(for example in 20 minutes). In other words, for predicting the traffic flow of S at time t+1, we need recent \u03b4 traffic condition of point S , as well as recent \u03b4 traffic condition of In(S), and recent \u03b4 traffic condition of Out(S).\nDefinition 5 (Network snapshot). Assume N = {S1,S2,S3, ...,SN}. Snapshot of N at time t, denoted by SNAPSHOT(N , t), and defined as follows:\nSNAPSHOT(N , t) = N\u22c3 i=1 Snapshot(Si, t)\nWhere Snapshot(Si, t) is the Point snapshot of Si at time t, and \u22c3 is the union of snapshots of the Network points. Therefore, Snapshot(Si, t) is a set of all point snapshots of Network points. Fig.1 schematically present SNAPSHOT(N , t).\nIn Fig.1, each box consists of the snapshot of one Network point at time t, thus all boxes indicate snapshot of the whole traffic network. Assume, Fig. 1 is the current snapshot of the\ntraffic network (SNAPSHOT(N , now)). And, It may be the input for prediction of the next time point (for example, in 20 minutes)."}, {"heading": "B. Problem Definition", "text": "Assume we have the historical Network snapshots of a region (e.g. North California), gained from traffic detectors located on Traffic points (Definition 1). Our system can learn traffic patterns from this historical data. Suppose, we have the current and the recent Network snapshots of another region (e.g. Southern California), because recently the latter region was equipped with traffic sensors. In this work, we try to predict the traffic flows of the latter region based on the traffic patterns learned from the former traffic network.\nProblem. Given the historical traffic observations of Network N1 and Snapshot(S, now), S 6\u2208 N1 , predict traffic condition of S at (now + 1), where (now + 1) is the next time point (e.g. traffic condition in 20 minutes from now)."}, {"heading": "III. DEEP TRAFFIC FLOW NETWORK", "text": "In this section, we try to use two deep learning model to solve the problem defined in subsection II-B. In order to do this, we utilize two prominent algorithms, namely, Convolutional Neural Network [8] in subsection III-A and Long Short-Term Memory [6] in III-B."}, {"heading": "A. Deep Traffic Flow convolutional Network", "text": "Now that we defined all the main concepts about Traffic Flow Prediction, we need to introduce our Deep Traffic Flow convolutional Network. Fig.2 illustrates the model while training. As seen, the inputs to this model are categorized in two broad groups, namely, Traffic Condition and Incidents. Traffic Conditions are the set of Network snapshots (See Definition 5). In other words, Traffic Conditions is as follows:\nTraffic Conditions = Z\u22c3 i=1 SNAPSHOT(N , ti)\nWhere Z is the size of the dataset, chosen for training the model, and SNAPSHOT(N , ti) is the Network snapshot in\neach training item. In Fig.2, we have N points in our Network N . For each Network point at a particular time point, we need to show the snapshot (a 2D array with size ((\u03b4 + 1) \u00d7 (n + m +1)).\nOn the other hand, Incidents are Weather inputs or information about Car accidents, Holiday dates, Road construction, and Events, such as soccer match or concerts. Also, sometimes Police may change the traffic flow. Intuitively, we know these incidents may have huge influence on traffic flow. In the first step, past Traffic Conditions are given to the first layer of Convolutional Neural Network as the training set. Then, the result of first layer is given to the second Convolutional layer. This trend continues until we have a set of one dimensional arrays. As we know, in each layer of Convolutional, the size of input will decrease (because of the filter (\u03b6 \u2217 \u03b6) applied on the input).\nWhen the output of a Convolutional layer is a set of 1D values, it is time to add the incident information to the output, and set the input for Fully-connected Network. The outcome Fully-connected Network outcome is the predicting values of Traffic Flow at t + 1. While training, this output should be compared to the actual traffic flows, and loss value should be calculated. By getting help from loss value, the weights and bias values may be updated. In this work, we try to solve the problem introduced in subsection II-B. In order to do this, we used the trained aforementioned model. Fig. 3 shows the test model of Fig. 2. Having the the traffic condition of point S (the point which we try to predict), and traffic condition of In(S) and Out(S) in time interval [now \u2212 \u03b4, now], the output is the traffic condition of S at now + 1."}, {"heading": "B. Long short-term memory Traffic Flow", "text": "In subsection III-A, we introduce our Deep Traffic convolutional Network for solve the problem defined in section II-B.\nIn this subsection, we bring up another method, called Long short-term memory Traffic Flow. In this method, we use the Long short-term memory (LSTM) network [6]. LSTM is a Recurrent Neural Network [4] with more complex structure in the repeating modules. In other words, each repeating modules contains 4 interacting layers, thus LSTM avoids the long-term dependency problem. Fig. 4 shows an instance of an LSTM module.\nIn this work, as we mentioned before, we try to predict the short-term future traffic condition for a Network point, where we do not have the historical Traffic condition about it, based on traffic patterns we learned from another road network.\nConsidering the structure of LSTM, our whole network is as in Fig. 5. In Fig. 5, the traffic condition of point S (the point which we try to predict), and traffic condition of In(S) and Out(S) at time t \u2212 \u03b4, are given to the first LSTM module. Then, in the next step the traffic condition of point S, In(S), and Out(S) at time t\u2212 (\u03b4\u22121), are given to the second LSTM module. This trend continues until the last module. In the last module the output is the traffic condition of S at now + 1."}, {"heading": "IV. EXPERIMENTAL EVALUATION", "text": "In order to examine the performance of our model, we explain our models in detail followed by introducing our dataset. In subsection IV-A, we describe our dataset, and in subsection IV-B, we bring up our method more in detail."}, {"heading": "A. Data set", "text": "In all experiments of this evaluation, we used real traffic data of California State. In order to do this, we used the data presented by Caltrans Performance Measurement System (PeMS)[12]. PeMS utilized over 39,000 detectors to collect real-time traffic data. These sensors cover the freeway system across all major metropolitan areas of the State of California. Therefore, PeMS prepared over 10 years of (historical) traffic flow data. The available data in PeMS are not limited to traffic flow data, but it also archived incidents data, such as, Car accidents, Weather information, Lane closures, etc. In this paper, we trained our model for 51 locations on duration of 48 days. Then, we test the model for the same location for the next 12 days. The raw dataset and cleaned dataset are available in [10]. These datasets can be used as the benchmark for future Traffic Flow Prediction models.\nThe data in PeMS are raw data. In order to use them in our model, we did the following pre-processing steps:\n1) Getting the data: The first step is getting the data from [12]. Thus, we download traffic flows (average speeds) of 58 consecutive locations of US 101 highway for 60 days (each detector on the freeway indicates one location). The aforementioned 60-days is from \u201cAugust 15, 2016\u201d to \u201cOctober 14, 2016\u201d. The granularity for the data is 5 minutes. By way of explanation, we have every-five-minute traffic flow of 58 Network points for 60 days (from \u201cAugust 15, 2016\u201d to \u201cOctober 14, 2016\u201d).\n2) Cleaning the data: The next step is the data cleaning. In order to do this, we checked the data and we noticed for a few temporal points, there is not any traffic flow information. For example, we have the traffic flow for Dayn at 13:45 and 13:55, but no data for 13:50. In this case, we calculate the mean values of data at 13:45 and 13:55, and consider them for 13:50.\n3) Normalizing the data: The main part of our data gathering is the normalizing of the data. In our experiment, we consider the number of In-flow and Out-flow for each network point are 4 (see Definition 2 and Definition 3). The In-flow and Out-flow values can be defined based on condition of case study, such as, the distance between two consecutive Network Points, average speed, etc. Defining the size of In-flow and Out-flow can be consider as the future work. Also, we assume that in each point snapshot we have traffic conditions of time t, and 4 time steps before t (\u03b4 = 4, see Definition 4). Therefore, point snapshots are 9 \u00d7 5 (( n + m + 1) \u00d7 (\u03b4 + 1)). Although we 58 network position, we will not be able to make point snapshots for more than 50 of them, because for the first 4 points we do not have In-flow, and the last 4 of them, we do not have Out-flow.\nBesides, we batch the data in buckets of 30-minutes based on the day of the week and time. Put differently, all the traffic flows of Mondays at 8:00 am are considered in the same buckets. Thus, we assign values of \u201c0 to 6\u201d to the days of the week (i.e. 0 is assigned to Sunday, 1 is assigned to Monday, and so on). At same time we assign values \u201c0 to 47\u201d to the time of the day (i.e. 0 is assigned to [00:00, 00:30), 1 is assigned [00:30, 01:00), and so on).\nNow that we convert time to two values, it is the time to normalize and prepare our data for training and the test. For normalizing the data, we need to convert all the values (traffic flow information and time) to values in the range [0, 1]. In order to do this, we divide all values by their possible maximum values. For this reason, we divide days and time points by 6 and 47 respectively. Also, we find the ratio of traffic flow of each point to the possible max speed (Speed limit). Hence, a sample of point snapshot is as follows:\n0.5, 0.6\n t\u22124 t\u22123 t\u22122 t\u22121 t L4 0.5 0.6 0.4 0.5 0.3 L3 0.4 0.7 0.4 0.8 0.5 L2 0.2 0.9 0.3 0.3 0.4 L1 0.4 0.7 0.5 0.6 0.5 S 0.3 0.8 0.1 0.8 0.9 R1 0.5 0.6 0.5 0.4 0.3 R2 0.4 0.7 0.3 0.9 0.5 R3 0.5 0.6 0.5 0.4 0.3 R4 0.4 0.7 0.3 0.9 0.5  In this instance, Day value and Time value are equal to 0.5 and 0.6, respectively (i.e. It is Wednesday at 14:00 to 14:30). In the matrix of traffic conditions, we have 9 rows, indicating the 4 In-flows, the 4 Out-flow, and the Source which is supposed\nto be predicting. Also, there are 5 columns, 1 column for time t, and 4 columns for the last 4 time points before t. The time interval between two consecutive time values is 5 minutes (the granularity we chose while getting the data)."}, {"heading": "B. Deep learning-based method", "text": "Now that we have the normalized cleaned data from the subsection IV-A, we need to implement two aforementioned methods in section III, namely, Deep Traffic Flow convolutional Network and Long short-term memory Traffic Flow to learn the traffic flow (traffic pattern) of one specific Road Network, N1). Then, the learned models should be used to predict another road Network, N2 (see subsection II-B). In this experiment, we use the first 20 Network points of normalized cleaned data as the training set and the rest 30 Network points as the test set. As we know, former Network points are southern part of dataset, and the latter ones belong to the northern section. Therefore, the two sets are disjoint in order to evaluate the generalization ability of the proposed methods (see subsection II-B).\nIn order to evaluate the proposed methods, we employed a system as follows: \u2022 Intel(R) Core(TM) i7 CPU 960 @ 3.20GHZ \u2022 8GB Ram \u2022 Quadro 600 NVDIA GPU 1GB We designed our Deep learning architectures using Lasagne Deep learning framework [2] installed on Theano [14]. The specifications of the proposed Networks are presented in Tables I and II, where inputs and outputs size of each layer, as well as their filters size are tabulated.\nIt is worth mentioning that, in this work, we used the Euclidean loss function to train the networks since our proposed problem is intrinsically categorized as Regression. Besides, intuitively, we know that traffic flow data are unbalanced. In other words, traffic flows are typically heavy in few hours of a day. Therefore, our data while traffic was heavy are significantly less than the light traffic data. In order to avoid biased training, we used a regularization equation for our loss as follows:\nLoss =\n\u221a\u2211N i=1[(Xi \u2212 Yi)2 + \u03c9i\u03b1]\nN (1)\nwhere \u03b1 is the absolute value of Xi \u2212 Yi, and \u03c9i is as follows:\n\u03c9i =\n{ 0, if Yi > 0.5\n1, otherwise\nEach of the proposed networks are trained for 30 epochs over the trained dataset containing the flow information for 20 Network points over of the course of 2 months. The trained networks are then used to predict congestion conditions of the road network.\nFig. 6 illustrates the Root Mean Square error (RMSE) error for 30 Network points. The RMSE is computed for each day at a specific Network point and the distribution of RMSE error for each Network point is plotted as a box plot in Fig. 6 for the CNN. On the other hand, Fig. 7 presents the same RMSE plot for LSTM network. As these plots illustrate, the RMSE for CNN is lower than LSTM and thus results in lower standard deviation.\nIn order to further evaluate the performance of the proposed methods on the benchmark, we examine the prediction of each network over the course of a day. Fig. 8 presents the predicted normalized average speeds for CNN and LSTM networks as well as the ground-truth data. The proposed methods successfully predict the congestion condition with high accuracy in compared with the ground-truth data. However, the error increases slightly during the rush hours and that is due to the unbalanced nature of the dataset. However, The proposed regularization term effectively decreased the gap during the rush hour.\nHereby, we take a deeper look into the prediction during the rush hours. Fig. 9 illustrates the congestion prediction for a single Network point over 30 consecutive days. For this experiment we utilized the information for Network point number 21 at 7:30 am. As shown in this figure, the error increases as the congestion increases however, both networks successfully follow the trends.\nOn the contrary, Fig. 10 illustrates the predicted network flow using LSTM and CNN for light-traffic conditions where we picked 12:00 pm as an example to plot the predicted average speed for Network point number 21. As shown in this figure, the predictions are more accurate in this case."}, {"heading": "V. CONCLUSION", "text": "Concepts of traffic bottleneck and congestion propagation are critical components of Intelligent transportation network management systems. There have been lot of effort to understand how the traffic flows and short-term prediction of congestion occurrence because of rush hours or incidents, such as car crashes or Sport events, can be beneficial to such systems to effectively manage and direct the traffic to the most appropriate detours. Most of traffic flow prediction systems rely on utilizing a central processing component where the prediction is carried out through aggregation of the information gathered from all measuring stations. Nevertheless,\nsuch system are typically scalable and unable to provide real-time feedback to the system whereas in a decentralized scheme, each node is responsible to predict its own shortterm congestion based on the local current measurements in neighboring nodes.\nIn this work, we introduced a scalable decentralized traffic flow prediction by utilizing deep learning-based method. Therefore each node accurately predicts its own congestion state in real-time based on the congestion state of the neighboring Network point. Besides, proposed method is significantly suitable in the cases, where we need to predict the traffic flow\nof newly installed stations, using Deep Network trained by historical data from another traffic network. we introduced a regularized euclidean loss function that favors high congestion samples over low congestion samples to avoid the impact of the unbalanced training dataset. A novel dataset for this purpose was designed based on the traffic data obtained from traffic control stations in northern California. Extensive experiments conducted on the designed benchmark reflected a successful congestion prediction."}], "references": [{"title": "Sequential deep learning for human action recognition", "author": ["M. Baccouche", "F. Mamalet", "C. Wolf", "C. Garcia", "A. Baskurt"], "venue": "International Workshop on Human Behavior Understanding, pages 29\u201339. Springer", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Lasagne: First release", "author": ["S. Dieleman", "J. Schlter", "C. Raffel", "E. Olson", "S.K. Snderby", "D. Nouri", "D. Maturana", "M. Thoma", "E. Battenberg", "J. Kelly", "J.D. Fauw", "M. Heilman", "diogo", "B. McFee", "H. Weideman", "takacsg", "peterderivaz", "Jon", "instagibbs", "D.K. Rasul", "CongLiu", "Britefury", "J. Degrave"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "The use of neural networks to recognise and predict traffic congestion", "author": ["M.S. Dougherty", "H.R. Kirby", "R.D. Boyle"], "venue": "Traffic engineering & control, 34(6)", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1993}, {"title": "Learning task-dependent distributed representations by backpropagation through structure", "author": ["C. Goller", "A. Kuchler"], "venue": "Neural Networks, 1996., IEEE International Conference on, volume 1, pages 347\u2013352. IEEE", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1996}, {"title": "Reducing the dimensionality of data with neural networks", "author": ["G.E. Hinton", "R.R. Salakhutdinov"], "venue": "Science, 313(5786):504\u2013507", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2006}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation, 9(8):1735\u20131780", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1997}, {"title": "Integrated traffic simulationstatistical analysis framework for online prediction of freeway travel time", "author": ["N. Juri", "A. Unnikrishnan", "S. Waller"], "venue": "Transportation Research Record: Journal of the Transportation Research Board, ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2039}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in neural information processing systems, pages 1097\u20131105", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Development of a hybrid model for dynamic travel-time prediction", "author": ["C. Kuchipudi", "S. Chien"], "venue": "Transportation Research Record: Journal of the Transportation Research Board, ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1855}, {"title": "Traffic dataset, 2016", "author": ["M.D. Laboratory"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "Large-scale transportation network congestion evolution prediction using deep learning theory", "author": ["X. Ma", "H. Yu", "Y. Wang", "Y. Wang"], "venue": "PloS one, 10(3):e0119044", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Direct forecasting of freeway corridor travel times using spectral basis neural networks", "author": ["L. Rilett", "D. Park"], "venue": "Transportation Research Record: Journal of the Transportation Research Board, ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1752}, {"title": "Improved flow-based travel time estimation method from point detector data for freeways", "author": ["L.D. Vanajakshi", "B.M. Williams", "L.R. Rilett"], "venue": "Journal of Transportation Engineering, 135(1):26\u201336", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "Urban traffic flow prediction using a fuzzy-neural approach", "author": ["H. Yin", "S. Wong", "J. Xu", "C. Wong"], "venue": "Transportation Research Part C: Emerging Technologies, 10(2):85\u201398", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2002}, {"title": "Short-term travel time prediction", "author": ["X. Zhang", "J.A. Rice"], "venue": "Transportation Research Part C: Emerging Technologies, 11(3):187\u2013210", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2003}, {"title": "Short-term freeway traffic flow prediction: Bayesian combined neural network approach", "author": ["W. Zheng", "D.-H. Lee", "Q. Shi"], "venue": "Journal of transportation engineering, 132(2):114\u2013121", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [{"referenceID": 15, "context": "[18]", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "In this regard, there have been various efforts to predict short-term traffic flow prediction, including mathematical equations [17], [15], simulation techniques [7], or statistical and regression approaches.", "startOffset": 128, "endOffset": 132}, {"referenceID": 12, "context": "In this regard, there have been various efforts to predict short-term traffic flow prediction, including mathematical equations [17], [15], simulation techniques [7], or statistical and regression approaches.", "startOffset": 134, "endOffset": 138}, {"referenceID": 6, "context": "In this regard, there have been various efforts to predict short-term traffic flow prediction, including mathematical equations [17], [15], simulation techniques [7], or statistical and regression approaches.", "startOffset": 162, "endOffset": 165}, {"referenceID": 2, "context": "Using Neural Network for modeling traffic flow and congestion prediction came to the picture in 1993 in [3].", "startOffset": 104, "endOffset": 107}, {"referenceID": 11, "context": "Therefore, some research uses a Neural Network, initially, to extract traffic flow patters (clustering), and then based on each pattern, they come up with a proper model to predict traffic flow [13], [16], [9].", "startOffset": 194, "endOffset": 198}, {"referenceID": 13, "context": "Therefore, some research uses a Neural Network, initially, to extract traffic flow patters (clustering), and then based on each pattern, they come up with a proper model to predict traffic flow [13], [16], [9].", "startOffset": 200, "endOffset": 204}, {"referenceID": 8, "context": "Therefore, some research uses a Neural Network, initially, to extract traffic flow patters (clustering), and then based on each pattern, they come up with a proper model to predict traffic flow [13], [16], [9].", "startOffset": 206, "endOffset": 209}, {"referenceID": 15, "context": "In this trend, [18] different predictors have different performance for various particular time periods.", "startOffset": 15, "endOffset": 19}, {"referenceID": 0, "context": "Besides, as we already mentioned, traffic flow and traffic congestion are based on human actions [1].", "startOffset": 97, "endOffset": 100}, {"referenceID": 10, "context": "In [11], the authors propose a fully automatic deep model for human-action-based spatiotemporal data.", "startOffset": 3, "endOffset": 7}, {"referenceID": 10, "context": "[11] does not mention traffic issues as one of the possible applications of their work, however it seems promising to make some model, which is ar X iv :1 70 3.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "In 2015, [11] Deep Learning theory was put into practice for large-scale congestion prediction.", "startOffset": 9, "endOffset": 13}, {"referenceID": 4, "context": "To this end, they utilized Restricted Boltzmann Machine [5] and Recurrent Neural Network [4] to model and predict the traffic congestion.", "startOffset": 56, "endOffset": 59}, {"referenceID": 3, "context": "To this end, they utilized Restricted Boltzmann Machine [5] and Recurrent Neural Network [4] to model and predict the traffic congestion.", "startOffset": 89, "endOffset": 92}, {"referenceID": 10, "context": "Give this matrix to the model presented in [11], the result will be the predicted traffic condition for each point at T+1.", "startOffset": 43, "endOffset": 47}, {"referenceID": 10, "context": "Although [11] presented a good performance for predicting traffic condition, it has some drawbacks:", "startOffset": 9, "endOffset": 13}, {"referenceID": 10, "context": "\u2022 In the model presented in [11], authors did not consider any order for Network points as the input (the rows of the matrix).", "startOffset": 28, "endOffset": 32}, {"referenceID": 7, "context": "In order to do this, we utilize two prominent algorithms, namely, Convolutional Neural Network [8] in subsection III-A and Long Short-Term Memory [6] in III-B.", "startOffset": 95, "endOffset": 98}, {"referenceID": 5, "context": "In order to do this, we utilize two prominent algorithms, namely, Convolutional Neural Network [8] in subsection III-A and Long Short-Term Memory [6] in III-B.", "startOffset": 146, "endOffset": 149}, {"referenceID": 5, "context": "In this method, we use the Long short-term memory (LSTM) network [6].", "startOffset": 65, "endOffset": 68}, {"referenceID": 3, "context": "LSTM is a Recurrent Neural Network [4] with more complex structure in the repeating modules.", "startOffset": 35, "endOffset": 38}, {"referenceID": 9, "context": "The raw dataset and cleaned dataset are available in [10].", "startOffset": 53, "endOffset": 57}, {"referenceID": 0, "context": "For normalizing the data, we need to convert all the values (traffic flow information and time) to values in the range [0, 1].", "startOffset": 119, "endOffset": 125}, {"referenceID": 1, "context": "We designed our Deep learning architectures using Lasagne Deep learning framework [2] installed on Theano [14].", "startOffset": 82, "endOffset": 85}], "year": 2017, "abstractText": "Tracking congestion throughout the network road is a critical component of Intelligent transportation network management systems. Understanding how the traffic flows and short-term prediction of congestion occurrence due to rush-hour or incidents can be beneficial to such systems to effectively manage and direct the traffic to the most appropriate detours. Many of the current traffic flow prediction systems are designed by utilizing a central processing component where the prediction is carried out through aggregation of the information gathered from all measuring stations. However, centralized systems are not scalable and fail provide real-time feedback to the system whereas in a decentralized scheme, each node is responsible to predict its own short-term congestion based on the local current measurements in neighboring nodes. We propose a decentralized deep learning-based method where each node accurately predicts its own congestion state in realtime based on the congestion state of the neighboring stations. Moreover, historical data from the deployment site is not required, which makes the proposed method more suitable for newly installed stations. In order to achieve higher performance, we introduce a regularized euclidean loss function that favors high congestion samples over low congestion samples to avoid the impact of the unbalanced training dataset. A novel dataset for this purpose is designed based on the traffic data obtained from traffic control stations in northern California. Extensive experiments conducted on the designed benchmark reflect a successful congestion prediction.", "creator": "LaTeX with hyperref package"}}}