{"id": "1703.10090", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Mar-2017", "title": "A Short Review of Ethical Challenges in Clinical Natural Language Processing", "abstract": "Clinical NLP has yet immense lack in among it how behavioral practice make be commercialization both the advent among heavily scale processing than analyzed complete. However, see prove would remained largely untapped due move slow needs various pressure first prohibitions data access argued in therapies. In this with, better plans the concern should liberties their early reduction it foregoing. We however often sources many particularly dangerous data. Finally, might draw talk to inconsistency that allows compromise where contradicted of empirical research and point even socially harmful applications.", "histories": [["v1", "Wed, 29 Mar 2017 15:12:10 GMT  (33kb)", "http://arxiv.org/abs/1703.10090v1", "First Workshop on Ethics in Natural Language Processing (EACL'17)"]], "COMMENTS": "First Workshop on Ethics in Natural Language Processing (EACL'17)", "reviews": [], "SUBJECTS": "cs.CL cs.CY", "authors": ["simon \\v{s}uster", "st\\'ephan tulkens", "walter daelemans"], "accepted": false, "id": "1703.10090"}, "pdf": {"name": "1703.10090.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["simon.suster@uantwerpen.be", "stephan.tulkens@uantwerpen.be", "walter.daelemans@uantwerpen.be"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 3.\n10 09\n0v 1\n[ cs\n.C L\n] 2\n9 M\nar 2\n01 7\ncontributing to how clinical practice will be revolutionized by the advent of large scale processing of clinical records. However, this potential has remained largely untapped due to slow progress primarily caused by strict data access policies for researchers. In this paper, we discuss the concern for privacy and the measures it entails. We also suggest sources of less sensitive data. Finally, we draw attention to biases that can compromise the validity of empirical research and lead to socially harmful applications."}, {"heading": "1 Introduction", "text": "The use of notes written by healthcare providers in the clinical settings has long been recognized to be a source of valuable information for clinical practice and medical research. Access to large quantities of clinical reports may help in identifying causes of diseases, establishing diagnoses, detecting side effects of beneficial treatments, and monitoring clinical outcomes (Agus, 2016; Goldacre, 2014; Murdoch and Detsky, 2013). The goal of clinical natural language processing (NLP) is to develop and apply computational methods for linguistic analysis and extraction of knowledge from free text reports (Demner-Fushman et al., 2009; Hripcsak et al., 1995; Meystre et al., 2008). But while the benefits of clinical NLP and data mining have been universally acknowledged, progress in the development of clinical NLP techniques has been slow. Several contributing factors have been identified, most notably difficult access to data, limited collaboration between researchers from different groups, and little sharing of implemen-\ntations and trained models (Chapman et al., 2011). For comparison, in biomedical NLP, where the working data consist of biomedical research literature, these conditions have been present to a much lesser degree, and the progress has been more rapid (Cohen and Demner-Fushman, 2014). The main contributing factor to this situation has been the sensitive nature of data, whose processing may in certain situations put patient\u2019s privacy at risk.\nThe ethics discussion is gaining momentum in general NLP (Hovy and Spruit, 2016). We aim in this paper to gather the ethical challenges that are especially relevant for clinical NLP, and to stimulate discussion about those in the broader NLP community. Although enhancing privacy through restricted data access has been the norm, we do not only discuss the right to privacy, but also draw attention to the social impact and biases emanating from clinical notes and their processing. The challenges we describe here are in large part not unique to clinical NLP, and are applicable to general data science as well."}, {"heading": "2 Sensitivity of data and privacy", "text": "Because of legal and institutional concerns arising from the sensitivity of clinical data, it is difficult for the NLP community to gain access to relevant data (Barzilay, 2016; Friedman et al., 2013). This is especially true for the researchers not connected with a healthcare organization. Corpora with transparent access policies that are within reach of NLP researchers exist, but are few. An often used corpus is MIMICII(I) (Johnson et al., 2016; Saeed et al., 2011). Despite its large size (covering over 58,000 hospital admissions), it is only representative of patients from a particular clinical domain (the intensive care in this case) and geographic location (a single hospital in the United States). Assuming that such a specific sample is\nrepresentative of a larger population is an example of sampling bias (we discuss further sources of bias in section 3). Increasing the size of a sample without recognizing that this sample is atypical for the general population (e.g. not all patients are critical care patients) could also increase sampling bias (Kaplan et al., 2014).1 We need more large corpora for various medical specialties, narrative types, as well as languages and geographic areas.\nRelated to difficult access to raw clinical data is the lack of available annotated datasets for model training and benchmarking. The reality is that annotation projects do take place, but are typically constrained to a single healthcare organization. Therefore, much of the effort put into annotation is lost afterwards due to impossibility of sharing with the larger research community (Chapman et al., 2011; Fan et al., 2011). Again, exceptions are either few\u2014e.g. THYME (Styler IV et al., 2014), a corpus annotated with temporal information\u2014or consist of small datasets resulting from shared tasks like the i2b2 and ShARe/CLEF. In addition, stringent access policies hamper reproduction efforts, impede scientific oversight and limit collaboration, not only between institutions but also more broadly between the clinical and NLP communities.\nThere are known cases of datasets that had been used in published research (including reproduction) in its full form, like MiPACQ2, Blulab, EMC Dutch Clinical Corpus and 2010 i2b2/VA (Albright et al., 2013; Kim et al., 2015; Afzal et al., 2014; Uzuner et al., 2011), but were later trimmed down or made unavailable, likely due to legal issues. Even if these datasets were still available in full, their small size is still a concern, and the comments above regarding sampling bias certainly apply. For example, a named entity recognizer trained on 2010 i2b2/VA data, which consists of 841 annotated patient records from three different specialty areas, will due to its size only contain a small portion of possible named entities. Similarly, in linking clinical concepts to an ontology, where the number of output classes is larger (Pradhan et al., 2013), the small amount of training data is a major obstacle to deployment of sys-\n1Sampling bias could also be called selection bias; it is not inherent to the individual documents, but stems from the way these are arranged into a single corpus.\n2The access to the MiPACQ corpus will be re-enabled in the future within the Health NLP Center for distributing linguistic annotations of clinical texts (Guergana Savova, personal communication).\ntems suitable for general use."}, {"heading": "2.1 Protecting the individual", "text": "Clinical notes contain detailed information about patient-clinician encounters in which patients confide not only their health complaints, but also their lifestyle choices and possibly stigmatizing conditions. This confidential relationship is legally protected in US by the HIPAA privacy rule in the case of individuals\u2019 medical data. In EU, the conditions for scientific usage of health data are set out in the General Data Protection Regulation (GDPR). Sanitization of sensitive data categories and individuals\u2019 informed consent are in the forefront of those legislative acts and bear immediate consequences for the NLP research.\nThe GDPR lists general principles relating to processing of personal data, including that processing must be lawful (e.g. by means of consent), fair and transparent; it must be done for explicit and legitimate purposes; and the data should be kept limited to what is necessary and as long as necessary. This is known as data minimization, and it includes sanitization. The scientific usage of health data concerns \u201cspecial categories of personal data\u201d. Their processing is only allowed when the data subject gives explicit consent, or the personal data is made public by the data subject. Scientific usage is defined broadly and includes technological development, fundamental and applied research, as well as privately funded research.\nSanitization Sanitization techniques are often seen as the minimum requirement for protecting individuals\u2019 privacy when collecting data (Berman, 2002; Velupillai et al., 2015). The goal is to apply a procedure that produces a new version of the dataset that looks like the original for the purposes of data analysis, but which maintains the privacy of those in the dataset to a certain degree, depending on the technique. Documents can be sanitized by replacing, removing or otherwise manipulating the sensitive mentions such as names and geographic locations. A distinction is normally drawn between anonymization, pseudonymization and de-identification. We refer the reader to Polonetsky et al. (2016) for an excellent overview of these procedures.\nAlthough it is a necessary first step in protecting the privacy of patients, sanitization has been criticized for several reasons. First, it affects\nthe integrity of the data, and as a consequence, their utility (Duquenoy et al., 2008). Second, although sanitization in principle promotes data access and sharing, it may often not be sufficient to eliminate the need for consent. This is largely due to the well-known fact that original sensitive data can be re-identified through deductive disclosure (Amblard et al., 2014; De Mazancourt et al., 2015; Hardt et al., 2016; Malin et al., 2013; Tene, 2011).3 Finally, sanitization focuses on protecting the individual, whereas ethical harms are still possible on the group level (O\u2019Doherty et al., 2016; Taylor et al., 2017). Instead of working towards increasingly restrictive sanitization and access measures, another course of action could be to work towards heightening the perception of scientific work, emphasizing professionalism and existence of punitive measures for illegal actions (Fairfield and Shtein, 2014; Mittelstadt and Floridi, 2016).\nConsent Clinical NLP typically requires a large amount of clinical records describing cases of patients with a particular condition. Although obtaining consent is a necessary first step, obtaining explicit informed consent from each patient can also compromise the research in several ways. First, obtaining consent is time consuming by itself, and it results in financial and bureaucratic burdens. It can also be infeasible due to practical reasons such as a patient\u2019s death. Next, it can introduce bias as those willing to grant consent represent a skewed population (Nyre\u0301n et al., 2014). Finally, it can be difficult to satisfy the informedness criterion: Information about the experiment sometimes can not be communicated in an unambiguous way, or experiments happen at speed that makes enacting informed consent extremely hard (Bird et al., 2016).\nThe alternative might be a default opt-in policy with a right to withdraw (opt-out). Here, consent can be presumed either in a broad manner\u2014 allowing unspecified future research, subject to ethical restrictions\u2014or a tiered manner\u2014 allowing certain areas of research but not others (Mittelstadt and Floridi, 2016; Terry, 2012). Since the information about the intended use is no longer uniquely tied to each research case but is more general, this could facilitate the reuse of datasets\n3Additionaly, it may be due to organizational skepticism about the effectiveness of sanitization techniques, although it has been shown that automated de-identification systems for English perform on par with manual de-identification (Deleger et al., 2013).\nby several research teams, without the need to ask for consent each time. The success of implementing this approach in practice is likely to depend on public trust and awareness about possible risks and opportunities. We also believe that a distinction between academic research and commercial use of clinical data should be implemented, as the public is more willing to allow research than commercial exploitation (Lawrence, 2016; van Staa et al., 2016).\nYet another possibility is open consent, in which individuals make their data publicly available. Initiatives like Personal Genome Project may have an exemplary role, however, they can only provide limited data and they represent a biased population sample (Mittelstadt and Floridi, 2016).\nSecure access Since withholding data from researchers would be a dubious way of ensuring confidentiality (Berman, 2002), the research has long been active on secure access and storage of sensitive clinical data, and the balance between the degree of privacy loss and the degree of utility. This is a broad topic that is outside the scope of this article. The interested reader can find the relevant information in Dwork and Pottenger (2013), Malin et al. (2013) and Rindfleisch (1997).\nPromotion of knowledge and application of best-of-class approaches to health data is seen as one of the ethical duties of researchers (Duquenoy et al., 2008; Lawrence, 2016). But for this to be put in practice, ways need to be guaranteed (e.g. with government help) to provide researchers with access to the relevant data. Researchers can also go to the data rather than have the data sent to them. It is an open question though whether medical institutions\u2014especially those with less developed research departments\u2014 can provide the infrastructure (e.g. enough CPU and GPU power) needed in statistical NLP. Also, granting access to one healthcare organization at a time does not satisfy interoperability (crossorganizational data sharing and research), which can reduce bias by allowing for more complete input data. Interoperability is crucial for epidemiology and rare disease research, where data from one institution can not yield sufficient statistical power (Kaplan et al., 2014).\nAre there less sensitive data? One criterion which may have influence on data accessibility is whether the data is about living subjects or not. The HIPAA privacy rule under certain conditions\nallows disclosure of personal health information of deceased persons, without the need to seek IRB agreement and without the need for sanitization (Huser and Cimino, 2014). It is not entirely clear though how often this possibility has been used in clinical NLP research or broader.\nNext, the work on surrogate data has recently seen a surge in activity. Increasingly more health-related texts are produced in social media (Abbasi et al., 2014), and patient-generated data are available online. Admittedly, these may not resemble the clinical discourse, yet they bear to the same individuals whose health is documented in the clinical reports. Indeed, linking individuals\u2019 health information from online resources to their health records to improve documentation is an active line of research (Padrez et al., 2015). Although it is generally easier to obtain access to social media data, the use of social media still requires similar ethical considerations as in the clinical domain. See for example the influential study on emotional contagion in Facebook posts by Kramer et al. (2014), which has been criticized for not properly gaining prior consent from the users who were involved in the study (Schroeder, 2014).\nAnother way of reducing sensitivity of data and improving chances for IRB approval is to work on derived data. Data that can not be used to reconstruct the original text (and when sanitized, can not directly re-identify the individual) include text fragments, various statistics and trained models. Working on randomized subsets of clinical notes may also improve the chances of obtaining the data. When we only have access to trained models from disparate sources, we can refine them through ensembling and creation of silver standard corpora, cf. Rebholz-Schuhmann et al. (2011).\nFinally, clinical NLP is also possible on veterinary texts. Records of companion animals are perhaps less likely to involve legal issues, while still amounting to a large pool of data. As an example, around 40M clinical documents from different veterinary clinics in UK and Australia are stored centrally in the VetCompass repository. First NLP steps in this direction were described in the invited talk at the Clinical NLP 2016 workshop (Baldwin, 2016)."}, {"heading": "3 Social impact and biases", "text": "Unlocking knowledge from free text in the health domain has a tremendous societal value. However, discrimination can occur when individuals or groups receive unfair treatment as a result of automated processing, which might be a result of biases in the data that were used to train models. The question is therefore what the most important biases are and how to overcome them, not only out of ethical but also legal responsibility. Related to the question of bias is socalled algorithm transparency (Goodman, 2016; Kamarinou et al., 2016), as this right to explanation requires that influences of bias in training data are charted. In addition to sampling bias, which we introduced in section 2, we discuss in this section further sources of bias. Unlike sampling bias, which is a corpus-level bias, these biases here are already present in documents, and therefore hard to account for by introducing larger corpora.\nData quality Texts produced in the clinical settings do not always tell a complete or accurate patient story (e.g. due to time constraints or due to patient treatment in different hospitals), yet important decisions can be based on them.4 As language is situated, a lot of information may be implicit, such as the circumstances in which treatment decisions are made (Hersh et al., 2013). If we fail to detect a medical concept during automated processing, this can not necessarily be a sign of negative evidence.5 Work on identifying and imputing missing values holds promise for reducing incompleteness, see Lipton et al. (2016) for an example in sequential modeling applied to diagnosis classification.\nReporting bias Clinical texts may include bias coming from both patient\u2019s and clinician\u2019s reporting. Clinicians apply their subjective judgments to what is important during the encounter with patients. In other words, there is separation between, on the one side, what is observed by the clinician and communicated by the patient, and on the other,\n4A way to increase data completeness and reduce selection bias is the use of nationwide patient registries, as known for example in Scandinavian countries (Schmidt et al., 2015).\n5We can take timing-related \u201ccensoring\u201d effects as an example. In event detection, events prior to the start of an observation may be missed or are uncertain, which means that the first appearance of a diagnosis in the clinical record may not coincide with the occurrence of the disease. Similarly, key events after the end of the observation may be missing (e.g. death, when it occurred in another institution).\nwhat is noted down. Cases of more serious illness may be more accurately documented as a result of clinician\u2019s bias (increased attention) and patient\u2019s recall bias. On the other hand, the cases of stigmatized diseases may include suppressed information. In the case of traffic injuries, documentation may even be distorted to avoid legal consequences (Indrayan, 2013).\nWe need to be aware that clinical notes may reflect health disparities. These can originate from prejudices held by healthcare practitioners which may impact patients\u2019 perceptions; they can also originate from communication difficulties in the case of ethnic differences (Zestcott et al., 2016). Finally, societal norms can play a role. Brady et al. (2016) find that obesity is often not documented equally well for both sexes in weight-addressing clinics. Young males are less likely to be recognized as obese, possibly due to societal norms seeing them as \u201cstocky\u201d as opposed to obese. Unless we are aware of such bias, we may draw premature conclusions about the impact of our results.\nIt is clear that during processing of clinical texts, we should strive to avoid reinforcing the biases. It is difficult to give a solution on how to actually reduce the reporting bias after the fact. One possibility might be to model it. If we see clinical reports as noisy annotations for the patient story in which information is left-out or altered, we could try to decouple the bias from the reports. Inspiration could be drawn, for example, from the work on decoupling reporting bias from annotations in visual concept recognition (Misra et al., 2016).\nObservational bias Although variance in health outcome is affected by social, environmental and behavioral factors, these are rarely noted in clinical reports (Kaplan et al., 2014). The bias of missing explanatory factors because they can not be identified within the given experimental setting is also known as the streetlight effect. In certain cases, we could obtain important prior knowledge (e.g. demographic characteristics) from data other than clinical notes.\nDual use We have already mentioned linking personal health information from online texts to clinical records as a motivation for exploring surrogate data sources. However, this and many other applications also have potential to be applied in both beneficial and harmful ways. It is easy to imagine how sensitive information from clinical notes can be revealed about an individual who\nis present in social media with a known identity. More general examples of dual use are when the NLP tools are used to analyze clinical notes with a goal of determining individuals\u2019 insurability and employability."}, {"heading": "4 Conclusion", "text": "In this paper, we reviewed some challenges that we believe are central to the work in clinical NLP. Difficult access to data due to privacy concerns has been an obstacle to progress in the field. We have discussed how the protection of privacy through sanitization measures and the requirement for informed consent may affect the work in this domain. Perhaps, it is time to rethink the right to privacy in health in the light of recent work in ethics of big data, especially its uneasy relationship to the right to science, i.e. being able to benefit from science and participate in it (Tasioulas, 2016; Verbeek, 2014). We also touched upon possible sources of bias that can have an effect on the application of NLP in the health domain, and which can ultimately lead to unfair or harmful treatment."}, {"heading": "Acknowledgments", "text": "We would like to thank Madhumita and the anonymous reviewers for useful comments. Part of this research was carried out in the framework of the Accumulate IWT SBO project, funded by the government agency for Innovation by Science and Technology (IWT)."}], "references": [{"title": "Social media analytics for smart health", "author": ["Abbasi et al.2014] Ahmed Abbasi", "Donald Adjeroh", "Mark Dredze", "Michael J. Paul", "Fatemeh Mariam Zahedi", "Huimin Zhao", "Nitin Walia", "Hemant Jain", "Patrick Sanvanson", "Reza Shaker"], "venue": null, "citeRegEx": "Abbasi et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Abbasi et al\\.", "year": 2014}, {"title": "ContextD: an algorithm to identify contextual properties of medical terms in a Dutch clinical corpus", "author": ["Afzal et al.2014] Zubair Afzal", "Ewoud Pons", "Ning Kang", "Miriam C.J.M. Sturkenboom", "Martijn J. Schuemie", "Jan A. Kors"], "venue": null, "citeRegEx": "Afzal et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Afzal et al\\.", "year": 2014}, {"title": "Give Up Your Data to Cure Disease, The New York Times, February 6. https://goo.gl/0REG0n", "author": ["David B. Agus"], "venue": null, "citeRegEx": "Agus.,? \\Q2016\\E", "shortCiteRegEx": "Agus.", "year": 2016}, {"title": "Towards comprehensive syntactic and semantic annotations of the clinical narrative", "author": ["W. Ward", "M. Palmer", "G.K. Savova."], "venue": "Journal of the American Medical Informatics Association, 20(5):922\u2013930.", "citeRegEx": "Ward et al\\.,? 2013", "shortCiteRegEx": "Ward et al\\.", "year": 2013}, {"title": "L\u2019impossibilit\u00e9 de l\u2019anonymat dans le cadre de l\u2019analyse du discours", "author": ["Kar\u00ebn Fort", "Michel Musiol", "Manuel Rebuschi"], "venue": "In Journe\u0301e ATALA e\u0301thique et TAL", "citeRegEx": "Amblard et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Amblard et al\\.", "year": 2014}, {"title": "VetCompass: Clinical Natural Language Processing for Animal Health", "author": ["Timothy Baldwin"], "venue": "Clinical NLP 2016 keynote", "citeRegEx": "Baldwin.,? \\Q2016\\E", "shortCiteRegEx": "Baldwin.", "year": 2016}, {"title": "How NLP can help cure cancer? NAACL\u201916 keynote", "author": ["Regina Barzilay"], "venue": null, "citeRegEx": "Barzilay.,? \\Q2016\\E", "shortCiteRegEx": "Barzilay.", "year": 2016}, {"title": "Confidentiality issues for medical data miners", "author": ["Jules J. Berman"], "venue": "Artificial Intelligence in Medicine,", "citeRegEx": "Berman.,? \\Q2002\\E", "shortCiteRegEx": "Berman.", "year": 2002}, {"title": "Exploring or Exploiting? Social and Ethical Implications of Autonomous Experimentation in AI", "author": ["Bird et al.2016] Sarah Bird", "Solon Barocas", "Kate Crawford", "Fernando Diaz", "Hanna Wallach"], "venue": "InWorkshop on Fairness, Accountability,", "citeRegEx": "Bird et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Bird et al\\.", "year": 2016}, {"title": "Suboptimal Clini", "author": ["Vidhu V. Thaker", "Todd Lingren", "Jessica G. Woo", "Stephanie S. Kennebeck", "Bahram Namjou-Khales", "Ashton Roach", "Jonathan P. Bickel", "Nandan Patibandla", "Guergana K. Savova"], "venue": null, "citeRegEx": "Brady et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Brady et al\\.", "year": 2016}, {"title": "Overcoming barriers to NLP for clinical text: the role of shared tasks and the need for additional", "author": ["Prakash M. Nadkarni", "Lynette Hirschman", "Leonard W. D\u2019Avolio", "Guergana K. Savova", "\u00d6zlem Uzuner"], "venue": null, "citeRegEx": "Chapman et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chapman et al\\.", "year": 2011}, {"title": "Biomedical natural language processing", "author": ["Cohen", "Dina Demner-Fushman"], "venue": null, "citeRegEx": "Cohen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cohen et al\\.", "year": 2014}, {"title": "Faire du TAL sur des donn\u00e9es personnelles : un oxymore", "author": ["Alain Couillault", "Gilles Adda", "Ga\u00eblle Recourc\u00e9"], "venue": "TALN", "citeRegEx": "Mazancourt et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mazancourt et al\\.", "year": 2015}, {"title": "Largescale evaluation of automated clinical note", "author": ["Katalin Molnar", "Guergana Savova", "Fei Xia", "Todd Lingren", "Qi Li", "Keith Marsolo", "Anil Jegga", "Megan Kaiser", "Laura Stoutenborough", "Imre Solti"], "venue": null, "citeRegEx": "Deleger et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Deleger et al\\.", "year": 2013}, {"title": "What can natural language processing do for clinical decision support", "author": ["Wendy W. Chapman", "Clement J. McDonald"], "venue": "Journal of Biomedical Informatics,", "citeRegEx": "Demner.Fushman et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Demner.Fushman et al\\.", "year": 2009}, {"title": "Considering something ELSE: Ethical, legal and socio-economic factors in medical imaging and medical informatics", "author": ["Carlisle George", "Anthony Solomonides"], "venue": null, "citeRegEx": "Duquenoy et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Duquenoy et al\\.", "year": 2008}, {"title": "Toward practicing privacy", "author": ["Dwork", "Pottenger2013] Cynthia Dwork", "Rebecca Pottenger"], "venue": "Journal of the American Medical Informatics Association,", "citeRegEx": "Dwork et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2013}, {"title": "Big data, big problems: Emerging issues in the ethics of data science and journalism", "author": ["Fairfield", "Shtein2014] Joshua Fairfield", "Hannah Shtein"], "venue": "Journal of Mass Media Ethics,", "citeRegEx": "Fairfield et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Fairfield et al\\.", "year": 2014}, {"title": "Part-of-speech tagging for clinical text: wall or bridge between institutions", "author": ["Fan et al.2011] Jung-wei Fan", "Rashmi Prasad", "Romme M. Yabut", "Richard M. Loomis", "Daniel S. Zisook", "John E. Mattison", "Yang Huang"], "venue": null, "citeRegEx": "Fan et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Fan et al\\.", "year": 2011}, {"title": "Natural language processing: state of the art and prospects for significant progress, a workshop sponsored by the National Library of Medicine", "author": ["Thomas C. Rindflesch", "Milton Corn"], "venue": null, "citeRegEx": "Friedman et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Friedman et al\\.", "year": 2013}, {"title": "The NHS plan to share our medical data can save lives but must be done right. https://goo.gl/MH2eC0", "author": ["Ben Goldacre"], "venue": null, "citeRegEx": "Goldacre.,? \\Q2014\\E", "shortCiteRegEx": "Goldacre.", "year": 2014}, {"title": "A Step Towards Accountable Algorithms?: Algorithmic Discrimination and the European Union General Data Protection", "author": ["Bryce W. Goodman"], "venue": "In NIPS Symposium on Machine Learning and the Law", "citeRegEx": "Goodman.,? \\Q2016\\E", "shortCiteRegEx": "Goodman.", "year": 2016}, {"title": "Equality of opportunity in supervised learning", "author": ["Hardt et al.2016] Moritz Hardt", "Eric Price", "Nati Srebro"], "venue": null, "citeRegEx": "Hardt et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Hardt et al\\.", "year": 2016}, {"title": "Caveats for the use", "author": ["Mark G. Weiner", "Peter J. Embi", "Judith R. Logan", "Philip R.O. Payne", "Elmer V. Bernstam", "Harold P. Lehmann", "George Hripcsak", "Timothy H. Hartzog", "James J. Cimino", "Joel H. Saltz"], "venue": null, "citeRegEx": "Hersh et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Hersh et al\\.", "year": 2013}, {"title": "The social impact of natural language processing", "author": ["Hovy", "Spruit2016] Dirk Hovy", "Shannon L. Spruit"], "venue": "In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume", "citeRegEx": "Hovy et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Hovy et al\\.", "year": 2016}, {"title": "Unlocking clinical data from narrative reports: a study of natural language processing", "author": ["Carol Friedman", "Philip O. Alderson", "William DuMouchel", "Stephen B. Johnson", "Paul D. Clayton"], "venue": null, "citeRegEx": "Hripcsak et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Hripcsak et al\\.", "year": 1995}, {"title": "Don\u2019t take your EHR to heaven, donate it to science: legal and research policies for EHR post mortem", "author": ["Huser", "Cimino2014] Vojtech Huser", "James J. Cimino"], "venue": "Journal of the AmericanMedical Informatics Association,", "citeRegEx": "Huser et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Huser et al\\.", "year": 2014}, {"title": "MIMIC-III, a freely accessible critical care", "author": ["Tom J. Pollard", "Lu Shen", "Li-wei H. Lehman", "Mengling Feng", "Mohammad Ghassemi", "Benjamin Moody", "Peter Szolovits", "Leo Anthony Celi", "Roger G. Mark"], "venue": null, "citeRegEx": "Johnson et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Johnson et al\\.", "year": 2016}, {"title": "Machine Learning with Personal Data", "author": ["Christopher Millard", "Jatinder Singh"], "venue": "Queen Mary School of Law Legal Studies Research Paper,", "citeRegEx": "Kamarinou et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Kamarinou et al\\.", "year": 2016}, {"title": "Big data and large sample size: a cautionary note on the potential for bias", "author": ["David A. Chambers", "Russell E. Glasgow"], "venue": "Clinical and translational science,", "citeRegEx": "Kaplan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kaplan et al\\.", "year": 2014}, {"title": "A study of concept extraction across different types of clinical notes", "author": ["Kim et al.2015] Youngjun Kim", "Ellen Riloff", "John F. Hurdle"], "venue": "In AMIA Annual Symposium Proceedings,", "citeRegEx": "Kim et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2015}, {"title": "Experimental evidence of massive-scale emotional contagion through social networks", "author": ["Jamie E. Guillory", "Jeffrey T. Hancock"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "Kramer et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kramer et al\\.", "year": 2014}, {"title": "Data Analysis, NHS and Industrial Partners. https://goo.gl/rRIcu5", "author": ["Neil Lawrence"], "venue": null, "citeRegEx": "Lawrence.,? \\Q2016\\E", "shortCiteRegEx": "Lawrence.", "year": 2016}, {"title": "Modeling Missing Data in Clinical Time Series with RNNs", "author": ["David Kale", "Randall Wetzel"], "venue": "arXiv preprint arXiv:1606.04130", "citeRegEx": "Lipton et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lipton et al\\.", "year": 2016}, {"title": "Biomedical data privacy: problems, perspectives, and recent advances", "author": ["Khaled El Emam", "Christine M. O\u2019Keefe"], "venue": "Journal of the American Medical Informatics Association,", "citeRegEx": "Malin et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Malin et al\\.", "year": 2013}, {"title": "Extracting information from textual documents in the electronic health record: a review", "author": ["GuerganaK. Savova", "Karin C. Kipper-Schuler", "John F. Hurdle"], "venue": null, "citeRegEx": "St\u00e9phaneM.Meystre et al\\.,? \\Q2008\\E", "shortCiteRegEx": "St\u00e9phaneM.Meystre et al\\.", "year": 2008}, {"title": "Seeing through the Human Reporting Bias: Visual Classifiers from Noisy Human-Centric Labels", "author": ["Misra et al.2016] Ishan Misra", "C. Lawrence Zitnick", "Margaret Mitchell", "Ross B. Girshick"], "venue": "In The IEEE Conference on Computer Vision and Pat-", "citeRegEx": "Misra et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Misra et al\\.", "year": 2016}, {"title": "The ethics of big data: current and foreseeable issues in biomedical contexts", "author": ["Mittelstadt", "Luciano Floridi"], "venue": "Science and engineering ethics,", "citeRegEx": "Mittelstadt et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Mittelstadt et al\\.", "year": 2016}, {"title": "The inevitable application of big data to health care", "author": ["Murdoch", "Detsky2013] Travis B. Murdoch", "Allan S. Detsky"], "venue": null, "citeRegEx": "Murdoch et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Murdoch et al\\.", "year": 2013}, {"title": "The European Parliament proposal for the new EU General Data Protection Regulation may severely restrict European epidemiological research", "author": ["Nyr\u00e9n et al.2014] Olof Nyr\u00e9n", "Magnus Stenbeck", "Henrik Gr\u00f6nberg"], "venue": "European Journal of Epidemiol-", "citeRegEx": "Nyr\u00e9n et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Nyr\u00e9n et al\\.", "year": 2014}, {"title": "Linking social media and medical", "author": ["Lyle Ungar", "Hansen Andrew Schwartz", "Robert J. Smith", "Shawndra Hill", "Tadas Antanavicius", "Dana M. Brown", "Patrick Crutchley", "David A. Asch", "Raina M. Merchant"], "venue": null, "citeRegEx": "Padrez et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Padrez et al\\.", "year": 2015}, {"title": "Shades of Gray: Seeing the Full Spectrum of Practical Data Deidentification", "author": ["Omer Tene", "Kelsey Finch"], "venue": "Santa Clara Law Review,", "citeRegEx": "Polonetsky et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Polonetsky et al\\.", "year": 2016}, {"title": "Task 1: Share/clef ehealth evaluation lab", "author": ["Noemie Elhadad", "Brett R. South", "David Martinez", "Amy Vogel", "Hanna Suominen", "Wendy W. Chapman", "Guergana Savova"], "venue": "In Online Working Notes of CLEF", "citeRegEx": "Pradhan et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Pradhan et al\\.", "year": 2013}, {"title": "Assessment of NER solutions against the first and second CALBC Silver Standard Corpus", "author": ["Antonio Jimeno Yepes", "Chen Li"], "venue": "Journal of Biomedical Semantics,", "citeRegEx": "RebholzSchuhmann et al\\.,? \\Q2011\\E", "shortCiteRegEx": "RebholzSchuhmann et al\\.", "year": 2011}, {"title": "Privacy, information technology, and health care", "author": ["Thomas C. Rindfleisch"], "venue": "Communications of the ACM,", "citeRegEx": "Rindfleisch.,? \\Q1997\\E", "shortCiteRegEx": "Rindfleisch.", "year": 1997}, {"title": "Multiparameter Intelligent Monitoring in Intensive", "author": ["Saeed et al.2011] Mohammed Saeed", "Mauricio Villarroel", "Andrew T. Reisner", "Gari Clifford", "Li-Wei Lehman", "George Moody", "Thomas Heldt", "Tin H. Kyaw", "Benjamin Moody", "Roger G. Mark"], "venue": null, "citeRegEx": "Saeed et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Saeed et al\\.", "year": 2011}, {"title": "The danish national patient registry: a review of content, data quality, and research potential", "author": ["S.A. Schmidt", "Jakob Lynge Sandegaard", "Vera Ehrenstein", "Lars Pedersen", "Henrik Toft S\u00f8rensen"], "venue": "Clinical Epidemiol-", "citeRegEx": "Schmidt et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Schmidt et al\\.", "year": 2015}, {"title": "Big data and the brave new world of social media research", "author": ["Ralph Schroeder"], "venue": "Big Data & Society,", "citeRegEx": "Schroeder.,? \\Q2014\\E", "shortCiteRegEx": "Schroeder.", "year": 2014}, {"title": "Big Data, Human Rights and the Ethics of Scientific Research. https://goo.gl/QREHUN", "author": ["John Tasioulas"], "venue": "Van Hasselt Lecture", "citeRegEx": "Tasioulas.,? \\Q2016\\E", "shortCiteRegEx": "Tasioulas.", "year": 2016}, {"title": "2017. Group Privacy: New Challenges of Data Technologies", "author": ["Taylor et al.2017] Linnet Taylor", "Luciano Floridi", "Bart van der Sloot"], "venue": null, "citeRegEx": "Taylor et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Taylor et al\\.", "year": 2017}, {"title": "Privacy: The new generations", "author": ["Omer Tene"], "venue": "International Data Privacy Law,", "citeRegEx": "Tene.,? \\Q2011\\E", "shortCiteRegEx": "Tene.", "year": 2011}, {"title": "Protecting patient privacy in the age of big data", "author": ["Nicolas P. Terry"], "venue": "University of Missouri-Kansas City Law Review,", "citeRegEx": "Terry.,? \\Q2012\\E", "shortCiteRegEx": "Terry.", "year": 2012}, {"title": "Big health data: the need to earn public trust. BMJ, 354:i3636", "author": ["Ben Goldacre", "Iain Buchan", "Liam Smeeth"], "venue": null, "citeRegEx": "Staa et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Staa et al\\.", "year": 2016}, {"title": "Recent advances in clinical natural language processing in support of semantic analysis", "author": ["D. Mowery", "Brett R. South", "Maria Kvist", "Hercules Dalianis"], "venue": "Yearbook of Medical Informatics,", "citeRegEx": "Velupillai et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Velupillai et al\\.", "year": 2015}, {"title": "Examining the presence, consequences, and reduction of implicit bias in health care: A narrative review", "author": ["Irene V. Blair", "Jeff Stone"], "venue": "Group Processes & Intergroup Relations", "citeRegEx": "Zestcott et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zestcott et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 14, "context": "The goal of clinical natural language processing (NLP) is to develop and apply computational methods for linguistic analysis and extraction of knowledge from free text reports (Demner-Fushman et al., 2009; Hripcsak et al., 1995; Meystre et al., 2008).", "startOffset": 176, "endOffset": 250}, {"referenceID": 25, "context": "The goal of clinical natural language processing (NLP) is to develop and apply computational methods for linguistic analysis and extraction of knowledge from free text reports (Demner-Fushman et al., 2009; Hripcsak et al., 1995; Meystre et al., 2008).", "startOffset": 176, "endOffset": 250}, {"referenceID": 10, "context": "limited collaboration between researchers from different groups, and little sharing of implementations and trained models (Chapman et al., 2011).", "startOffset": 122, "endOffset": 144}, {"referenceID": 6, "context": "data (Barzilay, 2016; Friedman et al., 2013).", "startOffset": 5, "endOffset": 44}, {"referenceID": 19, "context": "data (Barzilay, 2016; Friedman et al., 2013).", "startOffset": 5, "endOffset": 44}, {"referenceID": 27, "context": "An often used corpus is MIMICII(I) (Johnson et al., 2016; Saeed et al., 2011).", "startOffset": 35, "endOffset": 77}, {"referenceID": 45, "context": "An often used corpus is MIMICII(I) (Johnson et al., 2016; Saeed et al., 2011).", "startOffset": 35, "endOffset": 77}, {"referenceID": 29, "context": "not all patients are critical care patients) could also increase sampling bias (Kaplan et al., 2014).", "startOffset": 79, "endOffset": 100}, {"referenceID": 10, "context": "Therefore, much of the effort put into annotation is lost afterwards due to impossibility of sharing with the larger research community (Chapman et al., 2011; Fan et al., 2011).", "startOffset": 136, "endOffset": 176}, {"referenceID": 18, "context": "Therefore, much of the effort put into annotation is lost afterwards due to impossibility of sharing with the larger research community (Chapman et al., 2011; Fan et al., 2011).", "startOffset": 136, "endOffset": 176}, {"referenceID": 30, "context": "There are known cases of datasets that had been used in published research (including reproduction) in its full form, like MiPACQ, Blulab, EMC Dutch Clinical Corpus and 2010 i2b2/VA (Albright et al., 2013; Kim et al., 2015; Afzal et al., 2014; Uzuner et al., 2011), but were later trimmed down or made unavailable, likely due to legal issues.", "startOffset": 182, "endOffset": 264}, {"referenceID": 1, "context": "There are known cases of datasets that had been used in published research (including reproduction) in its full form, like MiPACQ, Blulab, EMC Dutch Clinical Corpus and 2010 i2b2/VA (Albright et al., 2013; Kim et al., 2015; Afzal et al., 2014; Uzuner et al., 2011), but were later trimmed down or made unavailable, likely due to legal issues.", "startOffset": 182, "endOffset": 264}, {"referenceID": 42, "context": "Similarly, in linking clinical concepts to an ontology, where the number of output classes is larger (Pradhan et al., 2013), the small amount of train-", "startOffset": 101, "endOffset": 123}, {"referenceID": 7, "context": "Sanitization Sanitization techniques are often seen as the minimum requirement for protecting individuals\u2019 privacy when collecting data (Berman, 2002; Velupillai et al., 2015).", "startOffset": 136, "endOffset": 175}, {"referenceID": 53, "context": "Sanitization Sanitization techniques are often seen as the minimum requirement for protecting individuals\u2019 privacy when collecting data (Berman, 2002; Velupillai et al., 2015).", "startOffset": 136, "endOffset": 175}, {"referenceID": 41, "context": "We refer the reader to Polonetsky et al. (2016) for an excel-", "startOffset": 23, "endOffset": 48}, {"referenceID": 15, "context": "their utility (Duquenoy et al., 2008).", "startOffset": 14, "endOffset": 37}, {"referenceID": 4, "context": "This is largely due to the well-known fact that original sensitive data can be re-identified through deductive disclosure (Amblard et al., 2014; De Mazancourt et al., 2015; Hardt et al., 2016; Malin et al., 2013; Tene, 2011).", "startOffset": 122, "endOffset": 224}, {"referenceID": 22, "context": "This is largely due to the well-known fact that original sensitive data can be re-identified through deductive disclosure (Amblard et al., 2014; De Mazancourt et al., 2015; Hardt et al., 2016; Malin et al., 2013; Tene, 2011).", "startOffset": 122, "endOffset": 224}, {"referenceID": 34, "context": "This is largely due to the well-known fact that original sensitive data can be re-identified through deductive disclosure (Amblard et al., 2014; De Mazancourt et al., 2015; Hardt et al., 2016; Malin et al., 2013; Tene, 2011).", "startOffset": 122, "endOffset": 224}, {"referenceID": 50, "context": "This is largely due to the well-known fact that original sensitive data can be re-identified through deductive disclosure (Amblard et al., 2014; De Mazancourt et al., 2015; Hardt et al., 2016; Malin et al., 2013; Tene, 2011).", "startOffset": 122, "endOffset": 224}, {"referenceID": 49, "context": "(O\u2019Doherty et al., 2016; Taylor et al., 2017).", "startOffset": 0, "endOffset": 45}, {"referenceID": 39, "context": "Next, it can introduce bias as those willing to grant consent represent a skewed population (Nyr\u00e9n et al., 2014).", "startOffset": 92, "endOffset": 112}, {"referenceID": 8, "context": "formation about the experiment sometimes can not be communicated in an unambiguous way, or experiments happen at speed that makes enacting informed consent extremely hard (Bird et al., 2016).", "startOffset": 171, "endOffset": 190}, {"referenceID": 51, "context": "Here, consent can be presumed either in a broad manner\u2014 allowing unspecified future research, subject to ethical restrictions\u2014or a tiered manner\u2014 allowing certain areas of research but not others (Mittelstadt and Floridi, 2016; Terry, 2012).", "startOffset": 196, "endOffset": 240}, {"referenceID": 13, "context": "Additionaly, it may be due to organizational skepticism about the effectiveness of sanitization techniques, although it has been shown that automated de-identification systems for English perform on par with manual de-identification (Deleger et al., 2013).", "startOffset": 233, "endOffset": 255}, {"referenceID": 32, "context": "We also believe that a distinction between academic research and commercial use of clinical data should be implemented, as the public is more willing to allow research than commercial exploitation (Lawrence, 2016; van Staa et al., 2016).", "startOffset": 197, "endOffset": 236}, {"referenceID": 7, "context": "Secure access Since withholding data from researchers would be a dubious way of ensuring confidentiality (Berman, 2002), the research has long been active on secure access and storage of sensitive clinical data, and the balance between the degree of privacy loss and the degree of utility.", "startOffset": 105, "endOffset": 119}, {"referenceID": 7, "context": "Secure access Since withholding data from researchers would be a dubious way of ensuring confidentiality (Berman, 2002), the research has long been active on secure access and storage of sensitive clinical data, and the balance between the degree of privacy loss and the degree of utility. This is a broad topic that is outside the scope of this article. The interested reader can find the relevant information in Dwork and Pottenger (2013), Malin et al.", "startOffset": 106, "endOffset": 441}, {"referenceID": 7, "context": "Secure access Since withholding data from researchers would be a dubious way of ensuring confidentiality (Berman, 2002), the research has long been active on secure access and storage of sensitive clinical data, and the balance between the degree of privacy loss and the degree of utility. This is a broad topic that is outside the scope of this article. The interested reader can find the relevant information in Dwork and Pottenger (2013), Malin et al. (2013) and Rindfleisch (1997).", "startOffset": 106, "endOffset": 462}, {"referenceID": 7, "context": "Secure access Since withholding data from researchers would be a dubious way of ensuring confidentiality (Berman, 2002), the research has long been active on secure access and storage of sensitive clinical data, and the balance between the degree of privacy loss and the degree of utility. This is a broad topic that is outside the scope of this article. The interested reader can find the relevant information in Dwork and Pottenger (2013), Malin et al. (2013) and Rindfleisch (1997).", "startOffset": 106, "endOffset": 485}, {"referenceID": 15, "context": "Promotion of knowledge and application of best-of-class approaches to health data is seen as one of the ethical duties of researchers (Duquenoy et al., 2008; Lawrence, 2016).", "startOffset": 134, "endOffset": 173}, {"referenceID": 32, "context": "Promotion of knowledge and application of best-of-class approaches to health data is seen as one of the ethical duties of researchers (Duquenoy et al., 2008; Lawrence, 2016).", "startOffset": 134, "endOffset": 173}, {"referenceID": 29, "context": "Interoperability is crucial for epidemiology and rare disease research, where data from one institution can not yield sufficient statistical power (Kaplan et al., 2014).", "startOffset": 147, "endOffset": 168}, {"referenceID": 0, "context": "health-related texts are produced in social media (Abbasi et al., 2014), and patient-generated data", "startOffset": 50, "endOffset": 71}, {"referenceID": 40, "context": "Indeed, linking individuals\u2019 health information from online resources to their health records to improve documentation is an active line of research (Padrez et al., 2015).", "startOffset": 149, "endOffset": 170}, {"referenceID": 47, "context": "(2014), which has been criticized for not properly gaining prior consent from the users who were involved in the study (Schroeder, 2014).", "startOffset": 119, "endOffset": 136}, {"referenceID": 31, "context": "See for example the influential study on emotional contagion in Facebook posts by Kramer et al. (2014), which has been criticized for not properly gaining prior consent from the users who were involved in the study (Schroeder, 2014).", "startOffset": 82, "endOffset": 103}, {"referenceID": 5, "context": "First NLP steps in this direction were described in the invited talk at the Clinical NLP 2016 workshop (Baldwin, 2016).", "startOffset": 103, "endOffset": 118}, {"referenceID": 23, "context": "As language is situated, a lot of information may be implicit, such as the circumstances in which treatment decisions are made (Hersh et al., 2013).", "startOffset": 127, "endOffset": 147}, {"referenceID": 23, "context": "As language is situated, a lot of information may be implicit, such as the circumstances in which treatment decisions are made (Hersh et al., 2013). If we fail to detect a medical concept during automated processing, this can not necessarily be a sign of negative evidence. Work on identifying and imputing missing values holds promise for reducing incompleteness, see Lipton et al. (2016) for an example in sequential modeling applied to diagnosis classification.", "startOffset": 128, "endOffset": 390}, {"referenceID": 46, "context": "A way to increase data completeness and reduce selection bias is the use of nationwide patient registries, as known for example in Scandinavian countries (Schmidt et al., 2015).", "startOffset": 154, "endOffset": 176}, {"referenceID": 54, "context": "case of ethnic differences (Zestcott et al., 2016).", "startOffset": 27, "endOffset": 50}, {"referenceID": 9, "context": "Brady et al. (2016) find that obesity is often not documented equally well for both sexes in weight-addressing clinics.", "startOffset": 0, "endOffset": 20}, {"referenceID": 36, "context": "Inspiration could be drawn, for example, from the work on decoupling reporting bias from annotations in visual concept recognition (Misra et al., 2016).", "startOffset": 131, "endOffset": 151}, {"referenceID": 29, "context": "Observational bias Although variance in health outcome is affected by social, environmental and behavioral factors, these are rarely noted in clinical reports (Kaplan et al., 2014).", "startOffset": 159, "endOffset": 180}, {"referenceID": 48, "context": "being able to benefit from science and participate in it (Tasioulas, 2016; Verbeek, 2014).", "startOffset": 57, "endOffset": 89}], "year": 2017, "abstractText": "Clinical NLP has an immense potential in contributing to how clinical practice will be revolutionized by the advent of large scale processing of clinical records. However, this potential has remained largely untapped due to slow progress primarily caused by strict data access policies for researchers. In this paper, we discuss the concern for privacy and the measures it entails. We also suggest sources of less sensitive data. Finally, we draw attention to biases that can compromise the validity of empirical research and lead to socially harmful applications.", "creator": "LaTeX with hyperref package"}}}