{"id": "1704.06619", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Apr-2017", "title": "Scientific Article Summarization Using Citation-Context and Article's Discourse Structure", "abstract": "We propose a grid-based approach have developed articles which turns advantage of citation - context and the reference philosophic changed. While codewords still more only type until generating clinical summaries, others changes this related context two into referenced memo has nor do thought accurately seem after article ' s content. Our precise succumbs the problem included gaffes line an citation concluded most the magazine ' represents content and funding defined for each citation. We also sufficient end blurring scientific journal ' h religion for developed yet uefa. We interview reason our changes reasoning under slowing making existing summarization approaches (greater mostly 55% comprehensive over way making performing speed) in terms however \\ textsc {Rouge} dozen on TAC2014 scientific summarization tcap. While the phase-space we use new evaluation name first when biomedical metadata, they of find approaches are force them whereby comparably failed including variants.", "histories": [["v1", "Fri, 21 Apr 2017 16:17:58 GMT  (2066kb,D)", "http://arxiv.org/abs/1704.06619v1", "EMNLP 2015"]], "COMMENTS": "EMNLP 2015", "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["arman cohan", "nazli goharian"], "accepted": true, "id": "1704.06619"}, "pdf": {"name": "1704.06619.pdf", "metadata": {"source": "CRF", "title": "Scientific Article Summarization Using Citation-Context and Article\u2019s Discourse Structure", "authors": ["Arman Cohan", "Nazli Goharian"], "emails": ["arman@ir.cs.georgetown.edu", "nazli@ir.cs.georgetown.edu"], "sections": [{"heading": "1 Introduction", "text": "Due to the expanding rate at which articles are being published in each scientific field, it has become difficult for researchers to keep up with the developments in their respective fields. Scientific summarization aims to facilitate this problem by providing readers with concise and informative representation of contributions or findings of an article. Scientific summarization is different than general summarization in three main aspects (Teufel and Moens, 2002). First, the length of scientific papers are usually much longer than general articles (e.g newswire). Second,\nin scientific summarization, the goal is typically to provide a technical summary of the paper which includes important findings, contributions or impacts of a paper to the community. Finally, scientific papers follow a natural discourse. A common organization for scientific paper is the one in which the problem is first introduced and is followed by the description of hypotheses, methods, experiments, findings and finally results and implications. Scientific summarization was recently further motivated by TAC2014 biomedical summarization track1 in which they planned to investigate this problem in the domain of biomedical science.\nThere are currently two types of approaches towards scientific summarization. First is the articles\u2019 abstracts. While abstracts provide a general overview of the paper, they cannot be considered as an accurate scientific summary by themselves. That is due to the fact that not all the contributions and impacts of the paper are included in the abstract (Elkiss et al., 2008). In addition, the stated contributions are those that the authors deem important while they might be less important to the scientific community. Moreover, contributions are stated in a general and less focused fashion. These problems motivated the other form of scientific summaries, i.e., citation based summaries. Citation based summary is a summary which is formed by utilizing a set of citations to a referenced article (Qazvinian and Radev, 2008; Qazvinian et al., 2013). This set of citations has been previously indicated as a good representation of important findings and contributions of the article. Contributions stated in the citations are usually more focused than the abstract and contain additional information that is not in the abstract (Elkiss et al., 2008).\nHowever, citations may not accurately represent 1Text Analysis Conference - http://www.nist.gov/ tac/\n2014\nar X\niv :1\n70 4.\n06 61\n9v 1\n[ cs\n.C L\n] 2\n1 A\npr 2\n01 7\nthe content of the referenced article as they are biased towards the viewpoint of the citing authors. Moreover, citations may address a contribution or a finding regarding the referenced article without referring to the assumptions and data under which it was obtained.\nThe problem of inconsistency between the degree of certainty of expressing findings between the citing article and referenced article has been also reported (De Waard and Maat, 2012). Therefore, citations by themselves lack the related \u201ccontext\u201d from the original article. We call the textual spans in the reference articles that reflect the citation, the citation-context. Figure 1 shows an example of the citation-context in the reference article (green color) for a citation in the citing article (blue color).\nWe propose an approach to overcome the aforementioned shortcomings of existing scientific summaries. Specifically, we extract citation-context in the reference article for each citation. Then, by using the discourse facets of the citations as well as community structure of the citation-contexts, we extract candidate sentences for the summary. The final summary is formed by maximizing both novelty and informativeness of the sentences in the summary. We evaluate and compare our methods against several well-known summarization methods. Evaluation results on the TAC2014 dataset show that our proposed methods can effectively improve over the well-known existing summarization approaches. That is, we obtained greater than 30% improvement over the highest performing baseline in terms of mean ROUGE scores."}, {"heading": "2 Related work", "text": "Document summarization is a relatively well studied area and various types of approaches for document summarization have been proposed in the past twenty years.\nLatent Semantic Analysis (LSA) has been used in text summarization first by Gong and Liu (2001). Other variations of LSA based summarization approaches have later been introduced (Steinberger and Jezek, 2004; Steinberger et al., 2005; Lee et al., 2009; Ozsoy et al., 2010). Summarization approaches based on topic modeling and Bayesian models have also been explored (Vanderwende et al., 2007; Haghighi and Vanderwende, 2009; Celikyilmaz\nand Hakkani-Tur, 2010; Ritter et al., 2010; Celikyilmaz and Hakkani-Tu\u0308r, 2011; Ma and Nakagawa, 2013; Li and Li, 2014). In these approaches, the content/topic distribution in the final summary is estimated using a graphical probabilistic model. Some approaches have viewed summarization as an optimization task solved by linear programming (Clarke and Lapata, 2008; Berg-Kirkpatrick et al., 2011; Woodsend and Lapata, 2012). Many works have viewed the summarization problem as a supervised classification problem in which several features are used to predict the inclusion of document sentences in the summary. Variations of supervised models have been utilized for summary generation, such as: maximum entropy (Osborne, 2002), HMM (Conroy et al., 2011), CRF (Galley, 2006; Shen et al., 2007; Chali and Hasan, 2012), SVM (Xie and Liu, 2010), logistic regression (Louis et al., 2010) and reinforcement learning (Rioux et al., 2014). Problems with supervised models in context of summarization include the need for large amount of annotated data and domain dependency.\nGraph based models have shown promising results for text summarization. In these approaches, the goal is to find the most central sentences in the document by constructing a graph in which nodes are sentences and edges are similarity between these sentences. Examples of these techniques include LexRank (Erkan and Radev, 2004), TextRank (Mihalcea and Tarau, 2004), and the work by Paul et al. (2010). Maximizing the novelty and preventing\nthe redundancy in a summary is addressed by greedy selection of content summarization (Carbonell and Goldstein, 1998; Guo and Sanner, 2010; Lin et al., 2010). Rhetorical structure of the documents have also been investigated for automatic summarization. In this line of work, dependency and discourse parsing based on Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) is used for analyzing the structure of the documents (Hirao et al., 2013; Kikuchi et al., 2014; Yoshida et al., 2014). Summarization based on rhetorical structure is better suited for shorter documents and is highly dependent on the quality of the discourse parser that is used. Training the discourse parser requires large amount of training data in the RST framework.\nScientific article summarization was first studied by Teufel and Moens (2002) in which they trained a supervised Naive Bayes classifier to select informative content for the summary. Later Elkiss et al. (2008) argue the benefits of citations to scientific work analysis. Cohan et al. (2015) use a search oriented approach for finding relevant parts of the reference paper to citations. Qazvinian and Radev (2008; Qazvinian et al. (2013) use citations to an article to construct its summary. More specifically, they perform hierarchical agglomerative clustering on citations to maximize purity and select most central sentences from each cluster for the final summary. Our work is closest to Qazvinian and Radev (2008) with the difference that they only make use of citations. While citations are useful for summarization, relying solely on them might not accurately capture the original context of the referenced paper. That is, the generated summary lacks the appropriate evidence to reflect the content of the original paper, such as circumstances, data and assumptions under which certain findings were obtained. We address this shortcoming by leveraging the citation-context and the inherent discourse model in the scientific articles."}, {"heading": "3 The summarization approach", "text": "Our scientific summary generation algorithm is composed of four steps: (1) Extracting the citation-context, (2) Grouping citation-contexts, (3) Ranking the sentences within each group and (4) Selecting the sentences for final summary. We assume that the citation text (the text span in\nthe citing article that references another article) in each citing article is already known. We describe each step in the following sub-sections. Our proposed method generates a summary of an article with the premise that the article has a number of citations to it. We call the article that is being referenced the \u201creference article\u201d. We shall note that we tokenized the articles\u2019 text to sentences by using the punkt unsupervised sentence boundary detection algorithm (Kiss and Strunk, 2006). We modified the original sentence boundary detection algorithm to also account for biomedical abbreviations. For the rest of the paper, \u201csentence\u201d refers to units that are output of the sentence boundary detection algorithm, whereas \u201ctext span\u201d or in short \u201cspan\u201d can consist of multiple sentences."}, {"heading": "3.1 Extracting the citation-context", "text": "As described in section 2, one problem with existing citation based summarization approaches is that they lack the context of the referenced paper. Therefore, our goal is to leverage citationcontext in the reference article to correctly reflect the reference paper. To find citation-contexts, we consider each citation as an n-gram vector and use vector space model for locating the relevant text spans in the reference article. More specifically, given a citation c, we return the ranked list of text spans r1, r2, ..., rn which have the highest similarity to c. We call the retrieved text spans reference spans. These reference spans are essentially forming the context for each citation. The similarity function is the cosine similarity between the pivoted normalized vectors. We evaluated four different approaches for forming the citation vector.\n1. All terms in citation except for stopwords, numeric values and citation markers i.e., name of authors or numbered citations. In figure 1 an example of citation marker is shown.\n2. Terms with high inverted document frequency (idf). Idf values of terms have shown to be a good estimate of term informativeness.\n3. Concepts that are represented through noun phrases in the citation, for example in the following: \u201c ... typically achieved by introducing DNA tumor virus oncoproteins such a ... \u201d which is part of a citation, the phrase \u201cDNA tumor virus oncoproteins\u201d is a noun phrase.\n4. Biomedical concepts and noun phrases\nexpanded by related biomedical concepts: This formation is specific to the biomedical domain. It selects biomedical concepts and noun phrases in the citation and uses related biomedical terminology to expand the citation vector. We used Metamap1 for extracting biomedical concepts from the citation text (which is a tool for mapping free form text to UMLS2 concepts). For expanding the citation vector using the related biomedical terminology, we used SNOMED CT3 ontology by which we added synonyms of the concepts in the citation text to the citation vector."}, {"heading": "3.2 Grouping the citation-contexts", "text": "After identifying the context for each citation, we use them to form the summary. To capture various important aspects of the reference article, we form groups of citation-contexts that are about the same topic. We use the following two approaches for forming these groups:\nCommunity detection - We want to find diverse key aspects of the reference article. We form the graph of extracted reference spans in which nodes are sentences and edges are similarity between sentences. As for the similarity function, we use cosine similarity between tf-idf vectors of the sentences. Similar to (Qazvinian and Radev, 2008), we want to find subgraphs or communities whose intra-connectivity is high but inter-connectivity is low. Such quality is captured by the modularity measure of the graph (Newman, 2006; Newman, 2012). Graph modularity quantifies the denseness of the subgraphs in comparison with denseness of the graph of randomly distributed edges and is defined as follows:\nQ = 1\n2m \u2211 vw [ Avw \u2212 kv \u00d7 kw 2m ] \u03b4(cv, cw)\nWhere Avw is the weigh of the edge (v, w); kv is the degree of the vertex v; cv is the community of vertex v; \u03b4 is the Kronecker\u2019s delta function and m = \u2211 vw Avw is the normalization factor.\nWhile the general problem of precise partitioning of the graph into highly dense communities\n1http://metamap.nlm.nih.gov/ 2Unified Medical Language System - a compendium of controlled vocabularies in the biomedical sciences, http:// www.nlm.nih.gov/research/umls\n3http://www.nlm.nih.gov/research/umls/Snomed/ snomed main.html\nthat optimizes the modularity is computationally prohibitive (Brandes et al., 2008), many heuristic algorithms have been proposed with reasonable results. To extract communities from the graph of reference spans, we use the algorithm proposed by Blondel et al. (2008) which is a simple yet accurate and efficient community detection algorithm. Specifically, communities are built in a hierarchical fashion. At first, each node belongs to a separate community. Then nodes are assigned to new communities if there is a positive gain in modularity. This process is applied iteratively until no further improvement in modularity is possible.\nDiscourse model - A natural discourse model is followed in each scientific article. In this method, instead of finding communities to capture different important aspects of the paper, we try to select reference spans based on the discourse model of the paper. The discourse model is according to the following facets: \u201chypothesis\u201d, \u201cmethod\u201d, \u201cresults\u201d, \u201cimplication\u201d, \u201cdiscussion\u201d and \u201cdataset-used\u201d. The goal is to ideally include reference spans from each of these discourse facets of the article in the summary to correctly capture all aspects of the article. We use a one-vs-rest SVM supervised model with linear kernel to classify the reference spans to their respective discourse facets. Training was done on both the citation and reference spans since empirical evaluation showed marginal improvements upon including the reference spans in addition to the citation itself. We use unigram and verb features with tfidf weighting to train the classifier."}, {"heading": "3.3 Ranking model", "text": "To identify the most representative sentences of each group, we require a measure of importance of sentences. We consider the sentences in a group as a graph and rank nodes based on their importance. An important node is a node that has many connections with other nodes. There are various ways of measuring centrality of nodes such as nodes degree, betweenness, closeness and eigenvectors. Here, we opt for eigenvectors and we find the most central sentences in each group by using the \u201cpower method\u201d (Erkan and Radev, 2004) which iteratively updates the eigenvector until convergence."}, {"heading": "3.4 Selecting the sentences for final summary", "text": "After scoring and ranking the sentences in each group which were identified either by discourse model or by community detection algorithm, we employ two strategies for generating the summary within the summary length threshold. \u2022 Iterative: We select top sentences iteratively from\neach group until we reach the summary length threshold. That is, we first pick the top sentence from all groups and if the threshold is not met, we select the second sentence and so forth. In the discourse based method, the following ordering for selecting sentences from groups is used: \u201chypothesis\u201d, \u201cmethod\u201d,\u201cresults\u201d, \u201cimplication\u201d and \u201cdiscussion\u201d. In the community detection method, no pre-determined order is specified. \u2022 Novelty: We employ a greedy strategy similar to\nMMR (Carbonell and Goldstein, 1998) in which sentences from each group are selected based on the following scoring formula:\nscore(S) def=\u03bbSim1(S, D)\n\u2212 (1\u2212 \u03bb)Sim2(S,Summary)\nWhere, for each sentence S, the score is a linear interpolation of similarity of sentence with all other sentences (Sim1) and the similarity of sentence with the sentences already in the summary (Sim2) and \u03bb is a constant. We empirically set \u03bb = 0.7 and also selected top 3 central sentences from each group as the candidates for the final summary."}, {"heading": "4 Experimental setup", "text": ""}, {"heading": "4.1 Data", "text": "We used the TAC2014 biomedical summarization dataset for evaluation of our proposed method. The TAC2014 benchmark contains 20 topics each of which consists of one reference article and several articles that have citations to each reference article (the statistics of the dataset is shown in Table 1). All articles are biomedical papers published by Elsevier. For each topic, 4 experts in biomedical domain have written a scientific summary of length not exceeding 250 words for the reference article. The data also contains annotated citation texts as well as the discourse facets. The latter were used to build the supervised discourse model. The distribution of discourse facets is shown in Table 2."}, {"heading": "4.2 Baselines", "text": "uses a measure called centrality to find the most representative sentences in given sets of sentences. It finds the most central sentences by updating the score of each sentence using an algorithm based on PageRank random walk ranking model (Page et al., 1999). More specifically, the centrality score of each sentence is represented by a centrality matrix p which is updated iteratively through the following equation using a method called \u201cpower method\u201d:\np = ATp\nWhere matrix A is based on the similarity matrix B of the sentences:\nA = [dU + (1\u2212 d)B]\nIn which U is a square matrix with values 1/N and d is a parameter called the damping factor. We set d to 0.1 which is the default suggested value. \u2022 MMR (Carbonell and Goldstein, 1998) - In\nMaximal Marginal Relevance (MMR), sentences are greedily ranked according to a score based on their relevance to the document and the amount of redundant information they carry. It scores sentences based on the maximization of the linear interpolation of the relevance to the document and diversity:\nMMR(S,D) def=\u03bbSim1(S, D)\n\u2212 (1\u2212 \u03bb)Sim2(S,Summary)\nWhere S is the sentence being evaluated, D is the document being summarized, Sim1 and Sim2 are similarity function, Summary is the summary formed by the previously selected sentences and \u03bb is a parameter. We used cosine similarity as similarity functions and we set \u03bb to 0.3, 0.5 and 0.7 for observing the effect of informativeness vs. novelty. \u2022 Citation summary (Qazvinian and Radev, 2008)-\nIn this approach, a network of citations is built and citations are clustered to maximum purity (Zhao and Karypis, 2001) and mutual information. These clusters are then used to generate the final summary by selecting the top central sentences from each cluster in a round-robin fashion. Our approach is similar to this work in that they also use centrality scores on citation network clusters. Since they only focus on citations, comparison of our approach with this work gives a better insight into how beneficial our use of citation-context and article\u2019s discourse model can be in generating scientific summaries."}, {"heading": "5 Results and discussions", "text": ""}, {"heading": "5.1 Evaluation metrics", "text": "We use the ROUGE evaluation metrics which has shown consistent correlation with manually evaluated summarization scores (Lin, 2004). More specifically, we use ROUGE-L, ROUGE-1 and ROUGE-2 to evaluate and compare the quality of the summaries generated by our system. While ROUGE-N focuses on n-gram overlaps, ROUGE-L uses the longest common subsequence to measure the quality of the summary. ROUGE-N where N\nis the n-gram order, is defined as follows:\nROUGE-N =\n\u2211 S\u2208{Gold summaries} \u2211 W\u2208S\nfmatch(W )\u2211 S\u2208{Gold summaries} \u2211 W\u2208S f(W )\nWhereW is the n-gram, f(.) is the count function, fmatch(.) is the maximum number of n-grams cooccurring in the generated summary and in a set of gold summaries. For a candidate summary C with n words and a gold summary S with u sentences, ROUGE-L is defined as follows:\nROUGE-Lrec =\nu\u2211 i=1\nLCS\u222a(ri, C)\u2211u i=1 |ri|\nROUGE-Lprec =\nu\u2211 i=1 LCS\u222a(ri, C)\nn\nWhere LCS\u222a(., .) is the Longest common subsequence (LCS) score of the union of LCS between gold sentence ri and the candidate summary C. ROUGE-L f score is the harmonic mean between precision and recall."}, {"heading": "5.2 Comparison between summarizers", "text": "We generated two sets of summaries using the methods and baselines described in previous sections. We consider short summaries of length 100 words and longer summaries of length 250 words (which corresponds to the length threshold in gold summaries). We also considered the oracle\u2019s performance by averaging over the ROUGE scores of all human summaries calculated by considering one human summary against others in each topic. As far as 100 words summaries, since we did not have gold summaries of that length, we considered the first 100 words from each gold summary. Figure 2 shows the box-and-whisker plots with ROUGE scores. For each metric, the scores of each summarizer in comparison with the baselines for 100 word summaries and 250 words summaries are shown. The citation-context for all the methods were identified by the citation text vector method which uses the citation text except for numeric values, stop words and citation markers (first method in section 3.1). In section 5.3, we analyze the effect of various citation-context extraction methods that we discussed in section 3\non the final summary. The name of each of our methods is shortened by the following convention: [Summarization approach] [Sentence selection strategy]. Summarization approach is based on either community detection (CitationContext-Comm) or discourse model of the article (Citation-Context-Disc) and sentence selection strategy can be iterative (It) or by relevance and diversification (Div).\nWe can clearly observe that our proposed methods achieve encouraging results in comparison with existing baselines. Specifically, for 100 words short summaries, the discourse based method (with 34.6% mean ROUGE-L improvement over the best baseline) and for 250 word summaries, the community based method (with 3.5% mean ROUGE-L improvement over the best baseline) are the best performing methods. We observe relative consistency between different rouge scores for each summarization approach. Grouping citation-context based on both the discourse structure and the communities show comparable results. The community detection approach is thus effectively able to identify diverse aspects of the article. The discourse model of the scientific article is also able to diversify selection of citation contexts for the final summary. These results confirm our hypotheses that using the citation context along with the discourse model of the scientific articles can help producing better summaries.\nComparison of performance of methods on individual topics showed that the citation-context methods consistently over perform all other methods in most of the topics (65% of all topics).\nWhile the discourse approach shows encouraging results, we attribute its limitation in achieving higher ROUGE scores to the classification errors that we observed in intrinsic classification evaluation. In evaluating the performance of several classifiers, linear SVM achieved the highest performance with accuracy of 0.788 in comparison with human annotation performance. Many of the citations cannot exactly belong to only one of the discourse facets of the paper and thus some errors in classification are inevitable. This is also observable in disagreements between the annotators in labeling as reported by (Cohan et al., 2014). This fact influences the diversification and finally the summarization quality.\nAmong baseline summarization approaches, LexRank performs relatively well. Its performance is the best for short summaries among other baselines. This is expected since LexRank tries to find the most central sentences. When the length of the summary is short, the main idea in the summary is usually captured by finding the most representative sentence which LexRank can effectively achieve. However, the sentences that it chooses are usually about the same topic. Hence, the diversity in the gold summaries is not considered. This becomes more visible when we observe 250 word summaries. Our discourse based method can overcome this problem by including important contents for diverse discourse facets (34.6% mean ROUGE-L improvement for 100 words summaries and 13.9% improvement for 250 word summaries). The community based approach achieves the same diversification effect in an unsupervised fashion by forming citation-context communities (27.16% mean ROUGE-L improvement for 100 words summaries and 14.9% improvement for 250 word summaries).\nThe citation based summarization baseline has somewhat average performance among the baseline methods. This confirms that relying only on the citations can not be optimal for scientific summarization. While LSA approach performs relatively well, we observe lower scores for all variations of MMR approaches. We attribute the low performance of MMR to its sub optimal greedy selection of sentences from relatively long scientific articles.\nBy comparing the two sentence selection approaches (i.e., iterative and diversificationrelevance), we observe that while for shorter length summaries the method based on diversification performs better, for the longer summaries results for the two methods are comparable. This is because when the length threshold is smaller, iterative approach may fail to select best representative sentences from all the groups. It essentially selects one sentence from each group until the length threshold is met, and consequently misses some aspects. Whereas, the diversification method selects sentences that maximize the gain in informativeness and at the same time contributes to the novelty of the summary. In longer summaries, due to larger threshold, iterative approach seems to be able\nto select the top sentences from each group, enabling it to reflect different aspect of the paper. Therefore, the iterative approach performs comparably well to the diversification approach. This outcome is expected because the number of groups are small. For discourse method, there are 5 different discourse facets and for community method, on average 5.2 communities are detected. Hence, iterative selection can select sentences from most of these groups within 250 words limit summaries."}, {"heading": "5.3 Analysis of strategies for citation-context extraction", "text": "Figure 3 shows ROUGE-L results for 250 words summaries based on using different citationcontext extraction approaches, described in section 3.1. Relatively comparable performance for all the approaches is achieved. Using the citation text for extracting the context is almost as effective as other methods. Keywords approach which uses the terms with high idf values for locating the context achieves slightly higher Rouge-L precision while it has the lowest recall. This is expected since keywords approach chooses only informative terms for extracting citation-contexts. This results in missing terms that may not be keywords by themselves but help providing meaning. Noun phrases has the highest mean F-score and thus suggests the fact that noun phrases are good indicators of important concepts in scientific text. We attribute the high recall of noun phrases to the fact that most important concepts are captured by only selecting noun phrases. Interestingly, introducing biomedical concepts and expanding the citation vector by related concepts does not improve\nthe performance. This approach achieves a relatively higher recall but a lower mean precision. While capturing domain concepts along with noun phrases helps improving the performance, adding related concepts to the citation vector causes drift from the original context as expressed in the reference article. Therefore some decline in performance is incurred."}, {"heading": "6 Conclusion", "text": "We proposed a pipeline approach for summarization of scientific articles which takes advantage of the article\u2019s inherent discourse model and citation-contexts extracted from the reference article1. Our approach focuses on the problem of lack of context in existing citation based summarization approaches. We effectively achieved improvement over several well known summarization approaches on the TAC2014 biomedical summarization dataset. That is, in all cases we improved over the baselines; in some cases we obtained greater than 30% improvement for mean ROUGE scores over the best performing baseline. While the dataset we use for evaluation of scientific articles is in biomedical domain, most of our approaches are general and therefore adaptable to other scientific domains."}, {"heading": "Acknowledgments", "text": "The authors would like to thank the three anonymous reviewers for their valuable feedback and comments. This research was partially supported by National Science Foundation (NSF) under grant CNS-1204347.\n1Code can be found at: https://github.com/acohan/ scientific-summ"}], "references": [{"title": "Jointly learning to extract and compress", "author": ["Taylor Berg-Kirkpatrick", "Dan Gillick", "Dan Klein."], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 481\u2013490.", "citeRegEx": "Berg.Kirkpatrick et al\\.,? 2011", "shortCiteRegEx": "Berg.Kirkpatrick et al\\.", "year": 2011}, {"title": "Fast unfolding of communities in large networks", "author": ["Vincent D Blondel", "Jean-Loup Guillaume", "Renaud Lambiotte", "Etienne Lefebvre."], "venue": "Journal of Statistical Mechanics: Theory and Experiment, 2008(10):P10008.", "citeRegEx": "Blondel et al\\.,? 2008", "shortCiteRegEx": "Blondel et al\\.", "year": 2008}, {"title": "On modularity clustering", "author": ["Ulrik Brandes", "Daniel Delling", "Marco Gaertler", "Robert Gorke", "Martin Hoefer", "Zoran Nikoloski", "Dorothea Wagner."], "venue": "Knowledge and Data Engineering, IEEE Transactions on, 20(2):172\u2013188.", "citeRegEx": "Brandes et al\\.,? 2008", "shortCiteRegEx": "Brandes et al\\.", "year": 2008}, {"title": "The use of mmr, diversity-based reranking for reordering documents and producing summaries", "author": ["Jaime Carbonell", "Jade Goldstein."], "venue": "SIGIR, pages 335\u2013336. ACM.", "citeRegEx": "Carbonell and Goldstein.,? 1998", "shortCiteRegEx": "Carbonell and Goldstein.", "year": 1998}, {"title": "A hybrid hierarchical model for multi-document summarization", "author": ["Asli Celikyilmaz", "Dilek Hakkani-Tur."], "venue": "ACL, pages 815\u2013824. Association for Computational Linguistics.", "citeRegEx": "Celikyilmaz and Hakkani.Tur.,? 2010", "shortCiteRegEx": "Celikyilmaz and Hakkani.Tur.", "year": 2010}, {"title": "Discovery of topically coherent sentences for extractive summarization", "author": ["Asli Celikyilmaz", "Dilek Hakkani-T\u00fcr."], "venue": "ACL: HLT-Volume 1, pages 491\u2013499. Association for Computational Linguistics.", "citeRegEx": "Celikyilmaz and Hakkani.T\u00fcr.,? 2011", "shortCiteRegEx": "Celikyilmaz and Hakkani.T\u00fcr.", "year": 2011}, {"title": "Query-focused multi-document summarization: Automatic data annotations and supervised learning approaches", "author": ["Yllias Chali", "Sadid a. Hasan."], "venue": "Nat. Lang. Eng., 18(1):109\u2013145, January.", "citeRegEx": "Chali and Hasan.,? 2012", "shortCiteRegEx": "Chali and Hasan.", "year": 2012}, {"title": "Global inference for sentence compression an integer linear programming approach", "author": ["James Clarke", "Mirella Lapata."], "venue": "J. Artif. Int. Res., 31(1):399\u2013429, March.", "citeRegEx": "Clarke and Lapata.,? 2008", "shortCiteRegEx": "Clarke and Lapata.", "year": 2008}, {"title": "Towards citation-based summarization of biomedical literature", "author": ["Arman Cohan", "Luca Soldaini", "Nazli Goharian."], "venue": "Proceedings of the Text Analysis Conference (TAC \u201914).", "citeRegEx": "Cohan et al\\.,? 2014", "shortCiteRegEx": "Cohan et al\\.", "year": 2014}, {"title": "Matching citation text and cited spans in biomedical literature: a search-oriented approach", "author": ["Arman Cohan", "Luca Soldaini", "Nazli Goharian."], "venue": "Proceedings of the 2015 NAACL-HLT, pages 1042\u20131048. Association for Computational", "citeRegEx": "Cohan et al\\.,? 2015", "shortCiteRegEx": "Cohan et al\\.", "year": 2015}, {"title": "Classy 2011 at tac: Guided and multi-lingual summaries and evaluation metrics", "author": ["John M Conroy", "Judith D Schlesinger", "Jeff Kubina", "Peter A Rankel", "Dianne P OLeary."], "venue": "Proceedings of the Text Analysis Conference.", "citeRegEx": "Conroy et al\\.,? 2011", "shortCiteRegEx": "Conroy et al\\.", "year": 2011}, {"title": "Epistemic modality and knowledge attribution in scientific discourse: A taxonomy of types and overview of features", "author": ["Anita De Waard", "Henk Pander Maat."], "venue": "Proceedings of the Workshop on Detecting Structure in", "citeRegEx": "Waard and Maat.,? 2012", "shortCiteRegEx": "Waard and Maat.", "year": 2012}, {"title": "Blind men and elephants: What do citation summaries tell us about a research article", "author": ["Aaron Elkiss", "Siwei Shen", "Anthony Fader", "G\u00fcne\u015f Erkan", "David States", "Dragomir Radev"], "venue": "Journal of the American Society", "citeRegEx": "Elkiss et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Elkiss et al\\.", "year": 2008}, {"title": "Lexrank: Graph-based lexical centrality as salience in text summarization", "author": ["G\u00fcnes Erkan", "Dragomir R Radev."], "venue": "J. Artif. Intell. Res.(JAIR), 22(1):457\u2013479.", "citeRegEx": "Erkan and Radev.,? 2004", "shortCiteRegEx": "Erkan and Radev.", "year": 2004}, {"title": "A skip-chain conditional random field for ranking meeting utterances by importance", "author": ["Michel Galley."], "venue": "EMNLP, pages 364\u2013372. Association for Computational Linguistics.", "citeRegEx": "Galley.,? 2006", "shortCiteRegEx": "Galley.", "year": 2006}, {"title": "Generic text summarization using relevance measure and latent semantic analysis", "author": ["Yihong Gong", "Xin Liu."], "venue": "Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "Gong and Liu.,? 2001", "shortCiteRegEx": "Gong and Liu.", "year": 2001}, {"title": "Probabilistic latent maximal marginal relevance", "author": ["Shengbo Guo", "Scott Sanner."], "venue": "SIGIR, pages 833\u2013834. ACM.", "citeRegEx": "Guo and Sanner.,? 2010", "shortCiteRegEx": "Guo and Sanner.", "year": 2010}, {"title": "Exploring content models for multi-document summarization", "author": ["Aria Haghighi", "Lucy Vanderwende."], "venue": "NAACL-HLT, pages 362\u2013370. Association for Computational Linguistics.", "citeRegEx": "Haghighi and Vanderwende.,? 2009", "shortCiteRegEx": "Haghighi and Vanderwende.", "year": 2009}, {"title": "Single-document summarization as a tree knapsack problem", "author": ["Tsutomu Hirao", "Yasuhisa Yoshida", "Masaaki Nishino", "Norihito Yasuda", "Masaaki Nagata."], "venue": "EMNLP, pages 1515\u20131520.", "citeRegEx": "Hirao et al\\.,? 2013", "shortCiteRegEx": "Hirao et al\\.", "year": 2013}, {"title": "Single document summarization based on nested tree structure", "author": ["Yuta Kikuchi", "Tsutomu Hirao", "Hiroya Takamura", "Manabu Okumura", "Masaaki Nagata."], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational", "citeRegEx": "Kikuchi et al\\.,? 2014", "shortCiteRegEx": "Kikuchi et al\\.", "year": 2014}, {"title": "Unsupervised multilingual sentence boundary detection", "author": ["Tibor Kiss", "Jan Strunk."], "venue": "Computational Linguistics, 32(4):485\u2013525.", "citeRegEx": "Kiss and Strunk.,? 2006", "shortCiteRegEx": "Kiss and Strunk.", "year": 2006}, {"title": "Automatic generic document summarization based on non-negative matrix factorization", "author": ["Ju-Hong Lee", "Sun Park", "Chan-Min Ahn", "Daeho Kim."], "venue": "Information Processing & Management, 45(1):20 \u2013 34.", "citeRegEx": "Lee et al\\.,? 2009", "shortCiteRegEx": "Lee et al\\.", "year": 2009}, {"title": "A novel feature-based bayesian model for query focused multi-document summarization", "author": ["Jiwei Li", "Sujian Li."], "venue": "Transactions of the Association for Computational Linguistics, 1:89\u201398.", "citeRegEx": "Li and Li.,? 2014", "shortCiteRegEx": "Li and Li.", "year": 2014}, {"title": "Putting the user in the loop: interactive maximal marginal relevance for query-focused summarization", "author": ["Jimmy Lin", "Nitin Madnani", "Bonnie J Dorr."], "venue": "NAACL-HLT, pages 305\u2013308. Association for Computational Linguistics.", "citeRegEx": "Lin et al\\.,? 2010", "shortCiteRegEx": "Lin et al\\.", "year": 2010}, {"title": "Rouge: A package for automatic evaluation of summaries", "author": ["Chin-Yew Lin."], "venue": "Text Summarization Branches Out: Proceedings of the ACL-04 Workshop, pages 74\u201381.", "citeRegEx": "Lin.,? 2004", "shortCiteRegEx": "Lin.", "year": 2004}, {"title": "Discourse indicators for content selection in summarization", "author": ["Annie Louis", "Aravind Joshi", "Ani Nenkova."], "venue": "Proceedings of the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 147\u2013156. Association for", "citeRegEx": "Louis et al\\.,? 2010", "shortCiteRegEx": "Louis et al\\.", "year": 2010}, {"title": "Automatically determining a proper length for multi-document summarization: A bayesian nonparametric approach", "author": ["Tengfei Ma", "Hiroshi Nakagawa."], "venue": "EMNLP, pages 736\u2013 746. Association for Computational Linguistics.", "citeRegEx": "Ma and Nakagawa.,? 2013", "shortCiteRegEx": "Ma and Nakagawa.", "year": 2013}, {"title": "Rhetorical structure theory: Toward a functional theory of text organization", "author": ["William C Mann", "Sandra A Thompson."], "venue": "Text, 8(3):243\u2013281.", "citeRegEx": "Mann and Thompson.,? 1988", "shortCiteRegEx": "Mann and Thompson.", "year": 1988}, {"title": "Textrank: Bringing order into texts", "author": ["Rada Mihalcea", "Paul Tarau."], "venue": "Association for Computational Linguistics.", "citeRegEx": "Mihalcea and Tarau.,? 2004", "shortCiteRegEx": "Mihalcea and Tarau.", "year": 2004}, {"title": "Modularity and community structure in networks", "author": ["Mark EJ Newman."], "venue": "Proceedings of the National Academy of Sciences, 103(23):8577\u20138582.", "citeRegEx": "Newman.,? 2006", "shortCiteRegEx": "Newman.", "year": 2006}, {"title": "Communities, modules and large-scale structure in networks", "author": ["MEJ Newman."], "venue": "Nature Physics, 8(1):25\u201331.", "citeRegEx": "Newman.,? 2012", "shortCiteRegEx": "Newman.", "year": 2012}, {"title": "Using maximum entropy for sentence extraction", "author": ["Miles Osborne."], "venue": "Proceedings of the ACL-02 Workshop on Automatic SummarizationVolume 4, pages 1\u20138. Association for Computational Linguistics.", "citeRegEx": "Osborne.,? 2002", "shortCiteRegEx": "Osborne.", "year": 2002}, {"title": "Text summarization of turkish texts using latent semantic analysis", "author": ["Makbule Gulcin Ozsoy", "Ilyas Cicekli", "Ferda Nur Alpaslan."], "venue": "COLING, pages 869\u2013876. Association for Computational Linguistics.", "citeRegEx": "Ozsoy et al\\.,? 2010", "shortCiteRegEx": "Ozsoy et al\\.", "year": 2010}, {"title": "The pagerank citation ranking: Bringing order to the web", "author": ["Lawrence Page", "Sergey Brin", "Rajeev Motwani", "Terry Winograd"], "venue": null, "citeRegEx": "Page et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Page et al\\.", "year": 1999}, {"title": "Summarizing contrastive viewpoints in opinionated text", "author": ["Michael Paul", "ChengXiang Zhai", "Roxana Girju."], "venue": "EMNLP, pages 66\u201376. Association for Computational Linguistics.", "citeRegEx": "Paul et al\\.,? 2010", "shortCiteRegEx": "Paul et al\\.", "year": 2010}, {"title": "Scientific paper summarization using citation summary networks", "author": ["Vahed Qazvinian", "Dragomir R Radev."], "venue": "Proceedings of the 22nd International Conference on Computational Linguistics-Volume 1, pages 689\u2013696. Association", "citeRegEx": "Qazvinian and Radev.,? 2008", "shortCiteRegEx": "Qazvinian and Radev.", "year": 2008}, {"title": "Generating extractive summaries of scientific paradigms", "author": ["Vahed Qazvinian", "Dragomir R Radev", "Saif Mohammad", "Bonnie J Dorr", "David M Zajic", "Michael Whidby", "Taesun Moon."], "venue": "J. Artif. Intell. Res.(JAIR), 46:165\u2013201.", "citeRegEx": "Qazvinian et al\\.,? 2013", "shortCiteRegEx": "Qazvinian et al\\.", "year": 2013}, {"title": "Fear the reaper: A system for automatic multi-document summarization with reinforcement learning", "author": ["Cody Rioux", "A. Sadid Hasan", "Yllias Chali."], "venue": "EMNLP, pages 681\u2013690. Association for Computational Linguistics.", "citeRegEx": "Rioux et al\\.,? 2014", "shortCiteRegEx": "Rioux et al\\.", "year": 2014}, {"title": "Unsupervised modeling of twitter conversations", "author": ["Alan Ritter", "Colin Cherry", "Bill Dolan."], "venue": "NAACL-HLT, HLT \u201910, pages 172\u2013180, Stroudsburg, PA, USA. Association for Computational Linguistics.", "citeRegEx": "Ritter et al\\.,? 2010", "shortCiteRegEx": "Ritter et al\\.", "year": 2010}, {"title": "Document summarization using conditional random fields", "author": ["Dou Shen", "Jian-Tao Sun", "Hua Li", "Qiang Yang", "Zheng Chen."], "venue": "IJCAI, volume 7, pages 2862\u20132867.", "citeRegEx": "Shen et al\\.,? 2007", "shortCiteRegEx": "Shen et al\\.", "year": 2007}, {"title": "Using latent semantic analysis in text summarization and summary evaluation", "author": ["Josef Steinberger", "Karel Jezek."], "venue": "Proc. ISIM04, pages 93\u2013 100.", "citeRegEx": "Steinberger and Jezek.,? 2004", "shortCiteRegEx": "Steinberger and Jezek.", "year": 2004}, {"title": "Improving lsa-based summarization with anaphora resolution", "author": ["Josef Steinberger", "Mijail A Kabadjov", "Massimo Poesio", "Olivia Sanchez-Graillet."], "venue": "EMNLP-HLT, pages 1\u20138. Association for Computational Linguistics.", "citeRegEx": "Steinberger et al\\.,? 2005", "shortCiteRegEx": "Steinberger et al\\.", "year": 2005}, {"title": "Summarizing scientific articles: Experiments with relevance and rhetorical status", "author": ["Simone Teufel", "Marc Moens."], "venue": "Comput. Linguist., 28(4):409\u2013445, December.", "citeRegEx": "Teufel and Moens.,? 2002", "shortCiteRegEx": "Teufel and Moens.", "year": 2002}, {"title": "Beyond sumbasic: Taskfocused summarization with sentence simplification and lexical expansion", "author": ["Lucy Vanderwende", "Hisami Suzuki", "Chris Brockett", "Ani Nenkova."], "venue": "Information Processing & Management, 43(6):1606\u20131618.", "citeRegEx": "Vanderwende et al\\.,? 2007", "shortCiteRegEx": "Vanderwende et al\\.", "year": 2007}, {"title": "Multiple aspect summarization using integer linear programming", "author": ["Kristian Woodsend", "Mirella Lapata."], "venue": "EMNLP, pages 233\u2013243. Association for Computational Linguistics.", "citeRegEx": "Woodsend and Lapata.,? 2012", "shortCiteRegEx": "Woodsend and Lapata.", "year": 2012}, {"title": "Improving supervised learning for meeting summarization using sampling and regression", "author": ["Shasha Xie", "Yang Liu."], "venue": "Computer Speech & Language, 24(3):495 \u2013 514. Emergent Artificial Intelligence Approaches for Pattern Recognition in Speech and", "citeRegEx": "Xie and Liu.,? 2010", "shortCiteRegEx": "Xie and Liu.", "year": 2010}, {"title": "Dependencybased discourse parser for single-document summarization", "author": ["Yasuhisa Yoshida", "Jun Suzuki", "Tsutomu Hirao", "Masaaki Nagata."], "venue": "EMNLP, pages 1834\u2013 1839, Doha, Qatar, October. Association for", "citeRegEx": "Yoshida et al\\.,? 2014", "shortCiteRegEx": "Yoshida et al\\.", "year": 2014}, {"title": "Criterion functions for document clustering: Experiments and analysis", "author": ["Ying Zhao", "George Karypis."], "venue": "Technical report, Citeseer.", "citeRegEx": "Zhao and Karypis.,? 2001", "shortCiteRegEx": "Zhao and Karypis.", "year": 2001}], "referenceMentions": [{"referenceID": 42, "context": "Scientific summarization is different than general summarization in three main aspects (Teufel and Moens, 2002).", "startOffset": 87, "endOffset": 111}, {"referenceID": 12, "context": "included in the abstract (Elkiss et al., 2008).", "startOffset": 25, "endOffset": 46}, {"referenceID": 35, "context": "Citation based summary is a summary which is formed by utilizing a set of citations to a referenced article (Qazvinian and Radev, 2008; Qazvinian et al., 2013).", "startOffset": 108, "endOffset": 159}, {"referenceID": 36, "context": "Citation based summary is a summary which is formed by utilizing a set of citations to a referenced article (Qazvinian and Radev, 2008; Qazvinian et al., 2013).", "startOffset": 108, "endOffset": 159}, {"referenceID": 12, "context": "Contributions stated in the citations are usually more focused than the abstract and contain additional information that is not in the abstract (Elkiss et al., 2008).", "startOffset": 144, "endOffset": 165}, {"referenceID": 40, "context": "Other variations of LSA based summarization approaches have later been introduced (Steinberger and Jezek, 2004; Steinberger et al., 2005; Lee et al., 2009; Ozsoy et al., 2010).", "startOffset": 82, "endOffset": 175}, {"referenceID": 41, "context": "Other variations of LSA based summarization approaches have later been introduced (Steinberger and Jezek, 2004; Steinberger et al., 2005; Lee et al., 2009; Ozsoy et al., 2010).", "startOffset": 82, "endOffset": 175}, {"referenceID": 21, "context": "Other variations of LSA based summarization approaches have later been introduced (Steinberger and Jezek, 2004; Steinberger et al., 2005; Lee et al., 2009; Ozsoy et al., 2010).", "startOffset": 82, "endOffset": 175}, {"referenceID": 32, "context": "Other variations of LSA based summarization approaches have later been introduced (Steinberger and Jezek, 2004; Steinberger et al., 2005; Lee et al., 2009; Ozsoy et al., 2010).", "startOffset": 82, "endOffset": 175}, {"referenceID": 15, "context": "used in text summarization first by Gong and Liu (2001). Other variations of LSA based summarization approaches have later been introduced (Steinberger and Jezek, 2004; Steinberger et al.", "startOffset": 36, "endOffset": 56}, {"referenceID": 31, "context": "Variations of supervised models have been utilized for summary generation, such as: maximum entropy (Osborne, 2002), HMM (Conroy et al.", "startOffset": 100, "endOffset": 115}, {"referenceID": 10, "context": "Variations of supervised models have been utilized for summary generation, such as: maximum entropy (Osborne, 2002), HMM (Conroy et al., 2011), CRF (Galley, 2006; Shen et al.", "startOffset": 121, "endOffset": 142}, {"referenceID": 14, "context": ", 2011), CRF (Galley, 2006; Shen et al., 2007; Chali and Hasan, 2012), SVM (Xie and Liu, 2010), logistic regression (Louis et al.", "startOffset": 13, "endOffset": 69}, {"referenceID": 39, "context": ", 2011), CRF (Galley, 2006; Shen et al., 2007; Chali and Hasan, 2012), SVM (Xie and Liu, 2010), logistic regression (Louis et al.", "startOffset": 13, "endOffset": 69}, {"referenceID": 6, "context": ", 2011), CRF (Galley, 2006; Shen et al., 2007; Chali and Hasan, 2012), SVM (Xie and Liu, 2010), logistic regression (Louis et al.", "startOffset": 13, "endOffset": 69}, {"referenceID": 45, "context": ", 2007; Chali and Hasan, 2012), SVM (Xie and Liu, 2010), logistic regression (Louis et al.", "startOffset": 36, "endOffset": 55}, {"referenceID": 25, "context": ", 2007; Chali and Hasan, 2012), SVM (Xie and Liu, 2010), logistic regression (Louis et al., 2010) and reinforcement learning (Rioux et al.", "startOffset": 77, "endOffset": 97}, {"referenceID": 37, "context": ", 2010) and reinforcement learning (Rioux et al., 2014).", "startOffset": 35, "endOffset": 55}, {"referenceID": 13, "context": "Examples of these techniques include LexRank (Erkan and Radev, 2004), TextRank (Mihalcea and Tarau, 2004), and the work by Paul et al.", "startOffset": 45, "endOffset": 68}, {"referenceID": 28, "context": "Examples of these techniques include LexRank (Erkan and Radev, 2004), TextRank (Mihalcea and Tarau, 2004), and the work by Paul et al.", "startOffset": 79, "endOffset": 105}, {"referenceID": 13, "context": "Examples of these techniques include LexRank (Erkan and Radev, 2004), TextRank (Mihalcea and Tarau, 2004), and the work by Paul et al. (2010). Maximizing the novelty and preventing", "startOffset": 46, "endOffset": 142}, {"referenceID": 3, "context": "by greedy selection of content summarization (Carbonell and Goldstein, 1998; Guo and Sanner, 2010; Lin et al., 2010).", "startOffset": 45, "endOffset": 116}, {"referenceID": 16, "context": "by greedy selection of content summarization (Carbonell and Goldstein, 1998; Guo and Sanner, 2010; Lin et al., 2010).", "startOffset": 45, "endOffset": 116}, {"referenceID": 23, "context": "by greedy selection of content summarization (Carbonell and Goldstein, 1998; Guo and Sanner, 2010; Lin et al., 2010).", "startOffset": 45, "endOffset": 116}, {"referenceID": 27, "context": "on Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) is used for analyzing the structure of the documents (Hirao et al.", "startOffset": 37, "endOffset": 62}, {"referenceID": 18, "context": "on Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) is used for analyzing the structure of the documents (Hirao et al., 2013; Kikuchi et al., 2014; Yoshida et al., 2014).", "startOffset": 116, "endOffset": 180}, {"referenceID": 19, "context": "on Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) is used for analyzing the structure of the documents (Hirao et al., 2013; Kikuchi et al., 2014; Yoshida et al., 2014).", "startOffset": 116, "endOffset": 180}, {"referenceID": 46, "context": "on Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) is used for analyzing the structure of the documents (Hirao et al., 2013; Kikuchi et al., 2014; Yoshida et al., 2014).", "startOffset": 116, "endOffset": 180}, {"referenceID": 41, "context": "Scientific article summarization was first studied by Teufel and Moens (2002) in which they trained a supervised Naive Bayes classifier to select informative content for the summary.", "startOffset": 54, "endOffset": 78}, {"referenceID": 12, "context": "Later Elkiss et al. (2008) argue the benefits of citations", "startOffset": 6, "endOffset": 27}, {"referenceID": 8, "context": "Cohan et al. (2015) use a search oriented approach for finding relevant parts of the reference paper to citations.", "startOffset": 0, "endOffset": 20}, {"referenceID": 8, "context": "Cohan et al. (2015) use a search oriented approach for finding relevant parts of the reference paper to citations. Qazvinian and Radev (2008; Qazvinian et al. (2013) use citations to an article to construct its summary.", "startOffset": 0, "endOffset": 166}, {"referenceID": 35, "context": "Our work is closest to Qazvinian and Radev (2008) with the difference that they only make use of citations.", "startOffset": 23, "endOffset": 50}, {"referenceID": 20, "context": "to sentences by using the punkt unsupervised sentence boundary detection algorithm (Kiss and Strunk, 2006).", "startOffset": 83, "endOffset": 106}, {"referenceID": 35, "context": "Similar to (Qazvinian and Radev, 2008), we want to find subgraphs or communities whose intra-connectivity is high but inter-connectivity is low.", "startOffset": 11, "endOffset": 38}, {"referenceID": 29, "context": "by the modularity measure of the graph (Newman, 2006; Newman, 2012).", "startOffset": 39, "endOffset": 67}, {"referenceID": 30, "context": "by the modularity measure of the graph (Newman, 2006; Newman, 2012).", "startOffset": 39, "endOffset": 67}, {"referenceID": 2, "context": "prohibitive (Brandes et al., 2008), many heuristic algorithms have been proposed with reasonable results.", "startOffset": 12, "endOffset": 34}, {"referenceID": 1, "context": "To extract communities from the graph of reference spans, we use the algorithm proposed by Blondel et al. (2008) which is a simple yet accurate and efficient community detection", "startOffset": 91, "endOffset": 113}, {"referenceID": 13, "context": "Here, we opt for eigenvectors and we find the most central sentences in each group by using the \u201cpower method\u201d (Erkan and Radev, 2004) which iteratively updates the eigenvector until convergence.", "startOffset": 111, "endOffset": 134}, {"referenceID": 3, "context": "\u2022 Novelty: We employ a greedy strategy similar to MMR (Carbonell and Goldstein, 1998) in which sentences from each group are selected based on the following scoring formula:", "startOffset": 54, "endOffset": 85}, {"referenceID": 40, "context": "\u2022 LSA (Steinberger and Jezek, 2004) - The LSA summarization method is based on singular value decomposition.", "startOffset": 6, "endOffset": 35}, {"referenceID": 13, "context": "\u2022 LexRank (Erkan and Radev, 2004) - LexRank uses a measure called centrality to find the most representative sentences in given sets of sentences.", "startOffset": 10, "endOffset": 33}, {"referenceID": 33, "context": "It finds the most central sentences by updating the score of each sentence using an algorithm based on PageRank random walk ranking model (Page et al., 1999).", "startOffset": 138, "endOffset": 157}, {"referenceID": 3, "context": "\u2022 MMR (Carbonell and Goldstein, 1998) - In Maximal Marginal Relevance (MMR), sentences are greedily ranked according to a score based on their relevance to the document and the amount", "startOffset": 6, "endOffset": 37}, {"referenceID": 35, "context": "\u2022 Citation summary (Qazvinian and Radev, 2008)In this approach, a network of citations is built", "startOffset": 19, "endOffset": 46}, {"referenceID": 47, "context": "and citations are clustered to maximum purity (Zhao and Karypis, 2001) and mutual information.", "startOffset": 46, "endOffset": 70}, {"referenceID": 24, "context": "We use the ROUGE evaluation metrics which has shown consistent correlation with manually evaluated summarization scores (Lin, 2004).", "startOffset": 120, "endOffset": 131}, {"referenceID": 8, "context": "as reported by (Cohan et al., 2014).", "startOffset": 15, "endOffset": 35}], "year": 2017, "abstractText": "We propose a summarization approach for scientific articles which takes advantage of citation-context and the document discourse model. While citations have been previously used in generating scientific summaries, they lack the related context from the referenced article and therefore do not accurately reflect the article\u2019s content. Our method overcomes the problem of inconsistency between the citation summary and the article\u2019s content by providing context for each citation. We also leverage the inherent scientific article\u2019s discourse for producing better summaries. We show that our proposed method effectively improves over existing summarization approaches (greater than 30% improvement over the best performing baseline) in terms of ROUGE scores on TAC2014 scientific summarization dataset. While the dataset we use for evaluation is in the biomedical domain, most of our approaches are general and therefore adaptable to other domains.", "creator": "LaTeX with hyperref package"}}}