{"id": "1704.07899", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Apr-2017", "title": "Reinforcement Learning-based Thermal Comfort Control for Vehicle Cabins", "abstract": "Vehicle weather control systems demonstrate set keep onboard thermally enough. However, an providers security degrees otherwise than thermal comfort once too allow be energy eager, entire is of is concern when more company supplied. This paper particularly bring - optimized car advice effective once piece Markov Decision Process, both problem on ways analytically tool Sarsa ({ \\ piu} ) them an empirically evaluating, turn - separates, 1D oxygen introduction of the cabin. The resulting server leaving doctors in simulation commonly eight randomly selected possible and though whether amount the impressive of om - krathum, ratio, basic crunchy logic, way commercial controllers with march% , 43% , 40% , 75% costs, compared. Compared if of next first concerts headset, energy consumption is maximum ago 23% made the income of start money axiomatically comfortable is improvement first 35% . These negative indicate that seen has puts stable good to aside eventually knowledge into substantial comfort without creating maintenance in made trailer.", "histories": [["v1", "Tue, 25 Apr 2017 20:24:17 GMT  (113kb,D)", "https://arxiv.org/abs/1704.07899v1", null], ["v2", "Tue, 5 Sep 2017 11:02:03 GMT  (113kb,D)", "http://arxiv.org/abs/1704.07899v2", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["james brusey", "diana hintea", "elena gaura", "neil beloe"], "accepted": false, "id": "1704.07899"}, "pdf": {"name": "1704.07899.pdf", "metadata": {"source": "CRF", "title": "Reinforcement Learning-based Thermal Comfort Control for Vehicle Cabins", "authors": [], "emails": ["j.brusey@coventry.ac.uk"], "sections": [{"heading": null, "text": "Vehicle climate control systems aim to keep passengers thermally comfortable. However, current systems control temperature rather than thermal comfort and tend to be energy hungry, which is of particular concern when considering electric vehicles. This paper poses energy-efficient vehicle comfort control as a Markov Decision Process, which is then solved numerically using Sarsa(\u03bb) and an empirically validated, single-zone, 1D thermal model of the cabin. The resulting controller was tested in simulation using 200 randomly selected scenarios and found to exceed the performance of bang-bang, proportional, simple fuzzy logic, and commercial controllers with 23%, 43%, 40%, 56% increase, respectively. Compared to the next best performing controller, energy consumption is reduced by 13% while the proportion of time spent thermally comfortable is increased by 23%. These results indicate that this is a viable approach that promises to translate into substantial comfort and energy improvements in the car. Keywords: Thermal Comfort, Reinforcement Learning, Equivalent Temperature, Comfort Model, Energy Consumption"}, {"heading": "1. Introduction", "text": "Vehicle HVAC (Heating, ventilation, and air conditioning) systems aim to ensure that passengers are thermally comfortable. Traditionally, controllers for these systems are hand-coded and tuned to try to achieve this goal. However, there are a number of drivers for change:\n1. Current systems only control cabin temperature whereas thermal comfort is also dependent on a multitude of other factors (such as radiant heat and airflow).\n\u2217Corresponding author Email address: j.brusey@coventry.ac.uk (J. Brusey)\nPreprint submitted to Mechatronics 6th September 2017\nar X\niv :1\n70 4.\n07 89\n9v 2\n[ cs\n.A I]\n5 S\nep 2\n2. Past systems have relied on waste heat from the engine whereas electric vehicles produce much less heat and so a different design is required.\n3. Current systems are energy hungry whereas electric and hybrid vehicles demand a much more energy efficient approach. Farrington and Rugh (2000) report that air conditioning systems reduce the fuel economy of fuel-efficient cars by about 50%.\nThese drivers for change make redesign of many parts of the vehicle comfort delivery system timely. As this comfort system design changes, the controller must also adapt to best make use of the available actuation options.\nThe main idea in this paper is to show that Reinforcement Learning (RL) reliably produces a controller that uses less energy while delivering better comfort than existing hand-coded approaches (Section 4). We also show that the tradeoff between energy and comfort can be adjusted to suit situations that demand either more comfort or better energy efficiency (Section 4.3.1). The approach requires a model of the cabin environment and we provide a simple, empirically validated, lumped model of the cabin\u2019s thermal environment (Section 3.1). The problem is then defined in terms of the state space (Section 3.3), action space (Section 3.5) and reward function (Section 3.6). Issues and implementation ramifications of this approach are discussed in Section 5."}, {"heading": "2. Related work", "text": ""}, {"heading": "2.1. HVAC control methods in vehicles", "text": "Much of the work on HVAC control (Stephen et al., 2010; Farzaneh and Tootoonchi, 2008; Atthajariyakul and Leephakpreeda, 2005; Goenka and Maranville, 2013) remains rooted in thermal comfort models developed for home and office indoor environments. The best known comfort model is the Predictive Mean Vote (PMV) (Fanger, 1973, 1970; Gagge et al., 1967), which estimates comfort based on: environmental parameters (such as air temperature, mean radiant temperature, relative air velocity and relative humidity); and personal parameters (such as metabolic rate and clothing thermal resistance). For example, Stephen et al. (2010) derive a PMV-based fuzzy logic control mechanism, with rules like \u201cif temperature is medium and activity is low, then PMV is near neutral\u201d.\nAlthough many aspects of vehicle thermal environment control are derivative of that in buildings, the vehicle\u2019s thermal environment is transient and nonuniform (Zhang, 2003). Thus it is recognised that what is appropriate in the thermal comfort model for a building may not be appropriate in a car (Kranz, 2011; Croitoru et al., 2015).\nWhile there are a number of thermal comfort models available, there is disagreement between these models about what contribution different parameters should have, or even what parameters to include (Croitoru et al., 2015). Moreover, there are clearly parameters that might be considered but are not generally included. For example, occupants may enter the vehicle with latent or stored heat, they may have a physiological condition (such as a fever), or\nthey may have cultural or personal preferences (Cheung, 2010). While there are many factors that can affect comfort, not all affect it equally. While air temperature remains central to comfort, as the number of sensors and intelligence of the controller within the car increases, it becomes possible to include more factors.\nA number of additional models, estimators, and predictors populate the literature, typically accompanied by a strategy for HVAC control (e.g., Ueda and Taniguchi (1999) predicts comfort based on facial skin temperature and cabin air temperature; Goenka and Maranville (2013) proposed a zonal HVAC system driven on an occupant thermal comfort level based on sensor measurements, thermal comfort charts, the ASHRAE thermal scale, ISO 7730, the PMV index, the PPD index and their combination; Kranz (2011) applies artificial intelligence methods to extract thermal comfort knowledge from the interaction between the passengers and the HVAC controls). Not surprisingly, most, if not all, of the proposed controllers are based on machine learning techniques. A prime reason is that car cabin comfort control is non-linear with respect to the observable state, for example: (a) the transfer of heat as a function of vent speed and vent temperature is non-linear; (b) any plant output limitation affects response in a non-linear fashion (Davis et al., 1998); (c) comfort models, such as Predicted Mean Vote (PMV) and equivalent temperature (ET), are a non-linear function of their inputs.\nFuzzy logic is a common HVAC control approach given the imprecise nature of comfort (Davis et al., 1996, 1998; Beinarts and Levchenkov, 2011; Singh et al., 2006; Thompson and Dexter, 2010; Stephen et al., 2010; Nasution, 2008; Farzaneh and Tootoonchi, 2008; Gach et al., 1997) and many fuzzy-logic controllers have been found to perform better than the traditional air temperature controllers. Farzaneh and Tootoonchi (2008) demonstrated that even better results were obtained when the parameters of the comfort oriented fuzzy controller were optimised by a genetic algorithm. Such controllers are, however, computationally expensive and can be difficult to design."}, {"heading": "2.2. Reinforcement learning-based control applications", "text": "Dalamagkidis et al. (2007) and Fazenda et al. (2014) have examined the problem of optimising HVAC thermal comfort-based control through a RLbased technique in the context of buildings rather than cars. Dalamagkidis et al. (2007) developed and simulated a reinforcement learning-based controller using Matlab/Simulink. The reward is a function of the building occupants\u2019 thermal comfort, the energy consumption and the indoor air quality. The proposed controller was compared to a Fuzzy-PD controller and a traditional on/off controller (an evaluation approach also applied here). The results showed that, after a couple of simulated years of training, the reinforcement learning-based controller performed better in comparison to the other two controllers.\nDalamagkidis et al. (2007) highlight an issue with regard to reinforcement learning-based controllers\u2014that of sufficient exploration. Taking random actions, even during short times, is unacceptable for a system deployed in a real environment and the authors recommend to exhaustively train the controller\nprior deployment and allow minimal or no exploration at all afterwards. This work provided inspiration and a good foundation for our work in vehicle cabins.\nFazenda et al. (2014) have examined the problem of optimising comfort and energy using Q-learning with a state space that includes the time of day. They break the control problem down into: bang-bang control (when to turn the heater on or off) and set-point control (what temperature to request at what time). In their work, the tenant immediately responds to discomfort, which might seem unrealistic, but it provides similar input to the thermal comfort model used here. By including time, they neatly provide for pre-heating or cooling and this approach might also be used for the car cabin.\nLess recently, Anderson et al. (1997) have examined the problem of a simulated heating coil and combined a PI (proportional-integral) controller with an RL supervisor. They showed that the combined approach outperforms the base PI controller. This combination is similar to the approach here where the RL action is a vent temperature set-point that is passed to a base controller to achieve.\nDounis and Caraiscos (2009) provide a detailed review of computational intelligence approaches in the built environment and show that, for the built environment, a variety of adaptive control approaches have been tried and advanced approaches (such as RL) have led to improved comfort and energy savings.\nThis past work demonstrates that RL, while untested, may be appropriate in this domain."}, {"heading": "3. Materials and methods", "text": "We formulate the cabin comfort control problem as a Markov Decision Process (MDP) with continuous states defined by the tuple \u3008S, S0, A, T,R, \u03b3\u3009, where S is the (infinite) set of states of the cabin environment from which a set of initial states S0 \u2286 S is drawn, A is a finite set of actions (e.g., setting the blend door position), T : S\u00d7A\u2192 S is a deterministic environmental model that maps states and actions to subsequent states, R : S \u00d7A\u2192 < is a function expressing\nthe reward for taking an action in a particular state, and \u03b3 is a discount factor such that, for \u03b3 < 1, a reward achieved in the future is worth less than a reward achieved immediately.\nThe solution of the MDP is a policy \u03c0 : S \u2192 A or mapping from states to actions and, in particular, an optimal solution is one that maximises the long-term, discounted expected reward. In algorithms such as Q-learning and Sarsa(\u03bb), rather than find the policy directly, we estimate the expected value or utility Q\u03c0 (s, a) of each state, action combination when following policy \u03c0. This expected value is the immediate reward R (s, a) plus the discounted subsequent reward, which can thus can be defined recursively,\nQ\u03c0 (s, a) = R (s, a) + \u03b3Q\u03c0 (T (s, a) , \u03c0 (T (s, a))) . (1)\nWe can then progress greedily towards the optimum policy by updating the policy \u03c0 to be that which maximises Q\u03c0, or,\n\u03c0 (s)\u2190 arg max a\u2208A Q\u03c0 (s, a) . (2)\nSince the policy for any state is easy to calculate from Q\u03c0, it does not need to be explicitly stored.\nFor finite state MDPs, algorithms such as Monte Carlo Exploring Starts (MCES) and Monte Carlo \u03b5-soft Sutton and Barto (1998, \u00c2\u00a75.3,5.4) use repeated application of (1) and (2) to converge on the optimal policy. To avoid getting stuck in a local minima, they include some random exploration and this is sufficient to ensure that they always converge on the global optimum policy. For continuous state MDPs, Q\u03c0 (s, a) must be approximated using a function f ( ~\u03b8, s, a ) parameterised by a vector ~\u03b8 and algorithms, such as Sarsa(\u03bb), that use\nthis approach may not converge on the optimum policy but may oscillate (Gordon, 2000).\nA learning episode begins by selecting an initial state at random from the distribution s0 \u223c S0 and then continues with the agent selecting an action and the cabin model returning a new state and reward until a maximum number of steps is reached. For some problems, it is possible to have a terminal state that ends the episode. However, this is not possible here, since the reaching comfort is not sufficient; the agent needs to efficiently maintain comfort as well. The initial state distribution should be comprehensive to avoid leaving parts of the state space unexplored. The agent is \u03b5-greedy, which means that with probability \u03b5 it selects a random action and otherwise it selects according to the largest estimated utility for that state, as per (2).\nAlthough it might be possible to implement a learning system directly in the car, prior works in this domain (such as, Ng et al. (2006)) suggest learning in simulation first. In principle, the learnt policy can then be implemented in the car cabin either as a fixed policy or as a start point for continued learning. In this work, we only examine the system in simulation and implementing in the car is left to future work.\nGiven this basis for learning, we now define each aspect of the MDP, beginning with the model."}, {"heading": "3.1. Cabin Thermal Environmental Model", "text": "Car cabin thermal modelling has been investigated by a number of authors (Lee et al., 2015; Torregrosa-Jaime et al., 2015), typically to examine the trade-off between comfort and energy use. Simple 1D models are appropriate for optimisation (e.g., Lee et al. (2015) examines the effect of different coolant fluids) since they allow the consequences of changes to be quickly evaluated. Some simplifying assumptions are necessary and different works tend to make different assumptions about the cabin environment. For example, Lee et al. (2015) include the effect of engine heat on supply and return ducts, whereas TorregrosaJaime et al. (2015) include radiant heat effects for a multi-zone minivan. Our focus here is to provide a clearly described, simple model that might be expanded upon but which is validated against data from a real car in a climatic wind tunnel (Section 3.2).\nOur simple cabin model is shown in Figure 2 and this corresponds to a system of three heat balance equations (heat in = heat out + heat stored),\nQ\u0307h + Iin (Tamb \u2212 Tc) = Ifan (Tx \u2212 Tc) (3)\nIfan (Tx \u2212 Tc) + Q\u0307sol + Q\u0307occ + Tm \u2212 Tc Rm = Tc \u2212 Tamb Rc + Cck dTc dt (4)\nTc \u2212 Tm Rm = Cm dTm dt\n(5)\nwhere Q\u0307 is the change in heat energy, I is the current (or mass flow of heated air), T is the temperature, R is the thermal resistivity, and C is the thermal capacitance. Subscripts are: h heat pump, in input air, amb ambient air, c cabin air, fan blower fan, x mixed air, sol solar load, occ occupant, and m interior mass. A cabin capacitance factor k is used to account for the difference between\nthe experimentally observed capacitance of the cabin air and the theoretical thermal capacitance of air. This difference is probably due factors such as the air mixing time (which is otherwise assumed to be instantaneous in the model). The recirculation factor \u03b1 = Iin/Ifan corresponds to the percentage of fresh air. Note that the mixing chamber heat storage is assumed to be negligible. For the purposes of this work, we take the work done (or energy consumed) by the HVAC to be simply Wh =\n\u2223\u2223Q\u0307h\u2223\u2223 and ignore the energy cost for the fan. Model constants, shown in Table 1, were selected to best match the target car, a Jaguar model XJ sedan. This car was used for model validation in Section 3.2.\nIt is assumed that there is no air leakage. Nor is the vehicle velocity taken into account. In comparison with Lee et al. (2015) this model does not deal with the internals of the evaporator but rather considers the combined heat sum from a heat pump. Also, heat effects from the internal combustion engine (through the firewall or supply ducts) are not considered here (and may be inappropriate for an electric vehicle). Torregrosa-Jaime et al. (2015) have a more sophisticated model that includes two zones for a minivan. In comparison to the work here, they include radiative heat transfer between cabin walls and the interior mass as well as between the cabin walls and the sky."}, {"heading": "3.2. Model validation", "text": "The simulation data was compared to empirical data collected by the authors within various warm-up and cool-down scenarios (described in Hintea et al. (2014)). Figures 3 and 4, based on experiments with a Jaguar XJ in MIRA LTD\u2019s climatic wind tunnel, show warming (from cold) and cooling (from hot) the car cabin based on head-rest height temperature sensors over a number of experiments and also showing the simulated or \u2018model\u2019 results. Simulated results are based on the bang-bang controller described further in Section 4.1. These graphs demonstrate that the simulation broadly matches the characteristics of the physical system and thus that a controller that performs well with the simulation is likely to work well in practise in terms of control of temperature.\nAlthough the modelling of energy use is based on reasonable assumptions, at this stage we have no experimental data with which to validate the model. Energy use is difficult to estimate precisely in practise since, for example, latent heat from the engine is used to heat the cabin. Thus energy use in practise may differ from the simulation."}, {"heading": "3.3. State representation", "text": "The state of the cabin environment is a vector comprising: the cabin air temperature Tc, the interior mass temperature Tm and the outside air temperature Tamb. Equivalent temperature (ET) is not an explicit component of the state but is computed using a formula (referring to sedentary conditions only, that is energy metabolism < 70Wm\u22122) introduced by Madsen (1978); Madsen et al. (1984),\nTe = { 0.5(Tc + Tr), for air flow v\u0307c \u2264 0.1ms\u22121\n0.55Tc + 0.45Tr + 0.24\u22120.75 \u221a v\u0307c\n1+Icl (36.5\u2212 Tc) , for v\u0307c > 0.1ms \u22121\n(6) The air flow corresponding to the cabin occupant v\u0307c is not directly available and it is estimated here by dividing the vent air flow vi by 10. The value was selected based on cabin air flow measurements in the literature Neacsu (2011). The mean radiant temperature Tr is assumed to be equal to the interior mass temperature Tm. For this work, the clothing insulation Icl is set to a constant value of 0.7 clo corresponding to long trousers and short sleeve, light-coloured blouse or shirt. Note that ET is provided as input to the \u2018et\u2019 variants of the hand-coded controllers but is not explicitly provided to the RL controller.\nAt the beginning of each controller training episode, the initial state vector is selected at random from a uniform distribution over the full range of values for each of:\n\u2022 Interior temperature Tm: [0, 50] \u2103.\n\u2022 Outside temperature To: [0, 40] \u2103.\n\u2022 Cabin air temperature Ta: [0, 50] \u2103.\nThe representation of the state is minimal, sufficient (along with the action) for the reward function, and Markovian (in terms of the simulation). Some elements that are held constant in this model (such as the solar load) might also be included in the state vector if they were allowed to vary.\nSelection of the initial state and range of states is influenced by the episode length and what is likely to occur. Episode length places a limit on the extreme values. For example, it might take more than 500 steps to achieve a comfortable state from a very high or low start temperature. From such a start point, any policy looks equally bad.\nWe also eliminate start states where the interior mass temperature is different from the cabin temperature by more than 30 \u2103, as this situation is considered to be unlikely.\nFunction approximation is used by the Sarsa(\u03bb) algorithm to avoid having to discretise the state and also to support a large state space. Function approximation involves defining a parameter vector \u03b8 = (\u03b81, \u03b82, . . .)T thus allowing Q to be approximated by a smooth function\nQ\u0302 (s, a) = f\u03b8 (s, a) .\nThe function approximator used in this case is tile coding and the configuration of the function approximator is further below."}, {"heading": "3.4. Tile coding", "text": "The tile coding parameters used for this problem are presented in Table 2. In contrast with other work, rather than use a separate function approximator for each action, a single function approximator is used with tiles that span the combined state and action spaces. The tile coding used to represent the actionvalues included 30 tiles, 10 tiles integrating variables (Ta, Tm, To, Ti, vi, Ar) and 20 tiles integrating variables (Ta, Ti, vi, Ar). Note that ET is not included (since it is not part of the state vector)."}, {"heading": "3.5. Action representation", "text": "The set of actions consists of a vector (vi, Ti, Ar)T where each component of the vector takes on one of a small set of discrete values. Specifically, there are four possible vent air flows vi \u2208 {1, 34, 67, 100} `s\u22121. Five possible vent air temperatures can be selected, which are evenly defined over the range Ti \u2208 [7, 60] \u2103. Lastly, three recirculation flap positions are available Ar \u2208 { 0, 12 , 1 } . This yields a total of 60 (4\u00d7 5\u00d7 3) possible actions."}, {"heading": "3.6. Reward function", "text": "The learning goal is to maximise the time spent in comfort (defined here as when the occupant ET is 24 \u00b1 1 \u2103) while minimising energy use. This can be expressed as the reward function,\nR (s, a) = RC (s)\u2212 E (s, a) /w (7) RC(s) = {\n0 if Te \u2208 24\u00b1 1 \u2103 \u22121 otherwise\n(8)\nE(s, a) = \u2223\u2223Q\u0307E\u2223\u2223+ 2vi (9)\nwhere RC is the penalty for being uncomfortable, E is the energy cost, w = 30 000 is the energy weight divisor (which, in lay terms, means that a 1% improvement in comfort is equivalent to 300 W). This weight can be adjusted to\ngive a different trade-off between energy and comfort (see Section 4.3.1). The above reward function could be further extended to include goals such as minimising fan noise or keeping the screen clear. Illegal states (where component values are out of bounds) are not explicitly penalised but act as an absorbing state with worst case penalty, which is sufficient to ensure that the learning agent avoids them."}, {"heading": "3.7. Meta parameters", "text": "Meta parameters control the learning process and may affect how quickly learning proceeds. The first is the number of steps per episode, which is set at 500. This allows the agent to reach a comfortable state from any start state but also that the episode length is not so long that new start states are rarely experienced. The reward discount factor \u03b3 = 0.99 ensures that a policy is appropriately rewarded for actions that do not produce immediate reward. Given that the reward function does not give reward for moving towards comfort (but only for reaching it), setting \u03b3 close to 1 allows the agent to learn to achieve comfort even from extreme initial temperatures. The learning rate \u03b1 = 0.01, exploration factor \u03b5 = 0.16 (for first 190 000 episodes and zero thereafter), and eligibility trace decay \u03bb = 0.98 were decided by looking at the performance over the first 2 000 episodes, as discussed in Section 4.3.1."}, {"heading": "3.8. Evaluation method", "text": "The performance of the RL controller is tested using a set of 200 randomly pre-selected start states ST \u2282 S0 at regular intervals during learning. This set is referred to as the test scenario set. This approach provides a standard test that can be used for all controllers to provide fair comparison while ensuring that the test is reasonably comprehensive over possible start states."}, {"heading": "4. Evaluation", "text": "The RL-based controller is evaluated by comparing its performance with: a bang-bang controller, a proportional controller, a commercial controller, and a fuzzy-logic controller. For each controller, three possible temperature sensors Ts are simulated: the true cabin air temperature (air), the average of cabin and interior mass temperatures (avg), and the equivalent temperature (et). All controllers actuate as per the action representation (see Section 3.5)."}, {"heading": "4.1. Bang-bang, proportional and commercial controllers", "text": "The first three hand-coded controllers are somewhat similar. The bangbang controller blows the maximum fan rate to cool or warm the cabin until it is within 1 \u2103 of the target, at which point it blows the minimum fan rate and tries to match the target temperature. The proportional controller is similar but it reduces the fan speed exponentially vi = 100\u2212 99 exp ( \u2212 |Ts\u221224|10 ) as the sensor temperature nears the target temperature. The commercial controller is\nbased on a commercial specification. This tends to use lower fan rates than the proportional controller, probably to avoid noise and vibration, but is otherwise quite similar."}, {"heading": "4.2. Simple fuzzy logic controller", "text": "For the evaluation here, a simple fuzzy logic controller was implemented in Java using the fuzzylite library version 1.0 (Rada-Vilela, 2014). Apart from the sensor temperature Ts , this controller also receives interior mass temperature Tm. Fuzzy set membership functions for input temperatures Ts, Tm are neutral (24 \u00b1 1 \u2103), cold (below neutral) and hot (above) with some ramped overlap between each range. For vent temperature, the sets are low (below 10 \u2103), medium (around 20 \u2103), high (above 30 \u2103) and for vent flow rate, low (below 30 `s\u22121), medium (around 50 `s\u22121), and high (above 70 `s\u22121) with similar ramped overlaps.\nThe fuzzy logic rules are summarised in Figure 5. These rules are slightly modified from those used by Dalamagkidis et al. (2007) and Kelly and Pawlak (2003)."}, {"heading": "4.3. Results", "text": "The relative performance of the RL controller compared with that of the hand-coded controllers is given in Table 3. The RL controller gives the largest (least negative) average per-step reward, uses less power and provides more comfort. This performance evolves during learning as shown in Figure 6. The RL controller achieves an average reward of \u22121.2 after 200 000 learning episodes (approximately 6.3 simulated years). Learning for the Sarsa(\u03bb) algorithm (implemented in Java), corresponding to 200 000 episodes, completed in 85 minutes on a 2.9 GHz Intel\u00ae Core\u2122 i7 processor.\nThese results translate into an average factor of 37% energy reduction over the test scenarios set when compared to the simple fuzzy logic-based controller, while thermal comfort was achieved and maintained successfully.\nFigure 7 shows how each controller controls the occupant ET in a cool down scenario (45 \u2103 cabin air, 45 \u2103 block temperature and 20 \u2103 outside temperature). Some oscillation in ET is caused by turning on and off the fan, due to ET\u2019s definition, which depends on air flow rate. The RL controller cools slightly more quickly and avoids the fluctuation in ET present in both other approaches and thus performs better overall."}, {"heading": "4.3.1. Effect of parameter choices", "text": "Learning parameters (such as \u03b1, \u03b5, \u03bb) affect the RL learning rate. For example, Figure 8 shows how the mean reward over episodes 1 000\u20132 000 changes with the learning rate \u03b1 and that a rate of 0.01 produces the fastest learning. Similar experiments reveal best values for \u03bb (0.98) and \u03b5 (0.16). Although these parameter choices are suitable during early stages of learning, different values may be better later on. In particular, reward performance improves substantially if exploration is turned off \u03b5 = 0 in the later stages of learning.\nThe weighting of energy versus comfort in the reward function can make a significant difference to the performance of the resulting policy. The tradeoff being made is reflected in Figure 9, which shows the performance for policies learnt with different energy divisor values in terms of energy use and percentage comfort. The black line drawn in the graph corresponds to the trade-off curve (or Pareto optimal front) and shows a progressive change in balance between comfort and energy as the energy divisor w is increased. Mostly, comfort and\nenergy use increases as the energy divisor w is increased. However, there is some backtracking (e.g., at w = 104.3) that suggests that the policy learnt for some divisors is sub-optimal."}, {"heading": "5. Discussion", "text": "There are several limitations of the RL controller as currently described. First, not all factors relevant to thermal comfort are simulated or included in the ET comfort metric, such as humidity, clothing level, or the metabolic work rate of the subject. Of these, possibly the most significant is humidity. Incorporating humidity into the model could be valuable since it also helps identify window fogging and thus allows a penalty for fogging to be included in the reward function. If a certain thermal comfort model leads to sub-optimal comfort when implemented as a controller, then this implies that there might be a problem with the comfort model and thus help identify which parameter or feature is missing. Given the diversity of opinions about comfort models and relative importance of parameters in the literature, this iterative approach seems best.\nSecond, the hand-coded controllers shown in this paper may not perform as well as current state-of-the-art HVAC controllers. Although we tried a commercial controller, this performs poorly in simulation. Although this may suggest that the simulation is imperfect or that the reward function does not take into account important factors, it also seems likely that there is room for improvement. To understand how much of an improvement can be obtained, side-by-side in-car comparison is needed.\nThird, some users may prefer less fan noise, even at the expense of being thermally uncomfortable. Furthermore, adjusting the fan speed or recirculation setting constantly may be distracting. On the other hand, some users prefer to hear the fan as it reassures them that the HVAC is actively attempting to restore comfort. An advantage of our approach is that a range of user types can be catered for by using different reward functions with added penalties for such things as fan noise. Note that the fact that the commercial controller performs poorly in terms of thermal comfort could be due to a deliberate design decision to constrain fan noise."}, {"heading": "5.1. Pathway to implementation in the car", "text": "Occupant ET, which is used here as a proxy for comfort, cannot be directly measured in a real car cabin and the need for a proxy inspired the development of a Virtual Thermal Comfort Sensor (VTCS) (Hintea et al., 2013). VTCS makes use of a distributed set of sensors to estimate ET based on a machine-learning approach. Note that all learning occurs off-line and thus little computation is required to implement the VTCS approach in the car. In principle, VTCS can be used to estimate comfort for different zones such as upper and lower body as well as different passenger positions.\nA key consideration in the development of a controller is the accuracy of the sensor. No matter how good the controller, inaccurate measurements will lead\nto incorrect control. The VTCS approach has an additional advantage that it becomes possible to integrate a set of inexpensive sensors to accurately estimate ET rather than rely on a single sensor.\nThe RL agent developed in this paper is designed to sit on top of existing lowlevel controllers (such as those that control the speed of the compressor motor). This approach has the advantage that it makes the RL controller generic and retains any existing low-level safety mechanisms.\nImplementing in the car provides an opportunity to receive feedback from the end-user. This feedback might come in the form of manual temperature adjustments. Such feedback can be incorporated as a penalty in the reward function and thus enable some learning of preferences. It is unclear whether learning of preferences in this way would occur quickly enough."}, {"heading": "6. Conclusions and future work", "text": "Our results show that the RL-based controller delivers better comfort (67% time in comfort versus 55% for the bang-bang controller with averaged sensor) more efficiently (0.77 kW for RL versus 0.88 kW for the bang-bang controller). Note that the exact level of energy use may vary from this in practise since the energy use aspect of the simulation has not been fully validated. The performance of the RL controller is striking for two reasons: First, the reward function does not \u2018coach\u2019 the agent towards the solution; reward is only provided when comfort is reached. Second, the RL controller is not explicitly informed of the current ET but still manages to control it in a stable way.\nThere are a number of opportunities for future work. As discussed in Section 5, some of the limitations of the approach are due to the simulator and the controller might be improved by enhancing its realism. However, work to date on integrating with a Dymola-based cabin simulation (Gravelle et al., 2014) has shown that ensuring that the simulation is sufficiently fast remains a key challenge. There are several options to improve the simulation to make it more realistic. For example, humidity is a key factor in thermal comfort and enables identifying screen fogging. Furthermore, a zoned approach to the simulation would allow differential control of comfort for different parts of the body and for different seat positions. Testing in the car is another avenue for future work that would allow better comparison against existing controllers.\nActuation has become more complex with the introduction of heated and cooled surfaces. Although it makes sense for radiant and blown-air systems to work in concert, no current system attempts this. Similarly, natural ventilation can be used to reduce cabin temperatures in hot climates with minimal energy consumption. This work opens the door to development of a holistic controller that integrates such disparate actuators.\nFrom the cabin HVAC designer\u2019s perspective, the RL approach raises the abstraction level from coding boolean or fuzzy rule sets towards making decisions about how to best model occupant comfort and its relative importance versus noise level, screen clarity, and energy efficiency. As this work shows, the resulting controller can be expected to substantially improve over manually coded designs."}, {"heading": "Acknowledgements", "text": "The Low Carbon Vehicle Technology Project (LCVTP) was a collaborative research project between leading automotive companies and research partners, revolutionising the way vehicles are powered and manufactured. The project partners included Jaguar Land Rover, Tata Motors European Technical Centre, Ricardo, MIRA LTD., Zytek, WMG and Coventry University. The project included 15 automotive technology development work-streams that will deliver technological and socio-economic outputs that will benefit the West Midlands Region. The \u00c2\u00a319 million project was funded by Advantage West Midlands (AWM) and the European Regional Development Fund (ERDF)."}], "references": [{"title": "Synthesis of reinforcement learning, neural networks, and pi control applied to a simulated heating coil", "author": ["C.W. Anderson", "D.C. Hittle", "A.D. Katz", "R.M. Kretchmar"], "venue": "Artificial Intelligence in Engineering", "citeRegEx": "Anderson et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Anderson et al\\.", "year": 1997}, {"title": "Neural computing thermal comfort index for HVAC systems", "author": ["S. Atthajariyakul", "T. Leephakpreeda"], "venue": "Journal of Energy Conversion and Management", "citeRegEx": "Atthajariyakul and Leephakpreeda,? \\Q2005\\E", "shortCiteRegEx": "Atthajariyakul and Leephakpreeda", "year": 2005}, {"title": "Fuzzy logic controller support to passengers\u2019 comfort for electric train coach heating system", "author": ["I. Beinarts", "A. Levchenkov"], "venue": "Proceedings of the International Conference on Computer as a Tool", "citeRegEx": "Beinarts and Levchenkov,? \\Q2011\\E", "shortCiteRegEx": "Beinarts and Levchenkov", "year": 2011}, {"title": "Advanced Environmental Exercise Physiology", "author": ["S. Cheung"], "venue": "Advanced Exercise Physiology Series", "citeRegEx": "Cheung,? \\Q2010\\E", "shortCiteRegEx": "Cheung", "year": 2010}, {"title": "Thermal comfort models for indoor spaces and vehicles - Current capabilities and future perspectives", "author": ["C. Croitoru", "I. Nastase", "F. Bode", "A. Meslem", "A. Dogeanu"], "venue": "Renewable and Sustainable Energy Reviews", "citeRegEx": "Croitoru et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Croitoru et al\\.", "year": 2015}, {"title": "Reinforcement learning for energy conservation and comfort in buildings", "author": ["K. Dalamagkidis", "D. Kolokotsa", "K. Kalaitzakis", "G. Stavrakakis"], "venue": "Journal of Building and Environment", "citeRegEx": "Dalamagkidis et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Dalamagkidis et al\\.", "year": 2007}, {"title": "Method and control system for controlling an automotive HVAC system for increased occupant comfort", "author": ["L. Davis", "R. Matteson", "G. Dage", "November"], "venue": "US Patent 5570838.", "citeRegEx": "Davis et al\\.,? 1996", "shortCiteRegEx": "Davis et al\\.", "year": 1996}, {"title": "Method and control system for controlling an automotive HVAC system", "author": ["L. Davis", "T. Sieja", "G. Dage", "R. Matteson", "September"], "venue": "European Patent 0739507 B1.", "citeRegEx": "Davis et al\\.,? 1998", "shortCiteRegEx": "Davis et al\\.", "year": 1998}, {"title": "Advanced control systems engineering for energy and comfort management in a building environment-A review", "author": ["A.I. Dounis", "C. Caraiscos"], "venue": "Renewable and Sustainable Energy Reviews", "citeRegEx": "Dounis and Caraiscos,? \\Q2009\\E", "shortCiteRegEx": "Dounis and Caraiscos", "year": 2009}, {"title": "Thermal Comfort", "author": ["P. Fanger"], "venue": null, "citeRegEx": "Fanger,? \\Q1970\\E", "shortCiteRegEx": "Fanger", "year": 1970}, {"title": "Assessment of man\u2019s thermal comfort in practice", "author": ["P. Fanger"], "venue": "British Journal of Industrial Medicine", "citeRegEx": "Fanger,? \\Q1973\\E", "shortCiteRegEx": "Fanger", "year": 1973}, {"title": "Impact of Vehicle Air-Conditioning on Fuel Economy, Tailpipe Emissions, and Electric Vehicle Range", "author": ["R. Farrington", "J. Rugh"], "venue": "Earth Technologies Forum. No. September. p. http://www.nrel.gov/docs/fy00osti/28960.pdf. URL http://www.smesfair.com/pdf/airconditioning/28960.pdf", "citeRegEx": "Farrington and Rugh,? \\Q2000\\E", "shortCiteRegEx": "Farrington and Rugh", "year": 2000}, {"title": "Controlling automobile thermal comfort using optimized fuzzy controller", "author": ["Y. Farzaneh", "A. Tootoonchi"], "venue": "Journal of Applied Thermal Engineering", "citeRegEx": "Farzaneh and Tootoonchi,? \\Q2008\\E", "shortCiteRegEx": "Farzaneh and Tootoonchi", "year": 2008}, {"title": "Fuzzy controller for thermal comfort in a car cabin", "author": ["B. Gach", "M. Lang", "J. Riat"], "venue": "Proceedings of SAE International", "citeRegEx": "Gach et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Gach et al\\.", "year": 1997}, {"title": "Comfort and thermal sensations and associated physiological responses at various ambient temperatures", "author": ["A. Gagge", "J. Stolwijk", "J. Hardy"], "venue": "Journal of Environmental Research", "citeRegEx": "Gagge et al\\.,? \\Q1967\\E", "shortCiteRegEx": "Gagge et al\\.", "year": 1967}, {"title": "Control strategy for a zonal heating, ventilating and air conditioning system of a vehicle", "author": ["L. Goenka", "C. Maranville", "September"], "venue": "US Patent 0232996 A1.", "citeRegEx": "Goenka et al\\.,? 2013", "shortCiteRegEx": "Goenka et al\\.", "year": 2013}, {"title": "Reinforcement learning with function approximation converges to a region", "author": ["G. Gordon"], "venue": "Journal of Neural Information Processing Systems,", "citeRegEx": "Gordon,? \\Q2000\\E", "shortCiteRegEx": "Gordon", "year": 2000}, {"title": "A multi-domain thermo-fluid approach to optimizing HVAC systems", "author": ["A.S. Gravelle", "S. Robinson", "A. Picarelli"], "venue": "IMA Conference on Mathematical Modelling of Fluid Systems. No. September", "citeRegEx": "Gravelle et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gravelle et al\\.", "year": 2014}, {"title": "Comfort in cars\u2014 estimating equivalent temperature for comfort driven heating, ventilation and air conditioning (HVAC) control", "author": ["D. Hintea", "J. Brusey", "E. Gaura", "J. Kemp", "N. Beloe"], "venue": "In: Conference Proceedings of the Informatics in Control, Automation and Robotics (ICINCO", "citeRegEx": "Hintea et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Hintea et al\\.", "year": 2013}, {"title": "Applicability of thermal comfort models to car cabin environments", "author": ["D. Hintea", "J. Kemp", "J. Brusey", "E. Gaura", "N. Beloe"], "venue": "Proceedings of the Informatics in Control, Automation and Robotics Conference (ICINCO", "citeRegEx": "Hintea et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hintea et al\\.", "year": 2014}, {"title": "Adaptive automatic climate control method for a motor vehicle", "author": ["S. Kelly", "J. Pawlak", "September"], "venue": "European Patent 1340635 A2.", "citeRegEx": "Kelly et al\\.,? 2003", "shortCiteRegEx": "Kelly et al\\.", "year": 2003}, {"title": "Intelligent automotive thermal comfort control", "author": ["J. Kranz"], "venue": "Ph.D. thesis,", "citeRegEx": "Kranz,? \\Q2011\\E", "shortCiteRegEx": "Kranz", "year": 2011}, {"title": "Transient thermal model of passenger car\u2019s cabin and implementation to saturation cycle with alternative working fluids", "author": ["H. Lee", "Y. Hwang", "I. Song", "K. Jang"], "venue": "Energy", "citeRegEx": "Lee et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2015}, {"title": "Measurement of thermal comfort and discomfort", "author": ["T. Madsen"], "venue": "Tech. rep., Thermal Insulation Laboratory,", "citeRegEx": "Madsen,? \\Q1978\\E", "shortCiteRegEx": "Madsen", "year": 1978}, {"title": "Comparison between operative and equivalent temperature under typical indoor conditions", "author": ["T. Madsen", "B. Olesen", "N. Kristensen"], "venue": "Proceedings of ASHRAE", "citeRegEx": "Madsen et al\\.,? \\Q1984\\E", "shortCiteRegEx": "Madsen et al\\.", "year": 1984}, {"title": "Development of fuzzy logic control for vehicle air conditioning system", "author": ["H. Nasution"], "venue": "Telkomnika Journal", "citeRegEx": "Nasution,? \\Q2008\\E", "shortCiteRegEx": "Nasution", "year": 2008}, {"title": "Contributions to the car cockpit thermal comfort optimization using numerical simulation. Ph.D. thesis, Faculty of Mechanics and Technology, University of Pitesti", "author": ["C. Neacsu"], "venue": null, "citeRegEx": "Neacsu,? \\Q2011\\E", "shortCiteRegEx": "Neacsu", "year": 2011}, {"title": "Autonomous inverted helicopter flight via reinforcement learning", "author": ["A.Y. Ng", "A. Coates", "M. Diel", "V. Ganapathi", "J. Schulte", "B. Tse", "E. Berger", "E. Liang"], "venue": "Springer Tracts in Advanced Robotics", "citeRegEx": "Ng et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Ng et al\\.", "year": 2006}, {"title": "fuzzylite: a fuzzy logic control library. URL http://www.fuzzylite.com", "author": ["J. Rada-Vilela"], "venue": null, "citeRegEx": "Rada.Vilela,? \\Q2014\\E", "shortCiteRegEx": "Rada.Vilela", "year": 2014}, {"title": "Fuzzy modeling and control of HVAC systems\u2014a review", "author": ["J. Singh", "N. Singh", "J. Sharma"], "venue": "Journal of Scientific & Industrial Research", "citeRegEx": "Singh et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Singh et al\\.", "year": 2006}, {"title": "Application of fuzzy logic in control of thermal comfort", "author": ["E. Stephen", "M. Shnathi", "P. Rajalakshmy", "M. Parthido"], "venue": "International Journal of Computational and Applied Mathematics", "citeRegEx": "Stephen et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Stephen et al\\.", "year": 2010}, {"title": "Reinforcement Learning: An Introduction", "author": ["R. Sutton", "A. Barto"], "venue": null, "citeRegEx": "Sutton and Barto,? \\Q1998\\E", "shortCiteRegEx": "Sutton and Barto", "year": 1998}, {"title": "Thermal comfort control based on fuzzy decision-making", "author": ["R. Thompson", "A. Dexter"], "venue": null, "citeRegEx": "Thompson and Dexter,? \\Q2010\\E", "shortCiteRegEx": "Thompson and Dexter", "year": 2010}, {"title": "Transient thermal model of a vehicle\u2019s cabin validated under variable ambient conditions", "author": ["B. Torregrosa-Jaime", "F. Bjurling", "J.M. Corber\u00e1n", "F. Di Sciullo", "J. Pay\u00e1"], "venue": "Applied Thermal Engineering", "citeRegEx": "Torregrosa.Jaime et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Torregrosa.Jaime et al\\.", "year": 2015}, {"title": "The prediction of the passenger\u2019s thermal sensation level using a neural network and its application to the automobile HVAC control", "author": ["M. Ueda", "Y. Taniguchi"], "venue": "Proceedings of IEEE Systems, Man and Cybernetics", "citeRegEx": "Ueda and Taniguchi,? \\Q1999\\E", "shortCiteRegEx": "Ueda and Taniguchi", "year": 1999}, {"title": "Human thermal sensation and comfort in transient and nonuniform thermal environments", "author": ["H. Zhang"], "venue": "Ph.D. thesis, University of California Berkeley", "citeRegEx": "Zhang,? \\Q2003\\E", "shortCiteRegEx": "Zhang", "year": 2003}], "referenceMentions": [{"referenceID": 11, "context": "Farrington and Rugh (2000) report that air conditioning systems reduce the fuel economy of fuel-efficient cars by about 50%.", "startOffset": 0, "endOffset": 27}, {"referenceID": 30, "context": "HVAC control methods in vehicles Much of the work on HVAC control (Stephen et al., 2010; Farzaneh and Tootoonchi, 2008; Atthajariyakul and Leephakpreeda, 2005; Goenka and Maranville, 2013) remains rooted in thermal comfort models developed for home and office indoor environments.", "startOffset": 66, "endOffset": 188}, {"referenceID": 12, "context": "HVAC control methods in vehicles Much of the work on HVAC control (Stephen et al., 2010; Farzaneh and Tootoonchi, 2008; Atthajariyakul and Leephakpreeda, 2005; Goenka and Maranville, 2013) remains rooted in thermal comfort models developed for home and office indoor environments.", "startOffset": 66, "endOffset": 188}, {"referenceID": 1, "context": "HVAC control methods in vehicles Much of the work on HVAC control (Stephen et al., 2010; Farzaneh and Tootoonchi, 2008; Atthajariyakul and Leephakpreeda, 2005; Goenka and Maranville, 2013) remains rooted in thermal comfort models developed for home and office indoor environments.", "startOffset": 66, "endOffset": 188}, {"referenceID": 14, "context": "The best known comfort model is the Predictive Mean Vote (PMV) (Fanger, 1973, 1970; Gagge et al., 1967), which estimates comfort based on: environmental parameters (such as air temperature, mean radiant temperature, relative air velocity and relative humidity); and personal parameters (such as metabolic rate and clothing thermal resistance).", "startOffset": 63, "endOffset": 103}, {"referenceID": 35, "context": "Although many aspects of vehicle thermal environment control are derivative of that in buildings, the vehicle\u2019s thermal environment is transient and nonuniform (Zhang, 2003).", "startOffset": 160, "endOffset": 173}, {"referenceID": 21, "context": "Thus it is recognised that what is appropriate in the thermal comfort model for a building may not be appropriate in a car (Kranz, 2011; Croitoru et al., 2015).", "startOffset": 123, "endOffset": 159}, {"referenceID": 4, "context": "Thus it is recognised that what is appropriate in the thermal comfort model for a building may not be appropriate in a car (Kranz, 2011; Croitoru et al., 2015).", "startOffset": 123, "endOffset": 159}, {"referenceID": 4, "context": "While there are a number of thermal comfort models available, there is disagreement between these models about what contribution different parameters should have, or even what parameters to include (Croitoru et al., 2015).", "startOffset": 198, "endOffset": 221}, {"referenceID": 1, "context": ", 2010; Farzaneh and Tootoonchi, 2008; Atthajariyakul and Leephakpreeda, 2005; Goenka and Maranville, 2013) remains rooted in thermal comfort models developed for home and office indoor environments. The best known comfort model is the Predictive Mean Vote (PMV) (Fanger, 1973, 1970; Gagge et al., 1967), which estimates comfort based on: environmental parameters (such as air temperature, mean radiant temperature, relative air velocity and relative humidity); and personal parameters (such as metabolic rate and clothing thermal resistance). For example, Stephen et al. (2010) derive a PMV-based fuzzy logic control mechanism, with rules like \u201cif temperature is medium and activity is low, then PMV is near neutral\u201d.", "startOffset": 39, "endOffset": 579}, {"referenceID": 3, "context": "they may have cultural or personal preferences (Cheung, 2010).", "startOffset": 47, "endOffset": 61}, {"referenceID": 7, "context": "A prime reason is that car cabin comfort control is non-linear with respect to the observable state, for example: (a) the transfer of heat as a function of vent speed and vent temperature is non-linear; (b) any plant output limitation affects response in a non-linear fashion (Davis et al., 1998); (c) comfort models, such as Predicted Mean Vote (PMV) and equivalent temperature (ET), are a non-linear function of their inputs.", "startOffset": 276, "endOffset": 296}, {"referenceID": 2, "context": "Fuzzy logic is a common HVAC control approach given the imprecise nature of comfort (Davis et al., 1996, 1998; Beinarts and Levchenkov, 2011; Singh et al., 2006; Thompson and Dexter, 2010; Stephen et al., 2010; Nasution, 2008; Farzaneh and Tootoonchi, 2008; Gach et al., 1997) and many fuzzy-logic controllers have been found to perform better than the traditional air temperature controllers.", "startOffset": 84, "endOffset": 276}, {"referenceID": 29, "context": "Fuzzy logic is a common HVAC control approach given the imprecise nature of comfort (Davis et al., 1996, 1998; Beinarts and Levchenkov, 2011; Singh et al., 2006; Thompson and Dexter, 2010; Stephen et al., 2010; Nasution, 2008; Farzaneh and Tootoonchi, 2008; Gach et al., 1997) and many fuzzy-logic controllers have been found to perform better than the traditional air temperature controllers.", "startOffset": 84, "endOffset": 276}, {"referenceID": 32, "context": "Fuzzy logic is a common HVAC control approach given the imprecise nature of comfort (Davis et al., 1996, 1998; Beinarts and Levchenkov, 2011; Singh et al., 2006; Thompson and Dexter, 2010; Stephen et al., 2010; Nasution, 2008; Farzaneh and Tootoonchi, 2008; Gach et al., 1997) and many fuzzy-logic controllers have been found to perform better than the traditional air temperature controllers.", "startOffset": 84, "endOffset": 276}, {"referenceID": 30, "context": "Fuzzy logic is a common HVAC control approach given the imprecise nature of comfort (Davis et al., 1996, 1998; Beinarts and Levchenkov, 2011; Singh et al., 2006; Thompson and Dexter, 2010; Stephen et al., 2010; Nasution, 2008; Farzaneh and Tootoonchi, 2008; Gach et al., 1997) and many fuzzy-logic controllers have been found to perform better than the traditional air temperature controllers.", "startOffset": 84, "endOffset": 276}, {"referenceID": 25, "context": "Fuzzy logic is a common HVAC control approach given the imprecise nature of comfort (Davis et al., 1996, 1998; Beinarts and Levchenkov, 2011; Singh et al., 2006; Thompson and Dexter, 2010; Stephen et al., 2010; Nasution, 2008; Farzaneh and Tootoonchi, 2008; Gach et al., 1997) and many fuzzy-logic controllers have been found to perform better than the traditional air temperature controllers.", "startOffset": 84, "endOffset": 276}, {"referenceID": 12, "context": "Fuzzy logic is a common HVAC control approach given the imprecise nature of comfort (Davis et al., 1996, 1998; Beinarts and Levchenkov, 2011; Singh et al., 2006; Thompson and Dexter, 2010; Stephen et al., 2010; Nasution, 2008; Farzaneh and Tootoonchi, 2008; Gach et al., 1997) and many fuzzy-logic controllers have been found to perform better than the traditional air temperature controllers.", "startOffset": 84, "endOffset": 276}, {"referenceID": 13, "context": "Fuzzy logic is a common HVAC control approach given the imprecise nature of comfort (Davis et al., 1996, 1998; Beinarts and Levchenkov, 2011; Singh et al., 2006; Thompson and Dexter, 2010; Stephen et al., 2010; Nasution, 2008; Farzaneh and Tootoonchi, 2008; Gach et al., 1997) and many fuzzy-logic controllers have been found to perform better than the traditional air temperature controllers.", "startOffset": 84, "endOffset": 276}, {"referenceID": 2, "context": "they may have cultural or personal preferences (Cheung, 2010). While there are many factors that can affect comfort, not all affect it equally. While air temperature remains central to comfort, as the number of sensors and intelligence of the controller within the car increases, it becomes possible to include more factors. A number of additional models, estimators, and predictors populate the literature, typically accompanied by a strategy for HVAC control (e.g., Ueda and Taniguchi (1999) predicts comfort based on facial skin temperature and cabin air temperature; Goenka and Maranville (2013) proposed a zonal HVAC system driven on an occupant thermal comfort level based on sensor measurements, thermal comfort charts, the ASHRAE thermal scale, ISO 7730, the PMV index, the PPD index and their combination; Kranz (2011) applies artificial intelligence methods to extract thermal comfort knowledge from the interaction between the passengers and the HVAC controls).", "startOffset": 48, "endOffset": 494}, {"referenceID": 2, "context": "they may have cultural or personal preferences (Cheung, 2010). While there are many factors that can affect comfort, not all affect it equally. While air temperature remains central to comfort, as the number of sensors and intelligence of the controller within the car increases, it becomes possible to include more factors. A number of additional models, estimators, and predictors populate the literature, typically accompanied by a strategy for HVAC control (e.g., Ueda and Taniguchi (1999) predicts comfort based on facial skin temperature and cabin air temperature; Goenka and Maranville (2013) proposed a zonal HVAC system driven on an occupant thermal comfort level based on sensor measurements, thermal comfort charts, the ASHRAE thermal scale, ISO 7730, the PMV index, the PPD index and their combination; Kranz (2011) applies artificial intelligence methods to extract thermal comfort knowledge from the interaction between the passengers and the HVAC controls).", "startOffset": 48, "endOffset": 600}, {"referenceID": 2, "context": "they may have cultural or personal preferences (Cheung, 2010). While there are many factors that can affect comfort, not all affect it equally. While air temperature remains central to comfort, as the number of sensors and intelligence of the controller within the car increases, it becomes possible to include more factors. A number of additional models, estimators, and predictors populate the literature, typically accompanied by a strategy for HVAC control (e.g., Ueda and Taniguchi (1999) predicts comfort based on facial skin temperature and cabin air temperature; Goenka and Maranville (2013) proposed a zonal HVAC system driven on an occupant thermal comfort level based on sensor measurements, thermal comfort charts, the ASHRAE thermal scale, ISO 7730, the PMV index, the PPD index and their combination; Kranz (2011) applies artificial intelligence methods to extract thermal comfort knowledge from the interaction between the passengers and the HVAC controls).", "startOffset": 48, "endOffset": 828}, {"referenceID": 2, "context": ", 1996, 1998; Beinarts and Levchenkov, 2011; Singh et al., 2006; Thompson and Dexter, 2010; Stephen et al., 2010; Nasution, 2008; Farzaneh and Tootoonchi, 2008; Gach et al., 1997) and many fuzzy-logic controllers have been found to perform better than the traditional air temperature controllers. Farzaneh and Tootoonchi (2008) demonstrated that even better results were obtained when the parameters of the comfort oriented fuzzy controller were optimised by a genetic algorithm.", "startOffset": 14, "endOffset": 328}, {"referenceID": 2, "context": ", 1996, 1998; Beinarts and Levchenkov, 2011; Singh et al., 2006; Thompson and Dexter, 2010; Stephen et al., 2010; Nasution, 2008; Farzaneh and Tootoonchi, 2008; Gach et al., 1997) and many fuzzy-logic controllers have been found to perform better than the traditional air temperature controllers. Farzaneh and Tootoonchi (2008) demonstrated that even better results were obtained when the parameters of the comfort oriented fuzzy controller were optimised by a genetic algorithm. Such controllers are, however, computationally expensive and can be difficult to design. 2.2. Reinforcement learning-based control applications Dalamagkidis et al. (2007) and Fazenda et al.", "startOffset": 14, "endOffset": 651}, {"referenceID": 2, "context": ", 1996, 1998; Beinarts and Levchenkov, 2011; Singh et al., 2006; Thompson and Dexter, 2010; Stephen et al., 2010; Nasution, 2008; Farzaneh and Tootoonchi, 2008; Gach et al., 1997) and many fuzzy-logic controllers have been found to perform better than the traditional air temperature controllers. Farzaneh and Tootoonchi (2008) demonstrated that even better results were obtained when the parameters of the comfort oriented fuzzy controller were optimised by a genetic algorithm. Such controllers are, however, computationally expensive and can be difficult to design. 2.2. Reinforcement learning-based control applications Dalamagkidis et al. (2007) and Fazenda et al. (2014) have examined the problem of optimising HVAC thermal comfort-based control through a RLbased technique in the context of buildings rather than cars.", "startOffset": 14, "endOffset": 677}, {"referenceID": 2, "context": ", 1996, 1998; Beinarts and Levchenkov, 2011; Singh et al., 2006; Thompson and Dexter, 2010; Stephen et al., 2010; Nasution, 2008; Farzaneh and Tootoonchi, 2008; Gach et al., 1997) and many fuzzy-logic controllers have been found to perform better than the traditional air temperature controllers. Farzaneh and Tootoonchi (2008) demonstrated that even better results were obtained when the parameters of the comfort oriented fuzzy controller were optimised by a genetic algorithm. Such controllers are, however, computationally expensive and can be difficult to design. 2.2. Reinforcement learning-based control applications Dalamagkidis et al. (2007) and Fazenda et al. (2014) have examined the problem of optimising HVAC thermal comfort-based control through a RLbased technique in the context of buildings rather than cars. Dalamagkidis et al. (2007) developed and simulated a reinforcement learning-based controller using Matlab/Simulink.", "startOffset": 14, "endOffset": 853}, {"referenceID": 2, "context": ", 1996, 1998; Beinarts and Levchenkov, 2011; Singh et al., 2006; Thompson and Dexter, 2010; Stephen et al., 2010; Nasution, 2008; Farzaneh and Tootoonchi, 2008; Gach et al., 1997) and many fuzzy-logic controllers have been found to perform better than the traditional air temperature controllers. Farzaneh and Tootoonchi (2008) demonstrated that even better results were obtained when the parameters of the comfort oriented fuzzy controller were optimised by a genetic algorithm. Such controllers are, however, computationally expensive and can be difficult to design. 2.2. Reinforcement learning-based control applications Dalamagkidis et al. (2007) and Fazenda et al. (2014) have examined the problem of optimising HVAC thermal comfort-based control through a RLbased technique in the context of buildings rather than cars. Dalamagkidis et al. (2007) developed and simulated a reinforcement learning-based controller using Matlab/Simulink. The reward is a function of the building occupants\u2019 thermal comfort, the energy consumption and the indoor air quality. The proposed controller was compared to a Fuzzy-PD controller and a traditional on/off controller (an evaluation approach also applied here). The results showed that, after a couple of simulated years of training, the reinforcement learning-based controller performed better in comparison to the other two controllers. Dalamagkidis et al. (2007) highlight an issue with regard to reinforcement learning-based controllers\u2014that of sufficient exploration.", "startOffset": 14, "endOffset": 1408}, {"referenceID": 0, "context": "Less recently, Anderson et al. (1997) have examined the problem of a simulated heating coil and combined a PI (proportional-integral) controller with an RL supervisor.", "startOffset": 15, "endOffset": 38}, {"referenceID": 0, "context": "Less recently, Anderson et al. (1997) have examined the problem of a simulated heating coil and combined a PI (proportional-integral) controller with an RL supervisor. They showed that the combined approach outperforms the base PI controller. This combination is similar to the approach here where the RL action is a vent temperature set-point that is passed to a base controller to achieve. Dounis and Caraiscos (2009) provide a detailed review of computational intelligence approaches in the built environment and show that, for the built environment, a variety of adaptive control approaches have been tried and advanced approaches (such as RL) have led to improved comfort and energy savings.", "startOffset": 15, "endOffset": 420}, {"referenceID": 16, "context": "For continuous state MDPs, Q (s, a) must be approximated using a function f ( ~ \u03b8, s, a ) parameterised by a vector ~ \u03b8 and algorithms, such as Sarsa(\u03bb), that use this approach may not converge on the optimum policy but may oscillate (Gordon, 2000).", "startOffset": 234, "endOffset": 248}, {"referenceID": 16, "context": "For continuous state MDPs, Q (s, a) must be approximated using a function f ( ~ \u03b8, s, a ) parameterised by a vector ~ \u03b8 and algorithms, such as Sarsa(\u03bb), that use this approach may not converge on the optimum policy but may oscillate (Gordon, 2000). A learning episode begins by selecting an initial state at random from the distribution s0 \u223c S0 and then continues with the agent selecting an action and the cabin model returning a new state and reward until a maximum number of steps is reached. For some problems, it is possible to have a terminal state that ends the episode. However, this is not possible here, since the reaching comfort is not sufficient; the agent needs to efficiently maintain comfort as well. The initial state distribution should be comprehensive to avoid leaving parts of the state space unexplored. The agent is \u03b5-greedy, which means that with probability \u03b5 it selects a random action and otherwise it selects according to the largest estimated utility for that state, as per (2). Although it might be possible to implement a learning system directly in the car, prior works in this domain (such as, Ng et al. (2006)) suggest learning in simulation first.", "startOffset": 235, "endOffset": 1145}, {"referenceID": 22, "context": "Cabin Thermal Environmental Model Car cabin thermal modelling has been investigated by a number of authors (Lee et al., 2015; Torregrosa-Jaime et al., 2015), typically to examine the trade-off between comfort and energy use.", "startOffset": 107, "endOffset": 156}, {"referenceID": 33, "context": "Cabin Thermal Environmental Model Car cabin thermal modelling has been investigated by a number of authors (Lee et al., 2015; Torregrosa-Jaime et al., 2015), typically to examine the trade-off between comfort and energy use.", "startOffset": 107, "endOffset": 156}, {"referenceID": 22, "context": "Cabin Thermal Environmental Model Car cabin thermal modelling has been investigated by a number of authors (Lee et al., 2015; Torregrosa-Jaime et al., 2015), typically to examine the trade-off between comfort and energy use. Simple 1D models are appropriate for optimisation (e.g., Lee et al. (2015) examines the effect of different coolant fluids) since they allow the consequences of changes to be quickly evaluated.", "startOffset": 108, "endOffset": 300}, {"referenceID": 22, "context": "Cabin Thermal Environmental Model Car cabin thermal modelling has been investigated by a number of authors (Lee et al., 2015; Torregrosa-Jaime et al., 2015), typically to examine the trade-off between comfort and energy use. Simple 1D models are appropriate for optimisation (e.g., Lee et al. (2015) examines the effect of different coolant fluids) since they allow the consequences of changes to be quickly evaluated. Some simplifying assumptions are necessary and different works tend to make different assumptions about the cabin environment. For example, Lee et al. (2015) include the effect of engine heat on supply and return ducts, whereas TorregrosaJaime et al.", "startOffset": 108, "endOffset": 577}, {"referenceID": 22, "context": "Cabin Thermal Environmental Model Car cabin thermal modelling has been investigated by a number of authors (Lee et al., 2015; Torregrosa-Jaime et al., 2015), typically to examine the trade-off between comfort and energy use. Simple 1D models are appropriate for optimisation (e.g., Lee et al. (2015) examines the effect of different coolant fluids) since they allow the consequences of changes to be quickly evaluated. Some simplifying assumptions are necessary and different works tend to make different assumptions about the cabin environment. For example, Lee et al. (2015) include the effect of engine heat on supply and return ducts, whereas TorregrosaJaime et al. (2015) include radiant heat effects for a multi-zone minivan.", "startOffset": 108, "endOffset": 677}, {"referenceID": 20, "context": "In comparison with Lee et al. (2015) this model does not deal with the internals of the evaporator but rather considers the combined heat sum from a heat pump.", "startOffset": 19, "endOffset": 37}, {"referenceID": 20, "context": "In comparison with Lee et al. (2015) this model does not deal with the internals of the evaporator but rather considers the combined heat sum from a heat pump. Also, heat effects from the internal combustion engine (through the firewall or supply ducts) are not considered here (and may be inappropriate for an electric vehicle). Torregrosa-Jaime et al. (2015) have a more sophisticated model that includes two zones for a minivan.", "startOffset": 19, "endOffset": 361}, {"referenceID": 18, "context": "Model validation The simulation data was compared to empirical data collected by the authors within various warm-up and cool-down scenarios (described in Hintea et al. (2014)).", "startOffset": 154, "endOffset": 175}, {"referenceID": 23, "context": "Equivalent temperature (ET) is not an explicit component of the state but is computed using a formula (referring to sedentary conditions only, that is energy metabolism < 70Wm\u22122) introduced by Madsen (1978); Madsen et al.", "startOffset": 193, "endOffset": 207}, {"referenceID": 23, "context": "Equivalent temperature (ET) is not an explicit component of the state but is computed using a formula (referring to sedentary conditions only, that is energy metabolism < 70Wm\u22122) introduced by Madsen (1978); Madsen et al. (1984),", "startOffset": 193, "endOffset": 229}, {"referenceID": 26, "context": "The value was selected based on cabin air flow measurements in the literature Neacsu (2011). The mean radiant temperature Tr is assumed to be equal to the interior mass temperature Tm.", "startOffset": 78, "endOffset": 92}, {"referenceID": 28, "context": "0 (Rada-Vilela, 2014).", "startOffset": 2, "endOffset": 21}, {"referenceID": 5, "context": "These rules are slightly modified from those used by Dalamagkidis et al. (2007) and Kelly and Pawlak (2003).", "startOffset": 53, "endOffset": 80}, {"referenceID": 5, "context": "These rules are slightly modified from those used by Dalamagkidis et al. (2007) and Kelly and Pawlak (2003). 4.", "startOffset": 53, "endOffset": 108}, {"referenceID": 18, "context": "Pathway to implementation in the car Occupant ET, which is used here as a proxy for comfort, cannot be directly measured in a real car cabin and the need for a proxy inspired the development of a Virtual Thermal Comfort Sensor (VTCS) (Hintea et al., 2013).", "startOffset": 234, "endOffset": 255}, {"referenceID": 17, "context": "However, work to date on integrating with a Dymola-based cabin simulation (Gravelle et al., 2014) has shown that ensuring that the simulation is sufficiently fast remains a key challenge.", "startOffset": 74, "endOffset": 97}], "year": 2017, "abstractText": "Vehicle climate control systems aim to keep passengers thermally comfortable. However, current systems control temperature rather than thermal comfort and tend to be energy hungry, which is of particular concern when considering electric vehicles. This paper poses energy-efficient vehicle comfort control as a Markov Decision Process, which is then solved numerically using Sarsa(\u03bb) and an empirically validated, single-zone, 1D thermal model of the cabin. The resulting controller was tested in simulation using 200 randomly selected scenarios and found to exceed the performance of bang-bang, proportional, simple fuzzy logic, and commercial controllers with 23%, 43%, 40%, 56% increase, respectively. Compared to the next best performing controller, energy consumption is reduced by 13% while the proportion of time spent thermally comfortable is increased by 23%. These results indicate that this is a viable approach that promises to translate into substantial comfort and energy improvements in the car.", "creator": "LaTeX with hyperref package"}}}