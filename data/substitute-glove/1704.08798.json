{"id": "1704.08798", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Apr-2017", "title": "Word Affect Intensities", "abstract": "Words without convey affect - - emotions, motivation, and attitudes. Lexicons of answer - needs association few requirements prior overhead jealousy precise taking natural nahuatl generation. However, which lexicons indicate only loam subjects of affect association. Here, for a 2005 one, just could kind sustain intensities phrase close sure - contracts one the federation. We instead piece skill be thing - deadliest scaling still mobility 36-bit consistency and obtains proved fine - chalky scores. The language collection giving combination brought between general English and terms analysis they religious media electronics. It in close it 6, 130 editions for four programs emotional. We let because immediately entries for other affect frame after.", "histories": [["v1", "Fri, 28 Apr 2017 03:33:16 GMT  (72kb,D)", "http://arxiv.org/abs/1704.08798v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["saif m mohammad"], "accepted": false, "id": "1704.08798"}, "pdf": {"name": "1704.08798.pdf", "metadata": {"source": "CRF", "title": "Word Affect Intensities", "authors": ["Saif M. Mohammad"], "emails": ["saif.mohammad@nrc-cnrc.gc.ca"], "sections": [{"heading": null, "text": "Words often convey affect\u2014emotions, feelings, and attitudes. Lexicons of word\u2013 affect association have applications in automatic emotion analysis and natural language generation. However, existing lexicons indicate only coarse categories of affect association. Here, for the first time, we create an affect intensity lexicon with real-valued scores of association. We use a technique called best\u2013worst scaling that improves annotation consistency and obtains reliable fine-grained scores. The lexicon includes terms from general English as well as terms specific to social media communications. It has close to 6,000 entries for four basic emotions. We will be adding entries for other affect dimensions shortly."}, {"heading": "1 Introduction", "text": "Words often convey affect\u2014emotions, feelings, and attitudes. Some words have affect as a core part of their meaning. For example, dejected and wistful denotate some amount of sadness (and are thus associated with sadness). On the other hand, some words are associated with affect even though they do not denotate affect. For example, failure and death describe concepts that are usually accompanied by sadness and thus they connotate some amount of sadness. Lexicons of word\u2013affect association have numerous applications, including: tracking brand and product perception, tracking support for issues and policies, tracking public health and well-being, literary analysis, developing more natural dialogue systems, and disaster/crisis management. However, existing manually created affect lexicons only indicate coarse\ncategories of emotion association, for example, associated with fear or not associated with fear.\nOn the other hand, words can be associated with different intensities (or degrees) of an emotion. For example, most people will agree that the word condemn is associated with a greater degree of anger (or more anger) than the word irritate. However, annotating instances for fine-grained degrees of affect is a substantially more difficult undertaking than categorical annotation. Respondents are presented with greater cognitive load and it is particularly hard to ensure consistency (both across responses by different annotators and within the responses produced by the same annotator).\nBest-Worst Scaling (BWS) is an annotation scheme that addresses these limitations (Louviere, 1991; Cohen, 2003; Louviere et al., 2015). Annotators are given n items (an n-tuple, where n > 1 and commonly n = 4). They are asked which item is the best (highest in terms of the property of interest) and which is the worst (least in terms of the property of interest). When working on 4- tuples, best\u2013worst annotations are particularly efficient because each best and worst annotation will reveal the order of five of the six item pairs. For example, for a 4-tuple with items A, B, C, and D, if A is the best, and D is the worst, then A > B, A > C, A > D, B > D, and C > D.\nWe can calculate real-valued scores of association between the items and the property of interest from the best\u2013worst annotations for a set of 4-tuples (Orme, 2009; Flynn and Marley, 2014). It has been empirically shown that three annotations each for 2N 4-tuples is sufficient for obtaining reliable scores (where N is the number of items) (Louviere, 1991; Kiritchenko and Mohammad, 2016).1\n1At its limit, when n = 2, BWS becomes a paired comparison (Thurstone, 1927; David, 1963), but then a much larger set of tuples need to be annotated (closer to N2).\nar X\niv :1\n70 4.\n08 79\n8v 1\n[ cs\n.C L\n] 2\n8 A\npr 2\n01 7\nHere, for the first time, we create an affect intensity lexicon with real-valued scores of association using best\u2013worst scaling. For a given word and emotion X, the scores range from 0 to 1. A score of 1 means that the word conveys the highest amount of emotion X. A score of 0 means that the word conveys the lowest amount of emotion X. We will refer to this lexicon as the NRC Affect Intensity Lexicon. It has close to 6,000 entries for four basic emotions: anger, fear, joy, and sadness. We will shortly be adding entries for four more emotions: trust, disgust, anticipation, and surprise. We will also be adding entries for valence, arousal, and dominance. It includes common English terms as well as terms that are more prominent in social media platforms, such as Twitter. It includes terms that are associated with emotions to various degrees. For a given emotion, this even includes some terms that may not predominantly convey that emotion (or that convey an antonymous emotion), and yet tend to co-occur with terms that do. Antonymous terms tend to cooccur with each other more often than chance, and are particularly problematic when one uses automatic co-occurrence-based statistical methods to capture word\u2013emotion connotations. Thus, it is particularly beneficial to have manual annotations of affect intensity for these terms.\nWe show that repeat annotations of the terms in the Affect Intensity Lexicon with independent annotators lead to affect association scores that are close to the scores obtained originally (Spearman Rank correlations of 0.92; Pearson correlation: 0.91). The fine-grained score obtained with BWS and the high correlations on repeat annotations indicate that BWS is both markedly discriminative (helps identify small differences in affect intensity) and markedly reliable (provides stable outcomes). We make the NRC Affect Intensity Lexicon freely available for, non-commercial, research purposes.2"}, {"heading": "2 Related Work", "text": "Psychologists have argued that some emotions are more basic than others (Ekman, 1992; Plutchik, 1980; Parrot, 2001; Frijda, 1988).3 Thus, most work on capturing word\u2013emotion associations has focused on a handful of emotions, especially since\n2www.saifmohammad.com/WebPages/AffectIntensity.htm 3However, they disagree on which emotions (and how\nmany) should be classified as basic emotions\u2014some propose 6, some 8, some 20, and so on.\nmanually annotating for a large number of emotions is arduous. In this project, the goal is to create an affect intensity lexicon for the eight emotions emotions: anger, fear, joy, sadness, disgust, trust, anticipation, and surprise. These are the eight emotions considered to be most basic by (Plutchik, 1980). The eight emotions include the six emotions considered most basic by (Ekman, 1992), as well as trust and anticipation.\nThere is a large body of work on creating valence or sentiment lexicons, including the General Inquirer (Stone et al., 1966), ANEW (Nielsen, 2011; Bradley and Lang, 1999), MPQA (Wiebe et al., 2005), and norms lexicon by Warriner et al. (2013). The work on creating lexicons for categorical emotions such as joy, sadness, fear, etc, is comparatively small. WordNet Affect Lexicon (Strapparava and Valitutti, 2004) has a few hundred words annotated with the emotions they evoke.4 It was created by manually identifying the emotions of a few seed words and then marking all their WordNet synonyms as having the same emotion. The NRC Emotion Lexicon was created by crowdsourcing and it includes entries for about 14,000 words and eight Plutchik emotions (Mohammad and Turney, 2013, 2010).5 It also includes entries for positive and negative sentiment.\nAll of the emotion work and a vast majority of the valence (sentiment) work has used categorical annotation or a coarse rating scale to obtain annotations. This is not surprising, because it is difficult for humans to provide direct scores at a fine granularity. A common problem is inconsistencies in annotations among different annotators. One annotator might assign a score of 7.9 to a word, whereas another annotator may assign a score of 6.2 to the same word. It is also common that the same annotator assigns different scores to the same word at different points in time. Further, annotators often have a bias towards different parts of the scale, known as scale region bias. Despite this, a key question is whether humans are able to distinguish affect at only four or five coarse levels, or whether we can discriminate across much smaller affect intensity differences.\nBest-Worst Scaling (BWS) was developed by Louviere (1991), building on some groundbreaking research in the 1960s in mathematical psychology and psychophysics by Anthony A. J.\n4http://wndomains.fbk.eu/wnaffect.html 5http://www.purl.org/net/saif.mohammad/research\nMarley and Duncan Luce. However, it is not well known outside the areas of choice modeling and marketing research. Within the NLP community, BWS has thus far been used for creating datasets for relational similarity (Jurgens et al., 2012), word-sense disambiguation (Jurgens, 2013), and word\u2013sentiment intensity (Kiritchenko and Mohammad, 2016). In this work we use BWS to annotate words for intensity (or degree) of affect. With BWS we address the challenges of direct scoring, and produce more reliable emotion intensity scores. Further, this will be the first dataset that will also include emotion scores for words common in social media.\nThere is growing work on automatically determining word\u2013emotion associations (Mohammad and Kiritchenko, 2015; Mohammad, 2012; Strapparava and Valitutti, 2004; Yang et al., 2007). These automatic methods often assign a realvalued score representing the degree of association. However, they have been evaluated on the class of emotion they assign to each word. With the NRC Affect Intensity Lexicon, one can evaluate how accurately the automatic methods capture affect intensity."}, {"heading": "3 NRC Affect Intensity Lexicon", "text": "We now describe how we created the NRC Affect Intensity Lexicon."}, {"heading": "3.1 Term Selection", "text": "We chose to annotate commonly used English terms, as well as terms common in social media texts, so that the resulting lexicon can be applied widely. Twitter has a large and diverse user base, which entails rich textual content.6 Tweets have plenty of non-standard language such as emoticons, emojis, creatively spelled words (happee), hashtags (#takingastand, #lonely) and conjoined words (loveumom). Tweets are often used to convey one\u2019s emotions, opinions towards products, and stance over issues. Thus, emotion analysis of tweets is particularly compelling.\nSince most words do not convey a particular emotion to a marked degree, annotating all words for all emotions is sub-optimal. Thus, for each of the eight emotions, we created separate lists of terms that satisfied either one of the two properties listed below:\n6Twitter is an online social networking and microblogging service where users post and read messages that are up to 140 characters long. The posts are called tweets.\n\u2022 The word is already known to be associated with the emotion (although the intensity of emotion it conveys is unknown).\n\u2022 The word has a tendency to occur in tweets that express the emotion.\nWith these properties in mind, for our annotation, we included terms form two separate sources:\n\u2022 The words listed in the NRC Emotion Lexicon that are marked as being associated with any of the Plutchik emotions.\n\u2022 The words that tend to co-occur more often than chance with emotion-word hashtags in a large tweets corpus. (Emotion-word hashtags, such as #angry, #fear, and #happiness, act as noisy labels of the corresponding emotions.)\nSince the NRC Emotion Lexicon (Mohammad and Turney, 2013, 2010) included only those terms that occur frequently in the Google n-gram corpus (Brants and Franz, 2006), these terms satisfy the \u2018commonly used terms\u2019 criterion as well.\nAs the Twitter source, we make use of the Hashtag Emotion Corpus (Mohammad, 2012), which is a large collection of tweets that each have at least one emotion-word hashtag. This dataset has emotion word hashtags corresponding to the eight basic Plutchik emotions. As mentioned before, we consider the emotion word hashtags as (noisy) labels of the corresponding emotions. For every word w that occurred more than ten times in the corpus, we compute the pointwise mutual information (PMI) between the word and each of the emotion labels e.\nPMI (w, e) = log freq(w, e)\nfreq(w) \u2217 freq(e) (1)\nwhere freq(w, e) is the number of times w occurs in a sentence with label e. freq(w) and freq(e) are the frequencies of w and e in the corpus. If a word has a greater-than-chance tendency to occur in tweets with a particular emotion label, then it will have a PMI score that is greater than 1. For each emotion, we included all terms in the Hashtag Emotion Corpus (Mohammad, 2012) that had a PMI > 1. Note that this set of terms included both terms that are more common in social media communication (for example, soannoyed, grrrrr, stfu, and thx) as well as regular English words.7\n7Some of the terms included from the Twitter source were deliberate spelling variations of English words, for example, bluddy and sux."}, {"heading": "3.2 Annotating for Affect Intensity with Best\u2013Worst Scaling", "text": "For each emotion, the annotators were presented with four words at a time (4-tuples) and asked to select the word that conveys the highest emotion intensity and the word that conveys the lowest emotion intensity. 2\u00d7N (where N is the number of words to be annotated) distinct 4-tuples were randomly generated in such a manner that each word is seen in eight different 4-tuples, and no two 4-tuples have more than two items in common. We used the script provided by Kiritchenko and Mohammad (2016) to obtain the BWS annotations.8\nKiritchenko and Mohammad (2016) showed that using just three annotations per 4-tuple produces highly reliable results. We obtained four independent annotations for each 4-tuple. Note that since each word occurs in eight different 4-tuples, each word is involved in 8 \u00d7 4 = 32 best\u2013worst judgments. We obtained annotations from native speakers of English residing in the United States of America. Annotators were free to provide responses to as many 4-tuples as they wished. The set of 4-tuples for each emotion was annotated by 50 to 75 people. A sample questionnaire is shown below.\nWords Associated With Most And Least Anger\nWords can be associated with different degrees of an emotion. For example, most people will agree that the word condemn is associated with a greater degree of anger (or more anger) than the word irritate. The goal of this task is to determine the degrees of anger associated with words. Since it is hard to give a numerical score indicating the degree of anger, we will give you four different words and ask you to indicate to us:\n\u2022 which of the four words is associated with the MOST anger\n\u2022 which of the four words is associated with the LEAST anger\nA rule of thumb that may be helpful is that a word associated with more anger tends to occur in many angry sentences, whereas a word associated with less anger tends to occur in fewer angry sentences.\nContent Warning: Since this task is about words associated with anger, some of the words you may encounter may be offensive.\n8http://saifmohammad.com/WebPages/BestWorst.html\nImportant Notes \u2022 Choose the answer that you think most native\nspeakers of English will choose. \u2022 If the answer could be either one of two or\nmore words (i.e., they are associated with equal degrees of anger), then select any one of them as the answer.\n\u2022 Some words such as, furious and irritated, are not only associated with anger, they also explicitly express anger. Others do not express anger, but they are associated with the emotion; for example, argument and corruption are associated with anger. To be selected as \u2018associated with MOST anger\u2019 or \u2018associated with LEAST anger\u2019, a word does not have to explicitly express anger.\n\u2022 Some words have more than one meaning, and the different meanings may be associated with different degrees of anger. If one of the meanings of the word is strongly associated with anger, then base your response on that meaning of the word. For example, if one of the words in the list is mad, then base your response on the angry sense of mad, as opposed to the mentally unstable sense of mad.\n\u2022 Even when considering a particular sense or meaning of word, the word may convey differing degrees of anger in differing contexts. Base your response on the average anger associated with the word in that sense.\n\u2022 Most importantly, try not to over-think the answer. Let your instinct guide you.\nEXAMPLE\nQ1. Identify the term associated with the MOST anger. \u2022 tree \u2022 grrr \u2022 boiling \u2022 vexed Ans: boiling\nQ2. Identify the term associated with the LEAST anger \u2022 tree \u2022 grrr \u2022 boiling \u2022 vexed Ans: tree\nThe questionnaires for other emotions are similar in structure.\nThe 4-tuples of words were uploaded for annotation on the crowdsourcing platform, CrowdFlower.9 About 5% of the data was annotated internally before hand (by the author). These questions are referred to as gold questions. The gold questions are interspersed with other questions. If one gets a gold question wrong, they are immediately notified of it. If one\u2019s accuracy on the gold questions falls below 70%, they are refused further annotation, and all of their annotations are discarded. This serves as a mechanism to avoid malicious annotations. In addition, the gold questions serve as examples to guide the annotators. In a post-annotation survey, the respondents gave the task high scores for clarity of instruction (an average of 4.5 out of 5) and overall satisfaction (an average of 4.3 out of 5).\nThe BWS responses were translated into scores by a simple calculation (Orme, 2009; Flynn and Marley, 2014): For each item, the score is the proportion of times the item was chosen as having the most intensity minus the proportion of times the item was chosen as having the least intensity. The scores range from -1 to 1. Since degree of emotion is a unipolar scale, we linearly transform the the -1 to 1 scores to scores in the range 0 to 1. We refer to the full list of words along with their real-valued scores of affect intensity as the NRC Affect Intensity Lexicon. The lexicon has about 12,000 entries with about 1500 entries for each of the eight\n9http://www.crowdflower.com\nemotions. Table 1 shows some example entries from the lexicon. Figure 1 shows the histogram of word\u2013anger intensities. Observe that the intensity scores have a normal distribution. The histograms for other emotions have a similar shape. The lexicon is made freely available for, non-commercial, research purposes.10\n10www.saifmohammad.com/WebPages/AffectIntensity.htm"}, {"heading": "4 Reliability of the Annotations", "text": "One cannot use standard inter-annotator agreement to determine quality of BWS annotations because the disagreement that arises when a tuple has two items that are close in emotion intensity is a useful signal for BWS. For a given 4-tuple, if respondents are not able to consistently identify the word that has highest (or lowest) emotion intensity, then the disagreement will lead to the two words obtaining scores that are close to each other, which is the desired outcome. Thus a different measure of quality of annotations must be utilized.\nA useful measure of quality is reproducibility of the end result\u2014if repeated independent manual annotations from multiple respondents result in similar intensity scores, then one can be confident that the scores capture the true emotion intensities. To assess this reproducibility, we calculate average split-half reliability (SHR) over 100 trials. SHR is a commonly used approach to determine consistency in psychological studies, that we employ as follows. All annotations for an item (in our case, tuples) are randomly split into two halves. Two sets of scores are produced independently from the two halves. Then the correlation between the two sets of scores is calculated. If the annotations are of good quality, then the correlation between the two halves will be high. Table 2 shows the split-half reliabilities for the anger, fear, joy, and sadness entries in the NRC Affect Intensity Lexicon. Observe that both the Pearson correlation and the Spearman rank correlations are above 0.9, indicating a high degree of reproducibility. Note that SHR indicates the quality of annotations obtained when using only half the number of annotations, the correlations obtained when repeating the experiment with four annotations for each 4-tuple is expected to be higher than 0.91. Thus 0.91 is a lower bound on the quality of annotations obtained with four annotations per 4-tuple."}, {"heading": "5 Applications", "text": "The NRC Affect Intensity Lexicon has many applications including automatic sentiment and emotion analysis. Mohammad and Bravo-Marquez (2017) show its usefulness for automatically determining in intensity of emotion conveyed by tweets. They also annotate a dataset of tweets for degree (or intensity) of emotion felt by the speaker\u2014the Tweet Emotion Intensity Dataset. The lexicon along with Tweet Emotion Intensity Dataset can be used to study the interplay between tweet emotion intensity and the intensity of words that make up the tweet. The lexicon also has applications in the areas of digital humanities and literary analysis, where it can be used to identify highintensity words. The NRC Affect Intensity Lexicon can also be used as a source of gold intensity scores to evaluate automatic methods of determining word affect intensity."}, {"heading": "6 Conclusions", "text": "We created the NRC Affect Intensity Lexicon, which is a high-coverage lexicons that captures word\u2013affect intensities for eight basic emotions. We used the technique of best\u2013worst scaling (BWS) to obtain fine-grained scores (and word rankings) and address issues of annotation consistency that plague traditional rating scale methods of annotation. We show that repeat annotations of the terms in the Affect Intensity Lexicon with independent annotators lead to affect association scores that are close to the scores obtained originally (Spearman Rank correlations of 0.92; Pearson correlation: 0.91). The fine-grained score obtained with BWS and the high correlations on repeat annotations indicate that BWS is both markedly discriminative (helps identify small differences in affect intensity) and markedly reliable (provides stable outcomes). The lexicon has applications in automatic emotion analysis as well as in understanding affect composition\u2014how affect of a sentence is impacted by the affect of its constituent words. We are already in the process of adding entries for the emotions of disgust, trust, surprise, and anticipation. Then we will obtain valence, arousal, and dominance scores for all of the terms in the NRC Affect Intensity lexicon."}, {"heading": "Acknowledgments", "text": "Many thanks to Svetlana Kiritchenko and Tara Small for helpful discussions."}], "references": [{"title": "Affective norms for English words (ANEW): Instruction manual and affective ratings", "author": ["Margaret M Bradley", "Peter J Lang."], "venue": "Technical report, The Center for Research in Psychophysiology, University of Florida.", "citeRegEx": "Bradley and Lang.,? 1999", "shortCiteRegEx": "Bradley and Lang.", "year": 1999}, {"title": "Web 1t 5-gram version 1", "author": ["Thorsten Brants", "Alex Franz."], "venue": "Linguistic Data Consortium .", "citeRegEx": "Brants and Franz.,? 2006", "shortCiteRegEx": "Brants and Franz.", "year": 2006}, {"title": "Maximum difference scaling: Improved measures of importance and preference for segmentation", "author": ["Steven H. Cohen."], "venue": "Sawtooth Software, Inc.", "citeRegEx": "Cohen.,? 2003", "shortCiteRegEx": "Cohen.", "year": 2003}, {"title": "The method of paired comparisons", "author": ["Herbert Aron David."], "venue": "Hafner Publishing Company, New York.", "citeRegEx": "David.,? 1963", "shortCiteRegEx": "David.", "year": 1963}, {"title": "An argument for basic emotions", "author": ["Paul Ekman."], "venue": "Cognition and Emotion 6(3):169\u2013200.", "citeRegEx": "Ekman.,? 1992", "shortCiteRegEx": "Ekman.", "year": 1992}, {"title": "Best-worst scaling: theory and methods", "author": ["T.N. Flynn", "A.A.J. Marley."], "venue": "Stephane Hess and Andrew Daly, editors, Handbook of Choice Modelling, Edward Elgar Publishing, pages 178\u2013201.", "citeRegEx": "Flynn and Marley.,? 2014", "shortCiteRegEx": "Flynn and Marley.", "year": 2014}, {"title": "The laws of emotion", "author": ["Nico H Frijda."], "venue": "American psychologist 43(5):349.", "citeRegEx": "Frijda.,? 1988", "shortCiteRegEx": "Frijda.", "year": 1988}, {"title": "Embracing ambiguity: A comparison of annotation methodologies for crowdsourcing word sense labels", "author": ["David Jurgens."], "venue": "Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics.", "citeRegEx": "Jurgens.,? 2013", "shortCiteRegEx": "Jurgens.", "year": 2013}, {"title": "Semeval-2012 task 2: Measuring degrees of relational similarity", "author": ["David Jurgens", "Saif M. Mohammad", "Peter Turney", "Keith Holyoak."], "venue": "Proceedings of the 6th International Workshop on Semantic Evaluation. Montr\u00e9al, Canada, pages 356\u2013364.", "citeRegEx": "Jurgens et al\\.,? 2012", "shortCiteRegEx": "Jurgens et al\\.", "year": 2012}, {"title": "Capturing reliable fine-grained sentiment associations by crowdsourcing and best\u2013worst scaling", "author": ["Svetlana Kiritchenko", "Saif M. Mohammad."], "venue": "Proceedings of The 15th Annual Conference of the North American Chapter of the Association for", "citeRegEx": "Kiritchenko and Mohammad.,? 2016", "shortCiteRegEx": "Kiritchenko and Mohammad.", "year": 2016}, {"title": "Best-worst scaling: A model for the largest difference judgments", "author": ["Jordan J. Louviere."], "venue": "Working Paper.", "citeRegEx": "Louviere.,? 1991", "shortCiteRegEx": "Louviere.", "year": 1991}, {"title": "Best-Worst Scaling: Theory, Methods and Applications", "author": ["Jordan J. Louviere", "Terry N. Flynn", "A.A.J. Marley."], "venue": "Cambridge University Press.", "citeRegEx": "Louviere et al\\.,? 2015", "shortCiteRegEx": "Louviere et al\\.", "year": 2015}, {"title": "Emotional Tweets", "author": ["Saif Mohammad."], "venue": "Proceedings of the First Joint Conference on Lexical and Computational Semantics (*SEM). Montr\u00e9al, Canada, pages 246\u2013255.", "citeRegEx": "Mohammad.,? 2012", "shortCiteRegEx": "Mohammad.", "year": 2012}, {"title": "Emotion intensities in tweets", "author": ["Saif M. Mohammad", "Felipe Bravo-Marquez."], "venue": "Submitted.", "citeRegEx": "Mohammad and Bravo.Marquez.,? 2017", "shortCiteRegEx": "Mohammad and Bravo.Marquez.", "year": 2017}, {"title": "Using hashtags to capture fine emotion categories from tweets", "author": ["Saif M. Mohammad", "Svetlana Kiritchenko."], "venue": "Computational Intelligence 31(2):301\u2013326. https://doi.org/10.1111/coin.12024.", "citeRegEx": "Mohammad and Kiritchenko.,? 2015", "shortCiteRegEx": "Mohammad and Kiritchenko.", "year": 2015}, {"title": "Emotions evoked by common words and phrases: Using Mechanical Turk to create an emotion lexicon", "author": ["Saif M. Mohammad", "Peter D. Turney."], "venue": "Proceedings of the NAACL-HLT Workshop on Computational Approaches to Analysis and Generation", "citeRegEx": "Mohammad and Turney.,? 2010", "shortCiteRegEx": "Mohammad and Turney.", "year": 2010}, {"title": "Crowdsourcing a word\u2013emotion association lexicon", "author": ["Saif M. Mohammad", "Peter D. Turney."], "venue": "Computational Intelligence 29(3):436\u2013465.", "citeRegEx": "Mohammad and Turney.,? 2013", "shortCiteRegEx": "Mohammad and Turney.", "year": 2013}, {"title": "A new ANEW: Evaluation of a word list for sentiment analysis in microblogs", "author": ["Finn \u00c5rup Nielsen."], "venue": "Proceedings of the ESWC Workshop on \u2019Making Sense of Microposts\u2019: Big things come in small packages. Heraklion, Crete, pages 93\u201398.", "citeRegEx": "Nielsen.,? 2011", "shortCiteRegEx": "Nielsen.", "year": 2011}, {"title": "Maxdiff analysis: Simple counting, individual-level logit, and HB", "author": ["Bryan Orme."], "venue": "Sawtooth Software, Inc.", "citeRegEx": "Orme.,? 2009", "shortCiteRegEx": "Orme.", "year": 2009}, {"title": "Emotions in Social Psychology", "author": ["W Parrot."], "venue": "Psychology Press.", "citeRegEx": "Parrot.,? 2001", "shortCiteRegEx": "Parrot.", "year": 2001}, {"title": "A general psychoevolutionary theory of emotion", "author": ["Robert Plutchik."], "venue": "Emotion: Theory, research, and experience 1(3):3\u201333.", "citeRegEx": "Plutchik.,? 1980", "shortCiteRegEx": "Plutchik.", "year": 1980}, {"title": "The General Inquirer: A Computer Approach to Content Analysis", "author": ["Philip Stone", "Dexter C. Dunphy", "Marshall S. Smith", "Daniel M. Ogilvie", "associates"], "venue": null, "citeRegEx": "Stone et al\\.,? \\Q1966\\E", "shortCiteRegEx": "Stone et al\\.", "year": 1966}, {"title": "Wordnet-Affect: An affective extension of WordNet", "author": ["Carlo Strapparava", "Alessandro Valitutti."], "venue": "Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC2004). Lisbon, Portugal, pages 1083\u20131086.", "citeRegEx": "Strapparava and Valitutti.,? 2004", "shortCiteRegEx": "Strapparava and Valitutti.", "year": 2004}, {"title": "A law of comparative judgment", "author": ["Louis L. Thurstone."], "venue": "Psychological review 34(4):273.", "citeRegEx": "Thurstone.,? 1927", "shortCiteRegEx": "Thurstone.", "year": 1927}, {"title": "Norms of valence, arousal, and dominance for 13,915 English lemmas", "author": ["Amy Beth Warriner", "Victor Kuperman", "Marc Brysbaert."], "venue": "Behavior Research Methods 45(4):1191\u20131207.", "citeRegEx": "Warriner et al\\.,? 2013", "shortCiteRegEx": "Warriner et al\\.", "year": 2013}, {"title": "Annotating expressions of opinions and emotions in language", "author": ["Janyce Wiebe", "Theresa Wilson", "Claire Cardie."], "venue": "Language Resources and Evaluation 39(2-3):165\u2013210.", "citeRegEx": "Wiebe et al\\.,? 2005", "shortCiteRegEx": "Wiebe et al\\.", "year": 2005}, {"title": "Building emotion lexicon from weblog corpora", "author": ["Changhua Yang", "Kevin Hsin-Yih Lin", "Hsin-Hsi Chen."], "venue": "Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions. pages 133\u2013136.", "citeRegEx": "Yang et al\\.,? 2007", "shortCiteRegEx": "Yang et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 10, "context": "Best-Worst Scaling (BWS) is an annotation scheme that addresses these limitations (Louviere, 1991; Cohen, 2003; Louviere et al., 2015).", "startOffset": 82, "endOffset": 134}, {"referenceID": 2, "context": "Best-Worst Scaling (BWS) is an annotation scheme that addresses these limitations (Louviere, 1991; Cohen, 2003; Louviere et al., 2015).", "startOffset": 82, "endOffset": 134}, {"referenceID": 11, "context": "Best-Worst Scaling (BWS) is an annotation scheme that addresses these limitations (Louviere, 1991; Cohen, 2003; Louviere et al., 2015).", "startOffset": 82, "endOffset": 134}, {"referenceID": 18, "context": "We can calculate real-valued scores of association between the items and the property of interest from the best\u2013worst annotations for a set of 4-tuples (Orme, 2009; Flynn and Marley, 2014).", "startOffset": 152, "endOffset": 188}, {"referenceID": 5, "context": "We can calculate real-valued scores of association between the items and the property of interest from the best\u2013worst annotations for a set of 4-tuples (Orme, 2009; Flynn and Marley, 2014).", "startOffset": 152, "endOffset": 188}, {"referenceID": 10, "context": "It has been empirically shown that three annotations each for 2N 4-tuples is sufficient for obtaining reliable scores (where N is the number of items) (Louviere, 1991; Kiritchenko and Mohammad, 2016).", "startOffset": 151, "endOffset": 199}, {"referenceID": 9, "context": "It has been empirically shown that three annotations each for 2N 4-tuples is sufficient for obtaining reliable scores (where N is the number of items) (Louviere, 1991; Kiritchenko and Mohammad, 2016).", "startOffset": 151, "endOffset": 199}, {"referenceID": 23, "context": "At its limit, when n = 2, BWS becomes a paired comparison (Thurstone, 1927; David, 1963), but then a much larger set of tuples need to be annotated (closer to N).", "startOffset": 58, "endOffset": 88}, {"referenceID": 3, "context": "At its limit, when n = 2, BWS becomes a paired comparison (Thurstone, 1927; David, 1963), but then a much larger set of tuples need to be annotated (closer to N).", "startOffset": 58, "endOffset": 88}, {"referenceID": 4, "context": "Psychologists have argued that some emotions are more basic than others (Ekman, 1992; Plutchik, 1980; Parrot, 2001; Frijda, 1988).", "startOffset": 72, "endOffset": 129}, {"referenceID": 20, "context": "Psychologists have argued that some emotions are more basic than others (Ekman, 1992; Plutchik, 1980; Parrot, 2001; Frijda, 1988).", "startOffset": 72, "endOffset": 129}, {"referenceID": 19, "context": "Psychologists have argued that some emotions are more basic than others (Ekman, 1992; Plutchik, 1980; Parrot, 2001; Frijda, 1988).", "startOffset": 72, "endOffset": 129}, {"referenceID": 6, "context": "Psychologists have argued that some emotions are more basic than others (Ekman, 1992; Plutchik, 1980; Parrot, 2001; Frijda, 1988).", "startOffset": 72, "endOffset": 129}, {"referenceID": 20, "context": "These are the eight emotions considered to be most basic by (Plutchik, 1980).", "startOffset": 60, "endOffset": 76}, {"referenceID": 4, "context": "The eight emotions include the six emotions considered most basic by (Ekman, 1992), as well as trust and anticipation.", "startOffset": 69, "endOffset": 82}, {"referenceID": 21, "context": "There is a large body of work on creating valence or sentiment lexicons, including the General Inquirer (Stone et al., 1966), ANEW (Nielsen, 2011; Bradley and Lang, 1999), MPQA (Wiebe et al.", "startOffset": 104, "endOffset": 124}, {"referenceID": 17, "context": ", 1966), ANEW (Nielsen, 2011; Bradley and Lang, 1999), MPQA (Wiebe et al.", "startOffset": 14, "endOffset": 53}, {"referenceID": 0, "context": ", 1966), ANEW (Nielsen, 2011; Bradley and Lang, 1999), MPQA (Wiebe et al.", "startOffset": 14, "endOffset": 53}, {"referenceID": 25, "context": ", 1966), ANEW (Nielsen, 2011; Bradley and Lang, 1999), MPQA (Wiebe et al., 2005), and norms lexicon by Warriner et al.", "startOffset": 60, "endOffset": 80}, {"referenceID": 22, "context": "WordNet Affect Lexicon (Strapparava and Valitutti, 2004) has a few", "startOffset": 23, "endOffset": 56}, {"referenceID": 0, "context": ", 1966), ANEW (Nielsen, 2011; Bradley and Lang, 1999), MPQA (Wiebe et al., 2005), and norms lexicon by Warriner et al. (2013). The work on creating lexicons for categorical emotions such as joy, sadness, fear, etc, is comparatively small.", "startOffset": 30, "endOffset": 126}, {"referenceID": 10, "context": "Best-Worst Scaling (BWS) was developed by Louviere (1991), building on some groundbreaking research in the 1960s in mathematical psychology and psychophysics by Anthony A.", "startOffset": 42, "endOffset": 58}, {"referenceID": 8, "context": "Within the NLP community, BWS has thus far been used for creating datasets for relational similarity (Jurgens et al., 2012), word-sense disambiguation (Jurgens, 2013), and word\u2013sentiment intensity (Kiritchenko and Mohammad, 2016).", "startOffset": 101, "endOffset": 123}, {"referenceID": 7, "context": ", 2012), word-sense disambiguation (Jurgens, 2013), and word\u2013sentiment intensity (Kiritchenko and Mohammad, 2016).", "startOffset": 35, "endOffset": 50}, {"referenceID": 9, "context": ", 2012), word-sense disambiguation (Jurgens, 2013), and word\u2013sentiment intensity (Kiritchenko and Mohammad, 2016).", "startOffset": 81, "endOffset": 113}, {"referenceID": 1, "context": "Turney, 2013, 2010) included only those terms that occur frequently in the Google n-gram corpus (Brants and Franz, 2006), these terms satisfy the \u2018commonly used terms\u2019 criterion as well.", "startOffset": 96, "endOffset": 120}, {"referenceID": 12, "context": "tag Emotion Corpus (Mohammad, 2012), which is a large collection of tweets that each have at least one emotion-word hashtag.", "startOffset": 19, "endOffset": 35}, {"referenceID": 12, "context": "For each emotion, we included all terms in the Hashtag Emotion Corpus (Mohammad, 2012) that had a PMI > 1.", "startOffset": 70, "endOffset": 86}, {"referenceID": 9, "context": "We used the script provided by Kiritchenko and Mohammad (2016) to obtain the BWS annotations.", "startOffset": 31, "endOffset": 63}, {"referenceID": 9, "context": "We used the script provided by Kiritchenko and Mohammad (2016) to obtain the BWS annotations.8 Kiritchenko and Mohammad (2016) showed that using just three annotations per 4-tuple produces highly reliable results.", "startOffset": 31, "endOffset": 127}, {"referenceID": 18, "context": "The BWS responses were translated into scores by a simple calculation (Orme, 2009; Flynn and Marley, 2014): For each item, the score is the proportion of times the item was chosen as having the most intensity minus the proportion of times the item was chosen as having the least intensity.", "startOffset": 70, "endOffset": 106}, {"referenceID": 5, "context": "The BWS responses were translated into scores by a simple calculation (Orme, 2009; Flynn and Marley, 2014): For each item, the score is the proportion of times the item was chosen as having the most intensity minus the proportion of times the item was chosen as having the least intensity.", "startOffset": 70, "endOffset": 106}, {"referenceID": 12, "context": "Mohammad and Bravo-Marquez (2017) show its usefulness for automatically determining in intensity of emotion conveyed by tweets.", "startOffset": 0, "endOffset": 34}], "year": 2017, "abstractText": "Words often convey affect\u2014emotions, feelings, and attitudes. Lexicons of word\u2013 affect association have applications in automatic emotion analysis and natural language generation. However, existing lexicons indicate only coarse categories of affect association. Here, for the first time, we create an affect intensity lexicon with real-valued scores of association. We use a technique called best\u2013worst scaling that improves annotation consistency and obtains reliable fine-grained scores. The lexicon includes terms from general English as well as terms specific to social media communications. It has close to 6,000 entries for four basic emotions. We will be adding entries for other affect dimensions shortly.", "creator": "LaTeX with hyperref package"}}}