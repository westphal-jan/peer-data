{"id": "1705.02750", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-May-2017", "title": "Density Estimation for Geolocation via Convolutional Mixture Density Network", "abstract": "Nowadays, demographic sources related to Twitter no underdeveloped example, for - porous applications. However, the amount of geographic services convince - because sunday Twitter becomes low, more makes brought dominance still many input challenging. Under such exception, exceed the beyond of a tweet is 's is trick since the present. Unlike most last developed both estimate however pre - defined courthouse actually part k\u00f6ppen prepare, well study 1,900 giving probability available to than richer suggested fact the tweet, to number after location certainly is its argument. To realize make empirical, simply requiring the convolutional fresh cumulative network (CMDN ), form device explicit data to registered first fresh modeling parameters. Experimentally copy 2008 reveal so CMDN enjoyed be highest expectations show among that method because predicting the location variance. It also provides takes underlying form most the location arise for full tweet that properly primarily one extracting the trustworthy particular extrapolate.", "histories": [["v1", "Mon, 8 May 2017 05:50:47 GMT  (1957kb,D)", "http://arxiv.org/abs/1705.02750v1", "8 pages"]], "COMMENTS": "8 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["hayate iso", "shoko wakamiya", "eiji aramaki"], "accepted": false, "id": "1705.02750"}, "pdf": {"name": "1705.02750.pdf", "metadata": {"source": "CRF", "title": "Density Estimation for Geolocation via Convolutional Mixture Density Network", "authors": ["Hayate Iso", "Shoko Wakamiya", "Eiji Aramaki"], "emails": ["iso.hayate.id3@is.naist.jp", "wakamiya@is.naist.jp", "aramaki@is.naist.jp"], "sections": [{"heading": "1 Introduction", "text": "Geographic information related to Twitter enriches the availability of data resources. Such information is indispensable for various practical applications such as early earthquake detection (Sakaki et al., 2010), infectious disease dispersion assessment (Broniatowski et al., 2013), and regional user behavior assessment during an election period (Caldarelli et al., 2014). However the application performance depends strongly on the number of geo-tagged tweets, which account for fewer than 0.5 % of all tweets (Cheng et al., 2010).\nTo extend the possibilities of the geographic information, a great deal of effort has been devoted to specifying the geolocation automatically (Han et al., 2014). These studies are classified roughly into two aspects, the User level (Cheng et al., 2010; Han et al., 2014; Jurgens et al., 2015; Rahimi et al., 2015) and the Message level (Dredze et al., 2016; Liu and Huang, 2016; Priedhorsky et al., 2014) prediction. The former predicts the residential area. The latter one predicts the place that the user mentioned. This study targeted the latter problem, with message level prediction, involving the following three levels of difficulty.\nFirst, most tweets lack information to identify the true geolocation. In general, many tweets do not include geolocation identifiable words. Therefore, it is difficult even for humans to identify a geolocation (Figure 1b).\nNext, some location names involve ambiguity because a word refers to multiple locations. For example, places called \u201cPortland\u201d exist in several locations worldwide. Similarly, this ambiguity also arises within a single country, as shown in Figure 2. Although additional context words are necessary to identify the exact location, many tweets do not include such clue words for identifying the location. As for such tweet, the real-valued point estimation is expected to be degraded by regression towards the mean (Stigler, 1997).\nFinally, if a user states the word that represents the exact location, the user is not necessarily there. In case the user describes several places in the tweet, contextual comprehension of the tweet is needed to identify the true location (Figure 1c).\nIn contrast to most studies, this study was conducted to resolve these issues based on the density estimation approach. A salient benefit of density estimation is to enable comprehension of the uncertainty related to the tweet user location because it propagates from the estimated distribution and handles tweets distributed to multiple\nar X\niv :1\n70 5.\n02 75\n0v 1\n[ cs\n.C L\n] 8\nM ay\n2 01\n7\npoints properly. Figure 1 shows each estimated density as a heatmap. The estimated distribution is concentrated near the true location (Figure 1a) and vice versa (Figure 1b) if the tweet includes plenty of clues. Furthermore, the density-based approach can accommodate the representation of multiple output data, whereas the regression-based approach cannot (Figure 1c).\nThe density-based approach provides additional benefits for practical application. The estimated density appends the estimation reliability for each tweet as the likelihood value. For reliable estimation, the estimated density provides the high likelihood (Figure 1a and 1c) and vice versa (Figure 1b).\nTo realize this modeling, we propose a Convolutional Mixture Density Network (CMDN), a method for estimating the geolocation density estimation from text data. Actually, CMDN extracts valuable features using a convolutional neural network architecture and converts these features to mixture density parameters. Our experimentally obtained results reveal that not merely the high prediction performance, but also the reliability measure works properly for filtering out uncertain estimations."}, {"heading": "2 Related work", "text": "Social media geolocation has been undertaken on various platforms such as Facebook (Backstrom et al., 2010), Flickr (Serdyukov et al., 2009), and Wikipedia (Lieberman and Lin, 2009). Especially, Twitter geolocation is the predominant field among all of them because of its availability (Han et al., 2014).\nTwitter geolocation methods are not confined\nto text information. Diverse information can facilitate geolocation performance such as meta information (time (Dredze et al., 2016) and estimated age and gender (Pavalanathan and Eisenstein, 2015)), social network structures (Jurgens et al., 2015; Rahimi et al., 2015), and user movement (Liu and Huang, 2016). Many studies, however, have attempted user level geolocation, not the message level. Although the user level geolocation is certainly effective for some applications, message level geolocation supports fine-grained analyses.\nHowever, Priedhorsky et al. (2014) has attempted density estimation for message level geolocation by estimating a word-independent Gaussian Mixture Model and then combining them to derive each tweet density. Although the paper proposed many weight estimation methods, many of them depend strongly on locally distributed words. Our proposed method, CMDN, enables estimate of the geolocation density from the text sequence in the End-to-End manner and considers the marginal context of the tweet via CNN."}, {"heading": "3 Convolutional Neural Network for Regression (Unimodal output)", "text": "We start by introducing the convolutional neural network (Fukushima, 1980; LeCun et al., 1998) (CNN) for a regression problem, which directly estimates the real-valued output as our baseline method. Our regression formulation is almost identical to that of CNN for document classification based on Kim (2014). We merely remove the softmax layer and replace the loss function.\nWe assume that a tweet has length L (padded where necessary) and that wi represents the word\ni-th index. We project the words wi to vectors xi through an embedding matrix We, xi = Wewi \u2208 Rd, where d represents the size of the embeddings. We compose the sentence vector x1:L by concatenating the word vectors xi, as\nx1:L = x1 \u2295 x2 \u2295 \u00b7 \u00b7 \u00b7 \u2295 xL \u2208 RLd.\nIn that equation, \u2295 represents vector concatenation.\nTo extract valuable features from sentences, we apply filter matrix Wf for every part of the sentence vector with window size ` as\nWf = [wf,1,wf,2, . . . ,wf,m] >\nci,j = \u03c6(w > f,jxi:i+` + bf,j)\nwhere m stands for the number of feature maps, and \u03c6 represents the activation function. As described herein, we employ ReLU (Nair and Hinton, 2010) as the activation function.\nFor each filter\u2019s output, we apply 1-max pooling to extract the most probable window feature c\u0302j . Then we compose the abstracted feature vectors h by concatenating each pooled feature c\u0302j as shown below.\nc\u0302j = max i\u2208{1,...,L\u2212`+1} ci,j\nh = [c\u03021, c\u03022, . . . , c\u0302m] >\nFinally, we estimate the real value output y using the abstracted feature vector h as\ny\u0302 = Wrh + br \u2208 Rq\nwhere q signifies the output dimension, Wr \u2208 Rq\u00d7m, denotes the regression weight matrix, and br \u2208 Rq represent the bias vectors for regression.\nTo optimize the regression model, we use two loss functions between the true value y and estimated value y\u0302. One is `2-loss as\nN\u2211 n=1 \u2016yn \u2212 y\u0302n\u201622\nand another is robust loss function for outlier, `1- loss,\nN\u2211 n=1 \u2016yn \u2212 y\u0302n\u20161 = N\u2211 n=1 q\u2211 q\u2032=1 |yn,q\u2032 \u2212 y\u0302n,q\u2032 |\nwhere N represents the sample size. The `1- loss shrinks the outlier effects for estimation rather than the `2 one."}, {"heading": "4 Convolutional Mixture Density Network (Multimodal output)", "text": "In the previous section, we introduced the CNN method for regression problem. This regression formulation is good for addressing well-defined problems. Both the input and output have one-toone correspondence. Our tweet corpus is fundamentally unfulfilled with this assumption. Therefore, a more flexible model must be used to represent the richer information.\nIn this section, we propose a novel architecture for text to density estimation, Convolutional Mixture Density Network (CMDN), which is the extension of Mixture Density Network by Bishop (1994). In contrast to the regression approach that directly represents the output values y\u0302, CMDN can accommodate more complex information as the probability distribution. The CMDN estimates the parameters of Gaussian mixture model \u03c0k,\u00b5k,\u03a3k, where k is the k-th mixture component using the same abstracted features h in the CNN regression (Sec 3)."}, {"heading": "4.1 Parameter estimation by neural network", "text": "Presuming that density consists of K components of multivariate normal distribution N (y|\u00b5k,\u03a3k), then the number of each q-dimensional normal distribution parameters are p = q(q+3)2 (q parameters for each mean \u00b5k and diagonal values of the covariance matrix \u03a3k and q(q\u22121) 2 parameters for correlation parameters \u03c1) between dimension outputs.\nFor q = 2, each component of the parameters is represented as\n\u00b5k = ( \u00b5k,1 \u00b5k,2 ) ,\u03a3k = ( \u03c32k,1 \u03c1k\u03c3k,1\u03c3k,2 \u03c1k\u03c3k,1\u03c3k,2 \u03c3 2 k,2 ) .\nTo estimate these parameters, we first project the hidden layer h into the required number of parameters space \u03b8 as\n\u03b8 = Wph + bp \u2208 RKp,\nwhere Wp \u2208 RKp\u00d7m and bp \u2208 RKp respectively denote the weight matrix and bias vector.\nAlthough the parameter \u03b8 has a sufficient number of parameters to represent the K mixture model, these parameters are not optimal for insertion to the parameters of the multivariate normal distribution N (y|\u00b5k,\u03a3k), and its mixture weight \u03c0k.\nThe mixture weights \u03c0k must be positive values and must sum to 1. The variance parameters \u03c3 must be a positive real value. The correlation parameter \u03c1k must be (\u22121, 1). For this purpose, we transform real-valued outputs \u03b8 into the optimal range for each parameter of mixture density."}, {"heading": "4.2 Parameter conversion", "text": "For simplicity, we first decompose \u03b8 to each mixture parameter \u03b8k as\n\u03b8 = \u03b81 \u2295 \u03b82 \u2295 \u00b7 \u00b7 \u00b7 \u2295 \u03b8K \u03b8k = (\u03b8\u03c0k , \u03b8\u00b5k,1 , \u03b8\u00b5k,2 , \u03b8\u03c3k,1 , \u03b8\u03c3k,2 , \u03b8\u03c1k).\nTo restrict each parameter range, we convert each vanilla parameter \u03b8k as\n\u03c0k = softmax(\u03b8\u03c0k)\n= exp(\u03b8\u03c0k)\u2211K k\u2032=1 exp(\u03b8\u03c0\u2032k) \u2208 (0, 1)\n\u00b5k,j = \u03b8\u00b5k,j \u2208 R, \u03c3k,j = softplus(\u03b8\u03c3k,j )\n= ln ( 1 + exp(\u03b8\u03c3k,j ) ) \u2208 (0,\u221e),\n\u03c1k = softsign(\u03b8\u03c1k)\n= \u03b8\u03c1k\n1 + |\u03b8\u03c1k | \u2208 (\u22121, 1).\nThe original MDN paper (Bishop, 1994) and its well known application of MDN for handwriting generation (Graves, 2013) used an exponential function for transforming variance parameter\n\u03c3 and a hyperbolic tangent function for the correlation parameter \u03c1. However, we use softplus (Glorot et al., 2011) for variance and softsign (Glorot and Bengio, 2010) for correlation.\nReplacing the activation function in the output layer prevents these gradient problems. Actually, these gradient values are often exploded or nonexistent. Our proposed transformation is effective to achieve rapid convergence and stable learning."}, {"heading": "4.3 Loss function for parameter estimation", "text": "To optimize the mixture density model, we use negative log likelihood as the training loss:\n\u2212 N\u2211 n=1 ln ( K\u2211 k=1 \u03c0kN (yn|\u00b5k,\u03a3k) ) ."}, {"heading": "5 Experiments", "text": "In this section, we formalize our problem setting and clarify our proposed model effectiveness."}, {"heading": "5.1 Problem setting", "text": "This study explores CMDN performance from two perspectives.\nOur first experiment is to predict the geographic coordinates by which each user stated using the only single tweet content. We evaluate the mean and median value of distances measured using Vincenty\u2019s formula (Vincenty, 1975) between the estimated and true geographic coordinates for the overall dataset.\nThe second experiment is used to filter out the unreliable estimation quantitatively using the likelihood-based threshold. Each estimated density assigns the likelihood value for every point of the location. We designate the likelihood values as reliability indicators for the respective estimated locations. Then, we remove the estimation from the lowest likelihood value and calculate both the mean and median values. This indicator is filtered correctly out the unreliable estimations if the statistics decrease monotonically.\nLocation estimation by estimated density In contrast to the regression approach, it is necessary to specify the estimation point from the estimated density of each tweet. In accordance with Bishop (1994), we employ the mode value of estimated density as the estimated location y\u0302. The mode value of the probability distribution can be found by numerical optimization, but it requires\noverly high costs for scalable estimation. For a simple and scalable approximation for seeking the mode value of the estimated density, we restrict the search space to each mean value of the mixture components as shown below:\ny\u0302 = argmax y\u2208{\u00b51,...,\u00b5K} K\u2211 k=1 \u03c0kN (y|\u00b5k,\u03a3k)."}, {"heading": "5.2 Dataset", "text": "Our tweet corpus consists of 24,633,478 Japanese tweets posted from July 14, 2011 to July 31, 2012. Our corpus statistics are presented in Table 1. We split our corpus randomly into training for 20M tweets, development for 2M, and test for 2M."}, {"heading": "5.3 Comparative models", "text": "We compare our proposed model effectiveness by controlling experiment procedures, which replace the model components one-by-one. We also provide simple baseline performance. The following model configurations are presented in Table 2.\nMean: Mean value of the training data locations.\nMedian: Median value of the training data locations.\nEnet: Elastic Net regression (Zou and Hastie, 2005), which consists of ordinary least squares regression with `2, `1-regularization.\nMLP-l2: Multi Layer Perceptron with `2-loss (Minsky and Papert, 1969)\nMLP-l1: Multi Layer Perceptron with `1-loss. CNN-l2: Convolutional Neural Network for regression with `2-loss based on Kim (2014) CNN-l1: Convolutional Neural Network for regression with `1-loss. MDN: Mode value of Mixture Density Network (Bishop, 1994) CMDN: Mode value of Convolutional Mixture Density Network (Proposed)"}, {"heading": "5.4 Results", "text": ""}, {"heading": "5.4.1 Geolocation performance", "text": "The experimental geolocation performance results are presented in Table 3.\nOverall results show that our proposed model CMDN provides the lowest median error distance: CNN-l1 is the lowest mean error distance. Also, CMDN gives similar mean error distances to those of CNN-l1. Both CMDN and CNN-l1 outperform all others in comparative models.\nIn addition to the results obtained for the feature extraction part, the CNN-based model consistently achieved better prediction performance than the vanilla MLP-based model measured by both the mean and median."}, {"heading": "5.4.2 Likelihood based threshold", "text": "We show how the likelihood-based threshold affects both mean and median statistics in Figure 3. The likelihood-based threshold consistently decreases both statistics in proportion to the likelihood lower bound increases. Especially, these statistics dramatically decrease when the likelihood is between 101 and 102. Several likelihood bounds results are presented in Figure 4. Although\nthe model mistakenly estimates many incorrect predictions for the overall dataset (blue), the likelihood base threshold correctly prunes the outlier estimations."}, {"heading": "6 Discussion", "text": "Our proposed model provides high accuracy for our experimental data. Moreover, likelihoodbased thresholds reveal a consistent indicator of estimation certainty. In this section, we further explore the properties of the CMDN from the viewpoint of difference of the loss function.\nLoss function difference\nWe compare the CNN-based model with different loss functions, `2, `1-loss for regression CNN-l2, CNN-l1 and negative log-likelihood for mixture density model CMDN. The output distance distributions are shown in Figure 5.\nAlthough `2-loss denotes the worst performance measured by mean and median among CNN-based models (Table 3), it represents the lowest outlier ratio. Consequently, the `2-loss is the most conservative estimate for our skewed corpus.\nWe can infer that the difference between the competitive model CNN-l1 and our proposed model CMDN is their estimation aggressiveness. The median of CMDN is remarkably lower than of CNN-l1, but the mean of CMDN is slightly larger than that of CNN-l1. The reason for these phenomena is the difference of the loss functions behavior for multiple candidate data. Even though the `1-loss function is robust to outliers, the estimation deteriorates when the candidates appear with similar possibilities. In contrast, CMDN can accommodate multiple candidates as multiple mixture components. Therefore, CMDN imposes the appropriate probabilities for several candidates and picks up the most probable point as the prediction. In short, CMDN\u2019s predictions become more aggressive than CNN-l1\u2019s. Consequently, CMDN\u2019s median value becomes lower than CNNl1\u2019s.\nAn important shortcoming of aggressive prediction is that the estimation deteriorates when the estimation fails. The mean value tends to be affected strongly by the outlier estimation. Therefore, CMDN\u2019s mean value becomes higher than that of CNN-l1\u2019s.\nHowever, CMDN can overcome this shortcoming using a likelihood-based threshold, which first filters out the outlier. Therefore, we conclude that the negative log-likelihood for mixture density is better than those of other loss functions `2 and `1- loss for the regression."}, {"heading": "7 Future work", "text": "This study assessed the performance of our proposed model, CMDN, using text data alone. Although text-only estimation is readily applicable to existing resources, we still have room for improvement of the prediction performance. The winner of the Twitter Geolocation Prediction\nShared Task, Miura et al. (2016), proposed that the unified architecture handle several meta-data such as the user location, user description, and time zone for predicting geolocations. The CMDN can integrate this information in the same manner.\nFurthermore, Liu and Huang (2016) reports that the user home location strongly affects location prediction for a single tweet. For example, a routine tweet is fundamentally unpredictable using text contents alone, but if the user home location is known, this information is a valuable indication for evaluating the tweet. As future work, we plan to develop a unified architecture that incorporates user movement information using a recurrent neural network.\nIn contrast, our objective function might be no longer useful for world scale geolocation because ours approximates the spherical coordinates into the real coordinate space. This approximation error tends to become larger for the larger scale geolocation inference. We will explore our method\u2019s geolocation performance using the world scale geolocation dataset such as W-NUT data (Han et al., 2016)."}, {"heading": "8 Conclusion", "text": "This study clarified the capabilities of the density estimation approach to Twitter geolocation. Our proposed model, CMDN, performed not only with high accuracy for our experimental data; it also extracted reliable geolocated tweets using likelihood-based thresholds. Results show that CMDN merely requires the tweet message contents to identify its geolocation, while obviating\npreparation of meta-information. Consequently, CMDN can contribute to extension of the fields in which geographic information application can be used."}], "references": [{"title": "Find me if you can: improving geographical prediction with social and spatial proximity", "author": ["Lars Backstrom", "Eric Sun", "Cameron Marlow."], "venue": "Proceedings of the 19th international conference on World wide web. ACM, pages 61\u201370.", "citeRegEx": "Backstrom et al\\.,? 2010", "shortCiteRegEx": "Backstrom et al\\.", "year": 2010}, {"title": "Mixture density networks", "author": ["Christopher Bishop."], "venue": "Technical report.", "citeRegEx": "Bishop.,? 1994", "shortCiteRegEx": "Bishop.", "year": 1994}, {"title": "National and local influenza surveillance through twitter: An analysis of the 20122013 influenza epidemic", "author": ["David A. Broniatowski", "Michael J. Paul", "Mark Dredze."], "venue": "PLoS ONE 8(12). https://doi.org/10.1371/journal.pone.0083672.", "citeRegEx": "Broniatowski et al\\.,? 2013", "shortCiteRegEx": "Broniatowski et al\\.", "year": 2013}, {"title": "A multilevel geographical study of italian political elections from twitter data", "author": ["Guido Caldarelli", "Alessandro Chessa", "Fabio Pammolli", "Gabriele Pompa", "Michelangelo Puliga", "Massimo Riccaboni", "Gianni Riotta."], "venue": "PLoS ONE 9(5):1\u201311.", "citeRegEx": "Caldarelli et al\\.,? 2014", "shortCiteRegEx": "Caldarelli et al\\.", "year": 2014}, {"title": "You are where you tweet: A content-based approach to geo-locating twitter users", "author": ["Zhiyuan Cheng", "James Caverlee", "Kyumin Lee."], "venue": "Proceedings of the 19th ACM International Conference on Information and Knowledge Management. ACM,", "citeRegEx": "Cheng et al\\.,? 2010", "shortCiteRegEx": "Cheng et al\\.", "year": 2010}, {"title": "Geolocation for twitter: Timing matters", "author": ["Mark Dredze", "Miles Osborne", "Prabhanjan Kambadur."], "venue": "North American Chapter of the Association for Computational Linguistics (NAACL).", "citeRegEx": "Dredze et al\\.,? 2016", "shortCiteRegEx": "Dredze et al\\.", "year": 2016}, {"title": "Bootstrap methods: Another look at the jackknife", "author": ["B Efron."], "venue": "The Annals of Statistics pages 1\u201326.", "citeRegEx": "Efron.,? 1979", "shortCiteRegEx": "Efron.", "year": 1979}, {"title": "Neocognitron: A selforganizing neural network model for a mechanism of pattern recognition unaffected by shift in position", "author": ["Kunihiko Fukushima."], "venue": "Biological cybernetics 36(4):193\u2013202.", "citeRegEx": "Fukushima.,? 1980", "shortCiteRegEx": "Fukushima.", "year": 1980}, {"title": "Understanding the difficulty of training deep feedforward neural networks", "author": ["Xavier Glorot", "Yoshua Bengio."], "venue": "Aistats. volume 9, pages 249\u2013256.", "citeRegEx": "Glorot and Bengio.,? 2010", "shortCiteRegEx": "Glorot and Bengio.", "year": 2010}, {"title": "Deep sparse rectifier neural networks", "author": ["Xavier Glorot", "Antoine Bordes", "Yoshua Bengio."], "venue": "Aistats. volume 15, page 275.", "citeRegEx": "Glorot et al\\.,? 2011", "shortCiteRegEx": "Glorot et al\\.", "year": 2011}, {"title": "Generating sequences with recurrent neural networks", "author": ["Alex Graves."], "venue": "arXiv preprint arXiv:1308.0850 .", "citeRegEx": "Graves.,? 2013", "shortCiteRegEx": "Graves.", "year": 2013}, {"title": "Textbased twitter user geolocation prediction", "author": ["Bo Han", "Paul Cook", "Timothy Baldwin."], "venue": "Journal of Artificial Intelligence Research 49:451\u2013500. https://doi.org/10.1613/jair.4200.", "citeRegEx": "Han et al\\.,? 2014", "shortCiteRegEx": "Han et al\\.", "year": 2014}, {"title": "Twitter geolocation prediction shared task of the 2016 workshop on noisy user-generated text", "author": ["Bo Han", "AI Hugo", "Afshin Rahimi", "Leon Derczynski", "Timothy Baldwin."], "venue": "WNUT 2016 page 213.", "citeRegEx": "Han et al\\.,? 2016", "shortCiteRegEx": "Han et al\\.", "year": 2016}, {"title": "Geolocation prediction in twitter using social networks: A critical analysis and review of current practice", "author": ["David Jurgens", "Tyler Finethy", "James McCorriston", "Yi Tian Xu", "Derek Ruths."], "venue": "ICWSM. pages 188\u2013197.", "citeRegEx": "Jurgens et al\\.,? 2015", "shortCiteRegEx": "Jurgens et al\\.", "year": 2015}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics, Doha, Qatar, pages 1746\u2013", "citeRegEx": "Kim.,? 2014", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba."], "venue": "arXiv preprint arXiv:1412.6980 .", "citeRegEx": "Kingma and Ba.,? 2014", "shortCiteRegEx": "Kingma and Ba.", "year": 2014}, {"title": "Gradient-based learning applied to document recognition", "author": ["Yann LeCun", "L\u00e9on Bottou", "Yoshua Bengio", "Patrick Haffner."], "venue": "Proceedings of the IEEE 86(11):2278\u20132324.", "citeRegEx": "LeCun et al\\.,? 1998", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "You are where you edit: Locating wikipedia contributors through edit histories", "author": ["Michael D Lieberman", "Jimmy J Lin."], "venue": "ICWSM.", "citeRegEx": "Lieberman and Lin.,? 2009", "shortCiteRegEx": "Lieberman and Lin.", "year": 2009}, {"title": "Where are you tweeting?: A context and user movement based approach", "author": ["Zhi Liu", "Yan Huang."], "venue": "Proceedings of the 25th ACM International on Conference on Information and Knowledge Management. ACM, New", "citeRegEx": "Liu and Huang.,? 2016", "shortCiteRegEx": "Liu and Huang.", "year": 2016}, {"title": "Perceptrons: An Introduction to Computational Geometry", "author": ["Marvin Minsky", "Seymour Papert."], "venue": "MIT Press, Cambridge, MA, USA.", "citeRegEx": "Minsky and Papert.,? 1969", "shortCiteRegEx": "Minsky and Papert.", "year": 1969}, {"title": "A simple scalable neural networks based model for geolocation prediction in twitter", "author": ["Yasuhide Miura", "Motoki Taniguchi", "Tomoki Taniguchi", "Tomoko Ohkuma."], "venue": "WNUT 2016 9026924:235.", "citeRegEx": "Miura et al\\.,? 2016", "shortCiteRegEx": "Miura et al\\.", "year": 2016}, {"title": "Rectified linear units improve restricted boltzmann machines", "author": ["Vinod Nair", "Geoffrey E Hinton."], "venue": "Proceedings of the 27th international conference on machine learning (ICML-10). pages 807\u2013814.", "citeRegEx": "Nair and Hinton.,? 2010", "shortCiteRegEx": "Nair and Hinton.", "year": 2010}, {"title": "Confounds and consequences in geotagged twitter data", "author": ["Umashanthi Pavalanathan", "Jacob Eisenstein."], "venue": "Proceedings of Empirical Methods for Natural Language Processing (EMNLP). http://www.aclweb.org/anthology/D/D15/D15-", "citeRegEx": "Pavalanathan and Eisenstein.,? 2015", "shortCiteRegEx": "Pavalanathan and Eisenstein.", "year": 2015}, {"title": "Inferring the origin locations of tweets with quantitative confidence", "author": ["Reid Priedhorsky", "Aron Culotta", "Sara Y Del Valle."], "venue": "Proceedings of the 17th ACM conference on Computer supported cooperative work & social computing. ACM, pages 1523\u2013", "citeRegEx": "Priedhorsky et al\\.,? 2014", "shortCiteRegEx": "Priedhorsky et al\\.", "year": 2014}, {"title": "Exploiting text and network context for geolocation of social media users", "author": ["Afshin Rahimi", "Duy Vu", "Trevor Cohn", "Timothy Baldwin."], "venue": "Proceedings of the 2015 Conference of the North American Chapter of the Associa-", "citeRegEx": "Rahimi et al\\.,? 2015", "shortCiteRegEx": "Rahimi et al\\.", "year": 2015}, {"title": "Earthquake shakes twitter users: Real-time event detection by social sensors", "author": ["Takeshi Sakaki", "Makoto Okazaki", "Yutaka Matsuo."], "venue": "Proceedings of the 19th International Conference on World Wide Web. ACM, New", "citeRegEx": "Sakaki et al\\.,? 2010", "shortCiteRegEx": "Sakaki et al\\.", "year": 2010}, {"title": "Placing flickr photos on a map", "author": ["Pavel Serdyukov", "Vanessa Murdock", "Roelof Van Zwol."], "venue": "Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval. ACM, pages 484\u2013491.", "citeRegEx": "Serdyukov et al\\.,? 2009", "shortCiteRegEx": "Serdyukov et al\\.", "year": 2009}, {"title": "Dropout: a simple way to prevent neural networks from overfitting", "author": ["Nitish Srivastava", "Geoffrey E Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov."], "venue": "Journal of Machine Learning Research 15(1):1929\u20131958.", "citeRegEx": "Srivastava et al\\.,? 2014", "shortCiteRegEx": "Srivastava et al\\.", "year": 2014}, {"title": "Regression towards the mean, historically considered", "author": ["Stephen M Stigler."], "venue": "Statistical methods in medical research 6(2):103\u2013114.", "citeRegEx": "Stigler.,? 1997", "shortCiteRegEx": "Stigler.", "year": 1997}, {"title": "Direct and inverse solutions of geodesics on the ellipsoid with application of nested equations", "author": ["Thaddeus Vincenty."], "venue": "Survey review 23(176):88\u201393.", "citeRegEx": "Vincenty.,? 1975", "shortCiteRegEx": "Vincenty.", "year": 1975}, {"title": "Regularization and variable selection via the elastic net", "author": ["Hui Zou", "Trevor Hastie."], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology) 67(2):301\u2013320.", "citeRegEx": "Zou and Hastie.,? 2005", "shortCiteRegEx": "Zou and Hastie.", "year": 2005}], "referenceMentions": [{"referenceID": 25, "context": "Such information is indispensable for various practical applications such as early earthquake detection (Sakaki et al., 2010), infectious disease dispersion assessment (Broniatowski et al.", "startOffset": 104, "endOffset": 125}, {"referenceID": 2, "context": ", 2010), infectious disease dispersion assessment (Broniatowski et al., 2013), and regional user behavior assessment during an election period (Caldarelli et al.", "startOffset": 50, "endOffset": 77}, {"referenceID": 3, "context": ", 2013), and regional user behavior assessment during an election period (Caldarelli et al., 2014).", "startOffset": 73, "endOffset": 98}, {"referenceID": 4, "context": "5 % of all tweets (Cheng et al., 2010).", "startOffset": 18, "endOffset": 38}, {"referenceID": 11, "context": "To extend the possibilities of the geographic information, a great deal of effort has been devoted to specifying the geolocation automatically (Han et al., 2014).", "startOffset": 143, "endOffset": 161}, {"referenceID": 4, "context": "These studies are classified roughly into two aspects, the User level (Cheng et al., 2010; Han et al., 2014; Jurgens et al., 2015; Rahimi et al., 2015) and the Message level (Dredze et al.", "startOffset": 70, "endOffset": 151}, {"referenceID": 11, "context": "These studies are classified roughly into two aspects, the User level (Cheng et al., 2010; Han et al., 2014; Jurgens et al., 2015; Rahimi et al., 2015) and the Message level (Dredze et al.", "startOffset": 70, "endOffset": 151}, {"referenceID": 13, "context": "These studies are classified roughly into two aspects, the User level (Cheng et al., 2010; Han et al., 2014; Jurgens et al., 2015; Rahimi et al., 2015) and the Message level (Dredze et al.", "startOffset": 70, "endOffset": 151}, {"referenceID": 24, "context": "These studies are classified roughly into two aspects, the User level (Cheng et al., 2010; Han et al., 2014; Jurgens et al., 2015; Rahimi et al., 2015) and the Message level (Dredze et al.", "startOffset": 70, "endOffset": 151}, {"referenceID": 5, "context": ", 2015) and the Message level (Dredze et al., 2016; Liu and Huang, 2016; Priedhorsky et al., 2014) prediction.", "startOffset": 30, "endOffset": 98}, {"referenceID": 18, "context": ", 2015) and the Message level (Dredze et al., 2016; Liu and Huang, 2016; Priedhorsky et al., 2014) prediction.", "startOffset": 30, "endOffset": 98}, {"referenceID": 23, "context": ", 2015) and the Message level (Dredze et al., 2016; Liu and Huang, 2016; Priedhorsky et al., 2014) prediction.", "startOffset": 30, "endOffset": 98}, {"referenceID": 28, "context": "As for such tweet, the real-valued point estimation is expected to be degraded by regression towards the mean (Stigler, 1997).", "startOffset": 110, "endOffset": 125}, {"referenceID": 0, "context": "Social media geolocation has been undertaken on various platforms such as Facebook (Backstrom et al., 2010), Flickr (Serdyukov et al.", "startOffset": 83, "endOffset": 107}, {"referenceID": 26, "context": ", 2010), Flickr (Serdyukov et al., 2009), and Wikipedia (Lieberman and Lin, 2009).", "startOffset": 16, "endOffset": 40}, {"referenceID": 17, "context": ", 2009), and Wikipedia (Lieberman and Lin, 2009).", "startOffset": 23, "endOffset": 48}, {"referenceID": 11, "context": "Especially, Twitter geolocation is the predominant field among all of them because of its availability (Han et al., 2014).", "startOffset": 103, "endOffset": 121}, {"referenceID": 5, "context": "Diverse information can facilitate geolocation performance such as meta information (time (Dredze et al., 2016) and estimated age and gender (Pavalanathan and Eisenstein, 2015)), social network structures (Jurgens et al.", "startOffset": 90, "endOffset": 111}, {"referenceID": 22, "context": ", 2016) and estimated age and gender (Pavalanathan and Eisenstein, 2015)), social network structures (Jurgens et al.", "startOffset": 37, "endOffset": 72}, {"referenceID": 13, "context": ", 2016) and estimated age and gender (Pavalanathan and Eisenstein, 2015)), social network structures (Jurgens et al., 2015; Rahimi et al., 2015), and user movement (Liu and Huang, 2016).", "startOffset": 101, "endOffset": 144}, {"referenceID": 24, "context": ", 2016) and estimated age and gender (Pavalanathan and Eisenstein, 2015)), social network structures (Jurgens et al., 2015; Rahimi et al., 2015), and user movement (Liu and Huang, 2016).", "startOffset": 101, "endOffset": 144}, {"referenceID": 18, "context": ", 2015), and user movement (Liu and Huang, 2016).", "startOffset": 27, "endOffset": 48}, {"referenceID": 23, "context": "However, Priedhorsky et al. (2014) has attempted density estimation for message level geolocation by estimating a word-independent Gaussian Mixture Model and then combining them to derive each tweet density.", "startOffset": 9, "endOffset": 35}, {"referenceID": 7, "context": "We start by introducing the convolutional neural network (Fukushima, 1980; LeCun et al., 1998) (CNN) for a regression problem, which directly estimates the real-valued output as our baseline method.", "startOffset": 57, "endOffset": 94}, {"referenceID": 16, "context": "We start by introducing the convolutional neural network (Fukushima, 1980; LeCun et al., 1998) (CNN) for a regression problem, which directly estimates the real-valued output as our baseline method.", "startOffset": 57, "endOffset": 94}, {"referenceID": 7, "context": "We start by introducing the convolutional neural network (Fukushima, 1980; LeCun et al., 1998) (CNN) for a regression problem, which directly estimates the real-valued output as our baseline method. Our regression formulation is almost identical to that of CNN for document classification based on Kim (2014). We merely remove the softmax layer and replace the loss function.", "startOffset": 58, "endOffset": 309}, {"referenceID": 21, "context": "As described herein, we employ ReLU (Nair and Hinton, 2010) as the activation function.", "startOffset": 36, "endOffset": 59}, {"referenceID": 1, "context": "In this section, we propose a novel architecture for text to density estimation, Convolutional Mixture Density Network (CMDN), which is the extension of Mixture Density Network by Bishop (1994). In contrast to the regression approach that directly represents the output values \u0177, CMDN can accommodate more complex information as the probability distribution.", "startOffset": 180, "endOffset": 194}, {"referenceID": 1, "context": "The original MDN paper (Bishop, 1994) and its well known application of MDN for handwriting generation (Graves, 2013) used an exponential function for transforming variance parameter \u03c3 and a hyperbolic tangent function for the correlation parameter \u03c1.", "startOffset": 23, "endOffset": 37}, {"referenceID": 10, "context": "The original MDN paper (Bishop, 1994) and its well known application of MDN for handwriting generation (Graves, 2013) used an exponential function for transforming variance parameter \u03c3 and a hyperbolic tangent function for the correlation parameter \u03c1.", "startOffset": 103, "endOffset": 117}, {"referenceID": 9, "context": "However, we use softplus (Glorot et al., 2011) for variance and softsign (Glorot and Bengio, 2010) for correlation.", "startOffset": 25, "endOffset": 46}, {"referenceID": 8, "context": ", 2011) for variance and softsign (Glorot and Bengio, 2010) for correlation.", "startOffset": 34, "endOffset": 59}, {"referenceID": 29, "context": "We evaluate the mean and median value of distances measured using Vincenty\u2019s formula (Vincenty, 1975) between the estimated and true geographic coordinates for the overall dataset.", "startOffset": 85, "endOffset": 101}, {"referenceID": 1, "context": "In accordance with Bishop (1994), we employ the mode value of estimated density as the estimated location \u0177.", "startOffset": 19, "endOffset": 33}, {"referenceID": 30, "context": "Enet: Elastic Net regression (Zou and Hastie, 2005), which consists of ordinary least squares regression with `2, `1-regularization.", "startOffset": 29, "endOffset": 51}, {"referenceID": 19, "context": "MLP-l2: Multi Layer Perceptron with `2-loss (Minsky and Papert, 1969)", "startOffset": 44, "endOffset": 69}, {"referenceID": 1, "context": "MDN: Mode value of Mixture Density Network (Bishop, 1994)", "startOffset": 43, "endOffset": 57}, {"referenceID": 13, "context": "CNN-l2: Convolutional Neural Network for regression with `2-loss based on Kim (2014) CNN-l1: Convolutional Neural Network for regression with `1-loss.", "startOffset": 74, "endOffset": 85}, {"referenceID": 6, "context": "The standard deviations of both the mean and median are calculated using Bootstrap methods (Efron, 1979).", "startOffset": 91, "endOffset": 104}, {"referenceID": 12, "context": "We will explore our method\u2019s geolocation performance using the world scale geolocation dataset such as W-NUT data (Han et al., 2016).", "startOffset": 114, "endOffset": 132}, {"referenceID": 17, "context": "Shared Task, Miura et al. (2016), proposed that the unified architecture handle several meta-data such as the user location, user description, and time zone for predicting geolocations.", "startOffset": 13, "endOffset": 33}, {"referenceID": 16, "context": "Furthermore, Liu and Huang (2016) reports that the user home location strongly affects location prediction for a single tweet.", "startOffset": 13, "endOffset": 34}], "year": 2017, "abstractText": "Nowadays, geographic information related to Twitter is crucially important for fine-grained applications. However, the amount of geographic information available on Twitter is low, which makes the pursuit of many applications challenging. Under such circumstances, estimating the location of a tweet is an important goal of the study. Unlike most previous studies that estimate the pre-defined district as the classification task, this study employs a probability distribution to represent richer information of the tweet, not only the location but also its ambiguity. To realize this modeling, we propose the convolutional mixture density network (CMDN), which uses text data to estimate the mixture model parameters. Experimentally obtained results reveal that CMDN achieved the highest prediction performance among the method for predicting the exact coordinates. It also provides a quantitative representation of the location ambiguity for each tweet that properly works for extracting the reliable location estimations.", "creator": "LaTeX with hyperref package"}}}