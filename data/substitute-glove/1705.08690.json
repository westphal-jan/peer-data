{"id": "1705.08690", "review": {"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-May-2017", "title": "Continual Learning with Deep Generative Replay", "abstract": "Attempts on train a focuses humans official fast of issues multiple tasks make been severely seen a sufferers problem called consequences messed. Although everything videoed most however data alleviates the what, done applies large unique many even seriously, fact heuristically only real world hardware turn their allows take past data it limited. Inspired meanwhile the computational culture some lesion as its longer - particular drives requires in shinto brain, no repeal later Deep Generative Replay, a episode framework taking entire cooperative element model curriculum consisting of kind broken paradigms changed (\" ignition \") turn his task technological model (\" solver \" ). With only these and systems, tactical data addition previous difficulties can easily be formatted and interleaved which those new entire introduced possible. We failed our methods in several sequential useful custom involving view level matters.", "histories": [["v1", "Wed, 24 May 2017 10:37:38 GMT  (6160kb,D)", "http://arxiv.org/abs/1705.08690v1", "Submitted to NIPS 2017"], ["v2", "Sat, 9 Sep 2017 15:31:38 GMT  (6160kb,D)", "http://arxiv.org/abs/1705.08690v2", "To appear in NIPS 2017"]], "COMMENTS": "Submitted to NIPS 2017", "reviews": [], "SUBJECTS": "cs.AI cs.CV cs.LG", "authors": ["hanul shin", "jung kwon lee", "jaehong kim", "jiwon kim"], "accepted": true, "id": "1705.08690"}, "pdf": {"name": "1705.08690.pdf", "metadata": {"source": "CRF", "title": "Continual Learning with Deep Generative Replay", "authors": ["Hanul Shin", "Jung Kwon Lee", "Jaehong Kim", "Jiwon Kim"], "emails": ["skyshin@mit.edu", "xhark@sktbrain.com", "jklee@sktbrain.com", "jk@sktbrain.com"], "sections": [{"heading": "1 Introduction", "text": "One distinctive ability of humans and large primates is to continually learn new skills and accumulate knowledge throughout the lifetime [6]. Even in small vertebrates such as rodents, established connections between neurons seem to last more than an year [13]. Besides, primates incorporate new information and expand their cognitive abilities without seriously perturbing past memories. The flexible memory system results from a good balance between synaptic plasticity and stability [1].\nContinual learning in deep neural networks, however, suffers from a phenomenon called catastrophic forgetting [21], in which the performance of a model on previously learned tasks abruptly degrades when trained for a new task. In artificial neural networks, inputs are coincided with the outputs by implicit parametric representation. Therefore training them towards a new objective can cause almost complete forgetting of former knowledge. Such problem has been a key obstacle to continual learning for deep neural network through sequential training on multiple tasks.\nPrevious attempts to alleviate catastrophic forgetting often relied on episodic memory system that stores past data [29]. In particular, recorded examples are regularly replayed with real samples drawn from the new task, and the network parameters are jointly optimized. While a network trained in this manner performs as well as separate networks trained solely on each task [27], a major drawback of memory-based approach is that it requires large working memory to store and replay past inputs. Moreover, such data storage and replay may not be viable in some real-world situations.\nNotably, humans and large primates learn new knowledge even from limited experience and still retain past memories. While several biological mechanisms contribute to this at different levels, primate brain\u2019s the most apparent distinction from artificial neural networks is the existence of separate, interacting memory systems [24]. The Complementary Learning Systems (CLS) theory illustrates the significance of dual memory systems involving the hippocampus and the neocortex. The hippocampal system acts as a short-term memory that encodes recent experiences and passes them to the neocortex, a lifelong memory storage. Here, the memory is consolidated through multiple replays of earlier\n\u2217Equal Contribution\nar X\niv :1\n70 5.\n08 69\n0v 1\n[ cs\n.A I]\n2 4\nM ay\n2 01\nexperiences stored in the hippocampus [25]\u2013a mechanism which inspired the use of experience replay [22] in training deep reinforcement learning agents.\nRecent evidences suggest that the hippocampus is more than a simple experience replay buffer. Rather, it regenerates earlier inputs by synchronized reactivations that are induced during unconscious or conscious recall or specific phase of sleep [8]. Stimulation of certain memory traces in the hippocampus can even create false memory that was never experienced [26]. These properties suggest that the hippocampus is better paralleled with a generative model than a replay buffer. Specifically, deep generative models such as deep Boltzmann machines [30] or a variational autoencoder [17] can generate high-dimensional samples that closely match observed inputs.\nWe now propose an alternative approach to sequentially train deep neural networks without referring to past data. In our deep generative replay framework, the model retains previously acquired knowledge by the concurrent replay of generated pseudo-data. In particular, we train a deep generative model in the generative adversarial networks (GANs) framework [10] to mimic past data. Generated data are then paired with corresponding response from a copy of the past task solver to represent old tasks. Called the scholar model, the generator-solver pair can produce fake data and desired target pairs as much as needed, and when presented with a new task, these produced pairs are interleaved with new data to update the generator and solver networks. Thus, a scholar model can both learn the new task without forgetting its own knowledge and teach other models with generated input-target pairs, even when the network configuration is different.\nAs deep generative replay supported by the scholar network retains the knowledge without revisiting actual past data, this framework can be employed to various practical situation involving privacy issues. Recent advances on training generative adversarial networks suggest that the trained models can reconstruct real data distribution in a wide range of domains. Although we tested our models on image classification tasks, our model can be applied to any task as long as the trained generator reliably reproduces the input space."}, {"heading": "2 Related Works", "text": "The term catastrophic forgetting or catastrophic interference was first introduced by McCloskey and Cohen in 1980\u2019s [21]. They claimed that catastrophic interference is a fundamental limitation of neural networks and a downside of its high generalization ability. While the cause of catastrophic forgetting has not been studied analytically, it is known that the neural networks parameterize the internal features of inputs, and training the networks on new samples causes alteration in already established representations. Several works illustrate empirical consequences in sequential learning settings [7, 27], and provide a few primitive solutions [16, 28] such as replaying all previous data."}, {"heading": "2.1 Comparable methods", "text": "A branch of works assumes a particular situation where access to data is limited to the current task. These works focus on optimizing network parameters while minimizing alterations to already consolidated weights. It is suggested that regularization methods such as dropout [31] and L2 regularization help reduce interference of new learning [12]. Furthermore, elastic weight consolidation (EWC) proposed in [18] demonstrates that protecting certain weights based on their importance to the previous tasks tempers the performance loss.\nOther attempts to sequentially train a deep neural network capable of solving multiple tasks reduce catastrophic interference by augmenting the networks with task-specific parameters. In general, layers close to inputs are shared to capture universal features, and independent output layers produce taskspecific outputs. Although separate output layers are free of interference, alteration on earlier layers still cause some performance loss on older tasks. Lowering learning rates on some parameters is also known to reduce forgetting [9]. A recently proposed method called Learning without Forgetting (LwF) [20] addresses the problem of sequential learning in image classification tasks while minimizing alteration on shared network parameters. In this framework, the network\u2019s response to new task input prior to fine-tuning indirectly represents knowledge about old tasks and is maintained throughout the learning process."}, {"heading": "2.2 Complementary Learning System(CLS) theory", "text": "A handful of works are devoted to designing a complementary networks architecture to resist catastrophic forgetting. When the training data for previous tasks are not accessible, only pseudoinputs and pseudo-targets produced by a memory network can be fed into the task network. Called a pseudorehearsal technique, this method is claimed to maintain old input-output patterns without accessing real data [29]. When the tasks are as elementary as coupling two binary patterns, simply feeding random noises and corresponding responses suffices [2]. A more recent work proposes an architecture that resembles the structure of the hippocampus to facilitate continual learning for more complex data such as small binary pixel images [15]. However, none of them demonstrates scalability to high-dimensional inputs similar to those appear in real world due to the difficulty of generating meaningful high-dimensional pseudoinputs without further supervision.\nOur generative replay framework differs from aforementioned pseudorehearsal techniques in that the fake inputs are generated from learned past input distribution. Generative replay has several advantages over other approaches because the network is jointly optimized using an ensemble of generated past data and real current data. The performance is therefore equivalent to joint training on accumulated real data as long as the generator recovers the input distribution."}, {"heading": "2.3 Deep Generative Models", "text": "Generative model refers to any model that generates observable samples. Specifically, we consider deep generative models based on deep neural networks that maximize the likelihood of generated samples being in given real distribution [11]. Some deep generative models such as variational autoencoders [17] and the GANs [10] are able to mimic complex samples like images.\nThe GANs framework defines a zero-sum game between a generator G and a discriminator D. While the discriminator learns to distinguish between the generated samples from real samples by comparing two data distributions, the generator learns to mimic the real distribution as closely as possible. The objective of two networks is thereby defined as:\nmin G max D V (D,G) = Ex\u223cpdata(x)[logD(x)] + Ez\u223cpz(z)[log(1\u2212D(G(z)))]\nTheoretically, the Nash equilibrium of this zero-sum game is when the generator perfectly mimics pdata and the discriminator cannot distinguish the fake from the real and outputs 12 everywhere."}, {"heading": "3 Generative Replay", "text": "We first define several terminologies. In our continual learning framework, we define the sequence of tasks to be solved as a task sequence T = (T1, T2, \u00b7 \u00b7 \u00b7 , TN ) of N tasks.\nDefinition 1 A task Ti is to optimize a model towards an objective on data distribution Di, from which the training examples (xi,yi)\u2019s are drawn.\nNext, we call our model a scholar, as it is capable of learning a new task and teaching its knowledge to other networks. Note that the term scholar differs from standard notion of teacher-student framework of ensemble models [5], in which the networks either teach or learn only.\nDefinition 2 A scholar H is a tuple \u3008G,S\u3009, where a generator G is a generative model that produces real-like samples and a solver S is a task solving model parameterized by \u03b8.\nThe solver has to perform all tasks in the task sequence T. The full objective is thereby given as to minimize the unbiased sum of loss among all tasks in the task sequence E(x,y)\u223cD[L(S(x; \u03b8),y)], where D is the entire data distribution and L is a loss function. While being trained under the task Ti, the model is fed with samples drawn from Di."}, {"heading": "3.1 Proposed Method", "text": "We consider sequential training on our scholar model. However, training a single scholar model while referring to the recent copy of the network is equivalent to training a sequence of scholar models\n(Hi) N i=1 where the n-th scholar Hn (n > 1) learns the current task Tn and the knowledge of previous scholar Hn\u22121. Therefore, we describe our full training procedure as in Figure 1(a).\nTraining the scholar model from another scholar involves two independent procedures of training the generator and the solver. First, the new generator receives current task input x and replayed inputs x\u2032 from previous tasks. Real and replayed samples are mixed at a ratio that depends on the desired importance of a new task compared to the older tasks. The generator learns to reconstruct cumulative input space, and the new solver is trained to couple the inputs and targets drawn from the same mix of real and replayed data. Here, the replayed target is past solver\u2019s response to replayed input. Formally, the loss function of the i-th solver is given as\nLtrain(\u03b8i) = rE(x,y)\u223cDi [L(S(x; \u03b8i),y)] + (1\u2212 r) Ex\u2032\u223cGi\u22121 [L(S(x \u2032; \u03b8i), S(x \u2032; \u03b8i\u22121))] (1)\nwhere \u03b8i are network parameters of the i-th scholar and r is a ratio of mixing real data. As we aim to evaluate the model on original tasks, test loss differs from the training loss:\nLtest(\u03b8i) = rE(x,y)\u223cDi [L(S(x; \u03b8i),y)] + (1\u2212 r) E(x,y)\u223cDpast [L(S(x; \u03b8i),y)] (2)\nwhere Dpast is a cumulative distribution of past data. Second loss term is ignored in both function when i = 1 because there is no replayed data to refer to for the first solver.\nWe build our scholar model with a solver that has suitable architecture for solving a task sequence and a generator trained in the generative adversarial networks framework. However, our framework can employ any deep generative model as a generator."}, {"heading": "3.2 Preliminary Experiment", "text": "Prior to our main experiments, we show that the trained scholar model alone suffices to train an empty network. We tested our model on classifying MNIST handwritten digit database [19]. Sequence of scholar models were trained from scratch through generative replay from previous scholar. The accuracy on classifying full test data is shown in Table 1. We observed that the scholar model transfers knowledge without losing information."}, {"heading": "4 Experiments", "text": "In this section, we show the applicability of generative replay framework on various sequential learning settings. Generative replay based on a trained scholar network is superior than other continual learning approaches in that the quality of the generative model is the only constraint of the task\nperformance. In other words, training the networks with generative replay is equivalent to joint training on entire data when the generative model is optimal. To draw the best possible result, we used WGAN-GP [14] technique in training the generator.\nAs a base experiment, we test if generative replay enables sequential learning while compromising performance on neither the old tasks nor a new task. In section 4.1, we sequentially train the networks on independent tasks to examine the extent of forgetting. In section 4.2, we train the networks on two different yet relevant domains. We demonstrate that generative replay not only enables continual learning on our design of the scholar network but also compatible with other known structures. In section 4.3, we show that our scholar network can gather knowledge from different tasks to perform a meta-task, by training the network on disjoint subsets of training data.\nWe compare the performance of the solver trained with variants of replay methods. Our model with generative replay is notated in the figure as GR. We specify the upper bound by assuming a situation when the generator is perfect. Therefore, we replayed actual past data paired with the predicted targets from the old solver network. We denote this case as ER for exact replay. We also consider the opposite case when the generated samples do not resemble the real distribution at all. Such case is denoted as Noise. A baseline of naively trained solver network is denoted as None. We use the same notation throughout this section."}, {"heading": "4.1 Learning independent tasks", "text": "The most common experimental formulation used in continual learning literature [32, 18] is a simple image classification problem where the inputs are images from MNIST handwritten digit database [19], but pixel values of inputs are shuffled by a random permutation sequence unique to each task. The solver has to classify permuted inputs into the original classes. Since the most, if not all pixels are switched between the tasks, the tasks are technically independent from each other, being a good measure of memory retention strength of a network.\nWe observed that generative replay maintains past knowledge by recalling former task data. In Figure 2(a), the solver with generative replay (orange) maintained the former task performances throughout sequential training on multiple tasks, in contrast to the naively trained solver (violet). An average accuracy measured on cumulative tasks is illustrated in Figure 2(b). While the solver with generative replay achieved almost full performance on trained tasks, sequential training on a solver alone incurred catastrophic forgetting (violet). Replaying random gaussian noises paired with recorded responses did not help tempering performance loss (pink)."}, {"heading": "4.2 Learning new domains", "text": "Training independent tasks on the same network is inefficient because no information is to be shared. We thus demonstrate the advantage of our model in more reasonable settings where the model aids from solving multiple tasks. In particular, we consider the expanded generalization of classes to new domains which share semantically the same classes.\nA model operating in multiple domains has several advantages over that only works in a single domain. First, the knowledge of one domain can help better and faster understanding of other domains if not the domains are completely independent. Second, generalization over multiple domains may result in more universal knowledge that is applicable to unseen domains. Such phenomenon is also observed in infants learning to categorize objects [3, 4]. Encountering similar but diverse objects, young children can infer the properties shared within the category, and can make a guess of which category that the new object may belong to.\nWe tested if the model can incorporate the knowledge of a new domain with generative replay. In particular, we sequentially trained our model on classifying MNIST and Street View House Number (SVHN) dataset [23], and vice versa. Experimental details are provided in supplementary materials.\nFigure 3 illustrates the performance on the original task (thick curves) and the new task (dim curves). A solver trained alone lost its performance on the old task when no data are replayed (purple). Since MNIST and SVHN input data share similar spatial structure, the performance on former task did not drop to zero, yet the decline was critical. In contrast, the solver with generative replay (orange) maintained its performance on the first task while accomplishing the second one. The results were no worse than replaying past real inputs paired with predicted responses from the old solver (green). In both cases, the model trained without any replay data achieved slightly better performance on new task, as the network was solely optimized to solve the second task.\nGenerative replay is compatible with other continual learning models as well. For instance, Learning without Forgetting (LwF), which replays current task inputs to revoke past knowledge, can be augmented with generative models that produce samples similar to former task inputs. Because LwF requires the context information of which task is being performed to use task-specific output layers, we tested the performance separately on each task. Note that our scholar model with generative replay does not need the task context.\nIn Figure 5, we compare the performance of LwF algorithm with a variant LwF-GR, where the task-specific generated inputs are fed to maintain older network responses. We used the same training\nregime as proposed in the original literature, namely warming up the new network head for some amount of the time and then fine tuning the whole network. The solver trained with original LwF algorithm loses performance on the first task when fine-tuning begins, due to alteration to shared network (green). However, with generative replay, the network maintains most of the past knowledge (orange)."}, {"heading": "4.3 Learning new classes", "text": "To illustrate that generative replay can recollect the past knowledge even when the inputs and targets are highly biased between the tasks, we propose a new experiment in which the network is sequentially trained on disjoint data. In particular, we assume a situation where the agent can access examples of only a few classes at a time. The agent eventually has to correctly classify examples from all classes after being sequentially trained on mutually exclusive subsets of classes. We tested the networks on MNIST handwritten digit database.\nNote that training the artificial neural networks independently on classes is difficult in standard settings, as the network responses may change to match the new target distribution. Hence replaying inputs and outputs that represent former input and target distributions is inevitable to train a balanced network. We thus compare the variants described earlier in this section from the perspective of whether the input and target distributions of cumulative real data is recovered. For ER and GR models, both the input and target distributions represent cumulative distribution. Noise model maintains cumulative target distributions, but the input distribution only mirrors current distribution. None model has current distribution for both.\nIn Figure 6, we divided MNIST dataset into 5 disjoint subsets, each of which contains samples from only 2 classes. When the networks are sequentially trained on the subsets, we observed that a naively trained classifier completely forgot previous classes and only learned the new subset of data (purple).\nRecovering only the past output distribution without a meaningful input distribution did not help retaining knowledge, as evidenced by the model with a noise generator (pink). When both the input and output distributions are reconstructed, generative replay evoked previously learnt classes, and the model was able to discriminate all encountered classes (orange).\nBecause we assume that the past data are completely discarded, we trained the generator to mimic both current inputs and the generated samples from the previous generator. The generator thus reproduces cumulative input distribution of all encountered examples so far. As shown in Figure 7, generated samples from trained generator include examples equally from encountered classes."}, {"heading": "5 Discussion", "text": "We introduce deep generative replay framework, which allows sequential learning on multiple tasks by generating and rehearsing fake data that mimics former training examples. The trained scholar model comprising a generator and a solver serves as a knowledge base of a task. Although we described a cascade of knowledge transfer between a sequence of scholar models, a little change in formulation proposes a solution to other topically relevant problems. For instance, if the previous scholar model is just a past copy of the same network, it can learn multiple tasks without explicitly partitioning the training procedure.\nAs comparable approaches, regularization methods such as EWC and careful training the shared parameters as in LwF have shown that catastrophic forgetting could be alleviated by protecting former knowledge of the network. However, regularization approaches constrain the network with additional loss terms for protecting weights, so they potentially suffer from the tradeoff between the performances on new and old tasks. To guarantee good performances on both tasks, one should train on a huge network that is much larger than normally needed. Also, the network has to maintain the same structure throughout all tasks when the constraint is given specific to each parameter as in EWC. Drawbacks of LwF framework are also twofold: the performance highly depends on the relevance of the tasks, and the training time for one task linearly increases with the number of former tasks.\nIn Table 2, we compare our method with Elastic Weight Consolidation and Learning without Forgetting, which are proven to achieve the best results so far in own branches. In marked contrast to other approaches, generative replay maintains the former knowledge solely with produced input-target pairs, so it allows ease of balancing the former and new task performance and flexible knowledge\ntransfer. Most importantly, the network is jointly optimized towards task objectives, hence guaranteed to achieve the full performance when the former input spaces are recovered by the generator. One defect of generative replay framework is that the efficacy of algorithm heavily depends on the quality of a generator. Indeed, we observed some performance loss while training the model on SVHN dataset with in same setting employed in section 4.3. Detailed analysis is provided in supplementary materials.\nWe acknowledge that the three branches are not completely exclusive, as they contribute to memory retention at different levels. Nevertheless, each method poses some constraints on training procedure or network configurations, and there is no straightforward mixture of any two frameworks. Still, we believe a good mix of three frameworks would give better solution to the chronic problem in continual learning.\nFuture works of generative replay may include extension to reinforcement learning domain or developing continuously evolving network that maintains knowledge from previous copy of the self. Also, we expect the improvements in training deep generative models would directly aid the performance of generative replay framework on more complex domains."}], "references": [{"title": "Memory retention\u2013the synaptic stability versus plasticity dilemma", "author": ["W.C. Abraham", "A. Robins"], "venue": "Trends in neurosciences,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2005}, {"title": "Avoiding catastrophic forgetting by coupling two reverberating neural networks", "author": ["B. Ans", "S. Rousset"], "venue": "Comptes Rendus de l\u2019Acade\u0301mie des Sciences-Series III-Sciences de la Vie,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1997}, {"title": "Infants\u2019 ability to draw inferences about nonobvious object properties: Evidence from exploratory play", "author": ["D.A. Baldwin", "E.M. Markman", "R.L. Melartin"], "venue": "Child development,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1993}, {"title": "The development of object categorization in young children: Hierarchical inclusiveness, age, perceptual attribute, and group versus individual analyses", "author": ["M.H. Bornstein", "M.E. Arterberry"], "venue": "Developmental psychology,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Ensemble methods in machine learning", "author": ["T.G. Dietterich"], "venue": "In International workshop on multiple classifier systems,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2000}, {"title": "Evidence for large long-term memory capacities in baboons and pigeons and its implications for learning and the evolution of cognition", "author": ["J. Fagot", "R.G. Cook"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "Catastrophic forgetting in connectionist networks", "author": ["R.M. French"], "venue": "Trends in cognitive sciences,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1999}, {"title": "Internally generated reactivation of single neurons in human hippocampus during free recall", "author": ["H. Gelbard-Sagiv", "R. Mukamel", "M. Harel", "R. Malach", "I. Fried"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["R. Girshick", "J. Donahue", "T. Darrell", "J. Malik"], "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Generative adversarial nets", "author": ["I. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "NIPS 2016 tutorial", "author": ["I.J. Goodfellow"], "venue": "Generative adversarial networks. CoRR,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2017}, {"title": "An empirical investigation of catastrophic forgetting in gradient-based neural networks", "author": ["I.J. Goodfellow", "M. Mirza", "D. Xiao", "A. Courville", "Y. Bengio"], "venue": "arXiv preprint arXiv:1312.6211,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Long-term dendritic spine stability in the adult", "author": ["J. Grutzendler", "N. Kasthuri", "W.-B. Gan"], "venue": "cortex. Nature,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2002}, {"title": "Improved training of wasserstein gans", "author": ["I. Gulrajani", "F. Ahmed", "M. Arjovsky", "V. Dumoulin", "A. Courville"], "venue": "arXiv preprint arXiv:1704.00028,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2017}, {"title": "A biologically inspired dual-network memory model for reduction of catastrophic forgetting", "author": ["M. Hattori"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Using fast weights to deblur old memories", "author": ["G.E. Hinton", "D.C. Plaut"], "venue": "In Proceedings of the ninth annual conference of the Cognitive Science Society,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1987}, {"title": "Auto-encoding variational bayes", "author": ["D.P. Kingma", "M. Welling"], "venue": "arXiv preprint arXiv:1312.6114,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2013}, {"title": "Overcoming catastrophic forgetting in neural networks", "author": ["J. Kirkpatrick", "R. Pascanu", "N. Rabinowitz", "J. Veness", "G. Desjardins", "A.A. Rusu", "K. Milan", "J. Quan", "T. Ramalho", "A. Grabska-Barwinska"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2017}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1998}, {"title": "Learning without forgetting", "author": ["Z. Li", "D. Hoiem"], "venue": "In European Conference on Computer Vision,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "Catastrophic interference in connectionist networks: The sequential learning problem", "author": ["M. McCloskey", "N.J. Cohen"], "venue": "Psychology of learning and motivation,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1989}, {"title": "Human-level control through deep reinforcement learning", "author": ["V. Mnih", "K. Kavukcuoglu", "D. Silver", "A.A. Rusu", "J. Veness", "M.G. Bellemare", "A. Graves", "M. Riedmiller", "A.K. Fidjeland", "G. Ostrovski"], "venue": "Nature, 518(7540):529\u2013533,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Reading digits in natural images with unsupervised feature learning", "author": ["Y. Netzer", "T. Wang", "A. Coates", "A. Bissacco", "B. Wu", "A.Y. Ng"], "venue": "In NIPS workshop on deep learning and unsupervised feature learning,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2011}, {"title": "Hippocampal and neocortical contributions to memory: Advances in the complementary learning systems framework", "author": ["R.C. O\u2019Reilly", "K.A. Norman"], "venue": "Trends in cognitive sciences,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2002}, {"title": "Play it again: reactivation of waking experience and memory", "author": ["J. O\u2019Neill", "B. Pleydell-Bouverie", "D. Dupret", "J. Csicsvari"], "venue": "Trends in neurosciences,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2010}, {"title": "Creating a false memory in the hippocampus", "author": ["S. Ramirez", "X. Liu", "P.-A. Lin", "J. Suh", "M. Pignatelli", "R.L. Redondo", "T.J. Ryan", "S. Tonegawa"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2013}, {"title": "Connectionist models of recognition memory: Constraints imposed by learning and forgetting functions", "author": ["R. Ratcliff"], "venue": "Psychological review,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1990}, {"title": "Catastrophic forgetting in neural networks: the role of rehearsal mechanisms", "author": ["A. Robins"], "venue": "In Artificial Neural Networks and Expert Systems,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1993}, {"title": "Catastrophic forgetting, rehearsal and pseudorehearsal", "author": ["A. Robins"], "venue": "Connection Science,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1995}, {"title": "Deep boltzmann machines", "author": ["R. Salakhutdinov", "G. Hinton"], "venue": "In Artificial Intelligence and Statistics,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2009}, {"title": "Dropout: a simple way to prevent neural networks from overfitting", "author": ["N. Srivastava", "G.E. Hinton", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1929}, {"title": "Compete to compute", "author": ["R.K. Srivastava", "J. Masci", "S. Kazerounian", "F. Gomez", "J. Schmidhuber"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2013}], "referenceMentions": [{"referenceID": 5, "context": "One distinctive ability of humans and large primates is to continually learn new skills and accumulate knowledge throughout the lifetime [6].", "startOffset": 137, "endOffset": 140}, {"referenceID": 12, "context": "Even in small vertebrates such as rodents, established connections between neurons seem to last more than an year [13].", "startOffset": 114, "endOffset": 118}, {"referenceID": 0, "context": "The flexible memory system results from a good balance between synaptic plasticity and stability [1].", "startOffset": 97, "endOffset": 100}, {"referenceID": 20, "context": "Continual learning in deep neural networks, however, suffers from a phenomenon called catastrophic forgetting [21], in which the performance of a model on previously learned tasks abruptly degrades when trained for a new task.", "startOffset": 110, "endOffset": 114}, {"referenceID": 28, "context": "Previous attempts to alleviate catastrophic forgetting often relied on episodic memory system that stores past data [29].", "startOffset": 116, "endOffset": 120}, {"referenceID": 26, "context": "While a network trained in this manner performs as well as separate networks trained solely on each task [27], a major drawback of memory-based approach is that it requires large working memory to store and replay past inputs.", "startOffset": 105, "endOffset": 109}, {"referenceID": 23, "context": "While several biological mechanisms contribute to this at different levels, primate brain\u2019s the most apparent distinction from artificial neural networks is the existence of separate, interacting memory systems [24].", "startOffset": 211, "endOffset": 215}, {"referenceID": 24, "context": "experiences stored in the hippocampus [25]\u2013a mechanism which inspired the use of experience replay [22] in training deep reinforcement learning agents.", "startOffset": 38, "endOffset": 42}, {"referenceID": 21, "context": "experiences stored in the hippocampus [25]\u2013a mechanism which inspired the use of experience replay [22] in training deep reinforcement learning agents.", "startOffset": 99, "endOffset": 103}, {"referenceID": 7, "context": "Rather, it regenerates earlier inputs by synchronized reactivations that are induced during unconscious or conscious recall or specific phase of sleep [8].", "startOffset": 151, "endOffset": 154}, {"referenceID": 25, "context": "Stimulation of certain memory traces in the hippocampus can even create false memory that was never experienced [26].", "startOffset": 112, "endOffset": 116}, {"referenceID": 29, "context": "Specifically, deep generative models such as deep Boltzmann machines [30] or a variational autoencoder [17] can generate high-dimensional samples that closely match observed inputs.", "startOffset": 69, "endOffset": 73}, {"referenceID": 16, "context": "Specifically, deep generative models such as deep Boltzmann machines [30] or a variational autoencoder [17] can generate high-dimensional samples that closely match observed inputs.", "startOffset": 103, "endOffset": 107}, {"referenceID": 9, "context": "In particular, we train a deep generative model in the generative adversarial networks (GANs) framework [10] to mimic past data.", "startOffset": 104, "endOffset": 108}, {"referenceID": 20, "context": "The term catastrophic forgetting or catastrophic interference was first introduced by McCloskey and Cohen in 1980\u2019s [21].", "startOffset": 116, "endOffset": 120}, {"referenceID": 6, "context": "Several works illustrate empirical consequences in sequential learning settings [7, 27], and provide a few primitive solutions [16, 28] such as replaying all previous data.", "startOffset": 80, "endOffset": 87}, {"referenceID": 26, "context": "Several works illustrate empirical consequences in sequential learning settings [7, 27], and provide a few primitive solutions [16, 28] such as replaying all previous data.", "startOffset": 80, "endOffset": 87}, {"referenceID": 15, "context": "Several works illustrate empirical consequences in sequential learning settings [7, 27], and provide a few primitive solutions [16, 28] such as replaying all previous data.", "startOffset": 127, "endOffset": 135}, {"referenceID": 27, "context": "Several works illustrate empirical consequences in sequential learning settings [7, 27], and provide a few primitive solutions [16, 28] such as replaying all previous data.", "startOffset": 127, "endOffset": 135}, {"referenceID": 30, "context": "It is suggested that regularization methods such as dropout [31] and L2 regularization help reduce interference of new learning [12].", "startOffset": 60, "endOffset": 64}, {"referenceID": 11, "context": "It is suggested that regularization methods such as dropout [31] and L2 regularization help reduce interference of new learning [12].", "startOffset": 128, "endOffset": 132}, {"referenceID": 17, "context": "Furthermore, elastic weight consolidation (EWC) proposed in [18] demonstrates that protecting certain weights based on their importance to the previous tasks tempers the performance loss.", "startOffset": 60, "endOffset": 64}, {"referenceID": 8, "context": "Lowering learning rates on some parameters is also known to reduce forgetting [9].", "startOffset": 78, "endOffset": 81}, {"referenceID": 19, "context": "A recently proposed method called Learning without Forgetting (LwF) [20] addresses the problem of sequential learning in image classification tasks while minimizing alteration on shared network parameters.", "startOffset": 68, "endOffset": 72}, {"referenceID": 28, "context": "Called a pseudorehearsal technique, this method is claimed to maintain old input-output patterns without accessing real data [29].", "startOffset": 125, "endOffset": 129}, {"referenceID": 1, "context": "When the tasks are as elementary as coupling two binary patterns, simply feeding random noises and corresponding responses suffices [2].", "startOffset": 132, "endOffset": 135}, {"referenceID": 14, "context": "A more recent work proposes an architecture that resembles the structure of the hippocampus to facilitate continual learning for more complex data such as small binary pixel images [15].", "startOffset": 181, "endOffset": 185}, {"referenceID": 10, "context": "Specifically, we consider deep generative models based on deep neural networks that maximize the likelihood of generated samples being in given real distribution [11].", "startOffset": 162, "endOffset": 166}, {"referenceID": 16, "context": "Some deep generative models such as variational autoencoders [17] and the GANs [10] are able to mimic complex samples like images.", "startOffset": 61, "endOffset": 65}, {"referenceID": 9, "context": "Some deep generative models such as variational autoencoders [17] and the GANs [10] are able to mimic complex samples like images.", "startOffset": 79, "endOffset": 83}, {"referenceID": 4, "context": "Note that the term scholar differs from standard notion of teacher-student framework of ensemble models [5], in which the networks either teach or learn only.", "startOffset": 104, "endOffset": 107}, {"referenceID": 18, "context": "We tested our model on classifying MNIST handwritten digit database [19].", "startOffset": 68, "endOffset": 72}, {"referenceID": 13, "context": "To draw the best possible result, we used WGAN-GP [14] technique in training the generator.", "startOffset": 50, "endOffset": 54}, {"referenceID": 31, "context": "The most common experimental formulation used in continual learning literature [32, 18] is a simple image classification problem where the inputs are images from MNIST handwritten digit database [19], but pixel values of inputs are shuffled by a random permutation sequence unique to each task.", "startOffset": 79, "endOffset": 87}, {"referenceID": 17, "context": "The most common experimental formulation used in continual learning literature [32, 18] is a simple image classification problem where the inputs are images from MNIST handwritten digit database [19], but pixel values of inputs are shuffled by a random permutation sequence unique to each task.", "startOffset": 79, "endOffset": 87}, {"referenceID": 18, "context": "The most common experimental formulation used in continual learning literature [32, 18] is a simple image classification problem where the inputs are images from MNIST handwritten digit database [19], but pixel values of inputs are shuffled by a random permutation sequence unique to each task.", "startOffset": 195, "endOffset": 199}, {"referenceID": 2, "context": "Such phenomenon is also observed in infants learning to categorize objects [3, 4].", "startOffset": 75, "endOffset": 81}, {"referenceID": 3, "context": "Such phenomenon is also observed in infants learning to categorize objects [3, 4].", "startOffset": 75, "endOffset": 81}, {"referenceID": 22, "context": "In particular, we sequentially trained our model on classifying MNIST and Street View House Number (SVHN) dataset [23], and vice versa.", "startOffset": 114, "endOffset": 118}], "year": 2017, "abstractText": "Attempts to train a comprehensive artificial intelligence capable of solving multiple tasks have been impeded by a chronic problem called catastrophic forgetting. Although simply replaying all previous data alleviates the problem, it requires large memory and even worse, often infeasible in real world applications where the access to past data is limited. Inspired by the generative nature of hippocampus as a short-term memory system in primate brain, we propose the Deep Generative Replay, a novel framework with a cooperative dual model architecture consisting of a deep generative model (\u201cgenerator\u201d) and a task solving model (\u201csolver\u201d). With only these two models, training data for previous tasks can easily be sampled and interleaved with those for a new task. We test our methods in several sequential learning settings involving image classification tasks.", "creator": "LaTeX with hyperref package"}}}